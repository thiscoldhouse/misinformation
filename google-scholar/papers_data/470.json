[{"title": "Investigating News Source Characterizations using Reddit Audience-based Metrics", "year": "2022", "pdf_data": "Investigating News Source\nCharacterizations using Reddit\nAudience-based Metrics\nJunita Sirait\nSubmitted in Partial Fulfillment\nof the\nPrerequisite for Honors\nin Computer Science\nunder the advisement of Eni Mustafaraj\nApril 2022\n\u00a92022 Junita Sirait\nAbstract\nIn this digital age, there is an abundance of news sources, with no one database\nthat characterizes the whole set of news sources. It is a difficult task to provide a\nmeaningful summary regarding the whole set of news producers and to characterize\neach of them, due to their massive number and the domain knowledge needed to\nmanually characterize them. In this thesis, I investigate the task of news sources\ncharacterization using only their Reddit audience sharing practices and metrics as\nthe features of the news sources. In total, I include in my analysis 2,647 news sources\nrepresented by 2,189 subreddits, with sharing metrics including the number of Reddit\nsubmissions that mention those news sources, the number of associated comments,\nand the total upvote ratio of those submissions.\nBy visualizing the representations of these news sources built using their Reddit\naudience-based metrics, I find that the news sources that are close together in the\nrepresentational space indeed have some \u201csimilar\u201d characteristics, although the notion\nof similar is different from one neighborhood of news sources to another. Therefore,\nfor unlabeled news sources, one can potentially observe where they are located in\nthe representational space built with the Reddit audience-based metrics as outlined\nin this thesis, and infer particular characteristics of those unlabeled news sources by\nleveraging known facts about the neighboring news sources.\nIn addition to the visual examination of the representations of the news sources,\nI also attempt to cluster them together using their Reddit audience-based sharing\nstatistics. Although imperfect, the clustering results suggest that particular news\nsource characteristics such as country of origin and some specific themes are promi-\nnent features that give rise to cluster structures that are easier to identify using k-\nmeans algorithms, than other features. Similarly, a small case study to build a simple\nclassifier suggests that building a classifier for predictive tasks is easier accomplished\nfor some features than others.\nI find that there are some evidence that Reddit audience sharing statistics alone\ncan be used for inferring some characteristics of news sources. Even a simple explo-\nration of comparing the total sharing frequency of a news source and the number\nof subreddits mentioning those news sources leads to interesting insights about news\nsourcepopularityandthebroadnessoftheiraudience, asshownintheExploringNews\nSources section. However, more work is needed to further engineer or improve these\nfeatures and potentially build models to predict these characteristics for unlabelled\nnews sources.\nAcknowledgments\nI am incredibly grateful to Professor Eni Mustafaraj, who has not only advised\nmy honor thesis, but also given unwavering guidance, support, and encouragement\nthroughout my undergraduate journey. What a good fortune it is to have Eni as a\nprofessor, advisor, and mentor.\nI would also like to express my gratitude to Professor Cassandra Pattanayak and\nProfessor Sohie Lee for being on my thesis committee and for their insightful advice\nand feedback. Thank you to Professor Ann Trenk for graciously agreeing to be the\nHonors Visitor on my thesis committee.\nThank you to Wellesley Cred Lab members, especially Beatriz Paulino, Ashley\nJang, Annabel Uhlman, Veronica Lin, and Ropah Shava, who have helped me greatly\nin my data collection and labelling processes.\nTo my friends who have patiently listened to my rants and ideas, and been there\nto offer encouragement and support \u2013 thank you!\nMy most tremendous gratitude to my Dad, Mom, and Brother, for providing\nlimitless support and warm comfort throughout my life.\nContents\n1 Introduction 12\n2 Background 16\n2.1 About News and Who Produces It . . . . . . . . . . . . . . . . . . . 16\n2.2 News Source Characterization . . . . . . . . . . . . . . . . . . . . . . 17\n2.3 Reddit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.3.1 Reddit as a Platform . . . . . . . . . . . . . . . . . . . . . . . 18\n2.3.2 Reddit as a Data Source . . . . . . . . . . . . . . . . . . . . . 23\n3 Related Works 25\n4 Introducing the Datasets 29\n4.1 GDELT and Muck Rack to define \u201cNews Source\u201d . . . . . . . . . . . . 29\n4.1.1 GDELT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.1.2 Muck Rack . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n4.2 Reddit Pushshift Dataset . . . . . . . . . . . . . . . . . . . . . . . . . 32\n5 Data Exploration 35\n5.1 Exploring News Sources . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.2 Exploring Subreddits . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n5.2.1 Subreddits Subscribers . . . . . . . . . . . . . . . . . . . . . . 43\n5.2.2 Subreddits Activity . . . . . . . . . . . . . . . . . . . . . . . . 44\n6 Methods for Data Representation 48\n4\n6.1 Building news source dataset . . . . . . . . . . . . . . . . . . . . . . . 49\n6.2 Building News Sources Representation . . . . . . . . . . . . . . . . . 51\n6.2.1 Streaming and processing Reddit zst data . . . . . . . . . . . 52\n6.2.2 Data Representation . . . . . . . . . . . . . . . . . . . . . . . 53\n6.2.3 Filtering Subreddits . . . . . . . . . . . . . . . . . . . . . . . . 54\n6.2.4 Filtering News Sources . . . . . . . . . . . . . . . . . . . . . . 55\n6.2.5 Scaling and PCA Dimensionality Reduction . . . . . . . . . . 56\n7 Methods for Data Analysis 59\n7.1 Visual Investigation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n7.2 Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n7.2.1 Clustering Algorithms Overview . . . . . . . . . . . . . . . . . 64\n7.2.2 Small Scale: Clustering using sports subreddits . . . . . . . . 68\n7.2.3 Big Scale: K-Means clustering for the entire dataset . . . . . . 72\n7.2.4 Clustering Conclusions and Challenges . . . . . . . . . . . . . 75\n7.3 Building Classifier: A Small Case Study . . . . . . . . . . . . . . . . 76\n8 Conclusion and Future Work 79\n8.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\n8.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nA Big Scale Clustering Result 84\nB Manually Removed Sites 88\nC Example of One NDJSON Representation of Reddit Submission 91\nD Code Repository 95\n5\nList of Figures\n2-1 The page of subreddit r/news (as highlighted in yellow). It contains\nsubmission space, as well as details about the subreddit such as de-\nscriptions, number of members/subscribers as highlighted in green as\nwell as subreddit-specific rules (not shown here). The first post that\nshows up has 18k total votes (as highlighted in blue), which are the\nhighest among the most recent posts. . . . . . . . . . . . . . . . . . . 20\n2-2 An example of a Reddit user\u2019s profile. u/Stuck_In_The_Matrix is\nthe Reddit username of Jason Baumgartner, who is the creator of the\nPushshift dataset. The amount of Karma he has is highlighted in yellow. 22\n4-1 A snapshot of some of the key-value pairs in one of the Python dictio-\nnaries representing a Reddit submission. . . . . . . . . . . . . . . . . 33\n5-1 Figure 5a shows that a lot of news sources are each shared in 100 or\nless different subreddits, but there are some that are shared in upto\n1000 different subreddits. Figure 5b shows the same information, that\nmost (98.8%) news sources appear in 400 subreddits or less. . . . . . 39\n5-2 Subreddit count v. Mention count of News sources. Quadrant num-\nbers are labeled in red. News sources in the first quadrant are both\nmentioned very frequently and in many subreddits (broad appeal), for\nexample theguardian.com, cnn.com, and nytimes.com. News sources\nin the second quadrant are mentioned very frequently but in fewer sub-\nreddits (more niche), for example mlb.com, thehindu.com, and breit-\nbart.com. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6\n5-3 Subreddits subscribers. More than half of the subreddits in our dataset\nhave about 1000 or less subscribers. . . . . . . . . . . . . . . . . . . . 47\n5-4 There is a positive correlation between the number of unique news\nsources and total news links shared in each subreddit (r=0.55). Some\noutliers, shown in the bottom left corner, are subreddits that are mod-\nerated by bots to only share news from specific news sources, such as\nr/BBCauto among others. . . . . . . . . . . . . . . . . . . . . . . . . 47\n6-1 An example ofReddit submission. The highlighted parts are what Iex-\ntract from the NDJSON files representing this submission. Note that\nthe current version of Reddit only shows the total number of votes\nreceived (weighted by +1 for upvotes and -1 for downvotes). How-\never, the Pushshift dataset contains the actual upvote ratio (number\nof upvotes divided by total votes), as does the old version of Reddit\n(old.reddit.com). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n6-2 Thefigureaboveshowsthecumulativepercentageofvarianceexplained\nby a set number of principal components derived from the subreddit-\nbased features. The red line shows that the first 300 principal compo-\nnents explain 0.86 of the features variance). . . . . . . . . . . . . . . 58\n7-1 Thecompletet-SNEparametersusedinthisthesistovisualizethenews\nsources representations by projecting them down to three dimensions. 61\n7-2 News source representations in 3D with colors representing their reli-\nability (green for unreliable, red for reliable, and purple for unlabeled\nnews sources). In the left side figure we see that news sources are\nnot exactly grouped together based on their reliability. However, some\nunreliable news sources (enclosed by the green circle) are very close to-\ngether. The same view with only unreliable news sources is presented\nby the figure on the right for clarity. Interactive three dimensional rep-\nresentations accessible at https://newssource-vis.herokuapp.com/ . 62\n7\n7-3 \u2018antiwar.com\u2019 is a close neighbor of a group of unreliable news sources.\nAn intuitive suggestion is that perhaps \u2018antiwar.com\u2019 is an unreliable\nsource. After manual investigation and according to Media Bias Fact\nCheck as well as Politifact, \u2018antiwar.com\u2019 indeed has medium to low\nreliability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n7-4 Different ways of calculating the distance between two clusters in ag-\nglomerative clustering, depending on the linkage criterion. Source:\nFigure 6.2 of Everitt et al. (2011) [15] . . . . . . . . . . . . . . . . . . 66\n7-5 Dendrogram of the resulting agglomerative clustering of news sources\nthataresharedinsports-relatedsubreddits(NFL,NBA,PremierLeague),\nwith weighted-linkage. We see that most UK-based news sources are\nclustered together (green branches), news sources that heavily write\nabout basketball and American football are clustered together (red\nbranches), and the more general news sources clustered together (or-\nange). However this is not a perfect clustering since some UK-based\nnews sources as well as sports-themed news sources are placed in the\norange more general (orange) cluster. . . . . . . . . . . . . . . . . . . 70\n7-6 Different WGSS values for different cluster sizes for the small dataset\nacquired by only considering sports-related subreddits. We see that\nthe elbow of the WGSS curve is found at cluster size k = 3, as after\nthis point an additional cluster does not significantly decrease WGSS. 71\n7-7 The silhouette coefficient values for individual data points. The red\nlines separate the three different clusters. The first cluster contains\nthe news sources that heavily write about sports, the second cluster\ncontains UK-based news sources, and the third cluster contains the re-\nmaining news sources that are general and only sometimes write about\nsports. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n7-8 Different WGSS values for different cluster sizes for the whole 2,647\nnews source dataset with all 2,189 subreddits used in building their\nrepresentations. There is no obvious elbow of the WGSS curve. . . . 73\n8\n7-9 Silhouette Coefficient values for different cluster sizes. The highest\nsilhouette coefficient value is achieved with k = 28, with silhouette\ncoefficient value being 0.2. However, in general these values are rather\nlow. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n7-10 Silhouette coefficient values of news source data points in the 28 dif-\nferent clusters. The red lines separate the different clusters. Some\nclusters have reasonably good silhouette coefficients while some others\nhave low and therefore bad silhouette coefficient values. . . . . . . . . 75\n7-11 The three dimensional visualization of news sources based in Australia,\nFrance, and Germany seem to be well (although not perfectly) sepa-\nrated. The green dots represent Germany-based news sources, the\npurple dots represent France-based news sources, and the red dots rep-\nresent Australia-based news sources. . . . . . . . . . . . . . . . . . . 77\n8-1 A preliminary graph built using only the top 200 subreddits ranked\nby the number of their subscribers. The size of the nodes is scaled to\nrepresent the number of total mentions of the associated news sources\n, while the width of the edges represents the strength of connection\nor similarity between two news sources calculated using the number\nof common subreddits they appear together and the similarity of their\nsharing frequencies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n9\nList of Tables\n5.1 Among the submissions that contain at least one URL each, 25% con-\ntain links to news sources and user generated content such as blogs\nand podcasts. Our set of news sources makes up about 7% of the links\nbeing shared on Reddit posts. . . . . . . . . . . . . . . . . . . . . . . 36\n5.2 Top 20 sites (not necessarily news sources) that are shared the most\non Reddit. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.3 Top 20 news sources that are shared the most on Reddit. . . . . . . . 38\n5.4 Top 20 news sources ranked by the number of subreddits they are\nshared in. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n5.5 Top 20 subreddits ranked based on the number of their subscribers. . 43\n5.6 Top 20 subreddits with the most submissions posted in them. . . . . 44\n5.7 Top 20 subreddits with the highest number of unique news source en-\ntities shared in them. . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.1 Summary of the number of news sources recognized by GDELT and\nMuck Rack, and the little overlap between the two. . . . . . . . . . . 51\n6.2 An example of a news source representation. The example news source\nis nytimes.com, with an example representation based on r/investing\nwhich is one of the subreddits being considered. In a later section, this\nmatrix will be further processed by scaling and dimensionality reduction. 54\nA.1 Prominentcharacteristicsfoundineachcluster, ifany, aswellassilhou-\nette coefficient means for the different 28 clusters found using k-means\nclustering of the whole dataset. . . . . . . . . . . . . . . . . . . . . . 87\n10\nB.1 Alistof133sitesImanuallyremovefrommyinitialsetofnewssources,\nbecause some of these sites are more appropriately categorized as user-\ngenerated content hosts, and some others are not news related sites. . 90\n11\nChapter 1\nIntroduction\nEngaging with news is how we learn about events and information originating in\nvarious places all around the globe. In this digital age, news is abundant as the\nnumber of news producers, aggregators, and spreaders is multiplying thanks to the\nadvancing digital technology, which lowers the technical barrier of participating in\nthe online news ecosystem.\nHowever, even with the same advanced technology, there is not an organization\nor database in the world that is thoroughly keeping track of these prominent actors\nin the online news ecosystem. It is a difficult task to provide a meaningful summary\nregarding the whole set of news producers and to characterize each of them, due to\ntheir massive number and the distributed nature of how the Web works.\nManual investigation to summarize and characterize each of them is simply too\nexpensive in terms of time and labor. Automated ways of doing so have been at-\ntempted (largely by companies or long-term big research projects), by characterizing\nnot only based on the self-reported labels of news sources, but also the actual news\narticles that are produced by them . Yet this is also resource-expensive in terms of\nthe computing power that is needed to do so, and the lack of high quality training\ndata. As a consequence, the resulting database of news source characterizations is\neither only available as a paid service, incomplete, or hard to replicate.\nGenerally, the efforts of news sources characterizations can be divided into three\nmain categories: a) content-based, b) audience-based, and c) propagation-based.\n12\nThe efforts that I listed in the previous paragraph are mainly concerned with\ncontent-based characterization. They depend on Natural Language Processing al-\ngorithms, which often need huge computational power and big high-quality training\ndatasets. My thesis, on the other hand, aims to investigate audience-based charac-\nterization of news sources. Here, the term \u201caudience\u201d is defined as people who engage\nin reading, sharing, commenting, liking, and discussing news on the internet. These\nengagements take place in various online platforms, for example Facebook, Twitter,\nor Reddit. This thesis focuses on the Reddit audience, who discuss and engage with\nnews articles in theme-specific communities on Reddit, called \u201csubreddits\u201d.\nBy focusing on the audience of the global news sources, I aim to investigate\nwhether we can use this audience-based approach in answering questions about the\nnews ecosystem in a large view or individual contexts. For example, we could inves-\ntigate questions from the following list:\n\u2022What news sources are most popular across different subreddits?\n\u2022Which ones are shared the most frequently regardless of the subreddits (i.e.\nlargest sharing volume)?\n\u2022Can we infer the reliability of news sources based on their co-occurrences with\nother news sources in various subreddits? What about their political biases?\n\u2022What is their primary medium (e.g., TV, radio, Web)?\n\u2022What is their country of origin and language?\nCombining these kinds of questions, I formulate this research question:\nRQ:Can we use news source audience engagement on Reddit to create meaningful\nrepresentations, which in turn will allow us to investigate a series of characteristics\nof news sources using unsupervised and supervised techniques?\nThisthesis, ismyattempttoanswerthisquestion. Inthisdocument, Ifirstgoover\nsomebackgroundinformationaboutnewssources,newssourcescharacterizations,and\nReddit in Section 2. Then, in Section 3, I connect my work to existing literature on\n13\nthe topic. In Section 4, I introduce the source of my dataset to build a dataset of\nsites I recognize as news sources, as well as audience engagement metrics for their\nrepresentations. In Section 5.1 I investigate the total sharing frequency of news\nsources and compare it to the number of subreddits in which those news sources are\nshared, to characterize the popularity and broadness of appeal of those news sources.\nIn Section 6.2.2, I build news sources representations using the subreddits that\ndiscuss them as their features, representing them as a matrix. I then explore and\nprocess this matrix including by filtering subreddits in Section 6.2.3, filtering news\nsources in Section 6.2.4, and employing the dimensionality reduction algorithm PCA\nin Section 6.2.5.\nIn Section 7.1, using the vector representations of the news sources, I employ\nt-SNE to visualize news sources in a three dimensional space and I visually inves-\ntigate whether news sources that are closer together (have short distance between\nthem) share similar characteristics. In Section 7.2, I also attempt to cluster the news\nsources based on their vector representations, to evaluate if the news sources that\nare close together have any similar characteristics. If they do, then we can reason\nthat embedding news sources based on their audience, using the method outlined in\nthis thesis, does indeed yield in news source representations that place news sources\nwith certain similarities together. Knowing this, for the unlabeled news sources that\nare in our dataset, we can infer particular characteristics for them, based on their\nclose neighbors in the vector space. As a small case study, in Section 7.3 I attempt\nto build classifier models to predict some characteristics of news sources, particularly\ntheir country of origin, and their reliability.\nIn Section 8.1 I summarize my findings, and I outline future works to undertake\nin Section 8.2.\nContributions of this thesis are as follows:\n\u2022In building a set of news sources, I find that there is little overlap between what\nare considered as news sources by the freely accessible GDELT project, and the\ncompany Muck Rack, confirming the need of a deeper understanding and more\ncomplete record of all available news sources.\n14\n\u2022I investigate a novel way of news sources representation by solely using their\nsharing statistics on Reddit, and explore its usefulness in news source charac-\nterization tasks.\n\u2022I provide evidence that interactive visualizations such as t-SNE are useful tools\nfor answering questions about the similarity of news sources.\n15\nChapter 2\nBackground\nIn this chapter, I discuss how this thesis defines \u201cnews\u201d and \u201cnews sources\u201d, I describe\nthe task of news source characterization, and I introduce the social platform Reddit\nand the data that I acquire from it.\n2.1 About News and Who Produces It\nAccording to Wikipedia, \u201cNews\u201d is the reporting of current events usually by local,\nregional or mass media in the form of newspapers, television and radio programs, or\nsites on the World Wide Web1. The news ecosystem is formed by complex inter-\nactions of actors in it. For example, news producers produce news stories. These\nnews producers are what I refer to as \u201cnews source\u201c or \u201cnews media\u201d. Some of these\nproducers are independent, for example BBC, CNN, NYT, etc., but some are hosted\non widely-accessible platforms such as Facebook, Blogspot, Apple Podcasts, Word-\nPress, etc. The news stories that they produce are aggregated by yet another type\nof agents, such as Google News (which relies heavily on algorithms), HuffPost (which\nrelies on journalists), and others. Finally news is consumed and shared by news\naudiences, such as Reddit users. This thesis is concerned with characterizing news\nsources, which are the actual actors that produce and publish news with their own\neditorial boards, and will disregard news aggregators and hosts.\n1https://en.wikipedia.org/wiki/Category:News\n16\nIt is also important to mention that currently there is an abundance of user-\ngenerated content, such as blog posts and podcasts, that discuss and share diverse\nmaterials including news. These user-generated contents are commonly hosted by\nsites such as Medium, Facebook, Blogspot, Apple Podcasts, WordPress, etc. In this\nthesis I will disregard both as they are not inherently news sources with an indepen-\ndent board of editors and journalists.\nIn this digital era, online news reporting agents are abundant, and different insti-\ntutions have different definitions of what counts as a news source. Instead of trying to\ncome up with a novel definition of news source, in my thesis I rely upon the definition\nof news sources used by third-party organizations, in particular Global Database of\nEvents, Language and Tone (GDELT) Project2, and Muck Rack3. More specifically,\nI only include sites in my set of news sources if they exist in both the GDELT and\nMuck Rack databases. I introduce both GDELT and Muck Rack in Section 4.1.1 and\nSection 4.1.2 respectively. After acquiring the intersection of the set of news outlets\nrecognized by GDELT and Muck Rack, I then filter out some major news aggregators,\nuser-generated contents, and hosts, for reasons described previously. I further explain\nthe reasoning and process of filtering news sources in the Section 5.1.\n2.2 News Source Characterization\nNews source characterization tasks include characterization by media type (e.g. print,\nonline, podcast, video, etc.), coverage reach (e.g., local, regional, etc.), topic (e.g.,\npolitics, sports, etc.), geographical origin, language, reliability, political leaning, and\nothers. Some of these characterizations are easier to do than others, for example\ncharacterizations by media type and language, as one can infer these characteristics\nexplicitly as they consume news from any news source. Characterization by geograph-\nical origin is also easy for the news sources that self-report their geographical origins,\nwhich most if not all of them do. Characterizations by reliability and political lean-\n2https://www.gdeltproject.org/\n3https://muckrack.com/\n17\ning are harder to do, as one has to have domain-specific knowledge to characterize\nmanually, or a model has to have gold-standard training data and be fairly complex\nto characterize automatically. Non-manual characterizations have mostly been done\nby looking at the style of writing [18] or the content of the news itself using Natural\nLanguage Processing (NLP) [12], or the features of the news sources themselves such\nas their social media accounts, URL structure, and types of Web traffic they attract\n[2].\nIn this thesis, I ponder whether we can infer these characteristics of news sources\nusing audience-based metrics. Yet another question to answer is: based only on their\naudience, how are news sources characterized as \u201csimilar\u201d? Which characteristics are\neasier to infer based on audience behaviors, and which are harder to infer? These are\nthe questions that this thesis attempts to answer.\nTo characterize news sources, in this thesis I attempt to build vector represen-\ntations (embeddings) of my set of news sources using audience-based data that I\nconstruct from Reddit posts. I then investigate whether various characteristics of\nnews sources can be inferred using their vector representations by clustering them,\nand building regression and classifications models to predict their characteristics.\n2.3 Reddit\nWhen considering audience-based metrics, researchers often turn to social media plat-\nforms such as Reddit, Facebook, and Twitter, where news is shared abundantly. This\nthesis specifically considers Reddit and this section serves an overview of what Reddit\nis as a platform and why it is chosen here as a data source to build audience-based\nmetrics to characterize news sources.\n2.3.1 Reddit as a Platform\nAccording to Wikipedia, Reddit is an American social news aggregation, web content\nrating, and discussion website4. It was founded in 2005 and, according to Alexa, is\n4https://en.wikipedia.org/wiki/Reddit\n18\ncurrently one of the most used social platforms, with 40.5% of its users residing in\nthe USA5. Reddit also ranks at the 23rd highest traffic globally, and 6th nationally\nin the US; higher than Twitter (ranking 27th and 18th respectively), another social\nplatform that people commonly use to discuss news among others. As of March 2022\nReddit has more than 50 million users6.\nOne starkly unique feature of Reddit is that it provides the opportunity for users\nto be anonymous. Unlike Facebook that requires users to use their real names and\nidentities as well as create only one account7, Reddit allows users to preserve their\nanonymity by not asking personal identifiers8(except email for signing up9), and\ncreating more than one account (as long as they are not used to mass-vote a post)10.\nReddit is accessible by everyone, even without an account. However, one needs\nan account to interact with posts and other users on the platform, such as to post,\ncomment, vote, share, give awards, or send a private message. A post on Reddit is\nalso called a \u201csubmission\u201d, and I will use these terms interchangeably. Users generally\npost to \u201csubreddits\u201d which are dedicated forums or communities on Reddit that are\ntopic specific, although users can post on their own profile page, if they so wish. They\ncan comment and vote on submissions, as well as reply to comments and vote on the\ncomments themselves. Users can also give \u201cawards\u201d to posts or comments as a sign of\nhigh appreciation, however users need to pay to access and give those awards. Users\ncan also share posts as well as report them if deemed inappropriate.\nSubreddits themselves are created by a Reddit user and moderated by one or more\nReddit users. An example of how a subreddit looks like is shown in Figure 2-1. In\naddition to regular posts by Reddit users, subreddits can also contain advertisements,\nwhichareasourceofrevenueforReddit. Advertisementsarenotalwaysrelatedtothe\ntheme of the subreddits, but users can interact with ads the same way they interact\nwith posts: upvote, downvote, comment, give awards, or share.\n5https://www.alexa.com/siteinfo/reddit.com\n6https://www.redditinc.com/\n7https://www.facebook.com/terms.php\n8https://www.redditinc.com/policies/privacy-policy\n9https://reddithelp.com/hc/en-us/articles/360060420092\n10https://reddithelp.com/hc/en-us/articles/204535759-Is-it-ok-to-create-multiple-accounts-\n19\nFigure 2-1: The page of subreddit r/news (as highlighted in yellow). It contains\nsubmission space, as well as details about the subreddit such as descriptions, number\nof members/subscribers as highlighted in green as well as subreddit-specific rules (not\nshown here). The first post that shows up has 18k total votes (as highlighted in blue),\nwhich are the highest among the most recent posts.\nEach subreddit has their own rules, such as for example discouraging spams and\nencouragingtaggingpostswithadescriptiveword(e.g. [Advice], [Lookingfor], [Avail-\nableLease]tagsinr/nycapartments)inadditiontothegeneralguidelinesofrespecting\nothers. Moderators of these subreddits are users (or bots) that make sure that all\nposts on their subreddits adhere to their subreddit rules. Moderators have the right\nto de-list posts that are deemed inappropriate.\nUsers can join as many subreddits as they want. This thesis will use the term\n\u201cjoin\u201d and \u201csubscribe\u201d interchangeably. The official term used to be \u201csubscribe\u201d, but\nReddit changed it to \u201cjoin\u201d a couple of years ago11. However, the database from\nwhich I gather my data (Pushshift) still uses the term \u201csubscribe\u201d. The Pushshift\ndataset will be introduced in Section 4.2. When a user subscribes to a subreddit, the\nsubmissions on that subreddits will appear on the user\u2019s Reddit timeline.\nTherearefourtypesofsubreddits: public,restricted,private,andpremium-only12.\nFor public subreddits, users can both vote and comment on a submission, regardless\nof whether the user is a subscriber of the subreddit in which the submission is posted\n11https://www.reddit.com/r/modnews/comments/b698ao/\n12https://www.reddithelp.com/hc/en-us/articles/360060416112-What-are-public-restricted-\nprivate-and-premium-only-communities-\n20\nor not. In restricted subreddits, anyone can view and comment but only approved\nusers can post. These users are approved by the moderators. Private subreddits are\nonly accessible to approved users, so no other users can view and participate in these\ncommunities. On the other hand, only Reddit Premium members can create, view,\nand participate in Premium-only communities.\nThere are two voting options on Reddit: upvote and downvote. Upvote will add\n+1 point to a post while downvote adds -1 point. A high number of upvotes will give\nthe associated post more visibility as the post is ranked higher and will appear higher\non the subreddit page (as seen on Figure X above) and the timeline of the subreddit\nsubscribers. In general, posts are ranked by both the total votes they have as well\nas when they are posted. When a user makes a post, Reddit automatically sets the\ntotal vote of the post be +1, with the user themself being the first voter.\nIn addition to voting on posts, users can also vote on the comments associated\nwith those posts. The technical details are the same, in that upvote will add +1\npoint to a comment, while downvote adds -1 point. Comments can be sorted based\non various metrics, including based on the total votes they have. Although comments\nareaninterestingpartofReddittostudy, thisthesiswillfocusmoreheavilyonReddit\nsubmissions that contain the links of our set of news sources. This thesis takes into\naccount the number of comments associated with each submission.\nAlthough users are free to post submissions, Reddit also has a system in place to\nregulate users\u201d activity, called \u201ckarma\u201d, which is a kind of score a user receives based\non the total votes that their posts and comments received. For example, if a user\nposts in a subreddit and receives 5 upvotes and 1 downvotes, they would gain 4 karma\npoints. Higher karma points allows users to post more frequently. This also means\nthat new users have limited posting ability, at least until they gain karma points. An\nexample of user profile is shown in Figure 2-2.\nIn addition to the regular free Reddit account type, Reddit also offers paid pre-\nmium account type for users. For $49.99 per year, users can upgrade their accounts to\npremium, allowing them to access Reddit without ads, as well as to use extra features\nsuch as filtering posts by subreddits or topics or pinning posts on their homepage.\n21\nFigure 2-2: An example of a Reddit user\u2019s profile. u/Stuck_In_The_Matrix is the\nReddit username of Jason Baumgartner, who is the creator of the Pushshift dataset.\nThe amount of Karma he has is highlighted in yellow.\nIn general, the members of a subreddit are very dedicated to the cause or theme of\ntheir particular subreddit. Such dedicated participation has been publicly shown, for\nexample, by the event of the short squeeze of various stocks, most notably Gamestop\n(GME), initiated by small-scale investors notably organized in r/WallStreetBets,\nwhich ended up affecting the financial system significantly [7]. This shows how in-\nteractions and discussions in subreddit not only reflect the real-world, but also affect\nit. For example, Zannettou et al. revealed that some alt-right communities in Red-\ndit could have significant influence in spreading alternative news to the other social\nplatforms such as Twitter and the Web in general, thus affecting the larger public\ncommunities [45]. This confirms the important link between Reddit and our society\nand thus supports the utilization of Reddit as a tool to gain insights about various\naspects of our society.\n22\n2.3.2 Reddit as a Data Source\nReddit data is valuable because it is the most permissive social platform to access.\nMeanwhile, other social media platforms like Facebook and Twitter, unlike Reddit,\nhave gotten less permissive over the years as companies juggle their priority of users\u201d\ndata safety and commitment to openness and transparency. Since Reddit users are\nlargely anonymous, Reddit does not have as many privacy concerns which leads to a\nmore accessible source of data.\nAnonymityitselfisanimportantfeaturetoconsiderasIaimtoanswermyresearch\nquestion of characterizing news sources based on their online audience. According to\nLuarn and Hsieh, users are more willing to express opinions in anonymous conditions\nthan in non-anonymous conditions [27]. This means that the opinions that people\nexpress on Reddit are more likely to be more representative of how people really feel.\nAs such, the news source consumptions and sharing patterns are reflective of what\npeople\u2019s preferences are in the physical world.\nAdditionally, Reddit also provides arguably familiar forums where people discuss\ncommon interests, in the community-driven subreddits. According to Luarn and\nHsieh, this also encourages \u201ccommunicative discussions\u201d and \u201cthe expression of un-\nconventionalviews\u201d whichfurtherconfirmthatpeople\u2019struepreferencestowardsnews\nsources are reasonably correctly mirrored on Reddit.\nThe abundant data and users, great accessibility, and built-in anonymity features\nof Reddit makes it a really attractive platform to study various issues in our society.\nFor example, Kumar et al. utilizes Reddit data to quantitatively examine society\u2019s\nearly perceptions of the COVID-19 vaccines by using topic modeling algorithms to\nunderstand how dominating words related to COVID-19 and vaccinations changed\novertime [23]. Choudhury and De specifically use Reddit data to examine the role\nof anonymity in discussions about stigmatic mental illnesses and the general role of\nsocial web in behavioral therapy [10].\nMoving from the medical field, researchers also utilize Reddit data to study social\nissues and phenomenons. Using Reddit data, Fire and Guestrin examine how trends\n23\nand network stars emerge and fade overtime by creating large temporal networks and\ninvestigating how high-degree vertices emerge and dissipate, which could for example\ngive insights to how people gain and lose political power, and how disease spreads\nthroughout populations [16]. Veselovsky et al, on the other hand, utilized Reddit\ndata to develop neural embedding methods to understand the social context of music\nsharing such as how there are a lot of extra-musical factors in music sharing [43].\nYet another use case of Reddit data is demonstrated by Setty and Rekve, where they\nutilized Reddit data for analysis and detection of fake news, using both the textual\ncontent of and social media comment to detect false claims [38].\nThere are many other published research projects that rely on Reddit to gain\ninsights about various aspects of our society, justifying the use of Reddit data in\nthese types of social computing study. Furthermore, as news plays an increasingly\nimportant part in our society, I see it fitting to utilize Reddit data as a source of\nsocial behavior in news consumption, to study news sources.\n24\nChapter 3\nRelated Works\nNews sources do not generally come with identifying labels such as political lean-\nings/biases, credibility, audience targets, and types/genres of news stories in focus,\nthus it is impossible to fully understand their characteristics if we only rely on their\nself-reported characteristics. Instead, the efforts of news sources characterizations can\nbe divided into three main categories, based on content, audience, and propagation.\nIn my thesis, I will focus mostly on the intersection of the second and third approach\nfor news sources characterizations. This is because in this thesis I look at how news\nsources audiences share or propagate news links in various subreddits.\nOnline communities in general, albeit being mostly anonymous, prove to be a\nuseful indicator/feature to consider, in the effort of understanding the online news\necosystem. As shown by Wang et al, \u201cdifferent communities discuss different types of\nnews\u201d and that some fringe communities could have \u201cdisproportionate influence with\nrespect to pushing narratives around certain news\u201d [44]. In this thesis, in addition\nto gaining insights about news sources based on the subreddits they are shared in, I\nalso explore the diverse subreddits themselves.\nPast research projects have utilized the sharing patterns of news stories\u201d links on\nsocial media platform to infer various characteristics of new sources, such as their\npolitical leanings (by Robertson et al.[34] and Bakshy et al.[1]), reliability (by Penny-\ncooketal.[32]), andtheirsocialgenre(audience-basedclusters)(bySamoryetal.[37]).\nI will go through the overview of each research project in order to summarize and\n25\ncompare the findings and methodologies used so far in this effort of gaining insights\nabout the online news ecosystem.\nIn their study, Robertson et al. investigated the partisan bias (political leanings)\nof various components of Google\u2019s Search Engine Result Pages (SERPs) since people\nextensively use Google search engine to find and fact-check information [14, 13] and\nthat partisan bias could affect undecided voters\u201d decision in the 2016 election [14].\nHowever, it is hard to create an objective partisan bias score that can be used for\ntheir purposes of auditing the search engine (Google) with respect to the existence of\na \u201cfilter bubble\u201d phenomenon. Establishing an objective partisan bias score is hard\nbecause, if done manually, this task is expensive in terms of time and labor and risks\nsubjectivity. In the paper, they tackle this issue by deriving audience-based partisan\nbias scores for web domains, specifically by leveraging the social network principle\nof homophily observable in Twitter, Facebook [1], and thus arguably other social\nplatforms such as Reddit. To derive the partisan bias scores, Robertson et al. uses\nthe voter registration data to label people\u2019s political leaning, find them on Twitter,\nand use their tweets to investigate the URLs they have shared. The actual Partisan\nAudience Bias (PAB) of a news source domain is calculated by the scaled difference of\nthe proportion of democratic accounts and republican accounts sharing the links from\nthat domain, resulting in partisan bias score in the range of -1 (shared exclusively by\ndemocrats) and +1 (shared exclusively by republicans), where PAB score of 0 means\nthat the links to that particular news source were shared by the same proportions of\ndemocratic accounts and republican accounts.\nRobertson et al.\u2019s PAB scores have a r>0.9 correlation with Bakshy et al., and\nsimilarly positive correlations with other partisan-bias-scoring projects such as All-\nSides (r>0.6) and Pew Research (r>0.7) [34]. This shows that audience-based (thus\ncommunity-based) characterization of news sources are comparable to content-based\nand rater-based characterizations [34], justifying the use of Reddit\u2019s communities\n(i.e. subreddits) to empirically characterize news sources. Furthermore, the use of\nthe largely anonymous and community-driven platform, Reddit, alleviates the issue\nof competing power between audience\u2019s choice in consuming/sharing news stories and\n26\nthe platform\u2019s algorithm effects.\nIn addition to political leaning (partisan bias), the audience role has also been\nutilized to infer news sources\u201d reliability, as shown by Pennycook et al. [32]. In their\npaper, Pennycook et al. use survey-based methodologies to show that the average\nperson\u2019s judgment of the reliability of news sources correlates strongly with expert-\nbasedreliability-checkforthedomain-leveljudgment(asopposedtostory-level). This\nis shown to be true (almost) regardless of the political leanings of the audience.\nAlthough the research methodologies do not rely on audience sharing patterns, this\nresearch still showcases the importance and strength of the crowd, suggesting that\nit is beneficial to infer insights from the news stories audience in general, arguably\nincluding their sharing patterns.\nCharacterizing news sources based on political leanings (partisan bias score) and\nreliability provides useful insights to the online news sources ecosystem, but we need\nmore analysis to investigate which characteristics of the news outlets drive actual\naudience engagement [37]. Therefore, a more nuanced news source characterization\nis needed [1]. In this thesis, I utilize k-means clustering methods as an attempt\nof a more nuanced news source characterization, where I investigate whether any\nclusters of news sources naturally come up given online audience-based metrics as\ntheir features.\nOnemethodofanalysisusedinthisthesisisclustering, specificallyk-means, which\naims to cluster entities by minimizing within-cluster sum of squared distances of the\npoints in each cluster. Barros et al. has employed the same method on Reddit-based\ndataset to classify health content on Reddit in an unsupervised manner [4]. However,\nthey utilize word embedding of posts instead of audience-metrics such as sharing\nfrequency, upvote ratio, and number of comments for embedding as in this thesis. In\nthis thesis, I investigate whether the same clustering algorithm but with embedding\nbased on audience-metrics can yield insights regarding news source characterizations.\nOther subreddit-based features have been used for clustering tasks as well. For\nexample, Chandrasekharan et al. clusters subreddits based on their features of how\nlikely those subreddits moderate comments posted in them, as well as based on their\n27\nspecific norms [6]. Morrison and Hayes, on the other hand, use specific audience-\nbased metrics as features to characterize the audience themselves based on \u201ctheir\npopularity and role in initiating and sustaining communication in their communities\u201d\n[28]. These features include the number of posts and comments the users engage in,\nthe number of comments that received at least one reply, the number of subreddits\nthe users engage in, and others. Similarly to Morrison and Hayes, this thesis utilizes\nfeatures based on Reddit users\u201d engagement on the platform. However, this thesis\naggregates such features based on subreddits instead of treating them individually\nas Morrison and Hayes do. Differently to Morrison and Hayes, this thesis utilizes\nthese features to cluster and gain insights about news sources instead of about the\naudiences themselves.\n28\nChapter 4\nIntroducing the Datasets\nIn this section I will introduce the sources of data being used in this thesis. I use\nGDELT and Muck Rack to build my set of news sources and the Reddit Pushshift\ncollection to extract features that demonstrate how these news sources are shared by\ntheir audience.\n4.1 GDELT and Muck Rack to define \u201cNews Source\u201d\nAs mentioned in Section 2.1, this thesis relies on the GDELT Project and the Muck\nRack company to build a set of sites recognized as \u201cnews sources\u201d. Here, I will intro-\nduce both GDELT and Muck Rack as an organization and a company, respectively.\nI explain how I acquire data from each of them in Section 6.1.\n4.1.1 GDELT\nThe GDELT Project aims to report all events happening all around the world by in-\ndexing and using NLP to process news. GDELT is a far-reaching multi-year project\nthat has been used by multitudes of other researchers, and is freely accessible to ev-\neryone. GDELT was authored by Kaleev Leetaru and Philip Schrodt. Leetaru is a\nMedia Fellow at the RealClearFoundation and a Senior Fellow at the George Wash-\nington University Center for Cyber and Homeland Security, where he also serves on\n29\nits Counterterrorism and Intelligence Task Force1. Leetaru still maintains the project\nand writes articles about its use cases as hosted on realclearpolitics.com2. Some of\nthe most recent articles that Leetaru wrote using data from GDELT include an article\nabout how the amount of coverage of Russia\u2019s invasion of Ukraine has been declining,\nless than two months since the start of the invasion3. Schrodt is a political scientist\nwhoiscurrentlyaseniorresearchscientistattheconsultingfirmParusAnalyticalSys-\ntems, after he left Pennsylvania State University where he was a professor. Schrodt\ncreated the Textual Analysis by Augmented Replacement Instructions (TABARI)\nsoftware and co-developed Conflict and Meditation Event Observation (CAMEO)\ndata coding framework, both of which were utilized in the making of GDELT [25].\nToday, GDELT contains over 250M event records covering the entire world from\n1979 until present, with new records being added every 15 minutes. As a project,\nGDELT aims to construct a single massive network that captures what is happening\naround the world, the context of the events, who is involved, and how the world\nis feeling about it, every single day4. GDELT is currently the largest open-access\ndatabase on human society events5.\nGDELT records events happening all around the world in various structures in-\ncluding the \u201cGlobal Knowledge Graph (GKG)\u201d database, where the project compiles\nactors and places from every news report. For each of the news report recorded by\nGDELT, the GKG database also records its details such as the link of the news report;\nthe domain name of the news source publishing the report; the numerical summaries\nincluded in the news report if available; themes; locations, organizations, and persons\nmentioned in the article; the tone of the article; image link; and video link.\nOverall, GDELT has built its events record using more than 240,000 news sources\noriginating from all around the world, including more than 13,500 English language\nsources. However, not all of these news sources are still active today, considering\n1https://www.kalevleetaru.com/vita.pdf\n2http://realclearpolitics.com\n3https://www.realclearpolitics.com/video/2022/04/11/ukraine_is_already_fading_on_television_news.html\n4https://www.gdeltproject.org/about.html#creation\n5https://cloudplatform.googleblog.com/2014/05/worlds-largest-event-dataset-now-publicly-\navailable-in-google-bigquery.html\n30\nthat news sources undergo changes or even shut down over time, and that new news\nsources emerge.\nAs a source of data, GDELT has been used in many research projects, with most\nof them focusing on political-related events. For example, Qiao et al. utilize GDELT\nto predict social unrest events with hidden markov models [33]. On the other hand,\nConiglio et al. utilized GDELT as part of their dataset to investigate \u201cthe effect of\nhosting refugees in camps on the occurrence of protests and social conflicts\u201d where\nGDELT data is used to determine the frequency of protests and social conflicts [8].\nAnother use case is by Nejjari et al. where the authors employ graph theory to verify\nthe assumptions that cyber threats are correlated to geopolitical events, by comparing\ngraph isomorphism and structures of the cyber events graph and geopolitical events\ngraph built using GDELT data [29].\nIt is worth mentioning that GDELT has also been critiqued in the past, especially\nregarding the concern of event duplications such as the kidnapping in Nigeria, as\nnoted by Jenkins and Maher [20], and other researchers. However, this thesis is not\nconcerned about the actual events and other labels reported by GDELT. Instead,\nthis thesis looks into GDELT to only aggregate the set of news sources recognized\nby GDELT in their event reporting process. Therefore, even with a critiqued event\nlabeling algorithm, GDELT is still a valid and important data source in this thesis\u2019s\nuse case.\n4.1.2 Muck Rack\nAs a company, Muck Rack claims to provide access to the \u201cmost accurate media\ndatabase\u201d where people can \u201cmonitor news as it breaks\u201d. Muck Rack\u2019s main consumer\ntargets are other companies\u2019 Public Relations Managements (PRMs), as they can use\nMuck Rack to build relationships with various media outlets and analyze how their\ncompanies are represented by the media; and journalists, as they can showcase their\nportfolio and measure the impact of their published articles[1]. Unlike GDELT, Muck\nRack is a paid service. However, it does have some resources open for the public to\nbrowse on their website, such as their media database, which is what this thesis uses.\n31\nAs a data source, Muck Rack data is mainly used in journalism-related research.\nGDELT and Muck Rack are two huge databases of news sources built for different\npurposes, but they both strive and claim to be complete media databases able to\nprovide a thorough news coverage. Intersecting these two databases gives us an\ninsight into the agreement between the private and public organizations regarding\nwhat counts as a \u201cnews source\u201d.\n4.2 Reddit Pushshift Dataset\nPushshift is a project that collects and archives longitudinal social media data, in-\ncluding Reddit in addition to other platforms such as Tik Tok and Twitter. It is open\nto the public and is continuously updated. The Pushshift dataset has been used in\nvarious research projects of all scales, either through the raw data dumps, Google\nBig Query access, or its API. These projects include a study looking at discussions\non skincare addition on Reddit [31], another study looking at posts discussing syn-\nthetic opioids in a retrospective observational study [5], a study focusing on language\nmodeling and other NLP-related tasks [35, 22], COVID-19 related studies (including\nmisinformation regarding the pandemic) [9, 30, 26], among others.\nEven though Pushshift does provide easy access to its data through the Pushshift\nAPI6, I chose to access their monthly data dumps directly7due to limited documen-\ntation, rate limitations, a few inaccuracies, and service outages every once in a while\nfor the API. Even so, the Pushshift API does provide better service than the official\nReddit API in various aspects, such as a five times higher rate limit and direct com-\nparison to the texts of Reddit submissions and comments; so its API is still a viable\nalternative of getting datasets regarding Reddit activity.\nEachmonthlydatadumpisstoredinNewlineDelimitedJSONformat(NDJSON),\nwith a decompressed size of about 130GB each file. To store and access such a big\ndataset, I keep the files compressed (9GB each) and utilize the zstandard Python\n6https://github.com/pushshift/api\n7https://files.pushshift.io/reddit/submissions/\n32\nFigure4-1: Asnapshotofsomeofthekey-valuepairsinoneofthePythondictionaries\nrepresenting a Reddit submission.\npackage, which allows me to stream the compressed data. At the time of writing this\nthesis, Pushshift data dates back to 2005 and the most recent dataset uploaded to\nPushshift is for June 2021, which was uploaded in August 2021.\nEach Reddit post in a monthly dump file is represented by a Python dictionary\ndata structure with 82 keys, recording various features of a post, including most im-\nportantly the URLs contained in the submission, the text of the submission, subreddit\nname where it is submitted, subreddit subscribers, number of comments associated\nwith the post, ratio of upvotes and downvotes, UTC timestamp of submission, and\nthe UTC timestamp of when Pushshift adds the post to its database, among others.\nFigure 4-1 shows a snapshot of some of the key-value pairs in one of the Python\ndictionaries representing a Reddit submission.\nOn another note, there are two things that are worth mentioning: the fact that\nPushshift treats some Reddit \u201cusers\u201d as \u201csubreddits\u201d, and that a lot of the links in the\n33\nsubmission files are reddit.com .\nThe first fact suggests that I should filter out these non-subreddits from my data\nof subreddits. Recall that subreddits are communities within Reddit that are cre-\nated by an user and moderated by one or more users, while users are the actual\nreddit accounts that people sign up for. Specifically, subreddits are noted with an\n\u201cr\u201d notation on Reddit, while users are often noted with a \u201cu\u201d notation on Red-\ndit. For example, the specific community on Reddit that discusses Pushshift is the\npushshift.io subreddit, represented by the notation /r/pushshift/ , which is ac-\ncessible on reddit using the URL https://www.reddit.com/r/pushshift/ . On the\notherhand, theuserthatcreatesPushshift(whoisalsoamoderatorin /r/pushshift )\nis/u/Stuck_in_the_Matrix . However, due to the fact that users are allowed to post\non their own home page as opposed to posting in a particular subreddit, Pushshift\ntreats some users as subreddits, i.e. by associating a number of Reddit submissions as\nbeing posted in subreddits that are actually users\u2019 usernames. Since the main usage\nof Reddit is the utilization of its theme-specific subreddits for people to discuss and\nask questions, very few users actually post in their own homepage because of the lack\nof traffic there by other users. Individual user\u2019s homepage is also not theme-specific\nand is only based on the preference of the user, therefore they do not add much infor-\nmation about the audience of these news sources. Thus, this thesis will ignore posts\nmade on users\u2019 homepages.\nSecondly, there are a lot of reddit.com URLs in the submission JSONs, which\nis due to the many inter-site sharing within Reddit, and because the \u201cURL\u201d field\nin the JSON files point to post itself if there are no outside URLs being shared. As\nexplainedintheAboutNewsandWhoProducesItsection, justlikeothernewssource\naggregators and user generated content hosts, reddit.com will not be included in the\nanalysis as a news source.\n34\nChapter 5\nData Exploration\nMy first approach to tackle the task of characterizing news sources is by exploring\nwhat news sources are included in my set of news sources given my method of building\nthis set of news sources, and exploring how they are shared on various different\nsubreddits. I expect that various characteristics of news sources can be inferred from\nthe patterns of how they are being shared. For example, I expect that we can infer\nthe popularity of news sources based on the total number of their news links that are\nshared on Reddit, and in how many subreddits they are shared. I also expect that we\ncan infer the audience broadness and appeal of some news sources by comparing their\ngeneral popularity (i.e. the total number of news links shared from that domain) and\ntheir popularity across different subreddits.\n5.1 Exploring News Sources\nIntersecting news sources from GDELT and Muck Rack yields 42,477 news sources.\nOut of those news sources, there are 23,575 news sources that were shared on Reddit\nat least once in the span of January - June 2021. Out of these, only 8,781 news\nsources were consistently shared at least once per month in the same time span. In\nthe \u201cMethods and Results\u201d section, I will go into details about the ways I filter these\nsites to only include news sources that are not sites of news aggregators and hosts of\nuser-generated content. In the same section, I also explain how I further subset the\n35\nset of news sources to filter out news sources that are shared on Reddit extremely\ninfrequently thus lack representation. In this section, I will go over the statistics of\nnews sharing on Reddit as a whole.\nAs shown in Table 5.1, there are more than 30 million monthly submissions on\nReddit, and about 60% of those submissions contain at least one URL. Among the\nsubmissions that contain at least one URL each, 25% contain links to news sources\nand user generated content such as blogs and podcasts. Our set of news sources makes\nup about 7% of the links being shared on Reddit posts.\nMonth Total submissionsSubmissions with link(s)\nexcluding \u2018reddit.com\u2018Submissions with news source\n& user generated content linksSubmissions with news\nsources as defined here\nJan 32,704,571 19,550,221 4,402,183 1,358,227\nFeb 31,147,947 18,296,269 4,186,966 1,248,924\nMar 33,006,103 19,494,992 4,639,876 1,387,165\nApr 31,616,206 18,505,024 4,639,876 1,387,165\nMay 36,310,673 21,850,116 4,670,423 1,314,159\nJun 34,118,481 20,050,925 4,488,769 1,022,494\nTable 5.1: Among the submissions that contain at least one URL each, 25% contain\nlinks to news sources and user generated content such as blogs and podcasts. Our set\nof news sources makes up about 7% of the links being shared on Reddit posts.\nEach of the sites in the set of news sources are not all equally popular, as some are\nshared more than the others, regardless of the number of subreddits they are shared\nin. \u2018imgur.com\u2018forexample, wassharedmorethan9milliontimes, and\u2018youtube.com\u2018\nmore than 4 million times. Many other news aggregators and user-generated content\nhosts are similarly shared with high frequency. It is interesting to note that these sites\nare extremely popular on Reddit, however, as discussed previously, I will disregard\nthese sites.\nThe list of sites that are shared the most on Reddit is summarized in Table 5.2.\nAs part of the data cleaning process, as will be explained later, I manually went\nthrough this ranked list of news sources and filtered out heavily-shared sites that are\nnot news sources, but are news aggregators or user generated content hosts instead,\nwhich have no editorial oversight. Although these platforms are interesting to learn\nabout, this thesis focuses on actual news sources. I filtered out 133 such sites. The\ncomplete list of these 133 sites is in Table B.1 in Appendix B.\nExcluding news aggregators and user-generated content hosts, we are left with the\n36\nSites# times they are\nshared (regardless\nof the subreddits)Proportion based on\ntotal # times all sources\nare shared (%)\nimgur.com 9957691 35.3%\nyoutube.com 4219365 14.9%\ntwitter.com 1888497 6.7%\nt.me 763911 2.7%\ngoogle.com 678895 2.4%\nmlb.com 318979 1.1%\nblogspot.com 317397 1.1%\nspotify.com 317203 1.1%\ntheguardian.com 226634 0.8%\nsteamcommunity.com 185928 0.6%\ninstagram.com 168276 0.6%\nwikipedia.org 164672 0.6%\ncnn.com 161038 0.6%\namazon.com 149672 0.5%\nfacebook.com 146110 0.5%\ngithub.com 145580 0.5%\nnytimes.com 144988 0.5%\nfoxnews.com 141893 0.5%\nmedium.com 130885 0.5%\nsoundcloud.com 126885 0.4%\nTable 5.2: Top 20 sites (not necessarily news sources) that are shared the most on\nReddit.\nactual news sources. Amongst them, \u2018mlb.com\u2018, which is the official site associated\nwith Major League Baseball, is the most shared news source as it was shared 318,948\ntimes in total in the timeframe of interest, encompassing 4.5% of the total news\nsharing frequency of over 7M. The list of the top 20 news sources that are shared the\nmost is summarized in Table 5.3.\nIn terms of statistics, the mean sharing frequency of news sources is 300 with\nmedian 10, representing an extremely right-skewed distribution.\nOne natural question to ask is if news sources that are in total shared the most,\nare the same news sources that are shared in the most subreddits (i.e. popular across\n37\nNews sources# times they are\nshared (regardless of\nthe subreddits)Proportion based on\ntotal # times all sources\nare shared (%)\nmlb.com 318948 4.5%\ntheguardian.com 225921 3.2%\ncnn.com 160451 2.3%\nnytimes.com 144252 2.0%\nfoxnews.com 141796 2.0%\nthehindu.com 88410 1.2%\nbbc.co.uk 87890 1.2%\nthestar.com 87662 1.2%\nreuters.com 85021 1.2%\nnypost.com 81594 1.1%\ncnbc.com 65440 0.9%\nthehill.com 63500 0.9%\nindiatimes.com 63034 0.8%\nwashingtontimes.com 59941 0.8%\nbreitbart.com 57660 0.8%\nusatoday.com 54144 0.7%\nscmp.com 52531 0.7%\ncbc.ca 52372 0.7%\napnews.com 48543 0.7%\nnbcnews.com 48378 0.7%\nTable 5.3: Top 20 news sources that are shared the most on Reddit.\ndifferent subreddits). Now that we have looked at the total sharing frequency of each\nof the news sources, let\u2019s look at the number of subreddits in which these news sources\nare shared.\nNewsaggregatorsitesanduser-generatedcontenthostsarepopularacrossdifferent\nsubreddits, as expected, since these sites are rarely theme-specific. In the analysis\nbelow, I will discard them and only consider news sources.\nAs shown in left hand side graph of Figure 5-1, a lot of news sources are each\nshared in 100 or less different subreddits, but there are some that are shared in up\nto 1000 different subreddits. In fact, about 4.5K (almost 20%) out of the total 23K\nnews sources are only shared in one subreddit each. From the graph in the right\n38\nFigure 5-1: Figure 5a shows that a lot of news sources are each shared in 100 or\nless different subreddits, but there are some that are shared in upto 1000 different\nsubreddits. Figure 5b shows the same information, that most (98.8%) news sources\nappear in 400 subreddits or less.\nhand side graph of Figure 5-1, we can also see that almost all news sources are only\nshared in a maximum of about 400 subreddits. In fact, the mean of the number of\nsubreddits a news source is shared in is 31, while the median is 5, representing the\nextremely right-skewed distribution. The fact that about 50% of the set of over 23K\nnews sources were only mentioned in less than 5 subreddits suggests that it might be\nbeneficial to also set a lower bound threshold of minimum number of subreddits as I\ntry to cluster these news sources later using the subreddits as the features.\nNext, let\u2019s look into what news sources are most popular across different subred-\ndits, ranked by how many subreddits contain posts that share these news sources\u2019\nlinks. The top 20 news sources are shown in Table 5.4.\nThe following news sources are in the list of top 20 news sources with the highest\nnumber of links shared, but not in the list of top 20 news sources with the most\nsubreddits they are shared in: mlb.com, foxnews.com, thehindu.com, thestar.com,\nthehill.com, breitbart.com, and cbc.ca. In fact, thestar.com, thehindu.com, breit-\nbart.com and mlb.com only place in 108, 209, 215, and 522 rank respectively in terms\nof the number of unique subreddits they are shared in. This suggests that these 4\nnews sources are very heavily shared in a small subset of subreddits.\n39\nNews sources# subreddits they\nare shared in\ntheguardian.com 5617\nnytimes.com 5438\ncnn.com 5005\nbbc.com 4241\nreuters.com 3906\nwashingtonpost.com 3692\nforbes.com 3488\ncnbc.com 3357\nbloomberg.com 3269\napnews.com 3084\nbusinessinsider.com 3026\nbbc.co.uk 2971\nnpr.org 2906\nnbcnews.com 2815\nindependent.co.uk 2728\nmsn.com 2699\ndailymail.co.uk 2693\nvice.com 2581\nnypost.com 2441\nwsj.com 2409\nTable 5.4: Top 20 news sources ranked by the number of subreddits they are shared\nin.\nComparing these two measures in this way can give us insights into what news\nsources are heavily shared by particular subreddits as well as what those subreddits\nare. This insight might be easily explained, for example in the case of mlb.com, it is\nverynichebecauseitcoversaveryspecifictopicthatisbaseball, soitisonlyappealing\nto, and thus shared by, a small subset of the Reddit community. However, this insight\nis more interesting for breitbart.com, for example. The news website breitbart.com is\na far-right news outlet that notoriously spreads misinformation, most recently about\nCovid-19, and in general fails to report news factually. The heavy sharing frequency\nof this news outlet in a small set of subreddit might play a factor in creating and\nsustaining an echo chamber of misinformation spread. This could be one way of\ncharacterizing news sources, in particular to find out which news sources are most\nheavily used to spread certain ideology.\n40\nVisually, Figure 5-2 shows the distribution of news sources based on their total\nmention count as well as the number of subreddits in which they are mentioned.\nThe figure itself is divided into four sections labeled as quadrant 1, 2, 3, and 4, by\ndrawing the green horizontal line Mention count = 1000, and the orange horizontal\nline Subreddit count = 1000. Note that these are high thresholds considering that,\nas mentioned before, overall news source mention count has median of 10 and mean\n272, while the number of subreddits in which the sources are shared has median of 5\nand mean 31.\nThe first quadrant contains news sources that have the highest mention count of\nmore than 1000 mentions, and are shared in proportionally many different subreddits\n(>1000 subreddits). These news sources are popular as they are shared many times,\nand also have a broad appeal as they are shared in a lot of different subreddits. In\ntotal there are 68 such news sources (0.29% of the total set of news sources). Some\nexamples are buzzfeed.com, thehill.com, nytimes.com, dw.com, cbc.ca, and others.\nThesecondquadrantcontainsnewssourcesthathavethehighestmentioncountof\nmore than 1000 mentions, but are mentioned in comparably fewer subreddits. These\nare news sources that are popular but are more niche. In other words, they are heav-\nily shared by only particular communities. In total, there are 734 such news sources\n(3.13% of the total set of news sources). Some examples are mlb.com (shared 318,947\ntimes in only 237 subreddits), breitbart.com (shared 57,659 times in 496 subreddits),\nnhl.com (shared 38,763 times in 148 subreddits), oann.com (shared 27,106 times in\n144 subreddits), hotnews.ro (shared 13,195 times in only 22 subreddits), and others.\nTheme or non-English language specific news sources such as mlb.com, nhl.com, and\nhotnews.ro are intuitively niche because only particular sets of communities under-\nstand and are invested in those types of news sources. However, knowing that some\nfar-right leaning news sources such as breitbart.com and oann.com (also known as\nOne America News Network) gives us an insight into how the perspectives of these\nnews sources are shared online. This helps us characterize these types of news sources\nas niche news sources.\nThe third quadrant contains news sources whose sharing frequency and count\n41\nof subreddits are not of special interest. These news sources are neither notably\npopular nor have niche audiences. There are 22,615 news sources in this quadrant\n(encompassing96.6%ofthetotalnewssources). Notethatthereareonlynewssources\nin the top left part of quadrant 3. This makes sense since the number of subreddits\nin which a news source is mentioned cannot be higher than the total mention of that\nnews source (e.g. if a news source is only mentioned in 10 subreddits, then it must\nhave 10 or less total mention counts). The fourth quadrant is empty for the same\nreason.\nIn conclusion, by looking at the measures of mention count and subreddit count\nfor the news sources, we are able to gain insights about which news sources are more\nbroadly popular and which are more niche. This type of characterization is very\nvaluable for understanding how news sources are consumed by online audiences, yet\nthe characterization process was able to be done simply by comparing the two metrics\nabove.\n5.2 Exploring Subreddits\nNow that we have a good understanding of how news sources are shared in various\nsubreddits, let\u2019s look into the subreddits themselves.\nIncluding both news aggregators and user-generated content hosts in addition to\nnews sources, there are 131,633 different subreddits in which people share at least\none link within the time frame of January to June 2021. As a side note, this number\n(131,633) makes sense because according to Reddit[1], it only has 100k+ active com-\nmunities out of the millions of subreddits that Reddit has in total. Out of these, only\n45,777 subreddits were consistently used at least once per month in our time frame\nof interest.\nExcluding posts that only share links to news aggregators and user-generated\ncontent hosts, there are 43,800 subreddits in total, in which people share at least one\nnews source link. Only a quarter of these were consistently used to share news links\nat least once per month within January - June 2021 time frame.\n42\nTo understand the popularity and rate of usage of the subreddits in my dataset,\nI look into the number of their subscribers (equivalent to members) as well as the\nactivity with those subreddits in terms of the number of posts. For the analysis below,\nI exclude news source aggregator sites as well as hosts of user-generated content.\n5.2.1 Subreddits Subscribers\nFirst, we look into the number of subscribers of each of these subreddits. Out of the\n43,800 subreddits, there are 20,637 subreddits that have subscribers\u2019 information.\nThe distribution of the number of subscribers is extremely right-skewed, so I use\nlog (base 10) to visualize the logged-subscribers distribution, as follows.\nAs we see from Figure 5-3, about half of the subreddits have about 0-1,000 sub-\nscribers. The other half have about 10,000 to 10,000,000 subscribers.\nTable 5.5 presents top twenty subreddits based on the number of their subscribers.\n1. funny 6. worldnews 11. news 16. food\n2. gaming 7. Music 12. Showerthoughts 17. Jokes\n3. aww 8. videos 13. IAmA 18. explainlikeimfive\n4. pics 9. movies 14. EarthPorn 19. books\n5. science 10. todayIlearned 15. askscience 20. LifeProTips\nTable 5.5: Top 20 subreddits ranked based on the number of their subscribers.\nNote that these subscribers are not unique, as one person can subscribe to several\nsubreddits (but one can only subscribe to each subreddit once). In future work, more\ndata should be analyzed to rerun this analysis while taking into account the difference\nbetween users.\nFrom the table above we see that most subreddits that have a lot of subscribers\nare very general and are not specifically associated with any real-life community. The\nsubreddit r/pics which is a subreddit for pictures, for example, do not specifically\nappeal to any particular real-life communities and thus do not contain any more\naudience-specific information than the subreddits with less subscribers. Thus, when\nconsidering the subreddits to use as features of news sources in the process of charac-\nterizing them, filtering by the number of their subscribers might not be such a good\n43\nidea. This is a useful insight for when I consider ways to reduce the dimensions of\nnews sources\u2019 vector representations using the subreddits in which they are shared in,\nas the features.\n5.2.2 Subreddits Activity\nThe second measure of the popularity and traffic of subreddits, is the activity within\nthem. Here, I define \u2018activity\u2019 as the number of posts made within those subreddits.\nBased on the number of submissions made to all subreddits during January to\nJune 2021, Table 5.6 presents the top 20 subreddits with the most activities.\n1. AutoNewspaper 6. COVID_CANADA 11. NoFilterNews 16. CertifiedNews\n2. politics 7. worldnews 12. FakeCollegeFootball 17. WrestlingBreakingNews\n3. TheNewsFeed 8. Conservative 13. nofeenews 18. FOXauto\n4. news 9. THEHINDUauto 14. TORONTOSTARauto 19. NewsfeedForWork\n5. TrendingQuickTVNews 10. niuz 15. trendandstyle 20. Coronavirus\nTable 5.6: Top 20 subreddits with the most submissions posted in them.\nThis list of top 20 subreddits based on the number of submissions in them, is\nrather consistent in the time frame of January to June 2021. Since we are focusing\non news source links, most of the submissions are made in news-related subreddits,\nwhich is expected. Note that there are a couple of subreddits that are aimed to\nhost posts posted by bots. r/AutoNewsPaper for example, claims to \u201cprovide diverse\nuncensored news via individual subreddits and a combined subreddit of the most\ncirculatedEnglishlanguagenewssourcesintheworld,\u201d withpostsmadebyautomated\nuser (bot) which acquires the news articles from news source RSS directly. In the\nfinal analysis, these subreddits are discarded.\nIn addition to submission counts, I also investigate the set of subreddits with the\nhighest number of different news sources mentioned in them. Table 5.7 records the\nlist of top 20 subreddits with the most news source entities mentioned in them.\nAs seen in Table 5.7, the subreddits with the highest number of mentioned news\nsources are generally news-themed, which makes sense. It is interesting to note that\nthere is very little overlap between the top 20 subreddits based on how many unique\nnews source entities are shared in them, and the top 20 subreddits based on the\n44\n1. COVID_CANADA 6. worldnews 11. wallstreetbets 16. CryptoCurrency\n2. news 7. nottheonion 12. tomorrowsworld 17. technology\n3. politics 8. prisons 13. autotldr 18. europe\n4. todayilearned 9. NoFilterNews 14. Conservative 19. electionReformNews\n5. Coronavirus 10. conspiracy 15. NoNewNormal 20. HumanTraffickingNews\nTable 5.7: Top 20 subreddits with the highest number of unique news source entities\nshared in them.\nnumber of submissions made in them in total.\nIn general, a higher number of news links shared in a subreddit means there are a\nhigher number of unique news sources mentioned in that subreddit. In other words,\nthere is a positive correlation (r=0.55) between the number of unique news sources\nmentioned in a subreddit and the total number of news links shared in that subreddit.\nThis positive correlation is shown in Figure 5-4. However, there are some subreddits\nwhere this is not the case, for example subreddits that are moderated by bots where\nonly articles from specific news sources are shared. Some examples are r/BBCauto,\nr/CHICAGOSUNauto, r/CNET_ALL_RSS, and others. These subreddits are re-\nmoved in my analysis.\nAmong the 131,633 different subreddits in which people share at least one news\nlink within the time frame of interest, 62,683 subreddits (47.6% of total subreddits)\nonly have 1 news link mentioned in it. This suggests that I should not use this big\nset of subreddits in its entirety for the clustering task, instead I should filter these\nsubredditstoonlyincludeasetofthosewiththemostcompleteinformationregarding\nour set of news sources. One way to approach this is by employing PCA (Principal\nComponent Analysis) to form a set of linear combinations of these subreddits and\nchoosing a subset that explains the most variance within these subreddits. This is\nimplemented in the \u201cPre-processing data\u201d section.\n45\nFigure 5-2: Subreddit count v. Mention count of News sources. Quadrant numbers\nare labeled in red. News sources in the first quadrant are both mentioned very\nfrequently and in many subreddits (broad appeal), for example theguardian.com,\ncnn.com, and nytimes.com. News sources in the second quadrant are mentioned very\nfrequently but in fewer subreddits (more niche), for example mlb.com, thehindu.com,\nand breitbart.com.\n46\nFigure 5-3: Subreddits subscribers. More than half of the subreddits in our dataset\nhave about 1000 or less subscribers.\nFigure 5-4: There is a positive correlation between the number of unique news sources\nand total news links shared in each subreddit (r=0.55). Some outliers, shown in the\nbottom left corner, are subreddits that are moderated by bots to only share news\nfrom specific news sources, such as r/BBCauto among others.\n47\nChapter 6\nMethods for Data Representation\nIn this section I will broadly go over the steps I take to process my dataset and\nutilize it to infer news source characterizations, then talk more deeply about it in the\nsubsections that follow.\nRecall that my goal is to investigate news source characterizations based on their\nonline audience. To do this, I will first represent each news source using the statis-\ntics of the consumption by their online audience. Then, using these representations\nas features, I will first investigate if clustering the news sources yields results in a\nrepresentation that places \u2018similar\u2019 news sources together. I define \u2018similar\u2019 as hav-\ning one or more identical news characteristics, such as media type, language, origin,\nthemes, reliability, etc. Using some news sources that are labeled based on these\ncharacteristics, I will then make note of the characteristic similarities that are most\nprominent among news sources that are represented closer together. If I find that it is\nthe case that similar news sources are indeed placed closer together using this method\nof representation, then I reason that we can characterize unlabeled news sources using\nthis kind of representation, by inferring characteristics of the news sources that are\nclose neighbors of those unlabelled news sources. In this thesis, the label of some\ncharacteristics for some news sources is obtained using Wikidata1which is a free\nknowledge based of 97M data items, and Media Bias Fact Check2, which is a fact-\n1https://www.wikidata.org/wiki/Wikidata:Main_Page\n2https://mediabiasfactcheck.com/\n48\nchecking website that rates the reliability and factuality of news sources that is open\nto the public.\nThe second way that I investigate the usefulness of audience-based metrics in\nnews source characterization is by building classification and regression models, using\nthe audience-based metrics to predict some news source characteristics. If good-\nperforming models are found, then I reason that we can characterize unlabelled news\nsources by using their audience-based representations and these classification and\nregression models.\nI represent my dataset of news sources using the number of times they are shared\nin users\u2019 posts in various subreddits (i.e. their sharing frequency), as well as that\nsharing frequency weighted by the number of comments and upvotes ratio that those\nposts have. In other words, I represent news source entities using the statistics of\ntheir presence in various subreddits as their features.\nBefore building vectors representing these news sources, I first filter out popular\nsites that are not news sources, but instead are news aggregators or hosts of users\u2019\ngenerated contents. Recall that there are a lot more subreddits than there are news\nsources. Therefore, due to the extremely high feature dimension of the news source\nentities, I also filter out subreddits that only contain very few news sources shared in\nthem.\nHowever, heavily filtering out subreddits based only on the sharing volume in\nthem is not a good idea because we will only be left with very general subreddits that\nwill not bring very much information about the characteristics of the news sources.\nTherefore, after scaling the data, I also employ the Principle Component Analysis\n(PCA) method for dimensionality reduction, with the hope of reducing the number\nof features while still retaining most of the information they bring.\n6.1 Building news source dataset\nRecall that I built my dataset of news sources by intersecting the set of news sources\naccording to GDELT and the set of news sources according to Muck Rack. Here I\n49\nwill describe how I went about getting these two sets of news sources.\nTo acquire the set of news sources recognized by GDELT, I focused on its Global\nKnowledge Graph (GKG) table as hosted on Google Big Query3. Although there is\na lot of information included in the table, I only extracted the information about the\ndomain name of the news source. To get as many active news sources as possible from\nGDELT, I collected the domain name of the news sources that GDELT has used in\nthe past 5 years, 2016 - 2021. In total there are 205,994 unique news source domain\nnames that I got from GDELT.\nMuck Rack, on the other hand, does not host their data in such an easy-to-query\ndatabase. To acquire the set of news sources recognized by Muck Rack, I utilize\ntheir publicly available table of news sources hosted on their website4using Python\u2019s\nselenium library. I extracted data from Muck Rack in two iterations. The first\ntime of scraping was in September 2021, where I acquired 67,782 news sources from\nMuck Rack. Since Muck Rack keeps on updating their database thus changing the\ntotal news outlets that they have, I went to the site again in January 2022, where\nI acquired 450,590 total news sources. This is a dramatic increase in the number of\nnews sources, but it is not the case that the number of global news sources more than\nquadrupled in the timespan of four months. In fact, I found that most of the new\nsites that were added were links to individual podcasts, including those hosted on\nanchor.fm and spreaker.com. However, just like other user-generated contents such\nas blog posts, these podcasts are filtered out in a later stage of data processing, since,\nby the definition used by this thesis, these user-generated contents and the sites that\nhost them do not count as news sources.\nI built the final set of news outlets recognized by Muck Rack by combining the\ntwo sets of news sources extracted in September 2021 and January 2022 via the union\noperation, resulting in 457,882 total news sources.\nTo build my final set of news sources, I intersected the set of news sources from\nGDELT and the set of news sources from Muck Rack. Their intersection results in\n3https://cloudplatform.googleblog.com/2014/05/worlds-largest-event-dataset-now-publicly-\navailable-in-google-bigquery.html\n4https://muckrack.com/media-outlets\n50\n42,477 news sources, which comprises about 20% of the total news sources appearing\nin GDELT, and 9% of the total news sources appearing in Muck Rack. As shown\nin Table 6.1, it is interesting to note that these two organizations have very little\nagreement on what counts as news sources. GDELT claims to cover most if not\nall events happening all around the world, thus utilizing most if not all global news\nsources. Similarly, Muck Rack claims to provide a complete media outlets database.\nYet, the two agree very little on what counts as news sources. This emphasizes the\nneed for us to gain further understanding of news sources. This thesis contributes to\nthis purpose by trying to understand the possibilities of deriving insights about news\nsources based on their online audiences.\nData source Number of news sources\nGDELT 205,994\nMuck Rack 457,882\nGDELT\u2229Muck Rack 42,477\nTable 6.1: Summary of the number of news sources recognized by GDELT and Muck\nRack, and the little overlap between the two.\nAfter intersecting the set of news sources acquired from GDELT and Muck Rack,\nI stored this set of news sources and later went on Pushshift Reddit database to see\nhow each of them are shared in various subreddits. For ease of reference, I will refer\nto this set of 42,477 news sources as \u2018gm_intersection\u2018.\n6.2 Building News Sources Representation\nSince my goal is to investigate news source characterizations based on their audience,\nI will represent each news source using the statistics of how they are shared by their\nonline audience on Reddit. Just as the usual dataset setting in data analysis or\nMachineLearningframeworkisrepresentedusingvariousfeatures, mydatasetofnews\nsources is also represented using their sharing statistics on Reddit as their features.\nIn this section I will explain how I acquire the sharing statistics of news sources from\nReddit and how I process and use them as features of my set of news sources.\n51\n6.2.1 Streaming and processing Reddit zst data\nIacquiredthedatasetofRedditsubmissionsinJanuary-June2021fromthePushshift\ndatabase by manually downloading the zst-formatted files, totalling in around 50GB\ncompressed size. Decompressing these files would require about 600 GB storage. Due\nto the prohibitively large uncompressed size of these files, I kept them compressed\nand utilized the zstandard Python package to stream the submission data in each of\nthe files.\nFigure 6-1: An example of Reddit submission. The highlighted parts are what I\nextract from the NDJSON files representing this submission. Note that the current\nversion of Reddit only shows the total number of votes received (weighted by +1 for\nupvotes and -1 for downvotes). However, the Pushshift dataset contains the actual\nupvote ratio (number of upvotes divided by total votes), as does the old version of\nReddit (old.reddit.com).\nRecall from Section 4.2 that each of these files contains Python dictionaries rep-\nresenting submissions. Figure 6-1 shows an example of Reddit submission with the\nparts that I extract highlighted in yellow. Each of these submission dictionaries\nare associated with a subreddit and have various details recorded in the dictionary.\nI then utilized regular expressions to extract URLs from each of the submissions\nmade on Reddit during the six months. Next, for each of the extracted URLs, I\nextracted the subdomain, domain, and suffix to form the host or domain name of the\nURLs. For each domain, I then checked if it is contained in my set of news sources\ngm_intersection. If it is, I then updated my records about the sharing frequency\nof this particular domain in the particular subreddit that the submission dictionary\n52\nis associated with. Within the same dictionary, there is also information about the\nupvote ratio and the number of comments that the post receives. Thus, in addition\nto keeping track of the sharing frequency of this particular domain in this particular\nsubreddit, I also keep track of the same frequency weighted by the upvote ratio, as\nwell as the same frequency weighted by the number of comments.\n6.2.2 Data Representation\nThere are two distinct yet very connected entities in my dataset: news sources and\nsubreddits. The connection between these two entities are very clear, which is that\nvarious news sources are mentioned in various subreddits thus forming connections\nbetweenthem. Mygoalistothenlearntheconnectionswithinthesetofnewssources.\nIn other words, I will try to infer the relationship between news sources based on how\nthey are connected to the other set which is the subreddits.\nAnintuitivemethodofgoingaboutthisisbyrepresentingtherelationshipbetween\nthe two sets in a matrix form, let\u2019s call this matrix m, where the rows will represent\neach of the news sources, and the columns representing each of the subreddits. The\nactual values in the matrix at position \ud835\udc5a[\ud835\udc56][\ud835\udc57]will then represent the weight of the\nrelationship between the news source at row i and the subreddit at row \ud835\udc57. The\nmost straightforward way of defining the values in the matrix would be by using\nbinarization, where we only use the value \ud835\udc5a[\ud835\udc56][\ud835\udc57]\u22080,1, where \ud835\udc5a[\ud835\udc56][\ud835\udc57] = 1if news\nsource \ud835\udc56was mentioned at all in subreddit \ud835\udc57, and \ud835\udc5a[\ud835\udc56][\ud835\udc57] = 0otherwise. However,\nrepresenting news sources based on their Reddit audience in this way discards a\nlot of useful information such as the different frequency of news source mentions in\nthe submissions in each of these subreddits, as well as the engagements with those\nsubmissions such as upvote ratio and number of comments. So, I employ a more\nexpansive matrix representation that keeps track of three news source engagement\nstatistics for each subreddit: sharing frequency, upvote-based weighted frequency, and\ncomment-based weighted frequency. Note that comment-based weighted frequency is\nequivalent to the total number of comments that posts sharing news source links\nreceive.\n53\nIn order to keep track of these three statistics, instead of using only one column to\nrepresent each subreddit, I use three columns instead. The first column of a subreddit\nwill record the raw number of sharing frequency of each news source, the second\ncolumn will record the sum of the upvote ratio that each submission sharing each\nnews source gets, while third column will record the sum of the number of comments\nthat each submission sharing each news source gets. Each row, on the other hand,\nstill represents one news source each. An example of such representation is shown\nin Table 6.2, for nytimes.com, with an example representation based on r/investing\nwhich is one of the subreddits being considered.\nNews Source ...Sharing freq.\nin r/investingTotal upvote ratio\nin r/investingTotal comments\nin r/investing...\n... ...... ... ... ...\nnytimes.com ...1392 121.79 7296 ...\n... ...... ... ... ...\nTable 6.2: An example of a news source representation. The example news source is\nnytimes.com, with an example representation based on r/investing which is one of the\nsubreddits being considered. In a later section, this matrix will be further processed\nby scaling and dimensionality reduction.\n6.2.3 Filtering Subreddits\nThere are three reasons why filtering subreddits is a good idea in this case. First,\nthere are a lot more subreddits than news sources in the dataset, in other words\nthere are a lot more feature columns than the data points (rows). This leads to\nwhat is commonly known as the \u201ccurse of dimensionality\u201d in Machine Learning, where\nthere are significantly more features than data points, which leads to poor-performing\nmodels5. Since I also represent each subreddit in three columns, the gap between the\nnumber of news sources and subreddits becomes even wider. Filtering out some\nsubreddits will help in reducing the dimensionality of the dataset.\nSecond, as discussed previously in the Section 5.2, there are a lot of subreddits\nthat do not have a lot of news source links shared in them thus contributing little to\n5https://en.wikipedia.org/wiki/Curse_of_dimensionality\n54\nno information. Additionally, there are also a lot of subreddits that have very few\nnews sources mentioned in them. As mentioned in Section 5.2.2, there are a lot of\nsubreddits with bots as their moderators and posters, where these bots only share\nnews links from particular news sources in an automated fashion. Since these kinds\nof subreddits do not bring in any information about news source audiences, I also\nexclude them from my analysis. In particular, I only included subreddits that have\nat least 10 unique news sources mentioned in them and at least 100 news links shared\nin them in the time span of six months (January - June 2021). Filtering subreddits\nin this way results in the final set of 2,189 subreddits. Even though this is a rather\nsmall subset of the original set of subreddits, the low threshold used to filter these\nsubreddits assures us that we are not losing too much information.\nThird, memory and computational power. My computer had trouble storing and\nprocessing the dataset with no or minimal subreddit filtering. Due to computing\npower and the limited time I have to work on my thesis, working with a smaller (yet\nnot much less informative) subset of my dataset is a good choice. Scaling the method\nto cover the full set of the dataset, and even covering longer periods of time, is an\ninteresting subject of future research.\nAll in all, the final set of 2,189 subreddits make up 2189 x 3 = 6,567 features.\n6.2.4 Filtering News Sources\nAs discussed in Section 2.1, some of the sites that are included in our original set of\nnews domains are not news sources, but instead are news aggregators and hosts of\nuser-generated content instead. These two groups of sites are filtered out of our set\nof news sources.\nI also have to consider the news sources that are not shared frequently enough\nin our dataset, which would be hard to characterize. For example, 35% of the news\nsources in our set of news sources were only shared less than 5 times. There are two\npossibilities of the low rate of sharing of these news sources. First possibility, these\ndomains might not be valid domains and are included in the dataset due to scraping\nerrors. Second, these domains are valid domains and are just shared very infrequently.\n55\nTo confirm that this big proportion of domains are indeed valid, as opposed to\ninvalid URLs resulting from problematic URL extraction, I randomly sampled 10%\nof these sites and investigated the HTTP response they return. Using the requests\nlibrary in Python, I found that about 77% of these sites are valid (with 200 response\ncodes). Another 5% returns SSL Error which indicates sites that are perceived to\nbe unsafe (but they do exist). In total, 82% of this sample are valid sites, though\nsome unsafe. The other 10% return 403 response codes, 0.4% return 404 response\ncodes, and the remaining 7.6% return various other responses. Thus, scraping error\nis unlikely to be a problem, and it is simply the case that a big subset of my set of\nnews sources were very infrequently shared on Reddit.\nIt is also hard to characterize these news sources that are shared in very few\nsubreddits because there is not enough data about them. Therefore, I set a threshold\nthat a news source must be shared at least 50 times within the first six months of\n2021 in order to be included for analysis. All news sources that were shared less than\nthis are excluded from my analysis. This filtering process brings down the number of\nnews sources in my analysis to 2,647 news sources.\nIn total, 2,647 news sources represented by 2,189 subreddits form a matrix with\n2,647 rows and 6,567 feature columns.\n6.2.5 Scaling and PCA Dimensionality Reduction\nNote that even after the filtering process, we still have a very large number of subred-\ndits compared to the number of news sources, thus potentially preserving the \u201ccurse of\ndimensionality\u201d. The next step in data processing is to employ Principle Component\nAnalysis for dimensionality reduction. However, before employing this dimensionality\nreduction technique, I first scale my data.\nScaling is an important part of data processing in common data analysis or ma-\nchine learning pipeline, if we have the right reasoning in doing it. In this case, I\nfound that not standardizing my data results in poorer clustering and classification\nperformance in inferring news source characteristics. Using clustering, for example,\nunscaled data yields in clustering popular news sources together, and not much else.\n56\nHowever, I hope to be able to extract other characteristics of news sources and repre-\nsent them in their embedding space such that similar news sources are closer together,\nso we can infer characteristics (thus characterize) news sources based on their close\nneighbors. I find that scaling yields a better result.\nFor further dimensionality reduction, differently from the previous step, in this\nstep I do not manually pick which subreddits to include as features. Instead, PCA\nbuilds a new feature set using linear combinations of the original feature set. The\nmembers of new feature sets are called the principal components.\nTherearetwoversionsofPCAthatIconsider: aregularPCA,whichisaLAPACK\nimplementation of the full Singular Value Decomposition (SVD); and a randomized\ntruncated SVD by the method of Halko et al. 20096. The two methods are sim-\nilar, with the exception that the second method does not center the data as part\nof its preprocessing, among other differences. I consider the second method because\nit works well with sparse data, which my dataset is. Recall that the first objective\nis to cluster the news sources using their lower dimensional vector representations.\nUsing various metrics to evaluate the clustering results such as silhouette coefficient,\nCalinski-Harabasz Index, and Davies-Bouldin Index7, I found that the first version of\nPCA, which is the regular PCA, results in a slightly better clustering results, given\nthat I first standardize the data, using the StandardScale() function from sklearn li-\nbrary. I then calculate the percentage variance explained by the principal components\nand summarize the result in Figure 6-2.\nAfter applying PCA, I found that the first 300 principal components explain most\nof the variance of the subreddit-based features. To be exact, they explain 0.86 of the\nfeatures variance. Thus, the final representation of the gm_intersection news sources\nis made of the 300 principal components as their features.\n6https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n7https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n57\nFigure 6-2: The figure above shows the cumulative percentage of variance explained\nby a set number of principal components derived from the subreddit-based features.\nThe red line shows that the first 300 principal components explain 0.86 of the features\nvariance).\n58\nChapter 7\nMethods for Data Analysis\nAs shown in Section 5.1, a simple comparison between mention count and subreddit\ncount of news source sharing leads to an interesting news source characterization in\nterms of their popularity and broadness of appeal. Now that I have represented the\ngm_intersection news sources using their sharing metrics on various subreddits, in\nthis section I will analyze whether this type of news source representation can be\nutilized to draw insights about news source characterizations.\nTo do this analysis, I first visualize the 300-dimensional representation of news\nsources down to 3-dimensional then visually investigate whether similar news sources\nare close together in this representational space. I then attempt to employ both\nclustering and classification methods to investigate whether any natural clusters of\nnews sources emerge in this representational space, or whether we would be able\nto infer some specific characteristics of news sources (such as reliability, country of\norigin, political leaning, and media type) using the 300-dimensional representation.\nIn the following sections I will go over the three methods.\n7.1 Visual Investigation\nVisualizing news sources using all of their 300 features for representation is difficult\nif not impossible due to the high feature dimensionality. For clarity of visualizations,\nI project down the 300-dimensional representation to 3-dimensional representations\n59\nusing T-distributed Stochastic Neighbor Embedding (t-SNE) as implemented in the\nPython\u2019s sklearn library1. One might wonder why I don\u2019t simply use the first three\nprincipal components that result from PCA for 3-dimensional representations of the\nnews sources. The reason for this is that the first three principal components only\nexplain less than 21% of the variance of all features, thus not ideal. On the other\nhand, simply using t-SNE, without PCA, to project down more than 6,000 features\nto 3 features is very expensive computationally and is generally not recommended. It\nis recommended to first use PCA to reduce the very high dimension to a reasonable\namount then use t-SNE to speed up computation and suppress noise, just as it is\ndone in this thesis.\nAsanoverview, t-SNEisastochasticalgorithmthatiscommonlyusedtovisualize\nhigh-dimensional data using a non-linear dimensional reduction method. It is based\non the Stochastic Neighbor Embedding (SNE) algorithm developed by Hinton and\nRoweisin2002, withthet-distributedvariantproposedbyvanderMaatenin2008. In\nsummary, t-SNE creates the low-dimensional embedding from the high-dimensional\nembedding by minimizing the Kullback-Leibler (KL) divergence of the joint proba-\nbilities in the original space and the embedded space using gradient descent2.\nt-SNE is chosen for further dimensional reduction for visualization purposes be-\ncause it is highly sensitive to local structures. In other words, entities that are closer\ntogether in their high-dimensional representation are also placed closer together by\nt-SNE in the lower dimensional space. This is a desirable feature because we want to\ninvestigate whether news sources that close together in their high-dimensional repre-\nsentations are in fact similar. We can investigate this by looking at how news sources\nare placed in the lower 3-dimensional space and visually examine if news sources that\nare closer together are in fact similar.\nt-SNE has a lot of parameters that can be tuned as an effort to find a better\nfit. Figure X below shows the complete parameters used in the t-SNE model used to\nvisualize the news source representations.\n1https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE\n2https://scikit-learn.org/stable/modules/manifold.html#t-sne\n60\nFigure 7-1: The complete t-SNE parameters used in this thesis to visualize the news\nsources representations by projecting them down to three dimensions.\nUsingvisualexamination,Ifindthatnewsrepresentationasdescribedinthisthesis\ndoes indeed place \u2018similar\u2019 news sources closer together. However, the notion \u2018similar\u2019\nis not constant throughout the distribution of the news sources in the representational\nspace. For instance, some news sources that are closer together are similar based on\ntheir reliability (i.e. some unreliable news sources placed closer together). Yet, not\nall of the unreliable news sources are close together. Some of them are closer to other\nnews sources instead, on the basis of similar country of origin, theme, media type, or\nother characteristics.\nSome groupings of similar news sources are as follows:\n1. thefederalist.com, redstate.com, pjmedia.com, breitbart.com, oann.com, then-\nationalpulse.com,americanthinker.com,amgreatness.com,bizpacreview.com,in-\ndependentsentinel.com, theepochtimes.com are all unreliable news sources that\nspread misinformation and fake news, more recently about Covid-19 and the\nelection. All of these news sources are close together in the representational\nspace. The cluster containing these news sources are shown in Figure 7-2.\n2. Canada-basednewssourcessuchasnationalpost.com,cbc.ca,winnipeg.ctvnews.ca,\nmacleans.ca, winnipegfreepress.com, calgaryherald.com, torontosun.com, wind-\n61\nsorstar.com are close together in the representational space. In this case, the\n\u2018similarity\u2019 criterion of these news sources are their country of origin. This is\nas opposed to media type as they have different media types of online newspa-\npers and TV network, or political leaning of conservative (calgaryherald.com,\ntorontosun.com), liberal (macleans.ca), and unbiased (winnipegfreepress.com).\n3. Some left-leaning news sources such as forward.com, thewalrus.ca, harpers.org,\nlamag.com, washingtonian.com, nhregister.com, and ctpost.com are close to-\ngether despite their different media types of magazines (lamag.com, washing-\ntonian.com), daily newspapers (ctpost.com, nhregister.com); country of ori-\ngin of Canada (thewalrus.ca) and the USA; themes of culture, food, fashion\n(lamag.com), and Jewish arts culture and opinion (forward.com). In this case,\nthe similarity criterion is political leaning.\nFigure7-2: Newssourcerepresentationsin3Dwithcolorsrepresentingtheirreliability\n(green for unreliable, red for reliable, and purple for unlabeled news sources). In the\nleft side figure we see that news sources are not exactly grouped together based on\ntheir reliability. However, some unreliable news sources (enclosed by the green circle)\nare very close together. The same view with only unreliable news sources is presented\nby the figure on the right for clarity. Interactive three dimensional representations\naccessible at https://newssource-vis.herokuapp.com/ .\nOther groupings can be found by visual examinations of the interactive 3D rep-\nresentation of these news sources on https://newssource-vis.herokuapp.com/. The\n62\nFigure 7-3: \u2018antiwar.com\u2019 is a close neighbor of a group of unreliable news sources.\nAn intuitive suggestion is that perhaps \u2018antiwar.com\u2019 is an unreliable source. After\nmanual investigation and according to Media Bias Fact Check as well as Politifact,\n\u2018antiwar.com\u2019 indeed has medium to low reliability.\nresulting visualization of news sources\u2019 representations is shown in Figure 7-2, with\ncolors corresponding to the reliability of the news sources as labeled by Media Bias\nFact Check3.\nOne potential application of this representation method is to help characterize un-\nlabelled news sources by leveraging known facts about the neighboring news sources.\nFor example, \u2018antiwar.com\u2019 is one of the unlabeled news sources in terms of their\nreliability. As shown in Figure 7-3, \u2018antiwar.com\u2019 is a close neighbor of the group of\nunreliable news sources as listed in number 1 in the list above. One can reasonably\nargue that since \u2018antiwar.com\u2019 has similar representations based on audience-based\nmetrics as a group of unreliable sources, perhaps \u2018antiwar.com\u2019 is another unreliable\nsource. After manual investigation and according to fact-checking websites such as\nMedia Bias Fact Check as well as Politifact4, \u2018antiwar.com\u2019 indeed has medium to\nlow reliability. Perhaps other characterization tasks for unlabeled news sources could\nbe done with this method.\n3https://mediabiasfactcheck.com/\n4https://www.politifact.com/\n63\n7.2 Clustering\nAfter seeing that some similar news sources are indeed close together in the new fea-\nture space, in this section I investigate whether there are naturally emerging clusters\nof news sources based on the new feature space. The idea is to see what characteris-\ntics of news sources are the most prominent in clusters of news sources, if any, when\nthese news sources are represented solely by their audience-based metrics as features.\nIn the following sections, I will give an overview of the two clustering methods\nthat are considered in this thesis, and the silhouette score metric as a way to evaluate\nthem. Next, I will expand on my attempt to cluster first using manually-chosen\nspecific subreddits (utilizing agglomerative clustering), then using the entire set of\nsubreddits (utilizing k-means clustering), to see if news source clusters emerge.\n7.2.1 Clustering Algorithms Overview\nThere are various types of clustering algorithms, such as density based clustering\n(e.g. DBSCAN,HDBSCAN,etc.),hierarchicalclustering(AgglomerativeorDivisive),\ncentroid-based partitioning clustering (K-Means), fuzzy clustering, and others. The\nfirst three types of clustering are hard-clustering, which means that each point is\nonly assigned to one cluster, whereas fuzzy clustering is a soft clustering method\nthat assigns probabilities to each point of joining the various clusters. In this thesis\nI focus on the hard clustering methods, specifically agglomerative clustering and k-\nmeans clustering.\nFor many clustering tasks, including the one that is being considered in this thesis,\none does not know in advance to which cluster each of one\u2019s data points belong. In\nother words, the ground truth labels of the data points are not known. This means\nthat it is hard to evaluate clustering results because there are no ground truth labels\nto compare the results to. One possible evaluation metric in this case is called the\n\u2018Silhouette Coefficient\u2019 metric as proposed by Rousseeuw in 1987 [36], which measures\nhow well samples are clustered with other samples that are similar to themselves.\nThe Silhouette Coefficient s for one data point is given as \ud835\udc60=\ud835\udc4f\u2212\ud835\udc4e\n\ud835\udc5a\ud835\udc4e\ud835\udc65 (\ud835\udc4e,\ud835\udc4f), where \ud835\udc4eis\n64\nthe mean distance between that data point and all the other points in the same class,\nand\ud835\udc4fis the mean distance between that data point and and all the other points in\nthe next nearest cluster5. Intuitively, a measures cluster cohesion (where smaller a\nmeans better cohesion), while b measures cluster separation (where larger b means\nbetter separation). Thus better clustering results would lead to larger numerator and\nlarger silhouette coefficient overall. Silhouette Coefficient values are in the range of -1\nand 1, where higher values closer to 1 indicate better clustering. Values closer to -1\nindicate assignments to the wrong cluster and values closer to 0 indicate overlapping\nclusters. One can calculate and report the Silhouette Coefficient value for each of the\ndata points individually, or as one number representing the mean of all the Silhouette\nCoefficient values.\nNext I will give an overview of the two clustering methods I consider in this thesis:\nagglomerative clustering and k-means clustering.\nAgglomerative Clustering\nAgglomerative clustering is a bottom-up hierarchical clustering approach, where ini-\ntially each of the points is clustered in a 1-element cluster, then clusters are combined\ntogether at each step based on a particular distance and linkage metrics until even-\ntually we end up with one big cluster containing all of the points.\nWhen considering which clusters to merge in the intermediary agglomerative clus-\ntering method, the algorithm measures the distance between clusters and merge two\nclosest clusters together at a time. Some common distance metrics are Euclidean\ndistance, squared Euclidean distance, Manhattan distance, Chebyshev (maximum\ndistance), and others. The usual default of distance metric is the Euclidean distance.\nSince clusters generally contain multiple points (except for the initial clusters\nwhere each cluster only contains one point), measuring distance between two clus-\nters is not very trivial. This is where the linkage criteria comes into play, where\nhaving different linkage criteria means measuring the distance between two clusters\ndifferently.\n5https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n65\nThere are various linkage criteria in agglomerative clustering, including the most\npopular as follows:\n1. Single (minimum) linkage clustering considers the minimum distance between\nall possible pairings of points in the two clusters as the distance between the\ntwo clusters.\n2. Complete (maximum) linkage clustering considers the maximum distance be-\ntween all possible pairings of points in the two clusters as the distance between\nthe two clusters.\n3. Average linkage clustering considers the maximum distance between all possible\npairings of points in the two clusters as the distance between the two clusters.\nThese linkage criteria are visualized in the Figure 7-4.\nFigure 7-4: Different ways of calculating the distance between two clusters in agglom-\nerative clustering, depending on the linkage criterion. Source: Figure 6.2 of Everitt\net al. (2011) [15]\nSome of the advantages of using hierarchical clustering such as agglomerative\nclustering are that the clustering process itself is easy to describe and visualize us-\ning a dendogram, and that it is non-parametric so we don\u2019t have to initially set\n66\nhow many clusters we are trying to find, which is unlike another clustering method\ncalled k-means. However, agglomerative clustering algorithms are computationally\nexpensive. Some variants such as SLINK [39] for single-linkage and CLINK [11] for\ncomplete-linkage have been developed to improve the runtime of agglomerative clus-\ntering algorithms6.\nK-Means Clustering\nK-means clustering is an expectation-maximization algorithm aiming to cluster enti-\nties by minimizing the within-group sum of squared distances (WGSS) of the points\nin each cluster. Specifically:\n\ud835\udc4a\ud835\udc3a\ud835\udc46\ud835\udc46 =\ud835\udc5e\u2211\ufe01\n\ud835\udc57=1\ud835\udc58\u2211\ufe01\n\ud835\udc59=1\u2211\ufe01\n\ud835\udc56\u2208\ud835\udc3a\ud835\udc59(\ud835\udc65\ud835\udc56\ud835\udc57\u2212\u00af\ud835\udc65(\ud835\udc59)\n\ud835\udc57)2, (7.1)\nwhere \u00af\ud835\udc65(\ud835\udc59)\n\ud835\udc57=1\n\ud835\udc5b\u2211\ufe00\n\ud835\udc56\u2208\ud835\udc3a\ud835\udc59\ud835\udc65\ud835\udc56\ud835\udc57is the mean of the data points in group \ud835\udc3a\ud835\udc59on variable \ud835\udc57[15].\nThe k-means clustering algorithm can be described as follows:\n1. Initialize the centroids of the pre-determined k clusters. This can be done\nby randomly sampling k of the data points, or more developed initialization\nalgorithms such as the k-means++ initialization that is used to speed up con-\nvergence7.\n2. Repeat until centroids do not change significantly or at all (convergence):\n(a) Assign each of the data points to the nearest centroid to it, forming \ud835\udc58\nclusters.\n(b) For each of the \ud835\udc58clusters, calculate its new centroid by taking the mean\nof all the data points.\nDue to the randomness of the initialization process, different runs of k-means\nclustering algorithms could lead to different clustering results. Another challenge\n6https://en.wikipedia.org/wiki/Hierarchical_clustering\n7https://scikit-learn.org/stable/modules/generated/sklearn.cluster.kmeans_plusplus.html\n67\nin using k-means clustering is the fact that we must predetermine the number of\nclusters \ud835\udc58that we expect, as a parameter to the algorithm. In unsupervised cases\nwhere clustering algorithms are used, such as the case in this thesis, one does not\nknow in advance how many clusters to expect, thus pre-determining \ud835\udc58is not trivial.\nOne way to do so is by employing the so-called \u2018elbow method\u2019 heuristic, where one\nplots the WGSS associated with different cluster sizes, then picking the elbow of the\ncurve, where adding one more cluster does not result in significant WGSS decrease,\nas the optimal number of clusters8.\nThek-meansclusteringalgorithmisnotwithoutadvantages. Thisalgorithmisone\nof if not the most popular and easiest-to-explain-and implement clustering algorithms\nwith applications in a vast range of fields9. Unlike agglomerative clustering, k-means\nalso scales well to large datasets, like the one in this thesis.\nNowthatwearemorefamiliarwiththeagglomerativeandk-meansclusteringalgo-\nrithms, in the next sections I will go over my attempts to cluster the gm_intersection\nnews sources to see if any of these news sources form natural clusters using their\nsharing metrics on Reddit as their features. I first realize clustering for a smaller and\nmore explainable subset of my data, then for the whole dataset.\n7.2.2 Small Scale: Clustering using sports subreddits\nAs the first step in clustering, I investigate whether using specific subreddits as fea-\ntures could yield insightful clustering results. Specifically, I use three types of subred-\ndits: 33 NFL-related subreddits, 30 NBA-related subreddits, and 20 Premier League-\nrelated subreddits, as listed by Solomon10. In total, there are 85 news sources that\nare mentioned at least 5 times in one or more of these subreddits.\nShort overview of the leagues:\n\u2022The National Basketball Association (NBA) is a professional basketball league\nin North America founded in New York in 194611, thus the subreddits related\n8https://en.wikipedia.org/wiki/Elbow_method_(clustering)\n9https://en.wikipedia.org/wiki/K-means_clustering\n10https://www.futuressport.com/en/insight/sports-fans-on-reddit.aspx\n11https://en.wikipedia.org/wiki/National_Basketball_Association\n68\nto this league are those that are specific to various regional basketball teams\nin North America, such as r/bostonceltics, r/NYKnicks, r/torontoraptors, and\nothers.\n\u2022The National Football League (NFL) is a professional American football league\nfounded in Ohio, USA in 192012. Related subreddits are football teams such as\nr/Patriots(forBoston-basedPatriotsteam),r/GreenBayPackers(forWisconsin-\nbased Green Bay Packers), r/Seahawks (for Seattle Seahawks), and others.\n\u2022The Premier League is the top level of the English football league system13.\nSome subreddits related to this league include r/reddevils (for Manchester\nUnited), r/LiverpoolFC, r/chelseafc, and others.\nUsing only these particular subreddits, I built representations of the 85 news\nsources using the method described in the Building News Sources Representation\nsection. After running the PCA step, I found that the first 7 principal components\nexplain 90% of the feature variance. So for clustering, I only use these 7 principal\ncomponents.\nFor this clustering task, I first utilize the agglomerative clustering as implemented\nby the SciPy package in Python14, with \u2018average\u2019 linkage. I then build a dendrogram\nbased on this agglomerative clustering to visualize how news sources are clustered\ntogether in the intermediary steps of the algorithm. I then also realize the k-means\nalgorithm for the same task and investigate whether either or both of the clustering\nalgorithms yields interesting results.\nFrom Figure 7-5 we see that the news sources are reasonably clustered based on\ntheir country of origin and themes (type of sports and whether the news sources are\nexclusively talking about sports or more general). Specifically, we see that there are\n4 main clusters that show up: general news sources that sometimes writes about\nsports (represented by orange branches), UK-based news sources (represented by\n12https://en.wikipedia.org/wiki/National_Football_League\n13https://en.wikipedia.org/wiki/Premier_League\n14https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html\n69\ngreen branches), sports-specific or general news sources that heavily writes about\nsports (represented by the red branch), and nba.com in its own cluster.\nFigure 7-5: Dendrogram of the resulting agglomerative clustering of news sources that\nare shared in sports-related subreddits (NFL, NBA, Premier League), with weighted-\nlinkage. We see that most UK-based news sources are clustered together (green\nbranches), news sources that heavily write about basketball and American football\nare clustered together (red branches), and the more general news sources clustered\ntogether (orange). However this is not a perfect clustering since some UK-based news\nsources as well as sports-themed news sources are placed in the orange more general\n(orange) cluster.\nThe next step is to realize k-means clustering. For initialization, I use k-means++\ninitialization [42]. to speed up convergence. To find the optimal number of clusters, I\nemploy the elbow method with results as shown in Figure 7-6. We see that the elbow\nof the WGSS curve is found for cluster size \ud835\udc58= 3. Thus in the final cluster, I will\nrealize k-means clustering on this small dataset using cluster size \ud835\udc58= 3.\nSimilar to the result of agglomerative clustering, using k-means clustering of \ud835\udc58= 3\nresults in one big cluster containing 63 general news sources, one cluster containing\n11 UK-based news sources, and 11 news sources that writes heavily about sports.\nAs an evaluation metric for this clustering result, I inspect the silhouette coeffi-\ncients of my 85 news source data points. The individual silhouette coefficient values\nare as shown in Figure 7-7, while the overall mean of the silhouette coefficient is 0.61.\n70\nFigure 7-6: Different WGSS values for different cluster sizes for the small dataset\nacquired by only considering sports-related subreddits. We see that the elbow of the\nWGSS curve is found at cluster size k = 3, as after this point an additional cluster\ndoes not significantly decrease WGSS.\n71\nRecall that Silhouette Coefficient takes values between -1 and 1, so a value of 0.61\nindicates a reasonably good clustering result.\nFigure 7-7: The silhouette coefficient values for individual data points. The red\nlines separate the three different clusters. The first cluster contains the news sources\nthat heavily write about sports, the second cluster contains UK-based news sources,\nand the third cluster contains the remaining news sources that are general and only\nsometimes write about sports.\nThis clustering result is rather stable across different algorithms (k-means and\nagglomerativeclustering). Itisinterestingtonotethatsuchclusteringofnewssources\nthat differentiates theme and country of origin of news sources, emerges with merely\nnews sources sharing statistics on Reddit as their features.\n7.2.3 Big Scale: K-Means clustering for the entire dataset\nWe have seen that a reasonable clustering result of news sources emerges when we\nonly use their sharing statistics on Reddit as their representational features, at least\nif we are intentional about choosing which subreddits to include, like we do in the\nSmall Scale clustering section. In this section I investigate whether, when using all\nthe available subreddits as features, any meaningful clustering results of news sources\nwould emerge.\n72\nFor this big scale clustering task, I utilize the k-means clustering algorithm, with\nk-means++ initialization. However, even after tuning the hyperparameters of the\nclustering algorithm, the clustering results do not seem very significant. First of all,\nin choosing the appropriate number of clusters \ud835\udc58, the elbow method seems not to\nwork well. As shown in the Figure 7-8, there is no discernible elbow of the curve to\nbe found, as increasing the number of clusters from 2 to 100 results in a constant\ndecrease of the WGSS. In other words, it seems that there is no one optimal number\nof clusters that can be found using this method.\nFigure 7-8: Different WGSS values for different cluster sizes for the whole 2,647 news\nsource dataset with all 2,189 subreddits used in building their representations. There\nis no obvious elbow of the WGSS curve.\nAs a second attempt to find the optimal number of clusters, I also calculated the\nmean silhouette score values for all numbers of clusters between 2 to 100. As shown in\nFigure 7-9 shows that the highest silhouette coefficient value is achieved with \ud835\udc58= 28,\nwith silhouette coefficient value being 0.2 which is a rather low value. Although, in\ngeneral, these values are rather low in the scale of \u22121and1, I will investigate the\nclustering results for when \ud835\udc58= 28.\nLooking into the clustering results of the k-means algorithm with \ud835\udc58= 28, some\nclusters indeed have meaningful prominent characteristics, while some others do not.\n73\nFigure 7-9: Silhouette Coefficient values for different cluster sizes. The highest silhou-\nette coefficient value is achieved with k = 28, with silhouette coefficient value being\n0.2. However, in general these values are rather low.\nSimilarly, some clusters have rather high silhouette coefficient means, while others\nhave low means. Table A.1 in Appendix A describes prominent characteristics found\nin each cluster, if any, as well as silhouette coefficient means for the different 28\nclusters, while Figure 7-10 presents the different silhouette coefficients of the members\nof each of the clusters. It is interesting to note how news sources specific to some\nregions, themes, or ideology come to be clustered together using Reddit audience-\nbased metrics. The criterion that news sources in the same cluster share is different\nacross clusters, and that the groups within that criterion do not all appear to have\ntheir own clusters. For example, there is one cluster of far-right news sources, but no\ncluster of far-left news sources. There is one cluster of TV-based news sources, but\nno cluster of podcasts.\nOverall, based on their silhouette coefficient values, we see that some clusters\nare well defined while others are not. The low quality and interpretability of the\nclustering results could be due to either the lack of natural clustering of news sources\nusing this representation method, or due to the need of further data processing before\nclustering.\n74\nFigure 7-10: Silhouette coefficient values of news source data points in the 28 different\nclusters. The red lines separate the different clusters. Some clusters have reasonably\ngood silhouette coefficients while some others have low and therefore bad silhouette\ncoefficient values.\n7.2.4 Clustering Conclusions and Challenges\nUsing the silhouette coefficient metric, we see that small-scale clustering using pre-\ndetermined subreddits to build news source representations lead to better clustering\nquality compared to clustering results using all of the available subreddits. How-\never, for both cases, the results are not perfectly interpretable, since, for example, in\nboth cases the majority of the news sources being considered are clustered into one\nbig cluster which indicates lack of natural clustering structure for most of the data\npoints. Even so, some clusters with high silhouette coefficient values, indicate that\nsome news sources are indeed close together in the space built based on their Reddit\nsharing statistics as their features. This could serve as a measure of news source sim-\nilarity, where the notion of similarity takes the form of different characteristics such\nas country of origin, media type, political leaning, and others. Perhaps with more\ninformation incorporated into their representations, a better clustering of the news\nsources can be achieved. This information could include, for example, the sharing\nfrequency of these news sources in the comment section, the text-based information\n75\nprovided in the actual submissions and comments on Reddit as well as the subreddit\ndescriptions.\n7.3 Building Classifier: A Small Case Study\nAnother way to see whether we would be able to infer some specific characteristics of\nnews sources (such as reliability, country of origin, political leaning, and media type)\nusingthe300-dimensionalrepresentationaspresentedinthisthesis, isbyinvestigating\nwhether, for a particular characteristic, we can build a model based on some labeled\nnews sources to predict the label of the unlabelled ones. It turns out that a simple\nclassification model can be built to predict particular characteristics, but not others.\nIn this section I focus on two characteristics: country of origin and reliability.\nThe first characteristic that I focus on is country of origin. Using Wikidata15, I\nlabeled the news sources based on which country they are based in, and extracted\n114 news sources that are based on one of the three countries Australia, France, and\nGermany. These three countries are chosen because based on the three dimensional\nrepresentation of news sources built using t-SNE in the Visual Investigation section,\nthey are reasonably well separated as seen in Figure 7-11, and they have a rather\nbalanced number of news sources within each group (28 news sources from France,\n35 news sources from Germany, and 51 news sources from Australia).\nAs a result, I was able to build a Support Vector Machine multiclass classifier that\ncan classify these news sources based on their country of origin of three possibilities\n(Australia, France, and Germany) with 74% accuracy, with ROC AUC of 0.96. Al-\nthough not extremely high, this accuracy is considerably higher than chance. The\nhigh ROC AUC (which computes the AUC of each class against the rest, also known\nas one-vs-rest, as implemented by sklearn16indicates that the model has a reasonably\ngood predictive power. Note that I built this model using the first 20 principal com-\nponents of the news source features, which cumulatively explain 40% of the feature\n15https://www.wikidata.org/wiki/Wikidata:Main_Page\n16https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n76\nvariance. I found that using the first 20 principal components results in a better\nclassification result, compared to if I further reduce the 300 principal components I\nhave been using for analysis down to 20 features.\nFigure 7-11: The three dimensional visualization of news sources based in Australia,\nFrance, and Germany seem to be well (although not perfectly) separated. The green\ndots represent Germany-based news sources, the purple dots represent France-based\nnews sources, and the red dots represent Australia-based news sources.\nHowever, for other characteristics such as reliability, building a predictive model\nis not as straightforward. With Media Bias Fact Check17as the source of credibility\nlabels, the models that I have come up with have not been particularly useful in\npredicting whether news sources are reliable or not using the representation method\noutlined in this thesis. The various models I built (using various regression and tree\n17https://mediabiasfactcheck.com/\n77\nbased models) have very low accuracies of <=50%, which is no better than chance.\nThere are a couple possible reasons for the poor performing model for news source\nreliability prediction. The first one is that perhaps further feature engineering and\nmore complex models are needed to use this type of news source representation to\nbuild a model to classify and predict news source reliability. The second possible\nreason is that it is simply hard if not impossible to infer the reliability of most news\nsources by only looking at their audience-based metrics. Previous research projects\non news reliability/credibility have instead focused on the news article level [40, 19],\ninstead of news source level as in this thesis. Different articles published by the same\nnews source can have different reliability/credibility thus it might make more sense\nto infer this quality in a more granular news article level.\nAt least based on this small case study, it is interesting to note how particular\ncharacteristics such as country of origin (for specific countries) is much easier to pre-\ndict than other characteristics such as reliability, using the representational method\nbuilt based on Reddit audience sharing metrics. Further studies could look into the\ngoodness of models that can be built for the multiclass classification task including\nall the possible countries, and classification tasks for other characteristics such as\npolitical leaning or media type.\n78\nChapter 8\nConclusion and Future Work\n8.1 Conclusion\nBy visualizing the representations of the gm_intersection news sources built using\ntheir Reddit audience-based metrics, I find that the news sources that are close to-\ngether in the representational space indeed have some \u201csimilar\u201d characteristics, al-\nthough the notion of similar is different from one neighborhood of news sources to\nanother. Some news sources that are closer together are based in the same coun-\ntries, while others that are closer together have a shared theme, yet others are closer\ntogether with shared political leanings or reliability. Therefore, for unlabeled news\nsources, one can potentially observe where they are located in the representational\nspace built with the Reddit audience-based metrics as outlined in this thesis, and infer\nparticular characteristics of those unlabeled news sources by looking at the neighbor-\ning news sources.\nIn addition to visual examination of the representations of the news sources, I also\nattempt to cluster them together using their Reddit audience-based sharing statistics.\nAlthough imperfect, the clustering results suggest that particular news source char-\nacteristics such as country of origin and some specific themes are prominent features\nthatgiverisetoclusterstructuresthatareeasiertoidentifyusingk-meansalgorithms,\nthan other features. Similarly, a small case study to build a simple classifier suggests\nthat building a classifier for predictive tasks is easier accomplished for some features\n79\nthan others.\nIn conclusion, there is some evidence that Reddit audience sharing statistics alone\ncan be used in inferring some characteristics of news sources. Even a simple explo-\nration of comparing the total sharing frequency of a news source and the number\nof subreddits mentioning those news sources leads to interesting insights about news\nsource popularity and the broadness of their audience, as shown in the Exploring\nNews Sources section. However, more work needs to be done to further engineer or\nimprove these features and potentially build models to predict these characteristics\nfor unlabelled news sources.\n8.2 Future Work\nIn this section, I will go over things that can be improved on and various methods\nthat can be implemented to further the analysis in this thesis.\nFirst of all, I excluded many news sources because they were infrequently shared\nin the dataset I utilized. Using more Reddit data, instead of only from January to\nJune 2021 as in this thesis, could provide more data points for these news sources,\nallowing them to be included meaningfully in the analysis. Further analysis should\nalso be done to investigate what kinds of news sources are shared so infrequently\non Reddit and if they are different from the more popular news sources in any way.\nMoreover, through the data exploration, I found that there are a lot of blogs and\npodcasts being considered as news sources by both GDELT and Muck Rack. Further\nstudies should investigate the relevance of these user-generated content hosts in the\nonline news ecosystem.\nSecond, more information from Reddit could be included in building audience-\nbased news source representations. For example, recall that each Reddit user has\ntheir own Karma score, which is potentially useful information. This thesis aggre-\ngates user engagement with news sources by only looking at specific subsets of users.\nFuture work can directly measure audience engagement by considering different users\nseparately. Additionally, according to Glenski et al., most people do not read an\n80\narticle prior to voting [17] and according to Morrison, Reddit users are not all equally\nlikelytovoteonsubmissionsandcomments[28], thus, adifferentwayofincorporating\nvoting information could be considered to take these findings into account. Moreover,\nthis thesis also only considers the submissions on Reddit that contain news source\nlinks. Future work could also consider comments that contain news source links (in-\nstead of just counting comments per post without investigating the content of those\ncomments). Last but not least, this thesis does not make use of various text-based in-\nformation from Reddit, such as the actual submission texts, user profile descriptions,\nand subreddit descriptions. Various NLP techniques could be used to incorporate\nthese.\nThird, in terms of analysis, several other methods should be employed for further\nanalysis. Forexample, forfurtherprocessingnewssourcefeatures, includingtoreduce\nthe feature space dimensions, more complex methods could be used. In this thesis I\nmainly use PCA, which is a linear dimensionality reduction technique, however non-\nlinear dimensionality reduction techniques should also be considered. In this thesis, I\nuse one such non-linear dimensionality reduction technique, which is t-SNE. However,\nunlike PCA, t-SNE is intended solely for visualization, not for data preprocessing\n[41]. Another non-linear dimensionality reduction technique worth considering is an\nautoencoder, which is a type of neural network (with non-linear activation functions)\nthat aims to meaningfully encode input vectors into a lower dimensional latent space,\nand decode it back to a reconstructed input such that it is as similar as possible as the\noriginal input [3]. Mean Squared Error (MSE) is the common loss criterion used to\ntrain autoencoders. The lower the loss, the more similar the input and reconstructed\ninput are. In fact, I have attempted to implement one myself for this thesis, using the\npytorchframework,whichisanopensourcemachinelearningframework1,resultingin\nan autoencoder with low reconstruction MSE error (0.0013). However, the resulting\nlatent representations did not yield useful results in the clustering or classification\ntasks, thus I conclude that more work needs to be done to build a useful auto-encoder\nmodel for this task.\n1https://pytorch.org/\n81\nFurthermore, for clustering tasks, other clustering algorithms could be used to\ndetect emerging news source cluster structure. In particular, I have only considered\nhard-clustering which assigns each point to exactly one cluster, yet soft-clustering\nsuch as fuzzy clustering2that assigns probabilities to points belonging to each of the\ndifferent clusters could also be considered. In terms of k-means clustering itself, a\nvariant called weighted k-means that specifically caters to sparse data [21] could also\nbe considered. Yet another clustering algorithm that should be considered in future\nworks is model-based clustering. Landau et al. point out that even though there are\nnot much objections to the use of k-means or agglomerative clustering, model-based\nclustering is the one that would give most persuasive results (at least to statisticians)\nin terms of formal inference [24].\nLastly, a method of analysis that should be utilized is analysis using network\nscience. Recall that I represent news sources using their sharing statistics in Reddit\nin a data frame or matrix where each row records one news source while one or\nmultiple columns record the news source\u2019s sharing statistic in one subreddit. We\ncan frame this problem using a graph data structure where the nodes represent news\nsources, and the edges between news sources represent their connection in terms of\nbeing shared in the same subreddit(s). The weights of the edges would depend on the\nnumber of common subreddits a pair of news sources are shared in, and the similarity\nof their sharing frequencies. The size of the nodes could be used to represent the\npopularity of news sources across subreddits. There are two ways of building such a\ngraph: by directly building the graph as described above with a manually determined\nedge weight, or by first building a bipartite graph and projecting it down to such\na graph as described above. In the case of the bipartite graph, there would be two\ntypes of nodes: one representing news sources, and the other representing subreddits.\nEdges would only exist between the two different types of nodes and not among the\nsame type. This bipartite graph could then be projected down to the final graph as\ndescribed above.\nIn fact, I have spent some time going in the direction of network analysis in this\n2https://pythonhosted.org/scikit-fuzzy/auto_examples/plot_cmeans.html\n82\nthesis, although eventually not pursuing it further due to limited time. Figure 8-1, for\nexample, shows a preliminary graph I built using only the top 200 subreddits ranked\nby the number of their subscribers. The size of the nodes is scaled to represent the\nnumber of total mentions of the associated news sources (the more a news source\nis shared then the bigger the node used to represent it), while the width of the\nedges represents the strength of connection or similarity between two news sources\ncalculated using the number of common subreddits they appear together and the\nsimilarity of their sharing frequencies.\nFigure 8-1: A preliminary graph built using only the top 200 subreddits ranked by the\nnumber of their subscribers. The size of the nodes is scaled to represent the number of\ntotal mentions of the associated news sources , while the width of the edges represents\nthe strength of connection or similarity between two news sources calculated using\nthe number of common subreddits they appear together and the similarity of their\nsharing frequencies.\nUsing such a representation, one can gain insights about the news sources that are\nsimilar to each other by investigating the ego-centric graph of each of the nodes, the\npopularity of news sources by investigating the size of the nodes and their degrees,\nand other insights. This is a promising direction for future research.\n83\nAppendix A\nBig Scale Clustering Result\nCluster Prominent CharacteristicsSilhouette\nCoefficient%news source\nin the cluster\n1Canada-based news sources (e.g. torontosun.com,\ntoronto.ctvnews.ca, citynews.ca, calgaryherald.com,\ncbc.ca, etc.)0.33 1.7%\n2 - 0.36 35.4%\n3 - -0.03 2.1%\n4India-based news sources (e.g. theprint.in,\nbusinesstoday.in, thewire.in, thehindu.com,\nnationalheraldindia.com, etc.)0.56 1.6%\n5 - -0.04 8.6%\n6News sources from various countries in\nEurope (e.g. greekreporter.com, thefirstnews.com,\nnotesfrompoland.com, lrt.lt, politico.eu,\nintellinews.com, etc.)0.17 1.1%\n7 - 0.12 2.9%\n8Technology-related news sources\n(e.g. pcworld.com, arstechnica.com,\ngeekwire.com, techspot.com, acm.org, etc.)0.04 2.9%\n84\nCluster Prominent CharacteristicsSilhouette\nCoefficient%news source\nin the cluster\n9Comics, fantasy, and movies related\nnews sources (e.g. variety.com, tor.com,\nlooper.com, wegotthiscovered.com,\new.com, etc.)0.19 1.9%\n10Game related news sources\n(e.g. nintendoeverything.com, kotaku.com,\ngematsu.com, altchar.com, dsogaming.com, etc.)0.41 1.8%\n11TV-stations (e.g. wgrz.com, 14news.com,\ntmj4.com, wane.com, cheknews.ca, etc.)-0.02 6.9%\n12Cars and clean energy related news sources\n(e.g. teslarati.com, rechargenews.com,\ngreencarcongress.com, caranddriver.com,\nelectrive.com)0.26 1.6%\n13Far-right and unreliable news sources\n(e.g. redstate.com, theamericanconservative.com,\ntheepochtimes.com, oann.com, lifesitenews.com, etc.)0.33 2.0%\n14 - -0.14 8.3%\n15Cryptocurrency and fintech related news sources\n(e.g. cryptonews.com, blockonomi.com,\nethereumworldnews.com, cointelegraph.com,\ncoinspeaker.com, etc.)0.40 1.6%\n16Stock market and investment related news sources\n(e.g. nasdaq.com, investorplace.com, morningstar.com,\nsimplywall.st, benzinga.com, etc.)0.21 1.5%\n17France-based and French-languages news sources\n(e.g. lemonde.fr, lefigaro.fr, journaldemontreal.com,\narte.tv, radio-canada.ca, etc.)0.53 0.9%\n85\nCluster Prominent CharacteristicsSilhouette\nCoefficient%news source\nin the cluster\n18Academia-related sites and publications\n(e.g. nature.com, psychologytoday.com,\nwiley.com, sciencedirect.com, bmj.com, etc.)0.16 2.0%\n19Asia-based news sources (e.g. yna.co.kr,\nnhk.or.jp, taiwannews.com.tw,\nchinadaily.com.cn, coconuts.co, etc.)0.03 2.2%\n20Texas-based news sources\n(e.g. houstonchronicle.com, cbsaustin.com,\nculturemap.com, dallasobserver.com,\ndmagazine.com, etc.)0.32 1.3%\n21Science-related news sources\nespecially magazines (e.g. popularmechanics.com,\ninverse.com, ecowatch.com,\ndiscovermagazine.com, aeon.co, etc.)0.13 2.2%\n22News sources based in or about the\nmiddle east region and Russia\n(e.g. aljazeera.com, israelhayom.com,\nal-monitor.com, palestinechronicle.com,\nrt.com, etc.)0.10 2.3%\n23Florida-based news sources\n(e.g. nbcmiami.com, miamiherald.com,\nfloridapolitics.com, orlandoweekly.com,\nsun-sentinel.com, etc.)0.37 1.2%\n24Massachusetts (mainly Boston) based\nnews sources (e.g. nbcboston.com,\nbostonglobe.com, wbur.org, masslive.com,\ncapecodtimes.com, etc.)0.41 0.8%\n86\nCluster Prominent CharacteristicsSilhouette\nCoefficient%news source\nin the cluster\n25Germany-based news sources\n(e.g. spiegel.de, zeit.de,\nberliner-zeitung.de, tagesspiegel.de,\nfocus.de, etc.)0.57 1.1%\n26Defense and military related\nnews sources (e.g. armytimes.com,\ndefensenews.com, taskandpurpose.com,\nairforcemag.com, stripes.com, etc.)0.31 1.0%\n27United Kingdom based news sources\n(e.g. telegraph.co.uk, theathletic.com,\nbbc.co.uk, mirror.co.uk,\nbelfasttelegraph.co.uk, etc.)0.12 1.4%\n28 - 0.17 1.4%\nTable A.1: Prominent characteristics found in each clus-\nter, if any, as well as silhouette coefficient means for the\ndifferent28clustersfoundusingk-meansclusteringofthe\nwhole dataset.\n87\nAppendix B\nManually Removed Sites\namazon.com quora.com home.blog\nwordpress.com chase.com archive.org\namazonaws.com wattpad.com herokuapp.com\nbit.ly t.co mystrikingly.com\nimgur.com gofundme.com xda-developers.com\nsoundcloud.com paypal.com redbubble.com\nfacebook.com telegra.ph artstation.com\nspotify.com googleapis.com teespring.com\nvimeo.com web.app notion.so\ngoodreads.com octopus.energy substack.com\ngoo.gl shopify.com over-blog.com\nyoutube.com playstation.com cloudfront.net\nt.me qualtrics.com steamcommunity.com\ngoogle.com naver.com bandcamp.com\ntwitter.com linkedin.com kicksonfire.com\ndiscord.com samsung.com discogs.com\npornhub.com walmart.com xvideos.com\namazon.co.uk netlify.app fangraphs.com\ndropbox.com android.com coingecko.com\n88\ntumblr.com wixsite.com podbean.com\netsy.com ikea.com trello.com\ngithub.com eventbrite.com bravesites.com\nmedium.com yahoo.com exercism.io\nebay.com weworkremotely.com bonhams.com\nimdb.com myspace.com food52.com\nblogspot.com instagram.com bookmyshow.com\npinterest.com myshopify.com withgoogle.com\npatreon.com whatsapp.com nucypher.com\nmicrosoft.com anchor.fm cpacanada.ca\ndeviantart.com nintendo.com hermanmiller.com\ntiktok.com homedepot.com haproxy.com\nnetflix.com audible.com pixelstech.net\ntowardsdatascience.com asus.com line.me\nsquarespace.com merriam-webster.com tripsavvy.com\ngoogleusercontent.com intel.com trivago.com\nwebmd.com leagueoflegends.com wikipedia.org\nyahoo.com nike.com wikimedia.org\nadobe.com discordapp.com wikiquote.org\napple.com blogger.com wikidot.com\nweebly.com office.com wikisource.org\nyahoo.co.jp itch.io cloudinary.com\nweibo.com lego.com wikitionary.org\nqq.com mailchi.mp fandom.com\ncrunchyroll.com go.com\namazon.de snapchat.com\n89\nTable B.1: A list of 133 sites I manually remove from my\ninitial set of news sources, because some of these sites are\nmoreappropriatelycategorizedasuser-generatedcontent\nhosts, and some others are not news related sites.\n90\nAppendix C\nExample of One NDJSON\nRepresentation of Reddit Submission\nThe following is an example of a NDJSON representation of a Reddit submission.\n{\n\u2019all_awardings \u2019: [] ,\n\u2019allow_live_comments \u2019: False ,\n\u2019archived \u2019: False ,\n\u2019author \u2019: \u2019elanglohablante9805 \u2019 ,\n\u2019author_created_utc \u2019: 1609519842,\n\u2019author_flair_background_color \u2019: \u2019#ffb000 \u2019 ,\n\u2019author_flair_css_class \u2019: None,\n\u2019author_flair_richtext \u2019: [] ,\n\u2019author_flair_template_id \u2019: \u20194f908eaa \u22129664\u221211ea\u2212\na567\u22120ed46a42aec3 \u2019 ,\n\u2019author_flair_text \u2019: \u2019Historiador 80 \u2212Day Streak \u2019 ,\n\u2019author_flair_text_color \u2019: \u2019dark \u2019 ,\n\u2019author_flair_type \u2019: \u2019text \u2019 ,\n\u2019author_fullname \u2019: \u2019t2_9lr431i4 \u2019 ,\n\u2019author_patreon_flair \u2019: False ,\n91\n\u2019author_premium \u2019: False ,\n\u2019can_gild \u2019: True ,\n\u2019category \u2019: None,\n\u2019content_categories \u2019: None,\n\u2019contest_mode \u2019: False ,\n\u2019created_utc \u2019: 1617235201,\n\u2019discussion_type \u2019: None,\n\u2019distinguished \u2019: None,\n\u2019domain \u2019: \u2019 self .WriteStreakES \u2019 ,\n\u2019edited \u2019: False ,\n\u2019gilded \u2019: 0,\n\u2019 gildings \u2019: {},\n\u2019hidden \u2019: False ,\n\u2019hide_score \u2019: False ,\n\u2019id \u2019: \u2019mhj2hj \u2019 ,\n\u2019is_created_from_ads_ui \u2019: False ,\n\u2019is_crosspostable \u2019: True ,\n\u2019is_meta \u2019: False ,\n\u2019is_original_content \u2019: False ,\n\u2019is_reddit_media_domain \u2019: False ,\n\u2019is_robot_indexable \u2019: True ,\n\u2019 is_self \u2019: True ,\n\u2019is_video \u2019: False ,\n\u2019link_flair_background_color \u2019: \u2019 \u2019 ,\n\u2019link_flair_css_class \u2019: None,\n\u2019 link_flair_richtext \u2019: [] ,\n\u2019link_flair_text \u2019: None,\n\u2019link_flair_text_color \u2019: \u2019dark \u2019 ,\n\u2019link_flair_type \u2019: \u2019text \u2019 ,\n\u2019locked \u2019: False ,\n92\n\u2019media \u2019: None,\n\u2019media_embed \u2019: {},\n\u2019media_only \u2019: False ,\n\u2019name\u2019: \u2019t3_mhj2hj \u2019 ,\n\u2019no_follow \u2019: True ,\n\u2019num_comments\u2019: 2,\n\u2019num_crossposts \u2019: 0,\n\u2019over_18 \u2019: False ,\n\u2019parent_whitelist_status \u2019: None,\n\u2019permalink \u2019: \u2019/r/WriteStreakES/comments/\nmhj2hj/streak_90_ha_llegado_la_primavera/\u2019,\n\u2019pinned \u2019: False ,\n\u2019pwls \u2019: None,\n\u2019quarantine \u2019: False ,\n\u2019removed_by_category \u2019: None,\n\u2019retrieved_utc \u2019: 1623447663,\n\u2019score \u2019: 1,\n\u2019secure_media \u2019: None,\n\u2019secure_media_embed \u2019: {},\n\u2019 selftext \u2019: \u2019Los p jaros est n cantando , las hierbas\nverdes est n brotando , y tengo alergias .\nEsto es la temporada de las alergias .\nEstornudo cada ma ana cuando me despierto , y\notra vez si voy afuera . Necesito tomar\nmedicina cada d a , pero no funciona tan bien .\n\\n\\nPor fuera , las lomas son bonitas porque\nson verdes y los robles tienen hojas nuevas .\nPor el fin de semana , hago caminatas pero\ncuando regreso a casa , necesito ducharme para\nremover el polen .\\n\\nCuando me jubile , voy a\n93\nviajar al desierto cada a o por toda la\nprimavera . No me gustar a quedarme aqu . \u2019 ,\n\u2019send_replies \u2019: True ,\n\u2019 spoiler \u2019: False ,\n\u2019 stickied \u2019: False ,\n\u2019subreddit \u2019: \u2019WriteStreakES \u2019 ,\n\u2019subreddit_id \u2019: \u2019t5_2eamt5 \u2019 ,\n\u2019subreddit_subscribers \u2019: 2205,\n\u2019subreddit_type \u2019: \u2019public \u2019 ,\n\u2019suggested_sort \u2019: None,\n\u2019thumbnail \u2019: \u2019 self \u2019 ,\n\u2019thumbnail_height \u2019: None,\n\u2019thumbnail_width \u2019: None,\n\u2019 title \u2019: \u2019Streak 90: Ha llegado la primavera \u2019 ,\n\u2019top_awarded_type \u2019: None,\n\u2019total_awards_received \u2019: 0,\n\u2019treatment_tags \u2019: [] ,\n\u2019upvote_ratio \u2019: 1.0 ,\n\u2019url \u2019: \u2019https ://www. reddit .com/r/\nWriteStreakES/comments/mhj2hj/\nstreak_90_ha_llegado_la_primavera/\u2019,\n\u2019whitelist_status \u2019: None, \u2019wls \u2019: None}\n94\nAppendix D\nCode Repository\nThe code I wrote to complete this thesis can be found in this GitHub repository:\nhttps://github.com/jsirait/honor_thesis\n95\nBibliography\n[1] Eytan Bakshy, Solomon Messing, and Lada A Adamic. Exposure to ideologically\ndiverse news and opinion on facebook. Science, 348(6239):1130\u20131132, 2015.\n[2] Ramy Baly, Georgi Karadzhov, Dimitar Alexandrov, James Glass, and Preslav\nNakov. Predicting factuality of reporting and bias of news media sources. arXiv\npreprint arXiv:1810.01765 , 2018.\n[3] Dor Bank, Noam Koenigstein, and Raja Giryes. Autoencoders. arXiv preprint\narXiv:2003.05991 , 2020.\n[4] Joana M Barros, Paul Buitelaar, Jim Duggan, and Dietrich Rebholz-Schuhmann.\nUnsupervised classification of health content on reddit. In Proceedings of the 9th\nInternational Conference on Digital Public Health , pages 85\u201389, 2019.\n[5] Daniel A Bowen, Julie O\u2019Donnell, and Steven A Sumner. Increases in on-\nline posts about synthetic opioids preceding increases in synthetic opioid death\nrates: a retrospective observational study. Journal of general internal medicine ,\n34(12):2702\u20132704, 2019.\n[6] EshwarChandrasekharan, MattiaSamory, ShagunJhaver, HunterCharvat, Amy\nBruckman, Cliff Lampe, Jacob Eisenstein, and Eric Gilbert. The internet\u2019s\nhidden rules: An empirical study of reddit norm violations at micro, meso,\nand macro scales. Proceedings of the ACM on Human-Computer Interaction ,\n2(CSCW):1\u201325, 2018.\n[7] Usman W Chohan. Counter-hegemonic finance: The gamestop short squeeze.\nAvailable at SSRN 3775127 , 2021.\n[8] NicolaDanieleConiglio, VitoroccoPeragine, andDavideVurchio. Thegeography\nof displacement, refugees\u2019 camps and social conflicts. 2022.\n[9] Brent D Davis, Dawn Estes McKnight, Rumi Chunara, Daniel J Lizotte, and\nAlona Fyshe. Quantifying depressed social media during covid-19: Information\nretrieval with ml & nlp. 2020.\n[10] Munmun De Choudhury and Sushovan De. Mental health discourse on reddit:\nSelf-disclosure, social support, and anonymity. In Eighth international AAAI\nconference on weblogs and social media , 2014.\n96\n[11] Daniel Defays. An efficient algorithm for a complete link method. The Computer\nJournal, 20(4):364\u2013366, 1977.\n[12] Venkatesh Duppada. \u201cattention\u201d for detecting unreliable news in the informa-\ntion age. In Workshops at the Thirty-Second AAAI Conference on Artificial\nIntelligence , 2018.\n[13] William H Dutton, Bianca Reisdorf, Elizabeth Dubois, and Grant Blank. Search\nand politics: The uses and impacts of search in britain, france, germany, italy,\npoland, spain, and the united states. 2017.\n[14] William H Dutton, Bianca Christin Reisdorf, Elizabeth Dubois, and Grant\nBlank. Search and politics: A cross-national survey.(2017). 2017.\n[15] Brian Everitt and Torsten Hothorn. An introduction to applied multivariate\nanalysis with R . Springer Science & Business Media, 2011.\n[16] Michael Fire and Carlos Guestrin. The rise and fall of network stars: Ana-\nlyzing 2.5 million graphs to reveal how high-degree vertices emerge over time.\nInformation Processing & Management , 57(2):102041, 2020.\n[17] Maria Glenski, Corey Pennycuff, and Tim Weninger. Consumers and curators:\nBrowsing and voting patterns on reddit. IEEE Transactions on Computational\nSocial Systems , 4(4):196\u2013206, 2017.\n[18] Mauricio Gruppi, Benjamin D Horne, and Sibel Adali. An exploration of unre-\nliable news classification in brazil and the us. arXiv preprint arXiv:1806.02875 ,\n2018.\n[19] Priyanka Harjule, Akshat Sharma, Sachin Chouhan, and Shashank Joshi. Reli-\nability of news. In 2020 3rd International Conference on Emerging Technologies\nin Computer Engineering: Machine Learning and Internet of Things (ICETCE) ,\npages 165\u2013170. IEEE, 2020.\n[20] JCraigJenkinsandThomasVMaher. Whatshouldwedoaboutsourceselection\nin event data? challenges, progress, and possible solutions. International Journal\nof Sociology , 46(1):42\u201357, 2016.\n[21] Liping Jing, Michael K Ng, and Joshua Zhexue Huang. An entropy weighting k-\nmeans algorithm for subspace clustering of high-dimensional sparse data. IEEE\nTransactions on knowledge and data engineering , 19(8):1026\u20131041, 2007.\n[22] Igor Kotenko, Yash Sharma, and Alexander Branitskiy. Predicting the mental\nstate of the social network users based on the latent dirichlet allocation and fast-\ntext. In2021 11th IEEE International Conference on Intelligent Data Acquisition\nand Advanced Computing Systems: Technology and Applications (IDAACS) , vol-\nume 1, pages 191\u2013195. IEEE, 2021.\n97\n[23] Navin Kumar, Isabel Corpus, Meher Hans, Nikhil Harle, Nan Yang, Curtis Mc-\nDonald, Shinpei Nakamura Sakai, Kamila Janmohamed, Keyu Chen, Frederick L\nAltice, et al. Covid-19 vaccine perceptions in the initial phases of us vaccine roll-\nout: An observational study on reddit. 2022.\n[24] Sabine Landau, Morven Leese, Daniel Stahl, and Brian S Everitt. Cluster anal-\nysis, section 6.5, page 185. John Wiley & Sons, 2011.\n[25] Kalev Leetaru and Philip A Schrodt. Gdelt: Global data on events, location,\nand tone, 1979\u20132012. In ISA annual convention , volume 2, pages 1\u201349. Citeseer,\n2013.\n[26] Yang Liu, Christopher Whitfield, Tianyang Zhang, Amanda Hauser, Taeyonn\nReynolds, and Mohd Anwar. Monitoring covid-19 pandemic through the lens\nof social media using natural language processing and machine learning. Health\nInformation Science and Systems , 9(1):1\u201316, 2021.\n[27] Pin Luarn and Ai-Yun Hsieh. Speech or silence: the effect of user anonymity and\nmember familiarity on the willingness to express opinions in virtual communities.\nOnline Information Review , 2014.\n[28] Donn Morrison and Conor Hayes. Here, have an upvote: Communication be-\nhaviour and karma on reddit. INFORMATIK 2013\u2013Informatik angepasst an\nMensch, Organisation und Umwelt , 2013.\n[29] Narjisse Nejjari, Sara Lahlou, Oumaima Fadi, Karim Zkik, Mustapha Oudani,\nand Houda Benbrahim. Conflict spectrum: An empirical study of geopolitical\ncyber threats from a social network perspective. In 2021 Eighth International\nConference on Social Network Analysis, Management and Security (SNAMS) ,\npages 01\u201307. IEEE, 2021.\n[30] Orestis Papakyriakopoulos, Juan Carlos Medina Serrano, and Simon Hegelich.\nThe spread of covid-19 conspiracy theories on social media and the effect of con-\ntent moderation. The Harvard Kennedy School (HKS) Misinformation Review ,\n18, 2020.\n[31] Rachel Parks, Emily C Newsom, Joyce H Park, and Naomi Lawrence. Skincare\naddiction on reddit: dermatology enthusiasts talk skin. Dermatologic Surgery ,\n46(10):1372\u20131374, 2020.\n[32] Gordon Pennycook and David G Rand. Fighting misinformation on social media\nusingcrowdsourcedjudgmentsofnewssourcequality. Proceedings of the National\nAcademy of Sciences , 116(7):2521\u20132526, 2019.\n[33] Fengcai Qiao, Pei Li, Xin Zhang, Zhaoyun Ding, Jiajun Cheng, and Hui Wang.\nPredicting social unrest events with hidden markov models using gdelt. Discrete\nDynamics in Nature and Society , 2017, 2017.\n98\n[34] Ronald E Robertson, Shan Jiang, Kenneth Joseph, Lisa Friedland, David Lazer,\nand Christo Wilson. Auditing partisan audience bias within google search. Pro-\nceedings of the ACM on Human-Computer Interaction , 2(CSCW):1\u201322, 2018.\n[35] Stephen Roller, Sainbayar Sukhbaatar, Jason Weston, et al. Hash layers for large\nsparse models. Advances in Neural Information Processing Systems , 34, 2021.\n[36] Peter J Rousseeuw. Silhouettes: a graphical aid to the interpretation and val-\nidation of cluster analysis. Journal of computational and applied mathematics ,\n20:53\u201365, 1987.\n[37] Mattia Samory, Vartan Kesiz Abnousi, and Tanushree Mitra. Characterizing the\nsocial media news sphere through user co-sharing practices. In Proceedings of\nthe International AAAI Conference on Web and Social Media , volume 14, pages\n602\u2013613, 2020.\n[38] Vinay Setty and Erlend Rekve. Truth be told: Fake news detection using user\nreactions on reddit. In Proceedings of the 29th ACM International Conference\non Information & Knowledge Management , pages 3325\u20133328, 2020.\n[39] Robin Sibson. Slink: an optimally efficient algorithm for the single-link cluster\nmethod. The computer journal , 16(1):30\u201334, 1973.\n[40] Francesca Spezzano, Anu Shrestha, Jerry Alan Fails, and Brian W Stone. That\u2019s\nfake news! reliability of news when provided title, image, source bias & full\narticle.Proceedings of the ACM on Human-Computer Interaction , 5(CSCW1):1\u2013\n19, 2021.\n[41] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne.\nJournal of machine learning research , 9(11), 2008.\n[42] Sergei Vassilvitskii and David Arthur. k-means++: The advantages of care-\nful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on\nDiscrete algorithms , pages 1027\u20131035, 2006.\n[43] VeniaminVeselovsky, IsaacWaller, andAshtonAnderson. Imagineallthepeople:\nCharacterizing social music sharing on reddit. In Proceedings of the International\nAAAI Conference on Web and Social Media , volume 15, pages 739\u2013750, 2021.\n[44] Yuping Wang, Savvas Zannettou, Jeremy Blackburn, Barry Bradlyn, Emiliano\nDe Cristofaro, and Gianluca Stringhini. A multi-platform analysis of political\nnews discussion and sharing on web communities. In 2021 IEEE International\nConference on Big Data (Big Data) , pages 1481\u20131492. IEEE, 2021.\n[45] Savvas Zannettou, Tristan Caulfield, Emiliano De Cristofaro, Nicolas Kourtelris,\nIlias Leontiadis, Michael Sirivianos, Gianluca Stringhini, and Jeremy Blackburn.\nThe web centipede: understanding how web communities influence each other\nthrough the lens of mainstream and alternative news sources. In Proceedings of\nthe 2017 internet measurement conference , pages 405\u2013417, 2017.\n99", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Investigating News Source Characterizations using Reddit Audience-based Metrics", "author": ["J Sirait"], "pub_year": "2022", "venue": "NA", "abstract": "In this digital age, there is an abundance of news sources, with no one database that  characterizes the whole set of news sources. It is a difficult task to provide a meaningful summary"}, "filled": false, "gsrank": 741, "pub_url": "https://repository.wellesley.edu/_flysystem/fedora/2023-11/WCTC_2022_SiraitJunita_InvestigatingNews.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:8s8g58HOLFoJ:scholar.google.com/&output=cite&scirp=740&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=8s8g58HOLFoJ&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 1, "citedby_url": "/scholar?cites=6497795694590480370&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:8s8g58HOLFoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://repository.wellesley.edu/_flysystem/fedora/2023-11/WCTC_2022_SiraitJunita_InvestigatingNews.pdf"}}, {"title": "COVID-19 infodemic on Facebook and containment measures in Italy, United Kingdom and New Zealand", "year": "2022", "pdf_data": "ZK[KF ZIN FZ\\OIS K\nIV^OJ/4= tzq{noytm {zLkmol{{v kzn\nm{ztktzyozt yok\u20acu~o\u20ac tzOtkwy. ]ztton\nRtzrn{y kzn Uow cokwkzn\nMkl~towo K\ufffd\ufffdk OJ\n4*.Fwo\ufffd\ufffdkzn~{ Mkwok\ufffd\ufffdt OJ\n5.Qkyto Zk\ufffd N\ufffd\ufffdmstzr\ufffd6.I{zz{~ [\ufffdt~wtzr Qkyo\ufffd\n[yt\ufffds6.Tk\ufffd~{ I{z\ufffdt7._kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{mmst4.Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk6\n4Ioz\ufffdo~ {qJk\ufffdk [mtozmo kznI{y|wo\ufffdt\ufffd\ufffd q{~[{mto\ufffd\ufffd. Jo|k~\ufffdy oz\ufffd{qI{y|\ufffd\ufffdo~ [mtozmo. [k|toz\ufffdk ]zt\ufffdo~\ufffd t\ufffd\u00e0\nntZ{yk. Z{yk .O\ufffdkw\ufffd. 5Jo|k~\ufffdy oz\ufffd{qKz\ufffdt~{zy oz\ufffdkw [mtozmo\ufffd. Ozq{~yk\ufffdtm\ufffd kzn[\ufffdk\ufffdt\ufffd\ufffdtm\ufffd. Ik)L{\ufffdmk~t\n]zt\ufffdo~\ufffdt\ufffd\ufffd {q^oztmo. ^oztmo. O\ufffdkw\ufffd. 6[ms{{w {qTk\ufffdsoyk\ufffd tm\ufffdkzn[\ufffdk\ufffdt\ufffd\ufffdtm\ufffd .]zt\ufffdo~\ufffdt\ufffd\ufffd {qIkz\ufffdo~l\ufffd~\ufffd .\nIkz\ufffdo~l\ufffd ~\ufffd.Uo\ufffd cokwkzn. 7Jo|k~\ufffdyoz\ufffd {qTk\ufffdsoyk\ufffdtm\ufffd .]zt\ufffdo~\ufffdt\ufffd\ufffd {qWkn{\ufffdk. Wkn{\ufffdk .O\ufffdkw\ufffd\n*}\ufffdk\ufffd\ufffd~{ mt{mmstEnt1\ufffd zt~{yk41t\ufffd\nFl\u20act~kmt\n\\so IV^OJ/4= |kznoytm sk\ufffdlooz msk~km\ufffdo~t\ufffdon l\ufffdk\ufffd{mtkw yontk \ufffdtzq{noytm\ufffd> kz{\ufffdo~/\nkl\ufffdznkzmo {qtzq{~yk\ufffdt{z \ufffds{\ufffdo k\ufffd\ufffdsoz\ufffdtmt\ufffd\ufffd yk\ufffd z{\ufffdkw\ufffdk\ufffd\ufffd lor\ufffdk~kz\ufffdoon1 _t\ufffds \ufffdso\n|{\ufffdoz\ufffdtkw \ufffd{wokn tznt\ufffdtn\ufffdkw\ufffd \ufffd{sk~yq\ufffdw nomt\ufffdt{z\ufffd q{~\ufffdso\ufffd{mto\ufffd\ufffd. \ufffdst\ufffdtzq{noytm ~o|~o\ufffdoz\ufffd\ufffd k\n\ufffdo\ufffdo~o \ufffds~ok\ufffd \ufffd{tzq{~yk\ufffdt{z \ufffdom\ufffd~t\ufffd\ufffd. |\ufffdlwtm sokw\ufffds kznnoy{m~km\ufffd1 Oz\ufffdst\ufffd|k|o~. \ufffdok\ufffd\ufffdo\ufffd\ufffd\n\ufffdsotz\ufffdo~|wk\ufffd lo\ufffd\ufffdooz \ufffdsotzq{noytm kzn\ufffd|omtqtm k\ufffd|om\ufffd\ufffd {q\ufffdso|kznoytm. \ufffd\ufffdms k\ufffd\ufffdsoz\ufffdy/\nlo~{qmk\ufffdo\ufffd. \ufffdso\ufffd\ufffd~tm\ufffdzo\ufffd\ufffd {qm{z\ufffdktzyoz\ufffd yok\ufffd\ufffd~o\ufffd. kzn\ufffdsozo\ufffd\ufffd yontk m{\ufffdo~kro1 _o\n|o~q{~y km{y|k~k\ufffdt\ufffd o\ufffd\ufffd\ufffdn\ufffd {z\ufffds~oo m{\ufffdz\ufffd~to\ufffd \ufffdsk\ufffdoy|w{\ufffdon ntqqo~oz\ufffd ykzkroyoz\ufffd \ufffd{q\n\ufffdsoIV^OJ/4= |kznoytm tz5353\u0152zkyow\ufffd O\ufffdkw\ufffd. \ufffdso]zt\ufffdon Rtzrn{y. kznUo\ufffd cokwkzn1 _o\nqt~\ufffd\ufffdkzkw\ufffd\ufffdo \ufffdso\ufffds~oo m{\ufffdz\ufffd~to\ufffd q~{y kzo|tnoyt{w{rtmkw |o~\ufffd|om\ufffdt\ufffdo \ufffd{msk~km\ufffdo~t\ufffdo \ufffdso\nty|km\ufffd {q\ufffdso|kznoytm kzn\ufffdso\ufffd\ufffd~tm\ufffdzo\ufffd\ufffd {q\ufffdso~o\ufffd\ufffd~tm\ufffdt{z\ufffd kn{|\ufffdon1 \\soz. \ufffdom{wwom\ufffd k\n\ufffd{\ufffdkw {q:ytwwt{z |{\ufffd\ufffd\ufffd q~{y Lkmol{{v \ufffd{no\ufffdm~tlo \ufffd\ufffdo~ zo\ufffd\ufffd m{z\ufffd\ufffdy|\ufffdt{z losk\ufffdt{~\ufffd \ufffdt\ufffds\n~o\ufffd|om\ufffd \ufffd{\ufffdso~owtkltwt\ufffd\ufffd {q\ufffd\ufffdms |{\ufffd\ufffd\ufffd1 Ltzkww\ufffd. \ufffdo}\ufffdkz\ufffdtq\ufffd \ufffdso~owk\ufffdt{z\ufffdst| lo\ufffd\ufffdooz \ufffdsoz\ufffdy/\nlo~{q|{\ufffd\ufffd\ufffd |\ufffdlwt\ufffdson tzokms {q\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\ufffd kzn\ufffdsoz\ufffdylo~ {qm{zqt~yon mk\ufffdo\ufffd. \ufffdso\n\ufffd\ufffd~tm\ufffdzo\ufffd\ufffd {q\ufffdso~o\ufffd\ufffd~tm\ufffdt{z\ufffd kn{|\ufffdon. kzn\ufffdso{zwtzo zo\ufffd\ufffd yontk m{\ufffdo~kro kl{\ufffd\ufffd \ufffdso|kz/\nnoytm1 V\ufffd~~o\ufffd\ufffdw\ufffd\ufffd \ufffds{\ufffd \ufffdsk\ufffd|{\ufffd\ufffd\ufffd ~oqo~~tzr \ufffd{~owtklwo \ufffd{\ufffd~mo\ufffd k~om{z\ufffdt\ufffd\ufffdoz\ufffdw\ufffd |~on{ytzkz\ufffd\ntz\ufffdsozo\ufffd\ufffd mt~m\ufffdwk\ufffdt{z. kzn\ufffdsk\ufffd\ufffd\ufffdo~\ufffd ozrkro y{~o \ufffdt\ufffds ~owtklwo |{\ufffd\ufffd\ufffd ~k\ufffdso~ \ufffdskz \ufffdt\ufffds\n|{\ufffd\ufffd\ufffd ~oqo~~tzr \ufffd{}\ufffdo\ufffd\ufffdt{zklwo \ufffd{\ufffd~mo\ufffd1 L\ufffd~\ufffdso~y{~o. {\ufffd~y{nowwtzr ~o\ufffd\ufffdw\ufffd\ufffd \ufffd\ufffdrro\ufffd\ufffd \ufffdsk\ufffdqkm/\n\ufffd{~\ufffd~owk\ufffdon \ufffd{\ufffdsoo|tnoyt{w{rtmkw kzntzq{~yk\ufffdt{zkw om{\ufffd\ufffd\ufffd\ufffdoy\ufffd mkz\ufffdo~\ufffdo k\ufffd|~{\ufffdto\ufffd \ufffd{\nk\ufffd\ufffdo\ufffd\ufffd \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdsotzq{noytm1\nOz\ufffd~{n\ufffdm\ufffdt{z\n\\so _{~wn Nokw\ufffds V~rkzt\u00fek\ufffdt{z *_NV+ nomwk~on IV^OJ/4= k\u20ack|kznoytm {zTk~ms 44.\n5353 d4f1\\{m{z\ufffd~k\u20ac\ufffd t\ufffd\u20ac\u20ac|~okntzr. r{\ufffdo~zyoz\ufffd\u20ac tz\ufffd~{n\ufffdmon k\u20aco~to\u20ac {qm{\ufffdz\ufffdo~yok\u20ac\ufffd~o\u20ac vz{\u00d0z\nk\u20acU{z/Wsk~ykmo\ufffd\ufffdtmkw/Oz\ufffdo~\ufffdoz\ufffdt{ z\u20ac*UWO\u20ac+ d5.6f>\ufffdsokn{|\ufffdt{z {qqkmoyk\u20acv\u20ac. }\ufffdk~kz\ufffdtzo\u20ac.\n\u20ac{mtkw nt\u20ac\ufffdkzmtzr. kzny{ltwt\ufffd\u00de wtyt\ufffdk\ufffdt{z\u20ac d7f1\\so |kznoytm kw\u20ac{ \u20ac|k~von kstrs zo\u00d0\u20ac \ufffd{w\ufffdyo\nPLOS ONE\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 4247k4444444444\nk4444444444\nk4444444444\nk4444444444\nk4444444444\nOPEN ACCESS\nIt\ufffdk\ufffdt{z> K\ufffd\ufffdkM.Mkwok\ufffd\ufffdt F.N\ufffd\ufffdmstzr\ufffd QZ.Qkyo\ufffd\n[yt\ufffds I[.I{z\ufffdt T.Y\ufffdk\ufffd\ufffd~{mt{m mst_.o\ufffdkw1*5355+\nIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffd\nyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{y kznUo\ufffd\ncokwkzn1 WS{[ VUK4;*9+> o35:;3551 s\ufffd\ufffd|\ufffd>22n{ t1\n{~r243146;4 2u{\ufffd~zkw1|{zo1 35:;355\nKnt\ufffd{~> T{skyon L1Qkww{s. Ioz\ufffdo~\ufffd q{~Jt\ufffdok\ufffdo\nI{z\ufffd~{w kznW~o\ufffdoz\ufffdt{z. ]UO\\KJ [\\F\\K[\nZomot\ufffdon> Qkz\ufffdk~\ufffd 5<.5355\nFmmo|\ufffdon> Tk~ms 64.5355\nW\ufffdlwt\ufffdson> Tk\ufffd4=.5355\nWoo~ Zo\ufffdto\ufffd Nt\ufffd\ufffd{~\ufffd> WSV[ ~om{rzt\ufffdo \ufffd\ufffdso\nlozoqt\ufffd\ufffd {q\ufffd~kz\ufffd|k~ ozm\ufffd tz\ufffdso|oo~ ~o\ufffdto\ufffd\n|~{mo\ufffd\ufffd? \ufffdso~oq{~o. \ufffdoozklwo \ufffdso|\ufffdlwtmk\ufffdt{z {q\nkww{q\ufffdsom{z\ufffdoz\ufffd {q|oo~ ~o\ufffdto\ufffd kznk\ufffd\ufffds{~\n~o\ufffd|{z\ufffdo \ufffdkw{zr\ufffdtno qtzkw. |\ufffdlwt\ufffdson k~\ufffdtmwo\ufffd1 \\so\nont\ufffd{~tkw st\ufffd\ufffd{~\ufffd {q\ufffdst\ufffdk~\ufffdtmwo t\ufffdk\ufffdktwklwo so~o>\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u{ \ufffd~zkw1|{zo13 5:;355\nI{|\ufffd~trs\ufffd> \u00a95355 K\ufffd\ufffdko\ufffdkw1\\st\ufffdt\ufffdkz{|oz kmmo\ufffd\ufffd\nk~\ufffdtmwo nt\ufffd\ufffd~tl\ufffd\ufffdon \ufffdzno~ \ufffdso\ufffdo~y\ufffd {q\ufffdsoI~ok\ufffdt\ufffdo\nI{yy{z\ufffd F\ufffd\ufffd~tl\ufffd\ufffdt {zStmoz\ufffdo. \ufffdstms |o~yt\ufffd\ufffd\n\ufffdz~o\ufffd\ufffd~tm\ufffdon \ufffd\ufffdo.nt\ufffd\ufffd~tl\ufffd\ufffdt{z .kzn~o|~{n\ufffdm\ufffdt{z tz\nkz\ufffdyont\ufffdy. |~{\ufffdtno n\ufffdso{~trtzkw k\ufffd\ufffds{~ kzn\n\ufffd{\ufffd~mo k~om~ont\ufffdon 1\nJk\ufffdk F\ufffdktwkltwt\ufffd \ufffd[\ufffdk\ufffdoyoz\ufffd> Jk\ufffdk mkzz{\ufffd lo\n\ufffdsk~on |\ufffdlwtmtw\ufffd lomk\ufffd\ufffdo \ufffdso\ufffd\ufffd\ufffdn\ufffd yktzw\ufffd ~owto\ufffd {z\nqkmol{{v |{\ufffd\ufffd\ufffd {l\ufffdktzon q~{y I~{\ufffdn\ufffdkzrwo \ufffdstms.\nk\ufffdt\ufffd\ufffd\ufffdk\ufffdo\ufffd tzs\ufffd\ufffd|\ufffd>22sow|1m~ {\ufffdn\ufffdkzrwo1 m{y2oz2\n{z\u20ac{mtkw yontk d9f.q\ufffd~\ufffdso~ tzm~ok\u20acon l\u00de\ufffdso\u20ac\ufffdk~\ufffd {q\ufffdso\ufffdkmmtzk\ufffdt{z mky|ktrz\u20ac d:f.\u00d0stms\nstrswtrs\ufffdon \ufffdsom~t\ufffdtmkw ~{wo |wk\u00deon l\u00detzq{~yk\ufffdt{z tzsokw\ufffds oyo~rozmto\u20ac d;.<f1\\so z{\ufffdow zo\u00d0\u20ac\nmt~m\ufffdwk\ufffdt{z n\u00dezkytm sk\u20aclooz noqtzon k\u20ac\ufffdtzq{noytm\ufffd l\u00de_NV. k\ufffdo~y tzntmk\ufffdtzr \ufffdkz{\ufffdo~kl\ufffdz/\nnkzmo {qtzq{~yk\ufffdt{z\u0152\u20ac{yo kmm\ufffd~k\ufffdo kzn\u20ac{yo z{\ufffd\u0152\ufffdsk\ufffd {mm\ufffd~\u20ac n\ufffd~tzr kzo|tnoytm\ufffd d=f1\n\\so \u20ac\ufffd\ufffdn\u00de {z\ufffdsooqqom\ufffd\u20ac ~owk\ufffdon \ufffd{tzq{noytm\u20ac sk\u20aclooz mk~~ton {zq{~y{~o \ufffdskz knomkno1\nOznoon. W~{q1 M\ufffdz\ufffdso~ K\u00de\u20acozlkms. tz5335. m{tzon \ufffdso\ufffdo~yinfodemiology d43f \ufffd{tzntmk\ufffdo \ufffd\ufffdso\n\u20ac\ufffd\ufffdn\u00de {q\ufffdsono\ufffdo~ytzkz\ufffd\u20ac kzn nt\u20ac\ufffd~tl\ufffd\ufffdt{z {qsokw\ufffds tzq{~yk\ufffdt{z kzn yt\u20actzq{~yk\ufffdt{z\u0152\u00d0stms\nyk\u00de lo\ufffd\u20acoq\ufffdw tzr\ufffdtntzr sokw\ufffds |~{qo\u20ac\u20act{zkw\u20ac kzn |k\ufffdtoz\ufffd\u20ac \ufffd{\ufffdso}\ufffdkwt\ufffd\u00de sokw\ufffds tzq{~yk\ufffdt{z {z\n\ufffdsoOz\ufffdo~zo\ufffd1 Ozq{~yk\ufffdt{z o|tnoyt{w{r\u00de. {~tzq{noyt{w{r\u00de. tnoz\ufffdtqto\u20ac k~ok\u20ac \u00d0so~o \ufffdso~o t\u20ack\nvz{\u00d0wonro \ufffd~kz\u20acwk\ufffdt{z rk|lo\ufffd\u00d0ooz lo\u20ac\ufffd o\ufffdtnozmo *\u00d0sk\ufffd \u20ac{yo o\u00f0|o~\ufffd\u20ac vz{\u00d0+ kzn |~km\ufffdtmo\n*\u00d0sk\ufffd y{\u20ac\ufffd |o{|wo n{+. k\u20ac\u00d0oww k\u20acyk~vo~\u20ac q{~jstrs/}\ufffdkwt\ufffd\u00de) tzq{~yk\ufffdt{z\ufffd1 \\st\u20ac \u20ac\ufffd\ufffdn\u00de k~ok\n{qqo~on \ufffdso{||{~\ufffd\ufffdzt\ufffd\u00de \ufffd{no\ufffdow{| k\ufffdk\u20ac\ufffd ky{\ufffdz\ufffd {qk||wtmk\ufffdt{z\u20ac d44\u02d849f q{~\u20ac\ufffd~\ufffdotwwkzmo.\nk\u20ac\u20aco\u20ac\u20acyoz\ufffd. kzn tz\ufffdo\u20ac\ufffdtrk\ufffdt{z. \u00d0s{\u20aco kty\u20ac k~o~om{rzt\u00feon \u00d0t\ufffds \ufffdso\ufffdo~y \ufffdtzq{\ufffdotwwkzmo\ufffd d4:f1\nOz\ufffdsom{z\ufffdo\u00f0\ufffd {q{|tzt{z n\u00dezkytm\u20ac {z\u20ac{mtkw yontk. ~omoz\ufffd \u00d0{~v\u20ac strswtrs\ufffdon s{\u00d0 \ufffd\u20aco~\u20ac\n\ufffdozn \ufffd{ozn{~\u20aco tzq{~yk\ufffdt{z knso~tzr \ufffd{\ufffdsot~ lowtoq\u20ac. trz{~tzr {||{\u20act\ufffdo |{tz\ufffd\u20ac {q\ufffdto\u00d0 d4;.\n4<f1 \\st\u20ac losk\ufffdt{~ |~{y{\ufffdon \ufffdsooyo~rozmo {qs{y{rozo{\ufffd\u20ac r~{\ufffd|\u20ac *\ufffdsk\ufffd t\u20ac.mw\ufffd\u20ac\ufffdo~\u20ac tz\ufffdso\n\u20ac{mtkw yontk zo\ufffd\u00d0{~v\u20ac+ \u00d0t\ufffds \u20actytwk~ zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z n\u00dezkytm\u20ac. mkwwon oms{ mskylo~\u20ac d4=\u02d8\n56f. kzn \ufffdsom~ok\ufffdt{z {q{zwtzo oz\ufffdt~{zyoz\ufffd\u20ac \u20acoz\u20act\ufffdt\ufffdo \ufffd{\ufffdsontqq\ufffd\u20act{z {qyt\u20actzq{~yk\ufffdt{z d57f1\nL\ufffd~\ufffdso~ ~o\u20ac\ufffdw\ufffd\u20ac |{tz\ufffdon {\ufffd\ufffd\ufffdsk\ufffd \ufffdsoq{~yk\ufffdt{z kzn \ufffdso\u20acor~ork\ufffdt{z {q\u20ac\ufffdms r~{\ufffd|\u20ac yk\u00de lo\nk\ufffd\ufffd~tl\ufffd\ufffdon \ufffd{\ufffdso~{wo {q|wk\ufffdq{~y\u20ac) qoon kwr{~t\ufffdsy\u20ac \ufffdsk\ufffd tzm~ok\u20aco \ufffdsont\u20ac\ufffdkzmo ky{zr tno{w{rt/\nmkww\u00de {||{\u20act\ufffdo r~{\ufffd|\u20ac {q\ufffd\u20aco~\u20ac d59. 5:f1 L\ufffd~\ufffdso~ oqq{~\ufffd\u20ac ktyon k\ufffd}\ufffdkz\ufffdtq\u00detzr \ufffdsoykrzt\ufffd\ufffdno kzn\n\ufffdsooqqom\ufffd\u20ac {qtzq{noytm {z\u20ac{mtkw yontk tz\ufffdo\u20ac\ufffdtrk\ufffdtzr kl~{kno~ ky{\ufffdz\ufffd {q|wk\ufffdq{~y\u20ac d9.5;.\n5<f1 F\ufffd\ufffds{~\u20ac q~{y d5=\u02d864f q{m\ufffd\u20acon {z\ufffdso\u20aco oqqom\ufffd\u20ac l\u00dekzkw\u00de\u00fetzr \ufffdso\ufffd{|tm\u20ac. oy{\ufffdt{z\u20ac. kzn m{z/\nmo~z\u20ac \ufffdsk\ufffd oyo~ron q~{y \u20ac\ufffdms |{\u20ac\ufffd\u20ac1 T{~o{\ufffdo~. k\ufffd\ufffds{~\u20ac q~{y d65f no\ufffdow{|on \ufffdsoOzq{noytm\nZt\u20acv Ozno\u00f0 *OZO+ \ufffd{}\ufffdkz\ufffdtq\u00de s{\u00d0 \ufffd\u20aco~\u20ac q~{y okms m{\ufffdz\ufffd~\u00de mkzlo\u20ac\ufffd\u20acmo|\ufffdtlwo \ufffd{\ufffdso\u20ac|~okntzr\n{q\ufffdz~owtklwo zo\u00d0\u20ac. noy{z\u20ac\ufffd~k\ufffdtzr s{\u00d0 \ufffdsom{z\u20ac\ufffdy|\ufffdt{z {q\ufffdsowk\ufffd\ufffdo~ nom~ok\u20aco\u20ac k\u20ac\ufffdsoz\ufffdylo~\n{qm{zqt~yon mk\u20aco\u20ac k~{\u20aco tz\ufffdsontqqo~oz\ufffd m{\ufffdz\ufffd~to\u20ac1\nOz\ufffdst\u20ac|k|o~. \u00d0om{y|k~o \ufffdsontqqo~oz\ufffdtkw ty|km\ufffd {q\ufffdsotzq{noytm tz\ufffds~oo m{\ufffdz\ufffd~to\u20ac. m{z/\n\u20actno~tzr l{\ufffds {zwtzo kzn {qqwtzo ~owo\ufffdkz\ufffd qkm\ufffd{~\u20ac> \ufffdsoq{m\ufffd\u20ac {q\ufffdsozo\u00d0\u20ac yontk m{\ufffdo~kro. \ufffdso\nz\ufffdylo~ {qo|tnoytm mk\u20aco\u20ac. kzn \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdsom{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac tz\ufffd~{n\ufffdmon l\u00de\ufffdso\nr{\ufffdo~zyoz\ufffd\u20ac *[\ufffd~tzrozm\u00de Ozno\u00f0. [O+1_okzkw\u00de\u20aco \ufffds~oo m{\ufffdz\ufffd~to\u20ac\u0152zkyow\u00de O\ufffdkw\u00de. \ufffdso]zt\ufffdon\nRtzrn{y. kzn Uo\u00d0 cokwkzn\u0152\ufffdsk\ufffd o\u00f0|o~tozmon kntqqo~oz\ufffd \ufffdtyo o\ufffd{w\ufffd\ufffdt{z {q\ufffdso|kznoytm kzn\n\ufffdsk\ufffd ty|woyoz\ufffdon ntqqo~oz\ufffd m{z\ufffdktzyoz\ufffd \u20ac\ufffd~k\ufffdorto\u20ac *\u20acoo [om\ufffdt{z q{~q\ufffd~\ufffdso~ no\ufffdktw\u20ac+1 _oqt~\u20ac\ufffd\n|~{\ufffdtno kzo|tnoyt{w{rtmkw k\u20ac\u20aco\u20ac\u20acyoz\ufffd {qokms m{\ufffdz\ufffd~\u00de \ufffd{msk~km\ufffdo~t\u00feo \ufffdsoty|km\ufffd {q\ufffdso|kz/\nnoytm kzn \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdso~o\u20ac\ufffd~tm\ufffdt{z\u20ac kn{|\ufffdon1 \\soz. \u00d0om{wwom\ufffd y{~o \ufffdskz :ytwwt{z\n|tomo\u20ac {qm{z\ufffdoz\ufffd \ufffdkwvtzr kl{\ufffd\ufffd IV^OJ/4= \ufffd{|tm\u20ac |{\u20ac\ufffdon {zLkmol{{v tz5353 q~{y |\ufffdlwtm\nr~{\ufffd|\u20ac kzn |kro\u20ac1 _omk\ufffdor{~t\u00feo \u20ac\ufffdms |{\u20ac\ufffd\u20ac tz\ufffd{ Y\ufffdo\u20ac\ufffdt{zklwo {~Zowtklwo. lk\u20acon {z\ufffdso\ufffd~\ufffd\u20ac\ufffd/\n\u00d0{~\ufffdstzo\u20ac\u20ac {q\ufffdso~oqo~ozmon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac. \ufffd{kzkw\u00de\u00feo \ufffdsoo\ufffd{w\ufffd\ufffdt{z kzn \ufffdsoozrkroyoz\ufffd \ufffdsk\ufffd\nl{\ufffds mk\ufffdor{~to\u20ac |~{n\ufffdmon1 Ltzkww\u00de. \u00d0o|o~q{~y k~or~o\u20ac\u20act{z {z\ufffdsoz\ufffdylo~ {q|{\u20ac\ufffd\u20ac l\u00deoy|w{\u00de/\ntzr\ufffdsoz\ufffdylo~ {qIV^OJ/4= m{zqt~yon mk\u20aco\u20ac. \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdso~o\u20ac\ufffd~tm\ufffdt{z |{wtmto\u20ac kn{|\ufffdon\nkzn \ufffdso{zwtzo zo\u00d0\u20ac yontk m{\ufffdo~kro kl{\ufffd\ufffd \ufffdso|kznoytm1 V\ufffd~ ~o\u20ac\ufffdw\ufffd\u20ac \u20acs{\u00d0 \ufffdsk\ufffd ~owtklwo |{\u20ac\ufffd\u20ac\nk~o|~o\ufffdkwoz\ufffd tz\ufffdsozo\u00d0\u20ac mt~m\ufffdwk\ufffdon tz5353. km~{\u20ac\u20ac \ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac. kzn \ufffdsk\ufffd \ufffd\u20aco~\u20ac ozrkron\ny{~o \u00d0t\ufffds \u20ac\ufffdms |{\u20ac\ufffd\u20ac \ufffdskz \u00d0t\ufffds }\ufffdo\u20ac\ufffdt{zklwo |{\u20ac\ufffd\u20ac tzO\ufffdkw\u00de kzn Uo\u00d0 cokwkzn *l\ufffd\ufffd z{\ufffdtz]R+\n\ufffds~{\ufffdrs{\ufffd\ufffd \ufffdsokzkw\u00de\u20act\u20ac |o~t{n1 T{~o{\ufffdo~. ~or~o\u20ac\u20act{z ~o\u20ac\ufffdw\ufffd\u20ac \u20ac\ufffdrro\u20ac\ufffd \ufffdsk\ufffd \ufffdsoz\ufffdylo~ {qmk\u20aco\u20ac.\n\ufffdso[\ufffd~tzrozm\u00de Ozno\u00f0 kzn \ufffdso{zwtzo zo\u00d0\u20ac yontk m{\ufffdo~kro mkz\u20aco~\ufffdo k\u20ac|~{\u00f0to\u20ac \ufffd{k\u20ac\u20aco\u20ac\u20ac \ufffdso\no\ufffd{w\ufffd\ufffdt{z {q\ufffdsotzq{noytm1\n_o|~{\ufffdtno kno\u20acm~t|\ufffdt{z {q\ufffdsom{\ufffdz\ufffd~\u00de \u20acowom\ufffdt{z. \ufffdsonk\ufffdk m{wwom\ufffdt{z |~{mo\u20ac\u20ac. \ufffdsowklowtzr\n{q\ufffdso|{\u20ac\ufffd\u20ac m{zmo~ztzr \ufffdsot~ zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac kzn s{\u00d0 \u00d0onoqtzon \ufffdsoyo\ufffd~tm\u20ac oy|w{\u00deon tz\ufffdst\u20ac\n\u00d0{~v1\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 5247k~\ufffdtmwo\ufffd279 9<;4:/\ufffdzno~\ufffd\ufffdk zntzr/kzn/ mt\ufffdtzr/\nm~{\ufffdn\ufffdkzrwo/ nk\ufffdk. mkzz{\ufffd lo\ufffdsk~on tzI[^q{~yk\ufffd1\nN{\ufffdo\ufffdo~. kz\ufffd~o\ufffdok~mso~ mkz~o}\ufffdt~o kmmo\ufffd\ufffd \ufffd{\nI~{\ufffdn\\kz rwo\ufffd|{z ~o}\ufffdo\ufffd\ufffd1 V\ufffd~[\ufffd||{~\ufffdtzr\ntzq{~yk\ufffdt{z qtwo\ufffdm{z\ufffdktz kww\ufffdsom{z\ufffdoz\ufffd\ufffd \ufffd{r\ufffdtno\n\ufffdsotz\ufffdo~o\ufffd\ufffdon ~okno~ tz~o|wtmk\ufffdtzr {\ufffd~\ufffd\ufffd\ufffdn\ufffd \ufffdt\ufffds\ntzq{~yk\ufffdt{z kl{\ufffd\ufffd I~{\ufffdn\\kz rwokmmo\ufffd\ufffd kznnk\ufffdk\nm{wwom\ufffdt{z yo\ufffds{n{w{ r\ufffd1\nL\ufffdzntzr> F\ufffd\ufffds{~\ufffd _Y.MK.FM~omot\ufffdon q\ufffdzntzr\nq~{y \ufffdso433:<6 KWOJ W~{uom\ufffd \ufffdMw{lkw Nokw\ufffds\n[om\ufffd~t\ufffd\ufffd Fmknoytm Zo\ufffdok~m sI{kwt\ufffdt{z\ufffd [IN/\n33334/66=4. |~{\ufffdtnon l\ufffd]R2M;1 \\soq\ufffdzno~\ufffd skn\nz{~{wotz\ufffd\ufffd\ufffdn\ufffd no\ufffdtrz. nk\ufffdkm{wwom\ufffdt{z kzn\nkzkw\ufffd\ufffdt\ufffd. nomt\ufffdt{z \ufffd{|\ufffdlwt\ufffds. {~|~o|k~k \ufffdt{z{q\ufffdso\nykz\ufffd\ufffdm~t|\ufffd1\nI{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd >\\sok\ufffd\ufffds{~\ufffd sk\ufffdo nomwk~on\n\ufffdsk\ufffdz{m{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd o\ufffdt\ufffd\ufffd1\nTk\ufffdo~tkw\ufffd kzn yo\ufffds{n\ufffd\nI{\ufffdz\ufffd~\u00de \u20acowom\ufffdt{z\n_o|o~q{~y km{y|k~k\ufffdt\ufffdo kzkw\u00de\u20act\u20ac {zO\ufffdkw\u00de. Uo\u00d0 cokwkzn. kzn \ufffdso]zt\ufffdon Rtzrn{y1 \\so\nms{tmo {q\ufffdso\u20aco m{\ufffdz\ufffd~to\u20ac ~owto\u20ac {z\ufffdsontqqo~oz\ufffd \u20ac\ufffd~k\ufffdorto\u20ac \ufffdso\u00de oy|w{\u00deon tz\ufffdsoyt\ufffdtrk\ufffdt{z {q\n\ufffdso\ufffdt~\ufffd\u20ac n\ufffd~tzr 53531 Oznoon. O\ufffdkw\u00de q{~yo~w\u00de ty|woyoz\ufffdon k\u20aco~to\u20ac {qm{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac\n{zw\u00de q{~\ufffds{\u20aco y\ufffdztmt|kwt\ufffdto\u20ac \u00d0stms \u00d0o~o tnoz\ufffdtqton k\u20ac\ufffdsomoz\ufffd~kw \u20ac|~okno~\u20ac {q\ufffdso\ufffdt~\ufffd\u20ac d66f1\n\\soz. \u20ac\ufffdms yok\u20ac\ufffd~o\u20ac \u00d0o~o o\u00f0\ufffdoznon \ufffd{~ort{z\u20ac q{ww{\u00d0tzr \ufffdso\u20ackyo ~k\ufffdt{zkwo. tz\ufffd~{n\ufffdmtzr \ufffdso\nmw{\u20ac\ufffd~o {q\u20acms{{w\u20ac kzn \ufffdzt\ufffdo~\u20act\ufffdto\u20ac1 \\so \u20aco\ufffdo~t\ufffd\u00de {q\ufffdsoo|tnoyt{w{rtmkw |~{qtwo won\ufffdsom{\ufffdz\ufffd~\u00de\n\ufffd{o\u20ac\ufffdklwt\u20acs kqt~\u20ac\ufffd zk\ufffdt{zkw w{mvn{\u00d0z q~{y 3=23625353 \ufffd{4<23925353. q{ww{\u00d0on l\u00dek\u20acom{zn {zo\nq~{y 5724525353 \ufffd{3:23425354 d67f1\nUo\u00d0 cokwkzn. tz\u20ac\ufffdokn. kn{|\ufffdon k\u20aco~to\u20ac {qm{\ufffdz\ufffdo~yok\u20ac\ufffd~o\u20ac \u00d0t\ufffds \ufffdso|~omt\u20aco r{kw {qo~kntmk\ufffd/\ntzr\ufffdso\ufffdt~\ufffd\u20ac. msk~km\ufffdo~t\u00feon l\u00deok~w\u00de. ~k|tn. kzn nomt\u20act\ufffdo r{\ufffdo~zyoz\ufffd km\ufffdt{z\u20ac k\ufffd\ufffdk~t{\ufffd\u20ac wo\ufffdow\u20ac\n\u20ac\ufffdms k\u20ac\u20ac\ufffd~tm\ufffd w{mvn{\u00d0z\u20ac. l{~no~/m{z\ufffd~{w. m{yy\ufffdzt\ufffd\u00de. kzn mk\u20aco/lk\u20acon m{z\ufffd~{w yok\u20ac\ufffd~o\u20ac d69f1\nT{~o{\ufffdo~. \ufffdsom{\ufffdz\ufffd~\u00de kw\u20ac{ ozq{~mon kzk\ufffdt{z\u00d0tno w{mvn{\u00d0z \ufffdsk\ufffd wk\u20ac\ufffdon q~{y 5623625353 \ufffd{\n4623925353 d67f. ykzkrtzr \ufffdso\u20ac|~okntzr {q\ufffdso\ufffdt~\ufffd\u20ac \ufffds~{\ufffdrs k\u20aco~to\u20ac {q|\ufffdlwtm sokw\ufffds kzn\n\u20ac{mtkw yok\u20ac\ufffd~o\u20ac {~rkzt\u00feon tzkq{\ufffd~/wo\ufffdow IV^OJ/4= Fwo~\ufffd [\u00de\u20ac\ufffdoy d6:f1\nI{z\ufffd~k~\u00de \ufffd{\ufffdsoqt~\u20ac\ufffd \ufffd\u00d0{m{\ufffdz\ufffd~to\u20ac. \ufffdso]zt\ufffdon Rtzrn{y {|\ufffdon q{~ytwno~ ykzkroyoz\ufffd {q\n\ufffdso|kznoytm tz\ufffdsook~w\u00de \u20ac\ufffdkro\u20ac d6;f1 \\so ~k|tn o\ufffd{w\ufffd\ufffdt{z {q\ufffdso|kznoytm. s{\u00d0o\ufffdo~. mk\ufffd\u20acon\nkztyyontk\ufffdo mskzro {qnt~om\ufffdt{z d6<f1 Oznoon. \ufffdso]zt\ufffdon Rtzrn{y kzz{\ufffdzmon t\ufffd\u20actz\ufffdoz\ufffdt{z\n\ufffd{o\u20ac\ufffdklwt\u20acs kw{mvn{\u00d0z. nowork\ufffdtzr t\ufffd\u20ac{~rkzt\u00fek\ufffdt{z \ufffd{t\ufffd\u20acq{\ufffd~ m{z\u20ac\ufffdt\ufffd\ufffdoz\ufffd m{\ufffdz\ufffd~to\u20ac> Kzrwkzn.\n[m{\ufffdwkzn. _kwo\u20ac. kzn U{~\ufffdso~z O~owkzn1 _kwo\u20ac ~ort\u20ac\ufffdo~on \ufffdsoy{\u20ac\ufffd |~{w{zron qt~\u20ac\ufffd w{mvn{\u00d0z\nq~{y 5623625353 \ufffd{4623;253531 [\ufffdmmo\u20ac\u20act\ufffdow\u00de. \ufffdsom{\ufffdz\ufffd~\u00de ozq{~mon \ufffd\u00d0{y{~o w{mvn{\u00d0z\u20ac tz\n5353 \ufffdsk\ufffd wk\u20ac\ufffdon q~{y 5624325353 \ufffd{4424525353 kzn 5:24525353 \ufffd{3523725354 d67f1\nJk\ufffdk m{wwom\ufffdt{z\nV\ufffd~ _{~wn tzJk\ufffdk1 \\so nk\ufffdk m{zmo~ztzr \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdsoz\ufffdylo~ {qIV^OJ/4= m{z/\nqt~yon mk\u20aco\u20ac kzn nok\ufffds\u20ac k~o{l\ufffdktzon q~{y I{~{zk\ufffdt~\ufffd\u20ac Wkznoytm \u20acom\ufffdt{z {qV\ufffd~ _{~wn tz\nJk\ufffdk d6=f1 \\so \u00d0ol\u20act\ufffdo {qqo~\u20ac k\u00d0{~wn\u00d0tno \u20aco\ufffd{q\u20ac\ufffdk\ufffdt\u20ac\ufffdtm\u20ac kzn yo\ufffd~tm\u20ac ~owk\ufffdon \ufffd{\ufffdsoIV^OJ/4=\n|kznoytm. tz\ufffdo~km\ufffdt\ufffdo \ufffdt\u20ac\ufffdkwt\u00fek\ufffdt{z\u20ac. kzn nk\ufffdk \u20ac{\ufffd~mo\u20ac1 Oz\ufffdsom{z\ufffdo\u00f0\ufffd {q\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de. \u00d0o~o\ufffd~to\ufffdon\n\ufffdsom{y|wo\ufffdo nk\ufffdk\u20aco\ufffd \ufffdsk\ufffd tzmw\ufffdno\u20ac \ufffdsonktw\u00de \u20ac\ufffdk\ufffdt\u20ac\ufffdtm\u20ac q{~kwwm{\ufffdz\ufffd~to\u20ac tz\ufffdso\u00d0{~wn \u20actzmo Qkz\ufffd/\nk~\u00de55.53531 _o~o\ufffdktzon {zw\u00de ~om{~n\u20ac q~{y O\ufffdkw\u00de. \ufffdso]zt\ufffdon Rtzrn{y. kzn Uo\u00d0 cokwkzn \ufffdsk\ufffd\n~oqo~~on \ufffd{53531\nLkmol{{v nk\ufffdk1 \\so m{wwom\ufffdt{z {q|{\u20ac\ufffd\u20ac {zLkmol{{v |o~q{~yon {zk|o~t{n \ufffdsk\ufffd r{o\u20ac\nq~{y 42425353 \ufffd{64245253531 \\{|~{\ufffdtno kyokztzrq\ufffdw {l\u20aco~\ufffdk\ufffdt{z {q\ufffdsonolk\ufffdon k~{\ufffdzn\nIV^OJ/4= \ufffd{|tm. \u00d0om~ok\ufffdon kwt\u20ac\ufffd{qvo\u00de\u00d0{~n\u20ac \ufffdsk\ufffd tzmw\ufffdnon \ufffdsorozo~kw nt\u20acm\ufffd\u20ac\u20act{z k~{\ufffdzn \ufffdso\nIV^OJ/4= {\ufffd\ufffdl~okv kzn \ufffdkmmtzk\ufffdt{z mky|ktrz\u20ac1 [\ufffdms nk\ufffdk\u20aco\ufffd m{z\u20act\u20ac\ufffd\u20ac {qk\u20aco\ufffd{qKzrwt\u20acs woy/\nyk\ufffdt\u00feon \ufffdo~y\u20ac \u00d0stms \u00d0o~o \ufffd~kz\u20acwk\ufffdon tz\ufffd{ O\ufffdkwtkz q{~m{z\u20act\u20ac\ufffdozm\u00de |\ufffd~|{\u20aco\u20ac *Zoqo~ \ufffd{\ufffdsom{y/\n|wo\ufffdo wt\u20ac\ufffd{q\ufffdo~y\u20ac \ufffd\u20acon tz\\klwo 4+1\n\\so {l\ufffdktzyoz\ufffd {q\ufffdsonk\ufffdk \u00d0k\u20ac\ufffdomsztmkww\u00de ykno \ufffds~{\ufffdrs \ufffdsooy|w{\u00deyoz\ufffd {qI~{\u00d0n\\kzrwo\nd73f. kLkmol{{v/{\u00d0zon \ufffd{{w \ufffdsk\ufffd \ufffd~kmv\u20ac tz\ufffdo~km\ufffdt{z\u20ac {z|\ufffdlwtm m{z\ufffdoz\ufffd q~{y Lkmol{{v |kro\u20ac.\n\\klwo 41St\u20ac\ufffd {q\ufffdo~y\u20ac oy|w{\u00deon tz\ufffdsonk\ufffdk m{wwom\ufffdt{z {q|{\u20ac\ufffd\u20ac {zLkmol{{v1 \\so k\u20ac\ufffdo~t\u20acv ~o|~o\u20acoz\ufffd\u20ac krozo~kw \u20ac\ufffd~tzr\nk||ok~tz rloq{~o {~kq\ufffdo~ \ufffdso\ufffdo~y. no|oznt zr{zt\ufffd\u20ac|{\u20act\ufffdt{z1\nI{\ufffdz\ufffd~\u00de \\o~y\u20ac\nO\\ m{\ufffdtn\ufffd.\ufffd\ufffdk\u00f0\ufffd.n{\u20aco\ufffd.qk~yk\ufffd.tyy\ufffdz\ufffd.\ufffdkmm\ufffd.\u20ack~\u20ac\ufffd.w{mvn{\u00d0z .o|tnoytk. |kznoytk. k\u20ac\ufffd~k\u00feozomk\ufffd.|qt\u00feo~\n]R \u2019\nUcm{\ufffdtn\ufffd.\ufffd\ufffdk\u00f0\ufffd.n{\u20aco\ufffd.|sk~yk\ufffd.tyy\ufffdz\ufffd.\ufffdkmm\ufffd.\u20ack~\u20ac\ufffd.w{mvn{\u00d0z .o|tnoytm. |kznoytm. k\u20ac\ufffd~k\u00feozomk\ufffd.\n|qt\u00feo~\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o135:;3551\ufffd33 4\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 6247\nr~{\ufffd|\u20ac. kzn \ufffdo~tqton |~{qtwo\u20ac1 I~{\u00d0n\\kzrwo n{o\u20ac z{\ufffdtzmw\ufffdno |ktn kn\u20ac\ufffdzwo\u20ac\u20ac \ufffds{\u20aco kn\u20aclorkz k\u20ac\n{~rkztm. z{z/|ktn |{\u20ac\ufffd\u20ac \ufffdsk\ufffd \u00d0o~o \u20ac\ufffdl\u20aco}\ufffdoz\ufffdw\u00de \ufffdl{{\u20ac\ufffdon\ufffd \ufffd\u20actzr Lkmol{{v)\u20ac kn\ufffdo~\ufffdt\u20actzr \ufffd{{w\u20ac1\nI~{\u00d0n\\kzrwo kw\u20ac{ n{o\u20ac z{\ufffdtzmw\ufffdno km\ufffdt\ufffdt\ufffd\u00de {z|~t\ufffdk\ufffdo kmm{\ufffdz\ufffd\u20ac {~|{\u20ac\ufffd\u20ac ykno \ufffdt\u20actlwo {zw\u00de \ufffd{\n\u20ac|omtqtm r~{\ufffd|\u20ac {qq{ww{\u00d0o~\u20ac1\nL~{y k\ufffdomsztmkw |o~\u20ac|om\ufffdt\ufffdo. I~{\u00d0n\\kzrwo n{o\u20ac z{\ufffd|~{\ufffdtno k\u20acok~mstzr yomskzt\u20acy \ufffd{\n~o\ufffd~to\ufffdo kww|{\u20ac\ufffd\u20ac |k~\ufffdtkww\u00de m{z\ufffdktztzr k|~{\ufffdtnon tz|\ufffd\ufffd \ufffdo~y1 \\so~oq{~o. \u00d0oo\u00f0|kznon \ufffdso\n\u00d0{~n\u20ac wt\u20ac\ufffdon tz\\klwo 4\ufffd{kww\ufffdsot~ |{\u20ac\u20actlwo ozntzr\u20ac1 \\so m{wwom\ufffdt{z {q|{\u20ac\ufffd\u20ac q~{y I~{\u00d0n\\kzrwo\ntzmw\ufffdnon kww|kro\u20ac \ufffdsk\ufffd m{z\ufffdktzon \ufffdso\u20acok~ms \ufffdo~y\u20ac q{~\ufffdsom{\ufffdz\ufffd~to\u20ac {qtz\ufffdo~o\u20ac\ufffd1\nIsk~km\ufffdo~t\u00fetzr ~owtkltwt\ufffd\u00de {q|{\u20ac\ufffd\u20ac l\u00dezo\u00d0\u20ac {\ufffd\ufffdwo\ufffd wokztzr\nV\ufffd\ufffdwo\ufffd mwk\u20ac\u20actqtmk\ufffdt{z1 \\{k\u20ac\u20aco\u20ac\u20ac \ufffdso\ufffd~\ufffd\u20ac\ufffd\u00d0{~\ufffdstzo\u20ac\u20ac {q|{\u20ac\ufffd\u20ac mt~m\ufffdwk\ufffdtzr {zLkmol{{v. \u00d0o\nl\ufffdtw\ufffd knk\ufffdk\u20aco\ufffd {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac) n{yktz\u20ac q~{y {\ufffd~{~trtzkw Lkmol{{v nk\ufffdk\u20aco\ufffd \u00d0so~o okms n{yktz\nt\u20acwklowon ot\ufffdso~ k\u20acQuestionable {~Reliable1 \\so mwk\u20ac\u20actqtmk\ufffdt{z ~owton {zkm{yltzk\ufffdt{z lo\ufffd\u00d0ooz\nTontk Gtk\u20ac2Lkm\ufffd Isomv *TGLI+ d74f. kztzno|oznoz\ufffd qkm\ufffd/msomvtzr {~rkzt\u00fek\ufffdt{z. kzn kwt\u20ac\ufffd{q\nzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac wklowwon k\u20acno\u20acm~tlon tzd75f1 VzTGLI. okms zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd t\u20ack\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds k\nwklow \ufffdsk\ufffd ~oqo~\u20ac \ufffd{t\ufffd\u20ac|{wt\ufffdtmkw ltk\u20ac. zkyow\u00de>Right,Right-Center,Least-Biased,Left-Center,and\nLeft1 [tytwk~w\u00de. \ufffdso\u00d0ol\u20act\ufffdo kw\u20ac{ |~{\ufffdtno\u20ac k\u20acom{zn wklow \ufffdsk\ufffd o\u00f0|~o\u20ac\u20aco\u20ac t\ufffd\u20ac~owtkltwt\ufffd\u00de. mk\ufffdor{~t\u00fe/\ntzr{\ufffd\ufffdwo\ufffd\u20ac k\u20acConspiracy-Pseudoscience, Pro-Science {~Questionable1 U{\ufffdtmoklw\u00de. \ufffdsoQuestion-\nable \u20aco\ufffdtzmw\ufffdno\u20ac k\u00d0tno ~kzro {q|{wt\ufffdtmkw ltk\u20aco\u20ac. q~{yExtremeLeft \ufffd{ExtremeRight1 L{~\ntz\u20ac\ufffdkzmo. \ufffdsoRight wklow t\u20ack\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds L{\u00f0 Uo\u00d0\u20ac. \ufffdsoQuestionable wklow \ufffd{G~ot\ufffdlk~\ufffd *k\nqky{\ufffd\u20ac ~trs\ufffd o\u00f0\ufffd~oyt\u20ac\ufffd {\ufffd\ufffdwo\ufffd+. kzn \ufffdsoPro-Science wklow \ufffd{Science1 TGLI kw\u20ac{ |~{\ufffdtno\u20ac kmwk\u20ac/\n\u20actqtmk\ufffdt{z lk\u20acon {zkrankingbiasscore \ufffdsk\ufffd no|ozn\u20ac {zq{\ufffd~ mk\ufffdor{~to\u20ac>BiasedWording/Head-\nlines,Factual/Sourcing, StoryChoices. kznPoliticalAffiliation1 Kkms mk\ufffdor{~\u00de t\u20ac~k\ufffdon {zk3\u02d843\n\u20acmkwo. \u00d0t\ufffds 3tzntmk\ufffdtzr \ufffdsokl\u20acozmo {qltk\u20ac kzn 43tzntmk\ufffdtzr \ufffdso|~o\u20acozmo {qyk\u00f0ty\ufffdy ltk\u20ac1\n\\sobiasoutletscore t\u20acm{y|\ufffd\ufffdon k\u20ac\ufffdsok\ufffdo~kro {q\ufffdsoq{\ufffd~ \u20acm{~o mk\ufffdor{~to\u20ac1 Fntqqo~oz\ufffd msk~km/\n\ufffdo~t\u00fek\ufffdt{z t\u20ac|~{\ufffdtnon q{~s\ufffdy{~ kzn |wk\ufffdq{~y\u20ac \u00d0ol\u20act\ufffdo\u20ac. z{\ufffdkmm{\ufffdz\ufffdtzr q{~\ufffdsomk\ufffdor{~t\u00fek\ufffdt{z\n|~{mo\u20ac\u20ac1\nJk\ufffdk m{wwom\ufffdt{z kzn mwk\u20ac\u20actqtmk\ufffdt{z ~o\u20ac\ufffdw\ufffd\u20ac1 \\so tzt\ufffdtkw m{wwom\ufffdt{z {q|{\u20ac\ufffd\u20ac q~{y |kro\u20ac |~o/\n\u20acoz\ufffdon tz[om\ufffdt{z |~{n\ufffdmon k\ufffd{\ufffdkw {q\ufffd:M|{\u20ac\ufffd\u20ac q~{y 54<5<3 \ufffdzt}\ufffdo \ufffd\u20aco~\u20ac1 \\soz. \u00d0o\noy|w{\u00deon \ufffdsomwk\u20ac\u20actqtmk\ufffdt{z |~{mo\u20ac\u20ac no\u20acm~tlon tz[om\ufffdt{z. {l\ufffdktztzr 5<:64 mk\ufffdor{~t\u00feon |{\u20ac\ufffd\u20ac\nq~{y 4;<9 \ufffdzt}\ufffdo \ufffd\u20aco~\u20ac q{~Uo\u00d0 cokwkzn. 449754 |{\u20ac\ufffd\u20ac q~{y 474;: \ufffdzt}\ufffdo \ufffd\u20aco~\u20ac q{~O\ufffdkw\u00de kzn\n4:7<5<6 |{\u20ac\ufffd\u20ac Lkmol{{v q~{y 444949 \ufffdzt}\ufffdo \ufffd\u20aco~\u20ac q{~\ufffdso]zt\ufffdon Rtzrn{y1 \\so ~o\u20ac\ufffdw\ufffd {q\ufffdso\nnk\ufffdk m{wwom\ufffdt{z |~{mo\u20ac\u20ac t\u20acno\u20acm~tlon tz\\klwo 51\nTo\ufffd~tm\u20ac\n[\ufffd~tzrozm\u00de Ozno\u00f0 *[O+1 \\{}\ufffdkz\ufffdtq\u00de \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {qm{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac ozq{~mon l\u00de\nr{\ufffdo~zyoz\ufffd\u20ac. \u00d0ooy|w{\u00de kyok\u20ac\ufffd~o mkwwon [\ufffd~tzrozm\u00de Ozno\u00f0 *[O+ d76f1 O\ufffdt\u20acm{y|{\u20acon {qztzo\ntzntmk\ufffd{~\u20ac m{zmo~ztzr m{z\ufffdktzyoz\ufffd kzn mw{\u20ac\ufffd~o |{wtmto\u20ac kzn sokw\ufffds kzn \u20ac\u00de\u20ac\ufffdoy |{wtmto\u20ac1 \\so [O\n\\klwo 51Jk\ufffdk l~okvn{\u00d0z {qLkmol{{v |{\u20ac\ufffd\u20ac m{wwom\ufffdon q~{y |kro\u20ac \u00d0s{\u20aco knytz \u00d0k\u20ac ~owk\ufffdon \ufffd{{zo {q\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac tzo\u00f0ky. \ufffd{ro\ufffds o~\u00d0t\ufffds \ufffdso~o\u20ac\ufffdw\ufffd\u20ac {q\ufffdsomwk\u20ac/\n\u20actqtmk\ufffdt{z |~{mo\u20ac\u20ac1\nI{\ufffdz\ufffd~\u00de \\{\ufffdkw W{\u20ac\ufffd\u20ac Ik\ufffdor{~t\u00feon W{\u20ac\ufffd\u20ac \u00d0t\ufffds kStzv Y\ufffdo\u20ac\ufffdt{zk lwoW{\u20ac\ufffd\u20ac Zowtklwo W{\u20ac\ufffd\u20ac\nUc 67=945 5<:64 663 5<634\n]R 66<5:5< 953953 947:9 7:=399\nO\\ 55;;353 449754 5=95 4457:=\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 135:;3551\ufffd335\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 7247\n{zkrt\ufffdoz nk\u00dett\u20acm{y|\ufffd\ufffdon \ufffds~{\ufffdrs \ufffdsoq{ww{\u00d0tzr o}\ufffdk\ufffdt{z>\nSIt\u00887\nAIjCtB \u00854\u0086\nKkms \u20ac\ufffdl/tzno\u00f0 \u20acm{~oIq{~kz\u00de{q\ufffdsoztzo tzntmk\ufffd{~\u20acj{zkz\u00dert\ufffdoz nk\u00dett\u20acm{y|\ufffd\ufffdon k\u20ac\nIjCt\u0088766vjCt\u00006B<\u0085Fj\u0000fjCt\u0086\nNjC \u00855\u0086\n\u00d0so~oNjt\u20ac\ufffdsoyk\u00f0ty\ufffdy \ufffdkw\ufffdo {q\ufffdsotzntmk\ufffd{~.Fj\u20ac|omtq\u00de \u00d0so\ufffdso~ \ufffdsotzntmk\ufffd{~ sk\u20ackqwkr\ufffdk~/\ntklwo *FjB4+{~z{\ufffd*FjB3+.fj.t\ufffdso~om{~non ltzk~\u00de qwkrq{~\ufffdsotzntmk\ufffd{~ kznvj.t\ufffdso~om{~non\n|{wtm\u00de \ufffdkw\ufffdo {z\ufffdso{~ntzkw \u20acmkwo1 Fno\u20acm~t|\ufffdt{z {q\ufffdsotzntmk\ufffd{~\u20ac tzmw\ufffdnon tz\ufffdsom{y|\ufffd\ufffdk\ufffdt{z\n{q[Omkzloq{\ufffdzn tz\\klwo 6.\u00d0stwo km{y|wo\ufffdo no\u20acm~t|\ufffdt{z kl{\ufffd\ufffd \ufffdsom{y|\ufffd\ufffdk\ufffdt{z {q\ufffdso[\ufffd~tz/\nrozm\u00de Ozno\u00f0 mkzloq{\ufffdzn k\ufffd\ufffdsoq{ww{\u00d0tzr wtzv d77f1\n_oovw\u00de o\ufffd{w\ufffd\ufffdt{z {q\ufffdsoozrkroyoz\ufffd1 \\{k\u20ac\u20aco\u20ac\u20ac \ufffd\u20aco~\u20ac) ozrkroyoz\ufffd l\u00de{\ufffd\ufffdwo\ufffd mk\ufffdor{~\u00de. \u00d0o\n\ufffd\u20acon kww|{\u20ac\u20actlwo \ufffd\u00de|o\u20ac {q\ufffd\u20aco~/|{\u20ac\ufffd tz\ufffdo~km\ufffdt{z \u02d8t1o1. kz\u00de\ufffd\u00de|o {q~okm\ufffdt{z. \u20acsk~o {~m{yyoz\ufffd1\n_o\ufffdsoz mkwm\ufffdwk\ufffdon \ufffdsok\ufffdo~kro \u00d0oovw\u00de ozrkroyoz\ufffd \ufffd{l{\ufffds \ufffdso}\ufffdo\u20ac\ufffdt{zklwo kzn ~owtklwo\n\u20ac{\ufffd~mo\u20ac k\u20acq{ww{\u00d0\u20ac1 So\ufffdQw\ufffdQkznRw\ufffdR~o|~o\u20acoz\ufffd kww\ufffdso}\ufffdo\u20ac\ufffdt{zklwo kzn ~owtklwo |{\u20ac\ufffd\u20ac\n\ufffdsk\ufffd k||ok~on tz\u00d0oovw1[tytwk~w\u00de. wo\ufffdrQw.cQwkznsQw~o|~o\u20acoz\ufffd \ufffdsoz\ufffdylo~ {q~okm\ufffdt{z\u20ac. m{y/\nyoz\ufffd\u20ac kzn \u20acsk~o\u20ac q{~okms }\ufffdo\u20ac\ufffdt{zklwo |{\u20ac\ufffd k\ufffd\u00d0oovw.\u00d0stw\u20ac\ufffdrRw.cRwkznsRw~oqo~ \ufffd{\ufffdsoz\ufffdy/\nlo~{q~okm\ufffdt{z\u20ac. m{yyoz\ufffd\u20ac kzn \u20acsk~o\u20ac ~o\u20ac|om\ufffdt\ufffdow\u00de q{~okms ~owtklwo |{\u20ac\ufffd k\ufffd\u00d0oovw1\\so~oq{~o.\n\ufffdsok\ufffdo~kro \u00d0oovw\u00de ozrkroyoz\ufffd q{~}\ufffdo\u20ac\ufffdt{zklwo |{\u20ac\ufffd\u20ac \ufffdeqwk\ufffd\u00d0oovwmkzlonoqtzon k\u20ac\n\ufffdeqw\u0088rQw\u0087cQw\u0087sQw\nyQwyC \u00856\u0086\n\u00d0stw\u20ac\ufffd t\ufffd\u20acm{\ufffdz\ufffdo~|k~\ufffd \ufffderwt\u20acnoqtzon k\u20ac\n\ufffderw\u0088rRw\u0087cRw\u0087sQw\nyRwyB \u00857\u0086\nMJKS\\ Vzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f01 \\so MJKS\\ *Mw{lkw Jk\ufffdklk\u20aco {qK\ufffdoz\ufffd\u20ac. Skz/\nr\ufffdkro. kzn \\{zo+ W~{uom\ufffd. |{\u00d0o~on l\u00deM{{rwo Qtr\u20ack\u00d0. t\u20acknk\ufffdklk\u20aco {qrw{lkw s\ufffdykz \u20ac{mto\ufffd\u00de\n\u00d0stms \ufffdy{zt\ufffd{~\u20ac \ufffdso\u00d0{~wn)\u20ac l~{knmk\u20ac\ufffd. |~tz\ufffd. kzn \u00d0ol zo\u00d0\u20ac q~{y zok~w\u00de o\ufffdo~\u00de m{~zo~ {qo\ufffdo~\u00de\nm{\ufffdz\ufffd~\u00de tz{\ufffdo~ 433wkzr\ufffdkro\u20ac kzn tnoz\ufffdtqto\u20ac \ufffdso|o{|wo. w{mk\ufffdt{z\u20ac. {~rkzt\u00fek\ufffdt{z\u20ac. \ufffdsoyo\u20ac.\n\u20ac{\ufffd~mo\u20ac. oy{\ufffdt{z\u20ac. m{\ufffdz\ufffd\u20ac. }\ufffd{\ufffdo\u20ac. tykro\u20ac kzn o\ufffdoz\ufffd\u20ac n~t\ufffdtzr {\ufffd~rw{lkw \u20ac{mto\ufffd\u00de o\ufffdo~\u00de \u20acom{zn\\klwo 61St\u20ac\ufffd {qtzntmk\ufffd{ ~\u20actzmw\ufffdnon tz\ufffdsom{y|\ufffd\ufffdk\ufffdt{z {q[\ufffd~tzrozm \u00deOzno\u00f0 *[O+1 Kkms \ufffdkw\ufffdo ozm{no\u20ac \ufffd{k\u20ac|omtqtm \u20aco\ufffd{qyok\u20ac\ufffd ~o\u20ack||wton m{zmo~zt zr\ufffdsotzntmk\ufffd{~\u20ac 1\\so\nLwkr m{w\ufffdyz tzntmk\ufffdo\u20ac \u00d0so\ufffdso~ \ufffdso|{wtm\u00de sk\u20ack\ufffdk~tklwo \ufffdsk\ufffd noqtzo\u20ac \ufffdsoro{r~k|s \u00de{qt\ufffd\u20ack||wtmk\ufffdt{z *4+{~z{\ufffd*3+1\nOzntmk\ufffd{~ Jo\u20acm~t| \ufffdt{z Tk\u00f0 \ufffdkw\ufffdo *Uv+ LwkrD *Lv+\n[ms{{w mw{\u20actzr *I4+ Zom{~n mw{\u20actzr\u20ac {q\u20acms{{w\u20ac kzn \ufffdzt\ufffdo~\u20act\ufffdto\u20ac 6 bo\u20acB4\n_{~v|wkmo mw{\u20actzr *I5+ Zom{~n mw{\u20actzr\u20ac {q\u00d0{~v|wkmo\u20ac 6 bo\u20acB4\nIkzmow |\ufffdlwtm o\ufffdoz\ufffd\u20ac *I6+ Zom{~n mkzmowwtzr |\ufffdlwtm o\ufffdoz\ufffd\u20ac 5 bo\u20acB4\nZo\u20ac\ufffd~tm\ufffdt{z\u20ac {zrk\ufffdso~tzr\u20ac *I7+ Zom{~n wtyt\ufffd\u20ac {zrk\ufffdso~tzr\u20ac 7 bo\u20acB4\nIw{\u20aco |\ufffdlwtm \ufffd~kz\u20ac|{~\ufffd *I9+ Zom{~n mw{\u20actzr {q|\ufffdlwtm \ufffd~kz\u20ac|{ ~\ufffd 5 bo\u20acB4\n[\ufffdk\u00de k\ufffds{yo ~o}\ufffdt~oyoz \ufffd\u20ac*I:+ Zom{~n {~no~\u20ac \ufffd{\ufffd\u20acsow\ufffdo~/tz/| wkmo\ufffd kzn {\ufffdso~\u00d0t\u20aco m{zqtzo \ufffd{\ufffdsos{yo 6 bo\u20acB4\nZo\u20ac\ufffd~tm\ufffdt{z\u20ac {ztz\ufffdo~zkw y{\ufffdoyoz\ufffd *I;+ Zom{~n ~o\u20ac\ufffd~tm\ufffdt{z\u20ac {ztz\ufffdo~zkw y{\ufffdoyoz\ufffd lo\ufffd\u00d0ooz mt\ufffdto\u20ac2~ort{z\u20ac 5 bo\u20acB4\nOz\ufffdo~zk\ufffdt{zk w\ufffd~k\ufffdow m{z\ufffd~{w \u20ac*I<+ Zom{~n ~o\u20ac\ufffd~tm\ufffdt{z\u20ac {ztz\ufffdo~zk\ufffdt{zk w\ufffd~k\ufffdow 7 U{B3\nW\ufffdlwtm tzq{~yk\ufffdt{z mky|ktrz \u20ac*N4+ Zom{~n |~o\u20acozmo {q|\ufffdlwtm tzq{ mky|ktrz\u20ac 5 bo\u20acB4\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 135:;3551\ufffd336\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 9247\n{qo\ufffdo~\u00de nk\u00de\ufffd d79f1 Fy{zr \ufffdsontqqo~oz\ufffd \u20aco~\ufffdtmo\u20ac \ufffdsk\ufffd MJKS\\ |~{\ufffdtno\u20ac. t\ufffd\u20ac\ufffd||wto\u20ac \ufffdso\ufffd~kz\u20acwk/\n\ufffdt{z {qkww\ufffdsozo\u00d0\u20ac \ufffdso\u00de tzm{~|{~k\ufffdo tz:9wkzr\ufffdkro\u20ac ~o|~o\u20acoz\ufffdtzr =<17& {qt\ufffd\u20acnktw\u00de z{z/\nKzrwt\u20acs y{zt\ufffd{~tzr \ufffd{w\ufffdyo d7:f1 \\st\u20ac qok\ufffd\ufffd~o kww{\u00d0\u20ac \ufffd{y{zt\ufffd{~ \ufffdsom{\ufffdo~kro \ufffdsk\ufffd zo\u00d0\u20ac yontk\n|o~q{~y k~{\ufffdzn \u20ac|omtqtm \ufffd{|tm\u20ac1 \\{\ufffdst\u20aco\u00f0\ufffdoz\ufffd. \u00d0onoqtzo k\u20acVzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f0\n*VUIO+ kz{~ykwt\u00feon yok\u20ac\ufffd~o {q\ufffdso|o~moz\ufffd {qkwwrw{lkw zo\u00d0\u20ac m{\ufffdo~kro y{zt\ufffd{~on l\u00de\nMJKS\\1 O\ufffdkww{\u00d0\u20ac \ufffd~kmtzr s{\u00d0 k\ufffd\ufffdoz\ufffdt{z \ufffd{k\u20ac|omtqtm \ufffd{|tm noqtzon l\u00de\ufffdso\u20acok~ms vo\u00de\u00d0{~n\u20ac sk\u20ac\nmskzron {\ufffdo~ \ufffdtyo kzn \u00d0so\ufffdso~ t\ufffdt\u20actzm~ok\u20actzr {~nom~ok\u20actzr1 Oz\ufffdsom\ufffd~~oz\ufffd \u20ac\ufffd\ufffdn\u00de. \u00d0oykno\n\ufffd\u20aco{q\ufffdso|\ufffdlwtm FWO |~{\ufffdtnon l\u00deMJKS\\ Vzwtzo Uo\u00d0\u20ac [\ufffdyyk~\u00de d7;f1 _o\u20aco\ufffd\ufffd|\ufffdso~o\u20acok~ms\n\u00d0t\ufffds \ufffdsoq{ww{\u00d0tzr |k~kyo\ufffdo~\u20ac>\n\u02ddRo\u00de\u00d0{~n*\u20ac+ qtown \u00d0k\u20ac\u20aco\ufffd\ufffd|\u00d0t\ufffds \ufffdsoq{ww{\u00d0tzr }\ufffdo~\u00de>\u201ccovidORcoronaORcoronavirusOR\ncovid-19ORsars-cov-2ORpfizerORastrazenecaORepidemicORpandemicORvaccineOR\nvaccinsORvaccinationORvaccinationsORlockdown\u201d\n\u02dd\\tyo Wo~t{n qtown\u20ac \u00d0o~o \u20aco\ufffd\ufffd|tz{~no~ \ufffd{lom{z\u20act\u20ac\ufffdoz\ufffd \u00d0t\ufffds \ufffdso{zo\ufffd\u20acon tz{\ufffd~kzkw\u00de\u20act\u20ac\n\u02ddStyt\ufffd \ufffd{I{\ufffdz\ufffd~\u00de qtown m{z\ufffdktzon \ufffdso\ufffdkw\ufffdo {qUnitedKingdom.NewZealand kznItaly\n\u02ddStyt\ufffd \ufffd{Skzr\ufffdkro qtown \u00d0k\u20ac\u20aco\ufffd\ufffd|\ufffd{English q{~Uo\u00d0 cokwkzn kzn \ufffdso]zt\ufffdon Rtzrn{y.\nItalian q{~O\ufffdkw\u00de1\n[tzmo \ufffdsoVUIO no|ozn\u20ac {z\ufffdsom{\ufffdo~kro |\ufffd~\u20ac\ufffdon l\u00dezo\u00d0\u20ac yontk {\ufffd\ufffdwo\ufffd\u20ac q~{y k\u20ac|omtqtm\nm{\ufffdz\ufffd~\u00de. \ufffdso\ufffd~ozn\u20ac k~oz{\ufffdyokz\ufffd \ufffd{lom{y|k~on oy|w{\u00detzr \ufffdsot~ kl\u20ac{w\ufffd\ufffdo \ufffdkw\ufffdo\u20ac1 Oz\u20ac\ufffdokn.\n\ufffdso\u20aco \ufffd~ozn\u20ac mkzlom{y|k~on l\u00deq{m\ufffd\u20actzr {z\ufffdsomskzro\u20ac \ufffdsk\ufffd sk||ozon \ufffd{\ufffdsoy k\ufffdk\u20ac|omtqtm\n\ufffdtyo1\nZo\ufffd\ufffdw\ufffd\ufffd kzn nt\ufffdm\ufffd\ufffd\ufffdt{z\nK\ufffd{w\ufffd\ufffdt{z {qIV^OJ/4= {\ufffd\ufffdl~okv\n_oqt~\u20ac\ufffd k\u20ac\u20aco\u20ac\u20ac \ufffdsoo|tnoyt{w{rtmkw \u20acmozk~t{ q{~O\ufffdkw\u00de *O\\+. Uo\u00d0 cokwkzn *Uc+. kzn \ufffdso]zt\ufffdon\nRtzrn{y *]R+ n\ufffd~tzr 53531 Ltr4~o|~o\u20acoz\ufffd\u20ac \ufffdsom\ufffdy\ufffdwk\ufffdt\ufffdo z\ufffdylo~ {qm{zqt~yon mk\u20aco\u20ac.\nnok\ufffds\u20ac kzn \ufffdsok\ufffdo~kro \u00d0oovw\u00de o\ufffd{w\ufffd\ufffdt{z {q\ufffdso[\ufffd~tzrozm\u00de Ozno\u00f0 *[O+1 \\so [Ot\u20ack\u20acmkwk~ \ufffdkw\ufffdo\nLtr41V\ufffdo~\ufffdto\u00d0 {qIV^OJ/ 4={\ufffd\ufffdl~okv tz5353 no|tm\ufffdon l\u00de>\ufffdsom\ufffdy\ufffdwk\ufffdt\ufffdo z\ufffdylo~ {qm{zqt~yo nmk\u20aco\u20ac *woq\ufffd+ kzn nok\ufffds\u20ac *ytnnwo+ .kzn \ufffdsoo\ufffd{w\ufffd\ufffdt{z\n{q\ufffdso[\ufffd~tzrozm\u00de Ozno\u00f0 *~trs\ufffd+ q{~O\ufffdkw\u00de *O\\\u0152~o| ~o\u20acoz\ufffdon tzlw\ufffdo+. Uo\u00d0 cokwkzn *Uc\u0152~o|~o \u20acoz\ufffdon tz\u00deoww{\u00d0+ kzn ]zt\ufffdon Rtzrn{y *]R\u0152~o|~ o\u20acoz\ufffdon\ntzr~ooz+1 Jk\u20acson wtzo\u20ac ~o|~o\u20acoz\ufffd \ufffdsoqt~\u20ac\ufffd |wk\ufffdok\ufffd {q\ufffdsom{~~o\u20ac|{zn tzryo\ufffd~tm q{~okms m{\ufffdz\ufffd~\u00de. \u00d0t\ufffds kmskzro ~k\ufffdt{ low{\u00d0 \ufffdskz 4&1\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u {\ufffd~zkw1|{zo 135:;3551r334\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 :247\n\ufffdsk\ufffd }\ufffdkz\ufffdtqto\u20ac \ufffdso\u20ac\ufffd~ozr\ufffds {q\ufffdsom{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac kn{|\ufffdon kzn t\ufffd~kzro\u20ac q~{y 3*z{\noqq{~\ufffd kn{|\ufffdon+ \ufffd{433*\u20acoo [om\ufffdt{z tzTk\ufffdo~tkw\u20ac kzn yo\ufffds{n\u20ac q{~y{~o no\ufffdktw\u20ac+1\nL~{y \ufffdsowoq\ufffdkzn ytnnwo |kzow {qLtr4\u00d0o{l\u20aco~\ufffdo s{\u00d0 kwwm{\ufffdz\ufffd~to\u20ac \u00d0o~o msk~km\ufffdo~t\u00feon l\u00de\nk~k|tn tzm~ok\u20aco {ql{\ufffds m{zqt~yon mk\u20aco\u20ac kzn nok\ufffds\u20ac tz\ufffdsotzt\ufffdtkw |sk\u20aco {q\ufffdso|kznoytm1 Uo\u00d0\ncokwkzn ~o\u20ac\ufffdw\ufffd\u20ac tzlotzr \ufffdsoqt~\u20ac\ufffd m{\ufffdz\ufffd~\u00de \ufffd{~okms k|wk\ufffdok\ufffd tz\ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdsoyo\ufffd~tm\u20ac. q{w/\nw{\u00d0on l\u00deO\ufffdkw\u00de kzn \ufffdso]zt\ufffdon Rtzrn{y1 Oz\ufffdo~y\u20ac {qm{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac. \ufffdso~trs\ufffd |kzow {q\nLtr4\u20acs{\u00d0\u20ac s{\u00d0 O\ufffdkw\u00de t\u20ac\ufffdsom{\ufffdz\ufffd~\u00de \u00d0t\ufffds \ufffdsook~wto\u20ac\ufffd ~o\u20ac|{z\u20aco. \u00d0t\ufffds t\ufffd\u20ac[O\ufffdkw\ufffdo tzm~ok\u20actzr\nq~{y 4=177 \ufffd{:=1=4 {zLol~\ufffdk~\u00de 56~n1 Uo\u00d0 cokwkzn ~o\u20ac\ufffdw\ufffd\u20ac tzlotzr \ufffdsom{\ufffdz\ufffd~\u00de \u00d0t\ufffds \ufffdsostrs/\no\u20ac\ufffd\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac yok\u20ac\ufffd~o\u20ac. ~okmstzr k[O\ufffdkw\ufffdo {q=:163 {zTk~ms 56~n tzm{~~o\u20ac|{znozmo \u00d0t\ufffds \ufffdso\ntz\ufffd~{n\ufffdm\ufffdt{z {q\ufffdsot~ qt~\u20ac\ufffd w{mvn{\u00d0z1 Ltzkww\u00de. \ufffdsor{\ufffdo~zyoz\ufffd {q\ufffdso]zt\ufffdon Rtzrn{y. no\u20ac|t\ufffdo\nt\ufffd\u20acnowk\u00deon ~okm\ufffdt{z. k||wton \ufffdso~o\u20ac\ufffd~tm\ufffdt{z yok\u20ac\ufffd~o\u20ac y{~o |o~ykzoz\ufffdw\u00de> t\ufffdozq{~mon 4::nk\u00de\u20ac\n{qw{mvn{\u00d0z krktz\u20ac\ufffd \ufffdso;;q~{y O\ufffdkw\u00de kzn \ufffdso;6q~{y Uo\u00d0 cokwkzn1\nY\ufffdkz\ufffdtq\u00detzr zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z kzn {zwtzo yontk m{\ufffdo~kro\n\\{msk~km\ufffdo~t\u00feo \ufffdso{zwtzo qw{\u00d0tzr {qtzq{~yk\ufffdt{z. \u00d0o}\ufffdkz\ufffdtq\u00de \ufffdsoky{\ufffdz\ufffd {q}\ufffdo\u20ac\ufffdt{zklwo\nkzn ~owtklwo |{\u20ac\ufffd\u20ac mt~m\ufffdwk\ufffdtzr tz\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac1 \\{n{\u20ac{.\u00d0omk\ufffdor{~t\u00feo |{\u20ac\ufffd\u20ac tz\ufffd{ Y\ufffdo\u20ac/\n\ufffdt{zklwo kzn Zowtklwo kmm{~ntzr \ufffd{\ufffdso\ufffd~\ufffd\u20ac\ufffd\u00d0{~\ufffdstzo\u20ac\u20ac {q\ufffdso~oqo~~on zo\u00d0\u20ac \u20ac{\ufffd~mo *\u20acoo [om\ufffdt{z\nq{~y{~o tzq{~yk\ufffdt{z+1 \\so woq\ufffd|kzow {qLtr5\u20acs{\u00d0\u20ac s{\u00d0 \ufffdsozo\u00d0\u20ac nto\ufffd tz\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac\nt\u20ac\u20acsk|on l\u00de\ufffdso|~o\u20acozmo {q~owtklwo |{\u20ac\ufffd\u20ac1 T{~o{\ufffdo~. ~trs\ufffd |kzow {qLtr5no\u20acm~tlo\u20ac s{\u00d0 O\ufffdkw\u00de\nLtr51Soq\ufffd |kzow> F\ufffdo~kro \u00d0oovw\u00de z\ufffdylo~ {q|{\u20ac\ufffd\u20ac \ufffdsk\ufffd mt~m\ufffdwk\ufffdon {zLkmol{{v q{~O\ufffdkw\u00de *\ufffd||o~+. Uo\u00d0 cokwkzn *ytnnwo+ kzn \ufffdso]zt\ufffdon Rtzrn{y\n*l{\ufffd\ufffd{y+. \u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{\ufffdsozo\u00d0\u20ac {\ufffd\ufffdwo\ufffd mk\ufffdor{~\u00de1 Ztrs\ufffd |kzow> F\ufffdo~kro \u00d0oovw\u00de z\ufffdylo~ {q|{\u20ac\ufffd tz\ufffdo~km\ufffdt{z\u20ac q{~O\ufffdkw\u00de *\ufffd||o~+. Uo\u00d0 cokwkzn *ytnnwo+\nkzn \ufffdso]zt\ufffdon Rtzrn{y *l{\ufffd\ufffd{y +.\u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{\ufffdsozo\u00d0\u20ac {\ufffd\ufffdwo\ufffd mk\ufffdor{~\u00de {q\ufffdso|{\u20ac\ufffd \ufffdsotz\ufffdo~km\ufffdt{z\u20ac ~oqo~ \ufffd{1\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u {\ufffd~zkw1|{zo 135:;3551r335\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 ;247\nkzn Uo\u00d0 cokwkzn |~{n\ufffdmo kstrso~ wo\ufffdow {qozrkroyoz\ufffd q{~~owtklwo |{\u20ac\ufffd\u20ac1 \\so ]zt\ufffdon Rtzr/\nn{y. {||{\u20act\ufffdow\u00de. \u20acs{\u00d0\u20ac k|~oqo~ozmo \ufffd{\u00d0k~n\u20ac }\ufffdo\u20ac\ufffdt{zklwo m{z\ufffdoz\ufffd\u20ac \ufffds~{\ufffdrs{\ufffd\ufffd kww\ufffdso\u00deok~1\n\\{q\ufffd~\ufffdso~ o\u00f0\ufffdozn \ufffdso\u20ac\ufffd\ufffdn\u00de {q\ufffdsozo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z. \u00d0o{l\u20aco~\ufffdo \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdso\n{zwtzo zo\u00d0\u20ac yontk m{\ufffdo~kro kl{\ufffd\ufffd IV^OJ/4= tz\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac1 _ooy|w{\u00de kyok\u20ac\ufffd~o\nmkwwon Vzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f0 *VUIO+ m{y|\ufffd\ufffdon {znk\ufffdk q~{y MJKS\\ *Mw{lkw Jk\ufffdk {z\nK\ufffdoz\ufffd\u20ac. S{mk\ufffdt{z. kzn \\{zo+ [\ufffdyyk~\u00de |~{uom\ufffd *\u20acoo [om\ufffdt{z q{~q\ufffd~\ufffdso~ no\ufffdktw\u20ac+1 Ltr6\u20acs{\u00d0\u20ac \ufffdso\nz{~ykwt\u00feon o\ufffd{w\ufffd\ufffdt{z {q\ufffdsoVzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f0 *VUIO+ q{~okms {q\ufffdso\ufffds~oo m{\ufffdz/\n\ufffd~to\u20ac1 _o{l\u20aco~\ufffdo s{\u00d0 m{\ufffdo~kro \ufffd~ozn\u20ac q~{y Uo\u00d0 cokwkzn kzn ]zt\ufffdon Rtzrn{y ~o\u20acoylwo\u20ac \ufffdso\n|{\u20ac\ufffdtzr losk\ufffdt{~\u20ac tzLtr5.\u20ac\ufffd\u20ac\ufffdktzon l\u00dekWok~\u20ac{z \u20acm{~o {q31<kzn 31=m{y|\ufffd\ufffdon lo\ufffd\u00d0ooz\nVUIO kzn \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdso\ufffd{\ufffdkw z\ufffdylo~ {q|{\u20ac\ufffd\u20ac tz\ufffdso\ufffd\u00d0{m{\ufffdz\ufffd~to\u20ac. ~o\u20ac|om\ufffdt\ufffdow\u00de1 O\ufffdkw\u00de.\ntz\u20ac\ufffdokn. \u20acs{\u00d0\u20ac kz{zwtzo m{\ufffdo~kro \ufffd~ozn \u00d0stms ~kt\u20aco\u20ac tz\ufffdsoozn {q5353. \u00d0stms yk\u00de lok\ufffd\ufffd~tl/\n\ufffd\ufffdklwo \ufffd{\ufffdso\u20ac\ufffdk~\ufffd {q\ufffdso\ufffdkmmtzk\ufffdt{z mky|ktrz\u20ac1\nOz\u20ac\ufffdyyk~\u00de. \u00d0o|~{\ufffdtno o\ufffdtnozmo kl{\ufffd\ufffd s{\u00d0 \ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac k~omsk~km\ufffdo~t\u00feon l\u00dek~owt/\nklwo zo\u00d0\u20ac nto\ufffd kl{\ufffd\ufffd IV^OJ/4= tz5353. \u00d0t\ufffds o\ufffd{w\ufffd\ufffdt{z tzwtzo\u00d0t\ufffds \ufffdso{zwtzo zo\u00d0\u20ac yontk\nm{\ufffdo~kro kl{\ufffd\ufffd \ufffdsoIV^OJ/4= \ufffd{|tm1 Oz\ufffdo~y\u20ac {qozrkroyoz\ufffd. \u00d0o{l\u20aco~\ufffdo \ufffdsk\ufffd \ufffdso]zt\ufffdon\nRtzrn{y t\u20ac\ufffdso{zw\u00de m{\ufffdz\ufffd~\u00de \u00d0so~o }\ufffdo\u20ac\ufffdt{zklwo |{\u20ac\ufffd\u20ac ~omot\ufffdo y{~o k\ufffd\ufffdoz\ufffdt{z \ufffdskz ~owtklwo\n{zo\u20ac1 Ozm{z\ufffd~k\u20ac\ufffd. O\ufffdkw\u00de kzn Uo\u00d0 cokwkzn k~onoqtzon l\u00dekr~ok\ufffdo~ kozrkroyoz\ufffd \ufffd{\u00d0k~n\u20ac ~owt/\nklwo zo\u00d0\u20ac \u00d0stms t\u20ac\u20ac\ufffd\u20ac\ufffdktzon \ufffds~{\ufffdrs{\ufffd\ufffd \ufffdsooz\ufffdt~o kzkw\u00de\u20act\u20ac |o~t{n1\nF\u20ac\u20aco\u20ac\u20actzr \ufffdso~{wo {qIV^OJ/4= qkm\ufffd{~\u20ac tzzo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z\n\\{}\ufffdkz\ufffdtq\u00de \ufffdsotz\ufffdo~|wk\u00de lo\ufffd\u00d0ooz \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdsozo\u00d0\u20ac mt~m\ufffdwk\ufffdtzr {zwtzo kzn ntqqo~oz\ufffd\nk\u20ac|om\ufffd\u20ac {q\ufffdso|kznoytm. \u00d0om~ok\ufffdo k\u20aco\ufffd{qqok\ufffd\ufffd~o\u20ac q~{y \ufffdso{zo\u20ac |~o\u20acoz\ufffdon tz[om\ufffdt{z kzn1\nLtr61K\ufffd{w\ufffd\ufffdt{ z{q\ufffdsoz{~ykwt\u00feon Vzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f0 *VUIO+ q{~O\ufffdkw\u00de *lw\ufffdo+. Uo\u00d0 cokwkzn *\u00deoww{\u00d0+ kzn \ufffdso]zt\ufffdon Rtzrn{y *r~ooz+1\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u {\ufffd~zkw1|{zo 135:;3551r336\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 <247\n\\st\u20ac \u20aco\ufffdm{z\ufffdktz\u20ac \ufffdso[O.\ufffdsom{zqt~yon z\ufffdylo~ {qIV^OJ/4= mk\u20aco\u20ac kzn \ufffdsoVUIO1 Ltr7\nno\u20acm~tlo\u20ac \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \u20ac\ufffdms qkm\ufffd{~\u20ac l\u00deyokz\u20ac {qWok~\u20ac{z)\u20ac \u20acm{~o\u20ac q{~O\ufffdkw\u00de *woq\ufffd+.\nUo\u00d0 cokwkzn *ytnnwo+ kzn \ufffdso]zt\ufffdon Rtzrn{y *~trs\ufffd+1 _o{l\u20aco~\ufffdo \ufffdsk\ufffd [Osk\u20ack\u20ac\ufffd~{zr |{\u20act/\n\ufffdt\ufffdom{~~owk\ufffdt{z \u00d0t\ufffds \ufffdsoz\ufffdylo~ {q|{\u20ac\ufffd\u20ac tzkww\ufffds~oo m{\ufffdz\ufffd~to\u20ac \u00d0t\ufffds \ufffdkw\ufffdo\u20ac \ufffdsk\ufffd ~kzro q~{y 31;\n\ufffd{31=.yokztzr \ufffdsk\ufffd \ufffdso\ufffdtrs\ufffdoztzr {q\ufffdso~o\u20ac\ufffd~tm\ufffdt{z r{o\u20ac \ufffd{ro\ufffdso~ \u00d0t\ufffds kztzm~ok\u20aco {q\ufffdso\n{zwtzo nolk\ufffdo \ufffd{w\ufffdyo1 VUIO. tz\u20ac\ufffdokn. sk\u20ackm{~~owk\ufffdt{z \u00d0t\ufffds \ufffdsoz\ufffdylo~ {q|{\u20ac\ufffd\u20ac {q316tzO\ufffdkw\u00de\nkzn 31<kzn 31=tz\ufffdso{\ufffdso~ m{\ufffdz\ufffd~to\u20ac. \u20acs{\u00d0tzr \ufffdsom{z\u20act\u20ac\ufffdozm\u00de lo\ufffd\u00d0ooz \ufffdso\ufffd{w\ufffdyo\ufffd~tm \ufffd~ozn\n{q\ufffdso{zwtzo zo\u00d0\u20ac m{\ufffdo~kro tzkm{\ufffdz\ufffd~\u00de kzn \ufffdso\ufffd{w\ufffdyo {q\ufffdsonolk\ufffdo {z\u20ac{mtkw yontk1 Ltzkww\u00de.\n\ufffdsoz\ufffdylo~ {qmk\u20aco\u20ac \u20acs{\u00d0\u20ac kwkmv {qm{~~owk\ufffdt{z \u00d0t\ufffds \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q|{\u20ac\ufffd\u20ac tz]zt\ufffdon Rtzrn{y.\no\u00f0|~o\u20ac\u20acon l\u00dekWok~\u20ac{z \u20acm{~o {q314.\u20ac\ufffdrro\u20ac\ufffdtzr s{\u00d0 \ufffdso\u20ac{mtkw yontk nolk\ufffdo tz\ufffdsom{\ufffdz\ufffd~\u00de\nyk\u00de lo~owk\ufffdon \ufffd{q\ufffd~\ufffdso~ qkm\ufffd{~\u20ac1 O\ufffdkw\u00de kzn Uo\u00d0 cokwkzn tz\u20ac\ufffdokn |~{\ufffdtno k\u20ac\ufffd~{zro~ |{\u20act\ufffdt\ufffdo\n~owk\ufffdt{z\u20acst| \u00d0t\ufffds k\ufffdkw\ufffdo {q31:kzn 31;~o\u20ac|om\ufffdt\ufffdow\u00de. no\u20acm~tltzr s{\u00d0 \ufffdso|\ufffdlwtm nolk\ufffdo t\u20actzqw\ufffd/\nozmon l\u00de\ufffdso\u20aco\ufffdo~t\ufffd\u00de {q\ufffdso|kznoytm {\ufffd\ufffdl~okv1\nL{~okms {q\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac kzkw\u00de\u00feon. \u00d0ooy|w{\u00de \ufffdsoqkm\ufffd{~\u20ac m{z\u20actno~on tzLtr7\ufffd{\ny{now \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdsoz\ufffdylo~ {q|{\u20ac\ufffd\u20ac {zLkmol{{v l\u00deyokz\u20ac {qwtzok~ VS[ ~or~o\u20ac\u20act{z {q\n\ufffdsoq{~y\nNBofPosts\u0088k6\u0087k7ONCI\u0087k9SI\u0087k:NBofCases \u00859\u0086\nZo\u20ac\ufffdw\ufffd\u20ac tz\\klwo 7no\u20acm~tlo \ufffdsoo\u20ac\ufffdtyk\ufffd{~\u20ac {l\ufffdktzon q~{y \ufffdso~or~o\u20ac\u20act{z tz\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac1\nOzrozo~kw. \u00d0o{l\u20aco~\ufffdo \ufffdsk\ufffd. q{~okms {q\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac. \ufffdsowtzok~ ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdso\nN.ofPosts kznONCI kznN.ofCases t\u20ac\u20actrztqtmkz\ufffd *k\ufffdkwo\ufffdow {q3139+1 \\st\u20ac \u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd \ufffdso\nm{z\u20ac\ufffdy|\ufffdt{z {q|{\u20ac\ufffd\u20ac tz\u20ac{mtkw yontk t\u20acm{~~owk\ufffdon \ufffd{l{\ufffds \ufffdsomskzro tz\ufffdsoo|tnoyt{w{rtmkw\n\u20acmozk~t{ kzn \ufffdso|kznoytm yontk m{\ufffdo~kro1 L{~O\ufffdkw\u00de kzn Uo\u00d0 cokwkzn \ufffdsoN.ofPosts |\ufffdl/\nwt\u20acson {zLkmol{{v t\u20acnt~om\ufffdw\u00de |~{|{~\ufffdt{zkw \ufffd{\ufffdso\ufffds~oo o\u00f0|wkzk\ufffd{~\u00de qkm\ufffd{~\u20ac \u00d0ooy|w{\u00deon tz\n{\ufffd~y{now> tz\ufffdso\u20aco m{\ufffdz\ufffd~to\u20ac. |kro\u20ac kzn r~{\ufffd|\u20ac k~oy{~o wtvow\u00de \ufffd{|{\u20ac\ufffd \u00d0soz \ufffdsoo|tnoyt{w{rt/\nmkw\u20act\ufffd\ufffdk\ufffdt{z \u00d0{~\u20acoz\u20ac. \ufffdso|kznoytm zo\u00d0\u20ac yontk m{\ufffdo~kro tzm~ok\u20aco\u20ac. kzn \ufffdsoy{ltwt\ufffd\u00de ~o\u20ac\ufffd~tm/\n\ufffdt{z yok\u20ac\ufffd~o\u20ac lom{yo\u20ac y{~o \u20ac\ufffd~tm\ufffd1 Oz\u20ac\ufffdokn. q{~\ufffdso]zt\ufffdon Rtzrn{y \ufffdsom{~~owk\ufffdt{z lo\ufffd\u00d0ooz\n\ufffdsoN.ofPosts kzn \ufffdsoN.ofCases t\u20aczork\ufffdt\ufffdo *o}\ufffdkw \ufffd{\u22123144 \u00d0t\ufffds k\u20ac\ufffdkznk~n o~~{~ {q3135. \u20actr/\nztqtmkz\ufffd k\ufffdkwo\ufffdow {q3139+1 T{~o{\ufffdo~. \ufffdsowtzok~ ~owk\ufffdt{z lo\ufffd\u00d0ooz \ufffdsoN.ofPosts kzn \ufffdsoSIt\u20ac\nz{\ufffd\u20actrztqtmkz\ufffd *k\ufffdkwo\ufffdow {q3139+. \u20ac\ufffdrro\u20ac\ufffdtzr \ufffdsk\ufffd \ufffdso\ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdsor{\ufffdo~zyoz\ufffd ~o\u20ac|{z\u20aco\nLtr71Wok~\u20ac{z)\u20ac m{~~owk\ufffdt{ zm{oqqtmtoz\ufffd ky{zr VUIO *Vzwtzo Uo\u00d0\u20ac I{\ufffdo~kro Ozno\u00f0+. [O*[\ufffd~tzrozm \u00deOzno\u00f0+. U\ufffdylo~ {qIV^OJ/ 4=I{zqt~yo nIk\u20aco\u20ac\nkzn W{\u20ac\ufffd\u20ac m{y|\ufffd\ufffdon {zk\u00d0oovw\u00de lk\u20aco q{~O\ufffdkw\u00de *woq\ufffd+. Uo\u00d0 cokwkzn *ytnnwo+ kzn]zt\ufffdon Rtzrn{y *~trs\ufffd+1\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u {\ufffd~zkw1|{zo 135:;3551r337\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 =247\nt\u20acz{\ufffdm{~~owk\ufffdon \u00d0t\ufffds \ufffdso\ufffd~ozn {q\ufffdsotzq{noytm1 \\s\ufffd\u20ac. q{~\ufffdso]zt\ufffdon Rtzrn{y \ufffdsotzq{noytm\n\ufffd{w\ufffdyo tzm~ok\u20aco\u20ac \u00d0t\ufffds \ufffdsozo\u00d0\u20ac yontk m{\ufffdo~kro \ufffd{w\ufffdyo kzn nom~ok\u20aco\u20ac \u00d0t\ufffds \ufffdsoz\ufffdylo~ {q\nIV^OJ/4= mk\u20aco\u20ac1\nI{zmw\ufffd\ufffdt{z\ufffd\nOz\ufffdst\u20ac\u00d0{~v. \u00d0o|o~q{~y km{y|k~k\ufffdt\ufffdo kzkw\u00de\u20act\u20ac {z\ufffds~oo m{\ufffdz\ufffd~to\u20ac. zkyow\u00de O\ufffdkw\u00de. Uo\u00d0 cok/\nwkzn. kzn \ufffdso]zt\ufffdon Rtzrn{y. \u00d0stms o\u00f0|o~tozmon ntqqo~oz\ufffd o|tnoytm \u20acmozk~t{\u20ac kzn kn{|\ufffdon\nntqqo~oz\ufffd m{z\ufffdktzyoz\ufffd \u20ac\ufffd~k\ufffdorto\u20ac q{~\ufffdsoIV^OJ/4= {\ufffd\ufffdl~okv1 Lt~\u20ac\ufffd. \u00d0o}\ufffdkz\ufffdtq\u00de \ufffdsoo|tnoyt{/\nw{rtmkw n\u00dezkytm\u20ac kzn \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdsom{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac \ufffdsk\ufffd msk~km\ufffdo~t\u00feon okms m{\ufffdz/\n\ufffd~\u00de1\\soz. \u00d0oo\u20ac\ufffdtyk\ufffdo \ufffdso|{\ufffdoz\ufffdtkw \ufffd{w\ufffdyo {q\ufffdsotzq{noytm \u00d0t\ufffds \ufffdsoz\ufffdylo~ {q|{\u20ac\ufffd\u20ac\nmt~m\ufffdwk\ufffdtzr. \ufffdso\ufffd\u20aco~ ozrkroyoz\ufffd \ufffdsk\ufffd \ufffdso|{\u20ac\ufffd\u20ac \u20ac|k~von. kzn m{\ufffdo~kro {qIV^OJ/4= l\u00de\ufffdso\nzk\ufffdt{zkw zo\u00d0\u20ac yontk1 Ltzkww\u00de. \u00d0o\u20ac\ufffd\ufffdn\u00de \ufffdsom{~~owk\ufffdt{z lo\ufffd\u00d0ooz \ufffdso\u20ac|~okn {qtzq{~yk\ufffdt{z kzn\n\u20aco\ufffdo~kw qkm\ufffd{~\u20ac o\u00f0|~o\u20ac\u20actzr ntqqo~oz\ufffd qkmo\ufffd\u20ac {q\ufffdso|kznoytm kzn tzq{noytm1\nV\ufffd~ qtzntzr\u20ac \u20acs{\u00d0 \ufffdsk\ufffd \ufffdsotzq{noytm o\ufffd{w\ufffd\ufffdt{z yk\u00de tzm~ok\u20aco \u00d0t\ufffds \ufffdso\ufffd{w\ufffdyo {q\ufffdso{zwtzo\nzo\u00d0\u20ac m{\ufffdo~kro kl{\ufffd\ufffd IV^OJ/4= tzkww\ufffdso\ufffds~oo m{\ufffdz\ufffd~to\u20ac1 T{~o{\ufffdo~. \ufffdsom{z\ufffdktzyoz\ufffd yok/\n\u20ac\ufffd~o\u20ac \ufffdtrs\ufffdoztzr k~om{~~owk\ufffdo \u00d0t\ufffds k|{\ufffdoz\ufffdtkw tzm~ok\u20aco tz\ufffdso\ufffd{w\ufffdyo {q\ufffdsotzq{noytm tzO\ufffdkw\u00de\nkzn Uo\u00d0 cokwkzn. l\ufffd\ufffdt\ufffd\u20acoqqom\ufffd t\u20acz{\ufffd\u20actrztqtmkz\ufffd tz]R1 Oz\ufffdo~y\u20ac {qzo\u00d0\u20ac nto\ufffd m{y|{\u20act\ufffdt{z. \u00d0o\n{l\u20aco~\ufffdo k|~on{ytzkz\ufffd mt~m\ufffdwk\ufffdt{z {q~owtklwo zo\u00d0\u20ac1 Oznoon. tzO\ufffdkw\u00de kzn Uo\u00d0 cokwkzn \ufffd\u20aco~\u20ac\ntz\ufffdo~km\ufffd y{~o \u00d0t\ufffds ~owtklwo \u20ac{\ufffd~mo\u20ac. \u00d0stwo tz\ufffdso]zt\ufffdon Rtzrn{y \ufffdso\u00de k||ok~ \ufffd{loy{~o\ntz\ufffd{w\ufffdon \u00d0t\ufffds zo\u00d0\u20ac ~oqo~~tzr \ufffd{}\ufffdo\u20ac\ufffdt{zklwo \u20ac{\ufffd~mo\u20ac1\nV\ufffd~ ~or~o\u20ac\u20act{z ~o\u20ac\ufffdw\ufffd\u20ac \u20ac\ufffdrro\u20ac\ufffd \ufffdsk\ufffd \ufffdsotzq{noytm yk\u00de sk\ufffdo k\u20actrztqtmkz\ufffd ~owk\ufffdt{z\u20acst| \u00d0t\ufffds\nl{\ufffds \u20ac{mt{/o|tnoyt{w{rtmkw qkm\ufffd{~\u20ac. \u20ac\ufffdms k\u20ac\ufffdsoz\ufffdylo~ {qmk\u20aco\u20ac kzn \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {q\ufffdsom{z/\n\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac. kzn \ufffdsok\ufffd\ufffdoz\ufffdt{z {q\ufffdso\ufffd~knt\ufffdt{zkw yontk. so~o }\ufffdkz\ufffdtqton l\u00de\ufffdso\ufffd{w\ufffdyo\n{q\ufffdsozo\u00d0\u20ac yontk m{\ufffdo~kro1 T{~o \u20ac|omtqtmkww\u00de. \ufffdsotzm~ok\u20aco {q|tomo\u20ac {qm{z\ufffdoz\ufffd\u20ac tz\ufffdso]zt\ufffdon\nRtzrn{y k||ok~\u20ac \ufffd{lok\u20ac\u20ac{mtk\ufffdon yktzw\u00de \u00d0t\ufffds \ufffdsoo\ufffd{w\ufffd\ufffdt{z {q\ufffdso{zwtzo zo\u00d0\u20ac yontk m{\ufffdo~/\nkro. \u00d0stw\u20ac\ufffd kz\u00detzm~ok\u20aco tz\ufffdsoo|tnoyt{w{rtmkw yo\ufffd~tm\u20ac t\u20ack\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds k~on\ufffdm\ufffdt{z {q|{\u20ac\ufffd\u20ac\nmt~m\ufffdwk\ufffdtzr1 OzO\ufffdkw\u00de kzn tzUo\u00d0 cokwkzn \ufffdsor~{\u00d0\ufffds {q\ufffdsotzq{noytm t\u20ack\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds kz\ntzm~ok\u20aco tzkz\u00de{q\ufffdsoqkm\ufffd{~\u20ac m{z\u20actno~on1\n_oqtzn \ufffdsk\ufffd \ufffdso{zr{tzr IV^OJ/4= |kznoytm sk\u20ackm{y|wo\u00f0 tz\ufffdo~km\ufffdt{z \u00d0t\ufffds \ufffdsoo\ufffd{w\ufffd/\n\ufffdt{z {q\ufffdsotzq{noytm. l{\ufffds q~{y k\ufffd\u20aco~ kzn kyontk |o~\u20ac|om\ufffdt\ufffdo1 L~{y kr{\ufffdo~zkzmo |o~\u20ac|om/\n\ufffdt\ufffdo. \ufffdso\u20aco qtzntzr\u20ac ~kt\u20aco \ufffdso\ufffd~rozm\u00de \ufffd{no\ufffdow{| |\ufffdlwtm sokw\ufffds ~or\ufffdwk\ufffdt{z\u20ac \ufffdsk\ufffd ~om{rzt\u00feo \ufffdso\ntz\ufffdo~|wk\u00de lo\ufffd\u00d0ooz \ufffdso{zwtzo kzn \ufffdso{qqwtzo \u00d0{~wn1 \ufffdOznoon. \ufffdsoo\u00f0t\u20ac\ufffdozmo {qk~{wo q{~\ufffdso\\klwo 71Zo\u20ac\ufffdw\ufffd\u20ac q{~~or~o\u20ac\u20act{z {\ufffdo~ \ufffdso\u00d0oov\u20ac \u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{\ufffdsok\ufffdo~kro z\ufffdylo~ {q|{\u20ac\ufffd\u20ac tzkm{\ufffdz\ufffd~\u00de \u00d0t\ufffds y\ufffdw\ufffdt|wo m{z\ufffd~{w \u20ac>VUIO. [\ufffd~tzroz m\u00deOzno\u00f0 *[O+ kzn \ufffdso\nz\ufffdylo~ {qIV^OJ/4= m{zqt~yon mk\u20aco\u20ac1\nI{\ufffdz\ufffd~\u00de Oz\ufffdo~mo|\ufffd VUIO lq[O U1{qIk\u20aco\u20ac R5\nO\\ /79;14\n*434;+<4943\ufffd\n*69793+;;17\ufffd\ufffd\ufffd\n*4913<+313;<\ufffd\ufffd\n*3135=+31:3\n]R /6434\ufffd\ufffd\ufffd\n*<7=17+<:7=\ufffd\ufffd\ufffd\n*<9717+/94153 1\n*5:13:+/3144\ufffd\ufffd\ufffd\n*3135+31<9\nUc /5761<=\ufffd\n*44416<+9:4;14<\ufffd\ufffd\ufffd\n*46<6177+451<5\ufffd\ufffd\ufffd\n*614;+461:=\ufffd\ufffd\ufffd\n*619;+31<;\n\\so \u20ac\ufffdkznk~n o~~{~\u20ac {q\ufffdsom{oqqtmtoz\ufffd \u20ack~o~o|{~\ufffdon tz|k~oz\ufffdso\u20act\u20ac. \u00d0stw\u20ac\ufffd \ufffdsok\u20ac\ufffdo~t\u20acv\u20ac ~oqo~ \ufffd{\ufffdso\u20actrztqtmkzmo {q\ufffdsot~ |/\ufffdkw\ufffdo\u20ac tz\ufffdsoq{ww{\u00d0tzr \u00d0k\u00de>\n\ufffd\ufffd\ufffdPD31334.\n\ufffd\ufffdPD3134.\n\ufffdPD3139.\n1PD314.\nj)PD41\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 135:;3551\ufffd337\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 43247\nz\ufffdylo~ {qmk\u20aco\u20ac. \ufffdsozo\u00d0\u20ac yontk m{\ufffdo~kro. kzn \ufffdso\u20ac\ufffd~tm\ufffdzo\u20ac\u20ac {qm{z\ufffdktzyoz\ufffd yok\u20ac\ufffd~o\u20ac tz\ufffdso\no\ufffd{w\ufffd\ufffdt{z {qtzq{noytm t\u20ack|t\ufffd{\ufffdkw |{tz\ufffd q{~|{wtm\u00de/ykvo~\u20ac \ufffd{\ufffdkvo nomt\u20act{z\u20ac q{~\ufffdso\u20ackqo\ufffd\u00de {q\nm{yy\ufffdzt\ufffd\u00de yoylo~\u20ac1 [\ufffdms nomt\u20act{z\u20ac \u20acs{\ufffdwn m{z\u20actno~ \ufffdsk\ufffd oqqom\ufffdt\ufffdo m{yy\ufffdztmk\ufffdt{z \u20ac\ufffd~k\ufffdorto\u20ac\ny\ufffd\u20ac\ufffd lono\ufffdow{|on kzn q{ww{\u00d0on \u00d0soz |\ufffdlwt\u20acstzr kzn mt~m\ufffdwk\ufffdtzr zo\u00d0\u20ac. vz{\u00d0tzr \ufffdsk\ufffd |o{|wo.\no\u20ac|omtkww\u00de n\ufffd~tzr k\u20aco\ufffdo~o o|tnoytm \u20ac|~okntzr. yk\u00de loy{~o \u20ac\ufffd\u20acmo|\ufffdtlwo \ufffd{\ufffdsom{z\ufffdoz\ufffd |~{/\n|{\u20acon1 L\ufffd~\ufffdso~y{~o. q\ufffd~\ufffdso~ km\ufffdt{z\u20ac k~o~o}\ufffdt~on \ufffd{tzm~ok\u20aco mt\ufffdt\u00feoz k\u00d0k~ozo\u20ac\u20ac kzn \ufffdzno~/\n\u20ac\ufffdkzntzr {q\ufffdso|kznoytm1 Fm{zm~o\ufffdo k||~{kms yk\u00de tzmw\ufffdno \ufffdsono\ufffdow{|yoz\ufffd {qo|tnoytm\nwt\ufffdo~km\u00de |~{r~ky\u20ac. \ufffdsotz\ufffd~{n\ufffdm\ufffdt{z {qtz\ufffdo~nt\u20acmt|wtzk~\u00de {l\u20aco~\ufffdk\ufffd{~to\u20ac \ufffdsk\ufffd }\ufffdkz\ufffdtq\u00de \ufffdsotz\ufffdo~/\nm{zzom\ufffdt{z lo\ufffd\u00d0ooz \ufffdso\ufffd\u00d0{om{\u20ac\u00de\u20ac\ufffdoy\u20ac \u00d0t\ufffds \ufffdsotz\ufffd{w\ufffdoyoz\ufffd {qty|km\ufffdon m{yy\ufffdzt\ufffdto\u20ac1\nFyku{~ wtyt\ufffdk\ufffdt{z \ufffd{\ufffdsokzkw\u00de\u20act\u20ac \u00d0om{zn\ufffdm\ufffdon t\u20ac\ufffdsok\ufffdktwkltwt\ufffd\u00de {q\u20ac{mtkw zo\ufffd\u00d0{~v\u20ac nk\ufffdk1\nLt~\u20ac\ufffd. k\u20acI~{\u00d0n\\kzrwo n{o\u20ac z{\ufffd|~{\ufffdtno \ufffdsom{z\ufffdoz\ufffd {q\ufffdsom{yyoz\ufffd\u20ac. \u00d0omkzz{\ufffd tz\ufffdo\u20ac\ufffdtrk\ufffdo\n\u00d0so\ufffdso~ |o{|wo k~otzmwtzon \ufffd{\u20ac|ky \ufffdsom{yyoz\ufffd \u20acom\ufffdt{z \u00d0t\ufffds yt\u20acwokntzr mwkty\u20ac o\ufffdoz tq\ufffdso\n{~trtzkw |{\u20ac\ufffd {zw\u00de |~o\u20acoz\ufffd\u20ac m~ontlwo tzq{~yk\ufffdt{z1 _ok~ok\u00d0k~o \ufffdsk\ufffd \ufffdst\u20acyo\ufffds{n{w{r\u00de ~on\ufffdmo\u20ac\n\ufffdso\u20ac\ufffd\ufffdn\u00de \u20acky|wo. \u00d0stms I~{\u00d0n\\kzrwo kw~okn\u00de ~o\u20ac\ufffd~tm\ufffd\u20ac \u20actzmo t\ufffd|~{\ufffdtno\u20ac {zw\u00de |{\u20ac\ufffd\u20ac q~{y |\ufffdlwtm\nLkmol{{v |kro\u20ac \u00d0t\ufffds y{~o \ufffdskz 59R Wkro Stvo\u20ac {~L{ww{\u00d0o~\u20ac. |\ufffdlwtm Lkmol{{v r~{\ufffd|\u20ac \u00d0t\ufffds k\ufffd\nwok\u20ac\ufffd =9R yoylo~\u20ac. kww][/lk\u20acon |\ufffdlwtm r~{\ufffd|\u20ac \u00d0t\ufffds k\ufffdwok\u20ac\ufffd 5Ryoylo~\u20ac kzn kww\ufffdo~tqton |~{/\nqtwo\u20ac1 d7<f1 L\ufffd~\ufffdso~y{~o. \ufffdso|~o\ufffdkwozmo {q~owtklwo zo\u00d0\u20ac yk\u00de o\ufffdtnozmo \ufffdso|{\u20act\ufffdt\ufffdo m{yyt\ufffd/\nyoz\ufffd o\u00f0|~o\u20ac\u20acon l\u00deLkmol{{v d7=f \ufffd{m{z\ufffd~k\u20ac\ufffd \ufffdso\u20ac|~okntzr {qIV^OJ/4= yt\u20actzq{~yk\ufffdt{z1\nbo\ufffd. \ufffdst\u20acmkzz{\ufffdlo\ufffdo~tqton wkmvtzr kz\u00de\ufffd~kz\u20ac|k~oz\ufffd tzq{~yk\ufffdt{z kl{\ufffd\ufffd ~oy{\ufffdon |{\u20ac\ufffd\u20ac. r~{\ufffd|\u20ac.\nkzn |kro\u20ac1 \\so ty|{~\ufffdkzmo {qtzq{noytm n\u00dezkytm\u20ac q{~{\ufffd~|\ufffdlwtm sokw\ufffds tz\ufffdt\ufffdo\u20ac \ufffd{|wokn q{~k\ny{~o \ufffd~kz\u20ac|k~oz\ufffd kmmo\u20ac\u20ac \ufffd{\u20ac{mtkw yontk zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z nk\ufffdk1\nL\ufffd\ufffd\ufffd~o {q\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de yk\u00de tzmw\ufffdno \ufffdso\u20acmkwtzr {q\ufffdso\u20aco ~o\u20ac\ufffdw\ufffd\u20ac {zkl~{kno~ \u20acmkwo. o\u00f0\ufffdozntzr\n\ufffdsoz\ufffdylo~ {qm{\ufffdz\ufffd~to\u20ac kzn \u20ac{mtkw yontk kzkw\u00de\u00feon. kzn w{mkwt\u00fetzr \ufffdso\u20ac\ufffd\ufffdn\u00de \ufffd{o\u00f0|w{~o \ufffdsontq/\nqo~oz\ufffdtkw ty|km\ufffd {q\ufffdsotzq{noytm {zm{yy\ufffdzt\ufffdto\u20ac y{~o \ufffdk~ro\ufffdon l\u00dent\u20actzq{~yk\ufffdt{z d93f1\n[\ufffd||{~\ufffdtzr tzq{~yk\ufffdt{z\n[4Ltwo1 Jk\ufffdk m{wwom\ufffdt{z kzn qtw\ufffdo~tzr |~{mon\ufffd~o1\n*WJL+\nF\ufffd\ufffds{~ I{z\ufffd~tl\ufffd\ufffdt{z\ufffd\nI{zmo|\ufffd\ufffdkwt\u00fek\ufffdt{z> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Qkyto Zk\u00de N\ufffd\ufffdmstzr\u20ac. I{zz{~ [\ufffdt~wtzr\nQkyo\u20ac [yt\ufffds. Tk\ufffd~{ I{z\ufffdt. _kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{mmst. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nJk\ufffdk m\ufffd~k\ufffdt{z> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Qkyto Zk\u00de N\ufffd\ufffdmstzr\u20ac. I{zz{~ [\ufffdt~wtzr\nQkyo\u20ac [yt\ufffds. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nL{~ykw kzkw\u00de\u20act\u20ac> Mkl~towo K\ufffd\ufffdk. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nL\ufffdzntzr km}\ufffdt\u20act\ufffdt{z> Tk\ufffd~{ I{z\ufffdt. _kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{mmst1\nOz\ufffdo\u20ac\ufffdtrk\ufffdt{z> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Qkyto Zk\u00de N\ufffd\ufffdmstzr\u20ac. _kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{m/\nmst.Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nTo\ufffds{n{w{r\u00de> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nW~{uom\ufffd knytzt\u20ac\ufffd~k\ufffdt{z> Mkl~towo K\ufffd\ufffdk. _kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{mmst. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nZo\u20ac{\ufffd~mo\u20ac> Mkl~towo K\ufffd\ufffdk. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\n[{q\ufffd\u00d0k~o> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\n[\ufffd|o~\ufffdt\u20act{z> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. _kw\ufffdo~ Y\ufffdk\ufffd\ufffd~{mt{mmst. Mt\ufffdwt{ ^kwoz\ufffdtz{\nJkwwk Zt\ufffdk1\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 44247\n^kwtnk\ufffdt{z> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\n^t\u20ac\ufffdkwt\u00fek\ufffdt{z> Mkl~towo K\ufffd\ufffdk. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\n_~t\ufffdtzr \u02d8{~trtzkw n~kq\ufffd> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Tk\ufffd~{ I{z\ufffdt. Mt\ufffdwt{ ^kwoz\ufffdtz{\nJkwwk Zt\ufffdk1\n_~t\ufffdtzr \u02d8~o\ufffdto\u00d0 \u2019ont\ufffdtzr> Mkl~towo K\ufffd\ufffdk. Fwo\u20ac\u20ackzn~{ Mkwok\u00fe\u00fet. Tk\ufffd~{ I{z\ufffdt. _kw\ufffdo~ Y\ufffdk\ufffd/\n\ufffd~{mt{mmst. Mt\ufffdwt{ ^kwoz\ufffdtz{ Jkwwk Zt\ufffdk1\nZoqo~ozmo\ufffd\n41 V~rkzt\ufffdk\ufffdt{ z_N1 _NV Jt~om\ufffd{~/ Mozo~kw)\ufffd {|oztzr ~oyk~v\ufffd k\ufffd\ufffdsoyontk l~toqtzr {zIV^OJ/4= \u015244\nTk~ms 5353?1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1\ufffds{1tz\ufffd2nt~ om\ufffd{~/rozo~ kw2\ufffd|oomso \ufffd2no\ufffdktw2\ufffd s{/nt~om\ufffd{~/\nrozo~kw/\ufffd/ {|oztzr/~ oyk~v\ufffd/k\ufffd/ \ufffdso/yontk/l~ toqtzr/{z/m{ \ufffdtn/4=\u0152 44/yk~ms/535 31\n51 Go\ufffd\ufffdms I._towo~ SN.Nklo~\ufffdkk\ufffd R1T{zt\ufffd{~tzr losk\ufffdt{ \ufffd~kwtz\ufffdtrs\ufffd\ufffd ~owk\ufffdon \ufffd{IV^OJ /4=1 \\so Skzmo\ufffd1\n5353? 6=9*43565+ >4599\u02d84 59:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 :2[3473/:; 6:*53+63; 5=/; WTOJ> 6557;656\n61 Utm{wk T.Fw\ufffdkqt c.[{s~klt I.Ro~\ufffdkz F.Fw/Qklt~ F.O{\ufffdtqtnt\ufffd I.o\ufffdkw1\\so \ufffd{mt{/om{z {ytm ty|wtmk\ufffdt{z \ufffd\n{q\ufffdsom{~{zk\ufffdt~ \ufffd\ufffd|kznoyt m*IV^OJ/4 =+>F~o\ufffdto\ufffd1 Oz\ufffdo~zk\ufffdt{zkw u{\ufffd~zkw {q\ufffd\ufffd~ro~\ufffd1 5353? ;<>4<9\u02d84=6 1\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 :2u1tu\ufffd\ufffd153 53137134< WTOJ> 656399 66\n71 Lo~r\ufffd\ufffd{z UT. Sk\ufffdn{z J.Uonuk\ufffdt/Mtwk ztM.Oykt U.Ftz\ufffdwto R.Gkr\ufffdowtz T.o\ufffdkw1Oy|km \ufffd{qz{z/|sk~yk/\nmo\ufffd\ufffdtmkw tz\ufffdo~\ufffdoz\ufffdt{z\ufffd *UWO\ufffd+ \ufffd{~on\ufffdmo IV^OJ/4= y{~\ufffdkwt\ufffd\ufffd kznsokw\ufffdsmk~o noykzn1 Oy|o~tkw I{wworo\nIV^OJ/4= Zo\ufffd|{z\ufffdo \\oky1 Oy|o~tkw I{wworo IV^OJ /4=Zo\ufffd|{z \ufffdo\\oky1 5353? |1531\n91 Itzowwt T.Y\ufffdk\ufffd\ufffd~{mt{m mst_.Mkwok\ufffd\ufffdt F.^kwoz\ufffdt\ufffdo IT. G~\ufffdrz{wt K.[msytn\ufffd FS.o\ufffdkw1\\so IV^OJ/4=\n\ufffd{mtkw yontk tzq{noytm1 [mtoz\ufffdtqt mZo|{~\ufffd\ufffd1 5353? 43*4+>4\u02d843 1s\ufffd\ufffd|\ufffd>22n{t1{~ r2431436 <2\ufffd749=</353/\n;6943/9 WTOJ> 663574 95\n:1 ^kwoz\ufffdt\ufffdo IT. Itzowwt T.Ukntzt T.Mkwok\ufffd\ufffdt F.Wo~\ufffd\ufffd\ufffdt F.K\ufffd\ufffdk M.o\ufffdkw1Skmv {qo\ufffdtnozmo q{~m{~~owk\ufffdt{z\nlo\ufffd\ufffdooz IV^OJ/4= tzq{noytm kzn\ufffdkmmtzo kmmo|\ufffdkzm o1k~at\ufffd |~o|~tz\ufffd k~at\ufffd>543;3; =7:1 53541\n;1 G~tkzn [I.Itzowwt T.Ur\ufffd\ufffdoz \\.So\ufffdt\ufffd Z.W~\ufffdl\ufffdw\ufffdvt J.^kwoz\ufffdt \ufffdoIT. o\ufffdkw1Ozq{noytm \ufffd>Fzo\ufffd mskwwozro\nq{~|\ufffdlwtm sokw\ufffds1 Ioww1 5354? 4<7*59+>:3 43\u02d8:3471 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 :2u1moww153 541431364 WTOJ>\n67<=397<\n<1 ck~{m{\ufffd\ufffdk\ufffd Q1N{\ufffd \ufffd{qtrs\ufffd kztzq{noytm1 \\so Skzmo\ufffd1 5353? 6=9*43559+ >:;:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2\n[3473/:;6 :*53+637: 4/aWTOJ> 654467=9\n=1 V~rkzt\ufffdk\ufffdt{ z_N1 Ozq{noytm ?1F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1\ufffds{1tz\ufffd2sok w\ufffds/\ufffd{|tm\ufffd2t zq{noytm$\ufffdk lB\ufffdkli41\n431 K\ufffd\ufffdozlkms M1Ozq{noyt{w{r \ufffd>\\so o|tnoyt{w{r\ufffd {q*yt\ufffd+ tzq{~yk\ufffdt {z1\\so Fyo~tmkz u{\ufffd~zkw {qyontmtzo1\n5335? 446*=+>;:6 \u02d8;:91 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2 [3335/=67 6*35+347; 6/3WTOJ> 4594;6:=\n441 Mtz\ufffdlo~r Q.T{sollt TN. Wk\ufffdow Z[.G~kyyo~ S.[y{wtz\ufffdvt T[. G~twwtkz\ufffd S1Jo\ufffdom\ufffdtzr tzqw\ufffdoz \ufffdko|tnoy/\ntm\ufffd\ufffd\ufffdtzr \ufffdok~ms ozrtzo }\ufffdo~\ufffd nk\ufffdk1 Uk\ufffd\ufffd~o1 533=? 79;*;565+> 4345\u02d843471 s\ufffd\ufffd|\ufffd>22n{t1{ ~r2431436<2\nzk\ufffd\ufffd~o3;:67 WTOJ> 4=353933\n451 Iso\ufffd IT1 Wkzno ytm\ufffd tz\ufffdsokro{q\ufffd\ufffdt\ufffd\ufffdo~> Fm{z\ufffdoz\ufffd kzkw\ufffd\ufffdt\ufffd {q\ufffdso533= s4z4 {\ufffd\ufffdl~o kv1]zt\ufffdo~\ufffdt\ufffd\ufffd {q\n\\{~{z\ufffd{? 53431\n461 _tmv\ufffd W.Tk\ufffd\ufffdkr wtT.R\ufffdwvk~zt F.Jk\ufffd\ufffdkz tN1]\ufffdo {qkz{zwtzo m{yy\ufffd zt\ufffd\ufffd\ufffd{no\ufffdow{| |k\ufffdtoz\ufffd/~o|{ ~\ufffdon\n{\ufffd\ufffdm{yo tz\ufffd\ufffd~\ufffdyoz \ufffd\ufffd>\ufffdsoT\ufffdw\ufffdt|wo [mwo~{ \ufffdt\ufffd\\~ok\ufffdyoz \ufffdFnso~ozm oY\ufffdo\ufffd\ufffdt{zzkt~ o*T[/\\FY+ 1Q{\ufffd~zkw {q\nyontmkw Oz\ufffdo~zo\ufffd ~o\ufffdok~ms 15344? 46*4+>o451 s\ufffd\ufffd|\ufffd>22n {t1{~r243154= :2uyt~14: <;WTOJ> 545::64<\n471 L~{\ufffd\ufffd Q.Vv\ufffdz [.^k\ufffdrskz \\.No\ufffd\ufffd{{n Q._tmv\ufffd W1Wk\ufffdtoz \ufffd/~o|{~\ufffdon {\ufffd\ufffdm{y o\ufffdk\ufffdk\ufffd{\ufffd~mo {qo\ufffdtnozmo\ntz{qq/wklow |~o\ufffdm~tltzr >kzkw\ufffd\ufffdt\ufffd {qnk\ufffdk q~{y Wk\ufffdtoz\ufffd\ufffdStv oTo1 Q{\ufffd~zkw {qyontmkw Oz\ufffdo~zo \ufffd~o\ufffdok~ms1\n5344? 46*4+>o:1 s\ufffd\ufffd|\ufffd>22 n{t1{~r243154 =:2uyt~14 :76WTOJ> 54595367\n491 cs{\ufffd a.[{zr b.Qtkzr N._kzr Y.Y\ufffdc.cs{\ufffd a.o\ufffdkw1I{y|k~t\ufffd{z {qW\ufffdlwtm Zo\ufffd|{ z\ufffdo\ufffd \ufffd{I{z\ufffdktz/\nyoz\ufffd Tok\ufffd\ufffd~o\ufffd J\ufffd~tzr \ufffdsoOzt\ufffdtkw V\ufffd\ufffdl~okv kznZo\ufffd\ufffd~rozmo {qIV^OJ/4= tzIstzk> Ozq{noyt{ w{r\ufffd\n[\ufffd\ufffdn\ufffd1 Q{\ufffd~zkw {qyontmkw Oz\ufffdo~zo\ufffd ~o\ufffdok~ms 15354? 56*7+>o5:9 4<1s\ufffd\ufffd|\ufffd>2 2n{t1{~r243154 =:25:94 <WTOJ>\n66;93;6=\n4:1 K\ufffd\ufffdozlkms M.o\ufffdkw1Ozq{noyt{ w{r\ufffd kzntzq{\ufffdotwwkzm o>q~kyo\ufffd{~v q{~kzoyo~rtz r\ufffdo\ufffd{q|\ufffdlwtm sokw\ufffds\ntzq{~yk\ufffdt m\ufffdyo\ufffds{n\ufffd \ufffd{kzkw\ufffd\ufffdo \ufffdok~ms. m{yy\ufffd ztmk\ufffdt{z kzn|\ufffdlwtmk\ufffdt {zlosk\ufffdt{~ {z\ufffdsoOz\ufffdo~zo \ufffd1Q{\ufffd~/\nzkw{qyontmkw Oz\ufffdo~zo\ufffd ~o\ufffdok~ms 1533=? 44*4+>o449 ;1s\ufffd\ufffd|\ufffd>22n{t1{~ r243154=:2uy t~1449; WTOJ> 4=65=73 <\n4;1 Gkv\ufffds\ufffd K.To\ufffd\ufffdtzr [.Fnkytm SF1K\ufffd|{\ufffd\ufffd~o \ufffd{tno{w{rtmkww\ufffd nt\ufffdo~\ufffdo zo\ufffd\ufffd kzn{|tzt{z {zLkmol{{v 1\n[mtozmo1 5349? 67<*:56=+ >4463\u02d844 651s\ufffd\ufffd|\ufffd>22n{t1{~ r2431445: 2\ufffdmtozmo1kkk4 4:3WTOJ> 59=96<53\n4<1 ^tmk~t{ TJ. Go\ufffd\ufffdt F.c{ww{ L.Wo\ufffd~{zt L.[mkwk F.Ikwnk~o wwtM.o\ufffdkw1\\so \ufffd|~okntzr {qyt\ufffdtzq{~y k\ufffdt{z\n{zwtzo1 W~{moontzr\ufffd {q\ufffdsoUk\ufffdt{zkw Fmknoy\ufffd {q[mtozmo\ufffd1 534:? 446*6+>997 \u02d899=1 s\ufffd\ufffd|\ufffd>22n{t1 {~r2431\n43;62|zk\ufffd 1494;774446 WTOJ> 5:;5=<:6\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 45247\n4=1 Fnkytm SF.Mwkzmo U1\\so |{wt\ufffdtmkw lw{r{\ufffd| so~o kzn\ufffdso5337 ][owom\ufffdt{z> nt\ufffdtnon \ufffdso\ufffd lw{r1 Oz>W~{/\nmoontzr \ufffd{q\ufffdso6~nOz\ufffdo~zk\ufffdt{z kw_{~v\ufffds{ |{zStzv Jt\ufffdm{\ufffdo~\ufffd ?53391 |16:\u02d8761\n531 Lwk\ufffdykz [.M{ow [.Zk{ QT1Ltw\ufffdo~ l\ufffdllwo\ufffd. oms{ mskylo~\ufffd. kzn{zwtzo zo\ufffd\ufffd m{z\ufffd\ufffdy |\ufffdt{z1 W\ufffdlwtm\nV|tzt{z Y\ufffdk~\ufffdo~w\ufffd1 534:? <3*[4+>5= <\u02d86531 s\ufffd\ufffd|\ufffd>2 2n{t1{~r243143 =62|{}2z q\ufffd33:\n541 ^tmk~t{ TJ. ^t\ufffdkwn{ M.Go\ufffd\ufffdt F.c{ww{ L.[mkwk F.Ikwnk~owwt M.o\ufffdkw1Kms{ Iskylo~\ufffd> Ky{\ufffdt{zk wI{z\ufffdk/\nrt{z kznM~{\ufffd| W{wk~t\ufffdk\ufffdt{z {zLkmol{{v1 [mtoz\ufffdtqt mZo|{~\ufffd\ufffd1 534:? :*4+1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431436<2\n\ufffd~o|6;<59 WTOJ> 5;=39735\n551 [\ufffdo\ufffdk~\ufffd FQ.T{\ufffdwos T.Jtkv{z{\ufffdk T.F~omsk~ FF.Zkzn JM. Ww{\ufffdvtz QG1Ozq{~yk\ufffdt{z ro~~\ufffdykz no~tzr\nkzn\ufffdznoy{m~ k\ufffdtmnomt\ufffdt{z\ufffd 1Uk\ufffd\ufffd~o1 534=? 9;6*;;;5+ >44;\u02d84541 s\ufffd\ufffd|\ufffd>22n {t1{~r2431436 <2\ufffd749<: /34=/\n493;/: WTOJ> 647<93 9<\n561 \\o~~oz S.G{~ro/G~ k\ufffd{Z1Kms{ Iskylo~\ufffd {z[{mtkw Tontk> F[\ufffd\ufffd\ufffdoy k\ufffdtmZo\ufffdto\ufffd {q\ufffdsoSt\ufffdo~k\ufffd\ufffd~o1\nZo\ufffdto\ufffd {qI{yy\ufffdztm k\ufffdt{z Zo\ufffdok~ms1 5354? =>==\u02d844<1 s\ufffd\ufffd|\ufffd>22n{t1 {~r243145<73 2O[[U15599 /74:9135<\n571 ^{\ufffd{\ufffdrs t[.Z{\ufffd J.F~kw [1\\so \ufffd|~okn {q\ufffd~\ufffdo kznqkw\ufffdo zo\ufffd\ufffd {zwtzo1 [mtozmo1 534<? 69=*:6<3+> 447:\u02d8\n44941 s\ufffd\ufffd|\ufffd>22n {t1{~r2431445 :2\ufffdmtozmo1 kk|=99= WTOJ> 5=9=3379\n591 Itzowwt T.T{~kwo\ufffd MJL. Mkwok\ufffd \ufffdtF.Y\ufffdk\ufffd\ufffd~{mt{m mst_.[\ufffdk~ztzt T1\\so oms{ mskylo~ oqqom\ufffd {z\ufffd{mtkw\nyontk1 W~{moontzr\ufffd {q\ufffdsoUk\ufffdt{zkw Fmknoy\ufffd {q[mtozmo\ufffd1 5354? 44<*=+>o53 566344 4<1s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n43143;62 |zk\ufffd15356634 44<WTOJ> 66:55;<:\n5:1 Gwo\ufffd I.bk\ufffd\ufffdo~t \\1W{\ufffdt\ufffdt\ufffdo kwr{~t\ufffds ytmltk\ufffd mkzz{\ufffd \ufffd\ufffd{| q~kryoz\ufffdk \ufffdt{ztzs{y{|stwtm zo\ufffd\ufffd{~v\ufffd1 \\so\nQ{\ufffd~zkw {qTk\ufffdsoy k\ufffdtmkw [{mt{w{r\ufffd 15353? |14\u02d84<1\n5;1 Lo~~k~k K1_sk\ufffd \ufffd\ufffd|o\ufffd {qIV^OJ /4=m{z\ufffd|t~kmt o\ufffdk~o|{|\ufffdwk\ufffdon l\ufffd\\\ufffdt\ufffd\ufffdo~ l{\ufffd\ufffdD Lt~\ufffd\ufffd T{znk\ufffd1 53531\n5<1 [skst MR. Jt~v\ufffd{z F.Tkums~\ufffdkv \\F1Fzo\ufffd|w{~k\ufffd{~\ufffd \ufffd\ufffd\ufffdn\ufffd {qm{\ufffdtn/4= yt\ufffdtzq{~yk\ufffdt {z{z\ufffd\ufffdt\ufffd\ufffdo~1 Vzwtzo\n\ufffd{mtkw zo\ufffd\ufffd{~v\ufffd kznyontk1 5354? 55>43343 71s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434: 2u1{\ufffdzoy1535 31433437 WTOJ>\n66:56<6:\n5=1 a\ufffdo Q.Isoz Q.N\ufffdZ.Isoz I.csozr I.[\ufffdb.o\ufffdkw1\\\ufffdt\ufffd\ufffdo~ Jt\ufffdm\ufffd\ufffd\ufffdt{z \ufffdkznKy{\ufffdt{z\ufffd Fl{\ufffd\ufffd \ufffdso\nIV^OJ/4= Wkznoy tm>Tkmstzo Sok~ztzr F||~{kms1 QTon Oz\ufffdo~zo\ufffd Zo\ufffd1 5353? 55*44+>o53 9931 s\ufffd\ufffd|\ufffd>22\nn{t1{~r243154 =:253993 WTOJ> 6644=96 9\n631 J{{rkz I.G\ufffdz\ufffdtz o_.Stzro~ N.G~\ufffdz\ufffd [1W\ufffdlwtm Wo~mo|\ufffdt{z\ufffd kznF\ufffd\ufffdt\ufffd\ufffdno\ufffd \\{\ufffdk~n IV^OJ/4= U{z|sk~ /\nykmo\ufffd\ufffdtmkw Oz\ufffdo~\ufffdoz\ufffdt {z\ufffdFm~{\ufffd\ufffd [t\ufffdI{\ufffdz\ufffd~to\ufffd> F\\{|tm T{nowtz rFzkw\ufffd\ufffdt\ufffd {q\\\ufffdt\ufffd\ufffdo~ Jk\ufffdk1 QTon Oz\ufffdo~/\nzo\ufffdZo\ufffd1 5353? 55*=+>o547 4=1s\ufffd\ufffd|\ufffd>22n{t1{~ r243154= :25474= WTOJ> 65;<74 =3\n641 Fln/Fw~k \ufffdk}F.Fws\ufffd\ufffdkt wJ.N{\ufffd\ufffdos T.Nkynt T.[sks c1\\{| m{zmo~z\ufffd {q\ufffd\ufffdoo\ufffdo~\ufffd n\ufffd~tzr \ufffdsoIV^OJ/\n4=|kznoyt m>tzq{\ufffdotww kzmo \ufffd\ufffd\ufffdn\ufffd1 Q{\ufffd~zkw {qyontmkw Oz\ufffdo~zo \ufffd~o\ufffdok~ms1 5353? 55*7+>o4=3 4:1s\ufffd\ufffd|\ufffd>22n{t1\n{~r243154=:2 4=34: WTOJ> 655<;36=\n651 Mkww{\ufffd\ufffdt Z.^kwwo L.Ik\ufffd\ufffdkwn{ U.[kmm{ W.JoJ{yoztm {T1F\ufffd\ufffdo\ufffd\ufffdt zr\ufffdso~t\ufffdv\ufffd {qjtzq{noytm \ufffd)tz\n~o\ufffd|{z\ufffdo \ufffd{IV^OJ/4= o|tnoytm\ufffd1 Uk\ufffd\ufffd~o N\ufffdykz Gosk\ufffdt{\ufffd ~15353? 7*45+>45<9 \u02d845=61 s\ufffd\ufffd|\ufffd>22n{t1{ ~r2\n431436<2 \ufffd749:5/353/ 33==7/: WTOJ> 66455<4 5\n661 [kzqowtmt T1\\so O\ufffdkwtkz Zo\ufffd|{ z\ufffdo\ufffd{\ufffdsoIV^OJ/4= I~t\ufffdt\ufffd> So\ufffd\ufffd{z\ufffd Sok~zon kznL\ufffd\ufffd\ufffd~o Jt~om\ufffdt{z tz\n[{mtkw Jo\ufffdow{|y oz\ufffd1\\so Oz\ufffdo~zk \ufffdt{zkw Q{\ufffd~zkw {qI{yy\ufffdz t\ufffd\ufffdkzn[{mtkw Jo\ufffdow{|yoz\ufffd1 5353? 5*5+>4=4\u02d8\n5431 s\ufffd\ufffd|\ufffd>22n{ t1{~r243144;; 2594::35 :53=6:36;\n671 _tvt|ontk 1IV^OJ/4= S{mvn{\ufffdz\ufffd 1F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22oz1\ufffd tvt|ontk1{~r2\ufffd tvt2IV^OJ/4 =iw{mvn{\ufffd z\ufffd\n691 Gkvo~ TM. _tw\ufffd{z U.Fzrwoy\ufffdo ~F1[\ufffdmmo\ufffd\ufffdq\ufffdw Kwtytzk \ufffdt{z{qI{\ufffdtn/4= \\~kz\ufffdyt\ufffd\ufffdt{z tzUo\ufffd cokwkzn 1\nUo\ufffd Kzrwkzn Q{\ufffd~zkw {qTontmtzo1 5353? 6<6*<+>o9: 1s\ufffd\ufffd|\ufffd>22n{t1{ ~r2431439:2U KQTm535953 6WTOJ>\n65;:;<=4\n6:1 Uo\ufffd cokwkzn M{\ufffdo~zyoz\ufffd1 Fl{\ufffd\ufffd \ufffdsoFwo~\ufffd [\ufffd\ufffd\ufffdoy? 53541 F\ufffdktwkl woq~{y> s\ufffd\ufffd|\ufffd>22m {\ufffdtn4=1r{ \ufffd\ufffd1z\ufffd2kwo~\ufffd/\nwo\ufffdow\ufffd/kz n/\ufffd|nk\ufffdo\ufffd2kl{\ufffd \ufffd/\ufffdso/kwo~\ufffd/\ufffd \ufffd\ufffd\ufffdoy21\n6;1 [mkww\ufffd M.Qkm{l\ufffd {zG.Fllk\ufffdt R1\\so ]R)\ufffd |\ufffdlwtm sokw\ufffds ~o\ufffd|{z\ufffdo \ufffd{m{\ufffdtn/4=1 GTQ1 5353? 6:=1 WTOJ>\n65747;45\n6<1 \\tyo\ufffd \\[1Zo\ufffdokwon> ]R)\ufffd w{mvn{\ufffd znt\ufffdso~tzr won\ufffd{\ufffd{~\ufffd\ufffd nok\ufffds \ufffd{wwtzK\ufffd~{|o? 53531 F\ufffdktwkl woq~{y>\ns\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1\ufffdso\ufffdtyo\ufffd1m {1\ufffdv2k~\ufffdtmwo 2~o\ufffdokwon/\ufffdv /\ufffd/w{mvn{\ufffdz/ nt\ufffdso~tzr/w on/\ufffd{/\ufffd{~\ufffd\ufffd /nok\ufffds/\ufffd{ww/tz/o \ufffd~{|o/\n\ufffd<:|\ufffd6ss9 1\n6=1 Zt\ufffdmsto N.V~\ufffdt\ufffd/V\ufffd|tz kK.Gow\ufffdovtkz J.Tk\ufffdsto\ufffd K.Nk\ufffdoww Q.Tkmn{zkwn G.o\ufffdkw1I{~{zk\ufffdt~ \ufffd\ufffdWkznoytm\n*IV^OJ/4 =+1V\ufffd~_{~wn tzJk\ufffdk1 53531\n731 \\oky I1I~{\ufffdn \\kzrwo1 Lkmol{{v. Tozw{ Wk~v. Ikwtq{~zt k.]zt\ufffdon [\ufffdk\ufffdo\ufffd1 53531\n741 Tontk Gtk\ufffd 2Lkm\ufffd Isomv. F\ufffdktwklwo q~{y> \ufffdTGLI1\ufffd s\ufffd\ufffd|\ufffd>22y ontkltk\ufffdqkm \ufffdmsomv1m{y2\n751 [{k~ T.[yt\ufffds ^S.Joz\ufffdt\ufffds TZa. Gk~zo\ufffd\ufffd J.Nkzzks R.Jkwwk Zt\ufffdk M^. o\ufffdkw1K\ufffdkw\ufffdk\ufffdt zr\ufffdsotzq{noytm>\nk\ufffd\ufffdo\ufffd\ufffdtz r\ufffdso|~o\ufffdkwozmo kznzk\ufffd\ufffd~o {qIV^OJ/4= \ufffdz~owtklwo kzn\ufffdz\ufffd~\ufffd\ufffd\ufffd\ufffd{~\ufffds \ufffdtzq{~yk\ufffdt {ztzF{\ufffdok~{k\nUo\ufffd cokwkzn )\ufffd\ufffd{mtkw yontk. Qkz\ufffdk~\ufffd\u02d8 F\ufffdr\ufffd\ufffd\ufffd 5353? 53531\n761 Nkwo \\.Wo\ufffdso~tmv F.Wstwwt|\ufffd \\._ol\ufffd\ufffdo~ [1^k~tk\ufffdt{z tzr{\ufffdo~zyo z\ufffd~o\ufffd|{z\ufffdo \ufffd\ufffd{IV^OJ/4= 1Gwk\ufffdk\ufffdzt v\n\ufffdms{{w {qr{\ufffdo~zyo z\ufffd\ufffd{~vtzr |k|o~1 5353? 64>5353 \u02d8441\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 46247\n771 \\~kmvo~ VIMZ1 To\ufffds{n{w{r\ufffd q{~mkwm\ufffdwk\ufffdtzr tzntmo\ufffd? 53541 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22rt\ufffds\ufffdl 1m{y2\nV\ufffdIMZ\\2 m{\ufffdtn/|{wtm\ufffd /\ufffd~kmvo~2lw{l2 yk\ufffd\ufffdo~2n{m\ufffdy oz\ufffdk\ufffdt{z2tzno\ufffd iyo\ufffds{n{ w{r\ufffd1yn1\n791 Soo\ufffdk~\ufffd R.[ms~{n\ufffd WF1Mnow\ufffd> Mw{lkw nk\ufffdk {zo\ufffdoz\ufffd\ufffd. w{mk\ufffdt{z. kzn\ufffd{zo. 4=;=\u02d853451 Oz>O[Fkzz\ufffdkw\nm{z\ufffdoz\ufffdt{z 1\ufffd{w151It\ufffdo\ufffdoo~? 53461 |14\u02d87=1\n7:1 MJKS\\1 MJKS\\ \\~kz\ufffdwtz r\ufffdkw> \\~kz\ufffdwk\ufffdt zr\ufffdsoWwkzo\ufffd?1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22lw{r1r now\ufffd|~{ uom\ufffd1{~r2\nrnow\ufffd/\ufffd~kz\ufffdwtz r\ufffdkw/\ufffd~kz\ufffd wk\ufffdtzr/\ufffdso/| wkzo\ufffd21\n7;1 MJKS\\ Vzwtzo Uo\ufffd\ufffd [\ufffdyyk~\ufffd F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22k|t1rn ow\ufffd|~{uom \ufffd1{~r2k|t2\ufffd 52\ufffd\ufffdyyk~\ufffd2 \ufffd\ufffdyyk~\ufffd\n7<1 I~{\ufffdn\\kzrwo 1_sk\ufffd nk\ufffdk t\ufffdI~{\ufffdn\\kzrwo \ufffd~kmvtzrD?1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22sow|1m ~{\ufffdn\ufffdkzr wo1m{y2oz2\nk~\ufffdtmwo\ufffd244 73=63/\ufffd sk\ufffd/nk\ufffdk/t\ufffd/m~ {\ufffdn\ufffdkzrwo /\ufffd~kmvtzr 1\n7=1 Iworr U1I{ylk \ufffdtzrIV^OJ/4= yt\ufffdtzq{~yk\ufffdt {zkm~{\ufffd\ufffd {\ufffd~k||\ufffd1 Lkmol{{v Uo\ufffd\ufffd~{{y Tk~1 5353?59 1\n931 Nkzzks R.Nk\ufffd\ufffd{\ufffd\ufffd\ufffdk [.\\k\ufffdw{~ R1Uo\ufffd cokwkzn q~{y 4;F\ufffdr\ufffd\ufffd\ufffd \ufffd{9U{\ufffdoylo~ 53541\nPLOS ONEIV^OJ/4= tzq{noytm {zLkmol{{v kznm{z\ufffdktzyoz \ufffdyok\ufffd\ufffd~o\ufffd tzO\ufffdkw\ufffd. ]zt\ufffdon Rtzrn{ ykznUo\ufffd cokwkzn\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135:;3 55 Tk\ufffd 4=.5355 47247", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "COVID-19 infodemic on Facebook and containment measures in Italy, United Kingdom and New Zealand", "author": ["G Etta", "A Galeazzi", "JR Hutchings", "CS James Smith"], "pub_year": "2022", "venue": "PloS one", "abstract": "The COVID-19 pandemic has been characterized by a social media \u201cinfodemic\u201d: an  overabundance of information whose authenticity may not always be guaranteed. With the potential"}, "filled": false, "gsrank": 742, "pub_url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0267022", "author_id": ["izHUn34AAAAJ", "DK0tXAIAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:ASqWPP0OkbcJ:scholar.google.com/&output=cite&scirp=741&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ASqWPP0OkbcJ&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 15, "citedby_url": "/scholar?cites=13227370061369846273&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ASqWPP0OkbcJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0267022&type=printable"}}, {"title": "Stigma sosial pengangguran di media daring Amerika Serikat pada masa pandemi COVID-19", "year": "2022", "pdf_data": "    P-ISSN: 1907 -848X, E -ISSN: 2548 -7647  \n  Volume 16, Nomor 2, April 2022 , Hal 169 -186  \nDOI: 10.20885/komunikasi.vol16.iss 2.art5 \n  \n \nCopyright \u00a9 2022 Authors. This is an open -access article distributed under the terms of the Creative Commons Attribution -Share Alike \n4.0 International License (http://creativecommons.org/licences/by -sa/4.0/ ) 169 \n  \n \n \nSocial Stigma of Unemployment in United States Online Media \nduring COVID -19 Pandemic  \n \nEvanytha   1*, Rustono Farady Marta   2, Hana Panggabean   3 ,  \ndan Mercedes Amanda 4 \n \n1 Prodi Psikologi, Fakultas Psikologi, Universitas Katolik Indonesi a Atma Jaya,  Jakarta, \nIndonesia. Email:  evanytha@univpancasila.ac.id  \n2 Prodi Ilmu Komunikasi, Fakultas Ilmu Sosial dan Ilmu Politik, Universitas Satya Negara \nIndone sia, Jakarta Utara, Indonesia , Email: rustono.farady@usni.ac.id  \n3 Prodi Psikologi, Fakultas Psikologi, Universitas Katolik Indonesi a Atma Jaya, Jakarta, \nIndonesia.  Email:hana.panggabean@atmajaya.ac.id  \n4 School of Journalism and Communication, Huaqiao Unive rsity, China . \nEmail:mercedesamanda11@gmail.com  \n* corresponding author  \n  \n \n \n  \nArticle Info  \n \nArticle History  \nReceived  \n18 Nov 2021  \nRevised  \n23 Apr 2022  \nAccepted  \n30 Apr 2022   \n \nKeywords : \nCOVID -19, \nframing, social \nstigma , \nunemployment  \n Abstract:  The social s tigma of unemployment during COVID -19 pandemic \nrelated to problems of marginalization. This study explores the construction \nof the meaning of the social stigma of unemployment in United States online \nmedia. This study is a comparative study to compare the construction of the \nmeaning of social stigma between online media usa.today and \nnbcwashington.com with Entman's framing analysis. The problem \nformulated through framing is that social stigma makes it difficult for \nunemployed people to get a job and stigma creates feelings of inferiority. The \ncause of the social stigma is perception low personal qualities and stigma \nconsciousness. Framing moral judgement is a negative perception in \nemployers mind and the feeling of shame due to unemployment. \nCountermeasure s uggestion is wide distribution of vaccines and suggestions \nabout ways to get job. Online media can contribute as agents of change \nthrough news framing that can improve public perceptions and  provide \ninformational support.  \n  \n  \n \n \nINTRODUCTION  \nCurrently, the COVID -19 pandemic \nhas hit the world, causing health, economic \nand social problems. Most of the digital \ncommunication channels are flooded by \nvarious news related to this virus (Setiawan \net al., 2021) . The pandemic also causes \nmany changes in social life, including \nuncertainty, financial pressure, social \nisolation, and causes psychological \npressure that can cause stress and anxiety \n(Li et al., 2021) . The economic crisis due to the COVID -19 pandemic is predicted to \nhave an impact on global unemployment \n(UN, 2022) . News about unemployment \ndominated the media coverage  in the \nUnited States during the pandemic, with \nconsistently high public attention. As the \nunemployment rate rises, fear spreads \nabout the condition of America\u2019s workforce  \n(Gallagher, 2021) .   \nUnemployment has a negative \nimpact related to social, financial, and \npsychological problems. Unemployment \n\n  \n  \n \n  \n \n170 Jurnal Komunikasi  \n has a direct impact on the financial \ncondition of individuals. There has been a \nsharp and persistent reduction in income \nthat forces unemployed individuals to \nmake severe adjustments that negatively \naffect the quality of nutrition, housing, and \nhealth care. Financial problems have \nconsistently been a significant predictor of \npsychological stress on unemployment \n(Farr\u00e9 et al., 2018) . \nPeriods of unemplo yment are \nassociated with symptoms of stress, such as \nstomach ailments, headaches, and mental \nhealth symptoms, such as anxiety, \ndepression, sleep problems, and declining \nhealth habits (Hammarstr\u00f6m & Ahlgren, \n2019) . Experiences that worsen or improve \nhealth depend  on the position of the \nworkforce acquired (Hammarstr\u00f6m & \nAhlgren, 2019) . This mental health \ncondition is related to the quality of human \nresources as reflected in the Human \nDevelopment Index (HDI), which covers \naspects of education, health, and economy. \nHDI is o ne measure of state welfare in \naddition to Gross Domestic Product \n(Suparno, 2018) .  \nPsychological problems can be the \nresult of unemployment, but poor mental \nhealth can also result in a person losing his \njob, being unable to find work, being \nunemployed for more extended periods, \nand having a lower chance of being \naccepte d for work (Krug et al., 2019) . Poor \nmental health can lead to job loss or the \ninability to find work (Farr\u00e9 et al., 2018) . \nThe refusal to accept unemployed \nindividuals due to the perception of \npersonal failure is a stigma effect. \n(O\u2019Donnell et al., 2015) .  The social stigma \nimposed on unemployment is one of the \nessential mechanisms related to \nunemployment's psychological and social \nconsequences (Tyler & Slater, 2018) . \nO\u2019Donnell et al. (2015)  reported the \nresearch results that the social stigma of unemployment negatively impacts \nindividuals. The greater the stigmatization \nthe unemployment has, the less the \ninstitutions' willingness to employ \nunemployed individuals  \nStigma is defined by Goffman  \n(1963)  as an attribute that discredits or \nvilifies a pe rson. Stigma is a relationship \nbetween attributes and stereotypes. The \ndiscrediting attributes are given to \nindividuals who have characteristics or \nbehavior that are different or deviate from \nwhat is considered normal by society. Link \nand Phelan (2001)  state that stigma is the \npresence of several components, namely \nlabeling, stereotypes, separation, loss of \nstatus, and discrimination.  \nStigma can lead to negative and \nhostile behavior towards stigmatized \npeople (Krug et al., 2019) . Labelling \ndeveloped because of a social selection \nprocess to  define different things in society. \nDifferences, such as race, can be easily \nrecognized so that society can categorize \npeople into specific groups based on race. \nLabels connect individuals or groups to \nseveral undesirable characteristics, which \ncan be use d then as stereotypes. The \nprocess of labelling and stereotyping \ncreates separation because people do not \nwant to be associated with less positive \ncharacteristics, so hierarchical categories \nare created. When the categories have been \nformed, groups with ne gative or unwanted \ncharacteristics become victims of the loss \nof status and discrimination. Individuals \nwho are stigmatized feel ashamed, and so \ndo those associates with the recipient of the \nstigma (Link & Phela n, 2001) .  \nStigma is a psychological process \nthat involves individual cognition. The \nsocio -cognitive approach explains how \nindividuals construct categories that relate \nthese categories to certain stereotyped \nbeliefs in the stigma process. Stigma is \ndiffer ent from discrimination. \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 171 \n  Discrimination gives greater attention to \nthe process of rejection and exclusion, \nwhile stigma is directed at something that \nis inside a person (Link & Phelan, 2001) . \nThere are three ty pes of stigmas, \nnamely ethnic identity, body hatred, and \ncharacter weakness. Ethnic identity stigma \nincludes ethnicity, religion, nationality, or \ngender stigma. Stigma related to body \nhatred covers the stigma of physical \ndisability. Stigma related to chara cter \nweakness are stigma against mental \ndisorders, addictions, or a history of \ndetention. Social stigma against \nunemployment is related to the belief that \nunemployment status is caused by personal \nweakness (Tyler & Slater, 2018) .  \nGoffman (in Tyler, 20 18) suggests \nfour crucial things about stigma. First, \nstigma is a perspective that develops in a \nsocial context; second, people learn to cope \nwith the adverse effects of social stigma by \nadopting identity -regulating strategies; \nthird, stigmatization is sp ecific; fourth, \nstigma can function as social control. \nFurthermore, according to Tyler (2018) , a \nbetter understa nding of stigma is \nsomething that can be improved, either \nthrough forms of social action that focus on \n\"educating people\" about stigmatized \nconditions or educating people who \nexperience stigmatization to be able to cope \nwith their stigmatized condition.  \nStigma can be classified into three \nlevels of social fields: social stigma, self -\nstigma, and professional stigma. The levels \nhere do not refer to the hierarchy of \ninterests of various stigmas. Social stigma \nis the belief that individuals who are \nstigmatized  are less equal or are part of an \ninferior group. The social stigma that exists \nin society can create inferiority. This belief \nsystem can result in unequal access to \nservices in the community or a policy \nsetting. Self -stigma is a social stigma that is internalized by individuals (Ahmedani, \n2011) . \nStigma can have negative impact \ntowar d well -being and physical health. \nO'Donnel et al. ( 2015)  reported the results \nof research that social stigma can cause \nnegative psychological impacts, such as \ndepression, anxiety, reduced quality of life, \nnegative emotions, and decreased self -\nesteem. Stigma can lead to poor phys ical \nhealth, such as increased symptoms of \nillness, which generally include chest pain, \nnausea, coughing, to comorbid chronic \ndiseases (O'Donnel et al., 2015) .  \n According to the World Health \nOrganization (2014) , stigma is a major \ncause of discrimination  and harms family \nrelationships, limiting individuals' ability \nto socialize and find work. Stigma also \nhinders efforts to prevent mental \ndisorders, improve well -being, and access \nhealth services, as well as human rights \nviolations. Based on the description , it \nshows that stigma given to the unemployed \ncan cause mental health problems, such as \nstress and depression. Therefore, it is \ncrucial to reduce, even break the stigma of \nunemployment. In this case, the role of \nonline media is significant, especially in \nconstructing the reality of unemployment \nduring the COVID -19 pandemic through \nframing news texts in the online media.  \nStigma against unemployment is \nreported in online media. The stigma of \nunemployment was reported and discussed \nby two US online media, na mely \nusatoday.com and nbcwashington.com. \nThe online media usatoday.com reports the \nresults of interviews about uemployment \nand stigma associated with unemployment.  \nThe online media interviews unemployed \nAmericans, business people, recruitment \npractitioner s, and social and economic \nscientists. Media usatoday.com is an online \nmedia included in the top 1o US online \nnewspaper according to \n  \n  \n \n  \n \n172 Jurnal Komunikasi  \n allyoucanread.com, the most extensive \ndatabase site for media from around the \nworld (Allyoucanread, n.d.) .  \nAnother view on the stigma of \nunemployment is  found on the online \nmedia nbcwashington.com. The online \nmedia nbcwashington.com reports on the \nresults of a LinkedIn survey, interviews \nwith a career expert and provides helpful \ntips for getting a job. LinkedIn is a social \nnetworking website primarily use d for \nprofessional and business networking. \nLinkedIn surveyed 2,000 recently \nunemployed people, 2,000 working \nprofessionals, and 1,000 hiring managers. \nAccording to a LinkedIn survey cited by \nnbcwashington.com, 46% of unemployed \npeople lie about losing the ir job.  \nDifferences in views in online media \nabout the social stigma of unemployment \nare essential and worth studying because \nthe media can influence individual \nperceptions of social reality through the \ninformation conveyed and constructed. \nEspecially in t his era of media convergence, \nmedia can reach people more quickly and \nwidely (Gushevinalti et al., 2020) . News \ncoverage in the media, especially during \nthis pandemic, even affect the business o f \nbig company that has a good reputation for \na long time (Hasibuan & Irwansyah, 2020) . \nThe reality presented by the  media \nbecomes the reality that is not objective but \nthe reality of the construction results that \nare constantly changing (Utami & \nSokowati, 2021) .  \nThe reality presented by the media \ncan be perceived as less objective in \ndescribing reality. A survey conducted by \nGallup, a survey agency in the United \nStates, indicates this trend. Gallup survey \nresults show t hat most adults in the United \nStates lack confidence in the media. Six out \nof ten adults in the United States said they \n\"did not strongly believe\" (27%), and 33% \n\"did not believe at all\" in the accuracy of the media, while 9% strongly believed and 31% \nbelieved it moderately (Brennan, 2020) . \nThe survey result makes the media in the \nUnited States relevant t o study.  \nThere are different perspectives on \nunemployment and problems related with \nit during the pandemic  (Gallagher, 2021) . \nThe stigma of unemployment was reported \nby online media usatoday.com and \nnbcwashington.com. There is a difference \nin emphasis on the issue  of social stigma of \nunemployment between usatoday.com and \nnbcwashington.com even though both \nonline media are classified as media with a \nleft tendency in polarization (MBSC, \n2022b ;   MBSC, 2022a ; Allsides, 2021) . In \ngeneral, sources which is rated right or left \ntendency support almost all policies in \ntheir category. The left t endency is \ncharacterized by collectivism, community \nabove the individual, equality, educational \nopportunities, and social safety nets for \nthose in need. The right tendency is \ncharacterized by individualism, placing the \nindividual above community, private \nproperty and competition. The evaluation \nis from an American perspective and may \nnot be compatible with all countries \n(MBSC, 2021) .  \nUsatoday.com online media tends \nto be skeptical about negative stigma of \nunemployment during the COVID -19 \npandemic . The tendency to hold a \npessimistic view is reflected in one of their \nnews stories entitled \u201c\u201cAs COVID -19 \npersists, more Americans are unemployed \nbeyond six months. Does that carry a \nstigma even in a pandemic?\u201d. They stated \nthat unemployment results in de clining \nskills and prolonged unemployment can \nlead to stigma.  \nThe media nbcwashington.com also \nreported that there was a stigma of \nunemployment during the COVID -19 \npandemic in the news entitled \n\u201cUnemployment Stigma? Majority of \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 173 \n  Unemployed Believe It Exist s\u201d.  But \ndifferent from usatoday.com, they \nemphasized the optimistic perspective that \nthe unemployment problems can be \novercome and it is important to help each \nother during the COVID -19 pandemic.  \nBased on the background of the \nproblem that has been descr ibed, this study \naims to analyze the text about \nunemployment stigma in two US online \nmedia, namely usatoday.com and \nnbcwashington.com. Therefore, \nusatoday.com and nbcwashington.com \nbecomes the unit of analysis of this study.   \nThe theory used in analysis i s \ngestalt theory and meaning construction in \nframing. Online media plays an essential \nrole in constructing reality (Utami & \nSokowati, 2021) . Framing, according to \nEntman, has relevance in explaining \nstigma because it involves the process of \ngiving meaning and ways to overcome \nstigma proposed by Frost  (2011) .  \nThe construction of meaning is \ncarried out on texts in online media which \ninvolves understanding language and \ncognitive processes. The process of \nstructuring words and sentenc es as \nlanguage units and construction of \nmeaning, in general, takes place \nsimultaneously, involving dynamic \nmechanisms that represent overall \nmeaning or Gestalt  (Col et al., 2011) .  \nThe process of interpreting \nmeaning can be explained by Gestalt theory \naccording to the figure and ground \nprinciple (Wagemans et al., 2012) . Gestalt \ntheory covers a vast field, from perception \nto social life (Stemberger, 2020) . Gestalt \ntheory states that all objects or events must \nbe observed as a unified w hole and \ncomprehensive. The Law of Simplicity in \nGestalt theory shows that an object or event \nis more important than its elements. \nHumans actively interpret objects or events \nthrough perceptions that are overall, namely a unified whole or Gestalt. The \nconc ept of figure and ground in Gestalt \ntheory states that humans actively \ninterpret objects or events through overall \nperception. All perceptions tend to be \norganized into different figures from the \nground. The focus of a person's attention \ndetermines what th at person sees (Irwanto \n& Gunawan, 2018) .  \nIndividuals who talk about and \ndescribe an event perform linguistic \nconceptuali zation and pay attention to \nvarying degrees of the aspects discussed \n(Choi et al., 2018) . The concept of figure \nand ground in Gestalt theory can be applied \nin framing, where things that focus on \nattention in framing become figures, while \nthings that are not the focus become \nground. The construction of figure and \nground in the la nguage is an individual's \neffort to express experiences clearly and \neffectively in their communication (Choi et \nal., 2018) .  \nCurrently, there is few research on \nstigma and health in unemployed \nindividuals, especially in online media. The \nliterature on social stigma focuses more on \nthe stigma of mental disorders or physical \nillne ss, race, ethnicity, sexual orientation, \nwhile there is still limited literature on \nsocial stigma against unemployment (Krug \net al., 2019) .  \nUnemployment causes stigmatization,  \nwhich becomes a stressor of  psychological \nand physical health problems. However, it \nis yet known whether the stigma of being \nunemployed is related to psycholo gical and \nphysical health (O\u2019Donnell et al., 2015) . \nSocial stigma in the context of work is a \nfairly large and complex problem, where \nthere is a knowledge gap about the long -\nterm effects stigma on unemployment \n(Brouwers, 2020) .   \nThe period of unemployment is \ncharacterized by reduced social contacts, \nwhere social media helps unemployed \n  \n  \n \n  \n \n174 Jurnal Komunikasi  \n individuals to maintain their social \nrelationships (Feuls et al., 2014) . Social \nnetworks have an important role in helping \npeople find work, but research reports that \nunemployed individual rarely engage in \nnetworking. The shame related with stigma \nis an importa nt factor in the desire to \nnetwork (Peterie et al., 2019) . \nUnemployment status is a shameful social \nidentity  (Panari & Tonelli, 2022)  \nResearch shows that both \nentertainment and news media tend to \npresent a distorted image that emphasizes \ndanger, crime and negative reactions to \nindividuals with mental disorders. The \nconsequences of the negative image \npresented by the media can lead to social \nstigma. The media plays an essential role in \nchanging these n egative perceptions and \nportraying the positive side of humanity. \nThe media can play an important role in \nchallenging public prejudices (Stuart, \n2006) .  \nThis study aims to examine the \nsocial stigma of unemployment in United \nState online media during th e COVID -19 \npandemic, in this case, usa.today is \ncompared with nbcwashington.com \nthrough framing analysis. The analysis was \nconducted on the United States online \nmedia because the United States is a \ncountry that has a dominant position in \nglobalization with  mastery of information \nand communication technology (Utami & \nSokowati, 2021) . The results of this study  \ncan provide benefits for the development of \ntheoretical understanding and its \napplication from a multidisciplinary \nperspective.  \n \nMETHOD  \nThis study applies a qualitative \napproach. Qualitative research explores \nthe meaning. The construction of meaning \ncan be done through the words used to describe the experience, which has a \nconstructive dimension and reflects reality \n(Willig, 2013) .  \nThis study uses a constructivist \nparadigm that views social reality because \nof social construction so that the truth is \nrelative. Humans can int erpret and \nconstruct reality. Truth results from \nconsensus between constructors, not \nrelated to objective reality (Patton, 2002) .  \nThe reason for choosing the \nconstructivism paradigm is because the \nreality of the social stigma of \nunemployment described in the text is the \nresul t of a relative social construction, \nwhich is influenced by the subjectivity of \nnews writers in highlighting certain \ninformation in the text.  \nThe method for analysis used in this \nstudy is framing analysis, according to \nEntman. Framing analysis is a text a nalysis \nmethod that is included in a qualitative \napproach (Marta et al., 20 20). To frame \nmeans to select some aspects of reality and \nmake them more prominent in a \ncommunication text. Analysis of the frame \nshows that the influence on the mind, \nnamely human consciousness, can occur \nthrough the transfer or communication of \ninformat ion from one place, such as news, \nto consciousness. Framing has four \nfunctions: defining a problem, interpreting \nits causes, conducting a moral evaluation, \nand providing recommendations for \nproblem -solving. Problem definition is to \ndefine a problem with it s disadvantages \nand benefits; the interpretation of causes is \nthe identification of the forces that cause \nproblems. Moral judgment is an evaluation \nof the causes of problems and their effects. \nSuggestions for countermeasures provide \nways of overcoming prob lems and \npredicting possible effects (Entman, 1993) .  \nTwo online media in the United \nStates, namely usatoday.com and \nnbcwashington.com, discussed the issue of \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 175 \n  unemployment stigma. Accord ing to a US \nmedia survey, usatoday.com and \nnbcwashington.com received high ratings \nfor factual reporting due to their precise \nsources and clean fact -checking records of \nnews reporting. Both media are also \nconsidered to have a left polarization \ntendency (MBSC, 2022b ;   MBSC, 2022a ; \nAllsides, 2021) . The COVID -19 pandemic \nhas incr eased the number of \nunemployment, so that the unit of analysis \nis online media with a left -leaning tendency \nthat sided with the community and \nproviding a social safety net.  \n \n \n \n RESULTS AND DISCUSSION  \nThe frame's power is formed b y \nhighlighting certain aspect s of an event to \nattract attention while other aspects are \nignored. According to Entman (1993) , \nframing has four functions, namely \ndefining a problem, interpreting its causes, \nconducting a moral evaluation, and \nproviding recommendations for problem -\nsolving.   \n \nProblem definition Framing  \nThe function of the problem \ndefinition framing is to determine the \nproblem with its disadvantages and \nbenefits (Entman, 1993) . The problem in \ntexts defined through framing is social \nstigma.  \n \nTable 1. Defi ning Problem in usatoday.com and  nbcwashington.com  \n \nusatoday.com  nbcwashington.com  \n COVID -19 cases  are hitting new  \nrecords\u2026.  \n \nHistorically,  the long -term   unemployed  \nhave  a much tougher      time  finding  jobs  \nthan those  sidelined  for  shorter  \nspells.\u2026\u2026,  and extended  unemployment   \nmay  carry  a stigma . The COVID -19 pandemic  has left millions  \nof Americans  without  jobs. According to a  \nnew  survey  from  LinkedIn,  46%  of \nunemployed people  have  lied about  being  \nout of work.  \n84%  said  they   believe  there\u2019s  a stigma  \nassociated   with  unemployment,  67%  \nbelieve  this       stigma  is affecting   their  \nability  to get hired . \n  \n(Source: Davidson, 2020 ; Royster  & Hogan, 2020 )  \n  \nTable 1 describes the framing \nfunction of the problem definition, namely \ndetermining the problem with its \ndisadvantages and benefits (Entman, \n1993) .  \nIn usatoday. com and \nnbcwashington.com texts, the problem is \nthe social stigma on unemployment during \nthe COVID -19 pandemic. Framing on \nusatoday.com text highlights the problem \nof social stigma that persists during the COV ID-19 pandemic. Based on the Gestalt \ntheory, the problem of unemployment  \nstigma that persists during the COVID -19 \npandemic has become a figure. This social \nstigma will make it difficult for the \nunemployed to get a job. Social stigma can \nlead to inferiority  and unequal access to \nservices or policymaking (Ahmedani, \n2011) .  \nThe online m edia nbcwashington.com  \nprovides a problem definition frame about \n  \n  \n \n  \n \n176 Jurnal Komunikasi  \n the social stigma against unemployment \nbelieved to exist by unemployed \nindividuals and makes it difficult for them \nto get a job. Media nbcwashington.com \nquoted the results of a survey by \nwww. linkedin.com about the stigma of \nunemployment during the COVID -19 \npandemic. According to Gestalt theory, the \nhighlighted information or that becomes a \nfigure is a problem of social stigma \nperceived by unemployed individuals so \nthat they do not openly or co ver up their \nstatus that is not working.  \nThe unemployment stigma can be \nperceived differently, resulting in different \nfigures and ground, as written in \nusatoday.com and nbcwashington.com \nnews texts. Media nbcwashington.com \nmakes the attitude of unemployed  \nindividuals who cover their unemployment \nstatus as figures, while other information \nabout stigma becomes ground because it is \nnot discussed in depth. This difference is \nbecause the world's perception is \nsubjective, which does not correspond to \nthe actual reality, but the structure that one \nassumes about the world (J\u00e4kel et al., \n2016 ).  \nMedia usatoday.com and media \nnbcwashington.com mention the \ndisadvantage of unemployment's stigma \nbecause the stigma can affect a person's \nability to be accepted for work. The social \nstigma of unemployment does not benefit \nunemployed individuals becaus e it makes \nit difficult for them to find work.  In the usatoday.com text, framing is \ndone by highlighting social stigma that \npersists during the COVID -19 pandemic. \nBased on the Gestalt theory, the problem of \nunemployment stigma that persists during \nthe COV ID-19 pandemic has become a \nfigure. This social stigma will make it \ndifficult for the unemployed to get a job. \nSocial stigma can lead to inferiority and \nunequal access to services or policymaking \n(Ahmedani, 2011) .  \n \nProblem Cause Framing  \nInterpretation of causes is the \nidentification of the forces that cause \nproblems (Entman, 1993) . Table 2 \ndescribes the framing function that causes \nthe problem.  \nThe cause of the social stigma of \nunemployment that is highlighted or \nbecomes a figure through framing by \nusatoday.com i s the increasing number of \nunemployed due to the COVID -19 \npandemic. In addition, a person's inability \nto get a job is associated with personal \nqualities. Mental health is one aspect of \npersonal quality, where poor mental health \ncan cause a person to be une mployed for a \nlonger time and have a lower chance of re -\nentering the job market (Farr\u00e9 et al., 2018) . \nStressors can lead to adverse effects, such \nas decreased performance (Tayl or, 2018) . \nThe refusal to accept unemployed \nindividuals due to the perception of \npersonal failure is a stigma effect \n(O\u2019Donnell et al., 2015) .  \n \n \n \n \n \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 177 \n  Table 2. Problem Cause in usatoday.com and nbcwshington.com  \nusatoday.com  nbcwashington.com  \nIf a long -term   unemployed  candidate  is \ncompeting  against  others     who  are working  \nor have  been  jobless  for  shorter periods,               some  \nfirms  may   assume  \u201cthey\u2019re  not  good  workers \nor they   got turned  down  at other   places,\u201d  Van  \nHorn  says.  \u201cI think  the stigma  will be \nthere.\u201d \u2026\u2026\u201cSkills  actually  do  atrophy.\u201d  \n \nSome data supports  this skeptical view . \n Eighty -four percent   said  they  believe  \nthere\u2019s  a stigma  associated  with  \nunemployment,  67 percent believe this  \nstigma  is affecting  their  ability  to get \nhired.  \n27%  who  are unemployed  have  not asked  \nanyone   they know for help  with  their  job \nsearch . \n(Source : Davidson, 2020 ; Royster  & Hogan, 2020 )  \nThe online media nbcwashington.com  \ndeveloped a framing of the causes of the \nsocial stigma problem of unemployment in \nterms of the effect of stigma on individual \nperceptions. According to Gestalt theory, \nthe figure in this framing is the individual's \nperception of the stigma of unemployment. \nThere is a belief that the stigma associated \nwith unemployment affects the chances of \ngetting hired. In addition, unemployed \nindividuals have problems finding work \nbecause they do not ask for help when \nlooking for work, especially from people \nthey know. This condition shows that \nstigma develops from subjective \nperceptions, which can affect a person's \nattitude toward looking for work.  \nA person can have a high sti gma \nconsciousness, namely the anticipation of \ngetting a stigma. The existence of stigma \nconsciousness can cause a person to have a negative self -concept so that they do not \nask for help to get a job. This is what can \ncause individuals with a high stigma of  \nconsciousness unemployment to have a \nlow chance of working again (Krug et al., \n2019) . In addition, stigma consciousness in \nunemployed individuals can cause \npsychological distress, and declining \nmental health tends to increase \nmarginalization (Farr\u00e9 et al., 2018) . \n \nMoral Judgement Framing  \nMoral judgment is an evaluation of \nthe causes of problems and their effects \n(Entman, 1993) . Table 3 describes the \nfunction of moral judgment framing based \non an assessment and the impact of the \nproblem.  \n \nTable 3. Moral Judgement in usatoday.com and nbcwashington.com  \n \nusatoday.com  nbcwashington.com  \nDespite  employers\u2019  goodwill,  some  \neconomists  believe  the long -term  \nunemployed  will likely  face the same  old  \nemployer  biases  as the pandemic  grinds  on \nand        their   jobless stint is lengthen.  They  say they  are embarrassed  or think  \npeople  aren\u2019t   willing  to help.  \n \n(Source: Davidson, 2020 ; Royster  & Hogan, 2020 )  \n \n \n \n  \n  \n \n  \n \n178 Jurnal Komunikasi  \n  \nThe news figure in usatoday.com on \nframing moral  judgement is that there is \nstill a bias in employers against \nunemployed individuals, which is no \ndifferent from the times before the COVID -\n19 pandemic, despite good intentions from \nemployers.   \nThe nbcwashington.com stated \ndifferent things, where this onli ne media \nframing moral judgments makes the \nfeeling of shame due to unemployment a \nfigure. Media nbcwashington.com \nhighlights the psychological aspect, namely \nthe feeling of shame due to unemployment, \nand explores the impact. As a result of \nfeeling ashamed,  unemployed individuals \ndo not ask for help, so the unemployment \nproblem is not solved. Other things related \nto moral judgments are not discussed in -\ndepth or become ground; for example, the \nbias against unemployed individuals still \nexists even though they are currently in the \nCOVID -19 pandemic.  \nStigma is a psychological process \nthat involves cognition (Link & Phelan, \n2001) . Individuals can internalize social \nstigma resulting in self -stigma. The \nexistence of a s tigma in society can have an \nimpact on individuals (Ahmedani, 2011) . \nFeelings o f shame about being unemployed \ncause unemployed individuals not to ask \nfor help from others to overcome their \nproblems because of the anticipation of \nbeing stigmatized by the existence of \nstigma consciousness (Krug et al., 2019) . Countermeasures Suggestion \nFraming  \nSuggestions for countermeasures \nprovide ways of overcoming problems an d \npredicting possible effects (Entman, 1993) . \nTable 4 describes the framing of the \ncountermeasure\u2019s suggestions.  \nThe online media usatoday.com \ndeveloped a framing of countermeasure \nsugg estion with figure for the wide \ndistribution of vaccines. The distribution of \nvaccines that reach the wider community \ncan bring the economy back to life, and \nunemployed individuals can return to \nwork.  \nThe online media nbcwashington.com  \nprovides framing of  countermeasure \nsuggestions with information figure on \nways to find work that unemployed \nindividuals can do. Although stigmatized \nindividuals are considered individuals who \nhave weakness character (Krug et al., \n2019) , nbcwashington.com emphasizes \nthat they do not need to feel ashamed of the \nsocial stigma that exists in society because  \nstigma exists as a result of their perception. \nAs recipients of framing messages in text, \nnewsreaders can be influenced by \nperceiving and processing information \nabout one interpretation and having little \ndata about alternative information \n(Entman, 1993) .  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 179 \n  Table 4. Countermeasure Suggestions in usatoday.com and nbcwashington.com  \n  \nusatoday.com  nbcwashington.com  \nIf a vaccine  is  widely  distributed  by \nspring,  the economy  could  bounce        back  \nmore  swiftly than expected, and   \nchronicall y jobless workers who have \nbeen  furloughed cou ld be recalled  while    \nthose  permanently laid    off suddenly  find \na plethora of open jobs \u2026 \n \n Here  are tips to help your job  search:  \n\u2022 Use the \u201cOpen  to Work \u201d tool on  \nLinkedIn  \u2026. \n\u2022 Learn  a new  skill or improve on \nthose you already have \u2026 \n\u2022 Ask friends and  family  to reach  out  to \ntheir  networks\u2026...  \n\u2022 Use social media  and professional  \nnetworking  sites  to  let everyone  know  \n\u2022 you\u2019re  out of work \u2026 \n \n(Source: Davidson, 2020 ; Royster  & Hogan, 2020 )  \n \nThe online media nbcwashington.com  \ndeveloped a framing that during the \nCOVID -19 pandemic people need to help \neach other, including at work. The figure in \nthis framing is in the aspect of social \nsupport. In response t o the existence of \nstigma in society, it is necessary to consider \nthe process of giving meaning, \ncountermeasure suggestion, and social \nsupport (Frost, 201 1). Social support plays \nan important role in overcoming mental \nhealth problems (Davison et al., 2004) .  \nSocial support is comfort, attention, \nappreciation, or assistance given by other \npeople or groups to in dividuals. The types \nof social support include emotional or \nesteem support, tangible or instrumental \nsupport, informational support, and \ncompanionship support. Emotional \nsupport can provide entertainment, \nreassure feelings, and make someone feel \nloved when  experiencing stress. \nInformation support in the form of \nproviding advice, direction, advice, or \nfeedback on what someone is doing. \nFriendship or companionship support \nincludes the willingness of others to spend \ntime with someone, thereby providing a \nfeeli ng of membership in a group that \nshares interests and social activities \n(Sarafino & Smith, 2011) .  Online media can provide \ninformation support through framing with \ninformation figure that can solve the \nproblem of unemployment. The solution to \nthe unemployment problem can be \nexplored in its meaning in the news text. It \nis done by nbcwashington.com, which \nreviews practical suggestions for finding \nwork for unemployed individuals and \nprovi des an optimistic view. The solution to \nthe unemployment problem is constructed \nas something internal, where individuals \ncan overcome the unemployment \nproblems, they experience by building \npositive perceptions of themselves and \nothers. This situation means  that the \nunemployed individual must eliminate the \nstigma of consciousness that can hinder \nhim from developing his potential.  \nMedia nbcwashington.com mentions  \nthe importance of developing one's \npotential by learning new skills. The \ndevelopment of self -potential is significant, \nespecially in the current era of \nglobalization, where individuals must \ndevelop global competencies that include \nhard and soft skills. Hard skills can be \nmastering foreign languages and \ndeveloping technical excellence, while soft \nskills, such as developing professional work \nattitudes, having intercultural sensitivity, \n  \n  \n \n  \n \n180 Jurnal Komunikasi  \n and fighting power in overcoming \nproblems (Panggabean, 2012) . Technology \ncan help society especially in the era of \npandemic to do activities, such as  \nRuangGuru as the solution of online \nlearning (Chinmi et al., 2020) . \nHumans need to have an \norientation that can truly be lived based on \nunderstanding and self -knowledge (Marta, \n2017) . Unemployed individuals need to \ndevelop positive perceptions about \nthemselves, such as not feeling ashamed, \nbeing open about unemployment, and \nseeking help. The f eeling of shame is \nrelated to inferiority or feelings of \ninferiority due to unemployment \n(Ahmedani, 2011) . Negative views from \nother people can be internalized by \nindividuals, giving rise to stigma \nconsciousness which causes individuals to \nanticipate rejection from others. It makes \nunemployed individuals tend to be less \nopen and not seek help to solve their \nproblems. Negative perceptions about the \nstigma of unemployment become a ground \nnot highlighted in the nbcwashington.com \nnews text. On the other hand, \nusatoday.com media presents a framing of \nunemployment solutions with external \nsolution figures, namely the availability of \nvaccines in sufficient quantities and \neconomic assistance from the government \nfor unemployed individuals. The \ndeveloping aspect of individual potential is \nthe ground in the USA.  Today media \nframing, and those unem ployed \nindividuals can work again if the economy \nrecovers after the vaccine is widely \ndistributed. This vaccination solution does \nnot explore self -potential development as \nin the nbcwashington.com media framing.  \nOnline media can provide \ninformation suppor t that can be a solution \nto the problem of unemployment. If this is \nnot addressed correctly, then the impact is \nthat the mental health of unemployment \ncannot be handled properly, and unemployed individuals do not obtain \ninformation that can be a solution t o their \nproblems.  \nOnline media can provide \ninformation support by presenting \nmessages based on objective data. The \nresults of a Gallup survey of the media \nshow that most adults in the United States \nlack confidence in the media (Brennan, \n2020) . The media need to pay attention to \nobjectivity in conveying information \nbecause the information presented is the  \nresult of the construction of news writers. \nDiscussions on the issue of social stigma in \nonline media texts usatoday.com and \nnbcwashington.com show that there are \ndifferent meaning constructions on the \nsocial stigma of unemployment. The \nselection of figur es and ground in \ndiscussing the problem of social stigma of \nunemployment can affect the perception of \nnews readers about the stigma of \nunemployment. For example, the media \nusatoday.com gives a view that tends to be \nskeptical, that unemployed individuals st ill \nhave difficulty getting jobs because the \nnumber of job opportunities is limited \nwhile job applicants are many and \nrecruitment managers tend to be selective. \nThe stigma of unemployment persists and \nmakes it difficult for unemployed \nindividuals to find w ork. On the other \nhand, the nbcwashington.com media sees \nthe problem of social stigma from a \ndifferent perspective that is more \noptimistic, that the unemployment \nproblem can be handled if individuals are \nopen, eliminate feelings of shame due to \nunemploymen t, do not hesitate to ask for \nhelp, and eliminate the perception that \nother people are not willing to help.  \nPresenting information objectively \nthrough online media can be a means of \neducation for the public (Sadmego & \nNasucha, 2019) . Objective information can \nalso provide benefits and produce optimal \nsolutions for various problems in the \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 181 \n  community, especially the pr oblem of \nunemployment.  \n \nCONCLUSION  \n Online media plays an essential \nrole in the construction of reality. Framing \ninvolves constructing meaning towards \nsocial stigma, so it plays an essential role in \nrepresenting the phenomenon of social \nstigma in online m edia.  \nThe construction of meaning \ninvolves understanding language and \ncognitive processes that coincide, which \nresults in an overall representation of \nmeaning that can be explained by Gestalt \ntheory. The concept of figure and ground in \nGestalt theory can be applied in framing, \nwhere things that focus on attention in \nframing become figure, while things that \nare not the focus become ground. The \nsocial stigma problem of unemployment \ncan be constructed with different figure \nand ground to produce different fram ing of \nthe same topic in news texts in online \nmedia. The construction of figure and \nground in a language attempt to express \nexperience clearly and effectively in \ncommunication.  \nThe problem formulated through \nframing is that social stigma makes it \ndifficul t for unemployed people to get a job. \nStigma of unemployment creates feelings \nof inferiority, such as feeling of shame. The \ncause of the social stigma is perception low personal qualities and stigma \nconsciousness, namely the anticipation of \ngetting a stigm a. Stigma consciousness can \ncause a person to have a negative self -\nconcept so that they do not ask for help to \nget a job. This condition can cause \nundemployed individuals to have a low \nchance of working again. Framing moral \njudgement is stigma related with  tendency \nof having a negative perception in \nemployers mind toward unemployed \nindividuals.  Social stigma also created the \nfeeling of shame due to unemployment. \nFraming countermeasure suggestion is \nwide distribution of vaccines and \nsuggestions about ways t o find work and \nimprove skills.  \nThe social stigma of unemployment \nthat exists in society can harm individuals. \nIt does not provide benefits because it can \nmake it difficult for unemployed \nindividuals to find work, cause mental \nhealth problems and marginal ization. \nOnline media can contribute as agents of \nchange in the social stigma of \nunemployment through news framing that \ncan improve public perceptions and \nattitudes     towards   unemployment.  It   is \nIt is further expected to reduce the stigma \nof unemplo yment. Online media can also \nhelp people to understand the social stigma \nof unemployment by providing \ninformational support in the form of \nwriting that can solve the problem of \nunemployment.  \n \n \n \n \n \n \n \n  \n  \n \n  \n \n182 Jurnal Komunikasi  \n REFERENCES  \n \nAhmedani, B. K. (2011). Mental Health \nStigma: Society, Individuals, and the \nProfession. Journal of Social Work \nValues and Ethics , 8(2), 41 \u2013416. \nhttps://www.ncbi.nlm.nih.gov/pmc/\narticles/PMC3248273/  \nAllsides. (2021). USA Today . \nhttps://www.allsides.com/ news -\nsource/usa -today -media -bias#July \n2021  \nAllyoucanread. (n.d.). Top 30 US \nNewspapers & News Sites . \nhttps://www.allyoucanread.com/ame\nrican -newspapers/  \nBrennan, M. (2020). American remain \ndistrustful of mass media . \nhttps://news.gallup.com/poll/321116\n/ameri cans -remain -distrustful -mass -\nmedia.aspx  \nBrouwers, E. P. M. (2020). Social stigma \nis an underestimated contributing \nfactor to unemployment in people \nwith mental illness or mental health \nissues: Position paper and future \ndirections. BMC Psychology , 8(1), 1 \u2013\n7. https://doi.org/10.1186/s40359 -\n020-00399 -0 \nChinmi, M., Marta, R. F., Haryono, C. G., \nFernando, J., & Goswami, J. K. \n(2020). Exploring online news as \ncomparative study between Vendatu \nat Indiaand Ruangguru from \nIndonesia in COVID -19 pandemic. \nJournal of C ontent, Community and \nCommunication , 10(6), 167 \u2013176. \nhttps://doi.org/10.31620/JCCC.06.2\n0/13  \nChoi, S., Goller, F., Hong, U., Ansorge, U., \n& Yun, H. (2018). Figure and Ground \nin spatial language: Evidence from \nGerman and Korean. Language and \nCognition , 10(4), 665 \u2013700. \nhttps://doi.org/10.1017/langcog.201\n9.3 Col, G., Aptekman, J., Girault, S., & \nPoibeau, T. (2011). Gestalt \nCompositionality and Instruction -\nBased Meaning Construction. Cogn \nProcess , 13(2), 151 \u2013170. \nhttps://doi.org/10.1007/s10339 -011-\n0431 -y \nDavidso n, P. (2020). As COVID -19 \npersists, more Americans are \nunemployed beyond 6 months. Does \nthat carry a stigma even in a \npandemic?  \nhttps://www.usatoday.com/story/mo\nney/2020/12/04/jobs -near -me-\nchronic -unemployment -stigma -even -\nduring -pandemic/3804962001/  \nDaviso n, G. C., Neale, J. M., & Kring, A. \nM. (2004). Abnormal psychology \n(9th ed.)  (9th ed.). John Wiley & \nSons, Inc.  \nEntman, R. M. (1993). Framing: Toward \nClarification of a Fractured \nParadigm. Journal of \nCommunication , 43(4), 51 \u201358. \nhttps://doi.org/10.1111/j.1 460-\n2466.1993.tb01304.x  \nFarr\u00e9, L., Fasani, F., & Mueller, H. (2018). \nFeeling useless: The effect of \nunemployment on mental health in \nthe great recession. IZA Journal of \nLabor Economics , 7(8), 1 \u201334. \nhttps://doi.org/10.1186/s40172 -018-\n0068 -5 \nFeuls, M., Fiese ler, C., & Suphan, A. \n(2014). A social net? Internet and \nsocial media use during \nunemployment. Work, Employment \nand Society , 28(4), 551 \u2013570. \nhttps://doi.org/10.1177/0950017013\n519846  \nFrost, D. M. (2011). Social Stigma and its \nConsequences for the Socially  \nStigmatized. Social and Personality \nPsychology Compass , 5(11), 824 \u2013\n839. https://doi.org/10.1111/j.1751 -\n9004.2011.00394.x  \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 183 \n  Funk, C., Tyson, A., Kennedy, B., & \nJohnson, C. (2020). Science and \nscientists held in high esteem across \nglobal publics . \nhttps://www. pewresearch.org/scienc\ne/2020/09/29/science -and-\nscientists -held -in-high -esteem -\nacross -global -publics/  \nGallagher, C. (2021). Employment Trends \nMedia and Social Media Analysis: A \nLook into the Evolving \nConversations Inside and Outside \nthe Beltway . https://for bes-\ntate.com/employment -trends -media -\nand-social -media -analysis -a-look -\ninto-the-evolving -conversations -\ninside -and-outside -the-beltway/  \nGoffman, E. (1963). Stigma: Notes on the \nmanagement of spoiled identity . \nPrentice Hall.  \nGushevinalti, G., Suminar, P., & \nSunaryanto, H. (2020). Transformasi \nKarakteristik Komunikasi Di Era \nKonvergensi Media. Bricolage: \nJurnal Magister Ilmu Komunikasi , \n6(01), 083. \nhttps://doi.org/10.30813/bricolage.v\n6i01.2069  \nHammarstr\u00f6m, A., & Ahlgren, C. (2019). \nLiving in the shadow of \nunemp loyment -an unhealthy life \nsituation: A qualitative study of \nyoung people from leaving school \nuntil early adult life. BMC Public \nHealth , 19(1), 1 \u201312. \nhttps://doi.org/10.1186/s12889 -019-\n8005 -5 \nHasibuan, M. R., & Irwansyah, I. (2020). \nStrategi Image Repai r PT HM \nSampoerna TBK pada peristiwa \n\u2018karyawan pabrik Surabaya positif \nCOVID -19.\u2019 Jurnal Komunikasi , \n15(1), 1 \u201318. \nhttps://doi.org/10.20885/komunikas\ni.vol15.iss1.art1  \nIrwanto, & Gunawan, F. Y. (2018). \nSejarah Psikologi  (1st ed.). PT \nGramedia Pustaka Utama.  J\u00e4kel, F., Singh, M., Wichmann, F. A., & \nHerzog, M. H. (2016). An overview of \nquantitative approaches in Gestalt \nperception. Vision Research , 126, 3\u2013\n8. \nhttps://doi.org/10.1016/j.visres.2016\n.06.004  \nKrug, G., Drasch, K., & Jungbauer -Gans, \nM. (2019). The Soci al Stigma of \nUnemployment: Consequences of \nStigma Consciousness on Job Search \nAttitudes, Behaviour and Success. \nJournal for Labour Market \nResearch , 53(11), 1 \u201327. \nhttps://doi.org/10.1186/s12651 -019-\n0261 -4 \nLi, F., Luo, S., Mu, W., Li, Y., Ye, L., \nZheng, X., Xu, B., Ding, Y., Ling, P., \nZhou, M., & Chen, X. (2021). Effects \nof Sources of Social Support and \nResilience on the Mental Health of \nDifferent Age Groups During the \nCOVID -19 Pandemic. BMC \nPsychiatry , 21(1), 1 \u201314. \nhttps://doi.org/10.1186/s12888 -020-\n03012 -1 \nLink, B. G., & Phelan, J. C. (2001). \nConceptualizing stigma. Annual \nReview of Sociology , 27(2001), 363 \u2013\n385. \nhttps://doi.org/10.1146/annurev.soc.\n27.1.363  \nMarta, R. F. (2017). Esensi Dan Pemetaan \nTeoretisasi Media Komunikasi Dalam \nPerspektif Karl Marx. Bricolage: \nJurnal Magister Ilmu Komunikasi , \n2(02), 117 \u2013123. \nhttps://doi.org/10.30813/bricolage.v\n2i02.839  \nMarta, R. F., Prasetya, A. A., Laurensia, B., \nStevani, S., & Syarnubi, K. L. (2020). \nImbalance Identity in E -Sports News \nIntersectionality on Covid -19 \nPandemic Situation. Jurnal \nASPIKOM , 5(2), 206. \nhttps://doi.org/10.24329/aspikom.v\n5i2.769  \n \n  \n  \n \n  \n \n184 Jurnal Komunikasi  \n MBSC. (2021). Left vs. Right Bias: How \nwe rate the bias of media sources . \nhttps://mediabiasfactcheck.com/left -\nvs-right -bias-how -we-rate-the-bias-\nof-media -sources/  \nMBSC. (2022a). NBC Washington . \nhttps://mediabiasfactcheck.com/wrc\n-tv-nbc-washington/  \nMBSC. (2022b). USA Today . \nhttps://mediabiasfactcheck.com/usa -\ntoday -2/ \nO\u2019Donnell, A. T., Corrigan, F., & \nGallagher, S. (2015). The impact of \nanticipated stigma on psychological \nand physical health problems in the \nunemployed group. Frontiers in \nPsychology , 6(August), 1 \u20138. \nhttps://doi.org/10.3389/fpsyg.2015.\n01263  \nPanari, C., & Tonelli, M. (2022). Future \nDirections in the Research on \nUnemployment: Protean Career \nOrientation and Perce ived \nEmployability Against Social \nDisadvantage. Frontiers in \nPsychology , 12(January), 1 \u20137. \nhttps://doi.org/10.3389/fpsyg.2021.\n701861  \nPanggabean, H. (2012). Peran \nPengalaman Studi ke Luar Negeri \ndalam Membangun Kompetensi \nGlobal. Mind Set , 3(2), 73 \u201383. \nPatton, M. Q. (2002). Qualitative \nresearch and evaluation methods  \n(3rd ed.). Sage Publications, Inc.  \nPeterie, M., Ramia, G., Marston, G., & \nPatulny, R. (2019). Social Isolation as \nStigma -Management: Explaining \nLong -Term Unemployed People\u2019s \n\u2018Failure\u2019 to Netwo rk. Sociology , \n53(6), 1043 \u20131060. \nhttps://doi.org/10.1177/0038038519\n856813  \n \n Royster, M., & Hogan, S. (2020). \nUnemployment Stigma? Majority of \nUnemployed Believe It Exists.  \nhttps://www.nbcwashington.com/ne\nws/consumer/unemployment -\nstigma -majority -of-unemployed -\nbelieve -it-\nexists/2457227/#:~:text=LinkedIn \nsurveyed 2%2C000 people \nrecently,their ability to get hired.  \nSadmego, V. B., & Nasucha, M. (2019). \nFraming News on Religion and Living \nEnvironment in Online Media. \nJurnal Komunikasi , 14(1), 93 \u2013104. \nhttps://doi.o rg/10.20885/komunikas\ni.vol14.iss1.art6  \nSarafino, E. P., & Smith, T. W. (2011). \nHealth psychology  (7th ed.). John \nWiley & Sons, Inc.  \nScheufele, D. A. (1999). Framing as a \ntheory of media effects. Journal of \nCommunication , 49(1), 103 \u2013122. \nhttps://doi.org/10. 1111/j.1460 -\n2466.1999.tb02784.x  \nSchrader, D. E. (2015). Constructivism \nand Learning in the Age of Social \nMedia: Changing Minds and \nLearning Communities. New \nDirections for Teaching and \nLearning , 2015 (144), 23 \u201335. \nhttps://doi.org/10.1002/tl.20160  \nSetiawan,  J. H., Caroline, C., & \nMuharman, D. (2021). Content \nAnalysis of Readers\u2019 Comments on \nMedia Aggregator as Feedback and \nForm of Public Opinion about \nCOVID -19. Aspiration Journal , 2(1), \n51\u201370. \nStemberger, G. (2020). Does a Society for \nGestalt Theory and Its Applications \nStill Fit in Our Time? Gestalt Theory , \n42(1), 63 \u201370. \nhttps://doi.org/10.2478/gth -2020 -\n0005  \n \n \n \n \n \n \n \nVolume 16, Nomor 2, April 2022, Hal 169-186 185 \n  Stuart, H. (2006). Media Portrayal of \nMental Illness and Its Treatments: \nWhat effect does It Have on People \nwith Mental Illness? CNS Drugs , \n20(2), 99 \u2013106. \nhttps://doi.org/10.2165/00023210 -\n200620020 -00002  \nSuparno. (2018). Gender -Based Poverty \nAlleviation in Grobogan Regency. \nKomunitas: International Journal of \nIndonesian Society and Culture , \n10(2), 157 \u2013168.  \nTaylor, S. E. (2018). Health psychology  \n(10th ed. ). McGraw -Hill Education.  \nTyler, I., & Slater, T. (2018). Rethinking \nthe Sociology of Stigma. The \nSociological Review Monographs , \n66(4), 721 \u2013743. \nhttps://doi.org/10.1177/0038026118\n777425  \nUN. (2022). COVID crisis to push global \nunemployment over 200 million  \nmark in 2022 . \nhttps://news.un.org/en/story/2021/\n06/1093182  \n Utami, M., & Sokowati, M. E. (2021). \nKonstruksi Identitas Global Dan \nLokal Dalam Majalah Gogirl!: Sebuah \nHibriditas (Analisis Semiotik Majalah \nGogirl! Edisi 101 Bulan Juni Tahun \n2013). Jurnal Komu nikasi , 15(2), 91 \u2013\n108. \nhttps://doi.org/10.20885/komunikas\ni.vol15.iss2.art2  \nWagemans, J., Elder, J. H., Kubovy, M., \nPalmer, S. E., Peterson, M. A., Singh, \nM., & Heydt, R. von der. (2012). A \nCentury of Gestalt Psychology in \nVisual Perception I. Perceptual \nGrouping and Figure -Ground \nOrganization. Psychol Bull , 138(6), \n1172 \u20131217. \nhttps://doi.org/10.1037/a0029333.A  \nWHO. (2014). Stigma and discrimination.  \nhttps://www.euro.who.int/en/health\n-topics/noncommunicable -\ndiseases/mental -health/priority -\nareas/stigma -and-discrimination  \nWillig, C. (2013). Introducing qualitative \nresearch in psychology  (3rd ed.). \nMcGraw -Hill Education.  \n \n.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n  \n \n186 Jurnal Komunikasi  \n  \n \n \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Stigma sosial pengangguran di media daring Amerika Serikat pada masa pandemi COVID-19", "author": ["E Evanytha", "RF Marta", "H Panggabean"], "pub_year": "2022", "venue": "Jurnal \u2026", "abstract": "The social stigma of unemployment during the COVID-19 pandemic related to problems of  marginalization. This study explores the construction of the meaning of the social stigma of"}, "filled": false, "gsrank": 743, "pub_url": "https://journal.uii.ac.id/jurnal-komunikasi/article/view/20545", "author_id": ["CWcE1g8AAAAJ", "FhIdteAAAAAJ", "Nu6pW_oAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:QkGa66R0G6cJ:scholar.google.com/&output=cite&scirp=742&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=QkGa66R0G6cJ&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 5, "citedby_url": "/scholar?cites=12041346280381366594&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:QkGa66R0G6cJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journal.uii.ac.id/jurnal-komunikasi/article/download/20545/13658"}}, {"title": "Characterizing the roles of bots during the COVID-19 infodemic on Twitter", "year": "2020", "pdf_data": "Noname manuscript No.\n(will be inserted by the editor)\nCharacterizing the roles of bots during the\nCOVID-19 infodemic on Twitter\nWentao Xu1\u0001Kazutoshi Sasahara2\nReceived: date / Accepted: date\nAbstract An infodemic is an emerging phenomenon caused by an overabun-\ndance of information online. This proliferation of information makes it di\u000ecult\nfor the public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic de-\nbuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots be-\nhaved during the infodemic is unclear. In this paper, we examined the roles of\nbots in the case of the COVID-19 infodemic and the di\u000busion of non-credible\ninformation such as \\5G\" and \\Bill Gates\" conspiracy theories and content\nrelated to \\Trump\" and \\WHO\" by analyzing retweet networks and retweeted\nitems. We show the segregated topology of their retweet networks, which in-\ndicates that right-wing self-media accounts and conspiracy theorists may lead\nto this opinion cleavage, while malicious bots might favor ampli\fcation of the\ndi\u000busion of non-credible information. Although the basic in\ruence of informa-\ntion di\u000busion could be larger in human users than bots, the e\u000bects of bots are\nnon-negligible under an infodemic situation.\nKeywords Bot\u0001COVID-19\u0001Conspiracy theory \u0001Infodemic\u0001Misinfomation\u0001\nSocial media\n1 Introduction\n\\We're \fghting an infodemic. Fake news spreads faster and more easily than\nthis virus, and is just as dangerous...\" said the World Health Organization\nE-mail: myrainbowandsky@gmail.com\n1Graduate School of Informatics, Nagoya University, Japan\n2School of Environment and Society, Tokyo Institute of Technology, JapanarXiv:2011.06249v4  [cs.CY]  19 Aug 2021\n2 Wentao Xu1, Kazutoshi Sasahara2\n(WHO) Director-General on February 15, 2020 [1]. Prior to this comment, a\nlarge amount of misinformation about the new coronavirus emerged on popular\nsocial networking sites (SNSs) and these began to play a major role in the di\u000bu-\nsion of misinformation. According to [2], in terms of information sources, top-\ndown misinformation from politicians, celebrities, and other prominent pub-\nlic \fgures accounted for 69% of total social media engagement. Additionally,\napproximately 60% of the COVID-19 related information was recon\fgured,\ntwisted, recontextualized and reworked on Twitter, while 38% of the misinfor-\nmation was completely fabricated. The fact-checking organization, Politifact\nalso pointed out that trustful and mostly trustful news about the coronavirus\ncomprised only up to 10% of the total information [3] being disseminated.\nSNS users tend to connect to like-minded users, which is known as the \\birds-\nof-a-feather phenomenon\" or homophily [4,5]. Meanwhile, users also tend to\nfollow in\ruencers and celebrities on SNS who present themselves as informa-\ntion hubs. Thus, when an in\ruencer posts misinformation, his or her followers,\noften with no doubts about the content, tend to believe it and share the post\nin a homophilic social network.\nIn addition to human users, previous studies have shown that bots (i.e.,\nautomated accounts controlled by a set of algorithms) play a key role in propa-\ngating misinformation. [6] discussed how bots engaged with humans to increase\ntheir in\ruence. A well-known case in politics is the 2016 US presidential elec-\ntion, during which bots were used to widely di\u000buse misinformation [7,8]. It was\nestimated that of all tweeted links to popular websites, 66% were shared by\nbots [9]. [10] analyzed 43.3 million English tweets and found the preferences\nof bots and humans in tweet contents by analyzing n-grams and hashtags.\nFurthermore, it was suggested that bots may play a critical role in driving\nthe viral spread of content from low-credibility sources and may be able to\namplify misinformation [11]. [12] found that social bots increased from 7.1%\nto 9.9% when examining German Twitter followers' prevalence and activi-\nties of seven German parties before the 2017 electoral campaigns. Bots were\nalso used for spreading and amplifying vaccine misinformation [13]. Research\nabout the COVID-19 infodemic has discovered the information \row pathways\nbetween humans and bots [14]. A study of social media manipulation in the\n2020 US presidential election characterized the di\u000berences between right and\nleft-leaning bot behavior [15]. In addition, bot activity is believed to be linked\nto hate toxicity in denser and more isolated local communities in both the US\nand the Philippines [16].\nThere are several methods for bot characterization and identi\fcation. Botome-\nter is a well-known tool for automatically detecting bots based on supervised\nmachine learning models [17,18]. Botometer examines six classes of features\nincluding pro\fle, friends, social network, temporal activity patterns, language,\nand sentiment which is further categorized into approximately 1,200 features\nfor a Twitter account. This tool computes a \\bot score\" for each user that\nranges from 0.0 to 1.0. The higher the score, the higher the probability that\nthe user is a bot. Botometer is a state-of-the-art tool for identifying bots, and\na series of studies have used this tool to quantify their online behaviors of bots\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 3\n[11,19]. We applied Botometer in our study therefore, to discriminate between\nbots and humans.\nGiven this context, an important research question is how bots behaved in\nthe spread of misinformation during the COVID-19 infodemic. To study this,\nwe focused on retweets on Twitter. Retweet is an information sharing behavior\nby which any user can share messages immediately with his or her followers.\nA retweet can be both a productive communicative tool and a sel\fsh act of at-\ntention seekers [20]. [21] found that an popular tweet has either an interesting\ncontext or it is produced (retweeted) by an in\ruencer. [22] pointed out that a\nuser's high popularity does not necessarily imply a high level of in\ruence and\nvice-versa, indicating that an in\ruencer's popularity and in\ruence are weakly\ncorrelated. However, [23,24,25] considered that a user's contextual information\n(e.g., social network topology, tweet content, URLs) a\u000bects the retweet behav-\nior. In this paper, we used retweets to address information-sharing behavior,\nshedding light on how COVID-19 misinformation is shared in an information\necosystem where bots live.\nMisinformation is classi\fed into several types and conspiracy theory is one\ntype [26]. The negative e\u000bect of a conspiracy theory is to elicit emotions includ-\ning avoidance, fear, anger, aggression and further result in irrational behaviors\n[26]. As an example, the 5G conspiracy theory was reported on January 22\nby a local Belgian newspaper, reporting that a local doctor claimed that 5G\nmight be linked to the coronavirus [27]. In the UK, 5G cell-phone masts came\nunder arson attacks due to this conspiracy theory [28]. Another version of\nthis conspiracy theory claims that 5G alters people's immune systems and\nchanges DNA structures, thus increasing people's susceptibility to contract-\ning the coronavirus [29,30]. Another popular conspiracy theory targeted Bill\nGates, co-founder of Microsoft Corporation, and claimed that Gates supported\nimplanting tracking chips in people under the pretext of a mandatory coro-\nnavirus vaccination [31,32]. US political groups were reported as showing a\nsigni\fcant partisan bias regarding this conspiracy [33]; compared to the left\nwing, the right wing was more inclined to believe in this conspiracy.\nTo investigate the spreading of misinformation during the COVID-19 info-\ndemic, we focused on the above-mentioned conspiracy theories related to 5G\nand Bill Gates as mentioned above. For comparison, we also focused on other\ntopics, such as \\WHO\" and \\Trump\" (the 45th US president). These keywords\nwere selected because health and political misinformation \rourished during the\nCOVID-19 infodemic. Moreover, recent research revealed that Trump was the\nlargest driver of COVID-19 misinformation [34].\nIn this paper, we \frst characterize the credible and non-credible bots\naround the four topics in the retweet networks. We then compare the retweet\nactivities as well as other features in the four topics considered. Our results\nmay help us understand how bots played a role during the COVID-19 info-\ndemic and provide insights into a mitigation strategy.\n4 Wentao Xu1, Kazutoshi Sasahara2\n2 Data and Methods\n2.1 Data collection and preprocessing\nWe used Twitter as a data source to characterize the COVID-19 infodemic. We\ncollected 279,538,960 English tweets from February 20 to May 31 by query-\ning COVID-19 related keywords: \\corona virus\"; \\coronavirus\"; \\covid19\";\n\\2019-nCoV\"; \\SARS-CoV-2\"; and \\wuhanpneumonia\" using Twitter's stan-\ndard search API. We focused on four topics in our analyses: \\WHO\"; \\Trump\";\n\\Bill Gates\"; and \\5G\" as noted. Extracting tweets regarding these topics\nresulted in a total of 37,219,979 tweets, of which 23,1515,441 (82.8%) were\nretweets. The breakdown of this dataset is shown in Table 1. Some users in\nour dataset could be considered malicious and were suspended based on Twit-\nter's spam policy during the period between the date we collected the tweets\nand the date we computed the corresponding bot scores; These users were,\nthus, not included in our analyses.\nAccording to a list of non-credible websites released on MisinfoMe1and\na list of non-credible news website domains released in [35], 893 responsive\nwebsites from the total of 1,143 domains were collected and used as the non-\ncredible domain list. We also examined a list of trustworthy rated media re-\nleased by [36] and retrieved 30 (all responsive) credible media domains. In\naddition, we added major science journals Nature2andScience3as credible\ndomains. Thus, we obtained a total of 32 credible domains and used these\nas the credible domain list. Based on the credible and non-credible domain\nlists, each tweet was labelled as \\credible\" if the tweet included a URL in the\ncredible domain list, and as \\non-credible\" if the tweet included a URL in the\nnon-credible domain list. Then, given a topic, each user was labelled as \\cred-\nible\" if the user retweeted credible tweets exclusively and \\non-credible\" if the\nuser retweeted non-credible tweets exclusively. In other words, non-credible\nusers are those who posted with URLs from the non-credible domain list at\nleast once but never posted with URLs from the credible domain list. Credible\nusers were similarly de\fned. Note that a user's label can change from topic to\ntopic. For instance, a user is labeled \\credible\" in the WHO topic if the user\nretweets credible domains, exclusively in that topic, even if the user retweets\nnon-credible domains in other topics.\nFurthermore, we used the Botometer API V3 to compute bot scores of\nusers. In this study, we used the CAP (complete automation probability) value\ninstead of the raw bot score. Given a screen name of a Twitter account, the\nBotometer returns a CAP value ranging from 0.0 to 1.0. After multiple trials\nof analyses, We set 0.54 as the threshold in our analyses. This means that a\nuser was considered to be a bot if the CAP value was larger than or equal to\n0.54; otherwise, the user was considered to be human.\n1https://misinfo.me\n2https://www.nature.com\n3https://www.sciencemag.org/\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 5\nTable 1: Overview of COVID-19 tweets by topic\nUnique\nusers (U)Unique Users\nwith\nBot score (US)Percentage\n(US/S)# Tweets # Retweets\nWHO 88,719 73,704 83.1 128,016 46,650\nTrump 1,125,251 947,694 84.2 5,631,459 2,322,036\n5G 67,523 55,315 81.9 97,638 31,814\nBill Gates 94,584 77,896 82.3 138,042 75,885\nUsing the above discriminative conditions for credible/non-credible and\nbot/human, we classi\fed users into \fve types for analyses: credible humans\n(CH), non-credible humans (NH), credible bots (CB), non-credible bots (NB),\nand the other.\n2.2 Veri\fcation of user classes\nThe classi\fcation results of users in the previous section (i.e., CH, CB, NH,\nNB) a\u000bect the results of our analyses. We con\frmed the reliability of the\nclassi\fcation using manual veri\fcation as described next.\nFor bot classi\fcation, we randomly selected 200 accounts from our dataset,\nwith 100 labeled as bots and 100 labeled as humans. We provided two human\nworkers with these account names and asked them to independently read pro-\n\fles and tweets by each user and then classify the user as a bot or human.\nThen we checked the classi\fcation consistency by computing Cohen's kappa\ncoe\u000ecient. The resulting \u0014= 0:68 indicates substantial agreement between\nthe two workers, indicating that the bot score threshold used is su\u000eciently\nreliable. Note that according to [37], Cohen's kappa value is interpreted as\nfollows: 0.0-0.2 for slight agreement; 0.2-0.4 for fair agreement; 0.4-0.6 for\nmoderate agreement; 0.6-0.8 for substantial agreement; and 0.8-1.0 for near\nperfect agreement.\nA similar veri\fcation process was conducted for credible/non-credible clas-\nsi\fcation with two additional workers. They evaluated 100 randomly selected\naccounts, with 50 labeled as credible and 50 labeled as non-credible, by reading\ntheir tweets and pro\fles, and then classi\fed them as credible or non-credible\nusers. After that, Cohen's kappa was computed and resulted in \u0014= 0:70, in-\ndicating a signi\fcant match. In this way, credible/non-credible classi\fcation\nbased on the above-mentioned criteria is, likewise, su\u000eciently reliable.\n2.3 Retweet behavior analysis\nTo examine information spreading patterns by topic, we constructed a retweet\nnetwork for each topic, in which nodes represent users and a directed edge was\nmade from the source to the target if a target user is retweeted by a source\nuser. The structural features were quanti\fed using these retweet networks.\n6 Wentao Xu1, Kazutoshi Sasahara2\nFor visibility, we illustrated the retweet network by including only bots and\nselected accounts (as anchors) by using the software Gephi [38], with the graph\nlayout algorithm ForceAtlas2 [39]. We highlighted the selected users with a\nlarge indegree that includes famous politicians, well-known mainstream media,\nand right-wing media from the top 40 indegree users. Moreover, we compared\ntemporal patterns of retweet activities by topic among four types of users (i.e,\nCH, CB, NH, NB).\nFurthermore, we quanti\fed how bots interacted with media and celebri-\nties using the aggregated retweet network ( n= 211) based on the bots that\nappeared across the topics. For this, we \frst identi\fed 19 credible media and\ncelebrity accounts (CM and CC), and 12 non-credible counterparts (NM and\nNC) in reference to their user pro\fles, their Wikipedia articles, and the o\u000e-\ncial websites, Media Bias / Fact Check,4etc. Then, we classi\fed media and\ncelebrity accounts as: (a) those retweeted by non-credible bots only; (b) those\nretweeted by both credible and non-credible bots; and (c) those retweeted by\ncredible bots only. The network visualization process was the same as above.\n2.4 Retweeted contents analysis\nWe also looked at di\u000berences in the contents of the retweeted URLs in each\ntopic. Retweets in our COVID-19 dataset did not contain a su\u000ecient amount of\ntexts, instead using hyperlinks or URLs to online articles. Thus, we focused on\ntweets including URLs to online articles and collected these articles retweeted\nby credible/non-credible humans and bots, separately. We characterized the\narticles based on terms (nouns), with their importance measured by the TF-\nIDF score. For this analysis, we selected the top 30 terms from credible users\nand the top 30 terms from non-credible users, and then merged them without\nduplicates from the collected articles.\nTF-IDF stands for term frequency{inverse document frequency and is com-\nmonly used in natural language processing (NLP). TF-IDF is calculated as\nfollows:\nTF\u0002IDF; (1)\nwhereTFis the number of a given term (noun). We used the following formula\nfor IDF:\nIDF = lnN\nd; (2)\nwhereNrepresents the total number of documents, and drepresents the num-\nber of documents that include the term.\nTo compare important terms used in articles retweeted by credible and\nnon-credible users, we summarized TF-IDF values by using the laterality index\n(LI) [40], de\fned as follows:\nLI=C\u0000NC\nC+NC;LI2[\u00001;1]; (3)\n4https://mediabiasfactcheck.com\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 7\nwhereCis the TF-IDF score for terms used in articles retweeted by credible\nusers andNCis used for terms used in articles retweeted by non-credible users.\nLIcompares the importance of a term between credible sites and non-credible\nsites. A negative LIindicates that the term is characteristic of non-credible\nsites; a positive LIindicates that the term is characteristic of credible sites;\nLI= 0 indicates that the term is equally important in both sites.\n3 Results\n3.1 Segregated structures of retweet networks\nWe looked at the retweet interactions between humans and bots for each topic\nusing the preprocessed COVID-19 tweets. The resulting retweet networks are\nshown in Fig. 1. It is notable that segregated structures emerged in all the\ntopics considered, with dense connections inside and sparse connections in\nbetween.\nIn the \\WHO\" network ( n= 88;719), 3.8% of labelled users are non-\ncredible users while 19.7% are credible bots. The credible group contained\no\u000ecial media accounts such as \\@washingtonpost\", \\@ABC\", \\@Reuters\",\n\\@CNN\"and \\@BBCWorld\" and were separated from the non-credible group\ncontaining \\@DailyCaller\", \\@gatewaypundit\" and \\@KimStrassel\"(Fig. 1a).\nWe found that non-credible bots were appearing around the US conserva-\ntive columnist \\KimStrassel\" (Kimberley Strassel) as well as \\@DailyCaller\"\n(an American right-wing misinformation website) and \\@gatewaypundit\" (an\nAmerican far-right website publishing misleading news). These results imply\nthat the non-credible bots might be attempting to interact with politically\nright-leaning users to increase these users' exposures to negative information.\nAlthough the WHO itself is a neutral topic, partisan asymmetry was visible\nduring the COVID-19 infodemic.\nPrevious research has found that the retweet network of the 2010 US\nmidterm elections showed typical \\left\" and \\right\" segregated groups [41].\nThus, we examined whether the \\Trump\" retweet network shares the similar\nfeatures. Fig. 1b shows the Trump network ( n= 1;125;251) where 3.2% of\nthe labelled users are non-credible bots while 23.5% are credible bots. Here\n\\@HillaryClinton\" (Hillary Clinton) and \\@JoeBiden\" (Joe Biden), represent-\ning the progressives clustered together, were distant from the conservative clus-\nter with \\@realDonaldTrump\" (Donald Trump). The political echo chamber\nwas reobserved in 2020 in the context of the COVID-19 infodemic. A notable\n\fnding is that \\@realDonaldTrump\" was mostly retweeted by non-credible\nbots (shown in red), whereas \\@HillaryClinton\" and \\@JoeBiden\" were less\nso.\n8 Wentao Xu1, Kazutoshi Sasahara2\n(a) WHO\n(b) Trump\n(c) 5G\n(d) Bill Gates\nFig. 1: Retweet networks related to \\WHO\",\\Trump\", \\5G\", and \\Bill Gates\".\nRed nodes indicate non-credible bots; green nodes indicate credible bots. Edges\nrepresent retweets among bots, and between bots and popular accounts (la-\nbelled).\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 9\nAs far as \\5G\" is concerned, two separate groups were observed again in the\nretweet network ( n= 67;523), in which 1.62% of the labelled users are non-\ncredible bots and 8.82% are credible bots (Fig. 1c). One side of the network\nincludes \\@davidicke\" (David Icke) and \\@davidkurten\" (David Kurten). The\nformer is reported to be a conspiracy theorist, and the latter is currently a\nmember of the UK Independence Party (right-wing populist party) and has\nbeen since 2016 [42,43,44]. They were the two most-retweeted users in the 5G\nconspiracy topic. By contrast, the mainstream British media \\@BBCWorld\"\nand \\@WHO\" were located on the other side of the network in Fig. 1c. More\nnon-credible bots were involved on the side of \\@davidicke\", while there were\nmore credible bots on the other side. Although \\5G\" was considered as a\npopular conspiracy theory in the early days of COVID-19 pandemic, a larger\nnumber of non-credible bots was not observed in comparison with other topics.\n\\Bill Gates\" is another conspiracy theory topic as mentioned earlier. In\nregard to this topic, 5.95% of the labelled users in the retweet network ( n=\n94;584) are non-credible bots while 18.0% are credible bots (Fig. 1d). Again,\nwe can \fnd the \\@davidicke\" and \\@DailyCaller\", which are occupied by non-\ncredible bots, on the right side, while a cluster on the left is covered by credible\nbots with legitimate media including \\@business\" and \\@thehill\". Moreover,\n\\@davidicke\" was observed in both \\5G\" and \\Bill Gates\" conspiracy topics;\nthis account was suspended by Twitter and is no longer accessible. It can be\nobserved that there are no visible links among these bots in the \\Bill Gates\"\nnetwork. This is because these bots and labelled accounts did not have mutual\nretweets; for example, \\@DailyCaller\" was retweeted by 336 humans, 294 of\nwhom were non-credible humans.\nThen, we quanti\fed indegrees (the numbers of retweeted posts by di\u000berent\nusers, used as a measure for engagement) as a function of the bot score (CAP).\nThe resulting scatter plots are shown in Fig. 2. The complementary cumulative\ndistribution Function (CCDF) of indegrees is shown in the supplementary\ninformation (SI). The majority of users are obviously credible humans. It turns\nout that the indegrees tend to be inversely proportional to the bot score and,\non average, indegrees for humans are larger than those for bots in all the\ntopics. Compared with humans, bots were, therefore less engaging in retweets\nin general. However, average indegrees of non-credible bots are higher than\nthose of credible bots ( t-test,p= 0:00047).\nThere are several outliers of non-credible bots that have larger indegrees\nin Fig. 2. For example, \\ @JoyaMia00\"(NB) is an MAGA (Make America\nGreat Again) user and a Trump supporter; \\@soleil82639\" (NB) retweets posts\nin at least three languages including English, Japanese, and French; These\nposts are related to history and politics as well as COVID-19. In addition,\n\\@freesandstorm\" (CB) is always retweeting climate and environment-related\nposts (\\@BillEsteem\" (CB) is closed.) (Fig. 2a). In the Trump topic, \\@Dallas-\nJames428\" (NB) and \\@Rparkerscience\" (NB) are suspended. \\@HarryPot-\nterMAGE\" (CB) is retweeting political tweets while \\@KMGGaryde\" (CB)\nis closed (Fig. 2b); In the \\5G\" topic, \\@iotworlds\" (CB) is closed. From\nthe page of \\@guidaautonoma\" (CB) we can say that the users is enthusias-\n10 Wentao Xu1, Kazutoshi Sasahara2\n(A) WHO(B) Trump\n(C) 5G(D) Bill Gates\nFig. 2: Degrees vs. Bot Score (CAP) in \\WHO\", \\Trump\", \\5G\" and \\Bill\nGates\" topics. The red dashed line is the threshold for bots/humans classi\f-\ncation (CAP=0.54).\ntic about autonomous car; \\@orion pentict\" (NB) retweets many anti-Biden\nposts, while \\@KJovic\" is an anti-lockdown supporter (Fig. 2c). In the Bill\nGates topic, \\@dyro874\" (CB) is suspended; \\@DrTony44\" is now retweeting\nposts not related to COVID-19 but to entertainment; \\@covid19 alert\" (NB)\nis retweeting COVID-19 posts; and \\@ttocs35\" is now suspended (Fig. 2d).\nThese non-credible bots were actually retweeted as many times as those of hu-\nman accounts and, thus, were as equally in\ruential as humans. We con\frmed\nthat some outlier bots were actually suspended by Twitter and are no longer\nactive. These results indicate that, although the number of retweets by non-\ncredible humans could be larger than the number by non-credible bots, the\ne\u000bects of the latter are still non-negligible because of the existence of the out-\nliers as well as the parasitic nature of non-credible bots, which we will discuss\nlater.\nOverall, two segregated networks of information-spreading emerged in all\nthe topics considered. It turns out that one side of the dense connected compo-\nnents was propagating credible sources mostly by credible bots. By contrast,\nthe other component was di\u000busing non-credible information, mainly ampli\fed\nby non-credible bots.\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 11\n3.2 Parasitic natures of bots\nNext, we examined how bots selectively ampli\fed voices from media and\ncelebrity accounts in the aggregated retweet networks mentioned in Sec. 2.3.\nFig. 3 shows the results by bot type. The top-\fve most-retweeted accounts\nwere plotted alongside.\nIn Fig. 3a, we can clearly see that non-credible bots are parasitic on far-\nright mass media accounts such as \\@DailyCaller\"( kin= 84) in terms of their\nretweets, although the indegrees of the other four are much smaller. Note\nthat \\@DailyPostNGR\"is a Nigerian local newspaper; \\@michaeljohns\" is an\nAmerican conservative commentator, speechwriter, and policy analyst; also,\n\\@nascarred14\" is now suspended.\nLooking at the accounts retweeted by both credible and non-credible bots\nin Fig.3b, it turns out that most non-credible bots are also parasitic on right-\nleaning celebrity and media accounts, including \\@DonaldJTrumpJr\" ( kin=\n61). His most popular article is reposted from the \\DailyCaller\" website, saying\nthat \\Chinese Government Finally Acknowledges Underreporting Coronavirus\nCases\". Other accounts include \\@TrumpWarRoom\" (\\The o\u000ece of Donald\nJ Trump\")5, \\@seanhannity\"(an American talk show program presenter and\nconservative political commentator.) and \\@yogagenie\" (suspended). By con-\ntrast, most credible bots are preferentially ampli\fed voices from legitimate\nmedia accounts, such as \\@washingtonpost\" ( kin= 205). Other accounts in-\nclude \\@thehill\", \\@CNNPolitics\" and \\@Independent\". A marked exception\nis \\@realDonaldTrump\" whose posts were largely shared not only by non-\ncredible bots ( kin= 29) but also credible bots ( kin= 199).\nFig.3c shows that major celebrities and media were selectively retweeted\nonly by credible bots, regardless of their political attitude. For instance, \\@Kim-\nstrassel\" (American conservative writer, kin= 155) and \\@HillaryClinton\"\n(US politician, kin= 267). The other accounts include \\@guardian\" (British\nnewspaper), \\@JoeBiden\" and \\@BillKristol\" (American neoconservative po-\nlitical analyst).\nThese results further support that non-credible bots cannot be ignored in\nthe context of the COVID-19 infodemic due to their parasitic natures toward\npopular right-leaning accounts.\n5https://https://donaldjtrump.com\n12 Wentao Xu1, Kazutoshi Sasahara2\n(a)\n(b)\n(c)\nFig. 3: Celebrities and media accounts retweeted by (a) non-credible bots only;\n(b) both credible and non-credible bots; (c) credible bots only. Green denotes\ncelebrity and orange denotes media. Accounts with black labels were all sus-\npended by Twitter (as of Aug. 7, 2021). The size of a node is proportional to\nits indegee.\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 13\n3.3 Temporal patterns of retweets in humans and bots\nWe assumed that non-credible bots' behaviors are correlated with non-credible\nhumans rather than credible accounts, because the intention of non-credible\nbots would be to amplify the spread of misinformation including conspiracy\ntheories. Thus, we quanti\fed temporal patterns of retweet behaviors in humans\nand bots. For comparisons among credible/non-credible humans and bots, we\nscaled daily retweet counts between 0 and 1, respectively. Fig. 4 shows daily\nretweet series by humans and bots for each topic, in which the patterns of\nretweets increase following similar trends.\n(A) WHO(B) Trump\n(C) 5G(D) Bill Gates\nFig. 4: Retweet count series (scaled 0-1) generated for bots and humans in four\ntopics.\nTo statistically con\frm this observation, we measured the Pearson corre-\nlation coe\u000ecient of temporal oscillations of retweets generated by these users.\nThe results are summarized in Table 2. This reveals that retweet actions by\nnon-credible bots correlated with those by non-credible humans to a much\nhigher degree than by credible humans in all of the topics. The above assump-\ntion is therefore partially supported. We further consider this assumption in\nthe next section by looking at commonality in retweets generated by bots and\nhumans.\n14 Wentao Xu1, Kazutoshi Sasahara2\nTable 2: Pearson correlation coe\u000ecients of retweets between NB and NH and\nbetween NB and CH.\nTopic Type Correlation Coe\u000ecient P-value\nWHONB & NH 0.84 6.05E-29\nNB & CH 0.15 0.1250527\nTrumpNB & NH 0.96 4.65E-61\nNB & CH 0.82 1.81E-26\n5GNB & NH 0.45 1.31E-06\nNB & CH 0.32 0.001031208\nBill GatesNB & NH 0.91 1.46E-41\nNB & CH 0.04 0.712220673\n3.4 Commonality in retweets by humans and bots\nFinally, we examined terms (nouns), domains (URLs), and users that com-\nmonly appeared in retweets generated by humans and bots. Consider the 5G\ntopic, for example; Fig. 5 compares term importance (measured by TF-IDF)\non the 5G-related articles retweeted by bots and humans. As seen in the red\nbars of Fig. 5 (a) and (b), the non-credible bots selectively retweeted articles\nthat include China-related terms such as \\wuhan\", \\china\", \\chinese\", and\nthe non-credible humans had the same tendency. Sample articles include the\nfollowing:\n\\The China Coronavirus 5G Connection is a very important factor when\ntrying to comprehend the coronavirus (formerly abbreviated 2019-nCoV, now\nCOVID-19) outbreak.\"6\nSuch articles aimed to connect \\china\" with coronavirus subjectively and\nhighlighted that Wuhan was a test city chosen for China's 5G rollout. By\ncontrast, the blue bars in Fig. 5 (a) and (b) show that the credible bots and\nhumans retweeted articles that include the word \\conspiracy.\" This suggests\nthat both credible bots and humans tended to retweet articles designed to\nwarn the readers about the conspiracy theory. Sample articles include:\n\\One theory claims that the novel coronavirus originated in Wuhan because\nthe Chinese city had recently been rolling out 5G. It's now supposedly spread to\nother cities that are also using 5G. These false conspiracy theories neglect to\nmention that a highly contagious virus would naturally spread more in densely\n6https://worldtruth.tv\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 15\npopulated cities with access to 5G, and that the coronavirus pandemic has hit\ncountries like Iran and Japan where 5G isn't in use yet.\"7\nThus, the 5G conspiracy theory went viral inside of an echo chamber con-\nsisting of non-credible accounts while shutting down contrasting voices from a\ncredible cluster.\nThe same linguistic analysis was conducted for the \\WHO\", \\Trump\", and\n\\Bill Gates\" topics, and resulted in the similar linguistic features (see Figs. 2a-\nf in SI). That is, the articles including China-related terms were preferentially\nshared by both non-credible bots and humans in the Trump topic and others.\nThese consistent patterns suggest that non-credible humans were di\u000busing\nChina-related mis/disinformation and conspiracy theories, ampli\fed by non-\ncredible bots with political inclinations.\nWe also calculated the shared terms ratio in each topic. The non-credible\nbots and humans shared 57%, 90%, 50%, and 30% of terms in the retweeted\narticles for \\WHO\", \\Trump\", \\5G\", and \\Bill Gates\" topics, respectively (cf.\ncredible bots and humans shared 73%, 93%, 70%, and 40% of terms, respec-\ntively). This indicates that the non-credible bots and humans are topically\nsimilar, and therefore, one may not be able to easily distinguish humans or\nbots based on the observation of a few tweets. These results, again, suggest\nthat the non-credible humans were di\u000busing China-related misinformation and\nmisleading claims, and that the non-credible bots were probably amplifying\ntheir e\u000bects. We will discuss the implications of this later.\n7https://www.theverge.com\n16 Wentao Xu1, Kazutoshi Sasahara2\n\u22121 \u22120.5 0 0.5 1sharecausetheoriesinfrastructuretimeioturbannationalmobilecityinformationaprilweekwirelessservicesecuritytheoryphoneconspiracynetworkpublictechnologyusehealthhumannewsmagovernmentradiationworldemfvitaminagendaimmunesyndromediseaseconnectionhighchinesefakeforeigndnaflubodymedicalglobalmarketmilitarywuhanCredible\nNon-credible5G :NB VS CB\nL I\n(a)\n\u22121 \u22120.5 0 0.5 1nationalradiogroupweektimetheoryconspiracymobileaprilpublicinformationnetworkhealthworldinfrastructurestatephoneimmunechinesenewschinausecauseresearchgovernmentdiseasetechnologycellwirelessradiationcitywuhanexposureindustrysmapresentCredible\nNon-credible5G :NH VS CH\nL I\n(b)\nFig. 5: Term importance in retweeted articles in the \\5G\" topic: (a) non-\ncredible bots vs. credible bots; (b) non-credible humans vs. credible humans.\nRed bars indicate word importance for non-credible users, whereas blue bars\nindicate credible users.\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 17\nTable 3: Popular retweeted domains and users in the 5G topic. (a) Top 10\ndomains retweeted by credible humans (CH), credible bots (CB), non-credible\nhumans (NH), and non-credible bots (NB). (b) Top 10 users retweeted by\nCH, CB, NH, and NB. Green denotes credible domains or users; red denotes\nnon-credible domains or users; blue denotes unknown domains or users.\n(a) Top 10 domains retweeted by\nNB CB NH CH\n1 beforeitsnews.com bbc.co.uk worldtruth.tv theguardian.com\n2 dailypost.ng theguardian.com express.co.uk bbc.co.uk\n3 worldtruth.tv bbc.com infowars.com bbc.com\n4 zerohedge.com reuters.com beforeitsnews.com theverge.com\n5 dailyrecord.co.uk theverge.com humansarefree.com businessinsider.com\n6 today.ng cnn.com neonnettle.com cnn.com\n7 infowars.com businessinsider.com thelastamericanvagabond.com reuters.com\n8 banned.video nytimes.com dailycaller.com ft.com\n9 thetruthaboutcancer.com newsweek.com paulcraigroberts.org vox.com\n10 rt.com vox.com thesun.co.uk nytimes.com\n(b) Top 10 users retweeted by\nNB CB NH CH\n1 @shinethelight17 @Reuters @WorldTruthTV @guardian\n2 @DailyPostNGR @guidaautonoma @BILDERBERG GP @rooshv\n3 @Laurel700 @Exchange5g @davidicke @guardiannews\n4 @davidicke @rooshv @shinethelight17 @verge\n5 @freezerohedge @HaroldSinnott @TornadoNewsLink @Omojuwa\n6 @NigeriaNewsdesk @verge @boblister poole @Reuters\n7 @BANNEDdotVIDEO @ipfconline1 @DailyPostNGR @davidicke\n8 @WorldTruthTV @Shirastweet @BANNEDdotVIDEO @Exchange5g\n9 @owhy3 @nuskitconsultan @davidkurten @davidkurten\n10 @guardian @buttscornershop @ruskin147\n18 Wentao Xu1, Kazutoshi Sasahara2\nTable 4: Common domains and users retweeted by non-credible users (NB and\nNH) and by credible users (CB and CH)\n(a) Domains\nTopic NB \\NH CB \\CH\nWHO 6 8\nTrump 10 8\n5G 3 9\nBill Gates 6 8\n(b) Users\nTopic NB \\NH CB \\CH\nWHO 8 6\nTrump 7 7\n5G 5 4\nBill Gates 7 7\nFurthermore, we found that both non-credible bots and humans exhibit\nhigh commonality in retweeted domains (URLs) and retweeted users. Again,\ntake the 5G topic as an example, the non-credible bots and humans shared\nmany popular domains as well as users (Table 3). The same analyses were\nalso conducted for other topics. For each user type, Table 4 summarizes the\ndomains and users that commonly appeared in retweets in all the topics. The\nnon-credible bots shared many in common with respect to the top-10 retweeted\ndomains and users, indicating the similarity in retweet behaviors between non-\ncredible bots and humans (as well as credible bots and humans). These \fndings\nfurther support the assumption that non-credible bots were following non-\ncredible humans rather than credible accounts.\n4 Discussion\nIn this paper, we investigated the roles of bots by analyzing retweet networks,\ntemporal patterns of retweets as well as retweeted contents during the COVID-\n19 infodemic. For analysis, we focused on misinformation and conspiracy-\ntheory-related topics, such as \\WHO\", \\Trump\", \\5G\", and \\Bill Gates\".\nOur analyses provided two major \fndings: the segregated retweet networks of\nbots and their temporal and topical similarities. We revisit the \fndings and\ndiscuss their implications here.\nFirst, we found that the retweet networks exhibited segregation and para-\nsitic natures, suggesting two types of voices or echo chambers in all the topics\n(Fig. 1). One represents mainstream media and public institutions and the\nother represents right-wing (self-)media and celebrities. The echo chamber\nstructures may amplify mis/disinformation from non-credible sources while\nhindering the dissemination of information from legitimate sources. According\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 19\nto the indegrees (Fig. 2), the basic in\ruence of retweets by non-credible hu-\nmans can be much larger than that by non-credible bots. Thus, one might think\nthat bots did not play as important a role during the COVID-19 infodemic\nas they did in previous political events, including the 2016 US presidential\nelection. However, we cannot simply make this a de\fnitive conclusion. Rather,\nthe clustering of non-credible bots may re\rect a partisan asymmetry and that\nnon-credible bots follow non-credible humans. In particular, non-credible bots\nwere parasitic on the far-right media and celebrity accounts, selectively am-\nplifying their voices (Fig. 3). We speculate that non-credible bots targeted at\nsuch in\ruential accounts because they needed to get ampli\fcation from pres-\ntigious accounts with social capital and high follower accounts and, thereby,\nextend their reach and engagement. The parasitic role of non-credible bots is\nfor them to interact with accounts that might give them a chance to have their\nnarratives or views ampli\fed into the public sphere.\nSecond, our results show that retweet actions and contents were highly cor-\nrelated between non-credible bots and humans for each topic (Figs. 4 and 5).\nWe found that non-credible bots preferentially distributed China-related terms\n(e.g., \\wuhan\",\\china\", \\chinese\") from non-credible sites and users in the 5G\ntopic (Fig. 5 and Table 3) and the other topics (Figs. 2a-f in SI). These con-\nsistent patterns may re\rect that many (although not all) non-credible humans\nwere di\u000busing China-related misleading claims and the non-credible bots were\namplifying their e\u000bects. It is said that Trump's fabrication of the term \\China\nvirus\" led to racism targeted at Chinese and Asian Americans further fueled\nAsian hate and Sinophobia (anti-Chinese sentiment) in Western countries.\nTherefore, we suspect that bots were abused for spreading such propaganda\nduring the early COVID-19 infodemic. Although Twitter suspended many ma-\nlicious accounts during the COVID-19 infodemic, sophisticated bots remained\nactive and selectively parasitic on the partisan clusters. Therefore, we conclude\nthat the role of non-credible bots is non-negligible in the COVID-19 infodemic.\nThis evidence and these considerations cause us to rethink the weaponized\nuse of bots for online manipulation and political interventions. This calls for\nthe necessity of continuously monitoring the information ecosystem of bots.\nThis is especially important to detect their coordinated acts, although we\ndid not \fnd evidence of such events in the current settings. However, this\ncould still represent a credible future threat that would likely have a negative\nsocietal impact. As the WHO mentioned, an infodemic is a \\second disease\"\nthat emerged alongside with COVID-19, and it is important to take immediate\naction to address this infodemic. As demonstrated in this study, social media\nanalysis is important in order to acquire an overview of the infodemic and gain\ninsights into a mitigation strategy.\nOur study has several limitations that need to be addressed in future re-\nsearch. Since Twitter suspends any accounts that it considers as \\malicious\",\nwe were unable to obtain a comprehensive picture of users' interactive be-\nhaviors in this study. We also had limited information about the sources of\ncredible and non-credible domains (URLs), which require frequent updates;\nthus, all of the URLs could not be labelled in our analyses. The availability\n20 Wentao Xu1, Kazutoshi Sasahara2\nproblem of a credible/non-credible domain list requires a collective e\u000bort to\nsolve. Despite these limitations, this study furthers our understanding of the\nroles of bots in misinformation propagation during an infodemic in the midst\nof a world-wide healthcare crisis, and re-emphasizes the need to develop an\ne\u000ecient method to address behaviors of malicious bots.\nCon\rict of interest\nThe authors declare that they have no con\rict of interest.\nReferences\n1. WHO. Munich Security Conference (2020)\n2. J.S. Brennen, F.M. Simon, P.N. Howard, R.K. Nielsen, Types, Sources, and Claims of\nCOVID-19 Misinformation. Tech. rep. (2020)\n3. Politifact. Facts are under assault in 2020 (2020)\n4. F. Menczer, Proceedings of the National Academy of Sciences 101(suppl 1), 5261 (2004)\n5. S. Redner, The European Physical Journal B - Condensed Matter and Complex Systems\n4(2), 131 (1998)\n6. J. Messias, S. Lucas, O. Ricardo, B. Fabricio. You followed my bot! Transforming robots\ninto in\ruential users in Twitter (2013)\n7. A. Bessi, E. Ferrara. Social bots distort the 2016 U.S. Presidential election online\ndiscussion (2016)\n8. O. Varol, E. Ferrara, C.A. Davis, F. Menczer, A. Flammini, Proceedings of the 11th\nInternational Conference on Web and Social Media, ICWSM 2017 pp. 280{289 (2017)\n9. Pew Research Center (2018)\n10. E. Ferrara. What types of covid-19 conspiracies are populated by twitter bots? (2020)\n11. C. Shao, G.L. Ciampaglia, O. Varol, K.C. Yang, A. Flammini, F. Menczer. The spread\nof low-credibility content by social bots (2018)\n12. T.R. Keller, U. Klinger. Social bots in election campaigns: Theoretical, empirical, and\nmethodological implications (2019)\n13. D.A. Broniatowski, A.M. Jamison, S. Qi, L. AlKulaib, T. Chen, A. Benton, S.C. Quinn,\nM. Dredze. Weaponized Health Communication: Twitter Bots and Russian Trolls Am-\nplify the Vaccine Debate (2018)\n14. R. Gallotti, F. Valle, N. Castaldo, P. Sacco, M. De Domenico. Assessing the risks of\n`infodemics' in response to COVID-19 epidemics (2020)\n15. E. Ferrara, H. Chang, E. Chen, G. Muric, J. Patel. Characterizing social media manip-\nulation in the 2020 u.s. presidential election (2020)\n16. J. Uyheng, K.M. Carley. Bots and online hate during the COVID-19 pandemic: case\nstudies in the United States and the Philippines (2020)\n17. C.A. Davis, O. Varol, E. Ferrara, A. Flammini, F. Menczer. Botornot: A system to\nevaluate social bots (2016)\n18. M. Sayyadiharikandeh, O. Varol, K. Yang, A. Flammini, F. Menczer. Detection of novel\nsocial bots by ensembles of specialized classi\fers (2020)\n19. S. Vosoughi, D. Roy, S. Aral. The spread of true and false news online (2018)\n20. D. Boyd, S. Golder, G. Lotan. Tweet, tweet, retweet: Conversational aspects of retweet-\ning on twitter (2010)\n21. M. Cha, H. Haddadi, F. Benevenuto, K. Gummadi. Measuring user in\ruence in twitter:\nThe million follower fallacy (2010)\n22. D.M. Romero, W. Galuba, S. Asur, B.A. Huberman. In\ruence and passivity in social\nmedia (2011)\n23. L. Hong, O. Dan, B.D. Davison. Predicting popular messages in Twitter (2011)\n24. B. Suh, L. Hong, P. Pirolli, E.H. Chi. Want to be retweeted? Large scale analytics on\nfactors impacting retweet in twitter network (2010)\nCharacterizing the roles of bots during the COVID-19 infodemic on Twitter 21\n25. H. Kwak, C. Lee, H. Park, S. Moon. What is twitter, a social network or a news media?\n(2010)\n26. K.M. Douglas, J.E. Uscinski, R.M. Sutton, A. Cichocka, T. Nefes, C.S. Ang, F. Deravi.\nUnderstanding conspiracy theories (2019)\n27. J. Temperton. How the 5G coronavirus conspiracy theory tore through the internet |\nWIRED UK (2020)\n28. I.A. Hamilton. 77 phone masts attacked in UK due to coronavirus 5G conspiracy theory\n- Business Insider (2020)\n29. E. DisinfoLab. COVID-19 and 5G: A case study of platforms' content moderation of\nconspiracy theories (2020)\n30. M. Ketchell. Coronavirus conspiracy theories are dangerous { here's how to stop them\nspreading (2020)\n31. F.C. Jack Goodman. Coronavirus: Bill Gates `microchip' conspiracy theory and other\nvaccine claims fact-checked - BBC News (2020)\n32. B.L. Jr. Bill Gates denies conspiracy theories that say he wants to use coronavirus\nvaccines to implant tracking devices (2020)\n33. A. Romano. New Yahoo News/YouGov poll shows coronavirus conspiracy theories\nspreading on the right may hamper vaccine e\u000borts (2020)\n34. S. Evanega, M. Lynas, J. Adams, K. Smolenyak, Quantifying sources and themes in the\nCOVID-19 'infodemic'. Tech. rep., The Cornell Alliance for Science (2020)\n35. M. Zimdars. False, Misleading, Clickbait-y, and Satirical \\News\" Sources (2016)\n36. J. N\u001crregaard, B. Horne, S. Adal\u0010. Nela-gt-2018: A large multi-labelled news dataset for\nthe study of misinformation in news articles (2019). 13th International Conference on\nWeb and Social Media, ICWSM 2019 ; Conference date: 11-06-2019 Through 14-06-2019\n37. J.R. Landis, G.G. Koch, Biometrics 33(1), 159 (1977)\n38. M. Bastian, S. Heymann, M. Jacomy. Gephi: An open source software for exploring and\nmanipulating networks (2009)\n39. M. Jacomy, T. Venturini, S. Heymann, M. Bastian. ForceAtlas2, a Continuous Graph\nLayout Algorithm for Handy Network Visualization Designed for the Gephi Software\n(2014)\n40. K. Sasahara. You are what you eat A social media study of food identity (2019)\n41. M.D. Conover, B. Gon\u0018 calves, A. Flammini, F. Menczer. Partisan asymmetries in online\npolitical activity (2012)\n42. BBC. UKIP aiming to be 'radical, populist' party - Gerard Batten - BBC News (2018)\n43. Skynews. Who is David Icke? The conspiracy theorist who claims he is the son of God\n(2020)\n44. UropeanConservative. David Kurten - European Conservative (2020)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Characterizing the roles of bots during the COVID-19 infodemic on Twitter", "author": ["W Xu", "K Sasahara"], "pub_year": "2020", "venue": "arXiv preprint arXiv:2011.06249", "abstract": "An infodemic is an emerging phenomenon caused by an overabundance of information  online. This proliferation of information makes it difficult for the public to distinguish trustworthy"}, "filled": false, "gsrank": 748, "pub_url": "https://arxiv.org/abs/2011.06249", "author_id": ["8V9X99YAAAAJ", "1-CMHnwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZVTjUh1WwS4J:scholar.google.com/&output=cite&scirp=747&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZVTjUh1WwS4J&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 1, "citedby_url": "/scholar?cites=3369068680194511973&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZVTjUh1WwS4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2011.06249"}}, {"title": "What Drives Online Popularity: Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes", "year": "2024", "pdf_data": "What Drives Online Popularity: Author, Content\nor Sharers? Estimating Spread Dynamics with\nBayesian Mixture Hawkes\nPio Calderon( \u0000)[0000 \u22120002\u22128747\u22128917]and Marian-Andrei\nRizoiu[0000\u22120003\u22120381\u2212669X]\nUniversity of Technology Sydney, Australia\npiogabrielle.b.calderon@student.uts.edu.au\nmarian-andrei.rizoiu@uts.edu.au\nAbstract. The spread of content on social media is shaped by inter-\ntwining factors on three levels: the source, the content itself, and the\npathways of content spread. At the lowest level, the popularity of the\nsharing user determines its eventual reach. However, higher-level factors\nsuch as the nature of the online item and the credibility of its source also\nplay crucial roles in determining how widely and rapidly the online item\nspreads. In this work, we propose the Bayesian Mixture Hawkes (BMH)\nmodel to jointly learn the influence of source, content and spread. We\nformulate the BMH model as a hierarchical mixture model of separable\nHawkes processes, accommodating different classes of Hawkes dynam-\nics and the influence of feature sets on these classes. We test the BMH\nmodel on two learning tasks, cold-start popularity prediction and tempo-\nral profile generalization performance, applying to two real-world retweet\ncascade datasets referencing articles from controversial and traditional\nmediapublishers.TheBMHmodeloutperformsthestate-of-the-artmod-\nels and predictive baselines on both datasets and utilizes cascade- and\nitem-level information better than the alternatives. Lastly, we perform a\ncounter-factual analysis where we apply the trained publisher-level BMH\nmodelstoasetofarticleheadlinesandshowthateffectivenessofheadline\nwriting style (neutral, clickbait, inflammatory) varies across publishers.\nThe BMH model unveils differences in style effectiveness between con-\ntroversial and reputable publishers, where we find clickbait to be notably\nmore effective for reputable publishers as opposed to controversial ones,\nwhich links to the latter\u2019s overuse of clickbait.\nKeywords: Hawkes process \u00b7hierarchical model \u00b7mixture model\n1 Introduction\nSocialmediaplatformshaveplayedanincreasinglyimportantroleasdistribution\nhubs for content. In 2023, it was reported that 69%of the U.S. adult population\nuse social media as a news source [7], implying a significant shift in how infor-\nmation is consumed. Understanding how content propagates on these platformsarXiv:2406.03390v3  [cs.LG]  21 Aug 2024\n2 P. Calderon and M.A. Rizoiu\n\"The Ultimate Food \nFrenzy Sweeping \nthe Nation\"Future articlepredict\n\"4 Celebrity Revelations\n That Shook the World\"Past articles published by \ntraincascade\n sizes\ninter-arrival\n timesCascades of Article 1 Article 1\nCold Start Popularity\nContent Half LifeArticle 20\nCascades of Article 20\nCasc. 1 Casc. 20\nCasc. 1 Casc. 5\n\"Shocking Images Expose\n Climate Catastrophe!\"BMH model for publisher\nBMH-P\nBMH-K\nFig.1: An intuitive plate diagram for the BMH model. Left:The BMH model\nis trained using a historical dataset: a collection of Mpublishers {\u03c11, . . . , \u03c1 M},\nitems for each publisher (i.e. articles), and a set of diffusion cascades for each\nitem. Each diffusion cascade consists of a timeline of events, here represented by\na set of lollipops. Upper Right: The BMH is a publisher-level model that maps\ncascade features (shown in blue color) and article features (in red color) to a\nmixture of Hawkes processes. Lower Right: The trained BMH model (with the\nhistorical follower count distribution) can be used to infer spread dynamics of\nfuture articles based on their headlines.\n\u2013 both the size and speed of dissemination \u2013 is vital since the impact is intrin-\nsically tied to the level of online engagement the content receives. To command\nattention in today\u2019s digital age, it is not sufficient to craft high-quality content\nalone, but rather high-quality content that resonates with social media.\nThe spread of content online is influenced by factors at varying levels. At\nthe lowest level, the breadth of a diffusion cascade , referring to the sequence of\ncontent shares triggered by a user, often hinges on the user\u2019s popularity as re-\nflected by their follower count [1]. If a highly followed user shares an online item,\nit reaches a broader audience, increasing the likelihood that it will be shared.\nHowever, the cascade\u2019s growth is not solely dependent on user popularity. The\nnature and category of the shared content play crucial roles, as various topics\nmay engage audiences in different ways [27,32]. For news dissemination, the way\nan article headline is written, particularly the use of clickbait tactics to create\naninformation gap to exploit the audience\u2019s curiosity [33], significantly impacts\nthe total attention (i.e. popularity ) the news article receives. Beyond cascade-\nand item-level factors, the reputation of the online item\u2019s source also affects how\nwidely and quickly information spreads [24]. An article from a reputable source\nlike The New York Times may spread more quickly and be taken more seriously\nthan an article from a controversial, lesser-known blog due to the former\u2019s es-\ntablished credibility. Accurately modeling diffusion cascades of online content\nrequires an approach that jointly considers these factors at different levels.\nBayesian Mixture Hawkes 3\nIn this work, we address two open questions related to jointly modeling the\ninfluence of the source, item- and cascade-level factors on online content spread.\nThe first research question examines how these three levels influence the\nspread of online content. While prior studies have explored the effects of cas-\ncade features [30] and item-level variations [12], a comprehensive framework\nthat jointly considers the three levels has yet to be developed. Our first question\nis:Can we build a model for the spread dynamics of online content\nthat accounts for the intertwining influence of its source, the content\nitself, and cascade-level factors? To tackle this, we propose the Bayesian\nMixture Hawkes (BMH) model, a novel source-level hierarchical mixture model\nof separable Hawkes processes that models diffusion cascades\u2019 size and temporal\nprofile as a function of cascade- and item-level features. The left half of Fig. 1\nshowcases how the source-level BMH model learns across both the cascade and\nitem levels from a hierarchically structured dataset (i.e., a set of items, cascade\ngroupsforeachitem,andfeaturesetsattachedtoeach).TheBMHmodeliscapa-\nble of learning different classes of Hawkes process dynamics, taking into account\nthe ability of online content to trigger varied responses, from highly popular to\nlargely unnoticed cascades, as well as those that fade quickly or diminish over\ntime. The BMH learns the influence of feature sets on these classes in two ways:\nthe location of each class in the Hawkes parameter space and the membership\nprobability of each cascade belonging to each class. The trained BMH model can\nthen be used to predict future items\u2019 popularity and spread dynamics from the\nsame source (see the right half of Fig. 1). We test the BMH model on two hier-\narchical retweet cascade datasets that reference articles from controversial and\nreputable media publishers [12] and on two tasks: cold-start popularity predic-\ntion and temporal profile generalization performance. We show that the BMH\noutperforms the state-of-the-art in item popularity prediction (Dual Mixture\nModel [12]), Empirical Bayes approach [30] and predictive baselines for both\ntasks and datasets, and that the BMH model jointly leverages cascade- (i.e.,\nthe follower count of the seed user) and article-level (i.e., the article headline\nembedding vector) information better than the benchmarks. Furthermore, our\nmodel ablation highlights the role of the initiating user in shaping the cascade\ndynamics related to controversial media, a factor less critical for cascades linked\nto reputable media. This distinction mirrors the diverse pathways of online in-\nformation dissemination: controversial media often circulate within topical social\ngroups [3,11], with the initial endorser serving to validate the content, while for\nreputable media the publisher\u2019s reputation is the most important factor.\nOursecondopenquestionrelatestolearningdifferencesinthespreaddynam-\nics across news publishers: Can we uncover across-publisher differences\nin how headline writing style (neutral, clickbait, inflammatory) affects\npublished content\u2019s popularity and temporal profile? We run a counter-\nfactual analysis using the trained publisher-level BMH models and a labeled set\nofarticleheadlines[13]toshowthevariationofheadlinestyleeffectivenessacross\npublishers. We find that the BMH model is able to capture nuanced publisher\nbehavior, such as the effectiveness of inflammatory headlines for tabloids. The\n4 P. Calderon and M.A. Rizoiu\nBMH model also unveils differences in the success of clickbait between contro-\nversial and reputable outlets, linking to existing research on clickbait fatigue and\nthe diminishing relationship between clickbait effectiveness and volume [33,17].\nThe main contributions of the work are as follows:\n1. The Bayesian Mixture Hawkes (BMH) model1, a novel hierarchical mixture\nmodel of the joint influence of cascade- and item-level features on online\nitem spread dynamics. On two news datasets, we show that the BMH out-\nperformsthestate-of-the-artandbaselinesincold-startpopularityprediction\nand temporal profile generalization performance.\n2. A counter-factual analysis showing how headline writing style affects pub-\nlished content\u2019s spread dynamics. Using the BMH model we learn the dif-\nferences in the effectiveness of headlines across publishers and show general\ntrends across controversial and reputable media outlets.\nRelated Work. In recent years, generative models, and specifically the Hawkes\nprocess [10], have been employed to model online information diffusion given\ntheirdual predictive andinterpretable capabilities[2,35,9,18].However,theHawkes\nprocess cannot incorporate feature sets in its base form since it relies only on ob-\nserved temporal sequences to fit the model parameters. Numerous modifications\nto incorporate feature sets have been proposed to enhance model fit and pre-\ndictive capabilities. A hybrid approach introduced in [20] integrates the Hawkes\nprocess with a scaling factor trained on cascade-level features to improve retweet\ncascade size prediction. The Empirical Bayes (EB) method [30] utilizes historical\nretweet sequences to link cascade features and the prior distribution of Hawkes\nprocess parameters, leading to better forecasting. The parametric Hawkes pro-\ncess [14] models the branching factor, i.e. the expected number of offsprings\nfrom a parent event, as a linear combination of event-level features. Lastly, the\nTweedie-Hawkes process [15] improves on this by combining the Hawkes process\nwith the Tweedie distribution to more realistically model the effect of event-level\nfeatures on the branching factor. The proposed BMH model is a hierarchical\nmodel and can incorporate two levels of feature sets: the cascade- and the item\n(i.e., cascade-group)-level, which previous work does not cover.\nAnother relevant area is mixtures of point processes, employed when the data\nis suspected to be generated from multiple dynamical classes (i.e., parameter\nsets). In [34], the Hawkes process was combined with the Dirichlet distribution\ntomodelclustersofcascades.Anonlinelearningframeworkwasintroducedin[8]\nto fit mixtures of multivariate Hawkes processes to learn the interaction network\nacross a set of actors. [29] introduces a generative model for mixtures of more\ncomplex point processes by using recurrent neural networks. Closest to our work\nis the Dual Mixture Model (DMM) [12], a generative model for cascade groups.\nEach cascade is sampled from a mixture of separable Hawkes processes learned\njointly with their mixture probabilities. To the best of our knowledge, including\n1The Stan/CmdStanPy implementation of the BMH model is available at https:\n//github.com/behavioral-ds/bayesian-mixture-hawkes/.\nBayesian Mixture Hawkes 5\nfeature sets into mixture models of point processes has not been explored: the\nBMH model solves this by learning the influence of features on the mixture\ncomponents.\n2 Preliminaries\nWe discuss two point process models that form the foundation of the BMH\nmodel. Section 2.1 presents the Hawkes Process (HP) [10], a temporal point pro-\ncess model that displays self-exciting behavior. Section 2.2 introduces the Dual\nMixture Model (DMM) [12], an approach to jointly model groups of cascades.\nAn introduction to Bayesian hierarchical modeling, which we employ to model\nhierarchical data, is included in Section 1.3 of the Online Appendix [5].\n2.1 Hawkes Process\nThe Hawkes process (HP) [10] is a temporal point process widely used to model\nphenomena that display self-excitation, i.e., the likelihood of an event increases\nasmoreeventsoccur.TheHPisspecifiedusingtheconditionalintensityfunction\n\u03bb(t|H), the event rate at any time tconditioned on the history H={tj|tj< t}\nof past events up to that point, i.e. \u03bb(t|H) =\u00b5+PN\nj=1\u03b1\u00b7g(t\u2212tj|\u0398). For\nbrevity, we drop the condition on the event history and write \u03bb(t|H)as\u03bb(t).\nUnder this parametrization, a Hawkes process HP(\u00b5, \u03b1,\u0398|g)is identified with\nthe parameters \u00b5,\u03b1andg(\u00b7|\u0398) :R+\u2192R+. The parameter \u00b5\u22650is the\narrival rate of events triggered by external sources, the branching factor \u03b1\u22650\nis the expected number of offsprings generated by a single parent event which\ncontrols the level of self-excitation from previous events, and the memory kernel\ng(\u00b7|\u0398)models the temporal decay of influence of previous events on future events\ncontrolled by the parameter set \u0398. In this work, we utilize the power law kernel\nparametrized by \u0398={\u03b8, d}, given by g(t|\u03b8, d) =\u03b8\u00b7d\u03b8\u00b7(t+d)\u2212(1+\u03b8). Other\ncommonchoicesforthememorykernelaretheexponentialkernel g(t|\u03b8) =\u03b8\u00b7e\u2212\u03b8t\nand the Reyleigh kernel g(t|\u03b8) =e\u22121\n2\u03b8\u00b7t2. We focus on the power law as it has\nbeen shown in [20] to outperform these alternatives in popularity prediction. HP\nestimation and prediction is discussed in detail in Sec. 1.1 of the Appendix [5].\nGiven a collection of complete cascades H={Hi}where each Hiis com-\npletely observed (i.e. terminal time Ti\u2192 \u221e), and assuming no exogenous events\n(i.e.\u00b5= 0, which occurs for instance with Twitter retweet cascades, where\nall retweets are considered to be spawned by the original tweet), the HP log-\nlikelihood L(\u03b1,\u0398|H)splits into two log-likelihoods [12],\nL(\u03b1,\u0398|H) =L(\u03b1|H) +L(\u0398|H), (1)\nL(\u03b1|H) =X\nHi\u2208Hlog\u0002\n\u03b1Ni\u22121e\u2212Ni\u03b1\u0003\n,L(\u0398|H) =X\nHi\u2208HX\ntj\u2208Hi,j\u22651logX\ntz<tjg(tj\u2212tz|\u0398),\nwhere we set Ni=|Hi|. Under this case, Hawkes process estimation splits into\ntwo independent problems, hence the term separable Hawkes process . The first\n6 P. Calderon and M.A. Rizoiu\nproblem (popularity estimation) utilizes the cascade sizes {Ni}to estimate the\nbranching factor \u03b1by maximizing L(\u03b1|H). It was shown in [12] that maximizing\nL(\u03b1|H)isequivalenttomaximizingP\nHi\u2208HlogB(Ni|\u03b1),where B(\u00b7|\u03b1)istheBorel\ndistribution [4]. The second problem (kernel estimation) uses the interevent-time\ndistribution T={tj\u2212tz}tz<tj,tj\u2208H,H\u2208Hto estimate \u0398by maximizing L(\u0398|H).\n2.2 Dual Mixture Model\nMaximizing Eq. (1) yields the best-fitting Hawkes parameter set {\u03b1,\u0398}. How-\never, this approach assumes that all cascades stem from a singular parameter\nset, an assumption which may not hold if there are multiple dynamical classes of\ncascade behavior. The Dual Mixture Model (DMM) [12] was proposed to model\na cascade group Hwith a mixture of Kseparable Hawkes processes of different\nparameter sets to account for different dynamical classes. Under separability, the\nDMM splits into two submodels: the Borel mixture model (BMM) for popular-\nity estimation and the kernel mixture model (KMM) for kernel estimation. The\nBMM assumes that there exist Kpopularity classes accounting for the cascade\nsizes{Ni}, where the ithclass is represented by the branching factor \u03b1\u2217\niwith\nprobability pB\ni, i.e.MB={(\u03b1\u2217\ni, pB\ni)}K\ni=1. Similarly, the KMM assumes that there\nareKkernel classes accounting for the interevent-time distribution T, where the\njthclass is represented by the kernel parameter set \u0398\u2217\njwith probability pg\nj, i.e.\nMg={(\u0398\u2217\nj, pg\nj)}K\ni=1. The DMM is the Cartesian product of MBandMg, i.e.\nM={(\u03b1\u2217\ni,\u0398\u2217\nj, pB\ni\u00b7pg\nj)|(\u03b1\u2217\ni, pB\ni)\u2208MB,(\u0398\u2217\nj, pg\nj)\u2208Mg}.DMM estimation and\nprediction is discussed in detail in Section 1.2 of the Online Appendix [5].\n3 Bayesian Mixture Hawkes (BMH) Model\nIn this section, we develop the Bayesian Mixture Hawkes (BMH) model, a hi-\nerarchical mixture model of separable Hawkes processes to learn the effect of\ncascade-level and item-level features on cascade spread dynamics. We first de-\nscribe the dataset structure that the BMH model is tailored to handle, then\ndiscuss the BMH model\u2019s objectives and the approach we adopt to address each.\nWe then present the two components of the BMH: the popularity submodel in\nSection 3.1 and the kernel submodel in Section 3.2.\nAssume that we are given the following dataset. First, we have a collection\nof items, denoted as A, from a shared source \u03c1, where each item a\u2208 Ais\ncharacterized by the feature vector\u2212 \u2192ya\u2208RNy. If\u03c1is a news publisher, then\nAcan represent a collection of news articles and\u2212 \u2192yathe embedding vector for\narticle a\u2019s headline. Second, we have a set of complete cascades Hafor each\nitem a\u2208 A, where cascade Hac\u2208Hahas size Nac, interevent distribution\nTac, and is described by the feature vector\u2212 \u2192xac\u2208RNx. In our news example,\nHacan represent discussions on Twitter related to article a, which we obtain by\ncollecting all retweet cascades initiated with a tweet linking article a\u2019s URL. The\nfeature vector\u2212 \u2192xaccan be taken as the follower count of the cascade\u2019s initiator.\nBayesian Mixture Hawkes 7\nTable 1: Summary of important quantities and notation.\nParameter Interpretation Real-World Mapping\na/Aitem/s produced by source \u03c1news article/s from publisher \u03c1\nHac/Hacascade/s related to item a retweet cascade/s for article a\u2212 \u2192yaitem-level features of a headline embedding for article a\nNaitem popularity of a overall tweet count for article a\u2212 \u2192xaccascade-level features of Hac# followers of Hacseed user\nNaccascade size of Hac\nTacintereevent-time distribution of\nHac\n(\u03b1ac,\u0398ac)HP parameter set generating Hac\n\u03c4ac\n1/2diffusion half-life of Hac\nK\u03b1/K\u0398# of BMH-P/-K classes\nzac\n\u03b1,k/zac\n\u0398,kclass kmembership probability\n\u03b4\u03b1,k/\u03b4\u03b8,kbaseline logit (\u03b1), log(\u03b8)for class k\n\u03b4z\u03b1,k/\u03b4z\u0398,kbaseline class kmem. probability\n\u2212 \u2192\u03b3\u03b1,k/\u2212 \u2192\u03b3\u03b8,keffect of\u2212 \u2192yaon class kcenter\u2212 \u2192\u03b3z\u03b1,k/\u2212 \u2192\u03b3z\u0398,keffect of\u2212 \u2192yaon class kmem. prob.\u2212 \u2192\u03b2\u03b1,k/\u2212 \u2192\u03b2\u03b8,keffect of\u2212 \u2192xacon class kcenter\u2212 \u2192\u03b2z\u03b1,k/\u2212 \u2192\u03b2z\u0398,keffect of\u2212 \u2192xacon class kmem. prob.\nWe model the generative process of Hacusing a separable power-law HP with\nparameter set (\u03b1ac,\u0398ac), i.e.Hac\u223c HP (\u03b1ac,\u0398ac|g). We construct the BMH as\na model for (\u03b1ac,\u0398ac)with three goals: (1) jointly learn across the item set A,\n(2) learn the relationship between\u2212 \u2192yaand(\u03b1ac,\u0398ac), and (3) learn the link\nbetween\u2212 \u2192xacand the same parameters. We handle goal (1) by using a two-level\nBayesian hierarchical model to jointly fit across each item a\u2208 Aand to tie\ntogether cascade- and item-level information. For goals (2) and (3), we consider\na mixture of separable HPs with K\u03b1classes for \u03b1acandK\u0398classes for \u0398ac.\nWe learn the influence of\u2212 \u2192yaand\u2212 \u2192xacon{\u03b1ac,\u0398ac}through the centers and\nmembership probabilities of the K\u03b1popularity classes and K\u0398kernel classes.\nDue to the separability of the underlying HP, the BMH divides into two\nindependentmodels:(1)BMH-P,the popularity submodelfor \u03b1ac,and(2)BMH-\nK,thekernelsubmodelfor \u0398ac.Table1liststhenotationforimportantvariables\nintheBMHandthemappingtoreal-worldquantitiesinthedatasetsinSection4.\n3.1 BMH-P, the Popularity Submodel\nThe branching factor \u03b1acis modeled as the mixture random variable\nlogit(\u03b1ac) =\u03b4a\n\u03b1,k+\u2212 \u2192\u03b3\u03b1,k\u00b7\u2212 \u2192ya, (2)\nwith membership probability zac\n\u03b1,k(k= 1, . . . , K \u03b1),\nzac\n\u03b1,k=exp(\u03b4a\nz\u03b1,k+\u2212 \u2192\u03b2a\nz\u03b1,k\u00b7\u2212 \u2192xac+\u2212 \u2192\u03b3z\u03b1,k\u00b7\u2212 \u2192ya)\nPK\u03b1\nk\u2032=1exp(\u03b4az\u03b1,k\u2032+\u2212 \u2192\u03b2az\u03b1,k\u2032\u00b7\u2212 \u2192xac+\u2212 \u2192\u03b3z\u03b1,k\u2032\u00b7\u2212 \u2192ya). (3)\n8 P. Calderon and M.A. Rizoiu\n(item level)(mixture components)(cascade \nlevel)\n*\n**\nFig.2: Plate diagram of the BMH-P model. Shaded nodes are observables while\nempty nodes are latent variables. Paired colored edges indicate source nodes ap-\npearing as a product in the target node. For instance, the green edges indicate\nthat\u2212 \u2192\u03b3\u03b1,kand\u2212 \u2192yaappear as\u2212 \u2192\u03b3\u03b1,k\u00b7\u2212 \u2192yain the expression for \u03b1acin Eq. (2). The\nsame concept holds for the blue and red edges. Edges marked with * indicate\ndependence of the target node on the source node indexed with kand the entire\nset{1,\u00b7\u00b7\u00b7, K\u03b1}. For instance, in Eq. (3) zac\n\u03b1,kdepends on\u2212 \u2192\u03b2a\nz\u03b1,k(see the numer-\nator) and\u2212 \u2192\u03b2a\nz\u03b1,k\u2032fork\u2032\u2208 {1,\u00b7\u00b7\u00b7, K\u03b1}(see the denominator).\nThe intercept \u03b4a\n\u03b1,kin Eq. (2) sets the centering of logit (\u03b1ac)for popularity class\nk. In Eq. (3), we designate k= 1as the reference class (i.e. \u03b4a\nz\u03b1,1=\u2212 \u2192\u03b2a\nz\u03b1,1=\n\u2212 \u2192\u03b3z\u03b1,1= 0); parameters for k > 1control deviation from class k= 1. The\nintercept \u03b4a\nz\u03b1,kcontrols the baseline proportion of class k\u2019. The influence of item\nfeatures on logit (\u03b1ac)and class kmembership are estimated by\u2212 \u2192\u03b3\u03b1,kand\u2212 \u2192\u03b3z\u03b1,k,\nrespectively, while the influence of cascade features on class kmembership is\nestimated by\u2212 \u2192\u03b2a\nz\u03b1,k. Note that\u2212 \u2192\u03b3\u03b1,k,\u2212 \u2192\u03b3z\u03b1,kare shared across Awhile\u2212 \u2192\u03b2a\nz\u03b1,kis\nestimated per a.\nFor brevity, we collect the parameter vector specific to item aas\u2212 \u2192pa\n\u03b1=\n[\u03b4a\n\u03b1,1, . . . , \u03b4a\n\u03b1,K\u03b1, \u03b4a\nz\u03b1,2, . . . , \u03b4a\nz\u03b1,K\u03b1,\u2212 \u2192\u03b2a\nz\u03b1,2, . . . ,\u2212 \u2192\u03b2a\nz\u03b1,K\u03b1]\u22ba.We link item awithAby\nassuming that\u2212 \u2192pa\n\u03b1is drawn from a source-level multivariate normal (MVN)\ndistribution with mean\u2212 \u2192p\u03b1and covariance matrix \u03a3\u03b1,\n\u2212 \u2192pa\n\u03b1\u223cMVN (\u2212 \u2192p\u03b1, \u03a3\u03b1), \u03a3 \u03b1=D\u03b1\u00b7\u2126\u03b1\u00b7D\u03b1,D\u03b1=diag(\u03c3\u2212 \u2192p\u03b1),(4)\nwhere \u2126\u03b1is a correlation matrix and \u03c3\u2212 \u2192p\u03b1is a vector of standard deviations\ncorresponding to\u2212 \u2192p\u03b1.\nThe plate diagram for the BMH-P model is shown in Fig. 2. Variable pairs\nthatappearasaproducttermarecoloredgreen,redandblueinEqs.(2)and(3),\nvisualized in Fig. 2 as source nodes with green, red and blue edges.\nBayesian Mixture Hawkes 9\nInferenceandPrediction. LetP\u03b1betheparametersetfortheBMH-Pmodel.\nFrom the set of cascade sizes {Nac}Hac\u2208Ha,a\u2208A, we estimate the posterior distri-\nbution P(P\u03b1|{Nac}ac)\u221dexp(L(P\u03b1|{Nac}ac))\u00b7P(P\u03b1), where P(P\u03b1)is the prior\nforP\u03b1andL(P\u03b1|{Nac}ac)is the log-likelihood of P\u03b1given the cascade sizes\n(derived in Section 2.2 of the Online Appendix [5]). Informative priors have to\nbe set on {\u03b4\u03b1,k, \u03b4z\u03b1,k}to identify the K\u03b1classes in the \u03b1parameter space. \u03b4\u03b1,k\nand\u03b4z\u03b1,kidentify the center and baseline proportion of the kthclass, respec-\ntively. Weakly informative priors are set for the other parameters in P\u03b1. We\nimplement1the BMH-P model in Stan[6], which uses the No-U-Turn Sampler\n(NUTS), a Hamiltonial Monte Carlo technique, to sample the posterior distribu-\ntionP(P\u03b1|{Nac}ac). We use CmdStanPy [31] to run Stan code through Python.\nUsing the average cascade count for items in A, denoted as \u02c6C\u03c1, and the\nempirical distribution of the cascade feature vector\u2212 \u2192xac, denoted as \u02c6f\u03c1(x), the\nfitted BMH-P model can be used to estimate the cold-start popularity \u02c6Na\u2217of\nan out-of-sample item a\u2217with feature vector\u2212 \u2192ya\u2217:\n\u02c6Na\u2217\u2248\u02c6C\u03c1\u00b7\u221eX\nx=0K\u03b1X\nk=1za\u2217,c\n\u03b1,k\u00b7h\n1 +exp\u0010\n\u03b4a\u2217\n\u03b1,k+\u2212 \u2192\u03b3\u03b1,k\u00b7\u2212 \u2192ya\u2217\u0011i\n\u00b7\u02c6f\u03c1(x),(5)\nwhere we assume that\u2212 \u2192xac=x\u2208N(see Section 2.2 of the Appendix [5]).\n3.2 BMH-K, the Kernel Submodel\nUnderthepower-law,thekernelparametersetgenerating Hacis\u0398ac= [\u03b8ac, dac]\u22ba.\nWe model \u0398acas a pair of mixture random variables taking the value\nlog(\u03b8ac) =\u03b4a\n\u03b8,k+\u2212 \u2192\u03b3\u03b8,k\u00b7\u2212 \u2192ya,log(dac) =\u03b4a\nd,k (6)\nwith probability zac\n\u0398,k(k= 1, . . . , K \u0398), where\nzac\n\u0398,k=exp(\u03b4a\nz\u0398,k+\u2212 \u2192\u03b2a\nz\u0398,k\u00b7\u2212 \u2192xac+\u2212 \u2192\u03b3z\u0398,k\u00b7\u2212 \u2192ya)\nPK\u0398\nk\u2032=1exp(\u03b4az\u0398,k\u2032+\u2212 \u2192\u03b2az\u0398,k\u2032\u00b7\u2212 \u2192xac+\u2212 \u2192\u03b3z\u0398,k\u2032\u00b7\u2212 \u2192ya). (7)\nIn Eq. (7) we designate k= 1as the reference class (i.e. \u03b4a\nz\u0398,1=\u2212 \u2192\u03b2a\nz\u0398,1=\n\u2212 \u2192\u03b3z\u0398,1= 0).\nLet\u2212 \u2192pa\n\u0398,k= [\u03b4a\n\u03b8,k, \u03b4a\nd,k]\u22baand\u2212 \u2192pa\nz\u0398=h\n\u03b4a\nz\u0398,2,, . . . , \u03b4a\nz\u0398,K\u0398,\u2212 \u2192\u03b2a\nz\u0398,2, . . . ,\u2212 \u2192\u03b2a\nz\u0398,K\u0398i\u22ba\n.\nThe complexity of estimating two parameters (i.e. \u03b8ac, dac) makes it challeng-\ning to estimate a joint source-level MVN distribution as we did for BMH-P. To\nsimplify, we assume independence of (\u03b4a\n\u03b8,k, \u03b4a\nd,k)across classes. For each kernel\nclass k, we assume\u2212 \u2192p\u0398,kis drawn from a source-level MVN distribution with\nmean\u2212 \u2192p\u0398,k= [\u03b4\u03b8,k, \u03b4d,k]\u22baand covariance matrix \u03a3\u0398,k. Lastly, we assume\u2212 \u2192pa\nz\u0398\nis drawn from an MVN distribution with mean\u2212 \u2192pz\u0398and covariance matrix \u03a3z\u0398.\n\u2212 \u2192pa\n\u0398,k\u223cMVN (\u2212 \u2192p\u0398,k, \u03a3\u0398,k), \u03a3\u0398,k=D\u0398,k\u00b7\u2126\u0398,k\u00b7D\u0398,k,D\u0398,k=diag(\u03c3\u2212 \u2192p\u0398,k)\n\u2212 \u2192pa\nz\u0398\u223cMVN (\u2212 \u2192pz\u0398, \u03a3z\u0398), \u03a3 z\u0398=Dz\u0398\u00b7\u2126z\u0398\u00b7Dz\u0398,Dz\u0398=diag(\u03c3z\u0398),\n10 P. Calderon and M.A. Rizoiu\n(mixture components)(item level)(cascade level)\n**\n*\nFig.3: Plate diagram of the BMH-K model. Shaded nodes are observables while\nempty nodes are latent variables. Paired colored edges indicate source nodes\nappearing as a product in the target node. For instance, the green edges indicate\nthat\u2212 \u2192\u03b3\u03b8,kand\u2212 \u2192yaappear as the product\u2212 \u2192\u03b3\u03b8,k\u00b7\u2212 \u2192yain the expression for \u03b8acin\nEq. (6). The same concept holds for the blue and red edges. Edges marked with\n* indicate dependence of the target node on the source node indexed with kand\nthe entire set {1,\u00b7\u00b7\u00b7, K\u0398}. For instance, in Eq. (7) zac\n\u0398,kdepends on\u2212 \u2192\u03b2a\nz\u0398,k(see\nthe numerator) and\u2212 \u2192\u03b2a\nz\u0398,k\u2032fork\u2032\u2208 {1,\u00b7\u00b7\u00b7, K\u0398}(see the denominator).\nwhere \u03c3\u2212 \u2192p\u0398,k, \u03c3\u2212 \u2192pz\u0398arestandarddeviationvectorsand \u2126\u0398,k, \u2126z\u0398arecorrelation\nmatrices.\nThe plate diagram for the BMH-K model is shown in Fig. 3. Variable pairs\nthatappearasaproducttermarecoloredgreen,redandblueinEqs.(6)and(7),\nvisualized in Fig. 3 as source nodes with green, red and blue edges.\nInference and Prediction. LetP\u0398be the parameter set for the BMH-K\nmodel.Fromtheinterevent-timedistributions {Tac}ac,weestimatetheposterior\ndistribution P(P\u0398|Tac)\u221dexp(L(P\u0398|{Tac}ac)\u00b7P(P\u0398). The log-likelihood of\nP\u0398given{Tac}acis derived in Section 2.3 of Online Appendix [5]. Informative\npriors have to be set on {\u03b4\u03b8,k, \u03b4d,k, \u03b4z\u0398,k}to identify the K\u0398classes in the (\u03b8, d)\nparameterspace. (\u03b4\u03b8,k, \u03b4d,k)and\u03b4z\u0398,kidentifythecenterandbaselineproportion\nof the kthclass, respectively. Weakly informative priors are set for the other\nparameters in P\u0398. Similar to the BMH-P model, we implementt1the BMH-\nK model in Stan and CmdStanPy to sample from the posterior distribution\nP(P\u0398|Tac).\nBayesian Mixture Hawkes 11\nTable 2: Statistics of the predictive evaluation datasets.\nCNIX \u2212Fit CNIX \u2212Test RNIX \u2212Fit RNIX \u2212Test\n#publishers 41 41 28 28\n#articles 72,009 40,506 2,682 18,116\n#cascades 4,620,509 1,874,729 244,596 460,504\n#tweets 42,546,067 18,235,185 1,573,909 5,139,967\nThe BMH-K model predicts the half-life \u02c6\u03c4a\u2217\n1/2of an out-of-sample item a\u2217as\n(see Section 2.3 of the Online Appendix [5]),\n\u02c6\u03c4a\u2217\n1/2\u2248\u221eX\nx=0K\u0398X\nk=1za\u2217,c\n\u0398,k\u00b7e\u03b4a\u2217\nd,k\u00b7h\n2exp (\u03b4a\u2217\n\u03b8,k+\u2212 \u2192\u03b3\u03b8,k\u00b7\u2212 \u2192ya\u2217)\u22121i\n\u00b7\u02c6f\u03c1(x).(8)\n4 Predictive Evaluation\nIn this section, we introduce two evaluation datasets (Section 4.1) and assess\nthe BMH model\u2019s performance on two tasks: cold-start popularity prediction\n(Section 4.2) and temporal profile generalization performance (Section 4.3), i.e.\nevaluating the likelihood of the interevent distribution of future cascades.\n4.1 Datasets\nWe use two datasets from [12] for predictive evaluation, consisting of collections\nof Twitter retweet cascades that link articles from online news sources. The Con-\ntroversial News Index ( CNIX) dataset consists of retweet cascades mentioning\narticles from 41 online news publishers known for controversial content, such as\nhttps://www.breitbart.com/ . Conversely, the Reputable News Index ( RNIX)\nfollows the same structure as the CNIXdataset but gathers cascades linked\nto articles from 28 reputable publishers, such as https://www.news.com.au/ .\nThe tweets for both datasets were collected by the QUT Digital Media Research\nCentre by retrospectively querying the Twitter search endpoint for URL men-\ntions of the articles between June 30, 2017 and Dec 31, 2019. In Table 1 we link\nquantities in these datasets with variables in the BMH model.\nBothCNIXandRNIXare temporally split into Fit(i.e. training) and Test\n(i.e. evaluation) datasets. The first contains tweets published from Jun 30, 2017\ntoJan1,2019,whilethesecondcontainstweetsfromFeb1,2019toDec31,2019.\nA one-month gap between FitandTestensures that cascades in the training\ndata are finished before the test period. Table 2 shows summary statistics.\nWe use the standardized 32-D embedding of a\u2019s headline (i.e. PCA-reduced,\nall-MiniLM-L6-v2 [26]) as our article feature vector\u2212 \u2192ya, and the standardized\nlog-follower count of the cascade\u2019s seed user as the cascade feature vector\u2212 \u2192xac.\n12 P. Calderon and M.A. Rizoiu\n4.2 Cold-Start Popularity Prediction\nOur first task is evaluating the ability of the BMH-P model to predict cold-start\npopularity of unpublished content. With publisher \u03c1\u2019s trained BMH-P model, we\npredict the future popularity Na\u2217of an out-of-sample article a\u2217with Eq. (5). To\nguide the selection of the number of mixture components K\u03b1, we fit the BMM\nto each publisher in RNIX. We observe that the BMM-fitted {\u03b1a\ni}distribution\nis bimodal, corresponding to clusters of popular and unpopular cascades. See\nSection 3.1 of the Appendix [5] for full details. Using this result, we fit a BMH-P\nmodel for each publisher in CNIXandRNIXin Stan with the hyperparameter\nK\u03b1= 2. The full set of priors for the BMH-P model is listed in Section 3.2 of\nthe Appendix [5]. Note that we use a Laplace prior on\u2212 \u2192\u03b3\u03b1,1,\u2212 \u2192\u03b3\u03b1,2,\u2212 \u2192\u03b3z\u03b1,2to\nimpose regularization given the high dimensionality of the article feature vector\n(|\u2212 \u2192ya|= 32) we consider.\nTo evaluate the predictive power of\u2212 \u2192xacand\u2212 \u2192ya, apart from the full model as\ndeveloped in Section 3.1 (which we call \u03b1(\u2212 \u2192ya)+z(\u2212 \u2192xac,\u2212 \u2192ya)) we fit three simpler\nvariants of BMH-P: (1) \u03b1(\u2212 \u2192ya) +z(\u2212 \u2192ya), where we set\u2212 \u2192xac= 0in Eq. (3); (2)\n\u03b1(\u2205) +z(\u2212 \u2192ya), where set\u2212 \u2192xac= 0in Eq. (3) and\u2212 \u2192yac= 0in Eq. (2); and (3)\n\u03b1(\u2205) +z(\u2205), where we set\u2212 \u2192xac= 0in Eq. (3) and\u2212 \u2192yac= 0in Eqs. (2) and (3).\nWe compare the performance of the BMH-P model to three approaches: (1)\nthe DMM [12], (2) the empirical Bayes (EB) approach [30], and (3) feature-based\ncascade-size (CR) regression models (i.e. a neural network with one hidden layer\nof 100 nodes) built using scikit-learn [25]. For EB and CR, we fit two variants:\none using only article features (i.e. EB(y) and CR(y)) and another using both\ncascade and article features (i.e. EB(x,y) and CR(x,y)). We report the Average\nRelative Error ( ARE) over the set of articles in the Testdatasets. Let Naand\n\u02c6Nabe the actual and predicted popularity of article a, then ARE (a) =|\u02c6Na\u2212Na|\nNa.\nResults. In the top half of Table 3, we summarize cold-start popularity pre-\ndiction performance of the model variants for CNIX/RNIX . In both datasets\nthe variants with only article-level features\u2212 \u2192yaand without the cascade-level\nfeatures\u2212 \u2192xacshow minimal performance gain ( RNIX) or even worse perfor-\nmance ( CNIX) over the no-feature \u03b1(\u2205)+z(\u2205)model. The full model \u03b1(\u2212 \u2192ya)+\nz(\u2212 \u2192xac,\u2212 \u2192ya)significantly outperforms each simpler variant, highlighting the im-\nportance of the seed user\u2019s popularity as a predictor of final popularity [1].\nWe compare the performance of the best-performing BMH-P model with\nthe benchmarks in the top row of Fig. 4(a) and Fig. 4(b). We can see that the\nBMH-P model outperforms each benchmark based on median performance. We\nnote that in each task, the benchmarks that only have article features ( CR(y)\nandEB(y)) outperform the corresponding benchmarks that also include cascade\nfeatures ( CR(x, y)andEB(x, y)). However, our ablation results show that the\nbest-performing BMH-P model includes both the cascade and article features.\nThis implies that the added structure of the BMH-P model jointly leverages the\narticle- and cascade-level information better than the benchmarks.\nBayesian Mixture Hawkes 13\nTable 3: Popularity prediction and generalization results. We show the median\n(25th,75thquantiles)forBMHwithdifferentfeaturecomponentsremoved.Lower\nARE/NLL mean better performance. The best score across variants is in bold.\nPopularity (ARE) CNIX RNIX\n\u03b1(\u2205) +z(\u2205) 0.707 (0.334, 1.513) 0.644 (0.335, 0.921)\n\u03b1(\u2205) +z(\u2212 \u2192ya) 0.708 (0.336, 1.497) 0.666 (0.339, 1.033)\n\u03b1(\u2212 \u2192ya) +z(\u2212 \u2192ya) 0.738 (0.370, 1.316) 0.643 (0.325, 0.953)\n\u03b1(\u2212 \u2192ya) +z(\u2212 \u2192xac,\u2212 \u2192ya) 0.646(0.313, 0.935) 0.635(0.342, 0.932)\nGeneralization (NLL) CNIX RNIX\n\u03b8(\u2205) +z(\u2205) -3.841 (-5.293, -2.717) -2.564 (-3.231, -2.031)\n\u03b8(\u2205) +z(\u2212 \u2192ya) -3.782 (-4.873, -2.683) -2.550 (-3.226, -1.988)\n\u03b8(\u2212 \u2192ya) +z(\u2212 \u2192ya) -3.649 (-4.816, -2.617) -2.689(-3.492, -2.117)\n\u03b8(\u2212 \u2192ya) +z(\u2212 \u2192xac,\u2212 \u2192ya) -4.013(-5.766, -2.714) -2.645 (-3.450, -2.063)\n4.3 Temporal Profile Generalization Performance\nOur second task is evaluating the performance of the BMH-K model in captur-\ning the inter-arrival distribution of future cascades of unpublished articles. Given\npublisher \u03c1\u2019strainedBMH-Kmodel,wecalculatethelog-likelihood L(P\u0398|{Ta\u2217c})\nof the inter-arrival distribution {Ta\u2217c}of an unpublished article a\u2217.\nTo guide the selection of the number of mixture components K\u0398, we fit the\nKMMtoeachpublisherin RNIX.WeobservethattheKMM-fitted {\u03b8a\ni, da\nI}dis-\ntribution is trimodal, corresponding to clusters of usual, slow- and fast-diffusing\ncascades cascades. See Section 3.1 of the Appendix [5] for full details. Using this\nresult, we fit a BMH-K model for each publisher in CNIXandRNIXin Stan\nwith the hyperparameter K\u0398= 3. The full set of priors for the BMH-K model\nis listed in Section 3.3 of the Appendix [5]. Note that we use a Laplace prior on\u2212 \u2192\u03b3\u0398,2,\u2212 \u2192\u03b3\u0398,3,\u2212 \u2192\u03b3z\u0398,2,\u2212 \u2192\u03b3z\u0398,3to impose regularization given the high dimensional-\nity of the article feature vector ( |\u2212 \u2192ya|= 32) we consider.\nIn addition to the full BMH-K model developed in Section 3.2 (which we call\n\u03b8(\u2212 \u2192ya) +z(\u2212 \u2192xac,\u2212 \u2192ya)) we fit three progressively simpler variants analogous to\nthe ablation for the BMH-P model: \u03b8(\u2212 \u2192ya) +z(\u2212 \u2192ya),\u03b8(\u2205) +z(\u2212 \u2192ya), and \u03b8(\u2205) +\nz(\u2205). To evaluate performance, we calculate the loglikelihood L(P\u0398|{Tac})of\ninter-arrival times {Tac}a\u2208Aover articles in the Testdatasets. Since we are\nevaluating on likelihood, we use generative models as benchmarks: the DMM,\nEB(y), EB(x,y), and publisher-level joint HP (see Sec. 1.1 of the Appendix [5]).\nResults. In the lower half of Table 3, we see that for CNIXeach addi-\ntional model component improves the log-likelihood, and that the full model\n\u03b1(\u2212 \u2192ya) +z(\u2212 \u2192xac,\u2212 \u2192ya)has the best performance. For RNIXwe observe that the\nvariant without the seed user follower count, i.e., \u03b8(\u2212 \u2192ya) +z(\u2212 \u2192ya), has the best\nperformance. This finding suggests that in cascades related to reputable media\narticles, the seed user is not as influential in determining how long a cascade\n14 P. Calderon and M.A. Rizoiu\nBMH EB(y) CR(y) CR(x,y) EB(x,y) DMM0 .51 .01 .52 .02 .5ARE\nBMH DMM Hawkes EB(y) EB(x,y)6\n4\n2\n02Neg. Holdout LogLik\n0.646\n0.649\n-1.527 -1.218\n0.7740.688 0.7200.912\n-4.0130.962\n1.251\n(a)\nBMH DMM CR(y) EB(y) CR(x,y) EB(x,y)0 .40 .60 .8Neg. Holdout LogLik\nBMH DMM Hawkes EB(y) EB(x,y)3\n2\n1\n0.635 0.677\n-1.255 -1.212-0.873\n-0.7930.697\n-2.6890.7260.805\n0.877ARE (b)\nFig.4: Predictive performance for (a) CNIX and (b) RNIX. The dots indicate\nthe median and the error bars give the 25th/75thquantiles. We compare the\nBMH with the DMM [12], EB [30], cascade-size (CR) models, and the joint HP.\nunfolds. In contrast, for controversial media articles, the seed user plays a sig-\nnificant role. We posit this is because the more fringe messaging in controversial\nmedia spreads through topical social groups (like conspiracy theorists, QAnon\nsympathizers and far-right supporters) [3,11]. As a result, the first endorser is\nparticularly important to legitimize content within the group. This is in contrast\nwith the publicizing of traditional media articles on social media, where the most\nimportant factor is the publisher\u2019s reputation. In the bottom row of Fig. 4(a)\nand Fig. 4(b), we see that similar to the popularity prediction task, the BMH-K\nmodel outperforms all benchmarks on median performance for both datasets.\n5 What-If? Headline Style Profiling\nThis section performs a counter-factual analysis to show that BMH successfully\ncaptures the relationship between headline writing style (i.e. neutral, clickbait\nor inflammatory) and content popularity and half-life. We run a \u2018What-If?\u2019 ex-\nperiment, taking headlines of different writing styles and using the trained BMH\nmodels to infer how these headlines would perform under different publishers.\nWe utilize HEADLINES , a dataset of 1,227article headlines collected us-\ning the news aggregation platform The Daily Edit [13]. The headlines come from\nfour topics (Top Stories, Australia, Finance, and Climate Change) and six me-\ndia sources (Daily Telegraph, Sky News, Sunday Morning Herald, The Guardian,\nnews.com.au). Each headline was examined and sorted into one of three cate-\ngories based on its informational and emotional content: neutral (N=727), click-\nbait (N=438) and inflammatory (N=62). Neutral headlines are detailed and\nappropriate, avoiding unnecessary information or emotive language, e.g. \u2018Aus-\ntralia\u2019s top military officer in the UK speaks ahead of Queen\u2019s funeral.\u2019 Click-\nbait lacks informational and/or emotive quality without being misleading or in-\nBayesian Mixture Hawkes 15\n2.0 2.3 2.61.5\n1.3\n1.1\nneutral\nclickbait\ninflammatory\n(a)\nCNIX RNIX0.3 00.4 00.5 00.6 00.7 0P(better than average)\nneutral\nclickbait\ninflammatory\n (b)\nCNIX RNIX0.10.30.50.70.9P(better than average)\n (c)\nFig.5: (a) Distribution of predicted half-life log \u02c6\u03c4a\n1/2vs. cascade size log\u02c6Nafor\neach article in HEADLINES using the news.com.au BMH model. (b and c)\nProbability that an article performs better than the publisher average, for each\nheadline style across CNIXandRNIX: (b) cascade size \u02c6Na; (c) half life \u02c6\u03c4a\n1/2.\nflammatory, often designed to attract attention, e.g. \u2018Bizarre sight spotted amid\nAussie floods.\u2019 Inflammatory headlines contain unnecessary details, often on se-\nrious topics, and may include inappropriate emotional language or details that\nreinforce negative stereotypes, e.g. \u2018Absolutely disgraceful\u2019: AFL fans blasted.\u2019\nWe use the trained publisher-level BMH models in Section 4 to predict per-\nformance of article headlines for each publisher in CNIXandRNIX: expected\ncascade size (Eq. (5)) (setting \u02c6C\u03c1= 1) and half-life (Eq. (8)). We use the\nvariants that include only item features (i.e. \u03b1(\u2212 \u2192ya) +z(\u2212 \u2192ya)for BMH-P and\n\u03b8(\u2212 \u2192ya) +z(\u2212 \u2192ya)for BMH-K) since cascade features are not available in this\ncounter-factual setting.\nResults. We apply the trained the BMH-P/-K models of each publisher \u03c1in\n{CNIX, RNIX }to each of the 1,227article headlines in HEADLINES to in-\nfer the article\u2019s peformance if it were published under \u03c1. We summarize the pre-\ndictions with a publisher-level performance heatmap ( log\u02c6Navs.log \u02c6\u03c4a\n1/2), where\nwedifferentiatetheperformanceofneutral,clickbaitandinflammatoryheadlines\nby aggregating the predictions of each headline style as contour plots. Fig. 5a ex-\nemplifies the performance heatmap for the RNIXpublisher news.com.au . For\nthisnewssource,weseethatinflammatoryheadlinesappeartohavemuchhigher\npopularity than neutral or clickbait headlines, while there is not much difference\nin half-life across headline styles. This is somewhat expected, as this publisher\nis known for its tabloid tendencies, focusing on \u201ccelebrity gossip, travel, lifestyle,\nsport, business, technology, money, and real estate\u201d, according to Media Bias\nFact Check (MBFC) [19]. MBFC also rates its factual reporting as \u201cMOSTLY\nFACTUAL\u201d due to the occasional use of poor sources. We observe differences\nin the patterns for the headline styles across publishers (see Section 4.1 of the\nOnline Appendix [5]), implying that effective headlines for one publisher might\nnot be effective for another, and that the BMH model learns these differences.\n16 P. Calderon and M.A. Rizoiu\nTo summarise the differences across the categories CNIXandRNIX, we\ncompute the probability that each headline performs better \u2013 has a larger pre-\ndicted cascade size or longer predicted half-life based on the BMH\u2013 than the\npublisher average based on the publisher\u2019s historical data. In Figs. 5b and 5c we\nshow the distribution of these probabilities for each category and headline style.\nWe have three observations for the popularity probabilities in Fig. 5b. First,\nwe see that for CNIX, neutral headlines are effective (i.e. median better-than-\naverage probability >50%). In contrast, clickbait headlines are ineffective (i.e.\nmedianbetter-than-averageprobability <50%).Welinkthisresulttotheknown\ninverse U-shaped relationship between clickbait volume and audience engage-\nment [33], where too little or too much clickbait leads to suboptimal attention,\nsuggesting the existence of a sweet spot for clickbait use. The over-prevalence of\nclickbait in controversial media outlets results in clickbait fatigue among readers\n[17],leadingtodiminishedeffectivenessofclickbaitheadlinesobservedinFig.5b.\nSecond and interestingly, we see that for RNIXclickbait tends to perform\nbetter than neutral headlines. This is explained by Rony et al [28], who show\nthattraditionalnews-orientedmediaconsistofonly22%clickbaitheadlineswhile\nunreliable media consists of 39% clickbait based on a large sample of headlines.\nSince reputable media publishers have lower clickbait volume than controver-\nsial outlets, they are closer to the sweet spot for clickbait usage, retaining its\neffectiveness for drawing audience engagement. We do see a larger variance for\nclickbait for RNIXcompared to CNIX, suggesting that clickbait effectiveness\nis inconsistent and may not resonate universally, linking to the fact that clickbait\nstrategies are only successful with certain audience segments [21].\nThird, we observe large variance of performance for inflammatory headlines\nin both categories, indicative of the polarizing nature of this headline style.\nInflammatory headlines tend to perform better in controversial outlets.\nFor the half-life probabilities (Fig. 5c), we see similar results, except that\nneutral headlines in both categories have higher half-life than clickbait, demon-\nstrating the ephemerality of clickbait [16] irrespective of where it is published.\n6 Conclusion and Future Work\nThis paper proposes the Bayesian Mixture Hawkes (BMH) model, a hierarchical\nmixture model of Hawkes processes capable of learning the influence of item-\nand cascade-level features on spread dynamics. We demonstrate the applicabil-\nity of the BMH model on two retweet cascade datasets that reference articles\nfrom reputable and controversial online news sources and show that the BMH\nmodel outperforms benchmark models in cold-start popularity prediction and\ntemporal profile generalization performance. We apply the trained BMH models\nto a dataset of article headlines written in different headline styles and show\ndifferences in performance of headline styles across reputable and controversial\noutlets.\nBayesian Mixture Hawkes 17\nLimitations and Future Work. We use the Hawkes process as the building\nblock of the BMH model since it does not require the branching structure of\ndiffusion cascades for inference. This choice is driven by data limitations on\nTwitter, where the branching structure of content shares is not accessible.\nWe propose two improvements. First, the BMH model assumes that \u03b1and\u0398\ndependonlyoncascade-andcontent-levelfeatures.Wecanallow \u03b1and\u0398tovary\nper event by including event-level features, which can be achieved by using the\nparametricHawkesprocess[14]orTweedie-Hawkes[15].Second,theBMHmodel\nassumesafixednumberofpopularity/kernelclasses,obtainedempiricallybypre-\nfitting with the DMM. We can learn the manifest number of components directly\nfrom the data by assuming an infinite number of components via nonparametric\nBayesian methods, such as using a Dirichlet Process prior [22].\nWe aim to develop the BMH model as a cold-start headline optimization tool\nby combining it with generative AI (e.g. ChatGPT [23]). The system would work\nin a \u2018generate-then-evaluate\u2019 loop, where headlines are generated automatically\nby ChatGPT and then we apply the BMH model to rank the generations.\nAcknowledgments. This work was partially funded by the Australian Department\nof Home Affairs, the Defence Science and Technology Group, the Defence Innovation\nNetwork and the Australian Academy of Science.\nDisclosure of Interests. The authors have no competing interests to declare that\nare relevant to the content of this article.\nReferences\n1. Bakshy, E., Hofman, J.M., Mason, W.A., Watts, D.J.: Everyone\u2019s an influencer:\nquantifying influence on twitter. In: WSDM 2011\n2. Bao, P.: Modeling and predicting popularity dynamics via an influence-based self-\nexcited hawkes process. In: CIKM 2016\n3. Booth, E., Lee, J., Rizoiu, M.A., Farid, H.: Conspiracy, misinformation, radicali-\nsation: understanding the online pathway to indoctrination and opportunities for\nintervention. Journal of Sociology (feb 2024)\n4. Borel, E.: Sur l\u2019emploi du theoreme de Bernoulli pour faciliter le calcul d\u2019une\ninfinite de coefficients. CR Acad. Sci. Paris (1942)\n5. Calderon, P., Rizoiu, M.A.: Appendix: What drives online popularity: Author,\ncontent or sharers? https://arxiv.org/pdf/2406.03390.pdf#page=19 (2024)\n6. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B., Betancourt,\nM., Brubaker, M., Guo, J., Li, P., Riddell, A.: Stan: A probabilistic programming\nlanguage. Journal of statistical software 76(1) (2017)\n7. Center, P.R.: Pew research center (2023), https://www.pewresearch.org/\njournalism/fact-sheet/social-media-and-news-fact-sheet/\n8. Ghassemi, M., Dalmasso, N., Lamba, S., Potluru, V., Balch, T., Shah, S., Veloso,\nM.: Online learning for mixture of multivariate hawkes processes. In: ICAIF 2022\n9. Gomez-Rodriguez, M., Balduzzi, D., Sch\u00f6lkopf, B.: Uncovering the temporal dy-\nnamics of diffusion networks. In: ICML 2011 (2011)\n10. Hawkes, A.G.: Spectra of some self-exciting and mutually exciting point processes.\nBiometrika 58(1), 83\u201390 (1971)\n18 P. Calderon and M.A. Rizoiu\n11. Johns, A., Bailo, F., Booth, E., Rizoiu, M.A.: Labelling, shadow bans and commu-\nnity resistance: did meta\u2019s strategy to suppress rather than remove covid misinfo\nand conspiracy theory on facebook slow the spread? Media International Australia\n12. Kong,Q.,Rizoiu,M.A.,Xie,L.:Describingandpredictingonlineitemswithreshare\ncascades via dual mixture self-exciting processes. In: CIKM 2020 (2020)\n13. Lee, J., Booth, E., Farid, H., Rizoiu, M.A.: Misinformation is not about Bad Facts:\nAn Analysis of the Production and Consumption of Fringe Content (mar 2024),\nhttp://arxiv.org/abs/2403.08391\n14. Li, L., Zha, H.: Learning parametric models for social infectivity in multi-\ndimensional hawkes processes. In: AAAI 2014\n15. Li,T.,Ke,Y.:Tweedie-hawkesprocesses:Interpretingthephenomenaofoutbreaks.\nIn: Proceedings of the AAAI Conference on Artificial Intelligence (2020)\n16. Liao, Y., Wang, S., Han, E., Lee, J., Lee, D.: Characterization and early detection\nof evergreen news articles. In: ML and Knowledge Discovery in Databases (2020)\n17. Lischka, J., Garz, M.: Clickbait news & algorithmic curation: Game theory frame-\nwork of the relation bet. journalism, users and platforms. New Media & Society\n18. Ma,J.,Gao,W.,Mitra,P.,Kwon,S.,Jansen,B.J.,Wong,K.F.,Cha,M.:Detecting\nrumors from microblogs with recurrent neural networks. In: IJCAI 2016 (2016)\n19. Media Bias Fact Check: News.com.au \u2013 Bias and Credibility (2024), https://\nmediabiasfactcheck.com/news-com-au/\n20. Mishra, S., Rizoiu, M.A., Xie, L.: Feature driven and point process approaches for\npopularity prediction. In: CIKM 2016. pp. 1069\u20131078\n21. Mukherjee, P., Dutta, S., De Bruyn, A.: Did clickbait crack the code on virality?\nJournal of the Academy of Marketing Science 50(3), 482\u2013502 (2022)\n22. Navarro, D.J., Griffiths, T.L., Steyvers, M., Lee, M.D.: Modeling individual differ-\nencesusingdirichletprocesses.JournalofmathematicalPsychology 50(2),101\u2013122\n(2006)\n23. OpenAI: Chatgpt (2023), https://openai.com/chatgpt , software tool\n24. Parikh, S.B., Patil, V., Makawana, R., Atrey, P.K.: Towards impact scoring of fake\nnews. In: MIPR 2019. IEEE\n25. Pedregosa, F., et.al.: Scikit-learn: Machine learning in Python. Journal of Machine\nLearning Research 12, 2825\u20132830 (2011)\n26. Reimers, N., Gurevych, I.: Sentence-bert: Sentence embeddings using siamese bert-\nnetworks. In: EMNLP 2019\n27. Rizoiu, M.A., Xie, L., Sanner, S., Cebrian, M., Yu, H., Van Hentenryck, P.: Ex-\npecting to be HIP: Hawkes Intensity Processes for Social Media. In: WWW 2017\n28. Rony, M.M.U., Hassan, N., Yousuf, M.: Diving deep into clickbaits: Who use them\nto what extents in which topics with what effects? (2017)\n29. Sharma, A., Ghosh, A., Fiterau, M.: Generative sequential stochastic model for\nmarked point processes. In: ICML Time Series Workshop (2019)\n30. Tan, W.H., Chen, F.: Predicting the popularity of tweets using internal and exter-\nnal knowledge: an empirical bayes type approach. AStA 105(2), 335\u2013352 (2021)\n31. Team, S.: Cmdstanpy (0.9.76). https://pypi.org/project/cmdstanpy (2023)\n32. Tsagkias, M., Weerkamp, W., de Rijke, M.: Predicting the volume of comments on\nonline news stories. In: CIKM 2009 (2009)\n33. W, Z., W, D., Y, B., et al.: Seeing is not always believing: an exploratory study of\nclickbait in wechat. Internet Research 30(3), 1043\u20131058 (2020)\n34. Xu, H., Zha, H.: A dirichlet mixture model of hawkes processes for event sequence\nclustering. Advances in neural information processing systems 30(2017)\n35. Zhao, Q., Erdogdu, M.A., He, H.Y., Rajaraman, A., Leskovec, J.: Seismic: A self-\nexciting point process model for predicting tweet popularity. In: SIGKDD 2015\nSupplementary Material for What Drives Online\nPopularity: Author, Content or Sharers?\nEstimating Spread Dynamics with Bayesian\nMixture Hawkes\nPio Calderon( \u0000)[0000\u22120002\u22128747\u22128917]and Marian-Andrei\nRizoiu[0000\u22120003\u22120381\u2212669X]\nUniversity of Technology Sydney, Australia\npiogabrielle.b.calderon@student.uts.edu.au\nmarian-andrei.rizoiu@uts.edu.au\n1 Background Material\n1.1 Hawkes Process\nInference. Given a cascade Hof lengthN, i.e. an ordered collection of time\nstamps{ti}N\ni=1observed until some terminal time T\u2265tN, we can estimate\nthe parameters of the Hawkes process (\u00b5\u2217,\u03b1\u2217,\u0398\u2217)that generated the data by\nmaximizing the log-likelihood function,\nL(\u00b5,\u03b1,\u0398|H={tj}N\nj=1) =N/summationdisplay\nj=1log\u03bb(tj;\u00b5,\u03b1,\u0398)\u2212/integraldisplayT\n0\u03bb(s;\u00b5,\u03b1,\u0398)ds.(1)\nThis approach can be extended to the case of a collection of cascades H=\n{Hi}, where the best-\ufb01tting Hawkes process is obtained by maximizing the sum\nof the log-likelihood functions,\nL(\u00b5,\u03b1,\u0398|H) =/summationdisplay\nHi\u2208HL(\u00b5,\u03b1,\u0398|Hi). (2)\nPrediction. The \ufb01tted Hawkes process can be leveraged to predict the cascade\nsize \u02c6Nof a new cascade H\u2208H:\n\u02c6N=E[N|\u03b1] =1\n1\u2212\u03b1. (3)\n1.2 Dual Mixture Model\nInference. Giventhepre-de\ufb01nednumberofcomponents K,weobtaintheBorel\nmixture model MBby maximizing the following log-likelihood function,\nLBMM =/summationdisplay\nHi\u2208HlogK/summationdisplay\nk=1pB\nkB(Ni|\u03b1\u2217\nk). (4)\n2 P. Calderon and M.A. Rizoiu\nNote that the DMM is not formulated as a Bayesian model in [2] and the\nExpectation-Maximization (EM) algorithm [4] is employed to maximize LBMM.\nSimilarly, the kernel mixture model Mgis obtained by applying the EM algo-\nrithm to the kernel log-likelihood\nLKMM =/summationdisplay\nHi\u2208HlogK/summationdisplay\nk=1pg\nkfg(Hi|\u0398\u2217\nk), (5)\nwheref(Hi|\u0398) =/producttext\ntj\u2208Hi/summationtext\ntz<tjg(tj\u2212tz|\u0398).\nCold Start Popularity Prediction. Assume that we are given a collection\nof related cascade groups {Ha}a\u2208A. For instance, suppose Ais a set of news\narticles from a common online publisher \u03c1andHais the set of retweet cascades\ndiscussing article a. Give a yet-to-be-published article a\u2217/negationslash\u2208A, we wish to model\nits popularity \u02c6Na\u2217by learning from historical data {Ha}a\u2208A.\nTodothis,wecanconstructapublisher-levelpopularitymodel MB\n\u03c1by\ufb01tting\nanindependentBMM MB\na(withKaclasses)toeach Haandthencollectingthese\nas a mixture MB\n\u03c1overA, i.e.,\nMB\n\u03c1=/uniondisplay\na\u2208AMB\na=/uniondisplay\na\u2208A/braceleftBigg/parenleftBigg\n\u03b1a\n1,pB,a\n1\n|A|/parenrightBigg\n,...,/parenleftBigg\n\u03b1a\nKa,pB,a\nKa\n|A|/parenrightBigg/bracerightBigg\n,(6)\nwhere (\u03b1a\ni,pB,a\ni)\u2208MB\na. We can estimate the cold-start popularity of a new\narticlea\u2217as\n\u02c6Na\u2217=\u02c6C\u03c1\u00b7EMB\u03c1/bracketleftbigg1\n1\u2212\u03b1/bracketrightbigg\n=\u02c6C\u03c1\u00b7/summationdisplay\na\u2208AKa/summationdisplay\ni=11\n1\u2212\u03b1a\ni\u00b7pB,a\ni\n|A|, (7)\nwhere \u02c6C\u03c1is an estimate of the cascade count of article a\u2217, which we can take as\nthe average cascade count of articles in A.\n1.3 Bayesian Hierarchical Modeling\nLet\u03b8be a parameter set of a generative process PandDbe a sample from P.\nBayesian inference involves (1) quanti\ufb01ng our prior belief on \u03b8through a prior\ndistribution P(\u03b8), which could be uninformative or based on expert opinion, and\nthen (2) updating P(\u03b8)using the dataD, with the likelihood function L(D|\u03b8)\nserving as our weight on \u03b8. Our result is the posterior distribution P(\u03b8|D), which\ncombines our beliefs on \u03b8based on our prior and the data:\nP(\u03b8|D)\u221dL(D|\u03b8)\u00b7P(\u03b8). (8)\nOne advantage of Bayesian inference is its ability to accommodate the hi-\nerarchical structure of our dataset. For example, suppose that we have Ndata\npoints{xi}which are sampled from some generative model P(\u03b8). Additionally,\nSupplementary Material: Bayesian Mixture Hawkes 3\nwe are given information that each data point belong to one of mrelated groups.\nWe can handle this information in three ways.\nFirst, we ignore it and assume that all groups are drawn from the same\ngenerative model, i.e. xi\u223cP(\u03b8). This approach ignores variability across groups.\nSecond, we assume that the groups are independent from one another and\n\ufb01t a separate \u03b8jfor each group, i.e. xi\u223cP(\u03b8j). This approach ignores the fact\nthat the groups are related.\nThe third approach, Bayesian hierarchical modeling, o\ufb00ers a compromise\nbetween these two by allowing variation across groups. Here, we assume that\neach group jhas its own \u03b8jparameter, and xj[i]\u223cP(\u03b8j),wherej[i]is read as\n\u2018the group data point ibelongs to\u2019. We assume that {\u03b8j}are not independent\nbut are samples from a group-level distribution Qparametrized by a group-\nlevel parameter \u03b8group, i.e.\u03b8j\u223cQ(\u03b8group ). Under this hierarchical framework,\nQ(\u03b8group )acts a prior for each parameter \u03b8j. Specifying a prior distribution\nfor\u03b8groupcompletes the Bayesian hierarchical model. Our posterior is a joint\ndistributionovereachgroup\u2019sparameter \u03b8jandthegroup-levelparameter \u03b8group.\n2 Additional Material for Main Text Section 3\n2.1 Complete Table of Notation\nIn Table 1 we show the full set of notation, BMH model parameters, their inter-\npretation and real-world mapping.\n2.2 BMH-P Model\nAssumptions. In Main Text Eqs. (2) and (3) we assume that the item-level\nfeatures/vector yain\ufb02uence the location (i.e. mean) and membership probability of each\npopularity class k, while the cascade-level features /vector xacin\ufb02uence only the mem-\nbership probability. As a concrete example, if we have two popularity classes\n(popular and unpopular), Abeing a set of articles, /vector yabeing the headline em-\nbedding vector of article a, and/vector xacthe follower count of the initiator of cascade\nc, our assumptions imply how large a cascade will turn out to be (Main Text\nEq. (2)) is in\ufb02uenced only by article content /vector ya, but whether a cascade will be\npopular or not is in\ufb02uenced by both article content /vector yaand follower count /vector xac.\n4 P. Calderon and M.A. Rizoiu\nLikelihood Function. The log-likelihood of P\u03b1given the set of cascade sizes\n{Nac}accan be derived as:\nL(P\u03b1|{Nac}ac) = log P({Nac}ac|P\u03b1)\n= log/productdisplay\na\u2208A/productdisplay\nHac\u2208HaP(Nac|P\u03b1)\n= log/productdisplay\na\u2208A/productdisplay\nHac\u2208HaP(Nac|\u03b1ac)\n(a)= log/productdisplay\na\u2208A/productdisplay\nHac\u2208HaB(Nac|\u03b1ac)\n(b)= log/productdisplay\na\u2208A/productdisplay\nHac\u2208HaK\u03b1/summationdisplay\nk=1zac\n\u03b1,k\u00b7B(Nac|inv-logit (\u03b4a\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya))\n=/summationdisplay\nHac\u2208Ha,a\u2208AlogK\u03b1/summationdisplay\nk=1zac\n\u03b1,k\u00b7B(Nac|inv-logit (\u03b4a\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya)),\nwhere in (a) we use the fact that the cascade size of a Hawkes process is Borel-\ndistributed with parameter \u03b1acand in (b) we note that the BMH-P model\nspeci\ufb01esaacas a mixture over the K\u03b1classes, weighted by the membership\nprobabilities{zac\n\u03b1,k}.\nCold-Start Popularity. First, from our dataset A, compute \u02c6C\u03c1as the average\ncascade count for an article in Aand \u02c6f\u03c1(/vector xac|/vector ya)as the empirical probability\ndensity of the cascade feature vector /vector xacgiven item feature vector /vector ya.\nSecond, from Main Text Eq. (4) we draw the parameter set /vector pa\u2217\n\u03b1for the out-\nof-sample item a\u2217. Consider an arbitrary cascade cof itema\u2217with feature vec-\ntor/vector xa\u2217c. The expected cascade size of cis given by the expectation of Main\nText Eq. (2) over the K\u03b1popularity classes Eza\u2217c\n\u03b1,k[E[Na\u2217c]|/vector xa\u2217c,/vector ya\u2217]. Sincec\nis arbitrary, we need to average /vector xa\u2217cout. Hence, our expected cascade size is\nE/vector xa\u2217cEza\u2217c\n\u03b1,k/bracketleftbig\nE[Na\u2217c]|/vector xa\u2217c,/vector ya\u2217/bracketrightbig\n. Our estimate \u02c6Na\u2217of itema\u2217\u2019s popularity is then\nSupplementary Material: Bayesian Mixture Hawkes 5\ngiven by\n\u02c6Na\u2217=\u02c6C\u03c1\u00b7E/vector xa\u2217cEza\u2217c\n\u03b1,k/bracketleftBig\nE[Na\u2217c]|/vector xa\u2217c,/vector ya\u2217/bracketrightBig\n=\u02c6C\u03c1\u00b7E/vector xa\u2217cEza\u2217c\n\u03b1,k/bracketleftBigg\n1\n1\u2212\u03b1a\u2217c/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vector xa\u2217c,/vector ya\u2217/bracketrightBigg\n(a)=\u02c6C\u03c1\u00b7E/vector xa\u2217cK\u03b1/summationdisplay\nk=1za\u2217,c\n\u03b1,k\u00b71\n1\u2212inv-logit/parenleftBig\n\u03b4a\u2217\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya\u2217/parenrightBig\n=\u02c6C\u03c1\u00b7E/vector xa\u2217cK\u03b1/summationdisplay\nk=1za\u2217,c\n\u03b1,k\u00b7/bracketleftBig\n1 +exp/parenleftBig\n\u03b4a\u2217\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya\u2217/parenrightBig/bracketrightBig\n(b)=\u02c6C\u03c1\u00b7/integraldisplayK\u03b1/summationdisplay\nk=1za\u2217,c\n\u03b1,k\u00b7/bracketleftBig\n1 +exp/parenleftBig\n\u03b4a\u2217\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya\u2217/parenrightBig/bracketrightBig\n\u00b7f\u03c1(/vector xa\u2217c|/vector ya\u2217)\u00b7d/vector xa\u2217c\n(c)\u2248\u02c6C\u03c1\u00b7/integraldisplayK\u03b1/summationdisplay\nk=1za\u2217,c\n\u03b1,k\u00b7/bracketleftBig\n1 +exp/parenleftBig\n\u03b4a\u2217\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya\u2217/parenrightBig/bracketrightBig\n\u00b7\u02c6f\u03c1(/vector xa\u2217c)\u00b7d/vector xa\u2217c,\nwhere in (a) we use the fact that the BMH-P model speci\ufb01es aacas a mixture\nover theK\u03b1classes, weighted by the membership probabilities {zac\n\u03b1,k}, in (b) we\nmarginalize over the unobserved cascade-level features /vector xa\u2217cin a cold-start setup,\nand in (c) we use the simpli\ufb01cation f\u03c1(/vector xac|/vector ya)\u2248\u02c6f\u03c1(x)as detailed in the main\ntext.\nTo simplify this expression, we impose two additional assumptions on the\nfeature vectors. First, assume our cascade feature vector is one-dimensional,\ndiscrete and nonnegative (for instance, this may be the follower count of the\nseed user). This simpli\ufb01es our probability density \u02c6f\u03c1(/vector xac|/vector ya)into a probability\nmass function over x\u2208N\u222a{0}, converting the integral over /vector xacinto a sum.\nSecond, in practice we usually will not have enough variance across /vector yato build\n\u02c6f\u03c1(/vector xac|/vector ya)reliably, and so we assume that /vector xacis independent of /vector ya. These two\nassumptions allow us to write \u02c6f\u03c1(/vector xac|/vector ya)\u2248\u02c6f\u03c1(x). Our expression simpli\ufb01es to\n\u02c6Na\u2217\u2248\u02c6C\u03c1\u00b7\u221e/summationdisplay\nx=0K\u03b1/summationdisplay\nk=1za\u2217,c\n\u03b1,k\u00b7/bracketleftBig\n1 +exp/parenleftBig\n\u03b4a\u2217\n\u03b1,k+/vector \u03b3\u03b1,k\u00b7/vector ya\u2217/parenrightBig/bracketrightBig\n\u00b7\u02c6f\u03c1(x),(9)\n2.3 BMH-K Model\nAssumptions. In Main Text Eqs. (6) and (7), we assume that the item-level\nfeatures/vector yain\ufb02uence the location of \u03b8acand notdac. We found that including\nin\ufb02uence of item-level features /vector yaon both parameters leads to identi\ufb01ability\nissues in the BMH-K model. We assume /vector yain\ufb02uence the location (i.e. mean)\nand membership probability of each popularity class k, while the cascade-level\nfeatures/vector xacin\ufb02uence only the membership probability. As a concrete example,\nif we have two kernel classes (slow and fast), Abeing a set of articles, /vector yabeing\n6 P. Calderon and M.A. Rizoiu\nthe headline embedding vector of article a, and/vector xacthe follower count of the\ninitiator of cascade c, our assumptions imply the speed at which a cascade will\ndi\ufb00use (Main Text Eq. (6)) is in\ufb02uenced only by article content /vector ya, but whether\na cascade will be slow or fast is in\ufb02uenced by both article content /vector yaand follower\ncount/vector xac.\nLikelihoodFunction. Thelog-likelihoodof P\u0398giventhesetofinterevent-time\ndistributions{Tac}acis\nL(P\u0398|{Tac}ac) = log P({Tac}ac|P\u0398)\n(a)= log/productdisplay\nHac\u2208Ha,a\u2208A\uf8ee\n\uf8f0/productdisplay\ntj\u2208Hac,j\u22651/summationdisplay\ntz<tjg(tj\u2212tz|\u03b8ac,dac)\uf8f9\n\uf8fb\n(b)= log/productdisplay\nHac\u2208Ha,a\u2208Af(Hac|\u03b8ac,dac)\n(c)= log/productdisplay\nHac\u2208Ha,a\u2208A/bracketleftBiggK\u0398/summationdisplay\nk=1zac\n\u0398,k\u00b7f(Hac|e\u03b4a\n\u03b8,k+/vector \u03b3\u03b8,k\u00b7/vector ya,e\u03b4a\nd,k)/bracketrightBigg\n=/summationdisplay\nHac\u2208Ha,a\u2208AlogK\u0398/summationdisplay\nk=1zac\n\u0398,k\u00b7f(Hac|e\u03b4a\n\u03b8,k+/vector \u03b3\u03b8,k\u00b7/vector ya,e\u03b4a\nd,k),\nwhere in (a) we make use of the likelihood for the interevent-time distribu-\ntion for separable Hawkes processes as derived in [2], in (b) we set f(H|\u03b8,d) =/producttext\ntj\u2208H/summationtext\ntz<tjg(tj\u2212tz|\u03b8,d), and in (c) we use the fact that the BMH-K model\nspeci\ufb01es\u0398acas a mixture over the K\u0398classes, weighted by the membership\nprobabilities{zac\n\u0398,k}.\nHalf-Life Prediction. Under the BMH-K model, the half-life of an out-of-\nsample item a\u2217can be expressed as\n\u02c6\u03c4a\u2217\n1/2=E/vector xa\u2217cEza\u2217c\n\u0398,k/bracketleftBig\n\u03c4a\u2217\n1/2|/vector xa\u2217c,/vector ya\u2217/bracketrightBig\n(a)=E/vector xa\u2217cEza\u2217c\n\u0398,k/bracketleftBig\nda\u2217c\u00b7(2\u03b8a\u2217c\u22121)|/vector xa\u2217c,/vector ya\u2217/bracketrightBig\n(b)=E/vector xa\u2217cK\u0398/summationdisplay\nk=1za\u2217,c\n\u0398,k\u00b7e\u03b4a\u2217\nd,k\u00b7/bracketleftBig\n2exp (\u03b4a\u2217\n\u03b8,k+/vector \u03b3\u03b8,k\u00b7/vector ya\u2217)\u22121/bracketrightBig\n(c)\u2248\u221e/summationdisplay\nx=0K\u0398/summationdisplay\nk=1za\u2217,c\n\u0398,k\u00b7e\u03b4a\u2217\nd,k\u00b7/bracketleftBig\n2exp (\u03b4a\u2217\n\u03b8,k+/vector \u03b3\u03b8,k\u00b7/vector ya\u2217)\u22121/bracketrightBig\n\u00b7\u02c6f\u03c1(x),\nwhere in (a) we use the expression for the half-life of a Hawkes process under the\npower lawg(t) =\u03b8\u00b7d\u03b8\u00b7(t+d)\u2212(1+\u03b8)(i.e. by solving \u03c41/2such that/integraltext\u03c41/2\n0g(t)dt=\n1\n2), in (b) we use the fact that the BMH-K model speci\ufb01es \u0398acas a mixture\nSupplementary Material: Bayesian Mixture Hawkes 7\n10.0\n7.5\n5.0\n2.5\n0.0\n2.5\n5.0\n7.5\nlogit alpha\n0.00\n0.05\n0.10\n0.15\n0.20\nFig.1: Distribution of DMM-estimated logit (\u03b1)acrossRNIXpublishers. We\nnote the bimodality of the distribution, with the modes corresponding to low\nand high cascade sizes. Based on this observation we set K\u03b1= 2for the BMH-P\nmodel.\nover theK\u0398classes, weighted by the membership probabilities {zac\n\u0398,k}, and in\n(c) we marginalize over the unobserved cascade-level features /vector xa\u2217cand use the\nsimpli\ufb01cation f\u03c1(/vector xac|/vector ya)\u2248\u02c6f\u03c1(x)as detailed in the main text.\n3 Additional Material for Main Text Section 4\n3.1 Selection of K\u03b1andK\u0398\nTo guide the selection of the number of mixture components for the BMH-P (i.e.\nK\u03b1) and BMH-K (i.e. K\u0398)models in Main Text Section 4, we \ufb01t the DMM [2]\nto each publisher in RNIX. Given that the EM algorithm is very sensitive to\ninitial conditions, we use 10 random EM initializations and select the output\nthat yields the highest log-likelihood.\nWe collect the distribution of parameter estimates for logit (\u03b1)across pub-\nlishers in Fig. 1. We see two modes for \u03b1, corresponding to cascade groups with\nlow and high sizes, prompting us to set K\u03b1= 2in Main Text Section 4.\nWe collect the distribution of parameter estimates for (log(c),log(\u03b8))across\npublishers in the upper plot of Fig. 2, where we see three modes for the kernel\nparameters. From the lower plot of Fig. 2, we can interpret these modes as\nbelonging to usual, fast and slow cascade groups, prompting us to set K\u0398= 3\nin Main Text Section 4.\n3.2 Prior Speci\ufb01cation for the BMH-P Model\nThe full set of priors for the BMH-P model implementation is given below. Infor-\nmative priors are set for \u03b4\u03b1,1,\u03b4\u03b1,2,\u03b4z\u03b1,2based on the observations in Section 3.1.\n8 P. Calderon and M.A. Rizoiu\n2\n0\n2\n4\n6\nlog theta\n6\n4\n2\n0\n2\n4\n6\n8log c\n12\n3\n(a)\n0.0 0.2 0.4 0.6 0.8 1.0\nt0.00.20.40.60.81.0g(t)\nClass 1 Class 2 Class 30.00.10.20.30.40.50.60.7percentage of cascades (b)\nFig.2:(a) Distribution of DMM-estimated (log(c),log(\u03b8))acrossRNIXpublish-\ners.Weobservethetrimodalityofthedistribution,withthemodescorresponding\nto usual (labeled 1), slow (labeled 2) and fast (labeled 3) cascades. Based on this\nobservation we set K\u0398= 3for the BMH-K model. (b) In the top plot, we show\nsamples of the power law kernel gfor the three classes. In the bottom plot, we\nshow the distribution of cascades for each class.\nWeakly informative priors are set for the other parameters. We use a Laplace\nprior on/vector \u03b3\u03b1,1,/vector \u03b3\u03b1,2,/vector \u03b3z\u03b1,2to impose regularization given the high dimensionality\nof the article feature vector ( |/vector ya|= 32) we consider.\n\u03b4\u03b1,1\u223cN(\u22122,0.5)\n\u03b4\u03b1,2\u223cN(2,0.5)\n\u03b4z\u03b1,2\u223cN(\u22121.39,0.5)\n/vector\u03b2z\u03b1,2\u223cN(0,0.1)\n/vector \u03b3\u03b1,1,/vector \u03b3\u03b1,2,/vector \u03b3z\u03b1,2\u223cLaplace (0,0.01)\n\u2126\u03b1\u223cLKJCorr (2)\n\u03c3\u03b4\u03b1,1,\u03c3\u03b4\u03b1,2,\u03c3\u03b4z\u03b1,2\u223cN(0,1)\n\u03c3/vector\u03b2z\u03b1,2\u223cN(0,0.1)\n3.3 Prior Speci\ufb01cation for the BMH-K Model\nThe full set of priors for the BMH-K model implementation is given below.\nInformative priors are set for \u03b4\u03b8,1,\u03b4d,1,\u03b4\u03b8,2,\u03b4d,2,\u03b4\u03b8,3,\u03b4d,3,\u03b4z\u0398,2,\u03b4z\u0398,3based on\nSupplementary Material: Bayesian Mixture Hawkes 9\nthe observations in Section 3.1. Weakly informative priors are set for the other\nparameters. We use a Laplace prior on /vector \u03b3\u0398,2,/vector \u03b3\u0398,3,/vector \u03b3z\u0398,2,/vector \u03b3z\u0398,3to impose regular-\nization given the high dimensionality of the article feature vector ( |/vector ya|= 32) we\nconsider. For \u2126\u0398,1,\u2126\u0398,2,\u2126\u0398,3, we set a LKJCorr (0.5)prior (i.e. higher weights\non the tails of [0,1]) as (\u03b8,d)for any given Hawkes \ufb01t are correlated.\n\u03b4\u03b8,1\u223cN(\u22120.41,0.5)\n\u03b4d,1\u223cN(\u22121.37,1)\n\u03b4\u03b8,2\u223cN(4,0.5)\n\u03b4d,2\u223cN(4.805,0.5)\n\u03b4\u03b8,3\u223cN(4,0.5)\n\u03b4d,3\u223cN(1,0.5)\n\u03b4z\u0398,2,\u03b4z\u0398,3\u223cN(\u22122,1)\n/vector\u03b2z\u0398,2,/vector\u03b2z\u0398,3\u223cN(0,0.1)\n/vector \u03b3\u0398,2,/vector \u03b3\u0398,3,/vector \u03b3z\u0398,2,/vector \u03b3z\u0398,3\u223cLaplace (0,0.01)\n\u2126\u0398,1,\u2126\u0398,2,\u2126\u0398,3\u223cLKJCorr (0.5)\n\u2126z\u0398\u223cLKJCorr (2)\n\u03c3\u03b4\u03b8,1,\u03c3\u03b4\u03b8,2,\u03c3\u03b4\u03b8,3,\u03c3\u03b4d,1,\u03c3\u03b4d,2,\u03c3\u03b4d,3,\u03c3\u03b4z\u0398,2,\u03c3\u03b4z\u0398,3\u223cN(0,1)\n\u03c3/vector\u03b2z\u0398,2,\u03c3/vector\u03b2z\u0398,3\u223cN(0,0.1)\n3.4 Implementation Details.\nWeusethePythonimplementationofStan[1]torunboththeBMH-PandBMH-\nK models. We run for 4 chains, adapt delta set to 0.9, 500 warmup iterations\nand 500 post-warmup iterations. To speed up convergence we implement non-\ncentered parametrization [3] for each of the normally distributed priors.\n4 Additional Material for Main Text Section 5\n4.1 Performance Heatmaps for CNIX and RNIX\nWe show performance heatmaps for a selection of CNIX publishers in Fig. 3\nand RNIX publishers in Fig. 4. Note the di\ufb00erent patterns of which headline\nstyle works for each publisher, implying that the BMH model picks up subtle\ndi\ufb00erences of what is e\ufb00ective across publishers.\nReferences\n1. Carpenter, B., Gelman, A., Ho\ufb00man, M.D., Lee, D., Goodrich, B., Betancourt,\nM., Brubaker, M., Guo, J., Li, P., Riddell, A.: Stan: A probabilistic programming\nlanguage. Journal of statistical software 76(1) (2017)\n10 P. Calderon and M.A. Rizoiu\n2. Kong, Q., Rizoiu, M.A., Xie, L.: Describing and predicting online items with reshare\ncascades via dual mixture self-exciting processes. In: Proceedings of the 29th ACM\nInternational Conference on Information & Knowledge Management. pp. 645\u2013654\n(2020)\n3. Papaspiliopoulos, O., Roberts, G.O., Sk\u00f6ld, M.: A general framework for the\nparametrization of hierarchical models. Statistical Science pp. 59\u201373 (2007)\n4. Tomasi, C.: Estimating gaussian mixture densities with em\u2013a tutorial. Duke Uni-\nversity pp. 1\u20138 (2004)\nSupplementary Material: Bayesian Mixture Hawkes 11\nTable 1: Table of Notation.\nParameter Interpretation Real-World Mapping\nSource-Level\n\u03c1source of items news publisher\nA set of items produced by \u03c1 news articles from publisher \u03c1\nf\u03c1(\u00b7)follower count distribution\n\u02c6C\u03c1cascade count estimate\nItem-Level\na\u2208A item produced by \u03c1 news article\nHaset of cascades related to item aretweet cascades for article a\n/vector yaitem-level features headline embedding for article a\nNaitem popularity overall tweet count for article a\n\u03c4a\n1/2content half-life\nCascade-Level\nHac\u2208Hacascade related to item a retweet cascade for article a\n/vector xaccascade-level features follower count of seed user\nNaccascade size\n\u03c4ac\n1/2cascade half-life\nTacintereevent-time distribution\n\u03b1acHawkes branching factor\n\u0398acHawkes kernel parameters\nBMH-P\nK\u03b1# of BMH-P mixture classes\n/vector \u03b3\u03b1,k e\ufb00ect of/vector yaon center of class k\n/vector \u03b3z\u03b1,ke\ufb00ect of/vector yaon membership proba-\nbility of class k\n\u03b4a\n\u03b1,k/\u03b4\u03b1,kitem-/ publisher-level baseline\nvalue of logit (\u03b1)for classk\n/vector\u03b2a\n\u03b1,k//vector\u03b2\u03b1,ke\ufb00ect of/vector xacon center of class k\nzac\n\u03b1,k mem. probability for class k\n\u03b4a\nz\u03b1,k/\u03b4z\u03b1,kitem-/ publisher-level mem. prob.\nsoftmax baseline for class k\n/vector\u03b2a\nz\u03b1,k//vector\u03b2z\u03b1,ke\ufb00ect of/vector xacon membership proba-\nbility for class k\n/vector pa\n\u03b1//vector p\u03b1item-/ pub.-level parameter vector\n\u03a3\u03b1/\u2126\u03b1cov./ corr. matrix for /vector p\u03b1\nBMH-K\nK\u0398# of BMH-K mixture classes\n/vector \u03b3\u03b8,ke\ufb00ect of/vector yaon center of class k\n/vector \u03b3z\u0398,ke\ufb00ect of/vector yaon membership proba-\nbility of class k\n\u03b4a\n\u03b8,k/\u03b4\u03b8,kitem-/ publisher-level baseline\nvalue of log (\u03b8)for classk\n/vector\u03b2a\n\u03b8,k//vector\u03b2\u03b8,ke\ufb00ect of/vector xacon center of class k\nzac\n\u0398,kmem. probability for class k\n\u03b4a\nz\u0398,k/\u03b4z\u0398,kitem-/ publisher-level mem. prob.\nsoftmax baseline for class k\n/vector\u03b2a\nz\u0398,k//vector\u03b2z\u0398,ke\ufb00ect of/vector xacon membership proba-\nbility for class k\n/vector pa\n\u0398,k//vector p\u0398,kitem-/ pub.-level kernel parameter\nbaseline values for class k\n/vector pa\nz\u0398//vector pz\u0398item-/ pub.-level membership\nprobability parameters for class k\n\u03a3\u0398,k/\u2126\u0398,kcov./ corr. matrix for /vector p\u0398,k\n\u03a3z\u0398/\u2126z\u0398cov./ corr. matrix for /vector pz\u0398\n12 P. Calderon and M.A. Rizoiu\n1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0\nlog cascade size2.5\n2.0\n1.5\n1.0\n0.5\n0.0log halflifeneutral\nclickbait\ninflammatorythefreethoughtproject.com\n(a)\n0.9 1.0 1.1 1.2 1.3 1.4\nlog cascade size3\n2\n1\n012log halflifeneutral\nclickbait\ninflammatoryempirenews.net (b)\n0.6 0.8 1.0 1.2 1.4\nlog cascade size3.0\n2.5\n2.0\n1.5\n1.0\n0.5\nlog halflifeneutral\nclickbait\ninflammatoryreact365.com\n(c)\n1.8 2.0 2.2 2.4 2.6 2.8 3.0\nlog cascade size3\n2\n1\n012log halflifeneutral\nclickbait\ninflammatoryglobalresearch.ca (d)\n1.2 1.3 1.4 1.5 1.6 1.7\nlog cascade size3.0\n2.5\n2.0\n1.5\n1.0\n0.5\nlog halflifeneutral\nclickbait\ninflammatorycollective-evolution.com\n(e)\n3.15 3.20 3.25 3.30 3.35 3.40\nlog cascade size200\n0200400600800log halflifeneutral\nclickbait\ninflammatoryduffelblog.com (f)\nFig.3: Peformance heatmaps for a selection of CNIX publishers.\nSupplementary Material: Bayesian Mixture Hawkes 13\n1.7 1.8 1.9 2.0 2.1 2.2\nlog cascade size1.4\n1.3\n1.2\n1.1\n1.0\n0.9\nlog halflifeneutral\nclickbait\ninflammatorytheage.com.au\n(a)\n2.0 2.1 2.2 2.3 2.4 2.5\nlog cascade size1.4\n1.3\n1.2\n1.1\n1.0\n0.9\n0.8\n0.7\nlog halflifeneutral\nclickbait\ninflammatorycrikey.com.au (b)\n2.05 2.10 2.15 2.20 2.25 2.30 2.35\nlog cascade size1.1\n1.0\n0.9\n0.8\n0.7\n0.6\n0.5\nlog halflifeneutral\nclickbait\ninflammatorythewest.com.au\n(c)\n2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8\nlog cascade size1.6\n1.4\n1.2\n1.0\n0.8\n0.6\n0.4\n0.2\nlog halflifeneutral\nclickbait\ninflammatoryafr.com (d)\n1.8 1.9 2.0 2.1\nlog cascade size1.0\n0.8\n0.6\n0.4\n0.2\nlog halflifeneutral\nclickbait\ninflammatorytheaustralian.com.au\n(e)\n2.35 2.40 2.45 2.50 2.55 2.60 2.65 2.70\nlog cascade size1.3\n1.2\n1.1\n1.0\n0.9\n0.8\nlog halflifeneutral\nclickbait\ninflammatoryskynews.com.au (f)\nFig.4: Peformance heatmaps for a selection of RNIX publishers.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "What Drives Online Popularity: Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes", "author": ["P Calderon", "MA Rizoiu"], "pub_year": "2024", "venue": "Joint European Conference on Machine Learning \u2026", "abstract": "The spread of content on social media is shaped by intertwining factors on three levels: the  source, the content itself, and the pathways of content spread. At the lowest level, the"}, "filled": false, "gsrank": 749, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-70362-1_9", "author_id": ["AE596-UAAAAJ", "J9sjxXYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:aueqmnJVkD4J:scholar.google.com/&output=cite&scirp=748&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=aueqmnJVkD4J&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:aueqmnJVkD4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2406.03390"}}, {"title": "What Makes A Video Radicalizing? Identifying Sources of Influence in QAnon Videos", "year": "2024", "pdf_data": "What Makes A Video Radicalizing? Identifying Sources of Influence in\nQAnon Videos\nLin Ai1, Yu-Wen Chen1, Yuwen Yu2, Seoyoung Kweon1,\nJulia Hirschberg1, Sarah Ita Levitan2\n1Columbia University,2Hunter College\n{lin.ai, julia}@cs.columbia.edu, {yc4093, sk4865}@columbia.edu\nyyu4@gradcenter.cuny.edu, sarah.levitan@hunter.cuny.edu\nAbstract\nIn recent years, radicalization is being increas-\ningly attempted on video-sharing platforms.\nPrevious studies have been proposed to iden-\ntify online radicalization using generic social\ncontext analysis, without taking into account\ncomprehensive viewer traits and how those can\naffect viewers\u2019 perception of radicalizing con-\ntent. To address the challenge, we examine\nQAnon, a conspiracy-based radicalizing group,\nand have designed a comprehensive question-\nnaire aiming to understand viewers\u2019 percep-\ntions of QAnon videos. We outline the traits\nof viewers that QAnon videos are the most ap-\npealing to, and identify influential factors that\nimpact viewers\u2019 perception of the videos.\n1 Introduction\nRadicalization, the process of developing extremist\nideologies and beliefs in others, has been increas-\ningly seen on social media in recent years. Previous\nstudies have proposed to identify online radicaliza-\ntion using lexical and social context analysis. How-\never, much of the current radicalization is being\nattempted on video-sharing platforms, where mul-\ntimodality features beyond text can be powerful\nin the promotion of extremist content. Moreover,\ngeneric social context analysis does not take into\naccount comprehensive viewer traits and how those\ncan affect viewers\u2019 perception of radicalizing con-\ntent. To address these challenges, we focus on\nradicalization in YouTube and BitChute. We exam-\nine QAnon, a conspiracy-based radicalizing group\noriginated in 2017. We have collected a QAnon\nvideo corpus from YouTube and BitChute, and have\ndesigned a comprehensive questionnaire aiming to\nidentify traits of viewers that QAnon videos are\nthe most appealing to, influential factors that con-\ntribute to viewers\u2019 perception, and how these traits\ndiffer between pro- and anti-QAnon videos. To the\nbest of our knowledge, this is the first work aiming\nto computationally analyze viewers\u2019 perception of\nQAnon video.In this study, we focus on three main research\nquestions: RQ1: What viewer traits, such as per-\nsonality traits and media consumption, are asso-\nciated with their video preferences? RQ2: What\nvideo characteristics, such as speaker traits, video\nquality, and arousing emotions, are correlated with\nviewers\u2019 perception? RQ3: Which modality fea-\ntures affect viewers\u2019 perception the most?\n2 Related Work\nMuch work has been done on radicalization in so-\ncial media. Hartung et al. (2017) attempt to iden-\ntify right-wing extremist content in German Twitter\nprofiles; Hofmann et al. (2022) leverage network\nstructure of Reddit forums to detect polarized con-\ncepts; and L\u00f3pez-S\u00e1ncez et al. (2018) and Araque\nand Iglesias (2020) develop methods to identify\nradicalizing content in Twitter. Research has also\nbeen done using multimodal features to detect rad-\nicalization in Jihadist YouTube videos using so-\ncial network analysis and sentiment (Bermingham\net al., 2009). Ribeiro et al. (2020) collect 330,925\nYouTube videos to identify radicalizing pipelines\nfor far-right groups, and Ai et al. (2021) identify\nmultimodal features of far-right and far-left groups\nwhich them more popular and more persuasive.\nIn recent years, QAnon has been identified as\none of the prime conspiracy-based radicalization\ngroups (Amarasingam and Argentino, 2020; Garry\net al., 2021). However, little study has computa-\ntionally analyzed QAnon related videos, in terms\nof how these videos drag viewers into the process\nof radicalization, and who the videos are the most\nappealing to. Therefore, in this work, we aim to\nidentify the viewers that are attracted the most to\nQAnon videos, and influential factors of the videos\nthat contribute the most to viewers\u2019 perception.\n3 Corpus and Annotation Collection\nWe have collected 5,924 YouTube and BitChute\nvideos on QAnon to study a full range of multi-arXiv:2404.14616v1  [cs.SI]  22 Apr 2024\nmodal characteristics of QAnon videos. We then\nselect a small subset of these videos, 3 pro- and 3\nanti-QAnon, based on the videos\u2019 relevance to the\ntopic, duration, diversity in styles, quality of con-\ntent, and popularity measured by number of likes,\ncomments and shares. To obtain human rating, we\ncreate a comprehensive questionnaire asking raters\nto explain aspects of their perception of the videos\nand of QAnon, and the actions they believe that\nthey or others might take after watching the videos.\nThe questionnaire is included in Appendix B.\n3.1 Rater Demographics and Background\nA total of 46 raters take part in the questionnaire.\nIn the beginning of the questionnaire, we ask raters\na few questions about their own demographics, in-\ncluding gender, age, ethnicity, level of education,\nand political leaning. See Table 25 in Appendix\nB for the full question set. The distribution of\nrater demographics is shown in Figure 1 in Ap-\npendix C. We also ask raters to provide personal-\nity information, as we are interested in learning\na comprehensive profile of viewers that would be\nattracted to either pro- or anti-QAnon videos. For\nthis, raters complete the Ten Item Personality In-\nventory (Gosling et al., 2003), that measures the\nBig Five personality dimensions: Neuroticism, Ex-\ntraversion, Openness to Experience, Agreeableness,\nand Conscientiousness. The responses are summa-\nrized in Figure 2 in Appendix C.\nTo study how individuals\u2019 perception of poten-\ntially radical videos may be affected by their ini-\ntial impression of extremist groups and the media\nthey consume, we ask raters to rate their opinions,\npositive, negative or neutral, of five well-known\nextremist groups, and how much they trust eight of\nthe mainstream media sources. The five extremist\ngroups include three far-right groups (QAnon, The\nProud Boys, Oath keepers) and two far-left groups\n(Antifa, the subset of BLM that involves in violent\nactions); and the eight media sources are Fox News,\nBreitbart News, MSNBC News, PBS News, Asso-\nciated Press News (AP), NPR, The Wall Street Jour-\nnal (WSJ), and CNN. The political bias of these\nmedia sources are obtained from Media Bias/Fact\nCheck (MBFC)1. The responses are summarized\nin Figure 3 and 4.\n1https://mediabiasfactcheck.com/3.2 Evaluation Metrics\nAs Borum (2011) argues, radicalization needs to\nbe distinguished from action pathways, the process\nof engaging in violent extremist actions, as most\npeople with radical ideas do not engage in violent\nactions or terrorism. Being curious about certain\nextremist groups, or even considering joining the\ngroups, are often the first steps in such action path-\nways. In this study, we generalize the concept\nof radicalization as the process of developing ex-\ntremist ideologies and taking the first steps in the\naction pathways towards violence. Therefore, to\nbetter assess the level of radicalization of a video,\nwe separately evaluate viewers\u2019 overall impression\ntowards the video, including whether they enjoy\nwatching the video in general, how they feel about\nthe content of the video, and the actions they think\nthey would take after watching the video. With this\npurpose, we use 3 metrics:\n1.Enjoyment Score: raters are asked to rate\nhow much they enjoy watching each video on\na 5-point Likert scale. The Enjoyment Scores\nare converted to [-2, 2].\n2.Content Score: raters are asked to say\nwhether they think a video is persuasive, trust-\nworthy, logical, and professionally created and\nthese rating scores are each converted to [-1,\n1]. Each video\u2019s Content Score is the sum of\nthese 4 traits\u2019 scores. High Content Scores\nimply that raters agree with the video content\nand think that it was was valid, trustworthy,\npersuasive, and logical.\n3.Actions Score: raters are asked whether they\nwould take the following actions after watch-\ning a video, listed from the most active gourp\nopposing actions to the most active group sup-\nporting actions: a)posting a criticizing com-\nment [score -2] b)disliking the video [score\n-1]c)liking the video [score 1] d)posting a\nsupporting comment [score 2] e)considering\njoining the group [score 3]. The Actions Score\nof a video is the sum of these actions\u2019 scores.\nThe higher the Actions Score, the more ac-\ntively the raters support the video, or even the\nQAnon ideology.\n4 Analyzing Viewer Ratings and Traits\nIn this and the following sections, we use the words\nrater and viewer interchangeably. To answer RQ1 ,\nwe investigate how viewers\u2019 self-reported person-\nalities, initial impression of extremist groups, and\ntheir media consumption correlate with their pref-\nerence for QAnon videos. We examine how these\ntraits correlate with the Enjoyment Scores, Content\nScores, and Actions Scores they give to all QAnon\nvideos as well as just to pro- or anti-QAnon videos.\nFor each metric score, we calculate a viewers\u2019 over-\nall score on all videos, pro-QAnon videos, and\nanti-QAnon videos as the average score they give\nto each video, to each pro-QAnon video, and to\neach anti-QAnon video.\nWe perform significance tests on the Spearman\u2019s\ncorrelation between these viewer traits and the\nthree metric scores. For our Enjoyment Score,\nthe significant viewer traits (p-value < 0.05) are\npresented in Table 1. Viewers having a positive\nopinion of Antifa and of The Proud Boys enjoy\nwatching all our QAnon videos in general. Par-\nticularly, viewers with a positive opinion towards\nAntifa enjoy watching anti-QAnon videos. This\nmatches our impression because The Proud Boys\nis also a far-right group, thus, viewers supporting\nThe Proud Boys enjoy watching QAnon videos\nin general; whereas Antifa is a left-wing group,\nthus, viewers supporting Antifa enjoy watching\nanti-QAnon videos. Viewers trusting CNN news\ntend to enjoy watching QAnon videos, especially,\nthe pro-QAnon videos, which is somewhat surpris-\ning since CNN is a left-biased media. One possi-\nble explanation could be that sometimes, people\nmight feel hilarious when perceiving information\nfrom the opposite side. Other viewers enjoying\nwatching pro-QAnon videos are those who trust\nthe WSJ, aligning with our assumption that right-\nleaning viewers would trust a right-center based\nsource.\nEnjoyment on All Videos\nFeature Corr p-value\nOpinion_CNN 0.358 0.0146\nOpinion_Antifa 0.345 0.0189\nOpinion_ProudBoys 0.297 0.0452\nEnjoyment on Pro-QAnon Videos\nFeature Corr p-value\nOpinion_CNN 0.329 0.0255\nOpinion_WSJ 0.298 0.0440\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\nOpinion_Antifa 0.368 0.0119\nTable 1: Significant viewer ratings and traits (p-value <\n0.05) on Enjoyment Scores\nFor our Content Score, the significant viewerratings and traits are listed in Table 2. Generally,\nviewers who trust Fox News agree with the content\nof our selected QAnon videos, specifically, pro-\nQAnon videos. This agrees with our presumption,\nas Fox News is rated as right-biased media. On\nthe other hand, viewers trusting NPR and AP tend\nto disagree with the content of pro-QAnon videos,\nwhich makes sense, since both media sources are\nleft-center biased. In addition, viewers who are\nself-reported as reserved and quiet tend to agree\nwith the content of anti-QAnon videos.\nContent of All Videos\nFeature Corr p-value\nOpinion_Fox 0.430 0.00283\nContent of Pro-QAnon Videos\nFeature Corr p-value\nOpinion_Fox 0.487 0.000592\nOpinion_NPR -0.376 0.0100\nOpinion_AP -0.330 0.0253\nContent of Anti-QAnon Videos\nFeature Corr p-value\nReserved 0.339 0.0213\nTable 2: Significant viewer traits and ratings (p-value <\n0.05) on Content Scores\nFor our Actions Score, the significant viewer\nratings and traits are listed in Table 3. As we\nexpect, viewers with positive opinions towards\nOath Keepers, Fox News, and WSJ tend to ac-\ntively support selected QAnon videos, especially\npro-QAnon videos, because Oath Keepers is con-\nsidered a far-right group, and Fox News and WSJ\nare both right leaning. Surprisingly, viewers with\npositive opinions towards Antifa and CNN also\ntend to support pro-QAnon videos. In addition,\nviewers self-reported as disorganized and careless\ntend to support anti-QAnon videos, and viewers\nself-reported as sympathetic and warm tend to op-\npose anti-QAnon videos.\n5 Analysis of Video Characteristics\nTo answer question RQ2 , the following informa-\ntion is collected from raters:\nOverall Impression: raters\u2019 overall impression\nof the videos, including whether they find them\nboring, lively, persuasive, trustworthy, logical, pro-\nfessionally created, and making a valid point (see\nQuestion 2, 8 and 15 in Table 26 and 27). Each\nresponse is converted into a score from [-1, 1].\nArousing Emotions: the emotions raters feel\nwhen watching the videos, including Ekman\u2019s 6\nemotions (Ekman and Friesen, 1971) and confused\nActions after All Videos\nFeature Corr p-value\nOpinion_OathKeepers 0.387 0.00793\nOpinion_Antifa 0.359 0.0143\nOpinion_Fox 0.350 0.0172\nOpinion_WSJ 0.322 0.0291\nActions after Pro-QAnon Videos\nFeature Corr p-value\nOpinion_OathKeepers 0.370 0.0114\nOpinion_Fox 0.358 0.0145\nOpinion_WSJ 0.346 0.0186\nOpinion_CNN 0.298 0.0442\nOpinion_Antifa 0.295 0.0467\nActions after Anti-QAnon Videos\nFeature Corr p-value\nDisorganized 0.318 0.0312\nSympathetic -0.317 0.0321\nTable 3: Significant viewer traits and ratings (p-value <\n0.05) on Actions Scores\n(see Question 12 in Table 27). Each emotion is\nscored 1 if selected present, and 0 otherwise.\nSpeaker Characteristics: the traits of the speak-\ners appearing in videos. We select a subset of\nspeaker traits used in (Yang et al., 2020) to de-\nfine the level of charisma of a speaker, including\ncharismatic, confident, eloquent, enthusiastic, intel-\nligent, convincing, tough, charming, and angry (see\nQuestion 10 in Table 27). Each rating is converted\ninto a score ranging [-1, 1].\nWe perform significance tests on the Pearson\u2019s\ncorrelation between the above traits and ratings and\nthe three metric scores. For our Enjoyment Score,\nthe significant results are listed in Table 4. For\npro-QAnon videos, those rated as more valid and\npersuasive are enjoyed more by viewers. However,\nno other significant traits are found to be associated\nwith the Enjoyment Score of anti-QAnon videos,\nor of all QAnon videos in general.\nEnjoyment on Pro-QAnon Videos\nFeature Corr p-value\nValidness 0.999 0.0234\nPersuasive 0.997 0.0452\nTable 4: Significant video traits and ratings (p-value <\n0.05) on the Enjoyment Scores\nSince the Content Score is a sum of persuasive,\ntrustworthy, logical, and professional scores, we ex-\nclude these 4 traits when performing another set of\ncorrelation significance tests on our Content Score.\nAs shown in Table 5, for anti-QAnon videos, if\nviewers feel disgusted or boredom when watching\nthem, they tend to disagree with the content. No\nother significant traits are found to be specifically\nassociated with the Content Score of pro-QAnonvideos, or all selected QAnon videos in general.\nContent of Anti-QAnon Videos\nFeature Corr p-value\nDisgust -0.998 0.0440\nBoring -0.998 0.0440\nTable 5: Significant video traits and ratings (p-value <\n0.05) on the Content Scores\nLooking at our Actions Scores, we find that\nviewer ratings that are positively correlated with\nsupporting actions are whether the videos are trust-\nworthy, persuasive, logical, and making a valid\npoint. Similarly, for anti-QAnon videos, viewers\nare also more likely to take supporting actions after\nwatching the videos if they think the videos are\ntrustworthy. On the other hand, if the speakers in\nthe videos are rated as enthusiastic, the viewers\nindicate that they are less likely to take supporting\nactions. For anti-QAnon videos, the liveliness of\nvideos is also negatively correlated with support-\ning activity. No significant traits are found to be\nassociated with the Actions Scores of pro-QAnon\nvideos.\nActions Likely after All Videos\nFeature Corr p-value\nTrustworthy 0.968 0.00150\nValidness 0.964 0.00191\nPersuasive 0.905 0.0131\nLogical 0.875 0.0225\nEnthusiastic -0.951 0.0486\nActions after Anti Videos\nFeature Corr p-value\nTrustworthy 1.00 0.0114\nLively -1.00 0.0167\nTable 6: Significant video ratings (p-value < 0.05) on\nthe Actions Scores\n6 Multimodal Feature Analysis\nTo answer RQ3 , we further analyze multimodal\nfeatures of these videos, including textual, acoustic,\nand visual features. We perform analysis on 2 lev-\nels:(1)inter-pausal unit (IPU) segment level; (2)\nwhole video level. We further perform significance\ntests on the Pearson\u2019s correlation between all the\nmultimodal features and the three metric scores on\nboth IPU segment level and video level. The com-\nplete lists of significant multimodal features are\nsummarized in Appendix A, and here we highlight\nsome of the key and interesting findings.\n6.1 Textual Features\nTo obtain textual features, we extract speech tran-\nscripts of these videos using the Google Speech-to-\nText service2. We then use Linguistic Inquiry and\nWord Count (LIWC) (Pennebaker et al., 2015) to\nextract lexico-semantic features, Grievance Dictio-\nnary (van der Vegt et al., 2021) to extract psycholin-\nguistic features, and V ADER (Hutto and Gilbert,\n2014) to extract textual sentiment scores.\nThe list of significant segment level textual fea-\ntures are summarized in Table 7, 8, and 9 in\nAppendix A.1.1. In general, lexicons related to\nfriends and gender are positively correlated with\nhow viewers perceive the videos, in terms of how\nthey enjoy watching the videos, agree with the\ncontent, and take active actions afterwards. Lexi-\ncons related to violence are negatively correlated\nwith how viewers enjoy watching the videos. For\npro-QAnon videos, lexicons related to violence,\nweapons, threat, power, and soldiers are signifi-\ncantly and negatively correlated with how viewers\nperceive the videos. These are when the topics\nsuch as war and crimes are being talked about.\nIn addition, V ADER sentiment is positively cor-\nrelated with with how viewers perceive the videos\nfor pro-QAnon videos. For anti-QAnon videos,\nlexicons related to friends are positively correlated\nwith viewer perception.\nOn video level, no significant lexical features\nstands out for pro-QAnon videos. For anti-QAnon\nvideos, or QAnon videos in general, lexicons re-\nlated to loneliness positively affect how viewers\nenjoy watching the videos. Viewers also tend to\nagree with the content more if lexicons related to\ngender and family are mentioned; and they tend to\ndisagree with the content if paranoia words such as\n\"crazy\" are mentioned. The complete list of signifi-\ncant video level textual features are summarized in\nTable 16, 17 and 18 in Appendix A.2.1.\n6.2 Acoustic Features\nWe extract acoustic-prosodic features, such as pitch\nand intensity, because they are proven to be relevant\nto how people express emotion (Sudhakar and Anil,\n2015), and attempt to be persuasive (Nguyen et al.,\n2021) and charismatic (Yang et al., 2020). We also\nextract emotions from the videos\u2019 speech using\nSpeechBrain system (Ravanelli et al., 2021).\nThe significant segment level acoustic features\nare listed in Table 10, 11, and 12 in Appendix A.1.2.\n2https://cloud.google.com/speech-to-textIn general, intensity and maximum pitch are neg-\natively correlated with viewer\u2019s perception \u2013 the\nlouder the speakers are, the less likely that the view-\ners would enjoy the videos and the content. This is\nwhat we observe for all videos, including pro- and\nanti-QAnon videos. In addition, the more angry the\nspeakers are, the less likely that the viewers would\nagree with the content.\n6.3 Visual Features\nFor visual features, we extract frame-level facial\nexpression features with a pre-trained FER model3.\nWe also detect weapons that appear in the videos us-\ning Clarifai\u2019s weapon detector model4, as we have\nproven in Secion 6.1 that topics related to violence\nand war are correlated with viewer\u2019 perception.\nThe significant segment level visual features are\nlisted in Table 13, 14, and 15 in Appendix A.1.3.\nIn general, if speakers appear in the videos show\nsurprise or sad facial expressions, viewers tend to\nhave negative perception. However, speakers\u2019 an-\ngry expressions are positively correlated with view-\ners\u2019 perception. For anti-QAnon videos, speakers\u2019\nnegative expressions, such as fear and disgust, are\nnegatively correlated with how viewers would en-\njoy and agree with the videos. In addition, the\nappearance of weapons, regardless of what types of\nweapons, has a negative impact on viewers\u2019 percep-\ntion. This agrees with what we observe in textual\nfeatures, where words related to violence are nega-\ntively correlated with viewer\u2019 perception.\nSimilarly, on video level, we observe that speak-\ners\u2019 surprise and fear expressions are negatively\ncorrelated with how viewers perceive the videos.\nThe complete list of significant video level visual\nfeatures are summarized in Table 21, 22, and 23.\n7 Conclusions and Future Work\nIn this study, we have collected a corpus of QAnon\nvideos and have designed a comprehensive ques-\ntionnaire. With the responses we collect from the\nquestionnaire, we are able to propose 3 metrics to\nevaluate viewers\u2019 perception towards the videos,\nand outline the traits of viewers that QAnon videos\nare the most appealing to, including their personal-\nities, media consumption, and presumption about\nother radicalizing groups. In addition, we iden-\ntify video characteristics, including generic content\n3Facial-Expression-Recognition.Pytorch\n4Clarifai Weapon Detector\ntraits and arousing emotions, that impact viewers\u2019\nperception of the videos.\nIn future, we will analyze multimodal features\nto investigate what modality features contribute to\nviewers\u2019 perception. We also aim to utilize mul-\ntimodal features to build models for identifying\nradical content and techniques.\nLimitations\nOne of the limitations of this study is the unbal-\nanced distribution of rater demographics. Specifi-\ncally, 91% of our raters report themselves having\na Bachelor\u2019s degree or higher, 84.7% of the raters\nconsider themselves to be liberal and moderate, and\n91% of the raters belong to the 18-29 age group. In\nfuture, we will collect crowdsourcing annotations\nfrom a more diverse population.\nAnother limitation of our study is the size of the\ndata we put out with the questionnaire \u2013 6 videos\nwith 3 pro- and 3 anti-QAnon, because manually\nselecting videos that are the most relevant and ap-\npropriate is extremely time-consuming. However,\nwith this study as an initial step, we will utilize the\nconclusions we have drawn and aim to make use\nof the full corpus of 5,924 QAnon videos that we\nhave collected so far for further analysis and model\nbuilding.\nEthics Statement\nWe discuss the ethical considerations of our study\nas follows:\nData Collection: We collect videos from\nYouTube and BitChute, where all videos and their\nassociated metadata are available to public. For\nYouTube videos, we use the official Google Devel-\noper API5. For BitChute videos, we scrape publicly\navailable videos and data without utilizing any in-\nternal APIs and private access.\nQuestionnaire Response Collection: All raters\ntake part in the questionnaire participate voluntarily\nand are fully aware of any risks of harm associated\nwith their participation. We do not collect any\npersonal information that would allow us to identify\nthe raters, or to associate them with their responses.\nData Release: Due to the sensitivity of the data,\nthe raw videos, video metadata, and detailed ques-\ntionnaire responses are not made available yet on\nany platforms. However, we are willing to con-\nsider sharing them with other research groups upon\nrequest.\n5https://developers.google.com/youtube/v3/docsReferences\nLin Ai, Anika Kathuria, Subhadarshi Panda, Arushi\nSahai, Yuwen Yu, Sarah Ita Levitan, and Julia\nHirschberg. 2021. Identifying the popularity and\npersuasiveness of right-and left-leaning group videos\non social media. In 2021 IEEE International Con-\nference on Big Data (Big Data) , pages 2454\u20132460.\nIEEE.\nAmarnath Amarasingam and Marc-Andr\u00e9 Argentino.\n2020. The qanon conspiracy theory: A security threat\nin the making. CTC Sentinel , 13(7):37\u201344.\nOscar Araque and Carlos A Iglesias. 2020. An ap-\nproach for radicalization detection based on emo-\ntion signals and semantic similarity. IEEE Access ,\n8:17877\u201317891.\nAdam Bermingham, Maura Conway, Lisa McInerney,\nNeil O\u2019Hare, and Alan F Smeaton. 2009. Combining\nsocial network analysis and sentiment analysis to\nexplore the potential for online radicalisation. In\n2009 International Conference on Advances in Social\nNetwork Analysis and Mining , pages 231\u2013236. IEEE.\nRandy Borum. 2011. Radicalization into violent extrem-\nism i: A review of social science theories. Journal of\nstrategic security , 4(4):7\u201336.\nPaul Ekman and Wallace V Friesen. 1971. Constants\nacross cultures in the face and emotion. Journal of\npersonality and social psychology , 17(2):124.\nAmanda Garry, Samantha Walther, Rukaya Rukaya, and\nAyan Mohammed. 2021. Qanon conspiracy theory:\nexamining its evolution and mechanisms of radical-\nization. Journal for Deradicalization , (26):152\u2013216.\nSamuel D Gosling, Peter J Rentfrow, and William B\nSwann Jr. 2003. A very brief measure of the big-\nfive personality domains. Journal of Research in\npersonality , 37(6):504\u2013528.\nMatthias Hartung, Roman Klinger, Franziska\nSchmidtke, and Lars V ogel. 2017. Ranking right-\nwing extremist social media profiles by similarity to\ndemocratic and extremist groups. In Proceedings of\nthe 8th Workshop on Computational Approaches to\nSubjectivity, Sentiment and Social Media Analysis ,\npages 24\u201333, Copenhagen, Denmark. Association\nfor Computational Linguistics.\nValentin Hofmann, Xiaowen Dong, Janet Pierrehum-\nbert, and Hinrich Schuetze. 2022. Modeling ideolog-\nical salience and framing in polarized online groups\nwith graph neural networks and structured sparsity.\nInFindings of the Association for Computational\nLinguistics: NAACL 2022 , pages 536\u2013550, Seattle,\nUnited States. Association for Computational Lin-\nguistics.\nClayton Hutto and Eric Gilbert. 2014. Vader: A parsi-\nmonious rule-based model for sentiment analysis of\nsocial media text. In Proceedings of the international\nAAAI conference on web and social media , volume 8,\npages 216\u2013225.\nDaniel L\u00f3pez-S\u00e1ncez, Jorge Revuelta, Fernando de la\nPrieta, and Juan M Corchado. 2018. Towards the\nautomatic identification and monitoring of radicaliza-\ntion activities in twitter. In International Conference\non Knowledge Management in Organizations , pages\n589\u2013599. Springer.\nHuyen Nguyen, Ralph Vente, David Lupea, Sarah Ita\nLevitan, and Julia Hirschberg. 2021. Acoustic-\nprosodic, lexical and demographic cues to persuasive-\nness in competitive debate speeches. In Interspeech ,\npages 1034\u20131038.\nJames W Pennebaker, Ryan L Boyd, Kayla Jordan, and\nKate Blackburn. 2015. The development and psycho-\nmetric properties of liwc2015. Technical report.\nMirco Ravanelli, Titouan Parcollet, Peter Plantinga,\nAku Rouhe, Samuele Cornell, Loren Lugosch, Cem\nSubakan, Nauman Dawalatabad, Abdelwahab Heba,\nJianyuan Zhong, Ju-Chieh Chou, Sung-Lin Yeh,\nSzu-Wei Fu, Chien-Feng Liao, Elena Rastorgueva,\nFran\u00e7ois Grondin, William Aris, Hwidong Na, Yan\nGao, Renato De Mori, and Yoshua Bengio. 2021.\nSpeechBrain: A general-purpose speech toolkit.\nArXiv:2106.04624.\nManoel Horta Ribeiro, Raphael Ottoni, Robert West,\nVirg\u00edlio AF Almeida, and Wagner Meira Jr. 2020.\nAuditing radicalization pathways on youtube. In\nProceedings of the 2020 conference on fairness, ac-\ncountability, and transparency , pages 131\u2013141.\nRode Snehal Sudhakar and Manjare Chandraprabha\nAnil. 2015. Analysis of speech features for emo-\ntion detection: a review. In 2015 International Con-\nference on Computing Communication Control and\nAutomation , pages 661\u2013664. IEEE.\nIsabelle van der Vegt, Maximilian Mozes, Bennett Klein-\nberg, and Paul Gill. 2021. The grievance dictionary:\nUnderstanding threatening language use. Behavior\nresearch methods , 53(5):2105\u20132119.\nZixiaofan Yang, Jessica Huynh, Riku Tabata, Nishmar\nCestero, Tomer Aharoni, and Julia Hirschberg. 2020.\nWhat makes a speaker charismatic? producing and\nperceiving charismatic speech. In Proc. 10th Interna-\ntional Conference on Speech Prosody , volume 2020,\npages 685\u2013689.A Significant Multimodal Features\nA.1 Segment Level Significant Features\nA.1.1 Textual Features\nEnjoyment on All Videos\nFeature Corr p-value\nviolence -0.138 0.0247\ndeadline -0.125 0.0429\ni 0.165 0.00716\nthey -0.141 0.0220\nmale 0.122 0.0475\nsocial -0.122 0.0478\nnegate 0.122 0.0488\nEnjoyment on Pro-QAnon Videos\nFeature Corr p-value\nsentiment 0.205 0.0337\nweaponry -0.387 0.0000384\nviolence -0.324 0.000671\ngod -0.266 0.00556\nsoldier -0.211 0.0294\nthreat -0.202 0.0370\nfocuspresent 0.377 0.0000630\nthey -0.351 0.000215\npower -0.328 0.000554\nipron 0.323 0.000677\ncogproc 0.301 0.00162\nauxverb 0.291 0.00235\nnegate 0.280 0.00351\nwe -0.277 0.00388\nsocial -0.273 0.00451\naffiliation -0.267 0.00543\ni 0.261 0.00664\ntentat 0.260 0.00675\nnegemo -0.242 0.0120\ndrives -0.241 0.0122\nadverb 0.231 0.0167\nppron -0.228 0.0182\nanger -0.222 0.0215\nverb 0.219 0.0233\ninformal 0.219 0.0235\ndiffer 0.212 0.0281\nhealth -0.210 0.0300\nbody -0.209 0.0310\ndiscrep -0.208 0.0314\nbio -0.196 0.0428\nquant 0.191 0.0484\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\ninterrog -0.165 0.0395\nTable 7: Significant segment level textual features (p-\nvalue <0.05) on Enjoyment Scores\nContent of All Videos\nFeature Corr p-value\ngod -0.128 0.0376\ntime -0.217 0.000393\ndiffer 0.139 0.0245\nfriend 0.135 0.0285\ninsight -0.134 0.0303\ningest 0.122 0.0475\nContent of Pro-QAnon Videos\nFeature Corr p-value\nsentiment 0.205 0.0337\nweaponry -0.387 0.0000384\nviolence -0.324 0.000671\ngod -0.266 0.00556\nsoldier -0.211 0.0294\nthreat -0.202 0.0370\nfocuspresent 0.377 0.0000630\nthey -0.351 0.000215\npower -0.328 0.000554\nipron 0.323 0.000677\ncogproc 0.301 0.00162\nauxverb 0.291 0.00235\nnegate 0.280 0.00351\nwe -0.277 0.00388\nsocial -0.273 0.00451\naffiliation -0.267 0.00543\ni 0.261 0.00664\ntentat 0.260 0.00675\nnegemo -0.242 0.0120\ndrives -0.241 0.0122\nadverb 0.231 0.0167\nppron -0.228 0.0182\nanger -0.222 0.0215\nverb 0.219 0.0233\ninformal 0.219 0.0235\ndiffer 0.212 0.0281\nhealth -0.210 0.0300\nbody -0.209 0.0310\ndiscrep -0.208 0.0314\nbio -0.196 0.0428\nquant 0.191 0.0484\nContent of Anti-QAnon Videos\nFeature Corr p-value\ntime -0.285 0.000316\nfriend 0.213 0.00765\nfocuspast -0.164 0.0409\nfemale 0.163 0.0420\ningest 0.163 0.0424\nconj -0.157 0.0498\nTable 8: Significant segment level textual features (p-\nvalue <0.05) on Content ScoresActions after All Videos\nFeature Corr p-value\ntime -0.214 0.000479\nfriend 0.147 0.0173\ninsight -0.132 0.0321\nnegate 0.130 0.0353\nfemale 0.130 0.0353\ningest 0.126 0.0417\nActions after Pro-QAnon Videos\nFeature Corr p-value\nsentiment 0.205 0.0337\nweaponry -0.387 0.0000384\nviolence -0.324 0.000671\ngod -0.266 0.00556\nsoldier -0.211 0.0294\nthreat -0.202 0.0370\nfocuspresent 0.377 0.0000630\nthey -0.351 0.000215\npower -0.328 0.000554\nipron 0.323 0.000677\ncogproc 0.301 0.00162\nauxverb 0.291 0.00235\nnegate 0.280 0.00351\nwe -0.277 0.00388\nsocial -0.273 0.00451\naffiliation -0.267 0.00543\ni 0.261 0.00664\ntentat 0.260 0.00675\nnegemo -0.242 0.0120\ndrives -0.241 0.0122\nadverb 0.231 0.0167\nppron -0.228 0.0182\nanger -0.222 0.0215\nverb 0.219 0.0233\ninformal 0.219 0.0235\ndiffer 0.212 0.0281\nhealth -0.210 0.0300\nbody -0.209 0.0310\ndiscrep -0.208 0.0314\nbio -0.196 0.0428\nquant 0.191 0.0484\nActions after Anti-QAnon Videos\nFeature Corr p-value\ntime -0.266 0.000795\nfriend 0.195 0.0146\ninsight -0.161 0.0442\nTable 9: Significant segment level textual features (p-\nvalue < 0.05) on Actions Scores\nA.1.2 Acoustic Features\nEnjoyment on All Videos\nFeature Corr p-value\nMax Intensity -0.660 3.14E-34\nMean Intensity -0.654 1.55E-33\nSd Intensity -0.565 1.32E-23\nSd Pitch -0.361 1.68E-09\nMax Pitch -0.354 3.68E-09\nJitter 0.303 5.66E-07\nMean Pitch 0.230 0.000164\nShimmer -0.134 0.0301\nEnjoyment on Pro-QAnon Videos\nFeature Corr p-value\nHNR 0.870 5.76E-34\nMean Pitch 0.738 1.26E-19\nMean Intensity -0.713 7.18E-18\nJitter 0.649 4.15E-14\nShimmer -0.640 1.17E-13\nMin Pitch 0.562 2.97E-10\nMax Intensity -0.507 2.46E-08\nSd Pitch -0.440 2.12E-06\nMax Pitch -0.424 5.42E-06\nMin Intensity -0.329 0.000548\nSd Intensity -0.230 0.0169\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\nMax Intensity -0.832 3.02E-41\nMean Intensity -0.829 9.96E-41\nSd Intensity -0.678 2.25E-22\nSd Pitch -0.348 8.33E-06\nMax Pitch -0.336 0.0000184\nHNR -0.328 0.0000285\nMin Intensity 0.298 0.000161\nJitter 0.172 0.0316\nTable 10: Significant segment level acoustic features\n(p-value <0.05) on Enjoyment ScoresContent of All Videos\nFeature Corr p-value\nanger -0.169 0.00602\nMin Intensity 0.618 4.36E-29\nSd Intensity -0.428 3.71E-13\nMean Intensity 0.367 8.08E-10\nMax Intensity 0.353 4.06E-09\nHNR -0.234 0.000129\nMin Pitch 0.192 0.00171\nContent of Pro-QAnon Videos\nFeature Corr p-value\nHNR 0.870 5.76E-34\nMean Pitch 0.738 1.26E-19\nMean Intensity -0.713 7.18E-18\nJitter 0.649 4.15E-14\nShimmer -0.640 1.17E-13\nMin Pitch 0.562 2.97E-10\nMax Intensity -0.507 2.46E-08\nSd Pitch -0.440 2.12E-06\nMax Pitch -0.424 5.42E-06\nMin Intensity -0.329 0.000548\nSd Intensity -0.230 0.0169\nContent of Anti-QAnon Videos\nFeature Corr p-value\nMin Intensity 0.676 3.58E-22\nSd Intensity -0.419 5.21E-08\nHNR -0.311 0.0000767\nMean Intensity 0.179 0.0256\nTable 11: Significant segment level acoustic features\n(p-value <0.05) on Content Scores\nActions after All Videos\nFeature Corr p-value\nSd Intensity -0.543 1.33E-21\nMin Intensity 0.518 1.99E-19\nMax Pitch -0.173 0.00488\nSd Pitch -0.173 0.00494\nHNR -0.164 0.00767\nActions after Pro-QAnon Videos\nFeature Corr p-value\nHNR 0.870 5.76E-34\nMean Pitch 0.738 1.26E-19\nMean Intensity -0.713 7.18E-18\nJitter 0.649 4.15E-14\nShimmer -0.640 1.17E-13\nMin Pitch 0.562 2.97E-10\nMax Intensity -0.507 2.46E-08\nSd Pitch -0.440 2.12E-06\nMax Pitch -0.424 5.42E-06\nMin Intensity -0.329 0.000548\nSd Intensity -0.230 0.0169\nActions after Anti-QAnon Videos\nFeature Corr p-value\nMin Intensity 0.687 3.77E-23\nSd Intensity -0.569 8.67E-15\nHNR -0.372 1.74E-06\nMax Pitch -0.164 0.0409\nTable 12: Significant segment level acoustic features\n(p-value <0.05) on Actions Scores\nA.1.3 Visual Features\nEnjoyment on All Videos\nFeature Corr p-value\nneutral -0.270 1.23E-10\nsurprise -0.143 7.95E-04\nhappy 0.126 3.20E-03\nsad -0.117 6.23E-03\nhas_weapon -0.215 1.01E-06\nlong-gun -0.210 1.74E-06\nsword -0.148 0.000799\nEnjoyment on Pro-QAnon Videos\nFeature Corr p-value\nhappy 0.259 0.0000105\nneutral -0.234 0.0000722\nsad -0.226 0.000127\nangry 0.166 0.00532\nsurprise -0.143 0.0160\nhas_weapon -0.243 0.000133\nlong-gun -0.220 0.000567\nsword -0.184 0.00413\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\nfear -0.230 0.000154\nsurprise -0.169 0.00579\ndisgust -0.156 0.0108\nTable 13: Significant segment level visual features (p-\nvalue <0.05) on Enjoyment Scores\nContent of All Videos\nFeature Corr p-value\nangry 0.311 9.41E-14\nsad -0.169 0.0000726\nsurprise -0.117 0.00628\nhappy 0.107 0.0122\nneutral -0.0995 0.0198\nlong-gun -0.139 0.00163\nhas_weapon -0.0923 0.0376\nsword -0.0904 0.0418\nContent of Pro-QAnon Videos\nFeature Corr p-value\nhappy 0.259 0.0000109\nneutral -0.235 0.0000673\nsad -0.226 0.000129\nangry 0.165 0.00548\nsurprise -0.143 0.0160\nhas_weapon -0.243 0.000136\nlong-gun -0.220 0.000561\nsword -0.184 0.00409\nContent of Anti-QAnon Videos\nFeature Corr p-value\nangry 0.482 7.06E-17\nneutral 0.167 0.00647\nfear -0.123 0.0451\nhas_weapon 0.141 0.0213\nlong-gun 0.143 0.0197\nTable 14: Significant segment level visual features (p-\nvalue <0.05) on Content ScoresActions after All Videos\nFeature Corr p-value\nangry 0.312 8.15E-14\nsad -0.148 0.000514\nsurprise -0.131 0.00215\nneutral -0.0905 0.0342\nlong-gun -0.124 0.00526\nActions after Pro-QAnon Videos\nFeature Corr p-value\nhappy 0.268 5.20E-06\nsad -0.231 0.0000892\nneutral -0.212 0.000343\nangry 0.178 0.00270\nsurprise -0.141 0.0182\nhas_weapon -0.251 0.0000816\nlong-gun -0.215 0.000746\nsword -0.179 0.00531\nActions after Anti-QAnon Videos\nFeature Corr p-value\nangry 0.429 2.43E-13\nfear -0.179 0.00335\nneutral 0.128 0.0374\nsurprise -0.121 0.0495\nhas_weapon 0.125 0.0424\nTable 15: Significant segment level visual features (p-\nvalue <0.05) on Actions Scores\nA.2 Video Level Significant Features\nA.2.1 Textual Features\nEnjoyment on All Videos\nFeature Corr p-value\nloneliness 0.969 0.00645\nplanning -0.921 0.0265\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\nloneliness 0.998 0.0360\nhonour 0.998 0.0429\nhome 1.000 0.00794\nTable 16: Significant video level textual features (p-\nvalue <0.05) on Enjoyment Scores\nContent of All Videos\nFeature Corr p-value\nrelativ -0.933 0.0208\ntime -0.903 0.0358\npercept -0.899 0.0380\nsexual 0.889 0.0436\nadj 0.885 0.0462\nContent of Anti-QAnon Videos\nFeature Corr p-value\ngod -1.000 0.0174\nparanoia -1.000 0.0174\nfamily 0.999 0.0234\nfemale 0.998 0.0440\nsexual 0.998 0.0440\ningest 0.998 0.0440\ndeath 0.998 0.0440\nswear 0.998 0.0440\nTable 17: Significant video level textual features (p-\nvalue <0.05) on Content Scores\nActions after All Videos\nFeature Corr p-value\nrelativ -0.992 0.000852\nadj 0.950 0.0135\ntime -0.942 0.0165\npercept -0.924 0.0250\nhear -0.907 0.0337\ningest 0.885 0.0458\nActions after Anti-QAnon Videos\nFeature Corr p-value\nhelp 1.000 0.0146\npercept -1.000 0.00369\ncompare 1.000 0.0103\nyou -0.999 0.0271\nrelativ -0.998 0.0364\nbio 0.997 0.0488\nTable 18: Significant video level textual features (p-\nvalue <0.05) on Actions ScoresA.2.2 Acoustic Features\nEnjoyment on All Videos\nFeature Corr p-value\nneutral 0.909 0.0323\nSd Pitch -0.916 0.0288\nMax Pitch -0.916 0.0291\nSd Intensity -0.884 0.0467\nEnjoyment on Anti-QAnon Videos\nFeature Corr p-value\nMax Pitch -1.00 0.0112\nSd Pitch -1.00 0.0494\nTable 19: Significant video level acoustic features (p-\nvalue <0.05) on Enjoyment Scores\nActions after Anti-QAnon Videos\nFeature Corr p-value\nMin Intensity 0.997 0.0500\nTable 20: Significant video level acoustic features (p-\nvalue <0.05) on Actions Scores\nA.2.3 Visual Features\nEnjoyment on All Videos\nFeature Corr p-value\nsurprise -0.894 0.0163\nTable 21: Significant video level visual features (p-value\n<0.05) on Enjoyment Scores\nContent of All Videos\nFeature Corr p-value\nsurprise -0.821 0.0450\nContent of Anti-QAnon Videos\nFeature Corr p-value\nangry 1.000 0.00109\nfear -0.998 0.0361\nsword 0.998 0.0440\nTable 22: Significant video level visual features (p-value\n<0.05) on Content Scores\nActions after All Videos\nFeature Corr p-value\nfear -0.812 0.0495\nTable 23: Significant video level visual features (p-value\n<0.05) on Actions Scores\nB Questionnaire Questions\n1. What is your gender\n2Male\n2Female\n2Nonbinary\n2Prefer not to say\n2. Which age group describes you?\n218-29\n230-39\n240-49\n250-59\n260 or over\n3. What is your ethnicity?\n2American Indian or Alaska Native\n2Asian\n2Black or African American\n2Native Hawaiian or Other Pacific Islander\n2White\n2Other\n4. What is the highest level of education you\u2019ve completed?\n2Some high school or less\n2High school diploma\n2Associate\u2019s degree\n2Bachelor\u2019s degree\n2Master\u2019s degree\n2Doctorate degree\n5. Do you consider yourself to be conservative or liberal when thinking about politics?\n2Conservative\n2Liberal\n2Moderate\n2Other/Undecided\n6. Here are a number of personality traits that may or may not apply to you. Please tick a number next to\neach statement to indicate the extent to which you agree or disagree with that statement. You should rate\nthe extend to which the pair of traits applies to you, even if one characteristic applies more strongly than the\nother.\n1-Disagree\nstrongly2-Disagree\nslightly3-Neither agree\nnor disagree4-Agree\nslightly5-Agree\nstrongly\nExtraverted, enthusiastic 2 2 2 2 2\nDependable, self-disciplined 2 2 2 2 2\nAnxious, easily upset 2 2 2 2 2\nOpen to new experiences, complex 2 2 2 2 2\nReserved, quiet 2 2 2 2 2\nSympathetic, warm 2 2 2 2 2\nDisorganized, careless 2 2 2 2 2\nCalm, emotionally stable 2 2 2 2 2\nConventional, uncreative 2 2 2 2 2\nTable 24: Demographic Information\n1. What is your opinion of the following groups?\nPositive Neutral Negative Never Heard of it\nQAnon 2 2 2 2\nAntifa 2 2 2 2\nProud Boys 2 2 2 2\nOath Keepers 2 2 2 2\nBLM 2 2 2 2\n2. Do you trust the following media as credible sources?\nPositive Neutral Negative Never Heard of it\nFox News (foxnews.com) 2 2 2 2\nBreitbart News (breitbart.com) 2 2 2 2\nMSNBC News (msnbc.com) 2 2 2 2\nPBS News (pbs.org) 2 2 2 2\nAssociated Press News (apnews.com) 2 2 2 2\nNPR (npr.org) 2 2 2 2\nThe Wall Street Journal (wsj.com) 2 2 2 2\nCNN (cnn.com) 2 2 2 2\nTable 25: Introductory Information\n1. Did you understand the video?\n2Yes\n2No\n2. Do you think the video was professionally produced with good quality?\n2Yes\n2No\n3. Who do you think the video was trying to appeal to? :\n4. Was there any violence displayed in the video?\n2Yes\n2No\n5. Was there any music in video?\n2Yes\n2No\n6. Did any of the following objects appear in the video? Choose all that apply.\n2Guns\n2Swords\n2Other Weapons\n2Flags\n2Symbols of the Group\n2None of the Above\n7. How likely do you think it is that the people in the video will become involved in the following actions?\nNot at All Likely Not Much Likely Undecided Somewhat Likely Very Much Likely\nProtests 2 2 2 2 2\nViolence 2 2 2 2 2\nIllegal Acts 2 2 2 2 2\nTable 26: Video Specific Questions.a\n8. Would you associate the following traits with this video?\nYes Neutral No\nBoring (could you pay attention the whole time or not?) 2 2 2\nLively (was it energetic? Ex. was there music?) 2 2 2\nPersuasive (were you convinced by the content?) 2 2 2\nTrustworthy (did you trust the content?) 2 2 2\nLogical (was there a structured argument or data presented?) 2 2 2\n9. Is the video\u2019s stance positive, negative, or neutral towards the group?\n2Positive\n2Negative\n2Neutral\n10. Do you think this speaker demonstrated any of the following characteristics?\nYes Neutral No\nCharismatic 2 2 2\nConfident 2 2 2\nEloquent 2 2 2\nEnthusiastic 2 2 2\nIntelligent 2 2 2\nConvincing 2 2 2\nTough 2 2 2\nCharming 2 2 2\nAngry 2 2 2\n11. Did you enjoy watching the video?\n1 2 3 4 5\nNot at All 2 2 2 2 2 Very Much\n12. What emotions did you feel when you watched the video? Check all that apply.\n2Happiness\n2Sadness\n2Surprise\n2Fear\n2Disgust\n2Anger\n2Confused\n13. Which part of the video was most impactful? (Give the approximate timestamps.) Enter N/A if not\napplicable. :\n14. Give a short description (a sentence) of the most impactful part of the video you listed above. Enter N/A\nif not applicable. :\n15. Do you think any of the content in the video makes a valid point?\n1 2 3 4 5\nNot at All 2 2 2 2 2 Very Much\n16. Would you take any of the following actions after watching this video? Check all that apply.\n2Like the video\n2Dislike the video\n2Post a supporting comment under the video\n2Post a criticizing comment under the video\n2Share the video with friends, families, or on social media platforms\n2Search for similar videos\n2Learn more about the group\n2Consider joining the group\n2Non of the Above\nTable 27: Video Specific Questions.b\n17. Do you think that others watching this video would consider taking any of the following actions? Check\nall that apply.\n2Like the video\n2Dislike the video\n2Post a supporting comment under the video\n2Post a criticizing comment under the video\n2Share the video with friends, families, or on social media platforms\n2Search for similar videos\n2Learn more about the group\n2Consider joining the group\n2Non of the Above\n18. Did the video change your mind about anything? If so, please elaborate. :\nTable 28: Video Specific Questions.c\n1. What is your opinion of the following groups?\nPositive Neutral Negative Never Heard of it\nQAnon 2 2 2 2\nAntifa 2 2 2 2\nProud Boys 2 2 2 2\nOath Keepers 2 2 2 2\nBLM 2 2 2 2\n2. Is there anything else about your experience watching these videos that you would like to mention? :\n3. Please rate your experience of this HIT\n1 2 3 4 5\nMuch worse than the average HIT 2 2 2 2 2 Much better than the average HIT\n4. If you would like to give feedback on your experience with this HIT, please do so here. :\nTable 29: Final Questions\nC Rater Demographics and Background\nDistribution\nWithin the 46 raters participated in the question-\nnaire:\n\u2022 29 raters were Male, 17 were Female.\n\u2022A major of raters (42) belonged to the 18-29\nage group. Only a few (4) belonged to the\n30-39 age group.\n\u2022A large number of raters were Asian (37), fol-\nlowed by White (7).\n\u202228 raters reported having a Bachelor\u2019s degree\nand 13 raters reported having a Master\u2019s de-\ngree.\n\u2022About 20 raters reported they were moderates\nand 19 reported they were liberal.\n\u202217 raters agreed slightly to be extroverted and\nenthusiastic, while others were evenly dis-\ntributed.\n\u202224 raters agreed slightly to be dependable\nand self-disciplined and no rater strongly dis-\nagreed.\n\u2022There was an even distribution of raters who\ndisagreed slightly, neither agreed nor dis-\nagreed, agreed slightly to be anxious and eas-\nily upset.\n\u2022A major of raters (39) either agreed slightly\nor strongly to be open to new experiences and\ncomplex.\n\u2022There was an even distribution of raters\nthrough out all range of disagreement and\nagreement to be reserved and quiet.\n\u202224 raters agreed slightly to be sympathetic and\nwarm and no rater strongly disagreed.\n\u202227 raters either disagreed slightly or strongly\nto be disorganized and careless and no rater\nstrongly agreed.\n\u202231 raters either agreed slightly or strongly to\nbe calm and emotionally stable.\n\u202223 raters disagreed slightly to be conventional\nand uncreative, and no rater strongly agreed.\u202226 raters showed negative opinion on QAnon,\n16 raters had never heard of it, and no rater\nshowed positive opinion.\n\u202218 raters showed negative opinion on Antifa,\n19 raters had never heard of it, and 1 rater\nshowed positive opinion.\n\u202223 raters showed negative opinion on Proud\nBoys, 21 raters had never heard of it, and no\nrater showed positive opinion.\n\u2022A major of raters (35) had never heard of Oath\nKeepers, and no rater showed positive opin-\nion.\n\u202218 raters showed positive opinion on BLM,\n15 raters were neutral, and 3 raters showed\nnegative opinion.\n\u202227 raters did not trust Fox News, 14 raters\nwere neutral, and 1 rater trusted it.\n\u202228 raters had never heard of Breitbart News\nand 11 raters did not trust it.\n\u202221 raters were neutral on MSNBC News and\n11 raters trusted it.\n\u202228 raters either trusted or were neutral on PBS\nNews and 3 raters did not trust it.\n\u202229 raters either trusted or were neutral on As-\nsociate Press News and 1 raters did not trust\nit.\n\u202229 raters either trusted or were neutral on NPR\nand one raters did not trust it.\n\u2022A major raters (44) either trusted or were neu-\ntral on The Wall Street Journal and 2 raters\ndid not trust it.\n\u2022A major raters (39) either trusted or were neu-\ntral on CNN and 7 raters did not trust it.\nFigure 1: Rater demographics. A total of 46 raters completed the questionnaire.\nFigure 2: Rater self-reported personalities. A total of 46 raters completed the questionnaire.\nFigure 3: Rater\u2019s opinion on radical groups. A total of 46 raters completed the questionnaire.\nFigure 4: Rater\u2019s opinion on media sources. A total of 46 raters completed the questionnaire.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "What Makes A Video Radicalizing? Identifying Sources of Influence in QAnon Videos", "author": ["L Ai", "YW Chen", "Y Yu", "S Kweon", "J Hirschberg"], "pub_year": "2024", "venue": "arXiv preprint arXiv \u2026", "abstract": "In recent years, radicalization is being increasingly attempted on video-sharing platforms.  Previous studies have been proposed to identify online radicalization using generic social"}, "filled": false, "gsrank": 750, "pub_url": "https://arxiv.org/abs/2404.14616", "author_id": ["G86oGoQAAAAJ", "", "Xpzdc_YAAAAJ", "AgLZ-YgAAAAJ", "Qrd7FCoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:B4EodCNhgsQJ:scholar.google.com/&output=cite&scirp=749&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D740%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=B4EodCNhgsQJ&ei=jLWsaNacO46IieoP0sKRuAk&json=", "num_citations": 1, "citedby_url": "/scholar?cites=14159986983306821895&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:B4EodCNhgsQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2404.14616"}}, {"title": "CoupTube: framing medi\u00e1tico sobre la democracia a partir de los casos\" Bolivia: Intento de Golpe\" y\" Corea del Sur: Ley Marcial\" en CNN y BBC", "year": "2025", "pdf_data": "Punto Cero a\u00f1o 30  n\u00b0 50 Junio de 202529\nCoupTube : framing  medi\u00e1tico sobre \nla democracia a partir de los casos \n\u201cBolivia: Intento de Golpe\u201d y \u201cCorea \ndel Sur: Ley Marcial\u201d en CNN y BBC\nPark, H. (2025). CoupTube : framing  medi\u00e1tico sobre la \ndemocracia a partir de los casos \u201cBolivia: Intento de Golpe\u201d y \n\u201cCorea del Sur: Ley Marcial\u201d en CNN  y BBC. Punto Cero, a\u00f1o \n30  n\u00b050, Junio 2025. Pp 29-46. Universidad Cat\u00f3lica Boliviana  \n\u201cSan Pablo\u201d Sede Cochabamba.Hyunjin Park\nSurcoreano, Licenciado en Comunicaci\u00f3n Social, Comunicador Social. \nC\u00f3digo ORCID: 0009-0008-1113-5599\nparkhyunjin13@gmail.com \nEl autor declara no  tener  conflicto  de  inter\u00e9s alguno con la  \nrevista Punto Cero. https://doi.org/10.35319/puntocero.202550266\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d30\nResumen\nLa presente investigaci\u00f3n descriptiva tuvo como objetivo establecer el framing  medi\u00e1tico \nde CNN  y BBC  (incluidas sus versiones en espa\u00f1ol) en YouTube  respecto a la democracia \nen Bolivia y en Corea del Sur a trav\u00e9s de los casos de \u201cIntento de Golpe\u201d y \u201cLey Marcial\u201d. \nEsto tuvo el fin de contribuir al di\u00e1logo sobre la ciudadan\u00eda digital y el discurso global \nsobre la democracia, y conocer la representaci\u00f3n de la democracia que ofrecen estas \nempresas period\u00edsticas. Con una muestra intencional de ocho videos y sus comentarios, \nse aplic\u00f3 una metodolog\u00eda mixta de an\u00e1lisis de contenido, considerando la interacci\u00f3n \nentre los frames  medi\u00e1ticos en los videos y los frames  de audiencia en los comentarios. \nLos resultados mostraron que la representaci\u00f3n de la democracia por parte de los medios \ny el p\u00fablico depende de: (1) El lenguaje y la cultura. (2) El discurso de \u201cnosotros\u201d vs. \u201cellos\u201d. \nEsto demuestra que el proceso comunicacional de framing  se actualiza constantemente, \nbas\u00e1ndose en el sesgo ideol\u00f3gico de los medios y la cr\u00edtica del p\u00fablico, y exige un di\u00e1logo \ndirecto con quienes viven en estos mundos de referencialidad para su entendimiento.\nPalabras clave:  Democracia, framing , periodismo, YouTube\nAbstract\nThe present descriptive investigation had the objective of establishing the media framing  \nof CNN  and BBC  (including their versions in Spanish) in YouTube  regarding democracy \nof Bolivia and of South Korea through the cases of \u201cCoup Attempt\u201d and \u201cMartial Law\u201d. \nThe purpose was to contribute to the dialogue regarding digital citizenship and global \ndiscourse of democracy, and to know the representation of democracy given by these \njournalistic enterprises. With a purposive sample of eight videos and their comments, a \nmixed methodology of content analysis was applied considering the interaction between \nthe media frames  in the videos and audience frames  in the comments. The results showed \nthe representation of democracy by the media and the public to be dependent upon: (1) \nLanguage and culture. (2) Discourse of \u201cus\u201d vs. \u201cthem\u201d. This shows the communicational \nprocess of framing  to be constantly updated based on the ideological bias of the media and \nthe criticality of the public and demands direct dialogue with people who live in these worlds \nof reference for its understanding.\nKeywords:  Democracy, framing , journalism, YouTube\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202531\n1. INTRODUCCI\u00d3N Y ESTADO DE LA CUESTI\u00d3N\n\u201c[L]a crisis es la forma cl\u00e1sica de la revelaci\u00f3n o reconocimiento de la realidad del todo \nsocial\u201d (Zavaleta Mercado, 2009, p. 214). En 2024, dos casos fueron cubiertos por los medios \ninternacionales CNN  y BBC  en la red social digital de YouTube  como \u201ccrisis democr\u00e1tica\u201d: \n(1) El caso del \u201cIntento de Golpe de Estado\u201d en Bolivia, el 26 de junio de 2024. (2) El caso \nde la \u201cLey Marcial\u201d en Corea del Sur, el 3 de diciembre de 2024. En ambos casos, estas \nempresas period\u00edsticas establecieron el problema, la causa, el juicio moral y el remedio de \nBolivia y Corea del Sur, respectivamente, como en \u201ccrisis\u201d (Entman, 1993, 2007, 2010). Y en \nambos casos, esta idea de las naciones en \u201ccrisis\u201d fue instrumentalizada por estos medios \ny sus p\u00fablicos para promover sus representaciones sobre los pa\u00edses democr\u00e1ticos (Voltmer, \n2013). El framing , o \u201clos procesos de construcci\u00f3n social de la realidad y a la producci\u00f3n de \nsentido en el intercambio comunicativo\u201d (Aruguete, 2017, p. 41), estaba claramente en juego \na nivel global. Se requiri\u00f3 una investigaci\u00f3n comunicacional para comprender el desarrollo \nde este \u201c CoupTube \u201d (tema period\u00edstico de \u201cgolpe\u201d + videos de noticias en YouTube ).\nLa presente investigaci\u00f3n se bas\u00f3 en dos premisas te\u00f3ricas para su an\u00e1lisis. La primera \npremisa fue que no existe un periodismo \u201cobjetivo\u201d. Todas las noticias tienen sesgos \nideol\u00f3gicos y riesgos de caer en la dramatizaci\u00f3n sensacionalista del hecho (Ortiz Gonz\u00e1lez \net al., 2024; Rodrigo-Gin\u00e9s et al., 2024). Esto ocurre debido a que la construcci\u00f3n de \nlas noticias en s\u00ed misma es una \u201cventana al mundo\u201d (Tuchman, 1983, p. 13). Estas ideas \nmediadas de la realidad se conocen como frames  medi\u00e1ticos y, en el contexto de la \npresente investigaci\u00f3n, se encuentran en los videos de las noticias en YouTube  (D\u2019Angelo, \n2017). Especialmente en periodismo digital donde se facilita la participaci\u00f3n del p\u00fablico, \nexiste una co-construcci\u00f3n entre los medios y su p\u00fablico de frames  medi\u00e1ticos que narran \na los \u201ch\u00e9roes\u201d y los \u201cvillanos\u201d de la democracia, o qu\u00e9 pa\u00eds es \u201cantidemocr\u00e1tico\u201d y cu\u00e1l es \nm\u00e1s \u201cdemocr\u00e1tico\u201d que el otro (Andrade et al., 2022; \u00c1vila S\u00e1nchez, 2020). Son movimientos \ndiscursivos en fluidez din\u00e1mica seg\u00fan los intereses variados.\nLa segunda premisa de la presente investigaci\u00f3n fue que no existen sujetos \u201cpasivos\u201d. \nTodos los sujetos comentando en las noticias son cr\u00edticos y presentan sus opiniones \nbas\u00e1ndose en sus \u201cfuentes de referencialidad\u201d (Guardia Crespo, 2021, p. 36). Estas ideas \npor parte del p\u00fablico de los medios se denominan frames  de audiencia y, en el contexto de \nesta investigaci\u00f3n, se encuentran en la secci\u00f3n de los comentarios (Aar\u00f8e, 2017). Bajo la \nsubjetividad del p\u00fablico, estos frames  convergen o divergen colectivamente en sentidos, lo \nque a veces resulta en aparentes polarizaciones radicales de bandas sobre la convivencia \ndemocr\u00e1tica (Gracia Landaeta et al., 2022; Rodr\u00edguez Fuentes, 2021). Por ejemplo, aunque \nla realidad es mucho m\u00e1s compleja, los medios de comunicaci\u00f3n polarizaron el caso \nboliviano como un grupo que pensaba \u201cgolpe de derechistas\u201d versus un grupo que pensaba \n\u201cautogolpe de Arce\u201d (Centro de Documentaci\u00f3n e Informaci\u00f3n Bolivia, 2024; Ministerio de \nGobierno Bolivia, 2024), mientras que polarizaron el caso coreano como un grupo que \nquer\u00eda \u201cla destituci\u00f3n del presidente Yoon\u201d versus un grupo que quer\u00eda \u201cla permanencia del \npresidente Yoon\u201d (Lee & Lee, 2025; Sohn & Kang, 2025). Se trata de ejercicios de ciudadan\u00eda \ndigital, que dan como resultado la comprensi\u00f3n y evaluaci\u00f3n colectiva del estado de la \ndemocracia.\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d32\nFigura 1. \nDin\u00e1mica comunicacional de framing  medi\u00e1tico\nFuente: Elaboraci\u00f3n propia con base en Entman (1993).\nCuando los frames  medi\u00e1ticos y los frames  de audiencia interact\u00faan entre s\u00ed, se establece \nun framing  medi\u00e1tico (Ver Figura 1), o un proceso comunicacional con una nueva \nrepresentaci\u00f3n sintonizada (o desintonizada) entre los medios y el p\u00fablico en la cultura \n(Entman, 1993; van Hulst & Yanow, 2016). Este framing  medi\u00e1tico representa la democracia \nde una naci\u00f3n desde una perspectiva espec\u00edfica en la cultura globalizada, lo que permite \ncomprender la representatividad y la participaci\u00f3n del medio y de la poblaci\u00f3n (Voltmer, \n2013). Entonces, con el prop\u00f3sito de continuar los di\u00e1logos sobre el discurso global de \nla democracia y la ciudadan\u00eda digital, la presente investigaci\u00f3n se propuso responder lo \nsiguiente: \u00bfC\u00f3mo representan los medios internacionales ( CNN , BBC ) en YouTube  junto con \nsu p\u00fablico la democracia en Bolivia y en Corea del Sur a partir de los casos identificados \ncomo \u201ccrisis democr\u00e1tica\u201d?\n2. MATERIAL Y M\u00c9TODOS\nLa presente investigaci\u00f3n fue de tipo descriptivo, lo que significa que se limit\u00f3 a identificar \ncaracter\u00edsticas y explicarlas con base en las dos premisas generales mencionadas en la \nintroducci\u00f3n (Bernal Torres, 2016). Por lo tanto, se evidenci\u00f3 que los datos de la investigaci\u00f3n \neran referenciales, y no viables para la universalizaci\u00f3n del fen\u00f3meno comunicacional ni \npara un mapeo complejo de las correlaciones. Aun as\u00ed, la presente investigaci\u00f3n mantuvo la \nrigurosidad de la sistematizaci\u00f3n para formular afirmaciones con fines de di\u00e1logo en base \na los siguientes materiales y m\u00e9todos.\nLas investigaciones comunicacionales sobre frames  y framing  suelen adoptar una \nmetodolog\u00eda mixta que prioriza el an\u00e1lisis de contenido (Samsudin, 2019). La presente \ninvestigaci\u00f3n sigui\u00f3 la misma corriente metodol\u00f3gica, reduciendo la ambig\u00fcedad del \nan\u00e1lisis de contenido mediante la integraci\u00f3n de la codificaci\u00f3n cualitativa y la frecuencia \ncuantitativa de palabras (Matthes & Kohring, 2008). El trabajo utiliz\u00f3 una muestra intencional \nde los videos y los comentarios, basado en ciertas caracter\u00edsticas no probabil\u00edsticas \nactualizadas a marzo de 2025 (Ahmad & Wilkins, 2024). Como la herramienta se utiliz\u00f3 \nATLAS.ti  para codificar el video y los comentarios, as\u00ed como para obtener la lista de \nfrecuencias de las palabras m\u00e1s repetidas en la secci\u00f3n de los comentarios.\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202533\nFigura 2. \nVideos seleccionados para an\u00e1lisis\nFuente: Elaboraci\u00f3n propia (2025).\nAl respecto a la muestra, se seleccion\u00f3 YouTube  como la red social digital en an\u00e1lisis por \nsu relevancia en la transici\u00f3n de los medios tradicionales y una poblaci\u00f3n demogr\u00e1fica \nrelativamente equilibrada (Newman et al., 2024). Segundo, se seleccionaron CNN  (+ CNN  \nen Espa\u00f1ol) y BBC  (+ BBC  Mundo) como los medios en an\u00e1lisis por su alcance basado en el \nn\u00famero de suscriptores y su subcuenta alternativa para el p\u00fablico espa\u00f1ol, con un total de \nocho videos (Ver Figura 2) para la muestra (Maher, 2022). Finalmente, para los comentarios \nde cada video, se seleccionaron los 20 comentarios con el mayor \u00edndice de interacci\u00f3n \nbasado en cantidad de \u201cme gusta\u201d (Andrade et al., 2022). En cuanto a la lista de frecuencia \nde palabras, se tuvieron en cuenta todos los comentarios no eliminados del video. \nFigura 3. \nCinco tipos de frames  medi\u00e1ticos\nFuente: Elaboraci\u00f3n propia con base en Semetko & Valkenburg (2000).\nComo primer objetivo, se identificaron los frames  medi\u00e1ticos en los videos de las noticias. \nEste objetivo fue realizado mediante codificaci\u00f3n cualitativa, utilizando los cinco frames  \nmedi\u00e1ticos y sus respectivos indicadores establecidos por Semetko & Valkenburg (2000) \npara el an\u00e1lisis de problemas pol\u00edticos (Ver Figura 3). Los audios de los videos fueron \nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d34\ntranscritos autom\u00e1ticamente con YouTube Transcript Extractor . Cada subdivisi\u00f3n textual \ncreada autom\u00e1ticamente por la herramienta se codific\u00f3 en una de las cinco categor\u00edas de \nframes  mediante ATLAS.ti . Para reducir el sesgo del investigador, los c\u00f3digos se verificaron \nde forma cruzada con ChatGPT , que actu\u00f3 como codificador mediante instrucci\u00f3n con los \nindicadores y las categor\u00edas (Ver Nota 1 para el prompt ).\nFigura 4.\n Cuatro tipos de frames  de audiencia\nFuente: Elaboraci\u00f3n propia con base en Entman (1993).\nComo segundo objetivo, se determinaron los frames  de audiencia en los comentarios de las \nnoticias. Este objetivo fue realizado mediante codificaci\u00f3n cualitativa, utilizando los cuatro \nframes  de audiencia y sus respectivos indicadores establecidos por Entman (1993) para \nel an\u00e1lisis de opiniones sobre problemas (Ver Figura 4). Los comentarios se recopilaron a \ntrav\u00e9s de YouTube Data API en Google Sheets y se jerarquizaron seg\u00fan el n\u00famero de \u201cme \ngusta\u201d de los 20 comentarios principales. Estos comentarios se codificaron con ATLAS.ti  \nseg\u00fan las cuatro categor\u00edas. Posteriormente, todos los comentarios del video (Ver Figura 2) \nse incorporaron al programa para obtener los 10 conceptos m\u00e1s frecuentes entre el p\u00fablico \ncomo la verificaci\u00f3n cuantitativa. Este proceso, similar al del primer objetivo, se verific\u00f3 \ncon ChatGPT , que actu\u00f3 como codificador con las instrucciones de los indicadores y las \ncategor\u00edas (Ver Nota 2 para el prompt ).\nComo consideraciones \u00e9ticas, la presente investigaci\u00f3n tuvo en cuenta la confidencialidad \nde los usuarios y la recopilaci\u00f3n de videos \u00fanicamente en el dominio p\u00fablico de YouTube  con \nfines educativos e investigativos (Alem\u00e1n-Andrade & Jim\u00e9nez, 2021). Adem\u00e1s, la presente \ninvestigaci\u00f3n utiliz\u00f3 la inteligencia artificial ( ChatGPT ) s\u00f3lo como apoyo de codificaci\u00f3n para \nel an\u00e1lisis de contenido, precisando que el an\u00e1lisis y la redacci\u00f3n final fue realizado por el \nmismo investigador.\n3. AN\u00c1LISIS Y RESULTADOS\nLa presente investigaci\u00f3n consider\u00f3 dos casos para analizar el framing  medi\u00e1tico y su \nrepresentaci\u00f3n de la democracia: \u201cIntento de Golpe\u201d en Bolivia y \u201cLey Marcial\u201d en Corea del \nSur. Con base en la cobertura de estos casos por parte de CNN  (y su versi\u00f3n en espa\u00f1ol, \nCNN  en Espa\u00f1ol) y BBC  (y su versi\u00f3n en espa\u00f1ol, BBC  Mundo) en YouTube  y la interacci\u00f3n \ndel p\u00fablico con estos videos, se establecieron dos secciones para la presentaci\u00f3n de \nresultados de la investigaci\u00f3n: (1) Democracia en Bolivia. (2) Democracia en Corea del Sur.\n3.1 Democracia en Bolivia: Caso \u201cIntento de Golpe\u201d\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202535\nEl 26 de junio de 2024, algunos grupos militares y carros blindados ligeros, dirigidos por \nel exgeneral Juan Jos\u00e9 Z\u00fa\u00f1iga, tomaron la Plaza Murillo en La Paz exigiendo un nuevo \ngabinete en lugar del presidente Luis Arce (Centro de Documentaci\u00f3n e Informaci\u00f3n Bolivia, \n2024). En pocas horas, los militares abandonaron la plaza con el exgeneral arrestado. En los \nmedios locales, este suceso fue encuadrado ya sea como un \u201cgolpe fallido\u201d (Ministerio de \nGobierno Bolivia, 2024) o un \u201cautogolpe\u201d (Opini\u00f3n, 2024) que fingi\u00f3 una crisis democr\u00e1tica. \nEn cualquier caso, el incidente fue r\u00e1pidamente olvidado por la poblaci\u00f3n boliviana, salvo en \nel caso de los medios internacionales y su p\u00fablico, que se pronunciaron sobre el problema \nde la democracia en Bolivia priorizando dos versiones y atribuyendo responsabilidad a \ndistintos actores: (1) CIA y los EEUU. (2) Autogolpe y MAS.\n3.1.1 CIA y EEUU\nLas cuentas originales de CNN  y BBC , ambos canales dirigidos a un p\u00fablico angloparlante, \nson conocidas por su sesgo ideol\u00f3gico \u201ccentroizquierda\u201d (van Zandt, 2024). Por ello, algunos \npuntos recurrentes de referencia de estos medios y del p\u00fablico son las cr\u00edticas a los partidos \nde derecha, como Donald Trump y su campa\u00f1a MAGA  (\u201cMake America Great Again\u201d) , y \nuna visi\u00f3n cr\u00edtica de la historia latinoamericana de dictaduras militares \u201cpatrocinadas\u201d \npor Estados Unidos (McIntosh & Mendoza-Denton, 2020; Rodrigo-Gin\u00e9s et al., 2024). As\u00ed, el \nframing  medi\u00e1tico de la democracia en Bolivia por parte de CNN  y BBC  se construy\u00f3 con \nestas ideas arraigadas en la cultura del p\u00fablico y el medio.\nFigura 5. \nLista de frecuencia de palabras sobre el caso en Bolivia por CNN\nFuente: Elaboraci\u00f3n propia (2025).\nEn el video \u201c Attempted coup taking place in Bolivia \u201d,  CNN  construy\u00f3 los siguientes frames  \nmedi\u00e1ticos sobre Bolivia: militares de derecha contra l\u00edderes civiles de izquierda (Frame \nConflicto) en una naci\u00f3n muy dividida en Latinoam\u00e9rica donde los golpes son comunes \n(Frame Inter\u00e9s Humano), causados   por el ej\u00e9rcito con movilizaci\u00f3n irregular (Frame \nResponsabilidad), con cr\u00edticas al apoyo de Estados Unidos a golpes anteriores en la \nregi\u00f3n (Frame Moralidad). En respuesta, como se muestra en la figura 5, los frames  de \naudiencia incluyeron principalmente palabras correspondientes a causas y juicios morales \n(Entman, 1993). Los comentarios consideraron a CIA (tercera palabra m\u00e1s frecuente en la \nsecci\u00f3n de comentarios; \u201c cia\u201d) y a Estados Unidos ( \u201cus\u201d, \u201cusa\u201d, \u201camerica \u201d) como la causa \ndel golpe (\u201c coup \u201d) en Bolivia, y juzgaron a los partidarios de Donald Trump (ej. MAGA  calls \nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d36\nthis a peaceful tourist visit ; \u201ctrump \u201d) como equivalentes a los golpistas. As\u00ed, la democracia \nboliviana fue representada en este video como dependiente o relacional con las potencias \noccidentales, o como oportunidad para burlarse de sus propias autoridades.\nFigura 6. \nLista de frecuencia de palabras sobre el caso en Bolivia por BBC\nFuente: Elaboraci\u00f3n propia (2025).\nEn el caso del video \u201c Bolivian police arrest leader of coup attempt \u201d de BBC , se consideraron \naspectos m\u00e1s locales de Bolivia en la construcci\u00f3n de los frames  medi\u00e1ticos: General \nJuan Jos\u00e9 Z\u00fa\u00f1iga vs. Luis Arce, y una tensi\u00f3n interna entre Evo Morales y Luis Arce (Frame \nConflicto), en una situaci\u00f3n tumultuosa de falta de d\u00f3lares y combustibles (Frame Inter\u00e9s \nHumano, Frame Consecuencias Econ\u00f3micas), con el General como responsable del posible \ngolpe (Frame Responsabilidad). A diferencia de CNN , BBC  incluy\u00f3 el frame  Consecuencias \nEcon\u00f3micas, generalmente relacionado con la cr\u00edtica de los defectos del modelo de \ngobierno vigente (Semetko & Valkenburg, 2000). Como se ve en la figura 6, los frames  \nde audiencia fueron casi id\u00e9nticos a los de CNN , con CIA (palabra m\u00e1s frecuente; \u201ccia\u201d) \ny Estados Unidos ( \u201cus\u201d, \u201camerica\u201d ) causando el golpe (\u201c coup \u201d) buscando el control por el \nrecurso litio (\u201clithium\u201d), juzgando que han fracasado (\u201c failed \u201d) en su misi\u00f3n. Como excepci\u00f3n, \ndos de los veinte comentarios m\u00e1s gustados elogiaron a Bolivia por su valent\u00eda y por \ndefender su democracia con el poder popular (\u201c democracy \u201d). En general, en este video se \npresent\u00f3 la democracia de Bolivia como tumultuosa y dependiente al mundo occidental, y \nal igual que CNN , como una oportunidad para criticar a las potencias occidentales.\n3.1.2 Autogolpe y MAS\nCNN  en Espa\u00f1ol y BBC  Mundo, como sus nombres lo indican, son subcuentas de CNN  \ny BBC  con un p\u00fablico diferente al original. Ambos canales est\u00e1n dirigidos a la poblaci\u00f3n \nhispanohablante, incluyendo al p\u00fablico latinoamericano, y por ello, la selecci\u00f3n de fuentes \ntambi\u00e9n incluye a personas que hablan el mismo idioma (van Zandt, 2024). Por esta raz\u00f3n, \nen noticias sobre hechos latinoamericanos, las personas del pa\u00eds en cuesti\u00f3n suelen \naparecer en los comentarios (ej. \u201cyo soy boliviano\u2026\u201d) para detallar una perspectiva local \nsobre el asunto. En este caso, el p\u00fablico boliviano coment\u00f3 en los videos centrando en los \nframes  sobre Luis Arce y el MAS.\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202537\nFigura 7. \nLista de frecuencia de palabras sobre el caso en Bolivia por CNN en Espa\u00f1ol\nFuente: Elaboraci\u00f3n propia (2025).\nEl contraste directo con la cobertura de CNN  en Espa\u00f1ol con CNN  sobre esta noticia fue \nla incorporaci\u00f3n de periodistas y abogados bolivianos como fuentes del reportaje. As\u00ed, el \nframing  medi\u00e1tico se construy\u00f3 de la siguiente manera: MAS (Evo vs. Arce) vs. General \nZ\u00fa\u00f1iga (Frame Conflicto), con una movilizaci\u00f3n que no representa una amenaza seria \npara la democracia (Frame Inter\u00e9s Humano), con el problema resuelto con el repliegue \nmilitar (Frame Responsabilidad), y la democracia boliviana en problemas no debido a la \nmovilizaci\u00f3n, sino a Evo Morales y Luis Arce (Frame Mensaje Moral). Como se observa en la \nfigura 7, los frames  de audiencia sintonizaron con el mensaje del medio e implicaron visiones \nclaras del problema, la causa y el juicio moral (Entman, 1993). Los comentarios enmarcaron \nde forma cr\u00edtica un autogolpe (ej. \u201cgolpe\u201d m\u00e1s chistoso, no hubo \u201cgolpe\u201d; \u201cautogolpe\u201d) \ndirigido por Luis Arce (\u201carce\u201d , \u201cgobierno\u201d), juzgando al MAS (\u201cevo\u201d , \u201cmorales\u201d , \u201cmas\u201d) como \nla causa de la crisis general del pa\u00eds. As\u00ed, la democracia de Bolivia qued\u00f3 representada \nen este video como problem\u00e1tica, pero no necesariamente por la movilizaci\u00f3n, sino por el \ngobierno vigente y sus tensiones pol\u00edticas.\nFigura 8. \nLista de frecuencia de palabras sobre el caso en Bolivia por BBC Mundo\nFuente: Elaboraci\u00f3n propia (2025).\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d38\nSimilar al caso encontrado en el contraste entre CNN  y CNN  en Espa\u00f1ol, BBC  Mundo \nincluy\u00f3 aspectos mucho m\u00e1s locales de Bolivia con respecto al incidente y enmarc\u00f3 lo \nsiguiente: MAS (Evo vs. Arce) vs. General Z\u00fa\u00f1iga (Frame Conflicto, Frame Responsabilidad), \nen un pa\u00eds de incertidumbre (Frame Inter\u00e9s Humano) debido a la falta de d\u00f3lares, materias \nprimas y gas (Frame Consecuencias Econ\u00f3micas), con cr\u00edtica hacia luchas pol\u00edticas que \nparalizan soluciones a la crisis econ\u00f3mica (Frame Mensaje Moral). Similar al caso de BBC  \nal cubrir este caso, hubo una inclusi\u00f3n detallada de las consecuencias econ\u00f3micas que \nevidencian la falta de competencia del gobierno vigente (Semetko & Valkenburg, 2000). En \nrespuesta, los frames  de audiencia mostraron una sinton\u00eda similar a CNN  en Espa\u00f1ol, por \nparte del p\u00fablico aparentemente boliviano. Como se muestra en la figura 8, los comentarios \nenmarcaron lo ocurrido como un autogolpe (ej. no hubo un \u201cgolpe\u201d , nunca vi un \u201cgolpe\u201d tan \npac\u00edfico; \u201cshow\u201d , \u201cautogolpe\u201d) dirigido por Luis Arce (\u201carce\u201d , \u201cgobierno\u201d), criticando al MAS \n(\u201cevo\u201d , \u201cmorales\u201d , \u201cmas\u201d). As\u00ed, la democracia boliviana en este video se represent\u00f3 como una \nincertidumbre sumada o surgida desde la crisis econ\u00f3mica, provocada por el fracaso de los \njuegos pol\u00edticos.\nEn conclusi\u00f3n, dependiendo de la caracter\u00edstica de los medios que determina las \nfuentes que enmarcan los videos y las referencias de los comentarios publicados, la \ndemocracia de Bolivia, a la luz del caso \u201cIntento de Golpe\u201d , se represent\u00f3 como una de \ndos opciones. Primero, para el p\u00fablico angloparlante, Bolivia se represent\u00f3 como una \ndemocracia dependiente de las potencias occidentales (ej. CIA, Estados Unidos ) o como \nuna oportunidad para criticar al r\u00e9gimen de derecha (ej. Trump ). Segundo, para el p\u00fablico \nhispanohablante, incluyendo a los bolivianos, Bolivia se represent\u00f3 como una democracia \nen problemas debido a que el MAS (ej. Luis Arce, Evo Morales) practicaba juegos pol\u00edticos \ncomo el autogolpe en lugar de centrarse en la crisis econ\u00f3mica.\n3.2 Democracia en Corea del Sur: Caso \u201cLey Marcial\u201d\nEl 3 de diciembre de 2024, el presidente Yoon Suk-yeol declar\u00f3 la ley marcial de emergencia, \nque permiti\u00f3 arrestos sin orden judicial junto con movilizaciones militares, condenando a las \nfuerzas comunistas dentro del pa\u00eds (Lee & Lee, 2025). Esta orden fue revocada por mayor\u00eda \nde votos en la Asamblea Nacional de Corea del Sur en pocas horas. En cuanto a la duraci\u00f3n \nde la actualizaci\u00f3n, CNN  y BBC  cubrieron este caso mucho m\u00e1s extensamente que el caso \nboliviano debido a la continua polarizaci\u00f3n dentro de Corea del Sur. Un bando declaraba \nla destituci\u00f3n del presidente y el otro la permanencia de su cargo (Sohn & Kang, 2025). En \nmedio de esta situaci\u00f3n, ambos medios presentaron mayores representaciones de Corea \ndel Sur como una utop\u00eda democr\u00e1tica, mientras algunos p\u00fablicos enmarcaron a Corea \ncomo distop\u00eda \u201cdemocr\u00e1tica\u201d.\n3.2.1 Utop\u00eda democr\u00e1tica\nCNN  y BBC , en cuanto a sus canales originales, son medios occidentales ( CNN  de Estados \nUnidos, BBC  de Inglaterra) con la obligaci\u00f3n period\u00edstica de destacar a los aliados de las \nautoridades occidentales (Rodrigo-Gin\u00e9s et al., 2024; van Zandt, 2024). Por lo tanto, en la \nnarrativa de \u201cnosotros\u201d contra \u201cellos\u201d (Semetko & Valkenburg, 2000), ambos medios tend\u00edan \na considerar a Corea del Sur como \u201cnosotros\u201d , una naci\u00f3n democr\u00e1ticamente fortalecida, y \na \u201cellos\u201d como estas irregularidades, ya fueran dictaduras o fuerzas comunistas. Adem\u00e1s, \nal ser el idioma base de estos canales el ingl\u00e9s, muchos surcoreanos (ej. \u201cI\u2019m Korean...\u201d) \nescribieron en ingl\u00e9s sus perspectivas locales en la secci\u00f3n de comentarios. En este \ncontexto, CNN  y BBC  representaron la democracia de Corea del Sur mucho m\u00e1s como una \nsociedad ut\u00f3pica en defensa de una democracia ideal.\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202539\nFigura 9. \nLista de frecuencia de palabras sobre el caso en Corea del Sur por CNN\nFuente: Elaboraci\u00f3n propia (2025).\nUna observaci\u00f3n inmediata en este framing  medi\u00e1tico fue la cantidad de participaci\u00f3n, lo \nque evidenci\u00f3 un mayor inter\u00e9s del p\u00fablico de CNN  por esta noticia que al caso boliviano. \nEl video titulado \u201c South Korean president declares emergency martial law \u201d obtuvo el mayor \nn\u00famero de comentarios (8,498) entre todos los videos de la muestra. CNN  construy\u00f3 los \nsiguientes frames  medi\u00e1tico en este video apoyado por un periodista surcoreano: el \npresidente Yoon contra el partido de la oposici\u00f3n con dos tercios del Parlamento (Frame \nConflicto), donde un presidente Yoon altamente impopular (Frame Responsabilidad, \nFrame Mensaje Moral) caus\u00f3 una interrupci\u00f3n en una naci\u00f3n que se encontraba entre \nlos bastiones del gobierno democr\u00e1tico (Frame Inter\u00e9s Humano). En respuesta, muchos \nsurcoreanos construyeron frames  de audiencia basados   en problemas, causas, juicios \nmorales y remedios (Entman, 1993). Basados en su inter\u00e9s, elaboraron la idea de que un \nacto impensable ocurri\u00f3 en Corea del Sur (Frame Problema), con el presidente Yoon como \n\u00fanico responsable (Frame Causa), juzg\u00e1ndolo de incompetente y manipulador (Frame \nJuicios Morales) y presentando la soluci\u00f3n a trav\u00e9s del poder popular (Frame Remedios). \nComo se observa en la figura 9, las palabras construyeron una narrativa de h\u00e9roes contra \nvillanos, marcadamente dividida entre los que amenazan la democracia ( \u201cpresident\u201d, \u201cnorth\u201d, \n\u201ctrump\u201d ) y los que la protegen ( \u201ckorean\u201d, \u201cpeople\u201d, \u201cdemocracy\u201d ). As\u00ed, este video represent\u00f3 \nla democracia de Corea del Sur como un ideal ut\u00f3pico, en el que la naci\u00f3n se fortalece y \nprotege contra quienes la interrumpen.\nFigura 10. \nLista de frecuencia de palabras sobre el caso en Corea del Sur por BBC\nFuente: Elaboraci\u00f3n propia (2025).\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d40\nLa noticia de BBC  sobre el caso, \u201c South Korea crisis - President lifts martial law in humiliating \nU-turn \u201d , mostr\u00f3 un framing  medi\u00e1tico similar al de CNN  por su sesgo ideol\u00f3gico (Entman, \n2007). La noticia enmarc\u00f3 el hecho de la siguiente manera: presidente Yoon con apoyo \nmilitar contra el partido de la oposici\u00f3n con mayor\u00eda en el Parlamento (Frame Conflicto), \ncon manifestantes que defend\u00edan una democracia estable (Frame Inter\u00e9s Humano), contra \nel impopular, desesperado y amargado presidente Yoon (Frame Responsabilidad, Frame \nMensaje Moral). Como respuesta, muchos comentarios que se revelaban como surcoreanos, \nconstruyeron principalmente frames  de juicio moral en base al contexto de las palabras \nmostradas en figura 10: el presidente Yoon como villano (ej. degenerate, crazy, useless; \n\u201cpresident\u201d, \u201cyoon\u201d ) y las personas como h\u00e9roes (ej. proud, strong, courage; \u201cdemocracy\u201d, \n\u201cpeople\u201d) . De esta manera, como CNN , BBC  tambi\u00e9n se hizo eco de la democracia en Corea \ndel Sur como una democracia estable interrumpida por un presidente impopular quien fue \nsilenciado por el pueblo.\n3.2.2 Distop\u00eda \u201cdemocr\u00e1tica\u201d\nCNN  en Espa\u00f1ol y BBC  Mundo, en relaci\u00f3n con este caso en particular, construyeron \nframes  medi\u00e1ticos muy similares a sus contrapartes originales (\u201cutop\u00eda democr\u00e1tica\u201d). \nSin embargo, la observaci\u00f3n notable se encontr\u00f3 en el proceso del framing  medi\u00e1tico, \nentre el p\u00fablico hispanohablante que discrepaba de los canales y presentaba sus propias \nrepresentaciones de Corea del Sur como una distop\u00eda. Y si coincid\u00edan con el medio, no era \nnecesariamente por la democracia surcoreana, sino por el apoyo hacia el canal.\nFigura 11. \nLista de frecuencia de palabras sobre el caso en Corea del Sur por CNN en Espa\u00f1ol\nFuente: Elaboraci\u00f3n propia (2025).\nEn el video de CNN  en Espa\u00f1ol, \u201c\u00bfQu\u00e9 est\u00e1 pasando en Corea del Sur? Ley marcial, \noposici\u00f3n y reacciones\u201d , el medio construy\u00f3 frames  medi\u00e1ticos muy similares a los de su \ncanal original: presidente Yoon vs. partido de oposici\u00f3n con mayor\u00eda en el Parlamento \n(Frame Conflicto), impopular y escandaloso presidente Yoon (Frame Responsabilidad, \nFrame Mensaje Moral), lo que provoc\u00f3 un hecho in\u00e9dito en la democracia floreciente de \nCorea del Sur (Frame Inter\u00e9s Humano). Sin embargo, como se observa en la figura 11, el \np\u00fablico hispanohablante se burl\u00f3 de este frame , juzgando que Corea del Sur no tiene una \ndemocracia real (ej. esa es la \u201cdemocracia\u201d , cuando conviene; \u00bfcu\u00e1l \u201cdemocracia\u201d?; \u201cgolpe\u201d , \n\u201cdictadura\u201d), y es el medio (\u201c cnn \u201d) el que construye una representaci\u00f3n de la democracia \nen Corea del Sur superior a la de Latinoam\u00e9rica. Este fue un ejemplo de que el medio y su \np\u00fablico no necesariamente entraron en sinton\u00eda en la representaci\u00f3n (Aar\u00f8e, 2017). As\u00ed, en \neste video, aunque el medio represent\u00f3 a Corea del Sur como una democracia floreciente, \nel p\u00fablico lo represent\u00f3 como una falsa democracia construida.\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202541\nFigura 12. \nLista de frecuencia de palabras sobre el caso en Corea del Sur por BBC Mundo\nFuente: Elaboraci\u00f3n propia (2025).\nOtro ejemplo notable fue el video \u201cLa ley marcial que desat\u00f3 la peor crisis de las \u00faltimas \nd\u00e9cadas en Corea del Sur\u201d de BBC  Mundo. En este video, se cre\u00f3 una sinton\u00eda entre \nel video y los comentarios, pero por un motivo diferente. BBC  Mundo, dirigido por una \nperiodista ecuatoriana, construy\u00f3 los siguientes frames  medi\u00e1ticos: presidente Yoon vs. \npartido de oposici\u00f3n con la gente cotidiana (Frame Conflicto), con cientos de manifestantes \n(Frame Inter\u00e9s Humano) contra un presidente escandaloso con una popularidad baj\u00edsima \n(Frame Mensaje Moral). Los comentarios del video, a primera vista, parecieron tener una \nsinton\u00eda mayoritariamente positiva, incluyendo elogios a Corea del Sur por su democracia \n(\u201cdemocracia\u201d , \u201cpueblo\u201d). Sin embargo, las palabras \u201cgracias\u201d y \u201cexcelente\u201d en la figura 12 \nen realidad eran elogios a la periodista ecuatoriana, sin comentarios sobre Corea del Sur. 13 \nde los 20 comentarios m\u00e1s gustados fueron elogios a la periodista, y 10 de ellos ni siquiera \nmencionaron a Corea del Sur. Los dem\u00e1s comentarios incluyeron reflexiones similares a las \nde CNN  en Espa\u00f1ol, calificando a Corea del Sur de estar en serios problemas de \u201cgolpe\u201d. As\u00ed \npues, este fue un ejemplo de un framing  medi\u00e1tico con \u201cfans\u201d repitiendo frames  del medio, \nfuera period\u00edstico o no (Lewis, 2019). Aun as\u00ed, en este video se represent\u00f3 a Corea del Sur \ncomo una democracia firmemente ligada al poder popular.\nEn conclusi\u00f3n, a la luz del caso \u201cLey Marcial\u201d en Corea del Sur, tanto CNN  como BBC  \nconstruyeron frames  medi\u00e1ticos de una utop\u00eda democr\u00e1tica basada en sus sesgos \nideol\u00f3gicos y aliados estrat\u00e9gicos (Rodrigo-Gin\u00e9s et al., 2024; Tuchman, 1983). En estos \nmedios, Corea del Sur se presentaba como una democracia estable, floreciente y \nprotegida por el pueblo, con una cr\u00edtica directa y personal al enemigo de la democracia, \nconcretamente al presidente Yoon. Por otro lado, entre el p\u00fablico hispanohablante, exist\u00eda \notra visi\u00f3n de Corea del Sur como una distop\u00eda fabricada para parecer una utop\u00eda. Esta \nvisi\u00f3n representaba a Corea del Sur como una distop\u00eda con un golpe, una dictadura como la \nde Latinoam\u00e9rica, pero protegida por los medios internacionales en su discurso.\n4. DISCUSI\u00d3N Y CONCLUSIONES\nLa presente investigaci\u00f3n se inici\u00f3 con la siguiente pregunta: \u00bfC\u00f3mo representan los medios \ninternacionales en YouTube  junto con su p\u00fablico la democracia en Bolivia y en Corea del Sur \na partir de los casos identificados como \u201ccrisis democr\u00e1tica\u201d? La respuesta es\u2014depende. \nEn base a las premisas b\u00e1sicas de la introducci\u00f3n de que depende del sesgo medi\u00e1tico y \nla cr\u00edtica p\u00fablica, los resultados demostraron \u00e1reas espec\u00edficas de discusi\u00f3n: (1) El lenguaje \ny la cultura como potenciadores y limitadores de la representaci\u00f3n de la democracia. (2) El \ndiscurso de \u201cnosotros\u201d vs. \u201cellos\u201d en el panorama global de la democracia.\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d42\nLos pensamientos pueden ser representados de infinitas maneras y utilizando \nlos lenguajes disponibles por los sujetos [\u2026] Tambi\u00e9n est\u00e1n presentes elementos \nde la tradici\u00f3n o las cosmovisiones con las cuales ha crecido. Estas son formas \nconstitutivas de la identidad cultural que son representadas de acuerdo con \nconcepciones profundas de tiempo y espacio, o de la posici\u00f3n del \u201cser humano\u201d \nfrente a la naturaleza y a sociedad. (Guardia Crespo, 2021, pp. 44-45)\nAunque la presente investigaci\u00f3n solo consider\u00f3 dos medios ( CNN , BBC  y sus versiones en \nespa\u00f1ol), la investigaci\u00f3n mostr\u00f3 al menos cuatro p\u00fablicos diferentes: (1) estadounidenses \ny europeos de habla inglesa; (2) latinoamericanos generales de habla espa\u00f1ola; (3) \nsurcoreanos de habla inglesa; y (4) bolivianos de habla espa\u00f1ola. As\u00ed, el lenguaje y el \ncontexto cultural de cada uno de estos grupos de sujetos, consciente o inconscientemente, \norientaron sus posiciones frente a la realidad (Guardia Crespo, 2021). Tomando el ejemplo \ndel caso \u201cIntento de Golpe\u201d , el p\u00fablico (1) habl\u00f3 en el lenguaje de CIA, Trump y Estados \nUnidos para el caso boliviano. El p\u00fablico (4) habl\u00f3 en el lenguaje del MAS, Arce, Evo y el \nautogolpe para el caso boliviano. Tomando como ejemplo el caso de la \u201cLey Marcial\u201d , el \np\u00fablico (3) elogi\u00f3 a Corea con el lenguaje de la ley marcial y el poder popular, mientras que \nel p\u00fablico (2) cuestion\u00f3 a Corea en el lenguaje de la dictadura y el golpe. Las construcciones \nde la representaci\u00f3n fueron dependientes del lenguaje y la cultura.\nEntonces, \u00bfc\u00f3mo fue esto un potenciador o limitador de la representaci\u00f3n de democracia? \nEn primer lugar, fue un potenciador porque incorporaron perspectivas locales sobre un \nconflicto extranjero. As\u00ed, CNN  en Espa\u00f1ol pod\u00eda traer periodistas y p\u00fablicos bolivianos \npara brindar m\u00e1s detalles del caso del \u201cIntento de Golpe\u201d , y CNN  pod\u00eda traer periodistas y \np\u00fablicos surcoreanos que hablan ingl\u00e9s para el caso de la \u201cLey Marcial\u201d. En segundo lugar, \nfue un limitador porque desconect\u00f3 a las personas que no hablan el mismo lenguaje. Por \nlo tanto, la discusi\u00f3n sobre el \u201cautogolpe vs. golpe\u201d de Bolivia no fluir\u00eda f\u00e1cilmente en el \np\u00fablico (1) y (3). No es un hecho imposible como tal como se demostr\u00f3 en los resultados, \npero las caracter\u00edsticas propias de la plataforma de YouTube  dificulta la transmisi\u00f3n de \nopiniones divergentes y facilita la creaci\u00f3n de c\u00e1maras de eco (Cinelli et al., 2021; Terren \net al., 2021). Esta fue la raz\u00f3n por la que los 20 comentarios m\u00e1s gustados en los videos \neran mayoritariamente en el mismo lenguaje, por lo que incluso si hubiera otros intentando \nintegrarse en la discusi\u00f3n, ser\u00edan excluidos algor\u00edtmica y colectivamente.\nPara contar algo es necesario narrar, organizar ideas, priorizar temas centrales y \narmar estructuras que permitan al orador dar sentido a la \u201chistoria\u201d que se quiere \ntransmitir. En ese proceso interviene toda esa compleja cantidad de componentes \nde la cultura humana basada en sensorialidad, emotividad y conocimientos que \nconfiguran las percepciones. (Guardia Crespo, 2021, p. 47)\nEl segundo punto de discusi\u00f3n es el discurso de \u201cnosotros\u201d vs. \u201cellos\u201d en el panorama \nglobal de la democracia. La representaci\u00f3n de la democracia es una imposici\u00f3n basada \nen intereses divergentes y depende de dar sentido a una crisis mediante una narrativa \n(Zavaleta Mercado, 2009). Uno de los frames  medi\u00e1ticos m\u00e1s comunes encontrados en los \nvideos fue el Frame Conflicto, basado en la narrativa de \u201cnosotros\u201d versus \u201cellos\u201d (Semetko \n& Valkenburg, 2000). Para los frames  de audiencia, los m\u00e1s comunes fueron el Frame \nCausas y el Frame Juicios Morales, que abordaron el \u201cqui\u00e9n\u201d y el \u201cc\u00f3mo\u201d en la comprensi\u00f3n \nde la situaci\u00f3n (Entman, 1993). As\u00ed, juntos, estos medios y p\u00fablicos crearon narrativas de \n\u201cenemigos\u201d y \u201camigos\u201d en cuanto a la representaci\u00f3n de la democracia que desearon \nofrecer. \nCNN  y BBC , en el caso de la \u201cLey Marcial\u201d , afiliados con el sesgo ideol\u00f3gico de aliarse con \nCorea del Sur, tuvieron mucha m\u00e1s seguridad al narrar un nosotros, el \u201cpueblo\u201d , versus \nellos, el \u201cpresidente\u201d. O, en el caso de \u201cIntento de Golpe\u201d , CNN  en Espa\u00f1ol y BBC  Mundo \npresentaron la lucha pol\u00edtica del MAS como el enemigo de la democracia. Una tendencia \nsimilar se encontr\u00f3 en los comentarios. Los estadounidenses y europeos criticaron a CIA y \nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202543\nTrump, los surcoreanos al presidente Yoon, mientras que los bolivianos atacaban al MAS \ncomo el obst\u00e1culo a la democracia. La misma din\u00e1mica explica el \u201cfandom\u201d de BBC  Mundo \n(\u201cnuestra periodista\u201d) o el cuestionamiento de Corea del Sur como una distop\u00eda (\u201cellos\u201d). Lo \nque esto demuestra es que existen m\u00faltiples representaciones de la democracia, incluso \ndentro del mismo p\u00fablico, pero tambi\u00e9n existe una intenci\u00f3n colectiva de simplificar la \nrealidad a trav\u00e9s de esta perspectiva binaria.\nLa crisis es una revelaci\u00f3n social, y las lecciones aprendidas de ella proporcionan \nreferencias para futuras transformaciones de la sociedad (Zavaleta Mercado, 2009). La \npresente investigaci\u00f3n se centr\u00f3 en dos casos espec\u00edficos de esta revelaci\u00f3n a trav\u00e9s \nde la representaci\u00f3n de la democracia en los medios internacionales, y encontr\u00f3 que el \nlenguaje, la cultura y el discurso del \u201cnosotros\u201d vs. \u201cellos\u201d son factores relevantes en su \nconstrucci\u00f3n. Desde el momento de la difusi\u00f3n de estos eventos, la representaci\u00f3n de \nuna \u201ccrisis democr\u00e1tica\u201d , ya sea con un enfoque institucional (ej. la crisis econ\u00f3mica en \nBolivia) o poblacional (ej. la crisis pol\u00edtica en Corea del Sur tras la destituci\u00f3n formal del \npresidente Yoon), fue retomada y reformulada en los medios internacionales. Por lo tanto, la \nrecomendaci\u00f3n para futuras investigaciones es continuar monitoreando la construcci\u00f3n de \nla representaci\u00f3n de la democracia en casos de todo el mundo, considerando lo siguiente: \n(1) Investigar el framing  period\u00edstico adem\u00e1s del medi\u00e1tico, considerando la entrevista a \nperiodistas y al p\u00fablico como t\u00e9cnica de investigaci\u00f3n (Entman et al., 2009). (2) Incluir medios \nlocales que utilizan el lenguaje del p\u00fablico en la muestra para un an\u00e1lisis comparativo. (3) \nPrestar atenci\u00f3n al resurgimiento de ciertos grupos e individuos, reforzados por los medios y \nel p\u00fablico como \u201cnosotros\u201d y \u201cellos\u201d. En conclusi\u00f3n, la representaci\u00f3n de la democracia tanto \npor los medios como por el p\u00fablico est\u00e1 siempre en evoluci\u00f3n y transformaci\u00f3n. Lo que no \ncambia, sin embargo, es la constante necesidad de un di\u00e1logo directo con las personas \nque viven en estos mundos de referencialidad para conversar sobre sus encuadres de la \nrealidad.\nNotas\n1. Prompt:  \u201cEstoy tomando en cuenta los siguientes frames  medi\u00e1ticos en mi investigaci\u00f3n \ncon los respectivos elementos de identificaci\u00f3n. (1) Frame Conflicto: Incluye -presentaci\u00f3n \nde lados (referencia a dos lados o a m\u00e1s de dos lados del problema), -desacuerdos \n(un desacuerdo entre partidos, individuos, grupos y pa\u00edses), -reproches (un partido, \nindividuo, grupo o pa\u00eds haciendo reproches a otro), -ganadores (referencia a ganadores \ny perdedores). (2) Frame Inter\u00e9s Humano: Incluye expresiones de -ejemplo de rostro \nhumano (un ejemplo humano del tema), -sentimiento (expresiones de indignaci\u00f3n, \nempat\u00eda, simpat\u00eda o compasi\u00f3n), -poblaci\u00f3n afectada (c\u00f3mo los individuos y los grupos \nse ven afectados por el problema) y -vida privada (adentrar en la vida privada o personal \nde los actores). (3) Frame Consecuencias Econ\u00f3micas: Incluye -presentaci\u00f3n de p\u00e9rdida/\nganancia (las p\u00e9rdidas o ganancias financieras actuales o futuras), -costo (los costos o el \ngrado de gasto involucrados) y -consecuencias econ\u00f3micas (consecuencias econ\u00f3micas \nde seguir o no seguir un curso de acci\u00f3n). (4) Frame Moralidad: Incluye presentaci\u00f3n de \n-mensaje moral (una expresi\u00f3n apelando a la \u00e9tica y moral), -Dios (referencia a Dios y a \notros principios religiosos) o -prescripci\u00f3n moral (prescripciones sociales espec\u00edficas sobre \nc\u00f3mo comportarse). (5) Frame Responsabilidad: Incluye presentaci\u00f3n de los -responsables \n(alg\u00fan nivel de gobierno o una persona responsable del problema), -capacidad de aliviar \nel problema (alg\u00fan nivel de gobierno con la capacidad de aliviar el problema), -soluci\u00f3n \n(sugerencia de soluciones al problema) o -sugerencia de acci\u00f3n urgente (sugerir que el \nproblema requiere una acci\u00f3n urgente). Ay\u00fadame a codificar los siguientes textos en base \na estos c\u00f3digos. Si no es 100% claro, expl\u00edcito y argumentable por citas directas en el texto, \nno lo incluyes, simplificas la redacci\u00f3n a nivel de codificaci\u00f3n.\u201d\n2. Prompt: \u201cEstoy tomando en cuenta los siguientes frames  de audiencia en mi investigaci\u00f3n \ncon los respectivos elementos de identificaci\u00f3n. (1) Frame Problemas: Incluye -acci\u00f3n (lo \nque hace el agente causal), -costo/beneficio (costos y beneficios del problema), -necesidad \nde cambio (aspectos de vida en necesidad de cambio dentro del problema), -diagn\u00f3stico \nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d44\n(diagn\u00f3stico del evento como problem\u00e1tico). (2) Frame Causas: Incluye -fuerzas (todas las \nfuerzas en problema), -creador (fuerza creadora del problema), -factor (fuerzas que aportan \nal problema) y -responsabilidad (pesos diferenciados en la responsabilidad de actores). (3) \nFrame Juicios Morales: Incluye -agente (evaluaci\u00f3n de agente causal del problema), -efecto \n(evaluaci\u00f3n de efectos de agentes causales), -visi\u00f3n del problema (visi\u00f3n compartida del \nproblema) y -llamada de acci\u00f3n (instrucci\u00f3n de llamada de acci\u00f3n). (4) Frame Remedios: \nIncluye presentaci\u00f3n de -tratamiento (tratamiento para problema), -predicci\u00f3n (posibles \nefectos), -acci\u00f3n correctiva (acciones correctivas para llegar a un consenso), -necesidad \nde soluci\u00f3n (descripci\u00f3n de necesidades colectivas de soluci\u00f3n). Ay\u00fadame a codificar los \nsiguientes textos en base a estos c\u00f3digos. Si no es 100% claro, expl\u00edcito y argumentable por \ncitas directas en el texto, no lo incluyes, simplificas la redacci\u00f3n a nivel de codificaci\u00f3n.\u201d\nReferencias bibliogr\u00e1ficas\nAar\u00f8e, L. (2017). Framing : Audience Frames . En P. R\u00f6ssler, C. A. Hoffner, & L. Zoonen (Eds.), \nThe International Encyclopedia of Media Effects  (1.a ed., pp. 1-9). Wiley. https:/ /doi.\norg/10.1002/9781118783764.wbieme0049\nAhmad, M., & Wilkins, S. (2024). Purposive sampling in qualitative research: A framework for the \nentire journey. Quality & Quantity . https:/ /doi.org/10.1007/s11135-024-02022-5\nAlem\u00e1n-Andrade, A., & Jim\u00e9nez, C. (2021). Gu\u00eda de consideraciones \u00e9ticas de investigaci\u00f3n \nsocial y de Comunicaci\u00f3n.  Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d Unidad \nAcad\u00e9mica Regional Cochabamba.\nAndrade, A. A., Pedriel, L. P., Baltazar, M. P., & Copa, A. O. (2022). Los tweets de la democracia. \nUniversidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d Sede Cochabamba.\nAruguete, N. (2017). Agenda setting y framing : Un debate te\u00f3rico inconcluso . M\u00e1s Poder Local, \n30, 36-42.\n\u00c1vila S\u00e1nchez, E. (2020). Los nuevos ecosistemas medi\u00e1ticos y las nuevas narrativas: Una \noportunidad para el periodismo transmedia y crossmedia en Bolivia. Revista Punto \nCero, 25 (40), 75-88. https:/ /doi.org/10.35319/puntocero.20204016\nBernal Torres, C. A. (2016). Metodolog\u00eda de la investigaci\u00f3n.  Pearson Educaci\u00f3n de Colombia.\nCentro de Documentaci\u00f3n e Informaci\u00f3n Bolivia. (2024). Pantomima de Golpe en Bolivia, \nan\u00e1lisis de los hechos ocurridos el 26 de junio de 2024.  CEDIB Informa,  2024 (2), 1-6.\nCinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, W., & Starnini, M. (2021). \nThe echo chamber effect on social media.  Proceedings of the National Academy of \nSciences, 1 18 (9), e2023301118. https:/ /doi.org/10.1073/pnas.2023301118\nD\u2019Angelo, P. (2017). Framing : Media Frames . En P. R\u00f6ssler, C. A. Hoffner, & L. Zoonen (Eds.), \nThe International Encyclopedia of Media Effects  (1.a ed., pp. 1-10). Wiley. https:/ /doi.\norg/10.1002/9781118783764.wbieme0048\nEntman, R. (1993). Framing : Toward Clarification of a Fractured Paradigm. Journal of \nCommunication, 43 (4), 51-58. https:/ /doi.org/10.1111/j.1460-2466.1993.tb01304.x\nEntman, R. (2007). Framing  Bias: Media in the Distribution of Power. Journal of Communication, \n57(1), 163-173. https:/ /doi.org/10.1111/j.1460-2466.2006.00336.x\nEntman, R. (2010). Framing  media power. En Doing news framing analysis: Empirical and \ntheoretical perspectives  (1. publ, pp. 331-355). Routledge.\nPunto Cero a\u00f1o 30  n\u00b0 50 Junio de 202545\nEntman, R., Matthes, J., & Pellicano, L. (2009). Nature, sources, and effects of news framing . En \nThe handbook of journalism studies  (pp. 175-190). Routledge.\nGracia Landaeta, O., Chipana Vedia, M. A., & Flores Meruvia, E. (2022). Naci\u00f3n, comunicaci\u00f3n y \nesfera p\u00fablica: Sobre la tensi\u00f3n entre nacionalismo y convivencia democr\u00e1tica. Revista \nPunto Cero, 27 (45), 9-25. https:/ /doi.org/10.35319/puntocero.20224517\nGuardia Crespo, M. (2021).  Mundos de referencialidad: El entorno comunicacional \ncontempor\u00e1neo.  Coordinaci\u00f3n de Investigaci\u00f3n de Sede.\nLee, J., & Lee, D. (2025). 2024 South Korean martial law crisis: Lessons for the democratic \nresilience.  Australian Journal of International Affairs,  1-8. https:/ /doi.org/10.1080/1035\n7718.2025.2458697\nLewis, R. (2019). \u201cThis Is What the News Won\u2019t Show You\u201d: YouTube  Creators and the Reactionary \nPolitics of Micro-celebrity. Television & New Media, 21 (2), 201-217.\nMaher, B. (2022, junio 29). Revealed: The biggest English-language news outlets on Youtube and \ntheir most popular videos. Press Gazette.  https:/ /pressgazette.co.uk/media-audience-\nand-business-data/biggest-news-youtube/\nMatthes, J., & Kohring, M. (2008). The Content Analysis of Media Frames : Toward Improving \nReliability and Validity.  Journal of Communication, 58( 2), 258-279. https:/ /doi.\norg/10.1111/j.1460-2466.2008.00384.x\nMcIntosh, J., & Mendoza-Denton, N. (2020).  Language in the Trump era: Scandals and \nemergencies.  Cambridge University press.\nMinisterio de Gobierno Bolivia. (2024, junio 30). Cronolog\u00eda del golpe de Estado fallido contra \nel Gobierno Nacional  [Post]. Facebook. https:/ /www.facebook.com/MindeGobierno/\nposts/cronolog%C3%ADa-del-golpe-de-estado-fallido-contra-el-gobierno-nacional-\ndetallando-la/813129244247340/\nNewman, N., Fletcher, R., Robertson, C. T., Arguedas, A. R., & Nielsen, R. K. (2024). Reuters \nInstitute Digital News Report 2024.\nOpini\u00f3n. (2024, junio 28).  \u2018Golpe fallido\u2019, \u2018autogolpe\u2019 y una tercera teor\u00eda; piden investigar . Opini\u00f3n \nBolivia. https:/ /www.opinion.com.bo/articulo/pais/golpe-fallido-autogolpe-tercera-\nteoria-piden-investigar/20240628000049949058.html\nOrtiz Gonz\u00e1lez, A., Berganza, R., & Herrero-Jim\u00e9nez, B. (2024). La polarizaci\u00f3n ideol\u00f3gica de \nlos periodistas espa\u00f1oles ante la corrupci\u00f3n institucional. Revista de Comunicaci\u00f3n. \nhttps:/ /doi.org/10.26441/RC23.2-2024-3589\nRodrigo-Gin\u00e9s, F.-J., Carrillo-de-Albornoz, J., & Plaza, L. (2024). A systematic review on media \nbias detection: What is media bias, how it is expressed, and how to detect it. Expert \nSystems with Applications, 237,  121641. https:/ /doi.org/10.1016/j.eswa.2023.121641\nRodr\u00edguez Fuentes, R. (2021). J\u00f3venes, crisis y democracia: Tensiones y puentes entre \nComunidad Ciudadana y el MAS-IPSP (2019-2020).  Revista Punto Cero, 26 (43), 25-39. \nhttps:/ /doi.org/10.35319/puntocero.202143178\nSamsudin, D. (2019). Understanding the Models of Framing  Analyses Approaches in Media \nFraming  Studies: Proceedings of the Second International Conference on Social, Economy, \nEducation and Humanity,  385-389. https:/ /doi.org/10.5220/0009159503850389\nISSN 2224-8838Universidad Cat\u00f3lica Boliviana \u201cSan Pablo\u201d46\nSemetko, H. A., & Valkenburg, P. M. V. (2000). Framing  European politics: A Content Analysis \nof Press and Television News.  Journal of Communication, 50 (2), 93-109. https:/ /doi.\norg/10.1111/j.1460-2466.2000.tb02843.x\nSohn, Y., & Kang, W.-T. (2025, febrero 6). How Polarization Undermines Democracy in South \nKorea.  Council of Councils. https:/ /www.cfr.org/councilofcouncils/global-memos/how-\npolarization-undermines-democracy-south-korea\nTerren, L., Open University of Catalonia, Borge-Bravo, R., & Open University of Catalonia. (2021). \nEcho Chambers on Social Media: A Systematic Review of the Literature.  Review of \nCommunication Research, 9,  99-118. https:/ /doi.org/10.12840/ISSN.2255-4165.028\nTuchman, G. (1983).  La producci\u00f3n de la noticia: Estudio sobre la construcci\u00f3n de la realidad. \nGustavo Gili.\nvan Hulst, M., & Yanow, D. (2016). From Policy \u201c Frames \u201d to \u201c Framing \u201d: Theorizing a More Dynamic, \nPolitical Approach. American Review of Public Administration, 46 (1), 92-112.\nvan Zandt, D. (2024). Media Bias/Fact Check\u2014Search and Learn the Bias of News Media. \nMediabiasfactcheck.com. https:/ /mediabiasfactcheck.com/\nVoltmer, K. (2013). The media in transitional democracies. Polity Press.\nZavaleta Mercado, R. (2009).  La autodeterminaci\u00f3n de las masas.  Siglo del Hombre Editores.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "CoupTube: framing medi\u00e1tico sobre la democracia a partir de los casos\" Bolivia: Intento de Golpe\" y\" Corea del Sur: Ley Marcial\" en CNN y BBC", "author": ["H Park"], "pub_year": "2025", "venue": "Punto Cero", "abstract": "La presente investigaci\u00f3n descriptiva tuvo como objetivo establecer el framing medi\u00e1tico de  CNN y BBC (incluidas sus versiones en espa\u00f1ol) en YouTube respecto a la democracia en"}, "filled": false, "gsrank": 751, "pub_url": "http://www.scielo.org.bo/scielo.php?pid=S1815-02762025000100029&script=sci_arttext", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:IaVEZhOZTroJ:scholar.google.com/&output=cite&scirp=750&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D750%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=IaVEZhOZTroJ&ei=jrWsaMr-H8DZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:IaVEZhOZTroJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://www.scielo.org.bo/pdf/rpc/v30n50/2224-8838-rpc-30-50-29.pdf"}}, {"title": "The Information Ecosystem of Online Groups with Anti-and Pro-vaccine Views on Facebook", "year": "2021", "pdf_data": "Title: The Information Ecosystem of Online Groups with Anti - and Pro -\nvaccine Views on Facebook  \n \nAuthors:  Soojong Kim1,2*, Kwanho Kim3,4 \nAffiliations:   \n1Cyber Policy Center, Stanford University; Stanford, CA 94305, United States.  \n2Center on Philanthropy and Civil Society , Stanford University ; Stanford, CA 94305, United \nStates.  \n3Department of Communication, Cornell University; Ithaca, NY 14853, United States.  \n4Annenberg School for Communication, University of Pennsylvania; Philadelphia, PA \n19104, United States.  \n*Corresponding author. Email: sjkim97@stanford.edu  \n \n \nAbstract : Opposit ion and hesitancy to vaccination have been one of the major threats to global \nhealth . Social media sites have been suspected as  a breeding ground of misleading  narratives \nabout vaccines , but little is known about  how pervasive anti -vaccine views  are on the world\u2019s \nlargest social media, Facebook . Here , we study  the prevalence  of online groups on Facebook \nwith anti - and pro -vaccine views and the information ecosystem that enables the production  and \ndissemination  of anti-vaccine narratives , using  the largest collection of Facebook data on this \nissue to date . The results reveal that 74% of posts  each month  on average  were generated by anti -\nvaccine groups . It is also shown that anti-vaccine groups had increasingly  more  relied on  \nrelatively credible  sources  while their posts us ing low credibility sources  were less than 2% and \nrecently decreasing . Furthermore, anti -vaccine groups depended more on  their exclusive sources \nand utilized sources representing  more conservative or far -right political views  than pro-vaccine \ngroups  did. The findings suggest that expansive and targeted interventions are urgently needed  to \ncurb the circulation of  online narratives  against  vaccination .  \nMain Text: There has been growing concern about public  distrust in science (1\u20133). Especially, \nopposit ion and hesitancy  to vaccination  have been one of the major threat s to global health , \nbecoming a significant obstacle in curbing  the COVID -19 pandemic  that has  taken over 4 million \nlives around the globe  (4\u20136). Social media services  have been  known  to fuel distrust and \nexacerbate  the \u201cinfodemic\u201d  by providing community spaces for online groups spreading \nmisleading and unsubstantiated  narratives about vaccines  (5, 7\u201310). It has been suspected that \nthe proliferation of anti -vaccine groups and content is especially severe on Facebook, the world\u2019s \nlargest social media site that has  more than  3 billion users (8, 11\u201313). However, evidence is  still \nthin about  how pervasive anti -vaccine views are on Facebook and how anti-vaccine  groups  \nproduce their false narratives  on the platform .  \nHere, we present an analysis  of 2,328 online groups  that discussed  vaccines and \nvaccinations on Facebook  between 2012 and 2020.  These groups  generated over 1.6 million \nposts  written in English  during the period  that induced  a total of over 700 million shares, \ncomments, and reactions, and th eir messages were  transmitted  over 1 40 billion times since  2018 \nto Facebook users following them  (SM S 3). We investigate the prevalence of anti - and pro -\nvaccine views among them and the information ecosystem that these groups  relied on to support \ntheir views . This research focused on t hree critical  but largely unanswered questions: How \npervasive anti-vaccine views are among online  groups discussing vaccines  and vaccination  on \nFacebook ? How dependent are these group s on information  from low credibility  sources ? How \ndo these groups with different views interact  within  the broader information ecosystem?  \nThis study leverages the largest observation  of online groups with pro- and anti -vaccine  \nviews on  Facebook , including  their recent  development  during the COVID -19 pandemic . \nPrevious research  provide d important  initial findings . Johnson et al. (11) analyzed  441 Facebook \npages with anti - and pro -vaccine views , focusing on the  connections  between them  created by \nthe page administrators . Schmidt et al. (14) collected data of 243 vaccine -related pages  on \nFacebook  and analyzed  their volume of content and number of user interaction s. Compared with \nthe past research, considerably more online groups were tracked in the current study  for a longer \ntime period , which helps us make more reliable  platform -level observation and inference  (SM \nS2). \nWe also expand  the approaches of the existing literature  by exploring  a broader \ninformation ecosystem  contributing to the production of  misleading  anti-vaccine narratives . \nPrevious  research  on online falsehood has focused on how fake news sites or stories  were  \nutilized  on social media  (15\u201318), but we need to  have a fuller understanding of online falsehood \nby examin ing a wide r range of online actors  beyond  a small set of fake news sources  (3, 15, 19, \n20). Thus, in addition to websites  supplying  misinformation (15, 17, 18), the present  research  \nexplores  how vaccine groups  interact with  other types of information sources  known to be \ncrucial  in investigating  social phenomena through the online  space, including  news sites that \nhave been viewed as  relative ly credible sources of information  (15, 17, 21\u201323), information \nsources run by government authorities  (24\u201326), and other social media  platforms , such as Twitter \nand Instagram  (27, 28).  \nIn the current study, a \u201cvaccine group\u201d refers to a community of Facebook u sers who \ncreated, consumed, and engaged with the content of a Facebook page or a Facebook group \ndiscussing vaccines and vaccination . A vaccine group can refer to people involved with either a \nFacebook page or a Facebook group . We identified each group\u2019s view  on vaccines and \nvaccination, and anti -vaccine groups were  defined as  vaccine  groups spreading misleading \nnarratives that emphasize the negative consequences of vaccinations  and encourage people to \nreject and avoid vaccines. See S1 for details . \nWe identified 2,328  vaccine groups  on Facebook during the period between January  1st, \n2012, and November 30th, 2020. Each group was  reviewed  and classified by multiple coders  into \neither anti -vaccine,  pro-vaccine,  or mixed/neutral  groups . See S2 for details.  \nAnti-vaccine views had been  dominant  among  online  group s discussing vaccines  on \nFacebook . Also, an anti-vaccine group  created more content  and stayed active for a longer period \nof time than a pro-vaccine group  on average . First, when averaged over the 107  month s, 74.1% \n(SD = 6.2%)  of all vaccine  posts  were generated  by anti-vaccine groups  each month . The \nproportion of posts created by anti-vaccine groups  steadily declined  over time  as shown in Fig. \n1A. The total number of posts  produced by vaccine groups  had increase d since 2012 , with \nnoticeable  surge s that coincid e with three major infectious disease outbreak s in the U.S.  (See \nS3.1).  Second, t he majority of vaccine  groups held anti-vaccine view s. Anti-vaccine groups \naccounted for  58.4% (SD = 2.9%) of all active vaccine groups  each month . The total number of \nactive groups has increased 5.4 times between  January 2012 and November 2020  (Fig. 1B). \nThird, an active anti-vaccine group has created 2.4 times more posts  in a year  on average  than an \nactive  pro-vaccine group  (Fig. 1D). Lastly, when the lifetime of a group, i.e., the time between \nits first and last content publication,  was computed,  the average  lifetime of anti -vaccine groups \nwas 3.3 years  (SD = 2.9 years , N = 1,083 ), and it was 1.5 times greater than that of pro-vaccine \ngroups  (M = 2.1 years, SD = 2.7 years, N = 1,206 ), as displayed in  Fig. 1E. See S3 for details.  \nConsidering Facebook users\u2019 engagement with the vaccine content, we found that anti-\nvaccine groups attracted more user engagement than pro -vaccine groups , but there was a \nnoticeable  change  recently  (Fig. 1C). The content generated by  anti-vaccine groups had been  \nshared more than pro -vaccine groups \u2019 until February 2020 , but pro -vaccine groups started \nattracting  more shares than their counterpart  since the early stage of the COVID pandemic . \nSimilarly , the proportions of c omments and reactions  received by anti -vaccine groups  also \nplummeted in 2020  after a long-term decline between 2012 and 2019 . See S 3 for details.  \n \n \nFig. 1. Prevalence  and activity  of vaccine groups.  A.  Content created by vaccine groups. A stacked bar represents the \nproportions of Facebook posts created by pro -vaccine , anti -vaccine , and mixed/ neutral groups in a given month (y -axis on the \nleft). A dot indicates the total number of posts created by all vaccine groups in a given month (y -axis on the right).  B.  Active \ngroups. A stacked bar represents the proportions of active pro -vaccine , anti -vaccine , and mixed/ neutral groups in a given \nmonth (y -axis on the left). A dot indicates the  number of all active groups in a given month (y -axis on the right). C.  Sharing of \nvaccine content . A stacked bar represents the proportions of shares that pro -vaccine , anti -vaccine , and mixed/neutral  groups \nreceived in total in a given month (y -axis on the left). A dot indicates the total number of shares in a given month (y -axis on the \nright). D. Activity level of groups. A box represents the distribution of the numbers of posts created by active pro - or anti -\nvaccine  groups in a given year. A green triangle indicates an average. A gray dot represent s an active group in a given year. E. \nLifetime duration of vaccine groups. 1 year is equal to 365 days. The solid and dashed lines represent means and medi ans, \nrespectively . \n \n\nWhat information sources do anti-vaccine groups  use to support their misleading \nnarratives ? To explore this question, we first  examined  the use of  Facebook internal sources  (i.e., \ninformation sources within the Facebook platform ) and external sources ( i.e., information  \nsources outside Facebook ) among  anti- and pro -vaccine groups . The proportion  of posts using \nFacebook internal sources ha s increased  7.0 times  among pro -vaccine groups  and 4.7 times \namong anti-vaccine groups  between 2012 and 2020 , while the use of external sources has \nsteadily decreased ( Fig. 2A). We also examined the proportions of video posts based on \nFacebook videos and YouTube videos , as an important case analysis comparing the use of \nFacebook internal sources and external sources . Consistent with th e aforementioned  patter ns, the \nproportion of video posts using Facebook videos has increased dramatically  between  2012 and \n2020  among both anti - and pro -vaccine groups , in stark contrast  to the substantial decline  in the \nproportion of YouTube video  posts (Fig. 2B). See S4 for details.  \n \n \nFig. 2. Information sources of anti- and pro -vaccine groups . A. The proportion s of posts using at least one Facebook internal \nsource in a n active  group in a given month (solid lines) and the proportion s of posts using at least one external source in a n \nactive  group in a given month (dashed lines). Blue  and red represent pro - and anti -vaccine, respectively . B. The proportion of \n\nvideo posts using Facebook videos (solid lines) and YouTube videos (dashed lines)  in a vaccine group that generated at least one \nvideo post in a given year . C. The averaged propor tions of posts using government sources in a n active anti - and pro -vaccine \ngroup  each month . Blue  and red represent pro - and anti -vaccine, respectively . D. News sources.  E. Social media sources. F. Low \ncredibility sources.  \nWe compared anti - and pro -vaccine  groups  in terms of their  reliance  on external sources  \nknown to supply misinformation  (15, 17) and other  important  types of external sources: \ngovernment sources  (24, 29), social media sources  (27, 28), and news  sources  (15, 17, 21, 22). \nAs shown in Fig. 2F, the monthly proportion of posts using low credibility sources in an anti -\nvaccine group w as generally limited with a n average of 1.7%  (SD = 0.9%) , but it was still greater \nthan the monthly average proportion in a pro -vaccine group, 0.1%  (SD = 0.05%) . Anti-vaccine \ngroups used social media sources  more frequently than pro -vaccine groups  (Fig. 2E), and their \nreliance on news sources was lower than pro -vaccine groups  (Fig. 2D). However,  we identified  \nsignificant  recent  increase s in the use of legitimate sources  among anti -vaccine groups , such as  \ngovernment  (Fig. 2C) and news sources , while their use of low credibility sources  has \nsignificantly decreased since 2016 . See S4 for details.  \nWe tested if posts  using certain types of information sources attract ed more or less \nengagement from Facebook users . As shown in  Fig. 3A and B , posts using low credibility \nsources produced 2. 4 times more shares than posts not using these sources , adjusting for \ncovariates . On the other hand, posts using  government sources  received 5 2% fewer shares than \nposts not using  these sources, and posts using social media sources attracted  55% fewer shares  \nthan posts without  the sources . Notably, these associations were consistent  for other measures of \nuser engagement , comments and reactions , as shown in Fig. 3C and D . See S5 for details.  \n \n \nFig. 3. Models estimating associations between the use of information sources and user engagement s. A. Associations \nbetween the use of different source types in a post and the number of shares of the post. A dot and a n error  bar indicate the \nmean and the 95% confidence interval (CI) of an incidence rate ratio (IRR). Social, social media sources other than Facebook; \nLow cred, low credibility sources; Other, sources  not classified into the first five types . N = 1,446,27 5.  B. Results of a negative \nbinomial model estimating the number of shares of a post as a function of variables shown in the leftmost column. Coef, \nregression coefficient; z, z score. All standard errors were clustered at the vaccine group level, and all models we re estimated \n\nwith cluster -robust standard error at the vaccine group level.  C. Associations between source types and comments.  D. \nAssociations between source types and reactions.  \nHow do anti- and pro -vaccine groups interact  within  the broader  ecosystem?  First, we \nexamined how  many information sources were  shared between  anti- and pro -vaccine groups.  For \nthis purpose, exclusive sources for anti -vaccine  [pro-vaccine]  groups  were defined as \ninformation sources used only by five or more vaccine  groups  with the same views  in a given \nmonth . When averaged over the 107  months , exclusive sources accounted for 19.3% of all \ninformation sources used by an anti-vaccine group  in a month  (SD = 4.1%, Fig. 4A), while  \nexclusive sources  for pro -vaccine groups  were  only 3.1% of all sources  that a pro -vaccine group \nused each month  (SD = 1.5%, Fig. 4B) (30). See S6 for details . Second, we investigated if \nvaccine groups with different view s relied on media sources emphasizing different values and \nbeliefs . An anti -vaccine affinity score  was calculated  for each information source , which \nindicates the degree to which a source was used more widely by anti-vaccine groups than pro-\nvaccine groups  (SM S7). We found that source s representing  more conservative  and far -right  \npolitical views  were  more widely used  by anti -vaccine groups , as the  significant and positive \ncorrelation  shown in Fig. 4C indicates.  Lastly, we investigated the  network of vaccine groups \nbased on URL links  between  them.  As the diagram in  Fig. 4D shows , vaccine groups displayed  \ninsular patterns of interactions , forming two dense clusters separated  from each other. \nSpecifically, t he cross -cutting connections  between vaccine groups were only 5.3% (SD = \n15.6% , N = 744 ) and 11.0% (SD = 22.7% , N = 410 ) of all connections that an anti- and a pro-\nvaccine group made with other  groups , respectively , in the largest connected component  (SM \nS8). \nThe current research studied  the activities of online groups with different  views  on \nvaccine s and the information ecosystem  enabling the production of misleading anti-vaccine  \nnarratives . The results  demonstrated  that anti -vaccine groups ha d dominat ed Facebook  in terms \nof the number of groups and the volume of content generated , which is aligned with previous  \nreports  based on smaller observations (11, 14). The analysis  showe d that anti-vaccine groups \nrelied more on low credibility sources  than pro-vaccine groups  did, but these sources  were not \nwidely  used on both sides . Anti-vaccine groups also utilized social media sources more than pro -\nvaccine groups  did, but their use of more legitimate sources, such as government sources and \nnews sources , has also increased in recent years . Lastly, w e discovered that  the set of information \nsources used by anti -vaccine groups is , not only  considerably segregated  from those utilized  by \npro-vaccine groups , but also likely to  represent more  conservative  and far -right  viewpoints  than \npro-vaccine groups\u2019 sources . \n \nFig. 4. Anti - and pro -vaccine groups  within the information ecosystem . A. Exclusive sources  for anti -vaccine groups . The height \nof each bar indicates t he proportion of exclusive sources  for anti -vaccine groups  among all  information  sources  in an anti -\nvaccine  group , averaged across all anti -vaccine groups  using at least one source  in a given month . The red, blue, green, purple , \nand brown,  portions of a bar represent the proportions of exclusive low credibility, social media, government, news,  and other \nsources  respectively , in a n anti-vaccine group . B. Exclusive sources  for pro -vaccine groups . C. Association between the \nideological  alignment and anti -vaccine affinity of sources.  Each circle represents an information source.  Ideology alignment \nscores were adopted from Bakshy et al.  (21). The color of a circle depends on the source\u2019s  anti-vaccine affinity.  The size of a \ncircle is proportional to the average popularity  of a source . The solid line represents the linear regre ssion  line relating the two \nscores, and the shade represents the 95% CI of its slope . \u03c1 is the Spearman rank correlation between the two scores . N = 327 . \nSee S7 for details . D. The v accine group network within Facebook. The diagram shows the largest connected component \nincluding 1,0 59 vaccine groups. The red , blue , gray  circles are anti -vaccine,  pro-vaccine , and mixed/neutral  groups, respectively . \nAn edge indicates that two groups wer e connected via one or more URLs.  Edge colors represent connections between anti -anti \n(red), anti -pro (yellow), and pro-pro(blue)  vaccine groups , and connections involving mixed/neutral groups colored gray . The \nsize of a circle is proportional to its degree.  \n \nThis study is not without limitations. Although it was successful in identif ying a large \nnumber of Facebook pages and groups discussing vaccine s, data on accounts and content  \nremoved by Facebook , individual profiles, and private accounts  are not a vailable to researchers . \nFacebook argued that it would remove posts promoting  false claims about C OVID -19 vaccines \n(31), so the pervasiveness of anti -vaccine content before this  alleged effort should have been \n\nmore severe than what was identified in this research. The influence of algorithms and social \nmedia policies  including content moderation  also could not  be considered due  to the lack of \navailable data and the limited collaboration  between academia and the social media platform .  \nDespite the limitations, this study provides evidence that is urgently needed to understand  \nand reduce  misleading narratives about vaccin es and vaccination  on social media . First, \nhindering the processes of  combining and merging Facebook internal resources  to support  anti-\nvaccine narratives , and disrupting Facebook\u2019s homegrown ecosystem enabling the production of \ndisinformation  should be a major  target  of intervention and policies  aiming for vaccine \ndisinformation  reduction . (8, 11). Second, the intrusion of information from \u201cfake news  sources \u201d \nis only one part of the problem . Both anti- and pro-vaccine groups use government, news, and \nsocial media sources  more than low credibility sources , and anti -vaccine groups also seem to \nstrive to be perceived as credibl e by using more and more  government and  legitimate  news \nsources.  Thus, although  monitoring  the use of suspicious sources  could be a good way to identify \nusers who are  susceptible  to misinformation  (15, 17) and to detect incorrect information likely to  \ngo viral (16), strategies focusing only on these sources  may not be sufficient in curbing false \nnarratives . Lastly, anti-vaccine  groups  draw information from sources physically and politically \ndistinguished  from  those of pro -vaccine groups , and the insular pattern of connections among  \nonline vaccine  groups further  limit s information flows  across  groups with different views.  \nTherefore , without considering the  segregation between anti - and pro -vaccine groups  on social \nmedia , public  campaigns and interventions  aiming to distribute  scientific information  may not be \nsuccessful in reaching  and influencing  individuals with anti -vaccine beliefs . \n \nReference s and Notes  \n1.  R. V. Tuckson, The disease of distrust. Science . 370, 745 \u2013745 (2020).  \n2.  C. Nast, The Mistrust of Science. The New Yorker  (2016).  \n3.  D. M. J. Lazer, M. A. Baum, Y. Benkler, A . J. Berinsky, K. M. Greenhill, F. Menczer, M. J. \nMetzger, B. Nyhan, G. Pennycook, D. Rothschild, M. Schudson, S. A. Sloman, C. R. \nSunstein, E. A. Thorson, D. J. Watts, J. L. Zittrain, The science of fake news. Science . 359, \n1094 \u20131096 (2018).  \n4.  M. S. Raz ai, U. A. R. Chaudhry, K. Doerholt, L. Bauld, A. Majeed, Covid -19 vaccination \nhesitancy. BMJ . 373, n1138 (2021).  \n5.  S. L. Wilson, C. Wiysonge, Social media and vaccine hesitancy. BMJ Global Health . 5, \ne004206 (2020).  \n6.  S. Loomba, A. de Figueiredo, S. J.  Piatek, K. de Graaf, H. J. Larson, Measuring the impact \nof COVID -19 vaccine misinformation on vaccination intent in the UK and USA. Nat Hum \nBehav . 5, 337 \u2013348 (2021).  \n7.  D. A. Broniatowski, A. M. Jamison, S. Qi, L. AlKulaib, T. Chen, A. Benton, S. C. Quin n, M. \nDredze, Weaponized Health Communication: Twitter Bots and Russian Trolls Amplify the \nVaccine Debate. American Journal of Public Health . 108, 1378 \u20131384 (2018).  \n8.  N. Jankowicz, C. Otis, Facebook Groups Are Destroying America. Wired  (2020).  \n9.  T. Bur ki, The online anti -vaccine movement in the age of COVID -19. The Lancet Digital \nHealth . 2, e504 \u2013e505 (2020).  \n10.  W.-Y. S. Chou, A. Gaysynsky, J. N. Cappella, Where We Go From Here: Health \nMisinformation on Social Media. Am J Public Health . 110, S273 \u2013S275 (2020).  \n11.  N. F. Johnson, N. Vel\u00e1squez, N. J. Restrepo, R. Leahy, N. Gabriel, S. El Oud, M. Zheng, P. \nManrique, S. Wuchty, Y. Lupu, The online competition between pro - and anti -vaccination \nviews. Nature  (2020), doi:10.1038/s41586 -020-2281 -1. \n12.  D. A. Broniatowski, A. M. Jamison, N. F. Johnson, N. Velasquez, R. Leahy, N. J. Restrepo, \nM. Dredze, S. C. Quinn, Facebook Pages, the \u201cDisneyland\u201d Measles Outbreak, and \nPromotion of Vaccine Refusal as a Civil Right, 2009 \u20132019. American Journal of Public  \nHealth . 110, S312 \u2013S318 (2020).  \n13.  Facebook, Company Info | About Facebook (2021), (available at \nhttps://about.facebook.com/company -info/).  \n14.  A. L. Schmidt, F. Zollo, A. Scala, C. Betsch, W. Quattrociocchi, Polarization of the \nvaccination debate on Fa cebook. Vaccine . 36, 3606 \u20133612 (2018).  \n15.  N. Grinberg, K. Joseph, L. Friedland, B. Swire -Thompson, D. Lazer, Fake news on Twitter \nduring the 2016 U.S. presidential election. Science . 363, 374 \u2013378 (2019).  \n16.  S. Vosoughi, D. Roy, S. Aral, The spread of t rue and false news online. Science . 359, 1146 \u2013\n1151 (2018).  \n17.  A. Guess, J. Nagler, J. Tucker, Less than you think: Prevalence and predictors of fake news \ndissemination on Facebook. Science Advances . 5, eaau4586 (2019).  \n18.  H. Allcott, M. Gentzkow, Social Media and Fake News in the 2016 Election. Journal of \nEconomic Perspectives . 31, 211 \u2013236 (2017).  \n19.  K. Starbird, in ICWSM  (2017).  \n20.  D. J. Watts, D. M. Rothschild, M. Mobius, Measuring the news and its impact on democracy . \nPNAS . 118 (2021), doi:10.1073/pnas.1912443118.  \n21.  E. Bakshy, S. Messing, L. A. Adamic, Exposure to ideologically diverse news and opinion \non Facebook. Science . 348, 1130 \u20131132 (2015).  \n22.  G. Pennycook, D. G. Rand, Fighting misinformation on social medi a using crowdsourced \njudgments of news source quality. Proceedings of the National Academy of Sciences . 116, \n2521 \u20132526 (2019).  \n23.  T. Yang, S. Maj\u00f3 -V\u00e1zquez, R. K. Nielsen, S. Gonz\u00e1lez -Bail\u00f3n, Exposure to news grows less \nfragmented with an increase in mobi le access. Proc Natl Acad Sci USA . 117, 28678 \u201328683 \n(2020).  \n24.  J. S. Brennen, F. M. Simon, P. N. Howard, R. K. Nielsen, Types, Sources, and Claims of \nCOVID -19 Misinformation. Reuters Institute Factsheet , 13 (2020).  \n25.  G. Grossman, S. Kim, J. Rexer, H. Thirumurthy, Political Partisanship Influences Behavioral \nResponses to Governors\u2019 Recommendations for COVID -19 Prevention in the United States \n(2020), doi:10.2139/ssrn.3578695.  \n26.  Y. T. Yang, D. A. Broniatowski, D. R. Reiss, Government Role in Regulating  Vaccine \nMisinformation on Social Media Platforms. JAMA Pediatrics . 173, 1011 \u20131012 (2019).  \n27.  T. Wilson, K. Starbird, Cross -platform disinformation campaigns: Lessons learned and next \nsteps. Harvard Kennedy School Misinformation Review . 1 (2020), doi:10. 37016/mr -2020 -\n002. \n28.  M. D. Vicario, S. Gaito, W. Quattrociocchi, M. Zignani, F. Zollo, in 2017 IEEE \nInternational Conference on Data Science and Advanced Analytics (DSAA)  (2017; \n10.1109/DSAA.2017.33), pp. 648 \u2013657. \n29.  L. Singh, L. Bode, C. Budak, K. Ka wintiranon, C. Padden, E. Vraga, Understanding high - \nand low -quality URL Sharing on COVID -19 Twitter streams. J Comput Soc Sc . 3, 343 \u2013366 \n(2020).  \n30.  The two lists of information sources used by at least five different anti -vaccine [pro -vaccine] \ngroups bu t never used by any pro -vaccine [anti -vaccine] groups for the 107 months are \navailable online. See S6.  \n31.  M. Isaac, Facebook says it will remove coronavirus vaccine misinformation. The New York \nTimes  (2020).  \n \nAcknowledgments:  The authors thank Nathaniel Persily, Rob Reich, Robert Hornik, and Sandra \nGonz\u00e1lez -Bail\u00f3n  for their comments .  \nAuthor contributions:   \nConceptualization: SK  \nMethodology: SK  \nInvestigation: SK, KK  \nVisualization: SK, KK  \nWriting \u2013 original draft: SK, KK  \nWriting \u2013 review & editing: SK, KK  \nCompeting interests:  Authors declare that they have no competing interests.  \nData and materials availability:  All data, code, and materials used in the analysis are \navailable in the supplementary materials .   \n \nSupplementar y Materials  \nFigs. S1 to S 14 \nTables S1 to S 14 \nReferences ( 1\u201348) \n \n1 \n Supplementary Material  for \u201cThe Information Ecosystem \nof Online Groups with Anti - and Pro -vaccine Views on \nFacebook\u201d \n \n \n \n  \n2 \n TABLE OF CONTENTS  \n \nS1 Definition and Terminology  ................................ ................................ ............  4 \nS1.1 Vaccine Group and Vaccine Content  ................................ ......................  4 \nS1.2 Information Source  ................................ ................................ ..................  5 \nS2 Data Co llection and Valence Coding  ................................ .............................  6 \nS2.1 Overview  ................................ ................................ ................................ . 6 \nS2.2 Data Collection Procedure ................................ ................................ ....... 6 \nS2.2.1 Stage 1: Iterative Keyword -based Searching  ................................  7 \nS2.2.2 Stage 2: Network -based Searching  ................................ ...............  9 \nS2.3 Evaluation of Group Valence  ................................ ................................  10 \nS2.4 Comparison with the Data Collected by Previous Studies  ....................  11 \nS3 Analysis: The Activities of Pro - and Anti -vaccine Groups  ........................  13 \nS3.1 The Volume of Content  ................................ ................................ .........  13 \nS3.2 The Number of Active Groups  ................................ ..............................  16 \nS3.3 The Number of Shares  ................................ ................................ ...........  16 \nS3.4 The Number of Comments and Reactions  ................................ ............  17 \nS3.5 Posts per Active Group in a Year  ................................ ..........................  18 \nS3.6 Group Lifetime  ................................ ................................ ......................  19 \nS4 Analysis: The Use of Information Sources  ................................ ..................  20 \nS4.1 The Use of Information Sources  ................................ ...........................  20 \nS4.2 Shortened URLs  ................................ ................................ ....................  20 \nS4.3 Facebook Internal Sources and External Sources  ................................ . 21 \nS4.3.1 Video Sources  ................................ ................................ .............  23 \nS4.4 Subtypes of External Sources  ................................ ................................  25 \nS4.4.1 Government Sources  ................................ ................................ ... 25 \n3 \n S4.4.2 N ews Sources  ................................ ................................ ..............  28 \nS4.4.3 Social Media Sources  ................................ ................................ .. 29 \nS4.4.4 Low Credibility Sources  ................................ .............................  30 \nS5 Analysis: User Engagement and Information Sources ...............................  33 \nS5.1 Robustness to Covariate Specification  ................................ ..................  35 \nS5.2 Subgroup Analysis: Pro -vaccine and Anti -vaccine  ...............................  36 \nS6 Analysis: Exclusive Sources  ................................ ................................ ..........  39 \nS6.1 Exclusive Sources ................................ ................................ ..................  39 \nS6.1.1 Subtypes Among Exclusive Sources ................................ ...........  40 \nS7 Analysis: Source Popularity and Anti -vaccine Affinity  .............................  42 \nS7.1 Source Popularity Among Pro - and Anti -vaccine Groups  ....................  42 \nS7.2 Anti -vaccine Affinity Score  ................................ ................................ .. 43 \nS7.3 Ideology Alignment and Anti -vaccine Affinity of Sources  ..................  45 \nS7.3.1 Robustness Analysis: Ideology Alignment based on MBFC Data\n ................................ ................................ ................................ ................  45 \nS7.3.2 Robustness Check: Ideology Al ignment based on All Sides Data\n ................................ ................................ ................................ ................  46 \nS8 Analysis: Networks of Vaccine Groups within Facebook  ..........................  50 \nS9 Data and Codes for Replication ................................ ................................ .... 53 \nS10 References  ................................ ................................ ................................ ..... 54 \n \n  \n4 \n S1 Definition and Terminology  \nS1.1 Vaccine Group and Vaccine Content   \nIn the current study, a \u201cgroup\u201d refer s to a community of Facebook users  who \ncreated, consume d, or engaged with  the content of a Facebook page or Facebook \ngroup.  A \u201cvaccine group\u201d refer s to a group  discussing vaccine -related issues . \nWhen referring to a webpage within Facebook that is either a Facebook page and \na Facebook group, we use the term a \u201cFacebook page/group\u201d  (without omitting \n\u201cFacebook\u201d ) or, simply put,  an \u201caccount .\u201d Compared with \u201cgroup s,\u201d \u201cFacebook \npages/groups\u201d or \u201caccounts\u201d  were used to highlight the  online  content that \ncommunit ies generate d or the online  space s in which communit ies communicate d. \n\u201cVaccine content\u201d  or \u201cvaccine posts\u201d  refer to Facebook posts created by vaccine \ngroups.  \nA pro -vaccine group refers to a vaccine group that  advocate s safety, \neffectiveness, and benefits of vaccines and vaccination; encourage s perception \nand norms favorable to vaccines; refute s claims about th e danger of and \nsuspicions about vaccines and criticizes  people supporting these claims; and/or \nprovide s information about services, policies, or campaigns for vaccines and \nrelated practices. An anti -vaccine group , on the other hand,  refers to a vaccine \ngroup  that emphasize s danger and negative consequences of vaccines  and \nvaccination; promote s information about vaccine exemptions and choice; \nhighlight s the benefits of other medical or dietary practices as alternatives; \npresent s claim s based on conspiracy theories and unsubstantiated information; \nand/or criticiz es pro-vaccine content and people who promote it . \nIn this research, we distinguish between misleading narratives and \nmisinformation. Misleading narratives refer to claims and st ories promoted by \nanti-vaccine groups. Misinformation, on the other hand, refers to information \ndrawn from low credibility information sources. The inclu sion of misinformation  \nin a Facebook post  is determined by the existence of URLs linked to low \ncredibil ity information sources, not by the view of the vaccine group producing  \nthe post.  Thus, t he inclusion of misinformation in a post does not necessarily \nindicate that the post was produced by an anti -vaccine group ; misinformation can \nbe included in content produced by not only anti -vaccine groups but also pro -\nvaccine groups . \n5 \n An active group refers to a group that created at least one post in a given \nperiod of time.  For example, \u201cactive groups in January 2015\u201d refers to  vaccine \ngroups that generated at least one post in that month, and \u201cactive groups in 2017\u201d \nrefer s to vaccine groups that generated at least one post in that year. In the same \nsense, an active anti -vaccine group [an active pro -vaccine group] indicates an \nanti-vaccine group [a pro -vaccine group] that created at least one post in a given \nperiod of time.  \n  \nS1.2 Information Source  \nThis research  explored the information ecosystem that enabled vaccine groups by \nanalyzing URLs included in the posts they generated  and identifying information \nsources used by them. Information sources used in a Facebook post can be \nidentified  by analyzing URLs (Unifie d Resource Locators) included in the post. \nEach URL  (e.g., https://www.cnn.com/health)  indicates  a source from which  a \npiece of information was drawn  (e.g., cnn.com) . Multiple URLs  can be included \nin a post , and data retrieved from CrowdTangle provide  information on all URLs \nin a post. For example, if a post in Facebook page A  includes a hyperlink to a \nCDC  webpage , a video uploaded on Facebook , and  an URL to a Washington Post \narticle , the data on the A\u2019s post  will include the URL of the CDC webpage , the \nURL of the video on Facebook,  and the URL of the Washington Post  article . In \nthis case,  the post in Facebook Group A is drawing information from three \ndifferent information sources: cdc.gov , facebook.com, and washingtonpost .com.  \n  \n6 \n S2 Data  Collection  and Valence  Coding  \nS2.1 Overview  \nCrowdTangle (CT)  is \u201ca public insights tool owned and operated by Facebook .\u201d It \nis one of the very few tools that help researchers and journalists  moni tor a large \nnumber of public Facebook pages and groups . CT maintains  data on  public \nFacebook accounts  that are selected by CT based on their popular ity or  are \nrequested  by CT users  (1, 2). Based on these features of CT, w e designed a n \niterative data collection method  combining data retrieval throug h CT and the \nidentification of new Facebo ok pages/groups. This method , which was inspired  by \nthe snowball sampling methods,  enabled  us to gather  a large number of Facebook \npages/groups that satisfy our search criteria beyond the limited number of \naccounts originally offered  by CT . The data collection was conducted between \nDecember 13th and December 25th, 202 0. \nAlthough , without  access to the company\u2019s internal knowledge base about \nthe Facebook  website and database architecture , it is currently impossible for \nindependent researchers to identify and access  a complete set of Facebook \npages/groups that meet certain  search criteria , we believe that the data collection  \nmethod  of the present study  has made a meaningful contribution  in expand ing the \nscope of data  that can be retrieve d from Facebook . \nThis study was approved by the Institutional Review Board of [removed \nfor the blind review process] . \n \n \nS2.2 Data Collection Procedure  \nData collection consist ed of two stages. In the first stage  (Stage 1) , iterative \nkeyword -based searching was conducted . Stage 1  consisted of the four rounds of \ndata collection.  In the second stage  (Stage 2) , we conducted n etwork -based \nsearching based on the results of the first stage.  Stage 2  aimed to capture \nadditional Facebook pages/groups that were connected  with accounts found in \nStage 1  but could not be captured by a keyword -based searching  strategy . \nWe considered the technical characteristics of CT when devising the data \ncollection strategy for the current study. Using CT is, as of now, the only way \navailable for external researchers wh o aim to search for specific Facebook \npages/groups and to download content created by these accounts. However, after \n7 \n an extensive examination of the CT\u2019s search function, we identified  the following  \nfunctional irregularities. (i) The search results were no t exhaustive. The search \nfunction did not provide all matching result s in one search attempt. We \ndiscovered that more results could be obtained by accompanying related \nkeywords with a keyword of interest. For example, the searching results of a \nkeyword sequence \u201cvaccin danger\u201d did not necessarily constitute a subset of the \nsearching results of \u201cvaccin.\u201d (ii) The search results were not exact. The search \nresults might include Facebook pages/groups with titles containing possible \nvariations of keywords. We speculated that it was because of Facebook\u2019s \nconsideration of potential user typos. For example, the search results of \u201cvaccin\u201d \nmight contain a Facebook page title with other words with similar spelling, such \nas \u201cvacation\u201d or \u201c vacuum .\u201d We contacted CrowdTangle for these issues, and they \nresponded that CT\u2019s search function util ized Facebook\u2019s search engine and that \nCT had only a limited ability to investigate, correct, or publicize technical details \nof Facebook\u2019s proprietary search function.  \n  \nS2.2.1 Stage 1: Iterative Keyword -based Searching  \nStage 1  conducted keyword -based searching and additional filtering to identify  \nFacebook pages/groups  discussing vaccine -related issues . Posts created by the \nresulting Facebook accounts  were  then retrieved through  CT. The design of Stage \n1 considers the aforementioned functional irregularities  and aims to overcome \nthem .  \n Round 1 followed the following steps. First, utilizing the page/group \nsearch function that CT\u2019s  web interface  provides , we searched for Facebook \npages/groups  discussing vaccine -related topics  using various combinations of \n\u201ccore\u201d and \u201csupporting \u201d keywords . To offset  the incompleteness of CT\u2019s search \nresults , multiple searches were conducted using  multiple keywords . Table S 1 \nshows  all combinations of core and supporting keywords used in this step. As \nshown in the table, t he two core keywords are \u201cvaccin \u201d and \u201cvax,\u201d and supporting \nkeywords are a set of keywords that are commonly used in the discussion of \nvaccine -related issues, such as \u201cprevent\u201d and \u201cdanger.\u201d Second, after retrieving \nfrom CT a full list of the Facebook pages/groups that correspond s the keyword  \ncombination s, we conducted additional filtering to select accounts containing one \nor more of the two core keywords  in their titles.  This step was to  overcome the \ninexactness of CT\u2019s search results by  filter ing out Facebook pages/groups that did \nnot contain any core keywords . Third, using CT\u2019s Post Search API, we \n8 \n downloaded English posts created between  January 1st, 2012 and November 30th, \n2020 by the Facebook pages/groups that passed the first and second steps . \nRound 2  started by analyzing all Facebook internal URLs included in the \npost data downloaded  in Round 1  and identifying new Facebook accounts that \nwere not included in the list of Facebook pages/groups identified in  Round 1 . We \nrequested CT to update its database if it had not been  tracking these new ly found  \naccounts. Among the se new accounts, w e selected Facebook pages/groups \nincluding one or more core keywords in their titles and retrieved all English posts \ncreated by the s elected accounts from January 1st, 2012 to November 30th, 2020 \nusing  the Post Search API.  \nSimilarly, Round 3  started by analyzing all Facebook internal URLs \nincluded in the post data downloaded  in Round 2  and identifying new Facebook \naccounts that were not included in the list of Facebook pages/groups identified in  \nthe previous  round s. We requested CT to update its database if it had not been \ntracking the newly found accounts.  Among the new accounts identi fied in Round \n3, we selected Facebook pages/groups including one or more core keywords in \ntheir titles . All English posts created by the selected accounts from January 1st, \n2012 to November 30th, 2020 were retrieved using  the Post Search API.  \nRound 4  also started by analyzing all Facebook internal URLs included in \nthe post data downloaded  in Round 3  and identifying new Facebook accounts that \nwere not included in the list of Facebook pages/groups identified in  the previous  \nround s. We requested CT to update its database if it had not been tracking these \nnewly found accounts. Among the new accounts iden tified in Round 4 , we \nselected Facebook pages/groups including one or more core keywords in their \ntitles . All English posts created by the selected accounts from January 1st, 2012 to \nNovember 30th, 2020 were retrieved using  the Post Search API.  Because onl y one \naccounts were newly identified in this round, we stopped Stage 1 in this round.  \nLastly, we merged all post data retrieved in Round 1 to 4 . The resulting \ndata contained posts  from 2,079 Facebook pages/groups.  \n \n \n9 \n Table S 1. Keyword Combinations for Stage 1  \n\"pro vaccin vax\"  \n\"vaccin vax good\"  \n\"vaccin vax safe\"  \n\"vaccin vax save\"  \n\"vaccin vax protect\"  \n\"vaccin vax prevent\"  \n\"vaccin vax benefit\"  \n\"vaccin vax immun\"  \n\"vaccin vax advoca\"  \n\"vaccin  vax support\"  \n\"vaccin vax science\"  \n\"vaccin vax access\"  \n\"anti vaccin vax\"  \n\"vaccin vax danger\"  \n\"vaccin vax risk\"  \n\"vaccin vax injury\"  \n\"vaccin vax damage\"  \n\"vaccin vax kill\"  \"vaccin vax death\"                        \n\"vaccin vax choice\"                       \n\"vaccin vax consent\"                       \n\"vaccin vax against\"                      \n\"vaccin vax stop\"                      \n\"vaccin vax concern\"                      \n\"vaccin vax victim\"  \n\"vaccin vax fact\"  \n\"vaccin vax truth\"  \n\"vaccin vax real\"  \n\"vaccin vax hoax\"                       \n\"vaccin vax myth\"  \n\"vaccin vax aware\"                        \n\"vaccin vax inform\"                        \n\"vaccin vax expert\"                       \n\"vaccin vax educat\"  \n\"vaccin vax know\"  \n\"vaccin vax mandat\"  \"vaccin vax cause\"  \n\"vaccin vax induce\"  \n\"vaccin vax disease\"  \n\"vaccin vax alliance\"  \n\"vaccin vax coalition\"  \n\"vaccin vax movement\"  \n\"vaccin vax action\"  \n\"vaccin vax\"  \n\"vaccine\"  \n\"vaccinate\"  \n\"vaccinated\"  \n\"vaccination\"  \n\"vaccinating\"  \n\"vaxxed\"  \n\"vaxxer\"  \n\"vaxxing\"  \n \n \nS2.2. 2 Stage 2: Network -based Searching  \nTo discover more Facebook pages/groups discussing vaccine -related issues, Stage \n2 conducted the following tasks: (a) A nalyz ing Facebook internal URLs included \nin the posts found in Stage 1 , (b) identif ying candidate accounts,  i.e., Facebook \npages/groups  connected with  the Stage 1 accounts via URLs , (c) among the \ncandidates, request ing CT to obtain d ata on newly found  accounts  that did not \nexist in its database , (d) select ing accounts  satisfying at least one  of the two \nconditions . The two conditions were: (1) a Facebook page/group was referenced \nby at least 5 different groups  found in Stage 1 , (2) a Facebook page/group \ncontains at least one of the following keyword s in its title: \u201cvac\u201d, \u201cvax\u201d, \n\u201cimmun\u201d, and \u201cshot\u201d.  These processes aimed to collect additional accounts that \ndiscuss vaccination but had not been captured in Stage 1 because their titles did \nnot meet  Stage 1 \u2019s keyword -searching criteria . (Note that Stage 2\u2019s keyword rule \nwas loosened from that of S tage 1, considering that the candidate accounts of \nStage 2 were already being referenced by other Facebook pages/groups  that \n10 \n satisf ied the criteria  of Stage 1 .) 391 Facebook pages/groups  were newly \ndiscovered in Stage 2 , and we retrieved their English posts  produced from January \n1st, 2012 to November 30th, 2020 .  \nWe merged all data retrieved in Stage 1 and Stage 2 . The resulting data \nincluded  2,462 accounts ( 2,315 Facebook pages, 1 47 Facebook groups).  \n \n \nS2.3 Evaluation of Group Valence  \nWe examined  the view  of each Facebook  page and group on vaccines and \nvaccination.  For this purpose, each Facebook page or group was evaluated  by two \nindependent coders  and classified  into one of the four categories: \u201cpro-vaccine, \u201d \n\u201canti-vaccine, \u201d \u201cmixed/neutral, \u201d and \u201cnot applicable. \u201d The classification of pro -\nvaccine and anti -vaccine groups w as based on the definitions provided in S1. A \nFacebook  page/group was labeled as mixed /neutral if it  present ed mixed \nviewpoints, or views that were  related to vaccines but neither pro - nor anti -\nvaccine. The \u201cnot applicable\u201d category included pages /groups that did not discuss \nvaccine -related issues (e.g., musi cians and metaphorical use of the word, \nvaccine ), were mostly about  animal or non-human vaccines, did not contain  any \ncontent written in English , was not accessible, or did not contain  two or more  \nposts  about vaccine s and vaccination . \nTwo subject -matter experts coded each Facebook page/group. B efore \nstarting the main coding task, all coder s reviewed  the same set of 100 randomly \nselected pages/groups  independently , following the coding procedure  described \nbelow . All coders then shared  and compared  their coding  results and discussed \nand resolved  discrep ancies  in their understanding. Coders  then coded  the rest of \nthe pages/groups.  Each page/group was coded by two independent coders.  \nThe coding procedure was as follows. First, e ach c oder checked the \ndescription of each page/group  in its  \u201cAbout\u201d tab on Facebook  and attempted to \ndetermine its view  based on the information provided in the description. I f the \ndescription did not provide su fficient information , coders review ed up to 25 most \nrecent post ings in a page/group , including posts, photos, status updates, and added \nevents.  A coding decision was made based on at least two postings related to \nvaccines or vaccination . \nThe coding results showed that t he evaluations  of two coders were \nidentical  for 2,373 of 2,462 Facebook pages/groups . Krippendorff\u2019s alpha \n11 \n was .93 6. For the 89 pages/groups that two coders did not agree upon, two coders \nmade final decision s together after discussion . The coding results also indicated \nthat that the collected data include d 134 \u201cnot applicable \u201d Facebook pages/groups , \nand we removed these accounts from the dataset . Consequently , the final dataset \ncontained  1,682,205 million  posts created by 2,328  vaccine  groups (1,206 pro -\nvaccine, 1,083 anti -vaccine , and 39 mixed/neutral  groups ; 2185  Facebook pages  \nand 143 Facebook groups ) from January 1st, 2012 to November 30th, 2020 .  \n \n \nS2.4 Comparison with the Data Collected by  Previous  Studies  \nWe have reviewed prior studies that analyzed communities discussing vaccines \nand vaccination  on social media  (3\u201316). Here, we com pare the current study with \nfour of the most comprehensive previous studies on Facebook vaccine \ncommunities, from the perspectives of data scale s, collection  methods,  and \nanaly tical approach es. \nFirst, Johnson et al. (15) manually identified 441 publicly accessible \nFacebook pages with pro - and anti -vaccine views in 2019. Specifically, they  first \nchose multiple \u201cseed\u201d pages about vaccination and identified pages liked by the \nseed pages\u2019  administrators . The researchers  then visited the se \u201cliked  pages \u201d and \nidentified other  pages  liked by the liked pages\u2019 administrators . By repeating this \nprocess, the researchers  found 317 \u201canti-vaccination ,\u201d 124 \u201cpro-vaccination ,\u201d and \n885 \u201cundecided \u201d pages (15). (Based on a similar sampling method , Broniatowski \net al. (14) identified 204 \u201canti-vaccination \u201d Facebook pages  in 2019  and \ndownloaded 288,175 posts created by them  through CT .) Thus, the current study \nis more extensive than Johnson et al ., considering  the number of online \ncommunities  identified and the duration of data collected  for research . The data \ncollected in the current study also include both Facebook groups  and pages , while  \nJohnson et al. targeted only the lat ter. Furthermore , we investigated the content of \nthese Facebook pages and groups, which was only qualitatively discussed in \nJohnson et al. In addition , the data collection method of the present study helps \nidentify a set of Facebook pages and groups that are more closely related to the \nvaccine s and vaccination issues, while  the method following Facebook accounts \nliked by page administrators might  overemphasize  the preference of a small \nnumber of individuals .  \n12 \n Second, Schmidt et al. (6) identified 243 Facebook pages discussing \nvaccines and vaccination between January 2010 and May 2017 , including  145 \npro-vaccination or 98 anti-vaccination  Facebook pages . They  focused on  the \nvolume of content and the number of  user engagement s over time. Cinelli et al.  \n(16) re-analyzed the data collected in Schmidt et al. and reported  that Facebook \nusers  with similar views  on vaccin ation  were more likely to  interact with each \nother . \n \n  \n13 \n S3 Analysis : The Activities of Pro - and Anti -vaccine \nGroups  \nS3.1 The Volume of Content  \nTable S2 shows the number of posts generated by all vaccine groups  each month \nand the proportion of posts from anti -vaccine, pro -vaccine, and mixed/neutral \ngroups.  The 107 -month average of the total number of posts was 15721.5 ( SD = \n5703.4 , Median = 18005 ). The 107-month average proportions of posts created by \nanti-vaccine, pro -vaccine, and mixed/neutral groups were 7 4.1% (SD = 6.2% , \nMedian = 74.3% ), 25.6% ( SD = 6.2% , Median = 25.2% ), and 0.2% ( SD = 0.2%, \nMedia n = 0.2% , N = 107 ), respectively.  \n As shown in Fig 1A,  the total number of posts produced by all vaccine \ngroups ha d increased steadily with noticeable surges that coincide with three \nmajor infectious disease outbreaks in the U.S: ( a) the 2015  U.S. measles outbreak \nthat peaked  in January 2015  (17), (b) the 2019 U.S. measles outbreak that peaked \nin March 2019 (18), and ( c) the early stage of the COVID -19 pandemic. (The U.S. \nNational Emergency concerning COVID -19 was declared in March 2020 (19).)  \n To examine  if the proportion of posts generated by anti-vaccine groups  \nwas mostly determined by a few Facebook pages/groups that published  a large \nnumber of posts, we also calculated  the proportion excluding  the top 10 vaccine \ngroups in terms of the total number of posts generated . As shown in Fig. S 1A, the \ncalculation showed that the majority of vaccine posts were  produced  by anti -\nvaccine groups  even when the top 10 vaccine groups were excluded . Specifically,  \nthe 107 -month average proportions of posts created by anti -vaccine, pro -vaccine, \nand mixed/neutral groups were 64.7% (SD = 5.2%, Median = 64.0%), 35.0% (SD \n= 5.3%, Median = 35.6%), and 0. 4% (SD = 0.3%, Median = 0. 3%, N = 107), \nrespectively.  When the top 20 vaccine groups  with the most posts  were removed \nfrom the dataset, the posts created by anti-vaccine groups were still dominant ( the \n107-month average  = 60.5%, SD = 4.3%, Median = 60.2%), as shown in Fig. \nS1B.  \n \nTable S2. Number of posts, active groups, and shares by month \n Posts  Active groups  Shares  \nMonth  Total \nnum  % \nAnti % \nPro % \nMix Total \nnum  % \nAnti % \nPro % \nMix Total \nnum  % \nAnti % \nPro % \nMix \n01/2012  5125  83.3  16.6  0.2 142 62.7  36.6  0.7 48077  75.3  24.7  0.0 \n14 \n 02/2012  5285  84.6  15.2  0.2 157 61.8  37.6  0.6 55084  76.7  23.3  0.0 \n03/2012  5989  85.9  14.0  0.1 155 62.6  36.8  0.6 68149  73.3  26.7  0.0 \n04/2012  5664  83.6  16.1  0.2 159 60.4  38.4  1.3 75162  84.1  15.9  0.0 \n05/2012  5819  82.0  17.7  0.3 165 61.8  37.0  1.2 97770  79.8  20.2  0.0 \n06/2012  5946  83.2  16.5  0.3 180 60.6  38.3  1.1 92443  87.7  12.3  0.0 \n07/2012  6822  84.9  15.0  0.1 185 60.5  38.4  1.1 121877  87.7  12.3  0.0 \n08/2012  7760  84.4  15.4  0.2 187 58.3  40.6  1.1 130619  83.5  16.5  0.0 \n09/2012  8484  85.7  14.1  0.2 201 57.7  41.3  1.0 162594  87.7  12.3  0.0 \n10/2012  10020  86.8  13.2  0.0 207 56.5  42.5  1.0 306125  92.0  8.0 0.0 \n11/2012  8766  87.4  12.5  0.1 209 57.4  42.1  0.5 160503  84.8  15.2  0.0 \n12/2012  8178  87.9  11.9  0.1 192 59.4  39.6  1.0 169136  85.2  14.8  0.0 \n01/2013  9158  85.0  14.9  0.2 216 56.9  42.1  0.9 249192  77.4  22.6  0.0 \n02/2013  8279  83.2  16.6  0.1 224 56.3  42.4  1.3 300533  69.3  30.6  0.0 \n03/2013  8386  81.9  18.1  0.1 220 56.8  42.7  0.5 292544  84.6  15.4  0.0 \n04/2013  8264  78.2  21.7  0.1 220 55.0  44.5  0.5 275467  73.0  27.0  0.0 \n05/2013  9390  78.0  21.9  0.1 230 56.1  43.5  0.4 375414  75.6  24.4  0.0 \n06/2013  8530  76.4  23.4  0.2 224 54.9  43.8  1.3 312671  78.5  21.5  0.0 \n07/2013  8388  78.0  21.9  0.1 224 54.9  44.2  0.9 275942  83.0  17.0  0.0 \n08/2013  8516  78.5  21.4  0.2 231 56.3  42.9  0.9 353703  86.7  13.3  0.0 \n09/2013  8024  79.2  20.6  0.2 221 54.3  44.3  1.4 388157  81.8  18.2  0.0 \n10/2013  8399  77.7  21.7  0.5 243 53.5  45.3  1.2 403260  86.1  13.9  0.0 \n11/2013  8727  80.0  19.2  0.8 247 55.5  43.7  0.8 484771  83.6  16.4  0.0 \n12/2013  8823  80.0  19.2  0.7 249 53.4  45.0  1.6 487774  85.2  14.8  0.0 \n01/2014  10383  81.9  16.9  1.2 250 53.6  44.8  1.6 453513  75.2  24.8  0.0 \n02/2014  9322  81.4  18.2  0.4 254 56.7  42.1  1.2 398747  79.3  20.7  0.0 \n03/2014  10571  77.8  21.7  0.5 274 55.5  43.1  1.5 476616  79.7  20.3  0.0 \n04/2014  9979  75.5  23.9  0.5 284 55.3  43.3  1.4 855542  75.0  25.0  0.0 \n05/2014  8730  74.8  24.5  0.7 277 54.5  44.4  1.1 658972  81.2  18.8  0.0 \n06/2014  8398  76.7  22.8  0.5 264 54.9  44.3  0.8 756047  79.8  20.2  0.0 \n07/2014  8872  77.3  22.3  0.3 282 55.7  43.6  0.7 633659  74.4  25.6  0.0 \n08/2014  9730  78.1  21.6  0.3 286 54.9  44.4  0.7 1018336  53.7  46.3  0.0 \n09/2014  11356  75.3  24.4  0.3 309 54.0  45.0  1.0 927603  80.3  19.7  0.0 \n10/2014  12744  73.0  26.9  0.2 335 54.3  44.8  0.9 1026374  75.7  24.3  0.0 \n11/2014  10808  76.6  23.2  0.2 308 56.8  42.5  0.6 781481  78.2  21.8  0.0 \n12/2014  10072  74.4  25.1  0.5 310 56.5  42.6  1.0 1037039  76.7  23.3  0.0 \n01/2015  13337  74.3  25.2  0.5 351 59.0  40.5  0.6 1340063  70.6  29.4  0.0 \n02/2015  16132  77.5  21.9  0.6 406 56.9  41.9  1.2 1173656  77.7  22.3  0.0 \n03/2015  12933  72.0  27.9  0.1 359 54.6  44.8  0.6 1543655  81.1  18.9  0.0 \n04/2015  14573  73.9  25.8  0.3 399 55.9  43.4  0.8 1326061  75.5  24.5  0.0 \n05/2015  18563  74.0  25.8  0.2 439 59.7  39.6  0.7 2916403  66.8  33.2  0.0 \n06/2015  17050  73.0  26.8  0.2 440 58.2  40.7  1.1 2138934  77.0  23.0  0.0 \n07/2015  18510  74.9  25.0  0.2 449 59.9  39.4  0.7 2712394  81.8  18.2  0.0 \n08/2015  18005  73.4  26.3  0.3 457 60.6  38.5  0.9 2520747  77.1  22.9  0.0 \n09/2015  18017  73.3  26.4  0.3 464 60.1  39.4  0.4 2408841  78.3  21.7  0.0 \n10/2015  19936  75.5  24.1  0.3 475 58.7  40.6  0.6 3587137  81.5  18.5  0.0 \n11/2015  18634  76.2  23.5  0.3 457 60.6  38.7  0.7 2762723  71.0  29.0  0.0 \n12/2015  17740  75.5  24.2  0.3 453 60.9  38.4  0.7 2831317  68.8  31.2  0.0 \n01/2016  19589  75.9  23.7  0.4 468 61.3  38.0  0.6 2680810  77.2  22.8  0.0 \n02/2016  18500  77.4  22.1  0.5 485 58.8  40.2  1.0 2708973  68.4  31.6  0.0 \n03/2016  19638  76.3  23.2  0.6 494 60.1  39.1  0.8 2858237  67.7  32.3  0.0 \n04/2016  20242  75.1  24.5  0.4 528 59.5  40.0  0.6 3041838  60.2  39.8  0.0 \n05/2016  19570  75.1  24.6  0.3 540 63.9  35.6  0.6 3818994  54.6  45.4  0.0 \n15 \n 06/2016  19315  77.5  22.0  0.4 532 64.1  35.0  0.9 2900978  70.1  29.9  0.0 \n07/2016  18658  77.9  21.7  0.4 544 64.0  35.3  0.7 3049748  66.3  33.7  0.0 \n08/2016  18999  73.7  25.9  0.4 550 61.5  37.8  0.7 4019756  67.1  32.9  0.0 \n09/2016  19488  74.0  25.7  0.3 554 62.3  37.0  0.7 4357140  62.4  37.6  0.0 \n10/2016  21005  75.9  23.8  0.3 571 62.3  37.0  0.7 4304908  59.9  40.1  0.0 \n11/2016  18585  76.2  23.5  0.3 536 62.5  36.8  0.7 3476339  53.6  46.4  0.0 \n12/2016  17747  76.4  23.3  0.3 553 62.4  37.1  0.5 3504012  43.1  56.9  0.0 \n01/2017  21138  76.2  23.6  0.2 580 62.4  37.1  0.5 3737598  47.1  52.9  0.0 \n02/2017  19613  74.6  25.2  0.2 575 60.5  39.0  0.5 2987266  49.5  50.5  0.0 \n03/2017  21011  73.4  26.4  0.2 577 62.6  37.1  0.3 3962861  65.1  34.9  0.0 \n04/2017  20617  71.5  28.3  0.2 626 61.8  37.5  0.6 2851254  46.6  53.4  0.0 \n05/2017  21478  72.5  27.3  0.2 616 61.2  38.1  0.6 2748132  53.7  46.3  0.0 \n06/2017  18632  71.6  28.2  0.2 582 62.7  36.8  0.5 2198230  62.6  37.4  0.0 \n07/2017  19643  72.7  27.0  0.2 632 61.6  37.7  0.8 3221800  72.3  27.7  0.0 \n08/2017  20454  73.0  26.7  0.3 631 62.9  36.5  0.6 2522100  51.6  48.4  0.0 \n09/2017  19345  71.0  28.7  0.3 624 61.4  38.1  0.5 2187021  62.4  37.6  0.0 \n10/2017  19123  71.4  28.3  0.3 634 61.7  37.9  0.5 2010559  67.3  32.7  0.0 \n11/2017  18746  69.1  30.6  0.3 607 60.6  38.9  0.5 3750020  71.4  28.6  0.0 \n12/2017  17331  67.6  32.1  0.3 606 63.0  36.5  0.5 2537571  50.1  49.9  0.0 \n01/2018  19014  69.7  30.0  0.3 629 61.7  37.7  0.6 2703535  59.2  40.8  0.0 \n02/2018  16806  68.2  31.5  0.3 618 61.7  37.4  1.0 2725997  54.2  45.8  0.0 \n03/2018  18433  68.0  31.6  0.3 617 60.3  39.1  0.6 2469085  56.7  43.3  0.0 \n04/2018  17771  67.5  32.3  0.2 598 59.5  39.6  0.8 3009583  58.9  41.1  0.0 \n05/2018  16739  67.6  32.0  0.4 602 58.5  40.7  0.8 2281952  47.6  52.4  0.0 \n06/2018  15178  67.4  32.4  0.2 601 58.2  41.3  0.5 2590198  71.4  28.6  0.0 \n07/2018  16225  70.6  29.2  0.1 624 59.9  39.4  0.6 1403892  54.9  45.1  0.0 \n08/2018  16360  67.7  32.1  0.2 638 58.9  40.4  0.6 1519633  53.3  46.7  0.0 \n09/2018  15948  67.6  32.3  0.1 624 59.5  40.1  0.5 1395174  54.2  45.8  0.0 \n10/2018  18377  65.5  34.3  0.2 649 59.0  40.1  0.9 1670604  50.7  49.3  0.0 \n11/2018  17574  66.4  33.5  0.1 669 58.9  40.4  0.7 2090182  47.7  52.3  0.0 \n12/2018  17283  66.8  33.0  0.2 652 58.1  41.4  0.5 1860983  58.0  42.0  0.0 \n01/2019  20819  65.9  34.0  0.1 695 59.4  40.3  0.3 2193122  53.7  46.3  0.0 \n02/2019  22835  64.2  35.8  0.1 769 55.9  43.7  0.4 3002673  55.1  44.9  0.0 \n03/2019  27341  66.7  33.2  0.1 817 54.0  45.3  0.7 3131218  58.7  41.3  0.0 \n04/2019  25084  65.1  34.7  0.2 814 54.8  44.7  0.5 2813407  54.1  45.9  0.0 \n05/2019  24604  65.5  34.4  0.1 810 53.7  45.7  0.6 2267324  56.7  43.3  0.0 \n06/2019  21406  65.3  34.6  0.1 786 54.5  44.9  0.6 1975834  63.9  36.1  0.0 \n07/2019  18346  63.2  36.7  0.1 724 56.4  43.1  0.6 1401804  50.6  49.4  0.0 \n08/2019  18136  61.8  38.0  0.1 723 58.1  41.4  0.6 1189524  48.8  51.2  0.0 \n09/2019  18981  65.2  34.7  0.1 753 57.0  42.5  0.5 1781059  65.7  34.3  0.0 \n10/2019  18449  67.2  32.7  0.2 760 57.4  42.2  0.4 1822944  51.0  49.0  0.0 \n11/2019  18206  67.9  32.0  0.1 745 57.9  41.7  0.4 1536385  51.8  48.2  0.0 \n12/2019  18325  67.6  32.4  0.0 737 58.1  41.8  0.1 1448610  58.9  41.1  0.0 \n01/2020  20617  70.7  29.3  0.0 746 59.7  40.2  0.1 1964350  48.4  51.6  0.0 \n02/2020  18036  68.4  31.5  0.1 734 56.9  42.5  0.5 1791510  51.8  48.2  0.0 \n03/2020  22149  66.4  33.5  0.1 726 57.2  42.6  0.3 4692857  15.8  84.2  0.0 \n04/2020  26276  70.7  29.2  0.1 745 59.2  40.5  0.3 4244794  29.0  70.9  0.0 \n05/2020  28875  75.4  24.5  0.1 757 57.5  42.1  0.4 4088297  36.6  63.4  0.0 \n06/2020  21074  69.8  30.2  0.0 705 56.6  43.0  0.4 2940719  30.9  69.1  0.0 \n07/2020  22582  68.4  31.6  0.1 775 55.2  44.1  0.6 6445781  20.2  79.8  0.0 \n08/2020  22133  70.7  29.2  0.1 785 54.1  45.0  0.9 4988837  28.7  71.3  0.0 \n09/2020  21407  69.3  30.6  0.1 729 57.2  42.1  0.7 3196672  26.2  73.8  0.0 \n16 \n 10/2020  21435  66.8  33.2  0.0 751 54.6  45.0  0.4 2317326  26.6  73.4  0.0 \n11/2020  19777  66.4  33.6  0.1 773 53.8  45.5  0.6 2536469  22.6  77.4  0.0 \n \n \nFig. S 1. A. The proportion of posts  by group valence , excluding the top 10 vaccine groups in terms of the \ntotal number  of posts  generated . A stacked bar represents the proportions of Facebook posts created by \npro-vaccine , anti -vaccine , and mixed/ neutral groups in a given month (y -axis on the left). A dot in dicates the \ntotal number of posts created by all vaccine groups in a given month (y -axis on the right).  B. The proportion \nof posts  by group valence, excluding the top 20 vaccine groups in terms of the total number of posts \ngenerated . \nS3.2 The Number of Active Groups  \nThe 107 -month average of the total number of active vaccine groups  in a month \nwas 485.9 (SD = 208.9, Median = 536 ). The average proportions of active  anti-\nvaccine, pro -vaccine, and mixed/neutral groups were 58.4% ( SD = 2.9%, Median \n= 58.3%), 40.9% (SD = 2.9%, Median = 40.7%), and 0. 7% (SD = 0.3%, Median = \n0.7%, N = 107), respectively.  Table S2 shows the number of active groups in a \nmonth and the proportion of active anti -vaccine, pro -vaccine, and mixed/neutral \ngroups.  \n \nS3.3 The Number of Shares  \nThe 107 -month average of the total number of shares  was 1933657 .1 (SD = \n1371819 .3, Median = 1975834 ). The average proportions of  shares received by  \nanti- and pro-vaccine  groups  were 64.5% (SD = 17.0%, Median = 67.3%) and \n35.5% (SD = 17.0%, Median = 32.7%) , respectively . The average proportion of  \n\n17 \n share s received by  mixed/ neutra l groups  was less than 0.01% . The total number of \nshares in each month and the proportion of shares received by anti -vaccine, pro -\nvaccine, and mixed/neutral groups are shown in Table S2. \n \nS3.4 The Number of Comments and Reactions  \nThe 107 -month average of the total number of comments  in a month  was \n517223 .3 (SD = 420892 .7, Median = 509730 ). The average proportions of \ncomments  received by anti -vaccine , pro-vaccine , and mixed/ neutral  groups were \n49.8% (SD = 15.0%, Median = 45.4%), 50.1% (SD = 15.0%, Median = 54.5%), \nand 0.1% ( SD = 0.1%, Median = 0.0% , N = 107 ), respectively.  The total number \nof comments received by all vaccine groups and the proportions of comments \nrecei ved by pro -vaccine, anti -vaccine, and mixed/ neutral groups are visualized in \nFig. S 2A. \nThe 107 -month average of the total number of reactions  in a month  was \n4498344 .6 (SD = 5160374 .0, Median = 3630366 ). The average proportions of  \nreactions  received by  anti-vaccine and pro -vaccine groups were 43.6% (SD = \n14.7%, Median = 42.6%) and 56.4% (SD = 14.7%, Median = 57.4%), \nrespectively.  The average proportion of reactions  received by mixed/ neutra l \ngroups was less than 0.01%.  The total number of reactions received by all vaccine \ngroups and the proportions of comments recei ved by pro -vaccine, anti -vaccine, \nand mixed/neutral  groups are visualized in Fig. S 2B. \n \n18 \n  \nFig. S 2. A. Comments on vaccine content. A stacked bar represents the proportions of shares that pro -\nvaccine , anti-vaccine , mixed/neutral groups received in total in a given month (y -axis on the left). A dot \nindicates the total number of comments  in a given month (y -axis on the right).  B. Reaction to  vaccine \ncontent . \n \nS3.5 Posts per Active Group  in a Year  \nTable S3 shows the average number of posts in an active group in a year and the \ndifference between  active anti -vaccine  and pro-vaccine groups.  The result s \nindicate that an anti-vaccine group create d more posts  than a pro-vaccine group  in \ngeneral . The 9 -year average number of posts produced by  anti-vaccine groups was \nalso 2.4 times greater than pro -vaccine groups.  \n \nTable S3. The average number of posts per active vaccine group and the \ndifference between pro - and anti -vaccine groups  \nYear  Num. posts per active group  \n(Pro -vaccine)  Num. posts per active group  \n(Anti -vaccine)  Difference between pro \nand anti \nAverage  \n(SD) Median  N Average  \n(SD) Median  N MW test U1 KS test  D \n2012  97.7 \n(134.4)  34 125 404.0 \n(1316.8)  38 177 9994.0  0.170 *  \n\n19 \n 2013  113.9 \n(221.3)  26 181 374.4 \n(1199.6)  38 219 17855.5  * 0.125  \n2014  120.1 \n(247.7)  25 229 368.7 \n(1048.4)  53 252 24749.0  ** 0.124  * \n2015  164.8 \n(383.5)  27 311 369.7 \n(1530.8)  48 410 55253.0  ** 0.14 2 **  \n2016  160.6 \n(363.4)  27 341 332.7 \n(1254.5)  51 528 79317.0  ** 0.11 4 **  \n2017  162.1 \n(431.0)  21 404 292.5 \n(1221.1)  42 585 104898.5  ** 0.12 3 **  \n2018  144.2 \n(338.3)  20 457 231.1 \n(918.2)  30 603 127169.0  * 0.070  \n2019  133.7 \n(361.9)  13 650 238.3 \n(774.4)  37 694 190222.0  *** 0.15 4 ***  \n2020  108.2 \n(283.2)  13 685 237.8 \n(709.7)  30 715 204730.0  *** 0.162  *** \n9-year \nAverage  133.9    316.6      \nNote . Standard deviation in parenthesis. MW and KS stand for Mann -Whitney and Kolmogorov -\nSmirnov, respectively.  U1 is the MW statistics for the pro -vaccine sample of a given year. The MW \nstatistics for the anti -vaccine sample of a given year, U2, is calculated as U2 = N1N2 - U1. *P < .05, ** P \n< .01, *** P < .001  \n \n \nS3.6 Group Lifetime  \nThe lifetime of a vaccine group was defined as the number of days  between its \nfirst post and its last post.  The lifetime can range between 0  (the first and last \nposts were posted on the same day)  and 3,256  days (the first post on January 1st, \n2012 , and the last post on November 30th, 2020) . A vaccine group with only one \npost was assigned a lifetime value of 0. The convers ion from the number of days \nto the number of years was conducted by dividing  the number of days by 365. \nFig. 1E  shows the distribution of lifetimes in the number of years.  \nThe average lifetime of an anti -vaccine group  was 1199 .0 days (SD = \n1049 .9, Median = 1004 , N = 1083 ) or 3.28 years . The average lifetime of a pro -\nvaccine group was 784.4 days (SD = 974.8, Median = 333.5 , N = 1206 ) or 2.15 \nyears . The difference between the anti - and pro -vaccine groups was significant  \n(Mann -Whitney U = 486188 .5, P < 0.0001; Kolmogorov -Smirnov D = 0.218, P < \n0.0001) .  \n20 \n S4 Analysis: The Use of Information Sources  \n \nS4.1 The Use of Information Sources  \nIn total, 86.2% of all posts included at least one URL, while only 13.8% did not \ninclude any URL. When aggregated by vaccine groups, 82.7% (SD = 25.8%, N = \n2328) of posts in a vaccine group  included one or more URLs.  \n \nS4.2 Shortened URLs  \nLink shortening services, such as bit.ly and tinyurl.com, receive URL s from their \nusers  and convert them  to new shorter URL s that redirect to the original URL s. \nFacebook users often include shortened URLs in their social media content \ninstead of original full URL s, and some of the information available in full URLs \nare removed during the process of link shortening. For example, bit.ly shortens \nhttps://en.wikipedia.org/wiki/Vaccine  into https://bit.ly/3zqKgw1 . In this \nexample, while the original full URL include s information about the domain, i.e., \nwikipedia.org, its shortened version does not.  \nHence , we identified shortened URLs, found their original full URLs, and \nextracted information about their actual domains. For this purp ose, we built a list \nof 63 popular link shortening services by supplementing the list of 49 services  \nreported by Yang et al. (20) and adding 14 more services  to it (fb.me, is.gd, \nchng.it, tobtr.com, eepurl.com, cutt.ly, gf.me, hubs.ly, gates.ly, loom.ly, zurl.co, \nsnip.ly, ed.gr, and m -gat.es ) to cover  all shortening services that are responsible \nfor 100 or more  URLs in our dataset . We detected shortened URLs based on this \nlist, retrieved their original URLs by transmitting HTTP calls to the shortened \nURLs and capturing redirected full URLs, and then identified actual domains \nfrom the original URLs. Original URLs were not identifiable for some of the \nshortened URLs, and in these cases , domains of their link shortening services \nwere considered as their actual domains.  \n \nTable S4. The domain list of link shortening services. 49 of the 63 services were \nadopted from Yang et al . (20) \nbit.ly  \ndlvr.it  \nliicr.nl  j.mp \nwapo.st  \nreut.rs  bitly.com  \ncrfrm.us  \nflip.it  sc.mp  \ngop.cm  \ncrwd.fr  hubs.ly  \ngates.ly  \nloom.ly  \n21 \n tinyurl.com  \ngoo.gl  \nift.tt \now.ly  \nfxn.ws  \nbuff.ly  \nback.ly  \namzn.to  \nnyti.ms  \nnyp.st  \ndailysign.al  drudge.tw  \nshar.es  \nsumo.ly  \nrebrand.ly  \ncovfefe.bz  \ntrib.al  \nyhoo.it  \nt.co \nshr.lc  \npo.st  \ndld.bz  mf.tt  \nwp.me  \nvoat.co  \nzurl.co  \nfw.to  \nmol.im  \nread.bi  \ndisq.us  \ntmsnrt.rs  \nusat.ly  \naje.io  zpr.io  \nscq.io  \ntrib.in  \nowl.li  \nfb.me  \nis.gd  \nchng.it  \ntobtr.com  \neepurl.com  \ncutt.ly  \ngf.me  zurl.co  \nsnip.ly  \ned.gr  \nm-gat.es  \n     \n \nS4.3 Facebook Internal Sources and External Sources  \nWe identified top-level domains of all URLs  included in vaccine posts . For \nexample, the top-level domain of an URL, https://www.cnn.com/health , is \ncnn.com . Each URL was  classified into  one of the two types  of information \nsources  based on its domain : Facebook internal sources and external sources.  \nFacebook internal sources were  identified by detecting URLs whose top -\nlevel domains are  the Facebook domains (e.g., facebook.com and fb.com). The \ninclusion of  these Facebook domains  in a post  indicates that  the post  referenced or \ncontained  Facebook in -house content (such as photos, videos, and notes stored on \nFacebook ), Facebook accounts (such as Facebook pages, groups, and individual \nprofiles ), or Facebook services  (such as Facebook Watch)  on a post. URLs that \nwere not classified as Facebo ok internal sources were defined as external sources.  \nFig. 2A shows the monthly average proportion of posts using at least one \nFacebook internal source in an active  vaccine group  and the monthly average \nproportion of posts using at least one external source in an active vaccine group . \nFig. S 3 shows the average proportions of posts  in an active  pro- and anti -\nvaccine group  in each year.  First, Fig. S 3A shows the average proportions  of posts \nusing at least one Facebook internal source  in an active vaccine group each year . \nThe proportion  of posts using  at least one  Facebook internal source  in an active  \npro-vaccine group  had increased from 8.0% (SD = 13.7%,  Median = 2.3%,  N = \n125) in 2012 to 55.7% (SD = 35.6%,  Median = 58.2%,  N = 685) in 2020 . The \ndifference  between 2012 and 2020  was statistically significant ( Mann -Whitney U \n= 12703 .0, P < 0.0001 ; Kolmogorov -Smirnov D = 0.672, P < 0.0001 ). The \nproportion  of posts using at least one Facebook internal source in an active anti-\n22 \n vaccine group had also increased from 9.5% (SD = 16.1%, Median = 3.9%,  N = \n177) in 2012 to 44.4% (SD = 31.2%, Median = 40. 0%, N = 715) in 2020. The \ndifference  between 2012 and 2020 was statistically significant (Mann -Whitney U \n= 2068 4.5, P < 0.0001; Kolmogorov -Smirnov D = 0.633, P < 0.0001) . The 9 -year \naverage proportion of posts using Facebook internal sources was 34.6% among \npro-vaccine groups and 29.1% among anti -vaccine groups.  \n \n \nFig. S 3 A. The proportion of posts using at least on e Facebook internal source in a n active vaccine  group in a \nyear. Blue bars  represent pro -vaccine groups, and red bars  represent anti -vaccine groups.  Error bars \nindicate 95% confidence intervals of the mean  computed using  bootstrapping . Each gray dot indicates a n \nactive  vaccine group  in a given year . B. The proportion of posts using at least one external source in a n \nactive vaccine  group in a year . \n \n\n23 \n Second, Fig. S 3B shows the average proportions of posts using at least one \nexternal source in an active vaccine group each year. T he proportion  of posts \nusing at least one external  source in a n active pro-vaccine group had decreased \nfrom 66.2% (SD = 36.2%, Median = 81.4%, N = 125) in 2012 to 43.9% (SD = \n37.1%, Median = 42.0%,  N = 685) in 2020. The difference between 2012 and \n2020 was statistically significant (Mann -Whitney U = 29423.5, P < 0.0001; \nKolmogorov -Smirnov D = 0.354, P < 0.0001).  The proportion  of posts using at \nleast one external  source in an active anti-vaccine group had also decreased  from \n70.3% (SD = 28.9%, Median = 78.2%,  N = 177) in 2012 to 55.5% (SD = 31. 0%, \nMedian = 60.0%,  N = 715) in 2020. The difference between 2012 and 2020 was \nstatistically significant (Mann -Whitney U = 44645.5, P < 0.0001; Kolmogorov -\nSmirnov D = 0.303, P < 0.0001). The 9 -year average proportion of posts using at \nleast one external source was 56.1% among active pro-vaccine groups and 66.2% \namong active anti-vaccine groups.  \n \nS4.3.1 Video Sources  \nFacebook and YouTube were  the two most frequently used sources by vaccine \ngroups, responsible for 35.2% of all URLs  included  in vaccine content. As an \nimportant case analysis examining the use of Facebook internal sources and \nexternal sources, we compared the proportion s of video posts based on Facebook \nvideos and YouTube videos. Facebook assigns one of the following labels to each  \npost: photo, link, native_video, youtube, video, status, live_video_complete, \nlive_video, live_video_scheduled, and albu m. We classified posts labeled \nnative_video, video, live_video_complete, live_video, or live_video_scheduled \ninto the \u201cvideo posts using Facebook videos\u201d  category , and posts labeled youtube \ninto the \u201c video posts using YouTube  videos\u201d category . All p osts in these two \ncategories were defined as \u201cvideo posts.\u201d  \n Videos were  a major type of resource s that vaccine groups utilize d to \nsupport their narratives . Anti-vaccine groups tended to use videos more than pro -\nvaccine groups.  First, the proportion of vaccine groups that created one or more \nvideo posts among all active groups each year is shown in Fig. S4A. The 9 -year \naverage proportion was 74.5% among anti -vaccine groups and 55.5% among pro -\nvaccine groups.  Second, the proportion of video posts in a n active  vaccine group \neach year is displayed in Fig. S4B. The 9 -year average was 14.5% among anti -\nvaccine groups and 7.3% among pro -vaccine groups.  \n24 \n  The proportion of video posts using Facebook videos  and YouTube videos  \nin a vaccine group that created at least one video post each month  is shown in  Fig. \n2B. Fig. S 5 shows the proportion of video posts using Facebook videos  and \nYouTube videos  in a vaccine group that created at least one video post in a given \nyear.  Among pro -vaccin e groups, the average proportion was 26.0% in 201 2 (SD \n= 31.8%, N = 65) and 66.9% in 2020 ( SD = 38.2%, N = 382). The difference  \nbetween 2012 and 2020  was statistically significant (Mann -Whitney U = 5919 .0, \nP < 0.0001; Kolmogorov -Smirnov D = 0.513, P < 0.0001).  Among anti -vaccin e \ngroups, the average proportion was 16.2% in 2012 ( SD = 24.8%, N = 123) and \n63.3% in 2020 ( SD = 32.1%, N = 537) on average . The difference was statistically \nsignificant (Mann -Whitney U = 9839.5 , P < 0.0001; Kolmogorov -Smirnov D = \n0.631, P < 0.0001) . \n \n \n \nFig. S4. A. The proportion of active groups that generated at least one video post among all \nactive groups in a given year.  Blue represent s pro-vaccine groups, and red represent s anti-\nvaccine groups.  B. The proportion of video posts among all posts in a vaccine group  in a given \nyear. Error bars indicate 95% confidence intervals of the me an computed using bootstrapping. \nEach gray dot indicates a n active  vaccine group.   \n \n\n25 \n  \nFig. S 5. The proportion of video posts using Facebook video s in a  vaccine group that created at \nleast one video post each  year. Error bars indicate 95% confidence intervals of the mean \ncomputed using bootstrapping. Each gray dot indicates a vaccine group.  \n \nS4.4 Subtypes of External Sources  \nAll non-Faceboo k domains were defined as \u201cexternal domains .\u201d URLs that were \ndirected to webpage s or resources  within external domains were considered as \nindicating the use of external sources. We focused on  the use of  external sources  \nthat are known to supply information with low credibility  (i.e., low credibility \nsources)  and compared it with the use of other subtypes  of external sources : \ngovernment sources , social media sources , and news sources . \n \nS4.4.1 Government Sources  \nIn total  15,707 domains were defined as government domains. These domains are \nincluded in at least one of the following lists:  the .gov domains listed by gsa.gov \n(21), the U.S. government -managed non -.gov listed by search.gov (22), and the \n87 international government domains (23). If the top -level domain of an URL was \na government domain  (for example, https://www.cdc.gov/vaccines/index.html) , \nthe URL was considered as indicating the use of a government source.  \nFig. 2 C shows the monthly average proportions of posts using one or more \ngovernment  sources in an active anti - or pro -vaccine group . The 107-month  \n\n26 \n average was 3.6% (SD = 1.5%) for anti-vaccine groups  and 4.5% (SD = 1.3%) for \npro-vaccine groups . \nAs reported in  Table S 5, Mann -Whitney tests show that the proportion of \nposts using government  sources was significantly greater in a n active anti-vaccine \ngroup than a n active pro-vaccine group between  2015  and 2020. The average \nproportion s of posts using government sources in an active group  each year are \nshown in Fig S 6A. \n \nTable S 5. The proportion of posts using at least one government source in an \nactive  pro- and anti -vaccine groups  \nYear  Pro-vaccine  group  Anti-vaccine group  Difference between pro and anti  \nAvg. (%)  \n(SD) Median (%)  N1 Avg. (%)  \n(SD) Median (%)  N2 MW test  U1 KS test  D \n2012  6.4 \n(15.2)  0.5 125 3.3 \n(9.5)  0.2 177 10328.0  0.109  \n2013  5.0 \n(12.0)  0.0 181 2.5 \n(5.6)  0.0 219 19527.5  0.099  \n2014  3.6 \n(8.6)  0.0 229 2.5 \n(7.5)  0.0 252 28095.0  0.089  \n2015  4.2 \n(11.9)  0.0 311 4.3 \n(10.3)  1.0 410 55727.0 **  0.134 **  \n2016  4.2 \n(12.5)  0.0 341 4.2 \n(10.3)  0.7 528 77482.0 ***  0.164 ***  \n2017  2.9 \n(9.2)  0.0 404 4.4 \n(10.3)  0.8 585 93942.0 ***  0.215 ***  \n2018  2.8 \n(9.5)  0.0 457 4.8 \n(10.3)  0.5 603 109190.5 ***  0.215 ***  \n2019  3.3 \n(12.1)  0.0 650 5.9 \n(11.7)  1.8 694 156681.5 ***  0.292 ***  \n2020  3.3 \n(11.9)  0.0 685 4.6 \n(11.1)  0.6 715 185850.0 ***  0.254 ***  \nNote . Standard deviation in parenthesis. MW and KS stand for Mann -Whitney and Kolmogorov -Smirnov, respectively.  \nU1 is the MW statistics for the pro-vaccine sample  of a given year . The MW statistics for the anti-vaccine sample  of a \ngiven year , U2, is calculated as U2 = N1N2 - U1. *P < .05, ** P < .01, *** P < .001  \n \nAmong pro -vaccine groups, the proportion of posts using government  \nsources in an active pro -vaccine group decreased from 6.4% in 2012 ( SD = \n15.2%, N = 125) to 3.3% in 2020 ( SD = 11.9%, N = 685 ), and the difference was \nstatistically significant  (Mann -Whitney U = 32551 .0, P < 0.0001; Kolmogorov -\nSmirnov D = 0.230, P < 0.0001). Among anti -vaccine groups, the proportion of \nposts using government  sources  in an active anti -vaccine group  increased from \n2.5% (SD = 5.6%, N = 219) in 20 13 to 4.6% (SD = 11.1%, N = 715) in 2020 , and \nthe difference was significant  (U = 70099 .0, P = 0.0064; D = 0.141, P = 0.0021). \n27 \n  \nFig S 6. A. The proportion of posts using government sources in a group. A bar represents the \nproportions averaged among all active pro - or anti -vaccine groups in a given year.  Error bars \n\n28 \n indicate 95% confidence intervals of the mean computed using bootstrapping.  Red represents \nanti-vaccine , and blue represent s pro-vaccine.  B. News sources.  C. Social media sources. D. Low \ncredibility sources.  \n \nS4.4.2 News Sources  \nThe news domain list includes \u201cHard news domains\u201d in Bakshy et al. (24), \u201cNews \nmedia sites\u201d in Yang et al. (25), \u201cNewspapers\u201d and \u201cDigital -native news outlets\u201d \nlabeled by Pew Research Center (26), and \u201cGreen\u201d and \u201cYellow\u201d domains in \nGrinberg et al. (27). (Grinberg et al. categorized webs ites into  six levels : green, \nyellow, orange, red, sati re, and not applicable. According to their categorization \ncriteria, t he first five levels  correspond to \u201creasonable and accountable \njournalism ,\u201d \u201clow quality journalism ,\u201d \u201cnegligent or deceptive ,\u201d \u201clittle regard for \nthe truth ,\u201d \u201cself -described as satirical and affirmed as such by the annotators ,\u201d \nrespectively  (27).) Domains that were a lso included in the low credibility domain \nlist were excluded from the news domain list. If the top -level domain of an URL \nexist s in the news domain list  (e.g., https://www.cnn.com/health ), the URL was \nconsidered as indicating the use of a news source.  \nFig. 2D shows the monthly average proportions of posts using one or more \nnews  sources in an active anti - or pro -vaccine group. The 107 -month average was \n6.5% (SD = 1.6%) for anti -vaccine groups and 10.5% (SD = 2.6%) for pro -\nvaccine groups.  \nAs reported in Table S 6 and visualized in  Fig S 6B and also in Fig. 2 D, the \nproportion of posts using news sources was significantly greater in a pro -vaccine \ngroup than in an anti -vaccine group between 2013 and 201 5. In 2020, however, \nanti-vaccine groups ( M = 6.8%, SD = 10.6%, Median = 2.8%, N = 715) surpassed \npro-vaccine groups ( M = 6.0%, SD = 12.7%, Median = 0.0%, N = 685) in terms of \nthe proportion of posts using news sources , and the gap between anti - and pro -\nvaccine groups was stat istically significant  as shown in Table S 6. \n \nTable S 6. The proportion of posts using at least one news  source in an active  pro- \nand anti -vaccine groups  \nYear  Pro-vaccine group  Anti-vaccine group  Difference between pro and anti  \nAvg. (%)  \n(SD) Median (%)  N1 Avg. (%)  \n(SD) Median (%)  N2 MW test  U1 KS test  D \n2012  9.1 \n(15.6)  2.8 125 6.7 \n(10.1)  3.3 177 10870.5  0.100  \n29 \n 2013  10.1  \n(15.6)  4.0 181 6.0 \n(10.5)  2.4 219 17545.5 *  0.159 *  \n2014  10.7  \n(15.0)  4.6 229 5.9 \n(8.5)  2.4 252 25169.5 **  0.197 ***  \n2015  10.1  \n(12.7)  5.2 311 6.6 \n(10.7)  3.6 410 58035.5 *  0.192 ***  \n2016  8.3 \n(15.2)  1.0 341 4.2 \n(8.8)  1.3 528 82704.0 *  0.187 ***  \n2017  7.2 \n(11.1)  0.8 404 4.2 \n(6.6)  1.8 585 113527.0  0.154 ***  \n2018  7.0 \n(12.2)  0.0 457 5.2 \n(10.7)  1.3 603 137617.0  0.090 *  \n2019  7.6 \n(14.6)  0.0 650 6.4 \n(11.7)  2.6 694 210246.0 *  0.130 ***  \n2020  6.0 \n(12.7)  0.0 685 6.8 \n(10.6)  2.8 715 201180.5 ***  0.203 ***  \nNote . Standard deviation in parenthesis. MW and KS stand for Mann -Whitney and Kolmogorov -Smirnov, respectively. U1 is \nthe MW statistics for the pro -vaccine sample of a given year. The MW statistics for the anti -vaccine sample of a given year, \nU2, is calculated as U2 = N1N2 - U1. *P < .05, ** P < .01, *** P < .001  \n \nAmong pro -vaccine groups, the proportion of posts using news sources in \nan active  group significantly decreased from 10.7% in 20 14 (SD = 15. 0%, Media n \n= 4.6%, N = 229) to 6.0% in 2020 ( SD = 12.7%, Media n = 0.0%, N = 685; Mann -\nWhitney U = 59389 .5, P < 0.0001; Kolmogorov -Smirnov D = 0.241, P < 0.000 1). \nFor anti -vaccine groups, the proportion of posts using news sources displayed a \nsignificant increase between 2016 and 2020 from 4.2% ( SD = 8.8%, Median = \n1.3%, N = 528) in 2016 to 6.8% ( SD = 10.6%, Medi an = 2.8%, N = 715) in 2020 \n(U = 165006.0, P < 0.0001; D = 0.158, P < 0.0001).  These longitudinal changes \nare also visible in Fig S 6B and Fig. 2 D \n \nS4.4.3 Social Media Sources  \nThe social media domain list includes the domains of social media sites that Pew \nResearch Center identified as social media in one or more of the foll owing reports \nthey had published between 2012 and 2020 (28\u201336). The social media domain list \nconsists of the domains of  Twitter, YouTube, Instagram, TikTok , Reddit, Tumblr, \nGoogle+, Twitch, Vine, WhatsApp, and Snapchat. If the top -level domain of an \nURL exists  in this list, the URL was considered as indicating the use of a social \nmedia source.  \nFig. 2 E shows the monthly average proportions of posts using one or more \nsocial media  sources in an active anti - or pro -vaccine group. The 107 -month \naverage was 7.5% (SD = 1.4%) for anti -vaccine groups and 3.2% (SD = 1.6%) for \npro-vaccine groups.  \n30 \n As report ed in Table S 7 and displayed in Fig S 6C and Fig 2E , the \nproportion of posts using social media sources was significantly greater in an anti -\nvaccine group than a pro -vaccine group in every year between 2012 and 2020.  \nAmong pro -vaccine groups, the proportion of posts using social media sources in \nan active  group was 4.2% ( SD = 10.8%, Median = 0.0%, N = 125) in 2012 and \n5.8% ( SD = 13.6%, Median = 0.9%, N = 181) in 2013 on average, and it \nsignificantly decreased between 2013 and 2020 to 1.6% ( SD = 5.4%, Median = \n0.0%, N = 685; Mann -Whitney U = 44074.5, P < 0.0001; Kolmogorov -Smirnov \nD = 0.272, P < 0.0001). Among anti -vaccine groups, the average proportion of \nposts using social media sources in a group fluctuated between 5.6% (in 2019, SD \n= 10.8%, N = 694) and 8.9% (in 2013, SD = 16.8%, N = 219).  \n \nTable S 7. The proportion of posts using at least one social media source in an \nactive  pro- and anti -vaccine groups  \nYear  Pro-vaccine group  Anti-vaccine group  Difference between pro and anti  \nAvg. (%)  \n(SD) Median (%)  N1 Avg. (%)  \n(SD) Median (%) N2 MW test  U1 KS test  D \n2012  4.2 \n(10.8)  0.0 125 7.6 \n(13.3)  2.9 177 8541.0 ***  0.191 **  \n2013  5.8 \n(13.6)  0.9 181 8.9 \n(16.8)  3.2 219 16184.0 ***  0.168 **  \n2014  3.4 \n(5.9)  0.0 229 6.6 \n(10.8)  2.4 252 22371.5 ***  0.187 ***  \n2015  2.8 \n(5.7)  0.0 311 6.4 \n(8.4)  3.9 410 44580.0 ***  0.295 ***  \n2016  2.5 \n(7.4)  0.0 341 7.5 \n(11.4)  4.0 528 56917.0 ***  0.337 ***  \n2017  2.3 \n(7.3)  0.0 404 7.6 \n(12.9)  3.4 585 76990.0 ***  0.352 ***  \n2018  1.8 \n(7.5)  0.0 457 6.6 \n(12.7)  2.2 603 88730.5 ***  0.316 ***  \n2019  1.7 \n(7.1)  0.0 650 5.7 \n(10.8)  1.9 694 145920.0 ***  0.340 ***  \n2020  1.6 \n(5.4)  0.0 685 7.0 \n(12.5)  2.1 715 155185.5 ***  0.344 ***  \nNote . Standard deviation in parenthesis. MW and KS stand for Mann -Whitney and Kolmogorov -Smirnov, respectively. \nU1 is the MW statistics for the pro -vaccine sample of a given year. The MW statistics for the anti -vaccine sample of a \ngiven year, U2, is calculated as U2 = N1N2 - U1. *P < .05, ** P < .01, *** P < .001  \n \n \nS4.4.4 Low Credibility Sources  \nThe low credibility domain list includes (a) the domains categorized as \u201cBlack,\u201d \n\u201cRed,\u201d or \u201cOrange\u201d sources by Grinberg et al.  (27), and (b) the domains identified \nas \u201cvery low credibility\u201d and \u201clow credibility\u201d by Media Bias and Fact Check , an \n31 \n \u201cindependent website that rates the bias, factual accuracy, and credibility of media \nsources \u201d (37). According to Grinberg et al ., the Black sources were taken from \nprevious lists of domains reported by Guess et al. (38), Allcott and Gentzkow \n(39), Snopes.com, and Buzzfeed ; and the Red and Orange sources are websites \nthat they evaluated as  \u201cnegligent or deceptive\u201d and \u201clittle regard for the truth\u201d  \n(27). If the top -level domain of  an URL was included  in this list, the URL was \nconsidered as indicating the use of a low credibility  source.   \nFig. 2 F shows the monthly average proportions of posts using one or more \nlow credibility  sources in an active anti - or pro -vaccine group. The 107 -month \naverage was 1.8% (SD = 1.1%) for anti -vaccine groups and 0.1% (SD = 0.1%) for \npro-vaccine groups.  \nAs reported in Table S 8 and depicted in Fig S 6D and Fig 2F , the \nproportion of posts using low credibility sources was significantly greater in an \nanti-vaccine group than a pro -vaccine group  every year betw een 2012 and 2020. \nAmong anti -vaccine groups, the proportion of posts using low credibility sources  \nin a group  increased from 0.7% ( SD = 2.1%, N = 177) in 2012 to 3.6% ( SD = \n9.0%, N = 528)  in 2016 (Mann -Whitney U = 35034.0, P < 0.0001; Kolmogorov -\nSmirnov D = 0.264, P < 0.0001)  and then significantly decreased between 2016 \nand 2020 to 1.0% ( SD = 5.8%, N = 715; U = 138178.0, P < 0.0001; D = 0.246, P \n< 0.0001) . \n \nTable S 8. The proportion of posts using at least one low credibility  source in an \nactive  pro- and anti -vaccine groups  \nYear  Pro-vaccine group  Anti-vaccine group  Difference between pro and anti  \nAvg. (%)  \n(SD) Median (%)  N1 Avg. (%)  \n(SD) Median (%)  N2 MW test  U1 KS test  D \n2012  0.1 \n(0.9)  0.0 125 0.7 \n(2.1)  0.0 177 8076.0 ***  0.269 ***  \n2013  0.1 \n(0.9)  0.0 181 1.2 \n(2.8)  0.0 219 12730.0 ***  0.355 ***  \n2014  0.1 \n(0.4)  0.0 229 1.9 \n(6.2)  0.0 252 16903.5 ***  0.411 ***  \n2015  0.0 \n(0.3)  0.0 311 2.5 \n(6.0)  0.5 410 32518.0 ***  0.482 ***  \n2016  0.1 \n(0.9)  0.0 341 3.6 \n(9.0)  0.2 528 48859.0 ***  0.446 ***  \n2017  0.1 \n(0.6)  0.0 404 1.7 \n(5.9)  0.0 585 74576.0 ***  0.362 ***  \n2018  0.2 \n(2.4)  0.0 457 1.6 \n(7.4)  0.0 603 92424.0 ***  0.323 ***  \n2019  0.0 \n(0.6)  0.0 650 1.3 \n(5.9)  0.0 694 158677.0 ***  0.296 ***  \n2020  0.0 0.0 685 1.0 0.0 715 177020.5 ***  0.276 ***  \n32 \n (0.4)  (5.9)  \nNote . Standard deviation in parenthesis. MW and KS stand for Mann -Whitney and Kolmogorov -Smirnov, respectively. \nU1 is the MW statistics for the pro -vaccine sample of a given year. The MW statistics for the anti -vaccine sample of a \ngiven year, U2, is calculated as U2 = N1N2 - U1. *P < .05, ** P < .01, *** P < .001  \n \n \n  \n33 \n S5 Analysis: User Engagement and Information Sources  \nWe examined the association between the use of information sources in a post and \nthe level of user engagement with the post  in pro-vaccine and anti -vaccine groups . \nThree different variables represented  the level of user engagement with a post: the \nnumber of shares of a post  (M = 123.3, SD = 2139.8 , N = 1,678,351 ), the number \nof comments to a post  (M = 33.0, SD = 330.6 , N = 1,678,351 ), and the number of \nreactions to a post  (M = 286.8, SD = 6196. 9, N = 1,678,351 ). The number of \nreactions was computed by summing eight  differen t reaction counters of a post: \nlike, love, wow, haha, sad, angry, thankful, and care.  SciPy package (version \n1.6.1) for the Python programming language was used for all analyses.   \nFor the posts using at least one information source , which corresponds to \n86.2% (N = 1,446,27 5) of all posts in our data , we fit a negative binomial \nregression model predicting  each of the three user engagement variables . The \nsample mean s of the three dependent variables were as follows: the number of \nshares of a p ost (M = 140. 9, SD = 2284.9 , N = 1,446,27 5), the number of \ncomments to  a pos t (M = 34.7, SD = 349. 9, N = 1,446,27 5), and the number of \nreactions to a post ( M = 320.3, SD = 6344.6 , N = 1,446,27 5). 71.4% of the posts \nwere shared at least once. 63.4% of the post s received at least one comment, and \n91.0% received at least one reaction.  \nThe regression models included six covariates:  (1) Vaccine opposition (a \nbinary variable indicating whether the vaccine group that created the post is an \nanti-vaccine group (2) subscriber (a counting variable indicating  the number of \nFacebook users subscrib ed to  the vaccine group ), (3) posting time (an integer  \nvariable ranging from 0 ( January 2012 ) to 106 (November 2020) ), (4) video (a \nbinary variable indicating whether a post includes a video), ( 5) photo (a binary \nvariable indicating whether a post includes a photo) , (6) Facebook group  (a binary  \nvariable indicating whether the vaccine group is a Facebook group or a Facebook \npage) . The second covariate, t he number of subscribers , was measured at the  time \nof data collection . (CT also report s the number of subscribers measured at the \ntime of post creation, but this metric  was not used for the current analysis \nbecause , according to the company\u2019s announcement (40), it does not provide \naccurate information for  posts published before  August 2017 .)  \nAll standard errors were clustered at the vaccine group  level, and all \nmodels were estimated with cluster -robust standard error at the vaccine group  \nlevel.  We computed incidence rate ratios ( IRRs) by exponentiating the \n34 \n coefficients of each negative binomial regression model.  Regression analysis \nresults for shares, comments, and reactions are reported  in Fig 3B, Table S9, and \nTable S10, respectively.   \n \nTable S9. Results of a negative binomial model estimating the number of \ncomments  to a post  \n coef  IRR 95% CI  std err  z P > |z|  \nFB internal source     0.5524   1.7374  [1.214 5, 2.485 6]    0.183   3.024  0.002  \nGovernment source    -0.5585   0.572 1 [0.4604, 0.7108]     0.111  -5.041  <0.00 1 \nNews source     0.1169   1.1240  [0.8648, 1.4609]     0.134   0.874  0.382  \nSocial media source    -1.1875   0.30 50 [0.204 8, 0.454 3]    0.203  -5.841  <0.00 1 \nLow credibility source     0.5303   1.699 5 [1.0963, 2.634 5]    0.224   2.371  0.018  \nOther source    -0.4642   0.6286  [0.5064, 0.780 4]    0.110  -4.208  <0.00 1 \nVaccine opposition    -0.5235   0.5924  [0.40 40, 0.8688]     0.195  -2.680  0.007  \nPhoto    -0.2140   0.807 4 [0.5922, 1.100 7]    0.158  -1.353  0.176  \nVideo     0.3534   1.4238  [1.1118, 1.8234]     0.126   2.800  0.005  \nSubscriber  1.254e -06  1.0000  [1.0000, 1.0000]  4.64e -07  2.702  0.007  \nMonth     0.0089   1.0089  [1.0049, 1.01 30]    0.002   4.375  <0.00 1 \nFB group (ref: FB page)    -1.1075   0.330 4 [0.218 6, 0.4994]     0.211  -5.254  <0.00 1 \nIntercept     2.6365  13.964 4 [7.122 3,27.379 3]    0.344   7.675  <0.00 1 \nNote . Results of a negative binomial model estimating the number of comments  of \na post as a function of variables shown in the leftmost column. Coef, regression \ncoefficient; IRR, incidence rate ratio; 95% CI, 95% confidence interval of IRR; z, z \nscore. All standard errors were clustered at the vaccine group level, and all models \nwere estimated with cluster -robust standard error at the vaccine group level.  N = \n1,446,27 5 \n \nTable S10. Results of a negative binomial model estimating the number of \nreactions to a post  \n coef  IRR 95% CI  std err  z P > |z|  \nFB internal source     0.1814   1.1989  [0.864 7, 1.6623]     0.167   1.088  0.277  \nGovernment source    -0.8321   0.4351  [0.3259, 0.58 10]    0.147  -5.643  <0.00 1 \nNews source     0.0425   1.043 5 [0.8271, 1.316 4]    0.119   0.359  0.720  \nSocial media source    -0.9640   0.381 4 [0.2571, 0.5657]     0.201  -4.792  <0.00 1 \nLow credibility source     0.5915   1.8066  [1.276 4, 2.557 1]    0.177   3.337  0.001  \nOther source    -0.2992   0.741 4 [0.598 8, 0.9179]     0.109  -2.746  0.006  \nVaccine opposition    -0.2775   0.757 7 [0.529 2, 1.084 9]    0.183  -1.515  0.130  \nPhoto     0.5376   1.71 20 [1.3152, 2.2284]     0.135   3.997  <0.00 1 \nVideo     0.3167   1.3726  [1.063 3, 1.7719]     0.130   2.431  0.015  \nSubscriber  1.796e -06  1.0000  [1.0000, 1.0000]  5.23e -07  3.437  0.001  \nMonth     0.0063   1.0063  [1.0019, 1.0107]     0.002   2.812  0.005  \nFB group (ref: FB page)    -2.0302   0.1313  [0.081 1, 0.212 7]    0.246  -8.251  <0.00 1 \nIntercept     4.2118  67.476 5 [32.774 5,138.9215]     0.368  11.431  <0.00 1 \nNote . Results of a negative binomial model estimating the number of reactions  of a post \nas a function of variables shown in the leftmost column. Coef, regression coefficient; \nIRR, incidence rate ratio; 95% CI, 95% confidence interval of IRR; z, z score. All \n35 \n standard errors were clustered at the vaccine group level, and all models w ere estimated \nwith cluster -robust standard error at the vaccine group level.  N = 1,446,27 5 \n \n \nS5.1 Robustness to Covariate Specification  \nWe checked the robustness of the aforementioned findings by estimating the \nassociation between the use of information sources in a post and the levels of user \nengagement  with it  while controlling for different sets of covariates . As shown in  \nTable S 11, the associations were very robust to the inclusion of vaccine opposition \nand month in the regression models.  \n \nTable S 11. Information sources and the number of shares, robustness to vaccine \nopposition  and month \n Share  Comment  \n Model 1  Model 2  Model 3  Model 1  Model 2  Model 3  \nFB internal   0.5155   0.4906   0.3669   0.5753 **   0.6525 **   0.5524 **  \nGovernment  -0.6235 ***  -0.6468 ***  -0.7424 ***  -0.5153 ***  -0.4748 ***  -0.5585 ***  \nNews   0.0193   0.0375  -0.0518   0.2136   0.1910   0.1169  \nSocial media  -0.7910 ***  -0.8038 ***  -0.7948 ***  -1.2878 ***  -1.2496 ***  -1.1875 ***  \nLow credibility   1.0490 ***   0.9204 ***   0.8649 ***   0.2951   0.5798 *   0.5303 *  \nOther  -0.1728  -0.2425 *  -0.2631 *  -0.5434 ***  -0.4436 ***  -0.4642 ***  \nVaccine opposition    0.3416   0.4410 *   -0.5780 **  -0.5235 **  \nMonth     0.0108 ***     0.0089 ***  \nFB group (ref: page)  -2.8730 ***  -2.9509 ***  -3.1031 ***  -1.2768 ***  -1.1032 ***  -1.1075 ***  \nSubscriber   1.83e -6 ***  1.90e -6 ***   1.99e -6 ***   1.36e -6 **  1.21e -6 **   1.25e -6 **  \nPhoto    0.2970   0.3711   0.4158  -0.0740  -0.1917  -0.2140  \nVideo    0.5414 **   0.5162 **   0.4960 **   0.3957 **   0.4445 **   0.3534 **  \n Reaction     \n Model 1  Model 2  Model 3     \nFB internal   0.2219   0.2393   0.1814     \nGovernment  -0.8115 ***  -0.7813 ***  -0.8321 ***     \nNews   0.1136   0.0948   0.0425     \nSocial media  -1.0190 ***  -0.9992 ***  -0.9640 ***     \nLow credibility   0.4758 *   0.6082 **   0.5915 **     \nOther  -0.3402 **  -0.2921 **  -0.2992 **     \nVaccine opposition   -0.3227  -0.2775     \nMonth     0.0063 **     \nFB group (ref: page)  -2.0969 ***  -2.0175 ***  -2.0302 ***     \nSubscriber   1.83e -6 ***  1.74e -6 **  1.80e -6 **     \nPhoto   0.5950 ***   0.5349 ***   0.5376 ***     \nVideo   0.3558 *   0.3688 **   0.3167 *     \nNote . Results of negative binomial models estimating the number of shares, comments, and reactions of a \npost as a function of variables shown in the leftmost column. The values are regression coefficients. All \nstandard errors were clustered at the vaccine group  level, and all models were estimated with cluster -\nrobust standard error at the vaccine group level. N = 1,446,27 5. *P < .05, ** P < .01, *** P < .001  \n \n36 \n  \nS5.2 Subgroup Analysis: Pro -vaccine and Anti -vaccine  \nTo examine  if the findings  reported in S 5 are consistent within a subset of pro-\nvaccine  groups or  anti-vaccine groups , we estimat ed the association between  the \nuse of  information sources and user engagement among  pro-vaccine and anti -\nvaccine  groups separately . The regression models estimated for this robustness \ncheck were identical to those in S 5, except that one variable , vaccine opposition  \nwas not included in the models  since it does not vary  within each subgroup.  In \ntotal, 6 models (3 user engagement variables \u00d7 2 subgroup s) were tested for this \ncheck.  All standard errors were clustered at the vaccine group level, and all \nmodels were estimated with cluster -robust standard error at the vaccine group \nlevel.  \n Even when the models were estimated for  pro-vaccine groups and anti -\nvaccine groups  separately , as shown in Table S 12, Table S 13, and Table S 14, the \nassociation s of the use of low credibility sources with the three user engagement  \nvariables  were still positive  and, in 4 out of 6 cases , still statistically significant. \nRegarding the use of social media sources in a post, all associations were still \nnegative and significant  even within the subsets of pro-vaccine groups and anti -\nvaccine groups.  The associations between the use of government sources and user \nengagement variables were all still negative and, in 5 out of 6 cases, maintained \ntheir statistical significance.  \n \nTable S 12. Results of negative binomial model s estimating the number of shares  \nof posts created by pro- and anti -vaccine groups  \n Posts by pro -vaccine groups  Posts by anti -vaccine groups  \n IRR [95% CI]  P > |z|  IRR [95% CI]  P > |z|  \nFB internal   1.2204 [0.4649, 3.2035]  0.6858   1.5618 [0.9215, 2.6471]  0.0976  \nGovernment   0.3058 [0.1367, 0.6842]  0.0039   0.7470 [0.6407, 0.8709]  0.0002  \nNews   1.0156 [0.6153, 1.6764]  0.9517   1.0816 [0.8557, 1.3670]  0.5117  \nSocial media   0.5749 [0.3570, 0.9257]  0.0228   0.4568 [0.3245, 0.6431]  <0.0001  \nLow credibility   1.2084 [0.6687, 2.1838]  0.5306   2.5538 [1.7515, 3.7236]  <0.0001  \nOther   0.5926 [0.4311, 0.8144]  0.0013   0.9171 [0.7470, 1.1259]  0.4081  \nPhoto   2.2319 [0.7313, 6.8120]  0.1580   1.2386 [0.7497, 2.0464]  0.4019  \nVideo   2.0633 [1.4187, 3.0007]  0.0001   1.7585 [1.2226, 2.5291]  0.0023  \nSubscriber   1.0000 [1.0000, 1.0000]  0.1527   1.0000 [1.0000, 1.0000]  <0.0001  \nMonth   1.0096 [1.0023, 1.0170]  0.0102   1.0117 [1.0056, 1.0178]  0.0001  \nFB group ( ref: FB page)   0.0207 [0.0080, 0.0535]  <0.0001   0.0554 [0.0400, 0.0768]  <0.0001  \nIntercept  23.2327 [6.5397,82.5350]  <0.0001  16.3193 [8.3828,31.7700]  <0.0001  \nN 434,359  1,011,91 6 \n37 \n Note . Results of a negative binomial model estimating the number of shares  of a post as a function of \nvariables shown in the leftmost column. Coef, regression coefficient; IRR, incidence rate ratio; 95% CI, \n95% confidence interval of IRR; All standard errors were clustered at the vaccine group level, and all \nmodels were estimate d with cluster -robust standard error at the vaccine group level.  \n \n \nTable S 13. Results of negative binomial models estimating the number of \ncomments of posts created by pro - and anti -vaccine groups  \n Posts by pro -vaccine groups  Posts by anti -vaccine groups  \n IRR [95% CI]  P > |z|  IRR [95% CI]  P > |z|  \nFB internal   1.4607 [0.7164, 2.9784]  0.2972  1.9072 [1.2732, 2.8567]  0.0017  \nGovernment   0.4448 [0.1544, 1.2808]  0.1333  0.8043 [0.6614, 0.9780]  0.0290  \nNews   1.0254 [0.7373, 1.4261]  0.8816  1.2180 [0.9461, 1.5680]  0.1259  \nSocial media   0.4508 [0.3459, 0.5875]  <0.0001  0.2908 [0.1879, 0.4499]  <0.0001  \nLow credibility   1.6479 [1.0223, 2.6563]  0.0403  1.6604 [1.0665, 2.5853]  0.0248  \nOther   0.5878 [0.4450, 0.7765]  0.0002  0.6537 [0.5081, 0.8411]  0.0009  \nPhoto   0.8717 [0.3771, 2.0147]  0.7480  0.7601 [0.5440, 1.0621]  0.1080  \nVideo   1.3771 [1.0343, 1.8335]  0.0284  1.5300 [1.1564, 2.0243]  0.0029  \nSubscriber   1.0000 [1.0000, 1.0000]  0.2631  1.0000 [1.0000, 1.0000]  0.0018  \nMonth   1.0098 [1.0035, 1.0162]  0.0024  1.0089 [1.0040, 1.0138]  0.0003  \nFB group (ref: FB page)   0.2815 [0.1189, 0.6668]  0.0040  0.3876 [0.2603, 0.5773]  <0.0001  \nIntercept  17.4444 [6.1170,49.7482]  <0.0001  6.5279 [3.5485,12.0090]  <0.0001  \nN 434,359  1,011,91 6 \nNote . Results of a negative binomial model estimating the number of comments of a post as a function of \nvariables shown in the leftmost column. Coef, regression coefficient; IRR, incidence rate ratio; 95% CI, \n95% confidence interval of IRR; All standard errors  were clustered at the vaccine group level, and all \nmodels were estimated with cluster -robust standard error at the vaccine group level.  \n \n \nTable S 14. Results of negative binomial models estimating the number of \nreactions of posts created by pro - and anti -vaccine groups  \n Posts by pro -vaccine groups  Posts by anti -vaccine groups  \n IRR [95% CI]  P > |z|  IRR [95% CI]  P > |z|  \nFB internal     1.3063 [ 0.7652, 2.2301]  0.3276   1.2183 [ 0.8424, 1.7619]  0.2943  \nGovernment     0.2438 [ 0.1329, 0.4472]  <0.0001   0.6587 [ 0.5560, 0.7804]  <0.0001  \nNews     1.1686 [ 0.7838, 1.7422]  0.4446   1.0794 [ 0.8472, 1.3754]  0.5363  \nSocial media     0.6197 [ 0.4432, 0.8665]  0.0051   0.3612 [ 0.2369, 0.5507]  <0.0001  \nLow credibility     1.1988 [ 0.7062, 2.0351]  0.5018   1.6983 [ 1.1477, 2.5128]  0.0081  \nOther     0.7198 [ 0.5569, 0.9302]  0.0120   0.7565 [ 0.5910, 0.9684]  0.0267  \nPhoto     1.8150 [ 0.8804, 3.7416]  0.1063   1.5281 [ 1.1473, 2.0351]  0.0037  \nVideo     1.4134 [ 1.0923, 1.8284]  0.0084   1.4227 [ 1.0798, 1.8745]  0.0122  \nSubscriber     1.0000 [ 1.0000, 1.0000]  0.1463   1.0000 [ 1.0000, 1.0000]  0.0002  \nMonth     1.0062 [ 0.9988, 1.0136]  0.0991   1.0070 [ 1.0018, 1.0124]  0.0090  \nFB group (ref: FB page)     0.1042 [ 0.0377, 0.2881]  <0.0001   0.1542 [ 0.0960, 0.2478]  <0.0001  \n38 \n Intercept  81.2663 [23.7394, 278.1968]  <0.0001  40.6861 [21.3134,77.6674]  <0.0001  \nN 434,359  1,011,91 6 \nNote . Results of a negative binomial model estimating the number of reactions of a post as a function of \nvariables shown in the leftmost column. Coef, regression coefficient; IRR, incidence rate ratio; 95% CI, 95% \nconfidence interval of IRR; All standard error s were clustered at the vaccine group level, and all models were \nestimated with cluster -robust standard error at the vaccine group level.  \n \n \n \n \n  \n39 \n S6 Analysis: Exclusive Sources  \nS6.1 Exclusive Sources  \nWe identified exclusive sources  for pro -vaccine groups  and exclusive sources  for \nanti-vaccine groups  each month . Exclusive sources  for pro -vaccine groups  refer to \ninformation  sources used by five or more pro-vaccine groups and not  by any anti -\nvaccine groups in a given  month . For example, if Source A was referenced by \nseven different pro-vaccine groups but was not referenced or mentioned by any \nanti-vaccine groups in September 2017 , Source A is a n exclusive  source  for pro -\nvaccine groups  of the month . Exclusive sources  for anti -vaccine groups , on the \nother hand, refer to information  sources that were used by five or more  anti-\nvaccine groups and not by any pro -vaccine groups in a given month . \nWe then calculated \u201csource exclusivity. \u201d The s ource exclusivity of a pro-\nvaccine [anti -vaccine] group was defined as the proportion of exclusive  pro-\nvaccine [anti -vaccine]  sources among all information sources used by the pro-\nvaccine [anti -vaccine] group  in a given month . Source exclusivity ranges from 0 % \nto 100%. For example, if the source exclusivity of an anti-vaccine group  was \n40%, it mean s that 4 out of 10 sources used in the group were  exclusive sources  \nfor anti -vaccine groups , which  were not utilized by any pro-vaccine groups  in the \ngiven month . In Fig. 4 and  Fig. S7, the source exclusivity of a n anti -vaccine group \nand the source exclusivity of a pro -vaccine group were referred to as \u201c% \nexclusive sources in an anti -vaccine group\u201d and \u201c% exclusive sources i n a pro -\nvaccine group,\u201d respectively , for ease of comprehension.  \nIt is worth emphasizing  that source exclusivity is the proportion  of \nexclusive sources  within  a vaccine  group . Source exclusivity is  not the total \nnumber of exclusive sources summed over vacc ine groups. Thus, even if anti-\nvaccine groups use more  information sources  in a month or there are more active \nanti-vaccine groups than active pro -vaccine groups in a month , the average source \nexclusivity  of anti -vaccine groups  of the month can be lower  than that of pro-\nvaccine groups.  \nThe average source exclusivities of an anti -vaccine group and a pro -\nvaccine group each month were displayed in Fig 4A.  It is shown that  anti-vaccine \ngroups were more  dependent  on their exclusive sources  than pro -vacci ne groups . \nWhen averaged across  the 107 months , the source exclusivity of an anti-vaccine \ngroup was 19.3% (SD = 4.1%). The source exclusivity  of a pro -vaccine group , on \nthe other hand,  was only 3.1% (SD = 1.5%). \n40 \n We examined  the robustness of these result s by calculating source \nexclusivity for each year, instead of each month.  As shown in Fig. S7, when \naveraged across the 9 years, the source exclusivity of anti -vaccine groups was \n15.3% (SD = 2.3%), while that of pro -vaccine groups was  only 2.9% (SD = \n1.2%). \nWe further identified that 2,601 sources were used by at least five anti -\nvaccine groups but never used by any pro -vaccine groups during the 107 -month \nperiod . Also,  297 sources were used by at least five pro -vaccine groups but never  \nused by any anti -vaccine groups during the 107 -month period.  We think that \nfuture research will be able to use the li sts of  these  \u201cdedicated\u201d anti -vaccine and \npro-vaccine sources in developing automated methods to detect views on vaccines \nvaccination from online content . The full lists of these sources are available \nonline  (41).    \n \nS6.1.1 Subtypes Among Exclusive Sources  \nWe identified low credibility, news, social media, and government sources among \nexclusive sources  for anti-vaccine [pro -vaccine]  groups  each month and defined \nthem as exclusive low credibility  sources , exclusive news  sources , exclusive \nsocial media  sources , and exclusive government sources  for anti-vaccine [pr o-\nvaccine]  groups , respectively.  \nWhen averaged over the 107 months  (Fig. 4A) , exclusive low credibility \nsources accounted for 5. 0% (SD = 3.2%) of all exclusive sources used by  an anti -\nvaccine group  each month . Exclusive government , news , social media  sourc es \nwere 2.2% ( SD = 2.5%), 3.3% (SD = 3.5%), and 0.1% ( SD = 0.2%),  respectively, \namong all exclusive sources used by an anti -vaccine group each month . \nFor pro -vaccine groups (Fig. 4B) , exclusive government , news , and social \nmedia  sources were 3.6% (SD = 11.2%), 5.5% (SD = 8.0%), and  0.4% (SD = \n2.5%), respectively, among all exclusive sources used by a pro -vaccine group \nwhen averaged over the 107 months. Low credibility sources were not identified \namong exclusive sources for pro -vaccine groups.  \n \n \n \n41 \n  \nFig. S7. Exclusive source s. A. Exclusive sources  for anti -vaccine groups  by year. The height of \neach bar indicates the proportion of exclusive  sources for  anti-vaccine groups  among all \ninformation sources used by  an anti -vaccine group  in a year . The red, blue, green, purple, and \nbrown, portions of a bar represent the proportions of exclusive low credibility, social media, \ngovernment, news, and other sources  for anti -vaccine groups , respectively, among all \ninformat ion sources  used by an anti -vaccine group . Error bars indicate 95% confidence intervals \nof the mean proportion of exclusive sources. B. Exclusive sources for pro -vaccine groups by year.  \n \n  \n\n42 \n S7 Analysis: Source Popularity and Anti -vaccine Affinity  \nS7.1 Source Popularity Among Pro - and Anti -vaccine Groups  \nWe assigned two different popularity s cores to each of the 7, 605 external \ninformation source s, which were  used by at least five different pro- or anti -\nvaccine groups  during the 107 -month period . These sources originated 91.6% of \nall URLs  linked to external sources of pro- and anti -vaccine groups . \nFirst, t he popularity of an information source  \ud835\udc56 among anti-vaccine groups  \n(\ud835\udc5f\ud835\udc56\ud835\udc4e) is calculated as \ud835\udc5f\ud835\udc56\ud835\udc4e=\ud835\udc5b\ud835\udc56\ud835\udc4e/\ud835\udc5b\ud835\udc4e, where \ud835\udc5b\ud835\udc4e is the total number of posts in anti -\nvaccine groups using one or more external sources, and \ud835\udc5b\ud835\udc56\ud835\udc4e is the total number of \nposts in anti -vaccine groups using \ud835\udc56 (0\u2264\ud835\udc5f\ud835\udc56\ud835\udc4e<1). The average \ud835\udc5f\ud835\udc56\ud835\udc4e was 9.2\u00d710-5 \nand ( SD = 1.0\u00d710-3). \nSecond, t he popularity of an information source \ud835\udc56 among pro -vaccine \ngroups  (\ud835\udc5f\ud835\udc56\ud835\udc5d) is calculated as \ud835\udc5f\ud835\udc56\ud835\udc5d=\ud835\udc5b\ud835\udc56\ud835\udc5d/\ud835\udc5b\ud835\udc5d, where \ud835\udc5b\ud835\udc5d is the total number of posts in \npro-vaccine groups using one or more external sources, and \ud835\udc5b\ud835\udc56\ud835\udc5d is the total \nnumber of posts in pro -vaccine gro ups using \ud835\udc56 (0\u2264\ud835\udc5f\ud835\udc56\ud835\udc5d<1). The average \ud835\udc5f\ud835\udc56\ud835\udc5d was \n9.0\u00d710-5 and ( SD = 6.5\u00d710-4). Because an external source was used in at least one \npost, \ud835\udc5f\ud835\udc56\ud835\udc4e and  \ud835\udc5f\ud835\udc56\ud835\udc5d also meet the following condition: \ud835\udc5f\ud835\udc56\ud835\udc4e+\ud835\udc5f\ud835\udc56\ud835\udc5d>0. Due to this \ncondition , the average popularity of a source is always greater than zero: (\ud835\udc5f\ud835\udc56\ud835\udc4e+\n\ud835\udc5f\ud835\udc56\ud835\udc5d)/2>0. \nAs shown in Fig. S 8, there was a negative correlation between \ud835\udc5f\ud835\udc56\ud835\udc4e and \n\ud835\udc5f\ud835\udc56\ud835\udc5d (Spearman \u03c1 = -0.04, P = 0.0004, N = 7605). The correlation remained  \nsignificant and negative  even when the outlier shown in Fig. S 8, YouTube,  was \nexcluded from the calculation  (\u03c1 = -0.04, P = 0.0003, N = 7604). The negative \ncorrelations indicate that the more widely used a source is among anti -vaccine \ngroups, the less widely used it is among pro -vaccine groups.  \n \n43 \n  \nFig. S 8. The distribution of \ud835\udc5f\ud835\udc56\ud835\udc4e and  \ud835\udc5f\ud835\udc56\ud835\udc5d of external sources. The histograms of \ud835\udc5f\ud835\udc56\ud835\udc4e and  \ud835\udc5f\ud835\udc56\ud835\udc5d on the \ntop and the right, respectively.  The dashed line represents the \ud835\udc5f\ud835\udc56\ud835\udc4e=\ud835\udc5f\ud835\udc56\ud835\udc5d line. N = 7,605. \n \nS7.2 Anti -vaccine Affinity Score  \nUsing the popularity scores described above, we assigned an anti -vaccine affinity \nscore to each of the external source s used by at least five vaccine groups . The \nanti-vaccine affinity score of a source represents how widely  the source is used by \nanti-vacci ne groups compared with  pro-vaccine groups. The anti -vaccine score of \nSource \ud835\udc56 is noted \u210e\ud835\udc56\ud835\udc4e and calculated as follows:  \n \n\u210e\ud835\udc56\ud835\udc4e=\ud835\udc5f\ud835\udc56\ud835\udc4e\u2212\ud835\udc5f\ud835\udc56\ud835\udc5d\n\ud835\udc5f\ud835\udc56\ud835\udc4e+\ud835\udc5f\ud835\udc56\ud835\udc5d  \n \nThis definition of anti -vaccine affinity has several good properties that \nsimplify our analysis an d interpretation. First, the score has the maximum value of \n1 when Source \ud835\udc56 is used only by anti -vaccine groups  (i.e., \ud835\udc5f\ud835\udc56\ud835\udc5d=0) and its \nminimum value of  \u22121 when it is used only by pro -vaccine groups  (i.e., \ud835\udc5f\ud835\udc56\ud835\udc4e=0). \nSecond, the score is positive when a  source is more popular among anti -vaccine \ngroups ( i.e., \ud835\udc5f\ud835\udc56\ud835\udc4e>\ud835\udc5f\ud835\udc56\ud835\udc5d) and negative when it is more popular among pro -vaccine \ngroups ( i.e., \ud835\udc5f\ud835\udc56\ud835\udc4e<\ud835\udc5f\ud835\udc56\ud835\udc5d). Third, for a source with \ud835\udc5f\ud835\udc56\ud835\udc5d>0, an anti -vaccine affinity \n\n44 \n score increases monotonically with a source\u2019s  relative popularity among anti -\nvaccine groups , which refers to the ratio between a source\u2019s anti -vaccine \npopularity and its pro -vaccine popularity  (i.e., \ud835\udc5f\ud835\udc56\ud835\udc4e/\ud835\udc5f\ud835\udc56\ud835\udc5d). Thus, for two different \nsources \ud835\udc56 and \ud835\udc57, \u210e\ud835\udc56\ud835\udc4e< \u210e\ud835\udc57\ud835\udc4e if  \ud835\udc5f\ud835\udc56\ud835\udc4e\n\ud835\udc5f\ud835\udc56\ud835\udc5d<\ud835\udc5f\ud835\udc57\ud835\udc4e\n\ud835\udc5f\ud835\udc57\ud835\udc5d.  \nThe distribution of \u210e\ud835\udc56\ud835\udc4e is shown in Fig. S 9. The average of \u210e\ud835\udc56\ud835\udc4e was 0. 21 \n(SD = 0.75, N = 7605 ).  \n \n \n \nFig. S 9. The d istribution of hia. The solid line indicates  the kernel density estimation.  N = 7,605. \n \n \n\n45 \n S7.3 Ideology  Alignment and Anti -vaccine Affinity  of Sources  \nWe examined the association between the anti-vaccine affinity score of an \ninformation source and the political view  that it tends to represent.  For this \npurpose, we adopted  a metric  reported by Bakshy et al.  (24) to quantify a source \u2019s \npolitical ideology . We  also check ed the robustness of findings  using different  \nmeasures  representing  a source\u2019s political characteristics . \n The list reported by Bakshy et al . (24) contains the top 500 most shared  \ndomains that had been shared at least 44,000 times on Facebook during the period \nfrom July 2014 to January 2015.  Each domain was assigned an average alignm ent \nscore , which  was calculated by comput ing the m ean political affiliation of \nFacebook users who shared each news story  from each domain  and then \ncalculating the average of these  mean values  for each domain . The authors found \nthat th e alignment score well capture d the ideolog ical differences  among  the \ninformation sources , so the current study called it the ideology alignment score.  \n We identified that 32 9 of the 500 domains  reported by  Bakshy et al.  were \nused by vaccine groups in the present  study . The results are visualized in Fig. \nS10. In this figure, e ach circle represents an information source. The color of a \ncircle depends on Source \ud835\udc56\u2019s anti-vaccine affinity  (\u210e\ud835\udc56\ud835\udc4e), and  the size of a circle is \nproportional to its average popularity , (\ud835\udc5f\ud835\udc56\ud835\udc4e+\ud835\udc5f\ud835\udc56\ud835\udc5d)/2. \nFor the  329 domains, we computed the correlation between their ideology  \nalignment scores and anti -vaccine affinity scores.  As Fig. S10 demonstrates , there \nwas a highly significant and positive correlation between anti-vacci ne affinity and \nideology alignment  (Spearman \u03c1 = 0.4 2, P < 0.0001, N = 329), indicating  that \ninformation sources used more widely by anti -vaccine groups  compared with  pro-\nvaccine groups  were  more ideologically conservative.  \nThe 329 sources displayed in Fig. S10 include two social media sites: \ntwitter.com and youtube.com. Considering the  difficulty of defining  and \ndeterminin g the overall  political  characteristics  of social media  sites (42, 43), we \nre-estimated the correlation after remov ing the two social media sites. The result \nis presented in Fig. 4C , and the correlation was still positive and significant  (\u03c1 = \n0.42, P < 0.0001, N = 327) . \n \nS7.3.1 Robustness Analysis : Ideology Alignment  based on MBFC Data \n Media Bias and Fact Check (MBFC, www.mediabiasfactcheck.com ) \nevaluate s news media  sites and classifies  each source into one of the five \n46 \n categories based on its assessment : left, left -center, center, right -center, and right.  \nIn April 2021, we retrieved their evaluation results of 1,920 sources , and 961 \nsources among them were used by at least five different vaccine groups in our \ndata. An ideology  alignment  score was assigned to each of the 961 source s based \non MBFC\u2019s evaluati on: -2(left), -1(left-center) , 0(center) , 1(right -center) , 2(right) . \nWe examined if a source\u2019s anti -vaccine affinity and its ideology alignment \nscore  reported by  MBFC  are correlated . It was  found that  there was a significant \ncorrelation between anti-vaccin e affinity and ideology alignment  (Spearman \u03c1 = \n0.14, P < 0.0001, N = 961,  Fig. S 11), confirming the aforementioned result  based \non alignment scores from Bakshy et al. (24).  \n \nS7.3.2 Robustness Check: Ideology Alignment  based on All Sides Data \n All Sides  (www.allsides.com ) publish es the \u201cmedia bias rating s\u201d that \nclassif y media sources  into five categories: left, left -center, center, right -center, \nand right.  We obtained All Sides\u2019 s rating data of 296 news media outlets (44). \nThere were  191 sources that existed both in the rating data and our list of external \nsources used by at lea st five different vaccine groups . We assigned an ideology  \nalignment  score to each  of the 191 sources based on All Sides\u2019s  evaluation:  -\n2(left), -1(left-center) , 0(center) , 1(right -center) , 2(right) . \nWe examined if a source\u2019s anti -vaccine affinity and its ideology alignment \nscore  based on All Sides\u2019 assessment  are correlated . It was found that there was a \nsignificant  and positive  correlation between anti -vaccine affinity and ideology \nalignment ( Spearman \u03c1 = 0.47, P < 0.0001, N = 191, Fig. S 12), confirming the \nfindings reported in S7.3 and S7.3. 1.  \n  \n47 \n  \n \nFig. S10. The association between the anti-vaccine affinity of an information source and its \nideology alignment  reported by Bakshy et al . (24). N = 329. \n \n \n\n48 \n  \n \nFig. S 11. The association between the anti-vaccine affinity of an information source and its \nideology alignment reported by MBFC  (mediabiasfactcheck.com) . N = 961. \n \n \n \n \n \n \n\n49 \n  \nFig. S 12. The association between anti -vaccine affinity of an information source  and its ideology \nalignment reported  by All Sides (allsides.com) . N = 191.  \n  \n\n50 \n S8 Analysis: Networks of Vaccine Groups within \nFacebook  \nWe constructed a weighted and undirect ed network among vaccine groups.  In this \nnetwork, each node represents  a vaccine  group. A n edge connecting  two nodes \nindicates that one vaccine group referenced the other group or its content, and the \nweight of a n edge  corresponds to the total number of refer ences between the two \ngroups.  All self -loops, which represent a vaccine group\u2019s referencing its own \ncontent, were removed from the network. Network analysis was conducted using \nNetworkX (45), a Python package for network data analysis. Network \nvisualization was based on Gephi, an open source software for network \nvisualization (46). The position of each node in a network  diagram  was \ndetermined by the ForceAtlas2 algorithm (47). \nFig. S 13 show s the network among 2,328 vaccine groups in our dataset . \nThe size of a node is proportional to its degree.  Isolated nodes that are not \nconnected with any other nodes are displayed on the l eft. The red , blue, and gray  \ncircles are anti -vaccine,  pro-vaccine , and mixed/neutral vaccine  groups, \nrespectively.  Edges connecting two anti -vaccine groups; two pro -vaccine groups; \nan anti -vaccine group and a pro -vaccine group; an anti - or pro-vaccine group with \na neutral/mixed vaccine group ; and two mixed/neutral groups  were colored red, \nblue, yellow , gray,  and gray  respectively.  In this network , 6.7% of all edges were \nconnecting an anti -vaccine group with a pro -vaccine group, while 66.8% a nd \n26.2% were connecting two anti -vaccine groups and two pro -vaccine groups, \nrespectively.  \nWe analyzed  the structure of the network\u2019s largest connected component  \n(LCC) . The LCC , shown in Fig. 4D,  included  1,159 nodes consisting of 410 pro -\nvaccine, 744 anti -vaccine, and 5 mixed/neutral groups. To examine the level of \nseparation between pro - and anti -vaccine groups, we calculated the proportion of \noutgroup edges connected to  each node  (Fig. S14). Outgroup edges refer to edges \nconnecting vaccine groups with different views, such as an edge connecting a pro -\nvaccine group and a n anti-vacci ne group. Ingroup edges , on the other hand,  refer \nto edges connecting groups with the same view, such as an edge connecting two \npro-vaccine groups.  In Fig. S14, red and blue represent anti - and pro -vaccine \ngroups. The height of a bar indicate s relative frequency , which  ranges from 0 to 1. \nSolid lines show the result of the Kernel density estimation (left y -axis). Dashed \nlines indicate the average proportions.  As shown in Fig. S14, the proportion of \n51 \n outgroup edges w as marginal . Specifically,  on average only 11.0% ( SD = 22.7%, \nmedian = 0.0% , N = 410) of all edges of a pro -vaccine node and 5.3% ( SD = \n15.6%, median = 0.0% , N = 744) of all edges connected to  an anti -vaccine node \nwere outgroup edges . The proportion of outgroup edges  that an anti -vaccine group \nhad was significantly lower  than that of a pro -vaccine group  (Mann -Whitney U1 = \n128292 .5, P < 0.0001 , N1 = 410, N2 = 744 ; Kolmogorov -Smirnov D = 0.192, P < \n0.0001). The results imply  that pro- and anti -vaccine groups were segregated from \neach other, and the level of insularity  was higher for anti -vaccine groups.  \n \n \nFig. S 13. The network of vaccine groups within Facebook.   \n\n52 \n  \n \nFig. S14. The proportion of outgroup edges of a node in the largest connected component .  \n  \n\n53 \n S9 Data and Codes  for Replication  \nData and codes to reproduce the results in the manuscript are available online  (41)  \n54 \n S10 References  \n1.  CrowdTangle Team, What data is CrowdTangle tracking? (2021), (available \nat http://help.crowdtangle.com/en/articles/1140930 -what -data-is-crowdtangle -\ntracking).  \n2.  CrowdTangle T eam, Citing CrowdTangle Data (2021), (available at \nhttp://help.crowdtangle.com/en/articles/3192685 -citing -crowdtangle -data).  \n3.  J. A. Shoup, K. J. Narwaney , N. M. Wagner, C. R. Kraus, K. S. Gleason, K. \nAlbright, J. M. Glanz, Social media vaccine websites: A comparative analysis \nof public and moderated websites. Health Education & Behavior . 46, 454 \u2013\n462 (2019).  \n4.  B. L. Hoffman, E. M. Felter, K. -H. Chu, A. Sh ensa, C. Hermann, T. Wolynn, \nD. Williams, B. A. Primack, It\u2019s not all about autism: The emerging \nlandscape of anti -vaccination sentiment on Facebook. Vaccine . 37, 2216 \u2013\n2223 (2019).  \n5.  K. Faasse, C. J. Chatman, L. R. Martin, A comparison of language use in  pro-\nand anti -vaccination comments in response to a high profile Facebook post. \nVaccine . 34, 5808 \u20135814 (2016).  \n6.  A. L. Schmidt, F. Zollo, A. Scala, C. Betsch, W. Quattrociocchi, Polarization \nof the vaccination debate on Facebook. Vaccine . 36, 3606 \u20133612 ( 2018).  \n7.  N. Smith, T. Graham, Mapping the anti -vaccination movement on Facebook. \nInformation, Communication & Society . 22, 1310 \u20131327 (2019).  \n8.  M. S. Deiner, C. Fathy, J. Kim, K. Niemeyer, D. Ramirez, S. F. Ackley, F. \nLiu, T. M. Lietman, T. C. Porco, Fa cebook and Twitter vaccine sentiment in \nresponse to measles outbreaks. Health Informatics J . 25, 1116 \u20131132 (2019).  \n9.  A. S. Bradshaw, S. S. Shelton, E. Wollney, D. Treise, K. Auguste, Pro -\nvaxxers get out: Anti -vaccination advocates influence undecided fir st-time, \npregnant, and new mothers on Facebook. Health communication . 36, 693 \u2013702 \n(2021).  \n10.  A. M. Jamison, D. A. Broniatowski, M. Dredze, Z. Wood -Doughty, D. Khan, \nS. C. Quinn, Vaccine -related advertising in the Facebook Ad Archive. \nVaccine . 38, 512 \u2013520 (2020).  \n55 \n 11.  L. E. Elkin, S. R. Pullon, M. H. Stubbe, \u2018Should I vaccinate my \nchild?\u2019comparing the displayed stances of vaccine information retrieved from \nGoogle, Facebook and YouTube. Vaccine . 38, 2771 \u20132778 (2020).  \n12.  M. L. Luisi, From bad to worse: The  representation of the HPV vaccine \nFacebook. Vaccine . 38, 4564 \u20134573 (2020).  \n13.  C. K. Gandhi, J. Patel, X. Zhan, Trend of influenza vaccine Facebook posts in \nlast 4 years: A content analysis. American journal of infection control . 48, \n361\u2013367 (2020).  \n14.  D. A. Broniatowski, A. M. Jamison, N. F. Johnson, N. Velasquez, R. Leahy, \nN. J. Restrepo, M. Dredze, S. C. Quinn, Facebook Pages, the \u201cDisneyland\u201d \nMeasles Outbreak, and Promotion of Vaccine Refusal as a Civil Right, 2009 \u2013\n2019. American Journal of Public Health . 110, S312 \u2013S318 (2020).  \n15.  N. F. Johnson, N. Vel\u00e1squez, N. J. Restrepo, R . Leahy, N. Gabriel, S. El Oud, \nM. Zheng, P. Manrique, S. Wuchty, Y. Lupu, The online competition between \npro- and anti -vaccination views. Nature . 582, 230 \u2013233 (2020).  \n16.  M. Cinelli, G. De Francisci Morales, A. Galeazzi, W. Quattrociocchi, M. \nStarnini, T he echo chamber effect on social media. Proc Natl Acad Sci USA . \n118, e2023301118 (2021).  \n17.  J. Zipprich, K. Winter, J. Hacker, D. Xia, J. Watt, K. Harriman, Measles \nOutbreak \u2014 California, December 2014 \u2013February 2015 (2015), (available at \nhttps://www.cdc. gov/mmwr/preview/mmwrhtml/mm6406a5.htm).  \n18.  M. Patel, A. D. Lee, N. S. Clemmons, S. B. Redd, S. Poser, D. Blog, J. R. \nZucker, J. Leung, R. Link -Gelles, H. Pham, R. J. Arciuolo, E. Rausch -Phung, \nB. Bankamp, P. A. Rota, C. M. Weinbaum, P. A. Gasta\u00f1aduy, Na tional \nUpdate on Measles Cases and Outbreaks \u2014 United States, January 1 \u2013October \n1, 2019. MMWR Morb. Mortal. Wkly. Rep.  68, 893 \u2013896 (2019).  \n19.  Whitehouse, Proclamation on Declaring a National Emergency Concerning \nthe Novel Coronavirus Disease (COVID -19) O utbreak \u2013 The White House \n(2020), (available at https://trumpwhitehouse.archives.gov/presidential -\nactions/proclamation -declaring -national -emergency -concerning -novel -\ncoronavirus -disease -covid -19-outbreak/).  \n56 \n 20.  K.-C. Yang, F. Pierri, P. -M. Hui, D. Axelrod,  C. Torres -Lugo, J. Bryden, F. \nMenczer, The COVID -19 Infodemic: Twitter versus Facebook. Big Data & \nSociety . 8, 20539517211013860 (2021).  \n21.  gsa.gov, A complete list of .gov domains (2014), (available at \nhttps://18f.gsa.gov/2014/12/18/a -complete -list-of-gov-domains/).  \n22.  Search.gov, Government -Managed Domains Outside the .Gov and .Mil Top \nLevel Domains (2019), (available at https://search.gov/developer/govt -\nurls.html).  \n23. . gov. Wikipedia  (2021), (available at \nhttps://en.wikipedia.org/w/index.php?title =.gov&oldid=1025358122).  \n24.  E. Bakshy, S. Messing, L. A. Adamic, Exposure to ideologically diverse news \nand opinion on Facebook. Science . 348, 1130 \u20131132 (2015).  \n25.  T. Yang, S. Maj\u00f3 -V\u00e1zquez, R. K. Nielsen, S. Gonz\u00e1lez -Bail\u00f3n, Exposure to \nnews grows less  fragmented with an increase in mobile access. Proc Natl \nAcad Sci USA . 117, 28678 \u201328683 (2020).  \n26.  Pew Research Center, Methodology: State of the News Media. Pew Research \nCenter\u2019s Journalism Project  (2019), (available at \nhttps://www.journalism.org/2019/0 7/23/state -of-the-news -media -\nmethodology/).  \n27.  N. Grinberg, K. Joseph, L. Friedland, B. Swire -Thompson, D. Lazer, Fake \nnews on Twitter during the 2016 U.S. presidential election. Science . 363, \n374\u2013378 (2019).  \n28.  J. Holcomb, J. Gottfried, A. Mitchell, N ews Use Across Social Media \nPlatforms. Pew Research Center\u2019s Journalism Project  (2013), (available at \nhttps://www.journalism.org/2013/11/14/news -use-across -social -media -\nplatforms/).  \n29.  E. Shearer, J. Gottfried, News Use Across Social Media Platforms 2017 . Pew \nResearch Center\u2019s Journalism Project  (2017), (available at \nhttps://www.journalism.org/2017/09/07/news -use-across -social -media -\nplatforms -2017/).  \n30.  E. Shearer, A. Mitchell, News Use Across Social Media Platforms in 2020. \nPew Research Center\u2019s Journa lism Project  (2021), (available at \n57 \n https://www.journalism.org/2021/01/12/news -use-across -social -media -\nplatforms -in-2020/).  \n31.  A. Perrin, M. Anderson, Share of U.S. adults using social media, including \nFacebook, is mostly unchanged since 2018. Pew Researc h Center , (available \nat https://www.pewresearch.org/fact -tank/2019/04/10/share -of-u-s-adults -\nusing -social -media -including -facebook -is-mostly -unchanged -since -2018/).  \n32.  M. Duggan, Mobile Messaging and Social Media 2015. Pew Research \nCenter: Internet, Science & Tech  (2015), (available at \nhttps://www.pewresearch.org/internet/2015/08/19/mobile -messaging -and-\nsocial -media -2015/).  \n33.  M. Duggan, J. Brenner, The Demographics of  Social Media Users \u2014 2012. \nPew Research Center: Internet, Science & Tech  (2013), (available at \nhttps://www.pewresearch.org/internet/2013/02/14/the -demographics -of-\nsocial -media -users -2012/).  \n34.  M. Duggan, N. B. Ellison, C. Lampe, A. Lenhart, M. Madden, S ocial Media \nSite Usage 2014. Pew Research Center: Internet, Science & Tech  (2015), \n(available at https://www.pewresearch.org/internet/2015/01/09/social -media -\nupdate -2014/).  \n35.  S. Greenwood, A. Perrin, M. Duggan, Demographics of Social Media Users \nin 2016 . Pew Research Center: Internet, Science & Tech  (2016), (available at \nhttps://www.pewresearch.org/internet/2016/11/11/social -media -update -\n2016/).  \n36.  A. Smith, M. Anderson, Social Media Use 2018: Demographics and \nStatistics. Pew Research Center: Internet,  Science & Tech  (2018), (available \nat https://www.pewresearch.org/internet/2018/03/01/social -media -use-in-\n2018/).  \n37.  Media Bias/Fact Check, About. Media Bias/Fact Check  (2021), (available at \nhttps://mediabiasfactcheck.com/about/).  \n38.  A. Guess, B. Nyhan , J. Reifler, Selective Exposure to Misinformation: \nEvidence from the consumption of fake news during the 2016 U.S. \npresidential campaign (2018) (available at www.dartmouth.edu/~nyhan/fake -\nnews -2016.pdf).  \n58 \n 39.  H. Allcott, M. Gentzkow, Social Media and Fake  News in the 2016 Election. \nJournal of Economic Perspectives . 31, 211 \u2013236 (2017).  \n40.  W. Bleakly, FAQ: Followers (2021), (available at \nhttp://help.crowdtangle.com/en/articles/4797890 -faq-followers).  \n41.  Anonymous authors, Online Material for \u201cThe Ecosyst em of Online Groups \nwith Pro - and Anti -vaccine Views.\u201d OSF (2021), (available at \nhttps://osf.io/csn39/?view_only=b28ef8d3e06947839b68cce13b509c92).  \n42.  R. Bond, S. Messing, Quantifying Social Media\u2019s Political Space: Estimating \nIdeology from Publicly Reve aled Preferences on Facebook. American \nPolitical Science Review . 109, 62\u201378 (2015).  \n43.  P. Barber\u00e1, J. T. Jost, J. Nagler, J. A. Tucker, R. Bonneau, Tweeting from left \nto right: Is online political communication more than an echo chamber? \nPsychological sc ience . 26, 1531 \u20131542 (2015).  \n44.  F. Votta, favstats/AllSideR  (2021; https://github.com/favstats/AllSideR).  \n45.  A. A. Hagberg, D. A. Schult, P. J. Swart, Exploring Network Structure, \nDynamics, and Function using NetworkX. Proceedings of the 7th Python in \nScience Conference  (2008).  \n46.  M. Bastian, S. Heymann, M. Jacomy, in Third International AAAI Conference \non Weblogs and Social Media  (2009; \nhttps://www.aaai.org/ocs/index.php/ICWSM/09/paper/view/154).  \n47.  M. Jacomy, T. Venturini, S. Heymann, M. Bastian, ForceAtlas2, a \nContinuous Graph Layout Algorithm for Handy Network Visualization \nDesigned for the Gephi Software. PLOS ONE . 9, e98679  (2014).  \n \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Information Ecosystem of Online Groups with Anti-and Pro-vaccine Views on Facebook", "author": ["S Kim", "K Kim"], "pub_year": "2021", "venue": "arXiv preprint arXiv:2108.06641", "abstract": "Opposition and hesitancy to vaccination have been one of the major threats to global health.  Social media sites have been suspected as a breeding ground of misleading narratives"}, "filled": false, "gsrank": 753, "pub_url": "https://arxiv.org/abs/2108.06641", "author_id": ["5rEBYxUAAAAJ", "gUrKLusAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:rYuRRtNQTwgJ:scholar.google.com/&output=cite&scirp=752&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D750%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=rYuRRtNQTwgJ&ei=jrWsaMr-H8DZieoPqdqh8QU&json=", "num_citations": 3, "citedby_url": "/scholar?cites=598786143815830445&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:rYuRRtNQTwgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2108.06641"}}, {"title": "Red bots do it better: Comparative analysis of social bot partisan behavior", "year": "2019", "pdf_data": "Red Bots Do It Better:\nComparative Analysis of Social Bot Partisan Behavior\nLuca Luceri *\nUniversity of Applied Sciences and Arts of Southern\nSwitzerland, and University of Bern\nManno, Switzerland\nluca.luceri@supsi.chAshok Deb\nUSC Information Sciences Institute\nMarina del Rey, CA\nashok@isi.edu\nAdam Badawy\nUSC Information Sciences Institute\nMarina del Rey, CA\nbadawy@isi.eduEmilio Ferrara\nUSC Information Sciences Institute\nMarina del Rey, CA\nemiliofe@usc.edu\nABSTRACT\nRecent research brought awareness of the issue of bots on social\nmedia and the significant risks of mass manipulation of public opin-\nion in the context of political discussion. In this work, we leverage\nTwitter to study the discourse during the 2018 US midterm elections\nand analyze social bot activity and interactions with humans. We\ncollected 2.6 million tweets for 42 days around the election day from\nnearly 1 million users. We use the collected tweets to answer three\nresearch questions: (i)Do social bots lean and behave according to\na political ideology? (ii)Can we observe different strategies among\nliberal and conservative bots? (iii)How effective are bot strategies?\nWe show that social bots can be accurately classified according\nto their political leaning and behave accordingly. Conservative bots\nshare most of the topics of discussion with their human counterparts,\nwhile liberal bots show less overlap and a more inflammatory attitude.\nWe studied bot interactions with humans and observed different\nstrategies. Finally, we measured bots embeddedness in the social\nnetwork and the effectiveness of their activities. Results show that\nconservative bots are more deeply embedded in the social network\nand more effective than liberal bots at exerting influence on humans.\nKEYWORDS\nsocial media, political elections, social bots, political manipulation\nACM Reference Format:\nLuca Luceri, Ashok Deb, Adam Badawy, and Emilio Ferrara. 2019. Red\nBots Do It Better: Comparative Analysis of Social Bot Partisan Behavior. In\nInternational Workshop on Misinformation, Computational Fact-Checking\nand Credible Web, May 14, 2019, San Francisco, CA. ACM, New York, NY ,\nUSA, 6 pages. https://doi.org/10.1145/1122445.1122456\n*Also with USC Information Sciences Institute.\nL. Luceri & A. Deb contributed equally to this work.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA\n\u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9999-9/18/06. . . $15.00\nhttps://doi.org/10.1145/1122445.1122456INTRODUCTION\nDuring the last decade, social media have become the conventional\ncommunication channel to socialize, share opinions, and access the\nnews. Accuracy, truthfulness, and authenticity of the shared content\nare necessary ingredients to maintain a healthy online discussion.\nHowever, in recent times, social media have been dealing with a\nconsiderable growth of false content and fake accounts. The re-\nsulting wave of misinformation (and disinformation) highlights the\npitfalls of social media networks and their potential harms to several\nconstituents of our society, ranging from politics to public health.\nIn fact, social media networks have been used for malicious pur-\nposes to a great extent [ 11]. Various studies raised awareness about\nthe risk of mass manipulation of public opinion, especially in the con-\ntext of political discussion. Disinformation campaigns [ 2,5,12,14\u2013\n16,21,23,25,29] and social bots [ 3,4,20,22,24,28,30,31] have\nbeen indicated as factors contributing to social media manipulation.\nThe 2016 US Presidential election represents a prime example\nof the significant perils of mass manipulation of political discourse.\nBadawy et al . [1] studied the Russian interference in the election\nand the activity of Russian trolls on Twitter. Im et al . [17] suggested\nthat troll accounts are still active to these days. The presence of\nsocial bots does not show any sign of decline [ 10,31] despite the\nattempts from social network providers to suspend suspected, ma-\nlicious accounts. Various research efforts have been focusing on\nthe analysis, detection, and countermeasures development against\nsocial bots. Ferrara et al . [13] highlighted the consequences asso-\nciated with bot activity in social media. The online conversation\nrelated to the 2016 US presidential election was further examined\n[3] to quantify the extent of social bots activity. More recently, Stella\net al. [26] discussed bots\u2019 strategy of targeting influential humans to\nmanipulate online conversation during the Catalan referendum for\nindependence, whereas Shao et al . [24] analyzed the role of social\nbots in spreading articles from low credibility sources. Deb et al .\n[10] focused on the 2018 US Midterms elections with the objective\nto find instances of voter suppression.\nIn this work, we investigate social bots behavior by analyzing\ntheir activity, strategy, and interactions with humans. We aim to\nanswer the following research questions (RQs) regarding social bots\nbehavior during the 2018 US Midterms election.arXiv:1902.02765v2  [cs.SI]  8 Feb 2019\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA L. Luceri, A. Deb, A. Badawy, and E. Ferrara\nRQ1 :Do social bots lean and behave according to a political ide-\nology? We investigate whether social bots can be classified\nbased on their political inclination into liberal or conservative\nleaning. Further, we explore to what extent they act similarly\nto the corresponding human counterparts.\nRQ2 :Can we observe different strategies among liberal and con-\nservative bots? We examine the differences between social\nbot strategies to mimic humans and infiltrate political discus-\nsion. For this purpose, we measure bot activity in terms of\nvolume and frequency of posts, interactions with humans, and\nembeddedness in the social network.\nRQ3 :Are bot strategies effective? We introduce four metrics to\nestimate the effectiveness of bot strategies and to evaluate the\ndegree of human interplay with social bots.\nWe leverage Twitter to capture the political discourse during the\n2018 US midterm elections. We collected 2.6 million tweets for\n42 days around election day from nearly 1 million users. We then\nexplore collected data and attain the following findings:\n\u2022We show that social bots are embedded in each political side\nand behave accordingly. Conservative bots abide by the topic\ndiscussed by the human counterpart more than liberal bots,\nwhich in turn exhibit a more provocative attitude.\n\u2022We examined bots\u2019 interactions with humans and observed\ndifferent strategies. Conservative bots stand in a more central\nsocial network position, and divide their interactions between\nhumans and other conservative bots, whereas liberal bots\nfocused mainly on the interplay with the human counterparts.\n\u2022We measured the effectiveness of these strategies and recog-\nnized the strategy of conservative bots as the most effective\nin terms of influence exerted on human users.\nDATA\nIn this study, we use Twitter to investigate the partisan behavior\nof malicious accounts during the 2018 US midterm elections. For\nthis purpose, we carried out a data collection from the month prior\n(October 6, 2018) to two weeks after (November 19, 2018) the day\nof the election. We kept the collection running after the election\nday as several races remained unresolved. We employed the Python\nmodule Twyton to collect tweets through the Twitter Streaming\nAPI using the following keywords as a filter: 2018midtermelections ,\n2018midterms ,elections ,midterm , and midtermelections . As a result,\nwe gathered 2.7 million tweets, whose IDs are publicly available\nfor download.1From this set, we first removed any duplicate tweet,\nwhich may have been captured by accidental redundant queries to\nthe Twitter API. Then, we excluded all the tweets not written in\nEnglish language. Despite the majority of the tweets were in English,\nand to a lesser degree in Spanish (3,177 tweets), we identified 59\nlanguages in the collected data. Thus, we inspected tweets from other\ncountries and removed them as they were out of the context of this\nstudy. In particular, we filtered out tweets related to the Cameroon\nelection, the Democratic Republic of the Congo election, the Biafra\ncall for Independence, democracy in Kenya (#democracyKE), to\nthe two major political parties in India (BJP and UPA), and college\nmidterm exams. Overall, we retain nearly 2.6 millions tweets, whose\naggregate statistics are reported in Table 1.\n1https://github.com/A-Deb/midtermsTable 1: Dataset statistics\nStatistic Count\n# of Tweets 452,288\n# of Retweets 1,869,313\n# of Replies 267,973\n# of Users 997,406\nMETHODOLOGY\nBot Detection\nNowadays, bot detection is a fundamental asset for understanding\nsocial media manipulation and, more specifically, to reveal malicious\naccounts. In the last few years, the problem of detecting automated\naccounts gathered both attention and concern [ 13], also bringing a\nwide variety of approaches to the table [ 7,8,19,27]. While increas-\ningly sophisticated techniques keep emerging [ 19], in this study, we\nemploy the widely used Botometer .2\nBotometer is a machine learning-based tool developed by Indiana\nUniversity [ 9,28] to detect social bots in Twitter. It is based on an\nensemble classifier [ 6] that aims to provide an indicator, namely bot\nscore , used to classify an account either as a bot or as a human. To\nfeed the classifier, the Botometer API extracts about 1,200 features\nrelated to the Twitter account under analysis. These features fall in\nsix broad categories and characterize the account\u2019s profile, friends,\nsocial network, temporal activity patterns, language, and sentiment.\nBotometer outputs a bot score: the lower the score, the higher the\nprobability that the user is human. In this study we use version v3of\nBotometer, which brings some innovations, as detailed in [ 31]. Most\nimportantly, the bot scores are now rescaled (and not centered around\n0.5 anymore) through a non-linear re-calibration of the model.\nIn Figure 1, we depict the bot score distribution of the 997,406\ndistinct users in our datasets. The distribution exhibits a right skew:\nmost of the probability mass is in the range [0, 0.2] and some peaks\ncan be noticed around 0.3. Prior studies used the 0.5 threshold to\nseparate humans from bots. However, according to the re-calibration\nintroduced in Botometer v3[31], along with the emergence of in-\ncreasingly more sophisticated bots, we here lower the bot score\nthreshold to 0.3 (i.e., a user is labeled as a bot if the score is above\n0.3). This threshold corresponds to the same level of sensitivity\nsetting of 0.5 in prior versions of Botometer (cf. Fig 5 from [31]).\nAccording to this choice, we classified 21.1% of the accounts as\nbots, which in turn generated 30.6% of the tweets in our data set.\nOverall, Botometer did not return a score for 35,029 users that corre-\nsponds to 3.5% of the accounts. We used the Twitter API to further\ninspect them. Interestingly, 99.4% of these accounts were suspended\nby Twitter, whereas the remaining percentage of users protected their\ntweets turning on the privacy settings of their accounts.\nPolitical Ideology Inference\nIn parallel to the bot detection analysis, we examine the political\nleaning of both bots and humans in our dataset. To classify users\nbased on their political ideology, we rely on the political leaning of\nthe media outlets they share. We make use of a list of partisan media\noutlets released by third-party organizations, such as AllSides3and\n2https://botometer.iuni.iu.edu/\n3https://www.allsides.com/media-bias/media-bias-ratings\nRed Bots Do It Better The Web Conference \u201919, May 14, 2019, San Francisco, CA\nFigure 1: Bot score distribution\nMedia Bias/Fact Check.4We combine liberal and liberal-center me-\ndia outlets into one list (composed of 641 outlets) and conservative\nand conservative-center into another (composed of 398 outlets). To\ncross reference these media URLs with the URLs in the Twitter\ndataset, we need to get the expanded URLs for most of the links in\nthe dataset, as most of them are shortened. However, this process is\nquite time-consuming, thus, we decided to rank the top 5,000 URLs\nby popularity and retrieve the long version only for those. These top\n5,000 URLs accounts for more than 254K, or more than 1/3 of all\nthe URLs in the dataset. After cross-referencing the 5,000 extended\nURLs with the media URLs, we observe that 32,115 tweets in the\ndataset contain a URL that points to one of the liberal media outlets\nand 25,273 tweets with a URL pointing to one of the conservative\nmedia outlets.\nTo label Twitter accounts as liberal or conservative, we use a\npolarity rule based on the number of tweets they produce with links\nto liberal or conservative sources. Thereby, if an account has more\ntweets with URLs pointing to liberal sources, it is labeled as liberal\nand vice versa. Although the overwhelming majority of accounts\ninclude URLs that are either liberal or conservative, we remove any\naccount that has equal number of tweets from each side. Our final\nset of labeled accounts includes 38,920 users.\nFinally, we use label propagation to classify the remaining ac-\ncounts in a similar way to previous work ( cf.[1]). For this purpose,\nwe construct a social network based on the retweets exchanged be-\ntween users. The nodes of the retweet network are the users, which\nare connected by a direct link if one user retweeted a post of an-\nother user. To validate results of the label propagation algorithm,\nwe apply a stratified cross (5-fold) validation to a set composed of\n38,920 seed accounts. We train the algorithm using 80% of the seeds\nand we evaluate the performance on the remaining 20%. Finally,\nwe compute precision and recall by reiterating the validation of the\n5-folds. Both precision and recall scores show value around 0.89 and\nvalidate the proposed approach. Moreover, since we combine liberal\nand liberal-center into one list (same for conservatives), we can see\nthat the algorithm is not only labeling the far liberal or conservative\ncorrectly, which is a relatively easier task, but it is performing well\non the liberal/conservative center as well.\n4https://mediabiasfactcheck.com/Table 2: Users and tweets statistics\nLiberal Conservative\nHumans 386,391 (38.7%) 122,761 (12.3%)\nBots 82,118 (8.2%) 49,488 (4.9%)\n(a) Number (percentage) of users per group\nLiberal Conservative\nHumans 957,726 (37.0%) 476,231 (18.4%)\nBots 288,659 (11.1%) 364,727 (14.1%)\n(b) Number (percentage) of tweets per group\nBot Activity Effectiveness\nWe next introduce four metrics to estimate bot effectiveness and, at\nthe same time, measure to what extent humans rely upon, and interact\nwith the content generated by social bots. Thereby, we propose the\nfollowing metrics:\n\u2022Retweet Pervasiveness (RTP) measures the intrusiveness of\nbot-generated content in human-generated retweets:\nRTP=no. of human retweets from bot tweets\nno. of human retweets(1)\n\u2022Reply Rate (RR) measures the percentage of replies given by\nhumans to social bots:\nRR=no. of human replies to bot tweets\nno. of human replies(2)\n\u2022Human to Bot Rate (H2BR) quantifies human interaction with\nbots over all the human activities in the social network:\nH2BR=no. of humans interaction with bots\nno. of humans activity, (3)\nwhere the numerator counts for human replies/retweets to/of\nbots generated content, while the denominator is the sum of\nthe number of human tweets, retweets, and replies.\n\u2022Tweet Success Rate (TSR) is the percentage of tweets gener-\nated by bots that obtained at least one retweet by a human:\nTSR=no. of tweet retweeted at least once by a human\nno. of bots tweets(4)\nRESULTS\nNext, we address the research questions discussed in the Introduction.\nWe examine social bot partisanship and, accordingly, we analyze\nbots\u2019 strategies and measure the effectiveness of their actions.\nRQ1: Bot Political Leaning\nThe combination of the outcome from the bot detection algorithm\nand the political ideology inference allowed us to identify four\ngroups of users, namely Liberal Humans, Conservative Humans,\nLiberal Bots, and Conservative Bots. In Table 2a, we show the per-\ncentage of users per group. Note that percentages do not sum up to\n100 as either the political ideology inference was not able to classify\nevery user, or Botometer did not return a score, as we previously\nmentioned. In particular, we were able to assign a political leaning\nto 63% of bots and 67% of humans. We find that the liberal user\npopulation is almost three times larger than the conservative coun-\nterpart. This discrepancy is also present, but less evident, for the bot\naccounts, which exhibit an unbalance in favor of liberal bots. Further,\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA L. Luceri, A. Deb, A. Badawy, and E. Ferrara\n(b) 25-core decomposition(a) 10-core decomposition\nFigure 2: Political discussion over (a)the 10-core, and (b)the 25-core decomposition of the retweet network. Each node represents a\nuser, while links represent retweets. Links with weight (i.e., frequency of occurrence) less than 2 are hidden to minimize visual clutter.\nBlue nodes represent liberal accounts, while red nodes indicate conservative users. Darker tones (blue and red) depict bots, while\nlighter tones (cyan and pink) relate to humans, and the few green nodes represent unclassified accounts. The link takes the same color\nof the source node (author of the retweet), whereas node size is proportional to the in-degree of the user.\nTable 3: Top 20 hashtags generated by liberal and conservative\nbots. Hashtags in bold are not present in the top 50 hashtags\nused by the corresponding human group.\nLiberal Bots Conservative Bots\n#MAGA #BrowardCounty\n#NovemberisComing #MAGA\n#TheResistance #StopTheSteal\n#GOTV #WalkAway\n#Florida #WednesdayWisdom\n#ImpeachTrump #PalmBeachCounty\n#Russia #Florida\n#V oteThemOut #QAnon\n#unhackthevote #KAG\n#FlipTheHouse #IranRegime\n#RegisterToV ote #Tehran\n#Resist #WWG1WGA\n#ImpeachKavanaugh #Louisiana\n#GOP #BayCounty\n#MeToo #AmericaFirst\n#AMJoy #DemocratsAreDangerous\n#txlege #StopTheCaravan\n#FlipTheSenate #Blexit\n#CultureOfCorruption #VoteDemsOut\n#TrumpTrain #V oterFraud\nwe investigate the suspended accounts to inspect the consistency of\nthis result. The inference algorithm attributed a political ideology to\n63% of these accounts, which in turn show once again the liberal\nadvantage over the conservative faction (45% vs. 18%).\nFigure 2 shows two k-core decomposition graphs of the retweet\nnetwork. In a k-core, each node is connected with at least kothernodes. Figures 2a and 2b capture the 10-core and 25-core decom-\nposition, respectively. Here, nodes represent Twitter users and link\nrepresent retweets among them. We indicate as source the user that\nretweeted the tweet of a target user. Colors represent the political\nideology, with darker colors (red and blue) being bots and lighter\ncolors (cyan and pink) being human users; size represents the in-\ndegree. The graph is visualized using a force-directed layout [ 18],\nwhere nodes repulse each other, while edges attract their nodes. In\nour setting, this means that users are spatially distributed accord-\ning to the amount of retweets between each other. The result is a\nnetwork naturally split into two communities, where each side is\nalmost entirely populated by users with the same political ideology.\nThis polarization is also reflected by bots, which are embedded,\nwith humans, in each political side. Two facts are worth noting: (i)\naskincreases, the left k-core appears to disrupt, while the right\nk-core remains well connected; and, (ii)askincreases, bots appear\nto outnumber humans, suggesting that bots may populate areas of\nthe retweet network that are more central and better connected.\nNext, we examine the topics discussed by social bots and com-\npare them with the human counterparts. Table 3 shows the top 20\nhashtags utilized by liberal and conservative bots. We highlight (in\nbold) the hashtags that are not present in the top 50 hashtags used\nby the corresponding human group to point out the similarities and\ndifferences among the groups. In this table, we do not take into ac-\ncount general hashtags (such as #elections, #midterms, #democrats,\n#liberals, #V oteRed(or Blue)ToSaveAmerica, and #Trump) as (i)\nthe overlap between bot and human hashtags is noticeable when\nthese terms are considered, and (ii)we aim to narrow the analy-\nsis to specific topics and inflammatory content, inspired by [ 26].\nMoreover, we used an enlarged subset of hashtags for the human\ngroups to further strengthen the differences and, at the same time,\nRed Bots Do It Better The Web Conference \u201919, May 14, 2019, San Francisco, CA\nTable 4: Average network centrality measures\nLiberal Conservative\nHumans 2.66\u00b710\u221264.14\u00b710\u22126\nBots 3.70\u00b710\u221267.81\u00b710\u22126\n(a) Out-degree centrality\nLiberal Conservative\nHumans 2.52\u00b710\u221264.24\u00b710\u22126\nBots 2.53\u00b710\u221266.22\u00b710\u22126\n(b) In-degree centrality\nto better understand the objective of social bots. Although bots and\nhumans share the majority of hashtags, two main differences can be\nnoticed. First, conservative bots abide by the corresponding human\ncounterpart more than the liberal bots. Second, liberal bots focus on\nmore inflammatory and provocative content (e.g., #ImpeachTrump,\n#ImpeachKavanaugh, #FlipTheSenate) w.r.t. conservative bots.\nRQ2: Bot Activity and Strategies\nIn this Section, we investigate social bot activity based on their\npolitical leaning. We explore their strategies in interacting with\nhumans and the degree of embeddedness in the social network.\nTable 2b depicts the number (and percentage) of tweets generated\nby each group. Despite the group composed of conservative bots\nis the smallest in terms of number of accounts, it produced more\ntweets than liberal bots and closely approaches the number of tweets\ngenerated by the human counterpart. The resulting tweet per user\nratio shows that conservative bots produce 7.4 tweets per account,\nwhich is more than twice the ratio related to the liberal bots (3.5),\nalmost the double of the human counterpart (3.9), and nearly three\ntimes the ratio of liberal humans (2.5).\nTo investigate the interplay between bots and humans, we con-\nsider the previously described retweet network. Figure 3 shows the\ninteraction among the four groups. We maintain the same color map-\nping described before, with darker color (on the bottom) representing\nbots and lighter color (on top) indicating humans. Node size is pro-\nportional to the percentage of accounts in each group, while edge\nsize is proportional to the percentage of interactions between each\ngroup. In Figure 3a, this percentage is computed considering all the\ninteractions in the retweet network, while in Figure 3b we consider\neach group separately, therefore, the edge size gives a measure of the\ngroup propensity to interact with the other groups. Consistently with\nFigure 2, we observe that there is a limited amount of interaction be-\ntween the two political sides. The majority of interactions are either\nintra-group or between groups of the same political leaning. From\nFigure 3b, we can observe that the two bot factions adopted different\nstrategies. Conservative bots balanced their interactions by retweet-\ning group members 43% of the time, and the human counterpart 52%\nof the time. On the other hand, liberal bots mainly retweeted liberal\nhumans (71% of the time) and limited the intra-group interactions\nto the 22% of their retweet activity. Interestingly, conservative hu-\nmans interacted with the conservative bots (28% of the time) much\nmore than the liberal counterpart (16%) with the liberal bots. To\nbetter understand these results and to measure the effectiveness of\nboth the strategies, in the next Section we evaluate the four metrics\nintroduced earlier in this paper.\nBotsHumans\n(a)Overall interactions (b)Group-based interactions\nFigure 3: Interactions according to political ideology\nFigure 4: k-core decomposition, liberal vs. conservative users\nFinally, we examine the degree of embeddedness of both humans\nand bots within the retweet network. For this purpose, we first com-\npute different network centrality measures, and then we adopt the\nk-core decomposition technique to identify the most central nodes\nin the graph. In Table 4, we show the average out- and in-degree\ncentrality for each group of users. Out-degree centrality measures the\nquantity of outgoing links, while in-degree centrality considers the\nnumber of of incoming links. Both of these measures are normalized\nby the maximum possible degree of the graph. Overall, conservative\ngroups have higher centrality measures than the liberal ones. We can\nnotice that conservative bots achieve the highest values both for the\nout- and in-degree centrality. To further investigate bots embedded-\nness in the social network, we use the k-core decomposition. The\nobjective of this technique is to determine the set of nodes deeply\nembedded in a graph. The k-core is a subgraph of the original graph\nin which every node has a degree equal to or greater than a given\nvalue k. We extracted the k-cores from the retweet network by vary-\ningkin the range between 0 and 30. Figure 4 depicts the percentage\nof liberal and conservative users as a function of k. We can notice\nthat, as kgrows, the fraction of conservative bots increases, while\nthe percentage of liberal bots remains almost stationary. On the hu-\nman side, the liberal fraction drops with k, whereas the conservative\npercentage remains approximately steady. Overall, conservative bots\nsit in a more central position in the social network and are more\ndeeply connected if compared to the liberal counterpart.\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA L. Luceri, A. Deb, A. Badawy, and E. Ferrara\nTable 5: Bot effectiveness\nMetric Liberal Bots Conservative Bots\nRT P 14.1% 25.6%\nRR 4.5% 15.5%\nH2BR 12.3% 23.2%\nT SR 35.3% 35.0%\nRQ3: Bot Effectiveness\nIn this Section, we aim to estimate the effectiveness of bot strategies\nand measure to what extent humans rely upon, and interact with the\ncontent generated by social bots. We examine the effect of bot activ-\nities by means of the four metrics described in Section Bot Activity\nEffectiveness . We evaluate each political side separately, thus, we\ncompare the interaction between bots and humans with the same\nleaning. In Table 5, we depict the results for each group of bots.\nDiverse aspects are worthy of consideration. We can observe that\nconservative bots are significantly more effective than the liberal\ncounterpart. Although the TSRs of the redandblue bots are com-\nparable, the gap between the two groups, with respect to the other\nmetrics, is significant. To carefully interpret this result, it should also\nbe noticed that(i)theTSR is inversely proportional to the number\nof tweets generated by bots, and (ii)conservative bots tweeted more\nthan the liberal counterpart, as depicted in Table 2b. Overall, conser-\nvative bots received a larger degree of interaction with (and likely\ntrust from) human users. In fact, conservative humans interacted\nwith the bot counterpart almost twice with retweets ( RTP), and more\nthan three times with replies ( RR) if compared to the liberal group.\nFinally, the H2BRhighlights a remarkable amount of human activi-\nties that involve social bots: almost one in four actions performed by\nconservative humans goes towards red bots.\nCONCLUSIONS & FUTURE WORK\nIn this work, we conducted an investigation to analyze social bots\nactivity during the 2018 US Midterm election. We showed that social\nbots are embedded in each political wing and behave accordingly.\nWe observed different strategies between conservative and liberal\nbots. Specifically, conservative bots stand in a more central position\nin the social network and abide by the topic discussed by the hu-\nman counterpart more than the liberal bots, which in turn exhibit\nan inflammatory attitude. Further, conservative bots balanced their\ninteraction with humans and bots of the red wing, whereas liberal\nbots focused mainly on the interplay with the human counterpart.\nFinally, we inspected the effectiveness of these strategies and\nrecognized the strategy of the conservative bots as the most effective.\nHowever, these results open the door to further interpretation and\ndiscussion. Are conservative bots more effective because of their\nstrategy or because of the human ineptitude to distinguish their\nnature? This, and related analysis, will be expanded in future work.\nAcknowledgements . The authors gratefully acknowledge support by the Air Force\nOffice of Scientific Research (award #FA9550-17-1-0327). L. Luceri is funded by the\nSwiss National Science Foundation (SNSF) via the CHIST-ERA project UPRISE-IoT .\nREFERENCES\n[1]Adam Badawy, Emilio Ferrara, and Kristina Lerman. 2018. Analyzing the Digital\nTraces of Political Manipulation: The 2016 Russian Interference Twitter Campaign.\nInInt. Conference on Advances in Social Networks Analysis and Mining . 258\u2013265.[2]Adam Badawy, Kristina Lerman, and Emilio Ferrara. 2018. Who Falls for Online\nPolitical Manipulation? arXiv preprint arXiv:1808.03281 (2018).\n[3]Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US\nPresidential election online discussion. First Monday 21, 11 (2016).\n[4]Olga Boichak, Sam Jackson, Jeff Hemsley, and Sikana Tanupabrungsun. 2018.\nAutomated Diffusion? Bots and Their Influence During the 2016 US Presidential\nElection. In International Conference on Information . Springer, 17\u201326.\n[5]Alexandre Bovet and Hern\u00e1n A Makse. 2019. Influence of fake news in Twitter\nduring the 2016 US presidential election. Nature communications 10, 1 (2019), 7.\n[6] Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001), 5\u201332.\n[7]Nikan Chavoshi, Hossein Hamooni, and Abdullah Mueen. 2016. DeBot: Twitter\nBot Detection via Warped Correlation.. In ICDM . 817\u2013822.\n[8]Zhouhan Chen and Devika Subramanian. 2018. An Unsupervised Approach\nto Detect Spam Campaigns that Use Botnets on Twitter. arXiv preprint\narXiv:1804.05232 (2018).\n[9]Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and\nFilippo Menczer. 2016. Botornot: A system to evaluate social bots. In Proceedings\nof the 25th International Conference Companion on World Wide Web .\n[10] Ashok Deb, Luca Luceri, Adam Badawy, and Emilio Ferrara. 2019. Perils and\nChallenges of Social Media and Election Manipulation Analysis: The 2018 US\nMidterms. arXiv preprint arXiv:1902.00043 (2019).\n[11] Emilio Ferrara. 2015. Manipulation and abuse on social media. ACM SIGWEB\nNewsletter Spring (2015), 4.\n[12] Emilio Ferrara. 2017. Disinformation and Social Bot Operations in the Run Up to\nthe 2017 French Presidential Election. First Monday 22, 8 (2017).\n[13] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro\nFlammini. 2016. The rise of social bots. Commun. ACM 59, 7 (2016), 96\u2013104.\n[14] Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and\nDavid Lazer. 2019. Fake news on Twitter during the 2016 U.S. presidential\nelection. Science 363, 6425 (2019), 374\u2013378.\n[15] Andrew Guess, Jonathan Nagler, and Joshua Tucker. 2019. Less than you think:\nPrevalence and predictors of fake news dissemination on Facebook. Science\nAdvances 5, 1 (2019), eaau4586.\n[16] Philip N Howard, Gillian Bolsover, Bence Kollanyi, Samantha Bradshaw, and\nLisa-Maria Neudert. 2017. Junk news and bots during the US election: What were\nMichigan voters sharing over Twitter. CompProp, OII, Data Memo (2017).\n[17] Jane Im, Eshwar Chandrasekharan, Jackson Sargent, Paige Lighthammer, Taylor\nDenby, Ankit Bhargava, Libby Hemphill, David Jurgens, and Eric Gilbert. 2019.\nStill out there: Modeling and Identifying Russian Troll Accounts on Twitter. arXiv\npreprint arXiv:1901.11162 (2019).\n[18] Mathieu Jacomy, Tommaso Venturini, Sebastien Heymann, and Mathieu Bastian.\n2014. ForceAtlas2, a continuous graph layout algorithm for handy network\nvisualization designed for the Gephi software. PloS one 9, 6 (2014), e98679.\n[19] Sneha Kudugunta and Emilio Ferrara. 2018. Deep Neural Networks for Bot\nDetection. Information Sciences 467, October (2018), 312\u2013322.\n[20] Bjarke M\u00f8nsted, Piotr Sapie \u02d9zy\u00b4nski, Emilio Ferrara, and Sune Lehmann. 2017.\nEvidence of Complex Contagion of Information in Social Media: An Experiment\nUsing Twitter Bots. Plos One 12, 9 (2017), e0184148.\n[21] Nathaniel Persily. 2017. The 2016 US Election: Can democracy survive the\ninternet? Journal of democracy 28, 2 (2017), 63\u201376.\n[22] Iacopo Pozzana and Emilio Ferrara. 2018. Measuring bot and human behavioral\ndynamics. arXiv preprint arXiv:1802.04286 (2018).\n[23] Dietram A Scheufele and Nicole M Krause. 2019. Science audiences, misinfor-\nmation, and fake news. PNAS (2019), 201805871.\n[24] Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Kai-Cheng Yang,\nAlessandro Flammini, and Filippo Menczer. 2018. The spread of low-credibility\ncontent by social bots. Nature communications 9, 1 (2018), 4787.\n[25] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news\ndetection on social media: A data mining perspective. ACM SIGKDD Explorations\nNewsletter 19, 1 (2017), 22\u201336.\n[26] Massimo Stella, Emilio Ferrara, and Manlio De Domenico. 2018. Bots increase ex-\nposure to negative and inflammatory content in online social systems. Proceedings\nof the National Academy of Sciences 115, 49 (2018), 12435\u201312440.\n[27] VS Subrahmanian, Amos Azaria, Skylar Durst, Vadim Kagan, Aram Galstyan,\nKristina Lerman, Linhong Zhu, Emilio Ferrara, Alessandro Flammini, Filippo\nMenczer, et al .2016. The DARPA Twitter Bot Challenge. Computer 49, 6 (2016).\n[28] Onur Varol, Emilio Ferrara, Clayton A Davis, Filippo Menczer, and Alessan-\ndro Flammini. 2017. Online human-bot interactions: Detection, estimation, and\ncharacterization. In Int. AAAI Conference on Web and Social Media . 280\u2013289.\n[29] Soroush V osoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false\nnews online. Science 359, 6380 (2018), 1146\u20131151.\n[30] Samuel C Woolley and Douglas R Guilbeault. 2017. Computational propaganda\nin the United States of America: Manufacturing consensus online. Computational\nPropaganda Research Project (2017), 22.\n[31] Kai-Cheng Yang, Onur Varol, Clayton A Davis, Emilio Ferrara, Alessandro Flam-\nmini, and Filippo Menczer. 2019. Arming the public with artificial intelligence to\ncounter social bots. Human Behavior and Emerging Technologies (2019), e115.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Red bots do it better: Comparative analysis of social bot partisan behavior", "author": ["L Luceri", "A Deb", "A Badawy", "E Ferrara"], "pub_year": "2019", "venue": "\u2026 of the 2019 world wide web \u2026", "abstract": "Recent research brought awareness of the issue of bots on social media and the significant  risks of mass manipulation of public opinion in the context of political discussion. In this work,"}, "filled": false, "gsrank": 757, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3308560.3316735", "author_id": ["veoVwKwAAAAJ", "WO95x00AAAAJ", "", "0r7Syh0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:H_ZbsTlnTWEJ:scholar.google.com/&output=cite&scirp=756&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D750%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=H_ZbsTlnTWEJ&ei=jrWsaMr-H8DZieoPqdqh8QU&json=", "num_citations": 128, "citedby_url": "/scholar?cites=7011373692372121119&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:H_ZbsTlnTWEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1902.02765"}}, {"title": "Tgdataset: a collection of over one hundred thousand telegram channels", "year": "2023", "pdf_data": "TGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset\nMassimo La Morgia\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nlamorgia@di.uniroma1.itAlessandro Mei\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nmei@di.uniroma1.itAlberto Maria Mongardini\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nmongardini@di.uniroma1.it\nAbstract\nTelegram is a widely adopted instant messaging platform. It has\nbecome worldwide popular because of its emphasis on privacy\nand its social network features such as channels\u2014virtual rooms in\nwhich only the admins can post and broadcast messages to all the\nsubscribers. Channels are used to deliver live updates ( e.g.,weather\nalerts) and content to a large audience ( e.g.,COVID-19 announce-\nments) but unfortunately also to disseminate radical ideologies and\ncoordinate attacks such as the Capitol Hill riot.\nThis paper introduces the TGDataset, the most extensive pub-\nlicly available collection of Telegram channels, comprising 120,979\nchannels and over 400 million messages. We outline the data collec-\ntion process and provide a comprehensive overview of the data set.\nUsing language detection, we identify the predominant languages\nwithin the dataset. We then focus on English channels, employing\ntopic modeling to analyze the subjects they cover. Finally, we dis-\ncuss some use cases in which our dataset can be instrumental in\nunderstanding the Telegram ecosystem and studying the diffusion\nof questionable news. Alongside the raw dataset, we release the\nscripts used in our analysis, as well as a list of channels associated\nwith a novel conspiracy theory known as Sabmyk.\nCCS Concepts\n\u2022Information systems \u2192Information retrieval ;Social networks .\nKeywords\nDataset, Telegram, Conspiracy Theories, Copyright Infringement\nACM Reference Format:\nMassimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2025.\nTGDataset: Collecting and Exploring the Largest Telegram Channels Dataset.\nInProceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\nand Data Mining V.1 (KDD \u201925), August 3\u20137, 2025, Toronto, ON, Canada. ACM,\nNew York, NY, USA, 11 pages. https://doi.org/10.1145/3690624.3709397If you cite this paper, please use the ACM SIGKDD Conference on Knowledge Discovery and Data Mining reference: Massimo La Morgia,\nAlessandro Mei, Alberto Maria Mongardini. 2025. TGDataset: Collecting and Exploring the Largest Telegram Channels Dataset. KDD. \u201925,\nAugust 3\u20137, 2025, Toronto, ON, Canada, 11 pages. https://doi.org/10.1145/3690624.3709397\n1 Introduction\nIn today\u2019s digital age, instant messaging apps have become ubiq-\nuitous, and Telegram stands out as one of the leading platforms.\nIts focus on user privacy is a significant factor behind its growing\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n\u00a92025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1245-6/25/08\nhttps://doi.org/10.1145/3690624.3709397popularity [ 10]. However, as is often the case with platforms that\nprioritize user privacy, this approach has also attracted malicious\nusers who exploit the platform for illegal activities. While Telegram\nserves legitimate purposes, such as disseminating weather alerts\nor government updates [ 42], it is also misused for spreading radi-\ncal ideologies [ 3], orchestrating violent attacks [ 1], and engaging\nin market manipulations, such as pump-and-dump schemes [ 41].\nThese dual uses underscore Telegram\u2019s complex nature and high-\nlight the need for a deeper exploration of its ecosystem.\nIn this study, we introduce and publicly release [ 38] the TG-\nDataset, a collection of public Telegram channels of over 120,000\nchannels and 400 million messages. To the best of our knowledge,\nthe TGDataset surpasses existing datasets in scale and scope, offer-\ning an unprecedented opportunity to study the Telegram ecosystem\ncomprehensively. Unlike prior datasets focused on specific topics\nor geographic regions, the TGDataset includes diverse channels\ncovering multiple languages and subjects, enabling a more holistic\nunderstanding of the platform. In particular, the TGDataset enables\nthe study of the platform\u2019s political leanings and the sharing of\nquestionable content, topics widely explored on other Online Social\nNetworks (OSNs) but not on Telegram. It also includes numerous\nchannels spreading conspiracy theories, as well as those engaged\nin borderline or illegal activities like carding, inciting violence, and\npromoting Nazi ideologies. Thus, with its scale and diversity, the\nTGDataset represents a valuable resource for researchers willing to\ninvestigate and shed light on both the legitimate and problematic\naspects of Telegram\u2019s ecosystem.\nThe main contributions of this work are the following:\n\u2022We present the largest publicly available dataset of Telegram\nchannels, enabling researchers to explore various phenom-\nena on the platform. We perform analyses such as language\ndetection and topic modeling to characterize the dataset\u2019s\ncontents, revealing dominant languages, prevalent topics,\nand temporal trends in channel creation.\n\u2022We explore several potential use cases of the TGDataset. One\napplication involves analyzing the diffusion of questionable\ncontent and biases across Telegram channels, providing in-\nsights into content moderation and information reliability.\nAnother use case focuses on investigating networks that\npromote conspiracy theories, including emerging phenom-\nena such as the Sabmyk network. Additionally, the dataset\ncan be used to investigate channels engaged in borderline\nor illegal activities, such as carding, copyright infringement,\nand extremist propaganda.arXiv:2303.05345v3  [cs.CY]  3 Mar 2025\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\n\u2022Alongside the dataset, we release scripts for analysis, lan-\nguage detection, and topic modeling, fostering reproducibil-\nity and facilitating further research.\n2 Background: Telegram\nStarted in 2013, Telegram is now a popular instant messaging plat-\nform, with more than 500 million active users in 2021 [ 7]. Telegram\nallows users to post content such as text messages, images, audio,\nstickers, videos, and files weighing up to 2 GB. In addition to private\nchats (one-to-one communication), Telegram provides two other\nways to communicate: Through groups and channels.\nGroups : Designed for many-to-many messaging, groups allow\nup to 200,000 members to communicate with each other by posting\ncontent. Groups are identified by a unique username and have a\ndescription and a title. They can be public ( i.e.,can be found with\nTelegram search, and every user can read its content and join the\ngroup) or private ( i.e.,only members can see the posts, and users\nneed an invite link to join it). Besides, a group presents a list of its\nmembers which, if the group is public, is visible to anyone (even\nnon-members).\nChannels : They offer one-to-many communication. Thus, dif-\nferently from groups where every member can post messages, in\nchannels, only administrators can publish posts. Channels have a\nunique username, a title, a description, and can be private or public.\nFig. 1 presents the information displayed by a channel. Contrary\nto groups, a channel can have an unlimited number of subscribers\nand does not display any users\u2019 information ( i.e.,nicknames) other\nthan the number of its subscribers. Thanks to these features, Tele-\ngram channels have become popular for disseminating content to a\nlarge audience. Indeed, several public figures and companies started\nusing official Telegram channels to share news and updates [ 42].\nNonetheless, this tendency caused an increase in the number of\nchannels on the platform seeking to impersonate official channels\nor sell counterfeit products and services.\nScam and Verified mark : To tackle this issue, Telegram has\nimplemented the verified and the scam marks. The verified mark\nrequires that channels, groups, and bots prove their verified sta-\ntus on at least two social media platforms( e.g.,TikTok, Facebook,\nTwitter, Instagram) [ 9]. In contrast, the scam status is assigned to\nchannels and groups reported for fraud by multiple users [52].\nThe forward mechanism : Although private chats, groups, and\nchannels can not communicate directly among them, they are not\nisolated but may be linked through message forwarding. Leveraging\nthis feature, users and channels can forward messages to other users,\ngroups, or channels displaying the post\u2019s original author. Fig. 1\nshows an example of message forwarding, where the admin of\n\"Channel A\" (Fig. 1 (C)) forwards in his channel a message from the\nBloomberg\u2019s channel. The message in the red square of Fig. 1 (B)) is\nthe original message, while the one in the red square of Fig. 1 (C) is\nthe forwarded message. As shown in Fig. 1, the forwarded message\ndisplays the name of the original channel of the post, which, if\nclicked, leads to that channel.\n3 Related works\nSeveral studies have been conducted on the Telegram platform\nand related issues. Hashemi et al. [ 27] collected Telegram IranianTable 1: Summary of the number of channels, channel mes-\nsages, and group messages present in both the TGDataset\nand Pushshift.\nDataset # channels # channels msgs Update to\nNobari et al. [20] 2,556 36,928 October 2016\nPushshift [16] 27,801 192,044,689 November 2019\nTGDataset 120,979 498,320,597 July 2022\nchannels and groups to distinguish high-quality groups ( e.g.,busi-\nness groups) from low-quality groups ( e.g.,dating groups). They\nfound that high-quality groups had longer messages and more user\nengagement. Jalilvand et al. [ 34] tackled the challenge of ranking\nchannels related to a user request on Telegram. Ng et al. [ 50] an-\nalyzed a Singapore-based COVID-19 Telegram group with over\n10,000 participants, examining group opinions over time. Their\nwork revealed a peak in engagement when the Ministry of Health\nraised the disease alert level but a subsequent decline in participa-\ntion. Nobari et al. [ 20] performed a structural and topical analysis\nof Telegram messages, building a dataset of over 2,500 channels and\n54 groups and constructing a graph based on mentions. This study\nfound that the PageRank algorithm was not effective in identifying\nhigh-quality Telegram channels. Analyzing the dataset released\nby Nobari et al., the TGDataset contains more than ten times the\nnumber of channels and is significantly more recent (July 2022\nversus October 2016).\nSimilar to our work, Baumgartner et al. [ 16] created the Pushshift\nTelegram dataset, containing both channels and groups. They col-\nlected over 27,800 channels and 317 million messages from 2.2 mil-\nlion unique users updated to November 2019. Differently from [ 16],\nthe TGDataset boasts a more recent dataset, with the message his-\ntory of channels aligned to July 2022, thus almost three years of\nmore data. Moreover, while the Pushshift dataset contains both\nchannels and groups, the TGDaset is made of only channels. Thus,\nnarrowing the comparison on the Telegram channels, the TG-\nDataset includes a significantly higher number of channels (ap-\nproximately four times more) and a greater volume of messages\nposted in channels (more than double). Table 1 provides the exact\nnumber of channels and messages contained in the dataset released\nby [20], Pushshift, and TGDataset. Finally, another important differ-\nence between the two datasets is about the seed choice. Indeed, the\nPushshift dataset used as seed channels only those of right-wing\nextremist politics or cryptocurrencies-related channels, while our\ndataset starts the collection from seed channels covering hetero-\ngeneous topics (see Sec. 4.1). This choice led to building a dataset\nthat should better represent the status of the Telegram channels\necosystem.\nWeerasinghe et al. [ 63] found that Telegram hosts organized\ngroups called \"pods\" where members boost each other\u2019s Instagram\naccount popularity through interaction. Other studies have docu-\nmented the presence of Telegram channels and groups focused on\ncryptocurrency pump and dump scams [ 41,65]. The work of Urman\net al. [ 61] explored far-right networks on Telegram, revealing that\nthe most prevalent communities are those related to 4chan [ 12]\nand Donald Trump\u2019s supporters. Moreover, the authors pointed out\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n1\n2\n435\n6\n(A) (B) (C ) \nFigure 1: Fig. (A) represents the main information about a channel: the title (1), the number of subscribers (2), the description\n(3), and the username (4). Fig. (B) shows the posts published by the channel (5). Fig. (C) displays a forwarded message (6).\nthat the sudden growth of these networks on Telegram corresponds\nwith the bans of numerous far-right figures on other online social\nnetworks. Additionally, numerous studies have investigated the\nuse of Telegram by terrorist organizations such as ISIS for content\ndissemination and proselytism [18, 66].\n4 Data collection\nPrevious Telegram datasets have been created with specific research\ngoals in mind, resulting in a limited scope of channels related to\na particular language, country, or topic. For example, [27] only in-\ncludes Iranian channels, [ 32] only contains 151 channels related to\nQAnon, and the PushShift dataset focuses on channels discussing\nright-wing extremism and cryptocurrency. In contrast, our dataset\naims to provide a global snapshot of the Telegram ecosystem. To\nachieve this goal, we require a dataset that provides an up-to-date\nrepresentation of Telegram and encompasses a broad range of pop-\nular and interconnected channels. This is the motivation behind\nthe creation of the TGDataset.\n4.1 Dataset construction\nTo build the TGDataset, we use a snowball approach as previously\ndone in [ 16]. We begin with a set of seed channels related to var-\nious topics and then extend our dataset by including the source\nchannel of each forwarded message. Fig. 2 represents the flow di-\nagram we use to collect the data. To determine the seed channels\n(Step 1 in Fig. 2), we utilize Tgstat [ 6], a popular freemium service\nthat indexes over 150,000 Telegram channels and gathers statistics\nabout them. Tgstat provides information for each channel, such\n(1) Seed \nchannels (2) Channels \nretrieval \n(5) Channels \nparsing (4) Data \nstoring \nChannels list \n(3) Data \nextraction Figure 2: Data collection flow diagram.\nas the subscriber count, topic category, growth rate, and language.\nAmong the other metrics, Tgstat lists the top 100 channels by the\nnumber of subscribers. From this rank, we retrieve all the categories\nthese channels belong to, finding the following 18 categories:: Sales ,\nHumor and entertainment ,News and Mass media ,Video & Movies ,\nBusiness & Startups ,Cryptocurrencies ,Politics ,Technologies ,Sport ,\nMarketing ,Economics ,Games ,Religion ,Software and Applications ,\nLifehacks ,Fashion & Beauty ,Medicine , and Adults . Finally, we se-\nlected the ten most popular channels from each category as the seed\nchannels according to their subscriber count. With this approach,\nwe collect 180 seed channels.\nFor each seed channel, we proceed with downloading all its\nmessages by leveraging the Telethon APIs [ 8] (Step (2)), an open-\nsource Python tool that provides access to the official Telegram\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nField name Description\nChannel ID the ID of Telegram channel\nCreation date the timestamp of the creation date of the channel\nUsername the Telegram username of the channel\nTitle the title of the channel\nDescription the description of the channel\nScam indicates if Telegram marked the channel as a scam\nVerified indicates if Telegram marked the channel as verified\n# subscribers the number of subscribers of the channel\nText messages\nMessage the text of the message\nDate the timestamp of the message publication\nAuthor the ID of who posted the message\nIs forwarded indicates if the message is forwarded\nForwarded from the ID from which the message is forwarded\nOriginal date the timestamp of the first post of the message\nMedia messages\nTitle the title of the content\nMedia ID the ID of the content on Telegram\nDate the timestamp of the content\nAuthor the ID of who posted the content (int)\nExtension the format of the content (string)\nIs forwarded indicates if the content is forwarded\nForwarded from the ID from which the content is forwarded\nOriginal date the timestamp of the first post of the content\nTable 2: Information stored about collected channels\nAPIs. Specifically, each call to download messages from a channel\nis performed five seconds after the previous one to avoid flooding\nthe Telegram service. Once we retrieved the data about the channel,\nwe proceeded with the data extraction (Step (3)): in particular, we\nretained all the information obtained by Telegram API, excluding\nmedia files such as images, videos, or PDFs. The reason behind this\ndecision is to avoid storing copyrighted or illegal content. Anyway,\neven for media-based messages, we collect the name, author, and ID\nof the media content using the Telegram API, and we infer the file\nformat based on the extension of the file name. Next, we store the\nextracted information in MongoDB [ 48], a NoSQL database (Step\n(4)). Finally, we parse the channel messages to identify forwarded\nmessages and their original authors (Step (5)). If the author repre-\nsents a channel that we have never seen, then the channel is added\nto the list of new channels. Conversely, if the author is a user or\nrepresents a group, we ignore the author of the forwarded message.\nTo iteratively expand the TGDataset, we repeat the above procedure\nof channel discovery (Steps 2, 3, 4, and 5) using the newly found\nchannels as new seeds. We stopped the iteration process on July 31,\n2022. Finally, to align our dataset, for each discovered channel, we\ndownload all the missing messages until July 31, 2022.\nFor each channel, we store the following information as listed\nin Tab. 2: title and if it is marked as verified or scam (item 1 in\nFig. 1 (A)), subscriber count (item 2), description (item 3), username\n(item 4), ID, and creation date. For the messages, we retain the\nauthor (the name of the channel), timestamp, and, in the case of\nforwarded messages, original posting date and original channel.4.2 Accessing the TGDataset and FAIR\nprinciples\nWe released the TGDataset in alignment with the FAIR (Findable,\nAccessible, Interoperable, Reusable) principles [64].\nFindable. We publicly released the TGDataset [ 37] on Zen-\nodo [24], an open repository managed by CERN.\nAccessible. The dataset is made of 121 files, each of which con-\ntains a maximum of 1,000 channels. To ease the retrieval of single\nchannels from the dataset, we store them in alphabetical order. In\naddition, each file\u2019s name describes the index of the channels it con-\ntains. Given the large dimension of the dataset, even if compressed\n(approx. 71GB), we divided the dataset into four parts. In this way,\nit is possible to download and explore also a single portion of the\ndataset. Moreover, we released a sample of the dataset on a public\nGitHub repository [ 38]. This enables users to explore the dataset\u2019s\nstructure without the need to download any portion of it.\nInteroperable. All the information is encoded in JSON format\nso that the data can be easily parsed and manipulated with most\nprogramming languages.\nReusable. We have outlined the methodology employed for data\ncollection, and the data is open for anyone to use. We also released\non the public GitHub repository [ 38], Python scripts to load the data\ninto a MongoDB [ 15] database, as well as scripts that show how to\nperform basic queries on the database (such as inserting new chan-\nnels or retrieving channels by username or ID). Furthermore, these\nscripts can also replicate some of the analysis that we performed\nin this work, including Language Detection of the channels (Sec-\ntion 5.1) and Topic Modeling (Section 5.2). Finally, we released as\nCSV files the list of channels belonging to the Sabmyk network and\nthe list of other channels promoting conspiracy theories (Sec. 6),\nthe list of channels annotated with the detected writing language,\nand the one containing the mapping of inferred topics.\n4.3 Dataset overview\nThe data collection for the TGDataset began on 4 January 2021 and\nended on 31 July 2022. The dataset has a total size of about 460 GB\nand includes 498,320,597 messages and 120,979 unique channels.\nOut of these channels, 654 (0.54%) have verified status, while 183\n(0.15%) are flagged as scam channels. For the purpose of clarity,\nwe will refer to the remaining 120,142 channels, which are neither\nscams nor verified, as standard channels .\nTo provide a general characterization of the channels contained\nin the TGDataset, in Fig. 3, we show the CDFs of the number of\nsubscribers, posts published, and the ratio of forwarded messages\nfor verified, scam, and standard channels. As shown in Fig. 3(a),\nverified channels (green line), in general, have more subscribers\nthan scam (dashed orange line) and standard channels (dotted blue\nline). Indeed, the verified channels with more than 1,000 subscribers\nare 98.32%, while the scams and standard are 68.85% and 38.11%, re-\nspectively. Concerning the number of messages published, Fig. 3(b)\nsuggests that verified channels tend to post more content than\nscams and standard ones. The standard channels with at least 1,000\nmessages are 57.16%, those verified are 83.79%, and the scams are\n50.82%. Moreover, we report the extent of use of the forwarding\nfunction among channels of the TGDataset. Fig. 3(c) reveals mes-\nsage forwarding is more prevalent in standard and scam channels.\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n0 2000000 4000000 6000000 8000000\nSubscribers0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard0 2000 4000 6000 8000 100000.00.20.40.60.8\n(a) Subscribers\n0 50000 100000 150000 200000 250000 300000\nMessages0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard 0 2000 4000 6000 8000 100000.00.20.40.60.8 (b) Messages.\n0.0 0.2 0.4 0.6 0.8 1.0\nRatio forwarded msgs0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard (c) Forwarded messages\nFigure 3: CDFs of the number of subscribers for scam, verified, and standard channels (3(a)), the number of messages posted\n(3(b)), and ratio of forwarded messages (3(c)).\nThe standard channels with at least a 0.1 ratio of their messages\nthat are forwarded are 33.5%, whereas the scams and the verified\nones are 32.24% and 13.15%, respectively.\n5 Dataset analysis\nIn this section, we first study the languages spoken within our\ndataset, leveraging language detection, and explore the English\nchannels to understand the covered topics using topic modeling.\nThen, we analyze the temporal aspects of the TGDataset.\n5.1 Language detection\nAs a first step in our analysis, we want to understand the language\ncoverage of our dataset. This study gives hints about the popular-\nity of the Telegram platform in different regions of the world. To\nautomatically retrieve the language used in a channel, we leverage\nLanguage Detection [ 54], a language detection library implemented\nin Java by Google with over 99%of precision for 53languages. To get\nmeaningful results dealing with text-based messages, first, the text\nhas to be normalized and polished from useless information [ 62].\nHence, we applied the following preprocessing steps. First, we ex-\ncluded messages shorter than 15 characters, as they do not provide\nsufficient information for accurate analysis [14]. Next, we utilized\nthe RegexpTokenizer developed by NLTK [ 5] to split text-based\nmessages into tokens. Then, we removed all numbers and emojis\nfrom the documents, as they do not contribute to language iden-\ntification. Also, we discarded references and mentions of groups,\nchannels, or users, as usernames typically do not aid in identifying\nthe language used.\nWe assign a channel to a specific language only if over 50% of\nits messages are written in that language. Otherwise, we will not\nassociate a language with that channel. At the end of the analysis,\nwe find that the five most spoken languages in our dataset are Rus-\nsian with 42,983 channels (35.52%), English with 19,768 channels\n(16.34%), Farsi with 16,779 channels (13.86%), German 4,950 (4.09%),\nand Arabic with 2,523 (2.08%). Of particular interest is the strong\npresence of the Russian and Farsi channels, which likely reflects the\npopularity of Telegram in Russia and Iran, despite Russia\u2019s govern-\nment banned Telegram from 2018 to 2020 [ 4], and it is still banned\nin Iran [ 13]. Although Iran banned Telegram on 30 April 2018 [ 2],\nin our dataset, there are 4,635 out of 16,779 (27.62%) channels in\nFarsi created after the date of the ban. Instead, looking at the lastactivity of Farsi\u2019s channels, we find that more than 66.53% (11,164)\nchannels continued to operate after the ban. Regarding Russian\nchannels, as shown in section Sec. 5.3, they continue to appear also\nafter the ban of 2018.\n5.2 Topic modeling\nIn this subsection, we investigate the topics covered by the channels\nin our TGDataset using Topic Modeling [ 30]. This is a data mining\ntool that allows finding a brief description of the topic addressed\nby the messages of a channel. For this analysis, we consider only\nchannels that post English content. Thus, we use as input to the\ntopic modeling 19,768 channels (16.34% of our dataset). As in lan-\nguage detection, a preprocessing phase is necessary. In addition to\nthe deletion of numbers, deletion of emoji, and normalization, we\nperform other preprocessing steps. We exclude words with one or\ntwo characters, as they are common in messages (e.g., y, no, ok)\nand do not provide meaningful information about the topic. We\nuse the en_core_web_sm model developed by spaCy [ 31] to reduce\ninflected words to their lemmas, ensuring that different forms of\na word are treated as a single term. Lastly, we employ the English\nstopwords list provided by NLTK [ 51] to discard common words\n(e.g., articles and prepositions) that do not carry significant meaning\nin a sentence [53].\nTo discover the latent topics addressed within the channels, we\nuse the Latent Dirichlet Allocation (LDA) [ 17] as the Topic Modeling\nalgorithm. LDA needs as input the number of topics, so we used\nthe UMass measure [ 47] to select the optimal one. In particular, the\nhigher the coherence of the words representing topics, the closer\nto 0 the value of UMass. In our case, we calculate the best UMass\nvalue reached by selecting the number of topics from 10 to 30.\nThe best UMass value (-0.69) is obtained with 13 topics. Tab. 3\nshows the inferred topics and the top 10 keywords for each of\nthem. Next, we group the channels according to the related topics\nusing LDA. Tab. 5 lists the topics discovered in the TGDataset\nand the number of channels for each. These emerged topics are\nquite different from those covered by the seed channels (see Sec. 4).\nIndeed, some disappeared ( e.g.,Psychology, Marketing), while other\ninteresting topics came up. This shift in topic distribution is due\nto the snowball approach, which adds new channels linked by\nmessage forwarding to the dataset. As a result, channels from larger,\nmore interconnected networks with higher forwarding activity are\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nTopic Top 10 keywords\nVideo-game\nmoddingpubg, esp, lvl, max, mod, login,\npassword, aimbot, vip, recoil\nCardingiphone, premium, netflix, amazon, samsung,\npaytm, giveaway, hacking, tutorial, vpn\nEntertainmentreddit, artist, submit, edition, meta,\ntil, hire, score, anime, league\nIndian educationindian, upsc, exam, affair, copyright,\ninfringement, unavailable, wildlife, prelim, batch\nReligionjesus, lord, christ, spirit, pray, holy, shall,\nchurch, prayer, bless\nUS newstrump, biden, vaccine, election, covid, joe,\ndonald, court, military, mandate\nSocialtwitter, reuter, tweet, album, telegram, ivurl,\nutc, radio, hashtag, youtube\nWorld Newsrussia, ukraine, independent, minister,\nmilitary, coronavirus, europe, foreign, israel, court\nSoftwareandroid, rupee, enroll, web, udemy, proxy,\nlinux, software, premium, mod\nCOVID-19vaccine, covid19, covid, medical, vaccination,\nvaccinate, pfizer, disease, patient, australia\nCryptobtc, bitcoin, crypto, usdt, binance, usd, token,\ntrading, blockchain, profit\nExtremists\nand radicalsviolate, defense, jews, jewish,\nattacker, defend, jew, defender, hitler, antifa\nAdult contentpornographic, leak, t.me, xxx, meme, wanna,\nsharp, iphone, porn, teen\nTable 3: Top 10 keywords within LDA topics.\nmore likely to be included. This method naturally shifts the dataset\ntoward more viral or widely shared topics.\nAmong the new topics, one is related to carding, the practice\nof selling full details of stolen credit cards or selling prepaid cards\nor other goods purchased with them. Similarly to what happens\nin dark web forums [ 35], carders (the people who own the stolen\ncredit cards) use Telegram channels to place gift cards or goods for\nsale. In the TGDataset, we find 1,489 channels (7.53% of the English\npart of the dataset) offering this service. In particular, Telegram\nmarked 45 carding channels as scams, suggesting that some of them\ndo not deliver the service they offer.\nAnother unusual cluster containing 989 channels (5% of English\nchannels) is the one about extremists and radicals. Here, several\nchannels promote white supremacy, as well as other Nazi ideolo-\ngies and conspiracies against the white race (the title of one of\nthese channels is White Genocide Immigration Anti-White Agenda ).\nInterestingly, there are four channels in this category having the\nverified status. One channel ( \"ISIS Watch\" ) just publishes daily up-\ndates on banned terrorist content. Instead, the other three channels\nare related to official news agencies of the Russian government\nand are no longer accessible on Telegram. Moreover, some of their\nmessages we collected are obscured by the platform. To investigate\nthis aspect deeper, we analyze the messages obscured by Telegram\nas they incited violence, published illegal pornographic content,\nor shared content protected by copyright. In this case, Telegram\nreplaced some or all of the channel\u2019s messages with text explaining\nthe reasons for obfuscation. Interestingly, the channel itself and the\n2015/11\n2016/5\n2016/11\n2017/6\n2017/12\n2018/6\n2018/12\n2019/6\n2019/12\n2020/6\n2021/1\n2021/7\n2022/1\nCreation date0100020003000Number of channelsAll\nRussian\nEnglishFigure 4: Creation date of Russian, English, and all the chan-\nnels. The green dot represents the date when Russia banned\nTelegram, while the azure one indicates WhatsApp\u2019s an-\nnouncement about privacy policy.\nmetadata ( e.g.,the posting date) related to the original messages\nare still available. As shown in Tab. 4, the service message most\nused by Telegram to obscure a post is the one about the violation\nof Telegram\u2019s Terms of Service (428,793 messages). Follow the one\nabout the spread of pornographic content (263,643 messages), the\nviolation of local laws (145,448 messages), and copyright infringe-\nment (48,402 messages). Finally, the other topics are more aligned\nwith the ones covered by the seed channel of the TGDataset.\n5.3 Temporal aspect\nAnother interesting aspect is the creation date of the collected chan-\nnels since, from this information, it is possible to understand how\nTelegram evolved through time. Fig. 4 shows the monthly creation\nrate of the channels contained in the TGDataset. In particular, the\nblue line represents the overall number of channels created on a\ncertain date, while the green and the orange lines the number of\nRussian and English channels, respectively. As we can see, the num-\nber of channels created is steadily increasing, indicating that the\nTelegram platform is becoming more popular daily. Indeed, also\nmany governments choose to use Telegram channels to commu-\nnicate information regarding COVID-19 [ 42]. Until the beginning\nof 2018, the growth of channels is led by Russian-speaking users.\nHowever, in the first months of 2018, it is possible to note a sudden\ndrop in daily created channels, likely due to the Russian ban of\nTelegram (green dot in Fig. 4). Nonetheless, Russian channels, even\nif at a lower rate, continue to appear every day. Finally, in the first\nmonths of 2021, there was an abrupt increase of English-language\nspoken channels that overtook the Russian ones for the first time\nin Telegram history, according to our data. This event coincides\nwith the change of WhatsApp\u2019s privacy policy (azure dot in Fig. 4)\nand the migration of many users from WhatsApp to Telegram [ 11].\n6 Use cases\nThe TGDataset has already been utilized in various studies [ 33,39,\n40]. For instance, La Morgia et al. [ 39] analyzed the problem of\nfake accounts on Telegram using the TGDataset, while Imperati\net al. [ 33] employed the TGDataset to identify 17,829 channels\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\nMessage description Number of messages Number of channels\nThis channel can\u2019t be displayed because it violated Telegram\u2019s Terms of Service. 428,793 2,546\nThis channel can\u2019t be displayed because it was used to spread pornographic content. 263,643 969\nThis channel can\u2019t be displayed because it violated local laws. 145,448 847\nThis channel is unavailable due to copyright infringement. 48,402 1,633\nTable 4: Number of posts obscured by each service message and number of channels presenting a specific service message.\nTable 5: Number of channels, scams, and verified ones be-\nlonging to each discovered topic.\nTopic # channels # scam # verified\nReligion 4,725 (23.90%) 0 5\nUS news 2,948 (14.91%) 38 51\nVideo-game modding 1,957 (9.90%) 14 0\nCovid 1,716 (8.68%) 0 5\nCarding 1,489 (7.53%) 45 0\nEntertainment 1,440 (7.28%) 0 3\nWorld news 995 (5.03%) 0 17\nExtremists and radicals 989 (5.00%) 0 4\nIndian education 939 (4.75%) 1 6\nSoftware 871 (4.41%) 2 14\nPorn 830 (4.20%) 5 0\nCrypto 563 (2.85%) 5 10\nSocial 306 (1.55%) 0 4\ndisseminating conspiracy-related content. In the following, this\nsection describes other scenarios that can be explored and analyzed\nusing the TGDataset.\nPolitical leaning and presence of questionable contents.\nPrevious studies show the presence of moderation in OSNs ( e.g.,\nTwitter) produces a significant reduction of questionable content,\nwith respect to not moderated OSNs ( e.g.,Gab) [ 21], and that the\ninformation diffusion is biased by the political leaning of the com-\nmunity [ 19]. However, very little is known about the loosely mod-\nerated Telegram platform. Thus, we use the TGDatset to perform\nthe first high-level investigation on Telegram. To this end, as done\nin [21,22], we leverage Media Bias/Fact Check (MBFC) [ 45], an\nindependent fact-checking organization that rates the bias of news\noutlets. In particular, MBFC classifies the political bias of news out-\nlets with one of the following labels: Extreme Left, Left, Left-Center,\nLeast-Biased, Right-Center, Right, Extreme Right . Additionally, MBFC\nprovides a second label to quantify the reliability of the outlet, cat-\negorizing outlets as Reliable andQuestionable .\nFor each English channel in the TGDataset, we label the links it\ncontains according to the Media Bias/Fact Check (MBFC) catego-\nrization. We then assigned each channel the most frequently chosen\nlabel among its categorized links. This approach classifies 9,045\nchannels out of 19,768; the remaining channels did not share news\nor contain sources not present in MBFC. Upon aggregating channels\ninto left-leaning (Left-Center, Left, Extreme Left) and right-leaning\n(Extreme Right, Right, Right-Center) groups, we found a nearly\nbalanced distribution: 4,491 channels shared right-leaning news,\nand 3,900 shared left-leaning news. However, 2,748 channels were\nidentified as spreading extreme right content, while none werefound to be spreading extreme left content. Among the top four\ntopics with the most categorized channels (World News, US News,\nReligion, and Covid), World News is the most left-leaning, with\nover 60% of the channels associated with left-leaning outlets. Chan-\nnels on the topic of Religion were almost evenly split between left\nand right. Conversely, channels dealing with US News and Covid\nwere predominantly right-leaning. Specifically, the extreme right\nwas underrepresented in World News (76 channels) but predom-\ninant in Religion (590 channels), US News (1,144 channels), and\nCovid (601 channels). These three topics\u2014Religion, US News, and\nCovid\u2014also had the highest number of channels sharing content\nfrom questionable sources, with 1,353, 2,320, and 1,277 channels,\nrespectively. Analyzing the reasons behind their questionable clas-\nsification, we find that 55% of Religion, 80% of US News, and 85% of\nCovid questionable channels shared content from outlets associated\nwith conspiracy theories by MBFC.\nThis analysis reveals a significant presence of Telegram channels\ndisseminating news from unreliable sources. Thus, the TGDataset\ncould be a valuable resource for researchers aiming to understand\nthe spread of misinformation, fake news, and conspiracy theories.\nThis use case involves using the content of the text messages posted\nby the channels (represented by the Message field) to extract links\nfor further processing, and the forwarding information, including\nwhether the message was forwarded and its source (contained in\ntheIs Forwarded andForwarded From fields).\nStudy of channels spreading conspiracy theories. In the\nprevious use case, we discovered that there are channels that spread\nnews related to conspiracy theories. Here, we attempt to identify\nthem through community detection. A community in a graph is\na subset of nodes that are densely connected to each other and\nweakly connected to nodes in other communities.\nFor this study, we represent our dataset as a directed graph\n\ud835\udc3a=(\ud835\udc49,\ud835\udc38)in which nodes in \ud835\udc49are the channels, and edge \ud835\udc62\u2192\ud835\udc63\nin\ud835\udc38represents the presence in channel \ud835\udc62of a message originally\nposted in\ud835\udc63and forwarded to \ud835\udc62by the admin of channel \ud835\udc62. Since the\nusers of channel \ud835\udc62can navigate the forwarded message and land\non channel\ud835\udc63, the edge represents in a natural way the possible flow\nthrough channels of users following forwarded messages. To build\nand analyze our graph, we use the NetworkX library [26].\nThen, we use the Leiden algorithm [ 60], an algorithm for commu-\nnity detection that improves the Louvain algorithm [ 25]. To ensure\nthe accuracy of our partition, we used modularity, a validation met-\nric that measures how much better our partitioning is compared\nto a random partition. Thus, we compute the optimal number of\ncommunities with respect to modularity, achieving a high score\nof 0.78, which indicates a strong community structure remarkably\nbetter than random partitioning. This approach finds a partition\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nwith 311 communities, 47 of which with more than one node. One\nof the communities, which consists of 236 channels and where Eng-\nlish is the common language, has the peculiarity that all posts and\nmessages forwarded from one channel to the other are about a new\nconspiracy theory called Sabmyk. Sabmik is a conspiracy theory\nthat proposes itself as a better alternative to QAnon. It promotes a\nquasi-religion centered around a messianic figure known as Sab-\nmyk [ 56]. This community of channels has, collectively, more than\n1 million subscribers. The most popular channel in the community\nisGreat Awakening Channel with 119,103 subscribers. According to\nour data, most of these channels were created at the beginning of\n2021\u2014130 of them (55.08%) between January and February\u2014with\nthe latest in our dataset created in February 2022. The nature of\nthese channels is very different: Some of them are fake channels of\ncelebrities ( e.g.,Mel Gibson, Keanu Reeves, Kanye West), while oth-\ners target news outlets or official channels of national bodies ( e.g.,\nU. S. Marines Channel, U. S. Navy Channel) and others conspiracy\ntheories like QAnon. Regardless of the name of the channel in the\ncommunity, the content is always the same. Indeed, they recycle\nand forward messages among them: Out of the 1,203,986 messages\npublished by these 236 channels, only 65,602 are unique. With this\nanalysis we scratch the surface of the Sabmyk network. Still, more\ninvestigation are needed to understand how Sabmyk lures such a\nlarge number of subscribers, its ultimate goal, and its connection\nto other conspiracy theories.\nPerforming this study requires several key elements of the dataset.\nBy analyzing the content of the Message field, it is possible to iden-\ntify the topics within conspiracy theories. With the Is Forwarded\nfield, we can understand if the message has been forwarded, and\nin the case it is, which was the source channel leveraging the For-\nwarded From field. This information makes it possible to build a\ngraph representing connections between channels and to detect\nthe communities as we did for our analysis.\nCarding and underground markets. In Section 5.2, we ex-\namine the main topics within our dataset. Upon investigating the\nchannels associated with these topics, we discovered several en-\ngaging in borderline activities, such as running underground mar-\nketplaces. These channels sell electronics, Netflix accounts, and\nhacking tools for low prices. These types of marketplaces are often\nassociated with carding. Consequently, it is worth delving further\ninto these Telegram channels to determine the types of goods being\nsold, their origins, whether the channels are just an attempt to fraud\nsubscribers or if they are actually engaged in more illegal activities,\nand whether there is any correlation with Dark Web marketplaces.\nFor this analysis, the Message field is crucial for identifying the\ntypes of goods sold within the channels, such as electronics, Netflix\naccounts, and hacking tools. Analyzing the content of the messages\nand extracting the URLs makes it possible to determine whether the\nchannels are involved in fraudulent activities or illegal transactions.\nCopyright Infringement and personal content. Recently,\nTelegram hit the news several times for its use for the distribution\nof copyrighted content ( e.g.,movies and software). For instance, Ital-\nian authorities seized 545 channels for copyright infringement [ 44].\nHowever, the issue extends beyond copyright violations. Indeed,\nthe platform is frequently misused to distribute personal content\nwithout consent, such as the unauthorized distribution and sale\nof an Indian teacher\u2019s course material [ 55]. Even more troubling,Telegram is also used to share leaked nude photos [ 43] or facili-\ntate revenge porn [ 36]. Joining the information about the topic of\nthe channels, and the description of the messages removed by the\nplatform (Tab. 4), we can observe that the four categories in which\nis most present the diffusion of copyrighted material are: Carding\n(448 channels), Indian Edu (219 channels), Video-game modding\n(208 channels), Adult content (157 channels). Starting from these\nchannels, it is possible to study the diffusion of the phenomenon,\nunderstand how these channels are organized, and how they mon-\netize. For this analysis, the Message field is essential for identifying\nillicit content, such as copyrighted material, while the Description\nfield could provide additional context about channel activities.\nCryptocurrencies frauds. We also found several (563) channels\nrelated to the cryptocurrency world. It is well known that Telegram\nchannels are exploited by Pump and Dump groups [ 49,65] that\nperpetrate frauds on the crypto-market. We notice that some of\nthe Pump and Dump channels monitored in [ 41] are also in our\ndataset. Previous works monitored the channels vertically, focusing\non the fraud and the groups\u2019 mechanics. Thus, using the Message ,\nForwarded from , and Description fields, the TGDatast can help under-\nstand how these channels are connected, if they operate together,\nhow they promote their services, and likely discover new channels\nthat carry out similar activities.\nViolence and extremism. According to several newspapers,\nthe Capitol Hill riot of January 2021 was planned months before\nalso leveraging Telegram channels and groups [ 29,46]. In response\nto this event, the platform has intensified its monitoring and ob-\nscured dozens of public channels promoting calls to violence [ 28].\nNonetheless, despite the commitment of Telegram to obfuscate\nthese channels, within our dataset, there are several public chan-\nnels promoting the spread of neo-Nazi ideologies or calls to vio-\nlence ( e.g., White Aryan Woman ,Feuerkrieg Division **OFFICIAL** ).\nTherefore, the problem is still far from being solved. The TGDataset\ncan help study and characterize these channels. Indeed, the main\nproblem with these channels is the absence of a dataset containing\nthem, as they are obscured or blocked once discovered. Instead, the\nTGDataset includes several unblurred channels of this typology that\ncan be used to analyze their features and build a machine-learning\nmodel able to detect them automatically. This study requires the\nMessage andDescription fields to analyze harmful content and ob-\ntain context on the purposes of these channels, and the Forwarded\nfrom field to trace the channel behind it.\nTemporal analyses and information propagation. The TG-\nDataset represents a valuable resource for exploring the temporal\ndynamics of information spread by leveraging message timestamps\nand channels\u2019 creation dates. Message timestamps ( Date field in\nText messages and Media messages) facilitate granular analyses of\ndissemination patterns, enabling researchers to track how content\nspreads within and across channels. Instead, channels\u2019 creation\ndates ( Creation date field) enable the analysis of the correlation\nbetween a channel\u2019s longevity and its influence on information\npropagation. These temporal attributes support a variety of stud-\nies. For example, if combined with the forwarding information ( Is\nforwarded andForwarded from fields in Text messages and Media\nmessages), they allow for tracing the rise and evolution of trending\ntopics, assessing the velocity of information diffusion for different\ncontent types, identifying peak activity periods for specific topics\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\nor channels, and examining shifts in information flow patterns\nover time. Moreover, beyond individual channels, the communi-\nties identified in the TGDataset present opportunities for studying\ninter-community information diffusion. Investigating these larger\nnetwork structures could provide valuable insights into how infor-\nmation propagates across interconnected groups within Telegram,\nunveiling the mechanisms that drive broader dissemination trends.\n7 Ethical Considerations\nThis paper presents the TGDataset, a new dataset that includes\n120,979 Telegram channels and over 400 million messages. The data\ncollection was conducted carefully to only include information from\nTelegram channels and exclude personal data such as usernames,\nphone numbers, and subscribed channels.\nOur data collection process complies with Telegram\u2019s Terms of\nService [ 58] and Telegram API\u2019s Terms of Service [ 57], as there are\nno clauses that prohibit the collection of public chat data. Addi-\ntionally, we have taken care to avoid flooding the platform with\nrequests during data collection. Moreover, our research complies\nwith the academic research exemptions outlined in Article 85 of\nthe GDPR [ 59], which provide certain flexibilities for processing\npublicly available data in the interest of freedom of expression\nand academic purposes. As our work exclusively involves publicly\naccessible content and does not process private user data, it falls\nunder the legitimate or public interest exemptions. Furthermore, we\nadhere to the principle of data minimization, as emphasized in the\nGDPR\u2019s guidelines [ 23]: We limit our analysis to admin-generated\npublic posts, ensuring that only the information strictly necessary\nfor our research objectives is processed.\nLastly, since the dataset includes channels that discuss contro-\nversial topics, some controversial messages may be present in the\ndataset. To comply with ethical standards, we did not download\nany images or include links in the public dataset as they may con-\ntain adult content or copyrighted material. Hence, according to our\nIRB\u2019s policy, we did not require explicit authorization to conduct\nour experiments.\n8 Limitation\nTo create the TGDataset, we began with 180 seed channels and then\nemployed a snowball technique to grow the dataset. This approach\nis limited to only reaching channels that are linked by message\nforwarding. Despite this constraint, we were able to uncover over\n100,000 channels and could potentially discover even more through\ncontinued iterations. Nonetheless, there may be groups of channels\nthat remain inaccessible from our seed channels.\nIn the TGDataset, channels are represented as a snapshot of their\ncurrent state. Although some historical details about the channels\nare available in the dataset, such as their creation date and times-\ntamp of messages, other information is not present. For instance,\na channel during time can change its name, description, and of\ncourse, the number of subscribers. This information could be useful\nfor reconstructing the evolution of the channels. In the current\nrelease of the TGDataset, we do not retrieve the comments posted\nby users on channels\u2019 messages or the reaction emojis they may\nhave used (such as the \u2019like\u2019 button on Facebook). While we haveobserved that many Telegram channels do not use these features,\nthey can still offer valuable insights for future analyses.\n9 Conclusions and Future works\nTelegram has gained significant popularity in recent years. As a\nresult, it is crucial to study and understand the activity taking place\non the platform.\nIn this work, we present the TGDataset [ 38], a collection of\nmore than 120,000 public Telegram channels that, to the best of our\nknowledge, is the largest collection of channels publicly available.\nAfter characterizing the main quantitative aspect of the TGDataset,\nwe performed language detection to understand which are the most\npopular languages on the dataset. Then, we investigate the main\ntopics covered by the English channels. Additionally, we publicly\nreleased the script we used to analyze it and the labeling we obtained\n(language and topic of the channels). In this paper, we investigate a\nfew possible use cases in which our dataset can be extremely useful.\nIn particular, our preliminary study of the TGDataset revealed some\nTelegram channels spread questionable content and conspiracy\ntheories. Moreover, we observed the presence of several borderline\nactivities and channels dealing with dubious ethical content. With\nthe release of the TGDataset, we aim to provide a valuable resource\nto researchers that enables further investigation into these areas,\nleading to a more refined understanding of Telegram and helping\nto mitigate potential risks to users.\nAs future work, we plan to continue running our data collector\nand further enlarge the TGDataset, releasing new versions of the\ndataset at regular intervals of time. Moreover, we intend to over-\ncome the actual limitations by recording channel updates (channel\u2019s\nname, subscribers, and description), adding to the list of channels\nto monitor also those referenced by link, inserting the possibility\nto add new seed channels, and collecting replies to messages.\n10 Acknowledgments\nThis work has been partially funded by projects: MUR National\nRecovery and Resilience Plan, SERICS (PE00000014); and ST3P\n(B83C24003210001) under the \"Young Researchers 2024-SoE\" Pro-\ngram funded by the Italian Ministry of University and Research\n(MUR).\nReferences\n[1]2017. Telegram to block terror channels after Indonesian ban. https://www.bbc.\ncom/news/business-40627739.\n[2]2018. Iran has banned Telegram after claiming the app encourages \u2018armed\nuprisings\u2019. https://www.theverge.com/2018/5/1/17306792/telegram-banned-iran-\nencrypted-messaging-app-russia.\n[3]2019. Telegram the latest safe haven for white supremacists. https://www.adl.\norg/blog/telegram-the-latest-safe-haven-for-white-supremacists.\n[4]2020. Russia lifts ban on Telegram messaging app after failing to block it. https:\n//www.reuters.com/article/us-russia-telegram-ban-idUSKBN23P2FT.\n[5]2021. NLTK RegexpTokenizer. https://www.nltk.org/_modules/nltk/tokenize/\nregexp.html.\n[6] 2021. Telegram Analytics. https://tgstat.com/.\n[7]2021. Telegram FAQ. https://telegram.org/faq#q-what-is-telegram-what-do-i-\ndo-here.\n[8] 2021. Telethon\u2019s Documentation. https://docs.telethon.dev/en/latest/.\n[9] 2022. Page Verification Guidelines. https://telegram.org/verify.\n[10] Jan. 2021. WhatsApp delays privacy policy changes after users defect to rivals\nSignal and Telegram. https://fortune.com/2021/01/15/whatsapp-delays-privacy-\npolicy-changes-after-users-defect-to-rivals-signal-and-telegram/.\n[11] May 2021. WhatsApp privacy policy change: Telegram, Signal saw massive\nspike in January, shows data. https://indianexpress.com/article/technology/\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nsocial/whatsapp-privacy-policy-change-telegram-signal-saw-massive-spike-\nin-january-shows-data/.\n[12] 4chan. 2023. 4chan. https://www.4chan.org/.\n[13] Azadeh Akbari and Rashid Gabdulhakov. 2019. Platform surveillance and resis-\ntance in Iran and Russia: The case of Telegram. Surveillance & Society 17, 1/2\n(2019), 223\u2013231.\n[14] Timothy Baldwin and Marco Lui. 2010. Language identification: The long and the\nshort of the matter. In Human language technologies: The 2010 annual conference\nof the North American chapter of the association for computational linguistics .\n229\u2013237.\n[15] Kyle Banker, Douglas Garrett, Peter Bakkum, and Shaun Verch. 2016. MongoDB\nin action: covers MongoDB version 3.0 . Simon and Schuster.\n[16] Jason Baumgartner, Savvas Zannettou, Megan Squire, and Jeremy Blackburn.\n2020. The Pushshift Telegram Dataset. In Proceedings of the International AAAI\nConf. on Web and Social Media , Vol. 14. 840\u2013847.\n[17] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.\nthe Journal of machine Learning research 3 (2003), 993\u20131022.\n[18] Zhenfeng Cao, Minzhang Zheng, Yulia Vorobyeva, Chaoming Song, and Neil\nJohnson. 2017. Dynamical patterns in individual trajectories toward extremism.\nAvailable at SSRN 2979345 (2017).\n[19] Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter\nQuattrociocchi, and Michele Starnini. 2021. The echo chamber effect on social\nmedia. Proceedings of the National Academy of Sciences 118, 9 (2021), e2023301118.\n[20] Arash Dargahi Nobari, Negar Reshadatmand, and Mahmood Neshati. 2017. Anal-\nysis of Telegram, an instant messaging service. In Proceedings of the 2017 ACM\non Conf. on Information and Knowledge Management . 2035\u20132038.\n[21] Gabriele Etta, Matteo Cinelli, Alessandro Galeazzi, Carlo Michele Valensise,\nWalter Quattrociocchi, and Mauro Conti. 2022. Comparing the Impact of Social\nMedia Regulations on News Consumption. IEEE Transactions on Computational\nSocial Systems (2022), 1\u201311. https://doi.org/10.1109/TCSS.2022.3171391\n[22] Gabriele Etta, Alessandro Galeazzi, Jamie Ray Hutchings, Connor Stirling\nJames Smith, Mauro Conti, Walter Quattrociocchi, and Giulio Valentino Dalla\nRiva. 2022. COVID-19 infodemic on Facebook and containment measures in Italy,\nUnited Kingdom and New Zealand. PloS one 17, 5 (2022), e0267022.\n[23] Your Europe. November 19, 2024. Data protection under GDPR.\nhttps://europa.eu/youreurope/business/dealing-with-customers/data-\nprotection/data-protection-gdpr/index_en.htm.\n[24] European Organization For Nuclear Research and OpenAIRE. 2013. Zenodo.\nhttps://doi.org/10.25495/7GXK-RD71\n[25] Sayan Ghosh, Mahantesh Halappanavar, Antonino Tumeo, Ananth Kalyanara-\nman, Hao Lu, Daniel Chavarria-Miranda, Arif Khan, and Assefaw Gebremedhin.\n2018. Distributed louvain algorithm for graph community detection. In 2018\nIEEE international parallel and distributed processing symposium (IPDPS) . IEEE,\n885\u2013895.\n[26] Aric Hagberg, Pieter Swart, and Daniel S Chult. 2008. Exploring network structure,\ndynamics, and function using NetworkX . Technical Report. Los Alamos National\nLab.(LANL), Los Alamos, NM (United States).\n[27] Ali Hashemi and Mohammad Ali Zare Chahooki. 2019. Telegram group quality\nmeasurement by user behavior analysis. Social Network Analysis and Mining 9, 1\n(2019), 1\u201312.\n[28] Taylor Hatmaker. 2021. Telegram blocks \u2018dozens\u2019 of hardcore hate channels\nthreatening violence. https://techcrunch.com/2021/01/13/telegram-channels-\nbanned-violent-threats-capitol/.\n[29] Rebecca Heilweil. Jan. 2021. How Trump\u2019s internet built and broadcast the Capitol\ninsurrection. https://www.vox.com/recode/22221285/trump-online-capitol-riot-\nfar-right-parler-twitter-facebook.\n[30] Thomas Hofmann. 2001. Unsupervised learning by probabilistic latent semantic\nanalysis. Machine learning 42, 1 (2001), 177\u2013196.\n[31] Matthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language under-\nstanding with Bloom embeddings, convolutional neural networks and incremen-\ntal parsing. (2017). To appear.\n[32] Mohamad Hoseini, Philipe Melo, Fabricio Benevenuto, Anja Feldmann, and\nSavvas Zannettou. 2023. On the globalization of the QAnon conspiracy theory\nthrough Telegram. In Proceedings of the 15th ACM Web Science Conf. 2023 . 75\u201385.\n[33] Vincenzo Imperati, Massimo La Morgia, Alessandro Mei, Alberto Maria Mongar-\ndini, and Francesco Sassi. 2025. The Conspiracy Money Machine: Uncovering\nTelegram\u2019s Conspiracy Channels and their Profit Model. In 34th USENIX Security\nSymp. (USENIX Security 25) .\n[34] Asal Jalilvand and Mahmood Neshati. 2020. Channel retrieval: finding relevant\nbroadcasters on Telegram. Social Network Analysis and Mining 10, 1 (2020), 1\u201316.\n[35] Alex Kigerl. 2020. Behind the Scenes of the Underworld: Hierarchical Clustering\nof Two Leaked Carding Forum Databases. Social Science Computer Review (2020),\n0894439320924735.\n[36] Rachel Kraus. October 29, 2020. Telegram\u2019s massive revenge porn problem has\nmade these women\u2019s lives hell. https://mashable.com/article/nudes-revenge-\nporn-crime-telegram.\n[37] Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2024. TG-\nDataset. https://zenodo.org/records/7640712.[38] Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2024. TG-\nDataset repository. https://github.com/SystemsLab-Sapienza/TGDataset.\n[39] Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, and Jie Wu.\n2023. It\u2019sa Trap! Detection and Analysis of Fake Channels on Telegram. In 2023\nIEEE International Conf. on Web Services (ICWS) . IEEE, 97\u2013104.\n[40] Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, and Jie Wu.\n2024. Pretending to be a VIP! Characterization and Detection of Fake and Clone\nChannels on Telegram. ACM Transactions on the Web (2024). https://doi.org/10.\n1145/3705014\n[41] Massimo La Morgia, Alessandro Mei, Francesco Sassi, and Julinda Stefa. 2020.\nPump and Dumps in the Bitcoin Era: Real Time Detection of Cryptocurrency Mar-\nket Manipulations. In 2020 29th International Conf. on Computer Communications\nand Networks (ICCCN) . IEEE, 1\u20139.\n[42] Dymples Leong. May 2020. Telegram, the powerful COVID-19 choice of\ncommunications by many governments. https://www.channelnewsasia.com/\ncommentary/coronavirus-covid-19-government-telegram-whatsapp-fake-\nnews-info-936061.\n[43] Hannah Gelbart Maria Korenyuk Lucy Swinnen, Jack Goodman and Juliana\nGragnani. 16 February 2022. Telegram: Where women\u2019s nudes are shared without\nconsent. Telegram:Wherewomen\u2019snudesaresharedwithoutconsent.\n[44] Andy Maxwell. October 10, 2022. Telegram Piracy: Police Target 545 Channels\n& Eight Suspected Admins. https://torrentfreak.com/telegram-piracy-police-\ntarget-545-channels-eight-suspected-admins-221010/.\n[45] MBFC. 2023. Media Bias Fact Check. https://mediabiasfactcheck.com/.\n[46] Jemima McEvoy. Jan. 2021. Capitol Attack Was Planned Openly Online For\nWeeks\u2014Police Still Weren\u2019t Ready. https://www.forbes.com/sites/jemimamcevoy/\n2021/01/07/capitol-attack-was-planned-openly-online-for-weeks-police-still-\nwerent-ready/?sh=1b06696376e2.\n[47] David Mimno, Hanna Wallach, Edmund Talley, Miriam Leenders, and Andrew\nMcCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings\nof the 2011 conference on empirical methods in natural language processing . 262\u2013\n272.\n[48] MONGODB. November 19, 2024. MongoDB. https://www.mongodb.com/.\n[49] Massimo La Morgia, Alessandro Mei, Francesco Sassi, and Julinda Stefa. 2021. The\ndoge of wall street: Analysis and detection of pump and dump cryptocurrency\nmanipulations. ACM Transactions on Internet Technology (TOIT) (2021).\n[50] Lynnette Hui Xian Ng and Loke Jia Yuan. 2020. Is this pofma? Analysing public\nopinion and misinformation in a COVID-19 Telegram group chat. arXiv preprint\narXiv:2010.10113 (2020).\n[51] NLTK Project. 2023. NLTK stopwords. https://www.nltk.org/search.html?q=\nstopwords&check_keywords=yes&area=default.\n[52] Jack Ricle. Aug. 2022. Scammers in telegram and how to report. https://www.\ntelegramadviser.com/scammers-in-telegram-and-how-to-report/.\n[53] Hinrich Sch\u00fctze. 1998. Automatic word sense discrimination. Computational\nlinguistics 24, 1 (1998), 97\u2013123.\n[54] Nakatani Shuyo. 2010. Language Detection Library for Java. http://code.google.\ncom/p/language-detection/\n[55] Manish Singh. November 30, 2022. Telegram shares users\u2019 data in copyright\nviolation lawsuit. https://techcrunch.com/2022/11/29/telegram-shares-data-of-\nusers-accused-of-copyright-violation-following-court-order/.\n[56] Joe Sommerlad. March 2021. Sabmyk Network: Founder of bizarre\nnew religion targeting QAnon believers \u2018unmasked\u2019 by Hope Not Hate.\nhttps://www.independent.co.uk/news/world/europe/sabmyk-network-qanon-\nconspiracy-theories-b1820639.html.\n[57] Telegram. November 19, 2024. Telegram API Terms of Service. https://core.\ntelegram.org/api/terms.\n[58] Telegram. November 19, 2024. Telegram Terms Of Service. https://telegram.org/\ntos/.\n[59] GDPR TEXT. November 19, 2024. Article 85 GDPR. Processing and freedom of\nexpression and information. https://gdpr-text.com/read/article-85/.\n[60] Vincent A Traag, Ludo Waltman, and Nees Jan Van Eck. 2019. From Louvain to\nLeiden: guaranteeing well-connected communities. Scientific reports 9, 1 (2019),\n1\u201312.\n[61] Aleksandra Urman and Stefan Katz. 2022. What they do in the shadows: examin-\ning the far-right networks on Telegram. Information, communication & society\n25, 7 (2022), 904\u2013923.\n[62] Alper Kursat Uysal and Serkan Gunal. 2014. The impact of preprocessing on text\nclassification. Information Processing & Management 50, 1 (2014), 104\u2013112.\n[63] Janith Weerasinghe, Bailey Flanigan, Aviel Stein, Damon McCoy, and Rachel\nGreenstadt. 2020. The pod people: Understanding manipulation of social media\npopularity via reciprocity abuse. In Proceedings of The Web Conf. 2020 . 1874\u20131884.\n[64] Mark D Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Apple-\nton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino\nda Silva Santos, Philip E Bourne, et al .2016. The FAIR Guiding Principles for\nscientific data management and stewardship. Scientific data 3, 1 (2016), 1\u20139.\n[65] Jiahua Xu and Benjamin Livshits. 2019. The anatomy of a cryptocurrency pump-\nand-dump scheme. In 28th{USENIX}Security Symp. ({USENIX}Security 19) .\n1609\u20131625.\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n[66] Ahmet S Yayla and Anne Speckhard. 2017. Telegram: The mighty application\nthat ISIS loves. International Center for the Study of Violent Extremism (2017).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tgdataset: a collection of over one hundred thousand telegram channels", "author": ["M La Morgia", "A Mei", "AM Mongardini"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2303.05345", "abstract": "Telegram is one of the most popular instant messaging apps in today's digital age. In addition  to providing a private messaging service, Telegram, with its channels, represents a valid"}, "filled": false, "gsrank": 759, "pub_url": "https://arxiv.org/abs/2303.05345", "author_id": ["G-P8k7MAAAAJ", "eCiUVHcAAAAJ", "7XqiiHUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:QqdimitGKJMJ:scholar.google.com/&output=cite&scirp=758&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D750%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=QqdimitGKJMJ&ei=jrWsaMr-H8DZieoPqdqh8QU&json=", "num_citations": 15, "citedby_url": "/scholar?cites=10603802475731527490&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:QqdimitGKJMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2303.05345"}}]