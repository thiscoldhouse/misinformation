[{"title": "Gender and Prestige Bias in Coronavirus News Reporting", "year": "2023", "pdf_data": "Gender and Prestige Bias in Coronavirus News Reporting\nRebecca Dorn\nUSC Information Science Institute\nMarina del Rey, CA, USA\nrdorn@usc.eduYiwen Ma\nUSC Information Science Institute\nMarina del Rey, CA, USA\nyiwenma@usc.edu\nFred Morstatter\nUSC Information Science Institute\nMarina del Rey, CA, USA\nfredmors@isi.eduKristina Lerman\nUSC Information Science Institute\nMarina del Rey, CA, USA\nlerman@isi.edu\nABSTRACT\nJournalists play a vital role in surfacing issues of societal impor-\ntance, but their choices of what to highlight and who to interview\nare influenced by societal biases. In this work, we use natural lan-\nguage processing tools to measure these biases in a large corpus of\nnews articles about the Covid-19 pandemic. Specifically, we identify\nwhen experts are quoted in news and extract their names and insti-\ntutional affiliations. We enrich the data by classifying each expert\u2019s\ngender, the type of organization they belong to, and for academic\ninstitutions, their ranking. Our analysis reveals disparities in the\nrepresentation of experts in news. We find a substantial gender gap,\nwhere men are quoted three times more than women. The gender\ngap varies by partisanship of the news source, with conservative\nmedia exhibiting greater gender bias. We also identify academic\nprestige bias, where journalists turn to experts from highly-ranked\nacademic institutions more than experts from less prestigious insti-\ntutions, even if the latter group has more public health expertise.\nLiberal news sources exhibit slightly more prestige bias than con-\nservative sources. Equality of representation is essential to enable\nvoices from all groups to be heard. By auditing bias, our methods\nhelp identify blind spots in news coverage.\nCCS CONCEPTS\nInformation systems \u2192Data mining, Social networks; Computing\nmethodologies\u2192Natural language processing\nKEYWORDS\ngender bias; prestige bias; ideological bias; news reporting; expert\nsources; named entity recognition; dependency parsing\n1 INTRODUCTION\nIn times of crisis people turn to news media for information and\nto make sense of the world; journalists, in turn, seek out experts\nand opinion leaders to interview and then help communicate their\nknowledge to the public. Mass media does not simply convey in-\nformation to the public but also shapes what is seen and what is\ndeemed important [ 12]. The interplay between mass media and the\npublic creates a cycle that amplifies attention to concerns and influ-\nences public policy. Given the media\u2019s role in identifying issues of\nsocietal importance, it is therefore critical that it equitably reflects\nthe interests of all stakeholders.\nRepresentation of groups and individual social identity in the\nmedia is one of the fundamental questions of equity. Does the media\nadequately represent issues that are important to women, ethnicminorities, the elderly, and the disadvantaged? Does it capture the\nlived experience of these groups, the challenges they face? Or does\nit focus on the concerns of the privileged few? One mechanism\nfor improving equity is to ensure that the pool of journalists and\nreporters reflects society\u2019s diversity. However, journalists are pre-\ndominantly men and often choose to interview subjects whose\ngender identity matches their own [11].\nAnother mechanism to improve equity is to diversify the pool\nof subjects that journalists pay attention to. For example, by talk-\ning to women, journalists will surface their views and concerns.\nThis is important, because women typically bear a larger share of\ncare responsibilities, and their concerns may bring up issues with\nchildcare, for instance, that may not be visible to men. Moreover, if\njournalists solely focus on sources from the same few prestigious\nacademic institutions, they lose the geographic and socio-economic\ndiversity that comes from interviewing experts from a range of\ninstitutions. This may introduce additional blind spots in news\ncoverage.\nAuditing gender representation in the news\u2014or the representa-\ntion of other identities\u2014has proven difficult due to the challenges\nof extracting representations from the text of the news stories. Pre-\nvious studies have identified gender bias in news reporting [ 23];\nhowever, they have generally relied on manually curated data or\nwere limited to certain media types, and thus do not scale to the\nsize of the media ecosystem. Addressing the question of bias in the\nnews media at scale calls for automated methods.In this study we\nuse natural language processing (NLP) methods to automate media\nanalysis, which enables us to scale our bias audit of news across\nlonger time periods and across more media sources. We focus on\ngender and academic prestige bias in the coverage of the Covid-19\npandemic. When the novel coronavirus emerged, little was known\nabout the severity of the disease it caused, what mitigations were\neffective and their benefits and costs. As researchers learned more\nabout the disease, public officials used these findings as a basis for\npolicy recommendations. Journalist sought out experts from the\nresearch community and government agencies to communicate the\nresearch findings, policy recommendations, and their trade-offs to\nthe public. We analyze thousands of news stories from six popular\nmedia sources along the breadth of US political spectrum to identify\nthe experts the journalists turned to. We analyze three left leaning\nnews sources and three right leaning sources to enable analysis by\npartisan bias and accommodate a variety of linguistic styles.\nOur analysis reveals a gender gap in news coverage where\nwomen appear much less frequently among the experts quotedarXiv:2301.11994v1  [cs.SI]  27 Jan 2023\nby journalists than men. The gender gap varies by political ideol-\nogy of the news source, with liberal media coming closer to gender\nparity than conservative media. In addition to gender, we look at\nthe institutional affiliations of the experts and classify their aca-\ndemic prestige. We identify prestige bias, in which experts from the\nhigher-ranked academic institutions are quoted more frequently\nthan experts with less prestigious affiliations. We find that prestige\nbias varies slightly by ideology of the reporting source.\nOne possible explanation for the observed bias is that women\nare a minority in science and medicine. However, women make up\nthe majority of doctoral students and junior faculty in public health\nand biomedical sciences [ 19], both of which are fields relevant to\nthe Covid-19 pandemic. Graduate-level public health degrees have\nbeen awarded to more women than men since 1979, with 73% of\nsuch degrees awarded to women in 2017 [ 9]. Therefore, the gender\ndisparity we observe is likely not due to a shortage of experts but\ndue to individual biases of reporters and media sources.\nOur analysis of the gender and prestige of experts quoted in the\nnews during the Covid-19 pandemic answers the following research\nquestions:\n\u2022Gender Bias: Are women underrepresented among experts\nwhom journalists turn to for information about the pan-\ndemic?\n\u2022Ideological Gender Bias: Does the gender gap vary by\nideological leaning of news source?\n\u2022Prestige Bias: Is there media preference for experts from\nhighly ranked institutions?\n\u2022Ideological Prestige Bias: Does the prestige gap change\nwith political leaning of news outlet?\n2 RELATED WORK\nThere has been work analyzing the gender composition of experts\nin television news. Scott et al. discovered that from September 25\nto October 6, 2006 and May 14 to May 25, 2007, 14.7% of people\nfeatured in PBS NewsHour were women [ 20]. The authors also\nfound that 13.7% of experts had academic affiliations, 4.3% from\nthink tanks and 42.9% with governmental affiliations.\nThe role of gender in international news media use of non-\ncoronavirus specific experts has been documented. Niemi et al.\nfound that less than 30% of experts interviewed in Finnish news\njournalism are women [ 15]. Lidia Ma\u00f1oso Pacheco found a high\ncorrelation between journalist and subject gender in 68 British\nand English newspaper articles [ 11]. Kitzinger et al. analyzed 51\nin-depth profiles of men and women scientists and found that 5\nmen are used for every 1 woman scientist [8].\nOnly manual analyses of American Coronavirus news experts\nexist. Fletcher et al. [ 3] reviewed a total of 4,463 articles from 9 U.S.\nnews sources dating April 1, 2020 to April 15, 2020 and found 35.9%\nof the 2,297 experts were women. In a special report from Luba\nKassova that looked at the frequency of men and women in 2,100\nquotes between March 1, 2020 and April 15, 2020, men were quoted\nthree times as much as women [ 6]. Kassova additionally found that\nwomen are less likely to be protagonists in news stories and more\nlikely to provide subjective views over expertise.\nLarge scale analysis of North American news experts exist, though\nnot specific to Coronavirus. Asr. et al. introduced a tool for largescale gender analysis in news quotes in The Gender Gap Tracker [ 2],\nwhich takes a sentence and returns people quoted and mentioned\nwith their inferred gender identities. Methods of extraction include\nsyntactic, heuristic and floating quote approaches. The software\nis illustrated on seven Canadian news outlets, where the authors\nfound that men are represented three times as much as women\nfrom October 2018 to September 2020.\nLarge-scale tools have been used to analyze the difference in how\nmen and women are featured in the news. LDA topic modelling is\nperformed on two years worth of American and Canadian news\narticles by Rao et al. [ 17]. Persons quoted and their genders are\ngathered using The Gender Gap Tracker. Contrary to our results, the\nauthors found that women are more represented in articles related\nto healthcare. An analysis of gender, fame and sentiment is done\nby Shor et al. [ 22]. The dataset used combines 14 million persons\nmentioned throughout 1,323 news outlets with a manual analysis of\nselect Wikipedia pages. The authors looked at sentiment scores for\nadjectives used with each person, and found that as women become\nmore famous the media attention recieved becomes increasingly\nnegative. Separately, Shor et al. analyzed gender and public interest\nwhile controlling for occupation and age [ 21]. The authors looked\nat over 20,000 persons from over 2,000 news sources. They found\nthat when men and women have similar occupations and ages,\nwomen obtain higher public interest but less media coverage.\nOne of the most frequently observed forms of social learning is\nwhere people observe and mimic seemingly competent and there-\nfore admirable individuals [ 5]. Jimenez et al. explained how first\norder cues of prestige (initially observable traits) are used to assume\nprestige when quality information is lacking, though these cues\nmay be wrong and deceptive [ 5]. Additionally, upward mobility in\nacademia is limited. In a survey of n = 348 universities, 20% of fac-\nulty positions are inhabited by 8 universities [ 25]. The same survey\nfound that only 5% to 23% of faculty members from United States\nuniversities hold doctorates from less prestigious institutions, and\nthat 64% of Universities have no departments listed as top 10 [25].\n3 METHODS\n3.1 Data\nThe AYLIEN Coronavirus Dataset consists of 1,673,353 news arti-\ncles related to the Coronavirus pandemic collected from over 440\ninternational news sources. This data is aggregated, analyzed, and\nenriched by AYLIEN using AYLIEN\u2019s News Intelligence Platform1.\nWe use the article attributes raw article text, article title, news\nsource name, and publication date and time. We analyze AYLIEN\nCoronavirus related news articles from six US-based news sources:\nHuffington Post (HUFF), Cable News Network (CNN), The New\nYork Times (NYT), The New York Post (NYP), Fox News (FOX),\nand Breitbart News Network (BREIT) between January 6, 2020,\nand July 31, 2020. These six news outlets are chosen because they\ncollectively exemplify an ideological spectrum in news reporting\nwhile all having some partisan bias. This allows us to separate news\noutlets into two distinct groups. Additionally, having 6 news outlets\nensures we cover a variety of linguistic style. This subset totals\n66,368 articles: 9,897 articles from the New York Times, 17,765 from\n1https://aylien.com/resources/datasets/coronavirus-dataset\nCNN, 19,911 from Fox News, 7,609 from Breitbart, 13,391 from New\nYork Post and 6,625 from the Huffington Post.\n3.2 Expert Quote Extraction\nFig. 1 shows an example of how journalists quote experts using\nthree different sentence structures. The components of interest are\nreported speech, reported verb, person and organization. Reported\nspeech (RSPEECH) directly quotes or indirectly reconstructs the\nwords of the speaker. A reporting verb (RVERB) is used to introduce\nor conclude reported speech (e.g. \u201creport\u201d, \u201cacclaim\u201d, \u201ctold\u201d). The\nperson is the speaker being quoted. An organization is the institu-\ntion associated with the speaker. We consider expert quotes to be\nany permutation of these components. We find sentences quoting\nexperts by taking the union of two approaches:\n3.2.1 Named Entity Recognition (NER). The three most common\nreporting verbs are \u201csaid\u201d, \u201csay\u201d and \u201csays\u201d. The most common\npattern quoting experts is:\n\u201c[\ud835\udc45\ud835\udc46\ud835\udc43\ud835\udc38\ud835\udc38\ud835\udc36\ud835\udc3b],\" (\u201csaid\"|\u201csay\"|\u201csays\") [PERSON]\nWhere|denotes logical orand [PERSON] denotes speaker. This\npattern is captured using the following regular expression:\n\u201c\ud835\udc60([a-zA-z0-9?\u2019,. \ud835\udc60()])*\ud835\udc60,\"(said|say|says)([a\u2212zA\u2212z0\u22129?\u2019,\ud835\udc60\n()])*\nThe NLP library SpaCy offers an NER library pretrained on web text\nwith entity labels including person, organization, date and location\n[4]. We use SpaCy\u2019s NER on sentences following this pattern and\nlook for PERSON entities listed outside of quotation marks.\n3.2.2 The Gender Gap Tracker. The second method we use to\nfind speakers is that of The Gender Gap Tracker Project [ 2]. The\nsyntactic method from The Gender Gap Tracker identifies quotes\nfollowing a clausal complement structure, where a dependent verb\nis featured with an internal subject. Sentences following this struc-\nture are only kept if they feature one of 262 reporting verbs. The\nsecond Gender Gap Tracker method we utilize identifies reported\nspeech introduced directly before or after the reporting verb \u201cac-\ncording to.\u201d Due to the difficulty in finding affiliated organizations,\nwe choose to omit the floating quote method which finds sentences\nwhere reported speech takes a full sentence and the speaker is\nintroduced elsewhere.\nWhen an expert is quoted in a news article, the journalist typi-\ncally introduces the expert, specifying their position and affiliation.\nTo help focus our data collection only on expert speakers, we require\nspeakers to be present alongside an organizational affiliation. On\nall sentences collected, we run NER and retain only those sentences\nwhere NER identifies an organization (ORG entity).\n3.3 Classifying Gender\nThe Python library gender-guesser implements a gender prediction\nprogram built on a database of 45,376 names with each name\u2019s\nmost likely gender identity [ 1]. The possible gender predictions\nfor a single person are \u201cmale\", \u201cfemale\", \u201candy\" (androgynous) and\n\u201cunknown\". For each person quoted, we run gender-guesser on the\nfirst string before a space (i.e., first name) to obtain that name\u2019s\nmost common gender association [18].\nThe gender labels include \u201cmale\" and \u201cfemale\" though would be\nmore accurately described as man/masculine and woman/feminine.We acknowledge that gender is non-binary and not captured by\na person\u2019s first name. Classifying by common gender affiliation\nwith names captures reader perception of gender, not the expert\nspeakers\u2019 actual gender identification. The discussion section fur-\nther elaborates on the inability of a single androgynous category\nto adequately capture non-binary non-cisgender gender identities.\n3.4 Classifying Organization Prestige\nDuring the Covid-19 pandemic, scientists, epidemiologists, and pub-\nlic health experts from a variety of different organizations worked\nto define our understanding of the disease and to define public\npolicy. These experts came from academic institutions (e.g., Brown\nUniversity), federal bodies (e.g., the Centers for Disease Control\nand Prevention), and a variety of think tanks (e.g., the Hoover In-\nstitution). Journalists turned to these experts for information and\nguidance to share with the public.\nWe use fuzzy string matching, a mechanism that generates sim-\nilarity scores between two strings, to determine whether organi-\nzation affiliations reference academic institutions, federal bodies,\nor think tanks. For example, fuzzy string matching would find that\n\u201cThe University of Maryland - College Park\" matches to \u201cThe Univer-\nsity of Maryland\" with a score of 90. Journalists typically introduce\norganizations with their full names, thus we do not accomodate for\norganization abbreviations.\n3.4.1 Academic Institutions. We use Times Higher Educations\u2019\n2015 World University Rankings2. This list gives 400 University\nnames as well as their ranking. Rankings are determined by fac-\ntors including teaching, research, citations, industry income, and\ninternational outlook.\n3.4.2 Federal Bodies. We compile a list of Federal Bodies by web\nscraping the U.S. Government Services and Information\u2019s index of\nFederal Departments and Agencies3. This list includes only federal\nagencies therefore nothing at the state level.\n3.4.3 Think Tanks. One of the most popular think tank defini-\ntions is by McGann and Weaver: \u201cnon-governmental, not-for-profit\nresearch organisations with substantial organisational autonomy\nfrom government and from societal interests such as firms, interest\ngroups, and political parties\u201d [ 16,26]. Think tanks frequently focus\non public policy. We use the open source database On Think Tanks4,\nwhich includes over 3,200 global think tanks and provides fields\nincluding region, topic, website and office address.\nFor each sentence, we measure similarity between NER-identified\norganization and organization names listed in these databases. We\nmanually review a sample of NER-extracted organizations, the or-\nganization name most closely matching and the distance metric\ncalculated for the two strings. For all three databases, we consider\na match if the similarity score is greater than or equal to 90. To\nminimize noise, organizations consisting of two or fewer characters\nin the name are ignored. We sample 25 random organizations of\ntwo or fewer characters to ensure minimal impact. We find that\n2https://www.timeshighereducation.com/world-university-rankings/2016/world-\nranking/methodology\n3https://www.usa.gov/federal-agencies\n4https://onthinktanks.org/open-think-tank-directory/\nFigure 1: Examples of Expert Quotes. Examples capture three varieties of quote structure. RSPEECH (Reported Speech) is the portion of the quote\ncontaining an exact quote or reconstruction of what the speaker previously said. RVERB (Reporting Verb) refers to the verb introducing or concluding reported\nspeech (\"say\", \"said\", \"explains\", etc.). PERSON refers to the speaker of the (reported) quote. ORG refers to the organization affiliated with the speaker. Quotes\nare considered expert quotes if it has the presence of RSPEECH, RVERB, PERSON and ORG. We consider a sentence as containing both RSPEECH and RVERB\nif it contains one of 262 Reporting Verbs, as a Reporting Verb implies the presence of Reported Speech. We use Named Entity Recognition (NER) to determine\nwhether a sentence features a PERSON and ORG.\nthe most common two-character string is \u201c\u201ds\", followed closely by\nstrings \u201c\u2019m\" and \u201cAP\".\n4 RESULTS\nWe extract 89,130 expert sources (pairs of speakers and their af-\nfiliated organizations): 19,137 pairs from HUFF, 17,156 from CNN,\n18,828 from NYT, 4,129 from NYP, 22,226 from FOX and 7,654 from\nBREIT. The Gender Gap Tracker accounts for 26.7% of these ex-\ntractions, and Named Entity Recognition-based for the rest. Our\nmethods improve the number of extractions by 65,263 pairs. The\nscale increase from adding our method helps promote accuracy and\nefficiency in studies of inequality.\nFor precision evaluation, we run our method on 100 randomly\nsampled articles and manually annotate each extraction. Extractions\nare labeled correct if they contain RSPEECH from a PERSON with\nan ORG affiliation. The precision from this sample is 64.7%. The\nmethod most commonly fails for instances where the ORG is the\nnews outlet rather than a professional affiliation. For example: \"The\ngovernment took a very important step, but they waited too long\nfor this decision, \u201d Dr. Jose Luis Vargas Segura, a pulmonologist, told\nFox News. \u2019 finding Fox News as the affiliated ORG. We also sample\n100 academic extractions, labeling whether the instance contains\nRSPEECH, a PERSON and their affiliated university. The accuracy\nfor this is much higher at 87%.\n4.1 Gender Bias\n36.8% of extracted speakers have no identifiable gender in gender-\nguesser. To reduce unknown genders, we take the union of each\nnews outlet\u2019s 25 most frequently mentioned people with unknown\ngender and manually label the gender where the person is recog-\nnizable. Most of the names are easily identifiable public figures\n(e.g., \u201cTrump\u201d, \"Biden\", and \u201cCuomo\u201d). After this procedure, 26.4%\nof extracted sentences have no persons with an identifiable gender.\nThe majority of androgynous names are Asian names popu-\nlar both as first and last names. We look at the 25 most frequentnames with androgynous labels and manually labeled their gender,\nif known. We find that the androgynous category captures a unique\nsubset of non-gender-identifying more than androgynous names,\nso we merge androgynous and unknown gender categories.\nFigure 2: Gender bias in news. Percentage of men and women in all\nidentified expert quotes. We show the composition in total mentions (speak-\ners counted each time they are referenced) and unique mentions (speakers\ncounted once over all mentions). Unique mentions are determined by check-\ning whether each expert\u2019s name has a string similarity (via fuzzy string\nmatching) score of 90 or higher to previously mentioned experts. Men are\noverrepresented in both total and unique mentions. The stronger affinity\ntowards men in total mentions demonstrates that journalists quote the same\nmen repeatedly.\nFigure 2 breaks down experts quoted in the news by gender. The\n26.4% of instances with unknown gender are omitted to better grasp\nthe immediate disparity between men and women. The left plot\nrepresents the total mentions of all individuals by gender: women\nrepresent 24% of all mentions of experts in the news. To identify\nunique experts, we iterate through all experts while maintaining a\nlist of previously quoted people. For each name, we check whether\nthe person quoted fuzzy string matches to anyone previously quoted\nwith a score of 90 or more. The left pie chart in Fig. 2 shows the\ngender breakdown of unique experts, where experts are counted\nonce over all mentions. Women\u2019s representation improves with\nunique mentions at 31%. However, this still shows that women\nare under-represented in the news, considering that the fields of\nepidemiology, bio-medicine, and public health\u2014all relevant to the\npandemic\u2014have achieved gender parity (or better) [ 9,19]. Instead,\nthe news media turns to the same group of male experts. The\nover-representation of men reinforces the idea that science requires\ntraditionally masculine traits and denies fair coverage (and therefore\ncareer advancement opportunities) to women.\nSentences quoting men have on average 240 characters per sen-\ntence and those quoting women have an average length of 236\ncharacters. This difference is found significant using a two sided\nt-test (p < 0.01). We also observe that 4.6% of sentences with expert\nwomen also feature an expert man, while only 1.3% of sentences\nwith an expert man appear with an expert woman.\nFigure 3: Gender Composition by Organization. Gender distribution\nseparated by type of organization. Quotes matched to organization types\nby fuzzy string matching to databases of organization names (Times Higher\nEducations\u2019 2015 World University Rankings, Index of Federal Departments\nand Agencies, and On Think Tanks). Error bars determined through boot-\nstrapping 1,000 times. All organization types exhibit gender bias, with\nfederal bodies containing the lowest proportion of women.\n4.2 Ideological Bias\nOut of all our extractions, 27.6% have an organization matching\nto our academic, federal and think tank databases. Analysis of the\norganizational breakdown reveals journalists are most likely to\nreach out to experts affiliated with federal agencies (60.5%), then\nacademic institutions (21.6%), and think tanks (17.9%). One possible\nexplanation is that federal agencies make recommendations for\npandemic safety procedures, which are then communicated to the\npublic by reporters.\nFig. 3 shows gender composition by organization type. The bars\nshow average gender representation over 1,000 bootstrapped sam-\nples of the data set. The category of unknown gender is included.\nExperts associated with federal bodies (e.g., CDC, FDA) exhibit the\nstrongest disparity by gender with the lowest percentage of women.\nExperts from academic institutions manifest less gender disparity,\nwith the highest percentage of women. The lowest percentage of\nmen occurs for experts affiliated with think tanks, which could be\ndue to the high number of persons with \u201cunknown\" gender.\nFig. 4 shows how each news outlet distributes attention over\nexperts from academic institutions, federal bodies and think tanks.\nFigure 4: Preferred Organization Type for Expertise. Distribution of\norganization types affiliated with news sources in expert quotes. Sources\nare listed from top to bottom by political leaning reported in Media Bias\nFact Check. Across the board, Federal Bodies are the most common type\nof expertise, though The New York Times has lowest proportion. Breitbart\nNews is the only news outlet with higher use of think tanks than academic\ninstitutions.\nQuotes with unknown organization types are not included. We\nobserve that federal bodies are always the most common sources\nof expertise. NYT quotes federal experts 40.6%, and all other out-\nlets utilize federal affiliated experts at least 60.8%. Additionally, we\nobserve that right-leaning outlets typically turn to experts from fed-\neral agencies more than left-leaning outlets. Academic institutions\nare the second most common organization type for experts after\nfederal bodies, except for BREIT and FOX which utilizes academic\nexperts 9.9% and 14%, respectively.\nFigure 5: Ideology and Gender Bias. Ratio of Women to Men experts\nquoted by a news source. Smaller ratios signal under-representation of\nwomen. Error bars included are from bootstrapping 1000 times. Outlets\nare ordered left to right by political ideology. Left leaning outlets have the\ngreatest ratio of women cited. The difference in median ratio of news outlets\nis found significant by the Kruskal-Wallis Test (p <0.01).\nFig. 5 shows gender bias across the ideological spectrum of news\noutlets, where HUFF, CNN and NYT are classified as liberal (left-\nleaning) sources, and NYP, FOX, and BREIT as conservative (right-\nleaning), as reported in Media Bias Fact Check5. The effect of news\n5https://www.mediabiasfactcheck.com\noutlet ideology on gender representation is measured by the ratio\nof the number of women quoted to the number of men. A ratio\nof 1.0 signifies equal representation of men and women, smaller\nration signal over-representation of men.\nAll news sources exhibit over-representation of men with ratios\nat most .387. BREIT has the largest gender disparity with a ratio\nof 0.264, and NYT has the least gender disparity with the share\nof women experts at 0.387. We use the Kruskal-Wallis H-Test to\ncompare medians for the share of women experts for left-leaning\nand right-leaning outlets (pictured in blue and red, respectively, in\nFig. 5). The Kruskal-Wallis test reports a statistic of 8.547 (p <0.01)\nsignifying a statistically significant moderate effect. We conclude\nleft-leaning news outlets exhibit less gender disparity than the\nright-leaning outlets.\n4.3 Prestige Bias\nFigure 6: Prestige Bias. Number of mentions of an academic institution\nin the news as a function of its ranking (for institutions ranked by the Times\nHigher Educations\u2019 World Rankings) shows journalists pay more attention\nto higher-ranking institutions. Lower rankings signal higher prestige.\nWe now take a closer look at experts from academic institu-\ntions. Fig. 6 shows the number of times an academic institution is\nmentioned in the news as a function of its placement in the Times\nHigher Educations\u2019 World Rankings. Spearman correlation mea-\nsures monotonicity between two variables and scores between -1\nand 1 (0 means no correlation). The scatter plot shows a downward\ntrend, with a Spearman coefficient of -0.379 (p <0.01), indicat-\ning more prestigious (higher-ranked) institutions generally receive\nmore mentions in the news than less prestigious (lower-ranked)\ninstitutions.\nWe measure prestige bias using the Gini coefficient. Gini is a\npopular statistical measure of inequality, here attention to academic\ninstitutions. A small Gini coefficient means attention (number of\nmentions of an institution) is equally distributed across universi-\nties of any rank, while a Gini coefficient close to one means one\nuniversity gets all the attention while the rest receive no mentions.\nThe Gini coefficient of mentions of institutions in our data is 0.568,\nsuggesting existence of prestige bias: journalists prefer to turn to\nexperts from the same high-ranking institutions again and again.\nFigure 7: Public Health Ranking and Prestige. Number of academic\ninstitution mentions by public health ranking. In top 48 public health insti-\ntutions, only a handful with high prestige are heavily utilized by journalists.\nBut what if news outlets are turning to prestige within a domain\nrelevant to the pandemic, like public health? For this case, we\nrank institutions by prestige in the field of public health using the\nUS News\u2019 ranking of US schools of public health6in Figure 7. If\njournalists were seeking out public health experts, we would expect\nthem to pay more attention to experts from these 48 institutions\nwith higher-ranked schools of public health, resulting in a much\nlower Gini coefficient. However, the Gini coefficient drops to 0.537,\nsuggesting that prestige bias is driven by extraneous factors such as\nthe institution\u2019s \u201cbrand name\u201d rather than expertise in the relevant\nfield of public health.\nFigure 8: Ideology and Prestige Bias. Boxplot bins the mentions of\nacademic institutions by their rankings, and shows the distributions of\nthe share of mentions of those institutions made by left- and right-leaning\nnews sources. Yellow dots represent group means. Left-leaning news outlets\ndisplay stronger preference for experts from prestigious institutions (top-50\nranked universities).\n6https://www.usnews.com/best-graduate-schools/top-health-schools/public-health-\nrankings\n4.3.1 Ideology and Prestige Bias. We analyze overlap between\nnews outlet ideological leaning and tendency to mention higher\nranked universities. The boxplot in Fig. 8 shows the distribution\nof academic expert mentions made by the left-leaning and right-\nleaning news outlets. The universities which experts are affiliated\nwith are binned by school rank. The boxplot shows the distribution\nover the share of institution mentions within each bin made by the\nnews sources. The boxplot shows the interquartile range, outliers\nand median for each bin\u2019s total mentions. The means within each\nbin are displayed with yellow points. Prestige bias exists at both\nends of the ideological spectrum, though left-leaning news outlets\ndisplay more prestige bias, i.e., stronger preference for experts from\nthe top-50 academic institutions.\nWe control for political orientation of news outlet in comparing\nacademic institution mentions and rankings. Left-leaning news\nsources have a Gini coefficient of 0.573 and Spearman coefficient\n-0.439 (p <0.01). Right-leaning news sources have a Gini coefficient\nof 0.562 and Spearman coefficient -0.317 (p <0.01). This suggests\nthat journalists from conservative sources divide their attention\nmore evenly across institutions than liberal journalists, though the\ndifference is small.\nFigure 9: Gender and Prestige Bias. Cumulative distribution of men-\ntions for the top 100 institutions broken down by gender. Shows minimal\ndifference in prestige bias between men and women in academia. Roughly\none third of quotations come from top 20 institutions, regardless of gender.\nMen are overrepresented among the quotations from top 10 institutions.\n4.3.2 Gender and Prestige Bias. Next we examine whether pres-\ntige bias varies with expert gender. Fig. 9 shows the cumulative\ndistribution of the share of mentions of experts of either gender\naffiliated with top- \ud835\udc5bacademic institutions. Values of \ud835\udc5bare 5, 10, 15,\netc. We observe almost no difference in how men and women\u2019s cov-\nerage varies with prestige. For each gender, top-50 highest ranked\nuniversities account for half of the academic expert mentions (49.6%\nfor women and 50.1% for men). For women, the Gini coefficient of\nuniversity mentions is 0.56 and Spearman correlation coefficient\nbetween the number of mentions and ranking is -.409 (p <0.01). For\nmen, the Gini coefficient is 0.572 and Spearman coefficient -0.397\n(p<0.01). This disparity shows that prestige inequality is slightly\nhigher for men than women.We expected that women would need to be from more presti-\ngious institutions to be considered qualified experts. However, we\nsee in Fig. 9 that there is no significant difference in the prestige\ndistribution for men and women. This lack of difference reveals that\ngender bias is not substantially amplified within expert mentions\nfrom highly ranked universities.\n5 DISCUSSION AND CONCLUSION\nInvolving a diverse set of perspectives in the research process en-\nhances quality of research. However, women make up the minority\nof faculty in most science departments, especially in the more senior\nand leadership positions [ 19]. Additionally, the reward structure of\nscience itself creates disparities through the \u201cMatthew effect\u201d [ 10],\nin which highly regarded scientists obtain disproportionate re-\nsources and become more likely to produce more successful work.\nWe see this in an example where reviewers in a single-blind peer\nreview process are more likely to accept for publication papers from\nauthors from more prestigious universities [ 24]. The researchers\nfrom a few prestigious institutions hold a greater influence in shap-\ning scientific research than authors from the less prestigious schools\nwith more diverse populations [14].\nOur analysis of a large pandemic-related news corpus shows that\nwomen are heard from less frequently than men. Women compose\n24% of expert mentions, though the representation rises to 31% for\nunique experts. This suggests that a few men, possibly public figures\nsuch as Donald Trump or Andrew Cuomo, are disproportionately\nrepresented. Rendering women with less visibility than men paves\nthe way for women\u2019s concerns, such as reopening childcare centers\nand schools, to receive less attention from policy makers.\nWe observe two different types of ideological bias. The represen-\ntation of women, measured by the ratio of women included to men,\nis always higher in left leaning sources than right. Additionally,\nleft leaning news sources display higher prestige bias than right\nleaning ones. All news sources could improve in representation.\nWe showed that journalists reporting on Covid-19 paid much\nmore attention to experts with more prestigious affiliations. The\ngender representation found is a starkly different than that of public\nhealth, which is a field one would hope Covid-19 reporting relies\nupon. When ranking experts by prestige of their institution in the\nfield of public health, ideally the distribution would be somewhat\neven. However, we observe only a marginally smaller ranking coeffi-\ncient. This suggests that journalists are either seeking out irrelevant\nexpertise, or wildly misrepresenting the public health field. Jour-\nnalists have a unique ability to hand pick their subjects, thereby\nshaping public perception of who constitutes scientific expertise.\nBy focusing their\u2014and the public\u2019s\u2014attention on the same small\ngroup of high-ranked universities, they risk perpetuating the cycle\nof advantage for the privileged minority. To our knowledge, this is\nthe first large scale study of prestige bias in news reporting.\nOur study has a number of limitations. Gender classification is a\nmajor limitation. It has been shown that Named Entity Recognition\nhas worse performance identifying women\u2019s names as PERSON en-\ntities compared to men\u2019s names [ 13]. As a result, it is likely that our\nextractions obtained through NER are under-representative of the\nnumber of women in the data set. Another gender-based limitation\nis that the gender predictor used has a misleading androgynous\ncategory. Rather than capturing names with equitable gender bal-\nance or high association with non-binary people, the androgynous\ncategory captures popular Asian last names. The gender classifier\nis based on a dataset built around cisgender people with historically\nWestern names, meaning our study inherently focuses on cisgender\npeople from Western countries. Such exclusion of non-cisgender\npeople in research continues a long legacy of transgender erasure\n[7].\nOur work can be expanded by auditing the gender and institu-\ntional prestige of Coronavirus experts who are active online on\nTwitter. We hope to compare network structure by gender category\nand see how engagement-increasing behaviors differ by gender.\nWe are also interested in hate speech analysis of how scientists\nof different genders are interacted with on Twitter. Twitter also\ngives users opportunities to provide their pronouns, allowing us to\nlook at under representations of the gender queer community in\nscientific research and expert positions.\nThis large scale analysis of Covid-19 expertise helps us better\nunderstand information ecosystems in times of crisis. We observe\nthat men are the dominant sources of expertise, and that a positive\nfeedback loop may occur in news media where men with research\nsuccess are featured more and therefore are better positioned for\nfurther success (and further features in the news media). By au-\ntomating this analysis, we demonstrate the utility of NLP tools. We\nhope these findings will help news media more faithfully represent\nsociety\u2019s diversity.\nETHICS STATEMENT\nThis work uses publicly available published news articles from\nwell known news outlets. Thus, the data set raises few ethical\nissues around privacy. Ethical concerns around gender inference\nmechanisms are discussed further in the Conclusion and Discussion\nportion. The code for this paper will be made available on GitHub.\nACKNOWLEDGEMENTS\nThis work was supported, in part, by the Defense Advanced Re-\nsearch Projects Agency under contract W911NF192027.\nREFERENCES\n[1]David Arcos, Ferhat Elmas, and Israel Perez. 2016. https://github.com/\nlead-ratings/gender-guesser. (2016).\n[2]Fatemeh Torabi Asr, Mohammad Mazraeh, Alexandre Lopes, Vasundhara Gautam,\nJunette Gonzales, Prashanth Rao, and Maite Taboada. 2021. The gender gap\ntracker: Using natural language processing to measure gender bias in media. PloS\none16, 1 (2021), e0245533.\n[3]Sarah Fletcher, Moss Bruton Joe, Santanna Hernandez, Inka Toman, Tyrone G\nHarrison, and Shannon M Ruzycki. 2021. The gender of COVID-19 experts in\nnewspaper articles: a descriptive cross-sectional study. Journal of general internal\nmedicine 36, 4 (2021), 1011\u20131016.\n[4]Matthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language under-\nstanding with Bloom embeddings, convolutional neural networks and incremen-\ntal parsing. (2017). To appear.\n[5]\u00c1ngel V Jim\u00e9nez and Alex Mesoudi. 2019. Prestige-biased social learning: Current\nevidence and outstanding questions. Palgrave Communications 5, 1 (2019), 1\u201312.\n[6]Luba Kassova. 2020. The missing perspectives of women in COVID-19 news. A\nSpecial Report on Women\u2019s Under-Representation in News Media. New York: Bill\nand Melinda Gates Foundation (2020).\n[7]Os Keyes. 2018. The misgendering machines: Trans/HCI implications of automatic\ngender recognition. Proceedings of the ACM on human-computer interaction 2,\nCSCW (2018), 1\u201322.\n[8]Jenny Kitzinger, Mwenya Diana Chimba, Andy Williams, Joan Haran, and Tammy\nBoyce. 2008. Gender, stereotypes and expertise in the press: how newspapers\nrepresent female and male scientists. (2008).[9]Jonathon P Leider, Christine M Plepys, Brian C Castrucci, Emily M Burke, and\nCraig H Blakely. 2018. Trends in the conferral of graduate public health degrees:\na triangulated approach. Public Health Reports 133, 6 (2018), 729\u2013737.\n[10] Chien Hsiang Liao. 2021. The Matthew effect and the halo effect in research\nfunding. Journal of Informetrics 15, 1 (2021), 101108.\n[11] Lidia Ma\u00f1oso Pacheco. 2019. Gender asymmetries in news reports. Ene11 (2019),\n27.\n[12] Maxwell E McCombs and Donald L Shaw. 1972. The agenda-setting function of\nmass media. Public opinion quarterly 36, 2 (1972), 176\u2013187.\n[13] Ninareh Mehrabi, Thamme Gowda, Fred Morstatter, Nanyun Peng, and Aram\nGalstyan. 2020. Man is to person as woman is to location: Measuring gender\nbias in named entity recognition. In Proceedings of the 31st ACM Conference on\nHypertext and Social Media . 231\u2013232.\n[14] Allison C Morgan, Dimitrios J Economou, Samuel F Way, and Aaron Clauset.\n2018. Prestige drives epistemic inequality in the diffusion of scientific ideas. EPJ\nData Science 7, 1 (2018), 40.\n[15] Mari K Niemi and Ville Pitk\u00e4nen. 2017. Gendered use of experts in the media:\nAnalysis of the gender gap in Finnish news journalism. Public understanding of\nscience 26, 3 (2017), 355\u2013368.\n[16] Hartwig Pautz. 2011. Revisiting the think-tank phenomenon. Public policy and\nadministration 26, 4 (2011), 419\u2013435.\n[17] Prashanth Rao and Maite Taboada. 2021. Gender bias in the news: A scalable\ntopic modelling and visualization framework. Frontiers in Artificial Intelligence 4\n(2021).\n[18] Luc\u00eda Santamar\u00eda and Helena Mihaljevi\u0107. 2018. Comparison and benchmark of\nname-to-gender inference services. PeerJ Computer Science 4 (2018), e156.\n[19] Enrique F Schisterman, Chandra W Swanson, Ya-Ling Lu, and Sunni L Mum-\nford. 2017. The changing face of epidemiology: gender disparities in citations?\nEpidemiology (Cambridge, Mass.) 28, 2 (2017), 159.\n[20] David K Scott, Mike Chanslor, and Jennifer Dixon. 2010. FAIR and the PBS\nNewsHour: Assessing diversity and elitism in news sourcing. Communication\nQuarterly 58, 3 (2010), 319\u2013340.\n[21] Eran Shor, Arnout Van De Rijt, and Babak Fotouhi. 2019. A large-scale test of\ngender bias in the media. Sociological science 6 (2019), 526\u2013550.\n[22] Eran Shor, Arnout van de Rijt, and Vivek Kulkarni. 2022. Women Who Break\nthe Glass Ceiling Get a \u201cPaper Cut\u201d: Gender, Fame, and Media Sentiment. Social\nProblems (2022).\n[23] Eran Shor, Arnout Van De Rijt, Alex Miltsov, Vivek Kulkarni, and Steven Skiena.\n2015. A paper ceiling: Explaining the persistent underrepresentation of women\nin printed news. American Sociological Review 80, 5 (2015), 960\u2013984.\n[24] I Sverdlichenko, S Xie, and E Margolin. 2022. Impact of institutional affiliation bias\non editorial publication decisions: A bibliometric analysis of three ophthalmology\njournals. Ethics, Medicine and Public Health 21 (2022), 100758.\n[25] K Hunter Wapman, Sam Zhang, Aaron Clauset, and Daniel B Larremore. 2022.\nQuantifying hierarchy and dynamics in US faculty hiring and retention. Nature\n(2022), 1\u20138.\n[26] R Weaver and James McGann. 2017. Think tanks and civil societies: Catalysts for\nideas and action . Routledge.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Gender and Prestige Bias in Coronavirus News Reporting", "author": ["R Dorn", "Y Ma", "F Morstatter", "K Lerman"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2301.11994", "abstract": "Journalists play a vital role in surfacing issues of societal importance, but their choices of  what to highlight and who to interview are influenced by societal biases. In this work, we use"}, "filled": false, "gsrank": 546, "pub_url": "https://arxiv.org/abs/2301.11994", "author_id": ["", "", "u-8h3HcAAAAJ", "PlAG11IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:wxOlgEZSZVsJ:scholar.google.com/&output=cite&scirp=545&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=wxOlgEZSZVsJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:wxOlgEZSZVsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2301.11994"}}, {"title": "Assessing News Thumbnail Representativeness: Counterfactual text can enhance the cross-modal matching ability", "year": "2024", "pdf_data": "Assessing News Thumbnail Representativeness:\nCounterfactual text can enhance the cross-modal matching ability\nYejun Yoon\u2020Seunghyun Yoon\u2021Kunwoo Park\u2020\u22c6\n\u2020Department of Intelligent Semiconductors, Soongsil University\n\u2021Adobe Research, USA\n\u22c6School of AI Convergence, Soongsil University\nyeayen789@gmail.com ,syoon@adobe.com ,kunwoo.park@ssu.ac.kr\nAbstract\nThis paper addresses the critical challenge of\nassessing the representativeness of news thumb-\nnail images, which often serve as the first vi-\nsual engagement for readers when an article\nis disseminated on social media. We focus on\nwhether a news image represents the actors dis-\ncussed in the news text. To serve the challenge,\nwe introduce NEWSTT, a manually annotated\ndataset of 1000 news thumbnail images and\ntext pairs. We found that the pretrained vision\nand language models, such as BLIP-2, struggle\nwith this task. Since news subjects frequently\ninvolve named entities or proper nouns, the\npretrained models could have a limited capa-\nbility to match news actors\u2019 visual and textual\nappearances. We hypothesize that learning to\ncontrast news text with its counterfactual, of\nwhich named entities are replaced, can enhance\nthe cross-modal matching ability of vision and\nlanguage models. We propose CFT-CLIP , a\ncontrastive learning framework that updates vi-\nsion and language bi-encoders according to the\nhypothesis. We found that our simple method\ncan boost the performance for assessing news\nthumbnail representativeness, supporting our\nassumption. Code and data can be accessed at\nhttps://github.com/ssu-humane/news-i\nmages-acl24 .\n1 Introduction\nThis study investigates the representativeness of\nnews thumbnails, which are images displayed as\npreviews of news articles. Visual content often car-\nries a more persuasive impact and leaves a long-\nlasting impression compared to text (Joffe, 2008;\nNewman et al., 2012; Seo, 2020). Consequently,\nthe misrepresentation in news thumbnails can cause\nmore critical consequences. Despite its importance,\nthere have been a few studies addressing the repre-\nsentativeness of news images (Hessel et al., 2021;\nChoi et al., 2022). Achieving the goal requires a\nmodel to understand the cross-modal relationship\nbetween visual and textual content.\nFigure 1: An illustration of the key idea of the proposed\nmethod. To assess whether a news thumbnail image rep-\nresents the body text, the method generates counterfac-\ntual text to be used as negative samples for contrastive\nupdates.\nResearchers in Natural Language Processing\nand Computer Vision communities have explored\nmultimodal technologies by addressing general vi-\nsion and language (V+L) tasks, including visual\nquestion answering (Antol et al., 2015), image-\ntext retrieval (Cao et al., 2022), and visual entail-\nment (Xie et al., 2019). Recent approaches have\nleveraged contrastive learning techniques for repre-\nsenting distinct modalities in the same vector space.\nCLIP (Radford et al., 2021) stands out as one of the\npioneering methods that achieve remarkable perfor-\nmance, aimed at increasing the similarity between\nimage-text pairs (referred to as positive samples)\ncompared to non-paired image and text (referred\nto as negative samples). While contrastive learn-\ning was not a new concept (Oord et al., 2018),\nCLIP outperformed preexisting methods by utiliz-\ning a vast collection of web-based image and text\ndata for pretraining. Recent advancements have fur-\nther enhanced the performance by refining learning\nobjectives (Li et al., 2022b), incorporating cross-\nattention layers into the model architecture (Li\net al., 2021a), and augmenting the training data\nwith high-quality samples (Li et al., 2022a; HaoarXiv:2402.11159v3  [cs.CL]  7 Jun 2024\net al., 2023).\nDespite the progress made in multimodal meth-\nods for general vision-and-language benchmarks,\nwe hypothesize that evaluating the representative-\nness of thumbnails remains difficult, even for the\nmost advanced models, due to two primary chal-\nlenges. (1) Preference for general descriptions in\npopular benchmarks : General V+L datasets, such\nas Conceptual Captions (Sharma et al., 2018) or\nCOCO-Caption (Chen et al., 2015), were primarily\ndesigned to enhance a model\u2019s ability to compre-\nhend general behaviors or scenes. Consequently,\nthese datasets deliberately avoid specific descrip-\ntions about entities (e.g., \u201c Theman at bat readies\nto swing at the pitch\u201d). In contrast, news events\ntypically revolve around political actors or organi-\nzations, leading to news texts that frequently refer-\nence named entities (Luo et al., 2021). (2) Lack of\ndataset labeled according to an objective defini-\ntion: Representativeness is an inherently abstract\nand subjective concept, where even humans may\ndisagree with each other. Developing an objective\ndefinition is imperative to obtain high-quality labels\nthat different human annotators can agree on and\nfacilitate the development of proper technologies.\nWhile there was a human-labeled dataset (Choi\net al., 2022), they asked for subjective opinions\nof human annotators without providing objective\ndefinitions grounded by journalism principles.\nTo address (1) and (2), borrowing the princi-\nple of five Ws in journalism (The Associate Press,\n2022), we introduce the evaluation dataset of NEWS\nThumbnails and Text pairs, NEWSTT. The annota-\ntors were instructed to label the 1000 pairs through\nthe lens of Who, on whether an image represents\nnews actors. Using the high-quality labels reflect-\ning the objective definition of representativeness,\nwe evaluated the zero-shot ability of vision and\nlanguage models to understand news actors\u2019 visual\nportrayals. We found that CLIP performed better at\nthe task than more recent methods, such as BLIP-\n2, suggesting the efficiencies of its dual encoder\narchitecture and contrastive objective. To improve\nits matching ability, this study introduces CFT-\nCLIP , aCounter Factual Text-guided Contrastive\nLanguage- Image Pretraining framework. As illus-\ntrated in Figure 1, the key idea of the proposed\nframework is to generate counterfactual news text\nwhere the actor of a news event is changed to be\nused as hard negatives for contrastive learning. In\nthe news text example, the actor is identified as\n\u2018Biden,\u2019 and its corresponding token is replacedwith \u2018Trump\u2019 by the counterfactual text generator.\nThus, the generated sentence no longer represents\nthe key actor of the news event depicted in the\nthumbnail image. Our research hypothesis is that\nlearning to contrast the generated counterfactual\ntext with the original news text will enhance the\nability of vision language models to assess the rep-\nresentativeness of a thumbnail image .\nWe summarize the contributions of this study.\n1.We address the problem of assessing news\nthumbnail representativeness by determining\nwhether a given news image depicts the actors\nof the news events (Who) according to the\nprinciple of 5Ws.\n2.To serve the task, we introduce NEWSTT,\na manually annotated dataset of 1,000 news\nthumbnails and text pairs with high-quality\nlabels. We found that general vision language\nmodels struggle with it.\n3.We propose CFT-CLIP , a counterfactual text-\nguided contrastive language-image pretrain-\ning framework. We found that our simple\nmethod could outperform larger pretrained\nand domain-adapted models, supporting the\nresearch hypothesis.\n2 Related Works\n2.1 Vision language contrastive pretraining\nResearchers have worked on pretraining methods\nto tackle V+L tasks such as image-text retrieval.\nLu et al. (2019) extended BERT to a multi-modal\nmodel by co-attentional transformer layers. An-\nother study proposed to learn a universal image and\ntext representation by four pre-training tasks, in-\ncluding masked language modeling and image-text\nmatching (Chen et al., 2020). Researchers proposed\nCLIP, a training scheme of visual representation by\nlearning directly from paired text using contrastive\nloss (Radford et al., 2021). Being trained on a web-\nscaled dataset, the transformer-based visual repre-\nsentation achieved state-of-the-art results in zero-\nshot tasks. Another study showed its potential as\na reference-free image-captioning metric (Hessel\net al., 2021). Other researchers presented ALIGN,\na bi-encoder trained by a contrastive loss similar\nto CLIP (Jia et al., 2021). While we used CLIP\nencoders as the target backbone in this study, our\ncontrastive learning framework can be applied to\na more recent vision-and-language model that in-\ncorporates the image-text alignment, such as BLIP-\n2 (Li et al., 2023).\nResearch has underscored the significance of\nincorporating hard negative samples into the con-\ntrastive objective (Nishikawa et al., 2022; Robinson\net al., 2021). In response, we introduce a method to\ngenerate hard negative text samples using a masked\nlanguage model. Although a handful of studies\nhave explored the use of masked language models\nfor generating hard negatives (Li et al., 2021b; Yao\net al., 2022), our approach stands apart due to its\ndistinct token selection and prediction procedures\nin the step of counterfactual text generation. We\ncompared its effectiveness against the autoregres-\nsive generation of GPT-3.5 Turbo in the ablation\nexperiments.\n2.2 Multimodal misinformation\nThis study falls into the broad category of research\non multimodal misinformation. Previous research\nmainly worked on fact verification involving mul-\ntimodal claims or evidence (Zlatkova et al., 2019;\nShu et al., 2020; Yao et al., 2023; Rani et al.,\n2023). In contrast, this study examines whether\nnews thumbnails and text present the same actor. A\nrelevant problem is image repurposing (Luo et al.,\n2021; Abdelnabi et al., 2022), where a realimage\nis used out-of-context to create realistically look-\ning misinformation. To tackle the problem, Luo\net al. (2021) proposed NewsCLIPPings, a dataset\nof out-of-context image detection in the news con-\ntext. They created the mismatched image-text pairs\nby swapping the matches of the collected news im-\nage and text pairs. Similarly, Mishra et al. (2022)\ncreated a dataset of multimodal fact verification,\nof which false claims were obtained by manipu-\nlating the pairs. Unlike the previous research on\nout-of-context image detection, this study aims to\nfocus on whether news subjects are represented\nin the thumbnail image. We also created a manu-\nally annotated evaluation dataset, contrasting with\nprevious datasets based on synthetic labels (Luo\net al., 2021; Mishra et al., 2022). Our target task is\nrelated to but differs from the manipulated image\ndetection (Huh et al., 2018; Rossler et al., 2019),\nknown as deepfakes or cheapfakes, which aimed to\ndetect a fake image generated by AI technologies\nor simple tools.3 Target Problem: Assessing News\nThumbnail Representativeness\nWe aim to address the problem of automatically\nevaluating the representativeness of a news thumb-\nnail image for its article. The task is critical due\nto the two reasons. First, the sharing of news on-\nline is abundant (Park et al., 2021a; Lee and Ma,\n2012; Hermida et al., 2012). Second, the thumb-\nnail often serves as the initial and sole visual inter-\naction for social media users when a news link\nis shared. Visual content is perceived as more\ncredible and leaves a long-lasting impression than\ntext (Joffe, 2008; Seo, 2020; Newman and Zhang,\n2020). Given these considerations, thumbnail im-\nages that do not accurately represent their content\ncan misguide the reader\u2019s understanding in online\nenvironments.\nWe formally define the problem as a binary clas-\nsification. Given a news thumbnail Iand its news\ntextT, we aim to develop a classifier f\u03b8(I, T)pre-\ndicting a binary label Lon predicting whether I\nrepresents T. We assign 1 to LifIrepresents T;\notherwise, 0. Iis deemed representative of TifI\nportrays at least one of the actors of a news event,\nwhich can be identified from T. This study aims\nto develop a vision language model that predicts\nLfrom a pair of IandT. We assume the task in a\nzero-shot setting, where the labeled data is limited.\nThe reference news text Tcan be either a title or a\nsummary.\n4 N EWS TT: A Dataset of Thumbnail\nRepresentativeness for News Text\n4.1 Raw data collection\nNELA-GT-2021 is a headline-oriented1news cor-\npus that encompasses nearly all news articles pub-\nlished by 367 news sources throughout the year\n2021 (Gruppi et al., 2022). Since the dataset does\nnot provide web links to thumbnail images, we\nconducted a supplementary data collection step.\nBy referencing the URLs of news articles avail-\nable in the dataset, we parsed the HTML docu-\nment and extracted the thumbnail image URL from\nthe meta tag with the og:image attribute. As a\nresult, we obtained 442,741 pairs of news head-\nlines and thumbnail images, which were sourced\nfrom 81 different news media outlets. According\nto the media ratings provided by Media Bias/Fact\n1They put the body text whose random tokens are masked.\nFigure 2: Labeled data examples.\nCheck (MBFC)2, the datasets were well-balanced\nfor the political orientation and trustworthiness\nratings. Subsequently, we partitioned this unla-\nbeled dataset into 427,741/5,000/10,000 pairs for\ntrain/validation/test purposes while keeping the dis-\ntribution of the number of articles over different\nmedia sources. The validation split was reserved\nfor hyperparameter optimization, and the test split\nserved as the source for labeled data construction.\n4.2 Data annotation\nWe describe the process for building the annotation\nguideline. Following a previous study (Choi et al.,\n2022), we conducted the pilot labeling task given\nan abstract definition of a representative thumb-\nnail, which is \u201c an image that visually conveys the\nnews event that can be identified from the accom-\npanying text \u201d. There were often disagreements in\nthe resulting labels likely due to the subjective na-\nture of definition. Following internal discussions\nand consultation with a journalism expert with a\nPh.D. in Communication, we focused on the key\ndimension of news events corresponding to the five\nWs (The Associate Press, 2022): on whether the\nimage represents news subjects, i.e., Who.\nFor the annotation process, we sampled 1,000\nnews articles from the pool of 10,000 instances of\nthe test split. Relying on the MBFC ratings, we\nsampled 500 articles from the trustworthy outlets,\nlabeled as mixed orhigh for the trustworthiness\nrating, and the remaining 500 from the fake news\nsources, labeled as low. We manually collected the\nbody text for the 1000 articles and ran the OpenAI\nAPI for obtaining the summary text by GPT-3.5\n2https://mediabiasfactcheck.com/Represent (1) Not represent (0)\nTitle Summary Title Summary\nWords 14.9 39.1 14.7 39\nNouns 3.45 8.63 3.75 9.7\nVerbs 1.81 4.06 1.68 4.09\nAdjectives 0.93 2.39 1.19 2.73\nNamed entities 2 3.41 1.64 2.76\nTable 1: Mean counts of words, part-of-speech units,\nand named entities measured on the labeled text.\nTurbo3. We hired three English-speaking students\nwho frequently read news online from one of the\nauthors\u2019 institutions. Given a news thumbnail, title,\nand summary text, the annotators were asked to\nanswer whether the news actors identified in the\nnews text are visually portrayed in the thumbnail\nimage. To facilitate the annotation process, we in-\nstructed them to identify the actors of the news\nevent by referring to the text and, in turn, to find\nvisually depicted ones. Detailed annotation guide-\nlines can be found in Appendix F. The annotation\nresults demonstrated a high inter-annotator agree-\nment rate, with a Krippendorff\u2019s alpha of 0.705,\nensuring the quality and reliability of the labels.\n4.3 Data analysis\nNEWSTT consists of 817 representative and\n183 non-representative image-text pairs. Table 1\npresents the descriptive characteristics of the\ndataset for each class. While the samples in the\ntwo classes are similarly long, the news text of la-\nbel 1 tends to include more named entities. Figure 2\npresents an example for each class. The label 1 ex-\n3The used prompt is in Appendix E.\nFigure 3: An illustration of the counterfactual text generation process by CFT-CLIP. We select named entity tokens\nin an original text that could indicate news subjects. A masked language model generates a counterfactual text by\npredicting new tokens for the selected entity tokens.\nample shows the image portraying Biden and Putin,\nwho are the actors of a news event. The thumbnail\nimage on the right does not show the news actor but\narouses the potential reader\u2019s interest by showing\nthe surprised faces.\n5 Methods\nTo tackle the task of assessing thumbnail represen-\ntativeness in a zero-shot setting where no labeled\ndata is available for training, we use a thresholding\nclassifier based on the cross-modal similarity,\nf(I, T) = 1(sim(vI,vT)> \u03c4), (1)\nwhere \u03c4is a thresholding hyperparameter, sim(\u00b7)\nis cosine similarity, 1(\u00b7)is an indicator function,\nandvIandvTindicate the feature embedding of I\nandT, respectively. Assuming the parity prior, we\nset\u03c4as the median of sim(\u00b7)on the validation set.\n5.1 Background: CLIP\nCLIP is a vision and language bi-encoder that rep-\nresents each modality in a fixed-dimensional vector\nspace (Radford et al., 2021). The model is based\non a bi-encoder architecture, fimage (\u00b7)andftext(\u00b7).\nFor an input image Iand text T, the two encoders\nreturn the image embedding vIand the text embed-\ndingvT, respectively. The parameters were trained\nvia contrastive learning on a large web collection of\nimage-text pairs. Since vIandvTare in the same\nvector space, CLIP can serve as a backbone for the\nzero-shot thresholding classifier in Eq. 1.\n5.2 Proposed method: CFT-CLIP\nWe propose CFT-CLIP, a counterfactual text-\nguided contrastive language-image pretraining\nmethod. The proposed framework aims to improve\nthe vision and language bi-encoder by contrastive\nupdates involving the counterfactual text generatedfrom an input text. Figure 3 shows an example of\ngeneration. While the original news pertains to an\nevent involving Biden\u2019s summit with the Mexican\npresident, the generated sentence implies a counter-\nfactual event centered on Trump by substituting the\ntoken \u2018Biden\u2019. This substitution is accomplished\nvia the prediction of a masked language model tar-\ngeting the named entity token. Based on the news\ncharacteristics on the prevalent coverage of named\nentities (Park et al., 2021b; M\u00fcller-Budack et al.,\n2020), we hypothesize that contrasting the original\nnews text with its counterfactual would make the\nvision and language bi-encoder to obtain a more\neffective representation for understanding a thumb-\nnail image\u2019s representativeness.\n5.2.1 Counterfactual text generation\nGiven a pair of image Iand text T, we aim to\ngenerate a counterfactual news text \u02dcT, which is\nsemantically distinct from the anchor image I(and\nthe original text T).\n(1) Candidate token set construction : The first\nstep aims to select tokens that likely refer to the\nactor of a news event. A part-of-speech tagger and\nnamed entity recognizer are applied to T, which\nreturns a candidate token set C. We tested several\nstrategies targeting named entity categories that are\nfrequently used in news articles, such as person,\norganization, and GPE4.\n(2) Token selection and masking : We select to-\nkens from Cand mask them in the original text T\nusing the special token [MASK] . To preserve the\noriginal context of T, we ensure that no more than\n30% of its total tokens are masked. If the number of\ntarget tokens selected from Cexceeds this thresh-\nold, we randomly select a subset of these tokens to\nmeet the condition. Otherwise, all tokens in Care\nmasked in T.\n4Countries, cities, states\n(3) Masked token prediction : Using a masked\nlanguage model, e.g., BERT (Devlin et al., 2019),\nwe predict new tokens for the masked positions\ninT. To avoid reconstructing the original text, we\ndivide the logit scores of the output vector by a\ntemperature parameter and repeatedly sample from\nthe softmax-normalized distribution until a token\ndifferent from the original is generated. This step\nproduces \u02dcT, which represents a synthetic event\nwherein the subject is modified from the original\nnews event, yet it preserves the overarching topic\nofT. Thus, \u02dcTcan be deemed a hard negative sam-\nple in contrastive learning, which diverges from\nIbut remains more closely aligned with Tthan a\nrandom text or in-batch negatives.\nIn Section 6.3, we present the ablation ex-\nperiments to show the effectiveness of the pro-\nposed counterfactual text generation. Additionally,\nwe demonstrate several counterfactual text exam-\nples generated by the proposed method in Ap-\npendix D.2.\n5.2.2 Training objective\nWe train an image and text bi-encoder model to\nminimize\n\u2212logesim(vIi,vTi)/\u03c4\nPN\nj=1{esim(vIi,vTj)/\u03c4+esim(vIi,v\u02dcTj)/\u03c4},\n(2)\nwhere vIiis the feature embedding of the vision\nencoder for Ii,vTiis the feature embedding of the\ntext encoder for Ti,sim(\u00b7)is the dot product, and\nNis the mini-batch size.\nMinimizing Eq. 2 aligns the text representation\nwith the image representation by increasing the sim-\nilarity of positive pair (Ii, Ti)compared to those\nof negative pairs (Ii, Tj)and(Ii,\u02dcTi). Since \u02dcTrep-\nresents a distinct news event of which actors were\nreplaced from T, the objective would help a bi-\nencoder model learn to capture whether the thumb-\nnail image represents the news actors that can be\nidentified from T.\n5.2.3 Model architecture\nFigure 4 depicts the neural architecture used for\nthe proposed method. We initialized the model by\nadopting a pretrained CLIP checkpoint5. The image\nencoder fimage is the ViT-L/14 vision transformer\n(24 layers), and the text encoder ftextis a causal\ntext transformer (12 layers). The image and text\n5https://huggingface.co/openai/clip-vit-large\n-patch14\nFigure 4: Neural architecture of CFT-CLIP\nencoder are followed by an MLP pooler mapping\nthe input to a 768-dimensional vector, respectively.\nTand\u02dcTare fed into the shared-weight text en-\ncoder, separately. According to the hyperparameter\noptimization experiment, we froze 11 out of 12 text\ntransformer layers during training. All vision layers\nwere updated.\n5.2.4 Pretraining corpus\nWe used two pretraining corpora. First, we used the\ntraining split of NELA unlabeled data. Inspired by\na prior study that replicated the CLIP pretraining\nbased on a web data collection (Schuhmann et al.,\n2022), we applied the data sanitization process to\nthe training split of unlabeled data by filtering only\nthose with a cosine similarity of 0.28 or higher over\nCLIP embeddings. The resulting 105,737 pairs for\nthe unlabeled training have a high likelihood of a\nrepresentative thumbnail ( L= 1). Since the body\ntext in the NELA corpus is incomplete, we relied\non the news title as the reference text for pretrain-\ning. Second, inspired by the recent research on the\nimportance of high-quality samples for pretrain-\ning (Zhou et al., 2024; Schuhmann et al., 2022),\nwe used a high-quality news corpus published by\ntheBBC , a UK-based news source rated as trust-\nworthy by MBFC (Verma et al., 2023). This cor-\npus comprises 196,538 pairs, each containing a\nnews title, an editor-written summary, and a thumb-\nnail image. The corpus encompasses news articles\nreleased through the official website from 2009\nto 2021. We applied the sanitation process to the\ndataset in the same manner as with the NELA cor-\npus, leaving 58,210 samples for contrastive training.\nWe ensured no overlap between the BBC training\nset and the NELA validation/test splits. Since New-\nsTT originates from the NELA corpus, we used\nthe NELA validation split for hyperparameter op-\ntimization. In the experiments using the BBC cor-\npus, we tested two variants using the news title and\nhuman-written summary as reference text.\n6 Evaluation\nWe conducted evaluation experiments to under-\nstand the effects of the proposed method and test\nthe research hypothesis. In Section 6.2, we exam-\nined how the pretrained and proposed vision lan-\nguage models perform for the target task. In ab-\nlation experiments (Section 6.3), we analyzed the\neffects of each module of the proposed method in\nmore detail. Lastly, in Section 6.4, we conducted\nqualitative analyses to identify the error patterns\nwhere the proposed method fails.\n6.1 Experimental setups\nAs baselines, we measured the ability of pre-\ntrained vision language models. In addition to\nCLIP , we used BLIP andBLIP-2 , which are a\nfamily of vision language encoders that is based\non bootstrapped training (Li et al., 2022a, 2023).\nThey achieved state-of-the-art performance in the\nvision-language benchmarks. BLIP-2 +SBERT is\na pipelined approach that integrates BLIP-2 with\nSentenceBERT. By obtaining a caption text from\nan input image Iby BLIP-2, we assessed its se-\nmantic similarity to the reference text using Sen-\ntenceBERT. To investigate the effects of domain-\nadaptive pretraining, we also included CLIPAdapt\nas a baseline model, which was trained by using\nthe CLIP objective on the training corpus. For in-\nference, we used the summary text as the reference\ntextTaccording to the results of an ablation exper-\niment (Table A2).\nTo evaluate the baseline and proposed methods,\nwe employed the f1 score and the Spearman rank\ncorrelation coefficient to evaluate binary prediction\nand cosine similarity scores, respectively. All exper-\niments were conducted using five different random\nseeds, and we reported the average performance\nalong with the standard error. The t-test was used\nfor estimating statistical significance. We used the\nSpaCy pipeline for named entity recognition. A\nBERT-base checkpoint was used for the masked\nlanguage prediction. All checkpoints used for ex-\nperiments and implementation details can be found\nin Appendix B. We optimized all hyperparameters\nusing the NELA validation split.\n6.2 Main results\nTable 2 presents the evaluation results of the base-\nline and proposed methods. Here, we reported the\nperformance of CFT-CLIP and CLIPAdapt mod-\nels that were pretrained using the BBC datasetModel F1 Spearman\nCFT-CLIP 0.815\u00b10.003 0.491\u00b10.005\nCLIPAdapt 0.767 \u00b10.006 0.459 \u00b10.004\nCLIP 0.763 0.409\nBLIP 0.737 0.408\nBLIP-2 0.707 0.415\nBLIP-2 +SBERT 0.694 0.341\nTable 2: Model comparison results\nTarget token F1 Spearman\nPerson 0.815\u00b10.003 0.491\u00b10.005\nOrganization 0.784 \u00b10.002 0.443 \u00b10.002\nGPE 0.762 \u00b10.004 0.410 \u00b10.005\nAll 0.785 \u00b10.003 0.457 \u00b10.003\nRandom (15%) 0.715 \u00b10.013 0.463 \u00b10.005\nRandom (30%) 0.68 \u00b10.007 0.461 \u00b10.002\nTable 3: Varying performance by token selection strate-\ngies in counterfactual text generation\nwith the summary text. For CFT-CLIP, we used\nthe model targeting person-labeled entity tokens.\nThe decisions were based on the ablation experi-\nments on the effect of pretraining corpus (Table 5)\nand counterfactual text generation (Table 3), respec-\ntively. We made three observations. First, among\nthe pre-trained models (the bottom four rows),\nCLIP achieved the best f1 of 0.763, and BLIP-\n2 was the best by the Spearman coefficient with\n0.415. Given that BLIP-2 (1.17B) is 2.74 times\nlarger than CLIP (427M), this observation suggests\nthe effectiveness of CLIP\u2019s bi-encoder architec-\nture for the target task. Second, CLIPAdapt outper-\nformed all the pretrained models. This suggests that\ndomain-adapted continued pretraining can improve\nthe performance for the target task, congruent with\nthe finding of a previous study (Gururangan et al.,\n2020). Third, CFT-CLIP outperformed all baseline\nmethods with the f1 of 0.815 and the Spearman co-\nefficient of 0.491 ( p<0.001). The performance gap\nwith CLIPAdapt, the second-best method, is sig-\nnificant: 0.048 for f1 and 0.032 for the Spearman\ncoefficient. The finding suggests that incorporat-\ning the counterfactual text in its contrastive objec-\ntive as hard negatives can improve the cross-modal\nmatching ability of the vision language bi-encoder,\nsupporting the research hypothesis.\n6.3 Ablation experiments\nWhat tokens should be targeted? We evalu-\nated the performance of CFT-CLIP variants aim-\ning to replace different types of entity tokens in\ncounterfactual text generation. In particular, we\ntargeted the frequently used named entity tokens\nin the news text: person, organization, and GPE.\nWe also tested the model that replaces all three\ntoken types, denoted All in the table. The top 4\nrows in Table 3 present the comparison results. We\nfound that targeting person-labeled entity tokens\nachieved the best performance. This finding could\nbe explained by the prevalent coverage of person\nentities, such as politicians, in news events (Park\net al., 2021b; M\u00fcller-Budack et al., 2020). Addi-\ntionally, we tested baseline strategies that replace\ntokens at random positions for being used for nega-\ntive samples in contrastive learning, as investigated\nin previous studies (Nishikawa et al., 2022; Robin-\nson et al., 2021). We evaluated two variants that\nselect 15% and 30% tokens, respectively, which\nwere predicted by the same BERT backbone as\nthe proposed method. The bottom two rows in Ta-\nble 3 show the model performance, achieving sig-\nnificantly worse f1 and Spearman coefficients than\nthe CFT-CLIP variants ( p<0.001). According to\nthe results, we targeted person-labeled tokens in\nthe proposed method.\nIs the masked LM necessary? CFT-CLIP used\na masked language model to generate counterfac-\ntual text for contrastive updates. An autoregressive\nlarge language model, such as GPT (Radford et al.,\n2018), could be used alternatively. To validate the\nidea, we ran the OpenAI API for generating coun-\nterfactual text for the BBC news summary by GPT\n3.5-Turbo. The generated text was used for con-\ntrastive update, following the objective in Eq. 2.\nThe used prompt is available in Appendix E. As\nshown in Table 4, the GPT-based contrastive up-\ndate was not as successful as the proposed method\nbased on a masked language model. The proposed\nselect-and-replace approach could generate a more\nsuitable counterfactual sample to be used for hard\nnegatives, rather than rewriting the whole sentence\nconditioned on the original text.\nWe also tested a baseline approach that ablates\na generation model for predicting masked tokens\nby randomly sampling person-labeled entities from\nthe tokens from the training set. The simple method\nachieved an f1 of 0.77 and a Spearman coefficient\nof 0.455, respectively. This finding supports the\neffectiveness and necessity of counterfactual text\ngeneration in the proposed method.\nData quality vs. quantity Table 5 presents the\nperformance of CFT-CLIP models with varyingModel F1 Spearman\nCFT-CLIP 0.815\u00b10.003 0.491\u00b10.005\nGPT-based 0.640 \u00b10.018 0.445 \u00b10.002\nTable 4: Comparison with the model trained with GPT-\nbased counterfactual text\nData F1 Spearman\nBBC ( T: summary) 0.815\u00b10.003 0.491 \u00b10.005\nBBC ( T: title) 0.790 \u00b10.007 0.504\u00b10.001\nNELA ( T: title) 0.772 \u00b10.003 0.448 \u00b10.002\nTable 5: Varying performance by the pretraining corpus\npretraining corpus. The BBC dataset resulted in su-\nperior model performance compared to the NELA\ndataset, following the same distribution of the la-\nbeled dataset. Given that the BBC is recognized for\nupholding high journalistic standards, this obser-\nvation may indicate that leveraging a high-quality\nsingular source is more beneficial than employ-\ning articles published by diverse news sources for\ncontrastive pretraining. This finding is aligned with\nthe recent research on large language models (Zhou\net al., 2024), emphasizing that ensuring data quality\nis more important than merely increasing the size\nof the training corpus. In the experiments compar-\ning title and editor-written summaries using BBC,\nwe could not find a clear winner. While using the\nsummary text led to the best f1 of 0.815, using\nthe title achieved the best Spearman coefficient of\n0.504. This suggests that both news headlines and\nsummary text can serve as a useful proxy for news\ncontent, in line with established journalism princi-\nples (The Associate Press, 2022). Since f1 is a more\nproper metric for evaluating classification ability,\nwe used BBC with the summary text for the other\nexperiments.\n6.4 Error analysis\nTo identify the remaining challenges, we analyzed\nerror categories for the sampled 100 error cases.\nThe first author identified the initial category by\nthematic coding, which were improved by the iter-\nation of discussion with the other authors and re-\nannotation. We observed four recurring categories:\nentity recognition failures (46%), external knowl-\nedge required (14%), deep textual understanding\nrequired (14%), and deep visual understanding re-\nquired (14%). Figure 5 presents two error exam-\nples. In the first example, which belongs to the\nentity recognition failure case, the model made a\nFigure 5: Error examples\nwrong prediction possibly due to the failed identifi-\ncation of Brian Sicknick, the officer involved in the\nGeorge Floyd case. In the second example, while\nthe image shows Anne-Marie Trevelyan, a UK min-\nister, the model could not find the cross-modal link\nwithout referring to external knowledge.\n7 Discussion and Conclusion\nAutomatically evaluating a news thumbnail im-\nage\u2019s representativeness is important for hold-\ning journalistic standards and building a trustwor-\nthy online environment. To address the important\nbut underexplored problem in the research com-\nmunity, this study introduced NewsTT, a paired\ndataset of news thumbnail images and text with\nhigh-quality labels on whether the image repre-\nsents the actor of the news event. We investigated\nthe use of vision language models for the zero-\nshot assessment. Our proposed CFT-CLIP outper-\nformed larger pretrained vision language models\nand domain-adapted methods. This supports the\nresearch hypothesis that counterfactual news text,\nof which named entities are replaced by a masked\nlanguage model, could enhance the cross-modal\nmatching ability by contrastive learning.\nIn ablation experiments, we found that using the\ncounterfactual text generated by an autoregressive\ntransformer language model, GPT-3.5 Turbo, as\nnegative samples could not achieve a better out-\ncome than CFT-CLIP. While this supports the ef-\nfectiveness of the proposed method, we do not con-\nclude that masked language models are clear win-\nners for the counterfactual news generation over\nautoregressive language models. After manually\nexamining the results, we observed that GPT could\nproduce plausible counterfactual news. By contrast,the generation by a masked language model some-\ntimes led to imperfect generations, including bro-\nken grammar (Table A4). As shown in a recent\nstudy on text embedding (Lee et al., 2024), an addi-\ntional step might be required to ensure the quality\nof the generated text.\nThis study has several future directions. First,\naccording to the rule of 5Ws, this study focused\non the Who aspect of news thumbnails. Future re-\nsearch could extend its focus to cover other aspects\nof 5Ws, such as whether the image represents the\nsubject\u2019s action, i.e., What . Question-answering ap-\nproaches could be investigated, as done in a recent\nstudy (Rani et al., 2023). Second, the proposed\nmethod could be improved to address the chal-\nlenges identified in the error analysis (Section 6.4).\nFuture studies could investigate the use of multi-\nmodal language models, such as InstructBLIP (Dai\net al., 2023), LLaV A (Liu et al., 2024), or GPT-\n4V (OpenAI, 2023), to allow for handling the errors\ninvolving deep visual understanding . The proposed\nCFT-CLIP could assist them with aligning the vi-\nsion and language representation by adopting the\ncounterfactual text. Third, this study could be ex-\ntended to the broader research on computational\nsocial science. As similarly done in previous stud-\nies (Lommatzsch et al., 2022; Oostdijk et al., 2020),\none could extend the target problem by addressing\nit as a ranking task rather than binary classification.\nIt could enable a news application that recommends\na suitable thumbnail image for a given news arti-\ncle. Additionally, the proposed CFT-CLIP could be\nadopted for automated fact verification involving\nimage evidence (Luo et al., 2021; Mishra et al.,\n2022; Yao et al., 2023).\nLimitations\nThis study bears several limitations. First, the scale\nof NewsTT is limited. Since the annotation task is\ncomplicated, we chose to do an in-lab annotation\nto provide high-quality labels for evaluation. Since\nthe dataset reflects the distribution of real-world\nnews articles and the label quality is high, it can\nbe used for a reliable evaluation corpus. Future\nstudies could scale up the dataset via crowdsourc-\ning with the annotation scheme developed in this\nstudy. Second, since we continued to pretrain the\nCLIP encoders, CFT-CLIP inherits the weakness\nof the CLIP vision encoder. CLIP might be cultur-\nally biased toward the Western countries where the\npretraining dataset may originate. The pretrained\nCLIP checkpoint used in this study cannot handle\nthe entire body text as input because the maximum\ntoken length is 77, which is smaller than the aver-\nage body text length. While the use of summary\ntext mitigates the limitation, future studies could\nuse a text encoder that can handle a long sequence\nto exploit the entire news article. Third, this study\nfocused on developing a zero-shot classifier based\non a CLIP-like dual encoder, which does not in-\nvolve labeled data for training. The performance\ncould be boosted by developing a fine-tuned classi-\nfier or few-shot prompt learning methods.\nEthics Statement\nThis study introduced CFT-CLIP, a contrastive\nlearning framework for training an image-text mul-\ntimodal encoder. For pretraining, this study used\npublicly available news articles shared by news\nmedia. While we tried to have a high-quality cor-\npus for pretraining, it is possible that the model\nlearned hidden biases in online news. Also, Since\nCFT-CLIP was updated from the pretrained CLIP\nweights, it may inherit the bias of CLIP. A user\nshould be cautious about applying the method to\nproblems in a general context and be aware of a\npotential bias. We have fewer privacy concerns be-\ncause our study used openly accessible news data\nthat may follow strict internal guidelines according\nto journalism principles. The NELA-GT-2021 was\nshared under the license of CC BY-NC 4.0, and\nthe BBC corpus was shared under the MIT license.\nWe will share NewsTT with CC BY NC 4.0. Some\nof the text was edited using AI assistants, such as\nChatGPT and Grammarly.Acknowledgements\nKunwoo Park is the corresponding author. This\nwork was supported by Innovative Human Re-\nsource Development for Local Intellectualization\nprogram through the Institute of Information &\nCommunications Technology Planning & Evalua-\ntion (IITP) grant funded by the Korean government\n(MSIT) (IITP-2024-RS-2022-00156360).\nReferences\nSahar Abdelnabi, Rakibul Hasan, and Mario Fritz.\n2022. Open-domain, content-based, multi-modal\nfact-checking of out-of-context images via online\nresources. In Proceedings of the IEEE/CVF Confer-\nence on Computer Vision and Pattern Recognition ,\npages 14940\u201314949.\nStanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-\ngaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and\nDevi Parikh. 2015. Vqa: Visual question answering.\nInProceedings of the IEEE international conference\non computer vision , pages 2425\u20132433.\nMin Cao, Shiping Li, Juntao Li, Liqiang Nie, and Min\nZhang. 2022. Image-text retrieval: A survey on re-\ncent research and development. Proceedings of the\nThirty-First International Joint Conference on Artifi-\ncial Intelligence (IJCAI-22) Survey Track .\nXinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakr-\nishna Vedantam, Saurabh Gupta, Piotr Doll\u00e1r, and\nC Lawrence Zitnick. 2015. Microsoft coco captions:\nData collection and evaluation server. arXiv preprint\narXiv:1504.00325 .\nYen-Chun Chen, Linjie Li, Licheng Yu, Ahmed\nEl Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and\nJingjing Liu. 2020. Uniter: Universal image-text\nrepresentation learning. In European conference on\ncomputer vision , pages 104\u2013120. Springer.\nHyewon Choi, Yejun Yoon, Seunghyun Yoon, and Kun-\nwoo Park. 2022. How does fake news use a thumb-\nnail? CLIP-based multimodal detection on the unrep-\nresentative news image. In Proceedings of the Work-\nshop on Combating Online Hostile Posts in Regional\nLanguages during Emergency Situations , pages 86\u2013\n94, Dublin, Ireland. Association for Computational\nLinguistics.\nWenliang Dai, Junnan Li, Dongxu Li, Anthony Tiong,\nJunqi Zhao, Weisheng Wang, Boyang Li, Pascale\nFung, and Steven Hoi. 2023. InstructBLIP: Towards\ngeneral-purpose vision-language models with instruc-\ntion tuning. In Thirty-seventh Conference on Neural\nInformation Processing Systems .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimCSE: Simple contrastive learning of sentence em-\nbeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 6894\u20136910, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nMaur\u00edcio Gruppi, Benjamin D Horne, and Sibel Adal\u0131.\n2022. Nela-gt-2021: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. ArXiv preprint , abs/2203.05659.\nSuchin Gururangan, Ana Marasovi \u00b4c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A. Smith. 2020. Don\u2019t stop pretraining:\nAdapt language models to domains and tasks. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n8342\u20138360, Online. Association for Computational\nLinguistics.\nXiaoshuai Hao, Yi Zhu, Srikar Appalaraju, Aston Zhang,\nWanqian Zhang, Bo Li, and Mu Li. 2023. Mixgen: A\nnew multi-modal data augmentation. In Proceedings\nof the IEEE/CVF Winter Conference on Applications\nof Computer Vision (WACV) Workshops , pages 379\u2013\n389.\nAlfred Hermida, Fred Fletcher, Darryl Korell, and\nDonna Logan. 2012. Share, like, recommend: De-\ncoding the social media news consumer. Journalism\nstudies , 13(5-6):815\u2013824.\nJack Hessel, Ari Holtzman, Maxwell Forbes, Ronan\nLe Bras, and Yejin Choi. 2021. CLIPScore: A\nreference-free evaluation metric for image captioning.\nInProceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n7514\u20137528, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nMinyoung Huh, Andrew Liu, Andrew Owens, and\nAlexei A Efros. 2018. Fighting fake news: Image\nsplice detection via learned self-consistency. In Pro-\nceedings of the European conference on computer\nvision (ECCV) , pages 101\u2013117.\nChao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana\nParekh, Hieu Pham, Quoc V . Le, Yun-Hsuan Sung,\nZhen Li, and Tom Duerig. 2021. Scaling up vi-\nsual and vision-language representation learning with\nnoisy text supervision. In Proceedings of the 38th In-\nternational Conference on Machine Learning, ICML\n2021, 18-24 July 2021, Virtual Event , volume 139 of\nProceedings of Machine Learning Research , pages\n4904\u20134916. PMLR.\nH\u00e9l\u00e8ne Joffe. 2008. The power of visual material:\nPersuasion, emotion and identification. Diogenes ,\n55(1):84\u201393.Chei Sian Lee and Long Ma. 2012. News sharing in\nsocial media: The effect of gratifications and prior ex-\nperience. Computers in human behavior , 28(2):331\u2013\n339.\nJinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, Blair Chen,\nDaniel Cer, Jeremy R. Cole, Kai Hui, Michael\nBoratko, Rajvi Kapadia, Wen Ding, Yi Luan, Sai\nMeher Karthik Duddu, Gustavo Hernandez Abrego,\nWeiqiang Shi, Nithi Gupta, Aditya Kusupati, Pra-\nteek Jain, Siddhartha Reddy Jonnalagadda, Ming-Wei\nChang, and Iftekhar Naim. 2024. Gecko: Versatile\ntext embeddings distilled from large language mod-\nels.\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.\n2023. Blip-2: Bootstrapping language-image pre-\ntraining with frozen image encoders and large lan-\nguage models. In International conference on ma-\nchine learning , pages 19730\u201319742. PMLR.\nJunnan Li, Dongxu Li, Caiming Xiong, and Steven\nHoi. 2022a. Blip: Bootstrapping language-image\npre-training for unified vision-language understand-\ning and generation. In International Conference on\nMachine Learning , pages 12888\u201312900. PMLR.\nJunnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare,\nShafiq Joty, Caiming Xiong, and Steven Chu Hong\nHoi. 2021a. Align before fuse: Vision and language\nrepresentation learning with momentum distillation.\nAdvances in neural information processing systems ,\n34:9694\u20139705.\nWei Li, Can Gao, Guocheng Niu, Xinyan Xiao, Hao\nLiu, Jiachen Liu, Hua Wu, and Haifeng Wang. 2021b.\nUNIMO: Towards unified-modal understanding and\ngeneration via cross-modal contrastive learning. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers) , pages 2592\u2013\n2607, Online. Association for Computational Lin-\nguistics.\nYangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui,\nWanli Ouyang, Jing Shao, Fengwei Yu, and Jun-\njie Yan. 2022b. Supervision exists everywhere: A\ndata efficient contrastive language-image pre-training\nparadigm. In International Conference on Learning\nRepresentations .\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae\nLee. 2024. Visual instruction tuning. Advances in\nneural information processing systems , 36.\nAndreas Lommatzsch, Benjamin Kille, \u00d6zlem \u00d6zg\u00f6bek,\nYuxiao Zhou, Jelena Te\u0161i \u00b4c, Cl\u00e1udio Bartolomeu,\nDavid Semedo, Lidia Pivovarova, Mingliang Liang,\nand Martha Larson. 2022. Newsimages: addressing\nthe depiction gap with an online news dataset for text-\nimage rematching. In Proceedings of the 13th ACM\nMultimedia Systems Conference , page 227\u2013233, New\nYork, NY , USA. Association for Computing Machin-\nery.\nJiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.\n2019. Vilbert: Pretraining task-agnostic visiolinguis-\ntic representations for vision-and-language tasks. Ad-\nvances in neural information processing systems , 32.\nGrace Luo, Trevor Darrell, and Anna Rohrbach. 2021.\nNewsCLIPpings: Automatic Generation of Out-of-\nContext Multimodal Media. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing , pages 6801\u20136817, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nShreyash Mishra, S Suryavardan, Amrit Bhaskar, Parul\nChopra, Aishwarya Reganti, Parth Patwa, Amitava\nDas, Tanmoy Chakraborty, Amit Sheth, Asif Ekbal,\net al. 2022. Factify: A multi-modal fact verification\ndataset. In Proceedings of the First Workshop on Mul-\ntimodal Fact-Checking and Hate Speech Detection\n(DE-FACTIFY) .\nEric M\u00fcller-Budack, Jonas Theiner, Sebastian Diering,\nMaximilian Idahl, and Ralph Ewerth. 2020. Multi-\nmodal analytics for real-world news using measures\nof cross-modal entity consistency. In Proceedings\nof the 2020 International Conference on Multimedia\nRetrieval , pages 16\u201325.\nEryn J Newman, Maryanne Garry, Daniel M Bernstein,\nJustin Kantner, and D Stephen Lindsay. 2012. Non-\nprobative photographs (or words) inflate truthiness.\nPsychonomic Bulletin & Review , 19:969\u2013974.\nEryn J Newman and Lynn Zhang. 2020. How non-\nprobative photos shape belief. Cognitive Science ,\npage 90.\nSosuke Nishikawa, Ryokan Ri, Ikuya Yamada, Yoshi-\nmasa Tsuruoka, and Isao Echizen. 2022. EASE:\nEntity-aware contrastive learning of sentence em-\nbedding. In Proceedings of the 2022 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , pages 3870\u20133885, Seattle, United States.\nAssociation for Computational Linguistics.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. ArXiv preprint , abs/1807.03748.\nNelleke Oostdijk, Hans van Halteren, Erkan Ba s,ar, and\nMartha Larson. 2020. The connection between the\ntext and images of news articles: New insights for\nmultimedia analysis. In Proceedings of the Twelfth\nLanguage Resources and Evaluation Conference ,\npages 4343\u20134351, Marseille, France. European Lan-\nguage Resources Association.\nOpenAI. 2023. Gpt-4v(ision) system card.\nKunwoo Park, Haewoon Kwak, Jisun An, and Sanjay\nChawla. 2021a. How-to present news on social me-\ndia: A causal analysis of editing news headlines for\nboosting user engagement. In ICWSM , pages 491\u2013\n502.Kunwoo Park, Zhufeng Pan, and Jungseock Joo. 2021b.\nWho blames or endorses whom? entity-to-entity di-\nrected sentiment extraction in news text. In Find-\nings of the Association for Computational Linguis-\ntics: ACL-IJCNLP 2021 , pages 4091\u20134102.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-\ntry, Amanda Askell, Pamela Mishkin, Jack Clark,\nGretchen Krueger, and Ilya Sutskever. 2021. Learn-\ning transferable visual models from natural language\nsupervision. In Proceedings of the 38th International\nConference on Machine Learning, ICML 2021, 18-24\nJuly 2021, Virtual Event , volume 139 of Proceedings\nof Machine Learning Research , pages 8748\u20138763.\nPMLR.\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018. Improving language under-\nstanding by generative pre-training.\nAnku Rani, S.M Towhidul Islam Tonmoy, Dwip Dalal,\nShreya Gautam, Megha Chakraborty, Aman Chadha,\nAmit Sheth, and Amitava Das. 2023. FACTIFY-\n5WQA: 5W aspect-based fact verification through\nquestion answering. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , pages 10421\u2013\n10440, Toronto, Canada. Association for Computa-\ntional Linguistics.\nJoshua David Robinson, Ching-Yao Chuang, Suvrit Sra,\nand Stefanie Jegelka. 2021. Contrastive learning with\nhard negative samples. In International Conference\non Learning Representations .\nAndreas Rossler, Davide Cozzolino, Luisa Verdoliva,\nChristian Riess, Justus Thies, and Matthias Nie\u00dfner.\n2019. Faceforensics++: Learning to detect manipu-\nlated facial images. In Proceedings of the IEEE/CVF\ninternational conference on computer vision , pages\n1\u201311.\nChristoph Schuhmann, Romain Beaumont, Richard\nVencu, Cade W Gordon, Ross Wightman, Mehdi\nCherti, Theo Coombes, Aarush Katta, Clayton Mullis,\nMitchell Wortsman, et al. 2022. Laion-5b: An open\nlarge-scale dataset for training next generation image-\ntext models. In Thirty-sixth Conference on Neural\nInformation Processing Systems Datasets and Bench-\nmarks Track .\nKiwon Seo. 2020. Meta-analysis on visual persuasion\u2013\ndoes adding images to texts influence persuasion.\nAthens Journal of Mass Media and Communications ,\n6(3):177\u2013190.\nPiyush Sharma, Nan Ding, Sebastian Goodman, and\nRadu Soricut. 2018. Conceptual captions: A cleaned,\nhypernymed, image alt-text dataset for automatic im-\nage captioning. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 2556\u20132565,\nMelbourne, Australia. Association for Computational\nLinguistics.\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-\nwon Lee, and Huan Liu. 2020. Fakenewsnet: A data\nrepository with news content, social context, and spa-\ntiotemporal information for studying fake news on\nsocial media. Big data , 8(3):171\u2013188.\nThe Associate Press. 2022. The AP Stylebook: 2022-\n2024 . Basic Books.\nYash Verma, Anubhav Jangra, Raghvendra Verma, and\nSriparna Saha. 2023. Large scale multi-lingual multi-\nmodal summarization dataset. In Proceedings of the\n17th Conference of the European Chapter of the As-\nsociation for Computational Linguistics , pages 3620\u2013\n3632, Dubrovnik, Croatia. Association for Computa-\ntional Linguistics.\nNing Xie, Farley Lai, Derek Doran, and Asim Ka-\ndav. 2019. Visual entailment: A novel task for\nfine-grained image understanding. arXiv preprint\narXiv:1901.06706 .\nBarry Menglong Yao, Aditya Shah, Lichao Sun, Jin-Hee\nCho, and Lifu Huang. 2023. End-to-end multimodal\nfact-checking and explanation generation: A chal-\nlenging dataset and models. In Proceedings of the\n46th International ACM SIGIR Conference on Re-\nsearch and Development in Information Retrieval ,\npages 2733\u20132743.\nDong Yao, Zhou Zhao, Shengyu Zhang, Jieming Zhu,\nYudong Zhu, Rui Zhang, and Xiuqiang He. 2022.\nContrastive learning with positive-negative frame\nmask for music representation. In Proceedings of\nthe ACM Web Conference 2022 , pages 2906\u20132915.\nChunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,\nJiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping\nYu, Lili Yu, et al. 2024. Lima: Less is more for align-\nment. Advances in Neural Information Processing\nSystems , 36.\nDimitrina Zlatkova, Preslav Nakov, and Ivan Koychev.\n2019. Fact-checking meets fauxtography: Verify-\ning claims about images. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP) , pages 2099\u20132108, Hong Kong,\nChina. Association for Computational Linguistics.\nAppendix\nA Unlabeled data characteristics\nTable A1 shows the data characteristics for the un-\nlabeled train dataset. In reference to Table 1, we\nfound that the labeled data follows a similar distri-\nbution to the unlabeled NELA across various di-\nmensions. The labeled summary text tends to have\ndifferent characteristics from the unlabeled BBC\nsummary dataset because the former was generated\nby GPT yet the latter is written by the news editor.NELA BBC\nTitle Title Summary\nWords 14.3 9.3 25.4\nNouns 3.24 2.56 5.22\nVerbs 1.67 1.07 2.44\nAdjectives 0.94 0.61 1.54\nNamed entities 2.14 1.73 2.71\nTable A1: Data distribution\nB Configuration details\nWe ran experiments on a machine equipped with\nAMD Ryzen Threadripper Pro 5975WX CPU,\nthree Nvidia RTX A6000 GPUs (48GB per GPU),\nand 256GB RAM. We trained the models with the\nAdamW optimizer with the initial learning rate of\n1e-4, updated by the cosine annealing scheduler.\nThe minibatch size is 128. The temperature \u03c4in the\nloss equation is 0.05, following Gao et al. (2021).\nOther hyperparameters were optimized by random\nsearch using a validation set. Model training was\nearly-stopped when the validation loss was not de-\ncreased five times consecutively, measured for ev-\nery 20 iterations. The experiments were conducted\non Python 3.9, Pytorch 1.10.1, Transformers 4.29.2,\nLA VIS 1.0.2, and SentenceTransformer 2.2.2. Five\nrandom seeds were used for repeated experiments:\n0, 1, 2, 3, and 4. The temperature used for adjusting\nthe masked token prediction is set as 2.0.\nThe pretrained model checkpoints used for the\nexperiments are as follows:\n\u2022CLIP: https://huggingface.co/openai/\nclip-vit-large-patch14\n\u2022 BLIP: blip_base (LA VIS)\n\u2022 BLIP-2: blip2_pretrain (LA VIS)\n\u2022BLIP-2 +SBERT: pretrain_opt2.7b (LA VIS),\nall-MiniLM-L6-v2 (SentenceTransformer)\n\u2022Named Entity Recognizer: https://huggin\ngface.co/spacy/en_core_web_trf\n\u2022Masked Language Model: https://huggin\ngface.co/bert-base-uncased\nC Ablation experiments\nReference text We compared the performance\nof using news title and summary text as reference\ntextTin the zero-shot classifier. Table A2 presents\nthe results, showing that using the summary text\ncould achieve a better outcome. Thus, we used the\nsummary text for inference.\nT F1 Spearman\nSummary 0.815\u00b10.003 0.491\u00b10.005\nTitle 0.759 \u00b10.003 0.386 \u00b10.003\nTable A2: Performance by the reference text type during\ninference\nTransfer learning To understand whether the\nproposed contrastive learning framework can lead\nto a better model than the standard CLIP objec-\ntive without transfer learning, we conducted ex-\nperiments that update the parameters of a vision\nand language bi-encoder from scratch by the CLIP\nand CFT-CLIP objectives. We used the transformer\nmodels with the same architecture but with ran-\ndomly initialized parameters. We used the BBC\ndataset with summary text for training, and all pa-\nrameters were updated until the 20th epoch. The\nother settings remained the same as those used in\nthe main experiment. Table A3 shows the results,\nindicating that CFT-CLIP outperformed CLIP with\nan f1 of 0.703 and a Spearman coefficient of 0.06.\nThis suggests that contrasting with the counterfac-\ntual text can make the vision language bi-encoder\nlearn the cross-modal matching ability for the tar-\nget task. However, its performance was lower than\nthat of the pretrained CLIP reported in Table 2,\nwhich achieved an f1 of 0.763 and a Spearman co-\nefficient of 0.409. Given that the pretrained CLIP\nwas trained on a web-scaled dataset, we guess the\nperformance degradation originated from the scale\nof the pretraining corpus.\nModel F1 Spearman\nCFT-CLIP 0.703\u00b10.008 0.060 \u00b10.016\nCLIP 0.625 \u00b10.005 0.045 \u00b10.007\nTable A3: Results without transfer learning\nD Data examples\nD.1 Failed prediction\nTable A1 presents two examples where the CFT-\nCLIP model made a failed prediction. The first\nexample presents the false positive case where the\nmodel returns a high similarity score for the un-\nrepresentative thumbnail. The example on the right\nshows an error case where referring to external\nknowledge is required. The person in the image isGlenn Youngkin, the governor of Virginia in the\nUS. A model could not return a high similarity\nscore without knowing his background.\nD.2 Counterfactual text\nTable A4 presents several examples derived from\nour counterfactual text generation method. Over-\nall, the proposed method successfully generates the\ncounterfactual text by selecting appropriate entities\nand substituting them with other entities. On the\nother hand, there are several cases where the gen-\nerated token breaks the grammar. For instance, in\nthe fourth example, the term \u2018Oisin Murphy\u2019 was\nreplaced by \u2018offensive.\u2019 Such anomalies may arise\nfrom the sampling process employed, which aims\nto prevent the recreation of the original text. De-\nspite its imperfect structure, the generated sentence\ncan still serve as a hard negative sample during\ncontrastive update, given that its general context is\npreserved.\nE API usage details\nWe used OpenAI API to use GPT 3.5-Turbo. We\nobtained news summaries for the labeled dataset\nand generated counterfactual text for the summary\ntext of the BBC unlabeled pretraining corpus. In to-\ntal, the API call cost $13.33. Below are the prompts\nused in the experiments.\nNews summarization\nArticle:{text}\nSummarize the article in one sentence.\nCounterfactual text generation\nCreate a counterfactual news summary by modi-\nfying the actors of news events:{text}\nAnswer in JSON. The JSON should be a string of\ndictionaries whose keys are \"counterfactual\".\nF Annotation details and guidelines\nWe hired two male and one female student from\nSoongsil University. The annotators were trained\nby using the guidelines in Table A5. The original\nguideline was in another language, and we present\nits English-translated version. All the annotators\nwere paid $0.1 per example.\nFigure A1: More error examples\nOriginal text Generated text\nOp-Ed: Memo to Saddleback Church: Replacing Pastor\nRick Warren is a minefieldOp-Ed: Memo to Saddleback Church: Replacing Pastor\nParker is a minefield\n\u2018The greatest striker\u2019: Gerd M\u00fcller, legendary German\nforward, dies aged 75\u2018The greatest striker\u2019: Joseph, legendary German forward,\ndies aged 75\nMatt Gaetz and wingman facing \u2019mutually assured de-\nstruction\u2019 after confession letter: legal expertPennant and wingman facing \u2019mutually assured destruc-\ntion\u2019 after confession letter: legal expert\nWilliam Buick treble sets up Flat jockeys\u2019 title race for\ndramatic finish as gap closes on Oisin MurphyDavid son treble sets up Flat jockeys\u2019 title race for dra-\nmatic finish as gap closes on offensive\nMichael Douglas says it was \u2018uncomfortable\u2019 for him\nand Catherine Zeta-Jones to share Mallorcan home with\nhis exNovella says it was \u2018uncomfortable\u2019 for him and Cather-\nine Zeta-Jones to share Mallorcan home with his ex\nExperts say Jussie Smol lett is in \u2018matrix of arrogance\u2019\nas he awaits sentencingExperts say Toni is in \u2018matrix of arrogance\u2019 as he awaits\nsentencing\nTedNugent tests positive for coronavirus after calling\npandemic a \u2018scam\u2019Danny tests positive for coronavirus after calling pan-\ndemic a \u2018scam\u2019\nJennifer Anis ton Explained How Therapy Helps Her\nDeal With The \"Tough Stuff\" Of Being FamousCharles Explained How Therapy Helps Her Deal With\nThe \"Tough Stuff\" Of Being Famous\nThousands mark anniversary of Kremlin critic\nNemtsov\u2019s murderThousands mark anniversary of Kremlin critic pastor\u2019s\nmurder\nNets Disregard AG Garland Grilled in Hearing for Tar-\ngeting ParentsNets Disregard AG Cicero Grilled in Hearing for Target-\ning Parents\nTravis Kelce Is Borderline Unrecognizable Without Fa-\ncial HairAnnie Is Borderline Unrecognizable Without Facial Hair\nBillionaire Ken Griffin bought a copy of the US Consti-\ntution for $43.2m because his son asked him toBillionaire Dublin bought a copy of the US Constitution\nfor $43.2m because his son asked him to\nDesperate Chuck Todd Hopes Trump Will Deflect Media\n\u2018Spotlight\u2019 From Dem \u2018Problems\u2019Desperate Joe Hopes Radha Will Deflect Media\n\u2018Spotlight\u2019 From Dem \u2018Problems\u2019\nChris Cuomo\u2019s Book Contract Dropped By Harper-\nCollinsHarriet Book Contract Dropped By HarperCollins\nJenPsaki shoots down a reporter comparing Biden to his\npredecessor: Trump suggested \u2018people inject bleach\u2019person shoots down a reporter comparing virus to his\npredecessor: Walden suggested \u2018people inject bleach\u2019\nWhat\u2019s the Deal With Gavin Newsom? 5 Plausible The-\nories To Explain His Mysterious HiatusWhat\u2019s the Deal With diplo macy? 5 Plausible Theories\nTo Explain His Mysterious Hiatus\nTable A4: Counterfactual text generation examples\nTask overview:\nIn this task, you are asked to answer whether a given news image represents the actors of the news events.\nInstruction:\n- Q1. Identify news actors in the text. The actors can be expressed as named entities, proper nouns, or\ncommon nouns.\n- Q2. Does the image display the news actors identified in Q1?\n- Q3. Identify the visually presented news actors in the image.\nExamples :\n- Q1: Trump, Impeachment Defense Team, David Schoen, Bruce Castor Jr., impeachment trial, disagree-\nments, legal strategy, United States Constitution, election fraud allegations\n- Q2: Y\n- Q3: Trump\n(More examples)\nTable A5: Translated annotation guideline", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Assessing News Thumbnail Representativeness: Counterfactual text can enhance the cross-modal matching ability", "author": ["Y Yoon", "S Yoon", "K Park"], "pub_year": "2024", "venue": "arXiv preprint arXiv:2402.11159", "abstract": "This paper addresses the critical challenge of assessing the representativeness of news  thumbnail images, which often serve as the first visual engagement for readers when an article"}, "filled": false, "gsrank": 547, "pub_url": "https://arxiv.org/abs/2402.11159", "author_id": ["Gpa1bAwAAAAJ", "UpymOMwAAAAJ", "xiZ1ImoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:N_umg-3lzE4J:scholar.google.com/&output=cite&scirp=546&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=N_umg-3lzE4J&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 1, "citedby_url": "/scholar?cites=5678166038486121271&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:N_umg-3lzE4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2402.11159"}}, {"title": "VaccinEU: COVID-19 vaccine conversations on Twitter in French, German and Italian", "year": "2022", "pdf_data": "VaccinEU: COVID-19 Vaccine Conversations on Twitter\nin French, German and Italian\nMarco Di Giovanni1, 3,*, Francesco Pierri1,2,*Christopher Torres-Lugo2and Marco Brambilla1\n1Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Italy\n2Observatory on Social Media, Indiana University, Bloomington, USA\n3Universit `a di Bologna, Italy\nfrancesco.pierri@polimi.it\nAbstract\nDespite the increasing limitations for unvaccinated people,\nin many European countries there is still a non-negligible\nfraction of individuals who refuse to get vaccinated against\nSARS-CoV-2, undermining governmental efforts to eradi-\ncate the virus. We study the role of online social media in\ninfluencing individuals\u2019 opinion towards getting vaccinated\nby designing a large-scale collection of Twitter messages\nin three different languages \u2013 French, German and Italian\n\u2013 and providing public access to the data collected. Focus-\ning on the European context, our VaccinEU dataset aims to\nhelp researchers to better understand the impact of online\n(mis)information about vaccines and design more accurate\ncommunication strategies to maximize vaccination coverage.\nData can be fully accessed in a Dataverse repository and a\nGitHub repository.\nIntroduction\nLess than a year into the COVID-19 pandemic, the first vac-\ncine was approved and made available to the public1, provid-\ning an effective tool to fight the spread of the virus (Oren-\nstein and Ahmed 2017). Vaccination programs started to-\nwards the end of 2020 in most European countries, and as\nof December 2021 over 700 M doses have been adminis-\ntered according to Our World in Data2. However, despite the\nlarge availability of vaccines, vaccine uptake exhibits a large\nvariability across different countries, ranging from 40% of\npeople vaccinated with at least one dose in Romania to 90%\nin Portugal3. This indicates that a considerable number of\npeople are still hesitant to get vaccinated, and that it will be\nhard to reach herd immunity .\nResearch in the past highlighted the role of online social\nmedia in promoting and amplifying negative views about\nvaccines (Burki 2019; Broniatowski et al. 2018; Johnson\net al. 2020). Specifically to the COVID-19 pandemic, con-\ncern has recently risen around the \u2019infodemic\u2019 (Zarocostas\n*These authors contributed equally.\nCopyright \u00a9 2022, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n1https://www.fda.gov/news-events/press-announcements/fda-\napproves-first-covid-19-vaccine\n2https://ourworldindata.org/covid-vaccinations\n3https://vaccinetracker.ecdc.europa.eu/public/extensions/COVID-\n19/vaccine-tracker.html2020; Yang et al. 2021; Gallotti et al. 2020) of misleading\ninformation about the virus spreading online, and it has been\nshown that online misinformation might negatively influ-\nence individuals\u2019 opinion towards getting vaccinated (Pierri\net al. 2021a; Loomba et al. 2021).\nIn this paper, we describe a data resource which will al-\nlow researchers and academics to study the impact of online\nconversations about COVID-19 vaccines on Twitter in three\ndifferent languages: French, German, and Italian.\nSpecifically to the Italian context, Righetti (2020) and\nCossard et al. (2020) analyzed the debate on Twitter around\nthe 2017 mandatory child vaccination law, observing the\nspread of problematic information and highlighting the pres-\nence of echo chamber effects (Cinelli et al. 2021). Gargiulo\net al. (2020) obtained similar results when analyzing French\ndata, finding that defenders and critics of vaccines focus on\ndifferent topics, and that, while there are more defenders,\ncritics are more active and coordinated. To the best of our\nknowledge, there is no previous work which analyzes vac-\ncine conversations on social media in German langauge.\nOur contribution is manifold. We curated a list of vaccine-\nrelated keywords as complete as possible with the help of na-\ntive speakers, using a snowball sampling approach (DeVerna\net al. 2021), and collected over 70 million tweets in three\ndifferent languages, from November 1st 2020 to November\n15th 2021, using a combination of streaming and historical\nsearch Twitter APIs. To the best of our knowledge there are\nno such datasets publicly available, with the only exception\nof VaccinItaly (Pierri et al. 2021b) in Italian language. We\nprovide public access to this data in agreement with Twit-\nter terms of service by releasing idsof tweets which can be\nused to retrieve full objects via APIs. For each language,\nwe further collected a list of hashtags which strongly state\na stance in favor or against vaccination, and we manually\nannotated a random sample of 1,000 tweets with four labels\n(Pro-vaccines, Anti-Vaccines, Neutral, Out-of-context). We\nprovide full access to this metadata, which can be used to\nbetter understand the polarized debate around vaccinations\nand train machine learning classifiers to automatically detect\nanti-vaccination messages (Di Giovanni et al. 2021). Finally,\nwe provide some preliminary analyses of the dataset in terms\nof volumes, hashtags, sources, geolocation and coordinated\nactivity.\nThe outline of the paper is the following: we first overview\nProceedings of the Sixteenth International AAAI Conference on Web and Social Media (ICWSM 2022)\n1236\nexisting datasets which relate to our work. Then, we describe\nin detail the data collection process. Next, we provide some\npreliminary analyses of the data, leaving more sophisticated\nanalyses for future work. Finally, we discuss limitations and\npotential uses of this dataset.\nRelated Datasets\nHere we describe some public data resources recently re-\nleased to study conversations around COVID-19 vaccines on\nsocial media.\nAt the beginning of 2021, DeVerna et al. (2021) released\nthe first Twitter dataset conceived to investigate English\nlanguage online conversations around COVID-19 vaccines.\nThey used a snowball sampling approach to curate a list as\ncomplete as possible of terms related to vaccines, and they\nprovide public access to idsof tweets collected since the be-\nginning of January 2020. They also have an associated on-\nline dashboard (CoVaxxy4), where they provide an interac-\ntive visualization of the relationship between online misin-\nformation spreading on Twitter and the evolution of the US\nvaccination program. Associations between online misinfor-\nmation and vaccine hesitancy were reported in Pierri et al.\n(2021a) leveraging their data.\nPierri et al. (2021b) released a public dataset of Italian\nlanguage tweets related to vaccines and collected since De-\ncember 2020 to October 20215. They also set-up a collection\nof public posts about vaccines shared by public Facebook\npages and groups and gathered through Crowdtangle. Simi-\nlar to CoVaxxy, they provide an online dashboard where they\nshow visualizations of the interplay between Twitter conver-\nsations and the vaccination program in Italy6.\nMuric, Wu, and Ferrara (2021) focused on antivaccine\nnarratives on Twitter and publicly released two data col-\nlections, one streaming keyword\u2013centered with more than\n1.8 million tweets, and another historical account\u2013level col-\nlection with more than 135 million tweets. Both collections\nare based on English language keywords. They showed that\nTwitter users who engaged the most in antivaccination narra-\ntives are politically right-wing leaning, and that questionable\nnews sources are very active in promoting negative views\nabout vaccines.\nHayawi et al. (2021) focused on online misinformation\naround COVID-19 vaccines. After collecting over 15 million\ntweets, they manually labeled a sample of 15k tweets with\nthe help of medical experts in order to identify unsubstan-\ntiated claims and misleading information about vaccines.\nThey eventually trained and test machine learning classifiers\non these tweets, reaching up to 98% of F1-score in the task\nof classifying vaccine misinformation.\nIn addition to the aforementioned resources, several\ndatasets have been released to study the COVID-19 pan-\ndemic on Twitter, providing oftentimes useful metadata (ge-\nolocation, sentiment, gender, etc) in addition to raw tweet ids\n(Banda et al. 2021; Chen et al. 2020; Lopez and Gallemore\n2021; Imran, Qazi, and Ofli 2021).\n4https://osome.iu.edu/tools/covaxxy\n5https://github.com/frapierri/VaccinItaly\n6http://genomic.elet.polimi.it/vaccinitaly/\nFigure 1: Daily number of vaccine-related tweets collected\nin different languages (left y-axis), along with the daily\nnumber of doses administered per million population (right\ny-axis) in several European countries (Austria, Belgium,\nFrance, Germany and Italy). All time series are smoothed\nwith a 7-day average. Daily vaccinations are obtained from\nOur World in Data (Mathieu et al. 2021) and correspond to\nthe average over different countries with 95% C.I. Vertical\ndashed lines indicate the beginning of the streaming collec-\ntion for France and Germany (red) and Italy (brown).\nData Collection\nIn this section, we describe our data collection process. We\ndetail every design choice made to obtain a dataset as com-\nplete and unbiased as possible.\nTwitter APIs\nWe use both the standard streaming Filter API v1.17and the\nnew historical Search API v28to collect tweets related to\nvaccines in three different languages: French, German, and\nItalian.\nThe Filter API filters tweets that match a defined query in\na real-time fashion, up to 1% of the global stream. Approxi-\nmately 500 million tweets are shared every day on Twitter9,\nand as shown in Figure 1 we collected at most 350k tweets in\na day, thus we likely never incur in this limitation. We started\nthe streaming collection of German and French tweets on\nJuly 1st, 2021 and Italian tweets on July 14th, 2021. We fil-\ntered tweets by language specifying the lang parameter in\nthe queries.\nWe experienced network malfunctioning issues in some\ncases, and to fill them we used the Historical Search API,\nwhich was released at the beginning of 2021, that allows\n7https://developer.twitter.com/en/docs/twitter-\napi/v1/tweets/filter-realtime/overview\n8https://developer.twitter.com/en/docs/twitter-\napi/tweets/search/introduction\n9https://www.internetlivestats.com/twitter-statistics/\n1237\nFigure 2: Percentage of tweets successfully retrieved using\ntheGET statuses/lookup endpoint. Each point corresponds\nto a different week, for which we extract a random sample\nof 10k tweets which we attempt to retrieve. The procedure\nwas done on December 16th, 2021.\nacademics and researchers to perform a full-archive search\nwith a set of selected keywords. We also employed it to re-\ncover all tweets shared since November 1st, 2020 to June\n30th, 2021 (N.B. July 13th for the Italian language).\nWe remark that data collected through the historical\nSearch is not complete, due to Twitter\u2019s Terms of Service.\nTwitter does not allow to retrieve deleted tweets nor those\nshared by protected or suspended accounts10. Nevertheless,\nwe believe that it is still useful to obtain a collection of\nvaccine-related tweets as complete as possible. To provide\na rough estimate of the amount of tweets that we might\nlose in the process, we hydrate a random selection of 10k\ntweets per week collected with the streaming API. We show\nthe percentage of tweets recovered running the GET sta-\ntuses/lookup endpoint on December 16th, 2021 in Figure 2.\nWe can see that we lost between 5 and 20% of shared tweets,\nand that this number likely increases as we search farther in\nthe past.\nQuery Keywords\nBoth Filter and Search APIs require one or more keywords\nto collect relevant tweets. An accurate selection of keyword\nis crucial to obtain a comprehensive dataset.\nWe iteratively selected the keywords with the help of three\nnative speakers for each language using a snowball sampling\napproach (DeVerna et al. 2021). We selected as initial set\nof keywords the translation of very generic vaccine-related\n10As a matter of fact, the streaming API also does not provide\ntweets which are shared by protected accounts.words such as \u201dvaccine\u201d and \u201dvaccination\u201d in French, Ger-\nman, and Italian. We made sure to include every grammat-\nically correct variation of words since Twitter APIs per-\nform case-independent exact match of keywords and the to-\nkenized texts of tweets (e.g., the tweet \u201dVaccines are neces-\nsary.\u201d will be selected if we include in our query the key-\nword \u201dvaccines\u201d, but it will not be collected when including\nthe keyword \u201dvaccine\u201d). This might be problematic for lan-\nguages like German, where words can appear with four dif-\nferent cases (nominative, accusative, dative, and genitive).\nAt each round, we used the historical API to filter tweets\nin the entire period November 2020 - June 2021, and we\ninspected the most frequent co-occurring words with those\nin the query. Then, we augmented our list of keywords with\nthose clearly related to vaccines, including specific hashtags,\nas indicated by native speakers. For instance, we include\n\u201d#Igetvaccinated\u201d because tweets containing this hashtag\nwill not be collected by simply using \u201dvaccinated\u201d as key-\nword.\nThe final list of keywords for each language is available\nin our Dataverse11.\nGold Hashtags\nThe goal of our project is to understand the influence of posi-\ntive and negative opinions about vaccines shared on Twitter.\nTo this aim, we collected sets of hashtags that indicate the\nstance (Pro or Anti vaccines) of tweets with high likelihood.\nWe define them as Gold Hashtags (GH), and similarly to our\nquery keywords, we used a snowball sampling approach to\nobtain a set of hashtags for each language with the help of\nannotators. We assume that tweets sharing one or more GH\nfrom the same stance express that specific view about vac-\ncines, but this might not always hold true.\nWe begun with the selection of one GH for each\nstance, respectively the translation in different languages\nof \u201dIwillgetvaccinated\u201d for Pro and \u201dIwillnotgetvaccinated\u201d\nfor Anti12. We iteratively added new GHs inspecting those\nthat co-occurred the most with the initial set of hashtags,\nbased on whether they clearly expressed a stance on vac-\ncines. We discarded hashtags when they generically referred\nto the topic of vaccines, but whose stance was unidentifi-\nable (such as #vaccine). We also discarded hashtags that,\nalthough their stance seemed clear to the annotators, highly\nco-occurred with GH of both stances. We iterated this pro-\ncedure three times. The final list of hashtags is available in\nour repository.\nTable 1 shows statistics of GHs. Manually inspecting a\nsmall set of tweets which included both a Pro and Anti GH,\nwe noticed that most often they do not state a clear stance\nand usually include questions and pools.\nGold Labels\nIn addition to hashtags which express a specific stance to-\nwards vaccines, we asked our native speakers to manu-\nally annotate a sample of random tweets. We randomly\n11https://doi.org/10.7910/DVN/NZUMZG\n12We checked that these hashtags were actually shared by Twit-\nter users in each language.\n1238\nGold Hashtags French\nGerman Italian\nPro 161,871 41,933\n53,374\nAnti 129,926 115,512\n83,097\nBoth 585 1,224\n451\nTable 1: Statistics of tweets sharing Gold Hashtags.\nGold Labels French\nGerman Italian\nPro-V accines 419 547\n314\nAnti-Vaccines 135 108\n151\nNeutral 279 169\n458\nOut-of-Context 167 176\n77\nTable 2: Statistics of manually annotated tweets.\nFrench German Italian\nTweets 38,198,048 15,573,108 16,581,210\nUsers 1,586,071 615,317 656,578\nURLs 4,749,359 2,808,657 2,686,055\nTable 3: Breakdown of the datasets in terms of unique\ntweets, users and URLs shared, for each language.\npicked 1,000 unique tweets for each language, thus discard-\ning retweets, and we asked two annotators to attach one\nof four \u201dGold Labels\u201d: Pro-vaccines, Anti-vaccines, Neu-\ntral, Out-of-Context. We gave them the following guide-\nlines: Pro- and Anti-vaccines tweets should clearly express\na stance about vaccines; Neutral tweets should not express\nany stance, or their stance is unclear; finally Out-of-Context\ntweets are tweets not related to COVID-19 vaccines (e.g.,\nanimal vaccines). A third annotator solved the conflicts by\npicking one of the two labels for the tweets when they did\nnot agree. We report statistics of the labels in Table 2.\nData Availability\nIn agreement with Twitter terms of service, we provide pub-\nlic access to the entire list of tweet idsin our Dataverse\ndataset13and Github repository14. These can be \u201dhydrated\u201d,\ni.e., fully retrieved using the GET statuses/lookup endpoint\nof Twitter API, unless they were deleted or their author sus-\npended in the meantime.\nIn addition to the raw list of ids, organized in daily files,\nwe provide the list of idsof tweets which contain Pro and\nAnti vaccine Gold Hashtags (as defined in previous subsec-\ntion). We also provide the text of tweets labelled using the\nfour Gold Labels defined in the previous subsection.\nData Characterization\nIn this section we provide descriptive statistics of the data\ncollected in terms of volumes, hashtags, news sources and\ngeolocation. These should be seen as potential uses of the\ndataset, whereas we leave more sophisticated analyses for\nfuture work. In Table 3 we provide basic statistics of the\ndata in terms of tweets, users and URLs for each language.\n13https://doi.org/10.7910/DVN/NZUMZG\n14https://github.com/DataSciencePolimi/VaccinEU\nFigure 3: Daily percentage of tweets and retweets sharing\npro and anti vaccine hashtags, respectively in blue and red,\nfor each language. We count tweets which contain only\nhashtags belonging to one of the two classes. Time series\nare smoothed with a 7-day average.\nVolumes\nIn Figure 1 we show the daily number of tweets collected for\neach language, highlighting with two vertical lines when the\nstreaming collection starts for French and German (July 1st\n2021), and for Italian (July 14th 2021). As a reference for the\nCOVID-19 vaccination programs, we show the daily num-\nber of vaccine doses administered (per 100 people) (Math-\nieu et al. 2021) averaged over different European countries\nwhere these languages are spoken, namely Austria, Bel-\ngium, France, Germany, and Italy.\nWe can see that overall the daily volume of French tweets\nis much higher compared to the other two languages, and\nthis might be due to the fact that it is more widespread, es-\npecially in the African continent (cf. also Table 3).\nWe bserve a peak of activity across all languages in Jan-\nuary, corresponding to the beginning of the vaccination pro-\ngram, and another one in March when alleged links be-\ntween the AstraZeneca vaccine and blood clots became vi-\nral in mainstream media. In summer there is an outstand-\ning increase of French and Italian tweets, probably linked to\nthe introduction of the restrictions for unvaccinated people,\nwhereas towards fall we can see that the topic is trending\nacross all languages (especially German) following a slight\nincrease in the number of vaccinations. In fact, there is a\nsignificant Pearson correlation between the daily volumes\nof tweets collected in different languages (in the range 0.56-\n0.71,P\u223c0).\n1239\nFigure 4: Daily percentage of tweets and retweets sharing\nlinks to low-credibility and mainstream news websites, re-\nspectively in red and blue, for each language. Time series\nare smoothed with a 7-day average. Dashed lines represent\nthe mean value over the entire period of observation.\nHashtags\nWhen we look at the top-10 most shared hashtags in\nthe three languages, we observe that they mostly con-\ntain generic references to the pandemic (e.g. \u201dvaccin\u201d,\n\u201dcovid19\u201d, \u201dcorona\u201d), the debate around the introduction\nof vaccination documents (e.g. \u201dpasssanitaire\u201d in French or\n\u201dgreenpass\u201d in Italian) and politicians (e.g. \u201dmacron\u201d and\n\u201ddraghi\u201d).\nIn Figure 3 we show instead the daily percentage of tweets\nsharing Pro and Anti vaccine Gold Hashtags (computed over\nthe total number of tweets shared in that day), using the list\nof GHs specified in the Data Collection section, for each\nlanguage. For each day we count tweets and retweets which\ncontain hashtags belonging to only one of the two classes.\nFor what concerns French, we notice a peak of activity for\nPro vaccine hashtags at the beginning of the campaign (Jan-\nuary 2021) and another in late summer, which follows a\nstrong peak of Anti vaccination hashtags. For what concerns\nGerman, we notice little sharing activity for Pro vaccine\nhashtags, whereas Anti vaccination ones exhibit a peak at\nthe beginning of summer, and then show an increasing trend\ntowards the beginning of fall. Finally, for what concerns Ital-\nian, we notice a large number of Italian Pro vaccine hashtags\nat the beginning of the campaign in January, and likewise in\ncorrespondence of the AstraZeneca blood clots \u2019event\u2019. To-\nwards summer, similarly to other langauges, we notice an\nincrease in the sharing of Anti vaccination hashtags. Over-\nall, daily volumes stay in a similar range across different\nlanguages (0-4%).News Sources\nWe now investigate the prevalence of low-credibility by us-\ning a source-based approach to label news articles, i.e., we\nlabel sources based on lists compiled by journalists, re-\nsearchers and fact-checkers and we propagate the label to\nall URLs linking to these websites. This approach is limited,\nsince not all stories published on a disinformation website\nare fake, but it is widely adopted in the literature to study\nlow-credibility content at scale (Yang et al. 2021; Bovet and\nMakse 2019; Shao et al. 2018; Caldarelli et al. 2021; Brena\net al. 2019). As a reference, we consider publishers of main-\nstream news as a proxy for reliable information similar to\n(Yang et al. 2021).\nSpecifically, we aggregate three different sources of la-\nbels:\n\u2022 a list of 60+ Italian low-credibility websites which were\nflagged by Italian fact-checkers and journalists for shar-\ning disinformation, misinformation, fake news, etc intro-\nduced in (Pierri, Artoni, and Ceri 2020) and employed\nin (Pierri 2020; Pierri, Piccardi, and Ceri 2020; Guar-\nino et al. 2021; Pierri et al. 2021b). It is available in our\nrepository.\n\u2022 a list of over 600 low-credibility domains based on infor-\nmation provided by the Media Bias/Fact Check website\n(MBFC, mediabiasfactcheck.com) (Yang et al. 2021). It\nis available in our repository.\n\u2022 a list of credibility scores in the range [0,100] provided\nby NewsGuard (https://www.newsguardtech.com/it/), a\njournalistic organization that rates websites on their ten-\ndency to spread true or false information. In particular,\nwe consider publishers with a score less than 60 as low-\ncredibility (as suggested by NewsGuard), and those with\na score higher than 60 as mainstream. We cannot disclose\nthis list because the data is proprietary.\nIn Figure 4 we show the daily percentage of tweets and\nretweets containing a link to low-credibility and mainstream\nnews websites. We can see that the amount of low-credibility\nis smaller yet non negligible compared to mainstream news.\nIt is also stationary around the mean value of the entire pe-\nriod (in the range [2.5%,4.8%]) in all languages, whereas\nmainstream coverage of vaccines exhibits a decreasing trend\ntowards summer for German and Italian. Interestingly, we\ncan notice that around October-November 2021 the amount\nof Italian misinformation circulating on Twitter was higher\nthan mainstream news. However, we remark that our lists are\nnot exhaustive, and that these estimations should be consider\nas a lower bound for both low-credibility and mainstream in-\nformation.\nWe further investigate which are the most shared low-\ncredibility news websites in different languages. In Figure\n5 we provide the Top-15 ranking of such websites. We\ncan see a similar prevalence on Twitter of most popular\nmisinformation websites, with the uppermost websites be-\ning shared over 100k times. In French: \u201dfrancesoir.fr\u201d is\na popular tabloid which has been criticised for publish-\ning false claims about the COVID-19 pandemic. In Ger-\nman: \u201dreitschuster.de\u201d is the blog of a political commentator\n(Boris Reitschuster) which has a borderline score according\n1240\nFigure 5: Top-10 most (re)tweeted low-credibility websites\nin different languages.to Newsguard (it\u2019s rated 59.5 out of 100) and that has been\nflagged for sharing misinformation about the pandemic. In\nItalian: \u201dimolaoggi.it\u201d is a news website which has been\nrepetitiously flagged for sharing hoaxes, misinformation and\nfake news. We leave further investigation of these websites\nfor future work.\nGeolocation\nWe used the methodology described in Mejova and Kourtel-\nlis (2021) to locate users in our dataset and estimate the ge-\nographical composition of the data collected for each lan-\nguage. This employs the GeoNames15location database to\nmatch the user-specified free-text location strings to a loca-\ntion. Not all users can be geolocated in this way, because\nmany do not put a string in the \u201dlocation\u201d field. We report\nthe following:\n\u2022 French: over 750k users and 17.4 million tweets are ge-\nolocated. Around 55% users are geolocated to France and\nare responsible for 67% of the geolocated tweets. Sec-\nond and third most frequent countries are United States\n(\u223c7% tweets) and Canada (\u223c 4% tweets).\n\u2022 German: over 270k users and 7.8 million tweets are ge-\nolocated. 66% of the users and tweets are geolocated in\nGermany. Second and third most frequent countries are\nAustria (\u223c 8% tweets) and Switzerland (\u223c 7.7% tweets).\n\u2022 Italian: over 290k users and 7.5 million tweets are ge-\nolocated. Around 52% of the users are geolocated to\nItaly, and they shared over 80% of the geolocated tweets.\nSecond and third most frequent countries are the United\nStates (\u223c 4%tweets) and France (\u223c 3% tweets).\nThe approach is not completely accurate, since it is based\non a simple string matching, but we can observe that indeed\nmost of the accounts are geolocated in the main countries\nwhere each language is spoken, namely France, Germany,\nand Italy. For what concerns French, we do not get a large\nnumber of users geolocated in African countries, but a fur-\nther investigation is needed to understand whether the ge-\nolocation technique is not working properly or Twitter is not\nvery used in those countries.\nCoordinated Activity\nIn this section we try to identify coordinated activity on\nthe dataset by applying a coordination detection framework\n(Pacheco et al. 2021). While coordination may occur over\nmany different possible dimensions, here we focus our at-\ntention on coordinated sharing of URLs. Other dimensions\ncould be explored to identify other coordinated accounts,\nbased for instance on shared hashtag and/or images.\nSpecifically, for each date in the period under analysis, we\nbuilt a bipartite network of users and URLs they shared on\nnative tweets (excl. retweets and quote retweets). Then, we\nprojected it to users such that two users would be connected\nif they shared the same URL. Edges between users are thus\nweighted by the number of same URLs that they shared.\n15The code for geolocation can be found at https://sites.google.\ncom/site/yelenamejova/resources\n1241\nTo focus on the most suspicious users, we filtered out\nedges with a weight smaller than 10, and removed singleton\nnodes resulting from this procedure. Finally, we aggregated\nall daily networks such that edge weights correspond to the\nnumber of days in which we found a pair of users sharing\nthe same URLs at least 10 times.\nThe resulting networks, one for each language, can be\nfound in Figure 6. The network for French has 1,888 nodes\nand 28,951 edges, for German it has 157 nodes and 236\nedges, and for Italian it has 392 nodes and 1,555 edges. The\nsize of nodes corresponds to the percentage of links to low-\ncredibility domains, as defined in the previous section, and\nedge are ranked by their weight, with thicker edges indicat-\ning a higher weight.\nThe Italian and French networks are dominated by a sin-\ngle large component. In contrast, the German one contains\ntwo large components. Of these two components, the one\non the bottom left is densely connected with thicker edges\nwhile the one in the middle is sparser with thinner edges.\nThis behavior makes the former more suspicious than the\nlatter. Additionally, all of these components exhibit dissim-\nilarities on uniformity or variety of low credibility sources\nshared. For example, the accounts found in the Italian net-\nwork shared a lower percentage of these sources compared\nto those in France network.\nConclusions\nWe presented a large-scale dataset of Twitter messages re-\nlated to vaccines in three different languages (French, Ger-\nman, and Italian), which allows to investigate the impact and\nthe influence of online conversations about COVID-19 vac-\ncines on social media.\nWe provided a few preliminary analyses of the dataset.\nWe showed that throughout 2021 there were a few peaks of\nattention around the topic in correspondence of the begin-\nning of vaccination programs, the AstraZeneca blood clots\nand the introduction of limitations for unvaccinated people.\nWe showed that hashtags expressing positive and negative\nviews about vaccines were highly shared in different peri-\nods depending on the language, and that online misinforma-\ntion accounts for around 5% of the tweets shared in each\nlanguage. We also showed that most of the users in our col-\nlection reside in three main countries: France, Germany, and\nItaly. We experimented with a coordinated activity frame-\nwork highlighting the presence of clusters of users promot-\ning anti-vaccination content in a coordinated fashion.\nThere a few limitations to our work. First, the procedure\nused to identify Twitter conversations about COVID-19 vac-\ncines involved a manual evaluation to determine relevant\nkeywords, and thus it might be unable to fully exclude irrel-\nevant data and/or conversations around vaccines which are\nnot COVID-19 specific (e.g. animals, MMR, etc). Still, it\nallows for further filtering and refinement at a later stage.\nSecond, Twitter users might not be a representative sam-\nple of the population, and their online activity might not re-\nflect the general public opinion (Wojick and Hughes 2020).\nBesides, according to the 2021 Reuters Digital News Re-\nFigure 6: Networks of coordinated accounts that shared the\nsame URLs at least 10 times on a daily basis, based respec-\ntively on French (top), German (center) and Italian (bottom)\ntweets.\n1242\nport16, Twitter was used respectively by 17% of the respon-\ndents in France, 6% in Germany and 8% in Italy for any pur-\npose. As a matter of fact, Facebook remains the most used\nsocial media platform (Boberg et al. 2020) in most countries,\nbut it does not allow to collect relevant data.\nThird, users cannot opt-out from our collection, and this\nmight raise important ethical concerns about anonymity.\nNevertheless, whenever a user deletes a tweet or account,\nthe related content will be unavailable in the re-hydration\nprocess.\nThere is a number of potential usages for this dataset. We\naim to explore the correlation between the prevalence of\nonline misinformation about vaccines (Pierri et al. 2021a)\nand public health outcomes (e.g. COVID-19 vaccine up-\ntake rates, hospitalizations, etc) in different countries. We\nalso plan to further investigate the presence of suspicious\naccounts, such as bots and trolls, and provide evidence\nof coordinated campaigns promoting anti-vaccine messages\n(Pacheco et al. 2021). Finally, we plan to build models to de-\nscribe how online vaccine misinformation and anti-vaccine\nsentiment spread in different countries.\nAcknowledgments\nThis work has been partially supported by the PRIN grant\nHOPE (FP6, Italian Ministry of Education), and the EU\nH2020 research and innovation programme, COVID-19\ncall, under grant agreement No. 101016233 \u201cPERISCOPE\u201d\n(https://periscopeproject.eu/). We are grateful to Lorenzo\nCorti, Andrea Tocchetti, Silvio Pavanetto, Pascal Garel,\nMoritz Laurer, and Anita Gottlob for helping in the selec-\ntion of relevant keywords, gold hashtags and for manually\nannotating tweets. Newsguard labels correspond to ratings\nreleased in September 2021.\nReferences\nBanda, J. M.; Tekumalla, R.; Wang, G.; Yu, J.; Liu, T.; Ding,\nY .; Artemova, E.; Tutubalina, E.; and Chowell, G. 2021. A\nlarge-scale COVID-19 Twitter chatter dataset for open sci-\nentific research\u2014an international collaboration. Epidemi-\nologia, 2(3): 315\u2013324.\nBoberg, S.; Quandt, T.; Schatto-Eckrodt, T.; and Frischlich,\nL. 2020. Pandemic populism: Facebook pages of alternative\nnews media and the corona crisis\u2013A computational content\nanalysis. arXiv preprint arXiv:2004.02566.\nBovet, A.; and Makse, H. A. 2019. Influence of fake news\nin Twitter during the 2016 US presidential election. Nature\nCommunications, 10(1): 7.\nBrena, G.; Brambilla, M.; Ceri, S.; Di Giovanni, M.; Pierri,\nF.; and Ramponi, G. 2019. News sharing user behaviour\non twitter: A comprehensive data collection of news arti-\ncles and social interactions. In Proceedings of the Inter-\nnational AAAI Conference on Web and Social Media, vol-\nume 13, 592\u2013597.\nBroniatowski, D. A.; Jamison, A. M.; Qi, S.; AlKulaib, L.;\nChen, T.; Benton, A.; Quinn, S. C.; and Dredze, M. 2018.\n16https://reutersinstitute.politics.ox.ac.uk/digital-news-\nreport/2021Weaponized health communication: Twitter bots and Rus-\nsian trolls amplify the vaccine debate. American journal of\npublic health, 108(10): 1378\u20131384.\nBurki, T. 2019. Vaccine misinformation and social media.\nThe Lancet Digital Health, 1(6): e258\u2013e259.\nCaldarelli, G.; De Nicola, R.; Petrocchi, M.; Pratelli, M.; and\nSaracco, F. 2021. Flow of online misinformation during the\npeak of the COVID-19 pandemic in Italy. EPJ data science,\n10(1): 34.\nChen, E.; Lerman, K.; Ferrara, E.; et al. 2020. Tracking\nsocial media discourse about the covid-19 pandemic: Devel-\nopment of a public coronavirus twitter data set. JMIR Public\nHealth and Surveillance, 6(2): e19273.\nCinelli, M.; Morales, G. D. F.; Galeazzi, A.; Quattrocioc-\nchi, W.; and Starnini, M. 2021. The echo chamber effect\non social media. Proceedings of the National Academy of\nSciences, 118(9).\nCossard, A.; Morales, G. D. F.; Kalimeri, K.; Mejova, Y .;\nPaolotti, D.; and Starnini, M. 2020. Falling into the echo\nchamber: the Italian vaccination debate on Twitter. In Pro-\nceedings of the International AAAI Conference on Web and\nSocial Media, volume 14, 130\u2013140.\nDeVerna, M.; Pierri, F.; Truong, B.; Bollenbacher, J.; Axel-\nrod, D.; Loynes, N.; Torres-Lugo, C.; Yang, K.-C.; Menczer,\nF.; and Bryden, J. 2021. CoVaxxy: A global collection of\nEnglish Twitter posts about COVID-19 vaccines. Proceed-\nings of the International AAAI Conference on Web and So-\ncial Media.\nDi Giovanni, M.; Corti, L.; Pavanetto, S.; Pierri, F.; Toc-\nchetti, A.; and Brambilla, M. 2021. A Content-based Ap-\nproach for the Analysis and Classification of Vaccine-related\nStances on Twitter: the Italian Scenario. Workshop Proceed-\nings of the International AAAI Conference on Web and So-\ncial Media.\nGallotti, R.; Valle, F.; Castaldo, N.; Sacco, P.; and\nDe Domenico, M. 2020. Assessing the risks of \u2018infodemics\u2019\nin response to COVID-19 epidemics. Nature Human Be-\nhaviour, 4: 1285\u20131293.\nGargiulo, F.; Cafiero, F.; Guille-Escuret, P.; Seror, V .; and\nWard, J. 2020. Asymmetric participation of defenders and\ncritics of vaccines to debates on French-speaking Twitter.\nScientific Reports, 10.\nGuarino, S.; Pierri, F.; Di Giovanni, M.; and Celestini, A.\n2021. Information disorders during the COVID-19 info-\ndemic: The case of Italian Facebook. Online Social Net-\nworks and Media, 22: 100124.\nHayawi, K.; Shahriar, S.; Serhani, M. A.; Taleb, I.; and\nMathew, S. S. 2021. ANTi-Vax: A Novel Twitter Dataset\nfor COVID-19 Vaccine Misinformation Detection. Public\nHealth.\nImran, M.; Qazi, U.; and Ofli, F. 2021. TBCOV: Two Bil-\nlion Multilingual COVID-19 Tweets with Sentiment, Entity,\nGeo, and Gender Labels. arXiv preprint arXiv:2110.03664\n- Forthcoming in Data.\nJohnson, N. F.; Vel \u00b4asquez, N.; Restrepo, N. J.; Leahy, R.;\nGabriel, N.; El Oud, S.; Zheng, M.; Manrique, P.; Wuchty,\n1243\nS.; and Lupu, Y . 2020. The online competition between pro-\nand anti-vaccination views. Nature, 1\u20134.\nLoomba, S.; de Figueiredo, A.; Piatek, S. J.; de Graaf, K.;\nand Larson, H. J. 2021. Measuring the impact of COVID-19\nvaccine misinformation on vaccination intent in the UK and\nUSA. Nature human behaviour, 5(3): 337\u2013348.\nLopez, C. E.; and Gallemore, C. 2021. An augmented mul-\ntilingual Twitter dataset for studying the COVID-19 info-\ndemic. Social Network Analysis and Mining, 11(1): 1\u201314.\nMathieu, E.; Ritchie, H.; Ortiz-Ospina, E.; Roser, M.;\nHasell, J.; Appel, C.; Giattino, C.; and Rod \u00b4es-Guirao, L.\n2021. A global database of COVID-19 vaccinations. Na-\nture human behaviour, 1\u20137.\nMejova, Y .; and Kourtellis, N. 2021. YouTubing at Home:\nMedia Sharing Behavior Change as Proxy for Mobility\nAround COVID-19 Lockdowns. In 13th ACM Web Sci-\nence Conference 2021, WebSci \u201921, 272\u2013281. New York,\nNY , USA: Association for Computing Machinery. ISBN\n9781450383301.\nMuric, G.; Wu, Y .; and Ferrara, E. 2021. COVID-19 Vaccine\nHesitancy on Social Media: Building a Public Twitter Data\nSet of Antivaccine Content, Vaccine Misinformation, and\nConspiracies. JMIR Public Health Surveill, 7(11): e30642.\nOrenstein, W. A.; and Ahmed, R. 2017. Simply put: Vacci-\nnation saves lives. Proceedings of the National Academy of\nSciences, 114(16): 4031\u20134033.\nPacheco, D.; Hui, P.-M.; Torres-Lugo, C.; Truong, B. T.;\nFlammini, A.; and Menczer, F. 2021. Uncovering Coordi-\nnated Networks on Social Media: Methods and Case Stud-\nies. In Proceedings of the International AAAI Conference on\nWeb and Social Media, volume 15, 455\u2013466.\nPierri, F. 2020. The diffusion of mainstream and disinfor-\nmation news on Twitter: the case of Italy and France. Com-\npanion Proceedings of the Web Conference 2020 (WWW \u201920\nCompanion).\nPierri, F.; Artoni, A.; and Ceri, S. 2020. Investigating Italian\ndisinformation spreading on Twitter in the context of 2019\nEuropean elections. PloS one, 15(1): e0227821.\nPierri, F.; Perry, B.; DeVerna, M. R.; Yang, K.-C.; Flammini,\nA.; Menczer, F.; and Bryden, J. 2021a. The impact of on-\nline misinformation on US COVID-19 vaccinations. arXiv\npreprint arXiv:2104.10635.\nPierri, F.; Piccardi, C.; and Ceri, S. 2020. A multi-layer ap-\nproach to disinformation detection in US and Italian news\nspreading on Twitter. EPJ Data Science, 9(35).\nPierri, F.; Tocchetti, A.; Corti, L.; Giovanni, M.; Pavanetto,\nS.; Brambilla, M.; and Ceri, S. 2021b. VaccinItaly: moni-\ntoring Italian conversations around vaccines on Twitter and\nFacebook. Workshop Proceedings of the International AAAI\nConference on Web and Social Media.\nRighetti, N. 2020. Health Politicization and Misinformation\non Twitter. A Study of the Italian Twittersphere from Before,\nDuring and After the Law on Mandatory Vaccinations. OSF\nPreprints, doi:10.31219/osf.io/6r95n.Shao, C.; Ciampaglia, G. L.; Varol, O.; Yang, K.-C.; Flam-\nmini, A.; and Menczer, F. 2018. The spread of low-\ncredibility content by social bots. Nature Communications,\n9: 4787.\nWojick, S.; and Hughes, A. 2020. Sizing Up Twitter\nUsers. Pew Research Center, https://www.pewresearch.org/\ninternet/2019/04/24/sizing-up-twitter-users/ (accessed Jan-\nuary, 2021).\nYang, K.-C.; Pierri, F.; Hui, P.-M.; Axelrod, D.; Torres-\nLugo, C.; Bryden, J.; and Menczer, F. 2021. The COVID-19\nInfodemic: Twitter versus Facebook. Big Data & Society.\nSpecial issue \u201dStudying the COVID-19 Infodemic at Scale\u201d.\nZarocostas, J. 2020. How to fight an infodemic. The Lancet,\n395(10225): 676.\n1244", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "VaccinEU: COVID-19 vaccine conversations on Twitter in French, German and Italian", "author": ["M Di Giovanni", "F Pierri", "C Torres-Lugo"], "pub_year": "2022", "venue": "Proceedings of the \u2026", "abstract": "Despite the increasing limitations for unvaccinated people, in many European countries there  is still a non-negligible fraction of individuals who refuse to get vaccinated against SARS-"}, "filled": false, "gsrank": 548, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/19374", "author_id": ["31D3j40AAAAJ", "b17WlbMAAAAJ", "FmhLgVQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:D80iaOqTFlUJ:scholar.google.com/&output=cite&scirp=547&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=D80iaOqTFlUJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 23, "citedby_url": "/scholar?cites=6131250577690250511&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:D80iaOqTFlUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/19374/19146"}}, {"title": "Weaponizing the Wall: The Role of Sponsored News in Spreading Propaganda on Facebook", "year": "2024", "pdf_data": "Weaponizing the Wall: The Role of Sponsored\nNews in Spreading Propaganda on Facebook\nDaman Deep Singh\nIndian Institute of Technology Delhi, IndiaGaurav Chauhan\nIndian Institute of Technology Delhi, IndiaMinh-Kha Nguyen\nUniversit \u00b4e Grenoble Alpes, France\nOana Goga\nCNRS, Inria, Institut Polytechnique de Paris, FranceAbhijnan Chakraborty\nIndian Institute of Technology Kharagpur, India\nAbstract \u2014A large fraction of people today consume most of\ntheir news online, and social media platforms like Facebook\nplay a significant role in directing traffic to news articles.\nWhile news organizations often use Facebook advertising to\ndrive traffic to their websites, this practice can inadvertently\nlead to biases in what articles users get exposed to, or worse,\ncould be used as a mechanism for manipulation. In this work,\nwe examine the impact of sponsored news on Facebook on\nthe dissemination of propaganda. Propaganda is a method of\npersuasion that is frequently employed to advance some sort\nof goal, such as a personal, political, or business objective. By\nanalyzing more than 17 Million Facebook posts and 6 Million\nsponsored advertisements gathered over 182 days, we observe\nthat advertisers of all kinds, including politicians, media houses,\nand commercial corporations, publish thousands of ads/boosted\nposts every day on Facebook. However, Facebook excludes ads\nfrom news organizations from their public ad archive even when\ntheir ads talk about politics and social issues, thus putting news\norganizations in the unique position of publishing paid political\nopinions without any transparency requirement. The danger is\nthat news organizations or other third-party interest groups can\ncarefully select news articles that drive their points and that look\nlegitimate because ads link to sites of known news organizations.\nIn this paper, we explore how sponsored news on Facebook can\nbe a powerful tool for spreading propaganda . We believe the\npaper will help raise awareness among users about the potential\nbiases in sponsored news and the need to critically evaluate the\ninformation they see on Facebook.\nIndex Terms \u2014Social and Media Analysis, Facebook, Propa-\nganda, Deep Learning\nI. I NTRODUCTION\nIn our increasingly interconnected world, the way we\nconsume news has undergone a profound transformation. A\nsignificant portion of today\u2019s population turns to the internet\nas its primary source of information, and while online news\noutlets are experiencing a surge in web traffic, a substantial\nshare of article views stems from social media referrals1.\nPlatforms like Facebook and X (Twitter) have become the\nprimary drivers for the dissemination of news, reshaping the\nway information flows through our digital society.\nTraditionally, the propagation of news articles on social\nmedia was largely organic, driven by user engagement through\nlikes, shares, and retweets. However, in recent times, news\n1https://www.zdnet.com/article/social-media-is-key-driver-for-news-\nconsumption/organizations have evolved their strategies to include the\npaid promotion of specific articles, harnessing the power of\nadvertising to reach wider audiences [1]. The concept of\npromoting news articles on platforms like Facebook isn\u2019t in-\nherently problematic, but it carries the potential for unintended\nconsequences. For instance, it can inadvertently introduce\nbiases into the information users encounter [2], or worse,\nbecome a means of manipulation [3]. The careful selection\nof news articles for promotion, combined with the micro-\ntargeting capabilities offered by platforms like Facebook [4],\ncan be exploited to advance various agendas, shaping public\nopinion and eliciting emotional responses from the audience.\nThis approach often falls under the realm of propaganda, a\nmethod of persuasion frequently employed to further personal,\npolitical, or business agenda.\nWhile advertisers from diverse backgrounds publish count-\nless ads and boosted posts on Facebook daily, there is a\nkey distinction in the content of the ads posted by news\norganizations. Most of news ads don\u2019t merely encourage users\nto subscribe or visit their homepage but explicitly promote\nindividual news articles. The challenge lies in the fact that the\ntitles (and snippets) of these ads carry message/information to\nthe users encountering them. Unlike when users visit a news\nwebsite, where they can exercise control over the articles they\nread, they have no such control over the sponsored news that\npopulates their Facebook timeline. This lack of control leaves\nthem vulnerable to the influence of the messaging, whether\nconsciously or subconsciously.\nFurthermore, a complex issue arises from Facebook\u2019s de-\ncision to exclude ads from news organizations from their\n\u2018social issues, elections, or politics\u2019 ad archive2, even when\nthese ads touch on political, electoral, or social issues. This\nomission negates the transparency requirements3imposed on\nother advertisers, placing news organizations in a unique\nposition to publish paid political opinions without account-\nability. Consequently, there is a concerning potential for news\norganizations or third-party interest groups to meticulously\nselect news articles that align with their agenda, all the while\n2https://www.fb.com/business/help/issuesandpolitics;\nhttps://www.fb.com/business/help/313752069181919?id=288762101909005\n3Including mandatory disclosure of amount spent to publish the ad, name\nof the entity/person responsible, etc. [5].\nFig. 1: Ratio of sponsored posts to all posts in\neach partisanship category.\nFig. 2: Box plot of engagement. Black lines rep-\nresent medians, and white dots represent means.\nPartisanship Sponsored Un-Sponsored Ratio\n(S) (US) (S/US)\nFar Left 0.001925 0.00068 2.848\nSlightly Left 0.002767 0.00062 4.498\nCenter 0.001090 0.00092 1.181\nSlightly Right 0.001557 0.00088 1.768\nRight 0.011814 0.00668 1.767\nTABLE I: Normalized engagement across sponsored and un-\nsponsored posts for different partisanship groups.\nappearing legitimate because these ads direct users to well-\nknown news outlets. When combined with the micro-targeting\ncapabilities of sponsored post platforms [3], this becomes a\npotent tool for influencing users and spreading propaganda.\nIn this work, by gathering extensive longitudinal data from\nFacebook, we try to analyze the role of sponsored posts in\nspreading propaganda. Leveraging a reliable, state-of-the-art\npropaganda detection model, we demonstrate that sponsored\nposts indeed contain more propaganda compared to non-\nsponsored news posts on Facebook, worryingly bringing in\nhigher engagement from the audience. We also check how\nthis trend varies across the political spectrum. Additionally,\nwe present a comprehensive analysis of propaganda spread by\nFacebook news pages around the time of the US Capitol attack\n(in January 2021), illustrating an escalation of propaganda\nduring this period across both left-leaning and right-leaning\nmedia outlets.\nWith 2024 being touted as the biggest election year in his-\ntory with more than half the world\u2019s population participating in\npolls4, and the recent concerns regarding the potential misuse\nof large language models (LLMs) in spreading propaganda\nat scale [6], [7], we believe that our work will help raise\nawareness about the potential issues with sponsored news and\nthe need to critically evaluate all the information users get on\nsocial media sites like Facebook.\nII. R ELATED WORKS\nPropaganda on Social Media. The pervasiveness of social\nmedia platforms has created a fertile ground for proliferation\n4https://www.economist.com/interactive/the-world-ahead/2023/11/13/2024-\nis-the-biggest-election-year-in-historyof propaganda. Subsequently, several studies have aimed at\nanalyzing and evaluating the impact of these platforms in\ninfluencing and reinforcing mass opinion across a variety\nof socially significant topics, including elections [9], [10],\ncontroversies [11], political-affiliations [12], and even eth-\nnic violence [13]. Prior works have focused on propaganda\ndissemination on different social media platforms, such as\nReddit [12], Twitter [14], and Facebook [15]\u2013[17].\nDetecting Propaganda. Propaganda is a subtle yet impactful\nway of influencing opinions that is hard to detect. As a\nconsequence, considerable effort have been put into precisely\ndefining propaganda and elaborating on nuanced propaganda\ntechniques [8], [18]. The research community has proposed\nuseful benchmark datasets [19]\u2013[23], as well as developed ef-\nfective propaganda detection methods, including BERT-based\nmodels [8], [12], [24], Large Language Models [25], among\nothers. Additionally, various methods have been devised to\ntackle specific challenges in propagandistic content, including\naddressing code-switched social media text [26], employing\nmultimodal approaches [27], and adapting strategies for multi-\nlingual propaganda [28], [29]. In this work, we utilize this line\nof work to select the best performing algorithm for detecting\npropaganda in news posts.\nInterdisciplinary Efforts for Combating Propaganda. Con-\ncerns over online propaganda\u2019s reach have sparked broad\nresearch across disciplines. Psychologists and linguists have\nstudied persuasion tacticssuch as emotional triggers and cog-\nnitive biases [30]\u2013[34]. Sociologists have delved into the\ncultural and societal conditions that facilitate the influence of\npropaganda [31], [35], [36]. Legal scholars have advocated\nfor regulating the use of technology towards responsible\nonline spaces [37], [38]. Besides these efforts, various studies\nhave focused on counteracting propaganda\u2019s impact through\nenhancing media literacy [39]. Our work complements these\nefforts by pointing out a novel source of propaganda and offers\npolicy suggestions to tackle their spread.\nIII. D ATASET GATHERED\nFollowing the data collection framework by [40], we gath-\nered extensive longitudinal data comprising news posts and\nsponsored ads posted by media organizations on Facebook\nPropaganda Type Definition\nDoubt Questioning the credibility of someone or something.\nAppeal to Fear/Prejudice Attempt to increase opposition to a position by spreading fear/terror among the populace.\nExaggeration/Minimization Attempting to make something seem either less or more significant than it truly is by employing\nexaggerations to diminish or amplify its importance.\nCausal Oversimplification Escaping the complexities of a situation by scapegoating a specific person or group, offering a\nsuperficial explanation that absolves others of responsibility.\nFlag Waving Emphasizing a profound sense of duty to intense national or group sentiment, such as race, gender,\nor political preference.\nLoaded Language Influencing a group by using emotionally charged (positive or negative) words and phrases\nName Calling or Labeling Assigning derogatory labels or names to individuals or groups as a means of discrediting them or\ntheir ideas.\nSlogans Succinct and impactful phrases with an emotional appeal, utilizing labels and stereotypes.\nThought-terminating Clich \u00b4e Usage of phrases or words to stifle meaningful conversation and critical thought on a subject, offering\nsimplistic answers or diverting attention from crucial ideas.\nRepetition Repeating a message with the expectation that the audience will eventually accept it.\nBandwagon Showcasing a majority\u2019s support for a certain belief to persuade others.\nBlack and White Fallacy Presenting two apparent solutions as the sole options, despite the existence of the only ones available\nwhen, in fact, there are more options.\nWhataboutism Instead of presenting solid evidence to challenge an opponent\u2019s argument, this approach seeks to\nweaken their perspective by alleging hypocrisy.\nObfuscation, Intentional Vague-\nness & ConfusionEmploying vague generalizations to prompt the audience to draw their own conclusions.\nAppeal to Authority Depending on expert opinion without concrete evidence about the incident or event.\nRed Herring Introducing an irrelevant topic into the discussion shift individuals\u2019 focus.\nReductio ad Hitlerum Proposing a conclusion solely based on the origin of something or someone, rather than considering\nits current meaning or context.\nStraw Man Substituting a comparable proposition for an opponent\u2019s, typically an extreme version, and refuting\nit instead of the original statement.\nTABLE II: Eighteen fine-grained propaganda techniques proposed by [8].\nover a period of 182 days, starting from 1st August 2020 till\n30th January 2021. First, we utilized the Meta Ad Library5\nto collect active ads, i.e., the ads that were posted/run on\nFacebook during the data collection period, resulting in a\ntotal of 6,741,422 advertisements in the given time frame.\nConcurrently, we employed Meta\u2019s CrowdTangle API [41] to\ngather news posts from the Facebook pages of various news\nmedia organizations.\nTo identify these organizations, we took a two-pronged\napproach. First, we relied on an independent media watchdog\n\u2018Media Bias/Fact Check\u2019 which surveys news outlets and pro-\nvides qualitative information about them, such as their political\nleaning and news quality [42]. Following this, we identified\n2,863 Facebook pages corresponding to the media organi-\nzations covered by Media Bias/Fact Check. Subsequently,\nrecognizing the rise of \u2018social media only\u2019 news channels\nthat might elude traditional media watchdog groups [43],\n[44], we considered all Facebook pages which claimed to be\n\u2018News Media\u2019 in their \u2018About\u2019 section and posted at least one\nadvertisement. In total, we compiled 10,492 Facebook news\nchannels, including details like their page id, name, city, coun-\ntry, website, followers count, creation time, misinformation\n5https://transparency.fb.com/en-gb/ researchtools/ad-library-tools/status, and partisanship indications.\nOverall, we collected 17,815,182 Facebook posts (on av-\nerage, 97,885 posts per day) and 6,741,422 ads (37,040\nads per day). Even after we filter non-English posts6and\nFacebook pages with less than 10 posts, we end up with a\ncollection of 12,506,833 posts which provides us with a rich\nand comprehensive dataset for the analysis.\nNotably, the time period under examination holds particular\nsignificance for the study of social media news, as it spans\nthe 2020 US Presidential Election, encompassing both pre-\nelection and post-election posts shared by news outlets on\nFacebook. Particularly noteworthy inclusion is the time of the\nUS Capitol attack (January 6, 2021) following the defeat of\nthe former President Donald Trump. The dataset serves as a\nvaluable resource for examining the combined impact of social\nmedia news, sponsorship, and the potential dissemination of\npropaganda within this context.\nIV. S PONSORED NEWS POSTS ON FACEBOOK\nThe dataset includes different types of ads (or sponsored\nposts) posted by various entities, including businesses, celebri-\n6We keep only English posts as our propaganda classifier (explained in\nlater section) was trained on English data alone.\nFig. 3: Ratio of propaganda posts to total posts\nby sponsorship and partisanship.\nFig. 4: Engagement of propagandistic and non-\npropagandistic across various partisanships.\nties, political parties, and news media outlets. We first identi-\nfied the sponsored news posts within this dataset by comparing\nthe destination URL of each advertisement with the destination\nURL of the collected news posts. A match between the two\nURLs indicates a sponsored post. While this methodology\nmay not capture all sponsored posts, it ensures the accuracy\nof identified sponsored content. Overall, we found 72,113\nsponsored posts (out of the total 12,506,833 posts) using this\napproach. For a comprehensive analysis, we categorize the\nidentified sponsored posts into various partisanship groups.\nTo this end, we employ the partisanship classifications from\nMedia Bias/Fact Check [42], focusing on 2,863 Facebook\npages they cover, categorized as far left,slightly left ,center ,\nslightly right , and far right . Next, we examine how various\nmedia outlets leverage Facebook ads to expand their reach.\nSponsored-to-Total-Post ratio across political spectrum.\nFigure 1 reveals the relative prevalence of sponsored con-\ntent across partisanship categories, expressed as the ratio of\nsponsored posts to total posts. Our findings indicate a notable\ntrend: news channels affiliated with either the far left, slightly\nleft, or slightly right political leanings tend to exhibit higher\nsponsored-to-total post ratios compared to the center. This\nsuggests a potential association between political orientation\nand susceptibility to sponsorship, with some leaning groups\nattracting more commercial partnerships than others. However,\nit is important to note that this trend does not appear to extend\nto the far-right channels, which deviate from the pattern by\ndisplaying a lower sponsorship ratio. We also observed that\nnewly established Facebook pages with a political inclination\ntend to exhibit a higher ratio of sponsored to total posts,\nindicating a potential strategy to quickly and effectively dis-\nseminate information and increase reach.\nAnalyzing engagement with sponsored posts. We analyze\nthe engagement of sponsored and unsponsored posts, by\nmeasuring engagement as the sum of the corresponding likes,\nreactions, and comments. As depicted by Figure 2, across all\npartisanship categories (with a negligible exception favoring\nunsponsored posts in slightly-right leaning pages), sponsored\nposts demonstrate higher reach compared to unsponsored posts\nof the same partisanship. The engagement of sponsored posts\nin left and right-leaning categories surpasses that of center-oriented pages.\nTable I presents the engagement levels for each partisanship\ncategory, normalized by the follower count of the correspond-\ning Facebook page, for both sponsored and non-sponsored\nposts. While there is only a slight increase in engagement\nfor the sponsored posts of center-leaning pages, there is a\nnotable increase in the corresponding engagement for right-\nand left-leaning pages, which suggests a deliberate approach\nin the design of sponsored posts to encourage higher user\nengagement. Hence, based on the above analysis, it is clear\nthat sponsored posts on Facebook is an effective strategy for\ngaining higher user engagement as compared to unsponsored\nposts.\nV. P ROPAGANDA DETECTION\nNext, we focus on identifying propaganda posts on Face-\nbook. Propaganda detection has typically been posed as a\nmulti-class classification problem [8], [12], [25], where the\nclassification labels differ based on the dataset under con-\nsideration. For our analysis, we utilize the multi-granularity\npropaganda detection model (MGN-ReLU) proposed by [8].\nThis model has been trained on a large, high-quality bench-\nmark dataset that features both sentence-level and span-level\nannotations, i.e., each sentence is manually annotated at the\nsentence level as either propaganda ornon-propaganda , and\neach text span within the sentence belonging to any of the\n18propaganda classes (described in Table II) is annotated\nwith the corresponding propaganda technique. We call this\ndataset as the QCRI dataset7. As shown by [8], due to the\nextra supervision provided by the span-level annotations, fine-\ngrained classification enhances the model\u2019s performance at\nthe sentence level. Consequently, the model not only pro-\nvides binary classification on input sentences but also offers\ninsights into the involved propaganda techniques. This also\nimproves the model\u2019s explainability, thereby enhancing its\noverall reliability. The reliability of this model is corroborated\nby subsequent studies such as [12], which show that the model\nis robust to topical biases in the annotated dataset and learns\n7Since it was contributed by researchers from the Qatar Computing Re-\nsearch Institute (QCRI) [8].\nModel Recall Precision F1-score\nRandom 0.501 0.245 0.329\nBERT 0.556 0.557 0.556\nALBERT 0.560 0.527 0.543\nXLNet 0.601 0.518 0.556\nT5 0.4535 0.607 0.519\nMGN-ReLU 0.593 0.554 0.577\nTABLE III: Comparison of classifiers on the QCRI test for\nsentence-level classification. Best results highlighted in bold.\nlinguistic patterns in the dataset rather than being influenced\nby topical confounds, which is desirable.\nFor establishing the suitability of the MGN-ReLU model\nfor our analysis, we perform a comparison against several\nprominent classification models. We fine-tune a suite of well-\nknown transformer-based classifiers such as BERT [45], AL-\nBERT [46], XLNet [47], and T5 [48] on the sentence-level\nQCRI dataset using the hyperparameters described in [8]. As\nan additional baseline, we also report the performance of a\nRandom classifier that classifies each sentence uniformly at\nrandom. Note that we do not fine-tune the MGN-ReLU model;\nrather we utilize the MGN-ReLU model provided by [8],\nwhich is already trained on the QCRI dataset. Table III shows\nthe performance of the models for the binary, sentence-level\nclassification on the QCRI dataset. As expected, all models\nperform significantly better compared to Random classifica-\ntion. Notably, the MGN-ReLU model emerges as the best\nclassifier, achieving the best F1-score, and reasonably good\nPrecision and Recall scores. Recently, large language models\n(LLMs) have also been employed for propaganda detection.\nHowever, they were found to perform worse than BERT-based\nmodels on the QCRI dataset [25]. Hence, we proceed with the\nMGN-ReLU classifier in this work.\nTo further validate the MGN-ReLU classifier\u2019s reliability\non our dataset, we randomly sampled 100 posts and manually\nannotated them. Subsequently, we evaluated the classifier\u2019s\nperformance on this subset of data. Remarkably, the classifier\nexhibited strong performance, achieving precision, recall, and\nF1-score values of 0.76,0.59, and 0.67, respectively. Notably,\nthis performance exceeded that observed on the QCRI test\nset, providing compelling evidence supporting the confident\nutilization of this classifier for our dataset analysis.\nVI. P ROPAGANDA IN FACEBOOK POSTS\nIn this section, we conduct a thorough analysis of the\nposts in our dataset, considering the classification labels ( pro-\npaganda ornon-propaganda ) assigned through the process\ndescribed in the previous section. Our investigation includes\na comprehensive study of sponsorship ,partisanship (Far Left,\nSlightly Left, Center, Slightly Right, and Far Right), and\nengagement (reactions, comments, etc.) across both propa-\nganda and non-propaganda labels. Note that the fine-grained\nclassification of posts in our dataset follows the same approach\nas that used for the news articles in the QCRI dataset [8].\nHowever, an entire Facebook post, typically comprising a few\nsentences, is classified as a propaganda post only if it containsat least one sentence predicted to be propagandistic by the\nclassifier.\nQ. Do sponsored posts spread more propaganda? We find\nthat approximately 19% of sponsored posts are classified as\npropaganda, compared to around 16% of unsponsored posts.\nThis suggests that sponsored posts are more likely to contain\npropaganda. To statistically validate this observation, while\nconsidering the substantial difference in the total number\nof unsponsored (around 12.4 million) and sponsored (near\n72K) posts, we performed a Chi-square test.The test reveals a\nsignificantly higher proportion of propagandistic posts among\nsponsored posts compared to unsponsored posts, with a \u03c72\nvalue of 264.29 and p << 0.05. Next, when we examine\nthe distribution of propaganda posts across various partisan\naffiliations in both sponsored and unsponsored posts, we\nobserve in Figure 3 that the overall partisanship distribution\nremains quite similar. However, there\u2019s a noticeable bias\ntowards Far Left and Far Right leanings. Notably, almost 70%\nof the propaganda posts originate from news channels with\nFar Left and Far Right political leanings, regardless of the\ntype of sponsorship. This correlation strongly suggests that\nthe political bias of these channels is positively associated with\ntheir use of propaganda.\nWe also analyzed various propaganda techniques present in\nthe posts. Table IV displays the top 5 propaganda techniques\nfound in our dataset. This table provides insights into the\ndistribution of posts associated with each technique across\ndifferent partisan affiliations and sponsorship categories. A\nnoteworthy observation is the general trend of sponsored posts\nexhibiting a relatively higher prevalence of propaganda com-\npared to unsponsored posts across all partisanships. The most\nsignificant disparity in terms of sponsorship is particularly\nevident in the case of Far Right-leaning propaganda posts,\nwith sponsored posts being up to twice as propagandistic in\nterms of numbers.\nQ. Do propagandistic posts generate more engagement?\nRecall that, in the previous sections, we\u2019ve already estab-\nlished that sponsored posts lead to more engagement and that\nsponsored content is more likely to contain propaganda. Here,\nwe examine the engagement levels of propaganda and non-\npropaganda posts (across various partisanship categories). To\ngauge engagement, we utilize the total sum of reactions and\ncomments on a post, normalized by the number of followers\nof the corresponding channel. Figure 4 illustrates the engage-\nment of propaganda posts categorized by their partisanship.\nRegardless of the partisanship, propaganda posts consistently\nexhibit higher engagement compared to non-propaganda posts\n(with a minor exception in the \u2019Far Right\u2019 partisanship group).\nQ. Do influential Facebook pages tend to post more pro-\npaganda? Now we study whether highly influential Facebook\npages, indicated by a substantial follower count8tend to share\nmore propagandistic content. Figure 5c shows the distribution\n8We observed a high correlation between the \u2018engagement\u2019 and \u2018followers\ncount\u2019 of a page, hence, using \u2018engagement\u2019 as a measure of a page\u2019s influence\ngives qualitatively similar results.\nPropaganda\nTypeOverall\n(S)Overall\n(US)Far\nLeft (S)Far\nLeft(US)Slight\nLeft (S)Slight\nLeft (US)Center\n(S)Center\n(US)Slight\nRight (S)Slight\nRight (US)Far\nRight (S)Far\nRight(US)\nLoaded Language 0.14 0.12 0.24 0.24 0.15 0.13 0.13 0.08 0.12 0.11 0.25 0.18\nName Calling/Labelling 0.07 0.06 0.14 0.14 0.06 0.06 0.06 0.04 0.06 0.05 0.16 0.1\nFlag Waving 0.03 0.02 0.06 0.04 0.03 0.02 0.03 0.01 0.02 0.02 0.08 0.04\nExaggeration/Minimisation 0.02 0.02 0.05 0.03 0.03 0.02 0.02 0.01 0.02 0.02 0.04 0.02\nDoubt 0.02 0.02 0.06 0.05 0.03 0.02 0.02 0.01 0.02 0.02 0.07 0.18\nTABLE IV: Fractions of Top-5 propaganda types spread across sponsorship and partisanship. (S) and (US) stand for\nsponsored posts and unsponsored posts respectively.\n(a)\n (b)\n (c)\nFig. 5: (a) Ratio of propaganda posts to total posts over time by all Facebook channels. (b) Plot of ratio of propaganda posts to\ntotal posts over time by US-based Facebook channels alone. (c) Line plot showing the distribution of the fraction of propaganda\nand sponsored posts for Facebook pages sorted by their followers\u2019 count.\nof the fraction of propaganda as well as sponsored posts\nposted by Facebook pages within our dataset, arranged in a\nnon-decreasing order of their followers\u2019 count9. Although a\nclear linear or monotonic correlation is not evident between a\npage\u2019s follower count10and its frequency of posting sponsored\nor propagandistic content, it can be seen that propaganda\nis more prevalent on pages with either very low or very\nhigh follower counts (as depicted by the co-occurring spikes\nof propagandistic and sponsored contents for such pages).\nSpecifically, the bottom 25% and top 25% pages by follower\ncount post significantly higher ( p < 0.05in Mann-Whitney\nU Test [49]) propaganda content compared to the overall\ndistribution. Delving deeper, we also find that any page with\n>20% sponsored posts tends to spread about 2.31 times more\npropaganda compared to pages posting <20% sponsored\ncontent.\nVII. C ASE STUDY : 2020 US P RESIDENTIAL ELECTION\nWhile so far we have reported the analyses of propaganda\nat a longer timescale, we now delve into a particular event.\nOur data collection period encompasses significant events like\nthe US Presidential Election on November 3rd, 2020, and the\nsubsequent US Capitol attack in Washington, D.C. on January\n6th, 2021. Our investigation entails a comprehensive scrutiny\nof propaganda disseminated through news pages on Facebook,\nspanning the periods preceding the election, the election itself,\nand the aftermath. This analysis seeks to offer insights into the\nrole and importance of propaganda in the political landscape\nduring this pivotal period.\n9For consistency, all values shown in the figure have been scaled between\n0 and 1 using min-max scaling.\n10Low Pearson (0.096) and Spearman (0.383) correlation coefficients.A. Pre-Election and Election Period\nThe influence of social media on political opinions is sub-\nstantial, often contributing to polarization by recommending\ncontent aligning with users\u2019 existing views. Particularly on\nFacebook, where news channel pages boast large followings,\nthere is a tendency to disseminate propagandistic content that\ncan sway the opinions of their followers. Table V presents\ndetailed examples of propaganda dissemination by both left-\nwing and right-wing news channels during the pre-election\nperiod.\nExamining Figure 5a, which tracks the propaganda trends\nfrom news pages over six months corresponding to our\ndataset\u2019s timeline, reveals a noteworthy pattern. The graph\nillustrates the proportion of propaganda posts relative to total\nposts. A noticeable peak emerges during the first week of\nNovember, falling between the two most statistically signifi-\ncant changepoints11, aligning with the election date (November\n3, 2020). This surge in propaganda posts seems to be initiated\naround mid-September, reaches its zenith in early November,\nand undergoes subsequent decline in December. This obser-\nvation strongly suggests that the news pages on social media\nexhibit a preference for employing propaganda as a subtle tool\nto influence their audience, particularly during pivotal events\nlike elections.\nB. Post Elections: Capitol Attack\nThe aftermath of the 2020 US presidential elections wit-\nnessed the alarming events of the Capitol attack, where around\n2000 individuals, seemingly fueled by the then president\u2019s\nspeech, marched to the Capitol to protest alleged voting\n11We performed the changepoint analysis using the Dynp algorithm12.\nChannel Partisanship Post Content Propaganda Type\nThe New Civil\nRights\nMovement\n(Followers:\n377679)Left\u201cDo all of Putin\u2019s operatives spread disinfo that can so easily be fact checked? \u201d*Richard\nGrenell, President Donald Trump\u2019s former Acting Director of National Intelligence, is under\nfire after posting a 2019 photo of Joe Biden and attacking him as phony**for not wearing a mask.\nSince the photo was clearly taken months before the coronavirus was even discovered,\nGrenell is ... \u2019Disinformation Grifter***\u2019: Ex-Trump Intel Chief\u2019s Anti-Biden Stunt Backfires,\nEarns Him a \u2019Manipulated Media\u2019 LabelDoubt*, Loaded\nLanguage**, Name-\nCalling***\nThe Stranger\n(Followers:\n128486)\u2014Election week 2020 begins tonight \u2014Biden sweeps Dixville Notch \u2014When will we know\nif we\u2019re still living in a democracy?After four long years that felt like a thousand endless\nnightmares*: Election week 2020 is finally here. East coast polls (plus Georgia and Indiana)\nclose at 4 p.m. PST, and we\u2019ll start seeing some results about a half-hour or an hour afterwards.\nSlog goes live shortly thereafter. Stay tuned for upda... Slog AM: Alright You Nervous Little\nFreaks**, It\u2019s Time to Boot the Bad President**and End This American Carnage***Exaggeration*,\nName calling**,\nFlag waving***\nPamela Geller\n(Followers:\n1291098)RightIt\u2019sone bombshell after*another now. BOMBSHELL AUDIO! Hunter Biden Confesses\nPartnership With \u201cThe F**king Spy Chief of China\u201d**. . . Joe Biden Named In Criminal\nCase Witness - Geller Report NewsLoaded Language*,\nName calling**\nPJ Media\n(Followers:\n405847)\u201dThis will get ugly.\u201d In the Battle for Florida, It Looks Like Democrats are Heading for a\nBloodbath* Loaded Language*\nTABLE V: Facebook posts before the US Elections from the Left and Right classified news channels, these posts clearly\nindicate the type of propaganda being spread out through the news channels on Facebook.\nChannel Post Content Propaganda Type\n100 Percent\nFed upThis isn\u2019t about Democrats or Republicans; this is about America*. American Patriots are\n100 Percent Fed Up with the corruption! Now arrives the hour of action! We\u2019ve got to do\nthis now! 100 Percent Fed Up \u2013 The Biden Campaign\u2019s primary defense is don\u2019t hear the\nevidence. That is why the pu... The Gateway Pundit: WOW! Stop The Steal!**Arrives. . . The\nHour Of ActionFlag waving*,\nSlogan**\nThe Globe and\nMail (Followers:\n786k)Vice President Pence Can Stop the Steal and Keep the Peace\u201dAll that is necessary for the\ntriumph of evil is that good men do nothing.\u201d (Edmund Burke) I suspect Vice President Mike\nPence has quoted that many times. January 6 might be his opportunity to live out his day to\nbe the good man who stopped evil*. About half of our nation**understands that Trump\u2019s ...Vice\nPresident Pence Can Stop The Steal And Keep The PeaceName calling*,\nFlag waving**\nTABLE VI: Facebook posts after the US elections and before the Capitol Attack.\nfraud13We analyze the influence of social media on this\nincident to understand and emphasize the extent of propaganda\nspread and its possible ramifications. In table VI, we present\nmanually labeled examples of propaganda dissemination by\nFacebook channels during the post-election and pre-attack\nperiod. During this phase, we observed a surge in propa-\nganda employing techniques like \u201cslogan\u201d, \u201cname-calling\u201d,\nand \u201cflag-waving\u201d. These tactics aimed at provoking individu-\nals to take action against the election results without presenting\nsubstantiated arguments. Concurrently, various Facebook cam-\npaigns emerged, encouraging people to protest by promoting\n\u201dslogan\u201d and \u201dflag-waving\u201d propaganda. A notable example\nis the relentless promotion of the slogan \u201dStop the Steal!\u201d\nto such an extent that Facebook intervened to mitigate posts\ncontaining this slogan14\nRevisiting Fig. 5a, the correlation between the Facebook\npropaganda dissemination and the timing of the Capitol attack\nis quite evident. The highest peak in propaganda around the\nsecond week of January precisely aligns with the date of the\nCapitol attack (7th January 2020). Figure 5b further elucidates\nthe dynamic response to the surge in propaganda. Particularly\nwe see an increase in right-wing propaganda following the\nperiod of the Capitol attack in order to pacify the protest,\nwhile the left-wing propaganda declines. Interestingly, we also\n13https://www.usatoday.com/in-depth/news/2021/02/01/ civil-war-during-\ntrumps-pre-riot-speech-parler-talk-grew-darker/ 4297165001/\n14https://www.nytimes.com/2021/01/11/us/facebook-stop-the-steal.htmlwitness a peak in propaganda across all partisan groups during\nthe period surrounding the attack, specifically in the first and\nsecond weeks of January, 2020. This suggests a link between\nthe surge in propaganda on social media and real-world events\nlike the attack, emphasizing the influential role that online\npropaganda on social media can play in shaping offline actions\nand consequences.\nVIII. C ONCLUSION\nIn this work, we emphasized the influence of spon-\nsored news posts on propaganda dissemination on Facebook.\nThrough extensive analysis and experiments on a curated\ndataset of Facebook posts, using advanced propaganda de-\ntection methods, we found that sponsored news posts are\nmore likely to be propagandistic and elicit increased user\nengagement. Additionally, we conducted a detailed analysis\nof Facebook posts surrounding the 2021 US Capitol Attack,\nrevealing patterns in propaganda dissemination by various\nnews channels during that time.\nLimitations. We acknowledge that although we have made\nextensive efforts to justify our hypotheses, our analysis is\nconstrained by the labels assigned through an imperfect pro-\npaganda classifier. Additionally, despite the comprehensive\nscope of the dataset, which spans a significant timeframe, the\ndynamic nature of the socio-political landscape introduces a\npotential limitation in its temporal generalizability.\nReproducibility. We aim to release our dataset and codebase\nafter acceptance.\nREFERENCES\n[1] K. A. Johnson and B. St. John III, \u201cNews stories on the facebook\nplatform: Millennials\u2019 perceived credibility of online news sponsored\nby news and non-news companies,\u201d Journalism Practice , 2020.\n[2] A. Chakraborty, S. Ghosh, N. Ganguly, and K. P. Gummadi, \u201cDissemina-\ntion biases of social media channels: On the topical coverage of socially\nshared news,\u201d in ICSWM , 2016.\n[3] F. N. Ribeiro, K. Saha, M. Babaei, L. Henrique, J. Messias, F. Ben-\nevenuto, O. Goga, K. P. Gummadi, and E. M. Redmiles, \u201cOn microtar-\ngeting socially divisive ads: A case study of russia-linked ad campaigns\non facebook,\u201d in FAccT , 2019.\n[4] G. Venkatadri, A. Andreou, Y . Liu, A. Mislove, K. P. Gummadi,\nP. Loiseau, and O. Goga, \u201cPrivacy risks with facebook\u2019s pii-based\ntargeting: Auditing a data broker\u2019s advertising interface,\u201d in 2018 IEEE\nSymposium on Security and Privacy (SP) . IEEE.\n[5] Meta, \u201cIncreasing our ads transparency,\u201d https://about.fb.com/news/\n2023/02/increasing-our-ads-transparency/, February 2023.\n[6] J. A. Goldstein, G. Sastry, M. Musser, R. DiResta, M. Gentzel, and\nK. Sedova, \u201cGenerative language models and automated influence op-\nerations: Emerging threats and potential mitigations,\u201d 2023.\n[7] C. Chen and K. Shu, \u201cCombating misinformation in the age of llms:\nOpportunities and challenges,\u201d 2023.\n[8] G. Da San Martino, S. Yu, A. Barr \u00b4on-Cede \u02dcno, R. Petrov, and P. Nakov,\n\u201cFine-grained analysis of propaganda in news articles,\u201d in EMNLP-\nIJCNLP , 2019.\n[9] M.-A. Rizoiu, T. Graham, R. Zhang, Y . Zhang, R. Ackland, and L. Xie,\n\u201cDebatenight: The role and influence of socialbots on twitter during the\n1st 2016 u.s. presidential debate,\u201d 2018.\n[10] D. Chernobrov and E. Briant, \u201cCompeting propagandas: How the united\nstates and russia represent mutual propaganda activities,\u201d Politics , 2022.\n[11] A. Guimaraes, O. Balalau, E. Terolli, and G. Weikum, \u201cAnalyzing the\ntraits and anomalies of political discussions on reddit,\u201d ICWSM , 2019.\n[12] O. Balalau and R. Horincar, \u201cFrom the stage to the audience:\nPropaganda on Reddit,\u201d in EACL . ACL, 2021. [Online]. Available:\nhttps://aclanthology.org/2021.eacl-main.309\n[13] P. Mozur, \u201cA genocide incited on facebook, with posts from myanmar\u2019s\nmilitary,\u201d 2018. [Online]. Available: https://www.nytimes.com/2018/10/\n15/technology/myanmar-facebook-genocide.html\n[14] S. Guarino, N. Trino, A. Celestini, A. Chessa, and G. Riotta, \u201cCharacter-\nizing networks of propaganda on twitter: a case study,\u201d Applied Network\nScience , 2020.\n[15] H. Seo and H. Ebrahim, \u201cVisual propaganda on facebook: A comparative\nanalysis of syrian conflicts,\u201d Media, War & Conflict , vol. 9, no. 3, pp.\n227\u2013251, 2016.\n[16] P. L. Moravec, A. Collis, and N. Wolczynski, \u201cCountering state-\ncontrolled media propaganda through labeling: Evidence from face-\nbook,\u201d Information Systems Research .\n[17] F. Pierri, L. Luceri, N. Jindal, and E. Ferrara, \u201cPropaganda and misinfor-\nmation on facebook and twitter during the russian invasion of ukraine,\u201d\nser. WebSci \u201923. ACM, 2023.\n[18] C. R. Miller, \u201cThe techniques of propaganda. from \u201dhow to detect and\nanalyze propaganda\u201d,\u201d 1939.\n[19] Z. Kmetty, V . Vincze, D. Demszky, O. Ring, B. Nagy, and\nM. K. Szabo, \u201cPartelet: A hungarian corpus of propaganda texts\nfrom the hungarian socialist era,\u201d in LREC\u201920 . Marseille, France:\nEuropean Language Resources Association, 2020. [Online]. Available:\nhttps://aclanthology.org/2020.lrec-1.290\n[20] V . Baisa, O. Herman, and A. Horak, \u201cBenchmark dataset for propaganda\ndetection in czech newspaper texts,\u201d in RANLP\u201919 . INCOMA Ltd.,\n2019. [Online]. Available: https://aclanthology.org/R19-1010\n[21] G. Da San Martino, A. Barr \u00b4on-Cede \u02dcno, H. Wachsmuth, R. Petrov, and\nP. Nakov, \u201cSemEval-2020 task 11: Detection of propaganda techniques\nin news articles,\u201d in SemEval-2020 . ICCL, 2020.\n[22] J. Tian, M. Gui, C. Li, M. Yan, and W. Xiao, \u201cMinD at\nSemEval-2021 task 6: Propaganda detection using transfer learning\nand multimodal fusion,\u201d in SemEval-2021 . ACL, 2021. [Online].\nAvailable: https://aclanthology.org/2021.semeval-1.150\n[23] K.-H. Huang, K. McKeown, P. Nakov, Y . Choi, and H. Ji, \u201cFaking\nfake news for real fake news detection: Propaganda-loaded training data\ngeneration,\u201d in ACL, 2023.\n[24] M. Abdullah, O. Altiti, and R. Obiedat, \u201cDetecting propaganda tech-\nniques in english news articles using pre-trained transformers,\u201d in\nICICS\u201922 , 2022.[25] K. Sprenkamp, D. G. Jones, and L. Zavolokina, \u201cLarge language models\nfor propaganda detection,\u201d 2023.\n[26] M. U. Salman, A. Hanif, S. Shehata, and P. Nakov, \u201cDetecting propa-\nganda techniques in code-switched social media text,\u201d 2023.\n[27] V . Ng and S. Li, \u201cMultimodal propaganda processing,\u201d AAAI , 2023.\n[28] V . Solopova, O.-I. Popescu, C. Benzm \u00a8uller, and T. Landgraf, \u201cAutomated\nmultilingual detection of pro-kremlin propaganda in newspapers and\ntelegram posts,\u201d 2023.\n[29] A. Purificato and R. Navigli, \u201cAPatt at SemEval-2023 task 3: The\nsapienza NLP system for ensemble-based multilingual propaganda de-\ntection,\u201d in SemEval-2023 , A. K. Ojha, A. S. Do \u02d8gru\u00a8oz, G. Da San Mar-\ntino, H. Tayyar Madabushi, R. Kumar, and E. Sartori, Eds. ACL.\n[30] W. Cai, \u201cAnalysis of the promotion of consumer psychological analysis\nand marketing to sports propaganda,\u201d Revista de Psicolog \u00b4\u0131a del Deporte\n(Journal of Sport Psychology) , 2023.\n[31] K. Young, F. B. Lindstrom, and R. A. Hardert, \u201cKimball young on\nsocial psychology, rural sociology, and anthropology at wisconsin,\n1926-1940,\u201d Sociological Perspectives , 1989. [Online]. Available:\nhttp://www.jstor.org/stable/1389124\n[32] A. Barfar, \u201cA linguistic/game-theoretic approach to detec-\ntion/explanation of propaganda,\u201d Expert Systems with Applications ,\n2022.\n[33] J. Zienkowski, \u201cPropaganda and/or ideology in critical discourse stud-\nies,\u201d DiscourseNet Collaborative Working Paper Series , 2021.\n[34] R. Torok, \u201cSymbiotic radicalisation strategies: Propaganda tools and\nneuro linguistic programming,\u201d 2015.\n[35] D. D. Chaudhari and A. V . Pawar, \u201cPropaganda analysis in social media:\nA bibliometric review,\u201d Information Discovery and Delivery , 2021.\n[36] M. Malhan and P. P. Dewani, \u201cPropaganda as communication strategy:\nHistoric and contemporary perspective,\u201d Academy of Marketing Studies\nJournal , 2020.\n[37] C. M. Corbin, \u201cThe unconstitutionality of government propaganda,\u201d\nOhio St. LJ , 2020.\n[38] Halina Swieboda, Mateusz Kuczabski, Ryszard Szpyra, Tomasz Za-\nwadzki, Tomasz Walecki, and Pawel Stobiecki, \u201cSocial control in the\nface of digital propaganda,\u201d European Research Studies Journal , 2021.\n[39] C. of Europe, \u201cDealing with propaganda, misin-\nformation and fake news,\u201d 2023. [Online]. Avail-\nable: https://www.coe.int/en/web/campaign-free-to-speak-safe-to-learn/\ndealing-with-propaganda-misinformation-and-fake-news\n[40] L. Edelson, M.-K. Nguyen, I. Goldstein, O. Goga, D. McCoy, and\nT. Lauinger, \u201cUnderstanding engagement with u.s. (mis)information\nnews sources on facebook,\u201d ser. IMC \u201921. New York, NY , USA: ACM,\n2021. [Online]. Available: https://doi.org/10.1145/3487552.3487859\n[41] Tess, \u201cCrowdtangle api,\u201d https://help.crowdtangle.com/en/articles/\n1189612-crowdtangle-api, 2024.\n[42] Dave Van Zandt, \u201cMedia biasfact checkk - search and learn the bias of\nnews media,\u201d https://mediabiasfactcheck.com, 2024.\n[43] P. Bengani, \u201cHundreds of \u2018pink slime\u2019 local news outlets are distributing\nalgorithmic stories and conservative talking points,\u201d Columbia Journal-\nism Review , 2019.\n[44] F. Ribeiro, L. Henrique, F. Benevenuto, A. Chakraborty, J. Kulshrestha,\nM. Babaei, and K. Gummadi, \u201cMedia bias monitor: Quantifying biases\nof social media news outlets at large-scale,\u201d in ICWSM , 2018.\n[45] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBert: Pre-training\nof deep bidirectional transformers for language understanding,\u201d arXiv\npreprint arXiv:1810.04805 , 2018.\n[46] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut,\n\u201cAlbert: A lite bert for self-supervised learning of language representa-\ntions,\u201d arXiv preprint arXiv:1909.11942 , 2019.\n[47] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdinov, and\nQ. V . Le, \u201cXlnet: Generalized autoregressive pretraining for language\nunderstanding,\u201d in NeurIPS , H. Wallach, H. Larochelle, A. Beygelzimer,\nF. d'Alch \u00b4e-Buc, E. Fox, and R. Garnett, Eds. Curran Associates,\nInc. [Online]. Available: https://proceedings.neurips.cc/paper files/\npaper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf\n[48] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\nY . Zhou, W. Li, and P. J. Liu, \u201cExploring the limits of transfer learning\nwith a unified text-to-text transformer,\u201d 2023.\n[49] P. E. McKnight and J. Najab, Mann-Whitney U Test . John Wiley\n& Sons, Ltd, 2010. [Online]. Available: https://onlinelibrary.wiley.com/\ndoi/abs/10.1002/9780470479216.corpsy0524", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Weaponizing the Wall: The Role of Sponsored News in Spreading Propaganda on Facebook", "author": ["DD Singh", "G Chauhan", "MK Nguyen", "O Goga"], "pub_year": "2024", "venue": "\u2026 on Advances in Social \u2026", "abstract": "A large fraction of people today consume most of their news online, and social media  platforms like Facebook play a significant role in directing traffic to news articles. While news"}, "filled": false, "gsrank": 550, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-78541-2_27", "author_id": ["7caaOyMAAAAJ", "", "w4cKb8EAAAAJ", "re_squoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:k6RtXnMGH6EJ:scholar.google.com/&output=cite&scirp=549&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=k6RtXnMGH6EJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:k6RtXnMGH6EJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.lix.polytechnique.fr/Labo/Oana.GOGA/papers/singh_propaganda_ASONAM24.pdf"}}, {"title": "From Generation to Detection: A Multimodal Multi-Task Dataset for Benchmarking Health Misinformation", "year": "2025", "pdf_data": "arXiv:2505.18685v1  [cs.CL]  24 May 2025From Generation to Detection: A Multimodal Multi-Task Dataset for\nBenchmarking Health Misinformation\nZhihao Zhang1*, Yiran Zhang1*, Xiyue Zhou2, Liting Huang3,\nImran Razzak4,Preslav Nakov4,Usman Naseem1\u2020,\n1Macquarie University, Australia,2University of Sydney, Australia\n3University of Technology Sydney, Australia,4MBZUAI, UAE\nAbstract\nInfodemics and health misinformation have sig-\nnificant negative impact on individuals and soci-\nety, exacerbating confusion and increasing hes-\nitancy in adopting recommended health mea-\nsures. Recent advancements in generative AI,\ncapable of producing realistic, human-like text\nand images, have significantly accelerated the\nspread and expanded the reach of health mis-\ninformation, resulting in an alarming surge in\nits dissemination. To combat the infodemics,\nmost existing work has focused on develop-\ning misinformation datasets from social me-\ndia and fact-checking platforms, but has faced\nlimitations in topical coverage, inclusion of\nAI-generation, and accessibility of raw con-\ntent. To address these issues, we present MM-\nHealth, a large scale multimodal misinforma-\ntion dataset in the health domain consisting\nof 34,746 news article encompassing both tex-\ntual and visual information. MM-Health in-\ncludes human-generated multimodal informa-\ntion (5,776 articles) and AI-generated multi-\nmodal information (28,880 articles) from var-\nious SOTA generative AI models. Addition-\nally, We benchmarked our dataset against three\ntasks\u2014reliability checks, originality checks,\nand fine-grained AI detection\u2014demonstrating\nthat existing SOTA models struggle to accu-\nrately distinguish the reliability and origin of\ninformation. Our dataset aims to support the de-\nvelopment of misinformation detection across\nvarious health scenarios, facilitating the detec-\ntion of human and machine-generated content\nat multimodal levels.\n1 Introduction\nHealth misinformation refers to information that\nis inaccurate, misleading, or false according to the\nbest available health evidence at the time. Such\nmisinformation tends to spread at unprecedented\n*Equal contribution.\n\u2020Corresponding author: usman.naseem@mq.edu.auspeed and scale on the World Wide Web and so-\ncial media (Office of the Surgeon General (OSG),\n2021), and has been shown to have significant neg-\native effects on society (Borges do Nascimento\net al., 2022; Abbott et al., 2021; Wang et al., 2019;\nMuhammed T and Mathew, 2022; Nathan Walter\nand Suresh, 2021). During crises, such as outbreaks\nof infectious diseases like COVID-19, the overpro-\nduction of health misinformation in both digital\nand physical environments is defined as an info-\ndemic. As society transitions into a long COVID\nera (Davis et al., 2023), the infodemic continues\nto evolve, leading to a reduction in public trust in\nhealth professionals (Nathan Walter and Suresh,\n2021). Furthermore, unfiltered exposure to health\nmisinformation can delay or prevent effective dis-\nease treatment and even threaten the lives of in-\ndividuals (Wang et al., 2019). Additionally, the\nrecent advent of generative image models, such\nas Stable Diffusion (Rombach et al., 2022), Mid-\njourneyV5 (Holz et al.), DALL-E2 (Ramesh et al.,\n2022), as well as human-level text generators like\nChatGPT (Ouyang et al., 2022) and LLaMa (Tou-\nvron et al., 2023), has amplified both the quantity\nand spread of misinformation (Zhou et al., 2023a).\nThe ease with which generative AI models can\nreplicate or manipulate multimodal content, includ-\ning text and images (Huang et al., 2024), further\ncontributes to the emergence of health misinforma-\ntion (Park, 2024). This presents a significant new\nchallenge in combating the infodemic.\nRecent studies have focused on developing and\nanalyzing datasets and detection methods to com-\nbat the infodemic. Common methods for collecting\nmultimodal health misinformation include scrap-\ning social media platforms (Kinsora et al., 2017;\nHayawi et al., 2022; Cui and Lee, 2020; Zhou\net al., 2020; Srba et al., 2022; Sun et al., 2023;\nLi et al., 2020; Chen et al., 2021b), such as Twitter\n(now known as X), and parsing fact-checking web-\nsites (Li et al., 2020; Chen et al., 2021b; Srba et al.,\nName YearHuman Context Machine Context Multiple\nAI ModelsReliability OriginalityGeneral\nAvaliable Text Image Text Image\nMedHelp 2013 \u2714 \u2718 \u2718 \u2718 \u2718 \u2714 \u2718 \u2718\nCOAID 2020 \u2714 \u2718 \u2718 \u2718 \u2718 \u2714 \u2718 \u2718\nANTi-Vax 2021 \u2714 \u2718 \u2718 \u2718 \u2718 \u2714 \u2718 \u2718\nMM-COVID 2020 \u2714 \u2714 \u2718 \u2718 \u2718 \u2714 \u2718 Partly\nReCOVery 2020 \u2714 \u2714 \u2718 \u2718 \u2718 \u2714 \u2718 Partly\nMonant 2022 \u2714 \u2714 \u2718 \u2718 \u2718 \u2718 \u2718 Partly\nMMCOV AR 2021 \u2714 \u2714 \u2718 \u2718 \u2718 \u2714 \u2718 Partly\nMed-MMHL 2023 \u2714 \u2714 \u2714 \u2718 \u2718 \u2714 \u2714 Partly\nOurs 2024 \u2714 \u2714 \u2714 \u2714 \u2714 \u2714 \u2714 \u2714\nTable 1: Comparison between our MM-Health dataset and other health related misinformation datasets.\n2022; Sun et al., 2023), such as Snopes and Poyn-\nter. However, these datasets exhibit the following\nnotable limitations:\n\u2022Exclusion of AI-generated misinformation:\nThe majority of existing datasets focus solely\non human-generated misinformation, ignor-\ning the growing trend of AI-generated misin-\nformation (Zhou et al., 2023b; Bashardoust\net al., 2024; Xu et al., 2023). With AI models\nnow capable of generating and manipulating\nboth text and image content (Liz-L\u00f3pez et al.,\n2024), it is crucial to include AI-generated\nmisinformation to ensure data diversity.\n\u2022Lack of accessible raw content: Many\ndatasets only provide URLs or Twitter IDs\nas delivery artifacts instead of the raw con-\ntent of the misinformation. Due to ongoing\ncensorship by news and social media plat-\nforms, much of this data is no longer acces-\nsible, severely limiting the usability of these\ndatasets.\nThe limitation of the previous health misinfor-\nmation datasets are summarised in Table 1. Most\nof the existing methods for automatically detect-\ning health misinformation include content-based\nCNNs (Cui and Lee, 2020; Zhou et al., 2020;\nDai et al., 2020), attention-based hierarchical en-\ncoders (Kinkead et al., 2020), and graph-based at-\ntention methods (Cui et al., 2020). These meth-\nods have demonstrated competitive performance\nafter being trained on health misinformation bench-\nmarks. However, they require extensive training\non benchmark datasets to achieve expected perfor-\nmance, which limits the models\u2019 ability to gener-\nalise to new health misinformation. Since health\nmisinformation is constantly evolving (Okoro et al.,\n2024), it is important to evaluate generalised mod-\nels under zero-shot settings. Additionally, these\nmodels only accept structured input and provide\nlabelled output without human-readable explana-\ntions. This constraint limits the usability of existingdetection methods for the general public outside\nof the research community. To address the afore-\nmentioned limitations, we develop MM-Health, a\ncomprehensive multimodal dataset designed for\ndetecting both human and AI generated health mis-\ninformation. Additionally, we conduct extensive\nexperiments using state-of-the-art (SOTA) Vision-\nLanguage Models (VLLMs) to evaluate their per-\nformance in assessing both the reliability and orig-\ninality of the health information in MM-Health,\nas well as performing a fine-grained AI detection\nanalysis. Our key contributions are as follows:\n\u2022We create and release a new large-scale multi-\nmodal (text and images) dataset called MM-\nHealth, which contains 34,746 news articles.\nThese articles were collected from existing\nmultimodal health datasets and generated us-\ning current state-of-the-art (SOTA) AI genera-\ntive models.\n\u2022We conduct a preliminary analysis of the data\nfor both human and AI-generated content,\nestablishing our dataset as a benchmark for\nbaseline evaluation against several SOTA Vi-\nsion Large Language Models (VLLMs) across\nthree tasks: reliability checks, originality\nchecks, and fine-grained AI detection.\n\u2022Our experimental results and analysis show\nthat current VLLMs, including GPT-4o1,\nstruggle to accurately verify content reliabil-\nity and originality. This highlights the impor-\ntance of developing generalised models for\nmultimodal health misinformation detection.\n2 Related Work\nWeb and social media provide valuable sources\nof information and play important roles in mul-\ntiple tasks like depression and suicide identifica-\ntion (Naseem et al., 2024), health mention classifi-\ncation (Naseem et al., 2022) and creditable knowl-\n1https://openai.com/index/hello-gpt-4o/\nedge management (Nisar et al., 2019). However,\nsystematic reviews shows that health-related mis-\ninformation on web and social media posts critical\nthreat to the community, which could lead to delay\nor prevent treatment and even threaten the lives of\nindividuals (Wang et al., 2019).\n2.1 Existing Datasets\nAs detailed in Table 1, several benchmark datasets\nhave been proposed for health related information\ndetection, which contain various features from dif-\nferent data sources.\nMedHelp (Kinsora et al., 2017), COAID (Cui and\nLee, 2020), and ANTi-Vax (Hayawi et al., 2022)\nare text datasets designed to address online health\nmisinformation. Specifically, MedHelp is collected\nfrom an online general health discussion forum.\nIt contains 1,338 non-misinformation comments\nand 887 misinformation comments annotated by\nhuman experts between 2001 and 2013. COAID\nincludes both news articles and Twitter content fo-\ncused on COVID-19 between December 2019 and\nSeptember 2020. It labels 204 fake news articles,\n3,565 true news articles, 28 fake claims, and 454\ntrue claims from a total of 1,896 news articles, 516\nTwitter posts, and 183,569 Twitter engagements.\nANTi-Vax is built solely from Twitter content fo-\ncused on the COVID-19 vaccine between Decem-\nber 2020 and January 2021. It includes a total of\n15,073 tweets, 5,751 of which are misinformation\nand 9,322 are general vaccine-related tweets.\nMM-COVID (Li et al., 2020), ReCOVery (Zhou\net al., 2020), Monant (Srba et al., 2022), MMCo-\nVaR (Chen et al., 2021b), and Med-MMHL (Sun\net al., 2023) are multimodal datasets for health-\nrelated misinformation detection. MM-COVID\ncontains 3,981 fake articles and 7,584 real articles\nrelated to COVID-19 which collected from Feb\n2020 to Jul 2020. ReCOVery includes both news\narticles and tweets mentioning COVID-19, labelled\nby NewsGuard2and Media Bias/Fact Check3.\nIt comprises 118,339 reliable articles and 28,274\nunreliable articles sourced between January 2020\nand May 2020. MMCoVaR focuses on vaccine-\nrelated misinformation between February 2020 and\nMarch 2021, featuring 958 unreliable and 1,635\nreliable news articles, plus 24,184 tweets catego-\nrized as reliable, unreliable, or inconclusive. Med-\nMMHL covers multiple diseases, integrating LLM-\ngenerated fake news, with 1,979 real and 1,604 fake\n2https://www.newsguardtech.com/\n3https://mediabiasfactcheck.com/articles, alongside 1,334 reliable and 639 unreliable\ntweets from January 2017 to May 2023. There are\nno existing dataset that incorporate both text and\nimage AI for misinformation generation. Further-\nmore, the most datasets rely on website URLs or\ntweet IDs, which have become partially or fully\ninaccessible due to Twitter\u2019s API restrictions and\nongoing content censorship.\n2.2 Existing Methods\n2.2.1 Methods for textual data\nExisting methods typically utilize a latent space\nto create embedding representations for article\ncontent. Embeddings capture contextual informa-\ntion and encode it into a lower-dimensional rep-\nresentation for downstream tasks such as classi-\nfication and prediction (Papanikou et al., 2024).\nMany approaches leverage this feature using the\nBERT to achieve exceptional performance in health\nmisinformation classification, either through fine-\ntuning (Kaliyar et al., 2021) or a combination\nof pre-training and fine-tuning (Lee et al., 2019).\nOther strategies, such as BERTweet (Nguyen et al.,\n2020) and COVID-Twitter-BERT (M\u00fcller et al.,\n2023), combine multiple pre-trained models across\nvarious contexts. These hybrid models achieve\nhigher performance due to the distinct contextual\nunderstanding provided by different models. How-\never, textual models capture only single-modality\nfeatures, neglecting the visual information often\nassociated with articles. We address this limitation\nby using SOTA vision-language models to capture\nboth textual and visual context.\n2.2.2 Methods for multimodal data\nPrevious studies have found that image-containing\nposts or articles tend to have higher user interaction,\nspread more quickly, and trigger stronger emotional\nresponses (Papanikou et al., 2024). Multimodal\nmisinformation detection requires both image and\ntext encoders to capture textual and visual features.\nOne method (Uppada et al., 2023) leverages these\nencoders to identify fake posts containing visual\ndata, while another approach detects inconsisten-\ncies between textual entities and image content for\nmisinformation detection. Limited research has ex-\nplored multimodal health misinformation detection.\nDGExplain (Shang et al., 2022) is a recent multi-\nmodal encoder-decoder architecture for COVID-19\nmisinformation detection that investigates cross-\nmodal associations between text and images to as-\nsess the reliability of news articles. However, these\nFigure 1: Data collection process for MM-Health includes: 1) utilising multiple existing open-source health\nmisinformation datasets as data sources, 2) validating the available data samples and collecting human-generated\nmultimodal data from the provided URLs, and 3) implementing generative AI models to collect AI-generated\nreplicated multimodal data. To ensure data quality, both human and AI generated content are evaluated by five\nhuman evaluators proficient in English.\nmodels often require extensive training on bench-\nmark datasets and offer limited interpretability. Our\nwork applies current advanced Vision-Language\nModels as a baseline for health misinformation de-\ntection to evaluate their performance.\n3 MM-Health Dataset\nThe overall data collection process for MM-Health,\nincluding human and AI-generated content, is il-\nlustrated in Figure 1. This process can be sum-\nmarised as follows: 1) utilising multiple existing\nopen-source health misinformation datasets as data\nsources, 2) validating the available data samples\nand collecting human-generated multimodal data\nfrom the provided URLs, and 3) implementing gen-\nerative AI models to collect AI-generated repli-\ncated multimodal data. To ensure data quality, both\nhuman and AI generated content are evaluated by\nfive human evaluators proficient in English.\n3.1 Data Collection\n3.1.1 Health Misinformation Collection\nTo ensure variability, we utilise four recent health-\nrelated misinformation datasets (Sun et al., 2023;\nChen et al., 2021b; Li et al., 2020; Zhou et al.,\n2020), collected between February 2020 and May\n2023, as our primary data sources. Since Twit-\nter (now known as X.com) restricted data ac-\ncess through its application programming inter-\nface (API) in 2023, we exclude tweets from these\ndatasets and focus on the available news articles.\nWhile Med-MMHL provides raw text and image\ndata, the other datasets only provide URLs as their\ndata source. However, not all URLs are accessi-\nble due to news websites consistently removingoutdated or misleading news, either voluntarily or\nin response to complaints. Therefore, we validate\nthe URLs in the database and scrape the text and\nimage metadata from the available URLs and at-\ntach the reliable and unreliable labels extracted\nfrom the original datasets. We also use the Pil-\nlow4library to filter out some images, such as\nblurry, logo-based, fuzzy, or meaningless images,\nwhich are often downloaded during web scraping.\nSee Figure 5 in appendix for examples of the\nremoved images .\n3.1.2 AI Health Misinformation Generation\nAfter collecting human generated misinformation\nfrom open-source datasets, we deploy five state-\nof-the-art (SOTA) generative AI models for each\nmodality to generate AI replicated data. To ensure\ndata variability, we adopt text and image models\nwith different architectures. For text generation, we\nuse Llama-3.1-8B, Qwen2.5-7B, ChatGLM-4-9B,\nGemma2-9B, and Mistral-v0.3-7B. For image gen-\neration, we use FLUX.1-dev5, Stable Diffusion\n1.5, Stable Diffusion XL, Stable Diffusion V AE,\nand Stable Diffusion PAG. To enhance model un-\nderstanding during text generation, we integrate\nboth textual and visual context, ensuring diverse\nand comprehensive outputs. Specifically, we im-\nplement a two-step generation pipeline as follows:\n1) providing raw text and image data to GPT-4o\nto create a topic summary for the article, and 2)\ninputting the topic summary into the five selected\nLLMs to generate the desired text. We find that\nspecific and concise prompts yield the best results\n4https://python-pillow.org/\n5https://github.com/black-forest-labs/flux\nfor LLMs. Image generation follows a similar two-\nstep pipeline to that of text generation. First, the\nimages are sent to GPT-4o to generate short image\ncaptions. Next, the original images and their cap-\ntions are supplied to the image generation models\nto create new images. The original images serve as\nanchor points during the generation process, pre-\ndefining the de-noising parameters as well as the\nimage dimensions. All the text and image models\nare provided with their default parameter settings.\nRefer to Figure 6 in appendix for text generation\nprompts and image generation prompts .\n3.1.3 Post-Processing with Human Evaluation\nOur two-stage generation process allows AI models\nto create most of the text and images based on ex-\nisting data without triggering their internal censor-\nship mechanisms (Glukhov et al., 2023). However,\nsome data samples are still not generated, as mod-\nels may refuse to produce them or output empty\nstrings and black images. Since different mod-\nels are equipped with different censorship mecha-\nnisms, there are variations in behaviour between\nmodels. To address this, we developed an algo-\nrithm to post-process data alignment between the\nhuman-generated context and all five AI-generated\ncontexts (see the Algorithm 1 in appendix for\nthe implementation ) . The dataset consists of two\nsources: human-collected text and images from\nopen-source datasets and AI-generated text-image\npairs created by five different models. For con-\nsistency, our algorithm will ensured that each AI-\ngenerated sample was present across all five mod-\nels before being included in the final dataset. Af-\nter data matching, we recruited five evaluators to\nreview the data and further remove low-quality\ntext and image pairs, resulting in 34,746 pieces\nof health-related information, of which 5,791 were\ncollected from open-source datasets and 28,955\nwere generated by AI models (see Figure 7 in ap-\npendix for examples of reliable and unreliable\nnews generated by humans and AI) . The news\narticles are written in diverse styles by different\nLLMs while addressing the same topic. While\nStable Diffusion 1.5 generates dramatically differ-\nent images, other models slightly manipulate the\noriginal images while maintaining a realistic ap-\npearance.\n3.2 Data Statistics and Analysis\nOverall data statistics. All instances in MM-\nHealth are multimodal, containing both textual andModel Avg Len Avg CSS\nLlama-3.1-8B 479.57 0.761\nQwen2.5-7B 568.4 0.766\nChatGLM-4-9B 577.55 0.761\nGemma2-9B 340.45 0.774\nMistral-v0.3-7B 337.87 0.783Model FID Avg CIS\nFLUX.1-dev 12.33 0.869\nSD 1.5 27.72 0.737\nSD XL 19.42 0.866\nSD XL V AE 15.76 0.883\nSD XL PAG 19.30 0.866\nTable 2: Statistics of generated text and image data from\ndifferent models. The left table shows text statistics:\n\"Avg Len\" is the average word count, and \"Avg CSS\"\nis the average Cosine Semantic Similarity. The right\ntable shows image statistics: \"FID\" is Fr\u00e9chet Inception\nDistance and \"Avg CIS\" is Average Cosine Image Simi-\nlarity.\nvisual information for reliability and originality\nstudies, with the proportion of reliable to unreli-\nable articles being approximately 4:1. We split our\ndataset into training and testing sets by randomly\nselecting 80% and 20% of the news articles from\nthe collected data instances. Additionally, 10%\nof the training set is further split into a validation\nset. As shown in Table 5, this results in a total\nof 4,154 training samples, 463 validation samples,\nand 1,159 testing samples from human-generated\nnews articles, while 20,770, 2,315, and 5,795 sam-\nples are used for training, validation, and testing,\nrespectively, from AI-generated news articles. To\nensure the generalisation of our dataset across all\nsplit sets, we further analyse the data statistics in\neach set, including the average text length and the\naverage number of images per article from both\nhuman and AI sources. The average text length\nand number of images are consistent across differ-\nent sets. It is worth noting that the average text\nlength generated by AI is shorter than that of the\noriginal human text, with an average of around\n450 words compared to approximately 850 words.\nAdditionally, unreliable news articles tend to be\nshorter, averaging around 650 to 750 words, while\ncontaining more images per article around 6 to 8\nimages compared to around 1.5 images in reliable\narticles. The overall statistics of the dataset are\npresented in appendix Table 5 .\nData analysis. To identify the differing data char-\nacteristics across the five AI models, we compare\ntheir statistics in Table 2. For text models, we\ncalculated the average article length from all five\ntext models. There is a noticeable variation among\nthe models, with ChatGLM-4 tending to generate\nlonger articles, while Mistral-v0.3 is more likely to\ngenerate shorter articles. Additionally, we utilise\nthe OpenAI text-embedding-3-small model to\ngenerate text embeddings for both human and AI\nFigure 2: KDE distribution of the semantic similarity\nbetween the human articles and articles from five LLMs.\narticles, comparing their semantic differences us-\ning cosine similarity. For news articles that are too\nlong to fit into the model\u2019s 8,191 context window,\nwe split these long articles into smaller chunks and\ncompute the mean vectors of all chunks to obtain\nthe final text embedding representations for those\narticles. As indicated on the left side of Table 2,\nthe average cosine semantic similarities across the\ntext models range from 0.76 to 0.78. We plot the\nGaussian Kernel Density Estimation (KDE) (Zhu\net al., 2022) distribution of the semantic similarity\nin Figure 2, showing that the cosine similarities are\nconcentrated between 0.8 and 0.85 across all mod-\nels, with slight variance. Notably, a small number\nof generated articles exhibit low semantic similarity\nwhen compared to human generated articles.\nFor image models, we calculated both the\nFr\u00e9chet Inception Distance (FID) (Seitzer, 2020)\nand the average cosine image similarity between\nAI-generated images and collected images. FID\nis a common metric used to evaluate the quality\nof images created from generative models by com-\nparing the distribution of generated images with\nthat of real images. A lower FID score indicates\ngreater similarity between the generated and real\nimages. The average cosine similarity is computed\nbetween the vector representations of AI and real\nimages, extracted using ResNet (He et al., 2016).\nThe average FID and average cosine image sim-\nilarities are reported in right side of Table 2, we\nalso plot KDE of the cosine image similarity in\nFigure 3. We observe that Stable Diffusion 1.5\nexhibits the greatest image variance compared to\nother models, while Stable Diffusion XL and its\nV AE and PAG variations generate the most similar\nimages. These trends hold for both the average and\ndistribution analyses of the image models. Unlike\nthe text models, no generated images exhibit low\nsimilarity when compared to real images.\nFigure 3: KDE distribution of image similarity between\nreal and generated images across five image models.\n4 Experiments\nExisting multimodal vision LLMs can provide in-\nsightful descriptions for input text and image data,\noffering the most accessible way to interact com-\npared to other deep learning models that require\nextensive training. We utilise both proprietary and\nopen-source models as baselines to detect data reli-\nability and originality using our MM-Health dataset\nand describe the benchmarking of these models.\n4.1 Task Definition\nWe designed three benchmark tasks to evaluate\nbaseline models\u2019 performance against both the re-\nliability and originality of the health information\ncollected in MM-Health. Those tasks are described\nas follows:\nTask 1: Information reliability check. This task\nevaluates the VLLMs\u2019 capability to distinguish\nwhether the provided information is reliable or un-\nreliable. We provide the models with three differ-\nent data settings: text-only data with human and\nAI content separated, text-image data with human\nand AI content separated, and text-image data with\nhuman and AI content mixed.\nTask 2: Information originality check. This task\nevaluates the VLLMs\u2019 capability to distinguish\nwhether the provided information is AI-generated,\nhuman-generated, or mixed. Following a similar\napproach to Task 1, we provide the models with\ncontent that is either separated into human and AI\ncategories or mixed.\nTask 3: Fine-Grained AI Detection Analysis.\nThis task provides deeper insights into the infor-\nmation originality check from Task 2. Since we\napplied five different text and image generation\nmodels for our MM-Health dataset, we mixed the\nAI-generated data to create twenty-five different\nvariations. This allows us to evaluate which com-\nbinations are the easiest or hardest for baseline\nmodels to detect as AI-generated.\nReliable Unreliable\nGPT4o GPT4o-mini Llama3.2-V LLaV A-1.6 Qwen2-VL GPT4o GPT4o-mini Llama3.2-V LLaV A-1.5 Qwen2-VL\nZS ZS ZS FS ZS FS ZS FS ZS ZS ZS FS ZS FS ZS FS\nTextHuman 0.499 0.499 0.500 0.499 0.500 0.494 0.499 0.499 0.334 0.328 0.246 0.376 0.077 0.348 0.162 0.348\nAI 0.499 0.500 1.000 0.436 1.000 0.498 0.500 0.499 0.183 0.105 0.020 0.238 0.010 0.101 0.019 0.113\nText &\nImageHuman 0.499 0.499 0.499 0.499 0.500 0.495 0.499 0.498 0.371 0.353 0.312 0.373 0.085 0.351 0.140 0.340\nAI 0.498 0.499 0.498 0.454 1.000 0.498 0.499 0.500 0.314 0.261 0.250 0.331 0.030 0.207 0.084 0.247\nAI-T 25% 0.499 0.499 0.499 0.468 1.000 0.497 0.498 0.500 0.347 0.304 0.287 0.349 0.065 0.267 0.124 0.302\nAI-T 50% 0.500 1.000 0.499 0.477 1.000 0.497 0.499 0.500 0.347 0.304 0.286 0.347 0.065 0.267 0.124 0.302\nAI-T 75% 1.000 1.000 1.000 0.490 1.000 0.497 0.499 0.500 0.395 0.372 0.330 0.381 0.086 0.339 0.207 0.392\nAI-I 25% 0.498 0.499 0.498 0.450 1.000 0.499 0.500 0.500 0.313 0.262 0.245 0.328 0.040 0.221 0.089 0.244\nAI-I 50% 0.499 1.000 0.499 0.450 1.000 0.499 0.500 0.499 0.310 0.264 0.253 0.333 0.043 0.219 0.075 0.231\nAI-I 75% 1.000 1.000 0.499 0.449 1.000 0.497 1.000 0.499 0.310 0.265 0.252 0.333 0.037 0.212 0.077 0.244\nTable 3: Marco F1 score of Task 1 information reliability check . \"ZS\" is zero-shot and \"FS\" is five-shot.\n4.2 Baseline Models\nWe established various multimodal baselines, in-\ncluding both proprietary and open-source mod-\nels for a comprehensive comparison. Pro-\nprietary models: We employed GPT-4o and\nGPT-4o Mini, which have demonstrated excel-\nlent performance on open-source benchmarks\nsuch as MMLU (Hendrycks et al., 2021), Hu-\nmanEval (Chen et al., 2021a), and MMMU (Yue\net al., 2024), and are widely adopted in vision\nand language research. These models serve as a\nbenchmark standard, representing the top zero-shot\nperformance that current state-of-the-art VLLMs\ncan achieve. Open-sourced models: We in-\nclude three open-source VLLMs for a comprehen-\nsive comparison. These models are: Llama-3.2-\nVision, built on the Llama-3.1-8B text model with\na 2-billion-parameter vision encoder; LLaV A-1.6,\nwhich utilises the 7-billion-parameter Qwen v1.5\nmodel with CLIP-ViT-L-336 attached via an MLP\nprojection layer; and Qwen2-VL, which employs\nMultimodal Rotary Position Embedding (M-RoPE)\nwith a 675M vision encoder and Qwen2-7B, result-\ning in a total of 7.6B parameters. These models\ndemonstrate competitive zero-shot performance on\nvision-and-language benchmarks. See appendix\nfor detailed experiment setup and prompts.\n5 Result\nTask 1: Information reliability check. The results\nof the information reliability check are presented in\nTable 3. We divide the dataset into reliable and un-\nreliable articles and apply VLLMs for binary classi-\nfication across various data settings, including text-\nonly, text-image, and mixed text-image content\nincorporating both human and AI-generated inputs.\nTo assess the impact of AI-generated content, we\nintroduce varying proportions of AI-generated con-\ntext at 25%, 50%, and 75%, in both text and image\nmodalities. Baseline models perform better at clas-\nsifying reliable articles than unreliable ones, with asignificant disparity in F1 scores observed in both\nzero-shot and five-shot settings. In zero-shot set-\nting, some models, such as Llava-1.6, GPT-4o, and\nGPT-4o-min, achieve perfect F1 scores for reliable\narticles but struggle to classify unreliable articles.\nThis may be caused by that the models tend to clas-\nsify input information as reliable without proper\nverification. In the five-shot setting, models\u2019 perfor-\nmance improve on unreliable articles but worsen\non reliable ones. This suggests that example-based\nlearning helps the models better understand content\nfor verification.\nTask 2: Information originality check. The re-\nsults of the originality check are presented in Ta-\nble 4. We classify the dataset into three categories:\nhuman-generated, AI-generated, and a mix of text-\nimage content combining human and AI inputs,\nfor multi-label classification. VLLMs are tasked\nwith distinguishing whether the input context is\nhuman, AI, or human-AI mixed. Similar to Task 1,\nwe introduce AI-generated content in both text and\nimages at proportions of 25%, 50%, and 75% to\nfurther evaluate the robustness of VLLMs in distin-\nguishing mixed content. Baseline models struggle\nto accurately classify the originality of articles in\nboth zero-shot and five-shot settings. We observe\nthat baseline models may perform worse in the\nfive-shot setting, suggesting that current VLLMs\nmay lack the ability to learn comprehensive rep-\nresentations for assessing information originality\nusing examples. GPT-4o performs the best among\nall the models, with Llama-3.2-Vision ranking as\nthe second-best model, slightly trailing GPT-4o in\nperformance. This performance difference is likely\nattributed to the larger dataset and model size used\nin GPT-4o\u2019s training.\nTask 3: Fine-grained AI detection analysis.\nWe visualise the performance of VLLMs using\nheatmaps that display the combinations of five\ntext and five image models, resulting in a total\nof twenty-five results per heatmap, as shown in\nReliable Unreliable\nGPT4o GPT4o-mini Llama3.2-V LLaV A-1.6 Qwen2-VL GPT4o GPT4o-mini Llama3.2-V LLaV A-1.6 Qwen2-VL\nZS ZS ZS FS ZS FS ZS FS ZS ZS ZS FS ZS FS ZS FS\nTextHuman 0.316 0.323 0.023 0.321 0.242 0.321 0.493 0.324 0.254 0.266 0.012 0.255 0.201 0.267 0.320 0.288\nAI 0.093 0.074 0.327 0.057 0.211 0.041 0.003 0.046 0.113 0.122 0.495 0.083 0.220 0.062 0.003 0.043\nText &\nImageHuman 0.234 0.304 0.140 0.312 0.137 0.319 0.321 0.317 0.263 0.239 0.069 0.237 0.138 0.279 0.301 0.298\nAI 0.155 0.119 0.188 0.122 0.271 0.070 0.093 0.071 0.215 0.233 0.231 0.164 0.282 0.063 0.091 0.099\nAI-T 25% 0.234 0.172 0.261 0.144 0.261 0.091 0.122 0.094 0.285 0.335 0.259 0.145 0.272 0.079 0.122 0.089\nAI-T 50% 0.268 0.188 0.316 0.173 0.239 0.118 0.143 0.125 0.306 0.339 0.284 0.159 0.270 0.091 0.111 0.097\nAI-T 75% 0.307 0.205 0.338 0.171 0.203 0.127 0.162 0.138 0.389 0.400 0.305 0.221 0.173 0.096 0.134 0.116\nAI-I 25% 0.236 0.143 0.256 0.173 0.262 0.100 0.114 0.096 0.261 0.264 0.279 0.176 0.295 0.067 0.093 0.118\nAI-I 50% 0.270 0.180 0.284 0.215 0.235 0.109 0.143 0.108 0.369 0.282 0.319 0.253 0.193 0.082 0.117 0.188\nAI-I 75% 0.322 0.218 0.333 0.246 0.185 0.134 0.156 0.130 0.358 0.275 0.316 0.203 0.154 0.093 0.118 0.194\nTable 4: Marco F1 score of Task 2 information originality check . \"ZS\" is zero-shot and \"FS\" is five-shot.\nFigure 4: Heatmap representation of the Task 3 fine-grained AI detection analysis . Each heatmap illustrates F1\nscores from various VLLMs across twenty-five different combinations of AI-generated content. Darker colours\nrepresent higher F1 scores.\nFigure 4. Each heatmap displays the F1 scores\nof different open-source VLLMs in the five-shot\nsetting, with darker colours indicating higher F1\nscores in the binary classification of AI-generated\ncontent. A comparison between the GPT-4o and\nGPT-4o-mini models in the zero-shot setting is\nprovided in the appendix Figure 11 and Fig-\nure 12 . Among the open-source models, Llama-\n3.2-Vision performs the best, followed by Qwen2-\nVL and Llava-1.6. We observe that text gener-\nated by Gemma-2-9B is more likely to be detected,\nwhile text generated by Qwen-2.5-7B is less likely\nto be detected. However, no consistent trend is\nobserved for image models. The average F1 scores\nacross all baseline models are approximately 0.2,\nindicating that none of the AI models cannot be\nreliably detected.\nThe results across all three tasks highlight the\nchallenges faced by existing SOTA VLLMs. For in-\nformation reliability check, model exhibit a strong\nbias towards reliable articles but struggle with unre-\nliable content. In the information originality check,\nmodels fail to effectively differentiate between hu-\nman, AI and mixed content, with five-shot setting\nshowing no significant improvement. The fine-\ngrained AI detection analysis decompose the model\nperformance towards different generative models,\nwith baseline models achieving low average F1scores, indicating the need for more advanced\ndetection methods. These findings demonstrate\nthat MM-Health presents a challenging benchmark\nfor the community. By releasing the MM-Health\ndataset, we aim to encourage the development of\nmore robust and effective models to accurately clas-\nsifying multimodal health misinformation.\n6 Conclusion\nWe introduce MM-Health, a multimodal dataset\ndesigned for detecting human and AI generated\nhealth misinformation. Unlike datasets limited to\nhuman generated information or augmented with\nLLM generated text, our approach combines text\nand image generative models to create multimodal\ncounterparts of misinformation. To ensure diversity\nin generative model outputs, we incorporate five\ndifferent open-source models for each modality.\nOur experiments involve five different VLLMs, in-\ncluding proprietary GPT-4o and GPT-4omini mod-\nels, as well as SOTA open-source models, to eval-\nuate data reliability and originality classification.\nExperimental results reveal that current VLLMs\ncannot accurately detect misinformation and AI-\ngenerated content, highlighting challenges in the\nera of generative AI. We hope publicly releasing\nthe MM-Health dataset guides future research.\nLimitations\nIn this work, we limited data collection to two\nmodalities due to their prevalence on mainstream\nsocial platforms. This decision restricts the range\nof misinformation addressed by MM-Health, par-\nticularly from short-video platforms like TikTok,\nthereby limiting the scope of its potential applica-\ntions. We encourage future studies to incorporate\na broader variety of modalities to further enhance\nthe diversity of machine-generated health informa-\ntion. Additionally, we exclusively employed out-\nof-the-box multimodal language models for mis-\ninformation detection, aiming to emulate common\npractices among the general public as our baseline.\nGiven the existence of several specialised models\ndesigned for misinformation detection, we suggest\nfurther research to facilitate a more comprehensive\ncomparison.\nEthical Considerations\nAll experiments strictly adhere to the Code of\nEthics. In Section 3.1.1, which details our hu-\nman evaluation in data collection, we clearly in-\nformed the human evaluators of the task and that\ntheir responses would be utilized to assess the\ncapabilities of large generative models. To en-\nsure the anonymity and privacy of individuals in-\nvolved in the data collection, we implemented a\nde-identification protocol. We directly remove all\nhuman evaluators\u2019 names associated with the gen-\nerated data, all de-identified articles are stored in\nplain text format, without any identifying informa-\ntion. The original raw data are permanently deleted\nafter the de-identification process. By taking these\nsteps, we ensure that our data collection and analy-\nsis processes align with ethical guidelines and data\nprotection regulations.\nReferences\nRebecca Abbott, Alison Bethel, Morwenna Rogers, Re-\nbecca Whear, Noreen Orr, Liz Shaw, Ken Stein, and\nJo Thompson Coon. 2021. Characteristics, quality\nand volume of the first 5 months of the COVID-19\nevidence synthesis infodemic: a meta-research study.\nBMJ Evid Based Med , 27(3):169\u2013177.\nAmirsiavosh Bashardoust, Stefan Feuerriegel, and\nYash Raj Shrestha. 2024. Comparing the willing-\nness to share for human-generated vs. ai-generated\nfake news. Proc. ACM Hum.-Comput. Interact. ,\n8(CSCW2).Israel J\u00fanior Borges do Nascimento, Ana Beatriz\nPizarro, Jussara M Almeida, Natasha Azzopardi-\nMuscat, Marcos Andr\u00e9 Gon\u00e7alves, Maria Bj\u00f6rklund,\nand David Novillo-Ortiz. 2022. Infodemics and\nhealth misinformation: a systematic review of re-\nviews. Bull World Health Organ , 100(9):544\u2013561.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\nHenrique Ponde de Oliveira Pinto, Jared Kaplan,\nHarri Edwards, Yuri Burda, Nicholas Joseph, Greg\nBrockman, Alex Ray, Raul Puri, Gretchen Krueger,\nMichael Petrov, Heidy Khlaaf, Girish Sastry, Pamela\nMishkin, Brooke Chan, Scott Gray, and 39 others.\n2021a. Evaluating large language models trained on\ncode.\nMingxuan Chen, Xinqiao Chu, and K. P. Subbalakshmi.\n2021b. Mmcovar: multimodal COVID-19 vaccine\nfocused data repository for fake news detection and a\nbaseline architecture for classification. In ASONAM\n\u201921: International Conference on Advances in Social\nNetworks Analysis and Mining, Virtual Event, The\nNetherlands, November 8 - 11, 2021 , pages 31\u201338.\nACM.\nLimeng Cui and Dongwon Lee. 2020. Coaid: COVID-\n19 healthcare misinformation dataset. CoRR ,\nabs/2006.00885.\nLimeng Cui, Haeseung Seo, Maryam Tabar, Fenglong\nMa, Suhang Wang, and Dongwon Lee. 2020. Deter-\nrent: Knowledge guided graph attention network for\ndetecting healthcare misinformation. In Proceedings\nof the 26th ACM SIGKDD International Conference\non Knowledge Discovery & Data Mining , KDD \u201920,\npage 492\u2013502, New York, NY , USA. Association for\nComputing Machinery.\nEnyan Dai, Yiwei Sun, and Suhang Wang. 2020. Ginger\ncannot cure cancer: Battling fake health news with\na comprehensive data repository. In Proceedings\nof the Fourteenth International AAAI Conference on\nWeb and Social Media, ICWSM 2020, Held Virtually,\nOriginal Venue: Atlanta, Georgia, USA, June 8-11,\n2020 , pages 853\u2013862. AAAI Press.\nHannah E Davis, Lisa McCorkell, Julia Moore V ogel,\nand Eric J Topol. 2023. Long COVID: major findings,\nmechanisms and recommendations. Nature Reviews\nMicrobiology , 21(3):133\u2013146.\nDavid Glukhov, Ilia Shumailov, Yarin Gal, Nicolas Pa-\npernot, and Vardan Papyan. 2023. Llm censorship:\nA machine learning challenge or a computer security\nproblem? Preprint , arXiv:2307.10719.\nK. Hayawi, S. Shahriar, M.A. Serhani, I. Taleb, and S.S.\nMathew. 2022. Anti-vax: a novel twitter dataset for\ncovid-19 vaccine misinformation detection. Public\nHealth , 203:23\u201330.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun. 2016. Deep residual learning for image recogni-\ntion. In 2016 IEEE Conference on Computer Vision\nand Pattern Recognition, CVPR 2016, Las Vegas,\nNV , USA, June 27-30, 2016 , pages 770\u2013778. IEEE\nComputer Society.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob Stein-\nhardt. 2021. Measuring massive multitask language\nunderstanding. In 9th International Conference on\nLearning Representations, ICLR 2021, Virtual Event,\nAustria, May 3-7, 2021 . OpenReview.net.\nDavid Holz, Jim Keller, Nat Friedman, Philip Rosedale,\nand Bill Warner. Midjourney V5.\nLiting Huang, Zhihao Zhang, Yiran Zhang, Xiyue Zhou,\nand Shoujin Wang. 2024. Ru-ai: A large multi-\nmodal dataset for machine generated content detec-\ntion. Preprint , arXiv:2406.04906.\nRohit Kumar Kaliyar, Anurag Goswami, and Pratik\nNarang. 2021. Fakebert: Fake news detection in so-\ncial media with a bert-based deep learning approach.\nMultimedia Tools Appl. , 80(8):11765\u201311788.\nLaura Kinkead, Ahmed Allam, and Michael Krautham-\nmer. 2020. Autodiscern: rating the quality of on-\nline health information with hierarchical encoder\nattention-based neural networks. BMC Medical In-\nformatics and Decision Making , 20(1):104.\nAlexander Kinsora, Kate Barron, Qiaozhu Mei, and\nV . G. Vinod Vydiswaran. 2017. Creating a labeled\ndataset for medical misinformation in health forums.\nIn2017 IEEE International Conference on Health-\ncare Informatics, ICHI 2017, Park City, UT, USA,\nAugust 23-26, 2017 , pages 456\u2013461. IEEE Computer\nSociety.\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon\nKim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang.\n2019. Biobert: a pre-trained biomedical language\nrepresentation model for biomedical text mining.\nBioinformatics , 36(4):1234\u20131240.\nYichuan Li, Bohan Jiang, Kai Shu, and Huan Liu. 2020.\nMM-COVID: A multilingual and multimodal data\nrepository for combating COVID-19 disinformation.\nCoRR , abs/2011.04088.\nHelena Liz-L\u00f3pez, Mamadou Keita, Abdelmalik Taleb-\nAhmed, Abdenour Hadid, Javier Huertas-Tato, and\nDavid Camacho. 2024. Generation and detection\nof manipulated multimodal audiovisual content: Ad-\nvances, trends and open challenges. Information\nFusion , 103:102103.\nSadiq Muhammed T and Saji K Mathew. 2022. The\ndisaster of misinformation: a review of research in\nsocial media. Int J Data Sci Anal , 13(4):271\u2013285.\nMartin M\u00fcller, Marcel Salath\u00e9, and Per E. Kummervold.\n2023. Covid-twitter-bert: A natural language pro-\ncessing model to analyse covid-19 content on twitter.\nFrontiers in Artificial Intelligence , 6.\nUsman Naseem, Matloob Khushi, Jinman Kim, and\nAdam G. Dunn. 2024. Hybrid text representation\nfor explainable suicide risk identification on social\nmedia. IEEE Trans. Comput. Soc. Syst. , 11(4):4663\u2013\n4672.Usman Naseem, Jinman Kim, Matloob Khushi, and\nAdam G. Dunn. 2022. Identification of disease or\nsymptom terms in reddit to improve health mention\nclassification. In WWW \u201922: The ACM Web Confer-\nence 2022, Virtual Event, Lyon, France, April 25 - 29,\n2022 , pages 2573\u20132581. ACM.\nCamille J. Saucier Nathan Walter, John J. Brooks and\nSapna Suresh. 2021. Evaluating the impact of at-\ntempts to correct health misinformation on social\nmedia: A meta-analysis. Health Communication ,\n36(13):1776\u20131784. PMID: 32762260.\nDat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen.\n2020. BERTweet: A pre-trained language model\nfor English tweets. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing: System Demonstrations , pages 9\u201314, On-\nline. Association for Computational Linguistics.\nTahir M. Nisar, Guru Prabhakar, and Lubica Strakova.\n2019. Social media information benefits, knowledge\nmanagement and smart organizations. Journal of\nBusiness Research , 94:264\u2013272.\nOffice of the Surgeon General (OSG). 2021. Con-\nfronting Health Misinformation: The U.S. Surgeon\nGeneral\u2019s Advisory on Building a Healthy Informa-\ntion Environment . US Department of Health and\nHuman Services.\nYvonne Oshevwe Okoro, Oluwatoyin Ayo-Farai,\nChinedu Paschal Maduka, Chiamaka Chinaemelum\nOkongwu, and Olamide Tolulope Sodamade. 2024.\nA review of health misinformation on digital plat-\nforms: Challenges and countermeasures. Interna-\ntional Journal of Applied Research in Social Sci-\nences .\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welin-\nder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instruc-\ntions with human feedback. In NeurIPS .\nVasiliki Papanikou, Panagiotis Papadakos, Theodora\nKaramanidou, Thanos G. Stavropoulos, Evaggelia\nPitoura, and Panayiotis Tsaparas. 2024. Health mis-\ninformation in social networks: A survey of it ap-\nproaches. Preprint , arXiv:2410.18670.\nHyun Jun Park. 2024. The rise of generative artificial\nintelligence and the threat of fake news and disinfor-\nmation online: Perspectives from sexual medicine.\nInvestig Clin Urol , 65(3):199\u2013201.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey\nChu, and Mark Chen. 2022. Hierarchical text-\nconditional image generation with CLIP latents.\nCoRR , abs/2204.06125.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\nPatrick Esser, and Bj\u00f6rn Ommer. 2022. High-\nresolution image synthesis with latent diffusion mod-\nels. In IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, CVPR 2022, New Orleans,\nLA, USA, June 18-24, 2022 , pages 10674\u201310685.\nIEEE.\nMaximilian Seitzer. 2020. pytorch-fid: FID Score\nfor PyTorch. https://github.com/mseitzer/\npytorch-fid . Version 0.3.0.\nLanyu Shang, Ziyi Kou, Yang Zhang, and Dong Wang.\n2022. A duo-generative approach to explainable mul-\ntimodal covid-19 misinformation detection. In Pro-\nceedings of the ACM Web Conference 2022 , WWW\n\u201922, page 3623\u20133631, New York, NY , USA. Associa-\ntion for Computing Machinery.\nIvan Srba, Branislav Pecher, Mat\u00fas Tomlein, R\u00f3bert\nM\u00f3ro, Elena Stefancova, Jakub Simko, and M\u00e1ria\nBielikov\u00e1. 2022. Monant medical misinformation\ndataset: Mapping articles to fact-checked claims. In\nSIGIR \u201922: The 45th International ACM SIGIR Con-\nference on Research and Development in Information\nRetrieval, Madrid, Spain, July 11 - 15, 2022 , pages\n2949\u20132959. ACM.\nYanshen Sun, Jianfeng He, Shuo Lei, Limeng Cui, and\nChang-Tien Lu. 2023. Med-mmhl: A multi-modal\ndataset for detecting human-and llm-generated mis-\ninformation in the medical domain. arXiv preprint\narXiv:2306.08871 .\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aur\u00e9lien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. CoRR ,\nabs/2302.13971.\nSantosh Kumar Uppada, Parth Patel, and Sivaselvan B.\n2023. An image and text-based multimodal model\nfor detecting fake news in osn\u2019s. Journal of Intelli-\ngent Information Systems , 61(2):367\u2013393.\nYuxi Wang, Martin McKee, Aleksandra Torbica, and\nDavid Stuckler. 2019. Systematic literature review on\nthe spread of health-related misinformation on social\nmedia. Social Science and Medicine , 240:112552.\nDanni Xu, Shaojing Fan, and Mohan Kankanhalli. 2023.\nCombating misinformation in the era of generative\nai models. In Proceedings of the 31st ACM Inter-\nnational Conference on Multimedia , MM \u201923, page\n9291\u20139298, New York, NY , USA. Association for\nComputing Machinery.\nXiang Yue, Yuansheng Ni, Tianyu Zheng, Kai Zhang,\nRuoqi Liu, Ge Zhang, Samuel Stevens, Dongfu\nJiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao\nYu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan\nZheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, and\n3 others. 2024. MMMU: A massive multi-discipline\nmultimodal understanding and reasoning benchmarkfor expert AGI. In IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, CVPR 2024,\nSeattle, WA, USA, June 16-22, 2024 , pages 9556\u2013\n9567. IEEE.\nJiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G\nParker, and Munmun De Choudhury. 2023a. Syn-\nthetic lies: Understanding ai-generated misinforma-\ntion and evaluating algorithmic and human solutions.\nInProceedings of the 2023 CHI Conference on Hu-\nman Factors in Computing Systems , CHI \u201923, New\nYork, NY , USA. Association for Computing Machin-\nery.\nJiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G\nParker, and Munmun De Choudhury. 2023b. Syn-\nthetic lies: Understanding ai-generated misinforma-\ntion and evaluating algorithmic and human solutions.\nInProceedings of the 2023 CHI Conference on Hu-\nman Factors in Computing Systems , CHI \u201923, New\nYork, NY , USA. Association for Computing Machin-\nery.\nXinyi Zhou, Apurva Mulay, Emilio Ferrara, and Reza\nZafarani. 2020. Recovery: A multimodal reposi-\ntory for COVID-19 news credibility research. In\nCIKM \u201920: The 29th ACM International Conference\non Information and Knowledge Management, Virtual\nEvent, Ireland, October 19-23, 2020 , pages 3205\u2013\n3212. ACM.\nRuonan Zhu, Qing Liu, Chongru Huang, and Bingyi\nKang. 2022. Z-ACM: an approximate calculation\nmethod of z-numbers for large data sets based on ker-\nnel density estimation and its application in decision-\nmaking. Inf. Sci. , 610:440\u2013471.\nA Remove Images\nExamples of removed images during health misin-\nformation collection, those images include blurry,\nlogo-based, fuzzy, or meaningless images, which\nare often downloaded during web scraping.\nFigure 5: Sample of removed images after web scrap-\nping. These images are irrelevant to the health topic,\nincluding blurry, logo-based, fuzzy, or meaningless im-\nages.\nB Overall Statics\nThe overall statics of MM-Health is presented in\nTable 5, we utilised five different generative models\nfor both text and image modalities to form the AI-\ngenerated portion of the dataset. The average text\nlength and number of images are consistent across\ndifferent sets.\nC Post-process Algorithm\nWe developed Algorithm 1 to post-process data\nalignment between the human-generated context\nand all five AI-generated contexts. Rtextand\nRimage represent the human data collected from\nthe open-source datasets, while N(k)\ntextandN(k)\nimage\nare inputs derived from AI-generated text and im-\nages, where kranges from one to five, representing\nthe five different models. The outer loop iterates\nthrough each possible text-image pair across all\nmodels, while the inner loop checks the pair Ntext i\nandNimage jagainst all five models. Only when\ntext and image pairs from all five models exist will\nthe matched data be added to Mfinal to form the\nfinal dataset.\nD Generation Prompts\nThe generation prompts are presented in Figure 6.\nWithin the prompts, text highlighted in blue repre-\nsents the raw input images extracted from the news\narticle. Green text highlights indicate the originalAlgorithm 1 Text and Image Alignment Across\nModels\nEnsure: Rtext, Rimage\nRequire: N(k)\ntext, N(k)\nimage, k= 1, ..., 5\nMfinal\u2190 \u2205\nfor all Ntext i, Nimage jdo\nmatch \u2190true\nfork\u21901to5do\nifN(k)\ntext i/\u2208Rtext\u2228N(k)\nimage j/\u2208Rimage\nthen\nmatch \u2190false\nbreak\nend if\nend for\nifmatch =truethen\nMfinal \u2190 Mfinal \u222a\n(Rtext i, Rimage j, Ntext i, Nimage j)\nend if\nend for\nreturn Mfinal\nnews article content, while grey text shows the in-\ntermediate output from GPT-4o, and orange text\ndenotes the final generated output. The generation\nexamples are shown in Figure 7, and we ensure\nthe generations are similar to the original images\nbut with modifications to mimic the real-world sce-\nnario where misinformation is only slightly differ-\nent from the truth.\nE Experiment Settings and prompts\nExperiment Settings. For the GPT-4o and\nGPT-4o mini models, we use the OpenAI\nAPI endpoints: gpt-4o-2024-08-06 and\ngpt-4o-mini-2024-07-18 , respectively, through-\nout our experiments. Open-source models are\nhosted on a server equipped with an Nvidia A6000\nGPU with 48GB of VRAM. To replicate realistic\nscenarios in most cases, we retain the default\nparameter settings for all models. To fully utilise\nthe potential of the models, we experiment with\nbaseline models using both zero-shot and five-shot\nsettings, employing consistent prompts designed\nfor different tasks. Zero-shot is directly evaluated\non the testing set, while five-shot uses five samples\nfrom the training set and evaluates the models on\nthe testing set. We use standard macro F1 scores\nto evaluate the baseline models across all three\ntasks. Since our evaluation tasks involve three\ndifferent data settings with human and AI context,\nSplit SourceReliable Unreliable\nArticle # Avg Len. Image # Avg IPA. Article # Avg Len. Image # Avg IPA.\nTrainHuman 3345 848.34 5175 1.55 809 635.77 6917 8.55\nAI 16725 463.84 25768 1.54 4045 450.56 34084 8.43\nValHuman 373 856.01 586 1.57 90 749.04 709 7.88\nAI 1865 464.34 2917 1.56 450 455.93 3415 7.59\nTestHuman 932 822.82 1435 1.54 227 669.3 1572 6.93\nAI 4660 460.21 7139 1.53 1135 450.28 7695 6.78\nOverallHuman 4650 843.84 7196 1.55 1126 651.58 9198 8.17\nAI 23250 463.15 35824 1.54 5630 450.93 45194 8.03\nTable 5: Overall statistics of the MM-Health dataset, where \"Avg Len\" represents the average word count of the\narticles, and \"Avg IPA\" indicates the average image count per article. The statistics are provided for both human and\nAI data across all data splits.\nFigure 6: AI generation prompts. Text generation prompts are shown on the left side of the figure. Image generation\nprompts are shown on the right side of the figure.\n(a) Reliable news generated from both human and AI.\n(b) Unreliable news generated from both human and AI.\nFigure 7: Examples of human and AI generated (a:) reliable and (b:) unreliable multimodal news. The examples at\nthe top represent reliable news, while those at the bottom represent unreliable news. Note that the articles have been\nrewritten on the same topic and the image details have been manipulated, as pointed by the \u21d2.\nFigure 8: Zero-shot and five-shot prompts for task 1 - information reliability check.\nFigure 9: Zero-shot and five-shot prompts for task 2 - information originality check.\nwe employ both binary classification (for human\nand AI) and multi-label classification (for human,\nAI, and mixed content).\nExperiment prompts. We also present the\nprompts used for all three tasks in the experiment,\ncovering both zero-shot and five-shot settings. Both\nproprietary and open-source models follow the\nsame prompts. Figure 8 illustrates the zero-shot\nand five-shot prompts for the information reliability\ncheck, Figure 9 depicts the prompts for the informa-\ntion originality check, and Figure 10 presents the\nprompts for the fine-grained AI detection analysis.\nArticle inputs are highlighted in green, while model\noutputs are highlighted in orange. Since models\nmay not always produce the exact output specified\nin the prompts, we run each model several times\nuntil all responses are correctly formatted to meet\nthe output requirements.F Heatmaps\nWe present the heatmaps in Figure 11 and Fig-\nure 12 for GPT4o, GPT4o-mini, Llama-3.2-Vision,\nQwen2-VL and Llava-1.6 in zero-shot setting for\ntask 3 - fine-grained AI detection analysis. All the\nmodels have been run through the exact zero-shot\nsettings and prompts as demonstrated in Figure 10.\nFigure 10: Zero-shot and five-shot prompts for task 3 - fine-grained AI detection analysis.\nFigure 11: Zero-shot GPT4o and GPT4o-mini heatmaps for task 3 - fine-grained AI detection analysis.\nFigure 12: Zero-shot Llama-3.2-Vision, Qwen2-VL and Llava-1.6 heatmaps for task 3 - fine-grained AI detection\nanalysis.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "From Generation to Detection: A Multimodal Multi-Task Dataset for Benchmarking Health Misinformation", "author": ["Z Zhang", "Y Zhang", "X Zhou", "L Huang", "I Razzak"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Infodemics and health misinformation have significant negative impact on individuals and  society, exacerbating confusion and increasing hesitancy in adopting recommended health"}, "filled": false, "gsrank": 551, "pub_url": "https://arxiv.org/abs/2505.18685", "author_id": ["zARYG3MAAAAJ", "N3V3husAAAAJ", "", "", "GlXI4N8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:BZ4MUZpgFekJ:scholar.google.com/&output=cite&scirp=550&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=BZ4MUZpgFekJ&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:BZ4MUZpgFekJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2505.18685"}}, {"title": "Tweets in time of conflict: A public dataset tracking the twitter discourse on the war between Ukraine and Russia", "year": "2023", "pdf_data": "Tweets in Time of Conflict: A Public Dataset Tracking the Twitter Discourse on\nthe War between Ukraine and Russia\nEmily Chen1,2, Emilio Ferrara1,2,3\n1Department of Computer Science, University of Southern California\n2Information Sciences Institute, University of Southern California\n3Annenberg School of Communication, University of Southern California\nechen920@usc.edu, emiliofe@usc.edu\nAbstract\nOn February 24, 2022, Russia invaded Ukraine. In the days\nthat followed, reports kept flooding in from laymen to news\nanchors of a conflict quickly escalating into war. Russia faced\nimmediate backlash and condemnation from the world at\nlarge. While the war continues to contribute to an ongoing hu-\nmanitarian and refugee crisis in Ukraine, a second battlefield\nhas emerged in the online space, both in the use of social me-\ndia to garner support for both sides of the conflict and also in\nthe context of information warfare. In this paper, we present\na collection of nearly half a billion tweets, from February\n22, 2022, through January 8, 2023, that we are publishing\nfor the wider research community to use. This dataset can\nbe found at https://github.com/echen102/ukraine-russia. Our\npreliminary analysis on a subset of our dataset already shows\nevidence of public engagement with Russian state-sponsored\nmedia and other domains that are known to push unreliable\ninformation towards the beginning of the war; the former saw\na spike in activity on the day of the Russian invasion, while\nthe other saw spikes in engagement within the first month\nof the war. Our hope is that this public dataset can help the\nresearch community to further understand the ever-evolving\nrole that social media plays in information dissemination, in-\nfluence campaigns, grassroots mobilization, and much more,\nduring a time of conflict.\nIntroduction\nTimeline of Key Events\nThe tensions between Ukraine and Russia have been on the\nrise for decades, but have substantially increased in the past\nfew years. Following the Soviet Union\u2019s dissolution in 1991,\nUkraine declared itself an independent country on August\n24, 1991 (Sullivan 2022). In 2010, the pro-Russian presi-\ndential candidate, Viktor Yanukovich, was elected into of-\nfice amid accusations of election fraud (Reuters 2022; Kahn\n2022). Yanukovich was ousted in 2014 after backing out of\nan agreement with the European Union (EU), an agreement\nwhich would have brought Ukraine closer to becoming a\nmember of the EU, in favor of engaging with Russia (Kahn\n2022).\nShortly after Yanukovich was removed from office, Rus-\nsia annexed Crimea from Ukraine against the wishes of\nCopyright \u00a9 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.the West, further exacerbating tensions between Russia and\nUkraine. Russia claimed that this action was supported by\nthe vast majority of the Crimean people, but this was also\ndenounced as a fraudulent vote by Western countries and\nUkrainian leadership (Clinch 2022; Myers and Barry 2014;\nCollett-White and Popeski 2014).\nPro-Russian separatist groups in Donetsk and Luhansk in\nthe Donbas region declared their independence, sparking the\nbeginning of the war in Donbas (Reuters 2022). Several iter-\nations of the Minsk agreement were signed between Ukraine\nand Russia in September 2014 in efforts to reach a resolu-\ntion for the war; these efforts, however, have proven to be\nunsuccessful to this day (Sullivan 2022).\nIn 2019, the current President of Ukraine, V olodymyr Ze-\nlenskyy was elected to office, and one of his intentions was\nto end the conflict in Donbas (Pereira and Reevell 2022).\nIn late 2021 through early 2022, it became clear that Rus-\nsia was amassing its forces near the Russian-Ukrainian bor-\nders. On February 21, 2022, Russia officially recognized\nthe independence of Donetsk (Donetsk People\u2019s Republic)\nand Luhansk (Luhansk People\u2019s Republic) (Westfall 2022;\nBloomberg 2022; Sullivan 2022).\nOn February 24, 2022, Russia invaded Ukraine, an act that\ndrew swift condemnation from many world leaders, includ-\ning the EU and NATO allies (McGee and Princewill 2022).\nThe Russian-Ukrainian war has caused and continues to\nbe, as of these days, a humanitarian emergency for Ukraini-\nans in the country, and has also created a refugee crisis\nas Ukrainians turned refugees flee to neighboring countries\nin large numbers (Schwirtz, Kramer, and Gladstone 2022;\nBloomberg 2022; Cengel 2022).\nOn March 2, 2022, Russia took control of Kherson,\nmarking the first major Ukrainian city to fall to Russian\ntroops (Schwirtz and P \u00b4erez-Pe \u02dcna 2022).\nAs a result of the Russian invasion, many Western pow-\ners have imposed sanctions on Russia in an attempt to de-\nter and reverse Russian aggression, and Western companies\nhave begun to withdraw their operations from Russia (Fu-\nnakoshi, Lawson, and Deka 2022).\nAs of this writing (April 2023), the war has continued to\nrage on, with causalities on both sides of the conflict (Bigg\n2023).\nProceedings of the Seventeenth International AAAI Conference on Web and Social Media (ICWSM 2023)\n1006\nSocial Media Activity\nDuring this time of conflict, information warfare and cam-\npaigns continued, both in the lead-up and in the after-\nmath of the invasion. This has taken place on a variety of\nsocial media platforms, including Twitter. Russian disin-\nformation campaigns have been rampant on social media\n(Badawy, Ferrara, and Lerman 2018; Broniatowski et al.\n2018; Badawy et al. 2019; Badawy, Lerman, and Ferrara\n2019; Dutt, Deb, and Ferrara 2019; Luceri, Giordano, and\nFerrara 2020; Ferrara et al. 2020; Ezzeddine et al. 2023).\nEvidence suggests they are being carried out both domesti-\ncally and abroad (Sharma et al. 2021; Scott 2022; La Gatta\net al. 2023; Pierri et al. 2022). However, Ukrainians have\nalso waged their social media fight against Russia, and Rus-\nsian President Vladimir Putin, by using social media plat-\nforms to promote the Ukrainian cause and garner interna-\ntional attention and support towards their current plight (Co-\nhen 2022; Garner 2022). Social media platforms have also\ntaken actions to combat misinformation and disinformation\nin the wake of the conflict (Cohen 2022; Bushwick 2022;\nFerrara 2022; Pierri, Luceri, and Ferrara 2022).\nAs the war continues to unfold, we hope that the re-\nsearch community can leverage our dataset to continue to\ncombat misinformation, identify vulnerable communities\nand understand how the pervasiveness of social media has\nchanged how modern conflict plays out both online and\non the ground. These are just a few of many potential re-\nsearch directions that this data can help to answer, partic-\nularly in times when warfare is no longer limited by geo-\ngraphic bounds. In this paper, we document how to access\nthis dataset and provide an overview of basic statistics and\ngeneral findings from our Twitter data collection.\nData Collection\nOur real-time Twitter data collection began on February 22,\n2022. We used Twitter\u2019s streaming API v1.11to track key-\nwords of interest that were both trending and related to the\nconflict at the time of collection. This version of their API\nhas since been deprecated. This list of keywords primarily\nfocused on terms related to events and locations prevalent in\nthe conflict within the first several months of the war; how-\never, we updated our list as needed. Our list of keywords is\nnot exhaustive, but we did our best to monitor ongoing dis-\ncourse and consulted knowledgeable colleagues. Prior work\nhas shown that the streaming API is not completely random,\nwhich results in some biases depending on collection and\ncollection volume (Mehrabi et al. 2021). However, we still\nleveraged the Twitter streaming API endpoint as it is the\nmost sustainable method of gathering data that still gives us\nan understanding of current Twitter discourse.\nWe also leveraged Twitter\u2019s search API to collect tweets\nprior to February 22, 2022; while we will continue to col-\nlect historical tweets, due to Twitter\u2019s rate limit on the Aca-\ndemic Track search API, we are only able to use the search\nendpoint to collect 10 million tweets each month.2Our cur-\n1https://developer.twitter.com/en/docs/twitter-api\n2https://developer.twitter.com/en/products/twitter-api/\nacademic-researchrent data collection consists of over 570 million tweets, with\nmore than 500 GB of raw data thus far. Our data collection\nconcluded in late March 2023 due to recent modifications to\nthe Twitter API. However, we remain optimistic that future\nAPI changes may enable us to recommence our data collec-\ntion efforts in due course.\nWe host the dataset on our public GitHub repository so\nthat other researchers are able to access tweet IDs that are\npertinent to the Ukraine-Russia conflict, as misinformation\nand influence campaigns have already been detected in the\nnarratives being pushed \u2013 both on and off Twitter. To re-\nmain in compliance with Twitter\u2019s Terms & Conditions, we\nare not permitted to publicly release text or metadata per-\ntaining to any specific tweet outside of their tweet IDs. As a\nresult, we have published tweet IDs so that researchers can\nuse the Twitter API or third-party tools, such as Hydrator3or\nTwarc,4to obtain the raw tweet payload. We note here that\nfor any tweet that has been removed from Twitter (Pierri,\nLuceri, and Ferrara 2022), or if the account that posted a\ntweet has been deleted, suspended, or banned, researchers\nwill be unable to retrieve the tweet content through Twit-\nter\u2019s API. Researchers can also ensure that their datasets are\nin compliance with Twitter\u2019s Terms & Conditions through\nTwitter\u2019s batch compliance endpoint to remove any tweets\nthat have since been removed or hidden from public Twitter\nfeeds.5\nTracked Keywords\nWe leveraged Twitter\u2019s trending topics and hashtags to iden-\ntify and curate a list of keywords that are pertinent to the de-\nveloping war between Ukraine and Russia. We then used this\nlist to query Twitter\u2019s streaming API for any tweets that con-\ntained the keywords of interest in the tweet\u2019s text. Twitter\u2019s\nstreaming API is capitalization agnostic, so we only need\nto track one capitalization permutation. We do, however, in-\nclude some capitalization variations of keywords, particu-\nlarly those that are not in English, to err on the side of cau-\ntion. The list of the keywords that we tracked can be found\nin Table 1, but as events continued to develop and unfold,\nwe expanded this list while consulting those more intimately\nfamiliar with the conflict. The most up-to-date keyword list\ncan be found on our GitHub repository.\nData & Access Modalities\nRelease v1.2 (October 6, 2022)\nOur third release contains tweets from the inception of our\ndata collection, February 22, 2022, 4 AM UTC, through\nthe end of October 1, 2022. This consists of a total of\n454,488,445 tweets, and we detail general statistics about\nthis release in this section. We note that we have since re-\nleased v1.5 of this dataset, but for the purposes of this paper,\nwe focus on Release v1.2. The language breakdown of re-\nlease v1.2 can be found in Table 2, and the keywords that\n3https://github.com/DocNow/hydrator\n4https://github.com/DocNow/twarc\n5https://developer.twitter.com/en/docs/twitter-api/compliance/\nbatch-compliance/quick-start\n1007\nKeywords Tracked Since Notes\nukraine 2/22/22\nrussia 2/22/22\nputin 2/22/22\nsoviet 2/22/22\nkremlin 2/22/22\nminsk 2/22/22\nukrainian 2/22/22\nNATO 2/22/22\nluhansk 2/22/22\ndonetsk 2/22/22\nkyiv 2/22/22\nkiev 2/22/22\nmoscow 2/22/22\nzelensky 2/22/22\nfsb 2/22/22\nKGB 2/22/22\n\u0423\u043a\u0440\u0430\u0457\u043d\u0430 2/22/22 Ukraine (uk)\n\u041a\u0438\u0435\u0432 2/22/22 Kiev (ru)\n\u0424\u0421\u0411 2/22/22 FSB (ru)\n\u0420\u043e\u0441\u0441\u0438\u044f 2/22/22 Russia (ru)\n\u041a\u0413\u0411 2/22/22 KGB\n\u041a\u0438\u0457\u0432 3/1/22 Kiev (uk)\n\u0443\u043a\u0440\u0430\u0457\u043d\u0438 3/1/22 ukraine (uk)\n\u0420\u043e\u0441i\u044f 3/1/22 Russia (uk)\n\u043a\u0433\u0431 3/1/22 kgb (uk/ru)\n\u0444\u0441\u0431 3/1/22 fsb (ru)\nSlavaUkraini 3/1/22 Glory to Ukraine (ru)\nukraini 3/1/22 ukraine\nU+1F1FA, U+1F1E6 3/1/22 Ukrainian Flag emoji\n\u0423\u043a\u0440\u0430\u0438\u043d\u0430 3/1/22 Ukraine (ru)\n\u0443\u043a\u0440\u0430\u0438\u043d\u044b 3/1/22 ukraine (ru)\nDonbas 3/1/22 donbas\n\u0414\u043e\u043d\u0431\u0430\u0441 3/1/22 donbas (uk)\nTable 1: Keywords that we actively tracked (v1.2 \u2014 October\n6, 2022). General notes and English translations provided in\nthe notes section. Translations are followed with the original\nkeyword language in parenthesis.\nwe were tracking are listed in Table 1. Some of the key-\nwords were added later to our live collection which impacted\nthe language proportions that we observed in our dataset;\nwe used Twitter\u2019s search API to obtain past tweets that we\nmissed in our initial collection that also contain these key-\nwords. We will be adding these additional tweet IDs in sub-\nsequent releases.\nLanguage Distribution Twitter automatically attempts to\ntag each tweet with its language ISO and includes the found\nISO in a tweet\u2019s metadata. When we investigate the language\ndistribution of the tweets, we find that English is the pre-\ndominant language that is identified. This aligns with our\nexpectations, as most of the keywords that we were initially\ntracking were all in English. When we added keywords in\nthe Ukrainian and Russian languages on March 1, 2022, we\nsaw a significant increase in the percentage of Ukrainian and\nRussian tweets in our dataset. We notice that the volume of\ntweets we collect initially averages over 4 million tweets\ncollected each day, which we attribute to Twitter limiting\nthe number of tweets we can collect due to high tweet vol-\nume (oso 2022); however, we see a gradual decline in theLanguage ISO No. tweets % total\nEnglish en 321,088,619 70.65%\nSpanish es 18,358,931 4.04%\nFrench fr 17,857,397 3.93%\nGerman de 14,533,854 3.2%\nItalian it 11,589,565 2.55%\nUndefined (und) 11,473,234 2.52%\nRussian ru 9,968,421 2.19%\nJapanese ja 9,113,466 2.01%\nUkrainian uk 8,016,384 1.76%\nTurkish tr 6,219,988 1.37%\nPortuguese pt 3,897,544 0.86%\nPolish pl 3,411,167 0.75%\nDutch nl 1,837,698 0.4%\nIndonesian in 1,607,514 0.35%\nChinese zh 1,430,735 0.31%\nTable 2: The top 15 languages in our dataset and the number\nof respective tweets. (v1.2 \u2014 October 6, 2022)\nvolume of tweets we collect as the Ukraine-Russia war con-\ntinued to rage on.\nWe also observe fluctuations in the volume of tweets\nposted in English, Ukrainian, and Russian, which, on an\nhourly granularity, matches the circadian patterns of the\ncountries that predominantly speak that language and have\na presence on Twitter. The English tweet volumes see an in-\ncrease during general waking hours that follow United States\ntime zones. This corroborates our finding, which we discuss\nlater in this paper, that most tweets originate from the United\nStates; Russian and Ukrainian tweets follow similar activity\npatterns, as Ukraine and Russia are in similar time zones.\nOur data also shows that spikes of tweets in a particular\nlanguage generally occur alongside major real-world events.\nWhen we examine the percentage of tweets that are written\nin Ukrainian and Russian, in general, Russian tweets make\nup a slightly larger percentage of the total number of tweets\nwe collected on any given day. However, there are several in-\nstances where Ukrainian tweets outnumber Russian tweets.\nFor example, on August 24, 2022, Ukrainians celebrated\ntheir independence day, which correlates with the increased\npercentage of Ukrainian tweets on that day (cf. Figure 1, bot-\ntom) (Hayda 2022; John and Kesaieva 2022).\nHashtags Table 3 lists the top 15 hashtags that we find\nused in our dataset. These hashtags are comprised of\nhashtags that are referring to groups involved or affili-\nated with the Ukraine-Russia war (e.g., #ukraine, #russia,\n#nato), and others are in support of Ukraine and against the\nwar (e.g., #standwithukraine, #stoprussia). Other commonly\nused hashtags refer to locations in Ukraine that have been\nat the center of conflict during the war (e.g., #kyiv, #mari-\nupol). The hashtag #tigray draws attention to the concurrent\nTigray war and humanitarian crisis occurring in Ethiopia,\nwith some wondering why the Ukrainian War has overshad-\nowed the conflict in Ethiopia (Cheng and Anna 2022; Walsh\n2022).\nOutside of these hashtags, other highly prevalent hashtags\ninclude #anonymous, which referred to the announcement\n1008\nFigure 1: Total volume of all tweets collected and volume of English, Ukrainian, and Russian tweets in our dataset. Note that\nwe observe a decline in overall tweet volume collected per day around March 12, 2022; tweet volume was limited by Twitter\nprior to this date due to the high volume of tweets using the keywords of interest. Engagement with these keywords began to\nwane in the following months.\nTop 15 Hashtags\nukraine\nrussia\nputin\nstandwithukraine\nukrainerussiawar\nnato\nrussian\nukrainian\nkyiv\nukrainewar\nzelensky\nmariupol\nstoprussia\nslavaukraini\ntigray\nTable 3: The top 15 hashtags used in our dataset, are listed\nin decreasing order from top to bottom. (v1.2 \u2014 October 6,\n2022)\nby the decentralized online hacking group Anonymous that\nthey would be targeting Russian government websites and\ninfrastructure while aiding Ukrainians (Pitrelli 2022).\nWhen we compare the number of tweets using a hash-tag containing the last name of the current political lead-\ners of Russia and Ukraine, we can see that #putin is much\nmore widely used than #zelenskyy. To further understand the\nmagnitude of tweets that include #putin, we also plotted the\nnumber of tweets that use #biden for the current President of\nthe United States, Joe Biden, and the number of tweets that\nuse #trump, referring to the former President of the United\nStates, Donald Trump (see Figure 2).\nIn Figure 2, we can see that #putin is used the most fre-\nquently, and experiences volatile usage which, in general,\nreacts to breaking news and events. There is a spike of en-\ngagement with Putin-related hashtags on March 4, 2022, and\na manual inspection of these tweets reveal that many users\nwere using the hashtag #SafeAirliftUkraine in tandem with\n#StopPutin, requesting the President of the United States,\nJoe Biden, to help with the evacuation of Ukrainians. This\ncoincides with reports on March 4 that, despite discussions\non temporary ceasefires the days before to establish human-\nitarian corridors to aid civilian evacuations, Russia was not\ncomplying with the agreements that were made (Stern et al.\n2022; Stern, Suliman, and Taylor 2022). While hashtags us-\ning Biden and Trump see some use, the use of a hashtag\nmentioning Zelenskyy comes the closest to matching and\nsometimes slightly surpassing the number of tweets that use\nhashtags mentioning Putin. Given that Zelenskyy is the cur-\nrent president of Ukraine, these findings fall in line with our\n1009\nRetweeted Country \u2192 Retweeter Country\nUnited States \u2192 United States\nUnited Kingdom \u2192 United Kingdom\nUkraine \u2192 United States\nUnited Kingdom \u2192 United States\nFrance \u2192 France\nUnited States \u2192 Canada\nUnited States \u2192 United Kingdom\nIndia \u2192 India\nUkraine \u2192 Ukraine\nGermany \u2192 Germany\nItaly \u2192 Italy\nCanada \u2192 United States\nTurkey \u2192 Turkey\nUkraine \u2192 United Kingdom\nSpain \u2192 Spain\nTable 4: The top 15 locations for retweets where a location\nfor both the retweeted and retweeter were identifiable. Loca-\ntions are listed in decreasing order from top to bottom. (v1.2\n\u2014 October 6, 2022)\nQuoted Country \u2192 Quoter Country\nUnited States \u2192 United States\nUnited Kingdom \u2192 United Kingdom\nUnited Kingdom \u2192 United States\nFrance \u2192 France\nUkraine \u2192 United States\nUnited States \u2192 United Kingdom\nUnited States \u2192 Canada\nGermany \u2192 Germany\nIndia \u2192 India\nUnited States \u2192 Japan\nJapan \u2192 Japan\nSpain \u2192 Spain\nRussia \u2192 United States\nCanada \u2192 Canada\nItaly \u2192 Italy\nTable 5: The top 15 locations for quoted tweets where a loca-\ntion for both the quoted user and user quoting a tweet were\nidentifiable. Locations are listed in decreasing order from\ntop to bottom. (v1.2 \u2014 October 6, 2022)\nexpectations.\nLocations of Tweeters In each tweet\u2019s metadata that Twit-\nter\u2019s API returns, we are given information about the user\nwho posted a tweet. This will sometimes contain geoloca-\ntion data from the user\u2019s post, but in previous works, we\nhave observed less than 1% of our dataset is returned with\nTwitter\u2019s own geolocation information (Jiang et al. 2020).\nThus, if a user manually provides a location in their user pro-\nfile, we use this as a proxy to determine where a user is lo-\ncated (Jiang et al. 2020). While this is not a perfect method,\nthis is one of the only ways we can ascertain a user\u2019s general\nor affiliated physical location on a larger scale.\nWe find that most tweets originate from the United Statesand the United Kingdom, which are primarily English-\nspeaking countries. Given that the vast majority of our initial\nkeywords were in English, this matches our expectations.\nThere are two different ways a user can retweet a post \u2013\na user can simply retweet a post without adding additional\ncommentary (we refer to this type of tweet as retweets) or\na user can add additional text to the post (which we refer to\nas aquoted tweet). If user A retweets or quotes user B, we\nconsider the direction of the retweet or quote to be from user\nB to user A. For quoted and retweeted tweets, we list the top\n15 locations in Table 4 where we were able to identify a lo-\ncation for both the retweeted and the retweeter. We do the\nsame for quoted tweets in Table 5.\nInterestingly, we find that users in the United States\nquote users from Ukraine 3.34 times more than they quote\nusers from Russia; users that are retweeting tweets from the\nUnited States are 9.11 times more likely to retweet users\nfrom Ukraine as opposed to users from Russia. Users from\nthe United States retweeting users from Russia is the 25th\nmost frequent location pairing.\nDomain Sharing Finally, we take a look at the domains\nthat users post as a part of their tweets. We consider any\ndomain that is included within a user\u2019s tweet as a do-\nmain that the user has shared, including domains that are\npart of a retweet. Within the top 50 domains that were\nshared, we find several domains that are known Russia state-\nsponsored media (www.RT.com), or tagged as questionable\n(www.rumble.com) and prone to conspiracies and pseudo-\nscience (www.zerohedge.com) by Media Bias / Fact Check\n(MBFC) (Zandt 2022). MBFC is an independently operated\nwebsite that classifies domains into certain factual and po-\nlitical lean categories, based on specific criteria that are de-\nscribed further on their per domain synopsis (Zandt 2022).\nWhile the number of tweets that interact with these partic-\nular domains make up a small proportion of all tweets posted\nabout the Ukraine-Russia war, we do see a fairly consistent\nnumber of tweets that interact with these domains over time\n(cf. Figure 3). ZeroHedge is the most consistently posted\nover our observation period, but we do note that these do-\nmains experience spikes in engagement occurred within the\nfirst month of the war, with Rumble being shared in the most\ntweets in early March.\nAccess\nOur dataset can be found on GitHub at: https://github.com/\nechen102/ukraine-russia.\nDue to recent changes to the Twitter API, we are no longer\nable to update this dataset with new data as of late March\n2023. We hope to resume our collection and regular updates\nin the future if subsequent API changes allow us to do so.\nGiven that monthly rate limits have significantly decreased,\nwe suggest interested parties take a random sample of tweet\nIDs to hydrate over the desired time frame.\nResearchers who would like to use our collected data must\nremain in compliance with Twitter\u2019s Terms & Conditions,6\n6https://developer.twitter.com/en/developer-terms/agreement-\nand-policy\n1010\nFigure 2: Total volume of tweets that use the hashtags #biden, #trump, #putin and #zelenskyy. For #zelenskyy, we also counted\n#zelensky. The capitalization of a hashtag did not matter, as we lower-cased all hashtags.\nFigure 3: Total volume of tweets that share specific domains in our dataset. RT.com is a known Russian state-owned media com-\npany, while MBFC has classified rumble.com as questionable and zerohedge.com as prone to conspiracy and pseudoscience.\nand agree upon the terms of usage as outlined in the accom-\npanying license.\nEthical Considerations\nAs mentioned earlier in this paper, we are only able to pub-\nlish the tweet IDs associated with our collected tweets as a\npart of our data collection. This is to ensure that we remain in\ncompliance with Twitter\u2019s developer terms of service, which\nrestrict us from publicly publishing any individual tweet in-\nformation outside of the tweet\u2019s unique ID. All tweets that\ncan be retrieved by the end user are tweets that are publicly\naccessible \u2013 any tweet that has been deleted, made private,\nor was tweeted by a user that has since made their account\nprivate, was suspended, or deleted their account is no longer\naccessible.\nThe collection of this dataset was IRB-approved by USC.\nInquiries\nIf you have technical questions about the data collection,\nplease refer to the issues section in the GitHub repository\nor contact Emily Chen at echen920@usc.edu.\nFor any further questions about this dataset, please contact\nDr. Emilio Ferrara at emiliofe@usc.edu.Acknowledgments\nThe authors gratefully acknowledge support from DARPA\n(contract no. HR001121C0169). The authors also thank\nKristina Lerman, Jon May, and our lab for helping to iden-\ntify pertinent keywords to track in our ongoing data collec-\ntion.\nReferences\n2022. Suspicious Twitter Activity around the Russian Inva-\nsion of Ukraine. Technical report, Indiana University.\nBadawy, A.; Addawood, A.; Lerman, K.; and Ferrara, E.\n2019. Characterizing the 2016 Russian IRA influence cam-\npaign. Social Network Analysis and Mining, 9: 1\u201311.\nBadawy, A.; Ferrara, E.; and Lerman, K. 2018. Analyzing\nthe digital traces of political manipulation: The 2016 Rus-\nsian interference Twitter campaign. In 2018 IEEE/ACM in-\nternational conference on advances in social networks anal-\nysis and mining (ASONAM), 258\u2013265. IEEE.\nBadawy, A.; Lerman, K.; and Ferrara, E. 2019. Who falls for\nonline political manipulation? In Companion proceedings of\nthe 2019 world wide web conference, 162\u2013168.\nBigg, M. M. 2023. Russia invaded Ukraine more than 10\nmonths ago. here is one key development from every month\n1011\nof the war. https://www.nytimes.com/article/ukraine-russia-\nwar-timeline.html. Accessed: 2023-01-15.\nBloomberg. 2022. A Visual Guide to the Russian In-\nvasion of Ukraine. https://www.bloomberg.com/graphics/\n2022-ukraine-russia-us-nato-conflict/. Accessed: 2023-01-\n15.\nBroniatowski, D. A.; Jamison, A. M.; Qi, S.; AlKulaib, L.;\nChen, T.; Benton, A.; Quinn, S. C.; and Dredze, M. 2018.\nWeaponized health communication: Twitter bots and Rus-\nsian trolls amplify the vaccine debate. American journal of\npublic health, 108(10): 1378\u20131384.\nBushwick, S. 2022. Russia\u2019s information war is\nbeing waged on social media platforms. https:\n//www.scientificamerican.com/article/russia-is-having-\nless-success-at-spreading-social-media-disinformation/.\nAccessed: 2023-01-15.\nCengel, K. 2022. The 20th-century history behind Russia\u2019s\ninvasion of Ukraine. https://www.smithsonianmag.com/\nhistory/the-20th-century-history-behind-russias-invasion-\nof-ukraine-180979672/. Accessed: 2023-01-15.\nCheng, M.; and Anna, C. 2022. WHO chief:\nLack of help for Tigray Crisis due to Skin Color.\nhttps://apnews.com/article/russia-ukraine-covid-health-\n09bce36f33719f793eaa79e1de520ad4. Accessed: 2023-01-\n15.\nClinch, M. 2022. How Russia invaded Ukraine\nin 2014. and how the markets tanked. https:\n//www.cnbc.com/2022/01/27/how-russia-invaded-ukraine-\nin-2014-and-how-the-markets-tanked.html. Accessed:\n2023-01-15.\nCohen, R. 2022. A surge of unifying moral outrage\nover Russia\u2019s war. https://www.nytimes.com/2022/03/\n01/world/europe/zelensky-ukraine-war-outrage.html. Ac-\ncessed: 2023-01-15.\nCollett-White, M.; and Popeski, R. 2014. Crimeans\nvote over 90 percent to quit Ukraine for Russia.\nhttps://www.reuters.com/article/us-ukraine-crisis/crimeans-\nvote-over-90-percent-to-quit-ukraine-for-russia-\nidUKBREA1Q1E820140316. Accessed: 2023-01-15.\nDutt, R.; Deb, A.; and Ferrara, E. 2019. \u201cSenator, We Sell\nAds\u201d: Analysis of the 2016 Russian Facebook Ads Cam-\npaign. In Advances in Data Science: Third International\nConference on Intelligent Information Technologies, ICIIT\n2018, Chennai, India, December 11\u201314, 2018, Proceedings\n3, 151\u2013168. Springer.\nEzzeddine, F.; Luceri, L.; Ayoub, O.; Sbeity, I.; Nogara,\nG.; Ferrara, E.; and Giordano, S. 2023. Characterizing and\nDetecting State-Sponsored Troll Activity on Social Media.\narXiv:2210.08786.\nFerrara, E. 2022. Twitter Spam and False Accounts Preva-\nlence, Detection and Characterization: A Survey. First Mon-\nday, (27).\nFerrara, E.; Chang, H.; Chen, E.; Muric, G.; and Patel, J.\n2020. Characterizing social media manipulation in the 2020\nUS presidential election. First Monday.Funakoshi, M.; Lawson, H.; and Deka, K. 2022. Track-\ning sanctions against Russia. https://graphics.reuters.\ncom/UKRAINE-CRISIS/SANCTIONS/byvrjenzmve/. Ac-\ncessed: 2023-01-15.\nGarner, I. 2022. How is the war going for Putin on social me-\ndia? not great. https://www.washingtonpost.com/outlook/\n2022/03/04/russian-social-media-ukraine-vk-propaganda/.\nAccessed: 2023-01-15.\nHayda, J. 2022. Kyiv hosts a different kind of\nparade to celebrate Ukraine\u2019s Independence Day.\nhttps://www.npr.org/2022/08/21/1118700800/ukraine-\nindependence-day-russia-war. Accessed: 2023-01-15.\nJiang, J.; Chen, E.; Yan, S.; Lerman, K.; and Ferrara, E.\n2020. Political Polarization Drives Online Conversations\nAbout COVID-19 in the United States. HBET, 2: 200\u2013211.\nJohn, T.; and Kesaieva, Y . 2022. Ukraine\u2019s Inde-\npendence Day darkened by Deadly Missile Strike.\nhttps://www.cnn.com/2022/08/23/europe/ukraine-\nindependence-day-kyiv-display-intl/index.html. Accessed:\n2023-01-15.\nKahn, J. 2022. Who is Viktor Yanukovych? the ousted\nUkrainian president that Putin hopes to put back in power.\n{https://fortune.com/2022/03/02/viktor-yanukovych-\nyanukovich-putin-put-back-in-power-ukraine-russia/},\nnote = Accessed: 2023-01-15.\nLa Gatta, V .; Wei, C.; Luceri, L.; Pierri, F.; and Ferrara, E.\n2023. Retrieving false claims on Twitter during the Russia-\nUkraine conflict. WWW\u201923 Companion Proceedings.\nLuceri, L.; Giordano, S.; and Ferrara, E. 2020. Detecting\ntroll behavior via inverse reinforcement learning: A case\nstudy of Russian trolls in the 2016 us election. In Proceed-\nings of the international AAAI conference on web and social\nmedia, volume 14, 417\u2013427.\nMcGee, L.; and Princewill, N. 2022. World lead-\ners respond to Ukraine invasion, as fresh sanctions\nawait Russia. https://www.cnn.com/2022/02/24/europe/\nglobal-response-to-russia-ukraine-intl/index.html. Ac-\ncessed: 2023-01-15.\nMehrabi, N.; Morstatter, F.; Saxena, N.; Lerman, K.; and\nGalstyan, A. 2021. A survey on bias and fairness in machine\nlearning. ACM Computing Surveys (CSUR), 54(6): 1\u201335.\nMyers, S. L.; and Barry, E. 2014. Putin reclaims Crimea\nfor Russia and bitterly denounces the west. https://www.\nnytimes.com/2014/03/19/world/europe/ukraine.html. Ac-\ncessed: 2023-01-15.\nPereira, I.; and Reevell, P. 2022. What to know\nabout Ukrainian President V olodymyr Zelenskyy.\nhttps://abcnews.go.com/International/ukrainian-president-\nvolodymyr-zelenskyy/story?id=83085078. Accessed:\n2023-01-15.\nPierri, F.; Luceri, L.; and Ferrara, E. 2022. How does Twit-\nter account moderation work? Dynamics of account cre-\nation and suspension during major geopolitical events. arXiv\npreprint arXiv:2209.07614.\nPierri, F.; Luceri, L.; Jindal, N.; and Ferrara, E. 2022. Propa-\nganda and Misinformation on Facebook and Twitter during\n1012\nthe Russian Invasion of Ukraine. 15th ACM Web Science\nConference 2023.\nPitrelli, M. B. 2022. Global Hacking Group\nAnonymous launches \u2019Cyber War\u2019 against Russia.\nhttps://www.cnbc.com/2022/03/01/how-is-anonymous-\nattacking-russia-disabling-and-hacking-websites-.html.\nAccessed: 2023-01-15.\nReuters. 2022. Timeline: The events leading up to Russia\u2019s\ninvasion of Ukraine. https://www.reuters.com/world/europe/\nevents-leading-up-russias-invasion-ukraine-2022-02-28/.\nAccessed: 2023-01-15.\nSchwirtz, M.; Kramer, A. E.; and Gladstone, R. 2022.\nHumanitarian crisis worsens for Ukrainians trapped in\nRussia\u2019s onslaught. https://www.nytimes.com/2022/03/07/\nworld/europe/ukraine-humanitarian-crisis-russia.html. Ac-\ncessed: 2023-01-15.\nSchwirtz, M.; and P \u00b4erez-Pe \u02dcna, R. 2022. First Ukraine\nCity Falls as Russia strikes more civilian targets. https:\n//www.nytimes.com/2022/03/02/world/europe/kherson-\nukraine-russia.html. Accessed: 2023-01-15.\nScott, M. 2022. As war in Ukraine evolves, so do disin-\nformation tactics. https://www.politico.eu/article/ukraine-\nrussia-disinformation-propaganda/. Accessed: 2023-01-15.\nSharma, K.; Zhang, Y .; Ferrara, E.; and Liu, Y . 2021. Identi-\nfying Coordinated Accounts on Social Media through Hid-\nden Influence and Group Behaviours. In Proceedings of the\n27th ACM SIGKDD Conference on Knowledge Discovery &\nData Mining, 1441\u20131451.\nStern, D. L.; Firozi, P.; Paquette, D.; Pannett, R.;\nFrancis, E.; Dixon, R.; Pa \u00b4ul, M. L.; Knowles, H.;\nand Kornfield, M. 2022. Limited cease-fire reached\nfor civilian evacuations as Russian forces cut off Key\nCities. https://www.washingtonpost.com/world/2022/03/03/\nrussia-ukraine-war-putin-news/. Accessed: 2023-01-15.\nStern, D. L.; Suliman, A.; and Taylor, A. 2022. Russia\nnot cooperating on proposed humanitarian corridor in Kher-\nson, Ukrainian officials say. https://www.washingtonpost.\ncom/world/2022/03/04/kherson-ukraine-russia/. Accessed:\n2023-01-15.\nSullivan, B. 2022. Russia\u2019s at war with Ukraine. Here\u2019s how\nwe got here. https://www.npr.org/2022/02/12/1080205477/\nhistory-ukraine-russia. Accessed: 2023-01-15.\nWalsh, D. 2022. After secret U.S. talks fail, a hidden war\nin Africa rapidly escalates. https://www.nytimes.com/2022/\n10/08/world/africa/ethiopia-tigray-war-talks-us.html. Ac-\ncessed: 2023-01-15.\nWestfall, S. 2022. Why are Donetsk and Luhansk\nin Ukraine\u2019s Donbas region a flash point for Putin?\nhttps://www.washingtonpost.com/world/2022/02/21/what-\nis-donbas-donetsk-luhansk-conflict/. Accessed: 2023-01-\n15.\nZandt, D. M. V . 2022. Media Bias/Fact Check. https:\n//mediabiasfactcheck.com/. Accessed: 2023-01-15.\n1013", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tweets in time of conflict: A public dataset tracking the twitter discourse on the war between Ukraine and Russia", "author": ["E Chen", "E Ferrara"], "pub_year": "2023", "venue": "Proceedings of the International AAAI Conference \u2026", "abstract": "On February 24, 2022, Russia invaded Ukraine. In the days that followed, reports kept  flooding in from laymen to news anchors of a conflict quickly escalating into war. Russia faced"}, "filled": false, "gsrank": 552, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/22208", "author_id": ["nSIGqY8AAAAJ", "0r7Syh0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:GZrJU8NJQLAJ:scholar.google.com/&output=cite&scirp=551&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=GZrJU8NJQLAJ&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 128, "citedby_url": "/scholar?cites=12700232052457970201&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:GZrJU8NJQLAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/22208/21987"}}, {"title": "The dawn of decentralized social media: an exploration of bluesky's public opening", "year": "2024", "pdf_data": "The Dawn of Decentralized Social Media: An\nExploration of Bluesky\u2019s Public Opening\nErfan Samieyan Sahneh1[0009\u22120004\u22124924\u22122315], Gianluca\nNogara1[0000\u22120002\u22124412\u2212131X], Matthew R. DeVerna2[0000\u22120003\u22123578\u22128339], Nick\nLiu2, Luca Luceri3[0000\u22120001\u22125267\u22127484], Filippo Menczer2[0000\u22120003\u22124384\u22122876],\nFrancesco Pierri4[0000\u22120002\u22129339\u22127566], and Silvia Giordano1[0000\u22120003\u22122603\u22129029]\n1ISIN - DTI, SUPSI, Lugano, Switzerland erfan.samieyan@supsi.ch\n2Observatory on Social Media, Indiana University, Bloomington, USA\n3Information Sciences Institute, USC, Los Angeles, California, USA\n4Dip. Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Italy\nAbstract. Bluesky is a Twitter-like decentralized social media platform\nthat has recently grown in popularity. After an invite-only period, it\nopened to the public worldwide on February 6th, 2024. In this paper, we\nprovide a longitudinal analysis of user activity in the two months around\nthe opening, studying changes in the general characteristics of the plat-\nform due to the rapid growth of the user base. We observe a broad dis-\ntribution of activity similar to more established platforms, but a higher\nvolume of original than reshared content, and very low toxicity. After\nopening to the public, Bluesky experienced a large surge in new users\nand activity, especially posting English and Japanese content. In particu-\nlar, several accounts entered the discussion with suspicious behavior, like\nfollowing many accounts and sharing content from low-credibility news\noutlets. Some of these have already been classified as spam or suspended,\nsuggesting effective moderation.\nKeywords: Bluesky \u00b7decentralization \u00b7online social media \u00b7misinformation.\n1 Introduction\nBluesky Social5is a novel decentralized social media platform for microblogging\nbased in the United States. Originally based on invite-only subscription, Bluesky\nofficially opened to the public on February 6th, 2024 [29]. With only a few\nthousand users active in January 2024, the platform registered more than one\nmillion new users on the first day of its opening [6].\nBluesky is built upon the Authenticated Transfer (AT) protocol [17], which\naims to enable modern social media and online conversations to function simi-\nlarly to the early web, where individuals could easily create blogs or use Really\nSimple Syndication (RSS) feeds to follow multiple blogs. This approach is in-\ntended to foster a more open and decentralized online community [20] compared\n5https://bsky.social/aboutarXiv:2408.03146v1  [cs.SI]  6 Aug 2024\n2 E. Samieyan Sahneh et al.\nto \u201cwalled-garden\u201d platforms like Facebook and Twitter/X. The AT protocol is\nan open framework for creating social applications, offering users insight into\ntheir construction and development. It establishes a standard format for user\nidentity, following mechanisms, and data across social applications, facilitating\ninteroperability between apps and empowering users to transfer their accounts\neffortlessly. Thus, Bluesky\u2019s model aims to promote competition among devel-\nopers, who are free to build various interfaces, filters, and additional services.\nAccording to Bluesky, this competitive environment should decrease the neces-\nsity for censorship as the best solutions naturally gain prominence [5].\nIn this paper, we provide the first exploration of how opening the Bluesky\nplatform to the public affected key metrics of interest. We investigate patterns of\nuser activity, their political leaning, and the quality of information circulating on\ntheplatform.Crucially,weexplorethesecharacteristicsbothbeforeandafterthe\nplatform was opened to the public. For a general analysis of the activity on the\nplatform during the first year, we refer the reader to contemporary work [13,27].\n2 Related work\nDistributed social networks aim for decentralization, allowing users to have more\ncontrol and privacy. Early efforts like LifeSocial.KOM [14] and PeerSON [8]\nwere based on the peer-to-peer model but faced challenges in performance and\nreliability.Thisledtoashifttowardserver-basedfederatedmodelslikeMastodon\n[28,32].Thisapproachbalancesflexibilityandeaseofusewhilemaintainingsome\ndecentralization [7].\nMastodon, created in 2016, is a free and open-source social media platform\nthatallowsuserstocreatetheirownservers(\u201cinstances\u201d)andconnectwithothers\nacross the globe. It is a decentralized social network, meaning that it is not\nowned by a single entity, but rather a network of independent servers that are\nconnected together. A number of studies have identified striking features that\nmake up Mastodon\u2019s distinct \u201cfingerprint,\u201d distinguishing it from better-known\nonline social networks [7,10]. Mastodon has, however, suffered from some natural\npressurestowardscentralization,whichcanleadtopotentialpointsoffailure[28].\nTo overcome this weakness, Bluesky developed its own AT protocol in order\nto provide decentralization, with several features that distinguish it from other\nauthentication protocols. Scalability, security, and ease of use make it an attrac-\ntive option for building open and decentralized social media applications that\nprioritize user privacy and data security [17]. Using standard web technologies\nand re-using existing data models from the Web 3.0 protocol family also con-\ntribute to its efficiency and reliability [12]. Additionally, its federated networking\nmodel bolsters security by dispersing data across numerous servers, mitigating\nthe risk of a single point of failure [28]. As mentioned above, two contemporary\nwork on Bluesky have been published: [13,27]. Unlike this work, they provide a\ngeneral analysis of Bluesky\u2019s first-year activities.\nAn Exploration of Bluesky\u2019s Public Opening 3\noriginal reply repost total %\nmessages 30,235,716 20,842,322 20,530,919 71,608,957\nwith links 3,215,963 339,921 2,683,874 6,239,758 8.57%\nactive users 2,734,569\nsharing messages 1,752,083\nwith links 389,077 14.22%\nfollow actions 39,214,164\nblock actions 2,799,597\nTable 1. Basic statistics of the Bluesky dataset.\n3 Methods\nThe present analysis is based on data collected in a two-month period around\nthe time that the platform opened to the public.\n3.1 Data collection\nWe collected data by accessing Bluesky\u2019s public and free \u201cFirehose\u201d endpoint,\nwhich provides developers with real-time access to atomic actions performed on\nBluesky such as user posts, follows, likes, etc. [2,4]. If a real-time connection\nwith Bluesky is interrupted, the endpoint enables data collectors to resume col-\nlection from the moment the connection was lost, retrieving data from up to 72\nhours prior. This ensures comprehensive data coverage throughout the observed\ntimeframe. We utilized the dartlibrary from the AT protocol [3] to fetch data\nby invoking the com.atproto.sync.subscribeRepos endpoint, also known as\nthe Firehose endpoint [16]. This process, facilitated by an existing open-source\nproject [9], is straightforward and flexible due to the absence of user authenti-\ncation requirements in the AT protocol.\nBluesky enables tracking of various user activities on the platform. Our anal-\nyses focus on several key actions: posts, replies, reposts, follows, and blocks.\nThese actions represent the main forms of user interaction and communication.\nUsers follow others to stay updated, create posts to share content or repost con-\ntent created by others, and reply to engage in discussions. While the Bluesky\nterms of service do not impose privacy restrictions on the data collection, we\ncollect only public information about users, posts, and any attached metadata\nin accordance with Bluesky\u2019s Privacy Policy.6We do not make the data publicly\navailable and only provide anonymized information in this paper, except for a\nfew prominent accounts in \u00a74.8.\nTable 1 provides basic statistics of our dataset, which spans 56 days, from\nJan 9th to March 4th 2024, and comprises 114 million activities (message actions\nplus other actions like follow and block).\n6https://bsky.social/about/support/privacy-policy\n4 E. Samieyan Sahneh et al.\n3.2 News source labeling\nTo assess the reliability of news outlets shared on Bluesky, we label web do-\nmains using NewsGuard7ratings, following a consolidated approach in the liter-\nature [25,30]. NewsGuard is a reputable and unbiased organization that employs\nexperts to evaluate news sources based on factors such as transparency, account-\nability, adherence to journalistic standards, and error correction to determine\ncredibility. NewsGuard ratings range from 0 (highly unreliable) to 100 (highly\nreliable). Approximately 6.2 million posts (8.7% of all posts) contained a URL.\nOf these, we were able to label around 1 million (16% of posts with URLs, and\n1.4% of all posts) with a NewsGuard rating. The average rating of the posts with\nlinks in the social network is high, close to 94. We further define low-credibility\nwebsites as news outlets with a NewsGuard rating of 30 or lower, following pre-\nvious literature [21,24,26]. We also leveraged political bias ratings from Media\nBias/Fact Check,8an independent organization that rates news media sources,\nto label the political leaning of news websites shared on Bluesky. Information\nsources are categorized across a seven-point political spectrum: Extreme Left\n(-3), Left (-2), Left-Center (-1), Least Biased (0), Right-Center (1), Right (2),\nand Extreme Right (3).\n4 Results\n4.1 Online activity\nFig. 1.Complementary cumulative distribution of\nuser activity (number of original posts) on Bluesky\nduring one day (March 4, 2024). The dashed line is\na power-law fit of the distribution, which yields a\nslope of 1.53 ( xmin = 1, xmax = 1,000).We observe in Table 1 that\noriginal posts are the most\ncommon user activity on\nthe platform, indicating that\nusers tend to create more\noriginal content rather than\nreshare or interact with ex-\nisting posts. This contrasts\nwith centralized social media\nplatforms, such as Twitter/X,\nwhereresharingthroughretweets\nis more prevalent [1,19], and\nis likely due to the sudden in-\ncrease in the user-base.\nThe daily average number\nof posts per active user is 3.16\n(95% CI: [3.13, 3.20]). How-\never,theuseractivityisquiteheterogeneous.Fig.1illustratesthatthenumberof\ndaily posts xfollows a broad, power-law distribution P(x)\u223cx\u2212\u03b1with \u03b1\u22482.53.\n7https://www.newsguardtech.com/\n8https://mediabiasfactcheck.com/\nAn Exploration of Bluesky\u2019s Public Opening 5\nThis exponent value is consistent across different days, ranging between 2.50\nand 2.71. This extreme level of heterogeneity indicates that the average is not\na good statistical descriptor of the activity distribution, as the fluctuations are\nveryhigh:mostuserspostinfrequentlybutanon-negligiblefractionpostsseveral\nhundred messages per day.\n4.2 Temporal patterns\nTo investigate the impact of the Bluesky opening on its user base, Fig. 2 plots\nthe daily number of active users and following actions. The platform\u2019s opening\non February 6th (dashed line) resulted in spikes of activity, up to 1 million\nactive users and over 7 million follow actions on the following day. These spikes\nin behavior represent an almost six-fold increase in active users and an almost\n35-fold increase in following actions, relative to the day before the opening. Both\ntrends decreased rapidly in the following days, stabilizing at levels slightly higher\nthan those seen before the opening, likely as the initial excitement around the\nnew platform subsided.\nDuring the entire observation period, 287,539 users blocked a total of 758,681\naccounts, yielding a ratio of 2.7 block actions per user. The average number of\nblock actions per user is higher (9.5) because this blocking activity is heteroge-\nnous, with some users blocking many accounts. Fig. 2 shows that an increase\nin users and following activities is associated with a rise in blocking activities,\nwith a 3.6-fold increase from 33,269 to 120,054 instances of blocking. After a few\ndays, the frequency of blocking activities stabilized but remained slightly higher\nthan the levels observed before February 6.\nFig. 3 illustrates the volume of shared posts over time. We distinguish user-\nsharing activities into original posts, replies, and reposts, as described in \u00a73.1.\nTable 1 previously highlighted that original posts are the most prevalent type\nof shared activity, a trend that becomes particularly prominent following the\nplatform\u2019s public launch.\nFig. 2.UseractivityonBlueskybeforeand\nafter the opening. The vertical dashed line\nrepresents the date of the opening (Feb 6).\nFig. 3.Sharing activity on Bluesky before\nand after the opening. The vertical dashed\nline represents the date of the opening.\n6 E. Samieyan Sahneh et al.\nAs expected, we observe a significant increase in the volume of shared content\ncoinciding with the platform\u2019s opening on February 6th. This surge is reflected\nin all types of sharing activities, likely due to the influx of new users joining\nduring this period, as shown in Fig. 2. Specifically, the volume of original posts\nincreased approximately 4.3 times, from 362k on February 5th to 1.5M the fol-\nlowing day. Reposts and replies also rose from 262,201 and 297,717 to 990,835\nand 656,063, respectively. Despite these substantial initial increases, the volume\nof each activity type diminished in the subsequent days.\n4.3 Languages\nFig. 4.Top 10 languages in Bluesky. Bars of the same\ncolor sum to one.To examine the language\ndistributioninuser-shared\ncontent, we removed ir-\nrelevant text (e.g., URLs,\nemojis, etc.) and applied\na language classifier using\nthelangdetect9NLP li-\nbrary.\nFig. 4 displays the\nprevalence of the top 10\nlanguages in user posts,\nhighlighting a dominance\nof English and Japanese,\nwhich together comprise more than two-thirds of all content. Prevalence of En-\nglish content decreased from 43% to 30% after the platform\u2019s opening, while\nthe share of Japanese content increased from 14% before the opening to 44%\nafterward.\nFig. 5.Trend of 5 top languages on Bluesky during the\nobservation period.Fig. 5 illustrates the\ntrends of the top five lan-\nguages used during the\nobservation period. We\nnote a significant increase\nin Japanese posts just\nafter the opening, mak-\ning it the most used lan-\nguage. Meanwhile, con-\ntent in other languages,\nincludingEnglish,remains\nrelatively similar to how\nit was before the opening,\nexperiencing only small\nfluctuations following the\nopening.\n9https://pypi.org/project/langdetect/\nAn Exploration of Bluesky\u2019s Public Opening 7\nFig. 6.Websites shared on Bluesky: in blue, we highlight the websites that are neither\nsocial media nor shortened links.\nFig. 7.Websites shared on Bluesky excluding social media and shortened links.\n4.4 Information sources\nFig.6 illustrates the ten domains most shared before and after February 6. We\nobserve that the most common links are either to other social media platforms,\nBluesky itself, or link-shortening services like bit.lyandt.co, Twitter\u2019s built-\nin service. This appears to suggest that a great deal of content on Bluesky is in\nreference to other, more mainstream platforms.\nFig. 7 presents the same information after removing links to social media\nplatforms (spotify.com, twitter.com, x.com, twitch.tv, youtu.be, youtube.com,\nbsky.app, instagram.com) and link shorteners (t.co, bit.ly, t.me). This procedure\nallows us to observe that content from news and information outlets like The\nGuardian ,The New York Times , and Wikipedia constituted a larger share of the\ncontentbeforetheplatform\u2019sopeningtothepublic.Consistentwiththelanguage\nanalysis (\u00a74.3), we observe a surge in Japan-related activity, with a high percent-\nage of links to Japanese websites following the opening (yahoo.co.jp, pixiv.net,\nnote.com, and dlsite.com). Patreon and Ko-fi, two platforms for crowdfunding\nand content creation, rank as the most shared web domains beyond social me-\ndia and news platforms. While such sites have been used to launch fundraising\ncampaigns in times of distress [31], manual inspection reveals that Patreon is\nprimarily used to promote adult content on Bluesky.\n8 E. Samieyan Sahneh et al.\n4.5 Political leaning\nFig. 8.Political leaning of Bluesky users (with at least\n5 rated posts) before and after February 6. Leanings are\ncalculated by averaging the political alignment of web-\nsites shared by each user. The violin plots also display\nthe interquartile range (box) and median (horizontal line\ninside the box).Fig. 8 shows the distri-\nbution of the estimated\npolitical alignment of ac-\ntive Bluesky users, de-\nfined as those engaging\nin at least five posts\nwith links to rated web-\nsites. The political align-\nment of each user is ob-\ntained by averaging the\npolitical alignment of the\nwebsites they share dur-\ning the observation pe-\nriod (see \u00a73.2). We used\na Mann-Whitney test and\ndid not find a statistically\nsignificant difference be-\ntween the distributions of\nthe political leanings before and after the opening ( p= 0.05).\nFig. 9.Political leaning of Bluesky posts before and after Feb. 6.Similarly,\nwe analyzed\nthedistribu-\ntion of the\nestimatedpo-\nlitical align-\nmentofposts\n(Fig.9).While\nnosignificant\ndifferencewas\nfound atthe\nuserlevelbe-\nfore and af-\ntertheopen-\ning,somevari-\nation is ob-\nservedatthe\npostlevel,par-\nticularly among right-center (Mann-Whitney: p= 0.03), right ( p= 0.046), and\nextreme-right posts ( p= 0.008).\n4.6 Credibility\nThenumberofuserssharinganylinkwithacredibilityratingis36,713beforeand\n47,612 after the opening. A small fraction of these (0.12%) shared low-credibility\ncontent.\nAn Exploration of Bluesky\u2019s Public Opening 9\nFig. 10 illustrates the production of low-credibility content before and after\nthe opening. While the volume of this content on Bluesky remained low (around\n0.4% of all posts on an average day), we find that it significantly increased after\nthe opening (Mann-Whitney: p < 0.001).\nFig. 10. Distributions of the percentage of posts linking to low-credibility sources, out\nof all posts linking to rated sites, for each day in the periods before and after the\nplatform opened.\nFig. 11. Most shared low-credibility websites before Feb. 6.\nFig.11reportsonthemostsharedlow-credibilitywebsitesbeforetheopening.\nThe list remained similar after the opening, with the notable exception of the\ntopwebsite, wsws.org ,whosesharesdecreasedtohalfofthepercentagerecorded\nprior to the opening. This is not due to a decrease in the share of this domain,\nbut rather to the increase in the share of all domains.\nSimilar to what has been reported for Twitter [11,15,23,26], we identified\na small subset of users responsible for most of the unreliable content shared in\n10 E. Samieyan Sahneh et al.\nFig. 12. Number of users sharing links with credibility ratings before and after the\nopeningfordifferentsubsetsofusers.Left:Userswhoonlysharedlinkstolow-credibility\nsources. Right: Users who shared at least one low-credibility link.\nBluesky\u2019s brief existence. In particular, we observe that ten accounts (1.8% of\nall users who spread low-credibility content) are responsible for spreading 62%\nof links to low-credibility sources. Manual inspection of each account confirms\nthat all were created before the platform opened to the public and remain active\nat the time of writing. Furthermore, they exhibit suspicious behavior, posting\na high volume of content almost exclusively from low-credibility news outlets,\npossibly in automated fashion.\nF 12 shows the number of users sharing links to low-credibility sources before\nandaftertheopening,distinguishingbetweennewandexistingusers.Weobserve\nthat the number of users who only shared low-credibility links quadrupled after\nthe opening. The number of those who shared at least one low-credibility link\napproximately doubled.\n4.7 Toxicity\nWe used the Perspective API [18] to analyze the toxicity of shared content in\nboth English and Japanese.\nAs illustrated in Fig. 13 (top), English content tends to have higher toxicity\nscores. Fig. 13 (bottom) shows that while, on average, the toxicity of English\ncontent is three times higher than that of Japanese content, the values remain\nstable over time.\n4.8 Follower network\nIn Fig. 2, we observed a significant increase in the following activities. This\nincrease is reflected in various follower network statistics before and after the\nopening, as detailed in Table 2. While the density of the follower network slightly\nAn Exploration of Bluesky\u2019s Public Opening 11\nFig. 13. Toxicity of Bluesky posts in English (EN) and Japanese (JA). Top: Distribu-\ntion of toxicity for the entire observation period. Bottom: Weekly running average of\ndaily toxicity scores. The dashed red line indicates the platform opening.\ndecreased after the opening, the size of the strongly connected component more\nthan tripled, and the average degree more than doubled, indicating that Bluesky\nusers tend to follow more accounts after the opening. The out-degree distribu-\ntions in Fig. 14 confirm this trend.\nTable 3 presents the ten accounts that gained the most new followers along-\nside the ten accounts that followed the most other users before and after the\nFig. 14. Complementary cumulative out-\ndegree distributions of node in the follower\nnetwork.\nFig. 15. Complementary cumulative in-\ndegree distributions of node in the follower\nnetwork.\n12 E. Samieyan Sahneh et al.\nBefore Feb. 6 After Feb. 6 Difference\nNumber of nodes 1,088,539 2,751,272 1,662,733\nNumber of edges 5,230,054 28,838,739 \u221223,608,685\nDensity 4.4\u00d710\u221263.8\u00d710\u22126\u2212.6\u00d710\u22126\nAvg. in-degree 9.6 20.3 10.7\nAvg. out-degree 7.4 14.9 7.5\nLSCC size \u223c200k \u223c650k \u223c450k\nTable 2. Follower network statistics. LSCC stands for the largest strongly connected\ncomponent.\nAccounts with most new followers Accounts who followed most accounts\nBefore Feb. 6 After Feb. 6 Before Feb. 6 After Feb. 6\nAccount Num. Account Num. Account Num. Account Num.\nBluesky /arrows-al\u25ce-h43,801 Bluesky /arrows-al\u25ce-h120,709 user 50,570 user\u1f4c5\u2642radiation167,220\nuser/arrows-al\u25ce-h 10,256 user\u1f4c5 88,438 user 24,588 user\u1f4c5 85,075\nuser 9,886 user/arrows-al\u25ce-h 66,535 user/user-times23,482 user\u1f4c5 55,073\nWash. Post /arrows-al\u25ce-h8,508NY Times /arrows-al\u25ce-h62,087 user 21,907 user\u1f4c5 45,848\nNY Times /arrows-al\u25ce-h8,393Wash. Post /arrows-al\u25ce-h60,904 user 13,414 user\u1f4c5/user-minus44,588\nuser 6,809 user 55,081 user 12,310 user/user-times 44,460\nBluesky CEO 6,314 user\u1f4c5 54,944 user 10,689 user\u1f4c5/user-minus43,786\nuser/arrows-al\u25ce-h\u1f4f0 5,744Bloomberg /arrows-al\u25ce-h54,800 user 9,950 user\u1f4c5\u2642radiation40,926\nuser/arrows-al\u25ce-h\u1f4f0 5,621user/arrows-al\u25ce-h\u1f4f0 52,455 user 8,211 user\u1f4c5 37,209\nBloomberg /arrows-al\u25ce-h5,332user\u1f4c5 49,697 user 7,588 user\u1f4c5 36,189\nAccount type:\u2642radiationspam;/user-minusdeleted;/user-timessuspended; Japanese;\u1f4f0Journalist.\nTime key:\u1f4c5created after Feb. 6;/arrows-al\u25ce-hpresent before and after Feb. 6.\nTable 3. Annotated list of the ten users with the most new followers and the ten users\nwho performed most follow activities before and after the platform\u2019s opening. Only the\nreal names of prominent accounts are included for privacy reasons.\nplatform\u2019s opening. For comparison, the average number of followers before and\nafter February 6th is 9.6 and 20.3, respectively, while the median is 3.0 and 4.0,\nrespectively.\nThe average number of accounts followed by Bluesky users before and after\nFebruary 6th is 7.4 and 14.9, respectively, while the median is 2.0 and 4.0, re-\nspectively. This analysis points to a potentially spammy behavior: some accounts\nfollowed a suspiciously large number of users right after joining the Bluesky, as\nillustrated in Fig. 14.\nThe crossover in the tail (just before degree 105) in the out-degree CCDF\ncurvesisduetotheunevendistributionoffollowactivitiesandtothediscrepancy\nin the number of users before and after the opening. In fact, both before and\nafter the opening, we have only one outlier user who performed a high number\nof follow actions (respectively, 50,570 and 167,220 actions, which is about 2-3\ntimes the number of actions of other users in Table 3). Furthermore, since the\nusers who performed follow actions before the opening are about 1/3compared\nto the users who performed follow actions after (see Table 2), the probability in\nAn Exploration of Bluesky\u2019s Public Opening 13\nthe CCDF tail for the first is higher than the one for the latter. When we remove\nthese two outlier users, this crossover between the two CCDF curves disappears.\nTheCCDF curvesforthe in-degreedistributions before andafterthe opening\nare illustrated in Fig. 15. Table 3 report the ten top users for both periods.\nAmong the users that gained the most followers, several are consistent across\nboth periods, with the majority being news outlets, such as Washington Post ,\nNew York Times , and Bloomberg . This prevalence of news outlets among the ac-\ncounts with the most new followers suggests that Bluesky may be evolving into\nanotherplatformfornewsdissemination,potentiallyreplacingTwitter.However,\nduring the observed period, three new Japanese accounts emerged in this cate-\ngory, with one reaching the second position, behind the official Bluesky account.\nBefore the platform\u2019s opening, the users who followed the most new accounts\nwere primarily English-language accounts and appeared to engage in normal\nactivity, except for one user suspended by Bluesky. However, after the opening,\nthe composition of these users changed significantly: half were Japanese, two\naccounts were deleted, one was suspended, and two were classified as spam by\nBluesky. Unlike the overall network behavior, these users were more engaged in\nreposting activities than in creating original posts.\n5 Discussion\nWe provided the first large-scale analysis of how opening the Bluesky platform\nto the public affected user activity and network structure. We observe a broad\ndistribution of activity similar to that of more established platforms; however,\nthere is a higher volume of original content compared to reshared content. This,\ncoupledwiththeverylowtoxicityweobserved,contrastswithother(centralized)\nsocial media platforms. After opening to the public, Bluesky experienced a large\nsurge in new users, especially posting English and Japanese content, and activi-\nties. The significant increase in Japanese users deserves further investigation; it\nmight signify a conversational system that is more appealing to this population.\nWe observed no significant changes in the toxicity level and in the political\nleaning of users, but some variation is observed at the post level. Further, we\ndiscovered some users exhibiting suspicious behavior, such as connecting with\nmany other users and sharing content from low-credibility news outlets. We also\nidentifiedasmallsubsetofusersresponsibleforthemajorityofunreliablecontent\nshared, echoing similar findings on platforms like Twitter/X. Additionally, after\nthe platform\u2019s opening, a subset of users that followed the most new accounts\nduring this time were flagged as spam or were even deleted or suspended. These\nfindings suggest some attempts to misuse Bluesky. However, the fact that some\nof the suspicious and misbehaving actors have already been banned or tagged as\nspam indicates that content moderation is taking place on Bluesky.\nThis work has some limitations. First, it is based on a relatively short period\n(56 days), during which a significant change occurred\u2014allowing anyone to join.\nSecond, it was not possible to trace 8% of the reposts back to their original posts\nas they predated our data collection period. Third, the websites for which we\n14 E. Samieyan Sahneh et al.\nhave credibility and political bias scores make up a small fraction of all links\nshared. Finally, our analysis of toxicity is limited only to English and Japanese\ncontent.\nFutureworkcouldincorporateamoreextendedmulti-languageanalysisthrough\ntools like Perspective API, which can evaluate toxicity in various languages [22],\nas well as longitudinal analyses of user behavior and network structure.\nAcknowledgments\nThis work was partially supported by the Swiss National Science Foundation\n(grant number CRSII5_209250) and the Italian Ministry of Education (PRIN\nPNRR grant CODE prot. P2022AKRZ9 and PRIN grant DEMON\nprot. 2022BAXSPY).\nReferences\n1. Alshaabi, T., Dewhurst, D.R., Minot, J.R., Arnold, M.V., Adams, J.L., Danforth,\nC.M., Dodds, P.S.: The growing amplification of social media: Measuring temporal\nand social contagion dynamics for over 150 languages on Twitter for 2009\u20132020.\nEPJ data science 10(1), 15 (2021)\n2. AT Protocol: Event Stream. https://atproto.com/specs/event-stream\n3. atprotodart.com: Bluesky | Dart package. Software library, https://pub.dev/\npackages/bluesky , accessed: 2024-04\n4. Bluesky: Firehose. https://www.docs.bsky.app/docs/advanced-guides/\nfirehose , accessed: 2024-04-29\n5. Bluesky: FAQ: What is Bluesky? (2024), https://bsky.social/about/faq , last\naccessed 17 April 2024\n6. Bluesky: One million new users since we opened Bluesky yesterday! (2024), https:\n//bsky.app/profile/bsky.app/post/3kkv3clm3su2h , post on Bluesky. Last ac-\ncessed 16 April 2024\n7. Bono, C.A., La Cava, L., Luceri, L., Pierri, F.: An Exploration of Decentralized\nModeration on Mastodon. In: Proc. 16th ACM Web Science Conference. pp. 53\u201358\n(2024)\n8. Buchegger, S., Schi\u00f6berg, D., Vu, L.H., Datta, A.: PeerSoN: P2P social networking:\nearly experiences and insights. In: Workshop on Social Network Systems (2009),\nhttps://api.semanticscholar.org/CorpusID:15841016\n9. Burghardt, K.: Data collection with Bluesky Firehose endpoint. https://github.\ncom/KeithBurghardt/bluesky_firehose/tree/main , accessed: 2024-04\n10. Cava, L.L., Greco, S., Tagarelli, A.: Understanding the growth of the Fediverse\nthrough the lens of Mastodon. Applied Network Science 6(2021), https://api.\nsemanticscholar.org/CorpusID:235669708\n11. DeVerna, M.R., Aiyappa, R., Pacheco, D., Bryden, J., Menczer, F.: Identifying and\ncharacterizing superspreaders of low-credibility content on Twitter. PLOS ONE\n19(5), e0302201 (2024), https://doi.org/10.1371/journal.pone.0302201\n12. Edwards, C.: Social Media and the Distributed Self. Engineering & Technology\n18(4), 40\u201346 (2023)\n13. Failla, A., Rossetti, G.: \u201cI\u2019m in the Bluesky Tonight\": Insights from a Year Worth\nof Social Data. arXiv preprint arXiv:2404.18984 (2024)\nAn Exploration of Bluesky\u2019s Public Opening 15\n14. Graffi, K., Gross, C., Stingl, D., Hartung, D., Kovacevic, A., Steinmetz, R.: Life-\nSocial.KOM: A secure and P2P-based solution for online social networks. 2011\nIEEE Consumer Communications and Networking Conference (CCNC) pp. 554\u2013\n558 (2011), https://api.semanticscholar.org/CorpusID:10789841\n15. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B., Lazer, D.: Fake news\non Twitter during the 2016 U.S. presidential election. Science 363(6425), 374\u2013378\n(2019), https://doi.org/10.1126/science.aau2706\n16. Kato, S.: Bluesky Firehose endpoint. https://atprotodart.com/docs/lexicons/\ncom/atproto/sync/subscriberepos/ , accessed: 2024-04\n17. Kleppmann, M., Frazee, P., Gold, J., Graber, J., Holmgren, D., Ivy, D., Johnson,\nJ., Newbold, B., Volpert, J.: Bluesky and the AT Protocol: Usable Decentralized\nSocial Media. arXiv preprint 2402.03239 (2024), https://arxiv.org/pdf/2402.\n03239.pdf\n18. Lees, A., Tran, V.Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., Vasserman, L.:\nA new generation of Perspective API: Efficient multilingual character-level trans-\nformers. In: The 28th ACM SIGKDD Conference on Knowledge Discovery and\nData Mining (KDD\u201922). pp. 3197\u20133207 (2022)\n19. Luceri, L., Cardoso, F., Giordano, S.: Down the bot hole: Actionable insights from\na one-year analysis of bot activity on Twitter. First Monday (2021)\n20. Masnick, M.: Protocols, Not Platforms: A Technological Approach to Free Speech.\nTechnical Report. Knight First Amendment Institute at Columbia University.\nLast accessed 16 April 2024 (2019), https://knightcolumbia.org/content/\nprotocols-not-platforms-atechnological-approach-to-free-speech\n21. Nogara, G., Pierri, F., Cresci, S., Luceri, L., Giordano, S.: Misinformation and\nPolarization around COVID-19 vaccines in France, Germany, and Italy. Proc. 16th\nACM Web Science Conference 2024 (2024)\n22. Nogara, G., Pierri, F., Cresci, S., Luceri, L., T\u00f6rnberg, P., Giordano, S.: Toxic Bias:\nPerspective API misreads German as more toxic. arXiv preprint arXiv:2312.12651\n(2023)\n23. Nogara, G., Vishnuprasad, P.S., Cardoso, F., Ayoub, O., Giordano, S., Luceri, L.:\nThe Disinformation Dozen: An Exploratory Analysis of Covid-19 Disinformation\nProliferation on Twitter. Proc. 14th ACM Web Science Conference 2022 (2022),\nhttps://api.semanticscholar.org/CorpusID:249993446\n24. Pierri, F.: The diffusion of mainstream and disinformation news on Twitter: the\ncase of Italy and France. In: Companion Proc. of The Web Conference (WWW).\npp. 617\u2013622 (2020)\n25. Pierri, F., DeVerna, M.R., Yang, K.C., Axelrod, D., Bryden, J., Menczer, F.: One\nYear of COVID-19 Vaccine Misinformation on Twitter: Longitudinal Study. Jour-\nnal of Medical Internet Research 25(2023)\n26. Pierri, F., Tocchetti, A., Corti, L., Di Giovanni, M., Pavanetto, S., Brambilla, M.,\nCeri, S.: VaccinItaly: monitoring Italian conversations around vaccines on Twitter\nand Facebook. arXiv preprint arXiv:2101.03757 (2021)\n27. Quelle, D., Bovet, A.: Bluesky: Network Topology, Polarisation, and Algorithmic\nCuration. arXiv preprint arXiv:2405.17571 (2024)\n28. Raman, A., Joglekar, S., Cristofaro, E.D., Sastry, N.R., Tyson, G.: Challenges in\nthe Decentralised Web: The Mastodon Case. Proc. Internet Measurement Confer-\nence (2019), https://api.semanticscholar.org/CorpusID:202565923\n29. Silberling,A.:Blueskyisnowopenforanyonetojoin(2024), https://techcrunch.\ncom/2024/02/06/bluesky-is-now-open-for-anyone-to-join/ , last accessed 16\nApril 2024\n16 E. Samieyan Sahneh et al.\n30. Yang, K.C., Pierri, F., Hui, P.M., Axelrod, D., Torres-Lugo, C., Bryden, J.,\nMenczer, F.: The COVID-19 Infodemic: Twitter versus Facebook. Big Data &\nSociety 8(1) (2021)\n31. Ye, J., Jindal, N., Pierri, F., Luceri, L.: Online networks of support in distressed\nenvironments: solidarity and mobilization during the Russian invasion of Ukraine.\nIn: Companion Proc. Intl. AAAI Conf. on Web and Social Media (ICWSM) (2023)\n32. Zignani, M., Gaito, S., Rossi, G.P.: Follow the \u201cMastodon\": Structure and Evo-\nlution of a Decentralized Online Social Network. In: International Conference\non Web and Social Media (2018), https://api.semanticscholar.org/CorpusID:\n49418536", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The dawn of decentralized social media: an exploration of bluesky's public opening", "author": ["ES Sahneh", "G Nogara", "MR DeVerna", "N Liu"], "pub_year": "2024", "venue": "\u2026 on Advances in Social \u2026", "abstract": "Bluesky is a Twitter-like decentralized social media platform that has recently grown in  popularity. After an invite-only period, it opened to the public worldwide on February 6th, 2024. In"}, "filled": false, "gsrank": 553, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-78541-2_26", "author_id": ["qTDdbDMAAAAJ", "s09SqmEAAAAJ", "bhEp-joAAAAJ", "osxyayQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:L7WdPHMrYv4J:scholar.google.com/&output=cite&scirp=552&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=L7WdPHMrYv4J&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 4, "citedby_url": "/scholar?cites=18330261207289541935&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:L7WdPHMrYv4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2408.03146"}}, {"title": "Effective Yet Ephemeral Propaganda Defense: There Needs to Be More than One-Shot Inoculation to Enhance Critical Thinking", "year": "2025", "pdf_data": "Effective Yet Ephemeral Propaganda Defense: There Needs to Be\nMore than One-Shot Inoculation to Enhance Critical Thinking\nNicolas Hoferer\nnicolas.hoferer@uzh.ch\nUniversity of Zurich\nZurich, SwitzerlandKilian Sprenkamp\nkilian.sprenkamp@uzh.ch\nUniversity of Zurich\nZurich, SwitzerlandDorian Christoph Quelle\ndorian.quelle@math.uzh.ch\nUniversity of Zurich\nZurich, Switzerland\nDaniel Gordon Jones\ndanielgordon.jones@uzh.ch\nUniversity of Zurich\nZurich, SwitzerlandZoya Katashinskaya\nzoya.katashinskaya@uzh.ch\nUniversity of Zurich\nZurich, SwitzerlandAlexandre Bovet\nalexandre.bovet@uzh.ch\nUniversity of Zurich\nZurich, Switzerland\nLiudmila Zavolokina\nliudmila.zavolokina@unil.ch\nUniversity of Lausanne\nLausanne, Switzerland\nUniversity of Zurich\nZurich, Switzerland\nAbstract\nIn today\u2019s media landscape, propaganda distribution has a signifi-\ncant impact on society. It sows confusion, undermines democratic\nprocesses, and leads to increasingly difficult decision-making for\nnews readers. We investigate the lasting effect on critical thinking\nand propaganda awareness on them when using a propaganda de-\ntection and contextualization tool. Building on inoculation theory,\nwhich suggests that preemptively exposing individuals to weakened\nforms of propaganda can improve their resilience against it, we\nintegrate Kahneman\u2019s dual-system theory to measure the tools\u2019 im-\npact on critical thinking. Through a two-phase online experiment,\nwe measure the effect of several inoculation doses. Our findings\nshow that while the tool increases critical thinking during its use,\nthis increase vanishes without access to the tool. This indicates a\nsingle use of the tool does not create a lasting impact. We discuss\nthe implications and propose possible approaches to improve the\nresilience against propaganda in the long-term.\nCCS Concepts\n\u2022Information systems ;\u2022Human-centered computing \u2192Em-\npirical studies in HCI ;\u2022Computing methodologies \u2192Machine\nlearning ;\nKeywords\npropaganda detection, Large Language Models, contextualization,\none-shot prompting\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\n\u00a92025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1395-8/2025/04\nhttps://doi.org/10.1145/3706599.3720125ACM Reference Format:\nNicolas Hoferer, Kilian Sprenkamp, Dorian Christoph Quelle, Daniel Gordon\nJones, Zoya Katashinskaya, Alexandre Bovet, and Liudmila Zavolokina. 2025.\nEffective Yet Ephemeral Propaganda Defense: There Needs to Be More than\nOne-Shot Inoculation to Enhance Critical Thinking. In Extended Abstracts\nof the CHI Conference on Human Factors in Computing Systems (CHI EA \u201925),\nApril 26-May 1, 2025, Yokohama, Japan. ACM, New York, NY, USA, 13 pages.\nhttps://doi.org/10.1145/3706599.3720125\n1 Introduction\nAccording to the World Economic Forum\u2019s Global Risks Report\n2024 [ 25], spreading misinformation and propaganda is a major\nglobal risk. It can undermine democratic values, increase societal\npolarization and lead to violence [ 15]. The rise of generative AI,\nespecially Large Language Models (LLMs), has simplified rapid pro-\npaganda distribution, while the difficulty of distinguishing between\nfake and real news complicates combating its spread.\nInoculation theory [ 4,28] offers a promising approach for build-\ning resistance against propaganda. By exposing individuals to a\nweakened form of propaganda, it strengthens resistance to future,\nmore potent attempts [ 12]. It works analogously to medical vac-\ncines, strengthening individuals\u2019 \u201cimmunity\u201d against propaganda.\nFor instance, Roozenbeek et al. [33] demonstrated that short inoc-\nulation videos improved resilience against propaganda on social\nmedia, though their impact on critical thinking (CT) remains un-\nclear.\nWhile traditional inoculation approaches rely on human-designed\ninterventions, technological developments offer new possibilities\nfor implementing them at scale. Machine learning approaches\nhave recently been developed for the task of propaganda detec-\ntion [ 11,39], including LLMs-based methods [ 36]. Automatic detec-\ntion of propaganda enables the creation of tools that nudge users\nabout propaganda techniques used in online news articles they\nare reading. For example, Zavolokina et al. [42] demonstrated thatarXiv:2503.16497v1  [cs.HC]  11 Mar 2025\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\nan LLM-based propaganda detection tool enhances CT and propa-\nganda awareness through nudging. While this work highlights the\nimmediate improvements in users\u2019 CT and awareness by such tools,\nthe question remains whether these effects persist once the tool is\nno longer used.\nTo address this gap, we developed a browser extension for pro-\npaganda detection and contextualization. Our tool implements in-\noculation theory through three key functions: detection and high-\nlighting of potential propaganda, explanations for deconstructing\npropaganda techniques, and presentation of additional contextual\ninformation. The contextual information is curated factual informa-\ntion and source details that help users understand why a statement\nmay be propagandistic and how it fits into the broader context.\nTogether, these features expose users to propaganda in a controlled\nway while simultaneously providing them with the understanding\nand tools to avoid being influenced by it - the core principles of\ninoculation theory.\nWe design five levels of exposure: (1) a control group receiving\nno inoculation intervention, (2) a low-dose group only receiving an\noverview of propaganda techniques, (3) a first medium-dose group\nusing the tool with propaganda detection and explanations, (4) a\nsecond medium-dose group getting the detection and contextual\ninformation related to the statement but no explanation, and (5) a\nhigh-dose group receiving the detection, the explanations and the\ncontextual information. The aim of these varying levels of exposure\nis to see if the inoculation doses affect users\u2019 CT and propaganda\nawareness differently. Our work specifically aims to investigate the\nfollowing two research questions:\nRQ1 Does exposure to a propaganda detection and contextualiza-\ntion tool lead to lasting improvements in CT after the tool is\nno longer available?\nRQ2 How do different inoculation doses (low, medium, high) af-\nfect CT and propaganda awareness?\nOur findings indicate that while the tool improves CT and pro-\npaganda awareness during its use, these improvements do not last\nonce the tool is no longer accessible. Even participants who showed\na positive immediate effect returned to baseline levels without the\ntool. These results suggest our approach is not sufficient to achieve\nlong-term improvement. We conclude our work by proposing alter-\nnative approaches.\n2 Related work\nThe challenge of combating propaganda effectively requires an\napproach that provides immediate help but also builds long-term\nresistance. Although propaganda detection systems [ 11,36] can\nprovide immediate assistance, their limited accessibility shows the\nneed for publicly available solutions that also help news readers\ndevelop independent CT [36].\n2.1 Propaganda Detection and\nContextualization\nPropaganda involves intentionally manipulating opinions using\nrhetorical and psychological strategies, such as loaded language\n(i.e., employing words or phrases with strong emotional implica-\ntions) [ 9]. Traditional approaches framed propaganda detection as\na classification problem [ 2,3,10,24], requiring extensive labeleddatasets and offering only limited interpretability. Da San Martino\net al. [9] systematically analyzed and defined 14 propaganda tech-\nniques, providing a comprehensive framework for understanding\npropaganda (detailed in Table 3 in the Appendix C). We leverage\ntheir established taxonomy of propaganda techniques as a basis for\nour tool.\nRecent developments in LLMs opened up new possibilities [ 36].\nIn particular, LLMs offer three key advantages. First, they enable\npropaganda detection through prompt-based learning without the\nneed for specialized datasets. Secondly, they can generate explana-\ntions about why it may be propaganda [ 42], making it more trans-\nparent and educational for users. Third, they are able to retrieve and\nsynthesize contextual information, helping users evaluate content\nbetter.\nSeveral approaches have been developed, from automated fact-\nchecking to generalist information retrieval systems [ 31,38,40,\n43]. While fact-checking systems show potential, their discrete\ntrue/false classifications can lead to excess false positives when\ndealing with predominantly true information. Instead of solely\nrelying on LLM judgments, a more effective approach may be to use\nLLMs to retrieve and synthesize relevant contextual information,\nallowing readers to form their own informed conclusions.\nOur tool combines three components: first, propaganda is de-\ntected, then the tool provides both an explanation of the techniques\nused and relevant contextual information to help readers evaluate\nthe content. This integrative approach aims not only to nudge read-\ners to potential propaganda but also to support their understanding\nof how propaganda works and provide context for independent\nassessment, which should lead to improved CT.\n2.2 Critical Thinking and Inoculation Theory\nOur approach builds on two theoretical frameworks: dual-process\ntheory and inoculation theory. CT refers to a human\u2019s ability to\nanalyze facts, evidence, and arguments to form a judgment through\nrational, skeptical, and unbiased evaluation [ 16]. Dual process theo-\nries explain how we think and make decisions by categorizing cog-\nnitive processes into two systems: System 1 (automatic) and System\n2 (reflective) [ 18,37]. System 1 is fast and intuitive, handling routine\ntasks like driving, while System 2 is slower and more deliberate,\nallowing for in-depth analysis [ 18]. Though System 2\u2019s thought-\nful approach seems superior, System 1\u2019s efficiency in managing\neveryday tasks\u2014like walking or talking\u2014is crucial. When dealing\nwith multiple demanding tasks, people may switch to System 1,\neven when System 2\u2019s critical analysis would be more suitable. This\nshift can lead to reliance on heuristics, which can introduce biases\nlike confirmation bias, favoring information that supports existing\nbeliefs [ 6]. Kahneman\u2019s studies identify six key characteristics of\ndual process thinking, summarized in Table 2 in the Appendix B.\nThese are essential for understanding how individuals engage in\nCT and whether they rely on System 1 or System 2 for decisions.\nWe use these characteristics in our study to capture the CT of our\nparticipants, i.e., news readers. Despite the broad acceptance of dual\nprocess theory, it has been criticized for oversimplifying cognitive\nprocesses by dividing them into two distinct systems [13].\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\nInoculation theory [ 28] offers a relevant extension to dual pro-\ncess thinking, particularly in the context of resistance to propa-\nganda. Here, the idea is to strengthen resistance to propaganda\nby exposing individuals to weakened forms of deceptive content\nor to refute it [ 7]. This approach has been successfully applied by\nMaertens et al. [23]. They investigated the long-term effectiveness\nof inoculation against misinformation. Recent work used inocula-\ntion with conversational agents and LLMs to improve propaganda\nawareness [ 34]. Roozenbeek et al. used inoculation videos [ 33] and\ngames [ 32] to improve propaganda awareness. Furthermore, Bas-\ntani et al. [5] showed how LLMs can hinder skill acquisition and\neven harm long-term learning, even when there might be an initial\nimprovement in immediate performance. Similarly, Kasneci et al.\n[20] observe that generative AI tools may be used as a \"crutch\",\nthus diminishing users\u2019 problem-solving skills.\nTo our best knowledge, no previous studies have combined these\ntwo theories within the context of propaganda detection and con-\ntextualization tools and different inoculation dosages. While ex-\nisting work showed immediate benefits, it remains unclear how\nlong inoculation effects persist in terms of CT. This work offers an\nopportunity for designing interventions that promote CT and im-\nprove resistance to propaganda, particularly in times of increasingly\nrealistic manipulative content.\n3 Propaganda Detection and Contextualization\nTool\nOur tool is a browser extension designed to assist users in identify-\ning propaganda within news articles. Figure 1 shows an example\nusage of the tool. The architecture diagram is shown in Appendix\nA.\nA user can select text on a webpage via a right mouse click and\nchoose propaganda detection with or without contextualization.\nThe marked text is sent to a FastAPI endpoint where a prompt\ntemplate (Appendix D.1) instructs GPT-4o [ 26] to detect propaganda.\nThe OpenAI API [ 27] identifies propaganda from the 14 techniques\ndefined by Da San Martino et al. [8] and provides explanations. The\nfrontend highlights the propaganda and adds annotations, as shown\nin Figure 4, by matching the output to the the correct locations on\nthe website.\nThe \u201ccontextualizer\u201d provides the user with factual information\non a selected text using Google Cloud Platform\u2019s search capabil-\nities with specialized source filtering mechanisms. The filtering\nprocess excludes sources through a predefined database of problem-\natic websites scraped from Media Bias/Fact Check (MBFC)1that\nincludes all links classified as \u201cquestionable\u201d. This filtering helps\nensure that when users search for text from an article, they are not\nredirected back to unreliable sources that may have originated the\nmisinformation.\nThe response format has two main sections: Context and Sources.\nThe Context section presents simplified, factual information about\nthe topic, while the Sources section lists the used references. This\nstructure helps users verify information and build resistance to pro-\npaganda by making facts and their verification easily accessible. The\ncontextual information is generated and extracted from the search\n1https://mediabiasfactcheck.comresult by an LLM using the Reasoning and Act (ReAct) prompt\nframework [ 41]. The prompt template is available in Appendix D.2.\n4 Methodology\nWe conducted an online experiment to investigate whether expo-\nsure to our tool could lead to lasting improvements in CT and\npropaganda awareness. Specifically, the experiment was structured\ninto two phases, each separated by one week, to capture immediate\nand short-term effects on participants\u2019 CT and propaganda aware-\nness. In the experiment, participants were first introduced to the\ntool, given access to it, and then asked to complete surveys that\ncaptured their perceptions. This design systematically controlled\nthe exposure while measuring the effects consistently.\nParticipants were recruited through Prolific [ 30], an online plat-\nform commonly used in academic research because of its quality\nand reliability [ 14]. The compensation was set to the platform\u2019s\nrecommended rate of 9 GBP / hour. To ensure a diverse yet con-\ntrolled participant pool, we applied the following selection criteria:\nparticipants had to be native English speakers, have no history of\nlanguage disorders, and possess no background in media or political\nstudies. These requirements ensured that language comprehension\nwas not a barrier and participants lacked prior expertise in the\nstudy\u2019s subject matter. We used several news articles to evaluate\nthe impact on CT and propaganda awareness. The articles varied\nin topic and content but were comparable in size and complexity,\nas given by the Flesch-Kincaid Grade Level (Article 1: 12.0, Article\n2: 12.3, Article 3: 12.2) [35].\nParticipants were randomly assigned to one of five groups ex-\nposed to a different dosage of inoculation, as shown in Table 1.\nFor the pretest, we recruited five participants per group. The total\nnumber of participants per group is listed in Table 1. For Survey 2,\nwe aimed to retain the same participants as in Survey 1, but some\ndropped out, leading to lower participation numbers.\nSurvey 1 measured the immediate effect, and participants com-\npleted the following three steps. First, depending on their group,\nthey read the assigned article(s) with or without using our tool.\nNext, participants completed standardized questionnaires to evalu-\nate their CT ability and propaganda awareness. Finally, groups that\nused the tool (Groups 3-5) provided feedback on their experience\nand the perceived quality of the tool. Participants from Group 2\nprovided feedback on the 14 propaganda techniques.\nOne week after Survey 1, we conducted Survey 2 to assess how\nwell participants retained CT and propaganda awareness. All par-\nticipants read the same article ( Article 3 ) without using the tool,\nthen completed the same standardized questionnaires as before to\nassess retention.\nWe employ a set of measurements to evaluate participants\u2019 CT\nabilities, propaganda awareness, and overall experience with the\ntool, such as the Need for Cognition Scale [ 22], a psychologically\ngrounded approach to assess the thinking tendencies of a partic-\nipant. For comparability, we adopted the measurement set from\nZavolokina et al. [42] (see Appendix E).\nBefore reading the assigned articles, participants filled out a\nquestionnaire to assess their political leanings, news consumption\nhabits, and trust in the tool as well as the news article. After reading\neach assigned article, participants were asked to complete a series\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\nFigure 1: Example Usage\nGroup Dosage Survey 1 Survey 2 Description\nGroup 1 None (control) 100 82 Read Article 2 without any intervention\nGroup 2 Low 103 86 Overview of 14 propaganda techniques (explana-\ntions and examples from [ 8], see Appendix D.1),\nthen read Article 2.\nGroup 3 Medium I 102 81 Tool (detected techniques, and explanations) for\nArticle 1, then read Article 2 without tool\nGroup 4 Medium II 101 87 Tool (detected techniques, and context) for Article\n1, then Article 2 without tool\nGroup 5 High 100 88 Tool (detected techniques, explanations and related\ncontext) for Article 1, then Article 2 without tool\nTable 1: Experimental Groups and Participation Overview\nof post-reading questionnaires. To measure propaganda awareness,\nparticipants reported whether they believed the article contained\npropagandistic elements and explained their reasoning. Then, they\nevaluated specific statements to determine whether they were pro-\npagandistic.\n5 Findings\n5.1 Survey 1 - Post Treatment Effect on CT and\nPropaganda Awareness\nSurvey 1 measures participants\u2019 CT and propaganda awareness in\ntwo phases. The first phase is during the inoculation treatment (i.e.,\nwith the overview for group 2 and tool assistance for groups 3 to\n5), and the second phase is after the inoculation treatment when\nreading a new article without the overview or tool assistance.\nIn the initial phase, we evaluate the tool\u2019s effectiveness in in-\ncreasing CT and propaganda awareness by replicating Zavolokina\net al. \u2019s experiment [ 42]. We compare the control and low-dosage\ngroups (who read Article 2 without the tool) against the medium\nand high-dosage groups (who read Article 1 with the tool). Even\nthough the articles are different, this comparison allows us to assess\nthe immediate effect of the tool. Our findings indicate that partic-\nipants with access to the tool demonstrate a significant increase\nin CT and propaganda awareness compared to those without it.\nSpecifically, \ud835\udc61-tests between Group 1 (control) and Groups 3, 4 and5 show significant differences (1 vs. 3: \ud835\udc61=\u22122.329,\ud835\udc5d=0.020; 1 vs.\n4:\ud835\udc61=\u22122.001,\ud835\udc5d=0.048; and 1 vs. 5: \ud835\udc61=\u22123.693,\ud835\udc5d=0.000, re-\nspectively), as does the comparison between Group 2 (low-dosage)\nand Groups 3 and 5 (2 vs. 3: \ud835\udc61=\u22122.078,\ud835\udc5d=0.038; and 2 vs. 5:\n\ud835\udc61=\u22123.460, \ud835\udc5d=0.001, respectively). \ud835\udc5d-values between the other\ngroups are all above 0.083. These results align with the previous\nresearch [ 42] and confirm that such a tool increases CT during its\nuse (see Figure 2 (a)).\nHowever, to answer our research question about whether these\nimprovements persist without access to the tool, we examine par-\nticipants\u2019 performance on article 2, i.e. without access to the tool or\nthe technique overview. Independent \ud835\udc61-tests reveal no statistically\nsignificant difference in overall CT between the groups regardless\nof treatment dosage when reading article 2, as shown in Figure 2\n(b) (all \ud835\udc5d-values are higher than 0.150).\nIn addition, we examine the effect for the medium and high\ndosage groups when transitioning from using the tool while reading\narticle 1 to not using it when reading article 2. We use dependent\n\ud835\udc61-tests and observe that as soon as participants do not have access\nto the tool, their CT drops statistically significantly (see Figure 2 (c)).\nSpecifically, the \ud835\udc5d-value for each group with vs. without the tool\nis less than 0.001. This indicates that there is no sustained transfer\neffect after using the tool once, and participants are not able to\nmaintain the same level of CT as during the use of the tool.\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\nFigure 2: CT assessment across different conditions: (a) Comparison of CT between control/low-dose groups (reading Article 2\nwithout tool) vs. medium/high-dose groups (reading Article 1 with tool), showing significant enhancement when using the\ntool; (b) Post-inoculation CT when all groups read Article 2 without tool access, demonstrating no sustained improvement; (c)\nWithin-group comparison showing significant decline in CT when tool access was removed. Error bars represent standard\nerror. Statistical significances: * p < 0.050 ** p < 0.010\nRegarding propaganda awareness, we observe a disconnect be-\ntween self-reported scores and the demonstrated ability to detect\npropaganda. Participants with access to the tool report feeling more\naware of propaganda (Figure 3). However, their actual performance\nin identifying propagandistic statements does not show statistically\nsignificant differences. This suggests that while participants are\nmore aware of propaganda when supported by the tool, this in-\ncreased awareness does not carry over to their independent analysis\nof new content.\n5.2 Survey 2 - One-Week Retention\nIn Survey 2, we evaluate the retention of CT and propaganda aware-\nness without access to the tool for all groups. The participants are\nall presented with the same new article and complete identical\nquestionnaires to ensure comparability. We use dependent \ud835\udc61-tests\nto compare CT scores within each group between the two surveys\nand independent \ud835\udc61-tests to compare performance between groups\nwithin the second survey.\nThe results show no statistically significant differences in CT\nscores within groups between the surveys (minimum \ud835\udc5d=0.015for\nGroup 4, \ud835\udc61=\u22122.447). All groups have similar CT scores to those in\nthe first survey.\nWe do not find consistent statistically significant differences in\nCT between survey 2 groups, with only one comparison showing\nsignificance: Group 1 vs. Group 4 ( \ud835\udc61=\u22122.141,\ud835\udc5d=0.033). All other\ngroup comparisons are not statistically significant (all \ud835\udc5d>0.110),\nsuggesting broadly similar CT levels across groups in the second\nsurvey.\nThis finding suggests that the inoculation does not lead to lasting\nimprovements in CT, no matter the dosage. The results show that a\nsingle exposure to the tool or the propaganda technique overview\nis insufficient to create lasting improvements in CT one week after\nthe treatment.\n6 Discussion and Conclusion\nOur work investigated whether and how an AI-based propaganda\ntool, designed with elements of inoculation, could foster CT in\nnews readers. Although our initial formulation suggested directlyapplying inoculation theory, our findings reveal a more nuanced\nrelationship between technological assistance and inoculation prin-\nciples.\nOur approach integrated weakened forms of propaganda through\nthree mechanisms: detection of propaganda, explanations, and con-\ntextual information. We provide empirical evidence of how these\ntechnological mechanisms and psychological frameworks interact.\nIn our experimental setup, participants were exposed to propa-\nganda content alongside the tool\u2019s annotations, effectively creating\na form of weakened exposure that aligns with inoculation theory\nprinciples. However, in practical applications, the tool functions\ndifferently. Rather than pre-exposing users to weakened forms of\npropaganda, it provides real-time analysis and annotations that\nhelp \"weaken\" propaganda techniques as users encounter them\nnaturally on websites.\nA key finding is the temporal nature of the tool\u2019s intervention.\nThe core challenge appears to be that participants used the tool\nas a \"crutch\" rather than developing independent CT. This depen-\ndency aligns with observations from recent research on LLM-based\ntools [ 5], where overreliance also happened. While participants had\naccess to the tool, their CT and propaganda awareness increased\nsignificantly. However, without access to the tool, these increases\nvanished. This tool dependency suggests users defaulted to System\n1 thinking instead of developing the deeper, more deliberate Sys-\ntem 2 thinking processes essential for genuine CT. Furthermore,\nvariations in engagement levels across experimental conditions\nmay have influenced these outcomes, i.e., through the using the\ntool, participants automatically interacted more with a given article\nand thus thought more critically. While this is a desired quality\nfor the tool, the experimental setup should be adjusted for better\ncomparability between treatments.\nOur experiments confirm a direct effect of the tool on CT and\npropaganda awareness, aligning with the findings of Zavolokina\net al. [ 42]. During its use, participants demonstrated significantly\nimproved CT, indicating that the tool effectively supports users\nin analyzing propaganda in real-time. However, this effect did not\npersist beyond immediate usage. Both directly after using the tool\nand in the follow-up assessment one week later, participants showed\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\nFigure 3: Results on propaganda awareness showing (a) self-reported increase in propaganda awareness across treatment groups,\ndemonstrating higher perceived awareness in groups that used the tool and (b) actual accuracy in identifying propagandistic\nstatements, showing no significant difference between groups despite varying treatments. Error bars in (b) represent the\nstandard error.\nno significant difference compared to treatments without the tool,\nshowing no evidence of inoculation. These results highlight the\nchallenge of achieving lasting improvements in CT through a one-\nshot intervention and emphasize the need for repeated exposure\nor alternative educational strategies to reinforce independent CT\nskills over time.\nWhen comparing our approach to successful inoculation imple-\nmentations, particularly Roozenbeek et al.\u2019s [33] work, some key\ndifferences in implementation and mechanisms emerge. They used\nshort videos, engaging stories, and visual elements to expose par-\nticipants to weakened forms of propaganda techniques. In contrast,\nour tool attempted to weaken existing propaganda through annota-\ntions. This suggests that our implementation of inoculation might\nbe an issue and that the mode of delivery plays a significant role.\nOur evaluation using Kahneman\u2019s framework extends beyond\nprevious work, such as Russo et al. \u2019s [34] conversational agent-based\nstudy. While their work demonstrated benefits through story cre-\nation and evaluation, our approach revealed a crucial gap between\nassisted and independent CT. This measurement approach allowed\nus to quantify not just the immediate effects of AI assistance but\nalso explain the cognitive mechanisms behind tool dependency.\nSeveral other factors might explain the limited retention of CT\ntoward propaganda. First, the lack of emotional elements in our ap-\nproach could play an important factor, as emotional engagement has\nbeen shown to play a crucial role in learning retention [ 29]. Second,\nas Maertens et al. [23] found in their work around the long-term\neffectiveness of inoculation, a single exposure might be insufficient,\nand repeated treatments or \"boosters\" might be required. Third,\nour measurement methodology for CT relied on self-reported ques-\ntionnaires, and the study setup might not be optimally suited for\ntesting inoculation effects, given the lack of participants\u2019 motiva-\ntion to improve CT. Here, the choice of Prolific as a recruitment\nplatform may have influenced our results, as participants may not\nhave had a strong intrinsic motivation to develop lasting resistance\nto propaganda. Unlike real-world users who actively seek to re-\nduce their exposure to manipulative content, Prolific participants\nengage in studies for compensation rather than personal interest\nin consuming less propaganda. Complementary to self-reporting,\nalternative approaches such as eye-tracking, neurological studies,or longitudinal observational studies could provide deeper insights\ninto whether actual inoculation effects occur. Our study also raises\nimportant considerations about the content generated by LLM-\nbased tools. While our tool aims to detect and explain propaganda\nand provide contextual information, it could also introduce its own\nbiases or misinformation.\nThese insights suggest several promising directions for future re-\nsearch and development. Future research should explore interactive,\nemotional, and multimedia-based interventions to make the learn-\ning process more compelling and address engagement challenges.\nHowever, future experiments should be set up in such a manner\nthat different treatment groups require the same engagement level,\na shortcoming of our study. Additionally, further studies should\nnot solely rely on self-reported metrics but include metrics such\nas eye-tracking, neurological studies, or longitudinal observation.\nFurther, the tool could be improved pedagogically to avoid being\nused as a crutch, perhaps by gradually reducing the level of anno-\ntation support while maintaining its ability to weaken propaganda\ntechniques in real-time. Additionally, the issue of sustaining learned\nskills could be tackled through spaced repetition or booster inter-\nventions that combine the tool\u2019s real-time weakening capabilities\nwith more traditional inoculation approaches. Future implemen-\ntations could also incorporate storytelling elements, interactive\nexercises, or gamification to actively engage users in identifying\npropaganda techniques and to activate CT.\nCombating propaganda requires bridging the gap between im-\nmediate effect and long-term improvements in CT and propaganda\nawareness. One path forward could lie in creating a system that\nbetter balances real-time propaganda weakening with lasting skill\ndevelopment, focusing on strengthening users\u2019 ability to think crit-\nically and independently about the information they read while\ncarefully considering the potential risks of using AI-generated con-\ntent. Overall, our findings show that, while AI-based tools can ef-\nfectively help with CT-heavy tasks, creating lasting improvements\nrequires a more sophisticated approach that combines technologi-\ncal assistance with established psychological principles of learning\nand behavior change.\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\nAcknowledgments\nWe thank the Digital Society Initiative of the University of Zurich\nand the Digitalization Initiative of the Zurich Higher Education In-\nstitutions (DIZH) for financing this study under the DIZH Founder\nCall.\nReferences\n[1]Malak Abdullah, Ola Altiti, and Rasha Obiedat. 2022. Detecting propaganda\ntechniques in english news articles using pre-trained transformers. In 2022 13th\nInternational Conference on Information and Communication Systems (ICICS) . IEEE,\n301\u2013308.\n[2]Hani Al-Omari, Malak Abdullah, Ola Al-Titi, and Samira Shaikh. 2019. JUST-\nDeep at NLP4IF 2019 Shared Task: Propaganda Detection using Ensemble Deep\nLearning Models. EMNLP-IJCNLP 2019 (2019), 113.\n[3]Firoj Alam, Hamdy Mubarak, Wajdi Zaghouani, Giovanni Da San Martino, and\nPreslav Nakov. 2022. Overview of the WANLP 2022 Shared Task on Propaganda\nDetection in Arabic. arXiv preprint arXiv:2211.10057 (2022).\n[4]John Banas. 2020. Inoculation Theory. The International Encyclopedia of Media\nPsychology (2020). https://api.semanticscholar.org/CorpusID:242608817\n[5]Hamsa Bastani, Osbert Bastani, Alp Sungu, Haosen Ge, \u00d6zge Kabakc\u0131, and Rei\nMariman. 2024. Generative AI Can Harm Learning. The Wharton School Research\nPaper (July 2024).\n[6]Ana Caraban, Evangelos Karapanos, Daniel Gon\u00e7alves, and Pedro Campos. 2019.\n23 ways to nudge: A review of technology-mediated nudging in human-computer\ninteraction. In Proceedings of the 2019 CHI conference on human factors in com-\nputing systems . 1\u201315.\n[7]Josh Compton. 2024. Inoculation theory. Review of Communica-\ntion 0, 0 (2024), 1\u201313. https://doi.org/10.1080/15358593.2024.2370373\narXiv:https://doi.org/10.1080/15358593.2024.2370373\n[8]Giovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, Henning Wachsmuth, Ros-\ntislav Petrov, and Preslav Nakov. 2020. SemEval-2020 Task 11: Detection of\nPropaganda Techniques in News Articles. In Proceedings of the Fourteenth Work-\nshop on Semantic Evaluation , Aurelie Herbelot, Xiaodan Zhu, Alexis Palmer,\nNathan Schneider, Jonathan May, and Ekaterina Shutova (Eds.). International\nCommittee for Computational Linguistics, Barcelona (online), 1377\u20131414. https:\n//doi.org/10.18653/v1/2020.semeval-1.186\n[9]Giovanni Da San Martino, Shaden Shaar, Yifan Zhang, Seunghak Yu, Alberto\nBarr\u00f3n-Cedeno, and Preslav Nakov. 2020. Prta: A system to support the analysis\nof propaganda techniques in the news. Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics: System Demonstrations , 287\u2013293.\n[10] Giovanni Da San Martino, Seunghak Yu, Alberto Barr\u00f3n-Cedeno, Rostislav Petrov,\nand Preslav Nakov. 2019. Fine-grained analysis of propaganda in news article.\nInProceedings of the 2019 conference on empirical methods in natural language\nprocessing and the 9th international joint conference on natural language processing\n(EMNLP-IJCNLP) . 5636\u20135646.\n[11] Marco L. Della Vedova, Eugenio Tacchini, Stefano Moret, Gabriele Ballarin, Mas-\nsimo DiPierro, and Luca de Alfaro. 2018. Automatic Online Fake News Detection\nCombining Content and Social Signals. In 2018 22nd Conference of Open Inno-\nvations Association (FRUCT) . 272\u2013279. https://doi.org/10.23919/FRUCT.2018.\n8468301\n[12] James Dillard and Lijiang Shen. 2024. The SAGE Handbook of Persuasion: Devel-\nopments in Theory and Practice (2 ed.). SAGE Publications, Inc., Thousand Oaks,\nCalifornia. https://doi.org/10.4135/9781452218410\n[13] Jonathan St BT Evans and Keith E Stanovich. 2013. Dual-process theories of\nhigher cognition: Advancing the debate. Perspectives on psychological science 8, 3\n(2013), 223\u2013241.\n[14] Peer Eyal, Rothschild David, Andrew Gordon, Evernden Zak, and Ekaterina\nDamer. 2021. Data quality of platforms and panels for online behavioral research.\nBehavior Research Methods 54 (09 2021). https://doi.org/10.3758/s13428-021-\n01694-3\n[15] World Economic Forum. 2024. Global Risks Report 2024. Online. https://www.\nweforum.org/publications/global-risks-report-2024/ [Online] Accessed Oct. 19.\n2024.\n[16] Edward M Glaser. 2017. Defining critical thinking. The International Center for\nthe Assessment of Higher Order Thinking (ICAT, US)/Critical Thinking Community.\nRetrieved 22 (2017).\n[17] Daniel Kahneman. 2003. Maps of Bounded Rationality: Psychology for Behavioral\nEconomics. The American Economic Review 93, 5 (2003), 1449\u20131475. http://www.\njstor.org/stable/3132137\n[18] Daniel Kahneman. 2011. Thinking, fast and slow. Farrar, Straus and Giroux\n(2011).\n[19] Daniel Kahneman. 2012. Two Systems in the Mind. Bulletin of the American\nAcademy of Arts and Sciences 65, 2 (2012), 55\u201359. http://www.jstor.org/stable/\n23208056[20] Enkelejda Kasneci, Kathrin Sessler, Stefan K\u00fcchemann, Maria Bannert, Daryna\nDementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G\u00fcnnemann, Eyke\nH\u00fcllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel,\nJ\u00fcrgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel,\nMatthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. 2023. ChatGPT\nfor good? On opportunities and challenges of large language models for education.\nLearning and Individual Differences 103 (2023), 102274. https://doi.org/10.1016/j.\nlindif.2023.102274\n[21] Gabriel Lins De Holanda Coelho, Paul H. P. Hanel, and Lukas J. Wolf. 2020.\nThe Very Efficient Assessment of Need for Cognition: Developing a Six-Item\nVersion. Assessment 27, 8 (Dec. 2020), 1870\u20131885. https://doi.org/10.1177/\n1073191118793208\n[22] Gabriel Lins de Holanda Coelho, Paul Hanel, and Lukas Wolf. 2020. The Very\nEfficient Assessment of Need for Cognition: Developing a Six-Item Version.\nAssessment 27 (12 2020), 1870\u20131885. https://doi.org/10.1177/1073191118793208\n[23] Rakoen Maertens, Jon Roozenbeek, Melisa Basol, and Sander van der Linden.\n2021. Long-term effectiveness of inoculation against misinformation: Three\nlongitudinal experiments. Journal of Experimental Psychology: Applied 27, 1\n(2021), 1\u201316. https://doi.org/10.1037/xap0000315 Place: US Publisher: American\nPsychological Association.\n[24] G Martino, Alberto Barr\u00f3n-Cedeno, Henning Wachsmuth, Rostislav Petrov, and\nPreslav Nakov. 2020. SemEval-2020 task 11: Detection of propaganda techniques\nin news articles. arXiv preprint arXiv:2009.02696 (2020).\n[25] Marsh McLennan et al .2024. The global risks report 2024 19th edition. World\nEconomic Forum Cologny, Switzerland.\n[26] OpenAI. 2024. GPT-4o System Card. arXiv:2410.21276 [cs.CL] https://arxiv.org/\nabs/2410.21276\n[27] OpenAI. 2024. OpenAI API Documentation . https://platform.openai.com/docs/api-\nreference/introduction Accessed: 2024-12-01.\n[28] Michael Pfau and Michael Burgoon. 1988. INOCULATION IN POLITICAL CAM-\nPAIGN COMMUNICATION. Human Communication Research 15 (1988), 91\u2013111.\nhttps://api.semanticscholar.org/CorpusID:143574957\n[29] Elizabeth A Phelps. 2004. Human emotion and memory: interactions of the\namygdala and hippocampal complex. Current Opinion in Neurobiology 14, 2\n(2004), 198\u2013202. https://doi.org/10.1016/j.conb.2004.03.015\n[30] Prolific. [n. d.]. Prolific. https://www.prolific.co [Online] Accessed Oct. 01. 2024.\n[31] Dorian Quelle and Alexandre Bovet. 2024. The perils and promises of fact-\nchecking with large language models. Frontiers in Artificial Intelligence 7 (2024),\n1341697.\n[32] Jon Roozenbeek and Sander van der Linden. 2019. Fake news game confers psy-\nchological resistance against online misinformation. Palgrave Communications 5,\n1 (2019), 65. https://doi.org/10.1057/s41599-019-0279-9\n[33] Jon Roozenbeek, Sander Van Der Linden, Beth Goldberg, Steve Rathje, and\nStephan Lewandowsky. 2022. Psychological inoculation improves resilience\nagainst misinformation on social media. Science Advances 8, 34 (Aug. 2022),\neabo6254. https://doi.org/10.1126/sciadv.abo6254\n[34] Renato Russo and Paulo Blikstein. 2023. Aide: A Conversational Agent Based\non Inoculation Theory and Large Language Models to Empower Learners to\nRecognize Disinformation. https://doi.org/10.22318/icls2023.715792\n[35] Marina Solnyshkina, Radif Zamaletdinov, L.A. Gorodetskaya, and A.I. Gabitov.\n2017. Evaluating Text Complexity and Flesch-Kincaid Grade Level. Journal of\nSocial Studies Education Research 8 (11 2017), 238\u2013248.\n[36] Kilian Sprenkamp, Daniel Gordon Jones, and Liudmila Zavolokina. 2023. Large\nlanguage models for propaganda detection. arXiv preprint arXiv:2310.06422\n(2023).\n[37] Fritz Strack and Roland Deutsch. 2004. Reflective and impulsive determinants of\nsocial behavior. Personality and social psychology review 8, 3 (2004), 220\u2013247.\n[38] Liyan Tang, Philippe Laban, and Greg Durrett. 2024. MiniCheck: Efficient Fact-\nChecking of LLMs on Grounding Documents. arXiv preprint arXiv:2404.10774\n(2024).\n[39] Vorakit Vorakitphan, Elena Cabrio, and Serena Villata. 2022. PROTECT: A\nPipeline for Propaganda Detection and Classification. In Accademia University\nPress . Milan, Italy, 352\u2013358. https://doi.org/10.4000/books.aaccademia.10884\n[40] Yuxia Wang, Revanth Gangi Reddy, Zain Muhammad Mujahid, Arnav Arora,\nAleksandr Rubashevskii, Jiahui Geng, Osama Mohammed Afzal, Liangming Pan,\nNadav Borenstein, Aditya Pillai, et al .2023. Factcheck-GPT: End-to-End Fine-\nGrained Document-Level Fact-Checking and Correction of LLM Output. arXiv\npreprint arXiv:2311.09000 (2023).\n[41] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,\nand Yuan Cao. 2023. ReAct: Synergizing Reasoning and Acting in Language\nModels. arXiv:2210.03629 [cs.CL] https://arxiv.org/abs/2210.03629\n[42] Liudmila Zavolokina, Kilian Sprenkamp, Zoya Katashinskaya, Daniel Gordon\nJones, and Gerhard Schwabe. 2024. Think Fast, Think Slow, Think Critical:\nDesigning an Automated Propaganda Detection Tool. In Proceedings of the CHI\nConference on Human Factors in Computing Systems . ACM, Honolulu HI USA,\n1\u201324. https://doi.org/10.1145/3613904.3642805\n[43] Xuan Zhang and Wei Gao. 2023. Towards llm-based fact verification on news\nclaims with a hierarchical step-by-step prompting method. arXiv preprint\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\narXiv:2310.00305 (2023).\nAPPENDIX\nA Tool Architecture and Usage\nFigure 4 shows the tool\u2019s architecture and how it works.\nB Critical Thinking Characteristics\nTable 2 shows the key characteristics of dual system thinking based\non Kahneman\u2019s work. It contrasts System 1 (fast, automatic, and\neffortless) with System 2 (slow, controlled, and effortful) across\nsix characteristics (speed, processing, control, effort, nature, and\nadaptability).\nC Propaganda Techniques\nTable 3 shows the different propaganda techniques after Abdullah\net al. [1], Da San Martino et al. [10].\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\nFigure 4: Example Usage and Architecture\nTable 2: Dual system thinking characteristics extracted from [17\u201319]\nCharacteristic Definition System 1 System 2\nSpeed Speed of thinking Fast Slow\nProcessing Approach to handling thinking tasks Parallel Serial\nControl Degree of conscious oversight Automatic Controlled\nEffort Cognitive load Effortless Effortful\nNature Inherent operating mechanism Associative Rule-governed\nAdaptability Ability to change or evolve Slow-learning Flexible\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\nPropaganda Technique Definition Example\nAppeal_to_Authority Supposes that a claim is true because a valid\nauthority or expert on the issue supports it\"The World Health Organisation stated, the\nnew medicine is the most effective treatment\nfor the disease.\"\nAppeal_to_fear-prejudice Builds support for an idea by instilling anxi-\nety and/or panic in the audience towards an\nalternative\"Stop those refugees; they are terrorists.\"\nBandwagon,Reductio_ad_hitlerum Justify actions or ideas because everyone else\nis doing it, or reject them because it\u2019s favored\nby groups despised by the target audience\"Would you vote for Clinton as president?\n57% say yes.\"\nBlack-and-White_Fallacy Gives two alternative options as the only pos-\nsibilities, when actually more options exist\"You must be a Republican or Democrat\"\nCausal_Oversimplification Assumes a single reason for an issue when\nthere are multiple causes\"If France had not declared war on Germany,\nWorld War II would have never happened.\"\nDoubt Questioning the credibility of someone or\nsomething\"Is he ready to be the Mayor?\"\nExaggeration,Minimisation Either representing something in an exces-\nsive manner or making something seem less\nimportant than it actually is\"I was not fighting with her; we were just\nplaying.\"\nFlag-Waving Playing on strong national feeling (or with\nrespect to a group, e.g., race, gender, political\npreference) to justify or promote an action\nor idea\"Entering this war will make us have a better\nfuture in our country.\"\nLoaded_Language Uses specific phrases and words that carry\nstrong emotional impact to affect the audi-\nence\"A lone lawmaker\"s childish shouting.\"\nName_Calling,Labeling Gives a label to the object of the propaganda\ncampaign as either the audience hates or\nloves\"Bush the Lesser.\"\nRepetition Repeats the message over and over in the\narticle so that the audience will accept it\"Our great leader is the epitome of wisdom.\nTheir decisions are always wise and just.\"\nSlogans A brief and striking phrase that contains la-\nbeling and stereotyping\"Make America great again!\"\nThought-terminating_Cliches Words or phrases that discourage critical\nthought and useful discussion about a given\ntopic\"It is what it is\"\nWhataboutism,Straw_Men,Red_Herring Attempts to discredit an opponent\u2019s position\nby charging them with hypocrisy without\ndirectly disproving their argument\"They want to preserve the FBI\u2019s reputation.\"\nTable 3: Propaganda Techniques after Abdullah et al. [1], Da San Martino et al. [10]\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\nD Prompts\nD.1 Propaganda detection and explanation\nprompt\n# Role\nYou are an expert in communication and political science and\nyou are specialized in identifying propaganda techniques in\npolitical articles.\n# Task\nYour task is to carefully analyze the given article and\nidentify any of the 14 propaganda techniques used in the\ntext.\nAlways be cautious and thorough in your analysis, ensuring\nnot to wrongly identify propaganda techniques.\n## Propaganda Techniques\nThese are the 14 propaganda techniques you will identify,\nwith definitions and examples (in no particular order):\n- [Loaded_Language]: Uses specific phrases and words that\ncarry strong emotional impact to affect the audience, e.g.,\n'a lone lawmaker 's childish shouting. '\n- [Name_Calling, Labeling]: Gives a label to the object of\nthe propaganda campaign that the audience either hates or\nloves, e.g., 'Bush the Lesser. '\n- [Repetition]: Repeats the message over and over in the\narticle so that the audience will accept it, e.g., 'Our\ngreat leader is the epitome of wisdom. Their decisions are\nalways wise and just. '\n- [Exaggeration, Minimization]: Either represents something\nin an excessive manner or makes something seem less\nimportant than it actually is, e.g., 'I was not fighting\nwith her; we were just playing. '\n- [Appeal_to_fear-prejudice]: Builds support for an idea by\ninstilling anxiety and/or panic in the audience towards an\nalternative, e.g., 'stop those refugees; they are\nterrorists. '\n- [Flag-Waving]: Playing on strong national feeling (or with\nrespect to a group, e.g., race, gender, political preference)\nto justify or promote an action or idea, e.g., 'entering\nthis war will make us have a better future in our country. '\n- [Causal_Oversimplification]: Assumes a single reason for\nan issue when there are multiple causes, e.g., 'If France\nhad not declared war on Germany, World War II would have\nnever happened. '\n- [Appeal_to_Authority]: Supposes that a claim is true\nbecause a valid authority or expert on the issue supports\nit, e.g., 'The World Health Organization stated the new\nmedicine is the most effective treatment for the disease. '\n- [Slogans]: A brief and striking phrase that contains\nlabeling and stereotyping, e.g., 'Make America great again! '\n- [Thought-terminating_Cliches]: Words or phrases that\ndiscourage critical thought and useful discussion about a\ngiven topic, e.g., 'it is what it is '\n- [Whataboutism, Straw_Men, Red_Herring]: Attempts to\ndiscredit an opponent 's\nposition by charging them with hypocrisy without directly\ndisproving their argument, e.g., 'They want to preserve the\nFBI's reputation. '\n- [Black-and-White_Fallacy]: Gives two alternative options\nas the only possibilities when actually more options exist,\ne.g., 'You must be a Republican or Democrat '- [Bandwagon, Reductio_ad_hitlerum]: Justify actions or\nideas because everyone else is doing it, or reject them\nbecause it 's favored by groups despised by the target\naudience, e.g., 'Would you vote for Clinton as president?\n57% say yes. '\n- [Doubt]: Questioning the credibility of someone or\nsomething, e.g., 'Is he ready to be the Mayor? '\n# Instructions\nFor the given article, please identify all occurrences of\nthe 14 propaganda techniques and provide an explanation of\nwhy each passage is considered political propaganda.\nFurther, return the EXACT passage where the political\npropaganda can be found.\nIf no propaganda technique was identified, return an empty\ndictionary.\nIf a propaganda technique is used multiple times in the\narticle,, all occurrences MUST be identified and explained.\n# Output Format\nThe output should be valid JSON, with each propaganda\ntechnique as a key and a list of occurrences as values.\nEach occurrence should have an explanation and the exact\npassage in the article where the propaganda technique is\npresent.\n## Example:\n\"Loaded_Language\": [\n\"explanation\": \"This is an example explanation.\",\n\"location\": \"This is the exact passage in the\narticle where the propaganda technique is present.\"\n,\n\"explanation\": \"This is another example\nexplanation.\",\n\"location\": \"This is the exact passage in the\narticle where the propaganda technique is present.\"\n],\n\"Name_Calling, Labeling\": [\n\"explanation\": \"This is another example\nexplanation.\",\n\"location\": \"This is the exact passage in the\narticle where the propaganda technique is present.\"\n]\nHere is the article:\"\nCHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan Hoferer et al.\nD.2 Contextualizer ReAct Prompt Template\nYou are an Assistant tasked to contextualise potentially\nmisleading statements to make sure users are safe and well\ninformed. You have access to the following tools:\nGoogle - Get previews of the top google search results to\nget more information about the statement. The function\nalways returns the next 10 results and can be called\nmultiple times. If initial results seem unrelated you\nmay use quotation marks to search for an exact phrase.\nUse a minus sign to exclude a word from the search. Use\nbefore:date and after:date to search for results within\na specific time period. Do not google the entire\nstatement verbatim.\nDo not use any tool more than three times. Use the following\nformat:\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Google]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat\n3 times)\nThought: I now have sufficient information to provide\ncontext for the user.\nFinal Answer: The context demanded by the user.\n**Final Response Format:**\n- **Misinformation Explanation:** (Detailed reasoning)\n- **Sources:** (List all important sources with hyperlinks)\n**Example Final Answer:**\nContext: Electric vehicles are generally less harmful to the\nenvironment over their lifetime than gasoline cars, though\nthey do have a high environmental cost at the production\nstage.\nSources:\n- [EPA](https://www.epa.gov/greenvehicles/electric-vehicle- \u230b\nmyths)\n- [MIT Climate\nPortal](https://climate.mit.edu/ask-mit/are-electric-vehicl \u230b\nes-definitely-better-climate-gas-powered-cars)\n- [NY\nPost](https://nypost.com/2024/03/05/business/evs-release-mo \u230b\nre-toxic-emissions-are-worse-for-the-environment-study/)\nBegin!\nQuestion: Contextualise the statement:\n'statement 'originator_sectiondate_section\nThought:agent_scratchpad\"\"\"\nE Measurements\nWe employed a comprehensive set of measurements to assess par-\nticipants\u2019 CT, propaganda awareness, and experiences with the tool.\nWhile we collected data across multiple dimensions, we focus here\non the key measurements most relevant to our research questions.\nThe complete survey included additional questions about news\nconsumption, political orientation, and general media trust.Pre-Reading Questionnaires. To assess participants\u2019 tendency to-\nward effortful cognitive activities, we used the Need for Cognition\nScale [ 21]. Participants rated their agreement with statements such\nasI would prefer complex to simple problems on a 7-point Likert scale\n(1 = strongly disagree to 7 = strongly agree). Before reading the\nassigned articles, participants completed questionnaires assessing\ntheir political leaning and news consumption habits. For politi-\ncal leaning, participants indicated their political orientation on a\n7-point Likert scale. Regarding news consumption, participants\nreported the frequency with which they read news articles and\nrated their level of trust in the news media. They also identified\nthe sources they typically use to consume news, selecting from a\nprovided list and an option to add any additional sources.\nPost-Reading Questionnaires. Following each reading task, par-\nticipants completed several questionnaires. To assess their critical\nthinking, participants were asked six question based on Kahneman.\nAs defined by [ 42] participants responded using 7-point Likert\nscales. Additionally, we added one open-ended question to allow\nus to gauge both the depth and quality of their critical thinking.\nCritical to our research question, we also assessed the propaganda\nawareness. To measure participants\u2019 awareness and recognition\nof propaganda techniques, we used two measures. First, partic-\nipants were asked to indicate whether they believed the article\ncontained propagandistic elements and explained their reasoning\nin an open-ended response. Second, participants were presented\nwith a series of passages extracted from the articles. The passages\nincluded both statements identified as propagandistic by the tool\nand non-propagandistic statements. Participants were asked to de-\ntermine whether each passage contained propagandistic elements\n(YesorNo). This task assessed their ability to recognize propaganda\nwithout the tools\u2019 assistance.\nNews Evaluation. Participants were also asked to evaluate the\narticle in several dimensions using 7-point Likert scales. The di-\nmensions were accuracy, bias, informativeness, trustworthiness,\nand clarity.\nTool Experience and Evaluation. For participants who used the\ntool (Groups 3\u20135), additional measures were used to assess their\nexperience and perceptions of the tool. We included questions on\nthe tool\u2019s usability, impact on trust and opinion, reliance, informa-\ntion overload, and critical thinking. Additionally, participants were\npresented with three randomly selected instances of propaganda\ndetected by the tool in Article 1 . For each instance, they assessed\nthe tool\u2019s accuracy, usefulness, relevance, trustworthiness, credi-\nbility, clarity and informativeness. Participants who received the\noverview of propaganda techniques were asked for suggestions for\nimprovements to the overview, how helpful it was in increasing\nawareness of propaganda techniques, and how likely they were to\nrecommend the overview to others.\nE.1 Key Survey Instruments\nCritical Thinking Assessment. The following questions were used\nto evaluate participants\u2019 CT, based on Kahneman\u2019s dual-system\nthinking framework:\n\u2022Speed: \"Did you feel like your thought process was more like\na...\" (1 = Quick skim, 7 = Slow, careful read)\nEffective Yet Ephemeral Propaganda Defense CHI EA \u201925, April 26-May 1, 2025, Yokohama, Japan\n\u2022Processing: \"Did you feel like you were...\" (1 = Absorbing\nseveral details at once, 7 = Focusing on one detail at a time)\n\u2022Effort: \"Did your thinking feel...\" (1 = Easy and automatic, 7\n= Like it required significant mental effort)\n\u2022Nature: \"Were you more likely to...\" (1 = Make connections\nbetween details instinctively, 7 = Apply a set of rules or\ncriteria to evaluate details)\n\u2022Adaptability: \"Did you find yourself...\" (1 = Sticking to your\ninitial impressions, 7 = Regularly updating your thoughts as\nyou read more)\n\u2022Control: \"While reading the article, did your thoughts feel\nmore...\" (1 = Spontaneous, 7 = Deliberate)\nAdditionally, participants were asked an open-ended question:\n\"Please explain why you felt this way while reading the article.\nProvide specific examples or reasons for your rating.\"\nPropaganda Awareness Evaluation. To assess propaganda aware-\nness we used two measurement approaches: Tool Impact Assessment\nParticipants self-reported their experience on a 7-point Likert scale\n(1 = not at all, 7 = very much):\n\u2022\"Did the tool help you become more aware of the different\npropaganda techniques used in media?\"\nPropaganda Detection Task Participants were presented with various\nstatements from the articles and asked to identify whether they\ncontain propagandistic elements or not:\n\u2022For each statement, participants indicated: \"Does it contain\npropagandistic elements?\" (Yes/No)\nFeedback and Net Promoter Score. At the end, participants who\nused the tool were asked to provide feedback on the tool, like\nsuggestions for improvements, what they found most helpful, and\nadditional comments or feedback. We also used the Net Promoter\nScore, participants were asked to rate how likely they were to\nrecommend the tool to others on a scale from 0 to 10.\nReceived 23 January 2025; revised 06 March 2025", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Effective Yet Ephemeral Propaganda Defense: There Needs to Be More than One-Shot Inoculation to Enhance Critical Thinking", "author": ["N Hoferer", "K Sprenkamp", "DC Quelle"], "pub_year": "2025", "venue": "Proceedings of the \u2026", "abstract": "In today\u2019s media landscape, propaganda distribution has a significant impact on society. It  sows confusion, undermines democratic processes, and leads to increasingly difficult decision"}, "filled": false, "gsrank": 555, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3706599.3720125", "author_id": ["", "RCzhpa8AAAAJ", "Ixp3440AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:gDiBkBH16y8J:scholar.google.com/&output=cite&scirp=554&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=gDiBkBH16y8J&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 3, "citedby_url": "/scholar?cites=3453122995097254016&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:gDiBkBH16y8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2503.16497?"}}, {"title": "4 When misinformation migrates", "year": "NA", "pdf_data": "Rogers (ed.) The Propagation of Misinformation in Social MediaThe Propagation  \nof Misinformation  \nin Social Media A Cross-\nplatform \nAnalysis\nEdited  \nby Richard Ro\ngers\nThe Propagation of Misinformation in Social Media\n\nThe Propagation of Misinformation \nin\u00a0Social Media\nA Cross-platform Analysis\nEdited by Richard Rogers\nAmsterdam University Press\nThe publication of this book is made possible by grants from First Draft and SoBigData++ \nwhich received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement nr. 871042.\nCover illustration: Kurt Schwitters, Merz #1, 1920.\nCover design: Co\u00f6rdesign, Leiden\nLay-out: Crius Group, Hulshout\nisbn\n 9\n78 94 6372 076 2\ne-isbn  9\n78 90 4855 424 9\ndoi \n10.5117/9789463720762\nnur  \n670\nCreative Commons License CC BY NC ND (http://creativecommons.org/licenses/by-nc-nd/4.0)\n\u00a0All authors / Amsterdam University Press B.V., Amsterdam 2023\nSome rights reserved. Without limiting the rights under copyright reserved above, any part of \nthis book may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any form or by any means (electronic, mechanical, photocopying, recording or otherwise).\nEvery effort has been made to obtain permission to use all copyrighted illustrations \nreproduced in this book. Nonetheless, whosoever believes to have rights to this material is advised to contact the publisher.\n T able of Contents\nPreface   7\n1 \u201c Serious queries\u201d and \u201ceditorial epistemologies\u201d   9\nHow social media are contending with misinformation\nRichard Rogers\n2 P roblematic information in Google Web Search?   33\nScrutinizing the results from U.S. election-related queries\nGuillen Torres\n3 T he scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified   47\nRichard Rogers\n4 W hen misinformation migrates   67\nCross-platform posting, YouTube and the deep vernacular web\nAnthony Glyn Burton\n5 F ringe players on political Twitter   83\nSource-sharing dynamics, partisanship and problematic actors\nMaarten Groen and Marloes Geboers\n6 T witter as accidental authority   109\nHow a platform assumed an adjudicative role during the COVID-19 \npandemic\nEmillie de Keulenaar, Ivan Kisjes, Rory Smith, Carina Albrecht and Eleonora Cappuccio\n7 T he earnest platform   139\nU.S. presidential candidates, COVID-19, and social issues on Instagram\nSabine Niederer and Gabriele Colombo\n8 A f ringe mainstreamed, or tracing antagonistic slang between \n4chan and Breitbart before and after Trump\n  165\nStijn Peeters, Tom Willaert, Marc Tuters, Katrien Beuls, Paul Van Eecke and Jeroen Van Soest\n9 P olitical TikTok   187\nPlayful performance, ambivalent critique and event-commentary\nNatalia S\u00e1nchez-Querub\u00edn, Shuaishuai Wang, Briar Dickey and \nAndrea Benedetti\nAfterword: The misinformation problem and the deplatforming \ndebates   207\nBibliography   213\nIndex   237\n Preface\nThis book is a product of a collaboration of media researchers at the University \nof Amsterdam, working together with colleagues in Belgium, Canada, Italy, \nthe U.K. and the U.S. and supported by First Draft, the journalist training \nnetwork concerned with misinformation. As a group we set out to study \nthe \u201cmisinformation problem\u201d in the areas where social media platforms \nwere seemingly working with great ardor to address it: elections and the \npandemic. How are they contending with misinformation in the areas that \nhave their special focus, some years on from the seminal \u201cfake news\u201d crisis? \nIn preliminary work we had found that platforms such as Facebook appeared \nactive in retarding the spread of extreme viewpoints and sources that directly \nrelated to elections and the pandemic but less successful in immediately \nadjacent areas such as election-related social issues and vaccines.\nWhat have platform efforts to curb the misinformation problem yielded? \nThe findings we report here are both generalizable as well as platform-\nspecific, which are the two sides of our cross-platform analysis. Generally, \nsocial media platforms are mainstreaming the fringe and marginalizing the \nmainstream. As others have found, extreme viewpoints and sources, particu -\nlarly from one side of the political spectrum, are receiving disproportionate \nengagement compared to other sources. But we made the additional, broad \nobservation that even in issue areas deemed serious\u2014elections and the pan -\ndemic\u2014mainstream media are less referenced or otherwise marginalized.\nMore specifically, the manner in which the platforms decenter the \nmainstream differs. Twitter, for example, has high percentages of \u201chyper -\npartisan\u201d sources present in tweets concerning politics, and while not in \nthe majority, many of Facebook\u2019s most engaged-with sources would be \nclassified as \u201cfake news,\u201d if one deploys the original definition by Craig \nSilverman in the seminal 2016 Buzzfeed News  article ushering in the term. \nWhere other platforms are concerned, Instagram users prefer influencers \nover experts, and rely on their social responsibility in debunking falsehoods. \nTikTok users parody mainstream media, and Reddit and 4chan (at least \ntheir leading forums and boards) dismiss it and send users to alternative \ninfluence networks and YouTube videos with extreme cultural commentary. \nGoogle Web Search, whose results for political queries we also studied, \nreturns more quality than alternative media but the presence of these \nsources decline as the election nears, owing to the preponderance of what \nthe researchers call special interest sites. Incidentally, we also found that \nin election-related Google returns the sources are politically imbalanced.\n8 T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nAs I note in the opening chapter, the social media platforms have \nintroduced \u201ceditorial epistemologies\u201d for elections and the pandemic, \nauthoring lists of authoritative sources that appear when one queries core \nelection-related or pandemic-related keywords or making other manual \ninterventions beyond commercial content moderation, the outsourced, \nlow-wage work of removing offensive content. They also have had to assume \nthe role of \u201caccidental authorities,\u201d developing rapidly evolving source and \ninformation adjudication policy that at the same time invites backlash for \nheavy-handedness as well as competition from \u201calt-tech\u201d platforms that \nmoderate with a lighter touch. The extent of the platforms\u2019 editing, and \nparticularly where it ends, is on display in each of the studies.\nEach of the chapters benefits from techniques developed to capture the \ndata necessary to exhibit the current state of the misinformation problem. \nSome rely on platform-supplied data (Twitter, Instagram), another on a \nrepurposed marketing data dashboard (Facebook) and others on scraping \n(Google Web Search, Reddit, 4chan, TikTok). There is also a study that uses \none platform (4chan) to analyze another (YouTube), given the copious \nreferencing of YouTube videos by \u201calternative influencers\u201d and later to \nvernacular newcomers. Many of the studies also classify sources as main -\nstream or alternative (to varying degrees) as well as evincing a political bent, \nrelying on (and triangulating) external classification schemes developed \nby journalists and other media analysts.\nThe platform studies were undertaken twice (and on occasion three \ntimes), first in the early run-up to the U.S. presidential elections and the \npandemic (March, 2020) and again after the elections and deeper into the \npandemic (January, 2021 and/or March, 2021). One of the Twitter studies \ntakes advantage of the data spanning the Capitol riots of January\u00a06, 2021 in \nWashington, DC, allowing for the analysis of how the platform\u2019s subsequent \npurge of accounts had an impact on the quality of the sources encountered.\nThe studies have been written up in the format of the Harvard Kennedy \nSchool Misinformation Review , where earlier versions of the Facebook and \n4chan/Reddit chapters were published. It is a format that leads with the \nresearch questions and is followed by an essay summary, the implications \nand the findings. The methods section comes last. To us the format highlights \nthe relevance of the work to journalists and thus also serves well the col -\nlaboration with First Draft.\nRichard Rogers\nNovember, 2022\n1 \u201c Serious queries\u201d and \u201ceditorial \nepistemologies\u201d\nHow social media are contending with misinformation\nRichard Rogers\nAbstract\nThe following concerns the \u201cmisinformation problem\u201d on social media \nduring the run-up to the 2020 U.S. presidential election. Employing data \njournalism techniques, it develops a form of cross-platform analysis that \nis attuned to both commensurability as well as platform specificity. It \nanalyses the top-ranked political content on seven platforms and finds that \neach marginalizes mainstream media and mainstreams the fringe. TikTok \nparodies mainstream media, while 4chan and Reddit dismiss it and direct \nusers to alternative influence networks and extreme YouTube content. \nTwitter prefers the hyperpartisan over it. Facebook\u2019s \u201cfake news\u201d problem \nconcerns declining amounts of mainstream media referenced. Instagram \nhas influencers dominating user engagement. By comparison, Google Web \nSearch buoys special interest sites. It concludes with a discussion of how \nplatforms filter the content through increasing editorial intervention.\nKeywords: Problematic information, content moderation, cross-platform \nanalysis, platform criticism, fringe media\nIntroduction: The politics of problematic information and its \ncross-platform study\nWhile scholars of hearsay, rumor and conspiracism would point to the history \nof its staying power (Olmsted, 2009), the spread of misinformation and other \nproblematic information is said to be \u201csupercharged\u201d by contemporary \nsocial media (Bounegru et al., 2018; Daniels, 2018). The following examines \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch01\n10 T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nthat thesis through an analysis of the current state of what globally could \nbe called the \u201cmisinformation problem\u201d (Allcott et al., 2019) across seven \nonline platforms: TikTok, 4chan, Reddit, Twitter, Facebook, Instagram \nand Google Web Search. The part played by YouTube is viewed by way \nof the videos referenced on 4chan. The case in question is the political \ninformation environment in the run-up to the U.S. presidential elections, \nor what may be dubbed U.S.-based, \u201cpolitical Facebook,\u201d \u201cpolitical Twitter,\u201d \n\u201cpolitical Instagram,\u201d etc. Borrowing a technique from data journalism, \nand examining the most interacted-with content around the candidates, \npolitical parties and election-related issues, the work reported here found \nthat stricter definitions of misinformation (imposter sites, pseudo-science, \nconspiracy, extremism only) lessen the scale of the problem, while roomier \nones (adding \u201chyperpartisan\u201d and \u201cjunk\u201d sites serving clickbait) increase it, \nalbeit rarely to the point where it outperforms mainstream media.\nThe misinformation problem differs per platform. On such youthful \nplatforms as TikTok and to a lesser extent Instagram, misinformation may \nbe delivered sarcastically or insincerely, making it difficult to characterize \nintent (Phillips and Milner, 2017). On the masked or anonymized political \nboards and communities of 4chan and Reddit, problematic sources are \nnot as copiously referenced as mainstream ones, but that finding does not \nmean to suggest the absence of a problem, as the most referenced collection \nof sources (on 4chan) are extreme YouTube videos, many of which end up \nbeing deleted from the platform. The users of mainstream social media as Twitter and Facebook continue to point in great proportions to hyperpar -\ntisan sources, originally defined as \u201copenly ideological web operations\u201d \n(Herrman, 2016). Political spaces on Instagram, however, were found to \nbe the \u201ccleanest,\u201d where most election-related content is non-divisive and \nearnestly posted, and influencers, with some exceptions, were found to be \nresponsible information providers, debunking rather than spreading 5G \ncoronavirus conspiracy theories.\nThe research provides a technique for \u201ccross-platform analysis,\u201d or the \nexamination of a single phenomenon (through engagement analysis) across a \nvariety of social media. It thereby addresses critiques of \u201csingle platform studies,\u201d \nwhere societal trends or phenomena are seen through one social media lens \nwithout the benefit of a comparative perspective that would furnish a baseline \n(Rogers, 2019). Engagement analysis of a single subject matter (election-related \ninformation, in this case) is considered one robust cross-platform approach \nsince it captures each platform\u2019s top content, which refers to the posts or web \nURLs that receive the most interactions (directly or indirectly). It has the \nbenefit of being more global in its outlook compared to other cross-platform \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 11\napproaches that rely on seeking one or more digital objects shared across \nplatforms (e.g., a hyperlink) and comparing resonance (Rogers, 2017).\nBut the cross-platform approach put forward here is not blind to platform \nspecificities. It seeks to account for differing platform metrics, vernaculars \nof use and user subcultures. Accounting for this \u201cmedium specificity\u201d is \nperformed in at least three ways. The first is that engagement is measured \ndistinctively per platform, as discussed in some detail below. Second, social \nmedia manipulation (such as artificially amplifying misinformation so \nthat it appears to be engaged-with content) also differs per platform. One is \ninterested in fake followers on Instagram and bots on Twitter, for example. \nBeing attuned to platform vernaculars, finally, rests on the study of cultures \nof use. For example, certain sound effects or facial gestures on TikTok suggest \ndisbelief or mistrust. In all, commensurability thereby relies on both the \ncross-platform study of engagement as well as individual platform analyses \nimbued with a medium-specific approach.\nIn the following I first introduce the current misinformation problem \nonline as bearing some resemblance to the quality of information debates \nfrom early web history. The contemporary concerns, however, flow from the \n\u201cfake news\u201d crisis of 2016, together with the continual study of the extent \nto which the platforms have addressed the issue (and how they have done \nso). Moreover, these debates have not escaped the politicization of \u201cbig \ntech\u201d and its supposed \u201cliberal bias\u201d (Vaidhyanathan, 2019), a claim that is \nalso a source of empirical study in the Google Web Search analysis below.\nIndeed, designating certain information as problematic may be political \n(and increasingly politicized), because, as others before us also have found \n(Benkler et al., 2018; Rogers and Hagen, 2020), it is more prevalent on the \nright side of the political spectrum, as are problematic or \u201cinauthentic\u201d \nusers, though they are not alone there. Making a case for balancing the \npartisanship of sources outputted by social media and search engines \n(rather than serving filter bubbles through personalization, for example) is \namong the emerging source adjudication methods under consideration, as \nI will discuss. The piece concludes with a discussion of source criticism on \nsocial media, including the recent rise of \u201ceditorial epistemologies\u201d alongside \ncrowdsourced ones associated with the (early) web.\nUncertainty online renewed\nThe web historically has been thought of as a space for the unsubstanti -\nated, authored by rumormongers, conspiracy theorists and all manner of \n12 r ichard rog erS \nself-publishers and fringe contributors. Indeed, one could argue, as it was put \nin 1994, that on the web \u201cthe eminent and the crackpot\u201d stand side-by-side, \na feature once celebrated as a productive collision (Rheingold, 1994; Rogers, \n2004). Indeed, in early internet studies, next to the blurring of the real and \nthe virtual, conspiracy theory in particular but also the production and \ncirculation of rumor were subjects of study, before notions as the \u201cwisdom \nof the crowd\u201d and projects as Wikipedia appeared to place the web on a less \nshaky epistemological footing (Dean, 1998; Shirky, 2008). Arguably, social \nmedia have put paid to that brief period of relative stability. Conspiracists or \nat least those who discuss such phenomena as the link between 5G and the \ncoronavirus are among some of the high-profile influencers or microcelebrities \nfound there (Bruns et al., 2020).1 In turn, scholars now write, as they did two \ndecades earlier, that the internet is \u201cmainstreaming the fringe\u201d (Barkun, 2016).\nThe recent uptick in attention to the study of problematic content online \ncould be attributed as well to the \u201cfake news crisis\u201d of 2016, where it was \nfound that so-called fake news outperformed mainstream news on Face -\nbook in the run-up to the U.S. presidential elections that year (Silverman, 2016). That finding also set in motion the subsequent struggle around the \noccupation of the term from a type of news originating from imposter \nmedia organizations or other dubious sources to a \u201cpopulist\u201d charge against \nmainstream and \u201celite\u201d media that seeks to delegitimate sources found \npublishing inconvenient or displeasing stories (van der Linden et al., 2020).\nIn its recent study we have had calls to cease using the term, fake news \n(Pepp et al., 2019). There also has been a series of classification moves. \nBoth the expansion as well as contraction of the notion may be seen in its \nreconceptualization by scholars as well as by the platforms themselves \n(Venturini, 2019). The definitional evolution is embodied in such phrasings \nas \u201cjunk news\u201d and \u201cproblematic information,\u201d which are broader in their \nclassification, while the platforms appear to prefer terms such as \u201cfalse\u201d \n(Facebook), which is narrower (Rogers, 2020a).\nOn the back end the platform companies also develop responses to these \nactivities. They would like to automate as well as outsource its detection \nand policing, be it through low-wage, outsourced content moderators, \n(volunteer) fact-checking outfits or user-centered collaborative filtering \nsuch as Twitter\u2019s \u201cbirdwatchers,\u201d an initiative they say born of societal \ndistaste for a central decision-making authority, as found through qualitative \ninterviews (Gillespie, 2018; Roberts, 2019; Coleman, 2021). They also take \nmajor decisions to label content by world leaders (and indeed have world \n1 5 G is the \u201cfifth generation\u201d technology standard for mobile phone networks.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 13\nleader content policies), which subsequently land platform governance and \ndecision-making in the spotlight (Twitter, 2019).\nMore broadly there has been a rise in the study of \u201ccomputational \npropaganda\u201d and \u201cartificial amplification\u201d which the platforms refer to \nas \u201cinauthentic behavior\u201d (Woolley and Howard, 2016; Colombo and De \nGaetano, 2020). These may take the form of bots or trolls; they may be \n\u201ccoordinated\u201d by \u201ctroll armies,\u201d which has been outlined in Facebook\u2019s \nregular \u201ccoordinated inauthentic behavior reports\u201d (Facebook, 2021a). As its \nhead of security policy puts it, Facebook defines it (in a plain speak manner) \nas \u201cpeople or pages working together to mislead others about who they are \nor what they are doing\u201d (Facebook, 2018). Occasionally datasets become \navailable (by Twitter or other researchers) that purport to be collections of \ntweets by these inauthentic, coordinated campaigners, whereupon scholars \n(among other efforts) seek to make sense of which signals can be employed \nto detect them (Roeder, 2018).\nOther types of individuals online have caught the attention of the plat -\nforms as \u201cdangerous\u201d (Facebook), and have been deplatformed, a somewhat \ndrastic step that follows (repeated) violations of platform rules and presum -\nably temporary suspensions (Rogers, 2020b). \u201cDemonetization\u201d also is among \nthe platforms\u2019 repertoire of actions, should these individuals, such as extreme \ninternet celebrities, be turning vitriol into revenue, though there is also \nthe question of which advertisers attach themselves (knowingly or not) to \nsuch content (Wilkinson and Berry, 2020). Moreover, there are questions \nabout why certain channels have been demonetized for being \u201cextremist.\u201d \nOthers ask, is \u201ccounter-speech\u201d an alternative to counter-action (Bartlett \nand Krasodomski-Jones, 2015; Gagliardone, 2019)?\nOn the interface, where the metrics are concerned, there may be fol -\nlower factories behind high follower and like counts (Lindquist, 2019). The \nmarketing industry dedicated to social listening as well as computational \nresearchers have arrived at a series of rules of thumb as well as signal \nprocessing that aid in the flagging or detection of the inauthentic. Just as \nsudden rises in follower counts might indicate bought followers, a sudden \ndecline suggests a platform \u201cpurge\u201d of them (Confessore et al., 2018). Perhaps \nmore expensive followers gradually populate an account, making it appear \nnatural. Indeed, there is the question of which kinds of (purchased) followers \nare \u201cgood enough\u201d to count and be counted. What is the minimum amount \nof grooming? Can it be automated, or is there always some human touch? \nFinally, there is a hierarchy in the industry, where Instagram followers \nare the most sought after, but \u201cinfluencers\u201d (who market wares there) are \noften contractually bound to promise that they have not \u201cparticipated in \n14 r ichard rog erS \ncomment pods (group \u2018liking\u2019 pacts), botting (automated interactions), or \npurchasing fake followers\u201d (Ellis, 2019).\nHaving touched upon the current state of uncertainty online, I would \nlike to turn to how problematic information manifests itself in social media \nplatforms around specific social issues as well as election-related keywords. \nThe following recounts a cross-platform analysis into the \u201cmisinformation \nproblem\u201d in the run-up to the 2020 U.S. presidential election. As noted above, \nthe overall approach is to study most engaged-with content with a sensitivity \nto platform metrics, vernaculars of use and user subcultures. It relates a \nset of empirical studies that enquire into the extent to which platforms are \nagain mainstreaming the fringe, examining more specifically those spaces \nconjured through \u201cserious queries\u201d that contain election-related as well \nas COVID-19 information. When querying political hashtags, candidate \nand party names as well as issues, and sifting through the content most \ninteracted with on the platforms, how do more mainstream sources fare \nin comparison to those characterized as problematic? More to the point, \nis social media marginalizing the mainstream?\nHere I take the most salient findings per platform in turn, before conclud -\ning with a discussion of the emergence of editorial epistemologies put into \nuse by social media platforms as well as search engines. Editorial source \nadjudication is a remarkable transformation in how these platforms sift \nand filter sources, indicating an exceptional information state, a point \nupon which I conclude.\nTikTok: Instilling doubt in mainstream accounts\nTikTok is not usually considered a site for political encounter, but recently \nthe short video sharing platform, used predominantly by youth, has posted \nrules about political content, indicating its growing presence there. It also \nwarns against \u201cmisleading information\u201d and urges users to \u201cverify facts \nusing trusted sources,\u201d suggesting that misinformation could be worthy \nof investigation on the platform (TikTok, 2020). Apart from how to think \nabout TikTok\u2019s place in political discourse, we asked, how do TikTok users \nexpress themselves politically? How may forms of creative expression on \nTikTok manifest themselves as misinformation?\nOn TikTok the most engaged-with videos (returned through platform \nqueries of hashtags) are fresh and topical, which implies that the platform can \nbe regarded as an event-commentary medium, where users may encounter \npolitical \u201cnews\u201d first through its parody. Political parody in media has a long \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 15\nhistory, though here the argument is that rather than specialized magazines \nsuch as Punch , the British weekly satirical magazine (1841\u20132002), or The \nOnion , an American one (1988\u2013 ), it is a regular or \u201cmainstream mode\u201d of \nelection engagement for users of the platform.\nHow are they expressing themselves? The singing and dancing users \ndemonstrate a form of civic engagement by making, tagging and uploading \nvideos that are characterized as forms of \u201cplayful political performances\u201d \nas well as \u201cremixing as ambivalent critique.\u201d The playful performances \ninclude \u201cgiving a speech\u201d as well as \u201cstaging an opinion\u201d such as when a \nman speculates that he hears \u201cthank God for Donald Trump\u201d in the song, \nDa Da Da. The remixing of news clips and other video that is typical on \nTikTok satirize candidates, their supporters as well as their viewpoints by \nintroducing sounds that sew mistrust or ridicule, though it is not always clear \nwhether the critique is sincere or ironic, thereby meriting the description \n\u201cambivalent critique\u201d (Philips and Milner, 2017).\nThese sounds are networked objects in the sense that one can select and \nfollow the sound to other videos that have embedded it. The sounds are \noften deployed in analogous manners, meaning that the audio pathway \nwill lead to more remixed videos that satirize the candidates and their \nsupporters, or videos that have stitched into the another with the sound \nin order to comment on it (e.g., by commenting on it or mocking it). For \ninstance, \u201cRide It\u201d by Regard is a viral sound that is often paired with finger \ndancing to relate stories of cultural misunderstanding. TikTokers have used \nit when dealing with accusations of being a Trump supporter, such as \u201cget called racist 24/7\u201d (sound), \u201cget yelled at for presenting facts\u201d (sound), and \n\u201caccused of not respecting women\u201d (sound). The viral sound denotes being \nmisunderstood, eliciting sympathy but also a knowing smile.\nTikTokers employ a range of creative expression such as singing, dancing, \nduet, lip-syncing, mimicking, finger dancing, viral sounds and facial expres -\nsions. Some have specific connotations for TikTok insiders and make for \ntrends. Having queried election related hashtags, such as #trump2020 and \n#biden2020, it was found first that TikTokers make copious use of political \nhashtags, attaching both Trump and Biden-related hashtags to the same \nvideo, thereby striving to maximize the audience and view counts, rather \nthan identify with one candidate or another. In the analysis, the researchers \nundertook a format and content analysis of the top 30 videos per hashtag \nquery, examining which forms of creative expression are used in political videos and where misinformation may be imparted.\nApart from viral sounds, two other forms of creative expression stand out: \nlip-synching and facial expressions. TikTokers match the lip movements of \n16 r ichard rog erS \nthe candidates, often sarcastically, for example when the comedian, Sarah \nCooper, lip-synched Trump\u2019s remarks during a White House briefing on using \nultraviolet light and detergent to thwart the coronavirus (2020). Finally, the \nfacial expression that approximates the doubtful emoji is another creative \nexpression often encountered. In these videos news footage may be cut \ninto the shots, such as multiple clips of Joseph Biden hugging women, with \nthe intention to sew doubt about his fitness for presidential office. Here \nwe found many of the political videos instilling mistrust in news clips \nthrough sarcastic and doubtful facial expressions. Such a finding prompted \nconsideration of adding \u201cinstilling mistrust\u201d as a category of misinformation \ntypes developed by Wardle (2017), which ranges from parody (least intent \nto deceive) through misleading content and false context to fabricated \n(most intent). Alternatively, one could argue that on TikTok all categories \nof misinformation could be hybridized, for TikTokers are employing parody \nwhen simultaneously introducing misleading content, false context or other \nmisinformation types.\n4chan and Reddit: Referencing extreme YouTube content\nUnlike public-facing platforms such as Facebook and Twitter, where users \ncultivate an online self, 4chan and Reddit are so-called masked spaces of \nanonymous users (De Zeeuw and Tuters, 2020). Particularly the board, \n4chan/pol, and the subreddit, r/TheDonald, have been associated with \nelection politics, and especially the 2016 Trump campaign, where support \nfor his candidacy took the form of \u201cthe great meme war,\u201d which comprised \nthe deployment of vernacular language, image macros and other tactical \nmedia to support the candidate\u2019s cause (Donovan, 2019). Previous research \ninto misinformation in 4chan/pol and across Reddit found little reference \nto outwardly problematic sources, such as imposter news sites or (Russian) \ndisinformation, but rather numerous links to extreme videos on YouTube \nthat were later removed (Hagen and Jokubauskait\u0117, 2020). Thus, while not \nnecessarily a space that links to disinformation sources, it is problematic \nfor other reasons.\nHere, in the context of the run-up to the U.S. presidential elections of \n2020, the research enquired into the extent to which U.S.-based political \nboards and forums on 4chan and Reddit share misinformation and \u201cjunk\u201d \ncontent, and more specifically imposter news and other types of \u201cpink slime\u201d \nwebsites, termed as such for the use of low-cost, newspaper-like sites often \npublishing repurposed content (Tarkov, 2012; Bengani, 2019). We also were \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 17\nquestioning the interest these boards and communities might have in what \nhas been termed an \u201calternative influence network,\u201d a group of extreme \nsocial media influencers that \u201cfacilitates radicalization\u201d (Lewis, 2018). The \nresearch employed the so-called \u201cneedle-to-haystack\u201d technique, querying \n4chan/pol and all of Reddit for the URLs of the pink slime websites, and the \u201chaystack-to-needle\u201d technique which queries an expert list of problematic \nsources (hosts) in the same platform datasets (Hagen and Jokubauskait\u0117, 2020).\nThere are two separate sub-studies, one covering the period from \nJanuary\u00a011, 2019 to March\u00a025, 2020 and the second picks up where the first \nended and runs to December\u00a031, 2021. Throughout no pink slime sites were \nencountered, suggesting either their lack of significance (despite returning \nhigh in Google queries) or the media literacy of the users on the boards and \ncommunities (or both). Modest amounts of problematic sources were found \nbut like in previous research copious YouTube links were identified, which \nled to the inquiry into whether YouTubers from the alternative influence \nnetwork are significantly present in those online cultures. The alternative \ninfluence network (AIN) is described here as a set of YouTube channels \nfluctuating between \u201cnews and personality-centric vlogging, spreading \nmisinformation-laden commentary\u201d (Burton and Koehorst, 2020). Indeed, \nin the first period, many of these channels were found between the boards \nand subreddits under study, though their presence was unequally distributed. \n4chan/pol and Reddit are rather different in their media consumption, with \npolitical Reddit preferring to reference videos using the \u201calternative debate \nstyle\u201d and /pol electing more for the \u201ctoxic vox populist\u201d style of single person, \ndirect-to-audience (Tuters and Burton, 2020). Indicating their extreme \nspeech, a significant percentage of the YouTube videos referenced on 4chan \nhas been removed by the platform. In the second period in the run-up to the \nelections, however, the alternative influence network\u2019s presence declined \nsignificantly. It should be noted that in June\u00a02020 Reddit closed r/TheDonald \nas well as other extreme subreddits for breaking platform rules. The decline \nin links to the AIN coincided with the deplatforming as well as the decline \nin \u201cjunk news\u201d referenced in political Reddit. But given the AIN\u2019s decline on \n4chan (where no analogous deplatforming took place) one could speculate \nthat they were no longer considered \u201calternative\u201d for the fringe space.\nTwitter: Hyperpartisan sources in ascendancy\nLike Facebook and to a lesser extent Instagram, Twitter also has been the focus of public attention concerning misinformation around the 2016 U.S. \n18 r ichard rog erS \npresidential elections and beyond. Twitter, rather unlike the other two \nplatforms, has aided researchers in its study through providing curated \ndatasets of Russian and alleged Iranian trolls and influence campaigners, \nor what are referred to as inauthentic users (Gadde and Roth, 2018). Thus, in \nthe study of misinformation on Twitter, there are generally two strands of \nanalysis to consider\u2014problematic content as well as users. During the 2016 \nelection campaigning and running through to at least late 2019, much of that \ncontent and those users, described as \u201csprawling inauthentic operation[s]\u201d \nwere promoting \u201cpro-Trump messages\u201d (Romm and Stanley-Becker, 2019).\nHere we revisit these claims through a study of the content and users on \n\u201cpolitical Twitter\u201d in the early run up to the 2020 U.S. presidential elections \nand its aftermath, where we examine result sets of queries for election-\nrelated hashtags and keywords, together with the users most active in \ndeploying them (Groen and Geboers, this volume). How much problematic \ninformation is present in the most interacted-with content on political \nTwitter? Are problematic users among the most active? Are they generally \nof a particular political persuasion?\nThe content under study are the URLs (hosts) that are referenced in the \ntweets, and the most active users defined as those who tweet the most. In a \nthree-week timeframe prior to and just after Super Tuesday (March, 2020), \nwhen a cluster of election primaries and caucuses were held, in the aftermath \n(December, 2020 / January, 2021) and after the dust had settled on the Capitol \nbuilding riots (March\u00a02021), we compared the hosts found in the tweets to a \nlist of problematic sources curated by combining pre-existing labeling sites, \nincluding Allsides.com, Media Bias/Fact Check, \u201cthe Chart,\u201d and NewsGuard. \nWe also consulted Wikipedia and other news sources mentioning the sources \nin question. With one exception (related to the query DACA, the immigration \nissue), we found little reference to disinformation, imposter news sources, \npseudo-science, conspiracy theory sources or extreme sites. When expanding \nthe definition of problematic information to include hyperpartisan sites, \nhowever, in the first period nearly half would fall into that category, with the \nimplication that social media (or at least a goodly share of users of political \nTwitter) appear to marginalize mainstream sources. Put differently, if we \nwere to employ Craig Silverman\u2019s original definition of \u201cfake news,\u201d it could \nbe said to challenge mainstream sources anew, as it had in the immediate run-up to the 2016 U.S. elections (on Facebook) (2016). In December\u00a02020 / \nJanuary\u00a02021 the proportion of hyperpartisan hosts in the examined tweets \ndecreased slightly, but by March, 2021, after Twitter removed users breaking \nplatform rules (e.g., of glorification of violence) that figure was significantly \nlower, suggesting a \u201cdeplatforming effect.\u201d\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 19\nFor the study of the most active users, we analyzed \u201cauthenticity\u201d with \nthe aid of SparkToro, which employs indicators (abnormal tweeting activity, \nunusual combinations of followers/following, etc.) to make a determination. \nWe also studied user partisanship or side-taking through qualitative profile \nanalysis. Our findings are not dissimilar to others in that there is far more \ninauthenticity in the pro-Trump user base, but we also found that there are \na few flagged users on the other side of the political spectrum, too.\nFacebook: The seminal \u201cfake news\u201d problem persists\nJournalists began calling Facebook the seminal \u201cfake news machine\u201d (Gal -\nlucci, 2016) just after the finding made by Buzzfeed News  that so-called \nfake news was liked and shared more than mainstream news on the social \nmedia platform in the three months prior to 2016 U.S. presidential elections \n(Silverman, 2016). Since then, there has been a steady stream of stories from \nFacebook\u2019s corporate blog concerning both its crackdowns on \u201cinauthentic \ncoordinated behavior,\u201d or influence campaigning, as well as its initiatives to \ncurb misinformation and \u201cfalse news,\u201d which is a narrow definition includ -\ning pseudo-science and conspiracy sites though excluding hyperpartisan \nones (Mosseri, 2017). The measures began in at least April\u00a02017 with among \nother plans to economically disincentivize such sources as the infamous \nMacedonian fake news factory that chose divisive pro-Trump messaging \n(over pro-Sanders\u2019) because it brought in far more revenue (Silverman and \nAlexander, 2016; Tynan, 2016). Has much changed in how well \u201cfake news\u201d is consumed on the platform since 2016?\nA team of researchers and I revisited the original Buzzfeed News  story and \nits data journalism method in order to investigate the state of the \u201cfake news\u201d \nproblem in January\u2013March, 2020 (Rogers, 2020a), which is roughly the first \nof the three timeframes under consideration in the original Buzzfeed News  \npiece entitled, \u201cviral fake election news stories outperformed real news on \nFacebook\u201d (Silverman, 2016). We investigated again in January\u00a02021, looking \ninto the run-up to the election as well as its aftermath, from March\u00a02020 \nuntil the end of December, 2020.\nSilverman defined \u201cfake news\u201d as sources ranging from \u201choax sites [to] \nhyperpartisan blogs\u201d (Silverman, 2016). Akin to his method, we ran election-\nrelated queries in BuzzSumo, the social media research and monitoring \ntool. From the results we compiled a list of sources and characterized them \nwith the aid of a series pre-existing \u201cbias\u201d labeling sites, as in both Twitter \nand Google studies in this volume, so that we had a rough indication of \n20 r ichard rog erS \ntheir quality and partisanship. Sources are categorized as problematic or \nnon-problematic (which more colloquially could be called \u201cmainstream\u201d), \nand those falling into the latter category were subcategorized as (hyper)\npartisan-conservative, (hyper)partisan-progressive or neither of the two, \nagain with the aid of the existing labeling sites. Problematic sources included \nimposter news (and so-called \u201cpink slime\u201d sites), pseudo-science, conspiracy \ntheory and extreme sites, as was done in the Twitter study above (Bengani, \n2019).\nWhen using Silverman\u2019s \u201cfake news\u201d definition (that includes hyperparti -\nsan sites) Facebook\u2019s fake news problem has worsened slightly. In the seven \ntimeframes under study (from March\u00a02019 to December\u00a02020) the proportion \nof engagement of \u201cfake news\u201d to mainstream was on average 1:1.8 compared \nto 1:2.6 in 2016. If, however, we tighten the definition, as Facebook has done, \nto \u201cfalse news\u201d and include in that category only the sources or stories flagged \nas \u201cproblematic\u201d the scale of the problem drops substantially to 1 in 12 on \naverage per quarter. It should be noted that we encountered one imposter \nnews site, which may suggest that they are well targeted by Facebook or \nthat they are not significantly resonating among users.\nNonetheless, in the last period under study in 2016, when Silverman \nfound that \u201cfake news\u201d performed well, imposter sites (as the Denver Guard -\nian) comprised a majority of those most interacted-with. One implication \nof the finding is that efforts to identify imposter sites (and other \u201cpink \nslime\u201d) continue to have value, despite the fact that they are not yet well \nconsumed. Another implication is that if the problem remains of a smaller \nscale, scaled-up fact-checking may continue to find its place amongst \nthe counter-initiatives, rather than only mass content moderation and \nautomation.\nInstagram: Influencers as responsible information sources?\nInstagram had been one of the more understudied and under-appreciated \nsocial media platforms when it came to misinformation. That changed with \nthe release of two major reports on the Russian disinformation campaigning \nsurrounding the 2016 U.S. presidential elections (Howard et al., 2018; DiResta \net al., 2018). In fact, in one study, it was noted that unlike the other social \nmedia platforms Instagram actually saw a rise in disinformation activity in \nthe period just after the elections (Howard et al., 2018). Many of the posts, \nincluding memes, were openly divisive, but others were sarcastic and more \ndifficult to decode with respect to stance or side-taking. As scholars have \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 21\nfound, over the past few years more and more content online could be \ndescribed as equivocal or ambivalent, where the sincerity of the post and \nthe sender is unclear (Phillips and Milner, 2017; Hedrick et al., 2018).\nIn the study of election-related Instagram posts in the early run-up to the \n2020 U.S. presidential elections (January\u2013April, 2020) and in the run-up to \nthe election and its aftermath (September, 2020\u2013January, 2021), we enquired \ninto the amount of divisive and ambivalent posts, compared to non-divisive \nand earnest ones (Colombo and Niederer, this volume). How sarcastic and \n\u201cedgy\u201d are the top election-related posts on Instagram? Does it form the \ndominant mode of political discourse on the platform? We also are interested \nin whether misinformation is spread in this divisive, ambivalent style. To \nbegin to answer these questions, we queried CrowdTangle, Facebook\u2019s \ncontent monitoring tool, for the names of the candidates and select social \nissues (healthcare, gun control, COVID-19 and 5G), and coded the top 50 \nposts for divisiveness (or non-divisiveness) and ambivalence (or earnestness), \nwhereby each post is ultimately given a hybrid label, e.g., divisive-ambivalent. \nWe scrutinized the candidate- or issue-related posts by influencers that had \nparticularly high engagement scores, often at the top of the rankings. We \nalso sought misinformation.\nPerhaps counter-intuitively, we found Instagram to be a rather healthy \nplatform. The vast majority of the top posts concerning the candidates as \nwell as the social issues are earnest and non-divisive. Virtually no posts \nwere found to be divisive and ambivalent. Indeed, most posts were sincere \nexpressions of support. Of the few divisive posts which the coders addition -\nally found to be earnest, half were by Donald Trump or Donald Trump, Jr., \nand most of the rest concern Trump or gun control. Apart from a few posts \npushing a conspiracy theory surrounding 5G and COVID-19 (including \none post that ranked second in engagement), no other misinformation \nwas encountered. The top 5G related post, by an influencer, debunked the \nconspiracy. Indeed, with a few exceptions we also found that the influencers \nwere posting responsibly and earnestly.\nIn a separate exercise we studied the authenticity of the followers as well \nas the political parties, employing the HypeAuditor tool. While, in both \ntimeframes, the Republican Party\u2019s account had over 25% of suspect follow -\ners, and Trump\u2019s had 25%, Biden was not far behind at about 20%. His party \nalso had 25% of suspect followers. It should be noted that when separating \nthe two categories that make up inauthentic followers\u2014\u201cmass follower\u201d \naccounts and \u201csuspect\u201d accounts\u2014in the first period the Republican Party \nand Trump tally higher on suspicious followers, defined as \u201cInstagram bots \nand people who use specific services for likes, comments and followers \n22 r ichard rog erS \npurchase\u201d (Komok, 2020), while in the second period the candidates and \nparties grow closer together in their suspect counts.\nGoogle Web Search: Liberal sources outnumber conservative \nones\nWhile Google Web Search could be considered the dominant information \nmachine online, among the major platforms and online services it has been \none of the least studied for misinformation. Recognizing the potential for \nits spread during the pandemic, or what the head of the WHO called the \n\u201cinfodemic\u201d (UN DGC, 2020), Google has been curating the results for queries \nconcerning the COVID-19 pandemic, with side bars ordering the official \ninformation served, and results geo-tailored to provide local and national \nresources. Such information curation is rather unprecedented, unless one \ncounts Google\u2019s disclaimer notice on top of the results page for the query \n\u201cJew\u201d (Sullivan, 2004), or the cleaning up of autosuggested queries to remove \nethnic, homosexual and other slurs (Gibbs, 2016). Another contemporary \ncontext behind the study of election-related Google results concerns the \ndebate surrounding \u201cliberal tech bias\u201d (Schwartz, 2018). Could Google results \nbe thought to exhibit a bias towards or against particular types of sites? \nHow to characterize the sites returned for political queries?\nIn order to start to answer these questions, we queried candidate names, \npolitical parties and a host of election-related issues in Google, with results \nfrom the \u201cU.S. region\u201d from January\u00a012, 2019 to March\u00a023, 2020 and again from \nMarch\u00a024, 2020 to January\u00a05, 2021 (Torres, this volume). In an examination \nof the top 20 results per query, we ask, how to characterize the sources \nreturned? Are problematic sources present and even highly ranked? How \ncould the results be characterized politically? To do the analysis, we curated \na source list of problematic and non-problematic sources, largely news \nand cultural commentary, combining a set of media labeling sources, as \nin the Twitter and Facebook projects discussed above. We also consulted \nWikipedia and online news mentions of potentially problematic sources. \nThe categorization is considered rough and is meant to give an indication \nrather than a determination. With the aid of the labeling sites, we also \nassigned political leanings. There are two distinctive political categorization \nschemes, one \u201cample\u201d and one \u201cnarrow,\u201d with the former merging center-left \nand left and center-right and right, and the latter only including left (liberal) \nor right (conservative) labels, according to the sites that sort sources in such \na fashion. (When there was disagreement among the labeling sites, we went \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 23\nwith the majority.) We also labeled the sites returned that fell outside the \ncategories, such as \u201cspecial interest,\u201d \u201clocal news\u201d and \u201cofficial.\u201d\nIn all we found that the Google results for our nearly 120 queries resulted in \nscant problematic information returned. Hardly present as well were official \nsources that we defined as federal or local government, intergovernmental \nagencies, politicians, or campaign websites. Special interest sites, a broad \ncategory ranging from think tanks to advocacy groups, have an outsized pres -\nence in the results, however, especially in the run-up to the elections. These \nsites tend to specialize in an issue or industry, which is also an indication of \nhow Google values information sources. Most significantly, when considering \nthe political leanings of sources, it is striking that Google could be said not \nto seek \u201cbalance.\u201d That is, liberal sources outnumber conservative ones in the results for all queries made. Employing the \u201cample\u201d categorization, for \nthe first period, the results were 6:1 in favor of liberal sources, and 3:1 when \nemploying the narrower scheme, and for the second period they jumped \nto 12:1 and 14:1.\nMarginalizing the mainstream\nAt the outset the question to be addressed concerned the extent to which \nsocial media is \u201cmainstreaming the fringe,\u201d not so unlike the early web, \nprior to the development of epistemologies that placed it on firmer ground. \nAmong those mentioned were the wisdom of the crowd such as Wikipedia\u2019s \ncollaborative editing, but there were others. For instance, Yahoo! and DMOZ \nemployed librarianship in their directory-making, Google used hyperlink \nanalysis scientometrically, and the early U.S. blogosphere constituted a kind \nof fact-checking, epistemic community, most famously uncovering faked \ndocuments held up as authentic by an authoritative TV news program (60 \nMinutes), in what has become known as the \u201cKillian documents controversy\u201d \n(Callery and Proulx, 1997; Langville and Meyer, 2006; Wikipedia contributors, \n2020). Here we now ask the same of social media. How to characterize the current epistemological foundations of online platforms?\nIn order to grapple with that question, I briefly sum up the findings \nwith respect to the relationship between the mainstream and the fringe \nper platform and draw conclusions from our cross-platform approach. \nGenerally speaking, social media and its users appear to be marginalizing \nthe mainstream. Subsequently, I discuss the prospects of source adjudication \nin terms of results curation or otherwise managing which content is allowed \nto remain on social media platforms. It is a form of \u201cplatform criticism\u201d \n24 r ichard rog erS \nthat speaks to the various emerging epistemologies on offer to stabilize \nsocial media.\nThe social media platforms under study have varied relationships with main -\nstream media, at least with respect to those sources or posts most interacted \nwith in the run-up to the 2020 U.S. presidential elections and its aftermath. \nBroadly speaking, TikTok parodies it, 4chan and Reddit dismiss it and direct \nusers to alternative influence networks and extreme as well as conspiratorial \nYouTube content. Twitter nearly prefers the hyperpartisan over it. Facebook\u2019s \n\u201cfake news\u201d problem also concerns declining amounts of mainstream media \nreferenced. Instagram has influencers (rather than, say, experts) dominating \nuser engagement, though is a rather healthy space. By comparison, Google \nWeb Search buoys the liberal mainstream (and sinks conservative sites), but \ngenerally gives special interest sources, as they were termed in the study, the \nprivilege to provide information rather than official sources.\nThese findings were made on the basis of cross-platform approach that \nseeks to attain commensurability of the findings through employing engage -\nment analysis on each platform. At the same time, it remains sensitive to \nthe platforms\u2019 specificities by remaining attuned to each of their differing \nmetrics, vernaculars of use and user subcultures, as related above.\nOverall, we found that social media marginalize the mainstream, albeit in \nmanners specific to each platform. Given the decline of what one could call \n\u201cmainstream authority\u201d online, how to characterize the contemporary ap -\nproaches to source adjudication, when considering problematic information? \nThat platforms are manually editing results (for certain queries) indicates what I would call an \u201cexceptional information state.\u201d\nRecently, social media platforms and Google web search have begun to \ncurate the results of such \u201cserious queries\u201d as coronavirus, COVID-19 and \nsimilar terms related to the global pandemic. Such filtering may explain \nthe scant amount of outwardly problematic information such as conspiracy \nwebsites encountered in the top results for coronavirus queries across the platforms. It does, however, raise the question of the epistemology behind the authority that is being applied, and whether it puts paid (for example) \nto the signals approach of algorithms, and instead puts forward \u201cediting in\u201d \nofficial sources as the top content recommended.\nEditorial epistemologies and serious queries\nSource list or results curation is laborious work and fell into decline with \nthe overall demise of the human editing of the web and the rise of the \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 25\nback end, and algorithmic signals, taking over from the editors (Rogers, \n2013). COVID-19 and the coronavirus are thus exceptional for they have \nmarked the return of the editors and raise the question of whether their \nwork should extend beyond pandemic sources to election-related informa -\ntion, as discussed above. Maintaining COVID-19 and the coronavirus as \nan exceptional information state would draw the line there, though cases \ncould be made to extend the adjudicative practice to the democratic process, \nwhere policymakers especially in Europe have directed their efforts. France\u2019s \nfalse news legislation comes to mind, as does Germany\u2019s extension of its \nhate speech act. There are also Facebook\u2019s efforts to maintain a political \nad archive tool. Each is (partially) a response to concerns of a repeat, in \nEurope and beyond, of the \u201cfake news\u201d crisis of 2016.\nSo far, the pandemic and (for some) election-related matters are \u201cserious \nqueries\u201d in the sense that the information returned should not be fully in \nthe hands of current trends in algorithmic culture but returned to editors. \nWith content reviewers and moderators, there is currently a blurring (and \nin a sense cheapening) of editors, however. Their low-wage, outsourced \nwork to date has had to do with violent and pornographic content rather \nthan the \u201cquality of information\u201d (Roberts, 2019). There is the question of \nthe journalistic training and qualifications for the editing work (Parks, \n2019). The professional fact-checking editors, as mentioned above, would \nstruggle with volume.\nThere are advocates of an editorial recovery online. Source adjudica -\ntion techniques on offer these days for results curation are, among others, \njournalistic balance, the absence of biased sources, fact-checked stories, and \n\u201clongue dur\u00e9e\u201d expertise, be it official and/or established. Crowd-sourcing \nusers to flag inappropriate content or only checking trending content are \nalso available approaches. All mark the return of qualitatively determin -\ning the worthiness of source appearance and could be dubbed editorial \nepistemologies. Each requires judgements in advance of the moment of \ngaveling the A/B or ignore/delete decision, as platforms are wont to decide \nto allow a post or not. (For world leaders, as mentioned, the posts may be \nlabeled.) There is also the question of handling the volume of posts to be \nscrutinized\nWhen curating results or otherwise managing outputs, to undertake \n\u201cbalanced list\u201d work implies making political or partisan source distinctions, \nand continually returning to the outputs to check the weight of each side \nper substantive query. An approach seeking an \u201cabsence of biased sources\u201d \npresupposes classification and monitoring and likely relying on official, \ninstitutionalized information. Fact-checking, rather than on a source level, \n26 r ichard rog erS \nswitches the efforts to the individual story, and subsequently researches, \narchives and labels them. At least as it has been performed on Facebook \nposts by DPA and AFP, the German and French news agencies respectively, \nit is such meticulous work that it outputs a total of about four fact-checks \nper day, if their production prior to the 2021 Dutch elections is exemplary \n(AFP, 2021; DPA, 2021). Relying on \u201clongue dur\u00e9e\u201d expertise could be another \nmeans of offering high-quality sources, as organizations working in the same \nterrain for many years would have accrued credibility, but to official sources \nit would add non-governmental and other specialized organizations with an established track record (and perhaps a noticeable political leaning).\nAnother starting point is to take an active audience approach, and assume \nthat another, perhaps more significant instance of filtering lies with the \nuser or what was once known as the \u201cwisdom of the crowd.\u201d Users can \n\u201cflag\u201d or report content on various platforms and label it as inappropriate, \nmisleading, etc. Taking such user reporting practices a step further, as \nmentioned above, Twitter\u2019s \u201cBirdwatch\u201d program seeks dedicated users (not \nso unlike Wikipedians, albeit without the non-profit spirit) to sift content and enforce platform rules.\nAs demonstrated in the empirical research reported above, engagement \nmeasures that consider rating (liking), circulating (sharing) and comment -\ning (reading) are another means to determine the activity of audiences. \nOn Facebook, but also on Twitter (retweeting), one may inquire into the \nstories about the coronavirus and other issues making audiences active. \nAdjudicating only those posts with the highest engagement would allow \nliking and sharing to trigger editorial interest.\nFinally, one also could argue for an \u201canything goes\u201d approach to mis -\ninformation, returning to a pre-pandemic algorithmic signals method \noperated in tandem with standard content moderation, editing out violence, \npornography, terrorism and hate. Such a return would appear unlikely \nas it would imply a regress in content review standards on mainstream \nplatforms. For example, since 2019, Twitter policies cover not just  violence \nbut its \u201cglorification\u201d (Twitter, 2019a), as publicized in a case of the labeling \na Donald Trump tweet as such. Indeed, more content types are scrutinized \nthese days. Specifically, since the coronavirus pandemic, the types have \nbeen expanded to include \u201cmisleading\u201d information.\nWith respect to identifying such information, Twitter writes, \u201cmoving \nforward, we may use these labels \u2026 in situations where the risks of harm \n\u2026 are less severe but where people may still be confused or misled by the content\u201d (Roth and Pickles, 2020). Setting aside for a moment the question \nof taking social media company utterances at face value (John, 2019), the \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 27\nstatement raises the prospect that the new editorial epistemologies, together \nwith the contestation that accompanies their fundaments, may abide beyond \nthe current exceptional information state.\nNote\nAn earlier version of the article appeared in the journal, Frontiers in Big \nData  (Rogers, 2021) .\nReferences\nAFP (2021). AFP Factcheck Nederland, Agence France-Presse. https://factcheckned -\nerland.afp.com/list.\nAllcott, H., Gentzkow, M. and Yu, C. (2019). Trends in the diffusion of misinforma -\ntion on social media. Research & Politics , April\u2013June\u00a02019: 1\u20138.\u2028 https://doi.\norg/10.1177/2053168019848554.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nBarkun, M. (2016). Conspiracy theories as stigmatized knowledge. Diogenes , 62(3\u20134). \nhttps://doi.org/10.1177/0392192116669288.\nBartlett, J. and Krasodomski-Jones, A. (2015). Counter-speech: Examining content \nthat challenges extremism online. Demos. http://www.demos.co.uk/wp-content/\nuploads/2015/10/Counter-speech.pdf.\nBengani, P. (2019, December\u00a018) Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points, Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y., Faris, R. and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBounegru, L., Gray, J., Venturini, T. and Michele, M. (2018). A field guide to fake \nnews . Public Data Lab.\nBruns, A., Harrington, S. and Hurcombe, E. (2020) \u201cCorona? 5G? or both?\u201d: The \ndynamics of COVID-19/5G conspiracy theories on Facebook. Media International \nAustralia , 177 (1). https://doi.org/10.1177/1329878X20946113.\nBurton, A. and Koehorst, D. (2020). The spread of political misinformation on \nonline subcultural platforms. Harvard Kennedy School Misinformation Review , \n1(6). https://doi.org/10.37016/mr-2020-40.\nBuzzSumo (2020). Buzzsumo media monitoring. https://buzzsumo.com.\n28 r ichard rog erS \nCallery, A. and Proulx, D.T. (1997) Yahoo! Cataloging the web. Journal of Internet \nCataloging , 1(1). https://doi.org/10.1300/J141v01n01_06.\nColeman, K. (2021). Introducing Birdwatch, a community-based approach to mis -\ninformation. https://blog.twitter.com/en_us/topics/product/2021/introducing-\nbirdwatch-a-community-based-approach-to-misinformation.html.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram: Junk news, fol -\nlower ecologies and artificial amplification, In R. Rogers and S. Niederer (Eds.) The \npolitics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University Press.\nCooper, Sara (2020). How to medical, TikTok video. https://www.tiktok.com/@\nwhatchugotforme/video/6819061413877763334.\nDaniels, J. (2018). The algorithmic rise of the \u201calt-right.\u201d Contexts , 17(1). ht tps://doi.\norg/10.1177/1536504218766547.\nDe Zeeuw, D. and Tuters, M. (2020). Teh Internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nDean, J. (1998). Aliens in America . Cornell University Press.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J. and \nJohnson, B. (2018). The tactics & tropes of the Internet Research Agency. New \nKnowledge. https://disinformationreport.blob.core.windows.net/disinformation-\nreport/NewKnowledge- Disinformation-Report-Whitepaper.pdf.\nDonovan, J. (2019). How memes got weaponized: A short history. MIT Tech -\nnology Review .  https://www.technologyreview.com/2019/10/24/132228/\npolitical-war-memes-disinformation/.\nDPA (2021). DPA fact-checking. Deutsche Presse-Agentur. https://dpa-factchecking.\ncom/netherlands/.\nEllis, E.G. (2019, September\u00a010) Fighting Instagram\u2019s $1.3 billion problem\u2014fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nFacebook (2018, December\u00a06). Coordinated inauthentic behavior. Facebook News -\nroom. https://about.fb.com/news/2018/12/inside-feed-coordinated-inauthentic-\nbehavior/.\nFacebook (2021a, February\u00a09). January\u00a02021 coordinated inauthentic be -\nhavior report. Facebook Newsroom. https://about.fb.com/news/2021/02/\njanuary-2021-coordinated-inauthentic-behavior-report/.\nGadde, V. and Roth, Y. (2018, October\u00a017). Enabling further research of information \noperations on Twitter. Twitter blog. https://blog.twitter.com/en_us/topics/\ncompany/2018/enabling-further-research-of-information-operations-on-twitter.\nhtml.\nGagliardone, I. (2019). Defining online hate and its \u201cpublic lives\u201d: What is the place \nfor \u201cextreme speech\u201d? International Journal of Communication , 13. ht tps://doi.\norg/1932\u20138036/20190005.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 29\nGallucci, N. (2016, November\u00a022). 8 ways to consume news without using Facebook. \nMashable . https://mashable.com/2016/11/22/consume-news-without-facebook/.\nGibbs, S. (2016, December\u00a05). Google alters search autocomplete to remove \u201care Jews \nevil\u201d suggestion. The Guardian . https://www.theguardian.com/technology/2016/\ndec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion.\nGillespie, T. (2018). Custodians of the Internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nHarris, S. (2019, February\u00a05). #148 \u2013 Jack Dorsey. Sam Harris Podcast. https://\nsamharris.org/podcasts/148-jack-dorsey/.\nHedrick, A., Karpf, D. and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal of Communication , 12(8). https://ijoc.org/index.\nphp/ijoc/article/view/8736.\nHerrman, J. (2016, August\u00a024). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHoward, P.N., Ganesh, B., Liotsiou, D., Kelly, J. and Fran\u00e7ois, C. (2018). The IRA, social \nmedia and political polarization in the United States, 2012\u20132018, Computational \nPropaganda Research Project, Oxford Internet Institute.\nHypeAuditor (2020). Instagram reports, https://hypeauditor.com/reports/\ninstagram/.\nJohn, N.A. (2019). Social media bullshit: What we don\u2019t know about facebook.com/\npeace and why we should care. Social Media + Society , January\u2013March: 1\u201316. \nhttps://doi.org/10.1177/2056305119829863.\nKomok, A. (2018). How to check Instagram account for fake followers. HypeAuditor. htt -\nps://hypeauditor.com/blog/how-to-check-instagram-account-for-fake-followers/.\nLangville, A.N. and Meyer, C.D. (2006). Google\u2019s PageRank and beyond: The science \nof search engine rankings . Princeton University Press.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube. Data & Society Research Institute. https://datasociety.net/output/\nalternative-influence/.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\nMahendran, L. and Alsherif, N. (2020, January\u00a08) Adding clarity to our Com -\nmunity Guidelines. TikTok newsroom. https://newsroom.tiktok.com/en-us/\nadding-clarity-to-our-community-guidelines.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nMosseri, A. (2017, April\u00a06). Working to stop misinformation and false news. Facebook \nNewsroom. https://about.fb.com/news/2017/04/working-to-stop-misinformation-\nand-false-news/.\n30 r ichard rog erS \nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nOlmsted, K. (2009) Real enemies: Conspiracy theories and American democracy, \nWorld War I to 9/11 . Oxford University Press.\nOtero, V. (2017). The Chart. version 3.1. ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nParks, L. (2019). Dirty data: Content moderation, regulatory outsourcing and The \nCleaners. Film Quarterly , 73(1). https://doi.org/10.1525/fq.2019.73.1.11.\nPepp, J., Michaelson, E. and Sterken, R. (2019). Why we should keep talking about \nfake news. Inquiry . https://doi.org/10.1080/0020174X.2019.1685231.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nPorter, J. (2020, May\u00a029). Twitter restricts new Trump tweet for \u201cglorifying violence.\u201d \nThe Verge . https://www.theverge.com/2020/5/29/21274323/trump-twitter-\nglorifying-violence-minneapolis-shooting-looting-notice-restriction.\nRheingold, H. (1994). The millennial whole earth catalog . HarperCollins.\nRoeder, O. (2018, August\u00a08). We gave you 3 million Russian troll tweets. Here\u2019s \nwhat you\u2019ve found so far. FiveThirtyEight. https://fivethirtyeight.com/features/\nwhat-you-found-in-3-million-russian-troll-tweets/.\nRogers, R. (2004 ). Information politics on the web . MIT Press.\nRogers, R. (2013). Digital methods . MIT Press.\nRogers, R. (2017). Digital methods for cross-platform analysis. In J. Burgess, A. \nMarwick and T. Poell (Eds.) The SAGE handbook of social media  (pp.\u00a091\u2013108). Sage.\nRogers, R. (2019). Doing digital methods . Sage.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nRogers, R. and Hagen, S. (2020). Epilogue: After the tweet storm. In R. Rogers \nand S. Niederer (Eds.) The politics of social media manipulation (pp.\u00a0253\u2013256). \nAmsterdam University Press.\nRomm, T. and Stanley-Becker, I. (2019, December\u00a021). Facebook, Twitter disable \nsprawling inauthentic operation that used AI to make fake faces. Washington \nPost . https://www.washingtonpost.com/technology/2019/12/20/facebook-twitter-\ndisable-sprawling-inauthentic-operation-that-used-ai-make-fake-faces/.\nRoth, Y. and Pickles, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.html.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 31\nSchwartz, O. (2018, December\u00a04). Are Google and Facebook really suppressing con -\nservative politics? The Guardian . https://www.theguardian.com/technology/2018/\ndec/04/google-facebook-anti-conservative-bias-claims.\nShirky, C. (2008). Here comes everybody . Penguin.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSilverman, C. and Alexander, L. (2016, November\u00a03). How teens in the Balkans \nare duping Trump supporters with fake news. Buzzfeed News . https://www.\nbuzzfeednews.com/article/craigsilverman/how-macedonia-became-a-global-\nhub-for-pro-trump-misinfo.\nSparktoro (2021). Audience intelligence. https://sparktoro.com.\nSullivan, D. (2004, April\u00a024) Google in controversy over top-tanking for anti-Jewish \nsite. Search Engine Watch . https://www.searchenginewatch.com/2004/04/24/\ngoogle-in-controversy-over-top-ranking-for-anti-jewish-site/.\nTarkov, A. (2012, June\u00a030). Journatic worker takes \u201cThis American Life\u201d inside out -\nsourced journalism. Poynter. https://www.poynter.org/reporting-editing/2012/\njournatic-staffer-takes-this-american-life-inside-outsourced-journalism/.\nTuters, M. and Burton, A. (2021). The rebel yell: Toxic vox populism on YouTube. \nCanadian Journal of Communication . forthcoming.\nTwitter (2019a). Glorification of violence policy, Twitter help center. https://help.\ntwitter.com/en/rules-and-policies/glorification-of-violence.\nTynan, D. (2016, August\u00a024) How Facebook powers money machines for obscure polit -\nical \u201cnews\u201d sites. The Guardian . https://www.theguardian.com/technology/2016/\naug/24/facebook-clickbait-political-news-sites-us-election-trump.\nUN DGC. (2020, March\u00a031). UN tackles \u201cinfodemic\u201d of misinformation and \ncybercrime in COVID-19 crisis. UN Department of Global Communica -\ntions. https://www.un.org/en/un-coronavirus-communications-team/\nun-tackling-\u2018infodemic\u2019-misinformation-and-cybercrime-covid-19.\nVaidhyanathan, S. (2019, July\u00a028). Why conservatives allege big tech is muzzling \nthem. The Atlantic . https://www.theatlantic.com/ideas/archive/2019/07/\nconservatives-pretend-big-tech-biased-against-them/594916/.\nVan der Linden, S., Panagopoulos, C. and Roozenbeek, J. (2020). You are fake news: \nPolitical bias in perceptions of fake news. Media, Culture & Society , 42(3). ht tps://\ndoi.org/10.1177/0163443720906992.\nVenturini, T. (2019). From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights  \n(pp.\u00a0123\u2013144). Routledge.\n32 r ichard rog erS \nWardle, C. (2017, February\u00a016). Fake news: It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nWikipedia contributors (2020). Killian documents controversy. Wikipedia: The \nFree Encyclopaedia . https://en.wikipedia.org/w/index.php?title=Killian_docu -\nments_authenticity_issues&oldid=962589844.\nWilkinson, W.W. and Berry, S.D. (2020). Together they are Troy and Chase: Who \nsupports demonetization of gay content on YouTube? Psychology of Popular \nMedia , 9(2). https://doi.org/10.1037/ppm0000228.\nAbout the author\nRichard Rogers , PhD, is Professor of New Media & Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods \nInitiative. He is author of Information Politics on the Web and Digital Methods  \n(both MIT Press) and Doing Digital Methods (SAGE).\n2 P roblematic information in Google \nWeb Search?\nScrutinizing the results from U.S. election-related queries\nGuillen Torres1\nAbstract\nThe goal of this study is to analyze the type and ranking of informa -\ntion sources furnished by Google Web Search for queries related to the \n2020 U.S. presidential election. Overall, we found that the presence of \nproblematic information in the returns is scant. In additionally studying \nthe diversity of sources, we found an asymmetry between liberal and \nconservative websites in the top results. This imbalance is notable when \napproaching it through the lens of an opposition or even competition for \nhigh rankings between liberal and conservative media, broadly defined. A \nmore nuanced classification does not eliminate the imbalance given the \nnear absence (from March\u00a02020 to January\u00a02021) of explicitly conservative \noutlets.\nKeywords: Google, problematic information, digital methods, elections \nresearch\nResearch questions\nHow are problematic sources positioned within the first 20 Google.com \nresults, when querying U.S. candidates and their most significant issues? \nFor issue-related queries, what are the predominant source types returned, \nand how may their leanings be characterized politically?\n1 Pa rts of this research were carried out in collaboration with Varvara Boboc and Robert \nBaciu.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch02\n34 g uillen Torre S \nEssay summary\nThe main finding is that within the top 20 Google results for election-related \nqueries from February\u00a02019 to January\u00a02021 the presence of problematic \ninformation is low. We also find that when using either \u201cample\u201d or \u201cnarrow\u201d \ndefinitions of liberal and conservative sources to query Google Web Search \nin different moments in time, liberal outnumber conservative. Moreover, \nwe find the predominance of mainstream news, a considerable presence \nof \u201cspecial interest\u201d websites and a fluctuating presence of official sources. \n\u201cSpecial interest\u201d is used as a broad category including professional as -\nsociations, think tanks, and industry or community news sites, producing \ninformation mostly around one specific topic (e.g., farming or taxes), while \n\u201cofficial sources\u201d are largely governmental or the candidates\u2019 own campaign \nwebsites.\nThis study undertakes a source-distance analysis of Google.com results \nfor the periods of February\u00a012, 2019 to March\u00a023, 2020 and March\u00a024, 2020 \nto January\u00a05, 2021, where one measures how far from the top of the returns \nare particular types of sources. To assign a rough political bias category \nto the search results, two classifications were devised, based on existing \nschemes. An \u201cample\u201d classification combines center-left and left political \norientations into left, and center-right and right into right. A \u201cnarrow\u201d \nclassification makes a stricter division and only considers explicitly left or \nright sources as liberal or conservative, while center-left and center-right \noutlets are considered mainstream.\nImplications\nThe low presence of official institutional sources in the returns to our queries \nis not necessarily problematic, but the strategies Google implemented to \nfight problematic information related to SARS-CoV-2 beg the question about \nwhether something similar may be justified for queries related specifically \nto elections, or more generally to public policies or governmental programs \nthat have proven controversial or divisive in the past (e.g., DACA or foreign \nrelations with China). Google already employs \u201cfeatured snippets\u201d that \nhighlight certain sources for general searches (e.g., [Trump policies] bring \nup a Wikipedia page), but this is not the case for queries about specific \npolicies. Whether it is desirable that Google privileges information produced \nby politically accountable institutions is a discussion that lies beyond the \nProble MaTi c infor MaTi on in go ogle Web Search?  35\nscope, but the fact that the company has decided to take a stance regarding \nSARS-CoV-2 suggests that there might be benefits to such a strategy.\nSecondly, the near absence of such problematic sources as imposter, \nconspiracy, pseudo-science or extreme sites in the top twenty results suggests \nthat Google\u2019s efforts to prevent such misinformation from rising to the top \nare succeeding (Google 2019a). This is the case at least for queries related \nto political issues and candidates. As other platforms are arguably losing \nthe battle against problematic information, particularly in the context of \nthe global pandemic and political unrest in the U.S. (Alba, 2020), Google\u2019s \nstrategies could be considered by other actors.\nThird, we found a preponderance of liberal sources over conservative \nones using both an \u201cample\u201d and a \u201cnarrow\u201d classification of information \nsources. Although this result could be related to the wording of our \nqueries (i.e., occasionally using more liberal keywords), we found that \nthe imbalance still stands for those queries that could be considered \nmore neutral (i.e., immigration). Considering that a perceived liberal \nmedia bias lingers in the U.S. political imaginary (Hassel et al., 2020), \nGoogle may find that clarifying anew why its algorithm privileges certain \noutlets over others could contribute to the debate about a \u201cliberal tech \nbias\u201d (Boxell et al., 2020). Although Google previously has openly stated \nthat there is no bias affecting its results (Wakabayashi, 2018) and the \nplatform\u2019s role in polarizing its users is still a heavily contested matter \n(Boxell et al., 2017; Sunstein, 2018; Bail et al., 2018), Google\u2019s reflection \nabout the possibilities of implicit bias could be beneficial. The company \noften frames the production of its results as a process guided by objective \nmeasures of content quality and value (Google, 2019a, 2019b); however, \nreflections around these concepts (Kelemen, 2005; Heuts and Mol, 2013) \nas well as about the politics of search engine rankings (Introna and \nNissenbaum, 2000; Noble 2018) could be matters for Google to discuss \nmore explicitly.\nFinally, the considerable presence of websites of special interest in our \nqueries implies that these sources have the privilege of supplying election-\nrelated information. Considering how those voices are boosted over official \nsources, this finding calls for a more specific analysis into the politics of the \ninformation they produce. Although previous studies have also noted the \npresence of this type of source (Courtois et al., 2018; Unkel and Haim, 2019), \nthey have not yet been the exclusive object of research. Such an analysis \nwould pertain to the study of less obvious partisanship in search engine \nrankings (Robertson et al., 2018).\n36 g uillen Torre S \nFindings\nFinding 1: Official sources are hardly in evidence in Google Web Search results \nfor queries related to the 2020 U.S. presidential candidates Joe Biden and Donald \nTrump. Overall, the presence of official sources, such as \u201c.gov\u201d sites or official \ncampaign sites is quite low. For the first period under research (February\u00a012, 2019 \nto March\u00a023, 2020), official sources make up only 1% of the total. For the second \n(March\u00a024, 2020 to January\u00a05, 2021), which includes the official campaign season, \nthe elections and the days prior to inauguration day, the presence of these \nsources increases considerably, making up 5% of the dataset. Queries related \nto Donald Trump produce the highest number of official sources, accounting \nfor nearly 10% of that subset of the results. In fact, the whitehouse.gov website \nwas the third most common top result for Trump-related queries. Given the \nscope of this chapter, it is not possible to identify whether this change is related \nto contextual factors such as current events or a change in the evaluation of \nsource relevance by the Google Web Search service.\nFinding 2: Problematic information is hardly present in Google Web \nSearch results for queries related to the 2020 U.S. presidential candidates \nbefore the start of the pre-campaigning, and it is entirely absent afterwards. \nProblematic sources are only present in our dataset if this category is made \nto include hyperpartisan websites. No imposter, fake news or fly-by-night \nsources were identified. Only five sources classified as problematic were \nidentified: The World Tribune, National File, RedState, TheBL, and  Breitbart, \nall labeled as hyperpartisan. These sources were present exclusively during \nthe period between the unofficial start of Trump\u2019s campaign and the suspen -\nsion of in-person rallies due to the COVID pandemic. Table\u00a02.1 displays the \ndistribution of problematic sources among the results. There is no particular \nquery that seems to be more likely to return problematic sources than others, \nalthough queries where hyperpartisan sources are present also seem to \nhave more conservative sources than liberal, which is remarkable given the \noverall low presence of right-of-center sources. It is noteworthy that while \nthe presence of this type of source is minimal, The World Tribune , National \nFile and RedState  show up as the first result for some queries. Queries related \nto Joe Biden produced the highest number of problematic sources.\nTable\u00a02.1  P roblematic sources in Google Web Search results.\nSource Query Candidate Result ranking\nWorld Tribune K-12 \nedu\ncation do\nnald Trump 1\nThe bl re\nparations Joe \nbid\nen 14\nProble MaTi c infor MaTi on in go ogle Web Search?  37\nSource Query Candidate Result ranking\nn\national \nfi\nle ch\narter Schools Joe \nbid\nen 1\nbre\nitbart da\nca J\noe \nbid\nen 19, 20\nre\nd State The \nco\nnstitution Joe \nbid\nen 1\nTimeframe: fe bruary\u00a012, 2019 to March\u00a023, 2020. da ta from go ogle.com.\nFinding 3: Mainstream news websites dominate the top 20 Google Web \nSearch Results. For both periods under review, the majority of the websites \npresent in the first 20 results of our political queries are mainstream news \nand special interest sites. Table\u00a02.2 summarizes the types of sources present \nin our queries for the first period under review. The ten most present sources \nare the following: Politico , The New York Times, The Hill , Forbes , Common \nDreams (which we classified as a liberal source, rather than mainstream), \nThe Guardian , Reuters , USA Today , The Wall Street Journal and Wikipedia . \nTogether, they make up 28% of the total results.\nTable\u00a02.2   Oc currences of different types of sources in the results of Google Web \nSearch to political queries. \nCandidate News \n(national)Special interestNews (local)Official Platform Academic Problematic/hyperpartisanOther\nTrump 73% 19.2% 6.2% 1% 0.9% 0.09% 0.04% 1.3%\nbid\nen 71% 15.8% 9.34% 1.5% 1.2% 0.08% 0.2% 1.3%\nTimeframe: \nfe\nbruary\u00a012, 2019 to March\u00a023, 2020. The category \u201cother\u201d includes websites that \nappeared in the results due to the keywords we used in connection with the names of the \ncandidates, but that did not include political information. \nda\nta from \ngo\nogle.com.\nTable\u00a02.3 summarizes the types of sources returned by Google Web Search \nfor the second period under review. The top positions this time are held \nby The Washington Post , followed by CNBC, The New York Times, Reuters, \nForbes, NPR, Politico, The White House, The Guardian and  NBC News . Together, \nthese sources represent 34% of the total results, which implies an increase \nin the overall prominence of these ten mainstream sources (together with \nthe one official source) in comparison to the period before. This result is \nnoteworthy considering that the overall presence of mainstream sources \nis lower in this second dataset, since special interest websites increased \ntheir incidence. The stable presence of The New York Times, Politico, Forbes, \nReuters and  The Guardian  suggests that Google Web Search assigns them \na high relevance.\n38 g uillen Torre S \nTable\u00a02.3   Oc currences of different types of sources in the results of Google Web \nSearch to political queries.\nCandidate News \n(national)Special interestNews (local)Official Platform Academic Other\nTrump 58% 20% 8% 9.3% 3% 0.7% 1%\nbid\nen 53.4% 28.5% 11.4% 3% 2.3% 0.5% 0.7%\nTimeframe: March\u00a024, 2020 to January\u00a05, 2021. The categories of \u201cproblematic\u201d and \u201chyperparti-\nsan\u201d are not included given that no source was classified as such. \nda\nta from \ngo\nogle.com.\nFinding 4: Overall, the presence of liberal sources is greater than that \nof conservative websites. Using news bias labeling sites as a rough in-\ndicator, we found a greater presence of liberal sources in comparison to \nconservative ones in all queries and for both periods under review, with \na slight decrease in the presence of right-of-center sources in the second. \nThis was the case both with \u201cample\u201d and \u201cnarrow\u201d definitions of what \nconstitutes a liberal or conservative source. Imbalances within search \nresults have been noted before by researchers, journalists and civil society \norganizations, and results have varied depending on geography and subject \nmatter. For example, Haim et al. (2017) found an overrepresentation of \nconservative sources in Germany, while in the U.S. audits tend to find more \nliberal websites than conservative ones (Trielly and Diakopoulos, 2018). \nIn our case, using the \u201cample\u201d classification makes the imbalance grow \nto a proportion of 6:1 in favor of liberal sources for the first period under \nanalysis and 12:1 for the second. Using the \u201cnarrow\u201d scheme changes the \nimbalance to around 3:1 and 14:1, respectively. The increase in the ratio of \nliberal to conservative sources in the second period of analysis is credited \nto a considerable decrease in the number of conservative websites in the \nreturns, rather than an increase of liberal ones. In fact, the data show \nan overall decrease of both types of sources, although the presence of \nconservative sources declined more. Tables\u00a02.4 and 2.5 show the propor -\ntions using both classifications. The imbalance stands even for queries \nthat deal with topics that would, intuitively, be connected to a higher \npresence of conservative sources (i.e., [Donald Trump] [Gun control] or \n[Donald Trump] [immigration]).\nProble MaTi c infor MaTi on in go ogle Web Search?  39\nTable\u00a02.4   P roportion of liberal and conservative news sources per candidate. \nEarly campaigning period\nCandidate Liberal\n(ample)Unbiased(ample)Conservative(ample)Liberal(narrow)Unbiased(narrow)Conservative(narrow)\ndo nald Trump 44.4% 24.2% 8% 11% 63% 3%\nJoe \nbid\nen 39% 25% 14% 12% 59% 6%\n\u201cSpecial interest\u201d websites are not considered, as their political orientation has not been defined. \nTimeframe: \nfe\nbruary\u00a012, 2019 to March\u00a023, 2020. \nda\nta from \ngo\nogle.com.\nTable\u00a02.5   P roportion of liberal and conservative news sources per candidate. \nRun-up to election and aftermath\nCandidate Liberal\n(ample)Unbiased(ample) Conservative\n(ample)Liberal(narrow)Unbiased(narrow)Conservative(narrow)\ndo nald Trump 41% 22% 2% 4% 61% 0.3\u00a0%\nJoe \nbid\nen 39% 22% 3% 5% 59% 1%\n\u201cSpecial interest\u201d websites are not considered, as their political orientation has not been defined. \nTimeframe: March\u00a024, 2020 to January\u00a05, 2021. \nda\nta from \ngo\nogle.com.\nThe imbalance is also present when analyzing the diversity of unique URLs \nfrom which Google Web Search draws its results. Our dataset consists of 1,300 \nunique URLs. The proportion liberal/conservative of these sources using \nthe ample scheme is around 3:1, whereas using the more restrictive criteria \nit is around 4:1. This difference suggests that, overall, Google seems to be \ndrawing results from a more diverse pool of liberal sites than conservative. \nWhen only explicitly progressive/conservative websites are classified as \nsuch, the imbalance increases. Rather than implying a liberal bias, this \nresult could be related to the existence of a higher number of liberal outlets \n(Trielli and Diakopoulos, 2019).\nThere is also a slight difference in the political composition of the unique \nsources in the two moments of data capture. For example, the five hyper -\npartisan conservative sources found in the first dataset did not appear in \nsubsequent queries, despite the use of the same keywords. This could be \nrelated to current events during the dates of the queries rather than a bias \nin Google\u2019s service. Table\u00a02.6 showcases the political composition of the two \ndatasets in terms of unique sources. This table suggests a tendency towards the \nreduction of liberal and conservative sources in the search results over time.\n40 g uillen Torre S \nTable\u00a02.6   Numb er of unique sources in absolute numbers, by political \norientation.\nFebruary\u00a012, 2019\u2013March\u00a023, 2020 March\u00a024, 2020\u2013January\u00a05, 2021\nLeft Center Right Left Center Right\nNarrow 60 290 28 40 265 7\nAmple 235 80 78 201 79 36\nda ta from go ogle.com.\nTable\u00a02.7 digs further into the reduction in the presence of explicitly liberal \nor conservative sources by showcasing how their presence changed between \nthe two periods under review. Common Dreams and Jacobin Magazine  \nexhibit the biggest change, given that they were prominently featured in \nthe first period, when they were even featured as the top result in 11 out of \n114 queries.\nTable\u00a02.7   T op liberal and conservative sources in absolute numbers, for both \nperiods under research.\nFebruary\u00a012, 2019\u2013March\u00a023, 2020 March\u00a024, 2020\u2013January\u00a05, 2021\nLiberal Conservative Liberal Conservative\ncommondreams.com 96 washingtontimes.com 53 newsweek.com 21 f\noxbusiness.com 10\njacobinmag.com 61 washingtonexaminer.com 45 newyorker.com 20 washingtonexaminer.com 3\nnewsweek.com 55 nationalreview.com 36 prospect.org 17 city-journal.org 1\nnymag.com 49 thefederalist.com 7 vanityfair.com 13 washingtontimes.com 1\nthenation.com 12 city-journal.org 1 nymag.com 9 nationalreview.com 1\nda ta from go ogle.com.\nFinding 5: Special interest websites (and local news stations) have a \nconsiderable presence within top 20 Google results for election-related \nqueries. Although national mainstream news outlets make up for the \nlargest proportion of results to our queries, they are not in the majority \nwhen analyzing the diversity of unique sources. For the first period of \nanalysis, special interest websites represent 40% of the pool of sources from \nwhich Google Web Search draws its results, whereas local news websites \nrepresent 20% and mainstream news websites represent only 19%. The \npresence of this type of source is higher when querying candidate names \nProble MaTi c infor MaTi on in go ogle Web Search?  41\ntogether with sensitive topics such as drugs, migration or gun control, but \nalso for some less obviously contentious topics such as K-12 education and \ntransportation.\nTable\u00a02.8 presents the distribution of unique sources in the results to \nour queries for both periods under review. Sites we have defined as special \ninterest are the largest number in both cases, and the data shows an increase \nof 40% of this type of source in the latter queries. The considerable presence \nof special interest websites suggests that Google\u2019s understanding of relevance \nvalues specialization and expertise less than the journalistic qualities of \nestablished news outlets. Thus, although search results are drawn from a \nmore diverse pool of special interest websites, they are featured less often. \nThe top five special interest websites for the first period were Marijuana \nMoment (cannabis enthusiasts), The Motley Fool (investment), EdWeek  \n(education), American for Tax Reform (policy), and The Tax Foundation \n(policy). For the second period, the top five sources were Marijuana Moment, \nThe Tax Foundation, The Balance (real estate), KHN (public health), and \nThe Tax Policy Center (policy). These sources tend to feature prominently \nand exclusively within their niche topics, rather than being spread over \nmultiple issue-queries.\nThe presence of local news websites within our dataset can be character -\nized in similar terms to special interest websites with the difference that \nthe numbers of the former did not increase from the first period of analysis \nto the second. In this case, we could argue that Google\u2019s understanding \nof relevance values the geographic proximity of content producers to the \nissues in question, but that this quality is less valued than the expertise of \nmainstream news outlets. Local news sources are usually confined to the \nsecond page of results, and although high in number in terms of source \ndiversity, they have a low occurrence. The most prominent local news sites \nin both datasets are connected to large metropolitan areas, such as Los \nAngeles, Philadelphia, Miami or Chicago.\nTable\u00a02.8  C lassification of unique sources in search results.\nNational \nNewsLocal NewsSpecial InterestAcademic Platform Official Problematic Other\nFirst period 179 213 267 7 8 20 5 36\nSecond period 136 188 372 18 7 34 0 24\nda ta from go ogle.com.\n42 g uillen Torre S \nMethods\nWe implemented a simple source-distance methodology (Rogers, 2019) whose \nobjective is to locate the position of different types of sources within Google \nWeb Search results, in order to find which ones are privileged by the search \nengine by assigning them positions close to the top. This method is employed \nto answer the following research questions: How are problematic sources \npositioned within the first 20 Google.com results for queries concerning \nU.S. candidates and their most significant issues? And for election-related \nqueries, what are the predominant source types returned, and how may they \nbe characterized politically? We followed Caroline Jack\u2019s conceptualization \nof problematic information as \u201cinaccurate, misleading, inappropriately \nattributed, or altogether fabricated\u201d (2017: 1).\nThe queries were designed on the basis of a list of political issues, trian-\ngulated from the two political parties\u2019 platforms, individual candidate\u2019s \nplatforms, and three voter support services: Politico,2 VoteSmart3 and On \nthe Issues.4 The queries consisted of the following keywords: [candidate] \nAND [issue]. Donald Trump and Joe Biden were the candidates queried. The \nqueries do not strive to replicate the search behavior by Google users, but \nrather to test the type of information returned generically in the United \nStates by the search engine when querying political issues deemed relevant \nby voter support services.\nAlthough research has shown that personalization is low in Google\u2019s \nWeb Search (Haim et al.\u00a02017, Robertson et al., 2018b), we still sought to \nreduce the prospects of individual (but not geographical) personalization \nin our results by performing queries on a clean Firefox Extended Support \nRelease browser (with a fresh installation and with no prior use of any \nother Firefox version); Virtual Private Network (VPN) software was used \nto acquire a U.S. IP address. The queries were performed with the Search \nEngine Scraper (Search Engine Scraper, n.d.). Adjusting the parameters of the \ntool, we scraped the first 20 results provided by Google, in the U.S. region, for two different periods: February\u00a012, 2019\u2013March\u00a023, 2020 and March\u00a024, \n2020\u2013January\u00a05, 2021. While the first period captures the unofficial start of \nthe Trump campaign and up to the suspension of in-person rallies due to the \nCOVID pandemic, the second period captures the official pre-campaigns, the elections, and up to a few days before Joe Biden\u2019s inauguration. We set \n2 ht tps://www.politico.com/2020-election/candidates-views-on-the-issues/\n3 \nhttps://justfacts.votesmart.org/\n4 ht\ntps://www.ontheissues.org/Issues.htm\nProble MaTi c infor MaTi on in go ogle Web Search?  43\nthe number of results to 20 under the assumption that users tend not to look \nmuch further than that (Jansen and Spink, 2003; Dan and Davison, 2016). \nOur dataset consists of the results for searches of about 114 issues, each of \nwhich was queried two times (one for each candidate) on two different dates \n(March\u00a023, 2020 and January\u00a05, 2021). This \u201cone shot\u201d strategy introduces \nsome limitations to the study given the known variability in the composition \nof Google results through time. This variability can be connected with \nbreaking news (Curtois et al.\u00a02018), or updates to the algorithm. Although \nresults variability affects the position that each source holds in the results \npage (which would have been relevant for our second finding, had we found \nmore problematic information), it seems to affect less the composition of the \nresults in terms of source diversity. For example, in two studies conducted \nby Trielly and Diakopoulos (2019, 2020) source diversity seems to remain \nstable throughout the queries performed. Thus, our findings 1, 3 and 4 \ncould be considered indicative despite ours not being a longitudinal study conducted through daily queries.\nThe resulting list of 9,120 links was compared against an expert list of \nknown problematic sources, which was curated by fellow researchers, \nusing a combination of labeling sites, AllSides.com, Media Bias/Fact Check, \n\u201cthe Chart,\u201d and NewsGuard. Wikipedia and news mentions of potentially \nproblematic sources also were consulted. In the relatively few cases where \nsources had not been previously classified, two researchers independently \nclassified them, following the guidelines of the labeling sites. When unla -\nbeled sources reproduced the content created by larger outlets (as is the \ncase with most local news), the resulting label was the same as assigned \nto the parent outlet (e.g., CBS, ABC, NPR). In cases where no affiliate was \nexplicitly acknowledged (mostly local news editorial pieces), the coding \nattempted to locate politically laden opinions. If no bias was detected, the source was labeled as \u201cleast biased.\u201d\nTwo categorization schemes were devised, still following the existing \nlabeling sites\u2019 overall viewpoints. The first, \u201cample\u201d one, combines center-\nleft and left political orientations, on the one hand, and center-right and \nright, on the other. As a result, mainstream sites such as The Guardian  and \nThe New York Times were labeled \u201cliberal,\u201d while The Wall Street Journal  \nwas labeled \u201cconservative.\u201d The second, \u201cnarrow\u201d scheme makes a stricter division and only considers more explicitly liberal or conservative sources \nas either left or right, while most mainstream news outlets remain in the \ncenter. As a result, sites as The New York Times, The Guardian  and The Wall \nStreet Journal  switched categories to \u201ccenter\u201d and sites as The National Review  \nand The Washington Times were labeled as conservative. Furthermore, we \n44 g uillen Torre S \nalso labeled certain websites as \u201cspecial interest,\u201d \u201clocal news,\u201d \u201cofficial,\u201d \n\u201cacademic,\u201d \u201cplatform\u201d and \u201cother.\u201d Special interest, the broad category of \nsources whose content is mostly oriented towards one particular topic, \ninclude such professional associations and think tanks whose ultimate goal is \nto advocate for public policy (e.g., Americans for Tax Reform or the Center for \nImmigration Studies), as well as industry or community news sites focusing \non a particular audience (e.g., Transport News, Agripulse  or the National Low \nIncome Housing Coalition). We differentiated between local and national \nnews outlets, since even if the first sometimes reproduce the content of the \nlatter, we found considerable original local reporting and opinion columns \nin the results of our queries, prompting a further opportunity to classify \npartisanship. We considered as \u201cofficial sources\u201d those belonging to the U.S. \nfederal or local government, inter-governmental agencies, politicians in \noffice, or the official campaign websites of current and former candidates. \nAcademic sources are those connected to a university (e.g., the University \nof Pennsylvania\u2019s Budget Model), while the platforms encountered are \nWikipedia, Twitter, YouTube and Facebook. Finally, the category \u201cother\u201d \nincludes all sources that bore no direct relation to the other types.\nReferences\nAlba, D. (2020, June\u00a01). Misinformation about George Floyd protests surges on social \nmedia. The New York Times. https://www.nytimes.com/2020/06/01/technology/\ngeorge-floyd-misinformation-online.html.\nBail, C.A., Argyle, L.P., Brown, T. W., Bumpus, J.P., Chen, H., Hunzaker, M.B.F., \nLee, J., Mann, M., Merhout, F., and Volfovsky, A. (2018). Exposure to opposing \nviews on social media can increase political polarization. Proceedings of the \nNational Academy of Sciences , 115(37), pp.\u00a09216\u20139221. https://doi.org/10.1073/\npnas.1804840115.\nBoxell, L., Gentzkow, M., and Shapiro, J. (2017). Is the internet causing political \npolarization? Evidence from demographics. National Bureau of Economic \nResearch. http://www.nber.org/papers/w23258.\nBoxell, L., Gentzkow, M., and Shapiro, J. M. (2020). Cross-country trends in affective \npolarization. National Bureau of Economic Research. https://www.nber.org/\npapers/w26669.\nCourtois, C., Slechten, L., and Coenen, L. (2018). Challenging Google Search filter \nbubbles in social and political information: Disconforming evidence from a \ndigital methods case study. Telematics and Informatics , 35(7), pp.\u00a02006\u20132015. \nhttps://doi.org/10.1016/j.tele.2018.07.004.\nProble MaTi c infor MaTi on in go ogle Web Search?  45\nDan, O., and Davison, B. D. (2016). Measuring and predicting search engine users\u2019 sat -\nisfaction. ACM Computing Surveys , 49(1), pp.\u00a01\u201335. https://doi.org/10.1145/2893486.\nDiakopoulos, N., Trielli, D., Stark, J., and Mussenden, S. (2018). I Vote For\u2014How \nSearch Informs Our Choice of Candidate. In M. Moore and D. Tambini (Eds.), Digi -\ntal dominance: The power of Google, Amazon, Facebook and Apple (pp.\u00a0320\u2013341). \nOxford University Press.\nDigital Methods Initiative. (n.d.). Search Engine Scraper . https://wiki.digitalmethods.\nnet/Dmi/ToolSearchEngineScraper.\nGoogle. (2019a). How Google Fights Misinformation. Google Blog. https://www.\nblog.google/documents/37/How_Google_Fights_Disinformation.pdf.\nGoogle. (2019b). Search Quality Evaluator Guidelines. https://static.googleusercon -\ntent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.\npdf.\nHaim, M., Graefe, A., and Brosius, H.-B. (2018). Burst of the filter bubble?: Effects \nof personalization on the diversity of Google News. Digital Journalism , 6(3), \npp.\u00a0330\u2013343. https://doi.org/10.1080/21670811.2017.1338145.\nHassell, H. J. G., Holbein, J. B., and Miles, M. R. (2020). There is no liberal media bias \nin which news stories political journalists choose to cover. Science Advances , \n6(14), eaay9344. https://doi.org/10.1126/sciadv.aay9344.\nHeuts, F., and Mol, A. (2013). What is a good tomato? A case of valuing in practice. \nValuation Studies , 1(2), pp.\u00a0125\u2013146. https://doi.org/10.3384/vs.2001-5992.1312125.\nIntrona, L., and Wood, D. (2004). Picturing algorithmic surveillance: The politics \nof facial recognition systems. Surveillance & Society , 2(2/3), pp.\u00a0177\u2013198.\nJack, C. (2017). Lexicon of Lies. Terms for Problematic Information. Data & Society \nResearch Institute. https://datasociety.net/pubs/oh/DataAndSociety_Lexi -\nconofLies.pdf.\nJansen, B. J., and Spink, A. (2006). How are we searching the World Wide Web? A \ncomparison of nine search engine transaction logs. Information Processing & \nManagement , 42(1), pp.\u00a0248\u2013263. https://doi.org/10.1016/j.ipm.2004.10.007\nKelemen, M. (2005). Managing Quality: Managerial and Critical Perspectives . Sage. \nhttps://doi.org/10.4135/9781446220382.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nNoble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism . \nNew York University Press.\nOtero, V. (2017). The Chart. version 3.1. ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nRobertson, R. E., Lazer, D., and Wilson, C. (2018). Auditing the personalization and \ncomposition of politically related search engine results pages. Proceedings of the \n2018 World Wide Web Conference on World Wide Web \u2013 WWW \u201818 , pp.\u00a0955\u2013965. \nhttps://doi.org/10.1145/3178876.3186143.\n46 g uillen Torre S \nRogers, R. (2019). Doing digital methods . Sage.\nSunstein, C. R. (2018). #Republic: Divided democracy in the age of social media . \nPrinceton University Press. https://doi.org/10.2307/j.ctv8xnhtd.\nTrielli, D., and Diakopoulos, N. (2019). Search as news curator: The role of Google \nin shaping attention to news information. Proceedings of the 2019 CHI Con -\nference on Human Factors in Computing Systems \u2013 CHI \u201819 , 1\u201315. https://doi.\norg/10.1145/3290605.3300683\nUnkel, J., and Haim, M. (2019). Googling politics: Parties, sources, and issue owner -\nships on Google in the 2017 German federal election campaign. Social Science \nComputer Review , 39(5), pp.\u00a0844\u2013861. https://doi.org/10.1177/0894439319881634.\nWakabayashi, D. (2018, September\u00a05). Trump says Google is rigged, despite its \ndenials. What do we know about how it works? The New York Times . ht tps://\nwww.nytimes.com/2018/09/05/technology/google-trump-bias.html.\nData availability\nData available at: https://bit.ly/2Q10kCO\nAbout the author\nGuill\u00e9n Torres is a PhD researcher and Lecturer at the Department of Media \nStudies, University of Amsterdam. His research focuses on how datafica -\ntion may foster the political action of minoritized communities. Within \nthe Digital Methods initiative, Guill\u00e9n\u2019s work revolves around the role of \nplatforms in mediating access to information.\n3 T he scale of Facebook\u2019s problem \ndepends upon how \u201cfake news\u201d is \nclassified\nRichard Rogers1\nAbstract\nUshering in the contemporary \u201cfake news\u201d crisis, Craig Silverman of \nBuzzfeed News  reported that it outperformed mainstream news on \nFacebook prior to the 2016 U.S. presidential election. Here the report\u2019s \nmethods are revisited for 2020. Examining Facebook user engagement \nof election-related stories, and applying Silverman\u2019s classification of fake \nnews, it was found that the problem has worsened. If, however, one were \nto classify \u201cfake news\u201d in a stricter fashion, as Facebook and others do \nwith the notion of \u201cfalse news,\u201d the scale of the problem shrinks. A smaller \nscale problem could imply a greater role for fact-checkers, while a larger \none could lead to the further politicization of source adjudication, where \nlabeling certain sources as \u201cfake\u201d results in backlash.\nKeywords: Fake news, false news, junk news, hyperpartisan, media \nlabeling\nResearch questions\nTo what extent is \u201cfake news\u201d (as defined in the 2016 seminal news article) \npresent in the most engaged-with, election-related content on Facebook in \nthe run-up to the 2020 U.S. presidential elections? How does the current \n1 T he first period of the analysis was reported in Rogers, 2020a. The research benefited \nfrom research assistance by Paul Bugeja, Maria Lompe, Yumeng Luo, Rimmert Sijtsma, Tatiana \nSmirnova, Giulio Valentini, Ilian Velasco and Nina Welt.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch03\n48 r ichard rog erS \n\u201cfake news\u201d problem compare to that of the 2016 election period, both with \nthe same as well as a stricter definition of \u201cfake news\u201d? Is there more user \nengagement with hyperpartisan conservative or progressive sources in politi -\ncal spaces on Facebook? How does such engagement imply a politicization \nof the \u201cfake news\u201d problem?\nEssay summary\nIn all, it was found that the \u201cfake news\u201d problem around the U.S. elections \nas observed in 2016 has worsened overall on Facebook in 2020. While \u201cfake \nnews\u201d did not outperform mainstream news in any period under study (as \nit did in August to November of 2016) the proportion of user engagement \nwith \u201cfake news\u201d to mainstream news stories was higher compared to 2016. \nIn the seven full quarters under study in the run up to and aftermath of \nthe 2020 elections (from March\u00a02019 to December\u00a02020) the proportion of \nengagement of \u201cfake news\u201d to mainstream was on average 1:1.8 compared \nto 1:2.6 in 2016. It is both an observation concerning the persistence of the \nproblem and an admonition that the measures undertaken to date have \nnot lessened the phenomenon.\nIf one applies a stricter definition of \u201cfake news\u201d such as only imposter \nnews and conspiracy sites (thereby removing hyperpartisan sites as in \nSilverman\u2019s original definition), mainstream sources outperform \u201cfake\u201d \nones by a much greater proportion.\nThe findings imply that how one defines such information has an impact \non the perceived scale of the problem, including the types of approaches to \naddress it. With a smaller-scale problem, fact-checking and labeling become \nmore viable alongside the \u201cbig data\u201d custodial approaches employed by \nsocial media firms.\nGiven there are more hyperpartisan conservative sources engaged with \nthan hyperpartisan progressive ones, the research points to how considera -\ntions of what constitutes \u201cfake news\u201d may be politicized. Targeting \u201cfake \nnews\u201d presumably would affect hyperpartisan conservative sources to a \ngreater degree than progressive ones. It thereby could invite criticism of \u201cbig \ntech,\u201d including claims of censorship on one side of the political spectrum. \nIt also could prompt social media firms to become less open to critical \nscrutiny by scholars and journalists alike interested in which sources and \nstories are being degraded or deplatformed.\nThe findings are made on the basis of Facebook user engagement of the \ntop 200 stories returned for queries for candidates and social issues. Based on \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  49\nexisting labeling sites, the stories and by extension the sources are classified \nalong a spectrum from more to less problematic as well as partisan.\nImplications\nThe initial \u201cfake news\u201d crisis (Silverman, 2016; 2017) had to do with fly-by-\nnight, imposter, conspiracy as well as so-called \u201chyperpartisan\u201d news sources \noutperforming mainstream news on Facebook in the three months prior \nto the 2016 U.S. presidential elections. In a sense it was both a critique of \nFacebook as \u201chyperpartisan political-media machine\u201d (Herrman, 2016) but \nalso that of the quality of a social media landscape witnessing a precipitous \nrise in the consumption and sharing of \u201calternative right\u201d news and cultural \ncommentary (Benkler et al., 2017; Holt et al., 2019).\nThe events of the first crisis have been overtaken by a second one where \npoliticians as former President Trump in the U.S. and elsewhere employ \nthe same term for certain media organizations in order to undermine their \ncredibility. Against the backdrop of that politicization as well as rhetorical \ntactic, scholars and platforms alike have demurred on using the term \u201cfake \nnews\u201d and instead offered \u201cjunk news,\u201d \u201cproblematic information,\u201d \u201cfalse \nnews\u201d and others (Vosoughi et al., 2018). Some definitions (as junk news and \nproblematic information) are roomier, while others are stricter in their source \nclassification schemes. Subsumed under the original \u201cfake news\u201d definition \nare imposter news, conspiracy sources and hyperpartisan, defined as \u201coverly \nideological web operations\u201d (Herrman, 2016) or sources that \u201cexpressly \npromotes views\u201d (Otero, 2017). The newer term, \u201cjunk news,\u201d covers the same \ntypes of sources but adds the connotation of attractively packaged junk \nfood that when consumed could be considered unhealthy (Howard, 2020; \nVenturini, 2019). It also includes two web-native source types. \u201cClickbait\u201d \ncaptures how the manner in which it is packaged or formatted lures one \ninto consumption, and \u201ccomputational propaganda\u201d refers to dubious news \ncirculation by bot and troll-like means, artificially amplifying its symbolic \npower. Problematic information is even roomier, as it expands its field of \nvision beyond news to cultural commentary and satire (Jack, 2017). Stricter \ndefinitions such as \u201cfalse news\u201d would encompass imposter and conspiracy \nbut are less apt to include hyperpartisan news and cultural commentary, \ndiscussing those sources as \u201cmisleading\u201d rather than as \u201cfake\u201d or \u201cjunk\u201d or \nas not being \u201cnews\u201d in the first instance (Kist and Zantingh, 2017).\nRather than an either/or proposition, \u201cfake news\u201d could be understood as \na spectrum with problematic information (the roomiest notion) on one end \n50 r ichard rog erS \nand \u201cfalse news,\u201d the strictest, on the other, with junk news and fake news \nin the middle (Wardle, 2016; 2017). While beyond the scope, the purview \ncould be widened even further to include more media than stories and \nsources, such as video and images.\nDepending on the definition, the scale of the problem changes as does \nthe range of means to address it (Gillespie, 2020). With \u201cfalse news,\u201d it grows \nsmaller, and fact-checking again could be a profession to which to turn \nfor background research into the story and the source. Fact-checking\u2019s \neffectiveness is occasionally regarded as limited, given the enormity of the \ntask, the large reach of some fake news stories (well before fact-checks have \nappeared) and the number of fact-checks an organization can complete per \nday (Annany, 2018). Moreover, the audiences of \u201cfake news\u201d and fact-checked \n\u201cfake news\u201d also may differ significantly, meaning that corrections rarely \nreach the original consumers of the offending content (Bounegru et al., 2018). \nMore attention may be paid to the stories that have merited a fact-check or \na label, expanding their reach and engagement.\nFacebook\u2019s content moderation is multi-facetted, relying on human review, \nuser reporting and automated approaches (Roberts, 2016; Gillespie, 2018; \nFacebook, 2021b). Where their approach to misinformation is concerned, \nFacebook has striven to work with fact-checking bodies, though some of the \nfledgling partnerships ended after a year or two (Madrigal, 2019). For the \nremaining partner organizations, there is a Facebook dashboard, populated \nwith content flagged through crowd-sourcing and automated techniques, \nwhere the fact-checkers can choose articles and write their reports, from \ntwo to five per day per fact-checker (Annany, 2018). These reports result in \ncontent removal or downgrading. When the problem is scaled down, these \napproaches become more viable as do other qualitative approaches such as \nlabeling, with adjudicators sifting through posts one by one.\nRoomier definitions make the problem larger and result in findings such \nas the most well-known \u201cfake news\u201d story of 2016. \u201cPope Francis Shocks \nWorld, Endorses Donald Trump for President\u201d began as satire and was \nlater circulated on a hyperpartisan, fly-by-night site (Ending the Fed). It \ngarnered higher engagement rates on Facebook than more serious articles \nin the mainstream news. When such stories are counted as \u201cfake,\u201d \u201cjunk\u201d \nor \u201cproblematic,\u201d and the scale increases, industrial-style \u201cscalable\u201d solu -\ntions may be preferred such as automated review and commercial content \nmoderation (rather than journalist fact-checking).\nAs more content is taken down as a result of roomy source classification \nschemes, debates about freedom of choice may become more vociferous \nrather than less. It recalls the junk food debate, and in this regard, Zygmunt \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  51\nBauman stressed how we as homo eligens or \u201cchoosing animals\u201d are wont \nto resist such restrictions, be it in opting for \u201chyperprocessed\u201d food or \nhyperpartisan news and cultural commentary (2013).\nLabeling hyperpartisan news as \u201cfake\u201d or \u201cjunk,\u201d moreover, may lead to \ngreater political backlash. Indeed, as our findings imply, the \u201cfake news\u201d or \n\u201cjunk news\u201d problem is largely a hyperpartisan conservative source problem, \nwhereas the \u201cfalse news\u201d one is not. As recently witnessed in the Netherlands, \nthe designation of hyperpartisan conservative sources as \u201cjunk news\u201d drew \nthe ire of sources so labeled as well as the leader of a conservative political \nparty, who subsequently labeled mainstream news as \u201cjunk fake news\u201d \n(Rogers and Niederer, 2020; Van Den Berg, 2019). Opting for the narrower \n\u201cfalse news\u201d classification would imply a depoliticization of the problem.\nFinally, it should be remarked that the sources outputting questionable \ncontent in 2020 do not appear to be the fly-by-night, imposter news sites in \noperation in 2016, but rather more \u201cestablished\u201d conspiracy and hyperparti -\nsan sites. If Facebook, as its policy states (2021), were to degrade the posts in \nthe News Feed from at least the conspiracy sites, thereby affecting their reach \nand engagement, then the scale of \u201cfalse news\u201d problem may be reduced. \nThe circulation of hyperpartisan sources would remain, however, making \nthe platform still the site where the competition between mainstream and \n\u201cproblematic information,\u201d \u201cjunk news\u201d and \u201cfake news\u201d will remain.\nSource and story classification tensions remain. Certain sources may \nhave hyperpartisan commentary but run mainstream stories from wire \nservices. Hyperpartisan sources may gradually mainstream. Distinctions \nbetween the hyperpartisan and conspiracy may be difficult to disentangle. \nConspiracy theories may become more legitimate with time such as the lab \norigins of the coronavirus.\nFindings\nThis study revisits the initial \u201cfake news\u201d findings made by Craig Silverman \nof Buzzfeed News  in 2016, where it was found that in the three months prior \nto the 2016 U.S. presidential elections \u201cfake news\u201d stories received more \ninteractions on Facebook than mainstream stories (see Figure\u00a03.1). It ushered \nin the \u201cfake news\u201d crisis with Facebook at its center.\nFinding 1: If we employ the same definition of \u201cfake news\u201d as Silverman \ndid during 2016, to date the problem has worsened somewhat. Whereas 1 in \n2.6 \u201cfake news\u201d sources (on average per quarter) were most engaged-with in \nFebruary\u2013November\u00a02016, from March, 2019 to December, 2020 it is now 1 \n52 r ichard rog erS \nfi gure\u00a03.1 \u201c fa ke news\u201d outperforms mainstream news in the months prior to the 2016 u. S. \npresidential elections. Source: Silverman, 2016.\n \nfi gure\u00a03.2 fa cebook engagement scores of \u201cfake news\u201d (Silverman\u2019s roomy definition) versus \nmainstream news for political candidate and social issue queries overall, March\u00a024, 2019\u2013 de-\nce\nmber\u00a023, 2020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  53\nin 1.8 (see Figures 3.1 and 3.2). The main finding, in other words, is that the \n\u201cfake news problem\u201d of 2016 has not been remedied four years later.\nFinding 2: If, however, one tightens the definition of \u201cfake news\u201d sites \nto imposter and conspiracy sites (as the definition of \u201cfalse news\u201d would \nhave it), thereby removing hyperpartisan sources from the categorization \nscheme, the proportion of most engaged-with \u201cfake news\u201d to mainstream \nnews in March\u00a02019 to December\u00a02020 lessens to 1 in 12 (see Figure\u00a03.3). After \na spike in the run up to the elections, there is a general downward trend in \nthe engagement with such sites.\nNote that the 2016 problem also could be thought to diminish if one were \nto disaggregate Silverman\u2019s original source list and remove hyperpartisan \nstories and sites. An examination of his list per period in question indicates \nin the first two quarters (February through July\u00a02016) most sources are \nhyperpartisan and satirical (Silverman, 2016). Only in the period between \nSeptember and the election do we find imposter sites. A case in point is the \nDenver Guardian (which is no longer online); as the Denver Post  wrote, \u201c[t]\nhere is no such thing as the Denver Guardian, despite that Facebook post \nyou saw\u201d (Lubbers, 2016). Imposter sites, however, are in the minority and \nmost engagement is driven by the hyperpartisan and the satirical such \nas Ending the Fed, Breitbart News and the World News Daily Report. In \nother words, their removal from the \u201cfake news\u201d classification would put \nmainstream news back on top.ProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\noverall\n0\n200,000,000\n400,000,000\n600,000,000\n800,000,000\n1,000,000,000\n1,200,000,000\n1,400,000,000\n1,600,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7engagement\ntimeQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.3 fa cebook engagement scores of \u201cfake news\u201d (narrow definition) versus mainstream \nnews for political candidate and social issue queries overall, March\u00a024, 2019\u2013 de\ncember\u00a023, 2020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n54 r ichard rog erS \nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.4 fa cebook engagement scores of \u201cfake news\u201d (Silverman\u2019s original roomy definition) \nversus mainstream news for political candidate and social issue queries, March\u00a02019\u2013 de\ncem-\nber\u00a02020. \nab\nsolute numbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  55\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\n56 r ichard rog erS \nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.5 fa cebook engagement scores of \u201cfake news\u201d (narrow definition) versus mainstream \nnews for political candidate and social issue queries, March\u00a02019\u2013 de\ncember\u00a02020. \nab\nsolute \nnumbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  57\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\n58 r ichard rog erS \nFinding 3: There are certain issues where more alternative sources provide \nthe coverage that was consumed (see Figure\u00a03.4), but, with the strict defini -\ntion, in no case did they (consistently) outperform mainstream sources (see \nFigure\u00a03.5). If we return to the original \u201cfake news\u201d definition (that includes \nhyperpartisan sites), alternative sources outperform mainstream ones (either \noverall or in certain weeks) for certain divisive issues such as abortion, death \npenalty, gun control, social security as well as the issue of fake news itself \n(see Figure\u00a03.4). There is also one issue (social security) where there is more \nengagement with \u201cfake news\u201d in the narrow sense than with mainstream \nnews (see Figure\u00a03.5), but overall the mainstream outperforms fake news \nin a narrow sense across most all issues and periods. With respect to the \ncandidates, Biden has proportionately more \u201cfake news\u201d (and \u201cfalse news\u201d) \nassociated with it than Trump, though Trump has a higher quantity overall. \nThe most engaged-with \u201cfake news\u201d story (PJ Media) relates to Trump and \nreads \u201cmilitary ballots found in the trash in Pennsylvania all were Trump votes.\u201d\nFinding 4: There is more engagement with hyperpartisan conservative \nsources than hyperpartisan progressive ones both overall as well as for \nthe majority of the candidates and issues (see Figures 3.6 and 3.7). The \nfinding suggests that any \u201cfake news\u201d definition that includes hyperpartisan \nsources will associate the problem more with conservative sources. When \nadjusting the definition to exclude such sources, \u201cfake news\u201d itself becomes \nless politicized.(hyper)partisan progressive(hyper)partisan conservativeFacebook engagement \nover time\noverall\n0\n200,000,000\n400,000,000\n600,000,000\n800,000,000\n1,000,000,000\n1,200,000,000\n1,400,000,000\n1,600,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7engagement\ntimeQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.6 fa cebook engagement scores of hyperpartisan conservative and hyperpartisan \nprogressive sources for political candidate and social issue queries, overall, March\u00a02019\u2013 de\ncem-\nber\u00a02020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  59\nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nfi gure\u00a03.7 fa cebook engagement scores of hyperpartisan conservative and hyperpartisan \nprogressive sources for political candidate and social issue queries, March\u00a02019\u2013 de\ncember\u00a02020. \nab\nsolute numbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic \nby \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n60 r ichard rog erS \nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  61\nMethods\nThis study builds upon the \u201cfake news\u201d report written by Craig Silverman \nand published in Buzzfeed News  in 2016. It employs a similar methodology, \nalbeit introducing a \u201cslider\u201d or gradient to indicate the extent of the problem \ndepending on how one classifies sources. The research enquires into the \ncurrent scale of the problem and compares it to the same timeframe in \n2016. It also demonstrates how roomier definitions of \u201cfake news\u201d make the \nproblem appear larger, compared to stricter definitions.\nFirst, a list of candidates and social issues is curated. The candidates \nchosen are the ones from the major parties, still in the race and campaigning \nat the time of the study. For social issues, the issue lists at four voting aid \nsources are first merged, and then filtered for those that appear on multiple \nlists: Politico, VoteSmart, On the Issues and Gallup (see Table\u00a03.1).\nTable\u00a03.1   T he list of candidates and issues queried in BuzzSumo.com in \nMarch\u00a02020 and January\u00a02021.\nTrump ca rbon emissions gun  control Private prisons\nbid\nen ch\narter schools healt\nh insurance Securing 5 g\nS\nanders cli\nmate change i\nmmigration Social security\nab\nortion co\nronavirus inf\nrastructure Student debt\naff\nordable housing da\nca M\nedicare Teacher pay\nas\nsault weapons dea\nth penalty Minimum wage Veterans\nba\nckground checks el\nection security oi\nl and gas drilling Wealth taxes\ncamp\naign financing fa\nke news Paid leave\nNext, we queried Buzzsumo, the marketing research and analysis tool, for \neach candidate and issue keyword, using the date ranges of March\u00a023, 2019 to \nMarch\u00a023, 2020 and March\u00a024, 2020 to January\u00a04, 2021, and the filter \u201cEnglish.\u201d \n(We limited our analysis to the end date, December\u00a023, 2020, thereby covering \nseven three-month periods.) We also retained non-American sources, in order \nto ensure that we did not miss highly engaging, problematic sources that are \nfrom outside the U.S. Buzzsumo returns a list of web URLs, ranked by interac -\ntions, which is the sum of reactions (including likes), shares and comments. \nThe study of engagement (or interactions) concerns a combination of rating \n(like), reading (comment) and circulating (share). In that sense, it is a rather \ncomprehensive measure. For every candidate and issue, we examined only \nthe top 200 stories returned, which is a limitation. Analyzing Facebook user \nengagement of \u201ctop\u201d content follows Silverman\u2019s original method. Silverman\u2019s \nincluded top 20 sources, whereas \u201ctop\u201d content is greater by a factor of 10.\n62 r ichard rog erS \nEach of the source names, headlines and any description text are read, \nand the sources are roughly labeled by concatenating pre-existing source \nclassification schemes (or when in disagreement choosing the majority label). \nTo gain an indication of their genre (non-problematic or problematic news \nincluding imposter news, conspiracy site, or clickbait) and (hyper)partisan-\nship, the sources are checked against media bias labeling sites including \nAllSides (2020), Media Bias/Fact Check (2020), \u201cThe Chart\u201d (Otero, 2017) and \nNewsGuard (2020); news sources\u2019 Wikipedia entries are also consulted. We \nalso searched for them online and consulted news and analysis that mention \nthe sources. Additionally, we checked the source lists returned by Buzzsumo \nagainst a study of imposter sources called \u201cpink slime sites,\u201d or sites that \nimitate local or national news sites (Bengani, 2019). Throughout the entire \nperiod and across all issues in the top 200 most engaged-with stories just \none pink slime site was found.\nSubsequently, we characterized the stories as problematic or non-\nproblematic, where the former adheres to the strict \u201cfalse news\u201d definition \n(imposter or conspiracy sites). These are then graphed overtime using RAW \ngraphs. We also applied the roomier definitions of \u201cfake news,\u201d which adds \nto imposter and conspiracy sites \u201chyperpartisan\u201d sources. We graphed these \nvalues anew. These graphs display the proportion of \u201cfake news\u201d versus \nnon-problematic sources in Facebook for the results of each candidate \nand social issue query over the election campaigning timeframe and its \naftermath, March\u00a02019 to December\u00a02020.\nWe then compared the 2020 findings with the 2016 results, in two ways. \nFirst, we compared the 2020 results with the roomier definition (imposter \n+ conspiracy + hyperpartisan) to the \u201cfake news\u201d findings of 2016 as propor -\ntions, finding that in 2019\u20132020, on average per quarter, there are 1 in 1.8 \nsources that are \u201cfake\u201d compared to 1 in 2.6 in 2016. Thus, the \u201coriginal\u201d \u201cfake \nnews problem\u201d has worsened. Second, we examined the source list from \nFebruary to November\u00a02016 in order to ascertain whether the findings were \nbased on a strict or roomy definition for that timeframe. Early in the 2016 \ncampaign, those sources were largely hyperpartisan or satirical, but the \nbest-performing story by far was from a reputable source that mistakenly \npublished a \u201cfake story,\u201d originating from a tweet by Sean Hannity of Fox \nNews  that the then candidate Trump had used his own private plane to \ntransport \u201c200 stranded marines\u201d (American Military News, 2016). Right \nbefore the 2016 election (August to November), the best-performing sources \nwere again hyperpartisan or satirical ones (as Ending the Fed, Breitbart and \nWorld News Daily Report), though imposter sites also make an appearance \n(Denver Guardian). For a sense of how definitions of fake news politicize, \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  63\nwe also examined which candidates were associated with hyperpartisan \nnews, noting how Biden is targeted far more often in such sources.\nTo study the politicization of the \u201cfake news\u201d problem further, we com -\npared the overall engagement on Facebook of hyperpartisan sources, both \nconservative and progressive, as well as the candidates and issues that \nhad each type most associated with it, finding that conservative, so-called \nhyperpartisan sources outperformed hyperpartisan progressive ones.\nReferences\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nAmerican Military News (2016, May\u00a023). Article removed\u2014Here\u2019s why. \nAmerican Military News , https://americanmilitarynews.com/2016/05/\ndonald-trump-sent-his-own-plane-to-transport-200-stranded-marines/.\nAnnany, M. (2018, April\u00a04). The partnership press: Lessons for platform-publisher \ncollaborations as Facebook and news outlets team to fight misinformation. Co -\nlumbia Journalism Review . https://www.cjr.org/tow_center_reports/partnership-\npress-facebook-news-outlets-team-fight-misinformation.php.\nBauman, Z. (2013). Does the richness of the few benefit us all? Polity.\nBengani, P. (2019, December\u00a018). Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points. Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y., Faris, R., Roberts, H. and Zuckerman, E. (2017, March\u00a03). Study: Breitbart-led \nright-wing media ecosystem altered broader media agenda. Columbia Journalism \nReview . https:/ /www.cjr.org/analysis/breitbart-media-trump-harvard-study.php.\nBounegru, L., Gray, J., Venturini, T. and Mauri, M. (2018). A field guide to \u201cfake news\u201d \nand other information disorders . Public Data Lab.\nFacebook (2021b, May\u00a025). False news, Facebook Transparency Center. https://\ntransparency.fb.com/policies/community-standards/false-news/.\nHerrman, J. (2016, August\u00a024). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHolt, K., Figenschou, T.U. and Frischlich, L. (2019). Key dimensions of alternative \nnews media. Digital Journalism , 7(7), pp.\u00a0860\u2013869. https://doi.org/10.1080/2167\n0811.2019.1625715\n64 r ichard rog erS \nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nGillespie, T. (2020). Content moderation, AI, and the question of scale. Big Data & \nSociety , July\u2013December: 1\u20135, https://doi.org/10.1177/2053951720943234.\nHoward, P. (2020). Lie machines . Yale University Press.\nJack, C. (2017) Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\nKist, R. and Zantingh, P. (2017, March\u00a06). Geen grote rol nepnieuws in aanloop \nnaar verkiezingen. NRC Handelsblad . https://www.nrc.nl/nieuws/2017/03/06/\nfake-news-nee-zo-erg-is-het-hier-niet-7144615-a1549050.\nLubbers, E. (2016, November\u00a05). There is no such thing as the Denver Guardian, \ndespite that Facebook post you saw. The Denver Post . https://www.denverpost.\ncom/2016/11/05/there-is-no-such-thing-as-the-denver-guardian/.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nOtero, V. (2017). The chart, version 3.1, ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nRoberts, S.T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S.U. Noble and B.M. Tynes (Eds.), The intersectional internet: Race, sex, class \nand culture online (pp.\u00a0147\u2013160). Peter Lang.\nRogers, R. and Niederer, S. (Eds.) (2020). The politics of social media manipulation . \nAmsterdam University Press.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake \nelection news stories outperformed real news on Facebook, Buzz -\nfeed News .  https://www.buzzfeednews.com/article/craigsilverman/\nviral-fake-election-news-outperformed-real-news-on-facebook.\nWardle, C. (2016, November\u00a018). 6 types of misinformation circulated this election \nseason. Columbia Journalism Review . https://www.cjr.org/tow_center/6_types_\nelection_fake_news.php.\nWardle, C. (2017, February\u00a016). Fake news. It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nVan Den Berg, E. (2019, July\u00a030). Opnieuw misser bij Forum voor Democratie: Per -\nsoonlijke advertentie Thierry Baudet offline gehaald. NPO3. https://www.npo3.\nnl/brandpuntplus/opnieuw-misser-bij-forum-voor-democratie-persoonlijke-\nadvertentie-thierry-baudet-offline-gehaald.\nVenturini, T. (2019) From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin, and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights \n(pp.\u00a0123\u2013144). Routledge.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  65\nData availability\nhttps://doi.org/10.7910/DVN/VFMJUH\nAbout the author\nRichard Rogers , PhD, is Professor of New Media & Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods \nInitiative. He is author of Information Politics on the Web and Digital Methods  \n(both MIT Press) and Doing Digital Methods (SAGE).\n\n4 W hen misinformation migrates\nCross-platform posting, YouTube and the deep vernacular \nweb\nAnthony Glyn Burton1\nAbstract\nThis chapter investigates the political information ecologies of the \n\u201cdeep vernacular web\u201d by studying the cross-posting of links on 4chan\u2019s \n\u201cpolitically incorrect\u201d board and a host of political subreddits. It finds \nthat Reddit\u2019s banning of political subreddits in June\u00a02020 proved effec -\ntive in culling the spread of misinformation. 4chan users turned from \nsharing propagandistic content towards conspiratorial links as the \n2020 U.S. election approached. This turn towards conspiracy parallels \nthe decline in popularity of alt-right punditry on both platforms, \nreflected in the shift in presence over time of these types of videos. \nThe chapter offers an example of how URLs and YouTube links can \nbe used as a cross-platform digital method in studying the spread of \nmisinformation.\nKeywords: 4chan, Reddit, misinformation, digital methods, YouTube\nResearch questions\nTo what extent do U.S.-based political boards and forums on 4chan and Red -\ndit share misinformation and \u201cjunk\u201d content? Are algorithmically generated \nimposter news websites among the misinformation that circulates? How \ncan we quantify and qualify the degree to which \u201calternative influence \n1 Pa rts of this chapter are drawn from Burton and Koehorst, 2020. The research team included \nDmitri Koehorst and Martijn van Schjip, who aided in the first round of research, and Yentel \nBoot, Frederikke Christiansen, David Dijkhuis, Morris Nieuwenhuis, and Alejandra O\u2019Connor, \nwho aided in the second round.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023doi: 10.5117/9789463720762_ch04\n68 anTh ony gl yn bu rTon  \nnetworks\u201d proliferate on these sites? How might we characterize the shift \nin the information ecologies of these spaces around the time of the 2020 \nU.S. election?\nEssay summary\nThis chapter takes up these questions through a quantitative analysis of the \nnews links shared on the spaces of the subcultural political web. It details \nthe results of two separate studies. The first dataset covers the beginning \nof the 2020 presidential primaries, while the second period the lead-up and \nfollow-through of the November\u00a03, 2020 election. We employed a variety \nof methods to tackle these questions, of which the \u201chaystack-to-needle\u201d \ndeductive method pioneered by Hagen and Jokubauskaite (2019) produced \nthe best results in investigating the texture of informational websites \nshared.\nConstructing a coding schema based on Benkler et al.\u2019s work studying the \n2016 U.S. election, we first investigated the presence of \u201cjunk\u201d news on each \nplatform, which Howard et al. define as content \u201cextremist, sensationalist, \nconspiratorial, masked commentary, [or] fake\u201d that presents itself as news \n(Howard et al.\u00a02017; see also Gray et al., 2019). The presence of junk news \non each platform remained relatively stable, comprising approximately a \nthird of sources on 4chan and a fifth on Reddit.\nWe then investigated those sources coded as news proper and as well as \nfor partisanship using a variety of expert sources. We find that while the \nfirst collection period was characterized by a plurality of websites coded \nas neutral news, the period leading up to and through the election marks \na shift towards partisanship in the news ecologies of both spaces.\nFinding YouTube as an outsized source in both spaces\u2014in both time -\nframes making up a higher share of links on 4chan than all other sites \ncombined, and a stark presence on Reddit\u2014we focus further on the types of \nvideos that characterize each platform\u2019s YouTube shares. While the network \nof right-wing pundits that make up what Lewis (2018) dubs the \u201calternative \ninfluence network\u201d constituted a strong presence in the first dataset, their \npopularity in the lead-up to the election dramatically wanes\u2014replaced by \nvideo clips that purport to illustrate the very theories that the AIN traffics \nin, and illustrating a potential abandonment of the mediated, parasocial \nrelationships that make up the AIN\u2019s appeal (Lewis, 2020). Methodologically \nspeaking, this chapter\u2019s cross-platform methods\u2014using hyperlinks as \nWhen MiSi nfor MaTi on M igra Te S 69\nmetaphors for interest as opposed to tracking infrastructural syntaxes \nspecific to particular platforms\u2014offers a further potential avenue for study \nin the face of deplatforming and the migration of user audiences across \nplatforms (Rogers, 2020b).\nImplications\nThe accelerated informational exchange and ease of publication afforded \nby social media took on a dystopic turn during the 2016 U.S. election, \nwhere coordinated campaigns to manipulate information ecologies on \nmainstream social media platforms like Twitter sounded an epistemic \nalarm and added \u201cmisinformation\u201d to the cultural lexicon (Shao et al., 2018). \nBut as platforms strengthen their harmful content policies in response \nto criticism for harboring misinformation and hate speech, especially \nafter the election (Einwiller and Kim, 2020; Donovan and boyd, 2018), \nwe began to see alternative spaces such as the relatively unmoderated \nand historically uncensored subcultural political web found on spaces \nlike Reddit and 4chan as primary hubs for the spread of misinformation \n(Coppins, 2020). The lack of oversight in these spaces marks a continuation \nof what Starbird et al. refer to as the \u201cecho-systems\u201d that characterized \nthe spread of misinformation in 2016, wherein particular news sources \nare amplified within a discursive space and iteratively gain volume and \nattention (2018). And while Reddit banned a number of subreddits in \nJune\u00a02020 for violating their hate speech policy\u2014including the notori-\nous alt-right subreddit \u201cr/The_Donald\u201d (included in our dataset)\u2014the \npseudonymous nature, sheer scale, and ideological underpinnings of these \nplatforms set up a \u201cpropaganda pipeline\u201d where misinformation and its \ncorrelates gain vivacity (Benkler et al., 2019). These subcultural political \nplatforms make up what Tuters calls the \u201cdeep vernacular web\u201d (2019), \ncharacterized by pseudonymous participation and its antecedent trolling, \nplayfulness, and dreams of unfettered freedom of speech (Massanari, \n2017; Coleman, 2012; Buyukozturk et al., 2018), and are thus important \nplayers in contemporary news ecologies. But to characterize every user of \nthese spaces as a part of this propaganda pipeline would be too general. \nWhat does news circulation on these spaces look like? How are common \nnarratives and shared realities drawn in these spaces? And what might \nbe different about their conceptions of information, political punditry, \nand mediated verification?\n70 anTh ony gl yn bu rTon  \nFindings: News ecologies, compared\nIncreasing junk news as the election drew near\nWe observed that \u201cjunk news\u201d aesthetically or through the adoption of tech -\nniques masquerading as news websites either pushed conspiracy theories \nor presented content with the aims of sensationalizing or propagandizing. \nOn 4chan, the presence of junk news remained relatively stable across our \ndatasets, with 32% of links posted falling under the category in the first \ntime period and 31% of websites in the second time period. On the other \nhand, the stark shift in the presence of junk news on Reddit between our \nfirst and second datasets points to the fact that Reddit\u2019s banning of starkly \npolitical subreddits may have played a role in the information ecologies of \nthe site: while 17% of links shared fell under the category of junk news in \nour first dataset, it fell to about 4% in the second dataset, with propaganda \nmaking up little over 1% of links, sensationalist media counting 3%, and \nconspiracy a paltry 0.5%.\nThe types of junk news that appear on each website provide us with fur -\nther insight on changes that occurred as the election approached, especially \non 4chan. While propaganda was in relative abundance in the initial data \ncollection period\u2014with 20.2% of total links falling under the category, \ncompared to 10.7% as sensationalist and 1.2% as conspiratorial\u2014the lead-up \nto the election saw propaganda junk news fall by almost half, to 10.4% of \ntotal news links posted. Sensationalist news decreased slightly to 6.9%. \nMost notably, 14.4% of links in our second dataset were categorized as \nconspiratorial. This is an increase by a factor of 14. And while it is still \noutranked by the first dataset\u2019s number of propagandistic links, the increase \nin conspiracy as the election approached signals a dramatic shift.\nIncreasing partisanship as the election drew near\nCompared to junk news, websites which appeared to follow journalistic \nstandards made up the majority of links in both datasets. The changes over \ntime, however, are notable: while both Reddit and 4chan hovered around \n60% of all links being to news websites in the first data collection period, \nnews links on 4chan slightly lowered to 58% on the second run while Reddit\u2019s \nnumber increased by almost a third to 83%. But what appears on the surface \nas a relatively stable and socially endorsed informational ecology belies the \npartisan shift that occurred as the election approached.\nWhen MiSi nfor MaTi on M igra Te S 71\nIn the first dataset, Reddit\u2019s news sources contained a plurality of neutral \nsources\u201448% of all websites, and 57.8% of all websites coded as \u201cnews.\u201d \nLeft-leaning sources made up 24.8% of all links, while right-leaning sources \nmade up 9.9% of news links. The second dataset saw a marked shift in the \npolitical valence of hostnames, however. In this period, left-leaning websites \nmade up a plurality of the links, with 42.0% of links posted being categorized \nas such. Much of this gain was at the loss of neutral links, which numbered \n21.1% of all total news links; meanwhile, the number of right-leaning links \ndecreased to 3.9% of all news links.\nThe shift towards partisanship (according to our coding) was starker on \n4chan. In the first dataset, news websites categorized as neutral made up \n46.4% of the total information websites posted, while right-leaning websites \nmade up 12.3% of links and left-leaning websites just 4.1%. In the run-up \nto the election, however, the amount of neutral websites that appeared \ndecreased by more than half, comprising just 17.5% of total news-coded \nlinks. This decrease was counterbalanced by a tripling of both left- and \nright-leaning links. Left-leaning links appeared 15.9% of the time in the \nsecond dataset, while right-leaning links made up over a third of all news links, appearing 35.0% of the time.\nVideo ecologies: Categories versus our own coding\nOn both 4chan\u2019s /pol/ and in the political subreddits, video plays an \nimportant part in collective information habits. In both datasets, links \nto YouTube on 4chan were higher than all other links combined; on Red -\ndit, YouTube was the top-linked website. In the first run-through of the \ndataset, we focused on studying the videos posted by using YouTube\u2019s \nown categories to characterize videos. \u201cNews & Politics\u201d made up the \nmajority of links shared on both websites, with \u201cPeople & Blogs\u201d being the \nsecond highest. \u201cNews & Politics\u201d contains political content, news clips, \nbroadcasts, and other related content, while the purview of \u201cPeople & \nBlogs\u201d is slightly larger, containing talk shows, interviews, video casts of \npodcast recordings, and vlogs. Despite these core similarities, \u201cEducation\u201d \nand \u201cNonprofits and Activism\u201d made up the third- and fourth-highest \ncategories in the Reddit data, while \u201cEntertainment\u201d and \u201cMusic\u201d made \nup the third- and fourth-largest categories on 4chan. Given the lack of \ngranularity of these categories we performed our own coding for the \nsecond dataset, applied to YouTube links on both 4chan and Reddit, \ndetailed in Table\u00a04.1.\n72 anTh ony gl yn bu rTon  \nTable\u00a04.1  C oding scheme of Y ouTube videos.\nVideo type Definition\ncl\nip Short, standalone clip without context\nShitposting de\nliberately low-quality content that provokes attention and disrupts \ndiscursive exchange \nco\nlley and Moore 2020, 22)\ndi\nscussion co\nnversation or debate surrounding a particular issue\nPress \nco\nnference Videos of partial or full press conferences held by officials\ninte\nrview i\nnterviews between individuals\nre\nportage re\nporting of an event by press or individuals\nl\nivestream The live filming and transmission of an event\ncom\npilation an e\ndited collection of videos, clips, reporting, etc.\ncamp\naign Video Videos created by political consultants or staff with a direct promo-\ntional purpose\nMeme Videos of a typically humorous nature with viral qualities\naud\niobook a\n video containing a narrativized recording of a book\noth\ner an\ny content that does not fit in the above categories\nOn 4chan a significant number of videos shared were categorized as \nshitposting, followed by discussion and clip (see Table\u00a04.2). On Reddit, \nthe top categories differed, with audiobooks, discussions, and inter -\nviews making up the top three. There was likewise a much higher level \nof homogeneity among videos shared on Reddit: only five of the twelve \ncategories appeared on Reddit, while 4chan\u2019s shared videos ran across \nthe different types.\nTable\u00a04.2  Y ouTube video types per platform (Reddit and 4chan).\nVideo type Reddit appearances 4chan appearances\ncl\nip 17.0 4% 30.81%\nShitposting 0% 18.23%\ndi\nscussion 22.69% 12.88%\nPress \nco\nnference 0% 5.93%\ninte\nrview 26.2% 2.77%\nre\nportage 24% 8.36%\nl\nivestream 0% 2.21%\ncom\npilation 0% 10.02%\ncamp\naign Video 0% 5.37%\nMeme 0% 2.12%\naud\niobook 10.07% 0%\noth\ner 0% 1.31%\nWhen MiSi nfor MaTi on M igra Te S 73\nThe decline of the alternative influence network\nWhile these categories were not used in the first round of data collection, \nqualitative observation of the data indicates that the type of videos shared \nshifted strongly over two datasets: the direct viewer address of alt-right \npolitical punditry gave way to a documentarian form of video clip, usually \ntaken out of its overall context, designed to act as \u201cunmediated\u201d footage \nof depicted events. At the beginning of the election period, videos from a \ngroup of alt-right pundits that Rebecca Lewis calls the \u201calternative influence \nnetwork\u201d constituted these spaces\u2019 video culture. The AIN is a group of \nloosely associated pundits that form a sort of \u201cnetwork,\u201d in Lewis\u2019s terminol -\nogy, by appearing on each other\u2019s YouTube channels and repeating talking \npoints brought up by websites such as Breitbart and the Daily Caller. The \ncast of characters on this network differentiate themselves by peddling \ntheir own particular brands of misinformative and conspiratorial content \nthat ideologically speaking ranges from the Trumpian Republican party \nline to neo-Nazism. AIN member Richard Spencer regularly propagandizes \nfor a white ethnostate (Kaplan, 2017); Paul Joseph Watson of Prison Planet \npushes the conspiracy that 9/11 was a covert government operation (Hines, \n2018); Jordan Peterson shot to fame by claiming a Canadian government bill \nintroducing gender identity as grounds for discrimination was an example \nof creeping \u201cpost-modern radical leftism\u201d (Peterson, 2016). The AIN could be \ndescribed as reactionary politics pivoting to video: by explicitly positioning \nthemselves as alternatives to legacy and mainstream news outlets, members \ncan adopt the techniques of social media influencers to \u201cbuild audiences \nand \u2018sell\u2019 them on far-right ideology\u201d (Lewis, 2018, p.\u00a04).\nIn the earlier dataset, these links made up 596 of the total YouTube links \nshared on 4chan, and 3989 of the links shared on Reddit. The second dataset \npaints a different picture of the video cultures of the deep vernacular web: \nthe AIN made an appearance on 4chan just 337 times, for a 42.5% reduction, \nwhile Reddit users shared videos from the AIN just 458 times, a reduction \nof 88.6%. The Reddit numbers are likewise boosted by 378 shares of a video \nby Mike Cernovich titled \u201cUn/Convention: Exposing Fake News at the RNC \nand DNC\u201d (2016). The second-most popular AIN members\u2014Ben Shapiro\u2019s \n\u201cDaily Wire,\u201d Rick Rubin\u2019s \u201cRubin Report,\u201d and Tim Pool\u2014were only shared \n15 times apiece.\nOne possible explanation is that a combination of deplatforming and \nsubreddit banning could explain their decline, but it does not bear out. The \nmost popular AIN figures on 4chan and Reddit in the earlier dataset, Joe Ro -\ngan and Ben Shapiro (\u201cPowerfulJRE\u201d and \u201cThe Daily Wire,\u201d in channel-name \n74 anTh ony gl yn bu rTon  \nterms), remain on YouTube, as do 4chan\u2019s two favorites, Sargon of Akkad and \nTarl Warwick (\u201cThe Thinkery\u201d and \u201cStyxhexenhammer666,\u201d respectively). \nAnd while Reddit banned a significant number of subreddits between the \nfirst and second data collection periods, as detailed above, this would have \nno bearing on 4chan\u2019s sharing numbers, which show a decline in viewing \nby nearly half.\nAlternative or mainstream influence network?\nFrom the purview of the subcultural spaces under study, the AIN\u2019s desig -\nnation as alternative could be revisited. Put differently, they could have \nmainstreamed or normified, in the sense that all the figures above as well \nas many others in the AIN still enjoy robust followings and high YouTube \nsubscriber counts outside of the subcultural spaces discussed here. Yet \nthe video consumption tastes of their original fans seem to have shifted. \nInstead of pointing to AIN pundit commentaries on political clips, they point \nincreasingly to clips discussed by lesser-known YouTube accounts. Three of \nthe top five shared YouTube videos on 4chan in the second dataset fall under \nthis category, and all are documentary-style recordings recontextualized \nto articulate a particular political or empirical theory by non-AINs. One \n\u201cAmy Adams\u201d has two of the top shared videos. The first is a 35-second \nundated clip of Joe Biden, posted in 2016, titled \u201cSHOCKING: Joe Biden \ndiscusses the left\u2019s globalist agenda\u201d (Adams 2016). The other is \u201cKRAKEN \nUNLEASHED: The press conference they don\u2019t want you to see\u2026\u201d (2020). \nAnother is a 70-second clip from 2017 titled \u201cSenator Schumer says God \nmade him a guardian of Israel,\u201d posted by the user \u201cIf Americans Knew,\u201d who \ndescribe themselves on their biography page as \u201can independent research \nand information dissemination institute, with particular focus on the \nIsraeli-Palestinian conflict, U.S. foreign policy regarding the Middle East, \nand media coverage of this issue. Specifically, the organization\u2019s objective is to provide information that is to a large degree missing from American press coverage of this critical region\u201d (2017).\nMigrating misinformation\nTwo observations may be made from a comparison of these two periods. \nWhen it comes to \u201ccleaning up\u201d the junk news strewn about on a platform, \neliminating spaces\u2014not necessarily users, which would be considered \ndeplatforming and is another discussion (see, e.g., Rogers, 2020; de Keule -\nnaar and Burton, 2021; Urman and Katz, 2020)\u2014may lead to precipitous \nWhen MiSi nfor MaTi on M igra Te S 75\nreductions. Reddit\u2019s banning of politically charged subreddits, especially the \nnotorious r/the_Donald, coincided with a steep decline in dubious content \non Reddit. The amounts also dwarf those in comparison with 4chan. If we \nthink of the changes in 4chan data as a rough way to normalize the Reddit \nchanges, the fact that only 4% of links were categorized as junk news at all \n(let alone a particular type of junk news) while the amount of junk news on \n4chan remained relatively stable lends credence to arguments concerning \nthe effectiveness of such actions.\nAs was found in a previous study of subreddit closures, users of r/the_Don -\nald are not known to have migrated en masse to any other particular subred -\ndit but rather moving to the group of independent \u201c.win\u201d platforms (Goforth, \n2021). While the \u201c.win\u201d platforms were outside the scope of this study, it\u2019s \nalso possible that some of the purged users from Reddit made their way to \n4chan/pol/ after June\u00a02020. It could explain the rise of conspiratorial content \non 4chan in the run-up to the election: not necessarily a shift in existing \nuser sentiment, but a migration of users themselves. It is worthy of further \ninvestigation given how that subreddit and /pol/ have been credited with \nan outsize influence on the spread of political misinformation (Blackburn, \n2018; Zanettou et al., 2017).\nThe second notable observation in the dataset is the decline in popularity \nof the alternative influence network in these spaces, paralleled on 4chan \nby the rise in conspiratorial \u201cfound footage,\u201d documentary-style clips. Out \nof the videos shared over 100 times on 4chan in the run-up to the election, \nthese clips made up 30.81% of all total videos\u2014almost double the runner-up, \n\u201cshitposting,\u201d at 18.23%. While these clips do not carry the explicitly political \nexplanations or expressions that characterize the AIN, they instead act to \nsupport pre-existing conspiratorial narratives on the far right. Adopting the \ngeneric affordances of documentary footage, they play into narratives of \nelection irregularities, COVID-19 hoax theories, and Hunter Biden\u2019s alleged \nties to Ukraine. Thus, the stark rise in conspiratorial links on 4chan is \nparalleled by the rise in popularity of these fodder-style videos, which is \nlikewise paralleled by Reddit\u2019s closing of r/the_Donald and other politically \nunsavory subreddits. Investigating this further would require a closer lens \non the months surrounding the subreddit\u2019s banning as well as innovations \nin method to determine an appropriate proxy for user migration, considering \nReddit\u2019s pseudonymity and 4chan\u2019s anonymity.\nWhat\u2019s clear is that the instability of contemporary platform ecologies \nrequires a robust framework for studying them across particular spaces and \nthat the open nature of hyperlinks, despite being one of the web\u2019s oldest \ninfrastructural elements, provides a way to track these spatial conflations. \n76 anTh ony gl yn bu rTon  \nIt\u2019s also clear that in order for the misinformation epidemic to stay under the \ngrasp of those tracking it, further research is needed on both the ecologies \nthat spring up on migratory platforms as well as the role these shifts play \nin the evolution of verification, epistemologies, and political narratives.\nMethod: Finding links in a web stack\nThis project consisted of two periods of data collection: from the beginning \nof the 2020 U.S. presidential campaign to its middle, and then the end of \nthe campaign and two months of its aftermath. We took Tulsi Gabbard\u2019s \ncampaign announcement for the Democratic Party nomination on January\u00a011, 2019 as marking the beginning of the campaign period. This research window \nran until March\u00a025, 2020, the day we began our data collection. The second \nround of research, conducted from January\u00a07\u201310, 2021, picked up where the \nfirst research window left off, up to December\u00a031, 2020.\nMethodologically, we oriented our data collection around the political \nspaces of the respective platforms. On 4chan, we drew our data from the /\npol/ board. Titled \u201cpolitically incorrect,\u201d /pol/ is the forum\u2019s largest board and \ncontains a few unique infrastructural syntaxes that allowed us to narrow \nour research. User posts are tagged with a small flag, which is automatically \nchosen based on the geographic location of the user\u2019s IP address. We thus \nqueried for user posts tagged with a U.S. flag in our given time periods. The \nflag is not a perfect proxy for location, because users can manually select \ncustom flags such as \u201cCommunist\u201d and \u201cEuropean\u201d alongside explicitly \noffensive and anachronistic flags like the Rhodesian flag (for context, during \nour first data collection period there were 4,173,476 posts with custom flags \non the entirety of the board, and 25,872,606 posts with U.S. flags). Users \ncannot change their flag to another geographic location, however, so while \nour collection did not incorporate users with custom flags, those U.S. flags \nwe did capture can reliably be said to originate in the U.S.\nFor Reddit, we relied on the Reddit bot named \u201cuserleansbot,\u201d in order to \ncollect political subreddits. Userleansbot is designed to provide \u201cinformation \nand transparency to the users engaged in political communities across \nreddit\u201d (userleansbot, 2020). Userleansbot\u2019s primary purpose is to provide \nthe political leaning of Reddit users on request. By replying to a user\u2019s \npost and tagging the bot, userleansbot analyzes the posting history of the initial poster and quantify the frequency of their participation on various \nsubreddits in order to provide an estimation of their political leanings. The \nlist from which userleansbot sources its information is crowd-sourced from \nWhen MiSi nfor MaTi on M igra Te S 77\nvarious Reddit users through personal threads as well as direct suggestions \nvia Reddit\u2019s direct messaging feature. The bot is popular on Reddit: users \nhave awarded it 50,254 karma points, a (high) score that refers to Reddit\u2019s \ninfrastructural points system that allows users to endorse the activity of \nother users (userleansbot, 2020). In order to build our list for analysis, we \ntook the list of subreddits that userleansbot relies on to code partisanship \nand then selected those subreddits that dealt with U.S. national politics.\nIn the first round of data collection, we began our research by employing \nthe \u201cneedle-to-haystack\u201d method (Hagen and Jokubauskaite, 2018). This \nmethod entails inductive investigation, looking for a \u201cneedle\u201d of particularly \ndefined URLs within the \u201chaystack\u201d of collected data. We employed the \n4chan Capture and Analysis Toolkit, or 4CAT (Peeters and Hagen, 2018), to \ncollect all posts in our time range from 4chan/pol/ with U.S. flags, and from \nour collected political subreddits. Given that our initial research questions \nrevolved around the presence of \u201cpink slime\u201d websites outlined in Bengani \n(2019), we used a list of these websites as our needle and our collected data as \nthe haystack. There were no pink slime websites found in either dataset. We \nthen turned to the \u201chaystack-to-needle\u201d method, taking a deductive approach \nto investigate the news ecologies of each space. In our first collection period, \nwe wrote a python script to filter for a regular expression that matched \nURLs to construct this dataset. In the second collection period, we used \n4CAT\u2019s functionality to extract hostnames from our datasets (which uses a similar regular expression strategy on its backend).\nHostnames were then manually coded according to the coding schema \nadapted from Benkler et al.\u2019s study of the media ecologies of the 2016 U.S. \nelection (Table\u00a04.1), using a combination of the qualitative study of each \nwebsite\u2019s front page alongside information from Media Bias/Fact Check \n(2020) (when the political valence was still unclear after consulting Media \nBias/Fact Check, both NewsGuard and AllSides.com were used). Media Bias/\nFact Check codes websites according to their political partisanship into 9 \ncategories, using a qualitative methodology to rank sources on 4 metrics: \nBiased Wording/Headlines, Factual/Sourcing, Story Choices, and Political \nAffiliation. While we drew basic readings from Media Bias/Fact Check, we \nused it as a guide for our first reading of the websites as opposed to adapting \nits coding schema directly because of its breadth. We coded news websites \nas those that adhered to journalistic standards, while websites that made \nno attempt or posture towards the appearance of presenting news were \ncoded as \u201cnon-news.\u201d The remainder, which we classified as \u201cjunk news,\u201d \nwas further split into conspiracy (circulating conspiratorial narratives), \npropaganda (misrepresenting facts for political aims), and sensational \n78 anTh ony gl yn bu rTon  \n(websites aiming to emphasize salacious perspectives or \u201cclickbait\u201d-style \ncontent). These coding definitions are found in Table\u00a04.3.\nTable\u00a04.3  C oding schema for hostnames. Adapted from Benkler et al., 2019.\nCode Definition\nnew\ns Websites that adhere to a framework of \u201cprofessional journalistic \nnorms,\u201d including the imposition of \u201chigher reputational costs on sites and authors who propagate rumor\u201d and the focus on \u201crelatively rapid fact checking, criticism of false claims, and rapid dissemination of and coalescence around corrected narratives\u201d (2018, p.\u00a074).\ncon\nspiracy Sites whose primary narrative or ideological focus is \u201calternative,\u201d \u201cconspiratorial,\u201d or otherwise outside of mainstream established truths as articulated by outlets who fall under the \u201cnews\u201d category.\nPropaganda\nco\nntent focused on \u201cmanipulating and misleading people intentionally \nto achieve political ends\u201d (2018, p.\u00a024).\nSensationalist cl\nickbait or disinformation focused on \u201cpartisan-confirming news \nemphasized over truth.\u201d \nas d\nistinct from propaganda, sensationalist \ncontent is organized based on the acquisition of attention (and, in turn due to the infrastructure of digital news, profit) as opposed to intentional political manipulation (2018, p.\u00a0274).\ncamp\naign an\ny website directly related to or directly promoting the political \ncampaign of a presidential candidate or public servant\nno\nn-news an\ny website that does not fall into the above categories (examples \ninclude Wikipedia, \nyo\nuTube, recipe websites, etc.).\nNews was further divided based on a rough indication of political and \nideological biases, based on an expert list informed by such media and \nnews bias sources as Allsides.com, Media Bias/Fact Check and NewsGuard \n(see Table\u00a04.4).\nTable\u00a04.4  P olitical valence coding scheme with examples.\nPolitical valence Examples\nne\nutral NBC ; Monthly Review\nl\niberal The Guardian ; The Nation\ncon\nservative Fox News ; Wall Street Journal\nada pted from Media bi as/fa ct ch eck, al lSides, and ne wsgua rd.\nIn the first observational period of this research, we selected our news sites \nto code based on whether they appeared over 2,000 times on Reddit and \n400 times on 4chan. From this, our coding dataset contained 204 websites \nWhen MiSi nfor MaTi on M igra Te S 79\nfrom Reddit and 182 from 4chan. We used Bernhard Reider\u2019s YouTube Data \nTools (2015) to collect video metadata, including category, view count, date \npublished, and title. Since the YouTube Data Tools use the YouTube API, \nwhich occasionally returns malformed data, we scripted a separate call in \nPython to the YouTube API that individually verified each video returned and whether it was deleted since its appearance in the links dataset.\nBoth our tooling and sampling criteria were changed for the second \nobservational period. Between our observational periods, Reddit banned four \nsubreddits that together constituted a large portion of data in our first study: \nr/ChapoTrapHouse, r/The_Donald, r/RightwingLGBT, and r/TheNewRight (Ingram and Collins, 2020). Our second observational period spanned the \nperiod of 9\u00a0months, in contrast to the 15\u00a0months observed between Janu -\nary\u00a02019 and March\u00a02020. Because of this smaller window, we reduced the \ncut-off we used for coding hostname links on Reddit from 2,000 to 100, which \nresulted in 220 hostnames from Reddit being coded. On 4chan, likewise, \nwe reduced the cutoff for coding websites from 400 mentions to 200, which \nyielded 219 results. Regressions and limitations introduced into YouTube\u2019s \nAPI between the first observational period and the second led us to writing \na custom script using youtube-dl (ytdl-org, 2021), in order to capture video \nmetadata. Instead of using YouTube\u2019s API, youtube-dl programmatically \nscrapes the information from the video by simulating the loading of what \na casual user would see on a video page. While this took longer to run than \nusing the YouTube Data Tools, our requests were not malformed or subject \nto the unknowns of YouTube\u2019s API interface.\nReferences\nAdams, A. (2016, August\u00a025). SHOCKING: Joe Biden discusses the left\u2019s globalist \nagenda. https://www.youtube.com/watch?v=KaCBYrVsic4. Accessed April\u00a021, \n2021.\nAdams, A. (2020, November\u00a020). KRAKEN UNLEASHED: The press conference \nthey don\u2019t want you to see\u2026 https://www.youtube.com/watch?v=_u34jhCKT2U. \nAccessed April\u00a021, 2021.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBlackburn, J. (2018, February\u00a016). How 4chan and The_Donald influence the \nfake news ecosystem . FIC Observatory. https://observatoire-fic.com/en/\n80 anTh ony gl yn bu rTon  \nhow-4chan-and-the_donald-influence-the-fake-news-ecosystem-by-jeremy-\nblackburn-university-of-alabama-at-birmingham/. Accessed April\u00a021, 2021.\nBuyukozturk, B., Gaulden, S. and Dowd-Arrow, B. (2018). Contestation on Reddit, \nGamergate, and movement barriers. Social Movement Studies , 17(5), pp.\u00a0592\u2013609. \nhttps://doi.org/10.1080/14742837.2018.1483227\nCernovich, M. (2016, September\u00a014). Un/Convention: Exposing fake news at the RNC \nand DNC. YouTube video. https://www.youtube.com/watch?v=cNwgKR88UDo.\nColeman, E.G. (2014). Hacker, hoaxer, whistleblower, spy: The many faces of Anony -\nmous . Verso.\nColley, T. and Moore, M. (2020). The challenges of studying 4chan and the Alt-Right: \n\u201cCome on in the water\u2019s fine.\u201d New Media & Society , 1461444820948803. https://\ndoi.org/10.1177/1461444820948803.\nCoppins, M. (2020, March). The billion-dollar disinformation campaign to reelect the \npresident. The Atlantic . https://www.theatlantic.com/magazine/archive/2020/03/\nthe-2020-disinformation-war/605530/.\nDonovan, J. and boyd, d. (2018, June\u00a01). The case for quarantining extremist \nideas. The Guardian . http://www.theguardian.com/commentisfree/2018/jun/01/\nextremist-ideas-media-coverage-kkk.\nEinwiller, S.A. and Kim, S. (2020). How online content providers moderate user-\ngenerated content to prevent harmful online communication: An analysis of \npolicies and their implementation. Policy & Internet , 12(2), pp.\u00a0184\u2013206. https://\ndoi.org/10.1002/poi3.239.\nGoforth, C. (2021, January\u00a021). Notorious pro-Trump forum rebrands as \u201cpatriots\u201d \nafter post-Capitol riot infighting. The Daily Dot . https://www.dailydot.com/\ndebug/pro-trump-site-renamed-internal-conflict/.\nGray, J., Bounegru, L., and Venturini, T. (2020). \u201cFake news\u201d as infrastructural uncanny. \nNew Media & Society , 22(2), pp.\u00a0317\u2013341. https://doi.org/10.1177/1461444819856912.\nHagen, S., Burton, A., Wilson, J., and Tuters, M. (2019, September\u00a08). Infinity\u2019s abyss: An \noverview of 8chan. OILab . https://oilab.eu/infinitys-abyss-an-overview-of-8chan/.\nHagen, S. and Jokubauskaite, E. (2019). Dutch junk news on 4chan and Reddit /\npol/. In R. Rogers and S. Niederer (Eds.), The politics of social media manipulation \n(pp.\u00a0115\u2013151). Dutch Ministry of the Interior and Kingdom Relations.\nHines, N. (2018, April\u00a022). Alex Jones\u2019 proteg\u00e9, Paul Joseph Watson, is about to \nsteal his crackpot crown. The Daily Beast . https://www.thedailybeast.com/\nalex-jones-protege-paul-joseph-watson-is-about-to-steal-his-crackpot-crown.\nHoward, P. N., Bolsover, G., Kollyani, B., Bradshaw, S., and Neudert, L.-M. (2017). \nJunk news and bots during the U.S. election: What were Michigan voters sharing \nover Twitter?  Data Memo 2017.1, Project on Computational Propaganda, Oxford \nInternet Institute. http://blogs.oii.ox.ac.uk/politicalbots/wp- content/uploads/\nsites/89/2017/03/What-Were-Michigan-Voters-Sharing-Over-Twitter-v2.pdf.\nWhen MiSi nfor MaTi on M igra Te S 81\nIf Americans Knew. (2017, February\u00a03). Senator Schumer says God made him a guard -\nian of Israel. YouTube video. https://web.archive.org/web/20210417224317/https://\nwww.youtube.com/c/IfAmericansKnew-Video/about. Accessed August\u00a02, 2020.\nIngram, D. and Collins, B. (2020, June\u00a029). Reddit bans hundreds of subreddits for \nhate speech including Trump community. NBC News . https://www.nbcnews.\ncom/tech/tech-news/reddit-bans-hundreds-subreddits-hate-speech-including-\ntrump-community-n1232408.\nKaplan Sommer, A. (2017, October\u00a019). White nationalist Richard Spencer gives \nIsrael as example of ethno-state he wants in U.S. Haaretz . https://www.haaretz.\ncom/us-news/richard-spencer-gives-israel-as-example-of-ethno-state-he-wants-\nin-u-s-1.5459154.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube.  Data & Society Research Institute. https://datasociety.net/library/\nalternative-influence/.\nLewis, R. (2020). \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nMassanari, A. (2017). #Gamergate and the fappening: How Reddit\u2019s algorithm, \ngovernance, and culture support toxic technocultures. New Media & Society , \n19(3), pp.\u00a0329\u2013346. https://doi.org/10.1177/1461444815608807.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nPeeters, S. (2020, May\u00a015). Normiefication of extreme speech and the wid -\nening of the Overton window. Open Intelligence Lab. https://oilab.eu/\nnormiefication-of-extreme-speech-and-the-widening-of-the-overton-window/.\nPeeters, S. and Hagen, S. (2018). 4CAT: 4chan Capture and Analysis Toolkit [soft -\nware]. https://4cat.oilab.eu.\nPeterson, J. (2016, November\u00a0 8). Jordan Peterson: The right to be po -\nlitically incorrect. National Post. https://nationalpost.com/opinion/\njordan-peterson-the-right-to-be-politically-incorrect.\nPhillips, W. (2018). The oxygen of amplification. Data & Society Research Institute. \nhttps://datasociety.net/output/oxygen-of- amplification/.\nReider, B. (2015). YouTube Data Tools [software]. https://tools.digitalmethods.net/\nnetvizz/youtube/index.php.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F. \n(2018). The spread of low-credibility content by social bots. Nature Communica -\ntions, 9 (1), p.\u00a04787. https://doi.org/10.1038/s41467-018-06930-7.\n82 anTh ony gl yn bu rTon  \nTuters, M. (2019). LARPing & liberal tears: Irony, idiocy & belief in the deep ver -\nnacular web. In M. Fielitz and N. Thurston (Eds.) Post-digital cultures of the far \nright: Online actions and offline consequences in Europe and the U.S. (pp.\u00a037\u201348). \nTranscript.\nUrman, A. and Katz, S. (2020). What they do in the shadows: Examining the far-right \nnetworks on Telegram. Information, Communication & Society , pp.\u00a01\u201320. https://\ndoi.org/10.1080/1369118X.2020.1803946.\nuserleansbot. (n.d.). List of political subreddits used by userleansbot. Reddit. \nhttps://www.reddit.com/user/userleansbot/comments/cfzho2/list_of_politi -\ncal_subreddits_used_ by_userleansbot/.\nytdl-org. (2021, February\u00a01). Youtube-dl . Youtube-Dl: Download Videos from YouTube \n(and More Sites). http://ytdl-org.github.io/youtube-dl/.\nZannettou, S., Caulfield, T., De Cristofaro, E., Kourtelris, N., Leontiadis, I., Sirivianos, \nM., Stringhini, G., and Blackburn, J. (2017). The web centipede: Understanding \nhow web communities influence each other through the lens of mainstream \nand alternative news sources. Proceedings of the 2017 Internet Measurement \nConference IMC\u201917  (pp.\u00a0405\u2013417). ACM. https://doi.org/10.1145/3131365.3131390.\nAbout the author\nAnthony Glyn Burton  is SSHRC Joseph Armand Bombardier Doctoral \nScholar in the Department of Communication, Simon Fraser University \nand holds a SFU-Mellon Critical Data Studies fellowship at the Digital \nDemocracies Institute. His dissertation work investigates the relationship \nbetween optimization and fascism.\n5 F ringe players on political Twitter\nSource-sharing dynamics, partisanship and problematic \nactors\nMaarten Groen and Marloes Geboers\nAbstract\nFocusing on the (early) run-up to and aftermath of the 2020 U.S. \npresidential elections, this study examines the extent of problematic \ninformation in the most engaged-with content and with the most active \nusers in \u201cpolitical Twitter.\u201d It was found that mainstream sources are \nshared more often than problematic ones, but their percentage was much \nhigher prior to the Capitol riots of January\u00a02021. Significantly, (hyper)\npartisan sources are close to half of all sources shared, implying a robust \npresence. By March\u00a02021, though, both the share of problematic and of \n(hyper)partisan sources decreased significantly, suggesting the impact \nof Twitter\u2019s deplatforming actions. Additionally, active, problematic users \n(fake profiles, etc.) were found across the political spectrum, albeit more \nabundantly on the conservative side.\nKeywords: hyperpartisanship, misinformation, U.S. elections, deplatform -\ning, Capitol riots, digital methods\nResearch questions\nTo what extent are problematic sources present in the most engaged-with \ncontent in political and social issue spaces on Twitter in the run-up to and aftermath of the 2020 U.S. elections? Has Twitter\u2019s deplatforming affected \nthe quality of sources shared? Are there problematic users among the most \nactive, and are they typically of a particular political leaning?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch05\n84 M aar Te n gr oen and Marloe S  ge boer S \nEssay summary\nTo probe the extent to which problematic sources are present on political \nTwitter, the study queries political keywords and investigates the most \nshared news sources and their credibility as well as the most active users, \ntheir authenticity and partisanship. Problematic sources refer to Jack\u2019s \ncharacterization as containing information that is \u201cinaccurate, mislead -\ning, inappropriately attributed, or altogether fabricated\u201d (2017, p.\u00a01). Most \nengaged-with  content on Twitter refers to the most retweeted tweets and/\nor most frequently shared sources within the given time periods. Most \nactive users or accounts are those with the highest tweeting activity, and \nproblematic ones are fake accounts, bots or locked/suspended users. Political \nand issue spaces on Twitter (or \u201cpolitical Twitter\u201d) refer to the result sets \nfrom keyword and hashtags queries for presidential candidates, political \nparties and social issues.\nIn March\u00a02020 the amount of problematic news sources shared on Twit -\nter was 16% of all shared news sources. By December\u00a02020 the share of \nproblematic news sources almost had doubled to 30%. In March\u00a02021 we \nfound a sharp decline in those shared, at just over 10%. While it may have \nto do with the decline in source sharing during that time frame, it also \ncould reflect the significant purge of user accounts by Twitter in the days \nafter the Capitol riots of January\u00a06. The purge likely affected users who were \ninvolved in sharing problematic sources.\nIn the first two time spans under study (March\u00a02020 and December\u00a02020/\nJanuary\u00a02021), close to half of the non-problematic sources circulating the \nnews were classified as (hyper)partisan,1 suggesting that Twitter, like Fa -\ncebook before it, is a platform where such sources perform well (Silverman, \n2016). In March\u00a02021, the third timeframe, we saw a drop to 34% in that \ncategory. The first two periods set themselves apart from the third in that \nthey witnessed the dominance of conservative (hyper)partisan sources \nwhich were no longer as strongly in evidence in the third period of time \n(after the deplatforming).\nIn terms of the users, in 2016 it was mostly pro-Republican fake and bot \naccounts that shared problematic information on Twitter (Bovet and Makse, \n2019). We noticed, however, that there are also pro-Democrat fake and bot \n1 (H yper)partisan is used with the parentheses not only to indicate an amalgamation of \nthe hyperpartisan and partisan source types, but also to signal the difficulty in consistently \ndisentangling them. Below we use (hyper)partisan when discussing sources that were labeled \nas such in the study.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 85\naccounts actively circulating such information. In addition, instead of using \ntheir own hashtags, both Democrat and Republican supporters tend to use \neach other\u2019s hashtags to draw attention from their opposition.\nImplications\nEver since its tagline changed from What are you doing? to What\u2019s happening? \n(2009) Twitter has become regarded less as an ambient friend-following \nmedium than as a \u201creporting machine\u201d at least in the Western social media \nrealm (Rogers, 2014; Tate, 2009). In the past decade, Twitter also has been \nregarded as a space for doing politics, exemplified by Donald Trump\u2019s usage \nof the platform as a political tool in his campaigning for the presidency \nin 2015\u20132016 and later by its integration into his administration. Trump\u2019s \ntweeting changed the nature of the presidency and allowed him to leverage a \nrelatively novel form of media power (Enli, 2017), at least up until the banning \nof his account on January\u00a08, 2021, as a response to the Capitol building riots \nand violence two days before, given the role that Trump played in fueling \nand \u201cglorifying\u201d them.\nGiven the dominant presence of Trump on Twitter, but also of other \ncandidates and their supporters and observers, it arguably became the \nkey social media platform where the politics of the 2020 U.S. presidential \nelections played out. Trump\u2019s \u201cpopulist anger\u201d (Wahl-Jorgensen, 2019, p.\u00a0117) \nwas not only on display on Twitter but connected to a hybrid media system \nin which mainstream media co-mingle with \u201cfringe\u201d players (Chadwick, \n2017; Wahl-Jorgensen, 2019). It is the extent of this co-mingling that one is able to study on Twitter.\nIn this regard, it is important to note how social media posting not \nonly \u201cfolds into\u201d (Niederer, 2019, pp.\u00a0119\u2013120) the content of mainstream \nmedia (within which we distinguish more or less partisan sources) but \nalso impacts their \u201caffective styles\u201d (Wahl-Jorgensen, 2019, p.\u00a0116). A broad \nset of transformations have accompanied these new media, enabling a \nmedia regime to emerge in which there is a \u201cnormalization of a new set of \n\u2018emotion rules\u2019 that allow a president to consistently make statements that \nare verifiably false, be called out on these falsehoods and pay no political price for them\u201d (Delli Carpini, 2018, pp.\u00a018\u201320).\nTwitter is a space that is vulnerable to problematic information and \nthe presence of potentially problematic users such as fake accounts and \nbots (Boyd et al., 2018). We identified such problematic activity during \nthe periods under study, each of which with distinctive user activity. The \n86 M aar Te n gr oen and Marloe S  ge boer S \ninitial time span is the period around \u201cSuper Tuesday\u201d on March\u00a03, 2020, \nwhen the greatest number of states hold their primaries or caucuses. We \nthen repeated our analyses in the final days of 2020 from late December \nup until January\u00a04, 2021, which covers the post-election time span and the \nsignificant U.S. Senate run-off elections in Georgia on January\u00a05 which \nwould result in a Senate majority for the Democrats. In retrospect, these \ndays were also close to the Capitol riots of January\u00a06 that were spurred by \nongoing speculations about election fraud. This time frame represents a \nTwitter discourse centering on speculations concerning the balance of \npower after the Senate run-offs as well as allegations of election fraud and \nsubsequent calls for protesting the \u201cvote steal.\u201d The final time span under \nstudy covers March\u00a010 to 22, 2021 and can be characterized as not only \npost-election but also post-purge after Twitter deplatformed over 70,000 \naccounts (many linked to QAnon conspiracies) between January\u00a09 and 12, in response to the aforementioned riots (Conger, 2021).\nOverall, our findings show that mainstream sources outperform (or are \nshared more often than) problematic sources on political Twitter. Though \nthe circulation of problematic sources was higher just after the election, \nthey never outperformed mainstream sources as was the case on Facebook \nin the run-up to the 2016 elections (Silverman, 2016). We do see a significant \ndrop in March\u00a02021 in the circulation of problematic sources after the \nTwitter purge.\nIn both March\u00a02020 and December\u00a02020/January\u00a02021 nearly half of the \nsources shared were coming from sources that we sub-categorized as (hyper)\npartisan progressive or (hyper)partisan conservative. We also witnessed a \nnoticeable uptick in problematic sources shared in the aftermath of the elec -\ntions which spans the weeks in which the Twitter discourse was dominated \nby allegations of electoral fraud. While (hyper)partisan sources do not share \nconspiracy or pseudo-science and are not problematic in that sense, the \nfindings point to a particular kind of hybrid media landscape. It provides \nplenty of space for (hyper)partisanship and problematic information to \nco-mingle with mainstream sources. Put differently, mainstream news is \nincreasingly confronted with more partisan players in the field, at least on \nTwitter in the run-up to and aftermath of the U.S. elections.\nThough beyond the scope of this study, our findings imply that more \nproblematic information is engaged with on social media than in other online \nmedia spaces such as the web, where the top-ranked media properties (by \ntraffic) are rather mainstream and include NBC, CBS, Disney and Turner \n(ComScore, 2019), though a separate measure should be taken of the \u201cpolitical \nweb.\u201d This disparity between Twitter and the web aligns with what Barnidge \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 87\nand Peacock (2019) point out concerning the reliance on social media for \nthe dissemination of hyperpartisan (and problematic) sources.\nIn the run-up to the presidential elections in 2016, multiple studies \nindicated that suspect accounts were mostly spreading problematic, pro-\nRepublican information on Twitter (Bovet and Makse, 2019). During the cam -\npaigning and in the (immediate) aftermath of the 2020 elections, however, \nwe also identified problematic, pro-Democrat accounts actively spreading \nproblematic information across Twitter, though they do not outnumber \nthose on the other side of the political spectrum. That is, compared to the \nfindings of previous studies concerning the type of problematic accounts, \nto date there are indications of a shift from mainly conservative to a mix \nof conservative as well as progressive problematic accounts. Additionally, \namong the datasets of most active users we found more problematic accounts \nthan authentic ones, implying that highly active accounts during election campaigning deserve scrutiny.\nWith respect to the most engaged-with tweets, the vast majority is posted \nby influential users, and they do not circulate many problematic sources. \nThe finding indicates that most retweeted content (rather than most tweeted \ncontent only) is a quality indicator, at least in this brief study. The role of \nfollower counts is thus important as there is a direct relationship between follower and retweet counts. If problematic users would attain influential masses of followers, such analyses might look different.\nIn light of the societal consequences of disseminating problematic or \nhyperpartisan sources, it is important to stipulate that the link between \nsharing and the actual visibility of such sources is not clear cut, given how \nvisibility is algorithmically determined. We can assume a higher probability \nof exposure, however, when tweets are retweeted (Kwak et al., 2010). Meier \net al. (2014) found that retweeting and liking could be regarded as audience \nengagement in a conversation and attention to the messages, which facilitates \ninformation transmission.\nSituating the findings: Diversification and polarization on \nTwitter\nWe situate our findings around the sharing of problematic and non-\nproblematic sources in the affordances of a platform that, to a certain \nextent, democratized news sharing in the sense of opening the gates for \nnon-mainstream sources to circulate and be amplified. In order for sources \nto be successful on Twitter, we need to understand both how people are \n88 M aar Te n gr oen and Marloe S  ge boer S \nexposed to news sources and what makes (news) content prone to ampli -\nfication in that realm. The rise of social platforms has posed challenges \nto theorizing selective exposure to news. Barnidge and Peacock (2019) \ndistinguish two ways in which social media have restructured selective \nexposure to news. Both ways provide a means to assess the implications \nof our findings that social media diversify social connections and facilitate \nthe rise of hyperpartisan news.\nThe diversification aligns with Bruns\u2019s reflections (2019) on the existence \nof filter bubbles and echo chambers (Pariser, 2011; Sunstein, 2001). Such \nstructures of isolated communities are based on a belief that social media \ninevitably promote echo chambers and filter bubbles as they personalize \ncontent to the extent that individuals consume news in isolated ways. \nEmpirical research into the existence of such structures have not found \nevidence to support this belief (O\u2019Hara and Stevens, 2015; Barnidge, 2017). \nBruns (2019) modified these concepts through introducing degrees of \n\u201cbubbleness\u201d or \u201cchamberness\u201d: scholars can quantify the extent to which \npeople connect or communicate within and beyond ideological groups. This \nmodification does justice to the fact that by far most people use multiple \nsources for their news consumption (Dubois and Blank, 2018) and that \npeople befriend others not just on the basis of their political leanings. Bruns \n(2019) backs the latter argument by stating how people are not primarily \non social media (or at least on Facebook) to talk politics. We would like to \nnote that Twitter\u2019s use culture is more geared toward talking politics than is Facebook\u2019s, for example, which might lead to different ways of curating one\u2019s social network.\nThough Twitter users may have diverse social networks and the infor -\nmation that people are exposed to is varied, the findings from our study \nunderscore how sharing sources seems to largely follow one\u2019s own political \nleaning: in the datasets where Republican leaning users were most active, \nthe (hyper)partisan sources were mainly conservative in kind and vice versa. \nNote, too, how the Republicans are overrepresented in the data demarcated \nby keywords pertaining to the Democrats, which is related to how Twitter users are calling out or attacking their opponents in their tweets.\nWithin all datasets we found a pattern whereby users employ the op -\nposition\u2019s keywords and hashtags, in order to target each other. It occurs \nin political spaces organized around both political parties and candidates. \nWithin these supporter spaces, there appear to be more sources shared that \nattack the opponent rather than support the candidate. (See also Starbird \n(2017) as well as Groshek and Koc-Michalska (2017) for investigations into \nstrategies of attack and trolling of mainstream media, especially apparent \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 89\non Twitter.) Our findings thus reiterate how the relentless targeting of people \nthrough hyperpartisan viewpoints continues and is a phenomenon practiced \non both sides of the political spectrum. One methodological implication is \nthat one cannot neatly demarcate a supporter space through hashtag and/\nor keyword queries only.\nBarnidge and Peacock (2019) point out that alongside the diversification of \ninformation described above, social media also allow hyperpartisan voices \nto reach a wider audience that is now able to share messages independently \nof mainstream media. Hyperpartisan news could be described as having \na slanted political agenda and making scant effort to balance opposing \nviews. It could be said to push anti-system messages that are critical of \nmainstream media and established politicians, relying on dubious informa-\ntion or misinformation to do so. It also depends heavily on social media for \nits dissemination (Barnidge and Peacock, 2019).\nThrough challenging mainstream narratives, hyperpartisan media also \noverlap with notions of alternative media. Strengthening Bruns\u2019s argument \nabout the absence of isolated bubbles, Peacock et al.\u2019s empirical investiga -\ntion (2019) found that strong partisans on social media are exposed to \nboth left- as well as right-leaning news. In order to proffer an \u201calternative \nperspective\u201d to mainstream news, hyperpartisan media and users have to \nmonitor mainstream sources to know how these outlets talk about issues. \nThey attach commentary to the narratives of mainstream media. As O\u2019Hara \nand Stevens point out: \u201cengaging with the enemy does not necessarily make \na group less partisan\u201d (2015, p.\u00a0418). Bruns (2019) expands on this point and \nsituates exposure to diversified information as intensifying polarization \nthrough in-group identification and providing an outside \u201cother\u201d that serves \nas an embodiment of the political enemy. We might not live in isolated \nbubbles; rather, it is the diversification of information on platforms that \nseems to spur polarization because of an increased exposure to opposing views. This observation would involve a much-needed research focus into \nhow people perceive and recontextualize news on social media to fit it into \ntheir existing beliefs.\nExpanding on Bruns\u2019 argument about \u201cporous\u201d filter bubbles and \necho chambers, we found that many tweets were formatted to call out or \nattack opponents, e.g., from the dataset that queried GOP: \u201cIf we \u2018move \non\u2019, the GOP will refuse to concede future elections, then judge-shop \nuntil they steal one. There must be a price paid for sedition or we will \nlose our democracy. This is critically important work in the next couple \nof years\u201d (Alter, 2021). This strategy of attacking opponents was apparent \nin the fact that the tweet data collected through (for example) words \n90 M aar Te n gr oen and Marloe S  ge boer S \nthat relate to Democrats contained largely Republican-leaning users \nwho were calling out or attacking Democrats and vice versa. Note for \nexample that in the March\u00a02020 Republican-oriented dataset, a tweet \nfrom a Democrat reads: \u201cReal quick: How are Republicans like Donald \nok with 2% of people dying from coronavirus as if 2% is not a very high \nnumber. But when you discuss a 2-cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happen \nto them\u201d (Salenger, 2020).\nMainstream media attempts to contextualize and balance the narra -\ntives injected by hyperpartisan sources. When terms like \u201cjunk news\u201d and \n\u201cconspiracy theory\u201d are invoked, they seem to trigger political backlash \n(Rogers, 2020a) and increase distrust in mainstream media. This dynamic \ncan only be further understood if affective and intuitive tactics of people \nwho are consuming and sharing news on social media are taken into account. \nAs Swart and Broersma (2021) found in their analyses of young people\u2019s \nassessments of the trustworthiness of news, it is prior knowledge, lived \nexperiences, and endorsements of sources by people within their own social \nnetworks that guide how people assess sources, which in turn plays a vital role in the choice to share particular sources over others.\nWhen it comes to sharing news, the existing literature also steers attention \ntoward the emotive underpinnings of hyperpartisan news and its effects \nwhen disseminated in the realm of social media. Twitter\u2019s business model \nis based on an attention economy, which places emotion at the forefront \nof journalistic practices. While emotion and information are not mutually \nexclusive, hyperpartisan media tend to exploit anger and a culture of outrage \n(Barnidge and Peacock, 2019; Berry and Sobieraj, 2014). Berry and Sobieraj \n(2014) move away from conventional wisdom that the rise of outrage media \nis the result of increased political polarization and argue for considering \nthe economic underpinnings of what they dub an \u201coutrage industry.\u201d They \nsituate this industry in the context of structural changes to the media \nlandscape that have fostered its exponential growth.\nTwitter as part of this new media landscape is market-driven and \ndependent on the stickiness of content circulating on its platform. What \nmakes users stick around (and share)? In the context of problematic and \nhyperpartisan news media, Berger and Milkman\u2019s study into viral news \ncontent (2012) is instructive for it examines what animates users to share \ncontent by assessing the emotive components of more and less shared \ncontent. They found that the virality of the content depends on evoking \nhigh-arousal positive (awe) or high-arousal negative (anger or anxiety) \nemotions. Content that evokes low-arousal, or deactivating, emotions (e.g., \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 91\nsadness) is less viral.2 Thus outrage is seen as viral, which sheds light on \nthe rise of hyperpartisan news on Twitter, as this kind of news is \u201cmeant \nto cause outrage, cue partisan emotions, and get clicks (i.e., make money). \nHyperpartisan news \u2026 provides low-quality news with the goal of making \nmoney from people\u2019s\u2014in many cases misguided\u2014anger and outrage\u201d \n(Barnidge and Peacock, 2019, p.\u00a06). Note, however, that a binary opposition \nbetween quality journalism that is \u201cinforming\u201d and less emotive and a \nsensationalized form that is merely emotive is false, as Wahl-Jorgensen \n(2019) also stipulates, in reference to Boltanski (1999). The creation of \nempathy is a prerequisite for political action. We want to stipulate that our \ndistinction between problematic and non-problematic sources is not based \non considerations regarding a distinction between factual and emotive \nnews sources; rather, we point to the role of exploiting outrage through \na socio-technical synergy between (hyper)partisan news outlets and a \nmarket-driven platform.\nNotwithstanding the fact that all journalistic items hold some emo -\ntion, the affordances of Twitter facilitate a discursive climate which is \nmore extreme, divisive and polarized than most mainstream news spaces \n(Shepherd et al., 2015). Trump but also hyperpartisan (and problematic) \nnews outlets have benefitted from this affective shift by crafting messages \nin such a way that they spill over to mainstream media (Karpf, 2017) that in \nturn, and perhaps unwantedly, amplify fringe players on the platform. So, \nalthough the majority of shared sources is still comprised of mainstream \nnews organizations, problematic and hyperpartisan sources are pushing \nfor more space and might have spillover effects in the form of steering \nmainstream content and affective styles of communication on the platform.\nThough investigating such spillover effects into content and style of legacy \nmedia is beyond the scope of our analyses, we did find that in political issue \nspaces such as that of DACA, mainstream media either followed uptakes \nin problematic source-sharing (see third time span, Figure\u00a05.4) or seemed \nto veer upwards after such flares in problematic source-sharing (second \ntime span, Figure\u00a05.4), suggesting that problematic sources can be at the \nforefront of constructing a particular narrative about an issue at hand that is \nthen taken up by mainstream sources. The latter dynamic can be the result \nof an algorithmically maintained power disparity between mainstream \nand fringe sources due to the intensification of majority (already popular) \n2 T hese results hold even when the authors controlled for how surprising, interesting, or \npractically useful content is (all of which are positively linked to virality), as well as external \ndrivers of attention, e.g., how prominently content was featured.\n92 M aar Te n gr oen and Marloe S  ge boer S \nvoices, a dynamic also hypothesized by among others Bruns (2019) as well as \nBozdag and Van den Hoven (2015). This observation opens a relevant future \ndirection for misinformation research which is more sensitive to detecting \nthe adoption, or the \u201cfolding in,\u201d of fringe and at times problematic sources \nin the coverage and affective styles of mainstream media.\nFindings\nFinding 1: On Twitter the number of mainstream sources attached to political \ntweets or retweets is greater than problematic sources, however much the \nhigh share of (hyper)partisan sources within mainstream sources points to \na rather polarized platform. After the Twitter purge of problematic accounts \nin January\u00a02021, the share of (hyper)partisan sources within mainstream \nsources decreased significantly.\nIn the data collected during all three time frames (March\u00a02\u201322, 2020, \nDecember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021) around a million \nlinks to media articles were shared. Of these, overall, mainstream news \nsources outperformed problematic sources on Twitter. In March\u00a02020, the \nshare of problematic news sources shared on Twitter was 16% of all shared \nnews sources. In December, the share of problematic news sources almost \ndoubled to 30%. In March\u00a02021, the share of problematic sources dropped \nsignificantly to 11%. The source classifications are based on source labeling \nplatforms and contain two main categories indicating whether a source is \nmainstream or problematic and sub-labels for mainstream sources indicating \n(hyper)partisanship conservative or (hyper)partisanship progressive. The \npercentage of mainstream sources shared from sources subcategorized \nas (hyper)partisan decreased slightly from 48% in March\u00a02020 to 43% in \nDecember and further dropped to 33% in March\u00a02021. This drop mostly \nowes to conservative (hyper)partisan sources being less circulated. Overall, \nmainstream sources are shared more often than problematic news websites, \nthough closely after the election, there was a significant rise in the share of \nproblematic sources which decreased again in March\u00a02021.\nFinding 2: Conservative sources are shared more often when discussing \nDemocrat keywords, and in most cases progressive sources are shared more \noften when discussing Republican ones. In Twitter we queried for specific \nkeywords and hashtags (see Table\u00a05.1) that represent each party and political \ncandidate and found that in both March periods of 2020 and 2021 conservative \nsources were shared more than progressive ones when discussing Democrat \nkeywords, and vice versa (Figures 5.2 and 5.3). Only in the December/January \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 93\nperiod the share of progressive sources in the Republican dataset was lower \nthan that of conservative sources. We also found that in both March periods \nthere were fewer problematic sources shared when discussing Republican \nkeywords than Democrat ones. In December the proportion of problematic \nsources was much higher which is a trend we see across all datasets. The \n(hyper)partisan conservative sources in December are shared more often \nacross both Republican and Democrat political spaces.\nThis finding is in contrast with the results in the other two periods that \nindicate a crossover of information where (hyper)partisan conservative \nsources were shared in the Democrat issue space and (hyper)partisan \nprogressive sources were shared in the Republican. The change in December \nindicates that in the aftermath of the elections, Democrats continue to \nattack Donald Trump and the Republican party while some problematic \nand conservative (hyper)partisan sources seem to make a shift and even \nattack Republicans in the December/January time period when the alleged \nelection fraud was a major topic. One example of this shift is an article3 \n3 https://www.thegatewaypundit.com/2020/12/raffensperger-gets-caught-georgia-ballots-\nprinted-differently-gop-counties-vs-dem-counties-election-rigged/\nfi gure\u00a05.1 cu mulative total of mainstream and problematic hosts shared on political Twitter over \nthree time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n94 M aar Te n gr oen and Marloe S  ge boer S \nfi gures 5.2 and 5.3 cum ulative total of mainstream and problematic hosts shared on political \nTwitter when querying \nre\npublican or \nde\nmocrat terms for three time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 95\nby the Gateway Pundit which made up 25% (23,000 shares) of the total of \nproblematic content shared in that 4-day period, attacking a Republican \nin Georgia (who had not followed Trump\u2019s wishes). In terms of hashtag \nuse, users who support the Democrats would use Republican keywords or \nhashtags such as #gop and #republicans to tweet against or at them. The \nsame holds for the Republican supporters using the Democrat terms.\nFinding 3: Mainstream sources are shared more often than problematic \nsources concerning social issues related to health care and climate change \nbut not DACA (Deferred Action for Childhood Arrivals) where problematic \nsources outperformed mainstream sources in certain periods during March \nand December\u00a02020 as well as in March\u00a02021. In the third time span DACA \nhas fewer partisan sources than in the first two time spans. That is, of those \nunder study, the one issue where problematic sources are shared more \noften than mainstream sources (only during the first week of March and \nDecember\u00a02020) is DACA (Figure\u00a05.4), though the high engagement is largely \nattributed to a few articles. In the second and third weeks of March\u00a02020, \nthe number of problematic sources in the DACA issue space significantly \ndecreased. Indeed, across the three social issues, with the exception of \nDACA, few problematic sources were shared.\nWe note a similar pattern of shared problematic sources across the issues \nwhen comparing all time frames. In general, all issue spaces show less \nengagement in the time periods after the election. For example, there was \nalmost no activity in the Medicare issue space in March\u00a02021, indicating \nits election relevance rather than a broader societal concern. Note that \nthe sample sizes in these issue spaces are small, so one article can quickly \nspike engagement.\nFinding 4: There were more problematic accounts (fake accounts, bots or \nlocked/suspended) than real accounts on Twitter among selected keyword \nand hashtag datasets (Democrat, Republican, Trump) except for Biden\u2019s \ndataset in the first time frame. The latter data did contain problematic \naccounts in the second time span, covering the immediate aftermath of \nthe elections.\nWe now move to the top 20 users with the highest number of tweets and \nretweets during two, three-day time frames in March (one during and one \nafter \u201cSuper Tuesday,\u201d March\u00a03, 2020) and a third time frame (January\u00a01\u20134, \n2021). In the Republican and Democrat keyword and hashtag datasets we \nnoticed that, in total, there were more problematic accounts than real \naccounts (Figure\u00a05.7) for these time frames. For the Democrat dataset we \nfound only four real accounts in March and one account that clearly labeled \nitself as a bot that retweets all tweets by Trump. The rest was a combination \n96 M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.4 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning \ndaca , d\nuring the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 \nand March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfi gure\u00a05.5 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning Medicare, during the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, \n2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 97\nof fake accounts and locked/suspended accounts that had been banned \nby Twitter. In the Democrat keyword and hashtag dataset, most accounts, \nwhether real or fake, were mostly pro-Republican, indicating again how \nusers are employing the opposing political party\u2019s terms. The same applies \nto the Republican keyword and hashtag dataset, where most users are \npro-Democrat as opposed to Republican, though a smaller proportion is \nfake. Interestingly, in January\u00a02021, the share of fake and bot accounts \nshifts between these two issue spaces. The number of fake accounts in the \nRepublican hashtag space is now larger than the Democratic space. In our \ndatasets in total, problematic accounts in January make up about 60% of \nall accounts which is roughly the same as in March.\nIn 2016 it was found that suspect accounts were mostly Pro-Republican, \nand these were responsible for spreading most of the problematic in -\nformation (Bovet and Maske, 2019). In March we found that there was \nalready a rise in problematic accounts associated with pro-Democrats. \nIn January, we found that there are more problematic pro-Democrat \naccounts compared to March. Thus, it can be argued that Democrats are \nemploying problematic accounts within Republican political spaces to \nattack the Republican party.\nfi gure\u00a05.6 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning \ngr\neen \nne\nw \nde\nal, during the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013Janu-\nary\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n98 M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.7 The top 20 users with the highest activity measure on Twitter within the de mocrat, \nre\npublican, \nbi\nden and Trump hashtag/keyword datasets, collected March\u00a02\u20134, 2020 and \nJanuary\u00a01\u20134, 2021. \nbu\nbble diagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 99\nfi gure\u00a05.8 The top 20 users with the highest activity measure on Twitter within the de mocrat and \nre\npublican hashtags/keywords datasets, collected during the time spans: March\u00a02\u20134, 2020 and \nJanuary\u00a01\u20134, 2021. \ndi\nagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n100  M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.9 The top 20 users with the highest activity measure on Twitter within the hashtag/\nkeyword datasets for the three political issues, collected during the time spans: March\u00a02\u20134, 2020 and January\u00a01\u20134, 2021. \ndi\nagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 101\nFor the candidates\u2019 datasets (Biden and Trump) the same process was fol-\nlowed, but we filtered the top 20 users (by tweeting activity) that @mention \neach candidate (Figure\u00a05.7). Interestingly, a similar shift can be seen in the \nDemocrat and Republican datasets when comparing the two time frames. \nIn March, the Biden dataset had the highest number of real accounts, with \na few fake and locked/suspended accounts. The majority of users that @\nmention Biden is not problematic, and they are supporters of his political \ncampaign. The opposite holds for users mentioning Trump where results \nare equally distributed between bots, fake, and real accounts. In terms \nof partisanship, the majority is pro-Republican, which indicates that in \ncontrast to the political party spaces, the most active users are supportive. \nIn January, however, the most active users are those who are attacking either \ncandidate. There are more pro-Democrat bots attacking Trump and more \nreal pro-Republican accounts attacking Biden. Overall, the debate seems \n(even) more polarized in January compared to March.\nFinding 5: The most retweeted tweets among all datasets in both \nMarch\u00a02020 and December\u2013January\u00a02021 were made mostly by influential \naccounts like the presidential candidates, members of Congress, organiza -\ntions, and journalists and largely do not contain any problematic sources. \nFew problematic sources were found among the top 20 most retweeted tweets \nin the Democrat and Republican keyword and hashtag datasets in the two \ntime frames (Figure\u00a05.8). For example, the two tweets flagged as problematic \nin the Republican space in March are linked to the website run by Dan \nBongino, a conservative talk show host. A large majority of the retweets are \nby less controversial, influential people, including presidential candidates, \nmembers of Congress and journalists. The results are largely similar for \nthe January\u00a02021 dataset, where one highly resonating retweet opposing \nDemocrats was labeled as questionable. It relates to a news item around \nelectoral fraud from the OAN (One America News), which is a problematic \nsource as per our classification based on Media Bias/Fact Check (see also \nmethods section). Another resonating retweet referred to Breitbart News \ncovering calls for investigating electoral fraud.\nMethods\nBefore initiating our Twitter data collection, we curated a list of queries \nfor political candidates, political parties and social issues, incorporating \npolitician-specific, party-specific and issue-specific keywords and hashtags \n(Table\u00a05.1). Three social issues (likely to animate both sides of the political \n102  M aar Te n gr oen and Marloe S  ge boer S \nspectrum) were selected from a longer issue list made by triangulating issue \nlists on voter aid sites: Politico, VoteSmart, On the Issues and Gallup. These \nkeywords and hashtags were captured using DMI-TCAT (Borra and Rieder, \n2014) from the 2nd until the 23rd of March\u00a02020 and from December\u00a024, \n2020 until January\u00a04, 2021. 4CAT4 was used in the period from March\u00a010 to \n22, 2021, when problematic users were not analyzed. In these time spans, \nclose to 3 million tweets were captured that contain a link to a news article. \nThese tweet sets we term \u201cpolitical Twitter.\u201d\nTable\u00a05.1  C urated list of political keywords and hashtags queried in Twitter.\nTopic Query\nd\nemocrat #democrats, 2020 de\nmocrats, \nba\nckThe b\nlueWave, \nco\nuntry ov\nerParty, \nde\nmocraticParty, \nde\nmocrats2020, \nde\nms, \nnot\nMeus\n, Towards\nade\nmo-\ncraticParty\nica\nnTrust, Vote b\nlue, Vote b\nluenoMa\ntterWho, Vote b\nlue-\nno\nMatterWho2020, Vote\nbl\nueToSave ame\nrica, WelcomeTo no\ntMe us\n, \ndemocrats, thedemocrats \nr\nepublican #gop, gop, republicans, #republicans, Vote re\nd, Vote re\nd2020, \nVote\nre\ndToSave ame\nrica, Vote\nre\ndToSave ame\nrica2020\nbid\nen #biden, #joebiden, \u201cjoe biden,\u201d \nbid\nen2020, \nbid\nenbou\nnceba\nck, \nbid\nenfo\nrPresident, \nbid\nenha\nrris, \nbid\nenha\nrris2020, \nbid\nenbe\natsTrump, \nJoebid\nen2020, JoeMentum, Mojoe, \nqu\nidProJoe, \nrid\ninWith bid\nen, \nTeam\nbid\nen, TeamJoe, WeKnowJoe, biden, joebiden\nTrump #trump, \u201cdonald trump,\u201d \nbl\nackVoices fo\nrTrump, \ncub\nansfo\nrTrump, \ndo\nnaldTrumpjr, K a\ng, Ka\ng2\n020, K a\ng2\n020la\nndslideVictory, Keep\nam\neri-\ncagr\neat, M a\nga,\n Ma\nga2\n020, M a\nga2\n020la\nndslide, PresidentTrump, \nPresidentTrump2020, \nreel\nectPresidentTrump2020, TW\ngrP\n, Trump2020, \nTrump2020 la\nndslide, Trump2020 la\nndslideVictory, trump\nda\nca d\naca\ngr\neen \nne\nw \nde\nal gre\nennewdeal\nMedicare medicareforall, medicare4all\nThe three types of data we collected were most shared links, the top users \n(in terms of the number of tweets made), and the most retweeted tweets. \nTo study the most shared links, an expert list of sources was created. Each \nsource was labeled into two main categories, mainstream or problematic. \nMainstream sources could be sub-categorized as (hyper)partisan conserva -\ntive, (hyper)partisan progressive or neither. The expert list was created \nusing existing labeling sites such as Allsides.com, Media Bias/Fact Check, \u201cthe Chart,\u201d and NewsGuard. We consider the categorization as rough. By \ncalculating the total number of times problematic sources were shared \n4 h ttps://github.com/digitalmethodsinitiative/4cat\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 103\nduring our duration of study and comparing it with the mainstream sources \nwe were able to show the magnitude of the matter at hand. Are problematic \nsources present and shared by the users on Twitter who make use of specific \npolitical hashtags and keywords? We limited the scope of the top users and \nhashtags under study to three days in the first two time frames, starting \nfrom the 2nd of March\u00a02020 and from the 1st of January\u00a02021. The reason for \nchoosing the specific March period was that it encompassed \u201cSuper Tuesday,\u201d \na day when the largest number of U.S. states hold primary elections, and it \nwould be a reasonable assumption that the Twitter engagement on this day, \nthe day prior, and the day after would be higher than the other days in our \ndate range. The January time frame was just before the deciding Georgia \nrun-off elections for the U.S. Senate on January\u00a05, which would give the \nDemocrats a slim majority and in hindsight, with that time frame, we also \ncaptured the days before the Capitol riots of January\u00a06, 2021.\nWith the dataset of most active users, we investigated the extent to which \nproblematic users/accounts (fake profiles, bots, or locked/suspended users) \nwere present. We examined the top 20 users with the greatest number of \ntweets on political Twitter. These users were then coded or categorized on \ntwo scales: \u201cauthenticity\u201d and \u201cpartisanship.\u201d For the authenticity label, \nthe top 20 users were classified into four types based on their Twitter \nprofiles, where the idea is to gain a sense of the genuineness and legitimacy \nof the top users: real, fake, bot, and locked/suspended. The categories are \nadopted from the audience intelligence website, SparkToro, which ranks \nTwitter users based on their attributes (Fishkin, 2018). For bots, the website \ncategorizes accounts by determining whether they have Twitter\u2019s default \nprofile image, if an account has an unusual ratio of followers/following, \nor posts an abnormal number of tweets per day, among other signals. \nFake/real profiles, too, are judged according to (usual/unusual) tweeting \nhabits and behavior. The second categorization is \u201cpartisanship,\u201d where \nall the top users\u2019 political leanings were labeled independently by two \nauthors by looking at their Twitter profiles and classifying them into one \nof three categories: Democrat-leaning, Republican-leaning, or unknown. \nAny disagreements between the authors resulted in labeling the one in \nquestion as unknown.\nWith regards to the most retweeted tweets, the top 20 tweets were ex -\ntracted from the political spaces, and from the three issue-specific hashtags, \nDACA, Green New Deal, and Medicare. The most retweeted or the most \npopular tweets were further categorized into two categories of partisanship \nand the categories problematic or non-problematic information provider.  \nSimilar to the problematic users\u2019 segment, the partisanship of the tweets was \n104  M aar Te n gr oen and Marloe S  ge boer S \nmanually labeled by looking at the language of the tweet and further details \nabout the person who tweeted. To decide if a tweet contains problematic \ninformation, we checked whether any news sources linked in the tweets \nwere classified as such in the labeled source list.\nReferences\nAlter, J. [jonathanalter]. (2021, January\u00a01). \u201cIf we \u2018move on\u2019, the GOP will refuse to \nconcede future elections, then judge-shop until they steal one. There must be a \nprice paid for sedition or we will lose our democracy. This is critically important \nwork in the next couple of years\u201d [tweet]. https://twitter.com/jonathanalter/\nstatus/1345074521561292800.\nBarnidge, M. and Peacock, C. (2019). A third wave of selective exposure research? \nThe challenges posed by hyperpartisan news on social media. Media and Com -\nmunication , 7(3), pp.\u00a04\u20137. https://doi.org/10.17645/mac.v7i3.2257.\nBarnidge, M. (2017). Exposure to political disagreement in social media versus \nface-to-face and anonymous online settings. Political Communication , 34(2), \n302\u2013321. https://doi.org/10.1080/10584609.2016.1235639.\nBerger, J. and Milkman, K. L. (2012). What makes online content viral? Journal of \nMarketing Research,  49(2), 192\u2013205. https://doi.org/10.1509/jmr.10.0353.\nBerry, J. and Sobieraj, S. (2014). The outrage industry . Oxford University Press.\nBoltanski, L. (1999). Distant suffering: Morality, media and politics. Cambridge \nUniversity Press.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Journal of Information Management  66(3), \npp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBovet, A. and Makse, H.A. (2019). Influence of fake news in Twitter during the \n2016 U.S. presidential election. Nature Communications , 10(1), p.\u00a07. https://doi.\norg/10.1038/s41467-018-07761-2.\nBoyd, R. L., Spangher, A., Fourney, A., Nushi, B., Ranade, G., Pennebaker, J., and \nHorvitz, E. (2018). Characterizing the Internet Research Agency\u2019s social media \noperations during the 2016 U.S. presidential election using linguistic analyses \n[Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/ajh2q.\nBozdag, E. and Van den Hoven, J. (2015). Breaking the filter bubble: Democracy and \ndesign. Ethics and Information Technology, 17 (4), 249\u201365. https://doi.org/10.1007/\ns10676-015-9380-y.\nBruns, A. (2019). Are filter bubbles real? Polity Press.\nChadwick, A. (2017). The hybrid media system: Politics and power. Oxford University \nPress.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 105\nComscore (2019). Comscore March\u00a02019 top 50 multi-platform website properties \n(desktop and mobile). https://www.comscore.com/Insights/Rankings.\nConger, K. (2021). Twitter, in widening crackdown, removes over 70,000 QAnon \naccounts. New York Times . https://www.nytimes.com/2021/01/11/technology/\ntwitter-removes-70000-qanon-accounts.html.\nDelli Carpini, M.X. (2018). Alternative facts: Donald Trump and the emergence of \na new U.S. media regime. In Z. Papacharissi and P. Boczkowski (Eds.), Trump \nand the media (pp.\u00a017\u201323). MIT Press.\nDubois, E. and Blank, G. (2018). The echo chamber is overstated: The moderating \neffect of political interest and diverse media. Information, Communication & \nSociety,  21(5), pp.\u00a0729\u201345. https://doi.org/10.1080/1369118X.2018.1428656.\nEnli, G. (2017). Twitter as arena for the authentic outsider: Exploring the social \nmedia campaigns of Trump and Clinton in the 2016 U.S. presidential elec -\ntion. E uropean Journal of Communication , 32(1), pp.\u00a050\u201361. https://doi.\norg/10.1177/0267323116682802.\nFishkin, R. (2018). SparkToro\u2019s new tool to uncover real vs. fake followers on Twitter, \nSparkToro. https://sparktoro.com/blog/sparktoros-new-tool-to-uncover-real-\nvs-fake-followers-on-twitter/.\nGroshek, J. and Koc-Michalska, K. (2017). Helping populism win? Social media use, \nfilter bubbles, and support for populist presidential candidates in the 2016 U.S. \nElection Campaign. Information, Communication & Society, 20 (9), 1389\u2013407. \nhttps://doi.org/10.1080/1369118X.2017.1329334.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\nKarpf, D. Digital politics after Trump. Annals of the International Communication \nAssociation , 41(2), pp.\u00a0198\u2013207. https://doi.org/10.1080/23808985.2017.1316675.\nKwak, H., Lee, C., Park, H. and Moon, S. (2010). What is Twitter, a social network \nor a news media? In Proceedings of the 19th International Conference on World \nWide Web  (pp.\u00a0591\u2013600). ACM.\nMeier, F., Elsweiler, D., and Wilson, M.L. (2014). More than liking and bookmark -\ning? Towards understanding Twitter favouriting behaviour. In Proceedings of \nICWSM\u201914 . AAAI Press. http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/\npaper/view/8094.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nNiederer, S. (2019). Networked content analysis: The case of climate change. \nInstitute of Network Cultures. https://networkcultures.org/blog/publication/\ntod32-networked-content-analysis-the-case-of-climate-change/.\nO\u2019Hara, K. and Stevens, D. (2015). Echo chambers and online radicalism: Assessing \nthe internet\u2019s complicity in violent extremism. Policy & Internet, 7(4), pp.\u00a0401\u2013422. \nhttps://doi.org/10.1002/poi3.88.\n106  M aar Te n gr oen and Marloe S  ge boer S \nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nPeacock, C., Hoewe, J., Panek, E., and Willis, G. P. (2019). Hyperpartisan news use: \nRelationships with partisanship, traditional news use, and cognitive and affec -\ntive involvement. Paper presented at the Annual Conference of the International \nCommunication Association, Washington, DC.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn Weller, K., Bruns, A., Burgess, J., Mahrt, M. and Puschmann, C. (Eds.), Twitter \nand society (pp. ix-xxvi) . Peter Lang.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nSalenger, M. [meredthsalenger]. (2020, March\u00a002). \u201cReal quick: How are Republicans \nlike Donald ok with 2% of people dying from coronavirus as if 2% is not a very \nhigh number. But when you discuss a 2-cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happened to \nthem\u201d [tweet]. https://twitter.com/meredthsalenger/status/1234337053.\nShepherd, T., Harvey, A., Jordan, T., Srauy, S., and Miltner, K. (2015). Histories of \nhating. Social Media + Society. https://doi.org/10.1177/2056305115603997.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook\nStarbird, K. (2017). Examining the alternative media ecosystem through the produc -\ntion of alternative narratives of mass shooting events on Twitter. In Proceedings \nof the 11th International AAAI Conference on Web and Social Media . AAAI Press. \nhttp:/ /faculty.washington.edu/kstarbi/Alt_Narratives_ICWSM17-CameraReady.\npdf.\nSunstein, C. R. (2001). Echo chambers: Bush v. Gore, impeachment, and beyond. \nPrinceton University Press.\nTate, R. (2009, 19 Nov.). Twitter\u2019s new prompt: A linguist weighs in . Gawker . ht tps://\ngawker.com/5408768/twitters-new-prompt-a-linguist-weighs-in.\nWahl-Jorgensen, K. (2019). Emotions, media and politics. Polity.\nData availability\nhttps://doi.org/10.7910/DVN/QIJQ3X\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 107\nAbout the authors\nMaarten Groen  is a researcher and programmer at the Visual Methodologies \nCollective at the Amsterdam University of Applied Sciences. His research \nfocuses on using data to empower citizens through participatory and \ndigital methods and the analysis and visualization of the resulting data. \nHis background is in Computer and Information Science.\nMarloes Geboers , PhD, is a member of the Visual Methodologies Collective \nat the Amsterdam University of Applied Sciences and Postdoctoral Fellow \nin platform subcultures in Media Studies, University of Amsterdam. She \nresearches the affective affordances of platforms, particularly how they \nshape the visualities and narratives of war and suffering. Her educational \nbackground is in political science and journalism.\n\n6 T witter as accidental authority\nHow a platform assumed an adjudicative role during the \nCOVID-19 pandemic\nEmillie de Keulenaar, Ivan Kisjes, Rory Smith, Carina Albrecht \nand Eleonora Cappuccio1\nAbstract\nThis chapter explores Twitter\u2019s moderation of authoritative sources and \ntheir audience\u2019s claims concerning COVID-19 treatments, transmission \nand prevention techniques. It examines how they diverge over time, \nand how Twitter intervenes in resulting debates via content moderation \nguidelines and techniques. It argues that as public health organizations \nand heads of state struggle to maintain consensus among themselves \nand with their Twitter audiences on these issues Twitter exceptionally \nsteps in as an authority in its own right. It does so by flagging, suspend -\ning and deleting contents, including those of authoritative sources that \nthreaten to disrupt a common understanding of the virus and vital health \ninformation.\nKeywords: Content moderation, platform rules, sensemaking, problematic \ninformation, COVID-19 treatment\nResearch questions\nHow did claims by authoritative sources (@realDonaldTrump, @CDC, @\nNIH, @WHO and @pahowho, the North American division of the World \nHealth Organization) on COVID-19 transmission, prevention and treatments \n1 T he authors would like to acknowledge Jack Wilson and Carlo De Gaetano for their con -\ntributions to this research. Emillie de Keulenaar\u2019s participation has been supported by the \nUKRI-Canada ESRC grant, Responsible AI for inclusive, democratic societies: A cross-disciplinary \napproach to detecting and countering abusive language online (ESRC reference: ES/T012714/1).\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch06\n110  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \ndiverge from those of their audiences between March and October\u00a02020? How \ndid Twitter\u2019s content moderation guidelines and techniques for COVID-19 \nmisinformation interfere in these divergences? How did COVID-19 affect \nTwitter\u2019s overall policies on misinformation?\nEssay summary\nAs new information on the epidemiological nature of COVID-19 infections \nand its impact on public safety evolves, so do claims on which objective \nfacts constitute it (Yong, 2020). Twitter has been tasked with ensuring \nthat their users maintain a basic level of consensus around public safety \nguidelines and other information relative to personal and public health by, \nfor example, centralizing access to local health organizations and representa -\ntives, flagging and at times deleting \u201cmisleading\u201d tweets that contradict \nsuch sources (Skopeliti and John, 2020). But with diverging guidelines and \nfacts occasionally opposing even authorities\u2014notably ex-U.S. President \nTrump, the American Center for Disease Control, the National Institutes \nof Health and the World Health Organization\u2014the platform has struggled \nto determine whom to attribute ultimate authority for reliable information \nabout COVID-19 transmission, treatment and protection.\nIn this context, we find that English-speaking publics who interact with \nany of these authorities have at times been polarized around either Donald \nTrump or the World Health Organization. As these authorities contradict \neach other, we find that Twitter begins to moderate\u2014and ultimately \nsuspend\u2014authorities that disrupt the general consensus over COVID-19, \nparticularly Donald Trump. We conclude that Twitter\u2019s moderation of \nproblematic information on the virus demonstrates how the platform relies \nless on specific guidelines over what constitute true and false information \nthan on the general consensus between public health authorities.\nThese findings suggest two main implications. First, Twitter\u2019s moderation \nof authoritative sources renders the platform an authority in its own right, as \nit ultimately decides which of these authorities can and cannot govern on its \nplatform. Second, COVID-19 has pushed platform moderation of misinforma-\ntion from detecting and suppressing technically inauthentic contents to \ninformation that affects the overall consensus over what constitutes correct \ninformation, leading the platform to sanction outliers or \u201cextremes,\u201d and \nshrink its size down to a more homogeneous (and thereby cohesive) public \nsphere. Both of these implications constitute a few emerging characteristics \nof a kind of \u201cpost-Trump\u201d internet.\nTWiT T e r a S  acciden Ta l au Th ori Ty  111\nImplications\nHeads of state, health organizations and the public have been frequently \ndivided on claims around COVID-19, such as whether asymptomatic people \nand children can contaminate others, whether one should use a mask, or if \nchildren can be contagious (Iati et al., 2020; O\u2019Leary, 2020). In this context, \ngovernments and public health authorities have struggled to maintain a \nconsensus with their local publics and each other (Starbird, 2020), hurting \npublic trust in their capacities as main references about the pandemic \n(Bordia and Difonzo, 2004; Bostrom et al., 2015; Starbird et al., 2016).\nIn response, social media, search engines and encyclopedic wikis have \nbeen tasked with ensuring that their users maintain consensus around \npublic safety guidelines and other information relative to public health \n(Skopeliti and John, 2020). Since the early months of 2020, Google Web \nSearch, YouTube, Facebook, Twitter and Reddit have set up centralized \naccess points to information provided by local and global \u201cauthoritative \nsources\u201d (Skopeliti and John, 2020). Though some stakeholders continue \nto demand more radical platform redesign (Dwoskin, 2020), more mod -\nest measures include prompting local guidelines on the virus whenever \none searches or consults information about COVID-19 (Lee and Oppong, \n2020), temporarily disabling the personalization of Newsfeeds (Lyons, \n2020); flagging contents (tweets, posts, videos) that disseminate contested \nclaims (Lyons, 2020), demoting \u201cborderline\u201d or suspicious contents like \nconspiracy theories and raising \u201cauthoritative content\u201d to the top of search \nand recommendation results (De Keulenaar et al., 2021; YouTube, 2019), \nand altogether deleting materials that pose a danger to public health, such \nas anti-vaccination or alternative medication (De Keulenaar et al., 2021; \nYouTube, 2020).\nBut with information about the virus being uncertain in the early months \nof the pandemic, one wonders how a platform like Twitter has adapted \nits COVID misinformation policy to tolerate the relative contingency of \nknowledge and facts about the virus. Not only have authoritative guid -\nance on treatments and protection frequently changed, but they have also \ncontradicted each other. Guidance by the World Health Organization, favored \nby nearly all social media platforms, at times differed from what the Centers \nfor Disease and Control Prevention, the NIH and then-U.S. President Donald \nTrump advised. While such discordances are to be expected, we assume \nthat it has at times created a crisis of authority in the platform\u2014a \u201cstate of \nexception\u201d (Schmitt, 2005)\u2014that has pushed Twitter to take exceptional \nmeasures to maintain a baseline of consensus in its platform.\n112  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nDrawing partly from studies on collective sensemaking and rumors \n(Caplow, 1946; Dailey and Starbird, 2015; Krafft et al., 2017; Shibutani, \n1966), we use close reading and natural language processing techniques \nto measure the relative divergence of authoritative and \u201caudience\u201d claims \nabout COVID transmission, prevention and treatments. Authoritative \nsources include international and U.S. representatives and public health \norganizations, with claims released on Twitter and their respective websites, \nand their \u201caudiences,\u201d defined here as the users who have at some point \nengaged with or referred to the former on Twitter. Our dataset contained \n250 million tweets that mention #covid or #coronavirus between March \nand October of 2020. Authoritative sources include then-U.S. President \nDonald Trump, the Centers for Disease Control and Prevention, the National \nInstitutes of Health, and the World Health Organization\u2019s International and \nRegional Office for the Americas. Using the Wayback Machine (Internet \nArchive, 2021), we then examine how Twitter adapted its content modera -\ntion techniques to moderate COVID-19 misinformation. We capture Twitter \nmoderation data for each of the tweets in our dataset using Selenium, a \nweb interface scraper, obtaining labels, suspensions and other removal \ndisclaimers.\nWe find that the pandemic has pushed Twitter and its platform counter -\nparts to delimit what \u201cmisinformation\u201d or other problematic information \nis, be it in a technical, authoritative or even rhetorical sense. Determining \nthe objective value of statements on COVID-19 treatments, prevention \nand transmission vehicles, however, is not a responsibility the platform \ninitially embraces. Its preference is to relay that decision to \u201cauthoritative \nsources,\u201d a solution already set by other platforms to prioritize authoritative \ncontents as \u201creputed\u201d or \u201ctrustworthy\u201d sources, despite mixed reactions \nfrom users suspicious of \u201cpolitical bias\u201d in favor of left-wing American \npolitical culture (Economist, 2019). This study also shows mixed results. \nThe absence of consensus among authoritative sources makes the 2020 \nU.S. (and international) crisis of authority on COVID-19 even more evident, \nwith the WHO, CDC, NIV and the White House contradicting one another. \nThe difference, we find, is that in the absence of authority, Twitter steps in \nas an authority itself.\nConsensus and misinformation in the process of COVID-19 \nsensemaking: Conceptual implications\nA number of misinformation policies and studies have focused on detecting \nand correcting misinformation by (for example) investing in media literacy \nTWiT T e r a S  acciden Ta l au Th ori Ty  113\nand pinpointing factors that can \u201cincrease the chances of citizens to be \nexposed to correct(ive) information\u201d (Scheufele and Krause, 2019, p.\u00a07664). \nStrategies include removing false content and demoting false or \u201cborderline\u201d \ninformation in favor of authoritative sources (Scheufele and Krause, 2019, \np.\u00a07664).\nA possible drawback of these strategies is the decontextualization of \nmisinformed claims from the premises and info spheres that substantiate \nthem. These spheres are frequently outside of misinformation-policed \nsocial media platforms (De Zeeuw et al., 2020), and their users may be \nunaware of the information needed to understand claims and directives from \nauthoritative sources (Kou et al., 2017). In other instances, misinformative \nclaims can come from more innocuous misunderstandings (De Zeeuw et \nal., 2020), or attempts at making sense of situations still unexplained by \nauthorities (Krafft et al., 2017, p.\u00a02976; Starbird et al., 2016). The inconsistency \nof official information is characteristic of the formation of rumors and other \n\u201cimprovised\u201d sensemaking (Shibutani, 1966), which in themselves constitute \nan attempt to create consensus or a \u201ccommon understanding\u201d where there \nis none (Bordia and Difonzo, 2004).\nIn this sense, we join a field of study that approaches misinformation as \na dynamic by-product of poor consensus between information providers \nand recipients\u2014authoritative sources and their audiences\u2014who must in \ncrises \u201cconverge\u201d around a common understanding of facts and the epistemic \nframeworks used to validate them (Scheufele and Krause, 2019, p.\u00a07663; \nStarbird, 2012, p.\u00a01). By pinpointing information that authoritative sources \nand their audiences mutually ignore and comparing diverging claims related \nto these terms,2 we find that authoritative sources and their audiences do \nnot always focus on the same aspects of COVID-19, nor do audiences always \nrely on the same authoritative sources.\nFrom misinformative to misleading tweets: How COVID affected \nTwitter\u2019s moderation of \u201cproblematic information\u201d\nOver the course of 2020, Twitter adapted its anti-misinformation content \nmoderation policies significantly. Twitter\u2019s initial approach to manag -\ning COVID-19 misinformation on its platform piggy-backed on existing \npolicies that targeted inauthentic user behavior. In early February\u00a02020, \nthe platform targeted COVID misinformation as deceitful contents, or \n2 F or example, audiences mention \u201c5G\u201d and \u201cfood\u201d as transmission vectors, while authoritative \nsources focus on \u201ccough\u201d and \u201ctouch.\u201d\n114  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \ndisinformation: doctored footage or photography, or contents forged with \nthe intention to mislead other users (Twitter, 2020). It uses the World \nHealth Organization as a reference from which to determine whether a \ntweet is false or not. This requires heavy-handed, top-down measures to \nremove tweets that contradict such authorities before they can spread \non the platform.\nAs the pandemic began to spread globally, however, it became clear \nthat existing conceptions of disinformation do not capture the fact that \nCOVID-19 is also the subject of widely diverging and contingent information. \nIt becomes difficult, arguably impossible, for the \u201cauthoritative sources\u201d \nTwitter recommends delivering stable facts and guidelines on the virus. On \nthe one hand, this leads Twitter to fine-tune its definition of misinformation \ndown to the level of the rhetoric of a tweet. This includes both what a tweet \nclaims and how  it claims it. On the other, Twitter also broadens its definition \nof misinformation as a problem of consensus. It recognizes that information \nabout the virus, even when provided by authoritative sources, is subject to \ndisagreements and change.\nRather than resorting merely to deletion, it seeks to reinforce a consensus \non guidelines and facts about the virus by centralizing users\u2019 access to COVID \ninformation. It wants to ensure that users comment on the virus within \ndelimited epistemic boundaries of what can and cannot be entrusted to \nbe true. The delimitation of those perimeters is an arbitration outsourced \nto local, legislative and medical authorities: those tasked with deciding \nthe truth about the virus. This means pointing users to local authorita -\ntive sources\u2019 websites on tweets that mention the virus or adding links \nto national or state-level guidelines on newsfeeds and homepages. These \nmeasures\u2014exemplified by the early #KnowTheFacts prompt\u2014would help \nfill in possible \u201cdata voids\u201d (Golebiewski and boyd, 2019) between authorita -\ntive sources and their audiences.\nTwitter as an accidental authority\nStill, trouble comes when authoritative sources begin to contradict one \nanother around mask usage, hydroxychloroquine treatments or airborne \nviral transmission. In such cases, Twitter does not favor one or another public \nhealth authority but does at times moderate authorities that disrupt their \noverall consensus. Ex-U.S. President Donald Trump\u2019s analogies of COVID \nand seasonal flu, or the merits of hydroxychloroquine-based treatments, \ncontradict and confuse statements by the CDC and NIH. His tweets are \nflagged, counter-balanced by resources Twitter recommends users consult \nTWiT T e r a S  acciden Ta l au Th ori Ty  115\ninstead. Though the first tweet it suspended was sanctioned for violating \nits \u201cglorification of violence\u201d policy, Trump\u2019s tweets on COVID are nearly \nalways labeled by default.\nThe decision to moderate authorities appears to mark a shift between \nredirecting users towards trust-worthy sources of information to curating \nsuch sources relative to their capacity to maintain a greater consensus \namongst other relevant authorities. In this sense, Twitter is no longer mod -\nerating tweets individually, but as a larger ensemble of statements whose \noverall consensus constitutes the objective quality of COVID information. \nTechnically, moderating consensus rather than single falsehoods grants \nTwitter significant institutional responsibilities. As it optimizes the relative \nproportion of public safety and consensus, Twitter accidentally becomes an \n\u201cauthoritative source\u201d\u2014or authority, for short\u2014in its own right.\nTwitter\u2019s moderation of existing authorities speaks to a number of foun -\ndational concepts of political theory, among which is Carl Schmitt\u2019s famed \nphrase that the \u201csovereign\u201d is \u201cthat which decides the state of exception\u201d \n(Schmitt, 1932). As consensus wanes among existing authorities in a given \nbody politic and crisis sets in, the one who will hold ultimate authority is \nthat who intervenes and decides for those in this sphere regardless of the \nlegality of their actions. It is not so much Twitter\u2019s content moderation \npolicies that legitimize its moderation of authoritative sources, but its very \nability to do so regardless of existing conventions.\nFindings\nFinding 1: Authoritative sources and their audiences contradict each \nother most on undetermined facts, such as COVID-19 treatments. As may \nbe expected, audiences and authoritative sources diverge most around \nunconfirmed information. There were no single, confirmed treatments \nfor COVID-19 until the announcement of the Pfizer vaccine in August of \n2020. Despite declaring that \u201cno treatment\u201d and \u201cvaccines\u201d were available by January, authoritative sources like the World Health Organization and \nthe CDC fail to prevent their audiences from contemplating a plethora of \ntreatments ranging from house-grown remedies and specialized medicines \n(see Figure\u00a06.1), be it vitamin C, ethanol, zinc or remdesivir.\nIn this context, authoritative sources act primarily as debunkers of \nunconfirmed or false information. The World Health Organization opens \na page dedicated to debunking false ingredients reported on social media. From January, it debunks nearly half of the ingredients discussed by their \n116  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nMar 23 2020\nApr 06 2020\nApr 20 2020\nMay 04 2020\nMay 18 2020\nJun 01 2020\nJun 15 2020\nJun 29 2020\nJul 13 202O\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 07 2020\nSep 21 2020\nOct 05 2020\naspirin\nazithromycin\nbiocharger\ncannabis\ncbd oil\nchlorine dioxide\nchloroquine\ncocaine\ncolloidal silver\ncow dung\ncow urine\ndexamethasone\ndietary supplement\ndurian\nessential oil\nethanol\nhoney\nlemon grass\nmango\nmethanol\nmineral\nnasal spray\nno cure\nno drug\nno treatment\nno vaccine\nremdesivir\nsaline\nsalt water\nsnake oil\nsupplemental oxygen\nsupportive care\ntamiflu\ntoothpaste\nturmeric\nvinegar\nvitamin c\nvitamin d\nwudu\n1,0\n1,051\n2,102\nApr 06 2020\nMay 04 202O\nJun 22 2020\nAug 10 2020\nSep 07 2020\nOct 05 2020\ndexamethasone\nethanol\nmethanol\nmineral\nremdesivirTimes a word is mentioned\n35,225 total mentions\n496,166 tweets98 total mentions\n910 tweetsCOVID-19 treatments mentioned by audiences (right) and authoritative sources (left), March 23 2020 - October 12 2020\nfi gure\u00a06.1 he atmap of forms of coVi d- 19 treatment mentioned by authoritative sources (tweets \nand website data) and their Twitter audiences (tweet replies and mentions of website domains by \nauthoritative sources, e.g., whitehouse.gov). Visualization by \nem\nillie de Keulenaar and \nel\neonora \nc\nappuccio.\nTWiT T e r a S  acciden Ta l au Th ori Ty  117\naudiences: ethanol, honey, lemon, cannabis, cocaine, colloidal silver, lopi -\nnavir and others (see Figure\u00a06.2).\nElsewhere, authoritative claims also express uncertainty on transmission, \ntreatments and prevention, stressing the uncertain nature of research on \nCOVID-19 (Bostrom et al., 2015, p.\u00a0633). This can be said about chloroquine, \nhydroxychloroquine, remdesivir, dexamethasone, prednisolone and Tamiflu, \nabout which authoritative sources mention ongoing research and testing. This \ndoes not prevent audiences from continuing to engage with these ingredients.\nFinding 2: Audiences are divided around contradicting claims by au-\nthoritative sources. Zooming into authoritative and audience claims on \nthe efficacy of hydroxychloroquine, we see that audiences (below, \u201cusers\u201d) \nappear to polarize around diverging authoritative statements. While some \necho Donald Trump\u2019s claims that the ingredient is effective (including in \ncombination with azithromycin), others relay the World Health Organiza -\ntion\u2019s claim that it is not. A small majority state the same claim as the CDC \nand the NIH who rule the matter as still \u201cuncertain.\u201d\nThe same can be said about modes of transmission. In the early months \nof the pandemic, authoritative sources and their audiences usually referred \nTreatment\nalcohol\n1\n0\nantibiotic\n1\n0\nbath\n1\n0\nblack pepper\n1\n0\nbleach\n1\n0\nchlorine\n1\n0\nchloroquine\n1\n0\n2\n0\ncold weather\n1\n0\nconvalescent plasma\n1\n0\ndisinfectant\n1\n0\ndryer\n1\n0\nethanol\n1\n0\ngarlic\n1\n0\nhydroxychloroquine\n1\n0\n2\n0\nhydroxychloroquine and azithromycin\n1\n0\n1\n0\nhyperimmune immunoglobulin\n1\n0\ninfluenza complex\n1\n0\nInterferons\n1\n0\nInterleukin-1 inhibitors\n1\n0\nInterleukin-6 inhibitors\n1\n0\nJanus kinase inhibitors\n1\n0\nlopinavir\n1\n0\nmineral\n1\n0\nno vaccine\n1\n0\n1\n0\nremdesivir\n1\n0\nsaline\n1\n0\nsesame oil\n1\n0\nsunlight\n1\n0\n1\n0\nuvc\n1\n0\n1\n0\nvitamin c\n1\n0\nvitamin d\n1\n0\nwarm weather\n1\n0\n1\n0\nzinc\n1\n0\nDebunk\nDisputed\nAuthoritative sourcesfi gure\u00a06.2 he atmap of authoritative clams on coVi d- 19 treatments. Purple values count as \nauthoritative debunks of audience claims; blue values indicate instances in which authoritative \nhave framed a given treatment as disputed. Visualization by \nca\nrlo \nga\netano.\n118  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nto different modes of COVID-19 transmission. Audiences do focus on modes \nof transmission mentioned by authoritative sources: (respiratory) droplets, \nclose contact, community spread, coughing, sneezing and touch. Here, too, \nauthoritative sources act as debunkers: 5G is dismissed at least twice after \ngaining considerable traction among audiences in March.\nThe caveat, here, is that audiences continue to focus on modes of trans -\nmission disputed among authoritative sources (see Figure\u00a06.4). With little \nscientific consensus on the minutiae of droplet transmissions, there is notable \npublic confusion on the airborne nature of the virus (Achenbach and Johnson, \n2020; Lewis, 2020; Mandavilli, 2020). The World Health Organization expresses \nuncertainty about airborne transmission throughout February, then later \njoins the U.S. Centers for Disease Control and Prevention in March to affirm \nthat it spreads mainly via droplets. Only in April\u00a02020 does the CDC offer a \nverdict: \u201caccording to experts,\u201d it says, \u201cthe virus can be transmitted by both \ndroplets and smaller, \u2018aerosol\u2019 types of particles\u201d (Centers for Disease Control \nand Prevention, 2020). While the World Health Organization rejects this claim, \na slight majority of users echoes the CDC\u2019s statement well until October.\nIn this context, audiences express a relatively constant amount of un -\ncertainty throughout, as well as conspiratorial suspicions in early March. \nFEBRUARY\nMARCH\nAPRIL\nMAY\nJUNE\nJULY\nAUGUST\nSEPTEMBER\nOCTOBER\nFEBRUARY\nMARCH\nAPRIL\nMAY\nJUNE\nJULY\nAUGUST\nSEPTEMBER\nOCTOBERamount of claims\namount of moderated claimsUsers\nAuthoritative sources\n@RealDonaldTrump\nwho.int\ncdc.gov nih.gov\nyes\nno\nyes, in combination with azithromycinIs hydroxychloroquine \neffective against COVID-19?\nuncertain\nfi gure\u00a06.3 be e swarm of authoritative and audience claims on whether hydroxychloroquine is or is \nnot effective against \ncoVi\nd-\n19 infections. Visualization by \nca\nrlo de \nga\netano.\nTWiT T e r a S  acciden Ta l au Th ori Ty  119\nMar 23 2020\nApr 06 2020\nApr 20 2020\nMay 04 2020\nMay 18 2020\nJun 01 2020\nJun 15 2020\nJun 29 2020\nJul 13 2020\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 07 2020\nSep 21 2020\nOct 05 2020\n5g\nairborne\nasymptomatic people\nblood transfusion\nbreast milk\nclose contact\ncommunity spread\ncoughing\ndirect contact\ndroplet nuclei\ndroplets\nelectromagnetic\nfecal transmission\nfecal-oral transmission\nfomites\nindirect contact\nintimate contact\nkissing\nmicrochip\nmosquito\noral transmission\npetrol\nphysical contact\nradiation\nrespiratory droplets\nsaliva\nsneezing\nsputum\ntick\ntouch\nwet particles\nwireless\n1\n1,051\n2,102\nMar 30 2020\nApr 27 2020\nMay 11 2020\nJun 01 2020\nJun 22 2020\nJul 13 2020\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 14 2020\nSep 28 2020\nOct 12 2020\n5g\nairborne\nasymptomatic people\nbreast milk\nclose contact\ncommunity spread\ncoughing\ndroplets\nelectromagnetic\nmosquito\nrespiratory droplets\nsaliva\nsneezing\ntick\ntouch\nTimes a word is mentioned\n32,230 total mentions\n496,166 tweetsTypes of transmission mentioned by authoritative sources (down) and \ntheir Twitter audiences (up), March 23 2020 - October 12 2020\n20 total mentions\n910 tweets\nfi gure\u00a06.4 he atmap of modes of transmission mentioned by authoritative sources (tweets and \nwebsites) and their Twitter audiences (tweet replies and mentions of website domains by authorita -\ntive sources, e.g., whitehouse.gov). Visualization by \nem\nillie de Keulenaar and \nel\neonora \nca\nppuccio.\n120  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nWhile this is especially applicable in the months of February and March, \naudiences appear to express a relatively constant amount of claims aligned \nwith the majority of authoritative sources. This may suggest that more \nconsensus between  authoritative sources could foster consensus among \ntheir publics.\nThere is further disagreement on whether COVID-19 is transmitted \nthrough droplets or smaller aerosol particles (see Figure\u00a06.5). While virtually \nall sources agree that the virus is transmitted by the former, some specify \nthat aerosols may remain in the air for longer periods of time. The World \nIs COVID-19 airborne? \n2342 -\n0 @whowpro \nFACT: #COVID19 is NOT airborne. \nThe #coronavirus is mainly transmitted \nthrough droplets generated when an \ninfected person coughs. sneezes or speaks. \nwhitehouse.gov \nyes whitehouse.gov \nyes \n57 -\n0 \n12 who.int conspiratorial \nclaims \nwho.int \nuncertain uncertain \nI \nFebruary March \nWeb domains: who.int, whitehouse.gov. cdc.gov and nih.gov I \nApril \nTweet replies for@who, @whitehouse, @cdc, @RealDonaldTrump and @nih \nTweets mentioning websites of authoritative sources who.int \n\ufffd within 1 meter \ncdc.gov\nunlikely\nI \nMay Key \n\u25a0 No\u25a0 Yes\n\u25a0 Uncertain \nI \nJune July \nfi gure\u00a06.5 li ne graph of audience and authoritative statements about whether coVi d- 19 is \nairborne or not. Visualization by \nele\nonora \nc\nappuccio and \nem\nillie de Keulenaar.\nTWiT T e r a S  acciden Ta l au Th ori Ty  121\nHealth Organization\u2019s expressions of doubt regarding the latter claim is \nquickly contradicted by the White House. Audiences express an equally \ndistributed amount of agreement with each claim, seemingly partitioned \ninto groups that either rely on the word of the World Health Organization or that of the White House.\nThe debate on whether the virus is droplet or aerosol airborne shows how \npopular understandings of viral transmission appear to have evolved through \ndiscussions between authoritative sources and audiences. Early public \ndoubts about whether the virus was airborne have prompted authorities to \ndefine and measure airborne transmission in increasingly concrete terms \n(see Figure\u00a06.6). While the World Health Organization had stated earlier \nthat airborne transmission is an exchange of infected droplets, recent \nfindings on aerosol transmission substantiate earlier public conceptions \nof airborne transmission as a somewhat ubiquitous form of \u201cair infection\u201d (Mandavilli, 2020).\nFinding 3: Twitter has adapted its content moderation policies to capture \nthe disputed nature of COVID-19 information. In the face of such disputes, \nTwitter\u2019s \u201cCOVID-19 misleading information\u201d policy underwent frequent changes throughout 2020 (see Figure\u00a06.7). On February\u00a04, 2020, Twitter\u2019s \ninitial definition of COVID-19 misinformation is based on a conception \nfi gure\u00a06.6 li ne graph of claims on droplet or aerosol transmission by authoritative sources \n(web domains) and their Twitter audiences (tweet replies and mentions of website domains by \nauthoritative sources, e.g., whitehouse.gov). Visualisation by \nele\nonora \nc\nappuccio and \nem\nillie de \nKeulenaar.\n122  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nof misinformation as deceit, be that in the intent of its author (\u201cmedia \nshared in a deceptive manner\u201d) or in its technical composition (\u201csynthetic \nor manipulated media\u201d on the virus) (Chu and McDonald, 2020). This \ndefinition follows existing conceptions of misinformation as disinforma -\ntion, or as semantically or technically inauthentic. Examples of the former \ninclude \u201ca deliberate intent to deceive people about the nature or origin \nof the content,\u201d and for the latter, \u201ccontent that has been substantially \nedited in a manner that fundamentally alters its composition, sequence, \ntiming, or framing,\u201d \u201cany visual or auditory information that has been \nadded or removed,\u201d and \u201cfabricated or simulated media depicting a real \nperson\u201d (Twitter, 2020a). Both of these types of information are subjected \nto an incremental type of moderation, where they are first labeled, de -\nmoted and altogether removed after infringing misinformation policies \nmore than once (Roth and Pickels, 2020). Twitter\u2019s policy against COVID \nmisinformation as \u201cmanipulated media\u201d is sealed with a general \u201czero \ntolerance approach to platform manipulation,\u201d announced in March\u00a04, \n2020 (Twitter, 2020b).\nAs the virus disseminates outside of China in early March, Twitter broad -\nens its conception of COVID-19 misinformation as contradicting local and \ninternational \u201cauthoritative sources\u201d (Twitter, 2020b). The idea, then, is to establish a baseline of facts about the virus with which to moderate user-\ngenerated contents. Content moderation targets content that may contradict \nwhat is known and stated by authoritative sources. This includes \u201cdenial of \nglobal or local health authority recommendations to decrease someone\u2019s \nlikelihood of exposure to COVID-19\u201d; \u201cdenial of established scientific facts \nabout transmission during the incubation period or transmission guidance \nfrom global and local health authorities\u201d; and \u201calleged cures for COVID-19 that are not immediately harmful but are known to be ineffective\u201d (Twit -\nter, 2020b). To reinforce this policy, Twitter prioritizes posts by the World \nHealth Organization and local health organizations in users\u2019 homepages and \npersonal timelines. From January\u00a029, 2020, Twitter also launches a series of \nlabeling techniques to redirect users towards claims by authoritative sources \non the transmission, protection and treatment of the virus. Contradictions \nto these claims are first labeled and then removed (see Figure\u00a06.6) (Twitter, \n2020b).\nThe fact that authoritative sources occasionally disagree with each other \nposes a new challenge to existing COVID policies. For this reason, content \nmoderation guidelines adopt a two-fold strategy: they simultaneously \nrestrict the kind of claims users can make about COVID-19 transmission, \nprevention and treatments, and highlight the disputed nature of such \nTWiT T e r a S  acciden Ta l au Th ori Ty  123\nclaims. The idea is to adapt moderation to the contingent and disputed \nnature of various information about the disease, be they international \ndiscrepancies in public health policies or diverging claims made by au-\nthoritative sources about the virus. As did other platforms (e.g., Google \nand Facebook), it also creates a flag prompt (\u201c#KnowTheFacts\u201d) whenever \nusers search or encounter information about the virus on the platform (Chu \nand McDonald, 2020). By May\u00a011, it introduces new labeling and warning \ntechniques intended to \u201cprovide additional context and information on \nsome tweets containing disputed or misleading information related to \nCOVID-19\u201d (Twitter, 2020c).\nLater, on December\u00a016, 2020, Twitter goes as far as to specify the type \nof rhetoric that infringes upon its COVID-19 misinformation policy. \nIt targets tweets that \u201cadvance a claim of fact, expressed in definite \nterms\u201d and later \u201ctweets that are an assertion of fact (not an opinion), \nexpressed definitely, and intended to influence others\u2019 behavior\u201d (Twit -\nter, 2020d). Misleading statements on \u201cvaccines\u201d consist in spreading \n\u201cpreventative measures that are not approved by health authorities, \nor that are approved by health authorities but not safe to administer \nfrom home\u201d; \u201cthe sale or facilitation of medicines or drugs that require \na prescription or physician consultation\u201d; or information on \u201cadverse \nimpacts or effects of receiving vaccinations, where these claims have been \nwidely debunked\u201d (Twitter, 2020d). It targets conspiratorial language, \nlabeling tweets \u201cwhich suggest that COVID-19 vaccinations are part of a \ndeliberate or intentional attempt to cause harm or control populations\u201d \n(Twitter, 2020d). It reinforces consent to local authoritative guidelines by \ntargeting tweets that dispute \u201clocal or national advisories or mandates \npertaining to curfews, lockdowns, travel restrictions, quarantine proto -\ncols, inoculations \u2026,\u201d and even targets tweets about \u201cresearch findings \n(such as misrepresentations of or unsubstantiated conclusions about \nstatistical data) used to advance a specific narrative that diminishes the \nsignificance of the disease.\u201d Once again, all of the above is first labeled, \nand then removed (Twitter, 2020d).\nFinding 4: Twitter acts as a debunking system. In practice, this means \nlabeling almost every tweet that mentions a COVID-19 treatment ingredient \ndisputed by authoritative sources (see Figure\u00a06.8). Though some are deleted, \nmost are simply flagged and redirected to a centralized reference page on \nlocal COVID-19 guidelines and information. This also applies to claims dis -\nputed amongst authoritative sources, such as whether hydroxychloroquine \nis or is not a safe drug.\n124  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nCovid-19 misleading information policy\nJanuary 29, 2020\nF\nebruary 4, 2020\nMarch 4, 2020\nZero tolerance approach to platform manipulation\nApril 11, 2020\nMay 11, 2020\nType of rhetoric\nMedia shared in a deceptive manner\nMarch 16, 2020\nJuly 14, 2020\nInformation that may increase the likelihood \nof exposure to the virus\nInformation that may have adverse effects \non the public health system\u2019s capacity to \ncope with the crisis\nDec 16, 2020\nFalse of misleading affiliation\nCounterspeech\nPersonal anectodes or first-person accounts\nPublic debate about the advancement of \nCOVID-19 science and research\nCOVID-19 #KnowTheFacts search prompt launched\n#KNOWTHEFACTS LABEL\nSynthetic or manipulated media\nREMOVAL\nLABEL\nWARNING\nDEMOTION\nREMOVAL\nLABEL\nWARNING\nDEMOTION\nBroadened definition of \n\u201c\nharm\n\u201d\nLABEL\nREMOVAL\nUnverified claims that have the potential to incite\npeople to action, could lead to the destruction or\ndamage of critical infrastructures, or cause \nwidespread panic or social unrest\nSUSPENSION\nNew labels and warning images\nLABEL\nTweets that are an assertion of fact (not an option),\nexpressed definitely, and intended to influence\nothers\u2019 behavior\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nFalse or misleading information about the nature \nof the virus\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nFalse or misleading information about the efficacy\nand/or safety of preventative measures, \ntreatments, or other precautions to mitigate or \ntreat the disease\nLABEL\nREMOVAL\nStrong commentary, opinions, and/or satire\nALLOWED\nALLOWED\nALLOWED\nALLOWED\nfi gure\u00a06.7 Timeline of Twitter\u2019s \u201c c oVi d- 19 \nmisleading information policy.\u201d Source \nin image. Visualization by \nem\nillie de \nKeulenaar, with previous contributions by \ngu\nilherme \nap\npolin\u00e1rio.\nTWiT T e r a S  acciden Ta l au Th ori Ty  125\nfi gure\u00a06.8 he atmap of audience tweets that mention a list of treatments for coVi d- 19. in g reen are \nnumbers of unmoderated tweets; in red, moderated tweets. Visualization by \nca\nrlo \nga\netano.\n126  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nfi gure\u00a06.9 be e swarm of Twitter labels for tweets mentioning coVi d  \ntransmission, prevention and treatment. Visualization by \nemi\nllie de \nKeulenaar.\nTWiT T e r a S  acciden Ta l au Th ori Ty  127\nfi gure\u00a06.10 be e swarm of moderated audience and Trump tweets mentioning words related to \nc\noVi\nd-\n19 treatments, transmission and prevention. \nev\nery dot is one or many tweets posted in a \ngiven day. Visualization by \nemi\nllie de Keulenaar.\n128  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nIt also means supporting authoritative sources in their continuous debunk -\ning of user claims (Figure\u00a06.9). Authoritative sources\u2014the World Health \nOrganization, in particular\u2014repeatedly deny claims made on social media.\nFinding 5: In the absence of consensus between authoritative sources, \nTwitter intervenes as an authority in its own right. At issue is that disagree -\nments amongst authoritative sources create a crisis of authority on the \nplatform. Twitter can no longer redirect users to one specific source. In \nthe absence of consensus among authorities, Twitter begins to highlight \nthe disputed nature of even authoritative claims (see Figure\u00a06.10). This \napplies particularly to U.S. President Donald Trump\u2019s private account. While \naudience tweets are more severely moderated (suspended, deleted), Trump\u2019s \ntweets initially obtain the \u201c#KnowTheFacts\u201d prompt the platform introduced \nin January\u00a029th (see Figure\u00a06.7). Reuniting several other authoritative sources, \nthis prompt is intended to display current consensus among a majority of \nauthoritative sources, including \u201ctrusted news sources\u201d (Twitter, 2020c). \nAs Trump alleges that \u201csometimes over 100,000\u201d people \u201cdie from the Flu\u201d \nin October, Twitter flags it for violating \u201cthe Twitter Rules about spreading \nmisleading and potentially harmful information related to COVID-19.\u201d The \nsame happens to a later tweet claiming immunity from COVID-19.\nBoth of them do stay up, in accordance with Twitter\u2019s \u201cWorld leaders\u201d and \n\u201cPublic-interest exceptions\u201d policies (Twitter, 2019), until Trump\u2019s account is \npermanently suspended for violating a separate policy designed to prevent \n\u201cglorification of violence\u201d (Twitter, 2021) .\nMethods\nThe methodology of this study is two-fold. Based on a collection of millions \nof tweets, we first parse, analyze and visualize diverging claims on COVID-19 \ntransmission, prevention and treatments between U.S. authoritative sources \nand their respective audiences. We then look at how Twitter moderated \ndisputed claims by first consulting content moderation policies designed \nfor COVID-19 misinformation, and then obtaining moderation metadata \nfrom tweets containing disputed contents.\nDefinitions\nThe U.S. has at least two channels responsible for communicating authorita -\ntive information on COVID-19: its head of state and its health departments \nor disease prevention agencies (See Table\u00a06.1 in Annex). Because Twitter \nTWiT T e r a S  acciden Ta l au Th ori Ty  129\nprioritizes the World Health Organization as an authoritative source, we also \ncaptured data from that organization\u2019s international and American offices. \nWe refer to heads of state and public health organizations as \u201cauthoritative \nsources,\u201d and the WHO, health ministries, departments and disease preven -\ntion agencies as \u201cpublic health organizations.\u201d By \u201caudiences,\u201d we refer to \nusers who have at some point interacted with any one of the authoritative \nsources on our list, be it by replying, mentioning them or their website \ndomains (e.g., whitehouse.org).\nBy \u201cclaims\u201d about the coronavirus, we mean information that can be \nconfirmed as true or refuted as false by governments and health organiza -\ntions. We focused on how the virus is transmitted, available treatments, \nand preventive methods.\nData collectionFor data collection on Twitter, we used Borra and Rieder\u2019s Twitter Capture \nand Analysis Toolkit, which collects tweets based on a chosen set of queries \n(Borra and Rieder, 2014). These queries were \u201ccovid,\u201d \u201ccoronavirus\u201d and \n\u201cWuhanVirus\u201d and captured a total of 61,498,037 tweets from January\u00a026 to \nOctober\u00a02020. Of those, we extracted 910 tweets from government and public \nhealth organizations and 496,166 replies and mentions of official domains. \nIn addition to tweets, we also collected claims on COVID-19 transmission, \nprevention and treatment by the CDC, NIV and Donald Trump\u2019s administra -\ntion on their official websites (cdc.gov, nih.org, whitehouse.gov). Information \non Twitter\u2019s COVID-19 misinformation moderation policies came primarily \nfrom two sources: Twitter\u2019s blog on COVID-19 and its \u201cCOVID-19 Misleading \nInformation Policy.\u201d From these, we were able to note what information they \ntarget and how they moderate it (suspension, labeling, deletion, etc.). We \nthen obtained moderation metadata from tweets that mentioned disputed \nclaims by using Selenium, the web scraping application.Parsing claims inductively and deductivelyTo map divergences in government, public health organization and \u201caudi -\nence\u201d statements about COVID-19, we sought to capture and compare the \nwidest possible range of claims about the transmission, prevention and \ntreatment of the virus. We captured both true and false statements with \nboth deductive and inductive approaches. The deductive approach consisted \nin consulting secondary sources on COVID-19 misinformation, such as \nWikipedia (Table\u00a06.1 in Annex). The inductive approach consisted in manual \n130  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nand semi-automatic capture of claims. This involved reading tweets and \n(authoritative or official) websites that contained the words \u201ctransmission,\u201d \n\u201cprevention\u201d or \u201cprotection\u201d and \u201ctreatment\u201d or \u201ccure.\u201d We also generated \nword embeddings and bigrams for the queries \u201ctransmission,\u201d \u201cprevention\u201d \nor \u201cprotection\u201d and \u201ctreatments\u201d or \u201ccure\u201d to find other relevant terms. We \nobtained a total of 48 words for transmission, 83 for treatments (2,739 with \nmedications extracted from drugbank.ca) and 79 for prevention (Table\u00a06.2 \nin Annex).\nCoding and filtering claims in tweets and official websitesWe split and detected sentences per topic as follows:\n1. Transmission: sentences mentioning \u201cinfect,\u201d \u201ctransmi,\u201d \u201ctransfer,\u201d \u201ccontag,\u201d \n\u201ccontamin,\u201d \u201ccatch,\u201d or \u201cspread\u201d;\n2. Prevention: sentences mentioning \u201cprevent,\u201d \u201cprotect\u201d; and3. Treatment: sentences mentioning \u201ctreatment,\u201d \u201ccure\u201d and \u201cvaccine.\u201d\nFor more complex queries such as whether the virus is airborne or whether \none should wear masks, we manually coded every sentence that mentioned \nboth \u201cwear\u201d and \u201cmask\u201d for the masks query and \u201cairborne\u201d and either \n\u201caerosol\u201d or \u201cdroplet\u201d for the \u201cairborne\u201d query. For sentences mentioning \nCOVID-19 transmission, coding meant annotating claims that (1) the virus \nis or is not airborne, and more specifically that (2) it spread through droplets \nor aerosols. For those mentioning protection, it implied annotating claims \nthat (1) the general public should and should not wear masks (\u201cshould wear,\u201d \n\u201cshould not wear,\u201d respectively) and (2) who should be wearing masks \n(caregivers, essential workers, travelers\u2026). In many cases, claims were far beyond simple binaries, and if frequent, required a category of their own.\nWe then manually coded the information retrieved from government \nand health authorities\u2019 official webpages on whether they provided any \ninstructions or claims about transmission, treatments and use of masks \nthat were inconsistent among them. We used the Internet Archive to track \nchanges in the information in these webpages from January\u00a02020 to July\u00a02020. \nFor each page with any information about transmission, treatments or use \nof masks, we coded them by date of change accordingly. For transmission, we coded if they agree if the transmission is possible through airborne or \naerosol, contact, droplet, fluid or animals. For treatments, we coded if they \nrecommend chloroquine, hydroxychloroquine or ibuprofen. For masks, we \ncoded if they recommend wearing a mask or face-covering in public, wear a mask if one has symptoms, or wear a mask if around sick people.\nTWiT T e r a S  acciden Ta l au Th ori Ty  131\nCoding and filtering claims in social media textual data: Limitations\nTwitter audience responses contain a large number of retweets of claims \nmade by authoritative sources. Because of this, we also included tweets that \ndo not necessarily reply or mention authoritative sources but are geolocated \nin the U.S. Geolocation is included in TCAT\u2019s tweet metadata.\nModeration data\nModeration status and labels for the 4.2 million relevant tweets (i.e., by \nauthoritative sources or audiences, and containing any of our keywords) \nwere gathered using web scraping (Selenium).\nReferences\nAchenbach, J. and Johnson, C. Y. (2020, April\u00a030). Studies leave question of \u201cair -\nborne\u201d coronavirus transmission unanswered. Washington Post . https://www.\nwashingtonpost.com/health/2020/04/29/studies-leave-question-airborne-\ncoronavirus-transmission-unanswered/.\nBordia, P. and Difonzo, N. (2004). Problem solving in social interactions on the \ninternet: Rumor as social cognition. Social Psychology Quarterly , 67(1), pp.\u00a033\u201349. \nhttps://doi.org/10.1177/019027250406700105.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Aslib Journal of Information Management , \n66(3), pp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBostrom, A., Joslyn, S., Pavia, R., Walker, A. H., Starbird, K., and Leschine, T. M. (2015). \nMethods for communicating the complexity and uncertainty of oil spill response \nactions and tradeoffs. Human and Ecological Risk Assessment: An International \nJournal , 21(3), pp.\u00a0631\u2013645. https://doi.org/10.1080/10807039.2014.947867.\nCaplow, T. (1946). Rumors in war departmental contributions: Teaching and research \nin the social sciences. Social Forces , 25(3), pp.\u00a0298\u2013302. https://heinonline.org/\nHOL/P?h=hein.journals/josf25andi=314.\nCenters for Disease Control and Prevention. (2020, April\u00a01). Healthcare professionals: \nFrequently asked questions and answers. Centers for Disease Control and \nPrevention. https://web.archive.org/web/20200401051025/https://www.cdc.gov/\ncoronavirus/2019-ncov/hcp/faq.html.\nChu, J. and McDonald, J. (2020, January\u00a029). Helping the world find credible informa -\ntion about novel #coronavirus. Twitter Blog. https://blog.twitter.com/en_us/\ntopics/company/2020/authoritative-information-about-novel-coronavirus.\n132  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nDailey, D. and Starbird, K. (2015). \u201cIt\u2019s raining dispersants\u201d: Collective sensemaking of \ncomplex information in crisis contexts. In Proceedings of the 18th ACM Conference \nCompanion on Computer Supported Cooperative Work and Social Computing , \npp.\u00a0155\u2013158. https://doi.org/10.1145/2685553.2698995.\nDe Keulenaar, E., Burton, A.G., and Kisjes, I. (2021). Deplatforming, demotion and \nfolk theories of Big Tech persecution. Fronteiras \u2013 Estudos Midi\u00e1ticos , 23(2), \npp.\u00a0118\u2013139. https://doi.org/10.4013/fem.2021.232.09.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion: A cross-platform analysis of the QAnon conspiracy theory. First Monday , \n25(11). https://doi.org/10.5210/fm.v25i11.10643.\nDwoskin, E. (2020, November\u00a012). Trump\u2019s attacks on election outcome prolong \ntech\u2019s emergency measures. Washington Post . https://www.washingtonpost.\ncom/technology/2020/11/12/facebook-ad-ban-lame-duck/.\nEconomist (2019, June\u00a08). Google rewards reputable reporting, not left-wing \npolitics. The Economist . https://www.economist.com/graphic-detail/2019/06/08/\ngoogle-rewards-reputable-reporting-not-left-wing-politics.\nGolebiewski, M. and boyd, d. (2019). Data voids: Where missing data can easily be \nexploited. Data & Society Research Institute. https://datasociety.net/wp-content/\nuploads/2019/11/Data-Voids-2.0-Final.pdf.\nIati, M., Kornfield, M., O\u2019Grady, S., and Mellen, R. (2020, May\u00a04). Trump says it\u2019s \nsafe to reopen states, while Birx finds protesters with no masks or distancing \n\u201cdevastatingly worrisome.\u201d Washington Post . https://www.washingtonpost.com/\nworld/2020/05/03/coronavirus-latest-news/.\nInternet Archive. (2021). Internet archive: Digital library of free & borrowable \nbooks, movies, music & Wayback Machine [Web-based]. Internet Archive. \nhttps://archive.org/.\nKou, Y., Gui, X., Chen, Y., and Pine, K. (2017). Conspiracy talk on social media: \nCollective sensemaking during a public health crisis. In Proceedings of the \nACM on Human-Computer Interaction , 1(CSCW), article no.\u00a061. https://doi.\norg/10.1145/3134696.\nKrafft, P., Zhou, K., Edwards, I., Starbird, K., and Spiro, E.S. (2017). Centralized, \nparallel, and distributed information processing during collective sensemaking. \nIn Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , \npp.\u00a02976\u20132987. https://doi.org/10.1145/3025453.3026012.\nLee, L. and Oppong, F. (2020, September\u00a01). Adding more context to trends. Twitter Blog. \nhttps://blog.twitter.com/en_us/topics/product/2020/adding-more-context-to-trends.\nLewis, D. (2020). Is the coronavirus airborne? Experts can\u2019t agree. Nature , 580(7802), \np.\u00a0175. https://doi.org/10.1038/d41586-020-00974-w.\nLyons, K. (2020, October\u00a011). Twitter flags, limits sharing on Trump tweet about being \u201cim -\nmune\u201d to coronavirus. The Verge . https://www.theverge.com/2020/10/11/21511682/\ntwitter-disables-sharing-trump-tweet-coronavirus-misinformation.\nTWiT T e r a S  acciden Ta l au Th ori Ty  133\nMandavilli, A. (2020, July\u00a04). 239 experts with one big claim: The coronavirus is \nairborne. New York Times . https://www.nytimes.com/2020/07/04/health/239-\nexperts-with-one-big-claim-the-coronavirus-is-airborne.html.\nO\u2019Leary, N. (2020, March\u00a010). How Dutch false sense of security helped corona -\nvirus spread. Irish Times . https://www.irishtimes.com/news/world/europe/\nhow-dutch-false-sense-of-security-helped-coronavirus-spread-1.4199027.\nRoth, Y. and Pickels, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.\nScheufele, D. A. and Krause, N. M. (2019). Science audiences, misinformation, and \nfake news. Proceedings of the National Academy of Sciences , 116(16), pp.\u00a07662\u20137669. \nhttps://doi.org/10.1073/pnas.1805871115.\nSchmitt, C. (2005). Political theology: Four chapters on the concept of sovereignty . \nUniversity of Chicago Press.\nShibutani, T. (1966). Improvised news: A sociological study of rumor . Ardent Media.\nSkopeliti, C., and John, B. (2020, March\u00a019). Coronavirus: How are the social media \nplatforms responding to the \u201cinfodemic\u201d? First Draft. https://firstdraftnews.\norg:443/latest/how-social-media-platforms-are-responding-to-the-coronavirus-\ninfodemic/.\nStarbird, K. (2012). Crowdwork, crisis and convergence: How the connected crowd \norganizes information during mass disruption events [PhD].\nStarbird, K. (2020, April\u00a027). How to cope with an infodemic. Brookings. https://\nwww.brookings.edu/techstream/how-to-cope-with-an-infodemic/.\nStarbird, K., Spiro, E., Edwards, I., Zhou, K., Maddock, J., and Narasimhan, S. (2016). \nCould this be true? I think so! Expressed uncertainty in online rumoring. In \nProceedings of the 2016 CHI Conference on Human Factors in Computing Systems , \npp.\u00a0360\u2013371. https://doi.org/10.1145/2858036.2858551.\nTwitter (2019, October\u00a015). World leaders on Twitter: Principles & approach. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2019/worldleaders2019.\nTwitter (2020a, February\u00a07). Synthetic and manipulated media policy. Twitter. \nhttps://web.archive.org/web/20200207000218/https://help.twitter.com/en/\nrules-and-policies/manipulated-media.\nTwitter (2020b, April). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020c, May\u00a011). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020d, December\u00a016). COVID-19 misleading information policy. Twitter. \nhttps://web.archive.org/web/20201216200114/https://help.twitter.com/en/\nrules-and-policies/medical-misinformation-policy.\nTwitter (2021, January\u00a08). Permanent suspension of @realDonaldTrump. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/suspension.\n134  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nYong, E. (2020, April\u00a029). Why the coronavirus is so confusing. The Atlantic . \nhttps://www.theatlantic.com/health/archive/2020/04/pandemic-confusing-\nuncertainty/610819/.\nYouTube (2019, January\u00a025). Continuing our work to improve recommenda -\ntions on YouTube. YouTube Blog. https://blog.youtube/news-and-events/\ncontinuing-our-work-to-improve/.\nYouTube (2020). COVID-19 medical misinformation policy\u2014YouTube Help. https://\nsupport.google.com/youtube/answer/9891785?hl=en.\nAbout the authors\nEmillie de Keulenaar  is a PhD candidate at the University of Groningen, \nand a researcher at the University of Amsterdam\u2019s Open Intelligence Lab \nand the United Nations Department of Political and Peacebuilding Affairs. \nHer interests lie in the history and impact of speech moderation from a \ncross-platform perspective as well as the effects of deep disagreements in \nthe production of online misinformation.\nIvan Kisjes  is a scientific programmer at the CREATE lab at the University \nof Amsterdam, involved in computational research in various humanities domains.\nRory Smith  is the Research Manager at First Draft, where he leads on the \norganization\u2019s digital investigations into mis- and disinformation around \nthe world. Before joining First Draft, Rory worked for CNN, Vox and Vice, \ncovering various topics from immigration and food policy to politics and \norganized crime.\nCarina Albrecht is a doctoral candidate and SSHRC Canada Graduate \nScholar in the School of Communication at Simon Fraser University, and \nSFU-Mellon Critical Data Studies fellow at the Digital Democracies Institute. \nHer dissertation project explores alternative network science models for \nrecommendation systems and search engines.\nEleonora Cappuccio  is a PhD student in the Italian National Doctoral \nProgram in Artificial Intelligence. She completed her master\u2019s degree in \nCommunication Design at the Polytechnic University of Milan, developing \nher thesis at the DensityDesign research lab.\nTWiT T e r a S  acciden Ta l au Th ori Ty  135Annex\nTable\u00a06.1  S ources of false and true COVID-19 information.\nTransmission (only vehicles) Treatment (ingredients and medication) Prevention (protective measures, gear \nand preventive medicine)\nSecondary \nsourcesWikipedia (2020) \u201cTransmission (medicine),\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=Transmission_(medicine)&oldid=963983254.Wikipedia (2020a) \u201c\nco\nronavirus disease \n2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=\ncor\nonavirus_\ndisease_2019&oldid=966470660.Wikipedia (2020a) \u201c co\nronavirus disease \n2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=\ncor\nonavirus_\ndisease_2019&oldid=966470660.\nWikipedia (2020) \u201cMisinformation related to the \ncoVi\nd-\n19 pandemic,\u201d \nWikipedia. https://en.wikipedia.org/w/index.php?title=Misinformation_related_to_the_\nc\noVi\nd-\n19_pandemic&oldid=966340289.Wikipedia (2020b) \u201c li\nst of unproven methods \nagainst \ncoVi\nd-\n19,\u201d Wikipedia. https://\nen.wikipedia.org/w/index.php?title= li\nst_\nof_unproven_methods_against_ c\noVi\nd-\n1\n9&oldid=966515765.Wikipedia (2020b) \u201c li\nst of unproven methods \nagainst \ncoVi\nd-\n19,\u201d Wikipedia. https://\nen.wikipedia.org/w/index.php?title= li\nst_\nof_unproven_methods_against_ c\noVi\nd-\n1\n9&oldid=966515765.\nWikipedia (2020) \u201c co\nronavirus disease 2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.\nphp?title= co\nronavirus_disease_2019&oldid=966470660.\nPrimary sources c\ndc\n (2020) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Transmission, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. https://\nwww.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/how-covid-spreads.html.c\ndc\n (2020a) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Prevention & Treatment, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. \nhttps://www.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/prevention.html.c\ndc\n (2020) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Prevention & Treatment, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. \nhttps://www.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/prevention.html.\ngo\nv.us (2020) \nho\nw it spreads \u2013 \ncoVi\nd-\n19 \nan\nswers, gov.us. https://faq.coronavirus.gov/\nspread/.c\ndc\n (2020b) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Therapeutic \nop\ntions, \ncen\nters \nfor \ndi\nsease \nco\nntrol and Prevention. https://\nwww.cdc.gov/coronavirus/2019-ncov/hcp/therapeutic-options.html.go\nv.uk (2020) \nco\nronavirus \n(c\noVi\nd-\n19): guidance, \ngoV\n.uK\n. https://\nwww.gov.uk/government/collections/coronavirus-covid-19-list-of-guidance.\n136  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  Transmission (only vehicles) Treatment (ingredients and medication) Prevention (protective measures, gear \nand preventive medicine)\nn\nhS\n (2020) \nco\nronavirus\u2014Virus transmis-\nsion, \nnh\nS. https://www.england.nhs.uk/\ncoronavirus/primary-care/about-covid-19/\nvirus-transmission/.drugba\nnk (2020) \ndrug\ns\u2014drugba\nnk, \ndr\nugba\nnk. https://www.drugbank.ca/drugs.go\nv.us (2020) \nho\nw it spreads\u2014 c\noVi\nd-\n19 \nan\nswers, gov.us. https://faq.coronavirus.gov/\nspread/.\ngo\nv.uk (2020) \nco\nronavirus \n(c\noVi\nd-\n19): guidance, \ngoV\n.uK\n. https://\nwww.gov.uk/government/collections/coronavirus-covid-19-list-of-guidance.n\nh\nS (2020) \nco\nronavirus\u2014Virus transmission, \nnh\nS. https://www.england.nhs.uk/\ncoronavirus/primary-care/about-covid-19/virus-transmission/.\nWorld \nhe\nalth \nor\nganization (2020) \nad\nvice \nfor the public, World \nhe\nalth \nor\nganization. \nhttps://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-public.ni\nh.gov (2020) What\u2019s new | \nco\nronavirus \ndi\nsease \ncoVi\nd-\n19, \ncoVi\nd-\n19 Treatment \ngu\nidelines. \nhttps://www.covid19treatmentguidelines.nih.gov/whats-new/.\nWorld \nhe\nalth \nor\nganization (2020) \nad\nvice for the public, W h\no. h\nttps://www.who.int/\nemergencies/diseases/novel-coronavirus-2019/advice-for-public.\nAdditional \nsourcesWord embeddings and bigrams for \u201ctransmission\u201d and \u201ccontagion\u201dWord embeddings and bigrams for \u201ccure\u201d and \u201ctreatment\u201dWord embeddings and bigrams for \u201cprotec -\ntion\u201d and \u201cprevention\u201d\nTWiT T e r a S  acciden Ta l au Th ori Ty  137\nTable\u00a06.2  D ictionaries of types of COVID transmission, treatment and prevention.\nTransmission (only \nvehicles)Treatment (ingredients and medication)Prevention (protective measures, gear and preventive medicine)\n5g ablution 1.5\u00a0m\nairborne alcohol 2\u00a0m\nasymptomatic people andrographis paniculata 6 ft\nbath tissue antihistamine ablution\nblood transfusion aspirin alcohol\nbreast milk azithromycin antibacterial soap\nclose contact bitter gourd avoid close contact\ncommunity spread black pepper avoid touching your eyes\ncoughing cannabis avoid touching your eyes, nose and mouth\ndirect contact\ncb\nd o\nil avoid touching your mouth\ndirect physical contact chlorine dioxide avoid touching your nose\ndroplet nuclei chloroform boiled ginger\ndroplets chloroquine carbolic soap\nelectromagnetic cocaine chlorine\nfecal-oral routes colloidal silver clean and disinfect\nfecal transmission cow dung cloth\nfecal-oral transmission cow urine disinfect regularly\nfomites dietary supplement disinfection\nindirect contact durian dispose of tissues\nindirect physical contact essential oil dryer\nintimate contact ethanol environmental cleaning\nkissing fasting facemask\nmicrochip fennel tea fasting\nmosquito goose fat gargling\noral transmission honey garlic\npetrol hot liquids garlic, ginger and onion\nphysical contact hot whiskey ginger\nradiation hydroxychloroquine sulphategood hygiene\nrespiratory droplets influenza complex high temperature\nsaliva lemon isolate\nsneezing mango lemon\nsputum methanol\nn95\nt\nick mineral mask\ntouch acetic acid face mask\nwet particles amphetamine, cocaine and nicotine2 arms\u2019 length\nwireless azithromycin 6 feet\nbiocharger arsenicum album\nboiled ginger avoid being exposed\n138  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nTransmission (only \nvehicles)Treatment (ingredients and medication)Prevention (protective measures, gear and preventive medicine)\ndexamethasone cover your mouth\nin\ndian cow cover your nose\nlemon grass hand hygiene\nmechanical ventilatory supporthot liquids\nmint tea limits for public gatherings\nmiracle mineral supplement physical distance\nmustard patch physical distancing\nnasal spray plain soap\nneem leave red soap\nno cure respiratory etiquette\nno drug rum, bleach and fabric softener\nno treatment salt water\nno vaccine sauna\nplant sap self-isolation\nremdesivir sneeze in the crook of your elbow\nsaline soap and water\nsalt water social distance\nshuanghuanglian surgical masks\nsix deep breaths throw used tissues\nsnake oil turmeric\nsupplemental oxygen\nuV-c\ns\nupportive care uVc\nTa\nmiflu Virus Shut \nou\nt Protection\ntinospora crispa warm water\ntoothpaste warm weather\nturmeric wash hand\nvinegar wash your hands\nvitamin \nc w\nater and soap\nvitamin \nd c\nloth face cover\nwudu hand sanitizer\nzitroneer wet wipes\nall drugs mentioned in drugbank.cawhite handkerchief\nwhite tissue\n7 T he earnest platform\nU.S. presidential candidates, COVID-19, and social issues on \nInstagram\nSabine Niederer and Gabriele Colombo\nAbstract\nIncreasingly, Instagram is discussed as a site for misinformation, inau -\nthentic activities, and polarization, particularly in recent studies about \nelections, the COVID-19 pandemic and vaccines. In this study, we have \nfound a different platform. By looking at the content that receives the \nmost interactions over two time periods (in 2020) related to three U.S. \npresidential candidates and the issues of COVID-19, healthcare, 5G and \ngun control, we characterize Instagram as a site of earnest (as opposed \nto ambivalent) political campaigning and moral support, with a rela -\ntive absence of polarizing content (particularly from influencers) and \nlittle to no misinformation and artificial amplification practices. Most \nimportantly, while misinformation and polarization might be spreading \non the platform, they do not receive much user interaction.\nKeywords: social media, Instagram, U.S. elections, COVID-19, disinforma -\ntion, digital methods\nResearch questions\nTo what extent is ambivalent and divisive (or earnest and non-divisive) \ncontent present in the most interacted-with posts concerning political \ncandidates and social issues on Instagram in the run-up to the 2020 U.S. \npresidential elections? Do the candidates control their own \u201cname space,\u201d \ni.e., the (top) posts about them? Are there signs of artificial amplification (so-\ncalled fake or suspicious followers) among the candidates and their parties? \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch07\n140  S abine ni ederer and ga briele co loMb o \nHow do influencers and celebrities on \u201cpolitical Instagram\u201d contribute to \nthe information climate?\nEssay summary\nDuring the \u201cfake news crisis\u201d of 2016, false news sources and front groups \nspread divisive and ambivalent information and misinformation across social \nmedia\u2014notably on Facebook but also on Twitter and Instagram\u2014in the \nperiod leading up to the U.S. presidential election (Silverman, 2016; DiResta \net al., 2018; Howard et al., 2018). In 2020, concerns about such misinformation \nand divisiveness heightened in the lead-up to the U.S. elections. These \nconcerns hit the global stage in full force with the rise of the COVID-19 \npandemic, in which misinformation about the disease, the necessity of \nthe precautions taken to curb its spread, and the safety of its vaccinations \ncould pose immediate public health threats.\nRecent studies and reporting have demonstrated that Instagram is suscep -\ntible to problematic information related to elections. Prior to the 2016 U.S. \nelections, Instagram was a fertile ground for disseminating misinformation \nand divisive content (Jack, 2017; DiResta et al., 2018). Furthermore, an analysis \nof Netherlands-based news media accounts on Instagram surfaced a special \naffinity (in terms of shared followers) between mainstream news sources and \nso-called junk news providers (Colombo and De Gaetano, 2020). Additionally, \nrecent studies have found that conspiracy theories and anti-vaccine content \nspread under the guise of lifestyle content (Bond, 2021; Tiffany, 2021; Maragkou, \n2020; McNeal and Broderick, 2020). Such \u201cpastel QAnon\u201d accounts\u2014con -\nspiracy theories spread in sugar-coated messages by \u201cmummy bloggers, \nwellness coaches and lifestyle influencers\u201d (Gillespie, 2020)\u2014are yet another \naddition to the \u201ccacophony of voices and narratives\u201d which \u201chave coalesced to create an environment of extreme uncertainty\u201d (Smith et al., 2020, p.\u00a02).\nA report by the Center for Countering Hate describes how users who follow \nanti-vax accounts are presented with other problematic information by the \nplatform\u2019s recommendation systems. These include \u201crecommendations for \nantisemitic content, QAnon conspiracy theories, and COVID misinforma -\ntion\u201d (Center for Countering Hate, 2021, p.\u00a08). The study points out how the \nU.S. elections and the pandemic have fueled the disinformation problem \n(Bond, 2021). Not only has there been an increase in disinformation because \nof the divisive U.S. elections and the COVID-19 pandemic, the platform\u2019s \nrecommendation systems further grow the problem by connecting health information to a diverse range of conspiracy theories.\nThe earne S T Pl aT for M 141\nInstagram has been studied for its role in spreading divisive and polarizing \ncontent and the amplification of hate speech or harmful content (Bradshaw \nand Howard, 2018). When other mainstream platforms successfully \u201cde -\nplatformed\u201d accounts accused of sharing hateful messages and polarizing \ncontent, for a while, Instagram functioned as a refuge, dubbed as \u201cinternet\u2019s \nnew home for hate\u201d (Lorenz, 2019) or \u201calt-right\u2019s new favorite haven\u201d (Sommer, \n2018). With deplatforming recently on the rise, and extreme user accounts \nforced to move to \u201can alternative social media ecosystem\u201d (Rogers, 2020b), \nthis opens up the question of whether the characterization of Instagram as \na safe place still holds and whether the platform has succeeded in cleaning \nup divisive and polarizing content, at least in high-engagement spaces.\nInstagram is also the platform most known (and studied) for inauthentic \nbehaviors, such as purchased followers or artificially inflated like and \ncomments counts, obtained through \u201cclick farms and follower factories\u201d \n(Lindquist, 2019), or by participating in \u201ccomment pods,\u201d where users convene to like and comment each other\u2019s posts to inflate their own \nengagement metrics (Ellis, 2019). Detecting and limiting such inauthentic \nactivities is an increasing need of the marketing industry, as one can \nnote from the deluge of audit tools to \u201cexamine the health\u201d (Hypeauditor, \n2021) of one account\u2019s follower base through scrutinizing various features \nsuch as following-follower ratios or number of posts. The platform itself \nperiodically deploys new measures with the aim of \u201ckeeping Instagram \nauthentic\u201d (Systrom, 2014), deactivating \u201cspammy accounts\u201d (Systrom, \n2014), deleting those using \u201cthird-party apps to boost their popularity\u201d \n(Instagram, 2018), or, more recently, asking suspicious profiles to verify \ntheir identity (Instagram, 2020).\nIn this study, we focus on multiple topics, exploring the quality of in -\nformation and the users active in those spaces as well as the authenticity \nof their follower bases. U.S. election-related posts are studied through the prism of the presidential candidates, Trump, Biden, and Sanders. We then identified much-discussed topics in these candidates\u2019 spaces and selected \ngun control, healthcare, COVID-19 and 5G as particularly salient. Where \nsome studies choose to filter out verified Instagram accounts to capture \n\u201corganic social media conversations as opposed to media reports\u201d (Smith \net al., 2020, p.\u00a08), or look at the \u201ctwilight zone\u201d (Shane, 2020) beyond highly engaged-with posts, for this study we focus on the most engaging content \n(in terms of user interactions) regardless of the source. Therefore, we do \nnot filter out any user accounts, which allows us to include in the analysis \ncelebrities and influencers, whose role in spreading misinformation and \ndivisive content has been an object of scrutiny in multiple cases due to \n142  S abine ni ederer and ga briele co loMb o \ntheir high level of interactions and follower bases \u201cpredisposed to believe \nthem and trust their messages\u201d (Ahmadi and Chan, 2020).\nThis study considers the quality of information on Instagram about \nthe U.S. presidential candidates of 2020, the COVID-19 pandemic, and a \nselection of social issues (healthcare, 5G, gun control). These topics are \nexplored in the spring and fall of 2020, where the study zooms in on posts \nper period that receive the most user interactions. For the top 50 posts, the \nstudy combines content analysis with user activity analysis and includes \na follower analysis to test for artificial amplification, as discussed in the \nmethods section.\nWe developed a coding scheme for the content analysis that builds on \nBenkler et al. (2018) and distinguishes between divisive content (that might \nfuel polarization, conspiracy, or conflict) and non-divisive content. Following \nPhillips and Milner (2017), we term as ambivalent content (contrasted here \nwith earnest content) posts that are not inflammatory but may still generate \na lighter form of division by possibly excluding those who do not have the \ncultural references to decode it, laugh about it, and involuntary become \n\u201claughed at\u201d (Phillips and Millner, 2017).\nIn applying these notions to the most interacted-with content concerning \npolitical candidates and social issues in 2020, we found, counter-intuitively, \nthat most is earnest as well as non-divisive. In fact, throughout 2020, the \npolitical and issue spaces become even more earnest. There is also little to \nno misinformation encountered. In spring of 2020, influencers, including \ncelebrities, mostly share responsible posts about the pandemic, while later in \nthe year, they mainly encourage people to vote. Regarding COVID-19, there is \nan evolution from health warnings and supportive messages to posts about \nmental health during a pandemic and posts demonstrating that personal \nand professional life goes on despite COVID-19.  Overall, our study finds a \nhealthier platform than one might expect from one often associated with \nmisinformation. While misinformation might be spreading on the platform, \nit does not receive much user interaction.\nImplications\nIncreasingly, Instagram is discussed as a site for misinformation, inauthentic \nactivities, and polarization, particularly in recent studies about elections, \nthe COVID-19 pandemic and vaccines. Conspiracy and anti-vax content \neven have appeared as gradient pastel images under the guise of wellness \nand lifestyle posts. In this study, we have found a different platform. By \nThe earne S T Pl aT for M 143\nlooking at the content that receives the most interaction, we characterize \nInstagram as a site of earnest political campaigning and moral support, with \na relative absence of polarizing content and little to no misinformation.\nFirst, we analyze posts that receive the most user interactions over two \ntime periods (the spring and fall of 2020) related to three U.S. presidential \ncandidates and the issues of COVID-19, healthcare, 5G and gun control. To \ncharacterize these spaces, we adopt a two-fold coding scheme: Following \nBenkler et al. (2018), we distinguish between \u201cdivisive\u201d and \u201cnon-divisive\u201d \nposts, and from Phillips and Milner (2017), we identify \u201cambivalent content\u201d \n(contrasted here with \u201cearnest content\u201d). These are posts that often through \nmultiple layers of meanings and irony might subtly fuel division, excluding \nthose who do not have the cultural references to decode them.\nSecond, in the same candidate and issues spaces, we perform a user \nactivity analysis, examining the most active users and the number of \ninteractions they generate with their posts. Third, in order to assess the \nauthenticity of U.S. presidential candidates and parties\u2019 audiences, we \nanalyze their follower bases, looking at suspicious behaviors (such as dubi -\nous geographical provenance) that might signal automation or artificial \namplification practices. Fourth, we zoom in on the role of celebrities and \ninfluencers, characterizing through close reading the nature and content \nof their posts with an eye towards their role in spreading misinformation and divisive content.\nOverall, our study finds a healthier space than one might expect from \na platform often associated with polarization and misinformation. In fact, \nthroughout 2020, the political and issue spaces become even more earnest. \nWhile misinformation and polarization might be spreading on the platform, \nthey do not receive much user interaction.\nIndeed, the findings show that while posts about political candidates may \nentail fierce campaigning, the overwhelming majority of the most engaged \nwith content is earnest and non-divisive. The finding is significant given \nthat research has shown how well divisive and false news and commentary \noften spread compared to more sincere content (Vosoughi et al., 2018; Klein \nand Robison, 2019).\nFor the posts concerning the three presidential candidates under study, \neach has an equal amount of divisive content (about 15%) in the top 50 \nposts. For that content, however, it was found that over half of it was posted \nby Trump or Trump, Jr. One implication is that the Trumps are a leading \nsource of divisiveness and that they are rather alone in that role, at least in \nthe top posts under study. It should be noted that Trump is also the main target of that content type. Of the remaining divisive content, most posts \n144  S abine ni ederer and ga briele co loMb o \nare about Trump or his administration. Engagement is an impact metric \nrather than a measure of sentiment. In other words, non-divisive, earnest \nposts may trigger positive but also negative comments, as we know from \nresearch into trolling and antagonistic behavior online (Phillips, 2015). \nNegativity in the comment space still leads to a high interaction score, so \nthe findings do not imply the absence of toxicity.\nThe namespace analysis shows an uneven distribution of attention to \nthe three candidates. Trump proved to be successful in dominating his own \nnamespace, while Biden\u2019s space is occupied by a variety of users (mainly \nendorsing him). Sanders is the most successful of the three candidates in \npopulating the others\u2019 namespaces. After losing the race to the presidential \nnomination in the fall, he is left alone in his space, and his language becomes \nmore divisive.\nIn a further examination of the followers of the political candidates and \nparties, we find signs of light artificial amplification only for the accounts \nof the Republican Party and Donald Trump. The finding implies that the \nmajority of the user interaction is not achieved through the purchasing of \nfollowers or likes, as was found in previous research, suggesting an apparent \nslowing of that practice (DiResta et al., 2018; Feldman, 2017).\nLastly, it is worthwhile to zoom in on the outsized role of particular users, \napart from the Trumps and the National Rifle Association. On a platform \nknown for its influencers, we can distinguish between at least two types of \n\u201cissue celebrities\u201d here. The one assumes a more traditional role of celebrity \nfundraising and awareness-raising, which we find mainly in healthcare posts \nby those who support front-line workers and hospitals during the pandemic \n(sometimes with financial donations). For the topic of COVID-19, we also \nsee other, more commercially entangled celebrity engagement, where they \nsell their products and promise to donate a percentage of the profits to a \nCOVID-related cause.\nThe study contributes to scholarly work that examines how visual \npractices on Instagram \u201care not just social media artifacts, isolated and \nindividual, but are surrounded by debates and discussions that take on \npolitical, legal, economic, technological, and sociocultural dimensions\u201d \n(Highfield and Leaver, 2016, p.\u00a049). By selecting the political content with \nmost interactions, we approach engagement on the platform in a more \ncomprehensive way than content posted by influencers only. Indeed, the \npoints of departure are the political debates and discussions. They take \ncenter stage rather than emerge as a byproduct of celebrity and influencer \nculture. In further assessing the content of top posts as earnest or ambiva -\nlent and divisive or non-divisive (Hedrick et al., 2018), it contributes to the \nThe earne S T Pl aT for M 145\ndiscussions on online (mis)information, offering an analytical framework \nthat is sensitive to critiques of thin ontologies as true or false content (Lazer \net al., 2018; Marres, 2018). The work thereby has methodological implications \nfor those categorizing contemporary social media content.\nFindings\nFinding 1: The top posts concerning political candidates and social issues on \nInstagram contain largely earnest and non-divisive content. Social media \nplatforms such as Instagram have been described as sites of misinformation \nand divisiveness, particularly around elections. In this study, however, the \npolitical and issue coverage that has received the most user interactions \non Instagram from January to mid-April\u00a02020 and from September\u00a02020 to \nJanuary\u00a02021 is primarily earnest and non-divisive, with scant ambivalent \ncontent.\nConcerning the political candidates, in spring approximately 85% of \nthe posts are non-divisive, and the vast majority is earnest. The amount \nof divisiveness in each of the different candidate\u2019s namespaces is more or \nless the same, but nearly half of such content is posted by Donald Trump \nor Donald Trump, Jr., and most of the remaining divisive posts are about \nTrump. In the fall, despite the U.S candidates\u2019 spaces remaining generally \nearnest and non-divisive, there are variations compared to the situation \nin spring, depending on the candidate. Biden\u2019s namespace has become \nmuch less divisive; both compared to that in spring and to the others. The \nnamespaces of Trump and Sanders have instead become more divisive than \nin spring. Sanders\u2019 space is the one with more divisive posts in the top 50 \namong the three candidates. Examining the tone and wordings of his posts, \nwe observe an increasingly more divisive language, with direct attacks to \nvarious opponents, including Joe Biden (see Figure\u00a07.2), President Trump and \nWall Street (e.g., \u201cpathetic \u2026 president\u201d and \u201cWall Street crooks\u201d). Posts about \nTrump also become slightly more divisive in spring. Trump\u2019s namespace \nhas the most memes and jokes, some making fun of him and others of his \nopponents (sometimes both in one meme). Furthermore, many of the posts \nin the Trump space are labeled and fact-checked by Instagram (Figure\u00a07.3), \nwith banners, blurring covers and various notices.\nThe fact that Instagram overlays content moderation notices and disclaim -\ners\u2014not only on Trump\u2019s statements and videos but also on memes and fake \nscreenshots posted by satirical accounts\u2014generates an additional layer of \nmessiness that contributes to the ambivalence of this space.\n146  S abine ni ederer and ga briele co loMb o \nfi gure\u00a07.1 ex ample of be rnie Sanders\u2019 posts becoming more divisive in wording. Sources: https://\nwww.instagram.com/p/ b9\nX3SZ o\nbx\nhX/; https://www.instagram.com/p/ c\nh1\nKx5 i\nbsMn/\n.\nfi gure\u00a07.2 ex amples of fact-checking and content moderation notices found in Trump space \nin fall. Sources: https://www.instagram.com/p/ c\ngr\nPpa-\nMKl1\n/; https://www.instagram.com/p/\nc\nhlS\n06f\nbu\nfb/\n; https://www.instagram.com/p/ c\nhncr w\nwl\ni\n4f/.\nThe earne S T Pl aT for M 147\nFinding 2: While social issues are mostly discussed in earnest and non-\ndivisive ways in the most engaging posts, some are more divisive than \nothers. Moving from spring to fall, issue spaces remain largely earnest \nand non-divisive (except for gun control), but the content of the posts dif -\nfers over time. Contrary to reports about online misinformation on social \nmedia, we find Instagram to be an earnest space of non-divisive content \nabout the COVID-19 pandemic and healthcare, mostly posting in support \nof healthcare workers and encouraging users to stay safe. In the fall posts \nabout the pandemic and health, in general, become even more earnest and \nnon-divisive (with only one divisive post in the healthcare space), and the \ncontent of the posts changes. COVID-19 no longer dominates healthcare \nposts; instead, they address mental health and include well-wishing.\nFrom the spring to the fall the COVID-19 space moves from posts support -\ning healthcare workers and encouraging users to stay safe to posts about \nactivities that are taking place despite the pandemic. In the first period \nconspiracy is present in the 5G space, amidst mainly commercial content, \nfi gure\u00a07.3 cl assification of the top 50 in stagram posts (receiving most interactions) in the political \ncandidates\u2019 namespaces. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013\nJanuary\u00a05, 2021. \nda\nta source: \ncr\nowdTangle.\n148  S abine ni ederer and ga briele co loMb o \nwith the top post dismissive of the conspiracy theory that the coronavirus is \nspread through Chinese-made 5G towers. The 5G space becomes even more \nearnest in the second period under study, with a total absence of divisive \nor ambivalent content in the top posts, which are mainly commercial and \nwith no signs of conspiracy-themed content in the top 50. We find one 5G \nconspiracy-related post well down in the results (#306). A post by Robert F. \nKennedy, Jr., now removed from Instagram (Jett, 2021), references \u201cdeadly \n5G radiation\u201d together with \u201cBig Pharma,\u201d \u201cBig Data,\u201d \u201cBill Gates\u201d and the \n\u201cCOVID vaccine project.\u201d Gun control is the most divisive of the issues we analyzed, and its top 50 posts are dominated by a single user, the National \nRifle Association (with 30 out of the 50 posts), becoming even more divisive \nover time.\nfi gure\u00a07.4 cl assification of the top in stagram 50 posts (receiving most interactions) in the issues \nspaces. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta \nsource: \ncr\nowdTangle.\nThe earne S T Pl aT for M 149\nFinding 3: Trump performs well in his own namespace in the spring, \nwhile Biden is crowded out of his. In the fall, Sanders is left alone in his own \nnamespace. For each candidate, we looked at their respective namespace, \nthat is, the body of posts that @-mention the candidate. The rationale to \ndo so is that when a presidential candidate holds control over his own \nnamespace, this space is likely to be less divisive or ambivalent than when \nothers mostly post about the candidate. For a candidate, controlling one\u2019s \nown namespace might mean being able to actively steer the discourse in \ntheir favor and reducing the level of divisiveness. In this next analytical step, \nwe assess if and how the namespace is affected\u2014in terms of its divisiveness \nand ambivalence\u2014when the candidate occupies it.\nLooking at the most active users in each candidate\u2019s namespace, Trump \nperforms well in his namespace in both time frames analyzed. Trump\u2019s own \nInstagram content, likely run by his campaign, is not as negative as the \ninsulting messages he is known for on Twitter (Quealy, 2017; Lee and Quealy, \n2019). Many of his most engaging Instagram posts in the initial period are \nabout his Super Tuesday wins in several states. However, of the earnestly \ndivisive posts across all namespaces, many are by Trump or Trump, Jr. \nCompared to the spring, Trump still dominates his own namespace in the \nfall. His top posts in total receive fewer interactions than before, however, \nand there is a broader variety of users receiving interaction, including Snoop \nDogg (with memes) as well as Kamala Harris, Michelle Obama, and Hillary \nClinton (with critical posts).\nIn the spring Biden\u2019s account does not have a strong presence in the top \nposts about him. His namespace shows the most user diversity. Popular \ncontent posted about him by others varies from endorsements, the most \npopular of which was that by Barack Obama, to criticism and campaigning, \nfor instance by Sanders in 1/5 of the top posts. Donald Trump, Jr. is also active \nin Biden\u2019s namespace, calling him out for his son\u2019s business in China and \nhis views on gun control. In the next period, Biden\u2019s namespace remains \ncrowded with diverse users, many of whom are non-political celebrities \nencouraging users to vote for him or congratulating him.\nIn the spring, Sanders is the most successful of the three candidates \nin populating the others\u2019 namespaces, posting much-interacted-with, \ncampaign-style content about Trump and Biden. In second timeframe, \nSanders is left alone in his own namespace, with the number of active users \nshrinking dramatically. Whereas in the first period, Sanders\u2019 namespace is \npopulated by a variety of users, in the second, Sanders dominates his own \nnamespace, with only six active users in the top 50, as expected after Biden \nbecame the democratic presidential candidate.\n150  S abine ni ederer and ga briele co loMb o \nFinding 4: There are few signs of artificial amplification in the U.S. political \nspace. In both time periods the accounts of U.S. presidential candidates \nand political parties on Instagram do not have suspicious follower bases, \nwith almost 75% giving indications of being genuine followers, with some \nexceptions and slight differences between the periods. In the spring Donald \nTrump\u2019s account and, more prominently, the Republican party account, have \nfi gure\u00a07.5 The most active in stagram users per political candidate\u2019s namespace. da te ranges: Janu-\nary\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta source: \ncr\nowdTangle. \nThe user accounts in our dataset not marked as \u201cverified\u201d public figures by \nin\nstagram are blurred \nin the visualization.\nThe earne S T Pl aT for M 151\nslightly over 25% followers that the method considers suspicious (bots, or \nreal accounts that use automatic tools for following or unfollowing other \naccounts). In the fall the composition of tool-suspected followers for the \nfi gure\u00a07.6 in stagram follower analysis of political parties and candidates\u2019 accounts. br eakdown of \naudience types into categories. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, \n2020\u2013January\u00a05, 2021. \nda\nta source: \nhy\npeau\nditor.\n152  S abine ni ederer and ga briele co loMb o \naccounts of Trump has slightly decreased, while that of both the Republican \nand Democratic parties remain largely the same. Contrariwise, the number \nof suspicious followers has risen slightly for Joe Biden (with a total of 21.4% \nmass and suspicious followers) and Bernie Sanders (who reaches nearly 27% \nof mass and suspicious followers).\nAnalyzing the geographical provenance of the followers of each ac -\ncount, which can also indicate artificial amplification practices, we \nfound both timeframes the follower bases of the political candidates and \nparties to be overwhelmingly U.S.-based, with the exception of Donald \nTrump\u2019s. In the spring Trump\u2019s official account had 25% of followers \nfrom other locations than the U.S., including Iran, Brazil, and India. \nfi gure\u00a07.7 in stagram follower analysis of political parties and candidates\u2019 accounts. br eakdown \nof followers\u2019 countries of origin, showing the top 5 locations of users in the follower base of each \naccount. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta source: \nhy\npeau\nditor.\nThe earne S T Pl aT for M 153\nIn the fall we no longer find India-based users in the top 5 locations of \nDonald Trump followers.\nFinding 5: Celebrities and influencers generally make responsible \ncontributions to political Instagram. It is also worthwhile to zoom in \non the role of celebrities and influencers on a platform known for their \nsignificance in influencing public opinion. Generally speaking, their posts \nfall into the category of earnest and non-divisive. They raise awareness, \ndonate to causes, show support for a candidate, serve as role models, \nand debunk conspiracy theories. Indeed, some contributions fit into a \nlongstanding tradition of \u201cissue celebrity\u201d fundraising and awareness-\nraising, particularly concerning healthcare, with posts by celebrities who \nsupport (sometimes with financial donations) healthcare workers and \nhospitals during the pandemic in spring. In the posts concerning COVID-19, \nwe also witness celebrities promoting their products and promising to \ndonate a percentage of the profits to COVID-19 related funds, as Kim \nKardashian does in her four posts that make it into the top 50 on that issue. \nOn healthcare, on top is Tom Hanks\u2019 message from Australia, reporting \nthat he and his wife were infected and in self-isolation in Australia. In \nthe 5G space, it is a repost of hip-hop artist 55Bagz making fun of the \ncoronavirus-5G conspiracy that receives the most user interactions. On \nthe issue of gun control, however, rapper Kevin Gates\u2019s post of his daughter \nposing with a gun receives a great deal of attention in a space otherwise \ndominated by the National Rifle Association (with 30 posts in the top \n50). Concerning posts about political candidates, we see how candidate \nsupport messages by model and actress Emily Ratajkowski attract high \namounts of user interactions.\nIn the fall we still observe the prominent role of celebrities both in the \nissue and candidate spaces, although the pool of most active ones in the \ntop 50 posts changes slightly: new celebrities appear (such as athletes \nCristiano Ronaldo and Virat Kohli), while others who reached the top \nin spring have disappeared (e.g., Tom Hanks). Kim Kardashian (present \nin the top 50 with multiple posts in Spring) remains at the top. For some \nissues, the tone and the content celebrities discuss change considerably \ncompared to the previous period. Concerning COVID-19, messages of \nsupport and advice about the pandemic are replaced by posts that show \nhow life goes on despite the pandemic (at least for celebrities who can afford \nit): film sets are moved to comply with travel restrictions, or \u201cCOVID-free\u201d \nbirthday parties are held on private islands. In the health space, support \nfor healthcare workers is partly replaced with messages of awareness \n154  S abine ni ederer and ga briele co loMb o \nabout mental health issues, specifically around World Mental Health Day \non October\u00a010th.\nIn the political spaces, more celebrities are active, calling on users to \ngo and vote, both in dedicated posts (e.g., Jennifer Aniston) or by adding \n#voteforBiden to otherwise non-political posts. Indeed, among the candi-\ndates, Biden is the one receiving the most celebrity support. Together with \ncelebrities, some famous politicians (e.g., Barack Obama) voice support \nfor Biden, while others express criticism for Trump (e.g., Kamala Harris, \nMichelle Obama, and Hillary Clinton). In the Trump space, Snoop Dogg \nreceives quite a lot of attention by posting memes about the president.\nfi gure\u00a07.8 ex amples of celebrities\u2019 posts in fall: ce lebrities urging to vote in dedicated posts \n(Jennifer \nan\niston), or by inviting to vote (for \nbi\nden) in the caption of otherwise non-political posts \n(ar\niana \ngr\nande); \nce\nlebrity personal life (Kim Kardashian) and professional life (The \nro\nck) going on \ndespite \ncoVi\nd-\n19. Sources: https://www.instagram.com/p/ c\ngs\nker\n_je5\nd; https://www.instagram.\ncom/p/ c\ng5\nrtaa f8\nk_/; https://www.instagram.com/p/ c\ng2\nzK7Wggh f/\n; https://www.instagram.\ncom/p/ c\nhX\n3Tvo\nfrf\nn/.\nThe earne S T Pl aT for M 155\nMethods\nContent analysis of candidates and issues spaces\nThe Instagram data for this study is collected with CrowdTangle, Facebook\u2019s \nmedia monitoring tool that has been made available to academics through \nthe Social Science One program. CrowdTangle allows users to collect \nInstagram posts that mention one or more keywords during a specific \nfi gure\u00a07.9 The most active in stagram users per issue space. da te ranges: January\u00a01, 2020\u2013 ap ril\u00a020, \n2020 and September\u00a022, 2020\u2013January\u00a05, 2021. Source: \ncr\nowdTangle. The user accounts in our \ndataset not marked as \u201cverified\u201d public figures by \nin\nstagram are blurred in the visualization.\n156  S abine ni ederer and ga briele co loMb o \ntime frame. To create our dataset, we first compiled a list of keywords \nfor each candidate, including candidate names, campaign slogans, and \nmost-used hashtags. Then, we selected four of the most-mentioned topics \nin the candidate spaces: healthcare, COVID-19, 5G and gun control. For \neach of these topics, we compiled a list of relevant keywords intending \nto include official terms, vernacular words, and, if applicable, pro- and \ncounter-terminology, e.g., including in the query both \u201cgun control\u201d and \u201cgun \nownership.\u201d (See Appendix for the full list of queries.) We used each query \nto collect Instagram posts shared in two timeframes: between January\u00a01 and \nApril\u00a020, 2020 (we refer to this period as spring throughout this chapter) \nand between September\u00a022, 2020, and January\u00a05, 2021 (which we refer to as \nfall). For each query and each period, we selected the top 50 posts based on \nthe total sum of interactions, which is the number of likes and comments \nby Instagram users that a post has received.\nIn this study, we focus on most engaged with posts, as well as most active \nusers in high-engagement spaces, asking specifically whether the posts from \nhighly visible accounts receiving the most user interactions are earnest or \nambivalent and whether they are divisive or not. After having manually \nremoved unrelated posts from the dataset, we conduct a close reading of the \ntop 50 posts per space, taking into consideration both the visual elements \n(image or video) and the post captions, applying a four-category analytical \nscheme (see Figure\u00a07.10).\nWe flag as divisive content posts that fuel conflict, polarization, or even \nradicalization (following Benkler et al., 2018), in contrast to more positive messages (e.g., supporting a candidate or sharing quarantine tips), which we label as non-divisive. We make a distinction between earnest content \nthat is posted with clear intent and may be understood by many users and \ncontent that often through humor or (sub)cultural references lends itself \nto different interpretations, depending on those who receive it and what \nthey read into it. Here, we keep in mind the possibility of encountering \nconvincing yet \u201cmaliciously \u2018fake\u2019 content\u201d (Highfield and Leaver, 2016, \np.\u00a052).\nIn opposition to \u201cearnest and non-divisive\u201d content, we categorized \nas \u201cearnest and divisive\u201d inflammatory posts that might fuel polariza -\ntion, conspiracy, or conflict. We used \u201cambivalent and non-divisive\u201d to \ncategorize content that is not inflammatory but may still generate a \nlighter form of division by possibly excluding those who do not have the cultural references to decode it, laugh about it, and involuntary become \n\u201claughed at\u201d as Phillips and Millner put it (2018). We subsequently tagged \nas \u201cambivalent and divisive\u201d content that, while ambivalent (as above), \nThe earne S T Pl aT for M 157\nfi gure\u00a07.10 an alytical scheme. ex amples of coded posts in earnest non-divisive, ambivalent \nnon-divisive, earnest divisive, and ambivalent divisive. Sources: https://www.instagram.com/tv/\nc\nhim\ntyqhfo9\n/; https://www.instagram.com/p/ c\nhKe\nganh\n_\ng3\n/; https://www.instagram.com/p/\nc\ngan\n6Kfs\njdq\n/; https://www.instagram.com/p/ c\nf1\n-vqonZJr/.\n158  S abine ni ederer and ga briele co loMb o \ncan be recognized as highly dismissive, polarizing, or otherwise geared \ntowards division.\nIt is important to note that as we are analyzing content during a political \ncampaign, and many posts were \u201ccampaigning\u201d in terms of both their \nmessage and tone of voice. Here, we only coded such content as divisive \nwhen it was explicitly dismissive of a political opponent or another person \nor accusatory in incendiary terms. Not all critical posts were labeled as \ndivisive, just as not all jokes were coded as ambivalent.\nUser activity analysis of candidates and issues spacesFor each of the presidential candidates and issue spaces, we analyzed the \nmost active users. Here, we count how many times a user has posted and \ncalculate the total number of interactions (likes and comments) received \nby each user for the total of his or her posts. User activity analysis tells us \nwhether one or more very active users dominate a political or issue space \nand whether those who are the most vocal are also the most interacted with \nby other users. Concerning the political candidates, we also ask whether \none candidate succeeds in \u201cinvading\u201d another candidate\u2019s namespace. As \none candidate mentions (often attacking or criticizing) another candidate, \ns/he may receive a high number of user interactions, therefore appearing \nin the top 50 posts of one of the opponents.\nArtificial amplification and follower analysis\nTo assess the authenticity of candidates\u2019 and parties\u2019 audiences and \ndetect signs of artificial amplification, we use the digital marketing tool, \nHypeAuditor. The tool provides a set of metrics for one Instagram ac -\ncount, which it compiles into an \u201caudience report.\u201d For each candidate and \nparty (Biden, Sanders, and Trump as well as the political party names), \nwe collect the Instagram usernames and then use HypeAuditor to obtain \nan audience report. The report provides an audience type breakdown, \ndividing followers into four categories: real people, influencers (> 5,000 \nfollowers), mass followers (>1,500 followers), and suspicious followers, \ndefined as \u201cInstagram bots and people who use specific services for likes, \ncomments and followers purchase\u201d (Komok, 2020). From the Hypeauditor \nreport, we also consider the followers\u2019 country analysis for each account, \nwhich breaks down followers by location and could also point to possible \nanomalies in the follower base.\nThe earne S T Pl aT for M 159\nCelebrities on Instagram\nIn the last part of the study, we zoom into the role of celebrities in the \nvarious political and issue spaces. In characterizing online celebrities, \nscholars have made the distinction between \u201csocial media natives,\u201d \nsometimes referred to as micro-celebrities to indicate the niche of their \nfame, whose \u201cactivities have been associated with social media from the \nbeginning\u201d (Giles, 2017), and established celebrities who become active \non social media and employ the techniques of micro-celebrities to engage \nwith their audience (Marwick and boyd, 2010). In our user activity analysis, \nrather than tracing where their fame originated from, we consider as \ncelebrities all public figures whose user accounts are labeled as \u201cverified\u201d \nby the platform.\nTo obtain a verified account on Instagram, reviewers assess whether an \naccount is \u201cin the public interest\u201d and (in addition to following the platform\u2019s \nterms of service) is \u201cauthentic, unique, complete and notable\u201d (Instagram, \nn.d.). Verified accounts must also be famous outside of Instagram, as the \nplatform \u201creview(s) accounts that are featured in multiple news sources\u201d \n(Instagram, n.d.) and assigns a verified badge only to those associated with \na \u201cwell-known, highly searched for person, brand or entity\u201d (Instagram, \nn.d.). Social media influencers who have not built up a public presence \noutside of the platform are not marked as verified. Once the badge of a \nverified account is earned, it is hardly revoked, and \u201cthere appear to be no \nconsequences when authentic, verified accounts share lies and half-truths\u201d \n(Ahmadi and Chan, 2020).\nAppendix\nOverview of queries used in CrowdTangle\nCovid-19 [corona, covid_19, covid, coronaviruspandemic, coronavirus]\n5G [5g]\nHealthcare [healthinsurance, medicareforall, medicare, medicareforallnow, \nhealth, healthcare, lowerdrugcosts, protectourcare, obamacare, Abortion, Medicare]Gun control [gun control, firearms regulation, gun restrictions, anti-gun, \ncarry permit, 2nd amendment, second amendment, right to keep and bear \narms, gun ownership]\n160  S abine ni ederer and ga briele co loMb o \nBiden [biden, joebiden, biden2020]\nSanders [berniesanders, sanders, feelthebern, bernie2020, votebernie]\nTrump [donaldtrump, trump, KAG2020, Trump2020, makeamericagreata -\ngain, maga]\nInstagram accounts that were part of the follower analysis with \nHypeAuditor\nPolitical candidate accounts: @berniesanders, @joebiden, @realdonaldtrump\nPolitical party accounts: @thedemocrats, @gop\nReferences\nAhmadi, A.A., and Chan, E. (2020). Online influencers have become powerful \nvectors in promoting false information and conspiracy theories. First Draft. \nhttps://firstdraftnews.org/latest/influencers-vectors-misinformation/.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBond, S. (2021, March\u00a09) Instagram suggested posts to users. It served up COVID-19 \nfalsehoods, study finds. NPR. https://www.npr.org/2021/03/09/975032249/\ninstagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-finds.\nBradshaw, S. and Howard, P.N. (2018). Challenging truth and trust: A global inventory \nof organized social media manipulation . Computational Propaganda Research \nProject. Oxford Internet Institute. https://demtech.oii.ox.ac.uk/wp-content/\nuploads/sites/93/2018/07/ct2018.pdf.\nBurkhardt, J.M. (2017). Combating fake news in the digital age. ALA Library Technol -\nogy Reports , 53(8): pp.\u00a05\u20139. https://doi.org/10.5860/ltr.53n8.\nCenter for Countering Hate (2021, March\u00a09). Malgorithm: How Instagram\u2019s al -\ngorithm publishes misinformation and hate to millions during a pandemic. \nhttps://252f2edd-1c8b-49f5-9bb2-cb57bb47e4ba.filesusr.com/ugd/f4d9b9_89e\nd644926aa4477a442b55afbeac00e.pdf.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram. Junk news, \nfollower ecologies and artificial amplification. In R. Rogers and S. Niederer (Eds.), \nThe politics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University \nPress.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J., and \nJohnson, B. (2018). The tactics & tropes of the internet research agency, White \nPaper, New Knowledge. https://disinformationreport.blob.core.windows.net/\ndisinformation-report/NewKnowledge-Disinformation-Report-Whitepaper.pdf.\nThe earne S T Pl aT for M 161\nEllis, E. G. (2019, September\u00a010). Fighting Instagram\u2019s $1.3 billion problem\u2014Fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nFeldman, B. (2017, June\u00a08). In Russia, you can buy Instagram likes from a \nvending machine. New York Times Magazine , June\u00a08. https://nymag.com/\nintelligencer/2017/06/you-can-buy-instagram-likes-from-a-russian-vending-\nmachine.html.\nGillespie, E. (2020, September\u00a030). \u201cPastel QAnon\u201d: The female lifestyle bloggers \nand influencers spreading conspiracy theories through Instagram. The Feed . \nhttps://www.sbs.com.au/news/the-feed/pastel-qanon-the-female-lifestyle-\nbloggers-and-influencers-spreading-conspiracy-theories-through-instagram.\nHedrick, A., Karpf, D., and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal of Communication, 12 (8). https://ijoc.org/index.\nphp/ijoc/article/view/8736/.\nHighfield, T. and Leaver, T. (2016). Instagrammatics and digital methods: Studying \nvisual social media, from selfies and GIFs to memes and emoji. Communication \nResearch and Practice , 2(1), pp.\u00a047\u201362. https://doi.org/10.1080/22041451.2016.115\n5332.\nHoward, P.N., Ganesh, B., Liotsiou, D., Kelly, J., and Fran \u00e7o is, C. (2018). The IRA, \nsocial media and political polarization in the United States, 2012\u20132018, Report, \nComputational Propaganda Research Project, Oxford Internet Institute. https://\ncomprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2018/12/The-IRA-Social-\nMedia-and-Political-Polarization.pdf.\nInstagram (n.d.). What are the requirements to apply for a verified badge on \nInstagram? Instagram Help Center. https://help.instagram.com/312685272613322.\nInstagram. (2018). Reducing inauthentic activity on Instagram. Instagram Blog. \nhttps://about.instagram.com/blog/announcements/reducing-inauthentic-\nactivity-on-instagram.\nInstagram. (2020). Introducing new authenticity measures on Instagram. \nInstagram Blog. https://about.instagram.com/blog/announcements/\nintroducing-new-authenticity-measures-on-instagram.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/pubs/oh/DataAndSociety_Lexi -\nconofLies.pdf.\nJenkins, H. (2017, May\u00a030). The ambivalent internet: An interview with Whitney \nPhillips and Ryan M. Milner (Part One). Confessions of an ACA-fan Blog. http://\nhenryjenkins.org/blog/2017/05/the-ambivalent-internet-an-interview-with-\nwhitney-phillips-and-ryan-m-milner-part-one.html.\nJett, J. (2021, February\u00a011). Robert F. Kennedy, Jr. is barred from Instagram over false \ncoronavirus claims. New York Times . https://www.nytimes.com/2021/02/11/us/\nrobert-f-kennedy-jr-instagram-covid-vaccine.html.\n162  S abine ni ederer and ga briele co loMb o \nKlein, E. and Robison, J. (2020). Like, post, and distrust? How social media use \naffects trust. Political Communication , 37(1), pp.\u00a046\u201364. https://doi.org/10.1080\n/10584609.2019.1661891.\nKomok, A. (2020). What are suspicious accounts? HypeAuditor . https://help.\nhypeauditor.com/en/articles/2221742-what-are-suspicious-accounts.\nLazer, D. M., Baum, M.A., Benkler, Y., Berinsky, A.J., Greenhill, K.M., Menczer, \nF., \u2026 and Schudson, M. (2018). The science of fake news. Science, 359 (6380), \npp.\u00a01094\u20131096. https://doi.org/10.1126/science.aao2998.\nLee, J.C. and Quealy, K. (2019, May\u00a024). The 598 people, places and things Donald \nTrump has insulted on Twitter: A complete list. New York Times . https://www.\nnytimes.com/interactive/2016/01/28/upshot/donald-trump-twitter-insults.html.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\nLorenz. T. (2019, March\u00a021) Instagram is the internet\u2019s new home for hate. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2019/03/\ninstagram-is-the-internets-new-home-for-hate/585382/.\nMaragkou, E. (2020, December\u00a08). The conspiracy theorist as influencer. Insti -\ntute of Network Cultures Blog. https://networkcultures.org/blog/2020/12/08/\nthe-conspiracy-theorist-as-influencer/.\nMarres, N. (2018). Why we can\u2019t have our facts back. Engaging Science, Technology, \nand Society, 4 , 423\u2013443. https://doi.org/10.17351/ests2018.188.\nMcNeal, S. and Broderick, R. (2020, April\u00a04). Lifestyle influencers are now sharing \nsome bogus far-right conspiracy theories about the coronavirus on Instagram. \nBuzzfeed News . https://www.buzzfeednews.com/article/stephaniemcneal/\ncoronavirus-lifestyle-influencers-sharing-conspiracy-qanon.\nOh, D. (2019). Review of The ambivalent internet: mischief, oddity, and antagonism \nonline. Information, Communication & Society , 22(8), pp.\u00a01189\u20131191. https://doi.\norg/10.1080/1369118X.2019.1606267.\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nQuealy, K. (2017, July\u00a026). Trump is on track to insult 650 people, places and things \non Twitter by the end of his first term. New York Times . https://www.nytimes.\ncom/interactive/2017/07/26/upshot/president-trumps-newest-focus-discrediting-\nthe-news-media-obamacare.html.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nThe earne S T Pl aT for M 163\nShane, T. (2020, December\u00a01). Searching for the misinformation \u201ctwilight zone.\u201d \nNieman Lab. https://www.niemanlab.org/2020/12/searching-for-the-misinfor -\nmation-twilight-zone/.\nSilverman, Craig (2016, November\u00a016) This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSmith, R., Cubbon, S. and Wardle, C. (2020, November\u00a012). Under the surface: \nCovid-19 vaccine narratives, misinformation and data deficits on social media. \nFirst Draft. https://firstdraftnews.org/long-form-article/under-the-surface-\ncovid-19-vaccine-narratives-misinformation-and-data-deficits-on-social-media/.\nSommer, W. (2018). Instagram is the alt-right\u2019s new favorite haven. The Daily Beast . \nhttps://www.thedailybeast.com/instagram-is-the-alt-rights-new-favorite-haven.\nSystrom, K. (2014). 300 million Instagrammers sharing real life moments. Insta -\ngram Blog. https://about.instagram.com/blog/announcements/300-million-\ninstagrammers-sharing-real-life-moments.\nTiffany, K. (2020, August\u00a018). How Instagram aesthetics repackage QAnon. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2020/08/\nhow-instagram-aesthetics-repackage-qanon/615364/.\nVan Driel, L. and Dumitrica, D. (2021). Selling brands while staying \u201cauthentic\u201d: \nThe professionalization of Instagram influencers. Convergence , 27(1), pp.\u00a066\u201384. \nhttps://doi.org/10.1177/1354856520902136.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nAbout the authors\nSabine Niederer , PhD, is Professor of Visual Methodologies at the Amsterdam \nUniversity of Applied Sciences, where she heads the Visual Methodologies \nCollective, specializing in visual, digital, and participatory research of social \nissues. She is Program Manager of ARIAS, the platform for artistic research \nin Amsterdam and co-coordinator of the Digital Methods Initiative at the \nUniversity of Amsterdam.\nGabriele Colombo , PhD, is a Research Associate at King\u2019s College London, \nDepartment of Digital Humanities, and collaborates with DensityDesign, \na research lab at the Design Department of Politecnico di Milano. He is \naffiliated with the Visual Methodologies Collective at the Amsterdam \nUniversity of Applied Sciences.\n\n8 A f ringe mainstreamed, or tracing \nantagonistic slang\n  b\netween 4chan and \nBreitbart before and after Trump\nStijn Peeters, Tom Willaert, Marc Tuters, Katrien Beuls, Paul \nVan Eecke and Jeroen Van Soest\nAbstract\nWe studied whether the vernaculars of the extremely vitriolic, \u201cpolitically incorrect\u201d sub-forum of 4chan/pol/ have crossed over to the comment sec -\ntion of Breitbart News, a right-wing news website that was found in earlier research to have played a significant \u201cagenda-setting\u201d role in the 2016 U.S. \npresidential elections. We study if crossover exists around both the 2016 and \n2020 elections. In our analysis, we find evidence suggestive of such crossover, \ncentered around the presence first on 4chan and later Breitbart of a series of \nracist, antagonistic and otherwise extreme terms. This crossover of 4chan/\npol/\u2019s vitriolic vernacular marks an expansion of hyper-antagonistic \u201calt-\nright\u201d politics to Breitbart\u2019s more mainstream right-wing populist audience.\nKeywords: Alt-right, 4chan, Breitbart, vernacular crossover, extreme \nspeech\nResearch questions\nCan we find evidence of language originating on 4chan that propagates to \nthe comment sections of Breitbart News around the time of the 2016 U.S. \nelections? How to characterize the words used on 4chan as compared to \nBreitbart around that time? Does the use and change in use of language \non both platforms suggest a spread of extreme political thought? Can we \nobserve similar dynamics of language propagation between both platforms \naround the 2020 U.S. presidential elections?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch08\n166  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nEssay summary\nOver the past decade a diverse and increasingly influential far-right online \nmedia sphere has emerged. It has raised concerns that parts of this sphere \nmay function as incubators for radicalization. In particular, the 2016 \npresidential elections in the United States were marked by the coarsening \nof the tone of political discourse, with candidate and eventual winner \nDonald Trump slandering his opponents, spreading conspiracy theories \nand provoking xenophobia. Alongside Trump\u2019s insurgent takeover of the \nRepublican party, his election campaign during 2015 and 2016 marked the \nemergence of the \u201calt-right\u201d political movement, which perceived Trump \nas an alternative to establishment conservatism.\nAs a libertarian movement with a strongly xenophobic, often racist stance \ntowards immigration, the alt-right was also characterized by its use of \nantagonistic vernacular. We can think of this antagonistic slang as \u201cmemes,\u201d \na concept typically used to refer to user-generated shared images that seem \nto spread across platforms and between communities, but which can also be \nused to refer to any \u201cbuilding blocks of complex cultures\u201d online, including \nwords and phrases (Shifman, 2011, p189). Indeed, in the analysis on offer \nhere, we view specific phrases and tokens as such memetic building blocks \nthat seem to propagate within and between distinct environments online. \nA platform of interest in this context is the far-right image board 4chan, \nwhich has been positioned as a \u201cbirthplace of memes\u201d (Ludemann, 2018), \nan incubator of conspiracy theories like QAnon (De Zeeuw et al., 2020), and \na place of rapid innovation of oftentimes antagonistic language (Peeters et \nal., 2021). It might therefore be expected that antagonistic alt-right slang \nincubated on the platform has the potential to spread to a wider audience, \nwith 4chan acting as a breeding ground. To study this hypothesis, we look at 4chan as well as a more mainstream platform that has been associated with the alt-right, Breitbart News.\nThe questions are particularly relevant as the alt-right is a relatively \nunique, insurgent far-right political movement that rose to international \nattention in 2015 with remarkably little in the way of a centralized organi -\nzational structure, and for whom the circulation of memes and internet \njargon was fundamental to its success (Hawley, 2017). Most emblematically, \nthe memetic subcultural icon of \u201cPepe the Frog\u201d became notoriously as -\nsociated with this school of thought during the first half of the 2010s and \nachieved widespread attention (Lobinger et al., 2020). Arguably, however, \namong the alt-right\u2019s most significant accomplishments was the extent to \nwhich their antagonistic slang succeeded in framing political discussion. \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  167\nIllustrative of this pattern was for example the expression \u201ccuckservative\u201d \nwhich emerged in early 2015 on (now deplatformed) alt-right websites such \nas My Posting Career, The Right Stuff as well as on 4chan\u2019s notorious /pol/ \nforum (Bernstein, 2015). In its original far-right subcultural usage the term \nreferred to a genre of often racialized pornography thereby connecting a \ncritique of establishment republicanism with the far-right\u2019s longstanding \npreoccupation with masculinity and miscegenation. By the end of the year, \nthe prolific alt-right author Vox Day had self-published a track with the \ntitle Cuckservative: How \u201cconservatives\u201d betrayed America , and this alt-right \nmeme had effectively worked its way into political discussion amongst \nmainstream Trump voters. It is this type of \u201cpropagation\u201d of politically \nextreme vocabulary that is under study in this chapter.\nConsidering these recent events, there is a legitimate concern that \nthe subculture associated with sites at the \u201cbottom\u201d of the internet could \ninsinuate itself (or has already done so) with an extreme and conspiratorial \ndiscourse into the American political debate across a continually evolving \nrange of platforms. There are indications that it has already transpired in the \nmore recent 2020 U.S. election campaign. The QAnon persona, central to a \nright-wing conspiracy theory positing, among other things, that prominent \nmembers of the Democratic Party are part of a Satan-worshipping can -\nnibalistic cult, started on 4chan but has since become a major factor in \nmainstream U.S. politics and as such is now discussed on a wide variety \nof platforms (De Zeeuw et al., 2020; Stanley-Becker, 2020). The polarized \nlanguage we study reflects this rift in recent American political discourse.\nAn understanding of the internet as having a \u201cbottom\u201d implies the exist -\nence of further \u201clayers.\u201d Along these lines, at the top we would find big media \nconglomerates, often rooted in \u201clegacy media\u201d such as major newspapers \nas the New York Times, cable broadcasters as CNN, and newer online-first \noutlets like Vox. As one moves \u201cdown,\u201d platforms grow more obscure, with a smaller reach and less clear editorial or content policies. At the bottom, \none finds \u201cfringe\u201d sites, with obscure subcultures; this \u201cdeep vernacular \nweb\u201d (De Zeeuw and Tuters, 2020) can appear culturally baffling as well as \noffensive to the uninitiated. Sites in this stratum usually have a relatively \nsmall number of visitors, compared to mainstream sites. 4chan is particularly \nrelevant here, as a fringe platform that has nevertheless been scrutinized for \nits production of internet memes (Bernstein et al., 2011), peculiar subcultural \npractices (Nissenbaum and Shifman, 2017) as well as language innovation (Tuters and Hagen, 2020; Peeters et al., 2021).\nOur findings are based on datasets centered on the 2016 and 2020 U.S. \nelections, collected from 4chan/pol/ and from the comment section of \n168  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nBreitbart News, a conservative, right-wing American news website especially \npopular during the first period as a staunch supporter of eventual winner \nDonald Trump. Although it has been described as \u201cfactually dubious\u201d (Guess \net al., 2018), Breitbart News occupied a crucial place in the political media \necosystem at the time. Benkler et al. (2018) offered an in-depth study of \nBreitbart\u2019s \u201cagenda-setting\u201d role in that election. Their analysis shows how \nBreitbart \u201canchored\u201d a network of other similarly dubious right-wing news \nsites such as Daily Caller, Gateway Pundit and Infowars. Though no formal or \neditorial association between these sites exists, they provide a similar brand \nof content characterized as a mix of \u201cparanoid conspiracy interpretations \naround a core of true facts\u201d (Benkler, 2018, p.\u00a034). Together they occupied a crucial position in the media ecology around the 2016 elections.\nIn this ecology Breitbart is a particularly interesting site for several \nreasons. One is that, at the time, Breitbart was the largest of these sites \nwith approximately 10% of the entire general news audience according to one estimate (Malone, 2016). Founded by the deceased Andrew Breitbart, \nformerly a reporter for the Huffington Post, under the more recent editorship \nof Steve Bannon the site championed the right-wing libertarian Tea Party \nand a strongly American populist, civic nationalist agenda (cf. Burley, 2017). \nReceiving substantial financial support from the billionaire Mercer family, \nwho initially backed Ted Cruz in the 2015 U.S. election campaigning, Breit -\nbart would develop into a nakedly partisan branch of the Trump campaign \nwhile at the same time Bannon famously claimed that he considered the \nsite to be a \u201cplatform for the alt-right\u201d (Posner, 2016). With a background in \nboth high finance and documentary filmmaking, Bannon is a self-styled \npublic intellectual noted for his interest in an obscure branch of far-right \npolitical philosophy known as Traditionalism, which also had a readership \non 4chan/pol/ (Teitelbaum, 2020; Tuters and OILab, 2020). Bannon would \nlater join the Trump campaign as its chief strategist (Green, 2017). In 2016, \nBreitbart published an article entitled An establishment conservative\u2019s guide \nto the alt-right , co-authored by the notorious alt-right provocateur Milo \nYiannopoulos. An investigative report later revealed it to have been written \nwith the participation of known alt-right ideologues (Bernstein, 2017). As \nsuch, the site combines a clear, alt-right editorial position and explicit ties to the Trump campaign with a relatively wide reach.\nEarlier analyses of Breitbart, including Benkler et al.\u2019s, were limited to \nthe editorial content of the site. We instead study the comment sections of \nBreitbart\u2019s articles that routinely receive thousands of comments, many only \ntangentially related to the article\u2019s subject. These appear to be moderated \nloosely, if at all. A 2017 report cites Disqus, which provides the technology on \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  169\nwhich Breitbart\u2019s comment section runs, promising that Breitbart \u201c[wants] to \nwork with us to figure out ways to minimize [hate speech]\u201d (Captain, 2017). \nIn this permissive setting, the comment section of Breitbart\u2019s London section \nwas characterized as \u201ca malignant swamp of race-baiting, nativism and \nantisemitic conspiracy,\u201d even accused of providing a platform for notorious \nalt-right celebrities (Mulhall et al., 2017). Appearing to function like a largely \nunmoderated discussion forum, the comment threads can thus serve to \nstudy the political views and discourse of the readership of a highly active \nelement of far-right politics that moved increasingly to the center of the \nAmerican Republican party around the 2016 elections.\nIn this same period /pol/, the self-described \u201cpolitically incorrect\u201d \ndiscussion board of anonymous imageboard 4chan, overtook /b/ (the \n\u201crandom\u201d board) as the site\u2019s most active discussion forum. Previous \nquantitative research on /b/ has noted how the site was an \u201cexcellent \nvenue for studying innovation diffusion,\u201d due in part to the fact that it was \ngenerally considered as \u201cthe source of many online memes\u201d (Bernstein, \n2011, p.\u00a056). While in the earlier period in which /b/ had been more popular \n4chan was the source of innocuous memes such as LOLcats, /pol/ memes \nwere far more toxic, including offensive depictions of Pepe the Frog as well \nas the antisemitic triple parentheses phrasal meme (Tuters and Hagen, \n2020). While there has been some quantitative research into the diffusion \nof toxic /pol/ memes to other web communities (Zannettou et al., 2018), to \nour knowledge there is no previous empirical work focused specifically on \nthe crossover of vernacular language from /pol/ to another such threaded \ndiscussion forum.\nThis chapter, then, adds to a growing body of work focused on the \u201cmain -\nstreaming\u201d of previously \u201cfringe\u201d web spaces like 4chan as the source of a \n\u201cneoreactionary\u201d style of political discourse (Nagle, 2017; Wendling, 2018; \nBeran, 2019; Woods, 2019). 4chan and Breitbart represent two parts of the \nmedia ecosystem that are particularly interesting to study in the context \nof the polarized and increasingly extreme U.S. political landscape. As such, \nwe investigate whether 4chan\u2019s discourse resonates beyond its own borders \naround the time of the 2016 and 2020 U.S. presidential elections. Since so \nmuch of the discourse on 4chan\u2019s political discussion board, /pol/, can be \ncharacterized as conspiratorial, racist or otherwise extreme (cf. Tuters and \nHagen, 2020), its later occurrence on other platforms is of great interest to \nthose studying the mainstreaming of extremism and misinformation. While \nour analysis is primarily focused on the 2016 election campaign in which \nthe alt-right movement first gained prominence, we also provide an initial \nanalysis of the 2020 campaign for comparison.\n170  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nWe found that there are far more terms that appear only in the language \nof 4chan/pol/ than in the language of Breitbart comments. Additionally, of \nthe terms that over time are prominent first in one dataset and later in both, \nthose that first appear on 4chan are often highly political and furthermore \ncan be characterized as anti-Muslim and xenophobic (e.g., \u201cgermanistan\u201d), \nhomophobic or transphobic (e.g., \u201cxhe\u201d) or otherwise extreme (e.g., \u201cshitlibs\u201d). \nThese extreme terms are then later observed on Breitbart. Though a direct \nrelationship is difficult to ascertain, our initial findings suggested that \n4chan, an active but non-mainstream niche site, had an outsized impact \nthat reaches beyond its own confines.\nWe reflect on these findings, concluding that for the period 2015\u20132017 \n4chan/pol can be considered an originator or incubator of extreme discourse, \nwhere extreme idioms appear before propagating to the more mainstream \ndiscussion space of Breitbart News. Additionally, our observations indicate \nthat this propagation of idioms between 4chan and Breitbart News seem to \nbe less intense around the time of the 2020 U.S. presidential elections, and \nthat consequently, studies of extreme discourse and misinformation should \nconsider and monitor other platforms as the main sites of the mainstream -\ning of such terms. We end with a brief section on our data collection and \nanalytical methods.\nImplications\nOur findings indicate that around the time of the 2016 U.S. elections antago -\nnistic, highly political and problematic words that also can be characterized \nas xenophobic (e.g., \u201cgermanistan\u201d); transphobic (e.g., \u201cxhe\u201d) or otherwise \nextreme (e.g., \u201cshitlibs\u201d) first observed on 4chan later entered the discourse \nin the comment section of Breitbart News, a more mainstream platform with \nimportant connections to the Trump presidential administration. While \nearlier research has investigated the crossing over of particular ideas (e.g., \nconspiracy theories), our study provides empirical data that suggests that \nthis crossing-over also occurs on the level of language and is not bound \nonly to specific theories or ideas. The findings further support previous \nobservations about the sustained connection between 4chan/pol/ and \nBreitbart\u2019s comment section during this period.\nOne possible explanation for the propagation of extreme \u201cchan\u201d vernacular \ntowards Breitbart around the 2016 elections is that some 4chan posters \nalso frequent Breitbart\u2019s comment section. It would not be surprising if \nthey used the language they were familiar with, which could explain their \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  171\noccurrence in both spaces. Tracing whether actors move between these \nplatforms is difficult because 4chan is designed as an anonymous platform \n(Knuttila, 2011). 4chan posters are notoriously derisive of \u201cmainstream \nmedia\u201d and typically dismiss Breitbart as inadequately extreme. Although \nBreitbart has been described as having an \u201cextreme right-wing bias\u201d (Media \nBias/Fact Check, 2021), it is seen as a place for \u201cnormies.\u201d In the vernacular, \n\u201cnormies\u201d are those who follow mainstream media and otherwise adhere \nto common social norms (De Zeeuw et al., 2020). Nevertheless, it is possible \nthat some 4chan posters may also frequent Breitbart News, which would \nbe one explanation for the appearance of 4chan-like vernacular there. \nIt would be the manner for both this vernacular as well as the extreme \npolitical positions to which it implicitly and explicitly refers to spread to a new \u201cnormie\u201d audience.\nThough a direct relationship between both platforms remains difficult \nto ascertain, our initial findings suggest that 4chan, the active but non-\nmainstream niche site, had an outsized impact that reaches beyond its \nown confines. As such, we conclude that for the period 2015\u20132017 4chan/pol \ncan be considered an originator or incubator of extreme discourse, where \nextreme idioms appeared before they propagated to the more mainstream \ndiscussion space of Breitbart News. Additionally, our observations indicate \nthat this propagation of idioms between 4chan and Breitbart News seems to \nbe less intense around the time of the 2020 U.S. presidential elections, and \nthat consequently studies of extreme discourse and misinformation should \nconsider and monitor other platforms as the main sites of the mainstreaming \nof such terms.\nA key implication of our work, then, is that 4chan /pol/ might give an \nearly impression of problematic discourse that may become used by a wider \naudience at a later stage. As such, continued observation of the language \ndisseminated through these fringe platforms\u2014for which we offer one \nmethodological blueprint by addressing its propagation towards Breitbart \nNews\u2014might benefit journalists, researchers and policy makers seeking \nto signal the emergence of new extreme discourses on emerging platforms \nsuch as Parler (cf. Floridi, 2021) and others that have more recently gained prominence in the 2020 U.S. election campaign.\nMore fundamentally, our findings speak to the much-debated relationship \nbetween the \u201cbottom\u201d of the internet\u2014consisting of niche, often politically \nextreme sites\u2014and more mainstream sites. The observation and study of this \u201cbottom\u201d has acquired urgency as ideas and vernacular that originate \nin these parts have been implicated in several far-right terrorist attacks \nin the United States, Canada and New Zealand. Furthermore, sites like \n172  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n4chan serve as incubators for various impactful conspiracy theories, e.g., \n\u201cPizzagate\u201d (Tuters et al., 2018) and the figure of QAnon (De Zeeuw et al., \n2020). Indeed, while for many years the effects of the web were framed in \nterms of the democratic promise of participatory media (Jenkins, 2006; \nBenkler, 2006), the last half decade has shaken that narrative to its core \nwith the emergence of \u201cdark participation\u201d in the context of online political \ndiscussion (Quandt, 2018). The role of the upstart Breitbart in anchoring a \nright-wing news ecosystem that set the agenda for the 2016 U.S. election \nmay be seen as the fruition of earlier concerns over the fragmentation of the \nweb into personalized spheres (Pariser, 2011), which continue apace with the \nemergence of the alt-tech ecosystem that has benefited from social media \nplatforms\u2019 \u201cdeplatforming\u201d of the Trump movement (Rogers, 2020b). Given \nthe \u201cfringe\u201d quality of some of these sites we have good reason to believe \nthat their vernacular subculture will overlap with that of 4chan, as this \nstudy showed for the \u201cnormie\u201d website, Breitbart News, in the midst of the \n2016 U.S. election.\nFindings\nFor both the 2015\u20132017 and 2020\u20132021 periods, we split up the 4chan and \nBreitbart posts and comments in terms; each word, after filtering out \nhyperlinks and punctuation, is a term. For each term we can then classify \non which of the platforms it occurs on a per-month basis, resulting in a \npropagation pattern for each term (see Figure\u00a08.1).\nOur findings suggest that around the 2016 U.S. presidential elections, the \npolitical vocabulary associated with extreme right-wing politics consistently \nappears on 4chan first, and then on the more mainstream Breitbart News \nlater, potentially representing one strand of this propagation dynamic. We \nalso observed that this dynamic becomes less prominent around the 2020 \nelections, suggesting that the locus for this extreme idiom\u2019s propagation from \nthe \u201cbottom\u201d of the internet has again shifted. In particular, the analysis of \nthese propagation patterns allows for the following observations:\nFinding 1: Around the time of the 2016 U.S. presidential elections, the lan -\nguage of 4chan/pol/ contains more unique terms than that in the Breitbart \ncomment sections. Our analysis shows that there are more terms unique to \nthe /pol/ dataset than there are terms unique to the Breitbart dataset. Of \nthe 67,605 terms, 19,346 (28.6%) were classified as occurring in the 4chan/\npol/ dataset only, while 2,857 (4.2%) were classified as occurring only in the \nBreitbart dataset (see Figure\u00a08.2). 4chan has previously been described as a \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  173\nsource of subcultural and linguistic innovation (Nissenbaum and Shifman, \n2017). This finding empirically confirms the observation, at least concerning \nthe unique use of language on the forum. As English-language datasets, \nboth are concerned with informal political discussion focused primarily on \nthe United States context. Thus, while some variation may be expected; in \nprinciple, one might expect the language used to be similar between both, \nbut this is only partially the case.\n4chan\u2019s vernacular has been referred to as \u201cchanspeak\u201d: \u201cpeculiar in-\ngroup misspellings\u201d characterized by \u201cshortening, simplifying and cutting \ndown words\u201d (Fiorentini, 2013; Herring, 2012). While this is perhaps true for \nthe broader 4chan vernacular, the /pol/ slang we found is not adequately \ncaptured by this description. This can be attributed to the rapid linguistic \ninnovation on this forum (Peeters et al., 2020). The terms we find are more \nadequately described as \u201cphrasal memes,\u201d highly self-referential \u201cremixes\u201d \nof words, e.g., \u201ccuckerberg\u201d (a combination of \u201ccuck\u201d and \u201cZuckerberg\u201d). \nWhile a proper linguistic analysis of this vernacular is outside the scope \nof this article, the dataset on offer here could in the case of /pol/ serve as a \nstarting point for such a study.\nFinding 2: During the same period, a substantial number of terms are \nfirst only observed in the language on 4chan, the fringe platform, but later \nalso on Breitbart, the more mainstream platform, suggesting propagation \nof this vocabulary. Terms that occur on one platform first and later on \nanother platform or both platforms can be observed in both \u201cdirections\u201d; \nsome occur first on Breitbart while others occur first on 4chan/pol/. In total, \n2,043 terms (3%) follow such a pattern. Of these, 932 (45.6%) occur on 4chan \nfirst, while 1,111 (54.4%) occur on Breitbart first. This seems counterintuitive; \nit would imply that terms are first anchored in the language of Breitbart \nand only later in that of 4chan, which is difficult to reconcile with 4chan\u2019s reputation as a more innovative linguistic space as established in Finding \nfi gure\u00a08.1 Visualization of the monthly occurrence of the terms \u201ccuckerberg,\u201d \u201cgermanistan,\u201d \n\u201cxhe,\u201d and \u201cshitlibs\u201d around the time of the 2016 \nu.\nS. presidential elections, between June\u00a02015 \nand March\u00a02017. \nfo\nr each month, terms are classified (color-coded) based on a comparison of their \nrelative frequencies in 4chan/pol posts and in the comments on \nbr\neitbart \nne\nws. These words \nrepresent the political vernacular found within the 4chan dataset.\n174  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n1. On the other hand, Breitbart is a far larger and arguably more influential \nplatform, and agenda-setting power may be attributed to it in that capacity. \nFrom this perspective, the fact that a substantial number of terms occur on \n4chan first at all is significant and suggests that the terms might indeed \n\u201cpropagate,\u201d with language spreading\u2014directly or indirectly\u2014from 4chan \neventually to Breitbart.\nA closer look at these terms reveals that they can be divided into two \nbroad categories\u2014\u201cnamed entities\u201d and \u201cneologisms.\u201d Linguistically, named \nfi gure\u00a08.2 cl assifications of all words in the 2015\u20132017 data ( n  = 67,605) over time. The consecutive \noccurrences of each word are represented as a single row of per-month squares that are color-\ncoded for the occurrence of the word in 4chan/pol/ posts and \nbr\neitbart comments respectively.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  175\nentities refer to all terms that are proper names, for example, countries \nand people. The other category, \u201cneologisms,\u201d are words that are neither \ncommon English nor otherwise used in \u201cnormal\u201d discourse. In practice, \nthese terms are mostly various slurs and part of a memetic vocabulary that \nis associated with 4chan discourse.\nThe named entities cannot reasonably be assumed to originate on either \nplatform. Instead, the likely explanation for the occurrence of these terms \nis that they refer to people, places or organizations that were discussed \nbecause they were relevant to a current event or news item. This indicates \nthat Breitbart users discussed these topics before 4chan, which is interesting \ninsofar as it provides insight into the type of topics discussed by both forums \nand how rapidly they enter the discourse. The \u201cneologisms\u201d (including the \nexamples in Figure\u00a08.1) on the other hand are likely to originate in the \nvernacular of online platforms (Peeters et al., 2021). As such, the fact that they \nappear on 4chan and later on Breitbart suggests that they do propagate from \nthe one to the other, either directly or via another intermediary platform.\nFinding 3: Around the time of the 2016 U.S. presidential elections, many \nterms that seem to propagate from 4chan/pol/ to Breitbart reflect an extreme \nfar-right politics. Of these terms that can be assumed to originate on 4chan/\npol/, most are implicitly or explicitly related to far-right and conspiratorial \ntheories or ideas. This is not surprising, since 4chan/pol/ itself has been \nassociated with the \u201cPizzagate\u201d political conspiracy (Tuters et al., 2018) \nand has been described as a \u201ckind of petri dish for concocting extreme \nand extremely virulent forms of right-wing populist antagonism\u201d (Tuters \nand Hagen, 2020, p.\u00a02223). Of the words that appear first on 4chan (see also \nFigure\u00a08.1) several are emblematic of an extreme political discourse, such as \n\u201ccuckerberg\u201d (a jab at Facebook owner Mark Zuckerberg combined with the \nslur \u201ccuckold\u201d; other variations found were \u201ccuckservative(s),\u201d \u201ccucktard,\u201d \n\u201ccucky,\u201d and \u201ccuckery\u201d), anti-Muslim terms such as \u201cgermanistan\u201d and \n\u201cbritainistan,\u201d words like \u201cxhe\u201d (used mockingly to insult transgender people), \nand various slurs aimed at liberal U.S. voters like \u201cshitlibs\u201d and \u201cberniebots.\u201d1\nWhile 4chan/pol/ is well-known as a far-right discussion space (Hine et \nal., 2017; Ludemann, 2018), our data and analyses show that the vocabulary \nassociated with this discourse is not contained to this \u201cfringe\u201d platform but \nafter initial usage it also appears on more mainstream platforms. More \nspecifically, the various xenophobic or otherwise extreme slurs and phrasal \nmemes that are developed and incubated on 4chan/pol/ in some cases see \n1 T he full list of terms that propagate may be found in the dataset available from Zenodo at \nhttps://doi.org/10.5281/zenodo.5535341.\n176  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nuptake in the comments on Breitbart News. As most of this language is \nunambiguous, and hard to mistake for anything else than derogatory, it \nraises concerns that not only the language but also the extreme political \ndiscourse associated with it is shared across sites.\nFinding 4: Around the time of the 2020 U.S. presidential elections, the \naforementioned mainstreaming of extreme chan vernacular seems to be less \noutspoken. Around the time of the 2020 U.S. presidential elections, some of \nthe vernacular that propagated in 2015\u20132017 remains shared between 4chan \nand Breitbart, with notable examples including \u201ccuck\u201d and its derivatives, \nsuch as \u201ccucked.\u201d Further analysis shows, however, that comparatively fewer \nnew terms propagate from 4chan to Breitbart News around this time. As \nobserved in our 2020\u20132021 dataset, only 347 terms out of 57,602 (or 0.6% \ncompared to 3% for the 2015\u20132017 dataset) actually move from one platform \nto the other, and of those, only 124 were classified as moving from 4chan/\npol to Breitbart (see Figure\u00a08.3). Closer inspection of these moving terms \nreveals few original vernacular terms, even though the data suggest that \nduring this period, 4chan in and of itself remains an incubator for extreme \nvernacular. Examples that do point towards a continued mainstreaming of \n4chan terminology and memes concern the terms \u201ccoomer\u201d (which refers \nto the 4chan meme of the \u201c20-year-old coomer\u201d), and \u201clibshits\u201d (an inver -\nsion of the previously discussed term \u201cshitlibs\u201d), but in comparison with \nthe 2015\u20132017 period, the language propagation dynamics between both \nplatforms seems much less outspoken.\nAny comparison between the two datasets is necessarily tentative as we \nare yet to capture as much of the post-election period as we did for the 2016 \nelections. As such there remains a possibility that the propagation dynamic \nlags in this case, or that Breitbart\u2019s comment space has later become milder \nfor other reasons\u2014perhaps 4chan\u2019s interest in Breitbart has diminished, \nwhich may be found in a subsequent analysis. Nevertheless, the discourse \naround both elections may be assumed to reach its zenith in the months \nsurrounding the election date. As such, the data gathered around the 2020 \nelections should provide a representative impression of the discourse around \nthat election, even if it is quantitatively smaller and of a shorter duration \nthan the earlier dataset.\nThese empirical observations strengthen previous assertions in the \nliterature that the period 2015\u20132017 was one characterized by an intensi-\nfied and salient \u201cmainstreaming\u201d of harmful vernacular between 4chan/\npol and Breitbart News. Possible explanations for the relative decline in \nthe propagation of idioms from 4chan to Breitbart around the 2020 U.S. \npresidential elections include the fact the site experienced a precipitous \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  177\ndecline after Trump took office, ultimately losing as much as three quarters \nof its total audience (Ellefson, 2019). According to Steve Bannon the site \nappears to have struggled financially following an advertiser boycott, \nwhich began in 2016 and was organized by Sleeping Giant to protest the \nsite\u2019s bigotry and sexism (Klayman, 2019). The billionaire Mercer family \nsold their shares in the site in 2017 and are currently majority stakeholders \nof the alternative social media site Parler, connected to the 2021 storm -\ning of the DC Capitol (Lerman, 2021). The growth in significance of such \nfi gure\u00a08.3 cl assifications of all words in the 2020\u20132021 data ( n  = 57,603) over time. The consecutive \noccurrences of each word are represented as a single row of per-month squares that are color-\ncoded for the occurrence of the word in 4chan/pol/ posts and \nbr\neitbart comments respectively.\n178  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n\u201calt-tech sites\u201d can be seen as one of the bi-products of the \u201cdeplatforming\u201d \nof alt-right figureheads from social media\u2014including eventually Trump \nhimself (Rogers, 2020b).\nMethods\n4chan data was collected with 4CAT, a forum analysis toolkit (Peeters and \nHagen, 2021) that contains a dataset comprising 4chan /pol/ data from 2013 \nto the present. This data is collected continuously (as it is posted on 4chan) \nby the tool itself and, for the period prior to 2018, supplemented with data \nfrom 4plebs.org, a third-party 4chan archive which publishes semi-regular \ndata \u201cdumps\u201d on the Internet Archive, containing all posts made on a number \nof 4chan\u2019s boards, including /pol/. (Merged 4plebs\u2019 and 4CAT\u2019s datasets have \nbeen used in other research on 4chan, too (Tuters and Hagen, 2019; Vou\u00e9 et \nal., 2020; Jokubauskait\u0117 and Peeters, 2020).) Notably, posts are included even \nif they are later deleted from the site, as all posts eventually disappear from \n4chan itself, as threads are deleted after a period of inactivity.\nThe 2015\u20132017 Breitbart data was collected between September\u00a02\u20139, 2019 \nusing a custom scraper written in Python which first crawled breitbart.\ncom for internal links to create an index of all articles posted on the site, \nand then collected all comments for all articles posted between June\u00a02015 \nand March\u00a02017, using the Disqus API. The resulting dataset reflects the \nstate of the comment section as it was at the moment of scraping. There \nis a possibility that some comments were removed between the moment \nof posting and the moment of scraping, up to 4 years later; however, as \nmentioned earlier, Breitbart\u2019s moderation policy seems to have been lax \nduring the period we study, and it is unlikely that later policies were enacted \nretroactively. We therefore assume that the data is a reasonably accurate \nreflection of what the comment threads would have looked like closer to \nthe date the comments were posted. The 2020\u20132021 Breitbart data was \ncollected with the same technique, between February\u00a017 and March\u00a03, 2021.\nOur first dataset thus spans the period between the announcement of \nDonald Trump\u2019s candidacy for the U.S. presidential election (June\u00a02015) \nand his first months in office, whereas the second dataset comprises a \nsmaller interval around the 2020 U.S. elections in which Trump was again a \ncandidate (and lost). As data capture of this nature is cumbersome, we were \nunable to gather a dataset comprising an equal timespan so shortly after \nthe 2020 elections; a more direct comparison would be a fruitful avenue \nfor future work.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  179\nBefore analyzing the captured data, for both datasets we cleaned the \nscraped comments and posts by applying case folding and removing punc -\ntuation, URLs, HTML tags (in Breitbart comments) and comment referral \nnumbers such as \u201c>>280207128\u201d (in /pol/ comments).\nAnalysis\nThis chapter addresses the questions of (1) whether we can empirically \nidentify terms that are first prominent in the language on 4chan/pol/ and \nlater also in the language of the Breitbart comment sections around the time \nof the 2016 U.S. presidential elections, (2) how to characterize the language \nused on 4chan/pol/ compared to that of Breitbart\u2019s comment sections at that \ntime, (3) whether the nature of these identified terms indicates a spread of \nextreme political thought, and (4) whether we can identify similar dynam -\nics between both platforms around the time of the 2020 U.S. presidential \nelections. We expect that we can observe this pattern for terms associated \nwith far-right thought, and that it constitutes a mainstreaming of fringe, \ntaboo or otherwise extreme political concepts.Quantitative analysis\nWe investigate corpora of posts and comments using methods from \nnatural language processing to empirically identify terms that occur first \non one platform and then on another, and to quantify the propagation \npatterns of these terms between both platforms (Willaert et al., 2020; \nWillaert et al., 2021). We collected two datasets for both platforms, a first \nset comprising posts from June\u00a02015 through March\u00a02017, and a second \nset containing data from May\u00a02020 through January\u00a02021. These texts \nwere then tokenized (split into individual terms). For both platforms, the \nmonthly frequencies of each term were counted, and those terms with an \nabsolute frequency of less than 200 were removed, as these were mostly \nless germane and included typos. Next, the relative monthly frequency of \neach term was calculated for both /pol/ and Breitbart. Relative frequencies \nwere used because we are interested in the prominence of the terms in \nthe language of each platform, and we aim to compare this prominence \nbetween platforms. We then compare these relative frequencies and \nclassify each term into one of four classification bins, indicating whether \nfor a given month the term:\n\u2013\n o\nccurred neither on /pol/ nor on Breitbart,\n\u2013\n o\nccurred on both /pol/ and Breitbart,\n180  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n\u2013 o ccurred exclusively on /pol/, or\n\u2013\n o\nccurred exclusively on Breitbart.\nFor each term, this analysis results in a sequence of classification bins. In \norder to reduce the influence of very low frequency terms, a term is only \nassigned to the Breitbart bin or /pol/ bin if it had a relative frequency of at \nleast 0.00001%. If not, its frequency is considered to be 0 for that month. \nThis filtering resulted in a classification sequence for each term, which was \nvisualized using color coding (Figure\u00a08.2).\nQualitative analysisThe initial quantitative approach yielded a subset of terms for both periods \nthat warranted further scrutiny; we are particularly interested in those terms \nthat were first observed as prominent on 4chan/pol/ and later also observed on \nBreitbart. Our approach here was to first remove any obvious named entities \n(people, countries, institutions) from the list as well as common English \nlanguage. The remaining tokens could then be analyzed in more detail via a \ncloser reading, in which the context and occurrence of the token on 4chan/pol/ \nas well as on other platforms is studied via 4plebs (the searchable archive of \n/pol/) and 4CAT (the modular web platform scraping tool). Here we retained \nwords with a clear political (sub)text, similar to those shown in Figure\u00a08.1.\nAs such, we have employed a quali-quantitative approach (Venturini \nand Latour, 2010), where we combine an initial computational analysis of \na large dataset to extract a relevant subset of the corpora at hand, which \nwe then analyze further with a more interpretative qualitative approach \nof this subset.\nReferences\nBenkler, Y. (2006). The wealth of networks: How social production transforms markets \nand freedom . Yale University Press.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBeran, D. (2019). It came from something awful: How a toxic troll army accidentally \nmemed Donald Trump into office . St. Martin\u2019s Publishing Group.\nBernstein, J. (2015, July\u00a027). Behind the racist hashtag that is blowing up Twitter. \nBuzzFeed News . https://www.buzzfeednews.com/article/josephbernstein/\nbehind-the-racist-hashtag-some-donald-trump-fans-love.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  181\nBernstein, J. (2017, October\u00a05). Here\u2019s how Breitbart and Milo smuggled Nazi and \nwhite nationalist ideas into the mainstream. BuzzFeed News . https://www.\nbuzzfeednews.com/article/josephbernstein/heres-how-breitbart-and-milo-\nsmuggled-white-nationalism.\nBernstein, M., Monroy-Hern\u00e1ndez, A., Harry, D., Andr\u00e9, P., Panovich, K., and \nVargas, G. (2011). 4chan and /b/: An analysis of anonymity and ephemerality in \na large online community. In Proceedings of the International AAAI Conference \non Web and Social Media , 5(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/\narticle/view/14134.\nBurley, S. (2017). Disunite the right: The growing divides in the pepe coalition. \nPolitical Research Associates. https://www.politicalresearch.org/2017/09/19/\ndisunite-the-right-the-growing-divides-in-the-pepe-coalition.\nCaptain, S. (2017, March\u00a08). Disqus grapples with hosting toxic comments on \nBreitbart and extreme-right sites. Fast Company . https://www.fastcompany.\ncom/3068698/disqus-grapples-with-hosting-toxic-comments-on-breitbart-\nand-extreme-right-sites.\nDay, V. and Eagle, J. R. (2016). Cuckservative: How \u201cconservatives\u201d betrayed America . \nCastalia House.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion. First Monday . https://doi.org/10.5210/fm.v25i11.10643.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nEllefson, L. (2019, August\u00a07). Breitbart\u2019s audience has dropped 72% since Trump \ntook office\u2014As other right-wing sites have gained. The Wrap . https://www.\nthewrap.com/breitbart-news-audience-dropped-steve-bannon-72-percent/.\nFiorentini, I. (2013). \u201cZOMG! Dis is a new language\u201d: The case of lolspeak. Newcastle \nWorking Papers in Linguistics , 13(1), pp.\u00a090\u2013108.\nFloridi, L. (2021). Trump, Parler, and regulating the infosphere as our commons. \nPhilosophy & Technology , 34(1), pp.\u00a01\u20135. https://doi.org/10.1007/s13347-021-00446-7.\nGreen, J. (2017). Devil\u2019s bargain: Steve Bannon, Donald Trump, and the nationalist \nuprising . Penguin.\nGuess, A., Nyhan, B., and Reifler, J. (2018). Selective exposure to misinformation: \nEvidence from the consumption of fake news during the 2016 U.S. presidential \ncampaign [Working paper]. http://www.dartmouth.edu/~nyhan/fake-news-2016.\npdf.\nHawley, G. (2017). Making sense of the alt-right . Columbia University Press.\nHerring, S. (2012). Special internet language varieties: Culture, creativity & language \nchange [Paper]. The II LETiSS Workshop Language Go Web: Standard and \nNonstandard Languages on the Internet, Pavia.\n182  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nHine, G., Onaolapo, J., Cristofaro, E. D., Kourtellis, N., Leontiadis, I., Samaras, R., \nStringhini, G., and Blackburn, J. (2017). Kek, cucks, and God emperor Trump: \nA measurement study of 4chan\u2019s politically incorrect forum and its effects \non the web. Proceedings of the International AAAI Conference on Web and \nSocial Media, 11(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/article/\nview/14893.\nJenkins, H. (2006). Convergence culture: Where old and new media collide . New \nYork University Press.\nJokubauskait\u0117, E. and Peeters, S. (2020). Generally curious: Thematically distinct \ndatasets of general threads on 4chan/pol/. In Proceedings of the International \nAAAI Conference on Web and Social Media (pp.\u00a0863\u2013867), 14.\nKlayman, A. (2019). The Brink [Feature documentary; Digital film]. https://ali -\nsonklayman.com/the-brink.\nKnuttila, L. (2011). User unknown: 4chan, anonymity and contingency. First Monday . \nhttps://doi.org/10.5210/fm.v16i10.3665.\nLerman, R. (2021, February\u00a024). Major Trump backer Rebekah Mercer orchestrates \nParler\u2019s second act. Washington Post . https://www.washingtonpost.com/\ntechnology/2021/02/24/parler-relaunch-rebekah-mercer/.\nLobinger, K., Kr\u00e4mer, B., Venema, R., and Benecchi, E. (2020). Pepe\u2014Just a funny \nfrog? A visual meme caught between innocent humor, far-right ideology, and \nfandom. In B. Kr\u00e4mer and C. Holtz-Bacha (Eds.), Perspectives on populism and \nthe media  (pp.\u00a0333\u2013352). Nomos. https://doi.org/10.5771/9783845297392-333.\nLudemann, D. (2018). /pol/emics: Ambiguity, scales, and digital discourse on \n4chan. Discourse, Context & Media , 24, pp.\u00a092\u201398. https://doi.org/10.1016/j.\ndcm.2018.01.010.\nMalone, C. (2016, August\u00a018). Trump made Breitbart great again. FiveThirtyEight . \nhttps://fivethirtyeight.com/features/trump-made-breitbart-great-again/.\nMedia Bias/Fact Check. (2021). Breitbart. https://mediabiasfactcheck.com/breitbart/.\nNagle, A. (2017). Kill all normies: Online culture wars from 4Chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNissenbaum, A. and Shifman, L. (2017). Internet memes as contested cultural \ncapital: The case of 4chan\u2019s /b/ board. New Media & Society , 19(4), pp.\u00a0483\u2013501. \nhttps://doi.org/10.1177/1461444815609313.\nPapasavva, A., Zannettou, S., Cristofaro, E. D., Stringhini, G., and Blackburn, J. \n(2020). Raiders of the lost kek: 3.5 years of augmented 4chan posts from the \npolitically incorrect board. Proceedings of the International AAAI Conference \non Web and Social Media , 14, pp.\u00a0885\u2013894.\nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nPeeters, S. and Hagen, S. (2021). The 4CAT Capture and Analysis Toolkit: A Modular \nTool for Transparent and Traceable Social Media Research (SSRN Scholarly \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  183\nPaper ID 3914892). Social Science Research Network. https://doi.org/10.2139/\nssrn.3914892.\nPeeters, S., Tuters, M., Willaert, T., and de Zeeuw, D. (2021). On the vernacular \nlanguage games of an antagonistic online subculture. Frontiers in Big Data , \n4(65). https://doi.org/10.3389/fdata.2021.718368.\nQuandt, T. (2018). Dark participation. Media and Communication , 6(4), pp.\u00a036\u201348. \nhttps://doi.org/10.17645/mac.v6i4.1519.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nShifman, L. (2012). An anatomy of a YouTube meme. New Media & Society , 14(2), \npp.\u00a0187\u2013203. https://doi.org/10.1177/1461444811412160.\nStanley-Becker, I. (2020, August\u00a01). How the Trump campaign came to court QAnon, \nthe online conspiracy movement identified by the FBI as a violent threat. Washing-\nton Post . https://www.washingtonpost.com/politics/how-the-trump-campaign-\ncame-to-court-qanon-the-online-conspiracy-movement-identified-by-the-fbi-as-\na-violent-threat/2020/08/01/dd0ea9b4-d1d4-11ea-9038-af089b63ac21_story.html.\nTeitelbaum, B. R. (2020). War for eternity: The return of traditionalism and the rise \nof the populist right . Penguin.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nTuters, M., Jokubauskait\u0117, E., and Bach, D. (2018). Post-truth protest: How 4chan \ncooked up the Pizzagate bullshit. M/C Journal , 21(3), Article\u00a03. https://doi.\norg/10.5204/mcj.1422.\nTuters, M. and OILab. (2020). Esoteric fascism online: 4chan and the Kali Yuga. \nIn L. D. Valencia-Garc\u00eda (Ed.), Far-right revisionism and the end of history: Alt/\nhistories (pp.\u00a0287\u2013303). Routledge.\nVenturini, T. and Latour, B. (2010). The social fabric: Digital footprints and quali-\nquantitative methods. Proceedings of Futur En Seine 2009: The Digital Future of \nthe City . Futur en Seine 2009.\nVou\u00e9, P., De Smedt, T., and De Pauw, G. (2020). 4chan & 8chan embeddings. \nArXiv:2005.06946 [Cs] . http://arxiv.org/abs/2005.06946.\nWendling, M. (2018). Alt-Right: From 4chan to the White House . Pluto Press.\nWillaert, T., Van Eecke, P., Beuls, K., and Steels, L. (2020). Building social media \nobservatories for monitoring online opinion dynamics. Social Media + Society , \n6(2). https://doi.org/10.1177/2056305119898778.\nWillaert, T., Van Eecke, P., Van Soest, J., and Beuls, K. (2021). A tool for tracking the \npropagation of words on Reddit. Computational Communication Research , 3(1), \npp.\u00a0117\u2013132. https://doi.org/10.5117/CCR2021.1.005.WILL.\n184  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nWoods, A. (2019). Cultural Marxism and the cathedral: Two alt-right perspec -\ntives on critical theory. In C. M. Battista and M. R. Sande (Eds.), Critical theory \nand the humanities in the age of the alt-right (pp.\u00a039\u201359). Springer. https://doi.\norg/10.1007/978-3-030-18753-8_3.\nZannettou, S., Caulfield, T., Blackburn, J., De Cristofaro, E., Sirivianos, M., Stringhini, \nG., and Suarez-Tangil, G. (2018). On the origins of memes by means of fringe web \ncommunities. ArXiv:1805.12512 [Cs] . http://arxiv.org/abs/1805.12512.\nFunding\nThe authors received funding from the ODYCCEUS project within the \nEuropean Union\u2019s Horizon 2020 program, grant agreement number 732942.\nData availability\nDatasets with the monthly term counts for Breitbart comments and 4chan/\npol/ counts for the periods under investigation are available from Zenodo at \nhttps://doi.org/10.5281/zenodo.5535341. The data do not contain any personal \ninformation or post-level metadata.\nAbout the authors\nStijn Peeters , PhD, is Assistant Professor in Media Studies at the University \nof Amsterdam, Technical Director of the Digital Methods Initiative, and \na co-investigator of the CAT4SMR project, where he has (co-)developed \nseveral research tools such as 4CAT. His research interests include the \nmedia-archaeological analysis of fringe communities on social media.\nTom Willaert , PhD, is a postdoctoral researcher in digital methods at the \nVrije Universiteit Brussel. His research bridges methodological gaps between \ndata science and humanities interpretative practice, with a focus on methods \nfor the analysis of online (mis)information.\nMarc Tuters , PhD, is a Senior Lecturer in Media Studies at the University of \nAmsterdam where his current research examines radical visual subcultures \nat the bottom of the Web together with colleagues at the Open Intelligence \nLab as well as the Digital Methods Initiative.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  185\nKatrien Beuls , PhD, is Assistant Professor in artificial intelligence in the \nFaculty of Computer Science at the University of Namur.\u00a0Her main research \ninterests include emergent communication and language, and computational \nconstruction grammar.\nPaul Van Eecke , PhD, is Assistant Professor in the Artificial Intelligence \nLaboratory at the Vrije Universiteit Brussel. His main research topics include \nthe emergence and evolution of language through communicative interac -\ntions and computational construction grammar and its applications.\nJeroen Van Soest , MSc, is a developer and member of the Evolutionary \nand Hybrid AI team in the Artificial Intelligence Laboratory at the Vrije \nUniversiteit Brussel (VUB). He has developed NLP tools and data science \napplications for the Horizon 2020 ODYCCEUS project and is VUB\u2019s lead \ndeveloper on the imec-ICON Trendify project.\n\n9 P olitical TikTok\nPlayful performance, ambivalent critique and event-\ncommentary\nNatalia S\u00e1nchez-Querub\u00edn, Shuaishuai Wang, Briar Dickey \nand Andrea Benedetti\nAbstract\nDuring the U.S. presidential election of 2020, TikTok, an app known for \nlip-synching and remixes of popular media, became a tool for ludic civic \nengagement, ambivalent critique and event-commentary. More specifi -\ncally, TikTokers practiced types of engagement such as playful political \nperformance, in which they express sentiments about a candidate by \ndancing or singing. They also practice remix as ambivalent critique by \njuxtaposing news clips and music to comment on current events. These \nexamples evoke genres of ludic civic engagement such as flash mobs and \ntactical clowning while also exhibiting qualities specific to TikTok. The \nrhetorical power of playfulness and remix lies in distorting, exaggerating, \nand dramatizing; on TikTok, these practices are mainstream rather than \nfringe, raising questions about the contribution of the platform to political \ndiscourse.\nKeywords: TikTok, remix video, playful engagement, ambivalent critique, \nevent-commentary\nResearch questions\nHow are people using TikTok in the run-up to the 2020 U.S. presidential \nelection, and how to characterize TikTokers\u2019 political engagement?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch09\n188  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nEssay summary\nDuring the 2020 U.S. presidential election campaign season, TikTok, together \nwith other social media platforms, served a great deal of political content in \nthe form of short videos. In doing so, TikTok became \u201cthe default platform \nfor millions of teenagers who want to educate themselves on issues, express \ntheir political ideologies and organize to take action\u201d (Lorenz, 2020a). \nJournalists reported, for example, on the TikTok teenagers that \u201cmeme the \nvote\u201d (Pardes, 2020), the activities of TikTok party-based coalitions or \u201chype \nhouses\u201d (Lorenz, 2020b) as well as the app\u2019s political misinformation problem.\nThese days people routinely use social media to engage with societal \nissues and events such as elections. For example, YouTube vloggers discuss \npolitics and conspiracy theories. Some of them amass large audiences and \nbecome ideological (social media) influencers (Lewis, 2020; Creech and \nMaddox, 2020). Remixing news content is also a popular sense-making \npractice and form of cultural commentary (Geboers, 2019). Reactions to \nevents circulate on Reddit, Twitter, Facebook, and 4Chan as memes and \nviral clips (Nagle, 2017; Tuters and Hagen, 2020). TikTok also assumed this \nrole in the run-up to the elections through its well-known cultural practices \nof lip-synching and creating sketches involving audio clips from popular \nmedia. TikTok has been described as a \u201cnever-ending talent show\u201d (Aroesti, \n2019, para. 4), for which people create content by replicating, remixing, and \nadapting media and sounds.\nOur research asks how people are using TikTok and its features politically. \nWe analyze popular TikTok videos associated with the 2020 presidential \ncandidates, Trump, Biden, and Sanders, using mixed methods. What we \nfind supports the argument that TikTok is an emerging tool for ludic civic \nengagement, ambivalent critique, event-commentary as well as the main-\nstreaming of polarizing satire. These findings are in line with the argument \nthat online media can facilitate \u201cparticipation through their performative, \nexperimental, and creative affordances\u201d (Glas et al., 2019, p.\u00a011). Moreover, \nthe practices that we explore in this chapter evoke ideas already familiar \nin media and political studies (e.g., using performance for political critique) \nwhile also exhibiting characteristics unique to TikTok as a medium. TikTok \nuse during the elections is, in this way, a recent example of the convergence \nbetween \u201ccitizenship, media technologies, and play\u201d (Glas et al., 2019, p.\u00a011).\nTikTok, we learn, remained \u201cfresh\u201d during the election cycle. The top \nvideos associated with Trump, Biden, and Sanders returned by the app (1,000 \nvideos per candidate), on two different dates, March\u00a02020 and January\u00a02021, \nshowed little overlap. Also, each set of videos addressed events current when \nPoli Ti cal Ti KT o K 189\nthe queries were made, thus offering evidence that TikTok is an emergent \nevent-commentary app.\nFurthermore, two media practices were predominant amongst the most \npopular videos. On the one hand, people use TikTok to practice playful \npolitical performance. By \u201cperformance,\u201d we refer to how people use \nsocial media to stage a persona\u2014in this case, a persona with a political \nstance\u2014while dancing, acting, and singing. In addition, we differentiate \nthree types of videos that involve this media practice. People \u201cstage an \nopinion\u201d about a candidate by acting and dancing, \u201cdocument and share \nactivities\u201d like voting, and \u201cgive speeches.\u201d Medina et al. (2020) describe the \npolitically engaged TikTok user in a similar way, namely, as a \u201cperformer \nwho externalizes personal political opinion via an audio-visual act, with \npolitical communication becoming a far more interactive experience than \non YouTube or Instagram\u201d (2020, p.\u00a0264).\nSecondly, we argue, TikTok users practice remix as ambivalent critique. \nThat means they use the app to re-edit, modify, and juxtapose clips from \nthe news and popular culture to comment on the elections. We see this \npractice in two types of videos. People \u201cdramatize\u201d news clips and remix each \nother\u2019s content to form counterarguments, which we call \u201cpartisan duetting \nand stitching.\u201d We add the term \u201cambivalent\u201d to emphasize that the intent and tone of these remix videos is difficult to pinpoint. Humor and serious \ncritique as well as engagement and disinterest appear to coexist in TikTok.\nFake news and conspiratorial narratives, we find, are mostly absent \nfrom the most popular content. However, the performative, playful, and \nambiguous tone of the videos, as well as its hyperpartisan and humorous \nnature invite reflection about problematic behavior on the app and the \ncontributions made to political discourse.\nImplications\nTikTok as an emerging app for event-commentary\nSocial media are described as \u201cevent-following machines\u201d when content \nabout an issue is fresh and aligns with current events. For instance, Twitter \nis the micro-blogging site where journalists, politicians, and lay people \nvoice opinions about pressing matters and inform themselves about what \nis happening during and in the aftermath of protests, natural disasters, and \ncultural events (Rogers, 2014, 2020; Bruns and Weller, 2016; Rathnayake and \nSuthers, 2018). A \u201cstale\u201d social media, on the contrary, is no longer the go-to \n190  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nspace to find information about what is happening or spread one\u2019s message. \nIt is also not an ideal source of data for cultural analysis.\nTikTok, we find, remained \u201cfresh\u201d during two different moments of the \nelection cycle. The most popular videos associated with Donald Trump, \nBernie Sanders, and Joe Biden, collected first in March\u00a02020 and later, \nin January\u00a02021, showed little overlap. Furthermore, each set of videos \naddressed events related to the elections that were important at the time the \nqueries were made. For example, videos associated with Trump, collected \nin March\u00a02020, featured clips from \u201cNamaste Trump,\u201d a rally held in India \nin late February\u00a02020. At the event, Trump was cheered by thousands of \nsupporting Indians (Crowley, 2020). Throughout and after the event, people \nused TikTok to share their sentiment about the upcoming election and \nvoting preferences. In February\u00a02021, the most popular videos addressed, \nby contrast, the outcomes of the election and issues such as misinformation \nand the alleged voter fraud to which, according to Trump supporters, Biden \nowed his victory. These findings add weight to the emerging argument that \nTikTok is a platform for political communication, issue-formation, and \nevent-commentary (Hautea, 2021).\nPlayful political performance: staging opinions, giving a speech, and \ndocumenting\nIn academic discussions, elections are theorized as theater, performance, and \nspectacles that depend on media coverage and are increasingly fashioned as \nentertainment (Chou and Roland, 2016). For example, politicians sit down \nfor interviews on television shows. Magazines report on the holidays and \nfashion choices of presidential candidates, making them into spectacles. \nPublic figures also promote themselves on social media like Twitter, a \nsoftware platform, but also, metaphorically, a place from which to speak \nto one\u2019s followers (Gillespie, 2010). Conventions and rallies feature musical \nacts and guest artists that lend candidates an air of coolness.\nCitizens also engage in political performance. Social media becomes a \ntool to stage a persona, with a political identity and stance. People use their \nsocial media accounts, for example, to share opinions about current issues, \ndonate, and make public their political affiliations. Sharing news articles, \nposting selfies wearing campaign gear, creating memes, and recording videos \ntalking about their experiences all can be forms of political performance.\nTikTok is a space for citizen political performance, too, albeit of a par -\nticular playful nature. In the context of the U.S. elections, TikTokers, we \nfind, combine political performance, in the sense of presenting a persona \nPoli Ti cal Ti KT o K 191\nwith a political stance online, with dancing, acting, and singing. When \ncreating this content, they also experiment with video editing techniques \nsuch as zooming, soundtracks, filters, special effects, and greenscreens. \nWe differentiate three types of TikTok videos that use playful political \nperformance: \u201cstaging opinions,\u201d \u201cgiving a speech,\u201d and \u201cdocumenting.\u201d\nIn Figure\u00a09.1, a woman dances and sings along to the song \u201cGreat Again\u201d \nby American musician James McCoy Taylor. The sound playing in the \nvideo features the verses, \u201cI voted for a man named Donald J. Trump / \n\u2018Cause when they\u2019re playin\u2019 the anthem I stand up / I know that half of \nAmerica will too / And we ain\u2019t scared of no Kim Jong-un.\u201d The video was \nposted as a response to a comment left on the woman\u2019s account, which \nis displayed also on the screen. It reads: \u201cI followed you and now you lost \nme. No more Trump.\u201d In another video, a man sings along to the \u201cTrump Theme Song.\u201d The song includes verses such as: \u201cRacism / Bigotry / Lying \n/ Polygamy / Immature asshole on God / Pride / Mediocrity / And how he \nhandled Iran\u2026\u201d These two videos are examples of what we call \u201cstaging an opinion.\u201d\nScholarship on music and politics has observed that soundtracks create \nemotional intensity around political personas. According to musicologist \nJames Deadville, specific sounds become associated with the different \npolitical camps and help \u201cto create a collective identity and to construct \nconsensus\u201d (Deadville, 2015, p.\u00a01). Songs are \u201cwritten or modified for a specific \ncandidate\u201d and concerts become political spaces (Deadville, 2015, p.\u00a01), \nlike when the \u201cDixie Chicks lead singer Natalie Maines infamously dissed \nBush at a 2003 concert in London\u201d (Henwood, 2017). Likewise, at public \nappearances, conventions, and rallies, the public expects certain playlists. \nOrganizers, Deadville (2015) explains, draw on new classics of patriotic \nand inspirational character such as Bruce Springsteen\u2019s song \u201cBorn in the \nU.S.A.\u201d for the Democrats. That \u201chardly any of the invited famous pop artists \nwanted to perform at [Donald Trump\u2019s] inauguration in January\u00a02017\u201d was reported extensively (Mehring, 2020, p.\u00a022). Moreover, outside convention \nfi gure\u00a09.1 \u201c i  voted for a man named do nald J. Trump\u201d [video frames]. a  TikTok user sings and \ndances to the pro-Trump song (and now, TikTok sound) \u201c gr\neat \nag\nain\u201d by \nam\nerican musician James \nMcco\ny Taylor.\n192  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nhalls, \u201cprotesters staged their own media-driven spectacles replete with \nmusic (and speech)\u201d (Deadville, 2015, p.\u00a08).\nThe activity on TikTok offers a recent example of the role music plays \nduring elections. When people \u201cstage their opinions,\u201d not unlike during \npolitical rallies and conventions, the lyrics and mood of a song become \nproxies for their feelings about a candidate (Mehring, 2020; Deadville, 2015). \nMusic also becomes a tool for contestation on TikTok. Trump supporters, \nfor example, used clips from the song \u201cRed Kingdom\u201d as a soundtrack for \ntheir TikTok videos. Red Kingdom, however, was intended as an anthem \nfor the Kansas City Chiefs, an American football team. Conservative \nTikTokers , according to a writer for the Kansas-based magazine The Pitch , \n\u201chave trolled themselves into thinking that a song by a Black activist for \na football team with a Black superstar quarterback was created for their \nhateful agenda\u201d (Searles, 2020, para. 3). To address the misappropriation, \nliberal TikTokers \u201cmade videos to flood the sound \u2018tag\u2019 with positive, \ninclusive content to \u2018drown out\u2019 the hateful posts\u201d (Searles, 2020). Luke \nBryan\u2019s song \u201cCountry Girl (Shake It for Me),\u201d similarly, was used by TikTok -\ners as a nod to the \u201cliberal cowboy,\u201d after it became public that the singer \nwas not a Trump supporter (Lenzen, 2020). Also, YG and Nipsey Hussle\u2019s protest track \u201cFDT\u201d (F\u2014 Donald Trump) \u201cmade similar waves but never \ngarnered as much TikTok fame as its conservative counterparts\u201d (Konrad, \n2021, para. 8).\nThe videos we discuss above were returned on top by TikTok\u2019s search \nengine when searching for the presidential candidates. They are successful \nexamples of broader trends and thus linked to other videos on the app, \nboth conceptually and technically by sounds and hashtags. Clicking on the \nhashtag \u201cRed Kingdom\u201d or the \u201cTrump Theme Song\u201d sound redirects users \nto other videos featuring these same auditory elements and engaging with \nthe same video concept, for example, by replicating or parodying it. TikTok \nis, in this sense, an \u201cevolving tapestr[y] of self-referential texts collectively created, circulated, and transformed by participants online\u201d (Phillips and Miller, 2017, p.\u00a030). On Facebook or Reddit, memes look like image macros \nannotated with text. There is scholarship that explores the role of these \nimage-based memes in contemporary politics, uncovering fringe visual \nand textual cultures. TikTok meme behavior is, however, performative, in \nthat \u201cusers replicate the same type of video or similar video concepts using \na sound or effect over and over again\u201d (Zulli and Zulli, 2020, p.\u00a010). TikTok \ninvites those interested in ludic civic engagement online to consider the \nrole of music in a new light.\nPoli Ti cal Ti KT o K 193\n\u201cStaging an opinion\u201d on TikTok also resonates with practices of ludic \ncivic engagement that make use not only of music but that also rely on \ntheatrical and humorous interventions (Glas et al., 2019). Stunts, tactical \nclowning, critical play, the carnival, and flash mobs are examples of such \nludic engagements. Majken Jul S\u00f8rensen (2016), a scholar specializing in \nthe subject of humor in activism, argues that these genres \u201cshare a playful \nattitude towards expression of dissent and use various creative or artistic ways of communicating\u201d (2016, p.\u00a012). For example, in 2013, a Spanish radio \nshow organized a flash mob in an unemployment office, at a time when \nSpain endured an unemployment rate of 26%. A small orchestra arrived \nunnoticed in the waiting room and played \u201cHere Comes the Sun\u201d by The \nBeatles (Urquhart, 2013). The intervention, while on the ground, aimed \nto spread awareness to Spain\u2019s growing economic crisis by going viral. \nOn another occasion, students staged a flash mob by dancing to Michael \nJackson\u2019s song \u201cThriller\u201d in \u201cfull Zombie regalia to protest the death of public \neducation in Chile\u201d (Colquhounon, 2013, para. 4).\nTikTok users also stage their opinions about the U.S. presidential elections \nusing theatrical gestures evocative of flash mobs and clowning. In Figure\u00a09.2, \nfor instance, a man uses Kamala Harris and Joe Biden\u2019s heads as drums. \nThe text on the video reads: \u201cwhich of the two has the most hollow head?\u201d In Figure\u00a09.3, another man bops to the viral sound, Bass Da Da Da , which \nis a fragment from a song by the same name. The text on the screen reads: \n\u201cDoes anyone else hear \u2018thank God for Donald Trump?\u2019\u201d The critiques posed \nby the Spanish and Chilean flash mobs are clear\u2014there is a discontent with \ncurrent employment and education situations. Spectators may read into the \nsymbology of a band of zombie dancing towards a public institution. In the \nTikTok videos we study there is, instead, ambiguity, a topic that we returned \nto in the next section. As a case in point, in Figure\u00a09.2, the discontent with \nBiden and Harris is clear, however much one may not infer a stance or goal \nfrom the video.\nBesides \u201cstaging an opinion,\u201d the two other types of videos that involve \nplayful political performance are \u201cgiving a speech\u201d and \u201cdocumenting.\u201d \nFigure\u00a09.4 is an example of \u201cgiving a speech\u201d; in the video, a man turns \nthe camera towards himself and warns viewers about the liberal party, \nwithout using dramatic embellishments such as music or the video editing \ncapabilities of TikTok. \u201cThe hard left,\u201d he says, \u201cthrows not facts just slurs\u201d and \n\u201cdoesn\u2019t care about facts or truth.\u201d Figure\u00a09.5 is an example of \u201cdocumenting.\u201d \nA man records himself from the inside of his car. The driver of the car \nbeside him has stepped outside and is hitting his window with a metal bar. \n194  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nOverlayed on the screen is the following text: \u201cThis is what happens when \nTrump supporters get mad. Someone identify him?\u201d\n\u201cGiving a speech\u201d and \u201cdocumenting\u201d are familiar online forms of political \nperformance. We find examples of \u201cdocumenting\u201d on Twitter from instances \nof citizen journalism to call outs and requests to find the perpetrator of a transgression. On YouTube, Facebook Live, and Instagram Stories people \nfi gure\u00a09.2 \u201c ho llow heads\u201d  [video frames]. in t his TikTok video a man uses editing effects to play \ndrums with the heads of the then presidential candidate, Joe \nbi\nden, and running mate, Kamala \nha\nrris. The text displayed on the video reads: \u201cwhich of the two has the most hollow head?\u201d\nfi gure\u00a09.3 Thank go d for do nald Trump?  [video frames]. in t his TikTok video, a man bops to the \nsound of Bass Da Da Da , a fragment from the song by the same name. The text on the screen \nreads: \u201c do\nes anyone else hear \u2018thank \ngo\nd for \ndo\nnald Trump?\u2019\u201d\nfi gure\u00a09.4 \u201c The left lies\u201d [video frames]. a  TikTok user turns the camera towards himself. he w arns \nviewers about the liberal party. The hard left, he says, \u201cthrows not facts just slurs\u201d and will avoid \nany facet of truth. \nac\ncording to him, the left \u201cdoesn\u2019t care about facts or truth.\u201d\nfi gure\u00a09.5 \u201c is t his what happens\u2026?\u201d [video frames]. a  man records an alleged Trump supporter \nhitting his car window with a bar. The text \u201cThis is what happens when Trump supporters get mad. Someone identify him?\u201d appears on the video.\nPoli Ti cal Ti KT o K 195\ntalk politics and give speeches, albeit in longer form than on TikTok. \u201cStag -\ning an opinion\u201d through TikTok speech-giving could be said to specific to \nTikTok.\nRemix as ambivalent critique: Dramatization of media clips and \npartisan stitching and duetting\nRemixing is a creative media practice. It involves reediting \u201ctelevision, \nmovies, and news media for critical and political purposes\u201d (McIntosh, 2012, \npara. 1). \u201cDonald Duck Meets Glenn Beck in Right Wing Radio Duck,\u201d a remix \nvideo by artist Jonathan McIntosh, exemplifies the practice. Glenn Beck \nis an American conservative commentator, conspiracy theorist, and radio \nhost. McIntosh edited audio from Beck\u2019s radio show with Disney cartoons, \nsuggesting a narrative in which Donald Duck became radicalized. The aim of \nthe piece was \u201cto demonstrate how right-wing media paradoxically appears \nsympathetic while fear-mongering\u201d (burrough and Dufour, 2018, p.\u00a098).\nAnother example of remix is the parody video \u201cCandidate Obama Debates \nPresident Obama on Government Surveillance.\u201d The creator juxtaposes \nclips from different interviews during Obama\u2019s career, \u201cpointing out the \ninconsistencies in Obama\u2019s position on national security\u201d (Nunes, 2018, \np.\u00a0219\u2013220). The video essay is yet another form of audio-visual criticism. \nRemixed footage has, indeed, been part of \u201cexperimental cinema and film criticism for a number of decades\u201d (McWhirter, 2016, p.\u00a0372). Recently, also \nYouTube has seen an outburst of video essayists. These are all examples \nof what media scholar Henry Jenkins calls participatory politics, namely, \ninstances of citizens having \u201cthe means of creating political commentary \nthrough the reuse and reappropriation of the media content that makes up \nthe majority of our contemporary political discourse\u201d (Nunes, 2018, p.\u00a0219).\nRemixing is an important practice within TikTok. Users of the app tend \nto \u201ccomment on and rework existing cultural imaginaries and narratives \nby refashioning old media forms \u2026. [T]his is immediately visible in TikTok \nusers combining audio fragments from movies and TV news with mimicry to \npoke fun of current events\u201d (Vijay and Gekker, 2021, p.\u00a0717). In line with these \ntrends, in the context of the U.S. presidential elections, we found TikTokers \npracticing remix as ambivalent critique. That is to say, TikTokers are using \nthe app to juxtapose, combine, and enhance audio-visual materials related \nto the elections. Amongst the most popular content are the videos we label \nas \u201cdramatization of media clips\u201d and \u201cpartisan duetting and stitching.\u201d We \nsee them as medium-specific forms of remix and examples of participatory \npolitics.\n196  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nWe labeled videos as \u201cdramatization of media clips\u201d when TikTok users \njuxtapose and re-edit news clips (e.g., fragments from a televised press \nconference) with other clips, text, sounds, and voiceover commentary. \nBringing together news content with these new elements reframes and alters \ntheir meaning, often overstating, mocking, and exaggerating actions, or in \nother words, dramatizing them. Figure\u00a09.6 is an example of this practice. The \nvideo includes footage from a press conference held in the White House, in \nOctober\u00a02018. Donald Trump points to Cecilia Vega, a journalist from ABC \nNews, signaling that she can ask him a question. The sentence \u201cwait for it\u201d appears on the video. Then, Trump says \u201cshe\u2019s shocked that I picked her\u2026 \nshe\u2019s like in a state of shock\u2026 That\u2019s OK. I know you\u2019re not thinking. You \nnever do.\u201d The video transitions into a Trump lookalike dancing in front of \na background with the words Trump 2020\u2014a visual punchline.\nIn another example of the \u201cdramatization of media clips,\u201d a TikTok user \nrecords a segment from the late-night television show Jimmy Kimmel Live!  \nand adds a laugh track (Figure\u00a09.7). The show created a video including \nboth real images of Trump\u2019s visit to Pope Francis and edited images of him \nallegedly taking Pope Francis\u2019s hand and then of Francis slapping it away. \nThe sketch mocked Trump and the former first lady\u2019s cold relationship and a \nsimilar hand-slapping incident. The CNN logo is displayed on the video. This \nuser seems to be in on the joke\u2014the video is a parody. The Jimmy Kimmel \nLive!  video, however, had to be debunked by fact-checker website Snopes \n(Evan, 2017), indicating that once outside the context of the television, not everyone was aware of its nature.\nSimilarly, a TikTok user records his television, where we see Joe Biden \ntaking part in a Wired magazine \u201cAutocomplete\u201d interview in May\u00a02020. \nDuring the segment, guests answer the most \u201cGoogled\u201d questions about \nthemselves (Figure\u00a09.8). One of the questions for Biden is: Does Joe Biden \nhave a brother? Biden responds by saying, \u201cI got a sister who is the love of \nmy life.\u201d The focus of the video shifts to a teenager, sitting in front of the \ntelevision, playing \u201cSweet Home Alabama\u201d on his guitar and tipping his \nhat. In this context, the song plays on the stereotype that incest abounds \nfi gure\u00a09.6 . \u201cWait for it\u201d [video frames]. The video is an example of \u201cremix as ambivalent critique\u201d \nand, specifically, of the \u201cdramatization of media clips.\u201d \na\n TikTok user edits together footage from \nthe press conference when Trump insults \nce\ncilia Vega, a journalist from \nabc\n \nne\nws, with images of \na Trump look-a-like dancing before the slogan Trump 2020.\nPoli Ti cal Ti KT o K 197\nin the American South, hinting that Biden\u2019s relationship with his sister is \ninappropriate. This particular moment in the interview generated numerous \nmemes.\nYet another memetic dynamic built into TikTok is the \u201cduet\u201d function. \n\u201cDuet\u201d means creating a split screen to display one\u2019s video side-by-side a \nvideo created by someone else. People \u201cduet\u201d to create a scene by bringing \ntogether two separate videos, dance parallel to someone else, or comment \non content created by other TikTok users. If a person uses the \u201cstitching\u201d \nfunction, instead of having a split-screen, the videos are integrated into \neach other. It is often about re-using snippets of other people\u2019s video clips \nto create responses and remixes on the same theme. We find that these \nfunctions are used to engage with the elections and offer a TikTok-specific \nform of competition or contestation between political parties. We call this \ntype of video \u201cpartisan duetting and stitching.\u201d\nAn example of duetting can be seen in Figure\u00a09.9. The original video \nfeatures a young Trump supporter, marching to the song \u201cKings & Queens\u201d \nby Ava Max and lifting her hand towards the edge of the screen. The text on \nher screen reads, \u201clet\u2019s start a chain of women for Trump.\u201d The invitation is for other women to post similar videos and to duet or stitch them together. \nfi gure\u00a09.7 \u201c do nald Trump and The Pope\u201d [video frames]. a  TikTok user records and overlaps \nwith a laugh track a comedic sketch from the television show Jimmy Kimmel Live!  where Trump \nappears to reach for Pope \nfr\nancis\u2019s hand and the latter slapping it away.\nfi gure\u00a09.8  \u201cbi den and his sister\u201d [video frames]. a  TikTok user records his television as Joe bi den\u2019s \nWired  magazine \u201c au\ntocomplete\u201d interview plays. When asked if he has a brother, Joe \nbi\nden \nresponds by saying, \u201c i\n got a sister who is the love of my life.\u201d The focus of the video shifts to a \nteenager playing \u201cSweet \nho\nme \nal\nabama\u201d on his guitar and tipping his hat, joking that \nbi\nden\u2019s \nrelationship with his sister might be inappropriate.\n198  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nIf they imitate the way the creator of the original video raises her hand, \nonce the videos come together it would be like they were all holding hands. \nIn Figure\u00a09.9, however, it is a young man who responds and parodies the \noriginal video. He marches to the same song but when the time comes to join \nhands, he lifts an iron, even including a hissing sound. In yet another video, a \nTrump supporter uses a spray bottle to demonstrate how liquid goes through \na mask. The video is \u201cstitched\u201d by a Biden supporter who conducts their own \nexperiment, demonstrating that masks, indeed, work. In yet another example, \nin Figure\u00a09.10, a young woman combs her eyebrows while the following text \nappears on the screen: \u201cwhen I can attract both genders.\u201d The video is stitched \nby a man wearing a Trump hat. He says, \u201cahh, so there are only two genders. \nThank you for proving my point sweetheart. He winks and tips his cap.\u201d\nTikTok, one could argue, has popularized a new form of political remix \nvideo. Yet, this is not to say that the TikTok videos we study are the same as \nthe work of artists as McIntosh, who are explicit about their political intent. \nTikTok videos are, instead, often ambivalent. We use the term ambivalent \nin similar fashion as Phillips and Milner (2017) and Tuters and Hagen (2020) \ndo (see also Niederer and Colombo, this volume). These authors remark how \nonline political communication (e.g., in forums as Reddit) is characterized \nfi gure\u00a09.9 \u201c le t\u2019s start a chain of women for Trump\u201d [video frames]. a  TikTok user invites women to \nrecord themselves marching to the song \u201cKings & \nqu\neens\u201d by \nav\na Max and stitch them together \nto show support for \ndo\nnald Trump. \nin t\nhe video, a man parodies the original video and mocks the \ncontent creator.\nfi gure\u00a09.10 \u201cWhen i  can attract both genders\u201d [video frames]. a  TikTok user combs her eyebrows, \nwhile the sentence \u201cwhen \ni\n can attract both genders\u201d hovers on the screen. The video was stitched \nby a man wearing a Trump hat. \nhe s\nays \u201cahh, so there are only two genders. Thank you for proving \nmy point sweetheart.\u201d \nhe w\ninks and tips his cap.\nPoli Ti cal Ti KT o K 199\nby humor, absurdity, and a sense of detachment. It can be \u201cantagonistic \nand social, creative and disruptive, humorous and barbed, the satirizing of \nproducts, antagonization of celebrities, and creation of questionable fan art\u201d \n(Phillips and Milner, 2017, p.\u00a010). Ambivalent can be understood in opposition \nto earnest or aligned with a clear agenda. TikTok, indeed, often leaves the \nviewer with the sensation that the absurdity of the current political reality \nis the object of critique. On TikTok, the lines between earnest and mocking \nentertainment and political engagement are constantly blurred\u2014\u201csharing a \n\u2018funny\u2019 video that has a certain political stance does not mean committing \nor aligning to that politics\u201d (Vijay and Gekker, 2021, p.\u00a0178).\nTikTok\u2019s misinformation problem\nWe have presented three arguments so far. We first posit that TikTok \nremained \u201cfresh\u201d during the elections as evidence of its function as event-\ncommentary medium. Then, we identified two media practices present in \npopular election-related videos: \u201cplayful political performance\u201d and \u201cremix \nas ambivalent critique.\u201d We also differentiate between types of videos that \ninclude these practices, such as \u201cstaging an opinion\u201d and \u201cdramatizing media \nclips.\u201d Furthermore, we discussed these videos and practices vis-\u00e0-vis playful \nactivism, parody, and political remix videos. TikTok videos relate to these \ngenres while also being medium-specific modes of ludic civic engagement. \nIn this section, we revisit \u201cplayful political performance\u201d and \u201cremix as \nambivalent critique\u201d in relation to the issue of information disorders.\nAccording to Claire Wardle (2017), co-founder of First Draft News, in -\nformation disorders are types of content that raise concern in the context \nof issue-making and democratic process. Existing studies have already \nidentified disorderly information on TikTok in the form of hyperpartisan, \nmisleading content, manipulated content, and false context content about \nthe U.S. presidential elections. For instance, Media Matters, a non-profit \norganization that scrutinizes right-leaning media, identified eleven examples \nof election conspiracies and misleading claims spreading on TikTok. These \ninclude videos with narratives about alleged voter fraud and a deceptively \nedited clip of Joe Biden, which accumulated hundreds of thousands of views \n(Little, 2020). To combat the problem, TikTok set up content guidelines for \nthe elections and moderated \u201cterms associated with hate speech, incitement \nto violence, or disinformation around voter fraud, such as ballot harvesting\u201d \n(TikTok, 2021). Posting about conspiracies like QAnon and anti-vaccination \nnarratives is now banned (TikTok, 2021). Media Matters reported that \nafter their investigation, TikTok removed the flagged videos, reduced the \n200  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \ndiscoverability of other problematic posts, and added banners linking \nsuspicious content to authoritative sources about the election.\nAmong the most popular videos\u2014from a subset of content returned in \nJanuary\u00a02021\u2014there are no fake and conspiratorial videos, for example, \nassociated with QAnon and other known, flagged topics. It is not entirely \nsurprising given the app\u2019s information cleaning efforts. What we did find are \nvideos in which misinformation is a topic. For example, in Figure\u00a09.4 a man \nclaims that the Democratic Party has no regard for the truth, a familiar argu-\nment amongst Trump supporters. This video is example of \u201cplayful political \nperformance\u201d and, specifically, \u201cgiving a speech.\u201d In another video, a TikToker \nduets an anti-mask video. They conduct an experiment that shows that masks \nactually block sprayed liquid. The parody clip created by Jimmy Kimmel Live!  \nfeatured Pope Francis brushing of Trump\u2019s hand is fake and plays on rumors \nabout Donald and Melania Trump\u2019s cold marriage. (As mentioned, the parody, \nnevertheless, had to be debunked by Snopes, the fact-checking organization.)\nTikTok videos beyond the examples above invite yet another line of \nquestioning. Playful performance, remix, and humor are dominant modes \nof expression on TikTok, and their meaning-making capacities depend \non altering, juxtaposing, exaggerating, and dramatizing. The goal is not \nto correct remix and playfulness, or humor. These practices are not new \nand exist in forms of activism, political cartoon, and comedy shows. As \nwe explored earlier in this chapter, they have important critical, civic, and \npolitical capacities to them by making \u201cpolitical issues into a piece of theater \nwhen their attacks on dominant discourses disrupt, subvert, oppose and \ntransform business as usual\u201d (S\u00f8rensen, 2016, p.\u00a013). Yet a challenge TikTok \nposes, we argue, is considering playful performance, remix, and humor \nnot as fringe critical practices but as mainstream modes for engaging with \nelections. Or, in other words, considering, for example, that one may learn \nabout an event first through its parody or remix.\nFor example, Ride It by Regard is a viral sound for TikTokers to create fin -\nger dancing videos with word bubbles denoting cultural misunderstandings. \nThese in-video texts usually display inaccurate representations of a culture, \na nation or a minority group. In the Netherlands, for example, local creators \nuse the sound to make videos indicating that not all Dutch people live in \nAmsterdam or the sunshine over the canals is a typical misrepresentation of Dutch life as wind and rain are a more common occurrence. For young \nvoters in the U.S., the same sound is widely deployed to make dancing videos \nengaging with the \u201caccusations\u201d of being Trump supporters, which include \n\u201cget called racist 24/7,\u201d \u201cget yelled at for presenting facts,\u201d and \u201caccused of not \nrespecting women.\u201d Aligning with the study that finds sounds on TikTok \nPoli Ti cal Ti KT o K 201\nfunctioning as a story builder to convey a specific message (Medina et al., \n2020), Trump supporters employ the sound to suggest that these accusations \nare untrustworthy and even entertaining.\nIn another video, a young man wearing a \u201cMAGA\u201d hat performs a finger \ndance with the caption \u201cnot sorry if you\u2019re offended by facts,\u201d referring to \n\u201cabortion is murder,\u201d \u201cguns don\u2019t kill people, people do,\u201d and \u201ctaking away \nguns is unconstitutional.\u201d These are slickly produced videos, using creative \ntools at once to entertain and to put forward misunderstanding as the root \nof disagreement with Trump politics.\nIn the study of misinformation, parody or satire is said to sometimes fool \nthe viewer, albeit unintentionally. Here we find that the sarcastic videos that \nparody candidates seem to be motivated by an intention to instill mistrust. \nMoreover, their lightheartedness could fool the viewers into thinking that it \nwas just for fun. To consider here is how the \u201cnon-serious nature of TikTok \nfurther obscures its actions as a playfield for (political) persuasion\u201d (Vijay \nand Gekker 2021, p.\u00a0714). TikTok has also raised concern \u201cabout its distorting \nimpacts on political discourse and participation\u201d (Vijay and Gekker, 2021, \np.\u00a0714). Also challenging is the mainstreaming of ambivalence: what is \nlabeled as \u201csatire\u201d is often hateful, polarizing and divisive content but it \nmust not be taken seriously because it is a \u201cjoke.\u201d\nFindings\nFinding 1: TikTok is an event-commentary medium, active and topical \nduring the election cycle. The hashtags linked to videos concerning the \nthen-presidential candidates, Joe Biden (#biden2020), Donald Trump \n(#trump2020, #maga2020), and Bernie Sanders (#bernie2020), were ac -\ntive between March\u00a02020 and February\u00a02021. Comparing the 1,000 most \nengaged with videos on TikTok for each hashtag query in March\u00a02020 and \nJanuary\u00a02021 revealed the most popular videos changed, an indication of \nactivity. Popularity on TikTok is measured in terms of cumulative interac -\ntions, including the number of views, likes, comments, and shares that a \nvideo receives. The videos popular in 2020 and in 2021 have content that \nis highly topical. That is, it is connected to current events such as Trump\u2019s visit to India in 2020, the tensions with Iran, and Bernie Sanders dropping out of the race. They treat current events by way of remixing, dramatizing \nand in general manipulating or creating original media content based on \nthose events. These digital activities are a key form of participating in the political discourse surrounding current events.\n202  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nFinding 2: There are typical TikTok political engagement practices. The \nresults of the coding of 120 TikTok videos collected in 2021 (30 per hashtag) \nresulted in 5 different types of videos, which were further subsumed under \ntwo media practices (see Table\u00a09.1).\nTable\u00a09.1  M edia practices and types of election-related TikTok videos.\nMedia practice Video Concept Description\nPlayful political \nperformanceStaging an opinion TikTok users engage in performative activities such as lip syncing, dancing or roleplaying to express their political ideas.\ndo\ncumenting/sharing a\n pre-existing piece of media is reposted \non TikTok with no meaning-altering embellishment.\ngi\nving a speech TikTok users use only the video capacity of TikTok to record and share a short speech, with no editing or embellishment.\nre\nmixing as \nambivalent critiqueTheatricalization of media TikTok users add embellishments such as sounds, music, laugh tracks, dub dialogue or other editing techniques to existing media clips in a way that frames or alters the meaning of the original clip(s).\nPartisan stitching and duettingTikTok users use the \u201cstitching\u201d tool, which places their own video next to another user\u2019s video, to create contrast with the latter. \nof\nten, the new video contests \nor mock\u2019s the content of the video it is stitched to.\nStrategy Count Percentage \nTheatricalization of media clips 48 40%\ndo\ncumenting/ sharing 24 20%\nac\nting an opinion 19 15.8%\nStitching and duetting as contrast 5 4.2%\ngi\nving a speech 2 1.7%\noth\ner 22 18.3%\nMethodology\nThe data was gathered using the TikTok-scraper (Drawrowfly, 2021), a \nsoftware tool that uses TikTok\u2019s Web API to scrape media and related \nmeta-information. We collected the 1,000 most popular videos associated \nPoli Ti cal Ti KT o K 203\nwith the hashtags #Trump2020, #maga2020, #biden, and #bernie2020 on \nMarch\u00a023, 2020 and January\u00a04, 2021. The scraper collected the video ID, \nusername, date of creation, video URL, caption, hashtags, and engagement \nmetrics such as view count for each of the videos. The dataset consists of \n8,000 videos. We extracted the top 30 videos per hashtags, creating a subset \nof 120 videos. We answered the first research question by comparing the \n1,000 videos collected for each of the hashtags on the two dates. Our goal \nwas to determine if the most popular videos changed. The techniques used \nby TikTok users and the various types of political videos were identified \nthrough a qualitative exploration of the top 30 videos per hashtags. Each \nvideo from this sample was coded according to the performative and remix \ntechniques used by its creator. This began with an open coding process \nto develop a consistent coding schedule which was then repeated several \ntimes. The four authors acted as coders and controlled for the consistency \nof the coding by employing an inter-researcher reliability test.\nReferences\nAroesti, R. (2019, November\u00a01). Why are teenagers on TikTok obsessed with an eerie \n1950s song? The Guardian . https://www.theguardian.com/culture/2019/nov/01/\nwhy-are-teenagers-on-tiktok-obsessed-with-an-eerie-1950s-song.\nBruns, A. and Weller, K. (2016). Twitter as a first draft of the present: And the \nchallenges of preserving it for the future. In Proceedings of the 8th ACM \nConference on Web Science (WebSci\u201916)  (pp.\u00a0183\u2013189). ACM. https://doi.\norg/10.1145/2908131.2908174.\nburrough, x. and Dufour, F. (2018). Creativity. In E. Navas, O. Gallagher, and x. \nburrough (Eds.) Keywords in remix studies (pp.\u00a092\u2013104). Routledge.\nCaramanica, J. (2020, March\u00a020). This \u201cImagine\u201d cover is no heaven. New York \nTimes . https://www.nytimes.com/2020/03/20/arts/music/coronavirus-gal-gadot-\nimagine.html.\nColquhoun, R. (2013, January\u00a013). Political art and activism: Flash mob. National \nCollective. http://www.nationalcollective.com/2013/01/13/political-art-and-\nactivism-flash-mob/.\nCrowley, M. (2020, February\u00a024) \u201cAmerica loves India,\u201d Trump declares at rally \nwith Modi. New York Times . https://www.nytimes.com/2020/02/24/world/asia/\ntrump-india.html.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Public Culture , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\n204  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nDeadville, J. (2015). The sound of media spectacle: Music at the party conventions. \nMusic & Politics, 9 (2), pp.\u00a01\u201324. https://doi.org/10.3998/mp.9460447.0009.205.\nDrawrowfly. (2021). TikTok scraper [software]. https://github.com/drawrowfly/\ntiktok-scraper.\nEvan, D. (2017, May\u00a026). Did Pope Francis slap away President Trump\u2019s hand? \nSnopes . https://www.snopes.com/fact-check/pope-francis-trump-hand-slap/.\nGeboers, M. (2019). \u201cWriting\u201d oneself into tragedy: Visual user practices and \nspectatorship of the Alan Kurdi images on Instagram. Visual Communication . \nhttps://doi.org/10.1177/1470357219857118.\nGekker, A. (2019). Playing with power: Casual politicking as a new frame for political \nanalysis. In R. Glas, S. Lammes, M. de Lange, J. Raessens, and I. de Vries (Eds.) \nThe playful citizen: Civic engagement in a mediatized culture (pp.\u00a0387\u2013419). \nAmsterdam University Press.\nHautea, S., Parks, P., Takahashi, B., and Zeng, J. (2021). Showing they care (or don\u2019t): \nAffective publics and ambivalent climate activism on TikTok. Social Media+ \nSociety . https://doi.org/10.1177/20563051211012344.\n \n K\nonrad, C. (2021, January\u00a028). Trump presidency permanently alters landscape of \nmedia. The Maneater . https://themaneater.com/trump-presidency-permanently-\nalters-landscape-of-media/.\nLenzen, C. (2020, November\u00a09). This Luke Bryan song is an anti-Trump anthem on Tik -\nTok. The Daily Dot . https://www.dailydot.com/irl/luke-bryan-anti-trump-tiktok/.\nLewis, R. (2020) \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nLorenz, T. (2020, November\u00a04). Election night on TikTok: Anxiety, analysis and \nwishful thinking. New York Times . https://www.nytimes.com/2020/11/04/style/\ntiktok-election-night.html.\nMcIntosh, J. (2012). A history of subversive remix video before YouTube: Thirty \npolitical video mashups made between World War II and 2005. Transformative \nWorks and Cultures, 9 . https://doi.org/10.3983/twc.2012.0371.\nMcWhirter, A. (2015). Film criticism, film scholarship and the video essay. Screen, \n56(3), pp.\u00a0369\u2013377. https://doi.org/10.1093/screen/hjv044.\nMedina Serrano, J.C., Papakyriakopoulos., O. and Hegelich S. (2020). Dancing to \nthe partisan beat: A first analysis of political communication on TikTok. In \nProceedings of the 12th ACM Conference on Web Science, pp.\u00a0257\u2013266. https://\ndoi.org/10.1145/3394231.3397916.\nNagle, A. (2017). Kill all normies: Online culture wars from 4chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNunes, M. (2018). Parody. In E. Navas, O. Gallagher, and x. burrough (Eds.) Keywords \nin remix studies (pp.\u00a0217\u2013229). Routledge.\nPoli Ti cal Ti KT o K 205\nPardes, A. (2020, October\u00a022). The TikTok teens trying to meme the vote. Wired . \nhttps://www.wired.com/story/tiktok-election-2020/.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nRathnayake, C., and Suthers, D.D. (2018). Twitter issue response hashtags as af -\nfordances for momentary connectedness. Social Media+ Society . ht tps://doi.\norg/10.1177/2056305118784780.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn K. Weller, A. Bruns, J. Burgess, M. Mahrt and C. Puschmann (Eds.), Twitter \nand society (pp. ix\u2013xxvi) . Peter Lang.\nRosenblatt, K. (2020, October\u00a017). They can\u2019t vote, but they can meme: How these TikTokers \nare trying to get Biden elected. NBC News . https://www.nbcnews.com/pop-culture/\nviral/they-can-t-vote-they-can-meme-how-these-TikTokers-n1243555.\nSalen, K. and Zimmerman, E. (2004). Rules of play: Game design fundamentals . \nMIT Press.\nSearles, S. (2020, August\u00a04). Republican Tik Tok thinks \u201cRed Kingdom\u201d by Tech \nN9ne is their new hype song; We\u2019re laughing. The Pitch . https://www.thepitchkc.\ncom/republican-tik-tok-thinks-red-kingdom-by-tech-n9ne-is-their-new-hype-\nsong-were-laughing/.\nSchellewald, A. (2021). Communicative forms on TikTok: Perspectives from digital \nethnography. International Journal of Communication, 15 , pp.\u00a01437\u20131457.\nSmith Gale, S (2020, October\u00a06). U.S. election 2020: TikTok gets pulled into the \ncampaigns. BBC News . https://www.bbc.com/news/technology-54374710.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nUrquhart, C. (2013, January\u00a012). Here comes the sun flash mob cheers Spanish \nunemployment office. The Guardian . https://www.theguardian.com/world/2013/\njan/12/here-comes-the-sun-spanish-unemployment-office.\nVijay, D. and Gekker, A. (2021). Playing politics: How Sabarimala played out \non TikTok. American Behavioral Scientist , 65(5), pp.\u00a0712\u2013734. https://doi.\norg/10.1177/0002764221989769.\nWardle, C. (2017, February\u00a016). Fake news. It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nZulli, D. and Zulli, D. J. (2020). Extending the internet meme: Conceptualizing \ntechnological mimesis and imitation publics on the TikTok platform. New Media \n& Society . https://doi.org/10.1177/1461444820983603.\n206  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nAbout the authors\nNatalia S\u00e1nchez-Querub\u00edn , PhD, is Assistant Professor at the University \nof Amsterdam. She works on digital media research and the intersection \nof social media with health stories and social issues.\nShuaishuai Wang , PhD, is Assistant Professor in the Department of Media \nand Communication at Xi\u2019an Jiaotong \u2013 Liverpool University. His research \nlies at the intersection of platform studies, critical algorithm studies and \ndigital culture.\nBriar Dickey  is a graduate of the Social and Cultural Science research \nmaster at Radboud University. His research takes an interdisciplinary, \nmixed methods approach to the examination of the far right, ontologies of \ngender, post-truth and identities online.\nAndrea Benedetti is a PhD student in Design at the Politecnico di Milano, \nItaly. He works in the field of data visualization, studying the relationship \nbetween data, interfaces, and society from a designerly standpoint in order \nto find alternative ways to design technological artifacts.\n A fterword: The misinformation \nproblem and the deplatforming \ndebates\nThe book arrives at the height of the \u201cdeplatforming\u201d debates, which among \nother matters concern the editorial power of social media platforms, with \nquestions about their authority and how they apply it in \u201carbitrating\u201d sources, \nspeech or truth. More specifically, the platforms\u2019 content moderation, as it \nis termed, includes warning, labeling, demoting as well as removing posts \nand users when they break platform rules. When a user is removed, it is \ncalled \u201cdeplatforming,\u201d but it may also refer to broader sanctioning such \nas suppression of content about multi-user movements such as QAnon, a \nwide-ranging conspiracy theory concerning the actions of operators inside \ngovernment. Facebook, in particular, has sought to ban QAnon content, \nremoving it from the platform.\nThe deplatforming debates also revolve around the extent to which the \nplatforms are doing too much or too little moderation. They concern whether \n(and when) it is justified as well as effective (and for whom). While the \nvolume authors do not address these questions directly, in the following I \nwould like to take up what we have found when studying the \u201cmisinforma -\ntion problem\u201d and the contributions we can make to the debates, however \nindirectly.\nIn all, I touch on five points where the misinformation problem relates to \nthe deplatforming discussion: the classification of problematic content (and \nits politics), platform privileging of certain content and users, the work put \ninto establishing editorial authority, the difference in content moderation per platform as well as the methodological challenges (and opportunities) in studying content and user removal. Each is taken in turn, whereupon I conclude with a modest proposal to re-orient the discussion.\nEspecially in the Facebook chapter but also in others, we have taken \na common approach to classifying sources as problematic or less so. The \napproach is both historicized as well as comparative. By historicized, I mean \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_after\n208  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nthat there has been an evolution in the definition and terminology of what \nwas incipiently referred to as \u201cfake news\u201d in 2016 by Craig Silverman of \nBuzzFeed News , when writing up his findings concerning the types of sources \nthat were performing well on Facebook in the run-up to the U.S. presidential \nelections (2016). When comparing engagement scores, or tallies of likes, \nshares and comments, he found that those from fly-by-night, imposter \nas well as \u201chyperpartisan\u201d sources received more engagement than those \nhe called mainstream. Subsequent scholarly work expanded the types of \nsources under study to \u201cproblematic information\u201d as well as \u201cjunk news,\u201d \nadding (for example) satire as well as \u201ccomputational propaganda\u201d which \nincludes amplification efforts such as fake followers and bot work (Jack, \n2017; Bolsover & Howard, 2018). Facebook but also certain journalists, for \ntheir part, then narrowed the classification of problematic content to \u201cfalse \nnews,\u201d focusing on hoaxes and imposter sources and removing from the \ndefinition the \u201chyperpartisan,\u201d originally referring to \u201copenly ideological \nweb operations\u201d (Herrman, 2016). Nowadays the term misinformation \n(which would include non-intentional falsehoods) is enjoying currency \nas an umbrella term. The evolution of the definitional led us to consider \na comparative perspective where we found that an ample classification \n(including hyperpartisan) would enlarge the misinformation problem and a \nnarrower definition (excluding hyperpartisan) would reduce its size, making \nit more ordinary. There is an accompanying political dimension, given that \nthe hyperpartisan sources (receiving the highest engagement) are often \nmore conservative in bent, at least at the time of writing. When classifying \nthem as fake, junk or problematic, the adjectives become sectarian markers, \nand any content moderation along those definitional lines seems to take \nsides and invites backlash.\nAs related particularly in the Twitter studies, the second observation \nconcerns which content as well as users are privileged by platforms. For some \ntime during our work, a New York Times journalist would tweet the most \nengaged-with sources on Facebook, pointing out how they disproportionately \nfavor hyperpartisan, conservative sources (Owen, 2021). A subsequent debate \nbetween the journalist and a Facebook representative took up whether \nthose sources were enjoying as much exposure as the engagement metric \nmight suggest, ultimately pointing to Facebook data in company transpar -\nency reports showing how the results of another metric\u2014reach\u2014indicate \notherwise. In fact, that data seemed to show that Facebook has a problem \nwith \u201cspammy, clickbait\u201d content, apart from that of the popularity of its \n\u201cright-wing pages\u201d (Warzel, 2021). The discussion points up the question \nof which users and content do well, metrically, both overall as well as per \nafTe r Wor d: The MiSi nfor MaTion  Pr oble M a nd Th e de Pl aTf or Mi ng deba TeS 209\nsocial media platform. It was at least partially answered in the expos\u00e9 of \nFacebook\u2019s privileging mechanisms, made possible by the former Facebook \nemployee, Frances Haugen, who presented news organizations with internal \ndocuments showing, among other things, that Facebook boosts posts which \nhave received \u201cangry\u201d reactions over those who have been merely \u201cliked.\u201d \nThus, one is able to score higher or have greater impact with posts that \nmake other users reply with anger. No similar whistle-blowing revelations \nhave been made of other platforms, but on Twitter, we made a finding \nakin to the New York Times journalist\u2019s. Hyperpartisan sources receive a \ndisproportionate amount of retweets, compared to other source types. Apart \nfrom the spammy or clickbait-like, driving engagement on major social media \nplatforms are source types variously characterized as \u201cmisinformation, \ntoxicity and low-quality news\u201d (Merrill and Oremus, 2021). As platforms \ncrack down on such content as misinformation and toxicity, it follows \nthat they are moderating popular material, which attracts attention to \nsuch moderation rather than keeping it out of sight, as was the case with \ncommercial content moderation from the beginning.\nPrior to the fake news crisis of 2016 and beyond, the critique made of \nsocial media content moderation concerned the kind of \u201csoul-crushing\u201d \nlabor behind it (Chen, 2014). Low-wage and outsourced, content moderation \nworkers did not enjoy the status (and benefits) of company employees \n(Roberts, 2016). They also worked at a rapid pace, monitored for their capacity \nto decide accurately which disturbing content should be deleted or ignored. \nIn our study we focus on the type of content that rises to the top when \nusers engage with posts concerning national elections and the COVID-19 \npandemic. Such material may intersect with the areas of conventional \ncontent moderation (such as violence and pornography) but are also moder -\nated, rather exceptionally, for misinformation. The labor still could be \ncalled content moderation by the companies, but given the partnerships \nmade with fact-checking organizations to undertake some of it, it more \nreadily would be called editorial (Perez, 2021). We discuss those social media \nplatforms and search engines specifically targeting misinformation around \nnational elections and the pandemic (including, in our study, Facebook, \nInstagram, Twitter, TikTok as well as Google Web Search) as employing \n\u201ceditorial epistemologies,\u201d curating lists of authoritative sources returned \nfor election- and pandemic-related queries and otherwise adjudicating \ncontent either automatically detected or flagged by users as problematic. \nIt is arguably novel editorial work undertaken by the platforms and opens \nthe questions of which other subject matters apart from elections and the \npandemic should also deserve scrutiny and which expertise is required. For \n210  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nexample, is climate change or another pressing social issue so deserving? \nThe shift in moderation culture would put the platforms on a footing where \nauthority for content demotion or deplatforming is achieved by editorial \nexpertise and delivered as fact checks.\nAs has been pointed out, all platforms perform content moderation, and \nit could be considered at the heart of a platform\u2019s business model (Gillespie, \n2018). The extent of its presence as well as its absence are objects of study, \ngiven how certain platforms have emerged known as \u201calt tech\u201d that explicitly \ntrade on low moderation or \u201cfree speech.\u201d They do not profess to the practice \nof deplatforming. For the platforms under study here, 4chan could be said to \noffer the least content moderation and Facebook (and Instagram) perhaps \nthe most. Whether the platform has high or low content moderation is \nworthy of study, but also of interest is which actors platforms privilege. \nOne could argue that platforms privilege their own \u201cperformers\u201d rather \nthan, say, news organizations. These performers may post hyperpartisan \ncontent, thereby making it more prominent on the platform. Indeed, as we \nreported in one of the Twitter chapters, mainstream news is marginalized \nnot through a lack of content moderation per se but rather by virtue of the \nabundance of hyperpartisan sources present in the posts that perform well \non the medium.\nFinally, there are methodological challenges in studying deplatform -\ning, and its connection to the misinformation problem, for the content is \nno longer available for scrutiny. It is also demanding to study demotion, \nespecially if one relies on engagement metrics to surface pertinent content \nfor study. Having been demoted, it is no longer ranked highly. One avenue \nis taken in the 4chan chapter, which ultimately deals with the extent to \nwhich an \u201calternative influence network\u201d is influential there. The researchers \nextracted the links from a 4chan board and examined the extent to which \nthey point to YouTube alt-influencers, especially on the right of the political \nspectrum. The approach may be called \u201cplatform perspectivism,\u201d whereby \none uses the data available on one platform to study another. The approach \npreviously was used to create a list of extreme YouTube videos linked from \n4chan in order to check whether they are still available on the video sharing \nplatform. Some had been deleted whereas others remained online, raising the \nquestion of the threshold for removal as well as the technique for identifica -\ntion. With respect to demotion, at the time of our study, TikTok introduced \ncontent removal or suppression policies which it later expanded to videos \nconcerning the war in Ukraine. While not explicitly undertaken in the TikTok \nstudy, its approach offers a means to study demotion. Continually archiving \nof the results of a query (as ranked video URL lists) and graphing their ranked \nafTe r Wor d: The MiSi nfor MaTion  Pr oble M a nd Th e de Pl aTf or Mi ng deba TeS 211\nplacement overtime would show whether there are any precipitous dips of \nsingle videos compared to the others in the list.\nIn conclusion, research on misinformation recalls debates about the qual -\nity of information on the internet more generally and content moderation \ndiscussions about approaches to make \u201crelevant\u201d sources rise to the top of \nsearch engine rankings (and what relevance means). The debates continued \nwith the shift in emphasis to the effects of personalization as a \u201csolution\u201d to the relevance problem. Personalization brought with it the atomization or individualization of media exposure. Individual feeds on social media, \noptimized for one\u2019s interests but also for one\u2019s trigger points (so to speak), are \nin a sense a further extension of personalization together with a more evident \naffective component, with the canonical example now being how Facebook \noptimizes for \u201cangry\u201d content or \u201cangertainment.\u201d When we find that social \nmedia, which dominates as an informational medium, is marginalizing the \nmainstream and mainstreaming the fringe, we are returning to the question \nof how to address the quality of information online but also how to handle \nthe affective dimension. These are somewhat different points of departure \nfrom the question of whether or when to deplatform misinformation, but \nthey could be re-introduced to guide the discussions.\nRichard Rogers\nAmsterdam, November\u00a02022\nReferences\nBolsover, G. and Howard, P. (2019). Chinese computational propaganda: Automation, \nalgorithms and the manipulation of information about Chinese politics on \nTwitter and Weibo. Information, Communication & Society , 22(14). https://doi.\norg/10.1080/1369118X.2018.1476576.\nChen, A. (2014, October\u00a023). The laborers who keep dick pics and beheadings out of \nyour Facebook feed. Wired . https://www.wired.com/2014/10/content-moderation/.\nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nHerrman, John (2016, August\u00a028). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\n212  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nMerrill, J. B. and Oremus, W. (2021, October\u00a026). Five points for anger, one for \na \u201clike\u201d: How Facebook\u2019s formula fostered rage and misinformation. Wash -\nington Post . https://www.washingtonpost.com/technology/2021/10/26/\nfacebook-angry-emoji-algorithm/.\nOwen, L. H. (2021, July\u00a014). At first, Facebook was happy that I and other journalists \nwere finding its tool useful\u2026but the mood shifted. NiemanLab. https://www.\nniemanlab.org/2021/07/at-first-facebook-was-happy-that-i-and-other-journalists-\nwere-finding-its-tool-useful-but-the-mood-shifted/.\nPerez, S. (2021, August\u00a02). Twitter partners with AP and Reuters to address misinfor -\nmation on its platform. TechCrunch . https://techcrunch.com/2021/08/02/twitter-\npartners-with-ap-and-reuters-to-address-misinformation-on-its-platform/.\nRoberts, S. T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S. U. Noble and B. Tynes (Eds.) The intersectional internet: Race, sex, class and \nculture online  (pp.\u00a0147\u2013160), Peter Lang.\nSilverman, C. (2016, November\u00a016) This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nWarzel, C. (2021, November\u00a011). Facebook\u2019s vast wasteland. The Atlantic Monthly . \nhttps://newsletters.theatlantic.com/galaxy-brain/618ad9942e822d00205a26b3/\nfacebooks-vast-wasteland/.\n Bibliography\nAchenbach, J. and Johnson, C. Y. (2020, April\u00a030). Studies leave question of \u201cair -\nborne\u201d coronavirus transmission unanswered. Washington Post . https://www.\nwashingtonpost.com/health/2020/04/29/studies-leave-question-airborne-\ncoronavirus-transmission-unanswered/.\nAdams, A. (2016, August\u00a025). SHOCKING: Joe Biden discusses the left\u2019s globalist \nagenda. https://www.youtube.com/watch?v=KaCBYrVsic4.\nAdams, A. (2020, November\u00a020). KRAKEN UNLEASHED: The press conference \nthey don\u2019t want you to see\u2026 https://www.youtube.com/watch?v=_u34jhCKT2U.\nAFP. (2021). AFP Factcheck Nederland, Agence France-Presse. https://factcheckned -\nerland.afp.com/list.\nAhmadi, A.A. and Chan, E. (2020). Online influencers have become powerful \nvectors in promoting false information and conspiracy theories. First Draft. \nhttps://firstdraftnews.org/latest/influencers-vectors-misinformation/.\nAlba, D. (2020, June\u00a01). Misinformation about George Floyd protests surges on social \nmedia.  New York Times. https://www.nytimes.com/2020/06/01/technology/\ngeorge-floyd-misinformation-online.html.\nAllcott, H., Gentzkow, M. and Yu, C. (2019). Trends in the diffusion of misinforma -\ntion on social media. Research & Politics , April\u2013June\u00a02019: 1\u20138.\u2028 https://doi.\norg/10.1177/2053168019848554.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nAlter, J. [jonathanalter]. (2021, Jan 01). \u201cIf we \u2018move on\u2019, the GOP will refuse to \nconcede future elections, then judge-shop until they steal one. There must be a \nprice paid for sedition or we will lose our democracy. This is critically important \nwork in the next couple of years\u201d [tweet]. https://twitter.com/jonathanalter/\nstatus/1345074521561292800.\nAmerican Military News (2016, May\u00a023). Article removed\u2014Here\u2019s why. American \nMilitary News , https://americanmilitarynews.com/2016/05/donald-trump-sent-\nhis-own-plane-to-transport-200-stranded-marines/.\nAnnany, M. (2018, April\u00a04). The partnership press: Lessons for platform-publisher \ncollaborations as Facebook and news outlets team to fight misinformation. Co -\nlumbia Journalism Review . https://www.cjr.org/tow_center_reports/partnership-\npress-facebook-news-outlets-team-fight-misinformation.php.\nAroesti, R. (2019, November\u00a01). Why are teenagers on TikTok obsessed with an eerie \n1950s song? The Guardian . https://www.theguardian.com/culture/2019/nov/01/\nwhy-are-teenagers-on-tiktok-obsessed-with-an-eerie-1950s-song.\n214  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nBail, C.A., Argyle, L.P., Brown, T.W., Bumpus, J.P., Chen, H., Hunzaker, M.B.F., \nLee, J., Mann, M., Merhout, F., and Volfovsky, A. (2018). Exposure to opposing \nviews on social media can increase political polarization. Proceedings of the \nNational Academy of Sciences , 115(37), pp.\u00a09216\u20139221. https://doi.org/10.1073/\npnas.1804840115.\nBarkun, M. (2016). Conspiracy theories as stigmatized knowledge. Diogenes , 62(3\u20134). \nhttps://doi.org/10.1177/0392192116669288.\nBarnidge, M. (2017). Exposure to political disagreement in social media versus \nface-to-face and anonymous online settings. Political Communication , 34(2), \npp.\u00a0302\u2013321. https://doi.org/10.1080/10584609.2016.1235639.\nBarnidge, M. and Peacock, C. (2019). A third wave of selective exposure research? \nThe challenges posed by hyperpartisan news on social media. Media and Com -\nmunication , 7(3), pp.\u00a04\u20137. https://doi.org/10.17645/mac.v7i3.2257.\nBartlett, J. and Krasodomski-Jones, A. (2015). Counter-speech: Examining content \nthat challenges extremism online. Demos. http://www.demos.co.uk/wp-content/\nuploads/2015/10/Counter-speech.pdf.\nBauman, Z. (2013). Does the richness of the few benefit us all? Polity.\nBengani, P. (2019, December\u00a018). Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points. Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y. (2006). The wealth of networks: How social production transforms markets \nand freedom . Yale University Press.\nBenkler, Y., Faris, R. and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBenkler, Y., Faris, R., Roberts, H. and Zuckerman, E. (2017, March\u00a03). Study: Breitbart-\nled right-wing media ecosystem altered broader media agenda. Columbia Journal -\nism Review . https://www.cjr.org/analysis/breitbart-media-trump-harvard-study.\nphp.\nBeran, D. (2019). It came from something awful: How a toxic troll army accidentally \nmemed Donald Trump into office . St. Martin\u2019s Publishing Group.\nBerger, J. and Milkman, K. L. (2012). What makes online content viral? Journal of \nMarketing Research,  49(2), 192\u2013205. https://doi.org/10.1509/jmr.10.0353\nBernstein, J. (2015, July\u00a027). Behind the racist hashtag that is blowing up Twitter. \nBuzzFeed News . https://www.buzzfeednews.com/article/josephbernstein/\nbehind-the-racist-hashtag-some-donald-trump-fans-love.\nBernstein, J. (2017, October\u00a05). Here\u2019s how Breitbart and Milo smuggled Nazi and \nwhite nationalist ideas into the mainstream. BuzzFeed News . https://www.\nbib liogra Phy 215\nbuzzfeednews.com/article/josephbernstein/heres-how-breitbart-and-milo-\nsmuggled-white-nationalism.\nBernstein, M., Monroy-Hern\u00e1ndez, A., Harry, D., Andr\u00e9, P., Panovich, K., and \nVargas, G. (2011). 4chan and /b/: An analysis of anonymity and ephemerality \nin a large online community. Proceedings of the International AAAI Conference \non Web and Social Media , 5(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/\narticle/view/14134.\nBerry, J. and Sobieraj, S. (2014). The outrage industry . Oxford University Press.\nBlackburn, J. (2018, February\u00a016). How 4chan and The_Donald influence the fake \nnews ecosystem . FIC Observatory. https://observatoire-fic.com/en/how-4chan-\nand-the_donald-influence-the-fake-news-ecosystem-by-jeremy-blackburn-\nuniversity-of-alabama-at-birmingham/.\nBolsover, G. and Howard, P. (2019). Chinese computational propaganda: Automation, \nalgorithms and the manipulation of information about Chinese politics on \nTwitter and Weibo. Information, Communication & Society , 22(14).\nBoltanski, L. (1999). Distant suffering: Morality, media and politics. Cambridge \nUniversity Press.\nBond, S. (2021, March\u00a09) Instagram suggested posts to users. It served up COVID-19 \nfalsehoods, study finds. NPR. https://www.npr.org/2021/03/09/975032249/\ninstagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-\nfinds.\nBordia, P. and Difonzo, N. (2004). Problem solving in social interactions on the \ninternet: Rumor as social cognition. Social Psychology Quarterly , 67(1), pp.\u00a033\u201349. \nhttps://doi.org/10.1177/019027250406700105.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Aslib Journal of Information Management , \n66(3), pp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBostrom, A., Joslyn, S., Pavia, R., Walker, A. H., Starbird, K., and Leschine, T. M. (2015). \nMethods for communicating the complexity and uncertainty of oil spill response \nactions and tradeoffs. Human and Ecological Risk Assessment: An International \nJournal , 21(3), pp.\u00a0631\u2013645. https://doi.org/10.1080/10807039.2014.947867.\nBounegru, L., Gray, J., Venturini, T. and Mauri, M. (2018). A field guide to \u201cfake news\u201d \nand other information disorders . Public Data Lab.\nBovet, A. and Makse, H.A. (2019). Influence of fake news in Twitter during the \n2016 U.S. presidential election. Nature Communications , 10(1), p.\u00a07. https://doi.\norg/10.1038/s41467-018-07761-2.\nBoxell, L., Gentzkow, M., and Shapiro, J. (2017). Is the internet causing political \npolarization? Evidence from demographics. National Bureau of Economic \nResearch. http://www.nber.org/papers/w23258.\n216  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nBoxell, L., Gentzkow, M., and Shapiro, J. M. (2020). Cross-country trends in affective \npolarization. National Bureau of Economic Research. https://www.nber.org/\npapers/w26669.\nBoyd, R. L., Spangher, A., Fourney, A., Nushi, B., Ranade, G., Pennebaker, J., and \nHorvitz, E. (2018). Characterizing the Internet Research Agency\u2019s social media \noperations during the 2016 U.S. presidential election using linguistic analyses  \n[Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/ajh2q.\nBozdag, E. and Van den Hoven, J. (2015). Breaking the filter bubble: Democracy and \ndesign. Ethics and Information Technology, 17 (4), 249\u201365. https://doi.org/10.1007/\ns10676-015-9380-y.\nBradshaw, S. and Howard, P. N. (2018). Challenging truth and trust: A global inven -\ntory of organized social media manipulation. Computational Propaganda \nResearch Project. Oxford Internet Institute. https://demtech.oii.ox.ac.uk/wp-\ncontent/uploads/sites/93/2018/07/ct2018.pdf.\nBruns, A. (2019). Are filter bubbles real? Polity Press.\nBruns, A. and Weller, K. (2016). Twitter as a first draft of the present: And the \nchallenges of preserving it for the future. In Proceedings of the 8th ACM \nConference on Web Science (WebSci\u201916)  (pp.\u00a0183\u2013189). ACM. https://doi.\norg/10.1145/2908131.2908174.\nBruns, A., Harrington, S. and Hurcombe, E. (2020) Corona? 5G? Or both?: The \ndynamics of COVID-19/5G conspiracy theories on Facebook. Media International \nAustralia , 177 (1). https://doi.org/10.1177/1329878X20946113.\nBurkhardt, J.M. (2017). Combating fake news in the digital age. ALA Library Technol -\nogy Reports , 53(8): pp.\u00a05\u20139. https://doi.org/10.5860/ltr.53n8.\nBurley, S. (2017). Disunite the right: The growing divides in the pepe coalition. \nPolitical Research Associates. https://www.politicalresearch.org/2017/09/19/\ndisunite-the-right-the-growing-divides-in-the-pepe-coalition.\nburrough, x. and Dufour, F. (2018). Creativity. In E. Navas, O. Gallagher, and x. \nburrough (Eds.) Keywords in remix studies (pp.\u00a092\u2013104). Routledge.\nBurton, A. and Koehorst, D. (2020). The spread of political misinformation on \nonline subcultural platforms. Harvard Kennedy School Misinformation Review , \n1(6). https://doi.org/10.37016/mr-2020-40.\nBuyukozturk, B., Gaulden, S. and Dowd-Arrow, B. (2018). Contestation on Reddit, \nGamergate, and movement barriers. Social Movement Studies , 17(5), pp.\u00a0592\u2013609. \nhttps://doi.org/10.1080/14742837.2018.1483227\nBuzzSumo. (2020). Buzzsumo media monitoring. https://buzzsumo.com.\nCallery, A. and Proulx, D.T. (1997) Yahoo! cataloging the web. Journal of Internet \nCataloging , 1(1). https://doi.org/10.1300/J141v01n01_06.\nbib liogra Phy 217\nCaplow, T. (1946). Rumors in war departmental contributions: Teaching and research \nin the social sciences. Social Forces , 25(3), pp.\u00a0298\u2013302. https://heinonline.org/\nHOL/P?h=hein.journals/josf25andi=314.\nCaptain, S. (2017, March\u00a08). Disqus grapples with hosting toxic comments on \nBreitbart and extreme-right sites. Fast Company . https://www.fastcompany.\ncom/3068698/disqus-grapples-with-hosting-toxic-comments-on-breitbart-\nand-extreme-right-sites.\nCaramanica, J. (2020, March\u00a020). This \u201cImagine\u201d cover is no heaven. New York \nTimes . https://www.nytimes.com/2020/03/20/arts/music/coronavirus-gal-gadot-\nimagine.html.\nCenter for Countering Hate (2021, March\u00a09) Malgorithm: How Instagram\u2019s al -\ngorithm publishes misinformation and hate to millions during a pandemic. \nhttps://252f2edd-1c8b-49f5-9bb2-cb57bb47e4ba.filesusr.com/ugd/f4d9b9_89e\nd644926aa4477a442b55afbeac00e.pdf.\nCenters for Disease Control and Prevention. (2020, April\u00a01). Healthcare professionals: \nFrequently asked questions and answers. Centers for Disease Control and \nPrevention. https://web.archive.org/web/20200401051025/https://www.cdc.gov/\ncoronavirus/2019-ncov/hcp/faq.html.\nCernovich, M. (2016, September\u00a014). Un/Convention: Exposing fake news at the RNC \nand DNC. YouTube video. https://www.youtube.com/watch?v=cNwgKR88UDo.\nChadwick, A. (2017). The hybrid media system: Politics and power. Oxford University \nPress.\nChen, A. (2014, October\u00a023). The laborers who keep dick pics and beheadings out of \nyour Facebook feed. Wired . https://www.wired.com/2014/10/content-moderation/.\nChu, J. and McDonald, J. (2020, January\u00a029). Helping the world find credible informa -\ntion about novel #coronavirus. Twitter Blog. https://blog.twitter.com/en_us/\ntopics/company/2020/authoritative-information-about-novel-coronavirus.\nColeman, E.G. (2014). Hacker, hoaxer, whistleblower, spy: The many faces of Anony -\nmous . Verso.\nColeman, K. (2021). Introducing Birdwatch, a community-based approach to mis -\ninformation. https://blog.twitter.com/en_us/topics/product/2021/introducing-\nbirdwatch-a-community-based-approach-to-misinformation.html.\nColley, T. and Moore, M. (2020). The challenges of studying 4chan and the \nAlt-Right: \u201cCome on in the water\u2019s fine.\u201d New Media & Society . ht tps://doi.\norg/10.1177/1461444820948803.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram. Junk news, fol-\nlower ecologies and artificial amplification. In R. Rogers and S. Niederer (Eds.), The \npolitics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University Press.\n218  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nColquhoun, R. (2013, January\u00a013). Political art and activism: Flash mob. \nNational Collective. http://www.nationalcollective.com/2013/01/13/\npolitical-art-and-activism-flash-mob/.\nComscore (2019). Comscore March\u00a02019 top 50 multi-platform website properties \n(desktop and mobile). https://www.comscore.com/Insights/Rankings.\nConger, K. (2021). Twitter, in widening crackdown, removes over 70,000 QAnon \naccounts. New York Times . https://www.nytimes.com/2021/01/11/technology/\ntwitter-removes-70000-qanon-accounts.html.\nCooper, Sara (2020). How to medical, TikTok video. https://www.tiktok.com/@\nwhatchugotforme/video/6819061413877763334.\nCoppins, M. (2020, March). The billion-dollar disinformation campaign to reelect the \npresident. The Atlantic . https://www.theatlantic.com/magazine/archive/2020/03/\nthe-2020-disinformation-war/605530/.\nCourtois, C., Slechten, L., and Coenen, L. (2018). Challenging Google Search filter \nbubbles in social and political information: Disconforming evidence from a \ndigital methods case study. Telematics and Informatics , 35(7), pp.\u00a02006\u20132015. \nhttps://doi.org/10.1016/j.tele.2018.07.004.\nCrowley, M. (2020, February\u00a024) \u201cAmerica loves India,\u201d Trump declares at rally \nwith Modi. New York Times . https://www.nytimes.com/2020/02/24/world/asia/\ntrump-india.html.\nDailey, D. and Starbird, K. (2015). \u201cIt\u2019s raining dispersants\u201d: Collective sensemaking of \ncomplex information in crisis contexts. In Proceedings of the 18th ACM Conference \nCompanion on Computer Supported Cooperative Work and Social Computing , \npp.\u00a0155\u2013158. https://doi.org/10.1145/2685553.2698995.\nDan, O. and Davison, B. D. (2016). Measuring and predicting search engine users\u2019 sat -\nisfaction. ACM Computing Surveys , 49(1), pp.\u00a01\u201335. https://doi.org/10.1145/2893486.\nDaniels, J. (2018). The algorithmic rise of the \u201calt-right.\u201d Contexts , 17(1). ht tps://doi.\norg/10.1177/1536504218766547.\nDay, V. and Eagle, J. R. (2016). Cuckservative: How \u201cconservatives\u201d betrayed America . \nCastalia House.\nDe Keulenaar, E., Burton, A.G., and Kisjes, I. (2021). Deplatforming, demotion and \nfolk theories of Big Tech persecution. Fronteiras \u2013 Estudos Midi\u00e1ticos , 23(2), \npp.\u00a0118\u2013139. https://doi.org/10.4013/fem.2021.232.09.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion. First Monday . https://doi.org/10.5210/fm.v25i11.10643.\nDeadville, J. (2015). The sound of media spectacle: Music at the party conventions. \nMusic & Politics, 9 (2), pp.\u00a01\u201324. https://doi.org/10.3998/mp.9460447.0009.205.\nbib liogra Phy 219\nDean, J. (1998). Aliens in America . Cornell University Press.\nDelli Carpini, M.X. (2018). Alternative facts: Donald Trump and the emergence of \na new U.S. media regime. In Z. Papacharissi and P. Boczkowski (Eds.), Trump \nand the media (pp.\u00a017\u201323). MIT Press.\nDiakopoulos, N., Trielli, D., Stark, J., and Mussenden, S. (2018). I Vote For\u2014How \nSearch Informs Our Choice of Candidate. In M. Moore and D. Tambini (Eds.), Digi -\ntal dominance: The power of Google, Amazon, Facebook and Apple (pp.\u00a0320\u2013341). \nOxford University Press.\nDigital Methods Initiative. (n.d.). Search Engine Scraper . https://wiki.digitalmethods.\nnet/Dmi/ToolSearchEngineScraper.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J. and \nJohnson, B. (2018). The tactics & tropes of the Internet Research Agency. New \nKnowledge. https://disinformationreport.blob.core.windows.net/disinformation-\nreport/NewKnowledge- Disinformation-Report-Whitepaper.pdf.\nDonovan, J. (2019). How memes got weaponized: A short history. MIT Tech -\nnology Review .  https://www.technologyreview.com/2019/10/24/132228/\npolitical-war-memes-disinformation/.\nDonovan, J. and boyd, d. (2018, June\u00a01). The case for quarantining extremist \nideas. The Guardian . http://www.theguardian.com/commentisfree/2018/jun/01/\nextremist-ideas-media-coverage-kkk.\nDPA. (2021). DPA fact-checking. Deutsche Presse-Agentur. https://dpa-factchecking.\ncom/netherlands/.\nDrawrowfly. (2021). TikTok scraper [software]. https://github.com/drawrowfly/\ntiktok-scraper.\nDubois, E. and Blank, G. (2018). The echo chamber is overstated: The moderating \neffect of political interest and diverse media. Information, Communication & \nSociety  21 (5): 729\u2013745. https://doi.org/10.1080/1369118X.2018.1428656.\nDwoskin, E. (2020, November\u00a012). Trump\u2019s attacks on election outcome prolong \ntech\u2019s emergency measures. Washington Post . https://www.washingtonpost.\ncom/technology/2020/11/12/facebook-ad-ban-lame-duck/.\nEconomist . (2019, June\u00a08). Google rewards reputable reporting, not left-wing \npolitics. The Economist . https://www.economist.com/graphic-detail/2019/06/08/\ngoogle-rewards-reputable-reporting-not-left-wing-politics.\nEinwiller, S.A. and Kim, S. (2020). How online content providers moderate user-\ngenerated content to prevent harmful online communication: An analysis of \npolicies and their implementation. Policy & Internet , 12(2), pp.\u00a0184\u2013206. https://\ndoi.org/10.1002/poi3.239.\nEllefson, L. (2019, August\u00a07). Breitbart\u2019s audience has dropped 72% since Trump \ntook office\u2014As other right-wing sites have gained. The Wrap . https://www.\nthewrap.com/breitbart-news-audience-dropped-steve-bannon-72-percent/.\n220  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nEllis, E.G. (2019, September\u00a010). Fighting Instagram\u2019s $1.3 billion problem\u2014Fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nEnli, G. (2017). Twitter as arena for the authentic outsider: Exploring the social \nmedia campaigns of Trump and Clinton in the 2016 U.S. presidential elec -\ntion. E uropean Journal of Communication , 32(1), pp.\u00a050\u201361. https://doi.\norg/10.1177/0267323116682802.\nEvan, D. (2017, May\u00a026). Did Pope Francis slap away President Trump\u2019s hand? \nSnopes . https://www.snopes.com/fact-check/pope-francis-trump-hand-slap/.\nFacebook (2018, December\u00a06). Coordinated inauthentic behavior. Facebook News -\nroom. https://about.fb.com/news/2018/12/inside-feed-coordinated-inauthentic-\nbehavior/.\nFacebook (2021a, February\u00a09). January\u00a02021 coordinated inauthentic be -\nhavior report. Facebook Newsroom. https://about.fb.com/news/2021/02/\njanuary-2021-coordinated-inauthentic-behavior-report/.\nFacebook (2021b, May\u00a025). False news, Facebook Transparency Center. https://\ntransparency.fb.com/policies/community-standards/false-news/.\nFeldman, B. (2017, June\u00a08). In Russia, you can buy Instagram likes from a vending \nmachine. New York Times Magazine , June\u00a08. https://nymag.com/intelligenc -\ner/2017/06/you-can-buy-instagram-likes-from-a-russian-vending-machine.html.\nFiorentini, I. (2013). \u201cZOMG! Dis is a new language\u201d: The case of lolspeak. Newcastle \nWorking Papers in Linguistics , 13(1), pp.\u00a090\u2013108.\nFishkin, R. (2018). SparkToro\u2019s new tool to uncover real vs. fake followers on Twitter, \nSparkToro. https://sparktoro.com/blog/sparktoros-new-tool-to-uncover-real-\nvs-fake-followers-on-twitter/.\nFloridi, L. (2021). Trump, Parler, and regulating the infosphere as our commons. \nPhilosophy & Technology , 34(1), pp.\u00a01\u20135. https://doi.org/10.1007/s13347-021-00446-7.\nGadde, V. and Roth, Y. (2018, October\u00a017). Enabling further research of information \noperations on Twitter. Twitter Blog. https://blog.twitter.com/en_us/topics/\ncompany/2018/enabling-further-research-of-information-operations-on-twitter.\nhtml.\nGagliardone, I. (2019). Defining online hate and its \u201cpublic lives\u201d: What is the place \nfor \u201cextreme speech\u201d? International Journal of Communication , 13. ht tps://doi.\norg/1932\u20138036/20190005.\nGallucci, N. (2016, November\u00a022). 8 ways to consume news without using Facebook. \nMashable . https://mashable.com/2016/11/22/consume-news-without-facebook/.\nGeboers, M. (2019). \u201cWriting\u201d oneself into tragedy: Visual user practices and \nspectatorship of the Alan Kurdi images on Instagram. Visual Communication . \nhttps://doi.org/10.1177/1470357219857118.\nGekker, A. (2019). Playing with power: Casual politicking as a new frame for political \nanalysis. In R. Glas, S. Lammes, M. de Lange, J. Raessens, and I. de Vries (Eds.) \nbib liogra Phy 221\nThe playful citizen: Civic engagement in a mediatized culture (pp.\u00a0387\u2013419). \nAmsterdam University Press.\nGibbs, S. (2016, December\u00a05). Google alters search autocomplete to remove \u201care Jews \nevil\u201d suggestion. The Guardian . https://www.theguardian.com/technology/2016/\ndec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion.\nGillespie, E. (2020, September\u00a030). \u201cPastel QAnon\u201d: The female lifestyle bloggers \nand influencers spreading conspiracy theories through Instagram. The Feed . \nhttps://www.sbs.com.au/news/the-feed/pastel-qanon-the-female-lifestyle-\nbloggers-and-influencers-spreading-conspiracy-theories-through-instagram.\nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nGillespie, T. (2020). Content moderation, AI, and the question of scale. Big Data & \nSociety , July\u2013December: 1\u20135, https://doi.org/10.1177/2053951720943234.\nGoforth, C. (2021, January\u00a021). Notorious pro-Trump forum rebrands as \u201cpatriots\u201d \nafter post-Capitol riot infighting. The Daily Dot . https://www.dailydot.com/\ndebug/pro-trump-site-renamed-internal-conflict/.\nGolebiewski, M. and boyd, d. (2019). Data voids: Where missing data can easily be \nexploited. Data & Society Research Institute. https://datasociety.net/wp-content/\nuploads/2019/11/Data-Voids-2.0-Final.pdf.\nGoogle. (2019a). How Google Fights Misinformation. Google Blog. https://www.\nblog.google/documents/37/How_Google_Fights_Disinformation.pdf.\nGoogle. (2019b). Search Quality Evaluator Guidelines. https://static.googleusercontent.\ncom/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf.\nGray, J., Bounegru, L., and Venturini, T. (2020). \u201cFake news\u201d as infrastructural uncanny. \nNew Media & Society , 22(2), pp.\u00a0317\u2013341. https://doi.org/10.1177/1461444819856912.\nGreen, J. (2017). Devil\u2019s bargain: Steve Bannon, Donald Trump, and the nationalist \nuprising . Penguin.\nGroshek, J. and Koc-Michalska, K. (2017). Helping populism win? Social media use, \nfilter bubbles, and support for populist presidential candidates in the 2016 U.S. \nElection Campaign. Information, Communication & Society, 20 (9), 1389\u2013407. \nhttps://doi.org/10.1080/1369118X.2017.1329334.\nGuess, A., Nyhan, B., and Reifler, J. (2018). Selective exposure to misinformation: \nEvidence from the consumption of fake news during the 2016 U.S. presidential \ncampaign [Working paper]. http://www.dartmouth.edu/~nyhan/fake-news-2016.pdf.\nHagen, S. and Jokubauskaite, E. (2019). Dutch junk news on 4chan and Reddit /\npol/. In R. Rogers and S. Niederer (Eds.), The politics of social media manipulation \n(pp.\u00a0115\u2013151). Dutch Ministry of the Interior and Kingdom Relations.\nHagen, S., Burton, A., Wilson, J., and Tuters, M. (2019, September\u00a08). Infinity\u2019s Abyss: \nAn Overview of 8chan. OILab . https://oilab.eu/infinitys-abyss-an-overview-\nof-8chan/.\n222  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nHaim, M., Graefe, A., and Brosius, H.-B. (2018). Burst of the filter bubble?: Effects \nof personalization on the diversity of Google News. Digital Journalism , 6(3), \npp.\u00a0330\u2013343. https://doi.org/10.1080/21670811.2017.1338145.\nHarris, S. (2019, February\u00a05). #148 \u2013 Jack Dorsey. Sam Harris Podcast. https://\nsamharris.org/podcasts/148-jack-dorsey/.\nHassell, H. J. G., Holbein, J. B., and Miles, M. R. (2020). There is no liberal media bias \nin which news stories political journalists choose to cover. Science Advances , \n6(14), eaay9344. https://doi.org/10.1126/sciadv.aay9344.\nHautea, S., Parks, P., Takahashi, B., and Zeng, J. (2021). Showing they care (or don\u2019t): \nAffective publics and ambivalent climate activism on TikTok. Social Media+ \nSociety . https://doi.org/10.1177/20563051211012344.\nHawley, G. (2017). Making sense of the alt-right . Columbia University Press.\nHedrick, A., Karpf, D., and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal Of Communication, 12 (8). https://ijoc.org/index.\nphp/ijoc/article/view/8736/.\nHerring, S. (2012). Special internet language varieties: Culture, creativity & language \nchange [Paper]. The II LETiSS Workshop Language Go Web: Standard and \nNonstandard Languages on the Internet, Pavia.\nHerrman, John (2016, August\u00a028) Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHeuts, F. and Mol, A. (2013). What is a good tomato? A case of valuing in practice. \nValuation Studies , 1(2), pp.\u00a0125\u2013146. https://doi.org/10.3384/vs.2001-5992.1312125.\nHighfield, T. and Leaver, T. (2016). Instagrammatics and digital methods: Studying \nvisual social media, from selfies and GIFs to memes and emoji. Communication \nResearch and Practice , 2(1), pp.\u00a047\u201362. https://doi.org/10.1080/22041451.2016.1155332.\nHine, G., Onaolapo, J., Cristofaro, E. D., Kourtellis, N., Leontiadis, I., Samaras, R., \nStringhini, G., and Blackburn, J. (2017). Kek, cucks, and God emperor Trump: \nA measurement study of 4chan\u2019s politically incorrect forum and its effects on \nthe web. In Proceedings of the International AAAI Conference on Web and Social \nMedia , 11(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/article/view/14893.\nHines, N. (2018, April\u00a022). Alex Jones\u2019 proteg\u00e9, Paul Joseph Watson, is about to \nsteal his crackpot crown. The Daily Beast . https://www.thedailybeast.com/\nalex-jones-protege-paul-joseph-watson-is-about-to-steal-his-crackpot-crown.\nHolt, K., Figenschou, T.U. and Frischlich, L. (2019). Key dimensions of alternative \nnews media. Digital Journalism , 7(7), pp.\u00a0860\u2013869. https://doi.org/10.1080/2167\n0811.2019.1625715.\nHoward, P. (2020). Lie machines . Yale University Press.\nbib liogra Phy 223\nHoward, P. N., Bolsover, G., Kollyani, B., Bradshaw, S., and Neudert, L.-M. (2017). \nJunk news and bots during the U.S. election: What were Michigan voters sharing \nover Twitter?  Data Memo 2017.1, Project on Computational Propaganda, Oxford \nInternet Institute. http://blogs.oii.ox.ac.uk/politicalbots/wp- content/uploads/\nsites/89/2017/03/What-Were-Michigan-Voters-Sharing-Over-Twitter-v2.pdf.\nHoward, P. N., Ganesh, B., Liotsiou, D., Kelly, J., and Fran \u00e7o is, C. (2018). The IRA, \nsocial media and political polarization in the United States, 2012\u20132018, Report, \nComputational Propaganda Research Project, Oxford Internet Institute. https://\ncomprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2018/12/The-IRA-Social-\nMedia-and-Political-Polarization.pdf.\nHypeAuditor. (2020). Instagram reports. https://hypeauditor.com/reports/\ninstagram/.\nIati, M., Kornfield, M., O\u2019Grady, S., and Mellen, R. (2020, May\u00a04). Trump says it\u2019s \nsafe to reopen states, while Birx finds protesters with no masks or distancing \n\u201cdevastatingly worrisome.\u201d Washington Post . https://www.washingtonpost.com/\nworld/2020/05/03/coronavirus-latest-news/.\nIf Americans Knew. (2017, February\u00a03). Senator Schumer says God made him a \nguardian of Israel. YouTube video. https://web.archive.org/web/20210417224317/\nhttps://www.youtube.com/c/IfAmericansKnew-Video/about. Accessed August\u00a02, \n2020.\nIngram, D. and Collins, B. (2020, June\u00a029). Reddit bans hundreds of subreddits for \nhate speech including Trump community. NBC News . https://www.nbcnews.\ncom/tech/tech-news/reddit-bans-hundreds-subreddits-hate-speech-including-\ntrump-community-n1232408.\nInstagram (n.d.). What are the requirements to apply for a verified badge on \nInstagram? Instagram Help Center. https://help.instagram.com/312685272613322.\nInstagram. (2018). Reducing inauthentic activity on Instagram. Instagram Blog. \nhttps://about.instagram.com/blog/announcements/reducing-inauthentic-\nactivity-on-instagram.\nInstagram. (2020). Introducing new authenticity measures on Instagram. \nInstagram Blog. https://about.instagram.com/blog/announcements/\nintroducing-new-authenticity-measures-on-instagram.\nInternet Archive. (2021). Internet archive: Digital library of free & borrowable \nbooks, movies, music & Wayback Machine [Web-based]. Internet Archive. \nhttps://archive.org/.\nIntrona, L. and Wood, D. (2004). Picturing algorithmic surveillance: The politics of \nfacial recognition systems. Surveillance & Society , 2(2/3), pp.\u00a0177\u2013198.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\n224  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nJansen, B.J. and Spink, A. (2006). How are we searching the World Wide Web? A \ncomparison of nine search engine transaction logs. Information Processing & \nManagement , 42(1), pp.\u00a0248\u2013263. https://doi.org/10.1016/j.ipm.2004.10.007.\nJenkins, H. (2006). Convergence culture: Where old and new media collide . New \nYork University Press.\nJenkins, H. (2017, May\u00a030). The ambivalent internet: An interview with Whitney \nPhillips and Ryan M. Milner (Part One). Confessions of an ACA-fan Blog. http://\nhenryjenkins.org/blog/2017/05/the-ambivalent-internet-an-interview-with-\nwhitney-phillips-and-ryan-m-milner-part-one.html.\nJett, J. (2021, February\u00a011). Robert F. Kennedy, Jr. is barred from Instagram over false \ncoronavirus claims. New York Times . https://www.nytimes.com/2021/02/11/us/\nrobert-f-kennedy-jr-instagram-covid-vaccine.html.\nJohn, N.A. (2019). Social media bullshit: What we don\u2019t know about facebook.com/\npeace and why we should care. Social Media + Society , January-March: 1\u201316. \nhttps://doi.org/10.1177/2056305119829863.\nJokubauskait\u0117, E. and Peeters, S. (2020). Generally curious: Thematically distinct \ndatasets of general threads on 4chan/pol/. Proceedings of the International AAAI \nConference on Web and Social Media , 14, pp.\u00a0863\u2013867.\nKaplan Sommer, A. (2017, October\u00a019). White nationalist Richard Spencer gives \nIsrael as example of ethno-state he wants in U.S. Haaretz . https://www.haaretz.\ncom/us-news/richard-spencer-gives-israel-as-example-of-ethno-state-he-wants-\nin-u-s-1.5459154.\nKarpf, D. Digital politics after Trump. Annals of the International Communication \nAssociation , 41(2), pp.\u00a0198\u2013207. https://doi.org/10.1080/23808985.2017.1316675.\nKelemen, M. (2005). Managing quality: Managerial and critical perspectives . Sage. \nhttps://doi.org/10.4135/9781446220382.\nKist, R. and Zantingh, P. (2017, March\u00a06). Geen grote rol nepnieuws in aanloop \nnaar verkiezingen. NRC Handelsblad . https://www.nrc.nl/nieuws/2017/03/06/\nfake-news-nee-zo-erg-is-het-hier-niet-7144615-a1549050.\nKlayman, A. (2019). The Brink [Feature documentary; Digital film]. https://ali -\nsonklayman.com/the-brink.\nKlein, E. and Robison, J. (2020). Like, post, and distrust? How social media use \naffects trust. Political Communication , 37(1), pp.\u00a046\u201364. https://doi.org/10.1080\n/10584609.2019.1661891.\nKnuttila, L. (2011). User unknown: 4chan, anonymity and contingency. First Monday . \nhttps://doi.org/10.5210/fm.v16i10.3665.\nKomok, A. (2018). How to check Instagram account for fake followers. HypeAuditor. htt -\nps://hypeauditor.com/blog/how-to-check-instagram-account-for-fake-followers/.\nKomok, A. (2020). What are suspicious accounts? HypeAuditor . https://help.\nhypeauditor.com/en/articles/2221742-what-are-suspicious-accounts.\nbib liogra Phy 225\n  Konrad, C. (2021, January\u00a028). Trump presidency permanently alters landscape of \nmedia. The Maneater . https://themaneater.com/trump-presidency-permanently-\nalters-landscape-of-media/.\nKou, Y., Gui, X., Chen, Y., and Pine, K. (2017). Conspiracy talk on social media: \nCollective sensemaking during a public health crisis. In Proceedings of the \nACM on Human-Computer Interaction , 1(CSCW), article no.\u00a061. https://doi.\norg/10.1145/3134696.\nKrafft, P., Zhou, K., Edwards, I., Starbird, K., and Spiro, E.S. (2017). Centralized, \nparallel, and distributed information processing during collective sensemaking. \nIn Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , \npp.\u00a02976\u20132987. https://doi.org/10.1145/3025453.3026012.\nKwak, H., Lee, C., Park, H. and Moon, S. (2010). What is Twitter, a social network or \na news media? In Proceedings of the 19th International Conference on World \nWide Web (pp.\u00a0591\u2013600). ACM.\nLangville, A.N. and Meyer, C.D. (2006). Google\u2019s PageRank and beyond: The science \nof search engine rankings . Princeton University Press.\nLazer, D. M., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, \nF., \u2026 and Schudson, M. (2018). The science of fake news. Science, 359 (6380), \npp.\u00a01094\u20131096. https://doi.org/10.1126/science.aao2998.\nLee, J.C. and Quealy, K. (2019, May\u00a024). The 598 people, places and things Donald \nTrump has insulted on Twitter: A complete list. New York Times . https://www.\nnytimes.com/interactive/2016/01/28/upshot/donald-trump-twitter-insults.html.\nLee, L. and Oppong, F. (2020, September\u00a01). Adding more context to Trends. Twitter Blog. \nhttps://blog.twitter.com/en_us/topics/product/2020/adding-more-context-to-trends.\nLenzen, C. (2020, November\u00a09). This Luke Bryan song is an anti-Trump anthem on Tik -\nTok. The Daily Dot . https://www.dailydot.com/irl/luke-bryan-anti-trump-tiktok/.\nLerman, R. (2021, February\u00a024). Major Trump backer Rebekah Mercer orchestrates \nParler\u2019s second act. Washington Post . https://www.washingtonpost.com/\ntechnology/2021/02/24/parler-relaunch-rebekah-mercer/.\nLewis, D. (2020). Is the coronavirus airborne? Experts can\u2019t agree. Nature , 580(7802), \np.\u00a0175. https://doi.org/10.1038/d41586-020-00974-w.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube.  Data & Society Research Institute. https://datasociety.net/library/\nalternative-influence/.\nLewis, R. (2020). \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\n226  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nLobinger, K., Kr\u00e4mer, B., Venema, R., and Benecchi, E. (2020). Pepe\u2014Just a funny \nfrog? A visual meme caught between innocent humor, far-right ideology, and \nfandom. In B. Kr\u00e4mer and C. Holtz-Bacha (Eds.), Perspectives on populism and \nthe media  (pp.\u00a0333\u2013352). Nomos. https://doi.org/10.5771/9783845297392-333.\nLorenz. T. (2019, March\u00a021) Instagram is the internet\u2019s new home for hate. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2019/03/\ninstagram-is-the-internets-new-home-for-hate/585382/.\nLorenz, T. (2020, November\u00a04). Election night on TikTok: Anxiety, analysis and \nwishful thinking. New York Times . https://www.nytimes.com/2020/11/04/style/\ntiktok-election-night.html.\nLubbers, E. (2016, November\u00a05). There is no such thing as the Denver Guardian, \ndespite that Facebook post you saw. The Denver Post . https://www.denverpost.\ncom/2016/11/05/there-is-no-such-thing-as-the-denver-guardian/.\nLudemann, D. (2018). /pol/emics: Ambiguity, scales, and digital discourse on \n4chan. Discourse, Context & Media , 24, pp.\u00a092\u201398. https://doi.org/10.1016/j.\ndcm.2018.01.010.\nLyons, K. (2020, October\u00a011). Twitter flags, limits sharing on Trump tweet about being \u201cim -\nmune\u201d to coronavirus. The Verge . https://www.theverge.com/2020/10/11/21511682/\ntwitter-disables-sharing-trump-tweet-coronavirus-misinformation.\nMahendran, L. and Alsherif, N. (2020, January\u00a08) Adding clarity to our Com -\nmunity Guidelines. TikTok newsroom. https://newsroom.tiktok.com/en-us/\nadding-clarity-to-our-community-guidelines.\nMalone, C. (2016, August\u00a018). Trump made Breitbart great again. FiveThirtyEight . \nhttps://fivethirtyeight.com/features/trump-made-breitbart-great-again/.\nMandavilli, A. (2020, July\u00a04). 239 experts with one big claim: The coronavirus is \nairborne. New York Times . https://www.nytimes.com/2020/07/04/health/239-\nexperts-with-one-big-claim-the-coronavirus-is-airborne.html.\nMaragkou, E. (2020, December\u00a08). The conspiracy theorist as influencer. Insti -\ntute of Network Cultures Blog. https://networkcultures.org/blog/2020/12/08/\nthe-conspiracy-theorist-as-influencer/.\nMarres, N. (2018). Why we can\u2019t have our facts back. Engaging Science, Technology, \nand Society, 4 , pp.\u00a0423\u2013443. https://doi.org/10.17351/ests2018.188.\nMassanari, A. (2017). #Gamergate and the fappening: How Reddit\u2019s algorithm, \ngovernance, and culture support toxic technocultures. New Media & Society , \n19(3), pp.\u00a0329\u2013346. https://doi.org/10.1177/1461444815608807.\nMcIntosh, J. (2012). A history of subversive remix video before YouTube: Thirty \npolitical video mashups made between World War II and 2005. Transformative \nWorks and Cultures, 9 . https://doi.org/10.3983/twc.2012.0371.\nMcNeal, S. and Broderick, R. (2020, April\u00a04). Lifestyle influencers are now sharing \nsome bogus far-right conspiracy theories about the coronavirus on Instagram. \nbib liogra Phy 227\nBuzzfeed News . https://www.buzzfeednews.com/article/stephaniemcneal/\ncoronavirus-lifestyle-influencers-sharing-conspiracy-qanon.\nMcWhirter, A. (2015). Film criticism, film scholarship and the video essay. Screen, \n56(3), pp.\u00a0369\u2013377. https://doi.org/10.1093/screen/hjv044.\nMedia Bias/Fact Check. (2020). Filtered search. https://mediabiasfactcheck.com.\nMedia Bias/Fact Check. (2021). Breitbart. https://mediabiasfactcheck.com/breitbart/.\nMedina Serrano, J.C., Papakyriakopoulos., O. and Hegelich S. (2020). Dancing to \nthe partisan beat: A first analysis of political communication on TikTok. In \nProceedings of the 12th ACM Conference on Web Science, pp.\u00a0257\u2013266. https://\ndoi.org/10.1145/3394231.3397916.\nMeier, F., Elsweiler, D., and Wilson, M.L. (2014). More than liking and bookmark -\ning? Towards understanding Twitter favouriting behaviour. In Proceedings of \nICWSM\u201914 . AAAI Press. http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/\npaper/view/8094.\nMerrill, J. B. and Oremus, W. (2021, October\u00a026). Five points for anger, one for \na \u201clike\u201d: How Facebook\u2019s formula fostered rage and misinformation. Wash -\nington Post . https://www.washingtonpost.com/technology/2021/10/26/\nfacebook-angry-emoji-algorithm/.\nMosseri, A. (2017, April\u00a06). Working to stop misinformation and false news. Facebook \nNewsroom. https://about.fb.com/news/2017/04/working-to-stop-misinformation-\nand-false-news/.\nNagle, A. (2017). Kill all normies: Online culture wars from 4chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNewsGuard (2020). NewsGuard nutrition label. https://www.newsguardtech.com.\nNiederer, S. (2019). Networked content analysis: The case of climate change. \nInstitute of Network Cultures. https://networkcultures.org/blog/publication/\ntod32-networked-content-analysis-the-case-of-climate-change/\nNissenbaum, A. and Shifman, L. (2017). Internet memes as contested cultural \ncapital: The case of 4chan\u2019s /b/ board. New Media & Society , 19(4), pp.\u00a0483\u2013501. \nhttps://doi.org/10.1177/1461444815609313.\nNoble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism . \nNew York University Press.\nNunes, M. (2018). Parody. In E. Navas, O. Gallagher, and x. burrough (Eds.) Keywords \nin remix studies (pp.\u00a0217\u2013229). Routledge.\nO\u2019Hara, K. and Stevens, D. (2015). Echo chambers and online radicalism: Assessing \nthe internet\u2019s complicity in violent extremism. Policy & Internet, 7(4), pp.\u00a0401\u2013422. \nhttps://doi.org/10.1002/poi3.88.\nO\u2019Leary, N. (2020, March\u00a010). How Dutch false sense of security helped corona -\nvirus spread. Irish Times . https://www.irishtimes.com/news/world/europe/\nhow-dutch-false-sense-of-security-helped-coronavirus-spread-1.4199027.\n228  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nOh, D. (2019). Review of The ambivalent internet: mischief, oddity, and antagonism \nonline. Information, Communication & Society , 22(8), pp.\u00a01189\u20131191. https://doi.\norg/10.1080/1369118X.2019.1606267.\nOlmsted, K. (2009) Real enemies: Conspiracy theories and American democracy, \nWorld War I to 9/11 . Oxford University Press.\nOtero, V. (2017). The chart, version 3.1, ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nOwen, L. H. (2021, July\u00a014) At first, Facebook was happy that I and other journalists \nwere finding its tool useful\u2026but the mood shifted. NiemanLab. https://www.\nniemanlab.org/2021/07/at-first-facebook-was-happy-that-i-and-other-journalists-\nwere-finding-its-tool-useful-but-the-mood-shifted/.\nPapasavva, A., Zannettou, S., Cristofaro, E. D., Stringhini, G., and Blackburn, J. \n(2020). Raiders of the lost kek: 3.5 years of augmented 4chan posts from the \npolitically incorrect board. Proceedings of the International AAAI Conference \non Web and Social Media , 14, pp.\u00a0885\u2013894.\nPardes, A. (2020, October\u00a022). The TikTok teens trying to meme the vote. Wired . \nhttps://www.wired.com/story/tiktok-election-2020/.\nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nParks, L. (2019). Dirty data: Content moderation, regulatory outsourcing and The \nCleaners. Film Quarterly , 73(1). https://doi.org/10.1525/fq.2019.73.1.11.\nPeacock, C., Hoewe, J., Panek, E., and Willis, G. P. (2019). Hyperpartisan news use: \nRelationships with partisanship, traditional news use, and cognitive and affec -\ntive involvement. Paper presented at the Annual Conference of the International \nCommunication Association, Washington, DC.\nPeeters, S. (2020, May\u00a015). Normiefication of extreme speech and the wid -\nening of the Overton window. Open Intelligence Lab. https://oilab.eu/\nnormiefication-of-extreme-speech-and-the-widening-of-the-overton-window/.\nPeeters, S. and Hagen, S. (2018). 4CAT: 4chan Capture and Analysis Toolkit [soft -\nware]. https://4cat.oilab.eu.\nPeeters, S. and Hagen, S. (2021). The 4CAT Capture and Analysis Toolkit: A Modular \nTool for Transparent and Traceable Social Media Research (SSRN Scholarly Paper \nID 3914892). Social Science Research Network. https://doi.org/10.2139/ssrn.3914892.\nPeeters, S., Tuters, M., Willaert, T., and de Zeeuw, D. (2021). On the vernacular \nlanguage games of an antagonistic online subculture. Frontiers in Big Data , \n4(65). https://doi.org/10.3389/fdata.2021.718368.\nPepp, J., Michaelson, E. and Sterken, R. (2019). Why we should keep talking about \nfake news. Inquiry . https://doi.org/10.1080/0020174X.2019.1685231.\nPerez, S. (2021, August\u00a02). Twitter partners with AP and Reuters to address misinfor -\nmation on its platform. TechCrunch . https://techcrunch.com/2021/08/02/twitter-\npartners-with-ap-and-reuters-to-address-misinformation-on-its-platform/.\nbib liogra Phy 229\nPeterson, J. (2016, November\u00a08). Jordan Peterson: The right to be politically incorrect. \nNational Post. https://nationalpost.com/opinion/jordan-peterson-the-right-to-\nbe-politically-incorrect.\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nPhillips, W. (2018). The oxygen of amplification. Data & Society Research Institute. \nhttps://datasociety.net/output/oxygen-of- amplification/.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nPorter, J. (2020, May\u00a029). Twitter restricts new Trump tweet for \u201cglorifying violence.\u201d \nThe Verge . https://www.theverge.com/2020/5/29/21274323/trump-twitter-\nglorifying-violence-minneapolis-shooting-looting-notice-restriction.\nQuandt, T. (2018). Dark participation. Media and Communication , 6(4), pp.\u00a036\u201348. \nhttps://doi.org/10.17645/mac.v6i4.1519.\nQuealy, K. (2017, July\u00a026). Trump is on track to insult 650 people, places and things \non Twitter by the end of his first term. New York Times . https://www.nytimes.\ncom/interactive/2017/07/26/upshot/president-trumps-newest-focus-discrediting-\nthe-news-media-obamacare.html.\nRathnayake, C. and Suthers, D.D. (2018). Twitter issue response hashtags as af -\nfordances for momentary connectedness. Social Media + Society . ht tps://doi.\norg/10.1177/2056305118784780.\nReider, B. (2015). YouTube Data Tools [software]. https://tools.digitalmethods.net/\nnetvizz/youtube/index.php.\nRheingold, H. (1994). The millennial whole earth catalog . HarperCollins.\nRoberts, S. T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S. U. Noble and B.M. Tynes (Eds.), The intersectional internet: Race, sex, class \nand culture online (pp.\u00a0147\u2013160). Peter Lang.\nRobertson, R. E., Lazer, D., and Wilson, C. (2018). Auditing the personalization and \ncomposition of politically related search engine results pages. Proceedings of \nthe 2018 World Wide Web Conference on World Wide Web , pp.\u00a0955\u2013965. https://\ndoi.org/10.1145/3178876.3186143.\nRoeder, O. (2018, August\u00a08). We gave you 3 million Russian troll tweets. Here\u2019s \nwhat you\u2019ve found so far. FiveThirtyEight. https://fivethirtyeight.com/features/\nwhat-you-found-in-3-million-russian-troll-tweets/.\nRogers, R. (2004 ). Information politics on the web . MIT Press.\nRogers, R. (2013). Digital methods . MIT Press.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn K. Weller, A. Bruns, J. Burgess, M. Mahrt and C. Puschmann (Eds.), Twitter \nand society (pp. ix\u2013xxvi) . Peter Lang.\n230  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nRogers, R. (2017). Digital methods for cross-platform analysis. In J. Burgess, A. \nMarwick and T. Poell (Eds.) The SAGE handbook of social media  (pp.\u00a091\u2013108). Sage.\nRogers, R. (2019). Doing digital methods . Sage.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nRogers, R. (2021) Marginalizing the mainstream: How social media privilege political \ninformation. Frontiers in Big Data . https://doi.org/10.3389/fdata.2021.689036.\nRogers, R. and Hagen, S. (2020). Epilogue: After the tweet storm. In R. Rogers \nand S. Niederer (Eds.) The politics of social media manipulation (pp.\u00a0253\u2013256). \nAmsterdam University Press.\nRogers, R. and Niederer, S. (Eds.) (2020). The politics of social media manipulation . \nAmsterdam University Press.\nRomm, T. and Stanley-Becker, I. (2019, December\u00a021). Facebook, Twitter disable \nsprawling inauthentic operation that used AI to make fake faces. Washington \nPost . https://www.washingtonpost.com/technology/2019/12/20/facebook-twitter-\ndisable-sprawling-inauthentic-operation-that-used-ai-make-fake-faces/.\nRosenblatt, K. (2020, October\u00a017). They can\u2019t vote, but they can meme: How these \nTikTokers are trying to get Biden elected. NBC News . https://www.nbcnews.\ncom/pop-culture/viral/they-can-t-vote-they-can-meme-how-these-TikTokers-\nn1243555.\nRoth, Y. and Pickels, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.\nSalen, K. and Zimmerman, E. (2004). Rules of play: Game design fundamentals . \nMIT Press.\nSalenger, M. [meredthsalenger]. (2020, March\u00a002). \u201cReal quick: How are Republicans \nlike Donald ok with 2% of people dying from coronavirus as if 2% is not a very \nhigh number. But when you discuss a 2 cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happened to \nthem\u201d [tweet]. https://twitter.com/meredthsalenger/status/1234337053.\nSchellewald, A. (2021). Communicative forms on TikTok: Perspectives from digital \nethnography. International Journal of Communication, 15 , pp.\u00a01437\u20131457.\nScheufele, D. A. and Krause, N. M. (2019). Science audiences, misinformation, and \nfake news. Proceedings of the National Academy of Sciences , 116(16), pp.\u00a07662\u20137669. \nhttps://doi.org/10.1073/pnas.1805871115.\nbib liogra Phy 231\nSchmitt, C. (2005). Political theology: Four chapters on the concept of sovereignty . \nUniversity of Chicago Press.\nSchwartz, O. (2018, December\u00a04). Are Google and Facebook really suppressing con -\nservative politics? The Guardian . https://www.theguardian.com/technology/2018/\ndec/04/google-facebook-anti-conservative-bias-claims.\nSearles, S. (2020, August\u00a04). Republican TikTok thinks \u201cRed Kingdom\u201d by Tech \nN9ne is their new hype song; We\u2019re laughing. The Pitch . https://www.thepitchkc.\ncom/republican-tik-tok-thinks-red-kingdom-by-tech-n9ne-is-their-new-hype-\nsong-were-laughing/.\nShane, T. (2020, December\u00a01). Searching for the misinformation \u201ctwilight zone.\u201d \nNieman Lab. https://www.niemanlab.org/2020/12/searching-for-the-misinfor -\nmation-twilight-zone/.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F. \n(2018). The spread of low-credibility content by social bots. Nature Communica -\ntions, 9 (1), p.\u00a04787. https://doi.org/10.1038/s41467-018-06930-7.\nShepherd, T., Harvey, A., Jordan, T., Srauy, S., and Miltner, K. (2015). Histories of \nhating. Social Media + Society. https://doi.org/10.1177/2056305115603997.\nShibutani, T. (1966). Improvised news: A sociological study of rumor . Ardent Media.\nShifman, L. (2012). An anatomy of a YouTube meme. New Media & Society , 14(2), \npp.\u00a0187\u2013203. https://doi.org/10.1177/1461444811412160.\nShirky, C. (2008). Here comes everybody . Penguin.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSilverman, C. and Alexander, L. (2016, November\u00a03). How teens in the Balkans \nare duping Trump supporters with fake news. Buzzfeed News . https://www.\nbuzzfeednews.com/article/craigsilverman/how-macedonia-became-a-global-\nhub-for-pro-trump-misinfo.\nSkopeliti, C. and John, B. (2020, March\u00a019). Coronavirus: How are the social media \nplatforms responding to the \u201cinfodemic\u201d? First Draft. https://firstdraftnews.\norg:443/latest/how-social-media-platforms-are-responding-to-the-coronavirus-\ninfodemic/.\nSmith Gale, S (2020, October\u00a06). U.S. election 2020: TikTok gets pulled into the \ncampaigns. BBC News . https://www.bbc.com/news/technology-54374710.\nSmith, R., Cubbon, S. and Wardle, C. (2020, November\u00a012). Under the surface: \nCovid-19 vaccine narratives, misinformation and data deficits on social media. \nFirst Draft. https://firstdraftnews.org/long-form-article/under-the-surface-\ncovid-19-vaccine-narratives-misinformation-and-data-deficits-on-social-media/.\n232  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nSommer, W. (2018). Instagram is the alt-right\u2019s new favorite haven. The Daily Beast . \nhttps://www.thedailybeast.com/instagram-is-the-alt-rights-new-favorite-\nhaven.\nSparktoro. (2021). Audience intelligence. https://sparktoro.com.\nStanley-Becker, I. (2020, August\u00a01). How the Trump campaign came to court \nQAnon, the online conspiracy movement identified by the FBI as a violent \nthreat. Washington Post . https://www.washingtonpost.com/politics/how-the-\ntrump-campaign-came-to-court-qanon-the-online-conspiracy-movement-\nidentified-by-the-fbi-as-a-violent-threat/2020/08/01/dd0ea9b4-d1d4-11ea-\n9038-af089b63ac21_story.html.\nStarbird, K. (2012). Crowdwork, crisis and convergence: How the connected crowd \norganizes information during mass disruption events [PhD].\nStarbird, K. (2017). Examining the alternative media ecosystem through the produc -\ntion of alternative narratives of mass shooting events on Twitter. In Proceedings \nof the 11th International AAAI Conference on Web and Social Media . AAAI Press. \nhttp:/ /faculty.washington.edu/kstarbi/Alt_Narratives_ICWSM17-CameraReady.\npdf.\nStarbird, K. (2020, April\u00a027). How to cope with an infodemic. Brookings. https://\nwww.brookings.edu/techstream/how-to-cope-with-an-infodemic/.\nStarbird, K., Spiro, E., Edwards, I., Zhou, K., Maddock, J., and Narasimhan, S. (2016). \nCould this be true? I think so! Expressed uncertainty in online rumoring. In \nProceedings of the 2016 CHI Conference on Human Factors in Computing Systems , \npp.\u00a0360\u2013371. https://doi.org/10.1145/2858036.2858551.\nSullivan, D. (2004, April\u00a024) Google in controversy over top-tanking for anti-Jewish \nsite. Search Engine Watch . https://www.searchenginewatch.com/2004/04/24/\ngoogle-in-controversy-over-top-ranking-for-anti-jewish-site/.\nSunstein, C. R. (2001). Echo chambers: Bush v. Gore, impeachment, and beyond. \nPrinceton University Press.\nSunstein, C. R. (2018). #Republic: Divided democracy in the age of social media . \nPrinceton University Press. https://doi.org/10.2307/j.ctv8xnhtd\nSystrom, K. (2014). 300 million Instagrammers sharing real life moments. Insta -\ngram Blog. https://about.instagram.com/blog/announcements/300-million-\ninstagrammers-sharing-real-life-moments.\nTarkov, A. (2012, June\u00a030). Journatic worker takes \u201cThis American Life\u201d inside out -\nsourced journalism. Poynter. https://www.poynter.org/reporting-editing/2012/\njournatic-staffer-takes-this-american-life-inside-outsourced-journalism/.\nTate, R. (2009, 19 Nov.). Twitter\u2019s new prompt: A linguist weighs in . Gawker . ht tps://\ngawker.com/5408768/twitters-new-prompt-a-linguist-weighs-in.\nTeitelbaum, B.R. (2020). War for eternity: The return of traditionalism and the rise \nof the populist right . Penguin.\nbib liogra Phy 233\nTiffany, K. (2020, August\u00a018). How Instagram aesthetics repackage QAnon. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2020/08/\nhow-instagram-aesthetics-repackage-qanon/615364/.\nTrielli, D. and Diakopoulos, N. (2019). Search as news curator: The role of Google \nin shaping attention to news information. Proceedings of the 2019 CHI Con -\nference on Human Factors in Computing Systems \u2013 CHI \u201819 , 1\u201315. https://doi.\norg/10.1145/3290605.3300683.\nTuters, M. (2019). LARPing & liberal tears: Irony, idiocy & belief in the deep vernacular \nweb. In M. Fielitz and N. Thurston (Eds.) Post-digital cultures of the far right: Online \nactions and offline consequences in Europe and the U.S. (pp.\u00a037\u201348). Transcript.\nTuters, M. and Burton, A. (2021). The rebel yell: Toxic vox populism on YouTube. \nCanadian Journal of Communication . forthcoming.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nTuters, M. and OILab (2020). Esoteric fascism online: 4chan and the Kali Yuga. \nIn L.D. Valencia-Garc\u00eda (Ed.), Far-right revisionism and the end of history: Alt/\nhistories (pp.\u00a0287\u2013303). Routledge.\nTuters, M., Jokubauskait\u0117, E., and Bach, D. (2018). Post-truth protest: How 4chan \ncooked up the Pizzagate bullshit. M/C Journal , 21(3), Article\u00a03. https://doi.\norg/10.5204/mcj.1422.\nTwitter (2019a). Glorification of violence policy, Twitter Help Center. https://help.\ntwitter.com/en/rules-and-policies/glorification-of-violence.\nTwitter (2019b, October\u00a015). World leaders on Twitter: Principles & approach. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2019/worldleaders2019.\nTwitter (2020a, February\u00a07). Synthetic and manipulated media policy. Twitter. \nhttps://web.archive.org/web/20200207000218/https://help.twitter.com/en/\nrules-and-policies/manipulated-media.\nTwitter (2020b, April). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020c, May\u00a011). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020d, December\u00a016). COVID-19 misleading information policy. Twitter. \nhttps://web.archive.org/web/20201216200114/https://help.twitter.com/en/\nrules-and-policies/medical-misinformation-policy.\nTwitter (2021, January\u00a08). Permanent suspension of @realDonaldTrump. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/suspension.\nTynan, D. (2016, August\u00a024) How Facebook powers money machines for obscure polit -\nical \u201cnews\u201d sites. The Guardian . https://www.theguardian.com/technology/2016/\naug/24/facebook-clickbait-political-news-sites-us-election-trump.\n234  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nUN DGC. (2020, March\u00a031). UN tackles \u201cinfodemic\u201d of misinformation and cyber -\ncrime in COVID-19 crisis. UN Department of Global Communications. https://\nwww.un.org/en/un-coronavirus-communications-team/un-tackling-\u2019infodemic\u2019-\nmisinformation-and-cybercrime-covid-19.\nUnkel, J. and Haim, M. (2019). Googling politics: Parties, sources, and issue owner -\nships on Google in the 2017 German federal election campaign. Social Science \nComputer Review, 39 (5), pp.\u00a0844\u2013861. https://doi.org/10.1177/0894439319881634.\nUrman, A. and Katz, S. (2020). What they do in the shadows: Examining the far-right \nnetworks on Telegram. Information, Communication & Society , 1\u201320. https://doi.\norg/10.1080/1369118X.2020.1803946.\nUrquhart, C. (2013, January\u00a012). Here comes the sun flash mob cheers Spanish \nunemployment office. The Guardian . https://www.theguardian.com/world/2013/\njan/12/here-comes-the-sun-spanish-unemployment-office.\nuserleansbot. (n.d.). List of political subreddits used by userleansbot. Reddit. https://\nwww.reddit.com/user/userleansbot/comments/cfzho2/list_of_political_subred -\ndits_used_ by_userleansbot/.\nVaidhyanathan, S. (2019, July\u00a028). Why conservatives allege big tech is muzzling \nthem. The Atlantic . https://www.theatlantic.com/ideas/archive/2019/07/\nconservatives-pretend-big-tech-biased-against-them/594916/.\nVan Den Berg, E. (2019, July\u00a030). Opnieuw misser bij Forum voor Democratie: Per -\nsoonlijke advertentie Thierry Baudet offline gehaald. NPO3. https://www.npo3.\nnl/brandpuntplus/opnieuw-misser-bij-forum-voor-democratie-persoonlijke-\nadvertentie-thierry-baudet-offline-gehaald.\nVan der Linden, S., Panagopoulos, C. and Roozenbeek, J. (2020). You are fake news: \nPolitical bias in perceptions of fake news. Media, Culture & Society , 42(3). ht tps://\ndoi.org/10.1177/0163443720906992.\nVan Driel, L. and Dumitrica, D. (2021). Selling brands while staying \u201cauthentic\u201d: \nThe professionalization of Instagram influencers. Convergence , 27(1), pp.\u00a066\u201384. \nhttps://doi.org/10.1177/1354856520902136.\nVenturini, T. (2019) From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin, and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights \n(pp.\u00a0123\u2013144). Routledge.\nVenturini, T. and Latour, B. (2010). The social fabric: Digital footprints and quali-\nquantitative methods. Proceedings of Futur En Seine 2009: The Digital Future of \nthe City . Futur en Seine 2009.\nVijay, D. and Gekker, A. (2021). Playing politics: How Sabarimala played out \non TikTok. American Behavioral Scientist , 65(5), pp.\u00a0712\u2013734. https://doi.\norg/10.1177/0002764221989769.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nbib liogra Phy 235\nVou\u00e9, P., De Smedt, T., and De Pauw, G. (2020). 4chan & 8chan embeddings. \nArXiv:2005.06946 [Cs] . http://arxiv.org/abs/2005.06946.\nWahl-Jorgensen, K. (2019). Emotions, media and politics. Polity.\nWakabayashi, D. (2018, September\u00a05). Trump says Google is rigged, despite its \ndenials. What do we know about how it works? New York Times . https://www.\nnytimes.com/2018/09/05/technology/google-trump-bias.html.\nWardle, C. (2016, November\u00a018). 6 types of misinformation circulated this election \nseason. Columbia Journalism Review . https://www.cjr.org/tow_center/6_types_\nelection_fake_news.php.\nWardle, C. (2017, February\u00a016). Fake news: It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nWarzel, C. (2021, November\u00a011). Facebook\u2019s vast wasteland. The Atlantic Monthly . \nhttps://newsletters.theatlantic.com/galaxy-brain/618ad9942e822d00205a26b3/\nfacebooks-vast-wasteland/.\nWendling, M. (2018). Alt-Right: From 4chan to the White House . Pluto Press.\nWikipedia contributors. (2020). Killian documents controversy. Wikipedia: The \nFree Encyclopaedia . https://en.wikipedia.org/w/index.php?title=Killian_docu -\nments_authenticity_issues&oldid=962589844.\nWilkinson, W.W. and Berry, S.D. (2020). Together they are Troy and Chase: Who \nsupports demonetization of gay content on YouTube? Psychology of Popular \nMedia , 9(2). https://doi.org/10.1037/ppm0000228.\nWillaert, T., Van Eecke, P., Beuls, K., and Steels, L. (2020). Building social media \nobservatories for monitoring online opinion dynamics. Social Media + Society , \n6(2). https://doi.org/10.1177/2056305119898778.\nWillaert, T., Van Eecke, P., Van Soest, J., and Beuls, K. (2021). A tool for tracking the \npropagation of words on Reddit. Computational Communication Research , 3(1), \npp.\u00a0117\u2013132. https://doi.org/10.5117/CCR2021.1.005.WILL.\nWoods, A. (2019). Cultural Marxism and the cathedral: Two alt-right perspec -\ntives on critical theory. In C.M. Battista and M.R. Sande (Eds.), Critical theory \nand the humanities in the age of the alt-right (pp.\u00a039\u201359). Springer. https://doi.\norg/10.1007/978-3-030-18753-8_3.\nYong, E. (2020, April\u00a029). Why the coronavirus is so confusing. The Atlantic . \nhttps://www.theatlantic.com/health/archive/2020/04/pandemic-confusing-\nuncertainty/610819/.\nYouTube (2019, January\u00a025). Continuing our work to improve recommenda -\ntions on YouTube. YouTube Blog. https://blog.youtube/news-and-events/\ncontinuing-our-work-to-improve/.\nYouTube (2020). COVID-19 medical misinformation policy\u2014YouTube Help. https://\nsupport.google.com/youtube/answer/9891785?hl=en.\n236  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nytdl-org (2021, February\u00a01). Youtube-dl . Youtube-Dl: Download Videos from YouTube \n(and More Sites). http://ytdl-org.github.io/youtube-dl/.\nZannettou, S., Caulfield, T., Blackburn, J., De Cristofaro, E., Sirivianos, M., Stringhini, \nG., and Suarez-Tangil, G. (2018). On the origins of memes by means of fringe web \ncommunities. ArXiv:1805.12512 [Cs] . http://arxiv.org/abs/1805.12512.\nZannettou, S., Caulfield, T., De Cristofaro, E., Kourtelris, N., Leontiadis, I., Sirivianos, \nM., Stringhini, G., and Blackburn, J. (2017). The web centipede: Understanding \nhow web communities influence each other through the lens of mainstream \nand alternative news sources. Proceedings of the 2017 Internet Measurement \nConference IMC\u201917  (pp.\u00a0405\u2013417). ACM. https://doi.org/10.1145/3131365.3131390.\nZulli, D. and Zulli, D. J. (2020). Extending the internet meme: Conceptualizing \ntechnological mimesis and imitation publics on the TikTok platform. New Media \n& Society . https://doi.org/10.1177/1461444820983603.\n Index\nPage numbers in italics  refer to figures and tables\naccounts\nInstagram verified\u2003159\nproblematic\u200320, 53, 62, 87, 95, 97\u201398purge of\u200383\u201384, 86Republican party\u200321, 144, 150\u201351verified\u2003141, 150 , 155 , 159\nactive audience approach, to content \nmoderation\u200326\nactivity, on social media\u200377, 84\u201386\nengagement and\u200326, 95popularity and\u2003201\nactivity, user\u200398\u2013100AIN see  alternative influence network\nalgorithms\u200335, 43\n\u201cserious queries\u201d and\u200324\u201325\nalternative influence network (AIN)\u200317, 68, \n210alt-right and\u200373deplatforming and\u200373\u201375mainstream and\u200374\nalt-right\u2003165\u201366\nAIN and\u200373deplatforming and\u2003141Facebook and\u200349memes and\u2003167Yiannopoulos and\u2003168\nambivalent content\nearnest compared to\u2003139, 142, 157on Instagram\u200320\u201321, 139mainstreaming of\u2003201TikTok and\u2003198\u201399\nambivalent critique\u2003188\nremix as\u200315, 189, 195, 196 , 199\nanalysis\ncross-platform\u20037\u201311, 14, 24geographical\u2003152Instagram\u2003151\u201352 , 155\u201356, 157\nlinguistic\u2003173namespace\u2003144\u201345, 147 , 149, 150 , 158\nquali-quantitative\u2003179\u201380user activity\u2003142\u201343, 158\nAniston, Jennifer\u2003154anonymity\nof 4chan\u20031694chan and Reddit and\u200310, 75\nartificial amplification, of followers\u2003139\u201340, \n158\u201359Instagram and\u2003150\u201353\nattacks\non candidates\u200388\u201389, 93far-right terrorist\u2003171using opponent hashtags\u200385, 90, 95, 97, \n158audience tweets\u2003125 , 126 , 127, 129\nauthoritative sources compared to\u2003116\u201321\nauthenticity\u2003103\nof behaviors\u200313, 18\u201319of followers\u200321, 141, 143, 158\nauthoritative sources\naudience tweets compared to\u2003116\u201321consensus from\u2003113, 120\u201322content moderation and\u2003115on COVID-19\u2003128\u201329hydroxychloroquine and\u2003123, 128personalization and\u2003111Trump, D., as\u2003110\u201311Twitter as\u2003112, 114\u201315, 128\nbacklash\ncontent moderation and\u2003208political\u200351, 90\nBannon, Steve\u2003168, 177Barnidge, M.\u200386\u201389Bass Da Da Da (viral sound)\u2003193, 194Bauman, Zygmunt\u200350\u201351Benkler, Y.\u200368, 143, 168\nmedia ecologies of\u200377\nBerger, J.\u200390\u201391bias\u200362\nideology and\u200378liberal\u200311, 35politics and\u2003112\nBiden, Joe\u200315\u201316, 36, 58, 74 see also  candidates, \npresidential; presidential elections, U.S.follower authenticity and\u200321hyperpartisan sources and\u200362\u201363influencers and\u2003154Instagram and\u2003144\u201345keyword data for\u200398 , 101\nObama, B., and\u2003149TikTok and\u2003190, 193, 194 , 196\u201397, 201\n\u201cBiden and his sister\u201d (TikTok video)\u2003197\u201cbig data\u201d\u200348, 148bots\u200313, 84\u201386 see also  problematic accounts\nBreitbart News\u2003178\nalt-right and\u2003166comment sections of\u2003168\u201370, 173\u201374 , 177\n4chan compared to\u2003165, 171, 174Trump, D., and\u2003168, 170, 176\u201377vernacular crossover to\u2003165\u201367, 169\u201371, \n173, 176\nvocabulary propagation and\u2003172, 173\u201374 , \n177\nBruns, A.\u200388\u201389Buzzfeed News  (website)\u20037, 19, 51, 61\nBuzzsumo\u200361\u201362\n238  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\ncandidates, presidential\u2003 61, 192 see also  \npresidential elections, U.S.\nattacks on\u200388\u201390, 93influencers and\u2003153, 154Instagram and\u2003141\u201345, 146\u201348 , 150\u201352\nparody of\u2003200\u2013201queries on\u200354\u201360supporters of\u200315, 85, 88\u201389\nCapitol riots\u20038, 18, 103\nParler and\u2003177\u201378purge of accounts after\u200383\u201384, 86Trump, D., and\u200385\ncategorization\nof content\u200316, 71\u201373, 156\u201357users and\u2003103, 151 , 158\nof websites and sources\u200322\u201323, 38 , 43\u201344, \n53, 86, 92, 102\nCDC see  Centers for Disease Control\ncelebrities see  influencers\nCenter for Countering Hate\u2003140Centers for Disease Control (CDC), COVID-19 \nand\u2003115, 118\nchoice, freedom of\u200350\u201351civic engagement\u200315\nludic\u2003188, 192\u201393\nclaims\nCOVID-19 and\u2003111\u201313, 117\u201318 , 121, 122\u201323, \n129\u201331\nDemocratic party and\u2003167, 200\nClinton, Hillary\u2003149coding schema\u200377, 78\ncontent analysis and\u2003142\u201343for sources\u200343, 68, 130\u201331for videos\u200371, 72 , 202\u20133\ncollective sensemaking\u2003112\u201313comment sections, of Breitbart News\u2003168\u201370, \n173\u201374 , 177\ncommunication\nhyperpartisanship and\u200391ideology and\u200369, 73, 88political\u2003189\u201390\nconsensus, from authoritative sources\u2003111, \n113, 120\u201322\nconservative sources\nhyperpartisanship and\u2003 58\u201360 , 208\nliberal compared to\u200323, 33\u201335, 38, 39\u201340 , 43\nin search results\u200340 , 43\nconspiracy theories\u2003140\nof COVID-19\u200351, 118, 120, 123debunking\u2003153extreme speech and\u2003175\u201cfake news\u201d and\u20031895G and\u2003147\u2013484chan and\u2003172\ncontent analysis\ncoding schemas for\u2003142\u201343on Instagram\u2003155\u201356, 157 , 158\ncontent moderation\u20039, 131, 207\nactive audience approach to\u200326authoritative sources and\u2003115backlash and\u2003208in Europe\u200325\u201326Facebook and\u200319\u201320, 48, 50, 210by Google Web Search\u200335on Instagram\u2003145labor of\u200325, 209partisanship and\u200311policies for\u200369problematic information and\u200312\u201313, 110, \n112\u201313, 209\u201310\non Reddit and 4chan\u200369Trump, D., and\u200326, 146on Twitter\u2003109\u201310, 113\u201314, 121\u201323\u201cwisdom of the crowd\u201d and\u200312, 23, 26\ncoronavirus see  COVID-19\nCOVID-19\u200312, 124 , 209\nauthoritative sources on\u2003128\u201329CDC and\u2003115, 118\nclaims about\u2003111\u201313, 117\u201318 , 121, 122\u201323, 129\u201331\nconspiracy theories of\u200351, 118, 120, 123divisiveness and\u2003140earnest content about\u2003142, 147, 153, 154exceptional information state and\u200325Instagram and\u2003144policies and\u2003110, 129problematic information and\u2003112sources on\u2003135\u201336transmission and treatment of\u2003109, 115, \n116\u201321, 117\u201318, 120\u201321, 125\u201327 , 130, 137\u201338\nTrump, D., and\u2003114\u201315Twitter mentions of\u2003116\u201321, 125\u201327uncertainty and\u2003111\ncreative expression, on TikTok\u200315\u201316, 200\u2013201credibility, media and\u200349crisis, of \u201cfake news\u201d\u200311, 49, 140critique, ambivalent\u2003188cross-platform analysis\u20037\u201310, 14, 24\nmedium-specificity in\u200311\nCrowdTangle\u200321, 155\u201356, 159\u201360curation, of information\u200322\u201325, 115, 209\nmethodology and\u200343, 61, 101, 102\nDACA see  Deferred Action for Childhood \nArrivals\n\u201cdark participation\u201d\u2003172data\u20038, 9, 13, 102, 179\u201380\nbig\u200348, 148from 4chan and Breitbart News\u2003178keyword\u200398 , 101\npolitical discourse and\u2003176from Reddit and 4chan\u200378\u201379TikTok and\u2003202\u20133\nDeadville, James\u2003191debates\nCOVID-19 and\u2003121deplatforming\u2003207\u20138, 211freedom of choice and\u200350\u201351political\u2003101, 144, 167\nin de X 239\ndebunking\nconspiracy theories\u2003153\nSnopes and\u2003196, 200Twitter and\u2003123, 128by WHO\u2003115\n\u201cdeep vernacular web\u201d\u200369, 167\non Reddit and 4chan\u200367\u201368\nDeferred Action for Childhood Arrivals \n(DACA)\u200395, 96 , 100 , 102\nDemocratic party\nclaims about\u2003167, 200keywords for\u200392\u201393, 94 , 98\u201399 , 101, 102\ndemocratization, of news, Twitter and\u200387\u201388demonetization\u200313demotion, on TikTok\u2003210Denver Guardian\u200320, 53deplatforming\u200313, 17, 69, 141, 207\u20138, 211\nAIN and\u200373\u201375alt-right and\u2003141QAnon conspiracies and\u200386, 172Trump, D.\u2003178Twitter and\u200318, 83\ndigital methods\u200376, 101\u20134, 128\u201331, 155\u201357\nfollowers and\u2003158\u201359hostnames and\u200371, 77, 78 , 79\nkeywords and\u2003159\u201360namespace analysis and\u2003144\u201345, 147 , 149, \n150, 158\nsource-distance methodology\u200342\u201344user activity analysis and\u2003142\u201343, 158\ndiscourse, political\u2003189, 201\u20132\ndata and\u2003176extreme\u2003171, 175\u201376polarization in\u2003167of Trump, D.\u2003166U.S. presidential elections and\u200386, 169\u201370\ndisinformation\u200316, 20, 114, 122, 140diversification, polarization compared \nto\u200388\u201389\ndivisive content\u200321, 139\nCOVID-19 and\u2003140on Instagram\u2003141\u201342, 145non-divisive compared to\u2003156, 157 , 158\nsocial issues and\u200334\u201335, 58, 147\u201348\ndocumentary video, problematic information \nand\u200374\u201375\n\u201cdocumenting,\u201d on TikTok\u2003193\u201395\u201cDonald Trump and The Pope\u201d (TikTok \nvideo)\u2003 197\nearnest content\nambivalent compared to\u2003139, 142, 157COVID-19 and\u2003147, 154influencers and\u200321, 153\u201354on Instagram\u2003143, 145\necho chambers\u200388\u201390ecologies\ninformation\u200367\u201370media\u200377, 168platform\u200375\u201376video\u200371\u201372\neditorial epistemologies\u2003209\nplatform criticism and\u200324\u201327social issues and\u2003210Twitter and\u200326\u201327\nelections research\u200335, 38, 40 , 42\u201343 see also  \npresidential elections, U.S.\nemotive news, factual compared to\u200391engagement\u200353, 200\nactivity and\u200326, 95civic\u200315on Facebook\u200348\u201349, 61\u201362on Instagram\u2003144, 156on TikTok\u2003188\u201389, 202on Twitter\u200384, 87\nepistemologies, editorial\u200324\u201327, 209\u201310An establishment conservative\u2019s guide to the \nalt-right  (Yiannopoulos)\u2003168\nEurope, content moderation in\u200325\u201326event-commentary\u2003188, 201\n\u201cfresh\u201d content and\u2003189\u201390\nexceptional information state\u200324\nCOVID-19 and\u200325editorial epistemology and\u200327\nexpertise, in search results, relevance \ncompared to\u200341\nextreme speech\nconspiracy theories and\u2003175on 4chan\u2003170\u201371neologisms and\u2003175\u201376right-wing vocabulary of\u2003172\u201373\nFacebook\nalt-right media and\u200349bots and trolls on\u200313, 49content moderation and\u200319\u201320, 48, 50, 210engagement on\u200348\u201349, 61\u201362\u201cfake news\u201d and\u200319, 47, 52\u201357Haugen and\u2003209hyperpartisan sources and\u200348, 51, 58\u201360 , \n62\u201363\nproblematic sources and\u2003207\u20138QAnon content and\u2003207U.S. presidential elections and\u200352\u201360 , \n61\u201362, 208\nwhistle-blowing and\u2003209\nfact-checking\u200325\u201326, 50, 146 , 209\nfactual news, emotive compared to\u200391fake accounts see  problematic accounts\n\u201cfake news\u201d\u200312, 18, 48, 63\nconspiracy theories and\u2003189crisis of\u200311, 49, 140Facebook and\u200319, 47, 52\u201357\u201cfalse news\u201d compared to\u200349, 53, 208\u201cjunk news\u201d and\u200349\u201351mainstream news websites compared \nto\u200352\u201356 , 58\nSilverman and\u20037, 19\u201320, 51, 61, 209\n240  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\n\u201cfalse news\u201d\u200319\u201320, 62\n\u201cfake news\u201d compared to\u200349\u201351, 53, 208\nFrance and\u200325\nfeatured snippets, in Google Web Search\u200334filter bubbles\u200388\u201390\npersonalization and\u200311\nFirst Draft News\u20037\u20138, 1995G (technology)\u200312 n. 1\nconspiracy theories and\u2003147\u201348COVID-19 and\u200312\nflash mobs\u2003193follower factories\u200313, 141followers\u2003150\nartificial amplification of\u2003139\u201340, 158\u201359authenticity of\u200321, 141, 143, 158digital methods and\u2003158\u201359geographical analysis of\u2003152on Instagram\u2003151\u201352\n4chan\u2003173 see also  Reddit, 4chan and\nanonymity of\u2003169Breitbart News compared to\u2003165, 171, 174content moderation on\u2003210data from\u200378\u201379, 178extreme speech on\u2003170\u201371memes on\u2003175\u201376QAnon conspiracies and\u2003166\u201367vernacular crossover from\u2003165, 170\u201371, 176vocabulary propagation and\u2003172, 173\u201374 , \n177\n4chan Capture and Analysis Toolkit\u200377Fox News , Hannity and\u200362\nFrance, \u201cfalse news\u201d and\u200325Francis, pope\u2003196, 197fraud, voter\u2003190, 199freedom, of choice\u200350\u201351\u201cfresh\u201d content\u2003199\nevent-commentary and\u2003189\u201390\u201cstale\u201d social media compared to\u2003188\nfringe activities\u200317, 167\nmainstream compared to\u200314, 23, 85, 187TikTok and\u2003200web history and\u200312\nGabbard, Tulsi\u200376Gates, Kevin\u2003153geographical analysis, of followers\u2003152Germany, search results in\u200338\u201cgiving a speech,\u201d on TikTok\u2003193\u201395, 200Google Web Search\u200333\ncontent moderation by\u200335featured snippets of\u200334imbalances in\u200338\u201339official sources in\u200336personalization in\u200342polarization and\u200335problematic information in\u200322\u201323, 34\u201336, \n36\u201338\nunique sources in\u200339, 40\u201341U.S. presidential elections and\u200336\u201341gradient classification\u200361\u201363Grande, Ariana\u2003154\u201cGreat Again\u201d (song) (Taylor)\u2003191Green New Deal, Twitter and\u200397\nHagen, S.\u2003198\u201399\n\u201chaystack-to-needle\u201d method of\u200368, 77\nHanks, Tom\u2003153\nHannity, Sean\u200362Harris, Kamala\u2003149, 154\nTikTok and\u2003193, 194\nHarvard Kennedy School Misinformation \nReview \u20038\nhashtags\u200315, 103, 203 see also  keywords\nattacks using\u200385, 90, 95, 97, 158\nHaugen, Frances\u2003209\u201chaystack-to-needle\u201d method\u200368, 77history, web\u200311, 23\nfringe contributions and\u200312\n\u201cHollow heads\u201d (TikTok video)\u2003194hostnames, digital methods and\u200371, 77, 78 , 79\nhydroxychloroquine\u2003 118\nauthoritative sources and\u2003123, 128polarization and\u2003117\nHypeAuditor\u200321, 158, 160hyperpartisanship\u200310, 36, 39, 91\nBiden and\u200362\u201363conservatism and\u200358\u201360 , 208\nFacebook and\u200320, 48, 51(hyper)partisanship and\u2003 84, 86, 92\nmainstream sources and\u200389problematic sources and\u200349\u201351, 86\u201387on TikTok\u2003199Twitter and\u2003209\nideology\u200349, 188, 208\nalt-right\u2003168bias and\u200378communication and\u200369, 73, 88\nimbalances, in Google Web Search\u200338\u201339imposter websites\u200320, 53, 62inauthentic behaviors\u200313, 18\u201319, 141India, followers from\u2003152\u201353influencers\ndivisive content and\u2003141\u201342earnest content and\u200321, 153\u201354Instagram and\u200313\u201314, 144, 154 , 159\nsocial issues and\u2003153\u201354, 154\ninformation\u2003142\ncuration of\u200322\u201325, 115, 209problematic\u20039\u201310, 42, 49, 103\u20134\ninformation ecologies\n\u201cjunk news\u201d and\u200370partisanship in\u200368during U.S. presidential elections\u200367\u201369\nInstagram\nambivalent content and\u200320\u201321, 139artificial amplification on\u2003150\u201353Biden and\u2003144\u201345\nin de X 241\ncontent analysis and\u2003155\u201356, 157 , 158\ndivisive compared to earnest content \non\u2003141\u201342, 145\nfollower analysis on\u2003151\u201352\ninfluencers on\u200313\u201314, 144, 154 , 159\nnamespace analysis and\u2003144\u201345, 147 , 149, \n150, 158\npolarization and\u2003139, 141\u201343, 156\u201358presidential candidates and\u2003141\u201345, \n146\u201348 , 150\u201352\nsocial issues and\u2003148 , 155\nTrump, D., and\u2003143\u201344, 146 , 149, 152, 154\nTrump, D., Jr., and\u2003143, 149U.S. presidential elections and\u200320\u201321, \n139\u201340, 143\nverified accounts on\u2003141, 150 , 155 , 159\nissues\ndivisive\u200334\u201335, 58, 147\u201348political\u200395, 96 , 100 , 102\nsocial\u2003 54\u201360 , 61, 141\u201342\nin U.S. presidential elections\u200333\n\u201cIs this what happens\u2026?\u201d (TikTok video)\u2003194\u201cI voted for a man named Donald J. Trump\u201d \n(TikTok video)\u2003191\nJack, Caroline, problematic information \nand\u200342, 84\nJenkins, Henry\u2003195Jimmy Kimmel Live! (television show)\u2003196, 197Jokubauskaite, E., \u201chaystack-to-needle\u201d method \nof\u200368, 77\n\u201cjunk news\u201d\u200377\u201378\n\u201cfake news\u201d and\u200349\u201351information ecologies and\u200370Netherlands and\u200351problematic information and\u2003208\nKardashian, Kim\u2003153, 154Kennedy, Robert F. Jr., Instagram and\u2003148keywords\nDemocrat and Republican\u200392\u201393, 94 , \n98\u201399 , 101, 102\ndigital methods and\u2003159\u201360\n\u201cKings & Queens\u201d (song)\u2003197, 198#KnowTheFacts\u2003114, 123, 128\nlabor, of content moderation\u200325, 209\n\u201cThe left lies\u201d (TikTok video)\u2003194\u201cLet\u2019s start a chain of women for Trump\u201d \n(TikTok video)\u2003198\nLewis, Rebecca\u200373liberalism\u2003 194\nbias and\u200311, 35voters and\u2003175\nliberal sources, conservative compared to\u200323, \n33\u201335, 38, 39\u201340 , 43\nlinguistic analysis\u2003173local news websites\u200340\u201341, 44ludic civic engagement\u2003188, 192\u201393mainstream activities\nAIN and\u200374ambivalence and\u2003201fringe compared to\u2003187harmful vernacular and\u2003176\nmainstreaming the fringe\u200314, 23, \n173\u201374, 179, 211 see also  marginalizing the \nmainstream\n4chan and Breitbart News and\u2003169\nmainstream sources\u200337, 43\u201344\n\u201cfake news\u201d websites compared to\u200352\u201356 , \n58\nfringe media and\u200385, 167hyperpartisan sources compared to\u200389problematic sources compared to\u200392, \n93\u201394 , 96\u201397\nmarginalizing the mainstream\u20037, 14, 23\u201324, \n211\nMax, Ava\u2003197, 198media\ncredibility and\u200349ecologies of\u200377, 168labeling of\u200318\u201320, 22, 38, 43, 47\u201351, 62, \n92, 102\npersonalization and\u2003211TikTok and\u2003199during U.S. presidential elections\u200385\nmedia, social see  specific topics\nMedicare\u2003 96, 100 , 102\nU.S. presidential elections and\u200395\nmedium-specificity, in cross-platform \nanalysis\u200311\nmemes\u200316, 166, 175\u201376\nalt-right and\u2003167news content and\u2003188\nmethodology\u2003178, 180, 203\nBuzzsumo in\u200361\u201362cross-platform analysis and\u20037\u201311, 14, 24CrowdTangle in\u200321, 155\u201356, 159\u201360curation of information and\u200343, 61, 101, 102digital methods and\u200376\u201379, 101\u20134, 128\u201331, \n155\u201360\n4chan Capture and Analysis Toolkit in\u200377gradient classification in\u200361\u201363\u201chaystack-to-needle\u201d\u200368, 77HypeAuditor and\u200321, 158, 160media labeling and\u200318\u201320, 22, 38, 43, \n47\u201351, 62, 92, 102\nnatural language processing in\u2003112, 179observational periods in\u200379pink slime websites and\u200377source-distance\u200342\u201344TikTok-scraper and\u2003202\u20133Twitter Capture and Analysis Toolkit \nand\u2003102, 129\nuserleansbot in\u200376\u201377Wikipedia in\u200322, 43, 62, 129\u201330YouTube Data Tools and\u200379\nMilkman, K. L.\u200390\u201391\n242  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nMilner, R. M.\u2003198\u201399\nmoderation, of content\u20039, 131, 207music, during U.S. presidential \nelections\u2003191\u201392\nnamespace analysis, on Instagram\u2003144\u201345, \n147, 149, 150 , 158\nNational Institutes of Health (NIH)\u2003111, \n114\u201315, 117\nNational Rifle Association, Instagram \nand\u2003144, 148, 153\nnatural language processing\u2003112, 179\u201cneedle-to-haystack\u201d method\u200377neologisms\nextreme speech and\u2003175\u201376right-wing vocabulary and\u2003174\u201376\nNetherlands, \u201cjunk news\u201d and\u200351news\nfake\u200312, 18, 48, 50false\u200319\u201320, 62junk\u200377\u201378local\u200340\u201341, 44memes and\u2003188partisanship and\u200370viral\u200390, 91\nNIH see  National Institutes of Health\nnon-divisive content, divisive compared \nto\u2003156, 157 , 158\nObama, Barack\u2003154, 195\nBiden and\u2003149\nObama, Michelle\u2003149, 154observational periods\u200379official source websites\u200334, 44\nin Google Web Search\u200336special interest compared to\u200335\nO\u2019Hara, K.\u200389\npandemic see  COVID-19\nParler\u2003171\nCapitol riots and\u2003177\u201378\nparody\nof candidates\u2003200\u2013201\nTikTok and\u200314\u201316, 192, 195\u201396, 198\u201399\nparticipation\u2003188\ndark\u2003172politics and\u2003195, 201pseudonyms and\u200369\n\u201cpartisan duetting and stitching,\u201d on \nTikTok\u2003197\u201398\npartisanship\u2003 78, 103\u20134 see also  \nhyperpartisanshipcontent moderation and\u200311in information ecologies\u200368news websites and\u200370Reddit and 4chan and\u200371Twitter and\u200319userleansbot and\u200376\u201377\nPeacock, C.\u200386\u201389personalization\nauthoritative sources and\u2003111filter bubbles and\u200311in Google Web Search\u200342media and\u2003211\nPfizer vaccine, for COVID-19\u2003115Phillips, W.\u2003198\u201399pink slime websites\u200320, 62\nmethodology and\u200377U.S. presidential elections and\u200316\u201317\nplatforms\u200317\nbased in U.S.\u200310, 67criticism of\u200323\u201324cross-platform analysis of\u20037\u201310, 14, 24ecologies of\u200375\u201376rules of\u200318, 128, 207\n\u201cplayful political performance,\u201d on Tik-\nTok\u2003189\u201391, 194\u201395, 199\u2013200\npolarization\ndiversification compared to\u200388\u201389Google Web Search and\u200335hydroxychloroquine and\u2003117Instagram and\u2003139, 141\u201343, 156\u201358TikTok and\u2003188, 201on Twitter\u200390, 92, 101in U.S.\u2003167, 169\npolicies\nBreitbart News\u2003178content moderation\u200369COVID-19 and\u2003110, 129on problematic information\u2003123Twitter\u2003111, 124 , 128, 208\npolitical debates\u2003101, 144, 167political information environment, during U.S. \npresidential elections\u200310\npoliticization\n\u201cfake news\u201d and\u200348, 58, 63liberal bias and\u200311\npolitics\u2003173, 189\u201390\nbacklash and\u200351, 90bias and\u2003112participatory\u2003195, 201search results and\u200322\u201323spectrum of\u200311, 19, 89on Twitter\u200383, 95, 96 , 100 , 102, 102\nunrest in U.S. of\u200335\npopularity, on TikTok\u2003201\u20132presidential elections, U.S.\u200336, 83, 165\ndata and\u2003178exceptional information state and\u200325extreme speech during\u2003170\u201371Facebook and\u2003 52\u201360 , 61\u201362, 208, 209\nGoogle Web Search results and\u200322, 36\u201341information ecologies during\u200367\u201369Instagram and\u200320\u201321, 139\u201340, 143issues in\u200333\u201cjunk news\u201d and\u200370media during\u200385, 168, 202Medicare and\u200395\nin de X 243\nmusic during\u2003191\u201392\npink slime websites and\u200316\u201317political discourse and\u200386, 169\u201370political information environment \nduring\u200310\nproblematic information and\u2003199Reddit and 4chan and\u200376research into\u200335, 38, 40 , 42\u201343\nTikTok and\u2003187\u201389, 190, 1952016\u200316\u201320, 47\u201348, 51, 52 , 53, 62\u201363, 69, 86, \n166, 168\u201376\n2020\u20039, 47, 48, 68, 87, 172, 176\u201377Twitter and\u200317\u201319, 85\u201387voters and\u2003 154, 190\nprevention, of COVID-19\u2003126\u201327 , 130, 137\u201338\nproblematic accounts\u200387, 95, 97\u201398\nimposter websites\u200320, 53, 62\nproblematic information\u20039\u201310, 42\u201343, 49, \n103\u20134content moderation and\u200312\u201313, 110, 112\u201313, \n209\u201310\nCOVID-19 and\u2003112curation and\u200322\u201325disinformation as\u200316, 20, 114, 122, 140documentary video and\u200374\u201375in Google Web Search\u200322\u201323, 34\u201336, \n36\u201338\non Instagram\u2003140\u201cjunk news\u201d and\u2003208policies on\u2003123sources for\u200384, 104Twitter and\u200318, 84\u201387, 110U.S. presidential elections and\u2003199\nproblematic sources\u200384, 91, 104\nFacebook and\u2003207\u20138hyperpartisanship and\u200349\u201351, 86\u201387mainstream sources compared to\u200392, \n93\u201394 , 96\u201397\nTwitter and\u200383\nprogressive sources see  liberal sources, \nconservative compared to\npseudonyms\u200369, 75purge, of accounts\u200383\u201384, 86\nQAnon conspiracies\u2003140\ndeplatforming and\u200386, 172\nFacebook and\u20032074chan and\u2003166\u201367on TikTok\u2003199\u2013200\nquali-quantitative analysis\u2003179\u201380\nRatajkowski, Emily\u2003153\nReddit, 4chan and\u200370\nanonymity and\u200310, 75banned subreddits and\u200373\u201375content moderation on\u200369data from\u200378\u201379\u201cdeep vernacular web\u201d on\u200367\u201368partisanship and\u200371pseudonyms and\u200369, 75U.S. presidential elections and\u200376YouTube links on\u200316\u201317, 68, 71, 72 , 73\u201374\n\u201cRed Kingdom\u201d (song)\u2003192Reider, Bernhard, YouTube Data Tools of\u200379relevance, in search results, expertise \ncompared to\u200341\nremix\u2003173, 198\nas ambivalent critique\u200315, 189, 195, 196 , 199\nRepublican keywords\u200392\u201393, 94, 98\u201399 , 101, 102\nRepublican party\naccounts of\u200321, 144, 150\u201351AIN and\u200373attacks on\u200393, 97Instagram and\u2003150\u201352\nretweets\u200326, 84, 101\u20133, 131 see also  Twitter\nright-wing vocabulary\u2003172\u201373, 173\u201374 , 177, 180 \nsee also  alt-right\nneologisms of\u2003174\u201376\nThe Rock\u2003154\nSanders, Bernie see also  candidates, presiden -\ntial; presidential elections, U.S.\ndivisive content and\u2003145, 146Instagram and\u2003144, 149TikTok and\u2003190, 201\nSchmitt, Carl\u2003115search results\u200322\u201323, 37 see also  Google Web \nSearchconservative compared to liberal sources \nin\u200323, 33\u201335, 38, 39\u201340 , 43\nrelevance and expertise compared in\u200341in U.S. compared to Germany\u200338U.S. presidential elections and\u200322, 36\u201341\nsensemaking, collective\u2003112\u201313\u201cserious queries,\u201d algorithms and\u200324\u201325Silverman, Craig\u200318, 208\nBuzzfeed News  article by\u20037, 51, 61\n\u201cfake news\u201d and\u20037, 19\u201320, 51, 61, 209\nSnoop Dogg\u2003149, 154Snopes, debunking and\u2003196, 200social issues\ndivisiveness and\u2003147\u201348editorial epistemologies and\u2003210influencers and\u2003153\u201354, 154Instagram users and\u2003148 , 155\nsocial media see  specific topics\nS\u00f8rensen, Majken Jul\u2003193source-distance methodology\u200342\u201344sources\nauthoritative\u2003109\u201312coding schemas for\u200343, 68, 130\u201331of COVID-19 information\u2003135\u201336(hyper)partisan\u200386mainstream\u200337, 43\u201344problematic\u200384, 91, 104as spectrum\u200348\u201349\nspecial interest websites\u200334, 37, 40\u201341, 44\nofficial sources compared to\u200335\n244  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nspectrum\n\u201cfake news\u201d as\u200349\u201350\npolitical\u200311, 19, 89sources as\u200348\u201349\n\u201cstaging an opinion,\u201d on TikTok\u2003191, 193, 195, \n199\n\u201cstale\u201d social media, \u201cfresh\u201d compared \nto\u2003188\u201390\nStevens, D\u200389supporters\nof Biden\u2003101, 198of candidates\u200315, 85, 88\u201389of Trump, D.\u2003190, 192, 194 , 197\u201398, 200\u2013201\n\u201cSweet Home Alabama\u201d (song)\u2003196, 197\nTaylor, James McCoy\u2003191\nterrorist attacks, far-right\u2003171\u201cThank God for Donald Trump?\u201d (TikTok \nvideo)\u2003 194\nTikTok\u2003 202\nambivalent content and\u2003198\u201399Biden and\u2003190, 193, 194 , 196\u201397, 201\ncreative expression on\u200315\u201316, 200\u2013201data and\u2003202\u20133demotion of content on\u2003210\u201cdocumenting\u201d on\u2003193\u201395engagement on\u2003188\u201389, 202fringe practices and\u2003200\u201cgiving a speech\u201d on\u2003193\u201395, 200media on\u2003199parody and\u200314\u201316, 192, 195\u201396, 198\u201399\u201cpartisan duetting and stitching\u201d \non\u2003197\u201398\n\u201cplayful political performance\u201d on\u2003189\u201391, \n194\u201395, 199\u2013200\npolarization and\u2003188, 201remix on\u2003195\u201396Sanders on\u2003190, 201\u201cstaging an opinion\u201d on\u2003191, 193, 195, 199Trump, D., on\u2003190\u201393, 194 , 196, 201\nU.S. presidential elections and\u2003187\u201389, \n190, 195\nvideos from\u2003191 , 194 , 196\u201398\nyouth and\u200310, 14\nTikTok-scraper\u2003202\u20133transmission, of COVID-19\u2003117\u201318, 119\u201321, \n120\u201321, 126\u201327 , 130, 137\u201338\ntreatments, for COVID-19\u2003109, 115, 116\u201318 , \n125\u201327 , 130, 137\u201338\ntrolling\u200318, 69 88\u201389, 144 see also  problematic \naccountson Facebook\u200313, 49\nTrump, Donald\u200358, 178 see also  candidates, \npresidential; presidential elections, U.S.as authoritative source\u2003110\u201311Breitbart News and\u2003168, 170, 176\u201377Capitol riots and\u200385content moderation and\u200326, 146COVID-19 information and\u2003114\u201315deplatforming of\u2003178divisive content and\u2003145\u201cfake news\u201d and\u200349follower authenticity and\u200321Instagram and\u2003143\u201344, 146 , 149, 152, 154\nkeyword data for\u200398 , 101\npolitical discourse of\u2003166TikTok and\u2003190\u201393, 194 , 196, 201\nTwitter and\u200385, 91, 95, 115, 117, 127 , 128\nvoters for\u2003167web content and\u200315\u201316, 36, 38, 93\nTrump, Donald, Jr.\u200321\ndivisive content and\u2003145Instagram and\u2003143, 149\n\u201cTrump Theme Song\u201d\u2003191\u201392trust, in news\u200390Tuters, M.\u2003198\u201399Twitter\u200390\nas authority\u2003112, 114\u201315, 128bots on\u200385\u201386content moderation on\u2003109\u201310, 113\u201314, \n121\u201323\nCOVID-19 mentions on\u2003116\u201321, 125\u201327debunking and\u2003123, 128democratization of news and\u200387\u201388deplatforming and\u200318, 83diversification compared to polarization \non\u200387\u201389\neditorial epistemology and\u200326\u201327engagement on\u200384, 87Green New Deal and\u200397hyperpartisanship and\u2003209#KnowTheFacts on\u2003114, 123, 128mainstream compared to problematic \nsources on\u200393\u201394 , 96\u201397\npartisanship and\u200319polarization on\u200392, 101policies of\u2003111, 123, 124 , 128, 208\npolitical issues on\u200383, 95, 96 , 100 , 102, 102\nproblematic accounts on\u200395, 97\u201398problematic information and\u200318, 84\u201387, 110retweets on\u200326, 84, 101\u20133, 131Trump, D., on\u200385, 91, 115, 117, 127 , 128\nusers of\u200395, 98\u201399 , 101\nU.S. presidential elections and\u200317\u201319, \n85\u201387\nTwitter Capture and Analysis Toolkit\u2003102, 129\nUkraine, war in\u2003210\nuncertainty\u200312\u201314\nCOVID-19 and\u2003111\nunique sources, in Google Web Searches\u200339, \n40\u201341\nUnited States (U.S.)\u200338, 131, 173\nplatforms based in\u200310, 67polarization in\u2003167, 169political unrest in\u200335sources outside\u200361users based in\u200376\nin de X 245\nuserleansbot, partisanship and\u200376\u201377\nusers\nactivity analysis of\u200398\u2013100 , 142\u201343, 158\nbased in U.S.\u200376categorization of\u2003103, 151 , 158\ndigital methods and\u2003142\u201343, 158of Twitter\u200395, 98\u201399 , 101\nvaccines\u2003123, 140, 142\nPfizer\u2003115\nVega, Cecilia\u2003196verified accounts, on Instagram\u2003141, 150 , 155 , \n159\nvernacular see also  \u201cdeep vernacular web\u201d\nof 4chan\u2003165\u201367, 169\u201372, 173 , 176\nmemes and\u200316, 166methodology and\u200311, 155\u201356\nvideos\u200371\u201372\ncoding schemas for\u2003202\u20133documentary\u200374\u201375from TikTok\u2003191 , 194 , 196\u201398\nviral news\u200390, 91vocabulary, right-wing\u2003172\u201373, 173\u201374 , 177, 180\nvoters\nfraud and\u2003190, 199liberal\u2003175support services for\u200342, 101\u20132Trump, D.\u2003167U.S. presidential elections and\u2003154 , 190Wahl-Jorgensen, K.\u200391\u201cWait for it\u201d (TikTok video)\u2003196Wardle, Claire\u2003199Wayback Machine\u2003112web history\u200311, 23\nfringe contributions and\u200312\nwebsites see also  sources\ncategories of\u200322\u201323, 37, 38 , 40, 53, 86, 92, \n102\nhyperpartisan\u200336, 39, 208official source\u200334, 44pink slime\u200320, 62special interest\u200337, 40\u201341, 44\n\u201cWhen I can attract both genders\u201d (TikTok \nvideo)\u2003 198\nwhistle-blowing\u2003209WHO see  World Health Organization\nWikipedia\u200318, 23\nin methodology\u200322, 43, 62, 129\u201330\nWired  (magazine)\u2003196, 197\n\u201cwisdom of the crowd\u201d\u200312, 23, 26World Health Organization (WHO)\u2003110\ndebunking by\u2003115hydroxychloroquine and\u2003117\nYiannopoulos, Milo\u2003168youth, TikTok and\u200310, 14YouTube, Reddit and 4chan linking\u200316\u201317, \n67\u201368, 71, 72 , 73\u201374\nYouTube Data Tools\u200379\n\nThere is growing awareness about how social media circulate extreme \nviewpoints and turn up the temperature of public debate. Posts that exhibit agitation garner disproportionate engagement. Within this clamour, fringe sources and viewpoints are mainstreaming, and mainstream media are marginalized. This book takes up the mainstreaming of the fringe and the marginalization of the mainstream. In a cross-platform analysis of Google Web Search, Facebook, YouTube, Reddit, Twitter, Instagram, 4chan and TikTok, we found that hyperpartisan web operators, alternative influencers and ambivalent commentators are in ascendency. The book can be read as a form of platform criticism. It puts on display the current state of information online, noting how social media platforms have taken on the mantle of accidental authorities, privileging their own on-platform performers and at the same time adjudicating between claims of what is considered acceptable discourse.\nRichard Rogers, PhD, is Professor of New Media and Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods Initiative. He is author of Information Politics on the Web and Digital Methods (both MIT Press) and Doing Digital Methods (SAGE).\nAU P. n lISBN: 978-94-6372-076-2\n9789463 720762Rogers (ed.) The Propagation of Misinformation in Social Media", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "4 When misinformation migrates", "author": ["AG Burton"], "pub_year": "NA", "venue": "edia", "abstract": "This chapter investigates the political information ecologies of the \u201cdeep vernacular web\u201d by  studying the cross-posting of links on 4chan\u2019s \u201cpolitically incorrect\u201d board and a host of"}, "filled": false, "gsrank": 559, "pub_url": "https://library.oapen.org/bitstream/handle/20.500.12657/61940/9789048554249.pdf?sequence=1#page=68", "author_id": ["FxoLSjYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:C4dk88G3nVYJ:scholar.google.com/&output=cite&scirp=558&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=C4dk88G3nVYJ&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:C4dk88G3nVYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://library.oapen.org/bitstream/handle/20.500.12657/61940/9789048554249.pdf?sequence=1#page=68"}}, {"title": "The inventory is dark and full of misinformation: understanding the abuse of ad inventory pooling in the ad-tech supply chain", "year": "2022", "pdf_data": "The Inventory is Dark and Full of Misinformation:\nUnderstanding Ad Inventory Pooling in the Ad-Tech Supply Chain\nYash Vekaria\nUniversity of California, DavisRishab Nithyanand\nUniversity of IowaZubair Shafiq\nUniversity of California, Davis\nAbstract \u2014Ad-tech enables publishers to programmatically sell\ntheir ad inventory to millions of demand partners through a\ncomplex supply chain. The complexity and opacity of the ad-\ntech supply chain can be exploited by low-quality publishers\n(e.g., misinformation websites) to deceptively monetize their ad\ninventory. To combat such deception, the ad-tech industry has\ndeveloped transparency standards and brand safety products.\nIn this paper, we show that these developments still fall short\nof preventing deceptive monetization. Specifically, we focus on\nhow publishers can exploit the ad-tech supply chain, subvert\nad-tech transparency standards, and undermine brand safety\nprotections by pooling their ad inventory with unrelated sites.\nThis type of deception is referred to as \u201cdark pooling.\u201d Our\nstudy shows that dark pooling is commonly employed by\nmisinformation publishers on various major ad exchanges, and\nallows misinformation publishers to deceptively sell their ad\ninventory to reputable brands. Our work suggests the need for\nimproved vetting of ad exchange supply partners, the adoption\nof new ad-tech transparency standards that enable end-to-end\nvalidation of the ad-tech supply chain, and the widespread\ndeployment of independent audits like ours.\n1. Introduction\nThe complexity of online advertising lends itself to fraud.\nA key to the success of online advertising is the ability\nof advertisers and publishers to programmatically buy and\nsell ad inventory across hundreds of millions of websites\nin real-time [1]. Notably, Real-Time Bidding (RTB) allows\npublishers to list their ad inventory for auction at an ad\nexchange [2]. The ad exchange then asks its demand partners\nto bid on the ad inventory listed by its supply partners, based\non the associated contextual and behavioral information.\nThe ad-tech supply chain is complex because it relies on\nhundreds of specialized entities to effectively buy and sell\nthe ad inventory in real-time and at scale [3]. Adding to this\ncomplexity, each ad impression often gets sold and resold\nthrough multiple parallel or waterfall auctions [4]. Such\nscale and complexity, combined with the opaque nature of\nthe ad-tech supply chain, makes it a ripe target for fraud and\nabuse [5]\u2013[13]. One of the most common types of ad fraud\ninvolves creating low-quality websites and monetizing their\nad inventory. Fraudsters attempt to drive large volumes of\ntraffic to their website through various illicit means such as\nbots, underground marketplaces, traffic exchanges, or evendriving legitimate traffic through click-bait and viral propa-\nganda [14]\u2013[16]. A notable example that motivated our work\nis that of the \u201cMacedonian fake news complex\u201d [17]\u2013[19].\nIn this scheme, fraudsters created misinformation websites\nwith misleading and clickbait headlines, aiming to go viral\non social media, which led to tens of millions of monetized\nad impressions.\nAdvertisers are invested in preventing fraud. Ad-tech has\nsafeguards to protect against this type of ad fraud by block-\ning the ad inventory of low-quality websites even when the\nad impressions might be from legitimate users. Specifically,\nbrand safety features supported by demand-side platforms\naim to allow advertisers to block ad inventory of web pages\nthat contain hardcore violence, hate speech, pornography,\nor other types of potentially objectionable content [20].\nAll the effort of fraudsters would be wasted if they are\nunable to monetize their ad inventory through programmatic\nadvertising due to these brand safety features. Fraudsters\nare known to exploit the opaque nature of the complex ad-\ntech supply chain to undermine brand safety protections\nby misrepresenting their ad inventory [21]. For example,\nin domain spoofing [22], low-quality publishers mimic the\nURLs of reputable publishers in their ad inventory, thus\ndeceiving reputable brands into purchasing their ad space\neven when their original domain is blocked due to brand\nsafety concerns [23]\u2013[25]. To combat ad fraud resulting\nfrom misrepresented ad inventory, the Interactive Advertis-\ning Bureau (IAB) introduced two transparency standards.\nads.txt [26] requires publishers to disclose all authorized\nsellers of their ad inventory. sellers.json [27] requires\nad exchanges to disclose all publishers and intermediate\nsellers involved in selling the ad inventory. Together, when\ncorrectly implemented, these standards can reduce ad fraud\nby enabling buyers to verify the sources of the inventory\nthey are purchasing.\nTransparency mechanisms to prevent fraud are falling\nshort. There is increasing concern that the ads.txt and\nsellers.json standards are either not widely adopted,\nimplemented in ways that do not facilitate effective supply-\nchain validation, or intentionally subverted by malicious\nactors in a variety of ways. In this paper, we empirically\ninvestigate these concerns. We find that the ads.txt and\nsellers.json disclosures are plagued by a large number\nof compliance issues and misrepresentations. Most notably,\nwe find extensive evidence of \u201cpooling\u201d of ad inventoryarXiv:2210.06654v3  [cs.CR]  14 Oct 2023\nfrom unrelated websites \u2014 a practice known in the industry\nas \u201cdark pooling.\u201d This makes it impossible for a buyer\nto reliably identify the sources of the ad inventory (i.e.,\nwhere their ad will ultimately be placed). Dark pooling\neffectively enables low-quality publishers to \u201claunder\u201d their\nad inventory, making it indistinguishable from that of well-\nreputed publishers. To gain insight into how low-quality\npublishers might circumvent the transparency required by\ntheads.txt andsellers.json standards, we selected\na set of well-known misinformation websites as a case\nstudy. This choice is motivated by the known instances\nwhere ads from reputable brands have inadvertently ended\nup on such websites in the past [28]\u2013[33]. Focusing on these\nmisinformation websites, we confirm: (1) their widespread\nfailure to comply with the ads.txt andsellers.json\nstandards; and (2) widespread prevalence of ad inventory\npooling. We also find instances of reputable brands buying\nad impressions on these misinformation websites, perhaps\nunintentionally. Taken together, we make three key contri-\nbutions.\nMeasuring compliance with the transparency standards of\nads.txt andsellers.json .We study a set of control\nand well-known misinformation websites to compare their\ncompliance with ads.txt andsellers.json . We find\nthat although compliance issues are widespread even in the\ncontrol set of websites, they are significantly more prevalent\non misinformation websites.\nMeasuring the prevalence of (dark) pooling. We measure\nthe high prevalence of ad inventory pooling by our control\nand misinformation websites. By analyzing the ads.txt\nandsellers.json files, we identified nearly 80 thousand\ninstances of pooling. We find that the misinformation pools\nare significantly more than twice as likely to pool ad inven-\ntory from unrelated websites than those that do not contain a\nmisinformation website. Upon further analysis of ad-related\nmetadata in network traffic, we confirmed the use of 297\npools across 38 ad exchanges by misinformation websites.\nMeasuring the (in)effectiveness of brand safety tools. We\nfind ads from 55 reputable brands, including Forbes, Go-\nDaddy, Harvard, Intel, Microsoft, Nike, Samsung, Tumblr,\nYahoo!, Verizon, and Wayfair, on misinformation websites.\nWe investigate the correlation between the prevalence of\npooling and ads from reputable brands on misinformation\nwebsites. We find that misinformation websites that are part\nof at least one dark pool are nearly 20% more likely to\nattract ads from reputable brands than those that are not part\nof a dark pool. The responses to our disclosures indicate\nthat reputable brands are generally unaware of their ads\nappearing on misinformation websites despite several using\na brand safety service.\nWhile there is some anecdotal evidence of a general\nlack of compliance with the ad-tech transparency standards\nand dark pooling [34], [35], it does not systematically study\nthese issues at scale. To the best of our knowledge, our\nwork is the first to systematically study compliance with ad\ntransparency standards and (dark) pooling at scale.\nAd\nAdvertisers DSP SSP Ad exchange Publisher Usersellers.json ads.txt\n1\n2 34\nFigure 1: Programmatic advertising ecosystem: When a user\nvisits a publisher website (Step \u2776), the publisher puts its\nad-inventory for sale on ad exchanges via SSPs in real-\ntime (Step \u2777). Advertisers bid for these slots via DSPs\n(Step\u2778). Advertisement of the winning bid is displayed\nto the user on the publisher website (Step \u2779). To mitigate\nfraud, advertisers use sellers.json of ad exchanges and\nads.txt of publishers to verify who is and who is not an\nauthorized seller of a given inventory.\n2. Background\nIn this section, we provide a high-level overview of the\nmechanisms behind the supply of programmatic ads (\u00a72.1)\nand the vulnerabilities in the ad supply chain (\u00a72.2).\n2.1. Programmatic advertising\nAlthough there are a variety of mechanisms for program-\nmatic advertising (e.g., real-time bidding, header bidding,\nexchange bidding) and the participating organizations might\ndiffer, the types of entities involved in the supply chain\nremain the same for each mechanism.\nThe programmatic advertising supply chain. Program-\nmatic advertising is made possible by the following entities\nillustrated in Figure 1: supply-side platforms (SSPs) for pub-\nlishers to list their ad inventory in real-time, ad exchanges\n(AdX) which aggregate the inventory of multiple SSPs and\nfacilitate bidding on individual ad slots, and demand-side\nplatforms (DSPs) which allow advertisers and brands to\nidentify targets for their ad creatives by suitably bidding\non the inventory listed at ad exchanges. These entities work\ntogether to create a supply chain for ads as follows: When\na user visits a publisher, the ad inventory associated with\nthat visit is put up for auction at an AdX by the SSP. DSPs,\noperating on behalf of advertisers and brands, then make\nbids on the ad inventory available at the AdX. These bids\nare informed by what is known (to the DSP) about the user\nand the publisher. The winner of the auction is then notified\nby the AdX and the associated ad creative is used to fill the\nad slot on the publisher\u2019s website.\nTransparency in the supply chain. Crucial to the operation\nof the ad supply chain is that the participating organizations\ncan trust that publishers and AdXs are not misrepresenting\ntheir inventories or their relationships with other entities. For\nexample, DSPs need to confirm that the ad inventory that\nthey are bidding on is actually associated with a particular\npublisher. Similarly, DSPs also need to confirm that the\nAdXs that they are purchasing ad inventory from are actually\nauthorized to (re)sell that inventory. The absence of trust in\n2\nthis supply chain can lead to situations where DSPs place\npremium bids for ad slots that are actually associated with\nnon-premium publishers \u2014 ultimately leading to a brand\u2019s\nad creative appearing on websites that they may not want\nto be associated with. To foster trust and enable DSPs\n(Demand-Side Platforms) to perform basic verification of\nthe ad inventory, the Interactive Advertising Bureau (IAB)\nintroduced two standards: ads.txt andsellers.json .\nThe ads.txt standard. The ads.txt1standard\n(introduced in 2017) aims to address ad inventory\nfraud by requiring each publisher domain to main-\ntain an ads.txt file at the root level directory (e.g.,\npublisher.example/ads.txt ). The ads.txt file is\nsupposed to contain entries for all AdXs that are authorized\nto sell or resell the ad inventory of the publisher. Each entry\nin the ads.txt file contains the following fields:\n\u2022the authorized AdX,\n\u2022the publisher ID assigned to the publisher domain within\nthe AdX network, and\n\u2022the authorized relationship between the publisher and\nauthorized AdX \u2014 i.e., whether the AdX is authorized\nas aDIRECT seller or RESELLER of inventory for the\ndomain.\nHowads.txt helps prevent fraud. When an ad request is\nsent by a publisher to an AdX (which issues bid requests\nto DSPs), the request contains the publisher ID and the\ndomain associated with the inventory being listed. Impor-\ntantly, because publisher IDs are typically associated with\nan organization and not a domain, it is possible for multiple\ndomains to share the same publisher ID. ads.txt enables\nverification that a website is not spoofing the domain in their\nad requests. More specifically, ads.txt allows:\n\u2022AdXs to verify that the publisher ID in the ad request\nmatches the publisher ID associated with the domain in\nthe ad request and\n\u2022DSPs to verify that the AdX claiming to (re)sell the\ninventory of a domain is authorized by the domain to\ndo so.\nBefore the ads.txt standard, there were no mechanisms\nto facilitate such checks and the sale of fraudulent inventory\nwas widespread [21].\nThe sellers.json standard. Similar to the\nads.txt standard, sellers.json aims to miti-\ngate ad inventory fraud and misrepresentation. The\nsellers.json standard2requires each AdX and SSP\nto maintain a sellers.json file at the root level\ndirectory (e.g., adx.example/sellers.json ).3This\nsellers.json filemust contain an entry for each entity\nthat may be paid for inventory purchased through the AdX\n1. \u201cads\u201d in ads.txt stands for Authorized Digital Sellers. Full spec-\nification of the ads.txt standard is available at: https://iabtechlab .com/\nwp-content/uploads/2021/03/ads .txt-1.0.3.pdf\n2. Full specification of the sellers.json standard is available at:\nhttps://iabtechlab .com/wp-content/uploads/2019/07/Sellers .json Final.pdf\n3. We observed that several AdXs, including Google, use non-\nstandard paths \u2014 e.g., Google\u2019s sellers.json is located at https:\n//storage .googleapis .com/adx-rtb-dictionaries/sellers .json\u2014 i.e., one entry for each partner that is an inventory\nsource for the AdX. Each entry in the sellers.json\nfile contains the following fields:\n\u2022the seller type which indicates whether the entry is as-\nsociated with a PUBLISHER , anINTERMEDIARY (i.e.,\ninventory reseller AdX), or BOTH (i.e., this entity has\ntheir own inventory and also resells other inventory);\n\u2022the seller ID associated with the inventory source (same\nas the publisher ID in ads.txt if this entry is associated\nwith a publisher. From this point onwards we will refer\nto seller ID or publisher ID as seller ID); and\n\u2022the name and domain associated with the seller ID (these\nfields may be marked as \u201cconfidential\u201d by AdXs to\nprotect the privacy of publishers).\nHow sellers.json helps prevent fraud. When a bid\nrequest is received by a DSP from an AdX that is compliant\nwith the sellers.json standard, it must contain infor-\nmation about the provenance of the inventory in a Supply\nChain Object (SCO).4At a high level, the sellers.json\nfile provides a mechanism for DSPs to identify and verify\nall the entities listed in this SCO. This is done as follows:\n\u2022When a bid request is received by the DSP, it should use\nthe AdX\u2019s sellers.json file to verify that the final\nAdX has an authorized relationship with the prior holder\n(an SSP or another AdX) of the inventory.\n\u2022The previous step is applied recursively (on all inter-\nmediate neighbors in the SCO) to verify the end-to-end\nauthenticity of the inventory.\n\u2022The DSP then uses the sellers.json files of all\nintermediaries and the ads.txt file of the publisher to\nverify that the publisher is legitimate and (re)sellers who\nhandle the publisher\u2019s inventory are authorized to do so.\nThis capability for end-to-end validation of the SCO (Supply\nChain Object) allows DSPs to identify instances where the\nad inventory originates from low-quality publishers using\nfraudulent ads.txt files or is being sold by malicious\nintermediaries.\n2.2. Supply chain vulnerabilities\nDespite the introduction of the ads.txt and\nsellers.json standards, there remain various vulner-\nabilities in the ad inventory supply chain. Our investiga-\ntion focuses on the vulnerabilities that enable low-quality\npublishers to monetize their ad inventory by misrepresent-\ning or obscuring its source. Some of these vulnerabili-\nties arise from misrepresentations in the ads.txt and\nsellers.json files, while others arise from pooling their\nlow-quality inventory with the inventory of unrelated high-\nquality publishers. We refer to the former as inventory\nmisrepresentation and the latter as dark pooling .\nInventory misrepresentation. Inventory misrepresentation\narises from misrepresentations of ad inventory by publishers.\nIt can be identified by discrepancies in the publisher\u2019s\n4. Supply Chain Object (SCO) contains an ordered list of all the entities\ninvolved in the ad transaction (e.g., publisher \u2192SSP\u2192reseller\u2192AdX).\n3\nads.txt file and is possible when DSPs and AdXs do\nnot follow the ads.txt andsellers.json standards.\nSome examples of these misrepresentations include:\n\u2022a publisher\u2019s ads.txt file might incorrectly use seller\nIDs of other publishers to suggest an authorized relation-\nship with an AdX to boost the perception of its inventory.\n(Misrepresentations #1 and #2)\n\u2022a publisher\u2019s ads.txt file might incorrectly indicate\nthat a popular AdX is an authorized (re)seller of its\ninventory to boost its reputation with other AdXs. (Mis-\nrepresentation #3)\n\u2022a publisher\u2019s ads.txt file might have more than\none entry of the same seller type for an AdX or\nsellers.json files might associate a seller ID with\nmultiple publishers or sellers making ads.txt and\nsellers.json verification unreliable. (Misrepresenta-\ntions #4 and #9)\n\u2022a publisher\u2019s ads.txt file might list authorized relation-\nships with (re)sellers that do not have sellers.json\nfiles, making end-to-end verification impossible. (Misrep-\nresentation #8)\nDark pooling. Pooling is a common strategy to share\nresources in online advertising. Consider, for example, the\ncase where two or more publishers are owned by the same\nparent organization. In such scenarios, the ability to share\nadvertising infrastructure and AdX accounts allows for more\nefficient operation and management. One way to identify\nthe occurrence of pooling is by noting a single AdX-\nissued \u2018seller ID\u2019 shared by multiple publisher websites.\nDark pools are pools in which seller IDs are shared by\norganizationally-unrelated publishers (possibly of differing\nreputation). Note that \u201cdark pooling\u201d is a term of art that\nis commonly used in industry. While pooling is not itself a\n\u201cdark\u201d practice, pooling seller IDs of unrelated publishers\nis considered a \u201cdark\u201d practice because it deceives potential\nbuyers about the actual source of the ad inventory [34], [35].\nThe seller ID defined in ads.txt and\nsellers.json standards is also defined in the RTB\nprotocol [36], [37]. Note that the payment after successful\ncompletion of an RTB auction is made to the publisher\n(i.e., the seller) associated with the seller ID [38]. Hence,\nit should be noted that simply using another domain\u2019s\nseller ID in ad requests from a website will result in any\nad-related payments being made to the owner of the seller\nID. Therefore, for revenue sharing, the creation of these\npools needs to be facilitated either through intermediaries\n(e.g., SSPs) or by collaboration between publishers.\nEnd-to-end validation of pooled supply chains. Pooling\nleads to a break down of any brand or DSP\u2019s ability to\nperform end-to-end verification of the ad inventory supply\nchain. Specifically, the final step of verification highlighted\nin \u00a72.1 cannot be meaningfully completed unless alldo-\nmains associated with a publisher\u2019s account are publicly\nknown (and unfortunately, this is not the case). This is\nbecause the end-to-end verification of the ad inventory\nsupply chain, as specified by the IAB, implicitly relies on\ntrust that seller IDs are actually associated with specificorganizations and that these associations are verified by\nAdXs. We illustrate this with an example.\n\u2022Consider a publisher website sportsnews.example\nwhich has a legitimate subsidiary: nbanews.example .\nThe publisher registers for an account with a popular\nAdX ( adx) and is issued the seller ID sellerid after\nbeing vetted by adx. It is expected that this website\ncan now share this seller ID with its subsidiaries. Both\nwebsites will now list adx as aDIRECT seller through\nthesellerid account in their ads.txt files.\n\u2022The publisher now decides to share adx-issued\nseller ID with fakesportsnews.example , an-\nother sports news website but of low quality, for\na cut of the revenue generated from ads shown on\nfakesportsnews.example . In its ads.txt file,\nfakesportsnews.example now adds adx as a\nDIRECT seller and also lists sellerid as its seller ID.\nNote that fakesportsnews.example would other-\nwise be unable to get directly listed on adx and monetize\nits ad inventory due to its low quality.\n\u2022When an ad request for some inventory is sent from\nfakesportsnews.example , all basic supply chain\nvalidation checks are successful because the seller ID\nsellerid is in fact registered by adx in their\nsellers.json file. Any bidding DSP will therefore\noperate under the assumption that the website receiving\ntheir ads has been vetted by adx and is associated with\nsportsnews.example .\n\u2022Complications only arise if the verifier notices that\nsellerid was only registered to the owner of\nsportsnews.example and the bid request actu-\nally originated at fakesportsnews.example . How-\never, invalidating the bid request simply because of\nthis inconsistency will mean that even legitimate sub-\nsidiaries such as nbanews.example cannot pool their\ninventory. Instead, additional checks are required to\nascertain whether fakesportsnews.example and\nsportsnews.example are related or whether adx\nvetted fakesportsnews.example as well. This is-\nsue remains unaddressed by current validation mecha-\nnisms.\nCaveat. The example described assumes collaboration\nbetween publishers \u2014 sportsnews.example and\nfakesportsnews.example . This might be inadvertent\nin some cases \u2014 e.g., if sportsnews.example and\nfakesportsnews.example are both assigned the same\nseller ID through a common intermediary (an SSP, for\nexample as shown in Figure 2).\nIn sum, by pooling various unrelated websites under a\nsingle seller ID, low-quality publishers can \u201claunder\u201d their\nad inventory, rendering it indistinguishable from the inven-\ntory of high-quality publishers. Moreover, this can occur\nwhen an AdX provides the seller ID to a trusted publisher\n(or an SSP), which then inadequately vets the low-quality\npublishers whose inventory it pools. Figure 2 illustrates this\nscenario of syndication-based pooling by some intermediary\nSSP. As we show later, such pooling is common. In fact, we\n4\nAdvertisersPublishers\nokay.example\ngood.examplessp.example\nAd exchange\nSample ad inventory\nA1A2\nDomain: okay.example\nsellerID: A2\nbad.exampleFigure 2: Illustration of pooling by an SSP \u2014 A premium\npublisher ( good.example ) or an AdX-trusted intermedi-\nary SSP ( ssp.example ) can list on the AdX to obtain\nseller IDs A1andA2respectively. Whereas, a low-quality\npublisher ( bad.example ) or legitimate but unrecognized\npublisher ( okay.example ) are unable to directly list on\nthe AdX. A legitimate publisher may not get listed on the\nAdX because, for instance, traffic requirements are not met.\nHowever, bad.example andokay.example are able\nto list on SSP, which essentially pools multiple publish-\ners together. Bid request may misrepresent the inventory\nonbad.example as that of okay.example using the\nseller ID of the SSP (i.e., A2). Reputable advertisers may\nbid on the inventory assuming that they are bidding on\nokay.example , when in fact their ad actually would end\nup on bad.example .\nfind some AdXs even providing services, via intermediaries,\nthat facilitate pooling of unrelated entities.\n3. Data\nIn this section, we describe the selection of publishers\nthat we study (\u00a73.1) and our methodology for collection\nofads.txt ,sellers.json , and ad-related metadata\nassociated with these websites (\u00a73.2).\n3.1. Publisher website selection\nOur goal is to identify practices that hinder the end-to-\nend validation of the ad inventory supply chain, both among\nhigh-quality and low-quality websites. We use misinforma-\ntion websites as a case study for low-quality websites and\nuse comparably ranked websites from the Tranco list [39]\nthat have ads.txt as a stand-in for high-quality websites\n(referred to as a control).\nSelection of misinformation websites. Since identifying\nmisinformation websites is itself not the focus of our work,\nwe leverage lists of misinformation websites curated in\nprior research by media scholars [40], [41] and computer\nscientists [42], [43].5To construct our list of misinformation\nwebsites, we began by aggregating all websites from these\n5. For websites obtained from [41], we discard those labeled as \u2018state\u2019,\n\u2018political\u2019, \u2018credible\u2019, and \u2018unknown\u2019.Notation Description Size\nMfull Complete set of misinformation domains studied 669\nMranked Sites in Mfullwithads.txt & part of Tranco-1M 251\nCranked Similar-ranked NM with ads.txt for each Mranked 251\nC100K Tranco Top-100K domains with ads.txt presence 20K\nDstaticads.txt andsellers.json crawled on 02/22 1.4K\nDcrawls(PD, AdX, OD) tuples from dynamic crawl of Mfull 2.8K\nDbrands(PD, Brand) pairs from dynamic crawl of Mfull 4.2K\nTABLE 1: Description of dataset notations and sizes. NM\nrepresents non-misinformation websites. PD and OD repre-\nsent publisher domain and owner domain respectively.\nlists and removing duplicates. This left us with 1276 web-\nsites. Next, we discarded 434 websites that were no longer\nfunctional. Finally, we additionally classified each misinfor-\nmation website using multiple independent sources includ-\ning Politifact, Snopes, MBFC, OpenSources, PropOrNot,\nand FakeNewsCodex to ensure that each remaining web-\nsites contained content that was undeniably misinformation.\nWe excluded the websites that were now parked domains,\nseemed to have been repurposed, or had conflicting labels\nacross different sources. This left us with a set of 669 mis-\ninformation websites (Mfull). Of these 669 websites, we cre-\nated a subset of all the 251 websites that had an ads.txt\nfile and were also present in the Tranco top-million list\n[39] ( Mranked ). We use Mranked to compare the prevalence\nofads.txt andsellers.json discrepancies between\nmisinformation and non-misinformation websites.\nSelection of benign (control) websites. To facilitate com-\nparisons of the prevalence of compliance issues between\nmisinformation and benign websites, we created a control\nset of non-misinformation websites ( Cranked ). For each web-\nsite in Mranked , we included the most similarly ranked non-\nmisinformation website that also had an ads.txt file.\nWe performed matching based on website domain ranks\nto avoid confounds related to website popularity. We also\ncreated a control set of the Tranco top-100K domains which\ncontained an ads.txt file ( C100K). This dataset was used\nto investigate the broad prevalence of pooling. These four\nsets of websites ( Mfull,Mranked ,Cranked , and C100K) are the\nsubject of our study.\n3.2. Data collection\nOur analysis relies on three sources of data: (1)\nads.txt andsellers.json files related to publishers,\nAdXs, and other intermediaries; (2) bid/ad requests and\nresponses during visits to a publisher domain; and (3) brands\nplacing advertisements on a publisher domain. An overview\nof our data collection is illustrated in Figure 3. Table 1\nlists the notations for different datasets used throughout the\npaper.\nads.txt and sellers.json files. To build evi-\ndence for the occurrence of pooling and other misrepre-\nsentations, we need to analyze published ads.txt and\nsellers.json files associated with publishers and ad-\ntech entities.\n5\nads.txt\ncrawler sellers.json\ncrawlerExtract distinct\nseller domains\nVisit the site HAR file dumpDstatic\nDbrands\nExtract URLs<iframe>\n<a>\nbrowser req. traces\nRetain ad URLs Click ad URL Extract landing domainDcrawls{Publisher, AdX, Owner}\nads.txt\nsellers.json\nMfull\n     https://brand.exampleExtract domain triplets\n C100KCrankedFigure 3: Overview of data collection methodology.\nProcessing ads.txt files. We searched for an ads.txt\nfile at the root of each website in Mfull,Mranked ,Cranked , and\nC100K. From these ads.txt files, we extracted the domains\nof all the entities that were listed as DIRECT sellers or\nRESELLERS of the publisher\u2019s inventory.\nProcessing sellers.json files. For each seller identified\nin our ads.txt files, we crawled the sellers.json\nfile at the domain\u2019s root. When the sellers.json file\nwas unavailable at this path, a best-effort attempt was\nmade to manually identify any non-standard location of\nthis file. We manually searched for the sellers.json\nfor the top-1K ranked seller domains that were detected\nasINTERMEDIARY orBOTH and no sellers.json\nwas extracted by the crawler for that domain. We per-\nformed a web search using \u201c <domain >\u2013 sellers.json\u201d\nquery and looked for the JSON file on the official web-\npage of the seller. Two sellers.json were detected\nin this manner \u2013 google.com and pubmatic.com. We then\nparsed each sellers.json file to identify entities (and\ntheir domains) that were associated with PUBLISHER ,\nINTERMEDIARY , orBOTH entries. Finally, until no new\nentities were discovered, we recursively fetched and parsed\nthesellers.json file associated with the entities labeled\nas either INTERMEDIARY orBOTH . This recursive fetching\nensures that we have complete coverage of all the supply\nchain entities that may sell the inventory of all publishers\nin our datasets.\nTheDstaticdatasets. We crawled and processed ads.txt\nandsellers.json files in February 2022. We refer to\nthe dataset as Dstatic. In total, Dstaticincluded over 98K\nrelationships from ads.txt files and 2.4M relationships\nfrom sellers.json files.\nLimitations of this dataset. It should be noted that, by itself,\nthis dataset cannot present evidence that pooling is actually\noccurring. This is because each publisher is responsible only\nfor the content of their own ads.txt file, misrepresenta-\ntion in other publishers\u2019 ads.txt files is not sufficient to\nimply pooling.\nObtaining real-time bidding metadata. To identify con-\ncrete evidence of pooling, we constructed a dataset of\nreal-time bidding metadata. These include bid requests, re-\nsponses, redirects, and payloads associated with ad requests\nand responses. Seller ID is communicated in requests and\nresponses to different entities in the advertising ecosystem.\nTherefore, during a crawl of a given publisher\u2019s website,\n\"seller_id\": \" pub-3740653521982427 \",\n\"seller_type\": \"PUBLISHER\", \n\"domain \": \"volcanodisco very.com\"\nhttps:// googleads.g.doublecl ick.net /pagead/ads?cl ient= ca-pub-3740653521982427\n&output=html&h=0&adk=4 200137118&adf=4165721491& w=0&r afmt=12&psa=0&\nurl=ht tps%3A%2F%2F galactic connection.com %2F&format=0x0&ea=0&flash=0&...AdX sellerID seller domain Ad-request captured on publisher domain : galacticconnection.com (no ads.txt ):\nowner domaingoogle.com , \npub-3740653521982427 , \nDIRECThttps://r ealtimebidding. google.com /sellers.json https:// volcanodisco very.com/ads.txt\n(a) True positive case of ID matching an ad request\n\"seller_id\": \" 57734 \",\n\"seller_type\": \"INTERMEDIAR Y\", \n\"domain \": \"google.com \"\nhttps://medianet -match. dotomi.com /match/bounce/curr ent?DotomiT est=47eb4c c43\nfa7123c &is_secur e=true&v ersion =1&networkI d=57734 &redir=ht tps%3A%2F%2Fc\nontextua l.media.net %2Fcksync.php %3Fcs%3D8%26vsi d%3D2907665791192295...AdX sellerID seller domain Ad-request captured on publisher domain : ufoholic.com :\nowner domainNo matching entry f or\nsellerID: 57734https:// yahoo.com/sellers.json https:// ufoholic.com /ads.txt\n(b) False positive case of ID matching in an ad request\nFigure 4: Illustration of seller ID matching in ad requests\nfor (a) true positive on the misinformation website: galactic-\nconnection.com and (b) false positive on the misinformation\nwebsite: ufoholic.com.\nobserving an unrelated entity\u2019s seller ID in these metadata\nconstitutes a more concrete evidence of pooling between\nthem.\nCrawling configuration. Following the best practices for\ncrawling-based data collection [44], [45], we collected this\ndataset using a web crawler driven by Selenium (v4.1.0) and\nthe Chrome browser (v91.0) with bot mitigation strategies\n(multiple randomly timed full page scrolls and randomized\nmouse movements), Xvfb from a non-cloud vantage point,\nand a 30-second waiting time after the completion of each\npage load. Prior work has shown that the bidders and content\nof ad slots are impacted by previous browsing history [46],\n[47]. Therefore, each page load was conducted with a new\nbrowser profile to avoid biases in our measurements of\nad responses and content. With these settings, we loaded\neach website twice in Mfulland saved the associated HTTP\nArchive (HAR) files and full-page screenshots.\nExtracting real-time bidding metadata from ad-related re-\nquests and responses. From each HAR file, we first identi-\nfied ad-related requests and responses by matching request\nURLs against well-known advertising filter lists used in\n6\nprior research [48]. We extracted the URLs, content, and\nHTTP POST-encoded data from each ad-related request and\nresponse. We then identified all (key, value) pairs using\nstandard delimiters (e.g., & in query parameters). Finally, we\nmatched the identified values with the seller IDs in from the\nDstaticdataset. To mitigate false positives, we only matched\nID strings with length greater than five characters.\nFigure 4a shows a sample ad request for doubleclick.net\nthat is matched for the highlighted seller ID. Since vol-\ncanodiscovery.com listed in Google\u2019s sellers.json and\nthe misinformation website galacticconnection.com are un-\nrelated, this represents a true positive instance of dark\npooling. For each ad-related request and response, we iden-\ntified the domain from which the request originated as the\npublisher domain (i.e., observed inventory source) and the\nAdX domain owning the detected seller ID as the AdX\n(i.e., inventory seller). We then used the sellers.json\nof the AdX/inventory seller to identify the domain that\nowned the seller ID found in the ad request. This domain\nis labeled as the owner domain (i.e., expected inventory\nsource). The ( publisher domain ,AdX,owner domain ) triples\nare used in later analysis. Figure 4b also shows a sample ad\nrequest on ufoholic.com, where one of the values matches\nwith a Yahoo-issued seller ID that is owned by Google.\nHowever, Google-associated domains are absent from the ad\nrequest. The seller ID also does not exist in ufoholic.com\u2019s\nads.txt . This match is deemed a false positive match and\ndiscarded from further analysis.\nMethodology validation. We manually evaluated the ac-\ncuracy of our method to extract metadata from ad-related\nrequests. Specifically, we manually examined the requests\nand responses to verify that they did in fact include a key\nthat suggested that the value was associated with a seller\nID. Our manual evaluation gave a false positive rate of 1.5%.\nThe Dcrawlsdataset. We label this dataset of ( publisher\ndomain ,AdX,owner domain ) triples as Dcrawls. In total, the\nDcrawlsdataset consisted of 3.1K distinct triples observed\nacross two crawls of 669 Mfullwebsites. In \u00a74, we use\nthese triples to determine (dark) pooling on misinformation\nwebsites.\nLimitations of this dataset. The programmatic advertising\nis auction-driven and participation from entities is non-\ndeterministic. Therefore, any observations of entities and the\nIDs in requests and responses related to ads will vary from\none crawl to the next, even when all other client-related\nfactors are identical. Further, the browser provides a vantage\npoint that typically only affords observations of the winners\nof real-time bidding auctions. Finally, it is possible that some\ncommunications regarding the involved seller ID are not\nvisible to us due to hashing or other forms of obfuscation\n[49]. These limitations are unavoidable. It should be noted,\nhowever, that these limitations only impact the completeness\nof our findings and not the correctness. In other words, the\nprevalence of pooling and other discrepancies, as measured\nby our crawls, are only a lower-bound for their actual\nprevalence.Identifying brands in advertisements. We also analyzed\nthe brands whose ads appear on misinformation websites.\nTo identify brands advertising on misinformation websites,\nwe performed 10 separate crawls. This repetition was to\naccount for the non-deterministic nature of programmatic\nadvertising that results in a user receiving different ads on\nrepeat visits to the same website. In each of the 10 crawls,\nafter each page load was complete and the 30-second wait\nperiod ended, we clicked the DOM elements associated with\neach ad-related URL on the page. These clicks typically\nresulted in navigation to the brand\u2019s website. We used this\nwebsite\u2019s domain to label the brand associated with the ad.\nMethodology validation. To test the effectiveness of this\nmethodology, we conducted a pilot test on one crawl where\nwe compared the brand names identified through manual\nanalysis and the automated approach. We found that in 30%\nof the displayed ads, the automated approach failed to iden-\ntify the brand associated with an ad. In these cases, failure\nwas largely because some ad-related request URLs were\nassociated with\u201cunclickable\u201d elements of the ad. As a result,\nour automated approach could not trigger navigation to the\nbrand\u2019s website. To mitigate this issue, we supplemented\nour automated approach by manually annotating the ads on\nall crawls that could not be associated with a brand. This\nprocess was relatively quick since most of the ads had been\nalready automatically annotated with associated brands.\nThe Dbrandsdataset. We recorded all ( publisher, brand )\npairs identified with this methodology in Dbrandsdataset. In\ntotal, the Dbrandsdataset consisted of 4.2K distinct (publisher,\nbrand) pairs and 2.1K unique brands.\nCrawl success rate. Our crawling infrastructure for\nads.txt andsellers.json had a 100% success rate\n(i.e., if a website had a file, we were able to crawl it without\nany failures). Dynamic web crawls did fail for a small\npercentage of websites ( <5%) due to timeouts. However,\nwe were able to crawl all websites at least once since we\nperformed multiple crawls for each website.\nLimitations. We performed all crawls from one IP address,\nwhich could impact our analysis of brands. In other words,\nwe might have observed more or less brands had we per-\nformed crawling from multiple IP addresses.\nEthical considerations. We discuss the ethics of our\nweb crawling along three dimensions: infrastructure costs,\nprivacy risks, and advertising costs caused by this study.\nOverall, our study respects the principle of beneficence as\noutlined in the Menlo Report [50] and Belmont Report [51]\nby maximizing the possible benefits and minimizing the\nharms.\nInfrastructure costs. Our crawls were used to measure the\nprevalence of compliance issues and misrepresentations. Our\ntwo dynamic crawls were not conducted concurrently to\navoid stressing the web servers. Similarly, our additional\nstatic crawls for ads.txt andsellers.json were per-\nformed six months apart. While our crawlers did not follow\ntherobots.txt directives (if present) on misinformation\npublishers, our crawling methodology is in line with ethical\n7\nand legal considerations of such crawling-based auditing\nsystems [52]\u2013[54]. Also note that our study did not involve\nhuman subjects or gather any personal information.\nAdvertising costs. To actually understand what brands\nare advertising on misinformation websites and what ad-\nexchange is responsible for showing that ad, we clicked on\nthe ads shown during the page loads. The costs associated\nwith our ad clicks are negligible (CPMs are in the order\nof fractions of cents and we clicked a total of 4247 ads).\nWe believe these costs are justifiable given the benefit of\nunderstanding vulnerabilities in the ad-tech ecosystem.\n4. Measuring Problematic Representations\nIn this section, we answer the question: what is the\nprevalence of pooling and other problematic representations\non misinformation websites? Specifically, we focus on mea-\nsuring the prevalence of misrepresentations that hinder end-\nto-end supply chain validation. In \u00a74.1, we provide a broad\noverview of the types of misrepresentations commonly seen\ninsellers.json andads.txt files. We compare the\nprevalence of these misrepresentations on control and mis-\ninformation websites. In \u00a74.2, we present evidence of ad\ninventory pooling and highlight cases of dark pooling by\nmisinformation websites.\n4.1. Prevalence of misrepresentations\nCertain types of misrepresentations in a publisher\u2019s\nads.txt file or an AdX\u2019s sellers.json file may pro-\nhibit automated end-to-end verification of the ad inventory\nsupply chain. We identify eight such problematic represen-\ntations:\n1)Misrepresented direct relationships: The Publisher claims\nthat an AdX is a DIRECT seller of its inventory, but the\nAdX\u2019s sellers.json lists it as an INTERMEDIARY\n(reseller) relationship;\n2)Misrepresented reseller relationships: The Publisher\nclaims that an AdX account is a RESELLER of its\ninventory, but the AdX\u2019s sellers.json associates the\ncorresponding account as a PUBLISHER (direct) entry;\n3)Fabricated seller IDs: A publisher\u2019s ads.txt claims\nthat an AdX is authorized to sell its inventory via some\nseller ID, but the AdX\u2019s sellers.json does not have\nanyaccount associated with that specific ID;\n4)Conflicting relationships: A publisher claims the same\ntype of relationship(s) with more than one seller ID on\na given AdX in their ads.txt , but the AdX only lists\none of these relationships in their sellers.json ;\n5)Invalid seller type: The sellers.json does not\nuse any of the three acceptable types ( PUBLISHER ,\nINTERMEDIARY , orBOTH ) to describe the source of\nthe inventory associated with a specific seller ID;Index Type C ranked Mranked\n1 Misrepresented direct relationships 51% 64%\n2 Misrepresented reseller relationships 47% 65%\n3 Fabricated seller IDs 65% 83%\n4 Conflicting relationships 33% 49%\nTABLE 2: Prevalence of problematic representations in\nads.txt from websites in Cranked andMranked .\nIndex Type No M full\u22651 M full\n5 Invalid seller type 0.7% 0%\n6 Invalid domain names 0.8% 54.8%\n7 Confidential sellers 0.1% 46.1%\n8 Intermediaries w/o sellers.json 13.3% 49.8%\n9 Non-unique seller IDs 62.6% 95.3%\nTABLE 3: Fraction of sellers.json entries that contain\ndifferent problematic representations from AdXs serving no\nMfullwebsites and at least one Mfullwebsite.\n6)Invalid domain names: Thesellers.json does not\npresent a valid domain name6in the \u2018domain\u2019 field;\n7)Confidential sellers: Thesellers.json lists the do-\nmain associated with the seller ID as \u2018confidential\u2019.\nIt should be noted that this is not a violation of the\nsellers.json standard, but does prevent end-to-end\nsupply chain verification because both the \u2018domain\u2019 and\n\u2018name\u2019 fields are redacted;\n8)Intermediaries without sellers.json :An AdX\u2019s\nsellers.json lists intermediaries that do not have a\nsellers.json ; and\n9)Non-unique seller IDs: Thesellers.json associates\nmultiple publisher or seller domains with the same seller\nID confounding the buyer\u2019s verification.\nTable 2 compares the prevalence of misrepresentations\ninads.txt files of Cranked andMranked websites. We find\na statistically significant difference in the number of errors\npresent in ads.txt files from Cranked andMranked websites\n(\u03c72-test; p < . 05). We find that misinformation websites\nare more likely to contain higher rates of ads.txt mis-\nrepresentations that result in failed supply chain validation,\neven when controlling for website rank. Table 3 compares\nthe prevalence of misrepresentations in sellers.json\nof AdXs that serve Mfull(344 AdXs) websites with the\nsellers.json from AdXs that do not serve any of our\nMfullwebsites (483 AdXs). Again, we see that the AdXs that\nengage with misinformation websites are significantly more\nlikely to have misrepresentations in their sellers.json\nthat result in the inability to perform supply chain validation.\nTaken together, our results highlight the lack of compliance\nwithads.txt andsellers.json standards and their\ncurrent inability to allow end-to-end supply chain validation.\nThis problem is especially pronounced for the ad inventory\nof misinformation publishers.\n6. While a buyer may still rely on the \u2018name\u2019 field, it is not suitable for\nautomated analysis because \u2018name\u2019 is a free text field. Automated analysis\nis crucial as bid requests need to be programmatically validated in real-time\nand at scale.\n8\n4.2. Prevalence of pooling\nAs described in \u00a72.2, pooling is the practice of using\na single AdX account to manage the inventory of multiple\nwebsites. This results in a single AdX-issued seller ID being\nassociated with multiple websites. Although this practice\nenables more efficient management of advertising resources\nfor publishers, it comes at the cost of increased opacity in\nthe advertising ecosystem and reduces the effectiveness of\nthe end-to-end supply chain validation mechanisms.\nGathering evidence of pooling with the Dstaticdataset.\nWe begin by identifying evidence of pooling in the C100K\nand Mfullwebsites from our Dstaticdataset. We use this\ndataset of ads.txt files associated with the Tranco top-\n100K domains to identify all cases where multiple domains\nlisted the same seller ID and AdX as a seller of their inven-\ntory. In total, we observed 79K unique pools \u2014 i.e., 79K\nunique (seller ID, AdX) pairs were observed to have been\nshared by multiple publisher domains. Of these 79K pools,\n11% (8.7K) also included at least one of the misinformation\nwebsites in Mfull. We refer to these 79K pools identified\nthrough the Dstaticdataset as static pools . The size of these\npools ranged from 2 to nearly 9K domains, with an average\nof 70 domains per pool.\nCharacteristics of pools identified in the Dstaticdataset.\nThese above-reported pool sizes were certainly larger than\nwhat we anticipated and necessitated additional inspection\nfor a better understanding of our findings. Specifically, we\npaid attention to the organizational relationships between\npooled entities and whether pooling was occurring due to\nsome ad-tech related mechanism.\nOrganizational homogeneity of pools. From a cursory\nmanual inspection of our pools, we observed (rather un-\nsurprisingly) that larger pools appeared to contain many\norganizationally unrelated domains \u2014 i.e., they were het-\nerogeneous . To measure the prevalence of such types of\npools at scale, we mapped each domain in a pool to their\nparent organization using the DuckDuckGo entity list [55]\nand labeled each pool as follows:\n1)Homogeneous: Pools whose member domains could all\nbe mapped to a single parent organization;\n2)Potentially homogeneous: Pools for which the parent\norganizations of all domains could not be identified.\nHowever, all domains that could be mapped were found\nto have the same parent organization;\n3)Heterogeneous: Pools whose member domains were\nowned by more than one parent organization; and\n4)Unknown: Pools for which no domain could be mapped\nto a single parent organization.\nFigure 5 illustrates how pools are categorized into homo-\ngeneous and heterogeneous. Table 4 provides a breakdown\nof the prevalence of different types of pools. We make three\nkey observations. First, we notice that heterogeneous pools\ncomprise a large fraction of all pools \u2014 a deviation from\nthe expectation that pools are allowed in order to facilitate\nresource sharing between sibling domains. The high inci-\ndence rates of heterogeneous pools in non-misinformation\n  \n      adexchange.example, 12345, DIRECT             \"seller_id\": \"12345\",\n             \"seller_type\": \" PUBLISHER \",\n             \"domain\": \" publisherA.example \",\n             \"name\": \"PublisherA\"\n       OR\n             \"seller_id\": \"12345\",\n             \"seller_type\": \" PUBLISHER \",\n             \"domain\": \" ABgr oup.example \",\n             \"name\": \"AB Group\"publisherA.example/ads.txt adexchange.example/sellers.json\n1. Homogenous Pools\n  \n      adexchange.example, 12345, DIRECTpublisherB.example/ads.txt\n  \n      adexchange.example, 12345, DIRECT             \"seller_id\": \"12345\",\n             \"seller_type\": \" PUBLISHER \",\n             \"domain\": \" publisherC.example \",\n             \"name\": \"PublisherC\"publisherA.example/ads.txt adexchange.example/sellers.json\n2. Heter ogenous Pools\n  \n      adexchange.example, 12345, DIRECTpublisherB.example/ads.txt\nFigure 5: Categorization of pools based on the relation of\nthe publishers with the domain owner organization. In the\nhomogeneous pool, PublisherA and PublisherB authorize\nseller account 12345 on adexchange.example as their direct\nseller. The sellers.json ofadexchange.example recog-\nnizing 12345 as an account owned by either PublisherA ,\nPublisherB , orAB Group represent all valid cases of pooling\nassuming PublisherA andPublisherB are related (in this case\nowned or operated by AB Group ). If the sellers.json\nofadexchange.example shows that the seller account 12345\nis owned by PublisherC and PublisherA orPublisherB\nare unrelated to PublisherC , then this represents a case of\nheterogeneous pool, which we consider a dark pool.\nwebsites also suggests that there may be legitimate (i.e., not\nill-intentioned) mechanisms that facilitate seller ID sharing\nbetween organizations. Second, pools containing misinfor-\nmation websites are statistically significantly more likely to\nbe heterogeneous (85%) than pools without misinformation\nwebsites (41%) [ \u03c72-test; p < . 05]. Finally, we see that\npools containing misinformation websites are statistically\nsignificantly larger (412.1 websites/pool) than pools without\nmisinformation websites (20.3 websites/pool) [2-sample t-\ntest:p < . 05;u-test: p < . 05]. Taken together, the latter\ntwo findings lend credence to the thesis that misinformation\nwebsites are effectively \u201claundering\u201d their ad inventory by\nparticipating in mechanisms that facilitate large heteroge-\nneous pools.\nPools facilitated by authorized ad-tech mechanisms. Our\nfindings about the high rate of heterogeneous pools of large\nsizes, even among non-misinformation websites, suggest\nthat there are ad-tech mechanisms that organically facilitate\npooling. After further investigation we found that many of\nthe heavily pooled (seller ID, AdX) pairs appeared to be\nissued by a small number of AdXs whose sellers.json\nfile indicated that the issued seller IDs were not associ-\nated with specific publishers but instead other ad platforms\n(AdXs or SSPs). In other words, the seller ID issuing AdX\u2019s\nsellers.json file indicated that the \u2018owner domain\u2019 of\n9\nPools w/ M full Pools w/o M full\nPool Type # Pools \u00b5size # Pools \u00b5size\nHomogeneous 40 (0.4%) 2.6 6.7K (9.6%) 2.6\nPo. Homogeneous 913 (9.1%) 18.8 18.4K (26.6%) 7.0\nHeterogeneous 8.6K (85.0%) 482.5 28.4K (41.0%) 42.2\nUnknown 563 (5.6%) 4.3 15.7K (22.7%) 3.9\nAll pools 8.7K 412.1 70.5K 20.3\nTABLE 4: Prevalence of pools from Dstaticin C 100K.\nPools are broken down by organization homogeneity and\nwhether they contained a misinformation website from the\nMfulldataset. \u00b5size denotes the average (mean) number of\nwebsites in a pool.\nthe pooled seller ID was another AdX/SSP \u2014 suggesting\nthat these pooling mechanisms might be authorized by the\nAdX platforms themselves for aggregating and reselling ad\ninventory of different publishers. Table 5 shows that three\nof the most commonly pooled owner domains belong to\nlarge AdXs ( google.com ,justpremium.com owned\nby GumGum, and townnews.com ). Most notably, nearly\n25% and 12% of the pools that used GumGum- and Google-\nowned seller IDs also contained known misinformation web-\nsites. For example, 100percentfedup.com , a website\nthat promoted anti-vax and stolen-election theories, received\nads through pools using Google-owned seller IDs issued by\nthe AdX \u2018Index Exchange\u2019. In contrast, TownNews, an ad-\nvertising firm focused on serving local media organizations\ndid not have a single pool containing known misinformation\nwebsites.\nTo investigate the prevalence of pooling, we looked for\nAdX-sanctioned programs that might require pooling \u2014 i.e.,\nis there public documentation of authorized programs to\nallow unrelated publishers to pool their inventory through\nintermediaries. Notably, we found public documentation of\nGoogle\u2019s Multiple Customer Management (MCM) program\nthat allows \u2018Google MCM-partner\u2019 organizations to manage\nthe inventory of multiple client publishers through a single\naccount [56]. As a result, all the publishers that are managed\nby an MCM partner are served ads via the same seller ID\nof the intermediary MCM organization. Our results show\nthat misinformation websites are able to monetize their\nad inventory by being part of these MCM networks. Our\nresults highlight a violation of Google\u2019s own policies re-\ngarding advertising on websites \u2018making unreliable claims\u2019\nor \u2018distributing manipulated media\u2019 [57]. However, public\ndocumentation does not clearly state whether Google dele-\ngates all website and content verification responsibilities to\ntheir MCM partners and therefore it remains unclear if the\nviolation is a failure of Google\u2019s own verification practices\nor those of their MCM partners. Similarly, the pooled misin-\nformation websites using GumGum-owned seller IDs were\nalso in violation of GumGum\u2019s content policy [58].\nPools using seller IDs with hidden or unknown owner\ndomains. During our investigation, we also discovered that\nmany AdX\u2019s sellers.json files did not allow identifica-\ntion of the owner domain of the seller ID that was used. This\ncomprised nearly half of all identified pools. The breakdownType Domain Pools Pools w/ M full\nOwner of sellerIDgoogle.com 5.1K 598\ngannett.com 370 5\njustpremium.com 337 84\ntownnews.com 313 0\nhearst.com 219 1\nAdX issuer of sellerIDgoogle.com 10.3K 461\ntaboola.com 6.6K 132\nfreewheel.com 3.9K 625\npubmine.com 3.6K 2\nopenx.com 2.4K 524\nTABLE 5: Most pooled domains and AdXs from Dstatic.\nThe top five rows represent the most frequently observed\ndomains whose seller IDs were used in pools. The bottom\nfive rows represent the most frequently observed AdXs who\nissued the seller IDs that were used for pooling.\nof reasons for this is provided in Table 6. Here, we see that\nthe most common reasons for failed identification of the\nowners of seller IDs being used in pooling are: (1) the seller\nID is itself unlisted in the issuing AdX\u2019s sellers.json\nfile and (2) the unavailability of a public sellers.json\nfrom the owner domain that owned the AdX-issued seller\nID (when owner domain is not a PUBLISHER type entry).\nIt is important to note that any of the reasons shown in\nTable 6 would result in the impossibility of any end-to-end\nsupply chain verification. Interestingly, we find no statis-\ntical differences ( \u03c72-test; p < . 05) between the reasons\nfor failed identification of owners of non-misinformation\nand misinformation pools. This suggests that the issues of\npoor compliance with end-to-end supply chain verification\nprocedures are industry-wide and no specific cause for these\nfailures is exploited by misinformation websites.\nReason All pools Pools w/ M full\nTotal pools 79K 8.7K\nseller ID unlisted 20.9K 2.5K\nsellers.json not public 16.5K 2.0K\nOwner not listed 2.6K 135\nOwner is confidential 3.4K 86\nTABLE 6: Pools from Dstaticusing IDs of unknown\nowners. Reasons for failed identification of the owners of\nseller IDs used in pools.\nFinding occurrences of pooling with the Dcrawlsdataset.\nBecause of the high rates of misrepresentations, unreliability\nof publisher-sourced ads.txt files, and the incomplete-\nness of AdX-sourced sellers.json files, it is important\nto note that our analysis of the Dstaticcan only be used as\nevidence that suggests the widespread practice of potential\ndark pooling. In order to confirm a dark pool\u2019s existence\nwith certainty we need to observe it in a live page load.\nTo this end, we leverage the set of all (publisher domain,\nAdX, owner domain) triples recorded in our Dcrawlsdataset\n(cf. \u00a73.2). Since these were obtained from actual ad-related\nmetadata from crawls of the Mfulldataset, they provide\nconcrete evidence of pooling actually being leveraged by\nknown misinformation websites (i.e., dark pooling). In total,\n10\nwe gathered 2.8K (publisher domain, AdX, owner domain)\ntriplets through two crawls of Mfullwebsites from which\nwe identified 297 pools across 38 ad exchanges. These 297\npools are depicted in Figure 6 Of these, 218 pools (73.4%)\noverlapped with those identified in our analysis of the Dstatic\ndataset and 79 were new. The non-existence of 79 pools in\ntheDstaticdataset prevented us from classifying them and\nthis once again highlights the ad industry\u2019s poor compliance\nwithads.txt andsellers.json standards.\nGoogle and PubMatic were found to be the issuers of\nthe seller IDs associated with 120 and 48 pools, respec-\ntively. These pools enabled advertising supply chains for\n127 (Google) and 67 (PubMatic) misinformation websites.\n33Across and Gourmet Ads were found to be the owners of\nseller IDs that were shared by the most number of misin-\nformation websites (28 and 23 websites, respectively). Both\nseller IDs were issued by PubMatic. Other notable AdXs\n(and count of the number of seller IDs issued by them which\nwere pooled by misinformation websites) include Rubicon\nProject (now Magnite) (34), ContextWeb (now PulsePoint)\n(30), Amazon (28), and media.net (25).\nHomogeneity of Dcrawlspools. From 297 distinct pools,\nwe were able to identify the presence of 15 homoge-\nneous and 203 heterogeneous pools. The homogeneity\nof the remaining pools could not be determined. The\nlargest homogeneous pool shared a seller ID issued to\nfunkedigital.de by PubMatic. This pool included\nnine websites such as principia-scientific.org ,\nallnewspipeline.com ,russia-insider.com \u2014\nMedia Bias/Fact Check identified all the nine websites as\n\u2018Conspiracy Theory\u2019 or \u2018Propaganda\u2019 related with \u2018Low\u2019\nfactual reporting and having \u2018Right\u2019 to \u2018Extreme-Right\u2019\nbias. We identified stories related to climate change de-\nnial, vaccination misinformation, and pro-insurrection views\n\u2014 all in violation of PubMatic\u2019s own content guide-\nlines for publishers [59]. Incidentally, a seller ID on Pub-\nmatic was also associated with the largest heterogeneous\npool with 47 unique misinformation websites, including\ndrudgereport.com andworldtruth.tv . Unfortu-\nnately, PubMatic\u2019s sellers.json file did not list the\nseller ID associated with this heterogeneous pool, suggesting\nthat it was employing fabricated or unlisted ID for pooling.\nDcrawlspools and the Google MCM program. In order\nto identify occurrences of pooling in Google\u2019s MCM pro-\ngram, we identified pools associated with the seller IDs\nissued by Google to MCM partners. Of the 203 unique\nheterogeneous pools identified, a vast majority were labeled\nas confidential in Google\u2019s sellers.json [60] but we\nwere able to link 15 to Google\u2019s MCM program based\non public documentation. In total, Google\u2019s MCM partners\nwere associated with 27 misinformation websites. Some of\nthese MCM partners whose Google-issued seller IDs were\npooled by misinformation websites include Adnimation,\nEzoic, etc. Misinformation websites supported by Google\u2019s\nMCM program included 369news.net (pseudoscience or\nanti-vaxx theories) and truthandaction.org (extreme-\nright propaganda and/or misinformation), amongst other\nFigure 6: Dark pooling relationships between AdXs (left)\nand owner domains of AdX-issued pooled IDs (right) for\n297 unique pools observed during the crawls of Mfullweb-\nsites. The counts represent the number of distinct misinfor-\nmation websites pooled.\n11\n0 25 50 75 100 125\nBrand Counts0.00.20.40.60.81.0Fraction of Sites\nFigure 7: Cumulative distribution of the number of distinct\nbrands across different misinformation websites\nsimilar websites. The MCM partners most frequently found\nto be using their Google-issued seller ID for pools contain-\ning misinformation websites were Monumetric (5 pools) and\nFreestar (4 pools).\nTakeaways. Our analysis shows a widespread failure to\nadhere to the ads.txt andsellers.json standards\nand the compliance is even more weaker amongst misinfor-\nmation websites (\u00a74.1). This poor adherence has one major\nconsequence: end-to-end validation of the ad-inventory sup-\nply chain is not always possible, particularly in the case of\nmisinformation websites. Further compounding supply chain\nvalidation challenges, we find that the pooling of seller IDs\nby unrelated publishers is also widespread (\u00a74.2). Misinfor-\nmation websites, which violate the publisher content policies\nof many AdXs, are able to monetize their ad inventory\nthrough these pools. In fact, we find that in many cases\nthey are able to leverage the authorized programs of the\nsame AdXs whose policies they violate.\n5. Brand Analysis\nIn this section, we analyze the display ads loaded on\nmisinformation websites to identify the advertisers/brands\nthat end up buying their ad inventory.\nData collection. We curate Dbrandsby crawling each of the\n669 misinformation websites ten times as discussed in \u00a73.2.\nWe are able to collect a total of 4,246 ads belonging to 2,068\ndistinct brands. Figure 7 plots the distribution of the number\nof distinct brands across misinformation websites. We find\nthat a non-trivial fraction of misinformation websites are\nable to get ads from tens of distinct brands. Specifically, 23\nmisinformation websites have ads from at least 41 distinct\nbrands each while 142 misinformation websites have ads\nfrom at most 10 distinct brands each.\nReputable brand classification and prevalence. To as-\nsess whether these ads are from reputable brands, we use\ntheir Tranco ranks as a rough proxy for their reputation.\nSpecifically, we classify brands with top-1K Tranco rank-\ning as \u201creputable\u201d. Figure 8 shows the number of distinct\nreputable and non-reputable brands across top-20 misinfor-\nmation websites that contain ads from the highest distinct\nbrands. Perhaps surprisingly, we find that Breitbart \u2013 a well-\nknown misinformation website \u2013 is able to attract ads from\nthe highest number of distinct brands. The two reputable\nbrands with ads on Breitbart include Forbes and GoDaddy.\n0 50 100\nBrand Countsactualidadpanamericana.comnewsrescue.comusamagazinestudio.comendtimeheadlines.orgisraelislamandendtimes.compaci\ufb01cpundit.comworldtruth.tvendoftheamericandream.comnewsammo.comimmediatesafety.orgburrardstreetjournal.comin5d.comamericanpatriotdaily.comtheeconomiccollapseblog.comusanetwork.infothedailycheck.netusasupreme.comlibertyunyielding.comreturntonow.netbreitbart.com\nNon-Reputed Brands\nReputed BrandsFigure 8: Distribution of reputable and non-reputable brands\namong the top-20 misinformation websites with the highest\nnumber of distinct brands advertising on their website.\nIn total, we observe ads from 55 reputable brands including\nForbes, GoDaddy, Harvard, Intel, Microsoft, Nike, Samsung,\nTumblr, Yahoo!, Verizon, and Wayfair. We note that these\ntop-20 misinformation websites tend to have more ads from\nreputable brands on average as compared to the remaining\nmisinformation websites. Specifically, the average number\nof reputable brands is 2.05 for the top-20 misinformation\nwebsites in Figure 8 and 0.78 for the remaining misinfor-\nmation websites.\nCorrelation between ad inventory misrepresentation and\nnumber of brands. Next, we investigate whether the mis-\nrepresentation of ad inventory by misinformation websites\nimpacts their ability to sell their ad inventory.\nFigure 9 plots the distribution of the distinct brand\ncounts of all the brands advertising on misinformation web-\nsites with/without ads.txt . Note that we are looking for\nthe existence of ads.txt .7We find that misinformation\nwebsites with ads.txt are able to attract ads from twice\nas many brands on an average as compared to the websites\nwithout ads.txt . We conclude that some brands do avoid\nadvertising on misinformation websites without ads.txt .\nFigure 10 plots the conditional probabilities of ob-\nserving reputable brands across misinformation websites\nwith/without dark pools. We find that more than half of the\nmisinformation websites part of one or more dark pools get\nads from reputable brands. In contrast, less than one-third of\nthe misinformation websites part of no dark pools get ads\nfrom reputable brands. This nearly 20% difference in the\nconditional probability shows that dark pooling significantly\nincreases the chances of ads from reputable brands ending\nup on misinformation websites.\nBrand disclosures. It is reasonable to assume that reputable\nbrands generally do not want to advertise on misinformation\nwebsites [29], [30], [32]. Taking the example of Breitbart,\nthere is ample evidence that reputable brands did not want\n7. The mere existence of ads.txt does not guarantee the veracity of its\ncontent. A misinformative publisher could have misrepresented ads.txt\nentries to bypass brand checks. Advertisers are recommended by IAB to\nperform ads.txt checks against the data observed in the bid requests\nbefore making a bid.\n12\n0 25 50 75 100 125\nBrand Counts0.00.20.40.60.81.0Fraction of SitesWebsites without ads.txt\nWebsites with ads.txtFigure 9: Cumulative distribution of the number of dis-\ntinct brands on misinformation websites with or without\nads.txt\ntheir ads shown on Breitbart [32], [61], [62]. DSPs and\nAdXs typically provide brand safety features [63] to help\nbrands avoid buying the ad inventory of low-quality web-\nsites. Brand safety features allow brands to block unwanted\nad inventory through a block list of domains or seller IDs\n[60]. One would expect that reputable brands would attempt\nto avoid buying the ad inventory of misinformation websites\nthrough these brand safety features. Since brand safety is\nnot externally measurable, we conduct individualized dis-\nclosures to these 55 reputable brands and specifically ask\nthem (a) whether they want their ads on misinformation\nwebsites or not and (b) whether they employ brand safety\nfeatures to this end.\nTo perform disclosures, we first attempted to find\nadvertising-related email addresses for each reputable brand\nfrom their website. If we were unsuccessful, we included\ngeneric email addresses from their \u201cAbout Us\u201d and \u201cContact\nUs\u201d pages. In our disclosures, we listed the misinforma-\ntion websites where the ads of the reputable brand were\nobserved. We included full-page screenshots showing the\nbrand\u2019s ad creative on the misinformation website as well\nas the full HTTP Archive (HAR) recording of the network\ntraffic. We also asked them whether they were aware of or\nintended to have their ads on the misinformation websites\nand whether/which brand safety service they used.\nWe received responses from 11 reputable brands. 8\nbrands confirmed that they were unaware and did not intend\nto advertise on these misinformation websites. For example,\none brand responded that \u201c We don\u2019t advertise on the site. It\nwas an unintentional oversight related to automated adver-\ntising and the ad was immediately pulled when discovered.\nWe always aim to advertise on sites that are aligned with\nour mission and values and we apologize if this upset any of\nour customers. \u201d Another brand mentioned that \u201c We will not\nwant to see our ads on misinformation websites. \u201d Regard-\ning the deployment of brand safety features, we received\nconfirmation from 4 brands that they indeed used a brand\nsafety service but it did not adequately detect or prevent\ntheir ad from appearing on the misinformation website. One\nbrand told us that it used Google Display Network\u2019s built-in\nbrand-safety measure while two brands employed the brand\nsafety service provided by Integral Ad Science (IAS). One\nbrand told us that \u201c the misinformation website disclosed by\nyou [...] is neither present in the logs provided to us by\nour DSP partner nor is flagged by IAS. We think that it is\n0.0 0.2 0.4 0.6 0.8 1.0\nConditional ProbabilityNo reputable brand adsReputable brandsMfullwith 0 dark pools Mfullwith 1+ dark poolsFigure 10: Conditional probabilities of ads from reputable\nbrands in presence or absence of dark pooling\nbeing misplaced on the misinformation website due to dark\npooling. \u201d Another brand told us that \u201c About the brand-safety\nservice, please understand we are not able to tell any detail \u201d\npresumably due to a confidentiality agreement.\nTakeaways. In summary, our results show that the mis-\nrepresentation of ad inventory by misinformation websites\nseems to be correlated with their ability to monetize their\nad inventory through reputable brands. We found that the ad\ninventory of misinformation websites that use dark pooling\nis more likely to be bought by reputable brands. The limited\nresponses from reputable brands suggest that they do not\nwant to advertise on misinformation websites and employ\nbrand safety features to this end.\n6. Related Work\nExamining the online advertising ecosystem. In recent\nyears, there have been many research efforts to bring trans-\nparency to the mechanisms of online advertising. A large\nnumber of these have focused on studying personal data\ncollection and sharing to deliver personalized ads [64]\u2013[69].\nOur work instead focuses on the prevalence of inventory\nfraud, pooling, and its impact on brands.\nInventory fraud. There have been a few measurements\nrelated to ads.txt standard and related inventory fraud\nsince its introduction. However, no work has focused on\nsellers.json or the ad-fraud that emerges by the com-\nbined failure of ads.txt andsellers.json . In 2019,\nBashir et al. [21] gathered and conducted a longitudinal\nanalysis of ads.txt files. They found that these files\nwere riddled with syntactic errors and inconsistencies that\nmade them difficult to process in an automated fashion.\nTingleff [70] and Pastor et al. [71] highlighted flaws of\ntheads.txt standard that undermines its effectiveness in\npreventing ad fraud, albeit without measurements to sup-\nport their hypotheses. Some of these identified flaws are,\nhowever, supported by measurements from Papadogiannakis\net al. [72]. These findings, suggesting that the ads.txt\nstandard is not effectively enforced, are corroborated by our\nstudy. Our work complements these efforts by undertaking a\nmeasurement study of both the standards of ads.txt and\nsellers.json for the first time to measure inventory\nfraud as well as prevalence of pooling, which allows low-\nquality publishers to launder their ad inventory.\n13\nBrand safety. There have been many studies that have\nhighlighted the impact of ads (and the websites on which\nthey appear) on the reputation of a brand [28], [63], [73],\n[74]. In fact, several activist efforts have successfully lever-\naged brand safety concerns to demonetize misinformation.\nNotable among these are the efforts of Check My Ads\nand Sleeping Giants [75], who successfully used public\ncampaigns to pressurize 820 brands to add Breitbart News\u2019\ndomain to their advertising block lists. Our cataloging of\nbrands found on known misinformation websites can supple-\nment these ad-hoc efforts and increase pressure on ad-tech to\nenforce its own ads.txt andsellers.json standards\nmore effectively. Other work has focused on measuring or\nimproving the effectiveness of mechanisms for identifying\n\u2018brand safe\u2019 web content. Most recently, V o et al. [76]\nbuilt an image-based brand-safety classifier to prevent ad\nplacement on inappropriate pages. Numerous products from\nmajor ad-tech firms such as DoubleVerify [77], Integral Ad\nScience [78], and Oracle [79] have also recently started\npromoting their \u2018brand safety\u2019 features.\nFunding infrastructure of misinformation. Ours is not\nthe first work to consider the role of the online advertising\necosystem in funding misinformation. In fact, it has been\nknown for several years that online advertising provides the\nprimary revenue stream for misinformation websites [80]\u2013\n[84]. Han et al. [85], in their study, focused on network\ninfrastructure, also explored the revenue streams on mis-\ninformation websites and identified disproportionately high\nreliance on advertising and consumer donations.\nBozarth et al. [86] showed that although there is a\nunique ecosystem of \u2018risky\u2019 AdXs that partner with pub-\nlishers of misinformation, there is also a heavy presence\nof mainstream AdXs (e.g., Google) in the misinformation\necosystem.\nBraun & Eklund [87] take a qualitative approach to\nunderstand the role of the advertising ecosystem in in-\ncreasing revenues of misinformation and the dismantling\nof traditional journalism. Their work, along with numerous\nothers [88]\u2013[90], has highlighted the need for additional\ntransparency to realize the promise of market-based strate-\ngies to curb funding of misinformation.\nConsidering another angle, several studies have also\nexamined how deceptive ads are used to promote and fund\nharmful products [91]\u2013[93] and ideologies [43], [94], [95].\nAt a high-level, our work complements all these efforts\nto better understand how the misinformation ecosystem is\nfunded by online advertising by uncovering and analyzing\nthe exploitation of specific advertising-related vulnerabilities\nsuch as pooling and relationship misrepresentations by the\nmisinformation ecosystem.\n7. Concluding Remarks\nOur work shows how the opacity of the ad-tech supply\nchain is exploited by misinformation publishers to mon-\netize their ad inventory. Through our measurements, we\ndemonstrate a widespread lack of compliance with the IAB\u2019sads.txt andsellers.json standards, ad inventory\npooling by misinformation publishers, and reputed brands\nwho end up buying this ad inventory of misinformation\npublishers. Taken all together, our results point to specific\ngaps that need to be further explored by the ad-tech and\nsecurity research communities.\nTrust delegation in advertising partner programs. One\nof our key findings is that a small number of ad exchanges\nare responsible for a majority of dark pooling. In many\ncases, we see evidence that this dark pooling is achieved\nthrough the use of legitimate partner programs made avail-\nable by ad exchanges (e.g., Google\u2019s MCM partner program\n[56]). These programs serve an important purpose \u2014 to\nhelp reduce the management burdens on small publishers.\nHowever, as we see in our study, this expanded access\nfacilitated via advertising partners results in new vulnera-\nbilities. Specifically, publishers who are in clear violation\nof the policies set by an ad exchange are still able to obtain\nseller IDs issued by the exchange through their partners.\nOne perspective of this problem is that there is a funda-\nmental breakdown of trust delegation \u2014 i.e., partners are\ndelegated the rights to assign and manage seller IDs on\nbehalf of exchanges, but without being properly delegated\nthe responsibilities for vetting publishers and verifying their\ncompliance with ad exchange policies. While this work is\nthe first to uncover this delegation of trust in the form of\nverification responsibilities in the ad-tech ecosystem, it is\nnot new to the security community. Indeed, this type of trust\ndelegation is a central theme in the public key infrastructure\n[96], app stores [97], and other domains. From these prior\nefforts to delegate verification responsibilities, it is clear that\nsuccess is only possible with effective mechanisms to moni-\ntor compliance and revoke delegated trust. A key difference\nfrom prior efforts, however, is that it is not publicly known\nhow these trust delegation processes work within specific ad\nexchanges. Without public documentation of these processes\nor research studies that uncover them, we anticipate that\nidentifying weaknesses and causes for failure will remain\nan open challenge.\nSupply chain transparency and compliance with in-\ndustry standards. The programmatic advertising supply\nchain is complex because of the large number of enti-\nties involved between publishers and advertisers. Further\ncomplicating matters, our study shows that these entities\nare frequently out of compliance with even basic standards\nsuch as ads.txt andsellers.json . In fact, many of\nthe concerning findings of our work could be addressed if\nadvertisers were able to trace the provenance of ad inventory\nusing the existing \u2018Supply Chain Object\u2019 (SCO) ad-tech\nstandard. Unfortunately, our analysis of SCOs in \u00a7B shows\nthat less than a quarter of bid requests actually include\nthe SCO. Further, even when the SCO is included in bid\nrequests, they are often incomplete and missing information\nwould make end-to-end verification of the supply chain\ndifficult. We further find that even major ad exchanges\nimplement digital advertising standards in a way that hinders\nexternal independent audits. Notably, Google\u2019s widespread\n14\nuse of confidential sellers.json entries [60] makes it\nchallenging to identify Google AdX\u2019s partners who are not\ndoing adequate compliance verification for the publishers\nwhose inventory they list. IAB has recently released new and\nupdated digital advertising standards [98], [99] to improve\nend-to-end validation of the ad-tech supply chain. However,\nthese are not widely adopted yet. Therefore, in its current\nstate, to mitigate ad fraud and reduce ad-tech\u2019s inadver-\ntent funding of misinformation, it is crucial that adoption\nand compliance with new and existing digital advertising\nstandards such as SCO, ads.txt , and sellers.json\nimprove. However, a key challenge is the absence of in-\ncentives for achieving compliance with these standards. It\nremains to be seen if recent US regulatory efforts will\nimprove compliance. Notably, the Digital Services Oversight\nand Safety Act (DSOSA) [100] and Advertising Middle-\nmen Endangering Rigorous Internet Competition Account-\nability Act (AMERICA) [101] introduce new requirements\nrelated to online advertising transparency. In addition, we\nare currently engaged in conversations with members of US\nCongress seeking to draft additional legislation specifically\nto strengthen compliance with ad-tech industry standards,\nimprove transparency around the ad-tech supply chain, and\nmitigate ad fraud.\nEffective notification and vulnerability reporting mech-\nanisms. The ad-tech industry is currently lacking mech-\nanisms through which supply chain vulnerabilities may be\nreported. This absence has resulted in several community-\norganized efforts such as the Check My Ads Institute [31]\nthat monitor ads on misinformation websites and use social\nmedia to report on the brands or ad-tech loopholes that fund\nthese publishers. While these efforts have been successful\nat mitigating some of the harms from the opacity of the\nsupply chain, they are not systematic reports and rely on\namplification via social media in order to reach their in-\ntended targets. Further, like our study, they generally focus\non specific harms caused by the opacity of ad-tech (e.g.,\nfunding of misinformation). There is a need to develop more\ngeneralized and systematic mechanisms for reporting sup-\nply chain vulnerabilities and non-compliance with existing\nindustry standards.\nFor reproducibility and to foster follow-up research,\nour dataset is available at https://osf .io/hxfkw/?view only=\nbda006ebbd7d4ec2be869cbb198c6bd5\nAcknowledgment\nThis work is supported in part by the National Science\nFoundation under grant numbers 2103439, 2103038, and\n2138139. We want to thank the anonymous shepherd and re-\nviewers for their constructive feedback that helped improve\nthe work.\nReferences\n[1] Shuai Yuan, Jun Wang, and Xiaoxue Zhao. Real-time bidding\nfor online advertising: measurement and analysis. In Proceedings\nof the seventh international workshop on data mining for online\nadvertising , 2013.[2] OpenRTB Guidelines. IAB: https://www .iab.com/guidelines/\nopenrtb/, 2022.\n[3] Display ad-tech Lumascape. https://lumapartners .com/content/\nlumascapes/display-ad-tech-lumascape/.\n[4] What\u2019s the Difference Between Waterfall Auctions & Header\nBidding? https://clearcode .cc/blog/difference-waterfall-header-\nbidding/, 2022.\n[5] Sumayah A. Alrwais, Alexandre Gerber, Christopher W. Dunn,\nOliver Spatscheck, Minaxi Gupta, and Eric Osterweil. Dissecting\nghost clicks: Ad fraud via misdirected human clicks. In Proceedings\nof the 28th Annual Computer Security Applications Conference\n(ACSAC) , 2012.\n[6] Brett Stone-Gross, Ryan Stevens, Apostolis Zarras, Richard Kem-\nmerer, Chris Kruegel, and Giovanni Vigna. Understanding fraudulent\nactivities in online ad exchanges. In Proceedings of the ACM Internet\nMeasurement Conference , 2011.\n[7] Jonathan Crussell, Ryan Stevens, and Hao Chen. Madfraud: Inves-\ntigating ad fraud in android applications. In Proceedings of the 12th\nAnnual International Conference on Mobile Systems, Applications,\nand Services , 2014.\n[8] Vacha Dave, Saikat Guha, and Yin Zhang. Measuring and finger-\nprinting click-spam in ad networks. In Proceedings of the ACM\nSIGCOMM Conference , 2012.\n[9] Apostolis Zarras, Alexandros Kapravelos, Gianluca Stringhini,\nThorsten Holz, Christopher Kruegel, and Giovanni Vigna. The dark\nalleys of madison avenue: Understanding malicious advertisements.\nInProceedings of the ACM Conference on Internet Measurement\nConference , 2014.\n[10] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.\nShady paths: Leveraging surfing crowds to detect malicious web\npages. In Proceedings of the ACM SIGSAC Conference on Computer\n& Communications Security , 2013.\n[11] Kurt Thomas, Elie Bursztein, Chris Grier, Grant Ho, Nav Jagpal,\nAlexandros Kapravelos, Damon Mccoy, Antonio Nappa, Vern Pax-\nson, Paul Pearce, Niels Provos, and Moheeb Abu Rajab. Ad injection\nat scale: Assessing deceptive advertisement modifications. In IEEE\nSymposium on Security and Privacy , 2015.\n[12] Shishir Nagaraja and Ryan Shah. Clicktok: Click fraud detection\nusing traffic analysis. In Proceedings of the Conference on Security\nand Privacy in Wireless and Mobile Networks , 2019.\n[13] Suibin Sun, Le Yu, Xiaokuan Zhang, Minhui Xue, Ren Zhou,\nHaojin Zhu, Shuang Hao, and Xiaodong Lin. Understanding and\ndetecting mobile ad fraud through the lens of invalid traffic. In\nProceedings of the 2021 ACM SIGSAC Conference on Computer\nand Communications Security (CCS) , 2021.\n[14] Mobin Javed, Cormac Herley, Marcus Peinado, and Vern Paxson.\nMeasurement and analysis of traffic exchange services. In Proceed-\nings of the ACM Internet Measurement Conference , 2015.\n[15] Shehroze Farooqi, Guillaume Jourjon, Muhammad Ikram, Mo-\nhamed Ali Kaafar, Emiliano De Cristofaro, Zubair Shafiq, Arik\nFriedman, and Fareed Zaffar. Characterizing key stakeholders in an\nonline black-hat marketplace. In APWG Symposium on Electronic\nCrime Research (eCrime) , 2017.\n[16] Manolis Chalkiadakis, Alexandros Kornilakis, Panagiotis Pa-\npadopoulos, Evangelos Markatos, and Nicolas Kourtellis. The rise\nand fall of fake news sites: A traffic analysis. In ACM Web Science\nConference , 2021.\n[17] Inside the Macedonian Fake News Complex. https:\n//www .wired .com/2017/02/veles-macedonia-fake-news/, 2022.\n[18] How teens in the balkans are duping trump supporters\nwith fake news. https://www .buzzfeednews .com/article/\ncraigsilverman/how-macedonia-became-a-global-hub-for-pro-\ntrump-misinfo# .fu2okXaeKo.\n15\n[19] How Facebook powers money machines for obscure political\nnews sites. https://www .theguardian .com/technology/2016/aug/24/\nfacebook-clickbait-political-news-sites-us-election-trump, 2016.\n[20] IAB Brand-safety. https://www .iab.com/topics/brand-safety/, 2022.\n[21] Muhammad Ahmad Bashir, Sajjad Arshad, Engin Kirda, William\nRobertson, and Christo Wilson. A longitudinal analysis of the ads.\ntxt standard. In ACM Internet Measurement Conference , 2019.\n[22] What is domain spoofing? https://www .adpushup .com/blog/what-\nis-domain-spoofing/, 2017.\n[23] Domain spoofing remains a huge threat to programmatic.\nhttps://digiday .com/marketing/domain-spoofing-remains-an-ad-\nfraud-problem/, 2017.\n[24] The Sentencing of The King Of Fraud and the Birth of Collective\nProtection. https://www .humansecurity .com/learn/blog/the-\nsentencing-of-the-king-of-fraud-and-the-birth-of-collective-\nprotection, 2021.\n[25] The four types of domain spoofing. https://integralads .com/insider/\nthe-four-types-of-domain-spoofing/, 2018.\n[26] IAB ads.txt Specifications. https://iabtechlab .com/ads-txt/, 2017.\n[27] IAB sellers.json Specifications. https://iabtechlab .com/sellers-json/,\n2019.\n[28] Chunsik Lee, Junga Kim, and Joon Soo Lim. Spillover effects of\nbrand safety violations in social media. Journal of Current Issues\n& Research in Advertising , 2021.\n[29] New ias report uncovers how consumer perception of misleading\ncontent impacts brand favorability. https://integralads .com/news/\nmisinformation-consumer-research/, 2022.\n[30] New ias report uncovers how misleading content impacts digital\nadvertising. https://integralads .com/news/new-ias-report-uncovers-\nhow-misleading-content-impacts-digital-advertising/, 2022.\n[31] Check My Ads Institute. https://checkmyads .org/, 2022.\n[32] List of advertisers that demonetized breitbart. https://twitter .com/\nslpng giants/status/1200473586886205440, 2020.\n[33] Cvs blocks breitbart. https://mobile .twitter .com/slpng giants/status/\n808381433173577730, 2016.\n[34] Further investigation into the \u201cdark pool sales house\u201d phenomenon.\nhttps://deepsee .io/blog/non-unique-pub-ids, 2021.\n[35] Murky ad-tech tactics: What you should know about dark pool sales\nhouses. https://www .adweek .com/media/dark-pool-sales-houses-\nwhat-you-need-to-know/, 2021.\n[36] Google openrtb integration. https://developers .google .com/\nauthorized-buyers/rtb/openrtb-guide.\n[37] Vungle openrtb integration. https://support .vungle .com/hc/\nen-us/articles/360045953431-Vungle-Exchange-OpenRTB-2-5-\nIntegration-Guide#3-2-2-source-ext-schain-nodes-object-0-12,\n2022.\n[38] Doubleclick for publishers. https://www .adpushup .com/blog/\ngoogle-dfp-doubleclick-for-publishers/, 2021.\n[39] Victor Le Pochat, Tom Van Goethem, Samaneh Tajalizadehkhoob,\nMaciej Korczy \u00b4nski, and Wouter Joosen. Tranco list. https://tranco-\nlist.eu. Accessed on 27th Oct, 2021.\n[40] Maciej Szpakowski and Renato. Fake news corpus. https://\ngithub .com/several27/FakeNewsCorpus, Feb 2018.\n[41] Media Bias/Fact Check Team. Media bias/fact check: The most com-\nprehensive media bias resource. https://mediabiasfactcheck .com.\n[42] Austin Hounsel, Jordan Holland, Ben Kaiser, Kevin Borgolte, Nick\nFeamster, and Jonathan Mayer. Identifying disinformation websites\nusing infrastructure features. In 10th USENIX Workshop on Free\nand Open Communications on the Internet (FOCI) , 2020.[43] Eric Zeng, Tadayoshi Kohno, and Franziska Roesner. Bad news:\nClickbait and deceptive ads on news and misinformation websites.\nInWorkshop on Technology and Consumer Protection (ConPro) ,\n2020.\n[44] Syed Suleman Ahmad, Muhammad Daniyal Dar, Zareed Zaffar,\nNarseo Vallina-Rodriguez, Rishab Nithyanand, et al. Apophanies\nor epiphanies: How crawlers can impact our understanding of the\nweb. In The Web Conference , 2020.\n[45] Jordan Jueckstock, Shaown Sarker, Peter Snyder, Aidan Beggs,\nPanagiotis Papadopoulos, Matteo Varvello, Benjamin Livshits, and\nAlexandros Kapravelos. Towards realistic and reproducibleweb\ncrawl measurements. In Proceedings of the Web Conference , 2021.\n[46] John Cook, Rishab Nithyanand, and Zubair Shafiq. Inferring tracker-\nadvertiser relationships in the online advertising ecosystem using\nheader bidding. Proceedings on Privacy Enhancing Technologies ,\n1, 2020.\n[47] Maaz Bin Musa and Rishab Nithyanand. Atom: Ad-network tomog-\nraphy. a generalizable technique for inferring tracker-advertiser data\nsharing in the online behavioral advertising ecosystem. Proceedings\non Privacy Enhancing Technologies , 2022.\n[48] Umar Iqbal, Peter Snyder, Shitong Zhu, Benjamin Livshits, Zhiyun\nQian, and Zubair Shafiq. Adgraph: A graph-based approach to ad\nand tracker blocking. In IEEE Symposium on Security and Privacy ,\n2020.\n[49] Panagiotis Papadopoulos, Nicolas Kourtellis, Pablo Rodriguez Ro-\ndriguez, and Nikolaos Laoutaris. If you are not paying for it, you\nare the product: How much do advertisers pay to reach you? In\nProceedings of the 2017 Internet Measurement Conference , 2017.\n[50] Menlo report. https://www .dhs.gov/sites/default/files/publications/\nCSD-MenloPrinciplesCORE-20120803 1.pdf, 2012.\n[51] Belmont report. https://www .hhs.gov/ohrp/regulations-and-policy/\nbelmont-report/read-the-belmont-report/index .html, 1979.\n[52] Robots.txt meant for search engines don\u2019t work well for web\narchives. https://blog .archive .org/2017/04/17/robots-txt-meant-for-\nsearch-engines-dont-work-well-for-web-archives, 2017.\n[53] Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric\nLangbort. Auditing algorithms: Research methods for detecting\ndiscrimination on internet platforms. Data and discrimination:\nconverting critical concerns into productive inquiry , 22(2014), 2014.\n[54] Madison Addicks. Van buren v. united states: The supreme court\u2019s\nruling on the fate of web scraping-\u201d access\u201d to discovery or deten-\ntion? Tul. J. Tech. & Intell. Prop. , 24, 2022.\n[55] Github \u2014 duckduckgo tracker-radar/entities. https://github .com/\nduckduckgo/tracker-radar/tree/main/entities.\n[56] Overview of MCM - Google AdMob Help. https:\n//support .google .com/admob/answer/9142605?hl=en.\n[57] Misrepresentation - Advertising Policies Help. Google Advertising\nPolicies, https://support .google .com/adspolicy/answer/6020955?hl=\nen&ref topic=1626336, 2022.\n[58] GumGum \u2014 Prohibited Content Policy for Buyers and Sellers.\nhttps://gumgum .com/terms-and-policies/buyer-policy, 2022.\n[59] Supply policy. Pubmatic, 2022.\n[60] Porn, piracy, fraud: What lurks inside google\u2019s black box ad em-\npire. https://www .propublica .org/article/google-display-ads-piracy-\nporn-fraud, 2022.\n[61] Sunrun blocks breitbart. https://twitter .com/slpng giants/status/\n1024019694523695111, 2018.\n[62] Sagenamerica blocks breitbart. https://twitter .com/slpng giants/\nstatus/913821166304763904, 2017.\n[63] Steven Bellman, Ziad HS Abdelmoety, Jamie Murphy, Shruthi Aris-\nmendez, and Duane Varan. Brand safety: the effects of controversial\nvideo content on pre-roll advertising. Heliyon , 4(12), 2018.\n16\n[64] Steven Englehardt and Arvind Narayanan. Online tracking: A\n1-million-site measurement and analysis. In Proceedings of the\n2016 ACM SIGSAC conference on computer and communications\nsecurity , 2016.\n[65] Abbas Razaghpanah, Rishab Nithyanand, Narseo Vallina-Rodriguez,\nSrikanth Sundaresan, Mark Allman, Christian Kreibich, Phillipa\nGill, et al. Apps, trackers, privacy, and regulators: A global study\nof the mobile tracking ecosystem. In The 25th Annual Network and\nDistributed System Security Symposium (NDSS 2018) , 2018.\n[66] Muhammad Ahmad Bashir, Sajjad Arshad, William Robertson, and\nChristo Wilson. Tracing information flows between ad exchanges\nusing retargeted ads. In USENIX Security Symposium , 2016.\n[67] Aaron Cahn, Scott Alfeld, Paul Barford, and Shanmugavelayutham\nMuthukrishnan. An empirical study of web cookies. In Proceedings\nof the 25th international conference on world wide web , 2016.\n[68] Yash Vekaria, Vibhor Agarwal, Pushkal Agarwal, Sangeeta Mahap-\natra, Sakthi Balan Muthiah, Nishanth Sastry, and Nicolas Kourtellis.\nDifferential tracking across topical webpages of indian news media.\nInACM Web Science Conference , 2021.\n[69] Marjan Falahrastegar, Hamed Haddadi, Steve Uhlig, and Richard\nMortier. The rise of panopticons: Examining region-specific third-\nparty web tracking. In International Workshop on Traffic Monitoring\nand Analysis . Springer, 2014.\n[70] S Tingleff. The Three Deadly Sins of Ads. Txt and How Publish-\ners Can Avoid Them. https://iabtechlab .com/blog/the-three-deadly-\nsins-of-ads-txt-and-how-publishers-can-avoid-them, 2019.\n[71] Antonio Pastor, Rub \u00b4en Cuevas, \u00b4Angel Cuevas, and Arturo Azcorra.\nEstablishing trust in online advertising with signed transactions.\nIEEE Access , 9, 2020.\n[72] Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos\nP. Markatos, and Nicolas Kourtellis. Who funds misinformation?\na systematic analysis of the ad-related profit routines of fake news\nsites. In Proceedings of the ACM Web Conference 2023 , pages\n2765\u20132776, 2023.\n[73] Edlira Shehu, Nadia Abou Nabout, and Michel Clement. The risk of\nprogrammatic advertising: Effects of website quality on advertising\neffectiveness. International Journal of Research in Marketing , 38(3),\n2021.\n[74] Sophie Bishop. Influencer management tools: Algorithmic cultures,\nbrand safety, and bias. Social Media+ Society , 7(1), 2021.\n[75] Claudia Pereira Ferraz. Sleeping giants and indirect boycotts against\nthe far right in united states of america. Aurora. , 14(40), 2021.\n[76] Quan Minh V o, Nhan Thi Cao, and An Hoa Ton-That. Unsafe image\nclassification using convolutional neural network for brand safety.\nInIEEE Asia-Pacific Conference on Computer Science and Data\nEngineering (CSDE) , 2020.\n[77] Doubleverify unveils expanded brand safety & brand\nsuitability integration with facebook - doubleverify.\nhttps://doubleverify .com/newsroom/doubleverify-unveils-expanded-\nbrand-safety-brand-suitability-integration-with-facebook/.\n[78] Integral ad science \u2014 brand safety & suitability solutions. https:\n//integralads .com/solutions/brand-safety-suitability/.\n[79] Oracle moat measurement \u2014 oracle advertising. https://\nwww.oracle .com/cx/advertising/measurement/.\n[80] Nir Kshetri and Jeffrey V oas. The economics of \u201cfake news\u201d. IT\nProfessional , 19(6), 2017.\n[81] Arvind Hickman. Advertisers spend $2.6bn on misinformation web-\nsites, study finds. https://www .campaignlive .com/article/advertisers-\nspend-26bn-misinformation-websites-study-finds/1725293, Aug\n2021.\n[82] Global Disinformation Index. Cutting the funding of disinformation:\nThe ad-tech solution. https://disinformationindex .org/wp-content/\nuploads/2019/05/GDI Report Screen AW2.pdf, May 2019.[83] Global Disinformation Index. The quarter billion\ndollar question: How is disinformation gaming ad tech?\nhttps://disinformationindex .org/wp-content/uploads/2019/09/GDI\nAd-tech Report Screen AW16 .pdf, Sep 2019.\n[84] Augustine Fou. Big advertisers still fund hate and disinformation\noutside of facebook. https://www .forbes .com/sites/augustinefou/\n2020/07/06/big-advertisers-still-fund-hate-and-disinformation-\noutside-of-facebook/?sh=383aa3376f78, July 2020.\n[85] Catherine Han, Deepak Kumar, and Zakir Durumeric. On the\ninfrastructure providers that support misinformation websites. In\nProceedings of the International AAAI Conference on Web and\nSocial Media , 2022.\n[86] Lia Bozarth and Ceren Budak. Market forces: Quantifying the role\nof top credible ad servers in the fake news ecosystem. In The\nInternational AAAI Conference on Web and Social Media , 2020.\n[87] Joshua A Braun and Jessica L Eklund. Fake news, real money: Ad\ntech platforms, profit-driven hoaxes, and the business of journalism.\nDigital Journalism , 7(1), 2019.\n[88] Joel Timmer. Fighting falsity: Fake news, Facebook, and the first\namendment. Cardozo Arts & Ent. LJ , 35, 2016.\n[89] Damian Tambini. Fake news: public policy responses. 2017.\n[90] Norman Vasu, Benjamin Ang, Terri-Anne Teo, Shashi Jayakumar,\nMuhammad Raizal, and Juhi Ahuja. Fake news: National security\nin the post-truth era . S. Rajaratnam School of International Studies.,\n2018.\n[91] Yelena Mejova and Kyriaki Kalimeri. Advertisers jump on coro-\nnavirus bandwagon: Politics, news, and business. arXiv preprint\narXiv:2003.00923 , 2020.\n[92] Amelia M Jamison, David A Broniatowski, Mark Dredze, Zach\nWood-Doughty, DureAden Khan, and Sandra Crouse Quinn.\nVaccine-related advertising in the facebook ad archive. Vaccine ,\n38(3), 2020.\n[93] Vanessa Boudewyns, Brian G Southwell, Kevin R Betts, Cather-\nine Slota Gupta, Ryan S Paquin, Amie C O\u2019Donoghue, and Natasha\nVazquez. Two awareness of misinformation in health-related adver-\ntising: A narrative review of the literature. Misinformation and mass\naudiences , 2021.\n[94] Eric Zeng, Miranda Wei, Theo Gregersen, Tadayoshi Kohno, and\nFranziska Roesner. Polls, clickbait, and commemorative $2 bills:\nproblematic political advertising on news and media websites around\nthe 2020 US elections. In Proceedings of the 21st ACM Internet\nMeasurement Conference , 2021.\n[95] Yingying Chen and Luping Wang. Misleading political advertising\nfuels incivility online: A social network analysis of 2020 US presi-\ndential election campaign video comments on YouTube. Computers\nin Human Behavior , 2022.\n[96] Laurent Chuat, AbdelRahman Abdou, Ralf Sasse, Christoph\nSprenger, David Basin, and Adrian Perrig. Sok: Delegation and\nrevocation, the missing links in the web\u2019s chain of trust. In IEEE\nEuropean Symposium on Security and Privacy (EuroS&P) , 2020.\n[97] Fuqi Lin, Haoyu Wang, Liu Wang, and Xuanzhe Liu. A longitudinal\nstudy of removed apps in iOS app store. In Proceedings of the Web\nConference , 2021.\n[98] Ads.cert 2.0. https://iabtechlab .com/ads-cert/, 2022.\n[99] ads.txt Version 1.1. https://iabtechlab .com/wp-content/uploads/\n2022/04/Ads .txt-1.1.pdf, 2022.\n[100] H.R.6796 - Digital Services Oversight and Safety Act of 2022. https:\n//www .congress .gov/bill/117th-congress/house-bill/6796/text, 2022.\n[101] S.1073 - Advertising Middlemen Endangering Rigorous Internet\nCompetition Accountability Act or the AMERICA Act. https://\nwww.congress .gov/bill/118th-congress/senate-bill/1073/text, 2023.\n17\nAppendix A.\nLongitudinal Analysis of sellers.json\nVarious campaigns have highlighted the role of AdXs in\nmonetizing the misinformation ecosystem, pressuring them\nto remove their support for these domains [31]. To under-\nstand the effectiveness of these campaigns, we monitored\nchanges to the sellers.json files present in our Dstatic\n.\ndataset for a three-month period (from Oct\u201921 to Feb\u201922).\nOf the 470 AdXs found to support misinformation web-\nsites (by listing them as publishers) on October 2021, 39\n(8.3%) AdXs delisted at least one misinformation website\nby February 2022.\nBashir et. al. [21] performed this analysis on ads.txt\nof Alexa Top-100K websites in their work. However, our\nstudy is on misinformation websites, whose ads.txt\nshould not be trusted. Hence, we perform this analysis on\nsellers.json files of trusted AdXs.\nWe observed 470 sellers.json supporting at least\none misinformation website as per October\u2019s crawl \u2013 46 of\nwhich support 10 or more misinformation outlets. The ones\nthat support the highest misinformation websites are revcon-\ntent.com (204), liveintent.com (56), outbrain.com (56), pix-\nfuture.com (39), and lijit.com (now part of Sovrn ) (30).\nFrom Oct\u201921 to Feb\u201922, only 39 AdXs de-list at least 1\nmisinformation website, while 53 sellers.json include\nat least 1 misinformation website in their files. Table 7\nshows the top AdXs and their longitudinal support for the\nmisinformation websites in their sellers.json .\nAd exchangeMisinformation Website Counts\nOct\u201921 Feb\u201922 Added Dropped\nrevcontent.com 204 73 2 133\noutbrain.com 56 35 0 21\n9mediaonline.com 20 1 0 20\nstitchvideo.tv 14 1 0 13\nadtelligent.com 26 28 13 11\ninfolinks.com 23 14 2 11\npublisherdesk.com 14 3 0 11\nmgid.com 20 32 13 1\nnextmillennium.io 7 9 3 1\nvidazoo.com 5 8 3 0\npixfuture.com 39 41 2 0\nlijit.com 30 30 0 0\nTABLE 7: AdXs that add and drop the most misinformation\nwebsites from their sellers.json between Oct\u201921 and\nFeb\u201922. The table is arranged in descending order of the\ndropped counts.\nUpon further investigation of RevContent, we observed\nthat it dropped \u223c87% of the total publisher domains from\ntheir sellers.json in mid-December 2021 (Oct\u201921:\n4727 domains to Feb\u201922: 621 domains) and we speculate\nthat their primary aim might not have been to drop mis-\ninformation websites, but they ended up de-listing a few\nof misinformation websites too as a result of their bulk\ndrop. There has always been a constant peer-pressure and\ncriticism from activists (e.g., [31]) forcing RevContent to re-\nmove their support for misinformation websites. There wereactive discussions on social media speculating RevContent\u2019s\nintent behind this massive drop. However, RevContent did\nthis silently and never publicly addressed this action. Even\nafter the drop, RevContent still potentially funds the most\nmisinformation websites in our data. Other than RevContent,\nother AdXs that continued their support for the highest mis-\ninformation websites in Feb\u201922 are LiveIntent (56), Pixfuture\n(41), Outbrain (35), and MGID (32).\nAdditionally, the misinformation outlets which were\nadded by the most AdXs are rearfront.com ,vidmax.com ,\nand thetruereporter.com . The former 2 outlets are agents\nof spreading viral and misleading content, while the latter\npublishes politicized news, commentary and analysis. These\nwere added by 6 different AdXs. Similarly, lifezette.com ,\nwaynedupree.com , and news18.co were dropped by 6, 6, and\n5 AdXs respectively.\nAppendix B.\nSupply Chain Object Analysis\nIf adopted and implemented correctly, Supply Chain\nObjects (SCOs) can aid overall validation and provide trans-\nparency into all the entities involved in (re-)selling of a\nparticular ad-inventory. In absence of SCOs, a buyer has\nvisibility into only the immediate upstream seller but not\nthe entire path of (re-)sellers that were involved before the\nupstream seller. It is the job of each seller to append its\nseller object in the existing SCO and forward the bid request\nfurther. A buyer extracts the SCO object from the bid request\nand parses the list of all seller nodes represented by key\nnodes . Higher the index of a node in this list, the more\nrecent the seller. When an AdX forwards the bid request\nfor a publisher, it associates the publisher with dictionary\nkeyasi and the account identifier for that publisher in its\nnetwork with the key sid.\nIn order to analyze the adoption and correctness of SCOs\nin our data, we use our custom SCO parser (based on the\nIAB guidelines) on all the bid requests captured in the\nDcrawlsdataset. Despite SCOs being introduced by IAB since\nJuly 2019, only 20.5% (3796) bid requests have included\nSCOs, all of which comprised only a single seller node. To\nverify the correctness of SCOs, we extracted sid andasi\nassociated with the seller node and performed sid lookup in\nthesellers.json file of the asi to obtain the upstream\nseller domain with which the ad-inventory is associated as\nper the SCO. Next, we checked if this website domain\nmatched the actual website\u2019s domain on which the current\nbid request was captured during the dynamic crawl. Let\u2019s\ncall this boolean result \u2013 A. We also validated all 3796 SCO-\nbased paths (upstream website \u2192asi seller\u2192ad-request\ndomain) against 3-hop static paths involving each misinfor-\nmation website generated from the sellers.json files.\nLet\u2019s call this boolean result \u2013 B. The cases where A and B\nwere True are cases where we could verify the correctness\nof the SCOs. The rest cases were SCO misrepresentations.\nWe observed only 18.94% (719) of 3796 bid requests with\ncorrect implementation of SCOs.\n18", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The inventory is dark and full of misinformation: understanding the abuse of ad inventory pooling in the ad-tech supply chain", "author": ["Y Vekaria", "R Nithyanand", "Z Shafiq"], "pub_year": "2022", "venue": "arXiv preprint arXiv:2210.06654", "abstract": "Ad-tech enables publishers to programmatically sell their ad inventory to millions of demand  partners through a complex supply chain. Bogus or low quality publishers can exploit the"}, "filled": false, "gsrank": 560, "pub_url": "https://arxiv.org/abs/2210.06654", "author_id": ["zoft_JcAAAAJ", "iFjAUN8AAAAJ", "Q3FvLzUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZqecPYnbRZMJ:scholar.google.com/&output=cite&scirp=559&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D550%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZqecPYnbRZMJ&ei=arWsaN3ZIfnSieoPxKLpgQ0&json=", "num_citations": 6, "citedby_url": "/scholar?cites=10612129479459120998&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZqecPYnbRZMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2210.06654"}}]