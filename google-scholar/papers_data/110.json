[{"title": "Assessing the risks of 'infodemics' in response to COVID-19 epidemics", "year": "2020", "pdf_data": "Articles\nhttps:/ / doi.org/10.1038/s41562-020-00994-61CoMuNe Lab, Fondazione Bruno Kessler, T rento, Italy. 2IULM University, Milan, Italy. 3Fondazione Bruno Kessler, T rento, Italy. \u2709e-mail: pierluigi.sacco@iulm.it; \nmdedomenico@fbk.euThe recent explosion of publicly shared, decentralized infor -\nmation production that characterizes digital societies1 and in \nparticular social media activity2 provides an exceptional labo -\nratory for the observation and study of complex social dynamics3, \nand potentially functions as a laboratory to understand, test and \nvalidate possible solutions to large-scale crises4. Pandemics are an \ninstance of such crises, and the current outbreak of COVID-19 may therefore be thought of as a natural experiment to observe social \nresponses to a major threat that may escalate to catastrophic lev\n-\nels and has already managed to seriously affect levels of economic \nactivity and radically alter human social behaviours across the globe. In this study, we show that information dynamics tailored \nto alter individuals\u2019 perceptions, and potentially their behavioural \nresponses, is associated with a shift of collective attention\n5 towards \nfalse6,7 or inflammatory8 content, a phenomenon named infodemic \n(that is, an epidemic of information)9\u201312, sharing similarities with \nmore traditional epidemics and spreading phenomena13\u201315.\nContrary to what could be expected in principle, this natural \nexperiment reveals that, on the verge of a threatening global pan -\ndemic emergency due to SARS-CoV-2 (refs. 16\u201318), human com -\nmunication activity is largely characterized by the production of informational noise and even of misleading or false information\n19. \nThis generates waves of unreliable and low-quality informa -\ntion with potentially dangerous impacts on society\u2019s capacity to respond adaptively at all scales by rapidly adopting those norms and behaviours that may effectively contain the propagation of the \npandemic\n20. Spreading false or misleading information may pre -\nvent the timely and effective adoption of appropriate behaviours \nand of public health recommendations or measures21. Therefore, \non the one hand, we face the threats of a pandemic, which spreads in the absence of effective therapies and valid countermeasures and \ncalls for major efforts to model and anticipate the time course of \nits diffusion\n18. On the other hand, we can speak of an infodemic \nthreat22, which proliferates when credible information sources fail \nto capture the attention and trust of some parts of the public, for whom alternative, low-quality sources are more appealing as they \ncapture more social attention\n23, better match their own beliefs or prejudices24, or sound more convincing, thanks to their typically \nstraightforward messages25.\nThe appeal of low-quality, misleading or manipulative informa -\ntion relies on simple, effective psychological mechanisms, such as \ncurbing anxiety by denying or minimizing the seriousness of the threat; controlling fear and anger by targeting scapegoat individu\n-\nals, groups or institutions as the ones responsible for the crisis; and delivering an illusory sense of control through the provision of \u2018mir\n-\nacle\u2019 remedies. Similarly to epidemics, infodemics could be thought of as outbreaks of false rumours and unreliable news\n26,27 with unex -\npected effects on social dynamics (Fig. 1), which can substantially increase epidemic spread. Infodemics call for suitable policy inter\n-\nventions built on state-of-the-art social and behavioural research28.\nAs shown in Fig. 1 , an infodemic is the result of the simultane -\nous action of multiple human and non-human sources of unreli -\nable or misleading news in times of great abundance of circulating information. Note that, although this study does not directly deal with non-human accounts and their role in (mis-)information dif\n-\nfusion, we include them in the figure because they are known to be important contributors of noise in online social media\n7,8,29\u201331. As \nusers are repeatedly hit by a given message from different sources, this works as an indirect validation of its reliability and relevance, \nleading the user to spread it in turn and to become a vector of \n \ndangerously misleading information.\nThe COVID-19 crisis allows us to provide an evidence-based \nassessment of such risks and of the real-time interaction of info -\ndemic and epidemic spread14. We focus our attention on the analysis \nof messages posted on Twitter32, an online social network charac -\nterized by heterogeneous connectivity33 and topological shortcuts \ntypical of small-world systems34. Information spread on this type of \nnetwork is well understood in terms of global cascades in a popu -\nlation of individuals who have to choose between complementary \nalternatives, while accounting for the behaviour and the relative size of the individuals\u2019 social neighbourhoods\n35, as well as for fac -\ntors that characterize the popularity of specific content, such as the memory time of users and the underlying connectivity structure\n36. \nHowever, the exact mechanisms responsible for the spread of false Assessing the risks of \u2018infodemics\u2019 in response to \nCOVID-19 epidemics\nRiccardo Gallotti\u200a \u200a1, Francesco Valle1, Nicola Castaldo\u200a \u200a1, Pierluigi Sacco\u200a \u200a2,3\u2009\u2709 and \nManlio De Domenico\u200a \u200a1\u2009\u2709\nDuring COVID-19, governments and the public are fighting not only a pandemic but also a co-evolving infodemic\u2014the rapid and \nfar-reaching spread of information of questionable quality. We analysed more than 100 million Twitter messages posted world-\nwide during the early stages of epidemic spread across countries (from 22 January to 10 March 2020) and classified the reliabil-\nity of the news being circulated. We developed an Infodemic Risk Index to capture the magnitude of exposure to unreliable news across countries. We found that measurable waves of potentially unreliable information preceded the rise of COVID-19 infec-\ntions, exposing entire countries to falsehoods that pose a serious threat to public health. As infections started to rise, reliable \ninformation quickly became more dominant, and Twitter content shifted towards more credible informational sources. Infodemic early-warning signals provide important cues for misinformation mitigation by means of adequate communication strategies.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1285\nArticles NATuRe HuMAN BeHAVIOuRinformation and inflammatory content, for example during political \nevents8,30,37,38, remain fundamentally unknown. Recently, it has been \nsuggested that this challenging phenomenon might exist because, at a population level, the dynamics of multiple interacting contagions \nare indistinguishable from social reinforcement\n39.\nThis feature reinforces the increasing consensus around the idea \nthat infodemics of news consumption should be analysed through the lens of epidemiology\n9,40 to gain insights about the role of online \nactivities in spreading reliable as well as unreliable news. To this \nend, we monitored Twitter activity and collected more than 112 \nmillion messages using a selection of words commonly used in \nthe medical discourse about COVID-19, between 22 January and 10 March 2020 (see Methods for the details). The messages were in 64 languages from around the world, but because of our data \nfiltering and enrichment procedures, the largest fraction of anal\n-\nysed messages point to English-language sources. As a result, the \nfindings reported in this study mostly capture the behaviour of the English-speaking portion of Twitter users, while in the majority of \ncountries included in our analysis, English is not an officially spo\n-\nken language. Additionally, Twitter demographics are not represen -\ntative of the general population\u2014there is overrepresentation of the \nhighly educated, working-age male population. Moreover, limiting the focus to medical terminology clearly narrows the scope of our \nsearch and is a further limitation of our work. However, it allows us \nuse terms such as \u2018coronavirus\u2019 and \u2018covid19\u2019 that are interculturally consistent and used in several languages not depending on local idi\n-\nomatic usages and variants. We describe in detail the limitations of our dataset in the Discussion and Methods.\nResults\nWhere available, we extracted URLs from messages, collecting approximately 20.7 million links (3.3 million unique) pointing to websites external to the platform. Each URL was then subjected to our \nsource reliability rating method, inheriting the reliability of its source (Methods, Table 1  and Supplementary Fig. 1). We successfully associ\n-\nated approximately 50% of URLs with a reliability rating by screen -\ning almost 4,000 expert-curated web domains; the remaining corpus \npointed to disappeared web pages or to content not classifiable auto -\nmatically (for example, videos on Y ouTube) and rarely shared sources.\nOur method allowed us to overcome the limitations due to text \nmining of different languages for the analysis of narratives. However, \nthis step in our analysis is predominantly based on sources in \nEnglish, and this prevents us from covering and representing local discourses that mostly use local languages.\nTo better understand the diffusion of these messages across \ncountries, we filtered messages that included geographic informa\n-\ntion. Approximately 0.84% of the collected posts were geotagged by the user, providing highly accurate information about their geo\n-\ngraphic location. By geocoding the information available in users\u2019 profiles, we were able to extend the corpus of geolocated messages to approximately 50% of the total observed volume (Fig. 2 and \nMethods). We therefore analysed more than 60 million geolocated \nmessages, containing more than 9 million news links.\nFor each message, we applied a distinction between verified and \nunverified users. Usually, verification is performed by the social \nplatform to clearly identify accounts of public interest and certify \nthat they are authentic. The number of followers K\nu of a single user u \ndefines the exposure (see Supplementary Note 1 for further details), in terms of potential visualizations at first-order approximation, of \na single message m posted by user u at time t. Let M\nu(t,t + \u0394t) indi -\ncate the set of messages posted by user u in a time window of length \n\u0394t. Since there are two different classes of users\u2014verified (V) and unverified (U) accounts\u2014we define the partial exposure (E) due to \na single class C\ni (i = V, U) as\nEit;t\u00fe\u0394t \u00f0 \u00de\u00bcX\nu2CiX\nm2Mut;t\u00fe\u0394t\u00f0\u00deKu\u00f01\u00de\nBot Human\n#SARSCoV2 is a\nbiological weapon\ndeveloped by China\nCoronavirus\nis just a flu...Follow social distancing\nrules to fight the spread\nof covid19\nStay at home!\n#covid-19Fake news\nspreader\nReliable news\nspreaderA\nBCD\nE\nF\nFig. 1 | How infodemics work. Human (circles) and non-human (squares) accounts participate in the spread of news across a social network. Some users \n(A and B) create unreliable content, such as false or untrustworthy news or unsupported claims, while others (C) create content informed by reliable sources. When the topic attracts worldwide attention as in the case of COVID-19, the volume of information circulating makes it difficult to orientate oneself and to identify reliable sources. Indeed, some users (D) might be exposed to unreliable information only, while others (e and F) might receive contradictory information and become uncertain as to what information to trust. This is exacerbated when multiple spreading processes co-occur, and some users might be exposed multiple times to the same content or to different contents generated by distinct accounts.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1286\nArticles NATuRe HuMAN BeHAVIOuRNote that different users of the same class might have overlap -\nping social neighbourhoods: those neighbours might be reached \nmultiple times by the messages coming from distinct users of the same class; therefore, our measure of exposure accounts for this \neffect. Note also that our measure provides a lower bound to the \nnumber of exposed users, because we do not track higher-order transmission pathways: a user might read a news item included in a message but not share it further. There is no way to account for \nsuch users.The assumption that all followers of a specific user u will be \nreached by posted messages is clearly unrealistic. In Supplementary \nNote 1, we provide a mathematical extension of the definition of exposure from equation (1), which allows one to relax this assump\n-\ntion on the basis of a recent study7 and a mean-field model, without \naltering the quantitative analysis presented in this study.\nFinally, for each message, we identified the presence of links \npointing to external websites, and for each link, we verified whether it came from a trustworthy source or not (Methods). The reliability r\nm of a single message m is either 0 or 1, because we discarded all \nweb links that could not be easily assessed (such as ones shortened by third-party services) or that pointed to external platforms (such \nas Y ouTube) where it is not possible to automatically classify the \nreliability of the content. The news reliability of messages produced by a specific class of users (R\ni) is therefore defined as\nRit;t\u00fe\u0394t \u00f0 \u00de\u00bcX\nu2CiX\nm2Mut;t\u00fe\u0394t\u00f0\u00derm\u00f02\u00de\nUnreliability can be defined similarly by replacing rm with 1 \u2212 rm. \nExposure and reliability are useful descriptors but do not fully suf -\nfice to assess the risk of infodemics. For this reason, we developed an Infodemic Risk Index (IRI), which quantifies the rate at which a generic user is exposed to unreliable news produced by a specific \nclass of users (partial IRI, equation (3)) or by any class of users \n \n(IRI, equation (4)):\npIRI it;t\u00fe\u0394t \u00f0 \u00de\u00bcP\nu2C iP\nm2M ut;t\u00fe\u0394t\u00f0\u00deKu1\ufffdrm \u00f0\u00de\nP\niEit;t\u00fe\u0394t \u00f0\u00de\u00f03\u00de\nIRI t;t\u00fe\u0394t \u00f0 \u00de\u00bcX\nipIRI it;t\u00fe\u0394t \u00f0\u00de\u00f04\u00de\nBoth indices are well defined and range from 0 (no infodemic \nrisk) to 1 (maximum infodemic risk). Note that we can calculate T able 1 | Description of the nine categories of news in our classification\nCategory Harm \nScoreDescription Count type total\nScience 1 Domains providing content validated via scientific scrutiny. 150 reliable 1,434\nMainstream media 2 Domains providing content that is generally subjected to professional fact checking and abides by the rules of media accountability.1,284\nSatire 3 Domains providing content that is intentionally and explicitly aiming at providing a distorted representation of events as a form of humour and/ or social critique.177 Unreliable 2,264\nClickbait 4 Domains providing content that generally distorts or intentionally misrepresents information to capture attention.47\nPolitical 7 Domains providing content that presents a partisan representation and interpretation of facts to support a political position over rival ones.697\nFake or hoax 8 Domains providing manipulative and fabricated content with the purpose of misleading public opinion on socially relevant issues and provoking inflammatory responses.917\nConspiracy and junk science9 Domains providing systematically manipulative and fabricated content with the purpose of legitimizing implausible conceptualizations of facts and knowledge through argumentative methods that coarsely mimic those of scientific reasoning but without any sound logical or factual basis, targeting individuals or social groups as covert instigators or perpetrators of harmful actions.426\nOther 5 Domains pointing to general content that cannot be easily classified, such as videos on Y ouT ube.160 Unknown 194\nShadow 6 Domains related to UrL shortening that cannot be classified a\u00a0priori but would require further UrL expansion.34\n1.2 Geolocated Recorded Lost\n1.0\n0.8\n0.6Number of tweets (\u00d7 107)\n0.4\n0.2\nDate0\n24 Jan 27 Jan 30 Jan 5 Feb2 Feb 8 Feb11 Feb14 Feb 23 Feb26 Feb29 Feb3 Mar 6 Mar9 Mar17 Feb 20 Feb\nFig. 2 |  the evolution of t witter activity about the COVID-19 pandemic.  \nWe observe a first increase in collective attention after the outbreak \nin Wuhan, China (between 24 January and 2 February 2020), and a second strong rise after the epidemics began to spread in northern Italy (20 February 2020 onwards). The fraction of geolocated messages (messages with shared locations, or geonamed, indicated in green) is constantly approximately 50% of the total volume recorded (indicated in blue). From 26 February, we reached the limit of the fraction of data shared by T witter (Methods), missing an increasing fraction of T weets (indicated in red).\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1287\nArticles NATuRe HuMAN BeHAVIOuRall the infodemic descriptors introduced above at a desired level of \nspatial and temporal resolution.\nFigure 3 shows how countries characterized by different levels of \ninfodemic risk present very different profiles of news sources, which appear not to be strictly correlated with the level of socio-economic development (Supplementary Fig. 2). In low-risk countries such as Canada and South Korea, the level of infodemic risk remains small \nthroughout the period of study, apart from isolated spikes mostly \nassociated with unverified sources. As the epidemic spreads to important levels, infodemic risk further decreases, signalling an increasing focus of the public towards reliable news sources. By contrast, in a high-risk country such as Venezuela, the infodemic is pronounced throughout the period of observation, and in addi\n-\ntion to the expected activity from unverified sources, even verified sources contribute to a large extent to the infodemic. Finally, in a relatively high-risk country such as Russia, infodemic risk is erratic \nwith sudden, very pronounced spikes, and again verified sources \nplay a major role. Here too, information about the epidemic is frag\n-\nmented and mostly unreliable.\nOverall, the global level of infodemic risk tends to decrease \nas COVID-19 spreads globally, suggesting that epidemic spread \nleads people to look for relatively more reliable sources. It also \nsuggests that verified influencers with many followers started to point to more reliable news (Supplementary Figs. 3 and 4 and \nSouth Kor eaCanadaRussia\nVenezuelaEpidemiology\nInfodemiology\nHigh\nexposure\nLow\nexposureWorld\nChina\nRest of the world1.00\n2.5\n2\n2\n34911131051243334611111111\n22\n2\n5.0\n7.52.5\n5.0\n7.5\n10.0\n12.5IRI1.00\n0.75\n0.50\n0.25\n00.750.50\n0.25\n0\nIRI\n1.000.5\n0.4\n0.30.2\n0.1\n00.75\n0.500.25\n0IRI1.00\n200\n4006008000.75\n0.500.25\n0IRIIRI1 Feb 15 Feb 1 Mar\n1 Feb 15 Feb 1 Mar\n21 Jan\n24 Jan27 Jan\n30 Jan\n02 Feb\n05 Feb08 Feb\n11 Feb\n14 Feb17 Feb20 Feb\n23 Feb\n26 Feb29 Feb\n03 Mar\n06 Mar\n09 Mar12 Mar1 Feb 15 Feb 1 Mar1 Feb 15 Feb 1 MarVerified\nUnverifiedIRI1.0\n0.8\n0.6\n0.4\n0.2\n0\n3516427344850546743585159958681357750528414423116922910073111111\n4331111\n7\n1\n2\nFig. 3 | Mapping infodemic risk worldwide. The infodemic risk of each country, aggregated over time, is colour-coded on the map. The panels show the \nevolution of risk over time for a sample of countries; the bars indicate the partial contributions of verified and unverified users to the overall risk and the dashed lines represent the cumulative mean of the IrI at a given day d (computed as the ratio between the cumulative sum of the daily IrI in the days between 22 January and d, and the number of days between these two dates). risk evolution for the whole world is also shown, demonstrating an overall decrease of risk over time (bottom middle panel, where the grey line represents a LOeSS regression with R\n2\u2009=\u20090.29). The markers horizontally aligned at \nthe top of each panel indicate the daily confirmed epidemiological cases, with their number encoded by the markers\u2019 sizes (Venezuela does not contain epidemiological markers as no confirmed cases were reported at the time of the anaysis). Map made with public domain Natural earth data.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1288\nArticles NATuRe HuMAN BeHAVIOuRSupplementary Note 2), possibly shifting the state of the info -\ndemic towards a clearer information landscape where it is easier to  \norientate and to identify unreliable facts.\nIn the case of Italy, where the epidemic struck the country heavily \nwithin the window of observation of the current study, we observe \nin coincidence with the first verified domestic contagions a sud -\nden, clear increase in national Google searches for the best-known \nItalian virologists as they gained substantial visibility on national mainstream media (Supplementary Note 2). Our data do not allow \nus to establish a causal relationship between the sudden increase \nin popularity and media exposure of such experts and the shift in focus from unreliable to reliable sources in online social media con\n-\nversations. However, it is likely that a spillover effect has occurred, contributing at least partly to this shift, as Italian Twitter is known to be very reflective of trending personalities and topics from the \nmainstream media\n41. This overall pattern, linking the local spread \nof the epidemics to the diffusion of more reliable information, is \nconfirmed in terms of measures of infodemic risk aggregated daily \nand at the country level (Fig. 4 and Supplementary Figs. 5 and 6). \nThis pattern is particularly pronounced with the escalation of the \nepidemic, suggesting that the effect could be mediated by levels of perceived social alarm.\nIn principle, countries with high infodemic risk could also pres\n-\nent more reliability issues in terms of reporting of epidemic data, thus altering the perceptions of the public and indirectly misleading \nthem in their search for reliable information. In fact, there have been \ncases of countries with high infodemic risk where political leaders have actively spread misleading information and openly questioned the necessity to accurately track and measure the development of \nthe epidemic diffusion, as well as the reliability of fact-checking \nsources\n42\u201345. Our results, though, do not provide direct supporting \nevidence for this possibility, and this remains an open question for future research.\nThe dynamic profiles of infodemic risk in countries with simi\n-\nlar risk levels may also be very different. Figure 5 compares Italy with the United States. In the case of Italy, the risk is mostly due to the activity of unverified sources, but we notice that with the out\n-\nbreak of the epidemic, the production of misinformation collapses, and there is a sudden shift to reliable sources. In the United States, misinformation is mainly driven by verified sources, and it remains \nessentially constant even after the epidemic outbreak. Notice also \nhow infodemic risk varies substantially across US states. As in our time window the United States lagged widely behind Italy in terms of epidemic progression, it remains to be seen whether a similar \nreadjustment can be observed for the United States later on. Figure \n5 shows, however, that the relationship between the reduction of infodemic risk and the spread of the epidemic seems to be a rather general trend, as the relationship between the number of confirmed cases and infodemic risk is (nonlinearly) negative, confirming the \nresult shown in Fig. 4. Figure 5 also shows how the evolution of \ninfodemic risk among countries with both high message volume and considerable epidemic contagion tends to be very different. The IRI maintained its relatively high level not only in countries such \nas Iran but also in the United States, Germany, the Netherlands, \nSweden and Norway. Conversely, in other countries such as Italy, South Korea and Japan, the IRI substantially dropped with the pro\n-\ngression of the epidemics.\nDiscussion\nOur findings show that, in a highly digital society, the epidemic and the infodemic dimensions of COVID-19 co-evolve. The infodemic dimension is driven by a heterogeneous set of actors who pursue \nlargely undisclosed goals.\nGiven the lack of pharmacological interventions to combat \nCOVID-19, responsible behaviours driven by reliable information \nat all scales are key for the mitigation of adverse effects. It may there\n-\nfore be important to develop integrated public health approaches, where the biological and informational dimensions of an epidemic are equally recognized, taken into account and managed through \ncareful policy design.\nHere, we have shown that in the context of the COVID-19 cri\n-\nsis, complex infodemic effects are indeed at work, with remark -\nable variations across countries, and the level of socio-economic \ndevelopment is not the key discriminant to separate countries with high versus low infodemic risk. In fact, we find that there are G8 \ncountries with remarkable infodemic risk (for example, Russia and \nGermany) and developing countries with far lower risk levels (for example, Thailand and the Philippines). This means that, especially in countries where infodemic risk is high, the eventual speed and \neffectiveness of the containment of COVID-19 could depend on a \nprompt policy switch in communication strategies and in the effec\n-\ntive countervailing of the most active sources of unreliable news. The escalation of the epidemics leads people to progressively pay attention to more reliable sources, thus potentially limiting the \nimpact of infodemics, but the actual speed of adjustment may make \na major difference in determining the social outcome (and in par\n-\nticular between a controlled epidemic and a global pandemic).\nOur study is characterized by important limitations. A key limi -\ntation of any data collection from social media content is that each social medium has a specific demographic that is not representative 00.250.500.751.00\n1\u22122 3\u22127 8\u221215 16\u221250 51\u22129,999 10,000+\nCum ulativ e number of reported casesIRI cumulative mean\nFig. 4 |  Reduction of infodemic risk after COVID-19 reaches countries.  \nAggregated view of the evolution of the IrI for increasing numbers of \nreported cases. For each day and each of the 162 countries considered in our analysis, we compute the cumulative mean of the IrI at a given day d (computed as the ratio between the cumulative sum of the daily IrI in the days between 22 January and d , and the number of days between these two \ndates). We aggregate days and countries with a similar cumulative number of reported cases, using bins of increasing size to compensate for the limited number of countries that reached high levels of contagion at the time of the analysis and reporting the average value on the x  axis. This allows us \nto describe the drop in IrI as the number of cases grows in a country using box plots. In box plots, the centre lines represent the medians, the boxes the range between the 25th and 75th percentile, and the whiskers the range between the smallest and largest data point, excluding outliers, which are represented as circles. Therefore, the difference between two boxes is statistically significant when each middle line lies outside of the other box. On the basis of the results of both a one-way ANOVA (F  statistic (degrees \nof freedom), 18.86 (5); P \u2009<\u20090.001; effect size, F  = 0.05; 95% confidence \ninterval, (0.03, 0.06); the data distributions were assumed to be normal, but this was not formally tested) and Kruskal\u2013Wallis rank sum tests F  137.14 \n(5); P\u2009<\u20090.001; effect size, F  = 0.0677; 95% confidence interval, (0.0501, \n0.0918); no assumptions are needed to use this non-parametric test), there is evidence of a statistically significant effect (P \u2009<\u20090.001 for both tests) of \nthe number of reported cases on the IrI cumulative mean. In Supplementary Fig. 4, we provide further tests illustrating the significant difference between each pair of boxes except pairs 3\u20137 with 1\u20132 and with 8\u201315 and pair 16\u201350 with 51\u20139,999, where the differences are not statistically significant.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1289\nArticles NATuRe HuMAN BeHAVIOuRof the whole population, so that different social media are biased in \ndifferent directions46. However, social media platforms offer unique \nopportunities to collect very large volumes of data in real time on key social phenomena, and currently there are no viable alternatives for the collection of similar amounts of data in an equally timely way from other sources. There is currently no means of obtaining \nItaly\nDaily casesEpidemiology\nInfodemiology\nUnited States\nAFG\nARE\nARG\nARMAUSAUTBEL\nBFABGDBGRBHR\nBLRBRACANCHE\nCHL\nCMRCOLCRICZEDEU\nDNK\nDOMDZAECUEGYESP\nESTFINFRA\nGBR\nGEOGRCHKG\nHUNIND IRLIRQ\nISLITA\nJORJPNKOR\nKWT\nLBN\nLKALTULUXLVAMAC\nMARMDA MDVMEX\nMLT\nNGANLDNOR\nNPLNZLOMN\nPAK\nPANPERPHLPOLPRT\nPRYQATROU\nRUS SAU\nSENSGP\nSRBSVNSWE\nTGOTHA\nTUN\nUKRUSA\nVNM\nZAF\n110,000\n0 0.25 0.50 0.75 1.00\nIRIVolume\n100Confirmed COVID-19 cases1.00a\n0.75\n500100\n200\n300 1,000\n1,5000.50\n0.25IRIIRI0\n1.0\n0.8\n0.6\n0.4\n0.2\n0\nIRN\n1 \u00d7 10\n5\n2 \u00d7 105\n3 \u00d7 105\n4 \u00d7 105Africa\nAmericas\nAsia\nEurope\nOceaniaSWE\nDEU\nNOR\nNLD\nUSA\nAUT\nKOR\nCHE\nCHN\nCBR\nITA\nDNK\nMYS\nBEL\nAUS\nJPN\nESP\nFRA\nHKG\nSGP1 Feb\n1 Feb 15 Feb 1 Mar15 Feb 1 Mar1.00172\n1\n42\n937493131202233240566342466587\n769\n7781,247\n1,492\n1,797\n977\n3761\n3\n2\n1\n1\n1\n2\n36\n6\n1\n28\n6\n2420\n31\n6845140116\n653\n0.75\n0.50\n0.25\nVerified\nUnverifiedIRI\n0\n1 Feb 15 Feb 1 Mar\nb c\nFig. 5 | Infodemic evolution is country dependent. a, As in Fig. 3, for the european Union and the United States at a finer resolution, with a detailed map for \nItaly (regional resolution). Areas with fewer than ten messages were excluded from the analysis and are colour-coded in grey. Note the striking drop in the Italian IrI coinciding with the first official report of non-imported epidemiological cases. b, risk evolution for countries characterized by a high volume of messages per day (at least one day with more than 2,000) and a high number of epidemiological cases (at least one day with more than 100). This picture illustrates, with the same colour legend as in the maps, how the temporal pattern of the infodemic is strongly localized and depends on the online discourse of each country. c, The number of epidemiological cases is shown against the IrI for all countries with at least one confirmed COVID-19 case. The countries are coloured according to their continent, with dot sizes proportional to the daily volume of messages generated. The black dashed curve encodes a local polynomial regression fit, here shown as a guide for the eye to highlight the highly nonlinear pattern relating epidemic and infodemic indices, while the shaded area and the solid red line encode a simple linear regression fit with a 95% confidence interval illustrating an anticorrelation (Spearman\u2019s r, \u22120.42; confidence interval, (\u22120.60, \u22120.24)). China is an outlier due to its role in the global epidemic in terms of the timing and size of the contagion, which makes it difficult to compare it with other countries; it has therefore been removed from this analysis. Maps made with public domain Natural earth data, which also define the country abbreviation codes used in b and c.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1290\nArticles NATuRe HuMAN BeHAVIOuRrepresentative data worldwide relying only on online sources, yet \nthe collection of offline sources presents other substantial limita -\ntions. In fact, before the advent of social media, it would have been unthinkable to carry out analyses of social phenomena at this scale in real time. Our focus on Twitter means that our reference popula\n-\ntion tends to be highly educated, working age and male, and our filter selection and source reliability database exacerbate this bias towards English-speaking users. One way to tackle this problem in \nfuture research is to extend data collection to several social media \nplatforms at once, but there is a clear trade-off between intensively collecting large volumes of data on a single platform and exten\n-\nsively collecting data from multiple platforms with smaller volumes for each. Moreover, joint collection from multiple biased sources remains biased in principle, although the overall bias becomes less \ncontrollable. We consider our approach as a first step, with clear \nlimitations, which may provide a benchmark for more comprehen\n-\nsive future approaches.\nThere are several important questions and goals for future \nresearch. We highlight four: (1) a better understanding of the role of \nartificial agents (bots) in infodemics, (2) the development of truly \nmultilingual corpora and source reliability databases, (3) the exten -\nsion of text mining to multiple social media platforms while main -\ntaining the highest possible volumes of mined content from each source, and (4) building a representative sample of the global popu\n-\nlation through a suitable integration of online and offline sources. These are formidable challenges, but their urgency and relevance do not need much argumentation. We look forward to the future \ndevelopments of what promises to be an emerging discipline with \nkey theoretical and policy implications.\nMethods\nData collection. We followed a methodology for collecting social media data \nconsolidated over the years. We focused on Twitter, which is well known for providing access to publicly available messages upon specific requests through their application programming interface (API). We identified a set of hashtags and keywords gaining collective attention since the first recorded cases of COVID-19: coronavirus, ncov, #Wuhan, covid19, covid-19, sarscov2 and covid. This set includes the official names of the virus and the disease, including the early tentative ones, as well as the name of the city where the first cases of COVID-19 were recorded. We estimate the recall rate for these keywords to be higher than 16% and probably in the 40%\u201360% range at the time of recording (see Supplementary Note 3 for more details). We used the Filter API to collect the data in real time from 24 January 2020 to 10 March 2020 and the Search API to collect the data between 21 January 2020 and 24 January 2020. Our choice allowed us to monitor, without interruptions and regardless of the language, all the tweets posted about COVID-19 since 22 January 2020, when China reported more than 6,000 cases, calling for the attention of the international community. The Stream API has the advantage of providing all the messages satisfying our selection criteria and posted to the platform in the period of observation, provided that their volume is not larger than 1% of the overall (unfiltered) volume of posted messages. Above 1% of the overall flow of information, the Filter API provides a sample of filtered tweets and communicates an estimate of the number of lost messages. Note that this choice is the most reliable to date: in fact, it was recently shown that biases affecting the Sample API (which samples data on the basis of rate limits), for instance, are not found in the REST and Filter APIs\n47. In Supplementary Note 4, we show how \nthis problem does not affect our data.\nWe estimate that until 24 February 2020, we lost approximately 60,000 tweets \nout of millions, capturing more than 99.5% of all messages posted (Fig. 2). The \nglobal attention towards COVID-19 increased the volume of messages after 25 February 2020; however, Twitter restrictions allowed us to get no more than 4.5 million messages per day, on average. We have estimated a total of 161.2 million tweets posted until 10 March 2020; we have successfully collected 112.6 million  of them.\nGeocoding. The user\u2019s self-declared location field was used for geocoding with \nArcGIS API. For approximately 56% of users, we had a response in terms of latitude and longitude. However, a large portion of these answers (about 10%) were associated with a small number (~1,600) of wrongly attributed locations that were removed (reaching the 50% ratio indicated in the main text). These errors were mostly caused by the use of non-toponyms in the location field such as \u2018Home\u2019 or \u2018Somewhere\u2019 , or other pieces of information (such as Instagram and website URLs), which were wrongly associated with real locations. We identified these errors by isolating single locations associated with a large number of different unique user-defined location strings. Finally, we also filtered out names of continents that were correctly geocoded but do not match the country-based granularity we set for our analysis. The reliability of our method was tested by comparing geocoded and georeferenced data for the United States (Supplementary Note 5).\nSource reliability rating. We collected manually checked web domains from \nmultiple publicly available databases, including scientific and journalistic ones. Specifically, we considered data shared by the sources listed in refs. \n48\u201356.\nThe databases adopted different labelling schemes to classify web domains. \nWe therefore first had to develop a unifying classification scheme, reported in Table 1, and map all existing categories into a unique set of categories. Note that we have also mapped those categories into a coarse-grained classification scheme, distinguishing between reliable and unreliable.\nWe found a total of 4,988 domains, reduced to 4,417 after removing hard \nduplicates across databases. Note that a domain is considered a hard duplicate if its name and its classification coincide across databases.\nA second level of filtering was applied to domains that are classified differently \nacross databases (for example, xyz.com might be classified as FAKE/HOAX in \na database and as SATIRE in another database). To deal with these cases, we \nadopted our own classification method by assigning to each category a Harm \nScore (HS) between 1 and 9. When two or more domains were soft duplicates, we kept the classification with the highest HS, as a conservative choice. This phase of processing reduced the overall database to 3,920 unique domains.\nThe HS classifies sources in terms of their potential contribution to the \nmanipulative and misinformative character of an infodemic. As a general principle, the more systematic and intentionally harmful the knowledge manipulation and data fabrication, the higher the HS. \u201cScience\u201d or \u201cScientific\u201d content has the lowest level of HS due to the rigorous process of validation carried out through scientific methods. \u201cMainstream media\u201d content has the second lowest level of HS due to its constant scrutiny in terms of fact checking and media accountability. \u201cSatire\u201d is an unreliable source of news, but due to its explicit goal of distorting or misrepresenting information according to specific cultural codes of humour and social critique, it is generally identified with ease as an unreliable source. \u201cClickbait\u201d is a more dangerous source (and thus ranks higher in HS) due to its intent to pass fabricated or misrepresented information for facts, with the main purpose of attracting attention and online traffic (that is, for mostly commercial purposes), but without a clear ideological intent. \u201cOther\u201d is a general-purpose category that contains diverse forms of (possibly) misleading or fabricated content, not easily classifiable but probably including bits of ideologically characterized content pursuing systematic goals of social manipulation, and thus ranking higher in HS. \u201cShadow\u201d is a similar category to the previous one, where links are anonymized and often temporary (for example, bit.ly and dlvr.it), thereby adding an extra element of unaccountability and manipulation that translates into a higher level of HS. Known vanity URL shorteners such usnyti.ms for the New York Times  and wpo.\nst for the Washington Post  are automatically associated with the source. \u201cPolitical\u201d \nis a category where we find an ample spectrum of content with varying levels of distortion and manipulation of information, also including mere selective reporting and omission, whose goal is to build consensus on a polarized political position against others; this category therefore directly aims at conditioning the public discourse and opinion making, with a higher HS than the previous categories. The majority of web domains listed in this category overlap with \u2018left\u2019 and \u2018right\u2019 categories as defined by the MediaBiasFactCheck source, while domains labelled as left-centre and right-centre are considered Mainstream media. \u201cFake or hoax\u201d contains entirely manipulated or fabricated inflammatory content that is intended to be perceived as realistic and reliable and whose goal may also be political but fails to meet the basic rules of plausibility and accountability, thus reaching an even higher level of HS. Finally, the highest level of HS is associated with \u201cConspiracy and junk science\u201d\u2014that is, to strongly ideological, inflammatory content that aims \nat building conceptual paradigms that are entirely alternative and oppositional to \ntested and accountable knowledge and information, with the intent of building \nself-referential bubbles where fidelized audiences are simply refusing a\u00a0priori any kind of knowledge or information that is not legitimized by the alternative source itself or by recognized affiliates, as is typical in sects of a religious or other nature.\nA third level of filtering concerned poorly defined domains\u2014for example, \nthe ones explicitly missing top-level domain names (such as \u201c.com\u201d or \u201c.org\u201d)\u2014as well as the domains not classifiable by means of our proposed scheme. This action reduced the database to the final number of 3,892 entries (Table 1 and Supplementary Fig. 1).\nFinally, in Supplementary Note 6 we also provide quantitative results excluding \neffects due to the shift of misinformation towards untracked domains during the time frame of our analysis. In Supplementary Note 7, we further provide a comparison between MediaBiasFactCheck and other databases.\nData limitations and possible selection biases. The process of gathering and \nintegrating vast sources of user-generated data provides us with the opportunity of analysing complex collective phenomena in almost real time. At the same time, it is subject to a number of limitations inherent in user-generated content data\n45 \nselection biases that might influence the analysis at different levels. In this section, we discuss these limitations in detail, as well as how they affect our results.\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1291\nArticles NATuRe HuMAN BeHAVIOuRUse of Twitter as a data source (population bias). All Twitter-based research has to \ncope with the intrinsic demographic limitations of Twitter\u2019s penetration: our results apply mostly to well-educated males (65% of Twitter users\n57) between the ages of 18 \nand 34 (58% of Twitter users, according to Statista GmbH58). Although our results \nmust be interpreted in the light of these demographic limitations, we believe that our work represents a first step in establishing a robust research agenda for the study of infodemic risk. Future research should expand our knowledge by working on different demographics from different data sources.\nFurthermore, as the COVID-19 public health emergency spread and raised \ninternational concern, Twitter (as well as Facebook and Google) took actions against the diffusion of unreliable/misleading news by attempting to prioritize reliable sources over unreliable ones. In Supplementary Note 8, we show how this action seems not to have influenced our measures.\nUse of words written with Latin characters in the Twitter Filter API (data filtering \nbias). Latin characters, and particularly English, are widespread and often used for hashtags in messages in languages not using the same alphabet. However, the fact that we used a set of terms shared by Western languages (including English, Spanish, French, Portuguese, German, Italian and others) to select tweets in the Filter API may exacerbate the Twitter bias towards highly educated individuals in countries where local languages do not use Latin characters.\nUse of a limited and static list of words in the Twitter Filter API (data filtering \nbias). As discussed above, our analyses do not focus on reconstructing the whole communication network related to the topic; instead, they focus on estimating the fraction and impact of unreliable news. Therefore, our rationale behind the word choice was to include the most commonly used keywords to ensure that, if the discourse abruptly changed its key terms, we were still tracking them. This might lower the recall rate, as new terms might be progressively emerging. In particular, our dataset only partially includes \u2018#stayathome\u2019 or \u2018#staystrong\u2019 messages, but ultimately our focus is on understanding whether news related to key medical pandemic hashtags is reliable or not, and to what extent this news reliablity correlates with the epidemic wave. For this reason, we chose a set of words commonly used in medical discourse, using query expansion when it was crucial for collecting medical-related data (for example, when the name of the virus and of the disease changed to SARS-CoV-2 and COVID-19, respectively, from the previous 2019-nCov).\nAn alternative would have been to use automated query expansion techniques \nto enlarge the set of terms used for filtering. Unfortunately, there is not yet an agreement on a standard methodology, as each design leads to a different source of bias. For example, a possible method would have been to build a hashtag co-occurrence network periodically and to expand the list using more central nodes in such networks. However, query expansions might have increased the sample at the expense of introducing further bias in our analysis, as it would have been done, day by day, on a considerably different user base. While our choice does not provide a complete picture of the social dynamics during the pandemic, it was specifically designed for the task of gathering tweets containing links to medically related news sources, reliable or not, which is the focus of our paper.\nUse of Western-centric fact-checking sites (data enrichment bias). To enhance \nthe specificity and robustness of our multilanguage Twitter dataset sample, we collected fact-checking information data from several different and independent sources. Since the World Wide Web is strongly English centric, this collection of sources provides an overabundance of information about content in English. The English-centric nature of the resources helping us identify unreliable news sources probably exacerbates the intrinsic Twitter demographic limitations towards well-educated English-speaking users, a bias that could not be amended by any more complete database.\nTo assess this limitation, we collected statistics from Amazon Alexa (www.\nalexa.com/topsites/countries) about web traffic (the top 50 most visited websites) for all countries across the globe, matching these lists with the list of domains we used to classify reliable and unreliable sources. Remarkably, for 127 countries we have at least one domain in the reliable top-50 news source, and for 21 (iso2 codes: AE, AR, BB, BE, CA, DK, FR, KE, MX, NG, PA, PE, PH, PR, PT, QA, SD, SE, TT, US and VE) we have at least one domain in the top-50 websites labelled as unreliable (split equally between politically biased and fake or hoax websites). In fact, this is a lower bound, because Alexa provided only major domains, disregarding subdomains that we instead classified as well. This large presence among the very top tier of websites suggests that our results are robust for multilanguage/multicultural analysis.\nIn our opinion, however, it is not entirely correct to say that fact-checking sites \nsuffer from a Western-centric bias. It is the very notion of institutional sources of fact-checking and certification of media bias that is today still largely Western centric. An eloquent picture is provided by Reporters Without Borders\u2019 Press Freedom Index (https://rsf.org/en/ranking), where it is clearly shown that today, apart from the Western world and a few isolated non-Western countries (South Korea, Costa Rica, Jamaica, Uruguay, South Africa, a few small Western African states and micro states), the media environment of all other countries cannot be considered free, and in such conditions, the possibility of thorough, transparent fact-checking is basically impossible. So, whereas we acknowledge that our study suffers from other sources of bias, we are not sure that this particular source should be classified as such: we are simply considering the only functioning, relatively reliable sources of fact-checking available.\nReporting Summary. Further information on research design is available in the \nNature Research Reporting Summary linked to this article.\nData availability\nThe datasets generated during the current study are available from the corresponding author on reasonable request. The aggregated information, compliant with all privacy regulations, is publicly available online at the Infodemics Observatory (http://covid19obs.fbk.eu/) and at OSF  (https://doi.org/10.17605/OSF.\nIO/N6UPX).\nCode availability\nThe custom code that supports the findings of this study is available from the corresponding author upon request and available alongside the data in the permanent repository indicated above.\nReceived: 11 April 2020; Accepted: 5 October 2020;  \nPublished online: 29 October 2020\nReferences\n 1. Benkler, Y . The Wealth of Networks: How Social Production Transforms \nMarkets and Freedom  (Y ale Univ. Press, 2006).\n 2. Fuchs, C. Social Media: A Critical Introduction  (SAGE, 2014).\n 3. Giglietto, F., Rossi, L. & Bennato, D. The open laboratory: limits and possibilities of using Facebook, Twitter, and Y ouTube as a research data source. J. Technol. Hum. Serv. 30, 145\u2013159 (2012).\n 4. Ojo, A. & Mellouli, S. Deploying governance networks for societal challenges. Gov. Inf. Q. https://doi.org/10.1016/j.giq.2016.04.001 (2016).\n 5. De Domenico, M. & Altmann, E. G. Unraveling the origin of social bursts in collective attention. Sci. Rep. 10, 4629 (2020).\n 6. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science  359, 1146\u20131151 (2018).\n 7. Shao, C. et\u00a0al. The spread of low-credibility content by social bots.  Nat. Commun.  9, 4787 (2018).\n 8. Stella, M., Ferrara, E. & De Domenico, M. Bots increase exposure to negative and inflammatory content in online social systems. Proc. Natl Acad. Sci. USA 115, 12435\u201312440 (2018).\n 9. Eysenbach, G. Infodemiology: the epidemiology of (mis)information. Am. J. Med.  113, 763\u2013765 (2002).\n 10. Eysenbach, G. Infodemiology and infoveillance: framework for an emerging set of public health informatics methods to analyze search, communication and publication behavior on the Internet. J. Med. Internet Res. 11, e11 (2009).\n 11. Eysenbach, G. Infodemiology and infoveillance tracking online health information and cyberbehavior for public health. Am. J. Prev. Med. 40, \nS154\u2013S158 (2011).\n 12. Zarocostas, J. How to fight an infodemic. Lancet  395, 676 (2020).\n 13. Pastor-Satorras, R., Castellano, C., Van Mieghem, P . & Vespignani, A. Epidemic processes in complex networks. Rev. Mod. Phys. 87, 925\u2013979 \n(2015).\n 14. De Domenico, M., Granell, C., Porter, M. A. & Arenas, A. The physics of spreading processes in multilayer networks. Nat. Phys. 12, 901\u2013906 (2016).\n 15. Brockmann, D. & Helbing, D. The hidden geometry of complex, network-driven contagion phenomena. Science  342, 1337\u20131342 (2013).\n 16. Huang, C. et\u00a0al. Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China. Lancet  395, 497\u2013506 (2020).\n 17. Zhu, N. et\u00a0al. A novel coronavirus from patients with pneumonia in China, 2019. N. Engl. J. Med. 382, 727\u2013733 (2020).\n 18. Chinazzi, M. et\u00a0al. The effect of travel restrictions on the spread of the 2019 novel coronavirus (COVID-19) outbreak. Science  368, 395\u2013400 (2020).\n 19. Lazer, D. M. J. et\u00a0al. The science of fake news. Science  359, 1094\u20131096 (2018).\n 20. Rapp, D. N. & Salovich, N. A. Can\u2019t we just disregard fake news? The consequences of exposure to inaccurate information. Policy Insights Behav. Brain Sci. 5, 232\u2013239 (2018).\n 21. Waszak, P . M., Kasprzycka-Waszak, W . & Kubanek, A. The spread of medical fake news in social media\u2014the pilot quantitative study. Health Policy Technol. 7, 115\u2013118 (2018).\n 22. Leung, G. M. & Leung, K. Crowdsourcing data to mitigate epidemics. Lancet Digit. Health  https://doi.org/10.1016/S2589-7500(20)30055-8 (2020).\n 23. Altay, S., de Araujo, E. & Mercier, H. \u2018If this account is true, it is most enormously wonderful\u2019: interestingness-if-true and the sharing of true and false news. Preprint at PsyArXiv  https://doi.org/10.31234/osf.io/tdfh5 (2020).\n 24. Vicario, M. D., Quattrociocchi, W ., Scala, A. & Zollo, F. Polarization and fake news. ACM Trans. Web 13, 10 (2019).\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1292\nArticles NATuRe HuMAN BeHAVIOuR 25. Britt, M. A., Rouet, J.-F., Blaum, D. & Millis, K. A reasoned approach to \ndealing with fake news. Policy Insights Behav. Brain Sci. 6, 94\u2013101 (2019).\n 26. Weekly Epidemiological Record  Vol. 95, 16 (WHO, 2020); https://www.who.\nint/wer/2020/wer9516/en/\n 27. Tangcharoensathien, V . et\u00a0al. A framework for managing the COVID-19 infodemic: methods and results of an online, crowdsourced WHO technical consultation. J. Med. Internet Res. https://doi.org/10.2196/19659 (2020).\n 28. Lunn, P . D. et\u00a0al. Using behavioral science to help fight the Coronavirus.  J. Behav. Public Adm. https://doi.org/10.30636/jbpa.31.147 (2020).\n 29. Ferrara, E., Varol, O., Davis, C., Menczer, F. & Flammini, A. The rise of social bots. Commun. ACM 59, 96\u2013104 (2016).\n 30. Bessi, A. & Ferrara, E. Social bots distort the 2016 U.S. Presidential election online discussion. First Monday  https://doi.org/10.5210/fm.v21i11.7090(2016).\n 31. Ferrara, E. Disinformation and social bot operations in the run up to the 2017 French presidential election. First Monday  https://doi.org/10.5210/fm.\nv22i8.8005 (2017).\n 32. Kwak, H., Lee, C., Park, H. & Moon, S. What is Twitter, a social network or a news media? In Proc. 19th International Conference on World Wide Web 591 (ACM, 2010).\n 33. Barabasi, A. L. & Albert, R. Emergence of scaling in random networks. Science  286, 509\u2013512 (1999).\n 34. Watts, D. J. & Strogatz, S. H. Collective dynamics of \u2018small-world\u2019 networks. Nature  393, 440\u2013442 (1998).\n 35. Watts, D. J. A simple model of global cascades on random networks.  Proc. Natl Acad. Sci. USA 99, 5766\u20135771 (2002).\n 36. Gleeson, J. P ., O\u2019Sullivan, K. P ., Ba\u00f1os, R. A. & Moreno, Y . Effects of network structure, competition and memory time on social spreading phenomena. Phys. Rev. X 6, 021019 (2016).\n 37. Aral, S. & Eckles, D. Protecting elections from social media manipulation. Science  365, 858\u2013861 (2019).\n 38. Stella, M., Cristoforetti, M. & De Domenico, M. Influence of augmented humans in online interactions during voting events. PLoS ONE 14,  \ne0214210 (2019).\n 39. H\u00e9bert-Dufresne, L., Scarpino, S. V . & Y oung, J.-G. Macroscopic patterns  of interacting contagions are indistinguishable from social reinforcement. Nat. Phys. https://doi.org/10.1038/s41567-020-0791-2 (2020).\n 40. Eysenbach, G. How to fight an infodemic: the four pillars of infodemic management. J. Med. Internet Res. 22, e21820 (2020).\n 41. Marchetti, R. & Ceccobelli, D. Twitter and television in a hybrid media system. Journalism Pract.  10, 626\u2013644 (2016).\n 42. Y en, H., Braun, S. & Woodward, C. AP fact check: Trump\u2019s alternate reality on COVID-19 threat. Associated Press  https://apnews.com/0aa783aa734b2ac3\nd984c5116b3e8039 (20 July 2020).\n 43. Broad, W . J. Putin\u2019s long war against American science. The New York Times https://www.nytimes.com/2020/04/13/science/putin-russia-disinformation-health-coronavirus.html (13 April 2020).\n 44. Iran\u2019s reaction to coronavirus has become a danger for the world. The Washington Post  https://www.washingtonpost.com/opinions/global-opinions/\nirans-moment-of-truth-on-coronavirus/2020/03/03/f82548fe-5cca-11ea-b29b-9db42f7803a7_story.html (3 March 2020).\n 45. Coronavirus: world leaders\u2019 posts deleted over fake news. BBC News  \nhttps://www.bbc.com/news/technology-52106321 (31 March 2020).\n 46. Olteanu, A. et\u00a0al. Social data: biases, methodological pitfalls, and ethical boundaries. Front. Big Data  2, 13 (2019).\n 47. Pfeffer, J., Mayer, K. & Morstatter, F. Tampering with Twitter\u2019s Sample API. EPJ Data Sci. 7, 50 (2018).\n 48. Zimdar, M. My fake news list went viral but made up stories are only part of the problem. The Washington Post  h                 t        t             p      s             :         /                /   w               w           w             .     w            a        s                 h  i                 n        g             t     o            n           p              o    s               t          .            c       o            m        /                 p o                 s        t            e       v            e          r              -\ny    t              h        i        n   g        /     w           p /           2     0        1   6        /       1         1  /          1      8        /    m       y   -       fa       k   e     -  n    e  w    s-    l  i    s t   - w  en  t -  vi  r a  l- bu t- ma de -up-stories-are-only-part-of-the-problem/\n(18 November 2016).\n 49. Silverman, C. Inside the partisan fight for your news feed. BuzzFeed News https://www.buzzfeednews.com/article/craigsilverman/inside-the-partisan-fight-for-your-news-feed (8 August 2017).\n 50. Fake News Watch (2015); https://web.archive.org/web/20180213181029/http://www.fakenewswatch.com/\n 51. Politifacts guide to fake news and what they peddle. Politifacts.com   \nhttps://www.politifact.com/article/2017/apr/20/politifacts-guide-fake-news-websites-and-what-they/ (20 April 2017).\n 52. The black list. La lista nera del web. Bufale.net  https://www.bufale.net/\nthe-black-list-la-lista-nera-del-web/ (2018).\n 53. Starbird, K. et\u00a0al. Ecosystem or echo-system? Exploring content sharing across alternative media domains. In 12th International AAAI Conference on Web and Social Media 365\u2013374 (AAAI, 2018).\n 54. Fletcher, R. et\u00a0al. Measuring the Reach of \u2018Fake News\u2019 and Online Disinformation in Europe  (Reuters Institute, 2018); https://reutersinstitute.\npolitics.ox.ac.uk/our-research/measuring-reach-fake-news-and-online-disinformation-europe\n 55. Grinberg, N. et\u00a0al. Fake news on Twitter during the 2016 US presidential election. Science  363, 374\u2013378 (2019).\n 56. MediaBiasFactCheck (2020); https://mediabiasfactcheck.com/\n 57. Distribution of Twitter Users Worldwide as of July 2020, by Gender  \n(Statista, 2020); https://www.statista.com/statistics/828092/distribution-of-users-on-twitter-worldwide-gender/\n 58. Distribution of Twitter Users Worldwide as of July 2020, by Age Group (Statista, 2020); https://www.statista.com/statistics/283119/age-distribution-of-global-twitter-users/\nAcknowledgements\nWe received no specific funding for this work. We acknowledge the support of the FBK\u2019s \nDigital Society Department and the FBK\u2019s Flagship Project CHUB (Computational Human Behavior). We thank all FBK\u2019s Research Units for granting us privileged access \nto extraordinarily high-performance computing for the analysis of massive infodemic \ndata. We thank J. Baumgartner for sharing data between 21 January and 24 January 2020. We acknowledge the WHO Information Network for Epidemics (WHO EPI-WIN) for \nuseful discussions and the scientific members of the WHO ad hoc online consultation on \nmanaging the COVID-19 infodemic for very inspiring insights and conversations.\nAuthor contributions\nM.D.D. conceived the study. M.D.D. and F.V . collected the data. R.G., N.C. and F.V . analysed the data. M.D.D., P .S. and R.G. interpreted the data and wrote the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary information is available for this paper at https://doi.org/10.1038/\ns41562-020-00994-6.\nCorrespondence and requests for materials should be addressed to P .S. or M.D.Peer review information Primary handling editor: Stavroula Kousta.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.\n\u00a9 The Author(s), under exclusive licence to Springer Nature Limited 2020\nNAtuRe HuMAN BeHAVIOuR | VOL 4 | DeCeMBer 2020 | 1285\u20131293 | www.nature.com/nathumbehav 1293\n1 nature research  |  reporting summary April 2020\nCorresponding author(s): Pierluigi Sacco, Manlio de Domenico\nLast updated by author(s): Sep 16, 2020\nReporting Summary\nNature Research wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency  and transparency \nin reporting. For further information on Nature Research policies, see our Editorial Policies  and the Editorial Policy Checklist .\nStatistics\nFor all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Me thods section.\nn/a Confirmed\nThe exact sample size ( n) for each experimental group/condition, given as a discrete number and unit of measurement\nA statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly\nThe statistical test(s) used AND whether they are one- or two-sided \nOnly common tests should be described solely by name; describe more complex techniques in the Methods section.\nA description of all covariates tested\nA description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons\nA full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regress ion coefficient) \nAND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals)\nFor null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted \nGive P values as exact values whenever suitable.\nFor Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings\nFor hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes\nEstimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated\nOur web collection on statistics for biologists  contains articles on many of the points above.\nSoftware and code\nPolicy information about availability of computer code\nData collection Custom code (python)\nData analysis Custom code (python and R)\nFor manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published lit erature, software must be made available to editors and \nreviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Research  guidelines for submitting code & software  for further information.\nData\nPolicy information about availability of data\nAll manuscripts must include a data availability statement . This statement should provide the following information, where applicable: \n- Accession codes, unique identifiers, or web links for publicly available datasets \n- A list of figures that have associated raw data - A description of any restrictions on data availability\nThe datasets generated during the current study are available from the corresponding author on reasonable request. Aggregated i nformation, compliant with all \nprivacy regulations, are publicly available online at the Infodemics Observatory (http://covid19obs.fbk.eu/) and on a permanent  repository (DOI 10.17605/OSF.IO/\nN6UPX).\n2 nature research  |  reporting summary April 2020Field-specific reporting\nPlease select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before m aking your selection.\nLife sciences Behavioural & social sciences  Ecological, evolutionary & environmental sciences\nFor a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf\nBehavioural & social sciences study design\nAll studies must disclose on these points even when the disclosure is negative.\nStudy description Quantitative analysis of automatically gathering and spatially and temporally aggregated user-generated data from Twitter.\nResearch sample Over 100 Million Twitter messages\nSampling strategy Twitter Search API with keywords : coronavirus, ncov, #Wuhan, covid19, covid-19, sarscov2, covid\nData collection python scripts\nTiming 22 jan - 10 mar 2020\nData exclusions Messages whose user position could not be geocoded. Messages with no URLs shared\nNon-participation NA\nRandomization NA\nReporting for specific materials, systems and methods\nWe require information from authors about some types of materials, experimental systems and methods used in many studies. Here,  indicate whether each material, \nsystem or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the approp riate section before selecting a response. \nMaterials & experimental systems\nn/a Involved in the study\nAntibodies\nEukaryotic cell lines\nPalaeontology and archaeology\nAnimals and other organisms\nHuman research participants\nClinical data\nDual use research of concernMethods\nn/a Involved in the study\nChIP-seq\nFlow cytometry\nMRI-based neuroimaging", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Assessing the risks of 'infodemics' in response to COVID-19 epidemics", "author": ["R Gallotti", "F Valle", "N Castaldo", "P Sacco"], "pub_year": "2020", "venue": "Nature human \u2026", "abstract": "During COVID-19, governments and the public are fighting not only a pandemic but also a  co-evolving infodemic\u2014the rapid and far-reaching spread of information of questionable"}, "filled": false, "gsrank": 169, "pub_url": "https://www.nature.com/articles/s41562-020-00994-6", "author_id": ["3XaGvR0AAAAJ", "", "sjBJfG8AAAAJ", "xnwu184AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:xgi3V7k9b0sJ:scholar.google.com/&output=cite&scirp=168&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D160%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=xgi3V7k9b0sJ&ei=IbWsaPvmC7_SieoPzJnloAQ&json=", "num_citations": 675, "citedby_url": "/scholar?cites=5435631141509335238&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:xgi3V7k9b0sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41562-020-00994-6.pdf"}}, {"title": "Overview of the clef-2024 checkthat! lab task 6 on robustness of credibility assessment with adversarial examples (incrediblae)", "year": "2024", "pdf_data": "Overview of the CLEF-2024 CheckThat! Lab Task 6 on\nRobustness of Credibility Assessment with Adversarial\nExamples (InCrediblAE)\nPiotr Przyby\u0142a1,2,*, Ben Wu3, Alexander Shvets1, Yida Mu3, Kim Cheng Sheang1,\nXingyi Song3and Horacio Saggion3\n1Universitat Pompeu Fabra, Barcelona, Spain\n2Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland\n3University of Sheffield, Sheffield, UK\nAbstract\nTask 6 at CheckThat! Lab, organised at CLEF-2024, is devoted to assessing the robustness of misinformation\ndetection solutions implemented as text classification models. The participants of the task were provided with\nprediction models and data examples for several problems of credibility estimation and their goal was to come\nup with adversarial examples (AEs): small modifications to the provided text fragments, such that the original\nmeaning is preserved, but the victim classifier changes its decision. The evaluation involved five domains\n(detection of: biased news, propaganda techniques, false claims, rumours and COVID-19 misinformation) and\nthree classifiers (BiLSTM, BERT and adversarially fine-tuned RoBERTa). Six teams participated in the task,\nrepresenting a variety of approaches and substantially outperforming previous AE generation solutions. We also\nperformed manual evaluation, which highlighted some modification techniques that are particularly likely to\npass unnoticed by human readers. Overall, the task results emphasise the need to assess the robustness of text\nclassification solutions before implementing them in content filtering on large platforms, such as social media.\nKeywords\nadversarial examples, robustness, misinformation detection, credibility, text classification, natural language\nprocessing\n1. Introduction\nThe challenges of misinformation have been taken up with great energy and vigour by the NLP and IR\ncommunities. The main reasons for such enthusiastic adoption of the new tasks are wide availability of\ntextual data to train on and tantalisingly simple dichotomy of fake vs.real, clearly fitting the familiar\ntask of binary classification. Among a great deal of work in the domain [ 1,2], this framework has also\nenabled numerous shared tasks, including detecting hyperpartisan news [3], propaganda [4], bots [5],\nfalse claims [ 6] and more. These research results quickly found applications in content moderation for\nlarge media platforms, which increasingly rely on ML tools to support, but also to replace the human\neffort [7].\nHowever, a shared task framework is far from the real-world application scenario, where the test\ndata are not fixed, but are generated continuously by users. This means that if a malicious actor sees\ntheir non-credible content rejected by the system, they are likely to try to modify it to pass the filters,\nrather than simply abandon their goals. Unfortunately, the deep learning architectures, which many of\nthe best-performing solutions use, are known for their susceptibility to adversarial examples , i.e. data\ninstances modified with the intent of fooling a classifier [ 8]. While discovering adversarial examples\nfor text is more challenging than in other domains, it is definitely possible [ 9]. Thus, investigating\nCLEF 2024: Conference and Labs of the Evaluation Forum, September 09\u201312, 2024, Grenoble, France\n*Corresponding author.\n/envel\u2322pe-\u2322penpiotr.przybyla@upf.edu (P. Przyby\u0142a); bpwu1@sheffield.ac.uk (B. Wu); y.mu@sheffield.ac.uk (Y. Mu);\nkimcheng.sheang@upf.edu (K. C. Sheang); x.song@sheffield.ac.uk (X. Song); horacio.saggion@upf.edu (H. Saggion)\n/orcid0000-0001-9043-6817 (P. Przyby\u0142a); 0009-0002-0918-526X (B. Wu); 0000-0002-8255-9435 (Y. Mu); 0000-0002-4662-0358\n(K. C. Sheang); 0000-0002-4188-6974 (X. Song); 0000-0003-0016-7807 (H. Saggion)\n\u00a92024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\nCEURWorkshopProceedingsceur-ws.orgISSN 1613-0073\nthe robustness of text credibility assessment solutions is indispensable for making them applicable in\nreal-world adversarial scenarios.\nHere we report on the shared task on Investigating Robustness of Credib ility Assessment with\nAdversarial Examples ( InCrediblAE ), which was organised as Task 6 of the CheckThat! 2024 evaluation\nlab [ 10,11] at the CLEF 2024 conference. In InCrediblAE, participants get access to the following\nresources for each domain :\n1. three victim classifiers , assessing the credibility of the input text and returning a score,\n2. an attack dataset , including around 400 instances unseen by the classifier in training.\nIn the task we take into account five domains, corresponding to important challenges in the credibility\nassessment \u2013 see section 2 for details.\nThe goal of the participants is to make modification to the instances in the attack dataset, turning\nthem into adversarial examples. Each adversarial example (AE) is evaluated on meaning preservation , i.e.\nhow similar it is to the original; and classifier confusion , i.e. whether the output of the victim classifier\nis different than for the original.\nThe evaluation consists of two stages. The automatic evaluation follows the framework established\nin the field of adversarial learning, with the above factors assessed through automatic measures, i.e.\nBODEGA score [ 12], leading to a ranking list \u2013 see section 3.1. In the manual evaluation we use human\njudgement to assess the semantic similarity between attack sentences and their original counterparts.\nThis process aims to highlight potential errors arising from automatic evaluation metrics, as well as to\ncreate a high-quality text similarity dataset for the future development and evaluation of metrics \u2013 see\nsection 3.2.\nThe task has attracted six teams submitting various approaches (section 4.1), some of which have\nclearly outperformed previous solutions applied to the same problems (section 4.2), generally confirming\nthe high vulnerability of popular text classifiers to adversarial attacks. What is more, the results of the\nmanual evaluation (section 4.3) highlight cases where AEs might appear far from the original text if\njudged by automatic measures, but are in fact quite convincing to human annotators. The results of the\nmanual annotation are made openly available for future research1. We also share the code2and data3\nfor the automatic evaluation.\n2. Task data\nThe shared task uses the foundation of the BODEGA framework [ 12], which has been created to enable\nsystematic robustness testing in the area of misinformation detection. Within this framework, several\ndomains are available, each organised around a credibility assessment problem, defined as a binary text\nclassification task. Within a domain, an expert-annotated corpus of documents is used to train victim\nclassifiers (train subset) and test the attack performance (attack subset).\nThe participants are provided with Python code, hosted on Google Colab, allowing to interact with\nthe victim models in an attack scenario through OpenAttack interface [ 13]. Their goal is to prepare\na procedure that modifies the text fragments in the attack dataset to achieve a different decision of a\nclassifier with a minimal meaning alteration. The participant submission includes the AEs, as well as\nthe number of victim model queries needed to find them.\n2.1. Datasets\nFour of the domains in InCrediblAE have been prepared in BODEGA based on previously published\ncorpora. The final one (C19) is new and was not available before.\nStyle-based news bias assessment (HN) is a task of verifying credibility of a news article based\non its overall writing style. It relies on previous work indicating that stylistic analysis of fake news\n1https://github.com/GateNLP/CLEF2024_InCrediblAE_Manual_Evaluation_Dataset\n2https://github.com/piotrmp/BODEGA\n3https://gitlab.com/checkthat_lab/clef2024-checkthat-lab/-/tree/main/task6\nTable 1\nThe sizes of subsets in each domain and the percentage of cases labelled as positive.\nTask Training Attack Development Positive\nHN 60,235 400 3,600 50.00%\nPR 12,675 416 3,320 29.42%\nFC 172,763 405 19,010 51.27%\nRD 8,694 415 2,070 32.68%\nC19 1,130 595 0 42.55%\noutlets can be used to distinguish them from credible sources [ 14,15]. The corpus contains news\nbias annotations assigned at the level of the source (whole website) by journalists from BuzzFeed and\nMediaBiasFactCheck.com4. For the purpose of BODEGA, 10% of the training instances were used and\nthe non-credibility label was assigned to articles from sources marked as hyperpartisan, both left- and\nright-wing.\nPropaganda detection (PR) is focused on recognising specific manipulation techniques appealing\nto emotions [ 16], for example name-calling, flag-waving or straw-man fallacy. This approach has\nthe advantage of being fine-grained by highlighting manipulative fragments in text, akin to the NER\n(Named Entity Recognition) tasks. We rely on the token-level annotations of 14 techniques, marked\nby professional annotators for the SemEval 2020 Task 11 ( Detection of Propaganda Techniques in News\nArticles ) [4], for which the training set is public5. In order to cast the task as binary text classification for\nBODEGA, the corpus was split into sentences and those including some tokens marked as propaganda\nwere labelled as non-credible.\nFact checking (FC) is an approach to misinformation detection based on extracting claims made in\na piece of text and verifying them with respect to a trusted knowledge base [ 17]. In order to represent\nthe problem as binary classification, we focus on the final stage of the workflow, when a claim is\ncompared to relevant evidence from the knowledge base, which either confirms its validity or refutes\nit. In BODEGA, the data from the FEVER shared task [ 18] is used, consisting of claims that were\npaired with relevant passages from Wikipedia articles. The instances where a claim is supported by the\nevidence were labelled as credible, and those when it is refuted as non-credible.\nRumour detection (RD) is aimed at detecting information spreading widely over social media\ndespite it not coming from a credible source. Rumours can be detected using many indicators [ 19],\nbut here we focus on the textual content of a social media post, as well as the reactions of other\nusers. In BODEGA, this is achieved thanks to the augmented dataset of rumours and non-rumours for\nrumour detection [20], created from Twitter threads relevant to six real-world events, labelled by experts\naccording to the source reliability of the initial post. One of the events (Charlie Hebdo shooting) was\nset aside as the attack dataset.\nCOVID-19 misinformation detection (C19) focuses on binary classification6of misinformation\nrelated to COVID-19 [ 21,22]. Given a known false claim about the disease, the task is to determine\nwhether a user\u2019s tweet supports that false claim. If so, the tweet is classified as COVID-19 misinformation\n(positive class). Alternative responses, such as contradicting, questioning, commenting, or irrelevance\nregarding the false claim are reserved for the negative class. Appendix B provides examples from the\ndataset.\nTable 1 summarises the information on datasets, including the sizes of subsets: training (for training\nvictim classifiers), development (reserved for future use) and attack (to be modified into AEs), as well as\nthe percentage of positive (non-credible) instances.\n4https://zenodo.org/record/1489920\n5https://zenodo.org/record/3952415\n6We merged IRRELEVANT and DEBUNK class as non-misinfo to covert original dataset into a binary classification\n2.2. Victim classifiers\nTraining datasets were used to prepare victim models, representing popular approaches to text classifi-\ncation. Two of the models (BiLSTM and BERT) were trained as in BODEGA framework, but the surprise\nclassifier was trained specifically for the shared task and it was revealed to the participants in the test\nphase, one week before the submissions.\nBiLSTM classifier consists of an embedding layer (token representations of size 32), two LSTM [ 23]\nlayers (forwards and backwards, hidden representation of size 128) and a dense linear layer converting\nthe text fragment representation (of size 256) into two-class probability, normalised using softmax.\nBERT classifier is a bert-base-uncased model [ 24] from the HuggingFace Transformers library\n[25], fine-tuned for sequence classification using Adam optimiser with linear weight decay [ 26] for 5\nepochs.\nSurprise classifier is a RoBERTa model [ 27], i.e. roberta-base from HuggingFace Transformers ,\nadversarially-trained to be more robust to adversarial attacks. We use data augmentation to improve\nrobustness: First, the model is fine-tuned for one epoch on the train dataset, then adversarial examples\nare generated from the entire train dataset using BERT-ATTACK [ 28], and then the model is fine-tuned\nfor one epoch on a combination of the train dataset and the successful adversarial examples. We train\nwith constant learning rate 2\u00d710\u22125and the Adam optimiser. We use batch of size 32 for all tasks\nexcept PR, which uses a batch of size 64. Due to computational constraints, for HN we only generate\nadversarial examples from a subset (6000 samples) of the training data.\n3. Evaluation\nThe evaluation procedure consists of two stages. Firstly, the BODEGA framework is used to automatically\nassess the attack effectiveness of each participant in 15 scenarios (5 domains \u00d73 victims). The average\nBODEGA score is used to create the leaderboard, expressing the overall performance. Secondly, the\ntask most challenging for automatic evaluation (fact-checking) is used to perform manual annotation of\nmeaning preservation in selected instances.\n3.1. Automatic evaluation\nIn automatic evaluation, when an example \ud835\udc65\ud835\udc56is modified into AE \ud835\udc65*\n\ud835\udc56, the quality of the transformation\nis assessed through BODEGA score defined as follows [12]:\nBODEGA_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56) =Con_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56)\u00d7Sem_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56)\u00d7Char_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56),\nwhere:\n\u2022Con_score , i.e. confusion score, takes value of 1when the attacked classifier predicts a different\nclass for \ud835\udc65*\n\ud835\udc56than it did for \ud835\udc65\ud835\udc56, and 0 otherwise.\n\u2022Sem_score , i.e. semantic similarity score, is a measure of meaning preservation between \ud835\udc65\ud835\udc56and\n\ud835\udc65*\n\ud835\udc56, computed using the BLEURT [29] evaluation measure ( BLEURT-20 variant), clipped to the\n(0-1) range.\n\u2022Char_score , i.e. character similarity score, is a measure of similarity of \ud835\udc65\ud835\udc56and\ud835\udc65*\n\ud835\udc56as character\nsequences, computed through Levenshtein distance [30], scaled to (0-1) similarity.\nWe can see that an AE will be ranked highly if it changes the output of the classifier\n(Con_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56) = 1 ), but at the same time preserves both the meaning ( Sem_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56)\u22481)\nand the appearance (Char_score (\ud835\udc65\ud835\udc56, \ud835\udc65*\n\ud835\udc56)\u22481) of the original text.\nTo measure the overall attack success in a particular scenario, the BODEGA score averaged over all\ninstances in the attack set is employed. However, the constituent scores, also averaged over the dataset,\ncan be used to understand the results. We also report the number of queries that is needed (on average)\nfor a single AE to be found.\nTable 2\nCategory definitions for the manual evaluation.\nCategory Definitions\nPreserve the\nSemantic MeaningThis label is used when the semantic content of the attack sample closely aligns with that of the original sample.\nParticipants should use this label if the meaning, context, and intent of the compared texts remain essentially un-\nchanged, indicating that the attack sample has effectively maintained the core message of the original.\nChange the\nSemantic MeaningParticipants should apply this label when there is a noticeable alteration in the semantic content between the ori-\nginal and the attack sample. This label indicates that while the attack sample may be related or similar in some\naspects to the original, it diverges enough in meaning or intent to be considered distinct or modified. For example,\nname entities (including Year, Name, Location, etc.) are changed in the modified text.\nNo sense The content of the attack sample does not make any sense.\nTable 3\nConfidence scores and definitions used by Mu et al. [31].\nConfidence Definitions\n1Extremely unconfident about the annotation (I\u2019m really unsure about the annotation. It may belong\nto another category as well, you may wish to discard this instance from the training.)\n2Not confident about the annotation (I\u2019m not sure about the annotation, it seems it also belongs to\nother categories, but you can still include this instance as a \u201csilver standard instance\u201d in training.)\n3Pretty confident about the annotation (I\u2019m pretty sure about the annotation, but might be in high\nchance other annotators may label it in a different category.)\n4Fairly confident about the annotation (I\u2019m confident about the annotation, but might be in small\nchance other annotators may label it in a different category.)\n5 Extremely confident about the annotation (I\u2019m certain about the annotation without a doubt.)\n3.2. Manual evaluation\nThe goal of the manual evaluation is to highlight the cases where the automatic evaluation measures,\nespecially regarding semantic similarity, might not be an accurate representation of human reception of\nthe adversarially modified content. To that end, we have selected the samples from the fact-checking do-\nmain and the surprise victim, where even small changes in text can alter the meaning and, consequently,\nthe credibility label.\nTask Description We aim to gather assessments regarding the semantic similarities between attack\nsamples and the original samples. Participants in the shared task are requested to dedicate approximately\n60 minutes to this manual evaluation (i.e., 100 samples per participant), which are conducted using an\nopen-source, collaborative annotation platform, i.e., GATE Teamware 2 [ 32]. Judges rate the sample\npairs based on the following scale: (a). Preserve the Semantic Meaning, (b). Change the Semantic\nMeaning, and (c). No sense. Table 2 demonstrates categories and descriptions. Similar to the work of\nMu et al. [31], annotators are required to indicate the confidence level (see Table 3) of their assigned\nclass in the \u2018Confidence Row\u2019.\nData Sampling We randomly select 100 paired samples (i.e., original and modified texts) from\neach submission, resulting in a total of 600 paired samples. Note that only the successful attacks are\nconsidered.\nAnnotator Training We train the annotators by providing a training document detailing the anno-\ntation pipeline, which includes (i) a step-by-step tutorial for using the GATE Teamware platform, (ii)\na user information sheet to inform about any potential issues and risks that may occur during data\nannotation, and (iii) a user consent sheet as required by the ethical approval from the University of\nSheffield, where the annotation was performed.\nA total of 12 annotators (i.e., 6 participants and 6 organisers) were recruited to manually annotate the\npaired samples. These 12 annotators were further divided into 6 separate groups (i.e., two annotators\nper group). In each group, 100 tweets were assigned to each annotator. Finally, this process yielded 100\ndouble-annotated paired samples from each group, resulting in 600 double-annotated samples in total.\nAnnotation Methodology and Quality Assurance All samples are double-annotated by the shared\ntask organizers and participants. Briefly, each paired sample is annotated by one participant and one\nshared task organiser. A third annotator from the shared-task organisers is used to resolve any conflicts.\nGiven that there are three categories in total, the annotation with the highest confidence score will be\nconsidered in the case of three differing annotations.\n4. Results\nHere we outline the results of the InCrediblAE shared task in three steps: first, we describe the solutions\nsubmitted by the participants (section 4.1), then we present the results of the automatic (section 4.2)\nand manual evaluation (section 4.3).\n4.1. Participating solutions\nThe SINAI team [ 33] proposes a method for adversarial attacks based on the substitution of characters\nby homoglyphs (e.g. characters which resemble the target such as l \u22481). The method uses exhaustive\nsearch with two variants: with memory and without memory. They ground their approach in the fact\nthat homoglyphs could deceive the human eye while at the same time provoke a Large Language Model\nclassifier to reverse its prediction due to the presence of an unexpected token. According to the official\nleader board, the approach is sub-optimal, obtaining the last rank in the task according to the official\nevaluation metrics. However, human evaluation of content preservation is ranked high.\nThe MMU_NLP participation [ 34] features a system to attack classifiers based on lexical substitution\nand character replacement. The proposed method searches for candidate words to attack followed\nby a word replacement mechanism. The word search mechanism masks words to check their vulner-\nability with those words having a high impact on the classifier performance retained for the attack.\nThe replacement step uses homoglyphs for character replacement or lexical substitution. Character\nreplacement is tested in two different conditions: random character attack or begin/end of word attack.\nThe lexical replacement attack uses a large language model to retrieve a word similar to the target\nword. Overall result fall short compared to other participants, however the proposed methods improves\nover the baseline in several settings. The character attack method seems more effective than the word\nreplacement approach.\nThe Pal\u00f6ri team [ 35] proposes an approach to identify vulnerable words by computing (relying on a\nmasked language model) the difference between the probability distribution of the original sentence\nand the sentence with a word masked. These differences are used as scores to rank words by their\n\"vulnerability\" according to the model. The ranked words (most to least vulnerable) are then replaced\nusing a word from a list of substitutes proposed by the language model. The sentence with the replaced\nword is used to attack the victim classifier. In case of success, the new sentence is returned, otherwise\nthe method loops using the sentence with the \"best\" possible substitution (i.e. one which reduced the\nvictim\u2019s confidence the most). The method produces successful attacks which however do not preserve\nthe original sentence\u2019s meaning. To address this problem a \"synonym\" dictionary is created, using\nGloVe embeddings and the aclImbd dataset, to draw substitutes from. The new method only contributes\nminor improvements over the masked language model.\nThe solution of the OpenFact team [ 36] consists in a coupling of various word-substitution approaches\nin an ensemble in such a way that if the first approach does not succeed in changing the classifier\u2019s\ndecision, then the second one is called. In particular, a modification of BERT-ATTACK [ 28] was\nproposed (it features a change in parameter values, an alternative selection of a replacement position\nby an exhaustive search of candidates that provide the largest difference in probabilities for a predicted\nclass, and an iterative replacement from 1 to 7 words, including punctuation and digits at the latter,\nuntil the success of an attack) and backed up by a genetic algorithm [ 37] realised in the OpenAttack\nframework [ 13]. Another ensemble was compiled of a proposed greedy search by word swap with\nsynonyms in the word embedding space (prebuilt \"counter-fitted\" GloVe embeddings [ 38]) and another\nmodel available in the OpenAttack, TextFooler [ 39], which unlike other similar approaches replaces\nwords in agreement with the syntax of the attacked text. Apart from ensemble models, approaches\nfrom the TextAttack framework [ 40] were used. They demonstrated superior performance over the\nbaseline methods in automatic scores. In particular, CLARE [ 41] \u2013 a model that implements a special\nmask-then-infill procedure that incorporates replace/insert/merge operations allowing for outcomes\nvaried in length \u2013 was applied for PR, FC and C19 tasks and consistently yielded better results in all\nautomatic scores. Overall, this solution gained the best automatic scores in most of the domains for\nmost of the victims, which made it the first in the leaderboard created by averaging the scores across\nall scenarios. However, it was ranked very low within the human evaluation, as in the majority of the\ncases the meaning of the text was changed.\nThe TurQUaz [ 42] team leverages a genetic algorithm to look for a combination of character modifica-\ntions. The modifications that are introduced using a mutation operator include homoglyph replacement,\nthree options of word splitting (random, favouring existing words in the subword outcome, and special\nheuristic-wise), insertion or removal of individual random letters, and shuffling the order of the letters\nwithin the word. The search is carried out until the first flip is found. Only the use of homoglyphs and\nword splits proved to be efficient. Apart from the genetic algorithm, the team experimented with attacks\nmade by utilizing large language models (LLMs) such as Llama 37and Mistral8. Three approaches have\nbeen tried: (i) prompting a model for text paraphrasing, (ii) leveraging a model for identifying words to\nbe changed, and (iii) generating adversarial examples with one LLM and verifying whether an attack is\ngoing to be successful with another LLM. None of the approaches outperformed the genetic algorithm,\nhowever, the team believes in the potential of LLMs and suggests fine-tuning the models specifically for\nthis task to improve their performance in the future. The primary solution has been ranked third based\non the BODEGA score.\nThe TextTrojaners team [ 43] introduces a BeamAttack method that makes attacks at a word level using\nRoBERTa [ 27] and a beam search as a backbone to produce contextually appropriate word substitutions.\nBeam search algorithm adapted by enabling operations of replacing, skipping, or removing words\nallows for generating and evaluating multiple alternative word replacement combinations in a single\nrun. For the identification of the most vulnerable words to be replaced, the team experiments with\ntwo ranking approaches that use the explainable AI framework LIME [ 44] and logit-based importance\nscores, as proposed in [ 28]. In a series of ablation studies, they show that the choice of a ranking method\nvaries across victims and depends on the dataset. The solution achieved the second-best result on the\nBODEGA evaluation metric but gained rather low manual evaluation scores.\n4.2. Automatic evaluation\nTable 4 includes the results of the evaluation against the BiLSTM victim. Generally, we can see that\ndifferent approaches dominate in different scenarios. However, in every domain, the best BODEGA\nscore (in boldface) is achieved by a solution submitted to InCrediblAE, rather than a reference solution\nfrom previous work (BERT-ATTACK or DeepWordBug). HN appears to be the easiest domain, with the\nleading solution (TextTrojaners) achieving BODEGA score of 0.91 through 100% confusion with 91%\nsemantic similarity and 99% character similarity. This result, closely followed by OpenFact, is especially\nimpressive when compared to the scores of BERT-ATTACK (BODEGA score of 0.64). The TextTrojaners\napproach also leads in PR, but we need to note its high amount of queries needed \u2013 in this case, 593\ncompared to TurQUaz achieving almost the same result (0.68 instead of 0.70) with six times less queries.\nThe C19 appears to be the domain most challenging for attacks, although even here we note a vast\nimprovement over the reference method (OpenFact: 0.72 vs BERT-ATTACK: 0.50).\nIn the attacks against the BERT victim, evaluated in table 5, the OpenFact method dominates, ceding\nonly in FC to homoglyph-based SINAI. We can also note that the best BODEGA score is either equivalent\n(for FC, HN and C19) or significantly lower (for PR and RD) than for BiLSTM, indicating higher difficulty\nof attacking a Transformer-based classifier. This also results in a higher number of queries necessary to\n7https://huggingface.co/docs/transformers/model_doc/llama3\n8https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\nTable 4\nResults of the automatic evaluation of attacks against the BiLSTM victims, for each of the five domains, expressed\nthrough BODEGA score and its constituents, as well as the number of queries (except for OpenFact, whose\nsubmission did not include this value).\nDomain Method BODEGA Confusion Semantic Character Queries\nPR MMU_NLP 0.40 0.57 0.74 0.95 390.42\nOpenFact 0.65 0.94 0.77 0.89 -\nPal\u00f6ri 0.60 0.98 0.68 0.90 52.31\nSINAI 0.34 0.37 0.93 0.98 318.27\nTextTrojaners 0.70 0.97 0.80 0.90 593.38\nTurQUaz 0.68 0.95 0.76 0.94 96.22\nBERT-ATTACK 0.53 0.80 0.72 0.91 61.41\nDeepWordBug 0.29 0.38 0.79 0.96 27.45\nFC MMU_NLP 0.49 0.66 0.77 0.96 175.32\nOpenFact 0.80 0.98 0.84 0.97 -\nPal\u00f6ri 0.69 1.00 0.71 0.97 76.47\nSINAI 0.82 0.98 0.86 0.96 507.16\nTextTrojaners 0.76 1.00 0.81 0.94 1,549.12\nTurQUaz 0.79 1.00 0.82 0.97 39.44\nBERT-ATTACK 0.60 0.86 0.73 0.95 132.80\nDeepWordBug 0.48 0.58 0.85 0.98 54.36\nRD MMU_NLP 0.12 0.28 0.44 0.97 2,198.42\nOpenFact 0.84 0.95 0.91 0.98 -\nPal\u00f6ri 0.30 0.71 0.44 0.95 532.04\nSINAI 0.14 0.17 0.85 1.00 140.96\nTextTrojaners 0.83 1.00 0.87 0.96 3,831.72\nTurQUaz 0.39 0.67 0.61 0.95 276.93\nBERT-ATTACK 0.29 0.79 0.41 0.89 985.52\nDeepWordBug 0.16 0.24 0.68 0.99 232.75\nHN MMU_NLP 0.54 0.91 0.59 0.99 898.83\nOpenFact 0.89 0.97 0.93 0.99 -\nPal\u00f6ri 0.64 0.99 0.65 0.99 373.22\nSINAI 0.41 0.48 0.87 1.00 172.92\nTextTrojaners 0.91 1.00 0.91 0.99 936.96\nTurQUaz 0.62 1.00 0.65 0.96 68.30\nBERT-ATTACK 0.64 0.98 0.66 0.99 487.85\nDeepWordBug 0.41 0.53 0.77 1.00 396.18\nC19 MMU_NLP 0.45 0.78 0.60 0.95 149.15\nOpenFact 0.72 0.91 0.83 0.96 -\nPal\u00f6ri 0.53 0.99 0.57 0.93 110.90\nSINAI 0.26 0.30 0.88 1.00 33.03\nTextTrojaners 0.72 0.99 0.77 0.92 837.35\nTurQUaz 0.58 0.93 0.65 0.96 103.10\nBERT-ATTACK 0.50 0.84 0.62 0.95 127.17\nDeepWordBug 0.33 0.48 0.70 0.99 61.15\nfind an AE, e.g. while the leading method for HN domain needed 937 queries to obtain the score of 0.91\nwith BiLSTM, attacking BERT with the same approach requires 4328 queries on average.\nThe results for the surprise victim (table 6) show that the adversarially-trained classifier indeed is\nmore challenging to attack, leading to lower scores in PR and RD domains. However, the general view\nremains similar, with OpenFact again dominating with the exception of FC. Their approach clearly works\nvery well with Transformer-based victims, just with an exception of this single task. The increasing\nlevel of difficulty is again reflected in a rising numbers of queries, reaching a record value of over 15000\nfor TextTrojaners attacking in the RD domain.\nFinally, table 7 shows the final leaderboard obtained by averaging the BODEGA scores across\nTable 5\nResults of the automatic evaluation of attacks against the BERT victims, for each of the five domains, expressed\nthrough BODEGA score and its constituents, as well as the number of queries (except for OpenFact, whose\nsubmission did not include this value).\nDomain Method BODEGA Confusion Semantic Character Queries\nPR MMU_NLP 0.33 0.47 0.75 0.95 438.26\nOpenFact 0.68 0.97 0.77 0.89 -\nPal\u00f6ri 0.56 0.97 0.64 0.88 65.37\nSINAI 0.38 0.43 0.92 0.98 288.73\nTextTrojaners 0.62 0.99 0.71 0.86 4,097.37\nTurQUaz 0.46 0.68 0.72 0.94 254.75\nBERT-ATTACK 0.43 0.70 0.68 0.90 80.16\nDeepWordBug 0.28 0.36 0.79 0.96 27.43\nFC MMU_NLP 0.55 0.73 0.78 0.96 710.29\nOpenFact 0.80 1.00 0.83 0.97 -\nPal\u00f6ri 0.62 0.98 0.66 0.96 102.52\nSINAI 0.82 0.97 0.86 0.98 250.74\nTextTrojaners 0.79 1.00 0.83 0.96 1,390.83\nTurQUaz 0.74 1.00 0.78 0.95 70.70\nBERT-ATTACK 0.53 0.77 0.73 0.95 146.73\nDeepWordBug 0.44 0.53 0.84 0.98 54.32\nRD MMU_NLP 0.15 0.37 0.42 0.93 986.24\nOpenFact 0.65 0.78 0.86 0.95 -\nPal\u00f6ri 0.18 0.45 0.42 0.94 1,077.24\nSINAI 0.12 0.14 0.87 1.00 143.06\nTextTrojaners 0.59 0.80 0.79 0.91 10,618.93\nTurQUaz 0.22 0.38 0.61 0.95 417.75\nBERT-ATTACK 0.18 0.44 0.43 0.96 774.31\nDeepWordBug 0.16 0.23 0.70 0.99 232.74\nHN MMU_NLP 0.47 0.86 0.55 0.97 806.60\nOpenFact 0.91 1.00 0.92 0.99 -\nPal\u00f6ri 0.60 0.96 0.64 0.98 502.03\nSINAI 0.24 0.27 0.87 1.00 245.10\nTextTrojaners 0.85 1.00 0.87 0.97 4,327.67\nTurQUaz 0.46 0.84 0.59 0.93 223.54\nBERT-ATTACK 0.60 0.96 0.64 0.97 648.41\nDeepWordBug 0.22 0.29 0.78 1.00 395.94\nC19 MMU_NLP 0.45 0.82 0.58 0.95 142.18\nOpenFact 0.72 0.91 0.82 0.96 -\nPal\u00f6ri 0.52 0.96 0.57 0.93 201.01\nSINAI 0.41 0.47 0.89 1.00 32.16\nTextTrojaners 0.71 0.98 0.78 0.92 2,628.90\nTurQUaz 0.57 0.96 0.62 0.95 102.92\nBERT-ATTACK 0.42 0.74 0.60 0.95 161.70\nDeepWordBug 0.27 0.39 0.71 0.99 61.06\nvictims and domains. We can see that all solutions submitted to the task have beaten the DeepWordBug\nreference and most have also outperformed BERT-ATTACK, which is a strong reference point. OpenFact\nand TextTrojaners are clear leaders, with the former slightly better-performing, especially against\nTransformers victim. However, we need to emphasise that the averaged ranking does not show the\nwhole picture and various methods work best for various scenarios. For example, SINAI is the best\napproach for the BERT-FC combination.\nTable 6\nResults of the automatic evaluation of attacks against the Surprise victims, for each of the five domains,\nexpressed through BODEGA score and its constituents, as well as the number of queries (except for OpenFact,\nwhose submission did not include this value).\nDomain Method BODEGA Confusion Semantic Character Queries\nPR MMU_NLP 0.28 0.40 0.76 0.94 525.66\nOpenFact 0.62 0.93 0.75 0.87 -\nPal\u00f6ri 0.25 0.54 0.55 0.83 482.21\nSINAI 0.26 0.31 0.89 0.97 374.20\nTextTrojaners 0.45 0.97 0.55 0.79 10,286.82\nTurQUaz 0.20 0.26 0.78 0.95 471.40\nBERT-ATTACK 0.20 0.32 0.69 0.91 117.64\nDeepWordBug 0.13 0.17 0.81 0.96 26.87\nFC MMU_NLP 0.51 0.68 0.78 0.96 201.15\nOpenFact 0.80 1.00 0.82 0.97 -\nPal\u00f6ri 0.66 1.00 0.68 0.97 117.77\nSINAI 0.44 0.50 0.89 0.99 43.14\nTextTrojaners 0.82 1.00 0.84 0.97 498.93\nTurQUaz 0.71 1.00 0.75 0.94 90.55\nBERT-ATTACK 0.56 0.79 0.73 0.96 164.07\nDeepWordBug 0.37 0.46 0.83 0.98 53.39\nRD MMU_NLP 0.16 0.35 0.46 0.97 2,894.29\nOpenFact 0.55 0.71 0.82 0.93 -\nPal\u00f6ri 0.19 0.47 0.43 0.93 1,513.25\nSINAI 0.09 0.10 0.85 1.00 149.12\nTextTrojaners 0.54 0.87 0.69 0.84 15,458.12\nTurQUaz 0.17 0.28 0.63 0.96 466.13\nBERT-ATTACK 0.17 0.41 0.42 0.95 951.87\nDeepWordBug 0.12 0.18 0.69 0.99 229.56\nHN MMU_NLP 0.47 0.77 0.62 0.97 713.89\nOpenFact 0.83 0.99 0.86 0.97 -\nPal\u00f6ri 0.34 0.57 0.62 0.98 1,453.38\nSINAI 0.36 0.41 0.88 1.00 202.67\nTextTrojaners 0.67 1.00 0.72 0.92 4,596.62\nTurQUaz 0.28 0.47 0.61 0.94 376.77\nBERT-ATTACK 0.38 0.67 0.60 0.95 1,781.97\nDeepWordBug 0.16 0.21 0.76 1.00 384.34\nC19 MMU_NLP 0.42 0.76 0.58 0.94 155.45\nOpenFact 0.72 0.99 0.78 0.93 -\nPal\u00f6ri 0.46 0.99 0.51 0.89 299.37\nSINAI 0.17 0.18 0.92 1.00 37.97\nTextTrojaners 0.65 1.00 0.71 0.91 6,491.39\nTurQUaz 0.41 0.75 0.59 0.92 253.78\nBERT-ATTACK 0.37 0.68 0.58 0.93 198.26\nDeepWordBug 0.20 0.28 0.72 0.98 60.94\n4.3. Manual Evaluation\nWe randomly selected 100 successful adversarial samples from each team\u2019s submission to the scenario\nincluding fact checking and surprise victim. During the evaluation, both the original and adversarial\nsamples were presented to the annotators, with differences highlighted. The annotators were asked to\ncategorise each sample pair into one of the three categories described in Section 3.2. They also provided\na confidence score for each annotation (5: very confident, 1: not confident). Each sample pair was\njudged by at least two annotators. The annotation agreement of the initial annotators was 0.52 (Cohen\u2019s\nKappa). A third annotator was invited if there was a conflict between the two initial annotators.\nWe determined the ranking of participants by the number of samples that fell into the \u2019Preserve the\nTable 7\nFinal leaderboard, created by averaging BODEGA scores across all scenarios (five domains and three victims).\n# Method BODEGA avg.\n1. OpenFact 0.7458\n2. TextTrojaners 0.7074\n3. TurQUaz 0.4859\n4. Pal\u00f6ri 0.4776\n5. MMU_NLP 0.3848\n6. SINAI 0.3507\n- BERT-ATTACK 0.4261\n- DeepWordBug 0.2682\nTable 8\nManual evaluation results.\nTeam % of Preserve the meaning\nSINAI 99%\nMMU_NLP 96%\nTurQUaz 62%\nPlagori 14%\nOpenFact 11%\nTextTrojaners 7%\nSemantic Meaning\u2019 category, adhering to the principle that a higher count indicates better performance.\nThis ranking method was used because the task demands that the adversarial samples maintain their\noriginal meaning. Table 8 presents the final manual evaluation results for all participants.\nIn general, we observe we observe a discrepancy between the manual and automatic evaluations\n(see Table 7). This may be because the manual evaluation task is a fact-checking task. Even a slight\nreplacement of named entities (such as changing the year from 1990 to 1991) could result in a change of\nmeaning.\nThe leading team (SINAI) in manual evaluation uses an adversarial attack method mainly based on\nthe substitution of characters with homoglyphs and achieves a 99% score. This suggests that the use of\nhomoglyphs can successfully deceive the annotator\u2019s eye. Similarly, team MMU employs similar attack\napproaches, such as lexical substitution and character replacement, which also achieve a high manual\nevaluation score (96%).\nTeam TurQUaz proposes a method of inserting white space to split English words, which achieved\nthird place on the leaderboard (62%). However, this method may sometimes change the meaning of\nthe original fact-checking document, resulting in a lower manual evaluation score compared to the\nmethods proposed by teams SINAI and MMU. Besides, by inserting white space in the original text,\nthe modified text may become non-interpretable by humans, resulting in a high proportion of third\ncategory submissions by Team TurQUaz, i.e., \u201cThe sentence does not make any sense.\u201d\nWe observe that OpenFact (11%) and TextTrojaners (7%) obtain lower manual evaluation scores. By\nmanually investigating text modified by Team OpenFact, we notice that some key information, such as\ntime and location, has been changed. Note that such named entities play a vital role in the context of\nfact-checking downstream tasks. Therefore, changes to these named entities result in a higher number\nof samples labelled as \u201cChange the Semantic Meaning.\u201d As for the solution of TextTrojaners, the choice\nof alternative words solely depends on the context rather than the word to be replaced. This can\nsignificantly deviate the meaning. In addition, the operation of word removal without further word\nagreement adjustment may lead to nonsensical sentences.\n5. Discussion\nThe first conclusion from the results obtained is clear: the state of the art in AE generation for misinfor-\nmation detection, established by previous solutions, has advanced considerably. Various solutions were\nsubmitted to the shared task, but they are based on the established lines of research in the area: word\nreplacements (preserving meaning similarity) or character replacements (preserving visual similarity).\nThe word-level solutions (esp. TextTrojaners and OpenFact) were performing the best in most\nscenarios, but not all of them. Fact checking is a clear outlier due to its nature: every word matters,\nmaking it hard to perform any change without drastically affecting the meaning. This opens the avenue\nfor character-level modifications and, indeed, such solution (SINAI) provided the best results in manual\nevaluation.\nWe also need to acknowledge the limitations of the evaluation setup. It aims to predict the likelihood\nof an AE fooling the victim classifier and transmitting the intended message, as encoded through\nBODEGA score. However, human readers are the intended recipients of misinformation, and they are\nalso able to refuse to engage with a message that seems suspicious, artificial or distorted, e.g. due to use\nof letter with non-standard shapes. Thus, the success of AEs will also depend on the visual appearance\nof the manipulated content, which is not directly evaluated in the current setup. Quantifying this effect\nwould be challenging in manual evaluation and even more so in an automatic setup.\nIn any case, the results that we do have leave one thing clear: popular architectures for text classifi-\ncation are very vulnerable to attack with AEs. While the adversarially-trained model posed slightly\nharder challenge, ultimately AEs were found for nearly all cases in these scenarios as well.\nHow can we protect the real-world deployments of text classifiers against such attack? The first\nbarrier can be established by limiting the access to the victim model. We can see from the results that\nthe advance over previous state of the art was accompanied by a raise in the number of queries sent, well\ninto hundreds and thousands for each generated AE sample. Nevertheless, all machine-learning-based\nsolutions for content filtering should be only deployed after a thorough analysis of their adversarial\nrobustness.\n6. Conclusion\nIn the InCrediblAE shared task, six teams participated with various solutions, both operating with the\nword-level and character-level changes. The participants\u2019 approaches (and two reference solutions)\nwere evaluated using five misinformation-detection scenarios and three victim models.\nIn total, 53,544 text modifications were considered and automatically assessed in terms of classifier\nconfusion, meaning preservation and character similarity. The submitted solutions easily outperformed\nprevious work in all of the tested scenarios. The manual evaluation highlighted the special role of the\nfact-checking tasks and the efficacy of character replacement in performing modification imperceptible\nto humans.\nWe hope that the combined effort of the participants and organisers of the InCrediblAE shared task\nwill succeed in both highlighting the importance of robustness testing and showcasing the best solutions.\nTo facilitate this outcome, the code and resources necessary for performing the automatic evaluation\nremain openly available.9\nAcknowledgments\nThe work of P. Przyby\u0142a is part of the ERINIA project, which has received funding from the European\nUnion\u2019s Horizon Europe research and innovation programme under grant agreement No 101060930.\nThis work has been also partially funded by the European Commission under contract numbers HE-\n101070278 and ISF-101080090. Views and opinions expressed are however those of the author(s) only\nand do not necessarily reflect those of the funders. Neither the European Union nor the granting\n9https://github.com/piotrmp/BODEGA\nauthority can be held responsible for them. We also acknowledge support from Departament de Recerca\ni Universitats de la Generalitat de Catalunya (ajuts SGR-Cat 2021) and from Maria de Maeztu Units of\nExcellence Programme CEX2021-001195-M, funded by MCIN/AEI /10.13039/501100011033.\nReferences\n[1]J. A. Tucker, A. Guess, P. Barber\u00e1, C. Vaccari, A. Siegel, S. Sanovich, D. Stukal, B. Nyhan,\nSocial Media, Political Polarization, and Political Disinformation: A Review of the Scien-\ntific Literature, Technical Report, Hewlett Foundation, 2018. URL: https://hewlett.org/library/\nsocial-media-political-polarization-political-disinformation-review-scientific-literature/.\n[2]S. van der Linden, Misinformation: susceptibility, spread, and interventions to immunize the\npublic, Nature Medicine 2022 28:3 28 (2022) 460\u2013467. URL: https://www.nature.com/articles/\ns41591-022-01713-6. doi: 10.1038/s41591-022-01713-6 .\n[3]J. Kiesel, M. Mestre, R. Shukla, E. Vincent, P. Adineh, D. Corney, B. Stein, M. Potthast, SemEval-2019\nTask 4: Hyperpartisan News Detection, in: Proceedings of the 13th International Workshop on\nSemantic Evaluation, Association for Computational Linguistics, Minneapolis, Minnesota, USA,\n2019, pp. 829\u2013839. URL: https://aclanthology.org/S19-2145. doi: 10.18653/v1/S19-2145 .\n[4]G. da San Martino, A. Barr\u00f3n-Cede\u00f1o, H. Wachsmuth, R. Petrov, P. Nakov, SemEval-2020 Task\n11: Detection of Propaganda Techniques in News Articles, in: Proceedings of the Fourteenth\nWorkshop on Semantic Evaluation (SemEval-2020), 2020, pp. 1377\u20131414. URL: http://propaganda.\nqcri.org/annotations/definitions.htmlhttp://arxiv.org/abs/2009.02696. arXiv:2009.02696 .\n[5]F. Rangel, P. Rosso, Overview of the 7th Author Profiling Task at PAN 2019: Bots and Gender\nProfiling, in: L. Cappellato, N. Ferro, D. E. Losada, H. M\u00fcller (Eds.), CLEF 2019 Labs and Workshops,\nNotebook Papers. CEUR Workshop Proceedings, CEUR-WS.org, 2019.\n[6]J. Thorne, A. Vlachos, O. Cocarascu, C. Christodoulopoulos, A. Mittal, The FEVER2.0 Shared Task,\nin: Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER), 2018.\n[7]M. Singhal, C. Ling, P. Paudel, P. Thota, N. Kumarswamy, G. Stringhini, S. Nilizadeh, SoK: Content\nModeration in Social Media, from Guidelines to Enforcement, and Research to Practice, in:\nThe 8th IEEE European Symposium on Security and Privacy (EuroS&P 2023), IEEE, 2022. URL:\nhttps://arxiv.org/abs/2206.14855v2. doi: 10.48550/arxiv.2206.14855 .arXiv:2206.14855 .\n[8]C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus, Intriguing\nproperties of neural networks, arXiv: 1312.6199 (2013). URL: https://arxiv.org/abs/1312.6199v4.\ndoi:10.48550/arxiv.1312.6199 .arXiv:1312.6199 .\n[9]W. E. Zhang, Q. Z. Sheng, A. Alhazmi, C. Li, Adversarial Attacks on Deep-learning Models in\nNatural Language Processing, ACM Transactions on Intelligent Systems and Technology (TIST)\n11 (2020). URL: https://dl.acm.org/doi/10.1145/3374217. doi: 10.1145/3374217 .\n[10] A. Barr\u00f3n-Cede\u00f1o, F. Alam, T. Chakraborty, T. Elsayed, P. Nakov, P. Przyby\u0142a, J. M. Stru\u00df, F. Haouari,\nM. Hasanain, F. Ruggeri, X. Song, R. Suwaileh, The clef-2024 checkthat! lab: Check-worthiness,\nsubjectivity, persuasion, roles, authorities, and adversarial robustness, in: N. Goharian, N. Tonel-\nlotto, Y. He, A. Lipani, G. McDonald, C. Macdonald, I. Ounis (Eds.), Advances in Information\nRetrieval, Springer Nature Switzerland, Cham, 2024, pp. 449\u2013458.\n[11] A. Barr\u00f3n-Cede\u00f1o, F. Alam, J. M. Stru\u00df, P. Nakov, T. Chakraborty, T. Elsayed, P. Przyby\u0142a, T. Caselli,\nG. Da San Martino, F. Haouari, C. Li, J. Piskorski, F. Ruggeri, X. Song, R. Suwaileh, Overview of\nthe CLEF-2024 CheckThat! Lab: Check-worthiness, subjectivity, persuasion, roles, authorities\nand adversarial robustness, in: L. Goeuriot, P. Mulhem, G. Qu\u00e9not, D. Schwab, L. Soulier, G. M.\nDi Nunzio, P. Galu\u0161\u010d\u00e1kov\u00e1, A. Garc\u00eda Seco de Herrera, G. Faggioli, N. Ferro (Eds.), Experimental IR\nMeets Multilinguality, Multimodality, and Interaction. Proceedings of the Fifteenth International\nConference of the CLEF Association (CLEF 2024), 2024.\n[12] P. Przyby\u0142a, A. Shvets, H. Saggion, Verifying the Robustness of Automatic Credibility As-\nsessment, arXiv preprint arXiv:2303.08032 (2023). URL: https://arxiv.org/abs/2303.08032v1.\narXiv:2303.08032 .\n[13] G. Zeng, F. Qi, Q. Zhou, T. Zhang, Z. Ma, B. Hou, Y. Zang, Z. Liu, M. Sun, OpenAttack: An\nOpen-source Textual Adversarial Attack Toolkit, in: ACL-IJCNLP 2021 - 59th Annual Meeting\nof the Association for Computational Linguistics and the 11th International Joint Conference\non Natural Language Processing, Proceedings of the System Demonstrations, Association for\nComputational Linguistics (ACL), 2021, pp. 363\u2013371. URL: https://aclanthology.org/2021.acl-demo.\n43. doi: 10.18653/V1/2021.ACL-DEMO.43 .arXiv:2009.09191 .\n[14] B. D. Horne, S. Adali, This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content\nin Text Body, More Similar to Satire than Real News, in: Proceedings of the 2nd International\nWorkshop on News and Public Opinion at ICWSM, Association for the Advancement of Artificial\nIntelligence, 2017. URL: http://arxiv.org/abs/1703.09398. arXiv:1703.09398 .\n[15] P. Przyby\u0142a, Capturing the Style of Fake News, in: Proceedings of the Thirty-Fourth AAAI\nConference on Artificial Intelligence (AAAI-20), volume 34, AAAI Press, New York, USA, 2020,\npp. 490\u2013497. URL: https://aaai.org/ojs/index.php/AAAI/article/view/5386. doi: 10.1609/aaai.\nv34i01.5386 .\n[16] T. J. Smith, Propaganda: A Pluralistic Perspective, Praeger, 1989.\n[17] L. Graves, Understanding the Promise and Limits of Automated Fact-Checking, Technical Report,\nReuters Institute, University of Oxford, 2018. URL: https://reutersinstitute.politics.ox.ac.uk/sites/\ndefault/files/2018-02/graves{_}factsheet{_}180226FINAL.pdf. arXiv:arXiv:1011.1669v3 .\n[18] J. Thorne, A. Vlachos, O. Cocarascu, C. Christodoulopoulos, A. Mittal, The Fact Extraction and\nVERification (FEVER) Shared Task, in: Proceedings of the First Workshop on Fact Extraction and\nVERification (FEVER), 2018. arXiv:1811.10971v1 .\n[19] M. Al-Sarem, W. Boulila, M. Al-Harby, J. Qadir, A. Alsaeedi, Deep learning-based rumor detection\non microblogging platforms: A systematic review, IEEE Access 7 (2019) 152788\u2013152812. doi: 10.\n1109/ACCESS.2019.2947855 .\n[20] S. Han, J. Gao, F. Ciravegna, Neural language model based training data augmentation for weakly\nsupervised early rumor detection, in: Proceedings of the 2019 IEEE/ACM International Conference\non Advances in Social Networks Analysis and Mining, ASONAM 2019, Association for Computing\nMachinery, Inc, 2019, pp. 105\u2013112. URL: https://dl.acm.org/doi/10.1145/3341161.3342892. doi: 10.\n1145/3341161.3342892 .arXiv:1907.07033 .\n[21] Y. Jiang, X. Song, C. Scarton, I. Singh, A. Aker, K. Bontcheva, Categorising fine-to-coarse grained\nmisinformation: An empirical study of the covid-19 infodemic, in: Proceedings of the 14th\nInternational Conference on Recent Advances in Natural Language Processing, 2023, pp. 556\u2013567.\n[22] Y. Mu, Y. Jiang, F. Heppell, I. Singh, C. Scarton, K. Bontcheva, X. Song, A large-scale comparative\nstudy of accurate covid-19 information versus misinformation, arXiv preprint arXiv:2304.04811\n(2023).\n[23] S. Hochreiter, J. Schmidhuber, Long Short-Term Memory, Neural Computation 9 (1997) 1735\u20131780.\ndoi:10.1162/neco.1997.9.8.1735 .\n[24] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training of Deep Bidirectional Transform-\ners for Language Understanding, in: Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, Asso-\nciation for Computational Linguistics, 2018, pp. 4171\u20134186. URL: http://arxiv.org/abs/1810.04805.\narXiv:1810.04805 .\n[25] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Fun-\ntowicz, J. Davison, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. L. Scao, S. Gugger,\nM. Drame, Q. Lhoest, A. M. Rush, Transformers: State-of-the-Art Natural Language Processing,\nin: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:\nSystem Demonstrations, Association for Computational Linguistics, Online, 2020, pp. 38\u201345. URL:\nhttps://www.aclweb.org/anthology/2020.emnlp-demos.6.\n[26] I. Loshchilov, F. Hutter, Decoupled Weight Decay Regularization, in: 7th International Conference\non Learning Representations, ICLR 2019, New Orleans, LA, USA, 2019. URL: https://openreview.\nnet/forum?id=Bkg6RiCqY7. arXiv:1711.05101v3 .\n[27] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, V. Stoyanov,\nP. G. Allen, RoBERTa: A Robustly Optimized BERT Pretraining Approach (2019). URL: https:\n//arxiv.org/abs/1907.11692v1. doi: 10.48550/arxiv.1907.11692 .arXiv:1907.11692 .\n[28] L. Li, R. Ma, Q. Guo, X. Xue, X. Qiu, BERT-ATTACK: Adversarial Attack Against BERT Using\nBERT, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP), Association for Computational Linguistics, 2020, pp. 6193\u20136202. URL: https:\n//aclanthology.org/2020.emnlp-main.500. doi: 10.18653/v1/2020.emnlp-main.500 .\n[29] T. Sellam, D. Das, A. Parikh, BLEURT: Learning Robust Metrics for Text Generation, in: Proceed-\nings of the 58th Annual Meeting of the Association for Computational Linguistics, Association\nfor Computational Linguistics, Online, 2020, pp. 7881\u20137892. URL: https://aclanthology.org/2020.\nacl-main.704. doi: 10.18653/v1/2020.acl-main.704 .\n[30] V. I. Levenshtein, Binary codes capable of correcting deletions, insertions, and reversals, Soviet\nPhysics Doklady 10 (1966) 707\u2013710.\n[31] Y. Mu, M. Jin, C. Grimshaw, C. Scarton, K. Bontcheva, X. Song, Vaxxhesitancy: A dataset for\nstudying hesitancy towards covid-19 vaccination on twitter, in: Proceedings of the International\nAAAI Conference on Web and Social Media, volume 17, 2023, pp. 1052\u20131062.\n[32] D. Wilby, T. Karmakharm, I. Roberts, X. Song, K. Bontcheva, GATE Teamware 2: An open-\nsource tool for collaborative document classification annotation, in: D. Croce, L. Soldaini\n(Eds.), Proceedings of the 17th Conference of the European Chapter of the Association for\nComputational Linguistics: System Demonstrations, Association for Computational Linguis-\ntics, Dubrovnik, Croatia, 2023, pp. 145\u2013151. URL: https://aclanthology.org/2023.eacl-demo.17.\ndoi:10.18653/v1/2023.eacl-demo.17 .\n[33] J. Valle Aguilera, A. J. Guti\u00e9rrez Meg\u00edas, S. M. Jim\u00e9nez Zafra, L. A. Ure\u00f1a L\u00f3pez, E. Mart\u00ednez C\u00e1mara,\nSINAI at CheckThat! 2024: Stealthy character-level adversarial attacks using homoglyphs and\nsearch, iterative, in: [45], 2024.\n[34] C. Roadhouse, M. Shardlow, A. Williams, MMU NLP at CheckThat! 2024: Homoglyphs are\nadversarial attacks, in: [45], 2024.\n[35] H. He, Y. Song, D. Massey, Pal\u00f6ri at CheckThat! 2024 shared task 6: Glota - combining glove\nembeddings with roberta for adversarial attack, in: [45], 2024.\n[36] W. Lewoniewski, P. Stolarski, M. Str\u00f3\u017cyna, E. Lewa\u0144ska, A. Wojewoda, E. Ksi\u0119\u017cniak, M. Sawi\u0144ski,\nOpenFact at CheckThat! 2024: Combining multiple attack methods for effective adversarial text\ngeneration, in: [45], 2024.\n[37] M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, K.-W. Chang, Generating Natural\nLanguage Adversarial Examples, in: Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing, Association for Computational Linguistics, Brussels, Belgium, 2018,\npp. 2890\u20132896. URL: https://aclanthology.org/D18-1316. doi: 10.18653/v1/D18-1316 .\n[38] N. Mrk\u0161i\u0107, D. \u00d3. S\u00e9aghdha, B. Thomson, M. Gasic, L. M. R. Barahona, P.-H. Su, D. Vandyke, T.-H.\nWen, S. Young, Counter-fitting word vectors to linguistic constraints, in: Proceedings of the 2016\nConference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, 2016, pp. 142\u2013148.\n[39] D. Jin, Z. Jin, J. T. Zhou, P. Szolovits, Is BERT Really Robust? A Strong Baseline for Natural\nLanguage Attack on Text Classification and Entailment, in: The Thirty-Fourth AAAI Conference\non Artificial Intelligence, AAAI 2020\u201e AAAI Press, 2020, pp. 8018\u20138025. URL: https://ojs.aaai.org/\nindex.php/AAAI/article/view/6311.\n[40] J. Morris, E. Lifland, J. Y. Yoo, J. Grigsby, D. Jin, Y. Qi, TextAttack: A Framework for Adversarial\nAttacks, Data Augmentation, and Adversarial Training in NLP, in: Proceedings of the 2020\nConference on Empirical Methods in Natural Language Processing: System Demonstrations,\nAssociation for Computational Linguistics, Online, 2020, pp. 119\u2013126. URL: https://aclanthology.\norg/2020.emnlp-demos.16. doi: 10.18653/v1/2020.emnlp-demos.16 .\n[41] D. Li, Y. Zhang, H. Peng, L. Chen, C. Brockett, M.-T. Sun, W. B. Dolan, Contextualized perturbation\nfor textual adversarial attack, in: Proceedings of the 2021 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, 2021,\npp. 5053\u20135069.\n[42] B. Demirok, M. Kutlu, S. Mergen, B. Oz, TurQUaz at CheckThat! 2024: Creating adversarial\nexamples using genetic algorithm, in: [45], 2024.\n[43] D. Guzman Piedrahita, A. Fazla, L. Krauter, TextTrojaners at CheckThat! 2024: Robustness of\ncredibility assessment with adversarial examples through beamattack, in: [45], 2024.\n[44] M. T. Ribeiro, S. Singh, C. Guestrin, \" why should i trust you?\" explaining the predictions of any\nclassifier, in: Proceedings of the 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining, 2016, pp. 1135\u20131144.\n[45] G. Faggioli, N. Ferro, P. Galu\u0161\u010d\u00e1kov\u00e1, A. Garc\u00eda Seco de Herrera (Eds.), Working Notes of CLEF\n2024 - Conference and Labs of the Evaluation Forum, CLEF 2024, Grenoble, France, 2024.\nA. Annotation Guidelines\nInCrediblAE Shared Task Annotation All participants who submit entries will have their submis-\nsions manually evaluated for semantic similarity. To aid in this human evaluation process, participants\nin the shared tasks will be required to manually assess a selection of the submitted examples.\nManual Scoring We will gather assessments regarding the semantic similarities between attack\nsamples and the original samples. Participants in the shared task are requested to dedicate approximately\n60 mins to this manual evaluation (i.e., 100 samples per participant), which will be conducted using this\nonline annotation tool. Judges will rate the sample pairs based on the following scale: (a). Preserve the\nSemantic Meaning, (b). Change the Semantic Meaning, (c). No sense.\nLabels and Definitions (a). Preserve the Semantic Meaning: This label is used when the semantic\ncontent of the attack sample closely aligns with that of the original sample. Participants should use this\nlabel if the meaning, context, and intent of the compared texts remain essentially unchanged, indicating\nthat the attack sample has effectively maintained the core message of the original. For example:\nText Original: middle-earth. middle-earth is the fictional setting of much of british writer\nj. r. r. tolkien \u2019s legendarium . middle-earth is a setting.\nText Modified: middle-earth. middle-earth is the fictional background of much of british\nwriter j. r. r. tolkien \u2019s legendarium . middle-earth is a setting.\n(b). Change the Semantic Meaning: Participants should apply this label when there is a noticeable\nalteration in the semantic content between the original and the attack sample. This label indicates that\nwhile the attack sample may be related or similar in some aspects to the original, it diverges enough in\nmeaning or intent to be considered distinct or modified. For example, name entities (including Year,\nName, Location, etc.) are changed in the modified text. For example:\nText Original: carol danvers. the character has also been known as binary , warbird , and\ncaptain marvel at various points in her history , and has been featured in other marvel\nlicensed products including video games , animated television series , and merchandise\nsuch as trading cards . carol danvers is a real person.\nText Modified: carol danvers. the character has also been known as binary , warbird , and\ncaptain marvel at various points in her history , and has been featured in other marvel\nlicensed products including video games , animated television series , and merchandise\nsuch as trading cards . carol danvers is a fictional person.\n(c). No sense: The sentence does not make any sense.\nConfidence Scores Please indicate how confident you are in your assigned class in the Confidence\nRow. The confidence scores range from 1 to 5.\nA.1. Information Sheet for InCrediblAE Participants\nYou are invited to participate in this research by contributing to the evaluation of the semantic similarity\nof adversarial examples. It is important for you to understand the goals of the task and what your\nparticipation will involve. Please take the time to read the following information. Please, ask us if there\nis anything that is not clear or if you would like more information. Thank you very much for your time.\nWhat is the task\u2019s purpose? The aim of this research is to evaluate the robustness of the text\nclassifier in adversarial attacks (a detailed description of the task can be found here: https://checkthat.\ngitlab.io/clef2024/task6/). In this manual evaluation, we will gather assessments regarding the semantic\nsimilarities between attack samples and the original samples. Participants in the shared task are\nrequested to dedicate approximately 8 hours to this manual evaluation, which will be conducted using\nan online tool. Judges will rate the sample pairs based on the following scale: 3 (Preserve the Semantic\nMeaning), 2 (Change the Semantic Meaning), and 1 (No sense).\nYour participation, what it involves and why we are grateful It is up to you to decide whether\nor not you want to participate in this annotation task. If you do decide to support us in the project, you\nwill be given this information sheet to keep (and be asked to sign a separate consent form). You can\nstill withdraw at any time without any consequences and without giving any reason. The entire data\ncollected from withdrawn participants will be destroyed immediately, and no personal information\nwill be kept. If participants submitted a solution to the shared task that also means their submission to\nthe shared tasks will not be manually scored. If you wish to withdraw, please contact Dr Xingyi Song\n(details in section 10). You will be asked to annotate adversarial examples into 4 categories using the\nGATE Teamware Platform (https://annotate.gate.ac.uk/).\nWhat are the possible advantages, disadvantages and risks of being involved? Participating\nin this evaluation will support our research on the development of a more accurate assessment of the\nrobustness of text classifiers and effectiveness of the adversarial attack methods. No major disadvantages\nor risks are foreseen, however, it is worth mentioning that the content being annotated may case distress.\nYou will be in charge of selecting the content to be annotated, therefore, you are free to only select\ncontent that you are comfortable with. If, at any part of the experiment you feel uncomfortable with\nthe content you are accessing, please talk to one of the responsible researchers.\nWill my involvement be kept confidential? All the information that we collect from you and\nabout you during the course of the research will be kept strictly confidential and will only be accessible\nto members of the research team. You will not be able to be identified in any reports or publications\nunless you have given your explicit consent for this on your participant consent form.\nWhat is the legal basis for processing my personal data? According to data protection legislation,\nwe are required to inform you that the legal basis we are applying in order to process your personal\ndata is that \u2018processing is necessary for the performance of a task carried out in the public interest\u2019\n(Article 6(1)(e)). Further information can be found in the University of Sheffield\u2019s Privacy Notice, which\nis available online under https://www.sheffield.ac.uk/govern/data-protection/privacy/general.\nWhat will happen to the data collected in this study? The data gathered during this scoring\ntask will be used to assess the effectiveness of adversarial examples generation. Since this data will\nalso benefit other researchers, we plan to release a version of the annotated dataset. You will not be\nidentified and your scoring will be aggregated with multiple other annotators. In the case that you\nprovided us with your e-mail address at the beginning of the scoring task, we will destroy it after the\nscoring task is finished. The University of Sheffield will act as the Data Controller for this study.\nWho is organising and funding the research? This study is organised jointly by Universitat\nPompeu Fabra and the University of Sheffield at the CheckThat! Lab at CLEF 2024. Universitat Pompeu\nFabra is funded by the European Union\u2019s Horizon Europe research and innovation programme under\ngrant agreement No 101060930. The University of Sheffield is funded by the the UK\u2019s innovation agency\n(Innovate UK) grant 10039055 (approved under the Horizon Europe Programme as vera.ai EU grant\nagreement 101070093).\nWho has ethically reviewed this study? This project has been ethically approved via the University\nof Sheffield\u2019s Ethics Review Procedure, as administered by the Computer Science Department.\nWhat if something goes wrong and I wish to complain about the research? If you have any\ncomplaints, either from the researcher or something occurring during or following your participation\nin the project (e.g. a reportable serious adverse event), please contact Dr. Xingyi Song (contact\ndetails in section 10). Should you feel your complaint has not been handled to your satisfaction, you\ncan also contact the Head of Department at the University of Sheffield, Professor Heidi Christensen\n(heidi.christensen@sheffield.ac.uk) who will then escalate the complaint through the appropriate\nchannels. If the complaint relates to how your personal data has been handled, information about\nhow to raise a complaint can be found in the University\u2019s Privacy Notice: https://www.sheffield.ac.uk/\ngovern/data-protection/privacy/general.\nContact for further information Details of who you should contact if you wish to obtain further\ninformation are as follows: Dr. Xingyi Song, Department of Computer Science, University of Sheffield,\n211 Portobello, Sheffield S1 4DP, UK. E-mail: x.song@sheffield.ac.uk Telephone: +44 114 222 18577.\nB. COVID-19 Misinformation Dataset Examples\nTable 9\nPositive and negative examples from the COVID-19 misinformation dataset (C19).\nLabel False Claim User Text\n1 (Misinforma-\ntion related to\nfalse claim)N95 masks block few,\nif any COVID-19 parti-\ncles due to their sizeCOVID-19 the average diameter of the virus particles is\naround 120 nm ( .12\ud835\udf07m). Any mask including N95 masks\ncan\u2019t filter this particle size, to filter it completely would\nprevent the subject being able to breath. Therefore, the\nmask are just the new normal, a fashion statement.\n0 (Other)N95 masks block few,\nif any COVID-19 parti-\ncles due to their sizeA #COVID19 particle is about 1 to 4 microns, an N95\nwill block 95% of tiny air particles, down to 0.3 microns,\nand surgical masks aren\u2019t effective at blocking particles\nsmaller than 100 microns. Hence surgical masks cannot\nstop the spread of #COVID19.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Overview of the clef-2024 checkthat! lab task 6 on robustness of credibility assessment with adversarial examples (incrediblae)", "author": ["P Przyby\u0142a", "B Wu", "A Shvets", "Y Mu", "KC Sheang"], "pub_year": "2024", "venue": "Working Notes of \u2026", "abstract": "Task 6 at CheckThat! Lab, organised at CLEF-2024, is devoted to assessing the robustness  of misinformation detection solutions implemented as text classification models. The"}, "filled": false, "gsrank": 170, "pub_url": "https://ceur-ws.org/Vol-3740/paper-28.pdf", "author_id": ["OpiwQjQAAAAJ", "R7PZv1kAAAAJ", "BWiWj-sAAAAJ", "WuS2yawAAAAJ", "5-samv4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:MPaDgeop2qQJ:scholar.google.com/&output=cite&scirp=169&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D160%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=MPaDgeop2qQJ&ei=IbWsaPvmC7_SieoPzJnloAQ&json=", "num_citations": 7, "citedby_url": "/scholar?cites=11878853054315099696&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:MPaDgeop2qQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ceur-ws.org/Vol-3740/paper-28.pdf"}}, {"title": "Detecting and responding to hostile disinformation activities on social media using machine learning and deep neural networks", "year": "2022", "pdf_data": "S.I. : LSNC & OUAI\nDetecting and responding to hostile disinformation activities on social\nmedia using machine learning and deep neural networks\nBarry Cartwright1\u2022Richard Frank1\u2022George Weir2\u2022Karmvir Padda1\nReceived: 13 August 2021 / Accepted: 13 April 2022 / Published online: 9 June 2022\n/C211The Author(s) 2022\nAbstract\nDisinformation attacks that make use of social media platforms, e.g., the attacks orchestrated by the Russian \u2018\u2018InternetResearch Agency\u2019\u2019 during the 2016 U.S. Presidential election campaign and the 2016 Brexit referendum in the UK, have\nled to increasing demands from governmental agencies for AI tools that are capable of identifying such attacks in their\nearliest stages, rather than responding to them in retrospect. This research undertaken on behalf of the Canadian ArmedForces and Department of National Defence. Our ultimate objective is the development of an integrated set of machine-\nlearning algorithms which will mobilize arti\ufb01cial intelligence to identify hostile disinformation activities in \u2018\u2018near-real-\ntime.\u2019\u2019 Employing The Dark Crawler, the Posit Toolkit, TensorFlow (Deep Neural Networks), plus the Random Forestclassi\ufb01er and short-text classi\ufb01cation programs known as LibShortText and LibLinear, we have analysed a wide sample of\nsocial media posts that exemplify the \u2018\u2018fake news\u2019\u2019 that was disseminated by Russia\u2019s Internet Research Agency, com-\nparing them to \u2018\u2018real news\u2019\u2019 posts in order to develop an automated means of classi\ufb01cation.\nKeywords Hostile disinformation /C1Machine learning /C1Deep neural network /C1Internet research agency\n1 Introduction\nOne of the key challenges facing governments, intelligence\nagencies, law enforcement agencies, cybersecurity per-\nsonnel and business owners-operators worldwide is how to\nmonitor and effectively respond to dynamic and emerging\ncybersecurity threats, with increasing attention being paidto disinformation activities orchestrated by hostile foreign\nactors on social media platforms [ 1]. To illustrate, an\napplication developed by Cambridge Analytica managed toscrape data from over 80 million Facebook pages world-\nwide. This information was then used to micro-targetvoters through Facebook advertisements that were pre-\nmised upon the demographic pro\ufb01les and known political\nleanings of those voters, based upon information which had\nbeen extracted using the Cambridge Analytica application\n[2,3]. In July 2018, Facebook was \ufb01ned \u00a3500,000\u2014the\nmaximum amount allowable under British law\u2014for its\nmishandling of data in the Cambridge Analytica scandal\n[4]. In July 2019, the US Federal Trade Commission \ufb01ned\nFacebook \ufb01ve billion USD for its failure to protect user\nprivacy [ 5]. The nexus between Cambridge Analytica,\nWikiLeaks, and Russian interference in the 2016 U.S.Presidential election remained under investigation by the\nU.S. Congress as recently as the Summer of 2020 [ 6].\nAccording to the 2017 Intelligence Community\nAssessment prepared by the Central Intelligence Agency\n(CIA), the Federal Bureau of Investigation (FBI) and the\nNational Security Agency (NSA), a number of other socialmedia platforms including Instagram and Twitter were also\nimplicated as (possibly unaware) participants in the hosting\nand dissemination of disinformation attacks associatedwith the Russian \u2018\u2018Internet Research Agency\u2019\u2019 (IRA) [ 7].&George Weir\ngeorge.weir@strath.ac.uk\nBarry Cartwright\nbarry_cartwright@sfu.ca\nRichard Frank\nrfrank@sfu.ca\nKarmvir Padda\nkarmvir_padda@sfu.ca\n1School of Criminology, Simon Fraser University, Burnaby,Canada\n2Computer and Information Sciences, University ofStrathclyde, Glasgow, UK\n123Neural Computing and Applications (2022) 34:15141\u201315163\nhttps://doi.org/10.1007/s00521-022-07296-0 (0123456789().,-volV) (0123456789(). ,- volV)\nSpecial Counsel Robert Mueller\u2019s report into Russian\ninterference in the U.S. Presidential election [ 8] set out\nhow purposively designed Facebook and Twitter accounts\ntargeted certain groups, such as Southern Whites (throughthe Patriototus Facebook page), the right-wing anti-immi-\ngration movement (through the Secured Borders Facebook\npage) and Blacks (through the Blacktivist Facebook page),as well as through Twitter feeds such as the anti-immi-\ngration account @America_1st and @TEN_GOP (which\nfalsely claimed to have a connection to the Republican\nParty of Tennessee). In the UK, Russian-orchestrated dis-\ninformation campaigns\u2014which primarily stoked Islama-phobic and anti-immigration passions\u2014made extensive use\nof Twitter employing handles such as #voteleave and\nReasonsToLeaveEU [ 9\u201312]. Evidence also indicates that\nthe Russian IRA maximized use of social media bots in\ntheir 2016 assaults on the U.S. Presidential election and the\nU.K. Brexit referendum [ 9,10,13,14], thereby amplifying\nthe disinformation content in order to reach and in\ufb02uence a\nmuch wider audience. Recent research demonstrates\nclearly that the Russian IRA also attempted to interfere inthe 2020 U.S. Presidential election [ 15\u201317]. More will be\nsaid about Russian involvement in disinformation warfare\nin Sect. 2of this paper, wherein we present our literature\nreview.\nOur research is being conducted by the International\nCyberCrime Research Centre (ICCRC) at Simon FraserUniversity in Canada, in cooperation with the Department\nof Information and Computer Sciences at the University of\nStrathclyde in Scotland. Essentially, this ongoing projectundertaken on behalf of the Canadian Armed Forces (CAF)\nand the Department of National Defence (DND) contem-\nplates the development of an arti\ufb01cial intelligence (AI) toolfor identifying hostile disinformation activities on social\nmedia platforms on-the-\ufb02y, or if not, then at least in near-\nreal-time. It is anticipated that the knowledge generated byour research will aid the CAF and the DND in the rapid and\naccurate pinpointing of disinformation attacks in their very\nearly stages, and allow them to take action whereappropriate.\nFor the present study we employed automation (AI)\ntools that include The Dark Crawler (TDC), TensorFlow(Deep Neural Networks), Random Forest, LibShortText,\nLibLinear and Posit. Additional information on these\nresearch tools is provided in Sect. 3, wherein we set out our\nmethodology. This present paper will focus on the classi-\n\ufb01cation accuracies attained by TensorFlow, Random For-\nest, LibShortText, LibLinear and the Posit toolkit when itcomes to their ability to discern between real information\nand dis/misinformation, sometimes referred to as \u2018\u2018real\nnews\u2019\u2019 and \u2018\u2018fake news.\u2019\u2019 Our research results are reportedin Sect. 4, and elucidated further in Sects. 5and6, wherein\nwe discuss our results, set out the directions that our futureresearch endeavours are expected to take, and present our\ninterim conclusions.\n2 Literature review\nAs noted in Sect. 1, social media platforms have come\nunder increasing scrutiny for permitting hostile foreign\nactors to manipulate public opinion through fake social\nmedia accounts that disseminate false information or \u2018\u2018fakenews\u2019\u2019 [ 18\u201320]. This false information or fake news can be\nbroken down into two broader categories: misinformation\nand disinformation. The less sinister of the two, misinfor-\nmation, is simply inaccurate or false information. While\nsometimes used by hostile foreign actors, misinformationmay also be based upon a genuine misapprehension of the\nfacts, as opposed to having been created with any particular\nintention of deceiving or manipulating people [ 21\u201323].\nDisinformation, on the other hand, especially when\nemployed by hostile foreign actors, is created and spread\nintentionally for the purpose of deception and manipulationof public opinion [ 21,23,24].\nAn example of misinformation might be the oft-repeated\nclaims by anti-vaccination groups that vaccinations containtoxins, that they erode immunity, or that they have been\nproven to be associated with autism or sudden infant death\nsyndrome [ 25], often buttressed by making reference to a\nstudy by Andrew Wake\ufb01eld, which was published in (and\nthen subsequently withdrawn by) the medical journal, The\nLancet . Wake\ufb01eld\u2019s \ufb01ndings were premised upon a sample\nof only 12 children and relied exclusively upon the beliefs\nand recollections of their parents, without any sort of\ncontrol group in place [ 26]. Although the article was\nwithdrawn by The Lancet , the study has continued to\nprovide fuel for the anti-vaccination movement, which\nitself is housed largely on the Internet [ 26]. Fake news may\nbe promulgated for a variety of reasons, such as pro\ufb01t, the\nfavouring of a particular partisan ideology, or supporting\nunfounded beliefs or conspiracy theories [ 1,18,27].\nThe activities of Russia\u2019s IRA during the 2016 U.S.\nPresidential election are a prime example of a disinfor-\nmation campaign mounted by a hostile foreign actor[10,13,28,29]. In February 2018, U.S. Special Counsel\nRobert Mueller obtained a grand jury indictment against\nthe IRA (which was bankrolled by Yevgeniy Prigozhin,often referred to as \u2018\u2018Putin\u2019s chef\u2019\u2019), plus Prigozhin\u2019s\nAmerican-based companies Concord Management and\nConsulting LLC and Concord Catering as well as Prigozhinhimself, along with a dozen Russian \u2018\u2018trolls\u2019\u2019 who were\nemployed by Prigozhin\u2019s IRA. The indictment stated that\nthe accused had \u2018\u2018operated social media pages and groupsdesigned to attract U.S. audiences\u2019\u2019 in order to advance\ndivisive issues and create discord, falsely claiming that15142 Neural Computing and Applications (2022) 34:15141\u201315163\n123\nthose pages and groups were controlled by American\nactivists [ 9,30].\nThe dozen Internet \u2018\u2018trolls\u2019\u2019 described in Mueller\u2019s\nindictment belonged to a larger workforce comprised ofapproximately 1000 Russian trolls employed by Pri-\ngozhin\u2019s IRA [ 31\u201333]. Working in a building in St.\nPetersburg, these IRA employees toiled around the clock intwo, 12-h shifts (a day shift and a night shift), with the\nobjective of fomenting discord, dissent, distrust and hos-\ntility within and between targeted groups in the American\npopulace [ 34\u201336]. In particular, these IRA trolls were\ninstructed to spread disinformation that would buttressDonald Trump\u2019s campaign for the U.S. Presidency, while\nundermining the campaign of Hillary Clinton\n[7,32,36,37].\nThe Computational Propaganda Project housed primar-\nily in the Oxford Internet Institute, reported that 19 million\nidenti\ufb01able \u2018\u2018bot\u2019\u2019 accounts tweeted in support of Trump orClinton in the week leading up to the 2016 Presidential\nelection, with 55.1% of those in favour of Trump and only\n19.1% in favour of Clinton [ 38\u201340]. This apparent disparity\nin Twitter support is dif\ufb01cult to account for except in terms\nof highly orchestrated and deliberate political interference,\ngiven that Hillary Clinton received 65,844,954 votescompared to Donald Trump\u2019s 62,979,879 votes [ 41].\nAccording to a study by Zannettou et al., 71% of these\n\u2018\u2018fake\u2019\u2019 accounts were created prior to the 2016 election[36]. The 2017 Intelligence Community Assessment pre-\npared by the CIA, FBI and NSA indicated that Russian\noperatives began researching the US electoral processesand election-related technology as early as 2014 and that\nthe Prigozhin-led IRA had started advocating on behalf of\nDonald Trump\u2019s candidacy as early as 2015, one year priorto the election [ 7]. Zannettou et al. reported that 24\naccounts were created a week before the Republican\nNational Conference (at which Donald Trump was for-mally nominated as the Republican candidate for the 2016\nPresidential election) [ 36]. The study also found that the\nRussian Internet trolls attempted to mask their disinfor-mation campaign by adopting different identities, changing\ntheir screen names and pro\ufb01le information, and in some\ncases, deleting their previous tweets.\nMuch has been said about the use of social media bots\nduring the 2016 U.S. presidential election and the 2016\nU.K. Brexit referendum [ 10,13,14]. Brie\ufb02y, the transfer\nand transformation of information on the Internet is not\naccomplished by people, but rather, by algorithms, which\nare scripts that convert mathematical expressions intoinstructions for the Internet [ 39]. The Cambridge Analytica\napplication, which attracted so much negative attention to\nFacebook in the aftermath of the 2016 U.S. Presidentialelection and the 2016 U.K. Brexit referendum, would be an\nexample of an algorithm that was designed for the expresspurpose of collecting and evaluating behavioural data such\nas the likes, dislikes and political proclivities of the Face-\nbook users whose data it collected [ 42].\nIt is estimated that these social media bots comprise\nbetween 5 and 9% of the overall Twitter population and\naccount for approximately 24% of all tweets [ 43]. Stories\nthat \u2018\u2018go viral\u2019\u2019\u2014i.e. that rise to the top of Twitter feeds\u2014are often pushed there by these social media bots through\nmanipulation of the social media platform\u2019s algorithms\n[43].\nMany consumers of \u2018\u2018fake news\u2019\u2019 or dis/misinformation\ntend to accept what they read at face value. The PewResearch Center reports that 36% of Americans get their\nnews from Facebook [ 44], and of those who use Twitter\nregularly, over half depend on Twitter as their source of\nnews [ 44,45]. It can be said that the frequent tweeting and\nre-tweeting of dis/misinformation by bots leads to ever-\nincreasing exposure, resulting in an \u2018\u2018echo chamber effect\u2019\u2019[46]. Evidence also suggests that many individuals are\nunable to distinguish between factual and non-factual\ncontent found on Twitter and Facebook [ 24]. Indeed,\naccording to a Stanford University study, far too many are\ninclined to accept images or statements that they come\nacross on social media at face value, without questioningthe source of those images or statements.\nRussian interference is by no means restricted to the US\nand the UK. To illustrate, in 2019, the European Com-mission released a progress report on its Action Plan\nAgainst Disinformation. According to the Commission,\nevidence gathered throughout 2018 and early 2019 con-\ufb01rmed ongoing disinformation activities originating from\nRussian sources, believed to be undertaken for the purpose\nof in\ufb02uencing voter preferences and suppressing voterturnout in the EU Parliamentary elections [ 22,47]. A\nrecent study of Canadian Twitter data suggests that Russian\ntrolls were behind \u2018\u2018fake news\u2019\u2019 stories that attempted tostoke fear and distrust between Muslims and non-Muslims\nfollowing the 2017 shooting deaths of six worshippers at a\nmosque in Quebec City, leading to renewed concerns thatRussian trolls might attempt to interfere in the Fall 2019\nCanadian federal election [ 48,49]. Indeed, Russian disin-\nformation activities on social media have continued apacein a concerted effort to promote anti-NATO sentiments and\npush pro-Russian narratives around the globe [ 49].\nThis is not to suggest that all known disinformation\ncampaigns have been launched by Russia. A 2019 inven-\ntory compiled by the Oxford Internet Institute found evi-\ndence of disinformation campaigns in 70 differentcountries around the world, for example, Armenia, India,\nMalaysia, Mexico, The Philippines, Saudi Arabia, The\nUnited Arab Emirates and Venezuela [ 50]. Countries such\nas China and Saudi Arabia are believed to be making\nincreasing use of disinformation campaigns beyond theirNeural Computing and Applications (2022) 34:15141\u201315163 15143\n123\nown borders [ 51]. That said, Russian disinformation\nactivities have been documented in the Czech Republic and\nSlovakia as far back as 2013 [ 52], and in the 2014 election\nin the Ukraine, which itself followed shortly after Russia\u2019sannexation of the Crimean Peninsula [ 53,54].\nObservers have warned that Beijing is now seeking\nnarrative control on a worldwide scale, believing that itmust prevent any critical external opinions of its policies or\npractices from entering domestic discourse out of fear that\nthey may damage the image of the CCP [ 54]. Recently, the\nChinese government\u2019s approach has become more\naggressive, as they attempt to exploit the openness ofWestern societies by eroding trust in their democratic\ninstitutions and processes via execution of state-sponsored\ndisinformation [ 54]. Chinese disinformation has struck\nagainst states within their immediate vicinity, e.g. Taiwan\nand Hong Kong, as well as against nations such as Aus-\ntralia, Canada and the US [ 55,56].\nIran has employed foreign interference against Canada\nvia disinformation on social media, particularly Twitter\n[48,56]. The 2015 Canadian federal election was targeted\nby Iran, although in contrast to Russian activities, Iranian\ndisinformation was primarily anti-Harper (the former\nPrime Minster of Canada) [ 47]. More recently, Iran has\nengaged in interference on Twitter, posting about Canadian\npipelines [ 56].\nThe Chinese and Iranians have learned from and adop-\nted Russian strategies and techniques, making it dif\ufb01cult to\ndistinguish between these foreign state actors [ 57]. A\ncomplicating factor is the adoption of Russian strategiesand techniques by far-right domestic groups. Nonetheless,\nsome differences appear, especially in terms of the lack of\nsophistication of Chinese disinformation when micro-tar-geting particular subgroups and Iran\u2019s generally more\n\u2018\u2018left-leaning\u2019\u2019 choice of content [ 58].\nVarious researchers have mobilized arti\ufb01cial intelli-\ngence to counter the type of disinformation warfare\nemployed by Russia during the 2016 U.S. Presidential\nelection and the 2016 U.K. Brexit referendum. In 2017,Darren Linvill and John Walker (from Clemson University)\ngathered and saved vast numbers of Twitter postings (prior\nto their removal from the Internet by the platform, therebypreserving the evidence and making the data available to\nthe academic, cyber-security and law enforcement com-\nmunities for study [ 51]. Our research team has made\nextensive use of the IRA\u2019s Twitter postings that were\ngathered, saved and made available by Linvill and Walker.\nIn 2017, William Yang Wang released his LIAR dataset,\nwhich included 12,836 statements labelled for their subject\nmatter, situational context, and truthfulness, broken down\ninto training, validation, and test sets, along with instruc-tions for automatic fake news detection [ 59]. In addition,\nWilliam Wang reported that the open-source softwaretoolkit, LibShortText, developed by the Machine Learning\nGroup at National Taiwan University, had been shown to\nperform well when it came to short text classi\ufb01cation\n[60,61]. The dataset provided by Linvill and Walker and\nthe suggestion by William Wang about using LibShortText\nwere both used by us to inform and re\ufb01ne the machine\nlearning and automated analysis processes described in thefollowing sections on Methodology and Research Results.\nIn the above-mentioned study using the LIAR dataset,\nWilliam Wang found that when it came to automatic lan-\nguage detection, a hybrid convoluted Deep Neural Network\nthat integrated both meta-data and text produced superiorresults to text-only approaches [ 59]. We are employing a\nsomewhat similar approach to that of William Wang, in\nthat we are using a combination of Tensor Flow [ 61], the\nLibShortText program developed by the Machine Learning\nGroup at National Taiwan University [ 60\n], LibLinear, a\ncompanion open source software package to LibShortText,again developed by the same Machine Learning Group at\nNational Taiwan University that developed LibShortText\n[62], a text-reading program (the Posit toolkit) that also\nproduces meta-data or mark-up [ 63,64], plus the Random\nForest classi\ufb01er [ 64].\nEmploying techniques of machine learning and natural\nlanguage processing, a 2018 study of Twitter troll activity\nin the 2016 U.S. Presidential election found that a model\nblending measurements of \u2018\u2018precision\u2019\u2019 and \u2018\u2018recall\u2019\u2019 failedto accurately classify 34% of troll posts, suggesting that\nsuch models could not be relied upon to identify and screen\nout fake news [ 65]. However, a 2019 paper entitled\n\u2018\u2018Defending Against Neural Fake News\u2019\u2019 reports on the\ndevelopment of GROVER, a computer model that can both\ngenerate and detect neural fake news, premised on thenotion that while most fake news is presently generated by\nhumans, the fake news of the future may be generated by\nmachines. The authors of this paper report additionally thatthey have been able to discriminate fake news with an\naccuracy of 92%, as opposed to the more standard 73%\naccuracy exhibited by other fake news discriminators [ 66].\nOur research results, reported below, come closer at times\nto approximating those described in this 2019 study.\nRecently, there has been an increasing focus on the\ndetection of foreign-controlled \u2018\u2018bots\u2019\u2019 and \u2018\u2018sock puppet\u2019\u2019\naccounts as a means of identifying disinformation cam-\npaigns [ 67]. As noted previously, bots are social media\naccounts that are controlled by software rather than by real\npeople [ 39]. Use of bots can arti\ufb01cially cause a topic or\nhashtag to trend, reaching many more users than could bereached by sending messages manually [ 68]. Sock puppet\naccounts are operated by users who are pretending to be\nsomeone else. They seek to accumulate a history of activityand obtain a level of trust in order to create the impression\nthat they are legitimate sources of information. The15144 Neural Computing and Applications (2022) 34:15141\u201315163\n123\naccounts are usually disguised by employing different\nidentities (multiple users) that seemingly have no rela-\ntionship to each other, but they can be detected because the\nsupposedly \u2018\u2018different\u2019\u2019 accounts exhibit similar sentimentorientation and behaviours [ 69].\n3 Methodology\nOur analysis of \u2018\u2018fake news\u2019\u2019 messages posted by the\n(IRA), before, during and after the 2016 U.S. Presidential\nelection, employed a variety of approaches, including\ncollection of IRA posts and \u2018\u2018real news\u2019\u2019 datasets using\nTDC, plus machine analysis of large samples of the posts\nusing TensorFlow, Random Forest, LibShortText, LibLin-ear and the Posit toolkit. Although this research was geared\nprimarily toward machine learning and the development of\nan arti\ufb01cial intelligence tool to aid in the rapid and accuratepinpointing of disinformation attacks in their early stages,\nwe also conducted qualitative, textual analysis of 2500 of\nthe Russian IRA\u2019s \u2018\u2018fake news\u2019\u2019 Twitter posts and 2500 oftheir \u2018\u2018fake news\u2019\u2019 Facebook posts in order to cross-validate\nthe classi\ufb01cation accuracies of the machine-learning algo-\nrithms and to probe into the alleged degree of Russianinvolvement in the alleged disinformation warfare\ncampaign.\n3.1 The dark crawler\nTDC is a custom-written, web-crawling software tool,\ndeveloped by Richard Frank of Simon Fraser University\u2019s\nICCRC. This application captures Web content from the\nopen and Dark Web, as well as structured content fromonline discussion forums and various social media plat-\nforms. TDC uses key words, key phrases and other syntax\nto retrieve relevant pages from the Web. TDC analysedthem and recursively follows the links out of those pages.\nStatistics are automatically collected and retained for each\nwebpage extracted, including frequency of keywords andthe number of images and videos (if any are present). The\nentire content of each webpage is also preserved for further\nmanual and automated textual analysis. Content retrievedby TDC is parsed into an Excel-style worksheet, with each\ndata element being identi\ufb01ed and extracted. In previous\nstudies of this nature, we have employed this same pro-cedure to collect over 100 million forum posts from across\na vast number of hacking and extremist forums, to be used\nfor later analysis [ 70,71].\n3.2 Natural language processing\nWe employed OpenNLP for data extraction and pre-pro-\ncessing for TensorFlow, LibShortText, LibLinear andRandom Forest. OpenNLP was originally a Java-based\nmachine learning toolkit for the processing of natural lan-\nguage text [ 71], which, although Java-based, can be inte-\ngrated into a.NET-based program. It has also been portedto the.NET family of languages, which we used for our\nNLP needs. The tools included in this processing include:\n(1) a sentence detector to separate paragraphs into\nsentences (not a trivial job, given how acronyms\nand numbers can also use periods)\n(2) a tokenizer to separate the sentences into words\n(3) a Part-Of-Speech tagger to tag each word with the\ntype of word it is (noun, verb, etc.) based on the wordand the context it is found within\n(4) a chunker , to group the tagged words into groups for\neasier analysis\nAll of these components were then combined to extract\nmore information from the given text.\nThis data that we input to the machine-learning models\ncontains only the ID of the content and the full textual\ncontent of the social media post, which are fed intoOpenNLP, which then analyses each text and generates\nextra statistics about the text. In our case, an additional 126\nfeatures are generated for each text, and were appended tothe data. This data is then moved onto the Windows server\nand Linux Server, where the various algorithms are used to\nbuild the respective models.\n3.3 TensorFlow (Deep Neural Networks)\nTensorFlow, originally developed by the Google Brain\nTeam, is a machine learning system that employs deep\nneural networks, inspired by real-life neural systems [ 61].\nThe learning algorithms are designed to excel in pattern\nrecognition and knowledge-based prediction by training\nsensory data through an arti\ufb01cial network structure ofneurons (nodes) and neuronal connections (weights). The\nnetwork structure is usually constructed with an input\nlayer, one or more hidden layers, and an output layer. Eachlayer contains multiple nodes, with connections between\nthe nodes in the different layers. As data are fed into this\nneural system, weights are calculated and repeatedly\nchanged for each connection [ 61].\nTo elaborate, Deep Neural Networks (DNN) constitute a\nnetwork of neurons, or nodes, which are organized into\nrows, each of which represents a layer. Layers are identi-\n\ufb01ed as input ,hidden and output , respectively. The input\nlayer takes information directly from the data, as an input\nvalue, and passes it through to the DNN. Hidden layers\nexist between the input layer and the output layer. DNNs\ncan use any number of hidden layers for the network. The\ngreater the number of hidden layers, the deeper the DNN\nbecomes. Multiple hidden layers allow DNNs to solveNeural Computing and Applications (2022) 34:15141\u201315163 15145\n123\nmore complex problems, by preventing the Network from\nrelying on linear separability, as would be the case with\ndecision trees. Where decision trees follow a linear rule\npattern, establishing which class values exhibit speci\ufb01ccharacteristics, DNNs can generate patterns that are not\nlimited to a single dimension. The output layer displays the\nvarious outputs required for the problem. In this case, theclass values ( real, fake orother ) would be presented in the\noutput layer .Figure 1demonstrates what a DNN looks\nlike. In this example the DNN is attempting to predict the\nprobability of a speci\ufb01c type of Iris (plant genus). In the\ninput layer, information about speci\ufb01c characteristics of\nIrises are exposed to the DNN, after which the hidden\nlayers attempt to group the characteristics into categories.\nThe output layer then produces the probability that an Iris\nwill be a certain species.\nIn the early stages of experimentation, we employed\nTensorFlow default settings for the parameters pertainingto the number of partitions, epochs, layers, learning rate,\nand regularization. With respect to regularization, data was\npartitioned into groups according to the order in which itappeared in the dataset. Thus, if the majority of the \u2018\u2018real\ninformation\u2019\u2019 messages appeared in the beginning of the\ndataset, it would be dif\ufb01cult to maintain consistent accu-racy when conducting X-fold cross-validation. To over-\ncome this issue, the data were randomized as it became\npartitioned. Furthermore, each partition maintained thesame data across all X-fold cross-validation tests, so that\nthe accuracy of the results could be compared properly.\nTensorFlow next compared the same data against the\nconstructed Deep Neural Networks model and utilized that\nmodel to predict the category for each data entry. To be\nable to run large numbers of experiments, we wrapped allcode into a standalone function, so that large numbers of\nvarious scenarios could be designed, set up and tested\ncontinuously. These batch jobs allowed us to evaluatedifferent combinations of parameters. The parameters of\neach run, and the corresponding results, are also shown\nbelow. Tests were run using 10 partitions, with training on\nthe \ufb01rst 9 partitions, and testing on the last partition.\n3.4 LibShortText\nLibShortText is an open-source software package, devel-\noped by the Machine Learning Group at National Taiwan\nUniversity. The use of LibShortText was recommended in\na 2018 paper by William Yang Wang of the University of\nCalifornia at Santa Barbara, wherein he also described (andprovided access to) his benchmark LIAR dataset. This\nLIAR dataset, which included 12,836 statements labelled\nfor their subject matter, situational context, and truthful-ness, was broken down into training, validation and test\nsets and was accompanied by instructions for automatic\nfake news detection [ 60].\nLibShortText is said to be more ef\ufb01cient and more\nextensible than other generalized text-mining tools,\nallowing for the conversion of short texts into sparse fea-ture vectors, and also for micro- and macro-level error\nanalysis [ 60]. On a typical computer, for example, pro-\ncessing and training with 10 million short texts requiresonly half an hour or so, whereas some text-mining tools\nsuch as Posit (discussed later) might require a day or more.\nLibShortText includes an interactive tool for error analysis,and the program\u2019s default options usually work well,\nwithout tedious \ufb01ne-tuning.\nFor our research project, we built a model using the\ndefault settings that came with the LibShortText software.\nWe started by running \u2018\u2018$ python text-train.py train\ufb01le,\u2019\u2019\nwhich generated a \u2018\u2018train\ufb01le.model\u2019\u2019 for our given \u2018\u2018train-\ufb01le.\u2019\u2019 Working with this previously built model, we set out\nto predict the classi\ufb01cation labels of the test set, or\n\u2018\u2018train\ufb01le,\u2019\u2019 using the instructions: \u2018\u2018$ python text-\nFig. 1 Neural nodes of a DNN used to predict probability of an Iris type15146 Neural Computing and Applications (2022) 34:15141\u201315163\n123\npredict.py -f test\ufb01le train\ufb01le.model predict_result,\u2019\u2019 fol-\nlowed by \u2018\u2018Option \u2013f\u2019\u2019 to overwrite the existing model \ufb01le\nand predict_result.\n3.5 LibLinear\nLibLinear is a companion open-source software package to\nLibShortText, again developed by the same Machine\nLearning Group at National Taiwan University that\ndeveloped LibShortText [ 62]. LibShortText is a text anal-\nysis program, while LibLinear is a classi\ufb01cation program.\nLibLinear predicts the accuracy of the classi\ufb01cation per-formed by LibShortText, much like WEKA predicts the\naccuracy of the classi\ufb01cation performed by Posit (discussed\nbelow). Another advantage to LibLinear is that it supportsincremental and decremental learning, or to express it\ndifferently, the addition and removal of data in order to\nimprove optimization and decrease run time. LibShortText,on the other hand, does not readily support updating of the\nmodel.\nIn an earlier test run, using a \u2018\u2018train\u2019\u2019 dataset consisting\nof 90,000 \u2018\u2018fake news\u2019\u2019 articles taken from the Kaggle and\nFA-KES datasets and the ISOT (fake news) dataset, juxta-\nposed with 80,000 \u2018\u2018real news\u2019\u2019 articles taken from theISOT (real news) dataset plus sources such as the BBC ,\nCBC ,The Globe & Mail ,Sky News and the Vancouver Sun ,\nfollowed afterward by a \u2018\u2018test\u2019\u2019 data set using 90,000 of thesame real news articles and 10,000 of the same fake news\narticles, LibLinear yielded a remarkable classi\ufb01cation\naccuracy of 98.24%. This however was a smaller datasetused as a preliminary test to determine viability of using\nthis algorithm for our experiments.\n3.6 Random forest\nA decision tree is one of the basic, and probably most\nunderstandable, classi\ufb01cation algorithms [ 72]. In the Ran-\ndom Forest method, classi\ufb01cation trees (of the type found\nin WEKA) are independently constructed by employing abootstrap sample of the entire dataset, and then relying on a\nsimple majority vote for predictive purposes (see Fig. 2),\nrather than relying on earlier trees to boost the weight ofsuccessive trees [ 65,73]. WEKA [ 74] employs a standard\nJ48 tree classi\ufb01cation method with tenfold cross-validation.\nIn this cross-validation, 10% of the data are hidden, andconditions are sought that will split the remaining 90% of\nthe dataset in two, with each part having as many data-\npoints as possible belonging to a single class. Accuracy ofthe tree is then considered relative to the hidden 10% of the\ndata. This process is normally repeated 10 times, each time\nwith a different hidden 10% subset, with WEKA producinga measure of how many data items were correctly\nclassi\ufb01ed.The predicted label of Random Forest \u2019s input data is a\nvote by the trees in the forest, weighted by their probability\nestimates. That is, the predicted class is the one with\nhighest mean probability estimate across the trees. Thus,the prediction probabilities of Random Forest can be\ncomputed as the mean predicted class probabilities of the\ntrees in the forest, and the class probability of a single treeis the fraction of samples of the same class in a leaf [ 75].\n3.7 The combined model\nThe combined model that we presently envision (see\nFig. 3) commences with TDC, which collects data from\nsocial media platforms, which are then stored in TDC\u2019s\ndatabase (Step 2). The section of the data for which knownlabels exist (e.g. dis/misinformation, real information or\nother) is exported into a \ufb02at-\ufb01le (CSV format\u2014Step 3).\nThis data contains only the ID of the content, and the fulltext of the content and is fed into our NLP algorithm\n(OpenNLP in our case) which analyses each text and\ngenerates extra statistics about the text; in our case, foreach text, an additional 126 features are generated and\nappended to the exported data. This data is then moved\nonto the Windows server (Step 5a) and Linux Server (Step5b) where the various algorithms are used to build the\nrespective models. A total of 4 models have been built,\nRandom Forest (using Scikit-learn) and Deep Neural Net-works (using TensorFlow) are built on Windows (where\nTensorFlow seems more stable) while LibLinear and Lib-\nShortText are built on Linux (where those algorithms werefound to be more stable). Once the resulting model \ufb01les are\ngenerated, the process is complete, and the system is ready\nfor prediction on new content.\nIn TDC, a new feature is available where users can\nbrowse paginated results of predicted posts, sorted mainly\nby Real, Fake and Troll class categories and News, Twitterand Facebook source types. On top of the predicted prob-\nabilities, the user can edit the four textbox \ufb01elds right\nbelow the columns for each model type (i.e. LibLinear ,\nLibShortText ,Random Forest ,TensorFlow ) to set the\nweights and click calculate to see the effective total\nprobability of prediction (see Fig. 4).\nThe formula for calculating the total probability is as\nfollows:\nWLL/C3PLL \u00f0\u00de \u00fe \u00f0 WLST/C3PLST\u00de\u00fe WRF/C3PRF \u00f0\u00de \u00fe WTF/C3PTF \u00f0\u00de\nWLL\u00feWLST\u00feWRF\u00feWTF\nwhere LL is the LibLinear model; LST is the LibShortText\nmodel; TF is TensorFlow \u2019sDeep Neural Net model; RF is\ntheRandom Forest model and Wxrepresents the user-as-\nsigned weight for algorithm x;Pxrepresents the probability\nof the requested class, as predicted by algorithm x.Neural Computing and Applications (2022) 34:15141\u201315163 15147\n123\nFor example, when calculating the prediction probabil-\nity that a speci\ufb01c text is \u2018\u2018real\u2019\u2019, the user-de\ufb01ned weight for\nLibLinear (WLL) is multiplied by the probability that the\ntext is \u2018\u2018real\u2019\u2019 according to LibLinear (PLL), which is then\nadded to the weight and probabilities of the other three\nalgorithms. The \ufb01nal total is divided by the sum of weightsassigned to all four algorithms, resulting in a weighted\naverage. If the user prefers to use only a single algorithm,\nthe weight can be set to 1, with the weights of the other\nFig. 2 Random es (Retrieved\nfrom https://compgenomr.\ngithub.io/book/trees-and-\nforests-random-forests-in-\naction.html\nFig. 3 Model building process\nFig. 4 Weight entry validation15148 Neural Computing and Applications (2022) 34:15141\u201315163\n123\nalgorithms set to 0. The ultimate goal is to provide a pre-\ndiction and alert process whereby the user can be noti\ufb01ed\nof a disinformation campaign on social media in near-real-\ntime.\nLibLinear, Random Forest and TensorFlow model\nalgorithms have an option for printing out the predicted\nclass probabilities (\ufb02oating-point numbers between 0.0 and1.0). Currently we are storing this information in the\ndatabase along with the predicted labels. LibLinear pre-\nsently supports probability outputs for logistic regression\nonly. The probability model for logistic regression is:\nPy =x\u00f0\u00de \u00bc1\n1\u00fee/C0ywTx;where y\u00bc/C61\nThe predicted label of Random Forest \u2019s input data is a\nvote by the trees in the forest, weighted by their probabilityestimates. That is, the predicted class is the one with\nhighest mean probability estimate across the trees. Thus,\nthe prediction probabilities of Random Forest can be\ncomputed as the mean predicted class probabilities of the\ntrees in the forest, and the class probability of a single tree\nis the fraction of samples of the same class in a leaf [ 75].\nFor the TensorFlow DNN classi\ufb01cation model, tf.esti-\nmator.DNNClassi\ufb01er returns four predictions: logits ,\nprobabilities ,class_ids ,classes , where class_id is integer\nandclasses is string representing the predicted class.\n3.8 The posit toolkit\nThe Posit toolkit was developed by George Weir of the\nDepartment of Computer and Information Sciences at theUniversity of Strathclyde. Posit generates frequency data\nand Part-of-Speech (POS) tagging while accommodating\nlarge text corpora. The data output from Posit includesvalues for total words (tokens), total unique words (types),\ntype/token ratio, number of sentences, average sentence\nlength, number of characters, average word length, nountypes, verb types, adjective types, adverb types, preposition\ntypes, personal pronoun types, determiner types, possessive\npronoun types, interjection types, particle types, nouns,verbs, prepositions, personal pronouns, determiners,\nadverbs, adjectives, possessive pronouns, interjections and\nparticles. When analysing texts using Posit, output isgenerated at several levels of detail. Of these, the summary\nlevel is the most general, e.g. the total number of verbs,\nnouns, adjectives, etc. for a total of 27 features in all. Anexample of such output is shown in Fig. 6.\nAs it was con\ufb01gured for previous studies, the Posit\ntoolkit created data on the basis of word-level information;thus, the limited content of the Russian IRA tweets that we\nwere examining meant that many of the original features\nmight have zero values. For this particular research project,Posit was extended to include analysis of character-levelcontent, to assist with the analysis of short texts. To this\nend, the system supplemented the standard word-level\nstatistics, generating an additional 44-character features for\neach instance of text data. These new features includedquantitative information on individual alphanumeric char-\nacters, plus a subset of special characters\u2014speci\ufb01cally,\nexclamation marks, question marks, periods, asterisks anddollar signs. The extension of Posit to embrace character-\nlevel as well as word-level data maintained the domain-\nneutral nature of Posit analysis. As a result of this extended\nPosit analysis, each data item (tweet) was represented by a\nset of 71 features, rather than the usual twenty-seven [ 1].\nThereafter, Posit\u2019s summary values for each data item\nare treated as features that describe the associated item.\nEach data item is thereby represented by numerical valuesfor Posit\u2019s 27 summary features. To these features, we can\nadd the pre-classi\ufb01cation value\u2013in the present case, this is\neither \u2018\u2018real\u2019\u2019 information or \u2018\u2018misinformation\u2019\u2019\u2014therebycharacterising each data item by these 28 features (see\nFig. 4).\nIn the case of Posit, the resultant data were input to the\nWEKA data analysis application. For Posit, the standard\nJ48 tree WEKA classi\ufb01cation method was applied, aug-\nmented with the Random Forest classi\ufb01cation method, bothwith ten-fold validation (as described above). WEKA then\nproduced a measure of how many of the text items were\ncorrectly classi\ufb01ed. In the Random Forest method, classi-\ufb01cation trees (of the type found in WEKA) are indepen-\ndently constructed, by employing a bootstrap sample of the\nentire dataset, and then relying on a simple majority votefor predictive purposes, rather than relying on earlier trees\nto boost the weight of successive trees.\nUsing a software tool such as WEKA, we evaluate the\nef\ufb01cacy of the quantitative data as a basis for matching the\npre-classi\ufb01cation of the considered data set. Speci\ufb01c\nalgorithms are selected within the classi\ufb01cation tool.Combined with the feature set, the software tool (WEKA)\nbuilds a classi\ufb01cation model and considers its ability to\nmatch the pre-classi\ufb01cation. As detailed elsewhere, theevaluation of any model\u2019s performance in WEKA gener-\nates the following measures: confusion matrix, accuracy\n(acc), precision (pr), recall (rec) and F1 score (f1). Aconfusion matrix is an NxN table that summarizes model\nperformance, where N is the number of classes being\nconsidered.\nIn the preliminary stages of our research, we envisioned\nthe Posit toolkit as part of our combined model, along with\nTDC, TensorFlow (Deep Neural Networks), LibShortText,LibLinear and Random Forest. However, we found that\nPosit worked better as a stand-alone model, as it was taking\nlonger than LibShortText and LibLinear to process socialmedia messages, and did not integrate particularly well into\nthe.Net and REST applications being used for the otherNeural Computing and Applications (2022) 34:15141\u201315163 15149\n123\nmachine-learning algorithms. Nevertheless, Posit per-\nformed as well as some of the other machine-learning\nalgorithms employed in our combined model, and at times\noutperformed one or more of them in certain experiments.Thus, we have continued to employ Posit in our research,\nand in fact, used it in a recent study of COVID-19 dis/\nmisinformation on social media.\n3.9 The research sample\nAt the beginning of the project, the research team down-loaded a dataset of 2,946,219 Twitter messages (tweets)from git.hub, which had been posted online by \ufb01vethir-\ntyeight.com. This dataset of tweets was collected and\nassembled by the aforementioned professors from ClemsonUniversity, Darren Linvill and Patrick Warren [ 51]. These\ntweets were described as originating from the Russian IRA,\nalso referred to in common parlance as the Russian trollfactory, a hostile foreign agency that was believed to have\nintentionally interfered in the 2016 U.S. Presidential elec-\ntion and the 2016 U.K. Brexit referendum. As the variousapproaches used in our research (i.e. manual qualitative\nanalysis, Posit, TensorFlow, LibShortText and Random\nForest) were designed to read English text, a decision wasmade to extract only those entries that were labelled as\nbeing \u2018\u2018English,\u2019\u2019 so in the process, we excluded languages\nsuch as Albanian, Bulgarian, Catalan, Croatian, Dutch,Estonian, French, German, Italian, Russian, Ukrainian,\nUzbek, Vietnamese. As a consequence, 13 new Excel\nspreadsheets were created, with 2,116,904 English-speak-ing tweets remaining in the dataset following the removal\nof all non-English tweets.\nHaving acquired the Russian (IRA) Twitter data, we\nthen sought a second Twitter dataset that would allow us to\ndevelop a classi\ufb01cation model based upon comparison\nbetween \u2018\u2018real news\u2019\u2019 and what has often been referred tosimply as \u2018\u2018fake news\u2019\u2019. To this end, we analysed the tex-\ntual content from the full set of IRA tweets (or \u2018\u2018fake\nnews\u2019\u2019) using Posit, in order to identify frequently occur-ring terms, and more speci\ufb01cally, nouns. The resultant\n\u2018\u2018keyword\u2019\u2019 list was used by TDC, in order to retrieve a set\nof matching \u2018\u2018real news\u2019\u2019 Twitter posts from legitimatenews sites.\nThe customized crawler harvested Twitter feeds main-\ntained by more \u2018\u2018traditional,\u2019\u2019 mainstream news sources,such as the Globe and Mail ,CBC News ,CTV News , the\nBBC , the New York Times , the Daily Telegraph , the Wall\nStreet Journal ,Asahi Shim-Bun ,Times of India , the\nWashington Post , the Guardian , and Daily Mail Online ,\ncollecting tweets posted between the beginning of January\n2015 and the end of August 2018 (within the approximatetime frame of the IRA tweets). Tweets from the \u2018\u2018real\nnews\u2019\u2019 dataset that were posted after August 2018 wereremoved, as the data from the IRA tweets did not extend\nbeyond that time frame. We started with 90,605 tweets, but\nwith the removal of 10,602 tweets that had been posted in\nlate 2018 and early 2019, we were left with 80,003 indi-vidual cases or tweets that exempli\ufb01ed \u2018\u2018real\u2019\u2019 or \u2018\u2018legiti-\nmate\u2019\u2019 news sources. These sources of information were\nselected for their reputation, journalistic integrity, andvariety in \u2018\u2018leanings\u2019\u2019 right, or left.\nA somewhat different sample was assembled for the\nTensorFlow (Deep Neural Networks) analysis, because for\nTensorFlow to operate effectively, a larger dataset is\ndesirable. To achieve this, we combined the 2,116,904English-speaking \u2018\u2018fake news\u2019\u2019 tweets that remained (fol-\nlowing the removal of all non-English cases) with the\n90,605 \u2018\u2018real news\u2019\u2019 tweets that were downloaded by TDC(prior to removal of tweets that extended beyond the time\nframe of the IRA activities). This dataset was supple-\nmented with 2500 posted by the IRA on Facebook pagesnamed variously as Blacktivist, Secured Borders, Being\nPatriotic, LGBT United and United Muslims of America.\nThis sample of Facebook posts was collected and madeavailable at data.world and Tableau by Jonathon Albright\nof Columbia University\u2019s Tow Center for Digital Journal-\nism. Dr. Albright has himself conducted research into IRAdisinformation activities on social media and realized the\nimportance of capturing and preserving the evidence and\nsharing it with other researchers [ 76,77]. Thus, a large\ndataset of tweets and Facebook posts was analysed in\nTensorFlow following the merging of these multiple\ndatasets.\nThe \ufb01rst of two \u2018\u2018real news\u2019\u2019 comparator datasets\nintended for analysis of the IRA data was derived from\n87,157 political news articles from October 2015, posted atwebhose.io. These \u2018\u2018real news\u2019\u2019 articles came from a wide\nvariety of Web-based news posts, from sources including\ntheWorldNews (WN) Network ,Independent Television ,\nPhiladelphia Daily News , the Buffalo News ,The Wall\nStreet Journal ,The Washington Times ,The Boston Herald ,\nThe Chicago Sun Times ,The New York Times ,Fox News ,\ntheBBC , etc. To ensure that our results would not be\npredicated on only one comparator dataset, we next\nobtained a second \u2018\u2018real news\u2019\u2019 dataset, this time of actualFacebook posts made available at github.com. The data\nthat we retrieved from github.com was originally com-\nprised of 164 sets of publicly accessible Facebook statusposts. From these status posts, we manually selected\nFacebook IDs that appeared to be associated with tradi-\ntional news sources, such as USA Today , the New York\nTimes andCNBC .\nFollowing our initial round of data collection, described\nunder Task 1 (above), we broadened and enriched ourselection of data sources under Task 2 (above), focussing\nprimarily on Facebook, Twitter, and other web-based news15150 Neural Computing and Applications (2022) 34:15141\u201315163\n123\nsources. A \u2018\u2018fake news\u2019\u2019 list of Facebook pages was gen-\nerated by searching for Facebook pages that belonged to\nwebsites described by MediaBiasFactCheck.com as com-\ning from \u2018\u2018questionable sources,\u2019\u2019 from which we derived alist containing 530 questionable sources (websites) referred\nto as \u2018\u2018fake news.\u2019\u2019 Of those, 185 were found to have a\nFacebook page. These pages were located by searching forthe website\u2019s name and/or link. Only pages meeting\nspeci\ufb01c selection criteria were harvested, yielding 96,219\nFacebook \u2018\u2018fake news\u2019\u2019 items, recently supplemented by a\nset of 3,736 Canadian Facebook \u2018\u2018fake news\u2019\u2019 items.\nTwitter fake news speci\ufb01cally assembled by the research\nteam for this project were extracted the same way as the set\nof \u2018\u2018fake\u2019\u2019 Facebook posts, i.e. using the list of 530\n\u2018\u2018questionable sources\u2019\u2019 published byMediaBiasFactCheck.com. From this, 181 Twitter\naccounts were identi\ufb01ed for data collection, accounting for\n43,193 data items. Only Twitter accounts that contained alink to the websites identi\ufb01ed by MediaBiasFactCheck.com\nas suspect and that met our selection criteria were included\nin this sample.\nOur third category of \u2018\u2018fake news\u2019\u2019 was derived from\nWeb sites presenting themselves as legitimate sources of\nreal news but considered \u2018\u2018fake.\u2019\u2019 News articles were col-lected from four publicly available datasets: (1) ISOT Fake\nNews , (2) Getting Real About Fake News , (3) Fake News\nCorpus and (4) FA-KES: A Fake News Dataset around the\nSyrian War . Finally, the FA-KES dataset, created at the\nAmerican University of Beirut with the intention of helping\ntrain machine learning models, contained 805 news articlesabout the con\ufb02ict in Syria, of which 46 are labelled as\n\u2018\u2018fake,\u2019\u2019 while the remaining 378 as \u2018\u2018real.\u2019\u2019\nComparator \u2018\u2018real news\u2019\u2019 Facebook and Twitter data sets\nhave been collected from of\ufb01cial news sources represent-\ning the top 24 Canadian newspapers in accordance with\ntheir known circulation in 2016. We also included Huff-\nington Post Canada and two TV News sources with large\nonline followings\u2014 CBC News andCTV News . Apart from\nthe CBC, CTV and the Canadian edition of the Huf\ufb01ngtonPost, we obtained data from 24 sources, including the\nGlobe and Mail ,The National Post ,The Toronto Star ,Le\nJournal de Montreal (French), Le Journal de Quebec\n(French), The Vancouver Sun ,The Toronto Sun ,The\nHamilton Spectator ,The Calgary Herald ,The Winnipeg\nFree Press ,The Edmonton Journal ,The Ottawa Citizen ,\nThe Chronicle Herald ,The Montreal Gazette , etc. In total,\nwe collected 31,557 \u2018\u2018real news\u2019\u2019 Facebook data items from\nthese \u2018\u2018trustworthy\u2019\u2019 news sources. We also collected253,936 \u2018\u2018real news\u2019\u2019 Twitter data items from these\n\u2018\u2018trustworthy\u2019\u2019 news sources.\nWe also collected a sample of 3,500 tweets from hash-\ntags such as #TrudeauMustGo, #TrudeauMustGoToJail,\nand #TrudeauMustResign all of which were suspected tocontain \u2018\u2018fake news\u2019\u2019 intended to in\ufb02uence the outcome of\nthe recent Canadian federal election in October 2019. We\nare now in the process of collecting data from the online\nnews site USAReally , as it is suspected of being set up by\nthe Russian IRA for the purpose of interfering in the\nupcoming 2020 US Presidential Election. We are also\ninvestigating the possibility of retrieving 6691 data itemsthat exemplify pro-Kremlin news stories identi\ufb01ed by the\nEuropean Union as designed to interfere in the recent 2019\nEU Parliamentary Election. While the EU disinformation\ncases do not involve social media campaigns per se, they\nnevertheless are expected to provide us with currentexamples of Russian-orchestrated disinformation activities\nin a broader geopolitical setting. In addition, we are cur-\nrently focussing our efforts on collecting Canadian-speci\ufb01c\n\u2018\u2018fake news\u2019\u2019 Facebook items, from The Buffalo Chronicle-\nCanadian edition , Canadian Truth Seekers, Million Cana-\ndian March, The Canadian Defence League, The SilentMajority Canada, The Angry Cousin, Proud Canadians and\nCanada Proud. The latter dataset presently consists of\n3,737 discrete data items.\nAt this point, we have assembled a database consisting\nof 6,562,080 \u2018\u2018real news\u2019\u2019 and \u2018\u2018fake news\u2019\u2019 items. This is a\ncurrent value, and good only at the moment of writing, asour data collection is extensive and ongoing.\n3.10 Labelling of data\nA team of \ufb01ve qualitative researchers (along with the teamleader) met several times, to discuss the manual classi\ufb01-cation process, review the tentative \ufb01ndings, and resolve\ndifferences in classi\ufb01cation methods and \ufb01ndings. If there\nwere disagreements with respect to the assessment, then theteam would listen to the various arguments advanced by\nthose who disagreed and come up with a solution that was\nmutually acceptable to all of the team members. To illus-trate, some of the team members were unable to arrive at a\n\ufb01nal classi\ufb01cation for messages that were in the French\nlanguage, as they lacked \ufb02uency in French. They were notinitially provided with the source of the French language\nmessages, nor with the source of any of the messages, for\nthat matter, so they did not realize that all of those mes-sages had been harvested from recognized, rep-\nutable French language media. Once the language that the\nmessages contained had been explained to them, and theybecame aware of the sources from which those messages\nhad been drawn, this classi\ufb01cation issue was overcome.\nA research decision was made to have this team of\nqualitative researchers manually classify the previously\nunseen set of 1000 Facebook posts and another previously\nunseen set of 1000 Twitter messages. These two datasetsconsisted of the above-mentioned \u2018\u2018real news\u2019\u2019 and \u2018\u2018fake\nnews,\u2019\u2019 randomly sampled from the massive \u2018\u2018real\u2019\u2019 andNeural Computing and Applications (2022) 34:15141\u201315163 15151\n123\n\u2018\u2018fake\u2019\u2019 datasets that had already been input to LibLinear,\nLibShortText, Random Forest and TensorFlow for training\nand classi\ufb01cation purposes. The classi\ufb01cations already\nassigned to these 1000 Facebook posts and 1000 Twittermessages 1000 were known to the research team working\nwith LibLinear, LibShortText, Random Forest and Ten-\nsorFlow, but not known to the qualitative researchers.\nEach of the messages in these new datasets consisting of\n1000 \u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Facebook posts and 1000 \u2018\u2018real\u2019\u2019\nand \u2018\u2018fake\u2019\u2019 Twitter messages were read and re-read several\ntimes, often by several researchers. Anything that they\ncontained that appeared to have the slightest possiblerelationship to \u2018\u2018real news\u2019\u2019 was subjected to a Google\nsearch, to determine authenticity or lack thereof. All\nviewable attachments or related stories were also taken intoconsideration. In the \ufb01nal analysis, where classi\ufb01cation\ndiscrepancies still existed, the known sources of the mes-\nsages were then examined by the team leader and a seniorresearcher, to maximize classi\ufb01cation precision. We clas-\nsi\ufb01ed 599 of the Facebook posts as \u2018\u2018real,\u2019\u2019 and 401 as\n\u2018\u2018fake,\u2019\u2019 and classi\ufb01ed 543 of the Twitter messages \u2018\u2018real,\u2019\u2019and 457 as \u2018\u2018fake.\u2019\u2019\n3.11 Ethical considerations in data collection\nInformed consent is a central ethical principle in researchscenarios that pose potential risk, harm, discomfort orembarrassment to the research subjects [ 78,79]. The type of\nInternet research undertaken in this study of dis/misinfor-\nmation on social media could abrogate the right of theresearch subjects to know about the nature and duration of\nthe research project, the potential risks and bene\ufb01ts, and\nwhat measures were being taken to ensure con\ufb01dentiality[80,81]. In the \ufb01nal analysis, this study of real information\nand dis/misinformation on social media used readily acces-\nsible archival materials posted in a public arena, it involvedno interaction with the research subjects, and posed no\ngreater risk than what might normally be encountered by the\nresearch subjects in their daily lives [ 82,83]. Moreover, it\naddresses a serious social problem, given that the type of dis/\nmisinformation promulgated by hostile foreign actors a real\nthreat to normal democratic processes.\n4 Research findings\n4.1 Research findings TensorFlow, LibShortText,\nLibLinear and random forest\nOverall, we found that LibShortText and LibLinear were\noutperforming TensorFlow (Deep Neural Networks, using5 hidden layer with 100 nodes) and Posit. To illustrate,\nwhen analysing 1000 randomly selected data items takenfrom our own \u2018\u2018real news\u2019\u2019 dataset and from the \u2018\u2018real\nnews\u2019\u2019 portions of the ISOT and FA-KES datasets, con-\ntrasted with 1000 randomly selected data items taken from\nour own \u2018\u2018fake news\u2019\u2019 dataset and from the \u2018\u2018fake news\u2019\u2019portions of the Kaggle, ISOT and FA-KES datasets, we\nfound that LibShortText and LibLinear exhibited classi\ufb01-\ncation accuracies of 93 and 92%, respectively, as opposedto Posit and WEKA at 72.7%, TensorFlow (using Posit-\ngenerated.arff content at 54.5%, TensorFlow (using content\nonly) at 52.5%, and TensorFlow (using tagged text) at\n48%. We would consider these TensorFlow numbers to be\nno better than tossing a coin, but these results were notentirely unexpected, as TensorFlow thrives on large data,\nand this experiment was conducted using only 2,000 dis-\ncrete data items.\nThe qualitative research team had a high degree of\ncon\ufb01dence in this manual classi\ufb01cation, regarding it as the\n\u2018\u2018gold standard,\u2019\u2019 against which the machine classi\ufb01cationcould then be cross-validated, in what could essentially be\nregarded as a \u2018\u2018double-blind\u2019\u2019 process. The qualitative\nclassi\ufb01cations were given to the other (machine-reading)research teams, who in turn gave the qualitative researchers\nthe classi\ufb01cations obtained by Posit, and by LibLinear,\nLibShortText, Random Forest and TensorFlow for thesesame two datasets. The qualitative research team then\nanalysed similarities and dissimilarities across the research\n\ufb01ndings.\nThere was a reasonably high degree of concordance\nbetween the classi\ufb01cations assigned by the different\nresearch teams to the new datasets consisting of 1000\u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Facebook posts and 1000 \u2018\u2018real\u2019\u2019 and\n\u2018\u2018fake\u2019\u2019 Twitter messages. For example, with the 1000\n\u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Facebook posts, the classi\ufb01cationsassigned by the LibLinear, LibShortText, Random Forest\nand TensorFlow combination were in agreement with the\nmanually assigned classi\ufb01cations 80.5% of the time (seeTable 1). In instances where there were classi\ufb01cation dif-\nferences, they occurred almost exclusively with the clas-\nsi\ufb01cation of \u2018\u2018real news\u2019\u2019 items (i.e. 196 of the \u2018\u2018real news\u2019\u2019messages, or 19.6% of the Facebook dataset). Moreover, in\ncases where there were disagreements between the\nLibLinear, LibShortText, Random Forest and TensorFlow\nTable 1 Classi\ufb01cation Agreement/Disagreement for Facebook\nDataset\nCategory Frequency Percentage\nNo Disagreement 803 80.3\nDisagreement-Real News 196 19.6Disagreement-Fake News 1 0.1Total 1000 100.015152 Neural Computing and Applications (2022) 34:15141\u201315163\n123\ncombination and the manually assigned classi\ufb01cations,\nLibLinear on its own agreed with (supported) the manual\nclassi\ufb01cation 88 times, suggesting that LibLinear should be\ngiven a greater weight in any future machine-readingclassi\ufb01cation process. Indeed, the relationship between the\nmanual classi\ufb01cation and the classi\ufb01cation provided by\nLibLinear was particularly strong and robust(X\n2= 608.374, df = 1, p= 0.001).\nMuch the same can be said with respect to the 1000\n\u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Twitter messages, albeit with not quite\nthe same degree of con\ufb01dence. The classi\ufb01cations assigned\nby the LibLinear, LibShortText, Random Forest and Ten-sorFlow combination were in agreement with the manually\nassigned classi\ufb01cations only 59.6% of the time (see\nTable 2). Unlike the case with the Facebook dataset,\nhowever, in instances where there were classi\ufb01cation dif-\nferences with Twitter, they occurred almost exclusively\nwith the classi\ufb01cation of \u2018\u2018fake news\u2019\u2019 items (i.e. 401 of the\u2018\u2018fake news\u2019\u2019 messages, or 40.1% of the Twitter dataset).\nAgain, in cases where there were disagreements between\nthe LibLinear, LibShortText, Random Forest and Ten-sorFlow combination and the manually assigned classi\ufb01-\ncations, LibLinear on its own agreed with (supported) the\nmanual classi\ufb01cation 331 times, adding further evidencethat LibLinear should be given a greater weight in any\nfuture machine-reading classi\ufb01cation process. As was the\ncase with the Facebook dataset, the relationship betweenthe manual classi\ufb01cation and the classi\ufb01cation provided by\nLibLinear was strong and robust ( X\n2= 238.077, df = 1,\np= 0.001), albeit not as strong and robust as it was for\nclassi\ufb01cation of the 1000 Facebook data items.\n4.2 Posit findings\u2014overview\nThe set of 1000 Facebook posts and 1000 Twitter messagesdescribed above were forwarded to the research team atStrathclyde University in Scotland for classi\ufb01cation and\ncross-validation purposes. As was the case with the sam-\nples initially provided to the qualitative research team,these datasets did not include classi\ufb01cation scores from the\nLibLinear, LibShortText, Random Forest, TensorFlow\nteam, nor did they include the classi\ufb01cation scores that hadsubsequently been assigned by the qualitative research\nteam. Rather, the classi\ufb01cation scores that had subse-\nquently been assigned by the qualitative research team\nwere only provided after the provisional classi\ufb01cation wasconducted in Posit. As importantly, the two new datasets\nthat were forwarded to Strathclyde for Posit analysis did\nnot include information about the sources from which the\u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 news were drawn, thereby precluding\nanyone at the Strathclyde end from identifying them as\n\u2018\u2018real\u2019\u2019 or \u2018\u2018fake, solely on the basis of source. Essentially,\nthis could be regarded as another \u2018\u2018double-blind\u2019\u2019 process.\nThe following is a detailed account of the \ufb01ndings of theresearch team at Strathclyde.\n(1) Complexion Analysis of 1000 Twitter messages and\n1000 Facebook messages\nThe purpose of complexion analysis is to reveal\nany gross discrepancies in characteristics betweenthe data items that have been classi\ufb01ed. For\ninstance, there is always a possibility that a single\ndistinctive feature may unduly in\ufb02uence the auto-mated classi\ufb01cation process. Once the classi\ufb01cation\nhas been undertaken, we are able to undertake the\nsubsequent inspection of key characteristics of eachclass, in order to gain a view on the likelihood of\nsuch in\ufb02uential factors as number of words, num-\nber of characters, number of special characters, aswell as maximum, minimum and average values\nfor each of these features.\nFollowing the manual classi\ufb01cation, all data\nsamples were contrasted to determine their com-\nplexion in terms of total words, total characters and\ntotal special characters. The special characters are asubset of the non-alphanumeric characters, which\nare expected to appear routinely in social media\nposts. This small subset comprises exclamationmarks, dollar signs, question marks, asterisks and\nperiods.\nThe following details the results of complexion\nanalysis on the Twitter and Facebook data subsets\nthat were classi\ufb01ed manually by the qualitative\nresearch team on the basis of extensive, in-depthanalyses of the 1000 randomly selected tweets and\n1000 randomly selected Facebook posts (Figs. 5\nand 6).\n(2) Twitter and Facebook Comparison\nData items drawn from different social media\nplatforms (SMPs, Facebook, for example) may beexpected to display distinctive characteristics that\nre\ufb02ect their particular SMP origin. Indeed, compar-\ning lexical features across social networks throughquantitative methods is not likely to afford useful\ninsights toward the classi\ufb01cation of individual items,\nTable 2 Classi\ufb01cation Agreement/Disagreement for Twitter Dataset\nCategory Frequency Percentage\nNo Disagreement 596 59.6\nDisagreement-Fake News 401 40.1Disagreement-Real News 3 0.3Total 1000 100.0Neural Computing and Applications (2022) 34:15141\u201315163 15153\n123\nsince their social network provenance is usually a\ngiven. Nevertheless, in the present context, we areexploring aspects that may in\ufb02uence the decision on\n\u2018\u2018real\u2019\u2019 or \u2018\u2018fake\u2019\u2019 classi\ufb01cation. Before presenting\ncomplexion details of the separate Twitter andFacebook data samples, we can note the evident\nsimilarities and dissimilarities between these two\ndatasets.\nThe number of words exhibited by the differently\nsourced samples, re\ufb02ecting how this is distributed\nacross each set of 1000 items, is illustrated in Fig. 7.\nThis exhibits a very similar distribution curve.\nThe corresponding distribution of character counts\nis shown in Fig. 8. This exposes a difference in scale,\nwith Twitter items generally greater in character\ncount than Facebook, but, once again, the distribu-\ntion curves reveal a similar shape.\nFinally, we may contrast the relative use of special\ncharacters in each of the Twitter and Facebook\ndatasets. This is illustrated in Fig. 9. As with the\nword and character counts, the distribution curves for\nspecial characters between the Twitter and Facebook\nFig. 5 Example of posit summary output\nFig. 6 Example of posit aggregate output (prepared for WEKA input)15154 Neural Computing and Applications (2022) 34:15141\u201315163\n123\ndatasets show similar shapes. Like the contrast\nbetween their character counts, Twitter items exhibita curve that is consistently above the values for the\nFacebook items.\n(3) Twitter\nThis Twitter dataset comprised 1000 samples that\nwere manually classi\ufb01ed by the qualitative researchteam as either \u2018\u2018real\u2019\u2019 or \u2018\u2018fake\u2019\u2019. The breakdown for\nthese two classes, as classi\ufb01ed by the qualitativeresearchers, was 543 \u2018\u2018real\u2019\u2019 and 457 \u2018\u2018fake\u2019\u2019 data\nitems. Considering the number of words that were\npresent in the data items from these two classes, wedetermined that there was little difference in the\naverage number of words of each class of tweet, with\n\u2018\u2018real\u2019\u2019 averaging 23 words and \u2018\u2018fake\u2019\u2019 averaging 22words. The minimum number of words were also\nclose, with \u2018\u2018real\u2019\u2019 tweets recording 6 words and\n\u2018\u2018fake\u2019\u2019 tweets recording 4 words. A greater differ-ence was apparent in terms of the maximum number\nof words, with \u2018\u2018real\u2019\u2019 tweets reaching 67 words and\n\u2018\u2018fake\u2019\u2019 tweets only 31 (Table 3). Despite the\napparent scale of this difference, the distribution of\ntweets when focusing on number of words for each\nof the two classes is fairly similar. Figure 10\nillustrates this distribution.\nWhile such contrasts in data complexion are not\nused in our present classi\ufb01cation, they demonstratethe insights that can be afforded by this step in our\nmethodology. This is all the more evident as we turn\nour attention to the individual datasets.\nThe Twitter samples displayed similar scale in the\naverage number of characters, with \u2018\u2018real\u2019\u2019 Tweets on\n170 characters and \u2018\u2018fake\u2019\u2019 Tweets on 172 characters.Minimum number of characters in Tweets were 40\nand 26, respectively. As with the comparison of\nmaximum number of words, the contrast in maxi-mum number of characters appears marked, with\n\u2018\u2018real\u2019\u2019 Tweets reaching 525 and \u2018\u2018fake\u2019\u2019 Tweets at\n279. Although the maximum number of charactersfor Tweets permitted on Twitter is 280 characters,\nthis is exceeded if URLs are included. The full length\nof such URLs would be retained as text in our datasamples. These contrasts are shown in Table 3, with\nthe corresponding distributions illustrated in Fig. 10.\nThe \ufb01nal contrast between the \u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019\nTweet classes took into consideration the presence of\nour special character set. In this case, the average\nspecial character count was similar between the twoclasses of Tweets, with \u2018\u2018real\u2019\u2019 reaching 27 and\n\u2018\u2018fake\u2019\u2019 at 26. The minimum and maximum number\nof occurrences were also very close for each Twitterclass, with \u2018\u2018real\u2019\u2019 minimum at 16 and \u2018\u2018fake\u2019\u2019\nminimum at 15, \u2018\u2018real\u2019\u2019 maximum at 38 and \u2018\u2018fake\u2019\u2019\nmaximum at 37 (Table 3). The distribution of special\ncharacter count across the two classes of Tweet is\nshown in Fig. 10.\nWhile these particular \u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Twitter\nclasses display similar graph shapes in distribution\nacross our three features (word count, charactercount and special character count), for each of these\nFig. 7 Word count distribution for twitter and facebook datasets\nFig. 8 Character count distribution for twitter and facebook datasets\nFig. 9 Special character count distribution for twitter and facebook\ndatasetsNeural Computing and Applications (2022) 34:15141\u201315163 15155\n123\nfeatures there is an evident extension in range for the\n\u2018\u2018real\u2019\u2019 Tweets. This may indicate that the process of\nmanual classi\ufb01cation was based upon sizes in wordcount, character count and special character count,\nwith Tweets at the higher reaches of these values\nbeing more readily characterised as \u2018\u2018real\u2019\u2019. Corre-spondingly, the manual classi\ufb01cation of \u2018\u2018fake\u2019\u2019\nTweets may be \u2018easier\u2019 for shorter Tweets (Fig. 11).\n(4) Facebook\nThis Facebook data set comprised 1000 samples\nthat were manually classi\ufb01ed as \u2018\u2018real\u2019\u2019 or \u2018\u2018fake\u2019\u2019.\nThe breakdown against these classes was 599 \u2018\u2018real\u2019\u2019and 401 \u2018\u2018fake\u2019\u2019.\nConsidering the number of words present in dataitems of these two classes, we determined that there\nwas some difference in the average number of words\nof each class of Facebook post, with \u2018\u2018real\u2019\u2019 averag-\ning 22 words and \u2018\u2018fake\u2019\u2019 averaging 14 words. Theminimum number of words were identical at 1\n(Table 3). A greater difference was apparent in terms\nof their maximum word length, with \u2018\u2018real\u2019\u2019 postsreaching 88 words and \u2018\u2018fake\u2019\u2019 posts only 70.\nFigure 12shows the distribution in the number of\nwords across posts in the two classes. From this, wesee that the difference in average number of words\nre\ufb02ects the greater number of longer posts in the\n\u2018\u2018real\u2019\u2019 class against the \u2018\u2018fake\u2019\u2019 class.\nThe Facebook posts displayed some difference in\naverage character lengths, with \u2018\u2018real\u2019\u2019 Facebook\nposts having, on average, 142 characters and \u2018\u2018fake\u2019\u2019Tweets having 94 characters. The minimum number\nof characters in posts was 6 and 4, respectively,\nwhile the difference in maximum number of charac-ters appears marked, with \u2018\u2018real\u2019\u2019 posts reaching 636\nand \u2018\u2018fake\u2019\u2019 posts 159. Since a greater number of\nwords is likely to translate into a greater number ofcharacters, we should expect the graphs of each\ndistribution (words vs. characters) to re\ufb02ect a similar\nshape. The character count contrasts are shown in\nTable 3, with the corresponding distributions illus-\ntrated in Fig. 13.\nThe \ufb01nal contrast between the \u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019\nFacebook post classes considered the presence of ourTable 3 Word and Character\nStatistics for Twitter and\nFacebook PostsTwitter Facebook\nWords Special characters Words Characters Special Characters\nReal Fake Real Fake Real Fake Real Fake Real Fake\nAverage 23 22 27 26 22 14 142 94 21 20\nMaximum 67 31 38 37 88 70 636 159 31 34Minimum 6 4 16 15 1 1 6 4 2 2\nFig. 10 Distribution of word count by twitter class\nFig. 11 Distribution of special character counts by twitter class\n Fig. 12 Distribution of word counts by class of facebook post15156 Neural Computing and Applications (2022) 34:15141\u201315163\n123\nspecial character set (Table 3). In this case, the\naverage number of occurrences for special characters\nwas similar between the two classes of posts, with\n\u2018\u2018real\u2019\u2019 reaching 21 and \u2018\u2018fake\u2019\u2019 at 20. The minimumand maximum number of occurrences were also very\nclose for each Facebook class, with both showing a\n\u2018\u2018real\u2019\u2019 minimum of 2 special character occurrences.Their values for maximum occurrence of special\ncharacters were 31 for \u2018\u2018real\u2019\u2019 and 34 for \u2018\u2018fake\u2019\u2019\n(Table 3). The distribution of number of special\ncharacters across the two classes of Tweet is shown\nin Fig. 14.\nThese particular \u2018\u2018real\u2019\u2019 and \u2018\u2018fake\u2019\u2019 Facebook\nclasses display notable differences in graph shapes\nfor distribution across our three features (word count,\ncharacter count and special character count). As withour Twitter samples, these complexion analyses shed\nlight on the decisions taken in manual classi\ufb01cation\nand give further indication that decisions on the\u2018\u2018real\u2019\u2019 items correlate closely with the scale of the\ndata items. This may suggest that \u2018\u2018real\u2019\u2019 items are\nmore easily identi\ufb01ed if they are lengthy. This isplausible on the assumption that the human decisionmaker simply had more evidence upon which to\nmake a judgment.\n4.3 Posit findings\n(1) Introduction\nFollowing qualitative analysis on two data subsets\nof social network posts from Facebook and Twitter,we undertook a further series of six classi\ufb01cation\nexperiments on the qualitatively analysed samples.\nAs noted, these comprised 1000 data samples fromeach of Facebook and Twitter and, following their\nqualitative analysis, these were manually classi\ufb01ed\nas \u2018\u2018real\u2019\u2019 or \u2018\u2018fake\u2019\u2019 news. The output from this stagewas a split of approximately half \u2018\u2018real\u2019\u2019 and \u2018\u2018half\u2019\u2019\nfake posts (Table 4).\nArmed with these classi\ufb01ed datasets, we sought to\ndetermine how accurately we might match this with\nautomated classi\ufb01cation based upon Posit and char-\ncount analyses. To this end, we conducted sixexperiments on these \u2018\u2018labelled,\u2019\u2019 i.e. pre-classi\ufb01ed,\nsets of data. The following analyses were performed\nfor each of the Facebook and Twitter datasets: Positfeatures only; charcount features only; Posit and\ncharcount features combined, to produce the exper-\nimental set noted in Table 5, below.\n(2) Applying Posit and charcount to posts from the\nFacebook dataset\n(a) Experiment 1\u2013Posit\nThis experiment applied a Posit analysis to\nthe Facebook manually classi\ufb01ed dataset inorder to generate the \u2018standard\u2019 Posit output of\n27 word-based features for each of the 1000\nFacebook data items. This feature informationwas then re-formatted for direct use with the\nWEKA knowledge acquisition software tool.\nIn turn, WEKA was con\ufb01gured to apply theRandom Forest classi\ufb01cation algorithm and\ndetermine the degree of match with the manual\nclassi\ufb01cation. Table 6details the performance\nresults for this experiment.\nThe performance by class for this result is\ngiven as a confusion matrix in Table 6, which\nshows that a total of 164 posts were classi\ufb01ed\nas \u2018\u2018real\u2019\u2019 when in fact they were \u2018\u2018fake\u2019\u2019, and\nFig. 13 Distribution of character counts by facebook class\nFig. 14 Distribution of special character counts by facebook classTable 4 Manually classi\ufb01ed\nFacebook and Twitter postsReal Fake Total\nFacebook 599 401 1000\nTwitter 540 460 1000Neural Computing and Applications (2022) 34:15141\u201315163 15157\n123\n71 were classi\ufb01ed as \u2018\u2018fake\u2019\u2019 when in fact they\nwere \u2018\u2018real\u2019\u2019.\n(b) Experiment 2\u2013Charcount\nThis experiment applied a charcount anal-\nysis to the Facebook manually classi\ufb01ed\ndataset to generate the output of 44 charac-ter-based features for each of the 1000 Face-\nbook data items. This feature information was\nready for direct use with the WEKA knowl-edge acquisition software tool. In turn, WEKA\nwas con\ufb01gured to apply the Random Forest\nclassi\ufb01cation algorithm and determine thedegree of match with the manual classi\ufb01cation.\nTable 6details the performance results for thisexperiment. The performance by class for this\nresult is given as a confusion matrix inTable 6.\n(c) Experiment 3\u2013Posit and charcount\nThis experiment applied a combined Posit\nanalysis with a charcount analysis to the\nFacebook manually classi\ufb01ed dataset to gen-\nerate the combined output of 71 word andcharacter-based features for each of the 1000\nFacebook data items. This feature information\nwas then re-formatted for direct use with theWEKA knowledge acquisition software tool.\nIn turn, WEKA was con\ufb01gured to apply the\nRandom Forest classi\ufb01cation algorithm anddetermine the degree of match with the manual\nclassi\ufb01cation. Table 6details the performance\nresults for this experiment. The performanceby class for this result is given as a confusion\nmatrix in Table 6.Table 5 Posit and charcount experiment set\nPosit charcount Posit ?charcount\nFacebook Experiment 1 Experiment 2 Experiment 3\nTwitter Experiment 4 Experiment 5 Experiment 6\nTable 6 Classi\ufb01cation Performance\nData\nSourceAnalysis Classi\ufb01cation\nalgorithmCorrectly\nClassi\ufb01ed\nInstances (%)Incorrectly\nClassi\ufb01ed\nInstances (%)Mean\nabsolute\nerrorRoot mean\nSquared\nerrorConfusion Matrix\nFacebook Posit Random\nForest76.50 23.50 0.3351 0.413 a b \\= classi\ufb01ed\nas\n528 71 a = real164 237 b = fake\nFacebook charcount Random\nForest73.50 26.50 0.3570 0.4219 a b \\= classi\ufb01ed\nas\n518 81 a = real184 217 b = fake\nFacebook Posit ?charcount Random\nForest73.50 26.50 0.3570 0.4219 a b \\= classi\ufb01ed\nas\n528 71 a = real172 229 b = fake\nTwitter Posit Random\nForest78.00 22.00 0.3172 0.3921 a b \\= classi\ufb01ed\nas\n439 105 a = real115 341 b = fake\nTwitter charcount Random\nForest74.40 25.60 0.3871 0.4223 a b \\= classi\ufb01ed\nas\n451 92 a = real164 293 b = fake\nTwitter Posit ?charcount Random\nForest81.60 18.40 0.3311 0.3845 a b \\= classi\ufb01ed\nas\n463 81 a = real103 353 b = fake15158 Neural Computing and Applications (2022) 34:15141\u201315163\n123\n(3) Applying Posit and charcount to Twitter dataset\n(a) Experiment 1\u2013Posit\nThis experiment applied a Posit analysis to\nthe Twitter manually classi\ufb01ed dataset to\ngenerate the \u2018standard\u2019 Posit output of 27word-based features for each of the 1000\nTwitter data items. This feature information\nwas then re-formatted for direct use with theWEKA knowledge acquisition software tool.\nIn turn, WEKA was con\ufb01gured to apply the\nRandom Forest classi\ufb01cation algorithm anddetermine the degree of match with the manual\nclassi\ufb01cation. Table 6details the performance\nresults for this experiment. The performanceby class for this result is given as a confusion\nmatrix in Table 6.\n(b) Experiment 2 \u2013 charcount\nThis experiment applied a charcount anal-\nysis to the Twitter manually classi\ufb01ed dataset\nto generate the output of 44 character-basedfeatures for each of the 1000 Twitter data\nitems. This feature information was ready for\ndirect use with the WEKA knowledge acqui-sition software tool. In turn, WEKA was\ncon\ufb01gured to apply the Random Forest clas-\nsi\ufb01cation algorithm and determine the degreeof match with the manual classi\ufb01cation.\nTable 6details the performance results for\nthis experiment. The performance by class forthis result is given as a confusion matrix in\nTable 6.\n(c) Experiment 3 \u2013 Posit and charcount\nThis experiment applied a combined Posit\nanalysis with a charcount analysis to the\nTwitter manually classi\ufb01ed dataset to generatethe combined output of 71 word and character-\nbased features for each of the 1000 Twitter\ndata items. This feature information was thenre-formatted for direct use with the WEKA\nknowledge acquisition software tool. In turn,\nWEKA was con\ufb01gured to apply the RandomForest classi\ufb01cation algorithm and determine\nthe degree of match with the manual classi\ufb01-\ncation. Table 6details the performance results\nfor this experiment. The performance by class\nfor this result is given as a confusion matrix in\nTable 6.\nThe results from this series of experiments\nallowed us to determine that the bestperformance in matching the manually classi-\n\ufb01ed data was for Twitter data using thecombined Posit and charcount features, at\n81.60%. Next best performance was for Twit-\nter data with Posit features only, at 78.00%.This was followed by Facebook data with Posit\nfeatures only, at 76.50% and Twitter data\nusing charcount features only, at 74.40%.Facebook data with combined Posit and using\nonly the charcount features both resulted at an\naccuracy of 73.50%.\n5 Discussion\nThe degree to which the IRA\u2019s disinformation campaignactually altered the outcome of the 2016 U.S. PresidentialElection remains a subject of debate. Uhlmann and\nMcCombie have argued that the IRA\u2019s efforts were poorly\ndisguised, and that the IRA\u2019s cooperation with otherbranches of the Russian government that were similarly\ntasked with meddling in the U.S. election were poorly\ncoordinated and likely not as effective as might be imag-ined [ 84]. Instead, the Russians may have bene\ufb01tted more\nfrom embarrassing the U.S. government by demonstrating\nto the international community the vulnerability of theAmerican system to this sort of attack, and by setting the\nvarious political factions within the US on the warpath in\nthe aftermath of the election. Nor can it be said that the US\nis an innocent victim in the arena of election meddling \u2014\nthey too have engaged for decades in interference in thepolitical affairs of other countries [ 82], e.g. Cuba, Vietnam,\nNicaragua, Grenada, Afghanistan and Iraq, to name but a\nfew.\nAs noted earlier, a 2019 inventory from the Oxford\nInternet Institute found evidence of disinformation cam-\npaigns in 70 different countries around the world, includingArmenia, India, Malaysia, Mexico, The Philippines, Saudi\nArabia, The United Arab Emirates and Venezuela [ 50].\nChinese disinformation has struck against Taiwan andHong Kong, as well as against the USA and Australia\n[55,56]. Iran has employed foreign interference against\nCanada, via disinformation on social media, particularlyTwitter during the 2015 and 2019 Canadian federal elec-\ntions [ 48,56].\nNevertheless, Russia remains the most familiar and\nwidely-studied actor, and its methods are the most well-\nknown. O\u2019Connor et al. found that between 2010 and 2020,\nRussia used online disinformation to interfere with \u2018\u201831Neural Computing and Applications (2022) 34:15141\u201315163 15159\n123\nelections and seven referendums involving 26 states\u2019\u2019\nincluding members of the EU, the USA, nations of Africa\nand South America, as well as Canada [ 58]. Russia, espe-\ncially through the IRA, used social media disinformation totarget both Canadian elections and Canadian society, pro-\nmoting Stephen Harper and denigrating Justin Trudeau,\nwhile \ufb01ercely encouraging right-wing extremism, particu-larly via amplifying and fomenting Islamophobia and anti-\nimmigrant hatred [ 47].\nWith democracy under threat from the intentional (and\nperhaps criminal) manipulation of Cloud-based social\nmedia, and the resultant digital wild\ufb01res [ 85], legislators,\nregulators and service providers are eagerly seeking solu-\ntions and defences against disinformation warfare [ 86]. We\nhave described the brazen attempts by the Russian InternetResearch Agency to manipulate public opinion in the US\nand UK, wherein the use of so-called \u2018\u2018fake news\u2019\u2019 sought\nto in\ufb02uence democratic processes across internationalboundaries. Looking ahead to technological responses, we\nanticipate developing tools that will permit agencies to\n\ufb01lter and identify suspicious social network content.\n6 Conclusion\nWe have customized TDC to monitor selected social mediaand online news sources, we have acquired massive data-sets that are representative of \u2018\u2018fake\u2019\u2019 and \u2018\u2018real\u2019\u2019 news, and\nwe have demonstrated our ever-improving ability to clas-\nsify \u2018\u2018fake\u2019\u2019 and \u2018\u2018real\u2019\u2019 news with a high degree of accu-racy, using machine-learning and a number of\ncomplementary automated text-reading/classi\ufb01cation pro-\ngrams. During this project, we were able to combinemultiple technologies successfully, and apply them to real-\nworld data (Facebook posts and tweets, and news articles),\ndemonstrating our ability to discern measurable differencesbetween \u2018\u2018fake\u2019\u2019 and \u2018\u2018real\u2019\u2019 news.\nDuring the course of our research, we have observed\nthat many social media messages (on some platforms, over50%) are accompanied by images, memes or videos, and\nthat the meme, image or video is the only messaging. Thus,\nwe plan to expand the scope of the social media contentthat our technology can monitor and analyse, by combining\nnatural-language processing (NLP), robust optical charac-\nter recognition (OCR) and Mask R-CNN to extract textualinformation from images, videos and memes. This will\ninclude biometric matching based on facial images, general\nimage matching via computer vision algorithm and basictext-based searching to identify areas of interest.\nWe are also de\ufb01ning and integrating into our technology\nan automated method for the detection of \u2018\u2018bots\u2019\u2019 and \u2018\u2018sockpuppet\u2019\u2019 accounts. As noted earlier, it is estimated that\nsocial media bots comprise between 5 and 9% of theoverall Twitter population and account for approximately\n24% of all tweets [ 43]. To spread dis/misinformation suc-\ncessfully, sock puppet accounts seek to obtain a level of\ntrust and accumulate a history of activity to create theimpression that they are legitimate sources of information.\nOur new approach will determine the trust method imple-\nmented by top social media platforms such as Reddit,Facebook, Twitter and Instagram, and then select a set of\nfeatures/factors and patterns of behaviour that can be col-\nlected and used to accurately assess the legitimacy of social\nmedia accounts.\nWe anticipate that the solutions and models we are\nbuilding (to detect differences between \u2018\u2018fake\u2019\u2019 and \u2018\u2018real\u2019\u2019\nnews) could be expanded upon to create a system that can\nretrieve, analyse, and predict \u2018\u2018fake\u2019\u2019 news on-the-\ufb02y, asdata is coming in. This would bene\ufb01t all countries through\nthe early detection\u2014and possible removal\u2014of fake news\ncontent as it is appearing. Even if removal is not possible,or dif\ufb01cult to achieve in time to mitigate its spread and\nin\ufb02uence, awareness of these campaigns would allow\nworldwide and trusted media sources to react and respondwith messaging that hopefully would be able to counter the\ndisinformation.\nOne need look no further than the disinformation cam-\npaign surrounding Russia\u2019s February 2022 invasion of the\nUkraine to appreciate the relevance of what we are\nattempting to achieve [ 87]. In fact, the Canadian Armed\nForces and the Department of National Defence recently\nrequested and received from us an updated (detailed)\nanalysis of Russian dis/misinformation pertaining to theRussian war against the Ukraine [ 88]. The Canadian\nMinistry of Heritage\u2014knowing of our work on disinfor-\nmation warfare\u2014just approached us about doing researchon their behalf into Russian disinformation on Canadian\nsocial media pertaining to the Russian war against the\nUkraine. The signi\ufb01cance and timeliness of this workcannot be overstated.\nFunding The research leading to these results received funding in part\nby the Canadian government\u2019s Cyber Security Cooperation Programand in part by the Department of National Defence and the Canadian\nArmed Forces through the Canadian government\u2019s IDEaS program.\nDeclarations\nConflict of interest The authors declare that they have no competing\ninterests.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and thesource, provide a link to the Creative Commons licence, and indicate\nif changes were made. The images or other third party material in this15160 Neural Computing and Applications (2022) 34:15141\u201315163\n123\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitteduse, you will need to obtain permission directly from the copyrightholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/ .\nReferences\n1. Cartwright B, Weir GRS, Frank R, Padda K (2019) Deploying\narti\ufb01cial intelligence to combat disinformation warafre: identi-\nfying and interdicting disinformation attacks against cloud-based\nsocial media platforms. Int J Adv Secur 12(3 & 4):203\u2013222\n2. Ebner D, Freeze C (2018) Aggregate IQ, Canadian data \ufb01rm at\ncentre of global controversy, was hired by clients big and small,\u2019\u2019\nGlobe and Mail. https://www.theglobeandmail.com/canada/arti\ncle-aggregateiq-canadian-data-\ufb01rm-at-centre-of-global-controvery-was/ Accessed: 14 July 2021\n3. Rathi R (2019) Effect of Cambridge Analytica\u2019s Facebook ads on\nthe 2016 US Presidential Election. Towards Data Science. https://\ntowardsdatascience.com/effect-of-cambridge-analyticas-facebook-ads-on-the-2016-us-presidential-election-dacb5462155d .\nAccessed 20 July 2019\n4. Russell J (2018) UK watchdog hands Facebook maximum \u00a3500K\n\ufb01ne over Cambridge Analytica data breach. TechCrunch. https://\ntechcrunch.com/2018/10/25/uk-watchdog-hands-facebook-500k-\n\ufb01ne/. Accessed: 18 August 2019\n5. McGill MH, Scola N (2019) FTC approves $5B facebook set-\ntlement that democrats label \u2019chump change. Politco. https://\nwww.politico.com/story/2019/07/12/facebook-ftc-\ufb01ne-5-billion-\n718953 . Accessed 12 Jul 2019\n6. Select Committee on Intelligence, United States Senate (2020)\nRussian active measures, campaigns and interference in the 2016\nU.S. election, Volume 2: counterintellgince threats and vulnera-\nbilities. https://www.intelligence.senate.gov/sites/default/\ufb01les/\ndocuments/report_volume2.pdf . Accessed: 14 July 2021\n7. Of\ufb01ce of the Director of National Intelligence (2017) Assessing\nRussian activities and intentions in recent US elections. www.dni.\ngov/\ufb01les/documents/ICA_2017_01.pdf . Accessed: 28 July 2019\n8. Mueller RS (2019) Report on the investigation into Russian\ninterference in the 2016 presidential election. www.justsecurity.\norg/wp-content/uploads/2019/04/Muelller-Report-Redacted-Vol-II-Released-04.18.2019-Word-Searchable.-Reduced-Size.pdf .\nAccessed: 28 July 2019\n9. Intelligence and Security Committee of Parliament (2020) Russia\nReport. https://isc.independent.gov.uk/wp-content/uploads/2021/\n03/CCS207_CCS0221966010-001_Russia-Report-v02-Web_Accessible.pdf . Accessed: 9 December 2020\n10. Bastos MT, Mercea D (2017) The brexit botnet and user-gener-\nated hyperpartisan news. Soc Sci Comput Rev 37(1):38\u201354.https://doi.org/10.1177/0894439317734157\n11. Field and Wright (2018) Russian trolls sent thousands of pro-\nLeave messages on day of Brexit referendum, Twitter datareveals: Thousands of Twitter posts attempted to in\ufb02uence thereferendum and US elections. The Telegraph .www.telegraph.co.\nuk/technology/2018/10/17/russian-iranian-twitter-trolls-sent-10-\nmillion-tweets-fake-news/ Accessed: 8 April 2019\n12. Evolvi G (2018) Hate in a tweet: exploring internet-based\nislamophobic discourses. Religions 9(10):37\u201351. https://doi.org/\n10.3390/rel9100307\n13. Badawy A, Ferrara E, Lerman K (2018) Analyzing the digital\ntraces of political manipulation: the 2016 russian interference\ntwitter campaign. In: 2018 IEEE/ACM International Conferenceon Advances in Social Networks Analysis and Mining (ASO-\nNAM), 2018, pp. 258-265, doi: https://doi.org/10.1109/ASO\nNAM.2018.8508646\n14. Shao C, Hui PM, Wang L, Jiang X, Flammini A, Menczer F,\nCiampaglia GL (2018) Anatomy of an online misinformation\nnetwork. PloS one. https://doi.org/10.1371/journal.pone.0196087\n15. Kim YM (2020) New evidence shows how russia\u2019s election\ninterference has gotten more brazen: the kremlin-linked operation\nbehind 2016 election meddling is using similar tactics for 2020,\nplus some new ones. Brennan Center for Justice. https://www.\nbrennancenter.org/our-work/analysis-opinion/new-evidence-shows-how-russias-election-interference-has-gotten-more .\nAccessed: 20 March 2022\n16. Luther C, Horen B, Zhang X (2021) Partisanship over security:\nPublic narratives via Twitter on foreign interferences in the 2016and 2020 U.S. presidential elections. First Monday. https://doi.\norg/10.5210/fm.v26i8.11682\n17. National Intelligence Council (2021) Foreign threats to the 2020\nUS federal elections. https://www.dni.gov/\ufb01les/ODNI/docu\nments/assessments/ICA-declass-16MAR21.pdf . Accessed: 20\nMarch 2022\n18. Berghel H (2017) Lies, damn lies, and fake news. Computer\n50(2):80\u201385\n19. Jankowski NW (2018) Researching fake news: a selective\nexamination of empirical studies. Javnost - The Public25(1\u20132):248\u2013255. https://doi.org/10.1080/13183222.2018.\n1418964\n20. Tandoc EC Jr, Lim ZW, Ling R (2018) De\ufb01ning \u2018fake news\u2019: a\ntypology of scholarly de\ufb01nitions. Digital Journal 6(2):137\u2013153.\nhttps://doi.org/10.1080/21670811.2017.1360143\n21. Lazer DM, Baum MA, Benkler Y, Berinsky AJ, Greenhill KM,\nMenczer F, Schudson M (2018) The science of fake news. Sci-ence 359(6380):1094\u20131096. https://doi.org/10.1126/science.\naao2998\n22. de Cock Buning M, Ginsbourg L, Alexandra S (2019) Online\ndisinformation ahead of the European parliament elections:toward societal resilience. European University Institute, Schoolof Transnational Governance https://cadmus.eui.eu/bitstream/\nhandle/1814/62426/STG_PB_2019_03_EN.pdf?sequence=\n1&isAllowed=y Accessed: 15 July 2019\n23. Desai S, Mooney H, Oehrli JA (2018) \u2018\u2018Fake News,\u2018\u2018 lies and\npropaganda: how to sort fact from \ufb01ction. https://guides.lib.\numich.edu/fakenews . Accessed: 15 July 2019\n24. Kshetri N, Voas J (2017) The economics of \u2018\u2018Fake News.\u2019\u2019 IT\nProf 19(6):8\u201312\n25. Kata A (2010) A postmodern pandora\u2019s box: anti-vaccination\nmisinformation on the Internet. Vaccine 28(7):1709\u20131716.https://doi.org/10.1016/j.vaccine.2009.12.022\n26. Bester JC (2016) Measles and measles vaccination: a review.\nJAMA Pediatr 170(12):1209\u20131215. https://doi.org/10.1001/jama\npediatrics.2016.1787\n27. Bennett WL, Livingston S (2018) The disinformation order:\ndisruptive communication and the decline of democratic institu-\ntions. Eur J Commun 33(2):122\u2013139\n28. Vosoughi S, Roy D, Aral S (2018) The spread of true and false\nnews online. Science 359(6390):1146\u20131151. https://doi.org/10.\n1126/science.aap9559\n29. Bennett WL, Livingston S (2018) The disinformation order:\ndisruptive communication and the decline of democratic institu-tions. Eur J Commun 33(2):122\u2013139\n30. United States v. Internet Research Agency LLC, Case 1:18-cr-\n00032-DLF, The United States District Court for the District OfColumbia, February 26, 2018. www.justice.gov/\ufb01le/1035477/\ndownload . Accessed: 8 April 2019\n31. Green JJ (2018) Tale of a troll: Inside the \u2018Internet Research\nAgency\u2019 in Russia. WTOP .https://wtop.com/j-j-green-national/Neural Computing and Applications (2022) 34:15141\u201315163 15161\n123\n2018/09/tale-of-a-troll-inside-the-internet-research-agency-in-rus\nsia/Accessed: 15 July 2019\n32. Reston L (2017) How Russia weaponizes fake news: the krem-\nlin\u2019s in\ufb02uence campaign goes far beyond Trump\u2019s victory. Their\nlatest unsuspecting targets: American conservatives. The New\nRepublic. https://newrepublic.com/article/142344/russia-weapo\nnized-fake-news-sow-chaos . Accessed: 20 July 2019\n33. Wagner K (2018). Facebook and twitter worked just as advertised\nfor Russia\u2019s troll army: social platforms are an effective tool for\nmarketers\u2014and nation states that want to disrupt an election.Recode Daily. https://www.vox.com/2018/2/17/17023292/face\nbook-twitter-russia-donald-trump-us-election-explained . Acces-\nsed 20 July 2019\n34. Marwick A, Lewis R (2017) Media manipulation and disinfor-\nmation online. New York: Data & Society Research Institute.https://datasociety.net/output/media-manipulation-and-disinfo-\nonline/ . Acessed: 29 July 2019\n35. Shu K, Silva A, Wang SH, Tang J, Liu H (2017) Fake news\ndetection on social media: a data mining perspective. ACM\nSIGKDD Explor Newsl 19(1):22\u201336. https://doi.org/10.1145/\n3137597.3137600Accessed:16July2021\n36. Zanettou S, Caul\ufb01ed T, de Cristofaro E, Sirivianos M, Stringhini\nG and Blackburn J (2019) Disinformation warfare: understanding\nstate-sponsored trolls on twitter and their in\ufb02uence on the web.\nIn: WWW \u201919: Companion Proceedings of The 2019 World WideWeb Conference, pp 218\u2013226, https://doi.org/10.1145/3308560.\n3316495 . Accessed15 July 2021\n37. Papenfuss M (2017) 1000 Paid Russian trolls spread fake news on\nhillary clinton, senate intelligence heads told. Huf\ufb01ngton Post.https://www.huf\ufb01ngtonpost.ca/entry/russian-trolls-fake-news_n_\n58dde6bae4b08194e3b8d5c4 . Accessed: 29 July 2019\n38. The Computational Propaganda Project (2016) Resource for\nunderstanding political bots. https://comprop.oii.ox.ac.uk/\nresearch/public-scholarship/resource-for-understanding-political-\nbots/ . Accessed: 29 July 2019\n39. Howard PN, Woolley S, Calo R (2018) Algorithms, bots, and\npolitical communication in the US 2016 election: the challenge ofautomated political communication for election law and admin-\nistration. J Inform Tech Polit 15(2):81\u201393. https://doi.org/10.\n1080/19331681.2018.1448735\n40. Rheault L, Musulan A (2021) Ef\ufb01cient detection of online\ncommunities and social bot activity during electoral campaigns.\nJ Inform Tech Polit 18(3):324\u2013337. https://doi.org/10.1080/\n19331681.2021.1879705\n41. Krieg G (2016) It\u2019s of\ufb01cial: clinton swamps trump in popular\nvote. CNN Politics Data. https://www.cnn.com/2016/12/21/poli\ntics/donald-trump-hillary-clinton-popular-vote-\ufb01nal-count/index.html. Accessed: 15 July 2021\n42. Stark Luke (2018) Algorithmic psychometrics and the scalable\nsubject. Soc Stud Sci 48(2):204\u2013231. https://doi.org/10.1177/\n0306312718772094\n43. Morstatter F, Wu L, Nazer,TH, Carley KN, Liu H (2016) A new\napproach to bot detection: Striking the balance between precision\nand recall. In: IEEE/ACM Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM), pp 533\u2013540. https://\nieeexplore-ieee-org.proxy.lib.sfu.ca/document/7752287 3\nAugust, 2019\n44. Shearar E, Mitchell A (2021) News use across social media\nplatforms in 2020: facebook stands out as a regular source ofnews for about a third of Americans. Pew Research Center.\nhttps://www.journalism.org/2021/01/12/news-use-across-social-\nmedia-platforms-in-2020/ . Accessed: 15 July 2021\n45. Allcott H, Gentzkow M (2017) Social media and fake news in the\n2016 election. J Econ Perspect 31(2):211\u2013236. https://doi.org/10.\n1257/jep.31.2.211TopofForm46. Chang HC, Chen E, Zhang M, Muric G, Ferrara E (2021) Social\nbots and social media manipulation in 2020: the year in review.\narXiv preprint arXiv:2102.08436 . 2021 Feb 16. Accessed: 15 July\n2021\n47. Al-Rawi A (2021) How did Russian and Iranian trolls\u2019 disinfor-\nmation toward Canadian issues diverge and converge? DigitalWar 2:21\u201334. https://doi.org/10.1057/s42984-020-00029-4\n48. Louden R, Frank R (2021) Information Trolls vs Democracy: An\nexamination of isinformation content delivered during the 2019\nCanadian Federal Election. CrimRxiv .https://doi.org/10.21428/\ncb6ab371.e1ca98a9 . Accessed: 15 July 2021\n49. DiResta R, Grossman S (2021) Fronts & freinds: an investigation\ninto two twitter networks linked to Russian actors. Cyber Policy\nCnter, Stanford Interney Observatory. https://cyber.fsi.stanford.\nedu/io/publication/fronts-friends-investigation-two-twitter-net\nworks-linked-russian-actors-takedown . Accessed: 15 July 2021\n50. Bradshaw S, Howard PN (2019) The global disinformation order:\n2019 global inventory of organized social media manipulation.https://comprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2019/\n09/CyberTroop-Report19.pdf . Accessed: 16 November 2019\n51. Linvill DL, Warren PL (2018) Troll factories: the internet\nresearch agency and state-sponsored agenda-building. ResourceCentre on Media. https://www.google.com/search?q=Troll ?fac\ntories%3A ?The?Internet ?Research ?Agency ?and?state-spon\nsored ?agenda-building&oq=Troll ?factories%3A ?The?Interne\nt?Research ?Agency ?and?state-sponsored ?agenda-buildin\ng&aqs=chrome..69i57j69i60l3.354j0j7&sourceid=chrome&ie=\nUTF-8 . Accessed: 21 July 2019\n52. Smolen \u02c7ova\u00b4I (2015) The pro-Russian disinformation campaign in\nthe Czech Republic and Slovakia. Prague: Prague Security\nStudies Institute. http://www.pssi.cz/download/docs/253_is-pro-\nrussian-campaign.pdf . Accessed: 21 July 2019\n53. Mejias A, Vokuev NE (2017) Disinformation and the media: the\ncase of Russia and Ukraine. Media, Cult Soc 39(7):1027\u20131042\n54. Curtis JS (2021) Springing the \u2018Tacitus Trap\u2019: countering Chi-\nnese state-sponsored disinformation. Small Wars Insurg32(2):229\u2013265. https://doi.org/10.1080/09592318.2021.1870429\n55. Heer T, Heath C, Girling K, Bugg E (2021) Misinformation in\nCanada: research and policy options. Evidence for Democracy.\nhttps://evidencefordemocracy.ca/en/research/reports/misinformation-canada-research-and-policy-options . Accessed: 23 July\n2021.\n56. Rocha R, Yates J (2019) Twitter trolls stoked debates about\nimmigrants and pipelines in Canada, data show | CBC News.https://www.cbc.ca/news/canada/twitter-troll-pipeline-immi\ngrant-russia-iran-1.5014750 . Accessed: 23 July 2021.\n57. Beskow DM, Carley KM (2020) Characterization and compar-\nison of Russian and Chinese disinformation campaigns. In: ShuK, Wang S, Lee D, Liu H (eds) Disinformation, misinformation,\nand fake news in social media: emerging research challenges and\nopportunities. Springer, pp 63\u201381\n58. O\u2019Connor S, Hanson F, Currey E, Beattie T (2020) Cyber-en-\nabled foreign interference in elections and referendums. Aus-\ntralian Strategic Policy Institue: International Cyber Policy\nCentre. https://www.aspi.org.au/report/cyber-enabled-foreign-\ninterference-elections-and-referendums . Accessed: 23 July 2021\n59. Wang WY (2018) \u2018Liar, Liar Pants on Fire\u2019: A New Benchmark\nDataset for Fake News Detection. arXiv preprint arXiv:1705.\n00648 .https://arxiv.org/abs/1705.00648 . Accessed:15 July 2019\n60. Yu HF, Ho CH, Juan YC and Lin CJ (2013) LibShortText: a\nlibrary for short-text classi\ufb01cation and analysis. Department of\nComputer Science, National Taiwan University. https://www.\ncsie.ntu.edu.tw/ *cjlin/papers/libshorttext.pdf . Accessed: 4\nAugust 2019\n61. Abadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, Devin M,\nGhemawat S, Irving G, Isard M, Kudlur M (2016) {TensorFlow}:15162 Neural Computing and Applications (2022) 34:15141\u201315163\n123\nA System for {Large-Scale} Machine Learning. In: 12th USE-\nNIX symposium on operating systems design and implementation\n(OSDI 16) pp 265\u2013283 https://www.usenix.org/conference/\nosdi16/technical-sessions/presentation/abadi , Accessed: March\n18, 2022\n62. Fan RE, Chang KW, Hsieh CJ, Wang XR, Lin CJ (2008) LIB-\nLINEAR: a library for large linear classi\ufb01cation. J Mach LearnRes 9:1871\u20131874\n63. Weir GRS (2009) Corpus pro\ufb01ling with the Posit tools. In: Pro-\nceedings of the 5th Corpus Linguistics Conference. http://cite\nseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.9606&rep=rep1&type=pdf . Accessed:4 August 2019\n64. Breiman L (2001) Random forests. Mach Learn 45:5\u201332\n65. Falk C (2018) Detecting twitter trolls using natural language\nprocessing techniques trained on message bodies. http://www.\nin\ufb01nite-machines.com/detecting-twitter-trolls.pdf . Accessed: 15\nJuly 2019\n66. Zellers R, Holtzman A, Rashkin H, Bisk Y, Farhadi A, Roesner F\nand Choi Y (2019) Defending against neural fake news. Adv\nNeural Inf Process Syst 32 (NeurIPS 2019)\n67. Vargas L, Emami P, Traynor P (2020) On the detection of dis-\ninformation campaign activity with network analysis. In:CCSW\u201920: Proceedings of the 2020 ACM SIGSAC Conference\non Cloud Computing Security Workshop, pp 133\u2013146 https://doi.\norg/10.1145/3411495.3421363\n68. Dubois E, McKelvey F (2019) Political bots: disrupting canada\u2019s\ndemocracy. Can J Commun 44(2):27\u201333\n69. Barojan D (2021) Building digital resilience ahead of elections\nand beyond. In: Jayakumar S, Ang B, Anwar ND (eds) Disin-formation and fake news. Springer, Singapore, pp 61\u201373\n70. Zulkarnine AT, Frank R, Monk B, Mitchell J and Davies G\n(2016) Surfacing collaborated networks in dark web to \ufb01nd illicitand criminal content. In: 2016 IEEE Conference on Intelligenceand Security Informatics (ISI) September 2016, pg 109\u2013114\nhttps://doi.org/10.1109/ISI.2016.7745452 Accessed: 4 August\n2019\n71. Hockenmaier J, Bierner G, Baldridge J (2004) Extending the\ncoverage of a CCG system. Res Lang Comput 2:165\u2013208\n72. Liaw A, Wiener M (2002) Classi\ufb01cation and regression by ran-\ndomForest. R News 2:18\u201322\n73. Albright J (2017) Itemized posts and historical engagement - 6\nnow-closed FB pages [data visualization]. In Tableau Public.\nhttps://public.tableau.com/pro\ufb01le/d1gi#!/vizhome/FB4/Total\nReachbyPage . Accessed: 1 August, 2021\n74. Hall M, Frank E, Geoffrey H, Pfahringer B, Reutemann P, Witten\nI (2009) The Weka data mining software: an update. SIGKDD\nExplor 11:10\u201318. https://doi.org/10.1145/1656274.1656278\n75. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B,\nGrisel O, Duchesnay E (2011) Scikit-learn: machine learning in\npython. J Mach Learn Res 12:2825\u20132830\n76. Thomas J (1996) Introduction: a debate about the ethics of fair\npractices for collecting social science data in cyberspace. Inf Soc12(2):107\u2013118. https://doi.org/10.1080/71385613777. Comstock G (2012) Research ethics: a philosophical guide to the\nresponsible conduct of research. Cambridge University Press,\nCambridge\n78. Mann C, Stewart F (2000) Internet communication and qualita-\ntive research: a handbook for researching online. Sage Publica-\ntions, London; Thousand Oaks, Calif\n79. Sharkey S, Jones RA, Smithson J, Hewis E, Emmens T, Ford T,\nOwens C (2011) Ethical practice in internet research involving\nvulnerable people: lessons from a self-harm discussion forum\nstudy (SharpTalk). J Med Ethics 37(12):752\u2013758. https://doi.org/\n10.1136/medethics-2011-100080\n80. Kitchin HA (2002) The Tri-Council on cyberspace: Insights,\noversights, and extrapolations. In: Van den Hoonaard WC (ed)\nWalking the tightrope: ethical issues for qualitative researchers.University of Toronto Press, Toronto, pp 160\u2013173\n81. Moreno MA, Fost NC, Christakis DA (2008) Research ethics in\nthe MySpace era. Pediatrics 121(1):157\u2013160\n82. Uhlmann AJ, McCombie S (2020) The russian gambit and the US\nintelligence community: Russia\u2019s use of Kompromat and\nimplausible deniability to optimize its 2016 information cam-\npaign against the US presidential election. Libr Trends68(4):679\u2013696. https://doi.org/10.1353/lib.2020.0017\n83. McCombie S, Uhlmann AJ, Morrison S (2020) The US 2016\npresidential election & Russia\u2019s troll farms. Intell Nat Sec\n35(1):95\u2013114. https://doi.org/10.1080/02684527.2019.1673940\n84. Lapowsky I (2018) Shadow politics: Meet the digital sleuth\nexposing fake news. Wired. https://www.wired.com/story/sha\ndow-politics-meet-the-digital-sleuth-exposing-fake-news/ .\nAccessed: 1 August 2021\n85. Narayanan V, Howard PN, Kollanyi B and Elswah M (2017)\nRussian involvement and junk news during Brexit. URL: com-\nprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2017/12/Russia-and-Brexit-v27. pdf.\n86. European Commission (2019) A Europe that protects: EU reports\non progress in \ufb01ghting disinformation ahead of European Coun-\ncil. https://ec.europa.eu/commission/commissioners/2014-2019/\nansip/announcements/europe-protects-eu-reports-progress-\ufb01ghting-disinformation-ahead-european-council_en . Accessed: 15\nJune 2019\n87. Khaldarova I, Pantti M (2016) Fake news: the narrative battle\nover the Ukrainian con\ufb02ict. J Pract 10(7):891\u2013901. https://doi.\norg/10.1080/17512786.2016.1163237\n88. Tuttle D (2019) Campaigns of disinformation: modern warfare,\nelectoral interference, and canada\u2019s security environment. SSRNElectron J. https://doi.org/10.2139/ssrn.3437117\nPublisher\u2019s Note Springer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional af\ufb01liations.Neural Computing and Applications (2022) 34:15141\u201315163 15163\n123", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Detecting and responding to hostile disinformation activities on social media using machine learning and deep neural networks", "author": ["B Cartwright", "R Frank", "G Weir", "K Padda"], "pub_year": "2022", "venue": "Neural Computing and \u2026", "abstract": "Disinformation attacks that make use of social media platforms, eg, the attacks orchestrated  by the Russian \u201cInternet Research Agency\u201d during the 2016 US Presidential election"}, "filled": false, "gsrank": 171, "pub_url": "https://link.springer.com/article/10.1007/s00521-022-07296-0", "author_id": ["", "1PeY2UUAAAAJ", "SBDcS-sAAAAJ", "c1EEwQQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:W3nYbHm3AKIJ:scholar.google.com/&output=cite&scirp=170&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=W3nYbHm3AKIJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 25, "citedby_url": "/scholar?cites=11673531966289377627&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:W3nYbHm3AKIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1007/s00521-022-07296-0.pdf"}}, {"title": "Quotatives indicate decline in objectivity in us political news", "year": "2023", "pdf_data": "Quotatives Indicate Decline in Objectivity in U.S. Political News\nTiancheng Hu1, Manoel Horta Ribeiro2, Robert West2, Andreas Spitz3\n1ETH Z \u00a8urich, Z \u00a8urich, Switzerland\n2EPFL, Lausanne, Switzerland\n3University of Konstanz, Konstanz, Germany\ntiancheng.hu@alumni.ethz.ch, manoel.hortaribeiro@epfl.ch, robert.west@epfl.ch, andreas.spitz@uni-konstanz.de\nAbstract\nAccording to journalistic standards, direct quotes should be at-\ntributed to sources with objective quotatives such as \u201csaid\u201d and\n\u201ctold,\u201d since nonobjective quotatives, e.g., \u201cargued\u201d and \u201cin-\nsisted,\u201d would influence the readers\u2019 perception of the quote and\nthe quoted person. In this paper, we analyze the adherence to\nthis journalistic norm to study trends in objectivity in political\nnews across U.S. outlets of different ideological leanings. We\nask: 1) How has the usage of nonobjective quotatives evolved?\n2) How do news outlets use nonobjective quotatives when cov-\nering politicians of different parties? To answer these questions,\nwe developed a dependency-parsing-based method to extract\nquotatives and applied it to Quotebank, a web-scale corpus of\nattributed quotes, obtaining nearly 7 million quotes, each en-\nriched with the quoted speaker\u2019s political party and the ideolog-\nical leaning of the outlet that published the quote. We find that,\nwhile partisan outlets are the ones that most often use nonob-\njective quotatives, between 2013 and 2020, the outlets that in-\ncreased their usage of nonobjective quotatives the most were\n\u201cmoderate\u201d centrist news outlets (around 0.6 percentage points,\nor 20% in relative percentage over seven years). Further, we find\nthat outlets use nonobjective quotatives more often when quot-\ning politicians of the opposing ideology (e.g., left-leaning out-\nlets quoting Republicans) and that this \u201cquotative bias\u201d is rising\nat a swift pace, increasing up to 0.5 percentage points, or 25% in\nrelative percentage, per year. These findings suggest an overall\ndecline in journalistic objectivity in U.S. political news.\n1 Introduction\nJournalistic objectivity is the notion that news should con-\ntain accurate information and not convey the personal opin-\nions or emotions of the writer (Ryan 2001; Calcutt and Ham-\nmond 2011). Historically, objectivity emerged alongside the\nconception of journalism as a profession (Schudson 1981)\nand has shaped many of the practices and norms in mod-\nern journalism (Boudana 2011). In the context of U.S. pol-\nitics, with its two major political parties, this can also be\ninterpreted as \u201cequal treatment\u201d of both parties (D\u2019Alessio\nand Allen 2006). Bias in the news could affect public opin-\nion (O\u2019Connell 1999; Kahn and Kenney 2002) and lead to\nchanges in voting behavior (DellaVigna and Kaplan 2007;\nBernhardt, Krasa, and Polborn 2008).\nCopyright \u00a9 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\u201cAbsolute\u201d objectivity has been criticized as unattainable,\nas structural biases would creep into news production (Be-\nharrell et al. 2009), or even as harmful, as the excessive\nbalance of viewpoints could create an illusion of credibil-\nity for dubious or unsupported positions (Dixon and Clarke\n2013). However, amidst the fragmented media ecosystem\nthat emerged from the digitization of news outlets and\nthe algorithmic serving of content (Thurman, Lewis, and\nKunert 2019), journalism scholars have argued that objectiv-\nity has become ever more important to consumers of journal-\nism (Boudana 2011; McNair 2017). This opinion is also held\nby the public worldwide, who, as of 2018, overwhelmingly\nagree that news media should be unbiased in its coverage of\npolitics (Mitchell et al. 2018).\nOne of the concrete ways in which journalists have sought\nto report the news objectively is through the usage of di-\nrect quotes (Brooks et al. 2007; Stenvall 2008). Since jour-\nnalists almost never directly observe the events they report,\nusing quotes lends them more reliability and factuality than\ntheir own words (Van Dijk 1988). Furthermore, direct quotes\nwould let people \u201cspeak for themselves,\u201d following one of\nthe golden rules of journalism (Ingram and Henshall 2012).\nHowever, even when using a direct quote, journalistic objec-\ntivity can still be compromised by the use of certain quota-\ntives that relay the emotions of reporters to readers (Mencher\nand Shilton 1997) or the attempt to describe the speaker\u2019s\nstate of mind (Gidengil and Everitt 2003). For example, in\nthe direct quote\n\u201cNew York is not afraid of terrorists, \u201d boasted Rep. Jerrold\nNadler , a Democrat representing Manhattan,\nthe quotative (boasted) carries an illocutionary force from\nthe reporter that influences how the reader perceives the\nquote itself, possibly distorting its original meaning (Caldas-\nCoulthard 1992). Objective quotatives, like \u201csay\u201d or \u201ctell,\u201d\non the other hand, are considered neutral, as they imply lit-\ntle about the presumed intent or the fashion in which the\nquote was uttered (Sonoda 1997; Bell 1991).\nRecent years were marked by increased political polar-\nization (Abramowitz and Saunders 2008), mistrust in me-\ndia (Brenan 2022), increased negative tone by politicians\n(K\u00a8ulz et al. 2022), and the perception that the public de-\nbate around politics has become less respectful and less fact-\nbased (Doherty et al. 2019). Solutions to these issues are\ncomplex, but analyzing the bias and the departure from jour-\nnalistic objectivity in political news coverage can help in-\nProceedings of the Seventeenth International AAAI Conference on Web and Social Media (ICWSM 2023)\n363\nform new practices and interventions that seek to improve\nthe political news media ecosystem. Quotatives, in this con-\ntext, are a powerful instrument to measure bias. Studying\nhow journalists deviate from the standard usage of quota-\ntives \u2013 e.g., \u201csay\u201d and \u201ctell\u201d (The Associated Press 2020) \u2013\nallows researchers to quantitatively assess adherence to jour-\nnalistic objectivity (Lee 2017) and reveal biases in journal-\nistic coverage of politics (Gidengil and Everitt 2003).\nPresent work. This paper analyzes quotatives to study ob-\njectivity and media bias in political journalism. We ask:\n\u2022RQ1 How has the usage of nonobjective quotatives\nevolved in U.S. political journalism?\n\u2022RQ2 How do news outlets use nonobjective quotatives\nwhen covering politicians of different parties?\nTo answer these research questions, we developed a method-\nology to extract quotatives from a large-scale news corpus.\nWe then performed a comprehensive study on how (and\nwhich) quotatives are used in direct quotes from U.S. politi-\ncians between 2013 and 2020, leveraging a large dataset of\nquotes from English-language media linked with relevant\nspeaker metadata (Vaucher et al. 2021) and enriched with\nthe political leanings of different U.S. outlets. By counting\nthe usage of nonobjective quotatives like \u201cshout\u201d or \u201cassert,\u201d\nwe analyze how U.S. news outlets of different political incli-\nnations adhere to basic journalistic objectivity principles and\nhow this adherence has evolved. Further, analyzing how out-\nlets of different political inclinations use quotatives to talk\nabout politicians of different parties, we study the evolution\nof quotative bias in news outlets.\nSummary of findings. We find that the usage of nonob-\njective quotatives varies across different outlet categories.\nOverall, the more ideologically extreme an outlet is, the\nmore nonobjective quotatives it uses. However, we also find\nthat centrist outlets are experiencing a significant increase\nin the usage of nonobjective quotatives over the last years\n(about 0.6 percentage points, or 20% in relative percentage),\nsuggesting that they may be \u201ccatching up\u201d to the more bi-\nased outlets, which are not experiencing such significant in-\ncreases (RQ1). We also find evidence of \u201cquotative bias,\u201d\ni.e., outlets tend to use nonobjective quotatives, especially\nwhen referring to politicians of opposing ideology. For in-\nstance, left and right-leaning outlets use nonobjective quota-\ntives up to 2% more often when referring to Republican and\nDemocrat politicians, respectively (RQ2). Last, we find that\nthis quotative bias is increasing at a swift pace, increasing as\nmuch as 0.5 percentage points per year in absolute percent-\nage, or 25% in relative percentage, for left-leaning outlets,\nsuggesting a rapid increase in polarization (RQ1 andRQ2).\nImplications. Our findings indicate a decline in journalis-\ntic objectivity in U.S. political news, particularly from cen-\ntrist outlets. This suggests that centrist outlets may play a\nrole in the increasingly less respectful and fact-based debate\naround politics (Doherty et al. 2019). Further, we also find\nevidence of an increasing quotative bias, which could further\nerode trust in the media (Brenan 2022).2 Background and Related Work\nWhen a quote occurs in the news, three elements are typi-\ncally involved: the source, i.e., the speaker who uttered the\nquote (underlined in the examples); the quoted content itself\n(initalic); and the quotative that introduces the quote (also\nknown as a cue, reporting verb, speech verb, or attribution\nverb; in bold). Quotes can be classified as either direct, in-\ndirect, mixed, or pure (Cappelen and Lepore 1997), where\nonly the former three types are typically of concern to jour-\nnalists. We give an example of a direct quote in the introduc-\ntion and of mixed and indirect quotes below.\nIndirect quote: Sen. Ron Wyden of Oregon, the chairman of\nthe Senate Finance Committee, indicated thatin 2019, about\n100 to 125 corporations reported financial statement income\ngreater than 1B USD.\nMixed quote: Catsimatidis said he\u2019d serve for 99 cents \u201cbe-\ncause I\u2019m a grocer. \u201d\nIn direct and mixed quotes, a pair of quotation marks\nare used, and we can infer that the speaker uttered the\nquoted words, whereas indirect quotes may paraphrase the\nspeaker\u2019s words. Therefore, journalists have the most free-\ndom in word choice in indirect quotes, as they can, to some\nextent, rewrite what the speaker said. In contrast, in direct\nquotes, journalistic norms require them to report the quoted\nwords verbatim (Harry 2014).\nIn our work, we focus on direct quotes for the fol-\nlowing reasons: Quotebank does not contain indirect\nquotes (Vaucher et al. 2021); automatically extracting the\nquotative in mixed quotes is technically challenging and,\nin some instances, impossible as there is no quotative, e.g.,\nJohn will not help as he has \u201cdone more for this house than\nall of us combined\u201d.\nMeasuring media bias. Previous work has studied me-\ndia biases: how journalists\u2019 and editors\u2019 personal opinions,\nbeliefs, and financial incentives shape what is considered\nnewsworthy (McCombs and Shaw 1972) and how issues are\ncovered (Iyengar 1994). Scholars argue that partisan media\nbias can harm democracy by distorting citizens\u2019 political\nknowledge and increasing polarization (Bernhardt, Krasa,\nand Polborn 2008; Boudana 2011; McNair 2017). Thus,\nmeasuring media bias is the first step to improving our in-\nformation ecosystem (Watts, Rothschild, and Mobius 2021).\nEarly studies in media bias required extensive manual an-\nnotation. For instance, Kobre (1953) studied how the press\nin Florida covered the U.S. 1952 presidential campaign by\ncoding the number of inches of text given to each party,\nthe position of pictures, etc., across hundreds of newspa-\npers. However, in recent times and with the digitization of\nnews, various methods have been developed to automat-\nically measure media bias (Hamborg, Donnay, and Gipp\n2019). Some of these methods are audience based, mea-\nsuring how segregated news consumers are across outlets,\ne.g., Zhou, Resnick, and Mei (2011) use votes on Digg, a\nsocial news aggregator, to classify political articles. Others\narecontent based, quantifying media bias by analyzing pub-\nlished content directly. For instance, Gentzkow and Shapiro\n(2010) measured bias using the frequency at which outlets\nreproduce partisan phrases in congressional speeches.\n364\nAccording to Budak, Goel, and Rao (2016), both content\nand audience-based approaches suffer from distinctive limi-\ntations. On the one hand, audience-based approaches do not\nscale beyond outlets for which detailed readership informa-\ntion can be obtained. On the other hand, content-based ap-\nproaches struggle to generalize well across different types of\nnews and outlets, e.g., methods that try to match politicians\u2019\nspeeches to news only apply to a minority of news articles,\nlimiting the scope of the results obtained.\nQuotatives and bias. Quotatives can impact how readers\nperceive a news story and the involved speakers (Geis 1987;\nJust, Crigler, and Buhr 1999). For instance, Cole and Shaw\n(1974) carried out an experiment in which they changed \u201cob-\njective\u201d quotatives like \u201csaid\u201d for stronger verbs like \u201car-\ngued\u201d or \u201cinsisted\u201d and asked participants to rate stories\nacross a variety of criteria. They found that in the modi-\nfied versions, stories were perceived as more exciting and\nless objective, and speakers were perceived as more rash.\nThrough quotatives, journalists can \u201cpaint reports on speech\nwith any brush they like\u201d (Geis 1987), which would not only\nreveal the beliefs and preferences of the writer (Gidengil and\nEveritt 2003) but also subtly influence the reader (Cole and\nShaw 1974). In this context, quotatives have been used to\nmeasure political bias, sometimes referred to as \u201cattribu-\ntion bias.\u201d This line of work dates from the 1960s when\nMerrill (1965) studied how Time magazine used quota-\ntives (among other things) when referring to U.S. Presi-\ndents Kennedy, Truman, and Eisenhower. More recently, Gi-\ndengil and Everitt (2003) analyzed differences in quotative\nusage between male and female party leaders on Canadian\ntelevision, finding that female leaders\u2019 speech was reported\nwith more negative and aggressive quotatives. With a similar\nmethodology, Lee (2017) studied differences in nonobjec-\ntive quotatives between offline and online newspapers, find-\ning the former to adhere better to journalistic standards.\nQuote attribution and analysis. Previous work in natural\nlanguage processing has studied the problem of quote attri-\nbution (see Vaucher et al. (2021) for a review), an important\ntask in understanding dialogue structure and developing bet-\nter conversational agents. For each quote, the goal is to ex-\ntract the speaker of the quote, either at the mention or entity\nlevel. This task is challenging as the speaker could be men-\ntioned implicitly or require anaphora resolution. The task\ncan be further combined with entity linking to extract unique\nIDs of speakers ( \u02c7Culjak et al. 2022). Most prior work, how-\never, has not dealt with the problem of quotative extraction.\nNonetheless, several datasets annotated for attributional\nrelationship exist (Pareti 2012, 2016; Newell, Margolin, and\nRuths 2018) that could be considered in this context. These\ndatasets contain labels for the content, source, and cue for\neach attributional relationship. They can be viewed as an ex-\ntension of The Penn Discourse TreeBank 2.0 (Prasad et al.\n2008) that provides annotation of discourse relations and ar-\ngument structures. While these datasets can potentially be\nused as resources for training a supervised model for quota-\ntive extraction, the attributional relationship they considered\nis much broader than quotation and thus not suitable for our\nstudy.Existing work has also analyzed quotes from different\nperspectives. Niculae et al. (2015) found a systematic pat-\ntern in the outlets\u2019 quoting behavior when covering the exact\nsame event. Lazaridou, Krestel, and Naumann (2017) found\nthat a machine learning classifier could reliably predict one\nof two news outlets based solely on the quotes they re-\nport, demonstrating media bias. Tan, Peng, and Smith (2018)\nshowed a declining trend of bipartisan quote coverage with\na bipartite graph of media outlets and the sentences they\nquoted. K \u00a8ulz et al. (2022) analyzed the quotes of U.S politi-\ncians between 2008 and 2020 and found a decrease in nega-\ntivity during Obama\u2019s tenure and a sudden increase starting\nfrom Trump\u2019s presidential primary campaign in 2015.\nRelationship with prior work. In this paper, we set out to\ninvestigate how the usage of nonobjective quotatives evolved\nin U.S. political journalism (RQ1) and how it is modu-\nlated by media biases (RQ2). We do so by using depen-\ndency parsing to extract quotatives from a large dataset (see\nSec. 3). Our method is related to quote attribution, a prob-\nlem widely studied in natural language processing, with the\nkey difference that previous methods aim to attribute quotes\nto speakers instead of finding the quotative used. Further,\nour approach is similar to previous work that derives au-\ntomated media bias measurements (Budak, Goel, and Rao\n2016). However, in contrast to previous work, we automate\nthe measurement of quotative bias instead of relying on tra-\nditional manual annotation (Cole and Shaw 1974). Due to\nthe scalability of our approach, we obtain results that help\nfurther understand the political news ecosystem (see Sec. 5).\nNamely, while previous work often attributes the decrease in\njournalistic objectivity to the rise of partisan media (McNair\n2017), we find that centrist outlets in our dataset have sys-\ntematically departed from journalistic standards.\n3 Materials and Methods\n3.1 Data and Data Processing\nTo study quotative usage across various news outlets, we\nuse the Quotebank dataset (Vaucher et al. 2021), a web-\nscale corpus of quotes. Quotebank contains over 235 million\nunique quotes, extracted from 196 million English news ar-\nticles from 377 thousand web domains between September\n2008 and April 2020. We additionally obtain a list of cur-\nrent and former U.S. politicians with their party affiliations\nfrom Wikidata, in the same fashion as K \u00a8ulz et al. (2022).\nWe filter Quotebank to consider the period containing the\nbest-quality speaker attributions (May 2013 to 2020) and re-\ntain only quotes from politicians on this list. In cases where\nquotes are attributed to more than one speaker in Quote-\nbank (which happens to 8.13% of speakers in 12.25% of the\nquotes), we heuristically attribute the quote to the speaker\nwith the alphanumerically smallest Wikidata identifier. We\nvalidate speaker attribution in our filtered dataset on a manu-\nally annotated sample of 100 quotes and find that combining\nthe speaker names provided by Quotebank with this heuris-\ntic yields 86% accuracy in identifying the correct ID.\nTo ensure the validity of our findings, we preprocess\nQuotebank as depicted in Figure 1. We 1) use heuristics to\nretain only direct quotes; 2) extract quotatives and remove\n365\n14.6M quotes\n(76.2%)19.2M quotes\nby U.S. politicians\n14.4M quotes\n(75.4%)\n7.3M quotes\n(38.0%)\n6.7M quotes\n(35.1%)Quotebank@!#?@!\n1: Removing titles and mixed quotes\n2: Extracting quotatives and removing non-verb quotatives\n3: Removing unsuitable news outlets\n4: Creating & applying dictionaries of common quotativesSelecting quotes attributed to U.S. politiciansFigure 1: Data processing pipeline. We outline the key steps\nin our data processing pipeline and the percentage of re-\ntained data after filtering.\nquotes without quotatives in the verb form; 3) filter quotes,\nkeeping only those from U.S-based outlets with human-\nverified bias ratings; and 4) create dictionaries of common\nquotatives, removing quotes with rare quotative verbs for\nwhich quotative extraction performs poorly. We detail each\nof these steps in the following paragraphs.\nStep 1: removing titles and mixed quotes. To remove titles\nfrom the dataset that are erroneously recognized as quotes\n(e.g., movies), we apply a filter using the percentage of\nwords in a quote whose first letter is capitalized. Afterward,\nto remove mixed quotes, we employ a sentence recognition\nfilter that combines constituency parsing1and dependency\nparsing2. We retain only quotes that can be parsed as a full\nsentence at the root level by constituency parsing and con-\ntain a subject and a predicate (root) in dependency parsing.\nThese heuristics improve data quality (e.g., extracted quo-\ntatives in Step 2 are much more accurate) while retaining\n76.2% of the dataset.\nStep 2: extracting quotatives and removing non-verb\nquotatives. In the next step, we adopt a three-stage approach\nto extract the quotative from each quote using dependency\nparsing. First, we run dependency parsing and acquire a dis-\ntribution of quotatives from the root node of each parsed\nquote. Second, we add a condition to ensure that in cases\nwhere one verb is identified as the root and another verb ex-\nists in a parallel node3, we choose the verb with the higher\n1Constituency parsing breaks down sentences into phrases and\nidentifies their grammatical roles, e.g., in \u201cI eat a big apple,\u201d \u201ca big\napple\u201d is a noun phrase. See Jurafsky and Martin (2022) for details.\n2Dependency parsing extracts dependency relationships be-\ntween words, with verbs typically being in the structural center,\ne.g., in \u201cI eat a big apple,\u201d \u201cbig\u201d is an adjectival modifier of \u201cap-\nple.\u201d See K \u00a8ubler, McDonald, and Nivre (2009) for details.\n3csubj, ccomp, xcomp, advcl, acl, parataxis, conj,probability as the quotative (according to the distribution of\nverbs extracted in the first stage). Finally, we take the lemma\nof each extracted quotative and remove quotatives that are\nnot in verb form. After this step, we retain around 75.4% of\nthe original data.\nStep 3: removing unsuitable outlets. We obtain a list\nof media bias ratings from mediabiasfactcheck.com (here-\ninafter MB/FC) and classify outlets into five categories\nbased on the bias rating: left, left-center, least-biased, right-\ncenter, and right. We refer to left-center, least-biased, and\nright-center outlets as centrist outlets in the following. We\nremove quotes from outlets without a bias rating, from out-\nlets that are not from the U.S. (also according to MB/FC\ndata), and from outlets that have very few quotes (which\nmay suggest data quality issues), only keeping outlets with\nmore than 20 quotes over a period of 12 months. After this\nstep, around 38.0% of the original data remains, all from rel-\nevant U.S. media outlets with human-verified bias ratings.\nManual inspection of the removed data confirms that the re-\nmoved outlets are predominantly non-news websites, small\nlocal newspapers, radio stations, and non-U.S news outlets.\nStep 4: creating dictionaries of common quotatives. In-\nspired by Lee (2017) as well as the recommendations laid\nout in Reuters (2008) and The Associated Press (2020),\nwe define quotatives as objective if they refer to the direct\nspeech action and do not involve any subjective judgment of\nthe action (e.g., like \u201csay\u201d and \u201ctell\u201d); and as nonobjective if\nthey refer to some additional action or conduct and with sub-\njective judgments (such as \u201cboasted,\u201d \u201crasped,\u201d \u201ctaunted,\u201d\nor \u201chailed\u201d). To optimize for precision, we exclude com-\nmon verbs with many non-quotative senses, such as \u201cgo.\u201d\nUsing this definition, we manually annotate the most fre-\nquent 99.5% of quotatives overall and the 98.0% of the most\nfrequent quotatives per month. We consulted a professional\njournalist throughout this process, who suggested that the\nverbs \u201copine,\u201d \u201cpen,\u201d and \u201cutter\u201d are only sometimes used\nnonobjectively. Since it would be infeasible to create a sep-\narate category just for these verbs, we excluded them. In the\nend, we curated a list of 32 objective and 152 nonobjective\nverbs (see Appendices A.1). We use this list to remove rare\nverbs (i.e., those not on the list), obtaining a final dataset\nwith 6.7M quotes (35.1% of the original data) from 14,031\npoliticians in 989 outlets.\nData summary: Table 1 summarizes the most frequent quo-\ntatives and speakers in the final dataset. Consistent with prior\nliterature (Gidengil and Everitt 2003), \u201csay\u201d and \u201ctell\u201d are\nthe most commonly used quotatives (over 80% of the time),\nand Twitter is a common source for quotes (Bane 2019). We\nfind minor differences in the coverage of each speaker across\noutlet categories, with Donald Trump being the most quoted\nspeaker. Table 2 depicts the number of outlets per category\nand the fraction of quotes belonging to the ten top outlets\nin each category. No single outlet dominates an entire outlet\ncategory, but the distribution is more concentrated in the left\nand right categories, given the relatively smaller number of\noutlets in these categories.\ncc,relcl, see https://universaldependencies.org/en/dep/\n366\nQuotative % Speaker % % Left % Left-Center %Least-Biased %Right-Center %Right\nsay 72.58 Donald Trump 15.64 19.51 15.59 15.18 13.85 16.93\ntell 8.82 Barack Obama 3.50 4.36 3.90 2.60 3.39 4.36\nwrite 3.82 Hillary Clinton 1.44 2.31 1.47 0.98 1.28 2.35\ntweet 2.97 Nancy Pelosi 1.35 1.26 1.16 1.43 1.26 1.89\nadd 2.56 Bernie Sanders 1.24 2.67 1.17 1.00 0.99 1.60\nask 1.29 Joe Biden 1.23 1.60 1.16 1.13 0.94 1.89\ncontinue 0.72 Mitch McConnell 1.04 1.03 0.98 1.11 0.99 1.13\nrespond 0.59 Chuck Schumer 0.90 0.73 0.85 0.98 0.85 1.03\ndeclare 0.59 Lindsey Graham 0.88 1.13 0.78 0.83 0.78 1.30\nstate 0.45 Elizabeth Warren 0.86 1.43 0.83 0.77 0.69 1.08\nTable 1: Statistics on top speakers and quotatives. Frequency of the top quotatives and speakers in the entire dataset after filter-\ning. We also include the speaker frequency in each outlet category for reference. Among the listed quotatives, only \u201cdeclare\u201d is\nnonobjective.\nLeft % Left-Center % Least-Biased % Right-Center % Right %\nn=80 n=249 n=467 n=142 n=51\nk=0.46M k=2.45M k=2.12M k=0.75M k=0.94M\nCNN 20.17 Yahoo 6.15 The Hill 6.41 Washington Times 11.50 Breitbart 17.68\nRaw Story 5.17 MSN 5.15 Roll Call 1.66 NW AR Democrat-Gaz. 3.42 Fox News 11.77\nSalon 5.16 SFGATE 3.44 KVIA-TV 1.38 AR Democrat-Gaz. 3.10 Wash. Examiner 11.62\nThe Week 5.02 WaPo 3.28 UPI 1.29 Chicago Tribune 2.74 Newsmax 9.36\nTPM 4.78 Politico 2.72 WTOP-FM 1.17 Laredo Morning Times 2.52 Daily Caller 4.52\nDaily Beast 4.11 CBS 2.69 CBS Local 1.07 Boston Herald 2.40 Free Beacon 3.31\nAlterNet 3.61 NBC News 2.50 KSL News 1.02 MyNorthwest 2.37 The Epoch Times 3.07\nNY Magazine 3.40 NY Times 2.46 KTVQ-TV 0.95 Daily Herald 2.25 WorldNetDaily 2.86\nV ox 2.69 Newsweek 2.03 WFMZ-TV 0.95 The Spokesman-Review 2.22 TheBlaze 2.76\nDaily Kos 2.68 LA Times 1.74 WTHR-TV 0.94 Albuquerque Journal 2.14 CNSNews 2.64\nTable 2: Statistics on outlets. Frequency and website names of the ten top outlets in each category. n: number of outlets in each\ncategory; k: number of quotes in each category.\n3.2 Validation Error Analysis\nTo validate our verb extraction approach, we divide our data\nbased on the detected verb type (objective and nonobjec-\ntive) and manually annotate 100 randomly sampled quotes\nper year per verb type; the results are shown in Table 3. Our\nmethod achieves high accuracy in objective and nonobjec-\ntive verb extraction, and this accuracy is stable over time,\nwith a combined accuracy of over 90% across all years.\nBefore removing quotatives that are not contained in our\ndictionary of common quotatives (see Step 4), we also ana-\nlyze the instances in which quotatives with rare verbs were\nretrieved by our model. We find that in many cases: 1) the\nactual quotative is not a verb (e.g., \u201caccording to\u201d is a com-\nmon quotative phrase); 2) the quote is a mixed quote without\nquotative; or 3) the method is applied to incomplete or noisy\ndata and identifies an incorrect quotative.3.3 Regression Model\nThroughout the results section, we fit linear probability mod-\nels (LPMs) specified as\nyq=Xq\u03b2\u03b2\u03b2+\u03b5q (1)\nusing ordinary least squares, where yqis a binary variable\nindicating whether a specific quote is nonobjective (1) or\nobjective (0), Xqis an array with explanatory variables as-\nsociated with quote q,\u03b2\u03b2\u03b2is the array of coefficients we esti-\nmate, and \u03b5qis the error term. Coefficients obtained in this\nfashion are unbiased and robust (if the predicted probabili-\nties lie between 0 and 1 (Horrace and Oaxaca 2003), which\nhappens for all our analyses). We estimate standard errors\nandt-statistics with cluster robust standard errors (at the\noutlet level), accounting for autocorrelation between quotes\nas well as heteroskedasticity (Cameron and Miller 2015).\nMore details about linear probability models can be found\nin Wooldridge (2010).\n367\nYear Objective (%) Nonobjective (%) Combined (%)\n2013 95 87 91\n2014 98 86 92\n2015 98 83 90.5\n2016 95 92 93.5\n2017 96 90 93\n2018 96 90 93\n2019 98 86 92\n2020 98 91 94.5\nTable 3: Validation of the proposed quotative extraction\nmethod. We take 100 random quotes from each year that\nour dataset covers, manually annotate the correct quotative,\nand show the accuracy. Note that the incorrect cases include\nthose in which a quotative cannot be identified. This is most\noften because no clear quotative is present (due to mixed\nquotes or because the article text is incomplete).\n102\n101\nPercentage of Nonobjective QuotativeLeft\nLeft-Center\nLeast-Biased\nRight-Center\nRightQuote-level average\nFigure 2: Usage of nonobjective quotatives across outlets of\ndifferent political leaning. For each media bias category (on\nthey-axis), we depict the usage of nonobjective quotatives\nper outlet (each represented by a circle \u25e6) and the overall av-\nerage usage pooled across outlets (\u00d7 ). Note that the x-axis\nis on a logarithmic scale. Pairwise differences between av-\nerages are statistically significant under the Wilcoxon Rank-\nSum Test with Bonferroni correction.\nRecent work has often favored LPM instead of logistic re-\ngression or other non-linear models due to the ease of inter-\npretation and of incorporating fixed effects (Gomila 2021),\ne.g., see Dai et al. (2021). In our case, we use the LPM since\nour main purpose is to approximate the partial effects of the\nexplanatory variables (Wooldridge 2010). We report all re-\nsults in this paper with significance level \u03b1=0.05.\n4 Results\n4.1 RQ1: How Has the Usage of Nonobjective\nQuotatives Evolved?\nAcross the study period, we find that the usage of nonob-\njective quotatives produces a sensible ordering of the media\nbias categories considered, with the more partisan outlets us-\ning the most nonobjective quotatives and the less partisan\noutlets using the least. We depict this order in Fig. 2, where\neach circle (\u25e6) represents the average usage of nonobjective\nquotatives in one of the outlets considered, and crosses (\u00d7 )\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.25 \u22120.125 0 0.125 0.25\nPercentage rate of change (\u03b2)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cfFigure 3: Percentage yearly rate of change of nonobjective\nquotative usage for each outlet category. A solid circle de-\nnotes a significant effect ( p<0.05), and a hollow circle de-\nnotes an insignificant effect. Note that the reported trends\ncorrespond to the estimated \u03b2coefficients in Eq. (2).\n2014 2017 2020\nYear0.5\n0.00.5% Nonobjective\nQuotative (centered)\nFigure 4: Percentage yearly rate of change of nonobjective\nquotative usage for all outlets combined. We show the per-\ncentage of nonobjective quotatives after performing center-\ning and plot a regression line showing the \u03b2coefficients es-\ntimated in our fixed effects model.\nindicate the average usage pooled across each media bias\ncategory. When quoting politicians, U.S. least-biased out-\nlets use nonobjective quotatives the least, followed by the\nleft-center and right-center outlets, and finally, right and left\noutlets. Outlets considered more partisan by MB/FC used\nnonobjective quotatives more. Pairwise differences between\naverages are statistically significant under the Wilcoxon\nRank-Sum Test with Bonferroni correction.\nTo study how the usage of nonobjective quotatives\nevolved, we use a fixed effects linear probability model. For\neach quote q, let o[q]be the outlet in which qwas reported,\nb[q]be the bias category of the outlet, and t[q]be the time\nwhen it was in reported in months relative to the starting pe-\nriod of our dataset (May 2013). We define the model as\nyq=\u03b1o[q]+\u03b3b[q]+\u03b2b[q]t[q]+ \u03b5q, (2)\nwhere the dependent variable yqequals 1 if the verb used\nin the quote qis nonobjective and 0 otherwise, \u03b1o[q]is an\noutlet-level intercept, \u03b3b[q]is a category-level intercept, and\n\u03b2b[q]is a category-level trend in the usage of nonobjective\nquotatives \u2013 the effect we are interested in estimating.Since\nwe are modeling time-series data (one per outlet), auto-\ncorrelation may shrink the confidence intervals of model\nestimates (see Bertrand, Duflo, and Mullainathan (2004)\nfor details). To address this, we estimate the model us-\n368\n2014 2017 2020\nYear1\n012% Nonobjective\nQuotative (centered)Left\n2014 2017 2020\nYearLeft-Center\n2014 2017 2020\nYearLeast-Biased\n2014 2017 2020\nYearRight-Center\n2014 2017 2020\nYearRightFigure 5: Trends in the usage of nonobjective quotatives across outlets of different political leaning. For each media bias\ncategory (one per column), we show the percentage of nonobjective quotatives after performing outlet-level centering and plot\nthe regression line showing the \u03b2coefficients estimated in our fixed effects model.\nQuotative Percentage Change Quotative Odds Ratio\nsay -10.18\u2193 tweet 1 \u219217.04\ntweet 4.157\u2191 falter 1\u219211.88\ntell 1.843\u2191 caption 1 \u219210.86\nwrite 1.555\u2191 restate 1\u21926.772\nadd 1.020\u2191 remark 1\u21925.614\nrespond 0.3538\u2191 punctuate 1\u21924.855\ncontinue 0.3454\u2191 blurt 4.891\u21921\ndeclare 0.2325\u2191 disclose 4.911\u21921\nremark 0.2159\u2191 enthuse 6.335\u21921\nclaim 0.2028\u2191 exult 15.65\u21921\nTable 4: Changes in quotatives used. We report the most\nchanged quotatives between our dataset\u2019s first and last 12\nmonths in absolute change and odds ratio. Italic highlighting\ndenotes nonobjective quotatives.\ning cluster robust standard errors, clustering on the outlet\nlevel (Cameron and Miller 2015).\nWe depict the estimated trends in nonobjective quotative\nusage in Fig. 3 (i.e., the estimated \u03b2b[q]in Equation (2)). Al-\nthough the least-biased outlets used nonobjective quotatives\nless on average (Fig. 2), we find that their usage of nonobjec-\ntive quotatives increases over time. We estimate that least-\nbiased outlets increase their usage of nonobjective quota-\ntives by 0.08% per year and that right-center and left-center\noutlets increase their usage by 0.10% and 0.06% per year,\nrespectively. If we compare the level of nonobjective quo-\ntative usage from 2013 to 2020 (beginning and end of our\nstudy), these changes translate to relative increases of 19.9%\nfor least-biased outlets, 21.3% for right-center and 13.6%\nfor left-center outlets. In contrast, left outlets experienced a\nstatistically insignificant decrease in their usage of nonob-\njective quotatives by 0.12% per year, and right outlets expe-\nrienced a smaller, statistically insignificant increase in usage\nof nonobjective quotatives (of roughly 0.01%). We also ex-\nperimented with an added seasonality factor shared across\nall outlets and politicians, either on a monthly or yearly ba-\nsis. We exclude these results here since 1) accounting for\nseasonality does not substantially change the results, 2) ef-fect sizes decrease only slightly when seasonality is consid-\nered, and 3) with only two four-year cycles, there is insuffi-\ncient data for a robust analysis of seasonality.\nWe further illustrate the results obtained in the fixed ef-\nfects model in Figure 4 and 5. In Figure 4, we center the\noverall quotative usage around 0 and plot the month-level\nnonobjective quotative usage, along with a regression line\ncapturing the trend. The increase in nonobjective quotative\nusage across all outlets aggregated in percentage per year\n(i.e., the slope) is 0.079% ( p<0.001). In other words, we\nfind that the overall rate of nonobjective quotative usage\namong all outlets is increasing, thereby supporting the ar-\ngument that changes in the usage of quotatives indicate a\nsteady decline in objectivity in U.S. political news.\nIn Figure 5, we plot at the outlet category level: we center\neach outlet time series around 0 and then report the month-\nlevel (demeaned) usage of nonobjective quotatives per outlet\ncategory, along with a regression line capturing the trend in\neach time series. Here, we observe that the usage of nonob-\njective quotatives increases for centrist outlets, decreases for\noutlets on the left, and only slightly increases for outlets on\nthe right, although the two latter results were not statistically\nsignificant according to the model. In other words, the over-\nall trend in decreasing objectivity can be explained by the\ntrends in centrist outlets.\nAnother way to understand the change in quotative usage\nis to consider the extremes. We compare how quotative us-\nage changes between the first 12 months (May 2013 - April\n2014) and the last 12 months (May 2019 - April 2020) of\nour dataset. In Table 4, we report the quotatives that expe-\nrienced the largest changes in terms of absolute percentage\npoints (on the left) and odds ratio (on the right). We find\nthat the usage of the quotative \u201csay,\u201d typically considered\nthe gold standard of quotatives, fell by more than 10% per-\ncentage points. At the same time, we see an increase in other\nobjective quotatives (e.g., tell), but this increase does not ac-\ncount for the entire ten percentage points. Lower in the list,\nwe see that nonobjective quotatives like \u201cclaim,\u201d \u201cremark,\u201d\nand \u201cdeclare\u201d are used more often. Finally, we highlight that\nquotatives reveal changes in where journalist source their\nquotes, with both \u201ctweet\u201d and \u201ccaption\u201d (usually employed\nwhen the speaker uploads a picture or video on social media)\nexperiencing large relative increases in usage.\n369\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22123 \u22122 \u22121 0 1 2 3\nDemocratic \u2212 Republican\nPercentage nonobjective quotative (\u03c3)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cfFigure 6: Differences in nonobjective quotative usage be-\ntween Democratic and Republican speakers. All estimates\nare significant. Reported differences correspond to the con-\ntrasts \u03c3democratic \u2212\u03c3republican in Eq. (3) (in percentage points).\n4.2 RQ2: How Do News Outlets Use Nonobjective\nQuotatives When Covering Politicians of\nDifferent Parties?\nNext, we investigate whether the outlets are biased in their\nquotative usage when they cover politicians from ideologi-\ncally similar vs. opposing political parties.\nQuotative bias across outlet categories. For each quote q,\nletp[q]be the party of the politician who uttered the quote.\nKeeping with the notation in Eq. (2), we again use a fixed\neffects linear probability model\nyq=\u03b3b[q]+\u03b7p[q]+\u03c3b[q], p[q]+\u03b5q, (3)\nwhere the dependent variable yqequals 1 if the quotative\nused in the quote qis nonobjective and 0 otherwise, \u03b3b[q]is a\ncategory-level intercept, \u03b7p[q]is a party-level intercept, and\n\u03c3b[q], p[q]captures the interaction between pairs of outlet bias\ncategory (b[q]) and speaker party ( p[q]). We emphasize that\noutlet and outlet category are outlet-level attributes, while\nthe political party is a politician-level attribute. We again\ncluster standard errors on the outlet level to address auto-\ncorrelation. Note that here, we are particularly interested in\nthe contrasts between different combinations of outlet cate-\ngories and speaker parties, e.g., the difference between how\nleft outlets quote Democratic and Republican speakers (in\nthe model \u03c3left,democratic \u2212\u03c3left,republican ).\nFor each media bias category, we show the estimated per-\ncentage difference in the usage of nonobjective quotatives\nfor Democratic and Republican speakers in Figure 6. For\nevery outlet category, there is a significant difference in quo-\ntative usage between Democratic and Republican speakers.\nNotably, this difference is nearly 2%, around a third of the\noverall nonobjective quotative usage, for both left and right\nmedia outlets, which use more nonobjective quotatives when\nreferring to politicians from opposing political parties. For\ncentrist outlets, we see a Democratic bias in the usage of\nquotatives, with Republicans being quoted with nonobjec-\ntive quotatives around 1% more for least-biased and left-\ncenter outlets and nearly 0.5% more for right-center outlets.\nMatched analysis. A possible explanation for what we ob-\nserve in Figure 6 is that outlets of different political lean-\nings cover different quotes (Tan, Peng, and Smith 2018) and\nLeft (Combined)\nRight (Combined)\n\u22121.25 \u22120.75 \u22120.25 0.25 0.75\nDemocratic \u2212 Republican\nPercentage nonobjective quotative (\u03c3)\u25cf\n\u25cfFigure 7: Differences in nonobjective quotative usage be-\ntween Democratic and Republican speakers for matched\nquotes. A solid circle denotes a significant effect ( p<0.05),\nand a hollow circle denotes an insignificant effect. Re-\nported differences correspond to the contrasts \u03c3democratic \u2212\n\u03c3republican in Eq. (3) (in percentage points).\nthat these quotes lend themselves more or less to being at-\ntributed to speakers through nonobjective quotatives. Even if\nthis were the case, one could still make a case against media\nbias, as journalistic textbooks and guidelines instruct the us-\nage of objective quotatives regardless of the quote (Mencher\nand Shilton 1997; Brooks et al. 2007; Reuters 2008; The As-\nsociated Press 2020; Rich 2015). Nevertheless, we entertain\nthis hypothesis by performing a matched analysis. Specifi-\ncally, we identify quotes covered by both the left and right\nmedia outlets, merging left/left-center and right/right-center\noutlets for ease of comparison (we refer to these merged bias\ncategories as left and right \u201ccombined\u201d). Using only this\nsubset of quotes (n =1.02M, 15.13% of all quotes in our\ndata), we fit the fixed effects model defined in Eq. (3).\nFor the two collapsed media bias categories and consider-\ning only matched quotes, we show the estimated difference\nin usage of nonobjective quotative for Democratic and Re-\npublican speakers in Figure 7. For right/right-center outlets,\nwe find a small non-significant positive difference (0.01%).\nNote that in the non-matched scenario, in Figure 6, these two\ntypes of outlets behave differently \u2013 right outlets use more\nnonobjective quotatives when quoting democrats, whereas\nright-center outlets do so when quoting republicans. Since\nwe aggregate right and right-center, it may be that these het-\nerogeneous effects cancel each other. For left/left-center out-\nlets, we find a significant difference of around -0.75% in the\nusage of nonobjective quotatives. This suggests that quote\nselection alone cannot explain the quotative bias previously\nobserved and that quotative selection forms an additional\nsource of bias on top of quote selection.\nTrends in quotative bias. Finally, we investigate if quota-\ntive bias has evolved during the study period, using a fixed\neffects linear probability model:\nyq=\u03b1o[q]+\u03b3b[q]+\u03b7p[q]+\u03bbb[q], p[q]t[q]+ \u03b5q, (4)\nwhere the dependent variable yqequals 1 if the quotative\nused in the quote qis nonobjective and 0 otherwise, \u03b1o[q],\n\u03b3b[q], and \u03b7p[q]are outlet, category, and party-level intercepts,\nand\u03bbb[q], p[q]is the trend in the usage of nonobjective quota-\ntives for each party/bias category combination.\nFor each media bias category, we depict the difference in\nthe trends of nonobjective quotative usage for Democrats\nand Republicans in Figure 8. For left and centrist outlets,\n370\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.5 \u22120.25 0 0.25 0.5\nDemocratic \u2212 Republican\nPercentage rate of change (\u03bb)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cfFigure 8: Differences in percentage yearly rate of change of\nnonobjective quotative usage between Democratic and Re-\npublican speakers for each media outlet category. A solid\ncircle denotes a significant effect ( p<0.05). Reported\ntrends correspond to the contrasts \u03bbdemocratic \u2212\u03bbrepublican in\nEq. (4) (in percentage points).\nthe gap between how nonobjective quotatives are used to\nquote Democrats and Republicans is increasing in the study\nperiod. These increases are statistically significant and sub-\nstantial compared to the existing level of quotative bias ob-\nserved in our data. For example, the estimated contrast of the\ntrend is around 0.33% for left-center outlets, and the existing\nquotative bias is 1.08%. Thus, the annual relative increase of\nquotative bias is above 30%. Left outlets exhibit the most in-\ncrease in quotative bias in absolute terms, at 0.5% per year.\nFor right outlets, the difference in trend leans Republican,\nbut the effect is not statistically significant.\n5 Discussion\nIn this work, we analyzed quotatives to study political jour-\nnalism, answering the following questions: How has the us-\nage of nonobjective quotatives evolved in U.S. political jour-\nnalism (RQ1)? How do news outlets use nonobjective quo-\ntatives when covering politicians of different parties (RQ2)?\nTo answer these questions, we proposed a method to identify\nquotatives for direct quotes using dependency parsing. We\nthen extracted quotatives from a large dataset of speaker-\nattributed quotes, resulting in over 6.7 million quotes over\neight years, from 2013 to 2020. By counting the usage of\nobjective and nonobjective quotatives, we analyzed the static\nand dynamic trends of quotative usage.\nWe find that the more partisan outlets use more nonob-\njective quotatives (Figure 2). However, during the study pe-\nriod, centrist outlets (classified as least-biased, left-center,\nand right-center by MB/FC) experienced a significant in-\ncrease in the usage of nonobjective quotatives, suggesting\nthat they may be \u201ccatching up\u201d to the more biased outlets\n(Figure 5). We further observe that outlets tend to use more\nnonobjective quotatives when covering politicians of the op-\nposing ideology, thereby exhibiting \u201cquotative bias\u201d (Fig-\nure 6). Even when we control for quotes by matching outlets\non the quote level, we find that this bias still exists for left\nand left-center outlets (Figure 7). Finally, we find a rapid in-\ncrease in quotative bias for most outlet categories over time,\nwhich may indicate that U.S. political news is becoming in-\ncreasingly polarized (Figure 8).These findings suggest that two simultaneous processes\nare at play: outlets are adopting more nonobjective quo-\ntatives overall andthe usage of nonobjective quotatives is\nincreasingly \u201cmediated\u201d by the party affiliation of quoted\npoliticians. Both processes indicate a measurable decrease in\njournalistic objectivity. While detecting bias often requires\nsome level of human judgment to determine neutrality, and\nwhile it is debatable how a neutral or balanced view can be\npresented in any specific context, quotative usage can be re-\ngarded as an easily quantifiable form of bias due to its promi-\nnence within journalism. There are clear and established\nrules for the usage of quotes on which journalists have his-\ntorically agreed, as is evident from textbooks (Brooks et al.\n2007; Mencher and Shilton 1997; Rich 2015) and editorial\nguidelines (Reuters 2008; The Associated Press 2020). Al-\nthough objective journalism is a 20th-century invention and\ncould be considered an anomaly throughout history, it is re-\ngarded as central to today\u2019s democratic process. In this con-\ntext, our results indicate a decrease in the level of objective\nquotative usage in U.S. political news coverage, which can\nbe seen as a devolution of journalism as a profession.\nAn interesting question is to which extent Donald Trump,\nthe most quoted speaker in our dataset, influences the find-\nings observed in this paper. To investigate this, we re-run all\nfixed effects models in the paper in a filtered dataset from\nwhich we removed Trump\u2019s quotes (see Appendices A.2).\nWe find that, without Trump, there is no significant increase\nin the overall usage of nonobjective quotatives. However,\nwe still observe quotative bias in all outlet categories except\nleft-center outlets.\nThe ways in which the observed increase in nonobjec-\ntive quotatives relates to broader trends in U.S. politics\nand the news ecosystem remains unclear. On the one hand,\nthe observed trend may merely reflect the reality of the\nnews business. As newspapers struggle to retain subscribers\nand attract clicks (Thurman, Lewis, and Kunert 2019), out-\nlets (including the least-biased ones) may have succumbed\nto nonobjective quotatives as they adapt to the fast-paced\nstyle of Web-first publishing and try to produce engaging\ncontent. Alternatively, journalists themselves may be sub-\nject to trends of increasing polarization in the general pub-\nlic (Abramowitz and Saunders 2008), becoming more prone\nto Freudian slips when reporting the speech of politicians\nthey (dis)like. On the other hand, the increase in quotative\nbias may influence people\u2019s opinions about politicians (Cole\nand Shaw 1974) or erode the reader\u2019s trust in the media out-\nlet, as they might disagree with the opinions subtly embed-\nded in the news piece by the writer (Gunther 1992).\nLimitations. We highlight three limitations of our work.\nFirst, while Quotebank covers a large number of outlets over\ntime, the number of quotes from each outlet does not neces-\nsarily reflect the actually published amount of content per\noutlet, nor does it represent the relative popularity of each\noutlet. Therefore, our findings should not be interpreted as\nthe perception that an average news consumer in the U.S.\nmay have. Second, since we focus on quotative verbs and do\nnot consider adverbs, we may not capture the complete pic-\nture of quotative usage. For example, the hypothetical quo-\n371\ntative \u201csay aggressively\u201d should be categorized as nonobjec-\ntive, but we still categorize it as objective since we do not\nconsider adverb usage. Empirically, however, this combina-\ntion of an objective quotative verb and a nonobjective adverb\nis uncommon (as it can be considered even more unprofes-\nsional than a nonobjective quotative verb) and is unlikely\nto affect our results. The occurrence of non-verb quotatives\nis rare as well. Also, despite our best effort, a few quota-\ntives may be misidentified or not included in our dictionary.\nWhile this should not affect our overall analysis, analyzing\nthese rare quotatives might yield additional insights. Third,\nwhile we carefully removed most indirect and mixed quotes\nfrom our dataset, some are expected to remain in the data.\nThus, we cannot completely eliminate the effect of indirect\nquotes on the obtained results.\nFuture Work. Future work could use and extend our\nmethodology to investigate trends in nonobjective quotative\nusage after the Trump presidency or in other countries and\nlanguages. Further, an even more comprehensive investiga-\ntion of the landscape of quotative usage in political journal-\nism could be obtained by extending our methodology to in-\nclude indirect and mixed quotes and/or considering nonverb\nphrases and adverbs as quotatives. Last, future work could\nexamine if nonobjective quotatives reflect changes in polar-\nization or the media ecosystem and to what extent they im-\npact readers\u2019 opinions of politicians and news outlets.\nA Appendices\nA.1 List of Objective and Nonobjective\nQuotatives\nObjective Quotative : say tell write tweet add ask continue\nrespond state explain note read reply quote announce re-\ncall conclude post begin describe answer cite testify recount\nclose email summarize finish caption inform accord preface\nNonobjective Quotative: declare warn claim argue in-\nsist remark joke suggest acknowledge urge promise com-\nment assert quip proclaim admit share complain vow praise\nstress predict charge shoot observe emphasize boast reiter-\nate pledge remind fire counter lament shout concede cau-\ntion assure retort confirm exclaim contend advise laugh blast\nhit indicate yell press reflect tout fume mock muse interject\ngush apologize brag clarify thunder challenge hail interrupt\nsnap elaborate chide chime plead lash intone confess dis-\nagree protest crow boom tease cry scold laud hint affirm\ncrack implore scoff bellow chuckle rail lecture smile spec-\nulate scream bemoan reassure shrug marvel rip underscore\ndecry commend gripe object confide jab pronounce taunt in-\nstruct enthuse admonish roar chastise whine rant reminisce\nreaffirm concur recite disclose beam whisper deflect posit\nrebuke pile falter articulate deride channel sneer blurt per-\nsist grumble ratchet punctuate forecast sigh sketch exhort\nexplode burst preach cede interrogate diagnose gloat tee shy\nwax mourn exult goad backpedal restate howl\nA.2 Analysis of Quotes Without Donald Trump\nIn Figure 9, we report the coefficients of interest for the fixed\neffects models depicted in Equations (2), (3), and (4) on a\nfiltered dataset containing no quotes by Donald Trump.\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.25 \u22120.125 0 0.125 0.25\nPercentage rate of change (\u03b2)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf(a) Same as Figure 3.\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22123 \u22122 \u22121 0 1 2 3\nDemocratic \u2212 Republican\nPercentage nonobjective quotative (\u03c3)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n(b) Same as Figure 6.\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.5 \u22120.25 0 0.25 0.5\nDemocratic \u2212 Republican\nPercentage rate of change (\u03bb)\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n(c) Same as Figure 8.\nFigure 9: These figures correspond to the same analysis from\nFigures 3, 6, and 8 in the main paper but without any quotes\nfrom Donald Trump.\nEthical Statement\nThis work uses publicly available data to analyze quotes\nfrom U.S. politicians to study media bias. We match politi-\ncians\u2019 names between Quotebank and Wikidata. Our study\nutilizes one identity characteristic \u2013 the political party of the\ninvolved speakers \u2013 at an aggregated level in order to investi-\ngate the effect of ideology in quotative usage. We do not per-\nform any individual-level inferences. Additionally, we man-\nually validate both speaker disambiguation and quotative\nextraction methods to minimize the risk of identifying the\nwrong individuals and ensure the veracity of our findings.\nGiven that politicians are public figures and the importance\nof research to better understand the language used in politi-\ncal journalism and its implications, we believe that our work\nis in line with reasonable expectations of privacy (Doherty\n2007). We do not foresee potential negative societal impacts\ncoming from this research. On the contrary, we believe that\na better understanding of our political media ecosystem is\nessential to improve it. We confirm that we have read and\nabide by the AAAI code of conduct.\n372\n(a) Coefficients shown in Fig. 3.\nOutlet \u03b2 SE t p\nAll 0.08 0.02 4.14 <0.001\nLeft -0.12 0.07 -1.86 0.063\nLeft-Center 0.06 0.02 3.36 0.001\nLeast-Biased 0.08 0.02 4.77 <0.001\nRight-Center 0.10 0.03 3.44 0.001\nRight 0.01 0.09 0.07 0.943\n(b) For coefficients shown in Fig. 6 (top) and Fig. 7 (bottom).\nOutlet \u03c3dem\u2212\u03c3rep SE t p\nLeft -1.89 0.37 -5.10 <0.001\nLeft-Center -1.09 0.09 -12.26 <0.001\nLeast-Biased -0.88 0.08 -11.36 <0.001\nRight-Center -0.40 0.11 -3.58 0.013\nRight 1.75 0.42 4.15 0.001\nLeft (Combined) -0.72 0.09 -8.00 <0.001\nRight (Combined) 0.10 0.14 0.73 0.883\n(c) For coefficients shown in Fig. 8.\nOutlet \u03bbdem\u2212\u03bbrep SE t p\nLeft -0.50 0.07 -7.67 <0.001\nLeft-Center -0.33 0.03 -12.50 <0.001\nLeast-Biased -0.29 0.02 -12.18 <0.001\nRight-Center -0.22 0.03 -7.82 <0.001\nRight 0.17 0.06 2.71 0.170\nTable 5: Regression result details. For key coefficients dis-\ncussed throughout the paper, we present standard errors, t\nstatistics, and pvalues.\nAcknowledgements\nWe would like to thank Jonathan K \u00a8ulz and Marko \u02c7Culjak\nfor their help in data preprocessing and Chris Stokel-Walker\nfor having a look at our list of quotatives. This project\nwas partly funded by the Swiss National Science Founda-\ntion (grant 200021 185043), the European Union (TAILOR,\ngrant 952215), the Microsoft Swiss Joint Research Center,\nand the Deutsche Forschungsgemeinschaft under the Excel-\nlence Strategy of the German federal and state governments\n(DFG, grant EXC-2035/1 - 390681379). We also acknowl-\nedge generous gifts from Facebook and Google supporting\nWest\u2019s lab.\nReferences\nAbramowitz, A. I.; and Saunders, K. L. 2008. Is Polarization a\nMyth? The Journal of Politics, 70(2): 542\u2013555.\nBane, K. C. 2019. Tweeting the Agenda. Journalism Practice,\n13(2): 191\u2013205.Beharrell, P.; Davis, H.; Eldridge, J.; Hewitt, J.; Hart, J.; Philo, G.;\nWalton, P.; and Winston, B. 2009. More Bad News (Routledge\nRevivals). Routledge.\nBell, A. 1991. The Language of News Media. Wiley-Blackwell.\nBernhardt, D.; Krasa, S.; and Polborn, M. 2008. Political Polar-\nization and the Electoral Effects of Media Bias. Journal of Public\nEconomics, 92(5): 1092\u20131104.\nBertrand, M.; Duflo, E.; and Mullainathan, S. 2004. How Much\nShould We Trust Differences-in-differences Estimates? The Quar-\nterly Journal of Economics, 119(1): 249\u2013275.\nBoudana, S. 2011. A Definition of Journalistic Objectivity as a\nPerformance. Media, Culture & Society, 33(3): 385\u2013398.\nBrenan, M. 2022. Media Confidence Ratings at Record Lows.\nGallup.\nBrooks, B. S.; Kennedy, G.; Moen, D. R.; and Ranly, D. 2007.\nNews Reporting and Writing. Macmillan.\nBudak, C.; Goel, S.; and Rao, J. M. 2016. Fair and Balanced?\nQuantifying Media Bias through Crowdsourced Content Analysis.\nPublic Opinion Quarterly, 80(S1): 250\u2013271.\nCalcutt, A.; and Hammond, P. 2011. Journalism Studies: A Critical\nIntroduction. Routledge.\nCaldas-Coulthard, C. R. 1992. Reporting Speech in Narrative Dis-\ncourse: Stylistic and Ideological Implications. Ilha do Desterro A\nJournal of English Language, Literatures in English and Cultural\nStudies, (27): 067\u2013082.\nCameron, A. C.; and Miller, D. L. 2015. A Practitioner\u2019s Guide\nto Cluster-robust Inference. Journal of Human Resources, 50(2):\n317\u2013372.\nCappelen, H.; and Lepore, E. 1997. Varieties of Quotation. Mind,\n106(423).\nCole, R. R.; and Shaw, D. L. 1974. \u2019Powerful\u2019 Verbs and \u2019Body\nLanguage\u2019: Does the Reader Notice? Journalism Quarterly, 51(1):\n62\u201366.\n\u02c7Culjak, M.; Spitz, A.; West, R.; and Arora, A. 2022. Strong Heuris-\ntics for Named Entity Linking. In Proceedings of the 2022 Confer-\nence of the North American Chapter of the Association for Compu-\ntational Linguistics: Human Language Technologies: Student Re-\nsearch Workshop, SRW@NAACL-HLT\u201922.\nDai, H.; Saccardo, S.; Han, M. A.; Roh, L.; Raja, N.; Vangala, S.;\nModi, H.; Pandya, S.; Sloyan, M.; and Croymans, D. M. 2021.\nBehavioural nudges increase COVID-19 vaccinations. Nature,\n597(7876): 404\u2013409.\nD\u2019Alessio, D.; and Allen, M. 2006. Media Bias in Presidential\nElections: A Meta-Analysis. Journal of Communication, 50(4):\n133\u2013156.\nDellaVigna, S.; and Kaplan, E. 2007. The Fox News Effect: Media\nBias and V oting. The Quarterly Journal of Economics, 122(3):\n1187\u20131234.\nDixon, G. N.; and Clarke, C. E. 2013. Heightening Uncertainty\nAround Certain Science: Media Coverage, False Balance, and the\nAutism-Vaccine Controversy. Science Communication, 35(3).\nDoherty, C.; Kiley, J.; Tyson, A.; and Johnson, B. 2019. Public\nhighly critical of state of political discourse in the US Pew Re-\nsearch Center.\nDoherty, M. 2007. Politicians as a species of\u201d Public Figure\u201d and\nthe Right to Privacy. Humanitas Journal of European Studies, 1(1):\n35\u201356.\nGeis, M. L. 1987. The Language of Politics. Springer.\n373\nGentzkow, M.; and Shapiro, J. M. 2010. What Drives Media Slant?\nEvidence From U.S. Daily Newspapers. Econometrica, 78(1): 35\u2013\n71.\nGidengil, E.; and Everitt, J. 2003. Talking Tough: Gender and Re-\nported Speech in Campaign News Coverage. Political Communi-\ncation, 20(3): 209\u2013232.\nGomila, R. 2021. Logistic or linear? Estimating causal effects of\nexperimental treatments on binary outcomes using regression anal-\nysis. Journal of Experimental Psychology: General, 150(4): 700.\nGunther, A. C. 1992. Biased Press or Biased Public? Attitudes\nToward Media Coverage of Social Groups. The Public Opinion\nQuarterly, 56(2).\nHamborg, F.; Donnay, K.; and Gipp, B. 2019. Automated Identifi-\ncation of Media Bias in News Articles: An Interdisciplinary Liter-\nature Review. Int. J. Digit. Libr., 20(4): 391\u2013415.\nHarry, J. C. 2014. Journalistic Quotation: Reported Speech in\nNewspapers From a Semiotic-linguistic Perspective. Journalism,\n15(8).\nHorrace, W. C.; and Oaxaca, R. L. 2003. New wine in old bottles:\nA sequential estimation technique for the LPM. Available at SSRN\n383102.\nIngram, D.; and Henshall, P. 2012. The News Manual, volume 1,\nchapter 8.\nIyengar, S. 1994. Is Anyone Responsible?: How Television Frames\nPolitical Issues. University of Chicago Press.\nJurafsky, D.; and Martin, J. H. 2022. Speech and Language Pro-\ncessing. online, 3rd ed. draft edition.\nJust, M.; Crigler, A.; and Buhr, T. 1999. V oice, Substance, and\nCynicism in Presidential Campaign Media. Political Communica-\ntion, 16(1): 25\u201344.\nKahn, K. F.; and Kenney, P. J. 2002. The Slant of the News: How\nEditorial Endorsements Influence Campaign Coverage and Citi-\nzens\u2019 Views of Candidates. American Political Science Review,\n96(2): 381\u2013394.\nKobre, S. 1953. How Florida Dailies Handled the 1952 Presidential\nCampaign. Journalism Quarterly, 30(2): 163\u2013169.\nK\u00a8ubler, S.; McDonald, R.; and Nivre, J. 2009. Dependency Parsing.\nSynthesis Lectures on Human Language Technologies, 1(1): 1\u2013127.\nK\u00a8ulz, J.; Spitz, A.; Abu-Akel, A.; G \u00a8unnemann, S.; and West, R.\n2022. United States Politicians\u2019 Tone Became More Negative with\n2016 Primary Campaigns. CoRR, abs/2207.08112.\nLazaridou, K.; Krestel, R.; and Naumann, F. 2017. Identifying Me-\ndia Bias by Analyzing Reported Speech. In Raghavan, V .; Aluru,\nS.; Karypis, G.; Miele, L.; and Wu, X., eds., IEEE International\nConference on Data Mining, ICDM\u201917.\nLee, G. 2017. Verb Objectivity and Source Qualification: Compar-\nison of Quotation Attributions in Offline and Online Newspapers.\nJournalism, 18(7): 890\u2013906.\nMcCombs, M. E.; and Shaw, D. L. 1972. The Agenda-Setting\nFunction of Mass Media. The Public Opinion Quarterly, 36(2):\n176\u2013187.\nMcNair, B. 2017. After Objectivity? Journalism Studies, 18(10).\nMencher, M.; and Shilton, W. P. 1997. News Reporting and Writ-\ning. Brown & Benchmark Publishers.\nMerrill, J. C. 1965. How Time Stereotyped Three US Presidents.\nJournalism Quarterly, 42(4): 563\u2013570.\nMitchell, A.; Simmons, K.; Matsa, K. E.; and Silver, L. 2018.\nPublics Globally Want Unbiased News Coverage, but are Divided\non Whether Their News Media Deliver.Newell, E.; Margolin, D.; and Ruths, D. 2018. An Attribution Re-\nlations Corpus for Political News. In Proceedings of the Eleventh\nInternational Conference on Language Resources and Evaluation,\nLREC\u201918.\nNiculae, V .; Suen, C.; Zhang, J.; Danescu-Niculescu-Mizil, C.;\nand Leskovec, J. 2015. QUOTUS: The Structure of Political Me-\ndia Coverage as Revealed by Quoting Patterns. In Gangemi, A.;\nLeonardi, S.; and Panconesi, A., eds., Proceedings of the 24th In-\nternational Conference on World Wide Web, WWW\u201915.\nO\u2019Connell, M. 1999. Is Irish Public Opinion towards Crime Dis-\ntorted by Media Bias? European Journal of Communication, 14(2):\n191\u2013212.\nPareti, S. 2012. A Database of Attribution Relations. In Pro-\nceedings of the Eighth International Conference on Language Re-\nsources and Evaluation, LREC\u201912.\nPareti, S. 2016. PARC 3.0: A Corpus of Attribution Relations. In\nProceedings of the Tenth International Conference on Language\nResources and Evaluation, LREC\u201916.\nPrasad, R.; Dinesh, N.; Lee, A.; Miltsakaki, E.; Robaldo, L.; Joshi,\nA.; and Webber, B. 2008. The Penn Discourse TreeBank 2.0. In\nProceedings of the Sixth International Conference on Language\nResources and Evaluation, LREC\u201908.\nReuters. 2008. Reuters Handbook of Journalism.\nRich, C. 2015. Writing and Reporting News: A Coaching Method.\nCengage Learning.\nRyan, M. 2001. Journalistic Ethics, Objectivity, Existential Jour-\nnalism, Standpoint Epistemology, and Public Journalism. Journal\nof Mass Media Ethics, 16(1): 3\u201322.\nSchudson, M. 1981. Discovering the News: A Social History of\nAmerican Newspapers.\nSonoda, K. 1997. Subject-verb Inversion Before a Quotation in the\nMedia Discourse. Current English Studies, 1997(36).\nStenvall, M. 2008. On Emotions and the Journalistic Ideals of Fac-\ntuality and Objectivity\u2014Tools for Analysis. Journal of Pragmat-\nics, 40(9): 1569\u20131586.\nTan, C.; Peng, H.; and Smith, N. A. 2018. \u201dYou Are No Jack\nKennedy\u201d: On Media Selection of Highlights from Presidential De-\nbates. In Proceedings of the 2018 World Wide Web Conference.\nThe Associated Press. 2020. The Associated Press Stylebook:\n2020-2022. Basic Books.\nThurman, N.; Lewis, S. C.; and Kunert, J. 2019. Algorithms, Au-\ntomation, and News. Digital Journalism, 7(8): 980\u2013992.\nVan Dijk, T. A. 1988. News as Discourse. Lawrence Erlbaum\nAssociates.\nVaucher, T.; Spitz, A.; Catasta, M.; and West, R. 2021. Quotebank:\nA Corpus of Quotations from a Decade of News. In The Fourteenth\nACM International Conference on Web Search and Data Mining,\nWSDM\u201921. ACM.\nWatts, D. J.; Rothschild, D. M.; and Mobius, M. 2021. Measur-\ning the News and Its Impact on Democracy. Proceedings of the\nNational Academy of Sciences, 118(15).\nWooldridge, J. M. 2010. Econometric analysis of cross section and\npanel data. MIT press.\nZhou, D. X.; Resnick, P.; and Mei, Q. 2011. Classifying the Po-\nlitical Leaning of News Articles and Users from User V otes. In\nProceedings of the Fifth International Conference on Weblogs and\nSocial Media, ICWSM\u201911.\n374", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Quotatives indicate decline in objectivity in us political news", "author": ["T Hu", "MH Ribeiro", "R West", "A Spitz"], "pub_year": "2023", "venue": "Proceedings of the International \u2026", "abstract": "According to journalistic standards, direct quotes should be attributed to sources with  objective quotatives such as``said''and``told,''since nonobjective quotatives, eg,``argued''and``"}, "filled": false, "gsrank": 173, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/22152", "author_id": ["Na1GOYgAAAAJ", "IN55QyEAAAAJ", "ZiFn598AAAAJ", "F_RkRmcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:UNLOBiZr1ncJ:scholar.google.com/&output=cite&scirp=172&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=UNLOBiZr1ncJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 10, "citedby_url": "/scholar?cites=8635207146596651600&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:UNLOBiZr1ncJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/22152/21931"}}, {"title": "Comparative investigation of media bias: How to spot media bias through CDA and CL text analysis", "year": "2022", "pdf_data": " \n \n \n \n    \n \nComparative Investigation of Media \nBias:  How to Spot Media Bias \nthrough  CDA and CL Text Analysis \n \n \nMarco Pozzi  \n \n \n \n \n \n   \n \n \n  \n \n \n \nEnglish Studies - Linguistics  \nBachelor  Thesis  \n15 credits  \nSpring 2022 Supervisor: Philip Clover\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   2 \n \n     Table of Contents  \n Abstract  3 \n1. Introduction and Aim  4 \n2. Background  \n  2.1. Situational Background  \n     2.1.1. Issues and Attitudes towards Trans Women in Sports  5 \n  2.2 Theoretical Background  6 \n   2.2.1. Media Bias  6 \n   2.2.2. Critical Discourse Analysis  6 \n   2.2.3. Gatekeeping  7 \n   2.2.4. M oral System Theory  8 \n  2.3 Specific Background 9 \n3. Data and Method  11 \n4. Results and Discussion 13 \n5. Concluding Remarks  26 \nReferences  28 \nAppendix I  31 \n \n  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   3 \n \n \n \n \nAbstract  \nThis paper searches for  media bias in the British press by focusing on the topic of transgender \nathletes competing in sports , by using C orpus L inguistics  tools and with Critical D iscourse \nAnalysis  based theories. Media bias is often investigated through polls or datasets such as the \nMoral Foundation Dictionary. However, the linguistic research on media bias detection is \noften limited to quantitative analysis. This research aims to detect med ia bias through the \nanalysis of the qualitative aspects and to connect media bias to the different moral system s of \nconservatives and liberals . Therefore, the contexts in which the relevant words resulting from \nthe quantitative analysis will be investigate d to reinforce the judgement on the different biases \nof media outlets. The chosen topic provides a context that is recent and subject to a quick polarization between two main thoughts. The research  expect s that the polarization of the two \nsides will transl ate to a difference in language use between conservative and liberal news \noutlets. To prove the link between the British press behaviour and bias towards transgender athletes the research looked for relevant search terms to investigate. These terms were fo und \nthrough the keyword tool from Corpus Linguistics software, the GLAAD guidelines on writing  about transgender people in media, and the latest extended Moral Foundation \nDictionary (eMFD). The key findings of this research confirm the perceived bias of the newspaper outlets analysed but emphasize the need for a qualitative assessment of the relevant words because the sheer numbers often detract from the conclusive remarks. This research will show the quantitative and qualitative results of the study and interpret the results according to the Moral System Theory and will  provide an answer for the detection of media \nbias through CL and CDA techniques, especially underlining the key role of comparing two sets of data.  \n  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   4 \n1. Introduction and Aim \nThis research tackles the issue of media bias in the English press. Media bias is often \nperceived by news consumers, but it is often hard to point out why a certain article or newspaper is biased. This research wants to investigate  media bias according to an objective \nanalysis of the language use d instead of the personal perception of people  or just by assessing \nthe quantitative presence of terms in specialized data set . Therefore, this research addresses \nhow bias is concealed and hard to point at with both a quantitative and qualitative analysis of news articles about transgender athletes competing in sports. Arguably, controversial topics such as this fuel a quick polarization of two opposite sides. In this case, one side would comprehend those contrary to their participation while the other would be for their inclusion. This research objective is to explain that media bias is  also a product of the different morals \nbetween conservatives and liberals, and this difference gets in newspaper articles in subtle ways, either through selection or dismissal of certain events, or using certain quotes and dismissing  others. The subtle nature of media bias becomes becomes clearer  in a comparative \nstudy such as this. As  Les Moonves, head of CBS\n1 once said, \u201cjournalism has changed \u2026 \npartisanship is very much a part of journalism now\u201d (Abcarian & Henne ssey 2012)  and this \npaper aim s to find clues of biased language in the English press by looking at the articles \ndebating transgender athletes competing in sports. Ultimately, this research aims to answer the following questions:  \n\u2022 Are Corpus Linguistics tools a viable option to carry rel evant research on bias \ndetection in newspapers?  \n\u2022 Will this research confute or confirm the already perceived media bias of the analysed newspapers?  \n\u2022 How does bias become visible in the study?  \n\u2022 Why it is necessary to carry a comparative study to better underst and the biased stance \nof newspapers?  \n \n \n \n \n1 American commercial broadcast television and radio network that serves as the flagship property of the CBS \nEntertainment Group division of Paramount Global.  (CBS) \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   5 \n2. Background  \n2.1. Situational Background  \nThis section serves to outline some details about the discourse surrounding transgender \nathletes competing in sports. Although the scope of the research and the search terms used to fetch the data do not favour the discourse on trans women competing, the m edia attention falls \non them. This happens because when trans men are allowed to compete in the men divisions, they seldom compete for first place. T he following section will expand on the discourse of \ntransgender athletes competing to offer a better understanding of the issue at hand.  \n 2.1.1. The problem with trans women competing  \nTransgender people  are at the centre of many debated issues that often call the attention of \nmass media, social media, politics, and public opinion. Among the debates rising from this gender identification, there is the one about transgender athletes participating in sports. Those opposing the presence of transgender women  in sports argue that people who were born male  \nmaintain  several physical advantages over female- born athletes. Conversely, t hose who \ndefend transgender athletes participating in sport s call for their rights to be respected for the \ngender they identify as, and to be able to compete according to that identification. This debate \nsparks  whenever a transgender woman  wins a competition, and because of the backlash from \nthe public, some countries are starting to prohibit transgender women  from competing  in the \nwomen\u2019s divisions . However, most countries decide to follow  the decisions  of the \nInternational Olympic Committee (IOC\n2) or the National Collegiate Athletic Association \n(NCAA3). The IOC decided that to participate in the Olympics, transgender women  had to \ntest their testosterone level to be less than 10 nmol/l of blood, while the NCAA  adopted a \nstricter rule, that being 5 nmol/l. The critics  of these rules claim that natural testosterone \nlevels in women are usually below 2.7 nmol/l, making the gap  between male- to-female and \nwomen athletes still too wide . Since the amount of testosteron e in the body is a key factor in \nsports performance, the successes of some transgender athletes are deemed unfair and harmful \nto the achievements of women in sports.  For example , college sports provide a launching pad \n \n2 An international non -governmental not -for-profit organisation . It is the supreme authority leading the \nOlympic Movement . Its job is to encourage the promotion of Olympic values, to ensure the regular celebration \nof the Olympic Games (Roles and responsibilities of the IOC and its partners , 2021 ) \n3 The NCAA is a member- led organization focused on cultivating an environment that emphasizes academics, \nfairness and well -being across college sports.  (Mission and priorities ) \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   6 \nfor many athletes' careers, women incl uded of course. Often a young athlete's career begins \nwith a sport scholarship, but integrating transgender women into the competition might \ndetract such opportunity for some women. The same goes for the Olympics, where most \nathletes are just honoured to participate in the games. However, in the women's division, this honour might be bestowed upon a testosterone -fuelled unfair competition. The polarizing \neffect of the debate ar ound transgender athletes competing in sports  makes for a great canvas \nfor a comparative analysis such as this, and its results can help to locate a difference in language use, as well as a connection  to a biased stance on the matter.  \n 2.2. Theoretical Background \nThis section serves to frame the theories and concepts needed to understand the scope and \nexpectation of the present study. This theoretical background will expand on the definition of \nmedia bias, explain some concept s of Critical Discourse Analysis, the concept of gatekeeping, \nand the Moral System Theory.  \n2.2.1. Media Bias  \nSome definitions of media bias focus on the papers\u2019 inclination towards one side of the aisle \nover the other. Indeed, Stevenson et al. (1973) focus on the imbalance of coverage between political candidates rather than the departure from the truth (p.213), and Waldman & Devitt (1998) affirm that \u201c[b]ias can be defined as any systematic slant favoring one candidate or ideology over another\u201d (p. 302). However, this paper wishes to adopt a more general definition agreeing with the fact that \"a political opinion is neither necessary nor sufficient to justify the conclusion that the news they produce would be biased\" (Groeling, 2013, p.133). In other words, the perception of bias in this research will not be only the result of an overt political opinion or slanted coverage but will look also look at other subtler ways to tilt public \nopinion. Therefore, this research will define media bias as \u201ca strong feeling  in favour of or \nagainst one group of people, or one side in an argument, often not based on fair judgement\u201d \n(Oxford Learner\u2019s Dictionaries). In addition to this definition, this paper will also add that the \ndistinction between left -leaning articles and ri ght-leaning articles will reflect the different \nmoral systems of progressives and conservatives. \n2.2.2. Critical Discourse Analysis  \nAs Critical Discourse Analysis (CDA) looks for the reiteration of ideolog ies and inequalities \nthrough the use of  language, then it becomes one of the fundamental theories  by which this \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   7 \nresearch wants to understand and uncover media bias in the English press. According to \nFairclough (1995, 2000, 2003), discourse analysis must  be carried out by looking \nsimultaneously at three dimensions, those being text, discourse practice, and social practices. Starting with the latter, social practice is  the \u201csocial phenomena existing prior to, and hence \nshaping, impinging upon and accessible to journalistic practice.\u201d (Richardson, 2004, p.5)  In \nthis case, the social influences that  contribute to  shape the content of the news articles \nselected for the study can be found in a  set of guidelines laid down by organizations focusing \non transgender people well -being (Zottola, 2019). Among these, a particular focus will be \nheld regarding the GLAAD (2022) guidelines , because they offer a thorough list of words and \nexpressions to use or to avoid. The influence  of such works  dealing with the regulation of \nlanguage use acting on the representation of transgender people is highlighted by the development of a set of official rules for writing news articles regarding transgender people \nby IPSO\n4. Secondly, discourse practice s are \u201cthe processes involved in the production and \nconsumption of texts\u201d (Richardson, 2007, p.75) , among these are the selection of the events to \ncover, the aimed target audience, and following the professional practices  of news reporting \nbased on ethics and objectivity (ibid.). In this study\u2019s case, the selection of the covered events \nwill be taken into consideration as  discourse practice s. If the selection of certain events or \nspecific quotations is drawn upon to further one particular rhetoric, the discourse practice \ncould highlight the direction of media bias in the two sets of articles selected for the analysis.  \n2.2.3. Gatekeeping \nAlong the line of discourse practice, and especially referring to the choice of events, the \nconcept of gatekeeping and selection bias is of utmost importance. Gatekeeping could easily \nbe a more subtle way to imprint biased views in newspapers.  To develop this  theory, David \nManning White (1950) build upon the previous work of Kurt Lewin (1947) and realize the \nfirst definition of gatekeeping and gatekeepers. For White (1950) gatekeepers are to be understood as the line of people that an event must pass through t o get into the paper. This \narticle already notices the influence of the editor's political stance on the released story, not \nonly in its political content but also in the language used. Shoemaker et al. (2001) further the study on the gatekeeping device expanding the idea of different forces coming into play in the release of news articles. These forces are the practical routines surrounding news production and are considered more relevant rather than  the political worldviews of single journalists.  \n \n4 The Independent Press Standards Organization is the independent regulator of most of the UK\u2019s newspapers \nand magazines . (Independent Press Standards Organisation ) \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   8 \nShoemaker et al. (2001) provide a nuanced definition of gatekeeping \"as a series of decision \npoints at which news items are either continued or halted as they pass along news channels from source to reporter to a series of editors\" (p.233). Ultimately, The Gatekeeping Theory \"describes the powerful process through which events are covered by the mass media, explaining how and why certain information either passes through gates or is closed off from media attention \u2026 even single, seemingly trivial gatekeeping decisions can come together to shape an audience\u2019s view of the world\u201d (Shoemaker & Vos, 2009, Opening page). This is much in line with what Richardson (2007) argues about C ritical D iscourse A nalysis , \"CDA \napproaches discourse as a circular process in which social practices influence texts, via shaping the context and mode in which they are produced, and in turn texts help influence society via shaping the viewpoints of those who read or otherwise consume them\" (p. 37).  In \nother words , gatekeeping  is a discourse practice device that interferes with which  event  ends \nup in the paper . Consequently, the audience exposed only to a certain set of events will shape \ntheir ideas  accordingly.  \n2.2.4. Moral System Theory  \nAlthough this research will not tackle the issue of which political party is favoured by the \ndifferent depiction of transgender athletes, it wants to bridge the idea that political bias depends on a set of morals  that are expected by the people from  the opposed sides of the \npolitical spectrum. To elaborate on that , the research points to Lakoff's (2002) Moral System \nTheory as presented in his book Moral Politics: how liberals and conservatives think. George \nLakoff (2002)  argues that \u201c[t]he conservative/liberal division is ultimately a division between \nstrictness and nurturance as ideals at all levels \u2013 from the family to morality to religion and, ultimately, to politics\u201d (preface). As a cognitive linguist, Lakoff (2002) wa s able to list the \nmetaphors of morality used by conservatives and liberals and concluded that these were based on very different moral systems (p.11). This research argues that since the two sides are driven by different moral systems, their use of langua ge will differ accordingly. So , Lakoff \n(2002) argues that conservative  types  follow the moral system of the strict father whereas \nliberal types follow the nurturant parent moral system and these systems translate into \ndifferent moral actions. Conservatives ' moral actions promote a strict and clear distinction \nbetween right and wrong, and the respect for authority and the natural order of things. Those who oppose the moral boundaries of what is right and wrong are immoral. Also, conservatives\u2019 moral action promotes the protection of moral people from external evils, whoever acts to inhibit this protection is immoral. L iberals\u2019 moral action, instead, focus on \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   9 \nempathy, promoting fulfilment in life, and generally helping the weaker (Lakoff, 2002, pp. \n163-166). With this, the research proposes that the language used in the newspapers ought to \nreflect the conservatives\u2019 or l iberals\u2019 moral systems. After all, if \"[a] moral system defines \nhow one views the world\" (Lakoff, 2002, p.162) it will  also affect how the language  is used.  \n Consequently, for the scope and aim of this research, this paper expects the left -leaning \narticles  to reflect the morality of the nurturant parent model whereas the right- leaning articles \nto reflect the strict father morality model. This means that the left- leaning articles should \ncomply more with the GLAAD and IPSO guidelines and the right -leaning art icles should care \nless about those. Indeed, it is plausible to expect the left -leaning articles to behave inclusive ly \nand empathize with a weaker minority . On the other hand, for the conservatives\u2019 morals \ntransgender people embody those who deviate (Lakoff, 2002, pp. 84- 86) from the natural \nnorms , and their actions \u201chave effects far beyond themselves\u201d (ibid. p.85) . Therefore, the \nright -leaning articles should contrast the inclusion of transgender women  that, with their \nactions, affects the outcome of  women's competitions by winning in  their place. According to \nLakoff (2002), in addition to inclusivity, the morals  of the nurturant parent also promote \nfairness. In the analysed situation then, advocating for the inclusion of a weaker minority \nwould inevi tably go against the fairness to women and their possibilities to achieve success in \nthe sporting field. This composes the same problem the conservative moral system implies \nthat when one deviates from the natural norms and authority, it is a risk to a bro ader \ncommunity  (Lakoff 2002) . Therefore, although the research expectations for the results will \nshow how the difference in the moral system translates into diverse language use, it also acknowledges that the conflict between two major liberals \u2019 morals cou ld play a part in \nlanguage use. \n \n2.3. Specific Background \nAngela Zottola (2019) carries out a study looking into the language of 'quality' and 'popular' \nBritish  press and their representation of transgender people as social actors. She also hints at \nthe use of LSP\n5 in transgender representation. Zottola \u2019s study also combine CL tools and \nCDA theories . After compiling two corpora split between quality and popular papers, she \napproaches a content analysis following the GLAAD guidelines, with particular attention to \n \n5 Language for Specific Purpose , \u201cgenerally regarded as a type of language used by experts communicating \nwithin their area of expertise, it can also be defined as an array of conventions and rules \u2013 sometimes \noverlapping with those used in general language \u2013  that are characterized by specific peculiarities such as topic, \ncommunicative goal, audience of reference or context of appearance \u201d (Zottola, 2019, p. 468).  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   10 \nthe use of transgender as an adjective and other instances of language use. She concludes that \nthe terminology is often confused or used improperly. Also, she adds that the popular papers \npresent a \"higher percentage of terms unrelated to transgender identity but associated to it \u201d \n(Zottola, 2019, p.477). Ultimately, she addresses that the \"terminology related to transgender identities being a type of LSP is most likely to change in the next few years as the press is increasingly becoming, together with other forms of media, a means through which this topic is being popularized and disseminated\" (ibid.). This research will build upon the meth odology \nused by Zottola of using the GLAAD terminology guidelines to assess if the correct language is used in media coverage. However, while Zottola checks the difference in the representation of transgender people in quality and popular papers, this rese arch will use the language \nvariation between right -leaning and left -leaning quality papers to investigate  bias.  \nJeremy A. Frimer (2019) replicates two previous studies and adds six more to assess if \nliberals and conservatives use different moral languages.  Frimer (ibid.) bases his study on the \nMoral Foundation Theory which stat es \u201cthat liberals rely more on foundations of care/harm \nand fairness/cheating whereas conservatives rely more on loyalty/betrayal, authority/subversion, and purity/degradation in their moral functioning\u201d  (Frimer, 2019, p.1) . \nSpecifically, his study links these moral foundations to the usage of harm  and fairness  words \nfor liberals and loyalty, authority, and  purity words for conservatives. The linguistic inquir y is \ncarried out through a software assess ing the  density of moral words provided by two sets of \nMoral Foundation Dictionaries . Frimer's (ibid.) study concludes that the Moral Foundation \nTheory is unsupported and that liberals and conservatives use similar  moral languages.  \nOpposed to Frimer\u2019s conclusion, Frederic R. Hopp et al. (2020) produce a study using \nthe new extended Moral Foundation Dictionary (eMFD) \u201cfor  extracting moral content from \ntextual corpora \u201d (p. 232 ) and conclude t hat the eMFD  more accurately predicts the presence \nof morally relevant article topics. It detects distinction s between the moral language used by \npartisan news organizations and confirms that the word scores of conservatives\u2019 sources are bound to loyal, authority, and sanctity morals, whereas the liberal -leaning outlets tend to tilt \ntowards care and fairness morals (Hopp et al., p. 243) . Therefore, this research will check if a \nsimilar conclusion can be drawn by searching the terms of the eMFD in the analysed data.  \n Furthermore, Tim Groeling \u2019s (2013)  article introduces the problems of subjectivity and \nunobserved population when studying media bias while \u201creviews some approaches \u2026 and explores several promising strategies and tools scholars have developed to help overcome these obstacles\u201d (p.129) . Also, Groeling ( 2013) lays down two major ways in which bias can \nsurface in the papers: Selection Bias and Presentation bias. The former  is linked to the theory \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   11 \nof gatekeeping and as such, explains that selecting which events to cover can show bias. The \nlatter explains how the same event can be presented significantly distorted favouring one side over another. So , the Unobserved Population problem tackles the issue of the impossibility to \nknow every event to cover, thus making it harder to understand when selective bias is present . \nAlso , the s ubjectivity problem tackles the issue of the researcher's reliability in the study of \nbias. In Groe ling & Kernell's (1998) words, \"the researcher is left with the task of defending \none set of arbitrary coding rules against alternatives that yield different distributions of good and bad ... news, and hence, different conclusions about bias\" (pp. 1065- 66). This research \naddresses the  issues raised by Groeling (2013) and notes that the  problem of  unobserved \npopulation will be avoided through the comparative nature of this  study by highlight ing the \ndifferent stories covered by the two sides. When an event is just covered by one side of the press, then gatekeeping or selection bias is acknowledged  by the other side. Indeed, Goreling \n(2013) also points to such a comparative solution in his study (p. 144) . Also, this study will \ntry to step over the subjectivity problem by adopting three different set of terms to analyse for bias detection. It is in the interpretation and difference between the two corpora that bias will be detected instead of an arb itrary count of words deemed conservative or liberal.  \n \n3. Data and Method  \nThe data comprehend 365 articles from the British  press from January 2019 to March 2022. \nThe data was gathered through Newsbank.com following these search terms: \"transgender athlete/s\" or \"transgender player/s\" or \"trans athlete/s\" or \"trans player/s\" and compet* or sport. The press outlets selected are  categorised as quality papers and are The Independent, \nThe Guardian, The Times and The Sunday Times, and The Daily Telegraph. By their own admission, the newspapers taken into consideration for this research affirm to be objective and bias -free. However, different websites rank these papers on a scale from left to right \nthrough their own studies and polls . This paper specifically sorted the selected newspapers \nbias according to the scores found in yougov.com, mediabiasfactcheck.com, and allsides.com  \nAlthough yougov.com does not focus only on media bias, it  asked the English people \nhow much biased each major newspaper was and confronted it with the political inclination of the respondents of the poll (Smith, 2017). Moreover , mediabiasfactcheck.com focuses \nexclusively on media bias and reaches conclusions about media bias through objective \nmeasures and subjective analysis (Media Bias / Fact Check, 2022). For example, the parameters for choosing the left or right bias of a newspaper are backed by the expected \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   12 \nstance on a particular issue. For example, mediabiasfactcheck.com expect the general \nphilosophy of the left to be collectivism, equality, and social safety whereas the general \nphilosophy of the right is individualism, individual freedom and personal propert y, and \ncompetition. Also, and much in line with  this research, mediabiasfactcheck.com expects the \nleft stance on gay rights to be generally in support of the LGBT community and disdain discriminatory rules against LGBT people whereas the right stance to be have generally in \nopposition to the LGBT community (Media Bias / Fact Check, 2021). Ultimately, allsides.com also specialises in bias rating through editorial reviews and blind surveys where participants do not know what newspaper they are rating but are only judging on the content of the article they are asked to analyse (AllSides). All of the mentioned websites  rate The \nindependent as left -leaning, The Guardian as left, The Times and Sunday Times as right -\nleaning, and The Daily Telegraph as right.  \nConsequently, t he articles were combined in two separate corpora reflecting their \nperceived bias . So, The Independent and The Guardian composed the LEFT corpus and would \nrepresent the progressive /liberal media  whereas The Times, Sunday Times, and The Daily \nTelegraph composed the RIGHT corpus  and represent the conservative media. The corpora \ncomprehend respectively 193 and 172 articles for a total of 142 910 words for the LEFT \ncorpus  and 121 737 words for the RIGHT corpus. The research acknowledges the different \nsizes of the two corpora. However, this difference does not change the outcome of the quantitative analysis. Indeed, this research compares and refer to absolute numbers only to \nhighlights the gap between the use of certain terms. The difference would  be still relevant if \nthe absolute number were the same, therefore the collected data is considered valid for the purpose of this study.  \nThis research also acknowledges the problem of repetition of  articles or paragraphs \nwhile digging in newsbank.com. The repetition was handled by excluding articles that were completely equal but kept in articles  with only similar paragraphs or very similar articles \npublished in two separate days. The reasoning behind this choice has to do with the audiences\u2019 exposure to  the content of the articles. The same article published two different \ndays probably reached more people than one published only one day. By the same token, the same paragraph written in different articles (sometimes even by different outlets) would reach more people and would affect more the attitudes toward the discourse of transgender athletes competing in sports.  \nThe data was  thus analysed both quantitatively and qualitatively through a Corpus \nLinguistics software by looking at  the keywords search, the GLAAD media writing \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   13 \nguidelines, and the extended Moral Foundation Dictionary (eMFD ). The results of these \nsearch terms were compared each ti me between the two corpora both quantitively and \nqualitatively . Specifically, terms that had a substantial difference in total hits, or words that \npresented interesting contexts were further investigated to reach a conclusion. Therefore , the \nfirst set of w ords comprised of keywords from both RIGHT and LEFT corpora revealed to be \nbest to uncover gatekeeping practices. The second set of words comprised of the  disapproved \nterms by the GLAAD guidelines revealed to be best to uncover the research expectations of \nlanguage use tilted by the different morals of conservatives and progressives. The third set of terms  composed of the eMFD  revealed that the interested w ords were used mostly by the \nLEFT articles, and the numerical results don\u2019t follow the conclusion reached with the first two data set. And this research suggests further qualitative investigation of such terms.  \n \n4. Results and Discussion  \nThe first step in this research was to compare the keywords between the two corpora to \ndiscover a possible difference in events coverage . Since the articles composing the corpora \nare drawn from the same period, the absence of events in one corpus over the other might suggest gatekeeping. The keywords search comparing the target LEFT corpus and the reference RIGHT corpus highlighted the following words .  \nTable 1. LEFT corpus keywords (RIGHT corpus as reference)   \n Bill StateRepublica\nnLaw Ban Bills Governor Legislation lawmakers\nLEFT 395 371 214 274 248 156 170 157 134\nRIGHT 23 32 5 29 23 2 2 7 5395\n371\n214274\n248\n156170157\n134\n2332\n529 23\n2 2 7 5\n050100150200250300350400450\nLEFT RIGHT\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   14 \n \n   \n    \n By looking at the collocations of these terms and by drawing a collocational network, this \nresearch highlights that the discourse pushed by the left -leaning articles is the decisions being \nmade about transgender athletes in sports on a legislative level in the US. Indeed, most of the \nwords in Table 1 are collocates of one another in the 5L/5R range, and taking into consideration the second order collocates, then all those terms are connected  (Figure 1).   \nFigure 1. Collocational network of the keywords in Table 1  \n \ntransgender      \n \nlegislation  \n \n \n  \n \nState/s    \n \n \n  \nbill/bills   \n \nban/s/banning  \n \nrepublican  \n  \n \ngovernor    \n \n \n  \nlaw    \nlawmakers  \n \nThe same interconnection of first and second order collocates is mostly retained also  in the \n3L/3R range, thus confirming the previously mentioned discourse. The KWIC tab of these \nterms constantly reminds the audience about new  laws against transgender athletes. For \nexample , bill and transgender  appear as collocates 73 times and 41 of these are about the ban, \nblock, bar, or prohibition of transgender athletes to compete or participate in sports  (Appendix \nI, 1 \u2013 2 \u2013 3 \u2013 4 \u2013 5) . Republ ican governments are often cited by the left -leaning articles, \nconfirming the idea that conservatives ought to be opposed to transgender athletes' inclusion. Moreover, republican top five collocates are governor, controlled, led, rep, and gov. (Table 2)  \nTable 2. Collocates of republican in the LEFT corpus  \nCollocate  Rank  FreqLR  FreqL  FreqR  \ngovernor  1 31 5 26 \ncontrolled  2 17 2 15 \nled 3 18 0 18 \nrep 4 18 4 14 \ngov 5 16 1 15 \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   15 \nThis indicates the purpose of labelling the culprits of these discriminatory decisions \n(Appendix I , 6 \u2013 7 \u2013 8) . The refore, the  LEFT articles  discourse around the legislation in the \nUSA focus on the republican states forwarding discriminatory law s (Appendix I , 6), \nreiterating every time the republican nature of the government allowing these law s (Appendix \nI, 6 \u2013 7 \u2013 8) and the overall discourse is the ban, the prohibition ( Appendix I , 9 \u2013 10 \u2013 11 \u2013 12 \n\u2013 13 \u2013 14) for transgender athletes to participate. These left -leaning articles go as far as \nreporting a ban for trans kids from playing sports (Appendix I , 13), thus reinforcing times and \ntimes again the vilification rhetoric of  Republican governments. \nTable 3. Mentioned KWIC examples from Appendix I  \n(6) LEFT / \nINDE  The legislation is similar to bans  passed by Republican -led legislatures in several \nstates, such as Mississippi, Tennessee, Arkansas and Florida. Opponents, including \nEdwards, have called the measure discriminatory.  \n(7) LEFT / \nINDE  a clear reflection  of the anti-trans movement  sweeping through conservative media \noutlets and states across the country. Republican-led  legislatures have sought to \nrestrict  transgender athletes  from participating in school sports  \n(8) LEFT / \nGUARD  Tate Reeves, the Republican governor of Mississippi , is set to sign a bill on \nThursday that will ban transgender athletes from competing on girls\u2019 or women\u2019s \nsports  \n(10) LEFT / \nINDE  More than 50 bills seek to ban transgender  athletes from school sports. In 2021, \nnine stat es banned transgender athletes from participating in sports that match \ntheir gender.  \n(13) LEFT / \nGUARD  Bills that more broadly ban trans kids  from playing  on the teams that match their \ngender were signed into law in Alabama, Montana and Tennessee.  \n(14) LEFT / \nINDE  The poll also found that 83 per cent of Republicans  wanted to ban trans athletes  \naltogether.  \n So, these first result s already give a glimpse of the LEFT articles' attitude against Republican \ngovernments and arguably, conservatives' morals . On the other hand, the RIGHT corpus  \nshows a totally different stance towards the same argument, highlighting the distance between \nthe two sets of articles  in this discussion. Not only the numbers of the same search terms are \nnoticeably lower, but the context also reveals another approach. For example, bill /s appear \nonly 25 times and it is  also regarded as praised (Appendix I , 15), supported ( Appendix I , 16), \nand deemed terrific ( Appendix I , 17). These sentiments never appear in the LEFT corpus \nwhereas the RIGHT articles seem to include these different takes on the issues by drawing from other speakers. Conversely , The Australian prime minister who comments on the terrific \nbill is never mentioned in the LEFT articles.  \nTo show how different the two corpora behave, the research compared what  is also \nreported of Mississippi Governor Tate Reeves. In the LEFT corpus, Tate Reeves bans  \n(Appendix I , 3 \u2013 8) or forces schools to bar  transgender athletes from sports (Appendix I , 18). \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   16 \nBut the RIGHT articles mention Tate Reeves only requiring schools to designate teams by the \nsex assigned at birth ( Appendix I , 19 \u2013 20) in order to protect  young girls ( Appendix I , 20). \nSo, the RIGHT articles seem less interested in the US legislation, and after checking the \ncontexts of ban it shows that these articles are more focused on rugby regulations rather than \nUS policies. This may be prompted by a preference for sports  events  by the right -leaning \narticles. In fact, cycling, cricket, and marathon are all keywords of the RIGHT corpus  as well , \nbut this preference does not detract from the idea that the RIGHT articles avoid discussing US \nlegislation  almost completely .  \nTable 4. RIGHT corpus keywords (LEFT corpus reference)   \n \nIndeed, out of the 23 hits of ban in the RIGHT corpus, 15 collocates with  rugby in the 9L/9R \nrange, proving a tilt in the discourse around bans. In these instances, the ban is sustained by arguing about  safety issues ( Appendix I , 21) caused  by the  size and force difference between \nmale an d female bodies ( Appendix I , 22) which  is not enough undermined by the treatments \nsuppressing testosterone (Appendix I , 22 \u2013 23).  \nTable 5. Mentioned KWIC examples from Appendix I  \n(21) RIGHT \n/ TIME World Rugby  became the first international sports body to rule that trans women \ncould no longer  play the elite -level women's game.  \nAfter a comprehensive review, it concluded that \" safety and fairness cannot be \nassured  for women competing against trans women in contac t rugby \" \n(22) RIGHT \n/ TELE The sport last year became the first to ban trans women from playing at the elite \nwomen\u2019s level \u201cbecause of the size, force-and power -producing advantages \nconferred by testosterone during puberty and adolescence , and the resultant player \nwelfare risks this creates\u201d.  rugby testosterone female richards\nLEFT 72 233 284 1\nRIGHT 274 455 492 6772233284\n1274455492\n67\n0100200300400500600\nLEFT RIGHT\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   17 \n(23) RIGHT \n/ TELE The ban by World Rugby came shortly after Swedish research on 11 transgender \nwomen found that, after 12 months of suppressing testosterone, they maintained \nthe muscle strength  in their thighs and lost only five per cent of the muscle mass.  \n \nHowever, the researchers noted that the overall attitude towards the RIGHT keywords is not \ndissimilar in the LEFT articles . The LEFT articles also write about  safety concerns ( Appendix \nI, 24 \u2013 25) , and when looking at testosterone most cases report the rules set by the NCAA or \nIOC regarding the limits of testosterone levels for female athletes to compete in women's categories ( Appendix I , 26 \u2013 27) or the advantages brought by testosterone in sporting \nactivities ( Appendix I , 28). Th e similarity in discourse is confirmed by the shared collocates \nof testosterone between the two corpora ( Figure 2).  \nFigure 2. collocates for testosterone in the 5L/5R range  \n \n Furthermore, the interesting finding about female has to do with its fourth collocate, as it is \nnot shared by the two corpora. Indeed, biologically appears as a collocate for female  only in \nthe RIGHT corpus, hinting at the idea that those articles are keener on arguing for the biological difference between males and females ( Appendix I , 29 \u2013 30 \u2013 31).   \nSo far, the comparison between the two corpora shows that t he LEFT corpus seems to  \nbe more interested in the legislative decision on the issue in the US whereas the RIGHT corpus shows more focus on sports ruling and fairness. Although the contexts of rugby and \ntestosterone are not much different between the two corpora, the fact that th e LEFT keywords \npoint towards a discourse barely touched by the RIGHT corpus suggests gatekeeping from the \n\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   18 \nconservative side. Arguably, gatekeeping could be suggested by the almost total absence (1 \nhit) in the LEFT articles of the RIGHT keyword Richards. T his name appears 67 times in the \nRIGHT corpus in 7 different articles. Ren\u00e9e Richards is a transgender athlete who finds herself often disagreeing with transgender inclusion in elite sports ( Appendix I , 32 \u2013 33 \u2013 34) . \nTable 6. Mentioned KWIC examples from Appendix I  \n(32) RIGHT \n/ TIME In the 1970s, Navratilova, for all the \"transphobia\" slurs, championed Ren\u00e9e \nRichards's right to play in the women's US Open . Richards,  who later became her \ncoach, was over 40 when she underwent full surgical transition yet held her own \nagainst females at their physical peak . She has since reflected that if she'd \ntransitioned at 22, \"no genetic woman in the world would have been able to come \nclose to me. And so I've reconsidered my opinion.\"  \n(33) RIGHT \n/ TELE Her different perspective also stems from the fact that despite being trans herself, \nRichards, 84, has a contrasting profile to the most vocal members of the \ncommunity  - many of whom are young and liberal. \"  \n(34) RIGHT \n/ SUN  Judgments ar e difficult and dilemmas abound ( Richards , a renowned \nophthalmologist , these days has misgivings about her actions herself  ), but the \nruling principle most be fairness.  \n For this reason , the research suggests that this gatekeeping happens because a transgender \nathlete with such a stance on this matter makes for a great relator to counter the liberals\u2019 \ninclusivity rhetoric and moral s. So , by analysing the keywords between the two corpora, the \nresearch confirms  gatekeeping because the two sides omit or focus on different events to write \nabout. Although some discourse might be qualitatively similar, as in the examples around rugby and testosterone , others showed an opposite take by allowing different speakers to be \nwritten onto paper , as in the case of Richards and by the different quotations  of senator Tate \nReeves.  This arguably causes a tilt in the audience's perception of the problem, those who \nread only the left -leaning articles might shift their attention and opinion against the legislative \naspects and transgender discrimination, whereas those who only read the right -leaning articles \nwould question their inclusion in a lesser degree since they are exposed only to articles about the advantages of a male body in competitive sports  \nTo further the investigation of the biased stance on the participation of transgender \nathletes in sports in the British  press, the research looked at the GLAAD guidelines  which  \nshow  the terms best to  avoid.  This research argues  that according to the moral polarization \nsuggested in the Moral System  Theory between conservatives and progressives the guidelines \nwould be followed by the progressive s\u2019 papers whereas the conservatives \u2019 one  would use less \ninclusiv e language. According to GLAAD, transgender  should be always used as an \nadjective , every mention of biological sex at birth, as well as referring to the transition are \ntaboo subjects and should be avoided. However, as stated in the IPSO rules for writing articles \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   19 \nconcerning transgender people, referring to the operation, the assigned gender at birth or their \nprevious name can be addressed only if crucial for the story. Because of the topic  taken into \nconsideration in this research, the articles are bound to use many terms and phrases that should be avoided according to the guidelines. I n any case, this research will further the \ninvestigation both qualitatively and quantitatively to look for differe nt discourse prosodies \nand potential biased language  use. The use of the following terms is discouraged by the \nGLAAD guidelines and were chose n because of their relevant presence in the analysed data.  \nTable 7. Comparison of the  GLAAD terms total hits in both corpora  \n \nAt first glance, the search shows that the RIGHT corpus relies more on these terms except for  \ngenetic* , advancing the idea of less inclusive language use in the right -leaning papers . Then, \nstarting with genetic*, the research found that out of the 46 hits in the LEFT corpus, 23 \ncollocate s with the Differences of Sexual Development (DSD6). Often this argument is \nproposed to further the idea that genetic differences give advantages to everybody in different \nways and that DSD should not be considered an unfair one  (Appendix I , 35 \u2013 36) . Of course, \nthis proposed rhetoric also prompts  the idea  that gender can not be confirmed by a single \nfactor (Appendix I , 37 \u2013 38 \u2013 39) . This rhetoric is avoided in the RIGHT papers which instead \n \n6 Disorders of sex development (DSDs), also known as differences in sex development, diverse sex development \nand variations in sex characteristics (VSC),[2] are congenital conditions affecting the reproductive system, in \nwhich the development of chromosomal, gonadal, or anatomical sex is atypical.  (Disorders of sex development ) Biological Biology biologicallyMale to\nfemaleIdenti* as Sex change Genetic*\nLEFT 79 16 6 14 37 1 46\nRIGHT 160 32 25 37 58 9 2379\n16\n61437\n146160\n32\n253758\n923\n020406080100120140160180\nLEFT RIGHT\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   20 \nargue for the advantage s coming from male genetic s (Appendix I , 40), and when quoting the \nstatement that genetic variation should be celebrated ( Appendix I , 41) it follows up with a \nresponse arguing that DSD and transgender women  will dominate the podiums and prize \nmoney in sport  if that happened ( Appendix I , 42). Another dissuaded phrase is sex change , \nwhich is seldom used in both corpora. The RIGHT articles, however, are less afraid to use it \neven though in all the nine instances the expression is presented between quotation marks and never used directly. Further discouraged terms by the guidelines are identi fies as and male to \nfemale because they undermine the gender affirmation of individuals. Although the number s \nare in line with the attitudes proposed so far, identi* as  is commonly used and it is never \nloaded. Instead, male to female is broadly used in the  right -leaning articles to underline the \ntransitioning process ( Appendix I , 43 \u2013 44)  and sometimes to recall the masculine  past of the \nathletes  (Appendix I , 45 \u2013 46) . On the other hand, out of the 14 hits in the LEFT corpus  for \nmale to female , 10 refer to the IOC policy, thus referring  their assessment s (Appendix I , 47 \u2013 \n48). Noticeably, when analysing male to female the name of Caitlyn Jenner came up in the \nKWIC tab in the LEFT corpus .  \nSo, by digressing and searching for Caitlyn Jenner  in the KWIC tab , the research  \nuncovered the attitude used by both sides when drawing from this  outside speaker. As a \nprominent figure in the transgender community, Caitlyn Jenner is referenced by both sides. However, the left -leaning articles seem to treat her poorly (Appendix I , 49 \u2013 50 \u2013 51).  \nTable 8. Mentioned KWIC examples from Appendix I  \n(49) LEFT / \nINDE  Former reality TV star told Sean Hannity of a friend who was \u2018packing up his \nhangar\u2019 over issue Jimmy Kimmel slammed Caitlyn Jenner  as an \u201cignorant \na**hole\u201d for her comments on homelessness in Los Angeles. Ms Jenner is running \nfor governor  of California  \n(50) LEFT / \nINDE  The lives of ordinary trans people, who don't have the same funds or high profiles \nas celebrities like Caitlyn Jenner , seemed largely unchanged. In some ways, the \nfresh focus has made things harder ; look at the vocal anger  of right -wing US groups  \n(51) LEFT / \nINDE  Humphries told The Daily Telegraph. \u201cSelf -mutilation, what\u2019s all this carry on? \nCaitlyn Jenner  \u2013 what a publicity -seeking ratbag .\u201d His comments prompted calls \nfor Humphries to be sacked from his BBC Radio 2 show  \n \nThe research acknowledges the different discourse in which the quotation comes from, nonetheless, thes e condemnation quotes  are what come up when looking for Caitlyn Jenner on \nthe LEFT corpus. Arguably, this  treatment for  a figure that would make a natural ally for th e \ncause is curious, and m aybe this is explained by the fact that Caitlyn Jenner will run as \nRepublican Governor of California ( Appendix I , 49). In the only case where she is not \nsomewhat attacked, the quotation serves only to underline the hardships of those who \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   21 \ntransition (Appendix I , 52), furthering an attitude in favour of  transgender athletes and \ninclusivity moral. In addition , this treatment becomes clearer  when comparing the results \nfrom the RIGHT corpus hits for Caitlyn Jenner . Although appearing only 4 times, the right -\nleaning articles make it clear that the ex -Olympian is against transgender athletes \u2019 \nparticipation  in women\u2019s divisions . Indeed, when Caitlyn Jenner  speaks about  Lia Thomas , \nshe points out her physical  advantage ( Appendix I , 53 \u2013 54) , otherwise, she speaks about the \ngeneral advantage of greater muscle mass of male bodies (Appendix I , 55).  \nTable 9. Mentioned KWIC examples from Appendix I  \n(53) RIGHT \n/ TIME the focus on testosterone is limited because it puts aside the years of biological \nadvancement from male hormones, including height. Transgender former athlete \nCaitlyn Jenner  also said she did not support the NCAA. \u201cHer hands are bigger. \nShe can swim faste r. That's a known,\u201d   \n(54) RIGHT \n/ TELE The national governing body for competitive swimming said the policy serves \"to \nmitigate the advantages associated with male puberty and physiology\". Transgender \nformer athlete Caitlyn Jenner  is among those to have claimed that Ms Thomas has \nan unfair adva ntage. \u201cHer hands are bigger. She can swim faster . \n(55) RIGHT \n/ TELE The same outrage was recently heaped on Caitlyn Jenner  for saying trans girls, \nwho are born with greater muscle mass, should not be permitted to compete in \nwomen\u2019s sport. You could  \n \nThis digression added to the previous idea that different actors are drawn to further one \nrhetoric over another, and the attitude towards Caitlyn Jenner is an example of the attitude of the different sets of articles. This research suggests that choosing on e statement over another \nis relatable to  biased writing in the press . \n Getting back to the GLAAD guidelines taboo terms, the reiteration of the original \nbiological sex of transgender people  is one of them , and as expected the RIGHT corpus \npresents more hit s on the subject as opposed to the LEFT corpus. The sheer numbers of \nbiolog* terms are twice the amount in the right -leaning articles, reaffirming the attitude so far \ntested. However, to confirm the bias for or against transgender athletes competing in sports the research will also look at the contexts in which these words are used . The only shared \ncollocate in the 5L/5R range, besides those often appearing as clusters, is advantages. Of \ncourse, this directs the discourse around the biological advantage of male bodies in sporting activities. While the LEFT corpus speaks of the biological advantages indirectly each time, introducing the argument with they argue, they contend, or some scientists have said  \n(Appendix I , 56 \u2013 57 \u2013 58), the RIGHT articles make others\u2019 words their own  (Appendix I , 59 \n\u2013 60 \u2013 61) , or use quotes that point out the physical advantages of male bodies ( Appendix I , \n62).  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   22 \nUltimately, the researchers noted a specific case of a heavily loaded term that is certainly \novertly biased. One of the less tolerated expressions  is transgendered, the addition of the \nsuffix -ed denote s a stance against transgender people  because it contains the idea of  the \ntransitioning process between the two sexes ( Appendix I , 65). In fact, the term is used in the \nRIGHT corpora 6 times, but all of them belong to the same article in The Sunday Times. This article is blatantly against transgender women  competing and the abus e of this word makes it \nclear.  Several times transgendered  is used to underline men competing in women\u2019s sports \n(Appendix I , 63 \u2013 64) , or to label who is winning women\u2019s competitions ( Appendix I , 66 \u2013 \n67). Arguably, The Sunday Times shows a stronger stance  on the issue with this controversial \npiece by publishing it in the news section rather than the opinion one. \nTable 10. Mentioned KWIC examples from Appendix I  \n(64) RIGHT \n/ SUN  Two states in the US, both Republican - Idaho and Arizona - have passed, or are \npassing, laws that make it illegal for transgendered men to compete against women \nin sport , legislation that the Democrat opposition insists is discriminatory and \n\"transphobic\" . \n(66) RIGHT \n/ SUN  Transgendered athletes are winning track -and-field titles in Canada and the US , \nincluding the extremely fast Andraya Yearwood.  \n(67) RIGHT \n/ SUN  The transgendered cyclist Rachel McKinnon , now known as Veronica Ivy (one \nbegins to lose track, I know), is the UCI Masters World Track Racing champion . \nThe \n \nAll in all, the sheer numbers  of the terms used in the two sets of articles point towards the \nsame attitude so far discussed. Indeed, the RIGHT corpus makes broader use of the unwelcomed terms according to the GLAAD guidelines. This is in line with the research expectations that, according to the Moral Foundation Theory, progressives would be keener on the use of inclusive language whereas c onservatives would care less about using \ndiscriminatory terms. The results for genetic*, male to female, and Caitlyn Jenner show a \nwider gap in attitude towards the issue of transgender athletes competing in sports. Where the LEFT focuses on the DSD disorder to support  transgender  athletes  in sports, speaks of male to \nfemale  mostly referring to the IOC ruling, and draws Caitlyn Jenner only to indirectly \ncondemn her or forward the hardship of transitioning; the RIGHT articles focus on the genetic  \nadvantages, use male to female  as a labelling device, and draw Caitlyn Jenner int o the picture \nas a voice against transgender women  competing  in women\u2019s divisions . Moreover, the \nSunday Times Article is the only one using a loaded transgendered in an article published in the news section, and although it is only one article among the 172 total, it does add to the perception of biased media coverage so far discussed. It must be said, though, that the \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   23 \nexamples around biolog* are looser. Indeed, when analysed close to the collocate advantages \nthose examples are similar between the two corpo ra and differ only in the direct or indirect \ndelivery of the term . Arguably, this might be prompted by a conflict of interests between two \nmajor morals of progressives as stated in the Moral Foundation Theory. Since progressive morals defend fairness and i nclusivity, the specific problem of transgender women  competing \nin sports cannot allow them both. However, the selection of which quotes to draw onto text from a prominent figure such as Caitlyn Jenner  again points toward the idea that reading only \none side of the articles might shape people's perception of the problem. After all, at this point of the research, already two transgender ex -athletes have commented on the unfairness of \ntheir participation, and these comments were reported only in the right -leaning articles.  \n It must be also noted though, that the term transgender is always used as an adjective. \nIndeed, the first and foremost suggestion of the GLAAD guidelines is to avoid referring to a \ntransgender  but always using the term as an  adjective. In the 365 articles taken into \nconsideration, transgender  appears 1249 times in the LEFT corpus and 718 times in the \nRIGHT corpus, and it is always used as an  adjective. The research can thus conclude that \nthere has been an overall strong shift in the attitude towards transgender people, proving that \nthe social practices as explained by Fairclough have had a strong influence on text production.  \nTo follow up on the analysis the research points to the latest version of the Moral \nFoundation Dictionary, but because of the scope of this research, will only analyse the quantitative aspects of the terms proposed.  According to previous research ( Frimer 2019, \nHopp et al., 2020), different terms are associated with conservat ive and liberal morals  and the \nresearchers expect the left -leaning articles to have more liberal terms whereas the right-\nleaning articles to have more conservative terms . The latest version of these sets of terms is \nshown in the extended Moral Foundation D ictionary  (eMFD) , introduced by Hopp et al. \n(2020). T he total hits of these terms are compared between the two corpora (Tables 11 \u2013 12 \u2013 \n13 \u2013 14) to see if the expectation s are confirmed. The table do not show the totality of terms \nin the eMFD but only those appearing at least ten times in the two corpora.  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   24 \nTable 11. Safety/Care (liberal) terms compared between the corpora \n \nTable 12. Fairness (liberal) terms compared between the corpora \n \nThe finding regarding the eMFD  mostly follows the expected use of words connected with the \nliberals' morals. However, a striking swift of the paradigm is seen as *fair*  and to a lesser \ndegree safe*. This research argues that this difference arises because of the conflicting morals 97\n81117\n2157\n1518 172447\n23 23\n113585\n8100\n2071\n2730\n610162339\n514\n22246\n3\n020406080100120140\nLEFT RIGHT\n213\n103\n30\n9275\n142398\n82190\n1055269\n88\n2 1139\n526104\n11565\n2043\n050100150200250300\nLEFT RIGHT\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   25 \nat play. Since the nurturant parent moral system emphasizes inclusivity and fairness, it \nbecomes impossible to endorse both in this specific topic . This research suggests th at this \nconflict  is the reason why these terms are used to a lesser degree in  the left -leaning articles. \nMoreover, the eMFD terms associated with conservatives\u2019 morals do not follow the expectations .  \nTable 13. Ingroup/loyalty (conservative) terms compared  between the corpora \n \n \n   \n \n   \n \nTable 14. Authority (conservative) terms compared between the corpora \n \nIndeed, most terms are more present in the LEFT corpus rather than the RIGHT one, even \nacknowledging the difference in the totality of tokens between the corpora. Therefore, the 187094\n2657\n19\n1247\n1254\n0102030405060708090100\nTogether Family/ies Community/ies Fellow* Individual*LEFT RIGHT\n110\n36\n444\n23\n1052\n43\n12932\n4\n020406080100120\nLegal* Respect* Authorities Leader/s/ship Position ControlLEFT RIGHT\nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   26 \nquantitative analysis of the terms of the extended Moral Foundation Dictionary does not \nsupport the expectation although it supports the suggestion of the conflicting liberal morals in the debate surrounding transgender women  competing in sports.  \n \n5. Concluding Remarks  \nThe research proposed by this paper aimed at the location of biased language  by analysing the \nreporting of  the events around transgender athletes competing in sports. As a matter of fact, a \ncontroversial subject such as this easily prompts a polarization between those who care for their inclusion and those who are against it. As explained by the Moral System  Theory, the \ndifferent morals between conservatives and progressives were taken as the base for the paper's expectations. Thus, this research expected the conservatives to be against the inclusion of transgender women  in competitive sports whereas the progre ssives would be more inclusive \nabout it. Therefore, the collected data was split between two corpora representing the already perceived bias according to different specialized websites. Comparing the two corpora provided side by side examples is crucial to spot biased language used and the covered events. \nFirstly, by looking at the keywords of both corpora the research avoided the problem of unobserved population as explained by Groeling (2013) and, more importantly, made it possible to uncover the discours e practice of gatekeeping ( Shoemaker & Vos, 2009) . Indeed, \nthe results of this research suggest gatekeeping by the right -leaning articles as they do not \ncover the US laws banning transgender athletes from competing, and gatekeeping by the left -\nleaning articles in the absence of quotes from Ren\u00e9e Richards or the Australian Prime Minister and his opinion about a \u201cterrific bill\u201d . Groeling (2013) also suggests the concept of \npresentation bias, and the results of this research suggest that presentation bias happens every time another voice is drawn into the debate to favour one side over the other. This type of bias is exemplified by the different depictions of Tate Reeves and Caitlyn Jenner in the two sets of articles . Arguably, the bias discove red with the first set of search terms also helps to \nunderstand how discourse practices (Fairclough 1995, 2000, 2003) have a role in media bias.  \nSecondly, the analysis of the terms selected from the GLAAD guidelines confirmed the expectations set by the r esearch. Indeed, the sheer number s of the terms best to avoid is higher \nin the right -leaning articles, much in line with the expectations according to the conservatives\u2019 \nmorals  as outlined  in the Moral System  Theory (Lakoff 2002) . The contexts of genetic*  terms \nand male to female  also confirmed the expected  attitude in line with the different moral \nsystems. However , the contexts of  biolog* terms  were unexpectedly similar, much like what \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   27 \nhappened with testosterone and rugby  from the first set of analysed terms. Therefore, this \npaper suggests that this second set of terms helped to uncover the conflict between the liberal \nmorals of inclusivity and fairness, which, in the case of transgender athletes competing in the \nwomen's division  cannot be both endorsed . Moreover , the use of transgender as an adjective \nin every case confirms the power of social practices (Fairclough 1995, 2000, 2003) in the overall use of language. Ultimately, the research concludes that CDA and CL tools ar e a \nviable solution to analyse media bias, especially in a comparative study where the problem of unobserved population can uncover gatekeeping, selection bias, and presentation bias. Also, the research confirms the perceived bias of the newspapers taken i nto consideration. \nHowever, the bias was uncovered much more by the nature of the covered events in contrast with the language used. The bias is shown in the events that end up in the paper as well as which quotation is associated with other speakers. Reve aling this kind of bias cannot be \nachieved only by looking at the numerical hits of the search terms but the context must be analysed as well. Indeed, if Frimer (2019) concludes that conservatives and liberals use the \nsame language, this research showed th at counting words is not enough when it comes to \nmedia bias detection. To extend, this research would suggest applying the same qualitative analysis method of this paper with the terms provided by the eMFD. In fact, looking at the \nhits difference between t he two corpora of the terms listed in the eMFD is not enough to \nsuggest the same conclusion this research reached by looking at the other set of terms. Overall, the research can confirm the discourse practice power in media bias as well as the influences o f social practices on language use.  Furthermore , the research suggests that media \nbias is harder to decipher only by reading one newspaper outlet, and that is why media bias is subtle. Only the article from the Sunday Times made it overly clear that it was against transgender athletes in women's sports and that is why a comparative study is highly recommended.  Further investigation within bias detection should therefore be carried also \ntaking into consideration the qualitative aspects of the relevant terms. Major focus should be held at the difference in the actual use of the terms. The integration of these methods could help the specialized branch assessing bias in media in a more empirical way rather than population polls. Ultimately, this study would s uggest that studies in media bias can be \ncarried with small data sample such as this especially when confronting a very polarizing issue discussed in the paper. Objectivity is never easy to achieve, and this paper do not want to assess that all newspapers should aim for absolute objectivity. However, newspaper outlets and other mass media ought to be clear in their stance as they have real power in tilting the public opinion of problematic and thorny issues . \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   28 \nReferences  \n \nAbcarian  R., Hennessey K., (2012). President Obama gets enthusiastic welcome at L.A. gay \nevent. Los Angeles Times, June 6. \nhttp://articles.latimes.com/2012/jun/06/nation/la -na-obama -gay-\nfundraiser20120607 \nAllSides . How all sides rates media bias . AllSides . (2022, March 25). Retrieved May 2022, \nfrom https://www.allsides.com/media -bias/media -bias-rating -methods  \nCBS. (2022, May 26). In  Wikipedia . Retrieved May 2022, from \nhttps://en.wikipedia.org/wiki/CBS  \nDisorders of sex development . (2022, May 19). In  Wikipedia . Retrieved May 2022, from \nhttps://en.wikipedia.org/wiki/Disorders_of_sex_development  \nFairclough, N., (1995). Critical Discourse Analysis: The Critical Study of Language . London. \nLongman.  \nFairclough, N., (2000). New Labour New Language? London. R outledge. \nFairclough, N., (2003). Analysing Discourse: Textual Analysis for Social Research. London. \nRoutledge.  \nFrimer, J. A. (2019). Do liberals and conservatives use different moral languages? Two \nreplications and six extensions of Graham, Haidt, and Nos ek\u2019s (2009) moral text \nanalysis . Journal of Research in Personality , 84, 103906. \nhttps://doi.org/10.1016/j.jrp.2019.103906  \nGLAAD. GLAAD Media Reference Guide -  Transgender terms. GLAAD. (2022, April 21). \nRetrieved from https://www.glaad.org/reference/trans -terms  \nGroeling T, Kernell S. ( 1998) . Is network news coverage of the president biased?  J. Polit. \n60:1063\u201387 \nGroeling, T. (2013). Media bias by the numbers: Challenges and opportunities in the \nempirical study of Partisan News. Annual Review of Political Science , 16(1), \n129\u2013151. https://doi.org/10.1146/annurev- polisci -040811- 115123  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   29 \nHopp, F. R., Fisher, J. T., Cornell, D., Huskey, R., & Weber, R. (2020). The Extended Moral \nFounda tions Dictionary (emfd): Development and applications of a crowd -\nsourced approach to extracting moral intuitions from text . Behavior Research \nMethods , 53(1), 232\u2013246. https://doi.org/10.3758/s13428- 020-01433- 0  \nIndependent Press Standards Organisation. IPSO. (n.d.). Retrieved May 2022, from \nhttps://www.ipso.co.uk/  \nLakoff, G. (2002). Moral politics: how liberals and conservatives think  (2nd ed.). University \nof Chicago Press.  \nLewin, Kurt, (1947). Channels of Group Life, Human Relations , Vol. 1, No.2, p. 145. \nMedia Bias / Fact Check. (2021). Left vs. right bias: How we rate the bias of media sources. \nMedia Bias/Fact Check. Retrieved from https://mediabiasfactcheck.com/left -vs-\nright -bias-how-we-rate-the-bias-of-media -sources  \nMedia Bias/Fact Check.  Methodol ogy. Media Bias/Fact Check. (2022, April 24). Retrieved \nfrom https://mediabiasfactcheck.com/methodology  \nMission and priorities . NCAA.org. (n.d.). Retrieved May 2022, from \nhttps://www.ncaa.org/sports/2021/6/28/mission -and-priorities.aspx  \nOxford Learner\u2019s Dictionaries.  Bias. OxfordLearnersDictionaries.com.  (n.d.). Retrieved April \n2022, from \nwww.oxfordlearnersdictionaries.com/defini tion/english/bias_1?q=bias  \nRichardson, J., E., (2004). (Mis)Representing Islam: The Racism and Rhetoric of the British \nBroadsheet Press. Amsterdam. John Benjamins.  \nRichardson, J. E. (2007). Analysing newspapers: An approach from critical discourse \nanalysis . Palgrave Macmillan.  \nRoles and responsibilities of the IOC and its partners . International Olympic Committee. \n(2021, November 23). Retrieved May 2022, from https://olympics.com/ioc/faq/roles -and-responsibilities -of-the-ioc   \nShoemaker, P. J., & Vos, T. P. (2009). Gatekeeping theory. Routledge.  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   30 \nShoemaker, P. J., Eichholz, M., Kim, E., & Wrigley, B. (2001). Individual and routine forces \nin gatekeeping. Journalism & Mass Communication Quarterly , 78(2), 233 \u2013246. \nhttps://doi.org/10.1177/107769900107800202  \nStevenson RL, Eisinger RA, Feinberg BM, Kotok AB. ( 1973) . Untwisting the news twisters: \na replication of Efron\u2019s study. Journalism Mass Commun. Q. 50:211\u201319 \nWhite, D. M. (1950). The \u201cgate keeper\u201d: A case study in the selection of news. Journalism \nquar terly, 27(4), 383- 390. \nWaldman P, Devitt J. (1998) . Newspaper photographs and the 1996 presidential election: the \nquestion of bias. Journalism Mass Commun. Q. 75:302\u201311 \nZottola, A. (2019). (Trans)Gender in the News: Specialized language in the UK press. A \ncorpus -based discourse analysis . Lingue E Linguaggi, 29, 461- 480. \ndoi:10.1285/i22390359v29p461 \n  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   31 \nAppendix I . Key Words In Context (KWIC) of the analysed terms in the research.  \n(1) LEFT / \nGUARD  \n This year more than 80 laws targeting trans people ha ve been proposed by \nconservative lawmakers nationwide Montana\u2019s governor has signed a bill that bans \ntransgender athletes from competing on school and university sports teams that \ncorrespond with their gender  \n(2) LEFT / \nINDE  Gov. John Bel Edwards has struck down a bill prohibiting transgender athletes from \ncompeting  on girls\u2019 sports teams in Louisiana schools  \n(3) LEFT / \nINDE  Mississippi Republican Gov. Tate Reeves has signed a bill banning transgender \nathletes  from competing on girls or women\u2019s sports teams  \n(4) LEFT / \nINDE  anti-transgender bill is coming under fire for saying transgender people \u201chave a \nmental illness.\u201d An Oklahoma lawmaker who helped revive a bill to ban \ntransgender athletes from participating in women\u2019s spor ts is coming under fire for \nsaying transgender people \u201chave a mental illness.\"  \n(5) LEFT / \nGUARD  South Dakota\u2019s state senate passed a bill that restricts transgender female athletes \nfrom competing  on high school and college girls\u2019 and women\u2019s teams.  \n  \n(6) LEFT / \nINDE  The legislation is similar to bans passed by Republican -led legislatures in several \nstates, such as Mississippi, Tennessee, Arkansas and Florida. Opponents, including \nEdwards, have called the measure discriminatory.  \n(7) LEFT / \nINDE  a clear reflection of the anti-trans movement  sweeping through conservative media \noutlets and states across the country. Republican -led legislatures have sought to \nrestrict transgender athletes  from participating in school sports  \n(8) LEFT / \nGUARD  Tate Ree ves, the Republican governor of Mississippi , is set to sign a bill on \nThursday that will ban transgender athletes from competing on girls\u2019 or women\u2019s \nsports  \n  \n(9) LEFT / \nINDE  lawsuit in Connecticut that seeks to ban transgender  athletes from participating in \ngirls high school sports. A federal judge dismissed that lawsuit in April.  \n(10) LEFT / \nINDE  More than 50 bills seek to ban transgender athletes from school sports . In 2021, \nnine states banned transgender  athletes from parti cipating in sports that match their \ngender.  \n(11) LEFT / \nINDE  Legislators in more than 20 states have introduced bills this year that would ban \ntransgender girls  from competing on girls\u2019 sports teams in public high schools  \n(12) LEFT / \nGUARD  North Carolina is among 37 states that have introduced some form of \u2018Save \nWomen\u2019s Sports\u2019 legislation that would ban transgender girls and women from \nplaying on school sports teams that don\u2019t reflect their sex at birth.  \n(13) LEFT / \nGUARD  Bills that more broadly ban trans kids from playing  on the teams that match their \ngender were signed into law in Alabama, Montana and Tennessee.  \n(14) LEFT / \nINDE  The poll also found that 83 per cent of Republicans wanted to ban trans athletes  \naltogether.  \n  \n(15) RIGHT \n/ TELE Alliance Defending Freedom praised the new bill . \u201cWhen we ignore science and \nbiological reality, female athletes lose medals, podium spots, public recognition, \nand opportunities to compete,\u201d  \n(16) RIGHT \n/ TELE  Mr Morrison said: \u201cI support it, as Claire knows. I think it\u2019s a terrific bill  and I\u2019ve \ngiven her great encouragement  \n(17) RIGHT \n/ TIME  The Australian prime minister has declared his support for a bill that would ban \ntransgender people from single -sex sports .  \n  \n(18) RIGHT \n/ TIME  \u201cthe Mississippi Fairness Act\u201d recently signed into law by Governor Tate Reeves . \nThe legislation forces scho ols to allocate teams based on genders assigned at birth \nand bars transgender athletes from participating   \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   32 \n(19) RIGHT \n/ TELE  Republican governor Tate Reeves  this week signed a bill requiring  the state\u2019s \nschools to designate teams by sex assigned at birth  \n(20) RIGHT \n/ TELE Tate Reeves, a Republican governor, last week signed a bill requiring the state's \nschools to designate teams by sex assigned at birth , saying it would \" protect young \ngirls from being forced to compete with biological males for athletic opportunities\".  \n  \n(21) RIGHT \n/ TIME  World Rugby became the first international sports body to rule that trans women \ncould no longer play the elite -level women's game.  \nAfter a comprehensive r eview, it concluded that \" safety and fairness cannot be \nassured for women competing against trans women in contact rugby \" \n(22) RIGHT \n/ TELE The sport last year became the first to ban trans women from playing at the elite \nwomen\u2019s level \u201cbecause of the size, force -and power -producing advantages \nconferred by testosterone during puberty and adolescence , and the resultant player \nwelfare risks this creates\u201d.  \n(23) RIGHT \n/ TELE The ban by World Rugby came shortly after Swedish research on 11 transgender \nwomen found that, after 12 months of suppressing testosterone, they maintained the \nmuscle strength  in their thighs and lost only five per cent of the muscle mass.  \n  \n(24) LEFT / \nINDE  World Rugby has put the safety of its professional female players first.  \n(25) LEFT / \nGUARD  Trans women will not be permitted to play elite women\u2019s rugby for the foreseeable \nfuture because of \u2018significant\u2019 safety concerns, World Rugby has stat ed after \nreleasing new guidelines for transgender players.  \n(26) LEFT / \nGUARD  set by the International Olympic Committee  in 2015, which permit trans women to \ncompete in female sport if they suppress their testosterone levels below 10nmol per \nlitre. \n(27) LEFT / \nINDE  Olympic Committee ( IOC) guidelines laid out in 2015 that permit trans women to \ncompete in female sport if they suppress their testosterone levels below 10nmol per \nlitre. \n(28) LEFT / \nGUARD  working group reported that players who are assigned male at birth and whose \npuberty and development is influenced by androgens/testosterone \u201c are stronger by \n25%-50%, are 30% more powerful, 40% heavier, and about 15% faster than players \nwho are assigned female at birth\u201d.  \n  \n(29) RIGHT \n/ TELE She ha s undergone hormone replacement therapy, but this alone does not negate the \nsignificant natural edge she has acquired over biologically female swimmers \nthrough puberty: the larger hands and feet, the wider pelvis, the increased lung \ncapacity. How, then, ha ve \n(30) RIGHT \n/ TELE His comments come during an ongoing controversy about whether pitting \nbiologically male athletes against biologically female athletes is unfair  and \npotentially dangerous.  \n(31) RIGHT \n/ TELE In recent years I\u2019ve become concerned by the increasingly common sight of trans \nathletes on podiums, flanked by two biologically female runners -up. The \u201closers\u201d \nmainly manage a faux -sporting rictus grin  \u2013 but inside they must be seething.  \n  \n(32) RIGHT \n/ TIME  In the 1970s, Navratilova, for all the \"transphobia\" slurs, championed Ren\u00e9e \nRichards's right to play in the women's US Open. Richards, who later became her \ncoach, was over 40 when she underwent full surgical transition yet held her own \nagainst females at their physical peak. She has since reflected that if she'd \ntransitioned at 22, \"no genetic woman in the world would have been able to come \nclose to me. And so I've reconsidered my opinion.\"  \n(33) RIGHT \n/ TELE Her different perspective also ste ms from the fact that despite being trans herself, \nRichards, 84, has a contrasting profile to the most vocal members of the community \n- many of whom are young and liberal. \"  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   33 \n(34) RIGHT \n/ SUN  Judgments are difficult and dilemmas abound ( Richards , a renowne d \nophthalmologist, these days has misgivings about her actions herself  ), but the \nruling principle most be fairness.  \n  \n(35) LEFT / \nINDE  Everyone (except identical siblings) has unique DNA that interacts with our \nenvironment to affect our physical appearance, behaviours and physical capabilities. \nThe genetic mutations found in DSD women are entirely comparable to those we all \npossess  \u2013  \n(36) LEFT / \nINDE  So the genetic mutations found in DSD women are not exceptional  and are \ncomparable to other genetic differences not affected by any regulations.  \n(37) LEFT / \nINDE  there\u2019s a range of DSDs that can involve either rare combinations of sex \nchromosomes (e.g. XXY or XYY) or genetic mutations on other chromosomes that \naffect sexual development. Thus, no single factor, genetic or otherwise, neatly \ndetermines whether an individual is male or female.  \n(38) LEFT / \nINDE  Furthermore, no formula exists that uses genetic and other data to produce an \nanswer of whether someone is male or female. The IAAF regulation disregards this \nreality and was surprisingly unenlightened  \n(39) LEFT / \nINDE  The World Health Organisation (WHO) clearly states that no single biological \nfactor determines sex. Sex is determined by a combination of genetic and other \nfactors, including hormone levels and anatomy.  \n  \n(40) RIGHT \n/ TIME  Therefore, either Bridges is made ineligible for competition - which penalises \ntransgender athletes - or Bridges remains eligible and the women against whom she \ncompetes are penalised. Until science can completely remove the genetic male \nadvantages, then i t has to be one or the other . \n(41) RIGHT \n/ TIME  Semenya's lawyers claim that this amounts to discrimination, and told The Times: \n\"Women with differences in sexual development have genetic variations that are no \ndifferent than other genetic variations that  are celebrated in sport.  \n(42) RIGHT \n/ TIME  Jonathan Taylor, the IAAF's lawyer, has said that if the organisation loses the case \nthen \" DSD and transgender athletes will dominate the podiums and prize money in \nsport , and women with normal female testostero ne levels will not have any chance \nto win\".  \n  \n(43) RIGHT \n/ TELE The controversy over male -to-female trans athletes competing against 'biological \nfemales' has been reignited  by American swimmer Lia Thomas' success at the \nNCAA Championships.  \n(44) RIGHT \n/ TELE Thomas, who is transitioning from male to female  and this year began competing \nagainst women, became the first transgender person to win a title at the National \nCollegi ate Athletic Association   \n(45) RIGHT \n/ TIME  the first time and now I'm an Olympic medallist.\" However, Hubbard failed to \nrecord a successful lift. The 43-year -old New Zealander transitioned from male to \nfemale in 2012 after hormone therapy. As a junior Hu bbard competed in male \nweightlifting  competitions but retired aged 23.  \n(46) RIGHT \n/ SUN  Hubbard transitioned from male to female nine years ago , at the age of 34. She had \ncompeted as a male weightlifte r for years before that.  \n(47) LEFT / \nINDE  The IOC policy specifies conditions under which those who transition from male to \nfemale are eligible to compete in the female category . Among them is that the \nathlete has declared that her gender identity is female  \n(48) LEFT / \nGUARD  Her inclusion in Tokyo is partly down to changes to the International Olympic \nCommittee transgender guidelines in 2015, under which athletes who transition \nfrom male to female can compete in the women\u2019s category  without requiring \nsurgery to remove their te stes  \n  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   34 \n(49) LEFT / \nINDE  Former reality TV star told Sean Hannity of a friend who was \u2018packing up his \nhangar\u2019 over issue Jimmy Kimmel slammed Caitlyn Jenner as an \u201cignorant \na**hole\u201d for her comments on homelessness in Los Angeles. Ms Jenner is running \nfor governor of California   \n(50) LEFT / \nINDE  The lives of ordinary trans people, who don't have the same funds or high profiles \nas celebrities like Caitlyn Jenner, seemed largely unchanged . In some ways, the \nfresh focus has made things harder ; look at the v ocal anger of right -wing US groups  \n(51) LEFT / \nINDE  Humphries told The Daily Telegraph. \u201cSelf -mutilation, what\u2019s all this carry on? \nCaitlyn Jenner \u2013  what a publicity -seeking ratbag .\u201d His comments prompted calls for \nHumphries to be sacked from his BBC Radi o 2 show  \n(52) LEFT / \nINDE  'Everyone loved the Games, a lot of people when they see you transition hate your \nguts' Caitlyn Jenner has said that transitioning from male to female was \u201cmuch \nharder\u201d than training for the Olympic Games .  \n  \n(53) RIGHT \n/ TIME  the focus on testosterone is limited because it puts aside the years of biological \nadvancement from male hormones, including height. Transgender former athlete \nCaitlyn Jenner also said she did not support the NCAA. \u201cHer hands are bigger. She \ncan swim faste r. That's a known,\u201d  \n(54) RIGHT \n/ TELE The national governing body for competitive swimming said the policy serves \"to \nmitigate the advantages associated with male puberty and physiology\". Transgender \nformer athlete Caitlyn Jenner is among those to have claimed that Ms Thomas has \nan unfair advantage. \u201cHer hands are bigger. She can swim faster . \n(55) RIGHT \n/ TELE The same outrage was recently heaped on Caitlyn Jenner for saying trans girls, who \nare born with greater muscle mass, should not be permitted to c ompete in women\u2019s \nsport. You could  \n  \n(56) LEFT / \nINDE  prompted a federal lawsuit. They argue that \u201cbiological boys\u201d have innate physical \nadvantages in girls\u2019 and women\u2019s sports that would ruin competition. \u201cWe cannot \nallow the business community to bully the women and girls in Kansas,\u201d  \n(57) LEFT / \nGUARD  Some scientists have said the guidelines do little to mitigate the biological \nadvantages of those who have gone through puberty as males . Advocates for \ntransgender inclusion argue the process of tran sition significantly decreases that \nadvantage  \n(58) LEFT / \nGUARD  is the current International Olympic Committee policy applied across almost every \nsport. However, World Rugby said that new research showed that they retain \n\u201csignificant\u201d physical advantages over biological women even after they take \nmedication to lower their testosterone. All trans women will still be able to play \nnon-contact rugby  \n  \n(59) RIGHT \n/ TELE That\u2019s how I feel about this complex issue. There are some sports where it\u2019s going \nto be e asier than others to mitigate the advantages of being born a biological male . \nCombining full inclusion with a completely level playing field is impossible.  \n(60) RIGHT \n/ TIME  muscle strength is almost negligible for men who transition to become women. That \ncould be significant in sporting terms because it indicates that the physical \nadvantages of biological males are maintained even after transitioning and after \nhormone therapy  to reduce testosterone levels.  \n(61) RIGHT \n/ TIME  testosterone suppression reduced strength by between 0 and 10per cent. This is \ncrucially important - it means that a significant portion of the male biological \nadvantages are retained . The \"fix\" does not work. Critics will argue that these \nstudies are imperfect, not done on athletes  \n(62) RIGHT \n/ TIME  When the US powerlifting body concluded it was unfair for trans women to \ncompete against biological women because male \"advantages such as increased \nbody  and muscle mass, bone density, bone structure, and connective tissue\" remain \nafter testosterone suppression , trans activists disrupted events. (McKinnon believes  \nCOMPARATIVE INVESTIGATION OF MEDIA BIAS   35 \n  \n(63) RIGHT \n/ SUN  Women athletes such as Sharron Davies and Martina Navratilova, who dare to \nvoice their discomfort at what they see as the intrusion of transgendered men into \nwomen's sport , are denounced as bigots or, worse, Terfs: trans-exclusionary radical \nfeminists.  \n(64) RIGHT \n/ SUN  Two states in the US, both Republican - Idaho and Arizona - have passed, or are \npassing, laws that make it illegal for transgendered men to compete against women \nin sport , legislation that the Democrat opposition insists is discriminatory and \n\"transphobic\" . \n(65) RIGHT \n/ SUN  They also argue that this is a piffling issue, given that fewer than 1 per cent of the \npopulation are transgendered. But in a sense, that's rather the problem: that fewer \nthan 1 per cent is punching very strongly above its weight in wom en's \n(66) RIGHT \n/ SUN  Transgendered athletes are winning track -and-field titles in Canada and the US , \nincluding the extremely fast Andraya Yearwood.  \n(67) RIGHT \n/ SUN  The transgendered cyclist Rachel McKinnon , now known as Veronica Ivy (one \nbegins to lose  track, I know), is the UCI Masters World Track Racing champion . \nThe \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Comparative investigation of media bias: How to spot media bias through CDA and CL text analysis", "author": ["M Pozzi"], "pub_year": "2022", "venue": "NA", "abstract": "Comparative Investigation of Media Bias: How to Spot Media Bias through CDA and CL Text  Analysis Page 1 Comparative Investigation of Media Bias: How to Spot Media Bias through"}, "filled": false, "gsrank": 175, "pub_url": "https://www.diva-portal.org/smash/get/diva2:1672058/FULLTEXT02", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:Zr9MD2c-9tsJ:scholar.google.com/&output=cite&scirp=174&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Zr9MD2c-9tsJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 1, "citedby_url": "/scholar?cites=15849924550936280934&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Zr9MD2c-9tsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.diva-portal.org/smash/get/diva2:1672058/FULLTEXT02"}}, {"title": "This is an unpublished working paper that has not undergone peer review", "year": "NA", "pdf_data": "1 \n \nThis is an unpublished working paper that has not undergone peer review  \n \n \n \nCombating misinformation: A megastudy of nine interventions designed to reduce the sharing of \nand belief in false and misleading headlines  \n \n \n \nLisa K. Fazio1, David G. Rand2, Stephan Lewandowsky3, Mark Susmann1, Adam Berinsky2, \nAndrew Guess4, Panayiota Kendeou5, Ben Lyons6, Joanne Miller7, Eryn Newman8, Gordon \nPennycook9, Briony Swire -Thompson10, Building a Better Toolkit Team  \n \n1Vanderbilt University , 2Massachusetts Institute of Technology, 3University of Bristol, \n4Princeton University, 5University of Minnesota, 6University of Utah, 7University of Delaware, \n8Australian National University, 9Cornell University, 10Northeastern University  \n \n \n  \n2 \n \nCombating misinformation: A megastudy of nine interventions designed to reduce the sharing of \nand belief in false and misleading headlines  \n \nConcern about the impact of misinformation on the epistemic integrity of democracy is \nwidespread 1. In addition, misinformation demonstrably affects attitudes and intentions towards \nhealth behaviors  in experiments2 and in real -world situations3,4. In response, r esearchers have \ntested a variety of interventions to combat misinformation on social media5 (e.g., accuracy \nnudge s6, digital literacy tips7, inoculation8, debunking9). These interventions work via different \npsychological mechanisms, but all share the goals of increasing recipients\u2019 ability to distinguish \nbetween true and false information and/or increasing the veracity of news shared on social \nmedia. This toolkit of approaches is useful, but it is currently difficult to compare the \ninterventions because they have been tested in different environments, with different sets of \nstimuli (e.g., headlines vs. tweets), using different particip ants and different methods. These \ndifferences make it difficult to know how the interventions would perform in an equal testing \nenvironment.  \nThe current study addresses this important question by testing nine prominent \nmisinformation interventions in an identical setting. These interventions fall into one of three \ncategories. Three of the interventions - accuracy nudges  (shifting users\u2019 attention to accuracy \nwhile deciding what to share)6,10, descriptive social norms  (indicating that most other users care \nabout accuracy)11, and thinking mode ( having users explain why they think each  headline is true \nor false)12,13 - aim to remind or prompt people to consider the accuracy of information they \nencounter. Four of the selected interventions - debunks of false or misleading claims provided \n3 \nafter exposure9,15, preemptive fact checks for false or misleading claims provided before \nexposure16, source credibility information14, and warning labels on false or misleading claims \nprovided on exposure (as currently used by Facebook)17,18 - provide information about the \nveracity and/or credibility of specific pieces of information. The final two interventions -  \ninoculation19 and media literacy tips7 \u2013 aim to help people recognize false or misleading content \nby educat ing them about common features of misinformation. In a large megastudy (N = 33,233 \nUS respondents), we tested each intervention\u2019s effect on belief in and the sharing of false , \nmisleading , and true  health -related and politic s-related  headlines. This effort is the first time that \na large set of prominent anti-misinformation interventions have been evaluated in a directly \ncomparable way, using the same sample and the same set of stimuli.  \nThe tested interventions were selected by a large team of international and \ninterdisciplinary misinformation researchers who also provided feedback about the research \ndesign and analyses. The team was gathered starting in July 2021 through a mix of direct emails \nto misinformation researchers, snowball sampling, and emails to relevant listservs. In September \nof 2021, each team member was asked to nominate up to five interventions that they wanted to \nsee tested in the megastudy. Seventy -eight researchers nomi nated at least one intervention. Eight \ninterventions were clearly the most popular, (in order: inoculation, accuracy nudge s, debunking, \nmedia literacy tips, source credibility, thinking mode, warning labels, descriptive norms, see \nTable 1 for a description of each intervention). While finalizing the experimental design we \ndecided to also include a preemptive fact -checking con dition where the debunking posts were \ndisplayed before the relevant headline. In order to provide a fair test to each intervention, we  \ndesignated a team lead for each intervention who was invested in that intervention succeeding \nand who finalized the exact implementation.  \n4 \nTable 1 . \nOverview of Intervention s \nIntervention  Description  Visual Example  \nWarnings  Showed a warning that each false and \nmisleading headline was such before \nshowing the headline.  \n \nThinking \nMode  Asked to explain how they knew each \nheadline was true or false.  \n \nSource \nCredibility  Labeled the credibility of the headlines\u2019 \nsources (low, medium, high, satire).  \n \nMedia \nLiteracy Tips  Provided tips for how to assess veracity \nof information, such as considering the \nsource and thinking about why the \nstory was shared.  \n \nInoculation  Warned of prominent misinformation \ntactics and features, such as appeals to \nfear and confirmation bias.  \n \nPreemptive \nFact Checking  False and misleading headlines were \nlabeled as such with brief explanations \nof why the headline was false or \nmisleading.  \n \n\n5 \nDescriptive \nNorms  Informed that the majority of \nAmericans believe others should form \nevidence -based beliefs, only share true \ninformation, and the majority will \nblock those who share false \ninformation.  \n \nAccuracy \nNudge  Rated accuracy of nine neutral \nheadlines.  \n \nDebunking  False and misleading headlines were \nlabeled as such with brief explanations \nof why the headline was false or \nmisleading.  \n \nThe study took part across two rounds, and participants were randomly assigned to one of \nthe nine intervention conditions or a control condition. All participants went through the same \nexperience, h owever, for participants  in an intervention co ndition t he assigned intervention  was \napplied either prior to , during, or after round 1 (see Figure 1) . Within each round, participants \nsaw a series of true, false, and misleading headlines and rated either how accurate they thought \neach headline was or how likely they would be to share each headline . Participants rated the \nsame set of headlines in both round 1 and round 2 to test if the interventions were still effective \nafter a brief delay . Participants also rated a new set of headlines in round 2 to see if the benefits \nwould transfer to novel headlines. The key outcomes of interest were participants' ability to \ndiscern between true and false headlines (i.e. rate true claims as more accurate or more likely to \nshare than false headlines) and to discern between true and misleading headlines20.   \n  \n\n6 \nFigure 1  \nExperimental Procedure for the Experiment  \n \nResults   \nThe effect sizes in the text are reported in terms of the coefficients  from our preregistered \nstatistical model s predicting accuracy or sharing ratings on a 6 -point scale (see Analysis Strategy \nfor details).  For interventions that were only applied to a subset of the headlines, the models only \ninclude the headlines that did receive treatment.  Negative regression coefficients signify \nimprovements in discernment relative to the control condition. Thus , a beta of -.10 for accuracy \ndiscernment indicates that the difference between rating s for true and false headlines was 0.10 \nscale points larger in the intervention condition than in the control condition. For ease of \ninterpretation, we visualize the effects as percent improvement ( \n(\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b  \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 \u2212 \ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc5c\ud835\udc59  \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61\n\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc5c\ud835\udc59  \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61)\u00d7100) in Figure 2.    \n  \n\n7 \nFigure 2  \nEffects of Interventions on Accuracy and Sharing Discernment and Raw Ratings Relative to the \nControl Condition  \n \nNote . Points in the left column discernment graphs represent the percent improvement in \ndiscernment caused by each intervention relative to the control condition  along with 95% \nconfidence intervals . Points in the right column graphs represent the percent change in accuracy \nor sharing ratings for each type of headline relative to the control condition  along with 95% \nconfidence intervals . The graphed values for all interventions other than debunking are \ncalculated from the round 1 data. The values for the deb unking condition are calculated from \nround 2 data.  \n\n8 \nDid the Interventions Increase Accuracy Discernment?  \nImmediate Effects  \n Within round 1, most interventions were effective at increasing accuracy discernment \nbetween true and false ( bs < -.10, ps < .005) and true and misleading ( bs < -.07, ps < .02) \nheadlines relative to the control condition, with some improving discernment by as much as 12% \n(see Figure 2).  The only exception was that the source credibility intervention did not \nsignificantly improve discernment between true and misleading he adlines ( b = -0.02, p = .796).  \n In an exploratory analysis, we compared each pair of interventions using the Holm -\nBonferroni method to correct for multiple -comparisons21. Note that we did not include \ndebunking in the direct comparisons (here or later in the manuscript) since the intervention was \nnot applied during round 1.  For false headlines, media literacy tips increased discernment \nsignificantly more than descriptive norms, inoculation, thinking mode, and warnings ; and \npreemptive fact checking increased discernment more than descriptive norms , thinking mode , \nand warnings . For misleading headlines, media literacy tips increased discernment significantly \nmore than descriptive norms, inoculation, source credibility, and thinking mode ; and w arnings \nincreased discernment significantly more than descriptive norms . No other differences were \nsignificant.  \nIt is also important to consider how the interventions achieved these outcomes20. Some \ninterventions improved discernment primarily by increasing accuracy ratings of true headlines, \nothers by reducing accuracy ratings of false and misleading headlines, and others by doing both. \nSee Table 2 for a full summary of which interventions sig nificantly altered accuracy and sharing \nratings of true, false, and misleading headlines.  \n9 \nTable 2.  \nComposition of Intervention Effects of Accuracy and Sharing Discernment  \n \nNote. Only interventions that had significant effects on the respective true, false, and/or \nmisleading accuracy and sharing ratings are included in this table.  The double arrow in the \nbottom row indicat es that the intervention decreased ratings for all items, but more so for fa lse \nand misleading ite ms.  \n Of note, there was differential attrition (i.e., different proportions  of participants \ndiscontinuing the experiment before completion) between the control condition and several \n\n10 \nintervention conditions both by the end of round 1 and by the end of round 2 ( see Figure 3). To \nexamine possible impacts of this differential attrition on the observed intervention effects, we \nconducted a combination of additional data collection and analyses. In brief, we recontacted all \nparticipants who dropped out of the experiment and invited  them to participate in a follow -up \nexperiment. This experiment was identical to the control condition of the main experiment and \nwas intended to assess the baseline accuracy or sharing discernment of those who dropped out of \nthe main experiment. These dat a were used to impute conservative estimates of missing \ndiscernment scores in the main study. We then examined discernment effects using the dataset \ncontaining the imputed discernment values.  \nFigure 3  \nDifferential Attrition by Intervention Condition.  \n \nNote. The dotted blue line represents the level of attrition in the control condition after round 1. \nThe dotted red line represents the level of attrition in the control condition after round 2.  \n\n11 \nThe pattern of results observed in our main analyses largely replicated in the imputed \ndataset, with most intervention effects not changing in whether they were significan t. For round \n1 accuracy discernment, the only exception was the thinking mode intervention, where after \naccounting for attritions, its effects on false and misleading accuracy discernment were no longer \nsignificant.  When comparing across conditions in the imputed dataset  the same comparisons \nwere again significant. In addition,  for false h eadlines, media literacy tips increased discernment \nmore than source credibility  and preemptive fact checking increased discernment more than \ninoculation. For misleading items, media literacy tips also increased discernment significantly \nmore than preemptive fact checking , warnings were more effective than source credibility  and \nthinking mode , and preemptive fact checking increased discernment more than source \ncredibility.  \nEffects After a Brief Delay  \n After an approximately 3\u20136-minute  delay , participants complete d round 2 in which they \nwere re -presented with the headlines from round 1. For content -specific interventions that \nprovided information about specific headlines in round 1 ( i.e., warnings, source credibility, and \npre-emptive fact checks ), the intervention was not re -applied in round 2 (that is, the headlines \nwere presented in round 2 as if they were in the control condition). Participants in the warning, \npreemptive fact checking, and descriptive norms conditions no longer showed significant \nimprovements in discernment between true and misleading headlines in round 2 ( bs > -0.06, ps \n>= .057). Warnings also no longer showed significant discernment improvement for false \nheadlines ( b = -0.03, p = .428). No other discernment effects changed in significance between \nrounds 1 and 2. Overall, the interventions that saw the most decay in their effect sizes between \nrounds 1 and 2 were tho se applied to individual items (preemptive fact checking, source \n12 \ncredibility and warnings; see Figure 4), likely because participants forgot which items were \npreviously labeled as false, misleading or coming from a low credibility source . \n \nFigure 4 \nPercentage of Round 1 Effect Still Present After a Delay in Round 2 by Intervention Condition.  \n \n Round 2 provided the first opportunity to evaluate the effectiveness of the debunking \nintervention, which significantly benefited discernment between true and false ( b = -0.28, p < \n.001) and true and misleading ( b = -0.24, p < .001) headlines. Differential attrition did not \nnotably impact the interpretation of round 2 results. The only exception was the descriptive \nnorms intervention, where the increase in accuracy discernment between true and false headlines \nin round 2 was no longer significant after imputing missing values.   \nDid the Interventions Increase Sharing Discernment?  \nImmediate Effects  \n\n13 \n All interventions improved sharing discernment between both true and misleading and \ntrue and false headlines relative to the control condition ( bs < -0.15, ps < .016; see Figure 2). The \ninterventions were also relatively consistent in how they achieved these discernment effects: All \ninterventions significantly reduced sharing intentions for false ( bs < -0.23, ps < .001) and \nmisleading ( bs < -0.09, ps < .047) headlines. Conversely, no interventions other than thinking \nmode produced a significant effect on sharing ratings of true headlines, with thinking mode \nsignificantly decreasing sharing likelihood for those headlines ( b = -0.38, p < .001). Accounting \nfor diff erential attrition  did not change the significance of any of these effects .  \nIn an exploratory analysis comparing the effects across condition (again using the Holm -\nBonferroni correction) , media literacy tips increased sharing discernment for both false and \nmisleading headlines significantly more than all of the other interventions . For false headlines, \ninoculation was significantly more effective than descriptive norms, warnings and accuracy \nnudges while preemptive fact checking was more effective than descriptive norms. For \nmisleading items, both inoculation and preemptive fact ch ecking were significantly more \neffective than descriptive norms and accuracy nudges. No other differences were significant. \nAfter accounting for attrition , the significant comparisons were similar . However,  for false \nsharing discernment , inoculation was no longer significantly more effective than accuracy \nnudges and preemptive fact checking was now also better than warnings . For misleading \nheadlines,  the same comparisons were significant along with preemptive fact checking \noutperforming source credibility and thinking mode increasing discernment more than accuracy \nnudges and descriptive norms.  \nEffects After a Brief Delay  \n14 \n All interventions\u2019 benefits to discernment between both true and false and true and \nmisleading headlines remained significant in round 2 ( bs < -0.10, ps < .001). These results were \nalso r obust to differential attrition. Though the interventions applied to individual items showed \nthe most decay in their effect sizes between rounds 1 and 2, the decrease was less pronounced \nthan the decay observed for accuracy discernment (see Figure 4).  \nDiscussion  \nThe current findings suggest that a wide variety of interventions can improv e discernment \nbetween true versus false or misleading information during accuracy and sharing judgments. We \ncompared nine different interventions on a level playing field, and the interventions, largely, \nshowed benefits as compared to the control condition. Reducing misinformation belief and \nsharin g is a goal that is accomplishable through multiple strategies targeting different \npsychological mechanisms.  \nInterestingly, most of the interventions had similarly -sized  effects on discernment. That \nsaid, media literacy tips were particularly effective in our study, outperforming most of the other \ninterventions for both accuracy and sharing discernment. In addition,  even when effective, the \ninterventions benefited discernment in different ways. Thus, the ideal intervention for a given \nsituation will depend on the current context and one\u2019s goals. For instance, if an organization \nhighly values increasing belief in true  information, they might consider media literacy tips, \nwhich increased belief in true information, over  preemptive  fact checking and debunking, which \nreduced belief in true information. However, if the primary aim is to reduce belief in false and/or \nmislea ding information (e.g., the misinformation is particularly harmful), fact checking and \ndebunking might be more appealing.   \n15 \n The interventions also differed in the duration of their effects. In general, interventions \nfocused on teaching new skills (inoculation and media literacy) showed less decay than \ninterventions that labeled specific pieces of content as reliable or unrelia ble (preemptive fact \nchecking, source credibility, warnings). Again, the usefulness of a given intervention depends on \none\u2019s goals. For some misinformation, the highest priority is getting people to stop engaging \nwith the headline at the moment of exposure . In these cases, item -specific interventions such as \nwarnings and fact checks can be very effective. However, they may not protect people if they are \nexposed to the same false information minutes or days later without the label. In contrast, \ncontent -neutr al interventions like inoculation or media literacy will have more lasting effects, but \ncan only protect people against misinformation that is easily detected as false. More plausible \nfalse information that is presented without any of the cues people are t aught to look for will go \nunnoticed and uncorrected.  \nAnother key way in which the interventions differed, from an application perspective, \nwas in how long they took to administer, and how feasible they would be to deploy in the field. \nFor example, the media literacy and inoculation interventions as deployed here forced \nparticipants to stay on each screen of the intervention for a minimum length of time (the exact \nvalue varied across screens, but was always more than 10s per screen)  in order to ensure that \neach intervention was comparable . This forced exposure  led to higher numbers of participants \ndropping out of the survey during those interventions (see Fig 3). Thus, some organizations (e.g. , \nsocial media companies) may be hesitant to apply such interventions because of negative impacts \non the user experience. Future work should test the effectiveness of such interventions when \ndelivered in a manner where participants were not forced to view t hem for a minimum duration.  \n16 \nAn additional intriguing question is whether the efficacy of the tested interventions might \nbe enhanced when they are combined with other interventions. Past research has demonstrated \nthat combining interventions can sometimes yield better results than adm inistering just a single \nintervention22, but past research in this space is limited and it remains unclear how generalizable \nthis approach might be and what factors, if any, might lead certain interventions to synergize \nbetter or worse with others.        \nLimitations  \nGiven the design of this experiment, it was not possible to include all misinformation \ninterventions found to be efficacious. For example, lateral reading is a promising intervention \nthat involves teaching people how to seek out additional information outs ide of the information \nbeing assessed to better evaluate that information\u2019s veracity23,24. Because the present experiment \nwas conducted online and was designed to be relatively brief, it would have been infeasible to \nquickly teach people how to do lateral reading and track whether participants actually engaged in \nthe activity. It is important to keep designing and testing more involved misinformation \ninterventions rather than only the light -touch interventions tested here.   \nRelatedly, we only tested a single version of each intervention. Yet there are many \ndifferent ways to operationalize each intervention. For example, warnings may use different \nkinds of labels (e.g. , the label in our warning condition was only applied on the screen before \nrating, and not on the screen where participants actually entered their ratings \u2013 which might \nexplain why warnings were less effective here than in most past research25. Similarly, many \ndifferent forms of inoculation have been proposed (e.g. , games, videos, etc .) and many different \nspecific techniques have been targeted by inoculation; and there are many different possible \n17 \ndigital media tips that might be shown. How the results found here generalize to other \noperationalizations is a key question for future work.  \nThe current study was designed to be similar to how people would be exposed to online \npolitical and health information, but it is of course not a perfect analog to actual real -world \nsetting. Perhaps most importantly, we were only able to measure people\u2019s i ntentions to share the \nheadlines rather than their actual sharing behavior. However, prior research suggests that sharing \nintentions are a useful surrogate for real -world shares. Self -reported sharing intentions correlate \nstrongly with actual sharing on Tw itter, and \u2013 even more importantly \u2013 there are very similar \nassociation patterns between news characteristics and both sharing intentions and actual \nsharing26. Furthermore, an accuracy  nudge  intervention developed using sharing intentions from \nsurveys was found to also be effective in Twitter and Facebook field experiments10,27.  \nConclusion  \nThe present experiment, for the first time in the literature, examined a wide variety of \npromising misinformation interventions in a high -powered mega experiment and found them to \nall perform well when examined on a level playing field. These findings suggest that \npractitioners have a plentiful toolbox of intervention approaches to choose from when working to \ncombat misinformation belief and spread. As such, our results suggest that, rather than it being a \nquestion of whether a given intervention is effective per se, the way in which an intervention is \neffective (i.e. , whether it inc reases belief in and/or sharing of true information and/or reduces \nbelief in and/or sharing of false or misleading information) might be the larger determinant of \nintervention selection along with practical implementation constraints. Ultimately, the prese nt \nresults are hopeful, and suggest that a variety of approaches to combat misinformation can be \nsuccessful.   \n18 \nMethods  \nEthics statement and reproducibility  \n This experiment received ethics approval from a university institutional review board.  \nParticipants  \nParticipants were recruited from the American population using online participant panels \nfacilitated by Forthright Access, Luth Research, and InnovateMR and participated in exchange \nfor monetary compensation. A total of 37,092 participants started the expe riment. Of those, \n36,067 got to the intervention instructions of the intervention condition to which they were \nassigned (or the control instructions for those in the control condition), 33,233 completed round \n1, and 30,134 completed round 2. Sampling quota s were used to ensure that the final sample of \nparticipants who completed the study were nationally representative on age, gender, \nrace/ethnicity, and region based on US census data.    \nInterventions  \nIn order to ensure similarity across the conditions, participants were required to stay on \nsome survey pages for a minimum amount of time. These minimum times were determined by \ncalculating the expected reading time for each instruction/material based on w ord count and then \ndividing that number in half. Delays were applied to the key instruction slides for the descriptive \nnorms (11 seconds), media literacy tips (16s and 12s), and inoculation (13s per slide) \ninterventions. In addition, we included minimum ti mes for the presentation of the debunking and \nfact checking images (7s each) and the warnings (1s each).  \nAccuracy Nudge  \n19 \n Before round 1, participants rated the accuracy of nine headlines that were unrelated to \npolitics or health (see Table 1 for an example). This intervention adapted best -practice methods \nused in past research.11,28  \nDebunking  \nThe debunking condition was identical to the control condition in round 1 of the \nexperiment. Following round 1 and before round 2, participants were shown debunks one at a \ntime. Each debunk labeled one of the false or misleading headlines seen in round 1 b y a \nparticipant as being false or misleading and included a brief explanation as to why (see Table 1 \nfor an example). This condition followed best practices used in prior research examining \nmisinformation corrections.29,30 \nDescriptive Norms  \n Before starting round 1, participants were presented with information stating that \nAmericans see accu racy as a central value regardless of party affiliation. They were also told \nover 80% of Americans said people should rely on evidence when forming beliefs and that over \n80% said it is important to only share true information on social media. Participants were also \ntold that a large majority of Americans report being likely to block people who share false news. \nAll presented information was accurate and taken from previous studies31\u201333. This condition \nborrowed from methods used in past work examining impacts of norms on misinformation belief \nand sharing.34,35 \nPreemptive Fact Checking  \n20 \n During round 1, participants saw a fact check of some false and misleading headlines \nbefore viewing the plain headline and rating it. These fact checks were identical to the debunks \nused in the debunking intervention.  \nInoculation  \n This intervention mirrored interventions used previously to inoculate against \nmisinformation tactics.8,19,36 \u201338 Before round 1, participants were told they would first be \npresented with information to help them better evaluate the headlines they would see. \nParticipants were then presented with a series of slides that contained information about common \nmanipulation tactics employed in false media, including outrage manipulation, fear exploitation, \nand confirmation bias.  \nMedia Literacy Tips  \n Methods used in prior research examining media literacy tips were adapted for use in the \nstudy.39 Prior to round 1, participants were told they would first see information that would aid \nthem in evaluating the headlines. They were then shown a list of seven  tips about how to \nscrutinize the veracity of media content, such as considering the source of the headline and \nthinking about why the story might have been shared to begin with.  \nSource Credibility  \nThis intervention follows from work finding that source credibility predicts \nmisinformation sharing.14 During round 1, headlines included labels that indicated the credibility \nof the source of each headline. Credibility ratings were sourced from Media Bias/Fact Check \n(https://mediabiasfactcheck.com/ )  and included four ratings: high credibility, medium \ncredibility, low credibility, and satire.  \n21 \nThinking Mode  \nMethods used for this intervention were similar to those used in past research.40,41 Before \nstarting  round 1, participants were told that they would be asked to explain how they knew that \neach headline was true or false. For each headline participants saw during round 1, they were \npresented with an open -ended text -entry box and instructe d to explain how they knew the \nheadline was true or false. After doing this, they were then asked to rate its accuracy or how \nlikely they would be to share it.  \nWarnings  \n This intervention adopted best practices from research examining misinformation \nwarnings.25 For some false and misleading headlines in round 1, participants would first view a \nwarning screen that contained a grayed out and blurred image of the headline with text that stated \nthat the information was false or misleading and that it was checked by independent fact -\ncheckers (see Table 1 for an example).  \nHeadlines  \nThe key stimuli were 80 true, false and misleading social media posts with a picture, \nsource, and headline (10 false medical, 10 misleading medical, 10 true medical, 20 false \npolitical, 10 misleading political, 20 true political). True headlines were selec ted from reliable \nnews organizations while the false headlines were selected from headlines rated as \u201cfalse\u201d by \nfact-checking websites and directly from websites that published other stories that were fact -\nchecked as false. The misleading headlines were so urced from fact -checking websites and were \nrated as \u201cmostly false\u201d or \u201cmixed\u201d and/or used at least one misleading technique (e.g., logical \nfallacy, missing context, polarization, emotional manipulation).  \n22 \nThe final 80 headlines were selected from a pretest of 461 headlines run on Lucid in \nOctober of 2022. 3,842 participants each rated a random sample of 10 headlines on how \nfavorable the headline was for Democrats vs Republicans (partisanship), the likelihoo d the \nheadline was true (accuracy), the level of sensationalism/exaggeration, the importance of the \nheadline, their familiarity with the headline, and how likely they would be to share the post on \nsocial media (sharing). On average, each headline was rated  by 34 Democrats and 28 \nRepublicans.  \nWe then selected the key headlines such that for the political headlines, mean ratings for \nthe pro -Democrat and pro -Republican headlines were within a decimal point of each other for (a) \npartisanship, (b) accuracy, and (c) sharing. Thus, the pro -Democratic  headlines were as pro -\nDemocratic as the pro -Republican headlines were pro -Republican. Furthermore, Democrats \nviewed the pro -Democratic headlines as equally accurate/shareable as Republicans did for the \npro-Republican headlines. For the medical headlines, we ignored partisanship and simply \nmatched Democrats and Republicans on (a) accuracy and (b) sharing (again, all within a decimal \npoint).  \nProcedure  \n After providing informed consent, participants were asked to report their political \npartisan affiliation, their political ideology, feeling thermometer ratings of the Republican and \nDemocratic Parties , and their social media digital literacy  \n Next, participants were randomly assigned to one of the nine intervention conditions or to \nthe control condition, and to provide either accuracy or sharing outcome ratings (19 conditions \n23 \ntotal1). After reading initial instructions and/or materials for whichever condition they were \nassigned, participants engaged in the round 1 headline rating task. For each participant, 18 \nheadlines were presented. These headlines were selected from the larger headline pool. The \nselection process was such that participants viewed 3 headlines from each of the veracity (true, \nfalse, misleading) X headline type (medical, political) subpools of headlines. The three headlines \nwere selected randomly. In the fact checking and warning conditions, fact checks and warnings \nwere applied to two out of the three headlines selected from the subpools containing false or \nmisleading headlines. These interventions were not a pplied to any of the true headlines. In the \nsource credibility condition, credibility labels were applied to \u2154 of the headlines from all \nsubpools. Participants viewed the headlines in random order one at a time and, depending on \ncondition, rated either how  accurate they considered the headline to be or how likely they would \nbe to share the headline. For accuracy, participants were asked \u201cTo the best of your knowledge, \nis the above headline accurate?\u201d and responded on a 6 -point scale where 1 = Definitely \nInaccurate and 6 = Definitely Accurate. For sharing, participants were asked \u201cIf you were to see \nthe above headline online, how likely would you be to share it?\u201d and responded on a 6 -point \nscale where 1 = Very Unlikely and 6 = Very Likely.  Sharing likelihood was the only outcome \nassessed in the accuracy nudge condition.  \nAfter completing round 1, participants in the debunking condition viewed debunks of \nsome of the false and misleading headlines they had seen in round 1. As in the fact checking and \nwarning conditions, debunks for only \u2154 of the false and misleading headline s from each subpool \nwere presented. In all other conditions, participants viewed a series of eight neutral headlines. \n \n1 Given that the accuracy nudge intervention is identical to the accuracy dependent variable (rating the \naccuracy of headlines), we only measured sharing intentions for participants in the accuracy nudge \ncondition.  \n24 \nThese generic headlines were included to equate the time spent between round 1 and round 2 in \nthese conditions with the time spent in between rounds by those in the debunking condition.  \nParticipants then completed round 2  with 24 headlines . In round 2, no interventions were \napplied to any of the headlines in any of the intervention conditions. Participants again rated how \naccurate they thought each headline was or how likely they were to share each headline \n(matching the type of rating they  gave in round 1). Participants rated all of the headlines they \nrated in round 1 in addition to one new headline from each of the veracity X headline type \nsubpools. After round 2, participants responded to an anti -establishment beliefs measure42. \nParticipants were then debriefed on the purpose of the study and shown the fact checks used in \nthe fact checking and debunking claims for all false and misleading headlines they had seen \nduring the study.      \nAnalysis strategy  \n Our analytical approach followed our preregistered analysis plan with a few minor \ndepartures noted below. All analyses reported in the main manuscript excluded headlines that did \nnot receive intervention treatments in conditions that targeted headlines individually (debunking, \nfact checking, source credibility, warnings). Additionally, because the debun king intervention \ncondition was identical to the control condition during Round 1, all analyses examining Round 1 \neffects pooled participants from the control and debunking conditions. Finally, though our \npreregistered analysis plan called for excluding al l participants who did not complete the \nexperiment from all analyses, we opted to deviate from this plan by including all participants \nwho completed the study through the part of the study containing the outcome of interest for \neach analysis. Namely, for a nalyses examining round 1 outcomes, all participants who completed \n25 \nround 1, regardless of whether they finished the rest of the experiment, were included in the \nanalyses. We did this to ensure maximum power for all analyses performed.   \nAnalyses predicting Round 1 and Round 2 accuracy and sharing likelihood ratings were \nconducted using the same multiple regression analyses. Because each participant rated a variety \nof different headlines, and because the headlines were shared across partic ipants, 2 -way clustered \nstandard errors clustered on participant id and headline were used to account for these \ndependencies in the data.  \n Models were constructed predicting the outcome (Round 1 or Round 2 accuracy or \nsharing ratings) from the following predictors. Two dummy coded variables, one representing \nfalse headlines (1 = false headlines, 0 = true and misleading headlines), and the ot her \nrepresenting misleading headlines (1 = misleading headline, 0 = true and false headlines) were \nincluded in the model. As such, true headlines acted as the reference group in these analyses. \nEach of these dummy codes was interacted with intervention con dition (represented as nine \ndummy coded variables, with each corresponding to each of the different interventions. For \nexample, for the dummy coded variable corresponding to accuracy nudges, 1 = accuracy nudge, \n0 = all other intervention conditions etc.).2 The control condition acted as the reference group for \nthese dummy coded variables. Participant demographic variables, including age, gender, \nethnicity, race, income, and education, were also included in the models as covariates, and each \nwas interacted w ith each of the headline veracity dummy coded variables.   \n \n2Because we did not assess accuracy ratings for the accuracy nudge intervention, analyses predicting \naccuracy excluded the dummy code that corresponded to the accuracy nudge condition. Likewise, \nbecause data from the debunking condition was pooled with data  from the control condition for Round 1 \nanalyses, the dummy coded variable corresponding to debunking was omitted from analyses examining \nRound 1 outcomes.  \n26 \nWithin these models, key effects of interest were discernment , or the propensity of \nparticipants to rate true headlines as being more accurate than false headlines and true more \naccurate than misleading headlines, or reporting being more likely to share true headlines than \nfalse headlines or misleading headlines. Gi ven the construction of these models, discernment was \ntested by the interaction between the dummy code for each intervention and the dummy code \nrepresenting false headlines or misleading headline s. For example, a significant negative \ninteraction coefficient between the fact checking dummy variable and the false headlines dummy \nvariable predicting accuracy ratings indicates that participants in the fact checking condition \nrated false headlines as b eing less accurate than true headlines to a significantly greater extent \nthan participants in the control condition.   \nAdditional exploratory models were conducted to examine the overall mean differences \nin accuracy and sharing ratings between the control condition and each intervention condition for \nfalse, misleading, and true headlines. Note that these analyses were not part of our preregistered \nanalysis plan. These models were constructed predicting accuracy or sharing ratings from the \ndummy codes representing each of the intervention conditions, and participant demograph ics \nwere included as control main effect terms. Standard errors were again calculated clustered by \nparticipant id and headline. For each model, data from only true, misleading, or false headlines \nwere included to allow for examination of effects within eac h headline type.   \n \n \n  \n27 \nReferences  \n1. Lewandowsky, S. et al.  Misinformation and the epistemic integrity of democracy. Curr. \nOpin. Psychol.  54, 101711 (2023).  \n2. Schmid, P., Altay, S. & Scherer, L. D. The Psychological Impacts and Message Features of \nHealth Misinformation: A Systematic Review of Randomized Controlled Trials. Eur. \nPsychol.  28, 162 \u2013172 (2023).  \n3. Allen, J., Watts, D. J. & Rand, D. G. Quantifying the impact of misinformation and vaccine -\nskeptical content on Facebook. Science  384, eadk3451 (2024).  \n4. Bursztyn, L., Rao, A., Roth, C. & Yanagizawa -Drott, D. Misinformation During a \nPandemic . w27417 http://www.nber.org/papers/w27417.pdf (2020) doi:10.3386/w27417.  \n5. Kozyreva, A. et al.  Toolbox of individual -level interventions against online misinformation. \nNat. Hum. Behav.  1\u20139 (2024) doi:10.1038/s41562 -024-01881 -0. \n6. Pennycook, G. & Rand, D. G. Accuracy prompts are a replicable and generalizable approach \nfor reducing the spread of misinformation. Nat. Commun.  13, 2333 (2022).  \n7. Guess, A. M. et al.  A digital media literacy intervention increases discernment between \nmainstream and false news in the United States and India. Proc. Natl. Acad. Sci.  117, 15536 \u2013\n15545 (2020).  \n8. Lewandowsky, S. & Van Der Linden, S. Countering Misinformation and Fake News \nThrough Inoculation and Prebunking. Eur. Rev. Soc. Psychol.  32, 348 \u2013384 (2021).  \n9. Chan, M. S., Jones, C. R., Hall Jamieson, K. & Albarrac\u00edn, D. Debunking: A meta -analysis \nof the psychological efficacy of messages countering misinformation. Psychol. Sci.  28, \n1531 \u20131546 (2017).  \n28 \n10. Pennycook, G. et al.  Shifting attention to accuracy can reduce misinformation online. Nature  \n592, 590 \u2013595 (2021).  \n11. Epstein, Z. et al.  Developing an accuracy -prompt toolkit to reduce COVID -19 \nmisinformation online. Harv. Kennedy Sch. Misinformation Rev.  (2021) doi:10.37016/mr -\n2020 -71. \n12. Fazio, L. K. Pausing to consider why a headline is true or false can help reduce the sharing \nof false news. Harv. Kennedy Sch. HKS Misinformation Rev.  (2020) doi:10.37016/mr -2020 -\n009. \n13. Pillai, R. M. & Fazio, L. K. Explaining Why Headlines Are True or False Reduces Intentions \nto Share False Information. Collabra Psychol.  9, (2023).  \n14. Nedelcu, D. & Blaban, D. C. The Role of Source Credibility and Message Credibility in \nFake News Engagement. Perspectives from an Experimental Study. J. Media Res.  14, 42\u201362 \n(2021).  \n15. Lewandowsky, S. et al.  The Debunking Handbook 2020. Copyr. Fair Use Sch. Commun. Etc  \n(2020).  \n16. Prike, T., Blackley, P., Swire -Thompson, B. & Ecker, U. K. H. Examining the replicability \nof backfire effects after standalone corrections. Cogn. Res. Princ. Implic.  8, 39 (2023).  \n17. Brashier, N. M., Pennycook, G., Berinsky, A. J. & Rand, D. G. Timing matters when \ncorrecting fake news. Proc. Natl. Acad. Sci.  118, (2021).  \n18. Grady, R. H., Ditto, P. H. & Loftus, E. F. Nevertheless, partisanship persisted: fake news \nwarnings help briefly, but bias returns with time. Cogn. Res. Princ. Implic.  6, 52 (2021).  \n29 \n19. Roozenbeek, J., van der Linden, S., Goldberg, B., Rathje, S. & Lewandowsky, S. \nPsychological inoculation improves resilience against misinformation on social media. Sci. \nAdv. 8, eabo6254 (2022).  \n20. Guay, B., Berinsky , A. J., Pennycook, G. & Rand, D. How to think about whether \nmisinformation interventions work. Nat. Hum. Behav.  7, 1231 \u20131233 (2023).  \n21. Holm, S. A Simple Sequentially Rejective Multiple Test Procedure. Scand. J. Stat.  6, 65\u201370 \n(1979).  \n22. Bak-Coleman, J. B. et al.  Combining interventions to reduce the spread of viral \nmisinformation. Nat. Hum. Behav.  6, 1372 \u20131380 (2022).  \n23. Wineburg , S. & McGrew, S. Lateral Reading: Reading Less and Learning More When \nEvaluating Digital Information. SSRN Electron. J.  (2017) doi:10.2139/ssrn.3048994.  \n24. Breakstone, J. et al.  Lateral reading: College students learn to critically evaluate internet \nsources in an online course. Harv. Kennedy Sch. Misinformation Rev.  (2021) \ndoi:10.37016/mr -2020 -56. \n25. Martel, C. & Rand, D. G. Misinformation warning labels are widely effective: A review of \nwarning effects and their moderating features. Curr. Opin. Psychol.  54, 101710 (2023).  \n26. Mosleh, M., Pennycook, G. & Rand, D. G. Self -reported willingness to share political news \narticles in online surveys correlates with actual sharing on Twitter. PLOS ONE  15, e0228882 \n(2020).  \n27. Lin, H. et al.  Reducing misinformation sharing at scale using digital accuracy prompt ads. \nPreprint at https://doi.org/10.31234/osf.io/u8anb (2024).  \n30 \n28. Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G. & Rand, D. G. Fighting COVID -19 \nMisinformation on Social Media: Experimental Evidence for a Scalable Accuracy -Nudge \nIntervention. Psychol. Sci.  31, 770 \u2013780 (2020).  \n29. Walter, N., Brooks, J. J., Saucier, C. J. & Suresh, S. Evaluating the Impact of Attempts to \nCorrect Health Misinformation on Social Media: A Meta -Analysis. Health Commun.  36, \n1776 \u20131784 (2021).  \n30. Walter, N. & Tukachinsky, R. A Meta -Analytic Examination of the Continued Influence of \nMisinformation in the Face of Correction: How Powerful Is It, Why Does It Happen, and \nHow to Stop It? Commun. Res.  47, 155 \u2013177 (2020).  \n31. Arechar, A. A. et al.  Understanding and combatting misinformation across 16 countries on \nsix continents. Nat. Hum. Behav.  7, 1502 \u20131513 (2023).  \n32. Pennycook, G. et al.  Shifting attention to accuracy can reduce misinformation online. Nature  \n592, 590 \u2013595 (2021).  \n33. Martel, C., Mosleh, M., Yang, Q., Zaman, T. & Rand, D. G. Blocking of counter -partisan \naccounts drives political assortment on Twitter. PNAS Nexus  3, pgae161 (2024).  \n34. Gimpel, H., Heger, S., Olenberger, C. & Utz, L. The Effectiveness of Social Norms in \nFighting Fake News on Social Media. J. Manag. Inf. Syst.  38, 196 \u2013221 (2021).  \n35. Koo, A. Z. -X., Su, M. -H., Lee, S., Ahn, S. -Y. & Rojas, H. What Motivates People to Correct \nMisinformation? Examining the Effects of Third -person Perceptions and Perceived Norms. \nJ. Broadcast. Electron. Media  65, 111 \u2013134 (2021).  \n36. Maertens, R., Anseel, F. & Van Der Linden, S. Combatting climate change misinformation: \nEvidence for longevity of inoculation and consensus messaging effects. J. Environ. Psychol.  \n70, 101455 (2020).  \n31 \n37. Maertens, R., Roozenbeek, J., Basol, M. & Van Der Linden, S. Long -term effectiveness of \ninoculation against misinformation: Three longitudinal experiments. J. Exp. Psychol. Appl.  \n27, 1\u201316 (2021).  \n38. Van Der Linden, S. Misinformation: susceptibility, spread, and interventions to immunize \nthe public. Nat. Med.  28, 460 \u2013467 (2022).  \n39. Guess, A. M. et al.  A digital media literacy intervention increases discernment between \nmainstream and false news in the United States and India. Proc. Natl. Acad. Sci.  117, 15536 \u2013\n15545 (2020).  \n40. Fazio, L. Pausing to consider why a headline is true or false can help reduce the sharing of \nfalse news. Harv. Kennedy Sch. Misinformation Rev.  (2020) doi:10.37016/mr -2020 -009. \n41. Pillai, R. M. & Fazio, L. K. Explaining Why Headlines Are True or False Reduces Intentions \nto Share False Information. Collabra Psychol.  9, (2023).  \n42. Uscinski, J. E. et al.  American Politics in Two Dimensions: Partisan and Ideological \nIdentities versus Anti\u2010Establishment Orientations. Am. J. Polit. Sci.  65, 877 \u2013895 (2021).  \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "This is an unpublished working paper that has not undergone peer review", "author": ["LK Fazio", "DG Rand", "S Lewandowsky", "M Susmann"], "venue": "NA", "pub_year": "NA", "abstract": "Concern about the impact of misinformation on the epistemic integrity of democracy is  widespread 1. In addition, misinformation demonstrably affects attitudes and intentions towards"}, "filled": false, "gsrank": 177, "pub_url": "https://files.osf.io/v1/resources/uyjha/providers/osfstorage/6678749253d5b903a2f65fad?format=pdf&action=download&direct&version=1", "author_id": ["AUtiwQQAAAAJ", "C0ANojIAAAAJ", "_A7rrswAAAAJ", "6wPVeZ8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Cw-CZhXNzPgJ:scholar.google.com/&output=cite&scirp=176&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Cw-CZhXNzPgJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:Cw-CZhXNzPgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.osf.io/v1/resources/uyjha/providers/osfstorage/6678749253d5b903a2f65fad?format=pdf&action=download&direct&version=1"}}, {"title": "Wikipedia and Westminster: Quality and dynamics of Wikipedia pages about UK politicians", "year": "2020", "pdf_data": "WIKIPEDIA AND WESTMINSTER : QUALITY AND DYNAMICS OF\nWIKIPEDIA PAGES ABOUT UK P OLITICIANS\nA P REPRINT OF ACCEPTED PUBLICATION AT THE 31STACM C ONFERENCE ON HYPERTEXT AND SOCIAL\nMEDIA (HT\u201920)\nPushkal Agarwal\nKing\u2019s College London\nLondon, UK\npushkal.agarwal@kcl.ac.ukMiriam Redi\nKing\u2019s College London\nLondon, UK\nmiriam.redi@gmail.comNishanth Sastry\nKing\u2019s College London\nLondon, UK\nnishanth.sastry@kcl.ac.uk\nEdward Wood\nUK Parliament\nLondon, UK\nwoode@parliament.ukAndrew Blick\nKing\u2019s College London\nLondon, UK\nandrew.blick@kcl.ac.uk\nJune 25, 2020\nABSTRACT\nWikipedia is a major source of information providing a large variety of content online, trusted by\nreaders from around the world. Readers go to Wikipedia to get reliable information about different\nsubjects, one of the most popular being living people, and especially politicians. While a lot is\nknown about the general usage and information consumption on Wikipedia, less is known about\nthe life-cycle and quality of Wikipedia articles in the context of politics. The aim of this study is\nto quantify and qualify content production and consumption for articles about politicians, with a\nspeci\ufb01c focus on UK Members of Parliament (MPs).\nFirst, we analyze spatio-temporal patterns of readers\u2019 and editors\u2019 engagement with MPs\u2019 Wikipedia\npages, \ufb01nding huge peaks of attention during election times, related to signs of engagement on other\nsocial media (e.g. Twitter). Second, we quantify editors\u2019 polarisation and \ufb01nd that most editors\nspecialize in a speci\ufb01c party and choose speci\ufb01c news outlets as references. Finally we observe that\nthe average citation quality is pretty high, with statements on \u2018Early life and career\u2019 missing citations\nmost often (18%).\nKeywords wikipedia; politics; editors; polarisation\n1 Introduction\nPolitical communication is de\ufb01ned by Brian McNair as \u201cpurposeful communication about politics\u201d [1]. It includes\n(inter alia) communication about politicians and other political actors, and their activities, as contained in news reports,\neditorials, and other forms of media discussion of politics such as large-scale online encyclopedias like Wikipedia.\nInformation about politics on Wikipedia would appear to ful\ufb01l at least three of the functions of the communication\nmedia in \u2018ideal-type\u2019 democratic societies as described by McNair: informing citizens of what is happening around\nthem; educating as to the meaning and signi\ufb01cance of the \u2018facts\u2019; and publicising the activities of governmental and\npolitical institutions [1].\nWikipedia\u2019s political content is pretty extensive. For example, all 650 elected Members of the Parliament (MPs) in the\nUnited Kingdom (UK) have a Wikipedia page or article1. Such content is also widely reused by the broader web: due\n1We use the terms \u2018page\u2019 and \u2018article\u2019 interchangeably. The dataset we collected from these articles is available for the research\ncommunity here: tiny.cc/wikipedia-mpsarXiv:2006.13400v1  [cs.SI]  24 Jun 2020\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\nto the popularity of Wikipedia as a platform, the top results returned by search engines queried for MPs show links to\ntheir Wikipedia pages.\nGiven the visibility of Wikipedia, and the importance of the online encyclopedia in forming public opinion, the in-\ntegrity and completeness of its content is crucial, especially during \u201ctimes of shock\u201dsuch as elections or referenda\n[2, 3]. To ensure information quality, Wikipedia editors operate in compliance with the core content policies of Neu-\ntrality and Veri\ufb01ability2. However, the scale of information and the free-to-edit Wikipedia policy sometimes limit the\ncapability of communities to maintain the quality and neutrality of Wikipedia pages, and little is known about the\nlife-cycle and quality of Wikipedia articles in the context of politics.\nIn this paper, we contribute to political communication studies by investigating, for the \ufb01rst time, citizens\u2019 engagement\nwith politicians through the lens of the largest online encyclopedia. We perform a large-scale quantitative analysis of\ncollective attention, quality, and polarization on Wikipedia pages of Members of Parliament in the UK. To this end,\nwe collect a huge dataset of all edits (231k) and views (160M, since 2015) to UK MPs\u2019 Wikipedia articles. We\n\ufb01rst investigate the spatio-temporal patterns of readers\u2019 and editors\u2019 engagement using the 650 UK MPs\u2019 Wikipedia\narticles. To understand the value of the political information viewed by millions of readers every month, and identify\npotential biases in political content in Wikipedia, we next focus on the polarisation of MP pages\u2019 editors and citations.\nTo do so, we look at editors\u2019 preferences in terms of the political party of the subjects they edit, as well as the overall\npolarisation of the sources across MP Wikipedia articles, and \ufb01nally compute at the quality and completeness of the\ncitations in MP Wikipedia articles. We list these focus areas in the following research questions:\nRQ-1 What are the spatio-temporal patterns on MPs Wikipedia pages? Are there times of heavy edit and pageview\nloads? (\u00a74)\nRQ-2 What is the quality of edits and citations on these pages? Is there polarisation of edits and citations along party\nlines? What is the citation quality? (\u00a75)\nWe \ufb01nd that engagement with MP Wikipedia articles is synchronized with election periods, and that a mild form\nof polarisation exists in editors\u2019 preferences and article references. Furthermore, we verify that citation quality is\ngenerally high.\nCollectively, these \ufb01ndings contribute to an in-depth understanding of political communication via Wikipedia. We\ndiscuss potential implications for information quality monitoring and disinformation studies in \u00a76.\n2 Background and Related Work\nWe now provide some brief background on the UK political system and then discuss related research work on different\nthemes.\nThe UK House of Commons. The UK Parliament has two chambers, of which the House of Commons is the lower\nchamber. It comprises 650 Members of Parliament (MPs) who are elected to represent constituencies by the First-Past-\nThe-Post (FPTP) system. Due to the operation of FPTP, most MPs belong to one of two main parties, Conservative\nand Labour. The UK Parliament created its \ufb01rst website in 1996, featuring a range of parliamentary papers, including\nHansard [4], the near-verbatim report of proceedings of both houses. The parliament website now has extensive\ninformation about individual MPs and how parliament works [5].\nEditors\u2019 Engagement with Wikipedia Wikipedia is a platform where thousands of volunteers revise and add content\nconstantly [6]. The work which is most closely relevant to ours is a recent study which looked at Wikipedia pages of\nmembers of Germany\u2019s parliament (Bundestag) [7, 8]. They show that German MPs use Wikipedia pages to enhance\ntheir image. Changes in pages are made at regular intervals, and signi\ufb01cant peaks in the number of edits are associated\nwith pursuing re-election. In [7], authors use IP based public user edits to identify edits made from within the\nBundestag and characterise types of changes.\nWikipedia pages quality. There are several works on various dimensions of page quality. Certain editors proclaim\ntheir political leaning and form communities [9]. Polarised teams\u2013those consisting of a balanced set of politically\ndiverse editors\u2013may create articles of higher quality than politically homogeneous teams [10]. Citations play a major\nrole in the monitoring of information quality on Wikipedia. To help with this, the Citation Need classi\ufb01er by [11]\ndetermines if a statement requires a citation.\nTo the best of our knowledge, this is the \ufb01rst study looking at political communication in Wikipedia in the context of\nUK Members of Parliament. While [7] focuses on edits coming from inside the German Parliament, our study focuses\n2https://en.wikipedia.org/wiki/Wikipedia:Core_content_policies\n2\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\non a much larger group of edits, and for the \ufb01rst time studies partisanship and neutrality of the Wikipedia editors of\nthe MP wiki pages.\n3 Dataset\nFollowing are details of our dataset of Wikipedia articles for the 650 MPs elected in the 2017 general election. We\nsummarise the distribution of the dataset in Figure 1a.\nPage Views To understand readers\u2019 engagement, we collect the daily page views data on all articles, using Wikime-\ndia\u2019s3page view API.4We use the earliest possible day that can be set (i.e. 01 July 2015) in the Wiki API query, and\nobtain daily page views per MP page until 30 June 2019. In total, we observe over 160M views for 650 pages during\nthis period.\nPage Edits We crawl the history of page edits for all 650 MPs from 01 June 2002 to 28 Aug 2019. We store in total\n231k edits. These edits are made by 43k unique editors. Across all edits we see that 55k edits are made using public\nIP addresses, which is shown as the username for anonymous editors.\nPage Content To understand the content of the pages, we also collect page text as HTML dumps as on 18 July 2019.\nFrom these dumps, we extract the paragraph text, section titles, the citations list and other metadata for each page.\nMPs Information We obtain additional pro\ufb01le information of MPs using Wikidata.org, a free Wikimedia foundation\nknowledge base. Wikidata provides information about MPs\u2019 gender, party, year of page creation and position held\nin the Parliament. We identify the role of each MP in politics, which is Wikidata\u2019s Position held (P39) property. For\nexample, for the current prime minister Boris Johnson his positions held include: Mayor of London, Secretary of State,\nMember of Parliament, Prime Minister and Leader of the Conservative Party .\nAdditional Data We obtain additional baseline data from Wikipedia and Twitter. We collect MPs\u2019 interactions on\nTwitter, such as number and popularity of mentions across 2 months from [12]. For Wikipedia, we crawl page views\nforSportspeople (footballers) and actors . These categories are popular biographies of living people in the UK5. We\nrandomly sample 1000 pages from a Wikidata page list of these two categories.\n0.000.250.500.751.00\n0 2 4 6\nCount Per MP, Log 10CDF\nEditors\nEdits\nViews\nWords\n(a) Dataset Counts\n (b) Page Views\n (c) Constituency Edits\nFigure 1: Spatio-temporal patterns. (a) CDF (Cumulative Distribution Function) of number of views, edits and editors\nper MP. (b) Page views of MPs pages and baselines (footballers and actors in the UK). (c) CDF of constituency\nengagement. Inset: All edits from constituencies of Greater London.\n4 Spatio-temporal patterns of Pages\nWe begin by investigating when the MPs\u2019 Wiki pages are created and edited and what events or actions have impact\non page views. In summary, we \ufb01nd that most MP pages are created soon after they are \ufb01rst elected; edits happen after\nsigni\ufb01cant changes such as elections or scandals; and most views happen just before or after important events such as\nreferenda, elections and scandals.\n3The Wikimedia foundation host projects and websites such as Wikipedia.\n4https://tools.wmflabs.org/pageviews/ , Accessed 26 Feb 2020\n5www.wikidata.org/wiki/Wikidata:Living_people/uk , Accessed 15 Feb 2020\n3\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\n4.1 Page Views\nUsing edit history for each article, we obtain the article creation date (i.e. the day when the \ufb01rst edit was made). The\nedit history data covers four UK general elections (2005, 2010, 2015 and 2017). We see from that for the majority of\npages, the creation date is close to a general election (60% of page creation falls within these four years). In addition,\n25% of the articles were created between 2002 and 2004 (both included), coinciding with the birth and subsequent\nrapid growth of Wikipedia. We focus on the dynamics of viewing behaviour. MP pages obtain a large number of\nviews, with an average of 247k views per MP during the period we consider. We show the average view count of\neach day (mean) and median in Figure 1b (Note: Y axis is log scale). The mean views count is high on days of two\nmajor events: the UK EU membership referendum (also known as the \u2018Brexit\u2019 referendum) of 24 June 2016 and the\nUK general election of 09 June 2017.\nWe note from Figure 1b that near the Brexit referendum there are multiple viewership peaks. This relates to a major\nreshuf\ufb02e of government ministers, which took place after Theresa May became the UK\u2019s new prime minister. This is\nsimilar to the patterns exposed in [7] for German MPs, where highest views generally follow ministers\u2019 resignations\nand new appointments. During the UK general election we see that the number of views rises from the day of the\nelection announcement [13].\nApart from events where a majority of MP pages get attention, there are events which are speci\ufb01c to individual (non-\npopular) MPs when they are in the limelight. Examples include anticipated and unanticipated events, such as ministers\u2019\nresignations, speeches, interviews etc. [12].\n4.2 Page Edits and their Spatial Distribution\nAnother core dimension of engagement with Wikipedia is the editing process carried out by largely anonymous volun-\nteers. Among all edits, 36% happen during the last three election years captured in the dataset (2010, 2015 and 2017).\nThese patterns are similar to the views pattern in Figure 1b (Pearson\u2019s correlation: 62%, p <0:001), and we omit the\n\ufb01gure with daily edit counts due to limited space.\nOut of all the edits, around 55k (22%) edits are by public IPs which are recorded in the page revision history for not\nlogged-in (anonymous) users. To understand the spatial distribution of editors, we map each public IP to a possible\nphysical location (postcode), using the service provided by db-ip.com , a geo-location database. We observe that 84%\nof public IP edits are from the UK. The remainder are from countries such as the United States\u20131768 edits, Ireland\u2013442\nedits, Australia\u2013364 edits, Canada\u2013297 edits, etc.\nWe then map each postcode to a local constituency using the list provided in [12]. We plot edit location at constituency\nlevel in Figure 1c (inset), and observe that most public IP edits come from the area of Greater London, and more\nspeci\ufb01cally from the Westminister borough (318 edits) where the Parliament sits. This is indicative of MPs\u2019 staff\nmanaging edits, similar to the \ufb01ndings of previous studies, which could provide a source of bias in the articles [7]. The\nhighest number of public IP edits coming from an MP\u2019s local constituency is for MP Amber Rudd MP , former home\nsecretary, who has 47 out of 232 edits from her own constituency (Hastings and Rye).\nTo further quantify the extent to which edits come from an MP\u2019s constituency, we calculate the Constituency Engage-\nment Factor (CE) of each MP mas the proportion of the edits to their articles which are localised to their constituency.\nIfmhasNmedits of their page and Nm;cedits from their constituency, we write:\nCEm;c=Nm;c\nNm(1)\nWe plot the distribution of the metric in Equation 1 in Figure 1c. We see that for 31% of MPs there is at least one edit\nfrom their own constituency, but CEis in general low, and only 6 MPs have more than half of their edits from their\nown constituency.\n5 Polarisation and Quality\nWe continue our study by looking at information quality through the lenses of potential ideological and societal biases\nin Wikipedia articles about UK MPs. We ask and answer two questions: (i)Do editors have an ideological bias, e.g.,\nfocusing on editing pages of MPs from a speci\ufb01c party? (ii)What is the quality of citations used for MP pages? Do\nthey have an ideological slant, and is their coverage suf\ufb01cient? We \ufb01nd that there is a specialisation of editors, with\nsome focusing mainly on Conservative party MPs, others on Labour MPs, and so on.\n4\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\n5.1 Editors\u2019 Ideological Preference\nTo understand the extent to which editors tend to polarize around a speci\ufb01c ideology, we start by tracing, for each of\nthe 42k editors, the party of pages which they mostly edit. To this aim, we compute the number of edits to MPs from a\ngiven party, similar to [14, 12], and associate each editor to the party to which they contribute the maximum edits. We\ndo this for editors editing at least three different MPs, in order to exclude cases in which an editor is only interested in\none MP or two MPs from different parties. This \ufb01ltering step leaves us with 4.2k (7%) of editors who are collectively\nresponsible for 67% of edits.\n(a) Editors Network\n0.00.51.01.5Density\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\nConservativeLabour\n0.00 0.25 0.50 0.75 1.00\nIdeologyParty\u25cf \u25cf Conservative Labour (b) Ideology scores\nFigure 2: Measure of Polarisation (Red: Labour, Blue: Conservative, Black: Others). (a) Network graph based on\neditors as nodes, with edges connecting editors who have edited the same MPs\u2019 pages. (b) Ideology scores and density\nbased on citations domains.\nTo understand communities forming this polarisation we perform network analysis \u2013 we de\ufb01ne editors as nodes and\ninduce weighted edges between each pair of editors by computing the Jaccard Coef\ufb01cient or similarity of the sets of\npages edited by them. Thus, if two editors edit exactly the same set of MP pages, the weight will have its highest\nvalue of 1, and if there is no overlap, the value will be 0 (considered as no edge). We then use the Louvain method to\nidentify communities of editors who have more connections within each community, but not many connections across\ncommunities. We \ufb01nd that this graph cleaves into 8 tightly knit communities, with a high modularity score of 0.229,\nindicative of polarisation or specialisation by party among editors.\nTo visualise this better, we focus on the most active editors, and remove nodes with a degree of less than 5. To remove\nclutter, we do not show edges with weights less than 0.5. Figure 2a depicts this graph by colouring the nodes (editors)\nbased on their party (Blue for Conservative editors, red for Labour and black for others), and visually con\ufb01rms the\npolarisation detected above by showing how the graph of editors divides along party lines,.\n5.2 Citations Preference\nWe next focus on the content rather than the authors. We may expect that if authors exhibit polarisation, the sources\nthey draw from to write the content, i.e., the MP pages, may also be polarised. To quantify this, we use URLs which\nare embedded in the References section as citations. We \ufb01nd that there are 19k citations on MP pages. The average\ncitation count is 29 per page and the median is 19. By checking the top citation URLs, we see that majority of them\nare news domains. This is consistent with the English Wikipedia articles study by [15] which shows that top domains\ncited are Google.com, DOI.org, Nytimes.com. NIH.gov, BBC.co.uk, TheGuardian.com and so forth. Similar to [15]\nwe also extract the base domain from each citation URL and obtain 2212 unique domains. Additionally we \ufb01nd long\nURLs for 1.4k web archive (web.archive.org and archive.is) short URLs. The top 5 domains which we get are BBC\n(15%), theguardian (11%), telegraph (6%), parliament.uk (6%), independent (5%). The top 10 domains cover 52% of\nthe citations list.\nTo check the use and representation of news domain sources on MP pages we compute an ideology score for each\nMP page. To do this we \ufb01rst check and label all possible news domains with their political leaning. We use scores\n5\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\nfrom Mediabiasfactcheck [16] and label the top 50 news domains with their political leaning (left, center or right).\nWe also add ideology scores for news domains using sub-strings such as conservative (right-leaning) or labour (left-\nleaning) in the domain name. With this approach we \ufb01nd and label 67% (13k) of the domains. Some examples of\ntop domains by citations count are Left\u2013Theguardian (2069), Independent (969), Newstatesman (262); Center\u2013BBC\n(2766), Parliament.uk (1151), UKwhoswho (233); and Right\u2013Telegraph (1207), thegazette (302), thetimes (251).\nAfter labeling, we compute an ideology score for each page, as the fraction of identi\ufb01ed and Mediabiasfactcheck -\nlabelled news domains on that page that are left-leaning (i.e., ideology score = (number of left leaning news domains\nin citations)/(number of left+right leaning citations)). Note that a score of 0 indicates usage of only right-leaning\nsources and a score of 1 indicates only left-leaning sources; a score of 0.5 indicates a perfect balance. Figure 2b shows\nthe ideology scores of Conservative and Labour pages as scatter and density plots. We see two peaks (median Labour:\n0.7 and median Conservative: 0.4) which indicate a slight polarisation, with a slightly more polarised (i.e., farther\naway from 0.5) score for Labour MP pages. Also, 53 (17%) Conservative and 57 (22%) Labour pages have extreme\npolarised scores of 0 and 1 respectively. The KS statistics test (two sample) also con\ufb01rms that there is a signi\ufb01cant\ndifference ( p <0:001) with a distance value D= 0:54in the two parties\u2019 ideology scores.\n5.3 Citation Quality\nTo further understand the quality of Wikipedia articles, we perform an additional experiment on citations, a key\nelement for monitoring information quality in Wikipedia. Are MP articles well sourced? To answer this question, we\ncompute a citation quality score for each page. To this end, we employ the \u201cCitation Need\u201d model de\ufb01ned in [11].\nThe model takes as input a sentence in a Wikipedia article and assigns a Citation Need score scnin the range [0;1].\nThe higher the Citation Need score, the more likely it is that the sentence needs a citation.\nFigure 3: Percentage of sentences which miss citation.\nFor each article we \ufb01rst parse all sentences and score them with the Citation Need model, after \ufb01ltering out statements\nin the main section, which are less likely to need a citation [11]. Next, we aggregate the sentence-level scores and\ncompute a Citation Quality CQ as the proportion of sentences needing citations that already have a citation. To do\nso, we \ufb01rst identify the set Cof sentences needing citations in an article ( N), namely those sentences whose scnis\ngreater than 0.5. Next, we count how many sentences in the set Calready have a citation in the original article text\n(Nc). Finally, we compute citation quality as the ratio between these two quantities:\nCQ=Nc\nN; (2)\n6\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\nWe check the distribution of citation quality values for each party. We see with the KS statistics test that for all party\npairs there is no signi\ufb01cant difference. However, we see that some pages for all parties have values of less than 0.5.\nWe manually check these pages (50) and \ufb01nd that they are mostly in the Stub, Start and C (has signi\ufb01cant problems)\nquality categories.\nWe see that the average citation quality for MP articles is pretty high: about 83% of sentences needing citations\nactually have one. This is higher than the average citation quality in English Wikipedia, and comparable to articles\nabout Medicine and Biology, which historically are constantly monitored for information quality6. We see that citation\nquality is uniform across MPs from different parties. Among the articles with high citation quality score we \ufb01nd many\nwith low quality Wikipedia article scores: for example, Scottish MPs David Linden and Martin Docherty, despite\nhaving just a few lines in their article (quality \u201cStart\u201d), have a CQequal to 1 because of the richness of their citations.\nConversely, we \ufb01nd that most articles with low citation quality are also low quality articles, with a few exceptions\nincluding the article about MP Robin Walker.\nWe report the percentage of statements where citation is missing in given sections in Figure 3. For instance we see\nthat sentences from Early Life and Career miss citations the most often (18%). It is likely that this section can be\nhard to \ufb01nd citations for as there may be fewer references in the digital media. We see that Expenses, Political Views,\nControversies and Honours are the best cited sections with only 5%\u20137% of statements missing citations.\n6 Discussion\nIn this paper, we discussed important dynamics of attention and content production in the context of Wikipedia articles\nfocusing on UK Members of Parliament. We \ufb01nd evidence of specialization in contribution patterns of the editors of\nMP pages. With our analysis, we contribute to the broader \ufb01eld of online political communication studies, and shed\nlight on behavior of contributors to the largest online encyclopedia. We summarise our \ufb01ndings as follows:\nSpatio-Temporal Peaks of Engagement. Similar to previous work, we \ufb01nd that MP page creations, views and edits\nare strongly aligned with media coverage and election periods. Furthermore, we \ufb01nd that only a small fraction of edits\ncome from within the constituency of the MP, whereas the majority of anonymous edits come from Central London\nwhere the political centre of the UK lies. Collectively, these \ufb01ndings suggest that attention peaks are localized both in\ntime and space, thus introducing potential vulnerabilities to the integrity of the content. Researchers working on moni-\ntoring and detecting coordinated disinformation attacks in political communications might bene\ufb01t from these \ufb01ndings\nand further investigate how these peaks of attention might affect temporarily the quality of content on Wikipedia MP\npages.\nPolarisation Dynamics. We observe signals of partisanship among edits and domains of citations on papers. Many\neditors contribute to the pages of MPs of one party, and we also see communities of editors who collectively focus on\neach party. We also see a different distribution of citation ideology scores between pages of MPs from the two main\nUK parties, with Labour MP pages drawing on sources with a slightly higher degree of ideological bias. To further\ninvestigate these \ufb01ndings, we contacted experienced editors from the sub-community of Wikipedia curating pages of\nUK MPs. One possible explanation for this polarisation of sources is that, before election, Labour MPs tend to be\nless well known than Conservative MPs, and thus only left-wing press tend to cover them when they are nominated.\nThis evidence of polarisation therefore might not necessarily imply political bias, but further research in this direction\nshould investigate the neutrality of the content coverage in those articles.\nHigh Source Quality. In terms of veri\ufb01ability and information quality, we \ufb01nd that MP articles are generally well\nsourced, with an average of only 10% of sentences detected as missing citations. The citation quality is therefore very\nhigh overall, similar to Wikipedia medical articles, with sections on early life and career having the highest proportion\nof statements which lack citations. This suggests that, despite signals of polarisation among contributors, the infor-\nmation in Wikipedia articles is backed by a suf\ufb01cient amount of sources. Our study \ufb01nds that the UK Parliament\u2019s\nwebsite is the source of (6%) of citations on these pages. Of\ufb01cial sources like this can be used to improve quality and\ntrustworthiness, although they will not provide effective sources for aspects such as early life and career.\nLimitations and Future Work In this paper, we do not investigate the dynamics of page evolution over time. We\nuse the \ufb01nal stable page state as of 28th Aug 2019 to compute metrics and features for the content and time patterns.\nFuture work should focus on mining temporal patterns of engagement, including changes resulting from the recent\n2019 general election and presence of pages in multiple languages [17, 18]. Also, while we trace quality patterns\nacross different topics, we do not look at the value of individual contributions, which could be used to help identify\nspam and vandalism and thereby measure online hate or disinformation campaigns.\n6meta.wikimedia.org/wiki/Research:Mapping_Citation_Quality\n7\nWikipedia and Westminster: Quality and Dynamics of Wikipedia Pages about UK Politicians PREPRINT\n7 Acknowledgements\nWe also acknowledge support via EPSRC Grant Ref: EP/T001569/1 particularly the theme for \u201cDetecting and Un-\nderstanding Harmful Content Online: A Metatool Approach\u201d, as well as a Professor Sir Richard Trainor Scholarship\n2017 at King\u2019s College London.\nReferences\n[1] Brian McNair. An introduction to political communication . Taylor & Francis, 2017.\n[2] Ark Fangzhou Zhang, Ruihan Wang, Eric Blohm, Ceren Budak, Lionel P Robert Jr, and Daniel M Romero.\nParticipation of new editors after times of shock on wikipedia. In AAAI ICWSM , 2019.\n[3] Aniket Kittur, Bongwon Suh, Bryan A. Pendleton, and Ed H. Chi. He says, she says: Con\ufb02ict and coordination\nin wikipedia. In Human Factors in Computing Systems , 2007.\n[4] UK Parliament. About hansard online. bit.ly/hansardUK , 2020.\n[5] UK Parliament. Mps and lords. members.parliament.uk/, 2019.\n[6] Takashi Iba, Keiichi Nemoto, Bernd Peters, and Peter A Gloor. Analyzing the creative editing behavior of\nwikipedia editors: Through dynamic social network analysis. Elsevier, 2010.\n[7] Sascha G\u00f6bel and Simon Munzert. Political advertising on the wikipedia marketplace of information. SAGE,\n2018.\n[8] Marcel Reif, Kandhasamy Rajasekaran, Tevriz Iusupova, Evgenii Vasilev, et al. Politicians on wikipedia and\ndbpedia. 2017.\n[9] Jessica J Neff, David Laniado, Karolin E Kappler, Yana V olkovich, Pablo Arag\u00f3n, and Andreas Kaltenbrunner.\nJointly they edit: Examining the impact of community identi\ufb01cation on political interaction in wikipedia. PloS\none, 2013.\n[10] Feng Shi, Misha Teplitskiy, Eamon Duede, and James A Evans. The wisdom of polarized crowds. Nature\nPublishing Group, 2019.\n[11] Miriam Redi, Besnik Fetahu, Jonathan Morgan, and Dario Taraborelli. Citation needed: A taxonomy and algo-\nrithmic assessment of wikipedia\u2019s veri\ufb01ability. In World Wide Web Conference , 2019.\n[12] Pushkal Agarwal, Nishanth Sastry, and Edward Wood. Tweeting mps: Digital engagement between citizens and\nmembers of parliament in the uk. In AAAI ICWSM , 2019.\n[13] UK Parliament. General election timetable. bit.ly/UKGEN2017, 2017.\n[14] Pablo Barber\u00e1. Birds of the same feather tweet together: Bayesian ideal point estimation using twitter data.\nCambridge University Press, 2015.\n[15] Tiziano Piccardi, Miriam Redi, Giovanni Colavizza, and Robert West. Quantifying engagement with citations\non wikipedia. In World Wide Web Conference , 2020.\n[16] MediaBias. Media bias/fact check. mediabiasfactcheck.com/ , 2020.\n[17] Scott A Hale. Multilinguals and wikipedia editing. In Proceedings of the 2014 ACM conference on Web science ,\npages 99\u2013108, 2014.\n[18] Pushkal Agarwal, Kiran Garimella, Sagar Joglekar, Nishanth Sastry, and Gareth Tyson. Characterising user\ncontent on a multi-lingual social network. In Proceedings of the International AAAI Conference on Web and\nSocial Media , volume 14, pages 2\u201311, 2020.\n8", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Wikipedia and Westminster: Quality and dynamics of Wikipedia pages about UK politicians", "author": ["P Agarwal", "M Redi", "N Sastry", "E Wood"], "pub_year": "2020", "venue": "Proceedings of the 31st \u2026", "abstract": "Wikipedia is a major source of information providing a large variety of content online, trusted  by readers from around the world. Readers go to Wikipedia to get reliable information about"}, "filled": false, "gsrank": 178, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3372923.3404817", "author_id": ["y3zImYMAAAAJ", "s4oWIYgAAAAJ", "arSRJpgAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:JKzXAeGWCHEJ:scholar.google.com/&output=cite&scirp=177&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=JKzXAeGWCHEJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 14, "citedby_url": "/scholar?cites=8144925819242261540&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:JKzXAeGWCHEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2006.13400"}}, {"title": "Evaluating the relationship between news source sharing and political beliefs", "year": "2025", "pdf_data": "Evaluating the relationship \nbetween news source sharing and \npolitical beliefs\nSof\u00eda M. del Pozo1,2,5, Sebasti\u00e1n Pinto1,2,5, Matteo Serafino3, Federico Moss1, \nTom\u00e1s Cicchini1,4, Hern\u00e1n A. Makse3 & Pablo Balenzuela1,2\uf02a\nIn an era marked by an abundance of news sources, access to information significantly influences public \nopinion. Notably, the bias of news sources often serves as an indicator of individuals\u2019 political leanings. \nThis study explores this hypothesis by examining the news sharing behavior of politically active social \nmedia users, whose political ideologies were identified in a previous study. Using correspondence \nanalysis, we estimate the Media Sharing Index (MSI), a measure that captures bias in media outlets \nand user preferences within a hidden space. During Argentina\u2019s 2019 election on Twitter, we observed \na predictable pattern: center-right individuals predominantly shared media from center-right biased \noutlets. However, it is noteworthy that those with center-left inclinations displayed a more diverse \nmedia consumption, which is a significant finding. Despite a noticeable polarization based on political \naffiliation observed in a retweet network analysis, center-left users showed more diverse media sharing \npreferences, particularly concerning the MSI. Although these findings are specific to Argentina, the \ndeveloped methodology can be applied in other countries to assess the correlation between users\u2019 \npolitical leanings and the media they share.\nKeywords News sharing, Social media, Correspondence analysis, Political leanings.\nThe massive and growing use of the internet and digital platforms has undoubtedly brought about changes in the \nway we live, including the resources at our disposal and the habits we have incorporated1. The political leaning \nof users plays a key role in both sharing and accessing specific news items2,3. Indeed, the media bias observed in \nshared news on Twitter has been employed as a proxy for users\u2019 political ideologies4,5.\nNews sharing behavior on Twitter within the context of political elections was analyzed by Weaver et al.6. \nThe authors used a bipartite network of users and news articles and analyzed the emergence of communities in \nthe projection onto the news layer and identified their main features that explain these communities. A similar \napproach was addressed in7 for Argentinian media outlets, comparing electoral and non-electoral periods. \nWithin this framework, the researchers observed that groups of users on Twitter form based on their preferences \nfor specific media outlets.\nInferring political leaning from available information of users on social media presents a challenge that has \nbeen addressed in different ways. For instance one approach involves utilizing hashtag information from tweets, \nas in8, to quantify the level of support for the impeachment of the former Brazilian president. Another example \nis seen in9, where hashtags were utilized to train a machine learning model aimed at predicting electoral trends \nduring the 2019 Argentinian elections. Also, Cinelli et al., deduce users\u2019 political leanings based on the media \nbias of the news outlets they share on Twitter4. However, directly inferring user ideology from shared media bias \nremains a hypothesis that is awaiting validation.\nAn alternative method for uncovering the political preferences of social media users was introduced by \nBarbera et al.10,11, where they developed a Bayesian model. This model treats ideology as a latent variable, which \ncan be inferred from observed connections among users, assuming that these connections adhere to the principle \nof homophily. Specifically, the authors estimated latent parameters by utilizing correspondence analysis on the \nadjacency matrix of users who follow political accounts on Twitter. A recent application of correspondence \nanalysis is found in Flamino et al. (2023)12, where it was utilized to examine political polarization during the \n1Departamento de F\u00edsica, Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires, Buenos Aires, \nArgentina. 2Instituto de F\u00edsica Interdisciplinaria y Aplicada (INFINA), CONICET - Universidad de Buenos Aires, \nBuenos Aires, Argentina. 3Levich Institute and Physics Department, City College of New York, New York 10031, \nUSA. 4CONICET - Universidad de Buenos Aires, Facultad de Ciencias Exactas y Naturales, Instituto de C\u00e1lculo (IC), \nBuenos Aires, Argentina. 5Sof\u00eda M. del Pozo and Sebasti\u00e1n Pinto have contributed equally to this work. \uf02aemail: \nbalen@df.uba.ar\nOPEN\nScientific Reports  |          (2025) 15:516 1 | https://doi.org/10.1038/s41598-024-84110-y\nwww.nature.com/scientificreports\n\n2016 and 2020 US presidential elections. The authors estimated individual positions from the users-influencers \nadjacency matrix. Similarly, Falkenberg et al.  employed a comparable method to estimate latent opinions within \nthe online discourse surrounding measures to address climate change13.\nIn this work, correspondence analysis is employed not to infer users\u2019 ideology, but to quantify their media \npreferences based on the news articles they share. We compare these preferences with their political ideology, \nwhich was previously inferred through a machine learning model developed and validated in Zhou et al., based \nonly on the hashtags supporting one of the two coalitions that contested the elections that year9. Specifically, we \nuse users\u2019 connections to Argentine news articles to deduce preferences for media outlets within a latent space, \nachieved by conducting correspondence analysis of the user-media matrix. The comparison of both metrics \nallows us to measure how the political ideology of the users is related to the preference for the media they \nshare. Additionally, we delve into the emergence of community structures within the retweet network (excluding \nretweets containing links to news articles) to discern whether user interactions are driven by political leaning or \nmedia outlet preferences.\nThis work aims to contribute to the quantitative analysis of the relationship between political ideology and \nmedia preferences, continuing the line of previous studies such as14 and15.\nBackground\nArgentinian context\nIn this section, given our focus on Argentina, we explore the country\u2019s political and media landscape during the \n2019 presidential election campaign to provide essential contextualization.\nEven though today Argentina is governed by Javier Milei of a libertarian party16,17, over the last decade, \nArgentina\u2019s political landscape has been dominated by two major coalitions: one, a center-left coalition (CL) led \nby Cristina Fern\u00e1ndez de Kirchner, known as Frente de Todos , and the other, a center-right coalition (CR) led by \nMauricio Macri, referred to as Juntos por el Cambio . Cristina Kirchner held the presidency in Argentina during \nthe periods of 2007\u20132011\u00a0 and 2011\u20132015, while Mauricio Macri served as president from 2015 to 201918\u201320. \nDuring the 2019 elections, the center-left coalition presented Alberto Fern\u00e1ndez and Cristina Fern\u00e1ndez de \nKirchner as their candidates. Meanwhile, the center-right coalition sought a second term for Mauricio Macri as \npresident, with Miguel \u00c1ngel Pichetto as his vice-presidential candidate.\nNational elections in Argentina comprise two obligatory phases: the primary election, known as PASO \n(which stands for Primarias, Abiertas, Simult\u00e1neas y Obligatorias  in Spanish, translating to Open, Simultaneous, \nand Obligatory Primaries in English), and the general election. In 2019, these events occurred on August 11th \nand October 27th, respectively. Additionally, if the results of the general election necessitate it, a third round, \nreferred to as a ballotage , may also be conducted.\nRegarding the media landscape, the digital media scene in Argentina is primarily characterized by three \nmajor players: Infobae , Clar\u00edn  and La Naci\u00f3n , each boasting approximately 20 million unique users in 2020, as \nreported by Comscore data21. In particular, in 2019, Infobae , Clar\u00edn , La Naci\u00f3n  and other media outlet,\u00a0 Todo \nNoticias (TN),  accounting for 80%  of the total reported online visits22. These media outlets are relevant through \nthis work. Following closely are a second tier of media outlets characterized by audience numbers ranging from \n6 to 13 million unique visitors. Prominent among this group are P\u00e1gina 12 , \u00c1mbito Financiero  and El Destape \nWeb , among others.\nIn Argentina, a pronounced polarization has been reported through the distinct ideological orientations \nof the country\u2019s primary media outlets7,23. For instance, P\u00e1gina 12 is recognized as a left-of-center broadsheet \nnewspaper24, Infobae is considered a center-left outlet25, while Clar\u00edn is considered a center-right tabloid26, and \nLa Naci\u00f3n is characterized as a center-right broadsheet newspaper24,27.\nData and methods\nIn this section, we present the data description (Section \u201c Data description \u201d), which outlines the dataset utilized \nin our study, followed by the explanation about how we use this data and its study through correspondence \nanalysis (Section \u201c Methods \u201d).\nData description\nIn this research, we employed a pre-existing Twitter dataset9 which comprised tweets collected between March \n1, 2019, and August 27, 2019. The details of this dataset can be found in the\u00a0\u201c Appendix \u201d . From this dataset, we \nfiltered for all types of tweets, including tweets, retweets, and quotes, that exclusively contained external URLs \nlinking to Argentinian media outlets listed in the ABYZ News Links Guide28. From this list, we selected 17 \nmedia outlets, ranking the outlets in descending order by the number of times they were shared on Twitter and \nselecting those with broad recognition and influence not only on this platform, but also across Argentine media \nas a whole, as reported in sources such as22. Given this filter, we first obtained a dataset encompassing the activity \nof 123,180 users, who collectively generated 1,039,281 tweets, sharing 66,982 unique news articles. Secondly, \nwe incorporated data concerning individuals\u2019 voting intentions, which had been determined previously using \na model detailed in9. In this paper, the authors developed a method to infer political preference of Twitter \nusers by implementing a dynamic classification model based on the balance of tweets in favor of each of the \ncontending coalitions. Such a model, described in detail in9 provides a temporal label to a subset of 17,349 users \nas supporters of the center-left (CL) candidates (Fern\u00e1ndez-Fern\u00e1ndez) and 15,361 individuals as sympathizers \nof the center-right (CR) coalition (Macri-Pichetto). Supporters of the CL coalition shared 19,276 news articles, \nwhile those leaning towards the CR coalition shared 10,135.\nFigure 1 depicts the methodology followed to organize the large set of tweets sharing news of politically \ntagged users into a bipartite network of users-media outlets.\nScientific Reports  |          (2025) 15:516 2 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\nMethods\nWe organize the data in a user-media matrix, where each row is associated with a user and each column is \nassociated with a media outlet. The components of the matrix represent the number of times a given user shares \nan article from a specific media outlet. By applying correspondence analysis (detailed below), we calculate what \nwe refer to as the Media Sharing Index (MSI)\u00a0in this context. This index positions users within a latent space \nreflecting their preferences for specific groups of media outlets. Simultaneously, it places media outlets within \nthe same latent space, determined by the average preferences of their audience. Essentially, users closer in this \nspace tend to share similar media outlets, indicating comparable preferences in media sharing. Similarly, media \noutlets situated closely in this latent space imply shared usage by a similar set of users. We compare the MSI with \nthe political leaning of those users identified by9 and their position within the interaction network.\nCorrespondence analysis\nFollowing previous studies10,12 that propose a methodology for inferring user coordinates in a latent space of \nsocial media based on correspondence analysis29, we begin by establishing a bipartite network denoted as G = \n(U, V , E), where U represents the set of users, V denotes the news outlets, and E stands for the edges in the graph. \nThe corresponding adjacency matrix associated with this network is denoted as Y . The element yij represents the \nnumber of times user i, with i\u2208U shares news from a media outlet j, with j\u2208V. The main difference between \nour implementation and the seminal proposal10 is that the bipartite network here is based on the content of \nusers\u2019 tweets, rather than explicit network connections (e.g., following-followers relations or retweets).\nThe matrix Y is converted into the correspondence matrix P by dividing each element by its grand total \nP=Y/\u2211\nijyij. The element pij represents the probability of finding an event in which user i shares an article \nfrom media outlet j. From matrix P, the matrix of standardized residuals S is computed as:\n S=D1/2\nr(P\u2212rcT)D1/2\nc\nwhere vectors r and c are defined as ri=\u2211\njpij and cj=\u2211\nipij.The element ri represents the likelihood \nthat user i shares an article from any media outlet. Conversely, cj represents the probability of media outlet j \nbeing shared by any user. The elements of outer product rcT (ricj) can be interpreted as the probability of user \ni sharing a media outlet j given a null model where only the activity of user i and the frequency of with which \nmedia outlet j is shared matter. By defining diagonal matrices Dr=diag(r ) and Dc=diag(c) , we can express \nthe elements of S as follows:\n sij=pij\u2212ricj\u221aricj\nFig. 1 . Methodology pipeline. ( I). Raw data. Example of original data from Twitter (now X), with a tweet \nsharing a URL to a news article at the top and another one with a political hashtag at the bottom. ( II) User \nideology. Hashtags were used to train a logistic regression model to classify tweets as supportive of either \ncandidate. Users are assigned to the candidate for whom they demonstrate the highest number of supportive \ntweets (further details in9). (III) User-media. The news URLs in the tweets are used to identify the media \noutlet. A bipartite network of users and media outlets is then created. For example, user i is linked to the media \noutlet El Destape  because this user shared a news article from it. \nScientific Reports  |          (2025) 15:516 3 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\nThis expression can be interpreted as the deviation, measured in standard units, of pij from a null model where \nusers and media outlets are independent.\nIn order to compute the MSI for each user, we first perform singular value decomposition on S, that is:\n S=UD\u03b1VT\nwhere UUT=VTV=I and D\u03b1 is a diagonal matrix with the singular values on its diagonal. The Media \nSharing Index for the user i, MSI i, is then identified by the standard row coordinates by projecting only over \nthe first singular component:\n MSI i=(D1/2\nrU)i\nand finally normalizing these values to have zero mean and a standard deviation equal to 1. As such, users with \nsimilar values of MSI imply that they share a similar set of media outlets. In particular, if user sharing behavior is \ndriven by two distinct groups of media outlets, as shown in7, we would expect to observe a group of individuals \nwith MSI i>0 and another with MSI i<0.\nFinally, we define the MSI for media outlets as the weighted average of the MSI of the users, weighted by the \nnumber of times user i shares media j:\n MSI j=\u2211\niyijMSI i\u2211\niyij (1)\nThe interpretation of MSI j is analogous to one provided for MSI i: media outlets with MSI j>0 will have a very \ndifferent set of users who share its articles compared to media outlets with MSI j<0.\nResults\nMedia sharing index\nAs described above, we construct the bipartite adjacency matrix Y, where each element yij represents the \nnumber of news articles from media outlet j shared by user i. We apply correspondence analysis to this matrix \nto calculate the Media Sharing Index (MSI), as discussed in Section \u201c Methods \u201d . For simplicity, we focus on \nthe primary 12 media outlets, excluding those that are shared by only a few users and where the majority of \nthe shared articles come from the outlets themselves. This reduces the dataset to 59,874 unique news articles \n(approximately 88% of the total unique news in the dataset) and 120,626 users (about 97% of the users in the \noriginal dataset). These users originate from a total of 1,015,380 tweets containing links to one of these 12 main \noutlets, which constitutes about 98% of the original tweet volume.\nFigure 2 illustrates the probability density function of the MSI for users who share articles from at least one of \nthe primary 12 media outlets. This figure reveals the emergence of a bimodal distribution in the Media Sharing \nIndex. Unimodality is rejected with a p-value practically equal to zero ( p<0.001 ), as determined by the Dip \ntest30,31. This bimodal distribution reflects the preferences of users sharing content from two distinct groups of \nmedia outlets. Specifically, a majority of users share news from a group of outlets that includes Clar\u00edn, La Naci\u00f3n, \nTodo Noticias, among others, with an MSI close to +1. Conversely, a minority group prefers outlets such as El \nDestape, P\u00e1gina 12, and Minuto Uno, with an MSI close to \u22121.\nGiven that Clar\u00edn and La Naci\u00f3n are considered center-right outlets26,27, and P\u00e1gina 12 is viewed as a left-\nof-center broadsheet24, we can associate the Media Sharing Index with media bias along the left-right political \ndimension. These results prompt the question: do left-leaning users predominantly share news from left-leaning \nnewspapers, aligning with their beliefs? Or is news sharing behavior independent of their political preferences? \nIn other words, can the media bias reflected in the news users share serve as a proxy for their political ideology? \nThis is the question we aim to answer in this paper.\nMedia sharing and political preferences\nIn this section, we explore the potential link between the sharing preferences of users, as observed in Fig. 2, \nand their underlying political polarization. As described in Section \u201c Data description \u201d , the dataset used in this \nanalysis is the same one employed by Zhou et al.9 to infer the political preferences of Twitter users based on their \nposts. The labels assigned to users in9 are dynamic, allowing for a more nuanced description of a user\u2019s ideology. \nTherefore, we define the ideology valence of a user i (IV i) as:\n IV i=#CR i\u2212#CL i\n#CR i+#CL i. (2)\nHere, #CR i and #CL i denote the number of times user i, identified as a center-right or center-left partisan \nat that time, shared a news article, respectively. The sum #CR i+#CL i represents the total number of \nnews articles shared by user i. By this definition, IV i=1 indicates a user consistently labeled as center-right, \nScientific Reports  |          (2025) 15:516 4 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\nrepresenting a pure CR partisan. Conversely, IV i=\u22121 indicates a pure CL partisan. IV is only defined for users \nwith a label assigned in9.\nThe relationship between the ideology valence (IV) and the Media Sharing Index (MSI) is illustrated in Fig. 3. As \npreviously mentioned, the MSI can serve as an indicator of media bias along the left-right political dimension. \nHowever, Fig. 3 reveals that media-sharing behavior on social media cannot always be directly associated with \nusers\u2019\u00a0 ideological leanings. This figure demonstrates that while center-right users exhibit a distinct media \nsharing profile, with a preference for sharing outlets aligned with their political leanings, center-left users share \nnews from media sources corresponding to both peaks observed in the probability density of the MSI in Fig. 2.\nA possible interpretation of the asymmetric behavior observed between ideological groups is that media \noutlets with MSI >0, such as Clar\u00edn, La Naci\u00f3n, and Infobae, are also predominant players in the Argentine \nmedia landscape21,22 (see Section \u201c Argentinian context \u201d). These outlets\u2019 extensive reach and influence may \ncontribute to the observed sharing patterns among center-left users at the aggregate level.\nFig. 3 . Joint Probability Density of MSI and IV . This figure illustrates the relationship between the media \nsharing behavior of users and their ideological leaning. \nFig. 2 . Probability density of the Media Sharing Index (MSI). This graph shows the probability density of the \nMSI for users and the 12 main media outlets. Radio Mitre is excluded from this display as it is a positive MSI \noutlier. Histograms have been smoothed using a Gaussian kernel with a bandwidth of 0.15. The grey lines \nindicate the positions of the media outlets. \nScientific Reports  |          (2025) 15:516 5 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\nRetweet user networks\nIn this section, we analyze user interactions by constructing the retweet network. We specifically focus on the \nrelationship between the emerging community structure, the Media Sharing Index (MSI), and the users\u2019 political \npreferences. By definition, the retweet network is directed and weighted. The direction of the links indicates the \nflow of information (i.e., arrows point from a retweeted user to the user who retweets), and the weights reflect \nthe number of retweets between users. This network comprises 114,673 nodes, representing approximately \n90% of the users described in Section \u201c Data description \u201d . The remaining 10% are users who did not retweet \nor were not retweeted by any other users during the analyzed period. Additionally, there are 12,993,644 edges, \ncorresponding to the total number of retweets among users in this network. It is important to note that this \nnetwork was constructed only considering retweets that do not include links to news articles, meaning it contains \nno data used in the calculation of the MSI.\nIn Fig. 4, the two main communities within the retweet network are shown, identified using the Louvain \nalgorithm32. Although the algorithm detects 440 communities in total, the two largest communities account for \n75% of the entire network, with nearly an equal number of nodes in each community. Figure 4 also reveals a \nhighly modular structure of the retweet network, with a modularity score of approximately Q\u223c0.48 .\nHistograms in Fig. 4 reveal the profile of each community in relation to the Media Sharing Index and the \nIdeological Valence. Each community correlates strongly with a distinct ideological position: The red community \nin Fig. 4, representing 38 % of the network, aligns with the center-right, while the blue community, representing \n37% of the network, aligns with the center-left. The fact that the histograms for the Ideological Valence index \nshow a clear peak for both communities suggests that the community structure emerging from the retweet \nnetwork is a reliable proxy for the ideological positions of its members.\nThe association found between the community label and the ideological position of users supports the \nreproduction of the results discussed in Section \u201c Media sharing and political preferences \u201d at a community level: \nthe center-right community exhibits media sharing behavior favoring center-right media outlets, as depicted in \nthe blue histogram of the MSI. Conversely, the center-left community displays a less biased MSI distribution, \nindicating that this community shares content from both center-left media outlets and those biased towards the \nopposite ideological spectrum. As mentioned in Section \u201c Media sharing and political preferences \u201d , the observed \ndiversity in sharing patterns among the CL group may be linked to the prominence of CR media outlets in \nthe overall media ecosystem. This prominence is reflected in audience metrics, as we mentioned in Section \n\u201cArgentinian context \u201d.\nDiscussion and conclusions\nIn this work, we describe the collective news sharing behavior of thousands of Twitter\u2019s users by a coordinate \nin a latent space which we named Media Sharing Index (MSI). This is obtained by performing correspondence \nanalysis to the bipartite network of users - media outlets which emerge from the information of news articles \nshared by users.\nThe MSI metric enables us to set up a scale that describes the preferences of social media users in news \nsharing behavior. In this work, we specifically observe a bimodal distribution of the MSI, where the two clearly \nFig. 4 . Retweet network. The two largest communities detected by the Louvain algorithm are displayed \n(account for 75% of the entire network). Histograms illustrate the distribution of the MSI and IV for each \ncommunity. Based on these distributions, the red community can be associated with a center-right political \nleaning, while the blue community can be associated with a center-left leaning. \nScientific Reports  |          (2025) 15:516 6 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\ndefined peaks can readily be linked to two distinct groups of media outlets. In the case of Argentina, these two \ngroups are exemplified by Clar\u00edn, La Naci\u00f3n, Infobae, and Todo Noticias, among others, on one side, and on \nthe other side, P\u00e1gina 12 and El Destape. These six media outlets stand out as the most widely shared on social \nmedia. Given that Clar\u00edn and La Nacion are considered as center-right outlets26,27 and P\u00e1gina 12 as a left-of-\ncenter broadsheet newspaper24, we can associate the Media Sharing Index as a measure of media bias in the \nleft-right political dimension.\nThe strength of the Media Sharing Index lies in its ability to quantify news sharing behavior among diverse \nmedia outlet groups. Coupled with the inference of users\u2019 political leaning derived from the machine learning \nmodel outlined in9, we can explore the correlations between these dimensions and address questions such as: \nCan the bias of the shared media outlets be used as a proxy of user\u2019s ideology?\nOur analysis reveals distinct patterns: while the CR group predominantly shares news from media that align \nwith their ideological stance, the CL group exhibits a broader range of media sources in their sharing behavior. \nThis observed diversity could likely be influenced by the prominent role of CR media outlets within the broader \nmedia ecosystem in Argentina, as we stated in section 2.1 and can be observed in21,22. An ideological asymmetry \nin news preferences and exposure has been also documented in other contexts. In the US, studies have examined \nthe asymmetry between right-wing and left-wing groups at the media ecosystem level33,34 and the preference for \nnews exposure in social media. However, the users\u2019 behavior is not similar to what we observe in this work. For \ninstance, in35, the authors analyze the reinforcing effects of liberal and conservative media on political beliefs \nduring the 2016 US election, finding that conservative beliefs contribute more to a conservative media echo \nchamber than liberal beliefs do to a liberal one. Similarly,36 explores ideological segregation in political news on \nFacebook during the 2020 US election, revealing that conservatives consume a disproportionately large amount \nof news, while liberal sources are less prevalent. Research conducted in countries outside the US also suggests \nthat ideology has a stronger influence on right-wing users compared to left-wing users when it comes to news-\nsharing behavior37.\nThe most significant limitation of this study is that it is restricted to Argentina during the 2019 electoral \nperiod. It is essential to examine how these results vary in other electoral periods in Argentina and what \nthe results would be in different countries. Nonetheless, we have developed a methodology here that can be \nextrapolated to all these scenarios in future studies.\nData availability\nTwitter data analyzed in this work are provided according to its terms and are available at https://osf.io/u29tk/ . \nCode availability\nAnalytical codes are available in https://github.com/ spinto88/MediaSharin gIndex.\nAppendix: Original dataset\nAs mentioned in Section \u201c Data description \u201d , we employed a pre-existing Twitter dataset9 comprising tweets \ncollected between March 1, 2019, and August 27, 2019. This dataset was obtained through the Twitter Academic \nAPI (at the time of acquiring the data, this API allowed full access to the complete history of the social media \nplatform) by searching for the following queries: Pichetto, Espert, victoria, Bregman, argentina, Voto, Kirchner, \nPropuesta Republicana, Moreno, Peron, Sola, kirchnerismo, Massa, UCR, PASO, Alternativa Federal, Justicial -\nista, PRO, Movimiento Socialismo, Rossi, #ArgentinaVota, Union Civica Radical, fuerza, Votar, Vidal, Alfonsin, \nalferdez, kicillof, Scioli, vamos, Frente Izquierda, Donda, miguelpichetto, CFK, Vote, kicillofok, Alberto Fernandez, \nUrtubey, elecciones, sergiomassa, ganamos, Peronista, CFKArgentina, peronismo, #EleccionesArgentina, PJ, Lav -\nagna, Partido Justicialista, mauriciomacri, Consenso 19, Cristina, Lousteau, Cambiemos, macrismo, mariuvidal, \nCapitanich, apoyo, Macri . Exclusively, tweets written in Spanish were selected.\nThe full dataset analyzed comprised around 170 million tweets and about 3.5 million users. Although the da -\ntaset is massive, given the keywords used to obtain it, the dataset may include users with a certain bias towards \ntweeting about politics and, therefore, must be considered with caution when evaluating its representativeness \nof the Argentinian population. On the other hand, Zhou et al.9 reported an average classification per day of \n114,653 tweets as CR supporters and 96,576 as CL supporters (MP and FF, respectively, in9), which indicates a \nbalanced classification.\nAll of these numbers are drastically reduced when considering only those tweets with URLs linking to Argen -\ntinian outlets, as stated in Section \u201c Data description \u201d.\nReceived: 28 May 2024; Accepted: 19 December 2024\nReferences\n 1. Graham, M. and Dutton, W .H. Society and the Internet: How Networks of Information and Communication are Changing Our Lives . \nOxford University Press, (2019).\n 2. Osmundsen, M. et al. Partisan polarization is the primary psychological motivation behind political fake news sharing on Twitter. \nAm. Political Sci. Rev.  115(3), 999\u20131015 (2021).\n 3. Eady, G. et al. News sharing on social media: Mapping the ideology of news media content, citizens, and politicians. In: (2020).\n 4. Cinelli, M. et al. The echo chamber effect on social media. Proc. Natl. Acad. Sci.  118(9), e2023301118 (2021).\n 5. An, J. et al. Sharing political news: The balancing act of intimacy and socialization in selective exposure. EPJ Data Sci.  3, 1\u201321 \n(2014).\n 6. Weaver, I. S. et al. Communities of online news exposure during the UK General Election 2015. Online Soc. Netw. Media  10, 18\u201330 \n(2019).\nScientific Reports  |          (2025) 15:516 7 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\n 7. Cicchini, T. et al. News sharing on twitter reveals emergent fragmentation of media agenda and persistent polarization. EPJ Data \nSci. 11(1), 48 (2022).\n 8. Cota, W . et al. Quantifying echo chamber effects in information spreading over political communication networks. EPJ Data Sci.  \n8(1), 35 (2019).\n 9. Zhou, Z. et al. Why polls fail to predict elections. J. Big Data  8(1), 1\u201328 (2021).\n 10. Barber\u00e1, P . et al. Tweeting from left to right: Is online political communication more than an echo chamber?. Psychol. Sci.  26(10), \n1531\u20131542 (2015).\n 11. Barber\u00e1, P . Birds of the same feather tweet together: Bayesian ideal point estimation using Twitter data. Political Anal.  23(1), 76\u201391 \n(2015).\n 12. Flamino, J. et al. Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections. In: \nNature Human Behaviour  (2023), pp. 1\u201313.\n 13. Falkenberg, M. et al. Growing polarization around climate change on social media. Nat. Climate Change  12(12), 1114\u20131121 (2022).\n 14. Calvo, E. et al. Winning! election returns and engagement in social media. Plos one  18(3), e0281475 (2023).\n 15. Aruguete, N., Calvo, E. & Ventura, T. News by popular demand: Ideological congruence, issue salience, and media reputation in \nnews sharing. Int. J. Press/Politics  28(3), 558\u2013579 (2023).\n 16. Presidencia de la Naci \u00f3 n Argentina . https ://www. argentina.go  b.ar/preside ncia Acc essed : 19th March 2024.\n 17. Argentina Government and Media Profile . https://medi  abiasfac tche ck.com/argen  tina-govern ment-and-media-profile/  Retrieved \nfrom: 19th March 2024.\n 18. Murillo, M. V . & Zarazaga, R. Argentina: Peronism returns. J. Democr.  31, 125 (2020).\n 19. Benezra, K. Neoliberalism in Crisis29. J. Latin Am. Cult. Stud.  29(3), 461\u2013467 (2020).\n 20. Cantamutto, F. Kirchnerism in Argentina: A populist dispute for hegemony. Int. Crit. Thought  62, 227\u2013244.  h t t p s : / / d o  i . o r g / 1 0 . 1 0 8 \n0 / 2 1 5 9 8 2 8 2 . 2 0 1 6 . 1 1 7 2 3 2 5     (2016).\n 21. Todo Medios (Comscore data) .  h t t p s :  / / w  w w .  t o t a l m  e d i o s  . c o  m / n  o t a / 5 4  0 9 0 / i n  f o b a e  - l i d e r  o - e n - u n - a  g o s t o - m a r c a d o - p  o r - l a s - p a s o - y - c \no n - c r e c i m i e n  t o - d e - t o d o s - l o s - s i  t i o s     . Accessed 14 Nov. 2023.\n 22. Digital News Report . https://www. digita lnewsr  eport.org/su rvey/2019/a  rgentina -2019/ . Retrieved from: 27th September 2024.\n 23. Newman, N. et al. Digital news report 2023. In: RISJ: Reuters Institute for the Study of Journalism  (2023).\n 24. Bonner, M. D. Media and punitive populism in Argentina and Chile. Bull. Latin Am. Res.  37(3), 275\u2013290 (2018).\n 25. Infobae Bias . https://m ediabiasfactcheck.com/infobae/ . Accessed: 19th March 2024.\n 26. Clar \u00ed n Bias. https:/ /mediabiasfactcheck. com/clarin-bias/ . Accessed: 19th March 2024.\n 27. La Naci \u00f3 n Argentina Bias. https :   //mediabiasfactc he ck. co  m/la-n  acion-ar  g entina-bias/ . Accessed: 19th March 2024.\n 28. ABYZ Web Links Inc.  Accessed 14 Nov. 2023. : http://www.abyznewslinks.com/argen.htm .\n 29. Greenacre, M. J. Correspondence analysis. Wiley Interdiscip. Revi. Comput. Stat.  2(5), 613\u2013619 (2010).\n 30. Hartigan, J. A. and Hartigan, P . M. The dip test of unimodality. In: The Annals of Statistics , pp. 70\u201384 (1985).\n 31. Diptest Python Library:  : https://pyp i.org/project/diptest/ .\n 32. Blondel, V . D. et al. Fast unfolding of communities in large networks. J. Stat. Mech.: Theory Exp.  2008 (10), 10008 (2008).\n 33. Benkler, Y . & Faris, R. and Roberts, H. (Manipulation, disinformation, and radicalization in American politics. Oxford University \nPress, Network propaganda, 2018).\n 34. Jamieson, K. H. and Cappella, J. N.. Echo Chamber: Rush Limbaugh and the Conservative Media Establishment . Oxford University \nPress, (2008).\n 35. Hmielowski, J. D., Hutchens, M. J. & Beam, M. A. Asymmetry of partisan media effects?: Examining the reinforcing process of \nconservative and liberal media with political beliefs. Political Commun.  37(6), 852\u2013868 (2020).\n 36. Gonz\u00e1lez-Bail\u00f3n, S. et al. Asymmetric ideological segregation in exposure to political news on Facebook. Science  381(6656), 392\u2013\n398 (2023).\n 37. Aruguete, N., Calvo, E., and Ventura, T. News by Popular Demand: Ideology, Reputation, and Issue Attention in Social Media News \nSharing . (2019).\nAuthor contributions\nSMdP , SP , and MS\u00a0(ORCID: 0000-0002-7907-1375) were responsible for collecting the raw data. SMdP and SP \ndeveloped the computational code utilized consistently throughout the paper. TC and FM made contributions to \nthe statistical analysis. PB and HAM conceptualized the research. All authors engaged in discussions about the \nresults and collaborated on the development of the manuscript.\nFunding\nHAM and MS were supported by NSF Grant No. 2214217. PB, SMdP and SP were supported by PICT-2020-\nSERIEA-00966.\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nCorrespondence  and requests for materials should be addressed to P .B.\nReprints and permissions information  is available at www.nature.com/reprints .\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nScientific Reports  |          (2025) 15:516 8 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/\nOpen Access   This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r  e a t i v e c o m m o \nn s . o r g / l i c e n  s e s / b y - n c - n d / 4 . 0 /     .  \n\u00a9 The Author(s) 2024 \nScientific Reports  |          (2025) 15:516 9 | https://doi.org/10.1038/s41598-024-84110-ywww.nature.com/scientificreports/", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Evaluating the relationship between news source sharing and political beliefs", "author": ["SM Del Pozo", "S Pinto", "M Serafino", "F Moss", "T Cicchini"], "pub_year": "2025", "venue": "Scientific Reports", "abstract": "In an era marked by an abundance of news sources, access to information significantly  influences public opinion. Notably, the bias of news sources often serves as an indicator of"}, "filled": false, "gsrank": 179, "pub_url": "https://www.nature.com/articles/s41598-024-84110-y", "author_id": ["ZpXsRWgAAAAJ", "Q9ssI9cAAAAJ", "YB_5JtoAAAAJ", "", "Vd-IBiUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:cziStALOW88J:scholar.google.com/&output=cite&scirp=178&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=cziStALOW88J&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 5, "citedby_url": "/scholar?cites=14941762699746490483&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:cziStALOW88J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-024-84110-y.pdf"}}, {"title": "Echo chambers on social media: A comparative analysis", "year": "2020", "pdf_data": "Echo Chambers on Social Media: A comparative analysis\nMatteo Cinelli,1,\u0003Gianmarco De Francisci Morales,2,yAlessandro\nGaleazzi,3,zWalter Quattrociocchi,4,xand Michele Starnini2,{\n1Applico Lab { ISC CNR, Via dei Taurini 19, 00185 Roma, Italy\n2ISI Foundation, via Chisola 5, 10126 Torino, Italy\n3University of Brescia, Via Branze, 59, 25123 Brescia , Italy\n4Ca'Foscari Univerity of Venice, via Torino 155, 30172 Venezia, Italy\nRecent studies have shown that online users tend to select information adhering to their system\nof beliefs, ignore information that does not, and join groups { i.e., echo chambers { around a\nshared narrative. Although a quantitative methodology for their identi\fcation is still missing, the\nphenomenon of echo chambers is widely debated both at scienti\fc and political level. To shed\nlight on this issue, we introduce an operational de\fnition of echo chambers and perform a massive\ncomparative analysis on more than 1B pieces of contents produced by 1M users on four social media\nplatforms: Facebook, Twitter, Reddit, and Gab. We infer the leaning of users about controversial\ntopics { ranging from vaccines to abortion { and reconstruct their interaction networks by analyzing\ndi\u000berent features, such as shared links domain, followed pages, follower relationship and commented\nposts. Our method quanti\fes the existence of echo-chambers along two main dimensions: homophily\nin the interaction networks and bias in the information di\u000busion toward likely-minded peers. We\n\fnd peculiar di\u000berences across social media. Indeed, while Facebook and Twitter present clear-cut\necho chambers in all the observed dataset, Reddit and Gab do not. Finally, we test the role of the\nsocial media platform on news consumption by comparing Reddit and Facebook. Again, we \fnd\nsupport for the hypothesis that platforms implementing news feed algorithms like Facebook may\nelicit the emergence of echo-chambers.\nINTRODUCTION\nSocial media allow users to access and share an unprece-\ndented amount of information, thus changing the way we\ninteract, debate and form our opinions [ 1,2]. The wide\navailability of content sparked the enthusiastic idea that\nusers might be better informed and exposed to diversi\fed\npoint of views [ 3{5]. However, the human attention span\nremains limited [ 6,7] and news feed algorithms might in-\n\ruence the selection process by promoting content similar\nto the ones already seen, thus reducing content diver-\nsity [ 8,9] and eventually leading to polarization [ 10{13].\nOn top of opinion polarization, users show the tendency\nto select information that adheres to their beliefs and join\npolarized groups formed around a shared narrative, called\necho chambers [ 14{18]. Inside these closed communities\nformed by users having similar preferences and content\nconsumption patterns, the information spreading is often\nbiased [ 14,19{23]. Such a con\fguration might hamper\nthe democratic deliberative process by altering the way\nfacts are perceived [24].\nNowadays, echo chambers are one of the most debated\nissues in relation to the social media environment [ 15,25],\ngiven their potential role in fostering actions of political\nmanipulation and in\ruence on voting behavior [ 26{28].\nSome studies point out echo chambers as an emerging\n\u0003matteo.cinelli@uniroma2.it\nygdfm@acm.org\nza.galeazzi002@unibs.it\nxw.quattrociocchi@unive.it\n{michele.starnini@gmail.come\u000bect of human tendencies, such as selective exposure\nand contagion [ 29{31]. Moreover, group polarization the-\nory [32] has been proposed as a mechanism to model the\ndynamics leaning to the emergence of echo-chambers in\nonline social networks [ 33]. It is remarkable that ma-\njor social media and former U.S. Presidents alike have\nvoiced such concerns [ 34]. Recently, however, the e\u000bects\nand the very existence of echo chambers have been ques-\ntioned [ 3,35{37]. This heated debate calls for a quantita-\ntive analysis able to gauge the presence of echo chambers\nacross topics and social media. In this work, we provide\na formal assessment of echo chambers by introducing an\noperational de\fnition independent of the social media\nplatform considered.\nWe propose a de\fnition of echo chambers based on\nthe coexistence of two main ingredients: ( i) opinion po-\nlarization with respect to a controversial topic, and ( ii)\nhomophilic interactions between users, i.e., the preference\nto interact with like-minded peers. We operationalize\nthese two abstract concepts into observables that can be\nquanti\fed empirically, thus providing a common method-\nological ground to obtain consistent results and compare\nthem across di\u000berent social media. We perform a com-\nparative analysis on four major social media platforms:\nFacebook, Twitter, Reddit, and Gab. These media share\nsome common features and functionalities (e.g., they all\nallow social feedback actions such as likes or upvotes) and\ndesign (e.g., Gab is similar to Twitter) but also distinc-\ntive features (e.g., Reddit is organized in communities of\ninterest called subreddits).\nWhile the environment and the main features behind\nmainstream social media have been widely investigated,\nother social media such as Reddit and especially Gab havearXiv:2004.09603v1  [physics.soc-ph]  20 Apr 2020\n2\nbeen somewhat overlooked. Reddit is one of the most\nvisited websites worldwide [ 38] and is organized as a fo-\nrum to collect discussions about a wide amount of topics,\nranging from politics to emotional support. Gab is rela-\ntively di\u000berent, as it claims to be a social platform aimed\nat protecting free speech. Such a claim, together with the\npolitical leaning of its developers, made Gab the \\safe\nhaven\" for the alt-right movement. However, low modera-\ntion and regulation on content has resulted in widespread\nhate speech. For these reasons, it has been repeatedly\nsuspended by its service provider, and its mobile app was\nbanned from both App and Play stores [ 39]. All these fea-\ntures make the comparison of the aforementioned social\nmedia particularly interesting for investigation. Overall,\nwe take into account the interactions of more than 1M\nactive users on the four platforms, for a total of more\nthan 1B unique pieces of content, including posts and\nsocial interactions. Our \fndings suggest that platforms\norganized around social networks and with algorithms\naccounting for social feedback may increase polarization\nand favor the emergence of echo chambers.\nCHARACTERIZING ECHO CHAMBERS IN\nSOCIAL MEDIA\nAt an abstract level, the echo chamber phenomenon\ncan be understood in the context of selective exposure\ntheory [ 40]. Humans have a tendency to seek informa-\ntion adhering to their pre-existing opinion, a phenomenon\nsometimes referred to as con\frmation bias [41]. Such\na tendency has been proven to be dominant in content\nconsumption on online social media [ 14,19,20,42]. In\na social context, this tendency may foster the emergence\nof homophilic clusters of individuals. This, in turn, cre-\nates an environment where individuals are surrounded\nby people whose opinion agrees with their own: an echo\nchamber .\nA fundamental mechanism to explain the origin of the\ntendency to selective exposure can be found in cognitive\ndissonance theory [ 43]. The theory posits that individuals\nstrive towards internal consistency of thoughts and beliefs,\nby virtue of the fact that inconsistency, or dissonance , is\npsychologically uncomfortable. An individual will thus\ntry to avoid information and situations that are likely to\nincrease their dissonance, and seek instead consonant ones.\nCognitive dissonance is thus possibly the primum movens ,\nor innate root cause, of the ultimate formation of echo\nchambers. According to group polarization theory [ 32],\nan echo chamber can act as a mechanism to reinforce an\nexisting opinion within a group, and as a result move the\nentire group towards more extreme opinions. The lack\nof exposure to alternative opinions also creates a false\nperception of unanimity, and thus a di\u000berent perception\nof reality across groups, which may hinder the democratic\ndebate given the lack of a shared common ground on\nwhich to operate.Operational de\fnitions\nAn echo-chamber can be de\fned as an environment\nin which the opinion, political leaning, or belief of an\nindividual about a certain topic are reinforced due to\nrepeated interactions with peers who share similar points\nof view. Two key elements are needed for this scenario\nto take place. First, a group of individuals that share\na common opinion in opposition to other individuals or\ngroups characterized by di\u000berent attitudes regarding the\nsame topic. Second, social interactions that convey a\n\row of information between these individuals about the\ntopic under consideration, that can thus in\ruence their\nbeliefs on the subject. Such interactions are more likely\nto be established between individuals characterized by\nsimilar opinions, that is, there is a certain degree of ho-\nmophily in social interactions. Therefore, echo-chambers\nare characterized by the coexistence of two elements: ( i)\nopinion polarization with respect to a controversial topic,\nand (ii)homophily in interactions, i.e. the preference\nto interact with like-minded peers. These two abstract\nconcepts need to be operationalized in order to be gauged\non empirical social systems, and in particular within the\nspeci\fc context of online social media.\nIn order to quantify the degree of polarization in social\nsystems, one needs \frst to identify the attitude of users,\nat a micro level. On online social media, the individual\nleaning of a useritoward a speci\fc topic, xi, can be\ninferred in di\u000berent ways, via the content produced, or the\nendorsement network among users [ 44,45]. With respect\nto the content, its leaning can be de\fned as the attitude\nexpressed by a piece of content towards a speci\fc topic.\nThis leaning can be explicit (e.g., arguments supporting a\nnarrative) or implicit (e.g., framing and agenda setting).\nLet us consider a user iproducing a number aiof contents,\nCi=fc1;c2;:::;c aig, whereaiis the activity of useriand\neach content leaning is assigned a numeric value. Then\nthe individual leaning of user ican be de\fned as the\naverage of the leanings of contents produced,\nxi\u0011Pai\nj=1cj\nai: (1)\nOnce individual leanings are inferred, polarization can\nbe de\fned as a state of the system such that the distribu-\ntion of leanings, P(x), is heterogeneous. If opinions are\nassumed to be embedded in a one-dimensional space, as\nusual in case of topics characterized by positive versus\nnegative stances, polarization can be quanti\fed by a bi-\nmodal distribution. That is, if opinions are represented\non an axis, x2[\u00001;+1], without loss of generality, polar-\nization is then characterized by two well-separated peaks\ninP(x), for positive and negative opinions, while neutral\nones are absent or underrepresented in the population.\nNote that polarization can happen independently from\nthe structure or the very presence of social interactions.\nHomophily in social interactions can be quanti\fed by\nrepresenting interactions as a social network, and then\nanalyzing its structure with respect to the opinions of\n3\nthe agents [ 21,46{48]. From online social media, social\nnetworks can be reconstructed in di\u000berent ways, where\nlinks represent social relationships or interactions. Since\nwe are interested in capturing the possible exchange of\nopinion between users, we assume directed links to repre-\nsent the substrate over which information may \row. For\ninstance, if user ifollows user jon Twitter, user ican\nsee tweets produced by user j, thus there is a \row of\ninformation from node jto nodeiin the network. That\nis, when the reconstructed network is directed, we assume\nthe link direction points to possible in\ruencers (opposite\nof information \row). Actions such as mentions or retweets\nmay convey similar \rows. In some cases, direct relations\nbetween users are not available in the data, so one needs\nto assume some proxy for social connections, e.g., a link\nbetween two users if they comment the same post on\nFacebook. Crucially, the two elements characterizing the\npresence of echo-chambers, polarization and homophilic\ninteractions, should be quanti\fed independently.\nImplementation on social media\nThis section explains how we implement the operational\nde\fnitions de\fned above on di\u000berent social media. For\neach medium, we detail ( i) how we quantify the individual\nleaning of users, and ( ii) how we reconstruct the inter-\naction network on top of which the information spread.\nFurther details are provided in the Materials and Methods\nSection.\nTwitter . We consider the set of tweets posted by user\nithat contain links to news organizations of known po-\nlitical leaning. To each news organization is associated a\npolitical leaning score [ 49] ranging from extreme left to\nextreme right in accordance to the classi\fcation reported\nin Materials and Methods. We infer the individual leaning\nof a useri,xi2[\u00001;+1] by averaging the scores of the\nnews organizations linked by user iaccording to Eq. (1).\nWe analyze three di\u000berent data sets collected on Twitter\nrelated to controversial topics: gun control, Obamacare,\nand abortion. For each data set, the social interaction\nnetwork is reconstructed by using the following relation,\nso that there exists a direct link from node ito nodejif\nuserifollows user j. Henceforth we focus on the data set\nabout abortion, others are shown in the Supplementary\nMaterial (SM).\nFacebook . The individual leaning of users is quanti\fed\nby considering endorsements in the form of likes to posts.\nWhile other actions such as comments or shares could be\ntaken into account, the written text may radically change\nthe inferred leaning. Additionally, while a like is usually\na positive feedback on a news item, comments and share\ncan be associated to di\u000berent purposes [ 8]. A comment\ncan have multiple features and meanings and can generate\ncollective debate, while a share indicates a desire to spread\na news item to friends. Posts are produced by pages that\nare labeled in a certain number of categories, and to\neach category we assign a numerical value (e.g., Anti-Vax(+1) or Pro-Vax (-1)). Each like to a post (only one like\nper post is allowed) represents an endorsement for that\ncontent, which is assumed to be aligned with the labeling\nof the page. Thus, the individual leaning of a user is\nde\fned as the average of the content leanings of the posts\nliked by the user, according to Eq. (1).\nWe analyze three di\u000berent data sets collected on Face-\nbook regarding a speci\fc topic of discussion: vaccines,\nscience versus conspiracy, and news. The interaction net-\nwork is de\fned by considering comments. In such an\ninteraction network two users are connected if they co-\ncommented at least one post. Henceforth we focus on the\ndata set about vaccines and news, others are shown in\nthe SM.\nReddit . Here, the individual leaning of users is quan-\nti\fed similarly to Twitter, by considering the links to\nnews organizations in the content produced by the users,\nsubmissions and comments. The interaction network is\nde\fned by considering comments and submissions, by\nreconstructing the information \row. There exists a direct\nlink from node ito nodejif usericomments on a sub-\nmission or comment by user j(we assume that ireads the\ncomment they are replying to, which is written by j). We\nanalyze three data sets collected on di\u000berent subreddits:\nthedonald, politics, and news. In the following we focus\non the data set collected on the Politics and on the News\nsubreddit, others are shown in the SM.\nGab. The political leaning xiof useriis computed\nby considering the set of contents posted by user ithat\ncontain a link to news organizations of known political\nleaning, similarly to Twitter and Reddit. To obtain the\nleaningxiof useri, we averaged the scores of each link\nposted by user iaccording to Eq. (1). The interaction\nnetwork is reconstructed by exploiting the co-commenting\nrelationships under posts in the same way as for Facebook.\nGiven two users iandj, an undirected edge between i\nandjexists if and only if they comment under the same\npost.\nCOMPARATIVE ANALYSIS\nIn the following we compare the presence or absence of\necho-chambers across social media. We select one data set\nfor each social media: Abortion (Twitter), Vaccines (Face-\nbook), Politics (Reddit), and Gab as a whole. Results\nfor other data sets for the same medium are qualitatively\nsimilar, as shown in the SM. We \frst characterize echo-\nchambers in the topology of the networks, then look at\ntheir e\u000bects on information di\u000busion. Finally, we directly\ncompare Facebook and Reddit on a common topic, news\nconsumption, to highlight the di\u000berences in the behavior\nof users.\n4\n(a)Twitter\n (b)Reddit\n(c)Facebook\n (d)Gab\nFIG. 1: Joint distribution of the leaning of users xand the\naverage leaning of their neighborhood xNNfor di\u000berent data\nsets. Colors represent the density of users: the lighter, the\nlarger the number of users. Marginal distribution P(x) and\nPN(x) are plotted on the x and y axis, respectively.\nHomophily in the interaction networks\nThe topology of the interaction network can reveal the\npresence of echo-chambers, where users are surrounded\nby peers with similar leaning and thus are exposed with\nhigher probability to similar contents. In network terms,\nthis translates into a node iwith a given leaning ximore\nlikely to be connected with nodes with a leaning close to\nxi[21]. This concept can be quanti\fed by de\fning, for\neach useri, the average leaning of their neighborhood, as\nxN\ni\u00111\nk!\niP\njAijxj, whereAijis the adjacency matrix of\nthe interaction network, Aij= 1 if there is a link from\nnodeito nodej,Aij= 0 otherwise, and k!\ni=P\njAijis\nthe out-degree of node i.\nFig. 1 shows the correlation between the leaning of a\nuseriand the leaning of their neighbors, xN\ni, for the four\nsocial media under consideration. The probability dis-\ntributionsP(x) (individual leaning) and PN(x) (average\nleaning of neighbors) are plotted on the x and y axis, re-\nspectively. All plots are color-coded contour maps, which\nrepresent the number of users in the phase space ( x;xN):\nthe brighter the area in the map, the larger the density\nof users in that area. The topics of vaccines and abor-\ntion, on Facebook and Twitter, respectively, clearly show\ntwo distinct groups whose leanings di\u000ber quite starkly,\nas indicated by the two bright areas characterized by a\nhigh density of users with like-minded neighbors. Simi-\n1101001000\n12345\nCommunity IDCommunity Size\nAgainst \nAbortionPro \nAbortion(a)Twitter\n110100100010000\n05101520\nCommunity IDCommunity Size\nExtreme \nLeftExtreme \nRight (b)Reddit\n101103105\n0 20 40 60\nCommunity IDCommunity Size\nPro VaccinesAnti Vaccines\n(c)Facebook\n110100100010000\n05101520\nCommunity IDCommunity Size\nExtreme \nLeftExtreme \nRight (d)Gab\nFIG. 2: Size and average leaning of communities detected in\ndi\u000berent data sets.\nlar behavior is found for di\u000berent topics from the same\nsocial media platform, see SM. Conversely, Reddit and\nGab show a di\u000berent picture. The corresponding plots in\nFig. 1 display a single bright area, indicating that users\ndo not split into groups with opposite leaning but form a\nsingle community, biased to the left (Reddit) or the right\n(Gab). Similar results are found for di\u000berent data sets on\nReddit, see SM.\nHomophilic interactions can be revealed by the com-\nmunity structure of the interaction networks. We detect\ncommunities by applying the Louvain algorithm for com-\nmunity detection [ 50]. We remove singleton communities\nwith only one user and look at the average leaning of\neach community, determined as the average of individual\nleanings of its members.\nFig. 2 shows the communities emerging for each social\nmedium, arranged by increasing average leaning on the\nx-axis (color-coded from blue to red), while the y-axis\nreports the size of the community. We \fnd a picture\nthat con\frms the pattern observed before. On Facebook\nand Twitter, communities span the whole spectrum of\npossible leanings, but each community is formed by users\nwith similar leaning. Some communities are characterized\nby very strong average leaning, especially in the case of\nFacebook. Conversely, communities on Reddit and Gab\ndo not cover the whole spectrum, and all show similar\naverage leaning. Furthermore, it is noticeable the almost\ntotal absence of communities with leaning very close to 0,\ncon\frming the polarized state of the systems. In addition,\nthe number of communities identi\fed is di\u000berent among\n5\nthe four social media. The similar number of communi-\nties found in Gab and Reddit and the strong di\u000berence\nwith respect to Facebook and Twitter suggests that both\nplatforms structure and feedback algorithm may have an\nimpact on the clustering process of users.\nE\u000bects on information spreading\nThe presence of echo chambers can be gauged by simple\nmodels of information spreading: users are expected to\nexchange information more likely with peers sharing a\nsimilar leaning [ 21,44,51]. Classical epidemic models such\nas the susceptible-infected-recovered (SIR) model [ 52]\nhave been used to study the di\u000busion of information, such\nas rumors or news [ 53,54]. In the SIR model, each agent\ncan be in either of three states: susceptible (unaware\nof the circulating information), infectious (aware and\nwilling to spread it further), or recovered (aware but not\nwilling to transmit it anymore). Susceptible (unaware)\nusers may become infectious (aware) upon contact with\ninfected neighbors, with certain transmission probability\n\f. Infectious users can spontaneously become recovered\nwith probability \u0017. In order to measure the e\u000bects of the\nleaning of users on the di\u000busion of information, we run\nthe SIR dynamics on the interaction networks, by starting\nthe epidemic process with only one node iinfected, and\nstopping it when no more infectious nodes are left.\nThe set of nodes in a recovered state at the end of\nthe dynamics started with user ias seed of infection,\ni.e., those that become aware of the information initially\npropagated by user i, forms the set of in\ruence of useri,\nIi[55]. The set of in\ruence of a user thus represents those\nindividuals that can be reached by a piece of content sent\nby him/her, depending on the e\u000bective infection ratio\n\f=\u0017. One can compute the average leaning of the set of\nin\ruence of user i,\u0016i, as\n\u0016i\u0011jI ij\u00001X\nj2Iixj: (2)\nThe quantity \u0016iindicates how polarized are the users that\ncan be reached by a message initially propagated by user\ni[21].\nFig. 3 shows the average leaning h\u0016(x)iof the in\ruence\nsets reached by users with leaning x, for the di\u000berent data\nsets under consideration. The recovery rate \u0017is \fxed at\n0.2 for every dataset, while relationship between infection\nrate\fand average degree hkivary from dataset to dataset\nand is reported in the caption of each \fgure. More details\nabout the network used for the SIR model are reported\nin Table I in Methods and Material Section. Again, one\ncan observe a clear distinction between Facebook and\nTwitter, on one side, and Reddit and Gab on the other\nside. For the topics of vaccines and abortion, on Facebook\nand Twitter, respectively, users with a given leaning are\nmuch more likely to be reached by information propagated\nby users with similar leaning, i.e., h\u0016(x)i\u0018x. Similar\nbehavior is found for di\u000berent topics from the same social\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n4080120160Influence Set \nAverage Size(a)Twitter\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n20002500300035004000Influence Set \nAverage Size (b)Reddit\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n1000200030004000Influence Set \nAverage Size\n(c)Facebook\n\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n100200300Influence Set \nAverage Size (d)Gab\nFIG. 3: Average leaning h\u0016(x)iof the in\ruence sets reached\nby users with leaning x, for di\u000berent data sets under\nconsideration. Size and color of each point represents the\naverage size of the in\ruence sets. The parameters of the SIR\ndynamics are set to \f= 0:10hki\u00001for panel (a),\n\f= 0:01hki\u00001for panel (b), \f= 0:05hki\u00001for panel (c) and\n\f= 0:05hki\u00001for panel (d), while \u0017is \fxed at 0.2 for all\nsimulations.\nmedia platform, see SM. Conversely, Reddit and Gab\nshow a di\u000berent behavior: the average leaning of the set\nof in\ruence,h\u0016(x)i, does not depend on the leaning x.\nThese results indicate that in some social media, namely\nTwitter and Facebook, information di\u000busion is biased\ntoward individuals that share similar leaning, while in\nothers { Reddit and Gab in our analysis { this e\u000bect is\nabsent. The quantity h\u0016(x)i, indeed, gauges the strength\nof the echo chambers e\u000bect: the more h\u0016(x)iis close to\nx, the stronger the echo chamber e\u000bect, while if h\u0016(x)i\nis independent of x, echo-chambers are not present. Our\nresults are robust with respect to di\u000berent values of the\ne\u000bective infection ratio \f=\u0017, see SM.\nFurthermore, Fig. 3 shows that the spreading capacity,\nrepresented by the average size of the in\ruence sets (color\ncoded in Fig. 3), depends on the leaning of the users. On\nTwitter, pro-abortion users are more likely to reach larger\naudiences, the same is true for anti-vax users on Facebook,\nleft-leaning users on Reddit, and right-leaning users on\nGab (in this data set, left-leaning users are almost absent\nthough).\n6\nNews Consumption on Facebook and Reddit\nThe striking di\u000berences observed across social media,\nin terms of homophily in the interaction networks and\ninformation di\u000busion, could be attributed to di\u000berent\ntopics taken into account. For this reason, here we com-\npare Facebook and Reddit on a common topic, news\nconsumption. Facebook and Reddit are particularly apt\nto a cross-comparison since they share the de\fnition of\nindividual leaning (computed by using the classi\fcation\nprovided by mediabiasfactcheck.org, see Methods for fur-\nther details) and the rationale in creating connections\namong users that is based on an interaction network.\nFig. 4 shows a direct comparison of news consumption\non Facebook and Reddit along the metrics used in the pre-\nvious Sections to quantify the presence of echo-chambers:\ni) the correlation between the leaning of a user xand the\naverage leaning of neighbors xN(top row), ii) the average\nleaning of communities detected in the networks (middle\nrow), and iii) the average leaning h\u0016(x)iof the in\ruence\nsets reached by users with leaning x, by running SIR\ndynamics (bottom row). One can see that all three mea-\nsures con\frm the picture obtained for other data sets: On\nFacebook, we observe a clear separation among users de-\npending on their leaning, while on Reddit users' leanings\nare more homogeneous and show only one peak. In the\nlatter social media, even users displaying a more extreme\nleaning (noticeable in the marginal histogram of Figure\n4 panel b top row) tend to interact with the majority.\nMoreover, on Facebook the leaning of the seed user has\nan e\u000bect on who the \fnal recipients of the information\nare, therefore indicating the presence of echo-chambers.\nOn Reddit this e\u000bect is absent.\nCONCLUSIONS\nThe presence and e\u000bects of echo chambers on online\nsocial media is a widely debated topic that has profound\nimplications on the way we consume information online\nand form our opinions. The wide availability of con-\ntent combined with con\frmation bias and news feed al-\ngorithms may foster the emergence of groups of users\naround a shared narrative. Furthermore, the similarity\nof interests may exacerbate polarization and reinforce\nexisting users tendencies and attitudes. To shed light on\nthis issue, in this paper, we introduced an operational\nde\fnition aimed at identifying echo chambers. We per-\nformed a massive comparative analysis on more than 1B\npieces of contents produced by 1M users on four social\nmedia platforms: Facebook, Twitter, Reddit, and Gab.\nThe proposed method quanti\fes the presence of echo-\nchambers along two main dimensions: ( i) homophily in\nthe interaction networks, and ( ii) bias in the information\ndi\u000busion toward likely-minded peers. Our results show\npeculiar di\u000berences across social media: while Facebook\nand Twitter are dominated by echo chambers in all the\nobserved dataset, Reddit and Gab are not. Furthermore,\n110100100010000\n24681012\nCommunity IDCommunity Size\nExtreme \nLeftExtreme \nRight\n1101001000\n010203040\nCommunity IDCommunity Size\nExtreme LeftExtreme Right\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n5101520Influence Set \nAverage Size(a)Facebook\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n600700800900Influence Set \nAverage Size (b)Reddit\nFIG. 4: Direct comparison of news consumption on\nFacebook (left column) and Reddit (right column). Joint\ndistribution of the leaning of users xand the average leaning\nof their nearest-neighbor xN(top row), size and average\nleaning of communities detected in the interaction networks\n(middle row), and average leaning h\u0016(x)iof the in\ruence sets\nreached by users with leaning x, by running SIR dynamics\n(bottom row) with parameters \f= 0:05hkifor panel (a) and\n\f= 0:006 hkifor panel (b) and \u0017= 0:2 for both.\nwe perform a direct comparison of news consumption on\nboth Reddit and Facebook. We found support for the hy-\npothesis that platforms organized around social network\nand with news feed algorithms which take into account\nusers' preferences foster the emergence of echo-chambers.\nMATERIALS AND METHODS\nLabelling of media sources\nThe labeling of news outlets is based on the informa-\ntion reported by Media Bias/Fact Check (MBFC [ 56]), an\n7\nFIG. 5: Example of two news sources, namely New York Time and Breitbart, classi\fed on mediabiasfactcheck.org. Notice that,\nalthough Breitbart is labeled as \"Questionnable\", a explicit leaning appears in its description.\n0100200300400500\nExtreme LeftLeft\nLeft\u2212CenterLeast\nRight\u2212CenterRight\nExtreme Right\nFIG. 6: Distribution of the leanings assigned to each source,\nranging from Extreme Left (numerical value: -1, colored in\nblue) to Extreme Right (numerical value: +1, colored in red).\nindependent fact-checking organization that rates news\noutlets on the base of the reliability and of the political\nbias of the contents they produce and share. The website\nprovides the political bias related to a wide range of media\noutlets. The labeling provided by MBFC, retrieved in\nJune 2019, ranges from Extreme Left to Extreme Right for\nwhat concerns the political bias. Certain media outlets are\ninstead classi\fed as `questionable' sources or `conspiracy-\npseudoscience' sources if they tend to publish misinforma-\ntion or false contents. However, most of the news outlets\nwithout an explicit political label reported by MBFC\nactually have a political bias (e.g., breitbart) that is re-\nported in their description, as shown in Figure 5. These\nmedia outlets often have a political bias that is classi\fed\nas extreme (either left or right). Considering the impor-\ntance of including such media outlets in our analysis, we\nmanually reported their classi\fcation from the description\nprovided by MBFC, thus adding 468outlets to the pool\nof1722 news outlets that already have a clear political\nlabel. The total number of media outlets for which we\nhave a political label is 2190 and the overall leaning is\nsummarized in Figure 6.Empirical data sets\nHere we report details on data collection for di\u000berent\nsocial media, summarized in Table I.\nTwitter\nGun control. We consider C= 19M tweets spanning\n14 days in June 2016, produced by N= 7506 users. We\nreconstruct a directed follow network formed by E=\n1 053 275 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify\nthe individual leaning of Nc= 6994 users.\nObamacare. We consider C= 34M tweets spanning 7\ndays in June 2016, produced by N= 8773 users. We\nreconstruct a directed follow network formed by E=\n3 797 871 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify\nthe individual leaning of Nc= 7899 users.\nAbortion. We consider C= 34M tweets spanning 7\ndays in June 2016, produced by N= 3995 users. We\nreconstruct a directed follow network formed by E=\n2 330 276 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify\nthe individual leaning of Nc= 3809 users.\nFacebook\nScience and Conspiracy. The dataset was built by\ndownloading posts of selected Facebook pages divided into\ntwo groups, namely conspiracy news and science news.\nConspiracy pages were selected based on their name, their\nself description and with the aid of debunking pages. The\n8\nTABLE I: For each data set, we report: the starting date of collection T0, time span Texpressed in days (d) or years (y),\nnumber of unique contents C, number of users N, coveragenc(fraction of users with classi\fed leaning), size of the giant\ncomponent Gand average node degree hki.\nMedia Data set T0 T C N n c G hki\nTwitterGun control 06/2016 14 d 19 M 7506 0.93 3964 798\nObamacare 06/2016 7 d 34 M 8773 0.90 8703 1405\nAbortion 06/2016 7 d 34 M 3995 0.95 798 478\nFacebookSci/Cons 01/2010 5 y 75 172 183 378 1.00 181960 228\nVaccines 01/2010 7 y 94 776 221 758 1.00 220275 419\nNews 01/2010 6 y 15 540 38 663 1.00 38594 700\nRedditPolitics 01/2017 1 y 353 864 240 455 0.15 240455 9\nThe Donald 01/2017 1 y 1 :234 M 138 617 0.16 138617 31\nNews 01/2017 1 y 723 235 179 549 0.20 179549 3\nGab Gab 11/2017 1 y 13 M 165 162 0.13 20701 328\nselection process was iterated until convergence among an-\nnotators. The dataset, that includes post from pages and\ncomments to such posts, was created by using Facebook\nGraph API and has previously been explored [ 57]. We\nconsider 75 172 posts by 73 pages categorized in Science\n(34) and Conspiracy (39) that involve N=183 378 active\nusers (at least 1 like and 1 comments) that co-commented\n20 807 976 times. The largest connected component of\nthe co-commenting network has G=181 960 nodes and\nE= 20 807 491 links.\nVaccines. The dataset was generated in three steps:\n\frst a search for pages containing the keywords vaccine,\nvaccines, or vaccination was made. Then the raw outcome\nwas cleaned from spurious pages. Finally all the posts\nand comments of selected pages were downloaded and\npages were manually classi\fed in Pro-Vax and Anti-Vax\ngroups. The dataset was created by using Facebook Graph\nAPI and has previously been explored [ 58]. Thus, we\nconsider 94 776 posts by 243 pages categorized in Pro-\nVax (145) and Anti-Vax (98) that involve 221 758 active\nusers (at least 1 like and 1 comment) that co-commented\n46 198 446 times. The largest connected components of\nthe co-commenting network has N=220 275 nodes and\nE= 46 193 632 links.\nNews. To build this dataset, a set of Facebook pages\nof news outlets listed by the Europe Media Monitor was\nidenti\fed as \frst step. By using the Facebook Graph API,\nall the posts and comments related to these pages in the\nperiods between 2010-2015 were downloaded. Facebook\npages are labelled according to the annotation provided by\nmediabiasfactcheck.org. The dataset without annotations\nand has previously been explored [ 8]. We consider 15 540\nposts by 180 pages categorized from Left to Right (Left\n(12), Left-Center (80), Least-Biased (42), Right-Center\n(33), Right (13)), 38663 active users ( \u00153 likes and 3\ncomments) that co-commented 13 525 230 times. The\nlargest connected component of the co-interaction network\nhasG= 38 594 nodes and E= 13 525 119 links.Reddit\nPolitics. We consider 353 864 comments and submissions\nposted on the subreddit politics in the year 2017. From\ncomments a submissions we reconstructed a directed net-\nwork formed by N=240 455 users andE=5 030 565\ndirected edges. The largest weakly connected compo-\nnent includes more than 0 :99% of nodes. We identify the\nindividual leaning of Nc= 37 148 users.\nThe Donald. We consider 1:234M comments and sub-\nmissions posted on the subreddit The Donald in the year\n2017. From comments a submissions we reconstructed\na directed network formed by N=138 617 users and\nE=5 025 290 directed edges. The largest weakly con-\nnected component includes more than 0 :99% of nodes.\nWe identify the individual leaning of Nc= 21 905 users.\nNews. We consider 723 235 comments and submissions\nposted on the subreddit news in the year 2017. From com-\nments a submissions we reconstructed a directed network\nformed byN=179 549 users andE=1 070 589 directed\nedges. The largest weakly connected component includes\nmore than 0 :99% of nodes. We identify the individual\nleaning ofNc= 36 875 users.\nGab\nThe dataset, downloaded from https://files.\npushshift.io/gab , spans from the \frst Gab post (oc-\ncurred in 2016) to the late 2018 and it includes data\nregarding post-reply relationships, number of upvotes of\nposts, repost or replies and their timestamps. We se-\nlected all the contents (post, reply, quote) from 11/2017\nto 10/2018, that is C=13 580 937 unique pieces of con-\ntent created by N=165 162 unique users. We consider\nall the post that have a link to an external source, for an\namount of 3 302 621 posts (excluding youtube links). By\nextracting the domain from each link we obtain 75 436\nunique domains. In this set, 1650 unique domains for a\ntotal of 1 454 502 URLs (44%) were labelled in the MBFC\ndatabase. We were able to compute the political leaning\n9\nofNc=31 286 users. We also reconstructed the interac-\ntion network using co-commenting as a proxy. The largestconnected component includes G=20 701 nodes, about\nthe 66% of the users with leaning, E= 8 273 412 edges.\n[1]Walter Quattrociocchi. Part 2-social and political chal-\nlenges: 2.1 western democracy in crisis? In Global Risk\nReport World Economic Forum , 2017.\n[2]An Nguyen and Hong Tien Vu. Testing popular news\ndiscourse on the \\echo chamber\" e\u000bect: Does political\npolarisation occur among those relying on social media as\ntheir primary politics news source? First Monday , 24(5),\n2019.\n[3]Elizabeth Dubois and Grant Blank. The echo chamber is\noverstated: the moderating e\u000bect of political interest and\ndiverse media. Information, Communication & Society ,\n21(5):729{745, 2018.\n[4]Leticia Bode. Political news in the news feed: Learning\npolitics from social media. Mass communication and\nsociety , 19(1):24{48, 2016.\n[5]Nic Newman, Richard Fletcher, Antonis Kalogeropoulos,\nand Rasmus Nielsen. Reuters institute digital news report\n2019, volume 2019. Reuters Institute for the Study of\nJournalism, 2019.\n[6]Andrea Baronchelli. The emergence of consensus: a\nprimer. Royal Society open science , 5(2):172189, 2018.\n[7]Matteo Cinelli, Emanuele Brugnoli, Ana Lucia Schmidt,\nFabiana Zollo, Walter Quattrociocchi, and Antonio Scala.\nSelective exposure shapes the facebook news diet. PloS\none, 15(3):e0229129, 2020.\n[8]Ana Luc\u0013 \u0010a Schmidt, Fabiana Zollo, Michela Del Vicario,\nAlessandro Bessi, Antonio Scala, Guido Caldarelli, H Eu-\ngene Stanley, and Walter Quattrociocchi. Anatomy of\nnews consumption on facebook. Proceedings of the Na-\ntional Academy of Sciences , 114(12):3035{3039, 2017.\n[9]Matteo Cinelli, Walter Quattrociocchi, Alessandro\nGaleazzi, Carlo Michele Valensise, Emanuele Brugnoli,\nAna Lucia Schmidt, Paola Zola, Fabiana Zollo, and An-\ntonio Scala. The covid-19 social media infodemic. arXiv\npreprint arXiv:2003.05004 , 2020.\n[10]Michael D Conover, Jacob Ratkiewicz, Matthew Fran-\ncisco, Bruno Gon\u0018 calves, Filippo Menczer, and Alessandro\nFlammini. Political polarization on twitter. In Fifth in-\nternational AAAI conference on weblogs and social media ,\n2011.\n[11]Christopher A Bail, Lisa P Argyle, Taylor W Brown,\nJohn P Bumpus, Haohan Chen, MB Fallin Hunzaker,\nJaemin Lee, Marcus Mann, Friedolin Merhout, and\nAlexander Volfovsky. Exposure to opposing views on so-\ncial media can increase political polarization. Proceedings\nof the National Academy of Sciences , 115(37):9216{9221,\n2018.\n[12]Nicola Perra and Luis EC Rocha. Modelling opinion dy-\nnamics in the age of algorithmic personalisation. Scienti\fc\nreports , 9(1):1{11, 2019.\n[13]Kazutoshi Sasahara, Wen Chen, Hao Peng, Giovanni Luca\nCiampaglia, Alessandro Flammini, and Filippo Menczer.\nOn the inevitability of online echo chambers. arXiv\npreprint arXiv:1905.03919 , 2019.\n[14]Michela Del Vicario, Alessandro Bessi, Fabiana Zollo,\nFabio Petroni, Antonio Scala, Guido Caldarelli, H Eugene\nStanley, and Walter Quattrociocchi. The spreading of mis-information online. Proceedings of the National Academy\nof Sciences , 113(3):554{559, 2016.\n[15]Kathleen Hall Jamieson and Joseph N Cappella. Echo\nchamber: Rush Limbaugh and the conservative media\nestablishment . Oxford University Press, 2008.\n[16]R Kelly Garrett. Echo chambers online?: Politically\nmotivated selective exposure among Internet news users.\nJournal of Computer-Mediated Communication , 14(2):265{\n285, 2009.\n[17]Walter Quattrociocchi, Antonio Scala, and Cass R Sun-\nstein. Echo chambers on Facebook. Available at SSRN\n2795110 , 2016.\n[18] Kiran Garimella, Gianmarco De Francisci Morales, Aris-\ntides Gionis, and Michael Mathioudakis. Political dis-\ncourse on social media: Echo chambers, gatekeepers, and\nthe price of bipartisanship. In Proceedings of the 2018\nWorld Wide Web Conference , WWW '18, pages 913{922,\nRepublic and Canton of Geneva, Switzerland, 2018. In-\nternational World Wide Web Conferences Steering Com-\nmittee.\n[19]Alessandro Bessi, Mauro Coletto, George Alexandru\nDavidescu, Antonio Scala, Guido Caldarelli, and Wal-\nter Quattrociocchi. Science vs conspiracy: Collective\nnarratives in the age of misinformation. PloS one ,\n10(2):e0118093, 2015.\n[20] Kiran Garimella, Gianmarco De Francisci Morales, Aris-\ntides Gionis, and Michael Mathioudakis. The E\u000bect of\nCollective Attention on Controversial Debates on Social\nMedia. In WebSci '17: 9th International ACM Web Sci-\nence Conference , pages 43{52, 2017.\n[21]Wesley Cota, Silvio C. Ferreira, Romualdo Pastor-\nSatorras, and Michele Starnini. Quantifying echo chamber\ne\u000bects in information spreading over political communi-\ncation networks. EPJ Data Science , 8(1):35, Dec 2019.\n[22]Duilio Balsamo, Valeria Gelardi, Chengyuan Han, Daniele\nRama, Abhishek Samantray, Claudia Zucca, and Michele\nStarnini. Inside the echo chamber: Disentangling\nnetwork dynamics from polarization. arXiv preprint\narXiv:1906.09076 , 2019.\n[23]Alessandro Cossard, Gianmarco De Francisci Morales,\nKyriaki Kalimeri, Yelena Mejova, Daniela Paolotti, and\nMichele Starnini. Falling into the echo chamber: the\nitalian vaccination debate on twitter. arXiv preprint\narXiv:2003.11906 , 2020.\n[24]Cass R Sunstein. Republic.com 2.0 . Princeton University\nPress, 2009.\n[25]Walter Quattrociocchi. Inside the echo chamber. Scienti\fc\nAmerican , 316(4):60{63, 2017.\n[26]Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol,\nAlessandro Flammini, and Filippo Menczer. The spread of\nfake news by social bots. arXiv preprint arXiv:1707.07592 ,\npages 96{104, 2017.\n[27]David MJ Lazer, Matthew A Baum, Yochai Benkler,\nAdam J Berinsky, Kelly M Greenhill, Filippo Menczer,\nMiriam J Metzger, Brendan Nyhan, Gordon Pennycook,\nDavid Rothschild, et al. The science of fake news. Science ,\n359(6380):1094{1096, 2018.\n10\n[28]Alexandre Bovet and Hern\u0013 an A Makse. In\ruence of fake\nnews in twitter during the 2016 us presidential election.\nNature communications , 10(1):7, 2019.\n[29]Itai Himelboim, Stephen McCreery, and Marc Smith.\nBirds of a feather tweet together: Integrating network\nand content analyses to examine cross-ideology exposure\non twitter. Journal of computer-mediated communication ,\n18(2):154{174, 2013.\n[30]Seth Flaxman, Sharad Goel, and Justin M Rao. Filter\nbubbles, echo chambers, and online news consumption.\nPublic opinion quarterly , 80(S1):298{320, 2016.\n[31]Dimitar Nikolov, Diego FM Oliveira, Alessandro Flam-\nmini, and Filippo Menczer. Measuring online social bub-\nbles. PeerJ Computer Science , 1:e38, 2015.\n[32]Cass R Sunstein. The law of group polarization. Journal\nof political philosophy , 10(2):175{195, 2002.\n[33]Fabian Baumann, Philipp Lorenz-Spreen, Igor M. Sokolov,\nand Michele Starnini. Modeling echo chambers and po-\nlarization dynamics in social networks. Phys. Rev. Lett. ,\n124:048301, Jan 2020.\n[34]E.g., Obama foundation's attempt to address the issue of\necho chambers. https://www.engadget.com/2017/07/\n05/obama-foundation-social-media-echo-chambers\nFacebook's CEO Mark Zuckerberg's open letter. https:\n//www.facebook.com/notes/mark-zuckerberg/\nbuilding-global-community/10103508221158471/ .\n[35]Pablo Barber\u0013 a, John T Jost, Jonathan Nagler, Joshua A\nTucker, and Richard Bonneau. Tweeting from left to\nright: Is online political communication more than an\necho chamber? Psychological science , 26(10):1531{1542,\n2015.\n[36]Axel Bruns. Echo chamber? what echo chamber? review-\ning the evidence. 2017.\n[37]Axel Bruns. Are Filter Bubbles Real? John Wiley & Sons,\n2019.\n[38] https://www.alexa.com/siteinfo/reddit.com .\n[39]Savvas Zannettou, Barry Bradlyn, Emiliano De Cristofaro,\nHaewoon Kwak, Michael Sirivianos, Gianluca Stringini,\nand Jeremy Blackburn. What is gab: A bastion of free\nspeech or an alt-right echo chamber. In Companion Pro-\nceedings of the The Web Conference 2018 , pages 1007{\n1014. International World Wide Web Conferences Steering\nCommittee, 2018.\n[40]Joseph T Klapper. The e\u000bects of mass communication.\n1960.\n[41]Raymond S Nickerson. Con\frmation bias: A ubiquitous\nphenomenon in many guises. Review of general psychology ,\n2(2):175{220, 1998.\n[42]Michela Del Vicario, Gianna Vivaldo, Alessandro Bessi,\nFabiana Zollo, Antonio Scala, Guido Caldarelli, and Wal-\nter Quattrociocchi. Echo chambers: Emotional contagion\nand group polarization on facebook. Scienti\fc reports ,\n6:37825, 2016.\n[43]Leon Festinger. A theory of cognitive dissonance , volume 2.\nStanford university press, 1962.\n[44] Kiran Garimella, Gianmarco De Francisci Morales, Aris-\ntides Gionis, and Michael Mathioudakis. Quantifying\nControversy in Social Media. In WSDM '16: 9th ACM\nInternational Conference on Web Search and Data Mining ,\npages 33{42, 2016.\n[45] Kiran Garimella, Gianmarco De Francisci Morales, Aris-\ntides Gionis, and Michael Mathioudakis. Quantifying\ncontroversy on social media. TSC: ACM Transactions on\nSocial Computing , 1(1):3, 2018.[46]Gueorgi Kossinets and Duncan J Watts. Origins of ho-\nmophily in an evolving social network. American journal\nof sociology , 115(2):405{450, 2009.\n[47]Luca Maria Aiello, Alain Barrat, Rossano Schifanella,\nCiro Cattuto, Benjamin Markines, and Filippo Menczer.\nFriendship prediction and homophily in social media.\nACM Transactions on the Web (TWEB) , 6(2):9, 2012.\n[48]Alessandro Bessi, Fabio Petroni, Michela Del Vicario,\nFabiana Zollo, Aris Anagnostopoulos, Antonio Scala,\nGuido Caldarelli, and Walter Quattrociocchi. Homophily\nand polarization in the age of misinformation. The Euro-\npean Physical Journal Special Topics , 225(10):2047{2059,\n2016.\n[49]Eytan Bakshy, Solomon Messing, and Lada A Adamic.\nExposure to ideologically diverse news and opinion on\nfacebook. Science , 348(6239):1130{1132, 2015.\n[50]Vincent D Blondel, Jean-Loup Guillaume, Renaud Lam-\nbiotte, and Etienne Lefebvre. Fast unfolding of communi-\nties in large networks. Journal of statistical mechanics:\ntheory and experiment , 2008(10):P10008, 2008.\n[51] Kiran Garimella, Gianmarco De Francisci Morales, Aris-\ntides Gionis, and Michael Mathioudakis. Reducing Con-\ntroversy by Connecting Opposing Views. In WSDM '17:\n10th ACM International Conference on Web Search and\nData Mining , pages 81{90, 2017.\n[52]R. M. Anderson and R. M. May. Infectious diseases in\nhumans . Oxford University Press, Oxford, 1992.\n[53]Laijun Zhao, Hongxin Cui, Xiaoyan Qiu, Xiaoli Wang, and\nJiajia Wang. Sir rumor spreading model in the new media\nage. Physica A: Statistical Mechanics and its Applications ,\n392(4):995 { 1003, 2013.\n[54]Clara Granell, Sergio G\u0013 omez, and Alex Arenas. Dynami-\ncal interplay between awareness and epidemic spreading\nin multiplex networks. Phys. Rev. Lett. , 111:128701, Sep\n2013.\n[55]Petter Holme. Network reachability of real-world contact\nsequences. Phys. Rev. E , 71:046119, Apr 2005.\n[56] https://mediabiasfactcheck.com .\n[57]Alessandro Bessi, Fabiana Zollo, Michela Del Vicario,\nMichelangelo Puliga, Antonio Scala, Guido Caldarelli,\nBrian Uzzi, and Walter Quattrociocchi. Users polarization\non facebook and youtube. PloS one , 11(8):e0159641, 2016.\n[58]Ana Luc\u0013 \u0010a Schmidt, Fabiana Zollo, Antonio Scala, Cor-\nnelia Betsch, and Walter Quattrociocchi. Polarization of\nthe vaccination debate on facebook. Vaccine , 36(25):3606{\n3612, 2018.\n11\nSupplementary InformationEcho Chambers on Social Media: A comparative analysis\nHere we show additional results not shown in the main paper: additional data sets in Section I and additional results\nfor the SIR dynamics run with di\u000berent parameters in Section II\nI. ADDITIONAL DATA SETS\nIn this section we report the results obtained for other four data sets not shown in the main paper, namely \\Science\nand Conspiracy\" (Facebook), \\Gun control\" (Twitter), \\Obamacare\" (Twitter) and `The Donald\" (Reddit). The\ntechniques and the pipeline is the same used for the datasets analyzed in the main paper.\nA. Science and Conspiracy\n(a)\n1e+011e+031e+05\n05101520\nCommunity IDCommunity Size\nScienceConspiracy (b)\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nseed leaninginfluence set leaning\n2.02.53.03.5Influence set \naverage size\n(c)\n\u25cf\u25cf\n\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n306090Influence Set \nAverage Size (d)\nFIG. 7: Science vs Conspiracy. Panel (a): Individual leaning versus neighborhood leaning. Panel (b): Community detection.\nPanel (c) and (d): average leaning h\u0016(x)iof the in\ruence sets reached by users with leaning x, for infection probability\n\f= 0:01hki\u00001and\f= 0:02hki\u00001, respectively, where hkiis the average degree of the network.\nFigure 7 displays the results obtained for the Facebook dataset called \\Science and Conspiracy\", described in\nMaterials and Methods of the main paper. Panel (a) shows the joint distribution of the leaning of users, x, against\nthe average leaning of their neighborhood XN. We note that the community referred to as \\Science\", to which is\nassociated a leaning of -1, is much smaller than the community called \"Conspiracy\" and for this reason it is not clearly\n12\nvisible in the density plot but only in the histograms at its margins. Panel (b) shows the size and average leaning of\ncommunities detected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning h\u0016(x)iof the in\ruence sets reached by\nusers with leaning x, for two di\u000berent values of the infection probability, while the recovery rate is \fxed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ruence sets.\nB. Guncontrol\n(a)\n1101001000\n1 2 3\nNumber of CommunitiesCommunity Size\nAgainst \nGuncontroPro \nGuncontrol (b)\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n20406080Influence Set \nAverage Size\n(c)\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n3.54.04.55.05.5Influence Set \nAverage Size (d)\nFIG. 8: Gun control. Panel (a): Individual leaning versus neighborhood leaning. Panel (b): Community detection. Panel (c)\nand (d): average leaning h\u0016(x)iof the in\ruence sets reached by users with leaning x, for infection probability \f= 0:1hki\u00001and\n\f= 0:2hki\u00001, respectively, where hkiis the average degree of the network.\nFigure 8 shows the results obtained for the Twitter dataset \\Gun control\", described in Materials and Methods of\nthe main paper. Panel (a) shows the joint distribution of the leaning of users, x, against the average leaning of their\nneighborhood XN, in which two di\u000berent regions are clearly visible. Panel (b) shows the size and average leaning of\ncommunities detected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning h\u0016(x)iof the in\ruence sets reached by\nusers with leaning x, for two di\u000berent values of the infection probability, while the recovery rate is \fxed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ruence sets.\n13\n(a)0.33\n1101001000\n1 2 3 4\nNumber of CommunitiesCommunity Size\nAgainst ObamacarePro Obamacare\n(b)\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n100200300400500Influence Set \nAverage Size\n(c)\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n46810Influence Set \nAverage Size (d)\nFIG. 9: Obamacare. Panel (a): Individual leaning versus neighborhood leaning. Panel (b): Community detection. Panel (c)\nand (d): average leaning h\u0016(x)iof the in\ruence sets reached by users with leaning x, for infection probability \f= 0:1hki\u00001and\n\f= 0:2hki\u00001, respectively, where hkiis the average degree of the network.\nC. Obamacare\nFigure 9 shows the results obtained for the Twitter dataset referred to as \\Obamacare\", described in Materials\nand Methods of the main paper. Panel (a) shows the joint distribution of the leaning of users, x, against the average\nleaning of their neighborhood XN, in which two interconnected regions are clearly visible. Panel (b) shows the size\nand average leaning of communities detected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning h\u0016(x)iof the in\ruence sets reached by\nusers with leaning x, for two di\u000berent values of the infection probability, while the recovery rate is \fxed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ruence sets.\nD. TheDonald\nFigure 10 shows the results obtained for the Reddit dataset \\The Donald\", described in Materials and Methods of\nthe main paper. Panel (a) displays the joint distribution of the leaning of users, x, against the average leaning of their\nneighborhood XN, showing a unique region spanning most of the x-axis and concentrated on the values around 0.25 on\nthe y-axis. Such a region is also characterized by few peaks of leaning (spanning mainly from Center to Extreme Right)\nthat are displayed in the histogram on the top margin. Panel (b) shows the size and average leaning of communities\ndetected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning h\u0016(x)iof the in\ruence sets reached by\n14\n(a)\n1101001000\n0 10 20 30\nCommunity IDCommunity Size\nExtreme \nLeftExtreme \nRight (b)\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n255075100125Influence Set \nAverage Size\n(c)\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n23002400250026002700Influence Set \nAverage Size (d)\nFIG. 10: The Donald. Panel (a): Individual leaning versus neighborhood leaning. Panel (b): Community detection. Panel (c)\nand (d): average leaning h\u0016(x)iof the in\ruence sets reached by users with leaning x, for infection probability \f= 0:0067 hki\u00001\nand\f= 0:013 hki\u00001, respectively, where hkiis the average degree of the network.\nusers with leaning x, for two di\u000berent values of the infection probability, while the recovery rate is \fxed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ruence sets.\n15\nII. ROBUSTNESS OF THE SIR DYNAMICS\nIn this section, we provide additional results for the SIR dynamics run with di\u000berent parameters on the 6 data\nsets considered in the main paper, namely \\Abortion\" on Twitter, \\Politics\" and \\News\" on Reddit, \\Vaccines\" and\n\\News\" on Facebook, and Gab.\nThe results, reported in \fg. 11, are qualitatively identical to the ones in the main paper and are reported here for\nthe sake of brevity. Details about the parameters used in the simulations are provided in the caption of Fig. 11.\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n4.04.55.05.56.06.5Influence Set \nAverage Size\n(a)Abortion (Twitter)\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n100200300400Influence Set \nAverage Size (b)Politics (Reddit)\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n4.04.55.05.56.0Influence Set \nAverage Size (c)Vaccines (Facebook)\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n5678910Influence Set \nAverage Size\n(d)Gab\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n2345Influence Set \nAverage Size (e)News (Facebook)\n\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\n\u22121.0\u22120.50.00.51.0\n\u22121.0\u22120.5 0.00.51.0\nSeed LeaningInfluence Set Leaning\n200022002400Influence Set \nAverage Size (f)News (Reddit)\nFIG. 11: Additional results of the SIR dynamics for the six data sets considered in the main paper. Average leaning h\u0016(x)iof\nthe in\ruence sets reached by users with leaning x, for infection probability \f= 0:05hki\u00001(Abortion on Twitter, panel (a)),\n\f= 0:005 hki\u00001(Politics on Reddit, panel (b)), \f= 0:02hki\u00001(Vaccines on Facebook, panel (c)), \f= 0:025 hki\u00001(Gab, panel\n(d)),\f= 0:025 hki\u00001(News on Facebook, panel (e)), \f= 0:01hki\u00001(News on Reddit, panel (f)), while the recovery rate is \fxed\n\u0017= 0:2. Size and color of each point is related to the average size of the in\ruence sets.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Echo chambers on social media: A comparative analysis", "author": ["M Cinelli", "GDF Morales", "A Galeazzi"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "Recent studies have shown that online users tend to select information adhering to their system  of beliefs, ignore information that does not, and join groups - ie, echo chambers - around"}, "filled": false, "gsrank": 180, "pub_url": "https://arxiv.org/abs/2004.09603", "author_id": ["3qOq_28AAAAJ", "R0JCEqMAAAAJ", "DK0tXAIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:YF2AXHhevcoJ:scholar.google.com/&output=cite&scirp=179&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D170%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=YF2AXHhevcoJ&ei=I7WsaOqIEbXCieoP4PfQ0A8&json=", "num_citations": 107, "citedby_url": "/scholar?cites=14608936637300759904&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:YF2AXHhevcoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2004.09603"}}, {"title": "Crowdsourced Measure of News Articles Bias: Assessing Contributors' Reliability.", "year": "2018", "pdf_data": "  Crowdsourced Measure of News Articles Bias:  Assessing Contributors\u2019 Reliability  Emmanuel Vincent* & Maria Mestre* *Factmata Ltd., 114 Whitechapel High St, London E1 7PT firstname.lastname@factmata.com    Abstract We tackle the challenge of building a corpus of articles la-belled for their political bias by relying on assessments pro-vided by a crowd of contributors. The definition of \u2018bias\u2019 can be ambiguous to participants and both the targets of the ratings (articles) and the source of ratings (contributors) can be biased in some ways. In this paper, we explore tech-niques to mitigate this subjectivity and learn about the bias of both articles and contributors from the agreements and disagreements among their assessments. We report on the effectiveness of using a set of gold-standard articles to eval-uate the reliability of contributors and discuss work in pro-gress to evaluate the bias of contributors from their relative assessments of articles\u2019 bias. Introduction   News providers are routinely accused of displaying politi-cal bias and this has become a pressing issue as the polari-zation is the population is increasing, notably in the US (Martin and Yurukoglu 2017). Social media platforms where users increasingly get their news have also been pointed as a source of increased polarization among the public and for favoring the rise of extremely biased infor-mation providers, whose inflammatory language is particu-larly prone to spreading on social media (Marwick and Lewis 2017).  Increased partisanship in news results in enhanced polar-ization in societies, which undermines democracy and is sometimes a factor in increasing ethnic violence (Minar and Naher 2018). For this reason, several governments have recently attempted to address this growing concern by developing legislation against \u201cfake news\u201d. Advertisers are also increasingly interested in measures and detection of extreme bias in online content, as their brand values might                                                 Copyright \u00a9 2018, Association for the Advancement of Artificial Intelli-gence (www.aaai.org). All rights reserved.  1 https://mediabiasfactcheck.com/ 2 https://crowdflower.com/ be incompatible with funding hyper partisan or divisive content.  In this context, finding scalable ways to assess the bias of articles or information providers is a pressing challenge. This paper presents the first step of ongoing work in Fact-mata\u2019s effort to create a corpus of articles annotated for political bias relying on a crowdsourced approach and de-sign of a system to identify the most reliable contributors. Related work Several websites compile lists of news outlets character-ized by their bias, one of the most prominent being Media Bias/Fact Check (MBFC)1. Like other similar initiatives, MBFC relies on the classification established by a few individuals and classifies news sources at the outlet level, based on analysis of a few articles published by the outlet. Approaches based on natural language processing (NLP) have been used to scale up bias detection, as Lazaridou and Krestel (2016), for example, who analyzed which politi-cians were being quoted by two major UK outlets, and showed this provided an indication of the outlets\u2019 political biases. Patankar and Bose (2016) have approached the challenge of determining bias at the individual news arti-cles level using NPL tools that detect non-neutral sentence formulations based on Wikipedia non-NPOV corpus.  Further automation of bias detection based on Machine Learning approaches will need the creation of large da-tasets of labeled articles, and in this case crowdsourced solutions offer interesting scalability perspective. Budak, Goel and Rao (2016) performed a large-scale analysis of media bias in which contributors recruited on Mechanical Turk assessed the political bias of more than 10,000 arti-cles from major media outlets covering US politics. How-ever studies like this one did not investigate how to learn about the bias and reliability of contributors from their                                                 1 https://mediabiasfactcheck.com/ \nassessments. More insight can be learned in this respect from online rating systems, in relation to which research has been lead on trust and reputation to identify contribu-tors\u2019 reliability and identify potentially biased or spam users (read Swamynathan, Almeroth and Zhao 2010 for an overview). The challenge is to develop a system that al-lows to learn both about the bias of the news articles that are being labeled and the bias and reliability of the contrib-utors who provide the labels. Data Crowdsourcing bias assessments We drew articles from a pilot study, representing a corpus of 1,000 articles on which ads had been displayed for the account of a customer; these thus form a sample of highly visited news articles from mainstream media as well as more partisan blog-like \u201cnews\u201d sources. We used the Crowdflower platform2 to present these articles to partici-pants who were asked to read each article\u2019s webpage and answer the question: \u201cOverall, how biased is this article?\u201d, providing one answer form the following five-point bias scale:  1. Unbiased  2. Fairly unbiased  3. Somewhat biased 4. Biased  5. Extremely biased   To guide their assessments, we provided contributors with more details regarding how to classify articles in the form of a general definition of biased article as well as examples of articles with their expected classification (see Appendix 1 for details of the instructions). We chose a five-point scale to allow contributors to express their de-gree of certainty, leaving the central value on the scale (3) for when they are unsure about the article bias while the values 1 and 2 or 4 and 5 represent higher confidence that the article is respectively unbiased or biased to a more (1 and 5) or less (2 and 4) marked extent. Fifty participants contributed to the labeling and five to fifteen contributors assessed each article (see Appendix 2 for an example).  \u2018Gold\u2019 dataset To assess the reliability of contributors, we also asked two expert annotators (a journalist and a fact-checker) to esti-mate which bias ratings should be counted as acceptable for a quarter of all the articles in the dataset. For each arti-cle in this \u2018gold\u2019 dataset, the values provided by the two experts are merged. Two values are typically found to be acceptable for an article (most often 1 and 2, or 4 and 5),                                                 2 https://crowdflower.com/ but sometimes three values are deemed acceptable and less often one value only: typically when both experts agree the article is either clearly extremely biased or not biased at all (e.g. because it covers a trivial and non-confrontational topic in the latter case). When experts disagree on the na-ture of the bias, providing a set of acceptable ratings as strictly greater than three for one and strictly lower than three for the other, the article is not considered in the gold dataset. Analysis of results Assessing contributors\u2019 reliability As a first approach to guide us regarding the quality of data we collected, we performed a comparison of contributors\u2019 rating with the gold dataset ratings. Building on the \u201cBeta reputation system\u201d framework (Ismail and Josang 2002), we represent users\u2019 reliability in the form of a beta proba-bility density function. The beta distribution \ud835\udc53(\ud835\udc5d|\ud835\udefc,\ud835\udefd) can be expressed using the gamma function \u0393 as:  \ud835\udc53(\ud835\udc5d|\ud835\udefc,\ud835\udefd)=\ud835\udee4(\ud835\udefc+\ud835\udefd)/(\ud835\udee4\ud835\udefc.\ud835\udee4\ud835\udefd) .\ud835\udc5d!(1\u2212\ud835\udc5d)!!!   (1) where \ud835\udc5d is the probability a contributor will provide an acceptable rating, and \ud835\udefc and \ud835\udefd are the number of \u2018correct\u2019 (respectively \u2018incorrect\u2019) answers as compared to the gold. To account for the fact that not all incorrect answers are as far from the gold, we further weight the incorrect answers as follows: an incorrect answer is weighted by a factor of 1, 2, 5 or 10 respectively if its shortest distance to an ac-ceptable answer is 1, 2, 3 or 4 respectively. So \ud835\udefd is incre-mented by 10 (resp. 2) for a contributor providing a rating of 1 (resp. 4) while the gold is 5 (resp. 2) for example. We use the expectation value of the beta distribution \ud835\udc45=\ud835\udefc(\ud835\udefc+\ud835\udefd) as a simple measure of the reliability of each contributor. See figure 1 for examples of reputation function obtained for (a) a user with few verified reviews, (b) a contributor of low reliability and (c) a user of high reliability.  Inter-rater reliability: We calculated Krippendorff\u2019s alpha to measure the inter-rater agreement (Krippendorff 2011). When we include every worker, we obtain a value for alpha of 0.078, which can be interpreted as a very low agreement. However, in-ter-rater agreement is much higher when we perform the calculation only for contributors with a high reliability: the value of alpha is 0.40 (resp. 0.76) when we consider con-tributors with R greater than 0.5 (resp. 0.7).  Assessing articles\u2019 bias based on contributors\u2019 rat-ings Our goal is to determine the articles\u2019 bias and a degree of confidence in that classification based on signals provided \nby the crowd. A straightforward way to obtain an overall rating is to simply take each assessment as a \u2018vote\u2019 and average these to obtain a single value for the article.  \nFigure 1 \u2013 Examples of reputation function obtained for (a) a user with few verified reviews for whom the uncertainty is still large, (b) a contributor of low reliability and (c) a user of high reliability. Shading shows the 95% probability interval. However to try and get closer to an objective assessment of the article\u2019s bias, we tested the approach of weighting each rating by the reliability of the contributor. We tested a \u2018linear\u2019 weight for which a user\u2019s rating is weighted by its reliability \ud835\udc45 and a more aggressive \u2018exponential\u2019 weight for which a user\u2019s rating is weighted by 10!\u00d7(!!!/!) so that an absolutely reliable (\ud835\udc45=1) contributor\u2019s rating would weight a hundred times more than a contributor of reliabil-ity \ud835\udc45=0.5. Figure 2 compares an article\u2019s ratings obtained with the-se different weightings applied. While the article\u2019s bias appears disputed from a simple vote perspective (Fig. 2a) with as many contributors judging the article as \u2018unbiased\u2019 (1) and \u2018biased\u2019 (4), it appears quite clearly biased when the exponential weight is applied (Fig. 2c). This reflects the fact that contributors who deem the article biased have higher reliability. In this case, the weighting is improving the clarity of the data collected since this reference-free, anecdote-based article in \u201cBreaking Israel news\u201d on \u201cthe invasion of Canada\u201d by \u201chordes of illegal aliens from Syr-ia, Haiti and anywhere else\u201d can arguably be classified as biased.   \nFigure 2 \u2013 Histogram displaying the bias ratings collected for an article titled \u201cThe invasion of Canada\u201d (a) simple count of the number of users who provided each rating, (b) count weighted by users\u2019 reliability and (c) count exponentially weighted by users\u2019 reliability as explained in the text. Experiment: using this annotated dataset to improve the machine learning model At Factmata we have a model to detect extreme political content online, which we provide as part of our commer-cial offering. One of the machine learning models was trained on a corpus of 35,236 articles scraped from do-\n0.00.51.012345Simple \u2018vote\u2019(ave=3.0)\n0.00.51.0Linear Weight(ave=3.47)\n0.00.51.0Exponential Weight(ave=4.11)Bias ratingNormalized countArticle id: 1586712037\n(b)(a)(c)\nmains that came from an open-source list of highly biased domains. This training dataset has noisy labels, so we de-cided to use the new labelled dataset described in this pa-per to estimate the performance of our algorithm, as well as understand how the performance would change if we added this dataset to the training data.  We first quantized the aggregated weighted scores, so that each article would fall into one of three categories: \u201cvery biased\u201d\u201d, \u201cunbiased\u201d or \u201cmixed/undecided\u201d. We only kept the first two categories, so we ended up with 280 biased instances (i.e. positives) and 260 unbiased instances (i.e. negatives). We split this dataset into training and test, splitting by domains. A domain tends to use similar lan-guage across all its pages, so by creating this test set, we are measuring how well a model generalizes to a new un-seen domain. We ended up with the dataset described in the table below.  Dataset Number of positives Number of negatives Original training 8971 26265 Original + manual training 9133 26439 Manual test dataset 86 118 We ran an experiment, where we trained the model on the aggregated training dataset, as well as the original. We then measured the performance improvement on the manu-ally labeled test set. The results are in the table below: Performance metrics on manual test set Precision Recall F1-score ROC-AUC Original training 0.74 0.78 0.76 0.52 Original + manual train-ing 0.71 0.88 0.78 0.65 As we can see, the largest improvement was seen in the recall of the new model, likely because the manually la-beled dataset has captured types of political bias that do not occur in the open-source dataset. Even though we only increased the training data by less than 1%, the ROC-AUC improved by 25% and the recall by 13%. This is a promis-ing result showing that a small addition of manually la-beled data can make a significant improvement in the pre-dictive power of a model trained on noisy labels. Conclusion, and future work In this paper, we have presented work in progress to create a corpus of news articles labeled for political bias and de-velopment of a method to identify reliable contributors. As a first step, we compute a reliability score for each contrib-utor by comparing their assessment to a set of experts-created acceptable assessments on a subset of the articles. Using a probabilistic framework allows us to estimate the confidence we can have in users\u2019 reliability scores. Weighting users\u2019 contributions by their reliability score increases the clarity of the data and allows us to identify the articles that have been confidently classified by the consensus of high reliability users to train our machine learning algorithms. This notably allows us to note that high reliability contributors disagree on the bias rating for about a third of the articles, which we use to train our ma-chine learning model to recognize uncategorizable articles in addition to biased and unbiased.  This research is very preliminary. An important next step will be to learn about potential contributors\u2019 bias from the pattern of their article ratings: for instance a contributor might be systematically providing more \u201cleft-leaning\u201d or \u201cright-leaning\u201d ratings than others, which could be taken into account as an additional way to generate objective classifications. This would turn a low quality input into useful data. Another avenue of research will be to mitigate possible bias in the gold dataset. This can be achieved by broadening the set of experts providing acceptable classifi-cation and/or by also calculating a reliability score for ex-perts, who would start with a high prior reliability but have their reliability decrease if their ratings diverge from a classification by other users when a consensus emerges. Appendix 1. Article bias assessment instructions provided to contributors Definition Biased articles provide an unbalanced point of view in de-scribing events; they are either strongly opposed to or strongly in favor of a person, a party, a country\u2026 Very often the bias is about politics (e.g. the article is strongly biased in favor of Republicans or Democrats), but it can be about other entities (e.g. anti-science bias, pro-Brexit bias, bias against a country, a religion\u2026).  A biased article supports a particular position, political view, person or organization with overly suggestive sup-port or opposition with disregard for accuracy, often omit-ting valid information that would run counter to its narra-tive.  Often, extremely biased articles attempt to inflame emo-tion using loaded language and offensive words to target \nand belittle the people, institutions, or political affiliations it dislikes. Rules and Tips Rate the article on the \u201cbias scale\u201d following these instruc-tions: \u2022 Provide a rating of 1 if the article is not biased at all; the article might discuss cooking, movies, lifestyle\u2026 or talk about politics in a neutral and factual way. \u2022 Provide a rating of 2 if the article is fairly unbiased; the article might talk about contentious topics, like poli-tics, but remains fairly neutral. \u2022 Provide a rating of 3 if the article is somewhat biased or if it is impossible to determine its bias, or the article is ambivalent (i.e. biased both for and against the same en-tity). \u2022 Provide a rating of 4 if the article is clearly biased; it overtly favors or denigrates a side, typically an opinion piece with little fairness. \u2022 Provide a rating of 5 if the article is extremely biased / hyper partisan; it overtly favors a side in emphatic terms and/or belittles the other \u2018side\u2019, with disregard for accuracy, and attempts to incite an action or emotion in the reader.  Please do not include your own personal political opinion on the subject of the article or the website itself. If you agree with the bias of the article, you still should tag is as biased. Try and remove any sense of your personal po-litical beliefs, and critically examine the language and the way the article has been written. Please do not pay attention to other information on the webpage (page layout, other articles, advertising etc.). On-ly the content of the article is relevant here: text, hyper-links in it, photos and videos within the text of the article. Also, do not look at the title of the website, its name, or how it looks - just examine the article in front of you and its text. Do not answer randomly, we will reject submissions if there is evidence that a worker is providing spam respons-es. Do not skip the rating, providing an overall bias is re-quired. Examples \u2022 Example of sentences from an hyper-partisan article with many mentions about Donald Trump, clear opposi-tion towards him and loaded language in bold (such an article should be rated as 5): \u201cThis is how a trickle-down of vileness acquires a fire hose. But the big story doesn\u2019t stop with Trump\u2019s globe-wide gift to the worst devils of human nature. The big story is that Trump, or his trusted Ministers of Internet Intake, inhabits a bottom-barrel world in which Fox News and Infowars and Gateway Pundit and\u2014sure\u2014Britain First loom large. They\u2019re picking this stuff up, combining through it, repurposing it all the time\u201d \u2022 Example of another hyper-partisan article, with loaded anti-Clinton language in bold, and a call to action at the end for others to join and support the ideology: \"It\u2019s a neat little magic trick. It is also incredibly unethi-cal and most likely illegal\u2026 but then again, that never stopped the Clinton machine before. Please press \u201cShare on Facebook\u201d if you think these dirty tricks need to be exposed!\" \u2022 Example of a biased article (should be rated as 4 on the 1-5 scale). Here, there is less loaded language, but clear-ly the article is one sided towards Trump: \u201cPresident Trump\u2019s stock market rally is historical! No President has seen more all time highs (63) in their first year in office than President Trump. President Trump set the record earlier this year for the most all time closing stock market highs during his first year in office. Currently the Dow has set 80 closing highs since last year\u2019s election and 63 since President Trump\u2019s inauguration. (As a com-parison, President Obama had no stock market highs his entire first term.)\u201d \u2022 Example of an article talking about a trivial topic. Even though the article speaks positively about money orders and Rite Aid, this shouldn\u2019t be marked as biased (should be rated as 1): \u201cFor people who want to pay bills, purchase goods, or simply want to send guaranteed funds without the risk as-sociated with exchanging cash, money orders are a trusted method of payment. Rite Aid money orders are convenient because of the low fees, numerous locations, and long hours.\u201d 2. Sample annotation data pageurl worker_id article_bias url1 44278209 3.0 url1 43718845 4.0 url1 38202325 4.0 url1 37881503 4.0 url1 44164300 4.0 url1 55128002 4.0 url1 55128001 3.0 url1 55128003 2.0 url2 31613324 3.0 url2 44128742 2.0 url2 39793872 5.0 url2 38202325 5.0 url2 44303394 5.0 url2 37881503 4.0 url2 55128002 4.0 url2 55128003 4.0 \nurl2 55128004 5.0 url3 31613324 4.0 url3 44128742 5.0 url3 16718271 1.0 url3 43951421 1.0 url3 44303394 3.0 url3 38202325 4.0 url3 37881503 2.0 url3 55128002 1.0 url3 55128001 1.0 url3 55128003 1.0 url3 55128004 1.0  \u2022 url1: http://www.stlamerican.com/news/local_news/privilege-at-the-protest-white-allies-demonstrate-without-incident-outside/article_543f4ba2-9f5f-11e7-95d0-c3a75bed0e90.html \u2022 url2: http://www.theamericanconservative.com/buchanan/trump-embraces-the-culture-war/ \u2022 url3: http://www.thegatewaypundit.com/2017/10/breaking-active-shooter-reported-usc-campus-lockdown-videos/ References Budak, C., Goel, S. and Rao, J.M., 2016. Fair and balanced? quantifying media bias through crowdsourced content analy-sis. Public Opinion Quarterly, 80(S1), pp.250-271. Ismail, R. and Josang, A., 2002. The beta reputation sys-tem. BLED 2002 proceedings, p.41. Krippendorff, K., 2011. Computing Krippendorff's alpha-reliability. Lazaridou, K. and Krestel, R., 2016. Identifying Political Bias in News Articles. Bulletin of the IEEE TCDL, 12. Martin, G.J. and Yurukoglu, A., 2017. Bias in cable news: Per-suasion and polarization. American Economic Review, 107(9), pp.2565-99. Marwick, A. and Lewis, R., 2017. Media manipulation and disin-formation online. New York: Data & Society Research Institute. Minar, M.R. and Naher, J., 2018. Violence originated from Face-book: A case study in Bangladesh. arXiv preprint arXiv:1804.11241. Patankar, A.A. and Bose, J., 2016, June. Bias Based Navigation for News Articles and Media. In International Conference on Applications of Natural Language to Information Systems (pp. 465-470). Springer, Cham.  Swamynathan, G., Almeroth, K.C. and Zhao, B.Y., 2010. The design of a reliable reputation system. Electronic Commerce Re-search, 10(3-4), pp.239-270. ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Crowdsourced Measure of News Articles Bias: Assessing Contributors' Reliability.", "author": ["E Vincent", "M Mestre"], "pub_year": "2018", "venue": "SAD/CrowdBias@ HCOMP", "abstract": "We tackle the challenge of building a corpus of articles labelled for their political bias by  relying on assessments provided by a crowd of contributors. The definition of \u2018bias\u2019 can be"}, "filled": false, "gsrank": 182, "pub_url": "https://sadworkshop.wordpress.com/wp-content/uploads/2018/07/sad_2018_paper_7-3.pdf", "author_id": ["", "1dh-y6QAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:8XGwt7VhJ6sJ:scholar.google.com/&output=cite&scirp=181&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D180%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=8XGwt7VhJ6sJ&ei=JbWsaMu1E-HUieoP9LKZ6AI&json=", "num_citations": 13, "citedby_url": "/scholar?cites=12332933537676161521&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:8XGwt7VhJ6sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://sadworkshop.wordpress.com/wp-content/uploads/2018/07/sad_2018_paper_7-3.pdf"}}]