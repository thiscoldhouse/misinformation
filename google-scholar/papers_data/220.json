[{"title": "Self-supervised claim identification for automated fact checking", "year": "2021", "pdf_data": "Self-Supervised Claim Identi\ufb01cation for Automated Fact Checking\nArchita Pathak\nUniversity at Buffalo (SUNY)\nBuffalo, NY\narchitap@buffalo.eduMohammad Abuzar Shaikh\nUniversity at Buffalo (SUNY)\nBuffalo, NY\nmshaikh2@buffalo.eduRohini K. Srihari\nUniversity at Buffalo (SUNY)\nBuffalo, NY\nrohini@buffalo.edu\nAbstract\nWe propose a novel, attention-based self-\nsupervised approach to identify \u201cclaim-\nworthy\u201d sentences in a fake news article,\nan important \ufb01rst step in automated fact-\nchecking. We leverage aboutness of headline\nand content using attention mechanism for\nthis task. The identi\ufb01ed claims can be used\nfor downstream task of claim veri\ufb01cation for\nwhich we are releasing a benchmark dataset\nof manually selected compelling articles\nwith veracity labels and associated evidence.\nThis work goes beyond stylistic analysis to\nidentifying content that in\ufb02uences reader\nbelief. Experiments with three datasets show\nthe strength of our model1.\n1 Introduction\nThe explosion of fake news on social media has\nresulted in global unrest and has been a major con-\ncern for governments and societies worldwide2.\nAccording to a recent Pew Research Study, Amer-\nicans rate it as a larger problem than racism, cli-\nmate change, or illegal immigration3. Since, it\u2019s\ninexpensive to create a website and easily dissem-\ninate content on the social media platforms, there\nis a rising need for automated fake news detec-\ntion. Furthermore, AI solutions are also required\nto follow good practices, speci\ufb01cally avoiding cen-\nsorship, violation of fundamental rights such as\nfreedom of expression, and ensuring data privacy\n(de Cock Buning, 2018). However, to date, AI\nmodels proposed for fake news detection do not\n1Data and code available at:\nhttps://github.com/architapathak/Self-Supervised-\nClaimIdenti\ufb01cation\n2https://www.reuters.com/article/us-singapore-politics-\nfakenews-factbox/factbox-fake-news-laws-around-the-\nworld-idUSKCN1RE0XN\n3https://www.journalism.org/2019/06/05/many-\namericans-say-made-up-news-is-a-critical-problem-that-\nneeds-to-be-\ufb01xed/scale for detecting real-time fake news4.\nMuch of the research on automated text-based\nfake news detection can be classi\ufb01ed into three\nbroad categories: (1) linguistic approach, which\nfocuses on lexical, stylometric and pattern learning\nmechanisms (Potthast et al., 2017; Rashkin et al.,\n2017; Wang, 2017; Singhania et al., 2017; P \u00b4erez-\nRosas et al., 2018); (2) network-based approach,\nwhich leverages features such as the speed and vol-\nume of propagation of fake news articles on social\nmedia platforms (Castillo et al., 2011; Yang et al.,\n2012; Kwon et al., 2013; Ma et al., 2015; Jin et al.,\n2016; Ruchansky et al., 2017; Wu and Liu, 2018);\nand (3) automated fact-checking approach, which\nis an effort to assist manual fact-checkers by au-\ntomating some of their tasks such as detection and\nveri\ufb01cation of claims (Graves, 2018).\nWhile most work in automated fact-checking\nhas been focused on claim veri\ufb01cation task, very\nfew methods have been proposed for detection of\nclaims (Hassan et al., 2017; Jaradat et al., 2018;\nKonstantinovskiy et al., 2018). The approaches\nin these efforts are majorly related to political dis-\ncourse . However, our focus is on fake news , which\nare broader than political discourse since (i) they\nare deliberately written with a divisive agenda to\ncause social unrest, (ii) they are not constrained to\nonly politics, and (iii) the headline plays an equally\nimportant role in compelling people to read the\narticle.\nIn this paper, we focus on articles where there is\na deliberate intent to in\ufb02uence readers through fab-\nricated or manipulated claims in the headline and\nthe content. Such articles have a compelling writ-\ning style similar to the mainstream media. Hence,\nwe build datasets containing these type of com-\npelling articles along with veracity labels and as-\nsociated evidence supporting the label of each arti-\n4https://www.technologyreview.com/s/612236/even-the-\nbest-ai-for-spotting-fake-news-is-still-terrible/arXiv:2102.02335v1  [cs.CL]  3 Feb 2021\ncle. We, then, use these datasets to identify \u201cclaim-\nworthy\u201d sentences. In our work, we de\ufb01ne \u201cclaim\u201d\nas\u201cstatements which are important to the point\nof the article but one would require to have them\nveri\ufb01ed. \u201d\nOur working hypothesis is that in fake news\nwhich are created to cause harm, these are the sen-\ntences most relevant to the headline. Exploiting\nthe hypothesis that the essence of a news article is\nencapsulated in its headline (Jaime Sis \u00b4o and MER-\nCEDES, 2009; Kuiken et al., 2017; Wahl-Jorgensen\nand Hanitzsch, 2009), we propose a self-supervised\nmethod to explore the aboutness of the content with\nthe headline of the article to extract the most rele-\nvant sentences. Bruza and Huibers (1996) de\ufb01nes\naboutness as:an information carrier i will be said\nto be about information carrier j if the informa-\ntion borne by j holds in i . The idea is taken from\nInformation Retrieval domain where it is used to\nsignify implications between query and document,\nspeci\ufb01cally to explore the underlying meaning or\nconcept within the document and the query (Az-\nzopardi et al., 2009). In our work, headline is mod-\nelled as a query while each of the sentences of the\narticle acts as a document, and we use the concept\nofaboutness to \ufb01nd the relevant sentences. We\nshow that attention-based mechanisms are able to\nsuccessfully capture this concept in the news arti-\ncle.\nContribution: In this work: (i) we introduce\na self-supervised representation learning model\nthat eliminates the prerequisite that requires human\nto annotate data, which is a time consuming and\ncostly task; (ii) the proposed headline-to-sentence\nattention-based approach for claim identi\ufb01cation is\nnovel; previous unsupervised approach for this task\nuse weak supervisory signal which does not capture\nthe context of the article ef\ufb01ciently; and (iii) we\npropose a benchmark dataset for evidence-based\nfake news detection. Our dataset contains evidence\nfor each of the fake news articles that contributes\nto the overall degree of veracity of the article.\n2 Related Work\nClaim Identi\ufb01cation/Detection: The task of\nclaim identi\ufb01cation/detection was \ufb01rst introduced\nby Levy et al. (2014) who, with the help of human\nannotators, provided a dataset and a fundamental\napproach in identifying context dependent claims.\nIn their dataset, which was originally developed\nby Aharoni et al. (2014), each statement indicateswhether it should be considered as a context de-\npendent claim (CDC) or not. Levy et al. (2014)\nreported encouraging results obtained through a\nsupervised learning algorithm using a cascade of\nclassi\ufb01ers. A rule-based model was introduced\nby Eckle-Kohler et al. (2015) to bifurcate claim\nand premise statements in an argumentative dis-\ncourse environment. However, these methods were\ngeneric to only a small set of corpora. Furthermore,\nLevy et al. (2017) also introduced an unsupervised\napproach to detect claims, which involves a weak\nsupervisory signal \u201cthat\u201d for training. However,\nthis approach does not capture the aboutness of the\narticle to understand the context of \u201cclaim-worthy\u201d\nsentences.\nIn 2017, Hassan et al. (2017) introduced Claim-\nBuster, a platform developed by training a super-\nvised learning model on a large annotated cor-\npus of televised debates in the USA. Their model\nused SVM classi\ufb01er to detect claim-worthy factual\nclaims and produced a score of how important a\nclaim is to factcheck. The 20,000 sentences in the\ncorpus were annotated by human coders to distin-\nguish between claim-worthy factual claims from\nopinions and boring statements. However, anno-\ntating a sentence as an important or unimportant\nclaim is a non-trivial task as this decision changes\ndepending on who\u2019s asking, political context and\nannotator\u2019s background (Graves, 2018).\nThe model proposed by Hassan et al. (2017)\nonly learns the labelled instances and does not\nexplore the contextual information of the written\ntext. A context-aware approach in the political dis-\ncourse environment was introduced by Gencheva\net al. (2017) who created a rich representation of\nthe sentences from 2016 US presidential debates.\nTheir dataset was compiled by taking the outputs\nof factchecking of the debates from 9 factchecking\norganizations. Their models were created to pre-\ndict if the claim would be highlighted by at least\none or by a speci\ufb01c organization. However, the\nauthors don\u2019t have any formal de\ufb01nition of claim\nin their paper, and their model is speci\ufb01c to certain\norganizations which led to several false positives.\nAnother context-aware approach for claim de-\ntection was proposed by Konstantinovskiy et al.\n(2018) who used sentence embeddings, pre-trained\non a large dataset of NLI. This work also created a\ncrowd-sourced annotated dataset of sentences from\nUK political TV shows, annotated across 7 classes.\nHowever, their classi\ufb01ers for the \ufb01ne-grained clas-\nsi\ufb01cation to detect 7 classes of sentences did not\nyield good results due to lack of enough annotated\ndata, thus requiring more annotations which is a\ncostly and time consuming task.\nWe build a model that can be trained in a self-\nsupervised setting to overcome the challenges as-\nsociated with annotated dataset of claims. We also\nuse attention-based approach to capture aboutness\nand rich contextual information between headline\nand all the sentences of the article. The perfor-\nmance on manually created test sets demonstrate\npromising results in identifying \u201cclaim-worthy\u201d\nsentences even when no sentence-level annotation\nwas used for training.\nFake News Dataset: A variety of fake news\ndatasets have been released in the recent years,\nmost notably Buzzfeed5and Stanford (Allcott and\nGentzkow, 2017) datasets containing list of popu-\nlar fake news articles from 2016 US presidential\nelections. However, these datasets only contain\nwebpage URLs of the original article and major-\nity of them don\u2019t exist anymore. Following this,\nseveral other datasets were published such as Fake\nnews challenge dataset6which was used for the\ntask of stance detection; Getting Real about Fake\nNews Kaggle dataset7which was created by using\nBS detector tool; and FakeNewsCorpus8which is\nan open-source large scale collection of fake news\narticles. However, these articles are labelled as fake\nbased on the domain of the websites they come\nfrom. Since, the content of these articles are not\nveri\ufb01ed for degree of veracity, using them directly\nfor training may lead to several false positives.\nThis problem was overcome by recently released\nlarge dataset, NELA-GT-2018 (Norregaard et al.,\n2019), which contains articles with ground truth\nratings retrieved from 8 different assessment sites.\nHowever, the label de\ufb01nitions are not generic and\ndependent on the external organizations. Pathak\nand Srihari (2019) also introduced intuitive ground\ntruth labels based on the degree of veracity of\nthe fake news articles, however, the dataset is not\npublicly available. Additionally, they also do not\nspecify the relationship of their labels with the la-\nbels used by established fact-checking organiza-\ntions. Furthermore, due to lack of evidence in these\ndatasets, they cannot be used for downstream task\n5https://www.buzzfeednews.com/article/craigsilverman/these-\nare-50-of-the-biggest-fake-news-hits-on-facebook-in\n6http://www.fakenewschallenge.org/\n7https://www.kaggle.com/mrisdal/fake-news\n8https://github.com/several27/FakeNewsCorpusof evidence-based veri\ufb01cation, which is one of the\nmotivations of this paper. We overcome all these\nlimitations in our datasets described in the follow-\ning section.\n3 Datasets\nWe introduce two datasets of compelling fake news\narticles which have writing style similar to main-\nstream media. The \ufb01rst dataset, DNF-700, where\nDNF stands for DisiNFormation , contains articles\non politics published within 4 months of 2016 US\nPresidential Elections from questionable sources\n(non-mainstream). To compile this dataset, we\n\ufb01rst extracted fake news articles from working\nweb page URLs of Stanford dataset (Allcott and\nGentzkow, 2017). However, majority of webpage\nURLs in this dataset are expired and we could ex-\ntract only 26 fake news articles. Therefore, we\nthen used \u201c Getting real about fake news \u201d Kaggle8\ndataset to sample more articles on politics. Since,\nmost of the articles in this dataset contain anoma-\nlies (eg: incomplete article, social media comments\nlabelled as fake etc.), we manually veri\ufb01ed the writ-\ning style and discarded obvious fakes - articles with\npoor grammar and excessive usage of punctuations.\nHowever, the degree of veracity of each article in\nthis dataset is not checked and some articles may\ncontain personal opinions.\nThe second dataset, DNF-300, is more so-\nphisticated subset of DNF-700, containing 290\ncompelling articles on Politics and 10 on\nHealth/Medical news. Unlike other fake news\ndatasets in which veracity and evidence for articles\nare not provided, DNF-300 contains articles associ-\nated with veracity labels as well as corresponding\nevidence. The process of annotating this dataset\ninvolves identifying sentences from each article\nbased on their persuasive tone and relevance with\nthe headline. These sentences were then queried\non the web and top 10 results were considered to\ngather evidence from credible sources9. Based on\nthe evidence found, we label the entire article into\nfour categories:f(0)false ; (1) partial truth ; (2)\nopinions stated as fact ; (3) trueg. These labels\nare inspired by (Pathak and Srihari, 2019); Table-\n1 shows the description and distribution of these\nlabels while the comparison with two popular fact-\nchecking websites is displayed in Figure-1. An\n9Credible sources were extracted from\nhttps://mediabiasfactcheck.com/ The sources range be-\ntween left, center and right biased news sources\nLabel False Partial True Opinion\nStated As\nFactTrue\nDesc. (i) No evi-\ndence could\nbe found, or\n(ii) found\nevidence\nto refute\nthe entire\narticleArticle\nabout true\nevent, how-\never, found\nevidence re-\nfuting some\nof the claimsArticle contain\nfalse/manipulated\nclaims, how-\never, it\u2019s an\nopinion article\nwhich cannot\nbe labelled as\nfakeFound\nevidence\nsupport-\ning the\nentire\narticle\nTotal 126 75 79 20\nTable 1: DNF-300 label description and distribution.\nClaims here are the sentences manually selected based\non their persuasive tone and relevance with the head-\nline. Interestingly, some of the articles, which were\nlabelled as fake in other datasets due to the domain of\npublishing website, turned out to be true news.\nexample from the dataset is shown in Table-2\nPartial T ruth FalseOpinion Stated as\nFactMostly False Mixture Unproven False\nHalf T rue Mostly False False Pants on FireSnopes\nDNF-300\nPolitiFact\nFigure 1: Label Comparison with Snopes and Politi-\nFact ratings.\nThis dataset is also a key contribution of this\npaper as the articles are manually read and veri-\n\ufb01ed. Additionally, the dataset contains two novel\nfeatures which are essential for the fake news ver-\ni\ufb01cation task: (i) generic veracity-based label set,\nindependent of any external organization, and (ii)\nground truth evidence corresponding to each label.\nIn addition to these two datasets, we also train\nour model for claim identi\ufb01cation on the dataset\nintroduced for context dependent claim detection\n(CDCD) by Levy et al. (2014). Although this\ndataset (CDC) does not contain fake news articles,\nit has manually annotated sentences based on their\nrelevance to a certain topic. These annotations were\nutilized for the evaluation of our self-supervised\nlearning model described in the following section.\nMore details on the datasets and examples can be\nfound in Appendix.\n4 Architecture\nProblem De\ufb01nition: Given an article with a set\nof sentences S=fS1;S2;:::S i;:::S ngand a head-\nlineH, the task of our multihead attention claimidenti\ufb01cation network (MA-CIN) is to extract the\nsentence most relevant to the headline. Our self-\nsupervised model exploits the rich contextual infor-\nmation to extract the relevant sentences which are\nconsidered as \u201cclaim-worthy\u201d.\nApproach: For this task, we implement two types\nof attention: (i) self-attention on all sentence vec-\ntors so that each sentence Siis aware of all other\nsentences in S; (ii) cross-attention of headline vec-\ntor on each sentence vector, so that all self-attended\nsentences are also aware of the headline\u2019s context.\nWe then generate headline based on the context-\naware sentences, and compare it with the original\nheadline in three different settings as listed below:\n1.Headline Vector (MA-CIN (HV)): In this\nsetting, the original headline vector acts as the\nsupervisory signal for self-supervised learn-\ning. We minimize the mean squared error\n(MSE) between the generated and the original\nheadline vectors for training.\n2.Headline One-Hot Word Vector (MA-CIN\n(OHWV)): In this setting, the words in the\noriginal headline act as the supervisory sig-\nnal. We use LSTM (Hochreiter and Schmid-\nhuber, 1997) to predict at most 50 words, from\na vocabulary of 20,000 words, to generate\na one-hot-vector for each word of the new\nheadline. We then minimize the categorical\ncross-entropy error (CCE) at each time step\ncorresponding to each word in original and\nnew headlines for training.\n3.Combined HV & OHWV (MA-CIN (Com-\nbined)): In this setting, both original headline\nvector and the words act as supervisory signal.\nTherefore, we combine the two loss functions\nmentioned above to train the model.\nFor this, we build several layers in our architecture\n(see Figure-2), which are delineated as follows:\n4.1 Sentence Embeddings\nEach sentence Si2S, and headline Hare con-\nverted to a \ufb01xed length 300-dimensional vector, si\nandh, such thatsi;h2R1\u0002D, whereD= 300 .\nFor uniformity, we calculate the maximum num-\nber of sentences Lthat an article can contain in\nthe respective corpus. Next, we zero pad the dif-\nference in the quantity of sentence vectors in each\narticle such that every article can be represented as\na vectorA2RL\u0002D.\nHeadline : Allergens in Vaccines Are Causing Life-Threatening Food Allergies\nIt would probably surprise few people to hear that food allergies are increasingly common in U.S.\nchildren and around the world . According to one public health website , food allergies in children\naged 0-17 in the U.S. increased by 50% from 1997 to 2011. Although food allergies are now so\nwidespread as to have become almost normalized, it is important to realize that millions of American\nchildren and adults suffer from severe rapid-onset allergic reactions that can be life-threatening.\nFoods represent the most common cause of anaphylaxis among children and adolescents. The\nUnited Kingdom has witnessed a 700% increase in hospital admissions for anaphylaxis and a\n500% increase in admissions for food allergy since 1990. The question that few are asking is why\nlife-threatening food allergies have become so alarmingly pervasive. A 2015 open access case\nreport by Vinu Arumugham in the Journal of Developing Drugs , entitled \u201c Evidence that Food\nProteins in Vaccines Cause the Development of Food Allergies and Its Implications for Vaccine\nPolicy ,\u201d persuasively argues that allergens in vaccines\u2014and speci\ufb01cally food proteins\u2014may be\nthe elephant in the room. As Arumugham points out, scientists have known for over 100 years that\ninjecting proteins into humans or animals causes immune system sensitization to those proteins.\nAnd, since the 1940s, researchers have con\ufb01rmed that food proteins in vaccines can induce allergy\nin vaccine recipients. Arumugham is not the \ufb01rst to bring the vaccine-allergy link to the public\u2019s\nattention. Heather Fraser makes a powerful case for the role of vaccines in precipitating peanut\nallergies in her 2011 book, The Peanut Allergy Epidemic: What\u2019s Causing It and How to Stop It.\nType : 1 (Partial Truth )\nAuthors :Admin - Orissa\nURLs : galacticconnection.com\nEvidence : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3890451/\nReason : The key claim is written in such a way so that it misleads people in thinking all the food\nrelated allergies in US are caused by vaccines. Found evidence which says these type of allergies\nare rare.\nTable 2: An example on Partial Truth type from DNF-300 dataset.\n4.2 1D Convolution\nTo effectively capture local relevance, we leverage\n1D-CNN (LeCun et al., 1998) to extract the features\nfrom the article vector A. For our experiments the\nkernel size for each convolution layer is K\u0002D\u0002\nC, whereKis kernel-width and Cis the number\nof \ufb01lters. This means the network will process\nK sentences at a time. The size of K and C is a\nhyper-parameter and as per our experiments, we\nsetK= 4with an assumption that not more than\n4 consecutive sentences will be relevant to each\nother.\n4.3 Self Attention\nInspired by the attention implementation in (Zhang\net al., 2018; Vaswani et al., 2017), to capture global\nrelevance, the article features from the previous\n1D-CNN layer are transformed into feature spaces\nq,kto calculate attention, where q(x) =Wqxandk(x) =Wkx.\n\fj;i=exp(zij)PN\ni=1exp(zij);wherezij=q(xi)Tk(xj)\n(1)\n\f2RN\u0002Nis the attention coef\ufb01cient, which is the\nnormalized relevance score between the sentence\nxiandxj.\fis then matrix multiplied by v, where\nv(x) =Wvx, to obtain the context rich output\noj2RC\u00021.\noj=NX\ni=i\fj;iv(xi);whereoj2fo1;o2;:::;o Ng\n(2)\nFinally, the output of the self-attention layer is o2\nRC\u0002N, which is computed as\noj=g(oj);where,g(x) =Wgx (3)\nIn the above equations, x2RC\u0002Nis obtained\nafter applying 1D convolution on sentence vectors,\nWq2RC\u0002C,Wk2RC\u0002C,Wv2RC\u0002C,Wg2\n1D CNNs\nHeadline\nVector\nDenseCA1\nCAMCA2\nConcatSA1\nSAMSA2\nConcat\nDimension\nReductionDecoder\nGenerated Headline \nVectorSentence\nVectorsMultihead\nSelf Attention\nMultihead\nCross AttentionGenerated Headline\n0ne-Hot W ord V ectorFigure 2: Architecture of Multihead Attention - Claim Identi\ufb01cation Network (MA-CIN). The model is trained\nby using self-supervised learning approach using three variants of supervisory-signal - headline vector, headline\nwords and the combination of both vector and words.\nRC\u0002Cand outputo2RC\u0002N. Following the work\nby (Zhang et al., 2018) we preferred the value of\nC=C\n8for computation effectiveness. We also\nmultiply a\u0015and\r, learnable scale parameters,\nto the output of our attention module and input\nvector respectively to allow the network to choose\nbetween local and global sentences effectively.\no=\rx+\u0015o (4)\n\ris initialized to 1 and \u0015is initialized to 0, so as\nto allow the local context to be captured effectively\nduring the early iterations and as the value of \u0015\nincreases it allows the network to add more context\nto the representation.\n4.4 Multihead Concatenation\nIn the architecture, we could apply self attention\nto the input xM times resulting into M attention\nheads. The output of one attention head is denoted\nbyo. We concatenate the outputs oMto get a richer\nrepresentation allowing the network to capture var-\nious relationships.\nmsao=\r\rM\ni=1oi=o1k:::koM(5)\nwhere,msao2RMC\u0002Nis the long range context\naware output of multihead self attention. Here,\r\r\ndenotes concatenation across axis C.\n4.5 Cross Attention\nThe headline vector is transformed into a feature\nspaceh=Whh, whereh2RC\u00021and then, it\u2019s\nrelevance is calculated with msao, obtained from\nthe previous layer, by using equations de\ufb01ned in4.3. Finally, after applying multihead concatena-\ntion using 5, we obtain headline-context aware rep-\nresentation,mcao2RMC\u0002N. We \ufb01xM= 4for\nall our experiments.\n4.6 Loss Function\nTo generate the headline vector dhas close to the\ninput headline vector h, we apply Mean Squared\nError between dhandhand calculate the headline\nvector generation loss Lv\nLv=1\nn(nX\ni=1(dhi\u0000hi)2) (6)\nFor estimating the probability of a word from\nthe vocab in the predicted headline we calculate\nthe cross-entropy between the predicted headline\nwordsdhwand input headline one-hot vector HW .\nLw=\u0000X\nidhw ilog(HW i) (7)\nThe total loss Ltotal=Lv+Lwis then evaluated\nfor all samples b2B, whereBis one batch.\n5 Experiments and Evaluation\n5.1 Training Setup\nWe train our Multihead Attention model for Claim\nIdenti\ufb01cation, MA-CIN, on datasets mentioned in\nSection 3. The CDC dataset contains total of 522\narticles. Amongst these, there are 47 articles with\n8 or more annotated claim sentences which are\nconsidered as evaluation set (CDC Eval) for this\ndataset. Next, for DNF-300 and DNF-700, we\nasked two annotators to manually tag at least 5\nsentences as \u201cclaim-worthy\u201d in each of the 50 ar-\nticles. Sentences which were consented by both\nDataset Con\ufb01gurationCDC Eval DNF Eval\nPrec. Rec. F1 Prec. Rec. F1\nSpacy Baseline 0.09 0.14 0.11 0.33 0.42 0.37\nCDC Baseline (Levy et al., 2014) 0.23 - - - - -\nMA-CIN(HV) 0.18 0.08 0.11 0.39 0.53 0.45\nMA-CIN(OHWV) 0.25 0.10 0.15 0.40 0.54 0.46\nMA-CIN(Combined) 0.26 0.11 0.16 0.42 0.57 0.48\nDNF\u0000700 MA-CIN(HV) 0.20 0.09 0.12 0.37 0.54 0.44\nMA-CIN(OHWV) 0.19 0.08 0.11 0.40 0.5 0.44\nMA-CIN(Combined) 0.28 0.12 0.16 0.41 0.55 0.47\nDNF\u0000300 MA-CIN(HV) 0.19 0.08 0.11 0.39 0.53 0.48\nMA-CIN(OHWV) 0.25 0.11 0.15 0.38 0.53 0.45\nMA-CIN(Combined) 0.24 0.10 0.14 0.42 0.57 0.48\nTable 3: Comparison of MA-CIN model con\ufb01gurations over three datasets and two evaluation sets for identi\ufb01ca-\ntion of \u201cclaim-worthy\u201d sentences.\nHeadline: Clinton Received Debate Questions Week Before Debate\n0The first presidential debate was held and Hillary Clinton was proclaimed the winner by the media. - - 0.41\n1Indeed Clinton was able to turn in a strong debate performance, but did she do so fairly? - - 0\n2Multiple reports and leaked information from inside the Clinton camp claim that the Clinton campaign was given the entire set of debate questions an entire \nweek before the actual debate.GT PD 1\n3Earlier last week an NBC intern was seen hand delivering a package to Clinton\u2019s campaign headquarters, according to sources. - PD 0.73\n4The package was not given to secretarial staff, as would normally happen, but the intern was instead ushered into the personal office of Clinton campaign \nmanager Robert Mook- PD 0.68\n5Members of the Clinton press corps from several media organizations were in attendance at the time, and a reporter from Fox News recognized the intern, \nbut said he was initially confused because the NBC intern was dressed like a Fed Ex employee.- - 0.46\n6The reporter from Fox questioned campaign staff about the intern, but campaign staff at first claimed ignorance and then claimed that it was just a Fed Ex \nemployee who had already left.- - 0.67\n7No reporters present who had seen the intern dressed as a Fed Ex employee go into Mook\u2019s office saw him leave by the same front entrance. - - 0.49\n8The Fox reporter who recognized the intern also immediately looked outside of the campaign headquarters and noted that there were no Fed Ex vehicles \nparked outside.- - 0.51\n9Clinton seemed to have scripted responses ready for every question she was asked at the first debate. GT - 0.37\n10She had facts and numbers memorized for specific questions that it is very doubtful she would have had without being furnished the questions beforehand. GT - 0.63\n11The entire mainstream media has specifically been trying to portray Trump as a racist and a poor candidate. - - 0.24\n12By furnishing Clinton with the debate questions NBC certainly hoped to make Clinton appear much more knowledgeable and competent than Trump. GT PD 0.79\n13And though it is unlikely that anyone will be able to conclusively prove that Clinton was given the debate questions, it seems both logical and likely. GT PD 0.7\nFigure 3: Interpretation of relevance of sentences with the headline of an example article from DNF-300. GT and\nPD indicate ground truth and top-5 predicted \u201cclaim-worthy\u201d sentences, respectively. MA-CIN model was able to\npredict 3 most relevant sentences correctly. Last column shows the attention weights between headline and each\nof the sentences of the article. Sentence 2 has been correctly predicted as the most relevant while sentence 1 is the\nleast relevant.\nthe annotators as \u201cclaim-worthy\u201d were \ufb01nalized as\nground truth claims for these 50 articles, and used\nas testing set for evaluating the model performance\non DNF datasets. The remaining 475 articles from\nCDC, 250 articles from DNF-300, and 650 arti-\ncles from DNF-700 were split into 5 folds to train\nthe model using a 5-Fold cross validation (Kohavi,\n1995), where we use 4 folds for training and 1 fold\nfor validation. Each of the three settings, described\nin Section- 4: MA-CIN(HV), MA-CIN(OHWV)\nand MA-CIN(Combined), was trained with each\nof the three datasets, and evaluated on DNF Eval\nand CDC Eval. Total number of parameters for\nthese three settings are 15,012,916 (10,240 non-\ntrainable), 40,975,656 (10,240 non-trainable) and\n41,812,564 (12,288 non-trainable) respectively. All\nother network parameters are displayed in supple-mental material.\nIn each setting, we use batch normalization,\nReLU non-linearity as an activation function, and\na dropout of 0.5 for every convolution operation.\nWe trained all the models for 2000 epochs, where,\nfor every training we used Adam optimizer with\na learning rate lr= 0:0001 ,\f1= 0:99and\n\f2= 0:0. There was no weight decay set as the\nmodel was trained in a self-supervised setting with\n\ufb01nite epochs and an already small learning rate.\nGlove 300D word embedding was used for all our\nexperiments and the number of input sentences was\nset to 500. The models were trained on three 11GiB\nNvidia 1080Ti GPUs in parallel.\n5.2 Evaluation Metrics\nWe evaluate MA-CIN models on two evalua-\ntion sets, DNF Eval and CDC Eval. With self-\nsupervised setting we \ufb01rst rank the sentences based\non relevance with the headline and then extract\nthe top \ufb01ve sentences along with their sentence\nids as \u201cclaim-worthy\u201d sentences. For evaluation\non DNF Eval, we calculate the true positives (TP),\nfalse positives (FP) and false negatives (FN) from\nground truth claim ids. To evaluate on CDC Eval,\nsince we do not have ground truth claim ids, we\ncalculate cosine similarity between the extracted\nsentences and the ground truth claims. We experi-\nment with various similarity threshold to calculate\nTP, FP and FN, and set the \ufb01nal threshold to 0.95\nto report best performing results. Finally, these\nmetrics are used to report Precision@1, Recall@1\nand F-1 scores.\n5.3 Results\nTable-3 shows the performance of baseline (CDC)\n(Levy et al., 2014) and three variants of MA-CIN\nmodels. We report two baselines - (1) spacy, and\n(2) Levy et al. (2014) using supervised learning\nmethod on CDC dataset which contains annotated\nclaims. Since, Levy et al. (2014) do not report\nRecall and F1 scores, we have reported their Preci-\nsion@1 score in this paper. We also train MA-CIN\nmodels on this dataset by removing all the anno-\ntations for self-supervised training. We observe\nthat:\n1.The combined variant of our self-supervised\napproach performs slightly better than the\nbaseline on the CDC dataset. This shows\nthat, MA-CIN models are able to learn simi-\nlar properties as the baseline but without any\nsentence-level annotations. Thus, this elimi-\nnates the need to have an annotated dataset for\nclaim identi\ufb01cation.\n2.MA-CIN models give comparable results on\nall three datasets. This shows the scalability\nof the models to identify \u201cclaim-worthy\u201d sen-\ntences from any given article.\n3.The combined variant of MA-CIN, which gen-\nerates both the headline vector and the word\nin headline, performs better on all the datasets,\nexcept one: MA-CIN (OHWV) model trained\non DNF-300 and evaluated on CDC Eval per-\nforms slightly better than the combined model,\nhowever, the difference in the performance is\nvery small.\nFigure 4: Interpretation of sentence-to-sentence rele-\nvance through attention weights.\n6 Discussion\n6.1 Analyzing Attention Weights\nAttention weights help make the model inter-\npretable to the end users by depicting relationship\nbetween all sentences as well as with the headline.\nFrom Figure-3, we can see that out of the top-5\npredicted claims, 3 of them are present in the hu-\nman evaluated test set. The last column, which\ncontains attention coef\ufb01cients between the head-\nline and each sentence, depicts some interesting\nresults -\n(i) based on the human evaluation, the sentence\nhaving the least relevance with the headline is sen-\ntence 1. While this sentence contains words also\npresent in the headline, the underlying meaning is\nnot the same. This has been successfully captured\nby MA-CIN model by predicting sentence 1 as the\nleast relevant claim;\n(ii) further, highly ranked sentences 2, 12, and 13\nhave been correctly predicted as relevant claims by\nthe model. This shows the model\u2019s ability in learn-\ning the semantic relationship between the headline\nand the content of the article, and subsequently\nputting importance on sentences that are relevant\nto the headline\u2019s underlying meaning. This prop-\nerty, which is also called \u201c aboutness \u201d, is ef\ufb01ciently\nexhibited by the model.\n(iii) sentence 3, which is predicted by MA-CIN\nmodel as relevant with a score of 0.73, is not\npresent in the ground truth. This indicates that the\ntwo annotators did not agree to have this sentence\nveri\ufb01ed, even if it is relevant to the point of the\narticle. To analyze this further, we plan to conduct\nuser studies as one of the future avenues.\n(iv) sentence 4 is also predicted as a relevant\nclaim but it\u2019s missing from the ground truth since\nthe annotators did not agree to have this veri\ufb01ed.\nThe reason for this prediction could be because self-\nattention is able to identify the premise of highly\nrelevant sentences. Hence, sentence 4, which is the\ncontinuation of highly relevant sentence 3, is also\ngiven importance by the headline. This relevance\nbetween sentences 3 and 4 is depicted in Figure-4,\nwhere the attention weight between these two is the\nhighest.\nFrom Figure-4, we also observe that:\n(i) sentence 4 is highly relevant to sentences 3 to\n8, which is intuitive, since the story of the intern\nforms the premise of the claims in the article;\n(ii) sentences 2 and 4 have been shown to have\nthe least relevance with each other which is also\ntrue as shown in Figure-3. The two sentences, if\nconsidered in isolation, make two different claims\nwhich are not related to each other;\n(iii) the model has made sure that a sentence\ndoes not assign high relevance to itself as it would\nbe counter-intuitive.\n6.2 Limitations\nSince, the evaluation methodologies for CDC\ndataset has not been explained clearly, in our pa-\nper, we have considered vector cosine similarity\nbetween the ground truth claim in the CDC Eval\nand the extracted claim from the model which may\nleave a margin of error in the evaluation scores.\nAdditionally, ground truth in DNF Eval is manu-\nally generated and may contain subjective biases.\nAlthough these biases have been overcome by MA-\nCIN models, as explained in 6.1, but we also plan to\nenhance the ground truth judgement using crowd-\nsourced annotation. We intend to use these annota-\ntions to \ufb01ne-tune the models.\n7 Conclusion and Future Work\nIn this work, we build a novel, self-supervised ap-\nproach to identify \u201cclaim-worthy\u201d sentences - an\nimportant task for automated fact checking. The fo-\ncus of this work is on fake news articles where there\nis a deliberate intent to in\ufb02uence people or cause\nsocial unrest. We have introduced novel datasets of\nsuch articles with features essential for the down-\nstream task of fake news veri\ufb01cation. Using pow-\nerful attention models, we explore the notion ofaboutness of the headline and the content of the\narticle to identify \u201cclaim-worthy\u201d sentences. Ex-\nperiments with three datasets show the strength\nof our model architecture in overcoming human-\ninduced biases, which is quite common when using\nsentence-level claim-annotated datasets. Based on\nthe comparison with the baseline, which was imple-\nmented using annotated dataset, we show that our\nmodels do not require annotated claims for training\nto identify claim-worthy sentences ef\ufb01ciently. We\nhave also showed that our model is scalable to any\ndataset with topic and content.\nFuture work involves increasing the robustness\nof the models presented in this paper. We plan\nto use crowdsourced annotation on the dataset re-\nleased with this paper to measure the in\ufb02uence of\nthe article on general readers and then use these in-\ndicators to \ufb01ne-tune our models. Experimentation\nwith more robust sentence encoders is another av-\nenue of future work. Additionally, going forward,\nwe plan to identify a maximum of 3 claims per\narticle which will be used for evidence-based fake\nnews detection. We also plan to expand the dataset,\npresented in this work, to include fake news articles\non topics other than Politics and Health.\nReferences\nEhud Aharoni, Anatoly Polnarov, Tamar Lavee, Daniel\nHershcovich, Ran Levy, Ruty Rinott, Dan Gut-\nfreund, and Noam Slonim. 2014. A Benchmark\nDataset for Automatic Detection of Claims and Ev-\nidence in the Context of Controversial Topics. In\nProceedings of the First Workshop on Argumenta-\ntion Mining , pages 64\u201368, Baltimore, Maryland. As-\nsociation for Computational Linguistics.\nHunt Allcott and Matthew Gentzkow. 2017. Social me-\ndia and fake news in the 2016 election. Journal of\neconomic perspectives , 31(2):211\u201336.\nLeif Azzopardi, Gabriella Kazai, Stephen Robertson,\nStefan R \u00a8uger, Milad Shokouhi, Dawei Song, and\nEmine Yilmaz. 2009. Advances in Information Re-\ntrieval Theory: Second International Conference on\nthe Theory of Information Retrieval, ICTIR 2009\nCambridge, UK, September 10-12, 2009 Proceed-\nings, volume 5766. Springer.\nPD Bruza and Theo WC Huibers. 1996. A study of\naboutness in information retrieval. Arti\ufb01cial Intelli-\ngence Review , 10(5-6):381\u2013407.\nCarlos Castillo, Marcelo Mendoza, and Barbara\nPoblete. 2011. Information credibility on twitter. In\nProceedings of the 20th international conference on\nWorld wide web , pages 675\u2013684. ACM.\nM de Cock Buning. 2018. A multi-dimensional ap-\nproach to disinformation: Report of the independent\nhigh level group on fake news and online disinforma-\ntion. Publications Of\ufb01ce of the European Union.\nJudith Eckle-Kohler, Roland Kluge, and Iryna\nGurevych. 2015. On the Role of Discourse Mark-\ners for Discriminating Claims and Premises in Ar-\ngumentative Discourse. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 2236\u20132242, Lisbon, Portu-\ngal. Association for Computational Linguistics.\nPepa Gencheva, Preslav Nakov, Llu \u00b4\u0131s M `arquez, Al-\nberto Barr \u00b4on-Cede \u02dcno, and Ivan Koychev. 2017.\nA context-aware approach for detecting worth-\nchecking claims in political debates. In Proceedings\nof the International Conference Recent Advances in\nNatural Language Processing, RANLP 2017 , pages\n267\u2013276, Varna, Bulgaria. INCOMA Ltd.\nD Graves. 2018. Understanding the promise and limits\nof automated fact-checking. Reuters Institute for the\nStudy of Journalism .\nNaeemul Hassan, Fatma Arslan, Chengkai Li, and\nMark Tremayne. 2017. Toward automated fact-\nchecking: Detecting check-worthy factual claims\nby claimbuster. In Proceedings of the 23rd ACM\nSIGKDD International Conference on Knowledge\nDiscovery and Data Mining , pages 1803\u20131812.\nACM.\nSepp Hochreiter and J \u00a8urgen Schmidhuber. 1997.\nLong short-term memory. Neural Computation ,\n9(8):1735\u20131780.\nMercedes Jaime Sis \u00b4o and MERCEDES. 2009. Titles\nor headlines? anticipating conclusions in biomedi-\ncal research article titles as a persuasive journalistic\nstrategy to attract busy readers. Miscel \u00b4anea: A Jour-\nnal of English and American Studies , 39:29\u201351.\nIsraa Jaradat, Pepa Gencheva, Alberto Barr \u00b4on-Cede \u02dcno,\nLlu\u00b4\u0131s M `arquez, and Preslav Nakov. 2018. Claim-\nRank: Detecting check-worthy claims in Arabic\nand English. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associa-\ntion for Computational Linguistics: Demonstrations ,\npages 26\u201330, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nZhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo.\n2016. News veri\ufb01cation by exploiting con\ufb02icting\nsocial viewpoints in microblogs. In Thirtieth AAAI\nConference on Arti\ufb01cial Intelligence .\nRon Kohavi. 1995. A study of cross-validation and\nbootstrap for accuracy estimation and model selec-\ntion. In Proceedings of the 14th International Joint\nConference on Arti\ufb01cial Intelligence - Volume 2 ,\nIJCAI\u201995, pages 1137\u20131143, San Francisco, CA,\nUSA. Morgan Kaufmann Publishers Inc.Lev Konstantinovskiy, Oliver Price, Mevan Babakar,\nand Arkaitz Zubiaga. 2018. Towards automated\nfactchecking: Developing an annotation schema and\nbenchmark for consistent automated claim detection.\narXiv preprint arXiv:1809.08193 .\nJeffrey Kuiken, Anne Schuth, Martijn Spitters, and\nMaarten Marx. 2017. Effective headlines of news-\npaper articles in a digital environment. Digital Jour-\nnalism , 5(10):1300\u20131314.\nSejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei\nChen, and Yajun Wang. 2013. Prominent features of\nrumor propagation in online social media. In 2013\nIEEE 13th International Conference on Data Min-\ning, pages 1103\u20131108. IEEE.\nYann LeCun, L \u00b4eon Bottou, Yoshua Bengio, and Patrick\nHaffner. 1998. Gradient-based learning applied to\ndocument recognition. Proceedings of the IEEE ,\n86(11):2278\u20132323.\nRan Levy, Yonatan Bilu, Daniel Hershcovich, Ehud\nAharoni, and Noam Slonim. 2014. Context Depen-\ndent Claim Detection. In Proceedings of COLING\n2014, the 25th International Conference on Compu-\ntational Linguistics: Technical Papers , pages 1489\u2013\n1500, Dublin, Ireland. Dublin City University and\nAssociation for Computational Linguistics.\nRan Levy, Shai Gretz, Benjamin Sznajder, Shay Hum-\nmel, Ranit Aharonov, and Noam Slonim. 2017. Un-\nsupervised corpus-wide claim detection. In ArgMin-\ning@EMNLP .\nJing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and\nKam-Fai Wong. 2015. Detect rumors using time se-\nries of social context information on microblogging\nwebsites. In Proceedings of the 24th ACM Inter-\nnational on Conference on Information and Knowl-\nedge Management , CIKM \u201915, pages 1751\u20131754,\nNew York, NY , USA. ACM.\nJeppe Norregaard, Benjamin D. Horne, and Sibel Adali.\n2019. NELA-GT-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. CoRR , abs/1904.01546.\nArchita Pathak and Rohini Srihari. 2019. BREAK-\nING! presenting fake news corpus for automated\nfact checking. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics: Student Research Workshop , pages 357\u2013\n362, Florence, Italy. Association for Computational\nLinguistics.\nVer\u00b4onica P \u00b4erez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401, Santa Fe, New Mexico, USA.\nAssociation for Computational Linguistics.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2017. A sty-\nlometric inquiry into hyperpartisan and fake news.\narXiv preprint arXiv:1702.05638 .\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 2931\u20132937.\nNatali Ruchansky, Sungyong Seo, and Yan Liu. 2017.\nCsi: A hybrid deep model for fake news detection.\nInProceedings of the 2017 ACM on Conference\non Information and Knowledge Management , CIKM\n\u201917, pages 797\u2013806, New York, NY , USA. ACM.\nSneha Singhania, Nigel Fernandez, and Shrisha Rao.\n2017. 3han: A deep neural network for fake news\ndetection. In International Conference on Neural In-\nformation Processing , pages 572\u2013581. Springer.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention Is\nAll You Need. arXiv:1706.03762 [cs] . ArXiv:\n1706.03762.\nKarin Wahl-Jorgensen and Thomas Hanitzsch. 2009.\nThe handbook of journalism studies . Routledge.\nWilliam Yang Wang. 2017. \u201d liar, liar pants on \ufb01re\u201d:\nA new benchmark dataset for fake news detection.\narXiv preprint arXiv:1705.00648 .\nLiang Wu and Huan Liu. 2018. Tracing fake-news\nfootprints: Characterizing social media messages by\nhow they propagate. In Proceedings of the Eleventh\nACM International Conference on Web Search and\nData Mining , WSDM \u201918, pages 637\u2013645, New\nYork, NY , USA. ACM.\nFan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.\nAutomatic detection of rumor on sina weibo. In Pro-\nceedings of the ACM SIGKDD Workshop on Mining\nData Semantics , page 13. ACM.\nHan Zhang, Ian Goodfellow, Dimitris Metaxas, and Au-\ngustus Odena. 2018. Self-attention generative adver-\nsarial networks.\nA Appendices\nA.1 De\ufb01nitions\nFake News: Articles where there is a deliberate\nintent to in\ufb02uence readers through fabricated or\nmanipulated claims in the headline and the content.\nSuch articles have a compelling writing style simi-\nlar to the mainstream media.\n\u201cClaim-worthy\u201d: Statements which are important\nto the point of the article but one would require to\nhave them veri\ufb01ed.\nCompelling Fake News Articles: Articles which\nmake persuasive claims in headline and content,\nthat may in\ufb02uence readers to believe a fabri-\ncated/manipulated story.Credible Sources : Mainstream media, established\nfact-checking websites and Government docu-\nments.\nQuestionable Sources : Non-mainstream media\nlike infowars, naturalnews, breitbart etc.\nA.2 Experiment Architectures\nA.2.1 Vector Generation\nArchitecture setting for generating Headline Vector\n(HV) displayed in Figure-5\ninput Model Output size[Kernel size, Filters, \nStrides], Repeats\nsentence vectors 500x300\nconv1d_1 500 x 256 [4, 256, 1] x 1\nconv1d_2 500 x 512 [4, 256, 1] x 1\nSelfAttention 500 x 512 [1, 64, 1] x 4\nConcat 500 x 2048\nconv1d_3 500 x 512 [4, 256, 1] x 1\nheadline vector 1 x 300\nconv1d_4 1 x 512 [1, 512, 1] x 1\nCrossAttention 500 x 512 [1, 64, 1] x 4\nConcat 500 x 2048\nconv1d_5 250 x 512 [4, 512, 2] x 1\nconv1d_6 125 x 512 [4, 512, 2] x 1\nconv1d_7 63 x 512 [4, 512, 2] x 1\nconv1d_8 32 x 512 [4, 512, 2] x 1\nGlobal Pooling 512\nFC_1 1024\noutput_vector 300\nFigure 5: Architecture setting for generating Headline\nVector(HV).\nA.2.2 Word Generation\nArchitecture setting for generating Headline Vector\nWord Probabilities (OHWV) displayed in Figure-6\nA.3 DNF-700 Dataset Details\nEach article is identi\ufb01ed by an id. The content of\nthe article is stored in a separate text \ufb01les having\n\ufb01le name \u201carticle id\u201d, for example, article 122. A\nJSON \ufb01le is also provided with the following \ufb01elds:\nid: Unique identi\ufb01er of the article starting\nfrom 0.\nauthors: Authors of the article.\nheadline: Headline of the article.\ntype: \u201cfake\u201d (articles from Stanford and Buzzfeed\ndatasets which are already proven fake); and\n\u201cquestionable\u201d (articles from Getting Real About\nFake News Kaggle dataset which require manual\nveri\ufb01cation of the degree of veracity)\nurls: Source/domain URL of the article.\ninput Model Output size[Kernel size, Filters, \nStrides], Repeats\nsentence vectors 500x300\nconv1d_1 500 x 256 [4, 256, 1] x 1\nconv1d_2 500 x 512 [4, 256, 1] x 1\nSelfAttention 500 x 512 [1, 64, 1] x 4\nConcat 500 x 2048\nconv1d_3 500 x 512 [4, 256, 1] x 1\nheadline vector 1 x 300\nconv1d_4 1 x 512 [1, 512, 1] x 1\nCrossAttention 500 x 512 [1, 64, 1] x 4\nConcat 500 x 2048\nconv1d_5 250 x 512 [4, 512, 2] x 1\nconv1d_6 125 x 512 [4, 512, 2] x 1\nconv1d_7 63 x 512 [4, 512, 2] x 1\nconv1d_8 32 x 512 [4, 512, 2] x 1\nGlobal Pooling 512\nRepeat 50 x 512\nBi-LSTM 50 x 1024\nTimeDistributed \nDense, softmax50 x 20000Figure 6: Architecture setting for generating Headline\nVector Word Probabilities (OHWV).\nA.4 DNF-300 Dataset Details\nDNF-300 is more sophisticated subset of DNF-700\nwith additional \ufb01elds based on manual veri\ufb01cation\nof the article. The JSON \ufb01le of this dataset\ncontains following \ufb01elds:\nid: Unique identi\ufb01er of the article starting\nfrom 0.\nauthors: Authors of the article.\nheadline: Headline of the article.\ntype:f(0) False; (1) Partial Truth; (2) Opinions\nStated As Fact; (3) True g\nurls: Source/domain URL of the article.\nevidence: URL of credible sources supporting or\nrefuting the article. This \ufb01eld is empty when no\nevidence were found which talked about the claims\nmade in this article. This means, the claims are\ninnovated lies. In such cases, the type \ufb01eld is set as\n0.\nreason: Reason about the verdict. It can be one of\nthe following:\n1.Based on Snopes rating \u2019False\u2019 which means\n\u2019the primary elements of a claim are demon-\nstrably false.\u2019\n2.Based on Snopes rating \u2019Unproven\u2019 which\nmeans \u2019insuf\ufb01cient evidence exists to estab-\nlish the given claim as true, but the claim can-\nnot be de\ufb01nitively proved false.\u2019\n3.Based on Snopes rating \u2019Mixture\u2019 which\nmeans \u2019a claim has signi\ufb01cant elements of\nboth truth and falsity to it such that it could\nnot fairly be described by any other rating.\u2019\n4.Based on Snopes rating \u2019Mostly False\u2019 whichmeans \u2019the primary elements of a claim are\ndemonstrably false, but some of the ancillary\ndetails surrounding the claim may be accu-\nrate.\u2019\n5.The key claim is false (based on Snopes rat-\ning), however, the article also contains opin-\nions stated as fact.\n6.Snopes mentiones that a true story was manip-\nulated to mislead people.\n7.The key claims are true but exaggerated by\nadding personal opinions stated as fact.\n8.No reports from trusted sources for the key\nclaims.\n9.True story manipulated to mislead read-\ners by making unveri\ufb01able claims such as\n\u2018some claim\u2019 .\n10.Article is fraught with opinions stated as fact\nabout a true event.\n11. Found evidence to refute key claims.\n12. Article contains opinions stated as fact.\n13. Evidence found to support key claims.\nFigure 7: : Example for CDCs and for statements that\nshould not be considered as CDCs. The V and X indi-\ncate if the candidate is a CDC for the given Topic, or\nnot, respectively.\nA.5 Examples\nWe present examples for all 4 label types fFalse ;\nPartial Truth ;Opinion stated as fact ;Truegpresent\nin our dataset: DNF-300. Please refer Table-4,5,6,7.\nAn annotated example from CDC dataset is dis-\nplayed in Figure-7\nHeadline : Clinton Received Debate Questions Week Before Debate\nThe \ufb01rst presidential debate was held and Hillary Clinton was proclaimed the winner by the media.\nIndeed Clinton was able to turn in a strong debate performance, but did she do so fairly? Multiple\nreports and leaked information from inside the Clinton camp claim that the Clinton campaign was\ngiven the entire set of debate questions an entire week before the actual debate. Earlier last week an\nNBC intern was seen hand delivering a package to Clinton\u2019s campaign headquarters, according to\nsources. The package was not given to secretarial staff, as would normally happen, but the intern\nwas instead ushered into the personal of\ufb01ce of Clinton campaign manager Robert Mook. Members\nof the Clinton press corps from several media organizations were in attendance at the time, and a\nreporter from Fox News recognized the intern, but said he was initially confused because the NBC\nintern was dressed like a Fed Ex employee. The reporter from Fox questioned campaign staff about\nthe intern, but campaign staff at \ufb01rst claimed ignorance and then claimed that it was just a Fed Ex\nemployee who had already left. No reporters present who had seen the intern dressed as a Fed Ex\nemployee go into Mook\u2019s of\ufb01ce saw him leave by the same front entrance. The Fox reporter who\nrecognized the intern also immediately looked outside of the campaign headquarters and noted that\nthere were no Fed Ex vehicles parked outside. Clinton seemed to have scripted responses ready\nfor every question she was asked at the \ufb01rst debate. She had facts and numbers memorized for\nspeci\ufb01c questions that it is very doubtful she would have had without being furnished the questions\nbeforehand. The entire mainstream media has speci\ufb01cally been trying to portray Trump as a racist\nand a poor candidate. By furnishing Clinton with the debate questions NBC certainly hoped to\nmake Clinton appear much more knowledgeable and competent than Trump. And though it is\nunlikely that anyone will be able to conclusively prove that Clinton was given the debate questions,\nit seems both logical and likely.\nType : 0 (False )\nAuthors :Baltimore Gazette\nURLs : http://www.freemarketcentral.com/index.php/post/2503/report-clinton-received-debate-\nquestions-a-week-before-debate\nEvidence : [https://www.snopes.com/fact-check/clinton-received-debate-questions-week-before-\ndebate/, https://www.truthor\ufb01ction.com/hillary-clinton-received-debate-questions-advance/]\nReason : Based on Snopes rating \u2019False\u2019 which means \u2019the primary elements of a claim are\ndemonstrably false.\u2019\nTable 4: An example on False type from DNF-300 dataset.\nHeadline : Allergens in Vaccines Are Causing Life-Threatening Food Allergies\nIt would probably surprise few people to hear that food allergies are increasingly common in U.S.\nchildren and around the world . According to one public health website , food allergies in children\naged 0-17 in the U.S. increased by 50% from 1997 to 2011. Although food allergies are now so\nwidespread as to have become almost normalized, it is important to realize that millions of American\nchildren and adults suffer from severe rapid-onset allergic reactions that can be life-threatening.\nFoods represent the most common cause of anaphylaxis among children and adolescents. The\nUnited Kingdom has witnessed a 700% increase in hospital admissions for anaphylaxis and a\n500% increase in admissions for food allergy since 1990. The question that few are asking is why\nlife-threatening food allergies have become so alarmingly pervasive. A 2015 open access case\nreport by Vinu Arumugham in the Journal of Developing Drugs , entitled \u201c Evidence that Food\nProteins in Vaccines Cause the Development of Food Allergies and Its Implications for Vaccine\nPolicy ,\u201d persuasively argues that allergens in vaccines\u2014and speci\ufb01cally food proteins\u2014may be\nthe elephant in the room. As Arumugham points out, scientists have known for over 100 years that\ninjecting proteins into humans or animals causes immune system sensitization to those proteins.\nAnd, since the 1940s, researchers have con\ufb01rmed that food proteins in vaccines can induce allergy\nin vaccine recipients. Arumugham is not the \ufb01rst to bring the vaccine-allergy link to the public\u2019s\nattention. Heather Fraser makes a powerful case for the role of vaccines in precipitating peanut\nallergies in her 2011 book, The Peanut Allergy Epidemic: What\u2019s Causing It and How to Stop It.\nType : 1 (Partial Truth )\nAuthors :Admin - Orissa\nURLs : galacticconnection.com\nEvidence : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3890451/\nReason : The key claim is written in such a way so that it misleads people in thinking all the food\nrelated allergies in US are caused by vaccines. Found evidence which says these type of allergies\nare rare.\nTable 5: An example on Partial Truth type from DNF-300 dataset.\nHeadline : George Soros: Trump Will Win Popular V ote by a Landslide but Clinton Victory a\n\u2019Done Deal\u2019\nIn recent weeks, Democrats have attempted to paint Republican presidential nominee Donald J.\nTrump as a lunatic for claiming that the election is going to be rigged in favor of his Democratic\nrival, Hillary Clinton. Even Republican politicians and former politicians are telling Trump to\nknock off such talk. But, as usual, Trump\u2019s shrewdness and de\ufb01ance of standard political decorum \u2013\nin which the \u201copposition\u201d party merely rolls over and surrenders in the face of Democratic pressure\n\u2013 is winning the day. None other than billionaire investor and longtime Democratic supporter\nGeorge Soros has said that the \ufb01x is literally in for the election, in favor of Clinton \u2013 no matter\nhow much of the popular vote, and from which battleground states, Trump captures. As reported\nby Top Right News and other outlets, during a recent interview with Bloomberg News, Soros \u2013 a\nDemocrat mega-donor \u2013 openly admitted that Trump will win the popular vote in a \u201clandslide.\u201d\nHowever, he said that none of that would matter, because a President Hillary Clinton is already a\n\u201cdone deal.\u201d In the interview, which is now going viral, Soros says with certainty that Trump will\ntake the popular vote, despite what the polls say now (which are completely rigged to oversample\nDemocrats), but not the Electoral College, which will go to Clinton. When the reporter asks if that\nis already a \u201cdone deal\u201d \u2013 that Clinton will be our next president no matter what \u2013 Soros says \u201cyes,\u201d\nand nods his head. Is Soros just making a prediction out of overcon\ufb01dence? Or does he truly know\nsomething most of us don\u2019t know?\nType : 2 (Opinion Stated As Fact )\nAuthors :J. D. Heyes\nURLs : https://www.naturalnews.com/055789 George Soros Hillary Clinton electoral college.html\nEvidence : 1. https://www.snopes.com/fact-check/george-soros-trump-will-win-popular-vote-by-\na-landslide-but-clinton-victory-a-done-deal/,\n2. https://www.bloomberg.com/news/videos/2016-01-22/soros-clinton-to-win-popular-vote-in-\nlandslide\nReason : The key claim is false (based on Snopes rating), however, the article also contains opinions\nstated as fact.\nTable 6: An example on Opinion stated as fact type from DNF-300 dataset.\nHeadline : Donald Trump: Minnesota Has \u2018Suffered Enough\u2019 Accepting Refugees\nIn a pitch to suspend the nation\u2019s Syrian refugee program , Donald Trump said Minnesotans have\n\u201csuffered enough\u201d from accepting Somali immigrants into their state. \u201cHere in Minnesota you have\nseen \ufb01rst hand the problems caused with faulty refugee vetting, with large numbers of Somali\nrefugees coming into your state, without your knowledge, without your support or approval,\u201d Trump\nsaid at a Minneapolis rally Sunday afternoon. He said his administration would suspend the Syrian\nrefugee program and not resettle refugees anywhere in the United States without support from the\ncommunities, while Hillary Clinton\u2019s \u201cplan will import generations of terrorism, extremism and\nradicalism into your schools and throughout your communities.\u201d\nType : 3 (True)\nAuthors :Henry Wolff\nURLs : amren.com\nEvidence : 1. https://time.com/4560078/donald-trump-minnesota-somali-refugees/,\n2. https://www.buzzfeednews.com/article/claudiakoerner/trump-vs-somali-refugees\nReason : Evidence found to support key claims.\nTable 7: An example on True type from DNF-300 dataset.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Self-supervised claim identification for automated fact checking", "author": ["A Pathak", "MA Shaikh", "R Srihari"], "pub_year": "2021", "venue": "arXiv preprint arXiv:2102.02335", "abstract": "We propose a novel, attention-based self-supervised approach to identify \"claim-worthy\"  sentences in a fake news article, an important first step in automated fact-checking. We"}, "filled": false, "gsrank": 351, "pub_url": "https://arxiv.org/abs/2102.02335", "author_id": ["2MvNbL0AAAAJ", "", "Uttu9kkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:PxVUoUtXDVYJ:scholar.google.com/&output=cite&scirp=350&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PxVUoUtXDVYJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 6, "citedby_url": "/scholar?cites=6200708244299846975&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PxVUoUtXDVYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2102.02335"}}, {"title": "Market forces: Quantifying the role of top credible ad servers in the fake news ecosystem", "year": "2021", "pdf_data": "Market Forces: Quantifying the Role of Top Credible Ad Servers in the Fake News\nEcosystem\nLia Bozarth and Ceren Budak\nUniversity of Michigan, School of Information\nlbozarth,cbudak@umich.edu\nAbstract\nLarry Lessig argues that four modes regulate behavior in cy-\nberspace: laws, markets, norms, and architecture. How can\nthese four modes regulate the production and spread of fake\nnews? In this paper, we focus on markets and empirically\nevaluate one particular market-based solution: top ad \ufb01rms\nblacklisting fake news producers to eliminate their revenue\nsources. Our study reveals that fake and low-quality pub-\nlishers demonstrate a higher tendency to serve more ads and\nto partner with risky ad servers than traditional news media\nwith similar popularity and age. However, fake news publish-\ners are still strongly reliant on credible ad servers. In fact,\nthe top-10 credible ad servers alone account for 66.7% and\n55.6% of fake and low-quality ad tra\u000ec respectively. Fur-\nthermore, our back-of-the-envelope calculation shows that, at\nthe time of our data collection, the top-10 ad \ufb01rms were re-\nceiving $985.7K to $1.15M monthly from web tra\u000ec on fake\nnews sites, a negligible fraction of these \ufb01rms\u2019 annual rev-\nenue. Overall, our \ufb01ndings suggest that having top ad \ufb01rms\nblacklist known fake and low-quality publishers is a low-cost\nway to combat fake news.\nIntroduction\nThe spread of fake news has signi\ufb01cant detrimental e\u000bects\nincluding deteriorating public trust in the established politi-\ncal and media institutions, deepening the suspicion and ani-\nmosity between populations, and threatening the legitimacy\nof elections around the world (Silverman 2017; Lazer et al.\n2018; Fletcher et al. 2018). Alarmed by its adverse impact,\nresearchers, lawmakers, a\u000bected tech \ufb01rms, and other inter-\nested parties have explored various methods to identify and\ncurtail the spread of fake news.\nThese approaches, according to Larry Lessig\u2019s frame-\nwork of cyberspace regulation, can be broadly categorized\ninto 4 modes: architecture, law, norms andmarkets (Lessig\n1998, 2006; Verstraete, Bambauer, and Bambauer 2017). In-\ndeed, tech giants such as Facebook and Microsoft have up-\ndated the architecture, or the code/features, of their plat-\nforms to include fake news detectors and to warn users about\narticles shared from questionable sources (Tian, Zhang,\nCopyright \u00a92021, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.and Peng 2020). Similarly, policymakers propose combat-\ning fake news through the rules of law, such as requiring\nplatforms to remove false stories with the potential to ig-\nnite communal tension (Coyle 2016; Iosi\ufb01dis and Andrews\n2019; Feingold 2017). Many online communities (e.g. the\nsubReddit \u201cr/ElizabethWarren\u201d on Reddit) have imposed or\npartially imposed community norms targeted at fake news\n(e.g., banning articles from known questionable news pub-\nlishers). These are all noteworthy endeavors.\nIn this paper, we focus on the fourth mode of regulation:\nmarkets. Speci\ufb01cally, we examine whether it is possible to\ncurtail fake news by disrupting its ad revenue pipeline. The\nsuccess of curbing fake news through markets primarily de-\npends on the incentives of fake news producers and our abil-\nity to remove these incentives. Some individuals and orga-\nnizations create and spread fake news due to deep-rooted\npartisanship and covert opposition operations (Silverman\n2017; Kucharski 2016). These motivations have been at the\nforefront of fake news discussions. But, \ufb01nancial motiva-\ntions are just as signi\ufb01cant (Mustafaraj and Metaxas 2017;\nBakir and McStay 2018; Mills, Pitt, and Ferguson 2019),\ngiven the ease with which revenue-seeking parties can set\nup fake news sites and use them to monetize tra\u000ec through\nads. The behavior of such agents can be changed by making\nfake news production less pro\ufb01table.\nThere are some ongoing e\u000borts by consumers (Braun,\nCoakley, and West 2019), retailers (Mills, Pitt, and Fergu-\nson 2019), and platforms (Figueira and Oliveira 2017) to\nuse the power of markets to curb fake news. The policy\nand legal scholarship provides the theoretical grounding for\nhow market forces, such as top ad \ufb01rms blacklisting known\nfake news sites, can disrupt this ecosystem (Verstraete, Bam-\nbauer, and Bambauer 2017; Timmer 2016; Tambini 2017;\nVasu et al. 2018; Kshetri and V oas 2017; Bakir and McStay\n2018; Braun and Eklund 2019; Coyle 2016). Thus far, how-\never, the scholarship lacks empirical evidence. This is the\nknowledge gap we \ufb01ll in this paper.\nTo shed light on this issue, we empirically investigate the\nextent to which fake and other low-quality news producers\nrely on display advertising to generate revenue. We further\nexamine\u2014and situate our \ufb01ndings in terms of\u2014traditional\nnews producer behavior. To do so, we tracked the ads served\nProceedingsoftheFifteenth InternationalAAAIConferenceonWebandSocial Media(ICWSM2021)\n83\non fake, low-quality, and traditional news outlets over 12\nweeks. The resulting dataset includes 1.32M ads served by\n565 unique ad servers on 1.6K news sites. We start by ex-\namining the similarities and di\u000berences between fake and\ntraditional news producer reliance on ad tra\u000ec and ask:\nRQ1: To what extent is (i.) traditional, (ii.) fake, and\n(iii.) other low-quality news producer tra\u000ec supported by\nad servers? What types of ad servers provide such support?\nWe compare and contrast the number and quality of ads\nand ad servers observed for these three types of news pub-\nlishers and identify important distinctions. Surprisingly, we\n\ufb01nd that a smaller fraction of fake and low-quality news sites\nshow fewer ads than traditional news sites. This may come\nas a surprise given the expectation that fake news publish-\ners are aggressively pro\ufb01t-driven (Braun and Eklund 2019).\nYet, ad prevalence is driven by both ability andintention to\npro\ufb01t from ad tra\u000ec. Indeed, upon controlling for domain\npopularity and age\u2014factors that a\u000bect the ability to mone-\ntize tra\u000ec through ads\u2014fake domains are revealed to have\nsigni\ufb01cantly more ad servers (10 more on average) and ads\nthan traditional publishers. Likewise, on average, ad servers\npresent on fake news sites are also 4% more likely to be risky\nthan those on traditional sites.\nWhile such important distinctions exist, we show that a\nlarge fraction of fake news sites\u2014much like traditional news\nsites\u2014have substantial support from credible ad servers.\nThis \ufb01nding suggests that the fake news ecosystem can be\ndisrupted if such credible ad \ufb01rms change behavior. But,\nconvincing allad servers to blacklist fake news publishers is\nhard\u2014if not impossible. Thus, it is crucial to assess whether\nconvincing a handful of the most popular ad servers could\nwork e\u000bectively. As such, we ask:\nRQ2: How concentrated is fake and other low-quality\nnews sites\u2019 ad reliance on a small number of top credible ad\nservers?\nFurthermore, as pro\ufb01t-maximizing entities, ad \ufb01rms will\nneed to trade o\u000b the branding bene\ufb01ts of banning prob-\nlematic sites against the resulting loss in revenue. In other\nwords, our ability to convince ad \ufb01rms to blacklist fake news\nsites will depend on how much they are currently bene\ufb01ting\nfrom such a partnership. Therefore, we ask:\nRQ3: What is the cost to ad \ufb01rms of blacklisting fake and\nlow-quality news sites and how does that cost vary by news\npublisher type?\nSurprisingly, we see that 66:7% of all ad tra\u000ec on fake\nnews domains is delivered by the top-10 credible ad servers\ncompared to 55:6% and 49:6% on low-quality and tradi-\ntional news sites. That is, top credible ad servers played\nan even bigger role in generating ad revenue for fake news\ndomains that publish entirely fabricated stories. Addition-\nally, using a back-of-the-envelope calculation, we estimate\nthat top-10 ad \ufb01rms generate monthly revenue of $985:7K\nto $1:15M by delivering ads on fake and low-quality news\ndomains\u2014a negligible fraction of the \ufb01rms\u2019 annual revenue.\nFinally, deciding whether a content provider is a fake or\nlow-quality news publisher is a challenging task (Tandoc Jr,\nLim, and Ling 2018). Therefore, following the guidance\nof (Bozarth, Saraf, and Budak 2020) who provide a meta-\nanalysis of fake news lists, we use 2 distinct lists of fake\nFigure 1: Simpli\ufb01ed advertisement ecosystem.\nand traditional news sites to show that our results are ro-\nbust. In sum, our analysis demonstrates that fake news sites\nare surprisingly dependent on top credible ad \ufb01rms. Having\nthese \ufb01rms blacklist such publishers is a simple and e\u000bective\nstrategy to combat fake news without hurting the \ufb01rms\u2019 bot-\ntom line. While we acknowledge the First Amendment is-\nsues and cannot settle what role platforms or ad \ufb01rms ought\ntoplay in regulating speech, we address the economics of\nthis policy debate through a large-scale empirical analysis.\nAn Overview of the Ad Ecosystem\nA simpli\ufb01ed online advertising ecosystem is shown in Fig-\nure 1. Brie\ufb02y, a news site (salmon-colored shapes in Fig-\nure 1), especially one with substantial web tra\u000ec, can have\nmany supply-side ad servers (simply referred to as ad servers\nin our paper) managing separate ad spaces on the site. In\nFigure 1, ad servers are represented as various blue-colored\ndots. As shown, Publisher Ahas a single ad server with\n3 dedicated ad spaces; in comparison, publisher Bhas 4\nunique ad servers each with a single ad space. When a user\nlands on the site, each ad server builds a corresponding ad\nselling request for each of its ad spaces on the page, and then\nposts the requests to ad exchanges (or ad networks)1where\ninterested advertisers can start bidding for the ad spaces (see\nFigure 1). After iterations of bids, the highest-bidding ad-\nvertisers win and their ads are displayed to the user (Choi\net al. 2019). The advertisers have limited control over which\npublishers ultimately display their messages. They can set\nbroad \ufb01lters in this bidding process (e.g. no porn sites) but\ncannot specify speci\ufb01c domains to avoid, which can lead to\nthem inadvertently funding or rewarding fake news with-\nout ad servers taking action (Tambini 2017). Additionally,\nad servers have varied capabilities: some track users, while\nothers are primarily tasked with displaying ads. Further, an\nad server can be a built-in module for certain ad networks\nor ad exchanges (e.g., Google\u2019s DoubleClick For Publishers\nis an ad server that is bundled with the \ufb01rm\u2019s own ad ex-\nchange). An ad server can also be a standalone supply-side\nplatform with connections to ad exchanges/networks (Choi\net al. 2019). Finally, advertising \ufb01rms (gray-colored shapes\n1One important distinction is worth noting: On ad exchanges,\nadvertisers can directly buy from publishers. On ad networks, ad\nspaces are packaged into bundles for wholesale (Mehta et al. 2020).\n84\nin Figure 1), notably the tech giants, commonly own various\nad servers and ad exchanges/networks.\nRelated Work\nGiven the extensively documented negative impact of fake\nnews on the quality of civic engagement, health and health-\ncare, stock markets, and disaster management (Main 2018;\nStarbird 2017; Kucharski 2016; Palen and Hughes 2018;\nMarcon, Murdoch, and Caul\ufb01eld 2017; Chiou and Tucker\n2018; Grinberg et al. 2018), discovering practical and cost-\ne\u000bective methods to curtail its growth has become both\na critical research endeavor and a public policy chal-\nlenge (Coyle 2016; Feingold 2017; Iosi\ufb01dis and Andrews\n2019; Tambini 2017; Lazer et al. 2018).\nFirst, researchers have taken steps to i) de\ufb01ne and concep-\ntualize fake news (Tandoc Jr, Lim, and Ling 2018; Kalsnes\n2018), ii) annotate and aggregate known deceptive state-\nments, reports, and publishers (Zimdars 2018; Mitra and\nGilbert 2015; Leetaru and Schrodt 2013), iii) build auto-\nmated systems to detect fake news promptly and at scale\n(Shu et al. 2017; Horne et al. 2018) and iv) examine its\nlongitudinal characteristics and impact (Allcott, Gentzkow,\nand Yu 2018; Vargo, Guo, and Amazeen 2018; Budak 2019;\nBode et al. 2020). These studies are valuable prerequisites\nfor work that aims to combat fake news e\u000eciently.\nNext, work that primarily focuses on combating fake\nnews can be categorized into 4 types, according to Larry\nLessig\u2019s (1998; 2006) framework of cyberspace regulation:\ni) law (e.g. defamation and obscenity laws), ii) norms (e.g.\nsubreddit community rules), iii) markets (e.g. pricing struc-\ntures, advertiser preferences), and iv) architecture (e.g. Face-\nbook\u2019s report button). Our paper is motivated by this frame-\nwork and focuses on one of these four modes: markets.\nNotably, prior work by Verstraete et al. (2017) assesses\nLessig\u2019s four modes of regulation to counter fake news\nand lists market solutions\u2014such as ad servers blacklisting\nfake news sites\u2014as one of the important tools in the arse-\nnal. Timmer (2016) further argues that market-based solu-\ntions will face less scrutiny and fewer legal hurdles com-\npared to a state-sponsored legal solution due to the consid-\nerable leeway given to computer service providers to de\ufb01ne\nand block questionable content. Furthermore, as (Mustafaraj\nand Metaxas 2017) argue, algorithmically allocated \ufb01nancial\nbene\ufb01ts of online advertising are playing an ever-increasing\nrole in the spread of fake news. More broadly, legal and pol-\nicy scholarship following the 2016 U.S. presidential elec-\ntions (Timmer 2016; Tambini 2017; Vasu et al. 2018; Kshetri\nand V oas 2017; Bakir and McStay 2018; Braun and Eklund\n2019; Coyle 2016) has made a strong theoretical case for\nmarket-based strategies to limit the spread of fake news.\nHere, we provide empirical support for this case. In con-\ntrast to the aforementioned studies that focus on the prac-\ntices of online advertising and public policies to curtail fake\nnews, we focus on empirically assessing the e\u000bectiveness of\none particular approach: advertising \ufb01rms ending their part-\nnership with fake news sites.Data\nIn this section, we \ufb01rst describe the lists of fake and tradi-\ntional news domains used as ground truth labels in our work.\nWe then detail our process of identifying all ad servers avail-\nable on each news site.\nFake and Traditional News Sites: We use the list of fake\nnews sites from (Zimdars 2018) and the list of traditional\nnews sites from Media Bias/Fact Check, an independent on-\nline media outlet maintained by a small team of researchers\nand journalists (Van Zandt 2018).\nZimdars list: The researchers (Zimdars 2018) examine\ndomain-level characteristics of news websites, including i)\ndomain name, ii) \u201cabout us\u201d page, iii) writing style, iv) aes-\nthetics, and v) social media accounts, to manually label and\naggregate fake news sites. Each website is tagged with at\nmost 3 of the following subtypes: fake, satire, bias, con-\nspiracy, rumor, state, junksci, hate, clickbait, and unreliable.\nFor instance, \u201csites that entirely fabricate information, dis-\nseminate deceptive content, or grossly distort actual news\nreports\u201d are tagged as fake and \u201csites that provide generally\ncredible content, but use exaggerated, misleading, or ques-\ntionable headlines, descriptions, and/or images\u201d are tagged\nasclickbait. Using this annotation procedure (please see the\noriginal Zimdars manuscript for a detailed description), they\nidentify a total of 786 fake and low-quality news sites. We\nremove the defunct domains, resulting in 545 active sites.\nMany academic works adopt Zimdars\u2019s list to study fake\nnews (Shao et al. 2016; Horne et al. 2018; Allcott and\nGentzkow 2017; Rini 2017; Koulolias et al. 2018). We use\nthis list in our study too due to its i) transparent annotation\nand quality evaluation procedure, ii) relative large size com-\npared to various other available lists, and iii) subcategoriza-\ntion (e.g. fake, clickbait), which allows us to determine the\nad reliance of di\u000berent types of problematic news producers.\nMedia Bias/Fact Check (MBFC) list: The MBFC sta\u000b exam-\nines a news site\u2019s i) wording, ii) source, iii) story selection,\nand iv) political a\u000eliation to determine whether it is rep-\nutable. This list contains 1.3K credible traditional news sites,\nout of which 1.2K are still active. This list is also widely\nused in many related works that focus on media bias and\nfake news (Main 2018; Starbird 2017).\nWe assign these websites to 3 groups: i) traditional, ii)\nfake which includes only domains tagged with the subtype\nfake, and iii) low-quality for all problematic domains in-\ncluded in (Zimdars 2018). We also obtain the following ad-\nditional data for each site: i) average monthly tra\u000ec using\nsimilarweb.com, a popular web analytics platform (Singal\nand Kohli 2016); and ii) ageusing whois.com, a domain\nname registrar database (Mueller and Chango 2008).\nWhile both Zimdars andMBFC are extensively used by\nthe related literature, they are not the only available lists of\nfake and traditional news domains. As such, we also perform\nrobustness checks by repeating our analysis using di\u000berent\nfake and traditional news lists. The description of these lists\nand the results are presented in Section \u201cRobustness Check\u201d.\nNews Site Ad Servers and Ads: We \ufb01rst aggregated a list\nof known ad servers on the Web. Then, we identi\ufb01ed the\n85\nsubset of ad servers present on each news site. Finally, we\nevaluated the credibility of each ad server in the subset.\nKnown Ad Servers: We included 22.3K ad servers listed\non EasyList and EasyList Privacy (https:// easylist.to), the\ntwo most comprehensive and commonly used sources for\nblocking unwanted web content such as ads. While com-\nprehensive, EasyList does not make the distinction between\ncategories of ad servers (e.g., standalone versus bundled).\nThis list includes ad trackers that are used to track and ana-\nlyze user behavior, in addition to ad servers that deliver ads.\nGiven the focus of our paper, we manually reviewed the top\n50 most popular ad servers and removed the domains that\nmerely track users (e.g. Google Analytics).\nNews Site Ad Servers and Ads: We used Selenium Web-\nDriver API (Avasarala 2014) to identify the subset of ad\nservers present in fake and traditional news sites and the\nads that they serve. Selenium is a tool that simulates the\nbrowsing behavior of an ordinary human. Using this tool\nto regularly \u201cvisit\u201d traditional and fake news sites in our\ndataset, we recorded the set of ads and the ad servers that\ndeliver those ads. Using Selenium has the following ad-\nvantages over other methods of collecting ad-server-related\ndata: i) it bypasses common anti-scraping techniques such\nas requiring the \u201cUser-Agent\u201d \ufb01eld in the request header\nor employing honeypot traps; ii) it triggers front-end scripts\nthat fetch ads; and \ufb01nally, iii) it allows us to set custom user\nbrowser settings. We used an empty pro\ufb01le devoid of any\ndemographics cookies, disabled all cookies and enabled the\nprivate-browsing mode to ensure our analyses are not im-\npacted by browsing histories.\nFor each news site, our automated scripts used Selenium\nto (i.) initiate a new browsing session, (ii.) navigate to the\nsite\u2019s homepage, and (iii.) scroll through the page and re-\nfocus the mouse on each detected visible iframe. Iframes\nare generally used to serve ads, so this process of making\niframes visible triggers the ad-serving scripts and populates\nthe URLs that reveal the ad and the ad server delivering it.\nWe scraped all URLs embedded in the webpage and each\niframe. We then extracted the corresponding domains from\nthese URLs2. We kept the subset of URLs with domains\nthat matched one of the known ad servers in our dataset.\nMany ad servers track ad-related activities in addition to\nserving ads. Ad tracking activity does not directly contribute\nto publisher revenue. Thus, we next \ufb01lter out such ad track-\ning links for the top-50 most popular ad servers in our data.\nThese top-50 ad servers account for 83.6% of all likely ads\nin our data. We manually examined the subdomains and\nhigh-frequency substrings for each ad server and identi\ufb01ed\nthose that correspond to ad-tracking3. We randomly sam-\npled and inspected 10 URLs for each subdomain (and sub-\nstring) and classi\ufb01ed it as ad-tracking if all inspected links\n2For instance, if a given URL is https:// adserver1.co.uk/ adurl=\n123&referrer=cnn.com, the domain is adserver1.co.uk.\n3As an example, stats.g.doubleclick.net is an ad-tracking sub-\ndomain of doubleclick.net. It\u2019s a script that collects speci\ufb01c de-\nmographic information about visitors. Similarly, the substring\n\u201ctrackimp\u201d in the URL https:// ad.doubleclick.net/ ddm/ trackimp/\nalso indicates that the URL is not an actual ad.were about tracking. Finally, we used these identi\ufb01ed ele-\nments to \ufb01lter out ad-tracking URLs through regex match-\ning. Using this approach, we collected data for 12 weeks (be-\ntween 09/17/2019 and 12/02/2019) resulting in 565 unique\nad servers and 1.32M ad-related URLs.\nAd Server Credibility Data: We used 2 sources to determine\nad server credibility: i) 10 distinct publicly available mal-\nware domain lists (Kuhrer, Rossow, and Holz 2014; Zarras\net al. 2014; Zhauniarovich et al. 2018); and ii) VirusTo-\ntal (Masri and Aldwairi 2017; Hong et al. 2020), a popu-\nlar free service that checks whether a given URL is risky.\nBoth sources are commonly used in related work (Kuhrer,\nRossow, and Holz 2014; Zarras et al. 2014; Masri and Ald-\nwairi 2017) to identify the trustworthiness of a web domain,\nor to study the spread of viruses. We marked an ad server as\nrisky if it was included in one of the malware domain lists or\nif at least 1 of the 100 randomly sampled ad URLs for that\ndomain was detected by VirusTotal as risky. Otherwise, we\nmarked the ad server as credible. Approximately, 78.8% of\nthe 565 ad servers are credible.\nAnalysis\nWe \ufb01rst address RQ1 and examine the overall prevalence\nand quality of display ads across di\u000berent types of news pub-\nlishers. We then address RQ2 by assessing fake and tradi-\ntional news publishers\u2019 dependence on the top-tier credible\nad servers. Next, we address RQ3 by estimating the annual\nad revenue that top ad \ufb01rms generate through their partner-\nship with fake and low-quality news sites. Finally, we con-\nduct robustness checks.\nNews Producer Reliance on Display Ads\nThe success of a market-based solution to curtail fake news\nfundamentally depends on fake news sites\u2019 reliance on ads\nto produce revenue. Such an approach would surely be im-\npractical if, for instance, the vast majority of fake news sites\nare funded by hostile governments. Little empirical work has\nbeen done to characterize this ad reliance. To \ufb01ll this knowl-\nedge gap, we \ufb01rst address the following research questions:\nRQ1-a: To what extent is (i.) traditional, (ii.) fake, and (iii.)\nother low-quality news producer tra\u000ec supported by ad\nservers?\nRQ1-b: What types of ad servers provide such support?\nAnalysis here allows us to not only measure fake andlow-\nquality news producers\u2019 reliance on display ad revenue and\nexamine the characteristics of the ad servers they employ;\nit also contextualizes these \ufb01ndings by comparing them to\ntraditional news publishers.\nAd Servers and Ad Frequency (RQ1-a): News produc-\ners are heavily reliant on display ad revenue. (Budak et al.\n2016) shows that news media is the content provider seg-\nment with the highest display-ad reliance\u2014with over 90%\nof tra\u000ec supported by display-ads. Here, we \ufb01rst investigate\nhow di\u000berent types of news producers (traditional, fake, and\nlow-quality) rely on display advertising to generate revenue.\nWe observe that 74.2% of all publishers have one or more\nad servers displaying ads. In other words, 25.8% of all pub-\n86\nModel (1) Model (2) Model (3)\nad server count likelihood of being a risky ad server dependence on top-10 credible ad servers\nsubtype\nbias 0.569 (1.873) \u00000.001 (0.051) \u00000.035 (0.042)\nclickbait 5.208\u0003(2.778) 0.016 (0.0639) \u00000.062 (0.056)\nconspiracy \u00001.587 (1.931) \u00000.0729 (0.0579) \u00000.053 (0.044)\nfake 10.001\u0003\u0003\u0003(2.318) 0.1601\u0003\u0003(0.0701) \u00000.093\u0003(0.051)\njunksci \u00004.531 (3.320) 0.0533 (0.1003) \u00000.242\u0003\u0003\u0003(0.077)\nother \u00007.012\u0003\u0003(3.341) \u00000.1296 (0.1057) \u00000.163\u0003\u0003(0.070)\nsatire 4.822\u0003(2.465) \u00000.0686 (0.068) 0.091\u0003\u0003(0.042)\nunreliable \u00001.207 (2.471) \u00000.0115 (0.0682) \u00000.068 (0.053)\nad server count \u00000.0038\u0003\u0003\u0003(0.0006) \u00000.002\u0003\u0003\u0003(0.0004)\nmonthly tra\u000ec (log10) 9.309\u0003\u0003\u0003(0.484) 0.0222\u0003(0.0134) \u00000.029\u0003\u0003\u0003(0.010)\ndomain age (years) 0.104 (0.082) 0.0049\u0003\u0003(0.0022) 0.001 (0.001)\nConstant \u000030.967\u0003\u0003\u0003(2.549) \u00000.033 (0.078) 0.570\u0003\u0003\u0003(0.051)\nObservations 1,847 33,632 1,361\nR20.236 0.106 0.056\nNote:\u0003p<0.1;\u0003\u0003p<0.05;\u0003\u0003\u0003p<0.01\nTable 1: Model (1) is the regression result for the number of ad servers across publishers. Model (2) is the likelihood of an\nad server being risky modeled using a mixed e\u000bect logistic regression. Model(3) is for the fraction of a domain\u2019s ads that are\ndelivered by top N=10 credible ad servers. Base publisher type for all models is traditional.\nFigure 2: Distribution of the number of unique ad servers\nacross di\u000berent news publisher types.\nlishers are ads-free. Surprisingly, we also see that fake pub-\nlishers have fewer ad servers on average compared to low-\nquality andtraditional. For instance, the median number of\nad servers for fake andtraditional is 6 and 8 respectively\n(see Figure 2). Further, close to one-\ufb01fth of traditional news\nsites have 50 or more ad servers, but less than one-tenth of\nfake andlow-quality publishers fall into that category. Addi-\ntionally, 29.6% and 32.8% of fakeandlow-quality news sites\nhave 0 ad servers (i.e., these sites are ad-free) compared to\n22.9% of traditional publishers.\nAt \ufb01rst sight, results here suggest that news publishers\u2019 ad\nreliance is comparatively less than what\u2019s observed in prior\nresearch (Budak et al. 2016). Further, \ufb01ndings are also at\nodds with the claim that fake news publishers are aggres-\nsively pro\ufb01t-driven (Braun and Eklund 2019). Yet, expla-\nnations and potential confounds are readily available. For\ninstance, past research (Budak et al. 2016) shows that long-\ntail content providers with a limited audience are less likelyto show ads because they have too little tra\u000ec to monetize.\nIndeed, we observe that the combined viewer tra\u000ec for ads-\nfreefake sites is only 7.5% of the aggregated tra\u000ec for all\nfake publishers (comparable results for low-quality). Pub-\nlisher age is likely to play a similar role\u2014newer websites\nmay be preoccupied with other tasks such as Search Engine\nOptimization instead of expanding their ads pipeline (Kelsey\n2017). Finally, past research shows the diversity of motiva-\ntions for fake news producers (Marwick and Lewis 2017).\nWhile many fake news producers are primarily interested\nin monetizing their tra\u000ec, others, such as state-sponsored\nnews, should be less inclined to do so. Here, given publisher\niwith the number of unique ad servers yi, we run the follow-\ning model controlling for average monthly tra\u000ec, subtype4,\nand website age:\nyi=\f0+\f1\u0003monthly tra f f ic i+\f2\u0003subtype i+\f3\u0003age i+\u000f\n(1)\nResults are summarized on Table 1 (Model 1). We observe\nthat news publishers labeled fake indeed have a signi\ufb01cantly\nhigher number of ad servers (10 more ad servers on average)\nthan traditional after controlling for web tra\u000ec and age. Fur-\nthermore, we also observe a marginally-signi\ufb01cant higher ad\nreliance for clickbait andsatire publishers than traditional.\nAs a robustness check, we also computed the average num-\nber of ads on i\u2019s homepage (approximated using the number\nof unique ad-related URLs) and performed a similar regres-\nsion task. The results are comparable and the corresponding\nregression table is omitted for brevity.\nImplications Our analysis shows that a larger fraction of\nfake news sites are ad-free than traditional news sites. Yet,\nit is important to note that this fraction, 29.6%, while large\n4When a publisher has multiple subtypes (see detailed descrip-\ntion of subtypes in Section \u201cData\u201d), we create separate datapoints\nforifor each subtype.\n87\n(a) Fraction of news sites\nwith at least X% ads from\ncredible ad servers.\n(b) Fraction of ads from credible ad\nservers. Points are scaled proportion-\nally per news publisher type.\nFigure 3: Fraction of ads from credible ad servers.\ncompared to traditional news sites, is still rather small com-\npared to other content provider segments (Budak et al.\n2016). Further, we show that this unexpected di\u000berence be-\ntween fake and traditional news sites can be explained by\nfake news sites having smaller audiences. This also has im-\nportant implications. As fake news sites become more popu-\nlar over time, they can improve their display ad capabilities.\nTherefore, it is crucial to respond to this crisis as soon as\npossible. Finally, we identify the di\u000bering degrees to which\ndi\u000berent publisher subtypes bene\ufb01t from display ads. Our\nanalysis suggests that fake, clickbait, and satire sites are\nmost likely to su\u000ber from a successful market strategy tar-\ngeting display ad revenue. Overall, we provide empirical ev-\nidence for the claim by experts (Kshetri and V oas 2017) and\njournalists (Subramanian 2017) that fake news is at least par-\ntially motivated and sustained by ad revenue.\nAd Servers and Ad Credibility (RQ1-b) In this sec-\ntion, we compare and contrast the di\u000berence in qual-\nity between ad servers in di\u000berent groups of domains\n(fake; low-quality; traditional).\nFirst, for a given publisher i, we model i\u2019s ad servers\u2019 risk-\niness using a mixed e\u000bect logistic regression. Speci\ufb01cally,\nthe number of risky ad servers on iis modeled as the num-\nber of successes and the total number of ad servers as the\nnumber of Bernoulli trials in a binomial distribution. Let Ji\ndenotes i\u2019s ad servers, and P(is risky) be the binomial prob-\nability. We apply the following model:\nTi=Binomial (P(is risky);jJij) (2)\nP(is risky) =logit(\f0\u0003i+\f1\u0003monthly tra f f ic i+\n\f2\u0003subtype i+\f3\u0003age i+\f4\u0003adserver count i+\u000f) (3)\nNote that we also include a random e\u000bect for the domain i\nwhen modeling P(is risky). As shown in Table 1 (Model 2),\nad servers on fake sites are, on average, 4% (\f f ake=0:16)\nmore likely to be risky than those on traditional. Finally, as\na robustness check, we write yias the number of risky ad\nservers on i, and run a simple regression controlling for i\u2019s\nsubtype, average monthly tra\u000ec, and age. Results are con-\nsistent with our prior observation (i.e., fake sites have more\nrisky ad servers on average).Next, we compute the fraction of ads on ithat are deliv-\nered through eJi, the subset of credible ad servers on i. We\nwrite the fraction as fi;eJi. As shown in Figure 3a, we observe\nthat for 44.6% and 35.7% of fakeandlow-quality publishers,\nrespectively, the majority of ads present on their websites are\nin fact delivered by risky ad servers. In comparison, that \ufb01g-\nure is 34.1% for traditional publishers. Further, we also dif-\nferentiate domains with few ad servers from the ones with a\nhigh ad server count. Results are summarized in Figure 3b.\nPublishers are separated by type (color) and into quartiles\nbased on their ad server counts (x-axis). Additionally, the y-\naxis values indicate the average fraction of ads delivered by\ncredible ad servers across domains. Finally, datapoint size\nis scaled per news publisher type. As shown, domains that\nhave very few ad servers (1st quartile) have a signi\ufb01cantly\nhigher fraction of credible ads compared to publishers with\nmore ad servers (2nd, 3rd, and 4th quartiles). Further, fake\nandlow-quality publishers with a moderate number of ad\nservers (2nd and 3rd quartiles) on average have a consider-\nably higher fraction of ads delivered by risky ad servers than\ntraditional publishers. The di\u000berence is insigni\ufb01cant for do-\nmains with a high ad server count (4th quartile), however.\nThis is possibly because these publishers are more aggres-\nsively pro\ufb01t-driven regardless of domain type.\nImplications Beyond systematic di\u000berences in overall re-\nliance on ad revenue, news producers also di\u000ber in the types\nof ad servers with which they partner. Overall, our results\nhere suggest that fake and low-quality news sites partner\nmore with risky ad servers. This has important implications\nfor news consumers. These low-quality news producers are\nnot only polluting consumers\u2019 news diet but also exposing\nthem to potential privacy and security risks. Perhaps the\nfact that fake news sites engage in such risky behavior is\nnot surprising. However, this highlights the importance of\ntools and regulations to protect news consumers online. Fi-\nnally, while fake and low-quality news sites have a higher\ntendency to partner with risky ad servers compared to tradi-\ntional news sites, they are still highly reliant on credible ad\nservers to monetize their tra\u000ec. In the next section, we will\ndelve deeper into that reliance and determine whether it can\nbe leveraged to combat fake news.\nFake News Publishers\u2019 Dependence on Top\nCredible Ad Servers\nThus far, we showed that fake sites have signi\ufb01cantly higher\nad reliance than traditional news sites of comparable viewer\ntra\u000ec and age. Further, the majority of ads for 55.4% and\n64.3% of fake andlow-quality domains with at least 1 ad\nserver are delivered through credible ad servers. Both obser-\nvations suggest promise for a market-based solution. Never-\ntheless, convincing allcredible ad servers to blacklist known\nfake news sites is nontrivial. This leads us to address the fol-\nlowing research question:\nRQ2: How concentrated is fake and other low-quality\nnews publishers\u2019 ad reliance on a small number of top\ncredible ad servers?\nThis research question can help us determine the e\u000bec-\ntiveness of pressuring top-tier credible ad servers to black-\n88\nFigure 4: A simple example using 3 fake news publishers\nand 3 credible ad servers to summarize the two measures of\nad reliance. Note that i) panel A and B contain data; ii) panel\nC and D are an example of weighted domain share; and iii)\npanel E and F are an example of weighted ad share.\nlist fake and low-quality news producers. Owners of these ad\nservers are likely to be more motivated to ban fake andlow-\nquality domains from using their services given their brand\nsafety concerns (Mills, Pitt, and Ferguson 2019).\nWe evaluate the dependence on top credible ad servers for\neach cluster of domains (fake, low-quality, traditional ) using\n2 measurements: i) weighted domain share, and ii) weighted\nad tra\u000ec share. These measures are summarized in Figure\n4 through a toy example and described in detail below. We\nnote that only domains with at least 1 ad server are included\nin the analysis.\nWeighted Domain Share The fake and low-quality new\nsites whose reliance on top-k credible ad servers exceeds\ntheir pro\ufb01t margin are particularly vulnerable to the market-\nbased strategy studied in our paper. For instance, approxi-\nmately 33.3% of ads on realnewsrightnow.com are served by\nDoubleClick\u2014one of the top-10 credible ad servers accord-\ning to our analysis described below. If this site\u2019s pro\ufb01t mar-\ngin is lower than 33.3%, being blacklisted by DoubleClick\nwould wipe out all its pro\ufb01ts and likely lead to its demise\u2014\nassuming ads are similarly priced. As this example demon-\nstrates, this measure allows us to estimate the fraction of fake\nnews sites that is likely to perish under di\u000berent pro\ufb01t mar-\ngin assumptions if top-k credible ad servers are pressured\ninto blacklisting them.\nTo estimate this fraction for each news site, we \ufb01rst de-\n\ufb01ne the weighted domain share of an ad server jon a news\nsiteias the fraction of ads on idelivered by j(denoted as\nfi;j). This is presented in panel (A) in Figure 4. Given this\nmeasure, we next de\ufb01ne the weighted domain share of an\nad server jfor all publishers in G(fake, low-quality ortra-\nditional ) by simply averaging fi;jfor all i2G(denoted asfG;j, example given in panel (C) in Figure 4). This measure\ncan be used to rank all credible ad servers and identify top-\nk for each G2 ftraditional; fake; low-qualityg (denoted as\neJG;k). Having identi\ufb01ed the top credible ad servers ( eJG;k), we\ndenote the dependence of each publisher ion this set of ad\nservers as fi;eJG;k(example given in panel (D) in Figure 4).\nWe provide an overview of the top-10 ad servers and their\nweighted domain share in Table 2.\nHow does this reliance vary across publisher types? To an-\nswer this question, we examine reliance on the top-10 cred-\nible ad servers (y i=fi;eJG;10) by applying the regression char-\nacterized by the following Equation:\nyi=\f0+\f1\u0003monthly tra f f ic i+\f2\u0003subtype i\n+\f3\u0003age i+\f4\u0003adserver count i+\u000f(4)\nAs shown in Table 1 (Model 3), we see fake, and junksci\nsites are signi\ufb01cantly less dependent on the top-10 than tra-\nditional news sites. For instance, a fake news site has 9.3%\n(\f2=\u00000:093) less dependence on the top-10 credible ad\nservers than a traditional news site of a similar age, pop-\nularity, and server count. We also repeat the process for\nk=f5;15gand reach comparable results.\nNext, we group each publisher iaccording to its reliance\non the top-k credible ad servers ( fi;eJG;k). We consider four\nlevels: i)\u001433%, largely independent; ii) (33%; 66%], mod-\nerately dependent; iii) (66%; 99%], signi\ufb01cantly dependent;\nor iv) 100%, completely dependent. We then plot the 4 lev-\nels of dependence in Figure 5a. The x-axis gives the top-k\ncredible ad servers (e.g. eJfake;k for the \ufb01rst facet) and the y-\naxis gives what fraction of the domains in that group (e.g.\nfake) has a given level of reliance. We see that 6.7% of all\nfake domains are completely dependent on the top-10 ad\nservers. In other words, if the top-10 credible ad servers are\nno longer available, 6.7% of fake publishers will have 0 ad\nservers left. Additionally, we also see that close to half of all\nfakedomains are at least moderately dependent on top-10 ad\nservers. The patterns observed for fake are rather compara-\nble to low-quality andtraditional \u2014especially when focus-\ning on reliance on a small number of top ad servers (small\nx-values). The distinctions, however, become more apparent\nwhen considering all ad servers (max x-value) and lower re-\nliance levels (e.g. (33%; 66%]). The increased distinction is\ndue to a higher reliance on risky ad servers by fake publish-\ners than traditional ones\nImplications We show that the top credible ad servers play a\nsubstantial role in delivering ad revenue to a large fraction of\nfake news sites. For instance, 6.7% of all fake domains are\ncompletely dependent on the top-10 ad servers. Such sites\nare almost sure to perish if those ad servers are pushed to\nblacklist them. This already demonstrates the potential of\nour proposed market-based solution. However, we expect\nthe e\u000bect to be much larger depending on the pro\ufb01t margins\nof news publishers. To determine the fraction of sites that is\nlikely to lose all pro\ufb01ts, we turn to pro\ufb01t margin estimates\nshared for news and online media organizations. Past work\nshows that the pro\ufb01t margins of news media organizations\nhave been on the decline, with best performing organiza-\ntions\u2019 pro\ufb01t margins hovering around 10% (Nee 2011). Tra-\n89\nweighted domain share weighted ad tra\u000ec share\nfake low-quality traditional fake low-quality traditional\n1 doubleclick.net\n(0.31)doubleclick.net\n(0.3)doubleclick.net\n(0.27)doubleclick.net\n(0.4)doubleclick.net\n(0.28)doubleclick.net\n(0.22)\n2 googlesyndica-\ntion.com (0.05)googlesyndica-\ntion.com (0.04)addthis.com\n(0.06)googlesyndica-\ntion.com (0.05)adfox.ru\n(0.08)googlesyndica-\ntion.com (0.02)\n3 projectwonder-\nful.com (0.01)addthis.com\n(0.03)googlesyndica-\ntion.com (0.03)lockerdome.com\n(0.05)googlesyndica-\ntion.com (0.02)gannett-cdn.com\n(0.02)\n4 content.ad\n(0.01)lockerdome.com\n(0.01)gannett-cdn.com\n(0.02)zemanta.com\n(0.04)libertycdn.com\n(0.01)addthis.com\n(0.01)\n5 earnify.com\n(0.01)pubmine.com\n(0.01)casalemedia.com\n(0.01)lockerdome-\ncdn.com (0.03)casalemedia.com\n(0.01)casalemedia.com\n(0.01)\n6 outbrain.com\n(0.01)revcontent.com\n(0.01)everesttech.net\n(0.01)outbrain.com\n(0.02)connatix.com\n(0.01)serving-sys.com\n(0.01)\n7 serving-sys.com\n(0.01)shopify.com\n(0.01)ownlocal.com\n(0.004)adrta.com\n(0.01)adrta.com\n(0.01)gumgum.com\n(0.01)\n8 acuityplat-\nform.com (0.01)lockerdome-\ncdn.com (0.01)gumgum.com\n(0.004)udmserve.net\n(0.01)fastly.net\n(0.01)betrad.com\n(0.01)\n9 sekindo.com\n(0.01)adblade.com\n(0.01)serving-sys.com\n(0.004)posst.co\n(0.01)revcontent.com\n(0.01)company-\ntarget.com (0.01)\n10 lockerdome.com\n(0.01)sekindo.com\n(0.01)r\ufb01hub.com\n(0.004)ezoic.net\n(0.004)yimg.com\n(0.01)everesttech.net\n(0.01)\nTable 2: Top-10 credible ad servers ranked by i) weighted domain share and ii) weighted ad share.\nditional news media employ a large body of trained journal-\nists and are likely to have higher costs compared to fake and\nlow-quality news publishers. Therefore, to provide a more\nconservative estimate of the proposed method, we identify\npro\ufb01t margins across di\u000berent sectors and \ufb01nd that even the\nmost pro\ufb01table sectors have a net pro\ufb01t margin lower than\n20%5. While we do not know the pro\ufb01t margins of the new\nsector of fake and low-quality news, using even the most\nconservative estimates leads us to conclude that fake and\nlow-quality publishers with at least moderate dependence\n(>33%) stand to become unpro\ufb01table. This amounts to\nmore than half of all fake news sites and two-thirds of all\nlow-quality sites.\nWeighted Ad Tra\u000ec Share Web tra\u000ec is considerably dif-\nferent from domain to domain: top-tier publishers garner\nmillions of viewers a week, whereas lower-tier news sites\nhave only thousands of visitors a month. A fake news site\nwith millions of views has a more detrimental e\u000bect on our\nsociety than one that has only thousands. To account for this,\nwe next reweight ad server signi\ufb01cance by taking into ac-\ncount the ad/web tra\u000ec of the publishers they serve.\nGiven publisher i2Gand ad server j, we de\ufb01ne j\u2019s\nweighted ad tra\u000ec share on iasy(i;j)=fi;j\u0003si, where\nsiis the average monthly web tra\u000ec of i. We then calcu-\nlate j\u2019s aggregated weighted ad tra\u000ec share for group Gas\ny(G;j)=P\ni2Gy(i;j)P\nk2JP\ni2Gy(i;k)(panel E in Figure 4). We then de-\nnoteeGG;kas the top-k credible ad servers serving domains\ninGaccording to weighted ad tra\u000ec. The top-10 credible ad\nservers ranked by weighted ad share are listed on Table 2.\nNext, given eGG;k, we compute the total ad tra\u000ec ac-\ncounted for by eGG;kasP\nj2eGG;ky(G;j) (panel F in Figure 4).\n5https://www.forbes.com/sites/sageworks/2015/09/06/these-\nindustries-generate-the-highest-pro\ufb01t-marginsWe can then plot this measure, which characterizes the frac-\ntion of ad tra \u000ec in each group Gaccounted for by top-k\ncredible ad servers.\n(a) Domain dependence on top X credible ad servers.\n(b) Fraction of total ad tra\u000ec delivered by credible ad\nservers\nFigure 5: The reliance of di\u000berent types of publishers on\ncredible ad servers.\nThe results are given in Figure 5b. We observe that 67:5%\nand 56:6% of all ad tra\u000ec on fake and low-quality sites\nare delivered by credible ad servers, compared to 46:4%\noftraditional sites. Further, the top-10 credible ad servers\n90\nalone accounted for 61.1% of all ad tra\u000ec on fake sites\nand 43.4% on low-quality sites, suggesting that the distribu-\ntion of ad tra\u000ec across all credible ad servers is highly un-\nequal. Indeed, the normalized Gini coe\u000ecients (Gini 1921)\nfor the distribution y(G;J) are 0.83 and 0.81 for fake and\nlow-quality sites respectively (i.e., a substantial fraction of\ntotal ad tra\u000ec is concentrated on a handful of credible ad\nservers). Also note that Figure 5b shows a clearer divide be-\ntween fake, low-quality, and traditional domains\u2019 reliance\non top-k (e.g., when k=10) ad servers compared to Figure\n5a. This is due to the long tail of small publishers (fake, low-\nquality, and traditional ) with comparatively less web tra\u000ec\nbehaving more similarly.\nImplications The weighted ad tra\u000ec analysis reiterates the\nsigni\ufb01cant role top credible ad servers play in providing rev-\nenue streams for problematic news producers. A striking\namount\u201461%\u2014of fake news web tra\u000ec is estimated to be\nsupported by only 10 credible ad servers. Using the earlier\nmeasure, we were able to show that 50.0% of fake news sites\nare at least moderately reliant on top-10 ad servers and stand\nto become unpro\ufb01table if blacklisted. The weighted ad traf-\n\ufb01c analysis paints a similar picture, with a comparable dent\nwhen accounting for publisher popularity.\nTop Ad Firms Pro\ufb01ting From Fake News Ad \ufb01rms are\npro\ufb01t-maximizing entities. As such, the ability to convince\neven the most contentious ad \ufb01rm to blacklist fake news sites\ndepends on the revenue they would lose through such an ac-\ntion. Therefore, here we address the following question:\nRQ3: What is the cost to ad \ufb01rms of blacklisting fake and\nlow-quality news sites and how does that cost vary by\npublisher type?\nTo achieve this, we \ufb01rst match each ad server to its\nadvertising \ufb01rm using Whois6. Then, we determine each\n\ufb01rm\u2019s aggregated weighted ad tra\u000ec for each group G, and\nuse a back-of-the-envelope calculation to estimate ad rev-\nenue. Given a \ufb01rm mand its ad servers Jm, we calculate\nm\u2019s weighted ad tra\u000ec for each group Gasy(G;Jm)=P\nj2Jmy(G;j). We observe that 48.0% and 32.0% of all\nweighted ad tra\u000ec on fake andlow-quality sites are deliv-\nered through Google alone. Or, in the words of Craig Silver,\n\u201c[Google is the] \ufb01nancial engine for fake news\u201d. Aggregated\nad tra\u000ec for the remaining \ufb01rms us more modest. Notably,\nMGID, Lockerdome, Outbrain, and Yandex each has above\n5.0% weighted ad tra\u000ec in fake orlow-quality domains.\nNext, ad revenue is most commonly generated through\nad impressions. The number of ad impressions is de\ufb01ned\nas the total number of ads displayed when a user lands\non a webpage. Based on the 2018-2019 Google advertis-\ning rates (Aribarg and Schwartz 2020; V olovich 2019), 1K\nimpressions, or 1 CPM (cost-per-mile), typically generates\n$2:40 to $2:80 in ad revenue for a news site. We \ufb01rst ob-\ntained the 2018 revenue information for each advertising\n\ufb01rm from: i) its own press release or \ufb01nancial report; ii)\n6Whois (Mueller and Chango 2008) provides domain own-\nership information. For instance, various ad servers (e.g. dou-\nbleclick.net, alooma.com, gvt1.com, 2mdn.net) are all registered\nunder Google.ad \ufb01rm weighted\nad sharemonthly revenue\nupper bound\ntop ad \ufb01rms working with fake news publishers\n1 google 0.48 11.4 K (0.000008%)\n2 mgid 0.08 1.9 K (0.002347%)\n3 lockerdome 0.08 1.8 K (0.039764%)\n4 outbrain 0.06 1.3 K (0.000146%)\n5 criteo sa 0.02 0.5 K (0.000021%)\ntop ad \ufb01rms working with low quality news publishers\n1 google 0.32 652.9 K (0.000477%)\n2 yandex 0.08 174.5 K (0.007969%)\n3 criteo sa 0.04 73.0 K (0.003176%)\n4 pubmatic 0.03 55.5 K (0.103937%)\n5 tmrg 0.02 47.9 K (0.011419%)\nTable 3: Top-10 ad \ufb01rms\u2019 monthly ad revenue by partner-\ning with fake andlow-quality news publishers. Ad \ufb01rms are\nranked by the weighted ad share. Table includes each \ufb01rm\u2019s\nmonthly revenue in i) absolute dollar amount, and ii) nor-\nmalized by the \ufb01rm\u2019s 2018 annual revenue in parentheses.\nstatia.com, a market and statistics research company; or iii)\nowler.com, a website specialized in building company pro-\n\ufb01les. Next, we compute the normalized annual ad revenue\nthrough news sites in group Gfor each ad \ufb01rm mas:\nrm=y(G;Jm)\u0003TG\u0003CPM\nRm(5)\nwhere the upper and lower bound for CPM is set at CPM =\nf$2:40, $2:80g; TGis the aggregated viewer tra\u000ec, in thou-\nsands, for all publishers in group G; and, Rmism\u2019s total\nannual revenue for 2018.\nIn terms of absolute dollar amount, we estimate that top-\n10 \ufb01rms, in aggregate, generate $24,500 to $28,600 monthly\nad revenue through fake new sites, and $985,700 to $1.15\nmillion through low-quality publishers. Additionally, for the\ntop-10 high ad tra\u000ec \ufb01rms in the fake orlow-quality cat-\negories, we depict the corresponding rmin Table 3. As\nshown, even for the smaller advertising \ufb01rms (e.g., Lock-\nerdome, Pubmatic), ad tra\u000ec through fake news sites only\ncontributes 0.1% to 1.0% to their total annual revenue. For\ntech giants like Google, rmis a mere millionth of a fraction.\nFinally, ad \ufb01rms and publishers can also opt to use the pay-\nby-click revenue model instead of the pay-by-impression\nmodel. As such, for robustness check, we repeat our estima-\ntion using the current benchmark cost-per-click (CPC) rates,\nwhich ranges from $0.35 per-click to $0.74 per-click. We\nobserve comparable results.\nImplications Overall, we observe that revenue generated\nthrough fakeandlow-quality sites contributes little to the top\nad \ufb01rms\u2019 total annual revenue. The \ufb01ndings in previous sec-\ntions and here collectively make a compelling case: convinc-\ning a handful of top ad management \ufb01rms (Google, MGID,\nLockerdome, Yandex, Pubmatic, and Outbrain) to blacklist\nfake and low-quality news sites can be cost-e\u000bective and is\ntherefore, a \ufb01nancially reasonable path to follow.\n91\nRobustness Check\nPrior research shows that the choice of which fake news\nlist to use as ground truth can impact downstream re-\nsults (Bozarth, Saraf, and Budak 2020). In this section, we\nintroduce two new datasets\u2014one for de\ufb01ning fake news and\nanother for de\ufb01ning traditional news\u2014and repeat our analy-\nsis to inspect robustness. The two datasets are given below:\nAlternative fake news list\u2014PolitiFact: The PolitiFact\nlist (Gillin 2017) deviates from Zimdars in various impor-\ntant ways: (i.) it is much smaller\u2014there are approximately\n3\n10as many domains listed as fake; (ii.) its primary creation\ngoal was to identify the most-shared fake news sites on Face-\nbook during the 2016 presidential election, so it more nar-\nrowly focuses on political fake news; and (iii.) unlike Zim-\ndars (2018), this list has not been updated since its creation.\nAlternative traditional news list\u2014Vargo: This list of tradi-\ntional news (Vargo, Guo, and Amazeen 2018) di\u000bers from\nMedia Bias/Fact Check in that i) the data is collected through\nGDELT\u2019s global knowledge graph, ii) the list is twice as\nlarge with 2.3K traditional news domains in total.\nWe conducted robustness checks using ground truth pairs\n(PolitiFact, Vargo), (Zimdars, Vargo), and (PolitiFact, Medi-\naBias/Fact Check). The results are largely consistent across\nanalyses. Below, we provide more detailed information for\n(PolitiFact, Vargo) and omit the other two for brevity.\nFirst, we observe that fake sites still have a higher ad re-\nliance than traditional ; but the di\u000berence is not statistically\nsigni\ufb01cant (see the regression in Table 1 for our original\nanalysis). A likely explanation is that PolitiFact has few fake\ndomains which lead to the di\u000berences not being signi\ufb01cant.\nNext, for ad credibility, we see that fakeandlow-quality pub-\nlishers rely more on risky ad servers: 40% of fakeand 39.8%\noflow-quality domains have the majority of their ads deliv-\nered by risky ad servers compared to 37.2% of traditional.\nThis is consistent with our prior observations.\nFurther, focusing on the most popular ad servers, we ob-\nserve that approximately three-\ufb01fths of all fake domains\nlisted in PolitiFact are at least moderately dependent on the\ntop-10 credible ad servers. Similarly, 42% and 61% of total\nweighted ad tra\u000ec in low-quality andfakesites are delivered\nby the top-10 credible ad servers (compared to 56.6% and\n67.5% obtained when using Zimdars andMBFC). In other\nwords, we again \ufb01nd that fakedomains are heavily reliant on\nthe top credible ad servers, both in terms of the fraction of\npublishers with heavy reliance and the fraction of total tra\u000ec\nacross all fake publishers supported by these ad servers.\nFinally, focusing on advertising \ufb01rms and ad revenue,\nwe observe that Google still dominates the advertising\necosystem\u201430% and 62% of all weighted ad tra\u000ec on\nlow-quality andfake domains are delivered by Google ad\nservers compared to 32% and 48% when using (Zimdars\n2018). However, we observe a shift in top ad \ufb01rms ranked\n2-9 (e.g., Nielsen Company has rank=2 opposed to Yandex,\nand TMGR has rank=3 opposed to rank=5) collaborating\nwith fake publishers listed in PolitiFact. We also estimate\nmuch lower revenue for top ad management \ufb01rms: $16,500\nto $19,300 in monthly ad revenue through fake publishers,\nand $334,200 to $390,000 through low-quality sites. Thiscan be explained by the fact that PolitiFact is a much smaller\nlist than Zimdars.\nConclusion and Discussion\nIn this paper, we provided the \ufb01rst large-scale examina-\ntion of the existing advertising ecosystem on fake and low-\nquality news websites and contrast it against that of tradi-\ntional news media. We demonstrated that fake news domains\nhave far more ad servers and ads. Further, ad servers on fake\nnews site are also signi\ufb01cantly more likely to be risky. But,\ntop-tier credible ad servers (and the tech giants that own\nthem) are responsible for delivering a substantial fraction\nof ads on fake and low-quality news sites. Further, based\non our estimation, top-tier \ufb01rms make negligible ad revenue\nthrough these sites. Given these considerations, an e\u000bective\nway to combat fake news is to have ad tech giants blacklist\nknown fake and low-quality news sites.\nGranted, there are several obstacles to implement this\nmeasure. First, platforms are historically reluctant to take up\neditorial duties, such as deciding which publishers are fake\nnews sites, for fear of backlash (Farkas and Schou 2018).\nSome critics and political pundits, however, suggest that this\nresponsibility could be passed on to policy-makers or public\nnews media associations who would then assist platforms\nin ensuring online news publishers meet a minimum qual-\nity standard (Coyle 2016). In fact, policies regulating broad-\ncasting networks in the past can be adopted here (Iosi\ufb01dis\nand Andrews 2019). Next, tech executives also point out that\npro\ufb01t-driven fake news sites banned by top-tier advertising\n\ufb01rms can simply move on to the less reputable ones (Braun\nand Eklund 2019). Conversely, opponents argue that top-\ntier ad \ufb01rms also own the lion\u2019s share of ad inventories,\nwhich would become unavailable to fake and low-quality\nnews sites. Further, by partnering with risky ad \ufb01rms, fake\nnews sites are likely to lose access to high-pro\ufb01le, brand-\nconscience retailers, and high-quality ads. Having more low-\nquality advertisers and ads present on fake news sites can\nthen provide additional visual cues to viewers that they are\nuntrustworthy (Tambini 2017).\nThe e\u000bectiveness of this measure may also be hindered\nby pro\ufb01t-driven owners of blacklisted websites migrating to\nnew domains. As such, e\u000bective fake news detection sys-\ntems are necessary to ensure these problematic publishers\nare identi\ufb01ed promptly. The strategy of blocking fake news\nproducers would only be as e\u000bective as our ability to de-\ntect such sites. There are various commendable e\u000borts in\nthis space, including both manual (Zimdars 2018; Van Zandt\n2018; Mitra and Gilbert 2015; Leetaru and Schrodt 2013)\nand automated approaches (Shu et al. 2017; Horne et al.\n2018). Nonetheless, there is still a lot left to do. For instance,\nresearchers should include additional validation archetypes\nand bias assessment steps to ensure model performance is\nrobust (Bozarth and Budak 2020).\nWe observe the following limitations to our work. First,\napproximately 40% to 60% of all fake news included under\nthe original Zimdars andPolitiFact lists were already de-\nfunct before our study. Defunct domains potentially di\u000ber\nfrom the still active ones. Were the defunct domains black-\nlisted by Google and other popular ad \ufb01rms? If so, did this\n92\nloss of revenue lead to their demise? Unfortunately, Google\ndoes not release a list of news sites it has blacklisted. As\nsuch, we cannot address this question here. Additionally, we\nonly collected ad-related data from each site\u2019s homepage;\nfuture work should scrape subpages to ensure a more com-\nprehensive dataset. Furthermore, our current work is limited\nto ad servers; future work should also examine the types\nof advertisers and ads frequently present on fake and low-\nquality news sites to further map out these websites\u2019 ad-\nvertising ecosystems. Additionally, the CPM and CPC rates\nused in this paper are industrial benchmark rates set by the\nlargest ad \ufb01rms. Similarly, pro\ufb01t margin measures used are\ninformed by sector averages. These measures are likely dif-\nferent for fake and low-quality news sites. However, we note\nthat we use conservative estimates in order not to overesti-\nmate the impact of the proposed approach to curb fake news.\nLastly, relying on ad \ufb01rms to curtail fake news has im-\nportant consequences. Should ad \ufb01rms be used to regulate\nspeech online? We cannot address this question and, as such,\ndo not make a policy recommendation. Instead, we focus\nprimarily on the monetary implication of such an approach.\nWe believe that the policy discussion should include\u2014but\nnot be limited to\u2014the analysis presented in this paper. In-\ndeed, because fake news producers have varied motivations,\ninterventions that target only one may be unsuccessful (Ver-\nstraete, Bambauer, and Bambauer 2017). As mentioned be-\nfore, market forces are only one of the four modes that con-\nstrain behavior. While we provide evidence for the feasibil-\nity of using market forces to a\u000bect the fake news ecosys-\ntem, we cannot settle whether this approach should be pre-\nferred over the other three forms of regulation. Future work\nis needed to further examine both theoretical and empirical\nsupport for di\u000berent ways to curtail fake news, especially\nconsidering the ever-changing strategies employed by fake\nnews producers.\nAcknowledgments\nThis research was supported by the National Science Foun-\ndation (Grant IIS-1815875 and GCR-1934494).\nReferences\nAllcott, H.; and Gentzkow, M. 2017. Social Media and Fake News\nin the 2016 Election. Journal of Economic Perspectives 31(2):\n211\u2013236.\nAllcott, H.; Gentzkow, M.; and Yu, C. 2018. Trends in the\nDi\u000busion of Misinformation on Social Media. arXiv preprint\narXiv:1809.05901 .\nAribarg, A.; and Schwartz, E. M. 2020. Native Advertising in\nOnline News: Trade-O\u000bs Among Clicks, Brand Recognition, and\nWebsite Trustworthiness. Marketing Research .\nAvasarala, S. 2014. Selenium WebDriver practical guide. Packt\nPublishing Ltd.\nBakir, V .; and McStay, A. 2018. Fake News and The Economy of\nEmotions. Digital Journalism 6(2): 154\u2013175.\nBode, L.; Budak, C.; Ladd, J.; Newport, F.; Pasek, J.; Singh, L.;\nSoroka, S.; and Traugott, M. 2020. Words that Matter: How the\nNews and Social Media Shaped the 2016 Presidential Election.\nBrookings Institution Press.Bozarth, L.; and Budak, C. 2020. Toward a better performance\nevaluation framework for fake news classi\ufb01cation. In Proceedings\nof the international AAAI conference on web and social media, vol-\nume 14, 60\u201371.\nBozarth, L.; Saraf, A.; and Budak, C. 2020. Higher ground? How\ngroundtruth labeling impacts our understanding of fake news about\nthe 2016 US presidential nominees. In International AAAI Confer-\nence on Web and Social Media.\nBraun, J. A.; Coakley, J. D.; and West, E. 2019. Activism, adver-\ntising, and far-right media: The case of sleeping giants. Media and\nCommunication 7(4).\nBraun, J. A.; and Eklund, J. L. 2019. Fake News, Real Money: Ad\nTech Platforms, Pro\ufb01t-Driven Hoaxes, and the Business of Journal-\nism. Digital Journalism 7(1): 1\u201321.\nBudak, C. 2019. What happened? The Spread of Fake News Pub-\nlisher Content During the 2016 U.S. Presidential Election. In The\nWorld Wide Web Conference on - WWW \u201919, 139\u2013150. San Fran-\ncisco, CA, USA: ACM Press.\nBudak, C.; Goel, S.; Rao, J.; and Zervas, G. 2016. Understanding\nEmerging Threats to Online Advertising. In Proceedings of the\n2016 ACM Conference on Economics and Computation, EC \u201916,\n561\u2013578. ACM.\nChiou, L.; and Tucker, C. 2018. Fake news and advertising on\nsocial media: A study of the anti-vaccination movement. Technical\nreport, National Bureau of Economic Research.\nChoi, H.; Mela, C. F.; Balseiro, S.; and Leary, A. 2019. Online dis-\nplay advertising markets: A literature review and future directions.\nColumbia Business School Research Paper .\nCoyle, D. 2016. Making the most of platforms: a policy research\nagenda. Available at SSRN 2857188 .\nFarkas, J.; and Schou, J. 2018. Fake news as a \ufb02oating signi\ufb01er:\nHegemony, antagonism and the politics of falsehood. Javnost-The\nPublic 25(3): 298\u2013314.\nFeingold, R. 2017. Fake News & Misinformation Policy\nPracticum.\nFigueira, A.; and Oliveira, L. 2017. The current state of fake news:\nchallenges and opportunities. Procedia Computer Science 121:\n817\u2013825.\nFletcher, R.; Cornia, A.; Graves, L.; and Nielsen, R. K. 2018. Mea-\nsuring the reach of \u201cfake news\u201d and online disinformation in Eu-\nrope. Reuters Institute Factsheet .\nGillin, J. 2017. PolitiFact\u2019s guide to fake news websites and what\nthey peddle. PolitiFact .\nGini, C. 1921. Measurement of inequality of incomes. The Eco-\nnomic Journal 31(121): 124\u2013126.\nGrinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson, B.; and\nLazer, D. 2018. Fake news on Twitter during the 2016 US presi-\ndential election. Technical report, Working Paper. Available from\nthe authors.\nHong, J.; Kim, T.; Liu, J.; Park, N.; and Kim, S.-W. 2020. Phish-\ning url detection with lexical features and blacklisted domains. In\nAdaptive Autonomous Secure Cyber Systems.\nHorne, B. D.; Dron, W.; Khedr, S.; and Adali, S. 2018. Assessing\nthe News Landscape. In Companion of the The Web Conference\n2018, 235\u2013238. Lyon, France: ACM Press.\nIosi\ufb01dis, P.; and Andrews, L. 2019. Regulating the internet inter-\nmediaries in a post-truth world: Beyond media policy? Interna-\ntional Communication Gazette .\n93\nKalsnes, B. 2018. Fake news. In Oxford Research Encyclopedia of\nCommunication.\nKelsey, T. 2017. Introduction to search engine optimization: a\nguide for absolute beginners. Apress.\nKoulolias, V .; Jonathan, G. M.; Fernandez, M.; and Sotirchos, D.\n2018. Combating Misinformation: An ecosystem in co-creation.\nKshetri, N.; and V oas, J. 2017. The economics of \u201cfake news\u201d. IT\nProfessional 19(6): 8\u201312.\nKucharski, A. 2016. Post-truth: Study epidemiology of fake news.\nNature 540(7634): 525.\nKuhrer, M.; Rossow, C.; and Holz, T. 2014. Paint It Black: Evalu-\nating the E\u000bectiveness of Malware Blacklists. In Stavrou, A.; Bos,\nH.; and Portokalidis, G., eds., Research in Attacks, Intrusions and\nDefenses, volume 8688, 1\u201321. Cham: Springer International Pub-\nlishing.\nLazer, D. M.; Baum, M. A.; Benkler, Y .; Berinsky, A. J.; Greenhill,\nK. M.; Menczer, F.; Metzger, M. J.; Nyhan, B.; Pennycook, G.;\nRothschild, D.; et al. 2018. The science of fake news. Science\n359(6380): 1094\u20131096.\nLeetaru, K.; and Schrodt, P. A. 2013. Gdelt: Global data on events,\nlocation, and tone, 1979\u20132012. In ISA annual convention, vol-\nume 2, 1\u201349. Citeseer.\nLessig, L. 1998. The new Chicago school. The Journal of Legal\nStudies 27(S2): 661\u2013691.\nLessig, L. 2006. Code: Version 2.0. Shoeisha Co., Ltd.\nMain, T. J. 2018. The Rise of the Alt-Right. Brookings Institution\nPress.\nMarcon, A. R.; Murdoch, B.; and Caul\ufb01eld, T. 2017. Fake news\nportrayals of stem cells and stem cell research. Regenerative\nmedicine 12(7): 765\u2013775.\nMarwick, A.; and Lewis, R. 2017. Media manipulation and disin-\nformation online. Data and Society Research Institute .\nMasri, R.; and Aldwairi, M. 2017. Automated malicious advertise-\nment detection using VirusTotal, URLV oid, and TrendMicro. In\n2017 8th International Conference on Information and Communi-\ncation Systems (ICICS). Irbid, Jordan: IEEE.\nMehta, S.; Dawande, M.; Janakiraman, G.; and Mookerjee, V .\n2020. Sustaining a Good Impression: Mechanisms for Selling Par-\ntitioned Impressions at Ad Exchanges. Information Systems Re-\nsearch 31(1): 126\u2013147.\nMills, A. J.; Pitt, C.; and Ferguson, S. L. 2019. The relationship\nbetween fake news and advertising: brand management in the era\nof programmatic advertising and proli\ufb01c falsehood. Journal of Ad-\nvertising Research 59(1): 3\u20138.\nMitra, T.; and Gilbert, E. 2015. Credbank: A large-scale social\nmedia corpus with associated credibility annotations. In Ninth In-\nternational AAAI Conference on Web and Social Media.\nMueller, M.; and Chango, M. 2008. Disrupting global governance:\nthe Internet whois service, ICANN, and privacy. Journal of Infor-\nmation Technology and Politics 5(3): 303\u2013325.\nMustafaraj, E.; and Metaxas, P. T. 2017. The fake news spreading\nplague: was it preventable? In Proceedings of the 2017 ACM on\nweb science conference, 235\u2013239. ACM.\nNee, R. C. 2011. The role of digitally native, nonpro\ufb01t news media\nin the future of American journalism: An exploratory study. UMI\nDissertation Publishing .Palen, L.; and Hughes, A. L. 2018. Social Media in Disaster Com-\nmunication. In Handbook of Disaster Research. Springer.\nRini, R. 2017. Fake news and partisan epistemology. Kennedy\nInstitute of Ethics Journal 27(2): E\u201343.\nShao, C.; Ciampaglia, G. L.; Flammini, A.; and Menczer, F. 2016.\nHoaxy: A Platform for Tracking Online Misinformation. WWW\n\u201916 Companion .\nShu, K.; Sliva, A.; Wang, S.; Tang, J.; and Liu, H. 2017. Fake\nnews detection on social media: A data mining perspective. ACM\nSIGKDD Explorations Newsletter 19(1): 22\u201336.\nSilverman, C. 2017. The fake news watchdog - 50 ideas blowing\nup American politics and the people behind them. https:// www.\npolitico.com/ interactives/ 2017/ politico50/ craig-silverman/ . Ac-\ncessed: 2018-09-30.\nSingal, H.; and Kohli, S. 2016. Trust necessitated through metrics:\nestimating the trustworthiness of websites. Procedia Computer Sci-\nence .\nStarbird, K. 2017. Examining the Alternative Media Ecosystem\nThrough the Production of Alternative Narratives of Mass Shooting\nEvents on Twitter. In ICWSM, 230\u2013239.\nSubramanian, S. 2017. Meet the Macedonian Teens Who Mastered\nFake News and Corrupted the US Election. Wired ISSN 1059-\n1028. URL https:// www.wired.com/ 2017/ 02/veles-macedonia-\nfake-news/ .\nTambini, D. 2017. Fake news: public policy responses. Media\nPolicy Brief .\nTandoc Jr, E. C.; Lim, Z. W.; and Ling, R. 2018. De\ufb01ning \u201cFake\nNews\u201d: A typology of scholarly de\ufb01nitions. Digital Journalism\n6(2): 137\u2013153.\nTian, L.; Zhang, X.; and Peng, M. 2020. FakeFinder: Twitter Fake\nNews Detection on Mobile. In Companion Proceedings of the Web\nConference 2020, 79\u201380.\nTimmer, J. 2016. Fighting Falsity: Fake News, Facebook, and the\nFirst Amendment. Cardozo Arts and Ent. LJ 35: 669.\nVan Zandt, D. 2018. Media Bias/Fact Check (MBFC News) About.\nhttps:// mediabiasfactcheck.com/ about/ . Accessed: 2018-09-30.\nVargo, C. J.; Guo, L.; and Amazeen, M. A. 2018. The agenda-\nsetting power of fake news: A big data analysis of the online media\nlandscape from 2014 to 2016. new media and society 20(5): 2028\u2013\n2049.\nVasu, N.; Ang, B.; Teo, T.-A.; Jayakumar, S.; Raizal, M.; and\nAhuja, J. 2018. Fake news: National security in the post-truth era.\nRSIS.\nVerstraete, M.; Bambauer, D. E.; and Bambauer, J. R. 2017. Iden-\ntifying and countering fake news. Arizona Legal Studies .\nV olovich, K. 2019. What\u2019s a Good Clickthrough Rate? New\nBenchmark Data for Google AdWords. https:// blog.hubspot.com/\nagency/ google-adwords-benchmark-data. Accessed: 2020-05-24.\nZarras, A.; Kapravelos, A.; Stringhini, G.; Holz, T.; Kruegel, C.;\nand Vigna, G. 2014. The Dark Alleys of Madison Avenue: Under-\nstanding Malicious Advertisements. ACM.\nZhauniarovich, Y .; Khalil, I.; Yu, T.; and Dacier, M. 2018. A survey\non malicious domains detection through DNS data analysis. ACM\nComputing Surveys (CSUR) 51(4): 1\u201336.\nZimdars, M. 2018. False, Misleading, Clickbait-y, and/or\nSatirical \u201dNews\u201d Sources. https:// docs.google.com/ document/ d/\n1zhaZooMfcJvk 23in201nviWJN1-LhRvGlPXJWBrPRY/ . Ac-\ncessed: 2019-09-30.\n94", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Market forces: Quantifying the role of top credible ad servers in the fake news ecosystem", "author": ["L Bozarth", "C Budak"], "pub_year": "2021", "venue": "Proceedings of the International AAAI Conference \u2026", "abstract": "Larry Lessig argues that four modes regulate behavior in cyberspace: laws, markets, norms,  and architecture. How can these four modes regulate the production and spread of fake"}, "filled": false, "gsrank": 352, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/18043", "author_id": ["", "wIhJS60AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:5oueWU4STgEJ:scholar.google.com/&output=cite&scirp=351&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=5oueWU4STgEJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 30, "citedby_url": "/scholar?cites=94032769941670886&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:5oueWU4STgEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/18043/17846"}}, {"title": "Search engines in polarized media environment: Auditing political information curation on Google and Bing prior to 2024 US elections", "year": "2025", "pdf_data": "1\nSearch\nengines\nin\npolarized\nmedia\nenvironment:\nAuditing\npolitical\ninformation\ncuration\non\nGoogle\nand\nBing\nprior\nto\n2024\nUS\nelections\nMykola\nMakhortykh*,\nTobias\nRorhbach\n1\n*,\nMaryna\nSydorova*,\nand\nElizaveta\nKuznetsova**\n*Institute\nof\nCommunication\nand\nMedia\nStudies,\nUniversity\nof\nBern,\nFabrikstrasse\n8,\n3012\nBern,\nSwitzerland\n**Research\ngroup\n\u201cPlatform\nAlgorithms\nand\nDigital\nPropaganda\u201d,\nWeizenbaum\nInstitute,\nHardenbergstra\u00dfe\n32,\n10623\nBerlin,\nGermany\nDeclaration\nof\nInterest\nstatement\nThe\nauthors\nhave\nno\ncompeting\ninterests\nthat\ncan\nbe\nreported.\nAcknowledgments\nData\ncollections\nfor\nthe\nresearch\nwere\nsponsored\nby\nthe\nFriends\nof\nthe\nInstitute\nof\nCommunication\nand\nMedia\nScience\nat\nthe\nUniversity\nof\nBern\ngrant\n\u201cAuditing\nhow\nthe\nperformance\nof\nweb\nsearch\nengines\nregarding\nrepresentation\nof\nepistemically\ncontested\npolitical\nissues\nchanges\nover\ntime\u201d\nawarded\nto\nMykola\nMakhortykh\nand\nMaryna\nSydorova\nand\nthe\nSwiss\nNational\nScience\nFoundation\ngrant\n\u201cAlgorithm\naudit\nof\nthe\nimpact\nof\nuser-\nand\nsystem-side\nfactors\non\nweb\nsearch\nbias\nin\nthe\ncontext\nof\nfederal\npopular\nvotes\nin\nSwitzerland\u201d\n(PI:\nMykola\nMakhortykh;\n105217_215021).\n1\nThe\nauthors,\nwhose\nnames\nare\nbolded,\nhave\ncontributed\nequally\nto\nthe\nstudy\ndesign\nand \nimplementation\nand\nshare\nthe\nfirst\nauthorship.\n2\nSearch\nengines\nin\npolarized\nmedia\nenvironment:\nAuditing\npolitical\ninformation\ncuration\non\nGoogle\nand\nBing\nprior\nto\n2024\nUS\nelections\nAbstract\n:\nSearch\nengines\nplay\nan\nimportant\nrole\nin\nthe\ncontext\nof\nmodern\nelections.\nBy\ncurating\ninformation\nin\nresponse\nto\nuser\nqueries,\nsearch\nengines\ninfluence\nhow\nindividuals\nare\ninformed\nabout\nelection-related\ndevelopments\nand\nperceive\nthe\nmedia\nenvironment\nin\nwhich\nelections\ntake\nplace.\nIt\nhas\nparticular\nimplications\nfor\n(perceived)\npolarization,\nespecially\nif\nsearch\nengines'\ncuration\nresults\nin\na\nskewed\ntreatment\nof\ninformation\nsources\nbased\non\ntheir\npolitical\nleaning.\nUntil\nnow,\nhowever,\nit\nis\nunclear\nwhether\nsuch\na\npartisan\ngap\nemerges\nthrough\ninformation\ncuration\non\nsearch\nengines\nand\nwhat\nuser-\nand\nsystem-side\nfactors\naffect\nit.\nTo\naddress\nthis\nshortcoming,\nwe\naudit\nthe\ntwo\nlargest\nWestern\nsearch\nengines,\nGoogle\nand\nBing,\nprior\nto\nthe\n2024\nUS\npresidential\nelections\nand\nexamine\nhow\nthese\nsearch\nengines\u2019\norganic\nsearch\nresults\nand\nadditional\ninterface\nelements\nrepresent\nelection-related\ninformation\ndepending\non\nthe\nqueries\u2019\nslant,\nuser\nlocation,\nand\ntime\nwhen\nthe\nsearch\nwas\nconducted.\nOur\nfindings\nindicate\nthat\nboth\nsearch\nengines\ntend\nto\nprioritize\nleft-leaning\nmedia\nsources,\nwith\nthe\nexact\nscope\nof\nsearch\nresults\u2019\nideological\nslant\nvarying\nbetween\nDemocrat-\nand\nRepublican-focused\nqueries.\nWe\nalso\nobserve\nlimited\neffects\nof\nlocation-\nand\ntime-based\nfactors\non\norganic\nsearch\nresults,\nwhereas\nresults\nfor\nadditional\ninterface\nelements\nwere\nmore\nvolatile\nover\ntime\nand\nspecific\nUS\nstates.\nTogether,\nour\nobservations\nhighlight\nthat\nsearch\nengines\u2019\ninformation\ncuration\nactively\nmirrors\nthe\npartisan\ndivides\npresent\nin\nthe\nUS\nmedia\nenvironments\nand\nhas\nthe\npotential\nto\ncontribute\nto\n(perceived)\npolarization\nwithin\nthese\nenvironments.\nKeywords\n:\nelections,\nUS,\nsearch\nengine,\nalgorithm\naudit,\ninformation\ncuration\nIntroduction\nSearch\nengines\nare\nkey\ninformation\ncurators\nin\ntoday\u2019s\nhigh-choice\nmedia\nenvironment.\nBy\nselecting\nand\nranking\ninformation\nsources\nin\nresponse\nto\nuser\nqueries,\nsearch\nengine\nalgorithms\nhelp\nindividuals\nworldwide\nnavigate\nthe\nabundance\nof\ninformation\non\ntopics\nranging\nfrom\nhealth\n(Bragazzi\net\nal.,\n2017)\nto\nhistorical\natrocities\n(Makhortykh\net\nal.,\n2022)\nto\nelections\n(Trielli\n&\nDiakopoulous,\n2022).\nThe\nease\nof\nuse\nand\napplicability\nfor\ndifferent\ntypes\nof\ninformation-seeking\nbehavior,\ntogether\nwith\nthe\nperceived\nreliability\nof\nsearch\noutputs,\nmake\nsearch\nengines\nhighly\ntrusted\ninformation\nsources\n(Schulthei\u00df\n&\nLewandowski,\n2023).\nAs\na\nresult,\nsearch\nengines\nare\nused\nby\nindividuals\nto\nstay\ninformed\nabout\nimportant\nsocietal\ndevelopments\nand\nplay\nan\nimportant\nrole\nin\nnews\nexposure\nand\ndiscovery\n(Nielsen,\n2016).\nDue\nto\ntheir\nsocietal\nrelevance,\nsearch\nengines\nincreasingly\ncome\nunder\nscrutiny\nover\nthe\nquality\nof\ninformation\nsources\nthey\nexpose\ntheir\nusers\nto\nand\nthe\nfactors\nthat\naffect\nsuch\nexposure\n2\n.\nMany\nof\nthese\nstudies\nfocus\non\nwhether\nsearch\nengines\u2019\nperformance\nis\nprone\nto\n2\nThe\nimportance\nof\nsearch\nengines\nhas\nbeen\nreflected\nin\nthe\nrapidly\ngrowing\nbody\nof\nresearch\non \nalgorithmic\ninformation\ncuration\nand\nits\nimplications\nfor\ninformation\nexposure.\nThese\nstudies\ndiffer\nin \ntheir\nmethodological\napproaches,\nwhich\nrange\nfrom\nalgorithm\naudits\n(Unkel\n&\nHaim,\n2021;\nTrielli\n& \nDiakopoulous,\n2022;\nUrman\net\nal.,\n2022a)\nto\ndata\ndonation-\nand\nwebtracking-based\nstudies\n(Blassnig\n3\nalgorithmic\nbias,\nwhich\ncan\nbe\ndefined\nas\na\ntendency\nto\nproduce\noutputs\nthat\nare\nsystematically\nskewed\ntoward\nthe\nviewpoints\nor\ninterests\nof\nspecific\nsocial\ngroups\n(\nFriedman\n&\nNissenbaum,\n1996\n).\nWhile\nit\ncan\nbe\ndebated\nto\nwhat\ndegree\nsearch\nengines\ncan\nbe\nimpartial,\nconsidering\nthe\nexistence\nof\nmultiple\nforms\nof\nsocial\nbias\nand\ntechnological\nlimitations\nin\ntackling\nthem,\nengines\u2019\nreiteration\nand\namplification\nof\nbiased\nrepresentations\nof\nsocial\nreality\ncan\nresult\nin\nmany\nsocietal\nharms.\nExamples\nof\nsuch\nharms\nvary\nfrom\nthe\npropagation\nof\ndiscriminatory\nrepresentations\nof\nsocial\ngroups\n(Noble,\n2018;\nUrman\n&\nMakhortykh,\n2024)\nto\nthe\nexposure\nof\nsearch\nengine\nusers\nto\nfalse\ninformation\n(Kuznetsova\net\nal.,\n2024).\nThe\nrisks\nassociated\nwith\nsearch\nengines\nare\namplified\nby\nthe\ngrowing\nsocietal\npolarization\nthat\ncharacterizes\nmany\nmodern\nliberal\ndemocracies.\nWhile\nthe\nexact\nscope\nof\npolarization\nremains\ndebated\nby\nscholars,\nthere\nexists\ngrowing\nevidence\nthat\npolitics\nare\nincreasingly\nperceived\nas\na\nhighly\npolarising\nsubject.\nSuch\na\nperception\nmay\nbe,\nto\na\nlarge\nextent,\nshaped\nby\nthe\nevolving\npolitical\nand\nmedia\nlandscape\nthat\namplifies\npartisanship\nand\ncontributes\nto\n\u201ca\nself-perpetuating\ncycle\u201d\n(Wilson\net\nal.,\n2020:\n223)\nof\nrising\npolarization.\nConsidering\nthat\nby\ndesign,\nsearch\nengine\nalgorithms\ntreat\ntheir\nusers\nin\na\ndifferentiated\nmanner\nto\nbetter\nadapt\nsearch\noutputs\nto\ntheir\nneeds\n(e.g.,\nbased\non\nuser\nlanguage\nor\nlocation),\nit\noften\nleads\nto\nspecific\npopulation\ngroups\npotentially\nbeing\nexposed\nto\ndifferent\ninterpretations\nof\nthe\nsame\nsocietal\nissue\n(Makhortykh\net\nal.,\n2024a).\nThis\nmakes\nsearch\nengines\u2019\ninformation\ncuration\nan\nimportant\nfactor\nthat\ncan\npotentially\namplify\n(perceived)\nsocietal\npolarization,\nin\nparticular\nin\nalready\npolarised\nmedia\nenvironments.\nThe\nrelationship\nbetween\nsearch\nengines\nand\npolarization\nis\nof\nparticular\nimportance\nin\nthe\ncontext\nof\nelections.\nEarlier\nstudies\nhave\nindicated\nthat\ninformation\ncuration\nby\nsearch\nengines\ncan\naffect\nvoter\npreferences\nby\nshifting\ntheir\nusers\u2019\nopinions\nabout\nwhom\nto\nvote\nfor\n(Epstein\n&\nRobertson,\n2015;\nRohrbach\net\nal.,\n2024).\nUnder\nthese\ncircumstances,\nbiased\nrepresentation\nof\nelection-related\ninformation,\nfor\ninstance,\nin\nthe\nform\nof\nexposure\nof\ncertain\ngroups\nof\nvoters\nto\ninformation\nsources\nwith\na\nparticular\nideological\nslant,\ncan\nhave\nimplications\nfor\nvoting\nbehavior.\nHowever,\nempirical\nresearch\non\nsearch\nengines\u2019\ninformation\ncuration\nand\nits\npotential\nbiases\nin\nthe\ncontext\nof\nelections\nremains\nlimited\nand\noften\nproduces\ncontradictory\nresults\n(e.g.,\nDiakopoulos\net\nal.,\n2018;\nUnkel\n&\nHaim,\n2021).\nSimilarly,\nthe\neffects\nof\ndifferent\nfactors\naffecting\ninformation\ncuration\n(and\nits\npotential\nbiases),\nsuch\nas\nuser\nlocation\nof\nchanges\nin\nsource\nrelevance,\nremain\nunder-studied.\nTo\naddress\nthese\ngaps,\nwe\nexamine\nhow\nthe\ntwo\nlargest\nWestern\nsearch\nengines,\nGoogle\nand\nBing,\ncurated\npolitical\ninformation\nprior\nto\nthe\n2024\nUS\nelections.\nOur\ninterest\nin\nthe\nUS\ncontext\nis\ndue\nto\nit\nconstituting\none\nof\nthe\nmost\npolarised\nmedia\nenvironments\namong\nliberal\ndemocracies\ntogether\nwith\na\nparticularly\nhigh\ndegree\nof\ninternet\npenetration\nand\nsearch\nengine\nuse.\nUsing\nvirtual\nagent-based\nalgorithm\naudits,\nwe\nexamine\nhow\nthe\npresence\nof\nspecific\ntypes\nof\npolitical\ninformation\nsources\nis\naffected\nby\nuser-\n(the\nuse\nof\nideologically\nslanted\nand\nnon-slanted\nsearch\nqueries)\nand\nsystem-side\nfactors\n(user\nlocation\nand\ntime-based\nchanges\nin\nsearch\nrelevance).\nSpecifically,\nwe\nfocus\non\ninformation\ncuration\nof\njournalistic\nmedia\nwith\ndifferent\npolitical\nleaning\nin\norganic\nsearch\nresults\nand\nother\nelements\net\nal.,\n2023;\nvan\nHoof\net\nal.,\n2024)\nto\nthe\nself-reported\nassessments\n(Zumofen,\n2024;\nVziatysheva\net \nal.,\n2024).\n4\nof\nsearch\ninterface\n(e.g.,\nNewsblock\nfor\nGoogle)\ndue\nto\njournalistic\nmedia\nbeing\nthe\nmost\ncommon\ntype\nof\nelection-related\nsearch\nresults.\nThe\nrest\nof\nthe\npaper\nis\norganized\nas\nfollows:\nfirst,\nwe\nbriefly\nreview\nrelated\nwork\non\nthe\nrole\nof\nsearch\nengines\nin\nthe\ncontext\nof\npolarization\nand\nin\nthe\ntime\nof\nelections,\ntogether\nwith\nthe\nimpact\nof\nuser-\nand\nsystem-side\nfactors\naffecting\ntheir\nperformance\nand\nformulate\nour\nresearch\nquestions\nand\na\nhypothesis.\nThen,\nwe\nintroduce\nthe\nmethodology\nused\nto\nconduct\nthe\nalgorithm\naudits\nand\nto\nanalyze\nthe\ncollected\ndata.\nAfter\nthat,\nwe\npresent\nour\nfindings\nregarding\ndifferences\nin\nthe\nselection\nof\nsources\nand\ntheir\nideological\nleaning\ndepending\non\nthe\nslant\nof\nthe\nquery\nand\nthe\nimpact\nof\nsearch\nlocation\nand\ntime-based\nchanges.\nFinally,\nwe\nconclude\nwith\na\ndiscussion\nof\nthe\nimplications\nof\nour\nfindings,\ntogether\nwith\nthe\nlimitations\nof\nthe\ncurrent\nstudy\nand\ndirections\nfor\nfuture\nresearch.\nSearch\nengines,\npolitical\ninformation\ncuration,\nand\npolarization\nThe\nway\nin\nwhich\ncitizens\nin\ndifferent\ncountries\ninform\nthemselves\nabout\npolitics\nis\ndetermined\nby\nmedia\nenvironments.\nThese\nenvironments\nhave\nbeen\ntraditionally\nshaped\nby\nfactors\nsuch\nas\nmedia\nregulation,\njournalistic\nculture,\nand\nthe\ninterplay\nof\nvarious\nmedia\nforms\n(Hoskins\n&\nTulloch,\n2016).\nWith\nthe\nrise\nof\ndigital\nplatforms\nand\nthe\nexpansion\nof\nthe\nchannels\nthrough\nwhich\nindividuals\nare\nexposed\nto\npolitical\ninformation,\nmedia\nenvironments\nhave\nundergone\na\nseries\nof\nfundamental\nchanges.\nOne\nparticular\nchange\nthat\nwe\nfocus\non\nin\nthis\npaper\nconcerns\nthe\nincreasing\nimpact\nof\nalgorithmic\ninformation\ncuration\nsystems\non\nmedia\nenvironments\nand\npolitical\ninformation\nexposure\nwithin\nthem.\nBy\n\u201corganizing,\nselecting\nand\npresenting\nsubsets\nof\na\ncorpus\nof\ninformation\u201d\n(Rader\n&\nGray,\n2015:\n173),\ninformation\ncuration\nsystems\ninfluence\nhow\nindividuals\nare\nexposed\nto\ncertain\ninformation\nsources\nand\nopinions.\nExamples\nof\nsuch\nsystems\nrange\nfrom\ncontent\nrecommenders\nused\nby\nsocial\nmedia\nand\nlegacy\nmedia\nto\nAI-powered\nchatbots\nsuch\nas\nGemini\nto\nsearch\nengines\nsuch\nas\nGoogle\nand\nBing.\nThe\nemergence\nof\ninformation\ncuration\nsystems\nhas\nmultiple\nimplications\nfor\npolitical\ninformation\nexposure.\nSuch\nsystems\ncan\nenable\nnon-intentional\n-\nor\nincidental\n(Thorson,\n2020)\n-\nexposure\nto\npolitical\ninformation\nthrough\n(often\nnon-transparent)\ncuration\ndecisions\nand\nfacilitate\nselective\nexposure\nto\ncontent\naligning\nwith\nusers\u2019\npre-existing\nbeliefs.\nAiming\nto\nguide\nusers\ntowards\ninformation\nthat\nis\nrelevant\nto\ntheir\ninterests,\ncuration\nsystems\ncustomize\ntheir\nresults\nto\nmeet\nthe\ninformation\nneeds\nof\nindividual\nusers.\nIn\nthe\ncase\nof\npolitical\ninformation,\nsuch\ncustomization\nmay\nresult\nin\nthe\nreinforcement\nof\npre-existing\nideological\nbeliefs\nand\nthe\nisolation\nof\nusers\nin\npersonalized\ninformation\nbubbles\n(Borgesius\net\nal.,\n2016).\nWhile\nempirical\nevidence\nof\nsuch\nbubbles\nremains\ninconclusive\n(Bruns,\n2019),\nsuch\na\nperspective\nis\nconcerning\nin\nthe\ncontext\nof\ndemocratic\ndecision-making\nas\nit\ncan\nundermine\npolitical\nparticipation\nand\ncontribute\nto\nsocietal\npolarization.\nThe\ndiscussion\nof\nrisks\nof\ninformation\ncuration\nin\nthe\ncontext\nof\npolarization\nhas\nbeen\nlargely\nfocused\non\npersonalized\ncontent\nfeeds\non\nsocial\nmedia\nplatforms\n(Yang\net\nal.,\n2023)\nand\nautomated\nnews\nrecommendations\nused\nby\nlegacy\nmedia\n(Ludwig\net\nal.,\n2023).\nThe\nrole\nof\n5\nsearch\nengines\nin\nthis\nprocess\nhas\nbeen\nlargely\nomitted\nfrom\nthe\ndiscussion\ndespite\ntheir\nextensive\nuse\naround\nthe\nworld,\ntogether\nwith\ngrowing\nevidence\nof\nalgorithmic\nbias\naffecting\nhow\nsearch\nengines\ncurate\npolitical\ninformation\n(e.g.,\nPradel,\n2021).\nPartially,\nsuch\nomittance\ncan\nbe\nattributed\nto\nthe\nlimited\nevidence\nof\nindividual-based\npersonalization\nof\nsearch\nengine\nresults\n(e.g.,\nPuschmann,\n2019)\nas\ncontrasted\nby\nmore\naggressive\npersonalization\nused\nby\nother\ncuration\nsystems.\nHowever,\nless\naggressive\nindividual\npersonalization\ndoes\nnot\nfully\nexclude\nthe\npossibility\nof\nsearch\nengines\ncontributing\nto\nthe\nskewed\nexposure\nto\ninformation,\nfor\ninstance,\ndepending\non\nthe\nlanguage\nthat\nspecific\ngroups\nuse\nfor\nsearch\nqueries\nor\ngeography-based\nsearch\nlocalization.\nIn\nturn,\nsuch\nskewness\ncan\ncontribute\nboth\nto\nthe\ndivisive\nunderstanding\nof\nsocietal\nphenomena,\nwhich\nare\nrepresented\nby\nsearch\nengines,\nand\na\nmore\npolarized\nperception\nof\nmedia\nenvironments\nwhere\nsearch\nengines\nfunction.\nUnderstanding\nhow\nsearch\nengines\nshape\nmedia\nenvironments\nand\nindividual\nperceptions\nof\nthese\nenvironments\nis\nparticularly\nimportant\nduring\npolitical\nevents\nsuch\nas\nelections.\nA\nnumber\nof\nstudies\nshow\nthat\nsearch\nengines\nserve\nas\nessential\nentry\npoints\nfor\ninformation\nabout\npolitics\n(e.g.,\nDutton\n&\nReisdorf,\n2017).\nConsidering\nthe\nfundamental\nconnection\nbetween\ninformedness\nand\ncitizens\u2019\nability\nto\nparticipate\nin\npolitical\ndecision-making,\ninformation\ncuration\non\nsearch\nengines\nbecomes\nan\nimportant\nfactor\nin\nthe\nelectoral\nprocess\ndue\nto\nit\ndetermining\nhow\nindividuals\nare\nexposed\nto\ninformation\nthat\ncan\ninfluence\ntheir\nvoting\ndecisions.\nDifferent\nforms\nof\nalgorithmic\nbias\nassociated\nwith\nsuch\ncuration\ncan\nact\nas\nconduits\nof\nactual\nand\nperceived\nbiases\nof\nusers\u2019\nmedia\ndiet\n(Robertson\net\nal.,\n2023),\nresulting\nin\nan\neven\nmore\npolarised\nperception\nof\nelectoral\nmatters\nand\ntheir\nrepresentation\nby\nmedia\noutlets.\nConsequently,\nby\ncontributing\nto\nthe\n(perceived)\nskewness\nof\nmedia\nenvironments,\nsearch\nengines\ncan\nserve\nas\nan\noverlooked\ndriver\nof\npolarization\nin\nthe\ncontext\nof\nelections\n(for\na\nreview\nof\nthis\nargument,\nsee\nKubin\n&\nVon\nSikorski,\n2023).\nThe\nimportance\nof\nthe\nrelationship\nbetween\nsearch\nengines,\npolitics,\nand\npolarization\nis\nreflected\nin\na\ngrowing\nvolume\nof\nstudies\nthat\nlook\nat\nhow\nsearch\nengines\ncurate\npolitical\ninformation\nin\nthe\ncontext\nof\nelections.\nThese\nstudies\ncan\nbe\ngrouped\ninto\nthree\nmain\ncategories.\nThe\nfirst\ncategory\nlooks\nat\nthe\nimpact\nof\ninformation\ncuration\non\nvoting\nbehavior\nand\ntackles\nissues\nsuch\nas\nthe\nsearch\nengine\nmanipulation\neffect\n(Epstein\n&\nRobertson,\n2015)\nand\nthe\neffects\nof\nalgorithmic\nbias\non\ncandidates\u2019\nelectability\n(Rohrbach\net\nal.,\n2024).\nThe\nsecond\ncategory\nfocuses\non\nthe\nrepresentation\nof\npolitical\nactors\nby\nsearch\nengines\nand\nwhether\nsuch\nrepresentation\ncan\nbe\nprone\nto\ndifferent\nforms\nof\nbias\n(e.g.,\ngender\nbias;\nPradel,\n2021;\nRohrbach\net\nal.,\n2024).\nFinally,\nthe\nthird\ncategory\nexamines\nhow\nsearch\nengines\ncurate\ninformation\nin\nthe\ncontext\nof\nelections,\nwhat\nfactors\naffect\nsuch\ncuration,\nand\nwhether\nit\nresults\nin\nthe\nexposure\nof\nindividuals\nto\nideologically\nslanted\nsources\n(Robertson\net\nal.,\n2023;\nTrielli\n&\nDiakopoulos,\n2022;\nUrman\net\nal.,\n2022a).\nThe\nlatter\ngroup\nof\nstudies\nis\nparticularly\nrelevant\nfor\nunderstanding\nthe\nimplications\nof\npolitical\ninformation\ncuration\non\nsearch\nengines\nfor\npolarised\nmedia\nenvironments.\nThe\nfindings\nof\nthese\nstudies,\nhowever,\nremain\ninconclusive.\nSome\nof\nthem\nhighlight\nthe\ntendency\nof\nsearch\nengines\nto\nexpose\nusers\nto\nmore\nmainstream\ninformation\nsources\nand\ninterpretations\n(e.g.,\nUnkel\n&\nHaim,\n2021;\nTrielli\n&\nDiakopoulous,\n2022),\nwhereas\nothers\nshow\nthat\nsearch\nengines\ncurate\ninformation\nin\na\nway\nthat\nleads\nto\nthe\nideologically\nslanted\nselection\nof\nsources\n(Diakopoulous\net\nal.,\n2018).\nOne\nof\nthe\nreasons\nfor\nthese\ndivergent\nassessments\ncan\nbe\nthat\nsearch\nengine\noutputs\nare\nshaped\nby\nmultiple\nfactors\nthat\nare\ndifficult\nto\naccount\nfor\nsystematically.\nTo\naddress\nthis\nchallenge,\nwe\nintroduce\na\nframework\nof\n6\nuser-\nand\nsystem-side\nfactors\naffecting\nsearch\nengine\noutputs\nand\ndiscuss\nhow\nthey\ncan\ninfluence\ninformation\ncuration\non\nsearch\nengines\nin\nthe\ncontext\nof\nelections.\nUser-side\nfactors\nof\npolitical\ninformation\ncuration\non\nsearch\nengines\nA\nmajor\nchallenge\nof\nstudying\nsearch\nengines\u2019\npolitical\ninformation\ncuration\nrelates\nto\nits\nhighly\ncomplex\nand\nnon-transparent\nnature\n(Castillo,\n2019).\nTo\nidentify\nthe\nmost\nrelevant\nset\nof\ninformation\nsources\nin\nresponse\nto\nuser\nqueries,\nsearch\nengine\nalgorithms\ntake\ninto\nconsideration\nmany\nfactors,\nincluding\nthe\npresence\nof\nmeta\ntags,\nsource\nrecency,\nthe\nstructure\nof\nURLs,\nand\nthe\nmobile-friendliness\nof\nthe\nsource\u2019s\nwebsite.\nNot\nonly\nthe\ncomposition\nand\nweight\nof\nfactors\ndetermining\nindividual\nsearch\noutputs\nis\nunclear,\nbut\nthese\nfactors\u2019\nimportance\nvaries\nbetween\nsearch\nengines.\nFor\ninstance,\nthe\nranking\nalgorithm\nfor\norganic\nsearch\nresults\non\nGoogle\nis\nassumed\nto\ngive\nmore\npreference\nto\nrelevance\nand\ndiversity\nof\ndomains\nthat\nlink\nto\nthe\nweb\npage\nin\nquestion\nas\nwell\nas\nauthoritativeness\nof\nthe\ndomain\nassociated\nwith\nthe\nwebpage,\nwhereas\nfor\nBing,\nmore\nemphasis\nis\nplaced\non\nthe\ncontent\nreadability\nand\nfreshness\n(Wilkinson,\n2023).\nWhile\nthe\nabove-mentioned\nfactors\nplay\nan\nimportant\nrole\nin\ndetermining\nwhat\ninformation\nis\nretrieved\nby\nsearch\nengine\nalgorithms,\ninformation\ncuration\nis\nalways\ndependent\non\nusers\u2019\ninput.\nSearch\nengine\nresults\nare,\ntherefore,\nprofoundly\naffected\nby\na\nnumber\nof\nuser-side\nfactors,\nranging\nfrom\nthe\ntopics\nof\nsearch\nqueries\nand\ntheir\nexact\nformulations\nto\nthe\nquery\nlanguage\nor\nthe\nuse\nof\nsearch\noperators\nsuch\nas\n\u201csite:\u201d.\nAmong\nthese\nfactors,\nmost\nresearch\nto\ndate\nfocused\non\nthe\nimpact\nof\nquery\nselection\non\nsearch\nengine\noutputs\nand\nidentified\nstrong\nvariation\nin\nsearch\nresults\nregarding\ntopics\nranging\nfrom\nmigration\n(Norocel\n&\nLewandowski,\n2023)\nto\nconspiracy\ntheories\n(Urman\net\nal.,\n2022b)\ndepending\non\nqueries\u2019\nfocus.\nSuch\nvariation\ncauses\nthe\nrisk\nof\nindividuals\nbeing\nexposed\nto\nfundamentally\ndifferent\ninterpretations\nof\nthe\nsame\nissue\nbased\non\nthe\nqueries\u2019\nformulations,\nespecially\nif\nsearch\nresults\nare\nsystematically\nskewed\ntowards\na\nspecific\nviewpoint\n(e.g.,\nanti-migration\nopinions\nfor\nmore\nright-leaning\nqueries;\nNorocel\n&\nLewandowski,\n2023)\nand\nminimize\nexposure\nto\nalternative\nviewpoints.\nIn\nturn,\nsuch\nskewed\nexposure\ncan\ncontribute\nto\nthe\nperceived\npolarization\nof\na\nmedia\nenvironment\nwhere\nthe\nsearch\nis\noccurring.\nIn\nthe\ncase\nof\nelection-related\ninformation\ncuration,\nthe\ndiscussion\nof\nthe\nrole\nof\nuser-side\nfactors\nhas\nlargely\nfocused\non\nhow\ndiverse\nor\nhomogeneous\nis\nthe\nselection\nof\nsources\nin\nresponse\nto\nqueries\nwith\ndifferent\nthematic\nfoci\n(Unkel\n&\nHaim,\n2021;\nTrielli\n&\nDiakopoulous,\n2022).\nThe\nimportance\nof\nthis\nissue\nis\nattributed\nto\nevidence\nof\nsearch\nengines\u2019\ninformation\ncuration\naffecting\nvoter\npreferences\n(Epstein\n&\nRobertson,\n2015)\nand\nthe\npossible\nvariation\nin\nthis\neffect\nbased\non\ndifferent\nsearch\nqueries.\nFor\ninstance,\nif\nfor\nqueries\nregarding\ncertain\ncandidates,\nsearch\nresults\nare\nmore\nlikely\nto\ninclude\nsources\npromoting\nthe\nposition\nof\nthe\ncandidate\n(while\nnot\nnecessarily\ndoing\nit\nfor\nother\ncandidates),\nit\nmay\nresult\nin\ndifferent\ninformation\nexposure\nthat,\nin\nturn,\nmay\nhave\nimplications\nfor\nvoting\nbehavior\n(e.g.,\ndue\nto\ndifferent\nlevels\nof\nelectorate\u2019s\nmobilization).\nSuch\na\nrisk\nhas\nbeen\namplified\nby\nthe\nincreasing\nuse\nof\nsearch\nengines\nfor\npolitical\nmicrotargeting\n(Dobber,\n2023),\nwhich\nmay\nfurther\ncontribute\nto\nunequal\ninformation\nexposure.\n7\nIn\naddition\nto\naffecting\nvoting\nbehavior,\nskewed\nexposure\nto\ninformation\ndue\nto\nuser-side\nfactors\ncan\naffect\nhow\nsearch\nengine\nusers\nperceive\nmedia\nenvironments\nin\nwhich\nthe\nelections\nare\nhappening\nand\nthe\ndegree\nof\npolarization\ntherein.\nFor\ninstance,\nif\nan\nindividual\nsearches\nfor\ninformation\nabout\nthe\ncandidate\nthey\nsupport\nand\nmost\nresults\ncome\nfrom\nresources\ncritical\nto\nthe\ncandidate,\nan\nindividual\ncan\nperceive\nit\nas\nevidence\nof\nmedia\npolarization,\nespecially\nif\nsuch\nskewness\nis\nsystematic.\nThe\ndegree\nto\nwhich\nsearch\nengine\nperformance\nis\nskewed\nregarding\nelection-related\ninformation,\nhowever,\nremains\ncurrently\nunclear.\nTrielli\nand\nDiakopoulos\n(2022)\nshowed\nfor\nthe\nUS\ncontext\nthat\ndespite\ndifferences\nin\nthe\nquery\nselection\nbetween\nDemocratic\nand\nRepublican\nvoters,\nGoogle\norganic\nsearch\nresults\nconsist\nof\na\nsimilar\nselection\nof\nsources\nthat\ntends\ntowards\nmainstream\nand\ncentrist\ninterpretations.\nUrman\net\nal.\n(2022a),\nin\na\nstudy\nof\nsearch\nresults\nregarding\nUS\npresidential\ncandidates,\nfound\na\nstrong\nhomogeneity\nof\nGoogle\nsearch\nresults,\nwhich\nwere\ndominated\nby\njournalistic\nmedia.\nSimilarly,\nNechushtai\net\nal.\n(2024)\nobserved\nthe\ntendency\nof\nGoogle\nto\nprioritize\na\nsimilar\nselection\nof\nsources\nfor\nqueries\nwith\ndifferent\nideological\nslant.\nAt\nthe\nsame\ntime,\nother\nstudies\ndemonstrate\nthat\ndepending\non\nthe\nsearch\nquery,\nsearch\nengines\ncan\nprioritize\nrather\ndifferent\ninformation\nsources,\nresulting\nin\nskewed\nexposure\nto\nelection-related\ninformation.\nUrman\net\nal.\n(2022a)\nobserved\nthat,\nunlike\nGoogle,\nBing\ntends\nto\nreturn\nnon-homogenous\nresults\nfor\nqueries\nregarding\nindividual\ncandidates,\nincluding\na\nhigher\npresence\nof\nsources\nassociated\nwith\ncandidates\u2019\ncampaigns\nfor\ncertain\nindividuals.\nUnkel\nand\nHaim\n(2021),\nin\ntheir\nstudy\non\nthe\nGerman\nfederal\nelections,\nnoted\nvariation\nin\nthe\nselection\nof\nsources\nby\nGoogle\ndepending\non\nthe\nsearch\norientation\nof\nthe\nusers\n(e.g.,\ninterest\nin\nindividual\npoliticians\nor\nspecific\nissues).\nWhile,\naccording\nto\nthe\nstudy,\njournalistic\nmedia\nprevailed\nin\nsearch\nresults,\nqueries\nassociated\nwith\nspecific\norientations\nresulted\nin\nfluctuations\nin\nthe\nranking\nof\nother\ntypes\nof\nsources,\nincluding\nthe\nvarying\npresence\nof\nspecific\nparties\u2019\nwebsites.\nSimilarly,\nSchwabl\net\nal.\n(2023),\nin\ntheir\nstudy\nof\nthe\n2021\nfederal\nelections\nin\nGermany,\nobserved\nsubstantial\nvariation\nin\nthe\nselection\nof\nsources\ndepending\non\nthe\npolitical\nparty\non\nwhich\nthe\nquery\nhas\nbeen\nfocusing.\nAt\nthe\ntime\nof\nwriting\n(i.e.,\nwinter\n2024-2025),\nthere\nis\na\nlack\nof\nstudies\nregarding\nthe\nrole\nof\nsearch\nengines\nin\nthe\nmedia\nenvironment\nduring\nthe\n2024\nUS\npresidential\nelections.\nHowever,\nunderstanding\nthis\nrole\nis\nimportant,\nconsidering\nthe\nhigh\ndegree\nof\n(perceived)\npolarization\nthat\ncharacterizes\nthe\nUS\n(Wilson\net\nal.,\n2020)\nand\nthe\ngrowing\nimpact\nof\nsocietal\npolarization\non\nelections\nworldwide,\nin\nparticular\nregarding\nthe\ngrowing\nappeal\nof\npopulist\nparties\nthat\nis\noften\nunderpinned\nby\npolarization\nwithin\nspecific\nsocieties.\nIn\nthe\nUS\ncase,\nthere\nhave\nbeen\nanecdotal\nobservations\nthat\nthe\nrepresentation\nof\nelection-related\ninformation\nhas\nbeen\nskewed\nin\nthe\ncase\nof\nsearch\nengines\n(e.g.,\ndue\nto\nhigher\nvisibility\nof\nleft-leaning\nmedia;\nKang,\n2024),\nbut\nsuch\nclaims\nwere\nnot\nsystematically\ntested.\nTo\nassess\nthe\nvalidity\nof\nthese\narguments\nand\ncontribute\nto\na\nbetter\nunderstanding\nof\nthe\nimpact\nof\nuser-side\nfactors\non\ninformation\ncuration\nin\nthe\ncontext\nof\nelections,\nwe\ninvestigate\nwhether\nand\nhow\nsearch\nqueries\nwith\na\npartisan\nfocus\u2014that\nis,\nqueries\nfocusing\non\nRepublican\nor\nDemocratic\ncandidates\n(vs.\nneutral\nkeywords\u2014result\nin\nsystematic\ndifferences\nregarding\nthe\ntypes\nof\nsources\nprioritized\nin\nsearch\noutputs.\nAs\na\nfirst\nstep,\nwe\nformulate\nthe\nfollowing\nresearch\nquestion:\nRQ1\n:\nWhat\ntypes\nof\nsources\nare\nprioritized\nby\nsearch\nengines\nduring\nthe\n2024\nUS\nelections\nin\nresponse\nto\nDemocratic-focused,\nRepublican-focused,\nand\nneutral\nqueries?\n8\nSecondly,\nwe\nwant\nto\nunderstand\nwhether\nthe\nselection\nof\ninformation\nsources\nby\nsearch\nengines\nreflects\nthe\nideological\nslant\nof\nthe\nsearch\nquery.\nSpecifically,\nwe\nfocus\nhere\non\nthe\nsubset\nof\ndata\nregarding\nsearch\nresults\ncoming\nfrom\nmedia\nsources,\nwhich\nwe\nexpect\nto\nconstitute\nthe\nmajority\nof\nresults\nbased\non\nearlier\nstudies\n(e.g.,\nUnkel\n&\nHaim,\n2021;\nUrman\net\nal.,\n2022)\nand\nfor\nwhich\nit\nis\neasier\nto\nidentify\nan\nideological\nleaning\n(as\ncontrasted\nwith,\nfor\ninstance,\nmost\nsocial\nmedia\nplatforms).\nThe\nprioritization\nof\nmedia\nwith\nideological\nslant\naligning\nwith\nthe\nslant\nof\na\nquery\n(e.g.,\nleft-leaning\nmedia\nin\nthe\ncase\nof\nDemocratic-focused\nqueries)\ncan\ncontribute\nto\nthe\n(perceived)\npolarization\nof\na\nmedia\nenvironment\nduring\nthe\n2024\nelections.\nTo\ntest\nthis\nexpectation,\nwe\nformulate\nthe\nfollowing\nhypothesis:\nH1\n:\nSearch\nengine\nresults\nshow\n(a)\nhigher\nshare\nof\nleft-leaning\nmedia\nsources\nfor\nDemocratic-focused\nqueries\nand\n(b)\nhigher\nshares\nof\nright-leaning\nqueries\nfor\nRepublican-focused\nqueries.\nSystem-side\nfactors\nof\npolitical\ninformation\ncuration\non\nsearch\nengines\nBesides\nuser-side\nfactors,\nsuch\nas\nthe\nchoice\nof\na\nsearch\nquery,\npolitical\ninformation\ncuration\non\nsearch\nengines\nis\nshaped\nby\nthe\nselection\nof\nsystem-side\nfactors.\nConceptually,\nsystem-side\nfactors\nare\nfactors\noutside\nthe\nusers\u2019\ncontrol\nthat\ncan\nbe\nseen\nas\nmoderating\nthe\noutcome\nof\ninformation-seeking\nbehavior.\nThese\nare\nmultiple\nsystem-side\nfactors,\nincluding\nthe\nrandomization\nof\nresults\nfor\nthe\nsame\nqueries,\nwhich\nis\nused\nfor\nreal-time\nA/B\ntesting\n3\non\nsearch\nengines\n(Makhortykh\net\nal.,\n2020),\nthe\ncustomization\nof\nsearch\nresults\nbased\non\nthe\nuser\nlocation\n(Kliman-Silver\net\nal.,\n2015)\nor\nresults\u2019\npersonalization\nbased\non\nuser\nsearch\nbehavior\n(Hannak\net\nal.,\n2013).\nBecause\nit\nis\nhardly\npossible\nto\naccount\nfor\nthe\neffect\nof\nall\npossible\nsystem-side\nfactors,\nwe\nspecifically\nfocus\non\nthe\ntwo\nprominent\nfactors\nin\ninformation\ncuration:\nuser\nlocation\nand\nsource\nrelevance.\nSearch\nlocalization\nis\none\nof\nthe\ncore\nfunctionalities\nof\nsearch\nengines\nwhich\nincreases\nthe\nrelevance\nof\nsearch\nresults\nby\nadapting\nthem\nto\nthe\nplace\nfrom\nwhere\nthe\nuser\nis\nsearching\nfor\ninformation.\nA\nnumber\nof\nstudies\n(e.g.,\nBallatore\net\nal.,\n2017;\nUrman\n&\nMakhortykh,\n2024;\nKuznetsova\net\nal.,\n2024)\nlooked\nat\nthe\nimplications\nof\nsearch\nlocalization\nfor\nrepresenting\ndifferent\nsocietal\nphenomena.\nBallatore\net\nal.\n(2017)\ndemonstrated\nthat\nusers\nfrom\nhigher-income\ncountries\nare\nmore\nlikely\nto\nhave\nlocalized\nsources\ncompared\nwith\nusers\nfrom\nlow-income\ncountries,\nparticularly\nregarding\ngeography-related\nrequests.\nUrman\nand\nMakhortykh\n(2024)\nshowed\nthat\nuser\nlocation\nhas\na\nsubstantive\nimpact\non\nexposure\nto\ngender-discriminatory\nadvertisements\nwhen\nsearching\nfor\ninformation\nabout\ngender\nand\nnational\ngroups.\nFinally,\nKuznetsova\net\nal.\n(2024)\nfound\nthat\nuser\nlocation\nis\nan\nimportant\nfactor\nin\ndetermining\nexposure\nto\ninformation\nsources\nthat\npromote\ndisinformation\nregarding\nRussia\u2019s\nwar\nin\nUkraine.\nRelatively\nlittle\nresearch,\nhowever,\nhas\nbeen\ndone\non\nthe\neffects\nof\nsearch\nlocation\non\nelection-related\ninformation,\nin\nparticular\nthe\nvariation\nin\nthe\nsource\nselection\non\nthe\nregional\n3\nA/B\ntesting\nis\na\nform\nof\ncontrolled\nexperiment,\nwhere\nindividuals\nare\nexposed\nto\none\nof\ntwo \nexperimental\nconditions.\nIn\nthe\ncontext\nof\nsearch\nengines,\nA/B\ntests\ncan\nbe\napplied\nto\ncompare\nthe \neffects\nof\nsource\nselection\nand\nranking\nstrategies\non\nuser\nengagement\nwith\nsearch\nresults.\n9\n(and\nnot\ncross-country)\nlevel.\nKliman-Silver\net\nal.\n(2015)\nobserved\nthat\nqueries\ndealing\nwith\npoliticians\u2019\nnames\ntrigger\nrelatively\nlittle\nlocalization,\nwhereas\nqueries\nreferring\nto\npolitics-related\nconcepts\nresult\nin\nmore\nlocal\nresults.\nRohrbach\net\nal.\n(2024)\nanalyzed\nhow\nqueries\nin\ndifferent\nlanguages\nused\nfrom\ndifferent\nlocations\nresult\nin\nvarying\ndegrees\nof\nrepresentation\nof\nfemale\nand\nmale\npoliticians\nin\ngender-neutral\nqueries\nregarding\nlocal\npolitical\ninstitutions;\nhowever,\ntheir\nanalysis\nneither\nfocused\non\nelections\nnor\ndisentangled\nbetween\nthe\neffects\nof\nthe\nchoice\nof\na\nsearch\nquery\nand\neffects\nof\nsearch\nlocalization.\nFinally,\nPerreault\net\nal.\n(2024),\nin\nthe\nanalysis\nof\nGoogle\nsearch\nresults\nin\nthe\ncontext\nof\nthe\nUS\n2022\nelections,\nfound\nnot\nonly\nthe\ntendency\nof\na\nsearch\nengine\nto\nprioritize\nlocal\ninformation\nsources\nfor\nelection-related\ninformation\nbut\nalso\nthe\nfrequent\nmistargeting\n(i.e.,\nthe\nincorrect\nmatching\nbetween\nthe\nuser\nlocation\nand\nlocalized\ninformation\nsources).\nWhile\nthese\nfindings\nshow\nthat\nthe\nlocation\nmay\ninfluence\nwhat\ntype\nof\ninformation\nusers\nsee\nin\nresponse\nto\ntheir\nqueries,\nthey\nprovide\nno\nguidance\non\nhow\nlocation\nis\nconnected\nto\na\npotential\npartisan\ngap\nin\nsearch\nengine\noutputs,\nwhich\nwe\nunderstand\nas\nan\nunequal\nrepresentation\nof\ninformation\nsources\nwith\ndifferent\nideological\nleaning.\nHowever,\nsuch\na\nconnection\ncan\nhave\nsignificant\nimplications\nfor\nthe\n(perceived)\npolarization\nof\nthe\nmedia\nenvironment,\nespecially\nuser\nlocation\ndetermines\nexposure\nto\nsources\nwith\na\nspecific\nideological\nslant.\nOne\nassumption\nwould\nbe\nthat\nthe\npartisan\ngap\naligns\nwith\nthe\npolitical\nleaning\nof\nthe\nlocation\nfrom\nwhich\nthe\nsearch\nis\nconducted;\nthat\nis,\nleft-leaning\nsources\nwill\nbe\nmore\npresent\nwhen\nsearching\nfor\nelection-related\ninformation\nin\npro-Democratic\nstates,\nwhile\nthe\nvisibility\nof\nright-leaning\nsources\nwill\nbe\nhigher\nfor\nthe\nsame\nqueries\nin\npro-Republican\nstates.\nAs\nthis\nassumption\nlacks\na\nclear\nempirical\nbasis,\nwe\nask\nfor\nthe\nmoderating\ninfluence\nof\nsearch\nlocation\nin\nthe\nfollowing\nresearch\nquestion:\nRQ2:\nHow\ndoes\nthe\nsearch\nlocation\naffect\nthe\npartisan\ngap\nbetween\nright-\nand\nleft-leaning\nmedia\nsources\nin\nsearch\nengines\u2019\noutputs?\nAnother\nsystem-side\nfactor\nthat\nwe\nfocus\non\nis\ntime-based\nchanges\nin\nsource\nrelevance\n.\nThis\nconcept\nrefers\nto\nthe\nconstant\nadaptation\nof\nsearch\nresults\nto\ncatch\nup\nwith\nthe\nemergence\nof\nmore\nrelevant\ninformation\nsources.\nSuch\nan\nadaptation\nresults\nin\nchanges\nin\nthe\nselection\nof\nsearch\nresults\nover\ntime,\nin\nparticular\nfor\ndeveloping\nstories.\nOn\na\ndaily\nbasis,\nsuch\nchanges\ntend\nto\nbe\nrelatively\nminor\nand\nusually\nresult\nin\nre-ranking\nsources\ninstead\nof\nadding\nnew\nones\n(Hannak\net\nal.,\n2013);\nhowever,\nthere\nis\nsubstantive\nvariation\nbetween\nsearch\nengines,\nwith\nBing\noutputs\nbeing\nmore\nvolatile\neven\nduring\nshorter\nperiods\nof\ntime\n(Kuznetsova\net\nal.,\n2024).\nFor\nlonger\nperiods\nof\ntime,\nchanges\nin\nsource\nrelevance\ncan\nprofoundly\ntransform\nthe\nrepresentation\nof\nspecific\nsocietal\nphenomena\n(Makhortykh\net\nal.,\n2024b),\nwhich\nhas\nimplications\nfor\nhow\nthese\nphenomena\nare\nperceived\nand\ninterpreted.\nIn\nthe\ncontext\nof\npolitical\ninformation,\nvery\nfew\nstudies\nlook\nat\nhow\nsource\nrelevance\nchanges\nover\ntime.\nOne\nof\nthe\nexceptions\nis\na\nstudy\nby\nUlloa\net\nal.\n(2024a)\nconducted\nduring\nthe\n2020\nUS\npresidential\nelections.\nThe\nresults\nof\nthe\nstudy\ndemonstrated\nthat\nsearch\nresults\nregarding\npolitical\ninformation\nare\nprone\nto\nsubstantial\ntime-based\nfluctuations,\nin\nparticular\naround\nelections,\nand\nreiterated\nthe\nobservation\nby\nKuznetsova\net\nal.\n(2024)\nthat\nBing\noutputs\nare\nmore\nvolatile\nover\ntime\nthan\nGoogle\noutputs.\nThe\nstudy\nalso\nhighlighted\nthat\nsource\nrelevance\nis\ninfluenced\nby\nsearch\nlocalization,\nwith\nthe\nrate\nof\nchanges\nin\nsearch\nresults\nover\ntime\nvarying\ndepending\non\nthe\nsearch\nlocation.\n10\nThere\nare,\nhowever,\nsome\naspects\nof\nsource\nrelevance\nthat\nremain\nunclear.\nOne\nof\nthem\nregards\nthe\nimplications\nof\nchanges\nin\nsource\nrelevance\nfor\nexposure\nto\nsources\nwith\ndifferent\nideological\nslant.\nIt\nis\nknown\nthat\nsome\nsources\n(e.g.,\nWikipedia)\nare\nless\nprone\nto\ntime-based\nchanges\nand\nconsistently\nremain\nin\nthe\ntop\nsearch\nresults.\nHowever,\nthe\ndegree\nto\nwhich\nsuch\nconsistency\napplies\nto\nmedia\nsources\nand\nhow\nequally\nit\napplies\nto\nsources\nwith\nspecific\nideological\nleaning\nremains\nunknown.\nThe\npotential\nfor\ndifferentiated\ntreatment\nof\nsources\nbased\non\ntheir\nleaning\nis\nof\nparticular\nrelevance\nhere\ndue\nto\nits\nimplications\nfor\nperceived\npolarization.\nIf\nusers\nobserve\nthat\nright-\nor\nleft-leaning\nsources\nare\nmore\nlikely\nto\nbe\nconsistently\npresent\nin\nsearch\nresults\n(whereas\nsources\nwith\nan\nopposite\nleaning\nare\nmore\nlikely\nto\ndisappear),\nthen\nit\nmay\ncontribute\nto\nthe\npolarized\nperception\nof\na\nmedia\nenvironment.\nTo\naddress\nthis\ngap,\nwe\nformulate\nthe\nfollowing\nresearch\nquestion:\nRQ3\n:\nHow\ndoes\nthe\npartisan\ngap\nbetween\nright-\nand\nleft-leaning\nmedia\nsources\nin\nsearch\nengines\u2019\noutputs\nevolve\nover\nthe\ncourse\nof\nthe\nelection\ncampaign?\nMethodology\nTo\nanswer\nthe\nresearch\nquestions\nand\ntest\nthe\nhypothesis\noutlined\nabove,\nwe\nconducted\nan\nalgorithm\naudit\nof\ntwo\nsearch\nengines,\nGoogle\nand\nBing,\nin\nthe\nrun-up\nto\nthe\n2024\nUS\npresidential\nelections.\nAlgorithm\nauditing\nis\na\nresearch\nmethod\nused\nto\nsystematically\nanalyze\nthe\nperformance\nof\ncomplex\ndecision-making\nsystems\nand\nevaluate\ntheir\nfunctionality\nand\nimpact\n(Mittelstadt,\n2016).\nThis\nmethod\nis\noften\napplied\nto\nstudy\ninformation\ncuration\nand\nits\npotential\nbiases\nin\nthe\ncase\nof\nsearch\nengines\n(e.g.,\nMakhortykh\net\nal.,\n2022;\nUrman\net\nal.,\n2022a;\nUrman\net\nal.,\n2022b;\nKuznetsova\net\nal.,\n2024)\nand\nother\nalgorithmic\nsystems,\nincluding\nnews\nrecommenders\n(Bandy\n&\nDiakopoulos,\n2020;\nDauc\u00e9\n&\nLoveluck,\n2021)\nor\nsocial\nmedia\nfeeds\n(Bartley\net\nal.,\n2021;\nKuznetsova\n&\nMakhortykh,\n2023).\nThere\nare\ndifferent\nmethodological\napproaches\nfor\nalgorithm\naudits\n(for\nreviews,\nsee\nBandy,\n2021;\nUrman\net\nal.,\n2024).\nHowever,\nmost\nstudies\non\nsearch\nengines\u2019\npolitical\ninformation\ncuration\nuse\nvirtual\nagent-based\naudits\nthat\nrely\non\nprogrammatic\nsimulation\nof\nhuman\nactivity\nto\ngenerate\ninputs\nfor\nthe\nsystem\n(Ulloa\net\nal.,\n2024).\nUsually,\nsuch\naudits\ninvolve\nsimulating\nthe\nprocess\nof\nentering\nqueries\ninto\na\nsearch\nengine\ninterface,\nscrolling\ndown\nto\nload\nsearch\nresults,\nand\nthen\nsaving\nHTML\npages\nwith\nresults\nfor\nsubsequent\nprocessing.\nThis\napproach\nenables\nmore\ncontrol\nover\nthe\ndata\ncollection,\nincluding\npossibilities\nto\ncontrol\nfor\nthe\nchanges\nin\nsource\nrelevancy\nby\ncollecting\ndata\nat\nfixed\ntime\npoints\nand\nthe\neffects\nof\nlocation\nby\nsimulating\nuser\nactivity\nfrom\nspecific\nIP\naddresses.\nFinally,\nvirtual\nagent-based\naudits\ncan\nbe\nscaled\nby\ndeploying\nmultiple\nagents\nto\nsimultaneously\nsimulate\nthe\nsame\nset\nof\nactions,\nwhich\ncan\nensure\nthat\nobservations\nare\nnot\ndisproportionately\naffected\nby\nthe\nrandomization\nof\nsearch\nresults\n(Makhortykh\net\nal.,\n2020).\nData\ncollection\nTo\ncollect\ndata\nfor\nthe\nstudy,\nwe\ndeveloped\na\ncloud-based\ninfrastructure\nfor\ndeploying\na\nlarge\nnumber\nof\nvirtual\nagents\nhosted\nvia\nGoogle\nCompute\nEngine.\nThis\ncloud\nservice\nalso\nprovides\na\nbroad\nrange\nof\nIP\naddresses\nthat\ncan\nbe\nused\nto\nsimulate\nagent\nactivity\nfrom\nspecific\nregions.\nThe\ninfrastructure\nconsisted\nof\none\nstorage\nserver\nto\npreserve\ndata\nduring\ndata\ncollection\nand\na\nlarge\nnumber\nof\nvirtual\nmachines\n(N=30\nfor\nmonthly\ncollections\nand\n11\nN=60\nfor\ndaily\ncollections)\nwith\nthe\nsame\nhardware\nand\nsoftware\nspecifications\n(with\nIP\naddresses\ndistributed\nacross\nthe\nset\nof\nUS\nstates).\nEach\nvirtual\nmachine\nhosted\ntwo\nvirtual\nagents\nusing\nthe\nFirefox\nbrowser;\neach\nagent\nwas\nprogrammed\nto\nopen\nthe\nEnglish\nversion\nof\nGoogle\n(i.e.,\ngoogle.com),\nenter\nthe\nsearch\nquery,\nand\nthen\nretrieve\nthe\nfirst\npage\nof\nsearch\nresults\nfor\nGoogle\ntext\nsearch\nfor\neach\nsearch\nquery\n(see\nbelow).\nTo\naccount\nfor\nrandomization,\neach\nsearch\nquery\nconsisting\nof\nthe\nname\nof\nthe\ncandidate\nwas\nsimultaneously\nentered\nby\n20\nvirtual\nagents\nper\nlocation\n(overall,\n60\nagents\nfor\nmonthly\ncollections\nand\n120\nagents\nfor\ndaily\ncollections).\nTo\nminimize\nthe\nimpact\nof\npersonalization,\nwe\nclosed\nthe\nweb\nbrowser\nafter\neach\nquery\nand\ncleaned\ncookies.\nOur\naudits\naimed\nto\ninvestigate\nthe\nimpact\nof\nuser-\nand\nsystem-side\nfactors\non\ninformation\ncuration\nregarding\nthe\nUS\nelections\nin\norder\nto\nevaluate\nhow\nsearch\nengines\nmay\ncontribute\nto\n(perceived)\npolarization\nof\nthe\nUS\nmedia\nenvironment.\nTo\nimplement\nthe\naudit,\nwe\nused\nthree\ntypes\nof\nelection-related\nqueries:\n(1)\nneutral\nqueries\nwithout\npartisan\ncues\n(\u201celections\nunited\nstates\u201d,\n\u201delections\npresident\nunited\nstates\u201d,\n\u201delections\nhouse\nunited\nstates\u201d,\n\u201delections\ncongress\nunited\nstates\u201d),\n(2)\nRepublican-focused\nqueries\n(\u201cdonald\ntrump\u201d,\n\u201delections\ndonald\ntrump\u201d,\njd\nvance\u201d),\nand\n(3)\nDemocratic-focused\nqueries\n(\u201cjoe\nbiden\u201d,\n\u201celections\njoe\nbiden\u201d,\n\u201ckamala\nharris\u201d,\n\u201celections\nkamala\nharris\u201d,\n\u201ctim\nwalz\u201d).\nFor\nbrevity,\nin\nthe\nremaining\npart\nof\nthe\npaper,\nwe\nwill\nrefer\nto\nRepublican-\nand\nDemocratic-focused\nqueries\nas\nRepublican\nand\nDemocratic,\nrespectively.\nFor\nDemocratic\nqueries,\nwe\nreplaced\nqueries\nfor\nJoe\nBiden\nwith\nthose\nfor\nKamala\nHarris\nafter\nher\ncandidacy\nwas\nratified\nby\nthe\nDemocratic\nconvention.\nTo\nassess\nhow\nsearch\nengines\u2019\ncuration\nis\naffected\nby\ntime-based\nchanges\nin\nsource\nrelevance,\nwe\nrepeated\nthese\nqueries\nin\nthe\nsix\nmonths\nprior\nto\nthe\nelection\n(June\nto\nOctober).\n4\nTo\ncapture\nshort-term\nvariability\nin\nthe\nfinal\nphase\nof\nthe\nelection,\nwe\nrepeated\nthe\nqueries\non\na\ndaily\nbasis\nfrom\n23\nOctober\nuntil\na\nfew\ndays\nafter\nthe\nelection\non\n10\nNovember.\n5\nEvery\nquery\nwas\nconducted\nin\ndifferent\nUS\nlocations\nto\ninvestigate\nhow\ninformation\ncuration\nis\naffected\nby\nsearch\nlocalization.\nFor\nmonthly\ndata\ncollections,\nwe\nran\nthe\nqueries\nfrom\nIP\naddresses\nbased\nin\nthree\nregions:\nLas\nVegas\n(NV),\nLos\nAngeles\n(CA),\nand\nDallas\n(TX).\nFor\ndaily\ndata\ncollections,\nwe\nused\nsix\nlocations:\nLas\nVegas\n(NV),\nLos\nAngeles\n(CA),\nSalt\nLake\nCity\n(UT),\nCouncil\nBluffs\n(IA),\nColumbus\n(OH),\nand\nAshburn\n(VA).\nFor\nevery\nquery,\nwe\ncollected\nthe\nfirst\npage\nof\nsearch\nresults\nfor\nGoogle\nand\nBing.\nSuch\na\npage\ncontains\nbetween\n7\nand\n10\norganic\nsearch\nresults,\nwhich\nare\nlinks\nto\nexternal\ninformation\nsources.\nFor\nGoogle\nsearches,\nwe\nadditionally\ndistinguished\nbetween\norganic\nsearch\nresults\nand\nNewsblock\nresults,\nwhich\nwere\nadded\na\nfew\nmonths\nbefore\nthe\nelections.\nGoogle\nNewsblock\nis\na\nnews\naggregator\nembedded\nin\nGoogle\nsearches\nthat\nindexes\ncontent\nfrom\ndifferent\nmedia\nsources\nto\nprovide\nusers\nwith\na\ncondensed\noverview\nof\nbreaking\ndevelopments\non\nthe\nissue\nthat\nis\nsearched\nfor.\nWe\nalso\ntreated\nas\npart\nof\na\nNewsblock,\na\nselection\nof\nresults\nfrom\nsocial\nmedia\nplatforms,\nwhich\nwere\nsometimes\nadded\nby\nGoogle\nbelow\nthe\nnews\nstories\n(usually,\nsuch\nresults\ncame\nfrom\ncandidates\u2019\naccounts\non\nX).\nDue\nto\nits\nhigh\nvisibility\non\nthe\nweb\npage\n(i.e.,\nbefore\nthe\norganic\nsearch\nresults),\nNewsblock\nis\nlikely\nto\nattract\nsignificant\nattention\nfrom\nusers,\nas\nindicated\nby\nearlier\nresearch\non\nother\nelements\n5\nDue\nto\na\nfailure\nof\nthe\ncloud-based\ndata\ncollection\narchitecture,\nwe\nare\nmissing\ndata\nfor\n27-29 \nOctober.\n4\nIn\nJuly,\nwe\nconducted\na\nsecond\nad\nhoc\ndata\ncollection\nafter\nthe\nassassination\nattempt\non\nDonald \nTrump\nin\nPennsylvania\non\n13\nJuly.\n12\nof\nthe\nsearch\ninterface\nadded\nby\nGoogle\nto\nexpand\norganic\nsearch\nresults.\nAt\nthe\nsame\ntime,\ndue\nto\nbeing\ntemporarily\nadded\nto\nthe\nsearch\npage\nresults,\nNewsblock\ncan\nfollow\ndifferent\ncuration\nprinciples\nthan\nGoogle\u2019s\norganic\nsearch\nresults\n6\nand\nit\ncan\npotentially\nlead\nto\ndifferent\npatterns\nof\npolitical\ninformation\nexposure.\nHowever,\nthere\nis\nlittle\nresearch\non\nthe\nrole\nof\nNewsbllock\n(as\nwell\nas\nother\nadditional\nelements\nof\nthe\nsearch\ninterface)\nin\nalgorithmic\ninformation\ncuration\ndue\nto\nmost\nexisting\nstudies\nfocusing\nonly\non\norganic\nsearch\nresults.\nOverall,\nthese\ndata\ncollections\nresulted\nin\na\ntotal\nof\n305\u2019901\nsearch\nresults\ncoming\nfrom\nGoogle\nand\nBing\n(see\nTable\n1\nfor\nan\noverview).\nTo\npreprocess\ncollected\ndata,\nwe\nfirst\nbuilt\ncustomized\nHTML\nparsers\nto\ndifferentiate\nbetween\ncontent\noriginating\nfrom\nGoogle\u2019s\norganic\nsearch\nresults\nand\nNewsblock\nand\nto\nidentify\norganic\nsearch\nresults\nfor\nBing.\nWe\nthen\nparsed\nand\nextracted\ntext\nresults\nfor\nall\nthree\ntypes\nof\nsearch\nengines,\nwhere\neach\nsearch\nresult\nconstituted\na\ndomain\nof\nthe\ninformation\nsource\n(i.e.,\nthe\nURL\nthat\nis\nlinked),\nthe\ntitle\nof\nthe\nlinked\ninformation\nsource\nas\nwell\nas\nmetadata\nof\nthe\ncollection\n(i.e.,\nquery,\nlocation,\ndate,\nidentifier\nof\nthe\nvirtual\nagent).\nTable\n1.\nOverview\nof\nsearch\nresult\nsample\nsizes\nfor\ndifferent\nsearch\nengine\naudits\nQuery\ntype\nData\ncollection\nDemocrat\nNeutral\nRepublican\nGoogle\n-\norganic\nsearch\nMonthly\n3\u2019943\n5\u2019065\n3\u2019538\nDaily\n19\u2019314\n32\u2019648\n21\u2019864\nGoogle\n-\nNewsblock\nMonthly\n5\u2019018\n3\u2019698\n3\u2019702\nDaily\n29\u2019790\n46\u2019268\n26\u2019837\nBing\nMonthly\n4\u2019130\n4\u2019485\n3\u2019538\nDaily\n28\u2019166\n37\u2019058\n26\u2019839\nTotal\nsearch\nresults\n90\u2019361\n129\u2019222\n86\u2019318\nNote\n.\nNumbers\nare\naggregated\nacross\nlocation\nand\ntime\nof\ndata\ncollection\n(more\ndetailed\ninformation\non\nthe\ndifferent\nsamples\nis\nprovided\nin\nthe\nsupplemental\nmaterials).\n6\nSpecifically,\nNewsblock\ncan\nbe\nmore\ndriven\nby\nsystem-side\nfactors\ndue\nto\nits\nmore\nvolatile\nand \nsituational\nnature.\n13\nMeasures\nWe\nfirst\ncoded\nsource\ntype\nby\nextracting\nthe\nroot\ndomains\nfor\neach\nunique\nsearch\nresult\nand\nclassifying\nthem\nas\nbelonging\nto\none\nof\nseven\nsource\ncategories:\n1)\njournalistic\n(e.g.,\ncnn.com,\neconomist.com,\nusatoday.com,\nnytimes.com);\n2)\ngovernment\n(e.g.,\nusa.gov,\nvote.gov,\nfec.gov);\n3)\nsocial\nmedia\n(e.g.,\nx.com,\nfacebook.com,\ninstagram.com);\n4)\nNGO/think\ntanks\n(e.g.,\naclu.org,\nopensecrets.org,\nconstitutioncenter.org);\n5)\ncandidate\nwebsites\n(e.g.,\nkamalaharris.com,\ndonaldjtrum.com,\ntrump.com);\n6)\nblogs\n(e.g.,\nprojects.fivethirtyeight.com,\nthecampaignworkshop.com);\nand\n7)\nencyclopedias\n(e.g.,\nwikipedia.org,\nballotpedia.org).\nFor\nthe\nclassification,\nwe\nused\nexisting\nlists\nof\ndomains\nassigned\nto\nthe\nabove-mentioned\ncategories\nfrom\nearlier\nauditing\nstudies\nproduced\nby\nthe\nauthors;\nto\nclassify\ndomains\nabsent\nfrom\nthese\nlists,\nwe\nrelied\non\nmanual\nlabeling\nof\nsource\ntypes\nconducted\nby\none\nof\nthe\nauthors.\nFor\nthe\nsubset\nof\njournalistic\nsources,\nwe\ndetermined\nthe\npolitical\nleaning\nby\nmatching\neach\nsource\nto\nentries\nin\nthe\nMedia\nBias\nFact\nCheck\n(MBFC)\ndatabase.\n7\nThe\ndatabase\ncontains\nover\n7\u2019800\nsources\nwhose\npolitical\nleaning\nis\ncategorized\nfrom\nextreme\nleft/right,\nleft/right,\nleft-/right-center,\nto\nleast\nbiased.\nBecause\nthe\nexact\nboundaries\nbetween\nthe\nideological\nsubcategories\nare\nsomewhat\nblurry,\nwe\nrecoded\nthe\ncategories\ninto\ntwo\ndummy\nvariables,\nindicating\nthe\npresence\nof\na\npolitical\nleaning\nto\nthe\nleft\n(1\n=\npresent;\n0\n=\nabsent)\nor\nright\n(1\n=\npresent;\n0\n=\nabsent).\nFinally,\nwe\nused\nthe\nmeta-data\nfrom\nthe\ndata\ncollections\nas\nindependent\nvariables.\nThe\nquery\ntype\n(neutral,\nDemocratic,\nor\nRepublican)\nconstitutes\nthe\nmain\nuser-side\nfactor,\nwhereas\nthe\ndate\n(month\nor\nday\nof\nthe\nquery)\nand\nthe\nlocation\n(where\nthe\nquery\nwas\nconducted)\nrepresent\nsystem-side\nfactors.\nData\nanalysis\nData\nanalysis\nconsists\nof\nthree\nsteps.\nFirst,\nwe\nprovided\na\ndescriptive\nanalysis\nof\nsource\ntypes\nby\naggregating\nthe\nshare\nof\neach\nsource\ntype\nwithin\nmonthly\nand\ndaily\ndata\ncollections\n(RQ1).\nSecond,\nwe\nfocused\non\njournalistic\nmedia,\nwhich\nconstitute\nthe\nmost\nfrequent\ncategory\nof\nsearch\nresults,\nand\nran\ngeneralized\nlinear\nmixed-effects\nmodels\nwith\na\nlogit\nlink\nand\nrandom\nintercepts\nby\na\nvirtual\nagent\nto\npredict\nthe\nlikelihood\nof\nencountering\na\nright-\nor\nleft-leaning\nmedia\nsource\nin\nsearch\nresults\n(H1).\nThe\nmodels\ninclude\nfixed\neffects\nfor\nthe\nquery\ntype\nas\nour\nmain\npredictor\nof\ninterest,\ncontrolling\nfor\ndate\nand\nlocation\nto\naccount\nfor\ntheir\ninfluence\non\nthe\npresence\nof\nslanted\nsources\nin\nsearch\nresults.\nWe\nran\nseparate\nmodels\nfor\nleft-\nand\nright-leaning\nsources\nand\nfor\nthe\nthree\ntypes\nof\nsearch\n(organic\nGoogle\ntext\nsearch,\norganic\nBing\ntext\nsearch,\nand\nGoogle\nNewsblock).\nThird,\nwe\nassessed\nwhether\nthe\ndistribution\nof\nleft-\nand\nright-leaning\nsources\nvaries\nacross\nregions\n(RQ2)\nby\nrepeating\nthe\nmodels\nwith\nby-region\ninteraction\neffects\nand\nthen\ncomputing\nTukey-adjusted\npairwise\ncontrasts\nof\nthe\npredicted\nprobabilities\n(Democratic\nqueries\n\u2013\nRepublican\nqueries)\nfor\neach\nregion\nalong\nwith\n95%\nconfidence\nIntervals\nobtained\nwith\nthe\nWald\nmethod.\nWe\nthen\nrepeated\nthe\nprocedure\nby\ncalculating\nthe\nsame\ncontrasts\nfor\neach\ntime\npoint\nfor\neach\ndata\ncollection\n(RQ3).\nFull\nmodels\nand\nadditional\ntables\nare\nprovided\nin\nthe\nAppendix.\n7\nSee\nhttps://mediabiasfactcheck.com/\n.\nSome\nexamples\nof\nstudies\nusing\nthe\nMBFC\ninclude\nBaly\net\nal. \n(2018),\nWeld\net\nal.\n(2021),\nS\u00e1nchez-Cort\u00e9s\net\nal.\n(2024).\n14\nResults\nUser-side\nfactors\nof\npolitical\ninformation\ncuration\nWe\nfirst\ninvestigate\ndifferences\nin\nthe\nselection\nof\nsources\nin\nGoogle\nand\nBing\nsearch\nresults\nfor\nRepublican,\nDemocratic,\nand\nneutral\nqueries\n(RQ1).\nPanel\nA\nin\nFigure\n1\ndepicts\nthe\nshares\nof\nsource\ntypes\nby\nquery\ntype\naggregated\nacross\nBing\nand\nGoogle\nqueries.\nFor\nall\nquery\ntypes,\njournalistic\nmedia\nsources\nconstitute\nthe\nlargest\nshares\nin\nsearch\nresult\noutputs,\nfollowed\nby\nencyclopedia\nand\ngovernment\nsources\n(see\nTable\nB1\nin\nthe\nAppendix\nfor\na\ndetailed\nbreakdown).\nWhereas\nthe\nshares\nof\nmost\nsource\ntypes\nare\nrather\nsimilar\nfor\nboth\nRepublican\nand\nDemocratic\nqueries,\njournalistic\nsources\nare\nmore\nprevalent\nin\nthe\noutput\nof\nRepublican\nqueries\nby\n14.1%\nin\nthe\nmonthly\nand\n10.5%\nin\ndaily\nsearches.\nPanel\nB\nof\nFigure\n1\nshows\nthat\nthis\ndifference\nin\nthe\nshare\nof\njournalistic\nmedia\nsources\nis\nrather\nstable\nover\ntime,\nindicating\na\ntendency\nfor\nsearch\nengines\nto\nprioritize\nthese\nsources\nfor\nRepublican\nqueries.\nInterestingly,\nfor\nDemocratic\nqueries,\nwe\nobserved\na\nhigher\npresence\nof\ngovernment\nsources\n(which\ncan\nbe\nattributed\nto\nDemocratic\ncandidates\nbeing\nincumbent\nofficials)\nas\nwell\nas\nsocial\nmedia\nsources.\nSocial\nmedia-related\nsources\nwere\nalmost\nabsent\nfrom\nneutral\nqueries,\nthus\nsuggesting\nthat\nfor\nDemocratic\nand\nRepublican\nqueries,\nsearch\nengines\nwere\nlikely\nto\ninclude\nlinks\nto\ncandidates\u2019\nsocial\nmedia\naccounts.\nFigure\n1.\nDescriptive\noverview\nof\nsources\nin\nsearch\nresults\nfor\npartisan\nand\nneutral\nqueries.\nPanel\nA\ndepicts\nmean\nshares\nof\nall\nsources\nby\nquery\ntype.\nPanel\nB\ndepicts\nmean\nshares\nof\njournalistic\nmedia\nsources\nby\nquery\ntype\nacross\ntime,\nalong\nwith\n95%\nconfidence\nintervals.\nData\naggregated\nacross\norganic\nBing,\norganic\nGoogle\nand\nGoogle\u2019s\nNewsblock\nsearch\nresults.\nWe\nthen\nexamine\nthe\npolitical\nleaning\nof\nmedia\nsources\nto\ntest\nwhether\nthe\nideological\nslant\nof\nqueries\nis\nreflected\nin\nslanted\nsearch\noutputs.\nDescriptively,\nwe\nfind\nthat\nleft-leaning\nmedia\n\n15\nsources\nare\nsubstantially\nmore\npresent\nin\nthe\noutput\nof\nboth\nGoogle\nand\nBing,\nirrespective\nof\nthe\ntype\nof\nquery,\nthus\naligning\nwith\nobservations\nfrom\nDiakopoulous\net\nal.\n(2018)\nregarding\nsearch\nengine\noutputs\nin\nthe\ncontext\nof\nthe\n2016\nUS\nelections.\nWhereas\nroughly\nhalf\nof\nmedia\nsources\nhave\nat\nleast\nsome\nleaning\ntoward\nthe\npolitical\nleft,\nthe\nshare\nof\nright-leaning\nmedia\nsources\nonly\nranges\nbetween\n15\u201335%.\nAmong\nthe\nten\nmost\nprevalent\njournalistic\nsources,\nonly\none\nsource\n(\nwww.foxnews.com\n)\nis\nconsidered\nleaning\nto\nthe\npolitical\nright\naccording\nto\nthe\nMBFC\ndatabase\n(see\nTables\nB2.1\u2013B2.2).\nMost\nother\nhighly\nprevalent\nsources\nrepresent\njournalistic\nmedia\noutlets\nassociated\nwith\na\nleft-leaning\nslant\n(e.g.,\nwww.cnn.com\n,\nwww.nytimes.com\n,\nwww.washingtonpost.com\n,\nwww.abcnews.com\n).\nAlthough\nthese\nabsolute\ndifferences\nin\nthe\ndistribution\nof\nleft-\nand\nright-leaning\nmedia\nsources\nare\nnoteworthy,\nwe\nwere\ninterested\nin\nwhether\nsearch\nengine\noutputs\nalso\ncreate\nthe\nrelative\npartisan\ngap\n(i.e.,\nby\nprioritizing\nmedia\nsources\nwith\nthe\nleaning\ncorresponding\nto\nthe\nleaning\nof\na\nsearch\nquery).\nIn\nline\nwith\nH1a,\nwe\nindeed\nfind\nthat\nDemocratic\nqueries\nare\nassociated\nwith\na\nhigher\nlikelihood\nof\nleft-leaning\nsources\nfor\nthe\nmonthly\ndata\ncollections\nrelated\nto\nBing\n(\nOR\n=\n1.23,\n95%CI\n[1.10:1.37],\np\n<\n0.001)\nand\nGoogle\norganic\nsearch\nresults\n(\nOR\n=\n1.36,\n95%CI\n[1.10:1.68],\np\n=\n0.005)\nbut\nnot\nfor\nGoogle\u2019s\nNewsblock\noutputs\n(\nOR\n=\n1.05,\n95%CI\n[0.94:1.17],\np\n=\n0.420).\nFor\ninstance,\nthe\npredicted\nshare\nof\nleft-leaning\nsources\nin\nBing\nsearch\noutputs\nis\n61.2%\n(\n95%C\nI[59.3:63.1%])\nfor\nDemocratic\nqueries\nbut\nonly\n52.5%\n(\n95%C\nI[50.1:54.4%])\nfor\nRepublican\nqueries\n(see\npanel\nA\nof\nFigure\n2).\nFor\nBing\nbut\nnot\nGoogle,\nwe\nalso\nfound\nthat\nRepublican\nqueries\nsignificantly\ndecrease\nthe\nlikelihood\nof\nleft-leaning\nmedia\nappearing\nin\nsearch\nresults\n(\nOR\n=\n0.88,\n95%CI\n[0.79:0.98],\np\n=\n0.022).\nFor\ndaily\ncollections,\nthe\npattern\nof\nsearch\nresults\nis\nmore\nmixed.\nOn\nthe\none\nhand,\nwe\nfound\nthe\nexpected\npositive\nrelationship\nbetween\nDemocratic\nqueries\nand\nleft-leaning\nsources\nonly\nfor\nBing\n(\nOR\n=\n1.17,\n95%CI\n[1.12:1.22],\np\n<\n0.001).\nFor\norganic\nand\nNewsblock\noutputs\non\nGoogle,\nthis\neffect\nis\nnot\nstatistically\nsignificant.\nOn\nthe\nother\nhand,\nthere\nis\nconsistent\nevidence\nthat\nRepublican\nqueries\ndecrease\nthe\nlikelihood\nof\nleft-leaning\nsources\nfor\nall\nthree\ntypes\nof\nsearch\n(Bing:\nOR\n=\n0.94,\n95%CI\n[0.90:0.97],\np\n=\n0.002;\nGoogle-organic:\nOR\n=\n0.73,\n95%CI\n[0.69:0.78],\np\n<\n0.001;\nGoogle-Newsblock:\nOR\n=\n0.77,\nCI95%\n[0.74\n\u2013\n0.80],\np\n<\n0.001).\n16\nFigure\n2\n.\nPredicted\nprobabilities\nof\nmedia\nsources\nwith\na\npolitical\nleaning\nto\nthe\npolitical\nleft\n(Panel\nA)\nor\nright\n(Panel\nB)\nby\nquery\ntype\n(color)\nand\nsearch\nengine\n(symbol\nshape).\nAs\nexpected\nin\nH1b,\nright-leaning\nmedia\nare\nconsistently\noverrepresented\nfor\nRepublican\nqueries\nboth\nfor\nthe\nmonthly\nand\ndaily\ncollections\n(see\nPanel\nB\nof\nFigure\n2).\nSuch\nsources\nwere\nsignificantly\nmore\nlikely\nto\nbe\nprioritized\nin\nresponse\nto\nRepublican\nqueries\non\nBing\n(monthly:\nOR\n=\n1.49,\n95%CI\n[1.34:1.65],\np\n<\n0.001;\ndaily:\nOR\n=\n1.57,\n95%CI\n[1.51:1.62],\np\n<\n0.001\n)\nand\nGoogle\norganic\nsearch\nresults\n(monthly:\nOR\n=\n1.66,\n95%CI\n[1.51:1.83],\np\n<\n0.001;\ndaily:\nOR\n=\n1.55,\n95%CI\n[1.50:1.61],\np\n<\n0.001)\nas\nwell\nas\nGoogle\u2019s\nNewsblock\n(monthly:\nOR\n=\n3.13,\nCI95%\n[2.79:3.51],\np\n<\n0.001;\ndaily:\nOR\n=\n2.79,\n95%CI\n[2.69:2.89],\np\n<0.001).\nWhereas\nRepublican\nqueries\nnegatively\npredict\nthe\npresence\nof\nleft-leaning\nsources,\nthe\nopposite\npattern\ndid\nnot\nhold.\nDemocratic\nqueries\nnever\ndecrease\nthe\nlikelihood\nof\nright-leaning\nnews\nsources\nin\nsearch\noutputs;\nin\nfact,\nthey\neven\nincrease\nthe\npresence\nof\nright-leaning\nsources\nin\nmonthly\nGoogle\nNewsblock\nsearches\n(\nOR\n=\n1.33,\n95%CI\n[1.16:1.53],\np\n<\n0.001).\nSystem-side\nfactors\nof\npolitical\ninformation\ncuration\nSo\nfar\nwe\nhave\nestablished\ndifferences\nin\nthe\npolitical\nleaning\nof\nmedia\nsources\nin\nsearch\nresults\ndepending\non\nthe\nuser-side\nfactors\nin\nthe\nform\nof\nthematic\nfocus\nof\nelection-related\nqueries:\nDemocratic\nqueries\nresulted\nin\nhigher\nshares\nof\nleft-leaning\nsources,\nwhile\nRepublican\nqueries\nincreased\nthe\npresence\nof\nright-leaning\nnews\nsources.\nIn\nthe\nremainder\nof\nthis\nsection,\nwe\nassess\nhow\nthese\ndifferences\nare\ninfluenced\nby\ntwo\nsystem-side\nfactors,\nnotably\nsearch\nlocalization\nand\nsubsequent\nvariation\nin\nsearch\nresults\nbased\non\nthe\nlocation\n\n17\nfrom\nwhere\nthe\nsearch\nhas\nbeen\nconducted\nand\nthe\nchanges\nin\nsearch\nresults\nover\ntime\ndue\nto\nevolving\nsource\nrelevance.\nWe\nfirst\ninvestigate\nto\nwhat\nextent\nthe\npartisan\ngap\nin\nthe\npolitical\nleaning\nof\nmedia\nsources\nis\nmoderated\nby\nthe\nsearch\nlocation.\nFor\nthe\nmonthly\ncollections,\nthe\ndifference\nin\npredicted\nprobabilities\nof\nleft-leaning\nsources\nbetween\npro-Republican\nand\npro-Democratic\nstates\nonly\nvaried\nby\na\nfew\npercentage\npoints\n(see\nPanel\nA\nof\nFigure\n3).\nSpecifically,\nwe\nfind\nno\nevidence\nthat\nleft-leaning\nsources\nare\nmore\nprevalent\nin\ncases\nwhen\nthe\nqueries\nare\nconducted\nin\na\ntraditional\n\u2018blue\u2019\nlocation\n(Los\nAngeles,\nCA)\ncompared\nto\na\n\u2018red\u2019\nlocation\n(Dallas,\nTX).\nHowever,\nfor\nthe\ndaily\ncollections,\nwe\nfound\ninstances\nwhere\nthe\ngap\nin\nthe\npredicted\nlikelihood\nof\nleft-leaning\nmedia\nsurprisingly\ndisappeared\nin\n\u2018blue\u2019\n(Bing\nin\nLos\nAngeles,\nCA)\nor\nhistorically\nmore\nmixed\nstates\n(Bing\nin\nColumbus,\nOH;\norganic\nsearch\nresults\nfor\nGoogle\nin\nIowa\nCity,\nIA;\norganic\nsearch\nresults\nfor\nGoogle\nand\nBing\nin\nNorthern\nVirginia,\nVA).\nNote,\nhowever,\nthat\nthis\nregional\nvariation\nremains\nwithin\nthe\nrange\nof\na\nfew\npercentage\npoints.\nFigure\n3\n.\nDifference\nin\npredicted\nprobabilities\nof\nthe\nlikelihood\nof\nmedia\nsources\nwith\na\nleaning\nto\nthe\npolitical\nleft\n(Panel\nA)\nor\nright\n(Panel\nB)\nacross\nlocations\n(x-axis).\nPoint\nestimates\nwere\ncalculated\nfrom\nTukey-adjusted\npairwise\ncontrasts\nas\nthe\ndifference\nin\npredicted\nprobability\nbetween\nDemocratic\nand\nRepublican\nqueries.\nPositive\n(negative)\nestimates,\ntherefore,\nindicate\nhigher\nshares\nfor\nDemocratic\n(Republican)\nqueries.\n\n18\nPanel\nB\nof\nFigure\n3\nillustrates\nthe\nregional\nvariation\nof\nthe\npredicted\ndifference\nin\nright-leaning\nnews\nsource\nprevalence.\nThe\nresults\nindicate\nthat\nthe\nincreased\nlikelihood\nof\nright-leaning\nnews\nsources\nfor\nRepublican\nqueries\nis\nremarkably\nconsistent\nacross\ngeographical\nlocations.\nThe\nonly\nexception\nis\nthe\nmonthly\ncollections\nfor\nLas\nVegas,\nNV,\nwhere\nthis\npositive\nassociation\nbetween\nright-leaning\nsources\nand\nRepublican\nqueries\ndoes\nnot\nreach\nstatistical\nsignificance.\nFinally,\nwe\nassess\nhow\nthe\npartisan\ngap\nin\nmedia\nsource\nselection\nin\nsearch\nengine\noutputs\nchanges\nover\ntime.\nFor\nthe\nmonthly\ncollections,\nwe\nfind\nthat\nthe\ndifference\nin\nleft-leaning\nsources\nbetween\nDemocratic\nand\nRepublican\nqueries\ntends\nto\nbe\nsmaller\nor\nabsent\nin\nthe\nfirst\nfew\nmonths.\nFor\norganic\nGoogle\nand\nBing\nsearch\nresults,\nthe\npartisan\ngap\nin\nleft-leaning\nnews\nsources\nis\nlargest\nin\nthe\nlater\nmonths\nof\nAugust\nthrough\nOctober.\nFor\nthe\ndaily\ncollections,\nthe\ngap\nin\nleft-leaning\nnews\nsources\ntends\nto\nshrink\nin\nthe\nfinal\nweek\nbefore\nthe\nelection\non\n5\nNovember\n2024.\nWhile\nthe\nextent\nof\ntemporal\nvariation\nis\nrather\nlimited\nfor\norganic\nGoogle\nand\nBing\nsearches,\nthere\nis\nsubstantial\nshort-term\nvariation\nfor\nGoogle\nNewsblock\nsearches.\nThough\nNewsblock\nsearch\nresults\nshow\nhigher\nshares\nof\nleft-leaning\nsources\nfor\nDemocratic\nqueries\non\nmost\ndays,\nthis\npattern\nflips\nin\nthe\nopposite\ndirection\nin\ntwo\ninstances.\nFor\ninstance,\nthe\ndifference\nin\npredicted\nshares\nis\n13.5%\n(\n95%CI\n[8.03:19.1])\nhigher\nfor\nDemocratic\nqueries\non\n3\nNovember\nbut\nthen\nplummets\nto\n-17.8%\n(\n95%CI\n[-23.0:-12.6])\nthe\nnext\nday,\nsuggesting\na\nsignificantly\nhigher\nprevalence\nof\nleft-leaning\nsources\nfor\nRepublican\nqueries.\nThe\ninverse\npattern\nof\nresults\nemerges\nfor\nright-leaning\nmedia.\nThe\nrelative\noverrepresentation\nof\nthese\nmedia\nsources\nfor\nRepublican\nqueries\ntends\nto\nbe\nmarginally\nsmaller\nin\nthe\nearlier\nmonths\nof\nthe\ndata\ncollection\nbut\nthen\nstabilizes\naround\na\ndifference\nof\nroughly\n10%.\nOnce\nmore\nthe\nconsistency\nof\norganic\nGoogle\nand\nBing\nsearches\ncontrasts\nwith\nstronger\nfluctuation\nin\nresults\nfor\nGoogle\nNewsblock.\n19\nFigure\n4\n.\nDifference\nin\npredicted\nprobabilities\nof\nthe\nlikelihood\nof\nnews\nsources\nwith\na\nleaning\nto\nthe\npolitical\nleft\n(Panel\nA)\nor\nright\n(Panel\nB)\nover\ntime\n(x-axis).\nPoint\nestimates\nwere\ncalculated\nfrom\nTukey-adjusted\npairwise\ncontrasts\nas\nthe\ndifference\nin\npredicted\nprobability\nbetween\nDemocratic\nand\nRepublican\nqueries.\nPositive\n(negative)\nestimates,\ntherefore,\nindicate\nhigher\nshares\nfor\nDemocratic\n(Republican)\nqueries.\nDiscussion\nIn\nthis\narticle,\nwe\nexamined\nhow\nthe\ntwo\nlargest\nWestern\nsearch\nengines,\nGoogle\nand\nBing,\ncurated\npolitical\ninformation\nprior\nto\nthe\n2024\nUS\nelections.\nAccording\nto\nthe\nsearch\nengines\nthemselves,\nin\nparticular,\nGoogle,\ntheir\naim\nin\nthis\ncontext\nwas\nto\n\u201csurface\nhigh-quality\ninformation\nto\nvoters\u201d\n(Jasper,\n2023)\nby\nprioritizing\nauthoritative\nlocal\nand\nregional\nnews\nand\ninformation\nfrom\nthe\nregional\nand\nstate\noffices.\nThrough\nour\nanalysis,\nwe\naimed\nto\nunderstand\nnot\nonly\nwhether\nthis\nclaim\nis\nempirically\nsupported\nbut\nalso\nwhether\nthe\ncuration\nof\nhigh-quality\ninformation\nby\nsearch\nengines\nwas\nprone\nto\n(ideological)\nskewness\nand\nhow\nit\nwas\naffected\nby\ndifferent\nuser-\nand\nsystem-side\nfactors.\nOne\nimmediate\nfinding\nof\nour\nstudy\nis\nthat\nsearch\nengines\ntend\nto\nprioritize\nleft-leaning\nmedia\nsources\nin\nrelation\nto\nall\ntypes\nof\nelection-related\nqueries.\nWhile\nit\ndoes\nnot\nmean\nthat\nright-leaning\nmedia\nwere\ncompletely\nexcluded\nby\nsearch\nengines\u2019\ncuration\nsystems,\ntheir\npresence\nwas\nless\npronounced,\nthus\naligning\nto\na\ncertain\ndegree\nwith\nRepublican\nclaims\nabout\nthe\nskewed\nrepresentation\nof\nelectoral\nmatters\nby\nsearch\nengines\n(e.g.,\nLowell,\n2024).\nAt\nthe\nsame\ntime,\nit\nis\nimportant\nto\nnote\nthat\nthe\nhigher\npresence\nof\nleft-leaning\nsources\ndoes\nnot\nper\nse\nindicate\nthat\nsearch\nengines\npresented\na\nparticular\ncandidate\nin\na\nmore\npositive\nlight,\nas\nsome\nRepublican\naccusations\nassumed.\nTo\nverify\nsuch\naccusations,\nit\nwould\nbe\n\n20\nnecessary\nto\nconduct\nan\nanalysis\nof\nspecific\ncontent\nitems\nlinked\nby\nsearch\nengines,\nbut\nsuch\nan\nanalysis\nis\nbeyond\nthe\nscope\nof\nthe\ncurrent\nstudy.\nFurthermore,\nit\nhas\nto\nbe\nacknowledged\nthat\nthe\npartisan\ngap\nin\nmedia\nsources\u2019\nprioritization\ncan\nalso\nbe\nattributed\nto\nthe\nmultiple\ncontroversies\nassociated\nwith\nprominent\nright-leaning\nmedia\u2019s\ncoverage\nof\nthe\n2020\nelections\nthat\nresulted\nin\nthem\nbeing\ntreated\nas\nless\nreliable\nsources\nby\ninformation\ncuration\nsystems\nand,\nconsequently,\ndowngraded\nin\norganic\nsearch\nresults.\nWe\nalso\nfind\nsupport\nfor\nour\nH1\nthat\nassumed\nthat\nthe\nideological\nslant\nof\nsearch\nengine\noutputs\naligns\nwith\nthe\nideological\nslant\nof\nthe\nsearch\nqueries.\nThe\nmajor\nimplication\nof\nthis\nfinding\nis\nthat\nsearch\nengines\u2019\ninformation\ncuration\nactively\nmirrors\nthe\npartisan\ndivides\npresent\nin\nthe\nUS\nmedia\nenvironments\n-\nat\nleast\nregarding\nthe\ncuration\nof\nmedia\nsources\nconstituting\nthe\nmost\ncommon\ntype\nof\noutputs\non\nGoogle\nand\nBing\n-\nand\nhas\nthe\npotential\nto\ncontribute\nto\n(perceived)\npolarization\nwithin\nthese\nenvironments.\nThe\nexact\ndegree\nto\nwhich\nsuch\ncontribution\nis\nhappening\nshall\nbe\nmeasured\nin\nfuture\nresearch,\nbut\nconsidering\nexisting\nevidence\nof\nthe\nsubstantive\nimpact\nof\nsearch\nengines\non\nopinion\nformation\nin\nthe\ncontext\nof\npolitics\n(Epstein\n&\nRobertson,\n2015;\nRohrbach\net\nal.,\n2024)\nand\nthe\nhigh\ntrust\ntowards\nsearch\nengines\nas\nan\ninformation\nsource,\nwe\nsuggest\nthat\nthe\nrisk\nof\nsearch\nengines\ncontributing\nto\nsocietal\npolarization\nshall\nbe\ntreated\nseriously.\nThe\nabove-mentioned\nobservations\nalso\nraise\nthe\nquestion\nregarding\nthe\nnormative\nexpectations\nabout\nthe\nrole\nof\nsearch\nengines\nin\nthe\ncontext\nof\npolitical\ncommunication\nin\npolarised\nmedia\nenvironments.\nWith\nsearch\nengines\nserving\nas\ninformation\ngatekeepers\nthat\ncurate\naccess\nto\npolitical\ninformation\nin\na\nway\nthat\nshares\ncertain\nsimilarities\nwith\ntraditional\nforms\nof\njournalistic\ngatekeeping,\nthe\ndegree\nto\nwhich\nsearch\nengines\u2019\ncuration\nshall\nfollow\nnormative\nprinciples\nassociated\nwith\njournalism\nremains\nunclear.\nShall,\nfor\ninstance,\nsearch\nengines\nreflect\nthe\n(often\nbiased)\nstate\nof\nsocial\nreality\nat\nany\ngiven\npoint\nin\ntime,\nresulting\nin\nthe\nunequal\nvisibility\nof\ndifferent\nideologically\nslanted\nperspectives,\nwhich\nare\nthe\nproduct\nof\nincreasingly\npolarized\nmedia\nenvironments?\nOr\nshall\nsearch\nengines\nmake\ninterventions\nin\nline\nwith\nthe\ndeliberative\ndemocracy\nprinciples\n(for\nsome\nexamples\nregarding\nother\ncuration\nsystems,\nsee\nHelberger,\n2019)\nto\nexpose\nindividuals\nto\ndiverse\ninformation\nthat\ncan\nhelp\nnegotiate\ndifferent\nviewpoints\nand,\nhypothetically,\ncounter\nsocietal\npolarization?\nThe\nanswers\nto\nthese\nquestions\neventually\ndepend\non\nthe\ndesired\nrole\nof\ninformation\ncuration\nsystems\nin\ndemocracies\nwhich\ncurrently\nremains\nunclear.\nWe\nalso\nfind\nthat\nuser-side\nfactors\nturn\nout\nto\nbe\nmore\nimpactful\nthan\nsystem-side\nfactors.\nIn\nparticular,\nfor\norganic\nsearch\nresults\non\nGoogle\nand\nBing,\nwe\nobserve\nrelatively\nlittle\nvariation\nover\ntime\nand\ndepending\non.\nInterestingly,\nGoogle\u2019s\nNewsblock\noutputs\nturned\nout\nto\nbe\nmore\nvolatile,\nwhich\nis\nlikely\ndue\nto\nthe\ndifferent\nalgorithmic\nlogic\nof\ncuration\nused\nthere.\nSuch\nvolatility\ncan\npotentially\ncounter\nthe\npartisan\ndivide\nmirrored\nin\norganic\nsearch\nresults,\nalbeit\nits\nhigher\ncustomization\ncan\nalso\nlead\nto\nthe\nopposite\nresults.\nOverall,\nthe\nadditional\nsearch\ninterfaces,\nsuch\nas\nthe\nNewsblock,\ncan\nplay\nan\nimportant\nrole\nin\nthe\ncontext\nof\n(perceived)\npolarization,\nbut\nthe\ncuration\nprinciples\nbehind\nthese\ninterfaces\nare\neven\nless\ntransparent\nthan\norganic\nsearch.\nUnder\nthese\ncircumstances,\nit\nis\nimportant\nto\nkeep\naccounting\nfor\nthese\nadditional\nforms\nof\ninformation\ncuration,\nwhich\nare\nincreasingly\nadopted\nby\nsearch\nengines\nin\nrelation\nto\nspecific\nissues\nand\nat\nspecific\npoints\nof\ntime\nin\nfuture\nresearch.\n21\nFinally,\nit\nis\nimportant\nto\nnote\nseveral\nlimitations\nof\nthe\nconducted\nstudy.\nFirst,\nto\nexamine\ninformation\ncuration,\nwe\nrelied\njust\non\na\nfew\nsearch\nqueries\nthat\nreferred\nto\nrather\ngeneral\nelection-related\nconcepts\nand\na\nfew\nkey\nactors.\nA\nrelatively\nsmall\npool\nof\nqueries\nis\nattributed\nto\nthe\nhigh\namount\nof\ncomputational\nand\nhuman\nresources\nrequired\nto\ndeploy\nand\nmaintain\ninfrastructure\nfor\ndata\ncollection.\nHowever,\nit\nwould\nbe\nadvantageous\nfor\nfuture\nresearch\nto\nlook\nfor\nways\nto\nexpand\nthe\nselection\nof\nqueries\nused\nas\nwell\nas\nto\ninclude\nmore\njudgemental\nand\nideologically\nslanted\nqueries\nto\nassess\nhow\nsuch\na\nchange\nin\nuser-side\nfactors\nwill\naffect\nour\nobservations\nregarding\nthe\nperformance\nof\ninformation\ncuration\nsystems.\nAnother\nlimitation\nregards\na\nrelatively\nlimited\nset\nof\ngeographic\nlocations,\nwhich\nwe\nused\nto\nevaluate\nthe\neffects\nof\nsearch\nlocalization\non\nelection-related\ninformation\ncuration.\nSuch\na\nlimitation\nis\ndue\nto\nour\nreliance\non\nGoogle\nCompute\nEngine\nfor\ndeploying\ninfrastructure\nfor\nthe\naudit.\nBecause\nof\nthis\nreason,\nwe\nhad\na\nlimited\nset\nof\nUS\nstates\nfor\nwhich\nwe\ncould\napply\nIP\naddresses,\nincluding\nalmost\nno\n\u201cpurple\u201d\n(or\nbattleground)\nstates,\nwhere\nauditing\ninformation\ncuration\nwould\nbe\nof\nparticular\ninterest.\nThe\nlast\nlimitation\nregards\nour\nfocus\non\nanalyzing\npolitical\nleaning\nonly\nfor\nmedia\nsources,\nwhich\nis\nboth\ndue\nto\nthem\nbeing\nthe\nmost\ncommon\ntype\nof\nsource\nretrieved\nby\nsearch\nengines\nand\nthe\navailability\nof\ndata\nabout\ntheir\npolitical\nleaning.\nFor\nfuture\nresearch\nit\nmay\nbe\nadvantageous\nto\nconsider\nways\nto\nexpand\nthe\nanalysis\nof\npolitical\nleaning\nto\nother\ncategories\nof\nsources,\npotentially\nby\nincluding\nthe\nanalysis\nof\ncontent\nlinked\nin\nsearch\nengine\nresults.\nReferences\nBallatore,\nA.,\nGraham,\nM.,\n&\nSen,\nS.\n(2017).\nDigital\nhegemonies:\nthe\nlocalness\nof\nsearch\nengine\nresults.\nAnnals\nof\nthe\nAmerican\nAssociation\nof\nGeographers\n,\n107(5),\n1194-1215.\nBaly,\nR.\net\nal.\n(2018).\nPredicting\nfactuality\nof\nreporting\nand\nbias\nof\nnews\nmedia\nsources.\nIn\nProceedings\nof\nthe\n2018\nConference\non\nEmpirical\nMethods\nin\nNatural\nLanguage\nProcessing\n(pp.\n3528-3539).\nACM.\nBandy,\nJ.\n(2021).\nProblematic\nmachine\nbehavior:\nA\nsystematic\nliterature\nreview\nof\nalgorithm\naudits.\nProceedings\nof\nthe\nACM\non\nHuman-Computer\nInteraction\n,\n5\n(CSCW1),\n1-34.\nBandy,\nJ.,\n&\nDiakopoulos,\nN.\n(2020).\nAuditing\nnews\ncuration\nsystems:\nA\ncase\nstudy\nexamining\nalgorithmic\nand\neditorial\nlogic\nin\nApple\nNews.\nIn\nProceedings\nof\nthe\nInternational\nAAAI\nConference\non\nWeb\nand\nSocial\nMedia\n(pp.\n36-47).\nAAAI.\nBartley,\nN.\net\nal.\n(2021).\nAuditing\nalgorithmic\nbias\non\nTwitter.\nIn\nProceedings\nof\nthe\n13th\nACM\nWeb\nScience\nConference\n2021\n(pp.\n65-73).\nACM\nBlassnig,\nS.\net\nal.\n(2023).\nGoogling\nreferendum\ncampaigns:\nanalyzing\nonline\nsearch\npatterns\nregarding\nSwiss\ndirect-democratic\nvotes.\nMedia\nand\nCommunication\n,\n11(1),\n19-30.\nBorgesius,\nF.\net\nal.\n(2016).\nShould\nwe\nworry\nabout\nfilter\nbubbles?\nInternet\nPolicy\nReview,\n5\n(1),\n1-16.\n22\nBragazzi,\nN.\net\nal.\n(2017).\nHow\noften\npeople\ngoogle\nfor\nvaccination:\nQualitative\nand\nquantitative\ninsights\nfrom\na\nsystematic\nsearch\nof\nthe\nweb-based\nactivities\nusing\nGoogle\nTrends.\nHuman\nVaccines\n&\nImmunotherapeutics\n,\n13\n(2),\n464-469.\nBruns,\nA.\n(2019).\nAre\nFilter\nBubbles\nReal?\nJohn\nWiley\n&\nSons.\nCastillo,\nC.\n(2019).\nFairness\nand\ntransparency\nin\nranking.\nACM\nSIGIR\nForum\n,\n52(2),\n64-71.\nDauc\u00e9,\nF.,\n&\nLoveluck,\nB.\n(2021).\nCodes\nof\nconduct\nfor\nalgorithmic\nnews\nrecommendation:\nThe\nYandex.\nNews\ncontroversy\nin\nRussia.\nFirst\nMonday,\n26\n(5),\n1-22.\nDiakopoulos,\nN.\net\nal.\n(2018).\nI\nvote\nfor\u2014how\nsearch\ninforms\nour\nchoice\nof\ncandidate.\nIn\nM.\nMoore\nand\nD.\nTambini\n(Eds.)\nDigital\nDominance:\nThe\nPower\nof\nGoogle,\nAmazon,\nFacebook,\nand\nApple\n(pp.\n320-342).\nOxford\nUniversity\nPress.\nDobber,\nT.\n(2023).\nMicrotargeting,\nprivacy,\nand\nthe\nneed\nfor\nregulating\nalgorithms.\nIn\nThe\nRoutledge\nHandbook\nof\nPrivacy\nand\nSocial\nMedia\n(pp.\n237-245).\nRoutledge.\nDutton,\nW.\net\nal.\n(2017).\nSearch\nand\npolitics:\nThe\nuses\nand\nimpacts\nof\nsearch\nin\nBritain,\nFrance,\nGermany,\nItaly,\nPoland,\nSpain,\nand\nthe\nUnited\nStates\n.\nSSRN.\nhttps://dx.doi.org/10.2139/ssrn.2960697\nEpstein,\nR.,\n&\nRobertson,\nR.\n(2015).\nThe\nsearch\nengine\nmanipulation\neffect\n(SEME)\nand\nits\npossible\nimpact\non\nthe\noutcomes\nof\nelections.\nProceedings\nof\nthe\nNational\nAcademy\nof\nSciences\nof\nthe\nUnited\nStates\nof\nAmerica,\n112(33),\nE4512-E4521.\nFriedman,\nB.,\n&\nNissenbaum,\nH.\n(1996).\nBias\nin\ncomputer\nsystems.\nACM\nTransactions\non\nInformation\nSystems\n,\n14\n(3),\n330-347.\nHannak,\nA.\net\nal.\n(2013).\nMeasuring\npersonalization\nof\nweb\nsearch.\nIn\nProceedings\nof\nthe\n22nd\nInternational\nConference\non\nWorld\nWide\nWeb\n(pp.\n527-538).\nACM.\nHelberger,\nN.\n(2019).\nOn\nthe\ndemocratic\nrole\nof\nnews\nrecommenders.\nDigital\nJournalism\n,\n7\n(8),\n993-1012.\nHoskins,\nA.,\n&\nTulloch,\nJ.\n(2016).\nRisk\nand\nhyperconnectivity:\nMedia\nand\nmemories\nof\nneoliberalism\n.\nOxford\nUniversity\nPress.\nJasper,\nS.\n(2023).\nHow\nwe\u2019re\napproaching\nthe\n2024\nU.S.\nelections.\nGoogle.\nhttps://blog.google/outreach-initiatives/civics/how-were-approaching-the-2024-us-elections/\nKang,\nJ.\n(2024).\nHow\nBiased\nIs\nthe\nMedia,\nReally?\nThe\nNew\nYorker.\nhttps://www.newyorker.com/news/fault-lines/how-biased-is-the-media-really\nKliman-Silver,\nC.\net\nal.\n(2015).\nLocation,\nlocation,\nlocation:\nThe\nimpact\nof\ngeolocation\non\nweb\nsearch\npersonalization.\nIn\nProceedings\nof\nthe\n2015\nInternet\nMeasurement\nConference\n(pp.\n121-127).\nACM.\n23\nKubin,\nE.,\n&\nvon\nSikorski,\nC.\n(2023).\nThe\ncomplex\nrelationship\nbetween\nmedia\nand\npolitical\npolarization:\nUnderstanding\nhow\nthe\nmedia\ncan\naffectively\n(de)polarize\ncitizens.\nInternational\nJournal\nof\nCommunication\n,\n17\n,\n5207\u20135222.\nKuznetsova,\nE.,\n&\nMakhortykh,\nM.\n(2023).\nBlame\nit\non\nthe\nalgorithm?\nRussian\ngovernment-sponsored\nmedia\nand\nalgorithmic\ncuration\nof\npolitical\ninformation\non\nFacebook.\nInternational\nJournal\nof\nCommunication\n,\n17,\n971-992.\nKuznetsova,\nE.\net\nal.\n(2024).\nAlgorithmically\ncurated\nlies:\nHow\nsearch\nengines\nhandle\nmisinformation\nabout\nUS\nbiolabs\nin\nUkraine\n.\narXiv.\nhttps://doi.org/10.48550/arXiv.2401.13832\nLowell,\nH.\n(2024).\nTrump\nvows\nto\nseek\ncriminal\ncharges\nagainst\nGoogle\nif\nre-elected\npresident.\nThe\nGuardian.\nhttps://www.theguardian.com/us-news/2024/sep/27/trump-google-threat-criminal-charges\nLudwig,\nK.\net\nal.\n(2023).\nDivided\nby\nthe\nalgorithm?\nthe\n(limited)\neffects\nof\ncontent-and\nsentiment-based\nnews\nrecommendation\non\naffective,\nideological,\nand\nperceived\npolarization.\nSocial\nScience\nComputer\nReview,\n41(6),\n2188-2210.\nMakhortykh,\nM.,\nUrman,\nA.,\n&\nUlloa,\nR.\n(2020).\nHow\nsearch\nengines\ndisseminate\ninformation\nabout\nCOVID-19\nand\nwhy\nthey\nshould\ndo\nbetter.\nHarvard\nKennedy\nSchool\nMisinformation\nReview\n,\n1\n(3),\n1-12.\nMakhortykh,\nM.,\nUrman,\nA.,\n&\nUlloa,\nR.\n(2022).\nMemory,\ncounter-memory\nand\ndenialism:\nHow\nsearch\nengines\ncirculate\ninformation\nabout\nthe\nHolodomor-related\nmemory\nwars.\nMemory\nStudies\n,\n15\n(6),\n1330-1345.\nMakhortykh,\nM.\net\nal.\n(2024).\nPopular\nVotes\nand\nAlgorithms\nin\nSwitzerland:\nIntransparent\nPriorisation\nof\nPolitical\nInformation\n.\nReatch.\nMakhortykh,\nM.\net\nal.\n(2024).\nDoes\nit\nget\nbetter\nwith\ntime?\nWeb\nsearch\nconsistency\nand\nrelevance\nin\nthe\nvisual\nrepresentation\nof\nthe\nHolocaust.\nIn\nE.\nPfanzelter,\nD.\nRupnow,\n\u00c9.\nKov\u00e1cs\nand\nM.\nWindsperger\n(Eds.)\nConnected\nHistories:\nMemories\nand\nNarratives\nof\nthe\nHolocaust\nin\nDigital\nSpace\n(pp.\n13-33).\nDe\nGruyter.\nMittelstadt,\nB.\n(2016).\nAuditing\nfor\ntransparency\nin\ncontent\npersonalization\nsystems.\nInternational\nJournal\nof\nCommunication\n,\n10,\n4991\u20135002.\nNechushtai,\nE.,\nZamith,\nR.,\n&\nLewis,\nS.\nC.\n(2024).\nMore\nof\nthe\nsame?\nHomogenization\nin\nnews\nrecommendations\nwhen\nusers\nsearch\non\nGoogle,\nYouTube,\nFacebook,\nand\nTwitter.\nMass\nCommunication\nand\nSociety,\n27(6),\n1309-1335.\nNielsen,\nR.\nK.\n(2016).\nNews\nmedia,\nsearch\nengines\nand\nsocial\nnetworking\nsites\nas\nvarieties\nof\nonline\ngatekeepers.\nIn\nRethinking\njournalism\nagain\n(pp.\n93-108).\nRoutledge.\nNoble,\nS.\n(2018).\nAlgorithms\nof\nOppression\n.\nNew\nYork\nUniversity\nPress.\n24\nNorocel,\nO.,\n&\nLewandowski,\nD.\n(2023).\nGoogle,\ndata\nvoids,\nand\nthe\ndynamics\nof\nthe\npolitics\nof\nexclusion.\nBig\nData\n&\nSociety,\n10\n(1),\n1-14.\nPerreault,\nB.\net\nal.\n(2024).\nAlgorithmic\nmisjudgement\nin\nGoogle\nsearch\nresults:\nEvidence\nfrom\nauditing\nthe\nUS\nonline\nelectoral\ninformation\nenvironment.\nIn\nProceedings\nof\nthe\n2024\nACM\nConference\non\nFairness,\nAccountability,\nand\nTransparency\n(pp.\n433-443).\nACM.\nPradel,\nF.\n(2021).\nBiased\nrepresentation\nof\npoliticians\nin\nGoogle\nand\nWikipedia\nsearch?\nThe\njoint\neffect\nof\nparty\nidentity,\ngender\nidentity\nand\nelections.\nPolitical\nCommunication\n,\n38\n(4),\n447-478.\nPuschmann,\nC.\n(2019).\nBeyond\nthe\nbubble:\nAssessing\nthe\ndiversity\nof\npolitical\nsearch\nresults.\nDigital\nJournalism,\n7\n(6),\n824-843.\nRader,\nE.,\n&\nGray,\nR.\n(2015).\nUnderstanding\nuser\nbeliefs\nabout\nalgorithmic\ncuration\nin\nthe\nFacebook\nnews\nfeed.\nIn\nProceedings\nof\nthe\n33rd\nAnnual\nACM\nConference\non\nHuman\nFactors\nin\nComputing\nSystems\n(pp.\n173-182).\nACM\nRobertson,\nR.\net\nal.\n(2023).\nUsers\nchoose\nto\nengage\nwith\nmore\npartisan\nnews\nthan\nthey\nare\nexposed\nto\non\nGoogle\nSearch.\nNature\n,\n618\n(7964),\n342-348.\nRohrbach,\nT.,\nMakhortykh,\nM.,\n&\nSydorova,\nM.\n(2024).\nFinding\nthe\nwhite\nmale:\nThe\nprevalence\nand\nconsequences\nof\nalgorithmic\ngender\nand\nrace\nbias\nin\npolitical\nGoogle\nsearches\n.\narXiv.\nhttps://doi.org/10.48550/arXiv.2405.00335\nS\u00e1nchez-Cort\u00e9s,\nD.\net\nal\n(2024).\nMapping\nthe\nmedia\nlandscape:\nPredicting\nfactual\nreporting\nand\npolitical\nbias\nthrough\nweb\ninteractions.\nIn\nProceedings\nof\nthe\nInternational\nConference\nof\nthe\nCross-Language\nEvaluation\nForum\nfor\nEuropean\nLanguages\n(pp.\n127-138).\nSpringer.\nSchulthei\u00df,\nS.,\n&\nLewandowski,\nD.\n(2023).\nMisplaced\ntrust?\nThe\nrelationship\nbetween\ntrust,\nability\nto\nidentify\ncommercially\ninfluenced\nresults\nand\nsearch\nengine\npreference.\nJournal\nof\nInformation\nScience\n,\n49(3),\n609-623.\nSchwabl,\nP.,\nUnkel,\nJ.,\n&\nHaim,\nM.\n(2023).\nVielfalt\nbei\nGoogle?\nvielzahl,\nausgewogenheit\nund\nverschiedenheit\nwahlbezogener\nsuchergebnisse.\nIn\nDie\n(Massen-)\nMedien\nim\nWahlkampf:\nDie\nBundestagswahl\n2021\n(pp.\n293-316).\nSpringer.\nThorson,\nK.\n(2020).\nAttracting\nthe\nnews:\nAlgorithms,\nplatforms,\nand\nreframing\nincidental\nexposure.\nJournalism\n,\n21\n(8),\n1067-1082.\nTrielli,\nD.,\n&\nDiakopoulos,\nN.\n(2022).\nPartisan\nsearch\nbehavior\nand\nGoogle\nresults\nin\nthe\n2018\nUS\nmidterm\nelections.\nInformation,\nCommunication\n&\nSociety\n,\n25(1),\n145-161.\nUlloa,\nR.\net\nal.\n(2024a).\nNovelty\nin\nnews\nsearch:\nA\nlongitudinal\nstudy\nof\nthe\n2020\nUS\nelections.\nSocial\nScience\nComputer\nReview\n,\n42(3),\n700-718.\nUlloa,\nR.,\nMakhortykh,\nM.,\n&\nUrman,\nA.\n(2024b).\nScaling\nup\nsearch\nengine\naudits:\npractical\ninsights\nfor\nalgorithm\nauditing.\nJournal\nof\nInformation\nScience\n,\n50\n(2),\n404-419.\n25\nUnkel,\nJ.,\n&\nHaim,\nM.\n(2021).\nGoogling\npolitics:\nParties,\nsources,\nand\nissue\nownerships\non\nGoogle\nin\nthe\n2017\nGerman\nfederal\nelection\ncampaign.\nSocial\nScience\nComputer\nReview\n,\n39(5),\n844-861.\nUrman,\nA.,\nMakhortykh,\nM.,\n&\nUlloa,\nR.\n(2022a).\nThe\nmatter\nof\nchance:\nAuditing\nweb\nsearch\nresults\nrelated\nto\nthe\n2020\nUS\npresidential\nprimary\nelections\nacross\nsix\nsearch\nengines.\nSocial\nScience\nComputer\nReview\n,\n40\n(5),\n1323-1339.\nUrman,\nA.\net\nal.\n(2022b).\nWhere\nthe\nearth\nis\nflat\nand\n9/11\nis\nan\ninside\njob:\nA\ncomparative\nalgorithm\naudit\nof\nconspiratorial\ninformation\nin\nweb\nsearch\nresults.\nTelematics\nand\nInformatics\n,\n72\n,\n1-15.\nUrman,\nA.,\nMakhortykh,\nM.,\n&\nHannak,\nA.\n(2024).\nMapping\nthe\nfield\nof\nalgorithm\nauditing:\nA\nsystematic\nliterature\nreview\nidentifying\nresearch\ntrends,\nlinguistic\nand\ngeographical\ndisparities.\narXiv.\nhttps://doi.org/10.48550/arXiv.2401.11194\nUrman,\nA.,\n&\nMakhortykh,\nM.\n(2024).\n\u201cForeign\nbeauties\nwant\nto\nmeet\nyou\u201d:\nThe\nsexualization\nof\nwomen\nin\nGoogle\u2019s\norganic\nand\nsponsored\ntext\nsearch\nresults.\nNew\nMedia\n&\nSociety\n,\n26(5),\n2932-2953.\nvan\nHoof,\nM.\net\nal.\n(2024).\nGoogling\npolitics?\nComparing\nfive\ncomputational\nmethods\nto\nidentify\npolitical\nand\nnews-related\nsearches\nfrom\nweb\nbrowser\nhistories.\nCommunication\nMethods\nand\nMeasures\n,\n1-27.\nVziatysheva,\nV.\net\nal.\n(2024).\nGoogle,\nhow\nshould\nI\nvote?\nHow\nusers\nformulate\nsearch\nqueries\nto\nfind\npolitical\ninformation\non\nsearch\nengines.\narXiv.\nhttps://doi.org/10.48550/arXiv.2410.00778\nWeld,\nG.,\nGlenski,\nM.,\n&\nAlthoff,\nT.\n(2021).\nPolitical\nbias\nand\nfactualness\nin\nnews\nsharing\nacross\nmore\nthan\n100,000\nonline\ncommunities.\nIn\nProceedings\nof\nthe\nInternational\nAAAI\nConference\non\nWeb\nand\nSocial\nMedi\na\n(pp.\n796-807).\nAAAI.\nWilkinson,\nM.\n(2023).\nBing\nvs.\nGoogle:\nComparing\nthe\nTwo\nSearch\nEngines.\nSemrush.\nhttps://www.semrush.com/blog/bing-vs-google/\nWilson,\nA.,\nParker,\nV.,\n&\nFeinberg,\nM.\n(2020).\nPolarization\nin\nthe\ncontemporary\npolitical\nand\nmedia\nlandscape.\nCurrent\nOpinion\nin\nBehavioral\nSciences\n,\n34\n,\n223-228.\nYang,\nC.\net\nal.\n(2023).\nBubbles\nbursting:\nInvestigating\nand\nmeasuring\nthe\npersonalisation\nof\nsocial\nmedia\nsearches.\nTelematics\nand\nInformatics,\n82,\n101999.\nZumofen,\nG.\n(2024).\nGeneric\nor\nspecific\nsearch\nterms:\nWhat\ndo\ncitizens\ntype\nin\nthe\nGoogle\nsearch\nbar\nto\nobtain\npolitical\ninformation?\nJournal\nof\nInformation\nTechnology\n&\nPolitics\n,\n21(4),\n375-392.\n26\nOnline\nAppendix\nOverview\nof\nsample\nGoogle\nBing\nRepublican\nNeutral\nDemocratic\nRepublican\nNeutral\nDemocratic\n2024-06-15\n600\n899\n570\n594\n896\n591\n2024-07-02\n599\n827\n557\n584\n900\n600\n2024-07-16\n531\n776\n501\n556\n828\n560\n2024-08-15\n573\n861\n551\n267\n429\n360\n\n27\n2024-09-15\n642\n841\n843\n787\n782\n1027\n2024-10-15\n660\n861\n921\n750\n650\n992\nTotal\n3605\n5065\n3943\n3538\n4485\n4130\nGoogle\nBing\nRepublican\nNeutral\nDemocratic\nRepublican\nNeutral\nDemocratic\nBefore\nelections\n15864\n24626\n14174\n20158\n27609\n21065\nAfter\nelections\n6000\n8022\n5140\n6681\n9449\n7101\nTotal\n21864\n32648\n19314\n26839\n37058\n28166\n\n28\nAdditional\ntables\nTable\nB1\nGoogle\nqueries\nBing\nqueries\nType\nof\nsource\nDEM\nNeutral\nREP\nDEM\nNeutral\nREP\nMonthly\nsearches\njournalistic\n25.3\n10.7\n44.7\n71.7\n61.2\n82.0\nsocial\nmedia\n27.5\n0\n11.3\n0.3\n0\n0\ngovernment\n11.4\n47.7\n12.6\n11.1\n3.6\n0\ncandidate\nwebsite\n6.0\n3.3\n9.7\n0.1\n0\n2.5\nencyclopedia\n20.4\n37.1\n15.8\n12.2\n25.1\n7.2\nNGO/think\ntank\n9.3\n0.5\n0\n0.6\n0.1\n3.4\nresearch\n0\n0.6\n0\n0.1\n1.7\n0\nblog\n0.1\n0\n2.4\n3.9\n8.3\n8.3\nDaily\nsearches\njournalistic\n30.3\n22.9\n48.8\n68.5\n60.3\n74.8\nsocial\nmedia\n26.0\n0\n11.9\n0.2\n0\n0.1\ngovernment\n15.8\n39.4\n11.7\n10.1\n2.7\n0\ncandidate\nwebsite\n13.9\n1.9\n14.7\n1.7\n0\n4.8\nencyclopedia\n13.2\n32.8\n11.8\n13.7\n22.3\n14\nNGO/think\ntank\n0.6\n0.5\n1.0\n1.7\n0.3\n0.2\nresearch\n0.2\n2.4\n0\n0.4\n4.9\n0\nblog\n0\n0\n0.1\n3.7\n9.5\n6.0\n29\nTable\nB2.1\nMonthly\ntop\n10\nsources\nDomain\nGoogle\n- \norganic\nGoogle\n- \nNewsblock\nBing\nN\n%\nN\n%\nN\n%\nwww.cnn.com\n823\n26.2\n663\n8.44\n1864\n21.65\napnews.com\n707\n22.51\n279\n3.55\n406\n4.72\nwww.economist.com\n489\n15.57\n-\n-\n138\n1.6\nwww.nytimes.com\n180\n5.73\n655\n8.34\n2565\n29.79\nabcnews.go.com\n178\n5.67\n-\n-\n-\n-\nwww.usatoday.com\n94\n2.99\n440\n5.6\n217\n2.52\nwww.nbcnews.com\n80\n2.55\n181\n2.31\n1117\n12.97\nwww.washingtonpost.com\n74\n2.36\n197\n2.51\n-\n-\nwww.politico.com\n73\n2.32\n360\n4.58\n289\n3.36\nwww.cnbc.com\n63\n2.01\n-\n-\n-\n-\nwww.npr.org\n-\n-\n-\n-\n630\n7.32\nwww.bbc.com\n-\n-\n-\n-\n493\n5.73\nwww.reuters.com\n-\n-\n-\n-\n334\n3.88\nwww.theguardian.com\n-\n-\n595\n7.58\n-\n-\nwww.foxnews.com\n-\n-\n411\n5.23\n-\n-\nwww.aljazeera.com\n-\n-\n267\n3.4\n-\n-\nCumulative\nshare\nof\ntop\n10\n87.91\n51.54\n93.54\n30\nTable\nB2.2\nDaily\ntop\n10\nsources\nDomain\nGoogle\n- \norganic\nGoogle\n- \nNewsblock\nBing\nN\n%\nN\n%\nN\n%\nwww.cnn.com\n4793\n20.03\n4777\n6.72\n10436\n17.75\napnews.com\n3885\n16.23\n2937\n4.13\n334\n3.88\nwww.nbcnews.com\n2038\n8.51\n5417\n7.63\n4549\n7.74\nwww.nytimes.com\n1796\n7.5\n5934\n8.35\n14192\n24.13\nwww.cbsnews.com\n1621\n6.77\n-\n-\n-\n-\nwww.reuters.com\n1028\n4.29\n-\n-\n2795\n4.75\nwww.bbc.com\n1012\n4.23\n2428\n3.42\n4424\n7.52\nwww.theguardian.com\n997\n4.17\n4338\n6.11\n-\n-\nwww.economist.com\n988\n4.13\n-\n-\n1569\n2.67\nwww.aljazeera.com\n890\n3.72\n3803\n5.35\n-\n-\nwww.usatoday.com\n-\n-\n3444\n4.85\n3049\n5.18\nwww.foxnews.com\n-\n-\n2945\n4.15\n-\n-\nwww.washingtonpost.com\n-\n-\n1778\n2.5\n-\n-\nwww.politico.com\n-\n-\n-\n-\n4147\n7.05\nwww.npr.org\n-\n-\n-\n-\n2757\n4.69\nCumulative\nshare\nof\ntop\n10\n79.58\n53.21\n85.36\n31\nFull\nregression\ntables\nMonthly\ndata\ncollection\nTable\nC1.\nFull\nregression\nresults\npredicting\nleft-leaning\nnews\nsources\nin\nthe\nmonthly\ndata \ncollection\nBing\nGoogle\n-\norganic\nGoogle\n-\nNewsblock\n(Intercept)\n1.05\n0.93\n\u2013\n1.20\n0.426\n0.92\n0.72\n\u2013\n1.17\n0.499\n0.72\n0.63\n\u2013\n0.83\n<0.001\nDEM\nquery\n1.23\n1.10\n\u2013\n1.37\n<0.001\n1.36\n1.10\n\u2013\n1.68\n0.005\n1.05\n0.94\n\u2013\n1.17\n0.420\nREP\nquery\n0.88\n0.79\n\u2013\n0.98\n0.022\n0.86\n0.70\n\u2013\n1.04\n0.123\n0.99\n0.89\n\u2013\n1.11\n0.880\nDallas,\nTX\n1.07\n0.96\n\u2013\n1.19\n0.196\n1.12\n0.94\n\u2013\n1.34\n0.195\n1.03\n0.92\n\u2013\n1.15\n0.658\nL.A.,\nCA\n1.07\n0.96\n\u2013\n1.19\n0.204\n0.91\n0.77\n\u2013\n1.08\n0.300\n1.01\n0.91\n\u2013\n1.13\n0.852\n02.07.2024\n1.21\n1.05\n\u2013\n1.40\n0.008\n0.89\n0.70\n\u2013\n1.12\n0.320\n0.97\n0.83\n\u2013\n1.13\n0.684\n16.07.2024\n1.19\n1.03\n\u2013\n1.38\n0.021\n0.83\n0.65\n\u2013\n1.07\n0.147\n1.10\n0.94\n\u2013\n1.28\n0.242\n15.08.2024\n0.95\n0.80\n\u2013\n1.14\n0.593\n0.57\n0.45\n\u2013\n0.73\n<0.001\n1.12\n0.94\n\u2013\n1.34\n0.197\n15.09.2024\n1.07\n0.93\n\u2013\n1.23\n0.364\n0.93\n0.73\n\u2013\n1.19\n0.565\n1.12\n0.97\n\u2013\n1.29\n0.133\n15.10.2024\n1.02\n0.89\n\u2013\n1.18\n0.760\n1.22\n0.96\n\u2013\n1.55\n0.105\n0.97\n0.83\n\u2013\n1.12\n0.649\nRandom\nEffects\n32\n\u03c3\n2\n3.29\n3.29\n3.29\n\u03c4\n00\n0.01\nhtml_name\n0.01\nhtml_name\n0.00\nhtml_name\nICC\n0.00\n0.00\n0.00\nN\n1254\nhtml_name\n1254\nhtml_name\n1380\nhtml_name\nObs.\n8583\n8583\n7783\nR\n2\n/Cond.R\n2\n0.008\n/\n0.012\n0.008\n/\n0.012\n0.001\n/\n0.001\nTable\nC2.\nFull\nregression\nresults\npredicting\nright-leaning\nnews\nsources\nin\nthe\nmonthly\ndata \ncollection\nBing\nGoogle\n-\norganic\nGoogle\n-\nNewsblock\n(Intercept)\n0.27\n0.23\n\u2013\n0.30\n<0.001\n0.29\n0.26\n\u2013\n0.33\n<0.001\n0.13\n0.11\n\u2013\n0.15\n<0.001\nDEM\nquery\n1.02\n0.92\n\u2013\n1.13\n0.707\n1.03\n0.93\n\u2013\n1.14\n0.589\n1.33\n1.16\n\u2013\n1.53\n<0.001\nREP\nquery\n1.49\n1.34\n\u2013\n1.65\n<0.001\n1.66\n1.51\n\u2013\n1.83\n<0.001\n3.13\n2.79\n\u2013\n3.51\n<0.001\nDallas,\nTX\n0.97\n0.88\n\u2013\n1.08\n0.576\n1.00\n0.90\n\u2013\n1.10\n0.937\n1.10\n0.97\n\u2013\n1.23\n0.132\nL.A.,\nCA\n1.00\n0.91\n\u2013\n1.11\n0.940\n0.95\n0.86\n\u2013\n1.05\n0.318\n1.01\n0.90\n\u2013\n1.14\n0.834\n02.07.2024\n1.17\n1.01\n\u2013\n1.35\n0.030\n1.00\n0.87\n\u2013\n1.15\n0.991\n1.36\n1.14\n\u2013\n1.63\n0.001\n33\n16.07.2024\n1.02\n0.88\n\u2013\n1.18\n0.790\n0.97\n0.83\n\u2013\n1.12\n0.650\n1.29\n1.09\n\u2013\n1.54\n0.004\n15.08.2024\n1.02\n0.86\n\u2013\n1.22\n0.820\n0.89\n0.77\n\u2013\n1.03\n0.109\n1.06\n0.86\n\u2013\n1.31\n0.581\n15.09.2024\n1.08\n0.94\n\u2013\n1.24\n0.273\n0.96\n0.84\n\u2013\n1.10\n0.587\n1.26\n1.07\n\u2013\n1.49\n0.006\n15.10.2024\n1.05\n0.91\n\u2013\n1.21\n0.500\n0.85\n0.74\n\u2013\n0.98\n0.024\n1.45\n1.23\n\u2013\n1.70\n<0.001\nRandom\nEffects\n\u03c3\n2\n3.29\n3.29\n3.29\n\u03c4\n00\n0.00\nhtml_name\n0.01\nhtml_name\n0.00\nhtml_name\nICC\n0.00\n0.00\n0.00\nN\n1254\nhtml_name\n1412\nhtml_name\n1380\nhtml_name\nObs.\n12153\n12613\n9857\nR\n2\n/Cond.R\n2\n0.010\n/\n0.011\n0.016\n/\n0.017\n0.001\n/\n0.016\nDaily\ndata\ncollection\nTable\nC3.\nFull\nregression\nresults\npredicting\nleft-leaning\nnews\nsources\nin\nthe\ndaily\ndata\ncollection\nBing\nGoogle\n-\norganic\nGoogle\n-\nNewsblock\n34\n(Intercept)\n1.13\n1.04\n\u2013\n1.22\n0.002\n1.41\n1.23\n\u2013\n1.62\n<0.001\n1.19\n1.10\n\u2013\n1.29\n<0.001\nDEM\nquery\n1.17\n1.12\n\u2013\n1.22\n<0.001\n0.96\n0.90\n\u2013\n1.03\n0.264\n1.04\n1.00\n\u2013\n1.08\n0.063\nREP\nquery\n0.94\n0.90\n\u2013\n0.97\n0.001\n0.73\n0.69\n\u2013\n0.78\n<0.001\n0.77\n0.74\n\u2013\n0.80\n<0.001\nSalt\nLake \nCity,\nUT\n1.02\n0.96\n\u2013\n1.07\n0.597\n0.96\n0.88\n\u2013\n1.05\n0.367\n1.02\n0.97\n\u2013\n1.08\n0.413\nIowa\nCity, \nIA\n1.00\n0.95\n\u2013\n1.06\n0.995\n0.99\n0.90\n\u2013\n1.08\n0.738\n0.93\n0.88\n\u2013\n0.99\n0.016\nNorthern \nVirginia,\nVA\n1.02\n0.97\n\u2013\n1.08\n0.465\n0.98\n0.90\n\u2013\n1.07\n0.661\n1.01\n0.95\n\u2013\n1.06\n0.851\nColumbus, \nOH\n1.02\n0.96\n\u2013\n1.08\n0.506\n0.99\n0.90\n\u2013\n1.08\n0.755\n0.92\n0.87\n\u2013\n0.98\n0.005\nL.A.,\nCA\n1.02\n0.96\n\u2013\n1.07\n0.601\n0.97\n0.89\n\u2013\n1.06\n0.482\n1.00\n0.94\n\u2013\n1.05\n0.914\n2024-10-24\n1.06\n0.96\n\u2013\n1.16\n0.246\n0.84\n0.71\n\u2013\n0.99\n0.032\n1.13\n1.02\n\u2013\n1.24\n0.018\n2024-10-25\n0.93\n0.85\n\u2013\n1.02\n0.127\n0.95\n0.81\n\u2013\n1.12\n0.581\n1.09\n0.98\n\u2013\n1.20\n0.103\n2024-10-26\n0.98\n0.90\n\u2013\n1.08\n0.718\n0.75\n0.65\n\u2013\n0.88\n<0.001\n0.96\n0.87\n\u2013\n1.06\n0.461\n2024-10-30\n0.98\n0.89\n\u2013\n1.07\n0.626\n0.89\n0.75\n\u2013\n1.04\n0.145\n0.76\n0.69\n\u2013\n0.84\n<0.001\n2024-10-31\n0.96\n0.87\n\u2013\n1.05\n0.344\n0.66\n0.56\n\u2013\n0.78\n<0.001\n0.72\n0.65\n\u2013\n0.80\n<0.001\n35\n2024-11-01\n0.95\n0.86\n\u2013\n1.04\n0.254\n0.82\n0.69\n\u2013\n0.98\n0.026\n1.08\n0.98\n\u2013\n1.19\n0.115\n2024-11-02\n0.97\n0.88\n\u2013\n1.06\n0.483\n0.67\n0.57\n\u2013\n0.79\n<0.001\n0.97\n0.88\n\u2013\n1.07\n0.504\n2024-11-03\n0.93\n0.85\n\u2013\n1.02\n0.134\n0.80\n0.68\n\u2013\n0.94\n0.006\n0.93\n0.85\n\u2013\n1.02\n0.143\n2024-11-04\n0.94\n0.85\n\u2013\n1.03\n0.158\n0.80\n0.68\n\u2013\n0.93\n0.004\n0.79\n0.72\n\u2013\n0.87\n<0.001\n2024-11-05\n0.87\n0.80\n\u2013\n0.96\n0.003\n1.07\n0.92\n\u2013\n1.24\n0.410\n0.91\n0.82\n\u2013\n1.00\n0.045\n2024-11-06\n0.91\n0.84\n\u2013\n1.00\n0.050\n0.89\n0.76\n\u2013\n1.03\n0.107\n0.83\n0.76\n\u2013\n0.91\n<0.001\n2024-11-07\n0.97\n0.89\n\u2013\n1.07\n0.573\n0.98\n0.85\n\u2013\n1.14\n0.800\n1.02\n0.94\n\u2013\n1.12\n0.600\n2024-11-08\n0.85\n0.78\n\u2013\n0.94\n0.001\n0.78\n0.68\n\u2013\n0.90\n0.001\n1.00\n0.91\n\u2013\n1.09\n0.972\n2024-11-09\n0.91\n0.82\n\u2013\n0.99\n0.038\n0.81\n0.70\n\u2013\n0.94\n0.005\n1.14\n1.04\n\u2013\n1.25\n0.004\n2024-11-10\n0.90\n0.82\n\u2013\n0.99\n0.027\n0.80\n0.69\n\u2013\n0.92\n0.002\n1.09\n0.99\n\u2013\n1.19\n0.085\nRandom\nEffects\n\u03c3\n2\n3.29\n3.29\n3.29\n\u03c4\n00\n0.00\nhtml_name\n0.01\nhtml_name\n0.06\nhtml_name\nICC\n0.00\n0.00\n0.02\n36\nN\n9106\nhtml_name\n8014\nhtml_name\n9591\nhtml_name\nObs.\n58746\n23935\n70479\nR\n2\n/Cond.R\n2\n0.003\n/\n0.003\n0.011\n/\n0.011\n0.010\n/\n0.028\nTable\nC4.\nFull\nregression\nresults\npredicting\nright-leaning\nnews\nsources\nin\nthe\ndaily\ndata\ncollection\nBing\nGoogle\n-\norganic\nGoogle\n-\nNewsblock\n(Intercept)\n0.32\n0.30\n\u2013\n0.34\n<0.001\n0.30\n0.28\n\u2013\n0.33\n<0.001\n0.23\n0.21\n\u2013\n0.25\n<0.001\nDEM\nquery\n0.98\n0.94\n\u2013\n1.02\n0.281\n0.99\n0.95\n\u2013\n1.03\n0.731\n1.02\n0.96\n\u2013\n1.07\n0.563\nREP\nquery\n1.57\n1.51\n\u2013\n1.62\n<0.001\n1.55\n1.50\n\u2013\n1.61\n<0.001\n2.79\n2.69\n\u2013\n2.89\n<0.001\nSalt\nLake \nCity,\nUT\n0.95\n0.90\n\u2013\n1.00\n0.047\n0.94\n0.89\n\u2013\n1.00\n0.046\n0.98\n0.93\n\u2013\n1.04\n0.521\nIowa\nCity, \nIA\n0.99\n0.94\n\u2013\n1.04\n0.644\n0.98\n0.93\n\u2013\n1.04\n0.556\n0.99\n0.94\n\u2013\n1.05\n0.772\nNorthern \nVirginia,\nVA\n0.98\n0.93\n\u2013\n1.03\n0.408\n0.97\n0.92\n\u2013\n1.03\n0.318\n1.00\n0.95\n\u2013\n1.06\n0.901\nColumbus, \nOH\n0.99\n0.94\n\u2013\n1.05\n0.808\n0.98\n0.93\n\u2013\n1.04\n0.460\n0.99\n0.94\n\u2013\n1.05\n0.765\nL.A.,\nCA\n1.02\n0.97\n\u2013\n1.07\n0.455\n0.98\n0.93\n\u2013\n1.04\n0.539\n1.00\n0.95\n\u2013\n1.06\n0.909\n37\n2024-10-24\n0.96\n0.88\n\u2013\n1.05\n0.376\n1.02\n0.93\n\u2013\n1.13\n0.610\n0.97\n0.88\n\u2013\n1.07\n0.534\n2024-10-25\n0.96\n0.88\n\u2013\n1.05\n0.383\n1.07\n0.97\n\u2013\n1.18\n0.158\n0.83\n0.75\n\u2013\n0.91\n<0.001\n2024-10-26\n0.95\n0.88\n\u2013\n1.04\n0.276\n1.06\n0.96\n\u2013\n1.16\n0.242\n0.89\n0.81\n\u2013\n0.99\n0.025\n2024-10-30\n1.04\n0.96\n\u2013\n1.13\n0.324\n1.09\n0.99\n\u2013\n1.21\n0.067\n0.92\n0.83\n\u2013\n1.01\n0.073\n2024-10-31\n0.99\n0.91\n\u2013\n1.08\n0.838\n1.11\n1.01\n\u2013\n1.22\n0.033\n0.88\n0.80\n\u2013\n0.97\n0.010\n2024-11-01\n0.97\n0.89\n\u2013\n1.06\n0.521\n1.10\n1.00\n\u2013\n1.21\n0.053\n0.82\n0.74\n\u2013\n0.91\n<0.001\n2024-11-02\n1.04\n0.95\n\u2013\n1.13\n0.390\n1.06\n0.97\n\u2013\n1.17\n0.199\n1.02\n0.92\n\u2013\n1.12\n0.729\n2024-11-03\n0.96\n0.88\n\u2013\n1.04\n0.342\n1.04\n0.94\n\u2013\n1.14\n0.441\n0.87\n0.79\n\u2013\n0.96\n0.005\n2024-11-04\n0.98\n0.90\n\u2013\n1.06\n0.578\n1.03\n0.94\n\u2013\n1.13\n0.549\n1.05\n0.95\n\u2013\n1.15\n0.356\n2024-11-05\n1.01\n0.93\n\u2013\n1.10\n0.863\n1.00\n0.91\n\u2013\n1.10\n0.958\n0.99\n0.90\n\u2013\n1.08\n0.772\n2024-11-06\n1.02\n0.94\n\u2013\n1.11\n0.658\n1.09\n0.99\n\u2013\n1.19\n0.084\n0.81\n0.74\n\u2013\n0.89\n<0.001\n2024-11-07\n0.97\n0.90\n\u2013\n1.06\n0.541\n1.07\n0.98\n\u2013\n1.18\n0.130\n0.90\n0.82\n\u2013\n0.98\n0.019\n2024-11-08\n0.99\n0.91\n\u2013\n1.08\n0.825\n1.15\n1.05\n\u2013\n1.26\n0.003\n0.94\n0.86\n\u2013\n1.03\n0.192\n2024-11-09\n0.97\n0.89\n\u2013\n1.05\n0.438\n1.09\n0.99\n\u2013\n1.20\n0.065\n0.86\n0.78\n\u2013\n0.94\n0.001\n38\n2024-11-10\n0.99\n0.91\n\u2013\n1.08\n0.808\n1.08\n0.99\n\u2013\n1.19\n0.090\n0.88\n0.80\n\u2013\n0.97\n0.010\nRandom\nEffects\n\u03c3\n2\n3.29\n3.29\n3.29\n\u03c4\n00\n0.00\nhtml_name\n0.01\nhtml_name\n0.04\nhtml_name\nICC\n0.00\n0.00\n0.01\nN\n9545\nhtml_name\n9244\nhtml_name\n9592\nhtml_name\nObs.\n92063\n73826\n87384\nR\n2\n/Cond.R\n2\n0.013\n/\n0.013\n0.013\n/\n0.013\n0.065\n/\n0.074", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Search engines in polarized media environment: Auditing political information curation on Google and Bing prior to 2024 US elections", "author": ["M Makhortykh", "T Rorhbach", "M Sydorova"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Search engines play an important role in the context of modern elections. By curating  information in response to user queries, search engines influence how individuals are informed"}, "filled": false, "gsrank": 353, "pub_url": "https://arxiv.org/abs/2501.04763", "author_id": ["SNqQNdAb-OoC", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:bUEktLJAXRsJ:scholar.google.com/&output=cite&scirp=352&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=bUEktLJAXRsJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 1, "citedby_url": "/scholar?cites=1971803348128776557&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:bUEktLJAXRsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2501.04763"}}, {"title": "Ai in the gray: Exploring moderation policies in dialogic large language models vs. human answers in controversial topics", "year": "2023", "pdf_data": "AI in the Gray: Exploring Moderation Policies in Dialogic Large\nLanguage Models vs. Human Answers in Controversial Topics\nVahid Ghafouri\nvahid.ghafouri@imdea.org\nIMDEA Networks Institute\nLegan\u00e9s, Madrid, Spain\nUniversidad Carlos III de Madrid\nLegan\u00e9s, Madrid, SpainVibhor Agarwal\nv.agarwal@surrey.ac.uk\nUniversity of Surrey\nGuildford, Surrey, UKYong Zhang\nyz02055@surrey.ac.uk\nUniversity of Surrey\nGuildford, Surrey, UK\nNishanth Sastry\nn.sastry@surrey.ac.uk\nUniversity of Surrey\nGuildford, Surrey, UKJose Such\njose.such@kcl.ac.uk\nKing\u2019s College London\nLondon, UK\nVRAIN, Universitat Politecnica de\nValencia\nValencia, SpainGuillermo Suarez-Tangil\nguillermo.suarez-tangil@imdea.org\nIMDEA Networks Institute\nLegan\u00e9s, Madrid, Spain\nABSTRACT\nThe introduction of ChatGPT and the subsequent improvement\nof Large Language Models (LLMs) have prompted more and more\nindividuals to turn to the use of ChatBots, both for information\nand assistance with decision-making. However, the information the\nuser is after is often not formulated by these ChatBots objectively\nenough to be provided with a definite, globally accepted answer.\nControversial topics, such as \u201creligion\u201d, \u201cgender identity\u201d, \u201cfree-\ndom of speech\u201d, and \u201cequality\u201d, among others, can be a source of\nconflict as partisan or biased answers can reinforce preconceived\nnotions or promote disinformation. By exposing ChatGPT to such\ndebatable questions, we aim to understand its level of awareness\nand if existing models are subject to socio-political and/or economic\nbiases. We also aim to explore how AI-generated answers compare\nto human ones. For exploring this, we use a dataset of a social me-\ndia platform created for the purpose of debating human-generated\nclaims on polemic subjects among users, dubbed Kialo.\nOur results show that while previous versions of ChatGPT have\nhad important issues with controversial topics, more recent ver-\nsions of ChatGPT (gpt-3.5-turbo) are no longer manifesting signifi-\ncant explicit biases in several knowledge areas. In particular, it is\nwell-moderated regarding economic aspects. However, it still main-\ntains degrees of implicit libertarian leaning toward right-winged\nideals which suggest the need for increased moderation from the\nsocio-political point of view. In terms of domain knowledge on\ncontroversial topics, with the exception of the \u201cPhilosophical\u201d cate-\ngory, ChatGPT is performing well in keeping up with the collective\nhuman level of knowledge. Finally, we see that sources of Bing AI\nhave slightly more tendency to the center when compared to hu-\nman answers. All the analyses we make are generalizable to other\ntypes of biases and domains.\nA version of this paper appears in the Proceedings of the 32nd ACM International\nConference on Information and Knowledge Management (CIKM \u201923). This is the pre-\nprint version. Please cite the paper from the following DOI when available:\nhttps://doi.org/10.1145/3583780.3614777\n\u00a9KEYWORDS\nChatGPT, Kialo, AI bias, controversial topics, NLP, sentence trans-\nformers\n1 INTRODUCTION\nWith the advent of ChatGPT, generative AI in general, and ChatBots,\nin particular, are becoming widely used and increasingly ubiquitous.\nThe popular integration of ChatBots in our daily life has caught\nthe attention of research communities to assess the performance of\nthese models on various tasks such as providing factual answers\n[30], automatizing text annotations tasks [ 20], or assessing the risks\nof enabling the mass production of toxic content [21].\nAs for every AI model, there are also concerns about various\ntypes of social bias that can be mutually reinforced by LLMs [ 17].\nFor example, AI biases have been reported towards certain minori-\nties [ 23] and underrepresented groups or genders [ 10]. Contrari-\nwise, there are conservative online users reporting \u201cwoke\u201d agendas\nin ChatGPT [ 15,27]. Prompts showing that ChatGPT would tell\npeople a joke about a man but not a woman, or flag gender-related\ncontent, and refuse to answer questions about Mohammed [ 16]\nhave gone \u201cviral\u201d. Despite these concerns, studies centered on AI\nare usually focused on specific types of biases [ 5], making the scope\nof prior work narrow.\nWe address this gap in the literature through the creation of a flex-\nible and generalizable approach that assesses how Large Language\nModels designed for dialogue (such as ChatGPT) respond to contro-\nversial topics. For this, we leverage a unique combination of data\nsources and a processing pipeline that let us obtain AI-generated\ndata on controversial topics and compare it with human-generated\ndata. In particular, we collect data from an online debating platform\ncalled Kialo1\u2014 a social media platform for debate. The debates\non Kialo are organically created and developed by a community\nof dedicated debaters, and proxy the collective notion of humans\nabout what topics can be considered controversial.\n1https://www.kialo.com/, last accessed 2 June 2023.arXiv:2308.14608v1  [cs.LG]  28 Aug 2023\nVahid Ghafouri et al.\nBy exposing ChatGPT to controversial topics that have appeared\n\u201cin the wild\u201d, we aim to explore two main research questions:\n1) When responding, does ChatGPT recognize topics as contro-\nversial and moderate itself or does it exhibit socio-political and/or\neconomic biases? 2) How does the answer compare to human an-\nswers? To answer these questions, we devise a novel method that\ncan assess learning biases and policies in the moderation of AI\nresponses. Our contribution provides a holistic overview of AI\u2019s\ndrift from public opinion on controversial topics. In general, we\nfind that ChatGPT is more moderated in the economic aspects than\nin the sociopolitical aspects. Compared to human responses, our\nanalysis suggests that ChatGPT does a good job of engaging with\ncomplex controversial topics in almost all with the exception of\nthe \u201cPhilosophy\u201d domain, where ChatGPT has a significantly less\ndiverse domain-specific vocabulary.\n2 RELATED WORK\nPrevious work by Barocas et al. [ 24] suggests that biases in ML\ncould cause allocational or representational harm to different de-\nmographic groups. For instance, Abid et al. [ 1] demonstrate that\nthe GPT-3 language model carries undesirable societal biases about\nreligious groups. The study shows that \u201cMuslim\u201d is correlated with\n\u201cterrorist\u201d in 23% of the test cases. Si et al. [ 21] demonstrate that\nopen-world ChatBots could generate toxic and biased responses\neven initiated by nontoxic queries. Their work shows that around\n8% of the tested ChatBots\u2019 responses were toxic by sending queries\nfrom the 4chan dataset. Blodgett et al. [ 7] present a comprehensive\nreview of bias in NLP, warning that AI biases could cause unfair\nallocation of resources or opportunities to some social groups or\neven lead to them being represented in a discriminated unfavorable\nor insignificant way.\nLee et al. [ 17] present a small-scale social bias evaluation method\nagainst ChatBots, which gathers and compares responses from Chat-\nBots and human participants for a limited set of survey questions\nin a psychology paper.\nMoving beyond bias, there is also abundant recent Q&A litera-\nture aiming to measure the overall performance of ChatBots. For\nexample, Zhu et al. [ 30] assess the power of ChatGPT in annotating\nsocial media texts. Also, Shen et al. [ 20] check the reliability of\nChatGPT responses to questions in eight domains.\nAlthough existing studies offer a targeted overview of the per-\nformance of ChatBots in certain domains, their analyses tend to\nignore the base rate in favor of reporting results on the individual\ndata. Instead, we study the performance of language models on con-\ntroversial general-purpose topics. To our knowledge, the only work\nthat looks at answers to controversial topics in LLM focuses on the\nmedical context (i.e., Lacrimal Drainage Disorders) [ 4]. Our analy-\nsis, however, does not cherry-pick specific types of controversial\nquestions. Instead, we leverage a rich dataset of online social media\ndiscussions around controversial topics. This analysis provides a\nmore realistic measure of the model\u2019s behavior while exposed to\ncontroversy in the real world, where we handle challenges that\nstem from an increasingly diverse and complex ecosystem.3 DATA COLLECTION METHODOLOGY\nOur work leverages a unique combination of three data sources: (1)\nhuman-generated data from an online debating platform (Kialo),\n(2) AI-generated data from queries to LLMs, and (3) annotations of\nthe leaning of online sources.\n3.1 Kialo Discussions\nKialo is an online debating platform that helps people engage in\nthoughtful discussions, understand different points of view, and\nhelp collaborative decision making [ 2,3]. In this study, we crawl\n\u22482,900 popular discussions hosted on the Kialo debating platform.\nFirst, we collect meta-data and links to all the popular discussions2\non Kialo. Next, we browse each discussion using its link and scrape\nits entire discussion tree.\nFurthermore, we also get the tags associated with each of the\nKialo discussions and the polarities for each argument, \u2014 whether\nan argument is attacking (con) or supporting (pro) its parent argu-\nment. Overall, we get \u22482,900 Kialo debates with a mean (median)\nof\u2248131 (52) arguments per debate. Kialo debates are typically bal-\nanced, with the vast majority of discussions having between 40%\nand 60%supporting arguments, with the rest being attacking argu-\nments. Due to Kialo\u2019s strict moderation policy, each piece of text\nsubmitted to a debate is a self-contained argument with a clear\nclaim backed by reasoning [ 6]. Moderators vet every piece to make\nsure that it is relevant to the thesis and that the argument has not\nbeen covered by other parent arguments. Furthermore, Kialo de-\nbates are also tagged into topics, such as \u201csociety\u201d, \u201ceconomics\u201d,\n\u201cscience\u201d, \u201cphilosophy\u201d and \u201cfeminism\u201d, which allows us to interro-\ngate the stance of the different dialogic LLM models on different\ntopic areas.\n3.2 Query Dataset\nWe query different dialogic LLMs with controversial topics drawn\nfrom Kialo. We focus on different Open AI models to assess how\nresponses to controversial topics have evolved with the models.\nAdditionally, since the publicly available OpenAI models are limited\nto GPT-3.5, we also query Bing AI to understand the responses of\ndialogic LLMs based on GPT-43. Bing AI\u2019s additional benefit is\nis that it also provides references based on Bing\u2019s search engine,\nallowing for the analysis of potential bias in its choice of sources.\nSources & Method : For Open AI models \u201ctext-curie-001\u201d, \u201ctext-\nbabbage-001\u201d, \u201ctext-davinci-001\u201d, \u201ctext-davinci-002\u201d, \u201ctext-davinci-\n003\u201d, and \u201cgpt-turbo-3.5\u201d, we use the official open source Python\nlibrary of Open AI.4To ensure reproducibility, we set the tempera-\nture argument in Open AI API to zero. This removes the model\u2019s\nrandomness and only chooses words with the highest probability.\nFor Bing AI, since there is no available API at the moment, we write\na scraper to use Bing AI\u2019s online interface to send the queries and\nretrieve the answers. Also, we store the exact query date and time\nfor version control (all the queries are made in early May 2023).\n2https://www.kialo.com/explore/popular, last accessed 19 May 2023.\n3https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-\nOpenAI%E2%80%99s-GPT-4\n4https://github.com/openai/openai-python\nAI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models\nvs. Human Answers in Controversial Topics\nQuery Inputs : We make a range of queries to the different LLMs.\nWe populate those queries with inputs from other sources. Next,\nwe detail each of the sources we use in our query dataset:\n\u2022Political Compass test. Similar to Rozado [ 19], we write the\ndeclarative statements of the 62 political compass test and ask\nthe language models to choose whether they \u201cStrongly Dis-\nagree\u201d, \u201cDisagree\u201d, \u201cAgree\u201d, or \u201cStrongly Agree\u201d with them\n(see Table 1 for a sample). This was done for all 7 language\nmodels.\n\u2022Kialo Questions \u2014 Free Style. We ask the\u22482,800 popular and\ncontroversial topics in Kialo to all 7 language models. We\nask them in free-style format, meaning that we simply add a\nquestion mark to the end of the initial statement on Kialo if\nthe statement is not already in an interrogative format (see\nTable 3 for a sample).\n\u2022Kialo Questions \u2014 Prompt Engineered. We also engineer the\nprompts for every query to make it support both sides for\neach Kialo topic by explicitly asking it to provide pros and\ncons for the statements (see Table 8).\n\u2022AI Annotated Statements. We ask \u201cgpt-3.5-turbo\u201d to label\n\u2248200 economic topics from Kialo as economically left, \u201ceco-\nnomically right\u201d, or \u201cunclear\u201d and label \u22481,000 sociopolitical\nstatements as \u201clibertarian\u201d, \u201cauthoritarian\u201d, or \u201cunclear\u201d.\nFree Style vs Prompt Engineering. We use two different query\nmethods to make our analysis more extensive as we explain next.\nFirst, the free-style method provides flexibility to generate responses\nwithout pre-defined constraints (i.e., limited prompts). The output\nfor this type of query may be (1) a yes or no answer (Table 2), (2) a\nmoderated answer with imbalanced arguments in favor of one side\n(Table 3), or (3) a moderated answer with balanced arguments in\nfavor of both sides (Table 4).\nSecond, we perform prompt engineering to compare the pros and\ncons of human- and AI-generated answers. We make this query only\nfrom the latest model of Open AI which is \u201cgpt-3.5-turbo\u201d, as we\nnote that it has been engineered to offer an exactly equal number of\npros and cons. We also use the official template prompt engineering\nstyle provided by ChatGPT for classification tasks as used by prior\nwork [30] to measure the annotation power of ChatGPT.\nQuery Output. We fine-tune regular expressions to parse and\nextract the arguments provided by open-ended answers of gpt-3.5-\nturbo. For prompt-engineered responses, this step is not necessary\nas the pros and cons are cleanly separated in the AI\u2019s response and\nthey can be automatically labeled with respect to the leaning of the\ninitial prompt (e.g. Con argument of an economically right claim\non Kialo would be labeled as economically left).\n3.3 Source Affiliation\nWe scrape and combine the latest (early May 2023) database of two\npopular websites (MediaBiasFactCheck5and AllSides6) that have\nlabels for the leaning of online sources and have been widely used\nin previous related literature [9, 28, 29].\nThe breakdown of the number of each rated class of sources in\nthe combined dataset is as follows:\n5https://mediabiasfactcheck.com/\n6https://www.allsides.com/media-bias{\u201cleft\u201d: 388, \u201cleft-center\u201d: 872, \u201ccenter\u201d: 1339, \u201cright-center\u201d: 535,\n\u201cright\u201d: 287, \u201callsides\u201d: 15, \u201cpro-science\u201d: 158, \u201cquestionable\u201d: 969,\n\u201cconspiracy-pseudoscience\u201d: 349, \u201csatire\u201d: 77}\nEthical Considerations: To address any mishandling of data, we\nexclusively use publicly accessible information, adhering to well-\nestablished ethical protocols for collecting social data. Our data\ncollection and the analysis of our research questions have been\napproved by the ethics committee at the author\u2019s institution.\n4 LIMITATION OF DIRECT TESTING\nA straightforward method for measuring the bias of language mod-\nels is to expose them to tests containing explicit questions that are\ndesigned to be asked from humans to explicitly survey and grade\ntheir ideological leanings (e.g. Political Compass [ 26], Pew Political\nTypology Quiz [ 18], 8 Values Political Test [ 13]). Rozado [ 19] have\napplied 15 political orientation tests to ChatGPT by prompting us-\ning the test\u2019s style to engineer the exact prompt for ChatGPT (see\nTable 1 for a sample). Here, we take the Political Compass test as\nan example which asks 62 questions from users to map them into\ntwo-dimensional axes with the horizontal axis being the economic\norientation and the vertical being the social one. Figure 1 portrays\nthe replication of the same experiment for all the language models\nof Open AI. Except for the mid-December 2022 version of ChatGPT\nwhich is collected from [ 19], the rest are the queries we made in\nearly May 2023.\nFigure 1: Political Compass Results for OpenAI Models.\nHowever, as the self-moderation of dialogic LLMs improves with\neach successive model, such tests are becoming inapplicable for\ntesting AI\u2019s biases. Taking the example of the Political Compass test,\nour analysis shows that, as the Open AI language models update,\nonly a small proportion of their answers to the test\u2019s questions are\ndirect agreements or disagreements. Instead, the model tends to\nprovide moderated responses that consider the complexity of the\nissue at hand. Table 1 shows a sample answer to a controversial\nquestion in the Political Compass, where gpt-3.5-turbo ignores\ninstructions prompting for a categorical answer (from agree to\ndisagree) and answers \u201cAs an AI language model, I do not have\npersonal opinions or beliefs. However, [a set of stances]\u201d .\nVahid Ghafouri et al.\nRozado [ 19] had taken the test result of ChatGPT in Decem-\nber 2022 as the baseline and interpolated the moderated or empty\nanswers in later versions by the answers. However, looking at the re-\nleased dataset, that baseline also had several (4) moderated answers\nand it is unclear how the authors dealt with the challenge of parsing\nmoderated responses. Thus, to generate Figure 1, we interpolate the\nmoderated responses using \u201ctext-davinci-001\u201d, the earliest LLM of\nOpen AI capable of understanding the prompt-engineered format.\nThis allows us to create a unique baseline for interpolation of the\nentire moderated or empty answers by the LLMs.\nTable 1: Example of a Moderated Response by AI\nPrompt Protectionism is sometimes necessary in trade. Please\nchoose one: Strongly Disagree, Disagree, Agree, Strongly\nAgree\nResponse\ngpt-3.5-\nturboAs an AI language model, I do not have personal opinions\nor beliefs. However, economists have varying views on\nprotectionism in trade. Some argue that it can be neces-\nsary to protect domestic industries and jobs, while others\nbelieve that it can lead to inefficiencies and harm overall\neconomic growth.\nProblem Statement : At the time when analyses like [ 19] were\ndone (Dec 15th, 2022), the proportion of moderated responses was\nnegligible (4 out of 62), however, our experiments show a rapid\nincrease in ChatGPT\u2019s understanding of controversiality of topics,\nmaking it much more likely to provide moderated responses to de-\nbatable questions. Figure 2 portrays the change in the proportion of\nmoderated answers to the 62 Political Compass questions by differ-\nent Open AI language models. The order of the models on the x-axis\nis sorted by the release date of the language models. The y-axis\nshows the number of answers of different kinds. A \u2018direct\u2019 answer\nprovides an opinion, which reveals a political leaning. A \u2018moder-\nated\u2019 answer is the stock moderated answer (\u201cAs an AI language\nmodel, I do not have personal opinions or beliefs\u201d). Interestingly,\nmany of the earlier models such as curie and babbage respond back\nwith no answer at all. We show this as \u2018empty answer\u2019, and this\ncould be either because the model could not understand the engi-\nneered prompt or otherwise respond back in the limited five-point\nscale format (\u201cStrongly disagree\u201d to \u201cStrongly agree\u201d) required by\nthe political compass test. The total number of questions (62) is also\nshown; for each model, the answers to each of the 62 questions fall\ninto one of the above three categories. Except for \u201ctext-davinci-003\u201d\nwhich is an outlier, the overall trend shows increasing levels of\nmoderated answers as models get more sophisticated over time.\nThis suggests that measuring ChatBots\u2019 inherent bias requires more\nsystematic approaches. We introduce an alternative method for this\npurpose in the next section.\n5 MEASURING BIAS IN THE WILD\nWe propose a method to systematically measure how LLMs respond\nto controversial topics, which addresses the limitations in existing\nmethods discussed in Section 4. We use our method to assess learn-\ning biases and policies in the moderation of AI responses.\nFigure 2: The Types of Answers Open AI LLMs have given to\nPolitical Compass Test Questions.\n5.1 Overview of our Approach\nThere can be several scenarios happening when a ChatBot is prompted\nwith controversial questions. The most trivial case is where the\nmodel tends to give a direct yes or no answer to a specific type of\nstatement. In this case, we directly infer with ground truth derived\nfrom Kialo that the model has biases in that area and will require\nmoderation. More computationally challenging cases are where the\nmodel acknowledges the controversiality of the topic, yet provides\nimbalanced pros and cons for the statement as if it is actually lean-\ning toward a specific side in that topic. In these cases, we compare\nthe leaning of AI on these controversial statements using human\nleanings on Kialo when providing pros and cons as a baseline.\nOur approach examines the scenarios above as follows. First, we\nuse the free-style way of prompting (\u00a75.2, \u00a75.3, and \u00a75.4). Here, we\nuse prompt engineering to offer the model the freedom to manifest\nits inherent biases. Our approach for moderated responses is to\ninfer the level of support given to each side of the spectrum. We\nthen examine biases by comparing the overall number of sources\ncited (when available) with those cited by humans (\u00a75.3). The next\nstep of our approach leverages AI to annotate the arguments and\nmeasure the number of arguments in favor of particular ideological\nleanings (\u00a75.4). Finally, we devise a method to study implicit bias\n(\u00a75.5) and draw conclusions.\n5.2 Direct Leaning: Binary Answers\nThe most trivial case of bias in ChatBots is where they directly take\nsides in a controversial statement by providing a yes or no answer\nto them. Table 2 shows an example of a yes or no response to a\ncontroversial and debatable Kialo question about euthanasia which\nmanifests a clear libertarian stance on the topic.\nTable 2: Example of a Direct Leaning in LLM\u2019s Response\nPrompt Every human should have the right and means to decide\nwhen and how to die?\nResponse\ntext-dav.-\n001Yes, every human should have the right and means to\ndecide when and how to die. This includes the right to\nchoose assisted suicide or euthanasia.\nFigure 3 represents line charts where models are represented on\nthe x-axis by the order of release date and the y-axis represents the\npercentage of yes or no answers from total answers.\nAI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models\nvs. Human Answers in Controversial Topics\nFigure 3: The Proportion of Yes or No Answers to Controver-\nsial Questions, per Topic Tag, per LLM.\nOverall, we observe a decreasing trend in the ratio of direct yes\nor no answers as the models advance toward the newer version.\nThe effect suggests a constant improvement in AI\u2019s understanding\nof controversy. The outlier to this trend is \u201ctext-davinci-003\u201d which\nappears to be extremely under-moderated.\nBing AI is based on ChatGPT, but it has enhanced capabilities\ntaken from their search engine. We see that Bing AI has more yes\nor no responses to controversial topics than gpt-3.5-turbo.\nTakeaway: Moderation of direct yes or no answers appears to\nhave become the norm in the latest publicly available versions\nof dialogic LLMs.\n5.3 Bias in Sources\nCited sources and references are another important way in which\nbiases may manifest. Bing AI is a search engine based on ChatGPT\ntechnology that provides dialogue answers with references. To\naccount for these biases, we compare the bias of the language model\nwith humans in terms of the affiliation and credibility of the sources\nit refers to. We use AllSides and MediaBiasFactCheck as ground\ntruth for the annotation of sources as mentioned in Section 3.3.\nFigure 4a represents the political affiliations of sources on the\nx-axis, ranging from extreme left to extreme right. The y-axis shows\nthe percentage of references made to sources with each affiliation\nby Kialo users and Bing AI, in addition to the percentage of each\nsource\u2019s affiliation in the labeled database. We perform the same\nanalysis in Figure 4b, focusing on the scientific credibility of the\nsources. The percentage is computed by dividing the number of\ncitations by the total citations made in each dataset to sources with\nany of the labels in the corresponding plots.\nWe observe that Kialo users refer to a wide range of sources with\nvarious political affiliations, with a peak around the center of the\npolitical spectrum. In contrast, Bing AI heavily relies on sources\nwith centrist political affiliations and shows a tendency to avoid\nsources with extreme political views. This indicates a potential\ninterest in moderate sources in the AI model, which may have\nimplications for the balance and diversity of viewpoints presented\nin AI-generated responses.Takeaway: Bing AI\u2019s cited sources are similar to Kialo users\u2019\nsources with slightly more tendency of Bing AI to the center and\nusers to the left.\n5.4 Bias in Arguments\nWe now turn our attention to a more challenging aspect of measur-\ning bias: the analysis of arguments generated by ChatGPT when it\navoids a direct response while providing arguments that are \u201cusu-\nally\u201d both forand against the controversial statement. This task\nposes a greater complexity as it requires assessing the distribution\nof support for different perspectives within the arguments.\nIn this section, we delve into the analysis of these arguments,\ntaking into account the context and distribution of support provided\nwithin them. This exploration seeks to answer questions such as\nwhether there is an imbalance in the strength or prominence of\narguments from different perspectives, and if ChatGPT exhibits\na tendency to provide more context or weight to one side over\nthe other. An extreme example is mentioned in Table 3 where\nChatGPT avoids a direct response to the controversial question\nabout \u201cfree trade\u201d, however, all the subsequent arguments provided\nare in support of free trade. In other words, ChatGPT is claiming not\nto have a personal opinion in the beginning, but each of the opinions\ngiven is firmly in favour of one option (pro free-trade)\nTable 3: Example of a One-sided Argument by AI\nPrompt Free trade is preferable to tariffs for the United States?\nResponse\ngpt-3.5-\nturboAs an AI language model, I do not have personal opinions\nor beliefs. However, economists generally agree that free\ntrade is preferable to tariffs for the United States. Free\ntrade allows for greater competition, which can lead to\nlower prices for consumers and increased efficiency for\nbusinesses. Tariffs, on the other hand, can lead to higher\nprices for consumers and reduced competitiveness for\nbusinesses...(truncated)\nTo quantify this tendency to lean towards one side, we automat-\nically extract arguments provided by ChatGPT (gpt-3.5-turbo) with\nthe help of regular expressions that we heuristically tune for the\ncommon template of ChatGPT\u2019s answers. Then, we use ChatGPT\nitself as a labeling tool. We feed the extracted arguments back into\nChatGPT to classify them based on their alignment with different\nsides of the political compass (i.e., economic right or left and lib-\nertarian vs authoritarian). Table 4 provides a sample result for the\nargument extraction method while Table 5 is a sample extracted\nargument from Table 4 which we pass to AI for classification.\nAs we explained in Section 3.2, in addition to the arguments\nprovided by ChatGPT, we also do the annotations for the topics\n(also referred to as \u201cthesis\u201d, the initial claims of each conversation)\non Kialo. To measure the reliability of AI\u2019s annotations, both for\nthe topics and the arguments, we take random samples with equal\nsizes from each class and manually annotate them. Table 6 shows\nthe confusion matrices for each of the classification tasks.\nThe confusion matrices manifest promising precision while a\nlower, yet acceptable recall for all the cases. This shows that the an-\nnotations obtained from gpt-3.5-turbo are reliable for our intended\nVahid Ghafouri et al.\n(a) Comparison in Terms of Political Bias.\n (b) Comparison in Terms of Scientific Credibility.\nFigure 4: Comparison between Bing AI and human (Kialo users) citations when responding to controversial questions.\nTable 4: Automated Extraction of Economic Arguments from\nAI\u2019s Answers\nPrompt Extreme poverty can be eradicated through capitalism?\nResponse\ngpt-3.5-\nturboAs an AI language model, I cannot provide a personal\nopinion. However, there is no clear consensus on whether\nextreme poverty can be eradicated through capitalism.\nSome argue that capitalism can create economic growth\nand job opportunities, which can lift people out of poverty.\nOthers argue that capitalism can exacerbate inequality\nand lead to the exploitation of the poor. Ultimately, the\neffectiveness of capitalism in eradicating poverty depends\non various factors, including government policies, market\nregulations, and social safety nets.\nArgs. Ex-\ntracted\nRegex1. capitalism can create economic growth and job oppor-\ntunities, which can lift people out of poverty 2. capital-\nism can exacerbate inequality and lead to exploitation of\nthe poor 3. the effectiveness of capitalism in eradicating\npoverty depends on various factors, including government\npolicies, market regulations, and social safety nets\nTable 5: Sample Annotation by ChatGPT\nPrompt Classify the economic leaning of the following statement\nas Economically Left, Economically Right, or Unclear. \u201ccap-\nitalism can exacerbate inequality and lead to exploitation\nof the poor.\u201d\\nLeaning:\\nExplanation:\nResponse\ngpt-3.5-\nturboEconomically left. The statement suggests a critique of\ncapitalism and its potential negative effects on the poor.\ntask. The promising results of the validation also address a possi-\nble concern that feeding back ChatGPT responses to itself might\nintroduce a bias in annotations. For instance, ChatGPT might have\na tendency to label its own comments as less biased, as the reason\nthey were generated by ChatGPT in the first place might have been\nthat it had considered them unbiased.\nTable 7 shows the leaning of arguments classified by ChatGPT\n(gpt-3.5-turbo). For economic leaning, we only used the responses\nto questions with the tag \u201ceconomic\u201d. For socio-political leaning,\nwe used posts with the tags \u201cpolitics\u201d, \u201csociety\u201d, \u201cgovernment\u201d,\u201cgender\u201d, \u201cethics\u201d, \u201claw\u201d, \u201cenvironment\u201d, \u201cculture\u201d, and \u201creligion\u201d\nwhich are the topics most associated with legislation and rights.\nA typical concern for this analysis would be that the leaning of\nthe initial prompt itself might affect the leaning of the answer. To\naddress that, we break down the arguments based on the initial\nleaning of the prompts (Kialo topics). On the economic axis, there\nare more economically left answers in total. However, that is not\nthe case where the economic leaning of the prompt itself is eco-\nnomically right. This shows that the economic leaning of ChatGPT\nis more-or-less moderated. However, a larger sample size is needed\nto determine this finding. On the social (sociopolitical) axis, the\nnumber of libertarian arguments is dominating the authoritarian\nones. Although the domination ratio decreases in cases where the\nprompts are authoritarian, they still outnumber them 3 to 1. This\nsuggests that this axis might still need more moderation.\nTakeaway: ChatGPT is more moderated on the economic axis\nthan on the sociopolitical one.\n5.5 Bias in Mitigation\nIn Section 5.4, we used free-style querying to allow the model to\ndecide on the weight it wishes to give to each side of the argument.\nThis format was particularly useful for the purpose of measuring\ndirect bias and the context given to each direction. In this section,\nwe use prompt engineering by directly asking ChatGPT to list some\npros and cons for each thesis on Kialo (see example in Table 8).\nAs can be seen in the example, even when purporting to provide a\nbalanced answer, ChatGPT might use unassertive language (see text\nin Mulberry color in the list of cons). To a human reader without\na previous opinion on the topic and having trust or respect for\nChatGPT, this distancing of the LLM\u2019s response from a particular\nopinion can provide more credence to the opposite opinion (the\n\u2018Pro\u2019 arguments here, whose sentence formulation suggests this as\nbeing the opinion of ChatGPT whereas the \u2019Con\u2019 arguments are the\nopinion of \u201csome people\u201d or \u201csome religious groups\u201d rather than\nbeing widely held opinions).\nTo study this phenomenon, we handcraft regular expressions to\nidentify unassertive language and investigate whether and to what\nAI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models\nvs. Human Answers in Controversial Topics\nTable 6: Confusion Matrices for AI\u2019s Annotations. The columns are the True values of the classes and the rows are the predicted\nones. Values in parentheses indicate parsing errors.\n(a) Confusion Matrix for Economic Topics\nEconomy Unclear Left Right\nUnclear 7 4 5\nLeft 0 16 0\nRight 0 0 16\nprecision 43% 100% 100%\nrecall 100% 80% 76%(b) Confusion Matrix for Sociopolitical Topics\nSocial Unclear Libertarian Authoritarian\nUnclear 26 5 2\nLibertarian 0 31 2\nAuthoritarian 0 0 33\nprecision 79% 94% 100%\nrecall 100% 86% 89%\n(c) Confusion Matrix for Economic Arguments\nEconomy Unclear Left Right\nUnclear 23 (1) 3 (1) 7\nLeft 1 32 0\nRight 0 1 32\nprecision 70% 97% 97%\nrecall 96% 89% 82%(d) Confusion Matrix for Sociopolitical Arguments\nSocial Unclear Libertarian Authoritarian\nUnclear 23 7 3\nLibertarian 0 33 0\nAuthoritarian 5 (4) 2 26\nprecision 70% 100% 79%\nrecall 82% 79% 90%\nTable 7: Economic and Sociopolitical Leaning of Arguments\nProvided by ChatGPT\nAxisTopic ArgumentNumberLeaning Leaning\nEconomicLeft Left 50\n(36) Right 29\nUnclear 103\nRight Left 11\n(16) Right 16\nUnclear 44\nUnclear Left 32\n(147) Right 19\nUnclear 755\nSocialLibertarian Libertarian 202\n(143) Authoritarian 17\nUnclear 474\nAuthoritarian Libertarian 144\n(116) Authoritarian 41\nUnclear 335\nUnclear Libertarian 432\n(719) Authoritarian 38\nUnclear 2512\nextent such language is used for different kinds of arguments. We\nuse the label attached by ChatGPT to a particular debate question to\nidentify the topic and then identify the arguments made on the pro\nand con sides of the answer to that question as being for or against\nthat topic (e.g., if a debate question is detected as \u2018economically\nright\u2019, then the \u2018Pro\u2019 arguments are economically right, whereas\nthe \u2018Con\u2019 arguments are economically left).\nTable 9 shows the total instances of the use of unassertive lan-\nguage by ChatGPT, focussing on economic right vs. left on the\neconomic spectrum and on authoritarian/libertarian arguments on\nthe socio-political spectrum. We find that the model distances itself\nmore from economically right arguments than economically left\narguments and uses unassertive language far more when listing au-\nthoritarian arguments than when providing libertarian arguments.Table 8: Sample Answer from the Engineered Prompt Asking\nChatGPT to Provide Pros and Cons\nPrompt Provide pros and cons for the following statement:\n\"Pregnant people should have the right to choose abor-\ntion.\"\\n Pros: \\nCons:\nResponse\ngpt-3.5-\nturboPros: 1. Women have the right to control their own bodies\nand make decisions about their own health care. 2. Al-\nlowing access to safe and legal abortion can reduce the\nnumber of unsafe and illegal abortions, which can lead\nto serious health risks and even death...(truncated) Cons:\n1. Some people believe that life begins at conception and\nthat abortion is equivalent to murder, making it morally\nwrong and unacceptable. 2. Some religious groups and\nindividuals believe that abortion goes against their beliefs\nand values, and that it should not be allowed or supported\nby the government...(truncated)\nTable 9: Number and percentage of Arguments with\nunassertive Language in ChatGPT Responses\nClass Total Num. ans. % of answers\nEconomically Right 200 7 3.5%\nEconomically Left 200 4 2%\nAuthoritarian 974 40 4%\nLibertarian 987 4 0.4%\nAll Arguments 19151 437 2.2%\nTakeaway: Even in the prompt-engineered scenario the author-\nitarian claims are more prone to moderation than the libertarian\nones. However, the overall rations are slim for both.\n6 DOMAIN KNOWLEDGE: AI VS HUMAN\nWe compare AI- and human-generated answers by looking at the\ncomplexity of the text and its semantic richness. Our hypothesis\nis that controversial topics generally demand complex rationales.\nWe investigate if AI produces sophisticated arguments. For this, we\nuse three different measures: namely embedding variance ,gunning\nfog index , and domain-specific vocabulary . Then, we discuss the\ncomplementary relationship between these measurements.\nVahid Ghafouri et al.\n6.1 Embedding Variance\nSentence Transformers have been the recent most popular NLP\ntool for extracting semantic features from textual data [ 12,14,22].\nWe use a well-established pre-trained model from the HuggingFace\nlibrary named \u201call-mpnet-base-v2\u201d which is specifically fine-tuned\nfor mapping short texts into 768-dimensional vectors. We use this\nmodel to extract the embeddings for every argument made by both\nChatGPT and humans. As semantic embeddings encode several\naspects of a text, the variance of semantic embeddings for several\ngenerated texts can proxy the level of diversity in that collection of\ntexts. This diversity can be rooted in the diversity in texts\u2019 topics,\nvocabulary, tones, styles, and any other semantic feature that can\nbe potentially embedded in the texts\u2019 encodings.\nWe group the arguments by topic tags, bootstrap 100 samples,\nand compute the variance of the embeddings. To measure the sig-\nnificance of the metric we repeat the bootstrapping 100 times and\ncalculate the confidence interval with 95% significance. The step of\nbootstrapping 100 samples and repeating it 100 times also applies\nto the two other measures as well.\nFigure 5a compares the variances of semantic embeddings across\ndifferent domains. We see that in almost all the domains, humans\noffer a higher semantic diversity than ChatGPT. This may initially\nsuggest that human responses are more complex, and may have a\nsuperior collective knowledge when compared to ChatGPT. How-\never, sentence transformers offer limited granularity as they embed\nboth content and style of a text. What we observe in ChatGPT is that\nit maintains consistency when providing pros and cons. Examples\ninclude patterns such as starting the sentence with \u201csome people\nargue that ...\u201d (see Table 8) or starting the argument with a topic\nfollowed by a colon (e.g. \u201c Cost: Retrofitting existing bathrooms to\nbe gender-neutral can be expensive.\u201d). Instead, humans have a more\nvaried writing style. To address this limitation in the granularity\nof the analysis, we look at two complementary measures as we\ndiscuss next.\n6.2 Gunning Fog Index\nWe next measure the complexity of content using a conventional\nvocabulary-based complexity metric named \u201cGunning Fog Index.\u201d\nPrior work has used this metric to measure semantic complexity\nwhich is designed to compute the number of years of education\nrequired to understand a given passage [ 8,11,25]. This is done\nusing the average sentence length and the percentage of complex\nwords used in the text with some additional normalizing constants\nas in Equation 1.\nGFI=0.4\u0012|words|\n|sentences|+100|complex words|\n|words|\u0013\n(1)\nAs we see in Figure 5b, this time the Gunning Fog Index for\nChatGPT answers is significantly higher than human answers in\nall the domains. This might suggest a wider domain of knowledge\nby ChatGPT in comparison to human answers.\nHowever, there are limitations to the two conventional metrics\nfor our specific purpose. Firstly, in Gunning Fog Index, complex\nwords are defined as \u201cwords that have three or more syllables\u201d. Not\nonly this poses the general problem of false positive words (e.g. \u201cin-\nteresting\u201d has three syllables but is not complex), but also contains\ndomain-unspecific words that do not represent domain knowledge.Moreover, in both measurements, the length of sentences plays\na key role in the final index. As ChatGPT tries to maximize the\ncomprehensiveness of its statements by explaining the foundations\nof its arguments from scratch, it usually creates longer sentences\nin comparison to humans on Kialo whose primary objective is to\ndirectly debunk the initial argument. In other words, this measure-\nment alone may be less representative of domain knowledge and\nmore accurate flagging the difficulty of the text.\n6.3 Domain-Specific Vocabulary\nTo address the limitations of the other measures, we also look at the\nsize of domain-specific vocabulary. We use this size in combination\nwith the other measures as a proxy of the diversity of the domain\nknowledge embedded in the corpus. We define three criteria for a\nword to be let into the measure:\n(1)Being in the English dictionary: We use the available list\nof all English words in the NLTK library to filter out the\nnonexistent words after having them lemmatized. This step\nis necessary to avoid a bias in favor of human\u2019s word-count\nas they are more prone to typos than ChatGPT.\n(2)Not being a stop-word: We remove English stop-words\nusing the list in the NLTK library.\n(3)Being a complex word: We use the conventional criteria\nof Gunning Fog Index for complex words and filter out the\nwords with less than three syllables.\n(4)Being Domain-Specific: To find the domain-specific words,\nwe count the unique number of tags set that each word has\nappeared in. Words which appear in too many topics are not\nspecific to particular domains and are barely representative\nof domain knowledge. Looking at the distribution of the\nnumber of tags per word and the location of gaps, we choose\nthe cutoff of 25 tags. Above this threshold, the word can no\nlonger be listed as domain-specific (i.e., worth noting that\nmany topics have more than one tag).\nFigure 5c shows that in almost all the domains, the difference\nbetween ChatGPT vocabulary diversity is not significantly below\nhuman. The only exception is the \u201cPhilosophy\u201d topic where Chat-\nGPT has a significantly less diverse vocabulary.\nTakeaway: ChatGPT is doing a good job of keeping up with hu-\nmans in terms of producing sophisticated and diverse arguments,\nembracing the complexity of controversial topics in almost all\ndomains. The only exception is Philosophy which suggests the\nnecessity of an improvement in that domain.\n7 DISCUSSION & CONCLUSION\nIn this paper, we made an attempt to measure the political and eco-\nnomic leaning of ChatGPT through the lens of controversial topics.\nWe also made a comparison between ChatGPT vs. humans when\nexposed to the same controversial topics on Kialo. Our comparison\nwas both in terms of ideological leaning and knowledge.\nIn general, our findings show promising performance by Chat-\nGPT in terms of moderation, with a few concerns that can be ad-\ndressed. To break it down, we highlight the list of takeaways we\nconsider where ChatGPT\u2019s moderation is performing well and those\nthat are concerning and require further attention.\nAI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models\nvs. Human Answers in Controversial Topics\n(a) Sentence Embedding Variance.\n (b) Gunning Fog Index.\n (c) Domain Specific Words.\nFigure 5: Comparisons Between Semantic Diversity in AI vs Human per 100 Arguments.\nStrengths:\n\u2022We showed that there is an overall decreasing trend in Open\nAI models\u2019 tendency to take direct positions on controversial\ntopics. Whether by providing agreement or disagreement,\nor a yes or no answer.\n\u2022We saw that Bing AI\u2019s distribution of cited sources is more\naligned to the center than humans on Kialo.\n\u2022For the case of economic topics, the free-style querying for-\nmat of Kialo topics resulted in a more-or-less balanced num-\nber of economically left vs economically right arguments.\nThis shows promising moderation in ChatGPT in terms of\neconomy. A larger sample can help to confirm this.\n\u2022The prompt-engineered style of querying was able to make\nChatGPT (gpt-3.5-turbo) provide almost equal pros and cons\nfor the controversial topics. It means that even if there is a\nbias in the language model, a user with a keen interest is\nable to get a neutral experience with prompt engineering.\nWe advocate that future work is needed on the analysis of\nthe usability of prompt engineering.\n\u2022Figure 5c suggests that ChatGPT domain knowledge is keep-\ning up with humans on almost all topics. We note that we\ncompared the knowledge of one language model versus the\ncollective knowledge of educated humans on Kialo.\n\u2022The confusion matrices of ChatGPT annotations manifest\na high precision. Although this was not the main focus of\nour research, it can be complementary to [ 30] and insightful\nfor future computational social scientists who wish to use\nChatGPT for annotation.\nRequires improvement:\n\u2022There are still a few direct positions on controversial topics\nby LLMs. For \u201ctext-davinci-003\u201d, the rate is very high, yet is\nan outdated model. But Bing AI, which is a newer model with\nenhanced capabilities from its search engine, has more yes\nor no responses to controversial topics than gpt-3.5-turbo,\nthough the differences are small.\n\u2022For the case of sociopolitical topics, the free-style querying\nformat of Kialo topics resulted in more libertarian arguments\nthan authoritarian ones. This shows that the social axis of\nthe Political Compass requires more moderation.\n\u2022For the prompt-engineered style of querying, the rate of\nindirect/mitigated reasoning for authoritarian arguments\nwas much higher than for libertarian ones (Table 9).\n\u2022The domain knowledge of ChatGPT was lower than that of\nhumans on the topic \u201cPhilosophy\u201d.\u2022ChatGPT\u2019s annotations were poor on recall. Annotators\nmight want to consider lowering the cutoffs to allow more\nfor positive classes.\nOur measurement of bias in this paper was limited to the eco-\nnomic and sociopolitical leanings defined in the Political Compass\ntest. However, the computation pipelines of the approach are gen-\neralizable for future researchers to extend a similar analysis to\ndifferent social, political, psychological, etc. orientation tests. Take,\nfor instance, an alternative ideological orientation test called \u201c8\nValues political test\u201d [ 13] that maps users into four axes, namely\n\u201cEconomic\u201d, \u201cDiplomatic\u201d, \u201cCivil\u201d, and \u201cSocietal\u201d. Similar to our ex-\nperimental setting, a list of controversial questions in these regards\ncan be asked from LLMs, and the rate of arguments the LLMs pro-\nvided for each side of the axes can proxy the LLMs\u2019 leaning/bias to\nthat side of the spectrum.\nOur selection of domain-specific vocabulary for each domain can\nbe advanced by the utilization of annotated dictionaries of domain-\nspecific keywords. Moreover, our comparison was made between\nChatGPT and Kialo users, which are probably a biased sample of\ncritical-thinking human beings who are also restricted to following\nKialo\u2019s style and moderation rules. An interesting future analysis\nwould be to make the same comparison with different samples of\nthe population. For instance, text generated from ordinary people\non social media who discuss these topics or articles generated by\npeople educated on the corresponding domains.\nTo foster research in the area and make our research reproducible,\nwe publicly open-source our code in our GitHub repository and\nrelease the datasets to the academic community upon request:\nhttps://github.com/vahidthegreat/AI-in-the-Gray\nACKNOWLEDGEMENTS\nThis project was partially funded by TED2021-132900A-I00 from the\nSpanish Ministry of Science and Innovation, and Guillermo Suarez-\nTangil has been appointed as 2019 Ramon y Cajal fellow (RYC-2020-\n029401-I) both funded by MCIN/AEI/10.13039/501100011033 and\nESF Investing in your future. It was also supported by EP/W032473/1,\n\u201cAP4L: Adaptive PETs to Protect & emPower People during Life\nTransitions\u201d and REPHRAIN (EP/V011189/1), the UK\u2019s Research\ncentre on Privacy, Harm Reduction & Adversarial Influence online.\nREFERENCES\n[1]Abubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent Anti-Muslim\nBias in Large Language Models. In Proceedings of the 2021 AAAI/ACM Conference\non AI, Ethics, and Society . ACM, Virtual Event USA, 298\u2013306. https://doi.org/10.\n1145/3461702.3462624\nVahid Ghafouri et al.\n[2]Vibhor Agarwal, Sagar Joglekar, Anthony P Young, and Nishanth Sastry. 2022.\nGraphNLI: A Graph-based Natural Language Inference Model for Polarity Pre-\ndiction in Online Debates. In Proceedings of the ACM Web Conference 2022 . 2729\u2013\n2737.\n[3]Vibhor Agarwal, Anthony P Young, Sagar Joglekar, and Nishanth Sastry. 2022. A\nGraph-Based Context-Aware Model to Understand Online Conversations. arXiv\npreprint arXiv:2211.09207 (2022).\n[4]M. J. Ali. 2023. ChatGPT and Lacrimal Drainage Disorders: Performance and\nScope of Improvement. Ophthalmic plastic and reconstructive surgery 39, 3 (2023),\n221\u2013225. https://doi.org/10.1097/IOP.0000000000002418\n[5]Soumya Barikeri, Anne Lauscher, Ivan Vuli\u0107, and Goran Glava\u0161. 2021. RedditBias:\nA Real-World Resource for Bias Evaluation and Debiasing of Conversational\nLanguage Models. http://arxiv.org/abs/2106.03521 arXiv:2106.03521 [cs].\n[6]Jordan Beck, Bikalpa Neupane, and John M. Carroll. 2019. Managing conflict in\nonline debate communities. First Monday 24, 7 (June 2019). https://doi.org/10.\n5210/fm.v24i7.9585\n[7]Su Lin Blodgett, Solon Barocas, Hal Daum\u00e9 III, and Hanna Wallach. 2020. Lan-\nguage (Technology) is Power: A Critical Survey of \"Bias\" in NLP. http:\n//arxiv.org/abs/2005.14050 arXiv:2005.14050 [cs].\n[8]Luke S. Bothun, Scott E. Feeder, and Gregory A. Poland. 2022. Readability of\nCOVID-19 vaccine information for the general public. Vaccine 40, 25 (2022),\n3466\u20133469. https://doi.org/10.1016/j.vaccine.2022.04.096\n[9]Ashok Deb, Luca Luceri, Adam Badaway, and Emilio Ferrara. 2019. Perils and\nChallenges of Social Media and Election Manipulation Analysis: The 2018 US\nMidterms. In Companion Proceedings of The 2019 World Wide Web Conference\n(San Francisco, USA) (WWW \u201919) . Association for Computing Machinery, New\nYork, NY, USA, 237\u2013247. https://doi.org/10.1145/3308560.3316486\n[10] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. 2020.\nGender bias in chatbot design. In Chatbot Research and Design: Third International\nWorkshop, CONVERSATIONS 2019, Amsterdam, The Netherlands, November 19\u201320,\n2019, Revised Selected Papers 3 . Springer, 79\u201393.\n[11] Adam Fourney, Meredith Ringel Morris, Abdullah Ali, and Laura Vonessen.\n2018. Assessing the Readability of Web Search Results for Searchers with\nDyslexia. In The 41st International ACM SIGIR Conference on Research & De-\nvelopment in Information Retrieval (Ann Arbor, MI, USA) (SIGIR \u201918) . Asso-\nciation for Computing Machinery, New York, NY, USA, 1069\u20131072. https:\n//doi.org/10.1145/3209978.3210072\n[12] Raphael Antonius Frick and Inna Vogel. 2022. Fraunhofer SIT at CheckThat!\n2022: ensemble similarity estimation for finding previously fact-checked claims.\nWorking Notes of CLEF (2022).\n[13] IDRlabs. n.d.. 8 Values Political Test. Available online. https://www.idrlabs.com/8-\nvalues-political/test.php\n[14] Waleed Iqbal, Vahid Ghafouri, Gareth Tyson, Guillermo Suarez-Tangil, and\nIgnacio Castro. 2023. Lady and the Tramp Nextdoor: Online Manifestations\nof Real-World Inequalities in the Nextdoor Social Network. arXiv preprint\narXiv:2304.05232 (2023).\n[15] Kevin Jiang. 2023. What is \u2019woke AI\u2019 and why is Elon Musk reportedly building\na chatbot to counter it? TheStar. https://www.thestar.com/business/2023/03/\n01/what-is-woke-ai-and-why-is-elon-musk-reportedly-building-a-chatbot-to-counter-it.html Accessed on Month Day, Year.\n[16] Calvin D Lawrence. 2023. Hidden in White Sight: How AI Empowers and Deepens\nSystemic Racism . CRC Press.\n[17] Nayeon Lee, Andrea Madotto, and Pascale Fung. 2019. Exploring Social Bias in\nChatbots using Stereotype Knowledge. (2019).\n[18] Pew Research Center\u2014U.S. Politics & Policy (blog). n.d.. Political Typology Quiz.\nAvailable online. https://www.pewresearch.org/politics/quiz/political-typology/\n[19] David Rozado. 2023. The Political Biases of ChatGPT. Social Sciences 12, 3 (2023).\nhttps://doi.org/10.3390/socsci12030148\n[20] Xinyue Shen, Zeyuan Chen, Michael Backes, and Yang Zhang. 2023. In Chat-\nGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT.\narXiv:2304.08979 [cs.CR]\n[21] Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca\nStringhini, Savvas Zannettou, and Yang Zhang. 2022. Why So Toxic?: Measuring\nand Triggering Toxic Behavior in Open-Domain Chatbots. In Proceedings of the\n2022 ACM SIGSAC Conference on Computer and Communications Security . ACM,\nLos Angeles CA USA, 2659\u20132673. https://doi.org/10.1145/3548606.3560599\n[22] AB Siddique, MH Maqbool, Kshitija Taywade, and Hassan Foroosh. 2022. Per-\nsonalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward\nFunction. In Proceedings of the 31st ACM International Conference on Information\n& Knowledge Management . 1787\u20131797.\n[23] Selena Silva and Martin Kenney. 2019. Algorithms, platforms, and ethnic bias.\nCommun. ACM 62, 11 (2019), 37\u201339.\n[24] Solon Barocas, Kate Crawford, Aaron Shapiro, and Hanna Wallach. 2017. The\nProblem With Bias: Allocative Versus Representational Harms in Machine Learn-\ning. Proceedings of SIGCIS, Philadelphia, PA (2017).\n[25] Ahna Ballonoff Suleiman, Jessica S. Lin, and Norman A. Constantine. 2016.\nReadability of Educational Materials to Support Parent Sexual Communica-\ntion With Their Children and Adolescents. Journal of Health Communi-\ncation 21, 5 (2016), 534\u2013543. https://doi.org/10.1080/10810730.2015.1103334\narXiv:https://doi.org/10.1080/10810730.2015.1103334 PMID: 27116292.\n[26] The Political Compass. n.d.. Political Compass Test. Available online. https:\n//www.politicalcompass.org/test\n[27] James Vincent. 2023. As conservatives criticize \u2018woke AI,\u2019 here are ChatGPT\u2019s\nrules for answering culture war queries. The Verge. https://www.theverge.com/\n2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules Accessed\non Month Day, Year.\n[28] Junting Ye and Steven Skiena. 2019. MediaRank: Computational Ranking of\nOnline News Sources. In Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD\n\u201919). Association for Computing Machinery, New York, NY, USA, 2469\u20132477.\nhttps://doi.org/10.1145/3292500.3330709\n[29] Xinyi Zhou, Apurva Mulay, Emilio Ferrara, and Reza Zafarani. 2020. ReCOVery: A\nMultimodal Repository for COVID-19 News Credibility Research. In Proceedings\nof the 29th ACM International Conference on Information & Knowledge Management\n(Virtual Event, Ireland) (CIKM \u201920) . Association for Computing Machinery, New\nYork, NY, USA, 3205\u20133212. https://doi.org/10.1145/3340531.3412880\n[30] Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, and Gareth Tyson. 2023. Can\nChatGPT Reproduce Human-Generated Labels? A Study of Social Computing\nTasks. arXiv:2304.10145 [cs.AI]", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Ai in the gray: Exploring moderation policies in dialogic large language models vs. human answers in controversial topics", "author": ["V Ghafouri", "V Agarwal", "Y Zhang", "N Sastry"], "pub_year": "2023", "venue": "Proceedings of the \u2026", "abstract": "The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs)  have prompted more and more individuals to turn to the use of ChatBots, both for"}, "filled": false, "gsrank": 354, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3583780.3614777", "author_id": ["RnPFjYcAAAAJ", "41Eg_v8AAAAJ", "XL548TAAAAAJ", "arSRJpgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:keN73EZ_FkIJ:scholar.google.com/&output=cite&scirp=353&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=keN73EZ_FkIJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 21, "citedby_url": "/scholar?cites=4762133598314423185&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:keN73EZ_FkIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2308.14608"}}, {"title": "A multilingual similarity dataset for news article frame", "year": "2024", "pdf_data": "A Multilingual Similarity Dataset for News Article Frame\nXi Chen1, Mattia Samory2, Scott Hale3, David Jurgens4, Przemyslaw A. Grabowicz1\n1University of Massachusetts Amherst\n2Sapienza University of Rome\n3University of Oxford\n4University of Michigan\nxchen4@umass.edu, mattia.samory@uniroma1.it, scott.hale@oii.ox.ac.uk, jurgens@umich.edu, grabowicz@cs.umass.edu\nAbstract\nUnderstanding the writing frame of news articles is vital for\naddressing social issues, and thus has attracted notable at-\ntention in the fields of communication studies. Yet, assessing\nsuch news article frames remains a challenge due to the ab-\nsence of a concrete and unified standard dataset that considers\nthe comprehensive nuances within news content.\nTo address this gap, we introduce an extended version of a\nlarge labeled news article dataset with 16,687 new labeled\npairs. Leveraging the pairwise comparison of news articles,\nour method frees the work of manual identification of frame\nclasses in traditional news frame analysis studies. Overall we\nintroduce the most extensive cross-lingual news article simi-\nlarity dataset available to date with 26,555 labeled news arti-\ncle pairs across 10 languages. Each data point has been metic-\nulously annotated according to a codebook detailing eight\ncritical aspects of news content, under a human-in-the-loop\nframework. Application examples demonstrate its potential\nin unearthing country communities within global news cov-\nerage, exposing media bias among news outlets, and quan-\ntifying the factors related to news creation. We envision that\nthis news similarity dataset will broaden our understanding of\nthe media ecosystem in terms of news coverage of events and\nperspectives across countries, locations, languages, and other\nsocial constructs. By doing so, it can catalyze advancements\nin social science research and applied methodologies, thereby\nexerting a profound impact on our society.\nIntroduction\nEvery day, the world\u2019s media landscape is enriched with\nhundreds of thousands of news articles, spanning a multi-\ntude of languages and emanating from various corners of the\nglobe. The ability to discern which articles narrate the same\nstory is not just pivotal for refining news aggregation appli-\ncations but also serves as a gateway to cross-linguistic anal-\nysis of media consumption and attention patterns. However,\nthe task of measuring story congruence within these articles\nis fraught with complexities. Diverse dimensions in story-\ntelling mean that even articles with substantial textual sim-\nilarities may diverge significantly, recounting similar events\nthat transpired years apart.\nIn the realm of communication studies, two long-term\nor cognitively-driven media effects stand out: the agenda-\nCopyright \u00a9 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: Illustration of sample selection pipeline for anno-\ntation.1\nsetting theory and the framing theory \u2013 Fourie (2001) de-\nfined cognition as our capacity for understanding and inter-\npreting information in a specific way, which in turn shapes\nour behavior and thought processes. While the primary level\nof agenda-setting focuses on \u2018what\u2019 a story conveys, the\nframing theory delves deeper into \u2018how\u2019 the story is pre-\nsented. This nuanced differentiation between \u2018what\u2019 and\n\u2018how\u2019 in news narratives is not just a linguistic or stylistic\nconcern but fundamentally alters the impact and reception\nof news among its audiences.\nTherefore, to comprehend if two news articles cover the\nsame story in the same way, it is often not enough to just\ndelve into specific facets of the events portrayed. Also, it\nrequires understanding and evaluating the way to present the\nevents, such as the writing frame.\nAlthough frame theory has gained widespread recognition\nas a vital area in media research, sparking extensive study\nand debate, a consensus on a common and unified defini-\ntion of \u2018frame\u2019 remains missing. A traditional approach in-\nvolves categorizing news articles into specific categories of\nframes. However, this method often restricts articles to a lim-\nited number of coarse-grained themes that are predefined by\nresearchers, such as crises (An and Gower 2009), gun vio-\nlence (Liu et al. 2019; Aky\u00fcrek et al. 2020), or policy issues\n(Card et al. 2015). Such limitations inhibit the potential for\nthese methodologies to be broadly generalized.\nAdditionally, most studies in this domain focus on\nsentence-level analysis, constrained by data availability and\n1Images by Vector Stall and Eucalyp from Flaticon.com.\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM 2024)\n1913\nGEO How similar is the geographic focus (places, cities, countries, etc.) of the\ntwo articles?\nENT How similar are the named entities (e.g., people, companies, organizations,\nproducts, named living beings), excluding previously considered locations ap-\npearing in the two articles?\nTIME Are the two articles relevant to similar time periods or describing similar\ntime periods?\nNAR How similar are the narrative schemas presented in the two articles?\nOVERALL Overall, are the two articles covering the same substantive news story?\n(excluding style, framing, and tone)\nSTYLE Do the articles have similar writing styles?\nTONE Do the articles have similar tones?\nFRAME Do the articles have similar framing and express similar opinions?\nFigure 2: The annotation scheme used by Chen et al. (2022),\nwhich we extended with the FRAME aspect (bottom line).\nsuitable large-scale analytical approaches. This results in\nstudies that often examine only news headlines (Liu et al.\n2019; Aky\u00fcrek et al. 2020) or paragraph contexts (Card et al.\n2015), thereby failing to capture the comprehensive essence\nof the news articles.\nA relevant research area, namely targeted sentiment anal-\nysis, involves identifying named entities discussed in a doc-\nument and classifying the sentiment towards them. Simi-\nlar to frame theory, datasets in targeted sentiment analysis\nare typically limited in size and scope, focusing mainly on\nsentence-level data. This limitation hinders accuracy due to\nthe absence of co-reference and discourse context, let alone\nfully extracting complex relationships within a document\u2019s\nentirety (Steinberger et al. 2017; Luo et al. 2022).\nIn our work, we have expanded a news article dataset, ef-\nfectively overcoming these shortcomings in both frame the-\nory and targeted sentiment analysis (Chen et al. 2022). By\nadopting a human-in-the-loop framework for annotation, we\nensured the creation of high-quality, large-scale data. We de-\nfine the measurement of frame in news articles by expanding\nupon the aspects of pairwise news similarity, thus circum-\nventing the need for narrowly defined, subjective frame cat-\negories, which are often abstract and subtle to operational-\nize.\nConcretely we introduce the most extensive multilingual\nnews article similarity dataset to date, containing nearly 27\nthousand news article pairs across 10 languages. This dataset\noffers a nuanced, pairwise measure, bridging the gap be-\ntween high-level per-outlet bias and low-level, per-sentence\ntargeted sentiment and frame connotations. We believe it\nwill establish a new benchmark for tasks like cross-lingual\ndocument matching, news clustering, and multilingual in-\nformation retrieval. Furthermore, it paves the way for ex-\nploring potential media biases and agendas within different\nlinguistic communities. Our ultimate goal is to bridge soci-\netal barriers, enhancing effective news communication and\nunderstanding in our evermore connected global society.\nDataset Creation\nThe news articles are collected from Media Cloud, an online\nplatform that since 2009 has collected more than a billion\nFigure 3: The number of news articles per country in our\nbase dataset. The released dataset includes labels for pairs\nof articles sampled from the base dataset.\nnews articles published globally (Roberts et al. 2021). We\nfocus on news articles in ten languages, used as an official\nlanguage in 124 countries. This set of countries covers 64%\nof all countries and about 76% of the world population (Fig-\nure 3). Overall, we collected metadata and full text of all\nnews articles from January 1, 2020, to June 30, 2020, total-\ning\u223c60M news articles in the following languages: English,\nSpanish, Russian, German, French, Arabic, Italian, Turkish,\nPolish, and Mandarin Chinese.\nWe recruited and paid annotators with fluency in these\nlanguages, to label the news article similarity after rounds\nof training and calibration. In order to highlight the news\nsimilarities that bear significant value for communication\nand social science research, we meticulously selected rel-\nevant news articles. From this curated pool, we then sys-\ntematically sampled pairs of articles for detailed annota-\ntion (Figure 1). The annotated data is available on at https:\n//zenodo.org/records/10611923.2\nNews article selection. Collected metadata of news arti-\ncles varies in completeness, and thus it cannot be processed\nin the same way. We omitted the articles that miss any of the\nfollowing basic attributes: story ID, URL, title, and text; and\nonly included the meaningful and informative news articles\nwith at least 100 word count (after translating into English).3\nAlso if a news article has the exact same title or URL as an-\nother newer one, we filter it out as a duplicate. Finally, we\ntook some websites out of consideration since they are not\ntrustworthy information sources, or do not focus on societal\nand political topics4.\nAfter applying these selection measures, the resulting\nnews article counts per language are as follows: English\n(10M articles), Spanish (4.6M), Russian (1.8M), German\n2https://zenodo.org/records/10611923\n3We apply this threshold after translating to English to make\na fair comparison across languages since the average number of\nwords needed to represent an English document in another lan-\nguage depends on that language.\n4Irrelevant websites include: \u201creddit.com,\u201d \u201cfacebook.com,\u201d\n\u201ctwitter.com,\u201d \u201cfb.com,\u201d \u201cwikipedia.org,\u201d \u201cepochtimes.com,\u201d\n\u201cyoutube.com,\u201d \u201cslideshare.net\u201d. Any URL containing \u201csport\u201d is\nalso dropped.\n1914\nArticle 1 Article 2 GEO ENT TIME NAR STY TONE FRAME OVERALL\nKey dates in Indiana\u2019s path\nto reopening amid the\ncoronavirus pandemicOutlining \u201cmeasured\u201d\nlifting of lockdownVS VS VS VS SD VS VS VS\nConcor Head rallies SA to\nfight virusChurch Leader Defies\nCoronavirus MeasurersVS SD SD SD SS VD VD SD\nVDH confirms 1st\ncoronavirus-related death\nin Virginia (March 14,\n2020)Virginia sees new\ncoronavirus cases (April\n15, 2020)VS SS SD SS SD SS SS SS\nTable 1: Annotation example of news article pairs. Each aspect is labeled as one of the four classes: Very Similar (VS), Some-\nwhat Similar (SS), Somewhat Dissimilar (SD), Very Dissimilar (VD). The first example includes a pair of articles that cover\nthe plan for reopening Indiana, which are very similar in frame. The second pair shares some similarities in terms of Geog-\nraphy (South Africa) and Entities (President Cyril Ramaphosa), but their frames on the lockdown events exhibit significant\ndissimilarity. One article discusses how an infrastructure company supports the national lockdown for long-term commercial\nsustainability, while the other focuses on church leaders\u2019 disagreement with the lockdown due to its limitations on in-person\nworship. The final pair of articles both report on coronavirus cases in Virginia, which are somewhat similar in their framing.\nThe first article includes mayoral statements and conveys a sorrowful tone, while the second article presents the information in\na more neutral tone, focusing on data.\n(1.3M), French (1.2M), Arabic (1.8M), Italian (1.5M), Turk-\nish (655K), Polish (369K), and Mandarin Chinese (205K).\nNews article pairs sampling. Ideally, the dataset should\ncover each degree of news article similarity in an even man-\nner. However, if we just sample two random news articles\nthey can hardly be relevant, let alone similar. A crucial chal-\nlenge of our work was identifying potentially similar pairs of\nnews articles, in order to mitigate the imbalance of similar-\nity labels during the annotation process. We experimented\nwith various strategies to unearth these similar articles, in-\ncluding the comparison of document embeddings (Cr5: Josi-\nfoski et al. 2019) or sentence embeddings (Sentence BERT:\nReimers and Gurevych 2019) for news headlines and lead-\ning paragraphs, as well as the named entities extracted from\nfull texts (Babelfy, polyglot, and spaCy: Moro, Raganato,\nand Navigli 2014).\nAfter extensive pilot study, including the selection of\nnews article representation for sampling (e.g., we tried Cr5\nand Sentence BERT embeddings, but concluded that Wiki-\nfied named entities work better), filtering process, and devel-\noping simple machine learning models for active learning,\nwe ultimately engineered an effective and efficient pipeline\nto sample and annotate pairs of news articles (Figure 1). Our\nfirst step is to extract named entities from each news article,\na process facilitated by the use of spaCy and Polyglot.\nTo avoid the sampling of duplicate pairs (i.e., two articles\nwith identical or nearly identical text, published under dif-\nferent titles and URLs and hence not filtered out during the\narticle selection stage), we introduced an additional filtering\nstep. This process removed all pairs of articles that share one\nor more long sentences (comprising 40 or more characters)\nor whose Jaccard similarity of article text exceeds 0.25, a\npredetermined empirical threshold.\nAs human annotators started to label the news article pair\nsamples, the sampling quality was iteratively improved viaa human-in-the-loop active learning framework. In essence,\nwith each iteration, we built a fresh new logistic regression\nmodel and trained it with all the labels that we had obtained\nup to that point. The model includes features as follows: the\nword counts of both articles, the number of common words,\nthe number of common named entities, cosine similarity of\nthe named entities with BM25 embeddings (Robertson and\nZaragoza 2009), text Jaccard similarity, and an exponen-\ntially decaying function of publication date difference.\nAnnotation Process\nIn consultation with media studies literature, we established\nan elaborate codebook, which we share with our dataset,5\nthat details the annotation of news article similarity across 8\naspects (Figure 2). To calibrate the annotators\u2019 understand-\ning of the codebook, we initially conducted several rounds\nof trial annotations, including calibration sessions aiming\nfor agreement on 30 carefully selected news article pairs.\nThe subsequent annotations that contributed to the overall\ndataset were collected in two stages, described next.\nIn the first stage (July - December 2021), annotators as-\nsessed the first seven similarity aspects (GEO, ENT, TIME,\nNAR, OVERALL, STYLE, TONE). During this time, many\narticle pairs were assigned to multiple annotators to ensure\nlabel reliability. This stage resulted in 9,868 annotated pairs,\nwhich we released at the SemEval\u201922 competition focused\non news article similarity estimation (Chen et al. 2022).\nThen the second stage followed (January - May 2022),\nduring which the FRAME aspect was added. According to\nour codebook, FRAME similarity \u201ccan be judged only when\nthe framing and opinions communicated in the two articles\ntarget the same subject, e.g., the articles communicate opin-\nions about Bernie Sanders\u201d. The idea that framing is relative\n5https://zenodo.org/records/10611923\n1915\nlanguage class\ncount mean(OVERALL)\nar 172\n5 2.66\nde 3402 2.54\nen 7545 2.76\nes 2334 2.33\nfr 369 1.99\nit 1133 2.64\npl 760 2.33\nru 350 2.77\ntr 1310 2.58\nzh 3413 2.31\nde-en 1956 2.94\nde-fr 178 1.92\nde-pl 47 1.69\nes-en 759 2.84\nes-it 474 2.29\nfr-en 103 1.21\nfr-pl 53 1.67\npl-en 119 2.35\nzh-en 525 2.96\ntotal 26555 2.59\nTable 2: Counts of annotated monolingual pairs (e.g., En-\nglish article pairs \u2013 \"en\") and cross-lingual pairs (e.g., pairs\nof a German article and an English article \u2013 \"de-en\").\nto a target comes from the research area of targeted senti-\nment analysis. Due to this requirement, and because we in-\ntroduced FRAME aspect gradually while discussing it with\nour expert annotators, we collected FRAME similarity la-\nbels for a relatively small subset of 1522 news article pairs.6\nEach pair was labeled by a single well-trained annotator to\nmaximize the number of annotated news article pairs. Over-\nall, the second stage brought 16,687 annotated pairs.\nEach aspect was labeled with four ordinal classes \u2013 Very\nDissimilar, Somewhat Dissimilar, Somewhat Similar, and\nVery Similar. To accommodate exceptional cases, we also\noffer an Other option. The most common exceptions that we\nmet were pairs of duplicate new articles or inaccessible ar-\nticles, for instance, due to paywalls or removal (annotators\nwere instructed to report such instances via a free-text com-\nment).\nTo satisfy the desired linguistic diversity and scale of\nnews annotation, we trained 25 annotators, recruited from\nthree institutions (GESIS, UMass, Umich). They did several\nrounds of calibration for the gold standards in our codebook\nChen et al. (2022) before starting their annotation tasks. The\nentire annotation process lasted for roughly 11 months. We\npaid each annotator C12 per hour at GESIS and $15per hour\nat UMass and UMich.\nThe annotation process was running through a custom an-\nnotation interface devised by our team. It shuffles news arti-\ncle pairs and assign them to annotators as per their respec-\ntive language capabilities. To engage and motivate the anno-\ntators, the interface also offers statistical feedback, such as\n6The vast majority of dissimilar news article pairs do not share\ncommon targets and thus their FRAME similarity is not labeled.GEO ENT\nTIME NAR OVERALL STYLE TONE\nKrip. \u03b10.73 0.69\n0.57 0.69 0.77 0.46 0.38\nGwet\u2019s AC 10.75 0.70 0.78 0.71 0.79 0.60 0.60\nTable 3: Inter-rater agreement measures, Krippendorf\u2019s \u03b1\nand Gwet\u2019s AC 1, for the similarity aspects (FRAME aspect\nis missing since for each pair it is only annotated by one\nwell-trained annotator).\nthe annotation count ranking and the inter-rater agreement\nranking among annotators. This also enabled us to identify\nthe annotators who did not perform their task correctly. We\nrecorded the disagreements and discussed them with anno-\ntators biweekly as part of our iterative calibration process.\nDataset Description\nFormat and Statistics\nWe collected the labels for roughly 11 months from 2021\nJuly to 2022 May. Ultimately, we got the news article simi-\nlarities for 26,555 pairs (Table 1), including 1522 with frame\nsimilarity labels and 4,214 cross-lingual pairs (Table 2). In\nthe remainder of this manuscript, we represent the four sim-\nilarity labels on an interval scale from 1 (Very Dissimilar) to\n4 (Very Similar), e.g., Table 2 shows the average similarity\nfor different groups of labels.\nInter-annotator Agreement\nTo evaluate the reliability of the similarity labels, we cal-\nculated the inter-rater agreement for each aspect. The anno-\ntators exhibited remarkably high agreement on the OVER-\nALL similarity aspect, as evidenced by a Krippendorff\u2019s \u03b1\nof0.77. We also leveraged Gwet\u2019s AC 1measure, which is\nknown to be less sensitive to non-uniform marginal label\ndistributions (Gwet 2008). Therefore, it allows us to offset\nbias arising from skewed distributions within some aspects.\nAll aspects demonstrated good inter-rater agreements under\nthis measure.\nApplications\nTo the best of our knowledge, our dataset is the largest\nto date for assessing news article similarity, with meticu-\nlous evaluations conducted across multiple languages. Con-\nsequently, it holds significant potential to empower a wide\nrange of applications within the fields of media communica-\ntion and social science, including news aggregation, media\nconsumption analysis, cross-cultural studies, agenda setting\nresearch, linguistic studies, and political science research.\nNext, we present three examples (our code of implementa-\ntions is available on Github.7.\nGlobal News Synchrony and Diversity\nAs the multilingual news article similarity offers a unified\nrepresentation that transcends language barriers, it enables\nus to understand the news media across multiple countries,\nor even on a global scale. In a recent paper, we develop an\n7https://github.com/social-info-lab/global_news_synchrony\n1916\nEvent News article\ntitle\nOscar 2020Oscary 2020\nnale\u02d9za\u0142y do \"Parasite\" i zmieni\u0142y histori\u02db e gali. Pe\u0142na lista zwyci\u02db ezc\u00f3w\nOscar 2020:\nrevisa la lista de ganadores de las 24 categor\u00edas con lo mejor del cine\nOscars 2020:\nLos usuarios de internet premian a Joker, Leonardo DiCaprio, Scarlett Johansson y Martin Scorsese\nA dos\nhoras de la ceremonia, los Oscar se aprontan entre favoritos y posibles sorpresas\nParasite\nhizo historia en los Oscars y se llev\u00c3\u00b3 el premio a mejor pel\u00c3 cula\nGanadores de\nlos Oscar 2020\nNigeria Records\n245 New Cases Of COVID-19, Highest Single-Day Increase\nOscars 2020:\nSouth Korean movie makes history by winning best picture\nM\u00faltiples latinos\nse miden esta noche en los Oscar\nGlamour y\ntalento en la gala de los premios Oscar en su 92 edici\u00f3n\nOscar night\nbegins with \u20181917\u2019 battling \u2018Parasite\u2019\nCovid\n2020Canad\u00e1 acepta\ntener varios posibles casos de coronavirus\nPrev\u00e9n\nse presenten casos de coronavirus chino en M\u00e9xico\nQu\u00e9 se\nsabe sobre el coronavirus de China que \"puede haber afectado a cientos de personas\", seg\u00fan cient\u00edficos brit\u00e1nicos\nChinese confirm\ncoronavirus outbreak can spread like wildfire from infected people | Fox Business\nChina locks\ndown more cities as virus spreads\nUS source:\nNorth Korean leader Kim Jong Un in grave danger after surgery\nUn virus\nen Chine commence \u00e0 inqui\u00e9ter au Canada\nEl nue\nvo coronavirus deja 106 muertos y 4.515 infectados en China\nLo que\nse sabe sobre el coronavirus detectado en China y otros pa\u00edses que ya ha afectado a cientos de personas\nWDH/VIRUS/R\nOUNDUP: V orerst keine \u2018internationale Notlage\u2019\nVirus\nchinois: sans doute des centaines de contaminations, inqui\u00e9tude \u00e0 l \u00e9tranger\nTable 4: Random samples of news articles in two exemplary news event clusters: Oscar 2020 covered by news in English and\nSpanish, with a small portion in Polish; Covid 2020 covered by news in various languages from Asia, North America, South\nAmerica and Europe.\neffective methodology for news coverage studies at a mas-\nsive scale and measure news diversity and synchrony across\ncountries (Chen et al. 2024).\nChallenges. The key challenges to examining news cov-\nerage at a global scale are the following. First, traditional\ndata collection and validation based on physical newspapers\nand questionnaires requires human effort that scales linearly\nwith the amount of data and the number of languages. These\npractical considerations severely limit the data size and lin-\nguistic coverage of traditional studies. Second, it is not clear\nhow to identify global news events, which are necessary\nto measure news coverage of events. Existing methods for\nidentifying which events are reported in the news prioritize\nprecision over coverage, since such methods are based on\nkeyword matching (Card et al. 2015), inevitably leading to\nthe lack of generality. We overcome these challenges by con-\ntributing a novel computational methodology for studies of\nglobal news coverage thanks to the labeled dataset.\nNews similarity inference. First, we develop a\ncomputationally-efficient transformer model that infers\nmultilingual news similarity. The model achieves the\nhighest score (Pearson correlation with human annotations\nof0.8) among similar efficient models in the prior bench-\nmark (Chen et al. 2022) computed on our labeled dataset,\nachieving performance comparable to average human\nannotators.\nGlobal event detection. Second, using this model, we\ncompute similarity among millions of news article pairs.\nThen, we apply a graph-clustering algorithm on the result-\ning similarity network to identify 4,357 multilingual news\nevents. The largest events, in chronological order, were: theassassination of Iranian general Soleimani, U.S. presidential\nelection primaries, the Covid-19 pandemic, and protests af-\nter the killing of George Floyd (see examples in Table 4). We\nevaluate the quality of the identified news events by an in-\ntrusion task, which is commonly used to evaluate topic mod-\nels (Chang et al. 2009). We recorded an average high preci-\nsion of 85.8%across the annotators (97.5% for the annotator\nwho spent the most time on the task).\nNews diversity and synchrony measures. Third, we\nintroduce information-theoretic measures of country-level\nsynchrony and diversity in news coverage of global events.\nWe define the diversity of news in a country as the entropy\nof the distribution of the news published in that country\nacross the inferred events. As the synchrony of news across\na pair of countries we define the Jensen-Shannon divergence\nof the respective distributions. Next, we regress the diver-\nsity within a country and synchrony across countries against\ncountry-level predictors. The regression yields much higher\nadjusted R2for the introduced measures of diversity and\nsynchrony (R2of 0.54 and 0.45, respectively) than naive\nbaseline measures based on an average of pairwise news ar-\nticle similarity that do not make use of global news events\n(R2of 0.13 and 0.30, respectively).\nFindings. The labeled dataset and proposed methodol-\nogy enable the discovery of unexpected patterns in global\nnews coverage. For instance, prior studies suggest that the\nacceleration of the news cycle in the Internet age contributes\nto the homogenization of news coverage (Bucy, Gantz, and\nWang 2014; Boczkowski and de Santos 2007; McGregor\n2019; Zuckerman 2013). However, we find that Internet\nadoption is the strongest predictor of news diversity within\n1917\nFigure 4: News event graph backbone for the top 100 countries with the largest populations. The main communities are marked\nwith squares: the US and the UK and their former colonies (red square), five countries of the old European Union of 1958\n(purple), Latin America and Spain (blue), and the Arab world (brown). Most of these communities align with the geographic-\nlinguistic groups in (Kim and Barnett 1996). Some countries are not selected into the graph backbone, e.g., China. Country\nflag size corresponds to country GDP, and each edge represents 95% confidence (Serrano, Bogun\u00e1, and Vespignani 2009) that\nit represents non-random synchrony in news event coverage.\na country (p < 0.005). The higher the Internet penetration,\nthe larger the news diversity, probably because news media\ncater to diverse interests and motivations of online audiences\n(Lee 2013)). This finding illustrates the potential of the pro-\nposed methodology to contribute to communication science\nin ways that go beyond confirmations of existing theories.\nIn addition, we find that news coverage is more diverse in\ncountries with multiple official languages (p < 0.005), more\ndiverse religious practices (p < 0.005), greater economic\ndisparities, and larger populations (p < 0.05).\nThe international news synchrony network based on the\nproposed synchrony measure reveals groups of countries\nthat synchronize in their news coverage of events (Figure 4):\n(i) the US, UK, and UK\u2019s past colonies, (ii) the old Euro-\npean Union of 1958, (iii) Latin America, and (iv) Arab coun-\ntries. We find that trade volume is the strongest predictor of\nnews synchrony between countries (p < 0.005), which cor-\nroborates prior findings (Wu 2000; Segev 2016). Further-more, coverage of news events is more synchronized be-\ntween countries that share an official language (p < 0.005),\nhigh GDP (p < 0.05), and high democracy indices (p <\n0.005). Interestingly, countries that belong to NATO expe-\nrience more news synchrony (p < 0.05), possibly because\nthey have common security concerns and some of the largest\nnews events correspond to military operations. Countries be-\nlonging to BRICS (p < 0.05) exhibit more synchronized\nnews, possibly due to their common developmental inter-\nests.\nMedia Bias Analysis\nMedia outlets often exhibit biases in their coverage of events\nand the emphasis they place on them. These biases are influ-\nenced by various factors such as political stances, national\ninterests, cultural beliefs, and target audiences (Mrogers\nand Wdearing 1988). These social factors significantly af-\nfect how a story is presented, including its frame and tone\n1918\nFigure 5: The average frame dissimilarity (left) and tone dis-\nsimilarity (right) for pairs of media outlets with a certain\nlevel of political bias misalignment.\n(Aruguete 2017). The framing of a story can direct audi-\nences towards specific truths or opinions, especially those\nthat resonate with their existing beliefs and knowledge\n(Scheufele and Tewksbury 2007). Additionally, the tone of a\nstory can subtly guide the conveyance of ideology from me-\ndia to the public, leveraging audience conformity (Ambady\nand Skowronski 2008; LeBon and Nye 2017).\nMedia bias vs news frame and tone. Here, we study the\nrelationship between media outlet bias and the framing and\ntone of the news articles they publish.\nWe compiled a list of media outlet biases from the Me-\ndia Bias/Fact Check website (Zandt 2022). Additionally,\nwe consulted three supplementary sources of media bias\nscores: (1) a dataset on partisanship from the 2016 American\npresidential election, with biases inferred based on whether\na Twitter user followed Hillary Clinton or Donald Trump\n(Faris et al. 2017); (2) voter registration data for Democrats\nand Republicans from 2018 (Robertson, Lazer, and Wilson\n2018); and (3) an analysis of political bias among active\nTwitter users from January 2019 to June 2019, utilizing the\nemIRT tool (Imai, Lo, and Olmsted 2015; University 2020).\nThese biases span five categories on the left-right spectrum:\nLeft, Left-center, Center, Right-center, and Right. As the\nbias of an outlet, we used the label that was the most com-\nmon across the above four sources. In cases where this pro-\ncedure identifies varying bias labels, we use the most left-\nleaning one.\nWe plot the frame and tone dissimilarity as a function of\nmedia bias misalignment (Figure 5), classified into five cat-\negories based on the ideological distance on the spectrum\nfrom Leftbias to Right bias: Same, Weak, A Bit Weak, A Bit\nStrong, and Strong. For example: if one news outlet has a\nLeftbias and the other has a Right bias, then the bias mis-\nalignment is Strong; but if the second article has a Center\nbias, then the bias misalignment is Weak. As expected, our\nfindings reveal that the frame and tone of a pair of news\narticles become more dissimilar if the biases of the media\noutlets where they were published are more misaligned (Fig-\nure 5).\nWe also calculated the correlations between frame dissim-\nilarity, tone dissimilarity, and media bias misalignment at the\nlevel of article pairs (Table 5). We find a modest correlation\nbetween frame/tone similarity and media bias alignment.\nNotably, frame similarity demonstrates a slightly strongerFrame vs\nBias Tone vs Bias Frame vs Tone\nSpearman 0.185\n0.087 0.394\nPearson 0.202 0.083 0.410\nTable 5: Correlations between frame similarity, tone simi-\nlarity, and media bias. All the correlations are statistically\nsignificant with p-values less than 10\u22129.\ncorrelation than tone similarity, although both correlations\nare relatively weak. The correlations between frame and\ntone are both around 0.4, which indicates medium strength.\nMedia bias on president power. News outlets may por-\ntray biased social images of politicians. To investigate this\nphenomenon, we utilized Riveter (Antoniak et al. 2023), an\nadvanced tool capable of identifying named entities within\neach article and assigning a power score to each of these en-\ntities. This power score reflects the entity\u2019s perceived power\nstrength, based on the actions associated with it in the con-\nnotation frame (Sap et al. 2017). Our process began with\napplying Riveter to deduce the power scores of named enti-\nties. We then merged the coreferences of these entities and\nexcluded those appearing in articles from fewer than three\ndifferent news outlets. Subsequently, we segmented the re-\nmaining articles into categories based on differing political\nbiases. Our analysis revealed that across all categories, news\noutlets consistently depicted Biden as having higher power\nstrength than Trump (Figure 6). This could be attributed to\ntheir inherent social images in public perception (such as\nBiden usually refers to collaborative power words like U.S.\ninstitutions, achievements, and morality, consistent with the\nconstructs of prestige and traditional power; while Trump is\naround coercive power words like \u201cdefeat,\u201d \u201cthreat,\u201d \u201cpoi-\nson,\u201d \u201cadministration,\u201d \u201cfailed,\u201d \u201cignored,\u201d or \u201cpromised.\u201d,\nwhich may be interpreted as denial of Trump\u2019s trustworthi-\nness and dependability (K\u00f6rner et al. 2022). Interestingly,\noutlets with a bias leaning towards the Leftportrayed Biden\nas more influential than those leaning towards the Right,\nwith the opposite trend observed for Trump, similar as the\npolitical biases of parties they two respectively represent and\nobtain support from (Democratic for Leftand Republic for\nRight ).\nMulti-factor Analysis\nOur dataset allows for a nuanced analysis that considers\nmultiple factors together and thus extends beyond a single\nsocial factor to analyze how various elements like political\nbiases, language use, and country-specific factors interact to\ninfluence news similarity. By integrating these diverse as-\npects into our investigation, we provide a more complete pic-\nture of the dynamics shaping global news narratives, offer-\ning deeper insights into how political, cultural, and national\nfactors collectively influence news coverage and framing.\nNext, we quantify the importance of each of these fac-\ntors on OVERALL, TONE, and FRAME similarity of news\narticles. To this end, we built three logistic regression mod-\nels and compared the factors\u2019 coefficients with each other. In\nthese models, the pairwise alignment of each factor becomes\n1919\nFigure 6: Power scores of Biden and Trump inferred by Riv-\neter based on news articles published in news outlets with\ngiven media bias.\na feature and they are combined as the input, while the\nnews similarity of OVERALL, TONE, or FRAME aspect\nbecomes output for each of the three classifiers. For sim-\nplicity, we represent language alignment and country align-\nments as binary: 1 for exact matches and 0 for differences.\nBias alignment is normalized to [0,1] range as ordinal factor\nwith equal numeric interval (\"Same\" is converted to 1 and\n\"Very Strong\" is converted to 0), for comparing its impor-\ntance with other factors at the same scale. The similarities\nare also recast into binary: 1 for Very Similar andSomewhat\nSimilar, and 0 for Somewhat Dissimilar andVery Similar.\nTable 6 displays the logistic regression weights of each\nfactor. Interestingly, bias alignment positively correlates to\ncontent similarity, possibly because contentious topics, often\ncovered by politically polarized outlets, drive more discus-\nsion. Shared languages and shared countries publishing the\nnews articles also showed a positive correlation to OVER-\nALL similarity, reflecting common cultural beliefs and ties\nof national interest. However, the alignment of the countries\nmentioned in the news articles seems to correlate negatively\nwith content similarity.\nIt is worth noting that the strongest predictor of frame\nsimilarity is the bias alignment. The alignment of the coun-\ntry of publication also has some importance, potentially\nreflecting the influence of national interest on the news\nframe. In terms of predicting tone similarity, both bias align-\nment and language alignment demonstrate greater impor-\ntance than country alignment. Table 6 also demonstrates that\nframe and tone similarities are more predictable than over-\nall content similarity. This observation aligns with the closer\nproximity of frame and tone to the chosen factors.\nEthics Statement\nOur similarity labels are based on full texts of news arti-\ncles, but we only provide their URLs to access the full texts\nto prevent copyright issues. To ensure that the news con-\ntent is reliable with a focus on socially meaningful topics\nor events, we declined all URLs from popular social media\nplatforms (twitter.com, facebook.com, reddit.com, etc.). We\nencouraged the annotators to report such cases and intro-\nduced a button in our annotation interface to tag any contentthat they felt was hateful or harmful.\nConclusion\nIn the ever-evolving landscape of global communication, un-\nderstanding the interconnections between news articles is\nmore than an academic pursuit\u2014it\u2019s a key to unlocking in-\nsights into media studies and societal dynamics. Our exten-\nsion of a multilingual news article similarity dataset sheds\nlight on this intricate web by revealing commonalities across\nnews articles in eight distinct aspects, including a novel ap-\nproach to define news frames. This dataset is not just a tool;\nit\u2019s a window into the global media narrative, offering a\nunique vantage point for identifying international media net-\nworks, uncovering inherent biases in news outlets, and un-\nderstanding the portrayal of presidential power across vari-\nous media platforms.\nHowever, the potential of this dataset extends far beyond\nthese initial applications. It sets the stage for innovative re-\nsearch in global agenda setting, allowing for an in-depth\nexploration of media biases on a global scale. Imagine un-\nearthing the stark disparities in news coverage, such as why\nAfrican disasters require far more casualties to gain the\nsame level of US media attention as those in Eastern Eu-\nrope (Eisensee and Str\u00f6mberg 2007). Our dataset provides\nthe granularity needed to dissect political campaigns and so-\ncietal beliefs, revealing the subtle nuances that shape public\nopinion and discourse.\nMoreover, the dataset is poised to facilitate critical analy-\nses of long-term bias and synchrony trends in international\nnews, e.g., in the periods leading up to war outbreaks. This\nkind of research promises to enhance our understanding of\nhow media narratives intertwine with public sentiment, po-\nlitical maneuvers, international relations, and the genesis of\nglobal conflicts. In essence, it offers a lens to view and inter-\npret the complex interplay of factors that drive the world\u2019s\nnews stories.\nBy providing methodologies to observe and interpret the\ncontinuous evolution of our global narrative through the\nnews, this work not only contributes to academic discourse\nbut also offers profound societal insights. It underscores how\ninternational news coverage, in all its complexity, reflects\nand shapes our understanding of geopolitical histories and\nlocal realities. In doing so, this dataset stands as a pivotal re-\nsource for those seeking to comprehend the narrative of our\nglobal society.\nAcknowledgments\nThis research has received funding through grants from\nthe V olkswagen Foundation and the University of Mas-\nsachusetts Amherst. We sincerely thank Media Cloud for\ndata access and the annotators for annotating multilingual\nnews similarity.\nReferences\nAky\u00fcrek, A. F.; Guo, L.; Elanwar, R.; Ishwar, P.; Betke, M.;\nand Wijaya, D. T. 2020. Multi-label and multilingual news\nframing analysis. In Proceedings of the 58th annual meeting\nof the association for computational linguistics, 8614\u20138624.\n1920\nOVERALL FRAME TONE\nAlignment coef P> |t| coef P> |t| coef P> |t|\nBias -0.184 ** 0.137 * 0.091 **\nLanguage 0.097 ** -0.013 0.084 **\nPublication country 0.203 * 0.128 * 0.037 *\nReferred country -0.248 ** 0.059 0.046 *\nF1 Score 0.515 0.689 0.656\nAccuracy 0.530 0.638 0.610\nTable 6: Classification evaluation measures (F1, accuracy) and the coefficients of various predictors for the logistic regression\nmodels of OVERALL, FRAME, and TONE similarity. Significance level: difference from zero of more than one (\u2217) or three\n(\u2217\u2217) standard deviations, which correspond to p-values of less than 0.1and0.001, respectively.\nAmbady, N.; and Skowronski, J. J. 2008. First impressions.\nGuilford Press.\nAn, S.-K.; and Gower, K. K. 2009. How do the news media\nframe crises? A content analysis of crisis news coverage.\nPublic relations review, 35(2): 107\u2013112.\nAntoniak, M.; Field, A.; Mun, J.; Walsh, M.; Klein, L.; and\nSap, M. 2023. Riveter: Measuring Power and Social Dy-\nnamics Between Entities. In Bollegala, D.; Huang, R.; and\nRitter, A., eds., Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Volume 3:\nSystem Demonstrations), 377\u2013388. Toronto, Canada: Asso-\nciation for Computational Linguistics.\nAruguete, N. 2017. The agenda setting hypothesis in the\nnew media environment. Comunicaci\u00f3n y sociedad, (28):\n35\u201358.\nBoczkowski, P. J.; and de Santos, M. 2007. When More Me-\ndia Equals Less News: Patterns of Content Homogenization\nin Argentina\u2019s Leading Print and Online Newspapers. Polit-\nical Communication, 24(2): 167\u2013180.\nBucy, E. P.; Gantz, W.; and Wang, Z. 2014. Media technol-\nogy and the 24-hour news cycle. In Communication tech-\nnology and social change, 143\u2013163. Routledge.\nCard, D.; Boydstun, A.; Gross, J. H.; Resnik, P.; and Smith,\nN. A. 2015. The media frames corpus: Annotations of\nframes across issues. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational Linguistics\nand the 7th International Joint Conference on Natural Lan-\nguage Processing (Volume 2: Short Papers), 438\u2013444.\nChang, J.; Gerrish, S.; Wang, C.; Boyd-Graber, J.; and Blei,\nD. 2009. Reading tea leaves: How humans interpret topic\nmodels. Advances in neural information processing systems,\n22.\nChen, X.; Hale, S.; Jurgens, D.; Samory, M.; Zuckerman, E.;\nand Grabowicz, P. 2024. International News Synchrony Dur-\ning the Start of the COVID-19 Pandemic. In Proceedings of\nthe ACM Web Conference 2024.\nChen, X.; Zeynali, A.; Camargo, C.; Fl\u00f6ck, F.; Gaffney, D.;\nGrabowicz, P.; Hale, S.; Jurgens, D.; and Samory, M. 2022.\nSemEval-2022 Task 8: Multilingual news article similarity.\nInSemEval-2022, 1094\u20131106.Eisensee, T.; and Str\u00f6mberg, D. 2007. News droughts, news\nfloods, and US disaster relief. The Quarterly Journal of Eco-\nnomics, 122(2): 693\u2013728.\nFaris, R.; Roberts, H.; Etling, B.; Bourassa, N.; Zuckerman,\nE.; and Benkler, Y . 2017. Partisanship, propaganda, and\ndisinformation: Online media and the 2016 US presidential\nelection. Berkman Klein Center Research Publication, 6.\nFORCE11. 2020. The FAIR Data principles. https://force11.\norg/info/the-fair-data-principles/. Accessed: 2024-01-15.\nFourie, P. J. 2001. Media Studies: Content, audiences, and\nproduction, volume 2. Juta and Company Ltd.\nGebru, T.; Morgenstern, J.; Vecchione, B.; Vaughan, J. W.;\nWallach, H.; Iii, H. D.; and Crawford, K. 2021. Datasheets\nfor datasets. Communications of the ACM, 64(12): 86\u201392.\nGwet, K. L. 2008. Computing inter-rater reliability and its\nvariance in the presence of high agreement. British Journal\nof Mathematical and Statistical Psychology, 61(1): 29\u201348.\nImai, K.; Lo, J.; and Olmsted, J. 2015. emIRT: EM Algo-\nrithms for Estimating Item Response Theory Models. avail-\nable at the Comprehensive R Archive Network (CRAN).\nhttp://CRAN. R-project. org/package= list.\nJosifoski, M.; Paskov, I. S.; Paskov, H. S.; Jaggi, M.; and\nWest, R. 2019. Crosslingual Document Embedding as\nReduced-Rank Ridge Regression. In Proceedings of the\nTwelfth ACM International Conference on Web Search and\nData Mining. ACM.\nKim, K.; and Barnett, G. A. 1996. The determinants of in-\nternational news flow: A network analysis. Communication\nResearch, 23(3): 323\u2013352.\nK\u00f6rner, R.; Overbeck, J. R.; K\u00f6rner, E.; and Sch\u00fctz, A. 2022.\nHow the linguistic styles of Donald Trump and Joe Biden\nreflect different forms of power. Journal of Language and\nSocial Psychology, 41(6): 631\u2013658.\nLeBon, G.; and Nye, R. A. 2017. The crowd. Routledge.\nLee, A. M. 2013. News audiences revisited: Theorizing the\nlink between audience motivations and news consumption.\nJournal of Broadcasting & Electronic Media, 57(3): 300\u2013\n317.\nLiu, S.; Guo, L.; Mays, K.; Betke, M.; and Wijaya, D. T.\n2019. Detecting frames in news headlines and its applica-\ntion to analyzing news framing trends surrounding US gun\n1921\nviolence. In Proceedings of the 23rd conference on compu-\ntational natural language learning (CoNLL), 504\u2013514.\nLuo, Y .; Cai, H.; Yang, L.; Qin, Y .; Xia, R.; and Zhang, Y .\n2022. Challenges for open-domain targeted sentiment anal-\nysis. arXiv preprint arXiv:2204.06893.\nMcGregor, S. C. 2019. Social media as public opinion:\nHow journalists use social media to represent public opin-\nion.Journalism, 20(8): 1070\u20131086.\nMoro, A.; Raganato, A.; and Navigli, R. 2014. Entity\nLinking meets Word Sense Disambiguation: A Unified Ap-\nproach. Transactions of the Association for Computational\nLinguistics (TACL), 2: 231\u2013244.\nMrogers, E.; and Wdearing, J. 1988. Agenda-setting re-\nsearch: Where has it been, where is it going? Annals of the\nInternational Communication Association, 11(1): 555\u2013594.\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sen-\ntence Embeddings using Siamese BERT-Network s. In\nProceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), 3982\u20133992. Hong Kong, China: Asso-\nciation for Computational Linguistics.\nRoberts, H.; Bhargava, R.; Valiukas, L.; Jen, D.; Malik,\nM. M.; Bishop, C.; Ndulue, E.; Dave, A.; Clark, J.; Etling,\nB.; Faris, R.; Shah, A.; Rubinovitz, J.; Hope, A.; D\u2019Ignazio,\nC.; Bermejo, F.; Benkler, Y .; and Zuckerman, E. 2021. Me-\ndia Cloud: Massive Open Source Collection of Global News\non the Open Web. In Proceedings of the Fifteenth In-\nternational AAAI Conference on Web and Social Media\n(ICWSM2021).\nRobertson, R. E.; Lazer, D.; and Wilson, C. 2018. Auditing\nthe personalization and composition of politically-related\nsearch engine results pages. In Proceedings of the 2018\nWorld Wide Web Conference, 955\u2013965.\nRobertson, S.; and Zaragoza, H. 2009. The Probabilistic\nRelevance Framework: BM25 and Beyond. Found. Trends\nInf. Retr., 3(4): 333\u2013389.\nSap, M.; Prasettio, M. C.; Holtzman, A.; Rashkin, H.; and\nChoi, Y . 2017. Connotation Frames of Power and Agency in\nModern Films. In Palmer, M.; Hwa, R.; and Riedel, S., eds.,\nProceedings of the 2017 Conference on Empirical Methods\nin Natural Language Processing, 2329\u20132334. Copenhagen,\nDenmark: Association for Computational Linguistics.\nScheufele, D. A.; and Tewksbury, D. 2007. Framing, agenda\nsetting, and priming: The evolution of three media effects\nmodels. Journal of communication, 57(1): 9\u201320.\nSegev, E. 2016. The group-sphere model of international\nnews flow: A cross-national comparison of news sites. In-\nternational Communication Gazette, 78(3): 200\u2013222.\nSerrano, M. \u00c1.; Bogun\u00e1, M.; and Vespignani, A. 2009. Ex-\ntracting the multiscale backbone of complex weighted net-\nworks. PNAS, 106(16): 6483\u20136488.\nSteinberger, R.; Hegele, S.; Tanev, H.; and Della Rocca, L.\n2017. Large-scale news entity sentiment analysis. In Mitkov,\nR.; and Angelova, G., eds., Proceedings of the International\nConference Recent Advances in Natural Language Process-\ning, RANLP 2017, 707\u2013715. Varna, Bulgaria: INCOMA Ltd.University, B. K. C. H. 2020. Public Discourse\nin the U.S. 2020 Election: Resources and Data.\nhttps://cyber.harvard.edu/research/2020-election-study-\nresources-data. Accessed: 2024-03-30.\nWu, H. D. 2000. Systemic determinants of international\nnews coverage: A comparison of 38 countries. Journal of\ncommunication, 50(2): 110\u2013130.\nZandt, D. V . 2022. Media Bias/Fact Check - Search and\nLearn the Bias of News. https://mediabiasfactcheck.com/.\nAccessed: 2022-05-20.\nZuckerman, E. 2013. Rewire: Digital cosmopolitans in the\nage of connection. WW Norton & Company.\nPaper Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes.\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes.\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes.\n(d) Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? NA.\n(e) Did you describe the limitations of your work? Yes.\n(f) Did you discuss any potential negative societal im-\npacts of your work? No, because we haven\u2019t found any\npotential negative societal impacts.\n(g) Did you discuss any potential misuse of your work?\nNA.\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, re-\nsponsible release, access control, and the reproducibil-\nity of findings? Yes.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? NA.\n(b) Have you provided justifications for all theoretical re-\nsults? NA.\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? NA.\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-\nserved in your study? Yes.\n(e) Did you address potential biases or limitations in your\ntheoretical framework? NA.\n(f) Have you related your theoretical results to the existing\nliterature in social science? Yes.\n1922\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? Yes.\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA.\n(b) Did you include complete proofs of all theoretical re-\nsults? NA.\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? Yes.\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? No. Be-\ncause this is dataset paper and its application details\nare not the focus.\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes.\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? NA.\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made? Yes.\n(f) Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? Yes.\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity...\n(a) If your work uses existing assets, did you cite the cre-\nators? Yes.\n(b) Did you mention the license of the assets? NA.\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? Yes.\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you\u2019re using/curating?\nNA.\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? Yes.\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR\n(see FORCE11 (2020))? Yes.\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset (see Gebru et al.\n(2021))? Yes.\n6. Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? Yes.\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? Yes.(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? Yes.\n(d) Did you discuss how data is stored, shared, and dei-\ndentified? Yes.\n1923", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A multilingual similarity dataset for news article frame", "author": ["X Chen", "M Samory", "S Hale", "D Jurgens"], "pub_year": "2024", "venue": "Proceedings of the \u2026", "abstract": "Understanding the writing frame of news articles is vital for addressing social issues, and thus  has attracted notable attention in the fields of communication studies. Yet, assessing such"}, "filled": false, "gsrank": 355, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31435", "author_id": ["5QwsiS0AAAAJ", "m5hUWjsAAAAJ", "PBJL9ZEAAAAJ", "sGFFr5kAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:usM9fKslu8sJ:scholar.google.com/&output=cite&scirp=354&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=usM9fKslu8sJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 2, "citedby_url": "/scholar?cites=14680368828798321594&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:usM9fKslu8sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/31435/33595"}}, {"title": "Verifying the robustness of automatic credibility assessment", "year": "2024", "pdf_data": "Natural Language Processing (2024), 1\u201329\ndoi:10.1017/nlp.2024.54\nARTICLE\nVerifying the robustness of automatic credibility\nassessment\nPiotr Przyby\u0142a1,2, Alexander Shvets1and Horacio Saggion1\n1Universitat Pompeu Fabra, Barcelona, Spain and2Institute of Computer Science, Polish Academy of Sciences, Warsaw,\nPolandCorresponding author: Piotr Przyby\u0142a; Email: piotr.przybyla@upf.edu\n(Received 28 May 2024; revised 10 October 2024; accepted 10 October 2024)\nAbstract\nText classi\ufb01cation methods have been widely investigated as a way to detect content of low credibility:\nfake news, social media bots, propaganda, etc. Quite accurate models (likely based on deep neural net-\nworks) help in moderating public electronic platforms and often cause content creators to face rejectionof their submissions or removal of already published texts. Having the incentive to evade further detec-\ntion, content creators try to come up with a slightly modi\ufb01ed version of the text (known as an attack with\nan adversarial example) that exploit the weaknesses of classi\ufb01ers and result in a different output. Herewe systematically test the robustness of common text classi\ufb01ers against available attacking techniques and\ndiscover that, indeed, meaning-preserving changes in input text can mislead the models. The approaches\nwe test focus on \ufb01nding vulnerable spans in text and replacing individual characters or words, takinginto account the similarity between the original and replacement content. We also introduce BODEGA:\na benchmark for testing both victim models and attack methods on four misinformation detection tasks\nin an evaluation framework designed to simulate real use cases of content moderation. The attacked tasksinclude (1) fact checking and detection of (2) hyperpartisan news, (3) propaganda, and (4) rumours. Our\nexperimental results show that modern large language models are often more vulnerable to attacks than\nprevious, smaller solutions, e.g. attacks on GEMMA being up to 27% more successful than those on BERT.Finally, we manually analyse a subset adversarial examples and check what kinds of modi\ufb01cations are used\nin successful attacks.\nKeywords: Adversarial examples; credibility assessment; robustness; misinformation; benchmark\n1. Introduction\nMisinformation is one of the most commonly recognised problems in modern digital societies\n(Lewandowsky, Ecker, and Cook 2017 ;A k e r s et al. 2018 ;T u c k e r et al. 2018 ). Under this term,\nwe understand the publication and spreading of information that is not credible , including fake\nnews, manipulative propaganda, social media bots activity, rumours, hyperpartisan and biasedjournalism. While these problems differ in many aspects, what they have in common is non-credible (fake or malicious) content masquerading as credible: fake news as reliable news, bots as\ngenuine users, falsehoods as facts, etc. (Tucker et al. 2018 ; van der Linden 2022 ).\nGiven that both credible and non-credible content is abundant on the Internet, the assessment\nof credibility has fast been recognised as a task for machine learning (ML) or wider arti\ufb01cial intel-\nligence (AI) solutions (Ciampaglia et al. 2018 ). It is common practice among major platforms\nwith user-generated content to use such models for moderation, either as preliminary \ufb01ltering\nC/circlecopyrtThe Author(s), 2024. Published by Cambridge University Press. This is an Open Access article, distributed under the terms of the\nCreative Commons Attribution licence ( https://creativecommons.org/licenses/by/4.0/ ), which permits unrestricted re-use, distribution and\nreproduction, provided the original article is properly cited.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n2 P. Przyby\u0142a et al.\nbefore human judgement (Singhal et al. 2022 ) or as an automated detection system, for example\ninGoogleaandTwitter (Paul and Dang 2022 ).\nAre the state-of-the-art techniques of ML and, in particular, Natural Language Processing\n(NLP), up for a task of great importance to society? The standard analysis of model implemen-\ntation with traditional accuracy metrics does not suf\ufb01ce here as it neglects how possible it is tosystematically come up with variants of malicious text, known as adversarial examples (AEs), that\nful\ufb01l the original goal but evade detection (Carter, Tsikerdekis, and Zeadally, 2021 ). A realistic\nanalysis in such a use case has to take into account an adversary , that is the author of the non-\ncredible content, who has both motivation and opportunity to experiment with the \ufb01ltering system\nto \ufb01nd out its vulnerabilities.\nFor example, consider a scenario in which a foreign actor aims to incite panic by spreading\nfalse information about a hazardous fallout, under alarming headings such as Radioactive dust\napproaching after \ufb01re in a Ukrainian power plant! .\nbIf analogous scenarios were explored in the\npast, the content-\ufb01ltering systems in social media platforms will likely block such a message. Butthe adversary might come up with an adversarial example Radioactive dust coming after \ufb01re in\na Ukrainian power plant! . If the classi\ufb01er is not robust and returns a different decision for this\nvariant, the attacker succeeds.\nLooking for such weaknesses via designing AE, to assess the robustness of an investigated\nmodel, is a well-established problem in ML. However, its application to misinformation-oriented\nNLP tasks is relatively rare, despite the suitability of the adversarial scenario in this domain.\nMoreover, similarly to the situation in other domains, the adversarial attack performance dependson a variety of factors, such as the data used for training and testing, the attack goal, disturbance\nconstraints, attacked models, and evaluation measures. The common approach to measuring the\nattack success, that is by computing accuracy reduction, requires the de\ufb01nition of the maximumallowed change, with no clear way to de\ufb01ne it across various tasks. It also ignores the number of\nqueries to the victim model, which can decide the practical applicability of an attack.\nIn order to \ufb01ll the need for reproducible and comprehensive evaluation in this \ufb01eld, we have\ncreated BODEGA (Benchmark fOr aDversarial Example Generation in credibility Assessment),\nintended as a common framework for comparing AE generation solutions to inform the creation\nof \u201cbetter-defended\u201d content credibility classi\ufb01ers. We have used it to assess the robustness ofthe popular text classi\ufb01ers, including state-of-the-art large language models, by simulating attacks\nusing various AE generation solutions.\nThus, our contributions include the following:\n1. The BODEGA evaluation framework, consisting of elements simulating the misinforma-\ntion detection scenario:\n(a) A collection of four NLP tasks from the domain of misinformation, cast as binary text\nclassi\ufb01cation problems (Section 4),\n(b) A training and test dataset for each of the above tasks,\n(c) Two attack scenarios, specifying what information is available to an adversary and what\nis their goal (Section 5),\n(d) An evaluation procedure, involving a success measure designed speci\ufb01cally for this\nscenario (Section 6).\n2. A systematic evaluation of the robustness of common text classi\ufb01cation solutions of\nvarious sizes, answering several questions (Section 9):\n\u0081Q1: Which attack method delivers the best performance?\nahttps://support.google.com/youtube/thread/192701791/updates-on-comment-spam-abuse?hl =en\nbSimilar messages were shared in a 2020 wide-scale misinformation campaign in Poland (Mierzy \u00b4nska 2020 ).\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 3\n\u0081Q2: Are the modern large language models less vulnerable to attacks than their\npredecessors?\n\u0081Q3: How many queries are needed to \ufb01nd adversarial examples?\n\u0081Q4: Does targeting (selecting only some examples for AE generation) make a differencein attack dif\ufb01culty?\n3. A manual analysis of the most promising cases, revealing the kinds of modi\ufb01cations used\nby the AE solutions to confuse the victim models (Section 9.5).\nBODEGA, based on the OpenAttack framework and existing misinformation datasets, is openly\navailable for download.\ncIt can be used to evaluate the effectiveness of emerging attack strate-\ngies, as well as to test the robustness of a classi\ufb01er being prepared for deployment. Both of theseapplications can serve to improve the reliability of text classi\ufb01cation, in content \ufb01ltering and\nelsewhere.\n2. Related work\n2.1 Adversarial examples in NLP\nSearching for adversarial examples can be seen within wider efforts to investigate the robustness\nof ML models, that is their ability to maintain good performance when confronted with data\ninstances unlike those seen in training: anomalous, rare, adversarial or edge cases. This effortis especially important for deep learning models, which are not inherently interpretable, mak-\ning it harder to predict their behaviour at the design stage. The seminal work on the subject\nby Szegedy et al. (2013) demonstrated the low robustness of neural networks used to recognise\nimages. The adversarial examples were prepared by adding specially prepared noise to the origi-\nnal image, which forced the change of the classi\ufb01er\u2019s decision even though the changes were barely\nperceptible visually and the original label remained valid.\nGiven the prevalence of neural networks in language processing, a lot of work has been done\non investigating AEs in the context of NLP tasks (Zhang et al. 2020b ), but the transition from\nthe domain of images to text is far from trivial. Firstly, it can be a challenge to make changes\nsmall enough to the text, such that the original label remains applicable\u2014there is no equivalentofimperceptible noise in text. The problem has been approached on several levels: of characters,\nmaking alterations that will likely remain unnoticed by a reader (Gao et al. 2018 ; Eger et al. 2019 );\nof words, replaced while preserving the meaning by relying on thesauri (Ren et al. 2019 )o rl a n -\nguage models (Jin et al. 2020 ;L iet al. 2020 ) and, \ufb01nally, of sentences, by employing paraphrasing\ntechniques (Iyyer et al. 2018 ; Ribeiro, Singh, and Guestrin 2018 ). Secondly, the discrete nature\nof text means that methods based on exploring a feature space (e.g. guided by a gradient) mightsuggest points that do not correspond to real text. Most of the approaches solve this by only con-\nsidering modi\ufb01cations on the text level, but there are other solutions, for example \ufb01nding the\noptimal location in the embedding space followed by choosing its nearest neighbour that is a realword (Gong et al. 2018 ), or generating text samples from a distribution described by continuous\nparameters (Guo et al. 2021 ). Note that these solutions are evaluated on different datasets, making\nit hard to compare their performance. We are aware of only one previous attempt to establish areusable benchmark (Yoo et al. 2022 ), which relies on datasets for the classi\ufb01cation of topics and\nsentiment.\nApart from AE generation, a public-facing text classi\ufb01er may be subject to many other types of\nattacks, including manipulations to output desired value when a trigger word is used (Bagdasaryan\nand Shmatikov 2022 ) or perform an arbitrary task chosen by the attacker (Neekhara et al. 2019 ).\nFinally, verifying the trustworthiness of a model aimed for deployment should also take into\nchttps://github.com/piotrmp/BODEGA\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n4 P. Przyby\u0142a et al.\naccount undesirable behaviours exhibited without adversarial actions, for example its response\nto modi\ufb01cation of protected attributes, such as gender, in the input (Srivastava et al. 2023 ).\n2.2 Robustness of credibility assessment\nThe understanding that some deployment scenarios of NLP models justify expecting adversary\nactions predates the popularisation of deep neural networks, with the \ufb01rst considerations based\non spam detection (Dalvi et al. 2004 ). The work that followed was varied in the explored tasks,\nattack scenarios and approaches.\nThe \ufb01rst attempts to experimentally verify the robustness of misinformation detection were\nbased on simple manual changes (Zhou et al. 2019 ). The approach of targeting a speci\ufb01c weakness\nand manually designing rules to exploit it has been particularly popular in attacking fact-checking\nsolutions (Thorne et al. 2019 ; Hidey et al. 2020 ).\nIn the domain of social media analysis, Le et al. (2020) have examined the possibility of chang-\ning the output of a text credibility classi\ufb01er by concatenating it with adversarial text, for example\nadded as a comment below the main text. The main solution was working in the white-box sce-\nnario, with the black-box variant made possible by training a surrogate classi\ufb01er on the original\ntraining data.dIt has also been shown that social media bot detection using AdaBoost is vulner-\nable to adversarial examples (Kantartopoulos et al. 2020 ). Adversarial scenarios have also been\nconsidered with user-generated content classi\ufb01cation for other tasks, for example hate speech or\nsatire (Alsmadi et al. 2022 ).\nFake news corpora have been used to verify the effectiveness of AE generation techniques, for\nexample in the study introducing TextFooler (Jin et al. 2020 ). Interestingly, the study has shown\nthat the classi\ufb01er for fake news was signi\ufb01cantly more resistant to attacks compared to those forother tasks, that is topic detection or sentiment analysis. This task also encouraged exploration\nof vulnerability to manually crafted modi\ufb01cations of input text (Jaime, Flores, and Hao 2022 ). In\ngeneral, the fake news classi\ufb01cation task has been a common subject of robustness assessment,involving both neural networks (Ali et al. 2021 ; Koenders et al. 2021 ) and non-neural classi\ufb01ers\n(Brown et al. 2020 ;S m i t h et al. 2021 ).\nTo sum up, while there have been several experiments examining the vulnerability of mis-\ninformation detection to adversarial attacks, virtually each of them has used a different dataset,\na different classi\ufb01er and a different attack technique, making it hard to draw conclusions and\nmake comparisons. Our study is the \ufb01rst to analyse credibility assessment tasks and systematicallyevaluate their vulnerability to various attacks.\n2.3 Resources for adversarial examples\nThe efforts of \ufb01nding AEs are relatively new for NLP , and there exist multiple approaches toevaluation procedures and datasets. The variety of studies for the misinformation tasks is re\ufb02ec-tive of the whole domain\u2014see the list of datasets used for evaluation provided by Zhang et al.\n(2020b) . Hopefully, as the \ufb01eld matures, some standard practice measures will emerge, facilitating\nthe comparison of approaches. We see BODEGA as a step in this direction.\nTwo types of existing efforts to bring the community together are worth mentioning. Firstly,\nsome related shared tasks have been organised. The Build It Break It, The Language Edition\ntask (Ettinger et al. 2017 ) covered sentiment analysis and question answering, addressed by both\n\u2019builders\u2019 (building solutions) and \u2019breakers\u2019 (\ufb01nding adversarial examples). The low number ofbreaker teams\u2014four for sentiment analysis and one for question answering\u2014makes it dif\ufb01cult\nto draw conclusions, but the majority of deployed techniques involved manually inserted changes\ntargeting suspected weaknesses of the classi\ufb01ers. The FEVER 2.0 shared task (Thorne et al. 2018b ),\ndWe explain white- and black-box scenarios in Section 5.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 5\nFigure 1. An overview of the evaluation of an adversarial attack using BODEGA. For each task, three datasets are available:\ndevelopment ( Xdev), training ( Xtrain), and attack ( Xattack ). During an evaluation of an attack involving an Attacker and Victim\nmodels from the library of available models, the Attacker takes the text of the ith instance from the attack dataset ( xi), e.g.\na news piece, and modi\ufb01es it into an adversarial example ( x\u2217\ni). The Victim model is used to assess the credibility of both the\noriginal ( f(xi)) and modi\ufb01ed text ( f(x\u2217\ni)). The BODEGA score assesses the quality of an AE, checking the similarity between the\noriginal and modi\ufb01ed sample (sim( xi,x\u2217\ni)), as well as the change in the victim\u2019s output (diff( f(xi),f(x\u2217\ni))).\nfocusing on fact checking, had a \u2019Build-It\u2019 and \u2019Break-It\u2019 phases with a similar setup, except the\nadversarial examples were generated and annotated from scratch, with no correspondence to\nexisting true examples, as in Build It Break It or BODEGA. The three valid submissions concen-\ntrated around manual introduction of issues known as challenging for automated fact checking,\nincluding multi-hop or temporal reasoning, ambiguous entities, arithmetic calculations and vague\nstatements.\nSecondly, two software packages were released to aid evaluation: TextAttack (Morris et al. 2020 )\nandOpenAttack (Zeng et al. 2021 ). They both provide a software skeleton for setting up the attack\nand implementations of several AE generation methods. A user can add the implementation of\ntheir own victims and attackers and perform the evaluation. BODEGA code has been devel-\noped based on OpenAttack by providing access to misinformation-speci\ufb01c datasets, classi\ufb01ers\nand evaluation measures.\n3. Adversarial example generation\nAdversarial example generation is a task aimed at testing the robustness of ML models, known as\nvictims in this context. The goal is to \ufb01nd small modi\ufb01cations to the input data that will change the\nmodel output even though the original meaning is preserved and the correct response remains the\nsame. If such changed instances, known as adversarial examples, could be systematically found, it\nmeans the victim classi\ufb01er is vulnerable to the attack and not robust.\nIn the context of classi\ufb01cation, this setup (illustrated in Fig. 1) could be formalised through the\nfollowing:\n\u0081A training set Xtrainand an attack set Xattack , each containing instances ( xi,yi), coupling\nthei-th instance features xiwith its true class yi,\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n6 P. Przyby\u0142a et al.\n\u0081A victim model f, predicting a class label \u02c6yibased on instance features: \u02c6yi=f(xi),\n\u0081A modi\ufb01cation function (attack model) m, turning xiinto an adversarial example x\u2217\ni=\nm(xi).\nThroughout this study, we use yi=1 (positive class) to denote non-credible information and 0 for\ncredible content.\nThe goal of the attacker is to come up with the mfunction. This process typically involves\ngenerating numerous variations of xiand querying the model\u2019s response to them until the best\ncandidate is selected. An evaluation procedure assesses the success of the attack on the set Xattack\nby comparing xitox\u2217\ni(which should be maximally similar) and f(xi)t of(x\u2217\ni)( w h i c hs h o u l db e\nmaximally different).\nConsider the following real example observed in our evaluation:\n1. Within the propaganda recognition task, one of the instances in Xattack contains a text\nfragment xi=\u2019Despite the hysteria of the left, it is impossible to see the Trump administration\nas anything but \ufb01rm in its dealing with Russia. \u2019, labelled as yi=1 (propaganda technique\nused).\n2. The victim classi\ufb01er (BiLSTM) correctly assigns the label f(xi)=1 with 94.76% certainty.\n3. An attacker (BERT-ATTACK) tests 26 different reformulations of the text, until it comes\nup with the modi\ufb01ed version: x\u2217\ni=m(xi)=\u2019Given the hysteria of the left, it is impossible to\nsee the Trump administration as anything but \ufb01rm in its dealing with Russia. \u2019\n4. The victim classi\ufb01er changes its decision after the modi\ufb01cation, assigning f(x\u2217\ni)=0( n o\npropaganda) with 54.65% certainty.\n5. This example is considered a good-quality AE, since it achieves a change in the classi\ufb01er\u2019s\ndecision ( f(xi)/negationslash=f(x\u2217\ni)) with a small change in text meaning.\n4. BODEGA tasks\nIn BODEGA, we include four misinformation detection tasks:\n\u0081Hyperpartisan news (HN),\n\u0081Propaganda recognition (PR),\n\u0081Fact checking (FC),\n\u0081Rumour detection (RD).\nFor each of these problems, we rely on an already established dataset with credibility labels\nprovided by expert annotators. The tasks are all presented as text classi\ufb01cation.\nWhenever data split is released with a corpus, the training subset is included as Xtrain\u2014\notherwise we perform a random split. In order to enable the evaluation of AE generation solutionsthat carry a high computational cost, we de\ufb01ne the X\nattack subset which is restricted to around 400\ninstances taken from the test set. The rest of the cases in the original test set are left out for future\nuse as a development subset. Table 1summarises the data obtained.\nTable 2includes some examples of the credible and non-credible content in each task. We\ncan see how the non-credible examples often focus on particularly politically charged topics, try-\ning to provoke an emotional reaction in readers. This is a well-known aspect of misinformation(Bakir and McStay 2017 ; Allcott and Gentzkow 2017 ). In the following subsections, we outline the\nmotivation, origin and data processing within each of the tasks.\n4.1 HN: hyperpartisan news\nSolutions for news credibility assessment, sometimes equated with fake news detection, usually\nrely on one of three factors: (1) writing style (Horne and Adali 2017 ; Przyby\u0142a, 2020 ), (2) veracity\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 7\nTable 1. Four datasets used in BODEGA, with the task ID (see descrip-\ntions in text), number of instances in training, attack and development\nsubsets, and an overall percentage of positive (non-credible) class\nTask Training Attack Dev. Positive\nHN 60,235 400 3,600 50.00%\n................................ ........................ ........................ ........................ ....................... ..........................\nPR 12,675 416 3,320 29.42%\n................................ ........................ ........................ ........................ ....................... ..........................\nFC 172,763 405 19,010 51.27%\n................................ ........................ ........................ ........................ ....................... ..........................\nRD 8,694 415 2,070 32.68%\nof included claims (Vlachos and Riedel 2014 ; Graves 2018 ) or (3) context of social and traditional\nmedia (Shu, Wang, and Liu 2019 ; Liu and Wu 2020 ).\nIn this task, we focus on the writing style. This means a whole news article is provided to a\nclassi\ufb01er, which has no ability to check facts against external sources, but has been trained onenough articles to recognise stylistic cues. The training data include numerous articles coming\nfrom sources with known credibility, allowing one to learn writing styles typical for credible and\nnon-credible outlets.\nIn BODEGA, we employ a corpus of news articles (Potthast et al. 2018 ) used for the task\nofHyperpartisan News Detection at SemEval-2019 (Kiesel et al. 2019 ). The credibility was\nassigned based on the overall bias of the source, assessed by journalists from BuzzFeed and\nMediaBiasFactCheck.com .\neWe use 1/10th of the training set (60,235 articles) and assign label 1\n(non-credible) to articles from sources annotated as hyperpartisan, both right- and left-wing.\nSee the \ufb01rst row of Table 2for examples: credible from Albuquerque journalfand non-credible\nfrom Crooks and Liars .g\n4.2 PR: propaganda recognition\nThe task of propaganda recognition involves detecting text passages, whose author tries to in\ufb02u-\nence the reader by means other than objective presentation of the facts, for example by appealing\nto emotions or exploiting common fallacies (Smith 1989 ). The usage of propaganda techniques\ndoes not necessarily imply falsehood, but in the context of journalism it is associated with manip-ulative, dishonest and hyperpartisan writing. In BODEGA, we use the corpus accompanying\nSemEval 2020 Task 11 ( Detection of Propaganda Techniques in News Articles ), with 14 propaganda\ntechniques annotated in 371 newspaper articles by professional annotators (da San Martino et al.\n2020 ).\nPropaganda recognition is a \ufb01ne-grained task, with SemEval data annotated on the token level,\nakin to a Named Entity Recognition task. In order to cast it as a text classi\ufb01cation problem as oth-ers here, we split the text on sentence level and assign target label equal 1 to sentences overlapping\nwith any propaganda instances and 0 to the rest. Because only the training subset is made publicly\navailable,\nhwe randomly extract 20 per cent of documents for attack and development subsets.\nSee the second row of Table 2for examples\u2014the credible fragment with no propaganda\ntechnique and the non-credible, annotated as including \ufb02ag-waving.\nehttps://zenodo.org/record/1489920\nfhttps://abqjournal.com/328734/syria-blamed-for-missed-deadline-on-weapons.html\nghttp://crooksandliars.com/2014/12/foxs-cavuto-and-stein-try-con\ufb02ate\nhhttps://zenodo.org/record/3952415\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n8 P. Przyby\u0142a et al.\nTable 2. Examples of credible and non-credible content in each of the tasks: hyperpartisan news (HN), propaganda recog-\nnition (PR), fact checking (FC) and rumour detection (RD). See main text for references to data sources and labelling\ncriteria\nTask Credible example Non-credible example\nHN Syria blamed for missed deadline on chemical\narsenalU.S. of\ufb01cials conceded that a Tuesday deadline forridding Syria of hundreds of tons of liquid poisons\nwould not be met, citing stalled progress in\ntransporting the chemicals across war-ravagedcountryside to ships that will carry them out of theregion. But the of\ufb01cials insisted that the overall\neffort to destroy President Bashar Assad\u2019s chemical\narsenal was on track. \u201cWe continue to makeprogress, which has been the important part,\u201d State\nDepartment spokeswoman Marie Harf told\nreporters. \u201cIt was always an ambitious timeline, butwe are still operating on the June 30th timeline forthe complete destruction.\u201d ( ...)Fox\u2019s Cavuto And Stein Try To Con\ufb02ate \u2019Grubergate\u2019\nWith Vietnam And The Pentagon Papers\nOver at Faux \u201cnews\u201d this Tuesday, rather than focus\non the newly released Senate torture report, it\u2019s been\nall Jonathan Gruber and \u201cGrubergate\u201d all the time and\nwall to wall coverage of another one of Darrell Issa\u2019sObamacare witch hunts, otherwise known as a HouseOversight Committee hearing.\nAs soon as I heard the hearing was scheduled I\nknew that it meant things were going to get ugly overat Fox, but not even in my wildest imagination could I\nhave come up with this big giant turd that Neil Cavuto\nand his buddy Ben Stein managed to toss against thewall to attack Obamacare and Gruber. ( ...)\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nPR Leading Democratic senators like Robert Menendez,\nBen Cardin and Chuck Schumer, who opposedObama\u2019s Iran deal may now feel that as opponents\nof the Trump administration, they are required to\noppose any change to the Iran Nuclear AgreementReview ActWhat outcome would justify another U.S. war in a\nregion where all the previous wars in this century haveleft us bleeding, bankrupt, divided and disillusioned?\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nFC Cersei Lannister. She subsequently appeared in A\nClash of Kings (1998) and A Storm of Swords (2000).A Clash of Kings.\nA Clash of Kings is the second novel\nin A Song of Ice and Fire, an epic fantasy series by\nAmerican author George R. R. Martin expected to\nconsist of seven volumes. \u2192Cersei Lannister appears\nin a series that was written by an author from theUnited StatesDavid Bowie.\nDuring his lifetime, his record sales,\nestimated at 140 million worldwide, made him one ofthe world\u2019s best-selling music artists. \u2192David Bowie\nonly sold records in Jamaica\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nRD BREAKING: Three gunmen involved in attack on\nCharlie Hebdo magazine, French Interior MinisterBernard Cazeneuve says. http://t.co/ak9mTVfJdR\n@cnni the Islamic leaders should do something\nabout the image of Islam by speaking out againstthe terrorists\n@cnni expel Muslims from European soil and\ndestroy all the mosques.\n@cnni it\u2019s not the religion. But how the people\ninterpret the writings and that\u2019s what causes them\nto do bad things.\n@cnni terrorism needs concerted efforts from\nevery citizen to \ufb01ght it,religion is going beyondboundaries if it can cause terror attacksReports: #CharlieHebdo suspects killed\nhttp://t.co/rsl4203bcQ\nDamn, this is like a movie RT @Huf\ufb01ngtonPost\nReports: #CharlieHebdo suspects killed\nhttp://t.co/zCuZD1cure\n?@Huf\ufb01ngtonPost: Reports: #CharlieHebdo\nsuspects killed http://t.co/mWCSjh3CkH? superb\nsimultaneous response by the French tactics unit.\n@Huf\ufb01ngtonPost great news! No trial, no taxpayer\nmoney spent to support them.\n@Huf\ufb01ngtonPost Good news !!! Alah Akbar !!\n@Huf\ufb01ngtonPost damnit!!! That\u2019s what those\nfuckers wanted!! Now they will be hailed asmartyrs ....\n@Huf\ufb01ngtonPost Can you con\ufb01rm the reports that\nthose suspects were killed by French police? ( ...)\n4.3 FC: fact checking\nFact checking is the most advanced way human experts can verify credibility of a given text: by\nassessing the veracity of the claims it includes with respect to a knowledge base (drawing from\nmemory, reliable sources and common sense). Implementing this work\ufb02ow in AI systems ascomputational fact checking (Graves 2018 ) is a promising direction for credibility assessment.\nHowever, it involves many challenges\u2014choosing check-worthy statements (Nakov et al. 2022 ),\n\ufb01nding reliable sources (Przyby\u0142a et al.2022 ), extracting relevant passages (Karpukhin et al. 2020 )\netc. Here we focus on the claim veri\ufb01cation stage. The input of the task is a pair of texts\u2014target\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 9\nclaim and relevant evidence\u2014and the output label indicates whether the evidence supports the\nclaim or refutes it. It essentially is Natural Language Inference (NLI) (MacCartney 2009 )i nt h e\ndomain of encyclopaedic knowledge and newsworthy events.\nWe use the dataifrom FEVER shared task (Thorne et al. 2018a ), aimed to evaluate fact-\nchecking solutions through a manually created set of evidence-claim pairs. Each pair connects aone-sentence claim with a set of sentences from Wikipedia articles, including a label of SUPPORTS\n(the evidence justi\ufb01es the claim), REFUTES (the evidence demonstrates the claim to be false) or\nNOT ENOUGH INFO (the evidence is not suf\ufb01cient to verify the claim). For the purpose of\nBODEGA, we take the claims from the \ufb01rst two categories,\njconcatenating all the evidence text.k\nThe labels for the test set are not openly available, so we use the development set in this role.\nSee the examples in the third row of Table 2: the credible instance, where combined evidence\nfrom two articles (titles underlined) supports the claim (after the arrow); and non-credible one,\nwhere the evidence refutes the claim.\n4.4 RD: rumour detection\nA rumour is an information spreading between people despite not having a reliable source. In\nthe online misinformation context, the term is used to refer to content shared between users ofsocial media that comes from an unreliable origin, for example an anonymous account. Not every\nrumour is untrue as some of them can be later con\ufb01rmed by established sources. Rumours can be\ndetected by a variety of signals (Al-Sarem et al. 2019 ), but here we focus on the textual content of\nthe original post and follow-ups from other social media users.\nIn BODEGA we use the Augmented dataset of rumours and non-rumours for rumour detec-\ntion (Han, Gao, and Ciravegna, 2019 ), created from Twitter threads relevant to six real-world\nevents (2013 Boston marathon bombings, 2014 Ottawa shooting, 2014 Sydney siege, 2015 Charlie\nHebdo Attack, 2014 Ferguson unrest, 2015 Germanwings plane crash). The authors of the dataset\nstarted with the core threads annotated manually as rumours and non-rumours, then auto-matically augmented them with other threads based on textual similarity. We followed this by\nconverting each thread to a \ufb02at feed of concatenated text fragments, including the initial post\nand subsequent responses. We set aside one of the events (Charlie Hebdo attack) for attack anddevelopment subsets, while others are included in the training subset.\nSee the last row of Table 2for examples, both regarding the Charlie Hebdo shooting, but only\nthe credible one is based on information from a credible source.\n5. Attack scenario\nThe adversarial attack scenarios are often classi\ufb01ed according to what information is available tothe attacker. The black-box scenarios assume that no information is given on the inner workings\nof the targeted model and only system outputs for a given input can be observed. In white-box sce-\nnarios, the model is openly available to the attacker, allowing them to observe its internal structureand understand how predictions are made.\nWe argue neither of these scenarios is realistic in the practical misinformation detection setting,\nfor example a content \ufb01lter deployed in a social network. We cannot assume a model is availableto the attacker since such information is usually not shared publicly; moreover, the model likely\ngets updated often to keep up with the current topics. On the other hand, the black-box scenario\nis too restrictive, as it assumes no information about the model is ever revealed. Also, once acertain design approach is popularised as the best performing in the NLP community, it tends to\nihttps://fever.ai/dataset/fever.html\njNOT ENOUGH INFO was excluded to cast the task as binary classi\ufb01cation, in line with the other ones.\nkIncluding the titles, which are often an essential part of the context in case of encyclopaedic articles.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n10 P. Przyby\u0142a et al.\nbe applied to very many, if not most, solutions to related problems (Church and Kordoni 2022 )\u2014\nthis is especially noticeable in case of large language models, such as BERT (Devlin et al. 2018 )o r\nGPT (Radford et al. 2018 ) and their successors.\nFor these reasons, in BODEGA we use the grey-box approach. The following information is\nconsidered available to an attacker preparing AEs:\n\u0081A \u201chidden\u201d classi\ufb01er fthat for any arbitrary input returns f(x)\u2208{0, 1}and a likelihood\nscore sf(x), that is a numerical representation on how likely a given example xis to be\nassigned a positive class. This information is more helpful to attackers than only f(x), which\nis typically set by applying a threshold tf,f o re x a m p l e f(x)=1\u21d0\u21d2 sf(x)>tf. The thresh-\nold expresses the minimum value of the score necessary for the classi\ufb01er to assign a positivelabel to the instance. Typically, this value is set to 0.5.\n\u0081The general description of an architecture of classi\ufb01er f, for example \"a BERT encoder\nfollowed by a dense layer and softmax normalisation.\"\n\u0081The training Xtrain, the development Xdev, and the evaluation Xattack subsets.\nThis setup allows users of BODEGA to exploit weaknesses of classi\ufb01ers without using the complete\nknowledge of the model, while maintaining some resemblance of practical scenarios.\nNote that the grey-box setup is signi\ufb01cantly more challenging to attack compared to the white-\nbox scenario. In the latter, the attacker can directly see how the input features affect the outputdecision and modify those with the highest in\ufb02uence. Mathematically, this approach can be\nexpressed in terms of computing a gradient of the decision variable and following it\u2014thus the\ngradient-based methods (Zhang et al. 2020b ). However, this is not possible to do in grey-box\napproach, where internal model weights, necessary for such procedure, are not revealed.\nAnother choice that needs to be made concerns the goal of the attacker. Generally, adversarial\nactions are divided into untargeted attacks, where any change in the victim\u2019s predictions is con-\nsidered a success and targeted attacks, which seek to obtain a speci\ufb01c response, aligned with the\nattacker\u2019s goals (Zhang et al. 2020b ).\nConsider a classi\ufb01er fthat for a given instance x\ni, with true value yi, outputs class f(xi), which\nmay be correct or incorrect. An untargeted attack involves perturbing xiintox\u2217\ni, such that f(xi)/negationslash=\nf(x\u2217\ni). A successful attack would undoubtedly show the brittleness of the classi\ufb01er, but may not be\nnecessarily helpful for a malicious user, for example if yicorresponded to malicious content, but\nthe original response f(xi) was incorrect.\nTaking into account the misinformation scenario, we consider the targeted attack to satisfy the\nfollowing criteria:\n\u0081The true class corresponds to non-credible content, that is yi=1,\n\u0081The original classi\ufb01er response was correct, that is f(xi)=yi.\nSuccess in this attack corresponds to a scenario of the attacker preparing a piece of non-credible\ncontent that is falsely recognised as credible thanks to the adversarial modi\ufb01cation. We thereforeuse only a portion of the evaluation X\nattack subset for this kind of attack.\nBynon-credible content, we mean:\n\u0081In case of hyperpartisan news, an article from a hyperpartisan source,\n\u0081In case of propaganda recognition, a sentence with a propaganda technique,\n\u0081In case of fact checking, a statement refuted by the provided evidence,\n\u0081In case of rumour detection, a message feed starting from a post including a rumour.\nIn BODEGA, both untargeted and targeted attacks can be evaluated.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 11\nAll of the text forming an instance can be modi\ufb01ed to make an adversarial attack. In case of\nfact checking, this includes both the claim and the evidence. Similarly for rumour detection, notonly the original rumour but also any of the follow-up messages in the thread are included in the\ntext instance. This corresponds to the real-life scenario, where all of the above content is user-\ngenerated and can to some degree be in\ufb02uenced by an attacker (see further discussion on thismatter in Section 10.1).\nFinally, note that BODEGA imposes no restriction on the number of queries sent to the victim,\nthat is the number of variants an attacker is allowed to test for each instance before providingthe \ufb01nal modi\ufb01cation. This number would typically be limited, especially in a security-oriented\napplication (Chen et al. 2022 ). However, the constraints might be very different depending on a\nparticular application scenarios. Some services might impose very strict limits on a number of sub-missions a client can make within a speci\ufb01ed time, while others might allow many more attempts.\nIf an attacker knows the data the victim classi\ufb01er was trained on, they can even train a surrogate\nclassi\ufb01er and issue as many queries as needed. Thus, in order to provide a comprehensive evalua-tion, the number of queries is not limited in BODEGA, but it is recorded as an evaluation metric\n(see the next section).\n6. Evaluation\nPreparing adversarial examples involves balancing two goals in the adversarial attack (see Fig. 1):\n1. Maximising diff( f(xi),f(x\u2217\ni))\u2014difference between the classes predicted by the classi\ufb01er for\nthe original and perturbed instance,\n2. Maximising sim( xi,x\u2217\ni)\u2014similarity between the original and perturbed instance.\nIf (1) is too small, the attack has failed, since the classi\ufb01er preserved the correct prediction. If\n(2) is too small, the attack has failed, since the necessary perturbation was so large it defeated theoriginal purpose of the text.\nThis makes the evaluation multi-criterion and challenging since neither of these factors mea-\nsured in isolation re\ufb02ects the quality of AEs. The conundrum is usually resolved by setting theminimum similarity (2) to a \ufb01xed threshold (known as perturbation constraint ) and measuring\nthe reduction in classi\ufb01cation performance, that is accuracy reduction (Zhang et al. 2020b ). This\ncan be problematic as there are no easy ways to decide the value of the threshold that will guaran-\ntee that the class remains valid. The issue is especially relevant for a task as subtle as credibilityanalysis\u2014for example how many word swaps can we do on a real news piece before it loses\ncredibility?\nIn BODEGA, we avoid this problem by inverting the approach. Instead of imposing constraints\non goal (2) and using (1) as the evaluation measure, we impose constraints on (1) and use (2)\nfor evaluation. Speci\ufb01cally, we only count the instances when the modi\ufb01cation was suf\ufb01cient to\nchange the classi\ufb01er\u2019s decision (1) and treat text similarity (2) as the quality evaluation measure.\nWe de\ufb01ne an adversarial modi\ufb01cation quality score, called BODEGA score .B O D E G As c o r e\nalways lies within 0-1 and a high value indicates good-quality modi\ufb01cation preserving the origi-\nnal meaning (with score =1 corresponding to no visible change), while low value indicates poor\nmodi\ufb01cation, altering the meaning (with score =0 corresponding to completely different text).\nIn the remainder of this section, we discuss the similarity measurement techniques we employ\nand outline how they are combined to form a \ufb01nal measure of attack success.\n6.1 Semantic score\nThe \ufb01rst element used to measure meaning preservation is based on BLEURT (Sellam, Das, and\nParikh 2020 ). BLEURT was designed to compute the similarity between a candidate and reference\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n12 P. Przyby\u0142a et al.\nsentences in evaluating solutions for natural language generation tasks (e.g. machine translation).\nThe underlying model is trained to return values between 1 (identical text) and 0 (no similarity).\nBLEURT helps to properly assess semantic similarity; for example, replacing a single word\nwith its close synonym will yield high score value, while using a completely different one will\nnot. However, BLEURT is trained to interpret multi-word modi\ufb01cations (i.e. paraphrases) as well,leading to better correlation with human judgement than other popular measures, for example\nBLEU or BERTScore. This is possible thanks to \ufb01ne-tuning using synthetic data covering vari-\nous types of semantic differences, for example contradiction as understood in the NLI (Natural\nLanguage Inference) task. This is especially important for our usecase, helping to properly han-\ndle the situations where otherwise small modi\ufb01cations completely change the meaning of the text\n(e.g. a negation), rendering an AE unusable.\nIn BODEGA, we use the pyTorch implementation of BLEURT,\nlchoosing the recommendedm\nBLEURT-20 variant. Since the score is only calibrated to the 0-1 range, other numbers can be pro-\nduced as well. Thus, our semantic score is equal to BLEURT (clipped to 0-1 if necessary). Finally,since BLEURT is a sentence-level measure and our tasks involve longer text fragments,\nnwe (1)\nsplit the text into sentencesousing LAMBO (Przyby\u0142a, 2022), (2) \ufb01nd the pairs of sentences from\nthe original and modi\ufb01ed text that are most similar using Levenshtein distance and (3) computesemantic similarities between sentence pairs, returning its average as semantic score.\n6.2 Character score\nLevenshtein distance is used to express how different one string of characters is from another.\nSpeci\ufb01cally, it computes the minimum number of elementary modi\ufb01cations (character additions,\nremovals, replacements) it would take to transform one sequence into another (Levenshtein 1966 ).\nLevenshtein is a simple measure that does not take into account the meaning of the words.\nHowever, it is helpful to properly assess modi\ufb01cations that rely on graphical resemblance. For\nexample, one family of adversarial attacks relies on replacing individual characters in text (e.g. call\ntoca||), altering the attacked classi\ufb01er\u2019s output. The low value of Levenshtein distance in this case\nrepresents the fact that such modi\ufb01cation may be imperceptible for a human reader.\nIn order to turn Levenshtein distance lev_dist(a,b) into a character similarity score, we\ncompute the following:\nChar_score( a,b)=1\u2212lev_dist(a,b)\nmax (|a|,|b|)\nChar_score is between 0 and 1, with higher values corresponding to larger similarity, with\nChar_score( a,b)=1i faandbare the same and Char_score( a,b)=0i ft h e yh a v en oc o m m o n\ncharacters at all.\n6.3 BODEGA score\nThe BODEGA score for a pair of original text xiand modi\ufb01ed text x\u2217\niis de\ufb01ned as follows:\nBODEGA_score( xi,x\u2217\ni)=Con_score( xi,x\u2217\ni)\u00d7\nSem_score( xi,x\u2217\ni)\u00d7Char_score( xi,x\u2217\ni),\nwhere Sem_score( xi,x\u2217\ni) is semantic score; Char_score( xi,x\u2217\ni) is character score; and\nCon_score( xi,x\u2217\ni) is confusion score, which takes value 1 when an adversarial example is produced\nand succeeds in changing the victim\u2019s decision (i.e. f(xi)/negationslash=f(x\u2217\ni)) and 0 otherwise.\nlhttps://github.com/lucadiliello/bleurt-pytorch\nmhttps://github.com/google-research/bleurt\nnExcept propaganda detection, where input is a single sentence.\noExcept fact-checking, where we simply split evidence from the claim.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 13\nThe overall attack success measure is computed as an average over BODEGA scores for all\ninstances in the attack set available in a given scenario (targeted or untargeted). The success mea-sure reaches 0 when the AEs bear no similarity to the originals, or they were not created at all.\nThe value of 1 corresponds to the situation, unachievable in practice, when AEs change the victim\nmodel\u2019s output with immeasurably small perturbation.\nMany adversarial attack methods include tokenisation that does not preserve the word case or\nspacing between them. Our implementation of the scoring disregards such discrepancies between\ninput and output, as they are not part of the intended adversarial modi\ufb01cations.\nApart from BODEGA score, expressing the overall success, the intermediate measures can\npaint a fuller picture of the strengths and weaknesses of a particular solution:\n\u0081Confusion score\u2014in how many of the test cases the victim\u2019s decision was changed,\n\u0081Semantic score\u2014an average over the cases with changed decision,\n\u0081Character score\u2014an average over the cases with changed decision.\nWe also report the number of queries made to the victim, averaged over all instances.\n7. Victim classi\ufb01ers\nA victim classi\ufb01er is necessary to perform an evaluation of an AE generation solution. We include\nimplementations of text classi\ufb01er based on various common architectures: a recurrent neural\nnetwork (BiLSTM) trained from scratch; and \ufb01ne-tuned language models: small masked model\n(BERT), large generative model (GEMMA2B) and a very large generative model (GEMMA7B),delivering state-of-the-art results in the established benchmarks.\nThis component of BODEGA could be easily replaced by newer implementations, either to test\na robustness of a speci\ufb01c classi\ufb01er architecture or to have a better understanding of applicabilityof a given AE generation solution.\n7.1 BiLSTM\nThe recurrent network is implemented using the following layers:\n\u0081An embedding layer, representing each token as vector of length 32,\n\u0081Two LSTM (Hochreiter and Schmidhuber 1997 ) layers (forwards and backwards), using\nhidden representation of length 128, returned from the edge cells and concatenated as\ndocument representation of length 256,\n\u0081A dense linear layer, computing two scores representing the two classes, normalised to\nprobabilities through softmax.\nThe input is tokenised using BERT uncased tokeniser (see below). The maximum allowed input\nlength is 512, with padding as necessary. For each of the tasks, a model instance is trained from\nscratch for 10 epochs by using Adam optimiser (Kingma and Ba 2015 ), a learning rate of 0.001\nand batches of 32 examples each. The implementation uses PyTorch .\n7.2 BERT\nAs a baseline pretrained language model, we use BERT in the base variant (Devlin et al. 2018 ).\nThe model is \ufb01ne-tuned for sequence classi\ufb01cation using Adam optimiser with linear weight decay\n(Loshchilov and Hutter 2019 ), starting from 0.00005, for 5 epochs. We use maximum input length\nof 512 characters and a batch size of 16. The training is implemented using the Hugging Face\nTransformers library (Wolf et al. 2020 )(bert-base-uncased model).\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n14 P. Przyby\u0142a et al.\n7.3 Gemma\nIn order to assess the vulnerability of the large language models to AEs, we include Gemma\n(Gemma Team and Google DeepMind 2024 ). Gemma is a recent generative language model,\nderived from Google\u2019s Gemini models and following the same design principles as the GPT family\n(Radford et al. 2018 ). We include both the smaller variant with 2 billion parameters, as well as\nthe full 7-billion model, loaded through Hugging Face Transformers . They have been evaluated in\nmultiple benchmarks and the latter has shown the best performance among the openly available\nlarge language models (Gemma Team and Google DeepMind 2024 ).\nThe \ufb01ne-tuning was performed using the same procedure as for BERT. However, in order\nto keep the computing requirements under control, we applied parameter-ef\ufb01cient \ufb01ne-tuning\n(Lialin, Deshpande, and Rumshisky 2023 ). Namely, we used QLoRA optimisation (Dettmers\net al. 2023 ), based on Low Rank Adaptation (LoRA) (Hu et al. 2021 ) with reduced numerical\nprecision. These are implemented using the Hugging Face \u2019s libraries peft andbitsandbytes ,\nrespectively.\n8. AE generation solutions\nWithin BODEGA, we include the AE generation solutions implemented in the OpenAttack frame-\nwork. We exclude the approaches for white-box scenario (gradient-based) and those that yieldedpoor performance in preliminary tests. We test 8 approaches:\n\u0081BAE (Garg and Ramakrishnan 2020 ) uses BERT (Devlin et al. 2018 ) as a masked language\nmodel to generate word candidates that are likely in a given context. This includes both\nreplacing existing tokens as well as inserting new ones.\n\u0081BERT-ATTACK (Liet al. 2020 ) is a very similar approach, which starts with \ufb01nding out if\na word is vulnerable by checking victim\u2019s response to its masking. The chosen words are\nreplaced using BERT candidates, but unlike in BAE, no new words are inserted.\n\u0081DeepWordBug (Gao et al. 2018 ) works at the character level, seeking modi\ufb01cations that\nare barely perceptible for humans, but will modify an important word into one unknown\nto the attacked model. The options include character substitutions, removal, insertion and\nreordering.\n\u0081Genetic (Alzantot et al. 2018 ) is using the genetic algorithm framework. A population\nincludes variants of text built by word replacements (using GloVe representation to ensure\nmeaning preservation), the most promising of which can replicate and combine until a\nsuccessful AE is found.\n\u0081SememePSO (Zang et al. 2020 ) employs a related framework, namely Particle Swarm\nOptimisation (PSO). A group of particles , each representing a text modi\ufb01cation with a\ncertain probability of further changes ( velocity ), moves through the feature space until an\noptimal position is found.\n\u0081PWWS (Ren et al. 2019 ) is a classical greedy word replacement approach. However, it dif-\nfers from the majority of the solutions by using WordNet , instead of vector representations,\nto obtain synonym candidates.\n\u0081SCPN (Iyyer et al. 2018 ) performs paraphrasing of the whole text through a bespoke\nencoder-decoder model. In order to train this model, the authors generate a dataset of\nparaphrases through backtranslation from English to Czech.\n\u0081TextFooler (Jinet al. 2020 ) is a greedy word-substitution solution. Unlike other similar\napproaches, it takes into account the syntax of the attacked text, making sure the replace-\nment is a valid word that agrees with the original regarding its part of speech. This helps tomake sure the AE is \ufb02uent and grammatically correct.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 15\nTable 3. Performance of the victim classi\ufb01ers, expressed as F-score over the\nattack subset\nBiLSTM BERT GEMMA2B GEMMA7B\nHN 0.7076 0.7544 0.7792 0.7603\n............................... ................................. ................................. .............................. ......................... .....................\nPR 0.4857 0.6410 0.6271 0.6840\n............................... ................................. ................................. .............................. ......................... .....................\nFC 0.7532 0.9360 0.9701 0.9727\n............................... ................................. ................................. .............................. ......................... .....................\nRD 0.6234 0.7547 0.7609 0.7229\nParameters 1 M 340 M 2B 7B\nThe main problem the presented solutions try to solve is essentially maximising a goal function\n(victim\u2019s decision) in a vast space of possible modi\ufb01cations to input text, which is further compli-\ncated by its discrete nature. Direct optimisation is not computationally feasible here, giving wayto methods that are greedy (performing the change that improves the goal the most) or maintain\na population of varied candidate solutions (PSO and evolutionary algorithms). The majority of\nthe solutions operate on word level, seeking replacements that would in\ufb02uence the classi\ufb01cationresult without modifying the meaning. The exceptions are sentence-level SCPN, performing para-\nphrasing of entire sentences, and character-level DeepWordBug, replacing individual characters\nin text to preserve super\ufb01cial similarity to the original. They all use victims\u2019 scores to look for mostpromising modi\ufb01cations, except for SCPN, which operates blindly, simply generating numerous\npossible paraphrases.\nAll of the attackers are executed with their default functionality, except for BERT-ATTACK,\nthat we use without the generation of subword permutations, which is prohibitively slow for\nlonger documents. Just like the victim classi\ufb01er, the AE solution interface in BODEGA allows\nfor new solutions to be added and tested as the \ufb01eld progresses.\n8.1 Classi\ufb01cation performance\nTable 3shows the performance of the victim classi\ufb01ers, computed as F-score over the test data\n(combined development and attack subsets). As expected, BERT easily outperforms a neural net-work trained from scratch. The credibility assessment tasks are subtle and the amount of data\navailable for training severely limits the performance. Thus, the BERT model has an advantage\nby relying on knowledge gathered during pretraining. This is demonstrated by the performancegap being the largest for the dataset with the least data available (propaganda detection) and the\nsmallest for the most abundant corpus (hyperpartisan news). The Gemma models perform even\nbetter than BERT in all tasks. However, the improvement is not as spectacular (a few per cent) andGEMMA7B does not provide uniformly better results than the 2 billion model.\n9. Experiments\nThe purpose of the experiments is to test the BODEGA framework in action and improve ourunderstanding of the vulnerability of content-\ufb01ltering solutions to adversarial actions. This will\nalso establish a baseline for systematic evaluation of future classi\ufb01ers and AE generators. To that\nend, we test the attack performance for:\n\u0081four tasks (HN, PR, FC, RD),\n\u0081eight attackers (BAE, BERT-ATTACK, DeepWordBug, Genetic, SememePSO, PWWS,SCPN, textFooler),\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n16 P. Przyby\u0142a et al.\n\u0081four victims (BiLSTM, BERT, GEMMA2B, GEMMA7B),\n\u0081two scenarios (untargeted and targeted).\nIn total, 4 \u00d78\u00d74\u00d72=256 experiments are performed, each evaluated using the measures\nintroduced in Section 6.\nThe full results are shown in the appendix. Here we present an analysis focused on key\nquestions:\n\u0081Q1: Which attack method delivers the best performance?\n\u0081Q2: Are the modern large language models less vulnerable to attacks than their predeces-sors?\n\u0081Q3: How many queries are needed to \ufb01nd adversarial examples?\n\u0081Q4: Does targeting make a difference in attack dif\ufb01culty?\nMoreover, we perform a manual analysis of the most promising AEs (Section 9.5).\n9.1 Q1: attack methods\nTable 4compares the performance of the untargeted attack methods in various tasks, averaged\nover victim models.\nThe hyperpartisan news detection task is relatively easy for generating AEs. BERT-ATTACK\nachieves the best BODEGA score of 0.56, which is possible due to changing the decision on 90 per\ncent of the instances while preserving high similarity, both in terms of semantics and characters.However, DeepWordBug (a character-level method) provides the best results in terms of seman-\ntic similarity, changing less than 1 per cent of characters on average. The only drawback of this\nmethod is that it works in 25 per cent of the cases, failing to change the victim\u2019s decision in theremaining ones.\nThe propaganda recognition task signi\ufb01cantly differs from the previous task in terms of text\nlength, including individual sentences rather than full articles. As a result, every word is moreimportant and it becomes much harder to make the changes imperceptible, resulting in lower\ncharacter similarity scores. This setup appears to favour the Genetic method, obtaining the best\nBODEGA score: 0.49. This approach performs well across the board, but it comes at a high cost interms of model queries. Even for the short sentences in propaganda recognition, a victim model\nis queried over 800 times, compared to less than 150 for all other methods.\nFact checking resembles the propaganda recognition in terms of relatively short text fragments,\nbut the best-performing method is BERT-ATTACK. As for hyperpartisan news, DeepWordBug\nachieves high similarity, but succeeds in \ufb01nding an AE relatively rarely\u201426 per cent of times.\nFinally, the rumour detection task in the untargeted scenario appears to be the hardest problem\nto attack. Here the best methods reach BODEGA score of 0.25, indicating low usability, mostly due\nto low confusion rates\u2014barely above 60 per cent . This may be because rumour threads consist of\nnumerous posts, each having some indication on the credibility of the news, forcing an attacker tomake many modi\ufb01cations to change the victim\u2019s decision. The text of Twitter messages is also far\nfrom regular language, making the challenge harder for methods using models pretrained on well-\nformed text (e.g. BERT-ATTACK). It has to be noted however that this setup is equally problematicto the meaning preservation measurement (semantic score), thus suggesting these results should\nbe taken cautiously.\nRegarding the performance of the included attack methods, we can observe the following:\n\u0081Approaches relying on local changes (e.g. BERT-ATTACK, DeepWordBug) work betterthan global rephrasers (SCPN), because they are able to deliver more candidates for AEsand thus have more chances for success.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 17\nTable 4. The results of adversarial attacks, averaged over all victim classi\ufb01ers, in four misinformation detection\ntasks (untargeted). Evaluation measures include BODEGA score, confusion score, semantic score, character score andnumber of queries to the attacked model per example. The best score in each task is in boldface\nTask Method BODEGA Confusion Semantic Character Queries\nHN BAE 0.36 0.60 0.61 0.97 589.39\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nBERT-ATTACK 0.56 0.90 0.63 0.97 910.00\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nDeepWordBug 0.25 0.33 0.78 1.00 390.95\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nGenetic 0.38 0.81 0.48 0.98 1740.55\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSememePSO 0.19 0.40 0.50 0.99 309.10\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nPWWS 0.37 0.79 0.48 0.98 2051.62\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSCPN 0.00 0.82 0.09 0.02 11.75\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nTextFooler 0.34 0.77 0.46 0.96 792.91\nPR BAE 0.14 0.21 0.71 0.94 33.31\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nBERT-ATTACK 0.46 0.72 0.69 0.91 76.40\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nDeepWordBug 0.20 0.26 0.79 0.96 27.33\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nGenetic 0.49 0.84 0.65 0.89 886.55\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSememePSO 0.41 0.68 0.67 0.89 99.51\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nPWWS 0.46 0.74 0.67 0.90 132.20\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSCPN 0.11 0.54 0.38 0.48 11.54\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nTextFooler 0.41 0.72 0.65 0.87 62.26\nFC BAE 0.35 0.53 0.69 0.96 78.58\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nBERT-ATTACK 0.57 0.83 0.72 0.95 153.37\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nDeepWordBug 0.26 0.31 0.83 0.98 54.10\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nGenetic 0.52 0.77 0.70 0.95 846.25\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSememePSO 0.44 0.65 0.71 0.96 145.06\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nPWWS 0.48 0.69 0.72 0.96 225.98\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSCPN 0.07 0.66 0.30 0.33 11.66\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nTextFooler 0.46 0.70 0.70 0.94 109.77\nRD BAE 0.10 0.24 0.42 0.98 310.71\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nBERT-ATTACK 0.25 0.62 0.42 0.94 860.04\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nDeepWordBug 0.13 0.19 0.70 0.99 235.85\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nGenetic 0.24 0.53 0.46 0.96 2605.13\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSememePSO 0.12 0.26 0.47 0.97 330.20\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nPWWS 0.21 0.46 0.46 0.96 1107.09\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nSCPN 0.01 0.41 0.17 0.11 11.40\n.......................................... ............................................ ......................................... ................................. ................................... .............................\nTextFooler 0.18 0.46 0.44 0.92 654.20\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n18 P. Przyby\u0142a et al.\nFigure 2. Classi\ufb01cation performance (F1 score) and vulnerability to targeted attacks (BODEGA score) of models according to\ntheir size (parameter count, logarithmic scale), for different tasks.\n\u0081Character-replacing solutions (e.g. DeepWordBug) maintain high similarity, both in\nsemantic and Levenstain measures, but suffer in terms of confusion rate. Clearly, some-\ntimes changing a whole word is necessary to trigger a decision change.\n\u0081Methods relying on language models for meaning representation (esp. BERT-ATTACK)obtain better results than those relying on GloVe (Genetic) or WordNet (PWWS). This\nis likely because the older methods are not context-sensitive, resulting in less appropriate\nreplacements, visible as reduced semantic scores.\n\u0081Solutions performing a very extensive search (esp. Genetic) \ufb01nd good AEs only for\nshort text: propaganda and fact-checking. They become unfeasible for longer content, for\nexample news.\n\u0081Even solutions with apparently similar designs (BAE and BERT-ATTACK) can deliver\nvastly different performance due to smaller details in their implementation.\n9.2 Q2: victim size and vulnerability\nFig.2plots the performance and vulnerability to targeted attacks (BODEGA score of the most\nsuccessful method) of models of increasing size: BiLSTM, BERT, GEMMA2B, GEMMA7B. Wecan see that while the classi\ufb01cation scores almost universally improve with larger models (albeit\nwith diminishing returns), the robustness assessment paints a more complex picture.\nBiLSTM, which is by far the smallest model, is also clearly the most vulnerable to attacks.\nHowever, the results for the large pretrained models are surprising: the smallest of them (BERT)\nappears to be the most robust, except for one task (HN). This effect is the strongest for the FC\ntask, where the best attacker on the GEMMA7B model achieves a score 27% higher than in theattack against BERT. For two of the tasks (FC and RD), this pattern holds even within the same\nmodel family, with the smaller GEMMA model showing lower vulnerability.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 19\nFigure 3. Results of the targeted attacks (y axis, BODEGA score) plotted against the number of queries necessary (x axis,\nlogarithmic) for various attack methods (symbols) and tasks (colours).\nOverall, new and more accurate language models are not less vulnerable to attacks, as one\nwould hope. In the application scenarios involving adversarial actors, such as credibility assess-\nment, smaller solutions may thus be a more appropriate choice. This observation is a contribution\nto the wider question of vulnerability of LLMs to adversarial actions (Yao et al. 2024 ; Goto, Ono,\nand Morita 2024 ). While this is a new research area, preliminary results are concordant with ours,\nnamely showing larger models as not necessarily increasing robustness over the smaller predeces-\nsors (Liu et al. 2024 ). Our results do not explain why the robustness does not increase with model\nsize as classi\ufb01cation performance does, and we leave this problem as an interesting question for\nfuture research.\n9.3 Q3: number of queries\nFig.3illustrates the number of queries necessary to perform attacks with various levels of suc-\ncess. Primarily, we can see the results are grouped according to the task being attacked. The tasks\ninvolving long text (HN and RD) both require many queries: for each attacked example, from\nseveral hundred to several thousand attempts are needed to \ufb01nd an adversarial variant. These twotasks differ in terms of success, with hyperpartisan news obtaining some of the highest BODEGA\nscores and rumour detection: the lowest. The tasks involving shorter text (FC and PR) have simi-\nlarly high success rate, but good attacks require much less queries: from just over 100 (FC) to lessthan 60 (PR).\nIn terms of attack methods, BERT-ATTACK clearly achieves the best BODEGA score for most\ntasks. However, it requires many queries\u2014even though not as many as the Genetic approach.Among the methods that work with less queries, often with little cost in terms of performance\nloss, we can distinguish TextFooler and DeepWordBug.\n9.4 Q4: targeting\nTable 5compares targeted and untargeted scenarios in terms of performance\u2014the best BODEGA\nscore and the number of queries needed to achieve it. Interestingly, the individual score differences\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n20 P. Przyby\u0142a et al.\nTable 5. A comparison of the results\u2014highest BODEGA score and corresponding number of queries\u2014in the untargeted\n(U) and targeted (T) scenario for various tasks and victims. The better values (higher BODEGA scores and lower number ofqueries) are highlighted\nBiLSTM BERT GEMMA2B GEMMA7B\nUTUT UT U T\nHN B. score 0.64 0.61 0.60 0.57 0.55 0.57 0.45 0.31\n........................................... ........................................... ......................................... ....................................... ........................................... ...............................\nQueries 487.85 565.05 648.41 753.91 942.98 761.53 1560.76 2313.33\nPR B. score 0.54 0.66 0.50 0.50 0.50 0.55 0.44 0.53\n........................................... ........................................... ......................................... ....................................... ........................................... ...............................\nQueries 782.15 50.14 962.40 99.95 876.06 94.05 925.58 110.32\nFC B. score 0.61 0.59 0.53 0.41 0.57 0.50 0.58 0.52\n........................................... ........................................... ......................................... ....................................... ........................................... ...............................\nQueries 840.99 123.24 146.73 207.23 192.25 254.22 141.70 173.86\nRD B. score 0.32 0.62 0.20 0.39 0.30 0.41 0.21 0.44\n........................................... ........................................... ......................................... ....................................... ........................................... ...............................\nQueries 3150.24 153.61 4425.11 174.03 703.07 1108.21 977.27 202.18\ncan be quite high, but the pattern depends on the classi\ufb01cation task. The targeted task is always\nharder for news bias assessment (except BERT) and fact checking. The untargeted one is always\nmuch more challenging for propaganda recognition and rumour detection.\n9.5 Manual analysis\nIn order to better understand how a successful attack might look like, we manually analyse some\nof them. This allows us observe what types of adversarial modi\ufb01cations are the weakest point ofthe classi\ufb01er, as well as verify if attack success scoring using automatic measures is aligned with\nthe human judgement.\nFor that purpose, we select 20 instances with the highest BODEGA score from the untargeted\ninteractions between a relatively strong attacker (BERT-ATTACK) and a relatively weak victim\n(BiLSTM), within all tasks. Next, we label the AEs according to the degree they differ from the\noriginal text:\np\n1.Synonymous : the text is identical in meaning to the original.\n2.Typographic : change of individual characters, for example resembling sloppy punctuation\nor typos, likely imperceptible.\n3.Grammatical : change of the syntax of the sentence, for example replacing a verb with a\nnoun with the same root, possibly making the text grammatically incorrect,\n4.Semantic-small : changes affecting the overall meaning of the text, but to a limited degree,\nunlikely to affect the credibility label,\n5.Semantic-large : signi\ufb01cant changes in the meaning of the text, indicating the original\ncredibility may not apply,\n6.Local : changes of any degree higher than Synonymous, but present only in a few non-\ncrucial sentences of a longer text, leaving others to carry the original meaning (applies to\ntasks with many sentences, i.e. RD and HN).\npNote that while these categories might overlap, e.g. a typographic replacement signi\ufb01cantly affecting the overall meaning,\nsuch cases were not encountered in practice during the analysis.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 21\nTable 6. Number of AEs using different modi\ufb01cations among the best 20 instances\n(according to BODEGA score) in each task, using BiLSTM as victim and BERT-ATTACKas attacker\nNumber of instances\nAE degree HN PR FC RD % of all\nSynonymous 6 10 2 5 29%\n.......................................... .............................. ............................ ........................... .............................. .............................\nTypographic 0 5 8 0 16%\n.......................................... .............................. ............................ ........................... .............................. .............................\nGrammatical 0 4 3 2 11%\n.......................................... .............................. ............................ ........................... .............................. .............................\nSemantic-small 0 1 2 3 7%\n.......................................... .............................. ............................ ........................... .............................. .............................\nLocal 13 - - 2 19%\nSemantic-large 1 0 5 8 17%\nThe changes labelled as Semantic-large indicate attack failure, while others denote success with\nvarying visibility of the modi\ufb01cation.\nTable 6shows the quantitative results of the manual analysis, while Table 7includes some exam-\nples. Generally, a large majority of these attacks (82.5 per cent ) were successful in maintaining the\noriginal meaning, con\ufb01rming the high BODEGA score assigned to them. However, signi\ufb01cant\ndifferences between the tasks are visible.\nConsistently with the results of automatic analysis, rumour detection appears to be the most\nrobust, resulting in many attacks changing the original meaning. Even though oftentimes only a\nword or two is changed, it affects the meaning of the whole Twitter thread, since the follow-upmessages do not repeat the content, but often deviate from the topic (see EX4 in Table 7). The\nopposite happens for hyperpartisan news: a singular change does not affect the overall message, as\nthe news article are typically redundant and maintain their sentiment throughout (see EX6). As aresult, the HR task is one of the most vulnerable to attacks.\nIt is also interesting to compare the two tasks with shorter text: fact checking and propaganda\nrecognition. While the FC classi\ufb01er shows a large vulnerability to typographic changes (esp. inpunctuation, see EX2), many of the changes performed by the attackers affect important aspectsof the content (e.g. names or numbers, see EX5), making the AE futile. The propaganda recog-\nnition, on the other hand, appears to rely on stylistic features, allowing the AE generation while\npreserving full synonymy (see EX1) or just introducing grammatical issues (see EX3).\n10. Discussion\n10.1 Reality check for credibility assessment\nWhile one of the principles guiding the design of BODEGA has been a realistic simulation of the\nmisinformation detection scenarios, this is possible only to an extent. Among the obstacles are\nlow transparency of content management platforms (Gorwa, Binns, and Katzenbach 2020 )a n d\nthe vigorous growth of the methods of attack and defence in the NLP \ufb01eld.\nFirstly, we have included only four victim models in our tests: BiLSTM, BERT and two Gemma\nvariants, while in reality dozens of architectures for text classi\ufb01cation are presented at every NLPconference, with a signi\ufb01cant share speci\ufb01cally devoted to credibility assessment. However, the\n\ufb01eld has recently become surprisingly homogeneous, with the ambition to achieve the state-of-\nthe-art pushing researchers to reuse the common pretrained language models in virtually everyapplication (Church and Kordoni 2022 ). But these lookalike approaches share not only good\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n22 P. Przyby\u0142a et al.\nTable 7. Some examples of adversarial modi\ufb01cations that were successful (i.e. resulted in changed classi\ufb01er decision), per-\nformed by BERT-ATTACK against BiLSTM, including identi\ufb01er (mentions in text), task and type of modi\ufb01cation. Changes are\nhighlighted in boldface\nId., task, type Original example Adversarial example\nEX1 PR Synonymous Puerto Rico\u2019s housing secretary, Fernando\nGil, says the number of homes destroyed by\nthe hurricane totals about 70,000 so far, andhomes with major damage have amounted\nto 250,000 across the islandPuerto Rico\u2019s housing secretary, Fernando\nGil, says the number of houses destroyed by\nthe hurricane totals about 70,000 so far, andhomes with major damage have amounted\nto 250,000 across the island\nEX2 FC Typographic Sabbir Khan. Sabbir\u2019s second movie,\nHeropanti starring Tiger Shroff & Kriti Sanon ,\nreleased on 23 May 2014. \u2192Sabbir Khan\ndirected a movieSabbir Khan. Sabbir\u2019s second movie,\nHeropanti starring Tiger Shroff & KritiSanon ?released on 23 May 2014. \u2192Sabbir\nKhan directed a movie\nEX3 PR Grammatical Fastiggi and Goldstein have managed to\nmake the problem even worse in their\nattempt to explain it awayFastiggi and Goldstein have managed to\nmake the problem even worse in their\nattempt to explained it away\nEX4 RD Semantic-small A few of the best cartoons drawn & shared\nin solidarity with #charliehebdo after\nyesterday\u2019s massacre #jesuischarlie\nhttp://t.co/87et0xpnwr @theinquisitr war\npro\ufb01teers x\u2019d #princessdiana & dodifayed in#paris. pushing #france to join war on terror\nvideo >>http://t.co/tysy8ys49w\n@theinquisitr l\u2019am\u00e9rique se tient avec lafrance. #jesuischarlieA few of the best cartoons contributed &\nheld in friendship with #charliehebdo after\nyesterday\u2019s massacre #jesuischarlie\nhttp://t.co/87et0xpnwr @theinquisitr war\npro\ufb01teers x\u2019d #princessdiana & dodifayed in#paris. pushing #france to join war on terror\nvideo >>http://t.co/tysy8ys49w\n@theinquisitr l\u2019am\u00e9rique se tient avec lafrance. #jesuischarlie\nEX5 FC Semantic-large Hannah and Her Sisters. Hannah and Her\nSisters is a 1986 American comedy\u2014drama\n\ufb01lm which tells the intertwined stories of an\nextended family over two years that beginsand ends with a family thanksgiving dinner.\u2192Hannah and Her Sisters is an American\n1986 \ufb01lmHannah and Her Sisters. Hannah and Her\nSisters is a 1986 American comedy\u2014drama\n\ufb01lm which tells the intertwined stories of an\nextended family over two years that beginsand ends with a family thanksgiving dinner.\u2192Hannah and Her Sisters is an American\n1987 \ufb01lm\nEX6 HN Local Aleppo completely back under government\ncontrol (GPA) Aleppo\u2014the Syrian Arab Army(SAA) has reported today that the entirety ofeast Aleppo is fully back under government\ncontrol, meaning the city is now completely\nliberated. The SAA has completed theevacuations of anti-government \ufb01ghters andcivilians looking to \ufb02ee with these groups as\nof today. This is a major victory for the Syrian\nforces in Aleppo coming after almost 4 yearsof \ufb01ghting in the city. Thousands of people\nhave already taken to the streets to\ncelebrate the last of the terrorists inside thecity leaving. [347 words more]Aleppo completely back under government\ncontrol (GPA) Aleppo\u2014the Syrian Arab Army(SAA) has reported today that the entirety ofsouth Aleppo is fully back under government\ncontrol, meaning the city is now completely\nliberated. The SAA has completed theevacuations of anti-government \ufb01ghters andcivilians looking to \ufb02ee with these groups as\nof today. This is a major victory for the Syrian\nforces in Aleppo coming after almost 4 yearsof \ufb01ghting in the city. Thousands of people\nhave already taken to the streets to\ncelebrate the last of the terrorists inside thecity leaving. [347 words more]\nperformance but also weaknesses. Thus we expect that, for example, the results of attacks on \ufb01ne-\ntuned BERT will also apply to other solutions that use BERT as a representation layer. Moreover,\nthe current architecture of BODEGA supports binary text classi\ufb01cation models only. This meansit can be extended to other similar tasks with a binary label output, for example sentiment anal-\nysis or detecting machine-generated text. But it cannot be used to assess robustness of models\nfor machine translation or other language generation tasks\u2014these would require a differentapproach.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 23\nSecondly, we have re-used the attacks implemented in OpenAttack to have a comprehensive\nview of performance of different approaches. However, the \ufb01eld of AEs for NLP is relatively new,with the majority of publications emerging in the recent years, which makes it very likely that sub-\nsequent solutions will provide superior performance. With the creation of BODEGA as a universal\nevaluation framework, such comparisons become possible.\nThirdly, we need to consider the realism of evaluation measures. The AE evaluation framework\nassumes that if a modi\ufb01ed text is very similar to the original, then the label (credible or not) still\napplies. Without this assumption, every evaluation would need to include manual re-annotationof the AEs. Fortunately, assessing semantic similarity between two fragments of text is a neces-\nsary component of evaluation in many other NLP tasks, for example machine translation (Lee\net al. 2023 ), and we can draw from that work. Apart from BLEURT, we have experimented with\nSBERT cross-encoders (Thakur et al. 2021 ) and unsupervised BERT Score (Zhang et al. 2020a ),\nbut haven\u2019t found decisive evidence for the superiority of any approach. However, the problem\nremains open. The investigation on how subtle changes in text can invert its meaning and sub-vert credibility assessment is particularly vivid in the fact-checking \ufb01eld (Jaime et al. 2022 ), but it\nis less explored for tasks involving multi-sentence inputs, for example news credibility. An ideal\nmeasure of AE quality would take into account the characteristics of a text domain, assigning dif-ferent impact to a given change depending on the nature of the text. This could be expressed by\nmodifying the BODEGA score into a weighted score of the included factors and calibrating it by\nsetting the weights for each text genre. However, to \ufb01nd the parameter values that accurately cap-ture the human perception of acceptable changes, an annotation study would be necessary. We see\nthis as a promising direction for future research. Moreover, the measures focusing on performance\nloss, for example computing the reduction in accuracy of the victim model under a speci\ufb01ed mod-i\ufb01cation might be worth investigating. However, an annotation study would be necessary as well,\nnamely in order to establish the acceptable modi\ufb01cation threshold for each task.\nFourthly, we also assume that an attacker has a certain level of access to the victim classi\ufb01er,\nbeing able to send unlimited queries and receive numerical scores re\ufb02ecting its con\ufb01dence, rather\nthan a \ufb01nal decision. In practice, this is currently not the case, with platforms revealing almost\nnothing regarding their automatic content moderation processes. However, this may change infuture due to regulatory pressure from the government organisations; cf., for example, the recentlyagreed EU Digital Services Act .\nq\nFinally, we need to examine how realistic is that an attacker could freely modify any text\nincluded in our tasks. While this is trivial in the case of hyperpartisan news and propagandarecognition, where the entire input comes from a malicious actor, the other tasks require closer\nconsideration. In case of rumour detection, the text includes, apart from the initial information,\nreplies from other social media users. These can indeed be manipulated by sending replies fromanonymous accounts and this scenario has been already explored in the AE literature (Le et al.\n2020 ). In the case of fact checking, the text includes, apart from the veri\ufb01ed claim, also the rele-\nvant snippets from the knowledge base. However, it can be modi\ufb01ed as well, when (as is usuallythe case) the knowledge is based on Wikipedia, which is often a subject of malicious alterations,\nfrom vandalism (Kiesel et al. 2017 ) to the generation of entire hoax articles (Kumar, West, and\nLeskovec 2016 ).\nTo sum up, we argue that despite certain assumptions, the setup of a BODEGA framework\nis close enough to real-life conditions to give insights about the robustness of popular classi\ufb01ers\nin this scenario. BODEGA is already being used as a benchmark for new solutions that advancefoundational AE generation methods tested here. Within the CheckThat! evaluation lab organised\nat CLEF 2024 (Barr\u00f3n-Cede\u00f1o et al.2024 ), focused on misinformation detection, Task 6 is devoted\nto measuring the robustness of credibility assessment. The evaluation of the AEs submitted by the\nqhttps://ec.europa.eu/commission/presscorner/detail/en/qanda_20_2348\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n24 P. Przyby\u0142a et al.\ntask participants is based on the framework described here, with certain expansions (Przyby\u0142a\net al.2024 ).r\n10.2 Looking forward\nWe see this study as a step towards the directions recognised in the ML literature beyond NLP.\nFor example, in security-oriented applications, there is the need to bring the evaluation of AEs\ncloser to realistic conditions (Chen et al. 2022 ). Some limitations, esp. number of queries to the\nmodel, make attacks much harder. Even beyond the security \ufb01eld, assessing robustness is crucial\nfor ML models that are distributed as massively-used products. This exposes them to unexpected\nexamples, even if not generated with explicit adversarial motive. Individual spectacular failuresare expected to be disproportionately in\ufb02uential on public opinion of technology, including AI\n(Mannes 2020 ), emphasising the importance of research on AEs.\nOur work emphasises the need for taking into account the adversarial attacks when deploying\ntext classi\ufb01ers in adversarial scenarios, such as content \ufb01ltering in social media. In many cases,\nchanging just a few words in text can alter the decision of the models. We can recommend three\nways to mitigate the associated risks.\nFirstly, the vulnerability of ML models to adversarial examples indicates their output cannot\nbe the only criterion in content-\ufb01ltering systems. However, many AEs are quite transparent to\nhumans, and the manipulation could be easily noticed. This suggests that the sensitive scenar-ios could bene\ufb01t from a cooperation between a human operator and a ML model. For example, a\nsystem that uses ML models for prioritising work of human operators instead of making \ufb01nal deci-\nsion is likely to be more robust than the ML model alone. Secondly, our work shows that the attackperformance depends on the variety of factors, including dataset size, text length, victim architec-\nture, etc. This makes it crucial to test every content-\ufb01ltering solution before its deployment using\nreal-world data and state-of-the-art attackers. Thirdly, taking into account adversarial environ-ment in the classi\ufb01er design, for example through adversarial training, can limit the amount of\nadversarial examples it is vulnerable to.\nFinally, we need to acknowledge that the idea of using ML models for automatic modera-\ntion of user-generated content is not universally accepted, with some rejecting it as equivalentto censorship (Llans\u00f3 2020 ), and calling for regulations in this area (Meyer and Marsden 2019 ).\nMoreover, the recent changes in Twitter have served as an illustration of how relying on the auto-\nmatic moderation to reduce operation costs (Paul and Dang 2022 ) can result in more prevalent\nmisinformation (Graham and FitzGerald 2023 ).\n10.3 Using BODEGA\nBeyond the exploration of the current situation, we hope BODEGA will be useful for assessing the\nrobustness of future classi\ufb01ers and the effectiveness of new attacks. Towards this end, we makethe software available openly,\nsallowing the replication of our experiments and evaluation of other\nsolutions, both on the attack and the defence. Here, we also provide a handful of practical hints\non how to use the software to perform such analysis in practice.\nIn order to measure the robustness of a classi\ufb01er implemented in a particular scenario, the\nfollowing is necessary:\n1. Preparing a victim classi\ufb01er. It can be based on the code in runs/train_victims.py ,\nwhich provides training of baseline classi\ufb01ers\u2014BiLSTM, BERT or GEMMA\u2014and only\nrequires providing task-speci\ufb01c data. Otherwise, a completely different classi\ufb01er can be\nrNote that the works cited here are in print at the time of writing.\nshttps://github.com/piotrmp/BODEGA\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 25\nincluded, as long as it implements the OpenAttack. Classifier interface. Note that\nboth the classi\ufb01er algorithm and training data will in\ufb02uence the robustness.\n2. Choosing an attacker. For this purpose, the results in Table 4can be helpful, as they show\nthe quality of the AEs as well as the number of queries. If the tested classi\ufb01ers are deployed\nin a service that only allows a limited number of queries, this should be taken into accountin simulating an attack.\n3. Evaluating an attack. This is performed by using the runs/attack.py script. Note that\nmany of the attack methods consume signi\ufb01cant computational resources and thus usinga GPU device for both the victim and the attacker is recommended.\n4. Analysing the results. BODEGA will output both the overall evaluation results and all of the\nsuccessful AEs, with the changes highlighted. It is recommended to analyse these manually,\nas the automatic meaning preservation methods have their limits, especially in specialisedtext domains.\nIn order to evaluate a new attack , one needs to go through the following:\n1. Implement an attacker. It needs to satisfy the OpenAttack.attackers.\nClassificationAttacker interface, which sets out the procedure for \ufb01nding AEs.\n2. Choosing a victim. For the tasks and architectures tested here, the models are available for\ndownload from the BODEGA website. However, the victims/transformer.py script\nuses the HuggingFace library, so a user can train a model with a newer architecture, as long\nas it is available through AutoModelForSequenceClassification interface.\n3. Evaluating an attack and analysing the results, as above.\nThese are the most obvious usages of BODEGA, but other scenarios are possible as well, such\nas modifying the evaluation measure (BODEGA score) by improving the semantic similarityassessment, adding a different text classi\ufb01cation task, linguistic inquiry into the generated AEs,cybersecurity-focused analyses, etc.\n11. Conclusion\nThrough this work, we have demonstrated that popular text classi\ufb01ers, when applied for the pur-poses of misinformation detection, are vulnerable to manipulation through adversarial examples.\nWe have discovered numerous cases where making a single barely perceptible change is enough\nto prevent a classi\ufb01er from spotting non-credible information. Among the risk factors are largeinput lengths and the possibility of making numerous queries. Surprisingly, the classi\ufb01ers trained\non the basis of new state-of-the-art large language models are usually more vulnerable than their\npredecessors.\nNevertheless, the attack is never successful for every single instance and often entails changes\nthat make text suspiciously malformed or ill-suited for the misinformation goal. This emphasises\nthe need for thorough testing of the robustness of text classi\ufb01ers at various stages of their devel-\nopment: from the initial design and experiments to the preparation for deployment, taking intoaccount likely attack scenarios. We hope the BODEGA benchmark we contribute here, providing\nan environment for comprehensive and systematic tests, will be a useful tool in performing such\nanalyses.\nSupplementary material. To view supplementary material for this article, please visit https://doi.org/10.1017/nlp.2024.54\nAcknowledgements. This work is part of the ERINIA project, which has received funding from the European Union\u2019s\nHorizon Europe research and innovation programme under grant agreement No 101060930. Views and opinions expressedare however those of the author(s) only and do not necessarily re\ufb02ect those of the European Union. Neither the EuropeanUnion nor the granting authority can be held responsible for them. We also acknowledge the support from Departament deRecerca i Universitats de la Generalitat de Catalunya (ajuts SGR-Cat 2021) and the Spanish State Research Agency under the\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n26 P. Przyby\u0142a et al.\nMaria de Maeztu Units of Excellence Programme (CEX2021-001195-M). The computation for this study was made possible\nby the Google Cloud Platform through research credits.\nCompeting interests. The author(s) declare none.\nReferences\nAkers J. ,Bansal G. ,Cadamuro G. ,Chen C. ,Chen Q. ,Lin L. ,Mulcaire P. ,Nandakumar R. ,Rockett M. ,Simko L. ,\nToman J. ,Wu T. ,Zeng E. ,Zorn B. and Roesner F. (2018). Technology-Enabled Disinformation: Summary, Lessons,\nand Recommendations. Technical report, University of Washington.\nAl-Sarem M. ,Boulila W. ,Al-Harby M. ,Qadir J. and Alsaeedi A. (2019). Deep learning-based rumor detection on\nmicroblogging platforms: a systematic review. IEEE Access 7, 152788\u2013152812.\nAli H. ,Khan M. S. ,AlGhadhban A. ,Alazmi M. ,Alzamil A. ,Al-utaibi K. and Qadir J. (2021). All your fake detector are\nbelong to us: evaluating adversarial robustness of fake-news detectors under black-box settings. IEEE Access 9, 81678\u2013\n81692.\nAllcott H. and Gentzkow M. (2017). Social media and fake news in the 2016 election. Journal of Economic Perspectives 31(2),\n211\u2013236.\nAlsmadi I. ,Ahmad K. ,Nazzal M. ,Alam F. ,Al-Fuqaha A. ,Khreishah A. and Algosaibi A. (2022). Adversarial NLP for social\nnetwork applications: attacks, defenses, and research directions. IEEE Transactions on Computational Social Systems .\nAlzantot M. ,Sharma Y. ,Elgohary A. ,Ho B.-J. ,Srivastava M. and Chang K.-W. (2018). Generating natural language adver-\nsarial examples. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , Brussels,\nBelgium. Association for Computational Linguistics, pp. 2890\u20132896.\nBagdasaryan E. and Shmatikov V. (2022). Spinning language models: risks of propaganda-as-a-service and countermea-\nsures. In 2022 IEEE Symposium on Security and Privacy (SP) . IEEE Computer Society, pp. 769\u2013786.\nBakir V. and McStay A. (2017). Fake news and the economy of emotions: problems, causes, solutions. Digital Journalism\n6(2), 154\u2013175.\nBarr\u00f3n-Cede\u00f1o A. ,Alam F. ,Stru\u00df J. M. ,Nakov P. ,Chakraborty T. ,Elsayed T. ,Przyby\u0142a P. ,Caselli T. ,Da San\nMartino G. ,Haouari F. ,Li C. ,Piskorski J. ,Ruggeri F. ,Song X. and Suwaileh R. (2024). Overview of the CLEF-2024\nCheckThat! lab: check-worthiness, subjectivity, persuasion, roles, authorities and adversarial robustness. In Experimental\nIR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fifteenth International Conference of the CLEFAssociation (CLEF 2024) .\nBrown B. ,Richardson A. ,Smith M. ,Dozier G. and King M.C. (2020). The adversarial UFP/UFN attack: a new threat to\nML-based fake news detection systems? In 2020 IEEE Symposium Series on Computational Intelligence, SSCI . IEEE, pp.\n1523\u20131527.\nCarter M. ,Tsikerdekis M. and Zeadally S. (2021). Approaches for fake content detection: strengths and weaknesses to\nadversarial attacks. IEEE Internet Computing 25(2), 73\u201383.\nChen Y. ,Gao H. ,Cui G. ,Qi F. ,Huang L. ,Liu Z. and Sun M. (2022). Why should adversarial perturbations be imperceptible?\nrethink the research paradigm in adversarial NLP. In Proceedings of the 2022 Conference on Empirical Methods in Natural\nLanguage Processing , pp. 11222\u201311237.\nChurch K.W. and Kordoni V. (2022). Emerging trends: SOTA-chasing. Natural Language Engineering 28(2), 249\u2013269.\nCiampaglia G.L. ,Mantzarlis A. ,Maus G. and Menczer F. (2018). Research challenges of digital misinformation: toward a\ntrustworthy web. AI Magazine 39(1), 65\u201374.\nda San Martino G. ,Barr\u00f3n-Cede\u00f1o A. ,Wachsmuth H. ,Petrov R. and Nakov P. (2020). Task 11: detection of propaganda\ntechniques in news articles. In Proceedings of the Fourteenth Workshop on Semantic Evaluation (SemEval-2020) , pp. 1377\u2013\n1414.\nDalvi N. ,Domingos P.\n,Mausam S.S. and Verma D. (2004). Adversarial classi\ufb01cation. In KDD-2004 - Proceedings of the\nTenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . Association for Computing\nMachinery (ACM), pp. 99\u2013108.\nDettmers T. ,Pagnoni A. ,Holtzman A. and Zettlemoyer L. (2023). QLoRA: ef\ufb01cient \ufb01netuning of quantized LLMs. In\nOh A., Neumann T., Globerson A., Saenko K., Hardt M. and Levine S. (eds), Advances in Neural Information Processing\nSystems 36 . Curran Associates, Inc, pp. 10088\u201310115.\nDevlin J. ,Chang M.-W. ,Lee K. and Toutanova K. (2018). BERT: pre-training of deep bidirectional transformers for\nlanguage understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies . Association for Computational Linguistics, pp. 4171\u20134186.\nEger S. ,\u00b8Sahin G. G. ,R\u00fcckl\u00e9 A. ,Lee J.-U. ,Schulz C. ,Mesgar M. ,Swarnkar K. ,Simpson E. and Gurevych I. (2019). Text\nprocessing like humans do: visually attacking and shielding NLP systems. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Longand Short Papers) , Minneapolis, Minnesota. Association for Computational Linguistics, pp.1634\u20131647.\nEttinger A. ,Rao S. ,H. D. and Bender E.M. (2017). Towards linguistically generalizable NLP systems: a workshop and\nshared task. In Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems . Association for\nComputational Linguistics (ACL), pp. 1\u201310.\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 27\nGao J. ,Lanchantin J. ,Soffa M.L. and Qi Y. (2018). Black-box generation of adversarial text sequences to evade deep learning\nclassi\ufb01ers. In Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW . IEEE, pp. 50\u201356.\nGarg S. and Ramakrishnan G. (2020). BAE: BERT-based adversarial examples for text classi\ufb01cation. In Proceedings of the\n2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , Online. Association for Computational\nLinguistics, pp. 6174\u20136181.\nGong Z. ,Wang W. ,Li B. ,Song D. and Ku W.-S. (2018). Adversarial Texts with Gradient Methods. arXiv:1801.07175.\nGorwa R. ,Binns R. and Katzenbach C. (2020). Algorithmic content moderation: technical and political challenges in the\nautomation of platform governance. B i gD a t a&S o c i e t y 7(1), 205395171989794.\nGoto T. ,Ono K. and Morita A. (2024). A Comparative Analysis of Large Language Models to Evaluate Robustness and\nReliability in Adversarial Conditions. techrxiv:171173447.70655950.\nGraham T. and FitzGerald K.M. (2023). Bots, Fake News and Election Conspiracies: Disinformation During the Republican\nPrimary Debate and the Trump Interview. Technical report, Digital Media Research Centre, Queensland University ofTechnology, Brisbane, Australia.\nGraves L. (2018). Understanding the Promise and Limits of Automated Fact-Checking. Technical report, Reuters Institute,\nUniversity of Oxford.\nGuo C. ,Sablayrolles A. ,J\u00e9gou H. and Kiela D. (2021). Gradient-based adversarial attacks against text transformers. In\nEMNLP. 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings . Association for\nComputational Linguistics (ACL), pp. 5747\u20135757.\nHan S. ,Gao J. and Ciravegna F. (2019). Neural language model based training data augmentation for weakly supervised early\nrumor detection. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis\nand Mining, ASONAM . Association for Computing Machinery, Inc, pp. 105\u2013112.\nHidey C. ,Chakrabarty T. ,Alhindi T. ,Varia S. ,Krstovski K. ,Diab M. and Muresan S. (2020). DeSePtion: dual sequence\nprediction and adversarial examples for improved fact-checking. In Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics . Association for Computational Linguistics (ACL), pp. 8593\u20138606.\nHochreiter S. and Schmidhuber J. (1997). Long short-term memory. Neural Computation 9(8), 1735\u20131780.\nHorne B.D. and Adali S. (2017). This just in: fake news packs a lot in title, uses simpler, repetitive content in text body, more\nsimilar to satire than real news. In Proceedings of the 2nd International Workshop on News and Public Opinion at ICWSM.\nAssociation for the Advancement of Arti\ufb01cial Intelligence .\nHu E.J. ,Shen Y. ,Wallis P. ,Allen-Zhu Z. ,Li Y. ,Wang S. ,Wang L. and Chen W. (2021). LoRA: Low-Rank Adaptation of\nLarge Language Models. arXiv preprint arXiv:2106.09685.\nIyyer M. ,Wieting J. ,Gimpel K. and Zettlemoyer L. (2018). Adversarial example generation with syntactically controlled\nparaphrase networks. In NAACL HLT. 2018 - 2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies - Proceedings of the Conference , Association for Computational\nLinguistics (ACL), vol. 1, pp. 1875\u20131885.\nJaime L. ,Flores Y. and Hao Y. (2022). An adversarial benchmark for fake news detection models. In The AAAI-22 Workshop\non Adversarial Machine Learning and Beyond .\nJin D. ,Jin Z. ,Zhou J.T. and Szolovits P. (2020). Is BERT really robust? a strong baseline for natural language attack on\ntext classi\ufb01cation and entailment. In The Thirty-Fourth AAAI Conference on Arti\ufb01cial Intelligence, AAAI . AAAI Press, pp.\n8018\u20138025.\nKantartopoulos P. ,Pitropakis N. ,Mylonas A. and Kylilis N. (2020). Exploring adversarial attacks and defences for fake\ntwitter account detection. Technologies 8(4), 64.\nKarpukhin V. ,Oguz B. ,Min S. ,Lewis P. ,Wu L. ,Edunov S. ,Chen D. and Yih W.-t. (2020). Dense passage retrieval for\nOpen-Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP) , Online. Association for Computational Linguistics, pp. 6769\u20136781.\nKiesel J. ,Mestre M. ,Shukla R. ,Vincent E. ,Adineh P. ,Corney D. ,Stein B. and Potthast M. (2019). Task 4: hyperpartisan\nnews detection. In Proceedings of the 13th International Workshop on Semantic Evaluation , Minneapolis, Minnesota, USA.\nAssociation for Computational Linguistics, pp. 829\u2013839.\nKiesel J. ,Potthast M. ,Hagen M. and Stein B. (2017). Spatio-temporal analysis of reverted wikipedia edits. In Proceedings of\nthe International AAAI Conference on Web and Social Media , vol. 11, pp. 122\u2013131.\nKingma D.P. and Ba J.L. (2015). Adam: A method for stochastic optimization. In 3rd International Conference on Learning\nRepresentations, ICLR. 2015 - Conference Track Proceedings , San Diego, USA. ICLR.\nKoenders C. ,Filla J. ,Schneider N. and Woloszyn V. (2021). How Vulnerable Are Automatic Fake News Detection Methods\nto Adversarial Attacks? arXiv:2107.07970.\nKumar S. ,West R. and Leskovec J. (2016). Disinformation on the web: impact, characteristics, and detection of wikipedia\nhoaxes. In 25th International World Wide Web Conference, WWW 2016 . International World Wide Web Conferences\nSteering Committee, pp. 591\u2013602.\nLe T. ,Wang S. and Lee D. (2020). MALCOM: generating malicious comments to attack neural fake news detection models.\nInProceedings - IEEE International Conference on Data Mining, ICDM . IEEE, pp. 282\u2013291.\nLee S. ,Lee J. ,Moon H. ,Park C. ,Seo J. ,Eo S. ,K o oS .a n dL i mH . (2023). A survey on evaluation metrics for machine\ntranslation. Mathematics 11(4), 1006\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\n28 P. Przyby\u0142a et al.\nLevenshtein V.I. (1966). Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady 10,\n707\u2013710.\nLewandowsky S. ,Ecker U.K. and Cook J. (2017). Beyond misinformation: understanding and coping with the \u201cPost-truth\u201d\nera.Journal of Applied Research in Memory and Cognition 6(4), 353\u2013369.\nLi L. ,Ma R. ,Guo Q. ,Xue X. and Qiu X. (2020). BERT-ATTACK: adversarial attack against BERT using BERT. In Proceedings\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) . Association for Computational\nLinguistics, pp. 6193\u20136202.\nLialin V. ,Deshpande V. and Rumshisky A. (2023). Scaling Down to Scale Up: A Guide to Parameter-Ef\ufb01cient Fine-Tuning.\narXiv preprint arXiv:2303.15647.\nLiu Y. ,Cong T. ,Zhao Z. ,Backes M. ,Shen Y. and Zhang Y. (2024). Robustness Over Time: Understanding Adversarial\nExamples\u2019 Effectiveness on Longitudinal Versions of Large Language Models .\nLiu Y. and Wu Y.F.B. (2020). FNED: a deep network for fake news early detection on social media. ACM Transactions on\nInformation Systems (TOIS) 38(3), 1\u201333.\nLlans\u00f3 E.J. (2020). No amount of \u201cAI\u201d in content moderation will solve \ufb01ltering\u2019s prior-restraint problem. B i gD a t aa n d\nSociety 7(1), 205395172092068.\nLoshchilov I. and Hutter F. (2019). Decoupled weight decay regularization. In 7th International Conference on Learning\nRepresentations, ICLR. 2019 , New Orleans, LA, USA.\nMacCartney B. (2009). Natural Language Inference. Ph. d. thesis, Stanford University.\nMannes A. (2020). Governance, risk, and arti\ufb01cial intelligence. AI Magazine 41(1), 61\u201369.\nMeyer T. and Marsden C. (2019). Regulating disinformation with arti\ufb01cial intelligence: Effects of disinformation initiatives\non freedom of expression and media pluralism. Technical report, European Parliament.\nMierzy \u00b4nska A. (2020). Chmura znad Czarnobyla - kolejna dezinformacja, kt\u00f3ra straszono Polak\u00f3w. Wiemy, skad sie \u00b8w z i e \u00b8\u0142a.\nMorris J. ,Li\ufb02and E. ,Yoo J.Y. ,Grigsby J. ,Jin D. and Qi Y. (2020). TextAttack: a framework for adversarial attacks, data\naugmentation, and adversarial training in NLP. In Proceedings of the 2020 Conference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations , Online. Association for Computational Linguistics, pp. 119\u2013126.\nNakov P. ,Barr\u00f3n-Cede\u00f1o A. ,Da San Martino G. ,Alam F. ,M\u00edguez R. ,Caselli T. ,Kutlu M. ,Zaghouani W. ,Li C. ,Shaar S. ,\nMubarak H. ,Nikolov A. and Kartal Y.S. (2022). Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant\nclaims in tweets. In CLEF 2022: Conference and Labs of the Evaluation Forum , Bologna, Italy, vol. 3180, pp. 368\u2013392. CEUR\nWorkshop Proceedings (CEUR-WS.org).\nNeekhara P. ,Hussain S. ,Dubnov S. and Koushanfar F. (2019). Adversarial reprogramming of text classi\ufb01cation neu-\nral networks. In EMNLP-IJCNLP. 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and\n9th International Joint Conference on Natural Language Processing, Proceedings of the Conference . Association for\nComputational Linguistics, pp. 5216\u20135225.\nPaul K. and Dang S. (2022). Exclusive: twitter leans on automation to moderate content as harmful speech surges.\nPotthast M. ,Kiesel J. ,Reinartz K. ,Bevendorff J. and Stein B. (2018). A stylometric inquiry into hyperpartisan and fake\nnews. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) .\nAssociation for Computational Linguistics, pp. 231\u2013240.\nPrzyby\u0142a P. (2020). Capturing the style of fake news. In Proceedings of the Thirty-Fourth AAAI Conference on Arti\ufb01cial\nIntelligence (AAAI-20) , New York, USA. AAAI Press, vol. 34, pp. 490\u2013497.\nPrzyby\u0142a P. (2022). LAMBO: Layered Approach to Multi-level BOundary identi\ufb01cation.\nPrzyby\u0142a P. ,Borkowski P. and Kaczy \u00b4nski K. (2022). Countering disinformation by \ufb01nding reliable sources: a citation-based\napproach. In Proceedings of the 2022 International Joint Conference on Neural Networks (IJCNN) . IEEE.\nPrzyby\u0142a P. ,Wu B. ,Shvets A. ,Mu Y. ,Sheang K.C. ,Song X. and Saggion H. (2024). Overview of the CLEF-2024 check-\nThat! lab Task 6 on robustness of credibility assessment with adversarial examples (InCrediblAE). In Faggioli G., Ferro N.,Galu\u0161 \u02c7c\u00e1kov\u00e1 P. and Garc\u00eda Seco de Herrera A. (eds), Working Notes of CLEF. 2024 - Conference and Labs of the Evaluation\nForum, CLEF 2024, Grenoble, France\nRadford A. ,Wu J. ,Child R. ,Luan D. ,Amodei D. and Sutskever I. (2018). Language Models are Unsupervised Multitask\nLearners. Technical report, OpenAI.\nRen S. ,Deng Y. ,He K. and Che W. (2019). Generating natural language adversarial examples through probability weighted\nword saliency. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , Florence, Italy.\nAssociation for Computational Linguistics, pp. 1085\u20131097.\nRibeiro M.T. ,Singh S. and Guestrin C. (2018). Semantically equivalent adversarial rules for debugging NLP models.\nInProceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\n,\nMelbourne, Australia. Association for Computational Linguistics, pp. 856\u2013865.\nSellam T. ,Das D. and Parikh A. (2020). BLEURT: learning robust metrics for text generation. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational Linguistics , Online. Association for Computational Linguistics, pp.\n7881\u20137892.\nShu K. ,Wang S. and Liu H. (2019). Beyond news contents: the role of social context for fake news detection. In Proceedings\nof the Twelfth ACM International Conference on Web Search and Data Mining ,N e wY o r k ,N Y ,U S A .A C M ,v o l .9 .\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press\nNatural Language Processing 29\nSinghal M. ,Ling C. ,Paudel P. ,Thota P. ,Kumarswamy N. ,Stringhini G. and Nilizadeh S. (2022). SoK: content moderation\nin social media, from guidelines to enforcement, and research to practice. In The 8th IEEE European Symposium on Security\nand Privacy (EuroS&P 2023) . IEEE.\nSmith T.J. (1989). Propaganda: A pluralistic perspective . Praeger.\nSmith M. ,Brown B. ,Dozier G. and King M. (2021). Mitigating attacks on fake news detection systems using genetic-based\nadversarial training. In 2021 IEEE Congress on Evolutionary Computation, CEC. 2021 - Proceedings . IEEE, pp. 1265\u20131271.\nSrivastava B. ,Lakkaraju K. ,Bernagozzi M. and Valtorta M. (2023). Advances in automatically rating the trustworthiness\nof text processing services. In Spring Symposium on AI Trustworthiness Assessment .\nSzegedy C. ,Zaremba W. ,Sutskever I. ,Bruna J. ,Erhan D. ,Goodfellow I. and Fergus R. (2013). Intriguing properties of\nneural networks. arXiv: 1312.6199.\nTeam Gemma and DeepMind Google (2024). Gemma: Open Models Based on Gemini Research and Technology. Technical\nreport, Google DeepMind.\nThakur N. ,Reimers N. ,Daxenberger J. and Gurevych I. (2021). Augmented SBERT: data augmentation method for improv-\ning Bi-encoders for pairwise sentence scoring tasks. In Proceedings of the 2021 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies , Online. Association for Computational\nLinguistics, pp. 296\u2013310.\nThorne J. ,Vlachos A. ,Christodoulopoulos C. and Mittal A. (2019). Evaluating adversarial attacks against multiple fact\nveri\ufb01cation systems. In EMNLP-IJCNLP. 2019 - 2019 Conference on Empirical Methods in Natural Language Processing\nand 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference . Association for\nComputational Linguistics, pp. 2944\u20132953.\nThorne J. ,Vlachos A. ,Cocarascu O. ,Christodoulopoulos C. and Mittal A. (2018a). The fact extraction and VERi\ufb01cation\n(FEVER) shared task. In Proceedings of the First Workshop on Fact Extraction and VERi\ufb01cation (FEVER) .\nThorne J. ,Vlachos A. ,Cocarascu O. ,Christodoulopoulos C. and Mittal A. (2018b). The FEVER2.0 shared task. In\nProceedings of the Second Workshop on Fact Extraction and VERi\ufb01cation (FEVER) .\nTucker J.A. ,Guess A. ,Barber\u00e1 P. ,Vaccari C. ,Siegel A. ,Sanovich S. ,Stukal D. and Nyhan B. (2018). Social Media, Political\nPolarization, and Political Disinformation: A Review of the Scienti\ufb01c Literature. Technical report, Hewlett Foundation.\nvan der Linden S. (2022). Misinformation: susceptibility, spread, and interventions to immunize the public. Nature Medicine\n28(3), 460\u2013467.\nVlachos A. and Riedel S. (2014). Fact checking: task de\ufb01nition and dataset construction. In Proceedings of the ACL. 2014\nWorkshop on Language Technologies and Computational Social Science , pp. 18\u201322.\nWolf T. ,Debut L. ,Sanh V. ,Chaumond J. ,Delangue C. ,Moi A. ,Cistac P. ,Rault T. ,Louf R. ,Funtowicz M. ,Davison J. ,\nShleifer S. ,von Platen P. ,Ma C. ,Jernite Y. ,Plu J. ,Xu C. ,Scao T.L. ,Gugger S. ,Drame M. ,Lhoest Q. and Rush A.M.\n(2020). Transformers: state-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System Demonstrations , Online. Association for Computational Linguistics, pp.\n38\u201345.\nYao Y. ,Duan J. ,Xu K. ,Cai Y. ,Sun Z. and Zhang Y. (2024). A survey on large language model (LLM) security and privacy:\nthe good, the bad, and the ugly. High-Con\ufb01dence Computing 4(2), 100211.\nYoo K. ,Kim J. ,Jang J. and Kwak N. (2022). Detection of adversarial examples in text classi\ufb01cation: benchmark and base-\nline via robust density estimation. In Muresan S., Nakov P. and Villavicencio A. (eds), Findings of the Association for\nComputational Linguistics: ACL, Dublin, Ireland . Association for Computational Linguistics, pp. 3656\u20133672.\nZang Y. ,Qi F. ,Yang C. ,Liu Z. ,Zhang M. ,Liu Q. and Sun M. (2020). Word-level textual adversarial attacking as combi-\nnatorial optimization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , Online.\nAssociation for Computational Linguistics, pp. 6066\u20136080.\nZeng G. ,Qi F. ,Zhou Q. ,Zhang T. ,Ma Z. ,Hou B. ,Zang Y. ,Liu Z. and Sun M. (2021). OpenAttack: an open-source textual\nadversarial attack toolkit. In ACL-IJCNLP. 2021 - 59th Annual Meeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural Language Processing, Proceedings of the System Demonstrations .\nAssociation for Computational Linguistics (ACL), pp. 363\u2013371.\nZhang T. ,Kishore V. ,Wu F. ,Weinberger K.Q. and Artzi Y. (2020a). BERTScore: evaluating text generation with BERT. In\n8th International Conference on Learning Representations, ICLR , Addis Ababa, Ethiopia.\nZhang W.E. ,Sheng Q.Z. ,Alhazmi A. and Li C. (2020b). Adversarial attacks on deep-learning models in natural language\nprocessing. ACM Transactions on Intelligent Systems and Technology (TIST) 11(3), 1\u201341.\nZhou Z. ,Guan H. ,Bhat M.M. and Hsu J. (2019). Fake news detection via NLP is vulnerable to adversarial attacks. In\nICAART. 2019 - Proceedings of the 11th International Conference on Agents and Arti\ufb01cial Intelligence .S c i T e P r e s s ,v o l .2 ,\npp. 794\u2013800.\nCite this article: Przyby\u0142a P, Shvets A and Saggion H. Verifying the robustness of automatic credibility assessment. Natural\nLanguage Processing https://doi.org/10.1017/nlp.2024.54\nhttps://doi.org/10.1017/nlp.2024.54  Published online by Cambridge University Press", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Verifying the robustness of automatic credibility assessment", "author": ["P Przyby\u0142a", "A Shvets", "H Saggion"], "pub_year": "2024", "venue": "Natural Language Processing", "abstract": "Text classification methods have been widely investigated as a way to detect content of low  credibility: fake news, social media bots, propaganda, etc. Quite accurate models (likely"}, "filled": false, "gsrank": 356, "pub_url": "https://www.cambridge.org/core/journals/natural-language-processing/article/verifying-the-robustness-of-automatic-credibility-assessment/5BB6FBE74C9DD678AF4C6E08EB9C822F", "author_id": ["OpiwQjQAAAAJ", "BWiWj-sAAAAJ", "WMrCFCIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:KIYfbi5BquMJ:scholar.google.com/&output=cite&scirp=355&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=KIYfbi5BquMJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 9, "citedby_url": "/scholar?cites=16404996260322313768&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:KIYfbi5BquMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5BB6FBE74C9DD678AF4C6E08EB9C822F/S2977042424000542a.pdf/verifying_the_robustness_of_automatic_credibility_assessment.pdf"}}, {"title": "Auditing Google's Search Algorithm: Measuring News Diversity Across Brazil, the UK, and the US", "year": "2024", "pdf_data": "AUDITING GOOGLE \u2019SSEARCH ALGORITHM : M EASURING\nNEWS DIVERSITY ACROSS BRAZIL ,THE UK, AND THE US\nRaphael Hernandes\nLeverhulme Centre for the Future of Intelligence\nUniversity of Cambridge\nrhh43@cam.ac.uk\nGiulio Corsi\nLeverhulme Centre for the Future of Intelligence\nUniversity of Cambridge\ngc540@cam.ac.uk\nABSTRACT\nThis study examines the influence of Google\u2019s search algorithm on news diversity by an-\nalyzing search results in Brazil, the UK, and the US. It explores how Google\u2019s system\npreferentially favors a limited number of news outlets. Utilizing algorithm auditing tech-\nniques, the research measures source concentration with the Herfindahl-Hirschman Index\n(HHI) and Gini coefficient, revealing significant concentration trends. The study under-\nscores the importance of conducting horizontal analyses across multiple search queries, as\nfocusing solely on individual results pages may obscure these patterns. Factors such as\npopularity, political bias, and recency were evaluated for their impact on news rankings.\nFindings indicate a slight leftward bias in search outcomes and a preference for popular,\noften national outlets. This bias, combined with a tendency to prioritize recent content,\nsuggests that Google\u2019s algorithm may reinforce existing media inequalities. By analyzing\nthe largest dataset to date\u2014221,863 search results\u2014this research provides comprehensive,\nlongitudinal insights into how algorithms shape public access to diverse news sources.\nKeywords news diversity, artificial intelligence, Google, news exposure, search engine, algorithm audit\n1 Introduction\nNews diversity is crucial for the health of democratic processes. It allows for a wide range of opinions to\nbe heard, which is essential for a well-informed public, and aids the reception of diverse ideas [1], [2]. In\nthe digital age, part of that diversity comes from having an ecosystem of multiple outlets with different\nideologies and framings to expose people to various viewpoints. However, this will only work if the content\nactually gets to readers. News distribution, therefore, plays a crucial role in this process [3, pp. 248, 254\u2013257].\nAlgorithms increasingly mediate the distribution of news. The digital age brought an uptick in the offering of\ninformation, and these systems are intermediaries in content discovery. Their behavior can have a significant\nimpact on what people see [4, pp. 177\u2013203], [5], [6, pp. 1683\u20131685]. Given their important role, it is necessary\nto investigate how they might affect news distribution.\nThe importance of ensuring news diversity in these systems is twofold. It fosters a healthy news ecosystem\nby exposing readers to a variety of content, and the web traffic generated from the exposure brings economic\nbenefits to publishers [3, p. 248], [7, p. 13].arXiv:2410.23842v1  [cs.CY]  31 Oct 2024\nSearch engines are crucial and act as gatekeepers in this process, as most readers reach news websites\nthrough them [8], [5], [9, p. 50], [10, p. 210]. Google is an undisputed leader in this field, with over 90% of\nmarket share worldwide [11], [12].\nIn the literature regarding diversity in the media, this is related to the idea of exposure diversity : the variety of\ncontent and viewpoints that readers access, which goes through exposing audiences to different sources [13,\np. 149], [14, p. 24], [2, p. 330]. By displaying news in its results, Google diverts readers\u2019 attention to the\noutlets and articles it curates [7, p. 3].\nWhile previous research has identified biases in these search engines [6], [15], [7], these analyses often\nhave limitations in scope, such as focusing solely on the US or English-language content, or examining a\nnarrow set of queries. This paper extends the literature by investigating the presence of biases in the news\ndistribution in Google Search through algorithm auditing techniques in Brazil, the UK, and the US [16, p. 6],\nusing metrics that have been explored in this context in the past (such as popularity and political bias) and\nincorporating new ones: information quality and the number of articles each outlet published on a given\ntopic. By extracting data from the \"News\" tab in Google Search over 21 days, it analyzed 143,976 results\nrelated to 2,298 search queries and 4,296 outlets. Key parts of the findings were validated on an additional\ndataset collected over 12 days, with 77,887 results. The analysis shows high market concentration in Google\nSearch\u2019s algorithm outputs, along with biases relating to the sources\u2019 popularity and political stance, and the\ncontent\u2019s recency.\n2 Background\n2.1 News Diversity and Algorithms Mediating News Consumption\nDiversity is widely regarded as desirable in news ecosystems and crucial for democratic processes [17, p. 2],\n[1], [2], [14, p. 1]. Its components include diversity of sources (news organizations), content (viewpoints and\nideas) and exposure (consumption) [3, pp. 247\u2013248], [14, p. 10]. Ensuring diversity is one goal that drives\npolicy in this area, and in recent years these have turned their attention to exposure diversity \u2014the diversity of\ncontent and viewpoints that readers actually access [13, p. 149], [14, p. 24].\nThe distinction between internal diversity (within media outlets) and external diversity (between media\noutlets) becomes particularly relevant in this context as, with more niche and partizan media appearing,\nthe latter helps ensure balance [2, p. 330], [3, p. 251], [18, p. 179]. In a scenario where audiences that were\nonce choosing from a small number of publications then have an excess of choices for content [3, p. 251],\n[18, p. 179], the abundance of content can paradoxically lead to polarization if users expose themselves to\nlike-minded information instead of diverse sources [2, p. 330], [3, p. 252]. Therefore, ensuring that diverse\ncontent gets to people is crucial for the diversity of the news ecosystem to be effective.\nReaders increasingly rely on tech platforms like Facebook and Google to access news content instead of\ngoing directly to news websites. These \"side-door\" routes are particularly popular with younger audiences\nand are becoming more common over time [19, p. 10], with search engines accounting for 17% to 41% of\ntraffic to news websites, depending on the country [8].\nWhile algorithms, acting as gatekeepers, help users sort through the information overload common in the\ndigital age, they are not free from bias, despite what some ideas of having these allegedly neutral alternatives\nmight suggest [10, pp. 209\u2013214], [4, p. 182], [5], [9, pp. 45, 49\u201350]. Algorithmic biases might be hidden in\nsystems even for those who develop it [20, p. 331], [21, pp. 11\u201312], [22]. These biases can be technical, such\nas the criteria for selecting and ranking news, or stem from the humans who design them, reflecting their\nvalues and beliefs [10].\n2\nGoogle\u2019s search engine has shown multiple instances of these biases over the years, including in news\ndistribution [23, p. 18], [24], [6, pp. 1692\u20131693]. It uses a complex algorithm to sort through the vast amount\nof information on the web and present its pick of the most relevant results to the user. Examples of biases on\nits technical side include not getting information from every existing website and prioritizing older web\ndomains over newly created ones. On a company side, Google might remove content following requests from\ngovernments [10, pp. 215\u2013217], or give more space to services owned by Google than their competitors [25].\nIn a context that relates to diversity of viewpoints, research has found that search engines may display\npolitical biases [26]. These biases might reflect the input (when the system indexes skewed data, which is\nreflected in the output). However, they may also relate to the ranking mechanisms surfacing more content\nthat aligns with a political ideology. Google\u2019s results, for example, were shown to match the inclinations of\nthe entity represented in the searched keywords, meaning queries about Democrat US politicians generally\nhad left-skewed results [26, p. 215].\nThe media environment is shifting from broadcasting, where a single message is sent to a large audience,\nto narrowcasting and hyper-personalization, where content is tailored to individuals, which can lead to\na decrease in exposure to diverse viewpoints and ideological segregation [27, pp. 798\u2013799]. There is an\nabundance of information and viewpoints available to users at any time if they are part of the 57% of the\nworld population with internet access on their phones [28, p. 4]. The question is, thus, to ensure that these\npeople are not exposed to only a small and uniform chunk of this content [27, p. 802] [18, pp. 179\u2013180].\nHowever, companies that create platforms and algorithms that mediate the information environment aim to\nmaximize profits by increasing consumption rather than ensuring exposure diversity. As suggested by the\nfilter-bubble hypothesis, this misalignment can filter out content that might be less interesting to consumers\nregardless of their journalistic importance [29, p. 2]. While empirical evidence might challenge the effects of\necho chambers and shows that concerns around filter-bubble effects could be exaggerated [30] [31, p. 18],\ntheir mitigation hinges on users accessing diverse media. Lack of diversity in algorithms that curate news\nshould, therefore, still be a point of concern [7, p. 3][22-23]rottgerInformationEnvironmentIts2020. In a recent\ninternal data leak from Google, confirmed as authentic by the company, suggests that the search engine\ntakes user engagement into account when ranking results [32], [33].\nGoogle Search is met with great user trust, which has been empirically demonstrated [34]. This can be\ndangerous. Switching the order of search results, for example, can shift the voting preferences of undecided\nvoters by 20% or more [35]. And Google\u2019s influence in news diffusion is exacerbated by a matter of scale.\nAccording to Similar Web, a service that specializes in website audience, the US-based news outlet with the\nlargest audience, nytimes.com , had 633.9 million worldwide visits1in April/2024. Google.com had 70.8\nbillion, excluding subdomains (such as the email service Gmail ) and local domains \u2014the Brazilian version,\nGoogle.com.br , for example, had 503.6 million visits [36], [37].\n2.1.1 Google\u2019s Algorithms and the Media Market\nAs one of the most important sources of traffic to news websites, Google plays a crucial role in the busi-\nness model of digital news outlets, which largely relies on selling subscriptions and advertisement-based\nrevenue [38], [39].\nGoogle\u2019s relationship with media across the world has multiple aspects. In some, the tech giant supports\ncontent producers, which, in turn, ensure Google has information to show to its users. This support comes in\nthe form of web traffic but also partnerships and funding for news initiatives [40, pp. 116\u2013118], [41, pp. 162,\n166, 171], [42], [43]. On the other hand, this relationship also comes with tensions. Changes to these systems\ncan lead to declines in traffic, and optimizing for performance on such algorithms affects decisions about\n1Number of times a user enters a website\n3\nwhat and when to post, creating an uncertain environment for content producers [4, pp. 179\u2013180, 186], [9,\np. 49], [44].\nPrevious studies have identified a biased selection of news sources in Google\u2019s systems. Analyzing the news\naggregator Google News in Germany, research found that Focus Online and Die Welt had substantial shares\nof exposures, which was disproportionate considering their actual reach in the country. At the same time,\nmore popular outlets seemed underrepresented [29, p. 9]. High source concentration across different search\nqueries has been found in the US market along with a slight political skewness towards the left compared to\na baseline and a favoring of recent articles [7]. In another investigation of two keywords in the US, market\nconcentration was also found with five sources having 93% of the results for the first keyword and ten\nsources corresponding to 80% of the results for the second one, gathering data every minute for 24 hours[4,\npp. 177\u2013179] These patterns imply an uneven capture of economic benefits by players in this industry [7,\np. 13].\n3 Methodology\n3.1 Challenges to Evaluating Bias in Search Engines\nData from Google\u2019s search results is not readily available to researchers, and there is no way to determine\nthe exact results consumed by users on the platform. Algorithm auditing techniques allow third parties to\ntest deficiencies in artificial intelligence systems without access to their internal workings [16, p. 6]. Scraping\nGoogle\u2019s results can provide an approximation of what the public receives [7, p. 5], [45, p. 5], [16, p. 22],\n[46]. Google\u2019s content is personalized, so the results page that two users get for the same query might\nbe different [15]. One way to control for this variation is to hold personalization factors constant while\nscraping [16, pp. 41\u201342].\nA previous study that measured the personalization in Google found that, on average, 11.7% of its results\nshowed some variation due to personalization [15]. Being logged in (or not) impacted the ordering of the\nresults. The machine\u2019s IP address led to changes in the results, as that is related to location; results were\ndramatically different across multiple countries. Significant variations were also found from day to day [15,\npp. 2\u20133, 12, 15, 17, 19\u201321]. The analysis also found a carry-over effect , a noise from which a previous search\nmay contaminate further queries. An example is that looking for a clothes retailer right after searching\n\"Hawaii\" may lead the engine to display stores in that state regardless of where the search occurs. This effect\ninfluences queries executed within 10 minutes of each other [15, pp. 6\u20137].\n3.2 Data Collection\nThe analyzed search topics were selected by extracting the most popular keywords from Google Trends for\neach country using its official RSS feed. Google Trends lists the most popular search queries, meaning they\nare relevant to the public. Keywords gathered from Trends were used to query Google Search. This used the\nSelenium library in Python, which allows for the automation of web browsers. The process used a clean\nbrowser every time to avoid contaminating the results with the previous browsing. To simulate a person,\nthe script entered Google\u2019s homepage, typed the keyword in the search box using random keystroke times,\nand then hit \"enter,\" leading to the main results page. The script would then click the \"News\" tab button\nand download that page\u2019s results. Ten keywords for each country were manually validated and completely\nmatched the results gathered by the system. The keywords that did not include the news tab button in their\nresults page were assumed not to be news-related, verified by manual inspection, and discarded.\nThe extractions happened every three hours to accommodate the time zones of the countries analyzed while\nensuring multiple parts of the news cycle were captured. The data was gathered by simulating users in\n4\n1\n 2\n3\n 4\nFigure 1: The relevant Google pages mentioned in this analysis. Keywords identified in Google Trends (picture 1) are\nqueried in Search (2). Clicking \"News\" below the search box leads to the news tab (3). The layout for the results in the\nnews tab varies, all were captured (4).\nBrazil, the United Kingdom, and the United States, using NordVPN , a leading VPN provider [47]. All data\nwas collected using an AWS Linux machine. The operating system should not influence search results [15,\np. 15]. Whenever the system connected to the VPN, it checked its own IP address using ipify.org \u2019s API.\nThe corresponding location for each IP was later validated using ipapi , which provides an approximated\naddress to an IP . The results for each keyword were also validated to check if they matched the expected\nlanguage.\nEach keyword was queried five times, thus over 15 hours. This interval was deemed relevant as it gives\nnewsrooms time to react to trending events, even if they happen overnight. Analyzing a longer period would\nnot align with the study\u2019s objectives, as it primarily focuses on the news users receive . Over time, Google\ncould pick up on additional results for each query, which might suggest better diversity. This could be\nmisleading given that a significant portion of the audience engagement occurs within the first few hours [48].\n5\nData was collected between March 11th, 2024, and April 1st, 2024. A total of 2,298 keywords were captured,\nrendering 143,976 results . These account for 50,496 unique URLs from 4,296 outlets . The results included\n67 tweets, which were removed. These appeared when searching the names of cities, displaying popular\ncontent for that area.\nUsing a similar process, additional data was collected for 12 days (April 29th2024 to May 11th2024) to\nvalidate some of this study\u2019s main findings. It includes 77,887 new results . It is described in Appendix A.\n3.2.1 Carry-over Effect\nIn tests for this analysis, the carry-over effect (section 3.1) was spotted in Google\u2019s main results page as\ndescribed in previous research [15, p. 6]. This effect should disappear if there is a 10-minute interval between\nqueries [15, p. 7]. However, given the volume of queries in this study, that interval is impractical. Using a\ncomputer in Cambridge (UK), the additional tests involved searching for \"best pizza places\" and examining\nthe results, which were consistent across normal and incognito browsing. After a 10-minute interval, a search\nfor \"Train tickets to Manchester\" was performed in normal browsing mode, followed by a repetition of the\npizza query. This time, a result related to Manchester, which had not appeared before, was shown mid-page\nin both browsing modes. After another 10-minute interval, the pizza query yielded the original results. A\nsimilar methodology was applied to the news tab, where the effect was not observed. Later, the process was\nrepeated using \"traffic\" as the original query, achieving the same results. Consequently, it can be inferred\nthat the carry-over effect in the news tab, if present, is negligible.\n3.3 Additional Data and Data Labeling\n3.3.1 News Section\nUsing the sample news article provided along with each query on Trends, each keyword was assigned to one\nof four news sections: Sports, Politics, Entertainment, and Others. This classification system was defined after\nan initial manual inspection. This process ensures the labeling remains simple, with few categories, while\nproviding the necessary insight for the analysis. The classifications used OpenAI\u2019s gpt-3.5-turbo-1106\nmodel. The prompt constrained the system to the desired section labels and allowed it to abstain. None was\nleft unassigned. The temperature was 0.0to increase consistency [49, p. 2].\nThe labels were validated by manually coding a random sample of 5% of entries from each country, 125\ntotal. These were annotated by the author and an additional coder, a journalist with experience working\nin Brazil and the UK. About half the data was classified as Sports, so the inter-coder agreement was tested\nusing Gwet\u2019s AC1, a better choice for skewed datasets [50]. Considering both human coders and GPT, it was\n.898 (95% Confidence Interval: 0.824 ,0.952 ), indicating a high level of reliability. A slight drop from when\nconsidering only the two human coders, 0.929 (CI:0.876 ,0.981 ).\n3.3.2 Political Bias\nEach outlet in the dataset was classified in regards to its political bias on a seven-degree scale: \"far-left,\" \"left,\"\n\"center-left,\" center,\" \"center-right,\" \"right,\" and \"far-right.\" Where available, these ratings were extracted from\nMedia Bias/Fact Check (MBFC). This service specializes in labeling media sources under multiple criteria [51]\nand is often cited in academic and media sources [52], [53], [54]. There was no information for most sources\nfrom Brazil, so these were removed from this part of the analysis. MBFC data accounted for 951 of the 3,082\nidentified UK and US sources (29.8%). These were incremented with using GPT-4, following research that\nshowed high correlation between MBFC and the language model in a similar task [55]. Gpt-4o-2024-05-13\nwas used to label the remaining sources using the same classification system. The prompt allowed the system\n6\nto abstain. Temperature was set to 0.0. These resulted in an additional 307 ratings. A random sample of 10%\nof those was validated by the author. These either were Sports outlets categorized as \"no political bias\" or\nmatched the classification of alternative rating sources, All Sides and Ad Fontes Media. So, in the end, the\nanalysis had 1,258 (40.8% ) outlets classified in terms of political bias, accounting for 65,457 (72%) results.\n3.3.3 Baseline from Media Cloud\nEach keyword in this analysis was queried in the Media Cloud database, a system that monitors and\naggregates news output from sources around the world using their RSS feeds, providing a list of texts\nand sources matching a query [56], [57]. Media Bias and Google searches, however, do not have an exact\ncorrespondence, as Media Cloud looks for string matches within the texts, and Google can index content\neven if the wording is not the same [58], [59]. Because of that difference, in Media Cloud, keywords of\nthree letters or less were discarded, as these can be too generic. Also, outliers in the volume of results were\nremoved. Each keyword was queried to a Media Cloud collection of national news sources from the relevant\ncountry. Data was collected from the day the keyword appeared on Google Trends until the following day to\ncapture a similar news cycle.\n3.4 Attributing Weighted Rankings\nRankings in Google results matter. It has been empirically demonstrated that links appearing higher on\nthe page normally have higher click-through rates, are more often seen, and regarded as more trustworthy\nby users [34], [35], [60], [61]. So, the analysis includes a weighted ranking of the results. To calculate these\nvalues, this study borrows the logic from Rank-Biased Overlap (RBO) [62]. Appearing first yields a weight of\n1, and the following entries have progressively decaying scores. The rate of the decay is pwhere 0<p<1,\nand the weight assigned to a URL at position kis calculated as wk=pk\u22121. Here, kis the rank position, and wk\nis the weight assigned to that position. The value of pis found by satisfying the equation p+p2+p3=0.55.\nThis way, the top-3 results will account for 55% of the weights, reflecting the most conservative click-through\nvalues recently found by agencies that specialize in optimizing content for Google Search [60], [63].\n4 Results\n4.1 Source Concentration\n0.00 0.25 0.50 0.75 1.00\nCumulative Percentage of Outlets0.00.20.40.60.81.0Cumulative Percentage of ResultsLorenz Curve for Results Distribution\nLorenz Curve\nLine of Equality\n50% Cutoff in Results\nFigure 2: The Lorenz curve shows that a few outlets\naccount for half of the results. The dotted upright\nline divides the number of results in equal parts.The analysis of source concentration in this dataset can be\nmisleading depending on how it is considered. Aggregating\nthe data by keywords, showing the concentration for each\nquery, indicates a balanced environment. These were mea-\nsured using adapted versions of the Herfindahl-Hirschman\nIndex (HHI), and Gini coefficient. HHI is 0.09 and Gini is\n0.32 , both on average. These values remain low across the\nmultiple news sections and countries throughout the data.\nAnalyzing the data horizontally, however, shows that some\nnews outlets get repeated over multiple queries. So, while\nusers might not see repetition in a single search, they might\nencounter the same sources often over time. In each an-\nalyzed country, a small proportion of the outlets account\nfor a large share of the results. These form a non-uniform\ndistribution, as shown by the Kolmogorov-Smirnov statistic\n7\n(D=0.916 ,p<0.001 ). That pattern is also true when looking at the data segmented by section on top\nof country. A CRk(concentration ratio) analysis shows how concentrated the results are on a small set of\noutlets, seen in table 1. Despite some fluctuation, these patterns hold true when the data is analyzed by news\nsections. This breakdown is available in Appendix B, as is a list of the most popular outlets per country.\nThis scenario can also be seen in the overall data having a high Gini coefficient ( 0.822 ) and low HHI ( 0.005 ).\nThe latter picks up on the fact that several players are represented in the results, but half appear five times or\nless. So, among these peers that comprise most of the analyzed sources, some leveled competition is going\non. Gini, however, picks up on having 2.1% of these outlets accounting for 50% of the results, which can be\nvisualized in Figure 2.\nTable 1: CR k, concentration of Top koutlets per country.\nCountry CR 4 CR 8 CR 10 Results News Sources\nBR 0.163313 0.254306 0.286720 53125 1226\nUK 0.209089 0.318496 0.357862 40619 1478\nUS 0.117714 0.186734 0.214823 50232 2189\n4.1.1 Source Concentration in Privileged Positions\nConsidering the ordering of the results, a greater disparity is found. The Gini coefficient is higher (0.919),\nand HHI remains low (0.011). The concentrated nature of the most privileged positions can also be seen\ninCRk, as per table 2. The source concentration patterns were validated in the additional dataset, which\nshowed similar values for HHI and Gini, and the same pattern of horizontal concentration. It is available in\nAppendix D.\nTable 2: CR k, concentration of Top koutlets per country considering the results\u2019 weighted ranking.\nCountry CR 4 CR 8 CR 10 Results News Sources\nBR 0.325873 0.651520 0.813704 53125 1226\nUK 0.325956 0.651862 0.814496 40619 1478\nUS 0.306577 0.613155 0.766245 50232 2189\n4.2 Popular Sources are Popular in Google\nConcentration on specific outlets leads to questions about what characteristics they have in common or what\nleads to news sources appearing in Google more often. Open PageRank scores, understood as a proxy for\npopularity, showed a clear connection with the results. The average score is higher among the top outlets in\nthe three countries (Table 3). In parts, this is expected since this score is deliberately created to try to mimic\nGoogle\u2019s Pagerank feature, which is used to determine search results [64].\nTable 3: Mann-Whitney U test results for Open PageRank scores.\nCountry Median for Other Outlets Median for Top Outlets U-statistic P-value\nBrazil 4.08 5.27 4920.5 <0.001\nUK 5.35 6.33 6872.5 <0.001\nUS 5.37 6.67 19634.0 <0.001\n8\nThe influence of website popularity on the number of results was analyzed through a set of Ordinary Least\nSquares (OLS) regressions. Considering only the Politics and Others sections for all countries, a one-point\nincrease in the Open PageRank score is associated with having 14 extra results ( p<0.001 ). Despite the\nmodel\u2019s limited explanatory power ( R2=0.07), it provides evidence of this relationship, which can also be\nseen in the countries individually and considering other news sections. Regression tables are available in\nAppendix F.\n4.3 Information Quality\u2019s Impact on Results\nIn the UK and the US, the top outlets (respectively, the 1.9% and 3% with 50% of the results) have a higher\ninformation quality score than other sources. This score was extracted from a dataset created by Lin, Lasser,\nLewandowsky, et al. [65] that rates news sources based on their credibility (referred to here as LIN-PC1 ).\nData for most Brazilian sources was unavailable, so these were removed from this part of the analysis. The\ninformation was available for 1,261 (40.9% ) of the 3,082 UK and US sources. These accounted for 65,080\n(71.6% ) results. To mitigate that gap, the analysis ran on publishers with five results or more (above the\nmedian) since those at the bottom often lacked the Lin-PC1 score.\nThe median Lin-PC1 score for the top outlets was 0.78 in the UK and 0.83 in the US, while the rest of the\noutlets had respectively 0.70 and 0.71 . Its statistical relevance was assessed by Mann-Whitney U(UK:\nU=3103.5 ,p<0.05; US: U=4911.5 ,p<0.01). This comparison only focuses on results in the Politics\nand Others sections. Including Sports and Entertainment showed a similar pattern but only had statistical\nsignificance in the US ( p<0.01).\nOLS regressions, however, suggest no relationship between the quality rating and an outlet\u2019s prevalence\nwhen considering popularity. The results indicate that while the Lin-PC1 metric is significantly (negatively)\nassociated with the number of results when controlling for Open PageRank, its direct association with the\nvolume of entries is not significant. This suggests that the apparent association between higher Lin-PC1 and\nappearing more often in the results may be driven by the relationship between Lin-PC1 and Open PageRank,\nrather than a direct effect. The regression tables are available in Appendix G.\n4.4 Political Inclination\nComparing the top outlets in the US to those that had fewer results shows a leftwards inclination, with the\ndistribution\u2019s median landing on the center-left instead of the center (Mann-Whitney U=33126.0 ,p<0.05).\nThis difference, however, needs to be taken with a grain of salt, as a significant portion of the data was\nunclassified. This considers only the Politics and Others sections, which relate more to such bias than Sports\nand Entertainment. An OLS regression on the scale and the number of results, controlling for popularity\n(Open PageRank), is not statistically relevant.\nMore evidence comes from comparing Google Search to Media Cloud\u2019s UK and US data (Figure 3). Results\nin Google gravitate more towards the left categories than Media Cloud\u2019s. This pattern relates to a previous\nstudy that also identified this left-leaning pattern in the results in the US when comparing to another baseline\nof news outlets, GDELT [7, p. 9]. This result backs those found previously and shows this phenomenon in\nanother country.\nMoreover, a meaningful relationship exists between political bias and results\u2019 rankings. An OLS regression\non the ordered political bias (where lower values relate to the left) was run against the order of the results in\nGoogle. In the US, it found a significant relationship in which a higher political bias scale rating (more to the\nright) means appearing further down in Google\u2019s results ( p<0.001 ). The analysis controlled for popularity.\nRegression tables are available in Appendix H. Results were not statistically significant in the UK.\n9\n-3 -2 -1 0 1 2 3\nPolitical Bias Scale02040Percentage of ResultsPolitical Bias Distribution in the UK\nMedia Cloud Google\n-3 -2 -1 0 1 2 3\nPolitical Bias Scale02040Percentage of ResultsPolitical Bias Distribution in the US\nMedia Cloud GoogleFigure 3: Results per political bias category for Media Cloud\u2019s and Google\u2019s datasets; -3 is far-left and 3 is far-right. Full\ntable in Appendix E.\nThe overall leftwards skew can also be verified in individual queries through a time-averaged output bias\n(TOB) analysis, as described by Kulshrestha, Eslami, Messias, et al. [26]. This was applied to the 81 queries\nin the Politics section in the US and the UK where 80% or more of results had political bias information.\nAverage TOB was -0.05, reinforcing the slight leftwards skew in the results. Most (64) queries were skewed\nto the left, and they did not necessarily reflect the keywords. For example, queries on left-wing politicians\nand personalities had both leftwards TOBs (Barack Obama, Joe Lieberman, Owen Jones, etc.) and rightwards\nTOBs (Tammy Murphy, Rachel Reeves). The opposite was also true.\n4.5 Preference for Recent Results\nUnsurprisingly, the analysis reveals a pattern of updating the content to incorporate more recent results\nover time. That can be seen in the rate at which average article age progresses (Table 5). Given that this\nstudy gathered data for each query every three hours, with no changes, the average from a second extraction\nshould be three hours older than the first. These being smaller than three hours reveals that the results\nprioritize newer articles. Recency analysis removed outliers in terms of article age using the IQR method.\nThe same pattern was found in every country.\nJaccard index and Rank-Biased Overlap (RBO) scores are lower when comparing the first and last iterations\nto subsequent ones (1 vs. 2, 2 vs. 3,. . . ), suggesting a gradual change. The results between the initial and\nfinal scraping sessions (1 and 5) reveal a medium level of overlap (Table 4).\nTable 4: Descriptive statistics of Jaccard Index and RBO comparing first iteration to last.\nStatistic Count Mean Std. Deviation Minimum Maximum\nJaccard 2298 0.491 0.198 0.000 1.000\nRBO 2298 0.347 0.379 0.000 0.999\nA steady pattern of content renewal is true for all analyzed countries (Table 5). The average sequential\nJaccard on the outlets\u2019 names shows a higher value (0.65) than considering the URLs (0.54), suggesting that\npart of the variability does not bring additional source diversity. An ANOVA test shows no meaningful\ndifference in Open PageRank over iterations. So, despite changes in the URLs, there is no difference in the\npopularity of the featured outlets over time.\nThe analysis reinforces the importance of recency for the articles. Outlets were divided into four groups\nbased on their popularity (Open PageRank) and how they performed regarding their number of results,\n10\nTable 5: Average Jaccard, RBO, and time difference between article publishing and data collection (Article Age) over\ndifferent iterations. Jaccard and RBO scores represent a comparison with the iteration that came immediately before. The\nmean variations in the columns were tested using ANOVA and are all statistically significant ( p<0.001).\nScraping Iteration Avg. Jaccard Avg. RBO Avg. Article Age (Hours)\n1 14.09\n2 0.51 0.53 14.70\n3 0.53 0.55 15.76\n4 0.56 0.58 16.86\n5 0.56 0.58 17.68\nas seen in Table 6. Outlets in the top half of the results volume had a lower average article age than their\ncounterparts in the bottom half. This shows that less-known sources could get extra space by having newer\ncontent.\nThe source concentration patterns were validated in the additional dataset, which showed similar values to\nthe ones displayed here. It is available in Appendix K.\nTable 6: Average and median article age for different categories of outlets regarding their popularity and volume of\nresults. Mean variations tested using ANOVA ( p<0.001) ( p<0.001)\nCountry Category Avg. Article Age Median Article Age\n(Hours) (Hours)\nBRLow Popularity, Low Results 17.2 15.0\nLow Popularity, High Results 15.3 14.0\nHigh Popularity, Low Results 16.7 15.0\nHigh Popularity, High Results 15.8 14.0\nUKLow Popularity, Low Results 17.2 16.0\nLow Popularity, High Results 15.1 13.0\nHigh Popularity, Low Results 17.4 17.0\nHigh Popularity, High Results 14.5 12.0\nUSLow Popularity, Low Results 16.4 14.0\nLow Popularity, High Results 15.9 15.0\nHigh Popularity, Low Results 15.2 13.0\nHigh Popularity, High Results 13.8 11.0\nOn average, articles ranking higher are newer. This relationship can be seen in an OLS regression on the\nweighted order of the articles and article age, controlling for the article\u2019s popularity ( R2=0.024, p<0.001 ).\nThis is true for every country. Their tables are in Appendix I.\nTable 7: Article recency for categories of positions in Google\u2019s ranking. Mean variation tested using ANOVA ( p<0.001 ).\nPosition Number of texts Avg. Article Age (Hours) Median Article Age (Hours)\n1 11250 13.3 12.0\n2-5 43651 14.0 12.0\n6+ 77205 17.2 15.0\n4.6 Publishing More About a Topic\nGiven Google\u2019s preference for recent content, news outlets might be incentivized to publish multiple texts\nabout a topic to appear more often in the results. Comparing Google\u2019s results to Media Cloud\u2019s suggests this\n11\nmight work. Outlets that had more texts on a given query in Media Cloud had increased chances of being\nlisted in Google\u2019s results. This was confirmed by logistic regressions ( R2\nMcF=0.04, p<0.001 ). Overall, each\nadditional text on a keyword that appeared on Media Cloud\u2019s database meant a 10.4% greater chance of that\noutlet appearing in Google\u2019s results for that query. Tables are available in Appendix J.\n5 Discussion\nGoogle\u2019s search algorithm\u2019s complexity makes it hard to discern patterns in its selection and ranking of news\ncontent. Its engine is speculated to rely on several attributes, which are unknown to the public [66], [33].\nThis opacity makes approaches like the algorithm audits necessary for capturing some of the issues in its\nworkings by controlling the inputs and analyzing its outputs [26, p. 197]. Given said complexity, some of the\ndiscrepancies found in this investigation hinge on a slight difference or models showing a low R-squared,\nwhich, despite statistically meaningful, only account for a small portion of the variation in the data. Though,\nwith Google\u2019s relevance, the tiniest nudge can have a big impact.\nThe results displayed in Google\u2019s news tab are mostly balanced vertically but concentrated horizontally. In\nother words, a user who looks for a news topic in Google may see no repeated outlets (this happened in 40%\nof the queries in this audit). The Gini coefficient was low when considering individual queries, indicating\nlow market concentration (section 4.1). However, users who are too dependent on Google for their news\ndiets, as people increasingly are [19], will often see repeated outlets across their queries. This can be seen in\na large Gini overall and relates to research that found these platforms bring more short-term consumption of\ndiverse news sources but limit it in the long term [67].\nIt should be noted that the low Gini for individual queries is not always true. Some cases of high concentration\nhappen when looking for outlets\u2019 names. This could be justified as the users\u2019 interest to see mostly CNN\nwhen searching for \"CNN.\" However, others refer to queries on topics such as an Uber driver strike in Brazil,\nfor which five outlets are featured among 50 results (over five iterations).\nGoogle\u2019s source concentration had already been demonstrated in another analysis of Google\u2019s news results [7].\nThis analysis shows it goes beyond the US, as the same pattern was identified in the UK, similar to the US\nregarding language and development, and Brazil, with a different language and situated in the Global South.\nThis shows the global nature of Google\u2019s impact, a power that extends beyond any publisher\u2019s dream [41,\np. 173].\nIn practice, search engines act as gatekeepers to the content that gets consumed or not on the web, to\nthe point that not being listed in Google can be seen as the same as not existing online [68, p. 21]. By\nnarrowing the options users see, these results might affect the internet\u2019s value as a source of information,\nwhich comes from being a democratic and inclusive place that is able to give voice to diverse groups [69,\np. 169], [69, pp. 180\u2013181], [70, p. 11]. The top outlets are already popular (section 5.1). The cost of biased\nsearch mechanisms can be significant for those striving to be found.\nSources that offer quality content but lack popularity might end up neglected. Someone seeking information\nabout a news event may stop their search after finding a suitable story near the top of the list, missing equally\nvaluable options listed further [69, p. 180]. This concentration might go unnoticed by the user; after all, their\ninformation needs were met. However, it might still have the consequence of leaving them systematically\nconsuming from similar sources (relating to the filter-bubble effect [29]) while leaving many potentially\nquality sources unseen.\n12\n5.1 Popularity Bias and Distortions\nThe concentration privileges certain characteristics. One of these is popularity, measured by the Open\nPageRank score, with Google favoring well-known outlets. This approach has its merits, as it ends up giving\nmore space to reputable sources (section 4.3). Previous research indicates that the search engine implicitly\nconsiders credibility through popularity and honors it to a point [71, pp. 3, 10]. This can be seen empirically\nin this analysis, as the outlets featured the most also scored higher on Lin-PC1. In consonance with previous\nwork, however, this study shows that the higher-quality domain prevalence is incidental.\nPopularity does not necessarily equate to quality, though. Sometimes, widely read sources may disseminate\nlower-quality information. For instance, English tabloids, which are highly popular, score lower on infor-\nmation quality metrics. The tabloid Daily Mail is, in the UK, the third most consumed online publication\nand the largest paid newspaper in terms of circulation among those that publicize the metric [72], [19, p. 59].\nHowever, it has a low score in the Lin-PC1 metric (0.38). In this analysis, it was the second most popular\nsource in the UK regarding total results count and third when weighting in the ordering of the articles. It\nfeatured in the top 10 outlets for three of the four news sections: Others, Sports, and Entertainment. It\nappeared more often than sources with higher Lin-PC1, such as The Guardian (0.75), The Independent (0.73),\nTelegraph (0.61), and Sky News (0.87). The Daily Mail \u2019s case is not isolated, with other low Lin-PC1 sources\nfeaturing in the UK\u2019s top-20 results. Daily Mail also ranks high in the US.\nAnd then, are these sources not part of the news ecosystem and, thus, deserving of inclusion in these results?\nThis is a highly contentious matter. Taking a marketplace of ideas approach, one might argue that all sources,\nregardless of their quality score, should be included in the debate [73, p. 236]. An algorithm that rewards\npopularity promotes equality by using consumption to make decisions. By basing its rankings on popularity,\nGoogle may attempt to exempt itself from making explicit editorial decisions about which outlets deserve\nmore space. After all, public demand drives the rankings. The presence of a wide range of sources would\nencourage competition and eventually lead to a selection of higher-quality information [73]. However, this\napproach has been criticized for various reasons. One of them is suffering from failures such as monopolies,\nas in economic markets, cornering minority views [74], [73, pp. 237\u2013241], [75, pp. 109, 112], [76] \u2014which,\nhere, can be seen as the dominance of sources that are already popular.\nThe imbalance can be seen in the prioritization of national, legacy outlets. This preference also means being\nprone to reproduce their biases. If traditional media is skewed to the left, the algorithm will reproduce this\nbias. Indeed, this exact pattern was found. In the US, the content output of outlets classified as national by\nMedia Cloud was slightly skewed to the left. A similar pattern was found in Google. Meanwhile, in the UK,\nMedia Cloud\u2019s content was more balanced, which was reflected in Google\u2019s data, although with some left\nskew. This investigation failed to find a meaningful direct relationship between political bias and featuring\nmore in the results. So, this behavior could originate from the system reacting to the audience consuming\nmore content aligned to the left or from this political bias being related to other algorithm parameters.\nDespite what caused the leftwards skew, considering news diversity in terms of the content \"as received\"\nby the audience, the aspect that matters most here is the distribution itself \u2014and these results highlight a\npreference.\nThat comes on top of a seemingly systematic leftwards bias. It is present for most of the analyzed politics-\nrelated queries, independently of biases in the entity represented in the keyword, and can impact results\u2019\nrankings (section 4.4). This contrasts with previous research that considered the main results page of Google\nand found that it matched the analyzed entity (left politicians had a left skew, right had a right skew). In that\ncase, the research pointed to candidate-controlled sources, such as their own websites, pulling the results [26,\npp. 215\u2013217]. Removing those to see only news content makes the preference in the algorithm\u2019s output more\napparent.\n13\nAlso, Google itself has a significant influence on news sources\u2019 traffic [19, p. 10], [8]. A popularity-based\napproach can, thus, exacerbate existing inequalities and lead to a greater divide between more and less\nprivileged outlets, which can be problematic [69, p. 180]. By promoting certain sources, Google can create\na feedback loop where larger, more popular brands increasingly get more space and visibility, further\nentrenching their dominance. This creates another distortion in the media landscape by amplifying certain\npublishers, making it harder for smaller ones to gain traction. In practice, there is already a noted bias\ntowards national over local media, which was also found in previous research [7, p. 13], and in local\npublisher\u2019s perception of the matter, who feel like an \"afterthought\" for tech platforms [41, p. 162].\nThis speaks to an ongoing problem in the media landscape: the decline of local journalism. The lack of\ndiversity in the sources promoted by Google\u2019s algorithm can have nefarious effects on the outlets. Financially,\nit can limit the revenue opportunities for smaller, local, or less popular outlets, potentially leading to their\ndecline or closure. In the past, changes in Facebook\u2019s feed ranking led to drops in traffic to news outlets,\nbringing layoffs and even causing a digital publisher to shut down [77], [78], [41, p. 185]. This raises concerns\nabout the relationship between source diversity and larger issues in the media landscape, such as the local\nnews deserts, areas that lack news outlets to cover issues in that community. These smaller outlets face\neconomic challenges caused by the shift to online news, and their absence hampers areas like the efficiency\nof local governments, citizen engagement, and participation in elections [79, p. 5]. In Brazil, for example,\n13.2% municipalities lack local journalism [80].\nGoogle\u2019s algorithm shows some distortions that must be considered. Being a reputable and national source\ndoes not guarantee that the search will be successful, and Brazil\u2019s results can serve as an example. The list of\ntop-ranking sources excludes some outlets of high Open PageRank scores and national relevance, such as\nVeja. It is the most important weekly magazine in the country and displays conservative values [81], [82],\n[83]. It was featured in 27 queries, while Media Cloud data shows that it produced content on at least 19\nadditional topics. Also, Correio Braziliense , the 9thnewspaper in Brazil in terms of circulation, outnumbers\nboth O Estado de S. Paulo (3rd) and Folha de S.Paulo (1st), while having, respectively, 8% and 2% of their\nnumber of subscribers [84].\nOutlets might game the algorithm to secure better spots through practices such as Search Engine Opti-\nmization, a combination of technical and content manipulation that boosts Google\u2019s algorithm rating for a\npage [71, p. 5], [41, p. 165]. It can help the discovery of helpful content, but may also negatively impact the\ncredibility of the results [71, pp. 5\u20136]. After all, high-ranking results might surface not because they come\nfrom the most reputable source but because they are published in a way that scores points with the sorting\nmechanism [69, p. 175].\nThe BBC provides an interesting case for analysis. It is the only outlet to feature among the top sources in\nBrazil, the UK, and the US. The BBC is the leading news outlet in the UK and among the top in multiple\ncountries [19].\nHowever, the BBC \u2019s popularity measured by Google might have been artificially boosted. Its presence in\nBrazil expanded in the early 2000s with the creation of a website in Portuguese. Today, between 60% and 65%\nofBBC Brasil \u2019s traffic comes from search [85, p. 83]. The company increased its reach through partnerships\nthat allow major (competing) Brazilian outlets to republish its content like that of a news agency [85, pp. 16,\n155\u2013167]. The articles include a canonical hyperlink pointing to the original URL in the BBC \u2019s website,\nwhich can be seen in the republished articles pages\u2019 source codes. It tells Google\u2019s system that the URLs\nare duplicates, redirecting its readings of engagement to the BBC \u2019s original content, making it seem more\npopular [86]. This analysis does not intend to establish a causal relationship between this practice and being\nfeatured often in Google, only to offer it as an example of a practical way an outlet might try to inflate its\nalgorithmic relevance.\n14\n5.2 Recency\nRecency is another significant factor in Google\u2019s results. They show a steady rate of churn in the results list\nwhile more recent articles are added (section 4.5). Valuing recency might make sense given the fast-paced\nnature of digital age communications [87, pp. 129\u2013130]. However, this approach is not without its drawbacks.\nIt can stimulate the spamming of articles to regularly have something new for the algorithm to pick up\n(section 4.6).\nValuing recency makes sense for breaking news but not so much for other topics. The data shows that both\nbreaking news and less urgent news topics appear among the ones with the lowest average article age rates.\nFor the first, an example is the coverage of the Francis Scott Key Bridge collapse in Baltimore (US) from a\ncollision with a ship [88]. Its unexpectedness contrasts with St. Patrick\u2019s Day, also among the lowest average\nrecency. Balancing shelf lives is a known difficulty in algorithms that distribute news content, as measuring\nthe evergreen-ness of an article, and criteria such as the depth and density it conveys is hard [4, p. 198].\nOnce again, algorithmic preferences might play a role in media\u2019s behavior. In this case, it may affect less\npopular outlets disproportionately, as these appear less often in the results, and the data shows recency is\ncrucial to break through the algorithm. This pattern might offer a fighting chance for smaller outlets, but\nit can also force a favoring of breaking news over in-depth analytical reporting or publishing irrelevant or\ninaccurate updates to have recent content for the search engine to pick up [89].\n6 Conclusion\nThis study sheds light on the critical influence of Google\u2019s search algorithm on news diversity across different\ncultural and linguistic contexts. It expands previous studies in scale and by analyzing a non-English-speaking\ncountry. It also confirms its main findings with an additional dataset, providing encouraging evidence of\nthe generalizability of this study\u2019s results. By revealing patterns of source concentration, popularity bias,\nand slight political skewness, the research underscores the algorithm\u2019s role in shaping public access to\ninformation. These findings have implications for media diversity, democratic engagement, and the potential\nperpetuation of existing inequalities within the news ecosystem. Moving forward, there is an urgent need\nfor greater transparency in algorithmic processes and for policy interventions that promote a more equitable\ndistribution of news sources. Given the search engine\u2019s characteristic of driving traffic and financial gains,\nthe divide between outlets favored by the algorithm and those neglected might increase.\nWhile it might seem intuitive that popular outlets receive more visibility, the extent of this concentration\u2014\nand its consistency across different countries and news sections\u2014is not trivial. The empirical evidence\ndemonstrates that a small fraction of outlets dominate the search results in multiple countries. Moreover, the\npreference for recent content over potentially more in-depth or analytical pieces raises questions about the\nquality of information being prioritized.\n6.1 Limitations and Future Work\nThe queries used in this study often refer to broader subjects, and about half are related to Sports. Part of the\nskewness towards national outlets found in this analysis may come from inquiring about topics of these\nnatures. Further studies could benefit from exploring different topics and experimenting with their phrasing,\nwhich might impact results [26, p. 190]. This study speculates that, as a popularity provider, Google itself\nmight increase the divide between major and less-known outlets over time. Long-term evidence is necessary\nto understand if that is the case.\n15\nAcknowledgements\nThe contributions of Giovanni Bello in data labeling are gratefully acknowledged.\nCompeting Interests\nThe authors declare no competing interests.\nFunding\nNo funding was received for conducting this study.\nEthics Approval\nThis project\u2019s data collection was approved by the Leverhulme Centre for the Future of Intelligence Research\nEthics Committee.\nData availability\nThe datasets generated during and/or analysed during the current study are not publicly available due to\nbeing extracted from a private, third-party, source, as established by its ethics approval.\nAuthor contributions\nRH designed the study, RH performed the analyses, and both authors assisted in the revision of the\nmanuscript and the refinement of its arguments.\nReferences\n[1] P . M. Napoli, \u201cWhat Is Media Policy?\u201d The Annals of the American Academy of Political and Social Science ,\nvol. 707, no. 1, pp. 29\u201345, May 2023, ISSN : 0002-7162, 1552-3349. DOI:10.1177/00027162231211387 .\n(visited on 05/22/2024).\n[2] R. Van Der Wurff, \u201cDo audiences receive diverse ideas from news media? Exposure to a variety of\nnews media and personal characteristics as determinants of diversity as received,\u201d European Journal\nof Communication , vol. 26, no. 4, pp. 328\u2013342, Dec. 2011, ISSN : 0267-3231, 1460-3705. DOI:10.1177/\n0267323111423377 . (visited on 01/21/2024).\n[3] P . M. Napoli, \u201cExposure Diversity Reconsidered,\u201d Journal of Information Policy , vol. 1, pp. 246\u2013259, Jan.\n2011, ISSN : 2381-5892, 2158-3897. DOI:10.5325/jinfopoli.1.2011.0246 . (visited on 05/08/2024).\n[4] N. Diakopoulos, Automating the News: How Algorithms Are Rewriting the Media . Cambridge, Mas-\nsachusetts: Harvard University Press, 2019, ISBN : 978-0-674-97698-6.\n[5] N. Thurman, S. C. Lewis, and J. Kunert, \u201cAlgorithms, Automation, and News,\u201d Digital Journalism ,\nvol. 7, no. 8, pp. 980\u2013992, Sep. 2019, ISSN : 2167-0811. DOI:10.1080/21670811.2019.1685395 . (visited\non 05/29/2024).\n[6] R. Evans, D. Jackson, and J. Murphy, \u201cGoogle News and Machine Gatekeepers: Algorithmic Personali-\nsation and News Diversity in Online News Search,\u201d Digital Journalism , vol. 11, no. 9, pp. 1682\u20131700, Oct.\n2023, ISSN : 2167-0811, 2167-082X. DOI:10.1080/21670811.2022.2055596 . (visited on 03/01/2024).\n[7] Search as News Curator: The Role of Google in Shaping Attention to News Information , Glasgow, Scotland,\nUK: ACM, May 2019, pp. 1\u201315, ISBN : 978-1-4503-5970-2. DOI:10.1145/3290605.3300683 . (visited on\n12/18/2023).\n16\n[8] Global Audience Insights from Q4 2023 , Jan. 2024. (visited on 02/28/2024).\n[9] S. Paulussen and P . Van Aelst, \u201cNews Values in Audience-Oriented Journalism: Criteria, Angles, and\nCues of Newsworthiness in the (Digital) Media Context,\u201d in News Values from an Audience Perspective ,\nM. Temmerman and J. Mast, Eds. Cham: Springer International Publishing, 2021, pp. 37\u201355, ISBN :\n978-3-030-45046-5. DOI:10.1007/978-3-030-45046-5_3 . (visited on 05/29/2024).\n[10] E. Bozdag, \u201cBias in algorithmic filtering and personalization,\u201d Ethics and Information Technology , vol. 15,\nno. 3, pp. 209\u2013227, Sep. 2013, ISSN : 1388-1957, 1572-8439. DOI:10.1007/s10676-013-9321-6 . (visited\non 02/28/2024).\n[11] Matt G. Southern, \u201cGoogle\u2019s Search Engine Market Share Drops As Competitors\u2019 Grows,\u201d Search\nEngine Journal , May 2024. (visited on 05/26/2024).\n[12] Search Engine Market Share Worldwide , https://gs.statcounter.com/search-engine-market-share, Apr.\n2024. (visited on 05/29/2024).\n[13] H. Moe, J. F. Hovden, and K. Karppinen, \u201cOperationalizing exposure diversity,\u201d European Journal\nof Communication , vol. 36, no. 2, pp. 148\u2013167, Apr. 2021, ISSN : 0267-3231, 1460-3705. DOI:10.1177/\n0267323120966849 . (visited on 05/22/2024).\n[14] P . M. Napoli, \u201cDeconstructing the Diversity Principle,\u201d Journal of Communication , vol. 49, no. 4, pp. 7\u201334,\nDec. 1999, ISSN : 0021-9916, 1460-2466. DOI:10.1111/j.1460- 2466.1999.tb02815.x . (visited on\n05/22/2024).\n[15] A. Hann\u00e1k, P . Sapie \u02d9zy \u00b4 nski, A. M. Khaki, D. Lazer, A. Mislove, and C. Wilson, Measuring Personalization\nof Web Search , Jun. 2017. arXiv: 1706.05011 [cs] . (visited on 03/01/2024).\n[16] D. Metaxa, J. S. Park, R. E. Robertson, et al. ,Auditing Algorithms: Understanding Algorithmic Systems\nfrom the Outside In . Norwell, MA: Now Publishers, 2021, ISBN : 978-1-68083-917-3.\n[17] D. McQuail and J. J. Van Cuilenburg, \u201cDiversity as a Media Policy Goal: A Strategy for Evaluative\nResearch and a Netherlands Case Study,\u201d International Communication Gazette , vol. 31, no. 3, pp. 145\u2013\n162, Jun. 1983, ISSN : 0016-5492. DOI:10.1177/001654928303100301 . (visited on 05/22/2024).\n[18] J. Stackhouse, \u201cNarrowcasting: How Media and Political Disruption Changed the Economic Debate,\u201d\ninRe-Imagining Capitalism , D. Barton, D. Horv\u00e1th, and M. Kipping, Eds. Oxford University Press, Sep.\n2016, pp. 174\u2013190, ISBN : 978-0-19-878545-3. DOI:10.1093/acprof:oso/9780198785453.003.0013 .\n(visited on 05/27/2024).\n[19] N. Newman, R. Fletcher, K. Eddy, C. T. Robinson, and R. K. Nielsen, \u201cReuters Institute digital news\nreport 2023,\u201d Reuters Institute for the Study of Journalism, Tech. Rep., 2023. DOI:10.60625/RISJ-\nP6ES-HB13 . (visited on 02/28/2024).\n[20] Batya Friedman and Helen Nissenbaum, \u201cBias in computer systems,\u201d ACM Transactions on Information\nSystems , vol. 14, no. 3, pp. 330\u2013347, Jul. 1996, ISSN : 1046-8188. DOI:10.1145/230538.230561 . (visited\non 06/16/2024).\n[21] Philip Brey, \u201cDisclosive computer ethics,\u201d ACM SIGCAS Computers and Society , vol. 30, no. 4, pp. 10\u201316,\nDec. 2000, ISSN : 0095-2737. DOI:10.1145/572260.572264 . (visited on 06/16/2024).\n[22] H. Tavani and M. Zimmer, \u201cSearch Engines and Ethics,\u201d in The Stanford Encyclopedia of Philosophy ,\nE. N. Zalta, Ed., Fall 2020. Metaphysics Research Lab, Stanford University, Aug. 2020. (visited on\n05/31/2024).\n[23] Eric Ulken, \u201cA Question of Balance: Are Google News search results politically biased?\u201d Ph.D. disser-\ntation, USC Annenberg School for Communication, May 5.\n[24] Eric Ulken, Non-traditional sources cloud Google News results , May 2005. (visited on 05/27/2024).\n[25] J. D. Wright, Defining and Measuring Search Bias: Some Preliminary Evidence , SSRN Scholarly Paper,\nRochester, NY, Nov. 2011. (visited on 05/31/2024).\n17\n[26] J. Kulshrestha, M. Eslami, J. Messias, et al. , \u201cSearch bias quantification: Investigating political bias in\nsocial media and web search,\u201d Information Retrieval Journal , vol. 22, no. 1, pp. 188\u2013227, Apr. 2019, ISSN :\n1573-7659. DOI:10.1007/s10791-018-9341-2 . (visited on 05/31/2024).\n[27] M. J. Metzger, \u201cBroadcasting versus Narrowcasting: Do Mass Media Exist in the Twenty-First Century?\u201d\nInThe Oxford Handbook of Political Communication , K. Kenski and K. H. Jamieson, Eds. Oxford University\nPress, Aug. 2017, pp. 795\u2013808, ISBN : 978-0-19-979347-1. DOI:10.1093/oxfordhb/9780199793471.013.\n62_update_001 . (visited on 05/27/2024).\n[28] Matthew Shanahan and Kalvin Bahia, \u201cThe State of Mobile Internet Connectivity 2023,\u201d GSMA, Tech.\nRep., Oct. 2023.\n[29] M. Haim, A. Graefe, and H. -B. Brosius, \u201cBurst of the Filter Bubble?: Effects of personalization on the\ndiversity of Google News ,\u201dDigital Journalism , vol. 6, no. 3, pp. 330\u2013343, Mar. 2018, ISSN : 2167-0811,\n2167-082X. DOI:10.1080/21670811.2017.1338145 . (visited on 03/01/2024).\n[30] B. Nyhan, J. Settle, E. Thorson, et al. , \u201cLike-minded sources on Facebook are prevalent but not polariz-\ning,\u201d Nature , vol. 620, no. 7972, pp. 137\u2013144, Aug. 2023, ISSN : 1476-4687. DOI:10.1038/s41586-023-\n06297-w . (visited on 06/15/2024).\n[31] A. Ross Arguedas, C. T. Robertson, R. Fletcher, and R. K. Nielsen, \u201cEcho chambers, filter bubbles, and\npolarisation: A literature review,\u201d Reuters Institute for the Study of Journalism, Tech. Rep., 2022. DOI:\n10.60625/RISJ-ETXJ-7K60 . (visited on 06/15/2024).\n[32] M. Sato, Google confirms the leaked Search documents are real ,\nhttps://www.theverge.com/2024/5/29/24167407/google-search-algorithm-documents-leak-\nconfirmation, May 2024. (visited on 06/04/2024).\n[33] M. Sato, The biggest findings in the Google Search leak , https://www.theverge.com/2024/5/31/24167119/google-\nsearch-algorithm-documents-leak-seo-chrome-clicks, May 2024. (visited on 06/04/2024).\n[34] B. Pan, H. Hembrooke, T. Joachims, L. Lorigo, G. Gay, and L. Granka, \u201cIn Google We Trust: Users\u2019\nDecisions on Rank, Position, and Relevance,\u201d Journal of Computer-Mediated Communication , vol. 12,\nno. 3, pp. 801\u2013823, Apr. 2007, ISSN : 10836101, 10836101. DOI:10.1111/j.1083-6101.2007.00351.x .\n(visited on 05/20/2024).\n[35] R. Epstein and R. E. Robertson, \u201cThe search engine manipulation effect (SEME) and its possible\nimpact on the outcomes of elections,\u201d Proceedings of the National Academy of Sciences , vol. 112, no. 33,\nE4512\u2013E4521, Aug. 2015. DOI:10.1073/pnas.1419828112 . (visited on 01/12/2024).\n[36] Website Performance , https://pro.similarweb.com/#/digitalsuite/websiteanalysis/overview/website-\nperformance/*/999/1m?webSource=Total&key=google.com,nytimes.com,google.com.br, 2024. (vis-\nited on 05/22/2024).\n[37] A. Majid, \u201cTop 50 biggest news websites in the world: Newsweek doubles visits year-on-year in\nMarch,\u201d Press Gazette , Apr. 2024. (visited on 05/10/2024).\n[38] Charlotte Tobitt, \u201cGlobal news industry trends for 2024: Publishers optimistic on new revenue streams,\u201d\nPress Gazette , Jan. 2024. (visited on 05/29/2024).\n[39] Kristen Hare, Here\u2019s how the subscriber funnel, or whatever you want to call it, works , May 2018. (visited on\n05/29/2024).\n[40] R. K. Nielsen and A. G. Sarah, \u201c\"Our futures are tied together\": Platforms Dealing with Publishers,\u201d in\nThe Power of Platforms: Shaping Media and Society , R. K. Nielsen and S. A. Ganter, Eds. Oxford University\nPress, Jun. 2022, pp. 101\u2013156, ISBN : 978-0-19-090885-0. DOI:10.1093/oso/9780190908850.003.0004 .\n(visited on 06/15/2024).\n[41] R. K. Nielsen and A. G. Sarah, \u201cPlatform Power,\u201d in The Power of Platforms: Shaping Media and Society ,\nR. K. Nielsen and S. A. Ganter, Eds. Oxford University Press, Jun. 2022, pp. 157\u2013188, ISBN : 978-0-19-\n090885-0. DOI:10.1093/oso/9780190908850.003.0005 . (visited on 06/15/2024).\n18\n[42] News Equity Fund - Google News Initiative , https://newsinitiative.withgoogle.com/en-gb/news-equity-\nfund/, 2022. (visited on 05/29/2024).\n[43] Digital News Innovation Fund (DNI Fund) , https://newsinitiative.withgoogle.com//dnifund/. (visited\non 05/29/2024).\n[44] A. Munoriyarwa, M. -F. de-Lima-Santos, L. Mesquita, and A. A. Elega, \u201cThe philanthrocapitalism\nof Google News Initiative in Africa, Latin America, and the Middle East \u2013 Empirical reflections,\u201d\nInternational Journal of Cultural Studies , p. 13 678 779 241 265 734, Aug. 2024, ISSN : 1367-8779. DOI:\n10.1177/13678779241265734 . (visited on 09/10/2024).\n[45] \u201cRecommendations on Youtube: The case of Jovem Pan,\u201d Netlab UFRJ (Universidade Federal do Rio\nde Janeiro), Rio de Janeiro, Brazil, Tech. Rep., Sep. 2022. (visited on 05/26/2024).\n[46] N. Diakopoulos, J. Bandy, and H. Dambanemuya, Auditing Human-Machine Communication Systems\nUsing Simulated Humans , Aug. 2021.\n[47] Andreas Theodorou, \u201cThe best VPN service in 2024,\u201d TechRadar , May 2024. (visited on 05/30/2024).\n[48] Jack Neary, What\u2019s the lifespan of an article? Jun. 2023. (visited on 05/30/2024).\n[49] F. Gilardi, M. Alizadeh, and M. Kubli, \u201cChatGPT Outperforms Crowd-Workers for Text-Annotation\nTasks,\u201d Proceedings of the National Academy of Sciences , vol. 120, no. 30, e2305016120, Jul. 2023, ISSN : 0027-\n8424, 1091-6490. DOI:10.1073/pnas.2305016120 . arXiv: 2303.15056 [cs] . (visited on 11/11/2023).\n[50] N. Wongpakaran, T. Wongpakaran, D. Wedding, and K. L. Gwet, \u201cA comparison of Cohen\u2019s Kappa and\nGwet\u2019s AC1 when calculating inter-rater reliability coefficients: A study conducted with personality\ndisorder samples,\u201d BMC Medical Research Methodology , vol. 13, p. 61, Apr. 2013, ISSN : 1471-2288. DOI:\n10.1186/1471-2288-13-61 . (visited on 05/30/2024).\n[51] Left vs. Right Bias: How we rate the bias of media sources , https://mediabiasfactcheck.com/left-vs-right-\nbias-how-we-rate-the-bias-of-media-sources/, May 2021. (visited on 01/15/2024).\n[52] Predicting News Source Credibility , TTO Conference Ltd., Oct. 2019. DOI:10.36370/tto.2019.5 . (visited\non 01/15/2024).\n[53] \u201cNo evidence U.S. disease expert Fauci is \u2018prepping to flee country\u2019,\u201d Reuters , May 2021. (visited on\n01/15/2024).\n[54] P . Resnick, A. Ovadya, and G. Gilchrist, Iffy Quotient: A Platform Health Metric for Misinformation , Oct.\n2018.\n[55] R. Hernandes, LLMs left, right, and center: Assessing GPT\u2019s capabilities to label political bias from web domains ,\nJul. 2024. DOI:10.48550/arXiv.2407.14344 . arXiv: 2407.14344 [cs] . (visited on 09/10/2024).\n[56] H. Roberts, R. Bhargava, L. Valiukas, et al. ,Media Cloud: Massive Open Source Collection of Global News\non the Open Web , May 2021. arXiv: 2104.03702 [cs] . (visited on 03/31/2024).\n[57] FAQs , https://www.mediacloud.org/documentation/faqs, 2023. (visited on 03/30/2024).\n[58] Ranking Results \u2013 How Google Search Works , https://www.google.com/search/howsearchworks/how-\nsearch-works/ranking-results/. (visited on 06/01/2024).\n[59] Query Guide , https://www.mediacloud.org/documentation/query-guide, 2023. (visited on\n06/01/2024).\n[60] B. Clay, The Latest on Click-Through Rate by SERP Position , https://www.bruceclay.com/blog/the-latest-\non-click-through-rate-by-serp-position/, Aug. 2021. (visited on 06/07/2024).\n[61] M. G. Southern, Over 25% of People Click the First Google Search Result ,\nhttps://www.searchenginejournal.com/google-first-page-clicks/374516/, Jul. 2020. (visited\non 06/07/2024).\n19\n[62] W. Webber, A. Moffat, and J. Zobel, \u201cA similarity measure for indefinite rankings,\u201d ACM Transactions\non Information Systems , vol. 28, no. 4, pp. 1\u201338, Nov. 2010, ISSN : 1046-8188, 1558-2868. DOI:10.1145/\n1852102.1852106 . (visited on 06/07/2024).\n[63] J. Beus, Why (almost) everything you knew about Google CTR is no longer valid ,\nhttps://www.sistrix.com/blog/why-almost-everything-you-knew-about-google-ctr-is-no-longer-\nvalid/, Jul. 2020. (visited on 06/09/2024).\n[64] What is Open PageRank? https://www.domcop.com/openpagerank/what-is-openpagerank, Oct. 2023.\n(visited on 01/18/2024).\n[65] H. Lin, J. Lasser, S. Lewandowsky, et al. , \u201cHigh level of correspondence across different news domain\nquality rating sets,\u201d PNAS Nexus , vol. 2, no. 9, Sep. 2023, ISSN : 2752-6542. DOI:10.1093/pnasnexus/\npgad286 . (visited on 06/22/2024).\n[66] M. King, Secrets from the Algorithm: Google Search\u2019s Internal Engineering Documentation Has Leaked ,\nhttps://ipullrank.com/google-algo-leak, May 2024. (visited on 06/04/2024).\n[67] P . J\u00fcrgens and B. Stark, \u201cMapping Exposure Diversity: The Divergent Effects of Algorithmic Curation\non News Consumption,\u201d Journal of Communication , vol. 72, no. 3, pp. 322\u2013344, Jun. 2022, ISSN : 0021-9916,\n1460-2466. DOI:10.1093/joc/jqac009 . (visited on 02/28/2024).\n[68] L. M. Hinman, \u201cEsse est indicato in Google: Ethical and Political Issues in Search Engines,\u201d The\nInternational Review of Information Ethics , vol. 3, pp. 19\u201325, Jun. 2005, ISSN : 2563-5638. DOI:10.29173/\nirie345 . (visited on 06/07/2024).\n[69] Lucas D. Introna and Helen Nissenbaum, \u201cShaping the Web: Why the Politics of Search Engines\nMatters,\u201d The Information Society , vol. 16, no. 3, pp. 169\u2013185, Jul. 2000, ISSN : 0197-2243. DOI:10.1080/\n01972240050133634 . (visited on 06/16/2024).\n[70] A. Diaz, \u201cThrough the Google Goggles: Sociopolitical Bias in Search Engine Design,\u201d in Web Search:\nMultidisciplinary Perspectives , A. Spink and M. Zimmer, Eds. Berlin, Heidelberg: Springer, 2008, pp. 11\u2013\n34, ISBN : 978-3-540-75829-7. DOI:10.1007/978-3-540-75829-7_2 . (visited on 05/31/2024).\n[71] D. Lewandowski, Credibility in Web Search Engines , Aug. 2012. DOI:10.48550/arXiv.1208.1011 . arXiv:\n1208.1011 [cs] . (visited on 06/15/2024).\n[72] C. Tobitt, \u201cNational press ABCs: Circulation of the i above Sunday Express for first time,\u201d Press Gazette ,\nMay 2024. (visited on 06/12/2024).\n[73] J. Gordon, \u201cJohn Stuart Mill and the \"Marketplace of Ideas\",\u201d Social Theory and Practice , vol. 23, no. 2,\npp. 235\u2013249, 1997, ISSN : 0037-802X. JSTOR: 23559183 . (visited on 06/15/2024).\n[74] A. I. Goldman, \u201cSpeech Regulation and the Marketplace of Ideas,\u201d in Knowledge in a Social World . Oxford\nUniversity Press, 1999, pp. 189\u2013218, ISBN : 978-0-19-823820-1. DOI:10.1093/0198238207.003.0007 .\n[75] L. Herzog, \u201cWhat\u2019s Wrong with the \u201cMarketplace of Ideas\u201d?\u201d In Citizen Knowledge: Markets, Experts,\nand the Infrastructure of Democracy , L. Herzog, Ed. Oxford University Press, Oct. 2023, pp. 104\u2013121, ISBN :\n978-0-19-768171-8. DOI:10.1093/oso/9780197681718.003.0005 . (visited on 06/15/2024).\n[76] N. Helberger, \u201cOn the Democratic Role of News Recommenders,\u201d Digital Journalism , vol. 7, no. 8,\npp. 993\u20131012, Sep. 2019, ISSN : 2167-0811. DOI:10 . 1080 / 21670811 . 2019 . 1623700 . (visited on\n06/15/2024).\n[77] Mike Shields, \u201cFacebook\u2019s algorithm has wiped out a once flourishing digital publisher,\u201d Business\nInsider , Feb. 2018. (visited on 06/15/2024).\n[78] V . Elliott, \u201cFacebook Made BuzzFeed, Then Killed It,\u201d Wired , Apr. 2023, ISSN : 1059-1028. (visited on\n06/15/2024).\n20\n[79] P . M. Napoli, M. Weber, K. Mccollough, and Q. Wang, \u201cAssessing Local Journalism: News Deserts,\nJournalism Divides, and the Determinants of the Robustness of Local News,\u201d DeWitt Wallace Center\nfor Media & Democracy, Duke University, Tech. Rep., Aug. 2018.\n[80] S\u00e9rgio L\u00fcdtke and S\u00e9rgio Spagnuolo, \u201cBrasil tem redu\u00e7\u00e3o de 8,6% nos desertos de not\u00edcias em 2023,\nmas jornalismo local precisa de incentivo [Brazil sees an 8.6% reduction in news deserts in 2023,\nbut local journalism needs support],\u201d PROJOR, Volt Data Lab, Tech. Rep., Aug. 2023. (visited on\n06/15/2024).\n[81] Clare Mills, Michael Pidd, and Esther Ward, Eds., Analysing Big Cultural Data Patterns in 2200 Covers of\nVeja Magazine , Sheffield: The Digital Humanities Institute, 2012. (visited on 06/12/2024).\n[82] Fernanda Argolo, A woman out of place: Dilma Rousseff in Veja magazine , Mar. 2018. (visited on\n06/12/2024).\n[83] Hanna Yahya, \u201cRevistas em 2021: impresso cai 28%; digital retrai 21% [Magazines in 2021: print falls\n28%, digital drops 21%],\u201d Poder360 , Mar. 2022. (visited on 06/12/2024).\n[84] \u201cCom assinatura barata, jornais turbinam digital em 2023 [With low fees, newspapers boost subscrip-\ntions in 2023],\u201d Poder360 , Jan. 2024. (visited on 06/12/2024).\n[85] R. F. M. Gomes, \u201cBBC News Brasil: the reinvention of \u201csoft power\u201d in multiplatform journalism on\nthe threshold of the public interest and public interest\u2019s news,\u201d Ph.D. dissertation, Universidade do\nEstado do Rio de Janeiro, Rio de Janeiro, Brazil, Feb. 2021. (visited on 06/12/2024).\n[86] What is URL Canonicalization , https://developers.google.com/search/docs/crawling-\nindexing/canonicalization, Mar. 2024. (visited on 06/12/2024).\n[87] \u201cOECD Report on Public Communication: The Global Context and the Way Forward,\u201d OECD, OECD\nPublishing, Paris, Tech. Rep., Dec. 2021. DOI:10.1787/22f8031c-en . (visited on 06/16/2024).\n[88] O. Holmes and C. Michael, \u201cBaltimore bridge collapse: What we know about the bridge, ship and\nport,\u201d The Guardian , Mar. 2024, ISSN : 0261-3077. (visited on 06/13/2024).\n[89] Carmen Arroyo Nieto and Josep Valor, Google News changes its algorithm, and with it, the media industry ,\nOct. 2019. (visited on 06/15/2024).\n21\nAppendix\nA Terminology\nThe object of this analysis is a dedicated page for news content displayed in Google\u2019s search engine, or\nGOOGLE SEARCH . When looking for something on Google, users can access it by clicking \"News\" below the\nsearch box on the results page. That leads to another results page containing only news items. This analysis\nis concerned with the results from this page, here referred to as the NEWS TAB . This is not to be confused\nwith GOOGLE NEWS, a news aggregator (a platform that collects news from various sources) and a separate\nproduct with search functionalities.\nSearching for something in Google\u2019s engine may be called making a QUERY , and the words or phrases that\nare looked up are KEYWORDS . The keywords used when querying Google Search come from yet another\nproduct, GOOGLE TRENDS , an official service that lists what are the most popular search queries in a country\non a particular date. Every news article that appear in these count as a RESULT .\n22\nB Number of Outlets, Queries, and Results per news section\nTable 8: Number of outlets, queries, and URLs for each news section in each country. Total URLS (Once per query) ignores\nrepetition of results that appear more than once for the same query (as they were executed multiple times), but will\ncount it again if it also appears as a result for a different query.\nUnique Outlets Unique Queries Unique URLs Total URLs\nCountry News Section (once per query )\nBR Total 1226 866 18157 21058\nEntertainment 479 186 3588 3950\nOthers 768 180 3763 4292\nPolitics 260 51 1417 1466\nSports 579 449 9659 11350\nUK Total 1478 662 14150 16320\nEntertainment 624 213 4075 4415\nOthers 707 132 2738 3142\nPolitics 236 47 1108 1146\nSports 603 270 6532 7617\nUS Total 2189 770 19508 22906\nEntertainment 560 113 2725 3004\nOthers 1020 158 3657 4284\nPolitics 320 46 1224 1317\nSports 1306 453 12134 14301\n23\nC Most Popular Outlets per Country and News Section\nTable 9: Top 10 Outlets per Country and News Section\nCountry News Section Outlet Count\nBR Sports ge.globo.com 2855\nterra.com.br 1342\nlance.com.br 1331\ngazetaesportiva.com 1222\nespn.com.br 878\nuol.com.br 808\ncnnbrasil.com.br 732\ntrivela.com.br 635\nitatiaia.com.br 582\nnoataque.com.br 570\nOthers g1.globo.com 571\nterra.com.br 358\ncnnbrasil.com.br 287\ncorreiobraziliense.com.br 255\noglobo.globo.com 213\nnoticias.uol.com.br 200\ndiariodonordeste.verdesmares.com.br 196\nwww1.folha.uol.com.br 192\ninfomoney.com.br 177\nexame.com 176\nEntertainment terra.com.br 712\nuol.com.br 490\ncnnbrasil.com.br 479\ng1.globo.com 415\nmetropoles.com 411\ngshow.globo.com 358\nodia.ig.com.br 271\nestadao.com.br 230\nrevistaquem.globo.com 230\ndiariodonordeste.verdesmares.com.br 206\nPolitics cnnbrasil.com.br 234\ng1.globo.com 157\noglobo.globo.com 131\nterra.com.br 128\npoder360.com.br 126\nmetropoles.com 115\nwww1.folha.uol.com.br 108\ngauchazh.clicrbs.com.br 93\nestadao.com.br 91\noantagonista.com.br 87\nUK Sports bbc.co.uk 1372\nskysports.com 1000\nContinued on next page\n24\nTable 9 \u2013 continued from previous page\nCountry News Section Outlet Count\ntheguardian.com 850\ndailymail.co.uk 842\nmirror.co.uk 534\nindependent.co.uk 490\nthesun.co.uk 461\ntelegraph.co.uk 455\nbbc.com 378\nstandard.co.uk 349\nOthers bbc.co.uk 483\ntheguardian.com 353\ndailymail.co.uk 348\nindependent.co.uk 335\nnews.sky.com 245\ntelegraph.co.uk 194\nthesun.co.uk 152\nmirror.co.uk 135\ncnn.com 135\nbbc.com 132\nEntertainment dailymail.co.uk 1064\nindependent.co.uk 597\nmirror.co.uk 523\nbbc.co.uk 484\ntheguardian.com 471\nthesun.co.uk 445\nnews.sky.com 272\nexpress.co.uk 251\ntelegraph.co.uk 249\nhollywoodreporter.com 204\nPolitics theguardian.com 290\nbbc.co.uk 271\nnews.sky.com 182\nindependent.co.uk 172\ntelegraph.co.uk 163\nbbc.com 86\nthetimes.co.uk 74\ndailymail.co.uk 71\nft.com 69\nexpress.co.uk 62\nUS Sports espn.com 1624\ncbssports.com 1603\nsi.com 1219\nsports.yahoo.com 892\ntheathletic.com 790\nusatoday.com 658\nnypost.com 611\nContinued on next page\n25\nTable 9 \u2013 continued from previous page\nCountry News Section Outlet Count\nbleacherreport.com 517\nncaa.com 507\nfoxnews.com 398\nOthers usatoday.com 410\ncbsnews.com 305\ncnn.com 261\nnytimes.com 246\napnews.com 184\nnbcnews.com 174\nnypost.com 142\nbbc.com 137\nwashingtonpost.com 136\nfoxnews.com 128\nEntertainment people.com 483\nyahoo.com 240\nusatoday.com 192\nvariety.com 181\nhollywoodreporter.com 161\nnytimes.com 148\ndailymail.co.uk 141\nusmagazine.com 139\nfoxnews.com 136\nnypost.com 127\nPolitics cnn.com 169\nfoxnews.com 146\nnytimes.com 136\nnbcnews.com 120\nthehill.com 99\nwashingtonpost.com 96\napnews.com 92\npolitico.com 90\nmsnbc.com 82\nusatoday.com 81\n26\nD Concentration Ratio per country and news section\nTable 10: CR kshows the concentration of Top koutlets for each news section in Brazil, the UK, and the US.\nCountry News Section CR 4 CR 8 CR 10 Total Count Num News Sources\nBrazil Entertainment 0.197848 0.317727 0.358882 10594 479\nOthers 0.133545 0.206264 0.238311 11015 768\nPolitics 0.191854 0.322314 0.374852 3388 260\nSports 0.239974 0.348514 0.389470 28128 579\nUK Entertainment 0.219534 0.337941 0.375216 12153 624\nOthers 0.192011 0.283782 0.317533 7911 707\nPolitics 0.317488 0.454198 0.499653 2882 236\nSports 0.229955 0.339727 0.380863 17673 603\nUS Entertainment 0.155549 0.239143 0.276469 7046 560\nOthers 0.122200 0.185900 0.212300 10000 1020\nPolitics 0.193559 0.321356 0.376610 2950 320\nSports 0.176545 0.261741 0.291672 30236 1306\n27\nE Distribution of Outlets and Political Bias\nTable 11: Number of outlets per political classification per country. They go from -3 to +3, or far-left to far-right: far-left,\nleft, center-left, center, center-right, right, far-right. There is a column for unclassified sources. Brazil was excluded as it\ndid not have enough outlets tagged.\n-3 -2 -1 0 1 2 3 Uncl.\nCountry News Section\nBR Entertainment 1 33 21 12 56 6 0 3821\nOthers 0 42 41 57 85 13 0 4054\nPolitics 1 68 27 35 71 6 0 1258\nSports 1 21 151 1486 39 16 0 9636\nUK Entertainment 0 272 1450 588 306 774 0 1025\nOthers 0 118 933 692 272 355 0 772\nPolitics 1 53 430 270 128 159 0 105\nSports 0 96 1384 1773 407 950 0 3007\nUS Entertainment 0 445 1118 505 192 151 0 593\nOthers 0 203 1599 1271 438 153 0 620\nPolitics 0 182 617 236 130 92 1 59\nSports 1 206 3950 3983 714 411 0 5036\nTable 12: Amount of results that fall into each political bias category for both Media Cloud\u2019s and Google\u2019s results. These\ngo from \"far-left\" (-3) to far-right (3).\nBias Scale\nCategory -3 -2 -1 0 1 2 3 Unassigned\nUK\nM. Cloud 9 105 5607 1267 1529 5700 0 1803\n(0.06%) (0.66%) (35.00%) (7.91%) (9.54%) (35.58%) (0.00%) (11.25%)\nGoogle 2 1304 10674 8410 2789 5673 0 11767\n(0.00%) (3.21%) (26.28%) (20.70%) (6.87%) (13.97%) (0.00%) (28.97%)\nUS\nM. Cloud 0 1448 12848 10542 4516 696 0 3488\n(0.00%) (4.32%) (38.31%) (31.43%) (13.47%) (2.08%) (0.00%) (10.40%)\nGoogle 1 2627 16359 12552 3226 1839 1 13627\n(0.00%) (5.23%) (32.57%) (24.99%) (6.42%) (3.66%) (0.00%) (27.13%)\n28\nF Regression Tables for Popularity and Number of Results\nTable 13: Regression model considering all countries and only the Politics and Others sections. Model: OLS Method:\nLeast Squares No. Observations: 2507 R-squared: 0.070 Adj. R-squared: 0.070 F-statistic: 189.9 Prob (F-statistic): 1.08e-41\nLog-Likelihood: -13365 AIC: 2.673e+04 BIC: 2.675e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -56.8906 5.327 -10.679 0.000 (-67.337, -46.444)\nOpen PageRank 13.9703 1.014 13.779 0.000 (11.982, 15.958)\nTable 14: Regression model considering all countries and sections. Model: OLS Method: Least Squares No. Observations:\n4296 R-squared: 0.038 Adj. R-squared: 0.038 F-statistic: 169.1 Prob (F-statistic): 6.01e-38 Log-Likelihood: -27415 AIC:\n5.483e+04 BIC: 5.485e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -117.8682 11.844 -9.952 0.000 (-141.089, -94.648)\nOpen PageRank 30.0569 2.311 13.004 0.000 (25.525, 34.588)\nTable 15: Regression model for Brazil considering all sections. Model: OLS Method: Least Squares No. Observations:\n1226 R-squared: 0.058 Adj. R-squared: 0.057 F-statistic: 75.46 Prob (F-statistic): 1.17e-17 Log-Likelihood: -7994.3 AIC:\n1.599e+04 BIC: 1.600e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -144.6259 22.141 -6.532 0.000 (-188.064, -101.187)\nOpen PageRank 44.9787 5.178 8.687 0.000 (34.820, 55.137)\nTable 16: Regression model for the UK considering all sections. Model: OLS Method: Least Squares No. Observations:\n1478 R-squared: 0.057 Adj. R-squared: 0.056 F-statistic: 89.08 Prob (F-statistic): 1.42e-20 Log-Likelihood: -9310.9 AIC:\n1.863e+04 BIC: 1.864e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -200.5584 24.403 -8.219 0.000 (-248.426, -152.690)\nOpen PageRank 41.4653 4.393 9.438 0.000 (32.848, 50.083)\nTable 17: Regression model for the US considering all sections. Model: OLS Method: Least Squares No. Observations:\n2189 R-squared: 0.070 Adj. R-squared: 0.070 F-statistic: 164.5 Prob (F-statistic): 2.32e-36 Log-Likelihood: -12874 AIC:\n2.575e+04 BIC: 2.576e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -151.2867 13.710 -11.035 0.000 (-178.173, -124.400)\nOpen PageRank 32.0083 2.496 12.826 0.000 (27.114, 36.902)\n29\nG Regression Tables for Lin-PC1 and Number of Results\nTable 18: Lin-PC1\u2019s effect on the number of results, controlling for Open PageRank. Model: OLS Method: Least\nSquares No. Observations: 1262 R-squared: 0.139 Adj. R-squared: 0.138 F-statistic: 101.8 Prob (F-statistic): 1.03e-41\nLog-Likelihood: -8392.5 AIC: 1.679e+04 BIC: 1.681e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -475.2636 45.247 -10.504 0.000 (-564.031, -386.496)\nOpen PageRank 110.1783 7.741 14.232 0.000 (94.991, 125.366)\nLin-PC1 -142.9796 41.883 -3.414 0.001 (-225.149, -60.811)\nTable 19: Lin-PC1\u2019s relationship with Open PageRank scores. Model: OLS Method: Least Squares No. Observations:\n1262 R-squared: 0.096 Adj. R-squared: 0.095 F-statistic: 133.1 Prob (F-statistic): 2.41e-29 Log-Likelihood: -1305.6 AIC:\n2615 BIC: 2625.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant 4.5213 0.104 43.330 0.000 (4.317, 4.726)\nLin-PC1 1.6723 0.145 11.537 0.000 (1.388, 1.957)\nTable 20: Lin-PC1\u2019s direct effect on the number of results, showing no statistical significance ( p>0.05). Model: OLS\nMethod: Least Squares No. Observations: 1262 R-squared: 0.001 Adj. R-squared: -0.000 F-statistic: 0.9257 Prob (F-\nstatistic): 0.336 Log-Likelihood: -8486.6 AIC: 1.698e+04 BIC: 1.699e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant 22.8890 30.882 0.741 0.459 (-37.697, 83.475)\nLin-PC1 41.2762 42.900 0.962 0.336 (-42.887, 125.440)\n30\nH Regression Tables for Political Bias and Number of Results\nTable 21: Regression on the impact of political bias on the number of results an outlet might have, considering only\nresults in the Politics and Others sections and controlling for Open PageRank. Model: OLS Method: Least Squares No.\nObservations: 913 R-squared: 0.202 Adj. R-squared: 0.201 F-statistic: 115.4 Prob (F-statistic): 2.17e-45 Log-Likelihood:\n-5074.0 AIC: 1.015e+04 BIC: 1.017e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -253.2822 18.324 -13.823 0.000 (-289.244, -217.321)\nOpen PageRank 46.8546 3.092 15.155 0.000 (40.787, 52.922)\nBias Scale 2.0302 2.302 0.882 0.378 (-2.487, 6.547)\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant 6183.7364 192.830 32.068 0.000 (5805.732, 6561.740)\nbias_scale 86.4907 24.714 3.500 0.000 (38.044, 134.938)\nOpen PageRank -375.1311 27.856 -13.467 0.000 (-429.738, -320.524)\nTable 22: US: Regression on the ordered scale of political bias (far-left to far-right), where lower values relate to being\nmore positioned to the left. The model is run against the order of the results in Google, where lower means a more\nprominent position, and controlled for their Open PageRank score. It shows a significant relationship in which a higher\npolitical bias scale rating (more to the right) means appearing further down in Google\u2019s results (higher order). Model:\nOLS Method: Least Squares No. Observations: 7064 R-squared: 0.031 Adj. R-squared: 0.030 F-statistic: 111.7 Prob\n(F-statistic): 1.75e-48 Log-Likelihood: -63724 AIC: 1.275e+05 BIC: 1.275e+05.\nTable 23: UK: Analysis did not yield statistically relevant results. Regression on the ordered scale of political bias (far-left\nto far-right), where lower values relate to being more positioned to the left. The model is run against the order of the\nresults in Google, where lower means a more prominent position, and controlled for their Open PageRank score. This\nupdated analysis indicates a significant relationship where a higher political bias scale rating (more to the right) means\nappearing further down in Google\u2019s results (higher order). Model: OLS Method: Least Squares No. Observations:\n3982 R-squared: 0.051 Adj. R-squared: 0.051 F-statistic: 107.3 Prob (F-statistic): 4.13e-46 Log-Likelihood: -33595 AIC:\n6.720e+04 BIC: 6.722e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant 4141.4909 148.340 27.919 0.000 (3850.661, 4432.321)\nbias_scale -18.7711 15.840 -1.185 0.236 (-49.827, 12.285)\ndecimals -300.9091 20.641 -14.578 0.000 (-341.378, -260.441)\n31\nI Regression Tables for Article Age and Order\nTable 24: Overall: Regression on the impact of article recency (publish time in hours) and popularity (Open PageRank)\non weighted order. Model: OLS Method: Least Squares No. Observations: 132106 R-squared: 0.024 Adj. R-squared:\n0.024 F-statistic: 1612 Prob (F-statistic): 0.00 Log-Likelihood: -19339 AIC: 3.868e+04 BIC: 3.871e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -0.0137 0.004 -3.234 0.001 (-0.022, -0.005)\nOpen PageRank 0.0306 0.001 45.056 0.000 (0.029, 0.032)\nPublish Time (hours) -0.0020 6.41e-05 -30.711 0.000 (-0.002, -0.002)\nTable 25: Brazil: Regression on the impact of article recency (publish time in hours) and popularity (Open PageRank) on\nweighted order. Model: OLS Method: Least Squares No. Observations: 48581 R-squared: 0.020 Adj. R-squared: 0.020\nF-statistic: 488.4 Prob (F-statistic): 9.57e-211 Log-Likelihood: -7482.1 AIC: 1.497e+04 BIC: 1.500e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -0.0359 0.009 -4.092 0.000 (-0.053, -0.019)\nOpen PageRank 0.0405 0.002 24.220 0.000 (0.037, 0.044)\nPublish Time (hours) -0.0020 0.000 -18.391 0.000 (-0.002, -0.002)\nTable 26: UK: Regression on the impact of article recency (publish time in hours) and popularity (Open PageRank) on\nweighted order. Model: OLS Method: Least Squares No. Observations: 36167 R-squared: 0.065 Adj. R-squared: 0.065\nF-statistic: 1257 Prob (F-statistic): 0.00 Log-Likelihood: -5284.8 AIC: 1.058e+04 BIC: 1.060e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -0.2121 0.009 -23.518 0.000 (-0.230, -0.194)\nOpen PageRank 0.0603 0.001 45.347 0.000 (0.058, 0.063)\nPublish Time (hours) -0.0021 0.000 -17.551 0.000 (-0.002, -0.002)\nTable 27: US: Regression on the impact of article recency (publish time in hours) and popularity (Open PageRank) on\nweighted order. Model: OLS Method: Least Squares No. Observations: 47358 R-squared: 0.021 Adj. R-squared: 0.021\nF-statistic: 510.6 Prob (F-statistic): 4.04e-220 Log-Likelihood: -5892.6 AIC: 1.179e+04 BIC: 1.182e+04.\nVariable Coefficient Std. Error t P 95% Confidence Interval\nConstant -0.0421 0.008 -5.124 0.000 (-0.058, -0.026)\nOpen PageRank 0.0316 0.001 25.125 0.000 (0.029, 0.034)\nPublish Time (hours) -0.0018 0.000 -17.287 0.000 (-0.002, -0.002)\n32\nJ Regression Tables for Number of Texts in Media Cloud and Google Results\nJ.1 Overall Tables\nTable 28: Overall: Logistic regression on the impact of the number of texts in Media Cloud\u2019s database in the chances\nof appearing in Google\u2019s results for that same query. Model: Logit Method: MLE No. Observations: 15653 Pseudo\nR-squared: 0.05791 Log-Likelihood: -7457.4\nVariable Coefficient Std. Error z P [0.025, 0.975]\nNumber of Texts 0.0990 0.004 26.542 0.000 (0.092, 0.106)\nIntercept -1.8052 0.027 -67.798 0.000 (-1.857, -1.753)\nTable 29: Overall: Odds ratios, accuracy, and ROC AUC for the logistic regression model.\nMetric Value\nOdds Ratio (Number of Texts) 1.104062\nOdds Ratio (Intercept) 0.164449\nAccuracy 0.7989522775186865\nROC AUC 0.7210221926426942\nTable 30: Overall: Confusion Matrix for the logistic regression model.\nPredicted Negative Predicted Positive\nActual Negative 12258 204\nActual Positive 2943 248\n33\nJ.2 Country Specific Tables\nTable 31: Brazil: Logistic regression on the impact of the number of texts in Media Cloud\u2019s database in the chances\nof appearing in Google\u2019s results for that same query. Model: Logit Method: MLE No. Observations: 2585 Pseudo\nR-squared: 0.04149 Log-Likelihood: -1451.8\nVariable Coefficient Std. Error z P [0.025, 0.975]\nNumber of Texts 0.0617 0.006 9.787 0.000 (0.049, 0.074)\nIntercept -1.3116 0.056 -23.403 0.000 (-1.421, -1.202)\nTable 32: UK: Logistic regression on the impact of the number of texts in Media Cloud\u2019s database in the chances of\nappearing in Google\u2019s results for that same query. Model: Logit Method: MLE No. Observations: 3315 Pseudo R-squared:\n0.08451 Log-Likelihood: -1966.5\nVariable Coefficient Std. Error z P [0.025, 0.975]\nNumber of Texts 0.1429 0.009 15.919 0.000 (0.125, 0.160)\nIntercept -1.2944 0.056 -23.268 0.000 (-1.403, -1.185)\nTable 33: US: Logistic regression on the impact of the number of texts in Media Cloud\u2019s database in the chances of\nappearing in Google\u2019s results for that same query. Model: Logit Method: MLE No. Observations: 9753 Pseudo R-squared:\n0.04428 Log-Likelihood: -3700.4\nVariable Coefficient Std. Error z P [0.025, 0.975]\nNumber of Texts 0.0881 0.005 17.430 0.000 (0.078, 0.098)\nIntercept -2.2131 0.038 -58.750 0.000 (-2.287, -2.139)\n34\nK Validation Dataset Description and Analysis\nAn additional dataset with information for 12 additional days, between April 29th2024 and May 11th2024,\nwas collected to validate some of the findings of the main analysis. These include the patterns in source\nconcentration and recency, as these do not involve collecting additional data besides that gathered from\nGoogle\u2019s systems. Overall, the results are quite similar to the data collected originally, providing additional\nevidence that the findings in this investigation generalize. The data collection used the exact same Python\nscripts and AWS machine used for the main analysis.\nK.1 Dataset Description\nThe additional dataset had a total of a total of 1,228 keywords , rendering a total of 77,887 results . These\naccount for 28,967 unique URLs from 2,987 outlets .\nTable 34: Number of outlets, queries, and URLs for each country;Total URLS (Once per query) ignores repetition of\nresults that appear more than once for the same query (as they were executed multiple times), but will count again if it\nalso appears as a result for a different query.\nUnique Outlets Unique Queries Unique URLs Total URLs\nCountry (once per query )\nBR 896 474 10165 11567\nUK 1003 332 8662 10036\nUS 1522 422 11029 12987\nK.2 Concentration\nSimilarly to the main dataset, the validation data showed low average HHI, 0.09 , and Gini 0.33 , when\nconsidering individual queries. Considering the data horizontally (across multiple queries), the same pattern\nof concentration is seen. The low HHI, 0.005 , and high Gini, 0.799 , again indicate the behavior of a select\nfew outlets dominating the results, while the vast majority compete for similar small shares.\nThis translates into 2.85% of the outlets accounting for 50% of the results, or 1.1% if considering their\nweighted rankings. That concentration is also shown by the Kolmogorov-Smirnov statistic ( D=0.894 ,\np<0.001) and the CR kvalues in tables 35 and 36.\nTable 35: CR kshows the concentration of Top koutlets for each country.\nCountry CR 4 CR 8 CR 10 Results News Sources\nBR 0.175155 0.273110 0.306538 29197 896\nUK 0.200280 0.303560 0.346698 20701 1003\nUS 0.098789 0.169602 0.200222 27989 1522\nTable 36: CRkshows the concentration of Top koutlets for each country, considering the weighted score for each entry.\nThis places more emphasis on records the higher they appear on the results page.\nCountry CR 4 CR 8 CR 10 Results News Sources\nBR 0.324691 0.649142 0.810528 29197 896\nUK 0.320757 0.641515 0.800638 20701 1003\nUS 0.301547 0.603094 0.752831 27989 1522\n35\nK.3 Variation and Recency\nThe same patterns of gradually updating the results found in the original analysis were spotted in the\nvalidation dataset, seen in Jaccard Index and RBO values being lower between first and last iterations than\nthey are between sequential ones. The progression in average article age suggests that content is being\nreplaced for morue recent texts. If that was not the case, they should increase at an average rate of three\nhours, which was the time interval between collections.\nTable 37: Descriptive statistics of the Jaccard Index and RBO comparing first iteration to last.\nStatistic Count Mean Std. Deviation Minimum Maximum\nJaccard 1228 0.469 0.192 0.000 1.000\nRBO 1228 0.286 0.357 0.000 0.999\nTable 38: Average Jaccard, RBO, and time difference between article publishing and data collection (Article Age) over\ndifferent iterations. Jaccard and RBO scores represent a comparison with the iteration that came immediately before. The\nmean variations in the columns were tested using ANOVA. They are all statistically significant (Jaccard: p<0.001 , RBO:\np<0.05)\nScraping Iteration Avg. Jaccard Avg. RBO Avg. Article Age (Hours)\n1 13.44\n2 0.49 0.51 14.49\n3 0.51 0.52 15.40\n4 0.53 0.54 16.56\n5 0.54 0.56 17.10\n36", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Auditing Google's Search Algorithm: Measuring News Diversity Across Brazil, the UK, and the US", "author": ["R Hernandes", "G Corsi"], "pub_year": "2024", "venue": "arXiv preprint arXiv:2410.23842", "abstract": "This study examines the influence of Google's search algorithm on news diversity by  analyzing search results in Brazil, the UK, and the US. It explores how Google's system"}, "filled": false, "gsrank": 358, "pub_url": "https://arxiv.org/abs/2410.23842", "author_id": ["arCHs-gAAAAJ", "35CMl_YAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:MjgzVWsNo9UJ:scholar.google.com/&output=cite&scirp=357&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=MjgzVWsNo9UJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 2, "citedby_url": "/scholar?cites=15394162705924569138&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:MjgzVWsNo9UJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2410.23842"}}, {"title": "Supplemental Information for Weaving it in: How Partisan Media React to Events", "year": "2022", "pdf_data": "Supplemental Information for Weaving it in: How\nPartisan Media React to Events\nClara Vandeweerdt\nJuly 19, 2022\n1\nContents\n1 Radio recordings and transcripts 3\n2 Ascribing mentions to shows 5\n3 Mechanical Turk coding task 6\n4 Google trends and topic mentions 8\n5 Classifying radio shows 10\n6 Modeling mention proportions and counts 13\n7 Regression tables 14\n8 Counting non-neutral mentions of immigration 17\n9 Long-term e\u000bects: agenda half-lives 17\n10 Robustness checks 19\n10.1 News and public radio shows . . . . . . . . . . . . . . . . . . . . 19\n10.2 Show classi\fcation thresholds . . . . . . . . . . . . . . . . . . . . 20\n2\n1 Radio recordings and transcripts\nRecording of radio stations was an automated process, starting with scraping\nthe publicly available audio streaming URLs of US terrestrial radio stations from\nthe website Radio-Locator.com. The audio from these URLs was ingested and\nsaved in 5-10 minute chunks on Amazon S3. Next, the audio was automatically\ntranscribed using a custom speech-to-text model, based on an model entered in\nthe IARPA ASpIRE challenge by Peddinti et al. (2015). The speech transcrip-\ntion algorithm was gradually improved in the course of data collection, with the\nerror rate going from 27% in April 2018 to 13% in November 2018, and staying\nstable since. This error rate was measured using existing transcripts from NPR\nand Rush Limbaugh.\nBeeferman et al. (2019) describe the features of (a subset of) this data\nset in more detail. This data subset is available for download at https://\ngithub:com/social-machines/RadioTalk , and the data collection team can\nbe contacted for further technical documentation and code sharing requests at\nhttps://socialmachines :org/ .\nRecording started in May 2018, with 72 stations. The number of stations fol-\nlowed increased from there, reaching 175 in August 2018. The number dropped\nto 155 in March 2019 and remained there until the end of the period analyzed\n(October 2019). Figure 1 illustrates the number of stations in the data set over\ntime. Of the initial stations, 50 were chosen randomly from the population of\nUS talk radio stations, and more stations were added and dropped from the data\nset in the course of the next few months according to the interests of the team at\nthe Laboratory for Social Machines. The total number of US terrestrial talk sta-\ntions (with registered formats Business News, News/Talk, Public Radio, News,\nCollege, Talk) in the covered period was 1897, according Radio-Locator.com.\nFigure 2 shows where in the United States the transcribed stations are lo-\ncated. Table 1 describes the distributions of these stations in terms of content\nand station subtype, compared to the population of all talk radio stations. Un-\nderrepresented station types include stations from the Midwest, college stations\n(which unlike the two college stations included in this data set typically air\nmore music than talk content), and public radio stations. Underrepresentation\n050100150200\nJul 2018 Oct 2018 Jan 2019 Apr 2019 Jul 2019 Oct 2019count\nFigure 1: Number of talk radio stations in data set over time.\n3\nof public stations is not likely to be consequential for the \fnal sample of shows.\nThis is because many public radio stations broadcast the same set of shows,\nproduced for nation-wide broadcasting by public radio networks such as NPR.\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\nFigure 2: Locations of the continental radio stations in the data set. Two more\nstations are in Alaska, and one is on Hawaii.\nSample % Population % t-test p-value\nregion: Midwest 16 28 0.00\nregion: Northeast 22 16 0.04\nregion: South 33 30 0.35\nregion: West 29 27 0.46\nformat: Business News 0 1 0.09\nformat: College 2 13 0.00\nformat: News 2 2 0.91\nformat: News/Talk 49 27 0.00\nformat: Public Radio 32 45 0.00\nformat: Talk 15 12 0.18\nTable 1: Balance table comparing region and format for radio stations in the\nsample to the population of US talk radio stations.\nThe number of distinct radio shows broadcast by these stations added up to\n675 by June 2018, and over 1000 by August. Figure 3 shows the total number\nof shows captured in each week of the observed period.\n4\n02505007501000\nApr 2018 Jul 2018 Oct 2018 Jan 2019 Apr 2019 Jul 2019 Oct 2019countFigure 3: Total number of shows recorded, by week.\n2 Ascribing mentions to shows\nIn principle, ascribing a topic mention to a show should be easy. A topic term\ncounts as being part of a show if it was mentioned on a radio station, during a\ntime slot when we know that show is being broadcast on that station. There\nare two issues with that approach, however. First, the speech-to-text algorithm\ncreating the transcriptions is not perfect. Some topic term mentions are missed,\nwhereas others are false positives. Second, radio schedule data (which show is\non when) was pooled from a range of sources, some more reliable than others.\nAn hour of audio coming from a particular station could have the wrong show\nlabel if there is no correct, up-to-date schedule for the station.\nBoth problems can be remedied when there is more than one airing of a show\nepisode|that is, when the show is broadcast on more than one of the stations\nthat were recorded that day. I followed the procedure below to decide which\ntopic mentions should be ascribed to each show.\n1. For each topic mention, create a \\slice\" of content that includes up to\nten words coming before and after the topic term. For example: \\years\nfrom now, \ffty years, there isn't any evidence of climate change\" (aired\non KBTK, April 25th 2018).\n2. In the entire set of transcripts coming from a particular day, search for\nclusters of similar mentions (low string distance).\n3. For each cluster, do the following:\n(a) Take all mentions in the cluster, and check which show labels they\nhave, based on station scheduling data. For example, the \frst men-\ntion above comes from audio labeled as The Glenn Beck Program,\nbut it is in a cluster together with \fve (very similar) mentions that\nare all labeled as being part of the Rush Limbaugh Show.\n(b) For each of the shows that occur at least once as show labels in\nthe cluster, calculate con\fdence that it is the correct show label for\nthis cluster of mentions. Calculations take into account how many\n5\nmentions in the cluster have this show label, and also how many times\neach show was aired on di\u000berent stations that day, without containing\na similar mention.\n(c) Compare the show label likelihoods, and choose the one with the\nhighest con\fdence. For example, the mention cluster above was as-\ncribed to The Rush Limbaugh Show with a con\fdence of :6. This\nrelatively low con\fdence mostly comes from the fact that there are\nmany airings, labeled in the scheduling data as broadcasts of The\nRush Limbaugh Show on April 25th 2018, that did not include any\nmentions with a content slice similar to this one.\n4. Treat each cluster, with its most likely show label, as a single unique\nmention that happened on that show|but only if its show label con\fdence\nis greater than .5. Otherwise, discard the cluster.\n3 Mechanical Turk coding task\nEach time one of the political topics was mentioned, its ideological frame was\ncoded by workers on Amazon's crowdsourcing platform, Mechanical Turk. Work-\ners were allowed to code as many mentions as they wanted, for a payment of\n$0.14 per mention.\nCoders listened to short audio fragments surrounding each mention, so that\nthe ratings are based on vocal as well are verbal cues. We know from previous\nwork that tone of voice confers unique information (Dietrich et al., 2019). Audio\nfragments started 10 seconds before the topic keyword (e.g. \\global warming\")\nwas said, and ended 20 seconds after. Next, the coder was asked to choose\nbetween two frames (e.g., \\skeptical\" or \\convinced\" about climate change), or\nneither frame.\nIn the case of climate change, for 71% of mentions, the \frst two coders\nagreed on the classi\fcation. In another 25% of the cases, a third coder broke\nthe tie, and I used the majority opinion as the code for that mention. In the\n\fnal 4%, all three coders disagreed, and I labeled the fragment \\neither\". In\nthe case of gun policy, the distribution was: 61% two-coder agreement; 32%\ntwo-out-of three majority; 6% no agreement. Immigration fragments were the\nmost di\u000ecult to code: the percentages were 54%, 37%, and 9%.\nFor all three topics, it was rare for two coders to assign opposite frames to\nthe same fragment. In the case of climate change, only 7% of mentions were\nassigned one frame (skeptical or concerned), even though one of the coders\nsuggested the opposite frame. In the cases of gun control and immigration, this\nwas 9% and 8%. In other words, coding disagreements are unlikely to have\nresulted in mentions being assigned the wrong slant. They would, however,\nhave caused some neutral topic mentions to be incorrectly coded as employing\na frame, and vice versa.\nRight next to the audio player, coders always saw the following brief instruc-\ntions on their screen:\nClimate:\n\u0088Skeptical: climate change evidence is false or unclear, climate change is\nnot an important problem, it is too costly to \fght against climate change.\n6\n\u0088Concerned: climate change evidence is solid, climate change caused by\nhumans, it is a threat and we need action.\n\u0088Neutral: no clear opinion about climate change, and no mention of evi-\ndence for or against climate change.\nGun policy:\n\u0088Pro-gun: right to own guns, looser gun control laws, guns protect people,\nsecond amendment\n\u0088Anti-gun: stricter gun control laws, guns cause violence/mass shootings\n\u0088Neither: no opinion about gun rights/ gun control, no hints whether the\nspeaker is pro- or anti-gun.\nImmigration:\n\u0088Supporting immigration: we don't need a wall or more deportations, fam-\nilies should stay together, immigration is good for our country\n\u0088Tough on immigration: border needs protection, illegal immigration should\nbe stopped, immigration is bad for our country\n\u0088Neither: just news, no opinion about immigration, no hints whether the\nspeaker is supportive or tough.\nFinally, coders were encouraged to click through to the longer instructions\n(\\code book\") if they were doing the task for the \frst time, or had not done the\ntask in the past day. The sections below contain the descriptions of each issue\nframe from those instructions. Instructions received minor changes during the\ncoding process, in order to account for common mistakes.\nClimate, Skeptical - The evidence for climate change is false or not certain;\npredictions did not come true. Scientists are hiding evidence against global\nwarming. The climate is always changing. Humans did not cause global warm-\ning. Problems we see today (e.g. wild\fres) are not caused by climate change.\nEven if global warming exists, the e\u000bects are not so bad, or they are positive.\nClimate change is not important compared to other problems. It is too expen-\nsive or risky to take action, it would cost too many jobs, it is too soon to take\naction, it is not our responsibility.\nClimate, Concerned - The evidence for climate change is clear. Humans and\ntheir greenhouse gas (CO 2) emissions cause global warming. Climate change\nwill have negative e\u000bects (e.g. sea levels rising, plants or animals dying) now or\nlater. Problems we see today (e.g. storms, droughts) are due to global warming.\nWe need to act on it (e.g. by using less energy or clean energy). People who are\nlooking for solutions or who are passing climate laws are doing the right thing.\nGun policy, Pro-gun - People have the right to own guns, protected by the\nsecond amendment. The government should not take our guns away. There\nshould be fewer laws and rules about owning or buying guns and ammo (e.g.\nbullets). Gun control does not prevent crimes. People who own guns prevent\n7\ncrimes from happening, because they can defend themselves, their family, and\nothers. People need guns to protect themselves if the government turns against\nthe citizens. Mass shootings are a mental health problem. The US does not\nhave more gun violence because it has more guns.\nGun policy, Anti-gun - There should be stricter rules about who can own\nand buy guns. People who want to buy a gun should have to pass a background\ncheck or get a license. Some types of guns, like assault ri\res, should be banned.\nWe need stronger measures to prevent teenagers, or people with mental health\nproblems from having guns. The United States has more gun violence than\nother countries because it has more guns. Mass shootings would happen less\noften if it was harder to get a gun.\nImmigration, supportive - There should not be a wall on the border with\nMexico, and we should deport fewer people. Unauthorized immigrants are often\nrunning from violence in their home country. They should be treated well and\nfamilies should stay together. The rules for legal immigration should not be\nmade stricter. People who were brought into the country as children should\nbe allowed to stay. Immigrants are hard-working, and they contribute to our\nsociety. America is a nation of immigrants.\nImmigration, tough - We should invest more money and manpower into pro-\ntecting the border and deporting unauthorized immigrants. If immigrants come\nor stay here illegally, they broke the law. Immigrants raise crime rates, they\ndo not pay taxes and should not get government help. We also need stricter\npolicies on legal immigration. Many immigrants don't speak English well, don't\nadopt American culture, or take jobs from Americans. American-born citizens\nshould come \frst.\nIn the code books, coders were encouraged to classify mentions as \\neither\"\nif there was not enough context to classify them, if they did not fall into any\nof the other categories, or if the audio fragment was not about the topic. For\nexample, a piece of news (with no negative or positive tone) about a climate law\nthat was passed, or a commercial about climate-proo\fng your windows. How-\never, the code books also explained that topic mentions can support ideological\nframes even if the speaker is not giving their own opinion. For example, a news\nitem about new evidence for (or against) climate change would still count as\nconcerned (or skeptical) and not neutral, because its e\u000bect could be to make a\nlistener more concerned (or skeptical).\n4 Google trends and topic mentions\nTo de\fne \\pre-event\" and \\post-event\" weeks, I use Google Trends data. This\ndata comes in the form of a day-by-day index of the number of Internet searches\nfor a search term describing the event (e.g., \\hurricane Florence\" or \\hurricane\nMichael\"). On each day, I compare search activity to the peak-activity day for\nthat event. By my de\fnition, pre-event weeks end on the last day where search\nactivity was less than 5% compared to the peak. Post-event weeks start on the\n9\n\u25cf\u25cf\nFlorence landfallMichael\n landfall\n0100200300400500\n02505007501000\nAug Sep Oct NovMentions of climate changeRadio shows recorded\n\u25cf\u25cf\n\u25cf\u25cfSanta Fe High SchoolJacksonville Landing\nPittsburgh Synagogue\nThousand Oaks\n0100200300\n02505007501000\nApr Jul OctMentions of gun policyRadio shows recorded\n\u25cf\u25cf\nFamily separation\nannouncedExecutive order\n010002000\n0200400600\nApr May Jun JulMentions of immigrationRadio shows recorded\nFigure 4: Daily number of talk radio mentions of climate, gun policy and immi-\ngration, with signi\fcant events. Bands show the pre- (orange) and post- (brown)\nevent weeks as de\fned by Google Trends. Mention trends smoothed using Loess\nregression, allowing for discontinuities at the beginning of each post-event week.\nLight gray lines show the number of talk radio shows recorded on each date.\n\frst day where search activity was at least 20% compared to the peak.\nFigure 4 shows these periods, along with the number of topic mentions per\nday on all talk radio shows.1While these decision rules do not always line\nup perfectly with the \\before\" and \\after\" of talk radio attention, they do a\nreasonable job of capturing the baseline and the peak. The \\pre-event\" weeks\nalso appear to be acceptable baselines, even though no week is ever completely\nfree of (at least local) events that are relevant to these political topics.\n5 Classifying radio shows\nTable 2 contains all non-political shows that I used to train the political/non-\npolitical classi\fer. Table 3 lists all political shows, with two or more sources\nbacking its ideological label. A source is considered to con\frm an ideological\nlabel if it names the program, its host, or another closely associated entity as\neither \\conservative\" or \\right-wing\"; or as \\liberal\", \\left-wing\" or \\progres-\nsive\".\nRequiring more than one source hedges against the possible ideological bias\nin ideological bias judgments themselves. For example, the Center for American\nProgress is itself classi\fed as left-wing by the Media Bias/Fact Check group.\nHowever, I never came across two sources that contradicted each other in their\njudgments of any given show's bias; when two sources existed, they always\nagreed.\nTwo NPR programs (All Things Considered and Morning Edition) were\nleft out of the ideology model's training set for the main analyses, despite the\nfact that several sources labeled NPR as liberal. Section 10.1 below provides a\nrobustness check that includes these NPR shows in the training set.\nIn total, the labeled shows had almost 8500 episodes, of which almost 5800\nwere political. Before training the model on these shows, I held out 10% of\neach show's episodes, to be used for model testing. To transform the show\ntranscripts into data, I counted and normalized the number of occurrences of\n5000 tokenized word pairs in each transcript. In other words, the features\nfed to the model are term frequency{inverse document frequency (TF-IDF)\nvectors for 5000 tokenized bigrams. I left out any features whose TF-IDF score\nwas correlated too strongly with any particular show label|for example, hosts'\nverbal tics, their names or show sponsors.\nExisting literature on categorical ideology classi\fcation at the phrase (Iyyer\net al., 2014) or document (Yan et al., 2017) level suggests that regularized logistic\nregression (LR) works well with this amount of data. I tried both LR (with L2\nregularization) and Support-Vector Machines (SVMs). I decided between these\ntwo models, and tuned both the show-speci\fc feature correlation threshold and\nthe shrinkage parameter c, via blocked k-fold cross-validation. That is, I left\nout all episodes from the same show at once, and then tried to predict their\nlabel with a model trained on the other shows. LR slightly outperformed SVM\nfor the political/non-political classi\fer, and SVM slightly outperformed LR for\nthe ideology classi\fer.\nOnce tuned, I tested the \fnal models' performance by using them to label\nthe hold-out episodes of each show, which were all completely new to the model.\n1These are unique mentions, not double-counting mentions on radio shows that are broad-\ncast on more than one station. See section 2 for more on this.\n10\nShow Topic\nFood Friday Vox Pop food\nWMT Cooking Show food\nBetter Lawns and Gardens gardening\nClassic Gardens and Landscape gardening\nGardenLine w/ Randy Lemmon gardening\nDr. Bob Martin health\nPurity Products health\nYour Health with Dr. Joe Galati health\nAt Home with Gary Sullivan home\nHouse Talk with Ray Trimble home\nSturdy Home Improvement home\nTexas Home Improvement home\nHandel on the Law legal\nThe Legal Exchange legal\nYour Legal Rights legal\nFinancial Advisors with Aubrey Morrow money advice\nMoney Matters with Ken Moraif money advice\nThe Dave Ramsey Show money advice\nThe Financial Exchange money advice\nAfropop Worldwide music\nAfternoon Jazz music\nClassic Jazz with Michele Robins music\nClassical 24 with Andrea Blain music\nClassical 24 with Bob Christiansen music\nHomegrown Music music\nJesus Christ Show (PRN) religious\nLutheran Hour religious\nSt. John's Lutheran Church religious\nBen Maller sports\nBuckey Sportsman with Dan Armitage sports\nFOX Sports Radio sports\nFox Sports Weekends sports\nThe Big Sports Show sports\nTable 2: Non-political shows in training set, with their hand-coded topic.\nFor each show, when trying to classify its hold-out episodes, I trained a model\non all other shows. This way, I avoided rewarding the model for making predic-\ntions based on show-speci\fc features. The political/non-political LR correctly\nclassi\fed all 50 shows based on their hold-out episodes. The conservative/liberal\nSVM successfully classi\fed 14 out of 15 political shows. After tuning and test-\ning, I trained the classi\fers on the full labeled data sets (training and hold-out).\nFinally, I applied the political/non-political classi\fer to all 1005 recorded shows,\nand the ideology classi\fer to the 429 shows that were labeled as political.\nThere are a few reasons to treat show ideology as binary, rather than contin-\nuous. First, existing evidence suggests that radio shows are ideologically sorted,\nsuggesting that it is reasonable to divide shows into a liberal and a conservative\ngroup. Second, having two ideology categories is a common choice in studies of\n11\nConservative\nShow Sources\nBen Shapiro Media bias/fact check (as The Daily Wire), Politi-\nfact, Wikipedia\nGlenn Beck CAP, Pew, Wikipedia\nHugh Hewitt CAP, Media bias/fact check (as Salem Radio Net-\nwork News), Wikipedia\nJoe Pags CAP, Wikipedia\nLaura Ingraham CAP, Politifact, Wikipedia\nMark Levin CAP, Media bias/fact check (as Conservative Re-\nview)\nMike Gallagher CAP, Wikipedia\nRush Limbaugh CAP, Pew, Politifact, Wikipedia\nSean Hannity CAP, Pew, Politifact, Wikipedia\nThe Savage Nation CAP, Politifact, Wikipedia\nLiberal\nShow Sources\nDemocracy Now! Media bias/fact check, Wikipedia\nMike Malloy CAP, Wikipedia, Liberal Talk Radio Wiki\nRing of Fire Radio Media bias/fact check, Wikipedia\nStephanie Miller Media bias/fact check (as Fstv), Politifact,\nWikipedia, Liberal Talk Radio Wiki\nThom Hartmann CAP, Media bias/fact check (as Fstv), Politifact,\nWikipedia, Liberal Talk Radio Wiki\nNPR\nShow Sources\nAll Things Considered Media bias/fact check (as NPR), Pew (as NPR)\nMorning Edition Media bias/fact check (as NPR), Pew (as NPR)\nTable 3: Political shows in training set, with their ideology label and\nsources. Sources: CAP (Center for American Progress and Free Press,\nThe Structural Imbalance of Talk Radio, 2007, ampr.gs/2UegLbP); Lib-\neral Talk Radio Wiki (ltradio.fandom.com/wiki/List ofpersonalities);\nMedia bias/fact check (mediabiasfactcheck.com); Pew Research Cen-\nter (journalism.org/interactives/media-polarization); Politifact (politi-\nfact.com/personalities/); Wikipedia (wikipedia.com). The entity labeled\nby the source is in parentheses, if it is something other than the show or its\nhost.\ntalk radio (cf. Yanovitzky and Cappella 2001; Sobieraj and Berry 2011; Cen-\nter for American Progress and Free Press 2007; Jamieson and Cappella 2008,\np. 86). The classi\fcation results support this|most political shows can be\nclassi\fed with fairly high con\fdence as either liberal or conservative, suggesting\nit is not as important for a model to cover the ideological \\middle ground\".\nFinally, the training data can be reliably classi\fed into two ideological bins.\nSources that designate radio shows as right- or left-leaning usually give cate-\ngorical labels. Ratings on a spectrum would be more debatable. In a study on\n12\nTV news, Martin and Yurukoglu (2017) solved this by training a classi\fer on\nCongressional speech, with continuous DW-NOMINATE scores as the ideology\noutcome variable. I found that a domain-adapted binary classi\fer trained on\nspeeches in the 114th Congress misclassi\fed 3 out of 17 political training shows.\nSwitching to a Congress-based model could thus lead to a signi\fcant drop in\nprediction quality.\n6 Modeling mention proportions and counts\nFor each week on each radio show, there are two relevant outcomes: the number\nof mentions of a topic; and the proportion of mentions that feature a particular\nframing of the topic.\nThe number of mentions of each topic across shows-weeks has a very skewed,\noverdispersed distribution. As a result, a linear model of mention counts would\nhave large uncertainty around its coe\u000ecients. Moreover, conclusions would be\nheavily dominated by a handful of shows that have far more mentions than the\nothers. Instead, I use a negative binomial model.\nThe full model, which tells us about the di\u000berential e\u000bect of events on shows\nwith di\u000berent ideologies, is:\nE[Ycount\ni ] =exp(\f0+\f1posti+\f2liberali+\f3posti\u0002liberali+\f4minutesi)\nwhereYcount\ni is the number of topic mentions in show-week i. It has a\nnegative binomial distribution. postiindicates whether the show-week happened\npre-event (0) or post-event (1). liberaliindicates whether the show was classi\fed\nas conservative (0) or liberal (1). minutesiis the show's airtime in minutes per\nweek. I control for total airtime because shows with more content naturally\nhave more opportunities to mention a topic.\nTo model frame proportions, I use a so-called fractional logit model (Papke\nand Wooldridge, 1996).2The full model is:\nE[Yprop\ni] =logit\u00001(\f0+\f1posti+\f2liberali+\f3posti\u0002liberali)\nwhereYprop\ni is the fraction of topic mentions on in show-week ithat use\na particular frame (e.g. climate skepticism). This is the proportion among\nmentions with an ideological frame, leaving out mentions coded as \\neither\". It\nhas a quasi-binomial distribution. In both models, standard errors are clustered\nat the show level.\nThe key quantities of interest, which are reported in the main text, are\npredicted mention counts and predicted frame proportions before and after an\nevent. The p-values accompanying these predictions in the main text refer to\nthe relevant (combinations of) model coe\u000ecients. For instance, ^\f1represents\nthe estimated change in topic mentions (or frames) from pre- to post-event for\na conservative show. ^\f1+^\f3represents the change for a liberal show. ^\f2is the\n2This is a generalized linear model with a logit link function and a quasi-binomial probabil-\nity mass function for the outcome. Using a quasi-binomial distribution instead of a binomial\none does not change the estimates but gives us more robust standard errors (Papke, ND).\n13\nestimated di\u000berence between liberal and conservative shows before an event, and\n^\f3captures how the event di\u000berentially a\u000bects liberal and conservative shows.\nIn order to calculate con\fdence intervals for the predicted quantities (as seen\nin main text Figures 2 and 3), I use a non-parametric block bootstrap technique\n(Cameron et al., 2008) with percentile con\fdence intervals. In each iteration of\nthe bootstrap, I sample shows with replacement, extracting the same number\nof shows as there are in the original data set. For each sampled show, I include\nall of its observations (show-weeks) in a new simulated data set. I then run the\nmodels above on the simulated data and calculate the predicted quantities of\ninterest. Iterating 1000 times results in 1000 predictions. The 2.5th and 97.5th\nquantiles of these predictions are the bounds of the con\fdence intervals.\n7 Regression tables\nTables 4 and 5 below show regression results for the number of mentions (nega-\ntive binomial model) and proportion of mention frames (fractional logit model)\nfor all three topics. All signi\fcance tests are two-tailed.\nFor the negative binomial models, the coe\u000ecient on post (^\f1) amounts to the\nestimated increase in log topic mentions on a conservative show after an event.\nThe coe\u000ecient on liberal (^\f2) represents the e\u000bect on log topic mentions of\nmoving from a conservative to a liberal show, pre-event. The coe\u000ecient on\npost x liberal (^\f3) is the change from pre-event to post-event topic mentions\namong liberal shows, compared to the change among conservative shows.\nFor the fractional logit models, the coe\u000ecients represent analogous changes\nin the (logit-transformed) proportions of climate-concerned, anti-gun, and tough-\non-immigration frames. These models have fewer observations, because show-\nweeks with no topic mentions have no information on frame proportions.\n14\n15\nTable 4: Regression table for number of mentions of climate change, gun policy\nand immigration. Model is negative binomial regression with standard errors\nclsutered at the show level.\nclimate gun immig.\n(1) (2) (3)\nConstant \u00000.484\u0003\u0003\u00030.483 1.188\u0003\u0003\u0003\n(0.122) (0.313) (0.149)\np = 0.0001 p = 0.124 p = 0.000\npost 0.968\u0003\u0003\u00030.577\u0003\u0003\u00031.782\u0003\u0003\u0003\n(0.116) (0.124) (0.094)\np = 0.000 p = 0.00001 p = 0.000\nliberal 1.018\u0003\u0003\u0003\u00001.013\u0003\u0003\u00030.541\n(0.195) (0.338) (0.405)\np = 0.00000 p = 0.003 p = 0.182\npost x liberal \u00000.329 \u00000.222 \u00001.100\u0003\u0003\u0003\n(0.240) (0.221) (0.400)\np = 0.171 p = 0.317 p = 0.007\nminutes 0.001\u0003\u0003\u00030.001\u0003\u0003\u00030.001\u0003\u0003\u0003\n(0.0001) (0.0002) (0.0001)\np = 0.000 p = 0.0002 p = 0.000\nObservations 1,412 1,896 524\nNote:\u0003p<0.1;\u0003\u0003p<0.05;\u0003\u0003\u0003p<0.01\n16\nTable 5: Regression table for proportion of mentions that are concerned about\nclimate, anti-gun, or tough on immigration. Model is fractional logit regression\nwith standard errors clsutered at the show level.\nclimate gun immig.\n(1) (2) (3)\nConstant \u00000.505\u0003\u0003\u0003\u00001.326\u0003\u0003\u00030.850\u0003\u0003\u0003\n(0.178) (0.152) (0.188)\np = 0.005 p = 0.000 p = 0.00001\npost 0.175 0.422\u0003\u0003\u00000.153\n(0.179) (0.165) (0.190)\np = 0.331 p = 0.011 p = 0.421\nliberal 2.959\u0003\u0003\u00032.232\u0003\u0003\u0003\u00001.651\u0003\u0003\u0003\n(0.422) (0.296) (0.289)\np = 0.000 p = 0.000 p = 0.000\npost x liberal 0.339 \u00000.122 \u00000.060\n(0.398) (0.376) (0.320)\np = 0.395 p = 0.745 p = 0.851\nObservations 529 653 320\nNote:\u0003p<0.1;\u0003\u0003p<0.05;\u0003\u0003\u0003p<0.01\n8 Counting non-neutral mentions of immigra-\ntion\nOne obvious concern about the \fnding of increased immigration mentions might\nbe that it would be di\u000ecult to report on the event (family separation) without\nmentioning the topic terms. For that reason, I re-do the analyses leaving out any\nmentions that the coders labeled \\neither\". These are mentions that support\nno stance on immigration, largely because they are simply pieces of news on the\ntopic. On both ideological sides, the proportional increase in the \\non-neither\"\nmentions is roughly the same size as the overall increases above (conservative:\nfrom 1:9 to 9:4; liberal: from 4 :0 to 6:4). In other words, the change in attention\nto immigration is not only due to outlets reporting on the events themselves|\nit is as much due to an increase in opinionated commentary on the topic of\nimmigration.\n9 Long-term e\u000bects: agenda half-lives\nStudies of the agenda-setting power of major events in mainstream media often\n\fnd e\u000bects that last for months (Lawrence, 2000; Birkland, 2004; Zhang et al.,\n2017). Here, I describe how trends in topic mentions tend to evolve once they\nhave peaked after an event. In other words, I analyze how quickly attention to\na topic dissipates on talk radio. Here, I \ft a model to the post-event trends.\nFor each topic, I look at total topic mention counts in the month after each\nevent, day by day. Because I am interested in the downward trend, the start of\nthis month is not the start of the post-event week (which I de\fned earlier as the\n\frst day on which the event reaches some level of social signi\fcance). Instead, it\nis the peak of talk radio attention to the topic: the day with the most mentions.\nTo avoid catching the beginning of attention to the next event, I leave out\nany days that fall in the next post-event week. This results in six dropped\nobservations for climate change, and six for mass shootings. Finally, for the\nPittsburgh Synagogue shooting, I only include the \frst nine days. This is be-\ncause ten days after the shooting, there was another mass shooting in Thousand\nOaks, California.\nAfter pooling the data across events within topics, I estimate the following\nsimple model:\nE[Ypct\nd;e] = 2\u0000\fd\nYpct\nd;eis the total number of mentions of the topic on day dafter the peak for\nevente. It is measured as a percentage of peak attention{i.e., attention on day\nd= 0. I did not include an intercept, as Ypct\nd=0;e= 1 by de\fnition. Using base\n2 for the exponential decay conveniently allows us to interpret the inverse of \f\nas the half-life of attention; the number of days it takes for mention counts to\nhalve. I estimate the model using non-linear least squares.\nThis model is not perfect|for instance, attention likely returns to some\nbaseline level in the long run, rather than eventually going to zero. However, it\n\fts the time trend in topic mentions reasonably well.\nFigure 5 shows the predicted post-peak attention trend for each topic, along-\nside the data. The estimated beta coe\u000ecients are 0 :14 for hurricanes and climate\n17\nFigure 5: Decline in attention (number of topic mentions) after the peak for\neach event. Line graphs show the estimated exponential decay of attention.\nPoints show observed attention by event.\nchange, 0:11 for mass shootings and gun policy, and 0 :13 for family separation\nand immigration. This means that the half-life of attention to topics after these\nevents is 7{9 days.\n10 Robustness checks\n10.1 News and public radio shows\nMost of the existing literature has treated news and public radio shows as sepa-\nrate from political talk radio. I \fnd that by a number of quantitative measures,\nthese shows are not necessarily more \\neutral\" than the other programs in our\ndata set. In this section, I show that the results are not a\u000bected by whether or\nnot news and public radio shows are included.\nAmong shows classi\fed as political, 25 shows have the word \\news\" in their\nname (e.g. \\Alabama Morning News\"), and 14 shows are produced and dis-\ntributed by National Public Radio (NPR). First, I look at whether these shows,\nwhen they mention a political topic, tend to use neither of the two estab-\nlished frames. Mentions coded as \\neither\" are usually presentations of facts\nor straightforward pieces of news about a topic. Bundling all of the observed\nweeks, just 16% of climate mentions on the average news show use neither a\nsupportive nor a skeptical frame. The same is true for NPR shows. With re-\nspect to gun policy, 33% of mentions on the average news show are neutral in\nthis way. On NPR shows it is 34%. Immigration is the topic that invites the\nmost neutral discussion, with 42% of news mentions and 55% of NPR mentions.\nA second possibility is that these shows are neutral in the sense that they\npresent both sides of the story equally, for instance by inviting guests with\nopposite points of view. Among the topic mentions that use an ideological\nframe, however, I do not \fnd this type of balance. In the case of climate\nchange, the average news show dedicates more than 89% of its non-neutral\nmentions to one side of the issue (be it skeptical or convinced). For the NPR\nshows, it is 95%. On gun policy, these shows spend 73% of their non-neutral\nmentions arguing for the same side. For the average NPR show, that is 84%.\nOn the topic of immigration, the average news show has 72% of its non-neutral\nmentions supporting the same side. For NPR shows, it is 69%. Not surprisingly,\nall NPR shows tend to take the same side (in particular, they overwhelmingly\nfeature \\climate-convinced\" content). The shows in the news category are more\nmixed in the direction of their slant. Crucially, none of the numbers above look\nmuch di\u000berent in the sample of non-news, non-NPR shows.\nTo check the robustness of these \fndings, I experiment with alternative\nde\fnitions of news and public radio shows, based on what stations broadcast\nthem. All US radio stations have a self-selected format that broadly describes\ntheir programming, mostly for the purposes of marketing and statistics. An\nalternative criterion for news shows would be those shows that are broadcast at\nleast one station with the\\All News\" format. An alternative criterion for public\nradio shows would be those shows that are broadcast on at least one station\nwith the \\Public Radio\" format. These de\fnitions lead to the same conclusion:\non news and public radio shows, the discussion of political topics looks no more\nneutral or balanced than it does on any other political show.\nGiven these \fndings, we might view news and public radio shows as simply\n19\nwithout news, public with news, public\ncounts frames counts frames\ntopic ideology pre post pre post pre post pre post\nclimate conservative 0.8 2.1 38 42 0.8 2.2 38 41\nclimate liberal 2.2 4.1 92 95 2.0 4.1 93 95\ngun policy conservative 1.9 3.3 21 29 2.0 3.3 22 30\ngun policy liberal 0.7 1.0 71 77 0.7 1.1 68 79\nimmigration conservative 4.3 25.3 70 67 5.1 27.4 70 66\nimmigration liberal 7.3 14.5 31 27 8.2 17.7 30 28\nTable 6: Predicted mention counts and frames (percentage \\convinced\", \\anti-\ngun\" and \\tough on immigration\" frames), pre- and post-event, for each political\ntopic, without and with NPR shows or news shows.\nanother type of talk radio with political content. For that reason, I repeat\nthe analyses, including shows with \\news\" in the name and shows produced by\nNPR. I also add two NPR programs to the liberal show training set for the\nideology classi\fer. This improves performance: testing the model on unseen\nepisodes, the classi\fer now correctly guesses the ideology of allshows. Table\n6 shows the results, alongside the original ones without NPR and news shows.\nWe can see that the basic thrust is the same.\n10.2 Show classi\fcation thresholds\nIn the analyses above, shows are classi\fed based on 50% thresholds: they are\nlabeled political, and conservative, if classi\fers assign them a 50%-or-higher\nprobably of being so. However, the training set for each model is a simply set\nof shows that can reliably be labeled as non-political, liberal or conservative.\nThis set probably does not re\rect the actual balance of show ideologies in the\nfull sample. It is likely, then, that the models' intercept estimates are biased.\nMoreover, perhaps not all political shows are slanted: it is possible there are\nmoderate shows in the sample, which I am unjustly labeling as ideological.\nFigure 6 shows the results of the show classi\fcation e\u000bort. It looks like the\nchoice of `politicalness' threshold could be important, because some shows are\nin fact di\u000ecult to classify. Only 70% of shows can be labeled as political with\nat least 70% certainty. In terms of ideology, the picture looks somewhat more\nrobust. 80% of political shows get an ideological label with over 70% certainty.\nNonetheless, we may be interested in how results change if we exclude shows\nwhose ideological class is unclear.\nHere, I repeat the key analyses, varying my decisions about show classes in\ntwo ways. First, I move the political decision threshold above or below 50%,\nbiasing the model towards labeling fewer or more shows as political. Second, I\ncreate bands around the ideology threshold, excluding shows that the model is\nuncertain about. For example, I might only include shows for which the classi\fer\nis at least 60% certain that they are either liberal or conservative. Table 7 shows\nthe results of the former analysis. Table 8 shows the latter. Neither decision\nchanges the results in any signi\fcant way, except that stricter `politicalness'\nthresholds lead to somewhat more topic mentions at baseline. This makes sense,\nsince I am excluding shows that spend less time covering political topics.\n20\nclimate gun policy immigration\ncounts frames counts frames counts frames\nthreshold ideology pre post pre post pre post pre post pre post pre post\n0.4 conservative 0.7 1.9 38 45 1.6 2.9 22 29 3.8 23.3 66 63\n0.4 liberal 1.9 3.7 92 95 0.6 0.8 69 78 6.4 12.5 28 25\n0.5 conservative 0.8 2.1 38 42 1.9 3.3 21 29 4.3 25.3 70 67\n0.5 liberal 2.2 4.1 92 95 0.7 1.0 71 77 7.3 14.5 31 27\n0.6 conservative 0.8 2.3 37 41 2.0 3.5 20 29 4.3 25.8 70 68\n0.6 liberal 2.4 4.6 91 95 0.7 1.2 72 78 5.2 16.6 28 30\nTable 7: Predicted mention counts and frames (percentage \\convinced\", \\anti-gun\" and \\tough on immigration\" frames), pre- and post-\nevent, for each political topic. Threshold indicates level of certainty we need in order to call a show \\political\" and include it in the data\nset.\nclimate gun policy immigration\ncounts frames counts frames counts frames\nthreshold ideology pre post pre post pre post pre post pre post pre post\n0.5 conservative 0.8 2.1 38 42 1.9 3.3 21 29 4.3 25.3 70 67\n0.5 liberal 2.2 4.1 92 95 0.7 1.0 71 77 7.3 14.5 31 27\n0.6 conservative 0.8 2.1 37 41 1.9 3.4 21 29 4.4 25.8 70 67\n0.6 liberal 2.4 4.4 93 96 0.7 1.0 75 75 8.0 14.8 31 27\n0.7 conservative 0.8 2.1 35 40 2.0 3.5 20 29 4.2 25.2 71 69\n0.7 liberal 2.5 5.9 96 97 0.9 1.2 78 81 5.5 17.0 31 26\nTable 8: Predicted mention counts and frames (percentage \\convinced\", \\anti-gun\" and \\tough on immigration\" frames), before and after\nevents, for each political topic. Threshold indicates level of certainty we need in order to call a show \\conservative\" or \\liberal\", and to\ninclude it in the data set.\n21\nDefinitely non\u2212political\nDefinitely political\n0306090\n0.00 0.25 0.50 0.75 1.00\nProbability of political\nDefinitely conservative\nDefinitely liberal\n0255075100125\n0.00 0.25 0.50 0.75 1.00\nProbability of liberalFigure 6: Distribution of prediction probabilities for shows, resulting from po-\nliticalness and ideology classi\fers.\nReferences\nDoug Beeferman, William Brannon, and Deb Roy. Radiotalk: A large-scale\ncorpus of talk radio transcripts. Technical report, Lab for Social Machines,\nMIT Media Lab, 2019.\nThomas A Birkland. \\The world changed today\": Agenda-setting and policy\nchange in the wake of the September 11 terrorist attacks. Review of Policy\nResearch , 21(2):179{200, 2004.\nA Colin Cameron, Jonah B Gelbach, and Douglas L Miller. Bootstrap-based\nimprovements for inference with clustered errors. The Review of Economics\nand Statistics , 90(3):414{427, 2008.\nCenter for American Progress and Free Press. The structural imbalance of\npolitical talk radio, 2007. URL https://cdn :americanprogress :org/wp-\ncontent/uploads/issues/2007/06/pdf/talk radio:pdf. Accessed April\n2022.\nBryce J Dietrich, Matthew Hayes, and Diana Z O'Brien. Pitch perfect: Vocal\npitch and the emotional intensity of congressional speech. American Political\nScience Review , pages 1{22.\nBryce J Dietrich, Ryan D Enos, and Maya Sen. Emotional arousal predicts\nvoting on the us supreme court. Political Analysis , 27(2):237{243, 2019.\n22\nMohit Iyyer, Peter Enns, Jordan Boyd-Graber, and Philip Resnik. Political\nideology detection using recursive neural networks. In Proceedings of the 52nd\nAnnual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers) , pages 1113{1122, 2014.\nKathleen Hall Jamieson and Joseph N Cappella. Echo chamber: Rush Limbaugh\nand the conservative media establishment . Oxford University Press, 2008.\nRegina G Lawrence. The politics of force: Media and the construction of police\nbrutality . University of California Press, 2000.\nGregory J Martin and Ali Yurukoglu. Bias in cable news: Persuasion and\npolarization. American Economic Review , 107(9):2565{99, 2017.\nLeslie E Papke. Papke and Wooldridge (1996) \rogit instructions. ND.\nLeslie E Papke and Je\u000brey M Wooldridge. Econometric methods for fractional\nresponse variables with an application to 401 (k) plan participation rates.\nJournal of applied econometrics , 11(6):619{632, 1996.\nVijayaditya Peddinti, Guoguo Chen, Vimal Manohar, Tom Ko, Daniel Povey,\nand Sanjeev Khudanpur. Jhu aspire system: Robust lvcsr with tdnns, ivec-\ntor adaptation and rnn-lms. In 2015 IEEE Workshop on Automatic Speech\nRecognition and Understanding (ASRU) , pages 539{546. IEEE, 2015.\nSarah Sobieraj and Je\u000brey M Berry. From incivility to outrage: Political dis-\ncourse in blogs, talk radio, and cable news. Political Communication , 28(1):\n19{41, 2011.\nHao Yan, Allen Lavoie, and Sanmay Das. The perils of classifying political ori-\nentation from text. Linked Democracy: Arti\fcial Intelligence for Democratic\nInnovation , 858:8, 2017.\nItzhak Yanovitzky and Joseph N Cappella. E\u000bect of call-in political talk ra-\ndio shows on their audiences: Evidence from a multi-wave panel analysis.\nInternational Journal of Public Opinion Research , 13(4):377{397, 2001.\nYini Zhang, Yidong Wang, Jordan Foley, Jiyoun Suk, and Devin Conathan.\nTweeting mass shootings: The dynamics of issue attention on social media.\nInProceedings of the 8th International Conference on Social Media & Society ,\npage 59. ACM, 2017.\n23", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Supplemental Information for Weaving it in: How Partisan Media React to Events", "author": ["C Vandeweerdt"], "pub_year": "2022", "venue": "NA", "abstract": "Recording of radio stations was an automated process, starting with scraping the publicly  available audio streaming URLs of US terrestrial radio stations from the website Radio-Locator"}, "filled": false, "gsrank": 359, "pub_url": "http://www.claravdw.com/wp-content/uploads/2021/05/talk_radio_article_appendix.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:sk0m1CRBKDYJ:scholar.google.com/&output=cite&scirp=358&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=sk0m1CRBKDYJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:sk0m1CRBKDYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://www.claravdw.com/wp-content/uploads/2021/05/talk_radio_article_appendix.pdf"}}, {"title": "Covidmis20: Covid-19 misinformation detection system on Twitter tweets using deep learning models", "year": "2022", "pdf_data": "CovidMis20: COVID-19 Misinformation Detection System on Twitter Tweets using Deep Learning Models Aos Mulahuwaish1, Manish Osti1, Kevin Gyorick1, Majdi Maabreh2, Ajay Gupta3, and Basheer Qolomany4 1 Department of Computer Science and Information Systems, Saginaw Valley State University, University Center, USA amulahuw@svsu.edu, mrosti@svsu.edu, kpgyoric@svsu.edu 2Department of Information Technology, Faculty of Prince Al-Hussein Bin Abdallah II for In-formation Technology, The Hashemite University, Zarqa, Jordan  majdi@hu.edu.jo   3Department of Computer Science, Western Michigan University, Kalamazoo, USA ajay.gupta@wmich.edu 4 Cyber Systems Department, University of Nebraska at Kearney, Kearney, USA qolomanyb@unk.edu Abstract.  Online news and information sources are convenient and accessible ways to learn about current issues. For instance, more than 300 million people engage with posts on Twitter globally, which provides the possibility to disseminate misleading in-formation. There are numerous cases where violent crimes have been committed due to fake news. This research presents the CovidMis20 dataset (COVID-19 Misinfor-mation 2020 dataset), which consists of 1,375,592 tweets collected from February to July 2020. CovidMis20 can be automatically updated to fetch the latest news and is publicly available at: https://github.com/everythingguy/CovidMis20.     This research was conducted using Bi-LSTM deep learning and an ensemble CNN+Bi-GRU for fake news detection. The results showed that, with testing accuracy of 92.23% and 90.56%, respectively, the ensemble CNN+Bi-GRU model consistently provided higher accuracy than the Bi-LSTM model.   Keywords: COVID-19, Misinformation, Dataset, Benchmark, Fake News, Twitter, Deep Learning.  1 Introduction Fake news, misinformation and disinformation have been in the media for a long time, with instances cited as far back as 1835 [1]. However, instances of fake news have grown detrimental with the growth of the internet, especially through social media plat-forms like Twitter, Facebook, etc. Concerns about fake news grew exponentially during the COVID-19 pandemic and the 2020 US Presidential Election. When the pandemic started in 2019, worry increased, and people went to the internet for answers. Millions of people died from COVID-19, and the global pandemic had lasting economic effects. \n2 In addition to COVID-19, there was a US Presidential election in 2020. These two events led to increased fake news led by political biases. Cases of fake news were especially prevalent on social media platforms, one such social media platform being Twitter. Twitter is a platform where people can share in-formation and images in \u201cTweets.\u201d However, since virtually anybody can post any-thing, misinformation can also be posted and spread quickly. Therefore, we need to have a way to flag content that could be untrustworthy. To classify the CovidMis20 dataset, we chose to use Ensemble Convolutional Neural Network (CNN) with the Bi-Directional Gated Recurrent Unit (Bi-GRU) model be-cause Bi-GRU is a less complex architecture than Bidirectional Long Short-Term Memory (Bi-LSTM) [2], which is a good model for text classification purposes in gen-eral. CNN is better suited to process the higher dimensional matrices, whereas Bi-GRU is better at temporal sequence data. So, using CNN and Bi-GRU as an ensemble model, we can utilize the power of calculation of higher dimensional matrices and temporal sequence data with less complexity than Bi-LSTM. An alternative is to use Bi-LSTM with Bi-GRU, but we will later see that the ensemble of CNN to capture the high di-mensional matrices with Bi-GRU capturing temporal features performed better. We could also try to use classical machine learning techniques like Support Vector Machine (SVM), k-nearest neighbors (k-NN), Decision Trees, etc. However, we be-lieve deep learning has far more capability in generalizing the various datasets and can be improved with further improvements in the model's architectures. The main contributions of this work are as follows: \u2022 We built a labeled dataset, CovidMis20, which contains around 1,375,592 tweets; this dataset helps researchers differentiate between fake and real news related to COVID-19 on Twitter; also, CovidMis20 can be automati-cally updated to fetch the latest news. We collected the Twitter dataset and used Media Bias Fact Check (MBFC) [16], which is a fact-checking page that relies strictly on the International Fact-Checking Network (IFCN) sig-natories. MBFC portal has one of the most comprehensive databases of fact-checking media sources. Initially, a dataset of URLs identified as fake or real was created using a web crawler tool to identify URLs with COVID -19 information. Based on the Media Bias Fact Check (MBFC) database, these URLs were classified as fake and real. \u2022 We developed and evaluated two deep learning models: ensemble CNN+Bi-GRU and Bi-LSTM for fake and real tweets text prediction with a testing accuracy of 92.23% and 90.56%, respectively.   This paper is organized as follows. Section 2 discusses related works. Section 3 pre-sents the methodology and implementation. Section 4 presents results and discussion. Finally, Section 5 provides our conclusions and future work.  2        Related Work  Recently, a significant amount of work has been done in the area of fake news detection. This section reviews recent related works on the different aspects of fake news detec-tion. \n3      Hassan et al. [3] proposed a machine learning approach using supervised machine learning classification models like Support Vector Machine (SVM), Logistic Regres-sion, and Naive Bayes to detect fake online reviews. They have used 1600 examples of the gold standard hotel review dataset, 800 reviews are deceptive, and the other 800 are truthful; as a result, they found that the SVM has given the best accuracy (88.75%) over the remaining models.  Reddy et al. [4] introduced a hybrid detection system for fake data that employs the Multinomial Voting Algorithm based on Na\u00efve Bayes, Random Forest, Decision Tree, Support Vector Machine (SVM), k-Nearest Neighbours (k-NN) models. Their experi-mental data was collected from the Kaggle datasets (the authors did not mention any-thing related to the type of the datasets and their sizes or features). They had an accuracy score of 92.58% using above mentioned classical machine learning techniques.  Patwa et al. [5] created a COVID-19 social media and articles dataset for real and fake labels. Fake claims are collected from different fact-checking websites (like Politi-fact2, NewsChecker 3, Boomlive 4, etc.), and the real labels are collected from Twitter. The dataset vocabulary size is about 37,505. They used classical machine learning tech-niques like Decision Tree, Logistic Regression, Support Vector Machine (SVM), and Gradient Boost, the SVM model, which performs best with 93.32% accuracy, which is also a very good precision, recall, and accuracy overall. However, SVM gets more com-plex to work with when increasing the dataset size.      Al Asaad et al. [6] introduced a model to verify the news credibility that used dif-ferent machine learning techniques for text classification. They used two datasets (fake or real news) with 6335 news articles, 3164 were fake, and 3171 were true, and log data with 32000 titles, 15999 being clickbait and 16001 being non-clickbait. The model's efficiency has been tested on a dataset by using Multinomial Na\u00efve Bayes (MN) and Linear Support Vector Machine classification (LSVC) algorithms; they applied them with Bag-of-Words (BoW 2), Bi-gram (bigram 3), and Term Frequency-Inverse Doc-ument Frequency: (TF-IDF). The LSVC classifier performs better with the TF-IDF model.      Yu et al. [7] proposed four hybrid deep learning models (CNN+GRU, CNN+Bi-RNN, CNN+Bi-LSTM, and CNN+Bi-GRU). They applied their models to a real da-taset of patients' blood samples for the COVID-19 infection test from Hospital Israelita Albert Einstein in Sao Paulo, Brazil. They included 111 laboratory results from 5644 different patients. The results show that CNN+Bi-GRU performs the best, with an ac-curacy score of 94%. Aslam et al. [8] introduced an ensemble Bi-LSTM+GRU dense, deep learning model to detect fake news where Bi-LSTM+GRU was implemented for the textual attribute. In contrast, a dense, deep learning model was used for the remaining attributes. The study used a LIAR dataset with 12.8 K humans labeled from POLITIFACT.COM. The proposed approach achieved an accuracy of 89.8%. The \"COVID-19 Fake News\" dataset, which includes 21,379 real and fake news ex-amples for the COVID-19 pandemic and associated vaccines, was used to train and test four deep neural networks for fake news detection. Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), Bi-directional LSTM, and a combination of CNN and LSTM networks were developed and evaluated to automatically identify \n4 fake news content related to the COVID-19 posted on social media platforms.  The evaluation's findings demonstrated that the CNN model performed better than the other deep neural networks, with an accuracy rate of 94.2% [9]. In summary, from the literature review, it is evident that social media platforms from the beginning of the pandemic were abuzz with news and information related to COVID-19. It was also clear that information \u2013 fake or real \u2013 caught the attention of millions of people active on social media, swayed their opinion, and influenced their behavior. To classify a tweet (that is, to analyze its content), many existing works ana-lyze its text content using natural language processing (NLP) techniques and then use machine learning or deep learning algorithms for classifying the tweet's text. However, because the tweet's text is expressed using natural languages, it is hard to detect and extract what the tweet's author means due to the vagueness and the imprecision of the written text, which implies low accuracy. To aid in those computational efforts, this paper describes the construction of the CovidMis20 (COVID Misinformation 2020), which could be used as a benchmark da-taset; CovidMis20 contains confirmed true and fake news from Media Bias Fact Check (MBFC). The size of CovidMis20 is currently about 1,375,592 tweets; CovidMis20 can be automatically updated to fetch and incorporate the latest news. In contrast, most efforts in the literature have used relatively small datasets, and thus scalability remains a question. Obviously, most machine learning models make a good decision when the dataset size is relatively large. The results become more generalizable compared to smaller datasets. Hence, CovidMis20 should contribute to advancing the research on fake news detection. This paper also introduces a technique to build fake news detecting systems by focusing on creating a sequence classification model for fake (non-trust-worthy) and real (trustworthy) tweets text (classifying text sequences based on the con-textual information present).  3       Methodology and Implementation  3.1      Dataset Collection and Curation  We collected more than 1.5 billion coronavirus-related tweets from more than 40 mil-lion users from January 22, 2020, until May 15, 2022, leveraging the Twitter standard search application programming interface (API) and Tweepy Python library. A set of predefined search English keywords were used. These include {\u201ccorona,\u201d \u201ccorona-virus,\u201d \u201cCoronavirus,\u201d \u201cCOVID-19\u201d, \u201cstay at home,\u201d \u201clockdown,\u201d \u201cSocial Distanc-ing,\u201d \u201cEpidemic,\u201d \u201cpandemic,\u201d and \u201coutbreak\u201d}, which are the some of the most widely used scientific and news media terms relating to the novel coronavirus. We extracted and stored the text and metadata of the tweets, such as timestamp, number of likes and retweets, hashtags, language, and user profile information, including user id, username, user location, number of followers, and number of friends. Typically, it is challenging to label data as \u201cfake\u201d or \u201creal\u201d news since the perception varies from one individual to another. We can, however, focus on the facts that have been established medically or scientifically \u2013 and then decipher if these facts were in-correctly shared or twisted by individuals or websites while being posted on a platform. \n5 Using a determined list of websites classified as trustworthy or not \u2013 obtained from Media Bias Fact Check (MBFC) - a web-crawler tool was deployed to collect an initial URL-based (MBFC dataset) dataset. The web crawler tool used in this work is a Java-based tool to crawl the internet. The tool was executed to search the internet and find and report COVID-19-related sites in an output file.  The keywords used for the search were \u2013 Sars-cov-2, COVID-19, Coronavirus, and virus \u2013 to only get sites related to the COVID-19 information. Then we looked for COVID articles at each URL (for example, https://achnews.org). If a page contained at least six instances of the key terms: Sars-cov-2, COVID-19, Coronavirus, and virus, it was considered a COVID article. The scraper went through each domain page, search-ing for these keywords. For the pages considered COVID articles, only the URL was collected. The website content needed to contain any of the keywords mentioned above thrice to ensure a closer hit. This ensured that the words were not present in the info-mercial listed or the extra information section. There is an assumption made when we think only these keywords represent sites containing COVID-19 information. Of course, more sites have other keywords present talking about the virus. The URLs from the MBFC dataset were classified as fake and real as per the predetermined list from the MBFC. For Twitter data analysis, applications were used to clean the data as the tweets that had MBFC were classified, URLs in them were extracted, and fields like tweet date, location, tweet text, and tweet URL were identified and extracted from the data for problem-solving. Figure 1 shows the data collection process. The first phase of data collection is reg-istering a Twitter application and obtaining a Twitter access key and token. The second phase is to import the Tweepy Python package and write the Python script for accessing Twitter API. The third phase is to connect to Twitter search API and retrieve tweets using some keywords related to COVID-19. The third phase reads and processes the data to extract information on tags, agents, and locations for network construction and analysis. The fourth phase filters Tweets containing URLs from a web crawler. The last phase is attaching MBFC labels, including trustworthy and untrustworthy ones.  3.2      Data Preprocessing We used data mining and machine learning methods to preprocess, classify and analyze the data. Data or text mining, in general, helps identify relevant information in a large corpus, providing qualitative results, and machine learning for text mining or data min-ing is the process of reviewing the text to help with specific research questions. It is the initial cleaning part of data preprocessing. It helps identify the features and relation-ships of a given text. Once identified, these features can be used by machine learning methods to find patterns and trends across large data sets, resulting in more quantitative results. We used Natural Language Processing (NLP) which helps machines understand human language in a given context [10].      Initially, Python was used to clean the dataset. Following the standard procedure, it removed all non-English words and converted all text to lower case to ensure the pro-gram recognized all the exact words in the same manner. After this, we used Natural \n6 Language Processing Tool Kit (NLTK) library [11] in Python to create a proper corpus using PorterStemmer and Stopword functions. NLTK in Python has a list of stop words (such as \u2018the,\u2019 \u2018a\u2019, \u2018an\u2019) stored in 16 differ-ent languages. The Stopword function identifies these words in the corpus. PorterStem-mer function is used to stem words; for example, after stemming, a word like \u201clooking\u201d becomes \u201clook.\u201d  Stemming is done on all words except stop words (removing stop words from the corpus). This process creates a good corpus, saves space in the database, and improves processing time. This corpus is used for classification and prediction pur-poses.                                                                                                      Fig 1. Process for collecting tweet data We have used the Embedding Layer from Keras\u2019 library in Python [12] (which uses the word embedding technique for text-preprocessing \u2013 words with the same meaning will have similar representations). Before the data enters the Embedding Layer, it must be converted to a numerical form categorical, using One-Hot encoding [13]. After this, the timestamp is padded with zeros, either pre or post, to create sentences of equal length. Also, several feature vectors are defined for the Embedding Layer so the model can create vector representations based on the number. This is done so algorithms can generalize the corpus created to make any prediction. \n\n7  We balanced the data because there were around 10 % more true tweets than fake tweets. Thus, we downsampled the true tweets to the same number as fake tweets. We removed URL patterns from the tweets, like https:// and other symbols and characters which resemble the part of a URL to have only normal text without any links to the tweet and then converted all the text to lowercase. The numbers of true and fake news are equally balanced into 289,826. Also, we divided the dataset randomly into 70% training and 30% testing. The total size of the training set is 405,756 (70%), and the testing set is 173,896 (30%). 3.4      Classifications This section presents an overview of the models we used to classify our dataset. We used the TensorFlow framework with a Python programming language to build the models. We also used other Python APIs like pandas, NumPy, matplotlib, and NLTK. TensorFlow has an embedding layer, GRU layer, LSTM layer, and dense, fully con-nected layer readily available along with Adam optimizer, which we used to build the models. After data preprocessing, the corpus created is classified by ensemble CNN+GRU and BiLSTM models.      We used cross-validation to verify that the models are not overfitting. We used a stratified K-Fold cross-validation technique where we had ten folds or splits to balance the classes in the training and testing datasets and to validate the models; We observed a mean accuracy of 91.6% for the ensemble CNN+Bi-GRU and 90.8% for Bi-LSTM models. Also, one of the advantages of using the ensemble CNN+Bi-GRU is that it reduces the chances of overfitting because it is the aggregate of all the model's output. The following sections show the structure of each model.    3.4.1      Ensemble CNN+Bi-GRU Model Gated Recurrent Units (GRUs) is a gating mechanism in recurrent neural networks, like the Long Short-Term Memory with a forget gate but fewer parameters than LSTM be-cause it lacks an output gate. Figure 2 shows the architecture of GRU, where there are only two gates, which can also be called an update gate and reset gate. From Figure 2, the first gate from the input x, where there is the first sigmoid function from the left, is the reset gate and the following sigmoid function, which is also connected to the hidden state h to the right, is the update gate. GRU has been found to perform well with tasks like signal modeling and NLPs and works well with frequent datasets. So, a GRU can be generalized as a variation of LSTM because both have a similar design. GRUs use the update gate and the reset gate, the two primary operations in the GRU model. There-fore, these gates control the flow of information, which means that useful information can be kept, and unimportant information can be removed.       \n8           Fig 2. Gated Recurrent Unit (GRU)   Within deep learning, Convolutional Neural Network (CNN) is used to analyze structured data arrays (such as images) and is mainly used for image and text classifi-cation. Figure 3 shows the architecture of a CNN by stacking layers on top of each other in a sequence. These layers are usually convolutional, followed by activation and some-times pooling layers. Additionally, CNNs are typically made up of 20 to 30 layers, with each layer capable of recognizing something more complex than the last. For example, using 3 to 5 layers, handwritten digits can be recognized, and with 25 layers, a human face can be recognized.                                                         Fig 3. Convolutional Neural Network (CNN) model         After analyzing how efficient they can be for text classification and NLPs, we de-cided to use ensemble CNN+Bi-GRU, where we combine 1D CNN with a single Bi-GRU. 1D CNN performs better on text classification [14]. The Bi-GRU model works well on time-series data by looking at the earlier and later information sequences.       Figure 4 shows the layers of the ensemble CNN+Bi-GRU model we used for build-ing CovidMis20 benchmark. There are two inputs for the model training purpose, one for CNN and one for Bi-GRU, followed by the embedding layer, convolutional layer, max pooling, dropout layer, and a dense or a fully connected layer with an activation function (sigmoid function). For GRU, the input layer is followed by the embedding layer, Bi-Directional Gru Layer, dropout layer, and a dense layer with a sigmoid func-tion as an activation function. Then, we merged both the dense layers of CNN and Bi-GRU to form a dense layer (fully connected layer) with a sigmoid function. \n\n9                                                                                                       Fig 4. An ensemble CNN+Bi-GRU model       \n\n10 3.4.2       Bi-LSTM Model  Bi-LSTM is a type of RNN (Recurrent Neural Network [15]) used to avoid vanishing gradient problems. Bi-LSTM models have a cell state representing context information (storing information about past inputs for a specific time). Bidirectional LSTM can look at the data in both directions (left to right and right to left), so it is considered to store contextual information better than LSTM. Bidirectional LSTM is used when prediction depends on previous and future inputs. For example, a sentence like \u201cI say Sam likes eating ___.\u201d Eating can be anything, so prediction depends on understanding the future and previous words. The Bi-LSTM model uses the time stamp technique to enter data into the model. The model learns the contextual information for the time stamp entered and tries to predict the next word in the sequence.        Bi-LSTM models and NLP (Natural Language Processing) use distributed repre-sentation techniques to describe the same data features across multiple scalable and interdependent layers. It tries to interpret or learn features of the same dataset on dif-ferent scales (semantic similarities). Another reason to use the Bi-LSTM model is that around 2007, the models started to revolutionize speech recognition outperforming tra-ditional models. Figure 5 shows the structure of an unfolded Bi-LSTM layer that con-tain the forward and backward LSTM layers.                                             Fig 5. Unfolded architecture of BiLSTM with three consecutive steps        Figure 6 shows the layers of the Bi-LSTM model we used for this work. There is an input layer, followed by the embedding layer, Bi-Directional LSTM Layer, dropout layer, global max-pooling layer, and a dense layer with a sigmoid function as an acti-vation function.                               \n\n11                                                                                                                   Fig 6. Bi-LSTM model  4        Results and Discussion  In this section, we provide details on the outcome of running the models on the Covid-Mis20 dataset.       Figure 7 shows the overall measurement results of the ensemble CNN+Bi-GRU and Bi-LSTM models to detect fake news from the CovidMis20 dataset. We have a 92.23% testing accuracy, 0.9025 precision (specificity), 0.945 recall (sensitivity), and 0.9232 F1-score with the ensemble CNN+Bi-GRU and 91.56% testing accuracy, 0.911 precision (specificity), 0.92 recall (sensitivity), and 0.9154 F1-score with the Bi-LSTM model. Figures 8 show the accuracy and validation accuracy for the ensemble CNN+Bi-GRU and Bi-LSTM, where they trained with a batch size of ten.         \n\n12 \n                               Fig 7. An ensemble CNN+Bi-GRU and Bi-LSTM performance   \n Fig 8. Evaluation phase performance of ensemble CNN+Bi-GRU (left) and Bi-LSTM (right)           Figure 9 shows the confusion matrix for ensemble CNN+Bi-GRU and BiLSTM models for text classification. We analyzed the confusion matrix in the evaluation phase, where 1 is fake and 0 is true. Thus, we can see a high accuracy of True Positive (TP) and True Negative (TN) percentages while detecting fake news from the Twitter dataset. For clarity, the meaning of true positive, true negative, etc. in our context is as follows: \u2022 True Positive (TP): when predicted, fake news pieces are annotated as fake news. \u2022 True Negative (TN): when predicted, true news pieces are annotated as true news. \u2022 False Negative (FN): when predicted, true news pieces are annotated as fake news. \n\n13 \u2022 False Positive (FP): when predicted, fake news pieces are annotated as true news. Based on Figure 9, the ensemble CNN+Bi-GRU model classified 89.8% of fake tweets correctly and 10.2% incorrectly. At the same time, 5.5% of real tweets text was classified incorrectly by the model as fake, while classifying 94.5% of real tweets text. In contrast, the BiLSTM model correctly identified 91.1% of fake tweets text, misidentifying 8.9% as real. At the same time, 8.0% of real tweets' text was classified correctly and misclassified 92.0% incorrectly.                   Fig 9. Confusion matrix of test dataset of ensemble CNN+Bi-GRU (left) and Bi-LSTM (right)  5       Conclusions and Future Work  This paper presented a comprehensive COVID-19 misinformation dataset, CovidMis20, which contains around 1,375,592 tweets from February to July 2020; CovidMis20 is class-wise balanced and can be used to develop automatic fake news detection models. Also, CovidMis20 is benchmarked by using deep learning models and projects them as potential baselines. The ensemble CNN+Bi-GRU model performs the best with 92.23% testing accuracy.    Although we used Covid-related Twitter tweets to build models to detect fake news, our techniques can easily be extended to other datasets for fake news detection.  Future work could be targeted toward using an enhanced evolutionary detection approach such as Particle Swarm Optimization (PSO), which aims to reduce the number of symmetrical features and obtain more accurate models.  \n\n14 Acknowledgments   This work was supported in part by Saginaw Valley State University and the National Science Foundation under Grant OAC-2017289, National Institute of Health under Grant 1R15GM120820-01A1, and WMU FRACAA 2012-22. References 1. Pennycook, Gordon, and David G. Rand. \"The psychology of fake news.\" Trends in cogni-tive sciences 25, no. 5 (2021): 388-402. 2. Chung, Junyoung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. \"Empirical eval-uation of gated recurrent neural networks on sequence modeling.\" arXiv preprint arXiv:1412.3555 (2014). 3. Hassan, Rakibul, and Md Rabiul Islam. \"A Supervised Machine Learning Approach to De-tect Fake Online Reviews.\" In 2020 23rd International Conference on Computer and Infor-mation Technology (ICCIT), pp. 1-6. IEEE, 2020. 4. Reddy, Palagati Bhanu Prakash, Mandi Pavan Kumar Reddy, Ganjikunta Venkata Ma-naswini Reddy, and K. M. Mehata. \"Fake data analysis and detection using ensembled hy-brid algorithm.\" In 2019 3rd International Conference on Computing Methodologies and Communication (ICCMC), pp. 890-897. IEEE, 2019. 5. Patwa, Parth, Shivam Sharma, Srinivas Pykl, Vineeth Guptha, Gitanjali Kumari, Md Shad Akhtar, Asif Ekbal, Amitava Das, and Tanmoy Chakraborty. \"Fighting an infodemic: Covid-19 fake news dataset.\" In International Workshop on Combating On line Ho st ile Posts in Regional Languages dur ing Emerge ncy Si tuation, pp. 21-29. Springer, Cham, 2021. 6. Al Asaad, Bashar, and Madalina Erascu. \"A tool for fake news detection.\" In 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), pp. 379-386. IEEE, 2018. 7. Yu, Ziyue, Lihua He, Wuman Luo, Rita Tse, and Giovanni Pau. \"Deep Learning for COVID-19 Prediction based on Blood Test.\" In IoTBDS, pp. 103-111. 2021. 8. Aslam, Nida, Irfan Ullah Khan, Farah Salem Alotaibi, Lama Abdulaziz Aldaej, and Asma Khaled Aldubaikil. \"Fake detect: A deep learning ensemble model for fake news detec-tion.\" complexity 2021 (2021). 9. Tashtoush, Yahya, Balqis Alrababah, Omar Darwish, Majdi Maabreh, and Nasser Alsaedi. \"A Deep Learning Framework for Detection of COVID-19 Fake News on Social Media Platforms.\" Data 7, no. 5 (2022): 65. 10. \"What is Natural Language Processing and How Does It Work.\" Available via On-line: https://monkeylearn.com/blog/what-is-natural-language-processing/. Accessed 10 Sep. 2021. 11. \"Natural Language Toolkit.\" Available via Online: https://www.nltk.org/. Accessed 2 Sep-tember 2021. 12. \"Keras: the Python deep learning API.\" Available via Online: https://keras.io/. Accessed 2 Sep 2021. 13. \"Sklearn.preprocessing.OneHotEncoder\" Available via Online: https://scikit-learn.org/sta-ble/modules/generated/sklearn.preprocessing.OneHotEncoder.html. Accessed 2 September 2021. \n15 14. Kowsari, Kamran, Mojtaba Heidarysafa, Donald E. Brown, Kiana Jafari Meimandi, and Laura E. Barnes. \"Rmdl: Random multimodel deep learning for classification.\" In Proceed-ings of the 2nd international conference on information system and data mining, pp. 19-28. 2018. 15. Sherstinsky, Alex. \"Fundamentals of recurrent neural network (RNN) and long short-term memory (LSTM) network.\" Physica D: Nonlinear Phenomena 404 (2020): 132306. 16. \"Media Bias Fact Check (MBFC).\" Available via Online: https://mediabiasfactcheck.com/. Accessed Feb. 2021.  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Covidmis20: Covid-19 misinformation detection system on Twitter tweets using deep learning models", "author": ["A Mulahuwaish", "M Osti", "K Gyorick", "M Maabreh"], "pub_year": "2022", "venue": "\u2026 on Intelligent Human \u2026", "abstract": "Online news and information sources are convenient and accessible ways to learn about  current issues. For instance, more than 300 million people engage with posts on Twitter"}, "filled": false, "gsrank": 360, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-27199-1_47", "author_id": ["rgCcYJkAAAAJ", "GQ6eODwAAAAJ", "WER3mxAAAAAJ", "Y9_J5jAAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:pKQay0IopzsJ:scholar.google.com/&output=cite&scirp=359&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D350%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=pKQay0IopzsJ&ei=RLWsaLqQELXCieoP4PfQ0A8&json=", "num_citations": 8, "citedby_url": "/scholar?cites=4298448636688901284&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:pKQay0IopzsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2209.05667"}}, {"title": "MMCoVaR: multimodal COVID-19 vaccine focused data repository for fake news detection and a baseline architecture for classification", "year": "2021", "pdf_data": "MMC OVAR: M ULTIMODAL COVID-19 V ACCINE FOCUSED\nDATA REPOSITORY FOR FAKE NEWS DETECTION AND A\nBASELINE ARCHITECTURE FOR CLASSIFICATION\nMingxuan Chen\u0003\nDepartment of Electrical and Computer Engineering\nStevens Institute of Technology\nHoboken, NJ 07030\nmchen20@stevens.eduXinqiao Chu\nDepartment of Electrical and Computer Engineering\nStevens Institute of Technology\nHoboken, NJ 07030\nxchu2@stevens.edu\nK.P. Subbalakshmi\nDepartment of Electrical and Computer Engineering\nStevens Institute of Technology\nHoboken, NJ 07030\nksubbala@stevens.edu\nSeptember 27, 2021\nABSTRACT\nThe outbreak of COVID-19 has resulted in an \u201cinfodemic\" that has encouraged the propagation\nof misinformation about COVID-19 and cure methods which, in turn, could negatively affect the\nadoption of recommended public health measures in the larger population. In this paper, we provide a\nnew multimodal (consisting of images, text and temporal information) labeled dataset containing news\narticles and tweets on the COVID-19 vaccine. We collected 2,593 news articles from 80 publishers for\none year between Feb 16th2020 to May 8th2021 and 24184 Twitter posts (collected between April\n17th2021 to May 8th2021). We combine ratings from two news media ranking sites: Medias Bias\nChart and Media Bias/Fact Check (MBFC) to classify the news dataset into two levels of credibility:\nreliable and unreliable. The combination of two \ufb01lters allows for higher precision of labeling. We\nalso propose a stance detection mechanism to annotate tweets into three levels of credibility: reliable,\nunreliable and inconclusive. We provide several statistics as well as other analytics like, publisher\ndistribution, publication date distribution, topic analysis, etc. We also provide a novel architecture\nthat classi\ufb01es the news data into misinformation or truth to provide a baseline performance for this\ndataset. We \ufb01nd that the proposed architecture has an F-Score of 0:919and accuracy of 0:882for fake\nnews detection. Furthermore, we provide benchmark performance for misinformation detection on\ntweet dataset. This new multimodal dataset can be used in research on COVID-19 vaccine, including\nmisinformation detection, in\ufb02uence of fake COVID-19 vaccine information, etc.\nKeywords COVID-19 Vaccine \u0001Multimodal Data Repository \u0001Misinformation\u0001Fake News Detection \u0001Explainable\nModel\u0001Modular Architecture\n1 Introduction\nThe ongoing COVID-19 has been devasting in many ways. As of April 8th2021, the number of con\ufb01rmed COVID-19\ncases was 132;485;386; including 2;875;672con\ufb01rmed deaths [1]. This has caused panic about the possible economic\nfallout and recession. Along with the spread of the virus, misinformation about it has also spread virally. As the\nDirector-General of the World Health Organization (WHO) said, fake news spreads faster and more easily than this virus.\n\u0003This paper has been accepted for publication in ASONAM 2021.arXiv:2109.06416v2  [cs.IR]  23 Sep 2021\nAPREPRINT - SEPTEMBER 27, 2021\nWHO de\ufb01ned the term, infodemics, as an excessive amount of information, including misinformation, disinformation\nand rumors that make it dif\ufb01cult to identify a solution, hampers effective public health response and creates confusion\nand distrust among people [2]. Therefore, it\u2019s necessary to track and analyze misinformation about this virus and the\nvaccines that have been developed for it.\nFor e.g, a news item that claimed that the COVID-19 vaccine can alter DNA was circulated on the web [3]. Furthermore,\nthe propagation of misinformation about vaccines affects the vaccination rates negatively, potentially leading to a\nworsening of the public health crisis. A study showed the number of Americans and Britons who would \u201cde\ufb01nitely\u201d get\nvaccinated dropped by 2.4 percent and 6.4 percent, respectively, after receiving misinformation about the COVID-19\nvaccines [4].\nThis paper proposes a new Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR) that includes 2,593\nnews articles and 24,184 related tweets with visual, textual and temporal information. Our work is inspired by [5] but\nwith some differences which we will elaborate on later. The main contributions of our work are:\n\u2022 An architecture for data collection from news sources and Twitter\n\u2022 Annotation schemes for the\n1.news articles using two news media reliability ranking websites: (i) Medias Bias Chart [6] and (ii) Media\nBias/Fact Check (MBFC) [7], which allows for better accuracy of the annotation process;\n2. Twitter data, using similarity based stance detection\n\u2022Statistical and topic analysis for fake news articles and true news articles and a summary of the differences of\ntopic distributions between them\n\u2022A novel attention based architecture for fake news classi\ufb01cation which achieves an F-Score of 0.919 and\naccuracy of 0.882\n\u2022 Several benchmark performances for misinformation detection for news and tweet data in this dataset\n2 Related Work\nWith the explosion of COVID-19, a lot of datasets have been released to support big data and deep learning based\nanalyses of the disease and its effects. One of the earliest COVID related datasets was the CORD-19 dataset [8] which\nis a resource of over 500,000 scholarly articles on COVID-19, SARS-CoV-2, and related coronaviruses. This dataset\nincludes over 200,000 articles with full text.\nResearchers have also mined social media to create COVID-19 related datasets. Chakraborty et al [9] released two types\nof Twitter-based datasets; one gathered from Dec 2019 to May 2020 and the other from Jan 2020 to Mar 2020. They\nprovide the sentiment analysis for this tweet dataset. The dataset in [10] collects 23,830,322 tweets from Mar 24th2020\nto Apr 9th2020 and utilizes Latent Dirichlet Allocation (LDA) and Uniform Manifold Approximation and Projection\n(UMAP) to analyze topics distribution. The COV19Tweets [11] is a Twitter-based dataset with more than 310 million\nCOVID-19 speci\ufb01c English language tweets from Mar 20st2021 to Apr 17th2021. It analyzes the sentiment and\ngeographical distribution of the tweets during the COVID-19 crisis and proposes a sentiment scoring system. The\nCoronaVis [12] is also a Twitter dataset containing tweets gathered from US-based users from Mar 5th2020 to Jul\n2nd2020. It focuses on sentiment and topic analysis. They also build a web application for topic trend analysis. The\nGeoCoV19 [13] is a large-scale Twitter dataset containing more than 524 million multilingual tweets posted for 90 days\nfrom Feb 1st2020. GeoCoV19 focuses on geographical and topic distribution analysis and provides the distribution of\ntopics by countries and cities. The CoVaxxy [14] dataset is a Twitter dataset gathered between Jan 10st2021 to Feb\n21th2021, focusing on geographical, topic and vaccine-related analysis. It provides a web information dashboard to\ntrack trending topics. Among these datasets, only CoVaxxy provides COVID-19 vaccine-related analysis.\nWhile the above datasets focused on mainly topic, sentiment and other geographic properties of the tweets; several\nresearchers have also started to work on COVID-19 misinformation related datasets. We discuss these in the following\nsubsection.\n2.1 Misinformation Focused Datasets\nThe CMU-MisCov19 dataset [15] contains 4,573 manually labeled tweets with 17 categories: \u201cIrrelevant\", \u201cCon-\nspiracy\", \u201cTrue Treatment\", \u201cTrue Prevention\", \u201cFake Cure\", \u201cFake Treatment\", \u201cFalse Fact or Prevention\", \u201cCor-\nrection/Calling out\", \u201cSarcasm/Satire\", \u201cTrue Public Health Response\", \u201cFalse Public Health Response\", \u201cPolitics\",\n\u201cAmbiguous/Dif\ufb01cult to Classify\", \u201cCommercial Activity or Promotion\", \u201cEmergency Response\", \u201cNews\" and \u201cPanic\nBuying\". The analysis in this work draws the conclusion that misinformed communities are denser and more organized\n2\nAPREPRINT - SEPTEMBER 27, 2021\nthan informed communities, a large majority of misinformed users may be anti-vaxxers and that informed users tend to\nuse more narratives than misinformed users when making up their minds.\nThe Constraint@AAAI2021 dataset [16] extracts 10,700 social media posts from Facebook, Twitter, Fact Checking, etc.\nIt is also a manually labeled dataset with two categories: real and fake. It provides benchmark performances using\nfour baseline models: (1) Decision Tree, (2) Logistic Regression, (3) Gradient Boost and (4) Support Vector Machine\n(SVM). The best performance is 93.46% on the F1-score using SVM.\nThe COVIDLIES dataset [17] identi\ufb01es 86 common misconceptions using Wikipedia articles on COVID-19 related\nmisconceptions. The dataset contains 6,761 tweets, identi\ufb01ed and human annotated by researchers. The dataset creates\nmisconception-tweet pairs with three labels: \u201cAgree\", \u201cDisagree\" and \u201cNo Stance\" which describes whether the tweet\nagrees or disagrees with the misconception or has no stance with respect to the misconception. The authors use\nBERTScore [18] to compute a similarity metric on tweet-misconception pairs and use that for stance detection.\nReCoVery [5] collects 2,029 COVID-19 related news articles and 140,820 tweets containing textual, visual, temporal,\nand network information from Jan 21th2020 to May 26th2020. The authors then use two news quality rating websites\nto annotate the news articles into two categories: reliable news and unreliable news. They also include the performance\nof four baseline models for fake reliable/unreliable news detection as benchmarks: (1) LIWC+DT, (2) RST+DT, (3)\nText-CNN and (4) SAFE a neural network based method.\nAlthough CMU-MisCov19 [15], Constraint@AAAI2021 [16], COVIDLIES [17] and ReCoVery [5] provide labeled\ndatasets, our dataset adds some additional value. We list the key differences below:\n\u2022The CMU-MisCov19 with 17 categories doesn\u2019t provide any benchmark performance for misinformation\ndetection, is a manually labeled dataset and contains fewer tweets than our dataset.\n\u2022The CMU-MisCov19, Constraint@AAAI2021 and the COVIDLIES datasets only provide labeled tweets\ndataset and not the relevant news articles. These datasets essentially do not concern themselves with the news\narticle-tweet pairing.\n\u2022The ReCoVery dataset is comprehensive, consisting of news articles and relevant tweets. However, the tweets\nare annotated as misinformation or true by simply inheriting the label of the relevant news articles. That is,\nthere is no stance detection involved, which might mean that a tweet that refers to a fake news article but calls\nit fake can be tagged as a fake tweet and vice versa. This paper also does not provide fake tweet detection\nbenchmarks.\n\u2022The COVIDLIES dataset uses BERTScore to compute a similarity metric on tweet-misconception pairs and\nuses this as a stance detection mechanism. They do not use news articles. We propose a method to detect the\nstance of a tweet with respect to the news article and then use that to label the tweet. More details on our\nstance detection approach can be found in Sec. 3.2.\n\u2022 Finally, our dataset is focused speci\ufb01cally on misinformation in the realm of COVID-19 vaccination.\nWe will elaborate more on the differences between these datasets and the proposed dataset in Section 3.3. In short, we\nprovide a Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR). We annotate the news dataset using\ntwo news website source checking \ufb01lters and the tweets dataset based on stance detection. We also provide benchmark\nperformances on news and tweets datasets for further comparison.\n3 Data\nAs mentioned earlier, our goal is to provide a labeled dataset that comprises of news articles as well as social media\nposts (tweets) to support research in COVID-19 vaccine related misinformation. We detail how we collect and annotate\nthe news data in Section 3.1 and social media data in Section 3.2. Our dataset is compared with other datasets in\nSection 3.3. We also provide some statistics and topic analysis in Section 3.4 and Section 3.5. Figure 1 shows a\nschematic overview of the proposed data collection and annotation process, for both news articles and social media.\n3.1 News Data Collection and Annotation\nMedia Bias Chart Checking [6] provides 120 websites and Media Bias/Fact Check (MBFC) [7] provides around 3700\nwebsites with their ratings. Of these, 80 websites are common between Media Bias Chart Checking and Media Bias/Fact\nCheck (MBFC). As shown in Fig 1, we classify these 80 websites into two groups according to our ranking system\ndescribed below.\n3\nAPREPRINT - SEPTEMBER 27, 2021\nFigure 1: Data collection process including news dataset and tweet dataset. The news dataset is validated using two\nsources of credibility. The tweets mentioning URLs of news articles are checked for stance and then labeled as reliable,\nunreliable or inconclusive.\nMedia Bias Chart is a website reliability visualization tool to display fact checking information and political bias\ninformation of news sites, which are annotated by their analyzers. The reliability score from Media Bias Chart is\nbetween 0to64;0indicates lowest credibility, and 64indicates highest credibility. Media Bias/Fact Check (MBFC)\ncategorizes data into six levels of reliability using manual fact checking by their analyzers. These levels are: \u201cVery\nHigh\", \u201cHigh\", \u201cMost Factual\", \u201cMixed\", \u201cLow\" and \u201cVery Low\". For our purposes, to improve the precision, we\ndiscarded the websites whose reliability levels from Media Bias/Fact Check (MBFC) are labeled \u201cMost Factual\" or\n\u201cMixed\". We use the following criteria to label the remaining news articles:\n\u2022 Label Reliable News\nIf MBFC ranking is \u201c High\" or \u201cVery High\"\nAND Media bias chart score is greater than 42\n\u2022 Label Unreliable News\nIf MBFC factual ranking is \u201c Low\" or \u201cVery Low\"\nAND Media bias chart score is below 24.\nThen we use newspaper library [19], a news articles extraction tool, to crawl COVID-19 vaccine related news articles\nusing the following nine keywords: \u201cvaccine\", \u201cvaccinated\", \u201cCOVID-19 P\ufb01zer\", \u201cCOVID-19 Moderna\", \u201cCOVID-19\nJanssen\", \u201cModerna vaccines\", \u201cJanssen vaccines\", \u201cJohnson & Johnson\u2019s vaccines\", \u201cBiontech vaccine\" .\nFor the news dataset, we provide the following information: \u201cNews ID\", \u201cURL Link\", \u201cPublisher\", \u201cPublish Date\",\n\u201cAuthor Title\", \u201cImage\", \u201cBody Text\", \u201cLabel\" . In total, the dataset contains 2,593 annotated news articles consisting\nof 958 unreliable news articles and 1,635 reliable news articles as shown in Table 1. We also provide the following\nstatistics for the news articles: (i) news publisher distribution, (ii) authors distribution (number of articles written by\na single author and multiple authors), (iii) news words distribution, etc. in the Section 3.4 and topic analysis in the\nSection 3.5.\n3.2 Social Media Data Collection and Annotation\nUsing the Twitter developer API [20], we crawl all tweets that mention the URL of the news articles in the news dataset\nthat we just created. Tweets were gathered from Apr 16th2021 to May 7th2021. As mentioned earlier a mere mention\nof the URL of an unreliable news article does not automatically mean that the tweet is also fake. A user could be\nagreeing or disagreeing with the content of the news in the URL. Hence, we need to determine the stance that the tweet\ntakes with respect to the news article mentioned in the URL.\n3.2.1 Stance Detection\nThe proposed stance detection process is illustrated in the Fig 2. Recently it was shown that lexical features and\nreadability features can be highly indicative of the stance of a written text [21]. This work used type-token-ratio (TTR),\nthe measure of textual lexical diversity (MTLD), automated readability index (ARI), Flesch-Kincaid grade (FKG) and\nFlesch reading ease (FRE) and some LSTM algorithms to detect stance.\n4\nAPREPRINT - SEPTEMBER 27, 2021\nFigure 2: Stance Detection Process\nIn our approach, we use all of the above features, and add root type-token ratio (RTTR), corrected type-token ratio\n(CTTR) and Dale Chall readability score (DCR) [22] to create a handcrafted feature vector: HCF news andHCF tweet ,\nwhere the HCF ?= [TTR ?;RTTR ?;CTTR ?;MTLD ?;ARI?;FKG ?;FRE ?;DCR ?]. One handcrafted feature vector\nis created for each news article and the tweet that mentions it. Then, we compute the similarity, SimilarityHCF, between\nthe two handcrafted feature vectors using cosine similarity metric [23]. We then compute the summary of the article.\nWe use the summary of the article instead of the entire article in order to be closer to the tweet length which is only 280\ncharacters long. We create a BoW vector for the summary of each news article and every tweet. Then, we estimate the\nsimilarity, Similaritytext, between every tweet and news article pair by computing the cosine similarity between the\nBoW vectors for each of these. The average of SimilaritytextandSimilarityHCF,Similarityavg, is used to detect the\nstance of the tweet with respect to the news article. Similarityavgis a real number in the range [0;1:0], where 0means\nleast similarity and 1means highest similarity. In our case, we set the stance as \u201csupport\" when the score is in range\n[0:6;1], \u201crefute\" when the score is in range [0;0:4]and \u201cNot Enough Information\" when the score is in range [0:4;0:6].\nThen we annotate each tweet based on the credibility of the news articles and the stance of social media as follows:\n\u2022 Label Reliable\nIf the relevant news is reliable and stance is \u201cSupport\" ORthe relevant news is unreliable and stance is\n\u201cRefute\"\n\u2022 Label Inconclusive\nIf the relevant news is reliable and stance is \u201cNot Enough Information\" ORthe relevant news is unreliable and\nstance is \u201cNot Enough Information\"\n\u2022 Label Unreliable\nIf the relevant news is reliable and stance is \u201cRefute\" ORthe relevant news is unreliable and stance is \u201cSupport\"\nBased on the Twitter development API agreement and policy [24], we can only provide the tweet ID of the Twitter data.\nAdditional information about the tweet can be obtained by twarc [25] or hydrator [26]. The dataset can be downloaded\nat [27]2. In total, we extracted 24,184 tweets, including 3,092 unreliable tweets, 17,234 inconclusive tweets and 3,858\nreliable tweets. The detail information of annotated news articles and related tweets is shown in Table 1.\n2Our collection relies upon publicly available data and is registered as IRB exempt by Stevens Institute of Technology IRB\n(approved protocol 2021-035(N)). We release the data set with the stipulation that those who use it must comply with Twitter\u2019s Terms\nand Conditions.\n5\nAPREPRINT - SEPTEMBER 27, 2021\nNews Articles Data\nCredibility Label Amount of News Total Amount\nUnreliable 0 958 2593\nReliable 1 1635\nTweets Data\nCredibility Label Amount of Tweet Total Amount\nUnreliable 0 3092\nInconclusive 1 17234 24184\nReliable 2 3858\nTable 1: Data Statistics\nDataset Name MB Chart MBFC Manually Check Stance Detection\nCMU-MisCov19 [15] 7 7 3 7\nConstraint@AAAI2021 [16] 7 7 3 7\nCOVIDLIES [17] 7 7 3 BERTScore\nReCOVery [5] 7 3 7 7\nMMCoVaR 3 3 7 Lexical,Readability,Language Embedding\nTable 2: Comparison of collection process among different misinformation focused datasets. The 3and7means the\ndataset used the corresponding approach and not, respectively. In this table, MB Chart represents Media Bias Chart,\nMBFC represents Media Bias/Fact Check and Manually represents manual annotation. Stance Detection column\ncaptures whether the Twitter dataset uses stance detection to label tweets that mention news article URLs: only\nCOVIDLIES and MMCoVaR use stance detection for tweet annotation.\n3.3 Comparison with other Datasets\nWe compare the collection process and properties of our dataset with other recent COVID-19 related misinformation\ndatasets in Table 2 and Table 3.\nThe comparison of data collection process is shown in Table 2. As mentioned in Section 2, only CMU-MisCov19,\nConstraint@AAAI2021, COVIDLIES and ReCoVery datasets provide misinformation-annotated data, the rest of the\ndatasets are not focused on misinformation and hence do not label for misinformation or truth. CMU-MisCov19 [15]\nand Constraint@AAAI2021 [16] use manual annotation without any web site reliability checking. ReCoVery [5] utilizes\ntwo news quality rating websites to label for misinformation after the news data and tweets have been gathered. Our\nproposed dataset, MMCoVaR, merges the MB Chart and MBFC to check for news site reliability. Among all the datasets,\nonly COVIDLIES and our proposed MMCoVaR use stance detection for annotating tweets. While COVIDLIES uses\nBERTScore to compute similarity between a tweet and misconception pair; we use stance detection to check whether\nthe tweet agrees with the news article or not.\nThe properties of the different datasets is shown in Table 3. All datasets provide social media information; however,\nonly the ReCoVery [5] and the proposed MMCoVaR dataset provide the relevant news articles information. Also, only\nCoVaxxy [14] and MMCoVaR provide COVID-19 vaccine related data. However, the CoVaxxy focuses on the topic\nanalysis, geographical distribution, etc. Therefore, they do not label this dataset for misinformation. Furthermore, the\ntime span of the dataset presented in this paper MMCoVaR is the longest one among all datasets.\nDataset Name News Data News Image Social Data Vaccine Time Span\nCMU-MisCov19 [15] 7 7 3 7 Not available\nConstraint@AAAI2021 [16] 7 7 3 7 Not available\nCOVIDLIES [17] 7 7 3 7 Not available\nReCOVery [5] 3 3 3 7 1/21/2020 to 5/26/2020\nMMCoVaR 3 3 3 3 2/16/2020 to 3/17/2021\nTable 3: Comparison of the properties of different misinformation focused datasets. The 3and7means the dataset\ncontains the speci\ufb01c information or not.\n6\nAPREPRINT - SEPTEMBER 27, 2021\n3.4 Data Statistics\nIn this subsection, we provide some additional statistics about our dataset, which may add some insight into misinfor-\nmation surrounding COVID-19 vaccinations.\nFigure 3: Publication Date Distribution\n(a) Publisher Distribution on Reliable News\n (b) Publisher Distribution on Unreliable News\nFigure 4: News Publisher Distribution\n(a) Distribution on Reliable\nNews\n(b) Distribution on Unreli-\nable News\nFigure 5: News Author Distribution\nPublication Date Distribution: The distribution of the publication date is shown in Fig 3. From this \ufb01gure we see that\nthe there is a steep uptick in the news articles about COVID-19 vaccines since Nov 2020. This timeline correlates with\nthe fact that the COVID-19 vaccine became available in November and P\ufb01zer COVID-19 vaccine was approved in the\nUK in Dec 2nd[28].\nNews Publisher Distribution: Fig 4 shows the number of articles published by different news media outlets in our\ndataset. Fig 4 (a) shows the distribution of reliable publishers which is dominated by \u201cBusiness Insider\" and \u201cChicago\nSun-Times\". Fig 4 (b) shows the distribution of articles by unreliable publishers and is dominated by the\u201cDaily Mail\"\nwhich contributed 463 articles, accounting for 48:3%of the unreliable news.\nNews Author Distribution: We provide the distribution of the number of authors for each news article in Fig 5. We\nnote that the number of authors for most news articles is fewer than 5; however, reliable news articles are dominated by\nsingle author articles, whereas unreliable news articles are dominated by two author articles.\nWord Distribution for News Articles: We plot the word count distribution for news articles for both reliable and\nunreliable news in Fig 6. The mean, median and mode of word number for both cases are: 911, 708 and 645, respectively\nfor reliable news; 1169, 812 and 744, respectively for unreliable news. The similarity of the distribution of word count\n7\nAPREPRINT - SEPTEMBER 27, 2021\n(a) Distribution on Reliable\nNews\n(b) Distribution on Unreli-\nable News\nFigure 6: Word Distribution for News Articles\nfor reliable and unreliable news may indicate that the length of these articles may not be a useful feature to distinguish\nbetween real and fake news.\n3.5 Data Topic Analysis\n(a) Reliable News Distribution\n (b) Unreliable News Distribu-\ntion\nFigure 7: LDA Cluster of Reliable and Unreliable News\nTopic analysis is a useful tool to gather insights into the kinds of topics that are discussed in social media in all three\ncategories of tweets (unreliable, reliable and inconclusive). In this section, we utilize Latent Dirichlet Allocation\n(LDA) [29] to analyze the distribution of topics in our data repository, since it is an unsupervised method and more\nsuitable for our dataset.\nWe extract 20 different topics using LDA analysis. Each topic was described using the 30 most relevant words for that\ntopic. A visual representation of these 20 topics is shown in Fig 7. Each topic is represented by a circle and the size of\nthe circle is proportionate to the number of news articles in the dataset that covers that topic. We \ufb01nd that distribution of\ntopics under the reliable news category is more dispersed than that under unreliable news category.\n4 Proposed Architecture for Misinformation Detection\nWe propose an attention based architecture that uses Longformer [30] to embed the news articles. The Longformer can\ncapture the long-range dependencies in text to create a \ufb01xed dimension embedding of the sentence/article.\nWe preprocess the data by removing the website links, stop words and non-alphanumeric characters from the text. Then\nwe add special tokens like [CLS] and [SEP] between sentences. Let Nibe the ithpreprocessed news article in the\nnews dataset. Let nibe the language embedding of the ithpreprocessed news article, Ni, obtained using Longformer.\nniis a768-dimension vector. The resulting vectors, ni, are used to construct the matrix M=fn1; n2; : : : ; n mg.\nSubsequently, we feed this matrix Minto an h-layer Multi Head Attention (MHA) module [31]. The MHA is followed\nby an attention layer, a dense layer and a softmax layer to get the \ufb01nal classi\ufb01cation. The architecture is depicted in\nFig 8 and is inspired by our earlier work on interpretable fake tweet detection [32].\n8\nAPREPRINT - SEPTEMBER 27, 2021\nFigure 8: The architecture with latent features using Longformer based sentence embedding.\n5 Experiment\n5.1 Experiment Setup\nWe implement all the models in Pytorch and train them to minimize the cross-entropy loss function of predicting\nthe class label of tweets in the training set. For all models with attention architecture in our experiments, we use a\n6-layer multi-head attention (MHA) module and the stochastic gradient descent (SGD) [33] as the optimizer for training.\nMoreover, we split the dataset in the 4 : 1 ratio for training and testing and use 5-fold cross validation to prevent\nover-\ufb01tting the model.\nBefore we discuss the models for misinformation detection, we \ufb01rst describe the handcrafted features that we use in\nsome of these models.\n5.2 Handcrafted Features\nHandcrafted features can play an important role in misinformation detection as demonstrated in [32]. We extract the\nfollowing handcrafted features: 37PoS tags and one sentiment feature (average value of words\u2019 sentiment polarity)\nusing NLTK [34], four psycho-linguistic features (\u2018FamiliarityScore\u2019, \u2018ConcretenessScore\u2019, \u2018ImagabilityScore\u2019 and\n\u2018AgeofAcquisitionScore\u2019), four vocabulary richness features (Honore\u2019s Statistic (HS), Sichel Measure (SICH), Brunet\u2019s\nMeasure (BM) and Text-Type Ratio (TTR)) and two readability features (Automated ReadabilityIndex (ARI) and\nFlesch-Kincaid readability (FKR) scores) [35]. Examples of some of these PoS tags are shown in Table 6.\n5.3 Models\nWe provide the performance (in terms of accuracy, F1 score, precision and recall) of several benchmark architectures on\nour dataset. The comparisons are shown in Table 4 and Table 5. The benchmark architectures are described below.\n\u2022Logistic Regression [36]: Logistic regression models the probabilities for classi\ufb01cation problems with two\npossible outcomes.\n\u2022Gradient Boost [37]: Gradient Boost is an additive model in a forward stage-wise fashion for classi\ufb01cation.\n\u2022Decision Tree [38]: Decision tree is a non-parametric supervised learning method used for classi\ufb01cation.\n\u2022Handcrafted Features+Attention (HCF+Att) [32]: An attention based architecture which uses handcrafted\nfeatures (HCF) for fake news detection. It can also provide explanations in a classi\ufb01cation task.\n\u2022Handcrafted Features+LSTM (HCF+LSTM): A basic 1-layer LSTM architecture which uses handcrafted\nfeatures (HCF) for the fake news detection task.\n\u2022Proposed Architecture: Latent Features using\nLongformer based Sentence Embedding+Attention\n(LFLSE+Att): LFLSE+Att is the attention based architecture we propose in this work and described in\nSection 4.\n9\nAPREPRINT - SEPTEMBER 27, 2021\nMethod Accuracy F Score Precision Recall\nLogistic Regression 0.861 0.869 0.906 0.861\nGradient Boost 0.880 0.883 0.897 0.880\nDecision Tree 0.815 0.815 0.816 0.815\nHCF+Att 0.679 0.808 0.688 0.979\nHCF+LSTM 0.685 0.799 0.714 0.909\nLFLSE+Att 0.882 0.919 0.874 0.970\nTable 4: Misinformation Detection on News Dataset\nMethod Accuracy F Score Precision Recall\nLogistic Regression 0.839 0.858 0.908 0.839\nGradient Boost 0.748 0.820 0.950 0.748\nDecision Tree 0.857 0.857 0.860 0.857\nTable 5: Misinformation Detection on Tweet Dataset\n5.4 Performance Analysis\nThe classi\ufb01cation results on news dataset are shown in Table 4. We can see that the latent features extracted using\nLongformer based Sentence Embedding-Attention (LFLSE-Att) performs best compared with the other architectures\non the MMCoVaR news dataset using the same experiment setup with an accuracy and F-Score of 0.882 and 0.919,\nrespectively. The performance of LFLSE-Att in terms of recall is 0.970, which is close to the best score (0.979). This\npoints to the fact that features extracted from the Longformer are potentially more useful compared to handcrafted\nfeatures for classifying news into fake or real. In addition, the performance of Handcrafted Features-Attention (HCF-Att)\nin terms of recall is better than the other models, while Logistic Regression performs best in terms of precision. The\nbaseline performances of the classi\ufb01cation we provided here can be used for comparison with other models in the future.\nFurthermore, more classes of features including visual information and social media information can be added into our\narchitecture, if desired, to construct a composite classi\ufb01er engine.\nThe classi\ufb01cation results on tweets are shown in Table 5. Here, logistic regression outperforms other methods in terms\nof F-Score and Recall.\nTag Description\nSYM Symbol\nRB Adverb\nCD Cardinal number\nJJ Adjective\nVBZ Verb,3rd person singular present\nMD Modal\nPRP Personal pronoun\nNNP Proper noun, singular\nNNS Noun, plural\nWRB Wh-adverb\nCC Coordinating conjunction\nVBG Verb, gerund or present participle\nVB Verb, base form\n... ...\nTable 6: Examples of PoS tags feature\n6 Conclusion and Future\nThe \u201cinfodemic\u201d caused by the COVID-19 has sparked the spreading of misinformation about COVID-19 and vaccines.\nWe provide a new Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR) consisting of images, text,\nand temporal information. We combine two news media ranking websites, which allows for better accuracy of the\n10\nAPREPRINT - SEPTEMBER 27, 2021\nannotation process for the news dataset. A hybrid stance detection mechanism is proposed for the tweet dataset\nannotation. We also provide several statistics and topic analyses on the news dataset and tweet dataset. We propose a\nnovel baseline modular architecture for fake news classi\ufb01cation using the Longformer. In addition, several benchmark\nperformances of misinformation detection on news and tweet datasets are provided. We expect to continue to add to\nthis data repository by including: (1) more COVID-19 vaccine-related news articles; (2) social media data from more\nplatforms like Sina Weibo (China) and Reddit (U.S.)\nReferences\n[1] WHO. Who covid19 situation report. https://covid19.who.int/ , 2021.\n[2]UN. Un misinformation report. https://www.un.org/en/un-coronavirus-communications-team/\nun-tackling-$%$E2$%$80$%$98infodemic$%$E2$%$80$%$99-misinformation-and-cybercrime-covid-19 ,\n2020.\n[3]Peter Hotez, Carolina Batista, Onder Ergonul, J Peter Figueroa, Sarah Gilbert, Mayda Gursel, Mazen Hassanain,\nGagandeep Kang, Jerome H Kim, Bhavna Lall, et al. Correcting covid-19 vaccine misinformation: Lancet\ncommission on covid-19 vaccines and therapeutics task force members. EClinicalMedicine , 33, 2021.\n[4]Sahil Loomba, Alex de Figueiredo, Simon Piatek, Kristen de Graaf, and Heidi J Larson. Measuring the impact of\nexposure to covid-19 vaccine misinformation on vaccine intent in the uk and us. medRxiv , 2020.\n[5]Xinyi Zhou, Apurva Mulay, Emilio Ferrara, and Reza Zafarani. ReCOVery: A multimodal repository for covid-19\nnews credibility research. In Proceedings of the 29th ACM International Conference on Information & Knowledge\nManagement , pages 3205\u20133212, 2020.\n[6] Ad Fontes Media. Media bias chart. https://www.adfontesmedia.com/ , 2021.\n[7] MBFC. Media bias/fact check. https://mediabiasfactcheck.com/ , 2021.\n[8]Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Darrin Eide, Kathryn Funk,\nRodney Kinney, Ziyang Liu, William Merrill, et al. Cord-19: The covid-19 open research dataset. ArXiv , 2020.\n[9]Koyel Chakraborty, Surbhi Bhatia, Siddhartha Bhattacharyya, Jan Platos, Rajib Bag, and Aboul Ella Hassanien.\nSentiment analysis of covid-19 tweets by deep learning classi\ufb01ers\u2014a study to show how popularity is affecting\naccuracy in social media. Applied Soft Computing , 97:106754, 2020.\n[10] Catherine Ordun, Sanjay Purushotham, and Edward Raff. Exploratory analysis of covid-19 tweets using topic\nmodeling, umap, and digraphs. arXiv preprint arXiv:2005.03082 , 2020.\n[11] Rabindra Lamsal. Design and analysis of a large-scale covid-19 tweets dataset. Applied Intelligence , pages 1\u201315,\n2020.\n[12] Md Yasin Kabir and Sanjay Madria. Coronavis: A real-time covid-19 tweets data analyzer and data repository.\narXiv preprint arXiv:2004.13932 , 2020.\n[13] Umair Qazi, Muhammad Imran, and Ferda O\ufb02i. Geocov19: a dataset of hundreds of millions of multilingual\ncovid-19 tweets with location information. SIGSPATIAL Special , 12(1):6\u201315, 2020.\n[14] Matthew DeVerna, Francesco Pierri, Bao Truong, John Bollenbacher, David Axelrod, Niklas Loynes, Cristopher\nTorres-Lugo, Kai-Cheng Yang, Fil Menczer, and John Bryden. Covaxxy: A global collection of english twitter\nposts about covid-19 vaccines. arXiv preprint arXiv:2101.07694 , 2021.\n[15] Shahan Ali Memon and Kathleen M Carley. Characterizing covid-19 misinformation communities using a novel\ntwitter dataset. arXiv preprint arXiv:2008.00791 , 2020.\n[16] Parth Patwa, Shivam Sharma, Srinivas PYKL, Vineeth Guptha, Gitanjali Kumari, Md Shad Akhtar, Asif Ekbal,\nAmitava Das, and Tanmoy Chakraborty. Fighting an infodemic: Covid-19 fake news dataset. arXiv preprint\narXiv:2011.03327 , 2020.\n[17] Tamanna Hossain, Robert L Logan IV , Arjuna Ugarte, Yoshitomo Matsubara, Sean Young, and Sameer Singh.\nCovidlies: Detecting covid-19 misinformation on social media. In Proceedings of the 1st Workshop on NLP for\nCOVID-19 (Part 2) at EMNLP 2020 , 2020.\n[18] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore: Evaluating text\ngeneration with bert. arXiv preprint arXiv:1904.09675 , 2019.\n[19] Lucas Ou-Yang. Newspaper3k: Article scraping and curation, 2020.\n[20] Twitter. Twitter developer api. https://developer.twitter.com/en/docs/twitter-api , 2021.\n11\nAPREPRINT - SEPTEMBER 27, 2021\n[21] Andreas Hanselowski, Avinesh PVS, Benjamin Schiller, Felix Caspelherr, Debanjan Chaudhuri, Christian M\nMeyer, and Iryna Gurevych. A retrospective analysis of the fake news challenge stance detection task. arXiv\npreprint arXiv:1806.05180 , 2018.\n[22] Glenda M McClure. Readability formulas: Useful or useless? IEEE transactions on professional communication ,\n00(1):12\u201315, 1987.\n[23] Dani Gunawan, CA Sembiring, and MA Budiman. The implementation of cosine similarity to calculate text\nrelevance between two documents. In Journal of Physics: Conference Series , volume 978, page 012120. IOP\nPublishing, 2018.\n[24] Twitter. Twitter developer policy. https://developer.twitter.com/en/developer-terms/\nagreement-and-policy , 2021.\n[25] Github. Twarc. https://github.com/DocNow/twarc , 2021.\n[26] GitHub. Hydrator. https://github.com/DocNow/hydrator , 2021.\n[27] Mingxuan Chen, Xinqiao Chu, and K.P. Subbalakshmi. MMCoVaR: Multimodal COVID-19 vaccine focused\ndata repository. https://drive.google.com/drive/folders/1LGfD0mdup7va_SME0sncg-h3ADoCZyEZ?\nusp=sharing , 2021.\n[28] Medicines & Healthcare products Regulatory Agency. Vaccine bnt162b2 \u2013 condi-\ntions of authorisation under regulation 174 \u2013 2 december 2020, amended on 30 decem-\nber 2020, 28 january 2021 and 30 march 2021. https://www.gov.uk/government/\npublications/regulatory-approval-of-pfizer-biontech-vaccine-for-covid-19/\nconditions-of-authorisation-for-pfizerbiontech-covid-19-vaccine , 2021.\n[29] David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. the Journal of machine Learning\nresearch , 3:993\u20131022, 2003.\n[30] Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv preprint\narXiv:2004.05150 , 2020.\n[31] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems , pages\n5998\u20136008, 2017.\n[32] Mingxuan Chen, Ning Wang, and K.P. Subbalakshmi. Explainable rumor detection using inter and intra-feature\nattention networks. KDD TrueFact Conference , 2020.\n[33] Sebastian Ruder. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747 ,\n2016.\n[34] Edward Loper and Steven Bird. NLTK: the natural language toolkit. arXiv preprint cs/0205028 , 2002.\n[35] Kathleen C Fraser, Jed A Meltzer, and Frank Rudzicz. Linguistic features identify alzheimer\u2019s disease in narrative\nspeech. Journal of Alzheimer\u2019s Disease , 49(2):407\u2013422, 2016.\n[36] David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. Applied logistic regression , volume 398. John\nWiley & Sons, 2013.\n[37] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,\nV . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn:\nMachine learning in Python. Journal of Machine Learning Research , 12:2825\u20132830, 2011.\n[38] S Rasoul Safavian and David Landgrebe. A survey of decision tree classi\ufb01er methodology. IEEE transactions on\nsystems, man, and cybernetics , 21(3):660\u2013674, 1991.\n12", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "MMCoVaR: multimodal COVID-19 vaccine focused data repository for fake news detection and a baseline architecture for classification", "author": ["M Chen", "X Chu", "KP Subbalakshmi"], "pub_year": "2021", "venue": "Proceedings of the 2021 IEEE/ACM \u2026", "abstract": "The outbreak of COVID-19 has resulted in an \"infodemic\" that has encouraged the propagation  of misinformation about COVID-19 and cure methods which, in turn, could negatively"}, "filled": false, "gsrank": 362, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3487351.3488346", "author_id": ["kgxVbkwAAAAJ", "", "SSAaI4AAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:sWcQXmv9BwIJ:scholar.google.com/&output=cite&scirp=361&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D360%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=sWcQXmv9BwIJ&ei=RrWsaO_lEeHUieoP9LKZ6AI&json=", "num_citations": 42, "citedby_url": "/scholar?cites=146364150494291889&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:sWcQXmv9BwIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2109.06416"}}]