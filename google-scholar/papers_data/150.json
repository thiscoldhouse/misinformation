[{"title": "The role of the big geographic sort in online news circulation among US Reddit users", "year": "2023", "pdf_data": "1\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreportsThe role of the big geographic \nsort in online news circulation \namong U.S. Reddit users\nLia Bozarth 1, Daniele Quercia 2,3*, Licia Capra 4 & Sanja \u0160\u0107epanovi\u0107 2\nPast research has attributed the circulation of online news to two main factors\u2014individual \ncharacteristics (e.g., a person\u2019s information literacy) and social media effects (e.g., algorithm-\nmediated information diffusion)\u2014and has overlooked a third one: the critical mass created by \nthe offline self-segregation of Americans into like-minded geographical regions such as states (a \nphenomenon called \u2018The Big Sort\u2019). We hypothesized that this latter factor matters for the online \nspreading of news not least because online interactions, despite having the potential of being global, \nend up being localized: interaction probability is known to rapidly decay with distance. Upon analysis \nof more than 8M Reddit comments containing news links spanning four years, from January 2016 to \nDecember 2019, we found that Reddit did not work as an \u2018hype machine\u2019 for news (as opposed to what \nprevious work reported for other platforms, circulation was not mainly caused by platform-facilitated \nnetwork effects). Rather, news circulation in Reddit worked as a supply-and-demand system: news \nitems scaled linearly with the number of users in each state (with a scaling exponent \u03b2  \u22481 , and a \ngoodness of fit R2\u22480.95  ). Furthermore, deviations from such a universal pattern were best explained \nby state-level personality and cultural factors ( R2\u2248{0.12, 0.39 } ), rather than socioeconomic \nconditions ( R2\u2248{0.15, 0.29 } ) or political characteristics ( R2\u2248{0.06, 0.21 } ). Higher-than-expected \ncirculation of any type of news was found in states characterised by residents who tend to be less \ndiligent in terms of their personality (low in conscientiousness) and by loose cultures understating \nthe importance of adherence to norms (low in cultural tightness). Interestingly, the combination of \nthose factors with low levels of education was then associated with the circulation of a particular type \nof news, that is, misinformation. These results suggest that online interactions are geographically \nbounded and, as such, news circulation cannot be studied purely as an Internet phenomenon but \nshould be grounded into a user\u2019s offline cultural environment, which has become increasingly \nsegregated over the decades, and is admittedly hard to change.\nPast research has attributed the circulation of online news to two main classes of factors. The first class includes \nindividual characteristics such as a person\u2019s personality and culture, education attainment, and political-lean-\ning1\u20139, often reinforced by confirmation  bias10,11. For example, users highly driven by self-presentation (personal-\nity) share more  news12,13, and political leaning affects the type of political news users  share14. Further, those with \nlower information literacy were observed to be more likely to spread  misinformation15.\nThe second class of factors has to do with the ways social media are engineered to work as a \u201cHype Machine\u201d16. \nFor instance, existing social media platforms\u2019 \u201cfriends suggestion algorithms\u201d\u2014which tend to disproportionately \nrecommend friends of friends who likely share similar behaviors and beliefs\u2014have amplified the online cluster -\ning of individuals into homophilous communities. Users were also observed to be more likely to team up with \nlike-minded others, which is commonly known as the echo chamber or filter bubble  effect17,18. Another platform-\namplified feature is affect. Platform algorithms were observed to preferentially recommend emotionally salient \nand polarizing content to boost user engagement and content  sharing19,20. Prior studies demonstrated that these \nsmall and densely connected online communities had significantly increased the size, depth, and speed of online \n spreading21. Indeed, online news circulation follows news  cycles22, influences social media  users23 who, in turn, \ninfluence each  other24,25, even beyond informational  purposes13, creating a news distribution system that goes \nbeyond a simple supply-and-demand  system26.\nThere is, however, a third overlooked factor: the offline self-segregation of Americans into like-minded \ncommunities such as geographic states, a phenomenon which Bill Bishop dubbed as \u201cThe Big Sort\u201d27. Work by OPEN\n1University of Michigan, Ann Arbor, USA. 2Bell Labs, Cambridge, UK. 3CUSP , Kings College London, London, \nUK. 4University College London, London, UK. *email: quercia@cantab.net\n2\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/Bishop and others has illustrated that people in the U.S. have been increasingly choosing to live in neighbor -\nhoods populated with others who are just like themselves in values and beliefs. Furthermore, this sorting has \nresulted in geographical regions (e.g., states) with distinct lifestyle and  culture28\u201330, political  ideology31, and even \n personality32\u201334. As an example, work by Rentfrow et\u00a0al.33 showed that the states of Utah and New Y ork are the \nmost and least agreeable among all the states, respectively. South Carolina is the most conscientious, and Maine \nthe least. Similarly, Mississippi has the most restrictive cultural and social norms, whereas California has the most \n loose33. Furthermore, states\u2019 personality and culture are indicative of their voting  patterns32. Previous research \nfound that the circulation of physical newspapers follows readership  interests35. Moreover, each newspaper \nmatches its political slant to its readers\u2019  slant36. The process of Americans geographically sorting themselves over \nthe past four decades into homogeneous communities still continues. Thus far, it is unclear whether it has had \nany impact on online  news circulation.\nTo ascertain that, we examined the geographical circulation of news on Reddit, a popular online content \naggregation and discussion website. We chose Reddit for our analysis given that it has one of the most compre -\nhensive publicly available archived datasets (available under pushshift.io). Reddit consists of many communi-\nties (or areas of interest) called subreddits that function akin to online forums. Users can make public posts \non these subreddits and others can then comment on the original posts. For instance, a user can post a news \narticle about Covid-19 on the subreddit r/news, and others can then discuss the article with each other. Unlike \nsocial media platforms such as Twitter and Facebook, Reddit is an anonymous platform without the concept of \n\u2018friends\u2019 . This anonymity in Reddit might have the advantage of removing the typical social pressure mechanism \nof circle-of-friend platforms like Facebook or Twitter. Therefore, Reddit is the ideal platform to single out and \nstudy geographic factors and their influence in news circulation.\nData\nReddit data. We used Pushshift\u2019s37 publicly available comments dataset from January 2016 to December \n2019. This dataset contained all comments from all public and quarantined subreddits. We then used the method \nfrom Balsamo et\u00a0al.38 to assign users to their geographical location. Specifically, we first identified a list of 2.87K \nsubreddits that can be matched to one of the U.S. states (e.g., r/seattle, r/california). Then, for each user who had \nposted at least once in these subreddits, we assigned the user to the corresponding U.S. state. Note that if a user \nhad posted in multiple states, we assigned the user the state with the majority of posts. As a result, 82.4% of users \nhad only posted in a single state, and 95.2% of users had posted in at most 2 states. Finally, only 3.8% of users \nwere not assigned a state due to not having a majority state. We identified approximately 3M users who were \nlocated in one of the 50 U.S. states. The correlation between a state\u2019s population and its number of Reddit users \nis shown in Fig.\u00a0 1. We saw that the number of Reddit users per state scaled linearly with the state\u2019s population \n( \u03b2=0.99 ). Additionally, approximately 1.4 billion (or 35%) comments on Reddit can be mapped to a user in \none of the 50 U.S. states. From these 1.4B comments, we identified a total of 8.23M (0.6%) comments containing \nnews links (as URLs). We then classified a Reddit comment as either reputable , fake, or low credibility  based on \nthe domain  that the news URL pointed to, using the groundtruth labeling procedure described next.\nWebsite groundtruth labels. We compiled a list of news websites (or domains) from various sources \nwidely used in researching online news  circulation39. Each news site was then labelled as one of three types\u2014\nfake, lowcred, or reputable \u2014as follows.\nReputable.  We used three sources to compile a list of reputable news sites: Vargo et\u00a0al.40, Alexa (alexa.com), and \nMedia Bias/Fact Check (mediabiasfactcheck.com). This resulted in 8.9k total reputable news sites.\nFake. Based on a detailed meta-review in related  work39, we compiled a list of questionable news sites from \n5 existing sources: Zimdars  list41, Media Bias/Fact Check,  PolitiFact42, the Daily  Dot43, and Allcott et\u00a0al.44. By \nusing the descriptions and granular labels of each of the five sources, we categorized a domain as fake  if it had \nroutinely published completely fabricated news articles. There were a total of 933 unique fake news sites across \nall five sources.\nLowcred. Unlike fake news sites, low-credibility news sites publish articles with mixed factualness rather than \ncompletely fabricated content. We included domains that were described by the previous 5 sources as unreli-\nable, hyperpartisan, clickbait, rumor, pseudoscience, and conspiracy sites, ending up with a total of 1801 low-\ncredibility news domains.\nUsing the compiled domain credibility lists, we labelled individual news articles with corresponding domain \nlabels. Hence, we attributed misinformation at the level of the publisher (i.e., domain) and not at the level of the \nindividual news article, which would be more precise. Nevertheless, the approach we took is widely used in misin-\nformation  studies39. Additionally, while our lists of news sites are widely popular in researching misinformation, \nprior work had highlighted that the different lists had been created using varying labeling  procedures39. As such, \nwe included additional steps detailed in Supplementary Material to validate our news site classification approach. \nBriefly, we compared our labels ( fake, lowcred , and reputable ) to trustworthiness scores of news sites provided \nby professional fact-checkers45, and observed that reputable news sites had the highest average trustworthiness \nscore (0.66), followed by low-credibility news sites (0.10), and finally fake news sites (0.02), suggesting that our \nlabels were well aligned with the ratings of professional fact-checkers.\n3\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/Classification of news comments. The circulation of news on Reddit (Table\u00a0 1) amounts mainly to repu-\ntable content: 7.6M (93%) comments contained reputable news articles, while only 116.2K contained fake news \narticles. We also observed that reputable news sites attracted, on average, only 36 Reddit comments, low-credi-\nbility 26, and fake 8. Those low average values are due to the frequency distribution of the number of comments \nper news site being skewed: most news sites attract a few comments only, while a few attract most comments \n(e.g., approximately one-fifth of all fake news comments contained URLs from breitbart.com). To then ascertain \nthat our localization procedure did not select a specific type of user but selected a set representative of the gen-\neral user population, we compared the 3M users with assigned locations to another 3M users without locations. \nWe observed that the average numbers of comments posted by users of the two groups were comparable, with \njust a small difference: 1.7% of all geotagged users had posted at least 1 comment containing fake news URLs, \nwhereas only 0.6% of non-geotagged users did. This difference can be explained by non-geotagged users being \nless invested in U.S. news as, on average, they are less likely to all be from the U.S.\nState-level attributes. We included the following state-level attributes that were shown by prior studies \nto be indicative of individual and community\u2019s tendency to share  misinformation2,5,46. These attributes were \ncategorized into personality and cultural factors, socio-economic conditions, and political attributes (Table\u00a02).\nPersonality and culture. Prior work had observed significant individual-level associations between personal-\nity/culture and circulation of  misinformation2,6,47,48. For instance, individuals scoring high in conscientiousness \nare significantly less likely to spread false  content2. Similarly, a lower level of extraversion is associated with a \nhigher discernment of  misinformation49. One of the most commonly used personality  tests is the Big Five test, \nwhich measures five main traits (abbreviated as OCEAN) 50,51: Openness (creative and open-minded), Conscien-\ntiousness (organised and responsible), Extraversion (sociable and energetic), Agreeableness (compassionate and \ncompliant), and Neuroticism (anxious and emotionally unstable). We used the test results of 1.69M respondents \nin the U.S.33. Analyses of these results found the traits to differ across  states34,52, and to influence a variety of \naspects, including information and knowledge sharing  preferences53\u201355. Another trait related to the task at hand \n(circulation of information) is cultural tightness . This measures the propensity of a society to  conformity56, and \nhas been associated with a variety of aspects concerning information sharing practices, such as digital engage-\nment, knowledge sharing, and acceptance of diverse  opinions57\u201361. This latter variable reflects also the propensity \nof holding adherence to norms in high  regard59, and might well be hindering the spreading of misinformation.\nTable 1.  Summary statistics for news comments. These comments are Reddit posts that contain links to news \narticles of three types.News_type Unique_comments Unique_user Unique_news_site Unique_urls Top_news_sites\nFake 116212 45485 933 60754breitbart.com, dailywire.com, thegateway-\npundit.com\nLowcred 536701 160146 1801 264010dailymail.co.uk, washingtonexaminer.com, \ndailycaller.com\nReputable 7645044 717198 5221 3319213 nytimes.com, washingtonpost.com, wsj.com\nFigure\u00a01.  Reddit users and comments per state: The x -axis denotes each state\u2019s population (logged) and the \ny-axis is the number of Reddit users/comments from each state. We see that the number of Reddit users/\ncomments scaled linearly with the population ( \u03b2=1.01/1.07  ), with an R2=0.84/0.81 .\n4\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/Socio\u2011economic. Some socioeconomic factors are indicative of an individual\u2019s political knowledge, information \nliteracy, and tendency to consume and diffuse news or  misinformation5,44,46. As an example, individuals who are \nsocio-economically well-off tend to have more political  knowledge62, which is associated with having a better \nability in telling apart factual news from  misinformation46. Overall, in terms of socio-economic indicators, we \nincluded five variables available from the 2019 American Community Survey: population (population ); popula -\ntion density as a proxy for urbanization (density); percentage of population over 25 years old without high school \ndiploma (no_highschool); percentage of person of color (minority ); and gdp per capita (gdp ).\nPolitical. The extensive literature  review1, found that news sharing is \u2018a specific kind of participatory behavior \nthat is dependent on people\u2019s [...] political interests\u2019 and that content featuring politics, government, or economics \nis increasingly spread during the heightened political  activity63. As such, it is valuable to consider environmental \ninfluences, such as political participation and leaning on general news  sharing1,63. Specifically for fake news, it is \nrepeatedly found to be politically driven and is more likely to be consumed and shared by conservative-leaning \nindividuals and online  communities5,44,46,64\u201366. Therefore, we postulated that states\u2019 political attributes would be \namong the most indicative of the states\u2019 tendency to circulate particular news and, especially, misinformation, \nand consequently included three political attributes: percentage gap between the population leaning towards \nthe Republican party and that leaning towards the Democratic party (republican ) provided by the 2016 Gallup \nPoll; whether a state was a battleground state during the 2016 presidential election or not (swing_state ) provided \nby the Center for Politics; and the political engagement score (political )  from67, which was calculated using the \nweighted sum of multiple metrics (i.e., percentage of registered voters, total political contribution, and percent-\nage of residents who participated in local political) provided between 2016 and 2019 by the American Commu-\nnity Survey, the U.S. Census Bureau, the Center for Responsive Politics, and Ballotpedia.\nTo those socio-economic attributes, we added a state\u2019s Reddit adoption rate as a control varaible. That is \nbecause online news circulation might well be explained by online adoption rates, which, in turn, happened to \nbe correlated with some of the socio-economic attributes in our case (Figure\u00a0 2): negatively with extraversion, \ncultural_tightness , and no_highschool , and positively with political . In other words, states that are social, culturally \nrestrictive, and have low education attainment have fewer-than-expected users on Reddit.\nMethods\nScaling laws of news circulation. To study circulation within states, we resorted to urban science research \nin the area of complex  systems68,69. Such work has shown that a variety of urban measures such as number of \npatents and income are power-law functions of population  size69,70. Y et, we do not know whether that is the case \nfor news circulation online: critics might rightly say that the process of online circulation may have little to do \nwith a user\u2019s offline conditions or may be just \u201ctoo complex\u201d to be subject to laws.\nTo investigate the relationship between news circulation and population size, we used a methodology \nthat was put forth by Bettencourt et\u00a0al.69. Say that Y  denotes circulation within a state, then this power-law \ndependency translates into saying that Y=constant \u00b7N\u03b2 . By then taking the log of both sides, we obtain: \nlog(Y )=\u03b2\u00b7log(N)+constant  , where N is the population size, constant  is a normalization constant, and \u03b2 is \nthe so-called scaling exponent . Typically, the values of this scaling exponent are grouped in three ranges:\n0.8>\u03b2 (sublinear ) is found for material quantities displaying economies of scale  (e.g., infrastructure);\n0.8\u2264\u03b2< 1.1 (linear ) is found for individual human needs (e.g., jobs, houses);Table 2.  List of state-level attributes.Category Variable name Description\nPersonality and cultureOpenness Imaginative, spontaneous\nConscientiousness Disciplined and careful\nExtraversion Social and fun-loving\nAgreeableness Trusting and helpful\nNeuroticism Anxious, pessimistic\nCultural_tightness Restrictive social norms and punishments for deviance\nSocio-economicdensity Population density (proxy for urbanization) 2019\nGdp State\u2019s gdp per capita 2019\nMinority Percentage of person of color 2019\nNo_highschool Percentage of population without a high school diploma 2019\nPopulation State population on 2019\nPoliticalPolitical Political engagement score\nRepublican Percentage prefer republican subtract percentage prefer democrat\nSwing_state Binary score of 0 (not swing state) or 1 (swing state)\nPlatform Adoption Adoption rate of reddit\n5\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/1.1\u2264\u03b2< 1.3 (superlinear ) is found for measures reflecting wealth creation and innovation with increasing \nreturns , which are typically associated with the intrinsically social nature of large cities (e.g., number of pat-\nents, number of successful startups).\nThree types of news. Since the number of Reddit users alone could explain a great portion of the variance \nin the online circulation of the three types of news, we used the following approach to separate the impact of \nplatform adoption and the characteristics of a state. Given a news type s\u2208{lowcred ,fake ,reputable } and state \ni, let \u03b2s be the scaling exponent for news type s, and \u03b2s\n0 the corresponding intercept term, fs,i denote the total \nnumber of news items of type s posted by users from i (in log value), and Ni be the number of users in state i \n(in log value). We then run the simple regression fs,i=\u03b2s\n0+\u03b2sNi+\u03b5s,i to determine the residual \u03b5s,i , which we \ncall the Residual Circulation(s,i) score of state i for the news type s. This is the portion of the circulation of news \nof type s in a state i that is not explained by the number of users in i. Next, we took that residual and run the \nfollowing model:\nwhere v1 , v2 , and vn are the predictors listed in Table\u00a0 2. Note that all variables were standardized with z -scores \nto make regression coefficients easier to interpret. For comparability\u2019s sake, in addition to this circulation met -\nric based on the residual, we also used the average number of news comments as as an alternative metric (i.e., \nCirculation (s,\u00a0i) was calculated as the average number of comments containing URLs to news type s  posted by \nReddit users from state i), and reported the results in Supplementary Material; both metrics showed comparable \nresults.\nResults\nThe role of platform-facilitated news diffusion. For each type of news (i.e., reputable, low-credibility \nand fake), we computed the cumulative fraction of articles that reached at least a given number of authors or \nstates (Fig.\u00a0 3a). We observed that geographical diffusion is rare on Reddit. More specifically, 74.8% of all repu-\ntable news articles were only posted by a single user who was located in the U.S., and 86.7% by at most 2 users. \nThe values were comparable for fake and low-credibility news. Additionally, the number of news URLs that were \nposted in 5 or more states was only 209.7K for (6.3% of) reputable news comments, 11.0 K for (4.8% of) low-\ncredibility ones, and 2.23K for (4.2% of) fake ones. Furthermore, we also observed that the time gaps between \nthe comments were lengthy (Fig.\u00a0 3b). For example, for all news URLs that reached exactly 5 states (only 6% of \nnews had reached 5 or more states), the average cascading time was over a year. We also ran analysis using the \nmedian cascading time, and results were similar. In sum, our results demonstrate that circulation of news on \nReddit is unlikely to be a function of diffusion, and there are several likely explanations for it. First, to reduce \ncontent duplication, Reddit moderators typically discourage users from reposting the same content on the same \nsubreddit or even on different  subreddits71. Another explanation could be geographical segregation. As the lit-(1) Residual Circulation(s ,i)=\u03b2\u2032\n0+\u03b2\u2032\n1\u2217v1+\u03b2\u2032\n2\u2217v2\u00b7\u00b7\u00b7+ \u03b2\u2032\nn\u2217vn+\u03b5\u2032,\nFigure\u00a02.  Cross-correlation between state-level factors. Statistically insignificant correlations (p -value\u22650.05 ) \nare grayed out. The matrix was created using version 0.92 of the following R package https:// cran.r- proje  ct. org/  \nweb/ packa  ges/ corrp  lot.\n6\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/erature showed for platforms other than  Reddit72,73, online users who live far away could be less likely to interact \nwith each other, thus reducing out-of-state news circulation in the case of Reddit. Our data allowed us to test this \nlatter explanation, and we did so next.\nThe role of geographical proximity. To test the extent to which online interactions are impacted by geographical \ndistance, we adopted a metric from related  work72. More specifically, we first generated a user-to-user comment \nnetwork in which an edge exists between a pair of users, if one user had commented on the other\u2019s comment/\npost74. The resulting network was unidirectional and weighted. We then computed the probability of having had \nan interaction, denoted as Connectivity d , between a pair of users who are at d physical distance apart (measured \nin km). The distance d between a pair of users was calculated as the distance between the geographical centers \nof the states that the pair resided in (users from the same state have d=0 ). Mathematically, for a fixed distance \nd where d={0km, 100km, 200km, 300km...}  , we calculated Connectivity d as:\nwhere Nd is the total number of users that were approximately d  distance apart offline, and |comments i,j|d is the \ntotal number of unique pairs of users who lived d  distance apart and who interacted on Reddit (this number is \nthe corresponding weight on the user-to-user comment network). The denominator 1\n2\u2217Nd\u2217(Nd\u22121) is the \ntotal number of possible user pairs at distance d . In other words, given d , Connectivity d is the number of user \npairs that interacted with each other normalized by the total number of possible user pairs. We then plotted the \nlogged Connectivity d in relation to the logged physical distance d  in Fig.\u00a0 4(red line). Consistent with prior  work72, \nwe found that Connectivity d rapidly decreases with d . For instance, users located approximately 100km apart had \n4.35e\u22125 probability of interacting with each other via comments. Whereas, the probability decreased to 2.6e\u22125 \nfor users located 1000km apart. In other words, geographic proximity increases the probability of interacting \n(i.e., users located closer in physical distance are more likely to interact with each other): indeed, the probability \nof interacting is highest for users of the same state ( 1.02e\u22124 ) as it is one order of magnitude higher than the out-\nof-state\u2019s probability ( \u22652.6e\u22125 ). Next, to ensure that our observation was not primarily driven by interactions on \nlocation-specific subreddits (e.g., r/seattle, r/california), we also limited the scope  of interaction to non-location \nsubreddits. To that end, we updated the definition of |comments i,j|d to be the number of unique pairs of users \nwho lived d  distance apart and, crucially, who also had interacted on subreddits that do not have a geographical \ncomponent. We found that the red and green lines overlap (Fig.\u00a0 4), and that non-geographically salient users still \npreferentially interacted with others in closer geographical proximity (green line), suggesting that the observed \ndecay with distance was not dependent on our localization procedure. That is to say, users from Seattle are not \nonly more likely to interact with each other in r/seattle but also in other, non-location subreddits. That is not \nentirely surprising as online interactions have been shown to be bounded by geography, not least because social \nnetworks are based on real-world friends/contacts (as an example, we applied the same Connectivity d formula to \na publicly available Facebook graph, and, in Supplementary Material, we observe that interactions on Facebook \nare even more geographically bounded than those on Reddit). Y et, in the case of Reddit, this result is remarkable \nbecause the platform is an anonymous forum where both a user\u2019s identity and physical location are hidden from \nother users. Such Reddit\u2019s anonymity lifts social pressure, and so geographically-bounded information spreading \nis more likely to stem, not from homophily at the circle-of-friends level (as in other social networks), but from \npeople having like-minded individuals in their locations (i.e., states).\nThe scaling laws of news circulation. Given that interactions are geographically bounded, it was reason-\nable to hypothesize that a state\u2019s news circulation is best explained by the state\u2019s variables rather than platform-\nspecific variables. As previously mentioned, based on the scaling laws literature, one of these state variables is the (2) Connectivity d=|comments i,j|d\n1\n2\u2217Nd\u2217(Nd\u22121),\n(a)DiffusionR each. Cumulati vefractio nofnewsarticles that\nreache datleast agivennumber (x-axisv alue)o fauthors orstates.\nWesawthata pproximately 90%o fallnewsarticles were only\nposte dby1or2usersirrespecti veofnewstype.\n(b)Diffusion Speed. Average cascadin gtimef ornewsarticles that\nreached atleasta givennumber( x-axisv alue) ofauthorso rstates.\nHowever,cascading time wasexceedingl ylongf orallnewstypes: for\nexample, average cascading time forn ewsthatreached 2states was\n226days, andf orthose thatreached 5states was522days.\nFigure\u00a03.  Diffusion of the three types of news (news type classification is based on domains) in Reddit.\n7\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/number of users. We indeed found evidence that the number of Reddit users in a state is an important predictor \nof news circulation. It alone explained 95% ( R\u22480.95 ) of the variance: 1 unit log scale gain in number of users is \napproximately correlated with exactly 1 unit log scale gain in news circulation ( \u03b2\u22481 ) for all three types of news \n(Fig.\u00a05), suggesting that news circulation on Reddit works as a supply-and-demand system.\nThe role of the big sort. To explore why news circulation might deviate from the supply-and-demand \nmodel at times, we studied the associations between the news circulation residual metric Residual Circulation(s ,i) \nand state-level attributes. Cultural tightness and conscientiousness had the highest correlation (absolute value) \nwith circulation across all news types (Fig.\u00a0 6), not least because the two variables are correlated with each other \n( r[cultural _tightness ,conscientiousness ]= 0.47, p<0.05 in Fig.\u00a0 2). This translates into saying that conscien-\ntious states with restrictive social norms circulated fewer news items than what was expected by their Reddit \nadoption. The association was even more prominent for reputable  news. For example, the correlation between \ncultural tightness  and Circulation  for fake  news was \u22120.31 ; the correlation was \u22120.53 for reputable  news. In \nother words, users from states ranked high in conscientiousness  were posting fewer reputable and fake news items \nthan what was expected from their numbers of Reddit users. Next, focusing on political variables, we found that \nthe presence of republican  voters was noticeably negatively correlated with circulation of reputable and low-\ncredibility news but not of fake news (in Fig.\u00a0 6, r[circulation ,\u00a0republican ] is negative for reputable  and lowcred , but \nbecomes insignificant for fake ). That result is in line with prior studies showing that the majority of misinforma-\ntion is conservative-leaning5,75. Also, that result has an additional explanation: states that are slightly more likely \nto use Reddit are democratic ones ( r[adoption, republican ]=\u2212 0.23, p>=0.05 in Figure\u00a0 2), as further detailed \nFigure\u00a04.  Geographic distance vs. Connectivity . The x -axis denotes the geographical distance between states\u2019 \ncenters and the y -axis is the probability that a pair of users with x  distance apart offline had interacted with each \nother on Reddit. Finally, the color denotes the scope of interaction. We surprisingly saw that even for subreddits \nwithout an inherent geographical affiliation, users still preferred to interact with others of closer geographical \nproximity.\nFigure\u00a05.  The scaling of news circulation. The x -axis is the total number of Reddit users from a state, and the \ny-axis denotes the number of posts containing each of the three types of news. We observed that the circulation \nof news approximates a supply and demand system (i.e., \u03b2\u22481.0).\n8\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/in Supplementary Material. Surprisingly, we also saw that swing states with competitive political races were not \nmore likely to circulate significantly more news. Finally, focusing on socioeconomic factors, we observed that \nwealthy states had higher circulation, irrespective of news types.\nNext, we focused on the combined effects of state-level attributes by studying each news type separately. \nFor each, we ran 3 partial regression models (personality and culture, socio-economic, and political) plus one \ncombined model. Each of the models (3 partial + 1 complete) was then fitted using stepAIC , a method that \nstatistically identifies the best combination of independent variables that lead to the best  fit76. AIC estimates the \nmodel\u2019s prediction error (the lower the value, the better the fit of the model), and its values should not be taken \nat face value but are best interpreted in a comparative fashion, allowing for model comparison. We ascertained \nthat there was no multicollinearity among our predictors by computing their Variance Inflation Factor (VIF) \n scores77, and finding them to be \u22642.5 (scores larger than 5 indicate multicollinearity). Since we were interested \nin which variables (personality and culture vs. socio-economic vs. political) best explained news circulation, we \nreport both the complete model and the partial model based on personality plus culture here (Table\u00a0 3), and report \nthe two other partial models in Supplementary Material. The StepAIC method chooses the best combination \nof predictors for a given dependent variable. Hence, the variables not shown in Table\u00a0 3 are those that were not \nFigure\u00a06.  Correlation between circulation and each independent variable. Statistically insignificant correlations \n(p-value\u22650.05 ) are grayed out. The matrix was created using version 0.92 of the following R package https://  \ncran.r- proje  ct. org/ web/ packa  ges/ corrp  lot.\nTable 3.  Residual circulation regression results. \u2217 p < 0.1; \u2217\u2217 p < 0.05; \u2217\u2217\u2217 p < 0.01. The personality and culture \nmodels (1)(3)(5) only used personality and cultural explanatory variables. The complete  models (2)(4)(6) \nused all explanatory variables. For all models, stepAIC selected the most predictive subset of predictors. The \npredictors not shown are those that were not selected by StepAIC to be part of the optimal model.Dependent variable: circulation\nReputable (personality \nand culture) Reputable (complete)Lowcred (personality and \nculture) Lowcred (complete)Fake (personality and \nculture) Fake (complete)\n(1) (2) (3) (4) (5) (6)\nAgreeableness 0.022 (0.014) 0.022 (0.015) 0.038\u2217\u2217 (0.017) 0.033 (0.020)\nConscientiousness \u2212 0.052\u2217\u2217\u2217 (0.015) \u2212 0.053\u2217\u2217\u2217 (0.015) \u2212 0.040\u2217\u2217 (0.016) \u2212 0.054\u2217\u2217\u2217 (0.018) \u2212 0.044\u2217\u2217\u2217 (0.016) \u2212 0.040\u2217 (0.021)\nOpenness \u22120.034 (0.023)\nCultural_tightness \u2212 0.038\u2217\u2217\u2217 (0.014) \u2212 0.025 (0.016) \u2212 0.025 (0.016) \u2212 0.027 (0.018) \u2212 0.036 (0.024)\nNo_highschool 0.032\u2217\u2217 (0.015) 0.054\u2217\u2217 (0.021)\nGdp 0.052\u2217\u2217 (0.019) 0.030\u2217 (0.017) 0.046\u2217\u2217 (0.020)\nDensity \u2212 0.027 (0.017)\nPolitical \u2212 0.023 (0.014)\nConstant \u2212 0.006 (0.012) \u2212 0.006 (0.011) \u2212 0.002 (0.014) \u2212 0.002 (0.013) 0.001 (0.016) 0.001 (0.015)\nObservations 48 48 48 48 48 48\nR2 0.432 0.521 0.261 0.401 0.142 0.349\nAdjusted R 2 0.393 0.451 0.228 0.329 0.123 0.254\nResidual Std. Error 0.081 (df = 44) 0.077 (df = 41) 0.096 (df = 45) 0.089 (df = 42) 0.110 (df = 46) 0.102 (df = 41)\nF Statistic 11.158\u2217\u2217\u2217 (df = 3; 44) 7.438\u2217\u2217\u2217 (df = 6; 41) 7.951\u2217\u2217\u2217 (df = 2; 45) 5.616\u2217\u2217\u2217 (df = 5; 42) 7.608\u2217\u2217\u2217 (df = 1; 46) 3.665\u2217\u2217\u2217 (df = 6; 41)\n9\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/selected by StepAIC as predictors of the optimal model. We found that the complete models were able to explain \na considerable fraction of variances in circulation residual (adjusted R2\u2248{0.25, 0.45}  in Table\u00a0 3). The obtained \nadjusted R  2 values allowed us to compare the importance of different factors. That was possible because these \nvalues, despite being moderate, were akin or above the values found in similar studies, such as the adjusted R 2 of \n0.08\u20130.51 when predicting crime rates from state  outcomes78, or the correlations of 0.10\u20130.65 between upward \nincome mobility and Facebook data-derived social capital  indices79. Further, the variable conscientiousness  was \na significant indicator for lower-than-expected circulation for all types of news for all models; whereas gdp  was \nsignificantly correlated with higher-than-expected circulation. More interestingly, we also saw that, for the per -\nsonality and culture partial models, the adjusted R2\u2248{0.12, 0.39}  . In other words, the R2 differences between \nthe personality and culture models and the complete models were small. As an example, the adjusted R2 for the \nfull model for reputable news was 0.45, whereas the adjusted R2 for the personality and culture model was 0.39 (a \ndifference of only 0.06). In fact, including personality and cultural variables improved the full models\u2019 adjusted R2 \nfrom 0.10 to 0.20 (see Supplementary Material). Additionally, we also saw that personality and culture models had \nhigher adjusted R2 values than, as Supplementary Material shows, models that exclusively used socioeconomic \nconditions (adjusted R2\u2248{0.15, 0.29}  ) or political characteristics (adjusted R2\u2248{0.06, 0.21}  ). As a robustness \ncheck, we also reran our analysis using normalized circulation volume. Specifically, we redefined Circulation (s,\u00a0i) \nas the average number of comments containing URLs to news type s  posted by Reddit users from state i . We then \nreran Eq.\u00a0(1 ). The main findings detailed in Supplementary Material did not change: personality and cultural \nfactors still remained strong indicators of circulation.\nFinally, by comparing the values of the beta coefficients for different news types in Table\u00a0 3, we observed that \ncirculation of any news types was facilitated in states that: are wealthier ( gdp has positive beta \u2019s in Table\u00a0 3), have \nresidents who are less diligent in terms of personality ( conscientiousness  has negative beta \u2019s), and are character -\nized by loose cultures which understate the importance of adherence to norms (  cultural _tightness  has negative \nbeta\u2019s). That holds for all types of news. We then focused on the circulation of misinformation specifically, and \nobserved that was taking place once these three factors were combined with a fourth one: low education levels \n( no_ highschool  has a positive beta  in the complete fake news model in Table\u00a0 3).\nDiscussion\nOur first finding is that platform-facilitated news diffusion within Reddit is limited. Specifically, we observed \nthat geographical diffusion is rare (for example, only 6% of news had reached 5 or more states), as is diffusion \nfrom person to person (for example, 75% of all reputable news articles were only posted by a single user). This \nis in contrast with previous work, which found that other types of social networks (e.g., Facebook and Twitter) \nwork as a \u201cHype Machine\u201d16.Our contrasting results likely stem from the moderation mechanism that Reddit \nemploys to avoid the reposting of the same content, and the posting of highly emotionally-charged content. \nNamely, volunteer moderators run each subreddit, settle disputes, and decide who may or may not participate. \nThey also levy rules on what is appropriate, and what content will stay online as is, be edited, or deleted. A recent \n study80 estimated that in 2020, the volunteer moderators\u2019 labour, if they were commercial moderators, would \ncost Reddit 2.8 per cent of the company\u2019s total revenue in 2019. Importantly, these volunteer moderators have a \nclose connection with their respective communities and in-depth knowledge about community dynamics, which \ncommercial moderators might not be able to replace.\nOur second finding is that Reddit users who are geographically close are more likely to interact, even if we \nwere to remove the interactions that took place in city- or state-related subreddits. This finding is in line with \nprevious literature, which showed that the probability of interaction in any social network exponentially falls \nwith physical  distance72,81,82.\nOur third finding is that news circulation on Reddit works as a supply-and-demand system. We indeed found \nthe scaling exponent of \u03b2 to be exactly 1 (linear) instead of being above 1 (superlinear). This is an interesting \nfinding as linear scaling is associated with elements that require individual maintenance (e.g., water pipes), \nwhile superlinear scaling is associated with the \u201ccreation of information, wealth and resources\u201d69, which could \nhave included the circulation of news online. The unitary scaling points to a novel finding, in that, online news \ncirculation is not amplified on Reddit (as per the Hype Machine  hypothesis16,83) but simply meets the demand.\nOur fourth and last finding is that deviations from the supply-and-demand model are mostly explained by \ngeographical factors. This is a new finding since the geographical side of online news has received little attention. \nFurthermore, we found that these factors include state-level personality and cultural factors rather than, as it \ncould have been hypothesized from previous  studies12,84,85, socio-economic conditions or political characteristics.\nOur work has one main ramification for research focused on \u201cwhy\u201d do people share news and, relatedly, on \n\u201chow\u201d to curtail the spread of misinformation. This has to do with the stability of personality and culture. Adding \nto that the fact that we geographically cluster with similar ones because that increases life satisfaction, the poten-\ntial for algorithms to influence the way we share information (including combating misinformation) is limited, \nat least for Reddit. Hence, we would be better off combating the production of misinformation altogether rather \nthan changing its circulation once it has been created. More specifically, personality and culture are ingrained \nparts of every individual; they generally remain stable for people who have reached  adulthood86. Moreover, past \nresearch showed that individuals are likely drawn to regions that match their personality and cultural norms \nas this matching increases their overall life  satisfaction30. In fact, prior longitudinal analysis on state-wide per -\nsonality traits showed that states\u2019 big-5 personality ranks remained unchanged in the last 20  years34. Given such \nlevel of \u201cstability\u201d and clustering, these traits are likely to affect news diffusion beyond the effects of the platform \nalgorithms, and, hence, make combating misinformation more difficult (for instance, it would be difficult to \ncompel \u201cunconscientious personalities\u201d to be more  conscientious87). Social media platforms\u2019 recommendation \nand personalization algorithms had led to the formulation of homogeneous, tight-knit communities en mass. \n10\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/These communities had then facilitated the circulation of (mis)information . Thus, researchers had proposed \nvarious ways to regulate these algorithms, including increasing the diversity of perspectives and connections \navailable to users. Y et, our results suggest that algorithmic amplification is not the main driver of news circulation, \nat least not in the case of Reddit. Rather, among the main drivers is geographic sorting that has been happening \nin the last 40 years. Given these considerations, we argue that a more productive way to combat misinformation \nis to reduce its production altogether. That is, we need to disincentivize the creation of fake and low-credibility \nnews sites and news content before they can be shared by individuals and online communities. This can be done \nin several ways. For instance, many fake news sites are driven by ad  profit19. As such, ad firms and retailers can \ncurtail misinformation by blacklisting known fake and low-credibility news sites, and recent research suggested \nthat, in so doing, major ad firms would not suffer any significant loss of  revenues88. Similarly, lawmakers can \nalso pass regulations such as criminalizing false stories (e.g., laws against defamation in the offline world already \nexist) with the potential to ignite communal  tension89.\nThere are five main limitations to our work. First, our work was exclusively focused on news circulation, and, \nas such, we did not address its actual consumption (e.g., we cannot determine the number of users who actually \nread and believed the content from the posted news URLs, but could only determine the number of those who \nwere potentially exposed).\nSecond, our project solely relied on Reddit data, and we do not know whether our results generalize to other \nplatforms. Reddit is an anonymous platform without the concept of \u2018friends\u2019 , unlike many other social networks. \nAs such, Reddit users are less likely to form echo chambers. Hence, geographically-bounded information spread-\ning is more likely to stem, not from belonging to the same circles of friends (as in other social networks), but \nfrom sharing similar interests. We cannot be sure that Reddit does not have a mechanism under the hood that \nencourages geographically-bounded interactions; however, since users are free to create and join subreddits of \ninterest, that does not seem likely. Moreover, in Supplementary Material, we showed that interactions on Face -\nbook are even more geographically localized that those on Reddit, suggesting that geographic segregation might \nplay an even stronger role on Facebook.\nThird, we approximated a user\u2019s geolocation at the state level because that was the granularity allowed by \nReddit. The probabilistic procedure with which Reddit users were geolocated effectively works at state level \n(e.g., correlation of .89 to .95 of the number of users with census population)38,90. However, it limits the ability \nto disentangle news circulation between urban and rural areas. A state\u2019s personality and culture, socioeconomic, \nand political attributes can vary significantly from one sub-region to another, including between rural and urban \nareas in the same  state91. Future work might attempt to perform a similar geolocation analysis at a finer granular -\nity (e.g., at city level) on platforms that allow for it.\nFourth, we labeled articles to represent misinformation based on their publishers and not on their content. \nThis approach is widely used in misinformation  studies39, in part because it is hard to label every single article, \nand do so accurately, as this would require extensive investigation of what is true and what is false in each single \nevent being covered. (For the same reasons, selection bias may arise when using article-level labels, as fact-check-\ners are time and resource constrained and might select only certain types of news that they consider significant \nand newsworthy.) A recent study showed that corporate fake news is negatively associated with a company\u2019s \ncontemporaneous abnormal return and positively associated with contemporaneous abnormal turnover, and this \nresult was independent of whether fakeness was defined using publisher-level or article-level credibility  scores92. \nWe also performed a Groundtruth Labels Robustness Check (in Supplemental Information) against trustworthi-\nness scores provided by professional fact-checkers. We found following trustworthiness scores for each of our \ncategories: reputable (0.66), low-credibility (0.1) and fake news sites (0.02), indicating that our publisher-level \ncredibility scores align well with the article-level ratings by professional fact-checkers.\nFifth, our data did not contain comments that were deleted prior to being collected by\u00a0pushshift.io. As such, \nwe could not examine whether those deleted comments contained news URLs. In particular, comments that \nwere removed by Automoderator (bots) were unavailable to us, as these comments were removed as soon as \nthey were posted. Nevertheless, the Reddit dataset from \u00a0pushshift.io remains one of the most comprehensive \ndatasets  available37. Furthermore, reputable news is unlikely to be removed by moderators, and our observations \nfor true news still showed the prominent role of regional personality and culture, speaking to the robustness of \nour findings.\nData availability\nWe made publicly available the following data: (1) geolocated Reddit users  (3M identifiers of users who were \nlocated in one of the 50 U.S. states), (2) news comments from those Reddit users (8.23M comments containing \nnews links), (3) names of news sites (news sites and their corresponding categories: fake, lowcred, and reputable), \nand (4) US state\u2011level attributes (personality and cultural, socio-economic, and political). A detailed description \nof how we created the data and how to retrieve it is available at the following link https:// doi. org/ 10. 6084/  m9. \nfigsh  are. 20223 867. v1 .\nReceived: 14 June 2022; Accepted: 10 April 2023\nReferences\n 1. K\u00fcmpel, A. S., Karnowski, V . & Keyling, T. News sharing in social media: A review of current research on news sharing users, \ncontent, and networks. Soc. Media Soc. 1, 2056305115610141 (2015).\n 2. Forgas, J. P . & Baumeister, R. The Social Psychology of Gullibility: Conspiracy Theories, Fake News and Irrational Beliefs (Routledge, \n2019).\n11\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/ 3. Burbach, L., Halbach, P ., Ziefle, M. & Calero\u00a0Valdez, A. Who shares fake news in online social networks? In Proceedings of the 27th \nACM Conference on User Modeling, Adaptation and Personalization 234\u2013242 (2019).\n 4. Buchanan, T. & Benson, V . Spreading disinformation on facebook: Do trust in message source, risk propensity, or personality \naffect the organic reach of \u201cfake news\u2019\u2019?. Soc. Media Soc.  5, 2056305119888654 (2019).\n 5. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on twitter during the 2016 us presidential \nelection. Science  363, 374\u2013378 (2019).\n 6. Balestrucci, A. & De\u00a0Nicola, R. Credulous users and fake news: a real case study on the propagation in twitter. In 2020 IEEE Con\u2011\nference on Evolving and Adaptive Intelligent Systems (EAIS) 1\u20138 (IEEE, 2020).\n 7. Kim, K., Baek, Y . M. & Kim, N. Online news diffusion dynamics and public opinion formation: A case study of the controversy \nover judges\u2019 personal opinion expression on sns in korea. Soc. Sci. J. 52, 205\u2013216 (2015).\n 8. Xiao, X. & Su, Y . Wired to seek, comment and share? Examining the relationship between personality, news consumption and \nmisinformation engagement. Online Information Review  46(6), (2022).\n 9. Mian, L. S. The Effects of Negative Emotions and Personality on News Sharing behaviour, Bachelor\u2019s Theses, NUS University (2020).\n 10. Ling, R. Confirmation bias in the era of mobile news consumption: The social and psychological dimensions. Digit. J.  8, 596\u2013604 \n(2020).\n 11. Amazeen, M. A., Vargo, C. J. & Hopp, T. Reinforcing attitudes in a gatewatching news era: Individual-level antecedents to sharing \nfact-checks on social media. Commun. Monogr.  86, 112\u2013132 (2019).\n 12. Kalogeropoulos, A., Negredo, S., Picone, I. & Nielsen, R. K. Who shares and comments on news?: A cross-national comparative \nanalysis of online and social media participation. Soc. Media Soc. 3, 2056305117735754 (2017).\n 13. Ihm, J. & Kim, E.-M. The hidden side of news diffusion: Understanding online news sharing as an interpersonal behavior. New \nMedia Soc.  20, 4346\u20134365 (2018).\n 14. An, J., Quercia, D. & Crowcroft, J. Partisan sharing: Facebook evidence and societal consequences. In Proceedings of the Second \nACM Conference on Online Social Networks  13\u201324 (2014).\n 15. Scherer, L. D. et al.  Who is susceptible to online health misinformation? a test of four psychosocial hypotheses. Health Psychol.  \n2021, 56 (2021).\n 16. Aral, S. The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health\u2013and How We Must Adapt  \n(Currency, 2020).\n 17. Pariser, E. The Filter Bubble: How the New Personalized Web is Changing What We Read and How We Think (Penguin, 2011).\n 18. Jamieson, K. H. & Cappella, J. N. Echo Chamber: Rush Limbaugh and the Conservative Media Establishment  (Oxford University \nPress, 2008).\n 19. Bakir, V . & McStay, A. Fake news and the economy of emotions: Problems, causes, solutions. Digit. J.  6, 154\u2013175 (2018).\n 20. Rathje, S., Van Bavel, J. J. & van der Linden, S. Out-group animosity drives engagement on social media. Proc. Natl. Acad. Sci.  118, \n25 (2021).\n 21. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science  359, 1146\u20131151. https://  doi. org/ 10. 1126/  scien  \nce. aap95  59 (2018).\n 22. Leskovec, J., Backstrom, L. & Kleinberg, J. Meme-tracking and the dynamics of the news cycle. In Proceedings of the 15th ACM \nSIGKDD International Conference on Knowledge Discovery and Data Mining 497\u2013506 (2009).\n 23. Y ang, J. & Leskovec, J. Modeling information diffusion in implicit networks. In 2010 IEEE International Conference on Data Mining  \n599\u2013608 (IEEE, 2010).\n 24. Myers, S.\u00a0A. & Leskovec, J. Clash of the contagions: Cooperation and competition in information diffusion. In 2012 IEEE 12th \nInternational Conference on Data Mining  539\u2013548 (IEEE, 2012).\n 25. Wang, X., Lan, Y . & Xiao, J. Anomalous structure and dynamics in news diffusion among heterogeneous individuals. Nat. Hum. \nBehav.  3, 709\u2013718 (2019).\n 26. Gravino, P ., Prevedello, G., Galletti, M. & Loreto, V . The supply and demand of news during covid-19 and assessment of question-\nable sources production. Nature Hum. Behav. 2022, 1\u201310 (2022).\n 27. Bishop, B. The Big Sort: Why the Clustering of Like \u2011Minded America is Tearing Us Apart (Houghton Mifflin Harcourt, 2009).\n 28. Glass, J. & Levchak, P . Red states, blue states, and divorce: Understanding the impact of conservative protestantism on regional \nvariation in divorce rates. Am. J. Sociol. 119, 1002\u20131046 (2014).\n 29. Monson, R. A. & Mertens, J. B. All in the family: Red states, blue states, and postmodern family patterns, 2000 and 2004. Sociol. \nQ. 52, 244\u2013267 (2011).\n 30. Jokela, M., Bleidorn, W ., Lamb, M. E., Gosling, S. D. & Rentfrow, P . J. Geographically varying associations between personality \nand life satisfaction in the london metropolitan area. Proc. Natl. Acad. Sci. 112, 725\u2013730 (2015).\n 31. Scala, D. J. & Johnson, K. M. Political polarization along the rural-urban continuum? the geography of the presidential vote, \n2000\u20132016. Ann. Am. Acad. Pol. Soc. Sci. 672, 162\u2013184 (2017).\n 32. Rentfrow, P . J., Jost, J. T., Gosling, S. D. & Potter, J. Statewide differences in personality predict voting patterns in 1996\u20132004 us \npresidential elections. Soc. Psychol. Bases Ideol. Syst. Justif. 1, 314\u2013349 (2009).\n 33. Rentfrow, P . J. et al. Divided we stand: Three psychological regions of the united states and their political, economic, social, and \nhealth correlates. J. Pers. Soc. Psychol. 105, 996 (2013).\n 34. Elleman, L. G., Condon, D. M., Russin, S. E. & Revelle, W . The personality of us states: Stability from 1999 to 2015. J. Res. Pers. 72, \n64\u201372 (2018).\n 35. Mullainathan, S. & Shleifer, A. The market for news. Am. Econ. Rev. 95, 1031\u20131053 (2005).\n 36. Gentzkow, M. & Shapiro, J. M. What drives media slant? Evidence from us daily newspapers. Econometrica  78, 35\u201371 (2010).\n 37. Baumgartner, J., Zannettou, S., Keegan, B., Squire, M. & Blackburn, J. The pushshift reddit dataset. In Proceedings of the International \nAAAI Conference on Web and Social Media, vol. 14 830\u2013839 (2020).\n 38. Balsamo, D., Bajardi, P . & Panisson, A. Firsthand opiates abuse on social media: Monitoring geospatial patterns of interest through \na digital cohort. In The World Wide Web Conference 2572\u20132579 (2019).\n 39. Bozarth, L., Saraf, A. & Budak, C. Higher ground? How groundtruth labeling impacts our understanding of fake news about the \n2016 us presidential nominees. In Proceedings of the International AAAI Conference on Web and Social Media, vol. 14 48\u201359 (2020).\n 40. Vargo, C. J., Guo, L. & Amazeen, M. A. The agenda-setting power of fake news. New Media Soc.  20, 2028\u20132049 (2018).\n 41. Zimdars, M. My \u201cfake news list\u201d went viral. but made-up stories are only part of the problem. The Washington Post  (2016).\n 42. Politifact staff. Politifact Guide to Fake News Websites and What They Peddle. https:// www. polit  ifact. com/ artic  le/ 2017/ apr/ 20/ polit  \nifacts- guide-  fake-  news-  websi  tes- and-  what-  they  (2018). Accessed 15 Mar 2023.\n 43. Couts, A. & Wyrich, A. Here Are All The \u2018fake news\u2019 Sites to Watch Out For on Facebook. https:// www. daily  dot. com/ debug/ fake-  \nnews-  sites-  list- faceb  ook (2016). Accessed 15 March 2023.\n 44. Allcott, H., Gentzkow, M. & Yu, C. Trends in the diffusion of misinformation on social media. arXiv:  1809. 05901  (2018).\n 45. Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. \nProc. Natl. Acad. Sci. 116, 2521\u20132526 (2019).\n 46. Khan, M. L. & Idris, I. K. Recognise misinformation and verify before sharing: A reasoned action and information literacy perspec-\ntive. Behav. Inf. Technol. 38, 1194\u20131212 (2019).\n 47. Bonney, K. M. Fake news with real consequences: The effect of cultural identity on the perception of science. Am. Biol. Teach. 80, \n686\u2013688 (2018).\n12\nVol:.(1234567890) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/ 48. Islam, A. N., Laato, S., Talukder, S. & Sutinen, E. Misinformation sharing and social media fatigue during covid-19: An affordance \nand cognitive load perspective. Technol. Forecast. Soc. Chang. 159, 120201 (2020).\n 49. Calvillo, D. P ., Garcia, R. J., Bertrand, K. & Mayers, T. A. Personality factors and self-reported political news consumption predict \nsusceptibility to political fake news. Person. Individ. Differ. 174, 110666 (2021).\n 50. Soto, C. J. & John, O. P . The next big five inventory (bfi-2): Developing and assessing a hierarchical model with 15 facets to enhance \nbandwidth, fidelity, and predictive power. J. Pers. Soc. Psychol. 113, 117 (2017).\n 51. John, O. P . & Srivastava, S. The Big Five Trait taxonomy: History, measurement, and theoretical perspectives. In Handbook of \npersonality: Theory and research (eds. Pervin, L. A. & John, O. P .)  102\u2013138 (Guilford Press, 1999).\n 52. Rentfrow, P . J. Statewide differences in personality: Toward a psychological geography of the united states. Am. Psychol. 65, 548 \n(2010).\n 53. Deng, S., Lin, Y ., Liu, Y ., Chen, X. & Li, H. How do personality traits shape information-sharing behaviour in social media? Explor -\ning the mediating effect of generalized trust. Inf. Res. Int. Electron. J.  22, n3 (2017).\n 54. Matzler, K., Renzl, B., M\u00fcller, J., Herting, S. & Mooradian, T. A. Personality traits and knowledge sharing. J. Econ. Psychol. 29, \n301\u2013313 (2008).\n 55. Gou, L., Zhou, M.\u00a0X. & Y ang, H. Knowme and shareme: Understanding automatically discovered personality traits from social \nmedia and user sharing preferences. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 955\u2013964 \n(2014).\n 56. Witkin, H. A. & Berry, J. W . Psychological differentiation in cross-cultural perspective. ETS Res. Bull. Ser.  1975, 1\u2013100 (1975).\n 57. Li, R., Gordon, S. & Gelfand, M. J. Tightness-looseness: A new framework to understand consumer behavior. J. Consum. Psychol.  \n27, 377\u2013391 (2017).\n 58. Babi\u010d, K., \u010cerne, M., \u0160kerlavaj, M. & Zhang, P . The interplay among prosocial motivation, cultural tightness, and uncertainty \navoidance in predicting knowledge hiding. Econ. Business Rev. 20, 395\u2013422 (2018).\n 59. Harrington, J. R. & Gelfand, M. J. Tightness-looseness across the 50 united states. Proc. Natl. Acad. Sci. 111, 7990\u20137995 (2014).\n 60. Deckert, C. & Schomaker, R. M. Cultural tightness-looseness and national innovativeness: Impacts of tolerance and diversity of \nopinion. J. Innov. Entrepreneurship 11, 1\u201319 (2022).\n 61. Mattison Thompson, F., Brouthers, K. D., national cultural differences and cultural tightness. Digital consumer engagement. J. Int. \nMark.  29, 22\u201344 (2021).\n 62. McLeod, D. M. & Perse, E. M. Direct and indirect effects of socioeconomic status on public affairs knowledge. J. Q.  71, 433\u2013442 \n(1994).\n 63. Gil-de-Z\u00fa\u00f1iga, H., Jung, N. & Valenzuela, S. Social media use for news and individuals\u2019 social capital, civic engagement and politi-\ncal participation. J. Comput.\u2011 Mediat. Commun. 17, 319\u2013336 (2012).\n 64. Guess, A., Nagler, J. & Tucker, J. Less than you think: Prevalence and predictors of fake news dissemination on facebook. Sci. Adv.  \n5, eaau4586 (2019).\n 65. Jones-Jang, S. M., Mortensen, T. & Liu, J. Does media literacy help identification of fake news? Information literacy helps, but \nother literacies don\u2019t. Am. Behav. Sci. 65, 371\u2013388 (2021).\n 66. He, L., Y ang, H., Xiong, X. & Lai, K. Online rumor transmission among younger and older adults. SAGE Open 9, 2158244019876273 \n(2019).\n 67. McCann, A. Most and Least Politically Engaged States. https:// walle thub. com/ edu/ most- least- polit  ically- engag  ed- states/ 7782 (2020). \nAccessed 15 March 2023.\n 68. West, G.\u00a0B. Scale: The Universal Laws of Growth, Innovation, Sustainability, and The Pace of Life in Organisms, Cities, Economies, \nand Companies  (Penguin, 2017).\n 69. Bettencourt, L. M., Lobo, J., Helbing, D., K\u00fchnert, C. & West, G. B. Growth, innovation, scaling, and the pace of life in cities. Proc. \nNatl. Acad. Sci. 104, 7301\u20137306 (2007).\n 70. Bonaventura, M., Aiello, L. M., Quercia, D. & Latora, V . Predicting urban innovation from the US Workforce Mobility Network. \nNature Human. Soc. Sci. Commun. 8, 25 (2021).\n 71. Richterich, A. \u2019karma, precious karma!\u2019karmawhoring on reddit and the front page\u2019s econometrisation. J. Peer Prod. 4, 1\u201312 (2014).\n 72. Liben-Nowell, D., Novak, J., Kumar, R., Raghavan, P . & Tomkins, A. Geographic routing in social networks. Proc. Natl. Acad. Sci.  \n102, 11623\u201311628 (2005).\n 73. Kuchler, T., Russel, D. & Stroebel, J. Jue insight: The geographic spread of covid-19 correlates with the structure of social networks \nas measured by facebook. J. Urban Econ.  2021, 103314 (2021).\n 74. Joglekar, S., Velupillai, S., Dutta, R. & Sastry, N. Analysing meso and macro conversation structures in an online suicide support \nforum. arXiv: 2007.  10159 (2020).\n 75. Calvillo, D. P ., Ross, B. J., Garcia, R. J., Smelter, T. J. & Rutchick, A. M. Political ideology predicts perceptions of the threat of covid-\n19 (and susceptibility to fake news about it). Soc. Psychol. Person. Sci. 11, 1119\u20131128 (2020).\n 76. Venables, W .\u00a0N. & Ripley, B.\u00a0D. Random and mixed effects. In Modern Applied Statistics with S 271\u2013300 (Springer, 2002).\n 77. VIF: Variance Inflation Factor (2023, Accessed 15 Mar 2023); https:// www. rdocu menta  tion. org/ packa  ges/ regcl  ass/ versi ons/1. 6/  \ntopics/  VIF.\n 78. Fatehkia, M., O\u2019Brien, D. & Weber, I. Correlated impulses: Using facebook interests to improve predictions of crime rates in urban \nareas. PLoS ONE 14, e0211350 (2019).\n 79. Chetty, R. et al. Social capital i: measurement and associations with economic mobility. Nature  608, 108\u2013121 (2022).\n 80. Li, H., Hecht, B. & Chancellor, S. Measuring the monetary value of online volunteer work. In Proceedings of the International AAAI \nConference on Web and Social Media, vol. 16 596\u2013606 (2022).\n 81. Newman, M. E., Barab\u00e1si, A.-L.E. & Watts, D. J. The Structure and Dynamics of Networks  (Princeton University Press, 2006).\n 82. Leskovec, J. & Horvitz, E. Planetary-scale views on a large instant-messaging network. In Proceedings of the 17th International \nConference on World Wide Web 915\u2013924 (2008).\n 83. Fuchs, C. Social Media: A Critical Introduction  (Sage, 2021).\n 84. An, J., Quercia, D., Cha, M., Gummadi, K. & Crowcroft, J. Sharing political news: The balancing act of intimacy and socialization \nin selective exposure. EPJ Data Sci.  3, 1\u201321 (2014).\n 85. Bobkowski, P . S., Jiang, L., Peterlin, L. J. & Rodriguez, N. J. Who gets vocal about hyperlocal: Neighborhood involvement and \nsocioeconomics in the sharing of hyperlocal news. J. Pract.  13, 159\u2013177 (2019).\n 86. McCrae, R. R. & Costa, P . T. Jr. The stability of personality: Observations and evaluations. Curr. Dir. Psychol. Sci.  3, 173\u2013175 (1994).\n 87. Schurer, S., de New, S. & Leung, F. Do universities shape their students\u2019 personality?  (Tech. Rep, Institute of Labor Economics (IZA), \n2015).\n 88. Bozarth, L. & Budak, C. Market forces: Quantifying the role of top credible ad servers in the fake news ecosystem. In Proceedings \nof the International AAAI Conference on Web and Social Media, vol. 15 83\u201394 (2021).\n 89. Finkel, J. et al. Fake News & Misinformation Policy Practicum  (Hewlett Foundation Madison Vincent Initiative Sheu, JD, 2017).\n 90. \u0160\u0107epanovi\u0107, S., Aiello, L. M., Zhou, K., Joglekar, S. & Quercia, D. The healthy states of america: creating a health taxonomy with \nsocial media. In Proceedings of the International AAAI Conference on Web and Social Media, vol. 15  621\u2013632 (2021).\n 91. Hindman, D. B. The rural-urban digital divide. Journal. Mass Commun. Q.  77, 549\u2013560 (2000).\n 92. Xu, R. Corporate Fake News on Social Media. Ph.D. thesis, University of Miami (2021).\n13\nVol.:(0123456789) Scientific Reports  |         (2023) 13:6711  | https://doi.org/10.1038/s41598-023-33247-3\nwww.nature.com/scientificreports/Author contributions\nL.B., L.C. and D.Q. designed the experiments and wrote the main manuscript text, L.B. performed the experi -\nments, and S.S. performed part of the data gathering. All authors reviewed the manuscript.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 023- 33247-3.\nCorrespondence and requests for materials should be addressed to D.Q.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article\u2019s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat  iveco  mmons. org/ licen  ses/ by/4. 0/.\n\u00a9 The Author(s) 2023", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The role of the big geographic sort in online news circulation among US Reddit users", "author": ["L Bozarth", "D Quercia", "L Capra", "S \u0160\u0107epanovi\u0107"], "pub_year": "2023", "venue": "Scientific Reports", "abstract": "Past research has attributed the circulation of online news to two main factors\u2014individual  characteristics (eg, a person\u2019s information literacy) and social media effects (eg, algorithm-"}, "filled": false, "gsrank": 235, "pub_url": "https://www.nature.com/articles/s41598-023-33247-3", "author_id": ["", "nPyDLd0AAAAJ", "iwzlsmUAAAAJ", "pwySZlwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:DN69qY3pELIJ:scholar.google.com/&output=cite&scirp=234&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D230%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=DN69qY3pELIJ&ei=LrWsaJ_HDrTWieoP1pCJ2AY&json=", "num_citations": 7, "citedby_url": "/scholar?cites=12831012133025996300&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:DN69qY3pELIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-023-33247-3.pdf"}}, {"title": "The role of the Big Geographic Sort in the circulation of misinformation among US Reddit users", "year": "2022", "pdf_data": "The role of the Big Geographic Sort in the circulation\nof misinformation among U.S. Reddit users\nLia Bozarth1, Daniele Quercia*,2,3, Licia Capra4, and Sanja Scepanovic2\n2Bell Labs, Cambridge, United Kingdom\n3CUSP , Kings College London, United Kingdom\n1University of Michigan, USA\n4University College London, UK\n*quercia@cantab.net\nABSTRACT\nPast research has attributed the online circulation of misinformation to two main factors - individual characteristics (e.g., a\nperson\u2019s information literacy) and social media effects (e.g., algorithm-mediated information diffusion) - and has overlooked a\nthird one: the critical mass created by the of\ufb02ine self-segregation of Americans into like-minded geographical regions such\nas states (a phenomenon called \u2018The Big Sort\u2019). We hypothesized that this latter factor matters for the online spreading of\nmisinformation not least because online interactions, despite having the potential of being global, end up being localized:\ninteraction probability is known to rapidly decay with distance. Upon analysis of more than 8M Reddit comments containing\nnews links spanning four years, from January 2016 to December 2019, we found that Reddit did not work as an \u2018hype machine\u2019\nfor misinformation (as opposed to what previous work reported for other platforms, circulation was not mainly caused by\nplatform-facilitated network effects) but worked as a supply-and-demand system: misinformation news items scaled linearly\nwith the number of users in each state (with a scaling exponent b\u00191, and a goodness of \ufb01t R2\u00190:95). Furthermore,\ndeviations from such a universal pattern were best explained by state-level personality and cultural factors ( R2\u0019f0:12;0:39g),\nrather than socioeconomic conditions ( R2\u0019f0:15;0:29g) or, as one would expect, political characteristics ( R2\u0019f0:06;0:21g).\nHigher-than-expected circulation of any type of news (including reputable news) was found in states characterised by residents\nwho tend to be less diligent in terms of their personality (low in conscientiousness) and by loose cultures understating the\nimportance of adherence to norms (low in cultural tightness). Interestingly, the combination of those factors with low levels of\neducation was then associated with the particular circulation of misinformation. These results suggest that online interactions\nare geographically bounded and, as such, circulation of misinformation cannot be studied purely as an Internet phenomenon\nbut should be grounded into a user\u2019s of\ufb02ine cultural environment, which has become increasingly segregated over the decades,\nand is admittedly hard to change.\nIntroduction\nThe circulation of misinformation online is a major contributor to various contemporary political and social issues in the U.S.,\nincluding the Clinton Email and Pizzagate conspiracies in 2016, the immigration crisis (migrant caravans) in 2018, and the\nJanuary 6th riot in the U.S. Capitol building in 2021. It is also associated with hyper-polarization of opinions, xenophobia, and\ncivil unrest1, 2. Alarmed by fake news\u2019 continued grip on a signi\ufb01cant portion of the U.S. population and its persistent negative\nimpacts, researchers have extensively examined factors associated with an individual\u2019s tendency to spread misinformation.\nPast research has attributed circulation to two main categories of factors. The \ufb01rst category includes individual characteristics\nsuch as a person\u2019s personality and culture, education attainment, and political-leaning3\u20137. For example, conscientious (careful,\ndiligent) individuals were shown to be signi\ufb01cantly less likely to spread false content, whereas credulous individuals tend\nto be signi\ufb01cantly more likely3, 7. Further, those with lower information literacy were observed to be more likely to spread\nmisinformation8. Similarly, past research has determined that individuals also share misinformation in an effort to attack\nideological opponents9.\nThe second category has to do with the ways social media are engineered to work as a \u201cHype Machine\u201d10. For instance,\nexisting social media platforms\u2019 \u201cfriends suggestion algorithms\u201d\u2014which tend to disproportionately recommend friends of\nfriends who likely share similar behaviors and beliefs\u2014have ampli\ufb01ed the online clustering of individuals into homophilous\ncommunities. Prior studies demonstrated that these small and densely connected online communities, in turn, had signi\ufb01cantly\nincreased the spread size, depth, and speed of misinformation11. For instance, Cinelli showed that users on Facebook are\nmuch more ideologically segregated compared to those on Reddit12. In addition, users were also observed to be more likely to\nshare ideologically congruent low-credibility news content to their immediate network13. This platform-enabled circulation ofarXiv:2205.10161v1  [cs.SI]  20 May 2022\nTable 1. Summary Statistics for News Comments. These comments are Reddit posts that contain links to news articles of\nthree types.\nnews_type unique_comments unique_user unique_news_site unique_urls top_news_sites\nfake 116212 45485 933 60754 breitbart.com, dailywire.com, thegatewaypundit.com\nlowcred 536701 160146 1801 264010 dailymail.co.uk, washingtonexaminer.com, dailycaller.com\nreputable 7645044 717198 5221 3319213 nytimes.com, washingtonpost.com, wsj.com\nmisinformation is commonly known as the echo chamber or \ufb01lter bubble effect14, 15. Another platform-ampli\ufb01ed feature is\naffect. Platform algorithms were observed to preferentially recommend emotionally salient and polarizing content to boost user\nengagement and content sharing16, 17. Given that misinformation tends to be more sensational and novel, this algorithmic bias\nhad also led to the oversharing of misinformation11.\nThere is, however, a third overlooked factor: the of\ufb02ine self-segregation of Americans into like-minded communities\nsuch as geographic states, a phenomenon which Bill Bishop dubbed as \u201cThe Big Sort\u201d18. Work by Bishop and others has\nillustrated that people in the U.S. have been increasingly choosing to live in neighborhoods populated with others who are just\nlike themselves in values and beliefs. Furthermore, this sorting has resulted in geographical regions (e.g., states) with distinct\nlifestyle and culture19\u201321, political ideology22, and even personality23\u201325. As an example, work by Rentfrow et al.24showed that\nthe states of Utah and New York are the most and least agreeable among all the states, respectively. South Carolina is the most\nconscientious, and Maine the least. Similarly, Mississippi has the most restrictive cultural and social norms, whereas California\nhas the most loose24. Furthermore, states\u2019 personality and culture are indicative of their voting patterns23. The process of\nAmericans geographically sorting themselves over the past four decades into homogeneous communities still continues. Thus\nfar, it is unclear whether it has had any impact on online news circulation, particularly the circulation of misinformation.\nTo ascertain that, we examined the geographical circulation of news on Reddit, a popular online content aggregation and\ndiscussion website. Reddit consists of many communities (or areas of interest) called subreddits that function akin to online\nforums. Users can make public posts on these subreddits and others can then comment on the original posts. For instance, a user\ncan post a news article about Covid-19 on the subreddit r/news, and others can then discuss the article with each other. Unlike\nsocial media platforms such as Twitter and Facebook, Reddit users are anonymous. We chose Reddit for our analysis given that\nit has one of the most comprehensive publicly available archived datasets (available under pushshift.io ). Additionally,\nReddit was also the home for the notorious misinformation hub: r/the_Donald, which was a subreddit responsible for spreading\na considerable volume of misinformation across other platforms26, 27.\nData\nReddit Data. We used Pushshift\u2019s28publicly available comments dataset from January 2016 to December 2019. This dataset\ncontained all comments from all public and quarantined subreddits (e.g., r/the_Donald was quarantined for a time before it was\npermanently removed on June 29, 2020). We then used the method from Balsamo et al.29to assign users to their geographical\nlocation. Speci\ufb01cally, we \ufb01rst identi\ufb01ed a list of 2.87K subreddits that can be matched to one of the U.S. states (e.g., r/seattle,\nr/california). Then, for each user who had posted at least once in these subreddits, we assigned the user to the corresponding\nU.S. state. Note that if a user had posted in multiple states, we assigned the user the state with the majority of posts. As a result,\n82.4% of users had only posted in a single state, and 95.2% of users had posted in at most 2 states. Finally, only 3.8% of users\nwere not assigned a state due to not having a majority state. We identi\ufb01ed approximately 3M users who were located in one of\nthe 50 U.S. states. The correlation between a state\u2019s population and its number of Reddit users is shown in Figure 1. We saw\nthat the number of Reddit users per state scaled linearly with the state\u2019s population ( b=0:99). Additionally, approximately\n1.4 billion (or 35%) comments on Reddit can be mapped to a user in one of the 50 U.S. states. From the 1.4B comments, we\nidenti\ufb01ed a total of 8.23M (0.6%) comments containing news links. Next, we classi\ufb01ed a Reddit comment as a fake news\ncomment if it contained a URL to a domain that appeared in the list of fake news domains, as per the groundtruth labeling\nprocedure described next.\nWebsite Groundtruth Labels. We compiled a list of news websites (or domains) from various sources widely used in\nresearching misinformation30. Each news site was then labelled as one of three types - fake, lowcred , orreputable - as follows.\nReputable: We used three sources to compile a list of reputable news sites: Vargo et al.31, Alexa ( alexa.com ), and Media\nBias/Fact Check ( mediabiasfactcheck.com ). This resulted in 8.9k total reputable news sites.\nFake: Based on a detailed meta-review in related work30, we compiled a list of questionable news sites from 5 existing sources:\nZimdars list32, Media Bias/Fact Check, PolitiFact33, the Daily Dot34, and Allcott, et al35. By using the descriptions and granular\nlabels of each of the \ufb01ve sources, we categorized a domain as fake if it had routinely published completely fabricated news\narticles. There were a total of 933 unique fake news sites across all \ufb01ve sources.\n2/12\nFigure 1. Thex-axis denotes each state\u2019s population (logged) and the y-axis is the number of Reddit users from each state. We\nsee that the number of Reddit users scaled linearly with population ( b=0:99), with an R2=0:84.\nTable 2. List of State-level Attributes.\nCategory Variable Name Description\npersonality and culture openness imaginative, spontaneous\nconscientiousness disciplined and careful\nextraversion social and fun-loving\nagreeableness trusting and helpful\nneuroticism anxious, pessimistic\ncultural_tightness restrictive social norms and punishments for deviance\nsocio-economic density population density (proxy for urbanization) 2019\ngdp state\u2019s gdp per capita 2019\nminority percentage of person of color 2019\nno_highschool percentage of population without a high school diploma 2019\npopulation state population on 2019\npolitical political political engagement score\nrepublican percentage prefer republican subtract percentage prefer democrat\nswing_state binary score of 0 (not swing state) or 1 (swing state)\nplatform adoption adoption rate of Reddit\nLowcred: Unlike fake news sites, low-credibility news sites publish articles with mixed factualness rather than completely\nfabricated content. We included domains that were described by the previous 5 sources as unreliable, hyperpartisan, clickbait,\nrumor, pseudoscience, and conspiracy sites, ending up with a total of 1801 low-credibility news domains.\nClassi\ufb01cation of News Comments. The circulation of reputable news signi\ufb01cantly outnumbered non-reputable news (Table 1):\n7.6M (93%) comments contained reputable news articles, but only 116.2K contained fake news articles. We also observed that\nreputable news sites attracted, on average, only 36 Reddit comments, low-credibility 26, and fake 8. Those low average values\nare due to the frequency distribution of the number of comments per news site being skewed: most news sites attract a few\ncomments only, while a few attract most comments (e.g., approximately one-\ufb01fth of all fake news comments contained URLs\nfrombreitbart.com ). To then ascertain that our localization procedure did not select a speci\ufb01c type of user but selected\na set representative of the general user population, we compared the 3M users with assigned locations to another 3M users\nwithout locations. We observed that the average numbers of comments posted by users of the two groups were comparable,\nwith just a small difference: 1.7% of all geotagged users had posted at least 1 comment containing fake news URLs, whereas\nonly 0.6% of non-geotagged users did. This difference can be explained by non-geotagged users being less invested in U.S.\nnews as, on average, they are less likely to all be from the U.S.. Additionally, while our lists of news sites are widely popular\nin researching misinformation, prior work had highlighted that the different lists had being created using varying labeling\nprocedures30. As such, we included additional steps detailed in Supplementary Material to validate our news site classi\ufb01cation\napproach. Brie\ufb02y, we compared our labels ( fake, lowcred , and reputable ) to trustworthiness scores of news sites provided\nby professional fact-checkers36, and observed that reputable news sites had the highest average trustworthiness score (0.66),\n3/12\nFigure 2. Cross-correlation between State-level Factors. Statistically insigni\ufb01cant correlations ( p-value\u00150:05) are grayed out.\nfollowed by low-credibility news sites (0.10), and \ufb01nally fake news sites (0.02), suggesting that our labels were well aligned\nwith the ratings of professional fact-checkers.\nState-level Attributes. We included the following state-level attributes that were shown by prior studies to be indicative of\nindividual and community\u2019s tendency to share misinformation3, 6, 37. These attributes were categorized into personality and\ncultural factors, socio-economic conditions, and political attributes (Table 2).\nPersonality and Culture: Prior work had observed signi\ufb01cant individual-level associations between personality/culture and\ncirculation of misinformation3, 7, 38, 39. For instance, individuals scoring high in conscientiousness are signi\ufb01cantly less likely\nto spread false content3. Similarly, a lower level of extraversion is associated with a higher discernment of misinformation40.\nTherefore, we included the big 5 personality variables of openness, conscientiousness, extroversion, agreeableness, and\nneuroticism (OCEAN)24, and added cultural tightness to them. This latter variable re\ufb02ects the propensity of holding adherence\nto norms in high regard41, and might well be hindering the spreading of misinformation.\nSocio-economic: Some socioeconomic factors are indicative of an individual\u2019s political knowledge, information literacy, and\ntendency to consume and diffuse misinformation6, 35, 37. As an example, individuals who are socio-economically well-off\ntend to have more political knowledge42, which is associated with having a better ability in telling apart factual news from\nmisinformation37. Overall, in terms of socio-economic indicators, we included \ufb01ve variables available from the 2019 American\nCommunity Survey: population ( population ); population density as a proxy for urbanization ( density ); percentage of population\nover 25 years old without high school diploma ( no_highschool ); percentage of person of color ( minority ); and gdp per capita\n(gdp).\nPolitical: An extensive literature had shown that fake news is politically driven and is more likely to be consumed and shared by\nconservative-leaning individuals and online communities6, 35, 37, 43\u201345. Therefore, we postulated that states\u2019 political attributes\nwould be the most indicative of the states\u2019 tendency to circulate misinformation, an consequently included three political\nattributes: percentage gap between the population leaning towards the Republican party and that leaning towards the Democratic\nparty ( republican ) provided by the 2016 Gallup Poll; whether a state was a battleground state during the 2016 presidential\nelection or not ( swing_state ) provided by the Center for Politics; and the political engagement score ( political ) from46, which\n4/12\nwas calculated using the weighted sum of multiple metrics (i.e., percentage of registered voters, total political contribution,\nand percentage of residents who participated in local political) provided between 2016 and 2019 by the American Community\nSurvey, the U.S. Census Bureau, the Center for Responsive Politics, and Ballotpedia.\nTo those socio-economic attributes, we added a state\u2019s Reddit adoption rate as a control varaible. That is because online\nnews circulation might well be explained by online adoption rates, which, in turn, happened to be correlated with some of the\nsocio-economic attributes in our case (Figure 2): negatively with extraversion, cultural_tightness , and no_highschool , and\npositively with political . In other words, states that are social, culturally restrictive, and have low education attainment have\nfewer-than-expected users on Reddit.\nMethods\nScaling laws of news circulation\nTo study circulation within states, we resorted to urban science research in the area of complex systems47, 48. Such work has\nshown that a variety of urban measures such as number of patents and income are power-law functions of population size48, 49.\nYet, we do not know whether that is the case for news circulation online: critics might rightly say that the process of online\ncirculation may have little to do with a user\u2019s of\ufb02ine conditions or may be just \u201ctoo complex\u201d to be subject to laws.\nTo investigate the relationship between news circulation and population size, we used a methodology that was put forth by\nBettencourt et al.48. Say that Ydenotes circulation within a state, then this power-law dependency translates into saying that\nY=constant\u0001Nb. By then taking the log of both sides, we obtain: log(Y) =b\u0001log(N)+constant , where Nis the population\nsize, constant is a normalization constant, and bis the so-called scaling exponent . Typically, the values of this scaling exponent\nare grouped in three ranges:\n0:8>b(sublinear ) is found for material quantities displaying economies of scale (e.g., infrastructure);\n0:8\u0014b<1:1 (linear ) is found for individual human needs (e.g., jobs, houses);\n1:1\u0014b<1:3(superlinear ) is found for measures re\ufb02ecting wealth creation and innovation with increasing returns , which\nare typically associated with the intrinsically social nature of large cities (e.g., number of patents, number of successful\nstartups).\nThree types of news\nSince the number of Reddit users alone could explain a great portion of the variance for the presence of the three types of news,\nwe used the following approach to separate the impact of platform adoption and the characteristics of a state. Given a news type\ns2flowcred ;f ake;reputablegand state i, letbsbe the scaling exponent for news type s,fs;idenote the total number of news\nitems of type sposted by users from i(in log value), and Nibe the number of users in state i(in log value). We then run the\nsimple regression fs;i=bsNi+es;ito determine the residual es;i, which we call the Circulation(s,i) score of state ifor the news\ntype s. This is the portion of the circulation of news of type sin a state ithat is not explained by the number of users in i. Next,\nwe took that residual and run the following model:\nCirculation (s;i) =b0\n0+b0\n1\u0003v1+b0\n2\u0003v2:::+b0\nn\u0003vn+e0; (1)\nwhere v1,v2, and vnare the predictors listed in Table 2. Note that all variables were standardized with z-scores to make\nregression coef\ufb01cients easier to interpret. For comparability\u2019s sake, in addition to this circulation metric based on the residual,\nwe also used the average number of misinformation news comments as as an alternative metric (i.e., Circulation (s;i)was\ncalculated as the average number of comments containing URLs to news type sposted by Reddit users from state i), and\nreported the results in Supplementary Material; both metrics showed comparable results.\nResults\nThe role of platform-facilitated news diffusion\nWe compared the virality of low-credibility and fake articles to that of reputable news. For each type of news, we generated\nthe cumulative fraction of articles that reached at least a given number of authors or states (Figure 3a). We observed that\ngeographical diffusion is rare on Reddit. More speci\ufb01cally, 74.8% of all reputable news articles were only posted by a single\nuser who was located in the U.S., and 86.7% by at most 2 users. The values were comparable for fake and low-credibility news.\nAdditionally, the number of news URLs that were posted by 5 or more states was only 209.7K for (6.3% of) reputable news\ncomments, 11.0K for (4.8% of) low-credibility ones, and 2.23K for (4.2% of) fake ones. Furthermore, we also observed that the\ntime gaps between the comments were lengthy (Figure 3b). For example, for all news URLs that reached exactly 5 states (only\n5/12\n(a)Diffusion Reach. Cumulative fraction of news articles that\nreached at least a given number ( x-axis value) of authors or states.\nWe saw that approximately 90% of all news articles were only\nposted by 1 or 2 users irrespective of news type.\n(b)Diffusion Speed. Average cascading time for news articles that\nreached at least a given number ( x-axis value) of authors or states. We\nsaw that fake news tended to take less time on average to reach the\nsame numbers of states and subreddits than reputable news. However,\ncascading time was exceedingly long for all news types: for example,\naverage cascading time for news that reached 2 states was 226 days,\nand for those that reached 5 states was 522 days.\nFigure 3. Diffusion for the Three Types of News on Reddit.\n6% of news had reached 5 or more states), the average cascading time was over a year. We also ran analysis using the median\ncascading time, and results were similar. In sum, our results demonstrate that circulation of news on Reddit is unlikely to be a\nfunction of diffusion, and there are several likely explanations for it. First, to reduce content duplication, Reddit moderators\ntypically discourage users from reposting the same content on the same subreddit or even on different subreddits50. Another\nexplanation could be geographical segregation. As the literature showed for platforms other than Reddit51, 52, online users who\nlive far away could be less likely to interact with each other, thus reducing out-of-state news circulation in the case of Reddit.\nOur data allowed us to test this latter explanation, and we did so next.\nThe role of geographical proximity\nTo test the extent to which online interactions are impacted by geographical distance, we adopted a metric from related work51.\nMore speci\ufb01cally, we \ufb01rst generated a user-to-user comment network in which an edge exists between a pair of users, if one\nuser had commented on the other\u2019s comment/post53. The resulting network was unidirectional and weighted. We then computed\nthe probability of having had an interaction, denoted as Connectivity d, between a pair of users who are at dphysical distance\napart (measured in km). The distance dbetween a pair of users was calculated as the distance between the geographical centers\nof the states that the pair resided in (users from the same state have d=0). Mathematically, for a \ufb01xed distance dwhere\nd=f0km;100km;200km;300km:::g, we calculated Connectivity das:\nConnectivity d=jcomments i;jjd\n1\n2\u0003Nd\u0003(Nd\u00001); (2)\nwhere Ndis the total number of users that were approximately ddistance apart of\ufb02ine, and jcomments i;jjdis the total\nnumber of unique pairs of users who lived ddistance apart and who interacted on Reddit (this number is the corresponding\nweight on the user-to-user comment network). The denominator1\n2\u0003Nd\u0003(Nd\u00001)is the total number of possible user pairs at\ndistance d. In other words, given d,Connectivity dis the number of user pairs that interacted with each other normalized by\nthe total number of possible user pairs. We then plotted the logged Connectivity din relation to the logged physical distance\ndin Figure 4 (red line). Consistent with prior work51, we found that Connectivity drapidly decreases with d. For instance,\nusers located approximately 100km apart had 4:35e\u00005probability of interacting with each other via comments. Whereas, the\nprobability decreased to 2:6e\u00005for users located 1000km apart. In other words, geographic proximity increases the probability\nof interacting (i.e., users located closer in physical distance are more likely to interact with each other): indeed, the probability\nof interacting is highest for users of the same state ( 1:02e\u00004) as it is one order of magnitude higher than the out-of-state\u2019s\nprobability (\u00152:6e\u00005). Next, to ensure that our observation was not primarily driven by interactions on location-speci\ufb01c\nsubreddits (e.g., r/seattle, r/california), we also limited the scope of interaction to non-location subreddits. To that end, we\nupdated the de\ufb01nition of jcomments i;jjdto be the number of unique pairs of users who lived ddistance apart and, crucially,\nwho also had interacted on subreddits that do not have a geographical component. We found that the red and green lines overlap\n(Figure 4), and that non-geographically salient users still preferentially interacted with others in closer geographical proximity\n6/12\nFigure 4. Geographic Distance vs.Connectivity . The x-axis denotes the geographical distance between states\u2019 centers and the\ny-axis is the probability that a pair of users with xdistance apart of\ufb02ine had interacted with each other on Reddit. Finally, the\ncolor denotes the scope of interaction. We surprisingly saw that even for subreddits without an inherent geographical af\ufb01liation,\nusers still preferred to interact with others of closer geographical proximity.\n(green line), suggesting that the observed decay with distance was not dependent on our localization procedure. That is not\nentirely surprising as online interactions have been shown to be bounded by geography, not least because social networks\nare based on real-world friends/contacts (as an example, we applied the same Connectivity dformula to a publicly available\nFacebook graph, and, in Supplementary Material, we observe that interactions on Facebook are even more geographically\nbounded than those on Reddit). Yet, in the case of Reddit, this result is remarkable because the platform is an anonymous forum\nwhere both a user\u2019s identity and physical location are hidden from other users.\nThe scaling laws of news circulation\nGiven that interactions are geographically bounded, it was reasonable to hypothesize that a state\u2019s news circulation is best\nexplained by the state\u2019s variables rather than platform-speci\ufb01c variables. As previously mentioned, based on the scaling laws\nliterature, one of these state variables is the number of users. As a case in point, consider that the state of California had a total\nof 60.4K posts containing low-credibility news posts, the highest amongst all the states. It is also the most populous state with\nthe highest number of Reddit users. Similarly, the state of Wyoming had only 1.1K low-credibility posts and is also the least\npopulous with the lowest number of Reddit users. We indeed found evidence that the number of Reddit users in a state is an\nimportant predictor of news circulation. It alone explained 95% ( R\u00190:95) of the variance: 1 unit log scale gain in number\nof users is approximately correlated with exactly 1 unit log scale gain in news circulation ( b\u00191) for all three types of news\n(Figure 5), suggesting that news circulation on Reddit works as a supply-and-demand system.\nThe role of the Big Sort\nTo explore why misinformation circulation might deviate from the supply-and-demand model at times, we studied the\nassociations between the news circulation residual metric Circulation (s;i)and state-level attributes. Cultural tightness and\nconscientiousness had the highest correlation (absolute value) with circulation across all news types (Figure 6), not least because\nthe two variables are correlated with each other ( r[cultural _tightness ;conscientiousness ] =0:47;p<0:05in Figure 2). This\ntranslates into saying that conscientious states with restrictive social norms circulated fewer news items than what was expected\nby their Reddit adoption. The association was even more prominent for reputable news. For example, the correlation between\ncultural tightness andCirculation forfake news was\u00000:31; the correlation was \u00000:53forreputable news. In other words,\nusers from states ranked high in conscientiousness were posting fewer reputable and fake news items than what was expected\nfrom their numbers of Reddit users. Next, focusing on political variables, we found that the presence of republican voters\nwas noticeably negatively correlated with circulation of reputable and low-credibility news but not of fake news (in Figure 6,\nr[circulation ;republican ]is negative for reputable andlowcred , but becomes insigni\ufb01cant for f ake). That result is in line\nwith prior studies showing that the majority of misinformation is conservative-leaning6, 54. Also, that result has an additional\nexplanation: states that are slightly more likely to use Reddit are democratic ones ( r[adoption ;republican ] =\u00000:23;p>=0:05\n7/12\nFigure 5. The Scaling of News Circulation. The x-axis is the total number of Reddit users from a state, and the y-axis denotes\nthe number of posts containing each of the three types of news. We observed that the circulation of news approximates a supply\nand demand system (i.e., b\u00191:0).\nTable 3. Circulation Regression Results. The personality and culture models (1)(3)(5) only used personality and cultural\nexplanatory variables. The complete models (2)(4)(6) used all explanatory variables. For all models, stepAIC selected the most\npredictive subset of predictors.\nDependent variable: circulation\nreputable (personality\nand culture)reputable (complete) lowcred (personality\nand culture)lowcred (complete) fake (personality and\nculture)fake (complete)\n(1) (2) (3) (4) (5) (6)\nagreeableness 0.022 (0.014) 0.022 (0.015) 0.038\u0003\u0003(0.017) 0.033 (0.020)\nconscientiousness \u00000.052\u0003\u0003\u0003(0.015)\u00000.053\u0003\u0003\u0003(0.015)\u00000.040\u0003\u0003(0.016)\u00000.054\u0003\u0003\u0003(0.018)\u00000.044\u0003\u0003\u0003(0.016)\u00000.040\u0003(0.021)\nopenness \u00000.034 (0.023)\ncultural_tightness \u00000.038\u0003\u0003\u0003(0.014)\u00000.025 (0.016) \u00000.025 (0.016) \u00000.027 (0.018) \u00000.036 (0.024)\nno_highschool 0.032\u0003\u0003(0.015) 0.054\u0003\u0003(0.021)\ngdp 0.052\u0003\u0003(0.019) 0.030\u0003(0.017) 0.046\u0003\u0003(0.020)\ndensity \u00000.027 (0.017)\npolitical \u00000.023 (0.014)\nConstant \u00000.006 (0.012) \u00000.006 (0.011) \u00000.002 (0.014) \u00000.002 (0.013) 0.001 (0.016) 0.001 (0.015)\nObservations 48 48 48 48 48 48\nR20.432 0.521 0.261 0.401 0.142 0.349\nAdjusted R20.393 0.451 0.228 0.329 0.123 0.254\nResidual Std. Error 0.081 (df = 44) 0.077 (df = 41) 0.096 (df = 45) 0.089 (df = 42) 0.110 (df = 46) 0.102 (df = 41)\nF Statistic 11.158\u0003\u0003\u0003(df = 3; 44) 7.438\u0003\u0003\u0003(df = 6; 41) 7.951\u0003\u0003\u0003(df = 2; 45) 5.616\u0003\u0003\u0003(df = 5; 42) 7.608\u0003\u0003\u0003(df = 1; 46) 3.665\u0003\u0003\u0003(df = 6; 41)\n\u0003p<0.1;\u0003\u0003p<0.05;\u0003\u0003\u0003p<0.01\nin Figure 2), as further detailed in Supplementary Material. Surprisingly, we also saw that swing states with competitive\npolitical races were not more likely to circulate signi\ufb01cantly more news. Finally, focusing on socioeconomic factors, we\nobserved that wealthy states had higher circulation, irrespective of news types.\nNext, we focused on the combined effects of state-level attributes by studying each news type separately. For each, we ran\n3 partial regression models (personality and culture, socio-economic, and political) plus one combined model. Each of the\nmodels (3 partial + 1 complete) was then \ufb01tted using stepAIC , a method that statistically identi\ufb01es the best combination of\nindependent variables with the lowest AIC value (lower AIC values indicate a better-\ufb01t model). Since we are interested in\nwhich class of variables (personality and culture vs.socio-economic vs.political) best explained misinformation circulation,\nwe only report the complete model and the personality and culture partial model here, and report the other 2 partial models\nin Supplementary Material. We found that the complete models were able to explain a considerable fraction of variances\nin circulation residual (adjusted R2\u0019f0:25;0:45gin Table 3). Further, the variable conscientiousness was a signi\ufb01cant\nindicator for lower-than-expected circulation for all types of news for all models; whereas gdpwas signi\ufb01cantly correlated\nwith higher-than-expected circulation. More interestingly, we also saw that, for the personality and culture partial models, the\nadjusted R2\u0019f0:12;0:39g. In other words, the R2differences between the personality and culture models and the complete\nmodels were small. As an example, the adjusted R2for the full model for reputable news was 0.45, whereas the adjusted\nR2for the personality and culture model was 0.39 (a difference of only 0.06). In fact, including personality and cultural\n8/12\nFigure 6. Correlation between Circulation and each independent Variable. Statistically insigni\ufb01cant correlations\n(p-value\u00150:05) are grayed out.\nvariables improved the full models\u2019 adjusted R2from 0.10 to 0.20 (see Supplementary Material). Additionally, we also saw that\npersonality and culture models had higher adjusted R2values than, as Supplementary Material shows, models that exclusively\nused socioeconomic conditions (adjusted R2\u0019f0:15;0:29g) or political characteristics (adjusted R2\u0019f0:06;0:21g). As a\nrobustness check, we also reran our analysis using normalized circulation volume. Speci\ufb01cally, we rede\ufb01ned Circulation (s;i)\nas the average number of comments containing URLs to news type sposted by Reddit users from state i. We then reran\nEquation (1). The main \ufb01ndings detailed in Supplementary Material did not change: personality and cultural factors still\nremained strong indicators of circulation.\nFinally, by comparing the values of the beta coef\ufb01cients for different news types in Table 3, we observed that circulation\nof any news types was facilitated in states that: are wealthier ( gd p has positive beta\u2019s in Table 3), have residents who are\nless diligent in terms of personality ( conscientiousness has negative beta\u2019s), and are characterized by loose cultures which\nunderstate the importance of adherence to norms ( cultural _tightness has negative beta\u2019s). That holds for all types of news.\nWe then focused on the circulation of misinformation speci\ufb01cally, and observed that was taking place once these three factors\nwere combined with a fourth one: low education levels ( no_highschool has a positive beta in the complete fake news model in\nTable 3).\nDiscussion\nWe have focused on examining factors associated with the geographical circulation of both reputable, fake and low credibility\nnews on Reddit. We observed that users\u2019 online interactions were mediated by their of\ufb02ine physical proximity, with users\nlocated far away from each other having a signi\ufb01cantly lower probability of interacting, despite their real identities and\nlocations not being visible. Further, news content was rarely circulated across states, likely the result of both interactions being\ngeographically constrained and Reddit\u2019s platform guidelines (e.g., Reddit discourages content reposts55). Overall, we found\nthat an individual user\u2019s news consumption was in\ufb02uenced by their state\u2019s characteristics rather than by some contagion effects\non the platform. Interestingly, these characteristics had more to do with cultural values than with political beliefs.\nOur work has two main rami\ufb01cations for research focused on \u201cwhy\u201d do people share fake news and on \u201chow\u201d to curtail\nthe spread of misinformation. The \ufb01rst has to do with the stability of personality and culture. More speci\ufb01cally, personality\nand culture are ingrained parts of every individual; they generally remain stable for people who have reached adulthood56.\nMoreover, past research showed that individuals are likely drawn to regions that match their personality and cultural norms\nas this matching increases their overall life satisfaction21. In fact, prior longitudinal analysis on state-wide personality traits\nshowed that states\u2019 big-5 personality ranks remained unchanged in the last 20 years25. Given such level of \u201cstability\u201d and\nclustering, these traits are likely to make combating misinformation more dif\ufb01cult (for instance, it would be dif\ufb01cult to compel\n\u201cunconscientious personalities\u201d to be more conscientious57).\nThe second rami\ufb01cation is focused on the role of social media. Social media platforms\u2019 recommendation and personalization\nalgorithms had led to the formulation of homogeneous, tight-knit communities en mass. These communities had then facilitated\nthe circulation of misinformation. Thus, researchers had proposed various ways to regulate these algorithms, including\n9/12\nincreasing the diversity of perspectives and connections available to users. Yet, our results suggest that algorithmic ampli\ufb01cation\nis not the root cause of misinformation, at least not in the case of Reddit. Rather, the root cause has to be found in the geographic\nsorting that has been happening in the last 40 years. Given these considerations, we argue that a more productive way to combat\nmisinformation is to reduce its production altogether. That is, we need to disincentivize the creation of fake and low-credibility\nnews sites and news content before they can be shared by individuals and online communities. This can be done in several\nways. For instance, many fake news sites are driven by ad pro\ufb01t16. As such, ad \ufb01rms and retailers can curtail misinformation\nby blacklisting known fake and low-credibility news sites, and recent research suggested that, in so doing, major ad \ufb01rms\nwould not suffer any signi\ufb01cant loss of revenues58. Similarly, lawmakers can also pass regulations such as criminalizing false\nstories (e.g., laws against defamation in the of\ufb02ine world already exist) with the potential to ignite communal tension59. More\ngenerally, our results speak to the importance of addressing questions relating to social justice. Issues subject of misinformation\nare complex phenomena, and may include questions of societal trust in institutions. Marginalized communities tend to cultivate\nmistrust because they have been negatively affected by the actions of those institutions60and, as such, trust between these\ncommunities and public institutions has to be rebuilt.\nThere are four main limitations to our work. First, our work was exclusively focused on circulation of misinformation,\nand, as such, we did not address its actual consumption (e.g., we cannot determine the number of users who actually read and\nbelieved the content from the posted news URLs, but could only determine the number of those who were potentially exposed).\nSecond, our project solely relied on Reddit data, and we do not know whether our results generalize to other platforms. Yet,\nin Supplementary Material, we showed that interactions on Facebook are even more geographically localized that those on\nReddit, suggesting that geographic segregation might play an even stronger role on Facebook.\nThird, we approximated a user\u2019s geolocation at the state level because that was the granularity allowed by Reddit. However,\na state\u2019s personality and culture, socioeconomic and political attributes can vary signi\ufb01cantly from one sub-region to another.\nFor instance, many prior studies had identi\ufb01ed signi\ufb01cant differences between rural and urban areas of the U.S.61. Future work\non platforms other than Reddit should consider using more granular location data whenever possible.\nFourth, our data did not contain comments that were deleted prior to being collected by pushshift.io . As such, we\ncould not examine whether those deleted comments contained news URLs. In particular, comments that were removed by\nAutomoderator (bots) were unavailable to us, as these comments were removed as soon as they were posted. Nevertheless, the\nReddit dataset from pushshift.io remains one of the most comprehensive datasets available28. Furthermore, reputable\nnews is unlikely to be removed by moderators, and our observations for true news still showed the prominent role of regional\npersonality and culture, speaking to the robustness of our \ufb01ndings.\nReferences\n1.Grado \u00b4n, K. Crime in the time of the plague: Fake news pandemic and the challenges to law-enforcement and intelligence\ncommunity. Soc. Regist. 4, 133\u2013148 (2020).\n2.Duong, H. Covid-19 fake news and attitudes toward asian americans. J. Media Res. 14, 5\u201329 (2021).\n3.Forgas, J. P. & Baumeister, R. The Social Psychology of Gullibility: Conspiracy Theories, Fake News and Irrational Beliefs\n(Routledge, 2019).\n4.Burbach, L., Halbach, P., Zie\ufb02e, M. & Calero Valdez, A. Who shares fake news in online social networks? In Proceedings\nof the 27th ACM Conference on User Modeling, Adaptation and Personalization , 234\u2013242 (2019).\n5.Buchanan, T. & Benson, V . Spreading disinformation on facebook: Do trust in message source, risk propensity, or\npersonality affect the organic reach of \u201cfake news\u201d? Soc. Media+ Soc. 5, 2056305119888654 (2019).\n6.Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on twitter during the 2016 us\npresidential election. Science 363, 374\u2013378 (2019).\n7.Balestrucci, A. & De Nicola, R. Credulous users and fake news: a real case study on the propagation in twitter. In 2020\nIEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS) , 1\u20138 (IEEE, 2020).\n8.Scherer, L. D. et al. Who is susceptible to online health misinformation? a test of four psychosocial hypotheses. Heal.\nPsychol. (2021).\n9.Osmundsen, M., Bor, A., Vahlstrup, P. B., Bechmann, A. & Petersen, M. B. Partisan polarization is the primary\npsychological motivation behind political fake news sharing on twitter. Am. Polit. Sci. Rev. 1\u201317 (2021).\n10.Aral, S. The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health\u2013and How We Must\nAdapt (Currency, 2020).\n11.V osoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science 359, 1146\u20131151, DOI: 10.1126/science.\naap9559 (2018).\n10/12\n12.Cinelli, M., Morales, G. D. F., Galeazzi, A., Quattrociocchi, W. & Starnini, M. The echo chamber effect on social media.\nProc. Natl. Acad. Sci. 118(2021).\n13.Guess, A., Aslett, K., Tucker, J., Bonneau, R. & Nagler, J. Cracking open the news feed: Exploring what us facebook users\nsee and share with large-scale platform data. J. Quant. Descr. Digit. Media 1(2021).\n14.Pariser, E. The \ufb01lter bubble: How the new personalized web is changing what we read and how we think (Penguin, 2011).\n15.Jamieson, K. H. & Cappella, J. N. Echo chamber: Rush Limbaugh and the conservative media establishment (Oxford\nUniversity Press, 2008).\n16.Bakir, V . & McStay, A. Fake news and the economy of emotions: Problems, causes, solutions. Digit. journalism 6,\n154\u2013175 (2018).\n17.Rathje, S., Van Bavel, J. J. & van der Linden, S. Out-group animosity drives engagement on social media. Proc. Natl.\nAcad. Sci. 118(2021).\n18.Bishop, B. The big sort: Why the clustering of like-minded America is tearing us apart (Houghton Mif\ufb02in Harcourt, 2009).\n19.Glass, J. & Levchak, P. Red states, blue states, and divorce: Understanding the impact of conservative protestantism on\nregional variation in divorce rates. Am. J. Sociol. 119, 1002\u20131046 (2014).\n20.Monson, R. A. & Mertens, J. B. All in the family: Red states, blue states, and postmodern family patterns, 2000 and 2004.\nThe Sociol. Q. 52, 244\u2013267 (2011).\n21.Jokela, M., Bleidorn, W., Lamb, M. E., Gosling, S. D. & Rentfrow, P. J. Geographically varying associations between\npersonality and life satisfaction in the london metropolitan area. Proc. Natl. Acad. Sci. 112, 725\u2013730 (2015).\n22.Scala, D. J. & Johnson, K. M. Political polarization along the rural-urban continuum? the geography of the presidential\nvote, 2000\u20132016. The ANNALS Am. Acad. Polit. Soc. Sci. 672, 162\u2013184 (2017).\n23.Rentfrow, P. J., Jost, J. T., Gosling, S. D. & Potter, J. Statewide differences in personality predict voting patterns in\n1996\u20132004 us presidential elections. Soc. psychological bases ideology system justi\ufb01cation 1, 314\u2013349 (2009).\n24.Rentfrow, P. J. et al. Divided we stand: Three psychological regions of the united states and their political, economic,\nsocial, and health correlates. J. personality social psychology 105, 996 (2013).\n25.Elleman, L. G., Condon, D. M., Russin, S. E. & Revelle, W. The personality of us states: Stability from 1999 to 2015. J.\nRes. Pers. 72, 64\u201372 (2018).\n26.Zannettou, S. et al. The web centipede: understanding how web communities in\ufb02uence each other through the lens of\nmainstream and alternative news sources. In Proceedings of the 2017 internet measurement conference , 405\u2013417 (2017).\n27.Zannettou, S. et al. On the origins of memes by means of fringe web communities. In Proceedings of the Internet\nMeasurement Conference 2018 , 188\u2013202 (2018).\n28.Baumgartner, J., Zannettou, S., Keegan, B., Squire, M. & Blackburn, J. The pushshift reddit dataset. In Proceedings of the\ninternational AAAI conference on web and social media , vol. 14, 830\u2013839 (2020).\n29.Balsamo, D., Bajardi, P. & Panisson, A. Firsthand opiates abuse on social media: monitoring geospatial patterns of interest\nthrough a digital cohort. In The World Wide Web Conference , 2572\u20132579 (2019).\n30.Bozarth, L., Saraf, A. & Budak, C. Higher ground? how groundtruth labeling impacts our understanding of fake news\nabout the 2016 us presidential nominees. In Proceedings of the International AAAI Conference on Web and Social Media ,\nvol. 14, 48\u201359 (2020).\n31.Vargo, C. J., Guo, L. & Amazeen, M. A. The agenda-setting power of fake news. new media & society 20, 2028\u20132049\n(2018).\n32.Zimdars, M. My \u201cfake news list\u201d went viral. but made-up stories are only part of the problem. The Wash. Post (2016).\n33.Politifact staff. Politifact guide to fake news websites and what they peddle (2018).\n34.Couts, A. & Wyrich, A. Here are all the \u2018fake news\u2019 sites to watch out for on facebook (2016).\n35.Allcott, H., Gentzkow, M. & Yu, C. Trends in the diffusion of misinformation on social media. arXiv preprint\narXiv:1809.05901 (2018).\n36.Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source\nquality. Proc. Natl. Acad. Sci. 116, 2521\u20132526 (2019).\n37.Khan, M. L. & Idris, I. K. Recognise misinformation and verify before sharing: a reasoned action and information literacy\nperspective. Behav. & Inf. Technol. 38, 1194\u20131212 (2019).\n11/12\n38.Bonney, K. M. Fake news with real consequences: the effect of cultural identity on the perception of science. The Am. Biol.\nTeach. 80, 686\u2013688 (2018).\n39.Islam, A. N., Laato, S., Talukder, S. & Sutinen, E. Misinformation sharing and social media fatigue during covid-19: An\naffordance and cognitive load perspective. Technol. Forecast. Soc. Chang. 159, 120201 (2020).\n40.Calvillo, D. P., Garcia, R. J., Bertrand, K. & Mayers, T. A. Personality factors and self-reported political news consumption\npredict susceptibility to political fake news. Pers. Individ. Differ. 174, 110666 (2021).\n41.Harrington, J. R. & Gelfand, M. J. Tightness\u2013looseness across the 50 united states. Proc. Natl. Acad. Sci. 111, 7990\u20137995\n(2014).\n42.McLeod, D. M. & Perse, E. M. Direct and indirect effects of socioeconomic status on public affairs knowledge. Journalism\nQ.71, 433\u2013442 (1994).\n43.Guess, A., Nagler, J. & Tucker, J. Less than you think: Prevalence and predictors of fake news dissemination on facebook.\nSci. advances 5, eaau4586 (2019).\n44.Jones-Jang, S. M., Mortensen, T. & Liu, J. Does media literacy help identi\ufb01cation of fake news? information literacy helps,\nbut other literacies don\u2019t. Am. Behav. Sci. 65, 371\u2013388 (2021).\n45.He, L., Yang, H., Xiong, X. & Lai, K. Online rumor transmission among younger and older adults. Sage open 9,\n2158244019876273 (2019).\n46.McCann, A. Most and least politically engaged states (2020).\n47.West, G. B. Scale: the universal laws of growth, innovation, sustainability, and the pace of life in organisms, cities,\neconomies, and companies (Penguin, 2017).\n48.Bettencourt, L. M., Lobo, J., Helbing, D., K\u00fchnert, C. & West, G. B. Growth, innovation, scaling, and the pace of life in\ncities. Proc. national academy sciences 104, 7301\u20137306 (2007).\n49.Bonaventura, M., Aiello, L. M., Quercia, D. & Latora, V . Predicting urban innovation from the US Workforce Mobility\nNetwork. Nature Humanities and Social Sciences Communications 8(2021).\n50.Richterich, A. \u2019karma, precious karma!\u2019karmawhoring on reddit and the front page\u2019s econometrisation. J. Peer Prod. 4,\n1\u201312 (2014).\n51.Liben-Nowell, D., Novak, J., Kumar, R., Raghavan, P. & Tomkins, A. Geographic routing in social networks. Proc. Natl.\nAcad. Sci. 102, 11623\u201311628 (2005).\n52.Kuchler, T., Russel, D. & Stroebel, J. Jue insight: The geographic spread of covid-19 correlates with the structure of social\nnetworks as measured by facebook. J. Urban Econ. 103314 (2021).\n53.Joglekar, S., Velupillai, S., Dutta, R. & Sastry, N. Analysing meso and macro conversation structures in an online suicide\nsupport forum. arXiv preprint arXiv:2007.10159 (2020).\n54.Calvillo, D. P., Ross, B. J., Garcia, R. J., Smelter, T. J. & Rutchick, A. M. Political ideology predicts perceptions of the\nthreat of covid-19 (and susceptibility to fake news about it). Soc. Psychol. Pers. Sci. 11, 1119\u20131128 (2020).\n55.Jhaver, S., Bruckman, A. & Gilbert, E. Does transparency in moderation really matter? user behavior after content removal\nexplanations on reddit. Proc. ACM on Human-Computer Interact. 3, 1\u201327 (2019).\n56.McCrae, R. R. & Costa Jr, P. T. The stability of personality: Observations and evaluations. Curr. directions psychological\nscience 3, 173\u2013175 (1994).\n57.Schurer, S., de New, S. & Leung, F. Do universities shape their students\u2019 personality? Tech. Rep., Institute of Labor\nEconomics (IZA) (2015).\n58.Bozarth, L. & Budak, C. Market forces: Quantifying the role of top credible ad servers in the fake news ecosystem. In\nProceedings of the International AAAI Conference on Web and Social Media , vol. 15, 83\u201394 (2021).\n59.Feingold, R. Fake news & misinformation policy practicum (2017).\n60.The Royal Society. The online information environment: Understanding how the internet shapes people\u2019s engagement\nwith scienti\ufb01c information. Tech. Rep., The Royal Society, London, UK (2012).\n61.Hindman, D. B. The rural-urban digital divide. Journalism & Mass Commun. Q. 77, 549\u2013560 (2000).\n12/12", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The role of the Big Geographic Sort in the circulation of misinformation among US Reddit users", "author": ["L Bozarth", "D Quercia", "L Capra"], "pub_year": "2022", "venue": "arXiv preprint arXiv \u2026", "abstract": "Past research has attributed the online circulation of misinformation to two main factors -  individual characteristics (eg, a person's information literacy) and social media effects (eg,"}, "filled": false, "gsrank": 236, "pub_url": "https://arxiv.org/abs/2205.10161", "author_id": ["", "nPyDLd0AAAAJ", "iwzlsmUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ch5irUaj-1cJ:scholar.google.com/&output=cite&scirp=235&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D230%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ch5irUaj-1cJ&ei=LrWsaJ_HDrTWieoP1pCJ2AY&json=", "num_citations": 1, "citedby_url": "/scholar?cites=6339840424406031986&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ch5irUaj-1cJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2205.10161"}}, {"title": "Trump vs. Hillary: What went viral during the 2016 US presidential election", "year": "2017", "pdf_data": "Trump vs. Hillary: What went Viral during the\n/two.prop/zero.prop/one.prop/six.prop US Presidential Election\nKareem Darwish1, Walid Magdy2, and Tahar Zanouda1\n1Qatar Computing Research Institute, HBKU, Doha, Qatar\n{kdarwish,tzanouda}@hbku.edu.qa ,\n2School of Informatics, The University of Edinburgh, Scotland\nwmagdy@inf.ed.ac.uk\nAbstract. In this paper, we present quantitative and qualitative analysis\nof the top retweeted tweets (viral tweets) pertaining to the US presidential\nelections from September /one.prop,/two.prop/zero.prop/one.prop/six.propto Election Day on November /eight.prop,/two.prop/zero.prop/one.prop/six.prop.\nFor everyday, we tagged the top /five.prop/zero.propmost retweeted tweets as supporting or\nattacking either candidate or as neutral/irrelevant. Then we analyzed the\ntweets in each class for: general trends and statistics; the most frequently\nused hashtags, terms, and locations; the most retweeted accounts and\ntweets; and the most shared news and links. In all we analyzed the /three.prop,/four.prop/five.prop/zero.prop\nmost viral tweets that grabbed the most attention during the US election\nand were retweeted in total /two.prop/six.prop./three.propmillion times accounting over /four.prop/zero.prop% of the\ntotal tweet volume pertaining to the US election in the aforementioned\nperiod. Our analysis of the tweets highlights some of the di\ufb00erences\nbetween the social media strategies of both candidates, the penetration\nof their messages, and the potential e\ufb00ect of attacks on both.\nKeywords: US elections, quantitative analysis, qualitative analysis, com-\nputational Social Science.\nIntroduction\nSocial media is an important platform for political discourse and political cam-\npaigns [ /two.prop/six.prop,/three.prop/one.prop]. Political candidates have been increasingly using social media\nplatforms to promote themselves and their policies and to attack their opponents\nand their policies. Consequently, some political campaigns have their own social\nmedia advisers and strategists, whose success can be pivotal to the success of the\ncampaign as a whole. The /two.prop/zero.prop/one.prop/six.propUS presidential election is no exception, in which\nthe Republican candidate Donald Trump won over his main rival Hilary Clinton.\nIn this work, we showcase some of the Twitter trends pertaining to the US\npresidential election by analyzing the most retweeted tweets in the sixty eight\ndays leading to the election and election day itself. In particular, we try to answer\nthe following research questions:\n/one.prop) Which candidate was more popular in the viral tweets on Twitter? What\nproportion of viral tweets in terms of number and volume were supporting or\nattacking either candidate?\n/two.prop) Which election related events, topics, and issues pertaining to each candi-\ndate elicited the most user reaction, and what were their e\ufb00ect on each candidate?\nWhich accounts were the most in\ufb02uential?arXiv:1707.03375v1  [cs.SI]  11 Jul 2017\n/two.propKareem Darwish et al.\n/three.prop) How credible were the links and news that were shared in viral tweets?\nTo answer these questions, we analyze the most retweeted (viral) /five.prop/zero.proptweets per\nday starting from September /one.prop,/two.prop/zero.prop/one.prop/six.propand ending on Election Day on November\n/eight.prop,/two.prop/zero.prop/one.prop/six.prop. The total number of unique tweets that we analyze is /three.prop,/four.prop/five.prop/zero.prop, whose\nretweet volume of /two.prop/six.prop./three.propmillion retweets accounts for over /four.prop/zero.prop% of the total\ntweets/retweets volume concerning the US election during that period. We have\nmanually tagged all the tweets in our collection as supporting or attacking either\ncandidate, or neutral (or irrelevant). For the di\ufb00erent classes, we analyze retweet\nvolume trends, top hashtags, most frequently used words, most retweeted accounts\nand tweets, and most shared news and links. Our analysis of the tweets shows\nsome clear di\ufb00erences between the social media strategies of each candidate and\nsubsequent user responses. For example, our observations show that the Trump\ncampaign seems to be more e\ufb00ective than the Clinton campaign in achieving\nbetter penetration and reach for: the campaign\u2019s slogans, attacks against his rival,\nand promotion of campaign activities in di\ufb00erent US states. We also noticed that\nthe prominent vulnerabilities for each candidate were Trump\u2019s views towards\nwomen and Clinton\u2019s email leaks and scandal. In addition, our analysis shows\nthat the majority of tweets bene\ufb01ting Clinton were actually more about attacking\nTrump rather than supporting Clinton, while for Trump, tweets in his favor had\nmore balance between supporting him and attacking Clinton. By analyzing the\nlinks in the viral tweets, the tweets attacking Clinton had the most number of\nlinks (accounting for /five.prop/eight.prop% of the volume of shared links), where approximately\nhalf were to highly credible sites and the remaining were to sites of mixed\ncredibility. We hope that our observations and analysis would aid political and\nsocial scientists in understanding some of the factors that may have led to the\neventual outcome of the election.\nBackground\nSocial media is a fertile ground for developing tools and algorithms that can\ncapture the opinions of the general population at a large scale [ /one.prop/three.prop]. Much work has\nstudied the potential possibility of predicting the outcome of political elections\nfrom social data. Yet, there is no uni\ufb01ed approach for tackling this problem.\nWhile Bollen et al. [ /four.prop] analyzed people\u2019s emotions (not sentiment) towards the\nUS/two.prop/zero.prop/zero.prop/eight.propPresidential campaign, the authors used both US /two.prop/zero.prop/zero.prop/eight.propPresidential\ncampaign and election of Obama as a case study. Sentiment typically signi\ufb01es\npreconceived positions towards an issue, while emotions, such as happiness or\nsadness, are temporary responses to external stimulus. Though the authors\nmentioned the feasibility of using such data to predict election results, they\ndid not o\ufb00er supporting results. Using the same approach, O\u2019Connor et al. [ /two.prop/three.prop]\ndiscussed the feasibility of using Twitter data to replace polls. Tumasjan et al. [ /two.prop/seven.prop]\nprovided one of the earliest attempts for using this kind of data to estimate\nelection results. They have used twitter data to forecast the national German\nfederal election, and investigated whether online interactions on Twitter validly\nmirrored o\ufb04ine political sentiment. The study was criticized for being contingent\non arbitrary experimental variables [ /nine.prop,/one.prop/zero.prop,/one.prop/four.prop,/two.prop/one.prop]. Metaxas et al. [ /two.prop/one.prop] argued\nTrump vs. Hillary /three.prop\nthat the predictive power of Twitter is exaggerated and it cannot be accurate\nunless we are able to identify unbiased representative sample of voters. However,\nthese early papers kicked o\ufb00 a new wave of research initiatives that focus on\nstudying the political discourse on Twitter, and how this social platform can be\nused as a proxy for understanding people\u2019s opinions [ /two.prop/two.prop]. On the other hand,\nmany studies have questioned the accuracy, and not just the feasibility, of using\nsocial data to predict and forecast [ /nine.prop,/one.prop/zero.prop]. Without combining the contextual\ninformation, together with social interactions, the results might lead to biased\n\ufb01ndings. One of the main problems of studying political social phenomena on\nTwitter is that users tend to interact with like-minded people, forming so-called\n\u201cecho chambers\u201d [ /one.prop,/six.prop,/one.prop/eight.prop]. Thus, the social structure of their interactions will\nlimit their ability to interact in a genuinely open political space. Though the\nliterature on the predictive power of twitter is undoubtedly relevant, the focus\nof this work is on performing post-election analysis to better understand the\npotential strengths and weaknesses of the social media strategies of political\ncampaigns and how they might have contributed to eventual electoral outcomes.\nA step closer to our politically motivated work, we \ufb01nd some studies that\nfocused on studying the US presidential election. For the /two.prop/zero.prop/one.prop/two.propUS presidential\nelection, Shi et al. [ /two.prop/five.prop] analyzed millions of tweets to predict the public opinion\ntowards the Republican presidential primaries. The authors trained a linear\nregression model and showed good results compared to pre-electoral polls during\nthe early stages of the campaign. In addition, the Obama campaign data analytics\nsystem/three.prop, a decision-making tool that harnesses di\ufb00erent kind of data ranging from\nsocial media to news, was developed to help the Obama team sense the pulse of\npublic opinion and strategically manage the campaign. With an attempt to study\nthe recent US presidential election, early studies have showed promising results.\nFor example, Wang et al. [ /two.prop/nine.prop] studied the growth pattern of Donald Trump\u2019s\nfollowers at a very early stage. They characterized individuals who ceased to\nsupport Hillary Clinton and Donald Trump, by focusing on three dimensions of\nsocial demographics: social status, gender, and age. They also analyzed Twitter\npro\ufb01le images to reveal the demographics of both Donald Trump and Hillary\nfollowers. Wang et al. [ /three.prop/zero.prop] studied the frequency of \u2018likes\u2019 for every tweet that\nTrump published. More recently, Bovet et al. [ /five.prop] developed an analytical tool\nto study the opinion of Twitter users, in regards to their structural and social\ninteractions, to infer their political a\ufb03liation. Authors showed that the resulting\nTwitter trends follow the New York Times National Polling Average.\nConcerning disseminating information, recent research has focused on how\ncandidates engaged in spreading fake news and in amplifying their message\nvia the use of social bots, which are programmatically controlled accounts that\nproduce content and automatically interact with other users [ /seven.prop,/one.prop/five.prop]. Bessi and\nFerrara [ /three.prop] investigated how the presence of social media bots a\ufb00ected political\ndiscussion around the /two.prop/zero.prop/one.prop/six.propU.S. presidential election. Authors suggest that the\npresence of social media bots can negatively a\ufb00ect democratic political discussion\nrather than improving it, which in turn can potentially alter public opinion and\n/three.propedition.cnn.com/ /two.prop/zero.prop/one.prop/two.prop//one.prop/one.prop//zero.prop/seven.prop/tech/web/obama-campaign-tech-team/index.html\n/four.propKareem Darwish et al.\nendanger the integrity of the presidential election. In the same context, Giglietto\net al. [ /one.prop/one.prop] studied the role played by \u201cfake-news\u201d circulating on social media\nduring the /two.prop/zero.prop/one.prop/six.propUS Presidential election. In this study, we provide a quantitative\nand qualitative analysis of tweets related to the /two.prop/zero.prop/one.prop/six.propUS presidential election. By\ntapping into the wealth of Twitter data, we focus on analyzing and understanding\nthe possible factors underlying the success and failure of candidates. Our work\nbuilds upon the aforementioned research in social and computer sciences to study\nand measure the volume and diversity of support for the two main candidates\nfor the /two.prop/zero.prop/one.prop/six.propUS presidential elections, Donald Trump and Hillary Clinton.\nData Collection and Labeling\nTo acquire the tweets that are relevant to the US presidential election, we obtained\nthe tweets that were collected by TweetElect.com from September /one.prop,/two.prop/zero.prop/one.prop/six.propto\nNovember /eight.prop,/two.prop/zero.prop/one.prop/six.prop(Election Day). TweetElect is a public website that aggregates\ntweets that are relevant to the /two.prop/zero.prop/one.prop/six.propUS presidential election. It shows the most\nretweeted content on Twitter including text tweets, images, videos, and links.\nThe site uses state-of-the-art adaptive \ufb01ltering methods for detecting relevant\ntweets on broad and dynamic topics, such as politics and elections [ /one.prop/nine.prop,/two.prop/zero.prop].\nTweetElect used an initial set of /three.prop/eight.propkeywords related to the US elections for\nstreaming relevant tweets. Consequently, adaptive \ufb01ltering continuously enriches\nthe set of keywords with additional terms that emerge over time [ /two.prop/zero.prop]. The /three.prop/eight.prop\nseeding keywords included all candidate names and common keywords (including\nhashtags) about the elections and participating parties. During the period of\ninterest, the total number of aggregated tweets per day (including retweets)\nrelated to the US elections typically ranged between /two.prop/zero.prop/zero.propK and /six.prop/zero.prop/zero.propK. This\nnumber increased dramatically after speci\ufb01c events or revelations, such as after\nthe presidential debates and Election Day, when the number of tweets exceeded\n/three.prop./five.propmillion tweets. The total number of unique tweets collected by TweetElect\nbetween September /one.propand November /eight.propwas/six.prop./eight.propmillion, while the full volume of\ntweets including retweets was /six.prop/five.prop./eight.propmillion.\nIn this work, we are interested in analyzing the most \u201cviral\u201d tweets pertain to\nthe US presidential elections, as they typically express the topics that garnered\nthe most attention on Twitter [ /one.prop/seven.prop]. Speci\ufb01cally, we constructed a set of the\nmost retweeted /five.prop/zero.proptweets for everyday in the period of interest. Thus, our\ncollection contained /three.prop,/four.prop/five.prop/zero.propunique tweets that were retweeted /two.prop/six.prop./six.propmillion times,\nrepresenting more than /four.prop/zero.prop% of the total volume of tweets during that period. Out\nof the /three.prop,/four.prop/five.prop/zero.proptweets in our collection, /seven.prop/zero.prop/zero.propwere authored by the o\ufb03cial account\nof Donald Trump, accounting for /eight.prop./seven.propmillion retweets, and /six.prop/nine.prop/eight.propwere authored by\nClinton\u2019s o\ufb03cial account, accounting for /four.prop./seven.propmillion retweets. Figure /one.propshows the\ndistribution of the number of tweets collected by TweetElect in the US elections in\nthe period of study. The number of unique tweets, retweets volume, and retweets\nvolume of the top viral daily tweets are displayed. As shown, the volume of\ntweets increased as election day approached. The biggest four peaks in the graph\nrepresent the days following the presidential debates and the election day. As\nit is shown, the retweet volume of the top /five.prop/zero.propdaily viral tweets correlates well\nTrump vs. Hillary /five.prop\n01,000,0002,000,0003,000,000\n01/09\n03/09\n05/09\n07/09\n09/09\n11/09\n13/09\n15/09\n17/09\n19/09\n21/09\n23/09\n25/09\n27/09\n29/09\n01/10\n03/10\n05/10\n07/10\n09/10\n11/10\n13/10\n15/10\n17/10\n19/10\n21/10\n23/10\n25/10\n27/10\n29/10\n31/10\n02/11\n04/11\n06/11\n08/11Volume of tweets/retweets of collected data and Top 50 daily viral tweets\n# tweets\n# retweets\n# retweets (top 50)\nFig./one.prop.Volume of retweets the top /five.prop/zero.propdaily viral tweets on the US collection compared\nto the full volume of tweets and retweets.\nLabel Tweet\nattack Trump, sup-\nport ClintonDonald Trump is un\ufb01t for the o\ufb03ce of president. Fortunately, there\u2019s an exceptionally quali\ufb01ed\ncandidate @HillaryClinton\nattack Trump, at-\ntack ClintonDonald Trump looks like what Hillary Clinton smells like\nattack Clinton A rough night for Hillary Clinton ABC News.\nattack Trump Trump to Matt Lauer on Iraq: I was totally against the war. Here\u2019s proof Trump is lying:\nhttps://t.co/ /six.propZhgJMUhs /three.prop\nneutral It s o\ufb03cial: the US has joined the #ParisAgreement https://t.co/qYN /one.propiRzSJk\nTable /one.prop.Example annotations\nwith the full retweet volume, with a Pearson correlation of /zero.prop./nine.prop/two.prop, which indicates\nnearly identical trend.\nWe calculated the daily coverage \ud835\udc36\ud835\udc51\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc66of the top /five.prop/zero.propdaily viral tweets to\nthe full tweet volume. The daily coverage ranged between /two.prop/three.prop% and /six.prop/six.prop%, with\nthe majority of the days having \ud835\udc36\ud835\udc51\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc66over /four.prop/zero.prop%. This indicates that the top /five.prop/zero.prop\nviral daily tweets may o\ufb00er good coverage and reasonable indicators for public\ninteraction with the US election on Twitter.\nAll tweets were labeled with one of \ufb01ve class labels, namely: \u201csupport Trump\u201d,\n\u201cattack Trump\u201d, \u201csupport Clinton\u201d, \u201cattack Clinton\u201d, or \u201cneutral/irrelevant\u201d,\nwith tweets being allowed to have multiple labels if applicable. Support for a\ncandidate included praising or defending the candidate, his/her supporters, or\nsta\ufb00, spreading positive news about the candidate, asking people to vote for the\ncandidate, mentioning favorable polls where the candidate is ahead, promoting\nthe candidate\u2019s agenda, or advertising appearances such as TV interviews or\nrallies. Attacking a candidate included maligning and name calling targeted at\nthe candidate, his/her supporters, or sta\ufb00, spreading negative news about the\ncandidate, mentioning polls where the candidates is behind, or attacking the\ncandidate\u2019s agenda. Other tweets were labeled as neutral/irrelevant. Tweets were\nallowed to have more than one label such as \u201csupport Trump, attack Clinton\u201d.\nThe labeling was done by an annotator with strong knowledge of US politics. The\nannotator was instructed to check the content of tweets carefully including any\nimages, videos, or external links to obtain accurate annotations. In addition, we\nadvised the annotator to check the pro\ufb01le of tweet authors to better understand\ntheir position towards the candidates if needed. One of the authors took a\nrandom sample of /five.prop/zero.proptweets to verify the correctness of the annotation. In all,\nboth agreed fully on /nine.prop/zero.prop% of the sample, partially agreed on /eight.prop%, and disagreed\non the remaining /two.prop%. The agreement between the annotator and the author,\nas measured using Cohen\u2019s Kappa, is /zero.prop./eight.prop/seven.prop, meaning nearly perfect agreement.\nTable /one.propshows few sample labeled tweets.\n/six.propKareem Darwish et al.\nClass No. of Tweets % of Tweets No. of Retweets % of Retweets\nSupport Clinton /five.prop/zero.prop/six.prop /one.prop/three.prop./six.prop% /three.prop,/two.prop/zero.prop/five.prop,/three.prop/zero.prop/three.prop /one.prop/one.prop./five.prop%\nAttack Trump /seven.prop/one.prop/two.prop /one.prop/nine.prop./one.prop% /six.prop,/three.prop/seven.prop/three.prop,/five.prop/four.prop/nine.prop /two.prop/two.prop./eight.prop%\nSupport Trump /eight.prop/four.prop/eight.prop /two.prop/two.prop./eight.prop% /six.prop,/eight.prop/nine.prop/six.prop,/nine.prop/four.prop/zero.prop /two.prop/four.prop./seven.prop%\nAttack Clinton /one.prop,/four.prop/five.prop/eight.prop /three.prop/nine.prop./two.prop% /nine.prop,/four.prop/four.prop/one.prop,/nine.prop/two.prop/one.prop /three.prop/three.prop./eight.prop%\nNeutral/irrelevant /one.prop/nine.prop/nine.prop /five.prop./three.prop% /one.prop,/nine.prop/seven.prop/eight.prop,/seven.prop/eight.prop/four.prop /seven.prop./one.prop%\nTable /two.prop.Number of tweets and retweet volume per class.\nTweet Analysis\nWe analyze tweets in every class from di\ufb00erent perspectives. Speci\ufb01cally, we\nlook at: user engagement with class over time, most viral events during election,\nmost discussed topics, most shared links and news, and most in\ufb02uential accounts\nsupporting them.\nPopularity of Candidates on Twitter Table /two.propshows the number of tweets\nand their retweet volume for each label. For further analysis, we ignore tweets\nthat are labeled as neutral/irrelevant as they are not interesting to this work.\nFigure /two.propshows a break down for each label across all days. Table /two.propshows that\nthe majority of the tweets and retweets volume were in favor of Trump ( /six.prop/one.prop./nine.prop%\nof tweets, /five.prop/eight.prop./six.prop% of retweet volume), either by supporting him or attacking\nClinton, while those in favor of Clinton represent only ( /three.prop/two.prop./seven.prop% of tweets, /three.prop/four.prop./three.prop%\nof retweet volume) of the total, either supporting her or attacking Trump. It can\nbe observed that the retweet volume of tweets attacking Clinton outnumbered\nthe retweet volume of tweets supporting her by nearly a /three.prop-to-/one.propmargin, while\nfor Trump those supporting and attacking him were almost evenly matched.\nFigure /two.prop(a) shows the distribution of support/attack of each candidate over the\nperiod of study. Figure /two.prop(b) shows the relative per day retweet volume for tweets\nsupporting/attacking each candidate. As expected, large spikes in volume happen\nin conjunction with major events such the presidential and vice presidential\ndebates, Election Day, the release of Trump\u2019s lewd Access Hollywood tape, and\nthe FBI announcement concerning the reopening of the investigation of Clinton.\nAn interesting observation from Figure /two.prop(b) is that tweets in favor of Trump\n(either supporting him or attacking Clinton) were retweeted more than tweets in\nfavor of Clinton for /eight.prop/five.prop% of the days, with the exception of a few days, especially\nthe day following the \ufb01rst presidential debate and following the release of Trump\u2019s\nlewd tape. This observation might be di\ufb00erent to the trends in normal media,\nwhere large number of articles were more negative towards Trump [ /two.prop/eight.prop].\nTable /three.proplists the three days for every class when each class had the largest\npercentage of tweet volume along with the leading topic. As can be seen, the\n\u201csupport Clinton\u201d class not only had the lowest average overall, but it also never\nexceed /three.prop/three.prop% on any given day. All other classes had days when their volume\nexceeded /six.prop/zero.prop% of the total retweet volume, with the \u201cattack Clinton\u201d class reach-\ning nearly /seven.prop/three.prop%. The relative volume of \u201csupport Clinton\u201d retweets peaked after\npublic appearances (promotional video, debate, and TV interview). The \u201cattack\nClinton\u201d class peaked when her health came into question and after WikiLeaks\nleaks questioned her integrity. For the \u201csupport Trump\u201d class, it peaked after\npolls showed he was ahead and after he announced the building of a wall with\nMexico. The \u201cattack Trump\u201d class peaked due positions on immigration and\nwomen. The most frequent hashtags and terms re\ufb02ect similar trends.\nTrump vs. Hillary /seven.prop\n0%10%20%30%40%50%60%70%80%90%100%\n01 Sep\n02 Sep\n03 Sep\n04 Sep\n05 Sep\n06 Sep\n07 Sep\n08 Sep\n09 Sep\n10 Sep\n11 Sep\n12 Sep\n13 Sep\n14 Sep\n15 Sep\n16 Sep\n17 Sep\n18 Sep\n19 Sep\n20 Sep\n21 Sep\n22 Sep\n23 Sep\n24 Sep\n25 Sep\n26 Sep\n27 Sep\n28 Sep\n29 Sep\n30 Sep\n01 Oct\n02 Oct\n03 Oct\n04 Oct\n05 Oct\n06 Oct\n07 Oct\n08 Oct\n09 Oct\n10 Oct\n11 Oct\n12 Oct\n13 Oct\n14 Oct\n15 Oct\n16 Oct\n17 Oct\n18 Oct\n19 Oct\n20 Oct\n21 Oct\n22 Oct\n23 Oct\n24 Oct\n25 Oct\n26 Oct\n27 Oct\n28 Oct\n29 Oct\n30 Oct\n31 Oct\n01 Nov\n02 Nov\n03 Nov\n04 Nov\n05 Nov\n06 Nov\n07 Nov\n08 NovRelative percentage of each class per day0200,000400,000600,000800,0001,000,0001,200,0001,400,000\n01 Sep\n02 Sep\n03 Sep\n04 Sep\n05 Sep\n06 Sep\n07 Sep\n08 Sep\n09 Sep\n10 Sep\n11 Sep\n12 Sep\n13 Sep\n14 Sep\n15 Sep\n16 Sep\n17 Sep\n18 Sep\n19 Sep\n20 Sep\n21 Sep\n22 Sep\n23 Sep\n24 Sep\n25 Sep\n26 Sep\n27 Sep\n28 Sep\n29 Sep\n30 Sep\n01 Oct\n02 Oct\n03 Oct\n04 Oct\n05 Oct\n06 Oct\n07 Oct\n08 Oct\n09 Oct\n10 Oct\n11 Oct\n12 Oct\n13 Oct\n14 Oct\n15 Oct\n16 Oct\n17 Oct\n18 Oct\n19 Oct\n20 Oct\n21 Oct\n22 Oct\n23 Oct\n24 Oct\n25 Oct\n26 Oct\n27 Oct\n28 Oct\n29 Oct\n30 Oct\n31 Oct\n01 Nov\n02 Nov\n03 Nov\n04 Nov\n05 Nov\n06 Nov\n07 Nov\n08 NovVolume per class per day\nsupport Trump\nattack Clinton\nattack Trump\nsupport Clinton\n1st debate\nVP debate\nTrump lewd tape\n2nd debate\n3rd debate\nFBI investigates CLinton\nElection Day\nFig./two.prop.(a) Retweet volume for each label per day, and (b) Percentage of labels per day.\nsupport Clinton\nDateLeading topic %\n/one.prop/one.prop//five.proprelease of a video promoting Clinton /three.prop/two.prop./nine.prop%\n/nine.prop//two.prop/six.propafter \ufb01rst presidential debate /three.prop/two.prop./two.prop%\n/nine.prop//two.prop/two.propinterview w/ comedy program (two Ferns) /two.prop/eight.prop./two.prop%\nattack Clinton\n/nine.prop//one.prop/one.propClinton faints at /nine.prop//one.prop/one.propmemorial /seven.prop/two.prop./nine.prop%\n/one.prop/zero.prop//three.prop/one.propWikiLeaks: Clinton got gifts from foreign governments /six.prop/nine.prop./four.prop%\n/one.prop/zero.prop//one.prop/nine.propWikiLeaks: Clinton got gift from Qatar /six.prop/two.prop./nine.prop%\nsupport Trump\n/one.prop/zero.prop//two.prop/two.propTrump leads in /three.propnational polls /six.prop/zero.prop./two.prop%\n/one.prop/zero.prop//six.propTrump leads in Virginia poll /five.prop/zero.prop./seven.prop%\n/nine.prop//one.propTrump says to build wall with Mexico /five.prop/zero.prop./one.prop%\nattack Trump\n/nine.prop//one.prop/six.propSanders attacks Trump on immigration /six.prop/six.prop./four.prop%\n/nine.prop//one.prop/five.propTrump quoted: \u201cpregnancy very inconvenient for business\u201d /six.prop/zero.prop./two.prop%\n/one.prop/zero.prop//seven.propTrump lewd tape released /five.prop/five.prop./five.prop%\nTable /three.prop.Top /three.propdays when relative volume for each class peaked with leading topic\nand percentage.\n.\nMost Frequent Hashtags In order to understand the most discussed topics\nin the viral tweets, Table /four.propshows the top hashtags that are used in attacking\nor supporting either candidate divided into categories along with the volume in\neach category. The top used hashtags for the di\ufb00erent labels reveal some stark\ncontrasts between the two candidates. These include:\n(i) The top most frequently appearing hashtags favoring Clinton were those\npraising her debate performances and attacking Trump. On the Trump side, the\nmost frequently appearing hashtags were those iterating his campaign slogans,\nencouraging people to vote, and spreading campaign news.\n(i) Hashtags of Trump\u2019s campaign slogans appeared nearly /two.prop/zero.prop/zero.proptimes more than\nClinton\u2019s campaign slogan (#IAmWithHer). In fact, Trump\u2019s campaign slogans\ncategory has the most frequently appearing hashtags.\n(ii) Hashtags indicating \u201cGet out of the vote\u201d were /four.proptimes more voluminous for\nTrump than Clinton. Trump and his campaign were more e\ufb00ective in promoting\ntheir activities (ex. #ICYMI \u2013 in case you missed it, #TrumpRally).\n(iii) Hashtags pertaining to the presidential debate appeared for every class. The\nsupport to attack hashtag volume ratio was roughly /three.prop-to-/two.propfor Clinton and /one.prop-to-/nine.prop\nfor Trump. Further, the debates were the number one category for the \u201csupport\nClinton\u201d and the \u201cattack Trump\u201d classes. It seems that most users thought that\nshe did better in the debates than him.\n/eight.propKareem Darwish et al.\nSupport Clinton\nCategory #tag Freq. Hashtags\nDebate performance /four.prop/eight.prop/six.prop,/four.prop/zero.prop/two.prop#DebateNight #Debate #SheWon #VPDebate #Debates /two.prop/zero.prop/one.prop/six.prop#NBCNews-\nForum\nAttacking Trump /one.prop/one.prop/four.prop,/six.prop/one.prop/four.prop#TrumpTapes #ImVotingBecause #TangerineNightmare #Interro-\ngateTrump #ImWithTacos #AlSmithDinner\nGet out the vote /eight.prop/six.prop,/two.prop/nine.prop/seven.prop#ElectionDay #Election /two.prop/zero.prop/one.prop/six.prop#Voting #OHVotesEarly #Vote #Elec-\ntions /two.prop/zero.prop/one.prop/six.prop\nCampaign Issues /one.prop/five.prop,/zero.prop/five.prop/five.prop#NationalComingOutDay #LatinaEqualPay\nCampaign slogan /one.prop/zero.prop,/zero.prop/eight.prop/four.prop#ImWithHer\nAttack Clinton\nCorruption/lying /eight.prop/four.prop/two.prop,/eight.prop/nine.prop/two.prop#DrainTheSwamp #CrookedHillary #BigLeagueTruth #GoldmanSach\n#FollowTheMoney #PayToPlay\nWikileaks Releases /six.prop/four.prop/zero.prop,/three.prop/three.prop/zero.prop#PodestaEmails #Wikileaks #PodestaEmails{ /eight.prop,/three.prop/one.prop,/two.prop/eight.prop,/two.prop/six.prop,/one.prop/five.prop} #SpiritCook-\ning #Podesta #DNCLeak #DNCLeak /two.prop#FreeJulian #AnthonyWeiner\nDebate performance /three.prop/four.prop/eight.prop,/seven.prop/four.prop/nine.prop#Debates /two.prop/zero.prop/one.prop/six.prop#Debate #DebateNight #VPDebate #Debates\nHealth Care /one.prop/one.prop/three.prop,/three.prop/one.prop/eight.prop#ObamaCare #ObamaCareFail #ObamaCareInThreeWords\nTension w/Sanders sup-\nporters/eight.prop/six.prop,/three.prop/three.prop/three.prop#FeelTheBern #BasementDwellers\nMedia/Election Bias /seven.prop/eight.prop,/five.prop/one.prop/one.prop#VoterFraud #RiggedSystem\nBen Ghazi attack /four.prop/six.prop,/seven.prop/two.prop/five.prop#BenGhazi\nClinton\u2019s health /three.prop/zero.prop,/seven.prop/four.prop/seven.prop#HillarysHealth\nSupport Trump\nCampaign slogans /two.prop,/zero.prop/eight.prop/nine.prop,/one.prop/six.prop/two.prop#MAGA (Make America Great Again) #DrainTheSwamp #AmericaFirst\n#MakeAmericaGreatAgain #ImWithYou #TrumpTrain #TrumpPence /one.prop/six.prop\nGet out the vote /three.prop/four.prop/nine.prop,/zero.prop/seven.prop/eight.prop#VoteTrumpPence /one.prop/six.prop#ElectionDay #VoteTrump #Vote #IVoted #Elec-\ntionNight #TheHoodForTrump #Vote /two.prop/zero.prop/one.prop/six.prop#EarlyVote\nCampaign news /one.prop/eight.prop/three.prop,/zero.prop/three.prop/one.prop#ICYMI (in case you missed it) #TrumpRally #Gettysburg (public speech)\nDebate performance /seven.prop/four.prop,/eight.prop/zero.prop/eight.prop#VPDebate #DebateNight #Debates #Debates /two.prop/zero.prop/one.prop/six.prop\nAttacking Clinton /six.prop/six.prop,/three.prop/one.prop/eight.prop#FollowTheMoney #DNCLeak #ObamaCareFailed #BigLeagueTruth\nAttack Trump\nDebate performance /seven.prop/seven.prop/six.prop,/nine.prop/five.prop/six.prop#DebateNight #Debate #VPDebate #Debates #NBCNewsForum\nSexual misconduct /seven.prop/eight.prop,/zero.prop/four.prop/three.prop#TrumpTapes #NatashaStoyno\ufb00\nGeneral attacks and in-\nsults/four.prop/four.prop,/one.prop/zero.prop/zero.prop#ImVotingBecause #TangerineNightmare #Lunatic #DangerousMan #Un-\n\ufb01t #Deceit #InterrogateTrump\nComedy attacks /two.prop/six.prop,/nine.prop/eight.prop/zero.prop#ACloserLook (segment on Seth Meyer comedy show) #AlSmithDinner\n(charity dinner)\nAttacking Trump\u2019s\nspeech/two.prop/one.prop,/one.prop/one.prop/seven.prop#LoveTrumpsHate #NastyWoman\nTable /four.prop.Top hashtags attacking or supporting both candidates with their categories.\n(iv) Attacks against Clinton focus on her character and on the WikiLeaks leaks,\nwhich cover Clinton\u2019s relationship with Wall Street (ex. #GoldmanSachs), alleged\nimpropriety in the Clinton Foundation (ex. #FollowTheMoney, #PayToPlay),\nmishandling of the Ben Ghazi attack in Libya, Democratic Party primary race\nagainst senator Sanders (ex. #BasementDewellers), the FBI investigation of\nClinton (#AnthonyWeiner), and accusation of witchcraft (#SpiritCooking).\n(v) Attacks against Trump were dominated by his debate performance. The\nfrequency of hashtags for the next category pertaining to accusations of sex-\nual misconduct (ex. #TrumpTapes) is one order of magnitude lower than the\nfrequency of those about the debate. This suggests that accusations of sexual\nmisconduct against Trump were not the primary of focus of users.\n(vi) Policy issues such as health care (ex. #ObamaCare, #LatinaEqualPay) were\neclipsed by issues pertaining to the personalities of the candidates and insults\n(ex. #CrookedHillary, #TangerineNightmare).\nMost Frequent Terms We look at the most frequent terms in the tweets to\nbetter understand the most popular topics being discussed. Figure /three.propshows\ntag-clouds of the most frequent terms for the di\ufb00erent classes, which exhibit\nsimilar trends to those in the most frequent hashtags. For example, top terms in\nthe \u201cattack Clinton\u201d class include \u201ccrooked\u201d, \u201cemails\u201d, \u201cFBI\u201d, \u201cWikiLeaks\u201d, and\n\u201c#DrainTheSwamp\u201d. Similarly, \u201c#DebateNight\u201d was prominent in the \u201csupport\nClinton\u201dand\u201cattackTrump\u201dclasses.Oneinterestingwordinthe\u201csupportTrump\u201d\nclass is the word \u201cthank\u201d, which typically appears in Trump authored tweets\nin conjunction with polls showing Trump ahead (ex. \u201cGreat poll out of Nevada-\nthank you!\u201d), after rallies (ex. \u201cGreat evening in Canton Ohio-thank you!\u201d), or in\nTrump vs. Hillary /nine.prop\n  \n(a) Support Clinton  (b) Attack Trump  \n \n  \n(c) Support Trump  (d) Attack Clinton  \n \nFig./three.prop.Tag-cloud of top frequent terms in each class support/attack Clinton/Trump.\nresponse to endorsements (ex. \u201cThank you Rep. @MarshaBlackburn!\u201d). Words of\nthanks appeared in /one.prop/six.prop/seven.prop\u201csupport Trump\u201d tweets that were retweeted more than\n/one.prop./five.propmillion times compared to /one.prop/five.prop\u201csupport Clinton\u201d tweets that were retweeted\n/seven.prop/five.propthousand times only. Another set of words that do not show in the hashtags\nare \u201cpregnancy\u201d and \u201cinconvenient\u201d that come from two tweets that mention\nthat \u201cTrump said pregnancy is very inconvenient for businesses\u201d. One of these\ntweets is the most retweeted in the \u201cattack Trump\u201d class.\nMentions of States One of the top terms that appeared in tweets supporting\nTrump is \u201cFlorida\u201d, Figure /three.prop(c). This motivated us to analyze mentions of states\nin the tweets of each class. The frequency of state mentions may indicate states\nof interest to candidates and Twitter users. Figure /four.proplists the number of times\neach of the /one.prop/five.propmost frequently mentioned states. To obtain the counts, we tagged\nall tweets using a named entity recognizer that is tuned for tweets [ /two.prop/four.prop]. We auto-\nmatically \ufb01ltered entities to obtain geolocations, and then we manually \ufb01ltered\nlocations to retain state names and city and town names within states. Then,\nwe mapped city and town names to states (ex. \u201cGrand Rapids\u201d \u2192\u201cIowa\u201d). As\nexpected, so-called \u201cswing states\u201d, which are states that could vote Republican or\nDemocrat in any given election/four.prop, dominated the list. The only non-swing states\non the list are New York, Washington, and Texas. Interestingly, the number\nof mentions in \u201csupport Trump\u201d tweets far surpasses the counts for all other\nclasses. Most of the mentions of swing states were in tweets authored by Trump\nindicating Trump rallies being held in these states. This suggests that the Trump\ncampaign e\ufb00ectively highlighted their e\ufb00orts in these states, and there was signif-\nicant interest from Twitter users as indicated by the number of retweets. Of the\nswing states in the \ufb01gure, Trump won the \ufb01rst six, namely Florida, Ohio, North\nCarolina, Pennsylvania, Michigan, and Arizona, along with Iowa and Wisconsin.\nMost Shared Links An important debate that surfaced after the US elections\nwas whether fake news a\ufb00ected the election results or not [ /one.prop/one.prop,/one.prop/six.prop]. Thus, we analyze\nthe credibility of the websites that were most linked to in the tweets for each\n/four.prophttps://projects.\ufb01vethirtyeight.com/ /two.prop/zero.prop/one.prop/six.prop-election-forecast/\n/one.prop/zero.propKareem Darwish et al.\nSupport Clinton Attack Trump\nLink CountVolumeLeaning Credibility Link CountVolumeLeaning Credibility\nHillaryclinton.com /six.prop/three.prop/three.prop/six.prop/three.prop,/one.prop/five.prop/three.propLeft \u2013Hillaryclinton.com /six.prop/five.prop/two.prop/three.prop/six.prop,/one.prop/two.prop/six.propLeft \u2013\nDemocrats.org /eight.prop/one.prop/two.prop/zero.prop,/zero.prop/two.prop/six.propLeft \u2013WashingtonPost.com /two.prop/three.prop/one.prop/zero.prop/two.prop,/one.prop/seven.prop/nine.prop-/two.propHigh\nIWillVote.com /two.prop/six.prop/one.prop/zero.prop/one.prop,/nine.prop/nine.prop/six.propLeft \u2013IWillVote.com /one.prop/one.prop/nine.prop/five.prop,/one.prop/two.prop/six.propLeft \u2013\nSnappyTV.com /one.prop/four.prop/five.prop/eight.prop,/nine.prop/two.prop/six.propN/A Mixed SnappyTV.com /one.prop/four.prop/eight.prop/six.prop,/one.prop/zero.prop/zero.propN/A Mixed\nCNN.com /six.prop/four.prop/three.prop,/three.prop/five.prop/five.prop-/three.propHigh Democrats.org /three.prop/six.prop/seven.prop,/eight.prop/four.prop/three.propLeft \u2013\nWashingtonPost.com /one.prop/zero.prop /two.prop/seven.prop,/two.prop/six.prop/four.prop-/two.propHigh Newsweek.com /one.prop/one.prop/five.prop/five.prop,/six.prop/six.prop/three.prop-/three.propHigh\nMedium.com /eight.prop/two.prop/seven.prop,/one.prop/eight.prop/seven.prop-/two.propMixed NYTimes.com /nine.prop/three.prop/seven.prop,/nine.prop/nine.prop/three.prop-/two.propHigh\nBusinessInsider.com /four.prop/one.prop/six.prop,/zero.prop/one.prop/zero.prop-/two.propHigh CNN.com /six.prop/two.prop/seven.prop,/two.prop/seven.prop/five.prop-/three.propHigh\nNYTimes.com /six.prop/one.prop/five.prop,/eight.prop/eight.prop/six.prop-/two.propHigh Vox.com /four.prop/one.prop/three.prop,/nine.prop/nine.prop/two.prop-/four.propHigh\nYouTube.com /two.prop/one.prop/one.prop,/five.prop/six.prop/four.propN/A Mixed Facebook.com /two.prop/one.prop/one.prop,/nine.prop/seven.prop/three.propN/A Mixed\nSupport Trump Attack Clinton\nDonaldJTrump.com /seven.prop/seven.prop/five.prop/zero.prop/three.prop,/three.prop/seven.prop/five.propright WikiLeaks.org /four.prop/seven.prop/four.prop/zero.prop/six.prop,/six.prop/zero.prop/seven.prop /two.propHigh\nFacebook.com /two.prop/five.prop/one.prop/six.prop/four.prop,/nine.prop/nine.prop/five.propN/A Mixed DailyCaller.com /two.prop/two.prop/one.prop/nine.prop/five.prop,/six.prop/nine.prop/five.prop /four.propMixed\nWashingtonPost.com /seven.prop/five.prop/six.prop,/eight.prop/five.prop/five.prop-/two.propHight FoxNews.com /two.prop/eight.prop/one.prop/four.prop/six.prop,/five.prop/seven.prop/one.prop /four.propMixed\nLifezette.com /three.prop/four.prop/nine.prop,/one.prop/three.prop/two.prop /four.propMixed YouTube.com /two.prop/nine.prop/one.prop/zero.prop/seven.prop,/nine.prop/one.prop/five.propN/A Mixed\nSnappyTV.com /four.prop/three.prop/six.prop,/six.prop/six.prop/three.propN/A Mixed Breitbart.com /one.prop/seven.prop/one.prop/zero.prop/two.prop,/nine.prop/four.prop/nine.prop /five.propMixed\nInstagram.com /five.prop/three.prop/six.prop,/one.prop/three.prop/two.propN/A Mixed Politico.com /one.prop/one.prop/nine.prop/three.prop,/one.prop/six.prop/five.prop-/two.propHigh\nDailyCaller.com /three.prop/three.prop/five.prop,/four.prop/seven.prop/four.prop /four.propMixed NYPost.com /one.prop/four.prop /nine.prop/two.prop,/one.prop/four.prop/seven.prop /three.propMixed\nNYPost.com /four.prop/three.prop/four.prop,/nine.prop/three.prop/zero.prop /three.propMixed CNN.com /one.prop/one.prop/seven.prop/eight.prop,/seven.prop/nine.prop/seven.propRight\nPeriscope.tv /three.prop/two.prop/two.prop,/five.prop/nine.prop/six.propN/A Mixed Vox.com /one.prop/six.prop /seven.prop/seven.prop,/three.prop/four.prop/zero.prop /three.propHigh\nYouTube.com /five.prop/two.prop/zero.prop,/zero.prop/four.prop/six.propN/A Mixed Facebook.com /nine.prop/six.prop/three.prop,/eight.prop/nine.prop/six.prop /three.propHigh\nTable /five.prop.Top shared links per class \u2013 support/attack Clinton/Trump \u2013 with ideological\nleaning (- /five.propextreme left to /five.propextreme right) and credibility (high or mixed) according\ntohttps://mediabiasfactcheck.com/\nclass. Our analysis shows that /two.prop/nine.prop% of the viral tweets ( /two.prop/one.prop% of the full retweet\nvolume) contained external links. Table /five.propshows the top /one.prop/zero.propweb domains that\nwere linked to in the tweets dataset along with ideological leaning and credibility\nrating. Aside from the o\ufb03cial websites of the campaigns (ex. HillaryClinton.com ,\nDemocrats.org , andDonaldJTrump.com ), the remaining links were to news\nwebsites (ex. CNN and NYTimes) and social media sites (ex. Facebook, Insta-\ngram, and YouTube). As Table /five.propshows, the candidates\u2019 o\ufb03cial websites received\nthe most links. However, it is interesting to note the large di\ufb00erence in focus\nbetween both. Clinton\u2019s website attacked Trump than it supported Clinton, while\nTrump\u2019s website did the exact opposite. This again shows the di\ufb00erences in\nstrategies and trends between both candidates and their supporters. We checked\nthe leaning and credibility of the news websites on mediabiasfactcheck.com , a\nfact checking website which rates news sites anywhere between \u201cExtreme Left\u201d\nto \u201cExtreme Right\u201d and their credibility between \u201cVery Low\u201d and \u201cVery High\u201d\nwith \u201cMixed\u201d being the middle point. We assumed social media sites to have\nno ideological leaning with a credibility of \u201cMixed\u201d. We opted for assigning\ncredibility to websites as opposed to individual stories, because investigating\nthe truthfulness of individual stories is rather tricky and is beyond the scope of\nthis work. Though some stories are easily debunked, such as the Breitbart story\nclaiming that \u201cHillary gave an award to a terrorist\u2019s wife/five.prop\u201d, other mix some truth\nwith opinion, stretched truth, and potential lies, such as the Breitbart story that\nthe \u201cFBI is seething at the botched investigation of Clinton\u201d.\nFigure /four.propaggregates all the number of retweets for each category for the\nwebsites with credibility of \u201cHigh\u201d and \u201cMixed\u201d \u2013 none of the sites had credibility\nof \u201cVery High\u201d, \u201cLow\u201d, or \u201cVery Low\u201d. The aggregate number of links for all\ncategories to \u201cHigh\u201d and \u201cMixed\u201d credibility websites was /one.prop./zero.prop/four.propmillion and /one.prop./one.prop/eight.prop\nmillion respectively. The \ufb01gure shows that a signi\ufb01cantly higher proportion of\nhighly credible websites were linked to for the \u201csupport Clinton\u201d and \u201cattack\n/five.prophttp://bit.ly/ /two.propd/nine.prop/nine.proplWD/6http://bit.ly/ /two.proptEUxVw\nTrump vs. Hillary /one.prop/one.prop\nFig./four.prop.Mentions of states for each class.\n Fig./five.prop.Credibility of websites that are\nlinked to from each category\nTrump\u201d categories compared to mixed credibility sites. The opposite was true\nfor the \u201csupport Trump\u201d category, where the majority of links used to support\nTrump was from mixed creditability websites. This may indicate that Trump\nsupporters were more susceptible to share less credible sources compared to\nClinton supporters. High and mixed credibility sites were evenly matched for the\n\u201cattack Clinton\u201d category. WikiLeaks was the foremost shared site for attacking\nClinton, which has high credibility. This again highlights the role of WikiLeaks in\nsteering public opinion against Clinton. It worth mentioning that \u201cThe Podesta\nEmails/six.prop\u201d was the most popular link. Thus, though lower credibility links were\nused to attack Clinton, high credibility links featured prominently. For ideological\norientation, left leaning sources featured prominently in the \u201csupport Clinton\u201d\nand \u201cattack Trump\u201d classes, and right leaning sources featured prominently for\nthe two other classes. The only left leaning sources appearing on the \u201csupport\nTrump\u201d and \u201cattack Clinton\u201d lists were Washington Post and Politico.\nMost Retweeted Tweets Table /six.proplists the top /five.propmost retweeted/seven.proptweets for\neach class. They illustrate the trends to those exhibited in our previous analysis,\nnamely: \u201csupport Clinton\u201d tweets are led by talk about debates and attacks\nagainst Trump; the most retweeted \u201cattack Clinton\u201d tweets are from WikiLeaks;\nTrump campaign slogans appear atop of \u201csupport Trump\u201d tweets; and the most\nretweeted attack Trump\u201d tweets cover demeaning statements against women\nand minorities and mockery of Trump. An interesting observation is that the\nmost retweeted tweet attacking Trump came from a Nigerian account with screen\nname \u201cOzzyonce\u201d who had less than /two.prop,/zero.prop/zero.prop/zero.propfollowers at the time when she posted\nthe tweet. Nonetheless, this tweet received over /one.prop/five.prop/zero.propK retweets in one day.\nMost Retweeted Accounts Table /seven.proplists the most retweeted accounts for each\nclass. As expected, the most retweeted accounts for \u201csupport\u201d and \u201cattack\u201d classes\nwere those of the candidates themselves and their rivals respectively. Notably:\n(i) Clinton authored /one.prop/zero.prop% more \u201cattack Trump\u201d tweets (with /three.prop/five.prop% more volume)\n/six.prophttps://wikileaks.org/podesta-emails/\n/seven.propThe number of retweets in the table are taken in November /two.prop/zero.prop/one.prop/six.prop\n/one.prop/two.propKareem Darwish et al.\nDate Author Text Count\nsupport Clinton\n/nine.prop//two.prop/seven.propJerry Springer Hillary Clinton belongs in the White House. Donald Trump belongs on my show. /seven.prop/eight.prop,/eight.prop/seven.prop/two.prop\n/nine.prop//two.prop/seven.propHillary Clinton RT this if you re proud to be standing with Hillary tonight. #debatenight\nhttps://t.co/ /nine.prop/one.proptBmKxVMs/seven.prop/two.prop,/four.prop/four.prop/three.prop\n/one.prop/zero.prop//one.prop/zero.propErin Ruberry Hillary is proof a woman can work hard rise to the top of her \ufb01eld still have to\ncompete against a less quali\ufb01ed man for the same job./seven.prop/two.prop,/one.prop/six.prop/seven.prop\n/one.prop/zero.prop//two.prop/zero.propHillary Clinton RT if you\u2019re proud of Hillary tonight. #DebateNight #SheWon\nhttps://t.co/H /seven.propCJep /seven.propAPX/seven.prop/two.prop,/one.prop/five.prop/zero.prop\n/one.prop/zero.prop//eight.propRichard Hine Trump: Don t judge me on the man I was /one.prop/zero.propyears ago. But please judge Hillary\non the man her husband was /two.prop/zero.propyears ago #TrumpTapes/six.prop/six.prop,/eight.prop/one.prop/seven.prop\nattack Clinton\n/one.prop/one.prop//one.propWikiLeaks No link between Trump Russia No link between Assange Russia But Podesta Clin-\nton involved in selling /two.prop/zero.prop% of US uranium to Russia/five.prop/one.prop,/three.prop/one.prop/one.prop\n/one.prop/zero.prop//one.prop/four.propWikiLeaks Democrats prepared fake Trump grope under the meeting table Craigslist employ-\nment advertisement in May /two.prop/zero.prop/one.prop/six.prophttps://t.co/JM /nine.propJMeLYet/four.prop/five.prop,/three.prop/four.prop/eight.prop\n/one.prop/zero.prop//three.propWikiLeaks Hillary Clinton on Assange Can t we just drone this guy \u2013 report\nhttps://t.co/S /seven.proptPrl/two.propQCZ https://t.co/qy /two.propEQBa /four.prop/eight.propy/four.prop/five.prop,/two.prop/three.prop/three.prop\n/one.prop/one.prop//four.propDonald J. Trump If Obama worked as hard on straightening out our country as he has trying to\nprotect and elect Hillary we would all be much better o\ufb00!/four.prop/two.prop,/three.prop/three.prop/one.prop\n/one.prop/one.prop//eight.propCloyd Rivers To everyone who wants to vote for Hillary just to keep Trump from becomin\nPresident watch this... https://t.co/TuUpD /seven.propQgcg/four.prop/one.prop,/zero.prop/four.prop/seven.prop\nsupport Trump\n/one.prop/one.prop//eight.propDonald J. Trump TODAY WE MAKE AMERICA GREAT AGAIN! /three.prop/five.prop/two.prop,/one.prop/four.prop/zero.prop\n/one.prop/one.prop//five.propDonald J. Trump MAKE AMERICA GREAT AGAIN! /six.prop/zero.prop,/seven.prop/one.prop/eight.prop\n/one.prop/zero.prop//eight.propDonald J. Trump Here is my statement. https://t.co/WAZiGoQqMQ /five.prop/two.prop,/eight.prop/eight.prop/seven.prop\n/one.prop/one.prop//seven.propImmigrants /four.propTrumpIf you make this go viral Trump will win. It s about /two.propminutes that makes the\nchoice in this election crystal clear https://t.co/CqMY /four.propCSJbp/four.prop/three.prop,/six.prop/two.prop/seven.prop\n/one.prop/zero.prop//one.prop/zero.propMike Pence Congrats to my running mate @realDonaldTrump on a big debate win! Proud to\nstand with you as we #MAGA./four.prop/two.prop,/one.prop/seven.prop/eight.prop\nattack Trump\n/nine.prop//one.prop/five.propOzzyonce Donald Trump said pregnancy is very inconvenient for businesses like his mother\ns pregnancy hasn\u2019t been inconvenient for the whole world./one.prop/five.prop/two.prop,/seven.prop/five.prop/six.prop\n/one.prop/zero.prop//two.prop/six.propBailey Disler Good morning everyone especially the person who destroyed Donald Trump s walk\nof fame star https://t.co/IcBthxMPd /nine.prop/one.prop/two.prop/four.prop,/three.prop/two.prop/two.prop\n/one.prop/zero.prop//two.prop/one.propStephen King My newest horror story: Once upon a time there was a man named Donald Trump\nand he ran for president. Some people wanted him to win./one.prop/two.prop/one.prop,/six.prop/three.prop/five.prop\n/one.prop/zero.prop//one.prop/zero.propKat Combs Trump writing a term paper: Sources Cited: /one.prop. You Know It /two.prop. I know It /three.prop. Every-\nbody Knows It/one.prop/zero.prop/five.prop,/one.prop/one.prop/eight.prop\n/one.prop/zero.prop//eight.propEs un racista Anna for you to sit here call Trump a racist is outrageous Anna: OH?! Well lemme\ndo it again in /two.proplanguages! https://t.co/nq /four.propDO/seven.propbN/seven.propJ/one.prop/zero.prop/two.prop,/zero.prop/six.prop/three.prop\nTable /six.prop.Top retweeted tweets for each class \u2013 support/attack Clinton/Trump.\nthan \u201csupport Clinton\u201d. In contrast, Trump authored /eight.prop/one.prop% more \u201csupport Trump\u201d\ntweets (with /three.prop/eight.prop% more volume) than \u201cattack Clinton\u201d tweets. This suggests that\nClinton expended more energy attacking her opponent than promoting herself,\nwhile Trump did the exact opposite. Trump campaign sta\ufb00ers and accounts, such\nas Kellyanne Conway, Dan Scavino Jr., and O\ufb03cial Team Trump, were slightly\nmore active in the \u201cattack Clinton\u201d class than the \u201csupport Trump\u201d class.\n(ii) Trump Campaign accounts featured prominently in \u201csupport Trump\u201d and\n\u201cattack Clinton\u201d classes, capturing /seven.propout of /one.prop/zero.propand/four.propout of /one.prop/zero.proptop spots for both\nclasses respectively. In contrast, Clinton campaign account captured /two.propout of\n/one.prop/zero.propand/one.propout of /one.prop/zero.proptop spots for \u201csupport Clinton\u201d and \u201cattack Trump\u201d classes\nrespectively. Top Clinton aides like Huma Abedin and John Podesta were absent\nfrom the top list, suggesting a more concerted Trump campaign Twitter strategy.\n(iii) Though Clinton authored /four.prop/eight.prop% more tweets attacking her rival than tweets\nTrump authored attacking her, his attack tweets led to /three.prop/four.prop% more retweet volume.\nThis suggests that his attacks were more e\ufb00ective than her attacks. Trump tweets\nwere more retweeted on average than Clinton\u2019s tweets with an average of /one.prop/one.prop,/one.prop/nine.prop/five.prop\nand/six.prop,/one.prop/two.prop/zero.propretweets per tweet for both respectively. Highlighting WikiLeaks\u2019 role\nin the election, WikiLeaks was the second most retweeted account attacking\nClinton and had four times as much retweet volume than the next account.\nDiscussion\nOur analysis contrasts di\ufb00erences in support for either candidate, namely:\nPopularity: While Trump received more negative coverage than Clinton in\nTrump vs. Hillary /one.prop/three.prop\nsupport Clinton attack Trump\nAccount Count Volume Account Count Volume\nHillary Clinton /three.prop/three.prop/one.prop /two.prop,/zero.prop/two.prop/five.prop,/eight.prop/two.prop/one.propHillary Clinton /three.prop/six.prop/three.prop /two.prop,/six.prop/nine.prop/eight.prop,/two.prop/zero.prop/nine.prop\nPresident Obama /four.prop /one.prop/two.prop/two.prop,/nine.prop/four.prop/seven.propBernie Sanders /one.prop/one.prop /three.prop/zero.prop/four.prop,/eight.prop/six.prop/zero.prop\nSenator Tim Kaine /one.prop/five.prop /eight.prop/four.prop,/two.prop/four.prop/five.propOzzyonce /one.prop /one.prop/five.prop/two.prop,/seven.prop/five.prop/six.prop\nJerry Springer /one.prop /seven.prop/eight.prop,/eight.prop/seven.prop/two.propBailey Disler /one.prop /one.prop/two.prop/four.prop,/three.prop/two.prop/two.prop\nErin Ruberry /one.prop /seven.prop/two.prop,/one.prop/six.prop/seven.propStephen King /two.prop /one.prop/two.prop/one.prop,/six.prop/three.prop/five.prop\nRichard Hine /one.prop /six.prop/six.prop,/eight.prop/one.prop/seven.propKat Combs /one.prop /one.prop/zero.prop/five.prop,/one.prop/one.prop/eight.prop\nBernie Sanders /seven.prop /four.prop/six.prop,/one.prop/eight.prop/zero.propEs un racista /one.prop /one.prop/zero.prop/two.prop,/zero.prop/six.prop/three.prop\nCNN /six.prop /four.prop/one.prop,/nine.prop/eight.prop/three.propRob Fee /one.prop /nine.prop/nine.prop,/four.prop/zero.prop/one.prop\nFunny Or Die /one.prop /two.prop/seven.prop,/nine.prop/zero.prop/nine.propJerry Springer /one.prop /seven.prop/eight.prop,/eight.prop/seven.prop/two.prop\nChannel /four.propNews /one.prop /two.prop/seven.prop,/four.prop/zero.prop/nine.propMaster of None /one.prop /six.prop/seven.prop,/six.prop/nine.prop/zero.prop\nSupport Trump attack Clinton\nDonald J. Trump /four.prop/four.prop/six.prop /four.prop,/nine.prop/nine.prop/two.prop,/eight.prop/four.prop/five.propDonald J. Trump /two.prop/four.prop/six.prop /three.prop,/six.prop/one.prop/three.prop,/zero.prop/two.prop/five.prop\nKellyanne Conway /five.prop/one.prop /one.prop/nine.prop/nine.prop,/five.prop/one.prop/one.propWikiLeaks /one.prop/four.prop/one.prop /one.prop,/four.prop/five.prop/four.prop,/nine.prop/zero.prop/three.prop\nMike Pence /three.prop/six.prop /one.prop/nine.prop/five.prop,/eight.prop/two.prop/four.propKellyanne Conway /nine.prop/two.prop /three.prop/four.prop/nine.prop,/zero.prop/two.prop/five.prop\nDan Scavino Jr. /four.prop/zero.prop /one.prop/eight.prop/one.prop,/six.prop/zero.prop/one.propPaul Joseph Watson /seven.prop/eight.prop /two.prop/nine.prop/seven.prop,/two.prop/seven.prop/three.prop\nO\ufb03cial Team Trump /one.prop/four.prop /one.prop/four.prop/one.prop,/two.prop/eight.prop/nine.propO\ufb03cial Team Trump /two.prop/three.prop /one.prop/five.prop/zero.prop,/nine.prop/three.prop/two.prop\nDonald Trump Jr. /two.prop/zero.prop /one.prop/one.prop/two.prop,/eight.prop/three.prop/five.propDonald Trump Jr. /three.prop/four.prop /one.prop/two.prop/six.prop,/seven.prop/four.prop/four.prop\nEric Trump /eight.prop /seven.prop/nine.prop,/three.prop/eight.prop/seven.propJared Wyand /one.prop/nine.prop /eight.prop/five.prop,/seven.prop/four.prop/two.prop\nImmigrants /four.propTrump /four.prop /five.prop/two.prop,/two.prop/five.prop/six.propCloyd Rivers /seven.prop /eight.prop/four.prop,/zero.prop/six.prop/three.prop\nCloyd Rivers /two.prop /four.prop/five.prop,/four.prop/nine.prop/three.propJuanita Broaddrick /four.prop /eight.prop/three.prop,/nine.prop/zero.prop/three.prop\nPaul Joseph Watson /one.prop/zero.prop /three.prop/eight.prop,/four.prop/seven.prop/four.propJames Woods /one.prop/six.prop /seven.prop/eight.prop,/seven.prop/one.prop/nine.prop\nTable /seven.prop.Top retweeted accounts per class \u2013 support/attack Clinton/Trump. Accounts\nof candidates and campaign a\ufb03liates are italicized.\nmainstream media [ /two.prop/eight.prop], Trump bene\ufb01ted from many more tweets that are either\nsupporting him or attacking his rival. In fact, /six.prop/three.prop% of the volume of viral content\non US election were in his favor compared to only /three.prop/seven.prop% in favor of Clinton.\nSimilarly, on /eight.prop/five.prop% of the days in the last two months preceding the election,\nTrump had more tweets favoring him than Clinton. This observation shows the\ngap between the trends of social media and traditional news media.\nPositive vs negative attention: The volume of tweets attacking and support-\ning Trump were evenly matched, while the volume of tweets attacking Clinton\noutnumbered tweets praising her by a /three.prop-to-/one.propmargin. Given the importance of\nsocial media in elections, this may have been particularly damaging.\nSupport points: Trump campaign accounts featured more prominently in the\ntop retweeted accounts supporting their candidate. Support came in the form\nof promoting his slogans, urging supporters to vote, and featuring positive polls\nand campaign news. Conversely, Clinton support came mostly in the form of\ncontrasting her to her rival, praise for her debate performance against Trump,\nand praise for her attacks on Trump. In fact, viral tweets from her campaign\naccount were attacking Trump more than promoting her. Unfortunately for her,\nshe was framed in reference to her rival, and research has shown that debates\nhave a dwindling e\ufb00ect election outcomes as the election day draws closer [ /two.prop,/eight.prop,/one.prop/two.prop].\nConsequently, her post-debate surges in volume of attacks against Trump eclipsed\nsurges of support for her.\nAttack points: Both candidates were attacked on di\ufb00erent things. Trump was\nmainly attacked on his debate performance, eclipsing attacks related to his scan-\ndals, such as the lewd Access Hollywood tape. Luckily for him, debates have\na diminishing e\ufb00ect on voters as election day draws near [ /two.prop,/eight.prop,/one.prop/two.prop]. Conversely\nfor Clinton, persistent allegations of corruption and wrongdoing triggered by\nWikiLeaks and the FBI investigation of her emails dominated attacks against\nher. These attacks may have led to her eventual loss, with polls suggesting that\n\u201cemail de\ufb01ne(d) Clinton\u201d/eight.prop.\n/eight.propgallup.com/poll/ /one.prop/eight.prop/five.prop/four.prop/eight.prop/six.prop/email-de\ufb01nes-clinton-immigration-de\ufb01nes-trump.aspx\n/one.prop/four.propKareem Darwish et al.\nMessage penetration: Trump\u2019s slogan, \u201cMake America Great Again\u201d, had a\nfar greater reach than that of his rival, \u201cStronger Together\u201d. Similarly, his policy\npositions and agenda items, such as the proposal to build a wall with Mexico,\nattracted signi\ufb01cantly more attention than those of Clinton, where her proposed\npolicy positions received very little mention.\nGeographical focus: Trump and his supporters e\ufb00ectively promoted his cam-\npaign\u2019s e\ufb00orts in swing state, with frequent mentions of rallies and polls from\nthese states along with messages of thanks for people turning-out for his rallies.\nThe volume of tweets mentioning swing states and supporting Trump were typi-\ncally two orders of magnitude larger than similar tweets supporting Clinton. This\nmight have contributed to the narrow victory he achieved in many of them.\nLow credibility links: Trump supporters were more likely to share links from\nwebsites of questionable credibility than Clinton supporters. However, WikiLeaks,\nwhich has high credibility, was the most prominent source attacking Clinton.\nTo better understand the presented results, a few limitations that need to be\nconsidered. First, the top /five.prop/zero.propviral tweets do not have to be representative of the\nwhole collection. Nonetheless, they still represent over /four.prop/zero.prop% of the tweets volume\non the US elections during the period of the study. Second, the results are based\non tweets collected from TweetElect. Although it is highly robust, the site uses\nautomatic \ufb01ltering methods that are not perfect [ /one.prop/nine.prop]. Therefore, there might be\nother relevant viral tweets that were not captured by the \ufb01ltering method. Lastly,\nmeasuring support for a candidate using viral tweets does not have to represent\nactual support on the ground for many reasons. Some of these reasons include\nthe fact that demographics of Twitter users may not match the general public,\nmore popular accounts have a better chance of having their tweets go viral, or\neither campaign may engage in astrotur\ufb01ng, in which dedicated groups or bots\nmay methodically tweet or retweet pro-candidate messages [ /three.prop].\nConclusion\nIn this paper, we presented quantitative and qualitative analysis of the top\nretweeted tweets pertaining to the US presidential elections from September\n/one.prop,/two.prop/zero.prop/one.prop/six.propto election day on November /eight.prop,/two.prop/zero.prop/one.prop/six.prop. For everyday, we tagged the\ntop/five.prop/zero.propmost retweeted tweets as supporting/attacking either candidate or as\nneutral/irrelevant. Then we analyzed the tweets in each class from the perspective\nof: general trends and statistics; most frequent hashtags, terms, and locations;\nand most retweeted accounts and tweets. Our analysis highlights some of the\ndi\ufb00erencesbetweenthesocialmediastrategiesofbothcandidates,thee\ufb00ectiveness\nof both in pushing their messages, and the potential e\ufb00ect of attacks on both. We\nshow that compared to the Clinton campaign, the Trump campaign seems more\ne\ufb00ective in: promoting Trump\u2019s messages and slogans, attacking and framing\nClinton, and promoting campaign activities in \u201cswing\u201d states. For future work,\nwe would like to study the users who retweeted the viral tweets in our study to\nascertain such things as political leanings and geolocations. This can help map\nthe political dynamics underlying the support and opposition of both candidates.\nTrump vs. Hillary /one.prop/five.prop\nReferences\n/one.prop.Barber\u00e1, P., Jost, J.T., Nagler, J., Tucker, J.A., Bonneau, R.: Tweeting from left to\nright is online political communication more than an echo chamber? Psychological\nscience ( /two.prop/zero.prop/one.prop/five.prop)\n/two.prop.Benoit, W.L., Hansen, G.J., Verser, R.M.: A meta-analysis of the e\ufb00ects of viewing\nus presidential debates. Communication Monographs /seven.prop/zero.prop(/four.prop),/three.prop/three.prop/five.prop\u2013/three.prop/five.prop/zero.prop(/two.prop/zero.prop/zero.prop/three.prop)\n/three.prop.Bessi, A., Ferrara, E.: Social bots distort the /two.prop/zero.prop/one.prop/six.propus presidential election online\ndiscussion. First Monday /two.prop/one.prop(/one.prop/one.prop) (/two.prop/zero.prop/one.prop/six.prop)\n/four.prop.Bollen, J., Mao, H., Pepe, A.: Modeling public mood and emotion: Twitter sentiment\nand socio-economic phenomena. ICWSM /one.prop/one.prop,/four.prop/five.prop/zero.prop\u2013/four.prop/five.prop/three.prop(/two.prop/zero.prop/one.prop/one.prop)\n/five.prop.Bovet, A., Morone, F., Makse, H.A.: Predicting election trends with twitter: Hillary\nclinton versus donald trump. arXiv preprint arXiv: /one.prop/six.prop/one.prop/zero.prop./zero.prop/one.prop/five.prop/eight.prop/seven.prop(/two.prop/zero.prop/one.prop/six.prop)\n/six.prop.Colleoni, E., Rozza, A., Arvidsson, A.: Echo chamber or public sphere? predicting\npolitical orientation and measuring political homophily in twitter using big data.\nJournal of Communication /six.prop/four.prop(/two.prop),/three.prop/one.prop/seven.prop\u2013/three.prop/three.prop/two.prop(/two.prop/zero.prop/one.prop/four.prop)\n/seven.prop.Davis, C.A., Varol, O., Ferrara, E., Flammini, A., Menczer, F.: Botornot: A system\nto evaluate social bots. In: Proceedings of the /two.prop/five.propth International Conference\nCompanion on World Wide Web. pp. /two.prop/seven.prop/three.prop\u2013/two.prop/seven.prop/four.prop. International World Wide Web\nConferences Steering Committee ( /two.prop/zero.prop/one.prop/six.prop)\n/eight.prop.Erikson, R.S., Wlezien, C.: The timeline of presidential elections: How campaigns\ndo (and do not) matter. University of Chicago Press ( /two.prop/zero.prop/one.prop/two.prop)\n/nine.prop.Gayo-Avello, D.: Don\u2019t turn social media into another\u2019literary digest\u2019poll. Commu-\nnications of the ACM /five.prop/four.prop(/one.prop/zero.prop),/one.prop/two.prop/one.prop\u2013/one.prop/two.prop/eight.prop(/two.prop/zero.prop/one.prop/one.prop)\n/one.prop/zero.prop.Gayo Avello, D., Metaxas, P.T., Mustafaraj, E.: Limits of electoral predictions using\ntwitter. In: Proceedings of the Fifth International AAAI Conference on Weblogs\nand Social Media. Association for the Advancement of Arti\ufb01cial Intelligence ( /two.prop/zero.prop/one.prop/one.prop)\n/one.prop/one.prop. Giglietto, F., Iannelli, L., Rossi, L., Valeriani, A.: Fakes, news and the election: A\nnew taxonomy for the study of misleading information within the hybrid media\nsystem ( /two.prop/zero.prop/one.prop/six.prop)\n/one.prop/two.prop.Hillygus, D.S., Jackman, S.: Voter decision making in election /two.prop/zero.prop/zero.prop/zero.prop: Campaign\ne\ufb00ects, partisan activation, and the clinton legacy. American Journal of Political\nScience /four.prop/seven.prop(/four.prop),/five.prop/eight.prop/three.prop\u2013/five.prop/nine.prop/six.prop(/two.prop/zero.prop/zero.prop/three.prop)\n/one.prop/three.prop.Jungherr, A.: Analyzing political communication with digital trace data. Cham,\nSwitzerland: Springer ( /two.prop/zero.prop/one.prop/five.prop)\n/one.prop/four.prop.Jungherr, A., J\u00fcrgens, P., Schoen, H.: Why the pirate party won the german election\nof/two.prop/zero.prop/zero.prop/nine.propor the trouble with predictions: A response to tumasjan, a., sprenger, to,\nsander, pg, & welpe, im \u201cpredicting elections with twitter: What /one.prop/four.prop/zero.propcharacters\nreveal about political sentimen\u201d. Social science computer review /three.prop/zero.prop(/two.prop),/two.prop/two.prop/nine.prop\u2013/two.prop/three.prop/four.prop\n(/two.prop/zero.prop/one.prop/two.prop)\n/one.prop/five.prop.Kollanyi, B., Howard, P.N., Woolley, S.C.: Bots and automation over twitter during\nthe \ufb01rst us presidential debate. Comprop Data Memo ( /two.prop/zero.prop/one.prop/six.prop)\n/one.prop/six.prop.Kucharski, A.: Post-truth: Study epidemiology of fake news. Nature /five.prop/four.prop/zero.prop(/seven.prop/six.prop/three.prop/four.prop),\n/five.prop/two.prop/five.prop\u2013/five.prop/two.prop/five.prop(/two.prop/zero.prop/one.prop/six.prop)\n/one.prop/seven.prop.Magdy, W., Darwish, K.: Trump vs. hillary analyzing viral tweets during us presi-\ndential elections /two.prop/zero.prop/one.prop/six.prop. arXiv preprint arXiv: /one.prop/six.prop/one.prop/zero.prop./zero.prop/one.prop/six.prop/five.prop/five.prop(/two.prop/zero.prop/one.prop/six.prop)\n/one.prop/eight.prop.Magdy, W., Darwish, K., Abokhodair, N., Rahimi, A., Baldwin, T.: # isisisnotislam\nor# deportallmuslims?: Predicting unspoken views. In: Proceedings of the /eight.propth ACM\nConference on Web Science. pp. /nine.prop/five.prop\u2013/one.prop/zero.prop/six.prop. ACM ( /two.prop/zero.prop/one.prop/six.prop)\n/one.prop/six.propKareem Darwish et al.\n/one.prop/nine.prop.Magdy, W., Elsayed, T.: Adaptive method for following dynamic topics on twitter.\nIn: ICWSM ( /two.prop/zero.prop/one.prop/four.prop)\n/two.prop/zero.prop.Magdy, W., Elsayed, T.: Unsupervised adaptive microblog \ufb01ltering for broad\ndynamic topics. Information Processing & Management /five.prop/two.prop(/four.prop),/five.prop/one.prop/three.prop\u2013/five.prop/two.prop/eight.prop(/two.prop/zero.prop/one.prop/six.prop)\n/two.prop/one.prop.Metaxas, P.T., Mustafaraj, E., Gayo-Avello, D.: How (not) to predict elections. In:\nPrivacy, Security, Risk and Trust (PASSAT) and /two.prop/zero.prop/one.prop/one.propIEEE Third Inernational\nConference on Social Computing (SocialCom), /two.prop/zero.prop/one.prop/one.propIEEE Third International\nConference on. pp. /one.prop/six.prop/five.prop\u2013/one.prop/seven.prop/one.prop. IEEE ( /two.prop/zero.prop/one.prop/one.prop)\n/two.prop/two.prop.Mislove, A., Lehmann, S., Ahn, Y.Y., Onnela, J.P., Rosenquist, J.N.: Understanding\nthe demographics of twitter users. ICWSM /one.prop/one.prop,/five.propth (/two.prop/zero.prop/one.prop/one.prop)\n/two.prop/three.prop.O\u2019Connor, B., Balasubramanyan, R., Routledge, B.R., Smith, N.A.: From tweets\nto polls: Linking text sentiment to public opinion time series. ICWSM /one.prop/one.prop(/one.prop/two.prop/two.prop-/one.prop/two.prop/nine.prop),\n/one.prop\u2013/two.prop(/two.prop/zero.prop/one.prop/zero.prop)\n/two.prop/four.prop.Ritter, A., Clark, S., Etzioni, O., et al.: Named entity recognition in tweets: an\nexperimental study. In: Proceedings of the Conference on Empirical Methods\nin Natural Language Processing. pp. /one.prop/five.prop/two.prop/four.prop\u2013/one.prop/five.prop/three.prop/four.prop. Association for Computational\nLinguistics ( /two.prop/zero.prop/one.prop/one.prop)\n/two.prop/five.prop.Shi, L., Agarwal, N., Agrawal, A., Garg, R., Spoelstra, J.: Predicting us primary\nelections with twitter. URL: http://snap. stanford. edu/social /two.prop/zero.prop/one.prop/two.prop/papers/shi. pdf\n(/two.prop/zero.prop/one.prop/two.prop)\n/two.prop/six.prop.Shirky, C.: The political power of social media: Technology, the public sphere, and\npolitical change. Foreign a\ufb00airs pp. /two.prop/eight.prop\u2013/four.prop/one.prop(/two.prop/zero.prop/one.prop/one.prop)\n/two.prop/seven.prop.Tumasjan, A., Sprenger, T.O., Sandner, P.G., Welpe, I.M.: Predicting elections\nwith twitter: What /one.prop/four.prop/zero.propcharacters reveal about political sentiment. ICWSM /one.prop/zero.prop,\n/one.prop/seven.prop/eight.prop\u2013/one.prop/eight.prop/five.prop(/two.prop/zero.prop/one.prop/zero.prop)\n/two.prop/eight.prop.Van Aelst, P., Van Erkel, P., D\u00e2\u0102\u0179heer, E., Harder, R.A.: Who is leading the cam-\npaign charts? comparing individual popularity on old and new media. Information,\nCommunication & Society /two.prop/zero.prop(/five.prop),/seven.prop/one.prop/five.prop\u2013/seven.prop/three.prop/two.prop(/two.prop/zero.prop/one.prop/seven.prop)\n/two.prop/nine.prop.Wang, Y., Li, Y., Luo, J.: Deciphering the /two.prop/zero.prop/one.prop/six.propus presidential campaign in the\ntwitter sphere: A comparison of the trumpists and clintonists. arXiv preprint\narXiv: /one.prop/six.prop/zero.prop/three.prop./zero.prop/three.prop/zero.prop/nine.prop/seven.prop(/two.prop/zero.prop/one.prop/six.prop)\n/three.prop/zero.prop.Wang, Y., Luo, J., Niemi, R., Li, Y., Hu, T.: Catching \ufb01re via\"likes\": Inferring topic\npreferences of trump followers on twitter. arXiv preprint arXiv: /one.prop/six.prop/zero.prop/three.prop./zero.prop/three.prop/zero.prop/nine.prop/nine.prop(/two.prop/zero.prop/one.prop/six.prop)\n/three.prop/one.prop.West, D.M.: Air wars: Television advertising and social media in election campaigns,\n/one.prop/nine.prop/five.prop/two.prop-/two.prop/zero.prop/one.prop/two.prop. Sage ( /two.prop/zero.prop/one.prop/three.prop)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Trump vs. Hillary: What went viral during the 2016 US presidential election", "author": ["K Darwish", "W Magdy", "T Zanouda"], "pub_year": "2017", "venue": "International conference on social \u2026", "abstract": "In this paper, we present quantitative and qualitative analysis of the top retweeted tweets (viral  tweets) pertaining to the US presidential elections from September 1, 2016 to Election"}, "filled": false, "gsrank": 237, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-319-67217-5_10", "author_id": ["y7tlR6UAAAAJ", "ACQD8jMAAAAJ", "3vnwlekAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:38-omEEMQ54J:scholar.google.com/&output=cite&scirp=236&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D230%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=38-omEEMQ54J&ei=LrWsaJ_HDrTWieoP1pCJ2AY&json=", "num_citations": 77, "citedby_url": "/scholar?cites=11403972157305835487&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:38-omEEMQ54J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1707.03375"}}, {"title": "Involvement drives complexity of language in online debates", "year": "2025", "pdf_data": "arXiv:2506.22098v1  [cs.CL]  27 Jun 2025INVOLVEMENT DRIVES COMPLEXITY OF LANGUAGE IN ONLINE\nDEBATES\nCOMPLEXITY 72H\nEleonora Amadori1,\nDaniele Cirulli2,\nEdoardo Di Martino3,\nJacopo Nudo4,\nMaria Sahakyan5,\nEmanuele Sangiorgio3,\nArnaldo Santoro6,\nSimon Zollo3,\nAlessandro Galeazzi1, and\n Niccol\u00f2 Di Marco4\n1Department of Mathematics, University of Padova, Padova, 35121 , eleonora.amadori@studenti.unipd.it ,\nalessando.galeazzi@unipd.it\n2Department of Physics and INFN, University of Rome \u201cTor Vergata\u201d, Rome, 00133, Italy , \u201cEnrico Fermi\u201d Research\nCenter, Rome, 00184, Italy , daniele.cirulli@cref.it\n3Department of Social Sciences and Economics, Sapienza University of Rome, Rome, 00185 ,\nedoardo.dimartino@uniroma1.it ,emanuele.sangiorgio@uniroma1.it ,simon.zollo@uniroma1.it\n4Department of Computer Science, Sapienza University of Rome, Rome, 00161 , jacopo.nudo@uniroma1.it ,\nniccolo.dimarco@uniroma1.it\n5Social Science Division, New York University Abu Dhabi, Abu Dhabi, 129188 , ms13502@nyu.edu\n6Department of Environmental Sciences, Informatics, and Statistics, Ca\u2019 Foscari University of Venice, Venezia, 30123 ,\narnaldo.santoro@unive.it\nJune 30, 2025\nABSTRACT\nLanguage is a fundamental aspect of human societies, continuously evolving in response to various\nstimuli, including societal changes and intercultural interactions. Technological advancements have\nprofoundly transformed communication, with social media emerging as a pivotal force that merges\nentertainment-driven content with complex social dynamics. As these platforms reshape public\ndiscourse, analyzing the linguistic features of user-generated content is essential to understanding\ntheir broader societal impact. In this paper, we examine the linguistic complexity of content produced\nby influential users on Twitter across three globally significant and contested topics: COVID-19,\nCOP26, and the Russia\u2013Ukraine war. By combining multiple measures of textual complexity, we\nassess how language use varies along four key dimensions: account type, political leaning, content\nreliability, and sentiment. Our analysis reveals significant differences across all four axes, including\nvariations in language complexity between individuals and organizations, between profiles with sided\nversus moderate political views, and between those associated with higher versus lower reliability\nscores. Additionally, profiles producing more negative and offensive content tend to use more\ncomplex language, with users sharing similar political stances and reliability levels converging\ntoward a common jargon. Our findings offer new insights into the sociolinguistic dynamics of digital\nplatforms and contribute to a deeper understanding of how language reflects ideological and social\nstructures in online spaces.\nKeywords Language Complexity \u00b7Online Discourse \u00b7Social Media\n1 Introduction\nLanguage has played a pivotal role in the development of human society, functioning as a fundamental medium for the\ntransmission of knowledge and the coordination of social interaction [ 1]. Over time, languages have evolved in response\nto several factors, such as changing socio-political conditions and intercultural contact, which may result in lexical\nborrowing, code-switching, and, in some cases, the formation of new dialects or creole languages [ 2]. As technological\nand socio-political landscapes continue to change, the nature and intensity of intercultural interactions have also\nchanged, particularly with the advent of digital communication technologies, which have dramatically increased\nComplexity72h 23-27 J UNE 2025 - M ADRID\nthe volume, speed, and global reach of such exchanges [ 3,4]. In this landscape, the rise of social media platforms\nplays a pivotal role, profoundly impacting the way people connect, communicate, and access information. With their\nincreasing popularity, these platforms have emerged as a key data source to analyze public discourse, information\ndiffusion, and social dynamics on a large scale. Their unique structure, comprising short user-generated messages,\nhashtags, mentions, and share mechanisms, has allowed researchers to study a wide range of troubling phenomena\nsuch as increased polarization [ 5,6,7,8,9,10], the spread of misinformation [ 11,12], and the amplification of hate\nspeech [ 13,14]. Unlike traditional media, Social Media Platforms offer immediacy, broad reach, and high variability\nin sentiment, tone, and engagement, making it a rich source for large-scale behavioral analysis [ 15,16,17], natural\nlanguage processing [ 18,19], and public opinion research [ 20]. Furthermore, previous studies have utilized social\nmedia data to investigate not only the content of online conversations but also the behavioral patterns and influence\ndynamics of users [21, 22].\nWithin this context, increasing interest is growing in analyzing the linguistic features of user-generated content [ 23,\n24,25,26]. These studies offer important insights into the complex social dynamics of communication in digital\nplatforms [ 27]. Nevertheless, accurately measuring language complexity remains a challenging task, particularly in\nspecialized domains that go beyond traditional linguistic and communicative-discursive frameworks\u2014most notably\nin psycho-cognitive areas such as reading comprehension and information processing [ 28,29]. Although extensive\nresearch in the educational field to examine the impact of vocabulary size and highlight individual differences in lexical\nknowledge has been conducted [30], the evolution of these dynamics in the digital era remains largely unexplored.\nDriven by concerns that internet may corrupt traditional writing conventions and face-to-face communication [ 31,32,\n33,34], interest in linguistic research on social media has been recently increasing. Notably, recent studies exhibit\npatterns of linguistic simplification [ 35,36] in the comments published in social media, while other researches measure\nthe same process of simplification in different domains [ 37,38]. Despite recent efforts, a fundamental question remains\nunanswered: do users with different stances or characteristics employ distinct vocabulary and linguistic properties?\nIn this study, we leverage a large-scale dataset of tweets posted by influencers on Twitter/X, covering three major topics:\nCOVID-19, COP26 and the Ukraine war. In addition, we collect detailed information on each influencer\u2019s stance and\nsocial characteristics, allowing for a more in-depth analysis.\nUsing this dataset, we apply multiple measures of textual complexity to the tweets, extracting a range of linguistic\nfeatures. Moreover, we apply tools from Network Science to understand how similar influencers are in terms of used\nlanguage.\nOur results reveal differences in the complexity of the language used by individual or organizations, as well as an effect\nof political stances and levels of reliability. Moreover, noxious semantic traits of users\u2019 language such as offensiveness\nand negative sentiment result in an higher complexity of the users\u2019 vocabulary.\nFinally, the semantic network of influencers reveals distinct clusters reflecting a convergence between language\nsimilarity, political bias, and reliability.\nBy unveiling the linguistic and ideological structures that underlie language complexity among key actors in the digital\nspace, our study sheds light on the mechanisms driving opinion formation and content dissemination in contemporary\nonline ecosystems\u2014ultimately contributing to a deeper understanding of how public discourse is shaped in the digital\nage.\n2 Methods\n2.1 Data Collection\nAll data used in this work were collected via the former Twitter API for Academic Research, using search queries\nspecific to each dataset. These datasets were originally compiled and curated as part of a previous study [ 39], from\nwhich we built upon for our analysis. We briefly summarize how the datasets are gathered.\nTweets and user information related to the COP26 debate were collected using the keyword \u201ccop26\u201d, spanning the\nperiod from 1 June 2021 to 14 November 2021\nData about COVID-19 were collected between 1 January 2020 and 30 April 2021 using keyword searches that included:\n\u201cvaccin\", \u201cdose\", \u201cpharma\", \u201cimmun\", \u201cno-vax\", \u201cnovax\", \u201cpro-vax\", \u201cprovax\", \u201cantivax\", and \u201canti-vax\".\nTweets about Ukraine were collected by tracking specific keywords related to the Russia-Ukraine conflict, spanning the\nperiod from 22 February 2022 to 17 February 2023. The tweet IDs were obtained from a publicly available dataset [ 40],\nfrom which a random sample comprising 25% of the available IDs was downloaded.\n2\nComplexity72h 23-27 J UNE 2025 - M ADRID\nFor each dataset, a set of \u201cinfluencers\u201d who played a prominent role in shaping the online debate was identified. Starting\nfrom the top 1% most retweeted accounts, those also ranked in the top 50% of original tweet producers (excluding\nreplies, quotes, and retweets) were selected to ensure consistent and active participation.\nInfluencers were manually labelled using questionnaires by the authors of Loru et al [ 39]. Each account was assigned to\none of six categories based on their social, political, or professional role: Activist, International Organization/NGO,\nMedia, Politics, Private Individual, or Other. Influencers were annotated independently for each topic, and only if they\nappeared among the selected accounts for that particular dataset.\nIn the current study, we focus on english tweets published by the influencers. A data breakdown of the resulting dataset\nis shown in Table 1.\nWe clarify that these datasets have been selected as they pertain to topics that have been the subject of significant debate\nin recent years.\nTable 1: Breakdown of the datasets used in the study. For each dataset, we report the number of tweets, the number of\nunique users, and the time span covered in the analysis.\nEvent N. of Tweets N. of unique users Time-span\nCOVID-19 607192 1488 01 /01/2020\u221230/04/2021\nCOP26 135636 561 01 /06/2021\u221214/11/2021\nUkraine 916955 967 22 /02/2022\u221217/02/2023\nTotal 1659783 3016\n2.2 Text Pre-processing\nAll tweets were preprocessed to keep only the significant part of the texts and avoid spurious results. All the tweets\nwere also cleaned of emojis, hashtag, tag, and URL. To compute K-complexity and vocabulary size, we concatenate all\ntexts published by an influencer and use the quanteda package in R to apply the following pre-processing steps:\n\u2022 We tokenize the texts and remove punctuation and English stopwords;\n\u2022 We reduce the resulting tokens to their root form by applying a stemmer;\n\u2022 We set each token to lowercase.\nIn this way, we obtain a set of tokens (words) and types (unique words) for each influencer.\nNote that, since a text may remain empty after these steps (for example, in the case it contains only tags or hashtags),\nwe removed all users containing 0 tokens.\n2.3 Labeling Users\u2019 Political Stance and Factual Reliability\nTo classify users according to political stance and the reliability of the content they shared, we employ Google\u2019s Gemini\nlarge language model, in line with recent studies demonstrating the effectiveness of large language models for social\nmedia annotation tasks [ 42,43]. Users are categorized as Left, Center, or Right leaning in terms of political orientation,\nand as either Reliable or Questionable with respect to the factual credibility of the content they disseminated. To ensure\nrobustness, we validate the model-generated labels against external assessments from MediaBias/FactCheck (MBFC,\nseehttps://mediabiasfactcheck.com ), a widely used independent news rating agency that provides political bias\nand reliability labels for news outlets and other information producers [ 6,44,45]. Although the overlap between our\ndataset and MBFC is limited (56 matched users), we compute Cohen\u2019s Kappa coefficient to assess the agreement\nbetween the two labeling systems. Results indicate a level of agreement from moderate to substantial for both political\nstance ( \u03ba= 0.58) and content reliability ( \u03ba= 0.75), suggesting that our automated labeling procedure is both reliable\nand consistent with established external benchmarks. The corresponding confusion matrices are reported in Figure S1\nand Figure S2 of the Supplementary Information appendix.\n2.4 Sentiment and Offensive Language Classification\nTransformer-based language models consistently demonstrate excellence performance in tweet classification tasks due\nto their ability to capture contextual, informal, and affective nuances present in social media text [ 46]. One of the\nmost widely adopted models is RoBERTa (Robustly Optimized BERT Pre-Training Approach), a variant of BERT\nthat removes the next-sentence prediction objective, trains with significantly more data, uses larger mini-batches and\n3\nComplexity72h 23-27 J UNE 2025 - M ADRID\nlearning rates, and dynamically changes the masking pattern during training to improve the model\u2019s ability to learn\ncontextual representations [ 47]. Its architecture makes it particularly well-suited for handling the lexical variability,\nslang, and conversational structure of social media content.\nFor sentiment analysis, RoBERTa and its variations achieve strong performance across diverse domains [ 48,49,50,\n51,52]. Comparative evaluations show that RoBERTa and BERTweet outperform earlier transformer architectures\nwhen adapted to in-domain Twitter content [ 53]. In the area of offensive language detection, RoBERTa-based models\ndemonstrate state-of-the-art performance across multiple benchmark evaluations. Barbieri et al. [ 54] introduced a\nRoBERTa model fine-tuned on a standardized suite of Twitter-based classification tasks, showing superior results\nin offensive language detection relative to prior models. Studies confirm the effectiveness of RoBERTa variants in\nidentifying offensive, abusive, or toxic language in multilingual and event-driven Twitter datasets, consistently reporting\nhigh accuracy and improved generalization across domains [55, 56].\nGiven the effectiveness and scalability of RoBERTa-based models in both sentiment and offensive language classification\ntasks, we selected domain-specific variants fine-tuned on Twitter data for our analysis. To fully exploit their capabilities\nand ensure reliable inference, we applied a structured pre-processing pipeline to align the raw tweet content with the\nmodels\u2019 input requirements.\nIn particular, to ensure the compatibility of Twitter content with RoBERTa-based models and to minimize noise, we first\nconvert all tweets into a standardized textual format, addressing issues of encoding, syntactic artifacts, and non-standard\nsymbols commonly found in user-generated content. Hypertext markup, external links, and long isolated numeric\nsequences are removed, as they offer limited linguistic value for sentiment or toxicity classification. User handles (i.e.\n\u201c@\" mentions) are replaced with a standardized placeholder to reduce lexical variability while preserving conversational\nstructure. Emojis are converted into textual descriptors to preserve their affective content in a form compatible with\nthe model\u2019s tokenizer. Punctuation and typographic inconsistencies, including non-standard quotation marks and\nexcessive whitespace, are normalized, and non-ASCII characters are excluded to prevent tokenization errors. Tweets\nare also screened for minimal linguistic content: entries consisting exclusively of user mentions, retweet shells without\ncommentary, or only hashtags are excluded. Furthermore, tweets dominated by non-verbal tokens (e.g., emojis or\nsymbols), are flagged for quality control. These pre-processing steps ensure that the input data conforms to the structural\nand lexical conventions of the pre-trained RoBERTa models, thereby enhancing the robustness of downstream inference.\nFollowing pre-processing, we apply two transformer-based language models to classify each tweet along distinct\ndimensions: sentiment and offensive language. Both models are based on the RoBERTa architecture and were pre-\ntrained on large-scale Twitter corpora. The sentiment classification model categorizes tweets into three classes: positive,\nneutral and negative [ 57] while the offensive language classifier distinguishes between offensive and non-offensive\ntweets [ 46]. Computation is performed on a GPU-enabled environment to accelerate inference, and the resulting\npredictions are used in subsequent analyses of linguistic patterns and discourse dynamics across events.\nIn total, we process 1,359,793 unique tweets authored by 3,016 distinct users. To enable user-level analysis of sentiment\nand offensive behavior, we aggregate the model predictions across all tweets associated with each user. Specifically, we\ncalculate the proportion of tweets labeled as negative to represent a user\u2019s overall negativity score, and similarly compute\nthe percentage of tweets classified as offensive to quantify their offensiveness level. We rely on these aggregated\nmetrics to analyze patterns in how individual users express themselves on Twitter and perform a systematic comparisons\nbetween different groups.\n2.5 Textual Complexity\nText complexity can be analyzed from multiple perspectives, and the academic literature offers a wide range of metrics\nfor this purpose [ 60,61,62,63,64,65]. Following a thorough review of the existing measures and related research, we\nselect two specific metrics that capture different, complementary dimensions of textual complexity: Yule\u2019s Kmeasure\nof lexical richness, gzip-based compression complexity and Flesch readability score.\nWe remove, on the raw text of tweets, each \u201c@\u201d, \u201c#\u201d, and emojis found in them, to avoid any distortion of the results.\nThese three measures provide a relatively orthogonal view, allowing for a more comprehensive assessment of three\ndifferent text characteristic: lexical complexity, repeatitivity and easiness of reading.\nIn more detail, Yule\u2019s K-complexity [ 66] quantifies how repetitive or diverse the vocabulary is, and it is considered to\nbe largely independent of the overall length of a text. In detail, for a text of length Ncontaining a Vunique words,\nYule\u2019s Kis defined as\nK= 104\u00b7\"\n\u22121\nN+VX\ni=1V(i, N)\u0012i\nN\u00132#\n,\n4\nComplexity72h 23-27 J UNE 2025 - M ADRID\nwhere V(i, N)represents the number of words that occur itimes. The measure has a theoretical lower bound of 0,\nwhich is achieved only when all words in the text are distinct (e.g., V(1, N) =N). In general, as Kincreases, the\nlexical richness of the text decreases, although there is no theoretical upper bound for the measure.\nTo assess the repetitiveness of a text, we adopt an approach similar to previous studies [37, 67, 35].\nThis approach estimates the compressibility of concatenated tweets for each user, with the underlying assumption that\nmore repetitive or predictable texts compress better than complex or diverse ones.\nThe procedure involves measuring the size in bytes of the original text (encoded in UTF-8) and then compressing the\nsame text using the G-Zip algorithm. The compressed size is also recorded. From these measurements, we compute the\ncompression ratio defined as the size of the compressed text divided by the size of the original text:\ngzip =scompressed\nsraw, (1)\nwhere srawrepresents the size of the raw text and scompressed the size of the compressed text.\nLower compression ratios indicate higher redundancy and lower complexity, whereas higher ratios suggest richer\nand less predictable language use. This metric complements traditional readability scores by capturing structural and\ninformational properties of the text.\nTo evaluate the readibility of tweets, we also consider the Flesch Index . This metric is commonly used to assess the\nreadability of English texts, providing a numerical score based on sentence length and syllable density. The formula is\ndefined as follows:\nFlesch Index = 206 .835\u22121.015\u00b7\u0012# words\n# of sentences\u0013\n\u221284.6\u00b7\u0012# of syllables\n# of words\u0013\n(2)\nHigher scores indicate texts that are easier to read (with standard journalistic English typically scoring between 60 and\n70), whereas lower or negative scores reflect more complex or less natural language structures.\n2.6 Statistically Validated Projections for Bipartite Networks\nIn this section, we discuss our procedure to construct the influencers network. First, we build a weighted bipartite\nnetwork W={wi\u03b1}between influencers iand content-types \u03b1, where wi\u03b1measures how extensively influencer iuses\ntype\u03b1. To focus on the most relevant links, we binarize Wvia the Revealed Comparative Advantage (RCA) filter [ 68]:\nRCA i\u03b1=wi\u03b1P\n\u03b2wi\u03b2P\njwj\u03b1P\nj,\u03b2wj\u03b2=\u21d2 mi\u03b1=\u001a1,ifRCA i\u03b1>1,\n0,otherwise,(3)\nwhere the binary matrix M={mi\u03b1}retains only links exceeding the expected global usage.\nNext, to project Monto the influencer layer while correcting for degree bias\u2014i.e., the tendency of high-degree\ninfluencers to exhibit spurious overlaps\u2014and filtering out random noise, we employ the Bipartite Configuration Model\n(BiCM) [ 69,70], a maximum-entropy null model for bipartite networks. This approach constructs an ensemble of\nnetworks Gthat is maximally random except that it preserves the degree sequences: kifor each influencer iand\u03ba\u03b1for\neach type \u03b1. We then derive, for each influencer pair (i, j), the null distribution of their shared neighbors and compute\nthe corresponding p-value.\nTo this end, we perform a constrained maximization of the Shannon entropy, which quantifies the uncertainty in the\nnetwork\u2019s configuration:\nS=\u2212X\nG\u2208GP(G) lnP(G), (4)\nThe equation \u27e8C\u27e9=P\nGP(G)C(G)determines the ensemble average of the constraint. Introducing Lagrange\nmultipliers {\u03b8i}and{t\u03b1}associated with these constraints, we define the Hamiltonian H(G;{\u03b8i, t\u03b1}) =P\ni\u03b8iki(G)+P\n\u03b1t\u03b1\u03ba\u03b1(G).\nMaximizing the entropy subject to constraints on the degrees of influencers kiand types \u03ba\u03b1yields the graph probability\ndistribution\n5\nComplexity72h 23-27 J UNE 2025 - M ADRID\nReutersDrEricDing\nNovavaxRobertKennedyJrCNN\nEricTopollog10(y) = 1.7+0.55 log10(x)\n10100100010000\n10030010003000\n Vocabulary Size\nIndividual\nOrganizationCOVID\u221219\nGretaThunberg\nJamesMelvilleNetZeroWatch\nRT_comredmayne_robert\nSgkPlanet_enlog10(y) = 1.6+0.58 log10(x)\n30010003000\n3010030010003000\nNumber of Tweets COP26\nRussianEmbassy\nKyivIndependentGerashchenko_enBSBonner\nNATOFidget02log10(y) = 1.7+0.59 log10(x)\n3001000300010000\n100 1000 10000\n  Ukraine\nFigure 1: Bivariate distribution of the number of tweets and the vocabulary size for each influencer considered in the\nanalysis. The color indicates whether the influencer is an individual or an organization. Notably, the dataset reveals\ndistinct clusters for each category. Regression lines obtained through Ordinary Least Squares (OLS) are also shown.\nLog-transformed marginal distributions are also shown on the axes.\nP(G| {\u03b8i, t\u03b1}) =e\u2212H(G;{\u03b8i,t\u03b1})\nZ({\u03b8i, t\u03b1}), (5)\nwhere Z(\u20d7\u03b8) =P\nG\u2208Ge\u2212H(G,\u20d7\u03b8)is the partition function over the ensemble.\nSolving the model, requiring that the ensemble averages of the constraints match their empirical values in G\u2217, yields\nthe independent link probabilities pi\u03b1[69].\nWe then compute, for each influencer pair (i, j), the null distribution of their shared neighbors under independent\nBernoulli trials and obtain the corresponding p-value for each projected link.\nFinally, we apply a false discovery rate (FDR) multiple-testing correction [ 71], retaining only those influencer pairs\nwith statistically significant co-occurrences in the validated projection.\nAll statistical validations were implemented using the software package described in Vallarano et al. [72].\nNetwork metrics were computed as detailed in the Supporting Information appendix. Community detection was\nperformed by maximizing modularity with the Louvain algorithm [ 73], and network layouts for visualization were\ngenerated using Gephi [74].\n3 Results\n3.1 Summary Statistics of Influencer Activity and Vocabulary Size\nWe begin our analysis by presenting an overview of the three datasets. Figure 1 illustrates the relationship between the\nnumber of tweets and the size of the vocabulary (i.e., the number of word types) for each influencer. The marginal\ndistributions of tweet count and vocabulary size are also shown, both exhibiting a heavy-tailed pattern that indicates\nthat most influencers produced relatively few tweets and employed a rather limited vocabulary.\nGiven that the two variables are log-transformed, the regression line reveals a power-function relationship between the\nnumber of posts published and the vocabulary size.\nInterestingly, we observe consistent trends across topics, characterized by comparable slope values, a notable regularity\nbetween datasets.\nAcross all topics, the most active influencers tend to use a wider variety of types (i.e., unique words used). No-\ntable examples include @Reuters (organization) for COVID-19, @redmayne _robert (individual) for COP26, and\n@BSBonner (individual) for the Russia-Ukrainian event. Interestingly, some influencers behave differently from oth-\ners. For instance, @SgkPlanet _en(activist organization) during the COP26 event and @Fidget 02(private individual)\nduring the Russia-Ukraine war published a large number of tweets but used a significantly limited vocabulary. These\npatterns highlight the importance of considering both activity level and linguistic diversity when analyzing influence\n6\nComplexity72h 23-27 J UNE 2025 - M ADRID\nand communication strategies across different events. Furthermore, the plots reveal the presence of distinct clusters for\nindividual and organizational influencers, suggesting different vocabulary characteristics.\nOverall, this first analysis provides a descriptive understanding of influencers\u2019 activity and language use, revealing\nconsistent patterns between vocabulary size and tweet volume across topics, as well as systematic differences between\nindividual and organizational accounts.\n3.2 Complexity Analysis\nWe then focus on the analysis of text complexity, comparing complexity measures across five different spectra: account\ntype, political leaning, content reliability, users\u2019 negativity of sentiment, and users\u2019 offensiveness.\nLexical complexity is quantified using Yule\u2019s K, while repeatitivity and readability aspects are measured using the gzip\ncompression ratio and the Flesch Reading Ease Index, respectively, as detailed in the Methods section. We report only\nthe results for Yule\u2019s Kin the main text, while results for the latter two are illustrated in Figure S3 and Figure S4 in\nthe Supplementary Information appendix.\nCategory, political stance and reliability Figure 2 shows the K\u2212complexity distributions according to the account\ntype (individual vs. organization), political stance, and reliability of the account, determined as explained in the Methods\nsection.\nNotably, as shown in Panel a), individuals exhibit statistically significantly lower K-complexity scores, showing how\ntheir language appears to be more complex than that used by organizations. These results are persistent and significant\nacross all three datasets as confirmed by the Kruskal-Wallis test, the results of which are reported in Table S1 of the\nSupporting Information appendix.\nIn Panel b), it can be observed how profiles expressing a lower political bias (Center) display higher values of K-\ncomplexity scores, while both left and right wing profiles tend to exhibit lower values of the metric, and so showing a\nhigher complexity of vocabulary used. This is possibly indicating that those who are more engaged in writing messages\nalong partisan lines tend to use a vocabulary greater in size and complexity.\nHowever, the Kruskal-Wallis tests highlight that only the COVID-19 dataset displays significant differences based\non the political leaning of influencers, while the COP26 and the Ukraine datasets show no statistically significant\ndifferences.\nFinally, Panel c) shows that accounts flagged as questionable in terms of content reliability tend to use more lexically\ncomplex language in the COVID-19 dataset. For the COP26 and Ukraine datasets, the differences are not significant.\nHowever there is a degree of variation in results across the three datasets, we show in Figure S3 and S4 of the\nSupplementary Information appendix that, when employing gzip orFlesch Index as a measure of redundancy of\nlanguage and readability, the patterns discussed above are shown to be persistent across the datasets.\nOffensiveness and Sentiment To investigate the connection between linguistic complexity and user behavior on\nTwitter during significant global events, we examine the association between Yule\u2019s K-complexity and aggregated\nmeasures of offensiveness and negative sentiment at the user level. The users were grouped into four categories, low,\nmedium, high and very high , according to the quartile of the distribution of their respective scores.\nFigure 3 shows the relationship between K-complexity, offensiveness, and negativity at the user-level.\nAs we can observe from both Panel a) and b), users in higher classes tend to exhibit lower K-complexity scores,\nindicating the use of more complex language. This inverse relationship is most pronounced in the context of COVID-19,\nbut the same trend is observed for COP26 and the Russia-Ukraine conflict, as confirmed by Figure S3 and Figure S4 in\nthe Supporting Information appendix. Overall, the pattern remains consistent across all three events. This suggests\nthat users who are more engaged in writing content that carries negative or offensive weight tend to express their\nperspectives with greater linguistic complexity.\n3.3 Analysis of Influencer Networks\nBuilding on our earlier findings, we aim to investigate whether distinct groups of influencers use different lexical\nchoices. To this end, for each of the three datasets we construct a weighted bipartite network linking \u201cInfluencers\u201d to the\n\u201cTypes\u201d, defined as the unique words they use. First, we binarize the bipartite network using the RCA filter (see Methods\n2.6). Next, we perform a statistical validation based on the Bipartite Configuration Model (BiCM) (see Methods 2.6)\nwhen projecting the bipartite network onto the influencer layer. This step filters out random noise, yielding a one-mode\nnetwork in which edges represent only statistically significant co-occurrences of influencers sharing types. Tables\n7\nComplexity72h 23-27 J UNE 2025 - M ADRID\nCOVID\u221219 COP26 Ukraine\n101001000\nAccount TypeK\u2212complexity\nIndividual Organizationa)\nCOVID\u221219 COP26 Ukraine\n1030100300\nPolitical LeaningK\u2212complexity\nLeftCenter Rightb)\nCOVID\u221219 COP26 Ukraine\n1030100300\nReliabilityK\u2212Complexity\nQuestionable Reliablec)\nFigure 2: K-complexity distributions according to a) the account type of the influencers (Individual or Organization), b)\nthe political leaning of the influencer (Left, Center, Right), c) the reliability of the influencer (Questionable or Reliable).\nS2 and S3 summarize the original bipartite networks and their statistically validated projections (see Supplementary\nInformation). Although the bipartite graphs are large, the BiCM-based validation filters out random noise (see Methods\n2.6), eliminating several influencers in the projection (i.e. those who share no types at a statistically significant level;\nsee S3 in Supplementary Information). We then detect communities in each co-occurrence network using the Louvain\nalgorithm by maximizing modularity (see Table S3).\nIn Figure 4a), we represent the three networks, highlighting the communities we found.\nTo understand if these communities are defined by a clear political orientation or reliability labels, we compute the\naverage political leaning and reliability scores of the users they comprise, along with the Shannon Entropy of these\ndistributions to assess the cluster\u2019s heterogeneity [ 75]. In doing so, we remove users with unknown political bias or\nunknown reliability labels to normalize the data.\n8\nComplexity72h 23-27 J UNE 2025 - M ADRID\nCOVID\u221219 COP26 Ukraine\n30100300\nOffensiveness ClassK\u2212Complexitya)\nCOVID\u221219 COP26 Ukraine\n30100300\nNegative Sentiment ClassK\u2212Complexityb)Low\nMid\nHigh\nVery High\nFigure 3: K-complexity distributions by (a) user offensiveness class and (b) negative sentiment class. The offensiveness\nclass is defined based on how frequently a user posts offensive tweets, while the negative sentiment class is determined\nby the average negativity score of the user\u2019s tweets.\nThe results, shown in Panel b) and c) of Figure 4, suggest that communities can be characterized by the political stance\nor reliability of their influencers. The COP26 dataset seems to be better clustered through the political dimension than\nCovid and Ukraine. On the other hand, all three datasets exhibit nice clustering according to the reliability score.\nNotably, this indicates that influencers sharing similar point of view both from political and reliability are more likely to\nuse similar words.\nFinally, we note how the alignment between the cluster community structure and the political / reliability dimensions\nis strongest in the dataset about COVID-19 and COP26 networks, precisely those with the highest modularity scores\n(reported in Tab. S3), probably reflecting the more science-driven nature of these topics (e.g., vaccines, climate science)\ncompared to debates rooted in politics. This could suggest that scientific topics tend to distinguish more the language\nused by actors with opposite opinions.\n4 Discussion\nWe investigate the complexity of language on social media by analyzing a set of influential Twitter/X users across\nthree highly debated topics: COVID-19, COP26, and the Russia-Ukraine war. We study several aspects that can\ninfluence language complexity, measuring its variations along four dimensions: account type, political stance, reliability,\nand sentiment. To this end, we employ a diverse set of metrics and methodologies, including K-complexity, gzip\ncompression, Flesch readability index, sentiment analysis, and network analysis.\nOur results reveal several noteworthy insights into how influencers communicate on social media. First, we identify a\nconsistent polynomial relationship between the size of an influencer\u2019s vocabulary and the volume of content published\nacross all three topics. We also find that individuals tend to use more complex language than organizations, possibly\ndue to greater freedom in expressing personal opinions.\nIn addition, according to two out of three employed complexity measures, language complexity varies with political\nstance and reliability: users with stronger partisan alignments exhibit higher complexity than politically neutral users,\nand accounts labeled as questionable show greater complexity than those deemed reliable. Further, NLP analyses\nindicate that users who frequently post negative or offensive content also tend to use more complex language. Finally,\n9\nComplexity72h 23-27 J UNE 2025 - M ADRID\nCOVID-19 COP26 Ukrainea)\nb)\nc)\nFigure 4: (a)Visualization of the influencers\u2019 networks for the three datasets. In panels (b)and(c), Size represent the\nnumber of influencers in each community, colors represent the political leaning ( b) or the reliability label ( c) of the\ncommunities detected using the Louvain algorithm. For each community, the number next to the bar represents the\nvalue of the Shannon Entropy calculated on the relative distribution of the political leaning or reliability label.\nour network-based analysis highlights how users with similar political stances or reliability labels are more likely to\nproduce linguistically similar content. Our results suggest that users with greater involvement, even of a different\nnature, tend to use more complex language in online debates. This dynamic is consistent across the three global debates.\nMoreover, we observe that these differences are more pronounced in the COVID-19 and COP26 datasets\u2014the topics\nmore closely tied to scientific discourse. Interestingly, this may suggest a higher linguistic differences in scientific topics\ncompared to those of a more socio-political nature such as the Russian-Ukranian conflict. Ultimately, these results as a\nwhole highlights how users with higher involvement - whether it results from political, ideological or behavioral and\ncivility elements - generally show a more complex vocabulary. These insights help to deep more into the dynamics of\nonline debates, particularly referring to the most active and influential users.\nOur results shed light on the complex relationship between language and influence on social media. Despite its\ncontributions, our study is subject to some limitations that also point to important avenues for future research. First,\nour analysis is restricted to Twitter/X, which may not generalize to other online spaces. Second, the study primarily\nanalyzes English-language posts, potentially excluding linguistic nuances or trends present in other languages or regions.\n10\nComplexity72h 23-27 J UNE 2025 - M ADRID\nFuture studies could extend this work in several directions. First, analyzing language complexity across other social\nmedia platforms and in multiple languages would enhance generalizability. Second, longitudinal analyses could reveal\nhow complexity evolves over time in response to events. Finally, incorporating different user classification methods and\na wider range of topics may improve accuracy and scope.\n5 Acknowledgements\nThis work is the output of the Complexity72h workshop, held at the Universidad Carlos III de Madrid in Legan\u00e9s,\nSpain, 23-27 June 2025 https://www.complexity72h.com . We thank Paolo Benanti and Walter Quattrociocchi for\ninspiring our analysis and project.\nReferences\n[1] David Crystal. The Cambridge encyclopedia of the English language . Cambridge university press, 2018.\n[2]Sarah Grey Thomason and Terrence Kaufman. Language contact, creolization, and genetic linguistics . Univ of\nCalifornia Press, 2023.\n[3]Jannis Androutsopoulos. Mediatization and sociolinguistic change , volume 36. Walter de Gruyter GmbH & Co\nKG, 2014.\n[4]Emanuele Sangiorgio, Niccol\u00f2 Di Marco, Gabriele Etta, Matteo Cinelli, Roy Cerqueti, and Walter Quattrociocchi.\nEvaluating the effect of viral posts on social media engagement. Scientific Reports , 15(1):639, 2025.\n[5]Seth Flaxman, Sharad Goel, and Justin M Rao. Filter bubbles, echo chambers, and online news consumption.\nPublic opinion quarterly , 80(S1):298\u2013320, 2016.\n[6]Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter Quattrociocchi, and Michele\nStarnini. The echo chamber effect on social media. Proceedings of the National Academy of Sciences ,\n118(9):e2023301118, 2021.\n[7]Brendan Nyhan, Jaime Settle, Emily Thorson, Magdalena Wojcieszak, Pablo Barber\u00e1, Annie Y Chen, Hunt\nAllcott, Taylor Brown, Adriana Crespo-Tenorio, Drew Dimmery, et al. Like-minded sources on facebook are\nprevalent but not polarizing. Nature , 620(7972):137\u2013144, 2023.\n[8]Joshua A Tucker, Andrew Guess, Pablo Barber\u00e1, Cristian Vaccari, Alexandra Siegel, Sergey Sanovich, Denis\nStukal, and Brendan Nyhan. Social media, political polarization, and political disinformation: A review of the\nscientific literature. Political polarization, and political disinformation: a review of the scientific literature (March\n19, 2018) , 2018.\n[9]Max Falkenberg, Alessandro Galeazzi, Maddalena Torricelli, Niccol\u00f2 Di Marco, Francesca Larosa, Madalina Sas,\nAmin Mekacher, Warren Pearce, Fabiana Zollo, Walter Quattrociocchi, et al. Growing polarization around climate\nchange on social media. Nature Climate Change , 12(12):1114\u20131121, 2022.\n[10] Paolo Benanti. Se l\u2019uomo non basta: Speranze e timori nell\u2019uso della tecnologia contro Covid-19 . LIT EDIZIONI,\n2020.\n[11] Michela Del Vicario, Alessandro Bessi, Fabiana Zollo, Fabio Petroni, Antonio Scala, Guido Caldarelli, H. Eugene\nStanley, and Walter Quattrociocchi. The spreading of misinformation online. Proceedings of the National Academy\nof Sciences , 113(3):554\u2013559, 2016.\n[12] Sandra Gonz\u00e1lez-Bail\u00f3n, David Lazer, Pablo Barber\u00e1, Meiqing Zhang, Hunt Allcott, Taylor Brown, Adriana\nCrespo-Tenorio, Deen Freelon, Matthew Gentzkow, Andrew M. Guess, Shanto Iyengar, Young Mie Kim, Neil\nMalhotra, Devra Moehler, Brendan Nyhan, Jennifer Pan, Carlos Velasco Rivera, Jaime Settle, Emily Thorson,\nRebekah Tromble, Arjun Wilkins, Magdalena Wojcieszak, Chad Kiewiet de Jonge, Annie Franco, Winter Mason,\nNatalie Jomini Stroud, and Joshua A. Tucker. Asymmetric ideological segregation in exposure to political news\non facebook. Science , 381(6656):392\u2013398, 2023.\n[13] Sergio Andr\u00e9s Casta\u00f1o-Pulgar\u00edn, Natalia Su\u00e1rez-Betancur, Luz Magnolia Tilano Vega, and Harvey Mauricio Her-\nrera L\u00f3pez. Internet, social media and online hate speech. systematic review. Aggression and Violent Behavior ,\n58:101608, 2021.\n[14] Alexandra A Siegel. Online hate speech. Social media and democracy: The state of the field, prospects for reform ,\npages 56\u201388, 2020.\n[15] Zafar Gilani, Reza Farahbakhsh, Gareth Tyson, and Jon Crowcroft. A large-scale behavioural analysis of bots and\nhumans on twitter. ACM Trans. Web , 13(1), February 2019.\n11\nComplexity72h 23-27 J UNE 2025 - M ADRID\n[16] Michele Avalle, Niccol\u00f2 Di Marco, Gabriele Etta, Emanuele Sangiorgio, Shayan Alipour, Anita Bonetti, Lorenzo\nAlvisi, Antonio Scala, Andrea Baronchelli, Matteo Cinelli, et al. Persistent interaction patterns across social media\nplatforms and over time. Nature , 628(8008):582\u2013589, 2024.\n[17] Edoardo Di Martino, Alessandro Galeazzi, Michele Starnini, Walter Quattrociocchi, and Matteo Cinelli. Ideo-\nlogical fragmentation of the social media ecosystem: From echo chambers to echo platforms. arXiv preprint\narXiv:2411.16826 , 2024.\n[18] Md Rakibul Hasan, Maisha Maliha, and M Arifuzzaman. Sentiment analysis with nlp on twitter data. In 2019\ninternational conference on computer, communication, chemical, materials and electronic engineering (IC4ME2) ,\npages 1\u20134. IEEE, 2019.\n[19] Martin M\u00fcller, Marcel Salath\u00e9, and Per E Kummervold. Covid-twitter-bert: A natural language processing model\nto analyse covid-19 content on twitter. Frontiers in artificial intelligence , 6:1023281, 2023.\n[20] Simon Zollo, Matteo Cinelli, Gabriele Etta, Roy Cerqueti, and Walter Quattrociocchi. Inference of social media\nopinion trends in 2022 italian elections. Expert Systems with Applications , 269:126377, 2025.\n[21] Stephan Lewandowsky, Michael Jetter, and Ullrich KH Ecker. Using the president\u2019s tweets to understand political\ndiversion in the age of social media. Nature communications , 11(1):5764, 2020.\n[22] Gunn Enli. Twitter as arena for the authentic outsider: exploring the social media campaigns of trump and clinton\nin the 2016 us presidential election. European journal of communication , 32(1):50\u201361, 2017.\n[23] Felix Greaves, Daniel Ramirez-Cano, Christopher Millett, Ara Darzi, and Liam Donaldson. Use of sentiment\nanalysis for capturing patient experience from free-text comments posted online. J Med Internet Res , 15(11):e239,\nNov 2013.\n[24] Guixian Xu, Yueting Meng, Xiaoyu Qiu, Ziheng Yu, and Xu Wu. Sentiment analysis of comment texts based on\nbilstm. IEEE Access , 7:51522\u201351532, 2019.\n[25] Abdulrahman Alrumaih, Ali Al-Sabbagh, Ruaa Alsabah, Harith Kharrufa, and James Baldwin. Sentiment analysis\nof comments in social media. International Journal of Electrical & Computer Engineering (2088-8708) , 10(6),\n2020.\n[26] Svitlana V olkova, Yoram Bachrach, Michael Armstrong, and Vijay Sharma. Inferring latent user properties from\ntexts published in social media. Proceedings of the AAAI Conference on Artificial Intelligence , 29(1), Mar. 2015.\n[27] Matja\u017e Perc. Evolution of the most common english words and phrases over the centuries. Journal of The Royal\nSociety Interface , 9(77):3323\u20133328, 2012.\n[28] Mary K Smith. Measurement of the size of general english vocabulary through the elementary grades and high\nschool. Genetic Psychology Monographs , 24:311\u2013345, 1941.\n[29] Erwin Tschirner. Breadth of vocabulary and advanced english study: An empirical investigation. Electronic\nJournal of Foreign Language Teaching , 1(1):27\u201339, 2004.\n[30] James Milton and Jeanine Treffers-Daller. V ocabulary size revisited: the link between vocabulary size and\nacademic achievement. Applied Linguistics Review , 4(1):151\u2013172, 2013.\n[31] Naomi S Baron. Always on: Language in an online and mobile world . Oxford University Press, 2010.\n[32] Gretchen McCulloch. Because internet: Understanding the new rules of language . Penguin, 2020.\n[33] Michele Zappavigna. Discourse of Twitter and social media . Bloomsbury Publishing, 2012.\n[34] Naomi S Baron. Words onscreen: The fate of reading in a digital world . Oxford University Press, 2015.\n[35] N. Di Marco, Edoardo Loru, Anita Bonetti, Alessandra Olga Grazia Serra, Matteo Cinelli, and Walter Quattro-\nciocchi. Patterns of linguistic simplification on social media platforms over time. Proceedings of the National\nAcademy of Sciences , 121(50):e2412105121, 2024.\n[36] Antonio Desiderio, Anna Mancini, Giulio Cimini, and Riccardo Di Clemente. Highly engaging events reveal\nsemantic and temporal compression in online community discourse. PNAS Nexus , 4(3):pgaf056, 02 2025.\n[37] Emilia Parada-Cabaleiro, Maximilian Mayerl, Stefan Brandl, Marcin Skowron, Markus Schedl, Elisabeth Lex,\nand Eva Zangerle. Song lyrics have become simpler and more repetitive over the last five decades. Scientific\nReports , 14(1):5531, 2024.\n[38] Niccolo\u2019 Di Marco, Edoardo Loru, Alessandro Galeazzi, Matteo Cinelli, and Walter Quattrociocchi. Decoding\nmusical evolution through network science. arXiv preprint arXiv:2501.07557 , 2025.\n[39] Edoardo Loru, Alessandro Galeazzi, Anita Bonetti, Emanuele Sangiorgio, Niccol\u00f2 Di Marco, Matteo Cinelli,\nAndrea Baronchelli, and Walter Quattrociocchi. Who sets the agenda on social media? ideology and polarization\nin online debates. arXiv preprint arXiv:2412.05176 , 2024.\n12\nComplexity72h 23-27 J UNE 2025 - M ADRID\n[40] Emily Chen and Emilio Ferrara. Tweets in time of conflict: A public dataset tracking the twitter discourse on the\nwar between Ukraine and Russia. In Proceedings of the International AAAI Conference on Web and Social Media ,\nvolume 17, pages 1006\u20131013, 2023.\n[41] Kenneth Benoit, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan M\u00fcller, and Akitaka Matsuo.\nquanteda: An r package for the quantitative analysis of textual data. Journal of Open Source Software , 3(30):774,\n2018.\n[42] Thomas Renault, Mohsen Mosleh, and David G Rand. Republicans are flagged more often than democrats\nfor sharing misinformation on x\u2019s community notes. Proceedings of the National Academy of Sciences ,\n122(25):e2502053122, 2025.\n[43] Fabrizio Gilardi, Meysam Alizadeh, and Ma\u00ebl Kubli. Chatgpt outperforms crowd workers for text-annotation\ntasks. Proceedings of the National Academy of Sciences , 120(30):e2305016120, 2023.\n[44] Peter Stefanov, Kareem Darwish, Atanas Atanasov, and Preslav Nakov. Predicting the topical stance and political\nleaning of media using tweets. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics , pages 527\u2013537, 2020.\n[45] James Flamino, Alessandro Galeazzi, Stuart Feldman, Michael W Macy, Brendan Cross, Zhenkun Zhou, Matteo\nSerafino, Alexandre Bovet, Hern\u00e1n A Makse, and Boleslaw K Szymanski. Political polarization of news media\nand influencers on twitter in the 2016 and 2020 us presidential elections. Nature Human Behaviour , 7(6):904\u2013916,\n2023.\n[46] Francesco Barbieri, Jose Camacho-Collados, Leonardo Neves, and Luis Espinosa-Anke. Tweeteval: Unified\nbenchmark and comparative evaluation for tweet classification. arXiv preprint arXiv:2010.12421 , 2020.\n[47] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint\narXiv:1907.11692 , 2019.\n[48] Akshat Gaurav, Brij B Gupta, Sachin Sharma, Ritika Bansal, and Kwok Tai Chui. Xlm-roberta based sentiment\nanalysis of tweets on metaverse and 6g. Procedia Computer Science , 238:902\u2013907, 2024.\n[49] S\u00e9rgio Barreto, Ricardo Moura, Jonnathan Carvalho, Aline Paes, and Alexandre Plastino. Sentiment analysis in\ntweets: an assessment study from classical to modern word representation models. Data Mining and Knowledge\nDiscovery , 37(1):318\u2013380, 2023.\n[50] A Krishnamoorthy, KA Sundhar, V Naveen Kumar, and V Karthik. Analyzing sentiments: A comprehensive\nstudy of roberta-based sentiment analysis on twitters. In 2024 4th International Conference on Advancement in\nElectronics & Communication Engineering (AECE) , pages 626\u2013630. IEEE, 2024.\n[51] Fabeela Ali Rawther and Geevarghese Titus. Transformer models for recognizing abusive language an investigation\nand review on tweeteval and solid dataset. In 2023 Second International Conference on Electrical, Electronics,\nInformation and Communication Technologies (ICEEICT) , pages 1\u20136. IEEE, 2023.\n[52] Kian Long Tan, Chin Poo Lee, Kalaiarasi Sonai Muthu Anbananthen, and Kian Ming Lim. Roberta-lstm: a hybrid\nmodel for sentiment analysis with transformer and recurrent neural network. IEEE Access , 10:21517\u201321525,\n2022.\n[53] Dat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen. Bertweet: A pre-trained language model for english tweets.\narXiv preprint arXiv:2005.10200 , 2020.\n[54] Francesco Barbieri, Jose Camacho-Collados, Luis Espinosa Anke, and Leonardo Neves. TweetEval: Unified\nbenchmark and comparative evaluation for tweet classification. In Findings of the Association for Computational\nLinguistics: EMNLP 2020 , pages 1644\u20131650, Online, November 2020. Association for Computational Linguistics.\n[55] Lisa Kaati, Amendra Shrestha, and Nazar Akrami. A machine learning approach to identify toxic language in the\nonline space. In 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining\n(ASONAM) , pages 396\u2013402. IEEE, 2022.\n[56] Gregor Wiedemann, Seid Muhie Yimam, and Chris Biemann. Uhh-lt at semeval-2020 task 12: Fine-tuning of\npre-trained transformer networks for offensive language detection. arXiv preprint arXiv:2004.11493 , 2020.\n[57] Daniel Loureiro, Francesco Barbieri, Leonardo Neves, Luis Espinosa Anke, and Jose Camacho-collados.\nTimeLMs: Diachronic language models from Twitter. In Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics: System Demonstrations , pages 251\u2013260, Dublin, Ireland, May 2022.\nAssociation for Computational Linguistics.\n[58] Maarten Grootendorst. Bertopic: Neural topic modeling with a class-based tf-idf procedure. arXiv preprint\narXiv:2203.05794 , 2022.\n13\nComplexity72h 23-27 J UNE 2025 - M ADRID\n[59] Davoud Moulavi, Pablo A Jaskowiak, Ricardo JGB Campello, Arthur Zimek, and J\u00f6rg Sander. Density-based\nclustering validation. In Proceedings of the 2014 SIAM international conference on data mining , pages 839\u2013847.\nSIAM, 2014.\n[60] Kristian TH Jensen. Indicators of text complexity. Mees, IM; F . Alves & S. G\u00f6pferich (eds.) , pages 61\u201380, 2009.\n[61] George Kingsley Zipf. The psycho-biology of language: An introduction to dynamic philology . Routledge, 2013.\n[62] Kumiko Tanaka-Ishii and Shunsuke Aihara. Computational constancy measures of texts\u2014yule\u2019s k and r\u00e9nyi\u2019s\nentropy. Computational Linguistics , 41(3):481\u2013502, 2015.\n[63] Alfr\u00e9d R\u00e9nyi. On measures of entropy and information. In Proceedings of the fourth Berkeley symposium on\nmathematical statistics and probability, volume 1: contributions to the theory of statistics , volume 4, pages\n547\u2013562. University of California Press, 1961.\n[64] Daniel Dugast. Vocabulaire et stylistique , volume 8. Slatkine, 1979.\n[65] Fiona J Tweedie and R Harald Baayen. How variable may a constant be? measures of lexical richness in\nperspective. Computers and the Humanities , 32:323\u2013352, 1998.\n[66] C Udny Yule. The statistical study of literary vocabulary . Cambridge University Press, 2014.\n[67] Antonio Desiderio, Anna Mancini, Giulio Cimini, and Riccardo Di Clemente. Recurring patterns in online social\nmedia interactions during highly engaging events. arXiv preprint arXiv:2306.14735 , 2023.\n[68] Bela Balassa. Trade liberalization and revealed comparative advantage. The Manchester School of Economic and\nSocial Studies , 33:99\u2013123, 1965.\n[69] Fabio Saracco, Mika J Straka, Riccardo Di Clemente, Andrea Gabrielli, Guido Caldarelli, and Tiziano Squartini.\nInferring monopartite projections of bipartite networks: an entropy-based approach. New Journal of Physics ,\n19(5):053022, may 2017.\n[70] Giulio Cimini, Tiziano Squartini, Fabio Saracco, Diego Garlaschelli, Andrea Gabrielli, and Guido Caldarelli. The\nstatistical physics of real-world networks. Nature Reviews Physics , 1(1):58\u201371, Jan 2019.\n[71] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: A practical and powerful approach to\nmultiple testing. Journal of the Royal Statistical Society. Series B (Methodological) , 57(1):289\u2013300, 2023/06/13/\n1995. Full publication date: 1995.\n[72] Nicol\u00f2 Vallarano, Matteo Bruno, Emiliano Marchese, Giuseppe Trapani, Fabio Saracco, Giulio Cimini, Mario\nZanon, and Tiziano Squartini. Fast and scalable likelihood maximization for exponential random graph models\nwith local constraints. Scientific Reports , 11(1):15227, 2021.\n[73] Aric A. Hagberg, Daniel A. Schult, and Pieter J. Swart. Exploring network structure, dynamics, and function\nusing networkx. In Ga\u00ebl Varoquaux, Travis Vaught, and Jarrod Millman, editors, Proceedings of the 7th Python in\nScience Conference , pages 11 \u2013 15, Pasadena, CA USA, 2008.\n[74] Mathieu Bastian, S\u00e9bastien Heymann, and Mathieu Jacomy. Gephi: An open source software for exploring and\nmanipulating networks. In Proceedings of the International AAAI Conference on Weblogs and Social Media\n(ICWSM) , 2009.\n[75] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni\nBurovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St\u00e9fan J. van der Walt, Matthew Brett, Joshua\nWilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J\nCarey, \u02d9Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman,\nIan Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, Ant\u00f4nio H. Ribeiro, Fabian Pedregosa, Paul\nvan Mulbregt, and SciPy 1.0 Contributors. Scipy 1.0: fundamental algorithms for scientific computing in python.\nNature Methods , 17:261\u2013272, 2020.\n14\nComplexity72h 23-27 J UNE 2025 - M ADRID\nSupplementary Information\n22\n90\n3\n80\n0\n07Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58Cohen's Kappa = 0.58\nLCR\nL C R\nMBFCGemini\nFigure S1: Confusion matrix showing the agreement between the political leaning of user profiles labeled by Gemini\nand those labeled by MBFC. MBFC ratings were collapsed into broader categories: \u201cL\u201d (Left), combining \u201cleft\u201d,\n\u201cextreme_left\u201d, and \u201cpro_science\u201d; \u201cC\u201d (Center), combining \u201ccenter\u201d, \u201cleft_center\u201d, and \u201cright_center\u201d; and \u201cR\u201d (Right),\ncombining \u201cright\u201d and \u201cextreme_right\u201d.\n81\n339Cohen's Kappa = 0.75Cohen's Kappa = 0.75Cohen's Kappa = 0.75Cohen's Kappa = 0.75\nQuestionableReliable\nQuestionable Reliable\nMBFCGemini\nFigure S2: Confusion matrix showing the agreement between the reliability of user profiles labeled by Gemini and\nthose labeled by MBFC.\n15\nComplexity72h 23-27 J UNE 2025 - M ADRID\nTable S1: Results of the Kruskal-Wallis test for the complexity metrics employed in this analysis: Yule\u2019s K,gzip, and\nFlesch Index . For each of them, we compare their distributions according to the following features: Account Type,\nPolitical Leaning, Reliability, Offensiveness, and Sentiment.\nComplexity Metric Feature Dataset p-value\nK Account Type COP26 0.0002\nK Account Type Ukraine 0.0018\nK Account Type COVID-19 <0.0001\nK Political Leaning COP26 0.4948\nK Political Leaning Ukraine 0.5725\nK Political Leaning COVID-19 <0.0001\nK Reliability COP26 0.743\nK Reliability Ukraine 0.7568\nK Reliability COVID-19 <0.0001\nK Offensiveness COP26 0.0044\nK Offensiveness Ukraine <0.0001\nK Offensiveness COVID-19 <0.0001\nK Sentiment COP26 0.0006\nK Sentiment Ukraine <0.0001\nK Sentiment COVID-19 <0.0001\nGZIP Account Type COP26 <0.0001\nGZIP Account Type Ukraine <0.0001\nGZIP Account Type COVID-19 <0.0001\nGZIP Political Leaning COP26 0.0007\nGZIP Political Leaning Ukraine <0.0001\nGZIP Political Leaning COVID-19 <0.0001\nGZIP Reliability COP26 0.0001\nGZIP Reliability Ukraine <0.0001\nGZIP Reliability COVID-19 <0.0001\nGZIP Offensiveness COP26 <0.0001\nGZIP Offensiveness Ukraine <0.0001\nGZIP Offensiveness COVID-19 <0.0001\nGZIP Sentiment COP26 <0.0001\nGZIP Sentiment Ukraine <0.0001\nGZIP Sentiment COVID-19 <0.0001\nFlesch Account Type COP26 <0.0001\nFlesch Account Type Ukraine <0.0001\nFlesch Account Type COVID-19 <0.0001\nFlesch Political Leaning COP26 <0.0001\nFlesch Political Leaning Ukraine <0.0001\nFlesch Political Leaning COVID-19 <0.0001\nFlesch Reliability COP26 0.0226\nFlesch Reliability Ukraine <0.0001\nFlesch Reliability COVID-19 <0.0001\nFlesch Offensiveness COP26 <0.0001\nFlesch Offensiveness Ukraine <0.0001\nFlesch Offensiveness COVID-19 <0.0001\nFlesch Sentiment COP26 <0.0001\nFlesch Sentiment Ukraine <0.0001\nFlesch Sentiment COVID-19 <0.0001\n16\nComplexity72h 23-27 J UNE 2025 - M ADRID\nCOVID\u221219 COP26 Ukraine\n0.20.30.5\nAccount TypeGZIP\u2212complexity\nIndividual Organizationa)\nCOVID\u221219 COP26 Ukraine\n0.20.30.5\nPolitical LeaningGZIP\u2212complexity\nLeftCenter Rightb)\nCOVID\u221219 COP26 Ukraine\n0.20.30.5\nReliabilityGZIP\u2212Complexity\nQuestionable Reliablec)\nCOVID\u221219 COP26 Ukraine\n0.20.30.5\nOffensiveness ClassGZIP\u2212Complexity\nLowMidHigh Very Highd)\nCOVID\u221219 COP26 Ukraine\n0.20.30.5\nNegative Sentiment ClassGZIP\u2212Complexity\nLowMidHigh Very Highe)\nFigure S3: GZIP-complexity distributions according to a) the account type of the influencers (Individual or Organization),\nb) the political leaning of the influencer (Left, Center, Right), c) the reliability of the influencer (Questionable or\nReliable), (d) user offensiveness class and (e) negative sentiment class.\n17\nComplexity72h 23-27 J UNE 2025 - M ADRID\nCOP26 COVID\u221219 Ukraine\n050100150\nAccount TypeFlesch Index\nIndividual Organizationa)\nCOP26 COVID\u221219 Ukraine\n050100150\nPolitical LeaningFlesch Index\nLeftCenter Rightb)\nCOP26 COVID\u221219 Ukraine\n050100150\nReliabilityFlesch Index\nQuestionable Reliablec)\nCOP26 COVID\u221219 Ukraine\n050100150\nOffensiveness ClassFlesch Index\nLowMidHigh Very Highd)\nCOP26 COVID\u221219 Ukraine\n050100150\nNegative Sentiment ClassFlesch Index\nLowMidHigh Very Highe)\nFigure S4: Flesch Index complexity distributions according to a) the account type of the influencers (Individual\nor Organization), b) the political leaning of the influencer (Left, Center, Right), c) the reliability of the influencer\n(Questionable or Reliable), (d) user offensiveness class and (e) negative sentiment class.\n18\nComplexity72h 23-27 J UNE 2025 - M ADRID\nTable S2: Information on Bipartite Networks between Influencers and Types for COVID-19, COP26, and Ukraine\nMetric COVID-19 COP26 Ukraine\nNodes 71,953 26,918 92,030\nNodes (Influencers) 1,577 561 1,166\nNodes (Types) 70,376 26,357 90,864\nEdges 1,900,389 463,720 2,347,020\nDensity 0.00073 0.0013 0.00055\nAverage Degree 52.82 34.45 51.01\nTable S3: Information on Validated Projected Influencer Networks for COVID-19, COP26, and Ukraine\nMetric COVID-19 COP26 Ukraine\nNodes 1,542 511 1,084\nEdges 137,458 7,748 179,423\nDensity 0.12 0.059 0.31\nAverage Degree 178.29 30.32 331.04\nAverage Modularity 0.3342 \u00b10.0003 0.3749 \u00b10.0003 0.17149 \u00b10.00009\n19", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Involvement drives complexity of language in online debates", "author": ["E Amadori", "D Cirulli", "E Di Martino", "J Nudo"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Language is a fundamental aspect of human societies, continuously evolving in response to  various stimuli, including societal changes and intercultural interactions. Technological"}, "filled": false, "gsrank": 238, "pub_url": "https://arxiv.org/abs/2506.22098", "author_id": ["", "", "rp_Lu2MAAAAJ", "prDI1NoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:sb1QRooz1osJ:scholar.google.com/&output=cite&scirp=237&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D230%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=sb1QRooz1osJ&ei=LrWsaJ_HDrTWieoP1pCJ2AY&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:sb1QRooz1osJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2506.22098"}}, {"title": "Watchdog or loyal servant? Political media bias in US newscasts", "year": "2020", "pdf_data": "Bernhardt, Lea; Dewenter, Ralf; Thomas, Tobias\nWorking Paper\nWatchdog or loyal servant? Political media bias in US\nnewscasts\nDICE Discussion Paper, No. 348\nProvided in Cooperation with:\nD\u00fcsseldorf Institute for Competition Economics (DICE), Heinrich Heine University D\u00fcsseldorf\nSuggested Citation: Bernhardt, Lea; Dewenter, Ralf; Thomas, Tobias (2020) : Watchdog or\nloyal servant? Political media bias in US newscasts, DICE Discussion Paper, No. 348, ISBN\n978-3-86304-347-6, Heinrich Heine University D\u00fcsseldorf, D\u00fcsseldorf Institute for Competition\nEconomics (DICE), D\u00fcsseldorf\nThis Version is available at:\nhttps://hdl.handle.net/10419/222963\nStandard-Nutzungsbedingungen:\nDie Dokumente auf EconStor d\u00fcrfen zu eigenen wissenschaftlichen\nZwecken und zum Privatgebrauch gespeichert und kopiert werden.\nSie d\u00fcrfen die Dokumente nicht f\u00fcr \u00f6ffentliche oder kommerzielle\nZwecke vervielf\u00e4ltigen, \u00f6ffentlich ausstellen, \u00f6ffentlich zug\u00e4nglich\nmachen, vertreiben oder anderweitig nutzen.\nSofern die Verfasser die Dokumente unter Open-Content-Lizenzen\n(insbesondere CC-Lizenzen) zur Verf\u00fcgung gestellt haben sollten,\ngelten abweichend von diesen Nutzungsbedingungen die in der dort\ngenannten Lizenz gew\u00e4hrten Nutzungsrechte.Terms of use:\nDocuments in EconStor may be saved and copied for your personal\nand scholarly purposes.\nYou are not to copy documents for public or commercial purposes, to\nexhibit the documents publicly, to make them publicly available on the\ninternet, or to distribute or otherwise use the documents in public.\nIf the documents have been made available under an Open Content\nLicence (especially Creative Commons Licences), you may exercise\nfurther usage rights as specified in the indicated licence.\n \n \n \n  \nNO 348 \nWatchdog or Loyal Servant?                    \nPolitical Media Bias in US Newscasts   \n \nLea Bernhardt  \nRalf Dewenter  \nTobias Thomas  \n \nAugust 2020  \n \nIMPRINT  \n \nDICE DISCUSSION PAPER  \n \nPublished by:  \nHeinrich -Heine -University D\u00fcsseldorf,  \nD\u00fcsseldorf Institute for Competition Economics (DICE),  \nUniversit\u00e4tsstra\u00dfe 1, 40225 D\u00fcsseldorf, Germany  \nwww.dice.hhu.de  \n \nEditor:  \nProf. Dr. Hans -Theo Normann \nD\u00fcsseldorf Institute for Competition Economics (DICE)  \nTel +49 (0) 211 -81-15125, E -Mail normann@dice.hhu.de  \n \nAll rights re served. D\u00fcsseldorf, Germany 2020 . \n \nISSN 2190 -9938 (online) / ISBN 978 -3-86304 -347-6 \n \nThe working papers published in the series constitute work in \nprogress circulated to stimulate discussion and critical comments.  \nViews expressed represent exclusively the authors \u2019 own opinions \nand do not necessarily reflect those of the editor.  \n1  \n \n \n \n \n \n \nWatchdog or Loyal Servant?  \nPolitical Media Bias in US Newscasts  \nLea Bernhard t1, Ralf Dewente r2 & Tobias Thomas3 \nAugust 2020 \n \n \nWe investigate if four leading,  electronic news gathering organizations in the US \u2013 ABC  News , CBS \nNews , FOX  News , and NBC News  \u2013 fulfill their role as the fourth estate in the US democrac y. Our \nanalysis , using  the Political Coverage Index ( PCI) introduced by Dewenter et al ( 2020), is based \non the tonality of their political coverage using 815,000 human -coded news items from 2001 \nthrough 2012 . For our econometric analysis , we use panel regression s with media and time fixed \neffects. To account  for endogeneity , we cut time span s around national elections out of our data. \nIn the remaining data , elections can be seen as a purely e xogenous event. Focusing on the entire \nmedia set , we find robust empirical results for an anti -government bias  in media reporting : Under  \nRepublican presidents, political coverage tends to be more liberal, whereas it tends to be more \nconservative if the president is a Democrat. However, when focusing on each single news  \norganization , interesting differences emerge : For CBS News  and NBC  News , we find robust \nempirical evidence of anti -government -bias. In contrast , FOX  News  is always much more critical \nof Democ rats than of Republicans. Hence, FOX  News  can be seen as a more loyal servant to one \nparty rather than acting as  the fourth estate . In addition, we find no evidence that ABC News  \nsignificantly chang es its position depending on the presiden cy. Although  desc riptive statistics \nshow a certain tendency toward government -critical reporting by ABC  News , the variation is not \nstatistically significant .  \nKeywords:    Political Coverage Index, government bias, tonality, media capture , US newscasts  \nJEL:      C43, D72, L8 2 \nResearch Funding:   This research did not receive any specific grant from funding agencies in the \npublic, commercial, or not -for-profit sectors.  \n \n \n \n                                                           \n \n1 Helmut Schmidt University Hamburg, Department of Economics, Germany, lea.bernhardt@hsu -hh.de.  \n2 Helmut Schmidt University Hamburg, Department of Economics, Germany, dewenter@hsu -hh.de.  \n3 D\u00fcsseldo rf Institute for Competition Economics (DICE) at Heinrich -Heine -University D\u00fcsseldorf, Germany, and Centre \nof Media Data and Society (CMDS) of the Central European University (CEU), Hungary, thomas@dice.hhu.de  \n2 Table of Contents  \n1. Introduction  ................................ ................................ ................................ ................................ ................................  3 \n2. Related Literature  ................................ ................................ ................................ ................................ ....................  5 \n3. The Political Positioning of the \u201cBig Four\u201d  ................................ ................................ ................................ ..... 8 \n3.1 The Da ta: Political Media Coverage of ABC, CBS, FOX, and NBC News  ................................ ..... 8 \n3.2 The Political Coverage Index ( PCI): A Tonality -Based Measure of Media Bias  ..................  11 \n3.3 Application of the Media Data to the PCI  ................................ ................................ ...........................  12 \n4. Do the Big Four serve as 4th Estate ? ................................ ................................ ................................ ...............  15 \n4.1 Empirical Strategy  ................................ ................................ ................................ ................................ ....... 15 \n4.1.1  Econometric Set Up  ................................ ................................ ................................ ...........................  15 \n4.1.2  Identification Strategy ................................ ................................ ................................ ......................  16 \n4.2 Empirica l Results  ................................ ................................ ................................ ................................ .........  19 \n4.2.1  Average Results on the Big Four  ................................ ................................ ................................ .. 19 \n4.2.2  Detailed Results on ABC, CBS, FOX, and NBC News  ................................ .............................  23 \n5. Conclusion  ................................ ................................ ................................ ................................ ................................  26 \nReferences  ................................ ................................ ................................ ................................ ................................ ..........  28 \nAppendix  ................................ ................................ ................................ ................................ ................................ .............  31 \n \n \n3 1. Intr oduction  \nWith the success of Donald Trump in the 2016 US presidential elections, the media and its role in \ndemocracies are, once again, under scrutiny. For instance, o n the one side, ABC  News , CBS News , \nand NBC  News  are often seen to be at least slightly p olitically left biased and are regularly accused \nof spread ing \u201cfake news\u201d from the US president\u2019s perspective. On the other side, FOX News is often \nseen as politically right  biased , spread ing \u201cfake news\u201d from the perspective  of the other side of the \npoliti cal spectrum. The strong and rising criticism o f traditional media in the late 2010s, not just \nin the US , leads us to the question the role media play in the US democrac y. In this context, a  rather \noptimistic perspective can be traced back to parliamentary  debate in 1787 in the United Kingdom \non providing media access to the parliament. In this debate , Edmund Burke claimed that media \nform the \u201cfourth estate \u201d of government \u2013 going beyond the traditional three estates: The Lords \nSpiritual, the Lords Temporal,  and the House of Commons.  \nA less optimistic perspective is provided by Public Choice literature: For instance, Anderson and \nMcLaren (2012) argue that media are owned by people with political and profit motives, who use \ntheir influence to change policy. Ot her authors argue that governments capture the media through \npolicy decisions in their favor or by access to the news stories  in order to maintain \u201ca \u2018cozy\u2019 \nrelationship with the media\u201d (Besley and Prat, 2006, 720). In particular, the latter explanation of  \nmedia capture implies that media outlets tend to be less critical of the government. The former \nexplanation would lead us to expect that such pro -government bias  exists among media outlets \nthat are owned or edited by people aligned with the political part y in power. In both cases, media \nwould fail in fulfilling their role as the fourth estate.  \nIn this contribution, we analyze the role of four leading news gathering organizations in the US \u2013 \nABC  News , CBS  News , FOX  News , and NBC  News  \u2013 on its democracy on the basis of a huge amount \nof hand -coded media data that allows for focus ing on the tonality of political reporting by the \naforementioned news  organizations . The selected news organizations are relevant, as ABC  News , \nCBS News , and NBC News  are the  news div isions of the  three big traditional commercial  broadcast  \ntelevision networks  in the US. Subsequently, in 1996, FOX News  was established as cable new s \nchannel, competing , in large part, with the three aforementioned news gathering organizations .4  \nBy applying the tonality -based Political Coverage Index ( PCI), introduced by Dewenter et al . \n(2020), to more than 815 ,000 human -coded news items on Democrat s and Republicans from \n2001 through 2012 , we are able to identify the relative political positioning of the four newscasts  \nduring the time span analyzed .  \n                                                           \n \n4 See section 3.1 for a discussion about this selection.  \n4 However , as the political positioning of a newscast can change over time , in a next step we analyze \nwhether media coverage of politicians and parties differs  depending on the party affiliation of the \npresident in office.  If newscasts tend to be less critical of the political affiliation of the president  \nin office , this could be seen as a hint o f media ca pture in the line of Besley and Prat (2006). In \ncontrast, if newscasts tend to be more critical of the political affiliation of the president in  office , \nthis could be seen as an indication that the media serve as forth estate in line with Edmund Burke.  \nBeyond  the general inquiry of the entire media data set, we will analyze the political coverage of \neach individual news  program  in the set to investigate the existence of a government or anti -\ngovernment  bias . Put differently, we analyze if ABC  News , CBS  News , FOX  News , and NBC  News  \ndeliver as fourth estates or if they are loyal servant s to only one party ; if the latter is true, this can \nbe seen as ideological ly driven . \nMethodologically , our analysis is  based on a panel regression  set up  with media and time fi xed \neffects as well as a multitude of economic and geopolitical controls to capture at least a part of the \nfactual performance of the government, which is also likely to be a major driver of the political \nmedia coverage. However, by this measure , we cannot  rule out certain serious endogeneity issues: \nIf, for instance , the political positioning of the media is not just affected by the party affiliation of \nthe president  in office  and the election results are also affected by the political positioning of the \nmedia , this would lead to biased coefficients due to reverse causality. Furthermore, if both the \npolitical positioning of the media as well as the election outcome were affected by the uncaptured \npart of the performance of the government , this would lead to  biased coefficients due to omitted \nvariable s. Hence, we cut the time span around the election s out of our data. Consequently , our \nanalysis is mainly based on the remaining part  of the data , where elections can be seen as purely \nexogenous event s. In doing so, we use elections as an identification tool.  \nThe remainder of our contribution is structured as follows: Section 2 provides an overview of the \nrelated literature and describes the research gap. In Section 3, the data are introduced  and the \npolitical po sitioning of the newscasts is demonstrated  by the Political Coverage Index ( PCI).  \nSection 4 econometrically investigates the role of the newscasts as the fourth estate  for both the \nentire media set as well as for each single newscast in the timeframe anal yzed and discusses the \nresults . Finally, section 5 concludes.  \n  \n5 2. Related Literature   \nMedia play an important role in the perception s and decisions of individuals in the economic and \npolitical context s, because, in addition to direct communicat ion and person al experience , \ninformation is typically gathered  indirect ly through media channels. This is relevant because \nmedia can never depict the complete reality, only paint ing a partial picture. In addition, media \nreality is prone to various types of distortions, so-called media bias ( Entman 2007 ). Of the various \ntypes of media bias , the most prominent are advertising bias, when media change their news \ncoverage in tone or volume to favor their advertising clients (see Dewenter and Heimeshoff, 2014, \n2015; Gambaro and Puglisi, 2015 ; or Reuter and Zitzewitz, 2006); the distance bias, when media \nreport more on events that take place close to their  main market ( Berlemann and Thomas, 2019); \nthe negativity bias, when media focus more on catastrophes, crime , and threatening political and \neconomic developments in comparison to more positive news (see Friebel and Heinz, 2014; Garz, \n2013, 2014; Heinz and Swinnen, 2015 or Soroka, 2006) ; and the newswor thiness bias, when news \non certain issues crowd out coverage on other issues because they are seen as more newsworthy \n(see Durante and Zhuravskaya, 201 8 or Eisensee and Str\u00f6mberg, 2007) .5  \nIn the political context, one question of interest is if media outl ets favor one or another side of the \npolitical spectrum. In addition to political science and communication sciences, this question is \nanalyzed in the public choice literature. For instance, Groseclose and Milyo (2005) , focus ing on \nthe US two party system , provide an index of media outlets by comparing the number of think \ntanks and interest groups cited by Democratic and Republican members of US Congress with the \nsame groups quoted by the media. The results show a strong liberal bias among all US news casts  \nexamined, except F OX News\u2019 Special Report. In contrast, Gentzkow and Shapiro (2010) compare \ncharacteristic phrases frequently used in different media outlets. In addition , political media \nbiases  are measured by Larcinese, Puglisi , and Snyder (2011) and Puglisi (2011) using references \nto core topics , Qin et al. (2018) count references to political leaders, and Chiang and Knight (2011) \nas well as Puglisi and Snyder (2015 b) us e newspapers' explicit endorsements and editorial \npositions.  Subsequently, Dewenter e t al ( 2020), introduce a tonality -based Political Coverage \nIndex ( PCI), apply it to 35 opinion -leading media in Germany  and find empirical evidence that \nmedia  is fulfilling its role as fourth estate in the German democra cy (see below) .6   \n                                                           \n \n5 In addition, there is a large literature in communication and media science on the existence of media biases and its \nfoundations (see, among others, Ball -Rokeach, 1985, Ball -Rokeach and DeFleur, 1976, and Dunham, 2013).  \n6 There is also exist ing research on the political bias of German media outlets, provided by Garz et al. (2020). The authors \nconstruct an index of media slant by comparing the language of Facebook posts by 84 German news outlets on \npoliticians who were investigated for crimina l offenses with that of the main political parties. The results are \ncomparable to those of Dewenter et al. (20 20). \n6 Consequently , individual perception s and decisions based on biased political media reporting \nmight deviate from perception s and decisions based on more unbiased information.7  These \ndeviations can affect  both voters and politicians. For instance, in 1987, Page et al. show  that \nnetwork television news accounts for a high proportion of changes in the policy preferences of \nU.S. citizens.  Benesch et al (20 19) provide econometric evidence that media can affect the worries \nof the population about policy relevant topics , like mig ration, by using media spill -overs from one \ncountry to another as an instrument. A closer look at the impact of media coverage on political \naction is provided by Snyder and Str\u00f6mberg (2010).8 The authors find that voters living in regions \nwith insufficient  political media coverage are less able to recall or evaluate their representatives. \nThis affects the work of politicians: Less covered congressmen are less willing to serve as \nwitnesses at congressional hearings or serve on committees . In addition, region s with less press \ncoverage of representatives receive less federal spending. The opposite causation, i.e. the impact \nof government parties on media , is analyzed by Gentzkow et al (2015) . In the international \npolitical context, Eisensee and Str\u00f6mberg (2007)  show that media coverage of natural disasters \ncausally affects US disaster relief. The authors find evidence that , in times of high news pressure \ncaused by Olympic Games , natural disasters are less likely to be covered, which leads to lower \ndisaster relie f.9 \nAnother outstanding reason for the relevance of political media coverage is that is can affect voting \nintentions and election outcome s: Dewenter et al . (2019 ) show that a less critical  tonality of the \nmedia coverage o f a political party can increase t he intention to vote for th at party , at least in the \nshort term. Prat (201 8) demonstrates  that media organizations are able to induce voters to make \nelectoral decisions that they would not make if reporting were unbiased.  Enikolopov et al. (2011)  \nfocus on the impact of media coverage on election outcomes. The authors , analyz ing electoral \noutcomes of parliamentary elections in 1999 in Russian regions with different access to  an \nindependent national TV channel , find that access to independent TV led to decrea sed vote s for \nthe governing party and to an increased vote for major opposition parties. The results are \n                                                           \n \n7 Beside inquiries regarding the impact of media reporting on perception and behavior in the political context, there is \nalso a huge and gro wing literature in the economic context.  For instance, Nadeau et al. (2000), Soroka (2006), and van \nRaaij (1989) show that the assessment of the state of the economy and economic expectations depends, at least in part, \non media reports. In this context, U lbricht et al. (2017) use media data to improve economic forecasts. Alsem et al. \n(2008), Goidel and Langley (1995), as well as Doms and Morin (2004) analyze the impact of media reporting on the \nconsumer climate. Garz (2012, 2013) investigates the impact of  distorted media coverage of unemployment on the \nperception of job insecurity, while Lamla and Maag (2012) analyze the impact of media reporting on inflation forecasts \nof both households and professional forecasters. Chadi (2015) shows that media coverage of economic crises can even \naffect life satisfaction. In addition, media coverage can also affect decisions and behavior. For instance, Dewenter et al. \n(2016) find evidence that car sales depend, at least in part, on media coverage of the automotive indust ry. \n8 Further contributions in this context are Bernhardt et al (2008), D\u2018Alessio and Allen (2000), Druckman and Parkin \n(2005), Gentzkow et al. (2011) as well as Morris (2007).  \n9 More evidence on the effect of media coverage in the international political context is provided by Beckmann et al. \n(2017) and Jetter (2017) with focus on terror activities and Durante and Zhuravskaya (2018) in the context of the \nIsraeli -Palestinian conflict.  \n7 comparable to those of DellaVinga and Kaplan (2007). Based on the successive rolling out of FOX \nNews across US states , the authors find that Republican s gained additional votes in presidential \nelections between 1996 and 2000 in cities with access to FOX News .   \nThe demonstrated impact of media on perception s and decisions in the political context draws \nour attention to the fundamental role of the media i n democracy. As mentioned in the \nintroduction , the perspective of Public Choice literature on the role of media in democracies is \nrather sobering : Anderson and McLaren  (2012) argue that media are owned by people with \npolitical and profit motives who use th eir influence to change policy. However, Gentzkow and \nShapiro (2010) find that the media\u2019s response to consumer preferences has a much higher \nexplanatory power for media slant than ownership structure s. Other authors argue that \ngovernments capture the medi a through policy decisions in their favor or by access to news \nstories in order to maintain \u201ca \u2018cozy\u2019 relationship with the media\u201d (Besley and Prat, 2006, 720). \nSpecifically , the latter explanation of media capture impl ies that media outlets tend to be les s \ncritical of the government . The former explanation would lead us to expect pro -government bias , \nespecially for those media outlets that are owned or edited by people aligned with the political \nparty in power.  In both cases, media\u2019s role as fourth estate would be , at least , rather  restricted.  \nTo better investigate the role of media in democracy , Dewenter et al ( 2020) introduce the Political \nCoverage Index ( PCI), which is  based on the tonality of news reports , and apply  it to Germany . The \nresult shows  the relative positioning of different media outlet s across the political spectrum. By \nanalyzing the variations of the political positioning in time , the authors tackle the question of \nwhether the media fulfill their role as the fourth estate or if there is emp irical evidence of media \ncapture . They find empirical evidence that media fulfill their role as the fourth estate , at least in \nGermany. In the present contribution , we apply PCI to four leading US news  gathering \norganizations \u2013 ABC  News , CBS  News , FOX  New s, and NBC  News . In doing so, our work is connected \nto Groseclose and Milyo (2005), Gentzkow and Shapiro (2010) , and Greenstein and Zhu (2012). \nHowever, in contrast to these contributions , we do not utilize quotes or characteristic phrases , \nrather we use the tonality of news reports on political parties and politicians based on human -\ncoded media data. Thereby, our contribution addresses the gap that analyzing  media bias by \n\u201cmeasuring the tone of articles and editorials, is relatively underutilized in econom ics\u201d (Puglisi \nand Snyder, 2015 a, 664). In addition, we apply  PCI to study government bias in news reporting. \nIn other words , we analyze whether the media fulfill its role as the fourth estate or whether the \nmedia are capture d. Therefore, our contribution i s also connected to the work of Anderson and \nMcLaren (2012) and Besley and  Prat (2006).  In contrast to Dewenter et al ( 2020), we not only \nanalyze the role of the media as a whole but also focus on each single newscast in our media set. \nIn addition, to tac kle endogeneity issues, which could not fully be ruled out by Dewenter et al \n(2020), we utilize elections as an identification tool in our empirical strategy.  \n8 3. The Political Positioning of  the \u201cBig Four \u201d \n3.1 The Data: Political Media Coverage of ABC, CBS, FOX , and NBC  News  \nThe Media Datas et  \nOur dataset , collected by Media Tenor International ,10 comprises news programs  by four major \nUS news  gathering organizations  \u2013 ABC News, CBS News, FOX News,  and NBC News  \u2013 namely ABC  \nWorld News Tonight , the CBS Evening New s, NBC  Nightly News , and FOX\u2019s Special Report  from the \nbeginning of 2001 through the end of 2012.   We are aware that by focusing on ABC News, CBS \nNews, FOX News , and NBC New s, we are mixing aired channels ( ABC News, CBS News, and NBC \nNews ) with a cable cha nnel ( FOX News ). However, the distinction of aired and cable channels is \nnot relevant for the analysis provided. In addition, other news organizations, like CNN , could also \nbe of interest. Although the selection of the media in our analysis is mainly drive n by data \navailability, FOX News  has higher  ratings  than CNN11. Hence, the selection can be argued from this \nperspective as well.   \nBeside s anecdotic al evidence and scientific work  by, among others, Groseclose and Milyo (2005) , \nthe \u201cMedia Bias/Fact check\u201d  website,12  which see s itself as \u201cthe most comprehensive media bias \nresource ,\u201d provides information on the political positioning of the ABC  News , CBS  News , FOX  News , \nand NBC  News :  \n\u2022 ABC News , founded in 1945 , is the  news  division of the  American Broadcasting \nCompany  (ABC ), which owned by the  Disney Media Networks  division of  The Walt Disney \nCompany . Its flagship program is the daily evening news cast  ABC  World News tonight,  \nwhich is a focus of our investigation. \u201cMedia Bias/Fact check\u201d sees ABC News  as having a \nslight to moderate  liberal of left -center bias with a high share of factual reporting .13   \n\u2022 CBS News , founded in 192 7, is the news division of American television and radio service  \nColumbia Broadcasting System  (CBS). The president of CBS News  is Susan Zirinsky . CBS \nNews  has multiple programs, including the CBS Evening  News,  which is a focus of our \ninvestigation. \u201cMedia Bias/Fact check\u201d sees CBS News  to have a slight to moderate  liberal \nor left -center bias with a high share of factual reporting.14 \n\u2022 Fox News  was founded in 1996 by Rupert Murdoch . It is an American cable and sa tellite \nnews television channel that is owned by the Fox Entertainment Group, a subsidiary of \n                                                           \n \n10 For more information see: www.mediatenor.com  \n11 See for instance: https: //variety.com/2019/tv/news/network -ratings -top-channels -fox-news -espn -cnn-cbs-nbc-\nabc-1203440870/  (last checked: August, 13th, 2020)  \n12 See: https://mediabiasfactcheck.com/ (last checked: August, 13th, 2020) . \n13 See https://mediabiasfactcheck.com/abc -news/  (last checked: August, 13th, 2020) . \n14 See https://mediabiasfactcheck.com/cbs -news/  (last checked: August, 13th, 2020) . \n9 21st Century Fox . One of its news shows  is FOX\u2019s Special Report , which is a focus of our \ninvestigat ion. \u201cMedia Bias/Fact check\u201d sees Fox News as having a moderate to strong \nconservative  or right bias with a mixed share of factual reporting.15 \n\u2022 NBC News  was founded in 1940  and is the news d ivision of the American \nbroadcast  television  network , NBC , formerly known as the  National Broadcasting \nCompany.  The division operates under  NBC Universal News Group , a subsidiary of NBC \nUniversal , which is, in turn , a subsidiary of  Comcast . One of  its flagship news programs is \nthe NBC Nightly News , which is a focus of our investigation. \u201cMedia Bias/Fact check\u201d sees \nNBC News  to have a slight to moderate  liberal or left -center bias with a high share of factual \nreporting .16 \nHuman Coding  \nEach news program was coded by human analysts , based upon over 700 characteristics  that are \ndefined in a binding coding manual (\u201cthe co debook \u201d), including  the reported topic (such as \ndomestic policy, health reform , military actions , etc.), participating persons (such as politicians, \nentrepreneurs, managers, celebrities , etc. ), participating institutions (such as political parties, \ncompani es, football clubs , etc. ), region of reference (such as Germany, USA, the UK, world), time \nreference (future, present , past), and the source of information (such as journalist, politician, \nexpert, etc.). Each report was analy zed news item by news item, i.e . each time that a new topic, \nperson, institution, region, time reference , or source was mentioned, an additional news item was \ncoded. In addition, the analysts captured if the relevant protagonists and/or institutions receive \npositive, neutral, or negativ e tone of coverage . Skipping all items that are not on political topics \nresult s in a total of 815,252 observations  that are used  in our analysis.   \nThe use of hand -coded data is an advantage , as \u201ccompared to human -based coding, automated \ncoding is less acc urate in detecting the tone of each specific text analyzed\u201d (Puglisi and Snyder \n2015 a, 656). With respect to political text analysis, Grimmer and Steward (2013) find that \ncomputer linguistic approaches achieve accuracy no more than 0.65. Consequently, Grim mer and \nSteward (2013) conclude that, for political text analysis, there is (at least so far) no adequate \nsubstitute for human coding.  In a similar line, more recently , in their comparative study of hand -\ncoding and computer -assisted text analysis methods , Nelson  et al. ( forthcoming , 25) conclude that \n\u201cnone of the methods replace the human researcher.\u201d17  Consequen tly, by now , \u201cmeasuring the \ntone of articles and editorials, is relatively underutilized in economics\u201d (Puglisi and Snyder, 2015 a, \n664). In contras t, for the human coded data utilized in the present contribution , Media Tenor \n                                                           \n \n15 See https://mediabiasfactcheck.com/fox -news/  (last checked: August, 13th, 2020) . \n16 See https://mediabiasfactcheck.com/nbc -news/ (last checked: August, 13th, 2020) . \n17 Earlier comparisons of human coding and computer assisted methods go b ack to Nacos et al. (1991).  \n10 guarantees a minimum accuracy of 0.85 in comparison to a coding that  is fully in line with the \ncodebook.18  \nTone and Tonality  \nOn average, the tone of the news items observed is n egative , with a mean of -0.06, confirming the \nwell -known negativity bias of media reporting.19 In addition, the average tone in the reporting of \nFOX  News  is, at -0.08, much more negative than the average tone of ABC  News , CBS  News , and NBC  \nNews , which  rang e from -0.03 to -0.05 (see Table 1). \n \nTable 1: Summary statistics for all newscasts  \n \n \nOur dataset covers all political coverage of the newscast analyzed on both Democrats and \nRepublicans during the  Republican presiden cy of George W. Bush  as well as the Democratic \npresiden cy of Barack Obam a. By comparing the tone in media reporting between the time of \nGeorge W. Bush\u2019s administration  (see  Figure 1) and Barack O bama\u2019s administration  (see Figure \n2), we can observe differences in the political coverage of the newscasts analyzed. Media \nreporting, for most newscasts, seems to be more critical toward Republicans during  their \npresidency and vice versa for Democrats.  \n \n \n \n \n                                                           \n \n18 The accuracy and reliability of the coding was regularly checked by Media Tenor, both with standard tests and random \nspot checks, based on the codebook. Each month, for each coder, three analyzed reports were selected randomly  and \nchecked. Coders scoring lower than 0.80, that is 80 percent accuracy in comparison to the codebook, were removed \nfrom the coding process. In no month did the mean deviation among all coders exceeded 0.15. As a result, Media Tenor's \ndata achieves an ac curacy of minimum 0.85.  \n19 The n egativity bias in media reporting indicates that media focus more on catastrophes, crime, as well as threatening \npolitical and economic developments than on more positive news (see among others Friebel and Heinz, 2014; Garz, \n2013, 2014; Heinz and Swinnen, 2015 or Soroka, 2006).  Medium  Obs  Mean  Std.Dev.  Min  Max  \nABC  News  135.128  -0.0387558  0.4676518  -1 1 \nCBS  News  121.286  -0.0471695  0.5127805  -1 1 \nFOX  News  394.736  -0.0830707  0.4943626  -1 1 \nNBC  News  164.102  -0.0340642  0.4589244  -1 1 \nTotal  815.252  -0.0605199  .4864011  -1 1 \n11 Figure 1: Share of positive, negative and neutral News \nduring Bush administration  Figure 2: Share of positive, negative and neutral News \nduring Obama administrati on \n  \n \nBased on the number of positive, negative , and neutral news items , as defined  by Dewenter et al. \n(2020), the tonality \ud835\udc60, on a specific person or institution \ud835\udc57, extracted from a newscast \ud835\udc56, during time \nt, can be defined as:  \n\ud835\udc60\ud835\udc56,\ud835\udc61\ud835\udc57=\ud835\udc5b\ud835\udc56,\ud835\udc57,\ud835\udc61\ud835\udc5d\ud835\udc5c\ud835\udc60\u2212 \ud835\udc5b\ud835\udc56,\ud835\udc57,\ud835\udc61\ud835\udc5b\ud835\udc52\ud835\udc54\n\ud835\udc41\ud835\udc56,\ud835\udc57,\ud835\udc61 \n (1) \nwhere \ud835\udc41\ud835\udc56,\ud835\udc57,\ud835\udc61 is the total of all news items,  \ud835\udc5b\ud835\udc56,\ud835\udc57,\ud835\udc61\ud835\udc5d\ud835\udc5c\ud835\udc60 is the number of positively rated reports , and  \ud835\udc5b\ud835\udc56,\ud835\udc57,\ud835\udc61\ud835\udc5b\ud835\udc52\ud835\udc54 \nthe equivalent for negati ve reports.  \n \n3.2 The Political Coverage Index ( PCI): A Tonality -Based Measure of Media Bias  \nThe Political Coverage Index ( PCI), as introduced by Dewenter et al. ( 2020), is based on tonalities \nof news reports about political parties and politicians . PCI serv es as a measure of the relative \npolitical positioning of the media. Thereby, our contribution addresses the research gap that \nanalyzing  media bias by \u201cmeasuring the tone of articles and editorials, is relatively underutilized \nin economics\u201d (Puglisi and Snyder, 2015, 664).   \nBy constructing the index, we are able to identify possible media biases and to analyze how \ncritically media cover specific parties, governments , or presidents. The unweighted PCI is \nconstructed by subtracting the average tonality of all news items about the Democrats from the \naverage tonality of the news about the Republicans.20 The PCI is measured as the difference \n                                                           \n \n20 In addition to biased media reporting in terms of tonality, media coverage might be biased by the share of coverage \ndedicated to one party. In extreme cases , media could neglect to report on a certain party. In order to account for the \nactual share of coverage of news items, we also define a weighted \ud835\udc43\ud835\udc36\ud835\udc3c\ud835\udc64 where \ud835\udc64\ud835\udc45\ud835\udc52\ud835\udc5d stands for the share of coverage of \nreports on the Republicans and \ud835\udc64\ud835\udc37\ud835\udc52\ud835\udc5a for the share of coverage on the Democrats [ \ud835\udc64\ud835\udc45\ud835\udc52\ud835\udc5d+\ud835\udc64\ud835\udc37\ud835\udc52\ud835\udc5a =1]: \ud835\udc43\ud835\udc36\ud835\udc3c\ud835\udc56,\ud835\udc61\ud835\udc64=\n\n12 between the two values, with  \ud835\udc60\ud835\udc61\ud835\udc45\ud835\udc52\ud835\udc5d consisting of the tonality about the Republicans and \ud835\udc60\ud835\udc61\ud835\udc37\ud835\udc52\ud835\udc5a \nabout the Democrats.  \n\ud835\udc43\ud835\udc36\ud835\udc3c \ud835\udc56,\ud835\udc61=\u2211\ud835\udc60\ud835\udc61\ud835\udc45\ud835\udc52\ud835\udc5d\ud835\udc5b\n\ud835\udc57=1\u2212\u2211\ud835\udc60\ud835\udc61\ud835\udc37\ud835\udc52\ud835\udc5a\ud835\udc5a\n\ud835\udc58=1 \n (2) \nAs per definition of the PCI, positive values indicate  a more conservative positioning of the media \noutlet, whereas negative values indicate more liberal reporting. In other words, positive values of \nthe PCI indicate  less critical coverage of the Republican Party and negative values less critical \ncoverage o f the Democratic Party.  \n3.3 Application of the  Media  Data to the PCI  \nBy applying the media data described in section 3.1 to the PCI ,as defined in section 3.2, the picture \nin Figure 3 emerges . The aggregated  PCI of all four newscasts varies between -0.40 and +0.79 with \nan average standard deviation of 0.15. The index starts with relatively high values but also with \nsharp fluctuations around the events of the terroris t attacks in the period after 9/11 and the Iraq \nWar in 2003. After a dip in 2004, the PCI varies around zero until 2007 , when it becomes less \nsteady.  \nFigure 3: Monthly PCI, aggregated for all media  with administration  \n \n                                                           \n \n\ud835\udc64\ud835\udc45\ud835\udc52\ud835\udc5d\u2211 \ud835\udc60\ud835\udc61\ud835\udc45\ud835\udc52\ud835\udc5d \ud835\udc5b\n\ud835\udc57=1 \u2212\ud835\udc64\ud835\udc37\ud835\udc52\ud835\udc5a \u2211 \ud835\udc60\ud835\udc61\ud835\udc37\ud835\udc52\ud835\udc5a \ud835\udc5a\n\ud835\udc58=1 . We also conduct our analyses with the weighted PCI, but the results do not show \nsubstantial dif ferences between weighted and unweighted PCI (see Table A1 in the Appendix). Therefore, we continue \nto focus on the unweighted PCI in the following sections.  \n\n13 Table 2: Summary statistics for all newscasts : PCI  \n \nBy splitting the data between the newscasts, we can see differences in the PCI of certain newscasts \nover time ( see Figure 4). The vertical lines indicate a new administration .21  \n \nFigure 4: PCI per medium  and presidencies  \n \n                                                           \n \n21 Note that for FOX  News , the obtained observations only begin in January 2004.  \nMedium  Obs  Mean  Std.Dev.  Min  Max  \nABC  News  143  -0.0126969  0.151564  -0.3595873  0.6633663  \nCBS  News  140 -0.0093912  0.1596853  -0.4005961  0.4712919  \nFOX  News  98 0.1016607  0.0982841  -0.0436856  0.3917593  \nNBC  News  142  -0.0015361  0.1552664  -0.368345 0 0.7868421  \nTotal  523  0.0126467  0.1522971  -0.4005961  0.7868421  \n14 Focusing on the average PCI of each medium during the Bush administration ( Figure 5) and during \nthe Obama administration ( Figure 6), one can see interesting differences in the political coverage \nof ABC  News , CBS  News , FOX  News , and NBC  News .22  \nDuring the Obama administration (Figure 6), the PCI shows positive values  for all newscasts , thus \nindicat ing that media reporting was more critical to the Democrats in power than to Republicans.  \nThis can be seen as a first hint of reporting that is cr itical of the government during the Obama \nadministration. H owever, the PCI value of FOX News is, at +0.17 , far higher than the PCI values  of \nABC  News , CBS  News , and NBC  News, which rang e from 0.0 06 to 0.0 1. This shows how con servative \nthe media repo rting o f FOX  News  was during the Obama administration.  \n \nFigure 5: PCI per medium during Bush administration  Figure 6: PCI per medium during Obama administration   \n \nIn contrast, during the Bush administration ( Figure 5), the PCI values of ABC  News , CBS  News , and \nNBC  News  show negative values, indicating that the media reporting was more critical to the \nRepublicans than on the Democrats. Again , this can be seen as a hint of a  government critical \nreporting , now during the Bush administration. However, the PCI values of ABC  News , CBS  News , \n                                                           \n \n22 For the aggrega ted PCI for each medium  over the whole timespan see Figure A1 in the Appendix.   \n\n15 and NBC  News  during the Bush administration are , from -0.02 to -0.01, much more negative than \ntheir  positive values during the Obama administ ration , from +0.006 to +0.1.  This can be seen as \na hint o f the  general ly republican -critical political positioning s of ABC  News , CBS  News , and NBC  \nNews . The political reporting of FOX  News  during the Bush administration  clearly presents a \ndifferent pictur e. In contrast to ABC  News , CBS  News , and NBC  News , during the Bush \nadministration the PCI values of FOX  News  are still positive, thus indicat ing that FOX  News  was  still \nreporting more critical ly on Democrats  even when Republicans were in power. The  FOX  News PCI \nvalue is , at +0.04, somewhat smaller than it was during  the Obama administration , at +0.17. \nHowever, it is still more positive than the PCI values for ABC  News , CBS  News , and NBC  News  are \nnegative.  \nOf cours e, this simple c hart inspection can only p rovide first hint s on systematic differences in the \nmedia reporting of the newscasts analyzed and is  not a substitute for a robust empirical analysis , \nwhich we provide in section 4.  \n4. Do the Big Four  serve as 4th Estate ? \nIn this section , we investigate the role of the media as the fourth estate by estimating the effect of \nthe presidencies on the political positioning of the media as measured by the Political Coverage \nIndex for each of the  four different newscasts in our sample . Expressed in a simple way, we analyze \neconometrically the obtained PCI values  of ABC, CBS, FOX,  and NBC  during the Republican  \npresidency of George W. Bush and during the Democratic presidency of Barak Obama . If we find \nrobust empirical evidence that media co verage is more critical toward the ruling party, we can \nconfirm the hypothesis that the media serves as an additional level of control for government , thus \nit is the fourth estate. In section  4.2.1 , the results for the entire me dia set are presented,  in section \n4.2.2 , a more in -depth analysis of each respective newscast in our media data set.  \n \n4.1  Empirical Strategy  \n4.1.1 Econometric Set Up  \nTo analyze the role of ABC  News , CBS  News , FOX  News , and NBC  News  in the US democracy \neconometrically, we f irst conduct a  basic Ordinary Least Squares (OLS) regression to estimate a \nmodel explaining PCI as the dependent variable. We include a dummy variable Democrat , which \nrepresents the presidential incumbent : taking the v alue of 1 during the D emocratic presiden cy of \nObama  and 0 during the Republican presidency of Bush .  \nIn addition, to capture at least a part of the factual performance of the government, which is likely \nto be a major driver of the political media coverage and the PCI as well, we add several economic \n16 and geopolitical controls . Specifically , we add monthly variables for the seasonally adjusted \nunemployment rate ( Unempl oyment ), the consumer price index ( CPI), which accounts for all items \nin the United States w ith base year 2015 , and business tendency surveys for manufacturing as a \nconfidence indicator  (Business ). In addition, we add the geopolitical risk index ( GPR ) to our \nregressions , which reflects the occurrence  of military tensions, terrorist attacks , or si milar threats \nworldwide  to account for the role and the self -understanding of the United States as a global \nsuperpower .   \nThe regression is then specified as follow s: For every media newscast \ud835\udc56, the \ud835\udc43\ud835\udc36\ud835\udc3c is described at \ntime \ud835\udc61, as \n\ud835\udc43\ud835\udc36\ud835\udc3c \ud835\udc56,\ud835\udc61=\ud835\udefd0+ \ud835\udefd1\ud835\udc37\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61 \ud835\udc61+\ud835\udefe1\ud835\udc36\ud835\udc43\ud835\udc3c \ud835\udc61+ \ud835\udefe2\ud835\udc48\ud835\udc5b\ud835\udc52\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc66\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 + \ud835\udefe3\ud835\udc35\ud835\udc62\ud835\udc60\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60 \ud835\udc61+ \ud835\udefe4\ud835\udc3a\ud835\udc43\ud835\udc45 \ud835\udc61\n+\ud835\udf00\ud835\udc56,\ud835\udc61 (4) \nwhere \ud835\udc37\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61 t is a dummy variable indi cating that a Democrat is the sitting president of the \nUnited States of America at time \ud835\udc61, the coefficients \ud835\udefd and \ud835\udefe are to be estimated , and \ud835\udf00 represents \nthe error term. In order to account for the panel structure of our data , in a next step , we add both \nmedia fixed effects as well as month fixed effects to our regression to control for unobserved \nstructural differences between the media as well as for seasonal variations in media coverage.  \nThus, the regression equation is expanded to the following:  \n\ud835\udc43\ud835\udc36\ud835\udc3c\ud835\udc56,\ud835\udc61=\ud835\udefc\ud835\udc56 +\ud835\udc47\ud835\udc61+\ud835\udefd0+ \ud835\udefd1\ud835\udc37\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61 \ud835\udc61+\ud835\udefe1\ud835\udc36\ud835\udc43\ud835\udc3c \ud835\udc61+ \ud835\udefe2\ud835\udc48\ud835\udc5b\ud835\udc52\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc66\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 + \ud835\udefe3\ud835\udc35\ud835\udc62\ud835\udc60\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60 \ud835\udc61\n+ \ud835\udefe4\ud835\udc3a\ud835\udc43\ud835\udc45 \ud835\udc61+\ud835\udf00\ud835\udc56,\ud835\udc61 (5) \nwhere \ud835\udefc\ud835\udc56 and \ud835\udc47\ud835\udc61 denote media and month fixed effects , respectively . \n \n4.1.2 Identification Strategy  \nWe are aware that conducing this kind of panel regression with media and time fixed effects can \nstill raise legitimate endogeneity concerns  for several reasons:  First, i t cannot be excluded that \nthe presiden cy not only affects the political positioning of the media measured by the PCI, but that \ntheir political coverage  affects the outcome of elections and , thus president in office. For instance, \nDellaVinga and Kaplan (2007),  Dewenter et al . (2019 ), and  Enikolopov et al. (2011) provide \nempirical evidence regarding the impact of media reporting on election  outcomes and voting \nintentions. If this is the case , the coefficients in our regression would be biased due to reverse \ncausality.  Secondly, a lthough the macroeconomic factors of u nemployment rates, the consumer \nprice index , business confidence , and geopolitical risks are controlled for, we cannot fully account \nfor the performance of the government. Therefore, we are unable to determine if the PCI values \nare really driven by the party affiliation of the incumbent or by the performance of the government  \napart from the \u201cperformance indicators\u201d controlled for. If the latter would drive the dependent \n17 PCI as well as the explanatory dummy variable Democrat , which indicates who is in office , this \nwould cause biased coefficients due to omitted variable s.  \nTo account for the possible endogeneity  issues  mentioned , we split our sample into different \nsubsamples, consisting of periods with and without elections . In order to do so , we create \ntimesp ans ranging from four months before the election date up to one month  after  the election. \nThe intuition behind this approach is, first, that in the four months  before the election and , thus,  \nduring the campaign , media reporting affects election outcomes , as shown by DellaVinga and \nKaplan (2007),  Dewenter et al . (2019 ), and Enikolopov et al. (2011) . Specifically , during this time , \nthe coefficients could be biased due to both reverse causality and omitted variable bias , as \ndiscussed above. In addition, i n th e weeks  directly after an election another effect could lead to \nbiased results . In the initial weeks following the November presidential election , there is \nsomehow an intermediate period before the elector\u2019s  election , which  takes place on the first \nMonday after December 12th. During  this period , political coverage is often dominated by \nreporting on elect oral  success  and the new president , who is not even elected by the electors ; this \ncoverage of the presidential -elect tends to be positive, with minimal crit icism level led, something \nstanding in stark contrast to subsequent coverage  during  the subsequent presidential  term . 23  \nHence , in our analysis , we focus  on time span s other than  periods from four months before the \nelection to one month after  it. Thus, in our sample , elections and election outcomes are purely \nexogenous event  (or at least less prone to endogeneity) . Hence, the endogeneity issue of reverse \ncausality of the PCI on the incumbent dummy  Democrat  can be ruled  out. In addition, the \nendogeneity issu e that both the dependent PCI and the explanatory Democrat  are driven by the \nperformance of the government  apart from the \u201cperformance indicators\u201d controlled for can also \nbe ruled out, as in this period Democrat  is given and purely exogenous. This  assumpti on would \nnot hold if the presidency could  end early , with snap elections, a feature t hat is , in contrast to many \nother democracies , constitutionally not possible in the US . Table 3 shows all relevant election dates \nfor our dataset . \n \n \n \n \n                                                           \n \n23 We also test variations of the timespans. For example, we test four months before and four months after an election, \nrespectively , and obtain similar results. As the inaugur ation takes place in January, we expect media reporting to be less \ninfluenced by electoral success by then and to have return ed to critical coverage. Furthermore, we test for three months \nbefore and one month after an election. However, the results show we aker coefficients , hinting at biased results due to \nreverse causality and omitted variable problems in the fourth month before the election (see Table 4 in comparison to \nTable A1 in the Appendix).  \n18 Table 3: Election dates  \nPresident  Election  Inauguration  Midterm Elections  End of Term  \nI G.W. Bush  7 November 2000  20 January 2001  5 November 2002  20 January 2005  \nII G.W. Bush  2 November 2004  20 January 2005  7 November 2006  20 January 2009  \nI Obama  4 November 2008  20 January 2009  2 November 2010  20 January 2013  \nII Obama  6 November 2012  20 January 2013  4 November 2014  20 January 2017  \n \nPresidential elections take place every four years in November ; this elec tion includes all 435 \nmembers of the US House of Representatives and one -third of all seats in the US Senate. M idterm \nelections are held after two years of a president\u2019s term in office , determin ing all 435 seats in the \nUS House of Representatives as well a s one-third of all seats in the US Senate. In our sample, which \nruns from the beginning of 2001  through the end of 2012, we have data covering  three  \npresidential elections and three midterm elections, as shown in Figure 7. For President George W. \nBush, the outcome of the 2002 midterm elections , during  his first term , generally favor ed his own \nparty, the Republicans. However, f our years later  the Democratic Party won a majority of the seats \nin Congress, resulting in a  loss for the governing party. The same pattern in midterm elections \noccurred during the presidency of Barack Obama in 2010 and 2014,  respectively.  \n \nFigure 7: Presidential elections and midterm elections  \n \n              Presidentia l elections are indicated by solid vertical lines ; midterm elections  by dashed lines.  \n\n19 4.2 Empirical Results  \n4.2.1 Average Results on the Big Four  \nSix different specifications of our empirical investigation on the entire media set are presented in  \nTable 4. Specifications OLS I  to OLS III are OLS models, FE I to FE III are the two-way fixed effect \nregressions. All models estimat e the political positioning of the Big Four measured by the PCI as \nthe dependent variable and the incu mbent dummy (\ud835\udc37\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61 ) as main explanatory variable . \nWhen the latter is reversed to a Republican presidency , we observe the expected reverted results  \nin our time span analyzed .  \n \nTable 4: Impact of the party affiliation of t he president on the political positioning of the Big Four  \n(all media , elections periods : 4/1 months before/after an election ) \nDependent \nvariable:  \n \nPCI OLS I  OLS II  OLS III  FE I   \n FE II   \n FE III   \n \n \nSample  Full sample  Presidential  \nelections  \nperiods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  Full sample  Presidential  \nelections  \n Periods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  \n       \nDemocrat  0.157***  0.214***  0.237***  0.175***  0.240***  0.265***  \n \n (0.0459)  (0.057 5) (0.0587)  (0.0446)  (0.0544)  (0.0551)  \nConsumer Price \nIndex  (CPI)  -0.00364**  \n(0.00184)  -0.00396*  \n(0.00204)  -0.00317  \n(0.00209)  -0.00546***  \n(0.00183)  -0.00586***  \n(0.00205)  -0.00511**  \n(0.00209)  \n       \nUnemployment  -0.00914  -0.0202*  -0.0321***  -0.0111  -0.02 41**  -0.0365***  \n (0.00927)  (0.0114)  (0.0120)  (0.00894)  (0.0108)  (0.0113)  \nBusiness  -0.0144**  -0.0154**  -0.0178**  -0.0149**  -0.0149**  -0.0174**  \n (0.00668)  (0.00752)  (0.00748)  (0.00633)  (0.00707)  (0.00717)  \nGPR  0.000455***  0.000483***  0.000450***  0.000505* ** 0.000523***  0.000509***  \n (0.000157)  (0.000159)  (0.000170)  (0.000154)  (0.000154)  (0.000169)  \nConstant  1.728**  1.905**  2.143**  1.918**  2.021**  2.291***  \n (0.781)  (0.847)  (0.849)  (0.745)  (0.801)  (0.817)  \n       \nObservations  523  451  386  523  451  386  \nR-squared  0.108  0.123  0.119  0.228  0.239  0.233  \nMonth FE  No No No Yes Yes Yes \nMedia FE  No No No Yes Yes Yes \nRobust standard errors in parentheses  \n*** p<0.01, ** p<0.05, * p<0.1  \n \nThe first specifications , OLS  I and FE  I, respectively, include the whole sample w ithout any \nrestrictions. For the second specifications , OLS II and FE  II, we drop the four  months before  and \none month  after  a presidential election  from our sample . Furthermore, in the third specification , \nOLS III and FE III, we not only drop the time spa n of four months before  and one month  after a  \npresidential election but also around midterm elections ; that is, August to December , every two \nyears from 2002 onwards.  \n20 The coefficient for a Democratic presidency ( Democrat ) is positive and highly significan t for every \nspecification. This indicates that media reporting during Democratic presidenc ies is generally \nassociated with higher PCI value s, which can be interpreted as more conservative news coverage. \nWhen removing the time span around presidential elect ions from our sample , this effect \nintensifies, leading to even more conservative reporting. When excluding all election periods, the  \neffect of the president\u2019s party affiliation on the political positioning of the Big Four , as measured \nby the PCI, is even s tronger . This can be seen as an indication that , around elections , the \ncoefficients are biased due to the aforementioned endogeneity problems. In addition, the results \nsuggest that critical media coverage accompanies the incumbent president , which hints at  the \nmedia fulfilling their role as the fourth estate.  Both the CPI and the business tendency indicator  \n(Business ) have , in nearly all specifications (despite the CPI in OLS III) , a significant and slightly \nnegative influence on the PCI, suggesting that hi gher consumer prices or higher business \nconfidence are connected with more conservative reporting. The coefficient for the \nunemployment rate is insignificant in specifications OLS I and FE I , which is, at least partly, \nexplained by the high correlation bet ween the macroeconomic variables. This could potentially \nhint at multicollinearity , but the test with variance inflation factors indicates that the degree of \ncollinearity is still tolerable. The coefficient for the geopolitical risk index is highly signifi cant and \npositively associated with the PCI, indicat ing that , in times with high geopolitical risk , media \nreport ing tends to be less critical o f Republicans than o f Democrats in comparison to times with \nlower geopolitical risk . This  is in line with the int uition .24  \nIn addition, we add both month and media dummies in the fixed effects regressions FE I to FE II I. \nThe month dummies are insignificant without exception, whereas the media dummies are \nsignificant and differ between the newscasts: ABC  News , CBS New s, and NBC News  are associated \nwith a lower PCI and, thus , more liberal reporting , where FOX News  positive ly affects  the PCI, \nsuggesting more conservative political  coverage. We also test t he inclu sion of  dummies for the \nparty holding the majority in the House of Representatives , which can change after every Federal \nelection. As the effect on the PCI is unclear and could go in either direction, we drop this variable \nfrom further consideration.  \nMoreover, we verified our identification strategy by estimating  the models with different time \nspans , testing the effect on the PCI. By switching the included months from actual election periods \nto non -election times, we can observe a statistically lower significance and a smaller impact of the \npresidential dummy on o ur dependent variable. Thus, w e conclude that , in our setting, elections \n                                                           \n \n24 See Table A2 in the appendix for regression results using the weighted PCI, which are quantitatively identical to the \nresults of regression using the unweighted index.  \n21 can be seen as an exogenous event with which we can identify the impact of the party affiliation \nof the president on the political positioning of the Big Four . \nTo check if our results  are ro bust to variation s in campaign tim ings,  we also varied the number of \nmonths before and after an election whe n campaigns are suppose d to happen. Overall, the results \nare quite stable  independent  of this variation.25  \nAlthough our sample is limited an d, thus , the number of observations strongly reduced, we also \ninvestigate the effects during the election campaign periods in separate regressions (see  Table 5).  \nAnalyzing the full sample of TV newscasts , the incum bent dummy (Democrat ) turns insignificant \nin three  of four regressions. Only OLS I show s significant results ; however , the coefficient is  now  \nnegative. Th is can be seen as an empirical hint of less critical media reporting on the upcoming \npresident  during the election campaign.  During the campaign , it can become increasingly clear \nthat one candidate has a good chance to become/remain president , which can result in more \npositive (less critical) reporting on the candidate who i s perceive d to be likely to win  the election.  \nWe interpret these results as some evidence for our assumption that the incumbent dummy and \nthe PCI are differently linked to each other during election campaigns for several endogeneity \nproblems , which support s our identification strategy to drop election campaigns from our sample.  \n \n                                                           \n \n25 See Table A1 in the appendix  for regression results using election campaign periods of three months b efore an \nelection and a honeymoon period of one month. Using the full sample (FE I) , the results are similar to those from Table \n4. However, on average, the effect of the party affiliation of the running president on the PCI seems to be weaker when \nassuming that election campaigns are three months long.  \n22 Table 5: Impact of the party affiliation of the president on the political positioning of the Big Four  \n(all media , elections periods : 4/1 months before/after an election)  \nDependent vari able:  OLS I  \n OLS II  \n FE I  \n FE II  \n \nPCI     \nSample  Presidential  \nelection  periods \nonly  Presidential  & \nmidterm  \nelection  \nperiods only  Presidential  \n election  \nperiods only  Presidential  & \nmidterm  \nelection  periods \nonly  \n     \nDemocrat  -0.708**  -0.00621  -0.666  0.0494  \n (0.303)  (0.0947)  (0.479)  (0.0927)  \n     \nConsumer Price Index  (CPI)  0.00582  -0.00562  0.00437  -0.00958*  \n (0.00635)  (0.00562)  (0.00951)  (0.00573)  \n     \nUnemployment  0.316***  0.0543***  0.302  0.0509***  \n (0.117)  (0.0151)  (0.192)  (0.0143)  \n     \nBusine ss  0.135**  0.0102  0.127  -0.00211  \n (0.0527)  (0.0164)  (0.0857)  (0.0168)  \n     \nGPR  -0.000982  0.000592*  -0.00112  0.000565  \n (0.00106)  (0.000316)  (0.000904)  (0.000352)  \n     \nConstant  -15.70**  -0.909  -14.76  0.650  \n (6.188)  (2.069)  (10.35)  (2.146)  \n     \nObse rvations  60 114  60 114  \nR-squared  0.112  0.256  0.435  0.410  \nMonth FE  No No Yes Yes \nMedia FE  No No Yes Yes \nRobust standard errors in parentheses , *** p<0.01, ** p<0.05, * p<0.1  \n \nIn summary, so far our econometric analysis shows that when generally analyzin g the Big Four \nnewscasts, we can confirm our hypothesis that the newscasts serve as an additional control for \ngovernmental activities , thus fulfill ing their role as the fourth estate. Based on our identification \nstrategy of dropping election campaign perio ds from our sample , we find robust empirical \nevidence that during D emocratic presiden cies, the coverage of the Big Four is general ly more \nconservative than during a Republican presiden cy and vice versa.  Next, we use a respective \nidentification strategy to analyze the role of each single TV news program separately.  \n \n \n23 4.2.2 Detailed Results on ABC, CBS, FOX , and NBC  News  \nThis s ection provide s a more in -depth analysis of each single newscast in our media set to \ndetermine if ABC  News , CBS  News , FOX  News , and NBC News  serve as a fourth estate or not.   \nFor CBS News , coefficients  indicating the impact of presidential party affiliation on political \npositioning are positive and statistically significant in all specifications (see Table 6, FE I - III). This \nshows that CBS News  report s are more conservative if a Democrat is in office  and vice versa . This \ngovernment -critical reporting by CBS News  is stronger than the average government -critical \nreporting of the Big Four (see  Table 4). Dropping election campaign windows with respect to \npresidential and midterm elections from our sample (see Table 6, FE III) , the incumbent dummy  \nshows , with a coefficient of 0. 313 , the strongest effect of presidential party affiliation on the \npolitical positioning of CBS News . This can be seen as an indicator that , during election campaign s, \nthe results are biased due to the several afore mentioned endogeneity problems. In specif ication \nFE III , two additional coefficient s are significant. A higher unemployment rate is connected with \nmore liberal reporting by CBS News , whereas high geopolitical risk is connected to more \nconservative reporting.  This follows intuition. As the results  show robust empirical evidence on \ngovernment -critical reporting by CBS News , we conclude that CBS News  did serve as fourth estate , \nat least during our sampl e period.  \nResult s for NBC  News  draw a similar picture. The coefficients indicating the impact of presidential \nparty affiliation on political positioning are positive and statistically significant in all specifications \n(see Table 6, FE IV - VI). This suggests  that NBC News  reports are more conservative when a \nDemocrat is in office and vice versa. Dropping election campaign times with respect to \npresidential and midterm elections from our sample due to endogeneity problems , the incumbent \ndummy shows , with a coefficient of 0.327 , the strongest effect of presidential  party affiliation on \nthe political positioning of NBC  News  (see Table 6, FE VI). Thus , NBC  News  appears to be even more \ngovernment -critical than CBS News . In specification FE VI , three more coefficient s are signifi cant. \nA higher consumer price index connect s with more liberal reporting by NBC  News . However, this \ncoefficient is only significant at the 10 percent level. Addition ally, a higher unemployment rate is \nconnected with a more liberal reporting by NBC  News , while periods of high geopolitical risk are \nconnected with more conservative reporting. Again , this  follows the intuition. As the results show \nrobust empirical evidence o f government -critical reporting by NBC  News , we conclude that NBC  \nNews  did serve as four th estate , at least during our sample period.  \n  \n24 Table 6: Impact of the party affiliation of the president on the political positioning of CBS News & NBC  News  \n(election periods:  4/1 months before/after an election)  \nDependent \nvariab le: FE I  \nCBS  News  FE II  \nCBS  News  FE III  \nCBS  News  FE I V \nNBC  News  FE V \nNBC  News  FE VI \nNBC  News  \nPCI       \nSample  Full sample  Presidential  \nelections  \nperiods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  Full sample  Presidential  \nelections  \n Periods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  \n       \nDemocrat  0.195**  0.283***  0.313***  0.220**  0.295***  0.327***  \n          (0.0879)  (0.103)  (0.106)  (0.0935)  (0.111)  (0.113)  \n       \nConsumer Price \nIndex  (CPI)  -0.00401  -0.00477  -0.00399  -0.00722**  -0.00781**  -0.00713*  \n (0.00319)  (0.00353)  (0.00376)  (0.00334)  (0.00366)  (0.00376)  \n       \nUnemployment  -0.0193  -0.0370*  -0.0524**  -0.0216  -0.0372*  -0.0516**  \n (0.0182)  (0.0212)  (0.0221)  (0.0188)  (0.0223)  (0.0235)  \n       \nBusiness  -0.0105  -0.00944  -0.0138  -0.0254*  -0.0227  -0.0257  \n (0.0132)  (0.0158)  (0.0162)  (0.0136)  (0.0154)  (0.0156)  \n       \nGPR  0.000745***  0.000772***  0.000683**  0.000509**  0.000538**  0.000616**  \n (0.000260)  (0.000266)  (0.000285)  (0.000212)  (0.000213)  (0.000254)  \n       \nConstant  1.365  1.418  1.889  3.192**  3.046*  3.367**  \n (1.426)  (1.638)  (1.699)  (1.550)  (1.678)  (1.688)  \n       \nObservations  140  122  104  142  124  106  \nR-squared  0.237  0.281  0.232  0.205  0.229  0.253  \nMonth FE  Yes Yes Yes Yes Yes Yes \nRobust standard errors i n parentheses , *** p<0.01, ** p<0.05, * p<0.1  \n \n \n \nTurning to the results for FOX  News , a different picture is drawn. None of the coefficients indicating \nthe impact of presidential party affiliation on the political positioning of FOX  News  are statistically \nsignificant (see Table 7, FE I - III). This shows that FOX  News  does  not changing its political \npositioning significantly , regardless of who is in the Oval Office . These results are in line with the \ndescriptive stat istics , which show that FOX  News  report s are always more critical o f Democrats \nthan o f Republicans (see Figure 5 and Figure 6). In specification FE III, which drops both \npres idential and midterm election campaign times from our sample due to endogeneity problems , \nonly one coefficient is significant. A higher consumer price index connect s with even more \nconservative reporting by FOX  News . As the results show no empirical eviden ce o f government -\ncritical reporting by FOX  News , we cannot find any evidence that FOX  News  serve s as fourth estate , \nat least during the period  under study . \nFinally , focusing on ABC News  exclusively , none of the coefficients indicating the impact of \npreside ntial party affiliation on the political positioning of ABC News  are statistically significant \n(see Table 7, FE IV - VI).  Hence, based on the econometric analysis provided , we do not find \nevidence that ABC  News  can be seen as the fourth estate , at least during our sample period.  \n25 While both  FOX News  and ABC News  do not seem to serve as a fourth estate, the ir respective  \npolitical coverage clearly differ s. While the a verage PCI of ABC  News , at -0.01269 , indicat es rathe r \nliberal reporting, the average PCI of FOX  News , at 0.10166 , indicat es strongly conservative \nreporting on average. In addition, descriptive statistics show that , on average,  ABC News  reports \nare more liberal during Republican presidenc ies and more conserv ative during Democratic \npresidencies , whereas FOX  News  reports are always more critical o f Democrats than o f the \nRepublicans , regardless of who is the Oval Office (see Figure 5 and Figure 6). However, the varying \npolitical positioning of ABC News  depend ent on presidential party affiliation is not statistically \nsignificant . \n \nTable 7: Impact of the party affiliation of the president on the political posit ioning of FOX News  & ABC  News   \n(election periods:  4/1 months before/after an election)  \nDependent \nvariable:  FE I  \nFOX News  FE II \nFOX News  FE III \nFOX News  FE I V \nABC  News  FE V \nABC  News  FE VI \nABC  News  \nPCI       \nSample  Full sample  Presidential  \nelections  \nperiods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  Full sample  Presidential  \nelections  \n Periods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  \n       \nDemocrat  0.0376  0.0720  0.101  0.117  0.144  0.146  \n (0.0559)  (0.0759)  (0.082 6) (0.0912)  (0.113)  (0.112)  \n       \nConsumer  0.00343  0.00851***  0.00829***  -0.00560  -0.00568  -0.00516  \nPrice Index  \n(CPI)  (0.00236)  (0.00281)  (0.00296)  (0.00352)  (0.00392)  (0.00403)  \n       \nUnemploy - 0.0153  0.000698  -0.00768  -0.00187  -0.00747  -0.0121  \nment \n (0.0137)  \n (0.0155)  \n (0.0172)  \n (0.0186)  \n (0.0226)  \n (0.0233)  \n \nBusiness  0.0181***  0.0158**  0.0122  -0.0206*  -0.0227*  -0.0239*  \n (0.00682)  (0.00686)  (0.00730)  (0.0113)  (0.0122)  (0.0124)  \n       \nGPR  0.000302  -0.000103  0.000203  0.000225  0.000212  0.000146  \n (0.000492)  (0.000458)  (0.000702)  (0.000265)  (0.000260)  (0.000270)  \n       \nConstant  -2.143***  -2.256***  -1.853**  2.446*  2.695*  2.806*  \n (0.709)  (0.688)  (0.739)  (1.353)  (1.422)  (1.470)  \n       \nObservations  98 80 68 143  125  108  \nR-squared  0.458  0.635  0.584  0.128  0.161  0.122  \nMonth FE  Yes Yes Yes Yes Yes Yes \nRobust standard errors in parentheses , *** p<0.01, ** p<0.05, * p<0.1  \n \n \n \n \n \n \n \n \n \n \n \n26 5. Conclusion  \nIn th is contribution , we investigate if the four big US news  gathering organizations \u2013 ABC  News , \nCBS News , FOX  News , and NBC  News  \u2013 (still) fulfill their role as the fourth estate in the US \ndemocrac y. Specifically , we analyze the political positioning of ABC  World News Tonight , the CBS \nEvening News , NBC  Nightly News , and FOX\u2019s Special Report , based on the tonality  of their political \ncoverage as well as the variation of their positioning depending on the presiden t. Beside the \ngeneral review of the  TV news  programs mentioned , we analyze the political coverage of each \nsingle newscast in the media set to investigate th e existence of a government or anti -government  \nbias . Put differently, we analyze if ABC  News , CBS  News , FOX  News , and NBC  News  deliver as fourth \nestates or if they are loyal servant s to only one party and , as such,  can be seen as ideological from \nthis pers pective.  \nOur analysis is based on more than 815,000 human -coded news items  from the aforementioned \nnewscasts  regarding Democrats and Republicans from 2001 through 2012 . Human coding is an \nadvantage of our inquiry as human coding,  in comparison to computer linguistic approaches , \nachieves greater accuracy , especially when it comes to topical context and tonality.  Hence, the data \nallow us to focus on the tonality of the political reporting of the four big US newscasts  mentioned. \nIn doing so, our contribution a ddresses the gap that analyzing political media coverage by \n\u201cmeasuring the tone of articles and editorials, is relatively underutilized in economics\u201d (Puglisi \nand Snyder 2015, 664).  \nBy using  the tonality -based Political Coverage Index ( PCI) introduced by D ewenter et al . (2020), \nwe find interesting difference in the political coverage of ABC  News , CBS  News , FOX  News , and NBC  \nNews : During the Democratic presidency of Barak Obama , the PCI shows positive values for all \nnewscasts, thus indicat ing that media rep orting was more critical of the Democrats in power than \nof the Republicans. This can be seen as a first hint of government critical reporting during the \nDemocratic presidency . However, the PCI value of FOX News  is, by far, higher than the PCI values \nof ABC  News , CBS  News , and NBC  News . This demonstrates how conservative  FOX News  report s \nwere during the Obama presidency . In contrast, during the  Republican presidency of George W. \nBush , the PCI values of ABC  News , CBS  News , and NBC  News  are negative, indicatin g that media  \nreport s were more critical of the Republicans than o f the Democrats. Again, this can be seen as a \nhint of government critical reporting, this time during the Bush administration. However, the PCI \nvalues of ABC  News , CBS  News , and NBC  News  duri ng the Bush administration are much more \nnegative than the ir respective  positive values during the Obama administration . This  can be seen \nas a hint o f a more general republican -critical political positioning of ABC  News , CBS  News , and \nNBC  News  \u2013 the so -called liberal media bias . Political reporting by FOX  News  during the Bush \nadministration clearly presents a different picture: During the Bush administration , the PCI values \n27 of FOX  News  are still positive, indicates that FOX  News  reports were still more crit ical o f the \nDemocrats than o f the Republicans in power , thus showing a strong conservative bias . However, \nthis simple inspection can only provide first hints o f systematic differences in the media reporting \nof the newscasts analyzed and is not a substitute  for a robust empirical analysis.  \nHence, we provide panel regression analysis with media and time fixed effects as well as a \nmultitude of economic and geopolitical controls to capture at least a part of the factual \nperformance of the government, which is also likely to be a major driver of the political media \ncoverage. However, with these measure s, we still cannot rule out certain serious endogeneity \nissues: If , for instance , the political positioning of the media would not just be affected by the party \naffiliation of the president in office, but the election results would be affected by the political \npositioning of the media as well , this would lead to biased coefficients due to reverse causality. \nFurthermore, if both the political positioning of the media as well as the election outcome are \naffected by the uncaptured part of the performance of the government , this would lead to biased \ncoefficients due to omitted variable s. Hence, we drop a window of time around the elections from \nour data. Consequently , our  analysis is based on the remaining part, when elections can be seen \nas a purely exogenous event. Therefore, we are able to use elections as an identification tool.  \nWhen using the entire media set, t he results of the econometric analysis show robust empir ical \nresults for an anti -government bias: When a Republican is in office , political coverage tends to be \nmore liberal, but it tends to be more conservative if the president is a Democrat. This can be seen \nas empirical evidence that the media analyzed serve  as a fourth estate  in the US . However, the \nobserv ed behavior of the media does not say anything about the motives behind it. Beside s \n\u201chonorable motives\u201d for fourth estate -behavior, it could simply be the case that the media try to \nimprove their circulatio n and viewing figures for economic reasons by covering more \nnewsworthy and attractive stories. If media coverage is, in this sense, biased toward power and \nnegativity, then media coverage would \u201cautomatically\u201d show the anti -government bias observed. \nHoweve r, although  their underlying motives would be different in this case, their actual behavior \nmedia would still fulfill their role as the fourth estate.  \nAgain , interesting differences emerge, when focusing on each single newscast in the media set : \nFor CBS News and NBC  News , we find robust empirical evidence for an anti -government -bias. \nStarting from a moderate liberal positioning , the political coverage of CBS News  and NBC  News  \nbecomes more conservative under a Democrat ic president  and becomes more liberal under a \nRepublican president. We see this as evidence that CBS News  and NBC  News  are fulfilling their role \nas the fourth estate  in the democracy . The econometric analysis of the political reporting of FOX \nNews  presents a clearly different picture. Here, we cannot find robust empirical evidence that FOX \nNews  significantly chang es its position depending upon the party affiliation of the president  in \noffice . On average, FOX News  reports are always much more critical o f Democrats than o f \n28 Republicans. Hence , FOX News  can be seen as a loyal servant to only one party and as ideological \nfrom this perspective , rather than acting as  a fourth estate  in the democracy. Finally , we do not \nfind r obust empirical evidence that ABC significantly chang es its position depending on the party \naffiliation of the president  in office . Although the descriptive statistics show a slight liberal \npositioning  and a certain tendency toward government -critical reporting by ABC  News , the \nvariation is not statistically significant . Hence, based  on the econometric analysis provided in our \ncontribution , ABC News  cannot be seen as a fourth estate in the democracy.  \nBased on the se results , future research could focus on different countries as well as on specific \npolicy issues (foreign policy, domesti c policy, economic policies, etc).  Addition ally, it would be \ninteresting to connect the results to the effects of media reporting on perception and behavior, \nwith the aim of investigat ing if the impact of partisan and fourth estate media differ and change \nover time.  \n \nReferences  \nAnderson , S.P. and McLaren , J. (2012). Media Mergers and Bias with Rational Consumers. Journal \nof the European Economic Association, 10, 831 \u2013859. \nAlsem, K. J., Brakman, S., Hoogduin, L. and Kuper, G. (2008). The impact of newspapers on \nconsumer confidence: does spin bias exist? Applied Economics, 40, 531 -539.  \nBall-Rokeach, S. J. (1985). The origins of individual media -system dependency: a sociol ogical \nframework. Communication Research, 12, 485 -510.  \nBall-Rokeach, S. J. and DeFleur, M. L. (1976). A dependency model of mass -media effects.  \nCommunication Research, 3, 3 -21.  \nBeckmann, K., Dewenter, R. and Thomas, T. (2017). Can news draw blood? The im pact of media \ncoverage on the number and severity of terror attacks. Peace Economics, Peace Science and \nPublic Policy, 23, 1 -16.  \nBenesch, C., Loretz, S., Stadelmann, D. and Thomas, T. (2019). Media Coverage and Immigration \nWorries: Econometric Evidence. J ournal of Economic Behavior and Organization, 160, 52 -67.  \nBerlemann, M. and Thomas , T. (2019), The Distance Bias in Natural Disaster Reporting \u2013 Empirical \nEvidence for the U nited States. Applied Economics Letters , 16, 1026 -1032.   \nBernhardt, D., Krasa, S. and Polborn, M. (2008). Political polarization and the electoral effects of \nmedia bias. Journal of Public Economics, 92, 1092 -1104.  \nBesley, T. and Prat, A. (2006). Handcuffs  for the grabbing hand? Media capture and government \naccountability. American Economic Review, 96, 720 -736.  \nChadi, A. (2015), Concerns about the Euro and happiness in Germany during times of crisis, \nEuropean Journal of Political Economy, 40, 126 -146.  \nChian g, C. and Knight, B. (2011). Media Bias and Influence: Evidence from Newspaper \nEndorsements. Review of Economic Studies, 78, 795 -820.  \nD\u2018Alessio, D. D.  and Allen, M. (2000). Media bias in presidential elections: a meta -analysis. Journal \nof Communication, 50 , 133 -156.  \nDellaVigna, S. and Kaplan, E. (2007). The Fox News Effect: Media Bias and Voting. The Quarterly \nJournal of Economics, 122, 1187 -1234.  \n29 Dewenter, R., Dulleck, U. & Thomas, T. ( 2020). Does the 4th estate deliver? The Political Coverage \nIndex and i ts application to media capture, Constitutional Political Economy, 31, 292 -328 . \nDewenter, R. and Heimeshoff, U. (2014). Media Bias and advertising: Evidence from a German car \nmagazine. Review of Economics, 65, 77 -94. \nDewente r, R. and Heimeshoff, U. (2015). More Ads, More Revs? A Note on Media Bias in Review \nLikelihood. Economic Modelling 44,  156 -161.  \nDewenter, R., Heimeshoff,  U. and Thomas , T. (2016). Media Coverage and Car Manufacturers\u2019 \nSales. Economics Bulletin, 36, 976 -982.  \nDewenter, R., Linder, M.  and Thomas, T. (2019 ). Can Media Drive the Electorate? Impact of Media \nCoverage on Voting Intentions. European Journal of Political Economy, 58, 245 -261 . \nDoms, M. and N. Morin (2004). Consumer sentiment, the economy, and the n ews media. Finance \nand Economics Discussion Series 2004 -51, Board of Governors of the Federal Reserve System.  \nDunham, W.R. (2013). Framing the Right Suspects: Measuring Media Bias. Journal of Media \nEconomics, 26, 122 -147.  \nDruckman J. N. and Parkin M. (2005 ). The Impact of Media Bias: How Editorial Slant Affects Voters. \nJournal of Politics, 67, 1030 -1049.  \nDurante, R. and Zhuravskaya, E. (2018). Attack when the world is not watching? International \nmedia and the Israeli -Palestinian conflict. Journal of Politi cal Economy, 126, 1085 \u20131133.  \nEisensee, T. and Str\u00f6mberg , D. (2007). News Droughts, News Floods, and U. S. Disaster Relief. The \nQuarterly Journal of Economics, 122, 693 -728.  \nEnikolopov, R., Petrova, M. and Zhuravskaya, E. (2011). Media and Political Persuasion: Evidence \nfrom Russia. American Economic Review, 101, 3253 -3285.  \nEntman R. M. (2007). Framing Bias: Media in the Distribution of Power. Journ al of Communication, \n57, 163 -173.  \nFriebel, G. and Heinz, M. (2014). Media slant against foreign owners: Downsizing. Journal of Public \nEconomics, 120, 97 -106.  \nGambaro, M. and Puglisi, R. (2015). What do ads buy? Daily coverage of listed companies on the \nItalian press. European Journal of Political Economy, 39, 41 -57. \nGarz, M. (2012). Job Insecurity Perceptions and Media Coverage of Labor Market Policy. Journal \nof Labor Research, 33, 528 -544.  \nGarz, M. (2013). Unemployment Expectations, Excessive Pessimism, an d News Coverage. Journal \nof Economic Psychology, 34, 156 -168.  \nGarz, M. (2014). Good news and bad news: evidence of media bias in unemployment reports. \nPublic Choice, 161, 499 -515.  \nGarz, M., Stone, D. and S\u00f6rensen, J. (20 20). Partisan Selective Engagement: Evidence from \nFacebook .   Journal of Economic Behavior & Organization, 177, 91 -108.  \nGentzkow, M. and Shapiro, J. M. (2010). What drives media slant? Evidence from U.S. daily \nnewspapers. Econometrica, 78, 35 -71. \nGentzkow, M., A., Shapiro, J.M. and Sinkinso n, M. (2011). The Effect of Newspaper Entry and Exit \non Electoral Politics. American Economic Review, 101, 2980 -3018.  \nGentzkow, M., Petek,  N., Shapiro,  J.M. and  Sinkinson , M. (2015). Do Newspapers Serve the State? \nIncumbent Party Influence on the US Press, 1869 -1928 . Journal of the European Economic \nAssociation, 13, 29 -61.  \nGoidel, R. K. and Langley, R. E. (1995). Media coverage of the economy and aggregate economic \nevaluations. Political Research Quarterly, 48, 313 -328.  \nGreenstein, S. and Zhu, F. (2012). Is Wikipedia biased? American Economic Review: Papers and \nProceedings, 120, 343 -348.  \n30 Grimm er, J. and Steward , B. M. (2013). Text as Data: The Promise and Pitfalls of Automatic Content, \nAnalysis Methods for Political Texts. Political Analysis, 21, 267 -297.  \nGroseclose, T. and Milyo, J. (2005). A measure of media bias. Quarterly Journal of Economi cs, 120, \n1191 \u20131237.  \nHeinz, M. and Swinnen, J. (2015). Media slant in economic news: A factor 20. Economics Letters, \n132, 18 \u201320. \nJetter, M. (2017 ). The effect of media attention on terrorism. J ournal of Public Econ omics,  153, 32-\n48.  \nLamla, M. J. and Maag , T. (2012). The Role of Media for Inflation Forecast Disagreement of  \nHouseholds and Professional Forecasters. Journal of Money, Credit and Banking, 7, 1325 -1350.  \nLarcinese, V., Puglisi, R. and Snyder Jr., J. M. (2011). Partisan Bias in Economic News: Eviden ce on \nthe Agenda -Setting Behavior of U.S. Newspapers. Journal of Public Economics, 95, 1178 -1189.  \nMorris, J.S. (2007). Slanted Objectivity? Perceived Media Bias, Cable News Exposure, and Political \nAttitudes. Social Science Quarterly, 88, 707 \u2013728.  \nNacos, B.  L., Shapiro, R. Y., Young, J. T.,  Fan, D. P., Kjellstrand, T. and McCaa, C. (1991). Content \nAnalysis of News Reports: Comparing Human Coding and a Computer -Assisted Method. \nCommunication, 12, 111 -128.  \nNadeau, R., Niemi , R. G. and Amato , T. (2000). Elite economic forecasts, economic news, mass \neconomic expectations, and voting intentions in Great Britain. European Journal of Political \nResearch, 38, 135 -170.  \nNelson, L. K., Burk, D., Knudsen, M., & McCall, L. (forthcoming). The future of coding: A  comparison  \nof hand -coding and three types of computer -assisted text analysis methods.  Sociological \nMethods & Research.  \nPage, B. I., Shapiro, R. Y. and Dempsey, G. R. (1987), What Moves Public Opinion? American \nPolitical Science Review, 81, 23 -43. \nPrat, A. (2018). Me dia power. Journal of Political Economy, 126, 1747 \u20131783.  \nPuglisi, R. (2011). Being The New York Times: The Political Behavior of a Newspaper. B.E. Journal \nof Economic Analysis & Policy, 11, 1 -32. \nPuglisi, R. and Snyder, J. M. (2015 a). Empirical Studies of Media Bias, Handbook of Media \nEconomics, Vol 1b, 647 -667.   \nPuglisi, R. and Snyder, J. M. (2015 b). The Balanced US Press, Journal of the European Economic \nAssociation, 13, 240 -264.  \nQin, B., Str\u00f6mberg, D. and Wu, Y. (2018). Media Bias in China. American Eco nomic Review, 108, \n2442 -76.  \nReuter, J. and Zitzewitz, E. (2006). Do ads influence editors? Advertising and bias in the financial \nmedia, Quarterly Journal of Economics, 121, 197 \u2013227.  \nSnyder Jr., J.M. and D. Str\u00f6mberg (2010). Press Coverage and Political Ac countability. Journal of \nPolitical Economy, 118,  355 -408.  \nSoroka, S. N. (2006). Good news and bad news: Asymmetric responses to economic information. \nThe Journal of Politics, 68, 372 \u2013385.  \nUlbricht, D., Kholodilin, K. and Thomas , T. (2017), Do media data help to predict German industrial \nproduction? Journal of Forecasting , 36, 483 -496.  \nvan Raaij, W. F. (1989). Economic news, expectations and macro -economic behavior. Journal of \nEconomic Psyc hology, 10, 473 \u2013493.  \n \n \n31 Appendix : Figures  \nFigure A1: PCI comparison, aggregated for each medium  \n \n \nFigure A2: Residuals compared  \n \n  \n\n32 Figure  A3: Residuals over time with (presidential and midterm) election periods  \n \n \nFigure  A4: Election campaign period  \n \n \n\n33 Appendix: Tables  \nTable  A1: Link/Impact of the party affiliation of the president on the political positioning of the Big Four  \n(Full Sample , election period: 3/1 months before/after an election)  \nDependent  \nvariable:  OLS I  OLS II  OLS III  FE I  FE II  FE III  \nPCI       \nSample  Full sample  Presidential  \nelections  \nperiods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  Full sample  Presidential  \nelections  \n Periods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  \n       \nDemocrat  0.157***  0.193***  0.214***  0.175***  0.211***  0.235***  \n (0.0459)  \n (0.0532)  (0.0540)  (0.0446)  (0.0511)  (0.0514)  \nConsumer Price  -0.00364**  -0.00326*  -0.00261  -0.00546***  -0.00478**  -0.00423**  \nIndex (CPI)  (0.00184)  \n (0.00195)  (0.00196)  (0.00183)  (0.00198)  (0.00199)  \nUnemployment  -0.00914  -0.0168  -0.0285**  -0.0111  -0.0199*  -0.0318***  \n (0.00927)  \n (0.0108)  (0.0112)  (0.00894)  (0.0102)  (0.0106)  \nBusiness  -0.0144**  -0.0168**  -0.0193***  -0.0149**  -0.0164**  -0.0188***  \n (0.00668)  \n (0.00743)  (0.00738)  (0.00633)  (0.00692)  (0.00697)  \nGPR  0.000455***  0.000483***  0.000444***  0.000505***  0.000528***  0.000510***  \n (0.000157)  \n (0.000159)  (0.000168)  (0.000154)  (0.000155)  (0.000167)  \nConstant  1.728**  1.972**  2.233***  1.918**  2.061***  2.327***  \n (0.781)  (0.839)  (0.838)  (0.745)  (0.787 ) (0.796)  \n       \nObservations  523  463  409  523  463  409  \nR-squared  0.108  0.122  0.116  0.228  0.236  0.230  \nMonth FE  No No No Yes Yes Yes \nMedia FE  No No No Yes Yes Yes \n       \nRobust and clustered standard errors in parentheses , *** p<0.01, ** p<0.05, * p<0. 1 \n \n \n \n \n \n \n \n \n \n \n34 Table A2: Regression Output: Weighted PCI  \n(Full Sample , election period: 4 /1 months before/after an election)  \nDependent \nvariable:  (1) (2) (3) (4) (5) (6) \nPCI OLS I  OLS II  OLS III  FE I  FE II  FE III  \n Full sample  Presidential  \nelections  \nperiods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  Full sample  Presidential  \nelections  \n Periods  \nexcluded  Presidential & \nmidterm  \nelections  \nperiods \nexcluded  \n       \nDemocrat  9.39e -07***  1.10e -06***  1.24e -06***  1.06e -06***  1.22e -06***  1.37e -06*** \n (2.97e -07) \n (3.43e -07) (3.45e -07) (2.95e-07) (3.40e -07) (3.40e -07) \nConsumer Price  -2.54e -08**  -2.23e -08* -1.76e -08 -3.35e -08***  -2.81e -08**  -2.43e -08* \nIndex (CPI)  (1.24e -08) \n (1.31e -08) (1.31e -08) (1.24e -08) (1.33e -08) (1.33e -08) \nUnemployment  -6.51e-08 -1.01e -07 -1.79e -07**  -8.16e -08 -1.25e -07* -2.03e -07***  \n (5.93e -08) \n (6.94e -08) (7.11e -08) (5.91e -08) (6.88e -08) (7.05e -08) \nBusiness  -1.08e -07**  -1.24e -07**  -1.40e -07***  -1.08e -07**  -1.22e -07**  -1.37e -07***  \n (4.50e -08) \n (5.04e -08) (4.98e -08) (4.32 e-08) (4.78e -08) (4.79e -08) \nGPR  3.37e -09***  3.52e -09***  3.20e -09***  3.62e -09***  3.73e -09***  3.55e -09***  \n (1.11e -09) \n (1.12e -09) (1.18e -09) (1.10e -09) (1.10e -09) (1.19e -09) \nConstant  1.27e -05**  1.42e -05**  1.59e -05***  1.34e -05***  1.46e -05***  1.63e -05***  \n (5.26e -06) (5.68e -06) (5.66e -06) (5.05e -06) (5.38e -06) (5.43e -06) \n       \nObservations  523  463  409  523  463  409  \nR-squared  0.103  0.112  0.109  0.169  0.184  0.175  \nMonth FE  No No No Yes Yes Yes \nMedia FE  No No No Yes Yes Yes \nRobust and clustered standard erro rs in parentheses , *** p<0.01, ** p<0.05, * p<0.1  \n \n \n \n \n \n \n \n \n \nPREVIOUS DISCUSSION PAPER S \n \n348 Bernhardt, Lea, Dewenter, Ralf and Thomas, Tobias, Watchdog or Loyal Servant? \nPolitical Media Bias in US Newscasts, A ugust 2020.  \n347 Stiebale, Joel, Suedekum, Jens and Woessner, Nicole, Robots and the Rise of \nEuropean Superstar Firms, July 2020.  \n346 Horst, Maximilian, Neyer, Ulrike and  Stempel, Daniel, Asymmetric Macroeconomic \nEffects of QE -Induced Increases in Excess Reserves in a Monetary Union, July 2020.  \n345 Riener, Gerhard, Schneider, Sebastian O. and Wagner, Valentin, Addressing Validity \nand Generalizability Concerns in Field Experiments, July 2020.  \n344 Fischer, Kai  and Haucap, Justus, Does Crowd Support Drive the Home Advantage in \nProfessional Soccer? Evidence from German Ghost Games during the COVID -19 \nPandemic , July 2020.  \n343 G\u00f6sser, Niklas and Moshgbar, Nima, Smoothing Time Fixed Effects, July 2020.  \n342 Breitkopf, Laura, Chowdhury, Shyamal, Priyam, Shambhavi, Schildberg- H\u00f6risch, \nHannah and Sutter, Matthias, Do Economic Preferences of Children Predict \nBehavior?, June 2020.  \n341 Westphal, Matthias, Kamh\u00f6fer, Daniel A. and Schmitz , Hendrik, Marginal College \nWage Premiums under Selection into Employment, June 2020.  \n340 Gibbon, Alexandra J. and Schain, Jan Philip, Rising Markups, Common Ownership, \nand Technological Capacities, June 2020.  \n339 Falk, Armin, Kosse, Fabian, Schildberg -H\u00f6risch, Hannah and Zimmermann, Florian, \nSelf-Assessment: The Role of the Social Environment , May 2020.  \n338 Schildberg -H\u00f6risch, Hannah, Trieu, Chi and Willrodt, Jana, Perceived Fairness and \nConsequences of Affirmative Action Policies, April 2020.  \n337  Avdic,  Daniel, de New, Sonja C. and Kamh\u00f6fer, Daniel A.,  Economic Downturns and \nMental W ellbeing, April 2020.  \n336 Dertwinkel -Kalt, Markus and Wey, Christian, Third- Degree Price Discrimination in \nOligopoly When Markets Are Covered, April 2020.  \n335 Dertwinkel -Kalt, Markus and K\u00f6ster, Mats, Attention to Online Sales: The Role of \nBrand Image Concerns, April 2020.  \n334 Fourberg, Niklas and Korff, Alex , Fiber vs. Vectoring: Limiting Technology Choices in \nBroadband Expansion, April 2020.        \n Published in: Telecommunications Policy, 44 (2020), 102002.  \n333 Dertwinkel -Kalt, Markus, K\u00f6ster, Mats and Sutter, Matthias, To Buy or Not to Buy? \nPrice Salience in an Online Shopping Field Experiment, April 2020.  \n332 Fischer, Christian, Optimal Payment Contracts in Trade Relationships,            \nFebruary 2020.  \n331 Becker, Raphael N. and Henkel, Marcel, The Role of Key Regions in Spatial \nDevelopment, February 2020.  \n330 R\u00f6sner, Anja, Haucap, Justus and Heimeshoff, Ulrich, The Impact of Consumer \nProtection in the Digital A ge: Evidence from the European Union, January 2020. \nForthcoming in: International Journal of Industrial Organization.  \n329 Dertwinkel -Kalt, Markus and Wey, Christian, Multi -Product Bargaining, Bundling, and \nBuyer Power, December 2019.                                                                                  \nPublished  in: Economics Letters , 188 (2020), 108936.   \n328 Aghe lmaleki, Hedieh, Bachmann, Ronald and Stiebale, Joel, The China Shock, \nEmployment Protection, and European Jobs, December 2019.  \n327 Link, Thomas, Optimal Timing of Calling In Large- Denomination Banknotes under \nNatural Rate Uncertainty, November 2019.  \n326 Heiss, Florian, Hetzenecker, Stephan and Osterhaus, Maximilian, Nonparametric \nEstimation of the Random Coefficient s Model: An Elastic Net Approach,       \nSeptember 2019.  \n325 Horst , Maximilian and Neyer, Ulrike, The Impact of Quantitative Easing on Bank Loan \nSupply and Monetary Policy Implementation in the Euro Area, September 2019.  \nPublished in: Review of Economics, 70 (2019), pp. 229- 265. \n324 Neyer, Ulrike and Stempel, Daniel, Macroeconomic Effects of Gender Discrimination, \nSeptember 2019.  \n323 Stiebale, Joel and Sz\u00fccs, Florian, Mergers and Market Power: Evidence from Rivals\u2019 \nResponses in European Markets, September 2019.  \n322 Henkel, Marcel, Seidel, Tobias and Suedekum, Jens, Fiscal Transfers in the Spatial \nEconomy, September 2019.  \n321 Korff, Alex and Steffen, Nico, Economic Preferences and Trade Outcomes,                \nAugust 2019.  \n320 Kohler , Wilhelm and Wrona, Jens, Trade in Tasks: Revisiting the Wage and \nEmployment Effects of Offshoring, July 2019.  \n319 Cobb- Clark, Deborah A., Dahmann, Sarah C., Kamh\u00f6fer, Daniel A. and Schildberg -\nH\u00f6risch, Hannah, Self -Control:  Determinants,  Life Outcomes and Intergenerational \nImplications, July 2019.  \n318 Jeitschko, Thomas D., Withers, John A., Dynamic Regulation Revisited: Signal \nDampening,  Experimentation and the Ratchet  Effect, July 2019 . \n317 Jeitschko, Thomas D., Kim, Soo Jin and Yankelevich, Aleksandr, Zer o-Rating and \nVertical Content Foreclosure, July 2019.  \n316 Kamh\u00f6fer, Daniel A. und Westphal, Matthias , Fertility Effects of College Education: \nEvidence from the German Educational Expansion, July 2019.  \n315 Bodnar, Olivia, Fremerey, Melinda, Normann, Hans -Theo and Schad, Jannika, The \nEffects of Private Damage Claims on Cartel Stability: Experimental Evidence,         \nJune 2019.  \n314 Baumann, Florian and Rasch, Alexander, Injunctions Against False Advertisi ng,   \nOctober 2019 (First Version June 2019).                                                                                                                                        \nForthcoming in: Canadian Journal of Economics.   \n \n313 Hunold, Matthias and Muthers, Johannes, Spatial Competition and Price \nDiscrimination with Capacity Constraints, May 2019 (First Version June 2017 under \nthe title \u201cCapacity Constraints, Price Discrimination, Inefficient Competition and \nSubcontracting\u201d).              \nPublished in: International Journal of Industrial Organization,  67 (2019), 102524.                                                                                                     \n312 Creane, Anthony , Jeitschko, Thomas D. and Sim, Kyoungbo, Welfare Effec ts of \nCertification under Latent Adverse Selection, March 2019.  \n311 Bataille, Marc, Bodnar, Olivia, Alexander Steinmetz and Thorwarth, Susanne,    \nScreening Instruments for Monitoring Market Power \u2013  The Return on Withholding \nCapacity Index (RWC), March 2019.                                                                     \nPublished in: Energy Economics, 81 (2019), pp. 227- 237.                                                                                                            \n310 Dertwinkel -Kalt, Markus and K\u00f6ster, Mats, Salience and Skewness Preferences, \nMarch  2019.                                                                                                                  \nForthcoming in: Journal of the European Economic Association.  \n309 Hunold, Matthias and Schl\u00fctter, Frank, Vertical Financial Interest and Corporate \nInfluence, February 2019.  \n308 Sabatino, Lorien and Sapi, Geza, Online Privacy and Market Structure: Theory and \nEvidence, February 2019.  \n307 Izhak, Olena, Extra Costs of Integrity: Pharmacy Markups and Generic Substitution in \nFinland, January 2019.  \n306 Herr, Annika and Normann, Hans -Theo, How Much Priority Bonus Should be Given to \nRegistered Organ Donors? An Experimental Analysis, December 2018.                    \nPublished in: Journal of Economic Behavior and Organization, 158 (2019), pp.367- 378. \n305 Egger, Hartmut and Fischer, Christian, Increasing Resistance to Globalization: The \nRole of Trade in Tasks, December 2018.                                                            \nPublished  in: European Economic Review , 126 (2020), 103446.  \n304 Dertwinkel -Kalt, Markus, K\u00f6ster, Mats and Peiseler, Florian, Attention- Driven Demand \nfor Bonus Contracts, October 2018 .                                                                          \nPublished in: European Economic Review , 115 (2019), pp.1- 24. \n303 Bachmann, Ronald and Bechara, Peggy, The Importance of Two- Sided \nHeterogeneity for the Cyclicality of Labour Market Dynamics, October 2018.  \nForthcoming in: The Manchester School.  \n302 Hunold, Matthias, H\u00fcschelrath, Kai, Laitenberger, Ulrich and Muthers, J ohannes, \nCompetition, Collusion and Spatial Sales Patterns \u2013  Theory and Evidence,     \nSeptember 2018.                                                                                           \nForthcoming in: Journal of Industrial Economics.  \n301 Neyer, Ulrik e and Sterzel, Andr\u00e9, Preferential Treatment of Government Bonds in \nLiquidity Regulation \u2013  Implications for Bank Behaviour and Financial Stability, \nSeptember 2018.  \n300 Hunold, Matthias, Kesler, Reinhold and Laitenberger, Ulrich, Hotel Rankings of Online \nTravel Agents, Channel Pricing and Consumer Protection, September 2018                      \n(First Version February 2017 ).                                                                                              \nForthcoming in: Marketing Science.  \n299 Odenkirchen, Johannes, Pricing Behavior in Partial Cartels, September 2018.  \n298 Mori, Tomoya and Wrona, Jens, Inter -city Trade, September 2018.  \n297 Rasch, Alexander, Th\u00f6ne, Miriam and Wenzel, Tobias, Drip Pricing and its \nRegulation: Experimental Evidence, A ugust 2018.      \n Forthcoming in: Journal of Economic Behavior and Organization.    \n296 Fourberg, Niklas, Let\u2019s Lock Them in: Collusion under Consumer Switching Costs, \nAugust 2018.  \n295 Peiseler, Florian, Rasch, Alexander and Shekhar, Shiva, Private Information, Price \nDiscrimination, and Collusion, August 2018.  \n294 Altmann, Steffen, Falk, Armin, Heidhues, Paul, Jayaraman, Rajshri and Teirlinck, \nMarrit, Defaults and Donations: Evidence from a Field Experiment, July 2018.              \nPublished in: Revie w of Economics and Statistics, 101 (2019), pp. 808- 826. \n293 Stiebale, Joel and Vencappa, Dev, Import Competition and Vertical Integration: \nEvidence from India, July 2018.  \n292 Bachmann, Ronald, Cim, Merve and Green, Colin, Long- run Patterns of Labour \nMarket  Polarisation: Evidence from German Micro Data, May 2018.                     \nPublished in: British Journal of Industrial Relations, 57 (2019), pp. 350- 376. \n291 Chen, Si and Schildberg- H\u00f6risch, Hannah, Looking at the Bright Side: The Motivation \nValue of Overconfidence, May 2018.                                                                                 \nForthcoming in: European Economic Review.  \n290 Knauth, Florian and Wrona, Jens, There and Back Again: A Simple Theory of \nPlanned Return Migration, May 2018.  \n289 Fonseca, Miguel A., Li, Yan and Normann, Hans -Theo, Why Factors Facilitating \nCollusion May Not Predict Cartel Occurrence \u2013  Experimental Evidence, May 2018. \nPublished in: Southern Economic Journal, 85 (2018), pp. 255- 275. \n288 Benesch, Christine, Loretz, Simon, Stadelmann, David and Thomas, Tobias, Media \nCoverage and Immigration Worries: Econometric Evidence, April 2018.                 \nPublished in: Journal of E conomic Behavior & Organization, 160 (2019), pp. 52- 67. \n287 Dewenter, Ralf, Linder, Meli ssa and Thomas, Tobias, Can Media Drive the \nElectorate?  The Impact of Media Coverage on Party Affiliation and Voting Intentions, \nApril 2018.                                                                                                                \nPublished in: European Journal of Political Economy, 58 (2019), pp. 245- 261. \n286 Jeitschko, Thomas D., Kim, Soo Jin and Yankelevich, Aleksandr, A Cautionary Note \non Using Hotelling Models in Platform Markets, April 2018.  \n285 Baye, Irina, Reiz, Tim and Sapi , Geza, Customer Recognition and Mobile Geo-\nTargeting, March 2018.  \n284 Schaefer, Maximilian, Sapi, Geza and Lorincz, Szabolc s, The Effect of Big Data on \nRecommendation Quality. The Example of Internet Search, March 2018.  \n283 Fischer, Christian and Normann,  Hans -Theo, Collusion and Bargaining in Asymmetric \nCournot Duopoly \u2013 An Experiment, October 2018 (First Version March 2018) . \nPublished  in: European Economic Review , 111 (2019), pp.360- 379. \n282 Friese, Maria, Heimeshoff, Ulrich and Klein, Gordon, Property Rights and Transaction \nCosts \u2013 The Role of Ownership and Organization in German Public Service Provision, \nFebruary 2018.                                                                                                                   \nPublished in: Internat ional Journal of Industrial Organization, 72 (2020), 102637.  \n281 Hunold, Matthias and Shekhar, Shiva, Supply Chain Innovations and Partial \nOwnership, February 2018.  \n280 Rickert, Dennis, Schain, Jan Philip and Stiebale, Joel, Local Market Structure and \nCons umer Prices: Evidence from a Retail Merger, January 2018.  \n \nOlder discussion papers can be found online at:  \nhttp://ideas.repec.org/s/zbw/dicedp.html  \n \n www.dice.hhu.de   \nHeinrich -Heine -Universit\u00e4t D\u00fcsseldorf  \n \nD\u00fcsseldorfer Institut f\u00fcr  \nWettbewerbs\u00f6konomie (DICE)  \n \nUniversit\u00e4tsstra\u00dfe 1, 40225 D\u00fcsseldorf  \nISSN 2190 -992X (online)  \nISBN 978 -3-86304 -347-6 ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Watchdog or loyal servant? Political media bias in US newscasts", "author": ["L Bernhardt", "R Dewenter", "T Thomas"], "pub_year": "2020", "venue": "NA", "abstract": "We investigate if four leading, electronic news gathering organizations in the US - ABC  News, CBS News, FOX News, and NBC News - fulfill their role as the fourth estate in the US"}, "filled": false, "gsrank": 239, "pub_url": "https://www.econstor.eu/handle/10419/222963", "author_id": ["ZA5l3D8AAAAJ", "", "BxXfbRIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Y4zAV86QtzMJ:scholar.google.com/&output=cite&scirp=238&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D230%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Y4zAV86QtzMJ&ei=LrWsaJ_HDrTWieoP1pCJ2AY&json=", "num_citations": 2, "citedby_url": "/scholar?cites=3726606432582274147&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Y4zAV86QtzMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.econstor.eu/bitstream/10419/222963/1/1727148142.pdf"}}, {"title": "Towards an understanding of conspiracy echo chambers on Facebook", "year": "2019", "pdf_data": "Association fo r Info rmation Systems\nAIS Ele ctronic L ibrary (AISeL )\nResearch-in-P rogress Papers ECIS 2019 P roceedings\n5-15-2019\nTOW ARDS AN UNDER STANDIN G OF\nCON SPIRA CY ECHO C HAMBER S ON\nFACEBOOK\nMarten Risius\nQueensland University, risius@g. clemson.edu\nOkan Aydinguel\nUniversity of M annheim, aydinguel@uni -mannheim .de\nMaximilian H aug\nNeu-U lm U niversity of App lied Scien ces, maximilian.haug@h s-neu-ulm .de\nFollow thi s and a dditional w orks at:https://ai sel.aisnet.org/ecis2019_r ip\nThis material is brought to you b y the E CIS 2019 P roceedings at AIS Ele ctronic L ibrary (AISeL). It has be en accepted for inclusion in R esearch-in-\nProgress Papers by an author ized admini strator of A IS Ele ctronic L ibrary (AISeL). For mor e infor mation, p lease contactelibrary@ai snet.org.Recomme nded Citation\nRisius, M arten; Aydinguel, Ok an; and H aug, Maximilian, (2019). \" TOWARDS AN UNDER STANDI NG OF C ON SPIRACY ECHO\nCHAMBER S ON F ACEBOOK\". In Proceedings of the 27th E uropean Confe rence on I nfor mation S ystems (ECIS), Stockholm &\nUppsala, Sweden, June 8-14, 2019. IS BN 978-1-7336325-0-8 R esearch-in-P rogress Papers.\nhttps://ai sel.aisnet.org/ecis2019_r ip/36\nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  1 \n \n TOWARDS AN UNDERSTAN DING OF  \nCONSPIRACY  ECHO CHAMBERS  ON FACEBOOK  \nResearch in Progress    \n \nRisius, Marten , Queensland Un iversity , Brisbane , Australia , m.risius@business.uq.edu.au  \nAyding\u00fcl, Okan , University  of Mannheim , Mannheim , Germany , aydinguel@uni -\nmannheim.de  \nHaug, Maximilian , Neu-Ulm University o f Applied Sciences , Neu -Ulm, Germany , \nMaximilian.Haug@hs -neu-ulm.de  \n \nAbstract  \nSelective  online exposure to information that serves to only affirm  people\u2019s opinions or is strongly \naligned with their interests is considered to be a major issue in modern societies. Echo chambers , for \nexample,  are online environments  in which users are only exposed to confirming opinions and \nalternative voices are excl uded  or discredited . Echo chambers are considered to be particularly \ndangerous , because they may lead to polarization and even radicalization . Social media facilitate the \nformation of echo chambers as described in the Social Identity Theory by means of homophily and \ndepersonalization . This can be especially harmful in the case of conspiracy beliefs , where particularly \nextreme opinions lead to a stronger seclusion from society, encourage socially destructive actions , \nand curate Fake News.  In our research we will assess different echo chambers in terms of actively \nestablished common patterns of consumed online information sources. To that end, we  analys e the \nnews source Likes from over 7,000 users with their approximately 1,450,000 Likes on Facebook. We \nintend to identify different types of Facebook echo chambers with a focus on conspiracy groups , \nunderstand distinguishing characteristics in communicative behaviour of the conspiracy groups on \nFacebook  and explore  unique characteristics of use rs in conspiracy echo chambers.  \n \nKeywords: Facebook , Echo Chambers , Conspiracy Theori es, Social Identity Theory, News, Media \nConsumption, Polarization  \n \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  2 \n \n 1 Introduction  \nIn 2011 Eli Pariser, co -founder of the viral content site \u201cUpworthy \u201d, wrote a seminal book that pointed \ntowards the danger of selective online information exposure  (Pariser 2011 ). Five years later, following \nthe US presidential election, respective effects in form of social media filter bubbles gained substantial \npublic interest. They were in part associated with the unexpected persuasiveness of arguments  to \ncertain demographic groups and the inaccurate prediction of the election results (Baer 2016 ).  \nEcho chambers  are environments in which users are exposed to conforming opinions, other voices are \nactively excluded or discredited, conflicting information may actually serve to reinforce the opinions \n(Nguyen 2018 ; Spohr 2017 ) to create enclaves of like -minded people that can lead to increased \npolarization (Dandekar et al. 2013 ). Particularly  conspiracy sources  publish unverifiable information \nwith an extreme bias that is not always supported by evidence (Media Bias/Fact Check 2018a ), which \nmay threaten  society and democracy when curat ing the belief in \u201cfake news\u201d (Sunstein 2018 ).  \nOnline social  networks have been found to play a strong role on this radicalization,  for example, after \n9/11 (Hamm and Spaaij 2015 ). The emergence of online echo chambers is theoretically grounded in \nhomophily and depersonalization as outlined by social identity theory (Bakshy et al. 2015 ; Boutyline \nand Willer 2017 ; Dandekar et al. 2013 ; Jasny et al. 2015 ; Nikolov et al. 2015 ; Shalizi and Thomas \n2011 ; Sunstein 2018 ). Homophily means the principle that similarity builds connections and structures \nnetwork ties of every type (e .g., marriage, friendship, work, advice, support, information transfer) \n(McPherson et al. 2001 ). Depersonalization describes the process of deriving the own identity from the \ngroup norms instead of  personal experiences (Carter 2015 ; Stets and Burke 2000 ). \nDespite  the considerable threats that are associated with echo chambers , research is currently limited \nto the emergence of echo chambers (Baumgaertner 2014 ; Flaxman et al. 2016 ; Nikolov et al. 2015 ; \nVaccari et al. 2016 ) and the respective role of individual choice as opposed to platform\u2019s \nrecommender algorithms (Bakshy et al. 2015 ; O'Hara and Stevens 2015 ), psychological mo tivations of \nforming a n echo chamber (Boutyline and Willer 2017 ), communication patterns within and across \necho chambers (Gr\u00f6mping 2014 ; Liao and Fu 2014 ; Williams et al. 2015 ), predicting partisanship \nthrough echo chambers (Colleoni et al. 2014 ), and consequences of echo chambers on climate policy \ndiscussions (Jasny et al. 2015 ). Research has not yet conclusively attempted identifying different kinds \nof echo chambers let alone conspiracy chambers (O'Hara and Stevens 2015 ). In order to overcome the \nappare nt knowledge gap we investigate what social media echo chambers exist as well as  whether and \nhow conspiracy echo -chambers can be distinguished ? \nWe approach this research question by analysing the patterns of media consumption of over 7,000 \nusers on Facebook. Thereby, we will provide three considerable contributions. First, we will identify \ndifferent types of Facebook echo chambers . Currently, rela ted research has adopted the oversimplified \nperspective of the two party system (i.e. democrat or republican) (Bakshy et al. 2015 ; Boutyline and \nWiller 2017 ; Colleoni et al. 2014 ). Due to their unique relevance, we focus particularly on the effects \nof conspiracy sites. Second, we will understand distinguishing characteristics in communicati ve \nbehaviour of the conspiracy groups  on Facebook . This is important since previous findings relied on \nsurvey (Jasny et al. 2015 ; Vaccari et al. 2016 ), web browsing (Flaxman et al. 2016 ; Nikolov et al. \n2015 ) or experimental data (Liao and Fu 2014 ), and only applied to very specific Facebook groups \n(Gr\u00f6mping 2014 ) or Twitter hashtag topics (Williams et al. 2015 ). Third, we assess unique \ncharacteristics of users in conspiracy echo chambers.  Since echo chambers have been found to rather \nresult from individual decisions on which kind of content to consume than from the platforms\u2019 \nrecommender algorithms (Bakshy et al. 2015 ; Flaxman et al. 2016 ), this will help identify risk factors \nand build an understanding of who is particularly susceptible to conspiracy news . \n \n \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  3 \n \n 2 Theoretical Background  \nWe draw on social identity theory, which has been researched extensively across various scholars \n(Stryker and Burke 2000 ). Social identity on a collective level focuses on how identities rise from a \nmembership of social groups (Henri and Turner 1986 ). It is argued that individuals like to become \ngroup members of a certain group and start to behave in a way which is appropriate for the group. If \nthe group is relevant to them, they will suppress their individuality and focus on their social identity \nwithin the group. This process is also known as depersonalization (Carter 2015 ; Stets and Burke \n2000 ). This phenomenon can also be seen in the  case of echo -chambers, in which individuals either try \nto fit into the social environment of the chambers, or the rules forbid every action which contradicts \nthe group\u2019s norm. Therefore, due to this conformity, ideas or ideologies are leveraged (Sunstein 2002 ), \nwhich explain the polarization in echo -chambers.  The initial  emergence of echo chambers is \ncommonly explained through ideological and political homophily and contagion (Colleoni et al. 2014 ). \nHomophily  describes the principle that similarity breeds connection and structures network ties. \nConsequently, people\u2019s personal networks become socio -demographically, behaviourally, and \ninterpersonally homogeneous. This limits people\u2019s social worlds with powerful impli cations for their \ninformation reception, attitude formation, and interaction experiences (McPherson et al. 2001 ). \nThere is va rious IS research which identified the existence of echo  chambers and how individuals e n-\ngage with information on social media. Shore et al. (2016 ) investigated how divers Twitter users seek \ninformation via their followers. They wanted to answer the question whether users are encapsulated in \necho -chambers and found that for the average account is linked more often to moderate news sources. \nHowever, t here is a tiny network core which shows evidence of polarization and due to their strong \nactivity and popularity this portion can explain the perception that social media incorporates wid e-\nspread echo -chambers.  Bessi (2016 ) targeted echo -chambers on Facebook and showed that users with \nsimilar psych ological profiles engage in pseudo -scientific echo -chambers. Furthermore, it is shown \nthat the participation in said echo -chambers in return has an effect on the psychological profile. It is \nargued that if users show low extraversion, high emotional stabil ity, low agreeableness, low conscie n-\ntiousness and high openness, there is a high likelihood that people will engage in pseudoscientific or \nconspiracy -like narrative. These profiles were extracted from their digital footprints, such as their la n-\nguage used o n social media.  \nBakshy et al. (2015 ) investigated how Facebook users may engage in cross -cutting content in the co n-\ntext of liberal, moderate and conservative co ntent. 10.1 million Facebook users were examined and \ntheir interaction with socially shared news. They found that conservatives have a 17% risk ratio on \nclicks on cross -cutting content, while liberals have a ratio of 6%. This is due to a higher amount of \nshared news from the conservative side. The authors argue that the consumption of cross -cutting co n-\ntent is highly dependent on the user\u2019s friends and the algorithm which sorts the news feed on Fac e-\nbook.  \nEcho chambers  in general  only provide limited  and ther efore insufficient  information to their \ncommunity basis . This leads to a selective exposure of the participating individual  (Messing and \nWestwood 2014 ). Echo chambers  in the c ontext of conspiracy theories  are especially dangerous \nbecause they lead to opinion polarization and even radicalization in a stronger degree  (Dandekar et al. \n2013 ). Radicalization can already occur by firmly  believing that  a position that is  within the political \nmainstream  is not just the best but that  any other choice would be catastrophic . Social media help with \nthis radicalization by encouraging group think, affecting the perceptions of identity and group \nmembership  (Sunstein 2018 ).  \nDue to the particular uniqueness of conspiracy theorists that are far away from common public \nopinions, we expect even stronger homophilic tendencies to occur. T his is especially  harmful since \nconspiracy beliefs are particularly extreme and lead to a stronger seclusion from society and encourage \nsocially destructive actions (e.g., terror attacks, political disengagement, and discriminatory \nbehaviour).  Due to the m entioned threats of conspiracy echo -chambers, we want to identify said echo -\nchambers with their specific characteristics, and investigate risk factors under which circumstances \nindividuals are prone to becom ing part of such communities . \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  4 \n \n 3 Method  \n3.1 Data Collect ion \nFirst, we collected a sample of Facebook user profiles. For this purpose, we began collecting profiles \nstarting from a random Facebook profile page with a public friend list, which was then copied into a \ndatabase. Afterwards, we copied the first public  friend lists of the profile with the lowest Facebook -\nissued account number. To avoid a sample bias by restricting profile collection to a particular \ndemographic class, we continuously repeated this process with the newly downloaded friend list and \nso fort h. Ultimately, we collected a list of 170,000 user profiles. In a second step, we collected the \nindividuals\u2019 Facebook likes. To avoid dispositional biases regarding selective information disclosure \n(e.g., only profiles that publicly disclose all informatio n \u2013 i.e. friends and likes), we checked all \nprofiles in our database for public like -items and profile information irrespective of whether or not \nthey had previously disclosed friend lists. We collected public likes from almost 7,000 individual users \nresul ting in a total of 1,450,000 likes and 280,576 unique items with averagely 207 items per profile \n(figure 1). The individual\u2019s data privacy was protected by omission of the user name and only using \nthe internal Facebook ID to match profile and like information. Thereby, personal identification based \non the publicly available informat ion is rendered highly unlikely .  \nTo further inform our data, we collected the political leanings (i.e., right, lean right, center, lean left, \nleft, pro science, conspiracy -pseudoscience, questionable, and satire) for 1,846 political sites from \nAllSides (AllSides 2018a ) and Media Bias -Fact Check (Media Bias/Fact Check 2018e ). \n \n \nFigure 1. Raw d ata sample excerpt  of user profile (left) and like item information (right) . \n \n3.2 Data Processing  \nFrom the over 280k like items, we initially select all potentially relevant items with regard to our r e-\nsearch objective. Thus, we selected 2,607 Like items from  any of 24 manually identified potential \nnews categories (e.g., News*, Politic*, Government*) . Subsequently, we conducted a soft match b e-\ntween the user-generated coding from AllSides and Media Bias -Fact Check with the media items in-\ncluded in the data sample. In total we were able to identify the political leaning for 2,136 unique items  \n(Table 1) .  \nWith regards to our research questi on, we wanted to further inform the types of conspiracy categories \n(Table 2). Thus, we selected all items from \u201cconspiracy -pseudoscience\u201d and \u201cquestionable\u201d, reviewed \nand discussed the different types of conspiracy sites among the authors, manually coded a ll distinct \nitems and discussed the few deviations until we found agreement (Krippendorff 2004 ; 2012 ). Due to \ntheir focus on conspiracy concepts, we decided to combine the two conspiracy -pseudoscience and \nquestionable categories into the general \u201cconspiracy\u201d category.  \n \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  5 \n \n  \n \nPolitical Leaning  Description  (Sources, e.g., in favour of)  Example s N (%)  \nLeft Government services, tax increases on the wealthy or \nkeeping abortion legal (AllSides 2018f ). VICE,  \nHuffPost  435 (20.37)  \nLean Left  Federal laws to protect consumers, the environment \nand equal rights (AllSides 2018d ). BBC , \n The Guardian  734 (34.36)  \nCenter  Does not systematically  show opinions favoring \neither end of the political spectrum  (AllSides 2018 b). Reuters,  \nFinancial Times  281 (13.16)  \nLean Right  Decreasing government involvement in economic \nissues, taxes, and federal regulation in general \n(AllSides 2018e ). The Telegraph,  \nNew York P ost 141 (6.6)  \nRight  Outlawing abortion, government should be as small \nas possible, traditional family values (AllSides \n2018c ). CBN,  \nFox News  250 (11.7)  \nPro Science  Legitimate science or are evidence based through the \nuse of credible scientific sourcing (Media Bias/Fact \nCheck 2018b ). CNET,  \nNational Geographic  183 (8.57)  \nConspiracy -\nPseudoscience  May publish unverifiable information that is not \nalways supported by evidence (Media Bias/Fact \nCheck 2018a ). InfoWars,  \nAnonymous,  38 (1.78)  \nQuestionable  Exhibits one or more of extreme bias, overt prop a-\nganda, poor or no sourcing and/or is fake news \n(Media Bias/Fact Check 2018c ). Qpolitical,  \nTruth Examiner  63 (2.95)  \nSatire  Exclusively use humor, irony, exaggeration, or rid i-\ncule to expose and criticize stupidity or vices (Media \nBias/Fact Check 2018d ). The Onion ,  \nNew Roman Times  11 (0.51)  \nNotes. Number of unique news sites = 2 ,607; number of coded news sites = 2,136 \nTable 1.  Data sample  of leaning -coded news sites on Facebook . \n \n \nFurthermore, research has indicated that the communication style alternates between democratic and \nrepublican echo chambers (Gr\u00f6mping 2014 ; Liao and Fu 2014 ; Williams et al. 2015 ). To properly \nunderstand the differences between the various echo chambers, we assess the communication \nbehaviour that has been discussed in the context of Fake News (Janze and Risius 2017 ) (Table 3).  \n \nConspiracy Categories  Description  Examples  N (%)  \nPolitical Left  Propagating an extreme left agenda  \nwith dubious information . Go Left America,  \nLiberal Speak  13 (12.87)  \nPolitical Right  Propagating an extreme right agenda  \nwith dubious information.  InfoWars,  \nBritain First  41 (40.59)  \nPolitical Establishment  Outspoken distrust in information and \nactivities from governmental agencies.  Anonymous,  \nTruth And Action  12 (11.88)  \nMedia Establishment  Outspoken distrust in information from \nestablished media.  Uncensored News,  \nCounter Current News  13 (12.87)  \nEnvironmental  Propagating a one -sided environme n-\ntalist agenda.  EcoWatch,  \nREALfarmacy  3 (2.97)  \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  6 \n \n Supernatural  Distributing information on supernat u-\nral occurrences.  Ancient Code,  \nAwareness Act  5 (4.95)  \nConspiracy Categories  Description  Examples  N (%)  \nNiche  Interest  Advocating niche interests with dub i-\nous information  Native Americans,  \nClarion Project  3 (2.97)  \nNational Interest  Propagating extreme nationalist age n-\ndas. Behold Israel,  \nNos Comunicamos  5 (4.95)  \nReligious  Propagating religious beliefs . Christian Science Monitor,  \n Jews News  6 (5.94)  \nNotes. Number of Conspiracy news -sties = 101  \nTable 2. Detailed categorization of conspiracy sites  based on their predominantly expressed \nopinions . \nCommunication \nVariable  Description  References  Account  Rating  Average of five point rating  (Cao et al. 2011 ; Ghose and Ipeirotis 2011 ; Hu et al. 2012 ) \nFollowers  Number of followers  (Clark and Melancon 2013 ; Risius et al. 2016 ) \nLikes  Number of likes  (Kosinski et al. 2013 ; Risius et al. 2016 ) Post Content  \nTitle and Message  Post Frequency  Number of posts per day  (Risius and Beck 2015 ; Risius et al. 2016 ; Shahbaznezhad \nand Tripathi 2017 ) \nContent Type  Share of media type \n(picture, video, article)  (Shahbaznezhad and Tripathi 2017 ) \nWord Count  Number of words  (Mudambi and Schuff, 2010; Pan and Zhang, 2011; \nKorfiatis, Garc\u00eda -Bariocanal and S\u00e1nchez -Alonso, 2012; \nCheng and Ho, 2015; Zhiwei Liu and Park, 2015; Park and \nNicolau, 201 5; Fang, Ye, Kucukusta and Law, 2016; Qazi \net al., 2016; Salehan and Kim, 2016)  \nPolarity  Average sentiment  (Mudambi and Schuff, 2010; Ghose and Ipeirotis, 2011; \nSalehan and Kim, 2016; Yin, Mitra and Zhang, 2016)  \nLoudness  Share of capitalized letters  (Cao, Duan and Gan, 2011; Park and Nicolau, 2015) . \nReadability  Flesh -Kincaid Score  Mudambi and Schuff, 2010; Cao et al., 2011; Ghose and \nIpeirotis, 2011; Korfiatis et al., 2012; Fang et al., \n2016) (DuBay 2004 ) \nCitations  Whether or not contains \nquotation  (Ayeh 2015 ; Liu and Park 2015 ; Park and Nicolau 2015 ; \nZhang et al. 2014 )  \nQuestions  Whether or not contains \nquestion  (Seebach 2012 ; Siering et al. 2014 ) Community  \nResponses  Likes  Average number of \u201clikes\u201d \nper post  (Kosinski, Stillwell and Graepel, 2013)  \nShares  Average number of \n\u201cshares\u201d per post  (boyd et al. 2010 ; Janze and Risius 2017 ; Risius and Beck \n2015 ; Vosoughi et al. 2018 ) \nLove  Average number of \u201clove\u201d \nper post  \n(Hyv\u00e4rinen and Beck 2018 ; Risius and Ak olk 2015 ; Risius \net al. 2015 ) Wow  Average number of \u201cwow\u201d \nper post  \nHaha  Average number of \u201chaha\u201d \nper post  \nSad Average number of \u201csad\u201d \nper post  \nAngry  Average number of \u201cangry\u201d \nper post  \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  7 \n \n Notes. Data has yet to be collected  \nTable 3.  Variables collected for the analysis of the communication behaviour of news sites.  \nLastly, research has shown that echo chambers predominantly depend on the individual\u2019s choices \nmuch more than the platforms\u2019 content recommender algorithms (Bakshy et al. 2015 ; Flaxman et al. \n2016 ). Most work on homophily has focus ed on similarities such as age, gender, and race. Sunstein \n(2018 ) even assumes that people form echo chambers that overcome more immediate attractors of \ndemography and physical proximity through a shared ideology or religion, for example (O'Hara and \nStevens 2015 ). To acknowledge the individual\u2019s effect  on echo chambers , we consider the user \ncharacteristics to predict membership to a particular echo chamber (Table 4). This will help identify \nwhether there are certain demographic and educational predispositions for joining echo chambers and \ncould ultimate ly help develop more targeted counter measures to prevent radicalization. These \ndifferent characteristics have been manually coded where applicable (i.e., current location, hometown, \neducation, work, skills) and properly transformed (i.e., gender, age, pol itical and religious views).  \n \nCharacteristics  Coding  \nGender  User specified (71 categories)  \nAge 5 year periods from 18 onwards  \nLocation  Urban or rural (binary)  \nHometown  Urban or rural (binary)  \nEducation  International Standard Classification of \nEducation (ISCED -97) (6 Levels)  \nWork  International Standard Industrial Class i-\nfication (ISIC 4) (22 categories)  \nSkills  International Standard Industrial Class i-\nfication (ISIC 4) (22 categories)  \nLanguages  Number of languages specified by user  \nPolitical Views  User specified  \nReligious Views  User specified  \nTable 4.  Individual user characteristics used to explore differences between group members \nacross echo chambers.  \n \n3.3 Further Analysis \u2013 Next Steps \nBefore conducting the final analysis, we need to gather and transform the remaining data on the \ncommunicative behaviour of the individual sites. Thus, we are currently collecting the respective data \nfrom the different news sites. Since o nly the past 10 posts are immediately accessible  through the \npublic API, we  will draw on those posts to approximate the general communication behaviour . \nTo understand the general media landscape on Facebook we conduct a Bayesian matrix factor analysis \nbased on the news sties co-occurrences within the data sample. After having ide ntified the proper \nnumber of factors that distinguish the media landscape, we apply a multi -dimensional scaling analysis \non the dissimilarities of the items to determine the number and composition of echo  chambers on \nFacebook (Figure 2). We operationalize echo chambers as the common patterns of consumed \ninformation sources actively estab lished through Facebook Likes. Subsequently, we apply a latent \nclass analysis to the communicative behaviour and conspiracy categories to determine differences \nbetween echo chambers. Lastly, we test individual user differences between groups through a decision \ntree and another latent class analysis.  \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  8 \n \n   \n \nFigure 2. Conceptual data transformation from raw data sample to identifying potential social \nmedia  echo chamber (s).4 \n4 Conclusion  \nEcho chambers are informationally encapsulated environments personalized to the singular users\u2019 \ninterests (Nagulendra and Vassileva 2014 ). They are considered to be a major threat for modern \nsociety and democracy as they lead to polarization and even radicalization (Dandekar et al. 2013 ; \nSunstein 2018 ). Echo chambers result from the homophilic desire to build connections with similar \nand likeminded people (McPherson et al. 2001 ). Particularly online social networks have been found \nto play a strong role on this radicalization (Hamm and Spaaij 2015 ). Research is currently strongly \nlimited , for example, to  artificial experimental settings or subjective self -report measures, the \noversimplified binary distinction between Republicans and Democrats. Thus, we comprehensively \ncollect real world data from 7,000 Facebook users and analyse general media consumption patterns \nacross 2,137 news sites to identify the actual echo chambers. In this regard, we are particularly \ninterested in the distinguishing characteristics of conspiracy echo chambers, which serve as a breeding \nground for fake news  (Sunstein 2018 ). We will be able to make three distinctive contributions: First, \nwe will identify different types of Facebook medi a consumption groups beyond left - and right -wing \ngroups. Second, we help understand distinguishing characteristics in communicative behaviour of the \nconspiracy groups on Facebook to identify them more easily. Third, we assess unique characteristics \nof user s in conspiracy echo chambers to identify target or high -risk individuals for potential counter \nmeasures.  \n  \n\nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  9 \n \n References  \nAllSides. 2018a. \"Media Bias Ratings.\"   Retrieved March 8, 2018, 2018, from \nhttps:// www.allsides.com/media -bias/media -bias-ratings  \nAllSides. 2018b. \"What Does a \"Center\" Media Bias Rating Mean?\"   Retrieved November 26, 2018, \n2018, from https:// www.allsides.com/media -bias/center  \nAllSides. 2018c. \"What Does a \"Right\" Media Bias Rating Mean?\"   Retrieved November 26, 2018, \n2018, from https:// www.allsides.com/media -bias/right  \nAllSides. 2018d. \"What Does a \u201cLean Left\u201d Media Bias Rating Mean?\"   Retrieved November 26, \n2018, 2018, from https:// www.allsides.com/media -bias/left -center  \nAllSides. 2018e. \"What Does a \u201cLean Right\u201d Media Bias  Rating Mean?\"   Retrieved November 26, \n2018, 2018, from https:// www.allsides.com/media -bias/right -center  \nAllSides. 2018f. \"What Does a \u201cLeft\u201d Media Bias Rating Mean?\"   Retrieved November 26,  2018, \n2018, from https:// www.allsides.com/media -bias/left  \nAyeh, J. K. 2015. \"Travellers\u2019 Acceptance of Consumer -Generated Media: An Integrated Model of \nTechnology Acceptance and Source Credibility Th eories,\" Computers in Human Behavior  \n(48), pp. 173 -180. \nBaer, D. 2016. \"The \u2018Filter Bubble\u2019 Explains Why Trump Won and You Didn\u2019t See It Coming.\"   \nRetrieved March 28, 2017, 2017, from http://nymag.com/scienceofus/2016/11/how -facebook -\nand-the-filter -bubble -pushed -trump -to-victory.html  \nBakshy, E., Messing, S., and Adamic, L. 2015. \"Exposure to Ideologically Diverse News and Opinion \non Facebook ,\" Science ). \nBaumgaertner, B. 2014. \"Yes, No, Maybe So: A Veritistic Approach to Echo Chambers Using a \nTrichotomous Belief Model,\" Synthese  (191:11), pp. 2549 -2569.  \nBessi, A. J. C. i. H. B. 2016. \"Personality Traits and Echo Chambers on Facebook,\"  (65), p p. 319 -324. \nBoutyline, A., and Willer, R. 2017. \"The Social Structure of Political Echo Chambers: Variation in \nIdeological Homophily in Online Networks,\" Political Psychology  (38:3), pp. 551 -569. \nboyd, d., Golder, S., and Lotan, G. 2010. \"Tweet, Tweet, Ret weet: Conversational Aspects of \nRetweeting on Twitter,\" 43rd Hawaii International Conference on System Sciences (HICSS) , \nHonolulu, HI, USA: IEEE, pp. 1 -10. \nCao, Q., Duan, W., and Gan, Q. 2011. \"Exploring Determinants of Voting for the \u201cHelpfulness\u201d of \nOnline User Reviews: A Text Mining Approach,\" Decision Support Systems  (50:2), pp. 511 -\n521. \nCarter, M. J. M. Q. 2015. \"Me, My Self, and I (T): Conceptualizing Information Technology Identity \nand Its Implications,\"  (39:4).  \nClark, M., and Melancon, J. 2013. \"Th e Influence of Social Media Investment on Relational \nOutcomes: A Relationship Marketing Perspective,\" International Journal of Marketing \nStudies  (5:4), pp. 132 -142. \nColleoni, E., Rozza, A., and Arvidsson, A. 2014. \"Echo Chamber or Public Sphere? Predicting  \nPolitical Orientation and Measuring Political Homophily in Twitter Using Big Data,\" Journal \nof Communication  (64:2), pp. 317 -332. \nDandekar, P., Goel, A., and Lee, D. T. 2013. \"Biased Assimilation, Homophily, and the Dynamics of \nPolarization,\" Proceedings of the National Academy of Sciences  (110:15), pp. 5791 -5796.  \nDuBay, W. H. 2004. \"The Principles of Readability,\" Online Submission ). \nFlaxman, S., Goel, S., and Rao, J. M. 2016. \"Filter Bubbles, Echo Chambers, and Online News \nConsumption,\" Public Opinion Qu arterly  (80:S1), pp. 298 -320. \nGhose, A., and Ipeirotis, P. G. 2011. \"Estimating the Helpfulness and Economic Impact of Product \nReviews: Mining Text and Reviewer Characteristics,\" IEEE Transactions on Knowledge and \nData Engineering  (23:10), pp. 1498 -1512.  \nGr\u00f6mping, M. 2014. \"\u2018Echo Chambers\u2019: Partisan Facebook Groups During the 2014 Thai Election,\" \nAsia Pacific Media Educator  (24:1), pp. 39 -59. \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  10 \n \n Hamm, M., and Spaaij, R. 2015. \"Lone Wolf Terrorism in America: Using Knowledge of \nRadicalization Pathways to Forge  Prevention Strategies,\" National Criminbal Justice \nReference Service, pp. 1 -28. \nHenri, T., and Turner, J. C. J. P. o. i. r. 1986. \"The Social Identity Theory of Intergroup Behavior,\"  \n(2), pp. 7 -24. \nHu, N., Bose, I., Koh, N. S., and Liu, L. 2012. \"Manipul ation of Online Reviews: An Analysis of \nRatings, Readability, and Sentiments,\" Decision Support Systems  (52:3), pp. 674 -684. \nHyv\u00e4rinen, H., and Beck, R. 2018. \"Emotions Trump Facts: The Role of Emotions in on Social Media: \nA Literature Review,\" Proceedings  of the 51st Hawaii International Conference on System \nSciences . \nJanze, C., and Risius, M. 2017. \"Automatic Detection of Fake News on Social Media Platforms,\" 21st \nPacific Asia Conference on Information Systems , Langkawi, Malaysia, p. 261.  \nJasny, L., Waggl e, J., and Fisher, D. R. 2015. \"An Empirical Examination of Echo Chambers in Us \nClimate Policy Networks,\" Nature Climate Change  (5), p. 782.  \nKosinski, M., Stillwell, D., and Graepel, T. 2013. \"Private Traits and Attributes Are Predictable from \nDigital Reco rds of Human Behavior,\" Proceedings of the National Academy of Sciences  \n(110:15), pp. 5802 -5805.  \nKrippendorff, K. 2004. Content Analysis , (2 ed.). Thousand Oaks, Calif: Sage Publications.  \nKrippendorff, K. 2012. Content Analysis: An Introduction to Its Meth odology , (3 ed.). Thousand Oaks, \nCA: SAGE Publications, Incorporated.  \nLiao, Q. V., and Fu, W. -T. 2014. \"Expert Voices in Echo Chambers: Effects of Source Expertise \nIndicators on Exposure to Diverse Opinions,\" in: Proceedings of the 32nd annual ACM \nconferen ce on Human factors in computing systems . Toronto, Ontario, Canada: ACM, pp. \n2745 -2754.  \nLiu, Z., and Park, S. 2015. \"What Makes a Useful Online Review? Implication for Travel Product \nWebsites,\" Tourism Management  (47), pp. 140 -151. \nMcPherson, M., Smith -Lovin, L., and Cook, J. M. 2001. \"Birds of a Feather: Homophily in Social \nNetworks,\" Annual review of sociology  (27:1), pp. 415 -444. \nMedia Bias/Fact Check. 2018a. \"Media Bias/Fact Check - Conspiracy -Pseudoscience.\"   Retrieved \nNovember 26, 2018, 2018, from ht tps://mediabiasfactcheck.com/conspiracy/  \nMedia Bias/Fact Check. 2018b. \"Media Bias/Fact Check - Pro-Science.\"   Retrieved November 26, \n2018, 2018, from https://mediabiasfactcheck.com/pro -science/  \nMedia Bias/Fact Check. 2018c. \"Media Bias/Fact Check - Quest ionable Sources.\"   Retrieved \nNovember 26, 2018, 2018, from https://mediabiasfactcheck.com/fake -news/  \nMedia Bias/Fact Check. 2018d. \"Media Bias/Fact Check - Satire.\"   Retrieved November 26, 2018, \n2018, from https://mediabiasfactcheck.com/satire/  \nMedia Bia s/Fact Check. 2018e. \"The Most Comprehensive Media Bias Resource.\"   Retrieved March \n8, 2018, 2018, from https://mediabiasfactcheck.com/  \nMessing, S., and Westwood, S. J. J. C. R. 2014. \"Selective Exposure in the Age of Social Media: \nEndorsements Trump Part isan Source Affiliation When Selecting News Online,\"  (41:8), pp. \n1042 -1063.  \nNagulendra, S., and Vassileva, J. 2014. \"Understanding and Controlling the Filter Bubble through \nInteractive Visualization: A User Study,\" in: Proceedings of the 25th ACM conferen ce on \nHypertext and social media . Santiago, Chile: ACM, pp. 107 -115. \nNguyen, C. T. 2018. \"Echo Chambers and Epistemic Bubbles,\" Episteme ), pp. 1 -21. \nNikolov, D., Oliveira, D. F. M., Flammini, A., and Menczer, F. 2015. \"Measuring Online Social \nBubbles,\" PeerJ Computer Science  (1), p. e38.  \nO'Hara, K., and Stevens, D. 2015. \"Echo Chambers and Online Radicalism: Assessing the Internet's \nComplicity in Violent Extremism,\" Policy & Internet  (7:4), pp. 401 -422. \nPariser, E. 2011. The Filter Bubble: What the Internet  Is Hiding from You . UK: Penguin Press HC.  \nPark, S., and Nicolau, J. L. 2015. \"Asymmetric Effects of Online Consumer Reviews,\" Annals of \nTourism Research  (50), pp. 67 -83. \nRisius et al. /Conspiracy Echo Chambers on Facebook  \nTwenty -Seventh European Conference on Information Systems (ECIS2019), Stockholm -Uppsala,  Sweden.  11 \n \n Risius, M., and Akolk, F. 2015. \"Differentiated Sentiment Analysis of Corporate Socia l Media \nAccounts,\" Proceedings of the 21st American Conference on Information Systems (AMCIS) , \nFajardo, Puerto Rico.  \nRisius, M., Akolk, F., and Beck, R. 2015. \"Differential Emotions and the Stock Market. The Case of \nCompany -Specific Trading,\" 23rd European  Conference on Information Systems (ECIS) , \nMuenster, Germany.  \nRisius, M., and Beck, R. 2015. \"Effectiveness of Corporate Social Media Activities in Increasing \nRelational Outcomes,\" Information & Management  (52:7), pp. 824 -839. \nRisius, M., Benthaus, J., and Akolk, F. 2016. \"Is It Worth It? Dismantling the Process of Social Media \nRelated Sales Performance,\" 24th European Conference on Information Systems (ECIS) , \n\u0130stanbul,Turkey.  \nSeebach, C. 2012. \"Searching for Answers -Knowledge E xchange through Social Media in \nOrganizations,\" 45th Hawaii International Conference on System Science (HICSS) : IEEE, pp. \n3908 -3917.  \nShahbaznezhad, H., and Tripathi, A. 2017. \"Studying the Effective Factors of User Engagement on \nSocial Media Fan Pages,\" 16th SIG e -Business Workshop (WeB) at the 36th International \nConference on Information Systems (ICIS 2017) Seoul, South Korea.  \nShalizi, C. R., and Thomas, A. C. 2011. \"Homophily and Contagion Are Generically Confounded in \nObservational Social Network Studies ,\" Sociological methods & research  (40:2), pp. 211 -239. \nShore, J., Baek, J., and Dellarocas, C. J. B. U. Q. S. o. B. R. P. 2016. \"Network Structure and Patterns \nof Information Diversity on Twitter,\"2813342).  \nSiering, M., Zimmermann, K., and Haferkorn, M. 2 014. \"Read This! How to Boost the Interest \nTowards Research Articles -a Study on Ssrn Research Impact,\").  \nSpohr, D. 2017. \"Fake News and Ideological Polarization: Filter Bubbles and Selective Exposure on \nSocial Media,\" Business Information Review  (34:3), pp . 150 -160. \nStets, J. E., and Burke, P. J. J. S. p. q. 2000. \"Identity Theory and Social Identity Theory,\"), pp. 224 -\n237. \nStryker, S., and Burke, P. J. J. S. p. q. 2000. \"The Past, Present, and Future of an Identity Theory,\"), \npp. 284 -297. \nSunstein, C. R. 2 018. # Republic: Divided Democracy in the Age of Social Media . Princeton \nUniversity Press.  \nSunstein, C. R. J. J. o. p. p. 2002. \"The Law of Group Polarization,\"  (10:2), pp. 175 -195. \nVaccari, C., Valeriani, A., Barber\u00e1, P., Jost, J. T., Nagler, J., and Tuc ker, J. A. 2016. \"Of Echo \nChambers and Contrarian Clubs: Exposure to Political Disagreement among German and \nItalian Users of Twitter,\" Social Media + Society  (2:3), p. 2056305116664221.  \nVosoughi, S., Roy, D., and Aral, S. 2018. \"The Spread of True and Fal se News Online,\" Science  \n(359:6380), pp. 1146 -1151.  \nWilliams, H. T. P., McMurray, J. R., Kurz, T., and Hugo Lambert, F. 2015. \"Network Analysis \nReveals Open Forums and Echo Chambers in Social Media Discussions of Climate Change,\" \nGlobal Environmental Chang e (32), pp. 126 -138. \nZhang, L., Peng, T. -Q., Zhang, Y. -P., Wang, X. -H., and Zhu, J. J. 2014. \"Content or Context: Which \nMatters More in Information Processing on Microblogging Sites,\" Computers in Human \nBehavior  (31), pp. 242 -249. \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Towards an understanding of conspiracy echo chambers on Facebook", "author": ["M Risius", "O Aydinguel", "M Haug"], "pub_year": "2019", "venue": "NA", "abstract": "Selective online exposure to information that serves to only affirm people\u2019s opinions or is  strongly aligned with their interests is considered to be a major issue in modern societies. Echo"}, "filled": false, "gsrank": 241, "pub_url": "https://madoc.bib.uni-mannheim.de/51061", "author_id": ["vjzOOUgAAAAJ", "Wq0hkr4AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:eBojOtWBck0J:scholar.google.com/&output=cite&scirp=240&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=eBojOtWBck0J&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 20, "citedby_url": "/scholar?cites=5580665641068862072&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:eBojOtWBck0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://madoc.bib.uni-mannheim.de/51061/1/TOWARDS%20AN%20UNDERSTANDING%20OF%20%20CONSPIRACY%20ECHO%20CHAMBERS%20ON%20FACEBOOK.pdf"}}, {"title": "Reliability of content and echo chambers on YouTube during the COVID-19 debate", "year": "2021", "pdf_data": "Reliability of Content and Echo Chambers on YouTube during the COVID-19\nDebate\nNiccol `o Di Marco1, Matteo Cinelli2, Walter Quattrociocchi2\n1University of Florence2Sapienza University of Rome\nAbstract\nThe spread of inaccurate and misleading information may\nalter behaviours and complicate crisis management, espe-\ncially during an emergency like the COVID-19 pandemic.\nThis paper aims to investigate information diffusion during\nthe COVID-19 pandemic by evaluating news consumption on\nYouTube. First, we analyse more than 2 million users\u2019 en-\ngagement with 13,000 videos released by 68 YouTube chan-\nnels, labelled with a political bias and fact-checking index.\nThen, we study the relationship between each user\u2019s polit-\nical preference and their consumption of questionable (i.e.,\npoorly fact-checked) and reliable information. Our results,\nquanti\ufb01ed using measures from information theory, provide\nevidence for the existence of echo chambers across two di-\nmensions represented by political bias and the trustworthi-\nness of information channels. We observe that the echo cham-\nber structure cannot be reproduced after properly randomis-\ning the users\u2019 interaction patterns. Moreover, we observe a\nrelation between the political bias of users and their tendency\nto consume highly questionable news.\nIntroduction\nThe case of the COVID-19 pandemic made explicit\nthe critical role of information diffusion during critical\nevents (Briand et al. 2021). A relevant example was the\nmassive amount of uncertain information shared by the me-\ndia to justify the withdrawal of one AstraZeneca vaccine\nbatch, which led to a dramatic lack of trust in it. In fact,\nthe information ecosystem radically changed with the ad-\nvent of social media platforms as they implement algo-\nrithms and interaction schemes to maximise user engage-\nment. Those algorithms account for users\u2019 preferences and\nmay signi\ufb01cantly alter social dynamics and information dif-\nfusion (Bakshy, Messing, and Adamic 2015; Cinelli et al.\n2021a). Therefore, it is crucial to understand how people\nseek or avoid information and how those decisions affect\ntheir behaviour (Sharot and Sunstein 2020) when the news\ncycle \u2014 dominated by the disinter-mediated diffusion of\ncontent \u2014 signi\ufb01cantly alters how information is consumed\nand reported on. This corresponds to investigating what is\ncalled social contagion, i.e., the spread of ideas, attitudes,\nCopyright \u00a9 2021, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.norms, or behavioural patterns from individual to individ-\nual through social in\ufb02uence, imitation, and conformity. So-\ncial contagion depends on users\u2019 attitudes, tendencies, and\nintentionality. Our attention span is limited and feed al-\ngorithms might further limit our selection process by sug-\ngesting content similar to those we are usually exposed to.\nPlus, users show a tendency to favour information adher-\ning to their beliefs and join groups formed around a shared\nnarrative, that is, echo chambers (Sunstein 2004; Garimella\net al. 2018; Cinelli et al. 2021a). Echo chambers are envi-\nronments in which users\u2019 opinion, political leaning, or be-\nlief about a topic gets reinforced due to repeated interac-\ntions with peers or sources having similar tendencies and\nattitudes. This work follows the de\ufb01nition of echo chambers\nprovided in (Cinelli et al. 2021a) to understand the users\u2019\nattention patterns on YouTube during the COVID-19 pan-\ndemic. According to some studies, YouTube plays a promi-\nnent role in the radicalisation of opinions (Ribeiro et al.\n2020; Hosseinmardi et al. 2021; Feezell, Wagner, and Con-\nroy 2021) and in the diffusion of questionable (i.e., poorly\nfact-checked) content (Ribeiro et al. 2020; Cinelli et al.\n2021b) being one of the most visited online domains and in-\nformation retrieval platforms. In such a context, the COVID-\n19 debate on YouTube seems to be a suitable case study for\ninvestigating the presence of the echo chamber effect and\nits relationship with the consumption of questionable infor-\nmation. The dataset exploited in our study contains 10 mil-\nlions comments to videos published by 68 prominent news\nchannels on YouTube, in the time window ranging from De-\ncember 2019 to September 2020. We start by introducing\nsome preliminaries used throughout the article. Then, we\nanalyse users\u2019 engagement, in terms of comments posted\nby the users on videos produced by YouTube channels with\na known political bias and fact-checking score. Finally, we\ninvestigate the relationship between users\u2019 political prefer-\nences and their consumption of questionable and reliable\ninformation \ufb01nding that echo chambers exist on YouTube\nacross the political and fact-checking dimensions.\nData and Methods\nWe collected videos using the of\ufb01cial YouTube Data API in\nthe period ranging from 2020/01/15 to 2020/09/06, search-\ning for videos that matched a list of keywords selected on the\nbasis of Google Trends\u2019 COVID-19 related queries. ThosearXiv:2106.08684v2  [cs.CY]  29 Nov 2022\nkeywords include the terms: coronavirus, nCov, corona\nvirus, corona-virus, covid or SARS-CoV . An in-depth search\nwas then performed by crawling the network of related\nvideos as provided by the YouTube algorithm. We \ufb01ltered\nthe related videos that matched our set of keywords in the\ntitle or description from the gathered collection and we col-\nlected the comments received by those videos.\nFrom all these videos, we kept only a set of 10,968,002\ncomments posted by 2,092,817 users on 12,933 videos pub-\nlished from 2019/12/2 to 2020/9/5 by 68 YouTube chan-\nnels directly linked to news outlets classi\ufb01ed by Media-Bias-\nFact-Check (MBFC) (bias/fact check 2014), an independent\nfact-checking agency. We specify that all these videos come\nfrom channels that posses a political bias and a factual re-\nporting index from MBFC. MBFC provides such indexes for\nnews outlets and we assumed that they are inherited by their\nof\ufb01cial YouTube channels. The \ufb01rst index provides a score\nfor the channel\u2019s bias in the political dimension (i.e., its po-\nlitical leaning). The second represents the overall factual re-\nporting level of the news published by the channel. Since the\nconcept of factual reporting is very broad, we specify that,\naccording to MBFC, a questionable source \u201cexhibits one or\nmore of the following: extreme bias, consistent promotion\nof propaganda/conspiracies, poor or no sourcing to credible\ninformation, a complete lack of transparency and/or is fake\nnews.\u201d\nFor instance, considering the YouTube channel of Breit-\nbart (a popular far-right news outlet), MBFC assigns to it a\npolitical leaning corresponding to Extreme right and a Fac-\ntual reporting index corresponding to Mixed . Speci\ufb01cally, in\nthe case of Political Bias, we assign numerical values to cat-\negorical labels as follows: -1 to Extreme left; -0.66 to Left;\n-0.33 to Left-center; 0 to Center; 0.33 to Right-center; 0.66\nto Right; and 1 to Extreme Right. Accordingly, for the fac-\ntual reporting, we assign: 0 to Very Low, 0.2 to Low, 0.4\nto Mixed, 0.6 to Mostly Factual, 0.8 to High and 1 to Very\nHigh. Figure 1 displays some general features of our dataset.\nIn particular, we note that the distribution of videos by chan-\nnel shows a lognormal-like shape (panel (b)) allowing for\nlarge deviations that are actually more likely in the distribu-\ntion of comments per user (panel (a)), as displayed by the\nheavy tail of the distribution. Furthermore, as shown in pan-\nels (c) and (d), the labels distributions in the set of channels\nis (reasonably) uneven and the observed heterogeneity is in-\ncreasing when we consider \ufb01rst videos and then comments.\nThis means that channels having more frequent labels pro-\nduce a higher share of videos and receive a disproportion-\nately higher amount of comments.\nWe quantify the strength of the preferences of YouTube\nusers through their engagement with videos (speci\ufb01cally the\nnumber of comments posted by each user). Consider a user\nileaving a total of nicomments on a set of videos com-\ning fromhichannels, in which channel jhas political bias\nbj. Suppose that ti\njis the total number of comments left in\nchanneljby useri. We de\ufb01ne the political bias of user ias\npi\u00111\nnihiX\nj=1ti\njbj: (1)\n0100002000030000\n10 100 1000\nNumber of commentsCount(a)\n05101520\n1101001000\nNumber of videosCount(b)\n0.00.51.0\nChannels VideosComments\nPolitical bias\nExtreme left\nLeft\u2212centerLeft\nCenterRight\u2212center\nRightExtreme right(c)\n0.00.51.0\nChannels VideosComments\nFactual reporting\nVery low\nLowMixed\nMostly factualHigh\nVery high(d)Figure 1: (a) density of comments per user (only users with\nat least 10 comments were considered), (b) density of videos\nper channel, (c) proportion of channels, videos and com-\nments considering the political bias of the channels, (d) pro-\nportion of channels, videos and comments considering the\nfactual reporting of the channels.\nThis index represents a (weighted) average of the chan-\nnels\u2019 political leanings on which user icommented and\ntherefore provides information about the user\u2019s political\npreference/bias. Similarly, each channel has a fact-checking\nindexfjand we de\ufb01ne the persistence index of user ias\nci\u00111\nnihiX\nj=1ti\njfj: (2)\nThe latter quantity has an interpretation similar to the for-\nmer. In particular, it is a (weighted) average of the channels\u2019\nfact-checking indexes on which user icommented and there-\nfore it provides information about the user\u2019s persistence in\ncommenting videos characterised by a certain trustworthi-\nness. Finally, note that pi2[\u00001;1], whileci2[0;1].\nTo study the relationship between the two indexes, piand\nci, we constructed an unweighted undirected bipartite net-\nworkGwith one partition representing the set of users and\non the other the set of channels, and in which two nodes i,j\nare connected if and only if the user icommented at least one\nvideo published by the channel j. We decided to follow the\nnetwork approach since it allows us to introduce relational\nindexes and study the social dynamics typical of a social net-\nwork, such as YouTube. First of all, we study the interplay\nbetween the political bias of users and their persistence in-\ndexes by visualising their joint distribution. Then, in order to\ndetect echo chambers, we compute the user bipartite projec-\ntionG0and we compare the political bias of users with the\naverage political bias of their neighbourhood. G0is a net-\nwork obtained from G: its adjacency matrix is A=BtB,\nwhereBis the incidence matrix of G. The nodes of G0are\nthe users and two users i;jare connected if and only if they\nhave commented at least one common channel. We repeat\nthe same analysis for the persistence index.\nResults\nTo test whether a relationship between the users\u2019 political\nbias and their tendency to consume questionable/reliable\ncontent is present on YouTube, we \ufb01rst inspect the joint dis-\ntribution of the two indexes of bias and persistence, namely\npiandci. In Figure 2 we report a 2D density plot show-\ning the relation between the political bias and the persis-\ntence of each user. Marginal distributions are also reported.\nThe colour represents the density of users: the lighter, the\nlarger the number of users. We note a multi-polarisation\nphenomenon, that is, users tend display an overall opin-\nion focused approximately on three main positions: Left,\nLeft-center and Right. Furthermore, recalling that a higher\nvalue of persistence implies a higher factual reporting, we\nnote that users with political leaning far from the Center\ntend to consume less fact-checked news. Speci\ufb01cally, users\nthat consume content produced by questionable sources are\nalso more likely to have an political leaning skewed to-\nwards the extremes. On the other hand, users that consume\nmostly fact-checked news present, on average, a political\nbias slightly shifted towards Left. Interestingly, users with\na political leaning skewed towards Left display more than\none behaviour, namely few of them have a higher persistence\nscore. Simultaneously, a relevant share of users display a low\npersistence value, possibly indicating that users with a polit-\nical leaning skewed towards Left comment information from\nreliable and questionable sources in a somewhat segregated\nmanner.\nFigure 2: Relationship between the political bias of users\nwith at least 10 comments and their persistence index. Users\nwith a leaning far from the Center tend to consume informa-\ntion from sources with lower fact-checking label. Users with\na Left bias display more than one behaviour: a part of them\nconsume more fact-checked news, while the others tend to\nget information through less reliable channels.\nThe echo chamber concept translates into a topological\nproperty of the co-commenting network G0, in which a user\ni, with a given piandci, is surrounded by other users sharing\nsimilar values of such indexes. This concept can be quanti-\n\ufb01ed by de\ufb01ning, for each user i, the average political leaning\nand persistence index of its neighbours as follows:pN\ni=1\nkiX\njAijpj (3)\ncN\ni=1\nkiX\njAijcj (4)\nwherekiis the degree of node iandAijis the adjacency\nmatrix of the user bipartite projection G0obtained from G.\nSpeci\ufb01cally, Aij= 1 if and only if user iand userjcom-\nmented at least one common video.\nFigure 3 shows the joint distribution of individual lean-\ning (persistence) and neighbourhood leaning (persistence)\nfor the nodes of the network. Also in this case the colour\nrepresents the density of users. Note that also marginal dis-\ntribution are shown. In more detail, panels (a) and (c) show\nthe presence of echo chambers in the political and the fact-\nchecking dimensions. Indeed, we note the presence of dis-\ntinct areas in which users aggregate with others similar to\nthem. Such areas are located on the diagonal of the plots\nindicating a positive correlation between individual leaning\n(persistence) and neighbourhood leaning (persistence). This\nhomogeneous mixing could be, at least partially, driven by\nthe homophilic tendency of users to interact with people that\nconsume similar content both in terms of political bias and\nreliability.\nTo understand if echo chambers represent a peculiar fea-\nture of the empirical network that we are taking into ac-\ncount, we randomised the links of the initial bipartite net-\nwork through the Maslov-Sneppen (MS) algorithm. Such\nan algorithm was employed to obtain, after 2x108rewiring\nsteps, a new randomised co-commenting network that has\nthe same degree distribution of the original one. The MS al-\ngorithm is based on the simple principle of rewiring network\nlinks by switching their endpoints and it works as follows:\ni) sample a couple of links uniformly at random (e.g. A\u2013B\nand C\u2013D) ii) switch their endpoints (thus obtaining the new\nlinks A\u2013D and B\u2013C) iii) if at least one of the new links al-\nready exists abort the iteration step and select a new pair of\nlinks iv) repeat the procedure a number of times proportional\nto the number of links of the network. The results are shown\nin panels (b) and (d) of Figure 3, in which we may note that\nthe echo chamber effect disappears. Thus, the presence of\necho chambers can be considered a non-random topological\nfeature of the empirical network. After the randomisation,\nusers regardless their value of piandciare in contact with\nusers with different values of those indexes thus resulting in\nan average distribution with little variation on the y axis, as\nshown by marginal plots.\nTo give a quantitative description of our results, we com-\npute the joint entropy of the distributions shown in Figure 3.\nThe joint entropy of two discrete random variables is a mea-\nsure of their degree of uncertainty. Consider two random\nvariablesXandY, the joint entropy is de\ufb01ned as:\nH(X;Y ) =\u0000X\nx2XX\ny2YP(x;y) log2(P(x;y)) (5)\nwhereXis the range of X,Yis the range of Yand\nP(x;y)is the joint probability of those values. If P(x;y) =\n(a) (b)\n(c) (d)Figure 3: Panel (a) displays the relationship between the po-\nlitical bias of users and the average political bias of their\nneighbourhood. Panel (c) displays the relationship between\nthe persistence index of users and the average persistence of\ntheir neighbourhood. Panels (b) and (d) are obtained anal-\nogously to (a) and (c) but in a randomised network. Panels\n(a) and (c) show the presence of echo chambers from both\nthe political and the questionable/reliable dimension while\npanels (b) and (d) con\ufb01rm that echo chambers do not arise\nfrom random behaviour.\n0we assume that also P(x;y)log2(P(x;y)) = 0 . The inter-\npretation of Equation 5 relies on the concept of information\ncontent: entropy measures the average amount of informa-\ntion carried by the outcome of a trial to predict future out-\ncomes and how uncertain the outcome is. The distribution\nwith the highest entropy is the uniform distribution since\nthere is no way to predict the future outcomes and it assumes\nthe valuelog2(n), wherenis the number of possible couples\n(x;y). On the other hand, the distribution with the lowest en-\ntropy value (H(X;Y ) = 0 isP(x;y) =\u000e(x0;y0)(where\n\u000e(x0;y0)is the Dirac Delta function), since it is possible\nto predict exactly what the next outcome is. We computed\njoint entropy for the joint distributions shown in Figure 3\nand compared resulting entropy values with their random\ncounterparts. To compute the joint probability we employed\na quantization of the space using a grid with steps of 0.01\n(used to sampling the frequencies of the distributions). We\ncreated a matrix of frequencies for each distribution. Since\npi2[\u00001;1]andci2[0;1]the matrices corresponding to\nthe political distribution had size 200x200, while the matri-\nces related to the persistence distribution had size 100x100.\nThe values were then normalised by their maximum value\nlog2(n). We obtain 0.3863 for the Political Bias and 0.2914\nfor its random counterpart. Instead, we obtain 0.4297 for thePersistence and 0.3338 for its random counterpart.\nThe computed values show that echo chambers, by clus-\ntering the opinion in several distinct points of the space,\nhave higher entropy values with respect to their random\ncounterparts. This can be explained by noticing that, after\nthe randomisation process, users interact with users in a\nwide spectrum of values and therefore the (average) Lean-\ning/Persistence is centred in (approximately) one point, re-\nsulting in reduced entropy.\nConclusion\nIn this paper, we studied information diffusion during the\nCOVID-19 pandemic by analysing the interaction of users\nwith YouTube channels related to news outlets. Our \ufb01nd-\nings show that, during the COVID-19 pandemic, the dis-\ncussion was structured in echo chambers considering both\nthe political and fact-checking dimensions. Furthermore, a\nsubstantial difference between the echo chambers behaviour\nand the random behaviour was highlighted in a quantitative\nmanner. A possible limitation of our study is the usage of\na single source, namely Media Bias Fact Check whose rat-\ning methodology despite being public could be affected by\nsubjective judgements, to label YouTube channels. This lim-\nitation could be overcome by considering further labelling\navailable online or alternative methodologies to infer the po-\nlitical bias. Future work will involve both a deeper investiga-\ntion of the network structure to describe the role of users in\nthe process of commenting and a syntactic/semantic analysis\nof the text of such comments.\nReferences\nBakshy, E.; Messing, S.; and Adamic, L. A. 2015. Expo-\nsure to ideologically diverse news and opinion on Facebook.\nScience 348(6239): 1130\u20131132.\nbias/fact check, M. 2014. Media bias/fact check -\nsearch and learn the bias of news media. URL https:\n//mediabiasfactcheck.com/.\nBriand, S. C.; Cinelli, M.; Nguyen, T.; Lewis, R.; Prybylski,\nD.; Valensise, C. M.; Colizza, V .; Tozzi, A. E.; Perra, N.;\nBaronchelli, A.; et al. 2021. Infodemics: A new challenge\nfor public health. Cell 184(25): 6010\u20136014.\nCinelli, M.; Morales, G. D. F.; Galeazzi, A.; Quattrocioc-\nchi, W.; and Starnini, M. 2021a. The echo chamber effect\non social media. Proceedings of the National Academy of\nSciences 118(9).\nCinelli, M.; Pelicon, A.; Mozeti \u02c7c, I.; Quattrociocchi, W.; No-\nvak, P. K.; and Zollo, F. 2021b. Dynamics of online hate and\nmisinformation. Scienti\ufb01c reports 11(1): 1\u201312.\nFeezell, J. T.; Wagner, J. K.; and Conroy, M. 2021. Explor-\ning the effects of algorithm-driven news sources on political\nbehavior and polarization. Computers in human behavior\n116: 106626.\nGarimella, K.; Morales, G. D. F.; Gionis, A.; and Math-\nioudakis, M. 2018. Quantifying controversy on social me-\ndia.ACM Transactions on Social Computing 1(1): 1\u201327.\nHosseinmardi, H.; Ghasemian, A.; Clauset, A.; Mobius, M.;\nRothschild, D. M.; and Watts, D. J. 2021. Examining the\nconsumption of radical content on YouTube. Proceedings of\nthe National Academy of Sciences 118(32).\nRibeiro, M. H.; Ottoni, R.; West, R.; Almeida, V . A.; and\nMeira Jr, W. 2020. Auditing radicalization pathways on\nYouTube. In Proceedings of the 2020 conference on fair-\nness, accountability, and transparency , 131\u2013141.\nSharot, T.; and Sunstein, C. R. 2020. How people decide\nwhat they want to know. Nature Human Behaviour 4(1):\n14\u201319.\nSunstein, C. R. 2004. Democracy and \ufb01ltering. Communi-\ncations of the ACM 47(12): 57\u201359.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Reliability of content and echo chambers on YouTube during the COVID-19 debate", "author": ["N Di Marco", "M Cinelli", "W Quattrociocchi"], "pub_year": "2021", "venue": "arXiv preprint arXiv:2106.08684", "abstract": "The spread of inaccurate and misleading information may alter behaviours and complicate  crisis management, especially during an emergency like the COVID-19 pandemic. This paper"}, "filled": false, "gsrank": 242, "pub_url": "https://arxiv.org/abs/2106.08684", "author_id": ["ZeW1KYEAAAAJ", "3qOq_28AAAAJ", "_OCIc6UAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:se7ZfDq0MB0J:scholar.google.com/&output=cite&scirp=241&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=se7ZfDq0MB0J&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 4, "citedby_url": "/scholar?cites=2103379189277781681&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:se7ZfDq0MB0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2106.08684"}}, {"title": "Instructed or Paid Way to Truth? The contribution of fact-checking tips and monetary incentives to recognizing scientific disinformation", "year": "NA", "pdf_data": "Instructed or Paid Way to Truth? The contribution of\nfact-checking tips and monetary incentives to recognizing\nscientific disinformation\nFolco Panizza1*,Piero Ronzani1, Simone Mattavelli2,Tiffany Morisseau3,4,5, Carlo\nMartini1,6,Matteo Motterlini1\n1Centre for Applied and Experimental Epistemology, Vita-Salute San Raffaele\nUniversity, Via Borromeo, 41, 20811 Cesano Maderno (MB), Italy.\n2Department of Psychology, Bicocca University, Piazza dell'Ateneo Nuovo, 1, 20126\nMilano, Italy.\n3Universit\u0013 e de Paris, Laboratoire de Psychologie et d'Ergonomie Appliqu\u0013 ees,\nBoulogne-Billancourt, France\n4Laboratoire de Psychologie et d'Ergonomie Appliqu\u0013 ees, Universit\u0013 e Gustave Eiffel,\nVersailles, France\n5Strane Innovation, Gif-sur-Yvette, France\n6TINT { Centre for Philosophy of Social Science, Department of Political and\nEconomic Studies, University of Helsinki, P.O. Box 24 (Unioninkatu 40A), 00014\nHelsinki, Finland.\n* corresponding author: panizza.folco@hsr.it\nAbstract\nScientific disinformation can impose enormous economic and public health burdens.\nSeveral types of interventions have been proposed to prevent the proliferation of false\ninformation online, where most of the spreading takes place. A recently proposed\nstrategy to help online users recognise false content is to follow the techniques of\nprofessional fact checkers, such as looking for information on other websites (lateral\nreading) and looking beyond the first results suggested by search engines (click\nrestraint). In two preregistered online experiments (N = 5387), we simulated a\nsocial-media environment and set-out two interventions, one in the form of a pop-up\nmeant to induce participants to follow such techniques, the other based on monetary\nincentive. In Experiment 1, we compared these interventions to a control condition. In\nExperiment 2 another condition was added to test the joint impact of the pop-up and\nthe monetary incentive. We measured participants' ability to identify whether presented\nscientific information was scientifically (in)valid. Results revealed that while monetary\nincentives were overall more effective in increasing accuracy, the pop-up contributed\nwhen the post originated from an unknown source (and participants could rely less on\nprior information). Additional analysis on participants' search style based on both\nself-report responses and objectively measured behaviour revealed that the pop-up\nincreased the use of fact-checking strategies, and that these in turn increased accuracy.\nStudy 2 also clarified that the pop-up and the incentive did not interfere with each\nother, but rather acted complementarily, suggesting that attention and literacy\ninterventions can be designed in synergy.\nSeptember 21, 2021 1/31\nIntroduction 1\nThe massive circulation of inaccurate scientific information can have nefarious societal 2\nconsequences. Successful misconceptions influence the public debate on decisions 3\nregarding the effectiveness of a vaccine, the adoption of solutions mitigating climate 4\nchange, or the cost of a social policy. The sharing of false information is easily fuelled 5\nby political or social motivations that disregard the best scientific evidence on the 6\nmatter. It is indeed tempting to share information on social media without verifying its 7\ntruthfulness, simply because the mere act of sharing allows us to exhibit our position on 8\na given topic and to justify the validity of such a position. This phenomenon is 9\namplified in crisis situations when scarce information is accompanied by multiple and 10\ncontrasting rumours (also called infodemic) that could serve different views. People's 11\npropensity to accept scientifically dubious information can thus become a crucial 12\nproblem for both democracy and public welfare. 13\nThere are structural challenges to fighting the spread of false information on social 14\nmedia. One key issue is that companies often perceive a trade-off between engaging 15\nusers and combating viral but fake content, to the point of favouring the former over 16\nthe latter [1]. Curtailment is made even more difficult when there is a deliberate intent 17\nbehind the dissemination, what researchers refer to as disinformation. For example, at 18\nthe peak of the coronavirus infodemic, only 16% of fact-checked disinformation was 19\nlabelled as such by Facebook's algorithms, partly because content creators were able to 20\nsimply repost content with minor changes, thus escaping detection [2]. It is therefore 21\nessential that, in combination with a systematic change in policy, users themselves are 22\nempowered against malicious or false content. User-based resilience needs to be part of a 23\ntoolkit to fight disinformation: for instance, among the pillars of infodemic management, 24\nEysenbach [3] lists eHealth Literacy, science literacy capacity, and critical thinking 25\nability to fact-check information. Fighting science-related disinformation is harder than 26\ncontrasting other forms of disinformation (e.g. political) because in the former case the 27\nlines between expertise and pseudoexpertise are blurred, and incompetent or otherwise 28\nbiased sources pose as expert sources on topics like epidemiology or climate change. 29\nResearch on countering disinformation has developed substantially over the last 30\ndecade, bringing a wealth of different approaches [4{8]. These include debunking, the 31\nsystematic correction of false claims after they have been seen or heard [9,10], 32\npre-bunking, preventive measures before exposure to disinformation [5,11], nudging, 33\ninterventions affecting users' choices without limiting their freedom of choice [12], and 34\nboosting, the empowering of users by fostering existing competences or instilling new 35\nones [12]. All of the above approaches have proven to be useful in a social media 36\ncontext, not least by adopting ingenious and innovative adaptations of classical 37\nparadigms. Debunking has been extensively studied, with several experiments focusing 38\non the source [13{16] and the timing [17] of fact checking. Research has also explored 39\nwhether evaluations about the quality of contents and sources can be delegated to the 40\nso-called wisdom of crowds, with encouraging results [18{20]. Studies on pre-bunkning 41\nhave largely focused on the concept of inoculation [5,21], namely exposing users to 42\ndisinformation strategies in order to ease their recognition in future settings. 43\nInoculation has demonstrated pronounced and lasting effects when introduced through 44\ngames [22{25]. Nudging was also tested by showing warning labels for unchecked or 45\nfalse claims [26{29], but also by priming users to pay attention to the accuracy of 46\ncontent they might be willing to share [30{32] (however see [33] for a critique of this 47\napproach). Finally, boosting was tested by presenting users with a list of news/media 48\nliteracy tips or guidelines on how to evaluate information on-line [34{38], producing 49\nsome remarkable results and some non-significant ones. 50\nA promising example of media literacy intervention has been carried out by 51\nresearchers interested in understanding how fact checkers search for information about 52\nSeptember 21, 2021 2/31\nunknown but institutional-looking sources [39]. Researchers catalogued fact checkers' 53\nstrategies and distilled a series of questions to evaluate content, a set of skills that was 54\nnamed Civic Online Reasoning [40,41]. Two are the most prominent strategies adopted 55\nby fact checkers. One is lateral reading, namely leaving a website and opening new tabs 56\nalong a horizontal axis in order to use the resources of the Internet to learn more about 57\na site and its claims. The other is click restraint, that is, skipping the first search results 58\nof a browser search to avoid biases created by results-ranking algorithms. These 59\nstrategies seem particularly fit when a content has unknown origins that are hardly 60\nidentifiable or that appear legitimate on the surface, a feature that has been associated 61\nwith content creators spreading scientific disinformation and disinformation [42]. 62\nDetecting scientific disinformation often requires specific expertise to evaluate the 63\ncontent and cross-check sources. Under such conditions, assessing the truthfulness of 64\ninformation becomes tricky. 65\nIn the absence of expertise and content knowledge, users can rely on a number of 66\nexternal cues to infer whether information presented as scientific is reliable [43]. Unlike 67\nfake news, scientific disinformation relies on background knowledge about the expertise 68\nof the source. We can check, for example, whether a piece of information is agreed upon 69\nby the scientific community, or whether a source is a genuine expert one or a 70\npseudo-expert one, and these elements can give us important cues as to whether a 71\nsource conveys scientific, rather than pseudo-scientific, information. Lateral reading and 72\nclick restraint can thus be used when scientific disinformation is deceptively 73\nsophisticated and difficult to detect. Indeed, training on Civic Online Reasoning has 74\nproven very effective in countering disinformation among high school and college 75\nstudents [44{46], as well as elderly citizens [47]. Despite extensive research on Civic 76\nOnline Reasoning, so far little attention has been paid to the application of these 77\ntechniques on social media. It is therefore unclear how effective presenting these 78\nstrategies on a social network can actually be. 79\nCritical thinking strategies might not be the only potentially effective tools in 80\nevaluating scientific (dis)information. For instance users might not be sufficiently 81\nmotivated to evaluate the truthfulness of the content they see. Many users might share 82\nnews simply because they come from a source they trust or like, or because those news 83\nalign with their values, without paying much attention to trust. The spread of scientific 84\ndisinformation then is not only related to false beliefs, but also to motivated behavior, 85\npaired with strong personal identities and values. In order to better exploit the benefits 86\nof critical thinking tools, it is therefore also important to identify the respective effects 87\nof being aware of truth-motivated strategies; i.e., being motivated to know the truth 88\nabout a given topic. It may be that people, while being somehow familiar with 89\nfact-checking and civic online reasoning techniques, are only eager to apply them when 90\nidentifying the truthfulness of the information is reinforced by specific incentives. 91\nOne way to test the effect of motivation then is the use of monetary incentives. In 92\nother words, does paying participants for their being accurate increase their accuracy in 93\nthe evaluation of content? The idea behind this intervention is that money increases 94\nmotivation, and thus the attention paid to otherwise ignored cues about the accuracy of 95\ncontent. Supporting this view, a study conducted with a sample of Mechanical Turk 96\nworkers on comparable settings showed that monetary incentives are the main driver for 97\npeople to spend time on the platform and, even in the face of small average earnings, 98\naspects such as immediate payment play an important role in workers' motivation [48]. 99\nMonetary incentives have been proven to be a cost effective tool to modify behavior 100\nin domains such as health and human development [49], where often an early boost in 101\nmotivation promotes the adoption of cheap preventive behaviours, avoiding this way 102\ncostly consequences [50]. From a psychological perspective, the use of incentives builds 103\non the attention-based account of disinformation spread. This account posits that 104\nSeptember 21, 2021 3/31\ncertain features of social networks favour the dissemination of interesting and 105\nunexpected content at the expense of accuracy [4,51]. Recent research in this field has 106\nfound both laboratory and field evidence that accuracy of content is often overlooked 107\nand that simple cues reminding participants to evaluate the accuracy of content they 108\nshare has an impact in terms of the proportion of fake/true news shared [30,32,52,53]. 109\nIncreasing accuracy through incentives is not an entirely novel idea in social media 110\neither, as shown in a recent initiative promoted by Twitter [54]. Although these 111\npremises indicate that this type of intervention can be very effective, it is not a given 112\nthat economic incentives will have a positive effect on scientific content evaluation. In 113\nan experimental setting in particular, social media content is subject to higher scrutiny 114\nthan when users scroll through their news feed [30]. It is therefore possible that 115\nadditional incentives may not further increase participants' accuracy. 116\nThe aim of the present study was to test and compare the effectiveness of Civic 117\nOnline Reasoning techniques and monetary incentives in contributing to the recognition 118\nof science-related content on social media. We conducted two pre-registered experiments 119\nwhere participants observed and interacted with one out of several Facebook posts that 120\nlinked to an article presenting science-themed information. Participants were free to 121\nconduct further research on external websites in order to form a more accurate idea of 122\nthe scientific validity of the post. Once satisfied with the information they gathered, 123\nparticipants rated how scientifically valid the claims contained in the post were. To test 124\nfor the usefulness of Civic Online Reasoning techniques, we designed a pop-up that 125\npreceded the post presenting the lateral reading and click restraint strategies 1. The use 126\nof a pop-up ensured that participants processed the content before observing the post, 127\nan approach that has also been adopted in previous research [52]. A pop-up could be 128\neasily adapted in a social media setting as regular reminders with the necessary 129\nprecautions to avoid the reduction of their salience with time [55,56]. To test the effect 130\nof monetary incentives instead, we doubled the participation fee (equivalent to an 131\naverage + \u00a38.40/hour) if participants guessed correctly the validity of the post they were 132\nevaluating. 133\nFig 1. Screenshot of the pop-up presented to participants.\nSeptember 21, 2021 4/31\nExperiment 1 134\nIn Experiment 1, we tested separately the efficacy of pop-up and monetary incentives, 135\nand compared their effects to a control condition with no interventions. To assess that 136\nthe effect of the interventions is effective over the widest possible range of contexts, we 137\nused a set of 9 different Facebook posts varying in various properties, such as the 138\nscientific topic, the source reputation, and its level of factual reporting. The original 139\npre-registration of this experiment can be retrieved from osf.io/gsu9j. 140\nMaterials and methods 141\nParticipants 142\nWe recruited 2700 U.K. residents through the online platform prolific.co on 11 March 143\n2021 (for a rationale of sample size, see S1 Methods). All participants gave their 144\ninformed consent for participating in the experiment. Average age was 36 ( SD= 13:5, 8 145\nnot specified), 60.7% of participants were female, (39.1% male, 0.2% other), and 55.6% 146\nhad a Bachelor's degree or higher. Although recruitment explicitly specified that the 147\nexperiment was supported only on computers or laptops, 316 participants (11.7%) 148\ncompleted the experiment on a mobile device. As our hypotheses were based on the 149\nassumption that search would happen on a computer, both stimuli and measures were 150\nnot designed for mobile use. We therefore had to exclude these participants from the 151\nanalyses. Analyses were thus conducted on 2384 participants. 152\nDesign 153\nWe conducted the experiment on Qualtrics and lab.js [57]. During the experiment, 154\nparticipants observed and were able to interact with one out of several Facebook-like 155\nposts (Fig 2 shows three examples; click here for an interactive example from 156\nExperiment 2). Participants' task was to rate the scientific validity of the statements 157\nreported in the title, subtitle, and caption of the post (\"how scientifically valid would 158\nyou rate the information contained in the post?\"; 6-point likert scale from (1) 159\n\"definitely non-valid\" to (6) \"definitely valid\"). Researchers rated independently the 160\nscientific validity of the posts' content in terms of valid/invalid according to 161\npre-specified criteria (see S3 Methods). Participants could take as much time as they 162\nwanted in giving their rating. Crucially, participants were also explicitly told that they 163\nwere allowed to leave the study page before evaluating the post. After the rating, 164\nparticipants completed a questionnaire and were paid \u00a30.70 for their time. Median 165\ncompletion time of the experiment was 5 minutes. 166\nExperimental conditions. Participants were randomly assigned to one of three 167\nexperimental conditions: control, incentive, and pop-up. In the control condition, 168\nparticipants completed the task as described above. In the incentive condition, 169\nparticipants were doubled their participation fee if their rating matched that given by 170\nthe experimenters. Unbeknownst to participants, the correctness of the answer depended 171\nonly on whether the answer was valid or invalid, and not on the extremity of the answer 172\n(e.g. having answered 4 instead of 5), even though we selected unambiguously valid or 173\ninvalid content. In the pop-up condition, presentation of the post was preceded by a 174\npop-up (Fig 1) presenting a list of civic online reasoning techniques (e.g., lateral reading, 175\nclick restraint) as tips to verify the information in the post. 176\nStimuli. Each participant observed one out of nine possible Facebook posts (Fig 2; 177\nsee S1 File for a full list). Posts varied in terms of: (i) scientific validity of the content 178\n(i.e., six valid and three invalid posts, either with verified or debunked information; S3 179\nMethods); (ii) topic (i.e., three on climate change, three on the coronavirus pandemic, 180\nthree on health and nutrition); (iii) factual reporting of the source, based on ratings 181\nSeptember 21, 2021 5/31\nfrom mediabiasfactcheck.com (i.e., three high/very high versus six low/very low); (iv) 182\nsource reputation, as measured in a screening survey (S4 Methods; three categories: 183\ntrusted (2 posts), distrusted (4), unknown source (3)). Posts were balanced to have 184\nthree posts for each topic, one from a source with high factual reporting displaying valid 185\ninformation, one from a source with low factual reporting displaying valid information, 186\nand one from a source with low factual reporting displaying invalid information. 187\nFig 2. Examples of the stimuli presented, varying in topic (Climate Change, Health and\nNutrition, COVID-19), factual reporting (high, low, low), scientific validity (high, low, low),\nand source reputation (trusted, untrusted, unknown source).\nWe standardised emoji reactions across all posts to control for their influence. In 188\naddition, post date, number of reactions and shares were blurred. The rest of the post 189\nwas instead accessible to the participant, who could click on different links to access the 190\nsource Facebook page, the original article, and the Wikipedia page (if present). Text 191\nand image were taken from the article. Captions were short statements of a scientific 192\nnature, i.e. facts or events pertaining to some scientific mechanism. 193\nMeasures 194\nAccuracy. We computed two measures of accuracy{correct guessing and accuracy 195\nscore. Correct guessing refers to a dichotomous variable that tracks whether participant 196\ngave a 'valid' (vs. 'invalid') rating when the post content was actually scientifically valid 197\n(vs. invalid). Accuracy score instead is a standardised measure ranging from zero to one, 198\nwith 0 indicating an incorrect \"1\" or \"6\" validity rating, 0.2 indicating an incorrect \"2\" 199\nor \"5\" rating, 0.4 an incorrect \"3\" or \"4\" rating, 0.6 a correct \"3\" or \"4\" rating, 0.8 a 200\ncorrect \"2\" or \"5\" rating, and 1 a correct \"1\" or \"6\" rating. Accuracy score allows to 201\ndistinguish validity evaluations that are associated with different behaviours: for 202\ninstance, not all participants would be willing to share content that they rated as 4 in 203\nterms of scientific validity. In addition, accuracy score is statistically more powerful 204\nthan correct guessing as it includes more possible responses [58]. We thus considered 205\naccuracy score as our main index. 206\nSearch behaviour. During the evaluation of the post, we tracked participants' 207\nbehaviour on the study page. We measured the time spent both inside and outside the 208\npage, and a series of dummy variables tracking whether participants had clicked on any 209\nof the links present (e.g., Facebook page, article page, Wikipedia page). Based on these 210\ncalculations we were able to estimate participants' response times and search behaviour. 211\nCivic Online Reasoning. After having rated the scientific validity of the post, 212\nparticipants completed a questionnaire investigating those factors that could have 213\ninfluenced their choice. In order to test our hypotheses, we asked participants whether 214\nthey engaged in lateral reading and click restraint. Participant were said to have used 215\nlateral reading if they reported having searched for information outside the study page 216\nSeptember 21, 2021 6/31\n(yes/no question), and if they specifically searched on a search engine among other 217\ndestinations (multiple selection question). Participants were said to have used click 218\nrestraint if they further reported looking beyond the first results suggested by the 219\nsearch engine (multiple choice question). Critically, questions were formulated in such a 220\nway as to avoid any expectation as to which answer to select, and thus reduce the 221\ninfluence of the experimenter. 222\nControl measures. In addition to measures of accuracy and civic online reasoning, 223\nwe included a series of control measures for our analyses (S5 Methods). Other questions 224\nincluded self-report measures of confidence in the validity rating, plausibility of the post 225\ncontent, subjective relevance of obtaining accurate information about the post, 226\nfamiliarity with the source, perceived trustworthiness of the source, subjective 227\nknowledge of the topic, trust in scientists, conspiratorial beliefs, and a scientific literacy 228\ntest. In addition to responses in the questionnaire, we obtained information about 229\nparticipants from the recruiting platform, such as their level of education, 230\nsocio-economic status, social media use, and belief in climate change. 231\nAnalyses 232\nStatistical tests were conducted using base R [59]. We adopted the standard 5% 233\nsignificance level to test against the null hypotheses. All tests were two-tailed unless 234\notherwise specified. Post-hoc tests and multiple comparisons were corrected using the 235\nBenjamini-Hochberg procedure. Non-parametric statistics were log-transformed for 236\nconciseness. For probability differences, the lower boundary indicates the 2.5% quantile 237\nof the effect of the target variable starting from the 2.5% quantile of the baseline 238\nprobability estimate, whereas the upper boundary indicates the 97.5% quantile of the 239\neffect of the target variable starting from the 97.5% quantile of the baseline probability 240\nestimate. Given the small number of stimuli ( N < 10), we do not cluster errors by 241\nFacebook post in our regression analyses. The use of random effects yields however 242\ncomparable results in magnitude and statistical significance unless otherwise reported. 243\nResults 244\nParticipant randomisation was balanced across conditions (Chi squared test, 245\n\u001f2(2) =:016,p=:99). Median time to evaluate the Facebook post was 33 seconds in 246\nthe control condition (incentive condition: 45 seconds; pop-up condition: 35 seconds; 247\nminimum overall time: 2 seconds, maximum overall time: 40 minutes). In the pop-up 248\ncondition, participants spent an additional median time of 11 seconds on the pop-up. On 249\na scale from 1 to 6 (3.5 response at chance level), average accuracy score in the control 250\ncondition was 4.35 ( SD= 1:20; incentive condition 4.48, SD= 1:32; pop-up condition 251\n4.35,SD= 1:19). In the control condition, 78.2% of participants correctly guessed the 252\nscientific validity of the post (incentive condition: 80.1%; pop-up condition: 78.1%). 253\nEffect of interventions 254\nTo test the effect of our interventions on accuracy, we adopted two tests, one for the 255\naccuracy scores, and one for correct guessing (original preregistered analyses are 256\npresented in S1 Analyses). Since accuracy scores were clearly non-normally distributed 257\n(Shapiro-Wilk test, all p<: 001), we used an ordinal logistic regression in place of the 258\nlinear regression to test the effect of condition on accuracy scores. Results showed a 259\nsignificant effect of incentive ( \f=:293 [:092;:494],z= 3:225,p=:003) and a lack of 260\nsignificance for the pop-up ( \f=\u0000:009 [\u0000:207;:188],z=\u00000:103,p=:918). According 261\nto the model, the probability of giving a \"definitely valid\" (\"definitely invalid\") correct 262\nSeptember 21, 2021 7/31\nresponse increases by 4.4% [1.5%,8.2%] in the incentive condition compared to the 263\ncontrol condition. 264\nTechnique adoption 265\nTo compare the adoption of Civic Online Reasoning techniques between experimental 266\nconditions (pre-registered hypothesis 2) we used a logistic regression with technique use 267\n(adoption of both lateral reading and click restraint) as predicted variable and 268\nexperimental condition as predictor. Results revealed that both incentive and pop-up 269\nincreased technique adoption (Fig 3; incentive: \f= 1:042 [:527;1:556],z= 4:728, 270\np<: 001; pop-up: \f= 1:556 [1:065;2:046],z= 7:405,p<: 001), but that the increase 271\nwas markedly higher with the presence of the pop-up than with monetary incentives 272\n(\f=:514 [:157;:871],z= 3:362,p<: 001). 273\nArticle \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%20%30%40%\n50%60%70%80%90%Article \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%20%30%40%\n50%60%70%80%90%Article \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%controlpop-upincentive\nFig 3. Race chart of self-report external search behaviour. Bars indicate the proportion of\nparticipants in each experimental condition reporting to have searched in either category of\nwebsites. Lateral reading is identified with the proportion of participants searching information\non a search engine (light red), whereas click restraint is the subset of these participants who\nreported not stopping at the first algorithmically-ranked results of the search (dark red).\nSince our measure of technique use is based on self-reporting, responses might have 274\nbeen biased by external expectations. We therefore checked whether participants who 275\nreported the use of techniques actually left the study by tracking their behaviour on the 276\npost's web page. According to our measures, 80% of these participants left the study in 277\nthe control condition, compared to 87% in the pop-up and 90% in the incentive 278\nconditions. This result, if anything, suggests that our interventions did not increase the 279\nrate of false reporting. Moreover, even after accounting for false reports, results did not 280\ndiffer (incentive: \f= 1:156 [:594;1:719],z= 4:791,p<: 001; pop-up: \f= 1:626 281\n[1:087;2:166],z= 7:024,p<: 001; pop-up >incentive:\f=:467 [:095;:845],z= 2:920, 282\np=:004; see sections S2 Analyses and S6 Analyses for an in-depth exploration of 283\nparticipants' search behaviour). 284\nDid the use of lateral reading and click restraint actually improve post evaluation? 285\nAnd did the use of techniques mediate the effect of our interventions? To test our first 286\nquestion, we ran an ordinal logistic regression with accuracy score as predicted variable, 287\nand a standard logistic regression with correct guessing as predicted variable, both tests 288\nincluding adoption of techniques as the sole predictor. Results showed that accuracy 289\nscore improved significantly if a participant reported using Civic Online Reasoning 290\ntechniques ( \f=:526 [:274;:778],z= 4:090,p<: 001). According to the model, the use 291\nof Civic Online Reasoning Techniques increased the probability of giving a \"definitely 292\nvalid\" (\"definitely invalid\") correct response by 8.8% [4.0%,14.7%]. This result however 293\nwas not confirmed by the standard logistic regression on correct guessing, which instead 294\nSeptember 21, 2021 8/31\nfound no significant effect of technique adoption ( \f=:219 [\u0000:121;:580],z= 1:228, 295\np=:220). 296\nBased on these results, we proceeded to test whether pop-up and incentives had 297\nsome mediated impact on accuracy score through technique adoption. To test mediation 298\nwe used the R package MarginalMediation [60]. Technique adoption was found to 299\nmoderate the effect of both incentive and pop-up on accuracy score (incentive: 300\nunstandardised \f=:004 [:001;:006],z= 4:728,p<: 001; pop-up: unstandardised 301\n\f=:007 [:003;:012],z= 7:405,p<: 001), suggesting that both interventions affected 302\nindirectly accuracy scores. 303\nResponse times 304\nAs we expected monetary incentives to increase motivation, we tested whether response 305\ntimes (a common proxy for increased deliberation and attention) were affected by our 306\ninterventions. We compared participants' evaluation time of the post across conditions 307\nby way of a Kruskal-Wallis rank sum test. The test was significant ( \u001f2(2) = 67:63, 308\np<: 001), thus we conducted post hoc comparisons. All comparisons were significant, 309\nwith participants in the incentive condition taking significantly more time than control 310\n(log(V) = 8:02,p<: 001) and pop-up (log( V) = 5:54,p<: 001) participants, and 311\npop-up participants taking more time than control (log( V) = 2:41,p=:016). 312\nWe tested whether longer evaluation times predicted higher accuracy scores by 313\nmeans of an ordinal logistic regression with log-transformed evaluation time as predictor 314\nand accuracy score as predicted variable. Results revealed a significant and positive 315\nassociation ( \f=:182 [:095;:268],z= 4:12,p<: 001). The result was confirmed also for 316\ncorrect guessing (logistic regression, \f=:242 [:120;:366],z= 3:87,p<: 001). 317\nWe additionally looked at how much time participants spent outside the study page 318\nwhen they left without clicking any link (a proxy of lateral reading). The Kruskal-Wallis 319\ntest was again significant ( \u001f2(2) = 13:482,p=:001): of those participants who 320\nperformed such external searches, control participants spent less time outside the page 321\nthan participants in both the incentive (log( V) = 2:85,p=:006) and the pop-up 322\nconditions ( log(V) = 3:58,p=:001), whereas we found no significant difference between 323\nincentive and pop-up (log( V) =:92,p=:360). 324\nSource reputation 325\nCivic Online Reasoning techniques were originally designed for helping to evaluate 326\ncontent from seemingly legitimate but unknown websites [39]. We thus analysed 327\ndifferences in our interventions based on the recognisability and perceived 328\ntrustworthiness of the posts' sources. The importance of a source's perceived 329\ntrustworthiness was exemplified by two posts covering the same scientific article, one 330\nfrom BBC News (a source trusted by most participants), and another one from the 331\nDaily Mail (a source barely trusted by most participants). Despite the posts covered the 332\nsame content and presented similar wording, participants' evaluation of the two posts 333\ndiffered considerably: average accuracy score was 4.7 for the BBC piece ( SD= 1:05) 334\nand 4.05 for the Daily Mail piece ( SD= 1:08; ordinal regression: \f= 1:255 [:926;1:584], 335\nz= 7:470,p<: 001), and the proportion of correct guesses was 90.7% and 77.3%, 336\nrespectively (logistic regression: \f= 1:059 [:568;1:576],z= 4:132,p<: 001). 337\nPerhaps not surprisingly, we observed that, in the pop-up condition, adoption of 338\nlateral reading and click restraint was strongly linked with source type (Chi squared test 339\nwith technique adoption and source category as variables, \u001f2(2) = 15:407,p<: 001): 340\nwhen the source was trusted, only 6.7% of participants used these techniques, whereas 341\nthe proportion was 20% when the source was unknown. We then tested differences of 342\nthe interventions by source type in accuracy scores and correct guessing. 343\nSeptember 21, 2021 9/31\nLikelihood-ratio tests confirmed the importance of this variable for both analyses 344\n(p<: 001), however family-wise corrected contrasts revealed only one significant result, 345\nthe effect of incentive on accuracy scores for unknown sources ( \f=:558 [:114;1:001], 346\nz= 3:445,p=:005; Fig 4; see S4 Analyses for results about the uncorrected contrasts). 347\n*****\n*control\nincentivepop-up4.37\n4.624.53*\n*random responseincentivecontrol\npop-up\n4.34.16\n4.15control\nincentivepop-up4.69\n4.624.52unknown distrusted trusted\n3 4 5 6\naccuracy scoreSource reputation\nFig 4. Bootstrap estimates of the average accuracy score by experimental condition and\nsource reputation (Min. 1, Max. 6, random response: 3.5). Asterisks refer to significance of\ncontrasts in the ordinal logistic regression. Black: family-wise corrected contrasts; dark grey:\nuncorrected contrasts. *: p < : 05; **: p < : 01; ***: p < : 001.\nDiscussion 348\nResults from Experiment 1 suggest that paying participants to be accurate does 349\nincrease the accuracy score but not the proportion of participants correctly guessing the 350\nscientific validity of the posts. Compared to control, participants with an incentive gave 351\nmore extreme answers, reported engaging in Civic Online Reasoning techniques more 352\noften (and did leave the page more often), spent more time in searching information 353\noutside the study page, and took longer to evaluate the post (even compared to pop-up 354\nparticipants). These results support the idea that monetary incentives affect accuracy, 355\npossibly by increasing motivation and attention in the task, although this hypothesis 356\nwould need further testing. 357\nBy contrast, the presence of the pop-up seemed not to affect directly any indicator 358\nof accuracy. In spite of that, participants in the pop-up condition reported more lateral 359\nreading and click restraint, as well as the frequency of searches outside the study page. 360\nIn turn, this increment of Civic Online Reasoning techniques (up to +13.5% when 361\nsource is unknown) seems to mediate a small but significant increase in accuracy scores 362\n(marginal mediation analysis), suggesting an indirect effect of the pop-up. An effect of 363\npop-up is possibly seen in posts produced by unknown sources, where correct guessing 364\n(but not accuracy scores) is slightly higher in the pop-up condition than in control (S4 365\nAnalyses). 366\nSeptember 21, 2021 10/31\nThese results suggest that monetary incentives might have more consistent effects 367\nover the presentation of Civic Online Reasoning techniques. At the same time, we 368\nobserve considerable variability in participants' behavior depending on specific features 369\nof the posts. For instance, source reputation seems to have a remarkable effect on the 370\nadoption of Civic Online Reasoning techniques, which were (foreseeably) overlooked by 371\nalmost all participants when looking at posts from generally trusted sources. 372\nOne potential takeaway from these findings is that some initial biases might affect 373\nthe rate at which participants look for information outside the content provided (e.g. 374\nfamiliarity and opinion about the source), as well as in the way they look for such 375\ninformation. To explore this possibility, we designed a second experiment in which we 376\ntried to reduce the presence of initial biases by presenting posts from generally unknown 377\nsources. In addition, we included a fourth condition where we test the combination of 378\nmonetary incentives and Civic Online Reasoning techniques, to explore whether and 379\nhow the two interact. 380\nExperiment 2 381\nIn line with evidence in the literature, we expected an increased impact of our 382\ninterventions in a context where participants could rely on less prior information. We 383\nthus conducted a second experiment that was statistically powered to test for this 384\npossibility. In the Experiment 2 we replicated the format of the first one, with two main 385\nmodifications: 1) we ran a pre-screening survey to identify lesser-known sources of 386\ninformation and only used those sources as the basis for the Facebook posts the 387\nparticipants were asked to evaluate; 2) we added an experimental condition that 388\nincluded both incentive and pop-up interventions, to test the interaction between the 389\ntwo. we advanced the idea that the two intervention strategies might trigger distinct 390\nbehavioral outcomes (i.e., increased time spent on the task and use of Civic Online 391\nReasoning). If this is the case, then combining the two interventions should produce 392\neven stronger effects on accuracy. The original pre-registration of this experiment can 393\nbe retrieved from osf.io/w9vfb. 394\nMaterials and methods 395\nParticipants 396\n3004 U.K. residents were recruited through the online platform prolific.co on 24 May 397\n2021 (for a rationale of sample size, see S2 Methods). All participants gave their 398\ninformed consent for participating in the experiment. Average age was 36 ( SD= 13:2, 6 399\nnot specified), 63.1% of participants were female, (36.7% male, 0.2% other), and 59.4% 400\nhad a Bachelor's degree or higher. Per our pre-registered criteria, we excluded one 401\nparticipant who was not a resident in the United Kingdom. Analyses were thus 402\nconducted on 3003 participants. 403\nDesign 404\nThe second experiment was a replication of the first one, with the major difference that 405\nsources of the Facebook posts were unknown to most participants. In addition, we 406\nincluded a fourth condition where we gave participants a monetary incentive and also 407\nshowed them the pop-up with the Civic Online Reasoning techniques. Thus, the 408\nexperiment had a between-subjects design with 2 factors, pop-up (present, absent) and 409\nmonetary incentive (present, absent). Median completion time of the experiment was 5 410\nminutes. 411\nSeptember 21, 2021 11/31\nStimuli 412\nParticipants observed one out of 6 posts that vared in terms of: the scientific validity of 413\nthe content, i.e. the validity of the scientific statements in the title, subtitle, and 414\ncaption of the post; the topic (climate change, coronavirus pandemic, and health and 415\nnutrition); factual reporting of the source, based on ratings from 416\nmediabiasfactcheck.com (3 high/very high versus 3 low/very low). All posts came from 417\nsources relatively unknown to participants, as measured in a preliminary survey and 418\nconfirmed by participants' familiarity ratings. There were two distinct posts for each 419\ntopic, one from a source with high factual reporting displaying valid information, one 420\nfrom a source with low factual reporting displaying invalid information. 421\nSome titles, subtitles and captions of the posts included references to governmental 422\nor academic institutions. To prevent that these references could affect the evaluation of 423\nthe content, we slightly rephrased some sentences to remove this information. In 424\naddition, we corrected also grammatical mistakes in the text that could have given away 425\nthe reliability of the source. 426\nResults 427\nParticipant randomisation was balanced across conditions (Chi squared test, 428\n\u001f2(1) =:409,p=:52); average N per post, per condition was 125, minimum 106, 429\nmaximum 146. Median time to evaluate the Facebook post was 33 seconds in the 430\ncontrol condition, 48 seconds in the incentive condition, 34 seconds in the pop-up 431\ncondition, and 58 seconds in the incentive + pop-up (minimum overall time: 2.5 432\nseconds, maximum overall time: 22 minutes). When the pop-up was present, 433\nparticipants spent an additional median time of 11 seconds on the pop-up. On a scale 434\nfrom 1 to 6 (3.5 response at chance level), average accuracy score in the control 435\ncondition was 3.96 ( SD= 1:33; incentive condition: 4.20, SD= 1:41; pop-up condition: 436\n4.07,SD= 1:33; incentive + pop-up: 4.29, SD= 1:44; Fig 5). In the control condition, 437\n64.6% of participants correctly guessed the scientific validity of the post (incentive 438\ncondition: 71.2%; pop-up condition: 66.2%; incentive + pop-up: 72.9%). Overall 439\nperformance was generally lower than in Experiment 1, most likely due to the use of 440\nrelatively unknown news sources that forces participants not to rely on source 441\nknowledge to evaluate content. 442\nEffect of interventions 443\nTo test the individual and combined effects of pop-up tips and monetary incentives we 444\nconducted two tests, one for each accuracy index. For accuracy scores, We used two 445\nordinal logistic regression models, one with pop-up, monetary incentive as predictors, 446\nand another regression including the same variables and the interaction between pop-up 447\nand incentive as an additional predictor. For correct guessing, we compared two logistic 448\nregressions, one with correct guessing as dependent variable and pop-up, monetary 449\nincentive as predictors, and another regression including the same variables and the 450\ninteraction between pop-up and incentive as an additional predictor. For both the 451\nindices, we then adopted the model fitting data best according to a likelihood-ratio test. 452\nPerhaps surprisingly, model comparison favoured models without the interaction term 453\n(accuracy score: \u001f2(1) =:032,p=:858; correct guessing: \u001f2(1) =:007,p=:931); we 454\nthus tested the effect of incentives and pop-up assuming that they are (approximately) 455\northogonal. Results revealed a significant effect of incentive on both accuracy scores 456\n(\f=:350 [:194;:505],z= 5:371,p<: 001) and correct guessing ( \f=:313 [:124;:501], 457\nz= 3:954,p<: 001), and a significant effect of pop-up on accuracy scores ( \f=:137 458\nSeptember 21, 2021 12/31\n[\u0000:018;:292],z= 2:115,p=:034)1, but not on correct guessing ( \f=:076 [\u0000:018;:292], 459\nz= 0:966,p=:334). In addition, we found that the combination of the two 460\ninterventions significantly increased both accuracy indices compared to control 461\n(accuracy score: \f=:487 [:268;:705],z= 5:315,p<: 001; correct guessing: \f=:389 462\n[:123;:654],z= 3:496,p<: 001), and that the contribution of incentive was greater than 463\nthe contribution of pop-up (accuracy score: \f=:213 [\u0000:007;:432],z= 2:307,p=:028; 464\ncorrect guessing: \f=:2362 [\u0000:032;:504],z= 2:103,p=:047). According to the ordinal 465\nlogistic regression model, the combination of the two interventions led to a 10.4% 466\n[5.4%,14.2%] increase in correct guessing, and a 6.9% [2.8%,12.4%] increase in 467\n\"definitely\" correct responses compared to control. 468\n*\n**** ***random responsecontrol\npop-up\nincentive\npop-up +\nincentive4.073.97\n4.294.2\n3 4 5 6\naccuracy score\nFig 5. Bootstrap estimates of the average accuracy score by experimental condition (Min. 1,\nMax. 6, random response: 3.5). Asterisks refer to significance of contrasts in the ordinal\nlogistic regression. *: p < : 05; **: p < : 01; ***: p < : 001.\nTechnique adoption 469\nWe tested whether technique adoption was influenced by either interventions following a 470\nsimilar procedure to our test for correct guessing (comparison of two logistic regressions 471\nwith/without interaction). likelihood-ratio tests again favoured the model without 472\ninteraction ( \u001f2(1) =:245,p=:621). Model contrasts revealed several significant 473\ndifferences (Fig 6): both incentive ( \f=:725 [:471;:978],z= 6:829,p<: 001) and 474\npop-up (\f= 1:191 [:926;1:455],z= 10:736,p<: 001) increased significantly the use of 475\nCivic Online Reasoning techniques, but pop-up effect was significantly stronger than the 476\neffect of the incentive ( \f=:466 [:106;:826],z= 3:093,p=:002). In addition, the 477\ncombined effect of pop-up and incentive was also significant ( \f= 1:915 [1:542;2:288], 478\nz= 12:263,p<: 001), leading to an estimated 16.5% [8.6%,26.0%] increase in technique 479\nuse compared to control. 480\nTo test the robustness of these findings, we checked as in Experiment 1 the rate of 481\nfalse reporting (i.e., participants who said they used fact-checking techniques while they 482\ndid not even leave the study page). False reporting was 22.2% in the control condition, 483\n16% in the pop-up condition, 15.3% in the incentive condition, and 12.8% in the 484\ncondition with both interventions. The results did not differ after accounting for false 485\nreporting (pop-up: \f= 1:210 [:924;1:496],z= 10:094,p<: 001; incentive: \f=:761 486\n[:488;1:033],z= 6:669,p<: 001; pop-up>incentive: \f=:449 [:061;:838],z= 2:759, 487\np=:006; pop-up + incentive: \f= 1:971 [1:570;2:372],z= 11:729,p<: 001; see S8 488\nAnalyses for an exploration of participants' search behaviour). 489\n1Mixed-effects regression with errors clustered by post: p=:052.\nSeptember 21, 2021 13/31\nArticle \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%incentivepop-up + incentivecontrolpop-upFig 6. Race chart of self-report external search behaviour. Bars indicate the proportion of\nparticipants in each experimental condition reporting to have searched in either category of\nwebsites. Lateral reading is identified with the proportion of participants searching information\non a search engine (light red), whereas click restraint is the subset of these participants who\nreported not stopping at the first algorithmically-ranked results of the search (dark red).\nTo test whether participants who adopted civic online reasoning techniques 490\nperformed better in the task we run two tests, one for each accuracy index. For 491\naccuracy scores, since accuracy scores were non-normally distributed (Shapiro-Wilk test, 492\nallp<: 001) we used a ordinal logistic regression model, with accuracy score as 493\ndependent variable and adoption of techniques as a dummy predictor variable. For 494\ncorrect guessing, we used a logistic regression, with correct guessing as dependent 495\nvariable and adoption of techniques as a dummy predictor variable. According to the 496\nmodels, participants adopting Civic Online Reasoning techniques were more accurate in 497\nterms of both accuracy score ( \f=:591 [:414;:767],z= 6:560,p<: 001) and correct 498\nguessing (\f=:506 [:281;:738],z= 4:345,p<: 001). According to the ordinal regression 499\nmodel, technique adoption increased the probability of giving a \"definitely valid\" 500\n(\"definitely invalid\") correct response increases by 9.5% [5.9%,13.7%]. 501\nWe also tested whether the use of Civic Online Reasoning techniques mediated the 502\neffect of the interventions with two marginal mediation analyses on accuracy score and 503\nSeptember 21, 2021 14/31\ncorrect guessing. Technique adoption was found to moderate the effect of both incentive 504\nand pop-up on accuracy score (incentive: unstandardised \f=:007 [:003;:010], 505\nz= 6:829,p<: 001; pop-up: unstandardised \f=:011 [:006;:015],z= 10:736,p<: 001) 506\nand correct guessing (incentive: unstandardised \f=:008 [:004;:013],z= 6:829, 507\np<: 001; pop-up: unstandardised \f=:014 [:007;:021],z= 10:736,p<: 001). 508\nResponse times. 509\nWe compared participants' evaluation time of the post across conditions using linear 510\nregressions with rank-transformed time as dependent variable and pop-up and 511\nincentives as predictors, with and without interaction. Again, model comparison 512\nfavoured the model without interaction ( F(1) = 1:104,p=:293). All contrasts were 513\nsignificant: both incentives ( \f= 370 [297;443],t(2928) = 12 :127,p<: 001) and pop-up 514\n(\f= 61 [\u000012;134],t(2928) = 2:011,p=:044) increased evaluation times, however 515\nincentives did so to a greater extent ( \f= 309 [205;413],t(2928) = 7:105,p<: 001). 516\nAlso, the combination of incentives and pop-up led to higher evaluation times than 517\ncontrol (\f= 431 [329;534],t(2928) = 10 :070,p<: 001). We tested whether longer 518\nevaluation times were associated with higher accuracy scores by means of an ordinal 519\nlogistic regression with log-transformed evaluation time as predictor and accuracy score 520\nas predicted variable. Results revealed a significant and positive association association 521\n(\f=:152 [:081;:223],z= 4:22,p<: 001). The result was confirmed also for correct 522\nguessing (logistic regression, \f=:204 [:117;:292],z= 4:56,p<: 001). We also 523\ncompared the duration of non-click external searches across conditions with the same 524\nprocedure as total evaluation times, again finding no interaction between interventions 525\n(F(1) = 0:1746,p=:676). Results showed a significant effect of incentive ( \f= 52 526\n[15;90],t(726) = 3:355,p=:001), pop-up ( \f= 80 [43;116],t(726) = 5:170,p<: 001), 527\nand their combination ( \f= 132 [80;184],t(726) = 6:100,p<: 001), but found no 528\nsignificant difference between the interventions ( \f= 27 [\u000026;80],t(726) = 1:217, 529\np=:224). 530\nDiscussion 531\nResults from Experiment 2 confirmed the effectiveness of monetary incentives on 532\naccuracy, and presented evidence in favour of the potential usefulness of fact-checking 533\ntips when the post's source is unknown. Monetary incentives increased both accuracy 534\nscores and correct guessing, the rate of (self-reported) Civic Online Reasoning 535\ntechniques, as well as the frequency and duration of non-link searches outside the study 536\npage. Participants offered with a monetary incentive spent more time evaluating the 537\npost than those who were not. Lastly, incentives seemed to increase the sharing 538\nintentions of valid information compared to control (S11 Analyses). 539\nContrary to the Experiment 1, the pop-up intervention seems to increase accuracy 540\nscores, but not correct guessing. We observed that the presence of the pop-up 541\ndramatically increased technique adoption (even compared to the presence of incentives) 542\nand the rate of non-link external searches, which in turn were linked to an increase in 543\nboth measures of accuracy. Marginal mediation analyses confirm an indirect effect of 544\npop-up on accuracy measures via an increase of search outside the post page. 545\nIn this experiment, we also tested the interaction between incentive and pop-up. 546\nModel comparison showed no interaction between the two interventions, suggesting that 547\npop-up and monetary incentives contributed separately to the increase in accuracy. We 548\nadditionally observe that monetary incentives increased participants' time spent on 549\nreading the pop-up: median time is 12.3 seconds with incentive compared to 9.6 when 550\nincentive is absent (S7 Analyses). Despite this increase in reading times, our statistical 551\ntests do not detect an increased pop-up effects by any other metric. 552\nSeptember 21, 2021 15/31\nGeneral Discussion 553\nIn this research, we studied whether presenting fact-checking tips and monetary 554\nincentives increases the correct evaluation of science-themed Facebook posts. In two 555\nexperiments, participants rated the scientific validity of the content of one out of several 556\nposts, with some participants receiving a monetary reward when they responded 557\ncorrectly and other participants being shown a pop-up window (superimposed on the 558\nFacebook post itself) that contained a list of fact-checking techniques proposed in the 559\nliterature (Civic Online Reasoning). Results showed that monetary incentives work as 560\nan accuracy booster. Moreover, data on search times and extremity of validity ratings 561\ncorroborated the hypothesis that incentives operate by increasing motivation and, 562\nsubsequently, attention on the content and other features of the post. This effect is 563\nparticularly remarkable given the strong benchmark against which it was compared: in 564\nfact, participants in the control condition were already primed for accuracy [30], and are 565\ntherefore likely to exert a greater degree of attention than when routinely browsing 566\nsocial media. The effectiveness of the pop-up as a way of introducing participants to 567\nfact-checking techniques received support in cases where the source of the post was 568\nrelatively unknown, i.e. when participants could rely on low prior information to 569\nevaluate posts. Furthermore, given that the presence of the pop-up significantly 570\nincreases the adoption of Civic Online Reasoning techniques, and that the use of these 571\ntechniques is, in turn, a strong predictor of participants' performance on the task, 572\nmarginal mediation analyses support the hypothesis that the pop-up may have an 573\nindirect positive effect on performance. 574\nOne of the original aims of this study was to establish whether incentives and 575\ntechniques could be compared in their effectiveness in improving the evaluation of 576\nscientific content, even when not directly accessible without technical expertise. In this 577\nrespect, our results suggest that the presence of the pop-up has less impact on 578\nsubsequent evaluation than monetary incentives. We suspect that the effectiveness of 579\nfact-checking advice may be hampered by several factors. A first explanation is that the 580\nadoption of the techniques might not have been effective enough to avoid the influence 581\nof previous beliefs about the content or of the search style. For example, if participants 582\nconsidered a content to be plausible in the first place, they might have selectively 583\nignored conflicting information even when it was clearly present in the search results 584\n(i.e. confirmation bias [61]); similarly, if a participant relied primarily on certain sources 585\nof information, consulting these sources might have steered the interpretation in the 586\nwrong direction. It is unclear however how such biases might have meaningfully reduced 587\nthe effectiveness of the pop-up but not of the monetary incentives. A second possibility 588\nis that participants failed to follow click restraint recommendations and did not search 589\ndeep enough to find relevant information and instead relied on unreliable sources 590\nfavoured by ranking algorithms. Lastly, the reduced impact of the pop-up may derive 591\nfrom its brevity: Civic Online Reasoning techniques have in fact been tested so far after 592\nbeing taught in extensive courses. It is therefore possible that simply presenting a 593\ncondensed set of tips on the best techniques is not enough to fully understand and 594\nmaster them. This possibility is in line with similar unsuccessful previous interventions 595\npresenting news literacy tips [35,55,62]. Thus, true ability to recognise pseudo-scientific 596\ninformation might only come from a minimal mastery of critical-thinking skills, which 597\ncannot be achieved by simply adding a snippet of information to a post, in the form of a 598\npop-up. Testing whether critical-thinking skills learned in the appropriate context can 599\nboost people's capacity to spot pseudo-scientific information is however problematic, 600\ndue to the subjective nature of critical thinking courses and their instructors in a virtual 601\nor physical classroom setting. 602\nDespite the asymmetric contribution of monetary incentives and fact-checking 603\ntechniques, our results also indicate that the interventions may work in a 604\nSeptember 21, 2021 16/31\ncomplementary way. In particular, Experiment 2 shows that these two interventions do 605\nnot appear to interact with each other. This result, which was replicated by testing 606\ndifferent variables of interest, suggests that the working mechanisms of the interventions 607\nare largely orthogonal, and thus can be combined to achieve an even stronger evaluation 608\nperformance by participants. 609\nOur results on incentives are in line with an attention-based account of information 610\nprocessing on social media; that is, increased deliberation is sufficient to decrease belief 611\nin false content [4]. Our results add to the literature of attention-based interventions by 612\nshowing how monetary incentives can additionally modulate motivation and attention 613\nand increase performance. 614\nThese promising results were not self-evident, as several experiments have cautioned 615\nagainst the universal effectiveness of monetary incentives as a behavioural driver. 616\n[63{65]. In fact, under some circumstances incentives decrease rather than increase 617\nmotivation [66]. One crucial aspect lies in incentives' calibration, as it has been proven 618\nthat if the effect of incentives on performance is non-monotonic and too small incentives 619\nare often counterproductive [66]. Moreover, when explicit incentives seek to modify 620\nbehaviour in areas such as education, environmental actions, and the formation of 621\nhealthy habits, a conflict arises between the direct extrinsic effect of incentives and how 622\nthese incentives may crowd out intrinsic motivations. Seeking accuracy in judging news 623\nis certainly driven by the intrinsic motivations of individuals. In all likelihood, however, 624\nthese intrinsic motivations do not conflict with monetary incentives. Seeking accuracy, 625\nunlike deliberately adopting ecological behaviour or going on a diet, is a largely 626\nautomatic process. 627\nAnother concern was that motivation and attention might not have been sufficient 628\nfor content that is hardly accessible to non-experts. The effectiveness of incentives is 629\nthen even more remarkable when considering that participants were asked to evaluate 630\ninformation based on scientific and technical reports, and thus had to rely external 631\nknowledge and intuition when claims and data were not immediately available. 632\nCompared to work on Civic Online Reasoning [39], our study finds correlational and 633\ncausal evidence supporting the importance of lateral reading and click restraint as 634\npredictors of accurate information, especially (as initially intended) when the 635\ninformation about the source is scarce. Notably, this is the first reported evidence of a 636\ngeneral population intervention in a social media context, extending the evidence for its 637\napplicability. We note however that the connection between our intervention (the 638\npop-up) and technique use is only indirect, as participants were free to ignore 639\nrecommendations. Stronger evidence for the efficacy of Civic Online Reasoning 640\ntechniques could come from within-subject studies that could limit selectively the use of 641\nthe techniques to assess their direct impact on users' behaviour. 642\nOur results also partly support literature on media and news literacy [34]. Previous 643\nsuccessful attempts at using fact-checking tips relied on presenting participants with 644\nsome of the Facebook guidelines for evaluating information [36,37]. Critically, these tips 645\nacted by reducing post engagement (liking, commenting, sharing) and perceived 646\naccuracy of headlines by hyper-partisan and fake-news sources. Given that our results 647\nhighlight the effectiveness of fact-checking tips when participants are less familiar with 648\nthe source, we suspect that the use of such tips is inversely associated to the knowledge 649\nand reputation of the source: that is, the more the source is well-known and widely 650\nrespected, the less participants will rely on guidelines and recommendations. This 651\ninterpretation goes against previous studies in the literature claiming that source 652\ninformation has little impact on the accuracy judgement of social media content [67 {69]. 653\nAlthough we did not directly test for the presence/absence of source information, we did 654\nfind that familiarity with and trust in a source largely affected the search style and 655\nevaluation of the content, suggesting that providing this information to participants had 656\nSeptember 21, 2021 17/31\na meaningful effect on their validity evaluations. One way to reconcile these apparently 657\nantithetical conclusions is by considering the relative capability of participants to assess 658\nthe plausibility of information: source knowledge can be a viable heuristic when 659\ninformation is harder to evaluate. Indeed, we suspect that in our experiment 660\ninformation about the source was often easier to assess than the plausibility of the 661\ncontent itself. In addition, compared to previous experiments, participants could open 662\nthe original article of the post to confirm that it had actually been produced by the 663\nsource and not fabricated, a factor that probably increased reliance on the source. 664\nThese considerations and our findings are not sufficient to ascertain whether and under 665\nwhat circumstances reliance on the source is beneficial or detrimental; however, we 666\nargue that source information is important in many situations [70,71]. 667\nOur study does not come without limitations. Possibly the most critical issue is the 668\nlimited number of stimuli that were used across experiments (15), which did not allow 669\nus to properly control for many features that could impact the evaluation of the posts. 670\nEven though we cannot exclude confounding variables and biases in the selection of 671\nstimuli, we tried as much as possible to follow a standardised procedure with pre-defined 672\ncriteria in order to exclude stimuli that could be considered problematic. Moreover, 673\neven though most of the literature and the present study have focused on standardised 674\nstimuli reporting content from news sources, we recognize that scientific (dis)information 675\ncomes in several formats that also depend on the topic, the audience, and the strategy 676\nof the creator. We decided to exclude other types of formats (e.g. videos or screenshots) 677\nto try to minimise the differences in experience between users, we think however that 678\nfuture research should explore more in depth the impact of varying media on the impact 679\nof disinformation spread and on possible counteracting interventions. Lastly, the study 680\nexplored the effectiveness of interventions when using a computer, as the very concept 681\nof lateral reading is based on browsing horizontally through internet tabs on a computer. 682\nAlthough nothing precludes the use of such techniques on other devices such as a mobile 683\nphone or tablet, the user interface is often not optimised to search for different contents 684\nat the same time, making their use more cumbersome. This is particularly problematic 685\nconsidering that social media are predominantly accessed through mobile devices. A 686\npromising direction in the fight to disinformation will be to study the influence of the 687\ndevice and UI in the ability of users to access high-quality information. Further studies 688\nshould also investigate how much easiness of accessing information from within a specific 689\napp could prompt users to fact-check what they see. For example, many apps allow to 690\ncheck information on the internet via an internal browser without leaving the app itself. 691\nConclusion 692\nThis study set out to assess the relative effectiveness of monetary incentives and 693\nfact-checking tips in recognising the scientific validity of social media content. We found 694\nstrong evidence that incentivising participants increases accuracy evaluations; we also 695\nfound evidence that fact-checking tips increase accuracy evaluation when the source of 696\nthe information is unknown. These results suggest a promising role of attention and 697\nsearch strategies, and open the way to the test of multiple approaches in synergy to 698\nachieve the most effective results. 699\nSupporting information 700\nS1 File. Facebook posts, Experiment 1. The spreadsheet including the list of 701\nFacebook posts for Experiment 1. 702\nSeptember 21, 2021 18/31\nS2 File. Facebook posts, Experiment 2. The spreadsheet including the list of 703\nFacebook posts for Experiment 2. 704\nS1 Methods. Sample size estimation, Experiment 1. Based on related 705\nfindings in the literature [36], we expected a small effect size (Cohen's d\u0019:15\u0000:20). 706\nAssuming no differences across the posts used as stimuli, and hence computing the 707\nsample size based on the main effect of a one-way ANOVA with three levels 708\n(experimental condition) yielded a minimum sample size of 1269 participants assuming 709\n\u000b= 5% and power (1 \u0000\f) = 90%. Aside from the main contrast, we expected also to 710\nanalyse the impact of secondary variables such as the topic of the post or 711\ntrustworthiness of the source. For this reason, we planned to recruit the maximum 712\nnumber of participants possible given our budget constraints. 713\nS2 Methods. Sample size estimation, Experiment 2. Our target sample size 714\nwas 3000 participants. We based our sample size estimation on the main effect of 715\npop-up on one of the two accuracy indices, correct guessing (analysis: logistic 716\nregression [72]). Estimate of this effect was based on the analyses of the first experiment 717\n(8% increase in correct guesses compared to control). To compute this effect size, we 718\nfiltered observations from the first experiment based on two criteria: the source of the 719\npost had to be unknown to most participants, and participants had to have completed 720\nthe task on a computer. Power 1 \u0000\fwas set to 95% and significance \u000bwas set to 5%. 721\nResults yielded a sample size of n= 733 per condition. We thus decided to recruit 750 722\nparticipants per condition, total N= 3000. 723\nWe further simulated achieved power for pre-registered hypotheses 3, 4 and 5, for 724\nboth accuracy indices (correct guessing and accuracy score). Simulations were based on 725\nN= 3000,\u000b= 5%, and effects sizes estimated from the first experiment.For correct 726\nguessing (test: logistic regression), achieved power is 96% for hypothesis 3 (pop-up main 727\neffect), and 88% for hypothesis 4 (incentive main effect). Combined effect of pop-up and 728\nincentive (hypothesis 5) depends on whether the two interventions interact. Therefore, 729\nwe simulate different scenarios exploring the effect of interaction on power. Results 730\nreveal that to achieve at least 95% power for this contrast, the interaction effect should 731\nnot be less than \u00004% (effect: change in the proportion of correct guesses). For accuracy 732\nscores (test: ordinal logistic regression), achieved power is 51% for hypothesis 3 (pop-up 733\nmain effect), and \u0019100% for hypothesis 4 (incentive main effect). Combined effect of 734\npop-up and incentive (hypothesis 5) depends on whether the two interventions interact. 735\nTherefore, we simulate different scenarios exploring the effect of interaction on power. 736\nResults reveal that to achieve at least 95% power for this contrast, the interaction effect 737\nshould not be less than \u00000.25 (effect: change in log odds). 738\nS3 Methods. Scoring of scientific validity. Sources of scientific information 739\nusually comply with standards approved by the community to guarantee that the 740\ninformation provided is obtained using rigorous methods and goes through several 741\nquality checks. In order for a content to be considered scientifically valid it had to 742\nsatisfy the following requirements: 743\n\u2022the original research could be found in a peer-reviewed publication; 744\n\u2022authors of the research had a track record certifying their expertise in their field 745\nof competence; 746\n\u2022research was not falsified by concomitant research in the field; 747\n\u2022there was no potential conflict of interest, or alternately the content had been 748\nindependently evaluated by a source with no conflicts of interest; 749\nSeptember 21, 2021 19/31\n\u2022the media article represented accurately data and claims of the original research. 750\nS4 Methods. Source familiarity and trustworthiness. Since we suspected that 751\nassessing familiarity and perceived trustworthiness of the source could be affected by 752\nthe observation of the Facebook post, we ran two separate surveys with independent 753\nraters to categorise and select the Facebook posts (first survey: N= 100, mean age 754\nM= 26:5,SD= 7:8, 2 not specified; 71 female, 1 not specified; second survey: 755\nN= 100, mean age M= 33:2,SD= 12:4; 68 female, 2 not specified). Raters were 756\nrecruited on the online platform prolific.co and had to assess the familiarity and 757\ntrustworthiness of several sources using a questionnaire taken from a previous study [20] 758\n(Fig 7). To categorise sources based on the raters' responses, we ran an expectation 759\nmaximisation model-based clustering algorithm using the McLust package in R [73]. 760\nResults revealed four clusters, one collecting known, trustworthy sources ( N= 4; e.g., 761\nNational Geographic and BBC), one known, untrustworthy sources ( N= 5; e.g., Daily 762\nMail and Daily Star), one unknown sources ( N= 21; e.g., Duluth News Tribune and 763\nthe American Enterprise Institute), and a last one including sources with mixed 764\nrecognition ( N= 7, e.g., the Washington Times and Live Science). 765\nS5 Methods. Post-rating questionnaire. After rating the post's scientific validity, 766\nthe participant completed a questionnaire. Below is the full list of questions asked: 767\n\u2022Confidence in rating: \"How confident are you in your response?\"; 6-point likert 768\nscale from (1) \"don't know\" to (6) \"absolutely certain\" 769\n\u2022Sharing intention (Experiment 2): Would you consider sharing this story online 770\n(e.g., through social networks or messaging apps)?; Yes/no 771\n\u2022Sharing behaviour (Experiment 2): Approximately how many news articles, 772\nmemes, opinion pieces, etc. have you shared in the last week?; numeric free-text 773\nresponse 774\n\u2022Source familiarity: \"Did you know [name of source] before the experiment?\"; 775\nYes/no 776\n\u2022Source trustworthiness: \"How much do you trust [name of source]?\"; 5-point likert 777\nscale from (1) \"not at all\" to (5) \"entirely\" 778\n\u2022Content plausibility (Experiment 1): \"How plausible do you find the content of the 779\npost?\"; 6-point likert scale from (1) \"totally implausible\" to (6) \"totally plausible\" 780\n\u2022Content plausibility (Experiment 2): \"Please respond as if you did not read the 781\nFacebook post: does it sound plausible to you that [statement based on the 782\npost]?\"; 6-point likert scale from (1) \"Totally implausible\" to (6) \"totally 783\nplausible\" 784\n\u2022External search: \"While you were evaluating the Facebook post, did you look for 785\ninformation outside the study page?\"; Yes/No 786\n\u2022if No: \"Why not?\"; randomised: It did not occur to me to do it; I had enough 787\ninformation already; I thought I would lose the experiment; I thought it was not 788\nallowed; I thought it was not possible; Other (free text entry). 789\n\u2022if Yes: \"Where did you look for information? (select all that apply)\"; randomised: 790\nThe article's web page; Wikipedia; Other web pages from the article's website; 791\nSearch engine (e.g., Google); Facebook. (lateral reading = search engine is 792\nselected) 793\nSeptember 21, 2021 20/31\n97%97% 97%95%97%95% 94%90%\n81%91%\n84%80%\n69%\n58%\n42%\n24% 23%\n16% 15%12%9% 8% 7% 7% 6% 5% 5% 5% 4% 4% 4% 4% 4% 3% 2% 2%0%NoYesDo you recognise the following websites?BBC News\nbbc.co.uk\nThe Guardian\ntheguardian.com\nThe Times\nthetimes.co.uk\nNational Geographic\nnationalgeographic.com\nDaily Mail\ndailymail.co.uk\nThe Sun\nthesun.co.uk\nDaily Mirror\nmirror.co.uk\nDaily Express\nexpress.co.uk\nDaily Star\ndailystar.co.uk\nThe New York Times\nnytimes.com\nThe Washington Post\nwashingtonpost.com\nLondon Evening Standard\nstandard.co.uk\nThe Washington Times\nwashingtontimes.com\nBusiness Insider\nbusinessinsider.com\nReuters\nreuters.com\nLive Science\nlivescience.com\nScienceDaily\nsciencedaily.com\nThe Conversation\ntheconversation.com\nIFLScience\niflscience.com\nFrance 24\nfrance24.com\nUnited Press International\nupi.com\nMedical Xpress\nmedicalxpress.com\nBioscience Resource Project\nindependentsciencenews.org\nThe Mercury News\nmercurynews.com\nAustralian National Review\naustraliannationalreview.com\nAgence France-Presse Fact Check\nfactcheck.afp.com\nFirstpost\nfirstpost.com\nThe Heartland Institute\nheartland.org\nAmerican Enterprise Institute\naei.org\nChildren's Health Defense\nchildrenshealthdefense.org\nCollective Evolution\ncollective-evolution.com\nDuluth News Tribune\nduluthnewstribune.com\nScience Vibe\nsciencevibe.com\nVaccineImpact\nvaccineimpact.com\nUKColumn\nukcolumn.org\nZME Science\nzmescience.com\nCO2 Coalition\nbiogenicco2.org\nNot at allBarelySomewhatA lotEntirely\ntrusted distrusted mixed unknown\nHow much do you trust each of these domains?Fig 7. Familiarity and trustworthiness ratings for a series of sources. Top: familiarity ratings, expressed as\nthe percentage of participants recognising the source. Bottom: trust ratings, with square size indicating the\nproportion of participants for each response and the segmented line indicating the average rating by source.\nColor represents categories derived from expectation maximisation model-based clustering.\n\u2022if Search engine is selected: \"While you were looking at the search browser results, 794\nwhat links did you open?\"; options: The first search results suggested.; The 795\nsubsequent search results.; Both the first and subsequent search results.; I did not 796\nopen any search results. (click restraint = either \"The subsequent search results.\" 797\nor \"Both the first and subsequent search results\" is selected) 798\n\u2022Subjective knowledge of the topic [74] (study 2): \"How much do you know about 799\n[topic]?\"; 6-point likert scale from (1) \"nothing at all\" to (6) \"a great deal\" 800\n\u2022Relevance of obtaining accurate information: \"We are considering compiling a 801\ncomprehensive summary of the scientific discussion behind the content of the post. 802\nIf so, would you be interested in receiving it by private message on your prolific 803\naccount?\"; Yes/No 804\n\u2022Trust in scientists: \"In general, how much do you trust scientists to do what is 805\nright?\"; 6-point likert scale from (1) \"not at all\" to (6) \"A lot\" (adapted from the 806\nSeptember 21, 2021 21/31\nEdelman Trust Barometer Yearly online survey) 807\n\u2022Conspiracy ideation trait [14]: 4, 5-point likert scales combined into a mean index 808\n\u2022Scientific literacy [74]: 15 true/false questions 809\nS6 Methods. Supplementary measures in Experiment 2. Measures of 810\nExperiment 2 were identical to those administered in Experiment 1, with three 811\nexceptions. 812\nScientific validity. In Experiment 1, all the scale points used to measure scientific 813\nvalidity were labelled with an adjective (e.g., 4 corresponded to \"possibly valid\"). We 814\nremoved intermediate labels and left only the ones for 1 and 6 (\"definitely 815\ninvalid/valid\"). We removed these labels to make sure that adjectives could not 816\ninfluence the evaluation in the conditions with incentives, where the participants were 817\nasked to give a response that matched the ratings of the experimenters. 818\nPlausibility. We changed one control measure, plausibility, to reflect more 819\nspecifically on the content of the post than on its general appearance. We thus singled 820\nout on claim from the post and asked participants if it sounded plausible, disregarding 821\nthe information they had gathered during the task . The content of a source should sound 822\nplausible to a participant if their background information is in agreement with the 823\ncontent itself, so measuring plausibility in this allows us to make inferences about a 824\nparticipant's background beliefs regarding the post they were given. 825\nSharing behaviour. As an additional exploratory measure we also asked 826\nparticipants' intention to share the post. This question is widely adopted in the 827\nliterature (see for instance [29]). We also asked participants to estimate their weekly 828\namount of sharing on social media, since this rate could affect the intention to share. 829\nS1 Analyses. Original pre-registered analyses (Experiment 1). We tested 830\ndifferences in accuracy scores using a linear probabilistic model with accuracy score as 831\npredicted variable, and experimental condition as predictor. Contrasts revealed a small 832\nbut significant impact of incentive on accuracy score ( \f=:0264 [\u0000:003;:055], 833\nt(2381) = 2:133,p=:04952), but not of the pop-up ( \f=\u0000:0005 [\u0000:0296;:0285], 834\nt(2381) = \u0000:042,p=:9667); we also found that accuracy scores were higher in the 835\nincentive condition than in the pop-up condition ( \f=:0269 [\u0000:002;:056], 836\nt(2381) = 2:177,p=:0495). To test correct guessing, we used a logistic3regression with 837\nthe guess of participant (i.e., \"valid\" or \"invalid\") as dependent variable and actual 838\nvalidity of the post content, experimental condition, and their interaction as predictors. 839\nNeither experimental condition nor its interaction with post validity yielded significant 840\nresults (all p>: 119), thus we could not reject the null hypothesis that there is no 841\ndifference in terms of correct guessing between conditions. 842\nWe additionally tested whether results differ when excluding participants who either 843\nfailed attention checks, encountered technical issues with the display of the Facebook 844\npost, or who did not close the pop-up (and therefore could not observe the post). Tests 845\nwere robust to all these exploratory exclusions. 846\nS2 Analyses. Differences in recorded search behaviour (Experiment 1). 847\nWe tracked participants' search behaviour on the post page as an additional proxy of 848\ntechnique use. Since the page did not include a link to a search engine, we tracked 849\n2Mixed-effects regression with errors clustered by post: p=:052.\n3Original preregistered analyses proposed the use of a probit regression instead of a logistic regression.\nThe two regressions yield the same results, but since we adopt ordinal logistic regressions for non-\nparametric analyses, we choose to report the results of the logistic regression for ease of comparison\nacross tests.\nSeptember 21, 2021 22/31\nwhether participants in each condition did leave the post page without clicking any link. 850\nResults confirm that more participants in the incentive and pop-up conditions left the 851\npage than participants in the control condition (Fig 8, light red bar; incentive: 852\n\f=:6754 [:3759;:9748],z= 5:282,p<: 001; pop-up: \f=:5226 [:2182;:8270],z= 4:021, 853\np<: 001), however the difference between the two interventions was not significant 854\n(\f=\u0000:1528 [\u0000:4258;:1203],z=\u00001:310,p=:190). 855\nArticle \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nExternal \nInfo button \nFacebook \nWikipedia \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%controlpop-upincentive\nFig 8. Race chart of recorded search behaviour, Experiment 1. Bars indicate the proportion\nof participants in each experimental condition that clicked on one of the available links, on\nFacebook's info button, or left the page without clicking any links (named \"external\" searches).\nThe links available to participants led to the original article, the source's Facebook page, a site\ncontaining the source's domain registration, and a Wikipedia page where one existed.\nS3 Analyses. Response extremity and confidence (Experiment 1). We 856\ntested whether our itnerventions affected the extremity (i.e. 4 versus 5 versus 6) and 857\nconfidence of ratings. To measure extremity of responses we looked at the three levels of 858\nevaluation regardless of their correctness. We ran an ordered logistic regression with 859\nextremity of response as predicted variable and experimental condition as predictor. 860\nParticipants in the incentive condition gave more extreme responses than participants in 861\nthe control ( \f=:4425 [:2351;:6499],z= 5:000,p<: 001) and pop-up ( \f=:4847 862\n[:27709;:6924],z= 5:471,p<: 001) conditions, whereas we found no effect of pop-up 863\nover control ( \f=\u0000:0422 [\u0000:2480;:1636],z=\u0000:481,p=:692). We also compared 864\nconfidence ratings between conditions, but found no statistically significant difference 865\nbetween conditions (ordinal logistic regression, all p>: 05). 866\nS4 Analyses. Uncorrected contrasts for source reputation (Experiment 1). 867\nGiven the smaller power for the exploratory analysis on source reputation, we looked at 868\nuncorrected contrasts. These tests suggested that, for unknown sources, accuracy scores 869\nwere higher in the incentive condition than in the pop-up condition ( \f=:3655 870\n[:0843;:8153],z= 2:226,puncorr =:026), and that correct guessing was higher in the 871\npop-up condition than in the control condition ( \f=:45177 [ \u0000:1323;1:0358],z= 2:118, 872\npuncorr =:034); for generally distrusted sources, participants in the incentive condition 873\nhad higher accuracy scores than control ( \f=:2807 [\u0000:0905;:6519],z= 2:071,p=:038) 874\nand than pop-up participants ( \f=:2788 [\u0000:0845;:6420],z= 2:102,p=:036); lastly, for 875\ngenerally trusted sources, correct guessing was lower in the pop-up condition than in the 876\ncontrol condition ( \f=\u0000:8168 [\u00001:7956;:1621],z=\u00002:285,p=:022). This last 877\ncounter-intuitive result may suggest that providing Civic Online Reasoning techniques 878\nwhen the source is known might actually backfire. However, this interpretation should 879\nbe taken with caution, since all trusted sources in the experiment were in fact 880\npresenting valid information, and thus we cannot exclude the influence of post validity 881\n(see S5 Analyses). 882\nSeptember 21, 2021 23/31\nS5 Analyses. Effect of post type on accuracy (Experiment 1). Here we 883\ntested for any potential post differences in terms of scientific validity and scientific topic. 884\nWhen testing for differences across valid and invalid posts, likelihood-ratio tests 885\nconfirmed the importance of this variable for accuracy scores ( chi2(3) = 92:331, 886\np<: 001) but not for correct guessing ( chi2(3) = 5:479,p<: 140); we thus tested only 887\nfor differences in accuracy scores. Contrasts revealed a significant effect of incentives 888\nwhen posts contained valid information: accuracy scores were higher in the incentive 889\ncondition than in the control ( \f=:3582 [:07329;:6431],z= 3:268,p=:003) and pop-up 890\nconditions ( \f=:3713 [:0913;:6514],z= 3:447,p=:003). Uncorrected contrasts did not 891\nreveal any other significant result. A possible interpretation of these findings is that 892\nthere was a bias in the task favouring the interpretation of the posts' content as 893\nscientifically invalid, and that the increase in time and attention produced by the 894\nincentives mitigated this bias. We do not however have the data to confirm or 895\ndis-confirm this conclusion. We also note that posts from trusted sources were all 896\npresenting valid content, and this could play a potential confound. 897\nWe then tested for differences between posts by scientific topic. Scientific topic had 898\nto have a significant effect on both accuracy scores and correct guessing (likelihood-ratio 899\ntest, allp<: 001). Contrasts reveal a significant effect of incentive on accuracy scores 900\nfor posts about the COVID-19 pandemic (against control: \f=:4016 [\u0000:0426;:8459], 901\nz= 2:476,p=:040; against pop-up: \f=:4556 [:0176;:8936],z= 2:849,p=:020) and 902\nclimate change (against pop-up: \f=:4505 [:0175;:8835],z= 2:850,p=:020). 903\nUncorrected contrasts did not reveal any other significant result. 904\nS6 Analyses. Search behaviour and post evaluation (Experiment 1). As an 905\nexploratory analysis, we tested what type of behaviour on the post page predicted 906\nhigher accuracy scores and correct guessing in the task. We tracked whether 907\nparticipants clicked on the links on the post's web page (Facebook page; original article; 908\nFacebook's info button; who.is, a website tracking information about the source domain; 909\nsource's Wikipedia page, when existing), or if they left the page without clicking any 910\nlinks. We ran an ordinal logistic regression for accuracy score and a logistic regression 911\nfor correct guessing, with predictors a series dummy variables indicating whether the 912\nparticipant performed each behaviour or not. Results revealed that leaving the page 913\nwithout clicking any link was a significant predictor both for accuracy scores ( \f=:4500 914\n[:2649;:6352],z= 4:760,p<: 001) and correct guessing ( \f=:4273 [:1552;:7100], 915\nz= 3:022,p=:003). In addition, participants who opened the original article were 916\nmore likely to correctly guess the validity of the post ( \f=:4137 [:1600;:6754], 917\nz= 3:149,p=:002). 918\nAs a confirmatory test, we ran an expectation maximisation model-based clustering 919\nalgorithm to categorise participants based on their tracked behaviour on the page. 920\nSpecifically, we fed the algorithm with participants' total search time (either reading the 921\ninfo window related to the post or searching outside the page), and the proportion of 922\ntime for each activity. Cluster analyses revealed four clusters of behaviours, plus a fifth 923\ngroup including participants who never left the study page. Results reveal that, for both 924\naccuracy scores and correct guessing, two clusters of participants performed better than 925\nthose who did not leave the study page: those who predominantly searched without 926\nclicking links (accuracy score: \f=:5876 [:3932;:7820],z= 5:920,p<: 001; correct 927\nguessing:\f=:6338 [:3493;:9317],z= 4:272,p<: 001), and those who searched 928\npredominantly via the link to the article (accuracy score: \f=:3130 [:1203;:5056], 929\nz= 3:180,p=:003; correct guessing: \f=:4761 [:1969;:7671],z= 3:277,p=:002). We 930\nspeculate (also based on comments in the post-experimental questionnaire) that 931\nparticipants searching on the original article used this exploration to confirm whether 932\nthe post content was not fabricated, and thus rely more directly on their opinion of the 933\nSeptember 21, 2021 24/31\nsource; we do not have results confirming this hypothesis. 934\nS7 Analyses. Additional pre-registered analyses (Experiment 2). 935\nMain effect of pop-up on adoption of techniques. To test whether the 936\npresence of the pop-up increases the adoption of civic online reasoning techniques, we 937\nused a chi squared test comparing the proportion of participants reporting to adopt the 938\nfact checking techniques (lateral reading and click restraint, dichotomous variable) when 939\npop-up was present versus absent. Proportions were indeed significantly different 940\n(\u001f2(1) = 122:66,p<: 001), with 23.6% of participants adopting lateral reading and click 941\nrestraint when the pop-up was present compared to 8.7% when the pop-up was absent. 942\nEffect of incentive on pop-up reading times. To test whether the monetary 943\nincentive increases attention towards the pop-up, we used a t-test (or an equivalent 944\nnon-parametric alternative) to compare the reading times of the pop-up between 945\nparticipants who did or did not receive a monetary incentive. Given that reading times 946\n(and their log-transformation) were not normally distributed (Shapiro-Wilk test, all 947\np<: 025), we adopted a Wilcoxon rank-sum test. The test was significant 948\n(log(W) = 5:32,p<: 001), with median reading times being 2.1 [1.5,2.8] seconds longer 949\nwhen the incentive was present. 950\nS8 Analyses. Differences in recorded search behaviour (Experiment 2). 951\nWe checked how many participants in each condition left the post page without clicking 952\nany link, a proxy of technique use. Likelihood-ratio test again suggested no interaction 953\nbetween incentive and pop-up ( \u001f2(1) =:678,p=:410). Results confirmed the 954\nsignificant effect of both incentive ( \f=:5239 [:3159;:7320],z= 6:010,p<: 001) and 955\npop-up (\f=:3901 [:1841;:5961],z= 4:519,p<: 001), but did not find any significant 956\ndifference in strength between the two interventions ( \f=:1339 [\u0000:1579;:4256], 957\nz= 1:095,p=:274; Fig 9). 958\nS9 Analyses. Exclusion criteria (Experiment 2). We tested whether results 959\ndiffered when excluding participants who reported being familiar with the source, or 960\nwho were not regular Facebook users. Pre-registered results did not differ with one 961\nexception: when controlling for source familiarity, the contrast comparing the strength 962\nof intervention between incentive and pop-up was no more significant (accuracy score: 963\n\f=:1645 [\u0000:0625;:3916],z= 1:730,p=:084; correct guessing: \f=:2124 964\n[\u0000:0647;:4895],z= 1:830,p=:090). 965\nS10 Analyses. Response extremity and confidence (Experiment 2). We 966\nmeasured differences in extremity of responses and confidence ratings across conditions 967\nas in Experiment 1. Both analyses favoured the model without interaction 968\n(likelihood-ratio tests, all p>: 05). Contrasts for response extremity revealed that 969\nincentives increased the ratio of extreme answers ( \f=:4963 [:3328;:6597],z= 7:245, 970\np<: 001) whereas pop-up did not ( \f=:1191 [\u0000:0434;:2815],z= 1:749,p=:080). 971\nContrasts for confidence ratings revealed that only when incentive and pop-up were 972\ncombined confidence ratings were significantly higher than control ( \f=:2830 973\n[:0617;:5043],z= 3:053,p=:009). 974\nS11 Analyses. Sharing behaviour (Experiment 2). In Experiment 2, after the 975\nrating of the post, we asked participants about their willingness to share it. We tested 976\nthe effect of incentives and pop-up on sharing behaviour. We ran two logistic 977\nregressions, one with sharing intention as predicted variable, and incentive, pop-up, 978\nscientific validity, the interaction between incentive and scientific validity, and the 979\ninteraction between pop-up and scientific validity as predictors, and a second regression 980\nSeptember 21, 2021 25/31\nArticle \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nExternal \nInfo button \nFacebook \nWikipedia \nRegistration \n  \n  0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%incentivepop-up + incentivecontrolpop-upFig 9. Race chart of recorded search behaviour, Experiment 2.\nidentical to the first one with the additional interaction between incentive and pop-up. 981\nBoth regressions included also a variable controlling for the self-report number of weekly 982\nshares of posts on social media. Given that one participant reported sharing an 983\nimplausibly large number of posts (50000; S6 Methods) we excluded this participant 984\nfrom this analysis. Comparison of the two models favoured the model without 985\ninteraction between the two interventions ( \u001f2(1) =:072,p=:788). Analyses revealed 986\nonly an increase in sharing intention when the post was valid and participants received 987\na monetary incentive ( \f=:7311 [:3856;1:0765],z= 5:392,p<: 001). One possible 988\ninterpretation of this increase is that the task (assessing the scientific validity of a post) 989\nincreases scepticism towards the content of the post, and that incentives counteract this 990\nscepticism by prompting people to investigate further. 991\nUncorrected contrasts also suggested that such increase was significantly stronger 992\nthan any potential increase due to the pop-up ( \f=:4821 [\u0000:0582;1:0224],z= 2:273, 993\npuncorr =:023). Moreover, pop-up appeared to slightly reduce the number of shared 994\nwhen the content was not valid, both compared to control ( \f=\u0000:3606 [\u0000:7862;:0650], 995\nz=\u00002:159,puncorr =:031) and to the effect of incentive ( \f=\u0000:5416 [\u00001:1933;:1100], 996\nz=\u00002:117,puncorr =:034). Whereas these results indicate an influence of our 997\ninterventions towards sharing behaviour, it is important to keep in mind that despite 998\nthe ecological validity of this task, participants in all conditions were asked to evaluate 999\nSeptember 21, 2021 26/31\nthe validity of the content which they were seeing, which could in turn influence any 1000\nsubsequent sharing intention [30,32,75]. 1001\nAcknowledgments 1002\nWe would like to thank Philipp Lorenz-Spreen, David J. Gr\u007f uning, and the members of 1003\nthe Prosocial Design Network for their insightful comments and advice. 1004\nReferences\n1.Roose K, Isaac M, Frenkel S. Facebook Struggles to Balance Civility and Growth;\n2020. https://www.nytimes.com/2020/11/24/technology/\nfacebook-election-misinformation.html .\n2. AVAAZ. Facebook's Algorithm: A Major Threat to Public Health; 2020.\nhttps://secure.avaaz.org/campaign/en/facebook_threat_health/ .\n3. Eysenbach G, et al. How to fight an infodemic: the four pillars of infodemic\nmanagement. Journal of medical Internet research. 2020;22(6):e21820.\n4. Pennycook G, Rand DG. The psychology of fake news. Trends in cognitive\nsciences. 2021;.\n5. Lewandowsky S, Van Der Linden S. Countering misinformation and fake news\nthrough inoculation and prebunking. European Review of Social Psychology.\n2021; p. 1{38.\n6. Kozyreva A, Lewandowsky S, Hertwig R. Citizens versus the internet:\nConfronting digital challenges with cognitive tools. Psychological Science in the\nPublic Interest. 2020;21(3):103{156.\n7. Lorenz-Spreen P, Lewandowsky S, Sunstein CR, Hertwig R. How behavioural\nsciences can promote truth, autonomy and democratic discourse online. Nature\nhuman behaviour. 2020; p. 1{8.\n8.Lewandowsky S, Ecker UK, Cook J. Beyond misinformation: Understanding and\ncoping with the \\post-truth\" era. Journal of applied research in memory and\ncognition. 2017;6(4):353{369.\n9.Lewandowsky S, Ecker UK, Seifert CM, Schwarz N, Cook J. Misinformation and\nits correction: Continued influence and successful debiasing. Psychological science\nin the public interest. 2012;13(3):106{131.\n10.Lewandowsky S, Cook J, Ecker U, Albarrac\u0013 \u0010n D, Amazeen MA, Kendeou P, et al..\nThe Debunking Handbook 2020; 2020.\n11. Cook J, Lewandowsky S, Ecker UK. Neutralizing misinformation through\ninoculation: Exposing misleading argumentation techniques reduces their\ninfluence. PloS one. 2017;12(5):e0175799.\n12.Hertwig R, Gr\u007f une-Yanoff T. Nudging and boosting: Steering or empowering good\ndecisions. Perspectives on Psychological Science. 2017;12(6):973{986.\n13.Walter N, Brooks JJ, Saucier CJ, Suresh S. Evaluating the impact of attempts to\ncorrect health misinformation on social media: a meta-analysis. Health\nCommunication. 2020; p. 1{9.\nSeptember 21, 2021 27/31\n14. Bode L, Vraga EK. See something, say something: Correction of global health\nmisinformation on social media. Health communication. 2018;33(9):1131{1140.\n15. Bode L, Vraga EK. In related news, that was wrong: The correction of\nmisinformation through related stories functionality in social media. Journal of\nCommunication. 2015;65(4):619{638.\n16. Colliander J. \\This is fake news\": Investigating the role of conformity to other\nusers' views when commenting on and spreading disinformation in social media.\nComputers in Human Behavior. 2019;97:202{215.\n17. Brashier NM, Pennycook G, Berinsky AJ, Rand DG. Timing matters when\ncorrecting fake news. Proceedings of the National Academy of Sciences.\n2021;118(5).\n18.Allen J, Arechar AA, Pennycook G, Rand DG. Scaling up fact-checking using the\nwisdom of crowds. Science Advances. 2021;7:1{10.\n19.Allen J, Arechar AA, Rand DG, Pennycook G. Crowdsourced Fact-Checking: A\nScalable Way to Fight Misinformation on Social Media; 2020.\n20. Pennycook G, Rand DG. Fighting misinformation on social media using\ncrowdsourced judgments of news source quality. Proceedings of the National\nAcademy of Sciences. 2019;116(7):2521{2526.\n21. McGuire WJ. Inducing resistance to persuasion. Some Contemporary\nApproaches. In: Berkowitz L, editor. Advances in Experimental Social\nPsychology. vol. 1. Academic Press; 1964. p. 191{229. Available from: https:\n//www.sciencedirect.com/science/article/pii/S0065260108600520 .\n22. Roozenbeek J, Van Der Linden S. The fake news game: actively inoculating\nagainst the risk of misinformation. Journal of Risk Research. 2019;22(5):570{580.\n23. Roozenbeek J, van der Linden S, Nygren T. Prebunking interventions based on\n\\inoculation\" theory can reduce susceptibility to misinformation across cultures.\nHarvard Kennedy School Misinformation Review. 2020;1(2).\n24. Roozenbeek J, van der Linden S. Breaking Harmony Square: A game that\n\\inoculates\" against political misinformation. The Harvard Kennedy School\nMisinformation Review. 2020;.\n25.Cook J. Cranky Uncle Vs. Climate Change: How to Understand and Respond to\nClimate Science Deniers; 2020.\n26. Clayton K, Blair S, Busam JA, Forstner S, Glance J, Green G, et al. Real\nsolutions for fake news? Measuring the effectiveness of general warnings and\nfact-check tags in reducing belief in false stories on social media. Political\nBehavior. 2019; p. 1{23.\n27. Mena P. Cleaning up social media: The effect of warning labels on likelihood of\nsharing false news on Facebook. Policy & internet. 2020;12(2):165{183.\n28. Gaozhao D. Flagging Fake News on Social Media: An Experimental Study of\nMedia Consumers' Identification of Fake News. Available at SSRN 3669375.\n2020;.\n29. Pennycook G, Bear A, Collins ET, Rand DG. The implied truth effect:\nAttaching warnings to a subset of fake news headlines increases perceived\naccuracy of headlines without warnings. Management Science. 2020;.\nSeptember 21, 2021 28/31\n30. Pennycook G, Epstein Z, Mosleh M, Arechar AA, Eckles D, Rand DG. Shifting\nattention to accuracy can reduce misinformation online. Nature. 2021; p. 1{6.\n31. Pennycook G, Epstein Z, Mosleh M, Arechar AA, Eckles D, Rand D.\nUnderstanding and reducing the spread of misinformation online. Unpublished\nmanuscript: https://psyarxiv com/3n9u8. 2019;.\n32. Pennycook G, McPhetres J, Zhang Y, Lu JG, Rand DG. Fighting COVID-19\nmisinformation on social media: Experimental evidence for a scalable\naccuracy-nudge intervention. Psychological science. 2020;31(7):770{780.\n33.Roozenbeek J, Freeman AL, van der Linden S. How accurate are accuracy-nudge\ninterventions? A preregistered direct replication of Pennycook et al.(2020).\nPsychological science. 2021; p. 09567976211024535.\n34. Tully M, Maksl A, Ashley S, Vraga EK, Craft S. Defining and conceptualizing\nnews literacy. Journalism. 2021; p. 14648849211005888.\n35.Vraga EK, Bode L, Tully M. Creating news literacy messages to enhance expert\ncorrections of misinformation on Twitter. Communication Research. 2020; p.\n0093650219898094.\n36. Guess AM, Lerner M, Lyons B, Montgomery JM, Nyhan B, Reifler J, et al. A\ndigital media literacy intervention increases discernment between mainstream and\nfalse news in the United States and India. Proceedings of the National Academy\nof Sciences. 2020;117(27):15536{15545.\n37. Lutzke L, Drummond C, Slovic P, \u0013Arvai J. Priming critical thinking: Simple\ninterventions limit the influence of fake news about climate change on Facebook.\nGlobal Environmental Change. 2019;58:101964.\n38. Jones-Jang SM, Mortensen T, Liu J. Does media literacy help identification of\nfake news? Information literacy helps, but other literacies don't. American\nBehavioral Scientist. 2019; p. 0002764219869406.\n39. Wineburg S, McGrew S. Lateral reading: Reading less and learning more when\nevaluating digital information; 2017.\n40. Breakstone J, Smith M, Wineburg S, Rapaport A, Carle J, Garland M, et al.\nStudents' civic online reasoning: A national portrait. Educational Researcher.\n2019; p. 0013189X211017495.\n41. McGrew S, Ortega T, Breakstone J, Wineburg S. The Challenge That's Bigger\nthan Fake News: Civic Reasoning in a Social Media Environment. American\neducator. 2017;41(3):4.\n42. Del Vicario M, Bessi A, Zollo F, Petroni F, Scala A, Caldarelli G, et al. The\nspreading of misinformation online. Proceedings of the National Academy of\nSciences. 2016;113(3):554{559.\n43. Martini C. Ad Hominem Arguments, Rhetoric, and Science Communication.\nStudies in Logic, Grammar and Rhetoric. 2018;55(1).\n44. McGrew S, Breakstone J, Ortega T, Smith M, Wineburg S. Can students\nevaluate online sources? Learning from assessments of civic online reasoning.\nTheory & Research in Social Education. 2018;46(2):165{193.\nSeptember 21, 2021 29/31\n45.McGrew S, Smith M, Breakstone J, Ortega T, Wineburg S. Improving university\nstudents' web savvy: An intervention study. British Journal of Educational\nPsychology. 2019;89(3):485{500.\n46. McGrew S, Byrne VL. Who Is behind this? Preparing high school students to\nevaluate online content. Journal of Research on Technology in Education. 2020; p.\n1{19.\n47.Moore RC, Hancock JT. The Effects of Online Disinformation Detection Training\nfor Older Adults; 2020.\n48. Kaufmann N, Schulze T, Veit D. More than fun and money: Worker motivation\nin crowdsourcing-a study on Mechanical Turk. Working paper. 2011;.\n49.Gneezy U, Meier S, Rey-Biel P. When and why incentives (don't) work to modify\nbehavior. Journal of economic perspectives. 2011;25(4):191{210.\n50. Rickard JA, Russell AM. Interest in Advance and Other Up-front Incentives.\nGraduate School of Management, University of Melbourne; 1986.\n51.Pennycook G, Rand DG. Lazy, not biased: Susceptibility to partisan fake news is\nbetter explained by lack of reasoning than by motivated reasoning. Cognition.\n2019;188:39{50.\n52. Epstein Z, Berinsky AJ, Cole R, Gully A, Pennycook G, Rand DG. Developing\nan accuracy-prompt toolkit to reduce COVID-19 misinformation online. Harvard\nKennedy School Misinformation Review. 2021;.\n53. Jahanbakhsh F, Zhang AX, Berinsky AJ, Pennycook G, Rand DG, Karger DR.\nExploring lightweight interventions at posting time to reduce the sharing of\nmisinformation on social media. Proceedings of the ACM on Human-Computer\nInteraction. 2021;5(CSCW1):1{42.\n54. Crawford E. Introducing Tip Jar; 2021. https:\n//blog.twitter.com/en_us/topics/product/2021/introducing-tip-jar .\n55. Tully M, Vraga EK, Bode L. Designing and testing news literacy messages for\nsocial media. Mass Communication and Society. 2020;23(1):22{46.\n56. Vraga EK, Tully M. Media literacy messages and hostile media perceptions:\nProcessing of nonpartisan versus partisan political information. Mass\nCommunication and Society. 2015;18(4):422{448.\n57. Henninger F, Shevchenko Y, Mertens U, Kieslich PJ, Hilbig BE. lab. js: A free,\nopen, online study builder. PsyArXiv. 2019;.\n58. Taylor AB, West SG, Aiken LS. Loss of power in logistic, ordinal logistic, and\nprobit regression when an outcome variable is coarsely categorized. Educational\nand psychological measurement. 2006;66(2):228{239.\n59.R Core Team. R: A Language and Environment for Statistical Computing; 2018.\nAvailable from: https://www.R-project.org/ .\n60. Barrett TS. MarginalMediation: Marginal Mediation; 2019. Available from:\nhttps://CRAN.R-project.org/package=MarginalMediation .\n61. Nickerson RS. Confirmation bias: A ubiquitous phenomenon in many guises.\nReview of general psychology. 1998;2(2):175{220.\nSeptember 21, 2021 30/31\n62. Vraga E, Tully M, Bode L. Assessing the relative merits of news literacy and\ncorrections in responding to misinformation on Twitter. New Media & Society.\n2021; p. 1461444821998691.\n63.Frey BS, Oberholzer-Gee F. The cost of price incentives: An empirical analysis of\nmotivation crowding-out. The American economic review. 1997;87(4):746{755.\n64. Fryer Jr RG. Financial incentives and student achievement: Evidence from\nrandomized trials. The Quarterly Journal of Economics. 2011;126(4):1755{1798.\n65. Chao M. Demotivating incentives and motivation crowding out in charitable\ngiving. Proceedings of the National Academy of Sciences. 2017;114(28):7301{7306.\n66. Gneezy U, Rustichini A. Pay enough or don't pay at all. The Quarterly journal\nof economics. 2000;115(3):791{810.\n67. Dias N, Pennycook G, Rand DG. Emphasizing publishers does not effectively\nreduce susceptibility to misinformation on social media. Harvard Kennedy School\nMisinformation Review. 2020;1(1).\n68. Pennycook G, Rand DG. Who falls for fake news? The roles of bullshit\nreceptivity, overclaiming, familiarity, and analytic thinking. Journal of\npersonality. 2020;88(2):185{200.\n69. Tsang SJ. Motivated fake news perception: The impact of news sources and\npolicy support on audiences' assessment of news fakeness. Journalism & Mass\nCommunication Quarterly. 2020; p. 1077699020952129.\n70. Kim A, Moravec PL, Dennis AR. Combating fake news on social media with\nsource ratings: The effects of user and expert reputation ratings. Journal of\nManagement Information Systems. 2019;36(3):931{968.\n71.Nadarevic L, Reber R, Helmecke AJ, K\u007f ose D. Perceived truth of statements and\nsimulated social media postings: an experimental investigation of source\ncredibility, repeated exposure, and presentation format. Cognitive Research:\nPrinciples and Implications. 2020;5(1):1{16.\n72.Hsieh FY, Bloch DA, Larsen MD. A simple method of sample size calculation for\nlinear and logistic regression. Statistics in medicine. 1998;17(14):1623{1634.\n73. Fraley C, Raftery AE. MCLUST version 3: an R package for normal mixture\nmodeling and model-based clustering. Washington Univ. Seattle Dept. of\nSatistics; 2006.\n74. Fernbach PM, Light N, Scott SE, Inbar Y, Rozin P. Extreme opponents of\ngenetically modified foods know the least but think they know the most. Nature\nHuman Behaviour. 2019;3(3):251{256.\n75. Pennycook G, Binnendyk J, Newton C, Rand D. A practical guide to doing\nbehavioural research on fake news and misinformation; 2020.\nSeptember 21, 2021 31/31", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Instructed or Paid Way to Truth? The contribution of fact-checking tips and monetary incentives to recognizing scientific disinformation", "author": ["F Panizza", "P Ronzani", "S Mattavelli", "T Morisseau"], "venue": "NA", "pub_year": "NA", "abstract": "Scientific disinformation can impose enormous economic and public health burdens. Several  types of interventions have been proposed to prevent the proliferation of false information"}, "filled": false, "gsrank": 243, "pub_url": "https://files.osf.io/v1/resources/vuqd3/providers/osfstorage/6149c6df77d75f0043c50d2e?format=pdf&action=download&direct&version=1", "author_id": ["3Czlt7sAAAAJ", "", "Dg1tCoIAAAAJ", "KJvyFSgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:cMesm0wHEb4J:scholar.google.com/&output=cite&scirp=242&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=cMesm0wHEb4J&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:cMesm0wHEb4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.osf.io/v1/resources/vuqd3/providers/osfstorage/6149c6df77d75f0043c50d2e?format=pdf&action=download&direct&version=1"}}, {"title": "MEDIA FRAMING, MORAL PANIC AND COVID-19: A COMPARATIVE ANALYSIS OF CHINA, SOUTH KOREA, AND THE US.", "year": "2021", "pdf_data": "Univ ersity of T exas Rio Gr ande V alley Univ ersity of T exas Rio Gr ande V alley \nScholarW orks @ UTRGV ScholarW orks @ UTRGV \nCriminal Justice F aculty Publications and \nPresentations College of Liber al Ar ts \n5-2021 \nMEDI A FRAMING, MORAL P ANIC AND CO VID-19: A MEDI A FRAMING, MORAL P ANIC AND CO VID-19: A \nCOMP ARATIVE AN ALYSIS OF CHIN A, SOUTH K OREA, AND THE COMP ARATIVE AN ALYSIS OF CHIN A, SOUTH K OREA, AND THE \nUS. US. \nDeena DeV ore \nSinyong Choi \nYudu Li \nThe Univ ersity of T exas Rio Gr ande V alley, yudu.li@utr gv.edu \nHong L u \nFollow this and additional works at: https:/ /scholar works.utr gv.edu/cj_fac \n Part of the Communication Commons , Criminology and Criminal Justice Commons , and the Public \nHealth Commons \nRecommended Citation Recommended Citation \nDeVore, D., Choi, S., Li, Y ., & L u, H. (2021). MEDI A FRAMING, MORAL P ANIC AND CO VID-19: A \nCOMP ARATIVE AN ALYSIS OF CHIN A, SOUTH K OREA, AND THE US. Asian Journal of Social Sciences & \nHumanities V ol, 10(1), 19\u201338. \nThis Ar ticle is br ought t o you for fr ee and open access b y the College of Liber al Ar ts at ScholarW orks @ UTRGV . It \nhas been accepted for inclusion in Criminal Justice F aculty Publications and Pr esentations b y an authoriz ed \nadministr ator of ScholarW orks @ UTRGV . For mor e information, please contact william.flor es01@utr gv.edu . \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 19  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n MEDIA FRAMING, MORAL PANIC AND  COVID -19:  \nA COMPARATIVE ANALYSIS OF CHINA, SOUTH KOREA, \nAND THE U.S.  \nDeena DeVore1, Sinyong Choi2, Yudu Li3, Hong Lu4 \n1Department of Criminal Justice, University of Nevada, Las Vegas,  2Department of Criminal Justice, \nUniversity of Nevada, Las Vegas, 3Department of Criminal Justice, University of Texas Rio Grande \nValley, 4Department of Criminal Justice, University of Nevada, Las Vegas,  \nUSA.  \n1deena.devore@unlv.edu, 2chois37@unlv.nevada.e du, 3yudu.li@utrgv.edu, 4hong.lu@unlv.edu  \nABSTRACT  \nCOVID -19 is perhaps the single most impactful event defining 2020 globally. \nDrawing on theory on media typology involving freedom and responsibility, media \nframing and moral panic theories, this paper exam ines media coverage on COVID -\n19 in three countries, China, South Korea and the United States. Data were obtained \nfrom six news outlets, Xinhua News, South China Morning Post, Chosun, Hankyoreh, \nCNN and Breitbart, two from each of the three countries. More than 1,000 COVID -\n19 related reports, spanning six days (the last day of January to June, 2020) were \nselected and coded based on common priming themes such as tone, the othering, \nmedical/science, economic consequences, attribution of responsibility, human \ninterests, conflict, leadership, and denial/severity. The results will be interpreted \nbased on the theory of freedom and responsibility, and the unique political and \neconomic characteristics of each country. Implications of press freedom and \nresponsibility,  media\u2019s role and citizens\u2019 rights to be informed are discussed.    \nKeywords:  COVID -19, media framing, moral panic, comparative research, \nChina, South Korea, United States    \nINTRODUCTION  \nThe year 2020 was marked by the unprecedented global pandemic, COVID -19. Coronavirus, \ninitially discovered in late 2019 in Wuhan, China, quickly spread across China and the world. \nBecause it was a newly emerging virus, China took an extraordinary measure to lockdown \nthe city of Wuhan, the epicenter where the virus was initi ally discovered, followed by the \nUnited States banning flights from China, and the WHO\u2019s declaration of COVID -19 as a \nGlobal Pandemic - all within a month or so.  \nMedia plays a major role in transmitting information, especially with a global pandemic of \nsuch magnitude. Media\u2019s role is rooted in broader differences of the political and economic \nstructure of a society. While authoritarian theory depicts that the press be subject to \ngovernmental control and be a servant of the state, the libertarian theory view s the media\u2019s \nfunctions as to inform the general public, help uncover the truth, and serve as a watchdog \nover the government and the democracy (Siebert, 1963). Citing differences between \nConfucianism and liberalism, Yin\u2019s (2008) theory of the press \u2013 freed om and responsibility, \nhelps to situate media\u2019s role in broader, comparative contexts; both political and economic \ncontext, as well as cultural traditions and institutions (Hallin & Mancini, 2004). Media \nframing, the narratives helping to shape public\u2019s pe rceptions and understanding about a \nparticular event, is necessarily influenced by the larger political, economic, and social \nconditions and priorities. For example, the SARS pandemic was framed as a public health \nconcern, a geopolitical issue, or a global  economic concern depending on national priorities \n(Meng & Berger, 2008). Moreover, the news media does not simply replicate reality, it often \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  20      \n helps to construe a \u201creality\u201d that may deviate from the \u201ctruth\u201d. Within this context of media \nbias and news as an  artifact of a socially constructed reality, moral panic theory depicts how \nmedia could exaggerate and distort an event, thus create a chain of reactions and responses \nfrom the public to official policies in dealing with the socially constructed \u201ccrises\u201d. In this \nvein, certain individuals, groups, or nations may be marginalized or labeled as \u201cthe other\u201d \nand accompanied with policies designed to address the moral panic.  \nThis study examines the media coverage of COVID -19 in China, South Korea (S.K. \nhereafter)  and the United States of America (U.S. hereafter). The three countries differ in \nsizes, political system, economic developmental path, and social characteristics, although \nthey have similarities in other aspects such as shared Confucian cultural roots of China and \nS.K., and a democratic political system of S.K. and the U.S. It is thus important to examine if \nthe media type and framing converge or diverge, and if the media arouses moral panic and \nproject a xenophobic undertone, among the three countries.  \nData are derived from thematic content analyses of a total of 1,352 news reports, from six \nnews outlets, two from each country, and on six days (the last day of each month from \nJanuary to June 2020). It addresses several interrelated questions: 1) How does the media of \neach country frame COVID -19? 2) Does framing vary by press typologies, and further by the \nnature of a particular media outlet? 3) Does the media coverage have xenophobic/the othering \nundertone and arouse moral panic, and what are the possible implications?  \nRESEARCH CONTEXT  \nResearch in media suggests that media is a dependent variable reflecting other aspects of \nsocial structures, and an exogenous variable impacting other political and social institutions. \nTo understand media and its impact, we must understand the political and social structures \nwithin which the media operates. In this section, we describe the COVID -19 pandemic, and \nthen the main political, economic, and social characteristics of China, S.K., and the U.S.  \nCOVID -19 \nChina was purpo rtedly reluctant to report the initial outbreak and suppressed the information. \nAfter acknowledging the person -to-person transmission on January 20, it began to take some \nof the most aggressive measures, beyond the requirement of WHO, to contain the virus (e.g., \nlockdowns, electronic surveillance and contact tracing, mandatory mask wearing, building \ntwo dedicated hospitals in Wuhan within 10 days, and mobilizing healthcare workers from all \nover China to support Wuhan). Its aggressive approach has altered th e course of a rapidly \nescalating epidemic. Nevertheless, China\u2019s political mobilization with extreme measures to \ngain public compliance were criticized in the West (Kupferschmidt & Cohen, 2020).  \nS.K.\u2019s response to COVID -19 involved three pillars. First was  fast and free testing. One week \nafter its first case emerged, officials urged medical companies to develop test kits. Six \nhundred testing centers were opened with the world\u2019s first drive -through stations, due to the \ninfectious -disease -prevention law\u2019s aut horization of using unapproved diagnostic kits during \na public -health emergency. Second was expansive tracing technology. The law allows health \nagencies to have warrantless access to CCTV footage and the geolocation data from the new \npatients\u2019 phones and r equire local governments to disclose recent whereabouts of new \npatients to alert the public. Based on this law, the government ordered the church that initially \nhad the breakout to turn over its membership list, identified thousands of churchgoers, and \nordered them to self -isolate. Third was mandatory isolation. S.K. divided people into three \ngroups. Those with serious cases were hospitalized, those with mild symptoms were placed in \nspecial facilities, and those who may have been exposed to the virus yet wi thout symptoms \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 21  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n were required to self -isolate at home while being checked in twice daily by health -service \nofficials. As a result, daily new cases dropped from 800 at the peak of Feb. to less than 100 in \nMarch (Thompson, 2020).  \nIn March, the U.S. and S.K. h ad the same number of deaths (approximately 90) caused by \nCOVID -19; in April, S.K.\u2019s death toll was 85 whereas the U.S.\u2019s number reached to 62,000. \nThe U.S. lost the initial six weeks to control virus due to the CDC\u2019s flawed test kits, tight \nregulation pre venting private labs from processing the tests, lack of airport screening and \nisolation measures, and messaging from the White House minimizing the disease. By mid -\nMarch, more states began initiating social distancing rules and lockdowns to flatten the cur ve, \nwhile struggling with shortages of testing kits, ventilators, PPE supplies, and hospital \ncapacity. Meanwhile, President Trump\u2019s shifting messages about the severity of the virus, \nmasks, conspiracies, and overhyped treatment/vaccines created confusion a bout the current \nstate of coronavirus (Cheng, 2020; Zurcher, 2020).  \nBy the end of June 2020, the total number of people tested positive for COVID -19 globally \nsurpassed 10 million, among them, more than 83,000 in China, 12,000 in S.K. and 26 million \nin the U.S.; the total number of deaths globally was 502,278, and 4,634, 282, 126,360 for \nChina, S.K. and the U.S. respectively.  \nChina\u2019s Political and Economic System  \nChina has undergone a dramatic economic transformation since 1978. The \u201csocialism with \nChinese c haracteristics\u201d challenges liberal economic orthodox (Wang & Groot, 2018). China \nhas had the fastest economic growth in history with its GDP averaging 9.5% through 2019 \nand lifted an estimated 800 million people out of poverty (Morrison, 2019). Consequentl y, a \nseries of social transformation emerged: increasing choice in education, employment, \nhousing, and health care; exposure to Western value such as rights consciousness; and legal \nreforms.  \nThe one -party, non -democratic political system, was consolidated under President Xi as the \n\u201csocialist consultative democracy\u201d. Xi also revived Confucianism and nationalism through \ncalls for the \u201cGreat Renaissance of the Chinese people\u201d and the \u201cChina dream\u201d. He linked \nChina\u2019s rising economic, geopolitical significance t o the Chinese exceptionalism (Bell, 2014; \nLam, 2015), and expanded universal human rights with including economic and social rights. \nIts recent policies regarding Hong Kong, Tibet, and Xinjiang showed its priority of \nmaintaining social stability and nation al security to achieve the total Party control (Wang & \nGroot, 2018).  \nS.K.\u2019s Political and Economic System  \nS.K. is a democratic republic with a presidential system of government and legal opposition \nparties. Elected for a five -year term, the president is th e head of the state, government, armed \nforces, and policy/law maker. President Moon, a liberal, has served as president since 2017. \nUnlike his conservative predecessor whose policies were anti -North Korea and plutocrat \u2013\nfriendly, the Moon government\u2019s polic ies show a softer stance on N.K., an economic \ndemocratization, and an innovation -driven economy.  \nRanked at the 12th among the world's biggest economies, S.K. made a notable economic rise \nfrom one of the poorest countries to becoming a high -income country i n one generation \n(\u201cProjected GDP Ranking,\u201d 2020). Given intrinsic limitations in the small market economy, \nS.K. economy has relied heavily on exports, devoting special attention to technology \ndevelopment and innovation to promote growth. The main industrie s include textile, steel, car \nmanufacturing, shipbuilding, and electronics, along with fast -growing service and tourism \nindustries.  \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  22      \n U.S.\u2019s Political and Economic System  \nThe U.S. is a federalist constitutional republic with three branches of government. Med ia is \nthe fourth pillar serving as the watchdog. The two -party system presumably engenders \ncompetition and gives voters a choice of competing policies. In recent years, liberalism and \nconservatism have increasingly clashed over ideologies and fundamental e conomic, social, \nand cultural values. As the U.S. grew into the world\u2019s economic powerhouse since World \nWar II, promoting democracy has been a staple element of its foreign policy (Bouchet, 2013).  \nThe U.S. represents the largest economy in the world with t he most technologically advanced \neconomy, especially in computers, medical, aerospace and military. It is the world\u2019s largest \nimporter and the second -largest exporter. With the abundance of natural resources, the U.S. \ncontinues to dominate the world econom ic system through rule setting and sanctioning \npower, albeit with its problems of recessions, unemployment, shrinking manufacturing jobs, \nand an increasing income gap.  \nTHEORY OF THE PRESS, MEDIA FRAMING, AND MORAL PANIC  \nFour theories of the Press (Siebert  et al., 1963) provided the foundation for comparative \nanalyses of the media, including authoritarian (Press is an institution controlled by the \ngovernment), libertarian (Press is a watchdog over the workings of government and hence \ndemocracy), social resp onsibility (Press\u2019s responsibility is to inform the public and provide \nthe debate), and the Soviet Communist theory (Press is a propaganda tool for the \ngovernment). Building on this theory and making these typologies applicable to non -Western \ncountries, Yi n (2008) proposed a two -dimensional coordinate grid: freedom and \nresponsibility, arguing that these two concepts are culturally specific, particularly between \nliberalism and Confucianism.  \nThe primary difference between liberalism and Confucianism is their conception of the \nindividual and government. Liberalism depicts natural law, individual\u2019s inalienable rights, \nand social contract. The sovereign individuals place civil liberty as foremost importance, thus \nset out boundaries for legitimate interference by governments only for self -protection. Rule \nof law is thus essential. Democracy is the preferred form as each individual counts and rules \nought to be established through a fair and open process. Media is thus regarded as an \nindependent watchdog, responsible  for holding the government accountable and keep the \npublic informed. To do so, media must be free from governmental control, and the only limit \nof their freedom is the law.  \nIn contrast, Confucianism treats governments as parents and rulers. Government as sumes the \npaternalistic role under the hierarchical order of political system. Individuals shall naturally \nobey the governmental authorities. With the middle path approach, Confucius argued the \nimportance of leading by examples and morality, not by force, and extols cooperative and \nharmonious relations. Hence, morality, not law, plays an important role in maintaining social \norder. Individuals are expected to be responsible for the group as they are viewed as a center \nof interdependent relationships with fam ily, society and the government, thus if the family \nand the state are strong, the wellbeing of individuals can be realized. Social order and \nstability are considered the primacy of political order as they are vital to the strength of a \ncountry and welfare of its people. Governments expect respect and obedience to keep social \norder, in turn, they are expected to act benevolently, protect, and look after the welfare of the \npeople. Government thus is measured by its efficiency and effectiveness, a much goal -\noriented system, as compared to liberal democratic process orientation that values individual \ninput. Instead of being a watchdog, media is regarded as a partner working with the \ngovernment achieving common social goals.  \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 23  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n Press freedom is a double -edged sword . A free press can effectively expose corruption and \ninjustice, if abused, however, it may create chaos and harm. Press responsibility is thus \ncritical to ensure professional and ethical reporting. Representing the liberal conception of \npress responsibilit y, Hutchins\u2019 report stresses media reporting being accurate, diverse and \ncomprehensive, addressing issues of public concerns, and acting as a watchdog of the \ngovernment and other powerful institutions, while avoiding invasion of privacy and \nsensationalism.  Press responsibility, under the Confucian framework (Yin, 2008) is more \nappropriately formulated based on evolving, current community standards, as many Asian \nsocieties are developing, both with its economy as well as with the media.  \nFraming  \nMedia framing  refers to the specific narrative properties that shape perceptions and \nunderstanding of particular events. News account tends to be selective and support dominant \nperspectives, suggesting government\u2019s ability to influence the news output, and journalists\u2019  \ntendency to self -censor and perceive events through political or cultural prisms (Beaudoin, \n2007; Entman & Rojecki, 1993; Robinson, 2001).  \nLuther & Zhou (2005) used five news frames when assessing media coverage of SARS in \nChina and the US. They include 1 ) economic consequences (economic impact of actions or \nevents on individuals, groups or nations); 2) responsibility (blame or credit for actions or \nevents); 3) human interest (individual lives are featured to personalize the story); 4) conflict \n(clashes, c ompetition or war -related rhetoric); and 5) leadership frame (political leadership). \nThey found that major news frames in the US press were also present in the Chinese news, \nparticularly the human -interest stories (even there, the U.S. focused more on huma n struggles \nwhereas China focused more on heroic actions), suggesting Chinese journalists adopting \nWestern media values. Significant differences were found along the lines of economic \nconsequences, responsibility, leadership, and conflict frames between th e two countries; \nwhile the U.S. were more negative on the economic consequences the SARS has, and \nblaming China for it, China media focused on the positive economic initiatives, and avoided \ndiscussing conflict.  \nMoral Panic and the Othering  \nMoral panic is a n exaggeration or distortion of some perceived deviant/criminal behavior, a \nresult of a complex interplay of behaviors and responses involving some key stages in \nconstructing a moral panic: 1) someone or something is defined as a threat to social norms; 2)  \nmedia orchestrates the threat into a recognizable symbol; 3) the portrayal of this symbol \nraises public concern and garners public support against the threat; 4) politicians and \nauthorities band together in enacting or enforcing the rule; and 5) the moral  panic precipitates \nsome sort of social change (Cohen, 2011).  \nMoral panic is different from normal concerns over social issues. Moral panic generates \nheightened concerns and disproportionate societal reaction that creates volatility and hostility \n(Goode & Ben-Yehuda 1994; Rothe & Muzzatti, 2004). This process of panic and \noverreaction does not happen spontaneously, but rather resulted from a complex interplay of \nbehaviors and responses (Muzzatti, 2005). Media\u2019s portrayal of the \u201cother\u201d (e.g., immigrants, \ndisease) tends to play a big part in arousing feelings of anxiety, fear, anger, or hatred, \nparticularly during times of economic crises and political turmoil. Studies found that this \nothering of illness was present in media report in SARS via selective, exag gerated, or \nxenophobic undertone (Muzzatti, 2005).  \nBelow is the summary of the nature of the media, in terms of its freedom and responsibility, \nin China, S.K. and the U.S. to lay the foundation for the current study.  \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  24      \n China\u2019s Media  \nTraditionally classified under the Soviet communist press theory, China\u2019s media can be put in \nthe \u201cnot free but responsible\u201d category with certain qualifications. Freedom House (2004) \nranked it at the 177th out of 187 countries, noting widespread restrictions on press freedom \nthrough laws, censorships, and criminal penalties (Beaudoin, 2007). The media becomes freer \ndue to greater choices, diversity, and independence. The transformation, from a few strictly \nstate-owned media outlets to thousands of newspapers, magazines and radio a nd TV stations, \nis driven by Westernized university journalism education that supply a large number of \ntrained journalists, and by market competition with decreased state subsidy (Luther & Zhou, \n2005).  \nChina\u2019s media is responsible from the perspective of t he Confucian hierarchical political \norder that serving the Party\u2019s interest trickles down to the well -being of individuals. \nHowever, it becomes messier without clear professional standards. Rarely in history, the \nmedia is influx with such diverse, yet conf licting, goals and expectations (e.g., is the media\u2019s \nrole providing news, information, entertainment, diverse voice, criticisms of the powerful, or \nserving as an instrument to achieve developmental and political goals of the state?) (Zhang & \nFleming,2005) . Driven by ratings and profits, tabloids, staged news, and sensationalism in \nmedia coverage becomes more common, albeit that more serious news reporting such as \ninvestigative journalism remains in demand, particularly when scandals happen (e.g., the \nFocal  Point, a CCTV news magazine program) (Kurtenback, 2002).  \nOne rule directly related to the current study is the law on emergency management passed \nafter SARS, which requires media outlets receiving an approval before reporting the story \nregarding a pandemi c. Studies on SARS coverages showed patterns of initial censorship, \ncontrolled information, and more positive reporting (Beaudoin, 2007; Liebman, 2005; Luther \n& Zhou, 2005). Studies also identified nationhood, globalization and economic edge are \ncommon the mes in SARS coverages, suggesting deep -seeded nationalism and a genuine \ndesire for international integration (Luther & Zhou, 2005). With the proliferation of social \nmedias in the current time, the dynamics of media reporting, and official control and \ncenso rship may be quite different, despite President Xi\u2019s intensified grip over media control \n(Zhang & Fleming, 2005).  \nS.K.\u2019s Media  \nPresident Moon (2017 - present) has improved media freedom after years of oppression from \nthe conservative governments. The S.K ne ws medias are generally free and competitive, \nserving as a watchdog of government. The liberal Moon administration supports a major \npress freedom initiative by Reporters Without Borders, also known as RSF (\u201cMoon declares,\u201d \n2019). According to the RSF's Wor ld Press Freedom Index, S.K.\u2019s ranking increased from \nthe 70th in 2016 to the 42nd in 2020. S.K. now has the freest media environment among \nAsian countries.  \nWhile S.K. seems to have the concept of a libertarian press, an authoritarian style remains in \npractice due to the long history of authoritarian rule. The press can cover aggressively \ngovernment policies, corruption and corporate wrongdoings, but some self -censorship is \nexpected due to a defamation law that can impose up to a seven -year imprisonment (Fr eedom \nHouse, n.d.). Journalists\u2019 independence remains questionable as the media outlets\u2019 leadership \npositions are filled by presidential appointment (Reporters Without Borders, n.d.), and the \nmedia industry has long allied itself with the government and ma jor corporations (Heo, Uhm, \n& Chang, 2000). While media censorship is generally restricted, the National Security Law \ncan censor reports involving North Korea (Reporters Without Borders, n.d.). In fighting the \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 25  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n growing \u2018fake news\u2019, the government also risks  violating free speech (Freedom House, n.d.). \nOverall, the S.K. media is characterized as development journalism, with focus on the \neducational function of the news, stories about social needs and self -help, and the priority of \nnation building. Its strong emphasis on social responsibility puts its media in between \nConfucianism and liberalism.  \nS.K.\u2019s media coverage of the H1N1 pandemic showed that S.K. has been an authoritarian, \ncapitalist country, in which journalists conformed to the prevailing political worldview; \nespecially in the conservative mass press (Oh et. al., 2012). While lacking either the \nattribution of responsibility or action frame, most Korean coverage focused on monitoring the \nflu\u2019s trend and delivering news based on sources released from t he conservative government. \nThis tendency was a result of the Korean governmental control over freedom of the press \nwith multiple measures, such as policy enforcement and financial support.  \nU.S.\u2019s Media  \nThe U.S. media falls in the category of free and resp onsible. Operating largely under the \nliberal ideologies that the press as a source of information, education, and a watchdog of the \ngovernment, the U.S. media is largely independent from governmental influence (Briggs, \n2004). The First Amendment of the U.S . Constitution protects press freedom, grants \njournalists access to information, and narrows the scope of libel cases against the press, with \nsome governmental and legal restraints on defamation, obscenity, indecency, wartime \nsedition, and national securit y issue such as the war on terror (Beaudoin, 2007).  \nJournalist code of ethics has been passed down generations of journalism students, despite of \nmostly privately funded, the media provides mostly quality information and often a public \nservice such as addr essing crime and voter turnout issues, without having to worry about \nmarket competition as well -developed, free media markets tend to assure responsible media \nof market support with the public demand of factual information. In recent years, however, \npartis an politics became more polarized, and media\u2019s credibility and relevance are slipping as \nit allows itself used as a political and ideological tool of partisan fight, rather than adherence \nto factual reporting. To deflect the growing COVID -19 crisis at home , for example, the \nTrump administration has intensified the rhetoric of the \u201cfake news\u201d media attack and the \nChina virus bashing, against the international rules of not labeling a virus with a nation or a \nregion.   \nStudies show that the U.S. media coverage  of SARS was characterized by sensationalisms \nand xenophobic fear -mongering, projecting images of the \u201cyellow peril\u201d reminiscent of the \npast racial bigotry (Muzzatti, 2005). Its media coverage of SARS was also accompanied by \ncriticizing the Chinese politic al system and its one -party, authoritarian system that censors \nmedia and information (Luther & Zhou, 2005).  \nTHE CURRENT STUDY  \nDrawing on theories of press typologies, media framing and moral panic, this study examines \nthe media coverage of the COVID -19 in China, S.K. and the U.S. The purpose of this \ncomparative analysis is to show how the same event, COVID -19, is framed by medias from \nthree countries with diverse political, economic, and cultural traditions and whether it \nprojects xenophobic undertones that  stigmatizes a particular group or nation. The result can \nshed light on our understanding of media freedom and responsibility, and the underlying \ntension among different political, economic, and cultural systems.  \nThree inter -related questions will be addr essed: 1) How does the media of each country frame \nCOVID -19? 2) Does framing vary by press typologies, and further by the nature of a \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  26      \n particular media outlet? 3) Does the media coverage have xenophobic/the othering undertone \nand arouse moral panic, and wha t are the possible implications?   \nMethod, Data, and Variables  \nData used in this analysis were derived from six news outlets, two from each county. Xinhua \nNews and South China Morning Post are the two Chinese news media selected. Founded in \n1940, Xinhua Ne ws is the official state -run news agency, regarded as the mouthpiece of the \nCommunist Party by the West (Liebman, 2005), representing one of the most influential news \noutlets in China with about 200 bureaus worldwide and employing tens of thousands of \npeop le (Xinhua, 2005). South China Morning Post (SCMP) is a top English -language and \njoint-stock Hong Kong newspaper since it was founded in 1903 (Xie & Ding, 2016). The \nnewspaper is highly ranked among HK newspapers and well known for its reports on \ncontrover sial social events/policies regarding mainland China (Duan, 2007; Xie & Ding, \n2015).  \nThe S.K.\u2019s two national newspapers, Chosun and Hankyoreh, were selected due to their \ncontrasting ideological approaches. While Chosun is traditionally conservative, Hankyo reh is \nliberal leaning. Established in 1920, Chosun represents the interests of capitalists, vested \ninterests, and relatively older generations, whereas Hankyoreh, launched in 1988 through \npublic fundraising, is less intertwined with political power, and t argets the young and low -\nclass readers.  \nThe two American news media, CNN and Breitbart, are on the opposite side of the \nideological spectrum. Founded in 1980 as the world\u2019s first 24 -hour news channel, CNN\u2019s \nprimary viewership are largely left -leaning with  its straight news reporting falls left -center \nthrough bias by omission, and its news reporting tends to be factually accurate \n(https://mediabiasfactcheck.com/cnn/). Breitbart was founded in 2007, a far -right syndicated \nnews, opinion and commentary website . It is rated as a questionable source based on extreme \nright -wing bias, conspiracy theories and false claims \n(https://mediabiasfactcheck.com/breitbart/).  \nA total of 1,352 reports were generated based on keywords (coronavirus, corona, virus, and \nCOVID -19) searches in google and over six days (the last day of January through June of \n2020). These reports were coded via deduction based on frames identified in previous studies, \nincluding medical/science economic consequences, responsibility, human interest, co nflict, \nleadership, and the denial/severity frame. In addition, to tap into possible moral panic, we \ncoded tone and the othering (e.g., xenophobic undertone) (Luther and Zhou, 2005). The \ndeductive approach is advantageous over inductive approach, especiall y in comparing news \ncoverage between different news outlets, as it creates comparative indices of news content \n(Beaudoin, 2007).  \nEach news frame contains multiple coding statements, capturing both the content and the \ntone. For example, the economic consequ ences variable is measured by mentions of \neconomic consequences for (1) home country, or (2) for the world, where no mention is \ncoded 0, negative coded 1, mixed coded 2, and positive coded 3. The attribution of \nresponsibility variable is measured by respon sibility attributed to government of (1) China, \n(2) S.K., (3) the U.S., or (4) WHO, where no mention is 0, to be blamed for coded 1, mixed \ncoded 2, and praised for coded 3. The human -interest frame is a composite variable of (1) \nindividuals; (2) groups; (3 ) photos or adjectives capturing human interests; (4) quality of \neveryday life, with 0 no mention to 3 a positive portrait of human interests for each of the \nstatement, making the range of value being 0 -12 for this variable. The conflict variable is \nmeasur ed by (1) China domestic; (2) China international; (3) S. K. domestic; (4) S. K. \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 27  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n international; (5) U.S. domestic; (6) U.S. international, with no mention coded 0, negative \ntone (e.g., war rhetoric) coded 1, mixed tone (e.g., acute problem but work togethe r) coded 2, \nand positive tone (e.g. fast building of hospital) coded 3. The leadership variable is measured \nby political leaderships of (1) China, (2) S.K., (3) U.S., (4) Who, or (5) other countries, where \nno mention is coded 0, lack of leadership coded 1,  mixed leadership coded 2, and effective \nleadership coded 3. The denial/severity frame is measured by the coverage regarding the \nseverity of COVID -19 where any mention of COVID -19 being severe coded as 0 and \nCOVID -19 being extremely severe such as causing death, infection, and other major \nproblems as 1. The medical/science frame is a composite variable, with a range of values \nbetween 0 -12, which includes mentions of science/research about the virus, infection \nprevention tips, and quarantine measures.  \nTwo v ariables tap into the moral panic theory. The first variable is the overall tone of the \nnews report measured on a five -point scale from extremely positive (1) to extremely \ncritical/negative (5). The second variable involving \u201cthe othering\u201d, which is a comp osite \nvariable with a range of 1 -12, which includes mention of elements of othering or xenophobic \nlanguage, the deadly nature of the virus, contagion, fear, or general panic.   \nFollowing major framing themes of the past studies, we expect that Chinese medi a will be \nmore positive when discussing economic consequences and giving credit to its own political \nleadership and responsibility as well as the international organization, whereas the S.K. and \nthe U.S. media coverage will be more likely to report negativ ely due to the role of media as a \nwatchdog under the democratic political system. Given the growing polarization in the world, \nparticularly in the U.S., media coverage might also be driven by ideological affiliation. In \ncomparison, China and S.K., under Co nfucian influence, might have a greater tendency to \nproject solidarity and stability domestically, thus less likely to cover the conflict frame \nnegatively, and less negative tones and xenophobic undertone. In contrast, as a world leader, \nand under Presiden t Trump\u2019s slogan of America first, the U.S. media might be more driven \nby ideological divide and more aggressive and negative in portraying the virus as the \u201cother\u201d \nand shift responsibility and blame to the other.  \nRESULTS AND ANALYSIS  \nTable 1. Percent Fram es by Press . \n  Denial  Medical  Responsibility  Leadership  Human In.  Conflict  Economic  \nN \n% % % % % % % \nCh. Press  82 69 30 39 25 28 25 279 \nXinhua  84 70 17 9 16 14 5 152 \nSCMP  80 69 46 75 35 44 42 127 \nS.K. Press  41 39 36 24 20 14 11 357 \nChosun  37 33 34 24 15 13 12 182 \nHankyoreh  45 45 38 23 25 16 9 175 \nU.S. Press  34 29 30 22 12 8 11 716 \nBreitbart  22 21 42 34 16 13 10 277 \nCNN  42 36 23 15 10 5 11 439 \nAll 46 40 32 26 17 14 13 1,35\n2 \n \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  28      \n Table 1 shows the frequency distributions of two variab les, frame and press. The results \nindicate that the denial/severity frame, was mostly emphasized (46%) by the presses in all the \nthree countries, followed by medical/science (40%), responsibility (32%), leadership (26%), \nhuman -interest (17%), conflict (14% ), and economic consequences (13%).  While the most \nused framing was denial/severity, the nature of the use of this framing is different. As China \ntended to express public health threats due to COVID -19 in other countries, both the U.S and \nS.K. had highest public health threat qualifiers within the severity framing for China. For \nboth China and S.K., the second most used framing was medical/science. For the U.S., the \nsecond most used framing was responsibility, followed by medical/science. This perhaps \ncontr ibutes to the different uses of the moral panic/othering frames in which many U.S. news \narticles, at least from Breitbart, employ language which \u201cothers\u201d and attributes a \nresponsibility for the negative impact of the virus to the segment of people it has o thered.  \nDenial/Severity Frame  \nThis framing defines the scope and the unprecedented nature of the pandemic. It focuses on \nthe numbers in terms of a global impact, additionally the use of phrasing such as \u201csuffered \nthe most\u201d gives the numbers a sense of huma nization. The severity of the problem is a world \nframing rather than just the framing of th e severity on the home country.  \nTable 2. Mean Denial/Severity Frame*  \n China  S.K. U.S. Others  N \nChinese Press  .55 \nN=111 .60 \nN=5 .65 \nN=14 .79 \nN=98 279 \nXinhua Ne ws .44 \nn=45 1 \nn=2 1 \nn=7 .88 \nn=73 152 \nSCMP  .62 \nn=66 .33 \nn=3 .29 \nn=7 .52 \nn=25 127 \nS.K. Press  .84 \nN=6 .22 \nN=110 .27 \nN=11 .42 \nN=19 357 \nChosun  .67 \nn=3 .41 \nn=46 .3 \nn=10 .44 \nn=9 182 \nHankyoreh  1 \nn=3 .08 \nn=64 0 \nn=1 .4 \nn=10 175 \nU.S. Press  .19 \nN=21 .1 \nN=10 .05 \nN=109 .06 \nN=106 716 \nBreitbart  .11 \nn=9 n/a \nn=0 .04 \nn=24 .07 \nn=29 277 \nCNN  .25 \nn=12 .1 \nn=10 .05 \nn=85 .05 \nn=77 439 \nAll .51 \nN=138 .23 \nN=125 .13 \nN=134 .41 \nN=223 1,352  \n*Severity of COVID -19: 0=severe; 1= severe as a public health threat; n/a = not available.  \nBased on Table 2, while all countries outlets report on the number of deaths due to COVID -\n19 and the number of infections, China, when reporting on China had a mean of .55 \nindicating a moderate coverage of this public health threat within t he severity frame, with the \ngeneral trend being to report the severity with the specific public health qualifier as being \nmore present in other countries (S.K. with .60, U.S. with .65, and all other countries reported \non with .79).  \nThe United States suffe red the most from the pandemic, with 1,764,671 cases \nand a death toll of 103,605. Countries with over 200,000 cases also included \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 29  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n Brazil, Russia, Britain, Spain, and Italy, according to the CSSE data.\u201d \u201cGlobal \nconfirmed COVID -19 cases topped 6 million on S aturday, reaching 6,003,762  \nas of 4:32 p.m.\u201d and \u201ca total of 367,356  people worldwide have died of the \ndisease (Global Covid -19, 2020 , para. 2 & 3).  \nSimilarly, SCMP (Coronavirus latest, 3/31/2020, para.2) reported that, in Spain, \u201cthe total \nnumber of death s rose by 849 in the past 24 hours... The number of new cases increased by 9, \n222 on Tuesday\u201d.  \nFor S.K., when reporting on the severity of the virus in China the mean was .84 indicating \nthat the severity framing with the public health qualifier was moderat ely high, while the use \nof this was moderately low when reporting elsewhere, with the lowest being in S.K. The \nseverity framing in S.K. press emphasizes the numbers of deaths and infection without a \ntendency to frame it with the specific public health thre at qualifier. For example, Chosunilbo \n(2020a) began with a specific death count: \u201cthree death cases on February 28th in Daegu\u201d \n(para. 1) as well as emphasis on the number of infected: \u201cmore than 2300 people have been \ninfected by coronavirus\u201d (para. 1), wit h particular emphasis on the rapid increase and the \nstrain on current response systems: \u201cthe number of new cases is rapidly increasing which will \nparalyze the medical system in Daegu soon\u201d (para. 1). \nFor the U.S., the severity framing rarely had the additi on of the specific \u201cextreme severity\u201d \nwith the public health threat, but like S.K., the articles which reported on China had the \nhighest mean (.19 for China, .10 for S.K., .05 for U.S. and .06 for all else). Most of CNN \ndenial/severity framing open with a take on the current numbers and infection rates \u201cAt least \n575 coronavirus deaths were reported in the United States on Monday... This is the most \nreported deaths in the US in a single day\u2026\u201d (Sutton,2020). It also reported the impact of the \nvirus such as \u201cR efrigeration units intended as makeshift morgues are seen parked behind \nBelleview Hospital Center in New York City\u201d (Sutton, 2020). For Breitbart, however, \nseverity framing was often used in conjunction with an attribution of responsibility or a \nblaming of  opposite political leadership, extending to not only China, but also other countries \n(e.g., \u201cMexico Nears 18K Coronavirus Cases Despite Admitted Undercount\u201d) (Ortiz & \nDarby, 2020 ). \nMedical/Science Frame  \nAll three countries mentioned quarantine measures an d science about the virus along with \nspecific prevention measures. The Chinese press (0.75) was more likely to highlight the \nimportance of science -based response to COVID -19, compared to the S.K. (0.19) a nd U.S. \n(0.43) presses . \nTable 3. Mean Medi cal/Science Frame*  \n China  S.K. U.S. Others  N \nChinese Press  .75 \nN=101 1 \nN=3 .62 \nN=13 .62 \nN=76 279 \nXinhua News  .85 \nn=47 1 \nn=2 .75 \nn=4 .64 \nn=53 152 \nSCMP  .67 \nn=54 1 \nn=1 .56 \nn=9 .57 \nn=23 127 \nS.K. Press  .12 \nN=8 .19 \nN=107 .29 \nN=7 .07 \nN=16 357 \nChosu n .33 \nn=3 .32 \nn=44 .4 \nn=5 .13 \nn=8 182 \nHankyoreh  0 \nn=5 .1 \nn=63 0 \nn=2 0 \nn=8 175 \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  30      \n U.S. Press  .36 \nN=25 .13 \nN=8 .43 \nN=100 .36 \nN=81 716 \nBreitbart  .17 \nn=6 n/a \nn=0 .44 \nn=34 .18 \nn=17 277 \nCNN  .42 \nn=19 .13 \nn=8 .42 \nn=66 .41 \nn=64 439 \nAll .64 \nN=134 .21 \nN=11 8 .44 \nN=120 .45 \nN=173 1,352  \n* 0= quarantine measures; 1= science about virus and prevention; n/a = not available.  \nFor China, wording within this frame emphasizes the connection between science about the \nvirus and prevention efforts. For example, the Xinh ua News (3/31/2020) reported that \u201cthe \nfirst batch of volunteers for a coronavirus epidemiological survey began to work on Tuesday \nin Shanghai after completing professional training\u201d. However, scientists also warned that \n\u201cThe antibodies may not remain for a long time, so there is still a risk that these recovered \npatients will be infected again. They should continue to keep themselves protected [by \navoiding mass gatherings]\u201d (Factbox, 2020, para.7), as well as medical inquiries into the \nvirus affects the bo dy long term: \u201cThe medical community has yet to establish how the virus \ncan affect the bodies of recovered patients\u201d (Zhou & Ng, 2020).  \nFor S.K., the coverage tended to focus on the quarantine aspect. When \ndiscussing information on the virus, the focus wa s on the fast spread of the \nvirus due to its contagious nature, and asymptomatic cases: \u201cAccording to Oh \nMyeong -done, a professor of infectious diseases at Seoul University of \nMedicine, an increasing case of asymptomatic [coronavirus] infection indicates \nthe explosive nature of [coronavirus] transmission\u201d (Kim, 2020a, para. 6).  \nFor the U.S., measures regarding possible vaccines as \u201creason to hope\u201d (Kraychik, 2020) and \nstudies which discuss the mortality and survival rates of patients as well as symptoms wer e \ndiscussed: \u201cit [the study] provides helpful insights into the symptoms of Covid -19 patients \nadmitted to hospital\u201d (Kraychik, 2020). Like China and S.K., most medical/science framing \nrelies heavily on medical experts directly quoted in the body of the new s articles.    \nResponsibility Frame  \nFor the attribution of responsibility framing, China and S.K. were more critical of the U.S. \n(1.36 and 1.16) whereas the U.S. was most critical of China (1.36) while highly praising S.K. \n(3.0). Responsibility of WHO was relatively seen as neutral by the press in the three \ncountries.  \nThe Chinese press used the responsibility frame mostly to construct COVID -19 as a world \nhealth crisis and not a sole attribution of China\u2019s responsibility. It typically focused on other \ncount ries blaming China for the virus, such as \u201cMoscow regrets the attempts of several \nWestern countries to put the blame on China for the coronavirus pandemic\u201d (Russia upset by \nWestern, 2020, para.1), and \u201cthe whole world should stop kicking China and Chinese \ncommunity when they are down\u201d (Letters, 2020 , para. title). It also called for WHO efforts \nworldwide and China\u2019s specific contribution to information as an end to \u201cfragmented \ninformation\u201d (Wu & Wong, 2020 ) on the virus.  \nFor S.K., the press reporting on Chin a remained neutral, however with respects to S.K., the \nU.S, and others, this focus was moderately critical.  \n\u2018Developed countries\u2019 prioritizing industrial interests lost valuable time [to \nprevent coronavirus outbreak] \u2026 The public health care systems in Ita ly and \nSpain that had suffered from chronic budget deficits exposed their \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 31  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n weaknesses\u2026 the U.S.\u2019s health care system revolving around profit -making, \nprivate hospitals is totally unsuitable for coping with a pandemic. In Japan, \u2018a \ndeveloped country\u2019, total c ases that have been reported so far are merely the tip \nof the iceberg due to Japan\u2019s restrained approach to [coronavirus] testing (Park, \n2020 , para. 3). \nFor the U.S. press coverage was mostly critical. When discussing positive attribution of \nresponsibility  for China in the U.S., CNN placed emphasis on the construction of more \nhospitals: \u201cChina is building two dedicated hospitals in Wuhan to help treat the thousands of \npeople affected by the deadly coronavirus\u201d (In photos,2020). By contrast, the majority of \nBreitbart articles with attribution of responsibility is extremely critical towards China: \n\u201coutrage of Chinese citizens over the Party lying about how contagious they knew the virus \nto be\u201d (Martel, 2020), often with mention of communism in conjunction with  respects to \nblame: \u201cweeks before the Chinese Communist Party revealed the existence of the virus to the \nworld\u201d (Martel, 2020). Breitbart articles with responsibility framing construct the problem as \na Chinese problem, and language mirrors this with blame and othering rhetoric. The coverage \nof S.K. was largely positive, praising its highly advanced technology as innovated responses \nto COVID -19.  \nHuman Interest Frame  \nFor this framing, China tended to report neutral human -interest stories about China, and \nnegative human -interest stories about S.K., the U.S. and others.  The focus of these stories is \nthe suffering and pain experienced by people affected by the virus, with quotes from residents \nwhich express anguish.  \nNobody knows how many times I\u2019ve cried at nig ht\u201d \u2013 Tam Sau -Lan, 81, also \nlive alone in a public rental housing flat in Lam Tin. Her husband died more \nthan 20 years ago, while her two sons and two daughters live and work in \nGuangzhou (Sun, 2020).  \nSimilarly, S.K. press tended to report negative human -interest framing which focuses on \nspecific and personal anguish individuals have faced due to the virus.  \nMr. Shin (33) who brings up a son who is six years old is having a hard time \nto find a place to take care of his child, as preschool is closed and the  opening \nday of school is postponed a week due to the spread of Wuhan coronavirus \n(Yu & Choi, 2020, para 1).  \nFor the U.S. press coverage of China tended to also emphasize personal suffering. \u201cFor now, \nthere is little people like Shi can do\u2026when Shi asked  what kind of patient would be \nadmitted, she says the staff member responded: \u2018We will admit (them) if they're dying\u2019\u201d \n(Hollingsworth, Yang, & Thomas, 2020).  \nEconomic Frame  \nSomewhat surprisingly, economic frame was the least covered frame of all (Table 1),  which \ncould be due to our analysis focusing on the beginning phase of the virus. For China, the \neconomic framing focused on short -term governmental interventions and long -term economic \nimpact: \u201cThe U.S. Federal Reserve\u2026 warned that the COVID -19 pandemic p oses \n\u2018considerable risks\u2019 to the U.S. economy\u201d (Spotlight, 2020, para.1).  \nRecovery is set to continue in the coming months\u2026while Beijing has not \nengaged in the huge volumes of stimulus seen in the U.S. and Europe in a \nbid to spend its way out of the pandem ic- caused economic problems, it has \nin recent weeks loosed the purse strings (Bermingham, 2020).  \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  32      \n  For S.K., economic framing was also tied to the use of leadership framing: \u201cThe government \nand ruling party officials who had expressed optimism\u2026 economy w ill bounce back soon, \nhave slightly changed their voice due to \u2018Wuhan pneumonia\u2019\u201d (Kim, 2020b, para 1). For the \nU.S., the economic frame discussed the long -term impact of the virus on the U.S economy \nand how this is connected to the world market. \u201cThe Fede ral Reserve is opening up another \navenue for stressed -out foreign central banks to get access to US dollars during the \ncoronavirus crisis\u201d (Egan, 2020).  \nMoral Panic/Othering  \nTable 6 presents results regarding the tone of the press coverage. The overall ton e is between \nneutral and somewhat negative (3.22). More specifically, Chinese media coverage is the most \nnegative (3.35), followed by the U.S. media (3.27) and then the S.K. (3.0). Notably, the \nliberal SCMP was more negative (mostly towards China) than the  state press, Xinhua News \n(more towards S.K. and the U.S.). The tone of conservative leaning Chosun was slightly \npositive, while the liberal leaning Hankyoreh was negative. The liberal leaning CNN was \noverall neutral (with negative tone primarily geared to wards the U.S. [3.27]), contrary with \nthe conservative Breitbart being nearly extremely negative on China (4.2).  \nTable 4. Press Coverage\u2019s Tone on Each Country*  \n China  S.K. U.S. Others  All \nChinese Press  \n 3.08 \nN=152 3.49 \nN=6 3.38 \nN=16 3.68 \nN=102 3.35 \nN=279  \n   Xinhua News  2.35 \nn=67 5 \nn=2 3.37 \nn=8 3.64 \nn=74 3.07 \nn=152 \n   SCMP  3.65 \nn=85 2.74 \nn=4 3.38 \nn=8 3.79 \nn=28 3.69 \nn=127 \nS.K. Press  3.25 \nN=12 3.00 \nN=387 3.00 \nN=22 3 \nN=36 3.00 \nN=357 \n   Chosun  3.17 \nn=6 3.07 \nn=141 2.81 \nn=16 3 \nn=19 3.07 \nn=182 \n   Hankyoreh  3.33 \nn=6 2.96 \nn=246 3.5 \nn=6 3 \nn=17 2.93 \nn=175 \nU.S. Press  3.53 \nN=58 2.67 \nN=15 3.27 \nN=407 3.22 \nN=237 3.27 \nN=716 \n   Breitbart  4.20 \nn=25 2 \nn=2 3.28 \nn=183 3.5 \nn=68 3.42 \nn=277 \n   CNN  3.03 \nn=33 2.77 \nn=13 3.27 \nn=224 3.11 \nn=169 3.17 \nn=439 \nAll 3.21 \nN=222 3.00 \nN=408 3.26 \nN=445 3.32 \nN=375 3.22 \nN=1,352  \n*1=extremely positive; 2=somewhat positive; 3=neutral; 4=somewhat negative; 5=extremely negative  \nApproximately one third of the news reports contributed to \u201cmoral panic\u201d, with the Chinese \npress (68%) leading the char ge, followed by S.K. (32%) and then the U.S. (13%) press. In \ncomparison, about 15% of the reports contains the language of \u201cthe othering\u201d, with the lowest \nshare from the Chinese press (7%), as compared to the S.K. and the U.S.\u2019s 18% and 17% \nshares respecti vely. Perhaps the most striking is the divergence in \u201cthe othering\u201d within \npresses in each country. For the Chinese press, Xinhua News contained no language of the \nothering, the reports (20 reports) came from South China Morning Post. For S.K., the \nmajorit y of reports with othering language came from Chosun (29 reports compared to 6 from \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 33  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n Hankyoreh). Lastly, the U.S. press had the majority of the othering reports from Breitbart (34 \nreports compared to 6 from CNN).  \nThe moral panic framing tended to stress th e lack of information about the virus, the rapid \nspread, and the lack of facilities to adequately respond to the virus as well as negative \nimpacts on the economy. Phrasing in this frame also had elements of combative language, \nbeing at \u201cwar\u201d with the virus  or language which inspire panic. The othering framing included \nphrasing which attributed the virus to one particular country or segments of people, phrasing \nsuch as \u201cWuhan virus\u201d, \u201cChina virus\u201d or mentions of Communist party, discrimination of \nimmigrant w orkers/ethnic minorities or rights infringed. Present in all three countries\u2019 news \ncoverage were comparisons of COVID -19 reporting to other epidemics such as MERS, \nEbola, and swine flu, but with particularly heavy comparison to SARS.  \nFor China, these frami ngs emphasized the panic and fear of stigmatization.  \nChinatowns across North America are reeling as panic and ignorance spread \nfaster than the actual coronavirus\u2026Chinese in North America are targets of \nmounting xenophobia and discrimination, including some  being told to \u201cgo \nhome\u201d. Though fear is a natural response to danger, the crisis has fanned \nentrenched stereotypes (Magnier, 2020).  \nThe manifestation of which is reported to be expressed through violence: \u201cother bullying, \nshunning, and assault cases hav e been reported across the continent, sparked by fears that \nthose with Asian features are more likely to carry the virus\u201d (Magnier, 2020). S. K. press, \nlikewise, covered news events with focus on French Asians\u2019 response to an \u201canti -Asian \nbacklash\u201d on socia l media with the hashtag of \u201cJeNeSuisPasUnVirus (I am not a virus)\u201d \n(Cho, 2020, para. 3). U.S. framing of moral panic/ othering from CNN tended to call out \negregious examples: \"The Indian state of Uttar Pradesh has sparked controversy after migrant \nworkers , returning home during a nationwide coronavirus lockdown, were doused in bleach \ndisinfectant used to sanitize buses\u201d (Gupta, Mitra, & Sud, 2020). Additionally, moral panic \ncoverage also coincides with talk of people panic buying items like masks, which al so \nfeatures othering: \u201cAt first, when I started looking for masks, people were really \nunderstanding,\" she said. \"But now, when I go up and ask, and I'm Asian, I can feel the look \non their face\u201d (Andrew & Yeung, 2020). The news outlet Breitbart in particula r had a high \npercentage of articles featuring the virus referred to as the \u201cWuhan virus\u201d or \u201cChina virus\u201d, \noften in discussion about responsibility.  \nDISCUSSION  \nThis study examined the COVID -19 press coverage through perspectives of framing and \nmoral panic.  Among the seven commonly used frames covering pandemics, denial/severity, \nmedical/science and economic consequence frames stood out, but for different reasons. While \nit was expected that the severity and medical/scientific frames were most frequently cove red \nthemes, what was striking was China\u2019s more intense focus on these issues, doubling the \namount of that of the S.K. and U.S.; moreover, conservative -leaning medias in S.K. and the \nU.S. tended to have less coverage on these issues than their liberal count erparts (e.g., \nBreitbart had only about half of the CNN\u2019s coverage on severity whereas about two -thirds of \nthe coverage on medical/science frame). Contrary to the vast coverage of severity and \nmedical frames, the economic consequences frame received minima l media attention despite \nof the COVID\u2019s devastating impact on economic activities. The other noteworthy findings \ninvolved mutual blames between China and the U.S. on leadership and responsibility, and \nChina\u2019s crusade on winning the war on coronavirus that  seemed to have aroused \ndisproportionate \u201cmoral panic\u201d, yet showed little interest in xenophobic \u201cthe othering\u201d tactics \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  34      \n aiming to label, stigmatize, or marginalize individuals and groups, when compared \nparticularly with the U.S.  \nTo be sure, this study had  data and methodological limitations, including sampling technics \n(selection of specific days and two media outlets per country) and the time frame (covering \nonly the first six months of 2020). As COVID -19 continued to evolve, the media\u2019s tone and \ncoverage  along these major frames could be changing as well. Nevertheless, our snapshot of \nthe particular time, event, and media coverage is informative for the theory on press\u2019s \nfreedom and responsibility, and within the larger political, economic and socio -cultu ral \ncontext.  \nYin\u2019s theory on press\u2019s freedom and responsibility provided a stark contrast between Eastern \nConfucian patriarchy and Western liberal social contract conceptions of government and the \nindividual. Media coverage of COVID -19, in our analysis, r eveals, in part, that governments \nin Asia (more so as shown in the Chinese strategies) tended to take full ownership of \neradicating the coronavirus by calling attention to the deadly virus (severity frame), and \ntaking extreme measures to lock -down cities a nd mandate stay -home order and mask wearing \n(severity and medical frames) in an effort to gain full control of the virus to save lives, albeit \njeopardizing some individuals\u2019 lives and needs in the process of doing so. In comparison, \nmedia coverage on gover nments in the U.S. tended to be more diverse and fragmented (partly \ndue to sporadic governmental responses and shifting strategies), raising awareness of the \ndeadly pandemic on the one hand, and challenging governmental authorities in mandatory \nshutdowns a nd mask wearing on the other.  \nWhile medias did seem to do their job in covering the governments\u2019 messages and serving as \na watch dog (e.g., SCMP, the Hong Kong based Chinese newspaper was somewhat critical of \nthe government), the extent to which they do th eir job depends on their role (e.g., Xinhua \nNews is the CCP\u2019s news agency thus serves its agenda), and organizational agenda (e.g., \nCNN and Breitbart represent the opposite ideological spectrum, thus at times projecting \ncompletely opposite tones and perspe ctives on the pandemic). Moreover, our analysis of the \nmedia coverage of the pandemic also seems to untangle (e.g., CNN condemned xenophobic \nattitudes towards Asians when coronavirus broke), and yet further entangles (e.g., Breitbart \nblamed China\u2019s failure  to stop the virus that resulted in huge financial losses and China shall \npay), the tension between nationalism/globalization and cultural misunderstandings/clashes \nof the East and the West. While Xinhua News and Chosun reported on mandatory mask \nwearing a s a matter of fact in China and S.K., mask wearing has been politicized and \notherized in the U.S. media.  \nIn a way, coronavirus, unlike previous, less contagious or deadly, outbreaks such as the \nSARS and the H1N1 flu, serves as a perfect human experiment in  examining competing \nnational models in handling a pandemic. It put the media outlets to the test as well, as truth \nand fairness of reporting will eventually emerge. Future research shall further explore the \ncompeting needs of a free and responsible press within the context of serving both the \nindividuals and national interests during a pandemic.  \n \n \n \n \n \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 35  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n REFERENCES      \n[1]. Andrew, S., & Yeung, J. (2020, Feb 29). Masks can't stop the coronavirus in the US, \nbut hysteria has led to bulk -buying, price -gouging and serious fear for the future. \nCNN. Retrieved from https://www.cnn.com/2020/02/29/health/coronavirus -mask -\nhysteria -us-trnd/index.html  \n[2]. Beaudoin, C. E. (2007). SARS news  coverage and its determinants in China and the \nUS. International Communication Gazette,  69(6), 509 -524. \n[3]. Bell, D. A. (2014). Reconciling Confucianism and nationalism.  Journal of Chinese \nphilosophy , 41(1-2), 33 -54. \n[4]. Bermingham, F. (2020, June, 30). China eco nomy steadied further in June, as slow \nrecovery from coronavirus continued. South China Morning Post. Retrieved from \nhttps://www.scmp.com/economy/china -economy/article/3091117/china -economy -\nsteadied -further -june-slow -recovery -coronavirus  \n[5]. Bouchet, N. (2013) . The democracy tradition in US foreign policy and the Obama \npresidency.  International Affairs,  89(1), 31 -51. \n[6]. Briggs, W. (2004). North America. In A. S. De Beer & J. C. Merrill (Eds.), Global \njournalism: Topical issues and media systems  (pp. 430 \u2013464). Bost on, MA: Allyn and \nBacon  \n[7]. Cheng, Maria. 2020. Testing Blunders Crippled US Response as Coronavirus Spread. \nUS News anad World Report. March 24, 2020. \nhttps://www.usnews.com/news/politics/articles/2020 -03-23/testing -blunders -crippled -\nus-response -as-coronavirus -spread  \n[8]. Cho, J. (2020, January 31). [\u201cI am not a virus\u201d hashtag movement among Asians]. \nChosunilbo. \nhttps://www.chosun.com /site/data/html_dir/2020/01/31/2020013100160.html  \n[9]. Chosunilbo. (2020a, February 29). [Opinion] We cannot overcome Wuhan corona \nwith such judgement and speed of decision making]. Chosunilbo. \nhttps://www.chosun.com/site/data/html_dir/2020/02/28/2020022803661. html \n[10]. Cohen, S. (2011). Whose side were we on? The undeclared politics of moral panic \ntheory.  Crime, media, culture,  7(3), 237 -243. \n[11]. Coronavirus latest: Spain sees single -day record 849 deaths; Indonesia bans foreigners \nentry. (2020, May 31). South China Mor ning Post. \nhttps://www.scmp.com/news/world/united -states -canada/article/3077656/coronavirus -\nlatest -trump -and-putin -discuss -pandemic  \n[12]. Duan, J. (2007). The discourse of disease: the representation of SARS -the China daily \nand the South China Morning Post.  \n[13]. Egan , M. (2020, March 31). Fed launches another emergency program to aid foreign \ncentral banks during pandemic. CNN. Retrieved from \nhttps://www.cnn.com/world/live -news/coronavirus -pandemic -03-31-20/index.html  \n[14]. Entman, R. M., & Rojecki, A. (1993). Freezing out t he public: Elite and media \nframing of the US anti \u2010nuclear movement.  \n[15]. Executive Branch -The President. (n.d.). Retrieved from \nhttp://www.opm.go.kr/en/government/branch.do  \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  36      \n [16]. Factbox: China's fight against novel coronavirus outbreak. (2020, March 31).  Xinhua. \nhttp://www.xinhuanet.com/english/2020 -03/31/c_138935827.htm  \n[17]. Freedom House. (n.d.). Freedom in the World 2020: South Korea. Retrieved from: \nhttps://freedomhouse.org/coun try/south -korea/freedom -world/2020  \n[18]. Global COVID -19 cases top 6 mln -- Johns Hopkins University. (2020, May, 31). \nXinhua. Retrieved from: http://www.xinhuanet.com/english/2020 -\n05/31 /c_139101588.htm  \n[19]. Goode, E., & Ben -Yehuda, N. (1994). Moral panics: Culture, politics, and social \nconstruction. Annual review of sociology, 20 (1), 149 -171. \n[20]. Gupta, S., Mitra, E., Sud, V. (2020, March 31). Migrant workers were sprayed with \ndisinfectant in on e Indian state. CNN. Retrieved from \nhttps://www.cnn.com/world/live -news/coronavirus -pandemic -03-31-20/index.html  \n[21]. Hallin, D. C., & Mancini, P. (2004). Comparing med ia systems: Three models of \nmedia and politics. Cambridge university press.  \n[22]. Italy records 203,591 coronavirus cases, death toll at 27,682. (2020, April 30). Xinhua. \nhttp://www.xinhuanet.com/english/2020 -04/30/c_139018964.htm  \n[23]. Hollingsworth, J., Yang, Y., & Thomas, N. (2020, January 31). 'We'll admit them if \nthey're dying': Virus outbreak pushes China's stretched health care workers to \nbreaking point. CNN. Retrieved from https://www.cnn.com/2020/01/30/asia/chinese -\nhealth -care-virus -intl-hnk/index.html  \n[24]. In phot os: Here's what construction on the new hospital in Wuhan looks like.(2020, \nJanuary 31). CNN. Retrieved from https://www.cnn.com/asia/live -news/coronavirus -\noutbreak -01-31-20-intl-hnk/index.html  \n[25]. Kim, C. (2020a, January 31). [An increasing case of infection which occurs a day or \ntwo before symptoms like a fever occur]. Chosunilbo. \nhttps://www.chosun.com/site/data/html_dir/2020/01/31/2020013100200.html  \n[26]. Kim, K. (2020b, Janua ry 31). [government who claimed economic rebound now \n\u201cconcerns about economic\u201d]. Chosunilbo. \nhttps://www.chosun.com/site/data/html_dir/2020/01/31/2020013100245.html  \n[27]. Kraychik, R. (2020, March 31). Dr. Nicole Saphier: \u2018Reason to Hope\u2019 with \nDeveloping Coronavirus Treatments. Brietbart. Retrieved from \nhttps://www.breitbart.com/radio/2020/03/31/dr -nicole -saphier -reason -hope -\ndeveloping -coronavirus -treatments/  \n[28]. Kupferschmidt, Ka i and Cohen, Hon. 2020. China\u2019s Aggressive Measures have \nslowed the Coronavirus. They may not work in other countries. Science. March 2, \n2020.  \n[29]. Lam, W. W. L. (2015).  Chinese politics in the era of Xi Jinping: Renaissance, reform, \nor retrogression? Routledg e. \n[30]. Letters (2020, February 29). Coronavirus outbreak: stop kicking China and Chinese \ncommunities when they\u2019re down. The South China Morning Post.  \nhttps://www.scmp.com/comment/letters/article/3052634/coronavirus -outbreak -stop-\nkicking -china -and-chinese -communities  \nAsian Journal of Social Sciences & H umanities   Vol. 10(1) F eb-May 2021  \n_____________________________________________________________________________________________________________________________ _______________________________________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ _________________________________________________________________________________  \nCopyright \u00a9 2021              Leena and Luna International, Chikusei , Japan.  \n 37  |  P a g e                (\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c ISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww. ajssh.  leena -luna.co.jp  \n [31]. Liebman, B. L. (2005). Watchdog or demagogue -the Media in the Chinese Legal \nSystem. Colum. L. Rev., 105, 1.  \n[32]. Luther,  C. A., & Zhou, X. (2005). Within the boundaries of politics: News framing of \nSARS in China and the United States . Journalism & Mass Communication \nQuarterly,  82(4),857 -872. \n[33]. Magnier, M. (2020, February 29). Coronavirus stigma adds to long -term challenges \nfor North American Chinatowns. South China Morning Post. Retrieved from \nhttps://www.scmp.com/news/china/society/article/3052981/coronavirus -stigma -adds-\nlong-term-challenges -north -american  \n[34]. Martel, F. (2020, January 31). Chinese Media: \u2018Local Negligence\u2019 Worse ned Viral \nOutbreak. Breitbart. Retrieved from \nhttps://www.breitbart.com/asia/2020/01/31/chinese -media -local -negligence -\nworsened -viral-outbreak/  \n[35]. Meng, J., & Berger, B. K. (2008). Comprehensive dimensions of government \nintervention in crisis management: A qualitative content analysis of news coverage of \nthe 2003 SARS epidemic in China.  China Media Research,  4(1), 19 -28. \n[36]. Moon declares support for i nt'l press freedom initiative. (2019, September 18). \nYONHAP NEWS AGENCY. Retrieved from: \nhttps://en.yna.co.kr/view/AEN20190918005100315  \n[37]. Morrison, Wayne M. 2019. China\u2019s Economic Rise: History, Trends, Challenges, and \nImplications for the United States. Congressional Research Service.   \n[38]. Muzzatti, S. L. (2005). Bits of falling sky and global pandemics: Moral panic and \nSevere Acute Respiratory Syndrome (SARS).  Illness, Crisis & Loss,  13(2), 117 -128. \n[39]. Ortiz, I., & Darby, B. (2020, April 30). Mexico Nears 18K Coronavirus Cases Despite \nAdmitted Undercount. Breitbart. Retrieved from \nhttps://www.breitbart.com/border/2020/04/30/mexico -nears -18k-coronavirus -cases -\ndespite -admitted -undercount/  \n[40]. Projected GDP R anking. (2020, February 20). Retrieved from \nhttp://statisticstimes.com/economy/projected -world -gdp-ranking.php  \n[41]. Reporters Without Borders. (n.d.). South Korea: Distinct impro vement after a bad \ndecade. Retrieved from: https://rsf.org/en/south -korea  \n[42]. Robinson, P. (2001). Theorizing the influence of media on world politics: Models of \nmedia influence on foreign policy.  European Journal  of Communication,  16(4), 523 -\n544. \n[43]. Rothe, D., & Muzzatti, S. L. (2004). Enemies everywhere: Terrorism, moral panic, \nand US civil society.  Critical Criminology,  12(3), 327 -350.  \n[44]. Russia upset by Western attempts to blame China for COVID -19: FM. (2020, April \n30). Xinhua. http://www.xinhuanet.com/english/2020 -04/30/c_139019206.htm  \n[45]. Siebert, F. (1963). The Authoritarian Theory. In Seiber, F. Peterson, T. & Schramm, \nW. (Ed.). Four Theories of the Press . Illinois: University of Illinois Press.  \n[46]. Spotlight: U.S. Fed warns of considerable medium -term risks amid COVID -19 fallout. \nXinhua. http://www.xinhuanet.com/english/2020 -04/30/c_139020985.htm  \nAsian Journal of Socia l Sciences & Humanities   Vol. 10(1) Feb -May 2021  \n___________________________________________________________________________________________ _____________________________________________________________________________________________________________________________ ________________________________________ _____________________________________________________________________________________________________________________________ _____________________________________________________________________  \n \nISSN: 2186 -8492,  ISSN:  2186 -8484 Print  \nwww.ajssh.leena -luna.co.jp  Leena and Luna International, Chikusei , Japan.                                 Copyright \u00a9 2021  \n(\u682a) \u30ea\u30ca\u30a2\u30f3\u30c9\u30eb\u30ca\u30a4\u30f3\u30bf\u30fc\u30ca\u30b7\u30e7\u30ca\u30eb , \u7b51\u897f\u5e02 ,\u65e5\u672c                                                                                   P a g e |  38      \n [47]. Sun, F. (2020, February 29). Amid coronavirus outbreak, bigger killers lurk for Hong \nKong\u2019s elderly living alone \u2013 isolation and panic. South China Morning Post. \nRetrieved from https://www.scmp.com/news/hong -kong/health -\nenvironment/article/3052694/amid -coronavirus -outbreak -bigger -killers -lurk \n[48]. Sutton, J. (2020, March 31). US reports highest daily death count. CNN. Retrieved \nfrom https://www.cnn.com/world/live -news/coronavirus -pandemic -03-31-\n20/index.html  \n[49]. Thompson, Derek. 2020. What\u2019s Behind South Korea\u2019s COVID -19 Exceptionalism? \nThe Atlant ic May 6. 2020.  \n[50]. Update: Coronavirus watch, April 30 (2020, April 30). Xinhua. \nhttp://www.xinhuanet.com/english/2020 -04/30/c_139021627.htm  \n[51]. Wang, R., & Groot, G. (2018). Who represe nts? Xi Jinping\u2019s grand united front work, \nlegitimation, participation and consultative democracy.  Journal of Contemporary \nChina,  27(112), 569 -583. \n[52]. Wu, W., & Wong, C. (2020, January 31). World Health Organisation call to arms \nagainst virus needs global res ponse to help China. South China Morning Post. \nRetrieved from https://www.scmp.com/news/china/society/article/3048491/worl d-\nhealth -organisation -call-arms -against -virus -needs -global  \n[53]. Xie, X., & Ding, Y. (2016). Framing iPhone Consumption by Chinese Mainlanders: \nCritical Discourse Analysis on News Coverage of China Daily and South China \nMorning Post. Procedia -Social and Behavio ral Sciences , 236, 39 -45. \n[54]. Xie, X., & Ding, Y. (2016). Framing iPhone Consumption by Chinese Mainlanders: \nCritical Discourse Analysis on News Coverage of China Daily and South China \nMorning Post. Procedia -Social and Behavioral Sciences , 236, 39 -45. \n[55]. Yin, J. (2008). Beyond the four theories of the press: A new model for the Asian & \nthe world press.  Journalism & Communication Monographs,  10(1), 3 -62. \n[56]. Yu, S., & Choi, W. (2020, February 29). [\u201cWhat if my child get infected by \ncoronavirus\u201d two percent application for Dolbom]. Chosunilbo.  \n[57].         https://www.chosun.com/site/data/html_dir/2020/02/29/2020022900115.html  \n[58]. Zhang, E., & Fleming, K. (2005). Examination of characteristics  of news media under \ncensorship: A content analysis of selected Chinese newspapers\u2019 SARS \ncoverage.  Asian Journal of Communication,  15(3), 319 -339. \n[59]. Zhou, C., & Ng, T. (2020, January 31). Coronavirus: Chinese health experts warn \npatients can get reinfected. South China Morning Post. Retrieved from \nhttps://www.scmp.com/news/china/society/article/3048320/china -coronavirus -deadly -\nday-hubei -record -high-42-patients -die \n[60]. Zurcher, Anthony. 2020. Coronavirus Response: Things the US has got right \u2013 and \ngot wrong. BBC N ews. May 13, 2020. https://www.bbc.com/news/world -us-canada -\n52579200  \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "MEDIA FRAMING, MORAL PANIC AND COVID-19: A COMPARATIVE ANALYSIS OF CHINA, SOUTH KOREA, AND THE US.", "author": ["D DeVore", "S Choi", "Y Li", "H Lu"], "pub_year": "2021", "venue": "Asian journal of social \u2026", "abstract": "COVID-19 is perhaps the single most impactful event defining 2020 globally. Drawing on  theory on media typology involving freedom and responsibility, media framing and moral panic"}, "filled": false, "gsrank": 246, "pub_url": "https://scholarworks.utrgv.edu/cj_fac/74/", "author_id": ["", "Qj58Fn4AAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:bZfHdMmqWHAJ:scholar.google.com/&output=cite&scirp=245&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=bZfHdMmqWHAJ&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 12, "citedby_url": "/scholar?cites=8095408112422852461&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:bZfHdMmqWHAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://scholarworks.utrgv.edu/cgi/viewcontent.cgi?article=1073&context=cj_fac"}}, {"title": "Detecting anti-vaccine users on Twitter", "year": "2023", "pdf_data": "Detecting Anti-vaccine Users on Twitter\nMatheus Schmitz, Goran Muric, Keith Burghardt\nUSC Information Sciences Institute\n{mschmitz, gmuric, keithab}@isi.edu\nAbstract\nVaccine hesitancy, which has recently been driven by online\nnarratives, significantly degrades the efficacy of vaccination\nstrategies, such as those for COVID-19. Despite broad agree-\nment in the medical community about the safety and efficacy\nof available vaccines, a large number of social media users\ncontinue to be inundated with false information about vac-\ncines and are indecisive or unwilling to be vaccinated. The\ngoal of this study is to better understand anti-vaccine senti-\nment by developing a system capable of automatically iden-\ntifying the users responsible for spreading anti-vaccine narra-\ntives. We introduce a publicly available Python package ca-\npable of analyzing Twitter profiles to assess how likely that\nprofile is to share anti-vaccine sentiment in the future. The\nsoftware package is built using text embedding methods, neu-\nral networks, and automated dataset generation and is trained\non several million tweets. We find this model can accurately\ndetect anti-vaccine users up to a year before they tweet anti-\nvaccine hashtags or keywords. We also show examples of\nhow text analysis helps us understand anti-vaccine discus-\nsions by detecting moral and emotional differences between\nanti-vaccine spreaders on Twitter and regular users. Our re-\nsults will help researchers and policy-makers understand how\nusers become anti-vaccine and what they discuss on Twitter.\nPolicy-makers can utilize this information for better targeted\ncampaigns that debunk harmful anti-vaccination myths.\nIntroduction\nAnti-science, and especially anti-vaccine, attitudes are\npresent within a large and recently active minority (Germani\nand Biller-Andorno 2021; Murphy et al. 2021). Anti-vaccine\nprotesters are partly responsible for a significant resurgence\nof measles and other diseases for which vaccines have ex-\nisted for decades (Smith 2017). Vaccine hesitancy is espe-\ncially problematic for COVID-19, which continues to be an\nepidemic, especially within the United States, due in part to\nindividuals not socially distancing, wearing masks, and be-\ncoming vaccinated, despite the advice of the medical com-\nmunity. The rapid spread of anti-science conspiracy theories\nand polarization online is one reason behind these attitudes\n(Druckman et al. 2020; Rao et al. 2020). This motivates our\nresearch in applying machine learning to predict, rather than\njust classify, if individuals will become anti-vaccine. Such a\nCopyright \u00a9 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.tool can help policy-makers and researchers uncover factors\nthat draw people to become anti-vaccine and design targeted\ncampaigns that reduce vaccine hesitancy. We would also like\nto do this at scale by applying these predictions to social me-\ndia users.\nIn this paper, we create an algorithm we call AVAX-\nTAR that evaluates the likelihood a Twitter account will\nspread anti-vaccine narratives. This code is freely avail-\nable as a Python package: https://github.com/Matheus-\nSchmitz/avaxtar. The underlying model in A V AXTAR is\ntrained to predict whether a Twitter account will spread anti-\nvaccine hashtags or keywords up to a year in advance. A\nresearcher can provide a Twitter ID or unique screen name\nto A V AXTAR and the package then retrieves the target ac-\ncount\u2019s recent activity. From this activity, the package re-\nturns the account\u2019s probability of future anti-vaccine discus-\nsion. Twitter is explored in this paper because it is a popu-\nlar social media website with an ongoing problem of anti-\nscience rhetoric (Rao et al. 2020).\nWe also leverage the dataset gathered for model train-\ning to explore the textual differences between the tweets\nposted by users who do and users who do not spread the\nanti-vaccine narratives. This analysis provides clues about\nthe underlying reasons for anti-vaccine sentiment as well as\nthe rhetorical devices people use to spread misinformation.\nOverall, the presented work provides a new method to un-\nderstand the recent uptick in anti-vaccine sentiment by iden-\ntifying users prone to disseminating such messages, and can\nhelp policy-makers devise targeted information campaigns.\nRelated Work\nDetecting Vaccine Sentiment\nSeveral papers on detecting vaccine sentiment have been de-\nveloped. Wang et al. (2020) developed a multi-modal system\nto classify tweets as containing anti-vaccine sentiment, and\nthe authors achieve a 97% accuracy and F1-score. A compli-\nmentary ablation study displays which sections of images,\ntexts and hashtags were most associated with the label by\nthe model. An alternative data source is presented by Carri-\neri et al. (2021), who use area-level indicators from Italy to\ndevelop various models which both detect vaccine hesitancy\nby region as well as provide a list of the most important fea-\ntures associated with vaccine hesitancy. A third approach to\nProceedings of the Seventeenth International AAAI Conference on Web and Social Media (ICWSM 2023)\n787\ndata collection was employed by Lincoln et al. (2022), who\ncollected survey data from adults in five countries, assessing\nstances on vaccine hesitancy as well a various demographic\nand psychographic factors. That data is then used to train a\nrandom forest classifier, which obtains a recall score of 82%\nand precision of 79-82% depending on country.\nPredicting anti-vaccine hesitancy, rather than simply de-\ntecting it, is a more difficult problem with comparatively less\nresearch. Huang et al. (2017) applied a range of conventional\nclassifiers to detect whether someone received, or intended\nto receive, an influenza vaccine from a Twitter dataset on\ntweets about influenza from 2013 to 2016 (three flu seasons).\nThey report F1 scores of up to 82%. Krishnan et al. (2021)\napplied the same dataset to predict vaccine hesitancy using\nLatent Dirichlet Allocation and Particle Swarm Optimiza-\ntion and found an F1 score of 84%.\nText Analysis of Vaccine Hesitancy\nOne of the first papers exploring text associated with vaccine\nhesitancy was by Amin et al. (2017) who explored moral val-\nues and vaccine hesitancy. They find that harm and fairness\nfoundations are not significantly associated with vaccine\nhesitancy, but purity and liberty foundations are. Medium-\nhesitancy adults were twice as likely as low-hesitancy ones\nto highly emphasize purity, while high-hesitancy adults were\ntwice as likely to strongly emphasize both purity and lib-\nerty. A complimentary explanation of the drivers of anti-\nvaccination behavior comes from Kadam (2017), who at-\ntempts to determine the events and incidences responsible\nfor amplifying pro-vaccination and anti-vaccination senti-\nments. The author reports two sets of hashtags which are\nassociated with positive and negative sentiments on vac-\ncines. Germani et al. (2021), meanwhile, explore data on\nanti-vaccination supporters within Twitter, identifying they\nshare more conspiracy theories, make larger use of emo-\ntional language, are more engaged in discussions and share\ntheir contents from a poll of strong influencers. The authors\nobserve that the anti-vaccine movement\u2019s success depends\non a strong sense of community, reliant on the content pro-\nduced by a minority of users, with the larger community\nworking as an amplifier bringing anti-vaccination discourse\nthe platform at large.\nFelmlee et al. (2020) exploit a Twitter policy change re-\nlated to abusive content to test the effectiveness of organiza-\ntional policies aimed at stemming online harassment. They\nfind evidence of a modest positive shift in the sentiment of\ntweets with slurs targeting women and/or African Ameri-\ncans. Retweeted messages are more negative than those not\nforwarded. These patterns suggest that organizational \u201canti-\nabuse\u201d policies can play a role in stemming hateful speech\non social media without inflaming further abuse. Network\neffects and the out-sized impact of certain users can be ap-\npreciated in Radzikowski el al. (2016), who explores Twitter\nnarratives regarding vaccination in the aftermath of the 2015\nmeasles outbreak. They find stories contributed by news or-\nganizations have a higher impact compared to direct tweets\nby health organizations in communicating health-related in-\nformation. A complimentary example of low relevance fac-\ntors comes by Hornsey et al. (2020), who study the rela-tionship between trust in Complementary and Alternative\nMedicines (CAM) and vaccine hesitancy, finding that trust\nin CAM is only a weak predictor of vaccine hesitancy.\nCommunity Analysis\nSeveral papers have explored relationships between the so-\ncial network and vaccine hesitancy. Francia et al. (2019)\ncombines both community detection and text analytics\nmethodologies to characterize the Twitter debate on vac-\ncination in Italy. The authors find a strong association be-\ntween political leaning and vaccination stance, a high simi-\nlarity between groups opposing vaccines entirely and those\nopposing vaccine mandates, and large passive communities\nwith a focus on non-vaccine topics but with a pro- or anti-\nvaccine stance. Bello et al. (2017) create a graph of Twit-\nter discussion communities on vaccination. Adding geoloca-\ntion information the authors generate a summary of the rele-\nvance of vaccination topics across countries and tag commu-\nnities to their associated countries, with the US hosting the\nmajority of the anti-vaccination movement. Combing Ma-\nchine Learning and graph models, Yuan et al. (2019) ex-\nplore tweets related to the MMR vaccine published after the\n2015 California Disneyland measles outbreak. They use ma-\nchine learning to classify users into anti-vaccination, neu-\ntral, and pro-vaccination groups. Using community detec-\ntion, the authors show that pro- and anti-vaccine users share\npredominantly in-group narratives. Moreover, anti-vaccine\ncommunities are highly clustered and enclosed. Schmidt et\nal. (2018) detect the emergence of communities on Face-\nbook (rather than Twitter, as in previous work), showing the\nconsumption of content about vaccines is dominated by the\necho chamber effect and that polarization has increased over\nthe years. Well-segregated communities emerge from the\nusers\u2019 consumption habits with few cross-ideological con-\ntent consumption.\nKang et al. (2017) constructed semantic networks of\nvaccine articles shared by Twitter users, finding negative\nvaccine-sentiment networks centered on larger organiza-\ntions, while positive-sentiment networks show more cohe-\nsive discourse, with discussions about parents, vaccines, and\ntheir non-association with autism. Analysis by Featherstone\net al. (2020) discuss analysis of tweets about childhood\nvaccines, finding a wide sharing of vaccine misinformation\nwithin a well-connected anti-vaccine community, with a few\ninfluential users located in certain geo-located clusters pro-\nducing the bulk of the content. The authors also find that\npro-vaccine and anti-vaccine tweets are predominantly of\nnegative tone, although such negativity can also be a re-\nflection of the incentives created by social media feed al-\ngorithms or negativity bias (Peeters and Czapinski 1990). A\ntheoretical take on communities is presented by Barlett et\nal. (2018), who discuss how social media anonymity can in-\ncrease cyberbullying perpetration. Further prescriptive guid-\nance is provided in Wilson et al. (2014), in the form of a\nframework for using mobile technology to increase vaccine\nconfidence as well as to create a surveillance and response\nsystem that monitors digital conversations on the topic and\nprovide public health officials early warning about clusters\nof people with fading confidence in vaccination.\n788\nContributions of our Research\nOur work contrasts with these previous papers by develop-\ning and distributing an open-source library to empower fu-\nture research in the field. Many previous papers developed\nbespoke machine learning models as steps to achieve other\ngoals, and few have been applied to classify anti-vaccine\nsentiment. More specifically, this work is unique in predict-\ning the vaccination stance of users up to one year before\nthey begin to tweet anti-vaccine rhetoric. In addition, our\ncomparative analysis of transformer-based classifiers within\nCOVID-19 tweet discussions improves the robustness of our\nmethods. Finally, we employ natural language processing\ntools to understand the differences in emotions, morals, and\ncommon words of anti-vaccine users at scale.\nMethods\nData Collection\nThe AVAXTAR classifier is trained on a comprehensive la-\nbeled dataset of tens of millions of tweets from approxi-\nmately 130 thousand Twitter accounts. Each account from\nthe dataset was assigned one of two labels: 1for the ac-\ncounts that actively spread anti-vaccination hashtags or key-\nwords (\u2248 70thousand) and 0for the accounts that do not\ntweet anti-vaccine hashtags or keywords (\u2248 60thousand).\nBy leveraging Twitter\u2019s Academic Research Product Track,\nwe were able to access the full archival search and overcome\nthe limit of 3,200 historical tweets of the standard API. We\ntherefore collect almost all historical tweets of most queried\naccounts (for a small fraction of accounts that are highly ac-\ntive we interrupted the collection prematurely, due to Twit-\nter\u2019s API limitations). Sample tweets from users belonging\nto each class are shown in Table 1.\nCollecting anti-vaccine samples. In this study, we la-\nbel anti-vaccination users as \u201c1\u201d, where ground-truth anti-\nvaccine users come from an existing dataset of anti-vaccine\nTwitter accounts and their respective tweets, collected and\npublished by Muric et al. (2021). The authors first used a\nsnowball method to identify a set of hashtags and keywords\nassociated with the anti-vaccination movement, and then\nqueried the Twitter API and collected the historical tweets\nof accounts that used any of the identified hashtags or key-\nwords. More than 135 million tweets were collected from\nmore than 70 thousand accounts.\nCollecting not anti-vaccine samples. To collect data on\nexamples of tweets and users that are not anti-vaccine (la-\nbeled \u201c0\u201d), we first performed a similar approach to Muric\net al. (2021), and queried the Twitter API to get historical\ntweets of accounts that do not use any of the predefined key-\nwords and hashtags. Using this method, we collected the\ntweets of \u223c30thousand accounts that do not spread anti-\nvaccination narratives or are impartial about the topic. This\nsample most likely represents typical Twitter users. We then\nenrich this sample by gathering the tweets from accounts\nthat are likely proponents of the vaccination. We identify the\nproponents of the vaccines in the following way: First, we\nidentify the set of twenty most prominent doctors and health\nexperts active on Twitter. Then, we manually collected theURLs of Lists1those health experts they made on Twitter.\nWe specifically searched for lists with epidemiology-related\nnames (e.g., \u201dcoronavirus experts\u201d or \u201depidemiologists\u201d).\nFrom those lists, we collected approximately one thousand\nTwitter handles of prominent experts and doctors who tweet\nabout the coronavirus and the pandemic. We went through\ntheir latest 200 tweets and collected the Twitter handles of\nusers who retweeted their tweets. That became our pool of\npro-vaccine users. The users who retweeted many distinct\nexperts were more likely to be included than users who\nretweeted a few. Finally, we collected the historical tweets\nof users from the pro-vaccine pool. This way we collected\nmore than 50 million tweets from more than 30 thousand\naccounts that are most likely pro-vaccine, therefore 60thou-\nsand accounts and more than 100 million tweets are gathered\nfrom users who were not anti-vaccine.\nClassification System\nGenerating Training Dataset. If we na \u00a8\u0131vely train on these\nlabeled data, we might only capture whether users did or\ndid not use particular keywords and hashtags, which would\nalso artificially inflate the model accuracy. We instead want\nto capture more nuanced user language, which allows for a\nmore robust and generalizable model. To address this, we\ntrain on anti-vaccine accounts before its labeling date, the\nfirst date in which the account published a tweet that con-\ntained one of the predefined anti-vaccination hashtags and\nkeywords defined in Muric et al. (2021). For the not anti-\nvaccine user cohort, their labeling date was the date of their\nmost recent tweet. All tweets from the 15 months prior to\nthat date were considered in model training, with samples\nbeing created within a 90-day time windows prior to the la-\nbeling date: [0-90), [60-150), [120-210), [180-270), [240-\n330), [300-390), [360-450) days. For each time window, all\ntweets from a given user were merged into a single docu-\nment. The resulting training dataset contains 130thousand\nusers, 70% of which were sampled for training, 15% for val-\nidation and 15% for testing.\nModel Selection. We consider three candidate sentence\nembedding models which are state-of-the-art in this cat-\negory while also being sufficiently small that users can\nrun them on regular desktop machines, as our goal is\nto provide an accessible and useful package. The models\ntested were: Sent2Vec (Gupta, Pagliardini, and Jaggi 2019),\nSentence-MPNet (Song et al. 2020), and Sentence-Distill-\nRoberta (Liu et al. 2019). Techniques for adapting word-\nlevel transformers into sentence-level models come from\nReimers et al. (2019), while distillation is a technique pio-\nneered by Hinton et al. (2015) that enables model shrinkage\nwith little or no loss in performance.\nSentence-Distill-Roberta was trained on OpenWeb-\nText (Radford et al. 2019). Sentence-MPNet was trained on\nWikipedia and BooksCorpus (Zhu et al. 2015), OpenWeb-\nText (Radford et al. 2019), CC-News (Liu et al. 2019) and\nStories (Trinh and Le 2018). Initially a Sent2Vec embed-\n1Twitter Lists allow users to customize, organize and prioritize\nthe tweets they see in their timelines. Users can choose to join Lists\ncreated by others on Twitter.\n789\nAccount 1 Account 2\nTweet 1 As first runner-up to my esteemed @StarTrek colleague\n@levarburton [when we appeared on #TheWeakestLink\n], I would be honored to try my hand as #Jeopardy guest\nhost. My experience as a science presenter for @explore-\nplanets emboldens me to #boldlygo !Even with the inflated (for scaremongering purposes I\ncan only assume) figure of 126k people who died WITH\n(not OF remember) covid19, that would mean that in\na whole year this \u201dkiller virus\u201d hasnt even managed\nto kill 0.19% of almost 68 million people in the UK.\n\u201dpandemic\u201d\nTweet 2 @SpaceX is daring some mighty things. To the stars! #NoVaccinePassportsAnywhere #NoVaccinePass-\nportAnywhere #NoVaccinePassports #NoVaccinePass-\nport #novaccinatingthechildren\nTweet 3 Congratulations to all at Blue Origin. Nicely done! It\u2019s a new week, and no better a time to remind @nad-\nhimzahawi that he\u2019s a disgusting, two-faced parasite\nwhose name will forever be synonymous with lies, cor-\nruption and bloodshed. Please help him get the message\nTweet 4 We visited Virgin Galactic back in 2018. Flew the sim-\nulator. Looked like it was going to fly well. And it did.\nCongratulations to All!#NoVaccinePassportsAnywhere #NoVaccinePassports\n#MedicalApartheid #wedonotconsent Really handy\nwebsite to contact your MP directly...\nAnti-\nVaccine\nProbabil-\nity0.0705813 0.99880254\nTable 1: Sample tweets from each class\nder pre-trained on Twitter bigrams was employed, but it pre-\nsented engineering challenges with regards to publishing a\npackage, as the model needs 22GB of working memory,\nmaking it too large for most users\u2019 computers. We ran exper-\niments with alternative smaller embeddings models, trained\non either Wikipedia or the BookCorpus dataset (Zhu et al.\n2015), and we found that a model based on a Wikipedia em-\nbedder presented only a 1% loss in F1-Score, while being\nsignificantly smaller, at 8GB. All comparisons in this paper\nare made using this Wikipedia-based version of Sent2Vec.\nEmbeddings are created for all tweets within each user-\nwindow. They are then used to train the feed-forward neu-\nral network. After fine tuning the architecture and hyper-\nparameters, the final obtained neural network consists of\nthree layers: (1) Fully connected layer of size equals to each\nmodels\u2019 embedding dimension, (2) Fully connected layer\nwith half the size of the previous layer and (3) Fully con-\nnected layer with half the size of the previous layer. In be-\ntween layers a 40% dropout rate was applied. We used hy-\nperbolic tangent activation between the layers and a softmax\nactivation to generate prediction confidences. The batch size\nwas 128, binary cross-entropy is used as loss function, and\nthe optimizer is Adaptive Moment Estimation with Weight\nDecay (AdamW) (Loshchilov and Hutter 2019).\nFeature Engineering. The Twitter API provides a stan-\ndard output containing a variety of data and metadata for\neach tweet. Thus, many more potentially useful tweet fea-\ntures are obtained, which are then used to generate several\nengineered features in an attempt to improve the predictive\nmodel. To construct engineered features, we considered fac-\ntors such as the count and share of tweets, retweets, replies\nand quotes; the median number of favorites, retweets, repliesand quotes that a user\u2019s publications receive; the number\nof days in which the user made a publication; whether the\nuser\u2019s account is verified; the average sentiment (positive\nor negative) of the users posts, obtained with the python\npackage (vaderSentiment) for V ADER (Hutto and Gilbert\n2014); the number and percentage of total tweets from\na user which are retweets of prominent anti-vaccination\nusers; and lastly, the number of times a user shared an\nURL to websites considered \u201cConspiracy Pseudoscience,\u201d\n\u201cQuestionable Sources,\u201d or \u201cPro Science\u201d according to Me-\ndia Bias/Fact Check (mediabiasfactcheck.com/), a website\nthat rates media outlets on their factual accuracy and po-\nlitical leaning. These features were generated using the\nsame sliding window procedure described above: [0-90),\n[60-150), [120-210), [180-270), [240-330), [300-390), [360-\n450) days. The model was then trained with embeddings\nplus engineered features, embeddings only, and engineered\nfeatures only, and performance analysis revealed all engi-\nneered features to have negligible impact on accuracy, F1-\nScore, ROC-AUC, and PRC-AUC when used alongside the\ntransformer embeddings. Based on those results, the engi-\nneered features were dropped from the model, and the final\nmodel thus utilizes only textual embeddings.\nFine Tuning. For all models we fine tune the classifica-\ntion threshold to be used, based on maximizing F1 score\non the validation set. Using the optimized threshold, the re-\nsulting models were then evaluated on a test set of users,\nachieving the scores shown in table 2. Based on this analysis,\nSent2Vec was chosen as the model to underpin the A V AX-\nTAR package, as it shows the highest performance across\nall metrics considered. For the chosen model, a test-set Con-\nfusion Matrix and F1-Score analysis is shown in Figure 1.\n790\nMetric Sent2Vec S-MPNet S-Distill-Roberta\nAccuracy 0.8566 0.8336 0.8350\nROC-AUC 0.9084 0.8821 0.8826\nPRC-AUC 0.9601 0.9474 0.9473\nPrecision 0.8541 0.8317 0.8319\nRecall 0.8566 0.8336 0.8350\nF1 0.8550 0.8325 0.8331\nTable 2: Classifier evaluation scores on the test set\nFigure 1: Upper: Confusion Matrix before and after thresh-\nold optimization; Lower: Relation between classification\nthreshold and F1-Score. Optimal threshold for the highest\nF1-Score is 0.5729.\nWe find that for the Sent2Vec model a threshold of 0.5729\nresults in the highest F1 Score, and thus recommend that\nthreshold instead of the more typical threshold of 0.5.\nWe assess the model against the full test data (using all\nwindows) as well as against each specific window. As we\nincrease the gap between data collection and the posting pe-\nriod being predicted, from 0 days up to 360 days, we see a\nslight decrease in performance, as the model must rely only\non tweets further in the past. When comparing the one-year\ngap with zero-days gap, we observe a drop in ROC-AUC\nfrom 0.94 to 0.85, as shown in table 3. We also notice a\nsparser set of data as we move further back because users are\nless likely to have continuously tweeted over one year. These\nresults suggests that predicting anti-vaccine sentiment, de-\nfined as using anti-vaccine hashtags or keywords, is feasible\nup to a year before a user makes any anti-vaccine tweets.\nPython Package. The trained neural network was\nbundled alongside a script that automates the fetching\nof the relevant data from the Twitter API. The code\nwas then packaged alongside auxiliary scripts and pub-\nlished to GitHub under the acronym A V AXTAR: Anti-\nV AXx Tweet AnalyzeR 1.0 and is accessible on GitHub:\nhttps://github.com/Matheus-Schmitz/avaxtar. The package\nabstracts all the feature generation and data manipulation as-\npects of the task, requiring the user to enter only their Twit-\nFigure 2: Most frequently used words for anti-vaccine and\nnon anti-vaccine users. A few words used uncommonly of-\nten by each respective group are highlighted.\nter credentials (required for fetching data), alongside a target\nuser\u2019s screen name or user id. The provided output consists\nof a set of probabilities for the user belonging to the \u201cnot\nanti-vaccine\u201d class (0) and to the \u201canti-vaccine\u201d class (1).\nData Analysis\nA model based on sentence embedding does not necessarily\nprovide insights into the differences between anti-vaccine\nusers and all others. To understand what sets these users\napart, we analyze the differences in their text. We first an-\nalyze the relative popularity of words used by members of\neach group, which is shown in Figure 2; axes are in log-scale\nand we plot the most common words in each class. We find\nthat, at least among the highest frequency words, the main\ntopic of discourse among Anti-Vaccine users is not vaccina-\ntion itself, but rather politics in general, with both Trump and\nBiden as well as \u201cdemocrat,\u201d \u201cfraud,\u201d and \u201cpatriot\u201d among\nthe words whose usage skews the most towards the Anti-\nVaccine group. The linguistic differences between Anti-\nVaccine users and not Anti-Vaccine users is consistent with\nresearch on conspiracy theory content, which found that\nconspiracy theorists consistently use words like \u201cstealing\u201d\nand \u201cgovernment\u201d more often than most users (Klein, Clut-\nton, and Dunn 2019). The Not Anti-Vaccine users, on the\nother hand, use COVID-19 and vaccination-related words\namong its most frequently used words. This is possibly a\nresult of how the Not Anti-Vaccine cohort is defined, with\nhalf of its samples being random Twitter users, and the other\nhalf being those who interact with pro-vaccination experts,\nwhere the latter group being more prone to active engage-\nment in conversation in the vaccination topic.\nUsing the NRC Lexicon (Mohammad and Turney 2013),\na sentiment and emotion lexicon, the average sentiment and\nemotion of tweets published by each class is displayed in\nFig 3. The anti-vaccination users lean towards a negative\nemotion, including displaying greater anger, disgust, fear,\n791\nTest Data Gap Not Anti-vaccine Samples Anti-vaccine Samples Accuracy F1-Score ROC-AUC PRC-AUC\nAll Windows 8471 22425 0.8566 0.8550 0.9084 0.9601\n[0-90) 1540 10233 0.9240 0.9216 0.9411 0.9893\n[60-150) 1427 3601 0.8566 0.8551 0.9113 0.9596\n[120-210) 1319 2495 0.8296 0.8298 0.8901 0.9319\n[180-270) 1218 1979 0.8051 0.8048 0.8708 0.9097\n[240-330) 1115 1675 0.8047 0.8040 0.8697 0.9021\n[300-390) 998 1468 0.8049 0.8024 0.8701 0.8987\n[360-450) 854 1351 0.7927 0.7915 0.8536 0.8941\nTable 3: Classifier evaluation scores on the test set\nFigure 3: Emotion and Sentiment of tweets from Anti-\nVaccination and Non-Anti-Vaccination accounts, based on\nNRC Lexicon (Mohammad and Turney 2013).\nsurprise, and trust. These users simultaneously have slightly\nlower sadness, anticipation, joy, and lower positive senti-\nment. The Mann-Whitney U Test revealed all features for\nboth emotions and sentiments to have a statistically signifi-\ncant between-class difference in their distributions (p-value\n<10\u22127).\nAn analysis of the Moral Framing associated with\neach group, based on the Modal Foundations The-\nory, was performed leveraging the Moral Foundations\nFrameAxis (Mokhberian et al. 2020) and is illustrated\nin Figure 4. Moral foundation theory considers five ba-\nsic moral foundations: loyalty, care, sanctity, authority,\nand fairness, used across cultures to determine moral-\nity (Haidt and Joseph 2004). Determining the morals in\ntext is difficult, but one method to address this is by using\nword embeddings (Mokhberian et al. 2020), and based on\nFrameAxis (Kwak et al. 2021).\nWe analyze two metrics from this method called bias and\nintensity. Bias tells us whether words tend to be associated\nwith a positive or negative aspect of a moral dimension. For\nexample, a highly positive loyalty bias means that a user is\nusing words that are likely associated with being loyal rather\nthan rebellious. Intensity tells us how prominently a particu-\nlar moral dimension is used. A low intensity suggests users\nare not strongly associated with a particular moral dimen-\nsion while high intensity suggests users are strongly asso-\nciated (either positively or negatively) with a moral dimen-\nsion. In more detail, the bias of a text towards each moralfoundation axis is the weighted mean of the cosine similarity\nof the text\u2019s words with each axis. The absolute value cap-\ntures the document\u2019s relevance to a moral dimension, while\nthe positive sign denotes bias towards the Axis\u2019 positive pole\nand negative sign denotes the opposite (Mokhberian et al.\n2020). For example, a bias of -1 would indicate that a text is\ncompletely geared towards the negative aspect of a given di-\nmension and a bias of +1 indicates the inclinations towards\nthe positive aspect of a given dimension. Intensity denotes\nhow frequently each moral dimension appears in the docu-\nment with respect to the background distribution. Intensity\ndisregards polarization, such that in situations where a text\nhas both positive and negative bias, the terms cancel out each\nother, and the document does not display a significant bias\ntowards any pole of that axis, yet intensity will show the rel-\nevance to that axis (Mokhberian et al. 2020). Typically most\nwords spoken within a tweet are not moral in nature, and\ntherefore most tweets have values near zero.\nThe median values of each metric for anti-vaccine and\nregular users are statistically significant different (Mann-\nWhitney U Test p-value <10\u22126). More specifically, we\nfind that anti-vaccine users have a lower positive bias and\nintensity in loyalty, care, authority, and fairness, but slightly\nhigher bias, and similarly more intense sanctity dimension\n(Figure 4). This overall points to a lower focus by anti-\nvaccine users on positive morals, and less focus on most\nmorals, which provides some support for anti-vaccine users\nbeing more anti-authority and anti-loyalty, and focusing less\non care, while focusing on sanctity, which are morals like\n\u201dpurity,\u201d \u201dimmaculate,\u201d and \u201dclean.\u201d Notably, however, these\ndifferences are not very large, and despite a statistically sig-\nnificant difference in means, the distributions themselves are\nhighly overlapped. Therefore, we should also keep in mind\nthat people across this divide are more alike than different\nwith regards to the morals they express.\nDiscussion\nOverall, A V AXTAR delivers a fast and accurate open-source\nmethod to predicts users\u2019 vaccination attitudes, providing\na foundational tool which facilitates further research in the\nfield. By exploring the training dataset, we find anti-vaccine\nusers are more negative and angrier and show a greater focus\non politics (with common words like \u201cballot\u201d and \u201ctrump\u201d).\nFinally, the analysis of user morals, based on Moral Foun-\ndation Theory (Haidt and Joseph 2004), demonstrates less\npositive pro-authority or pro-loyalty bias, and a greater fo-\n792\nFigure 4: Moral Foundations of anti-vaccine and regular users (Haidt and Joseph 2004). (a) Bias (the tendency of words to\npromote positive or negative aspects of each moral foundation) are typically less positive in anti-vaccine users. (b) Intensity\n(the focus of words towards particular moral foundations) is also typically lower for anti-vaccine users.\ncus on sanctity and purity, perhaps because anti-vaccine\nusers view vaccination as impure. This agrees with earlier\nwork by Amin et al. (2017), who found vaccine hesitant\ngroups strongly emphasize purity, which suggests that the\nsame moral framing has been used long before discussions\nof COVID-19 vaccine hesitancy.\nLimitations\nThe present algorithm utilizes a dataset by Muric et\nal. (2021) as anti-vaccine user samples. These data consist\nof automatically annotated anti-vaccine labels on Twitter\naccounts, via the usage of hashtags and keywords on pub-\nlished tweets. The not anti-vaccine samples includes both\nkeyword- and hashtags-based data as well as users identified\nby their retweeting of prominent medical professionals. This\nmethod may generate both false positives and false nega-\ntives, which would then subsequently impact the accuracy of\nany model trained on the mislabeled data points. False pos-\nitives can occur when a user does not display anti-vaccine\nsentiment, but made a publication including one of its as-\nsociated hashtags or keywords, which could be due to ty-\npos, irony, or other reasons. False negatives can occur when\na user clearly displays anti-vaccination sentiment, but hap-\npens not to use any of the hashtags or keywords employed\nin filtering for vaccine hesitant accounts. Since that same set\nof hashtags or keywords is used as negative filter in the non\nanti-vaccine class, such a user could end up being incorrectly\nincluded as a \u201cnot anti-vaccine\u201d user.\nBroader Perspective, Ethics and Competing\nInterests\nThe A V AXTAR system has the potential to positively impact\nour understanding of what leads to vaccine hesitancy. Con-\nversely, the same ability of identifying anti-vaccine users\ncould be leveraged to more perverse goals such as discrim-\nination or targeted attacks. It is a socially tenuous line be-\ntween incentivizing the population based on the vast re-\nsearch backing up vaccination and coercing or excluding\npersons given their stance on vaccination. Any efforts to de-\nfine an \u201cin-group\u201d and an \u201cout-group\u201d can run the risk of fur-\nther social division. For this reason, we make no judgementon whether a user with a probability score of, e.g., 0.6 or\n0.99, is anti-vaccine or not. These probabilities should only\nbe taken at face value. Lastly, we recognize that machine\nlearning models can sometimes make wildly incorrect pre-\ndictions, especially for edge cases. It is necessary to devise\nguardrails when building applications on top of A V AXTAR.\nThe main benefit of A V AXTAR is that it enables future\nscientific research as well as development of applied solu-\ntions to the current challenge of vaccine hesitancy. Maxi-\nmizing this positive impact demands free and open access to\nA V AXTAR. Such a publishing approach has to be weighted\nagainst the costs of possibly enabling the more perverse us-\nages of our work. After significant consideration, we regard\nthe risks of A V AXTAR being used to single out individu-\nals to an extend that would be materially harmful to them\nas very unlikely. Moreover, if such aims are present, the\nmalicious actor, who is supposedly willing to expend sig-\nnificant resources in its attack, can always replicate a sim-\nilar system (Yuan, Schuchard, and Crooks 2019; Carrieri,\nLagravinese, and Resce 2021; Huang et al. 2017; Lincoln\net al. 2022; Wang, Yin, and Argyris 2020). Conversely, we\nsee the muffling of A V AXTAR technology as a hindrance\nto an entire community working towards ameliorating the\nside-effects of social media, such that limiting A V AXTAR\u2019s\navailability should cause more harm via preventing develop-\nment on this area than it would prevent via curbing potential\nmalicious use. Thus we convene that a public and freely dis-\ntributed A V AXTAR is the preferable choice with regards to\nethics.\nFuture Work\nCorrectly identifying which social media users propagate\nanti-vaccination sentiment is one of the many necessary\nsteps to halt the current misinformation surge. It is there-\nfore important to devise a science-based information cam-\npaign that targets vaccine-hesitant users, with the goal of\nhalting the spread of misinformation. We also suggest an in-\ndepth exploration of the extent to which Twitter-based mod-\nels might rely on hashtags when generating predictions. This\ncould take the form of a ablation-style study where mod-\nels are compared against both full tweets as well as tweets\n793\nstripped from their hashtags. The relationship between the\nratio of replies to retweets or replies to likes might also pro-\nvide an interesting avenue to exploration as it can signal\nposts which are highly inflammatory, be it with regards to\nvaccination or any other topic (Minot et al. 2021). Another\nimportant area of research is to predict which users are sus-\nceptible to anti-vaccine misinformation. This could be ac-\ncomplished using data on the social media content a given\nuser is viewing and interacting with, along with the exist-\ning data on user posts, as these combined data would allow\nresearchers to understand what media consumption habits\npredicate a user joining the anti-vaccine movement.\nAcknowledgements\nFunding for this work is provided through the USC-ISI Ex-\nploratory Research Award and through DARPA (awards #\nHR0011260595 and # HR001121C0169).\nConflicts of Interest\nThe authors declare no conflicts of interest.\nReferences\nAmin, A. B.; Bednarczyk, R. A.; Ray, C. E.; Melchiori, K. J.;\nGraham, J.; Huntsinger, J. R.; and Omer, S. B. 2017. Associ-\nation of moral values with vaccine hesitancy. Nature Human\nBehaviour, 1(12): 873\u2013880.\nBarlett, C. P.; DeWitt, C. C.; Maronna, B.; and Johnson, K.\n2018. Social Media Use as a Tool to Facilitate or Reduce\nCyberbullying Perpetration: A Review Focusing on Anony-\nmous and Nonanonymous Social Media Platforms. Violence\nand Gender, 5(3): 147\u2013152.\nBello-Orgaz, G.; Hernandez-Castro, J.; and Camacho, D.\n2017. Detecting discussion communities on vaccination in\ntwitter. Future Generation Computer Systems, 66: 125\u2013136.\nCarrieri, V .; Lagravinese, R.; and Resce, G. 2021. Predict-\ning vaccine hesitancy from area-level indicators: A machine\nlearning approach. Health Economics, 30(12): 3248\u20133256.\nDruckman, J. N.; Klar, S.; Krupnikov, Y .; Levendusky, M.;\nand Ryan, J. B. 2020. Affective polarization, local contexts\nand public opinion in America. Nature Human Behaviour.\nFeatherstone, J. D.; Barnett, G. A.; Ruiz, J. B.; Zhuang, Y .;\nand Millam, B. J. 2020. Exploring childhood anti-vaccine\nand pro-vaccine communities on twitter \u2013 a perspective from\ninfluential users. Online Social Networks and Media, 20:\n100105.\nFelmlee, D.; DellaPosta, D.; d. C. Inara Rodis, P.; and\nMatthews, S. A. 2020. Can Social Media Anti-abuse Poli-\ncies Work? A Quasi-experimental Study of Online Sexist\nand Racist Slurs. Socius, 6: 2378023120948711.\nFrancia, M.; Gallinucci, E.; and Golfarelli, M. 2019. So-\ncial BI to understand the debate on vaccines on the Web and\nsocial media: unraveling the anti-, free, and pro-vax com-\nmunities in Italy. Social Network Analysis and Mining, 9(1):\n1\u201316.\nGermani, F.; and Biller-Andorno, N. 2021. The anti-\nvaccination infodemic on social media: A behavioral anal-\nysis. PloS one, 16(3): e0247642.Gupta, P.; Pagliardini, M.; and Jaggi, M. 2019. Better Word\nEmbeddings by Disentangling Contextual n-Gram Informa-\ntion. In NAACL-HLT (1), 933\u2013939. Association for Compu-\ntational Linguistics.\nHaidt, J.; and Joseph, C. 2004. Intuitive Ethics: How\nInnately Prepared Intuitions Generate Culturally Variable\nVirtues. Daedalus, 133(4): 55\u201366.\nHinton, G.; Vinyals, O.; and Dean, J. 2015. Distill-\ning the Knowledge in a Neural Network. arXiv preprint\narXiv:1503.02531.\nHornsey, M. J.; Lobera, J.; and D \u00b4\u0131az-Catal \u00b4an, C. 2020. Vac-\ncine hesitancy is strongly associated with distrust of con-\nventional medicine, and only weakly associated with trust\nin alternative medicine. Social Science & Medicine, 255:\n113019.\nHuang, X.; Smith, M. C.; Paul, M. J.; Ryzhkov, D.; Quinn,\nS. C.; Broniatowski, D. A.; and Dredze, M. 2017. Exam-\nining Patterns of Influenza Vaccination in Social Media. In\nAAAI Workshops, 94303.\nHutto, C. J.; and Gilbert, E. 2014. V ADER: A Parsimonious\nRule-Based Model for Sentiment Analysis of Social Media\nText. In Adar, E.; Resnick, P.; Choudhury, M. D.; Hogan, B.;\nand Oh, A. H., eds., Proceedings of the Eighth International\nConference on Weblogs and Social Media, ICWSM 2014,\nAnn Arbor, Michigan, USA, June 1-4, 2014. The AAAI\nPress.\nKadam, M. 2017. Understanding vaccination attitudes and\ndetecting sentiment stimulus in online social media. Illinois\nInstitute of Technology.\nKang, G. J.; Ewing-Nelson, S. R.; Mackey, L.; Schlitt, J. T.;\nMarathe, A.; Abbas, K. M.; and Swarup, S. 2017. Semantic\nnetwork analysis of vaccine sentiment in online social me-\ndia.Vaccine, 35(29): 3621\u20133638.\nKlein, C.; Clutton, P.; and Dunn, A. G. 2019. Pathways to\nconspiracy: The social and linguistic precursors of involve-\nment in Reddit\u2019s conspiracy theory forum. PLOS ONE,\n14(11): 1\u201323.\nKrishnan, G. S.; Sowmya Kamath, S.; and Sugumaran, V .\n2021. Predicting vaccine hesitancy and vaccine sentiment\nusing topic modeling and evolutionary optimization. In\nInternational Conference on Applications of Natural Lan-\nguage to Information Systems, 255\u2013263. Springer.\nKwak, H.; An, J.; Jing, E.; and Ahn, Y .-Y . 2021. FrameAxis:\ncharacterizing microframe bias and intensity with word em-\nbedding. PeerJ Computer Science, 7: e644.\nLincoln, T. M.; Schlier, B.; Strakeljahn, F.; Gaudiano, B. A.;\nSo, S. H.; Kingston, J.; Morris, E. M.; and Ellett, L. 2022.\nTaking a machine learning approach to optimize prediction\nof vaccine hesitancy in high income countries. Scientific\nreports, 12(1): 1\u201312.\nLiu, Y .; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;\nLevy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V .\n2019. RoBERTa: A Robustly Optimized BERT Pretraining\nApproach. arXiv preprint arXiv:1907.11692.\nLoshchilov, I.; and Hutter, F. 2019. Decoupled Weight De-\ncay Regularization. arXiv preprint arXiv:1711.05101.\n794\nMinot, J. R.; Arnold, M. V .; Alshaabi, T.; Danforth, C. M.;\nand Dodds, P. S. 2021. Ratioing the President: An explo-\nration of public engagement with Obama and Trump on\nTwitter. PLOS ONE, 16(4): 1\u201322.\nMohammad, S.; and Turney, P. D. 2013. Crowdsourc-\ning a Word-Emotion Association Lexicon. arXiv preprint\narXiv:1308.6297.\nMokhberian, N.; Abeliuk, A.; Cummings, P.; and Lerman,\nK. 2020. Moral Framing and Ideological Bias of News.\narXiv preprint arXiv:2009.12979.\nMuric, G.; Wu, Y .; and Ferrara, E. 2021. COVID-19 Vac-\ncine Hesitancy on Social Media: Building a Public Twitter\nDataset of Anti-vaccine Content, Vaccine Misinformation\nand Conspiracies. arXiv preprint arXiv:2105.05134.\nMurphy, J.; Valli `eres, F.; Bentall, R. P.; Shevlin, M.;\nMcBride, O.; Hartman, T. K.; McKay, R. T.; Bennett, K. M.;\nMason, L.; Gibson-Miller, J.; Levita, L.; Mart \u00b4\u0131nez, A. P.;\nStocks, T. V . A.; Karatzias, T.; and Hyland, P. 2021. Psy-\nchological characteristics associated with COVID-19 vac-\ncine hesitancy and resistance in Ireland and the United King-\ndom. Nature Communications, 12: 1\u201315.\nPeeters, G.; and Czapinski, J. 1990. Positive-Negative\nAsymmetry in Evaluations: The Distinction Between Affec-\ntive and Informational Negativity Effects. European Review\nof Social Psychology, 1(1): 33\u201360.\nRadford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and\nSutskever, I. 2019. Language Models are Unsupervised\nMultitask Learners. Technical report, OpenAI, 1\u201324.\nRadzikowski, J.; Stefanidis, A.; Jacobsen, K. H.; Croitoru,\nA.; Crooks, A.; and Delamater, P. L. 2016. The measles vac-\ncination narrative in Twitter: a quantitative analysis. JMIR\npublic health and surveillance, 2(1): e5059.\nRao, A.; Morstatter, F.; Hu, M.; Chen, E.; Burghardt, K.;\nFerrara, E.; and Lerman, K. 2020. Political Partisanship\nand Anti-Science Attitudes in Online Discussions about\nCOVID-19. arXiv preprint arXiv:2011.08498.\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sen-\ntence Embeddings using Siamese BERT-Networks. In Pro-\nceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing. Association for Computa-\ntional Linguistics.\nSchmidt, A. L.; Zollo, F.; Scala, A.; Betsch, C.; and Quat-\ntrociocchi, W. 2018. Polarization of the vaccination debate\non Facebook. Vaccine, 36(25): 3606\u20133612.\nSmith, T. C. 2017. Vaccine Rejection and Hesitancy: A Re-\nview and Call to Action. Open Forum Infectious Diseases,\n4(3). Ofx146.\nSong, K.; Tan, X.; Qin, T.; Lu, J.; and Liu, T.-Y . 2020. MP-\nNet: Masked and Permuted Pre-training for Language Un-\nderstanding. arXiv preprint arXiv:2004.09297.\nTrinh, T. H.; and Le, Q. V . 2018. A Simple Method for Com-\nmonsense Reasoning. arXiv preprint arxiv:1806.02847.\nWang, Z.; Yin, Z.; and Argyris, Y . A. 2020. Detecting\nMedical Misinformation on Social Media Using Multimodal\nDeep Learning. arXiv:2012.13968.Wilson, K.; Atkinson, K.; and Deeks, S. 2014. Opportuni-\nties for utilizing new technologies to increase vaccine confi-\ndence. Expert Review of Vaccines, 13(8): 969\u2013977. PMID:\n24931799.\nYuan, X.; Schuchard, R. J.; and Crooks, A. T. 2019. Ex-\namining Emergent Communities and Social Bots Within the\nPolarized Online Vaccination Debate in Twitter. Social Me-\ndia + Society, 5(3): 2056305119865465.\nZhu, Y .; Kiros, R.; Zemel, R.; Salakhutdinov, R.; Urtasun,\nR.; Torralba, A.; and Fidler, S. 2015. Aligning Books\nand Movies: Towards Story-like Visual Explanations by\nWatching Movies and Reading Books. arXiv preprint\narxiv:1506.06724.\n795", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Detecting anti-vaccine users on Twitter", "author": ["M Schmitz", "G Muric", "K Burghardt"], "pub_year": "2023", "venue": "\u2026 AAAI Conference on Web and Social \u2026", "abstract": "Vaccine hesitancy, which has recently been driven by online narratives, significantly  degrades the efficacy of vaccination strategies, such as those for COVID-19. Despite broad"}, "filled": false, "gsrank": 247, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/22188", "author_id": ["Y8rGM8EAAAAJ", "EMn-B3gAAAAJ", "kTA-fn8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:9fhHWVxWBFIJ:scholar.google.com/&output=cite&scirp=246&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=9fhHWVxWBFIJ&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 5, "citedby_url": "/scholar?cites=5909943565651802357&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:9fhHWVxWBFIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/22188/21967"}}]