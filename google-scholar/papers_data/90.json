[{"title": "The Information Professional's Role in the Fake News Phenomenon", "year": "2020", "pdf_data": "\u00a0\n131\u00a0The Information Professional\u2019s Role  in the Fake News Phenomenon \nCarina Mirass\u00f3 Pedr\u00f3s1, Juan-Jos\u00e9 Bot\u00e92 \nFacultat d'Informaci\u00f3 i Mitjans Audiovisuals. Universitat de Barcelona \nDepartament de Bibliotec onomia, Documentaci\u00f3 i Co municaci\u00f3 Audiovisual & Centre de Recerca en \nInformaci\u00f3, Comunicaci\u00f3 i Cultura, Universitat de Barcelona \nAbstract . The goal of this paper is to analyze the main characteristics of the Fake News \nphenomenon in the Information Science field. With the digital era and the use of new technologies, new information consumption habits have appeared, which favor the \ndissemination of distorted or false information on digital platforms. \nInformation professionals traditionally had control of the resources to satisfy the informational needs of their users. Reference sources were reliable and there was a certain \nguarantee and control of the information. In the digital era, informational professionals have \nlost the information monopoly and have been fo rced to share knowledge with Internet sites \nand social network sites that offer a broad array of information. The dissemination of this \nknowledge has led to the emergence of a new concept: Fake News. \nInformation professionals cannot ignore fake News and two essential tasks can be used to ensure truth. First, the use of resources that  allow the information professional to filter and \ncurate information to provide an adequate informational res ource for users. Secondly, to \nprovide strategies to fight fake news. Accordingly, we propose a guide that provides tools and resources to help users to check info rmation obtained through new technologies. \nAdditionally, these resources, tools and recommendations could enable information \nprofessionals to digitally curate information that could later be offered to end users. \nWe have reviewed papers and recommendations from a wide variety of institutions as well \nas international media to create an implementation guide for the information that is our workspace. \nKeywords : fake news, librarians, information professionals, information literacy, \ninformation evaluation. \n1 Introduction \nInformation \u00a0professionals \u00a0have\u00a0traditionally \u00a0had\u00a0reliable\u00a0information \u00a0sources\u00a0at\u00a0their\u00a0disposal.\u00a0\nThese\u00a0information \u00a0sources\u00a0allowed\u00a0librarians, \u00a0documentalists, \u00a0archivists \u00a0and\u00a0other\u00a0information \u00a0\nprofessionals \u00a0to\u00a0meet\u00a0the\u00a0information \u00a0needs\u00a0of\u00a0different\u00a0users.\u00a0\nThe\u00a0emergence \u00a0of\u00a0the\u00a0digital\u00a0era\u00a0with\u00a0the\u00a0Internet\u00a0and\u00a0other\u00a0new\u00a0technologies \u00a0has\u00a0changed\u00a0\nthe\u00a0habits\u00a0of\u00a0our\u00a0society\u00a0and\u00a0how\u00a0information \u00a0is\u00a0transmitted \u00a0and\u00a0received.\u00a0Information \u00a0is\u00a0\nbroadcast \u00a0from\u00a0traditional \u00a0media\u00a0such\u00a0as\u00a0radio\u00a0and\u00a0print,\u00a0as\u00a0well\u00a0as\u00a0through\u00a0digital\u00a0age\u00a0tools.\u00a0\nInformation \u00a0sources\u00a0on\u00a0the\u00a0Internet\u00a0include\u00a0Social\u00a0Networking \u00a0Sites\u00a0(hereafter \u00a0SNS)\u00a0which\u00a0\npermit\u00a0a\u00a0user\u00a0to\u00a0generate\u00a0content,\u00a0share\u00a0information \u00a0and\u00a0have\u00a0a\u00a0space\u00a0for\u00a0communicating \u00a0with\u00a0\nothers.\u00a0Established \u00a0sites\u00a0such\u00a0as\u00a0Facebook \u00a0and\u00a0Twitter\u00a0seem\u00a0to\u00a0have\u00a0started\u00a0the\u00a0growth\u00a0of\u00a0so\u2010\ncalled\u00a0Fake\u00a0News.\u00a0This\u00a0has\u00a0been\u00a0a\u00a0big\u00a0problem\u00a0because\u00a0users\u00a0sometimes \u00a0cannot\u00a0distinguish \u00a0\nwhether\u00a0the\u00a0information \u00a0they\u00a0receive,\u00a0watch\u00a0or\u00a0read\u00a0is\u00a0true\u00a0or\u00a0false.\u00a0\nInformation \u00a0and\u00a0documentation \u00a0professionals \u00a0cannot\u00a0ignore\u00a0this\u00a0phenomenon \u00a0and\u00a0are\u00a0\ninevitably \u00a0involved\u00a0in\u00a0it.\u00a0Our\u00a0involvement \u00a0is\u00a0generally\u00a0in\u00a0two\u00a0ways:\u00a0filtering\u00a0information \u00a0and\u00a0\ncurating\u00a0content\u00a0for\u00a0users\u00a0and\u00a0providing \u00a0different\u00a0strategies \u00a0to\u00a0spot\u00a0fake\u00a0news.\u00a0\nIn\u00a0this\u00a0paper,\u00a0we\u00a0review\u00a0a\u00a0number\u00a0of\u00a0publications \u00a0from\u00a0institutions \u00a0and\u00a0international \u00a0media\u00a0\nregarding \u00a0how\u00a0to\u00a0spot\u00a0fake\u00a0news\u00a0in\u00a0order\u00a0to\u00a0create\u00a0an\u00a0implementation \u00a0guide\u00a0in\u00a0the\u00a0field\u00a0of\u00a0\ninformation \u00a0and\u00a0documentation. \u00a0\n\u00a0\n132\u00a02 Fake News: Information or Misinformation \nThe\u00a0term\u00a0\u201cFake\u00a0News\u201d\u00a0has\u00a0been\u00a0growing\u00a0more\u00a0prominent \u00a0in\u00a0recent\u00a0times.\u00a0False\u00a0information \u00a0has\u00a0\nexisted\u00a0as\u00a0long\u00a0as\u00a0there\u00a0have\u00a0been\u00a0media\u00a0to\u00a0disseminate \u00a0it.\u00a0However, \u00a0before\u00a0the\u00a0advent\u00a0of\u00a0the\u00a0\nInternet,\u00a0false\u00a0news\u00a0was\u00a0hidden\u00a0or\u00a0deleted\u00a0before\u00a0it\u00a0could\u00a0reach\u00a0many\u00a0people.\u00a0The\u00a0problem\u00a0has\u00a0\nemerged\u00a0with\u00a0new\u00a0digital\u00a0media\u00a0that\u00a0make\u00a0it\u00a0easy\u00a0to\u00a0create\u00a0and\u00a0disseminate \u00a0stories\u00a0relating\u00a0to\u00a0\nmany\u00a0different\u00a0topics.\u00a0According \u00a0to\u00a0experts,\u00a0this\u00a0wide\u00a0variety\u00a0of\u00a0content\u00a0makes\u00a0it\u00a0very\u00a0difficult\u00a0\nto\u00a0determine \u00a0if\u00a0the\u00a0content\u00a0is\u00a0informing \u00a0or\u00a0misinforming \u00a0the\u00a0reader.\u00a0The\u00a0democracy \u00a0of\u00a0content\u00a0\ncreation\u00a0presented \u00a0by\u00a0SNS\u00a0allows\u00a0a\u00a0rapid\u00a0dissemination \u00a0of\u00a0information \u00a0when\u00a0compared \u00a0to\u00a0\ntraditional \u00a0media\u00a0such\u00a0as\u00a0radio,\u00a0television \u00a0and\u00a0print\u00a0media,\u00a0which\u00a0has\u00a0resulted\u00a0in\u00a0the\u00a0spreading \u00a0\nof\u00a0fake\u00a0news.\u00a0One\u00a0of\u00a0the\u00a0consequences \u00a0of\u00a0fake\u00a0news\u00a0is\u00a0that\u00a0users\u00a0of\u00a0SNS\u00a0are\u00a0subject\u00a0to\u00a0clickbait\u00a0\ntechniques \u00a0that\u00a0are\u00a0monetized \u00a0with\u00a0online\u00a0advertising \u00a0(Alvarez,\u00a02017).\u00a0In\u00a0addition,\u00a0there\u00a0is\u00a0\nevidence\u00a0of\u00a0an\u00a0industry\u00a0of\u00a0websites\u00a0publishing \u00a0misleading \u00a0political\u00a0articles\u00a0targeting\u00a0the\u00a0United\u00a0\nStates\u00a0(Oxenham, \u00a02019).\u00a0\nAlonso\u2010Arevalo\u00a0and\u00a0Castilla\u00a0(2019)\u00a0researched \u00a0the\u00a0information \u00a0overload\u00a0phenomenon \u00a0and\u00a0\nthe\u00a0connection \u00a0to\u00a0new\u00a0digital\u00a0technologies \u00a0which\u00a0give\u00a0rise\u00a0to\u00a0disinformation. \u00a0SNS\u00a0provides\u00a0\nenormous \u00a0quantities \u00a0of\u00a0information \u00a0on\u00a0such\u00a0diverse\u00a0topics\u00a0that\u00a0cause\u00a0people\u00a0to\u00a0be\u00a0\noverinformed, \u00a0and\u00a0at\u00a0the\u00a0same\u00a0time\u00a0uninformed, \u00a0because\u00a0they\u00a0cannot\u00a0process\u00a0such\u00a0diverse\u00a0\nnews\u00a0on\u00a0a\u00a0topic.\u00a0In\u00a0addition,\u00a0the\u00a0authors\u00a0suggest\u00a0that\u00a0if\u00a0they\u00a0added\u00a0a\u00a0malicious \u00a0intent,\u00a0the\u00a0Fake\u00a0\nNews\u00a0appears\u00a0to\u00a0spread\u00a0virally\u00a0in\u00a0most\u00a0cases.\u00a0\nThe\u00a0spread\u00a0of\u00a0fake\u00a0news\u00a0may\u00a0cause\u00a0a\u00a0lack\u00a0of\u00a0reliable\u00a0information. \u00a0For\u00a0instance,\u00a0Digital\u00a0News\u00a0\nReport\u00a02019\u00a0(Newman, \u00a0Fletcher,\u00a0Kalogeropoulos, \u00a0&\u00a0Nielsen,\u00a02019)\u00a0explains\u00a0that\u00a0only\u00a043%\u00a0of\u00a0\nSpanish\u00a0Internet\u00a0users\u00a0say\u00a0they\u00a0usually\u00a0rely\u00a0on\u00a0the\u00a0Internet\u00a0as\u00a0a\u00a0news\u00a0source,\u00a0despite\u00a0the\u00a0\nInternet\u2019s \u00a0growth\u00a0as\u00a0a\u00a0source\u00a0of\u00a0information. \u00a0This\u00a0report\u00a0also\u00a0shows\u00a0the\u00a0growing\u00a0use\u00a0of\u00a0SNS,\u00a0\nalthough\u00a0only\u00a0a\u00a0quarter\u00a0of\u00a0the\u00a0respondents \u00a0think\u00a0that\u00a0these\u00a0networks\u2019 \u00a0information \u00a0is\u00a0reliable.\u00a0\nAnother\u00a0report\u00a0published \u00a0in\u00a02018\u00a0by\u00a0the\u00a0Spanish\u00a0section\u00a0of\u00a0Reporters \u00a0without\u00a0Borders\u00a0\n(Campoamor, \u00a0Macu\u00a0de\u00a0la\u00a0Cruz,\u00a0Fuertes,\u00a0Fibla\u00a0&\u00a0Alonso,\u00a02018)\u00a0showed\u00a0a\u00a0growing\u00a0concern\u00a0for\u00a0the\u00a0\nphenomenon \u00a0of\u00a0fake\u00a0news,\u00a0which\u00a0threatens \u00a0press\u00a0freedom\u00a0and\u00a0leads\u00a0to\u00a0massive\u00a0harassment \u00a0of\u00a0\nonline\u00a0journalists. \u00a0The\u00a0report\u00a0suggests\u00a0that\u00a0there\u00a0are\u00a0hidden\u00a0individuals \u00a0working\u00a0behind\u00a0the\u00a0\nscenes\u00a0as\u00a0online\u00a0mercenaries \u00a0for\u00a0specific\u00a0interests\u00a0or\u00a0for\u00a0government. \u00a0This\u00a0report\u00a0also\u00a0mentions \u00a0\nthe\u00a0impact\u00a0that\u00a0this\u00a0may\u00a0have\u00a0on\u00a0journalists \u00a0who\u00a0are\u00a0attempting \u00a0to\u00a0be\u00a0objective. \u00a0Consequently, \u00a0\ntheir\u00a0work\u00a0may\u00a0be\u00a0obscured \u00a0by\u00a0the\u00a0overload\u00a0of\u00a0information \u00a0coming\u00a0from\u00a0questionable \u00a0sources.\u00a0\nOne\u00a0of\u00a0the\u00a0best\u2010known\u00a0examples \u00a0in\u00a0the\u00a0field\u00a0of\u00a0Fake\u00a0News\u00a0relates\u00a0to\u00a0the\u00a0U.S.\u00a0presidential \u00a0\ncampaign \u00a0in\u00a02016\u00a0that\u00a0led\u00a0the\u00a0world's\u00a0largest\u00a0power\u00a0to\u00a0elect\u00a0Donald\u00a0Trump.\u00a0In\u00a0this\u00a0electoral\u00a0\ncampaign, \u00a0online\u00a0sources\u00a0were\u00a0allegedly\u00a0used\u00a0by\u00a0Russians\u00a0for\u00a0the\u00a0creation\u00a0of\u00a0false\u00a0news\u00a0with\u00a0\nmultiple\u00a0profiles\u00a0and\u00a0bots.\u00a0The\u00a0goal\u00a0of\u00a0the\u00a0creation\u00a0of\u00a0false\u00a0news\u00a0was\u00a0to\u00a0change\u00a0voting\u00a0trends\u00a0\nand\u00a0influence \u00a0the\u00a0campaign \u00a0which\u00a0Trump\u00a0finally\u00a0won.\u00a0This\u00a0campaign \u00a0was\u00a0studied\u00a0by\u00a0the\u00a0U.S.\u00a0\nCongress\u00a0and\u00a0Senate,\u00a0particularly \u00a0in\u00a0relation\u00a0to\u00a0the\u00a0online\u00a0publication \u00a0of\u00a03,000\u00a0advertisements \u00a0\non\u00a0SNS\u00a0with\u00a0false\u00a0news,\u00a0estimated \u00a0to\u00a0have\u00a0reached\u00a0about\u00a0126\u00a0million\u00a0Americans, \u00a0representing \u00a0\nabout\u00a0half\u00a0the\u00a0eligible\u00a0U.S.\u00a0voters.\u00a0(Levin,\u00a02017;\u00a0Washington, \u00a02017).\u00a0Similarly,\u00a0a\u00a0study\u00a0analyzed\u00a0\n14\u00a0million\u00a0Twitter\u00a0messages \u00a0during\u00a0the\u00a0U.S.\u00a02016\u00a0campaign, \u00a0concluding \u00a0that\u00a0bots\u00a0spread\u00a0massive\u00a0\namounts\u00a0of\u00a0misinformation, \u00a0making\u00a0it\u00a0shareable \u00a0by\u00a0humans\u00a0(Shao\u00a0et\u00a0al.,\u00a02018).\u00a0\nFor\u00a0his\u00a0part,\u00a0Trump\u00a0uses\u00a0the\u00a0term\u00a0Fake\u00a0News\u00a0in\u00a0response\u00a0to\u00a0the\u00a0criticism\u00a0he\u00a0receives\u00a0in\u00a0his\u00a0\nmanagement \u00a0and\u00a0to\u00a0discredit\u00a0the\u00a0media\u00a0who\u00a0talk\u00a0about\u00a0his\u00a0policies\u00a0and\u00a0facts\u00a0that\u00a0do\u00a0not\u00a0favor\u00a0\nhim\u00a0(McCarthy, \u00a02017;\u00a0Wong,\u00a02019).\u00a0\nThere\u00a0are\u00a0several\u00a0types\u00a0of\u00a0fake\u00a0news\u00a0and\u00a0a\u00a0classification \u00a0of\u00a0the\u00a0different\u00a0typologies \u00a0have\u00a0been\u00a0\nproposed \u00a0(Lopez\u2010Borrull,\u00a0Vives\u2010Gr\u00e0cia,\u00a0&\u00a0Badell,\u00a02018).\u00a0However, \u00a0other\u00a0types\u00a0of\u00a0Fake\u00a0News\u00a0are\u00a0\nproduced \u00a0with\u00a0an\u00a0advanced \u00a0use\u00a0of\u00a0technology, \u00a0the\u00a0Deep\u00a0Fakes.\u00a0This\u00a0content\u00a0uses\u00a0advanced \u00a0\nvideo\u00a0techniques \u00a0combined \u00a0with\u00a0artificial\u00a0intelligence \u00a0(hereafter \u00a0AI).\u00a0As\u00a0an\u00a0example,\u00a0BBC\u00a0\npublished \u00a0a\u00a0story\u00a0that\u00a0there\u00a0was\u00a0a\u00a0social\u00a0video\u00a0where\u00a0Boris\u00a0Johnson\u00a0and\u00a0Jeremy\u00a0Corbin\u00a0each\u00a0\n\u00a0\n133\u00a0endorsed \u00a0the\u00a0other\u00a0for\u00a0Prime\u00a0Minister\u00a0(BBC,\u00a02019).\u00a0Similarly,\u00a0in\u00a0relation\u00a0to\u00a0the\u00a0past\u00a0Spanish\u00a0\nelections\u00a0in\u00a02019,\u00a0some\u00a0deep\u00a0fakes\u00a0with\u00a0candidates \u00a0went\u00a0viral\u00a0(Llanos,\u00a02019).\u00a0\nAs\u00a0can\u00a0be\u00a0observed \u00a0on\u00a0the\u00a0aforementioned \u00a0examples, \u00a0it\u00a0seems\u00a0that\u00a0fake\u00a0News\u00a0surrounds \u00a0us.\u00a0\nThe\u00a0current\u00a0phenomena \u00a0such\u00a0as\u00a0the\u00a0political\u00a0situation\u00a0in\u00a0Catalonia, \u00a0Brexit\u00a0and\u00a0many\u00a0other\u00a0daily\u00a0\ntopics,\u00a0generate\u00a0considerable \u00a0information \u00a0through\u00a0social\u00a0networking \u00a0sites\u00a0and\u00a0likely\u00a0distort\u00a0the\u00a0\ninformation. \u00a0Consequently, \u00a0as\u00a0information \u00a0professionals, \u00a0we\u00a0need\u00a0to\u00a0spot\u00a0this\u00a0phenomenon \u00a0to\u00a0\nhave\u00a0objective\u00a0and\u00a0real\u00a0information \u00a0available. \u00a0\n3 Projects and initiatives to deal with information and documentation \nIn\u00a0the\u00a0field\u00a0of\u00a0information \u00a0and\u00a0documentation, \u00a0professional \u00a0associations \u00a0in\u00a0the\u00a0field\u00a0are\u00a0aware\u00a0\nof\u00a0the\u00a0problem\u00a0and\u00a0lead\u00a0different\u00a0projects\u00a0and\u00a0initiatives. \u00a0\nThe\u00a0International \u00a0Federation \u00a0of\u00a0Library\u00a0Association \u00a0(hereafter \u00a0IFLA)\u00a0created\u00a0a\u00a02007\u00a0infographic \u00a0\ncalled\u00a0How\u00a0to\u00a0Spot\u00a0Fake\u00a0News\u00a0which\u00a0is\u00a0a\u00a0good\u00a0practice\u00a0guide\u00a0(Figure\u00a01).\u00a0It\u00a0is\u00a0translated \u00a0into\u00a037\u00a0\nlanguages \u00a0and,\u00a0according \u00a0to\u00a0IFLA,\u00a0it\u00a0is\u00a0a\u00a0tool\u00a0based\u00a0on\u00a0the\u00a0belief\u00a0that\u00a0with\u00a0education \u00a0it\u00a0is\u00a0easy\u00a0for\u00a0\nusers\u00a0to\u00a0acquire\u00a0confidence \u00a0and\u00a0governments \u00a0do\u00a0not\u00a0need\u00a0to\u00a0impose\u00a0censorship \u00a0(IFLA,\u00a02019).\u00a0In\u00a0\naddition,\u00a0IFLA\u00a0has\u00a0carried\u00a0out\u00a0campaigns \u00a0to\u00a0participate \u00a0in\u00a0debates\u00a0on\u00a0the\u00a0subject\u00a0and\u00a0about\u00a0\ninformation, \u00a0such\u00a0as\u00a0that\u00a0carried\u00a0out\u00a0in\u00a0Brussels\u00a0in\u00a0February\u00a02018,\u00a0where,\u00a0in\u00a0conjunction \u00a0with\u00a0the\u00a0\nEuropean \u00a0Union,\u00a0Internet\u00a0disinformation \u00a0was\u00a0debated,\u00a0concluding \u00a0that\u00a0there\u00a0is\u00a0a\u00a0need\u00a0for\u00a0training\u00a0\npolicies\u00a0in\u00a0digital\u00a0skills\u00a0(IFLA,\u00a02018).\u00a0\n\u00a0\nFig. 10.  IFLA infographic to detect Fake News. \nSource: https://www.ifla.o rg/publications/node/11174 \nCILIP\u00a0(the\u00a0Library\u00a0and\u00a0Information \u00a0Association )\u00a0also\u00a0places\u00a0much\u00a0importance \u00a0to\u00a0information \u00a0\nliteracy,\u00a0to\u00a0the\u00a0extent\u00a0that\u00a0in\u00a02018\u00a0it\u00a0modified\u00a0the\u00a0definition \u00a0it\u00a0made\u00a0in\u00a02004,\u00a0in\u00a0order\u00a0to\u00a0adapt\u00a0\nit\u00a0to\u00a0the\u00a0phenomenon \u00a0of\u00a0fake\u00a0News :\u00a0\n\u201cInformation \u00a0literacy\u00a0is\u00a0the\u00a0ability\u00a0to\u00a0think\u00a0critically\u00a0and\u00a0make\u00a0balanced \u00a0judgments \u00a0about\u00a0\nany\u00a0information \u00a0we\u00a0find\u00a0and\u00a0use.\u00a0It\u00a0empowers \u00a0us\u00a0as\u00a0citizens\u00a0to\u00a0reach\u00a0and\u00a0express\u00a0informed \u00a0\nviews\u00a0and\u00a0to\u00a0engage\u00a0fully\u00a0with\u00a0society\u201d\u00a0(CILIP,\u00a02018)\u00a0\n\n\u00a0\n134\u00a0The\u00a0American \u00a0Libraries\u00a0Association \u00a0(ALA),\u00a0through\u00a0the\u00a0Programming \u00a0Libraries\u00a0initiative\u00a0(ALA,\u00a0\n2019),\u00a0collects\u00a0resources \u00a0for\u00a0guiding\u00a0and\u00a0advising\u00a0national\u00a0libraries\u00a0in\u00a0order\u00a0to\u00a0offer\u00a0users\u00a0\neducation \u00a0to\u00a0distinguish \u00a0fake\u00a0news .\u00a0Among\u00a0the\u00a0resources \u00a0on\u00a0offer,\u00a0there\u00a0are\u00a0webinars\u00a0where\u00a0\nparticipants \u00a0may\u00a0discuss\u00a0fake\u00a0news .\u00a0Libguides\u00a0are\u00a0library\u00a0guides\u00a0discussing \u00a0different\u00a0aspects\u00a0of\u00a0the\u00a0\ntopic,\u00a0such\u00a0as\u00a0the\u00a0evaluation \u00a0of\u00a0information, \u00a0detection \u00a0of\u00a0false\u00a0news,\u00a0and\u00a0the\u00a0comprehension \u00a0and\u00a0\nidentification \u00a0of\u00a0fake\u00a0News.\u00a0It\u00a0also\u00a0provides\u00a0a\u00a0series\u00a0of\u00a0links\u00a0to\u00a0news\u00a0published \u00a0in\u00a0digital\u00a0media\u00a0on\u00a0\nthe\u00a0matter\u00a0and\u00a0to\u00a0studies\u00a0about\u00a0it.\u00a0\nIn\u00a0many\u00a0university \u00a0libraries\u00a0in\u00a0the\u00a0United\u00a0States,\u00a0it\u00a0is\u00a0quite\u00a0common\u00a0to\u00a0find\u00a0guides\u00a0offering\u00a0\ntools\u00a0and\u00a0information \u00a0to\u00a0guide\u00a0and\u00a0help\u00a0users\u00a0in\u00a0detecting \u00a0fake\u00a0news,\u00a0such\u00a0as\u00a0\u201cFake\u00a0News,\u00a0\nMisinformation, \u00a0and\u00a0Propaganda\u201d \u00a0(Harvard\u00a0Library,\u00a02019)\u00a0or\u00a0\u201cReal\u00a0News/Fake \u00a0News:\u00a0About\u00a0\nFake\u00a0News \u201d\u00a0(Berkeley \u00a0Library,\u00a02019).\u00a0We\u00a0easily\u00a0found\u00a0more\u00a0than\u00a0one\u00a0hundred\u00a0university \u2010\npublished \u00a0guides\u00a0on\u00a0this\u00a0topic.\u00a0In\u00a0some\u00a0cases,\u00a0it\u00a0is\u00a0implied\u00a0that\u00a0professors \u00a0were\u00a0involved\u00a0in\u00a0the\u00a0\nlibrary\u00a0guides,\u00a0in\u00a0other\u00a0cases\u00a0only\u00a0librarians \u00a0developed \u00a0these\u00a0guides\u00a0as\u00a0no\u00a0professors \u00a0are\u00a0\nmentioned. \u00a0\nIn\u00a0a\u00a0review\u00a0of\u00a0Spanish\u00a0libraries,\u00a0we\u00a0have\u00a0not\u00a0found\u00a0literature \u00a0or\u00a0guides\u00a0about\u00a0initiatives \u00a0to\u00a0\nspot\u00a0fake\u00a0news.\u00a0There\u00a0are\u00a0blogs\u00a0written\u00a0by\u00a0some\u00a0professional \u00a0librarians \u00a0about\u00a0the\u00a0initiatives \u00a0\nmainly\u00a0taken\u00a0in\u00a0the\u00a0United\u00a0States.\u00a0In\u00a0the\u00a0case\u00a0of\u00a0Spanish\u00a0universities, \u00a0only\u00a0a\u00a0few\u00a0universities \u00a0have\u00a0\npublished \u00a0guides.\u00a0\n4 How do we cope? How to spot misinformation? \nThe\u00a0process\u00a0to\u00a0detect\u00a0and\u00a0verify\u00a0fake\u00a0News\u00a0is\u00a0fact\u2010checking. \u00a0However, \u00a0this\u00a0is\u00a0not\u00a0currently\u00a0\npossible\u00a0in\u00a0all\u00a0languages \u00a0and\u00a0is\u00a0still\u00a0not\u00a0currently\u00a0possible\u00a0for\u00a0all\u00a0social\u00a0media\u00a0platforms. \u00a0There\u00a0\nare\u00a0some\u00a0experimental \u00a0tools\u00a0under\u00a0development \u00a0which\u00a0are\u00a0mainly\u00a0focused\u00a0on\u00a0one\u00a0platform. \u00a0In\u00a0\nGermany\u00a0Fraunhofer \u2010Gesellschaft \u00a0developed \u00a0software\u00a0that\u00a0focused\u00a0on\u00a0Twitter\u00a0to\u00a0analyze\u00a0and\u00a0\nfilter\u00a0out\u00a0Fake\u00a0News\u00a0and\u00a0disinformation \u00a0(Fraunhofer \u2010Gesellschaft, \u00a02019).\u00a0A\u00a0fact\u2010checking\u00a0tool\u00a0\nwas\u00a0developed \u00a0as\u00a0part\u00a0of\u00a0a\u00a0study\u00a0to\u00a0detect\u00a0fake\u00a0news\u00a0in\u00a0Greek\u00a0(Katsaounidou, \u00a0Vryzas,\u00a0Kotsakis,\u00a0\n&\u00a0Dimoulas, \u00a02019).\u00a0A\u00a0system\u00a0called\u00a0FakeNewsTracker \u00a0was\u00a0proposed \u00a0for\u00a0the\u00a0Twitter\u00a0platform, \u00a0\nbased\u00a0on\u00a0the\u00a0analysis\u00a0of\u00a0linguistic\u00a0and\u00a0social\u00a0engagements \u00a0features\u00a0in\u00a0published \u00a0information \u00a0\n(Shu,\u00a0Mahudeswaran, \u00a0&\u00a0Liu,\u00a02019).\u00a0Finally,\u00a0another\u00a0study\u00a0proposed \u00a0a\u00a0system\u00a0to\u00a0predict\u00a0and\u00a0\nreport\u00a0bias\u00a0in\u00a0news\u00a0media\u00a0sources\u00a0(Baly,\u00a0Karadzhov, \u00a0Alexandrov, \u00a0Glass,\u00a0&\u00a0Nakov,\u00a02018).\u00a0\nUsers\u00a0also\u00a0have\u00a0tools\u00a0to\u00a0spot\u00a0misinformation, \u00a0to\u00a0detect\u00a0fake\u00a0news\u00a0or\u00a0to\u00a0discover\u00a0that\u00a0news\u00a0is\u00a0\nbiased.\u00a0However, \u00a0these\u00a0tools\u00a0are\u00a0not\u00a0very\u00a0well\u00a0known\u00a0and,\u00a0in\u00a0most\u00a0cases,\u00a0are\u00a0not\u00a0promoted \u00a0\nenough.\u00a0For\u00a0instance,\u00a0there\u00a0are\u00a0browser\u00a0extensions \u00a0like\u00a0Official\u00a0Media\u00a0Bias\u00a0Fact\u00a0Check\u00a0Icon\u00a0\n(available \u00a0in\u00a0Chrome\u00a0or\u00a0Firefox\u00a0browser)\u00a0that\u00a0detect\u00a0how\u00a0biased\u00a0a\u00a0political\u00a0news\u00a0story\u00a0is,\u00a0built\u00a0\nby\u00a0Media\u00a0Bias\u00a0Fast\u00a0Check\u00a0(https://mediabiasfactcheck.com/). \u00a0Another\u00a0tool\u00a0is\u00a0FakerFact, \u00a0\navailable\u00a0for\u00a0Firefox\u00a0and\u00a0Chrome\u00a0browsers \u00a0(https://www.fakerfact.org/) .\u00a0In\u00a0the\u00a0case\u00a0of\u00a0Spanish,\u00a0\n19\u00a0fact\u2010checking\u00a0tools\u00a0were\u00a0compared \u00a0and\u00a0analyzed\u00a0to\u00a0determine, \u00a0whether\u00a0the\u00a0reporting \u00a0was\u00a0\ntextual,\u00a0visual\u00a0or\u00a0chromatic, \u00a0with\u00a0the\u00a0conclusion \u00a0that\u00a0not\u00a0all\u00a0analyzed\u00a0tools\u00a0were\u00a0recurrently \u00a0\nactive\u00a0(Herrero\u00a0&\u00a0Garc\u00eda,\u00a02019).\u00a0\u00a0\nAnother\u00a0option\u00a0to\u00a0spot\u00a0fake\u00a0news\u00a0is\u00a0the\u00a0use\u00a0of\u00a0Blockchain \u00a0technology. \u00a0This\u00a0technology \u00a0employs\u00a0\ninformation \u00a0blocks\u00a0where\u00a0each\u00a0block\u00a0contains\u00a0basic\u00a0information \u00a0(sender,\u00a0receiver,\u00a0date,\u00a0amount,\u00a0\netc.),\u00a0the\u00a0block\u00a0hash\u00a0(an\u00a0ID\u00a0number\u00a0that\u00a0is\u00a0unique\u00a0and\u00a0unrepeatable) \u00a0and\u00a0the\u00a0hash\u00a0of\u00a0the\u00a0previous\u00a0\nblock\u00a0so\u00a0that\u00a0each\u00a0block\u00a0is\u00a0connected \u00a0to\u00a0the\u00a0previous\u00a0one\u00a0and\u00a0the\u00a0next\u00a0one.\u00a0The\u00a0Blockchain \u00a0\noperation \u00a0is\u00a0based\u00a0on\u00a0the\u00a0hash\u00a0with\u00a0numbering \u00a0that\u00a0is\u00a0generated \u00a0at\u00a0the\u00a0time\u00a0of\u00a0its\u00a0creation,\u00a0so\u00a0that\u00a0\nif\u00a0you\u00a0modify\u00a0the\u00a0information \u00a0from\u00a0the\u00a0blog,\u00a0it\u00a0automatically \u00a0varies\u00a0the\u00a0hash\u00a0and\u00a0invalidates \u00a0the\u00a0\nstring\u00a0because\u00a0it\u00a0will\u00a0cease\u00a0to\u00a0fit\u00a0the\u00a0previous\u00a0and\u00a0subsequent \u00a0blocks.\u00a0The\u00a0security\u00a0and\u00a0certification \u00a0\nof\u00a0documents \u00a0using\u00a0this\u00a0technology \u00a0is\u00a0decentralized \u00a0since\u00a0it\u00a0is\u00a0provided\u00a0by\u00a0users,\u00a0so\u00a0when\u00a0you\u00a0want\u00a0\nto\u00a0add\u00a0a\u00a0piece\u00a0of\u00a0information \u00a0or\u00a0a\u00a0block\u00a0to\u00a0the\u00a0chain,\u00a0it\u00a0is\u00a0the\u00a0users\u00a0themselves \u00a0who\u00a0validate\u00a0it,\u00a0\n\u00a0\n135\u00a0checking\u00a0the\u00a0authenticity. \u00a0An\u00a0example\u00a0of\u00a0the\u00a0use\u00a0of\u00a0this\u00a0technology \u00a0is\u00a0the\u00a0CIVIL\u00a0(https://civil.io) \u00a0\nplatform,\u00a0which\u00a0uses\u00a0blockchain \u00a0technology \u00a0to\u00a0provide\u00a0the\u00a0user\u00a0with\u00a0trustworthy \u00a0news\u00a0while\u00a0also\u00a0\nprotecting \u00a0journalists \u00a0being\u00a0censored\u00a0(Pav\u00eda\u00a0Mart\u00ednez, \u00a02019).\u00a0\nWith\u00a0these\u00a0issues\u00a0in\u00a0mind,\u00a0along\u00a0with\u00a0tools\u00a0under\u00a0development, \u00a0the\u00a0possibility \u00a0to\u00a0use\u00a0browser\u00a0\nextensions \u00a0and\u00a0the\u00a0use\u00a0of\u00a0blockchain \u00a0technology, \u00a0we\u00a0propose\u00a0three\u00a0ways\u00a0to\u00a0combat\u00a0\nmisinformation: \u00a0information \u00a0literacy,\u00a0content\u00a0curation,\u00a0and\u00a0the\u00a0use\u00a0of\u00a0tools\u00a0to\u00a0evaluate\u00a0\ninformation. \u00a0\n1 Information \u00a0literacy\u00a0taught\u00a0by\u00a0information \u00a0professionals \u00a0would\u00a0permit\u00a0users\u00a0to\u00a0classify\u00a0\nthe\u00a0media\u00a0information, \u00a0evaluate\u00a0it\u00a0and\u00a0choose\u00a0truthful\u00a0and\u00a0objective\u00a0information. \u00a0In\u00a0this\u00a0\nsection\u00a0we\u00a0could\u00a0include\u00a0different\u00a0activities\u00a0such\u00a0as\u00a0practical\u00a0workshops \u00a0and\u00a0seminars\u00a0on\u00a0\ndetecting \u00a0Fake\u00a0News,\u00a0subscriptions \u00a0to\u00a0quality\u00a0media\u00a0or\u00a0online\u00a0training.\u00a0Similar\u00a0activities\u00a0\nwere\u00a0proposed \u00a0by\u00a0other\u00a0authors\u00a0(Caridad\u2010Sebasti\u00e1n \u00a0et\u00a0al.,\u00a02018;\u00a0Lopez\u2010Borrull,\u00a0A.,\u00a0Vives\u2010\nGr\u00e0cia,\u00a0J.,\u00a0&\u00a0Badell,\u00a0J.,\u00a02018)\u00a0\n2 Content\u00a0curation\u00a0is\u00a0a\u00a0technique \u00a0to\u00a0manage\u00a0the\u00a0enormous \u00a0quantity\u00a0of\u00a0information \u00a0helping\u00a0\nusers\u00a0with\u00a0information \u00a0overload. \u00a0Using\u00a0the\u00a04S\u00a0strategies \u00a0(search,\u00a0select,\u00a0sense\u00a0making\u00a0and\u00a0\nshare)\u00a0(Guallar\u00a0&\u00a0Leiva,\u00a02013),\u00a0information \u00a0professionals \u00a0may\u00a0select\u00a0sources\u00a0of\u00a0reliable\u00a0\ninformation \u00a0according \u00a0to\u00a0the\u00a0information \u00a0needs\u00a0of\u00a0users,\u00a0choosing\u00a0and\u00a0distributing \u00a0curated\u00a0\ninformation. \u00a0An\u00a0example\u00a0is\u00a0blogs\u00a0in\u00a0libraries\u00a0with\u00a0thematic\u00a0categories \u00a0to\u00a0disseminate \u00a0quality\u00a0\ncontent\u00a0selected\u00a0by\u00a0information \u00a0professionals. \u00a0\n3 The\u00a0creation\u00a0and\u00a0use\u00a0of\u00a0information \u00a0evaluation \u00a0tools.\u00a0Evaluation \u00a0tools\u00a0could\u00a0include\u00a0\nblockchain \u00a0technology \u00a0to\u00a0allow\u00a0information \u00a0distribution \u00a0platforms \u00a0to\u00a0provide\u00a0readers\u00a0with\u00a0\nvalidated \u00a0and\u00a0reliable\u00a0information \u00a0regarding \u00a0content\u00a0and\u00a0its\u00a0source\u00a0(Huckle\u00a0&\u00a0White,\u00a0\n2017).\u00a0However, \u00a0developing \u00a0platforms \u00a0with\u00a0this\u00a0technology \u00a0is\u00a0costly\u00a0and\u00a0requires\u00a0funding\u00a0\nto\u00a0make\u00a0them\u00a0sustainable. \u00a0\n5 Conclusion \nInformation \u00a0professionals \u00a0have\u00a0faced\u00a0different\u00a0obstacles \u00a0throughout \u00a0history\u00a0that\u00a0have\u00a0made\u00a0it\u00a0\ndifficult\u00a0to\u00a0offer\u00a0users\u00a0information \u00a0that\u00a0is\u00a0better\u00a0suited\u00a0to\u00a0current\u00a0needs.\u00a0The\u00a0use\u00a0of\u00a0social\u00a0\nnetworking \u00a0sites\u00a0means\u00a0that\u00a0we\u00a0currently\u00a0receive\u00a0massive\u00a0amounts\u00a0of\u00a0information \u00a0and\u00a0we\u00a0are\u00a0\nexposed\u00a0to\u00a0fake\u00a0news.\u00a0\nSpotting\u00a0fake\u00a0news\u00a0must\u00a0mobilize\u00a0a\u00a0range\u00a0of\u00a0professional \u00a0strategies \u00a0for\u00a0staff\u00a0working\u00a0in\u00a0the\u00a0\nfield\u00a0of\u00a0information \u00a0and\u00a0documentation. \u00a0As\u00a0professionals, \u00a0we\u00a0are\u00a0experts\u00a0because\u00a0of\u00a0the\u00a0\nacademic \u00a0training\u00a0allowing\u00a0us\u00a0to\u00a0combat\u00a0this\u00a0new\u00a0challenge. \u00a0It\u00a0is\u00a0necessary \u00a0to\u00a0insist\u00a0that\u00a0users\u00a0\nbe\u00a0trained\u00a0in\u00a0information \u00a0literacy,\u00a0while\u00a0also\u00a0offering\u00a0them\u00a0curated\u00a0content.\u00a0In\u00a0addition,\u00a0it\u00a0would\u00a0\nbe\u00a0beneficial \u00a0to\u00a0promote\u00a0and\u00a0provide\u00a0users\u00a0with\u00a0tools\u00a0such\u00a0as\u00a0fact\u2010checkers\u00a0along\u00a0with\u00a0back\u00a0end\u00a0\ntechnologies \u00a0such\u00a0as\u00a0blockchain \u00a0to\u00a0obtain\u00a0and\u00a0validate\u00a0information \u00a0in\u00a0a\u00a0secure\u00a0way.\u00a0\nHowever, \u00a0the\u00a0problem\u00a0of\u00a0fake\u00a0news\u00a0is\u00a0at\u00a0the\u00a0junction\u00a0of\u00a0information \u00a0dissemination \u00a0and\u00a0\neconomic \u00a0or\u00a0political\u00a0interests,\u00a0so\u00a0as\u00a0information \u00a0professionals \u00a0we\u00a0are\u00a0in\u00a0a\u00a0complex\u00a0and\u00a0difficult\u00a0\nstruggle.\u00a0We\u00a0think\u00a0it\u00a0would\u00a0be\u00a0beneficial \u00a0to\u00a0develop\u00a0common\u00a0strategies \u00a0among\u00a0information \u00a0\nprofessionals \u00a0along\u00a0with\u00a0documentation \u00a0that\u00a0would\u00a0help\u00a0to\u00a0spot\u00a0fake\u00a0News\u00a0on\u00a0the\u00a0most\u00a0common\u00a0\nSNS\u00a0such\u00a0as\u00a0Facebook \u00a0or\u00a0Twitter .\u00a0\nReferences \n1. American Library Association (2019). Programming librari an. Retrieved from http://programminglibrarian.org/ \n2. Alvarez, B. (2017). Public Libr aries in the Age of Fake News \u2009\u00bb Public Libraries Online. Retrieved from \nhttp://publiclibrariesonline.org/2017/01/feature- public-libraries-in-the-age-of-fake-news/ \n3. Arevalo-Ar\u00e9valo, J. & Mart\u00edn Castilla, S. (2019). El papel de las bibliotecas en un mundo de noticias falsas. \nRetrieved from http:/ /hdl.handle.net/10366/139437 \n\u00a0\n136\u00a04. Baly, R., Karadzhov, G., Alexandrov, D., Glass, J., & Nakov, P. (2018). Pr edicting Factuality of Reporting and \nBias of News Media Sources. ArXiv:1810.01765 [Cs, Stat ]. Retrieved from http://arxiv.org/abs/1810.01765 \n5. BBC (2019). The fake video where Johnson and Corbyn endorse each other. Retrieved from \nhttps://www.bbc.com/news/av/technology-50381728/the-fa ke-video-where-johnson-and-corbyn-endorse-each-\nother \n6. Berkeley Library. University of California. (2019). Real News/Fake News: About Fake News. Retrieved from \nhttps://guides.lib.berkeley.edu/fake-news \n7. Campoamor, L., de la Cruz, M., Fuerte s, S., Fibla, C., Alonso, P. (2018). In forme anual de reporteros sin fronteras. \nRetrieved from https:// www.informeanualrsf.es/ \n8. Caridad-Sebasti\u00e1n, M., Morales-Garc\u00eda, A.-M., Mar t\u00ednez-Cardama, S., & Garc\u00eda-L\u00f3pe z, F. (2018). Infomediaci\u00f3n \ny posverdad: el papel de las bibliotecas. El Profesional de la Informaci\u00f3n, 27(4), 891\u2013898. \nhttps://doi.org/10.3145/epi.2018.jul.17 \n9. CILIP. (2018). CILIP Definition of Information Literacy 2018. Retrieved from \nhttps://infolit.org.uk/ ILdefinitionCILIP2018.pdf \n10. Fraunhofer-Gesellschaft. (2019). Software that can auto matically detect fake news. Retrieved from Fraunhofer-\nGesellschaft website: https://www.fra unhofer.de/en/press/research-news/ 2019/february/software-that-can-\nautomatically-detect-fake-news.html \n11. Guallar, J., Leiva, J. (2013). El conten t curator. Gu\u00eda b\u00e1sica para el nuevo profesional de inte rnet. Editorial UOC: \nBarcelona. \n12. Harvard Library. (2019). Fake News, Misi nformation, and Propaganda. Retrieved from \nhttps://guides.library.harvard.edu/fake \n13. Huckle, S., & White, M. (2017). Fake News: A Technological  Approach to Proving the Origins of Content, Using \nBlockchains. Big Data, 5(4), 356\u2013371.  https://doi.org/10.1089/big.2017.0071 \n14. IFLA. (2018). Fake News and Misinformation Online.  Retrieved from https://www.ifla.org/FR/node/28963 \n15. IFLA. (2019). IFLA - How To Spot Fa ke News. Retrieved 9 July 2019, from \nhttps://www.ifla.org/ publications/node/11174 \n16. Katsaounidou, A., Vryzas, N., Kotsakis, R. & Dimoulas, Ch. (2019). Mu ltimodal news authenti cation as a service: \nThe \u00abTrue News\u00bb Extension. Journal of Education, Innovation, and Communication (JEICOM), 1, 11-26. DOI : \nhttps://doi.org/10.34097/jeicom_SI_Dec2019-1 \n17. Levin, S. (2017). Facebook to give C ongress thousands of ads bought by Russians during election. The Guardian. \nRetrieved from https://www.theguard ian.com/technology/2017/sep/21/face book-adverts-congress-russia-trump-\nus-election \n18. Llanos, H. (2019). De la par odia viral del Equipo E a los bulos: las dos ca ras de los v\u00eddeos 'deepfake' que circulan \npor WhatsApp. Retrieved from https://verne .elpais.com/verne/2019/11/12/articulo/1573550621_550329.html \n19. Lopez-Borrull, A., Vives-Gr\u00e0cia, J., & Badell, J. ( 2018). Fake news, \u00bfamenaza u oportunidad para los \nprofesionales de la informaci\u00f3n y la documentaci\u00f3n ? El Profesional de la Informaci\u00f3n, 27(6), 1346\u20131356. \nhttps://doi.org/10.3145/epi.2018.nov.17 \n20. McCarthy, T. (2017). How Russia used social media to  divide Americans. The Guardian. Retrieved from \nhttps://www.theguardian.com/us-news/2017/oct/ 14/russia-us-politics-social-media-facebook \n21. Newman, N., Fletcher, R., Kalogeropoul os, A., Nielsen. R. (2019). Reuter s Institute Digita l News Report 2019. \nRetrieved from https://reutersins titute.politics.ox.ac.uk/sites/defau lt/files/inline-files/DNR_2019_FINAL.pdf \n22. Oxenham, S. (2019). \u2018I was a Macedonian fake  news writer\u2019. BBC Future. Retrieved from \nhttps://www.bbc.com/future/article/20190528-i- was-a-macedonian-fake-news-writer \n23. Pav\u00eda Mart\u00ednez, A. (2019). El problema: fake news. La soluci\u00f3n: blockchain. Retrieved from \nhttp://openaccess.uoc.edu /webapps/o2/handle/10609/98506 \n24. Shao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., & Menczer, F. (2018). The spread of low-\ncredibility content by social bots. Nature Commun ications, 9(1), 1\u20139. https://doi.org/10.1038/s41467-018-06930-\n7 \n25. Shu, K., Mahudeswaran, D., & Liu, H. (2019). FakeNewsTrack er: a tool for fake news collection, detection, and \nvisualization. Computational and Mathem atical Organization Theory, 25(1), 60\u201371. \nhttps://doi.org/10.1007/s10588-018-09280-3 \n26. UNESCO. (2017). Alfabetizaci\u00f3n medi\u00e1tic a e informacional. Retrieved from \nhttp://www.unesco.org/new/es/co mmunication-and-information/media-development/media-literacy/mil-as-\ncomposite-concept/ \n27. UNESCO (2018). Five Laws of Media and Information Literacy. Retrieved from \nhttp://www.unesco.org/new/en/communi cation-and-information/ media-development/media -literacy/five-laws-\nof-mil/ \n28. Herrero, J. V., & Garc\u00eda, \u00c1. A. V. (2019). Plataformas de fact-checking en espa\u00f1ol: Caracter \u00edsticas, organizaci\u00f3n \ny m\u00e9todo. Comunicaci\u00f3n y sociedad = Communication & Society, 32(1), 127\u2013143. \n\u00a0\n137\u00a029. Washington, O. (2017). Russia-backed Facebook posts \u2018r eached 126m Americans\u2019 during U.S. election. The \nGuardian. Retrieved from https://www.theguardian. com/technology/2017/oct/30/face book-russia-fake-accounts-\n126-million \n30. Wong, J. C. (2019). \u2018Way ahead of the field\u2019: inside Trump\u2019s unprecedented social media campaign. The Guardian. \nRetrieved from https://www.theguardian.com/us-news/ 2019/jul/02/way-ahead-of-the-field-inside-the-trump-\ncampaigns-unprecedented-social-media-campaign ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Information Professional's Role in the Fake News Phenomenon", "author": ["C Mirass\u00f3 Pedr\u00f3s", "JJ Bot\u00e9-Vericad"], "pub_year": "2020", "venue": "\u2026 22-24, 2020. InLitAs. Paris. pp \u2026", "abstract": "The goal of this paper is to analyze the main characteristics of the Fake News phenomenon  in the Information Science field. With the digital era and the use of new technologies, new"}, "filled": false, "gsrank": 143, "pub_url": "https://diposit.ub.edu/dspace/handle/2445/183619", "author_id": ["", "1251VI8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ASZ797jdINIJ:scholar.google.com/&output=cite&scirp=142&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ASZ797jdINIJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:ASZ797jdINIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://diposit.ub.edu/dspace/bitstream/2445/183619/1/BOBCATSSS%202020_Bote2.pdf"}}, {"title": "Sampling the news producers: A large news and feature data set for the study of the complex media landscape", "year": "2018", "pdf_data": "Sampling the News Producers: A Large News and Feature\nData Set for the Study of the Complex Media Landscape\nBenjamin D. Horne, Sara Khedr, Sibel Adal\u0131\nRensselaer Polytechnic Institute, Troy, New Y ork, USA\n{horneb, khedrs, adalis }@rpi.edu\nAbstract\nThe complexity and diversity of today\u2019s media landscape pro-\nvides many challenges for researchers studying news produc-\ners. These producers use many different strategies to get their\nmessage believed by readers through the writing styles theyemploy, by repetition across different media sources with or\nwithout attribution, as well as other mechanisms that are yet\nto be studied deeply. To better facilitate systematic studies inthis area, we present a large political news data set, contain-\ning over 136K news articles, from 92 news sources, collected\nover 7 months of 2017. These news sources are carefully cho-sen to include well-established and mainstream sources, mali-\nciously fake sources, satire sources, and hyper-partisan politi-\ncal blogs. In addition to each article we compute 130 content-based and social media engagement features drawn from a\nwide range of literature on political bias, persuasion, and mis-\ninformation. With the release of the data set, we also providethe source code for feature computation. In this paper, we\ndiscuss the \ufb01rst release of the data set and demonstrate 4 use\ncases of the data and features: news characterization, engage-ment characterization, news attribution and content copying,\nand discovering news narratives.\nIntroduction\nThe complexity and diversity of today\u2019s media landscape\nprovides many challenges for researchers studying news. Inthis paper, we introduce a broad news benchmark data set,called the NEws LAndscape (NELA2017) data set, to facili-\ntate the study of many problems in this domain. The data set\nincludes articles on U.S. politics from a wide range of newssources that includes well-established news sources, satirenews sources, hyper-partisan sources (from both ends of thepolitical spectrum), as well as, sources that have been knownto distribute maliciously fake information. At the time ofwriting, this data set contains 136K news articles from 92\nsources between April 2017 and October 2017.\nAs news producers and distributors can be established\nquickly with relatively little effort, there is limited prior dataon the reliability of some of many sources, even though theinformation they provide can end up being widely dissemi-nated due to algorithmic and social \ufb01ltering in social media.It has been argued that the traditionally slow fact-checking\nCopyright c/circlecopyrt2018, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.process and journalistically trained \u201cgatekeepers\u201dare insuf-\n\ufb01cient to counteract the potentially damaging effect thesesources have on the public (Mele et al. 2017) (Buntainand Golbeck 2017). As a result, there is a great deal ofearly research in automatically identifying different writ-ing styles and persuasion techniques employed by newssources (Popat et al. 2016) (Potthast et al. 2017) (Horne andAdal\u0131 2017) (Chakraborty et al. 2016) (Singhania, Fernan-dez, and Rao 2017). Hence, a broad data set including manydifferent types of sources is especially useful in further re-\ufb01ning these methods. To this end, we include 130 content-based features for each article, in addition to the article meta-data and full text. The feature set contains almost all the fea-tures used in the related literature, such as identifying misin-formation, political bias, clickbait, and satire. Furthermore,we include Facebook engagement statistics for each article(the number of shares, comments, and reactions).\nWhile much of recent research has focused on automatic\nnews characterization methods, there are many other newspublishing behaviors that are not well-studied. For instance,there are many sources that have been in existence for a longtime. These sources enjoy a certain level of trust by theiraudience, sometimes despite their biased and misleading re-porting, or potentially because of it. Hence, trust for sourcesand content cannot be studied independently. While misin-formation in news has attracted a lot of interest lately, it is\nimportant to note that many sources mix true and false in-\nformation in strategic ways to not only to distribute false in-formation, but also to create mistrust for other sources. Thismistrust and uncertainty may be accomplished by writingspeci\ufb01c narratives and having other similar sources copy thatinformation verbatim (Lytvynenko 2017). In some cases,sources may copy information with the intention to misrep-\nresent it and undermine its reliability. In other cases, a sourcemay copy information to gain credibility itself. Similarly, thecoverage of topics in sources can be highly selective or mayinclude well-known conspiracy theories. Hence, it may beimportant to study a source\u2019s output over time and compare\nit to other sources publishing news in the same time frame.This can sometimes be challenging as sources are known to\nremove articles that attract unwanted attention. We have ob-served this behavior with many highly shared false articlesduring the 2016 U.S. election.\nThese open research problems are the primary reasons weProceedings of the Twelfth International AAAI Conference on Web and Social Media (ICWSM 2018)\n518\nhave created the NELA2017 data set. Instead of concentrat-\ning on speci\ufb01c events or speci\ufb01c types of news, this dataset incorporates all political news production from a diversegroup of of sources over time. While many news data setshave been published, none of them have the broad range ofsources and time frame that our data set offers. Our hope isthat our data set can help serve as a starting point for manyexploratory news studies, and provide a better, shared insightinto misinformation tactics. Our aim is to continuously up-date this data set, expand it with new sources and features,as well as maintain completeness over time.\nIn the rest of the paper, we describe the data set in de-\ntail and provide a number of motivating use cases. The \ufb01rstdescribe how we can characterize the news sources usingthe features we have provided. In the second, we show howsocial media engagement differs across groups sources. Wethen illustrate content copying behavior among the sourcesand how the sources covered different narratives around twoevents.\nRelated Work\nThere are several recent news data sets, speci\ufb01cally focusedon fake news. These data sets include the following.\nBuzzfeed 2016 contains a sample of 1.6K fact-checked\nnews articles from mainstream, fake, and political blogsshared on Facebook during the 2016 U.S. Presidential Elec-tion\n1. It was later enhanced with meta data by Potthast et\nal. (Potthast et al. 2017). This data set is useful for under-standing the false news spread during the 2016 U.S. Presi-dential Election, but it is unknown how generalizable resultswill be over different events. LIAR is a fake news bench-\nmark data set of 12.8K hand-labeled, fact-checked shortstatements from politifact.com (Wang 2017). This data setis much larger than many previous fake news data sets, butfocuses on short statements rather than complete news arti-cles or sources. NECO 2017 contains a random sample of\nthree types of news during 2016: fake, real, and satire. Eachsource was hand-labeled using two online lists. It containsa total of 225 articles (Horne and Adal\u0131 2017). While theground truth is reasonably based, the data set is very smalland time-speci\ufb01c. BS Detector contains approximately 12K\n\u201cfake news\u201d articles collected using the browser extensionBS Detector which labels news based on a manually com-piled source dictionary (http://bsdetector.tech/) and is pub-licly available on kaggle.com. The reliability of these lists\nare unknown.\nAdditionally, there are much larger, general news data sets\nthat are are focused on events, topics, and location. Theseinclude the following. GDELT contains a wide range of on-\nline publications, including news and blogs, in over 100 lan-guages. The collection is based on world events, focusing onlocation, temporal, and network features. GDELT providesa useful visual knowledge graph that indexes images and vi-suals used in news. While this data set provides news dataover an extended period of time, it is focused on news sur-rounding external events, and may not capture many \u201cfake\u201dnews sources. In addition, Kwak and An (Kwak and An\n1github.com/BuzzFeedNews/2017-12-fake-news-top-502016) point out that there is concern as to how biased theGDELT data set is as it does not always align with otherevent based data sets. Un\ufb01ltered News (un\ufb01ltered.news) is\na service built by Google Ideas and Jigsaw to address \ufb01lterbubbles in online social networks. Un\ufb01ltered News indexesnews data for each country based on mentioned topics. Thisdata set does not focus on raw news articles or necessarilyfalse news, but on location-based topics in news, making itextremely useful for analyzing media attention across timeand location. Data from Un\ufb01ltered News is analyzed in (An,Aldarbesti, and Kwak 2017).\nThere are many more data sets that focus on news or\nclaims in social networks. CREDBANK is a crowd sourced\ndata set of 60 million tweets between October 2015 andFebruary 2016. Each tweet is associated to a news eventand is labeled with credibility by Amazon Mechanical Turk-ers (Mitra and Gilbert 2015). This data set does not containraw news articles, only news article related tweets. PHEME\nis a data set similar to CREDBANK, containing tweetssurrounding rumors. The tweets are annotated by journal-ist (Zubiaga et al. 2016). Once again, this data set does notcontain raw news articles, but focused on tweets spread-ing news and rumors. Both PHEME and CREDBANK areanalyzed in (Buntain and Golbeck 2017). Hoaxy is an on-\nline tool that visualizes the spread of claims and relatedfact checking (Shao et al. 2016). Claim related data can becollected using the Hoaxy API. Once again, data from thistool is focused on the spread of claims (which can be manythings: fake news article, hoaxes, rumors, etc.) rather thannews articles themselves.\nOther works use study-speci\ufb01c data sets collected from\na few sources. Some of these data sets are publicly avail-able. Piotrkowicz et al. use 7 months of news data collectedfrom The Guardian and The New Y ork Times to assessheadline structure\u2019s impact on popularity (Piotrkowicz et al.2017). Reis et al. analyze sentiment in 69K headlines col-lected from The New Y ork Times, BBC, Reuters, and Dai-lymail (Reis et al. 2015). Qian and Zhai collect news fromCNN and Fox News to study unsupervised feature selectionon text and image data from news (Qian and Zhai 2014).Saez-Trumper at al. explore different types of bias in newsarticles from the top 80 news websites during a two-weekperiod (Saez-Trumper, Castillo, and Lalmas 2013).\nThere are 3 core issues with these data sets that we address\nwith the NELA2017 data set:\n1. Small in size and sources - The current data sets that fo-\ncused on news producers contain very few sources, typ-ically focused on one type of source (mainstream, fake,etc.), and have a small number of data points.\n2. Event speci\ufb01c - Many of the current data sets are focused\non small time frames or speci\ufb01c events (ex. 2016 Presi-dential Election). To ensure current results can be gener-alized and to track how the news is changing, researchersneed data across time and events.\n3. Engagement speci\ufb01c - The majority of these data sets\ncontain only highly engaged or shared articles. Whileit can be argued that these are the more important datapoints, they lack the complete picture of news producer\n519\nbehavior. In order to understand how news producers pub-\nlish, speci\ufb01cally hyper-partisan and malicious sources, re-searchers need to explore both the viral and the never seenarticles produced.\nHence, our goal for the NELA2017 data set is to create\na large, near-complete news article data set, across the vari-ous types of sources, in hopes of providing a more completeview of how news producers behave.\nData set creation\nIn creating our data set, we target a collection of sourcesto include both well-established news companies, politi-cal blogs, and satire websites ,as well as many alterna-tive news sources that have published misinformation in thepast or have relatively unknown veracity. To select thesesources, we used a 3-step process: 1. We select well-knownsources using Wikipedia lists to capture many mainstreamand well-established sources. 2. We randomly select sourcesfrom the opensources.co lexicon. OpenSources is expert-cu-rated news source lexicon containing 12 different types ofsources: fake, satire, extreme bias, conspiracy, rumor, state,junk science, hate speech, clickbait, unreliable, political, andreliable. This step captures many niche sources and thosewho have spread fake news in the past. 3. We hand selectsources cited by previously selected sources (based on read-ing random articles). This 3rd step provides even more di-versity across intentions and political leanings. To ensurethat we have a balance of left and right leaning sources,we review selected sources using the crowd-sourced bias-checking service mediabiasfactcheck.com.\nOnce we have the set of news sources, we create article\nscrapers for each source. Each scraper is collects news arti-cles at 12:00pm EST and 9:00pm EST each day. This nearreal-time collection allows us to maintain news articles thatare later deleted, a common practice among maliciously fakenew sources. Some sources can be collected using standardRSS feed scrapers, while others, especially the less crediblesources, need custom web scrapers to collect articles. Fornews sources with available RSS feeds, we use the Pythonlibrary feedparser\n2, for news sources with standard HTML\nstructure we use python-goose3, and for news sources with\ndif\ufb01cult to parse HTML structures, we use a mix of Beau-tifulSoup\n4, and feedparser to create site speci\ufb01c scrapers.\nOf the 100 sources selected, there were 8 that our scraperscould not consistently collect, leaving us with 92 sources.\nTo control for topic, we only collect political news from\neach source. For the majority of sources, controlling for\ntopic is very easy, as their websites are divided into topic-\nbased feeds. It is important to note that some topic-basedfeeds are less strict than others, speci\ufb01cally on fake newssites. Thus, in the political news feed, some pseudo-scienceand odd topic conspiracy articles are mixed in. We chooseto collect these occasional off-topic articles as well, as theymay provide insight to these fake news sources.\n2pythonhosted.org/feedparser/\n3github.com/grangier/python-goose\n4www.crummy.com/software/BeautifulSoup/bs4/doc/Each scraper collects the following information:\ncontent - the text from the body of the article\ntitle - the text from the title of the article\nsource - the source of the article\nauthor - the journalist who wrote the article, if the\ninformation is available in the web page meta data\npublished - the UTC time stamp of publication according\nto the web page\nlink - the url used to scrape the article (RSS feed or web\npage)\nhtml - the full HTML of the article page stored as unicode\nThis information is stored for each article in a JSON dic-\ntionary, with keys of the same name as above.\nUsing this process, we obtain almost 100% of the articles\nproduced during the 7 month time period. The approximate\ncompletion percentage for each source over the 7 months ofcollection can be found in Table 1.\nFeature set creation Next, to facilitate content-based\nanalysis and writing style research on these articles, wecompute 130 content-based features and collect 3 Facebookengagement statistics on each news article. These featurescome from a wide range of literature on false news detec-tion (Potthast et al. 2017) (Horne and Adal\u0131 2017) (Horneet al. 2018), political bias detection (Recasens, Danescu-Niculescu-Mizil, and Jurafsky 2013), content popularity (Pi-otrkowicz et al. 2017) (Horne, Adali, and Sikdar 2017),clickbait detection (Chakraborty et al. 2016), and generaltext characterization (Loper and Bird 2002). We break thesefeatures down into 7 categories: structure, complexity, senti-ment, bias, morality, topic, and engagement. All 130 featuresare computed on the title and the body text separately, giv-ing us 260 content-based features in total. Due to the widerange of literature these features are borrowed from, someare highly correlated, but all are computed differently. Toallow researchers even more \ufb02exibility, we provide all ofthe feature code in one easy-to-use Python script. All fea-ture code and implementation details are available at: (sup-\npressed for blind review). Descriptions of these features can\nbe found in Table 2. Due to lack of space, we will leavemajor implementation details to the data set and code docu-mentation.\nPotential use cases of the NELA2017 data set\nThere is a variety of news credibility research strands thatcan bene\ufb01t from this data set. In particular, we argue thatthis data set can not only test the generality of previous re-sults in computational journalism, but also spark research inlesser studied areas. In this section, we present 4 use caseswith varying levels of granularity, including: general newssource characterization, highly engaged article characteriza-tion, content attribution and copying, and analyzing speci\ufb01cnews narratives.\nNews Source Characterization\nThe most obvious and general use of the NELA2017 dataset is news source characterization and comparison. Withthe increasing public attention on news sources, many maps\n520\nSource Complete Source Complete Source Complete Source Complete\nAP 50% Freedom Daily 100% Observer 100% Duran 71%\nActivist Post 100% Freedom Outpost 100% Occupy Democrats 93% Fiscal Times 71%\nAddicting Info 57% FrontPage Mag 100% PBS 100% Gateway Pundit 100%\nAlt Media Syn 78% Fusion 86% Palmer Report 50% The Guardian 100%\nBBC 100% Glossy News 100% Politicus USA 100% The Hill 100%\nBipartisan Report 100% Hang the Bankers 72% Prntly 71% Huf\ufb01ngton Post 100%\nBreitbart 100% Humor Times 100% RT 71% The Inquisitr 100%\nBusiness Insider 100% Infowars 100% The Real Strategy 100% New Y ork Times 100%\nBuzzFeed 100% Intellihub 100% Real News Right Now 100% The Political Insider 100%\nCBS News 100% Investors Biz Daily 100% RedState 100% Truthfeed 79%\nCNBC 100% Liberty Writers 100% Salon 100% The Right Scoop 100%\nCNN 100% Media Matters 100% Shareblue 50% The Shovel 100%\nCNS News 100% MotherJones 36% Slate 100% The Spoof 100%\nConservative Trib 100% NODISINFO 86% Talking Points Memo 50% TheBlaze 100%\nCounter Current 100% NPR 100% The Atlantic 100% ThinkProgress 100%\nDaily Buzz Live 86% National Review 100% The Beaverton 100% True Pundit 100%\nDaily Kos 100% Natural News 100% Borowitz Report 93% Washington Examiner 100%\nDaily Mail 100% New Y ork Daily 100% Burrard Street Journal 86% USA Politics Now 36%\nDaily Stormer 72% New Y ork Post 100% The Chaser 100% USA Today 100%\nDrudge Report 79% NewsBiscuit 100% ConservativeTreeHouse 100% V eterans Today 100%\nFaking News 100% NewsBusters 72% D.C. Clothesline 93% Vo x 100%\nFox News 86% Newslo 93% Daily Beast 100% Waking Times 100%\nWorld News Politics 93% Xinhua 36% Yahoo News 100% Y oung Conservatives 93%\nTable 1: Approximate completion percentage of all sources in the data set. Since each news source publishes at different rates,\nwe compute completion as having more than 1 article published in each 2 week period of the data set.\nAbbr. Description\nPOS normalized count of each part of speech (36\nfeats)\nlinguistic # function words, pronouns, articles, preposi-\ntions, verbs, etc. using LIWC lexicons (24 fea-tures)\nclickbait clickbait title classi\ufb01cation using models built\nin (Chakraborty et al. 2016)\n(a) Structure Features\nsentiment negative, positive, and neutral sentiment\nscores from V ADER (Hutto and Gilbert 2014)\n(3 features)\nemotion positive, negative, affect, etc. words using\nLIWC and strong/weak emotion words from\nlexicons in (Recasens, Danescu-Niculescu-\nMizil, and Jurafsky 2013) (13 features)\nHappiness happiness score using (Mitchell et al. 2013)\nHappiness lexicon\n(b) Sentiment Features\nFacebook\nengage-\nment# of shares, comments, reactions collected us-\ning Facebook API\n(c) Engagement Features\nbio biological processes from LIWC lexicon (5\nfeatures)\nrelativity motion, time, and space words from LIWC\nlexicon (4 features)\npersonal\nconcernswork, home, leisure, etc. from LIWC lexicon\n(6 features)\n(d) Topic-dependent FeaturesAbbr. Description\nTTR Type-Token Ratio, also known as lexi-\ncal diversity or redundancy, computed as\n#uniquewords\ntotalwords\nFKE Standard readability measure computed\nby 0.39\u2217(totalwords\ntotalsentences)+1 1 .8\u2217\n(totalsyllables\ntotalwords)\u221215.59\nSMOG Standard readability measure computed by\n1.0430\u2217/radicalBig\n#polysyllables \u221730\n#sentences+\n3.1291\nwordlen average # characters in a word\nWC word countcogmech # cognitive process words (includes cause, in-\nsight, etc.) from LIWC lexicons (7 features)\n(e) Complexity Features\nbias several bias lexicons from (Recasens,\nDanescu-Niculescu-Mizil, and Jurafsky 2013)\nand (Mukherjee and Weikum 2015) (14 fea-\ntures)\nsubjectivity probability of subjective text using a Naive\nBayes classi\ufb01er trained on 10K subjective and\nobjective sentences from (Pang and Lee 2004)used in (Horne and Adal\u0131 2017)\n(f) Bias Features\nMoral features based on Moral Foundation The-\nory (Graham, Haidt, and Nosek 2009) and lex-\nicons used in (Lin et al. 2017) (10 features)\n(g) Morality Features\nTable 2: Different features implemented on data set. Each feature is compute on the title and body text separately\nof the media landscape have been offered to show how dif-\nferent sources compare to each other. Often these maps arebased on a subjective evaluation of these sources. Our fea-tures make it possible to draw such comparisons based on\nalgorithms with transparent criteria.\nWe \ufb01rst show the top 10 sources in Figure 1 according\n521\n(a) Top 10 Most Subjective Writing Style (on average) (b) Top 10 Hardest to Read (on average)\n(c) Top 10 Most Clickbait Titles (% of articles) (d)Top 10 Longest Title (on average)\n(e) Top 10 Most Negative Sources (on average) (f) Top 10 Most Lexically Redundant Sources (on average)\nFigure 1: Top 10 sources for a selection of features.\nto their average behavior with respect: (a) subjectivity based\non writing style, (b) grade level readability, (c) the click-\nbait nature of titles, (d) length of titles, (e)d negative sen-\ntiments expressed, and (f) the amount lexical redundancy,i.e. repetition in articles. Past research shows fake news ar-ticles are generally easier to read and more repetitive, butare not necessarily clickbait (Horne and Adal\u0131 2017). It isalso well-studied that many highly engaged fake articles andconspiracy theories express negative emotions (Bessi et al.\n2015). All of these previous results are accurately supported\nby the ranking with our features. For example, the subjectiv-ity accurately captures a number of highly partisan sourcesin our list and the clickbait predictions point to well-knownclickbait sources. However, these clickbait sources are notnecessarily among the sources with very long titles or repet-itive content. The sources with highest grade reading includesome sources that translate languages (Xinhua) and moreniche domain sources (The Fiscal Times).\nAdditionally, we also look at the consistency of sources\nare over time. Sources may show higher variation in thesedistributions due to lack of editorial standards, as well as,different types of content mixing (made up content or con-\ntent copied from other sources). In Figure 2, we show se-\nlect feature distributions over the full 7 months of data forfour news sources: Liberty Writers, Newslo, The New Y ork\nTimes, and PBS. We can clearly see both Liberty Writers\nand Newslo have very wide distributions, where as The New\nY ork Times and PBS have much more narrow distributions,illustrating consistency. These features are not only usefulfor quick source comparison, but have predictive power innews as shown in prior work (Popat et al. 2016) (Horne andAdal\u0131 2017). Given our feature set is a superset of all the fea-tures from the different literature threads, we expect them tohave accuracy as well or better than those reported. Due tolack of space, we do not provide examples of prediction.\nEngagement Characterization\nWhile the NELA2017 data set does not contain labels, suchas which articles are fake and which are not, we can makelabeled subgroups of the data set using external labeling orunsupervised clustering over different features described in\nthe previous use case. For space reasons, we provide an ex-\nample of external labeling only. There are many ways to la-bel news articles and sources in the NELA2017 data set suchas based on ownership, self-proclaimed political leaning, re-liability (using a lexicon like opensources.co), or the age ofthe news source.\nTo explore this method, we group sources by their self-\n522\nFigure 2: Feature distributions across different articles from speci\ufb01c sources\nMedian Max Median Max\n(a) Self-Proclaimed Political biased groups (b) Self-Proclaimed Political + previous behavior groups\nFigure 3: Facebook shares for source groups over time. The median or the max of the shares is measure every two weeks.\nHence, 0 is the beginning of April, and 14 is the end of October.\nproclaimed political leaning as conservative or liberal and\nexclude satire news sources and any news source that doesnot clearly claim a political ideology. These subgroups con-tain 16 liberal sources and 17 conservative sources. Whilethere are certainly other politically biased news sources inthe data set, we are strictly looking at self-proclaimed lean-ing. We can break down these groups even further by usingpreviously known reporting behavior. Speci\ufb01cally, we ask\u201chas the source published a completely false article in thepast?\u201d To do this, we manually use 3 online fact-checkers:\n(snopes.com, politifact.com or factcheck.org). In this divi-sion, we do not include sources that have published partiallyfalse articles, only completely false. This labeling can bethought of as source-level reliability rather than article-levelcorrectness.\nWith these newly labeled subgroups of the NELA2017\ndata set, we explore Facebook shares over time. In Figure 3a,we see that, on average, politically-left leaning news sourceshad higher shares over the 7 month time period and theseshares increased over time. When looking at the max num-ber of shares, rather than the median, we see politically-rightleaning news sources were often shared slightly more. InFigure 3b, when splitting by previously publishing a falsearticle, false politically-left sources were shared more thantrue politically-left news sources in the \ufb01rst 3 months of thetime slice, but decrease signi\ufb01cantly in the last 4 monthsof the time slice. In contrast, false right-leaning sources areshared more than true right-leaning source over the full 7\nmonth time slice. While this simple analysis does not con-\nclude that false news articles were more highly shared thantrue news articles during this time, it does illustrate differ-ences in engagement with political news sources that have\npublished false articles in the past.\nAttribution and Content Copying\nA lesser studied area that can bene\ufb01t from the NELA2017data set is news attribution, which has been studied in jour-nalism, but not in the context of today\u2019s news ecosystem. Incontext of today\u2019s news environment, Jane Lytvynenko of\nBuzzfeed News points out that the conspiracy news site In-fowars copied 1000\u2019s are articles from other sources without\nattribution over the past 3 years (Lytvynenko 2017). Mostnotably, Infowars copied from Russia Today (RT), Sputnik,CNN, BBC, The New Y ork Times, Breitbart, CNS News,and The Washington Post. This article sheds light on the po-tential content-mixing methods of fake and conspiracy news\nsources that publish original material with a speci\ufb01c mes-\nsage and also report \u201creal\u201d content from other sources to in-crease their perceived credibility.\nTo provide an example of this, we extract highly similar\narticles from several two-week intervals. We do this usingthe cosine similarity between TFIDF (Term-Frequency In-verse Document-Frequency) article vectors, a standard tech-nique in information retrieval. For every article pair from adifferent source, if the cosine similarity is above 0.90 (mean-ing the articles are almost verbatim), we extract the articlepair and compare time stamps to see which source publishedthe article \ufb01rst. Over each two week interval, we use the timestamp comparison to create a weighted directed graph, inwhich in-degree is how many articles are copied from thenode and out-degree is how many articles a node copies.In Figure 4, we show networks from two time frames: May\n523\n(a) May 1st-14th 2017 (b) July 1st-14th 2017\nFigure 4: Article similarity graphs during two different two-week periods. The weighted in-degree is the number of articles\ncopied from a source. The weight is indicated by the size of the arrow. The in-degree of a source is shown by the size of thenode. The color of a node indicates the community it belongs to based on modularity.\n1st-14th and July 1st-14th. In each \ufb01gure, the weighted in-\ndegree is represented by the size of the arrow. Each node\u2019sin-degree is shown by the size of the node and each node iscolored based on the community it belongs to (using modu-larity). Note, since this is a pair-wise analysis, there may beredundant links if the same story is copied by many sources.For example, if several sources copy a story from AP , thenetwork will not only point to AP , but also to the sourcesthat published that story earlier than another source. Whilethere are many potential types of content copying, this anal-ysis is only exploring near exact content copying. Speci\ufb01-cally, sources that may mix false and true content would notbe captured by the high cosine similarity.\nIn each graph, there are multiple connected components\nand clear communities of who copies from who. In par-ticular, we see well-known mainstream sources copy fromeach other (primarily from AP , a news wire service) andknown conspiracy sources copy from each other. In somecases, these two communities are completely disconnectedand other times there is a path between them. For example,\nin Figure 4a, there exists a path between USA Politics Now\nand Fox News (through Liberty Writers and The GatewayPundit). In other time slices (not shown), we see a directpath between Infowars and Fox News (Fox News copyingfrom Infowars and vice versa). In addition to these two largercommunities, we see many separate smaller communities ofsources, including satire, left-wing, and right-wing commu-nities. We see very similar community structure and attribu-tion patterns throughout the data set. Overall, the communitystructure we observe in content similarity networks is verysimilar to that of the news ecosystem on Twitter (Starbird2017), where alternative news sources form tight-knit com-\nmunities with few connections to mainstream news.\nWe further categorize the types of content copying we see\ninto three primary categories:\nProper Attribution, Different Title. Many sources pub-\nlish full, word-for-word articles from The Associated Press(AP), but provide clear citations such as \u201c2017 The Associ-ated Press. All Rights Reserved.\u201d or \u201cThe Associated Press\ncontributed to this report.\u201d Speci\ufb01cally, we see this citation\nbehavior in sources like CBS News, PBS News, Fox News,Breitbart, The Talking Points Memo, and The Huf\ufb01ngtonPost. More interestingly, while the content is almost exactlythe same, the titles can be very different. For example, the ti-tle for an AP article was \u201cScholars White Houses name gaffenot helping US-China ties,\u201d where as the Fox News title forthe same article was \u201cChinese scholars rip White House staff\nafter name mix up.\u201d Related, we see that True Pundit di-\nrectly copies many full articles from The Daily Caller (60copied articles between April 14th and May 14th). At theend of each article The Daily Caller writes: \u201cContent cre-ated by The Daily Caller News Foundation is available with-out charge to any eligible news publisher that can provide alarge audience.\u201d Thus, True Pundit\u2019s copying can be consid-ered legitimate attribution. Infowars similarly takes articlesfrom the Daily Caller.\nSame Author, Different Source. Surprisingly, we \ufb01nd\nthe majority of highly similar articles are written by the sameauthor on different sources. There are many examples of thisbehavior. We see The D.C. Clothesline and Freedom Out-post commonly publish articles written by Tim Brown. TheD.C. Clothesline also has articles written by Jay Syrmopou-\n524\nlos, who writes for Activist Post and The Free Thought\nProject. The Daily Caller, Infowars, and The Real Strategyall have word for word identical articles written by LukeRosiak. The Waking Times and Activist Post have articleswritten by Alex Pietrowski. Salon and Media Matters forAmerica have multiple articles written by Cydney Hargis. Insatire news, Rodger Freed writes the same articles for TheSpoof, Humor Times, and Glossy News, usually publishingon The Spoof \ufb01rst. In another example, a series of storiesabout a \u201cGeorge Soros backed Trump resistance fund\u201d arepublished word for word on both Infowars and Fox News,all written by Joe Schoffstal. Each article does not have clearattribution to one or the other source, despite being exactcopies and each article was written on Infowars days priorto its publication on Fox News. This example is particularlysurprising as Fox News captures a wide, mainstream audi-ence and Infowars is a well known conspiracy source, cre-ating a clear path between a well-established news sourceand conspiracy/false news. Note, while many of these arti-cles are clearly written by the same author, as the authorsstate they contribute to both sources, there are others thatmay just be copied with the authors name included. For ex-ample, The D.C. Clothesline seems to have many authorsthat contribute elsewhere, but there is no indication in theauthors\u2019 biographical information (on the other sources theycontribute to) that they contribute to The D.C. Clothesline.Hence, while the author contributes to multiple sources, it isunclear that they contribute to The D.C. Clothesline.\nNo Attribution. We also see several sources, particularly\nthose who have been caught spreading false news in thepast, copying news articles with no citation. In particular, wefound that both V eterans Today and Infowars copied multi-\nple articles directly from Russia Today (RT), with no citation\nsimilar to behavior that has been pointed out by Jane Lytvy-nenko (Lytvynenko 2017).\nIssue framing and narrative slant\nIn addition to \u201cbig picture\u201d analysis, NELA2017 can also beused to study speci\ufb01c events. To illustrate this, we explorediffering narratives reported around a speci\ufb01c event. Whilemany sources may cover the same topic, they may not reportall sides of a story or may have an imbalanced quantity ofcoverage (Lin, Bagrow, and Lazer 2011). This type of cov-erage bias has been explored in terms of political party slantin US congress stories (Lin, Bagrow, and Lazer 2011), andsimilar notions of bias, including framing and agenda settingbias, have been in explored in various media studies (Entman2007) (Pan and Kosicki 1993). There is more recent work on\nideological bias in news stories caused by journalists Twitter\nnetworks (Wihbey et al. 2017). However, there is little to norecent work on the speci\ufb01c dynamics of differing news nar-ratives. Further, since the NELA2017 data set covers manydifferent political events, it is ideal for tracking publishingand reporting behavior over a wide range of time, somethingthat has also not been explored in the literature.\nTo provide an example of event extraction from the\nNELA2017 data set, we perform a simple extraction tech-nique on two different events: 1. the U.S. national anthemprotests\n5, 2. the dismissal of James Comey6. The U.S.\nnational anthem protests were protests in which athletes,speci\ufb01cally NFL players, kneeled during the singing of theU.S. national anthem to protest police brutality and racialinequality in the U.S. These protests begin in 2016, butbecame widespread in late 2017 as U.S. President DonaldTrump called for NFL team owners to \ufb01re any player whokneeled. This event caused a debate of whether NFL play-ers were being disrespectful to the U.S. \ufb02ag and military.Hence, two sides of the story emerged: race inequality anddisrespecting the military. A similar two-sided story is thedismissal of James Comey. James Comey was the 7th di-rector of the Federal Bureau of Investigation (FBI), whowas dismissed by U.S. President Donald Trump in May2017. This dismissal came at a controversial time, as Pres-ident Trump\u2019s administration was under FBI investigationfor alleged Russian interference in the 2016 election. Atthe same time, James Comey had been widely criticized forthe way he handled the earlier Hilary Clinton email contro-versy\n7. The Trump administration publicly stated Comey\u2019s\ndismissal was due to the recommendation by then AttorneyGeneral Jeff Sessions and Comey\u2019s handling of the earlieremail investigation. The media created a divide between thetwo sides: did President Trump dismiss Comey due to theRussia investigation or due to the Clinton email investiga-tion. Therefore, in both of these events there are clear sidesthat news sources may or may not give fair coverage.\nTo do this analysis, we \ufb01rst select the dates of each event\nand extract all articles from several days before and afterthe event. With these articles extracted, we \ufb01lter by a setof event keywords and manually ensure all articles extractedare reporting the appropriate event. We then modify a simpleslant score technique used in (Lin, Bagrow, and Lazer 2011)to quantify the narrative slant. In (Lin, Bagrow, and Lazer2011), the slant score is measured by the log-odds-ratio ofthe number of times source irefers to party k(speci\ufb01cally\nrefers to a member of said party), where the baseline proba-bility is 50% (meaning an article has a 50-50 chance to refer\nto each party). We perform a similar analysis, but instead of\ncounting party references, we count narrative keyword ref-erences. These narrative keywords are manually generated.While there are more sophisticated methods to measure bias,this method provides a base understanding of coverage biaswithin these stories.\nU.S. national anthem protests. For the U.S. national an-\nthem protests, we use the following keywords for side 1:Kaepernick, racism, race, racist, police, brutality, African\nAmerican, and prejudice , and the following for side 2:\nrespect, stand, disrespect, \ufb02ag, troops, military , and anti-\nAmerican .\nIn Figure 5a, we show a scatter plot in which each point\nrepresents a source and the x-axis shows the computed slant\nscore. If a source reported both sides equally, it receives a\nslant score of 0 (indicated by the vertical dotted line). In thiscase, the higher the score the more coverage of side 1 (police\n5en.wikipedia.org/wiki/U.S. national anthem protests\n6en.wikipedia.org/wiki/Dismissal ofJames Comey\n7en.wikipedia.org/wiki/Hillary Clinton email controversy\n525\n(a) NFL Protests (Sept 20th 2017 to Sept Sept 30th 2017) (b) Comey Firing (May 10th 2017 to May 15th 2017)\nFigure 5: Issue slant score computed using the log-odds-ratio of narrative keywords. Each dot in the scatter plot represents a\nsource, the x-axis the slant score, and the y-axis is the overall number of references or a feature from the NELA2017 feature set.A score of 0 indicated by the vertical line is perfectly balanced coverage. In (a) sources with higher scores report more aboutwhat the players are protesting (police brutality) than the disrespect for the \ufb02ag and military (lower score is vice-versa). In (b)sources with higher scores report more about the Russia collusion than the Clinton email scandal (lower score is vice-versa).\nbrutality) and the lower the score the more coverage of side\n2 (disrespect of \ufb02ag). On the y-axis we show the either thenumber of keyword references overall or a feature selectedfrom the NELA2017 feature set.\nWe can see right away that there are sources across the\nspectrum of coverage slant; however, more so on side 1 (po-lice brutality). Despite more sources covering side 1, we seemore extreme slant (further from balanced) for side 2 (disre-spect of \ufb02ag), meaning they mention keywords correspond-ing to side 2 much more than side 1. When inspecting thesources with this extreme slant, we see several cases wherethere was no mention of side 1. Whereas even the most ex-treme slant towards side 2 mentions the debate of respecting\nthe \ufb02ag. Of those sources that only report the disrespecting\nof the \ufb02ag narrative, we see they are more subjective in writ-ing and slightly more negative than those sources who arenear balanced. On the other side, those who report more ofthe police brutality message use the 1st person plural wordsmore (like we, us, or our).\nDismissal of James Comey For the dismissal of James\nComey, we use the following keywords for side 1: Rus-\nsia, Trump-Russia, collusion, election , and meddling , and\nthe following for side 2: Hilary, Clinton, Democrats, dems,\nemail , and server . In Figure 5b, we show the same for scatter\nplots as in Figure 5a discussed above. In this case, the higherthe score the more coverage of side 1 (Russia) and the lowerthe score the more coverage of side 2 (Clinton emails).\nIn this story, we can see the vast majority of sources give\nbalanced coverage, receiving slant scores close to 0. In fact,\nthere is only 1 source that reported the event extremely one\nsided. When inspecting this source, they did not mentionanything about the Russia investigation, only the Clintonemail scandal. This one extreme source was much more neg-\native, more subjective, and used 1st person plurals more thanthe other sources.\nConclusions\nIn this paper, we presented the NELA2017 data set, whichcontains articles from 92 news sources over 7 months, aswell as, 130 content-based features that have been usedthroughout the news literature. Together with the data set,\nwe include the source code for computing the features (go\no.gl/JsxGt). We also illustrated potential research directionswith a number of use cases, showing the data set\u2019s use instudying individual sources, compare sources to each other,or study sources over a speci\ufb01c event. We are continuing toexpand and collect data for future releases. As we update, wewill release the data set by versions, thus, NELA2017 willbe an unchanged version corresponding to the meta data inthis paper. All data can be requested at nelatoolkit.science.\nReferences\nAn, J.; Aldarbesti, H.; and Kwak, H. 2017. Convergence ofmedia attention across 129 countries. In Intl. Conf. on Social\nInformatics , 159\u2013168. Springer.\nBessi, A.; Coletto, M.; Davidescu, G. A.; Scala, A.; Cal-\ndarelli, G.; and Quattrociocchi, W. 2015. Science vs Con-\nspiracy: Collective Narratives in the Age of Misinformation.\nPLoS ONE 10(2):e0118093\u201317.\nBuntain, C., and Golbeck, J. 2017. Automatically identify-\ning fake news in popular twitter threads. In 2017 IEEE Intl.\nConference on Smart Cloud , 208\u2013215. IEEE.\n526\nChakraborty, A.; Paranjape, B.; Kakarla, S.; and Ganguly,\nN. 2016. Stop clickbait: Detecting and preventing clickbaitsin online news media. In ASONAM , 9\u201316. IEEE.\nEntman, R. M. 2007. Framing bias: Media in the distribution\nof power. Journal of communication 57(1):163\u2013173.\nGraham, J.; Haidt, J.; and Nosek, B. A. 2009. Liberals and\nconservatives rely on different sets of moral foundations.Journal of personality and social psychology 96(5):1029.\nHorne, B. D.; Adali, S.; and Sikdar, S. 2017. Identifying\nthe social signals that drive online discussions: A case studyof reddit communities. In Computer Communication and\nNetworks (ICCCN), 2017 26th International Conference on ,\n1\u20139. IEEE.\nHorne, B. D., and Adal\u0131, S. 2017. This just in: Fake news\npacks a lot in title, uses simpler, repetitive content in text\nbody, more similar to satire than real news. In ICWSM\nNECO Workshop .\nHorne, B. D.; Dron, W.; Khedr, S.; and Adali, S. 2018. As-\nsessing the news landscape: A multi-module toolkit for eval-uating the credibility of news. In WWW Companion .\nHutto, C. J., and Gilbert, E. 2014. V ader: A parsimonious\nrule-based model for sentiment analysis of social media text.InICWSM .\nKwak, H., and An, J. 2016. Revealing the hidden patterns\nof news photos: Analysis of millions of news photos throughgdelt and deep learning-based vision apis. In ICWSM .\nLin, Y .-R.; Bagrow, J. P .; and Lazer, D. 2011. More voices\nthan ever? quantifying media bias in networks. ICWSM\n1(arXiv: 1111.1227):1.\nLin, Y .; Hoover, J.; Dehghani, M.; Mooijman, M.; and Ji, H.\n2017. Acquiring background knowledge to improve moralvalue prediction. arXiv preprint arXiv:1709.05467 .\nLoper, E., and Bird, S. 2002. Nltk: The natural language\ntoolkit. In ACL-02 Workshop on Effective tools and method-\nologies for teaching natural language processing and com-putational linguistics , 63\u201370.\nLytvynenko, J. 2017. Infowars has republished more\nthan 1,000 articles from rt without permission. Avail-able at \u201cwww.buzzfeed.com/janelytvynenko/infowars-is-running-rt-content\u201d.\nMele, N.; Lazer, D.; Baum, M.; Grinberg, N.; Friedland, L.;\nJoseph, K.; Hobbs, W.; and Mattsson, C. 2017. Combatingfake news: An agenda for research and action.\nMitchell, L.; Frank, M. R.; Harris, K. D.; Dodds, P . S.; and\nDanforth, C. M. 2013. The geography of happiness: Con-necting twitter sentiment and expression, demographics, andobjective characteristics of place. PloS one 8(5):e64417.\nMitra, T., and Gilbert, E. 2015. Credbank: A large-scale\nsocial media corpus with associated credibility annotations.\nInICWSM , 258\u2013267.\nMukherjee, S., and Weikum, G. 2015. Leveraging joint\ninteractions for credibility analysis in news communities. InCIKM , 353\u2013362. ACM.\nPan, Z., and Kosicki, G. M. 1993. Framing analysis:An approach to news discourse. Political communication\n10(1):55\u201375.\nPang, B., and Lee, L. 2004. A sentimental education: Sen-\ntiment analysis using subjectivity summarization based onminimum cuts. In ACL , 271.\nPiotrkowicz, A.; Dimitrova, V .; Otterbacher, J.; and Mark-\nert, K. 2017. Headlines matter: Using headlines to predictthe popularity of news articles on twitter and facebook. InICWSM , 656\u2013659.\nPopat, K.; Mukherjee, S.; Str \u00a8otgen, J.; and Weikum, G.\n2016. Credibility assessment of textual claims on the web.InCIKM , 2173\u20132178. ACM.\nPotthast, M.; Kiesel, J.; Reinartz, K.; Bevendorff, J.; and\nStein, B. 2017. A stylometric inquiry into hyperpartisanand fake news. arXiv preprint arXiv:1702.05638 .\nQian, M., and Zhai, C. 2014. Unsupervised feature selection\nfor multi-view clustering on text-image web news data. InCIKM , 1963\u20131966. ACM.\nRecasens, M.; Danescu-Niculescu-Mizil, C.; and Jurafsky,\nD. 2013. Linguistic models for analyzing and detectingbiased language. In ACL (1) , 1650\u20131659.\nReis, J.; Benevenuto, F.; de Melo, P . V .; Prates, R.; Kwak,\nH.; and An, J. 2015. Breaking the news: First impressionsmatter on online news. In ICWSM .\nSaez-Trumper, D.; Castillo, C.; and Lalmas, M. 2013. So-\ncial media news communities: gatekeeping, coverage, and\nstatement bias. In CIKM , 1679\u20131684. ACM.\nShao, C.; Ciampaglia, G. L.; Flammini, A.; and Menczer, F.\n2016. Hoaxy: A platform for tracking online misinforma-tion. In WWW 2016 , 745\u2013750.\nSinghania, S.; Fernandez, N.; and Rao, S. 2017. 3han: A\ndeep neural network for fake news detection. In Interna-\ntional Conference on Neural Information Processing , 572\u2013\n581. Springer.\nStarbird, K. 2017. Examining the alternative media ecosys-\ntem through the production of alternative narratives of mass\nshooting events on twitter. In ICWSM , 230\u2013239.\nWang, W. Y . 2017. \u201d liar, liar pants on \ufb01re\u201d: A new\nbenchmark dataset for fake news detection. arXiv preprint\narXiv:1705.00648 .\nWihbey, J.; Coleman, T. D.; Joseph, K.; and Lazer, D. 2017.\nExploring the ideological nature of journalists\u2019 social net-works on twitter and associations with news story content.arXiv preprint arXiv:1708.06727 .\nZubiaga, A.; Liakata, M.; Procter, R.; Hoi, G. W. S.; and\nTolmie, P . 2016. Analysing how people orient to andspread rumours in social media by looking at conversationalthreads. PloS one 11(3):e0150989.\n527", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Sampling the news producers: A large news and feature data set for the study of the complex media landscape", "author": ["B Horne", "S Khedr", "S Adali"], "pub_year": "2018", "venue": "\u2026 of the International AAAI Conference on \u2026", "abstract": "The complexity and diversity of today's media landscape provides many challenges for  researchers studying news producers. These producers use many different strategies to get"}, "filled": false, "gsrank": 145, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/14982", "author_id": ["T47ya5QAAAAJ", "", "Jk3gxBEAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:J61978swL-wJ:scholar.google.com/&output=cite&scirp=144&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=J61978swL-wJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 127, "citedby_url": "/scholar?cites=17018875169310879015&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:J61978swL-wJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/14982/14832"}}, {"title": "Search bias quantification: investigating political bias in social media and web search", "year": "2019", "pdf_data": "Vol:.(1234567890)Information Retrieval Journal (2019) 22:188\u2013227\nhttps://doi.org/10.1007/s10791-018-9341-2\n1 3\nSOCIAL MEDIA FOR\u00a0PERSONALIZATION AND\u00a0SEARCH\nSearch bias quantification: investigating political bias \nin\u00a0social media and\u00a0web search\nJuhi\u00a0Kulshrestha1,2 \u00a0\u00b7 Motahhare\u00a0Eslami3\u00a0\u00b7 Johnnatan\u00a0Messias1\u00a0\u00b7 \nMuhammad\u00a0Bilal\u00a0Zafar1\u00a0\u00b7 Saptarshi\u00a0Ghosh4\u00a0\u00b7 Krishna\u00a0P .\u00a0Gummadi1\u00a0\u00b7 Karrie\u00a0Karahalios3\nReceived: 12 November 2017 / Accepted: 3 August 2018 / Published online: 21 August 2018 \n\u00a9 The Author(s) 2018\nAbstract\nUsers frequently use search systems on the Web as well as online social media to learn \nabout ongoing events and public opinion on personalities. Prior studies have shown that \nthe top-ranked results returned by these search engines can shape user opinion about the \ntopic (e.g., event or person) being searched. In case of polarizing topics like politics, where \nmultiple competing perspectives exist, the political bias in the top search results can play \na significant role in shaping public opinion towards (or away from) certain perspectives. \nGiven the considerable impact that search bias can have on the user, we propose a gener -\nalizable search bias quantification framework that not only measures the political bias in \nranked list output by the search system but also decouples the bias introduced by the differ -\nent sources\u2014input data and ranking system. We apply our framework to study the political \nbias in searches related to 2016 US Presidential primaries in Twitter social media search \nand find that both input data and ranking system matter in determining the final search out -\nput bias seen by the users. And finally, we use the framework to compare the relative bias \nfor two popular search systems\u2014Twitter social media search and Google web search\u2014\nfor queries related to politicians and political events. We end by discussing some potential \nsolutions to signal the bias in the search results to make the users more aware of them.\nKeywords  Search bias\u00a0\u00b7 Search bias quantification\u00a0\u00b7 Sources of search bias\u00a0\u00b7 Social media \nsearch\u00a0\u00b7 Web search\u00a0\u00b7 Political bias inference\nThis work is an extended version of the paper: Kulshrestha et\u00a0al., Quantifying Search Bias: \nInvestigating Sources of Bias for Political Searches in Social Media, ACM Conference on Computer \nSupported Cooperative Work and Social Computing (CSCW \u201917), ACM, New York, NY, USA, \n417\u2013432. https  ://doi.org/10.1145/29981  81.29983  21.\n * Juhi Kulshrestha \n juhi@mpi -sws.org\n1 Max Planck Institute for\u00a0Software Systems (MPI-SWS), Saarbr\u00fccken, Germany\n2 GESIS - Leibniz Institute for\u00a0the\u00a0Social Sciences, Mannheim, Germany\n3 University of\u00a0Illinois at\u00a0Urbana-Champaign, Champaign, USA\n4 Indian Institute of\u00a0Technology Kharagpur, Kharagpur, India\n189 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n1 Introduction\nAlgorithmic systems have become ubiquitous in our modern lives, and they exert great \ninfluence on many aspects of our daily lives, including shaping news and information we \nare exposed to via information retrieval algorithms. An important class of such retrieval \nalgorithms is search systems. We all rely on search for a wide variety of goals in our day-to-day lives\u2014ranging from finding specific website or content (navigational que-\nries) to learning more broadly about entities, people, topics or events (informational que-\nries)\u00a0(Welch et\u00a0al. 2011). For instance, during election season, people are known to make \nrepeated queries about political candidates and events (e.g., \u201cdemocratic debate\u201d, \u201cDonald \nTrump\u201d, \u201cclimate change\u201d) on the Web, as well as on social media sites like Facebook and Twitter (http://tinyu rl.com/Offic ialGo ogleB log; Teevan et\u00a0 al. 2011) to learn more about \ntheir queried terms.\nWhile the goal of informational search queries is to provide users with greater knowl-\nedge about a topic, this knowledge is not necessarily always impartial. When a query is issued to a search system, a set of relevant items for the query are first extracted from the \nwhole corpus of data items (e.g., web links or social media posts). This set of relevant \nitems for the query are in turn fed to the ranking system which returns a ranked list of \nsearch results to the user who made the query. For polarizing topics like politics, many of these returned results can be biased towards one political perspective or the other, therefore \nby ranking items from one perspective higher than the other the ranking system could (pos-\nsibly inadvertently) return a list of politically biased search results to the user. This bias in the search results could be introduced because of biased data that forms the input to the \nranking system, or because of the ranking system itself.\nThe potential biases that search systems can introduce and users\u2019 unquestionable trust in \nsearch results have lead to growing concerns about search systems\u2019 impact on the behavior of users, especially in scenarios where they may potentially misinform or mislead the users. \nPrior field studies have shown that not only do the users place greater trust in highly ranked \nsearch results\u00a0(Pan et\u00a0al. 2007), but the opinions of undecided voters can be manipulated \nby biasing the search results about political candidates\u00a0(Epstein and Robertson 2015). In \nsuch polarizing scenarios, where multiple different perspectives about the searched topic \nexist (e.g., political candidates or events), the bias in the top search results can influence \nthe user\u2019s opinion and shape public opinion towards (or away from) certain competing per -\nspectives. However, such biases of search systems are challenging to detect and quantify, \nsince multiple sources of bias exist (e.g., input data and ranking system) whose effects are \nhard to disentangle.\nIn this paper, we tackle this challenge by proposing a novel generalizable search bias \nquantification framework. This framework not only captures the bias in the search results output by a search system but is also capable of decoupling this output bias into different \ncomponents to identify the sources of bias\u2014the input data or the ranking system. For our \nchosen context of 2016 US Presidential primaries, we first apply our search bias quantifica-tion framework to political searches on social media (Twitter) to quantify and investigate \nits sources of political bias, and then we use our framework to quantify and compare rela-\ntive bias for political searches on social media search (Twitter) and Web search (Google).\nTo apply our framework to study the sources of bias in political searches on Twitter \nsocial media, we first needed a methodology to measure the political bias of an indi-vidual search result, i.e., a tweet. We operationalized the political bias of a tweet as its \nsource bias, i.e., the political bias of the author of the tweet, and developed a highly \n190 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nscalable and accurate author based crowdsourced methodology for inferring the politi-\ncal bias of a Twitter user. We then utilized these inferred biases of tweets to quantify \nthe sources of bias for Twitter search. Not only could we observe the search results \noutput by the ranking system of Twitter search, but we were also able to gather the tweets containing a query which form the input to the ranking system. Armed with this \ndata, we were able to disentangle the bias of different sources of bias for Twitter search, \nusing our bias quantification framework. In our analyses of Twitter search results, we \nshow that the bias in the search results does not only originate from the ranking system, \nbut the bias of the input data (that is input to the ranking system) is also a significant contributor to the overall search bias. Moreover, we observe that the top Twitter search \nresults display varying degrees of political bias that depends on several aspects, such \nas the topic (event/person) being searched for, the exact phrasing of the query (even for semantically similar queries), and also the time at which the query is issued.\nAfter quantifying the bias in social media search, we proceed to use our quantifica-\ntion framework to compare the relative bias for political searches on two popular search \nsystems - Twitter social media search and Google Web search. Our motivation for per -\nforming this comparison is to make the biases of different channels more visible and \naccessible to the users. Traditional media channels like Fox News or CNN have often \nbeen scrutinized by academics\u00a0 (Ribeiro et\u00a0 al. 2015; Babaei et\u00a0 al. 2018; Budak et\u00a0 al. \n2016; Gentzkow and Shapiro 2010; Groseclose and Milyo 2005; Baron 2006; Mun-son et\u00a0al. 2013b) as well as media watchdog groups (like FAIR (fair.org) and AIM \n(aim.org)) for fairness, accuracy and balance in the news they report. Additionally, \ntools have also been developed to mitigate or expose the media bias\u00a0(Purple Feed 2018; \nPark et\u00a0al. 2009; Munson et\u00a0al. 2013b; https ://twitt er-app.mpi-sws.org/media -bias-monit  \nor/; https ://media biasf  actch eck.com) to users. However, the relative biases of newer dig-\nital algorithmic channels like search systems are not as well studied and documented as \nyet, and thus users may not be taking their relative biases into account while selecting \nthe channel to get their information from. In fact, many users believe that these algorith-mically curated channels (as opposed to human editorial curation) are powerful, infalli-\nble and thus unbiased\u00a0(Eslami et\u00a0al. 2016; Springer et\u00a0al. 2017), which is far from being \ntrue. This lack of awareness can results in \u201cblind faith\u201d in search systems\u00a0(Pan et\u00a0al. \n2007), and impairs the users from making an informed choice of which search channel \nto use. With this study, we aim to highlight the differences in the political bias of these \ntwo popular search systems\u2014Twitter social media search and Google Web search\u2014and \nmake their relative bias more visible.\nOur comparison of relative bias of the two search systems reveals that the bias for \npolitical candidates is much more favorable to the candidates on Web search than on social media search. This difference is mainly due to multiple neutral or supportive \n(candidate-controlled) web-links (for instance candidate\u2019s homepage or their social media profile links) that get included in the top results on Web search. We also observed \nthat the bias in Web search results is less dynamic over time as compared to bias in \nsocial media search. Our findings show that search systems exhibit not only political bias in their search results but also different search systems exhibit different biases. It \nis important to highlight these differences in political bias of varying search systems, \nsince the users currently may not be taking these biases into account when choosing one \nsearch system over the other to get information from.\nOur research contributions in this work can be summarized as follows:\n191 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n1. We propose a novel generalizable search bias quantification framework to measure \nnot only the bias in the search output but also to discern the contribution of different \nsources\u2014input data or ranking system (Sect.\u00a0 3).\n2. We apply the framework to investigate the sources of bias in political searches on Twitter \nsocial media search where we show that both input data and ranking system contribute \nto the final output bias seen by the users. We also observe that the bias varies with the \ntopic being searched for, the exact phrasing of the query and the time at which the query \nis made. (Sect.\u00a0 4).\n3. We also utilize our framework to compare the relative bias for political queries on \ntwo popular search systems: Twitter social media search and Google Web search. As \ncompared to social media search, we find that the political bias on Web search is a lot \nless dynamic, more favorable for the candidate queries, and has a higher fraction of top search results containing links to candidate-controlled sources, such as links to their \nwebsite or social media profiles (Sect.\u00a0 5).\nFinally, a version of the present work has been published earlier at a confer -\nence\u00a0(Kulshrestha et\u00a0al. 2017). This paper extends and improves upon the earlier paper in \nthe following manner: (i) We have strengthened the evaluation of bias inference for tweets by including a comparison of our source based scheme with a content based scheme in \nSect.\u00a0 4.3. Our results indicate that our bias inferred using our source based scheme has a \nhigher (70% or more) match with the bias of the tweets (using human annotations), and \nperforms better than content based schemes. (ii) We also included new results on the tem-\nporal variation of bias for political queries on Twitter social media search in Sect.\u00a0 4.4.3. \n(iii) And finally, we have applied our bias quantification framework to study the relative bias of two popular search systems\u2014Twitter social media search and Google web search. \nWe report our findings about the comparison in Sect.\u00a05.\nOur work is aimed towards making social media users aware of the potential political \nbiases of social media search and how it compare with the bias in web search and encour -\naging the development of novel information retrieval systems and mechanisms for pre-senting search results which could represent multiple competing perspectives on the same \nevent or person.\n2  Background\nToday, algorithms that curate and present information on online platforms can affect users\u2019 \nexperiences significantly. While powerful, these algorithms are not without flaws. Algo-\nrithms have been shown to create discriminatory ads based on gender (Datta et\u00a0al. 2015) \nor race (Sweeney 2013), to show different prices for the same products/service to different users (Hannak et\u00a0al. 2014), to skew users\u2019 ratings to benefit low-rated hotels (Eslami et\u00a0al. \n2017) and to mistakenly label a black man as an ape (Hern 2015). These issues have lead \nresearchers, organizations and even governments towards a new avenue of research called \n\u201cauditing algorithms\u201d, which endeavors to understand if and how an algorithmic system \ncan cause biases, particularly when they are misleading or discriminatory to users (Sandvig \net\u00a0al. 2014; Executive Office of the President 2016).\nSearch engines are an important set of algorithms that users interact with on daily basis \nand these algorithms\u2019 susceptibility to bias has resulted in several audit studies in recent years. These audits cover a wide range of search platforms including Web search and social \n192 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nmedia search. Next, we give an overview of prior work on examining the bias for search \nplatforms, and discuss how our work adds to this line of existing research.\n2.1  Bias in\u00a0web search\nIn recent years, Web search engines and their potential biases have received a lot of scru-tiny\u00a0 (Tavani 2014; Van\u00a0 Couvering 2010; Fortunato et\u00a0 al. 2006; Vaughan and Thelwall \n2004; Mowshowitz and Kawaguchi 2005). This scrutiny has typically stemmed from the concern that dominant search engines like Google might favor certain websites over others when ranking relevant search results. For example, some argue that Google manipulates its \nsearch results to rank it\u2019s services (such as Google Health links) higher than other compet-\ning services\u00a0(Edelman 2010). In another example, Vaughan and Thelwall (2004) examined \nthe geographical bias in Web search and observed that sites from certain countries like the \nUS are covered more than sites from other countries.\nSeveral studies have focused on the political bias of Web search results and queries dur -\ning recent years. Weber et\u00a0al. (2012) investigated the political leanings of search queries by linking the queries to political blogs. In another line of research, researchers conducted field studies to examine the influence of political bias seen in search results on users\u2019 vot-\ning decisions. For instance, Epstein and Robertson found that by manipulating the political \nbias in top search results they could impact the voting preferences of undecided voters by \n20% or more\u00a0(Epstein and Robertson 2015) and they termed this phenomenon as search \nengine manipulation effect. As a continuation of this line of research, Epstein et\u00a0al. have \nshown that modifying the design of search engines to include alerts about the bias in the \nsearch results shown to the users can mitigate the aforementioned search engine manipula-tion effect significantly\u00a0(Epstein et\u00a0al. 2017a). Motivated by these findings, in this paper, \nwe propose a generalizable search bias quantification framework and apply it to investigate \nthe sources of bias in social media search as well as apply it to compare relative biases of \nsocial media and web search.\nPersonalization in Web Search: A complementary line of work has focussed on the per -\nsonalization effects and studied the differences in the results seen by different users for the same query due to personalization. Various factors including geo-location of users has \nbeen found to lead to personalization of search results (Hannak et\u00a0al. 2013; Kliman-Silver et\u00a0al. 2015). On the other hand, in another study\u00a0(Koutra et\u00a0al. 2015) it was shown that dur -\ning disruptive events such as shootings, the users tend to changes their information-seeking behavior and use the search engines to seek information that they agree with. In contrast, \nwe study the bias in consistent, non-personalized search results for political queries shown \nto all users on social media search and the web search and we find that biases exist even for such non-personalized results. Addition of personalization is likely to add another source \nof bias for these search results and this is a potential direction of future research.\n2.2  Bias in\u00a0social media\nWith more and more users relying on social media platforms like Twitter and Facebook \nto receive news\u00a0(Lichterman 2010) and information about on-going events and public fig-\nures\u00a0(Teevan et\u00a0al. 2011), there has been a debate about the impact these platforms are hav -\ning on the news that users are consuming. While some have envisioned increased democ-\nratization with users from different political ideologies engaging with each other\u00a0(Semaan \n193 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\net\u00a0al. 2014), others warned that use of social media platforms could encourage selective \nexposure by reinforcing users\u2019 existing biases\u00a0(Liu and Weber 2014).\nFurther inspection of cross-ideological exposure\u00a0(Himelboim et\u00a0al. 2013) revealed that \npolitical discourse on Twitter is highly partisan and users are unlikely to get exposed to \ncross-cutting content via their social neighborhood. These results have been reinforced by \nstudies showing that not only are social media users more willing to communicate with \nother like-minded users\u00a0(Liu and Weber 2014; Smith et\u00a0al. 2013), they are also unable to \nengage in meaningful discussions with users with different beliefs than their own\u00a0(Yardi and Boyd 2010). Therefore, political polarization on social media platforms has been an active area of research, with multiple different studies analyzing the behaviors of ideologi-\ncally different groups of users. It has been shown that the retweeting network is highly \npartisan with users typically only retweeting other users who share their political ideol-ogy\u00a0(Conover et\u00a0al. 2011b).\nConsiderable research effort has also been dedicated to studying controversies and con-\ntroversial topics online\u00a0(Coletto et\u00a0al. 2017; Garimella et\u00a0al. 2016; Lu et\u00a0al. 2015). Gari-\nmella et\u00a0al. (2016) have proposed a method for quantifying controversy on social media \nusing social media network and content. While BiasWatch is a system to discover and track bias themes from opposing sides of a topic in a semi-supervised manner\u00a0(Lu et\u00a0al. 2015).\nWhile these studies give evidence of polarized and controversial content generation as \nwell as sharing on social media platforms, it is unclear how this data impacts automated retrieval systems like search systems and the bias in their results. In this paper, we pro-\npose a search bias quantification framework which not only quantifies the bias in the output \nranked list shown to the users, but it also discerns to what extent is this bias due to the ranking system of the search system, or the input data to the ranking system. We then apply \nthis framework to study political bias in social media and web search.\n2.3  Measuring political bias on\u00a0social media and\u00a0the\u00a0web\nThe first step in quantifying the bias for political searches on social media and web search \nis measuring the political bias of an individual result (i.e., a tweet or a weblink). There \nhave been some attempts to infer the political bias of blogs and news stories\u00a0(Adamic and \nGlance 2005; Yano et\u00a0al. 2010; Zhou et\u00a0al. 2011) as well as hashtags on Twitter\u00a0(Weber \net\u00a0al. 2013). However, there has been limited work on inferring the bias of content of short \nsocial media posts like tweets. Instead, researchers have inferred the bias of the users post-ing tweets by modeling how different polarity users use language\u00a0 (Purver and Karolina \n2015; Makazhanov and Rafiei 2013; Fang et\u00a0al. 2015), or by leveraging the linking behav -\nior of users (Golbeck and Hansen 2011; Conover et\u00a0al. 2011a, b), or by leveraging both \ntextual and network features for political leaning classification\u00a0 (Pennacchiotti and Pope-scu 2011). Zafar et\u00a0 al. (2016), have quantified the impartiality of social media posts by \nmeasuring how easy it is to guess the political leaning of its author. Bond and Messing \n(2015) inferred the political leanings of Facebook users by observing the endorsements of \nFacebook Pages of known politicians, while Wong et\u00a0al. (2016) measure the endorsements \nin terms of retweeting behavior of users to infer their political leanings. Cohen and Ruths \n(2013) used supervised methods to classify users into different groups of political activities \nand showed that it is hard to infer the political leaning of \u201cnormal\u201d users. Most of these \nprior studies make the assumption that the leaning of the user is explicit in their language, \nsocial connections or endorsements, however this may not always be true. We build upon these prior studies to propose a methodology for inferring the bias of a Twitter user by \n194 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nleveraging their interests, which are correlated to their political affiliation. And we use this \nproposed methodology to quantify the bias for political searches on Twitter social media \nand show that the method can be used to infer the political leaning of users with varied \nlevels of political activities.\nA number of prior studies have investigated political bias in traditional news \nmedia\u00a0(Budak et\u00a0al. 2016; Gentzkow and Shapiro 2010; Groseclose and Milyo 2005; Mun-son et\u00a0 al. 2013b). Budak et\u00a0 al. (2016) combined machine-learning and crowdsourcing techniques to study the selection and framing of political issues by news organizations. As \nonline news sources have gained popularity, such studies have also been extended to them, \nas in the case of the Balance study (Munson et\u00a0 al. 2013b), which assigns political bias scores to many of the popular news websites based on the political leanings of the web-\nsites, blogs and Digg users that link to or vote for the news website. We utilize this prior \nwork\u00a0(Munson et\u00a0al. 2013b) to quantify the bias of news search results on Twitter and the Web for comparing the relative biases of these two search systems.\n3  Search bias quantification framework\nThe first research question we focus on pertains to quantifying the bias of a search system. In this work, we quantify the bias for political searches on Twitter social media search and \nGoogle web search, in the context of the US political scenario, which has two primary \npolitical parties: the Democratic party and the Republican party. In this section, we pro-pose a bias quantification framework which captures the bias introduced at different stages \nof a search process, including metrics which measure the bias at each stage.\nFigure\u00a0 1 gives a high-level overview of the different stages of information retrieval via \nan algorithmic search system. The search system retrieves information from a corpus of \ndata, where each individual data item (e.g., \ni1 , i2 ) has an associated bias score (e.g., s1 , \ns2 ). In the later sections (Sects.\u00a0 4 and\u00a0 5), we describe methodologies for computing the \nbias score for political searches on Twitter social media and Google web search platforms. \nWhen a user makes a query q, a set of data items relevant to the query is first selected out {i1(s1),\ni2(s2),\ni3(s3),\ni4(s4),\ni5(s5)}\n(set)\nInput\n(Relev antitems )Ranking\nSystemi2(s2),\ni4(s4),\ni5(s5),\ni1(s1),\ni3(s3)\n(rank edlist)\nOutput\n(Rank editem s)\nFig. 1  Overview of our search bias quantification framework. For a given query q, a set of data items \nrelevant to the query is first selected. Each individual data item (e.g., i1 , i2 ) has an associated bias score \n(e.g., s1 , s2 ). These set of relevant items is input to the ranking system which produces a ranked list of the \nitems. Our framework includes metrics for measuring the bias in the set of relevant items input to the rank -\ning system (input bias), and the bias in the ranked list output by the ranking system (output bias)\n195 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nof the whole corpus. Then, this set of retrieved relevant items forms the input data to the \nranking system which produces a ranked list of the relevant items, which is shown as the \nsearch output to the users. The framework can also be generalized to modern-day IR sys-\ntems which perform retrieval and ranking together, such as systems using topic modeling. We comment on this issue in Sect.\u00a08.\nWithin our framework, we define three different components of the bias of a search \nsystem, each of which is quantified in terms of the biases of the individual data items: \n(i)\u00a0input bias: the bias in the set of retrieved items relevant to the query that are filtered \nout of the whole corpus. This set of retrieved items serve as the input data to the ranking \nsystem, (ii)\u00a0 ranking bias: the bias introduced by the ranking system, and (iii)\u00a0 output bias: \nthe cumulative bias in the ranked list output by the search system and shown to the users. In the rest of the section, we discuss the metrics we proposed to quantify these different components of bias of a search system.\n3.1  Bias score of\u00a0an\u00a0individual data item\nWe are interested in quantifying the search bias for political queries in the context of US politics. Since there are two primary political parties in the US, each data item (e.g., a tweet \nor a web-link) can be positively biased (i.e., supportive), negatively biased (i.e., opposing), \nor neutral towards each of the parties. Therefore the bias score of each item must capture the extent to which it is biased with respect to the two parties.\nTo apply our bias quantification framework in the context of political searches on a \nsearch platform, we need a methodology for inferring the bias scores for each data item \n(indicated by \nsi in Fig.\u00a0 1). Later in the paper, we present methodologies for measuring the \nbias scores of individual items for our chosen scenario of political searches on Twitter social media (Sect.\u00a04) and Google Web search platforms (Sect.\u00a05).\nNext, we use these bias scores of individual data items to define the metrics for the input \nbias, output bias, and ranking bias.\n3.2  Input bias\nOnce a user issues a query, the search system retrieves a set of items from the whole corpus \nthat are relevant to the query and provides them as an input to the ranking system. Since \nthis input data captures the bias introduced due to the filtering of the relevant items from \nthe data corpus according to the issued query, we measure the input bias for a query as the aggregate bias of all the items relevant to the query in this input data set. In other words, \ninput bias gives a measure of the bias a user would observe if they were shown random \nitems relevant to the query, instead of the output list ranked by the ranking system.\nSpecifically, the Input Bias IB(q) for query q is the average bias of the n data items that \nare relevant to q\nwhere the summation is over all the bias scores ( \nsi ) of the n data items found rel-\nevant to q. For instance, for the query q shown in Fig.\u00a0 1, the input bias is \nIB(q)=1\n5(s1+s2+s3+s4+s5).(1) IB(q)=\u2211n\ni=1si\nn\n196 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n3.3  Output bias\nThe output bias of a search system is the cumulative bias in the final ranked list of search \nresults presented to the user who issued the search query. Prior studies have shown that not \nonly are the users more likely to browse the top search results\u00a0(Manning et\u00a0al. 2008), but \nthey also tend to put more trust in them\u00a0(Pan et\u00a0al. 2007). Therefore, we propose an output bias metric inspired from the well-known metric\u2014mean average precision\u00a0(Manning et\u00a0al. \n2008)\u2014which gives more importance to higher ranked search results.\nFor a given search query q, we first define the bias till a particular rank r in the ranked \nresults (i.e., the aggregate bias of the top r results). The bias B(q,\u00a0 r) till rank r of the output \nranked list is defined as\nwhere the summation is over the top r items in the ranked list.\nAs an example, the first five rows in Table\u00a0 1 depict the bias till ranks \n1, 2,\u2026,5 , for the \nsample search scenario shown in Fig.\u00a01.\nThe Output Bias OB(q,\u00a0 r) for the query q at rank r is then defined by extending the \nabove definition as follows,\nThe last row of Table\u00a0 1 depicts OB(q,\u00a0 r) at rank r=5 with respect to Fig.\u00a0 1. In this for -\nmulation, the bias score s2 of the top-ranked item i2 is given the highest weight, followed \nby the bias score s4 of the second-ranked item i4 , and so on, following the intuition that \nthe bias in the higher ranked items is likely to influence the user more than bias in lower \nranked items.1(2) B(q,r)=\u2211r\ni=1si\nr\n(3) OB(q,r)=\u2211r\ni=1B(q,i)\nrTable 1  Explaining the bias \nmetrics with reference to Fig.\u00a01Rank r Bias till rank r Value\n1 B(q,\u00a01) s2\n2 B(q,\u00a02)1\n2(s2+s4)\n3 B(q,\u00a03)1\n3(s2+s4+s5)\n4 B(q,\u00a04)1\n4(s2+s4+s5+s1)\n5 B(q,\u00a05)1\n5(s2+s4+s5+s1+s3)\nOutput bias at rank 51\n5[s2(1+1\n2+1\n3+1\n4+1\n5)\n+s4(1\n2+1\n3+1\n4+1\n5)\n+s5(1\n3+1\n4+1\n5)\n+s1(1\n4+1\n5)\n+s3(1\n5)]\n1 Similar to how missing relevance judgements are handled in the Information Retrieval literature\u00a0(Yilmaz \nand Aslam 2006), in case there exists an item for which the bias score cannot be computed, we just ignore \nthe item and compute the rankings.\n197 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n3.4  Ranking bias\nIf the internal details of the deployed ranking system were known, then the ranking bias \ncould be measured by auditing the exact features being used for ranking. However, for \nmost of the real-world commercially deployed search engines, the internal details of \nthe ranking system are not known publicly. Therefore, building on previous studies that have adopted a \u201cblack-box\u201d view for an algorithmic system while auditing it (Eslami \net\u00a0al. 2015; Liao et\u00a0al. 2016; Hannak et\u00a0al. 2013, 2014; Chen et\u00a0al. 2015), we treat the \nranking system as a black-box, such that we only observe its inputs and outputs. In such a scenario, the ranking bias captures the additional bias introduced by the ranking sys-\ntem, over the bias that was already present in the input set of relevant items.\nTherefore, we define the Ranking Bias RB( q,\u00a0r) for the query q  as simply the differ -\nence between the output bias and the input bias for q  (as given by Eqs.\u00a01  and\u00a03 ).\n3.5  Time\u2011averaged bias\nTo capture the overall trend in the bias, we collect multiple snapshots of search results, compute the different bias metrics for each snapshot, and then compute the time-aver -\naged values of the aforementioned metrics. For instance we compute the time-averaged output search bias \nTOB (q,r) as the average of the OB( q,\u00a0r) (given by Eq.\u00a0 3) values meas-\nured at various instants of time. Similarly, we define TIB(q)  and TRB(q, r) as the time-\naveraged input bias and time-averaged ranking bias for query q  respectively.\n4  Investigating sources of\u00a0bias for\u00a0political searches on\u00a0social media\nHaving described our search bias quantification framework, we next apply it to political searches on Twitter social media for queries related to 2016 US presidential primaries. \nWith this study, we highlight an important application scenario of our framework, where \nnot only can we observe the search system\u2019s output results, but we also can observe the set of relevant items that form the input to the ranking system.\nWe begin by describing our selected queries and data set for Twitter search \n(Sect.\u00a0 4.1), followed by the methodology we used for measuring the political bias of \nan individual Twitter search result (Sect.\u00a0 4.2), and then we finally present our findings \nabout how biased are the search results for political topics on Twitter and where does this bias in the search results comes from (Sect.\u00a04.4).\n4.1  Collecting Twitter search data\nHere, we describe the queries we considered and the data gathered from Twitter for con-ducting the analyses.(4)\nRB(q, r)=OB(q, r)\u2212IB(q)\n198 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n4.1.1  Selecting search queries\nIn an ideal scenario, for studying the bias in political searches on Twitter, we would use \nthe actual search queries that people are making on the platform for following news and \ninformation related to 2016 US presidential primaries. However, we did not have access \nto this proprietary data about the queries issued on Twitter. In the absence of the actual search queries issued on Twitter, we followed the methodology used in\u00a0 Koutra et\u00a0 al. \n(2015) of first identifying a seed set of queries and then expanding them to identify a \nlarger set of potential queries. Our seed set consists of the queries democratic debate, and republican debate, and their shortened versions (dem debate and rep debate) popu-\nlar on Twitter because of their short lengths.\nWe wanted our expanded set of queries to satisfy two properties: (i) they should be pop-\nular and be used by many users, and (ii) they should not be biased towards any particular \nparty, candidate or organization in their formulation, i.e., the leaning of the user issuing the query should not be obvious from the query.\nTo satisfy the first property of selecting popular queries, we focused on hashtags for \nexpanding the query set. This choice was bolstered by the knowledge that hashtags are used \nextensively on Twitter to tag and follow discussions about politics\u00a0(Conover et\u00a0al. 2011a). \nAdditionally, every time a user clicks on a hashtag, a Twitter search page with the hashtag as the query opens up, making hashtags effectively act as recommended queries on Twitter. \nTo identify such popular hashtags, we collected the Twitter search results for our four seed \nqueries during the November 2015 Republican and Democratic debates. We then identi-fied top 10 most frequently occurring hashtags for each of the debate\u2019s dataset which con-\ntained the term \u201cdebate\u201d in them (to ensure they are about the primary debates), resulting \nin a total of 15 distinct hashtags (#debate, #demdebate, #democraticdebate, #republican-debate, #gopdebate, #debatewithbernie, #hillarycantdebate, #debatewithbe, #nprdebate, \n#cnndebate, #cnbcgopdebate, #fbngopdebate, #foxbusinessdebate, #gopdebatequestions, \n#gopdebatemoderators).\n2\nDue to our second desirable property, we wanted to retain only the unbiased queries \nfrom the above 15 hashtags, to avoid over-estimating the bias in the search results. Doing so, we removed queries which were biased towards (or against) a candidate (#debatewith-\nbernie, #hillarycantdebate, and #debatewithbe),\n3 an organization (#nprdebate, #cnnde-\nbate, #cnbcgopdebate, #fbngopdebate, and #foxbusinessdebate), or a party (#gopdebate-questions, and #gopdebatemoderators). Therefore, we were left with the expanded set of \n8 queries which are popular and for whom it was hard to guess the political leaning of the user issuing the query\u2014democratic debate, dem debate, #democraticdebate, #demdebate, \nrepublican debate, rep debate, #republicandebate and #gopdebate.\nIn addition, we also included the names of the 17 presidential candidates, resulting in \na total of 25 queries, which we used to measure the bias for political searches on Twitter. \nTable\u00a08 shows the exact phrasings of the 25 queries from our dataset.\n2 We did not include #debate in our selected query dataset because it was too generic and many tweets con-\ntaining it were about topics unrelated to 2016 US Presidential Primaries.\n3 For example, we observed that the hashtag #debatewithberine was biased towards Bernie Sanders (and \nthe Democratic party), with #FeelTheBern, #BernieSaidItFirst and #Bernie2016 being the hashtags which \nco-occurred with #debatewithbernie the most.\n199 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n4.1.2  Data collection from\u00a0Twitter\nFor applying our bias quantification framework to Twitter search, we needed to collect data \nabout the output search results given out by Twitter\u2019s ranking algorithm, as well as the set \nof tweets which were relevant to our selected queries that form the input to the ranking sys-\ntem. For performing our bias analysis, we collected the search data for a one week period in which both a Democratic debate (December 19, 2015) and a Republican debate (Decem-\nber 15, 2015) took place\u201414\u201321 December 2015.\nEven though Twitter provides multiple different filters for their search functionality, we \ncollected the search snapshots for our set of selected queries for the default filter of \u201ctop\u201d \nsearch results\u00a0(https ://twitt er.com/searc  h-home). The \u201ctop\u201d search results are the output of \nTwitter\u2019s proprietary ranking system, which performs ranking based on a multitude of fac-\ntors, including the number of users engaging with a tweet\u00a0(https ://help.twitt er.com/en/using \n-twitt er/top-searc  h-resul ts-faqs). During the one week period, search snapshots were col-\nlected at 10-min intervals for each query. Each snapshot consists of the top 20 results on \nthe first page of search results, and we used these snapshots to compute the output bias for \nthe queries. Across all queries, we collected a total of 28,800 snapshots which consisted of \n34,904 distinct tweets made by 17,624 distinct users.\nFinally, we used Twitter\u2019s streaming API to collect the tweets containing our selected \nqueries during this one week period, and this set of tweets formed the input to the ranking system and were used to compute the input bias for the queries.\n4 Across all queries, we col-\nlected more than 8.2 million tweets posted by 1.88 million distinct users.\nCollecting non-personalized search results: In this work, we focus on quantifying the \nbias in consistent, non-personalized search results shown to every user, therefore to miti-\ngate the personalization effects we made all the search queries from the same IP subnet (in \nGermany), and without logging in to Twitter.\n4.2  Measuring political bias of\u00a0an\u00a0individual search result\nTo apply our bias quantification framework to Twitter search for queries related to US pres-\nidential primaries, we need a methodology for inferring the political bias of an individual \nresult\u2014a tweet. The short length of tweets (140 characters) makes it very challenging to \ninfer the bias of a tweet from its content (i.e., to measure its content bias). Instead in this \nwork, we operationalize the bias of a tweet as its source bias, i.e., we approximate the bias \nof a tweet with the political bias of the author of the tweet.\nIn the rest of this section, we begin by presenting our methodology for inferring source \nbias of a tweet and then present our evaluation results. Finally, we end with a short analysis \nof how well source bias and content bias of a tweet match each other in practice for politi-cal searches on Twitter.\n4 We observed that 74.8% of tweets included in the search results were also included in the data that we \ncollected via the streaming API. In comparison, prior work that compared (Morstatter et\u00a0al. 2013) data col-\nlected using Twitter\u2019s Streaming API with Twitter\u2019s Firehose (full Twitter stream), found that on average, \nthe Streaming API contained 43.5% of data available on the Firehose on any given day.\n200 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n4.2.1  Source bias: inferring political bias of\u00a0Twitter users\nPrior studies have shown that people\u2019s political affiliations are correlated with their per -\nsonality attributes and responses to different stimuli\u00a0(Carney et\u00a0al. 2008; Shi et\u00a0al. 2017; \nhttp://2012e lecti on.proco n.org/view.resou rce.php?resou rceID =00481 8). Based on this \nknowledge, we propose a methodology for inferring political leaning of Twitter users by leveraging their interests. Therefore, our methodology for inferring the political bias of a \nTwitter user u, is based on the following three steps:\n1. Generating representative sets of Democratic and Republican users: We use the crowd-\nsourced methodology described in\u00a0Ghosh et\u00a0al. (2012) and Sharma et\u00a0al. (2012), which \ninfers the topical attributes of a user v  by mining the Twitter Lists that the other users \nhave included v  in. By relying on what others are reporting about a user, rather than what \nthe users are identifying themselves as, we avoid the self-reportage problem, as well as avoid biasing the sets towards the group of users who have self-reported. Following this methodology, we identified a seed set of 865 users labelled as \u201cDemocrats\u201d and 1348 \nusers labelled as \u201cRepublicans\u201d. These seed sets include known politicians (e.g., Steny \nHoyer, Matt Blunt), political organizations (e.g., DCCC, Homer Lkprt Tea-party) as \nwell as regular users.\n2. Inferring topical interests of a user: To infer the interests of a user u  we rely on the \nmethodology developed by Bhattacharya et\u00a0al. (2014a, b), which for a user u , returns a \nlist of topics of interest of u  along with the number of users whom u  follows who have \nbeen labeled with this topic using\u00a0the methodology described in Ghosh et\u00a0al. (2012) and \nSharma et\u00a0al. ( 2012 ). Therefore, our method leverages the network neighborhood of u to \ninfer the interests and hence the political leaning of u . For instance, if a user u  follows \nthree users tagged with \u2018politics\u2019 and four users tagged with \u2018entertainment\u2019, then the \nreturned list would be {politics: 3, entertainment: 4}. We convert this <topic, #users> \nlist into a weighted \ntf_idf vector for user u  (where the idf-s are computed considering \nthe interest lists of all the users in our dataset) and refer to it as the interest-vector Iu \nof the user u . We are not able to infer the topical interests of a user when either their \naccounts are protected, and we can not gather the users they are following or because they follow too few other users (less than 10). But in prior work, it has been shown that such cases are few, and this methodology infers the interests of a significant fraction of \nactive users on Twitter\u00a0(Bhattacharya et\u00a0al. 2014a, b).\n3. Matching user\u2019s interests to interests of Democrats and Republicans: We first com-pute the representative interest vectors for Democrats ( \nID ) and Republicans ( IR ) by \naggregating the interest vectors of users in each set and normalizing such that ID and \nIR vectors sum up to 1 each. These aggregate vectors not only capture the differences \nin the political interests of Democrats and Republicans (e.g., [progressive, democrats, obama, dems, liberals] and [patriots, conservative, tcot, right, gop] are the top terms in \nID and IR respectively), but also the differences in their non-political interests (e.g., IR \nhas higher weight for sports-related terms, while ID has higher weight for technology \nand entertainment related terms). Therefore, even in the case of users who don\u2019t follow any politicians on Twitter or the ones who follow politicians from both parties, these \nrepresentative vectors can be used to infer their likely political bias. Finally, the bias score of user u with interest vector \nIu is given by the difference in the cosine similarities \nof Iu with ID and IR , \n(5) Bias(u)= cos_sim(Iu,ID)\u2212cos_sim(Iu,IR).\n201 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n We max-min normalize the scores such that the bias score of a user lies in the range \n[\u22121.0, 1.0]  , with a score closer to +1.0 indicating more Democratic bias, while a score \ncloser to \u22121.0 indicating more Republican bias.\nPublic deployment of the source bias inference methodology: We have publicly deployed \nthe aforementioned source bias inference methodology in the form of a Twitter application, \nat http://twitt er-app.mpi-sws.org/searc  h-polit ical-bias-of-users /. One can login to the appli-\ncation using their Twitter credentials, and see their inferred political affiliation. One can \nalso search for other Twitter users to check out their inferred political leaning.\n4.2.2  Evaluation of\u00a0political bias inference methodology\nTo validate whether our bias inference method works well for a whole spectrum of politi-\ncally interested users, we perform the evaluation over three test sets of Twitter users\u2014\n(i)\u00a0politically interested common users, selected randomly from the set of users who have \nretweeted the two parties\u2019 accounts on Twitter, (ii)\u00a0the current US senators, and (iii)\u00a0self-identified common users (with fewer than 1000 followers), who have identified their politi-\ncal ideology in their account bios. We use two metrics for evaluating the methodology: \n(i)\u00a0coverage\u2014for what fraction of users can the methodology infer the political bias, and \n(ii)\u00a0accuracy\u2014for what fraction of users is the inference correct.\nWe begin by using the set of politically interested common users to evaluate our inferred \nbias scores, followed by a description of how we discretize our bias score into three distinct categories\u2014Republican, neutral and Democratic, and we end by presenting our methodol-\nogy\u2019s performance in inferring the political bias of senators and self-identified common \nusers.\nEvaluation for politically interested common usersIdentifying politically interested common users: Following the methodology developed \nby\u00a0Liu and Weber (2014), we collected up to 100 retweeters of each of the latest 3,200 tweets posted by the accounts of the two political parties\u2014@TheDemocrats and @GOP. \nWe removed the retweeters which retweeted the accounts of both the parties, obtaining \n98,955 distinct retweeters of @TheDemocrats, and 71,270 distinct retweeters of @GOP. From each of these two sets of retweeters, we randomly selected 100 retweeters, giving us \na total of 200 politically interested common users.\nGround truth bias of test users: We collected the ground truth bias annotations for these \n200 politically interested users by conducting an AMT survey where human workers were \nshown a link to user\u2019s Twitter profile. We only used Master workers from the US who have had at least 500 HITS approved, with an approval rating of \n95% . We paid the workers 4$ \nfor judging the political leaning of 45 Twitter users. The workers were asked to infer the \nuser\u2019s political leaning as either pro-Democratic, pro-Republican or neutral based on the \nuser\u2019s profile and tweets. For each user, we aggregated the judgements of 50 workers, add-ing \n+1 for each pro-Democratic, \u22121 for pro-Republican and 0 for each neutral judgement \nand normalizing by the total number of judgements to get an AMT bias score in the range \n[\u22121.0, 1.0]  , where a more positive score indicates a stronger Democratic bias, while a more \nnegative score indicates a stronger Republican bias.\nEvaluating our inferred score: With our methodology, we were able to infer the bias \nof all 200 users (i.e., coverage is 100%  ). To quantify the accuracy of the methodology, \nwe checked whether our inferred bias scores correlate well with the AMT bias scores. To \n202 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nverify this, we binned our inferred bias score into three bins: Bin 1 [\u22121.0,\u22120.5] , Bin 2 \n(\u22120.5, 0.5)  , and Bin 3 [0.5,\u00a01.0] and computed the average AMT bias scores for each bin. \nWe observe a strongly Republican leaning score ( \u22120.86 ) for Bin 1, while a strongly Demo-\ncratic leaning score (0.93) for Bin 3. We observe a similar trend if we bin according to the \nAMT bias scores and compute the average inferred score for each bin ( \u22120.32 for Bin 1 and \n0.14 for Bin 3), demonstrating a good correlation between the two bias scores.\nDiscretizing the bias score into categories: While the inferred bias scores are highly \ncorrelated with the AMT bias scores, we observe that the distribution (CDF) of the two \nscores in the interval [\u22121.0, 1.0]  are different, as shown in Fig.\u00a0 2. Due to this difference \nin the distributions of the two scores, we decided to discretize our inferred bias score, and \ncategorize users as\u2014neutral, Democratic or Republican leaning.\nIn order to do the discretization, we needed to identify a suitable threshold x on our \ninferred score, such that users with scores in the range (\u2212x ,x) are categorized as neutral, \nwhile the ones with scores x and above are identified as Democratic leaning, while \u2212x and Fig. 2  CDF of AMT bias scores \nand Inferred bias scores for \npolitically interested common users\n 0 0.2 0.4 0.6 0.8 1\n-1 -0.5  0  0.5  1CDF\nBias ScoreAMT bias score\nInferred bias score\nTable 2  Confusion matrix of the \nmatch between AMT bias scores and Inferred bias scoresAMT bias score Inferred rep (%) Inferred neutral (%)Inferred dem (%)\nAMT Bin 1 84.05 13.04 2.89\nAMT Bin 2 18.18 45.45 36.36\nAMT Bin 3 3.89 12.98 83.11\nTable 3  Coverage and accuracy \nof the political bias inference methodology for (i)\u00a0current US senators, and (ii)\u00a0common users who have declared their political ideology in their Twitter account profilesPolitical bias Coverage (%) Accuracy (%)\nCurrent US senators\nDemocratic (n=45) 97.78 86.36\nRepublican (n=54) 98.15 98.11\nAverage 97.96 92.23\nSelf-identified common users\nDemocratic (n=426) 92.01 88.52\nRepublican (n=675) 90.22 82.95\nAverage 91.12 85.73\n203 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nbelow are identified as Republican leaning. We experimented with x=0.01, 0.03, 0.05, 0.08  \nand 0.1, and for each of these values computed a confusion matrix of the match between \nthe AMT bias score and our inferred bias score. We selected x=0.03 to be the threshold as \nit maximizes the sum of the diagonal of the confusion matrix, as shown in Table\u00a0 2. In the \nrest of this section, we will only label the users as Republican or Democratic leaning when \ntheir bias scores lie outside of the neutral zone (\u22120.03, 0.03)  . We make this conservative \nchoice to not overestimate the bias in the search results.\nEvaluation for US senatorsTable\u00a0 3 outlines the performance of our methodology for the 100 current US senators (45 \nDemocrats, 54 Republicans, 1 Independent), showing that our methodology has very high \ncoverage. Closer inspection of the two senators, for whom we could not infer the bias, dis-\nclosed that one them does not follow any other users on Twitter while the other follows only one, making it impossible for us to infer their interests and consequently their bias. \nOur methodology also performs well in terms of accuracy by correctly identifying the bias \nfor \n86.4%  of Democratic senators and 98.1%  of Republican senators, out of the ones for \nwhom we could infer the bias.\nEvaluation for self-identified common usersWe collected our final set of self-identified common users using the service Followerwonk \nand gathering users located in the US, with less than 1000 followers, and whose Twitter \naccount biographies contained keywords matching Democrats (\u2018democrat\u2019, \u2018liberal\u2019, \u2018pro-\ngressive\u2019) or Republicans (\u2018republican\u2019, \u2018conservative\u2019, \u2018libertarian\u2019, \u2018tea party\u2019). We manu-ally inspected each user, and pruned out any users whose bios did not reflect their political \nideology. For instance, users with erroneous bios like \u201cI am a #conservative #Christian \nwho is neither a #Democrat nor a #Republican, but an #Independent voter\u201d and \u201cWe hate Politicians - Democrats, Republicans, all of them.\u201d were removed. Following this proce-\ndure, we collected a total of 426 self-identified Democratic users, and 675 self-identified \nRepublicans.\nTable\u00a0 3 also depicts the performance of our methodology for these self-identified users. \nThe average coverage is again high ( \n91.1%  ), with the users for whom we could not infer the \nbias either having protected accounts or following too few users such that it was impossible \nfor us to infer their interests and therefore their political bias. Our proposed method also \nhas a high accuracy of 85.7%  on average across all these self-identified common users for \nwhom we could infer the bias.\nFurther inspection of interest vectors of the users for whom we correctly inferred the \npolitical leaning reveals that the interest vectors of Democratic users not only contain political terms like \u2018liberal\u2019, \u2018progressive\u2019, and \u2018dem\u2019, but also other terms including \u2018gay\u2019, \n\u2018lgbt\u2019, \u2018science\u2019, and \u2018tech\u2019, while the interest vectors of Republican users contain terms \nlike \u2018tea\u2019, \u2018gop\u2019, and \u2018palin\u2019 along with other related terms like \u2018patriots\u2019, \u2018military\u2019, and \n\u2018vets\u2019.\n4.3  Match between\u00a0source bias and\u00a0tweet bias\nIn this section, we focus on answering the question, \u201chow closely do source bias and bias \nof a tweet reflect each other?\u201d.\n204 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nMeasuring tweet bias: For each of our selected queries, we gathered two search snap-\nshots from our chosen period in December 2015, one during the Republican debate and \none during the Democratic debate. Across all these snapshots, we gathered a total of 881 \ndistinct tweets, and we use these to evaluate the extent to which the tweet bias matches the inferred source bias. We use AMT workers to measure the tweet bias by showing each \ntweet (but not the user who posted it) to 10 AMT workers and asking them to label the \ntweet as either pro-Democratic, pro-Republican or neutral. Then following the methodol-\nogy in Sect.\u00a0 4.2.2, we computed a tweet bias score for each tweet by aggregating the judg-\nments of the 10 AMT workers. Using these scores, we generated the gold standard labels \nfor the bias of the tweets, by dividing the range of AMT tweet bias scores into 3 intervals \nand labelling tweets in interval \n[\u22121.0, 0.5]  as Republican, in interval (\u22120.5, 0.5)  as neutral, \nand in interval [0.5,\u00a01.0] as Democratic-leaning.Table 4  Confusion matrix for source bias classification\u2014gold standard tweet bias (based on AMT workers\u2019 \njudgement) versus source bias\nGold standard Source bias\nTweet bias  Republican (%)  Neutral (%)  Democratic (%)\nRepublican [\u22121.0, 0.5 ] 70.44 9.36 20.2\nNeutral (\u22120.5, 0.5 ) 27.61 16.96 55.43\nDemocratic [0.5,\u00a01.0] 11.71 10.24 78.05\nTable 5  Confusion matrix for content bias classification (support vector machine (SVM) classifier)\u2014gold \nstandard tweet bias (based on AMT workers\u2019 judgement) versus content bias\nGold standard Content bias\nTweet bias Republican (%) Neutral (%) Democratic (%)\nRepublican [\u22121.0, 0.5 ] 39.11 40.22 20.67\nNeutral (\u22120.5, 0.5 ) 16.67 76.19 7.14\nDemocratic [0.5, 1.0] 24.35 50.00 25.65\nTable 6  Confusion matrix for content bias classification (gradient boosted decision tree (GBDT) classi-\nfier)\u2014gold standard tweet bias (based on AMT workers\u2019 judgement) versus content bias\nGold standard Content bias\nTweet bias Republican (%) Neutral (%) Democratic (%)\nRepublican [\u22121.0, 0.5 ] 79.88 11.17 8.94\nNeutral (\u22120.5, 0.5 ) 57.14 35.72 7.14\nDemocratic [0.5,\u00a01.0] 64.10 8.97 26.93\n205 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nHow closely do source bias and tweet bias match each other?: To investigate the match \nbetween source bias and tweet bias, Table\u00a0 4 presents the confusion matrix for our source \nbias inference methodology. We observe that when the content is biased on either side, the \nmatch between source and AMT gold standard tweet bias is high ( 70% or more) indicating \nthat strongly biased content is produced mostly by users with the same bias. \nHow does our source based scheme compare to content based scheme for inferring the \nbias of a tweet?: To evaluate how well does a content-based scheme work for inferring bias of social media posts, especially in comparison with our source based methodology, we \nrepresented the tweets by a bag-of-words model (i.e., using every distinct unigram as a fea-\nture) and applied two well-known classifiers\u2014Support Vector Machine (SVM) and Gradi-\nent Boosted Decision Tree (GBDT).\n5 The unigram features were generated from the tweet \ntext by applying preprocessing steps of case-folding, stemming, stop word removal and removal of URLs. We used 5-fold cross validation for all the classification experiments.\nTables\u00a0 5 and\u00a0 6 depict the confusion matrices for the SVM and GBDT content based \nclassifiers respectively. Comparing with Table\u00a0 4, we observe that our source based method \nperforms better than the content based scheme. While the accuracy for SVM classifier is \nquite low, the GBDT classifier seems to classify most tweets as Republican. However, we \nwant a classifier where errors for the different classes are balanced, so that one class is not \ngrossly over-estimated, and from this perspective also our source-based classification per -\nforms better.\n4.4  Characterizing the\u00a0bias for\u00a0political searches on\u00a0Twitter social media\nHaving described our bias inference methodology, as well as the search data that we col-lected for political searches on Twitter social media, we next focus on analyzing the col-\nlected data to characterize the bias for political searches on Twitter. We begin by investigat-\ning the contributions of the two sources of bias\u2014input data and ranking system\u2014to the final output bias seen by the users. Then we examine the interplay between the input data \nand the ranking system that produces the output bias seen by the users. We end with an \nanalysis of the variation of bias over time.\n4.4.1  Where does the\u00a0bias come\u00a0from: input data or\u00a0ranking system?\nIt is not always the ranking system, input data matters: We show the three biases (out-put, input and ranking bias) for all our selected queries in Table\u00a0 7. When we compute the \naverage biases for the four sets of queries\u2014Democratic and Republican candidates and debates\u2014we find that the average input biases for all four sets are Democratic-leaning (i.e., larger than 0). Although the average input bias for Republican candidates and debates is \nless Democratic-leaning than Democratic ones, the full tweet stream containing all these \nquery terms (without any interference from the ranking system) on an average contains a \nmore Democratic slant. We observe that the input bias proves to be a prominent contributor \nto the final output bias seen by the users. For instance, the output bias for Bernie Sand-ers is very Democratic (0.71), with only a small amount of the bias being contributed by \nTwitter\u2019s ranking system (0.16); the majority of bias originates from the input data (0.55), \n5 Currently, we have used unigrams as features, however in the future other features including n-grams as \nwell as other classification methods can be explored to improve the content-based baselines.\n206 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nindicating that most of the users that discuss Bernie Sanders on Twitter have a Democratic \nleaning. The effect of input data on the output bias highlights the importance of also taking \ninto account the input data while auditing algorithms, to discern how much of the bias is \ndue to the data and how much is contributed by the algorithmic system. This insight is par -\nticularly crucial in this digital era where many algorithms are trained using vast amounts of data\u00a0(Barocas and Selbst 2014).Table 7  Time-averaged bias in Twitter search \u201ctop\u201d results, for selected queries (related to political candi-\ndates and debates)\u2014output bias TOB , input bias TIB , and ranking bias TRB\nHere a bias value closer to +1.0 indicates Democratic bias and a value closer to \u22121.0 indicates Republican \nbiasQuery Output bias (TOB) Input bias (TIB) Ranking \nbias (TRB)\nQueries related to democratic candidates\nHillary Clinton 0.21 0.03 0.18\nBernie Sanders 0.71 0.55 0.16\nMartin O\u2019Malley 0.64 0.57 0.07\nAverage 0.52 0.38 0.14\nQueries related to republican candidates\nDonald Trump 0.29 0.19 0.10\nTed Cruz \u2212\u00a00.48 \u2212\u00a00.11 \u2212\u00a00.37\nMarco Rubio \u2212\u00a00.41 \u2212\u00a00.12 \u2212\u00a00.29\nBen Carson 0.46 0.20 0.26\nChris Christie \u2212\u00a00.14 0.27 \u2212\u00a00.41\nJeb Bush \u2212\u00a00.31 0.09 \u2212\u00a00.40\nRand Paul \u2212\u00a00.37 \u2212\u00a00.18 \u2212\u00a00.19\nCarly Fiorina 0.16 0.38 \u2212\u00a00.22\nJohn Kasich \u2212\u00a00.09 \u2212\u00a00.13 0.04\nMike Huckabee 0.30 0.12 0.18\nRick Santorum \u2212\u00a00.04 0.18 \u2212\u00a00.22\nLindsey Graham \u2212\u00a00.45 0.07 \u2212\u00a00.52\nGeorge Pataki \u2212\u00a00.17 0.09 \u2212\u00a00.26\nJim Gilmore \u2212\u00a00.35 \u2212\u00a00.11 \u2212\u00a00.24\nAverage \u2212\u00a00.11 0.07 \u2212\u00a00.18\nQueries related to democratic debate\ndemocratic debate 0.43 0.38 0.05\ndem debate 0.52 0.29 0.23\n#democraticdebate 0.28 0.19 0.07\n#demdebate 0.57 0.56 0.01\nAverage 0.45 0.35 0.10\nQueries related to republican debaterepublican debate 0.53 0.27 0.26\nrep debate 0.31 0.40 \u2212\u00a00.09\n#republicandebate 0.39 0.34 0.05\n#gopdebate 0.04 0.10 \u2212\u00a00.06\nAverage 0.32 0.28 0.04\n207 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nWe also measured the bias of overall Twitter corpus in two ways: (i)\u00a0 User popula-\ntion bias: measured as the average bias of 1000 Twitter users selected randomly from \nthe Twitter user-id space (i.e., the user-ids were randomly selected from the range of \n1 through the id assigned to a newly created account in December 2015), and (ii)\u00a0 Full \ntweet stream bias: measured as the average source bias of 1000 tweets selected ran-\ndomly from Twitter\u2019s 1% random sample for December 2015. We found the user popu-\nlation bias to be 0.25 and a full tweet stream bias to be 0.3 indicating that not only is \nthe population of Twitter Democratic-leaning, but the active users (whose tweets have \nbeen included in Twitter\u2019s 1% random sample) are even more Democratic-leaning. These findings are in-line with prior studies\u00a0(http://www.pewre searc  h.org/2013/03/04/\ntwitt er-react ion-to-event s-often -at-odds-with-overa ll-publi c-opini on/) which have shown that Twitter has a high fraction of Democratic-leaning users.\nAlthough Twitter has a Democratic-leaning corpus bias, the input bias (TIB) of the \ndifferent queries varies across the spectrum (as shown in Table\u00a0 7). This variation in \nbias likely occurs because each query acts as a filter to extract a subset of Twitter users \nwhose tweets are relevant to that query, and the sets of users filtered out by different \nqueries have differing biases. Therefore, even with the corpus bias of Twitter being the same, each query determines the input data set and hence the input bias, which in turn \naffects the final output bias observed by the user for that query.\nThe power of the ranking system: Although input data does contribute to the final \noutput bias, the ranking system also exerts power over the final bias by shifting the bias or even changing its polarity, as demonstrated by the ranking biases shown in \nTable\u00a0 7. Even though we observed that the input biases for both the Democratic and \nRepublican candidates on an average were Democratic-leaning, we notice that on an \naverage the ranking system adds a Democratic-leaning ranking bias for the Democratic \ncandidates making the output more Democratic-leaning ( \nTOB =0.52)  , while it adds a \nRepublican-leaning ranking bias for Republican candidates making the output more \nRepublican-leaning ( TOB=\u2212 0.11 ). This change of polarity from a Democratic-lean-\ning input bias to a Republican-leaning output bias is particularly noticeable for some Republican candidates like Chris Christie, Jeb Bush and Lindsey Graham. These shifts \nin the bias caused by the ranking system (that can also result in a polarity change), \nexhibit the ranking system\u2019s power in altering the inherent bias of the input data.\nThe ranking of posts in social media search systems is a complex process with the \nplatform providers trying to provide the most relevant posts within the highest ranked \nitems. They use a number of factors to measure the relevance of posts for ranking \nsearch results, including the keywords it contains, the popularity of the post in terms of users\u2019 engagements with it (e.g., number of retweets, favorites or replies)\u00a0(https ://help.\ntwitt er.com/en/using -twitt er/top-searc  h-resul ts-faqs, https ://blog.twitt er.com/engin  \neerin g/en us/a/2014/build ing-a-compl ete-tweet -index .html), as well as the recency of \nthe post\u00a0 (https ://blog.twitt er.com/engin eerin g/en us/topic s/infra struc ture/2016/searc  \nh-relev  ance-infra struc ture-at-twitt er.html). Our goal in this work is not to reverse engi-\nneer Twitter\u2019s ranking system. However, we take a step towards gaining insight into the \nranking system of Twitter by examining the impact of the popularity of the posts on the \nsearch rankings. For doing so, we take the posts included in Twitter\u2019s top search results and rerank them based on the popularity of the post (i.e., the number of retweets and \nthe number of favorites). We then compared the bias of these simulated rankings with \nthe ranking bias of Twitter\u2019s ranking system (shown in Table\u00a0 8). For most of our que-\nries, the ranking biases of the three strategies are quite similar to each other, indicating \nthat popularity of the post can explain much of the observed bias in Twitter\u2019s ranking. \n208 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nHowever, in case of some queries (e.g., \u00a0 Martin O\u2019Malley, John Kasich, democratic \ndebate and #republicandebate), the difference in the ranking bias values between Twit-\nter\u2019s ranking and the popularity based rankings indicates that there are probably other \nfactors also that contribute to the overall bias of the search results. Note that this anal-ysis is just a first step towards understanding the influence of the different factors on \nthe overall bias of search results and we defer a more in-depth analysis for the future.Table 8  Time-averaged ranking bias for different ranking strategies: (i) Twitter\u2019s ranking (Twitter search \n\u201ctop\u201d results), (ii) Most retweeted tweet first ranking, and (iii) Most favorited tweet first ranking\nHere a bias value closer to +1.0 indicates Democratic bias and a value closer to \u22121.0 indicates Republican \nbiasQuery TRB of ranking strategies\nTwitter\u2019s ranking Most retweeted first Most favorited first\nQueries related to democratic candidates\nHillary Clinton 0.18 0.33 0.25\nBernie Sanders 0.16 0.22 0.16\nMartin O\u2019Malley 0.07 0.001 0.1\nQueries related to republican candidates\nDonald Trump 0.10 0.06 0.09\nTed Cruz \u2212\u00a00.37 \u2212\u00a00.49 \u2212\u00a00.35\nMarco Rubio \u2212\u00a00.29 \u2212\u00a00.36 \u2212\u00a00.27\nBen Carson 0.26 0.23 0.25\nChris Christie \u2212\u00a00.41 \u2212\u00a00.40 \u2212\u00a00.34\nJeb Bush \u2212\u00a00.40 \u2212\u00a00.46 \u2212\u00a00.34\nRand Paul \u2212\u00a00.19 \u2212\u00a00.25 \u2212\u00a00.17\nCarly Fiorina \u2212\u00a00.22 \u2212\u00a00.17 \u2212\u00a00.18\nJohn Kasich 0.04 0.04 0.11\nMike Huckabee 0.18 0.11 0.19\nRick Santorum \u2212\u00a00.22 \u2212\u00a00.34 \u2212\u00a00.16\nLindsey Graham \u2212\u00a00.52 \u2212\u00a00.45 \u2212\u00a00.56\nGeorge Pataki \u2212\u00a00.26 \u2212\u00a00.22 \u2212\u00a00.23\nJim Gilmore \u2212\u00a00.24 \u2212\u00a00.22 \u2212\u00a00.21\nQueries related to democratic debatedemocratic debate 0.05 0.21 0.12\ndem debate 0.23 0.22 0.22\n#democraticdebate 0.07 0.08 0.14\n#demdebate 0.01 \u2212\u00a00.01 0.01\nQueries related to republican debaterepublican debate 0.26 0.274 0.268\nrep debate \u2212\u00a00.09 \u2212\u00a00.09 \u2212\u00a00.09\n#republicandebate 0.05 0.08 0.17\n#gopdebate \u2212\u00a00.06 \u2212\u00a00.06 \u2212\u00a00.02\n209 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n4.4.2  Collective contribution of\u00a0the\u00a0input data and\u00a0the\u00a0ranking system\nHaving observed that both the input data and the ranking system contribute prominently \nto shape the final output bias seen by the users, we next explore the dynamics between \nthese two sources of bias. Here, we discuss two cases in which the interplay between the \ninput and ranking biases lead to an output bias which can noticeably affect a user\u2019s search experience.-1-0.5 0 0.5 1\nDonald-Trum p\nTed-Cruz\nMarco-Rubio\nBen-Carso n\nChris-Christie\nJeb-Bush\nRand-Paul\nCarly-Fiorina\nJohn-Kasich\nMike-Huckabee\nRick-Santorum\nLindsey-Graham\nGeorge-Pataki\nJim-Gilmor eOutput Bias (TOB)\nFig. 3  The time-averaged output bias TOB in Twitter \u201ctop\u201d search results for the Republican candidates\u2014\ncandidates are listed left to right from highest to lowest popularity\nTable 9  Randomly selected tweets from the search results for the queries Hillary Clinton and Donald \nTrump , which are posted by a user with an opposite bias as compared to the candidate\nRandomly selected tweets from Hillary Clinton \nsearch results, which are posted by a republican leaning userRandomly selected tweets from Donald Trump search results, which are posted by a democratic leaning user\nWT: Watchdog wants federal ethics probe of Clin-\nton, possible improprieties http://bit.ly/1Nvlr PAWilliamsburg, #Brooklyn Dec 15 #trump2016 \n#MussoliniGrumpycat #MakeAmericaHateAgain #DonaldTrump @realDonaldTrump pic.twitter.com/Hj6DC7M7V1\nThe Clintons both Bill and Hillary have a very long \nhistory of framing others while they commit the Crimes. History has destroyed the proofScotland defeats Trump on clean energy. Hopefully \nhell have a lot of time for golfing soon [url]\n@CarlyFiorina: @realDonaldTrump is a big \nChristmas gift wrapped up under the tree for @HillaryClinton. [url]Dirty little secret: Donald Trump is not a good \ndebater.\ns@CNN @HillaryClinton @BernieSanders hell no \nshes a murderer pic.twitter.com/zGQwR7dLZjhttp://MLive .com - Where Donald Trumps Michigan \ncampaign donations come from http://ow.ly/39hCW t\nI dont care if youre a Democrat or Republican, how \ncan you trust a word Hillary Clinton says and how can you consider voting for her??Enjoy the sweet music of Donald Trump in Carol of \nthe Trumps [url]\n210 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nThe case of popular candidates: Comparing the output biases for the candidate queries \nin Table\u00a0 7, we found that the search results for the more popular candidates have a higher \nbias towards the opposing perspective.6 For example, the top search results for the most \npopular Democratic candidate\u2014Hillary Clinton\u2014contained lesser Democratic-leaning \nresults than other Democratic candidates, while the results for the most popular Republi-\ncan candidate\u2014Donald Trump\u2014contained fewer Republican-leaning results as compared to other Republican candidates. In Fig.\u00a0 3, we plot the output bias for the Republican candi-\ndates ranked by their popularity. The negative slope of the line of best fit the figure seems to suggest that the more popular a candidate is, the more is the opposing perspective in \ntheir top search results (however we are limited in the number of data points to be able to \nmake any statistical inferences).\nThis situation may be undesirable for popular candidates, especially if users from the \nopposite perspective are more likely to speak negatively about the candidate and indeed this is what we find. Table\u00a0 9 shows tweets randomly sampled from the set of tweets included in \nthe top search results for a candidate, which were posted by users with an opposing polarity \nas compared to the candidate and they all either criticize or ridicule the candidates. Such \nnegative tweets could alter the opinions of undecided voters\u00a0(Epstein and Robertson 2015) \nand thus the situation is less than ideal for the popular candidates.\nWhen we examine the input biases for Hillary Clinton and Donald Trump, we observe \nthat they too lean towards opposite leaning indicating that opposite leaning users are more likely to talk about the popular candidates as opposed to less popular candidates. However, \nwe observe that the ranking system altered input bias for the two most popular candidates in different manners\u2014while the ranking system improved the situation for Hillary Clinton \nby adding a Democratic-leaning ranking bias and directing the search results towards her \nown party\u2019s perspective, it does the opposite for Donald Trump by adding Democratic-leaning ranking bias and thus increasing the opposite leaning bias for him. These opposing \ninterplay between the input data and ranking system (though possibly inadvertent) can have \nserious implications for the candidates, especially the one for whom the ranking system \nmade the tweets of opposite leaning users more visible in the final output search results.\nDifferent phrasings of similar queries: While looking for information about the same \ntopic, different users may use different phrasings of the query. For instance, for searching for the event Republican debate, users can use different queries like republican debate, \nrep debate, #republicandebate or #gopdebate. If users from different leanings preferen-\ntially use different keywords, phrases or hashtags to refer to the same event in their tweets, \nthen this might lead to differing biases for these differently phrased queries about the same \nevent. To investigate whether different phrasings of the query about the same event lead \nto different biases, we compare the bias values for the queries related to Democratic and \nRepublican debates, shown in Table\u00a0 7. The first thing we observe is that the output biases \nfor similar queries are noticeably different. For instance, the output bias of republican \ndebate ( \nTOB=0.53 ) has a lot more Democratic-leaning bias than the query rep debate \n( TOB=0.31 ), while the bias in search results for #demdebate ( TOB=0.57 ) are much \nmore Democratic-leaning than bias for the query #democraticdebate ( TOB=0.28).\nWhen we examine the input and ranking biases for our similarly phrased queries from \nTable\u00a0 7, we observe that for most of them, the input bias is the more prominent contribu-\ntor to the final output bias. However, in some cases even when the input biases are similar, \nas in the case of queries rep debate ( TIB=0.40 ) and republican debate ( TIB=0.27 ), the \n6 The popularity of a candidate is estimated from the polling data obtained from\u00a0RealClearPolitics (2015) \nfor December 2015.\n211 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nranking system shifts their biases in opposite directions, by adding a Democratic-leaning \nranking bias for republican debate ( TRB=0.26 ), while a Republican-leaning ranking \nbias for rep debate ( TRB=\u2212 0.09 ). This example illustrates the power the ranking system \nexerts on the input data, which can lead to search results for similar queries with similar input biases having different output biases. These observations about different biases for -1-0.5 0 0.5 1\n12-14 12-15 12-16 12-17 12-18\n(a) (b)\n(c)12-19 12-20 12-21 12-22Bias\nTimeOutput Bias\nInput Bias -1-0.5 0 0.5 1\n22-00 23-00 00-00 01-00 02-00 03-00 04-00 05-00 06-00 07-00Bias\nTimeOutput Bias\nInput Bias\n-1-0.5 0 0.5 1\n22-00 23-00 00-00 01-00 02-00 03-00 04-00 05-00 06-00 07-00Bias\nTimeOutput Bias\nInput Bias\nFig. 4  Temporal variation of output and input bias for the query dem debate\u2014(a)\u00a0variation across the full \nduration over which we collected data (December 14\u201322, 2015), (b)\u00a0variation during a 9-h window around \nthe republican debate on December 15, 2015, (c)\u00a0 variation during a 9-h window around the democratic debate on December 19, 2015\nTable 10  Statistical analysis of temporal variation of output bias for the query dem debate\u2014(i)\u00a0variation \nin output bias across 3\u00a0h before and 3\u00a0h after the Republican debate on December 15, 2015, (ii)\u00a0variation \nin output bias across 3\u00a0h before and 3\u00a0h after the Democratic debate on December 19, 2015, (iii)\u00a0variation in output bias across the 3\u00a0h time periods during the Republican debate (on December 15, 2015) and the Democratic debate (on December 19, 2015)\nOutput bias across 3-h time periods T1 T2 Paired t test Effect size r\nMean Mean\n(Std_dev) (Std_dev) df p val\nBefore Rep debate (T1) versus after Rep debate (T2) 0.3783 0.5189 35 0.0380 \u2212\u00a00.3008\n(0.2025) (0.2415)\nBefore Dem debate (T1) versus after Dem debate (T2) 0.7675 0.9576 35 0.0000 \u2212\u00a00.6375\n(0.1133) (0.1164)\nDuring Rep debate (T1) versus during Dem debate \n(T2)0.4200 0.6089 35 0.0034 \u2212\u00a00.3219\n(0.2974) (0.2565)\n212 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nsimilar queries raise questions about the impact that features like autocomplete queries and \nsuggested queries can have on the bias that the users see, and what mechanisms can be \ndesigned to make the users aware of these effects. These are open research questions that \ncan be pursued in the future and in Sect.\u00a0 8.4 we briefly discuss some solutions for signaling \nthe bias in the search results to the users.\n4.4.3  Variation of\u00a0bias over\u00a0time\nFinally, we explore whether the bias in the search results for a particular query varies with the time at which the query is issued. As described earlier, we collected the Twitter \ntop search results for our selected queries at 10-min intervals during the period Decem-\nber 14\u201321, 2015, which included both a Republican debate (December 15) and a Demo-cratic debate (December 19).\nTo illustrate how the bias in the search results for a query varies with time, Fig.\u00a0 4 shows \nthe variation in the output and input biases for the query dem debate during the entire one \nweek period (Fig.\u00a0 4a), during a 9-h interval around the Republican debate (Fig.\u00a0 4b), and \nduring a 9-h interval around the Democratic debate (Fig.\u00a0 4c). We observe noticeable varia-\ntion in the bias over time. The variation is lower for the input bias because we compute input bias over cumulative sets of tweets and hence it is less affected by instantaneous events. \nHowever, the variation in output bias is much higher, especially during and immediately after the debate events. (Fig.\u00a0 4b, c). In Table\u00a0 10, we present the statistical analysis for the \ntemporal variations in the output bias for the query dem debate (corresponding to Fig.\u00a0 4). \nThe first row of Table\u00a0 10 shows the comparison between the output bias values for the \nsearch snapshots for the query dem debate in the 3\u00a0h period before the start of the Repub-lican debate and the 3\u00a0h period after the end of the Republican debate. For comparison, we computed the significance of difference by performing paired t  test and determining the p  \nvalue for 95% confidence interval, and also computed the value of effect size r. Similarly, the second row in the table shows these values for the 3\u00a0h period before and after the Demo-cratic debate. For both the debates, we find that the differences in output bias before and \nafter the debate are statistically significant with medium to large effect sizes. We observed \nsimilar statistically significant temporal differences for other debate-related queries too.\nWe also observe another common trend in the variation of bias across different que-\nries. The output bias for most debate related queries shifted down (towards the Republican perspective) during the Republican debate when possibly a larger number of influential or \npopular Republican users were actively posting on Twitter. Correspondingly, the output \nbias for most debate related queries shifted up (towards the Democratic perspective) during the Democratic debate. This trend is visible in Fig.\u00a0 4b, c for the query dem debate, and we \nobserved similar trends for most other debate-related queries. The third row in Table\u00a0 10, \nshows the comparison between the output bias values for the search snapshots for the query dem debate during the 3\u00a0h period during the Republican debate and the 3\u00a0h period during \nthe Democratic debate. Again, we observe that difference between the two is statistically \nsignificant (with medium effect size) with the output bias being lower (more Republican-\nleaning) during Republican debate than during the Democratic debate. Therefore, we find \nthat which perspective is reflected more in the top Twitter search results varies with the time at which the query is issued.\n213 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n5  Comparing relative bias in\u00a0political searches on\u00a0the\u00a0web and\u00a0social \nmedia\nNext, we apply our bias quantification framework to compare the relative biases of political \nsearches on two different search systems\u2014Twitter social media search and Google Web \nsearch. This second study highlights another useful application scenario for our bias quan-\ntification framework where we can observe the output search results, but we do not have access to the input data to the ranking system (as is the case with most commercial search \nsystems). This unavailability of input data makes it infeasible to disentangle the effect of \ninput data and ranking system by measuring input bias and ranking bias separately, how -\never, we can still compare the relative biases of different search systems.\nOur choice of the two search systems to compare (Google and Twitter search) was \ndriven by the fact that these are two popular channels by which internet users are finding \nnews and information on the Web. Traditional media channels like Fox News or CNN have \noften been scrutinized by academics\u00a0(Ribeiro et\u00a0al. 2015; Babaei et\u00a0al. 2018; Budak et\u00a0al. \n2016; Gentzkow and Shapiro 2010; Groseclose and Milyo 2005; Baron 2006; Munson \net\u00a0al. 2013b), as well as media watchdog groups (like FAIR (fair.org ) and AIM (aim.\norg)) for fairness, accuracy and balance in the news they report. Additionally, tools have also been developed to mitigate or expose the media bias\u00a0(Purple Feed 2018; Park et\u00a0al. \n2009; Munson et\u00a0 al. 2013b; https ://twitt er-app.mpi-sws.org/media -bias-monit  or/; https ://\nmedia biasf  actch eck.com) to users. However, the relative biases of newer digital channels \nlike search systems are not as well studied and documented as yet, and thus users may not be taking their relative biases into account while selecting where to get their information from. With this study, we aim to highlight the differences in the bias of these two popular \nsearch systems\u2014Twitter social media search and Google Web search. To have a fair com-\nparison, we compare the Google search results with Twitter \u2018news\u2019 search results\u00a0 (https ://twitt er.com/searc  h-home), both of which frequently contain results from news media \nsources.\n5.1  Query selection and\u00a0data collection\n5.1.1  Collecting Google web search data\nWe collected the top 20 Google search results for the queries stated in Sect.\u00a0 4.1.1.7 The \nresults were collected at 10-min intervals during the period December 14\u201321, 2015, gather -\ning a total of 714 distinct web-links across all the queries. As was done while collecting the Twitter search results, to minimize any personalization effects, all the Google search results were collected without logging in to Google, and from the same IP subnet in Germany.\nNote that in the case of Web search, it is infeasible to gather the set of all relevant web-\nlinks for a query. Therefore we did not attempt to measure the input and ranking bias sepa-\nrately. Instead, we used the collected search snapshots to measure the bias in the output.\n7 We did not consider the hashtags as queries in this case, since hashtags are usually popular only on social \nmedia.\n214 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n5.1.2  Collecting Twitter news search data\nFollowing the methodology described in Sect.\u00a0 4.1.2, we collected the first page of top 20 \n\u201cnews\u201d search results for each query at 10-min intervals for the whole period. In total, \nacross all the selected queries, Twitter news search results contained tweets posted by 7512 \ndistinct accounts, an order of magnitude more than the number of distinct web-links in the dataset. We used these output search results to measure the output bias for Twitter news \nsearch.\n5.2  Measuring political bias of\u00a0a\u00a0search result\nFor applying the bias quantification framework, we need a methodology for inferring the \npolitical bias score of each data item. Next, we describe how we measured the political bias \nof Google search results and Twitter news search results.\n5.2.1  Measuring bias of\u00a0Google search results\nWe observed that the top Google search results for our chosen set of queries (US presiden-\ntial debates/candidates) contained a significant fraction of links from news media websites \nfor which the political biases have been documented \u00a0(Baron 2006; Gentzkow and Shapiro \n2010; Groseclose and Milyo 2005; Munson et\u00a0 al. 2013b). We use the results from Bal-ance study (Munson et\u00a0al. 2013b) which identified the political bias of a large number of \npopular news media sources, to infer the political bias of the news media links in the web search results. We mapped the URLs in the search results to media sources in the Balance \nlist\u00a0(Munson et\u00a0al.\u00a02013a), by considering the longest matching substring.\nApart from links from news media sources, Google search results also frequently con-\ntain Wikipedia articles, and personal websites and social media accounts of the political candidates (as also observed in\u00a0Trielli et\u00a0al. 2015). We considered all Wikipedia URLs to \nhave a zero or neutral bias,\n8 all personal websites of the candidates to have their own lean-\nings (e.g., \u00a0 trump.com, the website of Donald Trump, gets labelled as Republican), and \nall the social media profile links of the candidates to have their own leanings (e.g., the links to the Facebook, Twitter, Instagram accounts of Bernie Sanders are labelled as Dem-ocratic). Following this procedure, we were able to infer bias for \n86% of the top Google \nsearch results on an average across all the queries. The rest of the domains, for which we \ndid not attempt to infer bias, are mostly political facts websites (e.g., ontheissues.org, bal-\nlotopedia.org), informative websites (e.g., biography.com), or government websites (e.g., *.gov pages).\n5.2.2  Measuring bias of\u00a0Twitter news search results\nTo have a fair comparison between Google and Twitter news search results, we switch our methodology to infer the political leaning of Twitter results in this section and utilize Bal-\nance scores\u00a0(Munson et\u00a0al. 2013a) for them too. We observed that the 7512 accounts which \nwere included in the Twitter news search results include not only news media sources and \n8 Given Wikipedia\u2019s policy of neutral point of view\u00a0 (https ://en.wikip edia.org/wiki/Wikip edia:Neutr  alpoi \nntofv iew), we make this simplifying assumption. Though sometimes Wikipedia does contain misinforma-\ntion, prior work\u00a0Kumar et\u00a0al. (2016) has shown that most hoaxes are quickly detected and have little impact on Wikipedia.\n215 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\njournalists, but also other users like politicians and even academicians; hence, there was \nno way to match all these accounts to Balance scores. Therefore, we ranked these accounts \nbased on their frequency of occurrence in the Twitter news search results for all the queries \nand tried to manually map the top 200 accounts (which account for 63% of all the Twitter \nnews search results) to Balance scores. Additionally, we attempted to match the 100 of the \nmost influential media accounts on Twitter\u00a0 (Bremmen 2010) to Balance scores as well. \nTwitter news results also contained posts from journalists and political workers, and there \nwas no way to map them to Balance score, so we manually labeled such accounts with their \nself-declared leaning from their profile bios (whenever available). Finally, as before, we \nmarked the Twitter accounts of the presidential candidates with the candidate\u2019s own bias. \nBy following this methodology, we were able to get the bias annotations for 155 media \naccounts on Twitter, which cover 45% of the Twitter news search results on average across \nthe different queries.9\n5.3  Comparing relative biases of\u00a0Google search and\u00a0Twitter news search\nOur analysis shows three interesting ways in which the search bias for political queries on Google web search differs from that for Twitter social media search: (i) first, we inves-\ntigated the temporal dynamics of the bias in the search results on the two systems and \nfound the bias in social media search results to be significantly more dynamic across time, (ii) next, we compared their time-averaged output bias values to capture the overall trend \nand observed that for Google search the bias for most queries matches the leaning of the \nperson or event being queried for, while the bias of Twitter news search for most queries is \nDemocratic-leaning, and (iii) finally, we noticed that on Google search, a much higher frac-\ntion of search results are candidate-controlled sources (e.g., candidate\u2019s website or social media accounts), leading to more favorable results for the candidates on Web search than \non social media search. Next, we elaborate on each of our findings about the differences in \nbias of Google Web search and Twitter social media search.\n5.3.1  Temporal variation in\u00a0search bias\nWe began by comparing the two search systems along the temporal aspect by computing the standard deviation in the output biases of search result snapshots across time, for the \ndifferent queries. We observe that the Google web search results are much more stable over \ntime with a mean standard deviation of 0.046 in the output bias across all snapshots of all queries, while the standard deviation for Twitter news search results is an order of magni-\ntude higher at 0.452, highlighting their highly dynamic nature in comparison.\n5.3.2  Higher democratic bias in\u00a0Twitter news search results\nNext, to compare the overall trend in relative biases of the two search systems, we com-\nputed the time-averaged output bias ( TOB ) for all the queries on Google and Twitter news \n9 The political leaning inferred by the source bias method and the Balance score based method match for \n76% of these 155 media accounts. Here, we ignored the 9% of cases where our source bias methodology \ninferred the political leaning as neutral, which lead to a mismatch since the Balance Score does not output a \nneutral leaning.\n216 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nsearch, which are shown in Table\u00a0 11. As can be observed from the table, there is a strik -\ning difference between the two\u2014the TOB values for Twitter news search are positive (i.e., \nmore Democratic-leaning) for most of the queries, including many of the Republican can-\ndidates, while the TOB values for the Google search results in most cases match the lean-\ning of the candidate or event being searched for. So although the average TOB values for \nDemocratic candidates are Democratic-leaning for both systems, the average output bias for Republican candidates is Republican-leaning ( \nTOB=\u22120.264  ) for Google, while it is \non the positive side ( TOB=0.083  ) for Twitter news search results.\nThis difference between Google and Twitter news search results may be due to the larger \nfraction of Democratic-leaning users on Twitter as indicated by the Democratic-leaning \ncorpus bias we computed in Sect.\u00a0 4, as well as the Democratic-leaning input bias TIB val-\nues for most queries reported in Table\u00a0 7. These bias values mean that not only are there \nmore Democratic-leaning users on Twitter, but the users tweeting about many of our que-ries are also Democratic-leaning. These results hint at the tremendous influence that corpus \nand input data have on determining the final output bias.Table 11  Comparing time-averaged output bias TOB in (i)\u00a0Google search results, (ii)\u00a0Twitter news search \nresults\nQuery Google TOB Twitter news TOB\nQueries related to events\ndemocratic debate \u2212\u00a00.039 0.271\ndem debate 0.016 0.881\nrepublican debate \u2212\u00a00.224 0.216\nrep debate 0.073 0.07\nQueries related to democratic candidates\nHillary Clinton 0.766 0.3\nBernie Sanders 0.577 0.42\nMartin O\u2019Malley 0.552 0.701\nAverage 0.631 0.473\nQueries related to republican candidatesDonald Trump \u2212\u00a00.524 0.542\nTed Cruz \u2212\u00a00.543 0.288\nMarco Rubio \u2212\u00a00.055 0.253\nBen Carson \u2212\u00a00.259 0.191\nChris Christie \u2212\u00a00.105 \u2212\u00a00.286\nJeb Bush \u2212\u00a00.201 0.236\nRand Paul \u2212\u00a00.642 \u2212\u00a00.006\nCarly Fiorina \u2212\u00a00.487 0.09\nJohn Kasich \u2212\u00a00.364 0.442\nMike Huckabee 0.006 0.058\nRick Santorum \u2212\u00a00.229 \u2212\u00a00.041\nLindsey Graham \u2212\u00a00.183 \u2212\u00a00.12\nGeorge Pataki \u2212\u00a00.259 0.125\nJim Gilmore 0.138 \u2212\u00a00.608\nAverage \u2212\u00a00.264 0.083\n217 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n5.3.3  Favorable bias on\u00a0Google search via\u00a0candidate controlled sources\nWhen we dug deeper, we found that another potential reason for the differences in the rela-\ntive bias in Google search and Twitter news search results for a particular candidate is the \ndifference in the fraction of search results that come from sources controlled by the can-\ndidate themselves. For the Google search results, a significant fraction\u2014 24.48%  on aver -\nage across all queries\u2014of the results for the presidential candidates are from sources they \ncontrol, i.e., either their personal websites or their social media profile links (e.g., for Don-\nald Trump, we consider the webpage trump.com and his Twitter profile link https ://twitt er.com/realD onald Trump  to be sources controlled by him). A similar result is also reported \nin\u00a0 Trielli et\u00a0 al. (2015). This fraction is much smaller for most candidates on Twitter\u2014\nacross all the presidential candidates, only \n7.14%  of the Twitter news search results are \nfrom their own Twitter account. However, there are a few exceptions like Martin O\u2019Malley, \nChris Christie and Jim Gilmore, for whom 16.46%  , 14.62%  and 19.65%  respectively of their \nTwitter news search results come from their own Twitter accounts. And correspondingly, the search results for these candidates show a strong bias towards their own perspective (as \nshown in Table\u00a0 11). But, for most other candidates, the fractions of such tweets is much \nlower, and the bias in the Twitter news search results towards their own perspective is also \nlower.\nSince sources other than the candidate\u2019s websites and social media profile links can also \nbe controlled by the candidates, our measure likely underestimates the proportion of candi-\ndate controlled sources and thus provides a lower bound estimate of the observed favorable bias. In future, a more extensive analysis could be pursued using a larger set of possible \ncandidate controlled sources.\nThe above observations about web search, including lower dynamicity over time and \nthe candidates having favorable biases due to controlling a significant fraction of the links which come up in their top search results, make it easier for candidates to manipulate the \nWeb search results in their own favor. While, the results on Twitter are much more dynamic \nand affected more by popular users on Twitter, rather than the candidates themselves, mak -\ning them much harder to manipulate.\n6  Comparing relative bias of\u00a0Twitter\u2019s different ranking systems\nIn this paper, we measure the output bias of two different ranking systems of Twitter \nsearch\u2014\u2018top\u2019 and \u2018news\u2019 search filters\u2014for the same set of queries. Since the input biases \nfor the two are the same, we can compare the relative ranking biases for these two different \nranking systems of Twitter. When we consider the average biases for the Republican candi-dates, we find that the input bias is slightly Republican-leaning (average \nTIB=0.07 , shown \nin Table\u00a0 7), the Twitter \u2018top\u2019 search ranking system adds a Republican-leaning bias making \nthe output bias Republican-leaning (average TOB=\u2212 0.11 , shown in Table\u00a0 7). While the \nTwitter \u2018news\u2019 search ranking system adds a little Democratic-leaning ranking bias making \nthe output bias even more Democratic-leaning (average TOB=0.083  , shown in Table\u00a0 11). \nThis comparison of their relative ranking biases indicates that the \u2018news\u2019 filter of Twitter \nsearch highlights much more Democratic-leaning posts than the \u2018top\u2019 search filter.\n218 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n7  Limitations\nIn this study, we focused on a limited set of queries that were either related to a political \nevent or a political candidate. The main obstacles for expanding this set of queries included \nfinding a set of queries that are not biased towards any party or candidate (as described in \nSect.\u00a0 4.1.1) and Twitter data collection limitations (API keys and infrastructure). Extend-\ning our query set to include more general political queries on polarizing topics like gun \ncontrol or immigration could be done in the future to understand how the search systems \nare biasing the discourse about these popular debates in the society. Additionally, in the \nfuture, less popular queries which are less likely to be manually intervened could be ana-\nlyzed to understand the influence of the ranking system.\nAnother limiting factor in our study was using the simplifying assumption of consider -\ning a user as either neutral, pro-Democrat or pro-Republican. Under this assumption we can not have a user who is partially both pro-Republican and pro-Democrat. However, we should clarify that for doing this classification, we still considered two scores for each user, \none which captures the similarity to Republicans and the other to Democrats. Currently, to \ngive the user a final leaning, we consider the difference between these similarities. How -\never, in the future, we can use these two similarities to determine the extent to which a user is pro-Democrat as well as pro-Republican to have a more nuanced view of political lean-ings of users. Another interesting direction of future work would be to measure the users\u2019 \nopinions towards the different candidates in a more fine grained manner.\nAlso, the bipolar nature of US politics makes for a conducive environment for our bias \nmeasurement methodology. Extending our methodology for a multidimensional (politi-cal) space is likely to be quite challenging. Since our bias quantification framework can \nas easily work with a different methodology for inferring the bias of an individual item, future advances in measuring multidimensional bias could be plugged into our frame-\nwork to quantify search bias for more nuanced and complex multidimensional bias search \nscenarios.\nAnd lastly, while we discuss some potential solutions for signaling political bias in \nsearch results, and we have implemented our proposed split search as a Twitter applica-tion, however we have not done a user study to investigate the effect of this signaling on the \nusers\u2019 search experience. This exploration is an important follow up of our current work.\n8  Discussion\n8.1  Generalizability of\u00a0our search bias quantification framework\nHaving presented our results from applying our search bias quantification framework to \nmeasure the bias in political searches on Twitter social media search and Google Web \nsearch in the context of US politics, we now present a brief discussion of how our bias \nquantification framework can be generalized to scenarios of multiple perspectives, limited search data, and other search systems.\nExtending to multiple perspectives scenario: In this paper, we have focused on US poli-\ntics, and we have applied our bias quantification framework to this two-perspective sce-\nnario. However, it is possible to extend our framework to multiple perspective scenarios, \nfor instance with p different perspectives. These p different perspectives could correspond \n219 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nto the bias towards p different socio-political issues, or they could correspond to p different \npolitical parties. Our framework can be extended to p different perspectives, by associat-\ning a p-dimensional bias vector with each item, rather than a scalar bias score, as we did \ncurrently. More formally, the bias vector for the i-th data item would be given by Vi=[v1\ni , \nv2\ni,\u2026,vp\ni ], where vj\ni gives a measure of how biased the i-th data item is along the j-th per -\nspective, with values in the range of [\u22121, 1] . Here a value of vj\ni=1 could indicate support \nfor the j-th perspective, vj\ni=\u22121 could indicate opposition, whereas vj\ni=0 could indicate \nthat the item is neutral with respect to that perspective. By converting Eqs.\u00a0 1 to\u00a04, to their \nvector addition formulations, we can measure the input, output and ranking biases for this p-dimensional scenario. The primary challenge for pursuing this direction in the future is the development of a methodology to capture these bias vectors.\nExtending to limited data availability scenario: In many (if not most) cases, it may not \nbe possible or feasible to either access or collect the input dataset of all items containing \nthe selected queries. In such scenarios, we can adopt one of the following two approaches \nfor applying our quantification framework for estimating the search bias:\n1. Compare relative biases of two different search systems that function on similar input \ndata: For many modern IR systems, the items in the corpus are directly ranked according \nto their relevance for a query, without explicitly extracting an intermediate relevant item set. For such systems, we can compute the relative ranking biases of the two systems \nassuming them to operate upon similar input sets. For instance, we could compare the \nrelative ranking of different web search engines (e.g., Google vs. Bing vs. Yahoo), by \nobserving the output bias for the same set of queries.\n2. Approximate the input bias from the output search result snapshots: A simple approxi-\nmation of the input bias based on the output search snapshot could be computed by \ntaking an unweighted average of the bias scores of the items in the output set. This naive \napproximation can be improved by averaging over items in multiple search snapshots (e.g., n search snapshots), or averaging over items in a larger snapshot with more search \nresults (e.g., top-10k  instead of top-k  results).\nExtending to other search systems: Our bias quantification framework follows a black box \napproach and does not require the knowledge of the internal details of retrieval and rank -\ning systems to quantify the search bias. As a result, it can be easily applied to study the \nbias of a wide range of search systems, as long as a methodology for computing the bias \nof an individual item (e.g., web-pages, tweets, posts) is available. Measuring the bias of an \nindividual item in a search system is a context-dependent task, and since each platform is different, this in itself requires a significant effort. In this paper, we have delineated bias \nmeasurement techniques for tweets (Sect.\u00a0 4) and web-links (Sect.\u00a0 5). Also, in Sect.\u00a0 2, we \nhave briefly described prior work which has developed techniques for measuring the bias of users\u00a0(Purver and Karolina 2015; Makazhanov and Rafiei 2013; Fang et\u00a0al. 2015; Gol-\nbeck and Hansen 2011; Conover et\u00a0al. 2011a, b; Pennacchiotti and Popescu 2011; Bond \nand Messing 2015; Wong et\u00a0al. 2016) or content\u00a0(Zafar et\u00a0al. 2016; Weber et\u00a0al. 2013) on social media as well as blogs and news stories\u00a0(Adamic and Glance 2005; Yano et\u00a0al. 2010; \nZhou et\u00a0al. 2011; Budak et\u00a0al. 2016; Munson et\u00a0al. 2013b) on the Web. In the future, when \nbias quantification schemes are developed for other search systems, for instance for videos \n(e.g., Youtube search) or music (e.g., Spotify), these methodologies can be plugged into \nour bias quantification framework and be used to analyze the bias of these other search systems.\n220 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\n8.2  Search bias and\u00a0personalization\nIn this work, we have focused our attention on non-personalized search results, by adopt-\ning measures to mitigate the personalization effects as described earlier in the paper. We \ndo acknowledge that in reality, most searches made by users are personalized. Therefore \nour results may not be representative of the searches mostly done in the wild. However, we believe that the personalization is most likely to exacerbate the biases we observe and \nreport in this paper.\nIn the future, our bias quantification framework can be applied to study bias in person-\nalized search scenarios as well. By performing carefully controlled experiments\u00a0(Hannak \net\u00a0al. 2013; Kliman-Silver et\u00a0al. 2015), along with our framework, the different sources of \nbias in personalized search scenarios can potentially be discerned. We leave the detailed \ndesign and implementation of such a study for the future.\n8.3  The black box approach\nRecently, the rise of algorithmic platforms\u2019 influence on users\u2019 online experience has moti-\nvated many studies\u00a0(Datta et\u00a0al. 2015; Sweeney 2013; Hannak et\u00a0al. 2014; Sandvig et\u00a0al. \n2014; Executive Office of the President 2016) to audit these platforms and understand their \nbiases. While some of these algorithmic systems\u2019 functionalities are open to the public, making the auditing process easier, most of them are not. The walls of intellectual propri-\netary, high complexity of these algorithms and the perils of gaming a system via malicious \nusers put these algorithms in a black box, making it almost infeasible to have access to an \nalgorithm\u2019s specifications from outside, like in our study.\nWhile we know about a few general factors that a search engine takes into account in \ncurating the search results (such as relevancy, popularity, and recency), there are hundreds of other features that are hidden in a black-box, preventing us as researchers from being \nable to pinpoint the exact feature(s) of the algorithm which might be leading to the bias being introduced in the search results. However, it was possible for us (as outsiders) to \nobserve the unranked set of items that contained a query (input data) and the ranked list of \nitems output to the end user.\nTherefore, building on previous studies that have adopted the \u201cblack-box\u201d view for an \nalgorithmic system while auditing it (Eslami et\u00a0al. 2015; Liao et\u00a0al. 2016; Hannak et\u00a0al. \n2014, 2013; Chen et\u00a0al. 2015), we characterized the bias of the ranking algorithm in Twit-\nter\u2019s search platform and Google Web search platform, without knowing their internal functioning. We assume a simplistic view of the search engine where in the first step we determine the set of items containing the query term, and in the next step, the black-box \nranking system ranks these retrieved set of items into a ranked search output list, while tak -\ning into account all the relevance factors. Therefore we measure the input bias as the aver -\nage bias of this set of input items that contain the query term, while we measure the bias of the output ranked list using a MAP-style score that weighs higher ranked items higher \n(thereby capturing the impact of relevance and other factors used for ranking).\nIn this paper, we report the bias observed in the search outputs. However, we do not \nclaim that the search engines are intentionally adding bias to the search results because it is possible that the bias is introduced\u00a0due to the numerous factors that the search system is \nusing for ranking.\n221 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\n8.4  Signaling bias in\u00a0search results\nIn this work, we have shown that both social media search, as well as Web search results, \ndisplay varying degrees of bias. Next, we briefly discuss some solutions for tackling the \nbias, though their in-depth evaluation is left for the future.\nDesigning bias-aware ranking systems: A potential solution to address search bias is to \ndesign bias-aware ranking systems, which trade-off other metrics like relevance, popularity or recency with the bias of the search results. For instance, this could be achieved by mini-\nmizing the overall bias of search results by interleaving results with different biases using \nmethods similar to the ones used for injecting diversity in results\u00a0(Welch et\u00a0al. 2011; Yom-\nTov et\u00a0al. 2013). However, this may lead to a degradation of the quality of search results along these relevance metrics, and finding an optimal trade-off point might be domain and \nuser specific.\nMaking bias transparent in search interface design: An alternative method for address-\ning search bias could be to make the bias of each result transparent to the user by incor -\nporating it into the search engine\u2019s front-end design. Such a nudging practice has been \nused widely in the literature for purposes like delivering multiple aspects of news in social \nmedia\u00a0(Park et\u00a0al. 2009) and encouraging reading of diverse political opinions\u00a0(Munson \nand Resnick 2010; Munson et\u00a0al. 2013c). In a recent field study, it has been shown that by showing users alerts about the ranking bias in the search results can suppress the impact of \nthe ranking bias on undecided voters\u2019 voting preferences and also encourage them to read \nlower ranked results\u00a0(Epstein et\u00a0al. 2017b).\nHybrid approach\u2014split search: A hybrid approach of the above two methods could also \nbe proposed, which not only shows the bias of each search result, but also separates the results from the two political perspectives (Republican and Democratic) and shows them as \ndistinct ranked lists, with each distinct list retaining the ranking of the results in the origi-\nnal ranked list. This solution can be particularly effective in the cases where re-designing \nFig. 5  Screenshot of our Twitter-based split search service showing the results for the search term \u2018abor -\ntion\u2019. A widget adjacent to each result shows its bias measure\n222 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nthe algorithm and reaching a trade-off point for considering both bias and other relevance \nfactors in an algorithm\u2019s design is infeasible. This method is similar to how several product \ncompanies like Amazon separate product reviews into positive and negative reviews, such \nthat a user searching for that product can read the perspectives of others who either liked or disliked the product. By preserving the original search engine\u2019s ranking within each list, \nthis methodology ensures that the quality of the top search results does not degrade across \nother metrics such as relevance, popularity, and recency.\nWe have deployed the proposed split search methodology as a live Twitter-based search \nservice\u00a0(http://twitt er-app.mpi-sws.org/searc  h-bias-split -view/) which allows users to log in \nwith their Twitter credentials and do real-time searches for political queries on Twitter. The \ntop search results are presented to the user as two distinct ranked lists containing Demo-\ncratic- and Republican-leaning tweets, with each list maintaining the relevance rankings of the original search results returned by Twitter. Figure\u00a0 5 shows a snapshot of the tool for \nthe search term \u2018abortion\u2019. Besides showing the bias of each search result, this split search design helps users to understand what fraction of the top results are related to each political \nleaning. For example, Fig.\u00a0 5 shows that there are more Democratic-leaning search results \nfor the query \u2018abortion\u2019 than Republican-leaning ones amongst the first page of top search \nresults. Such differences can nudge users to notice which is the dominant political leaning \nfor the top search results for a search query and encourage them to read more results from \nthe other political side to gain more balanced information about a topic. A similar system has been developed by Wall Street Journal\u00a0(Keegan 2017) which presents posts from the \nmost biased news publishers on Facebook as chronological lists, with the aim of showing \nboth sides of the stories. However, how users interact with such alternative search interface designs remains to be investigated and is left for future work.\n9  Conclusion\nTo our knowledge, this work presents the first search bias quantification framework which not only quantifies the bias in the output search results but also discerns the contributions \nof two sources of bias\u2014input data and ranking system. We have applied our framework to \ninvestigate the sources of bias for political searches on Twitter social media and found both input data and the ranking system to be prominent contributors of the final bias seen by \nthe users in the output ranked list of search results. We found that factors such as the topic \nof the query, the phrasing of query and the time at which a query is issued also impact the \nbias seen by the users. We also applied our framework to compare the relative biases of \nGoogle Web search and Twitter social media search and found that Web search results are typically more favorable for the candidates from the two parties because many of the top \nresults include links to candidate-controlled sources like their own or their party\u2019s websites \nand social media accounts.\nWhile we do measure and report the bias introduced by the ranking systems of Twit-\nter and Google search engines, we do not claim that these biases are intentionally added by the platform. In fact, we did not find evidence of any systemic bias, i.e., the platforms \nconsistently ranking the items from one political leaning higher than the other, or consist-\nently making the search results more polarizing by adding a Democratic-leaning bias to Democratic party related queries and Republican-leaning bias to Republican party related \nqueries.\n223 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nAs an increasing number of people are relying on search systems to follow on-going \nevents and news and public opinion on well known personalities\u00a0(Teevan et\u00a0al. 2011), the \nbiases in search results can shape the users\u2019 opinions about these events and personali-\nties\u00a0(Pan et\u00a0al. 2007; Epstein and Robertson 2015). Our work lays the groundwork for the design of new mechanisms for making the users more aware of search bias, for instance \nby making the potential biases in the search results transparent to the users. For users, this \nawareness can lead to more intelligent use of the system to mitigate the effects of search \nbias. For system designers, the search bias framework can be used to audit their systems, \nespecially in cases when the bias is introduced by the ranking system and not the input data. And lastly, researchers and watchdog organizations can utilize our framework to audit \nand compare the biases of different search platforms, especially to unearth cases where the \nsearch bias may be ending up misleading the users.\nAcknowledgements Open access funding provided by Max Planck Society.\nOpen Access This article is distributed under the terms of the Creative Commons Attribution 4.0 Interna-\ntional License (http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, \nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.\nReferences\nAdamic, L. A., & Glance, N. (2005). The political blogosphere and the 2004 U.S. election: Divided they \nblog. In Proceedings of the 3rd international workshop on link discovery\u00a0(pp. 36\u201343). ACM.\nBabaei, M., Kulshrestha, J., Chakraborty, A., Benevenuto, F., Gummadi, K. P., & Weller, A. (2018). Purple \nfeed: Identifying high consensus news posts on social media. In Proceedings of the AAAI/ACM confer -\nence on artifical intelligence, ethics & society, AIES 2018,\u00a0New Orleans, USA.\nBarocas, S., & Selbst, A. D. (2014). Big data\u2019s disparate impact. Available at SSRN 2477899.Baron, D. P. (2006). Persistent media bias. Journal of Public Economics, 90(1\u20132), 1\u201336.Bhattacharya, P., Ghosh, S., Kulshrestha, J., Mondal, M., Zafar, M. B., Ganguly, N., & Gummadi, K. P. \n(2014a). Deep twitter diving: Exploring topical groups in microblogs at scale. In Proceedings of the 17th ACM conference on computer supported cooperative work and social computing, CSCW \u201914, pp. 197\u2013210. ACM, New York, NY, USA. http://doi.acm.org/10.1145/25316 02.25316 36\nBhattacharya, P., Zafar, M. B., Ganguly, N., Ghosh, S., & Gummadi, K. P. (2014b). Inferring user interests \nin the twitter social network. In Proceedings of the 8th ACM conference on recommender systems, Rec-Sys \u201914, pp. 357\u2013360. ACM, New York, NY, USA. https ://doi.org/10.1145/26457 10.26457 65.\nBond, R., & Messing, S. (2015). Quantifying social media\u2019s political space: Estimating ideology from pub-\nlicly revealed preferences on facebook. American Political Science Review, 109(01), 62\u201378.\nBremmen, N. (2010). The 100 most influential news media Twitter accounts. https ://memeb urn.\ncom/2010/09/the-100-most-influ entia l-news-media -twitt er-accou nts/.\nBudak, C., Goel, S., & Rao, J. M. (2016). Fair and balanced? Quantifying media bias through crowdsourced \ncontent analysis. Public Opinion Quarterly, 80(S1), 250\u2013271. https ://doi.org/10.1093/poq/nfw00 7..\nCarney, D. R., Jost, J. T., Gosling, S. D., & Potter, J. (2008). The secret lives of liberals and conservatives: \nPersonality profiles, interaction styles, and the things they leave behind. Political Psychology, 29(6), \n807\u2013840. https ://doi.org/10.1111/j.1467-9221.2008.00668 .x..\nChen, L., Mislove, A., & Wilson, C. (2015). Peeking beneath the hood of UBER. In Proceedings of the \n2015 ACM conference on internet measurement conference (pp. 495\u2013508). ACM.\nCohen, R., & Ruths, D. (2013). Classifying political orientation on twitter: It\u2019s not easy!. In Proceedings of \nAAAI international conference on web & social media, ICWSM 2013, Boston, USA.\nColetto, M., Garimella, K., Gionis, A., & Lucchese, C. (2017). A motif-based approach for identifying con-\ntroversy. arXiv  :1703.05053 .\nConover, M., Gon\u00e7alves, B., Ratkiewicz, J., Flammini, A., & Menczer, F. (2011a). Predicting the political \nalignment of twitter users. In Proceedings of IEEE third international conference on social computing, SocialCom \u201911, IEEE.\n224 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nConover, M., Ratkiewicz, J., Francisco, M., Gon\u00e7alves, B., Menczer, F., Flammini, A. (2011b). Political \npolarization on twitter. In Proceedings of AAAI international conference on web & social media, \nICWSM 2011.\nDatta, A., Tschantz, M. C., & Datta, A. (2015). Automated experiments on ad privacy settings: A tale of \nopacity, choice, and discrimination. In Proceedings on privacy enhancing technologies, http://arxiv \n.org/abs/1408.6491.\nEdelman, B. (2010). Hard-coding bias in google \u201calgorithmic\u201d search results. http://www.bened elman .org/\nhardc oding /.\nEpstein, R., & Robertson, R. E. (2015). The search engine manipulation effect (SEME) and its possible \nimpact on the outcomes of elections. Proceedings of of the National Academy of Sciences (PNAS), \n112(33), E4512\u2013E4521.\nEpstein, R., Robertson, R. E., Lazer, D., & Wilson, C. (2017a). Suppressing the search engine manipu-\nlation effect (SEME). Proceedings ACM Human\u2013Computer Interaction, 1, 42:1\u201342:22. https ://doi.\norg/10.1145/31346 77.\nEpstein, R., Robertson, R. E., Lazer, D., & Wilson, C. (2017b). Suppressing the search engine manipulation \neffect (SEME). Proceedings of the ACM: Human\u2013Computer Interaction, 1(2), 452.\nEslami, M., Karahalios, K., Sandvig, C., Vaccaro, K., Rickman, A., Hamilton, K., & Kirlik, A. (2016). First \ni \u201clike\u201d it, then i hide it: Folk theories of social feeds. In Proceedings of the 2016 CHI conference on human factors in computing systems (pp. 2371\u20132382). ACM.\nEslami, M., Rickman, A., Vaccaro, K., Aleyasen, A., Vuong, A., Karahalios, K., Hamilton, K., & Sandvig, \nC. (2015). I always assumed that i wasn\u2019t really that close to [her]: Reasoning about invisible algo-rithms in news feeds. In Proceedings of the 33rd annual ACM conference on human factors in comput-ing systems (pp. 153\u2013162). ACM.\nEslami, M., Vaccaro, K., Karahalios, K., & Hamilton, K. (2017). \u201cBe careful; things can be worse than \nthey appear\u201d: Understanding biased algorithms and users\u2019 behavior around them in rating plat-forms. In Proceedings of AAAI international conference on web & social media, ICWSM 2017\u00a0(pp. 62\u201371).\nExecutive Office of the President, U. (2016). Big data: A report on algorithmic systems, opportunity, and \ncivil rights. http://tinyu rl.com/Big-Data-White -House .\nFang, A., Ounis, I., Habel, P., Macdonald, C., & Limsopatham, N. (2015). Topic-centric classification of \ntwitter user\u2019s political orientation. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval, SIGIR \u201915 (pp. 791\u2013794).\nFortunato, S., Flammini, A., Menczer, F., & Vespignani, A. (2006). Topical interests and the mitiga-\ntion of search engine bias. Proceedings of of the National Academy of Sciences (PNAS), 103(34), \n12684\u201312689.\nGarimella, K., De\u00a0Francisci\u00a0Morales, G., Gionis, A., & Mathioudakis, M. (2016). Quantifying contro-\nversy in social media. In Proceedings of the 9th ACM international conference on web search and \ndata mining, WSDM \u201916.\nGentzkow, M., & Shapiro, J. (2010). What drives media slant? Evidence from U.S. daily newspapers. \nEconometrica, 78(1), 35\u201371.\nGhosh, S., Sharma, N., Benevenuto, F., Ganguly, N., & Gummadi, K. (2012). Cognos: Crowdsourcing \nsearch for topic experts in microblogs. In Proceedings of the 35th international ACM SIGIR confer -\nence on research and development in information retrieval, SIGIR \u201912 (pp. 575\u2013590). ACM, New \nYork, NY, USA. https ://doi.org/10.1145/23482 83.23483 61.\nGolbeck, J., & Hansen, D. (2011). Computing political preference among Twitter followers. In\u00a0 Proceed-\nings of the SIGCHI conference on human factors in computing systems (pp. 1105\u20131108). ACM.\nGroseclose, T., & Milyo, J. (2005). A measure of media bias. The Quarterly Journal of Economics, \n120(4), 1191\u20131237.\nHannak, A., Sapiezynski, P., Molavi\u00a0 Kakhki, A., Krishnamurthy, B., Lazer, D., Mislove, A., & Wil-\nson, C. (2013). Measuring personalization of web search. In Proceedings of the 22nd international \nconference on world wide web, WWW \u201913 (pp. 527\u2013538). ACM, New York, NY, USA. https ://doi.\norg/10.1145/24883 88.24884 35.\nHannak, A., Soeller, G., Lazer, D., Mislove, A., & Wilson, C. (2014). Measuring price discrimination \nand steering on e-commerce web sites. In Proceedings of the 2014 conference on internet measure-ment conference, IMC \u201914, pp. 305\u2013318. ACM, New York, NY, USA. https ://doi.org/10.1145/26637  \n16.26637 44.\nHern, A. (2015). Flickr faces complaints over \u2018offensive\u2019 auto-tagging for photos. http://tinyurl.com/\nFlickr-AutoTagging.\n225 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nHimelboim, I., McCreery, S., & Smith, M. (2013). Birds of a feather tweet together: Integrating network \nand content analyses to examine cross-ideology exposure on twitter. Journal of Computer-Mediated \nCommunication, 18(2), 40\u201360.\nKeegan, J. (2017). Blue feed, red feed\u2014see liberal facebook and conservative facebook, side by side. \nhttp://graph ics.wsj.com/blue-feed-red-feed/.\nKliman-Silver, C., Hannak, A., Lazer, D., Wilson, C., & Mislove, A. (2015). Location, location, loca-\ntion: The impact of geolocation on web search personalization. In Proceedings of the 2015 inter -\nnet measurement conference, IMC \u201915 (pp. 121\u2013127). ACM, New York, NY, USA. https ://doi.\norg/10.1145/28156 75.28157 14.\nKoutra, D., Bennett, P. N., & Horvitz, E. (2015). Events and controversies: Influences of a shocking \nnews event on information seeking. In Proceedings of the 24th international conference on world wide web, WWW \u201915, International world wide web conferences steering committee, Republic and Canton of Geneva, Switzerland (pp. 614\u2013624). https ://doi.org/10.1145/27362 77.27410 99.\nKulshrestha, J., Eslami, M., Messias, J., Zafar, M. B., Ghosh, S., Gummadi, K. P., & Karahalios, K. \n(2017). Quantifying search bias: Investigating sources of bias for political searches in social media. In Proceedings of the 2017 ACM conference on computer supported cooperative work and social \ncomputing, CSCW \u201917 (pp. 417\u2013432). ACM, New York, NY, USA. https ://doi.org/10.1145/29981  \n81.29983 21.\nKumar, S., West, R., Leskovec, J. (2016). Disinformation on the web: Impact, characteristics, and detec-\ntion of wikipedia hoaxes. In Proceedings of the 25th international conference on world wide web, WWW \u201916, International world wide web conferences steering committee, Republic and Canton of Geneva, Switzerland (pp. 591\u2013602).\nLiao, Q. V., Fu, W. T., & Strohmaier, M. (2016). # Snowden: Understanding biases introduced by behav -\nioral differences of opinion groups on social media. In Proceedings of the 2016 CHI conference on human factors in computing systems (pp. 3352\u20133363). ACM.\nLichterman, J. (2010). New pew data: More Americans are getting news on Facebook and Twitter. http://\nwww.niema nlab.org/2015/07/new-pew-data-more-ameri cans-are-getti ng-news-on-faceb ook-and-twitt er/.\nLiu, Z., & Weber, I. (2014). Is twitter a public sphere for online conflicts? A cross-ideological and cross-\nhierarchical look. In International Conference on Social Informatics (pp. 336\u2013347). Springer.\nLu, H., Caverlee, J., Niu, W., & Biaswatch, A. (2015). A lightweight system for discovering and tracking \ntopic-sensitive opinion bias in social media. In Proceedings of the 24th ACM international confer -\nence on information and knowledge management, CIKM \u201915.\nMakazhanov, A., & Rafiei, D. (2013). Predicting political preference of twitter users. In Proceedings \nof \u00a0advances in social networks analysis and mining, 289\u2013305, ASONAM \u201913.\nManning, C. D., Raghavan, P., & Schutze, H. (2008). Introduction to information retrieval. Cambridge: \nCambridge University Press.\nMedia Bias / Fact Check - The most comprehensive media bias resource. https ://media biasf  actch eck.\ncom.\nMorstatter, F., Pfeffer, J., Liu, H., & Carley, K. (2013). Is the sample good enough? Comparing data \nfrom twitter\u2019s streaming API with twitter\u2019s firehose. In International AAAI conference on web and \nsocial media, ICWSM \u201913, AAAI.\nMowshowitz, A., & Kawaguchi, A. (2005). Measuring search engine bias. Information Processing and \nManagement, 41(5), 1193\u20131205.\nMunson, S., Chhabra, S., & Resnick, P. (2013a). BALANCE\u2014Tools for improving your news reading \nexperience\u2014List of Classified sources. http://balan cestu dy.org/white list-class ifiab le.html.\nMunson, S., Chhabra, S., & Resnick, P. (2013b). BALANCE\u2014Tools for improving your news reading \nexperience. http://balan cestu dy.org/.\nMunson, S. A., Lee, S. Y., & Resnick, P. (2013c). Encouraging reading of diverse political viewpoints \nwith a browser widget. In International AAAI conference on web and social media, ICWSM \u201913, AAAI.\nMunson, S. A., & Resnick, P. (2010). Presenting diverse political opinions: How and how much. In Pro -\nceedings of the SIGCHI conference on human factors in computing systems (pp. 1457\u20131466). ACM.\nNews Media Bias Monitor Discover the Demographics of News and Media Outlets. (2018). https ://twitt  \ner-app.mpi-sws.org/media -bias-monit  or/.\nOfficial Google blog: New ways to stay informed about presidential politics. http://tinyu rl.com/Offic  \nialGo ogleB log.\nPan, B., Hembrooke, H., Joachims, T., Lorigo, L., Gay, G., & Granka, L. (2007). In google we trust: \nUsers\u2019 decisions on rank, position, and relevance. Journal of Computer-Mediated Communication, 12, 801\u2013823.\n226 Information Retrieval Journal (2019) 22:188\u2013227\n1 3\nPark, S., Kang, S., Chung, S., & Song, J. (2009). NewsCube: Delivering multiple aspects of news to \nmitigate media bias. In\u00a0 Proceedings of the SIGCHI conference on human factors in computing sys-\ntems\u00a0(pp. 443\u2013452). ACM.\nPennacchiotti, M., & Popescu, A. M. (2011). Democrats, republicans and starbucks afficionados: User \nclassification in twitter. In Proceedings of the 17th ACM SIGKDD international conference on \nknowledge discovery and data mining, KDD \u201911 (pp. 430\u2013438). ACM, New York, NY, USA. https  \n://doi.org/10.1145/20204 08.20204 77.\nProCon.org. (2015). Differences in conservative and liberal brains. http://2012e lecti on.proco n.org/view.\nresou rce.php?resou rceID =00481 8.\nPurple Feed. (2018). Identifying high consensus news posts on social media. https ://twitt er-app.mpi-sws.\norg/purpl e-feed/.\nPurver, M., & Karolina, S. (2015). Twitter language use reflects psychological differences between dem-\nocrats and republicans. PLoS ONE, 10(9), e0137\u2013e0422.\nRealClearPolitics\u2014Election 2016\u20142016 Republican Presidential Nomination. (2015). http://tinyu  \nrl.com/us-repub lican -polli ng-data.\nRibeiro, F. N., Lucas\u00a0Henrique, F. B., Chakraborty, A., Kulshrestha, J., Babei, M., & Gummadi, K. P. \n(2015). Media bias monitor: Quantifying biases of social media news outlets at large-scale. In Pro-\nceedings of the 12th international AAAI conference of web and social media, ICWSM \u201918.\nSandvig, C., Hamilton, K., Karahalios, K., & Langbort, C. (2014). Auditing algorithms: Research meth-\nods for detecting discrimination on internet platforms. Data and discrimination: Converting critical concerns into productive inquiry.\nSemaan, B. C., Robertson, S. P., Douglas, S., & Maruyama, M. (2014). Social media supporting political \ndeliberation across multiple public spheres: Towards depolarization. In Proceedings of the 17th ACM conference on computer supported cooperative work and social computing (pp. 1409\u20131421). ACM.\nSharma, N. K., Ghosh, S., Benevenuto, F., Ganguly, N., & Gummadi, K. (2012). Inferring who-is-who \nin the twitter social network. ACM SIGCOMM Computer Communication Review, 42(4), 533\u2013538. \nhttps ://doi.org/10.1145/23776 77.23777 82.\nShi, Y., Mast, K., Weber, I., Kellum, A., & Macy, M. (2017). Cultural fault lines and political polarization. \nIn Proceedings of the ACM conference on web science, WebSci \u201917 (pp. 213\u2013217). ACM, New York, \nNY, USA (2017). http://doi.acm.org/10.1145/30914 78.30915 20.\nSmith, L. M., Zhu, L., Lerman, K., & Kozareva, Z. (2013). The role of social media in the discussion of \ncontroversial topics. In 2013 International conference on social computing (SocialCom), (pp. 236\u2013243). IEEE.\nSpringer, A., Hollis, V., & Steve, W. (2017). Dice in the black box: User experiences with an inscrutable \nalgorithm. In The AAAI 2017 Spring symposium on designing the user experience of machine learning systems. AAAI.\nSweeney, L. (2013). Discrimination in online ad delivery. Queue, 11(3), 10.Tavani, H. (2014). Search engines and ethics. In Zalta, E. N. (Ed.), The Stanford encyclopedia of philoso-\nphy, spring 2014 Edn.\nTeevan, J., Ramage, D., Morris, & M. R. (2011). #twittersearch: A comparison of microblog search and \nweb search. In Proceedings of the 4th ACM international conference on web search and data mining, WSDM \u201911 (pp. 35\u201344). ACM, New York, NY, USA. https ://doi.org/10.1145/19358 26.19358 42.\nTrielli, D., Mussenden, S., & Diakopoulos, N. (2015). Why Google Search results favor democrats. http://\ntinyu rl.com/googl e-searc  h-favor  -dems.\nTwitter Application: Make Users Aware of the Biases in Search. http://twitt er-app.mpi-sws.org/searc  h-bias-\nsplit -view/.\nTwitter Blog: Building a complete Tweet index. https ://blog.twitt er.com/engin eerin g/en_us/a/2014/build ing-\na-compl ete-tweet -index .html.\nTwitter Blog: Search Relevance Infrastructure at Twitter. https ://blog.twitt er.com/engin eerin g/en_us/topic s/\ninfra struc ture/2016/searc  h-relev  ance-infra struc ture-at-twitt er.html.\nTwitter Help Center: Search result FAQs. https ://help.twitt er.com/en/using -twitt er/top-searc  h-resul ts-faqs.\nTwitter Reaction to Events Often at Odds with Overall Public Opinion. (2013). http://www.pewre searc \nh.org/2013/03/04/twitt er-react ion-to-event s-often -at-odds-with-overa ll-publi c-opini on/.\nTwitter Search Home. https ://twitt er.com/searc  h-home.\nVan\u00a0Couvering, E.(2010). Search engine bias: The structuration of traffic on the World-Wide Web. Ph.D. \nthesis, The London School of Economics and Political Science.\nVaughan, L., & Thelwall, M. (2004). Search engine coverage bias: Evidence and possible causes. Informa-\ntion Processing and Management, 40(4), 693\u2013707.\n227 Information Retrieval Journal (2019) 22:188\u2013227 \n1 3\nWeber, I., Garimella, V. R. K., & Borra, E. (2012). Mining web query logs to analyze political issues. In \nProceedings of the 4th annual ACM web science conference, WebSci \u201912, pp. 330\u2013334. ACM, New \nYork, NY, USA. https ://doi.org/10.1145/23807 18.23807 61.\nWeber, I., Garimella, V. R. K., & Teka, A. (2013). Political hashtag trends. In European conference on \ninformation retrieval,\u00a0ECIR \u201913 (pp. 857\u2013860). Berlin: Springer.\nWelch, M. J., Cho, J., & Olston, C. (2011). Search result diversity for informational queries. \u00a0In\u00a0 Proceedings \nof the 20th international conference on world wide web\u00a0(pp. 237\u2013246). ACM.\nWikipedia: Neutral point of view. https ://en.wikip edia.org/wiki/Wikip edia:Neutr  al_point _of_view .\nWong, F. M. F., Tan, C. W., Sen, S., & Chiang, M. (2016). Quantifying political leaning from tweets, \nretweets, and retweeters. IEEE Transactions on Knowledge and Data Engineering, 28, 2158.\nYano, T., Resnik, P., & Smith, N. A. (2010). Shedding (a thousand points of) light on biased language. In \nProceedings of NAACL HLT workshop on creating speech and language data with Amazon\u2019s mechani-cal turk (CSLDAMT).\nYardi, S., & Boyd, D. (2010). Dynamic debates: An analysis of group polarization over time on twitter. Bul-\nletin of Science, Technology and Society, 30(5), 316\u2013327.\nYilmaz, E., & Aslam, J. A. (2006). Estimating average precision with incomplete and imperfect judgments. \nIn Proceedings of the 15th ACM international conference on information and knowledge manage-\nment\u00a0(pp. 102\u2013111). ACM.\nYom-Tov, E., Dumais, S., & Guo, Q. (2013). Promoting civil discourse through search engine diversity. \nSocial Science Computer Review, 32, 145\u2013154.\nZafar, M. B., Gummadi, K. P., & Danescu-Niculescu-Mizil, C. (2016). Message impartiality in social media \ndiscussions. In Proceedings in\u00a0international AAAI conference on web and social media. ICWSM \u201916. AAAI.\nZhou, D. X., Resnick, P., & Mei, Q. (2011). Classifying the political leaning of news articles and users \nfrom user votes. In Proceedings\u00a0in\u00a0international AAAI conference on web and social media. ICWSM \u201911.\u00a0AAAI.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Search bias quantification: investigating political bias in social media and web search", "author": ["J Kulshrestha", "M Eslami", "J Messias", "MB Zafar"], "pub_year": "2019", "venue": "Information Retrieval \u2026", "abstract": "Users frequently use search systems on the Web as well as online social media to learn about  ongoing events and public opinion on personalities. Prior studies have shown that the top-"}, "filled": false, "gsrank": 146, "pub_url": "https://link.springer.com/article/10.1007/s10791-018-9341-2", "author_id": ["tYOEJ6sAAAAJ", "YY4jPkwAAAAJ", "EoGEeFAAAAAJ", "keWdp0AAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:JCkIwY2Qx4IJ:scholar.google.com/&output=cite&scirp=145&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=JCkIwY2Qx4IJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 148, "citedby_url": "/scholar?cites=9423659683799378212&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:JCkIwY2Qx4IJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1007/s10791-018-9341-2.pdf"}}, {"title": "Search personalization on Google. nl", "year": "2021", "pdf_data": "Bachelor thesisComputing Science\nRadboud University\nSearch personalization on\nGoogle.nl\nAuthor:\nRoland Leferink\nS4557972First supervisor/assessor:\nDr. ir. Eelco Herder\neelcoherder@cs.ru.nl\nSecond assessor:\nDr. Harrie Oosterhuis\nharrie.oosterhuis@ru.nl\nMarch 19, 2021\nAbstract\nWith more and more people gaining access to the internet, search engines\nlike Google gain a more important role as the gatekeepers to information.\nWith this role of gatekeeper also comes the power to decide what a user can\nsee when searching for something, will you show a user both perspectives on\na certain topic, or will you only show the perspective that you like?\nIn this thesis we will try to uncover if internet users in the Netherlands\nare caught in a so-called \flter bubble, an online echo chamber, that only\ncaters to a person's interest, created by Google. This could be done by\nselectively choosing which users get which results when searching for the\nsame subject. More speci\fcally, we will test if certain controversial topics\nare more likely to result in a more curated search result than more normal,\nnon-controversial topics.\nOur research shows that, while there are statistically signi\fcant di\u000berences\nbetween controversial and non-controversial search queries in terms of how\nunique the search results are, there isn't a clear reason as to why this is the\ncase.\nContents\n1 Introduction 3\n2 Preliminaries 5\n2.1 Google Search ranking . . . . . . . . . . . . . . . . . . . . . . 5\n2.2 PageRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.3 Contextualization . . . . . . . . . . . . . . . . . . . . . . . . . 6\n3 Related Work 8\n3.1 What did you see? Personalization, regionalization and the\nquestion of the \flter bubble in Google's search engine . . . . 8\n3.2 Location, Location, Location: The Impact of Geolocation on\nWeb Search Personalization . . . . . . . . . . . . . . . . . . . 9\n3.3 Measuring Political Personalization of Google News Search . 10\n4 Research 12\n4.1 Questionnaire . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n4.1.1 Why a questionnaire . . . . . . . . . . . . . . . . . . . 12\n4.1.2 Why these questions . . . . . . . . . . . . . . . . . . . 12\n4.1.3 Distributing questionnaire . . . . . . . . . . . . . . . . 14\n4.2 Data processing . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4.2.1 Python script . . . . . . . . . . . . . . . . . . . . . . . 14\n4.3 Website standings . . . . . . . . . . . . . . . . . . . . . . . . 15\n4.4 Comparing search results . . . . . . . . . . . . . . . . . . . . 15\n4.4.1 Levenshtein distance functioning . . . . . . . . . . . . 15\n4.4.2 Why Levenshtein distance . . . . . . . . . . . . . . . . 15\n4.4.3 Similarity . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.4.4 Why similarity . . . . . . . . . . . . . . . . . . . . . . 16\n5 Results 17\n5.1 Survey demographics . . . . . . . . . . . . . . . . . . . . . . . 17\n5.1.1 Personal information . . . . . . . . . . . . . . . . . . . 17\n5.1.2 Controversial survey . . . . . . . . . . . . . . . . . . . 19\n5.1.3 Non-controversial survey . . . . . . . . . . . . . . . . . 21\n5.2 Websites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n1\n5.2.1 General . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n5.2.2 Controversial websites . . . . . . . . . . . . . . . . . . 22\n5.2.3 Non-controversial websites . . . . . . . . . . . . . . . . 24\n5.3 Statistical signi\fcance . . . . . . . . . . . . . . . . . . . . . . 24\n5.3.1 T-test . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n5.3.2 Cause . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n5.3.3 Interference by Google . . . . . . . . . . . . . . . . . . 26\n6 Conclusions 27\n7 Future Work 28\n7.1 Search results between search engines . . . . . . . . . . . . . 28\n7.2 More diverse test population . . . . . . . . . . . . . . . . . . 28\nA Appendix 32\nA.1 Controversial Questionnaire . . . . . . . . . . . . . . . . . . . 32\nA.2 Non-controversial Questionnaire . . . . . . . . . . . . . . . . . 35\n2\nChapter 1\nIntroduction\nIn his 2011 book, The Filter Bubble: What the Internet Is Hiding from You,\n[10] Eli Parser came up with the term \\\flter bubble\". He describes it as:\n\\A personal ecosystem of information that's been catered by algorithms to\nwho they think you are.\" In other words, when two people are using the\nsame questions, they might receive di\u000berent answers based on assumptions\nmade by an algorithm. While most of the personalized results have good\nintentions, like making sure you don't see the website of a bakery on the\nother side of the planet when searching for local bakeries, or only receiving\nChinese websites when searching in Dutch, these algorithms could prevent\nyou from seeing relevant information because of their assumptions.\nIn this thesis we will investigate if the algorithms that Google uses actually\nlead to di\u000bering search results for the same search query, or if they actu-\nally create a \flter bubble. The \frst reason for investigating this, is because\nGoogle is by far the most used search engine with a market share of around\n90%1. The second reason is that, if users aren't receiving relevant informa-\ntion, because they think Google is impartial and shows everybody the same\nresults but instead results based on a pro\fle built by their algorithms, users\nshould be made aware of this.\nEven though a di\u000berence in search results on Google has already been studied\nin the past, this hasn't been done on Google.nl and the focus is usually on\ndi\u000berent search results for political search queries, like the names of politi-\ncians and political parties [7] or news articles [9]. For this thesis we will\nfocus on Google.nl , since this kind of research is usually very dependent on\nlanguage and location, and we will speci\fcally focus on both controversial\nand non-controversial queries to see if there is a di\u000berence between these two.\nAs we mentioned in the previous paragraph studies like this have already\n1https://gs.statcounter.com/search-engine-market-share\n3\nbeen done before in the past, but never for the Netherlands, and the search\nqueries in previous studies were never split between controversial and non\ncontroversial topics to see if there is a noticeable di\u000berence.\nOur research will be done by comparing the search results of around 200\npeople, split into two groups of roughly 100: one for each set of queries. We\ncan then use statistical analysis to determine if the search results di\u000ber too\nmuch for it to be a coincidence, which could mean that Google \flters possible\nrelevant search results from certain users. By using the exact same search\nquery for every person in the group, and registering when and where they\nsearch the mentioned queries, we can \flter out the expected di\u000bering search\nresults caused by location and time which leaves us with search results that\ncould only di\u000ber because of personalization based on information by Google.\nIn chapter 2, we will give some necessary background information on how\nGoogle search works. In chapter 3, we will compare our work to related\nstudies and highlight a couple of key di\u000berences and similarities. In chapter\n4 we will explain the methods used to obtain our data, and why we made\ncertain choices with regards to using this data. Chapter 5 will be used to\npresent the results of our research. In chapter 6 we will give a conclusion\nbased on our results. Finally, in chapter 7 we will give some suggestions for\nfuture research.\n4\nChapter 2\nPreliminaries\n2.1 Google Search ranking\nWhile Google is very con\fdent in their explanation of how their search\nalgorithm works1, its precise working isn't exactly known. While previ-\nous research has reported signi\fcant personalization based on location, and\nGoogle has been somewhat open about this, using searching for the term\n\\football\" in the US and the UK as an example of how they personalize your\nsearch results, it isn't very clear how much other factors like a user's browser\nhistory contribute to it [15, 7, 5]. While Google does admit that they use\nbrowser history in their personalization, the examples that they give for it\nare incredibly speci\fc, e.g. If you search for Barcelona after recently search-\ning Barcelona against Arsenal, it uses that to give you information about the\nfootball, club and not the city. Besides this the only other thing Google has\npublished about their search algorithm, is that they don't use it to deduce\npersonal and sensitive info from it, like race, religion, or political a\u000eliation.\n2.2 PageRank\nOne of the more well-known and oldest algorithms that Google uses to de-\ncide which web page ends up where on the search results page is PageRank.\nThis algorithm was developed by Google founders Larry Page and Sergey\nBrin, when they were still PhD students at Stanford, and is still in use to-\nday. While it's not the most important search algorithm anymore, and thus\nisn't used as one of the main ranking factors to decide which web page goes\nwhere on the search results page, those are Links, Content2and RankBrain3,\nit does give a bit of an insight into what Google uses to rank search results.\n1https://www.google.com/search/howsearchworks/\n2https://web.archive.org/web/20160325232656/http://www.bloomberg.com/news/articles/2015-\n10-26/google-turning-its-lucrative-web-search-over-to-ai-machines\n3https://daizy.media/googles-zoekalgoritme-mythes-bevestigd/\n5\nIn short, PageRank works by ranking web pages based on how often other\nweb pages link to that web page, and the quality of those web pages. The\noutput of PageRank is a probability distribution that represents the proba-\nbility that someone randomly clicking on links ends up at a particular page\nin a set of web pages.\nA simple explanation of how PageRank calculates the output distribution\nis as follows: Initially all web pages nin the set Nget the same probability\n1=Nas their PageRank value PR(n). Then for the \frst iteration each page n\ndivides its PR(n) equally over its outbound links L(n). This process would\nthen be repeated for a certain number of times to eventually get the \fnal\nPageRank for every web page. So, in general the following formula can be\nused to calculate the PageRank value for a page u:\nPR(u) =X\nv2BuPR(v)\nL(v)\nHere PR(u) is the PageRank value of uafter the iteration, vis a page that\nlinks to u, Buis the set of vthus the set that contains all the pages that\nhave a link to u,PR(v) the previous (or initial if it's the \frst iteration)\nPageRank value of page v,L(v) the total amount of outbound links on page\nv.\nWhile in reality the algorithm is a bit more complex, with also a damp-\ning factor that represents the imaginary user that eventually stops clicking\non links, and some extra rules for web pages that don't have any outgoing\nlinks to make it more fair for pages that do, these aren't very relevant in\nthis case to the overall use of PageRank and what it means for search results.\nFinally, after computing the PageRank values for a set of web pages Google\nuses these values in combination with other ranking factors to determine\nwhich pages should be near the top of the search results, and which should\nbe lower.\n2.3 Contextualization\nOn December 9th, 2019 Google rolled out their biggest update in the last \fve\nyears in over 70 languages including Dutch, which is the language we used\nfor our search queries. This update applies a new way of contextualization\ncalled Bidirectional Encoder Representations from Transformers or BERT\nfor short4. BERT was developed by Google as a new technique for natural\n4https://blog.google/products/search/search-language-understanding-bert/\n6\nlanguage processing to better understand search queries and thus to return\nbetter search results [3].\nLanguage representation models come in two di\u000berent forms: context-free\nand contextual. These contextual models can then either be unidirectional\nor bidirectional. Context-free models don't take into account the context of\nwhere a word is placed. For example, the word \\bill\" has the same repre-\nsentation in \\duck bill\" and \\restaurant bill\". A contextual representation\nwould also look at the other words in the sentence to give a more accurate\nrepresentation of the word \\bill\". This can be done either unidirectional\nwhere only one \\direction\" of the sentence is used for context, or bidirec-\ntional where both \\directions\" would be used. For example in the sentence\n\\I touched the bill of my pet duck\" a unidirectional contextual model would\nrepresent \\bill\" based on \\I touched the\" but not \\of my pet duck\" or vice\nversa. However, BERT would represent \\bill\" based on both the previous\nand the next context because of it being bidirectional. This helps returning\nbetter search results because it can make more use of context in the query\nthan before.5\nIn a blog posted earlier that year6Google gave some good examples on how\nthe use of BERT improved search results. One of these examples was the\nquery \\Parking on a hill with no curb\". Before the implementation of BERT\nGoogle's systems would focus too much on the word \\curb\" and not on the\n\\no\" in front of it and would thus return results on how to park on a hill\nthat has a curb.\n5https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n6https://blog.google/products/search/search-language-understanding-bert/\n7\nChapter 3\nRelated Work\nPersonalization of search results and by extension the \flter bubble has been\nthe subject of other research in the past. While this research is closely re-\nlated to this one they also di\u000ber in some key aspects. These di\u000berences are\nusually most noticeable in which type of personalization they're interested\nin. Some are focused on personalization based on location [7, 15], personal-\nization based on search history [9, 12], personalization in general [2, 4, 5],\nor personalization based on other characteristics [1, 6, 8]. For some of these\npapers I'll go more in depth and explain both the similarities and the di\u000ber-\nences between their research and ours, especially since at \frst glance they\nmight look almost identical since they're all just focused on personalization\nof search results.\n3.1 What did you see? Personalization, regional-\nization and the question of the \flter bubble in\nGoogle's search engine\nOne of these related studies was done by the Technical University of Kaiser-\nslautern in 2016. In their paper [8] Tobias Kra\u000bt, Michael Gamer, and\nKatharina Zweig analyze Google search results to investigate the degree of\npersonalization of search results, the proportion of regionalization, and the\nrisk of algorithm based \flter bubble formation or reinforcement by the leader\nin the search engine market.\nWhile there are similarities, both analyzed Google search results for instance,\nthere are some key di\u000berences. For their study Kra\u000bt, Gamer, and Zweig\ndeveloped a browser plugin that would automatically search a prede\fned\nset of German politicians and political parties every 4 hours if the browser\nwas open. The study had a couple of main focus points: investigate the de-\ngree of personalization of search results, how much regionalization a\u000bected\n8\nthose search results, and the risks of the formation of reinforcement of an\nalgorithm-based \flter bubble.\nOne big di\u000berence between this study and ours is, that for this study the\nresearchers wanted to analyze the changes of search results over time - which\nis the reason why the plugin searched Google every 4 hours - while we are\nonly interested in one search result per person.\nSome other noticeable di\u000berences between this research and ours are that\nfor this study, we only looked at the \"organic\" search results from Google,\nthis means no ads or featured stories but only the results returned by the\nsearch query, while Kra\u000bt, Gamer, and Zweig also included top stories in\ntheir search results, and looked at the results from Google News. They only\nfocused on results from Germany while in this study the focus is on results\nfrom the Netherlands. The last di\u000berence, which is an extension from the\nprevious, is that they focused on websites in German while our research is\nfocused on websites in Dutch.\nIn the end, Kra\u000bt, Gamer, and Zweig came to the conclusion that at least\nfor search results from the same country, and using the same language,\nan algorithm-based \flter bubble isn't present due to the su\u000ecient overlap\nin search results. They also noted that users that received non-German\nwebsites in their search results, which is probably due to search language\nsettings, had some overlap with each other, which means that there are signs\nthat a \flter bubble could exist. They mentioned that this is unavoidable\nhowever, due to the di\u000berence in languages.\nFinally, they mention a chicken-and-egg problem with investigating the exis-\ntence of a \flter bubble on Google due to their market share. Because Google\nis the most popular search engine in Germany, and a sizeable amount of vis-\nits to a website are achieved through Google, it's not known how much of a\nwebsites tra\u000ec is only due to Google, and thus the results of their study do\nnot represent a popularity measure independent of Google's algorithm.\n3.2 Location, Location, Location: The Impact of\nGeolocation on Web Search Personalization\nThis paper[7] was written by researchers from Brown University and North-\neastern University in the US about how important location is for the person-\nalization on Google Search results. To measure this, they divided both their\nqueries and locations into 3 categories: local, politicians, and controversial\nfor the queries, and county, state, and national for locations. The queries are\npretty self-explanatory, but the locations are a bit more complicated. For\n9\neach location category, they chose the centroid of a set of location divisions\nwithin that category to measure the personalization on that level. For the\nnational level they chose the centroids of 22 random states, for the state\nlevel they chose the centroids of 22 counties within the state, and for the\ncounty level they chose the centroids of 15 voting districts in the county. By\ndoing this they could check how much in\ruence distance had on di\u000bering\nsearch results.\nThis research is quite similar to ours with only a few major di\u000berences. The\nmain ones being the slightly di\u000berent query categories and the main focus\nof the study. While they are interested in personalization of Google search\nresults, they're mostly interested in the e\u000bect of location on it, not person-\nalization in general. Furthermore, this research was done in the US while\nwe're doing ours in the Netherlands. This \fnal di\u000berence is especially im-\nportant due to the di\u000berent political systems, the US has a two-party system\nwhile the Netherlands has a multi-party system. This di\u000berence in political\nsystems combined with a much more polarized political landscape in the US\ncompared to the Netherlands, makes it di\u000ecult to draw useful conclusions\nfrom this research for the Netherlands.\nThe main conclusion of their paper is that just location isn't very in\ruential\non the personalization of general search queries like politicians and contro-\nversial topics but that it does have a great e\u000bect on queries that search for\nlocations, with a greater e\u000bect when comparing search results from farther\naway.\n3.3 Measuring Political Personalization of Google\nNews Search\nIn this paper[9] researchers from three American universities studied the\ne\u000bects of search history on the personalization of search results on Google\nNews. They did this by creating 3 di\u000berent pro\fles: An anti-immigration\npro\fle, a pro-immigration pro\fle, and a control pro\fle. They did this by\nusing fresh installs of the Firefox browser, and using the anti-immigration\npro\fle to access links tweeted by an anti-immigration Twitter account, the\npro-immigration pro\fle to access links tweeted by a pro-immigration Twit-\nter account, and \fnally the control pro\fle didn't access any links at all.\nAfter training all pro\fles, they searched for 10 policy issues and used 5 dif-\nferent search terms for each policy, for example for the policy issue Veterans\nthey used the search terms `Support our Veterans', `Veteran a\u000bairs', `Veter-\nans', `Veteran bene\fts', and `PTSD'. Since they had control over all the pro-\n\fles that they built, they con\fgured Google to return 100 search results for\n10\neach query. After collecting all the search results, they compared the three\npro\fles in two ways: the \frst was by calculating the intersections of the sets\nof search results for every query, and using those to see the di\u000berences be-\ntween the lists, and the second was by computing the Damerau-Levenshtein\ndistance to see how much deletions, insertions, and substitutions are needed\nto transform the search results of one pro\fle into the search results of an-\nother pro\fle.\nThis research is almost identical to our research in regards to the two com-\nparison methods that they use: the di\u000berence measure they use is the op-\nposite of the similarity measure that we use, and their edit distance is cal-\nculated in the exact same way.\nThere are still quite a decent amount of di\u000berences between the two stud-\nies. While our study uses the search results of real people these researchers\ntrained three di\u000berent \\pro\fles\" to get di\u000berent search results by letting\nthem read news articles which hyperlinks were posted by two Twitter ac-\ncounts: one with a pro-immigration and another with an anti-immigration\nstance. After they trained their three pro\fles, they used them to search\nfor the topics they selected on Google News, while we had people use regu-\nlar Google search. Furthermore, because the researchers used Google News\nthey only received results from newspapers, which meant that every website\nthey found had a certain political bias, which they estimated with the use of\nmediabiasfactcheck.com , which provided the researchers with the politi-\ncal bias of 1540 di\u000berent domains on a 5-point scale, which the researchers\ngave di\u000berent values to, and consisted of left with -100, left-center with -50,\ncenter with 0, right-center with 50 and right with 100. This bias was then\nused to calculate the political bias of the search terms where the di\u000berence\nbetween the pro and anti immigration pro\fle was higher than 5%, which\nresulted in a total of 9 search terms. To calculate this, they simply added\nup the di\u000berent scores of all domains found in both the search results, and\nin the list of mediabiasfactcheck.com . From this, they found that search\nterms that received the most personalization tend to get results that rein-\nforce the opinion of the person searching for that term.\nIn the end the researchers concluded that there is signi\fcant personalization\nbased purely on browsing history, and that these personalized results tend\nto reinforce the opinions that Google saw in the browsing history.\n11\nChapter 4\nResearch\nAs mentioned in the introduction, this research set out to gather the search\nresults of nearly 200 people split into two equal groups to investigate the\npersonalization of Google search results. This turned out to be 181 people\nwith 92 in the controversial group, and 89 in the non-controversial group.\nThis chapter will delve into the details of this research.\n4.1 Questionnaire\nThe foundation of this research is based on two questionnaires consisting\nof 3 general questions, and either 5 controversial search queries, or 5 non-\ncontroversial search queries. Both of these questionnaires can be found in\nthe Appendix A.\n4.1.1 Why a questionnaire\nThere were two primary reasons why we chose a questionnaire was to collect\nthe necessary data: it was easier to both process and collect the data with\na questionnaire than with other methods like browser extensions. By using\na Google Form all the data gets automatically imported to an Excel sheet\nwhich are easy to process with a Python script. Regarding the collection of\ndata compared to a browser extension a questionnaire is more user friendly,\nsince it doesn't require installing anything, and a questionnaire is easier to\nmake than a browser extension.\n4.1.2 Why these questions\nThe general questions used in this questionnaire asked about the age, general\nlocation, and which political party they voted for in the last general election.\nThese questions were used to both give context for certain search results,\nand to see if di\u000berent demographics had di\u000bering amounts of personalization.\n12\nInitially the questionnaires were combined into one big questionnaire but due\nto the size of the answers they couldn't be submitted so the questionnaire\nwas split into two, with one having the controversial search queries, and the\nother the non-controversial search queries. We use both controversial and\nnon-controversial queries to check if the degree of personalization is di\u000berent\nbetween controversial and non-controversial topics. These queries are listed\nin table 4.1 below.\nControversial Query Non-Controversial Query\nAbortus tot hoeveel weken? Brood bakken recept\nOorzaken klimaatverandering Honden namen\nZwarte piet of roetveegpiet? Wat is het grootste bot in het menselijk lichaam?\nGevaren vaccinaties Hoeveel van een komkommer is water?\nGevolgen illegale immigratie Hoeveel mensen wonen er in Nederland?\nTable 4.1: The Controversial and Non-Controversial queries\nThe controversial queries were chosen to be about topics where there are\ntwo opposing opinions and be general enough that almost everybody in the\nNetherlands would have an opinion on it. With these restrictions the topics\nof abortion, climate change, Black Pete, vaccinations, and illegal immigra-\ntion were chosen.\nThese topics had to be phrased in such a way to be as neutral as possible\nas to not give preference to either advocates, or opponents of the subject\nin question. This is because suggestive search queries would in\ruence the\nsearch results we would get, e.g. phrasing the query about Black Pete as:\n\\Why is Black Pete racist?\" already implies that Black Pete is racist and\nwould thus lead to more results against Black Pete than the used phrasing of\n\\Black Pete or Soot Pete?\". By keeping the phrasing as neutral as possible\nthe probability that di\u000bering search results are caused by personalization by\nGoogle are increased.\nThe non-controversial queries were chosen to be about at least one of three\nthings: topics that are either factual, topics where there aren't vastly dif-\nferent opinions between two sides, or not location based. With these re-\nstrictions the topics of bread recipes, dog names, largest bone in the human\nbody, percentage of water in a cucumber, and the population of the Nether-\nlands were chosen.\nFor these queries the phrasing isn't as important as the controversial topics,\nsince these queries were either about facts, i.e. \\What is the largest bone\nin the human body?\" or about topics that don't have vastly di\u000berent opin-\n13\nions, i.e. \\Dog names\". Thus, the probability that someone would get vastly\ndi\u000berent results just because of the phrasing of the question was slim to none.\nOur hypothesis is twofold: First we hypothesize that search results are per-\nsonalized, and secondly that personalization has more in\ruence on contro-\nversial queries than non-controversial queries. This higher in\ruence for con-\ntroversial queries would result in more unique results for these controversial\nqueries. This is our hypothesis because topics that have two opposing opin-\nions would be easier to personalize than factual topics.\n4.1.3 Distributing questionnaire\nThe questionnaires were distributed through Facebook and Surveyswap.io1,\na website for exchanging surveys. These were chosen since Facebook and\nSurveyswap had the highest amount of people willing to \fll in the ques-\ntionnaires. Because there are two questionnaires a webtool2was used to\nrandomly redirect to one of the two to ensure that both, constantly had\nroughly an equal amount of responses.\n4.2 Data processing\nBecause the responses to the surveys were copy and pasted Google search\nresults, it needed to be processed to retrieve the websites from the answer\n\felds.\n4.2.1 Python script\nTo extract the addresses of the websites a Python script was made to \flter\nthem from the text and put them in a list. Because there wasn't a general\nform for the addresses, the \fltering was a bit more complicated than \frst\nanticipated. Not all websites found in the search results used \\http\" or\n\\https\" in their pre\fx, which meant we couldn't \flter based on that. Since\nthere were also multiple top-level domains, just \fltering everything that\ndidn't end in \\.com\" or \\.nl\" wasn't an option either. This meant that\nthe best possible way of \fnding all the websites was to split every response\ninto a list with each word being a single entry in that list. Then \fnding\nfor \\words\" that contained text followed by a `.' followed by text again.\nThis meant that every website was \fltered out, but this also meant that\nsome websites were counted twice, and some entries weren't websites due\nto typos in the description on the search results page. Unfortunately, these\nhad to be \fltered out manually since there wasn't any way to di\u000berentiate\nbetween typo's in the description, websites having their address in their\n1https://surveyswap.io/\n2https://allocate.monster/\n14\ndescription, and websites without \\http\" or \\https\". Luckily these were\nexceptions and not the norm, so this wasn't as time consuming as manually\n\fltering everything.\n4.3 Website standings\nAfter getting the results we tried to give all websites either a left, right,\nor neutral rating. These ratings were based on the entire website, and not\nthe speci\fc page that was linked in the results, since the speci\fc web pages\nweren't included in the copied text, and using ratings for speci\fc web pages\ncould lead to con\ricting ratings for the same website. After giving each\nwebsite a rating, they were compared to the political party a user voted\nfor. If the ratings of the websites and the political party's stances were very\nsimilar for a lot of people, it could suggest the existence of a \flter bubble,\nwhile a lack of similarity could suggest the opposite.\n4.4 Comparing search results\nFinally, to measure the amount of personalization of a user's search results,\nall users were compared to each other with the Levenshtein distance and a\nsimilarity function.\n4.4.1 Levenshtein distance functioning\nThe Levenshtein distance works as follows: when given two lists it compares\nthe two by seeing how much single-character edits are needed to transform\none of the lists into the other. Single-character edits are deletions, insertions\nand substitutions. Because all lists have the same length only substitutions\nare used for the transformations. If two lists are similar, it will have a low\nLevenshtein distance since it doesn't need a lot of single-character edits to\ntransform one into the other, and if two lists are completely di\u000berent it needs\na lot of single-character edits which gives a high Levenshtein distance.\nFor example, if we have two lists A= [1;2;3;4] and B= [1;3;2;4] the\nLevenshtein distance between AandBis 2 out of a maximum of 4 since we\nmust substitute the value at B[1] with 2 and the value at B[2] with 3.\n4.4.2 Why Levenshtein distance\nThe Levenshtein distance was chosen for comparing the lists of search results\nbecause it is an easy way to see how di\u000berent two lists are. This is done by\njust using the Levenshtein function from the TextDistance library. Because\n15\nonly substitutions are used in this instance, the resulting Levenshtein dis-\ntance is the amount of websites that are in the exact same position in both\nlists.\n4.4.3 Similarity\nThe similarity function used is a very simple one, it checks how many ele-\nments appear in both of the lists no matter the position of those elements.\nFor example, if we have two lists A= [1;2;3;4] and B= [3;2;1;5] the\nsimilarity between AandBis 3 out of a maximum of 4 since 1, 2 & 3 are\nin both lists.\n4.4.4 Why similarity\nWe use a combination of Levenshtein and similarity because just one of the\ntwo wouldn't accurately represent the similarity of 2 lists. For example,\nwhile the lists [1 ;2;3;4] and [2 ;1;4;3] are very similar the resulting Leven-\nshtein distance would be 4 because even though the lists contain the same\nelements, they aren't in the same positions. If you'd only look at the Lev-\nenshtein distance one would think that they're completely di\u000berent because\nLevenshtein doesn't take into account the other elements of the list when\nlooking at a speci\fc element. By adding the similarity function, we'd see\nthat both lists contain the exact same elements and are thus quite similar.\n16\nChapter 5\nResults\nAs mentioned in the previous chapter, this research consisted of two surveys.\nOne with controversial search queries, and one with non-controversial search\nqueries.\n5.1 Survey demographics\nThis section will give a brief overview of the demographics of the respon-\ndents.\n5.1.1 Personal information\nAt the start of both surveys respondents were asked to give 3 pieces of per-\nsonal information: their age range, the province that they live in, and which\npolitical party they voted for in the general election of 2017.\nThese 3 categories were chosen to see if any of these categories had a large\nin\ruence on the degree of personalization. Age was chosen mainly as a con-\ntrol category because if search results are heavily personalized it wouldn't\nbe done based on someone's age. Location was chosen because Google insin-\nuates that most of their personalization is based on location, e.g. searching\nfor football in the US and the UK give vastly di\u000berent results. Finally po-\nlitical a\u000eliation was chosen, since \fltering and personalizing search results\nto only show what the user wants to see based on their political a\u000eliation\nwould be one of the most dangerous forms of personalization, because that\nway people will only see results agreeing with their opinion, and thus enter\na \flter bubble where other opinions aren't heard.\n17\nAge All Respondents (% of total) Used Respondents (% of total)\n<18 5 (5.4%) 0 (0%)\n18 - 24 52 (56.6%) 28 (56%)\n25 - 34 20 (21.7%) 16 (32%)\n35 - 44 6 (6.5%) 1 (2%)\n45 - 54 5 (5.4%) 3 (6%)\n>55 4 (4.3%) 2 (4%)\nTable 5.1: Ages of respondents in the controversial survey\nProvince All Respondents (% of total) Used Respondents (% of total)\nNorth Holland 19 (20.7%) 9 (18%)\nSouth Holland 12 (13%) 5 (10%)\nZeeland 2 (2.2%) 1 (2%)\nNorth Brabant 13 (14.1%) 5 (10%)\nLimburg 4 (4.3 %) 3 (6%)\nFriesland 1 (1.1%) 0 (0%)\nGelderland 25 (27.2%) 19 (38%)\nDrenthe 0 (0%) 0 (0%)\nOverijssel 4 (4.3%) 2 (4%)\nFlevoland 0 (0%) 0 (0%)\nUtrecht 6 (6.5%) 4 (8%)\nGroningen 3 (3.3%) 2 (4%)\nAbroad 3 (3.3%) 0 (0%)\nTable 5.2: Location of respondents in the controversial survey\n18\nPolitical Party All Respondents (% of total) Used Respondents (% of total)\nVVD 18 (19.6%) 9 (18%)\nPVV 1 (1.1%) 1 (2%)\nCDA 5 (5.4%) 2 (4%)\nD66 23 (25%) 13 (26%)\nGL 15 (16.3%) 10 (20%)\nSP 2 (2.2%) 1 (2%)\nPvdA 2 (2.2%) 1 (2%)\nCU 2 (2.2%) 2 (4%)\nPvdD 5 (5.4%) 4 (8%)\n50PLUS 0 (0%) 0 (0%)\nSGP 0 (0%) 0 (0%)\nDENK 0 (0%) 0 (0%)\nFvD 4 (4.3%) 2 (4%)\nNone 15 (16.3%) 5 (10%)\nTable 5.3: Political a\u000eliation of respondents in the controversial survey\n5.1.2 Controversial survey\nThe controversial survey was \flled in a total of 92 times, but due to incor-\nrectly \flled in surveys, either by using the same search results for all queries\nor not answering the questions at all, nearly half of the surveys weren't us-\nable and, in the end, only 50 of the 92 surveys were usable.\nThe \frst thing we notice is that in each category a few options are over-\nrepresented with just 1 to 3 options accounting for more than half of the\nrespondents in all categories. This is due to the fact that this survey was\nmainly spread through Facebook contacts and because most of these people\nare young, progressive students, this group is over-represented in this sur-\nvey. For the speci\fc categories this means the following: the age group of\n18 - 24 accounts for more than half of the respondents. The provinces of\nGelderland, North Holland, South Holland and North Brabant, all of which\nhave popular universities, account for more than 75% of the total amount\nof responses. Finally, VVD, D66, and GroenLinks, all quite popular parties\nfor students, account for more than 60% of the amount of responses.\nBecause of this, options with less respondents might suggest either large\ndi\u000berences or small di\u000berences, while the opposite might be true due to the\nsmall sample size.\n19\nAge All Respondents (% of total) Used Respondents (% of total)\n<18 2 (2.2%) 1 (1.6%)\n18 - 24 50 (56.2%) 37 (59.7%)\n25 - 34 26 (29.2%) 15 (24.2%)\n35 - 44 1 (1.1%) 1 (1.6%)\n45 - 54 3 (3.4%) 2 (3.2%)\n>55 7 (7.9%) 6 (9.7%)\nTable 5.4: Ages of respondents in the non-controversial survey\nProvince All Respondents (% of total) Used Respondents (% of total)\nNorth Holland 14 (15.7%) 7 (11.3%)\nSouth Holland 17 (19.1%) 13 (21%)\nZeeland 1 (1.1%) 0 (0%)\nNorth Brabant 10 (11.2%) 4 (6.5%)\nLimburg 2 (2.2%) 1 (1.6%)\nFriesland 4 (4.5%) 4 (6.5%)\nGelderland 28 (31.5%) 22 (35.5%)\nDrenthe 0 (0%) 0 (0%)\nOverijssel 4 (4.5%) 4 (6.5%)\nFlevoland 0 (0%) 0 (0%)\nUtrecht 2 (2.2%) 2 (3.2%)\nGroningen 5 (5.6%) 5 (8.1%)\nAbroad 2 (2.2%) 0 (0%)\nTable 5.5: Location of respondents in the non-controversial survey\n20\nPolitical Party All Respondents (% of total) Used Respondents (% of total)\nVVD 14 (15.7%) 11 (17.7%)\nPVV 0 (0%) 0 (0%)\nCDA 2 (2.2%) 2 (3.2%)\nD66 29 (32.6%) 20 (32.3%)\nGL 19 (21.3%) 14 (22.6%)\nSP 0 (0%) 0 (0%)\nPvdA 4 (4.5%) 3 (4.8%)\nCU 2 (2.2%) 1 (1.6%)\nPvdD 2 (2.2%) 0 (0%)\n50PLUS 0 (0%) 0 (0%)\nSGP 0 (0%) 0 (0%)\nDENK 1 (1.1%) 0 (0%)\nFvD 6 (6.7%) 4 (6.5%)\nNone 10 (11.5%) 7 (11.3%)\nTable 5.6: Political a\u000eliation of respondents in the non-controversial survey\n5.1.3 Non-controversial survey\nThe non-controversial survey was \flled in a total of 89 times. Here there was\nalso a problem with wrongly \flled in surveys which meant that 27 surveys\nweren't usable meaning that in the end 62 of the 89 surveys were used.\nJust as in the controversial survey, because of the way the surveys were\nspread the young, progressive student is also over-represented in this survey.\n5.2 Websites\nThis section will give a brief overview of the websites found in the Google\nsearch results.\n5.2.1 General\nIn total 131 distinct websites were found with a total of 5370 links. Of these\n5370 links 2412 were from the controversial survey, and 2958 were from the\nnon-controversial survey. These 5370 links were divided over the 560 di\u000ber-\nent lists of search results pages, with each search page having between 8 and\n12 results. Due to this, before doing the Levenshtein distance comparison,\neach list of websites got scaled down to just the \frst 8 results of the search\n21\nresults page to better compare the di\u000berent lists with each other. This re-\nsulted in 113 distinct websites and 4480 links to these websites.\nAs mentioned in the previous chapter, a quantitative comparison was done\nby using the Levenshtein distance, and the similarity between lists. This re-\nsulted in an average Levenshtein distance of 4 :01 for the websites found in the\ncontroversial lists, and 4 :28 for the websites found in the non-controversial\nlists, and an average similarity of 6 :14 for controversial lists, and 6 :07 for\nnon-controversial lists. Because these comparisons were only used on the\ntrimmed lists containing 8 websites, the values for these comparisons range\nfrom 0 to 8 for both the Levenshtein distance, and the similarity. For similar-\nity a higher value meant that the 2 compared lists were more similar, while\na higher value for the Levenshtein distance meant that the 2 compared lists\nhad less elements on the same position.\nLevenshtein distance\nAs mentioned in section 4.4 a quantitative comparison was done by comput-\ning the Levenshtein distance for both the controversial and non-controversial\nlists. For the controversial lists the average Levenshtein distance turned out\nto be 4 :01, and for the non-controversial lists the average was 4 :28.\nThis means that on average, less than half of the search results were the\nsame website in the same position, when compared to other search results\nfor that same query.\nSimilarity\nIn addition to the Levenshtein distance a quantitative comparison for the\nsimilarity was done for both lists as well. For the controversial lists the\naverage similarity was 6 :14 and for the non-controversial lists it was 6 :07.\nFrom this we can conclude that, on average, less than 2 websites of the\nsearch results were unique, when compared to the search results of another\nperson for that same query.\n5.2.2 Controversial websites\nIn this section we will take a look at some interesting results found in the\ncontroversial survey. Before conducting our research, our hypothesis was\nthat, especially for controversial topics, a noticeable di\u000berence would be\nseen between the search results of di\u000berent individuals. For example, we\nthought that for the subject of abortion there would be a clear distinction\nbetween people that vote for more pro-life parties, and people that vote for\nmore pro-choice parties. Which would result in a fairly high Levenshtein\n22\nvalue and a fairly low similarity value. What we actually saw was quite the\nopposite, especially for the topic of abortion: here the average Levenshtein\ndistance was just 2 :7 and the average similarity was 7 :1 which means that,\nout of 2 lists of 8 websites, more than 7 of them were in both lists, with more\nthan 5 of those in the exact same position. This suggests that for the topic\nof abortion most people regardless of their personal opinion about abortion\nwould get the same search results.\nThis is also con\frmed by the raw data: out of the total 12 websites that were\nfound in the search results of the query: \\Abortus tot hoeveel weken?\" 6 of\nthem were found in every query. While in general websites that portrayed a\nmore positive opinion on abortion were more frequent, there was no de\fning\nattribute that was the cause of either seeing or not seeing a website that was\npro-life.\nAnother category that was surprising were the search results of the ques-\ntion: \\Gevaren Vaccinaties\", here 7 out of 17 websites were in nearly all\nsearch results, 4 of them being for vaccination and 3 of them against. Of\nall 499 links, which also includes the links that weren't in one of the \frst 8\npositions, found from the vaccination query, 231 of those were to websites in\nfavour of vaccination, while 172 of them were to websites either against or\nskeptical about vaccination. While having 34 :3% more links to websites in\nfavour of vaccination shows a clear advantage for pro-vaccination websites\noverall, since more than two thirds of users only look at the \frst 5 results of\na search results page[11], and the \frst 5 results have a relatively balanced\namount of websites that are either for or against vaccination.\nThis means that whether someone is for or against vaccinations, they always\nsaw websites that agreed and disagreed with them. And just as with the\nabortion query there isn't a clear distinct attribute that indicates whether\nsomeone will have mostly pro-vaccination or anti-vaccination websites.\nThe last surprise for the controversial websites was that websites, with a\nclear leaning to either the left or the right, didn't just show up in the search\nresults of users with the same political orientation. This is evident with\nthe websites joop.bnnvara.nl which is a left leaning opinion website[13],\nand jalta.nl which is at the opposite end of the spectrum[14]. If a \flter\nbubble is present, one would assume that mostly right leaning users would\nseejalta.nl in their search results, and mostly left leaning users would\nseejoop.bnnvara.nl , but this isn't the case. Of the 39 users that had\njalta.nl in their search results only 26% of users voted for a right leaning\nparty, this was less than the amount of users that saw the website and voted\nfor either a left leaning or a central party, 33% and 28% respectively. And\nof the 11 users that had joop.bnnvara.nl in their search results only 18%\n23\nwas left leaning with right leaning users being 45% and central users also\naccounting for 18%. For both these two websites the other users either didn't\nremember or hadn't voted in the previous election.\n5.2.3 Non-controversial websites\nIn this section we will take a look at some interesting results found in the\nnon-controversial survey. As said in the previous section our hypothesis\nwas that a noticeable di\u000berence would be seen between search results of\ndi\u000berent individuals for the controversial topics but not as much for the\nnon-controversial topics.\nThe \frst part of our hypothesis was con\frmed because roughly 25% of search\nresults were personalized when compared to other search results. Further-\nmore the average similarity of the non-controversial lists was higher than the\naverage similarity of the controversial lists which would suggest that the sec-\nond part of our hypothesis was also true. This higher similarity meant that\nit was quite a surprise that the Levenshtein distance for non-controversial\nqueries was higher than the Levenshtein distance for controversial queries.\nThis meant that while the non-controversial queries are less diverse when it\ncomes to the di\u000berent websites that they show in the search results, they\nare more diverse when it comes to the order in which these websites appear.\nThis slightly higher similarity could be explained by the fact that in the\n310 search results pages of the non-controversial queries only 60 di\u000berent\nwebsites were found, while the controversial queries contained 61 di\u000berent\nwebsites with 250 search results pages.\nFor example the search query: \\Hoeveel van een komkommer is water?\"\nhad only 10 di\u000berent websites in the search results with 4 of those 10 being\npresent in all results, with one of those being present twice in almost all\nresults, 2 of them were present in all but 1 list each. This resulted in very\nhigh similarity of 7 :09 but it still had a fairly high Levenshtein distance\nof 3:81 especially when compared to the results for the controversial query\nabout abortion which had an almost identical similarity of 7 :10 but had a\nLevenshtein distance of only 2 :74.\n5.3 Statistical signi\fcance\nTo check if the results that we found in our research are statistically signi\f-\ncant we performed an independent two-tailed t-test to calculate whether the\ndi\u000berences we measured between normal and controversial queries are actu-\nally statistically signi\fcant and not that they just happen to be di\u000berent.\n24\n5.3.1 T-test\nTo \fnd this out we used an independent two-tailed t-test on the Levenshtein\ndistances for all search results. First the reason we do an independent, and\nnot a dependent t-test is because the two groups of test subjects are un-\nrelated to each other, since people only \flled in 1 of the 2 questionnaires.\nSecond, the reason why we do a two-tailed instead of a one-tailed test is be-\ncause we aren't just interested in if normal search queries have more unique\nsearch results than controversial search queries, but also if normal search\nqueries have less unique search results than controversial search queries be-\ncause both of these outcomes will suggest that there is a di\u000berence in the\nsearch results between normal and controversial search queries.\nWe performed the t-test by comparing all search results of normal search\nqueries with each other, and all search results of controversial search queries\nwith each other, and calculating the Levenshtein distance between them\nwhich we then used to calculate both the mean Mand the standard devia-\ntionSD. This led to 9455 comparisons for normal search queries and 6125\ncomparisons for controversial search queries, and the following results from\nthe t-test:\nFor the 9455 normal search results comparisons ( M= 4:28,SD= 1:68)\ncompared to the 6125 controversial search results comparisons ( M= 4:01,\nSD= 1:69) the normal search results displayed a signi\fcantly higher degree\nof uniqueness, t(13048 :84) = 9 :71; p=:000.\nThese results suggest that whether you search for a controversial or a non-\ncontroversial query does indeed have an e\u000bect on the uniqueness of your\nsearch results. With normal search queries requiring 4 :28 substitutions to\ntransform the results from one person into the results of someone else com-\npared to controversial search queries which require only 4 :01 substitutions.\n5.3.2 Cause\nWhile these results prove that there is a statistical di\u000berence between normal\nand controversial search queries with normal search queries resulting in more\nunique search results, they don't explain why this di\u000berence exist in the \frst\nplace. If a \flter bubble does indeed exist on Google.nl one would assume\nthat controversial search queries would have a higher degree of uniqueness\nthan normal search queries because someone who is left leaning would get\nwildly di\u000berent search results than someone who is more right leaning on\nsubjects where these two people have vastly di\u000bering opinions. So, you could\nconclude from this that there isn't a \flter bubble present on Google.nl due\nto the fact that more normal search queries had more unique search results\nthan controversial search queries. However, what might be happening is\n25\nthat Google isn't making relatively small \flter bubbles for left and right\nleaning people but one big bubble that contains everybody.\n5.3.3 Interference by Google\nIn November of 2019 the Wallstreet Journal published an article regarding\nthe practices at Google related to search results1. In it the writers alleged\nthat Google tries to manipulate search results in multiple ways. For example\nthey compared the organic search results (the results that aren't placed on\nthe page due to ads, newsreel or other snippets) of Google, Bing, and Duck-\nDuckGo for the search term of abortion for 17 days between July and August\nof 2019, and found that in 93% of the total amount of search results on the\n\frst page of Google were from Planned Parenthood, a nonpro\ft abortion\nrights organization based in the US, while for Bing and DuckDuckGo these\npercentages were only 14% and 16% respectively. While a spokeswoman\nfor Google said that it doesn't make use of any ranking implementations to\npromote Planned Parenthood, this does seem like such a big di\u000berence that\nit can't be a coincidence.\nA way that Google in\ruences search results without directly tinkering with\nthe organic search results is by changing what users see on a search results\npage. Over the years Google has added more and more content besides the\nactual search results like ads, a Google maps to point to the location of\nrelevant search results, or news reels to name a few. Because these addi-\ntions to the web page aren't part of the \"real\" search results and most people\nclick on the \frst link that appears on their screen a company that pays more\nto be featured in an ad will receive more tra\u000ec than a company that doesn't.\nThese and other tactics mentioned in the article by the Wallstreet Journal\nsuggest that Google tries to both directly, with the use of content moder-\nation and blacklists, and indirectly, with the previously mentioned tactics,\nin\ruence which content users see not by deciding what certain groups of\nusers get to see but what all users get to see and thus creating one big \flter\nbubble for all users instead of multiple smaller ones for particular groups.\n1How Google interferes with its search algorithms and changes your results\n26\nChapter 6\nConclusions\nWithout access to the algorithms that Google uses to give users their search\nresults it is very di\u000ecult, if not impossible, to give a de\fnitive answer to the\nquestion: \\Does Google create \flter bubbles in their results?\". And while\nGoogle will always deny that they're moderating their search results, which\nin turn creates \flter bubbles, there is evidence as mentioned in the previous\nchapters that suggests the opposite.\nWe have shown in section 5.3 that the personalization we found in search\nresults is indeed statistically signi\fcant. And while the more unique search\nresults turned out to belong to the normal search queries, which wasn't what\nwe had hypothesized it does show that as a user you don't have complete\ncontrol over what will be served to you by Google when using their search\nengine.\nHowever, we didn't \fnd a clear reason as to why the non-controversial search\nresults ended up being more diverse than the controversial ones. As we de-\nscribed in sections 5.3.2 and 5.3.3 this could be due to Google \fltering more\nsearch results for controversial topics in general, but since that wasn't in the\nscope of this research we can't make any substantial claims about this.\nAll in all more research should be done in the future to determine how much\nGoogle actually personalizes someone's search results and if it's, like Google\nclaims, mostly to \flter out low quality web results, or, as others frame it, to\nsubconsciously in\ruence people by cherry picking what they're seeing.\n27\nChapter 7\nFuture Work\nIn this chapter we will go over certain topics that fell outside the scope of this\npaper but are related to it. In section 7.1 we will discuss comparing search\nresults between search engines to see if this problem is speci\fc to Google or\nif it's more widespread. In section 7.2 we will discuss getting a more diverse\nand representative test population to improve both the quantitative, and\nthe qualitative conclusions we can get from this.\n7.1 Search results between search engines\nJust as the journalists at the Wallstreet Journal1did as mentioned in section\n5.3.3, checking the di\u000berences for certain search queries between di\u000berent\nsearch engines, to see just how much impact using a di\u000berent search engine\ncould have, could be an interesting topic for a paper to further investigate\nthe existence of \flter bubbles on search engines.\n7.2 More diverse test population\nAs mentioned in sections 5.1.2 and 5.1.3, each of the three categories had a\ndisproportionate representation for certain groups in their speci\fc category.\nThis made the results obtained for the smaller groups less useful, especially\nfor groups that had only 2 or 3 respondents.\nFor example, the controversial questionnaire was only \flled in by 5 people\nin the age range 45 - 54, and only 3 of those were used. This group ended up\nwith a similarity of 7 :86 and a Levenshtein Distance of 1 :06. Now, because\nof the small pool of test subjects in this age range, there is no de\fnitive\nconclusion to make about why this result varies quite signi\fcantly from the\naverage. It could be a coincidence, or it could also be the norm for how\n1How Google interferes with its search algorithms and changes your results\n28\nsimilar the search results are for people between the age of 45 - 54, but it\ncan also be due to the other 2 attributes. As it turns out, 2 out of the 3\ndata subjects in this age range live in Gelderland, and voted for D66 which\nmeans that it's unlikely that these very similar search results are solely due\nto age, but mostly because of the similarities in all 3 categories between the\ndata subjects.\nA similar study with a more diverse group of data subjects could prevent\nthese kinds of outliers in the data by distributing the population more evenly\nover the di\u000berent categories, and thus preventing certain categories being\ndominated by a very speci\fc group.\n29\nBibliography\n[1] Judit Bar-Ilan, Kevin Keenoy, Eti Yaari, and Mark Levene. User rank-\nings of search engine results. Journal of the American Society for In-\nformation Science & Technology , 58(9):1254 { 1266, 2007.\n[2] Abhinandan S Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram.\nGoogle news personalization: scalable online collaborative \fltering. In\nProceedings of the 16th international conference on World Wide Web ,\npages 271{280, 2007.\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBert: Pre-training of deep bidirectional transformers for language un-\nderstanding, 2019.\n[4] Zhicheng Dou, Ruihua Song, and Ji-Rong Wen. A large-scale evaluation\nand analysis of personalized search strategies. In Proceedings of the 16th\ninternational conference on World Wide Web , pages 581{590, 2007.\n[5] Aniko Hannak, Piotr Sapiezynski, Arash Molavi Kakhki, Balachander\nKrishnamurthy, David Lazer, Alan Mislove, and Christo Wilson. Mea-\nsuring personalization of web search. In Proceedings of the 22nd Inter-\nnational Conference on World Wide Web , WWW '13, page 527{538,\nNew York, NY, USA, 2013. Association for Computing Machinery.\n[6] Anik\u0013 o Hann\u0013 ak, Piotr Sapie_ zy\u0013 nski, Arash Molavi Khaki, David Lazer,\nAlan Mislove, and Christo Wilson. Measuring personalization of web\nsearch, 2017.\n[7] Chloe Kliman-Silver, Aniko Hannak, David Lazer, Christo Wilson, and\nAlan Mislove. Location, location, location: The impact of geolocation\non web search personalization. In Proceedings of the 2015 Internet\nMeasurement Conference , IMC '15, page 121{127, New York, NY, USA,\n2015. Association for Computing Machinery.\n[8] Tobias D. Kra\u000bt, Michael Gamer, and Katharina A. Zweig. What did\nyou see? personalization, regionalization and the question of the \flter\nbubble in google's search engine, 2018.\n30\n[9] Huyen Le, Raven Maragh, Brian Ekdale, Andrew High, Timothy\nHavens, and Zubair Sha\fq. Measuring political personalization of\ngoogle news search. In The World Wide Web Conference , pages 2957{\n2963, 2019.\n[10] Eli Pariser. The \flter bubble: What the Internet is hiding from you .\nPenguin UK, 2011.\n[11] Advanced Web Ranking. Advanced web ranking, 2019.\n[12] Bin Tan, Xuehua Shen, and ChengXiang Zhai. Mining long-term search\nhistory to improve search accuracy. In Proceedings of the 12th ACM\nSIGKDD international conference on Knowledge discovery and data\nmining , pages 718{723, 2006.\n[13] Eric van den Berg. Joop: Jouw online opinie pagina, Oct 2009.\n[14] Frank van Kolfschooten. Een ouderwets opiniemagazine voor het smart-\nphonetijdperk, Mar 2015.\n[15] Xinyu Xing, Wei Meng, Dan Doozan, Nick Feamster, Wenke Lee, and\nAlex C. Snoeren. Exposing inconsistent web search results with bob-\nble. In Michalis Faloutsos and Aleksandar Kuzmanovic, editors, Passive\nand Active Measurement , pages 131{140, Cham, 2014. Springer Inter-\nnational Publishing.\n31\nAppendix A\nAppendix\nA.1 Controversial Questionnaire\nAll pages of the controversial questionnaire that was used:\n32\n33\n34\nA.2 Non-controversial Questionnaire\nAll pages of the non-controversial questionnaire that was used:\n35\n36\n37", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Search personalization on Google. nl", "author": ["R Leferink", "E Herder", "H Oosterhuis"], "pub_year": "2021", "venue": "NA", "abstract": "With more and more people gaining access to the internet, search engines like Google gain  a more important role as the gatekeepers to information. With this role of gatekeeper also"}, "filled": false, "gsrank": 147, "pub_url": "https://www.cs.ru.nl/bachelors-theses/2021/Roland_Leferink___4557972___Search_personalization_on_Google.nl.pdf", "author_id": ["", "YHzcc8cAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:0l--BepO0jkJ:scholar.google.com/&output=cite&scirp=146&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0l--BepO0jkJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:0l--BepO0jkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.cs.ru.nl/bachelors-theses/2021/Roland_Leferink___4557972___Search_personalization_on_Google.nl.pdf"}}, {"title": "Proactive discovery of fake news domains from real-time social media feeds", "year": "2020", "pdf_data": "Proactive Discovery of Fake News Domains from Real-Time\nSocial Media Feeds\nZhouhan Chen\nNew York University\nzhouhan.chen@nyu.eduJuliana Freire\nNew York University\njuliana.freire@nyu.edu\nABSTRACT\nThe proliferation of web sites that disseminate fake news is a grow-\ning problem in our society. Not surprisingly, the problem of identi-\nfying whether a web page contains fake news has attracted substan-\ntial attention. However, the problem of discovering new sources of\nfake news has been largely unexplored. Timely discovery of such\nsources is critical to combat misinformation and minimize its poten-\ntial harm. In this paper, we present an automatic discovery system\nthat proactively surfaces fake news domains before they are flagged\nby humans. Our system operates in two-steps: first, it uses Twitter\nfeeds to uncover user co-sharing structures to discover political\nwebsites; then it uses a topic-agnostic classifier to score and rank\nnewly discovered domains. To demonstrate the effectiveness of our\nsystem, we conduct an experimental evaluation in which we collect\ntweets related to the 2020 presidential impeachment process in the\nUnited States, and show that not only our system is able to dis-\ncover new sites, but that a large percentage of these sites are indeed\npublishing fake news. We also design an integrated user interface\nto support fact-checkers and leverage their knowledge. Through\nthis interface, fact-checkers can visualize domain interaction net-\nworks, query domain fakeness score, and tag incorrectly predicted\nresults. Our proactive discovery system will expedite fact-checking\nprocess and can be a powerful weapon in the toolbox to combat\nmisinformation.\nCCS CONCEPTS\n\u2022Computing methodologies \u2192Cluster analysis ;\u2022Informa-\ntion systems\u2192Social networks ;Web searching and informa-\ntion discovery .\nKEYWORDS\nmisinformation, fake news discovery, social network analysis\nACM Reference Format:\nZhouhan Chen and Juliana Freire. 2020. Proactive Discovery of Fake News\nDomains from Real-Time Social Media Feeds. In Companion Proceedings of\nthe Web Conference 2020 (WWW \u201920 Companion), April 20\u201324, 2020, Taipei,\nTaiwan. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3366424.\n3385772\nThis paper is published under the Creative Commons Attribution 4.0 International\n(CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their\npersonal and corporate Web sites with the appropriate attribution.\nWWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan\n\u00a92020 IW3C2 (International World Wide Web Conference Committee), published\nunder Creative Commons CC-BY 4.0 License.\nACM ISBN 978-1-4503-7024-0/20/04.\nhttps://doi.org/10.1145/3366424.33857721 INTRODUCTION\nThe rise of fake news and the use of misinformation campaigns\nis an increasing threat to our society. Much research has been\ndevoted to improve our understanding of this problem, from how\nto detect whether an article contains fake information [ 4,17,18]\nto exploring how fake news are propagated [ 8,24]. However, the\nproblem of discovering new sources of misinformation has been\nlargely unexplored. Timely discovery of such sources is crucial\nfor combating fake news and minimizing their effects before they\nbecome too widespread on the Internet.\nIn this paper, we propose and implement a proactive fake news\ndomain discovery system that leverages unlabeled but structured\nreal-time social media data. The unit of detection of our discovery\nsystem is domain. We adopt the definition of fake news domains\nas used in [ 22]: a fake news domain is a web site \u201cthat entirely\nfabricates information, disseminates deceptive content, or grossly\ndistorts actual news reports.\u201d Our system discovers new suspicious\ndomains from one of the most active online platforms: Twitter. The\nintuition behind our approach is that domains that cover similar\ntopics will be tweeted/retweeted by similar users. We leverage\nTwitter feeds to create a domain interaction graph based on user\nco-sharing similarities [ 21]. To do so, we first map each domain\nto a set of Twitter users that tweet about the domain. We then\nconstruct an unweighted and undirected graph where each node is\na domain, and two nodes are connected if the jaccard similarity of\ntheir corresponding user sets is above a threshold. Given this graph,\nwe extract the largest connected component. We show that with\na proper similarity threshold, the largest connected component\ncontains more than 95% of domains from the input collection and\nthus is sufficient for further analysis.\nThe domains discovered are potential sources of fake news. User\ninput is needed to further classify the sites. Because human resource\nis limited, in order to help fact-checkers explore this information, we\nneed a robust detector to score and prioritize the unlabeled domains.\nDetecting domain fakeness is an active research area [ 4,17]. For our\nsystem, we adopt a topic-agnostic fake news classifier proposed\nby [2]. The classifier captures the style of fake news sites, rather\nthan the topic, as predicting future news topic is very difficult.\nWe evaluate the ability of our system to discover fake news by\ncollecting real-time tweets related to the 2020 process to \u201cimpeach\nDonald Trump\u201d. Because our tweet collection is fresh and unlabeled,\nwe design a novel framework to evaluate our system performance.\nWe introduce two parameters: one controls the domain similarity\nfor the unsupervised clustering component, and the other controls\nthe decision boundary for the supervised component. By tuning\nthose two parameters we can achieve different levels of precision\nand recall. We discuss guidelines for how to choose the best model\nconfiguration with systematic parameter tuning.\nWWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan Zhouhan Chen and Juliana Freire\nThere are two indispensable elements during the spread of a fake\nnews domain: the domain itself, and the social media accounts that\ntweet about the domain. Using our tweet corpus and supervised\nclassifier, we then proceed to answer the question: what are charac-\nteristics of Twitter accounts that share more fake news? We define\nafakeness score for each Twitter account, and separate accounts\ninto several buckets based on their scores. We find that collectively,\naccounts with high fakeness score are more likely to use pro-Trump\nphrases in their account descriptions. Our findings corroborate the\nresults reported by Bovet and Makse [1], who analyzed individual\nfake account descriptions.\nFinally, we describe a Web interface we designed for our system\nto support fact-checkers to both explore and actively label the\ndiscovered domains. The interface allows fact-checkers to both\nvisualize domain network and submit labels for unchecked domains.\nThe rest of the paper is organized as follows. Section 2 discusses\nrecent research in fake news. Section 3 details the components of\nour system. Section 4 shows a real-world use case of our system and\npresents a characterization of Twitter accounts that share fake news.\nWe discuss the limitations of our work in Section 5. We conclude\nthe paper in Section 6.\n2 RELATED WORK\nTo the best of our knowledge, ours is the first approach that attempts\nto address the problem of timely discovery of fake news sources.\nOur system combines unsupervised discovery, supervised detection,\nand visualization into a unified system.\nSupervised detection. The majority of fake news detection work\nrelies on supervised methods to label or score news sources. Exist-\ning detection methods focus on different modalities, such as text\n[11,14], image [ 12], or multi-modalities [ 7]. The granularity of de-\ntection also varies from sentence-level claim [ 11,14] to page-level\narticle [ 5] to a single domain [ 2]. Extensive summaries of features,\nmachine learning models and datasets used by different fake news\ndetectors are provided in [ 4,17,18]. Detection is a key component\nof a discovery system: once a suspicious site is found, we need to\nascertain whether it is a potential propagator of fake news. The\nunit of detection of our discovery system is domain and we use the\ndetector proposed in [2].\nUnsupervised detection. Unsupervised detection refers to the\nprocess of identifying potential fake news sources from unlabeled\nor partially labeled data. Guo et al . [10] states that early discov-\nery of fake news is very crucial and remains a challenge. Several\nunsupervised or semi-supervised methods have been proposed to\ntackle this challenge. Qian et al . [13] generates synthetic user en-\ngagement to improve fake news detection. Yang et al . [27] utilizes a\nprobabilistic graphical model to estimate trustworthiness of news.\n[9] distinguishes different categories of false news using tensor\ndecomposition on the content. [ 19] uses weak labeling functions\nto expand training set, and [ 25] leverages users\u2019 reports as weak\nsupervision to enlarge the amount of training data.\nFake news visualization An intuitive visualization and human-\ncomputer interaction system enhances the practicality of under-\nlying fake news detection or discovery algorithms. For example,\n[14,16,26] build interactive applications to visualize the spread of\nfake news. Miranda et al . [11] takes a claim as input, and outputspredictions (true or false) and supporting evidence. Our user inter-\nface supports both a network view to visualize domain interactions,\nand a tabular view for fact-checkers to sort and label discovered\ndomains.\n3 SYSTEM ARCHITECTURE\nOur system consists of a front end user interface, and a back end\nstack of execution units. To bootstrap our discovery system, a user\nsimply submits a list of keywords. The choice of keywords can be\npolitically related, such as \u201cimpeachment\u201d, \u201cgovernment\u201d, or \u201celec-\ntion.\u201d After receiving keywords, our system triggers a Twitter data\ncollection, web page resolving, domain clustering and prediction\npipeline. Figure 1 illustrates our discovery pipeline. In this section\nwe explain each back end component in detail. Section 4 covers the\ndesign of front end interface.\n1.CollectlivetweetsthatcontainURLs\n7Fakenewsdomaindiscovery\nFakeNewsdetection on the largest connected component   \nUnsupervisedclustering\n2.Resolvefinal URL\n3.Reportfakedomainsandcollect user feedback\nFigure 1: Fake news domain discovery pipeline.\n3.1 Tweet collector\nWe employ a two-step data collection process to uncover domains\nrelated to a certain topic. We first use Twitter Streaming API to\ncollect live tweets based on a list of user-specified keywords. The\ncollection process stops when a certain number of tweets is col-\nlected or a certain number of minutes have passed, based on custom\nconfiguration.\nWe then extract all Twitter users who has generated at least\ntwo tweets with external URLs, i.e., URLs whose domain is not\ntwitter.com. We then use Twitter REST API to collect the past 200\ntweets of each user. We keep tweets that contain external URLs.\nWe now have the raw dataset on which subsequent steps depend.\nThe second collection process greatly expands the URL coverage\nand captures domains that are relevant but not covered by input\nkeywords.\n3.2 Web page resolver\nThe goal of this step is to extract embedded URLs from tweets,\nresolve final landing URLs, and collect features that will later be\nused by our supervised machine learning model. We use a headless\nChrome browser to visit each URL. We trace the entire URL redirec-\ntion chain, and store the HTML file of the final landing URL. Even\nthough browser simulation is a CPU-heavy operation, it is more\nreliable then simple scripting, due to the wide use of shortened\nURLs and unpredictable redirection behaviors.\nProactive Discovery of Fake News Domains from Real-Time Social Media Feeds WWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan\n3.3 Unsupervised domain discoverer\nThe domain discoverer identifies unknown domains by leveraging\nabundant but unlabelled social network structure. Shu and Liu [17]\npoint out that \u201cusers on social media tend to form groups containing\nlike-minded people where they then polarize their opinions, result-\ning in an echo chamber effect. The echo chamber effect facilitates\nthe process by which people consume and believe fake news.\u201d This\nobservation drives us to cluster domains based on user co-sharing\nsimilarity. We use Jaccard similarity1as our similarity measure.\nPrevious work [ 15,20] demonstrate that user co-sharing networks\nreveal the media ecosystem that surround political conversations.\nThe unit of our discovery algorithm is a domain. To construct\na domain interaction network, we first map each domain \ud835\udc51\ud835\udc56to a\nset of Twitter user ids \u0393(\ud835\udc51\ud835\udc56)whose tweets contain URLs to \ud835\udc51\ud835\udc56. We\nconstruct an undirected graph \ud835\udc3a<\ud835\udc49\ud835\udc37,\ud835\udc38>, where\ud835\udc49\ud835\udc37are domain\nnodes. For\ud835\udc511,\ud835\udc512\u2208\ud835\udc49\ud835\udc37, the weight of edge between \ud835\udc511and\ud835\udc512is\ndefined by a step function:\n\ud835\udc38\ud835\udc511,\ud835\udc512=0if\ud835\udc60\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc66(\ud835\udc511,\ud835\udc512)<\ud835\udefc\n=1otherwise\n\ud835\udc60\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc66(\ud835\udc511,\ud835\udc512)=|\u0393(\ud835\udc511)\u2229\u0393(\ud835\udc512)|\n|\u0393(\ud835\udc511)\u222a\u0393(\ud835\udc512)|\n\u0393(\ud835\udc51\ud835\udc56):=a set of user ids who have tweets containing \ud835\udc51\ud835\udc56\n\ud835\udefc:similarity threshold\nIn another word, an edge between two domains is removed if\ntheir co-sharing similarity is below a threshold, defined as \ud835\udefc. A\nlow\ud835\udefcresults in a densely connected graph with more irrelevant\ndomains, which in turn increases the overall recall but lowers the\nprecision. A high \ud835\udefchas the opposite effect. In Section 4 we show\nhow to systematically choose the optimal \ud835\udefc.\nAfter the graph construction, we run connected component al-\ngorithm to extract all clusters in the network. In our real world\nexperiment, the largest cluster is the only interesting one that con-\ntains more than 95% of domains from the input collection.\n3.4 Supervised detector\nThe final step is to score, rank and report domains just discovered.\nWe adopt and improve a topic-agnostic fake news classifier (TAG)\ndeveloped by [ 2]. TAG takes a web page as input and outputs a\nnumerical value to indicate the fakeness of that page. We summarize\nour reasons for being topic agnostic, features used by the classifier,\nour improvements, training data and test accuracy.\n3.4.1 Reasons for choosing TAG. As its name suggests, TAG does\nnot rely on the topic discussed in a web page, but focuses on the\nwriting style and page layout style. Future fake news topics are\nhighly unpredictable and are likely to differ from topics in the train-\ning set. We argue that it takes time and money to create professional\nwebsites and write in a professional way, both are big disincentives\nfor miscreants running on a budget. Therefore, while the news topic\nmay change day by day, the layout and writing style of a website\ndo not change as frequent.\n1Jaccard similarity of sets \ud835\udc34and\ud835\udc35is|\ud835\udc34\u2229\ud835\udc35|\n|\ud835\udc34\u222a\ud835\udc35|.Table 1: Learned top features associated with fake news and\nreal news.\nCategory Feature\nNameFeature Type Explanation\nreal newssvg web markup scalable vector graphics\nnoscript web markup defines an alternate content for\nusers that have disabled scripts\nin their browser\ncoleman-\nliau-\nindexreadability the higher the index, the more\ncomplex an article is\nfake newsins web markup underscore\nbr web markup blank space\ni web markup italic text\n3.4.2 Required features. Our classifier uses three categories of\nfeatures: web markup, readability and morphological. Together\nthey capture the aesthetic of a web page as well as the writing\nstyle and language usage of article writers. The full list of features\ncan be found in the original paper [ 2]. Table 1 shows a subset of\nfeatures positively linked to fake news and real news. Top features\nassociated with real news include advanced HTML tags and higher\nreadability score (for example, pages from The New York Times\nusually have a high readability score because the sentences are\nlonger and more sophisticated). Top features associated with fake\nnews include visual enhancers such as italic fonts and underscore.\n3.4.3 Improvements. To enhance the accuracy and make the classi-\nfier compatible with our discovery pipeline, we modify the source\ncode of [2] and make following improvements:\n(1)We add Quantile Transformer2to transform each feature\nto a normal distribution. Quantile Transformer is a robust\nprepossessing schema that reduces the impact of outliers.\n(2)We identify anomalies in training data. Specifically, we dis-\ncard web pages whose total number of words is less than\n200 or more than 2000. The former are pages with 404 errors\nand the latter are directory pages that are not relevant to a\nsingle piece of news.\n(3)We remove psychological features, which are used in the\noriginal paper to capture words\u2019 semantic patterns (anger,\nfear, happy, etc,.). This group of features require manual\nprocessing, which does not fit into our automated prediction\npipeline.\n3.4.4 Dataset and accuracy. We use the same PoliticalFakeNews\ntraining set introduced in [ 2]. The training set consists of 7,136\npages from 79 fake sites, and 7,104 pages from 58 real sites. The\nfake sites come from an aggregated list of Politifact, Buzzfeed 2016,\n2017 sets and Opensources.co. The real sites come from a subset\nof Alexa\u2019s top 500 news sites. We train a Support Vector Machine\n(SVM) with linear kernels. Our model achieves an average accuracy\nof 89% over a five-fold cross validation, 7% higher than the previous\nbest model accuracy reported in [ 2]. Figure 2 shows the Receiver\n2https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.\nQuantileTransformer.html\nWWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan Zhouhan Chen and Juliana Freire\nOperating Characteristic (ROC) curve and Area Under the Curve\n(AUC) value.\n0.0 0.2 0.4 0.6 0.8 1.0\nfalse positive rate0.00.20.40.60.81.0true positive rateROC-AUC of SVM classifier (5 folds)\nChance\nMean ROC (AUC = 0.97 \u00b1 0.02)\n\u00b1 1 std. dev.\nFigure 2: ROC-AUC plot of improved topic-agnostic fake\nnews classifier.\n3.4.5 Page-level score to domain level-score. Our TAG classifier\ntakes a web page as input. In order to assign a fakeness score to a\ndomain with multiple pages, we create a custom headless Chrome\ncrawler to first visit the domain home page, parse its HTML content,\nand randomly sample five hyperlinks with the same domain. The\nfakeness score of a domain is the average scores from those five\npages. Finally, to make a decision of fake,real, orunknown , we\nintroduce a parameter \ud835\udefd. Given a domain \ud835\udc51, a pre-trained TAG\nclassifier\ud835\udc36that returns a numerical value, and \ud835\udefd, our decision rule\nis:\n(1) if\ud835\udc36(\ud835\udc51)>\ud835\udefd,\ud835\udc51is fake.\n(2) if\ud835\udc36(\ud835\udc51)<\u2212\ud835\udefd,\ud835\udc51is real.\n(3) Otherwise, \ud835\udc51is unknown.\nSimilar to the first parameter \ud835\udefc,\ud835\udefdalso controls the relative impor-\ntance between precision and recall. A high \ud835\udefdincreases the precision\nbut lowers the recall, and a low \ud835\udefddoes the opposite. By default, and\nduring training and testing, \ud835\udefd=0. In Section 4 we show how to\ntune\ud835\udefdfor our real world application.\n4 SYSTEM DEMONSTRATION \u2013 A REAL\nWORLD STUDY TO DISCOVER FAKE NEWS\nDOMAINS ON TWITTER\nIn this section, we demonstrate a real world discovery experiment\nto prove the ability of our system to discover fake news domains.\nWe show how we evaluate and select the best model configuration.\nWe visualize interesting patterns behind the network of fake news\ndomains. We end this section with a characterization of Twitter\naccounts who tweet more fake domains.\n4.1 Real-time data collection\nOur discovery pipeline starts with keywords. We are interested in\nkeywords that are political, unique, and likely to appear in news\nheadlines. The impeachment inquiry of Donald Trump is a tensely\ndebated political event in the United States. The relevancy and\nnewsworthiness of this topic make it possible to discover domainsthat are never present in our training data. We trigger our dis-\ncovery pipeline by providing keywords impeach ,impeached and\nimpeachment .\nIn the 24 hours beginning October 29, 2019, we collect 220,909\ntweets from the Twitter Streaming API. We use 24 hours to capture\nall conversations happened in a day. From this initial collection, we\nextract 39,230 distinct Twitter account, and collect past 200 tweets\nfrom each account. This expands our collection to 2,284,544 tweets.\nWe then extract 4,042 unique domains from our expanded collec-\ntion, and calculate pair-wise user co-sharing similarity, as described\nin Section 3. This completes our data collection process.\n4.2 Model evaluation\nWe now introduce evaluation metrics, parameters, trade-offs we\nconsider, and configurations of our final discovery model.\n4.2.1 Evaluation metrics. Evaluating a fresh dataset is challenging\nbecause there is no complete ground truth. Our goal is to use lim-\nited ground truth to approximate global ground truth. We address\nthis problem by leveraging labels from another domain-based, ac-\ntively maintained fact-checking dataset. We choose to adopt labels\nprovided by MediaBiasFactCheck3(MBFC), an independent on-\nline fact-checking outlet. MBFC publishes and updates all labeled\ndomains on Github4, enabling us to check factness and bias of\nhundreds of domains programmatically. Other fact-checking ser-\nvices such as PolitiFact5and Snopes6mostly focus on claims and\nstatements made by officials, columnists, and political analysts [ 17],\nwhere MBFC focuses on domains. As of February 5, 2020, MBFC\nhas 2,793 unique domains that are human-labeled.\nFor each domain, MBFC provides seven labels, from VERY HIGH\ntoVERY LOW . To map seven labels to just realandfake, we define\nfake domains as those with labels LOW ,VERY LOW ,MIXED , and\nreal domains as those with labels VERY HIGH ,HIGH , and MOSTLY\nFACTUAL . We include MIXED in the fake category because MBFC\nassigns labels conservatively and 19% of fake news domains in our\ntraining data have MIXED labels.\nTo select the optimal discovery configuration, we consider two\nparameters introduced in Section 3: \ud835\udefcand\ud835\udefd.\ud835\udefcis the similarity\nthreshold used during domain network construction, and \ud835\udefdis the\ndecision threshold for our topic-agnostic classifier. To evaluate a\nconfiguration, we consider three metrics, which we call partial\nprecision\ud835\udc5d, partial recall \ud835\udc5f, and partial \ud835\udc531score, defined as:\n\ud835\udc5d=# domains predicted fake and labeled by MBFC as fake\n# domains predicted fake by our model\n\ud835\udc5f=# domains labeled by MBFC as fake and discovered by our model\n# domains labeled by MBFC as fake\n\ud835\udc531=2\u00d7(\ud835\udc5d\u00d7\ud835\udc5f)\n(\ud835\udc5d+\ud835\udc5f)\n4.2.2 Grid search. We use grid search to find the best configuration\nof\ud835\udefcand\ud835\udefd, with\ud835\udefc\u2208[0.4,0.6,0.8]and\ud835\udefd\u2208[0,0.5,1.0].We also\nconsider three \u201cno-network\u201d cases ( \ud835\udefd\u2208 [0,0.5,1.0]) where the\n3https://mediabiasfactcheck.com\n4https://raw.githubusercontent.com/drmikecrowe/mbfcext/master/docs/revised/csources.json\n5politifact.com\n6snopes.com\nProactive Discovery of Fake News Domains from Real-Time Social Media Feeds WWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan\nmodel does not leverage the network structure to filter out domains,\nbut predicts on all 4,042 domains in the collection. The results are\nlisted in Table 2.\nWe choose\ud835\udefc=0.4as the lower bound because when \ud835\udefc\u22640.3, the\ndomain interaction network is too weakly connected. The resulting\npartial precision and recall are not different from those obtained\nfrom \u201cno-network\u201d cases, which means that the model does not\nextract extra information from the domain interaction network.\nWe choose\ud835\udefc=0.8to be the upper bound because when \ud835\udefc\u22650.9,\nthe domain interaction network is broken. The largest connected\ncomponent only contains 47.6% of all domains, which does not\ncapture a complete conversational structure.\nWe choose \ud835\udefd\u2208 [0,0.5,1.0]by inspecting the fakeness score\ndistribution of domains from our training set, shown in Figure 3.\nThe greater the \ud835\udefd, the more conservative the decision boundary is: 0\nis liberal, 0.5is moderately conservative, and 1is very conservative.\n4\n 3\n 2\n 1\n 0 1 2 3 4\nsupervised fakeness score0.02.55.07.510.012.515.0fake\nreal\n=0\n=0.5\n=1\nFigure 3: Fakeness score distribution for domains in the\ntraining set. We experiment with three decision boundary\nthresholds ( \ud835\udefd): 0, 0.5 and 1. A larger \ud835\udefdcorresponds to a higher\nprecision and a lower recall.\n4.2.3 Optimal model configuration. The criteria of an optimal model\ndepends on the goal of end users. Table 2 shows that using net-\nwork pattern increases partial precision, degrades partial recall, but\nimproves partial \ud835\udc531score.\nFor our use case, we want to achieve a balance between precision\nand recall, because we are often constrained by limited human\nresource to fact-check discovered domains. Therefore we choose\n\ud835\udefc=0.8,\ud835\udefd=0.5, as this configuration yields the highest partial \ud835\udc531\nscore.\n4.3 Discovered domain interaction network\nAfter we decide the optimal system configuration, we first construct\nthe domain interaction network using \ud835\udefc=0.8. Figure 4 visualizes\nthe network structure of the largest connected component. This\ncomponent contains 2,238 domains, which accounts for 95.3%of\ndomains from all connected components. The rest of connected\ncomponents has less than 10 domains each. Therefore we are confi-\ndent that the largest connected component is representative of the\ndomain interaction network and we only focus on the largest one\nin further analysis.\nWe can identify two distinct clusters of domains related to the\ntopic \u201cimpeachment.\u201d Domains from the top left cluster are biasedTable 2: Evaluation of different model configurations. nn\nmeans \u201cno-network\u201d, i.e., we only use supervised score clas-\nsifier over all domains in our collection. We achieve the best\npartial\ud835\udc531score when we leverage network information to\nfilter out irrelevant domains, and set \ud835\udefc=0.8,\ud835\udefd=0.5.\nMetric partial precision partial recall partial f1\n\ud835\udefc&\ud835\udefd 0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8\n0 0.12 0.13 0.17 0.72 0.70 0.53 0.21 0.22 0.26\n0.5 0.16 0.17 0.24 0.48 0.47 0.37 0.24 0.25 0.29\n1.0 0.20 0.21 0.29 0.24 0.24 0.19 0.22 0.22 0.23\nnn 0 0.12 0.73 0.21\nnn 0.5 0.16 0.48 0.24\nnn 1 0.21 0.24 0.22\ntoward liberal causes. Two high degree nodes in this cluster are\nwashingtonpost.com andcnn.com . Domains from the bottom right\ncluster are biased towards conservative causes. Two high degree\nnodes in this cluster are breitbart.com andthegatewaypundit.com . A\nfew domains, notably wsj.com , stays in the middle, which suggests\nthat people from both parties tend to share information from those\nsources.\nFigure 4: Fake News Discoverer Interface (network view). We\nvisualize the domain interaction network using d3js. We can\nidentify two clusters of domains related to the topic \u201cim-\npeachment.\u201d Domains from the top left cluster are biased to-\nward liberal causes. Domains from the bottom right cluster\nare biased towards conservative causes.\nWWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan Zhouhan Chen and Juliana Freire\n4.4 Performance of best model: intersection\naccuracy and top-k accuracy\nWe now evaluate our supervised detector component. Using \ud835\udefd=0.5,\nwe filter out domains whose score is between \u22120.5and 0.5. We also\nremove domains that appear in our training set. This left us with\n890newly discovered domains, out of 2,238 domains.\nTo evaluate our best model, we breakdown discovered domains\ninto two categories \u2013 those that have been fact-checked by MBFC,\nand those that have not been fact-checked.\n4.4.1 Discovered domains, fact-checked. Among 890discovered\ndomains, 278 (31%) have been fact-checked. We now focus on this\nintersection. We use labels provided by MBFC as ground truth. Fig-\nure 5 shows the distribution of MBFC\u2019s factual ratings for domains\npredicated fake and domains predicated real. We summarize three\nmajor findings:\n(1)Our model\u2019s predictions mostly agree with fact-checkers\u2019\nlabels. Among domains predicted real, 83% have a factual\nreporting of HIGH ,VERY HIGH orMOSTLY FACTUAL . Only\n3% have a LOW rating.\n(2)Among domains predicted fake, 24% have a factual reporting\nofHIGH orMOSTLY FACTUAL , 31% have a factual reporting\nofLOW orVERY LOW . Overall, 76% of domains predicted\nfake have ratings below Mostly Factual .\n(3)45% of domains predicted fake are MIXED , versus 12% of\ndomains predicted real. The high percentage of MIXED label\nreflects the constraint of domain-level classification, as a\ndomain can host real pages and fake pages at the same time.\nVERY HIGH HIGH MOSTLY \n FACTUALMIXED LOW VERY \n LOWUNKNOWN\njudgement from fact-checker020406080category\npredicted real\npredicted fake\nFigure 5: Factual ratings provided by MBFC. Our models\u2019 pre-\ndictions mostly agree with fact-checkers\u2019 labels: only 3% of\ndomains predicted real have Low ratings, while 76% of do-\nmains predicted fake have ratings below Mostly Factual .\n4.4.2 Discovered domains, not fact-checked. For domains in this\ncategory, we measure the top-k accuracy, where \ud835\udc58=20. Specifically,\nwe sort domains according to their fakeness scores, and manually\nverify the top 20 domains that have not been fact-checked. This\npractice is consistent with how we intend our system to be used:\nfact-checkers first sort domains, then label the one with the highest\nscore first.\nTable 3 shows predicted score, our manual factual rating and\nbias rating of top 20 domains. In summary, 30% of domains are fake,\n30% of domains have a mixed factual rating with certain politicalbias, and 10% of domains can\u2019t be determined. Overall, 70% of\ndomains are suspicious and require investigation. This percentage\nis consistent with the percentage for discovered domains that are\nfact-checked, where 76% of domains predicted fake have ratings\nbelow Mostly Factual .\nTo streamline the fact-checking process, we implement a user\ninterface shown in Figure 6. When a domain is not fact-checked, a\nlabel of \u201cunchecked\u201d is shown. To label those domains, a user first\nranks domains by fakeness score, then clicks \u201cReport\u201d to assign\nlabels. This feedback loop will enable our discovery system to con-\nstantly improve itself by retraining models on a growing and more\naccurate dataset.\nFigure 6: Fake News Discoverer User Interface (tabular view).\nA user can rank domains by fakeness score. If a domain\nexists in mediabiasfactcheck.org, a user can cross-check\nhuman-rated factual rating and bias rating. If a domain is\nnot fact-checked, a label of \u201cunchecked\u201d is shown. A user\ncan click \u201cReport\u201d to assign a label to the domain. A sample\nreport window is shown on the right.\n4.5 From domain to account: characterizing\nTwitter accounts using fakeness score\n4.5.1 Why are Twitter account fakeness important? In this section,\nwe demonstrate how to use domain-level fakeness score to infer\naccount-level fakeness score. We define an account\u2019s fakeness score\nas the average score of domains tweeted by this account in its most\nrecent 200 tweets. How is account fakeness score useful? First of\nall, if domains are the source, Twitter accounts are the carriers that\nspread the source. Account fakeness score quantifies the relative\npropensity of an account to share fake news. Second, we can identify\npredictive features by segregating accounts according to different\nscore range and look for distributional difference. We believe that\nour account fakeness score, together with any derived features, is\nvaluable for downstream tasks such as social bot detection, troll\ndetection or sentiment analysis.\n4.5.2 How many bots are in our \u201cimpeachment\u201d collection? Recent\nresearch shows that bots, or accounts automated by software, are\nprevalent on Twitter feeds [ 6], especially among tweets with em-\nbedded URLs [ 3]. To estimate the percentage of bot accounts in our\ncollection, we leverage Botometer [23], a machine learning model\nthat predicts how likely an account is a bot based on more than\n1,200 features. For each account, Botometer calculates a complete\nProactive Discovery of Fake News Domains from Real-Time Social Media Feeds WWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan\nTable 3: Manual factual ratings for the top 20 discovered domains that are not fact-checked by the time of discovery. For\ndomains that are labeled \u201cLow,\u201d a link to a misleading page is provided. For domains labeled \u201cMixed,\u201d a bias judgement is\nprovided. For domains that are labeled \u201cIrrelevant,\u201d a short description of the website is given. Domains with \u201cUnknown\u201d\nlabel require more investigation.\nDomain Score Factual rating Comment\nblackmainstreet.net 2.59 Unknown\nnewsmagazinehouse.co.uk 2.45 Low right bias https://www.newsmagazinehouse.co.uk/hunters-\npaternity-case-spills-into-impeachment-judge-orders-\nbiden-to-hand-over-his-burisma-financial-records/\nnatureknows.org 2.34 Irrelevant about nature\npoliticodailynews.com 2.32 Mixed right bias\nthemindshield.com 2.32 Irrelevant personal blog\nfloppingaces.net 2.30 Low right bias http://www.floppingaces.net/2020/02/02/adam-\nschiffs-lifetime-of-lies/\nbreakthematrix.com 2.20 High\nleadpatriot.com 2.19 Low exaggeration https://leadpatriot.com/hillary-clinton-bashes-\nsanders-and-then-threatens-us-all/5806/\nmydaughtersarmy.org 2.14 Mixed left bias\nnycpost.pro 2.09 Low right bias https://www.nycpost.pro/judge-declares-omar-\nis-guilty-orders-her-to-repay-it-all-then-finds-another-\nskeleton-in-her-closet/\nheartlanddiaryusa.com 2.04 Mixed right bias\ndmlnewsapp.com 2.03 High\nbetshort.com 1.97 Low left bias http://betshort.com/collusion/\ntammybruce.com 1.91 Mixed right bias\njoemygod.com 1.90 Mixed right bias\niotwreport.com 1.89 Mixed right bias\nchurchandstate.org.uk 1.89 Irrelevant website that covers church-state separation and free speech.\nthedcpatriot.com 1.88 Unknown\npantsonfirenews.com 1.88 Low right bias https://pantsonfirenews.com/the-new-york-times-\nlatest-conspiracy-theory-is-so-insane-it-will-make-your-\nhead-hurt/\nsecureourvote.us 1.87 Irrelevant website about making the voting process more transparent\nautomation probability (CAP). This metric uses Bayes\u2019 theorem to\n\u201ctake into account an estimate of the overall prevalence of bots, so\nas to balance false positives with false negatives [23].\u201d\nWe query all 39,230 accounts via Botometer API. Figure 7 shows\nthe distribution of complete automation probability for those ac-\ncounts. The average probability of an account being a bot is 5.41%.\nIf we use 0.5 as a bot/not-bot threshold, 1.90% accounts are bots.\nIf we use 0.8 as a threshold, only 0.14% accounts are bots. We con-\nclude that the majority of accounts in our collection are operated\nby humans, and that our account characterization reflects humans\u2019\nonline behaviors.\n4.5.3 Discovered feature: account description. Using our \u201cimpeach-\nment\u201d collection, we characterize accounts with different fakeness\nscores and investigate what makes one account more likely to share\nfake news than others. We focus on active accounts that have at\nleast three tweets with URLs among the past 200 tweets. Having\nmore URLs reduces the variance of account fakeness score. There\nare 39,230 Twitter accounts in our \u201cimpeachment\u201d collection, and\n37,503 are active accounts. We first calculate fakeness score for each\naccount. Figure 8 is the histogram of all account fakeness scores.\n0.0 0.2 0.4 0.6 0.8 1.0\nBotometer Complete Automation Probability05000100001500020000number of accountsFigure 7: Botometer Complete Automation Probability\n(CAP) distribution for accounts in our \u201cimpeachment\u201d col-\nlection. 1.90% accounts are above the 0.5 (50%) likelihood\nthreshold.\nBased on the shape of the distribution, we break down accounts\ninto three categories: likely to share fake news (score > 0), might\nWWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan Zhouhan Chen and Juliana Freire\nshare fake news (-1 \u2264score\u22640), and not likely to share fake news\n(score < -1).\nFigure 8: Histogram of fakeness score for all accounts in our\n\u201cimpeachment\u201d collection. Because most scores are between\n-2 and 1, we segregate accounts into three categories: likely\nto share fake news (score > 0), might share fake news (-1 \u2264\nscore\u22640), and not likely to share fake news (score < -1).\nWe then look at feature distribution within each category to\nidentify discriminating features. We do not find difference in the\ndistribution of number of tweets sent, number of friends or number\nof followers. One very interesting linguistic feature we find is ac-\ncount description. Specifically, we extract all account descriptions,\nremove stop words and punctuations, and generate bigrams. Ta-\nble 4 shows the top 10 most commonly used bigrams in account\ndescriptions in each category. Accounts that are likely to share fake\nnews tend to be strong \u201cTrump supporters,\u201d prefer to use campaign\nhashtags such as \u201c#maga,\u201d \u201c#kag,\u201d and the word \u201cgod.\u201d Accounts\nthat are not likely to share fake news tend to label themselves as\n\u201cpolitical junkie\u201d and \u201cnews junkie,\u201d who are probably more willing\nto read news from multiple sources.\nOther than linguistic difference, we also notice demographic\ndifference in each category: accounts that are more likely to share\nfake news are \u201chappily married \u201d or \u201chusband father;\u201d accounts that\nmight share or are less likely to share fake news label themselves as\n\u201canimal lover\u201d and \u201cwife mother.\u201d To be more concrete, we present\nscreenshots of two Twitter account profiles in Figure 9. The image\non the left is a user with low fakeness score. In contrast, the image on\nthe right is a user with high fakeness score. Its profile is anonymous\nand its description is more provocative. We caution that those\ndifferences do not imply a causal relationship: whether certain\ndemographics are more susceptible to fake news (i.e., they share\nfake news without realizing the fact that the news is fake), or\nare more actively involved in sharing fake news requires further\ninvestigation.\n5 LIMITATIONS AND FUTURE WORK\n5.1 Sample bias and selection bias\nThere are two major types of bias from our system \u2013 sample bias\nand selection bias. Sample bias come from our US-centric training\ndataset. Selection bias come from two parts: one is that our system\nfocuses on Twitter exclusively, the other is that our data collection\nprocess requires input keywords which are subject to human choice.Table 4: Top 10 most commonly used bigrams in account de-\nscriptions. Users who are likely to share fake news tend to\nbe strong \u201cTrump supporters,\u201d and prefer to share campaign\nhashtags such as \u201c#maga.\u201d Users who are not likely to share\nfake news label themselves as \u201cpolitical junkie\u201d and \u201cnews\njunkie,\u201d who are probably more willing to read news from\ndifferent sources.\nrank likely to share fake\nnewsmight share fake\nnewsnot likely to share\nfake news\n1 trump supporter #maga #kag animal lover\n2 #maga #kag trump supporter political junkie\n3 president trump president trump wife mother\n4 happily married animal lover husband father\n5 god bless happily married wife mom\n6 god family wife mother new york\n7 love god follow back mother grandmother\n8 trump 2020 love god dog lover\n9 husband father god family news junkie\n10 family country husband father mom wife\nFigure 9: Twitter account profiles. The left one has a low fak-\neness score. The right one has a high fakeness score: its pro-\nfile is anonymous and its description more provocative.\nOur training data are predominantly English websites covering\nnews in the United States. As a result, our topic agnostic classifier\nassociates fake domains with unprofessional website designs and\nsimple writing styles. This might not hold true in other regions of\nthe world. One example is www.saamana.com, a regional website\nin India. The topic of the website is trustworthy but the design is\nshabby due to low budget.\nWe will reduce the sample bias by collecting feedback from fact-\ncheckers who interact with our system. We will also collect fake\nand real domains in different countries and different languages.\nWe plan to reduce the selection bias by collecting data from\nmultiple social media feeds, and using a wide variety of keywords,\nhashtags, user handles to capture potential news originators. For\nexample, instead of listening to certain keywords, we can collect\nreal-time tweets from accounts with high fakeness scores, because\nthose accounts are more likely to share fake news.\n5.2 Lack of unified dataset and evaluation\nframework\nResearch in cyber security suffer from a lack of unified dataset and\nevaluation framework. Unification is difficult because the target of\ndetection (for example: fake news, social bot, or computer virus)\nProactive Discovery of Fake News Domains from Real-Time Social Media Feeds WWW \u201920 Companion, April 20\u201324, 2020, Taipei, Taiwan\nadapts constantly. There is a risk of using previous dataset, as\nadversaries can use exactly the same dataset to circumvent the\ndetection. We are aware of this problem and therefore propose a\ncombination of supervised and unsupervised approach.\nOn the evaluation side, evaluating newly discovered domains\nis time consuming. This is partly why we are not able to evaluate\nall discovered fake domains that are not fact-checked. Our next\nstep is to introduce our Web interface to research communities,\nfact-checking groups, and social media companies to speed up the\nlabeling process all together. We will also introduce application\nprogramming interface (API) to allow researchers to query our\ngrowing database of newly discovered domains with ease.\n6 CONCLUSIONS\nWe present a discovery system that proactively surfaces fake news\ndomains by leveraging domain network structures reconstructed\nfrom real-time social media feeds. Our system combines unsuper-\nvised clustering, supervised prediction, and human-in-the-loop\ninteraction together. We provide a Web interface to allow users to\nvisualize, search and label fake news domains. We show that our\nsystem is able to discover suspicious domains that have not been\nfact-checked before. We also show discriminating features of Twit-\nter accounts that are likely to share fake news source. As much of\ntoday\u2019s political debates and social conversations have shifted to on-\nline social media, we are expecting to see more websites created to\nspread misinformation. For this reason, we hope that our work can\nimprove early detection rate and discovery capability. We plan to\nopen our system access to more research communities to facilitate\nfact-checking process and to leverage more crowd intelligence.\nREFERENCES\n[1]Alexandre Bovet and Hern\u00e1n A. Makse. 2019. Influence of fake news in Twitter\nduring the 2016 US presidential election. Nature Communications 10, 1 (2019), 7.\nhttps://doi.org/10.1038/s41467-018-07761-2\n[2]Sonia Castelo, Thais Almeida, Anas Elghafari, A\u00e9cio Santos, Kien Pham, Ed-\nuardo Nakamura, and Juliana Freire. 2019. A Topic-Agnostic Approach for\nIdentifying Fake News Pages. In Companion Proceedings of The 2019 World\nWide Web Conference (WWW \u201919) . ACM, New York, NY, USA, 975\u2013980. https:\n//doi.org/10.1145/3308560.3316739\n[3]Zhouhan Chen, Rima S. Tanash, Richard Stoll, and Devika Subramanian. 2017.\nHunting Malicious Bots on Twitter: An Unsupervised Approach. In Social Infor-\nmatics . Springer International Publishing, Cham, 501\u2013510.\n[4]Fernando Cardoso Durier da Silva, Rafael Vieira, and Ana Cristina Garcia. 2019.\nCan Machines Learn to Detect Fake News? A Survey Focused on Social Media.\nInHICSS .\n[5]Chris Dulhanty, Jason L. Deglint, Ibrahim Ben Daya, and Alexander Wong. 2019.\nTaking a Stance on Fake News: Towards Automatic Disinformation Assessment\nvia Deep Bidirectional Transformer Language Models for Stance Detection. CoRR\nabs/1911.11951 (2019). arXiv:1911.11951 http://arxiv.org/abs/1911.11951\n[6]Emilio Ferrara, Onur Varol, Clayton A. Davis, Filippo Menczer, and Alessandro\nFlammini. 2016. The rise of social bots. Commun. ACM 59 (2016), 96\u2013104.\n[7]Maria Glenski, Ellyn Ayton, Josh Mendoza, and Svitlana Volkova. 2019. Mul-\ntilingual Multimodal Digital Deception Detection and Disinformation Spread\nacross Social Platforms. CoRR abs/1909.05838 (2019). arXiv:1909.05838 http:\n//arxiv.org/abs/1909.05838\n[8]Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and\nDavid Lazer. 2019. Fake news on Twitter during the 2016 U.S. presidential\nelection. Science 363, 6425 (2019), 374\u2013378. https://doi.org/10.1126/science.\naau2706 arXiv:https://science.sciencemag.org/content/363/6425/374.full.pdf\n[9]Gisel Bastidas Guacho, Sara Abdali, Neil Shah, and Evangelos E. Papalexakis.\n2018. Semi-supervised Content-Based Detection of Misinformation via Tensor\nEmbeddings. 2018 IEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM) (Aug 2018). https://doi.org/10.1109/\nasonam.2018.8508241\n[10] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu. 2019. The Future of\nMisinformation Detection: New Perspectives and Trends. CoRR abs/1909.03654(2019). arXiv:1909.03654 http://arxiv.org/abs/1909.03654\n[11] Sebasti\u00e3o Miranda, David Nogueira, Afonso Mendes, Andreas Vlachos, Andrew\nSecker, Rebecca Garrett, Jeff Mitchel, and Zita Marinho. 2019. Automated Fact\nChecking in the News Room. In The World Wide Web Conference (WWW \u201919) .\nAssociation for Computing Machinery, New York, NY, USA, 3579\u20133583. https:\n//doi.org/10.1145/3308558.3314135\n[12] Kai Nakamura, Sharon Levy, and William Yang Wang. 2019. r/Fakeddit: A New\nMultimodal Benchmark Dataset for Fine-grained Fake News Detection. ArXiv\nabs/1911.03854 (2019).\n[13] Feng Qian, Chengyue Gong, Karishma Sharma, and Yan Liu. 2018. Neural User\nResponse Generator: Fake News Detection with Collective User Intelligence.\nInProceedings of the Twenty-Seventh International Joint Conference on Artificial\nIntelligence, IJCAI-18 . International Joint Conferences on Artificial Intelligence\nOrganization, 3834\u20133840. https://doi.org/10.24963/ijcai.2018/533\n[14] Chengcheng Shao, Giovanni Luca Ciampaglia, Alessandro Flammini, and Fil-\nippo Menczer. 2016. Hoaxy: A platform for tracking online misinformation. In\nProceedings of the 25th International Conference Companion on World Wide Web .\nInternational World Wide Web Conferences Steering Committee, 745\u2013750.\n[15] Kai Shu, Ahmed Hassan Awadallah, Susan Dumais, and Huan Liu. 2019. Detecting\nFake News with Weak Social Supervision. arXiv:arXiv:1910.11430\n[16] Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019. dE-\nFEND: Explainable Fake News Detection. In Proceedings of the 25th ACM SIGKDD\nInternational Conference on Knowledge Discovery & Data Mining (KDD \u201919) . ACM,\nNew York, NY, USA, 395\u2013405. https://doi.org/10.1145/3292500.3330935\n[17] Kai Shu and Huan Liu. 2019. Detecting Fake News on Social Media. Synthesis\nLectures on Data Mining and Knowledge Discovery (2019).\n[18] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake News\nDetection on Social Media: A Data Mining Perspective. SIGKDD Explor. Newsl.\n19, 1 (Sept. 2017), 22\u201336. https://doi.org/10.1145/3137597.3137600\n[19] Kai Shu, Suhang Wang, Dongwon Lee, and Huan Liu. 2020. Mining Disinfor-\nmation and Fake News: Concepts, Methods, and Recent Advancements. CoRR\nabs/2001.00623 (2020). arXiv:2001.00623 http://arxiv.org/abs/2001.00623\n[20] Kate Starbird, Ahmer Arif, and Tom Wilson. 2019. Disinformation As Collabora-\ntive Work: Surfacing the Participatory Nature of Strategic Information Operations.\nProc. ACM Hum.-Comput. Interact. 3, CSCW, Article 127 (Nov. 2019), 26 pages.\nhttps://doi.org/10.1145/3359229\n[21] Leo Graiden Stewart, Ahmer Arif, and Kate Starbird. 2018. Examining Trolls and\nPolarization with a Retweet Network.\n[22] Maciej Szpakowski. 2020. FakeNewsCorpus . https://github.com/several27/\nFakeNewsCorpus\n[23] Onur Varol, Emilio Ferrara, Clayton Davis, Filippo Menczer, and Alessandro\nFlammini. 2017. Online Human-Bot Interactions: Detection, Estimation, and\nCharacterization. https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/\nview/15587\n[24] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false\nnews online. Science 359, 6380 (2018), 1146\u20131151. https://doi.org/10.1126/science.\naap9559 arXiv:https://science.sciencemag.org/content/359/6380/1146.full.pdf\n[25] Yaqing Wang, Weifeng Yang, Fenglong Ma, Jin Xu, Bin Zhong, Qiang Deng,\nand Jing Gao. 2019. Weak Supervision for Fake News Detection via Re-\ninforcement Learning. arXiv e-prints , Article arXiv:1912.12520 (Dec 2019),\narXiv:1912.12520 pages. arXiv:cs.SI/1912.12520\n[26] Fan Yang, Shiva K. Pentyala, Sina Mohseni, Mengnan Du, Hao Yuan, Rhema\nLinder, Eric D. Ragan, Shuiwang Ji, and Xia (Ben) Hu. 2019. XFake: Explainable\nFake News Detector with Visualizations. In The World Wide Web Conference\n(WWW \u201919) . ACM, New York, NY, USA, 3600\u20133604. https://doi.org/10.1145/\n3308558.3314119\n[27] Shuo Yang, Kai Shu, Suhang Wang, Renjie Gu, Fan Wu, and Huan Liu. 2019.\nUnsupervised Fake News Detection on Social Media: A Generative Approach. In\nAAAI .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Proactive discovery of fake news domains from real-time social media feeds", "author": ["Z Chen", "J Freire"], "pub_year": "2020", "venue": "Companion proceedings of the web conference 2020", "abstract": "The proliferation of web sites that disseminate fake news is a growing problem in our society.  Not surprisingly, the problem of identifying whether a web page contains fake news has"}, "filled": false, "gsrank": 148, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3366424.3385772", "author_id": ["sEsP8UAAAAAJ", "sSzAlq0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:t9NycMS6gGMJ:scholar.google.com/&output=cite&scirp=147&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=t9NycMS6gGMJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 36, "citedby_url": "/scholar?cites=7169935959636759479&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:t9NycMS6gGMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.zhouhanc.com/src/CyberSafety_2020_final.pdf"}}, {"title": "Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection", "year": "2019", "pdf_data": "Proceedings of the 2nd Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda , pages 162\u2013170\nHong Kong, China, November 4, 2019 c\r2019 Association for Computational Linguistics162Findings of the NLP4IF-2019 Shared Task\non Fine-Grained Propaganda Detection\nGiovanni Da San Martino1Alberto Barr \u00b4on-Cede \u02dcno2Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Qatar\n2Universit `a di Bologna, Forl `\u0131, Italy\nfgmartino, pnakov g@hbku.edu.qa a.barron@unibo.it\nAbstract\nWe present the shared task on Fine-Grained\nPropaganda Detection, which was organized\nas part of the NLP4IF workshop at EMNLP-\nIJCNLP 2019. There were two subtasks. FLC\nis a fragment-level task that asks for the iden-\nti\ufb01cation of propagandist text fragments in a\nnews article and also for the prediction of the\nspeci\ufb01c propaganda technique used in each\nsuch fragment (18-way classi\ufb01cation task).\nSLC is a sentence-level binary classi\ufb01cation\ntask asking to detect the sentences that con-\ntain propaganda. A total of 12 teams submit-\nted systems for the FLC task, 25 teams did\nso for the SLC task, and 14 teams eventu-\nally submitted a system description paper. For\nboth subtasks, most systems managed to beat\nthe baseline by a sizable margin. The leader-\nboard and the data from the competition are\navailable at http://propaganda.qcri.\norg/nlp4if-shared-task/ .\n1 Introduction\nPropaganda aims at in\ufb02uencing people\u2019s mindset\nwith the purpose of advancing a speci\ufb01c agenda.\nIn the Internet era, thanks to the mechanism\nof sharing in social networks, propaganda cam-\npaigns have the potential of reaching very large\naudiences (Glowacki et al., 2018; Muller, 2018;\nTard\u00b4aguila et al., 2018).\nPropagandist news articles use speci\ufb01c\ntechniques to convey their message, such as\nwhataboutism ,red Herring , and name calling ,\namong many others (cf. Section 3). Whereas\nproving intent is not easy, we can analyse the\nlanguage of a claim/article and look for the use\nof speci\ufb01c propaganda techniques. Going at this\n\ufb01ne-grained level can yield more reliable systems\nand it also makes it possible to explain to the user\nwhy an article was judged as propagandist by an\nautomatic system.With this in mind, we organised the shared\ntask on \ufb01ne-grained propaganda detection at the\nNLP4IF@EMNLP-IJCNLP 2019 workshop. The\ntask is based on a corpus of news articles anno-\ntated with an inventory of 18 propagandist tech-\nniques at the fragment level. We hope that the\ncorpus would raise interest outside of the commu-\nnity of researchers studying propaganda. For ex-\nample, the techniques related to fallacies and the\nones relying on emotions might provide a novel\nsetting for researchers interested in Argumentation\nand Sentiment Analysis.\n2 Related Work\nPropaganda has been tackled mostly at the arti-\ncle level. Rashkin et al. (2017) created a corpus\nof news articles labelled as propaganda, trusted,\nhoax, or satire. Barr \u00b4on-Cede \u02dcno et al. (2019) ex-\nperimented with a binarized version of that cor-\npus: propaganda vs. the other three categories.\nBarr\u00b4on-Cedeno et al. (2019) annotated a large bi-\nnary corpus of propagandist vs. non-propagandist\narticles and proposed a feature-based system for\ndiscriminating between them. In all these cases,\nthe labels were obtained using distant supervision,\nassuming that all articles from a given news out-\nlet share the label of that outlet, which inevitably\nintroduces noise (Horne et al., 2018).\nA related \ufb01eld is that of computational argu-\nmentation which, among others, deals with some\nlogical fallacies related to propaganda. Habernal\net al. (2018b) presented a corpus of Web forum\ndiscussions with instances of ad hominem fallacy.\nHabernal et al. (2017, 2018a) introduced Argo-\ntario , a game to educate people to recognize and\ncreate fallacies, a by-product of which is a corpus\nwith 1:3karguments annotated with \ufb01ve fallacies\nsuch as ad hominem ,red herring andirrelevant\nauthority , which directly relate to propaganda.\n163Unlike (Habernal et al., 2017, 2018a,b), our cor-\npus uses 18 techniques annotated on the same set\nof news articles. Moreover, our annotations aim\nat identifying the minimal fragments related to a\ntechnique instead of \ufb02agging entire arguments.\nThe most relevant related work is our own,\nwhich is published in parallel to this paper at\nEMNLP-IJCNLP 2019 (Da San Martino et al.,\n2019) and describes a corpus that is a subset of\nthe one used for this shared task.\n3 Propaganda Techniques\nPropaganda uses psychological and rhetorical\ntechniques to achieve its objective. Such tech-\nniques include the use of logical fallacies and ap-\npeal to emotions. For the shared task, we use 18\ntechniques that can be found in news articles and\ncan be judged intrinsically, without the need to\nretrieve supporting information from external re-\nsources. We refer the reader to (Da San Martino\net al., 2019) for more details on the propaganda\ntechniques; below we report the list of techniques:\n1. Loaded language. Using words/phrases with\nstrong emotional implications (positive or nega-\ntive) to in\ufb02uence an audience (Weston, 2018, p. 6).\n2. Name calling or labeling. Labeling the ob-\nject of the propaganda as something the target au-\ndience fears, hates, \ufb01nds undesirable or otherwise\nloves or praises (Miller, 1939).\n3. Repetition. Repeating the same message over\nand over again, so that the audience will eventually\naccept it (Torok, 2015; Miller, 1939).\n4. Exaggeration or minimization. Either rep-\nresenting something in an excessive manner: mak-\ning things larger, better, worse, or making some-\nthing seem less important or smaller than it ac-\ntually is (Jowett and O\u2019Donnell, 2012, p. 303),\ne.g., saying that an insult was just a joke.\n5. Doubt. Questioning the credibility of some-\none or something.\n6. Appeal to fear/prejudice. Seeking to build\nsupport for an idea by instilling anxiety and/or\npanic in the population towards an alternative,\npossibly based on preconceived judgments.\n7. Flag-waving. Playing on strong national feel-\ning (or with respect to a group, e.g., race, gender,\npolitical preference) to justify or promote an ac-\ntion or idea (Hobbs and Mcgee, 2008).8. Causal oversimpli\ufb01cation. Assuming one\ncause when there are multiple causes behind an\nissue. We include scapegoating as well: the trans-\nfer of the blame to one person or group of people\nwithout investigating the complexities of an issue.\n9. Slogans. A brief and striking phrase that may\ninclude labeling and stereotyping. Slogans tend to\nact as emotional appeals (Dan, 2015).\n10. Appeal to authority. Stating that a claim\nis true simply because a valid authority/expert on\nthe issue supports it, without any other supporting\nevidence (Goodwin, 2011). We include the special\ncase where the reference is not an authority/expert,\nalthough it is referred to as testimonial in the liter-\nature (Jowett and O\u2019Donnell, 2012, p. 237).\n11. Black-and-white fallacy, dictatorship.\nPresenting two alternative options as the only pos-\nsibilities, when in fact more possibilities exist\n(Torok, 2015). As an extreme case, telling the\naudience exactly what actions to take, eliminating\nany other possible choice ( dictatorship ).\n12. Thought-terminating clich \u00b4e.Words or\nphrases that discourage critical thought and mean-\ningful discussion about a given topic. They are\ntypically short and generic sentences that offer\nseemingly simple answers to complex questions\nor that distract attention away from other lines of\nthought (Hunter, 2015, p. 78).\n13. Whataboutism. Discredit an opponent\u2019s\nposition by charging them with hypocrisy without\ndirectly disproving their argument (Richter, 2017).\n14. Reductio ad Hitlerum. Persuading an au-\ndience to disapprove an action or idea by suggest-\ning that the idea is popular with groups hated in\ncontempt by the target audience. It can refer to\nany person or concept with a negative connota-\ntion (Teninbaum, 2009).\n15. Red herring. Introducing irrelevant mate-\nrial to the issue being discussed, so that every-\none\u2019s attention is diverted away from the points\nmade (Weston, 2018, p. 78). Those subjected to a\nred herring argument are led away from the issue\nthat had been the focus of the discussion and urged\nto follow an observation or claim that may be as-\nsociated with the original claim, but is not highly\nrelevant to the issue in dispute (Teninbaum, 2009).\n164\nFigure 1: The beginning of an article with annotations.\n16. Bandwagon. Attempting to persuade the\ntarget audience to join in and take the course of\naction because \u201ceveryone else is taking the same\naction\u201d (Hobbs and Mcgee, 2008).\n17. Obfuscation, intentional vagueness, con-\nfusion. Using deliberately unclear words, to let\nthe audience have its own interpretation (Supra-\nbandari, 2007; Weston, 2018, p. 8). For instance,\nwhen an unclear phrase with multiple possible\nmeanings is used within the argument and, there-\nfore, it does not really support the conclusion.\n18. Straw man. When an opponent\u2019s proposi-\ntion is substituted with a similar one which is then\nrefuted in place of the original (Walton, 1996).\n4 Tasks\nThe shared task features two subtasks:\nFragment-Level Classi\ufb01cation task (FLC).\nGiven a news article, detect all spans of the text\nin which a propaganda technique is used. In\naddition, for each span the propaganda technique\napplied must be identi\ufb01ed.\nSentence-Level Classi\ufb01cation task (SLC). A\nsentence is considered propagandist if it contains\nat least one propagandist fragment. We then de-\n\ufb01ne a binary classi\ufb01cation task in which, given a\nsentence, the correct label, either propaganda or\nnon-propaganda , is to be predicted.5 Data\nThe input for both tasks consists of news articles\nin free-text format, collected from 36 propagandist\nand 12 non-propagandist news outlets1and then\nannotated by professional annotators. More de-\ntails about the data collection and the annotation,\nas well as statistics about the corpus can be found\nin (Da San Martino et al., 2019), where an earlier\nversion of the corpus is described, which includes\n450 news articles. We further annotated 47 addi-\ntional articles for the purpose of the shared task\nusing the same protocol and the same annotators.\nThe training, the development, and the test par-\ntitions of the corpus used for the shared task con-\nsist of 350, 61, and 86 articles and of 16,965,\n2,235, and 3,526 sentences, respectively. Fig-\nure 1 shows an annotated example, which con-\ntains several propaganda techniques. For ex-\nample, the fragment babies on line 1 is an in-\nstance of both Name Calling andLabeling .\nNote that the fragment not looking as though\nTrump killed his grandma on line 4 is an instance\nofExaggeration orMinimisation and it\noverlaps with the fragment killed his grandma ,\nwhich is an instance of Loaded Language .\nTable 1 reports the total number of instances per\ntechnique and the percentage with respect to the\ntotal number of annotations, for the training and\nfor the development sets.\n1We obtained the gold labels about whether a given news\noutlet was propagandistic from the Media Bias Fact Check\nwebsite: http://mediabiasfactcheck.com/\n165Technique Train (%) Dev (%)\nAppeal to Authority 116 (1.92) 50 (5.92)\nAppeal to fear / prejudice 239 (3.96) 103 (12.19)\nBandwagon 13 (0.22) 3 (0.36)\nBlack and White Fallacy 109 (1.80) 17 (2.01)\nCausal Oversimpli\ufb01cation 201 (3.33) 22 (2.60)\nDoubt 490 (8.11) 39 (4.62)\nExaggeration, Minimisation 479 (7.93) 59 (6.98)\nFlag Waving 240 (3.97) 63 (7.46)\nLoaded Language 2,115 (35.10) 229 (27.10)\nName Calling, Labeling 1,085 (17.96) 87 (10.30)\nObfuscation, Intentional\nVagueness, Confusion 11 (0.18) 5 (0.59)\nRed Herring 33 (0.55) 10 (1.18)\nReductio ad hitlerum 54 (0.89) 9 (1.07)\nRepetition 571 (9.45) 101 (11.95)\nSlogans 136 (2.25) 26 (3.08)\nStraw Men 13 (0.22) 2 (0.24)\nThought-terminating Cliches 79 (1.31) 10 (1.18)\nWhataboutism 57 (0.94) 10 (1.18)\nTable 1: Statistics about the gold annotations for the\ntraining and the development sets.\n6 Setup\nThe shared task had two phases: In the develop-\nment phase, the participants were provided labeled\ntraining and development datasets; in the testing\nphase, testing input was further provided.\nPhase 1. The participants tried to achieve the best\nperformance on the development set. A live\nleaderboard kept track of the submissions.\nPhase 2. The test set was released and the partici-\npants had few days to make \ufb01nal predictions.\nIn phase 2, no immediate feedback on the submis-\nsions was provided. The winner was determined\nbased on the performance on the test set.\n7 Evaluation\nFLC task. FLC is a composition of two sub-\ntasks: the identi\ufb01cation of the propagandist text\nfragments and the identi\ufb01cation of the techniques\nused (18-way classi\ufb01cation task). While F 1mea-\nsure is appropriate for a multi-class classi\ufb01cation\ntask, we modi\ufb01ed it to account for partial match-\ning between the spans; see (Da San Martino et al.,\n2019) for more details. We further computed an F 1\nvalue for each propaganda technique (not shown\nbelow for the sake of saving space, but available\non the leaderboard).\nSLC task. SLC is a binary classi\ufb01cation task\nwith imbalanced data. Therefore, the of\ufb01cial eval-\nuation measure for the task is the standard F 1mea-\nsure. We further report Precision and Recall.8 Baselines\nThe baseline system for the SLC task is a very sim-\nple logistic regression classi\ufb01er with default pa-\nrameters, where we represent the input instances\nwith a single feature: the length of the sentence.\nThe performance of this baseline on the SLC task\nis shown in Tables 4 and 5.\nThe baseline for the FLC task generates spans\nand selects one of the 18 techniques randomly.\nThe inef\ufb01cacy of such a simple random baseline\nis illustrated in Tables 6 and 7.\n9 Participants and Approaches\nA total of 90 teams registered for the shared task,\nand 39 of them submitted predictions for a total\nof 3,065 submissions. For the FLC task, 21 teams\nmade a total of 527 submissions, and for the SLC\ntask, 35 teams made a total of 2,538 submissions.\nBelow, we give an overview of the approaches\nas described in the participants\u2019 papers. Tables 2\nand 3 offer a high-level summary.\n9.1 Teams Participating in the\nFragment-Level Classi\ufb01cation Only\nTeam newspeak (Yoosuf and Yang, 2019)\nachieved the best results on the test set for the FLC\ntask using 20-way word-level classi\ufb01cation based\non BERT (Devlin et al., 2019): a word could be-\nlong to one of the 18 propaganda techniques, to\nnone of them, or to an auxiliary (token-derived)\nclass. The team fed one sentence at a time in\norder to reduce the workload. In addition to ex-\nperimenting with an out-of-the-box BERT, they\nalso tried unsupervised \ufb01ne-tuning both on the 1M\nnews dataset and on Wikipedia. Their best model\nwas based on the uncased base model of BERT,\nwith 12 Transformer layers (Vaswani et al., 2017),\nand 110 million parameters. Moreover, oversam-\npling of the least represented classes proved to be\ncrucial for the \ufb01nal performance. Finally, careful\nanalysis has shown that the model pays special at-\ntention to adjectives and adverbs.\nTeam Stalin (Ek and Ghanimifard, 2019)\nfocused on data augmentation to address the\nrelatively small size of the data for \ufb01ne-tuning\ncontextual embedding representations based\non ELMo (Peters et al., 2018), BERT, and\nGrover (Zellers et al., 2019). The balancing of\nthe embedding space was carried out by means of\nsynthetic minority class over-sampling. Then, the\nlearned representations were fed into an LSTM.\n166Team BERT LSTM Word Emb. Char. Emb. Features Unsup. Tuning\nCUNLP /check_sign /check_sign /check_sign\nStalin /check_sign /check_sign\nMIC-CIS /check_sign /check_sign /check_sign\nltuorp /check_sign\nProperGander /check_sign /check_sign\nnewspeak /check_sign /check_sign\nTable 2: Overview of the approaches for the fragment-level classi\ufb01cation task.\nTeam BERT LSTM logreg USE CNN Embeddings Features Context\nNSIT /check_sign /check_sign\nCUNLP /check_sign /check_sign /check_sign\nJUSTDeep /check_sign /check_sign /check_sign /check_sign\nTha3aroon /check_sign /check_sign\nLIACC /check_sign /check_sign /check_sign\nMIC-CIS /check_sign /check_sign /check_sign /check_sign /check_sign\nCAUnLP /check_sign /check_sign\nYMJA /check_sign\njinfen /check_sign /check_sign /check_sign\nProperGander /check_sign\nTable 3: Overview of the approaches used for the sentence-level classi\ufb01cation task.\n9.2 Teams Participating in the\nSentence-Level Classi\ufb01cation Only\nTeam CAUnLP (Hou and Chen, 2019) used two\ncontext-aware representations based on BERT. In\nthe \ufb01rst representation, the target sentence is fol-\nlowed by the title of the article. In the sec-\nond representation, the previous sentence is also\nadded. They performed subsampling in order to\ndeal with class imbalance, and experimented with\nBERT BASE and BERT LARGE\nTeam LIACC (Ferreira Cruz et al., 2019) used\nhand-crafted features and pre-trained ELMo em-\nbeddings. They also observed a boost in perfor-\nmance when balancing the dataset by dropping\nsome negative examples.\nTeam JUSTDeep (Al-Omari et al., 2019) used\na combination of models and features, including\nword embeddings based on GloVe (Pennington\net al., 2014) concatenated with vectors represent-\ning affection and lexical features. These were\ncombined in an ensemble of supervised models:\nbi-LSTM, XGBoost, and variations of BERT.\nTeam YMJA (Hua, 2019) also based their ap-\nproach on \ufb01ne-tuned BERT. Inspired by kaggle\ncompetitions on sentiment analysis, they created\nan ensemble of models via cross-validation.\nTeam jinfen (Li et al., 2019) used a logistic re-\ngression model fed with a manifold of representa-\ntions, including TF.IDF and BERT vectors, as well\nas vocabularies and readability measures.Team Tha3aroon (Fadel and Al-Ayyoub, 2019)\nimplemented an ensemble of three classi\ufb01ers: two\nbased on BERT and one based on a universal sen-\ntence encoder (Cer et al., 2018).\nTeam NSIT (Aggarwal and Sadana, 2019) ex-\nplored three of the most popular transfer learning\nmodels: various versions of ELMo, BERT, and\nRoBERTa (Liu et al., 2019).\nTeam Mindcoders (Vlad et al., 2019) combined\nBERT, Bi-LSTM and Capsule networks (Sabour\net al., 2017) into a single deep neural network and\npre-trained the resulting network on corpora used\nfor related tasks, e.g., emotion classi\ufb01cation.\nFinally, team ltuorp (Mapes et al., 2019) used\nan attention transformer using BERT trained on\nWikipedia and BookCorpus.\n9.3 Teams Participating in Both Tasks\nTeam MIC-CIS (Gupta et al., 2019) participated\nin both tasks. For the sentence-level classi\ufb01ca-\ntion, they used a voting ensemble including lo-\ngistic regression, convolutional neural networks,\nand BERT, in all cases using FastText embeddings\n(Bojanowski et al., 2017) and pre-trained BERT\nmodels. Beside these representations, multiple\nfeatures of readability, sentiment and emotions\nwere considered. For the fragment-level task, they\nused a multi-task neural sequence tagger, based\non LSTM-CRF (Huang et al., 2015), in conjunc-\ntion with linguistic features. Finally, they applied\nsentence- and fragment-level models jointly.\n167SLC Task: Test Set (Of\ufb01cial Results)\nRank Team F 1 Precision Recall\n1ltuorp 0.6323 0.6028 0.6648\n2 ProperGander 0.6256 0.5649 0.7009\n3 YMJA 0.6249 0.6252 0.6246\n4 MIC-CIS 0.6230 0.5735 0.6818\n5 CUNLP 0.6183 0.5778 0.6648\n6 Tha3aroon 0.6138 0.5309 0.7274\n7 JUSTDeep 0.6112 0.5792 0.6468\n8 CAUnLP 0.6109 0.5180 0.7444\n9 LIPN 0.5962 0.5241 0.6914\n10 LIACC 0.5949 0.5090 0.7158\n11 aschern 0.5923 0.6050 0.5800\n12 MindCoders 0.5868 0.5995 0.5747\n13 jinfen 0.5770 0.5059 0.6712\n14 guanggong 0.5768 0.5039 0.6744\n15 Stano 0.5619 0.6666 0.4856\n16 nlpseattle 0.5610 0.6250 0.5090\n17 gw2018 0.5440 0.4333 0.7306\n18 SDS 0.5171 0.6268 0.4400\n19 BananasInPajamas 0.5080 0.5768 0.4538\n20 Baseline 0.4347 0.3880 0.4941\n21 NSIT 0.4343 0.5000 0.3838\n22 Stalin 0.4332 0.6696 0.3202\n23 Antiganda 0.3967 0.6459 0.2863\n24 Debunkers 0.2307 0.3994 0.1622\n25 SBnLP 0.1831 0.2220 0.1558\n26 Sberiboba 0.1167 0.5980 0.0646\nTable 4: Of\ufb01cial test results for the SLC task.\nTeam CUNLP (Alhindi et al., 2019) considered\ntwo approaches for the sentence-level task. The\n\ufb01rst approach was based on \ufb01ne-tuning BERT. The\nsecond approach complemented the \ufb01ne-tuned\nBERT approach by feeding its decision into a lo-\ngistic regressor, together with features from the\nLinguistic Inquiry and Word Count (LIWC)2lexi-\ncon and punctuation-derived features. Similarly to\nGupta et al. (2019), for the fragment-level problem\nthey used a Bi-LSTM-CRF architecture, combin-\ning both character- and word-level embeddings.\nTeam ProperGander (Madabushi et al., 2019)\nalso used BERT, but they paid special attention to\nthe imbalance of the data, as well as to the differ-\nences between training and testing. They showed\nthat augmenting the training data by oversampling\nyielded improvements when testing on data that\nis temporally far from the training (by increasing\nrecall). In order to deal with the imbalance, they\nperformed cost-sensitive classi\ufb01cation, i.e., the er-\nrors on the smaller positive class were more costly.\nFor the fragment-level classi\ufb01cation, inspired by\nnamed entity recognition, they used a model based\non BERT using Continuous Random Field stacked\non top of an LSTM.\n2http://liwc.wpengine.com/SLC Task: Development Set\nRank Team F 1 Precision Recall\n1 Tha3aroon 0.6883 0.6104 0.7889\n2 KS 0.6799 0.5989 0.7861\n3 CAUnLP 0.6794 0.5943 0.7929\n4 ProperGander 0.6767 0.5774 0.8173\n5 JUSTDeep 0.6745 0.6234 0.7347\n6 ltuorp 0.6700 0.6351 0.7090\n7 CUNLP 0.6649 0.6198 0.7171\n8 aschern 0.6646 0.6104 0.7293\n9 jinfen 0.6616 0.5800 0.7699\n10 YMJA 0.6601 0.6338 0.6887\n11 SBnLP 0.6548 0.5674 0.7740\n12 guanggong 0.6510 0.5737 0.7523\n13 LIPN 0.6484 0.5889 0.7212\n14 Stalin 0.6377 0.5957 0.6860\n15 Stano 0.6374 0.6561 0.6197\n16 BananasInPajamas 0.6276 0.5204 0.7902\n17 Kloop 0.6237 0.5846 0.6684\n18 nlpseattle 0.6201 0.6332 0.6075\n19 gw2018 0.6038 0.5158 0.7280\n20 MindCoders 0.5858 0.5264 0.6603\n21 NSIT 0.5794 0.6614 0.5155\n22 Summer2019 0.5567 0.6724 0.4749\n23 Antiganda 0.5490 0.6609 0.4695\n24 Cojo 0.5472 0.6692 0.4627\n25 Baseline 0.4734 0.4437 0.5074\n26 gudetama 0.4734 0.4437 0.5074\n27 test 0.4734 0.4437 0.5074\n28 Visionators 0.4410 0.5909 0.3518\n29 MaLaHITJuniors 0.3075 0.4694 0.2286\nTable 5: Results for the SLC task on the development\nset at the end of phase 1 (see Section 6).\n10 Evaluation Results\nThe results on the test set for the SLC task are\nshown in Table 4, while Table 5 presents the re-\nsults on the development set at the end of phase\n1 (cf. Section 6).3The general decrease of the F 1\nvalues between the development and the test set\ncould indicate that systems tend to over\ufb01t on the\ndevelopment set. Indeed, the winning team ltuorp\nchose the parameters of their system both on the\ndevelopment set and on a subset of the training set\nin order to improve the robustness of their system.\nTables 6 and 7 report the results on the test and\non the development sets for the FLC task. For\nthis task, the results tend to be more stable across\nthe two sets. Indeed, team newspeak managed to\nalmost keep the same difference in performance\nwith respect to team Antiganda . Note that team\nMIC-CIS managed to reach the third position de-\nspite never having submitted a run on the develop-\nment set.\n3Upon request from the participants, we reopened the sub-\nmission system for the development set for both tasks after\nthe end of phase 2; therefore, Tables 5 and 7 might not be up\nto date with respect to the online leaderboard.\n168FLC Task: Test Set (Of\ufb01cial Results)\nRank Team F 1 Precision Recall\n1newspeak 0.2488 0.2862 0.2200\n2 Antiganda 0.2267 0.2882 0.1868\n3 MIC-CIS 0.1998 0.2234 0.1808\n4 Stalin 0.1453 0.1920 0.1169\n5 CUNLP 0.1311 0.3234 0.0822\n6 aschern 0.1090 0.0715 0.2294\n7 ProperGander 0.0989 0.0651 0.2056\n8 Sberiboba 0.0450 0.2974 0.0243\n9 BananasInPajamas0.0095 0.0095 0.0095\n10 JUSTDeep 0.0011 0.0155 0.0006\n11 Baseline 0.0000 0.0116 0.0000\n12 MindCoders 0.0000 0.0000 0.0000\n13 SU 0.0000 0.0000 0.0000\nTable 6: Of\ufb01cial test results for the FLC task.\n11 Conclusion and Further Work\nWe have described the NLP4IF@EMNLP-\nIJCNLP 2019 shared task on \ufb01ne-grained\npropaganda identi\ufb01cation. We received 25 and 12\nsubmissions on the test set for the sentence-level\nclassi\ufb01cation and the fragment-level classi\ufb01cation\ntasks, respectively. Overall, the sentence-level\ntask was easier and most submitted systems\nmanaged to outperform the baseline. The\nfragment-level task proved to be much more\nchallenging, with lower absolute scores, but most\nteams still managed to outperform the baseline.\nWe plan to make the schema and the dataset\npublicly available to be used beyond NLP4IF. We\nhope that the corpus would raise interest outside\nof the community of researchers studying propa-\nganda: the techniques related to fallacies and the\nones relying on emotions might provide a novel\nsetting for researchers interested in Argumentation\nand Sentiment Analysis.\nAs a kind of advertisement, Task 11 at SemEval\n20204is a follow up of this shared task. It features\ntwo complimentary tasks:\nTask 1 Given a free-text article, identify the pro-\npagandist text spans.\nTask 2 Given a text span already \ufb02agged as pro-\npagandist and its context, identify the speci\ufb01c\npropaganda technique it contains.\nThis setting would allow participants to focus\ntheir efforts on binary sequence labeling for Task 1\nand on multi-class classi\ufb01cation for Task 2.\n4http://propaganda.qcri.org/\nsemeval2020-task11/FLC Task: Development Set\nRank Team F 1 Precision Recall\n1 newspeak 0.2422 0.2893 0.2084\n2 Antiganda 0.2165 0.2266 0.2072\n3 Stalin 0.1687 0.2312 0.1328\n4 ProperGander 0.1453 0.1163 0.1934\n5 KS 0.1369 0.2912 0.0895\n6 CUNLP 0.1222 0.3651 0.0734\n7 aschern 0.1010 0.0684 0.1928\n8 gudetama 0.0517 0.0313 0.1479\n9 AMT 0.0265 0.2046 0.0142\n10 esi 0.0222 0.0308 0.0173\n11 ltuorp 0.0054 0.0036 0.0107\n12 Baseline 0.0015 0.0136 0.0008\n13 CAUnLP 0.0015 0.0136 0.0008\n14 JUSTDeep 0.0010 0.0403 0.0005\nTable 7: Results for FLC tasl on the development set.\nThe values refer to the end of phase 1 (see section 6)\nAcknowledgments\nThis research is part of the Propaganda Analy-\nsis Project,5which is framed within the Tanbih\nproject.6The Tanbih project aims to limit the ef-\nfect of \u201cfake news\u201d, propaganda, and media bias\nby making users aware of what they are reading,\nthus promoting media literacy and critical think-\ning, which is arguably the best way to address dis-\ninformation and \u201cfake news.\u201d The project is de-\nveloped in collaboration between the Qatar Com-\nputing Research Institute (QCRI), HBKU and the\nMIT Computer Science and Arti\ufb01cial Intelligence\nLaboratory (CSAIL).\nThe corpus for the task was annotated by A Data\nPro,7a company that performs high-quality man-\nual annotations.\nReferences\nKartik Aggarwal and Anubhav Sadana. 2019.\nNSIT@NLP4IF-2019: Propaganda detection from\nnews articles using transfer learning. In (Feldman\net al., 2019).\nHani Al-Omari, Malak Abdullah, Ola AlTiti, and\nSamira Shaikh. 2019. JUSTDeep at NLP4IF 2019\nTask 1: Propaganda detection using ensemble deep\nlearning models. In (Feldman et al., 2019).\nTariq Alhindi, Jonas Pfeiffer, and Smaranda Muresan.\n2019. Fine-tuned neural models for propaganda de-\ntection at the sentence and fragment levels. In (Feld-\nman et al., 2019).\n5http://propaganda.qcri.org\n6http://tanbih.qcri.org\n7http://www.aiidatapro.com\n169Alberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the 33rd AAAI Conference on Arti\ufb01-\ncial Intelligence , AAAI \u201919, pages 9847\u20139848, Hon-\nolulu, HI, USA.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni Da\nSan Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics , 5:135\u2013146.\nDaniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua,\nNicole Limtiaco, Rhomni St. John, Noah Constant,\nMario Guajardo-Cespedes, Steve Yuan, Chris Tar,\nYun-Hsuan Sung, Brian Strope, and Ray Kurzweil.\n2018. Universal sentence encoder. CoRR ,\nabs/1803.11175.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00b4on-Cede \u02dcno, Rostislav Petrov, and Preslav\nNakov. 2019. Fine-grained analysis of propaganda\nin news articles. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing , EMNLP-\nIJCNLP 2019, Hong Kong, China.\nLavinia Dan. 2015. Techniques for the Translation of\nAdvertising Slogans. In Proceedings of the Interna-\ntional Conference Literature, Discourse and Multi-\ncultural Dialogue , LDMD \u201915, pages 13\u201323, Mures,\nRomania.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, MN, USA.\nAdam Ek and Mehdi Ghanimifard. 2019. Synthetic\npropaganda embeddings to train a linear projection.\nIn (Feldman et al., 2019).\nIbrahim Fadel, Ali Tuffaha and Mahmoud Al-Ayyoub.\n2019. Pretrained ensemble learning for \ufb01ne-grained\npropaganda detection. In (Feldman et al., 2019).\nAnna Feldman, Giovanni Da San Martino, Alberto\nBarr\u00b4on-Cede \u02dcno, Chris Brew, Chris Leberknight, and\nPreslav Nakov, editors. 2019. Proceedings of the\n2019 Workshop on Natural Language Processing for\nInternet Freedom (NLP4IF): censorship, disinfor-\nmation, and propaganda . Hong Kong, China.Andr \u00b4e Ferreira Cruz, Gil Rocha, and Henrique Lopes\nCardoso. 2019. On sentence representations for pro-\npaganda detection: From handcrafted features to\nword embeddings. In (Feldman et al., 2019).\nMonika Glowacki, Vidya Narayanan, Sam Maynard,\nGustavo Hirsch, Bence Kollanyi, Lisa-Maria Neud-\nert, Phil Howard, Thomas Lederer, and Vlad Barash.\n2018. News and political information consumption\nin Mexico: Mapping the 2018 Mexican Presidential\nelection on Twitter and Facebook. Technical Report\nCOMPROP DATA MEMO 2018.2, Oxford Univer-\nsity, Oxford, UK.\nJean Goodwin. 2011. Accounting for the force of the\nappeal to authority. In Proceedings of the 9th Inter-\nnational Conference of the Ontario Society for the\nStudy of Argumentation , OSSA \u201911, pages 1\u20139, On-\ntario, Canada.\nPankaj Gupta, Khushbu Saxena, Usama Yaseen,\nThomas Runkler, and Hinrich Schutze. 2019. Neu-\nral architectures for \ufb01ne-grained propaganda detec-\ntion in news. In (Feldman et al., 2019).\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings\nof the Conference on Empirical Methods in Natu-\nral Language Processing , EMNLP \u201917, pages 7\u201312,\nCopenhagen, Denmark.\nIvan Habernal, Patrick Pauli, and Iryna Gurevych.\n2018a. Adapting serious game for fallacious argu-\nmentation to German: pitfalls, insights, and best\npractices. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation , LREC \u201918, Miyazaki, Japan.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych,\nand Benno Stein. 2018b. Before name-calling: Dy-\nnamics and triggers of ad hominem fallacies in web\nargumentation. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201918, pages 386\u2013\n396, New Orleans, LA, USA.\nRenee Hobbs and Sandra Mcgee. 2008. Teaching\nabout propaganda: An examination of the historical\nroots of media literacy. Journal of Media Literacy\nEducation , 6(62):56\u201367.\nBenjamin D Horne, Sara Khedr, and Sibel Adali. 2018.\nSampling the news producers: A large news and\nfeature data set for the study of the complex media\nlandscape. In Proceedings of the International AAAI\nConference on Web and Social Media , ICWSM \u201918,\npages 518\u2013527, Stanford, CA, USA.\nWenjun Hou and Ying Chen. 2019. CAUnLP\nat NLP4IF 2019 shared task: Context-dependent\nBERT for sentence-level propaganda detection. In\n(Feldman et al., 2019).\n170Yiqing Hua. 2019. Understanding BERT performance\nin propaganda analysis. In (Feldman et al., 2019).\nZhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-\nrectional LSTM-CRF models for sequence tagging.\nCoRR , abs/1508.01991.\nJohn Hunter. 2015. Brainwashing in a large group\nawareness training? The classical conditioning hy-\npothesis of brainwashing. Master\u2019s thesis, Uni-\nversity of Kwazulu-Natal, Pietermaritzburg, South\nAfrica.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012. What is\npropaganda, and how does it differ from persuasion?\nInPropaganda & Persuasion , chapter 1, pages 1\u201348.\nSage Publishing.\nJinfen Li, Zhihao Ye, and Lu Xiao. 2019. Detection of\npropaganda using logistic regression. In (Feldman\net al., 2019).\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A robustly optimized BERT pretraining\napproach. arXiv , abs/1907.11692.\nHarish Tayyar Madabushi, Elena Kochkina, and\nCastelle Michael. 2019. Cost-sensitive BERT for\ngeneralisable sentence classi\ufb01cation on imbalanced\ndata. In (Feldman et al., 2019).\nNorman Mapes, Anna White, Radhika Medury, and\nSumeet Dua. 2019. Divisive language and pro-\npaganda detection using multi-head attention trans-\nformers with deep learning BERT-based language\nmodels for binary classi\ufb01cation. In (Feldman et al.,\n2019).\nClyde R. Miller. 1939. The Techniques of Propaganda.\nFrom \u201cHow to Detect and Analyze Propaganda,\u201d an\naddress given at Town Hall. The Center for learning.\nRobert Muller. 2018. Internet Research Agency Indict-\nment. http://www.justice.gov/file/\n1035477/download .\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. GloVe: Global vectors for word\nrepresentation. In Proceedings of the Conference on\nEmpirical Methods in Natural Language Process-\ning, EMNLP \u201914, pages 1532\u20131543, Doha, Qatar.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word rep-\nresentations. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the As-\nsociation for Computational Linguistics: Human\nLanguage Technologies , NAACL-HLT \u20192018, pages\n2227\u20132237, New Orleans, LA, USA.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varyingshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201917, pages 2931\u20132937, Copen-\nhagen, Denmark.\nMonika L Richter. 2017. The Kremlin\u2019s platform for\n\u2018useful idiots\u2019 in the West: An overview of RT\u2019s ed-\nitorial strategy and evidence of impact. Technical\nreport, Kremlin Watch.\nSara Sabour, Nicholas Frosst, and Geoffrey E. Hinton.\n2017. Dynamic routing between capsules. In Pro-\nceedings of the Annual Conference on Neural Infor-\nmation Processing Systems 2017 , NIPS \u201917, pages\n3856\u20133866, Long Beach, CA, USA.\nFrancisca Niken Vitri Suprabandari. 2007. Ameri-\ncan propaganda in John Steinbeck\u2019s The Moon is\nDown. Master\u2019s thesis, Sanata Dharma University,\nYogyakarta, Indonesia.\nCristina Tard \u00b4aguila, Fabr \u00b4\u0131cio Benevenuto, and Pablo\nOrtellado. 2018. Fake news is poisoning Brazilian\npolitics. WhatsApp can stop it. https://www.\nnytimes.com/2018/10/17/opinion/\nbrazil-election-fake-news-whatsapp.\nhtml .\nGabriel H Teninbaum. 2009. Reductio ad Hitlerum:\nTrumping the judicial Nazi card. Michigan State\nLaw Review , page 541.\nRobyn Torok. 2015. Symbiotic radicalisation strate-\ngies: Propaganda tools and neuro linguistic pro-\ngramming. In Proceedings of the Australian Se-\ncurity and Intelligence Conference , pages 58\u201365,\nPerth, Australia.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Proceedings of the Conference on\nNeural Information Processing Systems , NIPS \u201917,\npages 5998\u20136008, Long Beach, CA, USA.\nGeorge-Alexandru Vlad, Mircea-Adrian Tanase, Cris-\ntian Onose, and Dumitru-Clementin Cercel. 2019.\nSentence-level propaganda detection in news ar-\nticles with transfer learning and BERT-BiLSTM-\nCapsule model. In (Feldman et al., 2019).\nDouglas Walton. 1996. The straw man fallacy . Royal\nNetherlands Academy of Arts and Sciences.\nAnthony Weston. 2018. A rulebook for arguments .\nHackett Publishing.\nShehel Yoosuf and Yin Yang. 2019. Fine-grained pro-\npaganda detection with \ufb01ne-tuned BERT. In (Feld-\nman et al., 2019).\nRowan Zellers, Ari Holtzman, Hannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019. Defending against neural fake\nnews. CoRR , abs/1905.12616.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection", "author": ["G Da San Martino", "A Barron-Cedeno"], "pub_year": "2019", "venue": "Proceedings of the \u2026", "abstract": "We present the shared task on Fine-Grained Propaganda Detection, which was organized  as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two subtasks. FLC is a"}, "filled": false, "gsrank": 149, "pub_url": "https://aclanthology.org/D19-5024/", "author_id": ["URABLy0AAAAJ", "0q0QVG4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ghDeu2ErfZwJ:scholar.google.com/&output=cite&scirp=148&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ghDeu2ErfZwJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 107, "citedby_url": "/scholar?cites=11276216740769304706&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ghDeu2ErfZwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/D19-5024.pdf"}}, {"title": "MurkySky: Analyzing News Reliability on Bluesky", "year": "2025", "pdf_data": "MurkySky: Analyzing News Reliability on Bluesky\nVikas Reddy1,2, Giovanni Luca Ciampaglia2,\n1Johns Hopkins University, Baltimore, MD, USA\n2University of Maryland, College Park, MD, USA\nvkasire2@jhu.edu, gciampag@umd.edu\nAbstract\nBluesky has recently emerged as a lively competitor to Twit-\nter/X for a platform for public discourse and news sharing.\nMost of the research on Bluesky so far has focused on char-\nacterizing its adoption due to migration. There has been less\ninterest on characterizing the properties of Bluesky as a plat-\nform for news sharing and discussion, and in particular the\nprevalence of unreliable information on it. To fill this gap, this\nresearch provides the first comprehensive analysis of news re-\nliability on Bluesky. We introduce MurkySky, a public tool to\ntrack the prevalence of content from unreliable news sources\non Bluesky. Using firehose data from the summer of 2024, we\nfind that on Bluesky reliable-source news content is prevalent,\nand largely originating from left-leaning sources. Content\nfrom unreliable news sources, while accounting for a small\nfraction of all news-linking posts, tends to originate from\nmore partisan sources, but largely reflects the left-leaning\nskew of the platform. Analysis of the language and hashtags\nused in news-linking posts shows that unreliable-source con-\ntent concentrates on specific topics of discussion.\nIntroduction\nDecentralization is a recent trend in social media that seeks\nto challenge the status quo offered by tech giants such as\nFacebook, Twitter/X, or TikTok. These novel networks of-\nfer a vision of user empowerment and distributed gover-\nnance, shifting control away from large tech companies to\nindividual users and collectives (Zhang et al. 2024; Hogg\net al. 2024). Yet, despite their promise for greater agency\nand control, decentralized social media platforms also in-\ntroduce challenges for researchers who wish to study them,\nand, given their relative novelty, also raise questions about\nthe reliability of the information that is being shared on them\n(Datta et al. 2010).\nOne of the most interesting new players in this field is\nBluesky: started initially within Twitter with the goal of cre-\nating a decentralized version of that platform, it later became\nan independent project with the goal, in direct competition\nwith Twitter, of providing users with greater influence on\ncontent moderation decisions and more choice in algorith-\nmic curation (Kleppmann et al. 2024). It then became one of\nthe beneficiaries of the \u2018Great Twitter Migration\u2019 (He et al.\n2023), and has recently emerged as a serious competitor to\nTwitter/X.In part due to the circumstances behind its rise, much of\nthe literature on Bluesky and other decentralized platforms\nsuch as Mastodon has so far focused on their adoption as\na consequence of the aforementioned migration from Twit-\nter/X (Jeong et al. 2024; La Cava, Greco, and Tagarelli 2021;\nHe et al. 2023; La Cava, Aiello, and Tagarelli 2023). This\nis in part due to the fact that this migration offers the rare\nopportunity to observe in real time a process of platform\u2013\nplatform competition, reminiscent in some ways of the early\nrise of the previous generation of social networking ser-\nvices, such as Facebook and LinkedIn (Ribeiro and Falout-\nsos 2015; Anderson et al. 2015).\nHowever, less attention has been devoted to characteriz-\ning properties of these emerging platforms in and of them-\nselves, not in relation to other legacy platforms. This is es-\npecially relevant, since the rise of decentralized services is\nin part in response to concerns about the degradation of\ncivic discourse under the traditional (i.e. centralized) plat-\nform model (Doctorow 2023), including concerns about the\nproliferation of inaccurate information on them (Shao et al.\n2018a,b; Lazer et al. 2018). It is thus important to assess\nwhether Bluesky offers a viable alternative as a channel for\nreliable information. To address this gap, here we study the\nprevalence of unreliable news content on BlueSky, and char-\nacterize the audiences that share and engage with it.\nIn addition to this substantive gap, there are also method-\nological reasons that make it compelling to focus on Bluesky\nas a case study for decentralized social media beyond their\nmere user growth. Decentralization poses unique challenges\nto research. Under the decentralized model all data are, by\ndesign, distributed across different entities and organiza-\ntions. In addition, on certain networks, like Mastodon, in-\ndividual instance\u2013nodes may actively discourage data col-\nlection on ethical and privacy grounds (W \u00a8ahner et al. 2024).\nThus it is important to develop novel data collection tools to\nfacilitate independent research on these platforms.\nTo address this limitation, here we introduce MurkySky, a\npublic-facing tool designed to ( i) systematically collect pub-\nlic posts with news links shared on Bluesky, and ( ii) assess\nthe prevalence of content from unreliable news source. To do\nthis, MurkySky relies on source reliability ratings as a coarse\nway to distinguish between reliable and unreliable sources,\nwhich have been shown to be robust across raters and assess-\nment criteria (Lin et al. 2023). Data from MurkySky can bearXiv:2501.10557v1  [cs.SI]  17 Jan 2025\naccessed via a REST API available at https://rapidapi.com/\ncsdl-umd-csdl-umd-default/api/murkysky-api.\nUsing MurkySky, we collected a corpus of posts contain-\ning links to news sources and their associated reliability rat-\ning. We first aggregate posts based on their reliability, and\ntracked over time the prevalence of unreliable news con-\ntent across the whole platform, observing temporal trends\nand fluctuations in the frequency of its posting and shar-\ning by Bluesky users. We then extracted the contents of the\nposts (links, hashtags, terms, etc.) and performed a num-\nber of analyses to visualize the structure of news topics,\nand the major audiences that engage and share such posts.\nFinally, we turned to analyzing the news sources included\nin these posts. We identified news sources by extracting the\nWeb domain information from the URLs of the links embed-\nded in these posts. Focusing only on English-based sources,\nwe then estimated the popularity and prevalence of news\nsources across the Left\u2013Right political spectrum.\nUltimately, by characterizing the prevalence, kind, and\nideological composition of unreliable information on\nBlueSky, our study contributes to the growing literature\non decentralized social media. Even though the results re-\nported here provide only a snapshot in time of the evolu-\ntion BlueSky, and may not generalize to other time periods,\nnonetheless MurkySky provides a user-friendly way for so-\ncial media researchers to continue monitoring the develop-\nment of this platform over time.\nRelated Works\nUsers migrate platforms in response to various push andpull\nfactors. Push factors, such as dissatisfaction with platform\npolicies or shifts in community environments, drive users\naway from their current platforms (Hou and Shiau 2020).\nFor example, the acquisition of Twitter by Elon Musk led\nto widespread concerns about content moderation and plat-\nform policies, prompting many users to seek alternatives like\nMastodon and Bluesky (Jeong et al. 2024). Pull factors, like\nthe promise of enhanced privacy, decentralized control, and\nimproved information quality attract users to new platforms\nthat better align with their values (Jeong et al. 2024).\nOf course, when users consider migrating to alternative\nsocial media platforms, their choices also reflect their prior-\nities regarding community governance, technical infrastruc-\nture, and the balance between server autonomy and network-\nwide coordination (DeVito, Birnholtz, and Hancock 2017).\nUnderstanding these distinct characteristics helps explain\nmigration patterns. We can distinguish two major models,\nthough both models distribute control away from central au-\nthorities (Raman et al. 2019).\nFederated networks like Mastodon consist of indepen-\ndently managed servers, or instances , that communicate\nthrough standardized protocols (Lemmer-Webber et al.\n2018). This setup promotes decentralization while ensur-\ning coordination and consistency across servers (La Cava,\nGreco, and Tagarelli 2021; La Cava, Aiello, and Tagarelli\n2023). Users benefit from increased control on their data, al-\nthough many other aspects of their experience depend on the\nlocal instance policies, for example vis a vis privacy.Instead, decentralized networks like Bluesky emphasize a\nunified user experience similar to that of a legacy platform\nlike Twitter/X, and relegate decentralization to its underly-\ning protocol (Kleppmann et al. 2024). This model still ad-\ndresses some of the fundamental issues of data ownership\nand platform governance at the heart of user dissatisfaction\nwith centralized platforms (Quelle and Bovet 2024), while\nfacilitating migration through the deployment of a more fa-\nmiliar user experience.\nWhile decentralization can reduce the information asym-\nmetry between users and platform operators that is moti-\nvating migration from centralized systems, it is important\nto note that it does not automatically preserves user pri-\nvacy \u2013 a key consideration for migrating users. In fact, in\nthe current implementation of Bluesky, any relay operators\ncan access user data, including direct messages and block\nlists. Nonetheless, the approach of Bluesky to decentraliz-\ning governance may be attracting users who are specifically\nconcerned about censorship and algorithmic manipulation\nin traditional systems, which may also influence the kind of\ncontent and sources they choose to share and engage with on\nthe platform (Goel et al. 2010).\nFinally, the quality of information and the health of\ncivic discussions plays a crucial role in platform dynam-\nics and user migration patterns. While decentralized plat-\nforms may initially attract users seeking reliable informa-\ntion, their growth can paradoxically make them more attrac-\ntive targets for actors seeking to spread misinformation (Co-\nhen et al. 2020; Acemoglu, Ozdaglar, and ParandehGheibi\n2010). This highlights the importance of developing mea-\nsurement tools to monitor and understand the prevalence\nof unreliable content on these platforms (Shao et al. 2016).\nThese tools are essential not only for platform operators and\nresearchers, but also for ordinary users, who seek to make\ninformed decisions about which platforms to join and trust.\nOne such tool is the Iffy Quotient, which our MurkySky\ntool is inspired to, and which tracks the share of content\nfrom \u2018iffy\u2019 (i.e. unreliable) sources on Twitter and Face-\nbook (Resnick, Ovadya, and Gilchrist 2023).\nOf course, such tools require a technical infrastructure\nfor the collection and analysis of data from these platforms.\nResearchers have traditionally relied on tools for program-\nmatic access, like the Pushshift API or the Twitter API to\nanalyze centralized social media platforms like Reddit or\nTwitter, respectively (Baumgartner et al. 2020; Murtfeldt\net al. 2024). Unlike other decentralized platforms such as\nMastodon, where data access is fragmented across instances,\nand thus there is not a single entry point capable of providing\naccess to data about the entire network, the Bluesky proto-\ncol includes a firehose primitive that gives access to the full\nstream of messages on the platform (Schneider 2019).\nMethodology\nThis section briefly describes the design of MurkySky, as\nwell as our approach for studying how news content is\nshared and engaged with on Bluesky. We briefly give details\nin particular on hashtag co-occurrence networks, audience\nsegmentation, the political orientations of news sources, and\nrank\u2013frequency distributions to uncover media consumption\ntrends.\nThe MurkySky Tool\nMurkySky collects and analyzes links shared on the Bluesky\nplatform by connecting to the Firehose API, a primitive in\nthe AT protocol that provides a real-time feed of user ac-\ntivities such as posts, likes, follows, and handle changes.\nEach Personal Data Server (PDS) is responsible for man-\naging a stream of activity for its assigned repositories, and\nwhen data is requested, relays aggregate the relevant streams\nfrom multiple PDSs into a unified feed, effectively creat-\ning a comprehensive firehose of user interactions (cf. https:\n//docs.bsky.app/docs/advanced-guides/firehose).\nMurkySky captures all these events (i.e. posts, likes, and\nreposts), extracting any embedded URIs included in them.\nWhen a user reposts or likes content, their Personal Data\nServer (PDS) stores a strong reference to the original con-\ntent in another PDS. To retrieve the original post, MurkySky\nutilizes the app.bsky.feed.getPosts endpoint from\nthe Bluesky Lexicon APIs, fetching the record from the PDS\nthat originally created the post. The extracted URLs are then\nevaluated using the NewsGuard rating system (see below)\nto assess the reliability of the information from the news\nsources, if any is present in the post.\nThe link sharing and reliability data processed by\nMurkySky is visualized using Shiny for Python, with two\nmain approaches to presenting news source reliability pat-\nterns: \u2018Relative\u2019 and \u2018Absolute\u2019 measurements. The \u2018Rela-\ntive\u2019 view displays the ratio of unreliable to reliable news\nsource links shared on Bluesky over various time frames \u2013\n1 week, 30 days, the entire dataset, or a custom period \u2013\nproviding insights into how the proportion of reliable ver-\nsus unreliable news sources changes over time. In contrast,\nthe \u2018Absolute\u2019 view offers a breakdown of these quantities\nby showing three separate trend lines: the total volume of\nnews links shared, the number of links from reliable news\nsources, and the number of links from unreliable sources ac-\ncording to NewsGuard ratings. These visualization options\nare available in both hourly and daily aggregations, enabling\na comprehensive analysis of both the volume and reliability\ntrends of news sources being shared across the Bluesky plat-\nform.\nSource Reliability Assessment\nTo determine the prevalence of unreliable content,\nMurkySky relies on source reliability ratings provided by\nNewsGuard. The NewsGuard rating system provides a sys-\ntematic approach to evaluating news source credibility. Their\nmethodology assesses news sources based on nine non-\npartisan, impartial criteria focused on credibility and trans-\nparency, such as avoiding false or misleading content, re-\nsponsibly reporting and presenting information, and clearly\nidentifying advertising (NewsGuard 2024). Trained journal-\nists evaluate each news source using this standard rubric and,\nif any of the criteria was unmet, reach out to the editorial\nteam at the news source to offer them the chance of a re-\nsponse. Senior editors then review and fact-check each rat-\ning to ensure fairness and accuracy. Ratings are regularlyupdated to reflect changes in editorial practices of a source.\nNews sources that score at or above 60 on the rubric ad-\nhere to basic standards of credibility and transparency and\nare rated reliable; scores below 60 typically indicate that a\nnews source does not meet basic journalistic standards, and\nis thus rated unreliable (Bianchi et al. 2024).\nHashtag Co-occurrence Analysis\nThis study explores hashtag co-occurrence in posts contain-\ning news links on the Bluesky platform to analyze discus-\nsions around trustworthy and untrustworthy news sources.\nAn undirected graph is constructed where nodes represent\nhashtags; in this graph there is an edge between two hash-\ntags if they co-occur within one or more posts. The weight\nof each edge is a measure of the reliability of the posts in\nwhich two given hashtags appear together. This is calculated\nby considering all posts with the two co-occurring hashtags\nthat have a link to some news source, and computing the dif-\nference between the frequency of reliable-source link-posts\nto that of unreliable-source ones, normalized by the total fre-\nquency link-posts with the two hashtags, that is\nEdge Weight =WUT\u2212WT\nWUT+WT(1)\nwhere WUT(respectively WT) refers to the number of posts\ncontaining NewsGuard-rated links with scores below 60\n(resp. at or above 60) where both hashtags co-occur. The\nweight of each node is then calculated based on the aver-\nage weight of all its incident edges. This average reflects the\noverall trustworthiness of the hashtag in relation to its other\nco-occurring hashtags. The resulting graph, with weighted\nnodes and edges, is visualized using the network analysis\ntool Gephi.\nAudience Segmentation\nWe also performed a k-core analysis of the network of likes\nand reposts on Bluesky. This network, where each user is\na node and there is an undirected edge between two users\nif one of the two liked or reposted content from the other\none, provides fine-grained information into the types of au-\ndiences that are responsible for the dissemination of news\ncontent on the platform. By identifying the highest k-core\nvalue k= 38 , we focused on the most active users who\nrepost and like posts containing news links, and then seg-\nmented them into distinct modularity classes based on their\ninteraction patterns and content preferences.\nTo better characterize these audience segments, we cre-\nated a word cloud to visualize the most prominent terms\nassociated with these highly active user groups. The word\ncloud was constructed by analyzing the \u2018user timeline\u2019 of\neach user \u2013 the feed comprising of posts and reposts made\nby the user \u2013 within each modularity class, creating a bag\nof words for the text corpus of each class, as well as a to-\ntal bag of words combining the corpora from all the mod-\nularity classes. Log-odds ratios with informative Dirichlet\npriors were then applied to identify terms that are signifi-\ncantly more likely to appear in posts from each modularity\nclass compared to the whole corpus overall (Monroe, Co-\nlaresi, and Quinn 2008). The log-odds ratio for a word w,\ndenoted as \u03b4(i\u2212j)\nw , is estimated as:\n\u03b4(i\u2212j)\nw = log\u0012yiw+aw\nni+a0\u2212yiw+aw\u0013\n\u2212\nlog\u0012yjw+aw\nnj+a0\u2212yjw+aw\u0013\n(2)\nwhere yiwis the count of word win the target modularity\nclass, yjwis the combined count of word win the other\nmodularity classes, awis the total count of word wacross\nall modularity classes, niis the total count of all words in\nthe target modularity class, njis the total count of all words\nin the other modularity classes, and a0is the total count of\nall words across all modularity classes.\nThis formula measures how much more likely a word is to\nappear in the target modularity class compared to the other\nmodularity classes, effectively highlighting distinctive terms\nand themes. By comparing the relative frequencies of words\nacross different classes, the log-odds ratio reveals key topics\nand vocabulary that are characteristic of the interactions and\ninterests of each class, providing insights into the content\npreferences and engagement patterns of users within each\nmodularity class.\nMedia Source Political Orientation\nTo classify the political orientation of media sources, we\ncombined three datasets \u2013 Media Bias Fact Check (https:\n//mediabiasfactcheck.com/), AllSides (https://www.allsides.\ncom/unbiased-balanced-news), and NewsGuard (https://\nwww.newsguardtech.com/) \u2013 providing a balanced, and\nhigh-coverage analysis of political leanings and reliability\nfor news shared on the Bluesky platform. The process be-\ngan with data collection using Media Bias Fact Check Data\nCollection, a Python script developed by the Center for\nComputational Analysis of Social and Organizational Sys-\ntems at CMU to compile a CSV file containing the politi-\ncal orientation of media outlets (https://github.com/CASOS-\nIDeaS-CMU/media bias factcheck data collection). This\ntool provided a strong starting point by offering bias ratings\nfor over 2,000media outlets.\nTo enhance the comprehensiveness and reliability of our\ndataset, we developed a hierarchical approach to combin-\ning multiple rating systems. We prioritized Media Bias Fact\nCheck as our primary source due to its higher credibility and\ndetailed analysis of news sources. For outlets not covered\nby Media Bias Fact Check, we turned to AllSides ratings,\nas both systems offer granular political bias classifications\n(such as \u201cLeft-Leaning\u201d versus simply \u201cLeft\u201d). Finally, for\nsources not covered by either Media Bias Fact Check or All-\nSides, we incorporated NewsGuard ratings, which helped\nidentify additional unreliable sources and complete our cov-\nerage. During the consolidation process, we adhered to this\nstrict hierarchy to resolve any rating discrepancies between\nsystems: Media Bias Fact Check ratings took precedence,\nfollowed by AllSides, and then NewsGuard. This system-\natic approach allowed us to develop a unified dataset that\ncomprehensively combines political bias and trustworthi-\nness assessments into a single CSV file, maximizing cov-\nerage while maintaining consistent classification standards.After collecting all NewsGuard links from June to Au-\ngust, 2024, we categorized media sources based on their rat-\nings. We relied on the threshold suggested by NewsGuard\n(see above). This process let us generate a chart illustrating\nthe distribution of political orientations across reliable and\nunreliable news links shared on the Bluesky platform. The\nfinal visualization revealed patterns in media consumption\nand reliability, offering insights into the political leanings of\nthe shared news links.\nRank\u2013Frequency of NewsGuard Domains\nTo investigate the rank\u2013frequency distribution of media\nsources on Bluesky, we applied statistical analysis to iden-\ntify patterns of media source prominence and compare dis-\ntributions between reliable and unreliable sources as classi-\nfied by NewsGuard.\nWe began by extracting and preprocessing links shared\non Bluesky between June and August, 2024, isolating their\ndomains using base URLs to ensure consistency and elimi-\nnate duplicates. These domains were then classified as \u2018re-\nliable\u2019 or \u2018unreliable\u2019 based on NewsGuard ratings (see\nabove), resulting in two separate datasets. Next, we per-\nformed a rank\u2013frequency analysis for each dataset. Do-\nmains were grouped by their frequency of occurrence, and\nwere ranked in descending order. This approach aligns with\nheavy-tailed distributions, which describe how a small num-\nber of elements often dominate occurrences in systems rang-\ning from language to information networks (Cristelli, Batty,\nand Pietronero 2012).\nTo analyze the distributions, we plotted rank against fre-\nquency for both reliable and unreliable domains. Given\nthe heavy-tailed characteristics typically observed in rank-\nfrequency distributions, we employed a logarithmic scale for\nboth axes (log\u2013log plots). This transformation allowed us\nto visualize the steepness of frequency declines and com-\npare the distributional slopes of reliable versus unreliable\ndomains. A sharper decline for reliable domains would in-\ndicate greater concentration among a few dominant sources,\nwhile a flatter curve for unreliable domains would suggest a\nmore diffused, less hierarchical distribution.\nLastly, we performed a combined rank\u2013frequency anal-\nysis, merging reliable and unreliable domains into a single\ndataset. This allowed us to observe overarching patterns of\nsource dominance across the entire platform and identify\nthe extent to which reliable and unreliable sources coexisted\nwithin the top ranks.\nResults\nDeployment of MurkySky\nWe deployed MurkySky on December 8th, 2023. After an\ninitial phase during which only posts, but not their reposts,\nwere collected, we started collecting reposts too on June\n14th, 2024. Here we report results for the period from June\n14th, 2024 to August 29, 2024, a period of slow, but steady\ngrowth, which occurred prior to the major influx of users that\noccurred in the wake of the 2024 US Presidential Elections.\nThese data reveal that unreliable information on Bluesky did\nFigure 1: Left: Hourly total counts of reliable, unreliable, and total news links on Bluesky. Right: Proportion of unreliable news\nlinks relative to total news links on Bluesky.\nnot occur frequently at the time, contributing only a small\nportion of the total news content available on the platform.\nThe Absolute Values chart (left panel of Fig. 1), which\ntracks the total number of links categorized by NewsGuard\nratings each day, shows that unreliable news links were rela-\ntively scarce during the observation period. The chart reveals\na consistent daily pattern, with the number of news articles\nshared peaking in the afternoon Greenwich Mean Time (or\nmorning Eastern Standard Time) and decreasing throughout\nthe rest of the day (Kates et al. 2021).\nThe Relative Values chart (right panel of Fig. 1), which\nexamines the proportion of unreliable links compared to the\ntotal number of links with a NewsGuard rating, further con-\nfirms the rarity of content from unreliable sources. Although\nthere are occasional spikes in the ratio of unreliable links\nwith a NewsGuard rating, these instances are infrequent. On\naverage, only about 2% of the links with a NewsGuard rating\nare from an unreliable source. This suggests that while there\nare brief periods of increased sharing of unreliable source,\nthe overall proportion of their content remained very low\nthroughout the summer of 2024.\nHashtag Co-occurrence Analysis\nWe then extract k-core hashtag co-occurrence networks for\ndifferent values of k(see Fig. 2). Combined with our weight-\ning scheme (see Eq. 1), the hashtags with which Bluesky\nusers choose to describe their posts provide a rough indi-\ncation of what topics were associated to news content, and\nthe reliability of their sources. Overall, and consistent with\nthe fact that unreliable sources were rare on Bluesky dur-\ning the observation period, most hashtags appeared exclu-\nsively in conjunction with content from reliable sources.\nHowever, unreliable-source content tended to be concen-\ntrated around certain topics only, and not uniformly dis-\ntributed across topics. By producing different network maps\nfor different values of k, we can thus evaluate the central-\nity of unreliable-source content within the broader semanticstructure of Bluesky conversations.\nAt the maximum core value ( k= 26 ), the network pre-\ndominantly captures global topics and significant events.\nProminent hashtags include #Covid , along with country-\nspecific tags like #NewZealand ,#Korea ,#Mexico ,\n#Brazil , and#Philippines . At this core level, content\nfrom unreliable news sources is rare and primarily clustered\naround two distinct topics: #CopCulture and a set of\nGerman location-based hashtags ( #Witten ,#M\u00a8ucheln ,\nand#Geilenkirchen ). These German hashtags repre-\nsent cities where massive demonstrations occurred against\nthe AfD (Alternative for Germany) party following revela-\ntions about a secret meeting where party members and other\nfar-right figures allegedly discussed plans for \u201cremigration\u201d\n\u2013 a dog-whistle for the mass deportation of immigrants and\nGerman citizens with immigrant backgrounds (Mendelsohn\net al. 2023), drawing widespread comparisons to Nazi-era\npolicies.\nFork= 21 , the network maintains the global focus ob-\nserved before, but introduces an additional cluster centered\non environmental and scientific topics. This includes hash-\ntags like #PublicHealth ,#Spatial ,#Ecosystems ,\n#GIS ,#Hydrology , and #Melting . These hashtags\nsuggest an emphasis on climate change and geographical\nresearch. Content from unreliable sources is associated to\nhashtags such as #Water and#Writers , hinting at pos-\nsible controversies or misrepresentations related to environ-\nmental and public health issues.\nFork= 16 , we see a more diversified network, reflect-\ning a broader array of topics. In addition to the environ-\nmental and geographical clusters, the network encompasses\ndiscussions on political figures like Biden and Trump, the\nclimate crisis, planet exploration, and paleontology. Content\nfrom unreliable news sources becomes notably concentrated\naround sensitive subjects including LGBTQIA+, the Israel\u2013\nHamas conflict, the MeToo movement, climate crisis, and\nthe aforementioned #CopCulture . All these involve con-\nk=11\n k=16\nk=21\n k=26Figure 2: Hashtag co-occurrence for different k-core networks ( k= 11,16,21,26). Node color indicates the reliability of news\nlinks shared with each hashtag (Yellow = unreliable, Purple = Reliable). Node position computed with a force-directed layout.\ntentious social, political, and environmental issues.\nFinally, for k= 11 we see a network where unreliable-\nsource content is primarily on global health and geopolitical\nconflicts. Key topics include Covid-19, the U.N., eugenics,\nthe aforementioned Israel\u2013Hamas conflict, and neurology.\nBluesky News Audience Segmentation\nTo better understand what type of audiences were engaged\nwith news content during the study period, we extracted un-\nigrams from the \u2018user timeline\u2019 feeds of users, focusing in\nparticular on their posts and reposts of news-linking con-\ntent. We then defined a network of likes and reposts using\nthese reposts and likes, and applied community detection to\nsegment the network in distinct audiences of users (Blondel\net al. 2008), each associated with a specific corpus of uni-\ngrams describing their reposts and like. We then used Eq. 2\nto compute the log-odds of each unigram across the various\ncorpora, and visualize word clouds for the most representa-\ntive words in each corpus, see Fig. 3. The analysis of these\ncommunity-drawn corpora, which were drawn only from\nusers in the max- k-core of the underlying network ( k= 38 ),\nreveals six prominent groups, each with distinct thematic fo-\ncuses. These groups reflect the varied interests and priorities\nof Bluesky users, especially in relation to news reliability\nand content dissemination.Traditional Media and Disinformation : This group\nis characterized by terms associated with both traditional\nmedia practices and the spread of misinformation. Key\nterms include \u201cliberation,\u201d \u201cpublishers,\u201d and \u201cinvestigation,\u201d\nwhich highlight a focus on media operations and integrity.\nAdditionally, words like \u201cdisinformation\u201d and \u201cmisinforma-\ntion\u201d highlight the group\u2019s engagement with issues of media\ncredibility and the challenges posed by misleading informa-\ntion. The presence of terms such as \u201cfacebook,\u201d \u201cinflation,\u201d\nand \u201ccrowdfunding\u201d suggests an interest in how traditional\nmedia intersects with broader societal and economic issues.\nEnvironmental and Climate Issues : Users in this group\nfocus on environmental and climate-related topics, which\ncan be seen from terms such as \u201cwildfires,\u201d \u201cclimatechange,\u201d\nand \u201cextremeheat.\u201d These words indicate a concern for long-\nterm environmental impacts and behaviors affecting the\nplanet. The inclusion of \u201cempathy\u201d and \u201caccountable\u201d re-\nflects a call for responsible and considerate action towards\nenvironmental issues, with \u201cphysorgnews\u201d and \u201cecosearch\u201d\npointing to sources and platforms that are engaged in scien-\ntific discourse about climate change.\nPolitical Movements and Censorship : This group fo-\ncuses on political activism, particularly from the perspec-\ntive of the U.S. Democratic party, as indicated by terms like\n\u201cbluewave\u201d and \u201cvoteblueeveryelection.\u201d The presence of\nFigure 3: Word clouds for each modularity class from the\nmax-k-core of the likes and repost network for posts with\nlinks to news sources. The size of each word is proportional\nto its log-odds ratio (see Eq. 2).\n\u201ccensorship\u201d points to concerns about freedom of speech\nand political influence. The term \u201coped\u201d refers to opinion\npieces from news sources like The New York Times , reflect-\ning the group\u2019s interest in political commentary. Addition-\nally, \u201ctransformation\u201d suggests a focus on political change\nand its impact on public discourse.\nHealthcare and Misinformation : This group addresses\nhealthcare related topics and misinformation within the\nmedical field. Terms such as \u201ctreatment,\u201d \u201ctracking,\u201d and \u201cfi-\nbromemes\u201d suggest a focus on health conditions, including\nchronic illnesses like fibromyalgia, and the spread of mis-\nleading or humorous content about them. Words like \u201cdisin-\nformation\u201d and \u201cchronicallyill\u201d point to concerns about how\nunreliable content can affect health perceptions and treat-\nment options. The group\u2019s attention to \u201cairborne\u201d and \u201cin-\nfection\u201d highlights ongoing issues related to disease spread\nand public health communication.\nPolitical Conflict and Community Actions : The lan-\nguage in this group reflects a focus on political conflict and\ncommunity responses, with a particular emphasis on U.S.\nDemocratic perspectives. Terms like \u201cactions,\u201d \u201cuntrustwor-\nthy,\u201d and \u201ctraitorous\u201d suggest concerns with political dis-\nputes and perceptions of betrayal or mistrust. The inclusion\nof slogans related to the 2024 U.S. Presidential Election,\nsuch as \u201cwhenwefightwewin\u201d and \u201cwearenotgoingback\u201d in-\ndicates discussions on how Kamala Harris and her party\ncould address and resolve global issues.\nTwitter Refugees, Elon Musk, and Public Discourse :\nThis group consists of users who migrated from Twitter and\nseek a similar social media experience but are dissatisfied\nwith Elon Musk\u2019s actions and the changes implemented un-\nder his leadership. Terms like \u201cxtwitter,\u201d \u201celonmusk,\u201d and\n\u201cwitless\u201d reflect their frustration with the transformation ofTable 1: Top 10 Reliable and Unreliable Domains\nRank Reliable Domains Unreliable Domains\n1 theguardian.com dailykos.com\n2 nytimes.com msnbc.com\n3 bbc.com thegatewaypundit.com\n4 washingtonpost.com wsws.org\n5 spiegel.de democracydocket.com\n6 cnn.com ohiocapitaljournal.com\n7 reuters.com middleeastmonitor.com\n8 nbcnews.com trtworld.com\n9 npr.org newsfromthestates.com\n10 rawstory.com globaltimes.cn\nthe platform. Additionally, the focus on \u201cpuberty blockers\u201d\nand \u201ccurrency\u201d highlights ongoing debates around social is-\nsues and their impact on public discourse. This vocabulary\ndemonstrates desire for a more open and user-centered ex-\nperience, contrasting with the changes and perceived short-\ncomings on Twitter.\nNews Source Political Orientation\nThen, we plotted the prevalence of news-source content, fo-\ncusing on the relationship between source political orienta-\ntion and credibility, see Fig. 4 (Left). For this analysis, we\nconsidered only English-language sources. Consistent with\nthe audience segmentation findings, we observe a prevalence\nof left or left-leaning sources. Specifically, among reliable\nsources, 59.44% are classified as \u2018Lean Left,\u2019 with an ad-\nditional 24.18% positioned on the \u2018Left,\u2019 while only 3.4%\nand 16.9% are either \u2018Lean Right\u2019 or \u2018Right\u2019, respectively.\nThis pattern applies to unreliable sources too, though unre-\nliable sources tend to be more partisan (i.e. less leaning in\ntheir orientation), compared to reliable ones. While 52.81%\nof unreliable sources are categorized as \u2019Left,\u2019 and 16.95%\nare classified as \u2019Right,\u2019 only 2.8% and 3.0% are \u2018Lean Left\u2019\nand \u2018Lean Right\u2019, respectively.\nRank\u2013Frequency of NewsGuard Domains\nThe right panel of Fig. 4 shows the rank\u2013frequency plot for\nthe popularity of news sources on Bluesky. Consistent with\nmuch of the literature, we observe a tendency for few popu-\nlar news sources to dominate the popularity rankings in both\ncategories. For reliable sources, the top entries (see Table 1)\ncorrespond to established news outlets like The New York\nTimes andThe Guardian . For unreliable sources, the top en-\ntries include a mix of national news outlets (e.g. MSNBC ,\nDaily Kos ), emerging local news networks (e.g. ohiocap-\nitaljournal.com ), and sources run by foreign entities (e.g.\ncensor.net ,globaltimes.cn ).\nThis disparity could perhaps explain the reason why con-\ntent from unreliable sources was still rare on Bluesky during\nthe summer of 2024, and is likely a reflection of the particu-\nlar audiences present on the platform, which tended to skew\non the left and favor more established (and thus also more\nreliable) news outlets (Lazer et al. 2018).\nLeft Lean Left Center Lean Right Right N/A0102030405060Prevalence (%)24.2%59.4%\n7.3%\n3.4%1.4%4.3%52.8%\n2.8%1.0%3.0%16.9%23.5%Reliable\nUnreliable\n101103101102103104105Frequency\nReliable\n101103\nRank\nUnreliable\n101103\nCombinedFigure 4: Left: Content prevalence, by source orientation and reliability. Right: Rank\u2013Frequency plots of news source popularity\nLimitations and Ethical Considerations\nThis study offers valuable insights into news source reli-\nability and user behavior on Bluesky, but several limita-\ntions should be acknowledged. One significant limitation is\nrelated to the real-time nature of the data collection pro-\ncess. MurkySky uses a WebSocket connection to collect data\nabout events (posts, reposts, likes, etc.) from the Bluesky\nFirehose. Because the Bluesky Firehose delivers only ref-\nerences to reposts, but not their complete payload, collec-\ntion of reposts required additional processing time, which at\ntimes caused our script to lag behind the stream of events and\ndisconnect from the stream. To minimize potential bias from\ndata collection outages, here we reported results from a re-\nstricted observation window, from June to August 2024, dur-\ning which our script ran without interruptions. This means\nour findings are only a snapshot in time and do not represent\nthe full period of activity of Bluesky since its inception. In\nparticular, variations in hashtag usage and language within\nthis time frame can impact the generalizability of the co-\noccurrence relationships and the identification of significant\nterms in both the hashtag co-occurrence and audience seg-\nmentation analyses.\nThe assessment of news source reliability using News-\nGuard ratings also has its limitations. While NewsGuard of-\nfers a comprehensive evaluation rubric based on indepen-\ndent, non-partisan criteria, it relies on a mix of manual an-\nnotation and social listening to identify news sources to rate.\nThis is slow a process and cannot identify each and every\nnews source, especially those in the long tail of the popular-\nity distribution, like niche or emerging news outlets (Reuben\net al. 2024). Furthermore, focusing our reliance on source-\nlevel ratings as opposed to content-level ones necessarily\nmeans our prevalence measurements are coarse-grained es-\ntimates of the true prevalence of unreliable content on the\nplatform (Green et al. 2024). Indeed, unreliable sources are\nknown to often republish content from reliable sources (for\nexample as part of syndication agreements) (Shao et al.\n2018a). In this sense, our results should be seen as a likely\nupper bound on the true prevalence of unreliable content.\nEthically, we follow best practices from the literature on\npublic social media. Our social listening tool (MurkySky)is designed to collect public data only, and even though we\ndo not keep track of post deletions, and thus cannot honor\nuser intentions about content deletions, all our results are\nreported in the aggregate only and do not include disaggre-\ngated information about individual users or posts. Likewise,\nour content analyses focus on hashtags and news sources,\nand do not mention individual users or posts.\nConclusion\nThis study presents a comprehensive analysis of news source\nreliability and user behavior on Bluesky, revealing that un-\nreliable information constitutes only about 2% of the to-\ntal news content on the platform, suggesting a relatively\nhigh standard of information reliability. The hashtag co-\noccurrence analysis uncovers distinct patterns of misinfor-\nmation, particularly around sensitive topics such as polit-\nical conflicts and environmental issues, while the k-core\nword cloud analysis highlights the diverse thematic focuses\namong user groups, ranging from environmental concerns to\npolitical activism.\nWe find that on Bluesky reliable content is prevalent\nand left-leaning, with more than 90% of news content that\nwas posted or reposted on Bluesky originating from reli-\nable sources (according to NewsGuard) and, of these, more\nthan 80% of news-posts and reposts originating from left\nor left-leaning sources. In contrast, when it come to (much\nrarer) unreliable-source content, the fraction of said content\noriginating from right or right-leaning sources is somewhat\nhigher, but still dominated by a prevalence of content from\nleft or left-leaning sources.\nAs Bluesky grows in popularity, and more users join it,\neither by migrating from different platforms or as their first\nsocial media platform, it is not clear whether these trends\nwill persist, or whether the prevalence of unreliable-source\ncontent will inevitably increase. We hope that our research\ntool, MurkySky, can help Bluesky users make sense of fu-\nture trends and serve as a tool for technologists and policy\nmakers to reflect on the health of this novel social media\nplatform.\nReferences\nAcemoglu, D.; Ozdaglar, A.; and ParandehGheibi, A. 2010.\nSpread of (mis)information in social networks. Games and\nEconomic Behavior , 70(2): 194\u2013227.\nAnderson, A.; Huttenlocher, D.; Kleinberg, J.; Leskovec, J.;\nand Tiwari, M. 2015. Global Diffusion via Cascading Invi-\ntations: Structure, Growth, and Homophily. In Proceedings\nof the 24th International Conference on World Wide Web ,\nWWW \u201915, 66\u201376. Republic and Canton of Geneva, CHE:\nInternational World Wide Web Conferences Steering Com-\nmittee. ISBN 9781450334693.\nBaumgartner, J.; Zannettou, S.; Keegan, B.; Squire, M.; and\nBlackburn, J. 2020. The Pushshift Reddit Dataset. In Pro-\nceedings of the International AAAI Conference on Web and\nSocial Media , volume 14, 830\u2013839.\nBianchi, J.; Pratelli, M.; Petrocchi, M.; and Pinelli, F. 2024.\nEvaluating Trustworthiness of Online News Publishers via\nArticle Classification. In Proceedings of the 39th ACM/SI-\nGAPP Symposium on Applied Computing , SAC \u201924, 671\u2013\n678. New York, NY , USA: Association for Computing Ma-\nchinery. ISBN 9798400702433.\nBlondel, V . D.; Guillaume, J.-L.; Lambiotte, R.; and Lefeb-\nvre, E. 2008. Fast unfolding of communities in large net-\nworks. Journal of Statistical Mechanics: Theory and Exper-\niment , 2008(10): P10008.\nCohen, R.; Moffatt, K.; Ghenai, A.; Yang, A.; Corwin, M.;\nLin, G.; Zhao, R.; Ji, Y .; Parmentier, A.; P\u2019ng, J.; Tan, W.;\nand Gray, L. 2020. Addressing misinformation in online\nsocial networks: Diverse platforms and the potential of mul-\ntiagent trust modeling. Information (Switzerland) , 11(11):\n1\u201340.\nCristelli, M.; Batty, M.; and Pietronero, L. 2012. There is\nMore than a Power Law in Zipf. Scientific Reports , 2: 812.\nDatta, A.; et al. 2010. Decentralized online social networks.\nInHandbook of social network technologies and applica-\ntions , 349\u2013378. Springer.\nDeVito, M. A.; Birnholtz, J.; and Hancock, J. T. 2017. Plat-\nforms, People, and Perception: Using Affordances to Under-\nstand Self-Presentation on Social Media. In Proceedings of\nthe 2017 ACM Conference on Computer Supported Coop-\nerative Work and Social Computing , CSCW \u201917, 740\u2013754.\nNew York, NY , USA: Association for Computing Machin-\nery. ISBN 9781450343350.\nDoctorow, C. 2023. Social Quitting. Locus , 90(1): 29. Com-\nmentary.\nFORCE11. 2020. The FAIR Data principles. https://force11.\norg/info/the-fair-data-principles/.\nGebru, T.; Morgenstern, J.; Vecchione, B.; Vaughan, J. W.;\nWallach, H.; Iii, H. D.; and Crawford, K. 2021. Datasheets\nfor datasets. Communications of the ACM , 64(12): 86\u201392.\nGoel, S.; Broder, A.; Gabrilovich, E.; and Pang, B. 2010.\nAnatomy of the Long Tail: Ordinary People with Extraordi-\nnary Tastes. In Proceedings of the Third ACM International\nConference on Web Search and Data Mining , WSDM \u201910,\n201\u2013210. New York, NY , USA: Association for Computing\nMachinery. ISBN 9781605588896.Green, J.; McCabe, S.; Shugars, S.; Chwe, H.; Horgan, L.;\nCao, S.; and Lazer, D. 2024. Curation Bubbles. American\nPolitical Science Review . Forthcoming.\nHe, J.; Zia, H. B.; Castro, I.; Raman, A.; Sastry, N.; and\nTyson, G. 2023. Flocking to Mastodon: Tracking the Great\nTwitter Migration. In Proceedings of the 2023 ACM on In-\nternet Measurement Conference , IMC \u201923, 111\u2013123. New\nYork, NY , USA: Association for Computing Machinery.\nISBN 9798400703829.\nHogg, L.; DiResta, R.; Fukuyama, F.; Reisman, R.; Keller,\nD.; Ovadya, A.; Thorburn, L.; Stray, J.; and Mathur, S. 2024.\nShaping the Future of Social Media with Middleware. Tech-\nnical report, CoRR. ArXiv:2412.10283 [cs].\nHou, A.; and Shiau, W.-L. 2020. Understanding Facebook to\nInstagram migration: a push-pull migration model perspec-\ntive. Information Technology & People , 33(1): 272\u2013295.\nJeong, U.; Sheth, P.; Tahir, A.; Alatawi, F.; Bernard, H. R.;\nand Liu, H. 2024. Exploring Platform Migration Patterns be-\ntween Twitter and Mastodon: A User Behavior Study. Pro-\nceedings of the International AAAI Conference on Web and\nSocial Media , 18(1): 738\u2013750.\nKates, S.; Tucker, J.; Nagler, J.; and Bonneau, R. 2021. The\nTimes They Are Rarely A-Changin\u2019: Circadian Regularities\nin Social Media Use. Journal of Quantitative Description:\nDigital Media , 1.\nKleppmann, M.; Frazee, P.; Gold, J.; Graber, J.; Holmgren,\nD.; Ivy, D.; Johnson, J.; Newbold, B.; and V olpert, J. 2024.\nBluesky and the AT Protocol: Usable Decentralized Social\nMedia. In Proceedings of the ACM Conext-2024 Work-\nshop on the Decentralization of the Internet , DIN \u201924, 1\u20137.\nNew York, NY , USA: Association for Computing Machin-\nery. ISBN 9798400712524.\nLa Cava, L.; Aiello, L. M.; and Tagarelli, A. 2023. Drivers of\nsocial influence in the Twitter migration to Mastodon. Sci-\nentific Reports , 13(1): 21626.\nLa Cava, L.; Greco, S.; and Tagarelli, A. 2021. Under-\nstanding the growth of the Fediverse through the lens of\nMastodon. Applied Network Science , 6(1): 1\u201315.\nLazer, D. M. J.; Baum, M. A.; Benkler, Y .; Berinsky, A. J.;\nGreenhill, K. M.; Menczer, F.; Metzger, M. J.; Nyhan,\nB.; Pennycook, G.; Rothschild, D.; Schudson, M.; Sloman,\nS. A.; Sunstein, C. R.; Thorson, E. A.; Watts, D. J.; and\nZittrain, J. L. 2018. The science of fake news. Science ,\n359(6380): 1094\u20131096.\nLemmer-Webber, C.; Tallon, J.; Shepherd, E.; Guy, A.; and\nProdromou, E. 2018. ActivityPub. W3C recommendation,\nWorld Wide Web Consortium, Wakefield, MA 01880, USA.\nLin, H.; Lasser, J.; Lewandowsky, S.; Cole, R.; Gully, A.;\nRand, D. G.; and Pennycook, G. 2023. High level of corre-\nspondence across different news domain quality rating sets.\nPNAS Nexus , 2(9).\nMendelsohn, J.; Le Bras, R.; Choi, Y .; and Sap, M. 2023.\nFrom Dogwhistles to Bullhorns: Unveiling Coded Rhetoric\nwith Language Models. In Rogers, A.; Boyd-Graber, J.; and\nOkazaki, N., eds., Proceedings of the 61st Annual Meeting\nof the Association for Computational Linguistics (Volume 1:\nLong Papers) , 15162\u201315180. Toronto, Canada: Association\nfor Computational Linguistics.\nMonroe, B.; Colaresi, M.; and Quinn, K. 2008. Fightin\u2019\nWords: Lexical Feature Selection and Evaluation for Iden-\ntifying the Content of Political Conflict. Political Analysis ,\n16(4): 372\u2013403.\nMurtfeldt, R.; Alterman, N.; Kahveci, I.; and West, J. D.\n2024. RIP Twitter API: A eulogy to its vast research contri-\nbutions. Technical report, CoRR. ArXiv:2404.07340 [cs].\nNewsGuard. 2024. NewsGuard Rating Process and Criteria.\nAccessed: January 10, 2024.\nQuelle, D.; and Bovet, A. 2024. Bluesky: Network Topol-\nogy, Polarisation, and Algorithmic Curation. Technical re-\nport, CoRR. ArXiv:2405.17571 [cs].\nRaman, A.; Joglekar, S.; de Cristofaro, E.; Sastry, N.; and\nTyson, G. 2019. Challenges in the decentralised web: The\nMastodon case. In Proceedings of the ACM SIGCOMM In-\nternet Measurement Conference (IMC) , 217\u2013229. ACM.\nResnick, P.; Ovadya, A.; and Gilchrist, G. 2023. Iffy Quo-\ntient: A Platform Health Metric for Misinformation. White\nPaper v3, University of Michigan Center for Social Media\nResponsibility, Ann Arbor, MI, USA.\nReuben, M.; Friedland, L.; Puzis, R.; and Grinberg, N. 2024.\nLeveraging Exposure Networks for Detecting Fake News\nSources. In Proceedings of the 30th ACM SIGKDD Confer-\nence on Knowledge Discovery and Data Mining , KDD \u201924,\n5635\u20135646. New York, NY , USA: Association for Comput-\ning Machinery. ISBN 9798400704901.\nRibeiro, B.; and Faloutsos, C. 2015. Modeling Website Pop-\nularity Competition in the Attention-Activity Marketplace.\nInProceedings of the Eighth ACM International Conference\non Web Search and Data Mining , WSDM \u201915, 389\u2013398.\nNew York, NY , USA: Association for Computing Machin-\nery. ISBN 9781450333177.\nSchneider, N. 2019. Decentralization: an incomplete ambi-\ntion. Journal of Cultural Economy , 12(4): 265\u2013285.\nShao, C.; Ciampaglia, G. L.; Flammini, A.; and Menczer,\nF. 2016. Hoaxy: A Platform for Tracking Online Misinfor-\nmation. In Proceedings of the 25thInternational Confer-\nence Companion on World Wide Web , WWW \u201916 Compan-\nion, 745\u2013750. Republic and Canton of Geneva, Switzerland:\nInternational World Wide Web Conferences Steering Com-\nmittee. ISBN 978-1-4503-4144-8.\nShao, C.; Ciampaglia, G. L.; Varol, O.; Yang, K.; Flammini,\nA.; and Menczer, F. 2018a. The spread of low-credibility\ncontent by social bots. Nature Communications , 9(1): 4787.\nShao, C.; Hui, P.-M.; Wang, L.; Jiang, X.; Flammini, A.;\nMenczer, F.; and Ciampaglia, G. L. 2018b. Anatomy of an\nonline misinformation network. PLOS ONE , 13(4): 1\u201323.\nW\u00a8ahner, M.; Deubel, A.; Breuer, J.; and Weller, K. 2024.\n\u201cDon\u2019t research us\u201d\u2014How Mastodon instance rules connect\nto research ethics. Publizistik , 69(3): 357\u2013380.\nZhang, Z.; Zhao, J.; Wang, G.; Johnston, S.-K.; Chalhoub,\nG.; Ross, T.; Liu, D.; Tinsman, C.; Zhao, R.; Van Kleek, M.;and Shadbolt, N. 2024. Trouble in Paradise? Understand-\ning Mastodon Admin\u2019s Motivations, Experiences, and Chal-\nlenges Running Decentralised Social Media. Proc. ACM\nHum.-Comput. Interact. , 8(CSCW2).\nPaper Checklist \u2013 Ethics Guidelines\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes\n(d) Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? Yes, this\nis mentioned in the Limitations and Ethical Consider-\nations section.\n(e) Did you describe the limitations of your work? Yes, in\nthe Limitations and Ethical Considerations section.\n(f) Did you discuss any potential negative societal im-\npacts of your work? Yes, in the Limitations and Ethical\nConsiderations section.\n(g) Did you discuss any potential misuse of your work?\nYes, in the Limitations and Ethical Considerations sec-\ntion.\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, re-\nsponsible release, access control, and the reproducibil-\nity of findings? Yes, in the Limitations and Ethical\nConsiderations.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? NA\n(b) Have you provided justifications for all theoretical re-\nsults? NA\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? NA\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-\nserved in your study? NA\n(e) Did you address potential biases or limitations in your\ntheoretical framework? NA\n(f) Have you related your theoretical results to the existing\nliterature in social science? NA\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? NA\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA\n(b) Did you include complete proofs of all theoretical re-\nsults? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? NA\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? NA\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nNA\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? NA\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made? NA\n(f) Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? NA\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity ...\n(a) If your work uses existing assets, did you cite the cre-\nators? Yes\n(b) Did you mention the license of the assets? NA\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? NA\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you\u2019re using/curat-\ning? No, because we are analyzing publicly available\nBluesky data collected with a social listening tool and\nso obtaining consent for this collection is not practical.\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? Yes\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR\n(see FORCE11 (2020))? NA\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset (see Gebru et al.\n(2021))? NA\n6. Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity ...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA(d) Did you discuss how data is stored, shared, and dei-\ndentified? NA", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "MurkySky: Analyzing News Reliability on Bluesky", "author": ["V Reddy", "GL Ciampaglia"], "pub_year": "2025", "venue": "arXiv preprint arXiv:2501.10557", "abstract": "Bluesky has recently emerged as a lively competitor to Twitter/X for a platform for public  discourse and news sharing. Most of the research on Bluesky so far has focused on"}, "filled": false, "gsrank": 150, "pub_url": "https://arxiv.org/abs/2501.10557", "author_id": ["w49k3AgAAAAJ", "ay9uGpcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:-NybAU4tvaYJ:scholar.google.com/&output=cite&scirp=149&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=-NybAU4tvaYJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:-NybAU4tvaYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2501.10557"}}, {"title": "LOCO: the topic-matched corpus for studying conspiracy theories", "year": "2024", "pdf_data": "LOCO: the topic-matched corpus for studying conspiracy theories\nAlessandro Miani,a\naUniversity of Bristol, School of Psychological Science, 12a, Priory Road, Bristol BS8 1TU, United Kingdom\n\u00a9 20xx Elsevier Ltd. All rights reserved.\nAbstract\nLOCO is an 88-million-token corpus of conspiracy and mainstream standalone documents (N= 96,743) gathered\nfrom 150 websites. LOCO has been built as a freely available resource to help researchers extract features, test\nhypotheses, and generate predictive and classification models. With its rich set of additional data (freely available at\nhttps://osf.io/snpcg), LOCO allows for the study of both the content and spread of CTs, permitting comparisons\nwith a topic-matched corpus of mainstream documents.\n1 Introduction\nConspiracy theories (CTs) explain significant social events as being secretly orchestrated by powerful and malicious\nelites (Douglas et al., 2019). Associated with detrimental societal outcomes, such as vaccine hesitancy, climate skep-\nticism, and non-normative political engagement (Jolley et al., 2022), CTs pose substantial threats to democracy and\npublic health (Ecker et al., 2024). Therefore, understanding the content of CTs is crucial to combating their spread\nand mitigating their consequences. To achieve this goal, the first step is to build comprehensive corpora of CTs.\nSince the advent of Web 2.0, studies devoted to understanding CTs have typically focused on user-generated texts\nfrom social media (e.g., Klein et al., 2019; Samory & Mitra, 2018). However, posts and comments found on social\nmedia are not CTs per se, as they generally consist of short texts and are often tied to a thread. A better approach\nto address these limitations is to study CTs as texts from web pages. Compared to posts and tweets on social media,\nweb pages provide space for in-depth and elaborated discourse, constituting standalone and structured texts.\nYet, even when researchers consider web pages, the resource-intensive nature of manual coding prevents the creation\nof corpora with sufficient statistical power for language analysis, typically limiting studies to a few hundred documents\n(see e.g., Sak et al., 2015). Thus, a solution is to automate text extraction by first compiling a list of websites delivering\nCTs and then extracting their content. For this purpose, pre-compiled lists of misinformation websites exist, such as\nthe proprietary NewsGuard1and other freely available lists, like MediaBiasFactCheck (MBFC),2the Misinformation\nDomains dataset,3and the work of Lin et al. (2023). Works relying on these lists have typically reached large\nsample sizes, consisting of hundreds of thousands to millions of documents (Carrella et al., 2023; Miani, Carrella, &\nLewandowsky, 2024).\nHowever, building a corpus solely of conspiracy documents is not sufficient because it does not enable comparisons\nbeyond descriptive analyses. To systematically study the language of CTs, researchers need a control corpus that\nallows for between-group comparisons. Ideally, these two corpora should be matched by topics, meaning that for each\ntopic, there is both a conspiracy and a non-conspiracy (mainstream) version. Such a structure facilitates language\ncomparison and helps identify discriminating features of conspiratorial language. We thus created LOCO, a topic-\nmatched corpus of web pages delivering CTs.\n2 LOCO\nLOCO (theLanguageOfCOnspiracy theories; Miani et al., 2021) is a turnkey resource for understanding the\nlanguage of CTs that includes 23,937 conspiracy and 72,806 mainstream documents matched by topics that revolve\naround events that have generated CTs. Each document in LOCO is associated with both fine- and coarse-grained\nsemantic indexing as well as a measure of spread.\n2.1 Building LOCO\nLOCO was built by retrieving documents via Google searches using seeds associated with events that generated CTs on\nwebsites previously classified as either conspiratorial or mainstream. Figure 1 illustrates the workflow to build LOCO.\n1https://www.newsguardtech.com\n2https://mediabiasfactcheck.com\n3https://github.com/JanaLasser/misinformation domains\nThis manuscript is a preprint and has not undergone proofreading, copy-editing, or typesetting. It is shared here in\nits original form ahead of formal publication in theInternational Encyclopedia of Language and Linguistics(3rdedition).\nReaders should be aware that the content may still contain errors or inconsistencies. The published version is\navailable at doi:10.1016/B978-0-323-95504-1.00183-6.1\nWebsites\nbbc.com\nfoxnews\ninfowars\n...Seeds\nmoon landing\nclimate change\ncovid-19\n...\nSearch query (website i\u00d7seed j)\nsite:bbc.com climate change\nGoogle Search page\nURLs Extraction\n1.https://www.bbc.com/url 01.html\n2.https://www.bbc.com/url 02.html\n3.https://www.bbc.com/url 03.html\nTexts Extraction\nDoc1:Climate change could move into un-\ncharted...\nDoc2:The ultimate goal of the Arctic experi-\nment...\nDoc3:In a tumultuous year, the positive mile-\nstones...\nFig. 1:LOCO\u2019s construction workflow\nWe paired a set of websites (W i) with a set of seeds (S j) to generate a series of Google queries (Q ij=W i\u00d7S j). From\neach query, the HTML results page was parsed to extract the URLs needed to extract texts.\nWe started by compiling the two lists of seeds and websites. Seeds are search terms used to retrieve topic-specific\ntext associated with popular and timely CTs (N= 47; e.g.,Princess Diana\u2019s death,Moon Landing,9/11). The list of\nconspiracy websites (N= 58; e.g.,infowars.com) was obtained by selecting websites with the highest conspiratorial\nrating from MBFC. The list of mainstream websites (N= 92; e.g.,bbc.com) was generated in a data-driven fashion\nby extracting websites returned by Google for each seed.\nWe combined the two lists to generate Google search queries that return web pages containing the seed\u2019s terms\nwithin a website (e.g., \u201csite:bbc.com climate change\u201d). Google was chosen because it allows for automated URL\nextraction and provides consistent search criteria across all websites, avoiding biases introduced by site-specific search\nengines. To ensure the results were in English, we added \u201chl=en\u201d to the queries. For each results page, we parsed\nthe HTML to extract URLs pointing to candidate web pages. The R scripts for reproducing LOCO\u2019s construction are\navailable athttps://osf.io/4vk7f.\nThe human-readable text was extracted from the HTML page via the Python packagegoose,4chosen for its superior\nperformance from our tests compared to other packages. Next, we cleaned the corpus by removing documents where\nthe percentage of the top 1,000 English words was below 40%, and those with word counts outside\u00b12.5 standard\ndeviations around the mean. The final word count range for each document was between 100 and 10,000 words.\n2.2 Extracting Features from LOCO\nLOCO includes a comprehensive set of additional data. At the document level, beyond typical text statistics (such\nas word, sentence, and paragraph counts) and the seeds used to retrieve the web pages, each text is provided with\nfine-grained semantic fingerprinting (see Box .1), including lexical features and topics. Lexical features (N= 286)\nwere extracted using two popular word-counting tools, LIWC and Empath. Topics (N= 600) were extracted via topic\nmodeling at three different resolutions (100, 200, and 300 topics) and labeled using the top 15 most important terms.\nWe also included a measure of whether a text is a representative instance of the conspiracy subcorpus (N= 4,277).\nThis was achieved by computing the similarity of each document to the overall conspiracy subcorpus. High similarity\nindicates that the document exhibits prototypical conspiratorial language. Each document also includes metrics of\nsocial media engagement, such as Facebook shares, comments, and reactions, obtained via the web tool SharedCount.5\nAt the website level, we gathered information from MBFC about each website\u2019s political bias, factual reporting,\nand level of pseudoscientific claims. From the web tool SimilarWeb,6we collected metrics such as monthly global\n4https://github.com/goose3/goose3\n5https://www.sharedcount.com\n6https://www.similarweb.com/corp/ourdata/\nThis manuscript is a preprint and has not undergone proofreading, copy-editing, or typesetting. It is shared here in\nits original form ahead of formal publication in theInternational Encyclopedia of Language and Linguistics(3rdedition).\nReaders should be aware that the content may still contain errors or inconsistencies. The published version is\navailable at doi:10.1016/B978-0-323-95504-1.00183-6.2\nvisits and rank, as well as the percentages for each type of incoming traffic (e.g., direct access, Google search, or social\nmedia).\n2.3 Using LOCO\nGiven the large number of variables offered in LOCO, there is a risk offishing expeditions, i.e., testing numerous\nvariables simultaneously and then HARKing (Hypothesizing After the Results are Known; Hills & Miani, in press).\nWhen testing multiple variables at once, researchers should consider correcting for multiple tests to limit the rate of\nfalse positives. Furthermore, the unrestricted availability of LOCO complicates pre-registrations, as researchers might\nalready be familiar with the data before pre-registering (S\u00f8gaard et al., 2023). Leveraging LOCO\u2019s topic-matching\nstructure, researchers might consider multilevel modeling, cross-nesting documents within topics (or seeds) and/or\nwebsites.7Note also that the average explained variance (R2) of individual lexical features is typically low (with an\naverage marginalR2of .00055; Miani, van der Plas, & Bangerter 2024).\nSemantic fingerprinting\nEach document in LOCO is provided with two types of fine-grained semantic fingerprinting: lexical features and topic modeling.\nThe extraction of lexical features is usually done by counting words using dictionaries, which are pre-compiled lists of words or\nfeatures categorized by topic (e.g., health), psychological dimension (e.g., affection), or typographical/grammatical category (e.g.,\npunctuation, past-tense verbs). Two widely used and complementary sets of dictionaries are LIWC (a proprietary standalone\nprogram; Tausczik & Pennebaker, 2009) and Empath (an open-source Python package; Fast et al., 2016). The main difference\nbetween the two is that LIWC was constructed based on human coding, whereas Empath was assembled in a data-driven fashion\nand can generate ad hoc categories. The two dictionaries highly correlate with each other on similar categories (for a comprehensive\ndiscussion, see Hills & Miani, in press).\nTopic modeling is based on Latent Dirichlet Allocation (LDA, Blei et al., 2003), which is an unsupervised probabilistic machine\nlearning model capable of identifying co-occurring word patterns and extracting the underlying topic distribution for each text\ndocument within a corpus. Extracting LDA topics from a corpus requires researchers to set the desired number of topics (k): a\nlarger number of topics provides a fine-grained resolution, while a smaller number yields more general topics (Colin & Murdock,\n2020). Efforts are underway to develop unsupervised algorithms for identifying the optimalk, such as fitting an LDA model\nfor each value ofkprovided by the researcher. This method has been used to estimatekfrom tweets, press articles, and web\npages (Lasser et al., 2023; Mayor & Miani, 2023; Miani et al., 2022). However, applying such algorithms to large corpora can be\nresource- and time-intensive. Therefore, for large corpora, researchers have typically chosen to provide different topic resolutions\n(Carrella et al., 2023; Miani, Carrella, & Lewandowsky, 2024).\n3 Works using LOCO\nSince its release, LOCO has been a valuable resource for various research endeavors. Comprising texts with additional\nmetadata, LOCO provides a comprehensive tool for analyzing the content and spread of CTs. LOCO\u2019s construction\nmethod is versatile and can be applied to various types of corpora beyond CTs. For example, it was employed to\ncreate DONALD, the topic-matched corpus of 2 million documents focused on politically polarizing topics across four\ntypes of ideological biases, including a large set of CTs (Miani, Carrella, & Lewandowsky, 2024).\nUsing LOCO\u2019s texts, researchers have applied various computational techniques to investigate conspiratorial dis-\ncourse. Unlike the typically short posts on social media, the longer texts from LOCO provide a richer context for\nunderstanding conspiratorial incoherence (Miani et al., 2022). Results support the psychological notion that incoher-\nence is a hallmark of conspiracism (Miani & Lewandowsky, 2024). Additionally, other studies have used LOCO to\nanalyze term co-occurrence in gender identity issues (Fleckenstein, 2024) and to examine word-formation patterns in\nnominal compounds (Miani, van der Plas, & Bangerter, 2024). Future research could focus on parsing documents to\nidentify narrative elements using syntactic rules, replicating methods applied to social media texts (Samory & Mitra,\n2018; Tangherlini et al., 2020).\nBy simply counting words, researchers can investigate the psychological dimensions of conspiracism. Using Em-\npath, we found that conspiracy (vs. mainstream) documents frequently use language related to deception, dominance,\nterrorism, and power (Miani et al., 2021). This aligns with language patterns observed among conspiracy believers on\nsocial media (Klein et al., 2019). We also discovered that representative (vs. other) conspiratorial documents tend to\nexhibit exaggerated conspiratorial language associated with social identification, negative emotions, and refutational\nrhetoric. These documents are also more frequently shared on Facebook. Perhaps unsurprisingly, conspiratorial lan-\nguage appears intensified in both mainstream and conspiracy documents that mention (real or theorized) conspiracies.\nBesides texts, LOCO includes a rich set of supplementary data. Topics, seeds, and lexical features can be used as\nindependent or dependent variables, or to further subset LOCO for specific analyses, such as examining health-related\n7In R, usinglme4:lmer(DV\u223csubcorpus + (1|topic) + (1|website))\nThis manuscript is a preprint and has not undergone proofreading, copy-editing, or typesetting. It is shared here in\nits original form ahead of formal publication in theInternational Encyclopedia of Language and Linguistics(3rdedition).\nReaders should be aware that the content may still contain errors or inconsistencies. The published version is\navailable at doi:10.1016/B978-0-323-95504-1.00183-6.3\ncontent across different ideologies (Reiter-Haas, 2023) or constructing networks based on topic co-occurrence patterns\n(Miani et al., 2022). On the website level, analysis of incoming traffic to LOCO\u2019s websites revealed that users of\nconspiratorial sites are more likely to gather information via bookmarked websites or through online social networks,\nrather than impartial search engines (Miani et al., 2021; Carrella et al., 2023). This behavior suggests the presence of\nconfirmation bias.\nAnnotation schemes for CTs have been developed using LOCO (Fort et al., 2023; Mompelat et al., 2022). Future\nresearch should focus on developing tools for the automatic identification of CTs. For instance, leveraging LOCO\u2019s\ntopic-matched structure, researchers can create dictionaries of CTs by contrasting mainstream and conspiracy nar-\nratives within each seed topic (e.g.,Lady Diana), so to isolate conspiracy-specific terms, filtered from topic-specific\nwords (e.g.,car crash,Paris).\n4 Conclusions\nLOCO is a freely available topic-matched corpus from which researchers can extract features and generate predictive\nand classification models. The strength of LOCO lies in its richness in (meta-)data, which allows for the study of\nboth the content and spread of CTs and facilitates comparisons with a topic-matched set of mainstream documents.\nThe multilevel structure of LOCO allows researchers to consider the natural hierarchical grouping of documents cross-\nnested within websites and topics. This is useful for extracting conspiracy-specific linguistic markers. Concluding,\nLOCO is a rich resource that, while primarily providing data for lexical analysis and document spread, can also help\nto reveal psychological processes.\nAcknowledgments\nAM (ORCID:0000-0001-6610-3510) is supported by the Swiss National Science Foundation (SNSF, project number\n214293, \u201cIn/coherent worldviews\u201d).\nBlei, D. M., Ng, A. Y ., & Jordan, M. I. (2003, March). Latent dirichlet allocation.The Journal of Machine Learning Research,3(null), 993-1022.\nCarrella, F ., Miani, A., & Lewandowsky, S. (2023, May). IRMA: the 335-million-word Italian coRpus for studying MisinformAtion. In A. Vlachos\n& I. Augenstein (Eds.),Proceedings of the 17th conference of the european chapter of the association for computational linguistics(pp.\n2339\u20132349). Dubrovnik, Croatia: Association for Computational Linguistics. doi: 10.18653/v1/2023.eacl-main.171.\nColin, A., & Murdock, J. (2020). LDA Topic Modeling: Contexts for the History & Philosophy of Science. In G. Ramsey & A. de Block (Eds.),\nDynamics Of Science: Computational Frontiers in History and Philosophy of Science.S.l.: Pittsburgh University Press.\nDouglas, K. M., Uscinski, J., Sutton, R. M., Cichocka, A., Nefes, T., Ang, C. S., & Deravi, F . (2019, 2). Understanding conspiracy theories.\nPolitical Psychology,40(S1), 3\u201335. doi: 10.1111/pops.12568.\nEcker, U., Roozenbeek, J., van der Linden, S., Tay, L. Q., Cook, J., Oreskes, N., & Lewandowsky, S. (2024, June). Misinformation poses a bigger\nthreat to democracy than you might think.Nature,630(8015), 29\u201332. doi: 10.1038/d41586-024-01587-3.\nFast, E., Chen, B., & Bernstein, M. S. (2016, May). Empath. InProceedings of the 2016 CHI conference on human factors in computing systems.\nACM. doi: 10.1145/2858036.2858535.\nFleckenstein, K. (2024). Representations of gender in conspiracy theories: a corpus-assisted critical discourse analysis.Critical Discourse\nStudies,(), 1\u201317. doi: 10.1080/17405904.2024.2334263.\nFort, M., Tian, Z., Indiana University, USA, Gabel, E., Indiana University, USA, Georgiades, N., . . . Indiana University, USA (2023). Bigfoot\nin Big Tech: Detecting Out of Domain Conspiracy Theories. InProceedings of the Conference Recent Advances in Natural Language\nProcessing - Large Language Models for Natural Language Processings(pp. 353\u2013363). INCOMA Ltd., Shoumen, BULGARIA. doi: 10.26615/\n978-954-452-092-2 040.\nHills, T., & Miani, A. (in press). A short primer on historical natural language processing. In T. Hills & G. Pogrebna (Eds.),Cambridge handbook\nof behavioral data science.Cambridge University Press.\nJolley, D., Marques, M. D., & Cookson, D. (2022, October). Shining a spotlight on the dangerous consequences of conspiracy theories.Current\nOpinion in Psychology,47(), 101363. doi: 10.1016/j.copsyc.2022.101363.\nKlein, C., Clutton, P ., & Dunn, A. G. (2019, June). Pathways to conspiracy: The social and linguistic precursors of involvement in Reddit\u2019s\nconspiracy theory forum.PLOS ONE,14(11), e0225098. doi: 10.1371/journal.pone.0225098.\nLasser, J., Aroyehun, S. T., Carrella, F ., Simchon, A., Garcia, D., & Lewandowsky, S. (2023). From alternative conceptions of honesty to\nalternative facts in communications by us politicians.Nature human behaviour,7(12), 2140\u20132151. doi: 10.1038/s41562-023-01691-w.\nLin, H., Lasser, J., Lewandowsky, S., Cole, R., Gully, A., Rand, D. G., & Pennycook, G. (2023, September). High level of correspondence across\ndifferent news domain quality rating sets.PNAS Nexus,2(9), . doi: 10.1093/pnasnexus/pgad286.\nMayor, E., & Miani, A. (2023). A topic models analysis of the news coverage of the omicron variant in the united kingdom press.BMC Public\nHealth,23(1), 1-18. doi: 10.1186/s12889-023-16444-7.\nMiani, A., Carrella, F ., & Lewandowsky, S. (2024). DONALD: the 2m-document dataset of news articles for studying the language of dubious\ninformation.. Retrieved fromhttps://osf.io/6xpa2\nMiani, A., Hills, T., & Bangerter, A. (2021). LOCO: The 88-million-word language of conspiracy corpus.Behavior Research Methods,54(4),\n1794\u20131817. doi: 10.3758/s13428-021-01698-z.\nMiani, A., Hills, T., & Bangerter, A. (2022). Interconnectedness and (in)coherence as a signature of conspiracy worldviews.Science Advances,\n8(43), 1\u20139. doi: 10.1126/sciadv.abq3668.\nMiani, A., & Lewandowsky, S. (2024). Still very much dead and alive: Re-reconsidering belief in contradictory conspiracy theories.\ndoi: 10.31219/osf.io/t6a54.\nThis manuscript is a preprint and has not undergone proofreading, copy-editing, or typesetting. It is shared here in\nits original form ahead of formal publication in theInternational Encyclopedia of Language and Linguistics(3rdedition).\nReaders should be aware that the content may still contain errors or inconsistencies. The published version is\navailable at doi:10.1016/B978-0-323-95504-1.00183-6.4\nMiani, A., van der Plas, L., & Bangerter, A. (2024). Loose and tight: Creative formation but rigid use of nominal compounds in conspiracist texts.\nThe Journal of Creative Behavior,58(1), 114\u2013127. doi: 10.1002/jocb.633.\nMompelat, L., Tian, Z., Kessler, A., Luettgen, M., Rajanala, A., K \u00a8ubler, S., & Seelig, M. (2022). How \u201cloco\u201d is the loco corpus? annotating the\nlanguage of conspiracy theories. InProceedings of the 16th linguistic annotation workshop (law-xvi) within lrec2022.\nReiter-Haas, M. (2023). Exploration of Framing Biases in Polarized Online Content Consumption. InCompanion Proceedings of the ACM Web\nConference 2023(pp. 560\u2013564). Austin TX USA: ACM. doi: 10.1145/3543873.3587534.\nSak, G., Diviani, N., Allam, A., & Schulz, P. J. (2015, December). Comparing the quality of pro- and anti-vaccination online information: a\ncontent analysis of vaccination-related webpages.BMC Public Health,16(1), . doi: 10.1186/s12889-016-2722-9.\nSamory, M., & Mitra, T. (2018). \u201cthe government spies using our webcams\u201d: The language of conspiracy theories in online discussions.\nProceedings of the ACM on Human-Computer Interaction,2(CSCW), 1\u201324. doi: 10.1145/3274421.\nS\u00f8gaard, A., Hershcovich, D., & de Lhoneux, M. (2023). A two-sided discussion of preregistration of NLP research.\nTangherlini, T. R., Shahsavari, S., Shahbazi, B., Ebrahimzadeh, E., & Roychowdhury, V. (2020, June). An automated pipeline for the discovery\nof conspiracy and conspiracy theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the web.PLOS ONE,15(6), e0233879.\ndoi: 10.1371/journal.pone.0233879.\nTausczik, Y. R., & Pennebaker, J. W. (2009, December). The psychological meaning of words: Liwc and computerized text analysis methods.\nJournal of Language and Social Psychology,29(1), 24\u201354. doi: 10.1177/0261927x09351676.\nThis manuscript is a preprint and has not undergone proofreading, copy-editing, or typesetting. It is shared here in\nits original form ahead of formal publication in theInternational Encyclopedia of Language and Linguistics(3rdedition).\nReaders should be aware that the content may still contain errors or inconsistencies. The published version is\navailable at doi:10.1016/B978-0-323-95504-1.00183-6.5", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "LOCO: the topic-matched corpus for studying conspiracy theories", "author": ["A Miani"], "pub_year": "2024", "venue": "NA", "abstract": "LOCO is an 88-million-token corpus of conspiracy and mainstream standalone documents (N=  96,743) gathered from 150 websites. LOCO has been built as a freely available resource"}, "filled": false, "gsrank": 151, "pub_url": "https://files.osf.io/v1/resources/bfuv3_v2/providers/osfstorage/682c643d0d7051a771f07db3?format=pdf&action=download&direct&version=1", "author_id": ["zsMnlFgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:rC58RwP1hgwJ:scholar.google.com/&output=cite&scirp=150&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D150%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=rC58RwP1hgwJ&ei=H7WsaJGVCJXUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:rC58RwP1hgwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.osf.io/v1/resources/bfuv3_v2/providers/osfstorage/682c643d0d7051a771f07db3?format=pdf&action=download&direct&version=1"}}, {"title": "Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections", "year": "2023", "pdf_data": "Nature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 904\nnature human behaviour\nArticlehttps://doi.org/10.1038/s41562-023-01550-8\nPolitical polarization of news media and \ninfluencers on Twitter in the 2016 and 2020 \nUS presidential elections\nJames Flamino\u2009  \u20091, Alessandro Galeazzi\u2009  \u20092,3, Stuart Feldman4, \nMichael W. Macy\u2009  \u20095, Brendan Cross\u2009  \u20091, Zhenkun Zhou6, Matteo Serafino7, \nAlexandre Bovet\u2009  \u20098, Hern\u00e1n A. Makse\u2009  \u20097  & Boleslaw K. Szymanski\u2009  \u20091 \nSocial media has been transforming political communication dynamics for \nover a decade. Here using nearly a billion tweets, we analyse the change in Twitter\u2019s news media landscape between the 2016 and 2020 US presidential elections. Using political bias and fact-checking tools, we measure the volume of politically biased content and the number of users propagating such information. We then identify influencers\u2014users with the greatest ability to spread news in the Twitter network. We observe that the fraction of fake and extremely biased content declined between 2016 and 2020. However, results show increasing echo chamber behaviours and latent ideological polarization across the two elections at the user and  influencer levels.\nA growing number of studies have documented increasing political  \npolarization in the USA that is deeper than at any time since the  \nAmerican Civil War1\u20133. Partisan division over issues has increased among \nthose affiliated with political and news media organizations\u2014elected \nrepresentatives, party officials and political pundits\u2014alongside an \nalarming increase in affective polarization among voters4,5. This two-level  \npattern\u2014issue polarization among political elites and affective  \npolarization among voters\u2014invites further research on the diffusion  \nof polarized political information between those in positions of  \npolitical influence and the larger population.\nThis diffusion of political information is difficult to track with \ntraditional survey and roll call voting data that lack relational measures. \nIncreasing reliance on social media for political communication is \nopening unprecedented opportunities to study the diffusion of politi -\ncal information and misinformation6,7 over communication networks8. \nFurthermore, the rapid growth of Twitter, Facebook, Reddit and other \nsocial media have transformed the communications and information \npropagation landscape. Alongside traditional broadcast media and face-to-face communication, people now can search for and exchange \ninformation with billions of other users in a global network. Recent \nstudies have examined the impact of new technologies, like Twitter and \nYouTube, on election outcomes9\u201318, including the effects of disinforma -\ntion19\u201325. Other studies have documented how social media platforms \ncontribute to polarization through the creation of echo chambers26\u201335.\nWe use a vast amount of social media data collected from  \nTwitter over the 2016 and 2020 US presidential elections enriched with \npolitical bias classifications to study diffusion dynamics of political \ncontent through news media. In this longitudinal study, we focus on \nshifts in Twitter\u2019s political landscape caused by changes in the news \nmedia content being disseminated. We discovered that, proportion -\nally, the fraction of tweets in the fake news and extremely biased news \ncategories decreased or stayed the same on Twitter.\nWe also focus on analysing news media influencers, defined as \nusers with the greatest ability to broadly propagate news media infor -\nmation over social media. We analyse changes in their influence, com -\nposition and the types of news media they are disseminating between Received: 28 January 2022\nAccepted: 3 February 2023\nPublished online: 13 March 2023\n Check for updates\n1Department of Computer Science and Network Science and Technology Center, Rensselaer Polytechnic Institute, Troy, NY, USA. 2University of Brescia, \nBrescia, Italy. 3Ca\u2019 Foscari University of Venice, Venice, Italy. 4Schmidt Futures, New York, NY, USA. 5Departments of Information Science and Sociology, \nCornell University, Ithaca, NY, USA. 6School of Statistics, Capital University of Economics and Business, Beijing, China. 7Levich Institute and Physics \nDepartment, City College of New York, New York, NY, USA. 8Department of Mathematics and Digital Society Initiative, University of Zurich, Zurich, \nSwitzerland. \u2009e-mail: hmakse@ccny.cuny.edu; szymab@rpi.edu\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 905\nArticle https://doi.org/10.1038/s41562-023-01550-8is not actually a 100% sample, the 10% is not a randomly distributed 10% \nand the 1% is not a randomly distributed 1%. Thus, standard sampling \nmethods are difficult to apply to the collected Twitter data. However, for the goals of our article, this is our best option as there are no other \nlarge-scale, comprehensive datasets available for both the 2016 and \n2020 US elections that are readily accessible to us.\nThe classifications of news media websites presented below and \nused here, including \u2018fake\u2019 , \u2018extremely biased\u2019 , \u2018left\u2019 and \u2018right\u2019 , and espe -\ncially the boundaries between categories, are a matter of opinion rather \nthan a statement of fact. We use terms \u2018left\u2019 and \u2018right\u2019 for political lean -\nings that are often referred to as \u2018liberal\u2019 and \u2018conservative\u2019 on the US political ideology spectrum. The categorizations and labels assigned \nto the corresponding classes and used here originated in publicly \navailable datasets from fact-checking and bias rating organizations, \nwhich are credited below. The classifications of political views and the \nrelated conclusions contained in this article should not be interpreted \nas representing opinions of the authors or their funders.\nFor each tweet containing a URL link, we extracted the domain \nname of the URL (for example, www.cnn.com) and classified each link \ndirecting to a news media outlet according to this outlet\u2019s political bias. \nThe 2016 and 2020 classifications rely on the website allsides.com (AS), \nfollowed by the bias classification from the website mediabiasfactch-\neck.com (MBFC) for outlets not listed in AS (both accessed on 7 January \n2021 for the 2020 classification). We classified URL links for outlets that \nmostly conform to professional standards of fact-based journalism in \nfive news media categories: right, right leaning, centre, left leaning and \nleft. We also include three additional news media categories to include \noutlets that tend to disseminate disinformation: extreme bias right, \nextreme bias left and fake news. Websites in the fake news category have \nbeen flagged by fact-checking organizations as spreading fabricated \nnews or conspiracy theories, while websites in the extremely biased \ncategory have been flagged for reporting controversial information \nthat distorts facts and may rely on propaganda, decontextualized \ninformation or opinions misrepresented as facts. A detailed explana-\ntion of the methodologies used by AS and MBFC for rating news outlets \nand of the differences in classification between 2016 and 2020 is given \nin the Methods. The full lists of outlets in each category in 2016 and \n2020 are given in Supplementary Tables 1 and 2. In the 2016 dataset,  \n30.7 million tweets, sent by 2.3 million users, contain a URL directed \nto a media outlet website. The 2020 dataset contained 72.7 million  \ntweets with news links sent by 3.7 million users. This number reveals  \na drop in the fraction of tweets flowing from users that propagate  \nnews media links, from 18% in 2016 to 10% in 2020.\nThe proportions of tweets and users who sent a tweet in each of the \nnews media categories are shown in Fig. 1a,b along with other statistics \nabout the activity of users in each category. The raw numbers used to \ngenerate this figure are shown in Supplementary Table 3. Importantly, \nthey demonstrate that the fraction of tweets in the fake and extremely \nbiased category (representing outlets that were most susceptible \nto sharing disinformation) decreased from 10% to 6% for fake news \nand from 13% to 6% for extreme bias right news. The fraction of users \nwho shared those tweets also decreased for extreme bias right news \n(from 6 to 3%) but not for fake news (which remained at 3%). However, the total number of tweets and users increased over the same period  \nby 411 and 80%, respectively. In short, between 2016 and 2020, the \nnumbers of tweets and users grew at a rate in the range of 80 to\u2009246% \nfor all categories, except the number of users who shared extreme bias \nright news, which declined by 10%.\nThe fraction of tweets in the extreme bias left category was only \n2% in 2016 and it dropped to a mere 0.05% in 2020. The number of \ntweets in this category also dropped. The fraction of tweets in the \ncentre category also decreased, from 21 to 10%, but the number  \nof tweets increased dramatically. By contrast, the fraction of left-leaning  \ntweets increased from 24 to 45%, while the fraction of right-leaning \ntweets increased from 3 to 6%.the two elections. We find that the proportion of top influencers affili -\nated with news media organizations decreased in 2020, while the pro -\nportion of those affiliated with political organizations increased. We \nalso quantify and compare the levels of polarization between 2016 and \n2020. There are multiple types and levels of polarization established in \nliterature36\u2013 43, which we discuss in the Supplementary Materials. How -\never, we focus on \u2018ideological polarization\u201944 of Twitter users, defined \nas the level of ideological separation between the political alignments \nof the content that these users propagate. For the remainder of the \narticle, we use the term \u2018polarization\u2019 to refer specifically to \u2018ideological  \npolarization\u2019 . Our polarization analysis reveals an increase in echo \nchamber behaviour between 2016 and 2020 resulting from Twitter \nusers\u2019 tendency to be less likely to disseminate information or interact \nwith users on the other side of the political spectrum. This analysis also \nsuggests that new influencers from 2020 are more polarized than the influencers who persisted from the 2016 US presidential election. We \nbelieve these results establish a foundation for future work by provid -\ning observations on trends and patterns arising in Twitter\u2019s political \nlandscape in news media.\nResults\nWe note that the initial foundation for this research is established in \nref. 21, which analysed the news media diffusion dynamics on Twitter \nduring the 2016 US presidential election. We harness part of the data \nused in that article and follow its relevant methodology to identify and \nclassify influencers in the 2020 US election data. Additionally, following \nan editorial request added to the reviews of this article, we anonymized \nall Twitter usernames of personal accounts in both the main manu-\nscript and the Supplementary Materials. Specifically, if the username \nbeing presented does not represent an established major news organi-\nzation that is verified on Twitter, that username is replaced with an \nalias. This alias consists of two parts: affiliation and year of relevance. A \nuser\u2019s affiliation can be with the media, US politics or personal (see the  \n News media influencers section for more information on how we define  \naffiliations). The personal affiliation is also split into \u2018individual\u2019 and \n\u2018other\u2019 labels, with the former representing no official affiliation with \nmedia or politics, and the latter representing a lack of information \nrequired to make a distinction. All affiliation labels are shortened to \ntheir first five letters in the alias. Year of relevance is determined as \nbeing in the top 100 list of influencers for 2016, 2020 or both. See the Twitter retweet networks section for more details on influencers and \nour influencer identification algorithm. So, a politically affiliated user \nthat was influential only in 2016 will have an alias of \u2018Polit_2016\u2019 .\nNews media on Twitter in 2016 and 2020\nWe tracked the spread of political news on Twitter in 2016 and 2020 \nby analysing two datasets containing tweets posted between 1 June \nand election day (8 November in 2016 and 2 November in 2020). The \ndata were collected continuously using the Twitter search API with the \nnames of the two presidential candidates in each of the presidential \nelections in 2016 and 2020 as keywords. Using more keywords target-\ning specific media outlets or hashtags concerning specific news events \ncould miss election-related tweets that did not contain references to \nthe list of outlets or events.\nThe 2016 dataset contains 171 million tweets sent by 11 million users \nand was used in refs. 13,21 to assess the influence of disinformation on \nTwitter in 2016. The 2020 dataset contains 702 million tweets sent by 20 million users. Hence, we observe a near doubling of the number of Twitter users involved in spreading political news in 2020 compared with 2016.\nAt the time we collected our data, the statistical analyses of the \nraw collected data were limited because the data collection process \ndesigned by Twitter itself has been shown to have sampling issues. For \ninstance, the probability of non-responses from API queries is not pro -\nvided by Twitter, and Twitter has acknowledged that the 100% firehose \nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 906\nArticle https://doi.org/10.1038/s41562-023-01550-8The shift away from the centre may indicate the increasing ideo -\nlogical polarization, both among users and media outlets. However, \nmost of the decrease in the fraction of centre media outlets reflects the \nshift of cnn.com, because it was categorized by AS as centre in 2016 and \nas left leaning in 2020. CNN accounted for more than twice the number \nof tweets in 2020 compared to the top outlet of the centre category  \nin that year ( thehill.com) (Supplementary Table 2).\nFigure 1c,d shows the fraction of URLs for all categories as a func-\ntion of a user\u2019s modal category for users that posted at least two links \nin our datasets. The analysis reveals two clusters in 2016 and 2020, \none with categories from the right (right leaning, right, fake news and \nextreme bias) and a second cluster with categories from the centre and \nleft (centre, left leaning and left). These two clusters can be interpreted \nas two echo chambers in terms of a separation in news consumption. \nAsymmetrical patterns in Fig. 1c,d above and under the diagonal reveal \nthat users in the right-wing echo chamber also link to an extremely \nlimited number of left-wing media outlets. The users in the left-wing \necho chamber link to right-wing media in an even more limited way. This \nis consistent with asymmetry between left-leaning and right-leaning \nusers in social media observed in previous studies21,25 ,35,45.\nTo estimate the volume of tweets sent from automated accounts \nsuch as bots, we counted the number of tweets sent from unofficial \nTwitter clients, such as Twitter clients other than the Twitter Web client, Android client, iPhone client or other official clients. Unofficial Twitter \nclients include those who are using a variety of different applications used to automate all or part of an account activity, such as third-party \napplications used typically by brands and professionals (for example, \nSocialFlow or Hootsuite) or bots created with malicious intentions13. \nThere is no fast and precise method for bot detection, and the sheer \nsize of our datasets prevented us from using complicated methods, \nwhich often use natural language processing, machine learning clas-\nsifiers and similar techniques46. Filtering through unofficial clients \nprovides a simple alternative that meets the baseline requirements \nfor our analyses. Accounts from unofficial clients are only removed \nduring our polarization analysis presented later in the article. For all \nother analyses, these accounts are kept, as they impact the patterns of \ninformation diffusion that we are analysing.\nThe overall fraction of tweets sent from unofficial clients was 8% in \n2016, but this had dropped to 1% in 2020. A similar drop over the same \nperiod was observed in the average activity of their users (Supplemen-\ntary Table 3). This decrease, and the proportional decrease of extremely \nbiased and fake news, could be attributed in part to measures taken by Twitter to limit the virality of disinformation. As mentioned above, the \nrelative volume of tweets linking to disinformation websites dropped by a \nhalf in 2020 compared to 2016, and the fraction of users sharing fake news \ndecreased even more substantially (Fig. 1a,b  and Supplementary Table 3).\nFraction of tweets\nFraction of users\n0\nLeft Left Left\nleaningRight\nleaningRight\nFake news andextreme biasCentreLeft\nleaningRight\nleaningRight\nFake news andextreme biasCentre0.20.40.6\nLeft\nLeft leaning\nCentre\nRight leaning\nRight\nFake news and\nextreme bias\nLeft\nLeft leaning\nCentre\nRight leaning\nRight\nFake news and\nextreme biasLeftLeft leaningCentreRight leaningRightFake news and\nextreme bias\nLinks categoryUser main category\n00.20.40.6Fraction\nof linksa b\nc d\nFig. 1 | Distribution of news media links in 2016 and 2020 by news media \ncategory. a,b, The fraction of tweets (a ) and users (b ) that sent tweets with a \nURL pointing to a website belonging to one of the categories. Solid coloured bars show fractions for the 2016 election, while striped bars represent the corresponding fractions from the 2020 election. Users are classified as being in the category in which they posted the most links. c ,d, The fractions of links across \ncategories as a function of the users\u2019 main categories, for those users that have at least two links classified, in 2016 (c ) and 2020 (d ).\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 907\nArticle https://doi.org/10.1038/s41562-023-01550-8To understand how users shifted between categories from 2016 \nto 2020, we track users that were active during both election years  \n(14% of the users present in 2020) and we classified each of them into \nthe category in which they posted the most tweets in each year. Figure 2  \nshows the resulting shifts. The two largest shifts are among users in \nthe centre and left news category in 2016 that AS rating shifted to the \nleft-leaning category in 2020. This made the left-leaning category the \nlargest in 2020, by shifting the three most widely shared news out -\nlets: The New York Times, Washington Post and CNN (Supplementary  \nTable 2). We also observe a large fraction of users in the fake and \nextremely biased news category in 2016 that moved to the right news category in 2020. However, these user shifts also reflect the change in \nthe classification of media outlets from 2016 to 2020. We infer the ideo -\nlogical position of Twitter users without relying on the news outlet clas -\nsification (see the subsection Polarization among Twitter users) and \nshow that the resulting positions are highly correlated with the user\u2019s positions computed using the news categories in which they posted.\nTwitter retweet networks\nTo capture the dynamics of information diffusion, we reconstruct \nretweet networks corresponding to each news media category. We add \na link (a directed edge) going from node v  to node u  in the news network \nwhen user u retweets the tweets of user v\u2009\u2260\u2009u containing a URL linking \nto a website belonging to one of the news media categories. Only one \nsuch link is created regardless of the number of tweets retweeted by u . \nWith our convention, the direction of the link represents the direction \nof the influence propagation between Twitter users.\nA 2015 study by Metaxas et al.47 found that \u2018retweeting indicates \nnot only interest in a message, but also trust in the message and the \noriginator, and agreement with the message contents\u2019 . Although the \nretweeting does not explicitly represent support of the retweeted \ncontent (since a user who almost always retweets CNN might occa -\nsionally retweet Fox News), in a retweet the user cannot remark about \nreasons for propagating this content to others, while the alternatives of  \nquoting or replying do allow users to remark and so are much more  \nsuitable for non-supporting forwarding of news. Accordingly,  \nwe assume that most users agree with and are influenced by the  \ninformation they are propagating through retweets.\nWithin a network, the in-degree of a node is the number of links \nthat point inward to the node and the out-degree is the number of links \nthat originate at a node and point outward to other nodes. A retweet originates at the node that posted the original tweet, not at the node \nthat posts the retweet (indicating the flow of influence in the direc -\ntion of the retweeter). Thus, for our retweet networks, the in-degree \nof a user is equal to the number of users they retweeted at least once \nand their out-degree is the number of users who have retweeted them \nat least once. The higher a node\u2019s out-degree, the greater its local \ninfluence. The characteristics of the retweet networks are shown in \nSupplementary Table 4.\nWe then use an algorithm to find the best spreaders of news media \ninformation within each network, that is, the influencers of the cor -\nresponding news media category. An alternative of finding the \u2018most \ninfluential users overall\u2019 through extracting influencers from the \nretweet networks of all users would result in a list of influencers domi -\nnated by left-leaning and centre-biased influencers while other news \nmedia bias categories would be underrepresented (see Supplementary \nFig. 1, which shows the top overall influencers and their political align -\nments for both 2016 and 2020). This imbalance would understate the impact of these influencers on polarization between the two election \nyears. Hence, we extract the top influencers from the retweet networks \nof each news media category to present an accurate representation \nof critical influencers from the different news media categories. As \nmentioned earlier, our work builds on and uses some of the results of \nthe 2016 US election from ref. 21, which identifies influencers using the \nCollective Influence (CI) approach48. To ensure consistency of results, \nwe too use CI to find influencers in the 2020 data.\nNews media influencers\nThe CI heuristic identifies and ranks influencers in 2016 and 2020 data -\nsets and assigns to each influencer a value CIout that represents the \nstrength of influence it exerts. The influencers identified from these \nnetworks only pertain to Twitter accounts who disseminate content \nby providing links to external sources. We compare the rankings of \nthe influencers extracted from the 2020 network with the rankings \nof the influencers previously extracted by CI from the 2016 network21.  \nA selection of 87 influencers (limited to officially recognized major news \norganizations that are verified on Twitter as per our disclaimer at the \nbeginning of this section) and their rankings with their corresponding \nnews media categories are shown in Supplementary Table 5.\nFor the remainder of the article, we use the top influencers \nextracted from the fake, extreme bias right, right, right-leaning, centre,  \nleft-leaning and left news media categories. However, we do not \n20202016Left\nLeftLeft\nleaning\nLeft\nleaningRight\nleaning\nRight\nleaningRight\nRightFake and\nextreme bias\nFake and\nextreme biasCentre\nCentre\nFig. 2 | Shifts of users across news media categories from 2016 to 2020. The \nrelative size of each category in 2016 corresponds to the ratio of the numbers of unique users in this category to the left category (Fig. 1 ). The shifts among categories over time are proportional to the fraction of users that were classified in 2016 and in 2020 in the two involved categories. Overall, 14% of the users present in 2020 persisted from the 2016 dataset.\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 908\nArticle https://doi.org/10.1038/s41562-023-01550-8include any influencers from the extreme bias left news media cate-\ngory. According to Supplementary Table 4, this category is sparse and \ndisconnected, with very few users compared to the users\u2019 populations \nin the other networks. Our goal is to extract influencers that are highly \nrelevant to the dissemination of information on Twitter across the dif -\nferent news media categories. However, we find that the influencers \nextracted from the extreme bias left category have an extremely low \nstanding in the Twitter community compared to influencers extracted \nfrom other categories. For example, the 25th most influential user of \nthe extreme bias left category has about 100 followers, while the 25th most influential user of the left category has over one million. Hence, \nkeeping the extreme bias left category exaggerates the importance of \nthese influencers and diminishes the importance of influencers in other \ncategories. Consequently, we exclude the extreme bias left category \nfrom the analyses that follow.\nAnalysis of our lists of the top influencers in 2016 reveals that  \ntraditional news influencers were mostly journalists with verified  \nTwitter accounts linked to traditional news media outlets. By con -\ntrast, fake and extremely biased news also contains influencers whose \naccounts are unverified or deleted, with deceptive profiles and much \nshorter lifespans on Twitter than traditional media influencers (see Sup -\nplementary Figs. 2 and 3 and supporting data in Supplementary Table 6  \nfor details on the proportional shift of users to and from inactivity \nbetween election years). However, some of these influencers, despite \ntheir unknown, non-public nature, still played an important role in the \ndiffusion of disinformation and information on Twitter21. There has \nbeen a substantial increase in deleted influencer accounts spreading \nfake news, from two in the top 25 in 2016 to eight in 2020. Also, the \nextreme bias right news, which in 2020 consisted primarily of verified \ninfluencers, grew from 15 in the top 25 in 2016 to 23 in 2020. We also \nfound that among the top 100 influencers from each news media cat-\negory in 2020, there was a 29% retention rate of influencers persisting \nfrom 2016. Furthermore, for the top 25 influencers from each of these \ncategories, we find the retention rate to be 36%. Meanwhile, as noted \nearlier, the rate of retention between 2016 and 2020 for the average \n2016 user was 14%. The increase in retention rate between the average user and the top 25 influencers is 157%, indicating that the more influ-ential a user, the higher their retention rate.\nUsing a manual labelling process (see Methods for details), we label \nthe top 25 influencers of each news media category in 2016 and 2020 \nas affiliated with media or political organizations, or unaffiliated, to \nobserve the makeup of influencer types for these labels. Here, we define \nan influencer\u2019s \u2018affiliation\u2019 with media or politics as their primary job, \nor other direct connection from which they received periodic financial \nsupport. Or, if the influencer is an organizational entity, this classifica -\ntion indicates that this is a legally recognized company. Subsequently, \nan affiliation indicates if the influencer is either a professional or a  \nlegal company outside Twitter.\nAn influencer affiliated with a media organization could be a media \ncompany or official media outlet, or an established writer, reporter or \npaid consultant. An influencer affiliated with a political party could be a \npolitician, a political campaign platform or an affiliate of the platform, \nor someone who officially represents an aspect of US politics. We also \nsplit the unaffiliated label into two subclassifications: independent \nand \u2018other\u2019 . An independent influencer is not officially affiliated with \nany media or political platforms. The \u2018other\u2019 label represents influ -\nencers whose accounts have no description or context that could \nbe used to identify them. We generalized these affiliation labels to \ncapture a variation of affiliations to media and politics. It also prevents  \novercategorization of influencers or the creation of categorization \nexceptions.\nThe fractions of influencers within these affiliation labels are \nshown in Fig. 3 . The results reveal that unaffiliated influencers are more \ncommon in the fake and extreme bias news media categories, while \naffiliated influencers are more common in the other news categories.  A similar trend is evident in the fractions of verified and unverified influ -\nencers found in these categories, as fake and extreme bias news catego -\nries contain fewer verified influencers. In addition, media-affiliated \ninfluencers have a greater presence in the left, left-leaning and centre news categories compared with their counterparts.\nInterestingly, the number of media-affiliated influencers within \nmost of the news media categories decreased from 2016 to 2020. The exceptions are the extreme bias right and fake news catego\n-\nries, in which the number of media-affiliated influencers increased. \nAlso, the extreme bias right category had increased numbers of politically affiliated influencers. This indicates a shift in polariza\n-\ntion of influencers affiliated with right-biased political and media organizations towards the extreme bias right and fake news, as well as the emergence of news media-affiliated influencers in \nthese categories. We discuss these changes in polarization in more  \ndetail below.\nIn addition to changes in affiliations from 2016 to 2020, we observe \na substantial reshuffle of the ranking of influencers. Figure 4  shows the \nchange in rankings of the top 10 influencers in left and left-leaning, \nright and right-leaning, and extreme bias right and fake news catego -\nries. The ranking reshuffle in the centre news category is shown in  \nSupplementary Fig. 4.\nThe comparison reveals several interesting changes between 2016 \nand 2020. First, we see that highly influential users rise from obscurity. \nAcross all categories, a set of previously unranked or very low-ranked \nusers break into the top 10 rankings. Considering all unique users in the \ntop 25 influential users (from all categories of news media), 58% came \nfrom outside the top 100 influential users in 2016. However, most of \nthese newly influential users are related in some way to media or politi -\ncal organizations, while 28% of these new influencers are independent.\nObserving the change in rankings by news media category, we \nsee that right and right-leaning, and extreme bias right and fake news \ncategories have a substantally higher fraction of the top 10 influencers \nwho were previously outside the top 50, compared with the change in \nrankings among the groups in left and left-leaning news categories. All \ncategories show a large number of influencers falling out of the top 50 \nfrom 2016 to 2020, and in the case of the left news influencers, we see \ntheir former positions filled by users who were much less influential in \n2016. The influencers with extreme bias right and fake news affiliations \nshow the most volatility with regards to retaining the top 10 influencer 100\nMedia\nPolitical\nIndependent\nOther\n2016\n202080\n60\n40\n20Percentage of influencer account types\n0\nLeft\nLeft leaningRight leaningRight\nFake news\nExtreme bias rightCentre\nFig. 3 | Reshuffling distribution of the top 25 influencer types from 2016 to \n2020, by news media category. Influencers are classified as affiliated with a media organization, political organization, independent or other (for example, unidentified).\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 909\nArticle https://doi.org/10.1038/s41562-023-01550-8positions, with many top 10 influencers in 2016 ranked below 50 in  \n2020 (or even banned from Twitter).\nThe change of classification of some news media outlets is also \nreflected in the category shifts of their Twitter accounts. In particular, \nthe first- and third-highest ranked influencers in the centre category  \n(@CNN and @politico) in 2016 shifted to left leaning. Such shifts of \nlarge and influential media influencers from news categories indicate \nthe increased content polarization on Twitter. A shift of media-affiliated \ninfluencers from the right to the extreme bias right is also visible (for \nexample, @DailyMail and @JudicialWatch), as is the emergence of \nnew media-affiliated influencers in these categories (for example,  \n@newsmax and @OANN). In contrast with the shift to the extremes \namong large media influencers, the centre rankings remained mostly \nconsistent between 2016 and 2020 (Supplementary Fig. 4). Some new \nusers rose from low ranks to fill in the gaps, including the winner of the \n2020 US presidential election, but only one user dropped out of the top 50 \nentirely, and the remaining shifts are internal to these top-ranked users.\nPolarization among Twitter users\nThe evolution of influencers from different news media categories  \n(Figs. 1 and 2 ) suggests an increased polarization in the relations among \ninfluencers between 2016 and 2020. Here we broaden the scope of \npolarization analysis to the Twitter users who are consuming and retweeting the influencers\u2019 content. For the 2016 and 2020 data, we \nconsider a set of the top 100 influencers from each news media cate -\ngory. To avoid polarization changes caused by the varying composition \nof the set of influencers, we filter these sets to contain only influenc -\ners that were present in both the 2016 and 2020 CI rankings. For 2016 and 2020, the final set sizes are 505 and 548 influencers, respectively. For this analysis we use all the retweets in our datasets, not only those containing a link to a news outlet, but remove the retweets sent from unofficial Twitter clients.\nWith influencers as nodes, we create two fully connected similarity \nnetworks derived from the 2016 and 2020 Twitter networks, respec -\ntively. The weight of an edge between any two influencers in these  \nnetworks represents the similarity between the retweeters that propa -\ngate the content of these influencers (see Methods for more details). \nAny edges with a weight of 0 are removed. A distribution of the similar -\nity values for both networks, as well as their degree distributions, are shown in Supplementary Fig. 5a,c. In both similarity networks, a com-munity detection algorithm found two communities. One contained \ninfluencers affiliated with news media in the centre, left-leaning and \nleft news categories, while the other contained those affiliated with \nnews media in the right-leaning, right and fake news categories. This \nindicates that influencers separate their user bases according to the \ncontent they generate.\nIcon lege nd\nLinked to  media organ ization\nLinked to  political organization\nOtherIndependentRank 2016 User Rank 20201\n2\n3\n4\n5\n6\n7\n8\n9\n10\n12\n3119\nRank >  50Rank 2016 User Rank 2020\n1\n2\n3\n4\n6\n7\n8\n9\n10\n11\n12\n14\n19\n32\nRank >  50Rank 2016 User Rank 2020\n@FoxNews\n@WSJ\nPolit_both\n@DailyCaller\n@WashTimes\n@RT_com\n@dcexaminer\nMedia_2016\n@RT_America\n@nypost\n@FoxNewsInsider\n@WSJPolitics\n@DailyMail\nPolit_2016\nPolit_2016\nIndep_both\nPolit_2016\nMedia_2016\n@foxandfriends\nPolit_both\nMedia_both\nPolit_2020\nMedia_2020\nMedia_2020\nMedia_2020\nMedia_2020\nPolit_2020\nMedia_20201\n2\n3\n4\n5\n6\n7\n8\n9\n10\n31\n37\nRank >  50\nIndep_both\nPolit_both\n@DailyCaller\nOther_2016\n@BreitbartNews\nMedia_both\nMedia_2016\n@wikileaks\nMedia_2016\nMedia_both\n@DailyMail\nMedia_both\nIndep_2016\nOther_2016\nIndep_both\nIndep_2016\nMedia_2016\n@gatewaypundit\nPolit_both\n@JudicialW atch\nMedia_both\nMedia_2020\nMedia_2020\nMedia_2020\nMedia_2020\nMedia_2020\n@newsmax\n@OANN\nIndep_2020\nIndep_20201\n2\n3\n4\n5\n6\n7\n8\n9\n10\n13\n16\n27\n37\nRank >  501\n2\n3\n4\n5\n6\n7\n8\n910\n13\n19\n27\n32\n50\nRank >  50@CNN\n@Hu\ufb00Post\n@nytimes\n@TIME\n@washingtonpost\n@ABC\n@politico\n@thedailybeast\n@CNNPolitics\n@NBCNews\n@RawStory\n@Hu\ufb00PostPol\n@Slate\n@NewY orker\n@PolitiFact\n@CBSNews\nMedia_both\n@TPM\n@voxdotcom\n@ABCPolitics\n@Salon\nMedia_2016\n@thinkprogress\n@MSNBC\nMedia_both\n@NPR\nMedia_2020\nMedia_2020\nIndep_2020\nMedia_20201\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n14\n22\n25\n50\nRank >  50\nCentreLeft leaningLeft\nExtreme bias rightRightRight leaning\nFake newsExtreme bias right/fake newsLeft/left leaning Right/right leaning\nColour legend\nFig. 4 | Change in influencers\u2019 rankings from 2016 to 2020. Influencers \nranked in the top 10 in at least one news media category in 2016 or 2020 are shown. The 2016 rankings are displayed to the left of the username or alias, with 2020 rankings listed on the right. For each user only one shift is shown. Its colour changes from the user\u2019s highest ranked news media category in 2016 to that in 2020. Each panel shows the change over time between two news media categories.\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 910\nArticle https://doi.org/10.1038/s41562-023-01550-8Figure 5 illustrates this separation, showing subsampled similar-\nity networks of the 25 most influential nodes for each news media  \ncategory for 2016 (left panel) and 2020 (right panel). Using force-  \ndirected network layouts driven by the weighted similarity edges, we \nvisualize for both years the two formed communities, one consisting  \nof the right-biased and fake news influencers and the other the \nleft-biased influencers. These communities form an echo chamber \nmotif like the one seen in Fig. 1c,d for the analysis of the fractions of \nURLs in all news media categories.\nVisually, Fig. 5  suggests a loss of intercommunity connections and \nincreased density of intracommunity links from 2016 to 2020. We probe if these changes are reflected in the communities arising in the two main \nsimilarity networks containing the nodes from the influencer sets with \nthe top 100 influencers of each news media category. We found that \nthe trends persist, with community separation in the 2020 network \nincreasing compared to the separation of communities in the 2016 \nnetwork, as measured by modularity and the normalized cut between \ncommunities (see Methods for details).The modularity for the 2020 network was 0.465 with a 95% con -\nfidence interval (CI95) of (0.454,\u20090.475), versus 0.401 with a CI95 of \n(0.392,\u20090.409) in 2016, indicating more closely knit communities in \n2020, with stronger in-community ties and weaker between-community \nties. This trend agrees with the changes of the average normalized cut, \nwhich decreased from 0.285 with a CI95 of (0.232,\u20090.339) in 2016 to \n0.052 with a CI95 of (0.046,\u20090.058) in 2020. Both results show a much \nstronger separation of the two clusters in the later election and suggest \na fundamental shift in retweeting behaviour. Between 2016 and 2020, \nusers became even more likely to disseminate content from influencers \nwith similar biases and less likely to spread content from influencers with opposing biases, effectively reducing cross-bias encounters and \ndiscourse. In addition, we also computed the above metrics on net -\nworks generated from user quote similarity to confirm that retweets \nare the strongest form of endorsement of influencer content (Sup -\nplementary Table 7). We also report the modularity and normalized \ncut for the subsampled networks of Fig. 5 in Supplementary Table 8, \nwhich reinforces the trend observed in the results above.\nFake newsExtreme bias rightRightRight leaningCentreLeft leaningLeft\n1818\n2926\n27\n2824\n252117\n161616\n1919\n2320333\n7\n2213\n15144\n10\n121186\n91\n2\n5\n(1)(4)\n(9)\n(12)(25)(12)\n(19)\n(3)(1)\n(1)(1)(19)\n(2)\n(5)(7)(3)\n(2)(13)\n(3)\n(1)\n5 Polit_both55 Polit_both5\n5 Media_both2 @gatewaypundit\n3 Indep_20204 @JudicialW atch3 Media_2020\n1 Media_both4 Indep_both4 Polit_2020\n1 Polit_both1,31 Polit_both1,33 Polit_both1,1\n4 Media_both22 Media_both4\n2 @BreitbartNews3 Media_20204 Media_20203,33 Media_20203,43 Media_20203,4\n2 @nytimes\n5 @FoxNews5 Media_2020\n2 @WSJ1 @nypost4 Media_both\n1 @thehill\n3 @Reuters2 @AP4 @ABC1 @CNN\n5 @washingtonpost1 @MSNBC\n2 @thedailybeast\n5 @Hu\ufb00Post\nFake newsExtreme bias rightRightRight leaningCentreLeft leaningLeft\n3027\n28\n29\n232323\n19191919\n25\n264\n2221\n243\n16\n2018172\n1411\n13121\n151076\n985\n3 Media_both4 @wikileaks\n1 Indep_both\n2 Other_2016\n4 Media_20164,55 Media_20164,44 Media_20164,5\n5 Polit_both1,2,41 Polit_both2,4,52 Polit_both1,4,54 Polit_both1,2,5\n2 @DailyCaller\n3 @BreitbartNews4 @RawStory\n3 @dcexaminer1 @FoxNews\n5 @nypost3 @thedailybeast\n1 @WSJ\n5 @R T_America3 @R T_com2 @W ashT imes2 @TIME\n4 @CNNPolitics1 @CNN\n3 @politico2 @thehill1 @Hu\ufb00Post\n5 @Reuters5 @Slate2 @washingtonpost1 @nytimes\n4 @NBCNews3 @ABC5 @Hu\ufb00PostPol2016 2020\n28\n25\n21\n24\n1729\n11\n15\n6\n9\n871312141\n5\n410\n2162018\n30\n327\n2614 29\n21\n16\n24\n1823\n27\n26\n28\n22\n11\n10\n12\n15 69 5\n87113\n3\n24171925\n202319\n22Fig. 5 | Similarity networks for nodes among the top 25 influencers from each \nnews media category for the two election years. Node size is proportional to its degree in their respective network. Node colour indicates which news media category the node spreads. Nodes that spread information from more than one \ncategory are represented as pie charts, where the size of each slice is proportional \nto their CI score within that respective news media category. An edge between each pair of influencers is weighted by the similarity between the retweeters of those influencers. Both networks are visualized using a force-directed node layout, with the strength of the force defined by the weights of the edges. Since these are complete networks, they are sparsified for visualization purposes, with each node only having up to their five strongest edges visible. Each of the two networks has 405 visible edges in total. Visible intercommunity edges are coloured purple, while intracommunity edges are orange. The distribution of the similarity values, and the degree distributions, for the visible edges of these two networks are shown in Supplementary Fig. 5b,d. Text to the side of each of \nthe two networks shows the top five users of each news media category. A green \nnumber to the left of each user corresponds to a labelled node in the network, showing the location of that top influencer. The purple numbers in the 2020 tables indicate the user\u2019s 2016 rank in that category. Users ranked in the top 25 for multiple news media categories have coloured superscripts, indicating the rank and media classification of their other top five positions.\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 911\nArticle https://doi.org/10.1038/s41562-023-01550-8To further quantify and compare the changes in user behaviour \nand, subsequently, in user polarization, we infer the ideology of Twitter  \nusers based on the ideological alignment of political actors whom \nthese users follow29,49. The bipartite network of followers is then pro -\njected on a one-dimensional scale using correspondence analysis50,51, \nwhich applies singular value decomposition of the adjacency matrix, \nstandardized to account for the differences in popularity and activ -\nity of the influencers and their followers (see Methods for details).  \nTwo users are close on the resulting latent ideology scale if they fol -\nlow similar influencers. This method has been shown to produce  \nideological estimates of the members of the US Congress that  \nhighly correlated with ideological estimates based on roll call voting \nsimilarity such as DW-NOMINATE49.\nFor 2016 and 2020, the data for the analysis consists of the top \n100 influencers of each news media category, as used in the previous \npolarization analysis, and the sets of users that retweeted at least three \ndifferent influencers (considering all tweets in our datasets, not only \nthe ones with URLs). As discussed earlier, we interpret retweeting as \nan endorsement of the content being retweeted. Twitter offers other \ntypes of interactions, allowing users to comment on the content, such \nas quote tweets and replies. The ratio of quotes to retweets of users to \ninfluencers was very stable and small (<5%) in 2016 and 2020, for users on both the left and right sides of the latent ideology (Supplementary \nTable 9A), which motivated our focus on retweets to infer the ideol -\nogy of users. The ratio of quotes to retweets from users of one side \nof the ideology spectrum to influencers of the other side increased \nfrom 2016 to 2020, indicating an increased usage of quotes to com -\nment on tweets from influencers of the opposite side. However, the \noverall usage of quotes over retweets remained small (Supplementary  \nTable 9B). We extract the coordinates of each user on the first dimen-\nsion of the results of the correspondence analysis applied to the \nweighted network of retweets between the users and the influencers \n(see Methods for the details and robustness checks that we performed). \nFinally, for 2016 and 2020, the coordinates of all users are standardized \nto a mean of zero and a standard deviation of one. Two users are close \ntogether on the latent ideology scale if they tend to retweet similar \ninfluencers. The influencers\u2019 latent ideological positions are then \ncomputed as the median of their retweeters\u2019 positions.\nFigure 6 shows the result of this analysis. The distribution of ide-\nology positions of the users and of the influencers, displayed in green and purple, respectively, shows that polarization increased between \n2016 and 2020. This is confirmed by a Hartigans\u2019 dip test (HDT) for uni -\nmodality, which measures multimodality in a sample by the maximum \ndifference, over all sample points, between the empirical distribution @Hu\ufb00PostMedia_both\n@thedailybeast\n@ReutersMedia_2020\n@thehill@washingtonpost@MSNBC\n@ABC\n@WSJMedia_2020\n@AP@CNN@nytimes\n@FoxNews@nypost\n@JudicialWatch@gatewaypundit\nMedia_2020Polit_both\nMedia_both\nIndep_2020Media_both\nPolit_bothPolit_2020Media_both@BreitbartNews\nMedia_2020\nIndep_bothn = 63,667n = 126,192\nn = 110,000\nn = 85,254n = 65,718\nn = 317,580n = 174,117n = 214,165\nn = 183,422\nn = 49,192n = 398,290\nn = 132,556n = 268,938n = 240,975\nn = 58,045n = 100,777\nn = 63,339n = 82,677\nn = 252,429n = 614,420\nn = 69,669\nn = 104,239n = 207,512\nn = 401,238n = 267,714n = 136,245n = 96,186\nn = 85,328\nn = 340,139\n0369\n\u20132 \u20131 0 1 2\nLatent ideologyDensityInfluencers\nUsersLeft Right@CNNPolitics@NBCNews@TIME@Hu\ufb00Post@Slate\n@Hu\ufb00PostPol\n@thedailybeast@RawStory\n@Reuters\n@thehill@washingtonpost\n@ABC\n@WSJ@CNN@nytimes\n@politico\nOther_2016@RT_America\n@FoxNews@WashTimes\nMedia_2016@wikileaks@nypost\nIndep_bothMedia_both\n@dcexaminer\nPolit_both@DailyCaller\n@BreitbartNews@RT_comn = 68,980n = 48,425n = 36,511n = 48,153n = 42,935\nn = 26,329\nn = 34,188n = 32,579\nn = 35,812\nn = 133,238n = 65,335\nn = 76,436\nn = 29,683n = 146,923n = 108,616\nn = 103,604\nn = 32,032n = 15,644\nn = 160,260n = 15,225\nn = 62,863n = 163,008n = 31,338\nn = 116,116n = 18,397\nn = 55,145\nn = 242,194n = 49,673\nn = 45,522n = 17,002\n0369\n\u20132 \u20131 0 1 2\nLatent ideologyDensityInfluencers\nUsersLeft Right2016Right news Fake news Right-leaning news Centre news Left news Left-leaning news Extreme bias right\n2020\nFig. 6 | Latent ideology scale of influencers and their retweeters in 2016 \n(left) and 2020 (right). Top, the latent ideology of the top five influencers of each category is shown as a box plot representing the distribution of the ideology of the users who retweeted them. Bottom, the distributions for the \nusers are shown in green and the distributions for the top 100 influencers of \neach news media category (computed as the median of the ideology of their retweeters) are displayed in purple. Box plots indicate the median and the 25th and 75th percentiles of the distributions with whiskers indicating the 5th and 95th percentiles. The sample size used for the computation of each box plot is reported to their side. Pie charts next to the influencers\u2019 names represent the \nnews categories to which they belong (weighted by their respective CI ranks in \neach category).\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 912\nArticle https://doi.org/10.1038/s41562-023-01550-8function and the unimodal distribution function that minimizes that \nmaximum difference52. For the user distribution, the test statistic is \nD\u2009=\u20090.11074 with a CI95 of (0.11038, 0.1112) in 2016. In 2020, we have \nD\u2009=\u20090.14751 with a CI95 of (0.1471, 0.1477). For the influencer distribu-\ntion, the test statistics are D\u2009=\u20090.18328 with a CI95 of (0.1672, 0.195) in \n2016 and D \u2009=\u20090.23251 with a CI95 of (0.206, 0.238) in 2020. All tests \nreject the null hypothesis of a unimodal distribution with P \u2009<\u20092.2\u2009\u00d7\u200910\u221216 \nand the 95% confidence intervals are computed from 1,000 bootstrap \nsamples using the bias-corrected and accelerated method. Increasing \nvalues of the test statistic indicates distributions that increasingly devi -\nate from a unimodal distribution, corroborating the growing division \nfound in the similarity networks.\nTo resolve whether the increase in polarization is caused by the \narrival of new users and influencers in 2020, we repeat the analysis \nincluding (1) only users (shown in Supplementary Fig. 6), (2) only \ninfluencers (Supplementary Fig. 7) and (3) both users and influencers  \n(Supplementary Fig. 8) that were active during both elections. In all \nthree cases we observe an increase of the HDT statistics (see Supple-\nmentary Fig. 9 and Supplementary Table 10) that means that the change \nin behaviour of the users in selecting whom to send their retweets \ncontributes to the polarization increase. The largest increase in HDT \nfor the user distribution arises when all users from years 2016 and 2020 \nand only influencers that were present during both years are considered \n(+0.08). This setting also corresponds to the smallest increase of the \ndip test of the influencer distribution (+0.01, within CI95), suggesting \nthat the new influencers of 2020 have more polarized ideologies than the influencers who continued from 2016 to 2020. Thus, we conclude \nthat the increased polarization of the users is caused, to a substan -\ntial extent, by the arrival and departure of users between elections  \n(Supplementary Fig. 9 and Supplementary Table 10).\nFigure 6 reveals a clear increase in polarization of the users and \ninfluencers in 2020 compared to 2016 and an alignment of their latent \nideologies in two distinct groups, mirroring the news media classifi -\ncation groupings seen in Fig. 5  and Supplementary Fig. 6. This echo \nchamber behaviour for users became more concentrated in 2020, with \ntwo clearly opposite poles that had fewer influencers having a user base \nbridging opposite ideologies.\nThese results also independently confirm the shift of news outlets \nand influencers from the centre to the right and left observed using \nthe news media classifications by external sources. Indeed, we find an \nextremely high correlation (above 0.90 for 2016 and 2020) between the \nusers\u2019 latent ideology position and their left- or right-leaning distribu -\ntion computed using the news media categories in which they posted \n(see Methods for details). This high correlation indicates that the shift \nin bias observed at the level of the media outlets is also present at the \nlevel of the users\u2019 retweeting pattern and serves as an independent \nvalidation of the media outlet classification.\nDiscussion\nWe collected and analysed Twitter data during two important  \nUS presidential elections in 2016 and 2020 to document changes \nin Twitter\u2019s political news media landscape and measure the result -\ning polarization induced by social media influencers and their audi -\nences. Our analyses focus on the identification of influencers and their  \npolitical alignments. We developed a comparative framework that led \nto the discovery of important changes in the ideological composition \nand organizational affiliation of influencers and the level of political \npolarization among influencers and their audiences. Our descriptive \naccount will be useful for readers and researchers concerned about  \nthe power of even a few social media influencers to shape and polarize  \nthe news media landscape on Twitter. These results are also an  \nimportant first step towards the discovery of mechanisms behind  \nthe trends, patterns and behaviours we report.\nBetween 2016 and 2020, the number of influencers affiliated with \nmedia organizations declined by 10%, replaced mostly by influencers affiliated with centre and right-leaning political organizations. This \nchange in the news media landscape on Twitter indicates a shift in the \nrelative influence of journalists and political organizations. Among \nprofessional media influencers, there was a shift away from independ -\nent journalism and towards extreme bias right and fake news.\nImportantly, while the number of tweets and users propagating \nfake and extremely biased news declined between 2016 and 2020, \npolarization increased across the political spectrum. We found an \nincrease in the division of influencers and users into opposing echo \nchambers from the first election to the the second. We confirmed this \nobservation by analysing latent ideologies of influencers and users, \ndiscovering corresponding increases in their polarization as well. \nThis analysis also suggests that new influencers from 2020 have more \npolarized ideologies than the influencers who persisted from 2016.\nWe hope that our results and observations will encourage future \nstudies. One promising direction is to use Natural Language Processing \nto distinguish between positively and negatively quoted tweets and to \ndetermine their topic. Another direction is to extend user classification \nto refine the categorization of organizational and individual Twitter \naccounts, and broaden the hierarchy of the users\u2019 affiliations. The \nmeasures of polarization can also be refined to enable deeper analysis \nof the patterns of behaviours that affect polarization and to expand \nthe application of influencer analysis to the spread of political news \non other social media.\nMethods\nThis research was reviewed and classified as exempt by the City University  \nof New York (CUNY) Integrated Institutional Review Boards (IRB), as \nthe research involved the collection of existing data from sources that \nare publicly available. This decision is shown in IRB file no. 2022-0429 \n(approved on 8 July 2022) and IRB file no. 2017-0625 (approved on  \n12 June 2017). These files are available at https://osf.io/e395q/ link.\nNews media URL classification\nThe website www.allsides.com (AS) rates media bias using a com -\nbination of several methods such as blind surveys, editorial review, \nthird-party analysis (for example, academic research), independent \nreview and community feedback (see www.allsides.com/media-bias/\nmedia-bias-rating-methods for a detailed explanation of the  \nmethodology). The website mediabiasfactcheck.com (MBFC) \nscores media bias by evaluating wording, sourcing and story choices \nas well as political endorsement (see mediabiasfactcheck.com/  \nmethodology ). MBFC is maintained by a small independent team of \nresearchers and journalists, offering the largest set of biased and inac -\ncurate news sources among five fact-checking datasets53. They are used \nfor labelling bias and veracity of news sources54\u201356. However, neither \nAS nor MBFC are considered perfect assessments of bias, but no major \nmedia assessment platform is considered objectively unbiased from all ideological perspectives. According to the University of Michigan \nlibrary (an endorser of AS), \u2018there is no one exact methodology to \nmeasure and rate the partisan bias of news sources\u201957, and as such, we \nconsider AS and MBFC our best options for this research.\nTo be consistent with the results from 201621, we discard as insig -\nnificant outlets that accumulate less than 1% of the cumulative number \nof tweets of the more popular outlets in each category. Removing \nuniformly insignificant outlets from all categories also ensures that \nthe tweet volume in each category is independent of the number of outlets classified in this category by AS and MBFC. The full lists \n \nof outlets in each category in 2016 and 2020 are given in Supplementary \nTables 1 and 2. AS and MBFC updated their bias classification for several \noutlets between 2016 and 2020, changing the classification used in \nour analyses as well. For example, CNN Web News was classified in the centre category in 2016 by AS and then in the left-leaning category in 2020, reflecting a bias shift occurring during this time ( www.allsides.\ncom/blog/yes-cnns-media-bias-has-shifted-left).\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 913\nArticle https://doi.org/10.1038/s41562-023-01550-8In ref. 21, the fake news and extreme bias categories were based \non the classification of a team of media experts (available at github.\ncom/alexbovet/opensources) and was cross-checked using the factual \nreporting scores from MBFC. As the classification source from 2016 was \nnot updated in 2020, we use the list of outlets classified as \u2018question-\nable sources\u2019 from MBFC as a reference for 2020. MBFC describes a \nquestionable source as one \u2018that exhibits one or more of the following: \nextreme bias, consistent promotion of propaganda/conspiracies, poor \nor no sourcing to credible information, a complete lack of transparency \nand/or is fake news\u2019 . MBFC rates the factual reporting of each source \non a scale from 0 (very high) to 10 (very low) based on their history of \nreporting factually and backing up claims with well-sourced evidence. \nOutlets with a level of \u2018low\u2019 (score of 7 to 9) or \u2018very low\u2019 (score of 10) are \nclassified in the fake news category while outlets with a \u2018mixed\u2019 level \n(score of 5 or 6) are classified in the extremely biased category. No out -\nlets in the disinformation categories have a level higher than \u2018mixed\u2019 . \nA \u2018low\u2019 or \u2018very low\u2019 factual reporting level on MBFC corresponds to \nsources that rarely or almost never use credible sources and \u2018need to \nbe checked for intentional fake news, conspiracy, and propaganda\u2019 .  \nA \u2018mixed\u2019 level is assigned to sources that \u2018do not always use proper \nsourcing or source to other biased/mixed factual sources\u2019 . We also \nverify that all outlets in the extremely biased category have a \u2018bias\u2019 \nreported on MBFC of \u2018right\u2019 , \u2018extreme right\u2019 , \u2018left\u2019 or \u2018extreme left\u2019 .\nWe identify the following in our datasets (giving the top website \nhost name as an example in parenthesis): for the fake news category, \n16 website host names in 2016 (top: thegatewaypundit.com) and 20 \nwebsite host names in 2020 (top: thegatewaypundit.com); for the \nextreme bias right category, 17 website host names in 2016 (top: bre -\nitbart.com) and 10 website host names in 2020 (top: breitbart.com); \nfor the extreme bias left category, 7 website host names in 2016 (top: \ndailynewsbin.com) and 7 website host names in 2020 (top: occupy -\ndemocrats.com); for the left news category, 18 website host names in \n2016 (top: huffingtonpost.com) and 18 website host names in 2020 \n(top: rawstory.com ); for the left-leaning news category, 19 website \nhost names in 2016 (top: nytimes.com) and 19 website host names \nin 2020 (top: nytimes.com); for the centre news category, 13 website host names in 2016 (top: cnn.com) and 13 website host names in 2020 (top: thehill.com); for the right-leaning news category, 7 website host \nnames in 2016 (top: wsj.com) and 13 website host names in 2020 (top: nypost.com); and for the right news category, 20 website host names \nin 2016 (top: foxnews.com) and 19 website host names in 2020 (top: \nfoxnews.com). The full lists of outlets in each category in 2016 and \n2020 are given in Supplementary Tables 1 and 2.\nInfluencer identification algorithms\nHere, we search for influencers using the Collective Influence (CI) approach\n48, which includes an algorithm that finds a minimal set \nof nodes that can cause a global cascade in the network operating \nunder the Linear Threshold Model58. This task is nondeterministic \npolynomial-time complete, so the algorithm is prohibitively slow in \npractice. Thus, we use a computationally efficient CI heuristic that \nyields an approximate solution. However, the influencer sets used here \nlimit coverage to less than 80% of the global information cascades in our \nretweet networks. In this range of network cascades, many heuristics, \nincluding CI and the popular method PageRank59, select similar sets of \ninfluencers. As an example, Supplementary Fig. 10 shows that CI and \nPageRank yield highly correlated lists of influencers, demonstrating \nthat our results do not depend on a choice of heuristic.\nInfluencer type classification\nFor each of the years 2016 and 2020, we manually classified the top \n25 influencers in each news media category as either (1) affiliated to a media organization, (2) a political organization, or unaffiliated (clas-\nsified either as (3) an independent user or as (4) an unidentified \u2018other\u2019 \nuser). The manual labelling procedure was as follows: eight of the authors were randomly assigned a subset of the top 25 influencers \nin these category lists to independently classify to one of the catego -\nries (1)\u2013(4), such that three different authors examined each subset. \nEach author was shown the account name of the influencer along with \ndescriptions, posts and all available non-Twitter information such as \ntheir Wikipedia entry. Each influencer was then assigned their category \nbased on the majority vote of the three independent classifications.\nSimilarity network analysis\nWe create for each influencer i a vector Si of size U, which stands for the \nnumber of users in each election dataset. An index u  denotes a specific \nuser. The vector element si\nu defines the number of times user u  has \nretweeted influencer i. Then, we create the adjacency matrix W of size \nI\u2009\u00d7\u2009I, where I is the number of influencers in each election year dataset. \nFor the 2016 dataset, I \u2009=\u2009505 while 2020 dataset has I \u2009=\u2009548. The weight \nof each edge, and therefore value of each matrix element wi1,i2, is set to \nthe cosine similarity between vectors Si1 and Si2. It follows that the higher \nthe cosine similarity of a pair of their user, the more similar are fractions \nof retweets from influencers i1,\u2009i2 for this pair. To account for the differ -\nent number of influencers in two compared election datasets, we \nextract equally sized random subsets from the two similarity matrices \nto create the similarity networks used in the following analyses. Each \nof these networks is limited to a size of 200 nodes. This randomized \nsubset selection process is repeated 100 times. For each pair of similar -\nity networks created in this process, we detect communities in this pair \nsimilarity network using the Louvain algorithm60. For all 100 pairs of \nthe similarity networks for both election years, we found two com -\nmunities. Using the accounts of influencers in each community, we \nfound that for both election years one community contains influencers \nprimarily associated with fake and right-biased news categories, while \nthe other contains influencers from centre and left-biased news catego -\nries. This split coincides with an underlying division among the Twitter \nuser bases in the content they propagate.\nWe quantify the severity of this split using two measures of separa -\ntion between communities. First is modularity that computes the sum of difference between the fraction of edges within each community and the \nfraction expected within this community in a random network with the \nsame number of nodes and edges. This metric has a range of [\u22120.5,\u20091.0]61. \nA positive value indicates the presence of communities separated from \neach other. The closer the modularity is to 1.0, the stronger communi-\nties are separated. The modularity for the 2016 network was 0.401 with \na CI95 of (0.392, 0.409). For the 2020 network, it was 0.465 with a CI95 of (0.454, 0.475), in agreement with other methods.\nThe second measure uses the normalized cut, which is the sum of \nthe weights of every edge that links a pair of communities divided by the sum of the weights of all edges. The result has a range of [0,\u20091], and \nthe smaller the value, the stronger the separation among communi -\nties. The normalized cut for the 2016 network was 0.285 with a CI95 of \n(0.232, 0.339). However, it decreased to 0.052 with a CI95 of (0.046, \n0.058) in the 2020 network.\nLatent ideology estimation\nOur latent ideology estimation follows the methods developed in  \nrefs. 29,49, which rely on retweet interactions instead of following  \nrelations. Accordingly, we use correspondence analysis50 to infer ideo -\nlogical positions of Twitter users.\nThe adjacency matrix, A , of the retweet network between the \ninfluencers and their retweeters is the matrix with element aij equal to \nthe number of times user i  retweeted influencer j . We only select tweets \nthat have been sent from the official Twitter client to limit the presence \nof bots and professional accounts, and we also remove users that show \na low interest in the US elections by removing users that retweeted less \nthan three different influencers. For the 2016 data, the matrix A  has \n751,311 rows corresponding to distinct users, 593 columns correspond -\ning to influencers and a total number of retweets equalling 39,385,772. \nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 914\nArticle https://doi.org/10.1038/s41562-023-01550-8For the 2020 data, the matrix A has 2,034,970 rows corresponding to \ndistinct users, 591 columns corresponding to influencers and a total \nnumber of retweets equalling 153,463,788.\nThe correspondence analysis method is executed in the following \nsteps51. The matrix of standardized residuals of the adjacency matrix \nis computed as S=D\u22121/2\nr(P\u2212rc)D\u22121/2c , where P=A(\u2211ijaij)\u22121 is the adja -\ncency matrix normalized by the total number of retweets. Let 1 denotes \na vector of 1\u2019s, r = 1P  is the vector of row sums, c \u2009=\u20091TP is the vector  \nof column sums, Dr\u2009=\u2009diag(r) and Dc\u2009=\u2009diag(c). Using the standardized \nresiduals allows the inference to account for the variation of popularity \nand activity of the influencers and the users, respectively29. Then, a \nsingular value decomposition is computed such that S \u2009=\u2009UD\u03b1VT with \nUUT\u2009=\u2009VVT\u2009=\u2009I and D\u03b1 being a diagonal matrix with the singular values  \non its diagonal. The positions of the users are given by the standard \nrow coordinates: X=D\u22121/2\nrU, where we only consider the first dimen -\nsion, corresponding to the largest singular value. Finally, the ideologi -\ncal positions of the users are found by standardizing the row \ncoordinates to have a mean of zero and a standard deviation of one. \nThe ideological position of the influencers is given by the median of \nthe weighted positions of their retweeters.\nTo test robustness of this method, we construct three variants of A \nby (1) removing entries with unit weight to discard relations showing a \nweak ideological alignment; (2) considering the logarithm of the num-\nber of retweets as weight for influencer for a sublinear relation between \nthe number of retweets and the strength of ideology alignment; and \n(3) selecting a random subsample of the 2020 retweet data of the same \nsize as the 2016 retweet data to avoid potential effects of size differ -\nence of the two datasets. All robustness tests match the results of our \ninitial method with correlation coefficients between the user position \ndistributions in the robustness tests and in the initial configuration at \nabove 0.995. We also compare the users\u2019 latent ideology distribution \nwith the users\u2019 average leaning distribution and find a correlation above \n0.90 for 2016 and 2020. The average leaning of users is computed for all \nusers that have at least three tweets classified in at least one news media \ncategory, and is estimated as the weighted average of the news media \ncategory positions as the fraction of the distance from the centre, which \nis assigned bias 0. Each step to the left decreases the bias by 1/3, while \neach step to the right increases the bias by 1/3, resulting in fractions 4/3 \nassigned to fake news bias\u20094/3, 1 to extreme bias right, 2/3 to right bias\u2009, \n1/3 to right leaning bias, \u22121/3 to left leaning bias, and \u22122/3 to left\u2009bias.\nReporting summary\nFurther information on research design is available in the Nature  \nPortfolio Reporting Summary linked to this article.\nData availability\nThe Twitter data is available at https://osf.io/j6pks/ (2016 data) and at \nhttps://osf.io/e395q/ (2020 data).\nCode availability\nThe code used to reproduce the 2016 results are deposited at https://\nosf.io/e4tvh/, https://github.com/makselab/twitter_opinion_mining  \nand https://github.com/makselab/information_diffusion. The code \nused to reproduce the 2020 results are at https://osf.io/dbzm2/.\nReferences\n1. Brady, D. W. & Han, H. C. in Red and Blue Nation: Characteristics \nand Causes of America\u2019s Polarized Politics (eds Nivola, P. S. & \nBrady, D. W.) 1 (3), 119\u2013141 (Brookings Institute Press, Washington \nD.C., 2006).\n2. Hare, C. & Poole, K. T. The polarization of contemporary American \npolitics. Polity 46, 411\u2013429 (2014).\n3. Axelrod, R., Daymude, J. J. & Forrest, S. Preventing extreme polarization of political attitudes. Proc. Natl Acad. Sci. USA  \n118(50), e2102139118 (National Academy of Sciences, 2021).4. Iyengar, S., Lelkes, Y., Levendusky, M., Malhotra, N. & Westwood, S. J. The origins and consequences of affective polarization in the United States. Annu. Rev. Political Sci. 22, 129\u2013146 (2019).\n5. Druckman, J. N., Klar, S., Krupnikov, Y., Levendusky, M. & Ryan, J. B. Affective polarization, local contexts and public opinion in America. Nat. Hum. Behav. 5, 28\u201338 (2021).\n6. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science 359, 1146\u20131151 (2018).\n7. Juul, J. L. & Ugander, J. Comparing information diffusion mechanisms by matching on cascade size. Proc. Natl Acad. Sci. USA 118(46), e2100786118 (National Academy of Sciences, 2021).\n8. Guilbeault, D. & Centola, D. Topological measures for identifying \nand predicting the spread of complex contagions. Nat. Commun.  \n12(1), 4430 (2021).\n9. Effing, R., Van Hillegersberg, J. & Huibers, T. Social media and \npolitical participation: are Facebook, Twitter and Youtube democratizing our political systems? In International Conference on Electronic Participation (eds Tambouris, E., Macintosh, A. & Bruijn, H.) 25\u201335 (Springer, 2011).\n10. Broersma, M. & Graham, T. Social media as beat: tweets as a news source during the 2010 British and Dutch elections. Journalism \nPract. 6, 403\u2013419 (2012).\n11. Metaxas, P. T. & Mustafaraj, E. Social media and the elections. \nScience 338, 472\u2013473 (2012).\n12. Ceron, A., Curini, L. & Iacus, S. Politics and Big Data: Nowcasting and Forecasting Elections with Social Media (Taylor & Francis, 2016); https://doi.org/10.4324/9781315582733\n13. Bovet, A., Morone, F. & Makse, H. A. Validation of Twitter opinion trends with national polling aggregates: Hillary Clinton vs Donald Trump. Sci. Rep. 8, 8673 (2018).\n14. Soares, F. B., Recuero, R. & Zago, G. Influencers in polarized political networks on Twitter. In Proc. 9th International Conference on Social Media and Society (eds Gruzd, A., Mai, P.), 168\u2013177 (2018).\n15. Grover, P., Kar, A. K., Dwivedi, Y. K. & Janssen, M. Polarization and acculturation in US Election 2016 outcomes \u2013 can Twitter analytics predict changes in voting preferences. Technol. Forecast. Soc. Change 145, 438\u2013460 (2019).\n16. Lee, S. & Xenos, M. Social distraction? Social media use and political knowledge in two US Presidential elections. Comput. Hum. Behav. 90, 18\u201325 (2019).\n17. Acharoui, Z., Alaoui, A., Ettaki, B., Zerouaoui, J. & Dakkon, M. Identifying political influencers on YouTube during the 2016 Moroccan General Election. Procedia Comput. Sci. 170,  \n1102\u20131109 (2020).\n18. Suau-Gomila, G., Pont-Sorribes, C. & Pedraza-Jim\u00e9nez, R. Politicians or influencers? Twitter profiles of Pablo Iglesias and Albert Rivera in the Spanish general elections of 20-D and 26-J. Commun. Soc. 33, 209\u2013225 (2020).\n19. Allcott, H. & Gentzkow, M. Social media and fake news in the 2016 election. J. Econ. Perspect. 31, 211\u2013236 (2017).\n20. Shao, C. et al. Anatomy of an online misinformation network.  \nPLoS ONE 13, e0196087 (2018).\n21. Bovet, A. & Makse, H. A. Influence of fake news in Twitter  \nduring the 2016 US presidential election. Nat. Commun. 10, 7 \n(2019).\n22. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during the 2016 U.S. presidential election. Science 363, 374\u2013378 (2019).\n23. Ruths, D. The misinformation machine. Science 363, 348 (2019).\n24. Machado, C., Kira, B., Narayanan, V., Kollanyi, B. & Howard, P. A study of misinformation in WhatsApp groups with a focus on the Brazilian presidential elections. In Companion Proc. 2019 World Wide Web Conference (eds Nivola, P. S. & Brady, D. W.), 1013\u20131019 (Rowman & Littlefield, 2019).\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916\n 915\nArticle https://doi.org/10.1038/s41562-023-01550-825. Benkler, Y., Faris, R. & Roberts, H. Network propaganda: \nmanipulation, disinformation, and radicalization in American politics (Oxford Univ. Press, 2018).\n26. Conover, M. et al. Political polarization on Twitter. In Proc. International AAAI Conference on Web and Social Media (eds Nicolov, N. & Shanahan, J. G.,) (PKP Publishing Services Network, 2011); https://ojs.aaai.org/index.php/ICWSM/article/view/14126\n27. Prior, M. Media and political polarization. Annu. Rev. Polit. Sci. 16, \n101\u2013127 (2013).\n28. Mocanu, D., Rossi, L., Zhang, Q., Karsai, M. & Quattrociocchi, W. Collective attention in the age of (mis)information. Comput. Hum. Behav. 51, 1198\u20131204 (2015).\n29. Barber\u00e1, P., Jost, J. T., Nagler, J., Tucker, J. A. & Bonneau, R. Tweeting from left to right: is online political communication more than an echo chamber? Psychol. Sci. 26, 1531\u20131542 (2015).\n30. Bessi, A. et al. Homophily and polarization in the age of misinformation. Eur. Phys. J. Spec. Top. 225, 2047\u20132059 (2016).\n31. Vaccari, C. et al. Of echo chambers and contrarian clubs: exposure to political disagreement among German and Italian users of Twitter. Soc. Media Soc. 2, https://doi.\norg/10.1177/2056305116664221 (2016).\n32. Bessi, A. et al. Users polarization on Facebook and Youtube. PLoS \nONE 11(8):e0159641; https://doi.org/10.1371/journal.pone.0159641 \n(2016).\n33. Lelkes, Y., Sood, G. & Iyengar, S. The hostile audience: the effect of access to broadband internet on partisan affect. Am. J. Polit. Sci.  \n61, 5\u201320 (2017).\n34. Bail, C. A. et al. Exposure to opposing views on social media can increase political polarization. Proc. Natl Acad. Sci. USA 115, \n9216\u20139221 (2018).\n35. Cinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, W. & Starnini, M. The echo chamber effect on social media. Proc. \nNatl Acad. Sci. USA 118, e2023301118 (2021).\n36. McCarty, N. Polarization: What Everyone Needs to Know (Oxford Univ. Press, 2019).\n37. Galston, W. A. & Nivola, P. S. Delineating the problem in Red and Blue Nation: Characteristics and Causes of America\u2019s Polarized Politics (eds Nivola, P. S. & Brady, D. W.) 1 (1):1\u201346 (Brookings \nInstitute Press, Washington D.C., 2006).\n38. Abramowitz, A. I. & Fiorina, M. P. (2017, July 14). Polarized or  \nsorted? Just what\u2019s wrong with our politics, anyway. Amer.  \nInterest. Retrieved February 19, 2023, from https://www.the-  \namerican-interest.com/2013/03/11/polarized-or-sorted-just-  \nwhats-wrong-with-our-politics-anyway/\n39. Fiorina, M. P. & Abrams, S. J. Political polarization in the American public. Annu. Rev. Polit. Sci. 11, 563\u2013588 (2008).\n40. Layman, G. C., Carsey, T. M. & Horowitz, J. M. Party polarization in American politics: characteristics, causes, and consequences. Annu. Rev. Polit. Sci. 9, 83\u2013110 (2006).\n41. Mason, L. \u2018I disrespectfully agree\u2019: the differential effects of partisan sorting on social and issue polarization. Am. J. Polit. Sci.  \n59, 128\u2013145 (2015).\n42. Brown, J. R. & Enos, R. D. The measurement of partisan sorting for 180 million voters. Nat. Hum. Behav. 5(8), 98\u20131008 (2021).\n43. Druckman, J. N. & Levendusky, M. S. What do we measure when we measure affective polarization? Public Opin. Q. 83, 114\u2013122 \n(2019).\n44. Dalton, R. J. Modeling ideological polarization in democratic party systems. Elect. Stud. 72, 102346 (2021).\n45. Bakshy, E., Messing, S. & Adamic, L. A. Exposure to ideologically diverse news and opinion on Facebook. Science 348, 1130\u20131132 \n(2015).\n46. Efthimion, P. G., Payne, S. & Proferes, N. Supervised machine learning bot detection techniques to identify social Twitter bots. SMU Data Sci. Rev. 1, 5 (2018).47. Metaxas, P. et al. What do retweets indicate? Results from user survey and meta-review of research. In Proc. Int. AAAI Conf. Web \nSoc. Media, 9 (ed. Quercia, D.)(PKP Publishing Services Network, \n2015).\n48. Morone, F. & Makse, H. A. Influence maximization in complex networks through optimal percolation. Nature 524, 65\u201368 (2015).\n49. Barber\u00e1, P. Birds of the same feather tweet together: Bayesian ideal point estimation using Twitter data. Polit. Anal. 23, 76\u201391 \n(2015).\n50. Benz\u00e9cri, J.-P. et al. L\u2019analyse des donn\u00e9es, Vol. 2 (Dunod, 1973).\n51. Nenadic, O. & Greenacre, M. Correspondence analysis in R, with two-and three-dimensional graphics: the ca package. J. Statist. \nSoftw. 20, 1\u201313 (2007).\n52. Hartigan, J. A. & Hartigan, P. M. et al. The dip test of unimodality. \nAnn. Stat. 13, 70\u201384 (1985).\n53. Bozarth, L., Saraf, A. & Budak, C. Higher ground? How groundtruth labeling impacts our understanding of fake news about the 2016 US presidential nominees. In Proc. Int. AAAI Conf. Web Soc. Media, 14 (ed. De Choudhury, M.) 48\u201359 (PKP Publishing Services \nNetwork, 2020).\n54. Main, T. J. The Rise of the Alt-Right (Brookings Institution Press, \n2018).\n55. Stefanov, P., Darwish, K., Atanasov, A. & Nakov, P. Predicting the \ntopical stance and political leaning of media using tweets. In Proc. 58th Annual Meeting of the Association for Computational Linguistics (eds Jurafsky, D, Chai, J., Schluter, N. & Tetreault, J.), 527\u2013537 (Association for Computational Linguistics, 2020).\n56. Cinelli, M. et al. The COVID-19 social media infodemic. Sci. Rep.  \n10, 16598 (2020).\n57. Desai S. & Oehrli, J. A., \u2018Fake News,\u2019 Lies and Propaganda: How to Sort Fact from Fiction, accessed 21 July 2022; https://guides.lib.umich.edu/c.php?g=637508&p=4462444 (2022).\n58. Kempe, D., Kleinberg, J. & Tardos, \u00c9. Maximizing the spread of influence through a social network. In Proc. of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (ed. Senator, T.) 137\u2013146 (ACM Press, New York, NY, 2003).\n59. Bakshy, E., Hofman, J. M., Mason, W. A. & Watts, D. J. Identifying influencers on Twitter. In 4th ACM International Conference on Web Search and Data Mining (WSDM) (ed. King, I.), 2  (ACM, New \nYork, NY, 2011).\n60. Blondel, V. D., Guillaume, J.-L., Lambiotte, R. & Lefebvre, E. Fast unfolding of communities in large networks. J. Stat. Mech. Theory Exp. 2008 , P10008 (2008).\n61. Brandes, U. et al. On modularity clustering. IEEE Trans. Knowl. Data Eng. 20, 172\u2013188 (2007).\nAcknowledgements\nJ.F., B.C. and B.K.S. were partially supported by DARPA-INCAS under  \nAgreement No. HR001121C0165 and by NSF Grant No. BSE-2214216. H.A.M. was supported by NSF Grant No. BSE-2214217. Z.Z. was supported by the R&D Program of Beijing Municipal Education Commission, Grant No. KM202210038002. M.W.M. was partially supported by NSF Grant No. SES-2049207. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.\nAuthor contributions\nS.F., H.A.M. and B.K.S. conceived the research. B.K.S., H.A.M. and A.B. designed and supervised the research. A.B., J.F. and B.K.S. coordinated and supervised the analysis. S.F., M.W.M., A.B., H.A.M. and B.K.S. defined the scope of the article. J.F., A.G., B.C., Z.Z., M.S., B.K.S. and A.B. processed the collected data. All authors analysed the results. A.B., J.F., M.W.M. and B.K.S. wrote the first draft and all authors edited and approved the article.\nNature Human Behaviour | Volume 7 | June 2023 | 904\u2013916 916\nArticle https://doi.org/10.1038/s41562-023-01550-8Competing interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary information The online version contains \nsupplementary material available at  \nhttps://doi.org/10.1038/s41562-023-01550-8 .\nCorrespondence and requests for materials should be addressed to \nHern\u00e1n A. Makse or Boleslaw K. Szymanski.\nPeer review information Nature Human Behaviour thanks  \nPhilip Howard, Deb Roy and the other, anonymous,  \nreviewer(s) for their contribution to the peer review  \nof this work.Reprints and permissions information is available at  \nwww.nature.com/reprints.Publisher\u2019s note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.\n\u00a9 The Author(s) 2023\n1 nature portfolio  |  reporting summary March 2021\nCorresponding author(s): Boleslaw K. Szymanski and Hernan A. Makse\nLast updated by author(s): 1/20/2023\nReporting Summary\nNature Portfolio wishes to improve the reproducibility of the w ork that we publish. This form provides structure for consisten cy and transparency \nin reporting. For further information on Nature Portfolio polic ies, see our Editorial Policies  and the Editorial Policy Checklist .\nStatistics\nFor all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or M ethods section.\nn/a Confirmed\nThe exact sample size ( n) for each experimental group/condition, given as a discrete nu mber and unit of measurement\nA statement on whether measurements were taken from distinct sa mples or whether the same sample was measured repeatedly\nThe statistical test(s) used AND whether they are one- or two-s ided \nOnly common tests should be described solely by name; describe more complex techniques in the Methods section.\nA description of all covariates tested\nA description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons\nA full description of the statistical parameters including cent ral tendency (e.g. means) or other basic estimates (e.g. regres sion coefficient) \nAND variation (e.g. standard deviation) or associated estimates  of uncertainty (e.g. confidence intervals)\nFor null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom a nd P value noted \nGive P values as exact values whenever suitable.\nFor Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings\nFor hierarchical and complex designs, identification of the app ropriate level for tests and full reporting of outcomes\nEstimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated\nOur web collection on statistics for biologists  contains articles on many of the points above.\nSoftware and code\nPolicy information about availability of computer code\nData collection standard Twitter API was used\nData analysis Custom code for analysing data is available at a public reposit ory\nFor manuscripts utilizing custom algorithms or software that ar e central to the research but not yet described in published li terature, software must be made available to editors and \nreviewers. We strongly encourage code deposition in a community  repository (e.g. GitHub). See the Nature Portfolio  guidelines for submitting code & software  for further information.\nData\nPolicy information about availability of data\nAll manuscripts must include a data availability statement . This statement should provide the following information, wher e applicable: \n- Accession codes, unique identifiers, or web links for publicl y available datasets \n- A description of any restrictions on data availability \n- For clinical datasets or third party data, please ensure that  the statement adheres to our policy  \n \nLink to the data is provided in the manuscript\n2 nature portfolio  |  reporting summary March 2021Field-specific reporting\nPlease select the one below that is the best fit for your resea rch. If you are not sure, read the appropriate sections before making your selection.\nLife sciences Behavioural & social sciences  Ecological, evolutionary & environmental sciences\nFor a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf\nBehavioural & social sciences study design\nAll studies must disclose on these points even when the disclos ure is negative.\nStudy description We tracked the spread of political news on Twitter in the 2016 and 2020 U.S. Presidential election.  \nResearch sample We included those users whose tweets contained the names of the  two presidential candidates in each of the presidential electi ons \nin 2016 and 2020 as keywords.\nSampling strategy All users sending and receiving tweets with  tweets containing the names of the two presidential candidates in elections withi n limits \nfor the speed of collecting data imposed by the Twitter, were i ncluded.\nData collection We used the Twitter Search API to collect data.\nTiming We collected the data over two periods, from June 1st to Novemb er 8th in 2016 and from June 1st to November 2nd in 2020.\nData exclusions No data were excluded.\nNon-participation In some analyses comparing results for both elections, we exclu ded participants that were active only in one election.\nRandomization No randomization was used.\nReporting for specific materials, systems and methods\nWe require information from authors about some types of materia ls, experimental systems and methods used in many studies. Here , indicate whether each material, \nsystem or method listed is relevant to your study. If you are n ot sure if a list item applies to your research, read the appro priate section before selecting a response. \nMaterials & experimental systems\nn/a Involved in the study\nAntibodies\nEukaryotic cell lines\nPalaeontology and archaeology\nAnimals and other organisms\nHuman research participants\nClinical data\nDual use research of concernMethods\nn/a Involved in the study\nChIP-seq\nFlow cytometry\nMRI-based neuroimaging\nAntibodies\nAntibodies used Describe all antibodies used in the study; as applicable, provi de supplier name, catalog number, clone name, and lot number.\nValidation Describe the validation of each primary antibody for the specie s and application, noting any validation statements on the \nmanufacturer\u2019s website, relevant citations, antibody profiles i n online databases, or data provided in the manuscript.\nEukaryotic cell lines\nPolicy information about cell lines\nCell line source(s) State the source of each cell line used.\nAuthentication Describe the authentication procedures for each cell line used OR declare that none of the cell lines used were authenticated.\nMycoplasma contamination Confirm that all cell lines tested negative for mycoplasma cont amination OR describe the results of the testing for \nmycoplasma contamination OR declare that the cell lines were no t tested for mycoplasma contamination.\n3 nature portfolio  |  reporting summary March 2021Commonly misidentified lines\n(See ICLAC  register)Name any commonly misidentified cell lines used in the study an d provide a rationale for their use.\nPalaeontology and Archaeology\nSpecimen provenance Provide provenance information for specimens and describe permi ts that were obtained for the work (including the name of the \nissuing authority, the date of issue, and any identifying infor mation). Permits should encompass collection and, where applica ble, \nexport.\nSpecimen deposition Indicate where the specimens have been deposited to permit free  access by other researchers.\nDating methods If new dates are provided, describe how they were obtained (e.g . collection, storage, sample pretreatment and measurement), wh ere \nthey were obtained (i.e. lab name), the calibration program and  the protocol for quality assurance OR state that no new dates are \nprovided.\nTick this box to confirm that the raw and calibrated dates are available in the paper or in Supplementary Information.\nEthics oversight Identify the organization(s) that approved or provided guidance  on the study protocol, OR state that no ethical approval or gu idance \nwas required and explain why not.\nNote that full information on the approval of the study protoco l must also be provided in the manuscript.\nAnimals and other organisms\nPolicy information about studies involving animals ; ARRIVE guidelines  recommended for reporting animal research\nLaboratory animals For laboratory animals, report species, strain, sex and age OR state that the study did not involve laboratory animals.\nWild animals Provide details on animals observed in or captured in the field ; report species, sex and age where possible. Describe how anim als were \ncaught and transported and what happened to captive animals aft er the study (if killed, explain why and describe method; if re leased, \nsay where and when) OR state that the study did not involve wil d animals.\nField-collected samples For laboratory work with field-collected samples, describe all relevant parameters such as housing, maintenance, temperature, \nphotoperiod and end-of-experiment protocol OR state that the st udy did not involve samples collected from the field.\nEthics oversight Identify the organization(s) that approved or provided guidance  on the study protocol, OR state that no ethical approval or gu idance \nwas required and explain why not.\nNote that full information on the approval of the study protoco l must also be provided in the manuscript.\nHuman research participants\nPolicy information about studies involving human research participants\nPopulation characteristics See above\nRecruitment None, we collected publicly available records of tweets contain ing a name of at least one of the two presidential candidates \nin each of the two elections. \nEthics oversight The City University of New York (CUNY) Integrated Institutional  Review Board\nNote that full information on the approval of the study protoco l must also be provided in the manuscript.\nClinical data\nPolicy information about clinical studies\nAll manuscripts should comply with the ICMJE guidelines for publication of clinical research  and a completed CONSORT checklist  must be included with all submissions.\nClinical trial registration Provide the trial registration number from ClinicalTrials.gov o r an equivalent agency.\nStudy protocol Note where the full trial protocol can be accessed OR if not av ailable, explain why.\nData collection Describe the settings and locales of data collection, noting th e time periods of recruitment and data collection.\nOutcomes Describe how you pre-defined primary and secondary outcome meas ures and how you assessed these measures.\nDual use research of concern\nPolicy information about dual use research of concern\nHazards\n4 nature portfolio  |  reporting summary March 2021Could the accidental, deliberate or reckless misuse of agents o r technologies generated in the work, or the application of inf ormation presented \nin the manuscript, pose a threat to:\nNo Yes\nPublic health\nNational security\nCrops and/or livestock\nEcosystems\nAny other significant area\nExperiments of concern\nDoes the work involve any of these experiments of concern:\nNo Yes\nDemonstrate how to render a vaccine ineffective\nConfer resistance to therapeutically useful antibiotics or anti viral agents\nEnhance the virulence of a pathogen or render a nonpathogen vir ulent\nIncrease transmissibility of a pathogen\nAlter the host range of a pathogen\nEnable evasion of diagnostic/detection modalities\nEnable the weaponization of a biological agent or toxin\nAny other potentially harmful combination of experiments and ag ents\nChIP-seq\nData deposition\nConfirm that both raw and final processed data have been deposi ted in a public database such as GEO .\nConfirm that you have deposited or provided access to graph fil es (e.g. BED files) for the called peaks.\nData access links \nMay remain private before publication.For \"Initial submission\" or \"Revised version\" documents, provid e reviewer access links.  For your \"Final submission\" document,  \nprovide a link to the deposited data.\nFiles in database submission Provide a list of all files available in the database submissio n.\nGenome browser session \n(e.g. UCSC )Provide a link to an anonymized genome browser session for \"Ini tial submission\" and \"Revised version\" documents only, to \nenable peer review.  Write \"no longer applicable\" for \"Final su bmission\" documents.\nMethodology\nReplicates Describe the experimental replicates, specifying number, type a nd replicate agreement.\nSequencing depth Describe the sequencing depth for each experiment, providing th e total number of reads, uniquely mapped reads, length of reads  and \nwhether they were paired- or single-end.\nAntibodies Describe the antibodies used for the ChIP-seq experiments; as a pplicable, provide supplier name, catalog number, clone name, a nd lot \nnumber.\nPeak calling parameters Specify the command line program and parameters used for read m apping and peak calling, including the ChIP, control and index files \nused.\nData quality Describe the methods used to ensure data quality in full detail , including how many peaks are at FDR 5% and above 5-fold enric hment.\nSoftware Describe the software used to collect and analyze the ChIP-seq data. For custom code that has been deposited into a community \nrepository, provide accession details.\n5 nature portfolio  |  reporting summary March 2021Flow Cytometry\nPlots\nConfirm that:\nThe axis labels state the marker and fluorochrome used (e.g. CD 4-FITC).\nThe axis scales are clearly visible. Include numbers along axes  only for bottom left plot of group (a 'group' is an analysis o f identical markers).\nAll plots are contour plots with outliers or pseudocolor plots.\nA numerical value for number of cells or percentage (with stati stics) is provided.\nMethodology\nSample preparation Describe the sample preparation, detailing the biological sourc e of the cells and any tissue processing steps used.\nInstrument Identify the instrument used for data collection, specifying ma ke and model number.\nSoftware Describe the software used to collect and analyze the flow cyto metry data. For custom code that has been deposited into a \ncommunity repository, provide accession details.\nCell population abundance Describe the abundance of the relevant cell populations within post-sort fractions, providing details on the purity of the \nsamples and how it was determined.\nGating strategy Describe the gating strategy used for all relevant experiments,  specifying the preliminary FSC/SSC gates of the starting cell \npopulation, indicating where boundaries between \"positive\" and \"negative\" staining cell populations are defined.\nTick this box to confirm that a figure exemplifying the gating strategy is provided in the Supplementary Information.\nMagnetic resonance imaging\nExperimental design\nDesign type Indicate task or resting state; event-related or block design.\nDesign specifications Specify the number of blocks, trials or experimental units per session and/or subject, and specify the length of each trial \nor block (if trials are blocked) and interval between trials.\nBehavioral performance measures State number and/or type of variables recorded (e.g. correct bu tton press, response time) and what statistics were used \nto establish that the subjects were performing the task as expe cted (e.g. mean, range, and/or standard deviation across \nsubjects).\nAcquisition\nImaging type(s) Specify: functional, structural, diffusion, perfusion.\nField strength Specify in Tesla\nSequence & imaging parameters Specify the pulse sequence type (gradient echo, spin echo, etc. ), imaging type (EPI, spiral, etc.), field of view, matrix size , \nslice thickness, orientation and TE/TR/flip angle.\nArea of acquisition State whether a whole brain scan was used OR define the area of  acquisition, describing how the region was determined.\nDiffusion MRI Used Not used\nPreprocessing\nPreprocessing software Provide detail on software version and revision number and on s pecific parameters (model/functions, brain extraction, \nsegmentation, smoothing kernel size, etc.).\nNormalization If data were normalized/standardized, describe the approach(es) : specify linear or non-linear and define image types used for \ntransformation OR indicate that data were not normalized and ex plain rationale for lack of normalization.\nNormalization template Describe the template used for normalization/transformation, sp ecifying subject space or group standardized space (e.g. \noriginal Talairach, MNI305, ICBM152) OR indicate that the data were not normalized.\nNoise and artifact removal Describe your procedure(s) for artifact and structured noise re moval, specifying motion parameters, tissue signals and \nphysiological signals (heart rate, respiration).\n6 nature portfolio  |  reporting summary March 2021Volume censoring Define your software and/or method and criteria for volume cens oring, and state the extent of such censoring.\nStatistical modeling & inference\nModel type and settings Specify type (mass univariate, multivariate, RSA, predictive, e tc.) and describe essential details of the model at the first a nd \nsecond levels (e.g. fixed, random or mixed effects; drift or au to-correlation).\nEffect(s) tested Define precise effect in terms of the task or stimulus conditio ns instead of psychological concepts and indicate whether \nANOVA or factorial designs were used.\nSpecify type of analysis: Whole brain ROI-based Both\nStatistic type for inference\n(See Eklund et al. 2016 )Specify voxel-wise or cluster-wise and report all relevant para meters for cluster-wise methods.\nCorrection Describe the type of correction and how it is obtained for mult iple comparisons (e.g. FWE, FDR, permutation or Monte Carlo).\nModels & analysis\nn/a Involved in the study\nFunctional and/or effective connectivity\nGraph analysis\nMultivariate modeling or predictive analysis\nMultivariate modeling and predictive analysis Specify independent variables, features extraction and dimensio n reduction, model, training and evaluation \nmetrics.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections", "author": ["J Flamino", "A Galeazzi", "S Feldman", "MW Macy"], "pub_year": "2023", "venue": "Nature Human \u2026", "abstract": "Social media has been transforming political communication dynamics for over a decade.  Here using nearly a billion tweets, we analyse the change in Twitter\u2019s news media landscape"}, "filled": false, "gsrank": 152, "pub_url": "https://www.nature.com/articles/s41562-023-01550-8", "author_id": ["OJ8NTo8AAAAJ", "DK0tXAIAAAAJ", "", "7OW6weoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:4zRNas8bW-oJ:scholar.google.com/&output=cite&scirp=151&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D150%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=4zRNas8bW-oJ&ei=H7WsaJGVCJXUieoPmrax2A8&json=", "num_citations": 133, "citedby_url": "/scholar?cites=16887121805411431651&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:4zRNas8bW-oJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41562-023-01550-8.pdf"}}, {"title": "Philosophical Musings on the Underbelly of Information Age", "year": "2021", "pdf_data": "Informatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n132 DOI: 10.35643/Info.26.1.8  \nDossier tem\u00e1tico:  \u00c9tica de la Informaci\u00f3n  \n \nPhilosophical Musings on the Underbelly of Information  Age \nMeditaciones filos\u00f3ficas sobre las entra\u00f1as de la Era de la Informaci\u00f3n  \nReflex\u00f5es filos\u00f3ficas sobre o ponto fraco da era da informa\u00e7\u00e3o  \n \nThomas J. Froehlicha \n \na Ph.D. School of Information. Kent State University  Professor Emeritus  United States of America . \nORCID : 0000 -0002 -5720 -7606. Correo electr\u00f3nico: tfroehli@kent.edu . \nAbstract  \nThere is an underbelly of the Age of Information. Its opportunities and promises \nhave been diverted to dubious ends, manipulating the users of information \ntechn ologies for economic rewards and political power.  Drawing and \nextrapolating on previous and current research, we pose different ways to \ncharacterize the Age of Information as the Age of Plato's Cave -Dwellers (inspired \nby Plato and Aristotle), the Age of Di straction (inspired by Heidegger), the Age of \nDisinformation (inspired by the manipulation of internet content to provoke \ninformation -disinformation wars), the Age of Surveillance Capitalism (inspired by \ninformation technology companies' use of software an d apps to manipulate \nconsumer behavior), and the Age of Inflamed Grievances (inspired by the use of \ninternet sites and apps to solidify and inflame partisan political grievances so as to \nmaintain, gain or manipulate political power).  The last two pose the greatest \ndangers to the destruction of democracies, countries and the planet.  \nKeywords:  THE AGE OF DISINFORMATION; THE AGE OF DISTRACTION; \nTHE AGE OF THE ANTI -ENLIGHTENMENT; THE AGE OF \nSURVEILLANCE CAPITALISM; THE AGE OF INFLAMED GRIE VANCES.  \nResumen  \nEste trabajo representa una mirada reflexiva a las entra\u00f1as de la Era de la \nInformaci\u00f3n. Sus oportunidades y promesas han sido desviadas a dudosos finales, \nmanipulando a los usuarios de las tecnolog\u00edas de la informaci\u00f3n hacia \nrecompensas econ\u00f3micas y poder pol\u00ed tico. El an\u00e1lisis desde la investigaci\u00f3n \nprevia y en curso, permite identificar diferentes maneras de caracterizar la Era de \nla Informaci\u00f3n como la Era de la Caverna de Plat\u00f3n (inspirada por Plat\u00f3n y \nArist\u00f3teles), la Era de la Distracci\u00f3n (inspirada por He idegger), la Era de la \nDesinformaci\u00f3n (inspirada por la manipulaci\u00f3n de los contenidos de Internet para \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n133 provocar guerras de informaci\u00f3n y desinformaci\u00f3n), la Era del Capitalismo \nVigilante (inspirada por el uso que hacen las compa\u00f1\u00edas de tecnolog\u00edas de la \ninformaci\u00f3n, de programas inform\u00e1ticos y aplicaciones para manipular el \ncomportamiento de los consumidores),y la Era de los Agravios Exacerbados \n(inspirada por el uso de los sitios web de Internet y las aplicaciones, para \nconsolidar e inflamar los agravios pol\u00edticos partisanos, as\u00ed como para mantener, \nconquistar o manipular el poder pol\u00edtico).  Las \u00faltimas dos plantean los m\u00e1s \ngrandes peligros para la destrucci\u00f3n de las democracias, los pa\u00edses y el planeta.  \nPalabras clave : LA ERA DE LA DESINFORMACI\u00d3N; LA ERA DE LA \nDISTRACCI\u00d3N; LA ERA DE LA ANTI -ILUMINACI\u00d3N; LA ERA DEL \nCAPITALISMO VIGILANTE; LA E RA DE LOS AGRAVIOS \nEXACERBADOS.  \nResumo  \nH\u00e1 um ponto fraco da Era da Informa\u00e7\u00e3o. As suas oportunidades e promessas t\u00eam \nsido desviadas para fins duvidosos, manipulando os utilizadores das tecnologias \nde informa\u00e7\u00e3o para recompensas econ\u00f3mica e poder pol\u00edtico.  Baseando -nos em \npesquisas anteriores e atuais, colocamos diferentes formas de caracterizar a Era da \nInforma\u00e7\u00e3o como a Era das Cavernas de Plat\u00e3o (inspirada por Plat\u00e3o e  \nArist\u00f3teles), a Era da Distra\u00e7\u00e3o (inspirada por Heidegger), a Era da \nDesinforma\u00e7\u00e3o (inspirada pela manipula\u00e7\u00e3o do conte\u00fado da Internet para \nprovocar guerras de informa\u00e7\u00e3o -desinforma\u00e7\u00e3o), a Era do Capitalismo de \nVigil\u00e2ncia (inspirada pelo uso de software e  aplica\u00e7\u00f5es das empresas de \ntecnologia de informa\u00e7\u00e3o para manipular o comportamento dos consumidores), e \na Era das Inflamadas Reclama\u00e7\u00f5es (inspirada pelo uso de sites e aplica\u00e7\u00f5es da \nInternet para solidificar e inflamar as reclama\u00e7\u00f5es pol\u00edticas partid\u00e1rias  de modo a \nmanter, ganhar ou manipular o poder pol\u00edtico).  Os dois \u00faltimos representam os \nmaiores perigos para a destrui\u00e7\u00e3o das democracias, dos pa\u00edses e do planeta.  \nPalavras -chave:  IDADE DA DESINFORMA\u00c7\u00c3O; IDADE DA DISTRA\u00c7\u00c3O; \nIDADE DO ANTI -ILUMINA\u00c7\u00c3O; IDADE  DO CAPITALISMO DE \nVIGIL\u00c2NCIA; IDADE DAS QUEIXAS INFLAMADAS.  \n \nReceived : 20/08/2020  \nAccepted : 02/05/2021  \n \n \nThere has been a paradigmatic shift with the emergence of the Age of \nInformation, built upon the speed, sophistication, miniaturization and widespread \navailability of computer technology and the  networks that allow quick and easy \naccess to all sorts of information from all sorts of sources.  No one doubts the \nbenefits of such an evolution.  What we now realize is that with these benefits \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n134 come with a deluge of problematic consequences that threaten the survival of \ndemocracy, countries, the world and the planet.  We consider alternative names for \nthe Age of Information, each of which displays something of the character of its \ndark side.   \n1. Prolegomena:  The Age of Plato's Cave Dwellers  \nBefore tracking Pla to's contribution to understanding the current age, we need to \nsort out different kinds of beliefs.  Beliefs come in three general types: (1) true \nbeliefs, (2) beliefs that are preferences, being neither true nor false, and (3) false \nbeliefs. \"True belief\" is a belief that could be turned into knowledge (or which can \nbe justified) through experience, education or research, such as seeking evidence \nfrom reliable sources. If one did not know that the hypotenuse of a right triangle is \nthe square root of the sum  of its sides squared, one could take a course in \ngeometry to learn it. If one believes that Pizzagate is a fake news story, one can do \nthe research using reliable sources for confirming that assessment.  If I think that \nJuan Diego Fl\u00f3rez is a better opera tenor than Jonas Kaufmann, that may be true \nfor one person and not others.  Matters of taste, for which one can make \narguments, are never true per se. They are matters of preferential beliefs that will \nvary among individuals or groups, even though one can a dvance arguments for \nwhy one would prefer one over the other. There are \"false beliefs,\" e.g., climate \nchange denial, which cannot be converted into truth.  Some false beliefs are often \ntried to be portrayed as truth through appeals to false arguments, fals e or selective \nexperts, faulty data collection or manipulation, or false evidence.  \nWith that background in mind, one can consider Plato's Metaphor of the Line.  He \ntakes a line and divides into two parts, the upper part being knowledge, being \nsubdivided in to the forms (e.g., justice, truth, beauty, equality) and mathematical \nknowledge.  The lower part of the line is the general area of opinion, which is \nsubdivided into belief and imagining. The focus for this research will be on the \nbottom half of the line.  Belief is focused on the world of perception, physical \nobjects, where we accept sensory perceptions as givens.  Imagining undermines \nphysical reality, where dwellers live in some sort of alternate reality.   \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n135 Opinion ( doxa) is the lower part of the line . Acco rding to Plato, some kinds of \nopinions could be converted into genuine information or knowledge. While there \nare various interpretations about what Plato meant or whether it was justified, in \nhis Theaetetus , Socrates suggested that knowledge is justified t rue belief (201 c -\nd). For example, one may believe that the area of a circle is equal to \u03c0r2 (pi times \nthe radius squared) and then prove it (at which point it becomes knowledge) (see \nthe slave experiment in Meno, 82b-85b).  Some opinion cannot be so converted: \ne.g., a belief in  the \"best movie of the past year\" or the \"best political novel.\" \nInformation specialists or librarians try to promote opinions (\u03b4\u03cc\u03be\u03b1 - doxa) as \ninformation \u2013 and within these, we hope at least to provide \"right opinion\" or the \northodoxy ( \u1f40\u03c0\u03b8\u03bf\u03b4\u03bf\u03be\u03af\u03b1, orthod oxia \u2013 \"right opinion\") that we hope will lead to \nsome version of truth(s).  The orthodoxy, to resurrect a not so common word, is \nthe \"knowledge\" of a subject according to the prevailing paradigm of that subject, \ngenerally built on the consensus of its expe rts. \nImagining is a distorted perception of the sensible world.  It is not hard to relate \nthis state with the beliefs of many citizens in contemporary culture, for example, \npersons who believe in QAnon or that Trump was a competent strategist in \nhandling th e coronavirus pandemic. Plato's lowest category may be likened to a \ncognitive state where all fake news is accepted as fact.  Understanding false beliefs \nor imaginings in the world of misinformation and disinformation, however, might \nbe further elucidated b y using Plato's Allegory of the Cave (Plato, Republic , \n514a \u2013520a).  \nSocrates describes a situation that takes place in a dark cave.  A number of \nprisoners have lived in this deep cave since birth, never seeing the light of day, \nand are physically constrained  in such a way that they cannot look to either side or \nbehind them.  Behind them is a fire, and behind the fire is a low wall, from behind \nwhich various objects are lifted into the air manipulated by another group of \npeople, who are out of sight behind the wall. The fire casts shadows of the objects \nacross the wall facing the prisoners.  The prisoners watch the sequences that the \nshadows play out and play games predicting the sequences and sounds that \nreverberate in the cave. When they refer to one of the sha dows as a \"chair\" for \nexample, they are not actually seeing a chair, but rather the shadow of a chair, \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n136 confusing its shadowy appearance with actual reality. Because of their condition \nand constraints, they believe their perceptions are the most real things  in the \nworld. They are so convinced of the reality of their context, they mock anyone \nwho would make claims otherwise.  \nAs the allegory continues to be extrapolated, the prisoners are forced to come to \nsee their actual condition, first by being shocked int o an awareness of their \ncondition, by becoming aware of the real source of the light (the fire and then the \nsun), seeing how things are as they are forced to move out of the cave; and second \nthrough a mid -wife (a la Socrates), letting them, through an inte rrogation, to come \nto understand for themselves, in a form of self -realization, their actual condition.  \nIn the Platonic/Socratic view of true education, there are two aspects of the \nSocratic method of education. Socrates as a stingray, electric eel or gad fly (to \nwhich he is referred variously Platonic writings), shocking or benumbing his \ninterlocutors into an awareness of their ignorance as they are temporarily blinded \nby the light. The purpose of this shock is to clear away what one unidentified \ncommentat or referred to as \"the conceit of false knowledge.\" It is a brilliant \nsuccinct description of the intent of the first aspect of the Socratic method.  In the \nsecond aspect, Socrates plays a midwife \u2013 using questions skillfully to have his \ninterlocutors come to a self -realization of their true condition, guiding them to the \nbirth of their ideas.  \nThis conversion process does not always succeed as many are secure in their state \nof ignorance; or they lack the wit to follow the logical conclusion of Socrates's \nquestions.  In current psychological jargon, they are victims of the Dunning -\nKruger effect.  They think that they are competent thinkers, but they lack critical \nthinking abilities that allow them to understand that there are alternate perceptions \nof reality or that their critical thinking abilities lack a foundation.  They are \nunaware of what they are unaware and do not have the capacity to make \nthemselves aware.  \nThe Socratic method is prefaced, if you recall many of Plato's dialogs, with his \nprofession of ignor ance. His interlocutor in a dialog, e.g., Meno in the Meno , \nbrings up a topic to be discussed, such as virtue. Socrates' response is an \nenthusiastic willingness to learn, because he professes that he has little or no \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n137 knowledge of the topic at hand. His pro fession of ignorance has been referred to \nas ironic, because in the end, his knowledge of the topic, as 'limited' as it is \nprofessed to be, turns out to be the most informed.  \nWhat is fascinating is the condition out of which education takes place from a \nSocratic perspective: the rise of \"imaginings\" or ignorance. This condition can \nhelp us understand contemporary world politics, especially in U. S. presidential \npolitics. Not only are many supporters of Trump are likened to Cave Dwellers but \nalso that they a re happy with their condition and do not want to leave. And they \nmock those who would claim otherwise, claiming that the outsiders believe in \nfake news. The irony is that their reality is fake, and what is fake to them is \nreality.  The question is how and w hy. During the current coronavirus pandemic, \nTrump has made claims for his managing the pandemic in the best possible way, \nthat he had anticipated the pandemic, that there were enough tests and ventilators. \nAll of these claims are verifiably false (by citi ng scientific evidence), but that does \nnot seem to deter most of the viewers of Fox News  (an ultra -right cable news \npropaganda machine) either to endorse his leadership or to ignore, dismiss or \nrationalize (e.g., he really did not mean what he said) some o f his claims (e.g., to \ninternally use bleach or disinfectant to cure the coronavirus).  \nIt would seem that there is the cognition below imagining, where not only are \nfalse beliefs entertained, but they are proudly and loudly proclaimed as knowledge \nand any  other sources or viewpoints are disavowed as fake news, that there is only \none viewpoint, theirs, for which no claims or evidence will render it problematic.  \nIt is where the weak willfully subject themselves to the strong, just as many \nfemale Trump suppor ters find no problem offering themselves for his sexual \nsatisfaction.  In another example, Trump supporters have screamed about their \ncivil rights when asked to wear a mask mandated by the store in which they want \nto do some shopping.  Their civil rights are  neither civil (they ignore the general \nhealth of the public) nor a right (their rights only extend to the point where their \nrights impinge on the rights of others \u2013 i.e., in one's minimizing the general \npublic's exposure to the coronavirus).  They themselv es are living in a fake reality.  \nAccording to them, their fake reality is their only reality.  Not only that they are \naddicted to that reality because news sources like Fox News  inflames their \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n138 grievances and stokes them to get them addicted to one news sour ce that keeps \nfeeding their biases, a process that we will elucidate later.  Plato could not have \nanticipated the sophistication of technologies to use psychology against the \ncommon good.   \nThe communication among the prisoners has been enhanced.  The cave ha s been \nextended and enlarged throughout the world. They can not only talk to one \nanother, but in the current world, but also can create a misinformation \ndisinformation ecology whereby news sources, like -minded friends, neighbors, \npolitical associates and r eligious leaders all make and reinforce the same talking \npoints, memes, narratives and propaganda.   \nA somewhat confusing scenario needs to be sorted out: what information, \ndisinformation or misinformation consumers receive is information that pretends \nto be knowledge, even if second -hand knowledge, and that may be claimed to be \nknowledge by the consumer, based on their belief in a cognitive authority (such as \na political leader, religious leader, political organization or news organization) and \nyet which is  at best in the consumer's mind second -hand knowledge that may be in \nactuality belief and even false belief, or in line with Plato's notion of imagining.  \nMany Trump supporters are now enslaved to their inflamed biases, way better \nthan any Goebbels could ha ve ever imagined \u2013 they have chosen to be enslaved \nand stoked in their biases.  They would scream and punch any Socrates that would \nforce them out of the Cave.  \nOne might think that if one used the Socratic educational techniques, benumbing \nand midwifery, on e might be able to make progress.  Consider Plato's Meno , where \nMeno meets Socrates on the street and enthusiastically wants to tell him about \nwhat virtue, \u2015knowledge\u2016 that he derived from his Sophist teachers.  Socrates is \npleased with Meno's offer, profess ing a lack of knowledge on the subject.  By \ninterrogating Meno through questions, the definitions that Meno offers are \ndemolished one after another, such that Meno is stung into an awareness of his \nreal ignorance on the subject matter, but not much liking t o be embarrassed about \nhis ignorance.  He had been parroting the talking points of his teachers, the \nSophists, who were unable to ground them in a real understanding of what virtue \nwas. When Meno is challenged, he cannot pull out of himself any groundwork f or \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n139 understanding what it is.  In a pique of self -righteousness he challenges Socrates \nwith a sophistic dilemma (an argument that appears to be correct, but is not).  It is \nspecious reasoning (in other words sophistry \u2013 derived form sophia (wisdom) but \ncorrup ted by the Sophists).  The dilemma is that if you know something, you know \nyou know and therefore, there is no need to inquire because you already know it.  \nIf you do not know something, there is no need to inquire, because even if you fell \nupon an answer, y ou would not recognize it because you don't know what you are \nlooking for.  Socrates points out the problem \u2013 the problem of knowledge is not a \nmatter of either/or, because there is a third state, opinion in which you sort of \nknow something but do not know it for sure.   \nIn the current environment, the nature of what is true, what is false and what is a \nmatter of opinion is at stake.  In fact, it has been pushed to the extreme in what one \nperson knows is unassailable and what your opponent knows is a hoax or f ake \nnews.  This strategy parades in false equivalences: each opinion is equally valid as \nany other opinion.  But we know this claim to be false.  Some opinions are true \nbeliefs that can be grounded in reality; other opinions have no such grounding.  \nTrump supp orters and their media assert that many things are true based on their \npseudo -cognitive authorities but are not grounded in facts or evidence, such as, \nthat the coronavirus is a hoax, that Trump did a wonderful job in handling it, etc.  \nNot only that, but t hat they assert that all other perceptions or information sources \nare fake, that their skewed perceptions of reality are the only ones. In the current \nworld, there appear to be two types of persons, those open to genuine learning, \nsuch as Meno's slave who came to understand how to double the size of a square, \nfollowing the midwifery of Socrates to have him come to realize a mathematical \ntruth in himself. But the Trump supporters are not only unwilling to learn but \ncondemn others who have an alternate or enl arged notion of reality.  In \ncontemporary issues, any attempts to train them with information literacy, media \nliteracy or digital literacy is a waste of time, so closed off are they to any learning, \njust as Meno cannot cope with Socrates's queries and stomp s away frustrated.  \nTo make another Platonic allusion, Trump and the current Republican party are \nlike Callicles and Gorgias in the Gorgias , self -absorbed, rapacious, amoral \npolitical realists. The Gorgias  is a dialog replete with themes echoed in the Age o f \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n140 Information and the nature of political control by the rich and powerful over the \ngoverned.  It contrasts the life of the manipulative politician, like Gorgias whose \nserves \u2015superior\u2016 pleasures and the philosopher like Socrates that serves the good.  \nThe d ialog's theme is rhetoric, the art of persuasion, and whether it is a true art or \na false one, like flattery or a knack.  Socrates suggests that it is knack or flattery \nbecause it convinces the ignorant rather than experts.  Real art should strive to \npromote  justice and the good of the people.  Gorgias maintains that the orator \nshould be able to convince the crowd on any subject, without regard to knowing \nanything about that subject.  A rhetorical argument, he argues, should persuade a \npatient to take medicine,  even though he is not a pharmacist.  If he succeeds, he \ncreates a belief in the patient (much in the manner of second -hand knowledge that \nwe will discuss later).  That belief can be founded (if the rhetorician knew what he \nwas talking about, having the appr opriate trustworthiness and expertise) or \nunfounded.  Socrates's interaction with Callicles is the most engaging part of the \ndialog as it pits the life of the politician, Callicles, with that of a philosopher, \nSocrates, whose occupation Callicles insults. T heir pursuits differ: Callicles' rule \nof the city, Socrates's pursuit of knowledge and the good, though Socrates doubts \nthat he will ever attain full knowledge.  Callicles suggests that there is no value to \nsuffering and that it should be avoided.  He wants to distinguish between man -\nmade laws and nature.  In his view, nature deems that the stronger should \ndominate the weaker and that only the weaker want laws to protect them.  These \nsuperior politicians are \"intelligent in the affairs of the city, and brave\" ( 491e).  \nBut they do not need virtues of justice or moderation, and they deserve more than \nother citizens (491b).  When Socrates asks of what these superior people deserve \nmore, Callicles rejects the idea of more eating and drinking. Still, he can't say \nwhat kinds of things are desirable by superior people, but they should be held in \nhigher regard. Socrates argues that the real politician does what is good for the \nstate, not what the hoi polloi wants to hear.  \nTrump and his base supporters are on the side of C allicles, though his base is a \nsubset of the governed, a subset living a filter bubble. They are flattered by his \nsupport of their biases (e.g., for white supremacy, against the liberal elites, for \nresentments and grievances about the lack of jobs or adequ ate income, due to \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n141 immigrants or the exportation of jobs to cheap -labor countries) and distortions \nabout the balance of powers (Trump is a king and should have no constraints in \npreserving law and order) or the rule of law (as the mechanism of the rich to keep \ntheir position of power and wealth). Trump would agree that democracy is the \ntyranny of the many against the superior individual, one with a lot of power.  \nCitizens should allow themselves to be ruled by these strong men (of which \nTrump fancies himself , as he alone can fix America's problems). Trump reflects \nand encourages his supporters' fear, grievances and anger at the status quo. \nHowever, the superiority of a Callicles seems to have a cleverness that Trump did \nnot seem to be able to muster, given hi s incompetence in handling the coronavirus \npandemic and his lack of any plans for that, healthcare, the infrastructure and job \ncreation.  Why should he and other superior individuals (e.g., government leaders, \nCEOs) still be regarded as superior? Why should  they get a greater share?  Like \nCallicles, their response is not clear.  But for Republicans, it seems to be to retain \nand build the status quo, get more shares of money, have more political control, \ndie with the best and most toys (homes, vacations, yachts , etc.)  For what, more \nhappiness?  Pleasure without justice, in the end, will make one miserable unless \none is numbed with an addiction (to money or power?).  The only real thing that \nmakes people happy is living well and doing well, within the constraints o f justice \n(as suggested by Plato).  Trump and the Republican party have shed any pretense \nof supporting democracy.  They believe that the strong (the oligarchs, the wealthy, \nthe powerful) should rule the weak. So they engage in voter suppression, vote \nsuppre ssion by making it difficult to register or get to the polls, gerrymandering to \nshape political districts to favor Republican election outcomes, and declaring that \nthe Biden election was due to voter fraud. Lawsuits to curtail the right of citizens \nto vote , etc.  They do not believe America is a democracy. On Twitter, Utah's \nRepublican Senator Mike Lee commented that the U. S. is not actually a \ndemocracy because despite Democrats winning the popular vote in two elections, \nthey did not win the electoral colle ge (which no longer justly reflects the U.S. \ndemographics).  \"Democracy isn't the objective; liberty, peace, and prospefity (sic) \nare. We want the human condition to flourish. Rank democracy can thwart that\" \n(Wolf, 2020).  Trump and many Republicans agree, a rguing that they would stop \nlosing elections if the popular vote prevailed.  Laws should not be made to restrict \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n142 banks, giant corporations, and wealthy individuals from continuing to retain their \nprivileges, which for them have become rights.   \nFollowing a r eflection of Plato\u2019s approach to rhetoric, we can follow it with a \nsojourn into Aristotle\u2019s Rhetoric (Aristotle, 2020). Aristotle discusses three types \nof appeals that a writer, author or speaker should use as a means of persuasion:  \nethos, logos and pathos  (Aristotle, 2020, Chapter II). An argument from ethos or a \ncharacter approach relies on how trustworthy or credible an author, speaker or a \nwriter is and what expertise they bring to a subject, message or theme.  They need \nto have relevant experience and a  good reputation. If they are not known, their \ncharacter is created through the text of the message, its tone, style and approach to \nthe subject matter through different perspectives.  In this case writer, author or \nspeaker connect their arguments with the audience's own set of views and values.   \nIn contemporary jargon, we might refer to the speaker, author or writer as a \ncognitive authority. What is a cognitive authority?  When one lacks experience, \neducation, or knowledge, or does not have the time or incli nation to acquire such, \na cognitive authority is a person, organization, media source, group, or leader \nwhose information one takes as second -hand knowledge based on that entity's \ncredibility, trustworthiness, and reliability. This author extends the notio n of \ncognitive authority from Patrick Wilson's book, Second -hand Knowledge:  An \nInquiry into Cognitive Authority  (Wilson,1983).  For an more elaborate treatment \nsee four papers by the author, especially the latest one: \"A not -so-brief account of \ncurrent info rmation ethics: the ethics of ignorance, missing information, \nmisinformation, disinformation and other forms of deception or incompetence,\" \n(Froehlich 2017), \"The role of pseudo -cognitive authorities and self -deception in \nthe dissemination of fake news,\" ( Froehlich, 2019), \"Ten lessons for the age of \ndisinformation,\" (Froehlich, 2020) and \"A Disinformation -Misinformation \nEcology: The Case of Trump,\" (in press). In the last two papers, I establish how \nthere are false cognitive authorities that pretend to be genuine authorities but lack \nthe necessary credentials and foundation.  It would be helpful to contrast a \nlegitimate cognitive authority from a fake one.  For example, we will use a set of \ntables, contrasting The New York Times  with Fox News . \nTable 1: What V iewers/Readers/Audiences Believe  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n143 New York Times  Fox News  \nCenter -left bias (mediabiasfactcheck.com) Because \nthey have a bias does not mean that their reporting is \nnot grounded in facts.  Strongly right bias (mediabiasfactcheck.com) \nBecause they have a bias does not mean that their \nreporting is not grounded in facts.  \nTrustworthy \"captures the perceived goodness and \nmorality of the source \" (Rieh, 2010, p. 1337).  Trustworthy \"captures the perceived goodness and \nmorality of the source \" (Rieh, 2010, p. 1337).  \nPossesses expertise:  they provide information that is \naccurate and valid  Possesses expertise; they provide information that is \naccurate and valid  \nReal News  Real News (but other sources are Fake News)  \nTable 2: New York Times : Actuality  \nNew York Times  Basis  for their Authority  \nCenter -left bias (mediabiasfactcheck.com)  Having a political leaning does not invalidate the \ncontent, particularly because opinion articles are \npublished as opinion  \nTrustworthy \" captures the perceived goodness and \nmorality of the sou rce\" (Rieh, 2010, p. 1337).  Long history (1851) as a respected publication. \nArticles are well -researched and verified. Opinion is \nidentified as opinion (e.g., editorials).  \nPossesses expertise: they provide information that is \naccurate and valid  Produces ( 1) second -hand knowledge, (2) well -\ninformed opinion (with which other may disagree: \ne.g., Trickle -down economics is not successful), and \n(3) preferences (best movies to watch)  \n Has a cadre of respected and experienced experts. \nWhen they become aware of fa lse or problematic \nstatements or reporting, they issue retractions  \n Believe in fact -finding and verification by multiple \nsources  \nAdheres to the Principles of Good Journalism \n(https://americanpressassociation.com/principles -of-\njournalism/  ) The obligation to present the truth (or the best \nrepresentation thereof, by providing evidence and \nupgrading narrative as facts and errors emerge)  \nNY Times follows these principles  Its first  loyalty is to citizens, not to partisan politics  \nFor a measured assessment, see: \nhttps://mediabiasfactcheck.com/new -york-times/  Practitioners must maintain an independence of those \nthey cover  \u2013 when covering anything connected to \nthe NY Times, they note it  \n Serve as an independent monitor of power \u2013 they \ndon't fall prey to party or administration favoritism  \n Must provide a forum for public criticism and \ncompromise \u2013 all sides of an issue are  striven to be \nportrayed and balanced  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n144  Must strive to make the significant interesting and \nrelevant  \n Must keep the news interesting and proportional. \nThis means that one does not sensationalize certain \nevents and ignore others, stereotyping or being over ly \nnegative \u2013 all affected communities and perspectives \nmust be taken in account.  \n Its practitioners must be allowed to exercise their \npersonal conscience. Opinions of editorialists and \nreporters reflect an ethical framework.  \n \nCompare this table with the  table for Fox News:  \nTable 3: Fox News: Actuality  \nFox News  Basis for their Authority  \nStrong right bias (mediabiasfactcheck.com). For a \nmeasured assessment see: \nhttps://mediabiasfactcheck.com/fox -news / Having a political leaning does not invalidate the \ncontent, particularly because opinion pieces are \npublished as opinion.  Unfortunately, their political \nposition is reflected in what are supposed to be \nfactual observations, what they say and what the \nomit. \nThey claim that they are trustworthy implying that \nthey stand for \"the perceived goodness and morality \nof the source \" (Rieh, 2010, p. 1337).  It has a long history associated with right and \nconservative causes, a history which has been often \nshaky and scandalous, with commentators leaving \n(e.g., Bill O'Reilly) for various reasons, often sexual \nharassment.  (Stelter, 2020; Smith, 2019).  Sometimes \ntheir sources are conspiracy theories taken from alt -\nright web sites.   \nPossesses expertise:  they purport to p rovide \ninformation that is accurate and valid  They have various pundits, Sean Hannity, Tucker \nCarlson, Jeanine Pirro, Neil Cavuto, et al., who claim \nto be experts, but they are mostly apologists for ring -\nwing viewpoints. Its second -hand knowledge on \npoliti cal matters is often at best opinion or opinion \nbased on alternative \"facts\" or misconstrued data. \nLou Dobbs praised Trump for being nominated for a \n\"Noble\" Prize, omitting the fact that anyone can \nnominate anyone for a Nobel Prize and that the \nnominator w as a far -right Norwegian with an ax to \ngrind about immigration to Norway (Harvey, 2020).  \nThe obligation to present the truth (or the best \nrepresentation thereof, by providing evidence and \nupgrading narrative as facts and errors emerge)  For four straight m onths, they pushed misinformation \nevery single day (Sullivan, 2019). Trump's failure or \nincompetence in dealing with the coronavirus \nepidemic is never mentioned, and in fact, he is \npraised for his superior leadership.  \nIts first loyalty is to citizens  Their loyalty is toward its partisan viewers, not to all \ncitizens, though they hope to convert them.  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n145 Practitioners must maintain an independence of those \nthey cover  The most obvious case is that of Donald Trump.  \nThey never criticize his speech or behavior and  claim \nhe is the best president that the US has ever had.  He \nfrequently is invited or invites himself for interviews.  \nTheir relationship is so close that Fox News is often \nreferred to as \"Trump TV.\"  \nServe as an independent monitor of power  See the above; most commentary and commentators \nsupport right -wing causes:  unfettered capitalism, \noligarchy, pro -business, anti -labor agenda, etc.  They \nendorse the Republican party and the Trump agenda, \noften ignoring previous principles of conservatism \n(e.g., anti -commu nism, fiscal responsibility).  \nMust provide a forum for public criticism and \ncompromise  They rarely invite speakers, politicians or \ncommentators from the Democrats or the left.  They \nalso refuse to run advertisements that are critical of \nthe president or ri ght-wing agenda  \nMust strive to make the significant interesting and \nrelevant  They are committed to reporting or making narratives \nthat support the biases of their viewers, a right -wing \nor conservative viewpoint (which has been muddled).  \nMust keep the ne ws interesting and proportional.  \nThis means that one does not sensationalize certain \nevents and ignoring others, stereotyping or being \noverly negative \u2013 all affected communities and \nperspectives must be taken in account.  They are often committed to sensati onalism, such as \nfear of migrants, fear of communism and socialism, \nturning peaceful protests into riots against law and \norder, etc.  For an overview of a variety of issues, see:  \nhttps://en .wikipedia.org/wiki/Fox_News_controversi\nes \nIts practitioners must be allowed to exercise their \npersonal conscience.  When reporting, one should include their viewpoint \nreflecting their own moral conscience.  Certainly, \nmany of Fox News pundits do so:  Sean Hannity, \nTucker Carlson, Jeanine Pirro, Neil Cavuto, et al. \ntake that view, but there are serious questions about a \nmoral compass that approves of children in cages, \nthat support a continuous liar (20,000+ lies or \nmisleading information until July 13, 2020  \n(https://www.washingtonpost.com/politics/2020/07/1\n3/president -trump -has-made -more -than-20000 -false-\nor-misleading -claims/ ) or ignore, hide or manipulate \nrelevant information.  \n \nBy any rational assessment, Fox News  is a false or pseudo cognitive authority.  It \nis not that Fox News  is the only false cognitive authority in the ultra -right echo \nsystem.  There are many social medi a sites on the internet that also play that role.  \nBut Fox News  is a major source.  It persists as a reliable source of information to \nmany information consumers, especially Republicans.  A study Pew Research \nCenter undertook in the fall of 2019 provides an a nalysis of how Fox News  \ninfluences the American public. It concluded:  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n146 1. Around four -in-ten Americans trust Fox News . Nearly the same share \ndistrust it.  \n2. Republicans [(2/3) and Republican -leaning independents (65%)] trust \nFox News  more than any other outlet. Democrats distrust it more than \nany other outlet.  \n3. On an ideological scale, the average Fox News  consumer is to the right \nof the average U.S. adult, but not as far to the right as the audiences of \nsome other outlets [Such as Rush Limbaugh and Alex Jones.]  \n4. People who cite Fox News  as their main source of political news are \nolder and more likely to be white than U.S. adults overall.  \n5. Those who name Fox News  as their main source of political news \nstand out from the general public in their views on key issues an d \npeople, including President Donald Trump. (Gramlich, 2020)  \nHow is it possible? It is possible because these kinds of Trump supporters live in a \n\"closed propaganda loop,\u2016 (Benkler et al., 2018) where they interact within the \nsame disinformation -misinforma tion ecology, where each element (like minded \nnews sources, political party, political leaders, religious leaders, peers and \nassociates) echo and reinforce one another, and where they are conditioned to \nbelieve that all other news sources and social media sites are \"fake news.\" They \nfall prey to confirmation bias, among many others (e.g., stereotyping bias, the \navailability heuristic, attentional bias, illusory truth, affect bias), all of which \nprecondition Fox News  viewers and other alt -right propaganda si tes to accept their \ncontent uncritically.  Confirmation bias is a common one.  Confirmation bias \ninvolves interpreting information that supports one's existing beliefs, even when \npresented with conflicting evidence. Trump supporters hold all sorts of \nimproba ble beliefs because they concord with their preexisting beliefs: e.g., that \nTrump was a great president; he was successful in curbing the coronavirus, its \ninfection, and death rate; he cares about poor people; he is draining the \nWashington swamp; he is a g reat businessman; that his tax cuts helped all \nAmericans; and that he has an excellent plan for healthcare, all of which are false.  \nNot only do they engage a confirmation bias, but also a disconfirmation bias \"in \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n147 which we expend disproportionate energy try ing to debunk or refute views and \narguments that we find uncongenial.\" (Mooney, 2011).   \nReturning to Aristotle, Trump's supporters would appear to believe that the kinds \nof arguments presented to them belong to ethos, which relies on how trustworthy \nor cre dible an author, speaker or writer is, and what expertise they bring to a \nsubject or theme. The viewers or audience believe that those speakers, authors or \nwriters have relevant experience and a good reputation. Despite the flawed nature \nof Fox News  pundit s, they claim to be credible and have the expertise (despite \nevidence to the contrary). Their pundits connect their arguments with the \naudience's own set of views and values (even as they create and shape many of \nthem).   \nIn actuality, their arguments are f rom pathos, arguments that draw on the \naudience's or viewer's emotions, sympathies, interests, and/or biases. In this case, \nthe audience is solicited to identify with the speaker, author, writer or messenger \u2013 \nto feel or experience what the speaker, author , or messenger feels. It is often \nengaged by pundits who stoke the fear or anger of its viewers, message receivers, \net al., culminating in moral outrage and self -righteousness over events, memes \nand narratives that oppose their established beliefs.  \nAristot le's third type of rhetorical argument does not seem to apply in this \ndisinformation ecology because it relies on the clarity of the message's claim, \nlogic, and the supporting evidence.  The audience or viewers should follow a clear \nprogression of ideas bac ked up with reasonable and appropriate details.  Yet, in \nthis disinformation ecology, some think that the arguments that Fox News  presents \nare from logic and evidence. But, the logic is one that supports their viewers\u2019 \nbiases and the evidence is cherry -picked from available data or like -minded \nselected sources and contrary evidence is omitted or ignored.  This failure to be \ncritical seems to be the consequence, as mentioned earlier, of the Dunning Kruger \neffect in which individuals overestimate the truth of t heir opinions and their \ncritical thinking abilities, and underestimate the soundness of their beliefs.   \nIt is clear that Fox News is a false cognitive authority that spreads false messages \nto its devotees (conditioned by, appealing to and enhancing the cog nitive biases of \nits viewers). It dovetails with the research of Rafael Capurro in \u2015Pseudoangelia \u2013 \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n148 Pseudoangelos:  On False Messages and Messengers in Ancient Greece\u2016 (Capurro, \n2020).  False cognitive authorities and false messages have been as old as man.  If \nwe take Genesis literally, Eve was tempted by the first false messenger (pseudo -\ncognitive authority), the serpent, with the first false message that it conveyed \nwhen she told it that she was not allowed to eat of the fruit of the tree in the \nmiddle of t he garden.  \u2015And the serpent said unto the woman, Ye shall not surely \ndie: For God doth know that in the day ye eat thereof, then your eyes shall be \nopened, and ye shall be as gods, knowing good and evil. (King James Bible, 2017, \nGenesis 3:4 -5). It turned o ut to be the first case of paltering, because Adam and \nEve did come to know good and evil after disobeying God, but the devil did \nmanage not to explain all the consequences that would come with having self -\nconsciousness. There are some correspondences betw een the trustworthiness of \nmessengers and reliability of messages in ancient Greece and the criteria of \ncognitive authorities detailed above which are expertise, (i.e., it increases a \nperson\u2019s perception that a source is able to provide information that is  accurate \nand valid (Rieh, 2010, 1337 -1138)) and trustworthiness (i.e., the sources of the \ninformation are perceived to be good and they exist within an ethical framework, \none at least that comports with the orthodoxy (Rieh, 2010, 1337)).  Capurro cites \nLewis concerning the criteria for evaluating the news and the messenger as \ntrustworthy:  (1) identity (credentials), (2) class (status), (3)  autopsy  (eye-witness),  \n(4) motive  (financial  gain,  official  herald) (Capurro, 2020, 113).  The context is \ndifferent ( polis versus nation -states, such as the United States) and the notion of \nwhat is news differs between the ancients and moderns.  There is no word for news \nas such in Greece, Lewis asserts, but is related to the word for report (Capurro, \n2020, 111). With that c aveat in mind, identity or credentials can be seen to map to \nexpertise. Class maps to social strata, which is mixed in contemporary societies \n(different levels of message receivers exist in different societies and countries).  \nMost information sources in co ntemporary society claim access to eyewitnesses \nunless they are the eyewitnesses; this property maps to both trustworthiness and \nexpertise, because the source of the information is perceived to be good and the \nsource of the information is thought to provid e accurate information.  In both \nmodern and ancient societies, there is an interest in financial gain (e.g., make \nprofits from the news), but whether it represents an official herald depends on the \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n149 context (an authentic context or inauthentic context), but the intention includes \nmaintaining or gaining power or political influence.  We can continue the contrast \nof Fox News  and the New York Times  mentioned above, as messengers or \ncognitive authorities, dispensing true or false messages to their political client s. \nThe New York Times  has strong credentials reporting reliable information \n(messages) for close to 150 years, correcting their reporting when appropriate, \ndespite a center -left bias.  It has achieved an important status in a democratic \nsociety, and provide s reliable information for mostly an educated class.  It either \nplays the expert or pays for experts or uses expert witnesses to support their \nreports (messages).  They seek financial compensation for providing reliable news, \nbut also want to serve as an ind ependent monitor of power.  Fox News,  on the \nother hand, does have an identity and credentials: its identity and credentials are \nas a conservative news source, though its viewpoint has declined into a source of \npropaganda for Trump and an alt -right agenda, in which conservatism has moved \nfrom fiscal responsibility to fiscal irresponsibility and from rejection of foreign \ninterference to encouraging relationships with dictators.  They are not an \nindependent monitor of power, but promote and inflate the power of  Trump and \nhis political party, the GOP having become the Trump party.  It has achieved a \nstatus among conservative circles, because it panders to their fears or grievances, \neither real, imagined or inflamed. Its use of eyewitnesses is frequently dishonest:  \nfor example, to continue to establish the false message that the coronavirus was \noverrated, Fox News pundit, Tucker Carlson, on April 27, 2020 argued against the \nlockdowns imposed by medical authorities by appealing two \u2015experts,\u2016 Drs. Dan \nErickson and Ar tin Massihi, who claimed that the lockdown was excessive,  that it \nundercut economic activity, especially the ability to make an income, and \nimpinged on the rights of citizens to freely associate.  Their research has been \ndiscredited by reputable researchers  and research organizations \u2013 there were \nstatistical errors in their research and there is contravening evidence of thousands \nof genuine medical experts (LeTourneau, 2020).  Its motives are quite clear, to \nmake a lot of money (Fox News makes $2 billion doll ars per year (Stelter, 2020, \np. 20)) and it promotes a very right political agenda, in order to maintain power \n(trying to have Trump remain as president) and/or to gain power.  In \u2015A \ndisinformation -misinformation ecology: the case of Trump\u2016 (Froehlich, 2020 ), \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n150 this author analyzes the different strata of the Trump ecology \u2013 those at the top \nwho want retain power and political influence and those at the bottom that want \ntheir inflamed grievances appeased.  Fox News is a rumor mill, sometimes \ncreating conspiracy  theories or spreading conspiracy theories taken from alt -right \nweb sites, but to a specialized group, whose members that live in a closed \npropaganda feedback loop.  They are a kind of polis , a city within the nation, \nwhose boundaries are set by a misinform ation -disinformation ecology of like -\nminded news sources, like -minded political leaders, religious leaders, colleagues, \nfriends, associates, and partisans, enveloped in social and collective self -deception \nand rejecting any sources that do not conform to t he beliefs within their filter \nbubble.   \nThe difference between the wiles of rumor in Capurro\u2019s paper and in \ncontemporary culture is that the nature of the group within which the rumors \ncirculate or take hold and the nature of the rumors that are circulated . In the polis, \nthe rumors were echoed through the class structure and the nature of the rumor is \nrelated to the political structure of the polis  and external events.  Within the closed \npropaganda feedback loop there are circulated conspiracy theories where  \nauthority, message, messenger, ingroup, eyewitness and motive reinforce each \nother and outlaw other rumors (such as authentic news).  They are methods of \ntrickery in the InfoWars or rather the wars of disinformation against authentic \ninformation, expertise  and humanism, that turn genuine information and expertise \ninto a culture war (such as defending the use of hydroxychloroquine as a \ntreatment against Covid -19, a method debunked by medical authorities). The \nrumors of the filter bubble in which they exist c an be quite fantastic, such as those \nof QAnon who hold that Trump is their savior from Democrats and liberal elites \nwho are involved in the sex -trafficking of children and the murder of children to \nextend the life of the elites (Wong, 2020), or those that believe the election was \nstolen from Trump.  Sidney Powell, a lawyer for Trump advanced claims of huge \nvoter fraud and a rigged election, by claiming a supercomputer called Hammer \nhacked votes, that Trump won the election by \u2015millions of votes,\u2016 and that \nDominion Voting Systems, the voting software company, changed the tallies in \nfavor of Biden (Qiu, 2020).  There is no evidence for such a claim and yet it was \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n151 circulated and amplified and accepted in the misinformation -disinformation \necology as genuine inform ation, only genuine for false messengers such as Fox \nNews  dispensing false messages, e.g., that Trump won the election. There is only \none subtext for most of the rumors:  the sowing of discord and divisiveness, \nfulfilling the dream of Russian chicanery, the  destruction of American democracy.  \nSuch chicanery is part and parcel of the Age of Distraction.  \n2. The Age of Distraction  \nWe are all born into a world in a specific context at a specific time.  As we grow \nup, we are given a set of perceptions and told what pe rceptions are important, are \ngiven interpretations about those perceptions, including emotional valences.  As \nthe Heideggerian (Heidegger, 2010, Section 38) metaphor indicates, we are born \nin a state of fallenness, a state where we are absorbed into the wor ld in its \neverydayness. While man in his essence is care and openness to being, he is \nstifled by our culture and society.  Such fallenness into the world is manifested in \neveryday things, in idle talk or gossip, the endless search for curiosity, and living \nin ambiguity, something akin to Sartre's bad faith, in which one manages to live \nlife believing what one does not believe and avoiding responsibility for one's life \nchoices (which are held as not -choices).  \nIdle talk or gossip means more than just talking a bout tweets, sports or the \nweather.  Any speaking or writing does not open one's possibilities to becoming \none's specific authentic self but constricts them.  It is talk that does not involve \nthinking.  It is an uncritical, unexamined way of talking about fac ts and \ninformation while failing to use language to understand what is actually \nhappening critically.  People merely repeat everything they have heard about the \nsubject under discussion (whether information or disinformation) and use that \nunderstanding to j ustify their approach to the topic.  In accepting opinions or \n\"knowledge\" that they believe are common to everyone, they seek conformity in \nthought and action. This disposition is characteristic of all human beings in their \neverydayness; we interpret things  in terms of what we believe is orthodoxy or \ncustomary.  How does this work for those living in a \"closed propaganda loop\" \n(Benkler et al., 2018)?  It is not that they are living in the ordinary. They have \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n152 resolutely decided to stay not only in the ordinary but also in ignorance \u2013 they've \nbeen chosen or enticed into being permanent and resolute dwellers of Plato's \nCave.  Inside of a disinformation ecology, their \"understanding\" is based on the \n\"they\" of their like -minded sources, cognitive authorities, friends , political \nideology (not that their individual grievances are the same, but they participate \nsomewhere in a partisan framework or filter bubble) with a commitment so strong \nthat no adverse information is allowed to enter and any Socrates would be \nexecuted , not because Socrates offended the orthodoxy (e.g., as in Athenian \ndemocracy) or because he offended not the unorthodox, but that he questioned the \nanti-orthodox, where alt -right partisans live (though they live in a king of \northodoxy, where the rightness  of their opinions are tied to their biases)>  \nTo say that curiosity is one of the aspects of fallenness seems odd at first. \nHeidegger's notion of curiosity is not to be taken in the usual sense, but the \nongoing fascination with the new.  Situated within our  ordinary, everyday \nexistence, one is swept along by an endless quest for what is new, a quest that is \nendless.  One seeks endless stimulation rather than focusing one's energies on \nmeaningful action that will help one determine one's purpose is in life. \"T hey\" \n(society, culture, the Zeitgeist, Silicon Valley Tech companies, Facebook \"likes\") \nbeckon us to seek more and more novelty, to grab our attention. How does that \nwork in the disinformation ecology?  In the disinformation ecology, the partisans \nseek more , different and new sources to feed their grievances, resentment, fear or \nanger in opposition to others not embracing their position.  Driven by self -\nrighteousness or to bolster their self -deception and social self -deception, they seek \nto find new and more \"evidence\" about the rightness of their position and their \nconfirmation bias from Fox News , like -minded news sources and partisan -minded \nsites on the internet have a lot to offer, such as Breitbart, Truthfeed, and certain \nfeeds or sources on Facebook, YouT ube, including click -bait, or other sources.   \nAmbiguity is the third feature of fallenness.  In the sphere of everydayness (what \nwe typically do day by day in conformity with what we think is expected of us), \none chatters about the latest trends, what is fa shionable, what is the most engaging \nentertainment, what video streams to binge on, whose tweeting about what, etc.  \nLiving in ambiguity represents a loss of any sensitivity to the distinction between \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n153 genuine understanding and superficial chitchat; it is to  fall prey to whatever \nexplanation \"they\" offer.  There is no attempt to get to a real understanding of \none's self, one's goals, or one's position in society or the world, let any significant \ncontribution to it. In the disinformation ecology, consumers of t he propaganda \nfeedback loop or those living in a filter bubble, are restricted to \"understanding\" in \nterms of conformity with the memes, narratives and tropes of their  crowd, their  \nparty, their ingroup , their  news channels, their  social media sites, and their \ncognitively authorized propaganda.  They live in the ambiguity of being right \nabout their being right (arrogant self -reinforcing self -righteousness), yet \nsubconsciously knowing that they live in a prison of biases and resentments.  \nWhile Heidegger (1962 ) established his philosophy almost a century ago ( Being \nand Time was published in 1927), he well anticipated what we might well call the \nAge of Distraction.  Our technology feeds and solicits us with constant streams of \ninformation and amusements to which to pay attention, billions of facts, products, \nentertainments or events of whatever character. Recalling Neil Postman's \nprescient book, Amusing Ourselves to Death , we now have streaming services \nwith which we can occupy ourselves with an almost infinite li fetimes of movies, \ntelevision series, opera, any form of audio, video, photography, scents, texts, \ntactile experiences, all lavish intoxications for the senses, individually or \ncombined.  The origin of 'amuse' comes \"from late 15c., 'to divert the attention , \nbeguile, delude,' from Old French amuser' fool, tease, hoax, entrap; make fun of,' \nliterally 'cause to muse' (as a distraction).\" \n(https://www.etymonline.com/word/amuse ). Granting  that there are piece s of art \nthat teach us about ourselves and the world, it is not clear that how much of such \nbeguiling, hoaxes or entrapments help us understand ourselves, our world or our \nroles better, but to distract us into streams of diversions from one thing (latest \nfashion on Home Shopping Network) to another (latest gossip on entertainment \ntelevision) and then another (email notification from a friend) to another (new \ntechnological gadget), a whirlwind of contrivances to occupy our time and divert \nfrom boredom.  We ha ve Google, which can supply data for most trivial of our \nquestions (but anything beyond the first page of results does not count for it \nexceeds the user's attention span). We can consult Alexa to fill up any possible \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n154 vacuum in our lives with trivia, should  we want \u2013 it continuously offers us games, \nfactoids, and trifles to keep us amused, not that it can't help us move toward \nauthenticity as well.  Our cell phones constantly provide alerts about email, about \nthe latest news, about calls from friends and soli citors, to the point of addiction (to \nwhich we will return shortly).  While the original goal of this technology is to \nprovide useful information, amusement, photography, among many other \napplications, it is also to make more profits for their creators, esp ecially by \nexpanding its use.  This technology is not bad, but in our fallenness, it inclines us \nto fill the void avoiding the decisions to make meaning for our lives, our country, \nour world and our earth.   \nGiven a partisan political obsession, this fallenn ess involves an ecology based on \none's circumstances.  This ecology predisposes the individual to a way of seeing \nand interpreting the world.  Whether by conscious motivation (through \"willful \nignorance\" or information avoidance), or unconscious motivation ( through \ngullibility or cognitive bias) , their receptivity to the world is restrained, and their \neverydayness is deformed. The \"they\" that drives their explanations are a few like -\nminded or like -promoting sources or cognitive authorities (like Fox News  or \n8chan or Rush Limbaugh, a radical -right -wing radio host). The ecology most \nlikely flows with a mixture of information, disinformation, misinformation, and \nopinions, whether true, false, or a preference. While may partisan adherents may \nthink that they are getting knowledge, they are getting at best second -hand \nknowledge and at worst false opinions.  Their cognitive authorities are like the \nSophists, who had the appearance of promoting knowledge or wisdom, but could \nnot do so, so they became known for their s ophistry. They appear to have \nmemorized the key points (a la Meno) suited to their cognitive biases, but they \ncannot explain the information they get or provide genuine arguments.  It satisfies \nthem that Trump said so or Fox News  said so or Breitbart said s o because it \nsupports their emotional triggers.  The sophistic cognitive authorities fool \nthemselves into thinking that their thinking is the only correct one and they think \nthat they communicate it to their students, but they fail, for the students only \nmemorize the opinions, memes or talking points but cannot provide any grounds \nfor it.  These authorities and their students come to deceive themselves about what \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n155 they \"know.\" This self -deception is echoed and reaffirmed in like -minded friends, \nassociates, nei ghbors, internet sources, religious or political leaders who \ndialectically reinforce each other's viewpoint leading to social and collective self -\ndeception.  In addition, there are cognitive authorities who reinforce these \nviewpoints and explicitly deny the  validity of any other views.  They enforce the \nidea that they and like -minded authorities are the sole sources of truth and that all \ncompeting authorities are to be rejected.  What puts power into the self -reinforcing \ndialectic of each dimension is the repe tition of the same message, not only from \none source but also from multiple sources (the president, partisan legislators, \ncabinet members, and like -minded friends, neighbors, religious leaders, political \npundits, web sites and sources).  In such a way, does  Heidegger anticipate the Age \nof Disinformation, another way of characterizing the underbelly of the Age of \nInformation.   \n3. The Age of Disinformation  \nThe Age of Information has provided access to information throughout the world \nwith the inventions of comput ers and networks that can share all sorts of \ninformation. However, it did not take time for disinformation and misinformation \nto wreak havoc on the internet, for all the good intentions for information -sharing \nturned to misinformation - or disinformation -sharing, mainly for political \nexploitation.  The difference between misinformation and disinformation is that \nthe latter is created with the specific intent to deceive. In many cases, it is not \nclear whether a piece of misinformation is just misinformation or  disinformation \nbecause the intention may not be clear.  This false information comes in various \nforms, paltering, lies, fake news, ignorance or attacks on credible sources.  Access \nto the internet is now, more often than not, access to resources that reinfo rce \nbiases, ignorance, prejudgments, and stupidity. Parallel to a right to information, \nwe have created a right to ignorance.  Not only that: we, whether as individuals, \ngroups or institutions like the government, have the legal right in the United States \nto disseminate ignorance and to block venues of facts and truth and smugly claim \nto present lies and distortions as \"alternative facts.\"   \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n156 In some respect, we have also entered an age of the Anti -Enlightenment, in which \nknowledge gained systematically and th rough careful observation of the \nenvironment is rejected and replaced by arrogant anti -science, anti -humanitarian \npropaganda whose misinformation or disinformation is transmitted through print \nor digital media, cable broadcasting or social media. The Enlig htenment (roughly \nstarting in the 18th century Europe) encompassed various ideas centered on \nreason as the primary source of authority and rightfulness, not church, royalty, or \npolitical or inherited rank.  It advanced ideals of individual liberty, constitu tional \ngovernment, separation of church and state and religious tolerance.  Many of these \nnotions were institutionalized in the United States Constitution and the structure \nof its government.  In the current environment, individual liberty is now claimed to \nsupport partisan politics (e.g., only right partisan politics are true), to erase \nseparation of church and state (e.g., America was established as a Christian \nnation), and to attack contravening reason and evidence, so as to support \nintolerance of those wh ose views are different from a right -partisan ideology.  Not \nall aspects of the Enlightenment were positive, according to some thinkers.  In \nfact, one Catholic nun believes that some aspects of it have contributed to \nnegative aspects of contemporary life and  political activities in that life.  For Sr. \nJoan Chittister, a Benedictine nun, the Enlightenment has increasingly favored \nradical individualism and denigrated the common good.  Its fruition lies in many \nexamples of contemporary culture, for example, where anti-maskers scream at \nstore personnel refusing to wear a mask when asked to do so for public health.  \nAccording to them, individual civil rights trump any concern for the common \ngood or public health. She has come to call it \"toxic individualism\" (Chittist er, \n2020).  The notion of a public good has been currently challenged by the right, \nfailing to see that, for example, education for all has benefits for all.  Fake news \nsources are generated by various political actors to produce lies and \ndisinformation.  They are propagated through the internet and social media, stories \nuncritically gobbled up by adherents of a partisan position.  They are clothed as \nalternative facts, making the notion of fact or evidence itself problematic.  Science \nis denigrated if it does n ot concord with a political agenda.   \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n157 Americans have been dying by the thousands for failing to adhere to experts' \nassessments on handling the coronavirus pandemic.  Expertise of whatever \ncharacter is not only challenged but rejected: real news, science, cli mate change, \nenvironmental issues, national security information, etc., are all said not to exist or \nbe a hoax, and any contrary evidence is claimed to be fake.  There is the loss of \nrespect for expertise, the consequences of which Tom Nichols detailed in The \ndeath of expertise: The campaign against established knowledge and why it \nmatters (2017).  He is a national security professor at U. S. Naval War College, \nwho looks at phenomena in higher education, technology, and the news media.  \nKey points of his insig hts include: (1) We have moved into a world where we \nadhere to our values and reject evidence (as in the case of anti -vaxxers, who come \nfrom all levels of education). (2) Even educated people are prone to confirmation \nbias, mathematical illiteracy, and fai lure to understand the scientific method as an \nevolving, self -correcting process. (3). In academia, there has been a shift to the \nstudent as client or customer view, which raises two concerns:  (a) while there may \nbe some limited value in student assessment  of teachers, it creates a \"habit of \nmind in which the layperson becomes accustomed to judging the expert, despite \nbeing in an obvious position of having inferior knowledge of the subject material\" \n(Nichols, 2017, p. 97) and (b) it also fosters the idea th at  \nWhen feelings matter more than rationality of facts, education is a doomed \nexercise.  Emotion is an unassailable defense against expertise, a moat of \nanger and resentment in which reason and knowledge quickly drown. And \nwhen students learn that emotion trumps everything else, it is a lesson they \nwill take with them for the rest of their lives (Nichols, 2017, p. 99).  \n(c) Universities (and high schools) have inflated students' ideas of competence \nthrough grade inflation. (4) The use of Google and other se arch engines conflates \ninformation, knowledge, experience, fact and opinion, and reinforces that \nconflation.  (5) Instantaneous communication with immediate response to queries \nfosters gut reactions to information and does not foster critical thinking.  In \nresponse to that observation, I would suggest a slow -thinking movement in the \nsame way that the slow food movement arose as a response to fast food. (6) In an \nideology of democratic equality, experts are demeaned as elitists; on the other \nhand, because expe rts are smarter than others in certain subject areas, they often \nmake the mistake of thinking that they are smarter than others in areas in which \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n158 they are not experts, which demeans their real expertise. (7)  Universities are \nsacrificing their intellectual authority by activists that attack the traditions of free \ninquiry by opposing the presence of speakers on campus whom they deem are not \npolitically correct (e.g., cancel culture).  (8) Journalism itself contributes to the \ndeath of expertise:  \nJournalism is n ow sometimes as much a contributor to the death of expertise \nas it is a defense against it\u2026.  \nThis fusing of entertainment, news, punditry, and citizen participation is a \nchaotic mess that does not inform people so much as it creates the illusion of \nbeing informed.  Just as clicking through endless Internet pages makes people \nthink they are learning new things, watching countless hours of television \nand scrolling through hundreds of headlines is producing laypeople who \nbelieve \u2013erroneously \u2014that they understa nd the news. Worse, their daily \ninteraction with so much media makes them resistant to learning anything \nmore that takes too long or isn't entertaining enough.  (Nichols, 2017, pp. \n137, 143).  \n(9) Journalism has morphed \"news into entertainment [that] stretc hes across every \ndemographic\" (Nichols, 2017, p. 156).  (10) Modern media is an exercise in \nconfirmation bias: \"This means that Americans are not just poorly  informed, \nthey're misinformed  (Nichols, 2017, p. 157).  These two disorders are different.  \nCiting a 2000 Pew Research Center study, uninformed citizens do not have access \nto information at all, and misinformed people reject evidence that does not accord \nwith their belief system and seek data that harden their belief system. \"And, of \ncourse, the most misi nformed citizens' tend to be the most confident in their views \nand are also the strongest partisans'\" (Nichols, 2017, p. 157).  The earlier analysis \nof Fox News confirms this assertion as being a long -standing purveyor of \ndisinformation and misinformation w here contrary to factual evidence, they have \npromoted Trump as an excellent president and where there is no critical \nevaluation of him.  As a result, \"Those who say they trust Fox most as a television \nnews source are far more likely to approve of Trump than  those who don't. In fact, \nnearly every Republican who most trusts Fox News says they approve of how \nTrump's faring as president (Bump, 2020).\" In October 2020 survey, Fox News \nRepublicans approved of Trump at around 97% and for all Republicans, it is 78% \n(Bump, 2020).  \nWorld War III has started.  As much as one would like to rail against the \ndisinformation and conspiracy theories of Alex Jones, he is right about one thing:  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n159 we are engaged in InfoWars, the title of his \"news\" program.  To name it more \ncorrectly , they are the disinformation -information wars, where misinformation or \ndisinformation trumps genuine information, where one's partisan opinions not \nonly trumps what opposes it but also attempts to discredit it. In this respect, \nanother name of the underbe lly of the Age of Information is the Age of \nDisinformation -Information Wars. The first major salvo of WW III was InfoWar \nI, the 2016 election of Trump, echoed in other authoritarian countries in the world. \nThe war is not trivial.  It is a World War.  \nNo matt er what the country (e.g., Bolsonaro's election in Brasil), it is a battle for \nscience, reason, evidence, expertise and fact (and humanism) to anchor political \ndecision making, individually and collectively, and to save the planet from \nbecoming uninhabitab le. On the one side, we have cable news channels (e.g., Fox \nNews, Sinclair Broadcasting), Russian trolls, conspiracy theorists, social media \nrun amuck with \"alternative facts,\" and a president, an administration, and a \npolitical party (i.e., the GOP) commi tted or consenting to the destruction of \ndemocratic norms, and the resurgence of racism, sexism, fascism, rampant \ncorruption, climate denial, etc.  On the other side, we have news channels \n(MSNBC \u2013 a center -left cable news channel), news organizations ( New York \nTimes ), social media, an opposition party, a side that also sometimes degenerates \ninto a negative force (e.g., cancel culture). There is a third party, the disengaged, \nwho fails to be concerned (let alone understand) with the deterioration of \nAmerican  democracy, the climate crisis or the proper role the U. S. needs to play \nin the world.  It is a war of disinformation, misinformation, lies, absent \ninformation, etc., against the evidence and truth, and for power and greed trolling \nsimplistic solutions to complex problems.  The sides are not balanced, for the one \nside (the right) spreads disinformation and actively challenges, abuses, and attacks \nthose committed to truth, evidence, facts, and logic.  It is not that we have two \ncompeting opinions (say that of Rachel Maddow of MSNBC versus Sean Hannity \nof Fox News ) but a belief that declares its opposition to have no valid grounds, \nthat in a supreme example of false equivalences, all opinions are equal, but the \nright's opinion outweighs all others, that all othe rs are fake news. It is true to say \nthat everyone is entitled to an opinion, but not all opinions are the same or \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n160 equivalent \u2013 some are grounded and others unfounded.  The argument on the right \nis to insist they are the same, that the right's biases trump s cience, evidence, logic \nand facts.  Science and advice from experts are treated as opinions in a political \nculture war.  Of course, people on the left can exercise the same ploy (e.g., left -\nwing authoritarians), but research indicates that the strategy takes  place more on \nthe right than for the center or the left.  Not only that, but Ingraham found that \nconservatives are more likely to fall for fake news stories than the left (Ingraham, \n2019).  \nYochai Benkler, Robert Faris, and Hal Roberts published Network Pro paganda: \nManipulation, Disinformation, and Radicalization in American Politics, which \nshows that right and other media differ significantly in dealing with network \ninformation.  By doing a rigorous analysis of online stories, tweets, and Facebook -\nshares dat a points, the authors conclude that \"something very different was \nhappening in right -wing media than in centrist, center -left and left -wing media.\" \n(Benkler et al., 2018, p. 14). They observe that  \nthe behavior of the right -wing media ecosystem represents a  radicalization of \nroughly a third of the American media system. We use the term \n\"radicalization\" advisedly in two senses. First, to speak of \"polarization\" is \nto assume symmetry. No fact emerges more clearly from our analysis of how \nfour million political  stories were linked, tweeted, and shared over a three -\nyear period than that there is no symmetry in the architecture and dynamics \nof communications within the right -wing media ecosystem and outside of it. \nSecond, throughout this period we have observed re peated public \nhumiliation and vicious disinformation campaigns mounted by the leading \nsites in this sphere against individuals who were the core pillars of \nRepublican identity a mere decade earlier. (Benkler et al., 2018, p. 14).  \nBenkler et al. believe th at the research they performed generally indicated that the \nleft were less susceptible to their biases and that the right sought confirmation bias \nto their preexisting beliefs.  They conclude that \"the right -wing media ecosystem \ndiffers categorically from t he rest of the media environment,\" and has been much \nmore susceptible to \"disinformation, lies and half -truths.\" As for Fox News 's role \nin this, \"we found Fox News  accrediting and amplifying the excesses of the radical \nsites.\" (Benkler et al., 2018, p. 14) . \nThe right and the alt -right trade in fake memes, tropes or narratives, especially in \nan extreme form. This condition of embracing and seeking exaggerated tropes, \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n161 tropes, and conspiracy theories and narratives is similar to a distortion of a \nscenario disc ussed in S\u00f8ren Kierkegaard's notion of what faith's demands. In \nSickness unto Death (1849), God demands that Abraham sacrifice his beloved \nson, Isaac. Abraham not only sets out to obey but also does not even try to \nrationalize and explain himself to others , and only God's intermediary, an angel, \nstops him. For Kierkegaard, the act of faith entails following God's demands, as \nirrational as they may appear to be. Kierkegaard wonders what faith would be if it \ndemanded only something rational. The more irration al the demand, the greater \nthe demand of faith to follow through. This seems to be true of the addicted \nTrump supporters \u2014the greater his insane comments and demands, the greater the \nunflinching allegiance (e.g., science is a cultural war against one's indi vidual \nrights to refuse to wear a mask, unless your child gets a case of smallpox (anti -\nvaxxers not withstanding)).  Like Abraham's unflinching acceptance of God's \ndemands, consider the unflinching acceptance of conspiracy theories (conspiracy \ntheories seem  to thrive on an addiction to apophenia), such as the willing \nsuspension of disbelief that was required to swallow one of the early conspiracy \ntheories called Pizzagate. It was conspiracy theory espoused by the alt -right, \nparticularly through Alex Jones, t he host of InfoWars, that Hillary Clinton was \nsexually abusing children in the basement of a pizza shop, Comet Ping Pong, in \nWashington, DC. On December 4, 2016, based on his embrace of the Alex Jones' \nnarrative (along with an anti -Democratic bias and othe r cognitive biases), Edgar \nMadison Welch, of Salisbury, NC, walked through the front door of the \nrestaurant, pointed an assault rifle in the direction of an employee and fired \n(Robb, 2020). Fortunately, no one was hurt, but the narrative was so compelling \nto Welch that checking the facts did not occur to him (e.g., the restaurant had no \nbasement). What is disturbing is his unflinching acceptance of the narrative, his \nemotional triggers having become supersensitive. Another case was the \nconspiracy theories a bout the cause of the horrendous fires in Oregon and \nCalifornia in the summer of 2020. The conspiracy theory was that members of \nAntifa (Anti -Fascists, started initially been to fight racism but expanded to include \nother extremists (Antifa, 2020)) set the fires. When homeowners were asked to \nleave their homes for safety reasons, they refused, arguing that they needed to \nprotect their homes from the roaming gangs of Antifa (Healy & Baker, 2020). It \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n162 was a false rumor most likely set by the alt -right trying to  help Trump's reelection \ncampaign. Their \"faith\" in Trump is another form of sickness unto death, sickness \nbuilt on an ill -conceived, propagandized self -righteousness that supports a faux \npatriotism and misguided interpretation of the Constitution, the sep aration of \npowers, and the nature of American democracy. The difference between \nKierkegaard's sickness unto death and theirs was that his goal was redemption, \nwhile theirs is willful ignorance that pretends it is not willful, an addiction to \nsome Gnostic g ospel that is supposedly the subtext of all political reality.  \nWhat has changed the name of the game are the attention merchants who design \nthe gimmicks, ploys or widgets to capture our attention, in Google, Facebook and \nother social media.  It is often les s a matter of what is left or right but what grabs \nour attention, politically, socially, commercially, etc. With that in mind, another \nway of characterizing the current age is the Age of Surveillance Capitalism.  \n4. Age of Surveillance Capitalism  \nWonderful in sight about this topic is found in Netflix's documentary, The Social \nDilemma  (Orlowski, 2020).  The following commentary summarizes some of its \nthemes.  It should be no surprise the silicon valley tech companies, primarily \nFacebook, Apple and Google, can and  do keep track of everything that anyone \ndoes online \u2013 what sites one visits and for how long, what images one looks at and \nfor how long, what things one buys or are interested in, what friends one has, what \n\"likes\" (or its variations) one posts, who one p hototags or is phototagged by, what \nengagement one has with what sites (how one navigates through a site, how long \none stays on pages or subpages, what interactions one engages in, such as posting \na comment, giving one's email address, engaging in a poll, clicking through links, \netc. (all known as engagements).  These are all fed into a profile that slowly builds \nover time, never disappears, and is continuously updated and refined.  It is like \ntaking every news story and changing it for where and who one is r eading it, \nmaking the content of a news entry vary for each and every person.  This is what is \nhappening on Facebook.  One gets a different answers and different \nadvertisements for where and who one is, built on one's profile so that if one asks \nabout climat e change, the person next to you in the lab or a Facebook friend will \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n163 get a different answer.  One might be told that it is a hoax or that it is not man -\nmade, and somebody else will be presented with an opposite view.  As one \nobserver said in The Social Dile mma , citing a lack of social responsibility of these \nsoftware developers and companies, a disinformation -for-profit model. It can \ninvolve shaming by suggesting that one is not living up to norms (that is, the \nnorms of a typical white male's version of soci ety (i.e., that of the software \ndeveloper).  In an engaging webinar, \"Your Online Data & Algorithmic Bias: How \nit Affects You Every Day - Virtual Roundtable Discussion\" (November 12, 2020), \n(https://umdischool.activehosted.com/index.php?action=social&chash=bbcbff5c1f\n1ded46c25d28119a85c6c2.470 ) panelist Dr. Jen Golbeck presented a personal \nstory. While she is married, she made a conscious dec ision not to have children.  \nAs she approached 40 years old, her social media feeds were filled with \nsolicitations about freezing her eggs.  After all, she was a woman and who would \nabrogate the norms that the job of a woman, especially a married woman, was to \nhave a baby?  Another panelist, Dr. Nicol Turner -Lee, a sociologist researcher, \ndiscussed how software algorithms were racist and discriminatory in what \nopportunities are made to what individuals, based on perceived (or assumed) \nincome level and social b ackground, derived from online profiling.  \nThis infinite, individual profiling is possible because of computers' enormous \ncomputational power, cheap and easily available storage, across and through \nworld -wide high -speed networks.  It will not only predict on e's behavior but also it \nwill slowly begin to control one's behavior through psychological mechanisms.  \nThe purpose of attention merchants is not only to engage your attention but also to \npromote addiction to technologies, sites and apps.  For the surveillan ce capitalists, \nthere are three goals:  the engagement goal (keep the person engaged and wanting \nto return to a site), the growth goal (get the users to get others to join), and the \nadvertising goal (to market and sell products) (Orlowski, 2020).  These goal s are \ndriven by the desire to make money by attracting one's attention (which makes \nmoney from advertisers) or attracting one's consumption of products, goods and \nservices.  The problem is that there are no constraints on their money -making, \ndespite its man y damaging effects, such as adolescents cutting themselves or \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n164 committing suicide for a lack of getting enough \"likes\" in Facebook and other \napps.   \nThe Social Dilemma  ironically notes that even the people who developed the \naddicting software fell prey to th e software, even knowing what was behind it.  To \none, the addiction was Twitter, to another email, to another Facebook.  The \naddiction is based on positive intermittent reinforcement (adding a reward, such as \nfinancial gain, in order to invoke a response).  Like a gambling addict at a slot \nmachine, when the last lever pull of the \"one -arm bandit\" did not succeed in a \nwinning row, it entices the next lever pull by occasionally offering a win.  Human \nvulnerabilities in psychology are exploited for monetary advant age, without \nregard to harmful effects.  For example, every time you binge -watch a movie on \nNetflix or Amazon Prime (itself possibly an addiction), you are offered the reward \nof another movie similar to the one just seen so that one can binge on binge -\nwatch ing. \nMany mostly ex -software developers or marketers for the big three, Apple, \nFacebook, and Google, have raised alarms about manipulative software.  One is \nTristan Harris, who began to discuss these problems in a 2016 Atlantic article, \n\"The Binge Breaker\" (Bosker, 2016), in which he discusses the process of \naddiction to smartphones.  He has worked on a lot of projects promoting ethical \noptions in software (such as, instead of a sound or vibration to attract attention \nwhen one gets an email, to keep the phone  silent to prevent constant interruptions \nso that one can stay focused on the project at hand).  One of the stars of The Social \nDilemma , he currently is the president and co -founder of a Center for Humane \nTechnology.  Another voice for an ethical response to  software applications is \nJaron Lanier.  Some of the arguments that Jaron Lanier has posed in Ten \nArguments for Deleting Your Social Media Accounts Right Now are that it robs \none of one's free will, social media is undermining the truth (both by the \nexploit ation of psychological weaknesses), it makes what one says meaningless \n(by leveling all forms of cognition), it turns one into a jerk (by squandering one's \ntime seeking vapid methods for approval, like \"thumbs up\" or hearts on social \nmedia sites).  Anna Lem ke claims that social media is a drug (Orlowski, 2020).  \nAccording to the Newport Academy, a rehabilitation center for adolescents and \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n165 their families struggling with mental health issues, eating disorders, and substance \nabuse, The Social Dilemma  provides fo ur adverse effects of social media on \nteenagers: (1) persuasive technology \u2013 their generated profiles leads \"to persuade \nthem to keep scrolling longer, so they will view more ads, invite more friends, and \ngenerate more money for the platforms and their adv ertisers\"; (2) fake popularity \n\u2013 teenagers place great value on such short -term rewards as hearts, likes, \"thumbs \nup,\" but when they don't get them they feel \"even more vacant and empty\" than \nbefore, citing Chamath Palihapitiya, Facebook's former VP of gro wth, in the film; \n(3) snapshot dysmorphia  -- teenagers, especially girls, develop poor body images, \nas a result of the unrealistic standards for beauty depicted in social media, which \nmay lead to cutting themselves or suicide; and (4) digital pacifier \u2013 there is \ngrowing evidence that teenagers (and adults) \"have lost the ability to calm and \nsoothe themselves with real -world reflection, activities, and relationships. Instead, \nthey deal with challenging emotions by turning to social media for distraction and \nentertainment\" (Monroe, 2020).  Perhaps more problematic is the use of \"digital \npacifiers\" shoved in front of children to occupy them to prevent them from being \nbored or crying, so that they learn to avoid developing any interior life, \ncontinuously external izing their needs and wants.  One suspects that some crying \nhas moral benefits for children.  \nThe \"Age of Surveillance Capitalism\" was articulated and developed by Shoshana \nZuboff, the Charles Edward Wilson Professor Emerita at Harvard Business \nSchool, in The Age of Surveillance Capitalism.  She defines surveillance \ncapitalism as:  \n1. A new economic order that claims human experience as free raw material \nfor hidden commercial practices of extraction, prediction, and sales;  2. A \nparasitic economic logic in which  the production of goods and services is \nsubordinated to a new global architecture of behavioral modification; 3. A \nrogue mutation of capitalism marked by concentrations of wealth, \nknowledge, and power unprecedented in human history; 4. The foundational \nframework of a surveillance economy; 5. As significant a threat to human \nnature in the twenty -first century as industrial capitalism was to the natural \nworld in the nineteenth and twentieth; 6. The origin of a new instrumentarian \npower that asserts dominance  over society and presents startling challenges \nto market democracy; 7. A movement that aims to impose a new collective \norder based on total certainty; 8. An expropriation of critical human rights \nthat is best understood as a coup from above: an overthrow of the people's \nsovereignty. (Zuboff, 2020, preface).  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n166 Given the context discussed above, she believes that human beings' experiences \nare commodities that are and will be manipulated by international tech companies \nfor exploitation and profit, overthrowing democracy.  It is a bleak portrait, but \ngiven the current trends in psychological manipulation with no impetus to stop it, \nit does represent a possible and frightening future, where the whole world \nbecomes Plato's Cave.  \nMany unresearched adverse effects of social media and digital technologies are \nthrown upon the world because it makes money without concern about the long -\nrange, not to mention the immediate impact, of those technologies.  One of the \nmost destructive phenomena is the algorithm that drives YouT ube. YouTube \nengages a rabbit hole phenomenon that increases right -wing radical viewership.  \nWhen perusing YouTube videos for certain content, such as a specific conspiracy \ntheory, the site's algorithm suggests more provocative videos to view, which in \nturn offers more provocative videos to view. The impact is to advance Google's \nprofits, with dire political consequences. Sociologist and information and library \nscience professor Zeynep Tufekci declared YouTube to be \"one of the most \nradicalizing instruments of the 21st century\" because of these mechanisms \n(Tufekci, 2018).  According to the analysis of New York Times columnists Max \nFisher and Amanda Taum, Brazil's ultra -right president Jair Bolsonaro owes his \nelectoral success primarily to YouTube videos (Fishe r & Taub, 2019).  With such \nalgorithmic features that inflame one's political grievances, it is easy to see \nanother possibility for describing the underbelly of the Age of Information as the \nAge of Inflamed Grievances.  \n5. The Age of Inflamed Grievances  \nIn the United States at the moment, there are two areas in which one's grievances \nare primarily inflamed politically: cable news shows such as Fox News described \nearlier and in social media.  Take Fox News  as the first example.  \nFox News  starts with or instills a m aelstrom of grievances, resentments, a sense of \ninvisibility or a lack of importance of its viewers. The wider culture often \nchallenges many of their core values (e.g., white male dominance).  It then tells \nthose viewers what they want to hear, consciously or unconsciously, with claims \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n167 supporting and fulfilling their cognitive biases and real, instilled or professed \nideology.  For example, they may think of themselves as conservatives, without \nhaving much depth about its meaning, except maintaining things as they were \n(e.g., white male dominance in society).  Fox News  (pseudoangelia) will then \nshape and enlarge that image with anti -liberal, anti -labor, pro -business, pro -\naverage -joe narratives.  \nThese messages are myths, tropes, and narratives (pseudoangelos), of ten detailed \nthrough the shows of their various pundits. They include persistent myths about \nantifa conspiracies, fast fixes or lies about the coronavirus epidemic or the \nextraordinary leadership of Trump.  They echo the view that God rewards those \nwho work  hard and other variations of the Protestant work ethic, implying that \nthose who are poor or disadvantaged have not worked hard enough and deserve \ntheir circumstances. It presents white privilege as the natural way of things and \nracism as a thing of the pa st. Kneeling during the national anthem is an insult to \nthe flag or to the country. It satirizes the mass media as pushing values that are \nun-American. It claims that restrictions on gun ownership are an assault on \nfundamental human rights and the Constitu tion. It mirrors and accentuates the lies \non radical right -wing websites, such as Breitbart (Benkler et al., 2018, p. 14). The \nemotional triggers that it fosters are legion, not to say they are real, only that they \nwork.  \nThey engage in \"motivated reasoning ,\" especially when the topic at hand is \nsomething that promotes or inflames their cause.  It is the effect of emotions that \nwe associate with a given topic at a primal level.  It is not really reasoning but \nrationalization, making our arguments fit a pre -determined end.  Not only does it \ninvolve a confirmation bias but also, as noted earlier, a \"disconfirmation bias\" \"in \nwhich we expend disproportionate energy trying to debunk or refute views and \narguments that we find uncongenial.\" (Mooney, 2011).  When they g rab onto what \nappears to be scientific evidence that supports their bias, they pounce on it.  When \none \"scientist\" proclaims that climate change is a hoax, they are featured on Fox \nNews  and the overwhelming majority of scientists are ignored, if not mocked.  \nThese arguments from motivated reasoning or memes, myth, tropes and narratives \nare reinforced and repeated throughout the disinformation -misinformation \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n168 ecosystem to the point of addiction where viewers' self -deception dialectically \nreinforces and is reinf orced by the social and collective self -deception of others \nand selective events in the disinformation -misinformation ecosystem.  This \ndisinformation -misinformation ecosystem is a filter bubble or \"propaganda \nfeedback loop.\" (Benkler et al., 2018, p. 33).  Morrison (2018) suggests that right -\nwing media keep over a quarter of Americans siloed in this \"propaganda feedback \nloop.\" Because Fox News  promotes relentless moral outrage, viewers are prone to \nbelieve irrational or unfounded claims or assertions and rega rd all other venues as \nfake news.  This moral outrage is reflected in the actions of the viewers taken into \nthe market place, such as the refusal to wear masks for the coronavirus pandemic \nor the urgency to call the police when any Black person they imagine  is \nthreatening to them. It is not that Fox News alone does this \u2013 so do some social \nmedia sites \u2013 but it is a major factor given its degree of influence that we have \noutlined earlier. Fox News  claims to base its stories on evidence and facts.  At best, \nwhen they actually use facts, their interpretation of these facts is often distorted, \nmanipulated, misleading or missing.   \nIt claims to the trustworthy \u2013 it is only trustworthy in that it reinforces and stokes \nbias. It claims to have journalistic integrity.  It is not journalistic integrity when \nyou make the narrative about the facts or the omission of facts fit your political \nbias or when you originate a narrative based on a conspiracy theory of a radical \nright -wing social media site. (Benkler et al., 2018, p.  14). It claims to have \nexpertise, but its expertise is sophistry, because they are interested in political \npower and influence and economic rewards  -- as noted earlier, they make nearly 2 \nbillion dollars a year (Stelter, 2020, p. 20), getting partisans ad dicted to Fox News.  \nThe repetition of  Fox News \u2019s messages through social media and other personal \nand social interactions reinforces and socializes the self -deception. Fox News  (as a \npseudoangelia) exists as a significant component of a disinformation -\nmisinformation ecology composed of like -minded peers, friends, associates, \nreligious leaders, politicians, and pundits which foster, nurture and reinforce one's \ngrievances through memes, narratives, tropes and stories (pseudoangelos).  It is a \nmajor component o f a \"propaganda feedback loop,\" where each part reinforces \nand inflames the others, through multiple channels (Cable news, social media, \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n169 group associations, party rallies, word -of-mouth, etc.), all of them echoing each \nother. Fox News  relies for its author ity on a self -reinforcing dialectical process \nwhere each part reinforces the other and rejects discordant information.  Despite \nall the lies, distortions and misinformation, Fox News has a robust approval rating \nat 43% and a steady 63% among Republicans and  Republican leaning \nindependents (Gramlich, 2020).  The right -wing mania awash with all sorts of \nfalse information is not mirrored in the center or on the right, as noted above by \nBenkler (Benkler et al, 2018, p. 14).   \nRegardless of topic, Fox News  commenta tors are supposed to stoke rage and push \nthe emotional buttons of their viewers. Tobin Smith, a former Fox News  \ncommentator, suggests that their programming fosters an addictive and \nresentment -based process to:  \n[1] Understand the elderly white conservative  viewer's pre -tribal mindset, \nwhich is a compilation of their resentments, indignations, cultural values, \nreligious values, political values, racial perspectives, regional outlooks, and \nworldviews.  \n[2] Scare or outrage the crap out of viewers by boring dow n on a recently \nexposed tribal nerve like a psychic dentist with a drill, presenting hearsay or \nan innately scary image of non -white/non -Christian foreigners, immigrants, \nor terrorists doing horrible things.  \n[3] Produce each seven -minute rigged outcome opi nion-debate segment \naround the carefully selected partisan hearsay such that the \"fair and \nbalanced\" debate is massively rigged for the conservative pundits on the \nprogram to . . .  \n[4] Deliver the climactic and righteous rhetorical victory for the partisa n \nright -wing viewer to trigger the jolt of dopamine and serotonin that the \naddict anticipated and knew was coming. (Smith, 2019, pp. 485 \u2013486).  \nIn other words, Smith argues that Fox News programming fosters an addictive \nprocess, based in addictive fear, ang er and/or resentment, that is played and \nreplayed over and over again, and validated by a chosen -in-bad-faith, restrictive \nenvironment (i.e., their filter bubble) in which Fox News  viewers live and dwell \n(i.e., peers, friends, political associates, religio us affiliates, social media sources, \netc., that reinforce their confirmation and disconfirmation biases).  \nAccording to Eric Wemple, the influence of Fox News  cannot be underestimated.  \nThere's simply no outlet that dominates any other part of the political  \nspectrum in the way Fox News  dominates the right. With that dominance, \nFox News has done great damage. It's not as if Fox News 's influence extends \nto only however many millions may be viewing in prime time. There's what \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n170 experts call a \"media ecosystem\" ou t there, where people take nonsense \nuttered on Fox News , then share it on Twitter, on Facebook, with their \nneighbor. Nonsense has a high pass around rate. (Wemple, 2019)  \nThe dominance of Fox News  recalls the dominance of government -controlled \nnews in autho ritarian countries, from the Third Reich to modern -day Russia and \nChina. In other countries control is through some government -run propaganda \nagency, but in Trump's world, the enslavement to one's biases is self -imposed by \nfostering addiction and inflating  biases or resentments. Fox News  viewers have no \ndesire to escape it (nor right -wing social media sites), as its system of self -\nreinforcing self -deception \u2014individual, social, and collective \u2014is more robust than \npast generators of propaganda could ever conce ive. Tobin Smith, refers to the \nconsumption of Fox News as addiction to \"tribal partisan identity porn,\" based on \ncultural and political resentments that \"trigger feelings of hate, anger and \noutrage \u2014the addictive trifecta of tribal partisan pornography\" (S mith, 2019, p. \n459).  \nSocial media sites can also act as cognitive authorities or pseudo -cognitive \nauthorities (pseudoangelia).  The problem with the internet is that is a self -serve \n\"information\" bank.  Using Google or some social media sites like \nmediabiasf actcheck.com, one can often find legitimate information. For many on \nthe right, right -wing social media (e.g., Breitbart, Truthfeed, Infowars, Gateway \nPundit, Zero Hedge, QAnon) is a self -serve disinformation or misinformation \nbank. It is not quite self -serve because the self that is served is one that enprisons \none\u2019s biases.  Right -wing ideologues, foreign agents and click -bait entrepreneurs \n(all pseudoangelia) produce a deluge of disinformation of memes and narratives \n(pseudoangelos) to solicit (at a minim um) and inflame (at a maximum) the \ndisinformation seeker at these sites.  Self-serve engagement is mediated by \ncognitive bias, confirmation bias, and steerage to selective sources.  Generally, \nthere are little restrictions on the kind of content that is made  available.  \nConservatives are more susceptible to clickbait than liberals, more likely to fall \nfor fake news. (Ingraham, 2019).  Beyond specific right -wing media sources, as \npolitical commentator and professor Robert Reich argued in the  Guardian , \nFacebook a nd Twitter are alarmingly influential. As he wrote:  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n171 The reason 45% of Americans rely on Facebook for news and Trump's \ntweets reach 66 million is because these platforms are near monopolies, \ndominating the information marketplace. No TV network, cable gian t or \nnewspaper even comes close. Fox News'  viewership rarely exceeds 3 \nmillion. The New York Times  has 4.7 million subscribers.  \nFacebook and Twitter aren't just participants in the information marketplace. \nThey're quickly  becoming  the information marketpla ce. (Reich, 2019).  \nOne of the most problematic aspects of social media are the number of hate \ngroups and the far -right partisans that use it to attract followers and disseminate \ntheir propaganda. A report of \"Hate in America,\" a project produced by the \nCarnegie -Knight News21 initiative, did a study of far -right users of Facebook, \nTwitter, Gab, VK, and others during a two -week period in June 2018.  They \ntracked more than 3 million followers and compiled more than 2,500 posts from \nthese platforms that threaten ed harm against Black Americans, Latinos, Jews, and \nLGBTQ+ people.  These posts got over a half -million likes and were shared \n200,000 times.  This evidence shows the strength and breadth of these groups, who \ngain power by assembling a collective voice, despi te some platforms' restrictions \n(Gardner, 2018). What poses an additional threat is the spread and speed of \ndisinformation and the inflammation of emotional triggers (memes, tropes).  MIT \nresearchers Soroush Vosoughi, Deb Roy, and Sinan Aral (2018) found in  a study \nof rumor cascades from 2006 to 2017 that false information spreads more quickly \nand broadly than truthful information and that those on the right are more \nsusceptible and more prone to disseminate false information than those on the left.   \nIt is s imply wrong to believe that Facebook as a whole is balanced or neutral and \nhas no particular bias.  The Economist  did a study on Facebook using \nCrowdTangle, a Facebook tool that tracks how web material is shared across \nsocial media.  They discovered that in August, 2020, the two most popular sites \nwere Fox News  and Breitbart measured by user engagements \u2013 shares, views, \ncomments and other activities.  They concluded that  \nwhatever Facebook's intentions, the social -networking site has more of a \npolitical slant t han Mr. Zuckerberg lets on. Using CrowdTangle, we \ncompiled a list of the media outlets that received the most Facebook \nengagement in August. We then examined the top 35 for which data on their \npolitical biases were available from Ad Fontes Media, a media -watchdog \norganisation. All told, these sites received an average of 8.7m engagements \nin August. Fox News topped the list with 56.4m interactions in the month; \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n172 MSNBC, a rival cable -news network, received just 9.7m  (Facebook. . ., \n2020).  \nObviously, it is nic e to think that the truth will always win out. But in the Age of \nDisinformation, this approach seems too simplistic. Thus, we must ask, is there a \nlimit to free expression when that expression leads to harmful acts to demonized \npopulations, the destruction  of trust in political, governmental and media \ninstitutions, the loss of expertise, and the denigration of science and evidence?   \nRobert Reich (Reich, 2019) argues that two actions need to occur to bring rational \ncontrol back to the internet.  First, there should be some anti -trust action that \nwould break up the large providers, such as Facebook and Twitter.  He argues that \nthey have a too broad and monolithic influence.  Second, we must prevent such \nproviders from pretending to be neutral providers of informa tion for which they \nhave no responsibility. They must develop policies to constrain lies and \ndisinformation at a minimum.  \nIn sum, we have a diversity of sites on the internet and there are places where one \ncan obtain reliable information.  There are many si tes where the opposite is true.  \nFox News and alt -right social media sites are two of the major factors that have \ncontributed to the uncivil discourse in American society, the undermining of \nAmerican democracy and democratic institutions, the decline in law  and order, an \nanti-science, anti -humanistic agenda, and the hypersensitivity to presumed threats \nto one's rights and ideology.  These are sites that can serve to inflame one's biases, \nwhich one's proclivities and social media can solicit and inflame one's fear, anger \nand self -righteousness, particularly on the right.  It is naive to think that users can \nsort out misinformation or disinformation by themselves: many lack the skills to \nevaluate information critically or to assess who are proper cognitive author ities, or \nthey fall prey to the Dunning Kruger effect by being unable to recognize the limits \nof their perceptions, much like Plato's Cave dwellers.  The problem is that they are \nenslaved in their biases and so heavy doses of information, media and digital \nliteracies are not likely to reach into their filter bubble or closed propaganda loop.  \nIf we had a choice to describe which Age was the best to describe the underbelly \nof the Age of Information, the last two, the Age of Surveillance Capitalism and \nthe Age of Inflamed Grievances are the most potent, for until their issues are \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n173 addressed we are surely destined to self -destruct, as a democracy, as a country, as \na world and as a planet.  \nBibliography  \nAristotle. (2020). Rhetoric  (W. R. Ro berts, Trans.). d igireads. com. \nBenkler, Y., Faris, R., Roberts, H. (2018). Network propaganda: manipulation, \ndisinformation, and radicalization in American politics . Oxford, UK: \nOxford University Press.  \nBosker, B. (2017). What Will Break People's Addictions to Their Phones? The \nAtlantic . https://www.theatlantic.com/magazine/archive/2016/11/the -\nbinge -breaker/501122/ . (Retrieved November 13, 2020 ) \nBump, P. (2020 ). The stunning extent to whic h Trumpism is centered among Fox \nNews -watching Republicans. Washington Post . \nhttps://www.washingtonpost.com/po litics/2020/10/19/stunning -extent -\nwhich -trumpism -is-centered -among -fox-news -watching -republicans/ . \n(Retrieved November 13, 2020)  \nCapurro, Rafael.  (2020). Pseudangelia \u2014 Pseudangelos: On False Messages and \nMessengers in Ancient Greece.  Informatio , 25(1):106-131. DOI: \n10.35643/Info.25.1.5. \nhttps://informatio.fic.edu.uy/index.php/informatio/article/view/246/249 . \n(Retrieved November 14, 2020 ) \nChittister, J. (2020 ). Land of the free, home of the self -centered. National \nCatholic Reporter Online . \nhttps://www.ncronline.org/news/coronavirus/where -i-stand/land -free-\nhome -self-center ed. (Retrieved November 14, 2020 ) \nCollins, B. (2017). Trump fans, foiled by google translate, believe 'covfefe' was a \nsecret arabic message. The Daily Beast.  \nhttps://www.thedailybeast.com/trump -fans-foiled -by-google -translate -\nbelieve -covfefe -was-a-secret -arabic -message . (Retrieved August 26, 2020 ) \nFacebook offers a distorte d view of American news. (2020 ). The Economist . \nhttps://www.economist.com/graphic -detail/2020/09/10/facebook -offers -a-\ndistorted -view -of-american -news?utm_campaign=t he-economist -today . \n(Retrieved September 14, 2020)  \nFisher, M., Taub, A. (2019). How YouTube radicalized Brazil. New York Times . \n(Retrieved August 29, 2019)  \nhttps://www.ny times.com/2019/08/11/world/americas/youtube -brazil.html .  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n174 Froehlich, T. J. (2017). A not -so-brief account of current information ethics: the \nethics of ignorance, missing information, misinformation, disinformation \nand other forms of deception or incompete nce. BiD: textos universitaris de \nbiblioteconomia i documentaci\u00f3 , 39. http://bid.ub.edu/en/39/froehlich.htm  \ndoi: http://dx.doi.org/10.1344/BiD2017.3 9.8 . (Retrieved March 4, 2019)  \nFroehlich, T. J. (2019). The role of pseudo -cognitive authorities and self -\ndeception in the dissemination of fake news. Open Information Science , \n3(1):115\u2013136. https://d oi.org/10.1515/opis -2019 -0009  .  \nFroehlich, T. J. (2020). Ten lessons for the age of disinformati on. In: K. Dalkir \nand R. Katz (E ds). Navigating Fake News, Alternative Facts and \nMisinformation in a Post -Truth World . IGI Global  (pp. 36 -88). \nhttps://www.igi -global.com/gateway/chapter/full -text-pdf/249503 . \nFroehlich, T. J. (in press). A disinformation -misinformation ecology: The case of \nTrump. In:  Fake News Is Bad News - Hoaxes, H alf-truths and the Nature \nof Today's Journalism . IntechOpen.  \nGardner, K. (2018). Social media: Where voices of hate find a place to preach. \nThe Center for Public Integrity . https://publicintegrity.org/politics/social -\nmedia -where -voices -of-hate-find-a-place -to-preach/ . (Retrieved September \n03, 2020)  \nGramlich, J. (2020). 5 facts about Fox News. Pew Research Center . \nhttps://www.pewresearch.org/fact -tank/2020/04/08/five -facts -about -fox-\nnews/ . (Retrieved August 25, 2020)  \nGrothaus, M. (2018 ). QAnon's \"codes\" are probably just random typing, says \nresearcher. Fast Co mpany . \nhttps://www.fastcompany.com/90219187/qanons -codes -are-probably -just-\nrandom -typing -says-researcher  . (Retrieved August 27, 2020)  \nHarvey,  J. (2020, September 10). Lou Dobbs claims Trump 'had a great day.' \ncritics say he's 'delusional.' Huffpost . https://www.huffpost.com/entry/lou -\ndobbs -trump -great-day_n_5f59a1cac5b62874bc182e18 . (Retrieved \nSeptember 12, 2020)  \nHealy, J., & Baker, M. (2020). In Oregon, a year of political tumult extends to \ndevastating wildfires. The New York Times . \nhttps://www.nytimes.com/2020/09/11/us/fires -oregon -antifa -rumors.html . \n(Retrieved September 15, 2020)  \nHeidegger, M. (2010).  Being and Time (Stambaugh, J., Trans.). State University \nof New York Press. (Original work published: 1927).  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n175 Ingraham, C. (2019, April 29). Why conservatives might be more likely to fall for \nfake news. The Washington Post . Retrieved October 26, 2019, from \nhttps://www.washingtonpost.com/news/wonk/wp/2016/12/07/why -\nconservatives -might -be-more -likely -to-fall-for-fake-news/   \nKierkegaard, S. (2013). The Sickness Unto Death (W. Lowrie, Trans).  Wiseblood \nBooks. (Original work published: 1849 ). \nKing James Bible. (2017). King James Bible Online . \nhttps://www.kingjamesbibleonline.org/ .  \nLeTourneau, N. (2020, April 29). The Misinformation Being Used to Pressure Us \nInto Re -Opening the Economy. Washington Monthly . \nhttps://washingtonmonthly.com/2020/04/29/the -misinformation -being -\nused-to-pressure -us-into-re-opening -the-economy/ . (Retrieved November \n22, 2020)  \nMalik, N. (2020, November 11). Not every Trump voter is racist or misled. \nThere's a rational Trump voter too. The Correspondent.  \nhttps://thecorrespondent.com/790/not -every -trump -voter -is-racist -or-\nmisled -theres -a-rational -trump -voter -too/47019208940 -41e70894 . \n(Retrieved November 11, 2020)  \nMooney, C. (2011 ). The science of wh y we don't believe science. Mother Jones.  \nhttps://www.motherjones.com/politics/2011/04/denial -science-chris -\nmooney/?fbclid=IwAR0joSt0kxWLUlWut1AMYwn0xT3d_wEp9l79mhV\nySrs26pi3WvtbW3pyptk . (Retrieved August 22, 2020)  \nMonroe, J. (2020). What to Learn from 'The Social Dilemma'. Newport Academy.  \nhttps://www.newportacademy.com/resources/empowering -teens/social -\ndilemma/ . (Retrieved November 13, 2020 ) \nNichols, T. M. (2017). The death of expertise: The campaign against established \nknowledge and why it matters . New York, NY:  Oxford University Press.  \nOrlowski, J. (2020). The Social Dilemma . Drama, Documentary. Exposure Labs.  \nPlato. (2008). Collected works of Plato (B. Jowett, Trans.). Charleston, SC: \nBiblioBazaar.  \nPlato. (1987). Gorgias  (D. Zeyl, Trans.). Indianapolis, IN: Hac kett Publishing.  \nQiu, L. (2020, November 19). How Sidney Powell inaccurately cited Venezuela's \nelections as evidence of U.S. fraud. The New York Times . \nhttps://www.ny times.com/2020/11/19/technology/sidney -powell -\nvenezuela.html . (Retrieved November 22, 2020)  \nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n176 Reich, R. (2019, November 03). Facebook and Twitter spread Trump's lies \u2013 they \nmust be broken up. The Guardian.  \nhttps://www.theguardian.com/commentisfree/2019/nov/02/facebook -\ntwitter -donald -trump -lies. (Retrieved September 02, 2020 ) \nRieh, S.  Y. (2010). Credibility and cognitive a uthority of information. In: Bates  \nM. & Maack  M. N.  (Eds.) Encyclopedia of Library and Information \nSciences,  3rd Ed. (pp. 1337 \u20131344), New York: Taylor and Francis Group, \nLLC. http://hdl.handle.net/2027.42/106416 . (Retrieved August 18, 20 17) \nRobb, A. (2020, July 20). Anatomy of a fake news scandal. RollingStone.  \nhttps://www.rollingstone.com/feature/anatomy -of-a-fake-news -scandal -\n125877/ . (Retrieved September 15, 2020 ) \nSmith, T. (2019). Foxocracy: Inside the Network\u2019s Playbook of Tribal Warfare . \nNew York, NY: Diversion Books.  \nStanley -Becker, I. (2020, August 02). How the Trump campaign came to court \nQAnon, the online conspiracy movement identified by the FBI as a violent \nthreat. The Washington Post . \nhttps://www.washingtonpost.com/politics/how -the-trump -campaign -came -\nto-court -qanon -the-online -conspiracy -movement -identified -by-the-fbi-as-\na-violent -threat/2020/08/01/dd0ea9b4 -d1d4 -11ea -9038 -\naf089b63ac21_story.html . (Retrieved Augu st 22, 2020)  \nStelter, B. (2020). Hoax: Donald Trump, Fox News and The Dangerous \nDistortion of Truth . Atria Books.  \nSullivan, K. (2019, May 13). The Fox \"News\" lie: Fox's \"news\" side pushed \nmisinformation every day for four months straight. Media Matters  for \nAmerica . https://www.mediamatters.org/fox -news/fox -news -lie. \n(Retrieved August 26, 2020 ) \nTufekci, Z.  (2018, March 10).  YouTube, the great radicalizer. The New York \nTimes.  https://www.nytimes.com/2018/03/10/opinion/sunday/youtube -\npolitics -radical.html . (Retrieved August 29, 2019 ) \nVosoughi, S., Roy, D.  & Aral, S. (2018, March 9). The spread of true  and false \nnews online.  Science . 359(6380) :1146 -1151.  \nWemple, E. (2019, April 11). Yes, Fox News matters. A lot. The Washington \nPost.  https://www.washingtonpost.com/opinions/2019/04/11/yes -fox-\nnews -matters -lot/?noredirect&utm_term=.8ad57d66b52f . (Retrieved April \n14, 2019)  \nWijnberg, R. (2020, April 16). How the truth became whatever makes you click. \nThe Correspondent.  https://thecorrespondent.com/410/how -the-truth -\nInformatio  \n26(1), 202 1, pp. 132-177        ISSN: 2301 -1378  \n \n \n177 became -whatever -makes -you-click/9567807150 -326405ae . (Retrieved \nAugust 29, 2020)  \nWikipedia . (2020). Antifa . https://en.wikipedia.org/wiki/Antifa_(United_States) . \n(Retrieved November 11, 2020)  \nWilson, P.  (1983). Second -hand Knowledge: an Inquiry into Cognitive Authority.  \nWestport, CT: Greenwood P ress.  \nWolf, Z. (2020, October 09). A GOP senator has gone public against democracy. \nCNN Politics.  https://www.cnn.com/2020/10/09/politics/what -matters -\noctober -8/index .html . (Retrieved November 15, 2020 ) \n Wong, J.  C. (2020, August 11). Revealed: QAnon Facebook groups are growing \nat a rapid pace around the world. The Guardian.  \nhttps://www.theguardian.com/us -news/2020/aug/11/qanon -facebook -\ngroups -growing -conspiracy -theory . (Retrieved September 11, 2020)  \nZuboff, S. (2020). The age of surveillance capitalism: The fight for a human \nfuture at the new frontier of power.  New York: PublicAffairs.  \n \nAuthor\u2019s n otes \nParts of this paper were extracted from, adapted from or expanded from \n(Froehlich, 2017), (Froehlich, 2019), (Froehlich,  2020) or (Froehlich, n.d.)  \n \nAuthor contribution  \nThe entirety of this manuscript was prepared by Thomas J. Froehlich . \n \nEditor\u2019s n otes \nThe editor responsible for the publication of this article was Raf ael Capurro.  \nStyle editing and linguistic revisi on to the wording in this text  has been performed \nby Prof. Adj. Hugo E. Valanzano  (State University, Uruguay).  \nNilzete Ferreira Gomes (Universidade Federal Rural da Amaz\u00f5nia (UF RA), Par\u00e1, \nBrazil), was in charge of translating from Portuguese to Spanish.  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Philosophical Musings on the Underbelly of Information Age", "author": ["TJ Froehlich"], "pub_year": "2021", "venue": "Informatio. Revista del Instituto de Informaci\u00f3n \u2026", "abstract": "There is an underbelly of the Age of Information. Its opportunities and promises have been  diverted to dubious ends, manipulating the users of information technologies for economic"}, "filled": false, "gsrank": 153, "pub_url": "https://informatio.fic.edu.uy/index.php/informatio/article/view/313", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:1634Lb5AXoEJ:scholar.google.com/&output=cite&scirp=152&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D150%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=1634Lb5AXoEJ&ei=H7WsaJGVCJXUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:1634Lb5AXoEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://informatio.fic.edu.uy/index.php/informatio/article/download/313/334"}}]