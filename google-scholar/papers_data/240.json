[{"title": "Unbiased misinformation policies sanction conservatives more than liberals", "year": "2024", "pdf_data": "Unbiased misinformation policies  sanction conservatives more than liberals Mohsen Mosleh1,2, Qi Yang3, Tauhid Zaman4, Gordon Pennycook5,6, David G. Rand2,3,7\u01c2 1Management Department, University of Exeter Business School; 2Sloan School of Management, Massachusetts Institute of Technology; 3Institute for Data, Systems, and Society, Massachusetts Institute of Technology; 4Yale School of Management, Yale University; 5Hill/Levene Schools of Business, University of Regina; 6Department of Psychology, University of Regina, 7Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology \u01c2Corresponding Author: drand@mit.edu  In response to intense pressure from policy makers and the public, technology companies have enacted a range of policies aimed at reducing the spread of misinformation online1-3. The enforcement of these policies has, however, led to technology companies being regularly accused of political bias4-6. We argue that even under politically neutral anti-misinformation policies, such political asymmetries in enforcement should be expected, as there is a political asymmetry in the sharing of misinformation7-12. We support this argument with an analysis of Twitter data from 9,000 politically active users during the U.S. 2020 presidential election. While users on the political right were indeed substantially more likely to be suspended than those on the left, users on the right also shared far more links to low quality news sites \u2013 even when news quality was determined by politically-balanced groups of laypeople, or groups of only Republicans \u2013 and were estimated to have a far higher likelihood of being bots. We find similar associations between conservatism and low quality news sharing (based on both expert and politically-balanced layperson ratings) in seven other datasets of sharing from Twitter, Facebook, and survey experiments, spanning 2016 to 2023. These results demonstrate that political imbalance in enforcement need not imply bias, and should not dissuade technology companies from taking action against the spread of misinformation.   Mass communication is a central feature of modern life, with social media playing an increasingly important role in the global distribution and consumption of information13. These changes in the world\u2019s information ecosystem are being accompanied by a rapid co-evolution of technology, cultural norms, and public policy. Although social media companies are constrained by government regulations to some extent (e.g., the E.U.\u2019s General Data Protection Regulation), they set their own internal policies across a wide range of content. For example, platforms have largely had free reign over their content moderation policies and have developed their own institutions for managing such policies (e.g., the Facebook Oversight Board).   As a result of this freedom, social media companies have faced widespread charges of bias in the policies they have adopted. Some of the loudest such accusations have arisen in the context of concerns about disinformation, misinformation, and \u201cfake news\u201d. There is substantial public pressure on platforms to reduce the spread of inaccurate content. For example, both liberals and conservatives in the United States believe technology companies should take action against misinformation14,15, as do many people across European Union member countries16. Indeed, governments around the world have begun to regulate misinformation on social media17. In response, social media companies have implemented a wide range of anti-misinformation policies \nin recent years, such as removing or flagging posts deemed to be false by professional fact-checkers, using ranking algorithms to reduce the likelihood that users see potentially inaccurate posts, and suspending users who spread misinformation3.   These policies, however, have often led to social media companies being accused of political bias in their choices about who and what to take action against. In the United States, for example, it has been claimed that conservatives and Republicans are purposefully targeted for enforcement because of their political orientation (e.g., when Donald Trump said that Twitter \u201ctotally silences conservatives\u2019 voices\u201d4, or when Representative Jim Jordan charged that academics, social media platforms, and the government colluded to censor conservatives18. This view is shared by many Republican voters - for example, in an August 2020 poll, 69% of Republican respondents said major social media sites tend to favor liberals over conservatives, compared to only 25% of Democratic respondents6. Allegations of platform bias against conservatives have become an important part of the American political landscape, as such allegations are now regularly used in the rhetoric of Republican politicians5,6. Many social media companies are also very concerned about being perceived as having an anti-conservative bias19, and such concerns may sway the decision-making of such companies.   Given that the employees of social media companies \u2013 as well as the professional fact-checkers they partner with \u2013 are typically left-leaning (e.g., Ref 20), it is plausible that they may exhibit bias against conservatives when deciding what counts as misinformation or who to take action against.  At the same time, however, people can sometimes override intuitive biases through conscious effort21,22. Social media companies are surely keenly aware of the accusations of political bias made against them, and therefore may correct (or even over-correct) such biases. In other words, the fact that the employees at social media companies are largely liberal does not make it impossible for them to craft politically-neutral policies, or necessitate that their policies will exhibit anti-conservative bias. For example, there is evidence that the Twitter algorithm preferentially amplified posts by conservative politicians in numerous countries, including the United States, in 202023.  Here, we argue that making inferences about bias in anti-misinformation enforcement is particularly difficult because, if members of one party share more misinformation then members of the other party, reducing misinformation will be inexorably intertwined with appearing to have political bias. In the current historical moment in the United States, for example, although there is a bi-partisan desire for action against misinformation, there is considerable evidence of a partisan asymmetry in the sharing of misinformation. Studies have found that news from websites that journalists and fact-checkers deemed to be low-quality \u201cfake news\u201d sites were shared much more by conservatives than liberals on Facebook during the 2016 election10 and 2020 election24, and on Twitter during the 2016 election11 and Donald Trump\u2019s first impeachment25; conservatives on Twitter were much more likely to follow elites that made false claims than Democrats12; right-leaning images on Facebook were much more likely to be misleading than left-leaning images26 and survey experiments that present participants with politically balanced sets of headlines (removing the supply-side confound present in many observational studies) typically find that conservatives indicate higher sharing intentions for articles deemed to be false by professional fact-checkers than liberals7,8. Furthermore, this association is not limited to the U.S. For example, a survey experiment conducted in 16 countries found widespread cross-cultural evidence of \nconservatives sharing more COVID-19 misinformation than liberals9; and an examination of Twitter data found that political elites on the right shared links to lower quality news sites than political elites on the left in the United States, Germany, and the UK27. Of course, a natural objection to these prior results is that they rely on journalists and professional fact-checkers to evaluate content or sources, who may themselves have a liberal bias. Below, we present new data and re-analyses of existing data that show a similar pattern when using the evaluations of politically-balanced groups of laypeople, a process which cannot be accused of having liberal bias.  If there is indeed a political asymmetry in misinformation sharing, this means that politically neutral enforcement against misinformation by the platforms \u2013 aimed at satisfying the bipartisan demand for a reduction in online misinformation \u2013 could lead to political asymmetries in who faces sanctions. If misinformation is shared by conservatives more so than liberals, then suspending users who share falsehoods will lead even a politically-neutral set of enforcement policies to preferentially sanction conservatives.  Here, we shed new empirical light on this issue, taking a specific social media policy choice that has drawn intense criticism as a case study: Twitter\u2019s suspension of users following the 2020 U.S. Presidential Election. Specifically, in October 2020 we identified 100,000 Twitter users who shared hashtags related to the U.S. Presidential Election, and randomly sampled 4,500 of those users who shared at least one #VoteBidenHarris2020 hashtag and 4,500 who shared at least one #Trump2020 hashtag. We used each user\u2019s data from that pre-election time period to quantify their tendency to share low quality news (as well as numerous other potentially relevant characteristics), and then checked seven months later (after the election season) to determine which users got suspended by Twitter (for methodological details, see Supplementary Information; data and code available at https://osf.io/mrbsw). These data allow us to make several contributions to policy discussions around political bias and anti-misinformation efforts.   First, accusations of political bias are based largely on anecdotes or salient unique cases, such as the suspension of former President Donald Trump. Thus, it remains unclear whether conservatives are, in fact, generally more likely to get suspended than liberals. Our data do support this claim: Accounts that had shared the #Trump2020 hashtag during the election were 4.4 times more likely to have been subsequently suspended than those that shared the #VoteBidenHarris2020 hashtag (\ud835\uded82(1)=486.9, p<0.0001). Specifically, while only 4.5% of the users who shared Biden hashtags had been suspended as of July 2021, 19.6% of the users who shared Trump hashtags had been suspended.   Critically, however, this association does not necessarily indicate a causal effect of a user\u2019s politics on suspension \u2013 because of the potential for political orientation to be confounded with the tendency to share misinformation (or to engage in other sanctioned behaviors). Thus, we also examined how the political orientation of the users in our study related to their sharing of links to low quality news sites in October 2020.   As discussed above, prior studies examining the link between political orientation and misinformation sharing have relied exclusively on professional fact-checkers or journalists to determine news quality, which makes this work susceptible to criticisms of liberal bias in the evaluations. We address this issue by complementing four such sets of news site evaluations \ngenerated by experts28 with evaluations of 60 news sites (20 mainstream, 20 hyper-partisan, 20 fake news) generated using N=970 demographically representative (quota-sampled) American laypeople29. To generate these crowd ratings, each survey respondent indicated how much they trusted each of the 60 news outlets using a 5-point Likert scale. For each outlet, we then calculated politically balanced crowd ratings by calculating the average trust among Democrats and the average trust among Republicans, and then averaging those two average ratings. Thus, we gave the ratings of Democrats and Republicans equal weight when constructing our laypeople ratings, and as a result these laypeople ratings cannot reasonably be accused of having liberal bias. See SI Section 1.1 and Table S1 for details on the expert and crowd ratings used in our study.  We find that people in our dataset who used Trump hashtags shared news from domains that were on average rated as much less trustworthy than people who used Biden hashtags. Critically, this was true based on not only on the expert domain quality ratings (0.71 < r < .79 depending on rating set, p < .001 for all), but also based on the politically-balanced layperson ratings (r(8943) = .73, p < .001); see Figure 1. To contextualize the magnitude of this difference, we discretize our continuous quality ratings to classify each domain as low versus high quality (see SI Figure S1 for details), and find that the median Trump hashtag poster shared 4 times more low quality links compared to the median Biden hashtag poster.   Even when creating a purposefully right-biased quality measure by only using the trustworthiness ratings of Republican laypeople, we still find that people who used Trump hashtags shared news from much lower quality domains than people who used Biden hashtags (r(8943) = 0.54, p < .001; Figure S2). Beyond the use of Trump versus Biden hashtags, we also find high correlations between the measures of low-quality news sharing and various measures of ideology based on the Twitter accounts the users follow8 or the news sites that the users share11,30 (expert ratings, 0.73 < r < .88 depending on partisanship/ideology measure, p < .001 for all; politically-balanced layperson ratings, 0.73 < r < .82 depending on partisanship/ideology measure, p < .001 for all; Figure S2). Thus, in our study the politically active Twitter users on the political right shared information from much lower quality sites than the politically active Twitter users on the political left \u2013 even when quality was judged by a politically-balanced group of U.S. laypeople. This observation provides clear evidence for a political asymmetry in misinformation sharing in our dataset that cannot be attributed to liberal bias in what is considered misinformation or low quality news.    \n \n \n Figure 1. Social media users on the political right shared links to lower quality news sites than users on the political left. (A,B) Distribution of low quality news sharing scores across people who used the #VoteBidenHarris2020 hashtag versus the #Trump2020 hashtag in our sample of 9000 Twitter users, based on links shared as of October 2020. Scores are standardized (z-scored) for comparability; higher values indicate lower quality news sharing. Panel A users news site quality ratings given by eight professional fact-checkers; panel B uses news site quality ratings given by American laypeople recruited from Lucid, quota-matched to the national distribution on age, gender, education, and geographic region; ratings of Democratic respondents and Republican respondents were averaged to create politically-balanced layperson ratings. For details of the ratings, see SI Section 1.1 and Ref 29. (C) Top 5 most-shared news sites among the people in our sample who used Trump versus Biden hashtags, using list of news sites from Ref 29. (D) This pattern generalizes beyond Twitter users who shared political hashtags during the 2020 U.S. Presidential election. Shown is the correlation between conservatism and low quality information sharing across numerous datasets. For x-axis labels, the first row indicates the data source for low quality news sharing, the second row indicates the source from which the users were sampled, the third row indicates the year in which the data was collected, and the fourth row indicates the sample size. For details of each dataset, see SI Section 3. Error bars indicate 95% confidence intervals.  This political asymmetry in sharing low-quality information may therefore help to explain the apparent preferential suspension of right-leaning users. When we calculate the area-under-the-curve (AUC, which captures accuracy while accounting for differences in base rates and is a standard metric of model performance in fields such as machine learning31), the various measures of sharing low quality news predict suspension (0.68 < AUC < 0.72) to a similar degree as the various partisanship and ideology measures (0.67 < AUC < 0.71); Figure 2A. Thus, when examined independently, political orientation and sharing low quality news are similarly predictive of suspension.   \nShare by people who used Trump hashtag  Shared by people who used Biden hashtag News site # Shares  News site # Shares foxnews.com 50973  nytimes.com 33604 breitbart.com 47841  cnn.com 28488 nypost.com 38692  rawstory.com 20759 dailymail.co.uk 10719  cbsnews.com 6639 dailycaller.com 9968  usatoday.com 5715  \n\nWe also ask what happens when political orientation and sharing low quality news, along with numerous relevant control variables, are used simultaneously to predict suspension. To do so, we construct an aggregate measure of political orientation by taking the first component of a principal component analysis (PCA) of our four ideology/partisanship measures, and an aggregate measure of sharing low quality news by taking the first component of a PCA of our four expert news site quality measures. We then use probit regression to predict whether the user was suspended as of the end of July 2021, with p-values Holm\u2013Bonferroni corrected to adjust for multiple comparisons (see SI Section 1.2 for full list of control variables and SI Table S3 for regression tables). When doing so, the association between political orientation and suspension is not statistically significant (b = 0.12, z = 2.33, p = 0.14), whereas sharing low quality news is positively associated with suspension (b = 0.24, z = 5.18, p < 0.001), as are other problematic behaviors such as likelihood of being a bot (b = 0.20, z = 5.09, p < 0.001) and use of toxic language (b = 0.17, z = 6.58, p < 0.001); results are similar when using ridge (penalized) regression or logistic regression (see SI Table S3).  Of course, because of their correlational nature, these analyses do not allow us to definitively assess whether there was a causal effect of political orientation on Twitter suspensions during the 2020 election. Even if we had more precise measures of misinformation sharing (e.g., post-level instead of source-level, or real-time ratings instead of using pre-election tweets to prospectively predict as we do here), or were able to include additional features (e.g., harmful content that was deleted prior to API retrieval), our estimates could still be biased in either direction by additional omitted variables.   These data do, however, allow us to ask a more general question that has implications beyond just re-litigating the 2020 election cycle: What would we expect to happen if an entirely politically neutral anti-misinformation policy was implemented? To answer this question, we use simulations to examine which users would be suspended if suspension was based only on sharing links to low-quality news sites (and not at all on political orientation). That is, by construction we can remove any causal effect of political orientation, and then ask how much of a political asymmetry we nonetheless observe given politically neutral enforcement policies. To do so, we consider a range of suspension policies that differ in their harshness, where a given policy specifies the probability of a user getting suspended each time they share a link to a low quality news domain. For each policy, we can then calculate the average suspension probability of users estimated to be Democrats versus Republicans based on their use of hashtags. See SI Section 1.3 for details. \n \n Figure 2. Political orientation is not a unique predictor of getting suspended, and politically neutral enforcement policies will lead to political asymmetries in suspension rates. (A) When considered separately, political orientation and sharing low quality information are similarly predictive of suspension. Shown is area-under-the-curve (AUC, a standard measure of predictive accuracy) when predicting whether a user was suspended using models that take different features as the independent variable. Green bars indicate AUC for measures of political orientation (partisanship based on sharing of #VoteBidenHarris2020 versus #Trump2020 hashtags; ideology based on accounts followed, estimated using the model of Ref 32; ideology based on news sites shared, estimated using the model of Ref 30 or the model of Ref 11. Purple bars indicate AUC for measures of sharing links to low quality news sites based on ratings from Ad Fontes Media (AFM)33, Media Bias/Fact Check (MBFC)34,27, eight professional fact-checkers29, and 970 American laypeople weighting Democrats and Republicans equally29. Error bars indicate bootstrapped 95% confidence intervals. See SI Table S3 for results of regressions jointly considering political orientation, sharing low quality news links, and other controls. (B) Simulating a politically neutral anti-misinformation policy \u2013 in which there is a constant probability of getting suspended each time a user shares a link to a low quality news site, as judged by politically-balanced groups of laypeople \u2013 leads to disparate impact against users on the political right. Shown is the expected probability of suspension for policies which vary in their harshness (i.e., in the probability of getting suspended each time a user shares a low quality link); see SI Section 1.3 for details. (C) Simulating a politically neutral anti-bot policy, in which accounts below a given probability of being human are suspended, shows a similar partisan asymmetry; see SI Section 1.3 for details. 0.500.550.600.650.700.75\nHashtagSharedNewsSitesShared 1NewsSitesShared 2AccountsFollowedAFMRatingsMBFCRatingsLasserRatingsFact-CheckerRatingsLaypersonRatingsAUC when Predicting SuspensionPolitical OrientationLow Quality News Sharing\n\nUsing this approach, we find that suspending users for sharing links to news sites deemed to be untrustworthy by politically-balanced groups of laypeople leads to far higher rates of suspension for Republicans than Democrats (Figure 2B); findings are equivalent when basing suspension on expert assessments of news site quality, or when comparing suspension rates of liberals versus conservatives (see SI Section 2).   Beyond the sharing of misinformation or conspiracy theories often promoted by low quality news sites, conservatives in our dataset may also have been preferentially suspended for engaging in other sanctioned behaviors, such as engaging in calls for violence (e.g., in connection with the insurrection at the U.S. capital on January 6th 2021, which occurred during our study period), or for using bots. Indeed, as with sharing links to low-quality news sites, users on the political right had significantly higher estimated likelihoods of being a bot (0.70 < r < 0.76 depending on political orientation measure), and simulating suspension based on likelihood of being a bot leads to much higher suspension rates for Republican accounts than Democrat accounts (Figure 2C; see SI Section 1.3 for details). Importantly, the associations between political orientation and low quality news sharing are robust to controlling for bot scores, and to only examining users with low likelihood of being bots; see SI Section 2. Regardless of which prohibited behavior(s) are in operation, the same fundamental point applies \u2013 partisan asymmetries in behavior can lead to partisan asymmetries in suspension, even when suspension policies are politically neutral.   These analyses show that even in the absence of any (intentional) disparate treatment on the part of technology companies, partisan asymmetries in sanctioned behaviors will lead to (unintentional) disparate impact whereby conservatives are suspended at greater rates. From a legal perspective, political orientation is not a protected class in the United States, and thus neither form of disparate treatment is illegal (although potentially still normatively undesirable). While disparate impact may reasonably be considered to constitute discrimination in some cases (e.g., employment discrimination based on job-irrelevant factors that correlate with race), in the present context reducing the spread of misinformation and the prevalence of bots are legitimate and necessary goals for social media platforms. This makes a normative case for disparate impact based on political orientation.  Although we focused on Twitter suspensions and U.S. politics during the 2020 election cycle as a case study, the lessons learned from our analysis are relevant whenever there is an association between political orientation and misinformation sharing (or other sanctioned behaviors) \u2013 regardless of the specific platform or form of enforcement, or which political group is engaging in more sanctioned behavior. To provide evidence of the generality of the association between conservatism and political misinformation sharing demonstrated above, we analyzed 7 additional datasets. We consistently find that conservatives shared links to significantly lower quality news outlets than liberals when examining YouGov respondents\u2019 Facebook sharing in 2016, Prolific respondents\u2019 Twitter sharing in 2018 and 2020, and the sharing of Twitter users sampled in various ways in 2021, 2022, and 2023; see Figure 1D and SI Section 3. Thus, the results in our main analyses are not unique to highly politically active Twitter users during the election cycle. That being said, of course, it is important to keep in mind that people who share content on social media are not representative of the general public, and therefore the consistent pattern we observe here does not necessarily generalize to comparisons of the average liberal versus conservative or Democrat versus Republican. \n For reasons of tractability, our main analyses use domain-level quality ratings as a proxy for information quality (based on the premise that low quality news outlets are more likely to publish claims that are false or misleading). Importantly, however, additional analyses examining specific URLs deemed to be inaccurate by either professional fact-checkers or politically-balanced crowds also find that political misinformation is shared more by conservatives than liberals on Twitter (SI Section 4); and in a large-scale survey experiment examining sharing intentions of COVID-19 related claims across 16 countries, which presented claims without source attribution and controlled for potential exposure confounds (SI Section 5). Thus, our conclusions from domain-level approximations generalize to content-specific measurements of misinformation sharing. For a more detailed discussion regarding different ways of measuring misinformation sharing, see Box 1. Social media companies typically do enforcement based on the contents of specific problematic posts, rather than sanctioning users based on the domains they share. This post-level approach has the advantage of being much finer grained, as much of the content from low quality domains may not be problematic. Thus, enforcement using domain-level quality will lead to many false positives, where users are sanctioned for sharing content that is not misinformation. Conversely, post-level sanctions create an incentive for users to not post inaccurate or misleading content in particular. Relatedly, platform sanctions can be deployed at the level of the user (e.g. suspending users who post problematic content) or the post (e.g. attaching warning labels to posts flagged by fact-checkers35, and ranking algorithms \u2013 which generally favor content that generates engagement and thus may promote misinformation \u2013 can also be tools of anti-misinformation enforcement by downranking content that has been identified as inaccurate (or users who have previously posted inaccurate content).   Our findings have important implications in the context of regulation such as the Digital Services Act recently passed by the European Union, which requires platforms to take down content that involves misinformation. Our results suggest that when they comply, platforms are likely to face accusations of partisan bias. As such, that policymakers in the EU must accept that such patterns will likely arise from the actions they are requiring platforms to take, even if platforms comply in a political-neutral manner. Critically, technology companies should not be punished or accused of biased when they preferentially sanction groups who share more misinformation. Our results also suggest that using politically-balanced crowds to evaluate content36-38 may be a way to identify misinformation while ameliorating charges of political bias. Furthermore, increased transparency on the part of platforms regarding the characteristics (e.g., demographics) of users who are getting sanctioned, and why those sanctions are occurring, may help the public better understand how neutral policies can lead to the appearance of bias.  More broadly, the data presented here drive home the point that, if there are political asymmetries in misinformation sharing (in either direction), platforms face a fundamental tradeoff between reducing the spread of misinformation and being politically balanced in their enforcement. Regarding the specific asymmetry we document here, our data are agnostic regarding the extent to which conservatives share more misinformation because they are more inclined to do so, versus simply being exposed to more misinformation (e.g., because, at this particular cultural moment, conservative elites share more misinformation than liberal elites12,27). The key point of our piece, however, is not specific to this particular direction of association between political orientation and misinformation sharing \u2013 which could potentially change in the future, or for particular topics. \nAsymmetric enforcement could also occur outside the context of political orientation (e.g., if a particular demographic group is preferentially targeted with misinformation, they may share more of it and thus be sanctioned more frequently). If one political, social, or demographic group shares more misinformation \u2013 be it those on the right, the left, or some other group \u2013 it is not possible to be maximally effective in combatting misinformation without preferentially taking action against members of that group. Given the widespread (and bi-partisan) public demand for reducing misinformation online, policy makers must accept that some level of differential enforcement across groups is necessary if technology companies are to keep misinformation in check. The goal should be neutral policy design, not neutral enforcement \u2013 and concerns about asymmetric enforcement should not prevent technology companies from taking steps to reduce the spread of misinformation.  Data availability  All data necessary to reproduce the results are available at https://osf.io/mrbsw.  Code availability  All scripts necessary to reproduce the results are available at https://osf.io/mrbsw.  Acknowledgements  We are indebted to Andy Guess and Isaias Ghezae for assistance in our re-analysis of data from the papers on which they are lead authors.   Author Contribution   MM and DR designed the study, MM and QY collected the data, MM and DR analyzed the results, DR and GP wrote the paper within input from TZ and MM.  Competing Interest statement  Other work by MM, DR, and GP is funded by Meta and Google.  References  1 Kozyreva, A., Lewandowsky, S. & Hertwig, R. Citizens versus the internet: Confronting digital challenges with cognitive tools. Psychological Science in the Public Interest 21, 103-156 (2020).  2 Pennycook, G. & Rand, D. G. The psychology of fake news. Trends in cognitive sciences (2021).  3 Persily, N. & Tucker, J. A. Social Media and Democracy: The State of the Field, Prospects for Reform.  (Cambridge University Press, 2020). 4 Bond, S. Trump Accuses Social Media Of Anti-Conservative Bias After Twitter Marks His Tweets, 2020). 5 Wermund, B. Ted Cruz digs in for congressional battle over \u2018censorship\u2019 on Twitter, Facebook, <https://www.houstonchronicle.com/politics/texas/article/Ted-Cruz-digs-in-for-congressional-battle-over-15740624.php> (2020). 6 Vogels, E. A., Perrin, A. & Anderson, M. Most americans think social media sites censor political viewpoints. Pew Research Center 19 (2020).  \n7 Guay, B., Pennycook, G. & Rand, D. Examining Partisan Asymmetries in Fake News Sharing and the Efficacy of Accuracy Prompt Interventions.  (2022).  8 Pennycook, G. & Rand, D. G. Accuracy prompts are a replicable and generalizable approach for reducing the spread of misinformation. Nature communications 13, 1-12 (2022).  9 Arechar, A. A. et al. Understanding and reducing online misinformation across 16 countries on six continents.  (2022).  10 Guess, A., Nagler, J. & Tucker, J. Less than you think: Prevalence and predictors of fake news dissemination on Facebook. Science advances 5, eaau4586 (2019).  11 Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during the 2016 US presidential election. Science 363, 374-378 (2019).  12 Mosleh, M. & Rand, D. G. Measuring exposure to misinformation from political elites on Twitter. Nature Communications 13, 7144 (2022). https://doi.org/10.1038/s41467-022-34769-6 13 Mitchell, A., Jurkowitz, M., Oliphant, J. B. & Shearer, E. Americans who mainly get their news on social media are less engaged, less knowledgeable. Pew Research Center (2020).  14 Koopman , C. CGO Tech Poll. The Center for Growth and Oppurtunity at Utah State University (2021).  15 Atreja, S., Hemphill, L. & Resnick, P. Remove, Reduce, Inform: What Actions do People Want Social Media Platforms to Take on Potentially Misleading Content? arXiv preprint arXiv:2202.00799 (2023).  16 Flash Eurobarometer 464: Fake News and Disinformation Online v1.00. European Commission Directorate-General for Communication (2018).  17 A guide to anti-misinformation actions around the world. https://www.poynter.org/ifcn/anti-misinformation-actions/   18 Tollefson, J. Disinformation researchers under investigation: what's happening and why. Nature (2023).  19 Clayton, J. Social media: Is it really biased against US Republicans?, <https://www.bbc.co.uk/news/technology-54698186> (2020). 20 Bowden, J. Twitter CEO Jack Dorsey: I \u2018fully admit\u2019 our bias is \u2018more left-leaning.\u2019. Hill (2018).  21 Pennycook, G. A framework for understanding reasoning errors: From fake news to climate change and beyond.  (2022).  22 Pennycook, G. & Rand, D. G. Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition 188, 39-50 (2019).  23 Husz\u00e1r, F. et al. Algorithmic amplification of politics on Twitter. Proceedings of the National Academy of Sciences 119, e2025334119 (2022).  24 Gonz\u00e1lez-Bail\u00f3n, S. et al. Asymmetric ideological segregation in exposure to political news on Facebook. Science 381, 392-398 (2023).  25 Rossetti, M. & Zaman, T. Bots, disinformation, and the first impeachment of US President Donald Trump. Plos one 18, e0283971 (2023).  26 Yang, Y., Davis, T. & Hindman, M. Visual misinformation on Facebook. Journal of Communication, jqac051 (2023).  27 Lasser, J. et al. Social media sharing of low-quality news sources by political elites. PNAS nexus 1, pgac186 (2022).  28 Lin, H. et al. High level of agreement across different news domain quality ratings.    29 Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. Proceedings of the National Academy of Sciences 116, 2521-2526 (2019).  30 Eady, G., Nagler, J., Bonneau, R. & Tucker, J. Political information sharing and ideological polarization. Midwest Political Science Association, Chicago (2019).  31 Huang, J. & Ling, C. X. Using AUC and accuracy in evaluating learning algorithms. IEEE Transactions on knowledge and Data Engineering 17, 299-310 (2005).  \n32 Barber\u00e1, P., Jost, J. T., Nagler, J., Tucker, J. A. & Bonneau, R. Tweeting from left to right: Is online political communication more than an echo chamber? Psychological science 26, 1531-1542 (2015).  33 Ad Fontes Media. http://adfontesmedia.com   34 Media Bias/Fact Check. http://mediabiasfactcheck.com/   35 Martel, C. & Rand, D. G. Misinformation warning labels are widely effective: A review of warning effects and their moderating features. Current Opinion in Psychology 54, 101710 (2023). https://doi.org/https://doi.org/10.1016/j.copsyc.2023.101710 36 Allen, J., Arechar, A. A., Pennycook, G. & Rand, D. G. Scaling up fact-checking using the wisdom of crowds. Science advances 7, eabf4393 (2021).  37 Godel, W. et al. Moderating with the mob: Evaluating the efficacy of real-time crowdsourced fact-checking. Journal of Online Trust and Safety 1 (2021).  38 Resnick, P., Alfayez, A., Im, J. & Gilbert, E. Searching For or Reviewing Evidence Improves Crowdworkers' Misinformation Judgments and Reduces Partisan Bias. arXiv preprint arXiv: 2108.07898 (2023).  39 Lin, H. et al. High level of correspondence across different news domain quality rating sets. PNAS Nexus 2 (2023). https://doi.org/10.1093/pnasnexus/pgad286 40 Allen, J. N. L., Watts, D. J. & Rand, D. Quantifying the Impact of Misinformation and Vaccine-Skeptical Content on Facebook.  (2023).  41 Pennycook, G., Binnendyk, J., Newton, C. & Rand, D. G. A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology 7 (2021). https://doi.org/10.1525/collabra.25293 Box 1: How misinformation sharing is defined and measured has important implications for the conclusions that can be drawn from any analyses. Most research on online misinformation takes one of two approaches. The first approach \u2013 most often used when analyzing large social media datasets where it is not feasible to evaluate each post individually \u2013 focuses on URLs, and uses the quality of the publishing domain as a proxy for the veracity (or, more broadly \u201cquality\u201d) of the specific URL39. The logic behind this approach is that URLs from low quality sources are more likely to be false or inaccurate than URLs from high quality domains. While this approach is scalable, it is quite coarse as some stories from lower quality outlets may be accurate, and some stories from higher quality outlets may be false, inaccurate, or otherwise misleading40. That being said, there is at least substantial consistency in which domains experts consider to be low quality39, and this domain-based approach has the benefit of providing ratings of relative quality for a sizable fraction of people\u2019s news diet. The second approach \u2013 most often used when recruiting participants to complete survey experiments \u2013 is to collect specific headlines, posts, or articles that have been debunked or are veridical, and ask participants to indicate how likely they would be to share the posts if they saw them online41. While this approach does not suffer from the coarseness of the domain ratings and removes potential exposure confounds (where some types of users may be exposed to misinformation more than others), it is difficult to implement at scale and relies on self-report sharing intentions rather than actual social media sharing. As each approach has limitations, it can be particularly compelling to observe convergent results when asking the same question using both approaches.  Across both approaches, researchers typically rely on professional fact-checker ratings (either of the trustworthiness of publishers, or the veracity of individual stories) to evaluate content. In this \narticle, we demonstrate how ratings from politically balanced layperson crowds can also be used to evaluate domains and stories in a fashion that cannot be accused of political bias.  Finally, we note that while most misinformation research to date has largely focused on news stories, other forms of content such as images, video, and posts without URLs are also very important vectors of information online. It is vital for future research to look beyond URLs, as well as to develop ways of measuring the actual impact of exposure to content at scale rather than simply using inaccuracy as the metric of harm40. \nUnbiased misinformation policies sanction  conservatives more than liberals Mohsen Mosleh1,2, Qi Yang3, Tauhid Zaman4, Gordon Pennycook5,6, David G. Rand2,3,7\u01c2  1Management Department, University of Exeter Business School; 2Sloan School of Management, Massachusetts Institute of Technology; 3Institute for Data, Systems, and Society, Massachusetts Institute of Technology; 4Yale School of Management, Yale University; 5Hill/Levene Schools of Business, University of Regina; 6Department of Psychology, University of Regina, 7Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology \u01c2Corresponding Author: drand@mit.edu Supplementary Information 1. Supplemental Methods 1.1 Sample and basic data collection First, we collected a list of Twitter users who tweeted or retweeted either of the election hashtags #Trump2020 and #VoteBidenHarris2020 on October 6, 2020. We also collected the most recent 3,200 tweets sent by each of those accounts. We processed tweets and extracted tweeted domains from 34,920 randomly selected users (15,714 shared #Trump2020 and 19,206 shared #VoteBidenHarris2020), and filtered down to 12,238 users who shared at least 5 links to domains used by the ideology estimator of Ref 1. We also excluded 426 \u2018elite\u2019 users with more than 15,000 followers who are likely unrepresentative of Twitter users more generally (because of this exclusion, suspension data was not collected for these users; however, as described below in SI Section 2, we find similar associations between political orientation and low quality news sharing among these elite users). These data were collected as part of a project that was approved by the MIT Committee on the Use of Humans as Experimental Subjects Protocol 91046. We then constructed a politically balanced set by randomly selecting 4,500 users each from the remaining 4,756 users who shared #Trump2020 and 7056 users who shared #VoteBidenHarris2020. After nine months, on July 30, 2021, we checked the status of the 9000 users and assessed suspension. We classify an account as having been suspended if the Twitter API returned error code 63 (\u201cUser has been suspended\u201d) when querying that user.  To measure a user\u2019s tendency to share misinformation, we follow most other researchers in this space2-5 and use source quality as a proxy for article accuracy, because it is not feasible to rate the accuracy of individual tweets. Specifically, to quantify the quality of news shared by each user, we leveraged a previously published set of 60 news sites (20 mainstream, 20 hyper-partisan, 20 fake news; see Table S1) whose trustworthiness had been rated by eight professional fact-checkers as well as politically-balanced crowds of laypeople. The crowd ratings were determined as follows. A sample of 971 Americans, quota-matched to the national distribution on age, gender, ethnicity, and geographic region were recruited via Lucid6. Each participant indicated how much they trusted each of the 60 news outlets using a 5-point Likert scale. For each outlet, we then calculated \npolitically balanced crowd ratings by calculating the average trust among Democrats and the average trust among Republicans, and then averaging those two average ratings. We also examined Reliability ratings for a set of 283 sites from Ad Fontes Media, Inc.7, Factual Reporting ratings for a set of 3,216 sites from Media Bias/Fact Check8, and Accuracy ratings for a set of 4,767 sites from a recent academic paper by Lasser and colleagues9. We then used the Twitter API to retrieve the last 3,200 posts (as of October 6, 2020) for each user in our study, and collected all links to any of those sites shared (tweeted or retweeted) by each user. Following the approach used in prior work4,5, we calculated a news quality score for each user (bounded between 0 and 1) by averaging the ratings of all sites whose links they shared, separately for each set of site ratings. Finally, we transform these ratings into low quality news sharing scores by subtracting the news quality ratings from 1. Over 99% of users in our study had shared at least one link to a rated domain. When combining the four expert-based measures into an aggregate news quality score, we replaced missing values with the sample mean; PCA indicated that only one component should be retained (87% of variation explained), which had weights of 0.50 on Pennycook & Rand 201910 fact-checker ratings, 0.51 on Ad Fontes Media Reliability ratings, 0.48 on Media Bias/Fact Check Factual Reporting ratings, and 0.51 on Lasser et al. 20229 Accuracy ratings. In all PCA analyses, we use parallel analysis to determine the number of retained components. Mainstream Hyper-partisan Fake news Domain Politically balanced layperson rating Fact-checker rating Domain Politically balanced layperson rating Fact-checker rating Domain Politically balanced layperson rating Fact-checker rating abcnews.go.com 0.45 0.56 activepost.com 0.2 0 americannews.com 0.22 0 aol.com/news 0.35 0.41 antiwar.com 0.18 0 angrypatriotmovement.com 0.18 0 bbc.co.uk 0.38 0.81 blacklistednews.com 0.18 0 bb4sp.com 0.18 0 bostonglobe.com 0.33 0.75 breitbart.com 0.22 0.16 beforeitsnews.com 0.19 0 cbsnews.com 0.48 0.66 commondreams.org 0.18 0.03 channel24news.com 0.25 0.06 chicagotribune.com 0.38 0.53 conservativetribune.com 0.24 0.03 clashdaily.com 0.18 0 cnn.com 0.47 0.84 crooksandliars.com 0.18 0.13 conservativedailypost.com 0.23 0 dailymail.co.uk 0.3 0.44 dailycaller.com 0.21 0.13 dailybuzzlive.com 0.24 0 foxnews.com 0.45 0.44 dailykos.com 0.2 0.16 downtrend.com 0.19 0 huffingtonpost.com 0.41 0.47 dailysignal.com 0.2 0 freedomdaily.com 0.2 0.03 latimes.com 0.33 0.75 dailywire.com 0.25 0.16 newsbreakshere.com 0.19 0 msnbc.com 0.44 0.66 ijr.com 0.19 0.09 notallowedto.com 0.17 0 news.yahoo.com 0.4 0.59 infowars.com 0.21 0.03 now8news.com 0.2 0 nydailynews.com 0.33 0.34 newsmax.com 0.23 0.13 onepoliticalplaza.com 0.19 0 nypost.com 0.38 0.38 patriotpost.us 0.21 0 react365.com 0.17 0 nytimes.com 0.45 0.91 rawstory.com 0.19 0.09 realnewsrightnow.com 0.21 0 sfchronicle.com 0.26 0.59 redstate.com 0.2 0.06 socialeverythings.com 0.18 0 usatoday.com 0.45 0.66 thedailysheeple.com 0.18 0.09 thenewyorkevening.com 0.24 0 washingtonpost.com 0.45 0.91 thepoliticalinsider.com 0.22 0.03 whatdoesitmean.com 0.19 0 wsj.com 0.34 0.72 westernjournal.com 0.22 0.06 yournewswire.com 0.19 0.06 Table S1. Set of 60 news site quality scores generated by 8 professional fact-checker trustworthiness ratings and  politically-balanced trustworthiness ratings from 970 laypeople; see 10 for details. These scores indicate quality, such that higher values indicate higher quality. To generate the low quality news site sharing scores used in our analyses, these quality scores are subtracted from 1 (to transform quality scores into low quality scores). To measure a user\u2019s political orientation, we first classify their partisanship based on whether they shared more #Trump2020 or #VoteBidenHarris2020 hashtags. Additionally, we retrieved all accounts followed by users in our sample and used the statistical model from Ref 11 to obtain a continuous measure of users\u2019 ideology based on the ideological leaning of the accounts they followed. Similarly, we used the statistical models from Ref 12 and Ref 3 to estimate users\u2019 \nideology using the ideological leanings of the news sites that the users shared content from. We also calculated user ideology by averaging political leanings of domains they shared through tweets or retweets based on the method in Ref 3. The intuition behind these approaches is that users on social media are more likely to follow accounts (and share news stories from sources) that are aligned with their own ideology than those that are politically distant. Thus, the ideology of the accounts the user follows, and the ideology of the news sources the user shares, provide insight into the user\u2019s ideology. When combining these four measures into an aggregate political orientation score, we replaced missing values with the sample mean; PCA indicated that only one component should be retained (88% of variation explained), which had weights of 0.49 on hashtag-based partisanship, 0.49 on follower-based ideology, 0.51 on sharing-based ideology estimated via Ref 12, and 0.51 on sharing-based ideology estimated via Ref 3. We also used this aggregate measure to calculate a user\u2019s extent of ideological extremity by taking the absolute value of the aggregate ideology measure; and we used PCA to combine measures of the standard deviation across a user\u2019s tweets of news site ideology scores from Ref 3 and Ref 12, and standard deviation of ideology of accounts followed from Ref 11, as a measure of the ideological uniformity (versus diversity) of news shared by the user.   1.2 Additional measures for regression analyses Beyond low quality news sharing and political orientation, we used each user\u2019s most recent 200 tweets (rather than the 3200 available tweets, for tractability) as of October 6, 2020 to calculate the average of the following metrics for language use; all language metrics are winsorized at the 99th percentile. We examined harmful language used in the tweets using Google Jigsaw Perspective API13 (including \u201ctoxicity\u201d, \u201csevere toxicity\u201d, \u201cidentity attack\u201d, \u201cinsult\u201d, \u201cprofanity\u201d, and \u201cthreat\u201d) and using Rewire Online API14 (including \u201cabuse\u201d, \u201chate\u201d, \u201cprofanity\u201d, \u201cviolent\u201d, and \u201csexually explicit\u201d). PCA of these items indicated that three components should be retained, whose loadings are shown in Table S2 and which describe general toxicity, sexually explicit language, and profane language. We used VADER to measure the extent to which the tweets had positive valence, negative valence, and neutral valence15. PCA indicated that these measures all loaded on a single component (70.8% of variation explained) with weightings of 0.56 on positive valence, 0.46 on negative valence, and -0.69 on neutral valence. We used the approach from Ref 16 to quantify the expression of moral outrage in the tweets.  In addition to these language metrics, we used the API from Ref 17 to estimate the likelihood of each user being a bot based on the text of the user's tweets. We also collected each user\u2019s number of followers and number of friends, and calculated each user\u2019s friend/follower ratio, which were highly correlated with each other; we log-transformed each of these variables and performed PCA, which indicated that these measures all loaded on a single component (70.4% of variation explained) with weightings of 0.69 on log(friends+1), 0.57 on log(followers+1), and -0.45 on log((friends+1)/(followers+1)). Finally, as a measure of overall activity level on the platform, we included the number of tweets the user made in the two weeks prior to October 6, 2020; as a proxy of high-frequency tweeting, which can lead to suspension due to anti-spamming policies, we calculated the maximum number of primary tweets they made in any 1-hour time interval in our dataset; and as a proxy for the repeated posting of extremely similar tweets, which can lead to suspension due to anti-manipulation policies, we vectorized all primary tweets from the timeline of \nthe user and used cosine similarity with threshold 0.5 to find similar tweets, and then used the sum of the number of times each tweet was repeated. Each of these count variables were log-transformed due to right skew. For all variables, we replaced missing values with the sample mean. In all regression models, all independent variables are z-scored to make the coefficients comparable.   \n   Toxic Sexually Explicit Profane Jigsaw: Toxicity 0.39 -0.14 0.07 Jigsaw: Insult 0.37 -0.14 0.03 Jigsaw: Profanity 0.36 0.20 0.16 Jigsaw: Severe Toxicity 0.34 0.31 -0.24 Jigsaw: Identity Attack 0.31 0.07 -0.46 Jigsaw: Threat 0.28 0.20 -0.51 Rewire: Abuse 0.33 -0.36 0.29 Rewire: Hate 0.24 -0.58 0.01 Rewire: Profanity 0.25 0.21 0.44 Rewire: Violent 0.23 -0.07 0.04 Rewire: Sexually Explicit 0.13 0.52 0.40 Variance explained 56.1% 11.9% 10.8% Table S2. Loadings on the 3 retained components for toxicity measures.    \n1.3 Policy simulations In addition to the regression analyses, we also simulate politically-neutral suspension policies and determine each user\u2019s probability of suspension; and from this, determine the level of differential impact we would expect in the absence of differential treatment. The procedure is as follows. First, we identify a set of low quality sources that could potentially lead to suspension. We do so using the politically-balanced layperson trustworthiness ratings from Ref 10, as well as using the fact-checker trustworthiness ratings from that same paper. For both sets of ratings, there is a natural discontinuity at a value of 0.25 (on a normalized trust scale from 0=Not at all to 1=Entirely); see Figure S1. Thus, we consider sites with average trustworthiness ratings below 0.25 to be \u201clow quality\u201d; and for each user, we count the number of times they tweet links to any of these low quality sites. \n  Figure S1. News quality ratings from Pennycook & Rand (2019), generated by politically balanced crowds of laypeople (y-axis) and professional fact-checkers (x-axis). News sources show as red diamonds are counted as low quality for simulating suspensions. 00.250.50.751\n00.250.50.751Trust averaged over Democrats and RepublicansTrust among Fact-CheckersEntirelyA lotSomewhatBarelyNot at all\nWe then define a suspension policy as the probability of a user getting suspended each time they share a link to a low quality news site. We model suspension as probabilistic because many (almost certainly most) of the articles from low quality news sites are not actually false, and sharing such articles does not constitute a suspendable offense. Thus, we consider who would get suspended under suspension policies that differ in their harshness, varying from a 0.01% chance of getting suspended for each shared link to a low quality news site up to a 10% chance. Specifically, for each user, we calculate their probability of getting suspended as  p(suspended) = 1 \u2013 (1\u2013k)L where L is the number of low quality links shared, and k is the probability of suspension for each shared link (i.e. the policy harshness). The only way the user would not get suspended is if on each of the L times they share a low quality link, they are not suspended. Since they do not get suspended with probability (1-k), the probability that they would never get suspended is (1-k)L. Therefore, the probability that they would get suspended at some point is 1-(1-k)L. We then calculate the mean (and 95% confidence interval) of that probability across all Democrats versus Republicans in our sample (as determined by sharing Biden versus Trump election hashtags). The results of these analyses are shown in Figure 2b; and the Supplemental Results present statistical analyses of estimated probability of suspension based on each measure of political orientation. We also do a similar exercise using the likelihood of being a bot, rather than low quality news sharing. The algorithm of Ref 17 provides an estimated probability of being a bot for each user, based on the contents of their tweets. We define a suspension policy as the minimum probability of being human k required to avoid suspension (or, in other words, a threshold on bot likelihood above which the user gets suspended). Specifically, for a policy of harshness k, users with bot probability greater than (1-k) are suspended. The results of these analyses are shown in main text Figure 2c.   \n2. Supplemental Results In the main text, Figure 1 shows the distribution of low quality news sharing by party using ratings of fact-checkers and politically-balanced groups of laypeople from Ref 10. Here, in Figure S2 we show the same distributions using the other three sets of expert news site quality ratings, as well as ratings generated using only the Republican laypeople from Ref 10. Figure S3 shows the distribution of Bot Sentinel17 scores by party. The relationship between political orientation and sharing links to low quality news sites is robust to controlling for Bot Sentinel score (0.44 < standardized \u03b2 < 0.75 depending on which measures of political orientation and low quality news sharing are used). The relationship between political orientation and sharing links to low quality news sites is also robust to only examining users with a Bot Sentinel score lower than 50 out of 100 (0.65 < r < 0.83 depending on which measures of political orientation and low quality news sharing are used). We also find a strong political asymmetry in low quality news sharing among the elite users with more than 15,000 followers who were not included in our main analyses. Suspension and follower data were not collected for these users, but we were nonetheless able to use their collected tweets to calculate sharing of low quality news (using fact-checker and crowd ratings from Ref 10; 424 of the 426 elites shared at least one rated tweet), ideology based on the news sources they shared (all 426 elites were classifiable), and partisanship based on the hashtags they shared (315 elites were classifiable). As with the main analysis users, we find extremely strong correlations between the low quality sharing measures and the ideology measures about the elite accounts (fact-checkers and ideology, r = 0.87; politically-balanced crowds and ideology, r = 0.82; Republican crowds and ideology, r = 0.58; fact-checkers and partisanship, r = 0.85; politically-balanced crowds and ideology, r = 0.81; Republican crowds and ideology, r = 0.59; p < 0.0001 for all). As a result, a neutral suspension policy would lead to much higher suspension rates for conservative elites relative to liberal elites \u2013 for example, with a 1% likelihood of getting suspended for each low quality link, 18.0% [15.7%, 20.4%] of conservative elites would get suspended compared to 2.3% [1.4%, 3.3%] of liberal elites. Turning to our models predicting user suspension, Table S3 shows the full regression model for the probit model reported in the main text. Table S3 also shows the coefficients for the full model estimated using ridge regression with the penalty parameter selected using 5-fold cross validation; the penalty that maximizes out of sample prediction is very small, such that the coefficients in the penalized regression are quite similar to the standard probit model. Finally, Table S3 also shows the equivalent models using logistic regression instead of probit regression. Finally, for our policy simulations, in the main text we show differences in expected suspension rates for people who used Biden versus Trump hashtags. Here, we show that we get similar results when using our various ideology measures. As these measures are continuous rather than binary, we cannot easily make equivalent figures to what is shown in the main text. Instead, we fix k = \n0.01 (1% chance of suspension per low quality news site link) and examine the correlation between each user\u2019s probability of suspension and the different political orientation measures. Doing so shows that more conservative users have significantly higher suspension probabilities than more liberal users (r = 0.31 estimating ideology using accounts followed, and r = 0.33 and r = 0.38 estimating ideology using the two different news sharing approaches); p<0.0001 for all.   \n   \n    Figure S2. Low Quality News Site Sharing scores by partisanship using alternative quality rating sets. Scores are standardized (z-scored) for comparability; higher values indicate lower quality news sharing.  00.050.10.150.20.250.3\n-2.4-1.201.22.4FrequencyLow Quality News SharingLasser et al. 2022 RatingBiden HashtagsTrump Hashtags\n00.050.10.150.20.250.3\n-2.4-1.201.22.4FrequencyLow Quality News SharingMedia Bias/Fact Check RatingBiden HashtagsTrump Hashtags\n00.050.10.150.20.250.3\n-2.4-1.201.22.4FrequencyLow Quality News SharingAd Fontes Media Rating Biden HashtagsTrump Hashtags\n00.050.10.150.20.250.3\n-303FrequencyLow Quality News Sharing Republican-Only Layperson RatingBidenHashtagsTrumpHashtags\n Figure S3. Bot sentinel scores by partisanship.   00.050.10.150.20.250.3\n00.10.20.30.40.50.60.70.80.91FrequencyLikelihood of Being a BotDemocratsRepublicans\nTable S3. Regression models. Models 2 and 4 shows coefficients from ridge regression.  (1) (2) (3) (4)  Probit Probit Ridge Logit Logit Ridge      Political Orientation 0.123 0.134 0.250 0.266  (0.0526)  (0.0999)  Low Quality News Sharing 0.240*** 0.224 0.460*** 0.430  (0.0463)  (0.0860)  Followers & Friends -0.000759 0.002 -0.000937 0.003  (0.0208)  (0.0386)  Toxic Language 0.166*** 0.162 0.286*** 0.280  (0.0253)  (0.0462)  Sexually Explicit Language 0.0862** 0.084 0.155** 0.151  (0.0263)  (0.0477)  Profane Language 0.0592* 0.058 0.103* 0.101  (0.0207)  (0.0371)  # Tweets in Past 2 Weeks 0.328*** 0.317 0.605*** 0.585  (0.0208)  (0.0378)  Bot Score (Botsentinel) 0.195*** 0.188 0.374*** 0.359  (0.0384)  (0.0703)  Political Extremity -0.107*** -0.099 -0.224*** -0.208  (0.0221)  (0.0411)  Valanced Language -0.0339 -0.034 -0.0578 -0.058  (0.0225)  (0.0412)  Moral Outrage 0.0313 0.033 0.0724 0.073  (0.0333)  (0.0614)  Political Language -0.0289 -0.029 -0.0726 -0.070  (0.0276)  (0.0509)  Max # Tweets in 1h Window 0.366*** 0.357 0.636*** 0.623  (0.0696)  (0.129)  # Highly Similar Tweets -0.0308 -0.028 -0.0614 -0.056  (0.0359)  (0.0663)  Political Uniformity -0.0235 -0.027 -0.0339 -0.041  (0.0254)  (0.0462)  Constant -1.788*** -1.776 -3.153*** -3.125  (0.0773)  (0.144)       Observations 9,000  9,000     \n3. Additional samples evaluating the association between political orientation and sharing links to low quality news domains 3.1. Facebook sharing in 2016 by users recruited via YouGov Here we analyze data presented in Ref 2. A total of N=1191 survey respondents recruited using YouGov gave the researchers permission to collect the links they shared on Facebook for 2 months (via a Facebook app), starting in November 2016. As part of the survey, participants self-reported their ideology (using a 5-point Likert scale; not including participants who selected \u201cNot sure\u201d, yielding N=995 respondents with usable ideology data) and their party affiliation (Democrat, Republican, Independent, Other, Not sure). As in our Twitter studies, we calculate low quality information sharing scores for each user by using the fact-checker and politically balanced crowd ratings for the 60 news sites from Ref 10, as described above in SI Section 1.1. A total of 893 participants shared at least one rated link. We replicate the association between self-reported conservatism and sharing low quality news links using both fact-checker ratings (r(757) = 0.33, p < 0.0001) and politically balanced crowd ratings (r(757) = 0.21, p < 0.0001). We find a similar relationship using partisanship, with Republicans sharing lower quality news links than Democrats using both fact-checker ratings (r(513) = 0.36, p < 0.0001) and politically balanced crowd ratings (r(513) = 0.26, p < 0.0001).  3.2. Twitter sharing in 2018 and 2020 by users recruited via Prolific Here we analyze data presented in Ref 18. A total of N=2100 participants were recruited using the online labor marketing Prolific in June 2018. Twitter IDs were provided by participants at the beginning of the study. However, some participants entered obviously fake Twitter IDs\u2014for example, the accounts of celebrities. To screen out such accounts, accounts with follower counts above the 95th percentile in the dataset were excluded. We had complete data and usable Twitter IDs for 1901 users.  As part of the survey, participants self-reported the extent to which they were economically liberal versus conservative, and socially liberal versus conservative, using 5-point Likert scales. We construct an overall ideology measure by averaging over the economic and social measures. The Twitter API was used to retrieve the content of their last 3200 tweets (capped by the Twitter API limit). Data was retrieved from Twitter on August 18, 2018, and then again on April 12, 2020 (the latter data pull excludes tweets collected during the former data pull). We calculate low quality information sharing scores for each user by using the fact-checker and politically balanced crowd ratings for the 60 news sites from Ref 10, as described above in SI Section 1.1. A total of 594 participants shared at least one rated link in the 2018 data pull and 379 participants shared at least one rated link in the 2020 data pull; 288 participants shared at least one rated link in both data pulls. As shown in Table S4, we replicate the finding that conservativism is associated with sharing links to lower quality news domains in both the 2018 and 2020 data pulls, using both fact-checker and \npolitically balanced crowd ratings. We find equivalent results when restricting to the 288 participants with tweets containing links to rated domains in both the 2018 and 2020 data pulls (0.16 < r(286) < 0.29; p<.006 for all); we also note that participants\u2019 quality scores in 2018 and 2020 were highly correlated with each other (r(286)=0.46 for fact-checker ratings, r(286)=0.48 for politically-balanced crowd ratings). Interestingly, Table S4 shows that the association was roughly twice as strong for social conservatism compared to economic conservativism.  Table S4. Correlations between sharing low quality news domains on Twitter and ideology in the data from Mosleh et al. (2021)18.   Overall Ideology Social Ideology Economic Ideology Fact-checkers 2018 r(592) = 0.17 p < 0.0001 r(592) = 0.18 p < 0.0001 r(592) = 0.12 p = 0.003 Politically balanced crowd 2018 r(592) = 0.16 p = 0.0001 r(592) = 0.20 p < 0.0001 r(592) = 0.11 p = 0.008 Fact-checkers 2020 r(377) = 0.27 p < 0.0001 r(377) = 0.29 p < 0.0001 r(377) = 0.22 p < 0.001 Politically balanced crowd 2020 r(377) = 0.20 p = 0.0001 r(377) = 0.25 p < 0.0001 r(377) = 0.12 p = 0.019  3.3. Twitter sharing in 2021 by users who followed at least 3 political elites Here we analyze data presented in Mosleh & Rand (2023)19, in which Twitter accounts for 816 elites were identified, and then 5000 Twitter users were randomly sampled from the set of 38,328,679 users who followed at least three of the elite accounts. Each user\u2019s last 3200 tweets were collected on July 23, 2021, and sharing of low quality news domains was assessed using the fact-checker and politically balanced crowd ratings from Ref 10. A total of 3070 users shared at least one rated link. The statistical model from Ref 11 was used to obtain a continuous measure of users\u2019 ideology based on the ideological leaning of the accounts they followed. We replicate the association between estimated conservatism and sharing low quality news links using both fact-checker ratings (r(3068) = 0.57, p < 0.0001) and politically balanced crowd ratings (r(3068) = 0.40, p < 0.0001).  3.4. Twitter sharing in 2022 by users who followed at least 3 political elites Here we analyze previously unpublished data, in which 11,805 Twitter users were sampled from a set of 296,202,962 users who followed at one of the political elite accounts used above in SI Section 3.2. We randomly sampled from users who had more than 20 lifetime tweets and followed at least three political elites for whom we had a partisanship rating. Each user\u2019s last 3200 tweets were collected on December 25, 2022, and sharing of low quality news domains was assessed using the fact-checker and politically balanced crowd ratings from Ref 10. A total of 4,040 users \nshared at least one rated link. The statistical model from Ref 11 was used to obtain a continuous measure of users\u2019 ideology based on the ideological leaning of the accounts they followed. We replicate the association between estimated conservatism and sharing low quality news links using both fact-checker ratings (r(4038) = 0.40, p < 0.0001) and politically balanced crowd ratings (r(4038) = 0.20, p < 0.0001).  3.5. Twitter sharing in 2023 by users who followed at least 1 political elite, stratified on follower count Here we analyze previously unpublished data in which 11,886 Twitter users were randomly sampled, stratified based on log-10 transformed number of followers (rounded to the nearest integer) from the same set of 296,202,962 users who followed at one political elite account. On March 4, 2023, we retrieved all tweets made by each user since Dec 22, 2022 using the Twitter Academic API. Sharing of low quality news domains was assessed using the fact-checker and politically balanced crowd ratings from Ref 10. A total of 4,408 users shared at least one rated link. The statistical model from Ref 11 was used to obtain a continuous measure of users\u2019 ideology based on the ideological leaning of the accounts they followed. We replicate the association between estimated conservatism and sharing low quality news links using both fact-checker ratings (r(4404) = 0.28, p < 0.0001) and politically balanced crowd ratings (r(4404) = 0.14, p < 0.0001).   4. Sharing of false claims on Twitter, from Ghezae et al.  (2023)20  4.1 Methods Here we analyze data from Ghezae et al. (2023)20. Unlike the previous analyses, this dataset does not use domain quality as a proxy for misinformation sharing. Instead, sets of specific false versus true headlines were used. The headline sets were assembled by collecting claims that third-party fact-checking websites such as snopes.com or politifact.org had indicated were false, and collecting veridical claims from reputable news outlets. Furthermore, the headlines were pre-tested to determine the extent to which they had a left-leaning or right-leaning bent (based on survey respondents\u2019 evaluation of how favorable the headline, if entirely accurate, would be for the Democrats versus Republicans; see Ref 21 for details of the pre-testing procedure).  Survey participants were recruited to rate the accuracy of each URL\u2019s headline claim. Specifically, each participant was shown 10 headlines randomly sampled from the full set of headlines, and rated how likely they thought it was that the headline was true using a 9-point scale from \u201cnot at all likely\u201d to \u201cvery likely\u201d. For each headline, we created politically-balanced crowd ratings by averaging the accuracy ratings of participants who identified as Democrats, averaging the accuracy ratings of participants who identified as Republicans, and then averaging these two average ratings. \nWe then classify URLs as inaccurate (and thus as misinformation) based on crowd ratings if the politically-balanced crowd rating was below the accuracy scale midpoint. Additionally, the Twitter Academic API was used to identify all Twitter users who had posted primary tweets containing each URL. These primary tweets occurred between 2016 and 2022 (2016, 1%; 2017, 2%; 2018, 4%; 2019, 5%; 2020, 34%; 2021, 27%; 2022, 27%). The ideology of each of those users was estimated using the statistical model from Ref 11 based on the ideological leaning of the accounts they followed. This allows us to count the number of liberals and conservatives who shared each URL on Twitter.  The dataset pools across three different iterations of this procedure. The first iteration used 104 headlines selected to be politically balanced, such that the left-leaning headlines were as left-leaning as the right-leaning headlines were right-leaning; N=1,319 participants from Amazon Mechanical Turk were then shown a random subset of headlines that were half politically neutral and half aligned with the participant\u2019s partisanship. The second iteration used 155 headlines (of which 30 overlapped with headlines using in the first iteration); N=853 participants recruited using Lucid rated randomly selected headlines. The third iteration used 149 headlines (no overlap with prior iterations); N=866 participants recruited using Lucid rated randomly selected headlines. The Amazon Mechanical Turk sample was a pure convenience sample, whereas the Lucid samples were quota-matched to the national distribution on age, gender, ethnicity, and geographic region, and then true independents were excluded. For the 30 headlines that overlapped between iterations 1 and 2, the politically balanced crowd accuracy ratings from Amazon Mechanical Turk and Lucid correlated with each other at r(28)=0.75. Therefore, we collapsed the politically-balanced ratings across platforms for those 30 headlines. In total, this resulted in a final dataset with fact-checker ratings, politically-balanced crowd ratings, and counts of number of posts by liberals and conservatives on Twitter for 378 unique URLs. Finally, we also classified the topic of each URL. To do so, we used Claude, an artificial intelligence (AI) system designed by Anthropic that emphasizes reliability and predictability, and has text summarization as one of its primary functions. We uploaded the full set of headlines to the AI, and first asked it to summarize the topics discussed in the headlines. We then asked it to indicate the topic covered in each specific headline, and manually inspected the results to ensure that the classifications were sensible. Next, we examined the frequency of each topic, synthesized the results into a set of six overarching topics, and then finally asked the AI to categorize each headline into one of these six topics. This process led to the following distribution of topics: U.S. Politics (174 headlines), Social Issues (91 headlines), COVID19 (48 headlines), Business/Economy (41 headlines), Foreign Affairs (28 headlines), and Crime/Justice (26 headlines). As a test of the robustness of the classification, we also asked another AI system, GPT4, to classify the first 100 headlines into the six topics. We found that Claude and GPT4 agreed on 80% of the headlines. 4.2 Results \nOf the 378 unique URLs, 109 were rated as false by professional fact-checkers, and 129 were rated as inaccurate by political-balanced crowd ratings (the fact-checkers and the crowd agreed in 92.1% of cases). We find that a larger number of conservative Twitter users shared misinformation URLs than liberal users, both when examining URLs rated as false by professional fact-checkers (Wilcoxon sign-rank test, z=6.641, p<.0001; linear regression predicting log10(shares+1) using an ideology dummy, b=0.654, p<.0001) and when examining URLs rated as inaccurate by politically balanced crowds (Wilcoxon sign-rank test, z=5.634, p<.0001; linear regression predicting log10(shares+1) using an ideology dummy, b=0.589, p<.0001); see Figure S8.  \n   Figure S8. Distribution of the number of posts containing misinformation links based on liberals versus conservatives on Twitter. Y-axis shows log10(count of primary posts containing the URL+1).  Importantly, there was no significant partisan asymmetry in the sharing of non-misinformation, both when examining URLs rated as false by professional fact-checkers (Wilcoxon sign-rank test, z=1.366, p=.172; linear regression predicting log10(shares+1) using an ideology dummy, b=0.080, p=.058) and when examining URLs rated as accurate by politically balanced crowds (Wilcoxon sign-rank test, z=1.352, p=.176; linear regression predicting log10(shares+1) using an ideology dummy, b=0.068, p=.114). Furthermore, the relationship between ideology and log10(shares+1) was significantly larger for misinformation than for non-misinformation (interaction between non-misinformation dummy and conservative dummy: professional fact-checker ratings, b=-0.573, p<.0001; politically balanced crowd ratings, b=-0.521, p<.0001). Thus, conservatives selectively share more misinformation and less discerning in their sharing, rather than simply sharing more of both types of content. We find similar results when restricting our analyses to just the data from the first iteration of data collection, in which the headlines were politically balanced. As in the main analyses, a larger number of conservative Twitter users shared misinformation URLs than liberal users, both when examining URLs rated as false by professional fact-checkers (Wilcoxon sign-rank test, z=3.869, p=.0001; linear regression predicting log10(shares+1) using an ideology dummy, b=0.513, p<.001) and when examining URLs rated as inaccurate by politically balanced crowds (Wilcoxon sign-rank test, z=3.287, p=.001; linear regression predicting log10(shares+1) using an ideology \ndummy, b=0.502, p<.001). And the relationship between ideology and log10(shares+1) was significantly larger for misinformation than for non-misinformation (interaction between non-misinformation dummy and conservative dummy: professional fact-checker ratings, b=-0.384, p=.012; politically balanced crowd ratings, b=-0.458, p=.002). Finally, we ask how the association between ideology and misinformation sharing varies by topic. Figure S9 shows the coefficient on the ideology dummy in a linear regression predicting log10(shares+1) for each of the six topics. We see that although there is variation in the magnitude of the association across topics, there is a consistent pattern of conservatives sharing more misinformation. Most importantly, although there is little evidence of ideological differences in sharing of some topics (e.g. Business/Economy), there are no topics for which liberals share significantly (or even directionally) more misinformation than conservatives. \n \n \nFigure S9. Shown is the coefficient on an ideology dummy in a linear regression predicting log10(# misinformation shares +1) separately for URLs of each topic, along with the overall estimate from a random effects meta-analysis. Top panel shows results when considering URLs rated as false by professional fact-checkers; bottom panel shows results when considering URLs rated as inaccurate by politically-balanced crowds.   5. Sharing intentions of false COVID-19 claims across 16 countries Here, we examine survey data from Ref 22. In these experiments, participants were recruited from 16 different countries using Lucid, with respondents quota-matched to the national distributions on age and gender in each country. Participants were shown 10 false and 10 true claims about COVID-19 (sampled from a larger set of 45 claims), presented without any source attribution. The claims were collected from fact-checking organizations in numerous countries, as well as sources such as the World Health Organization\u2019s list of COVID-19 myths. This approach removes ideological variation in exposure to misinformation online19, as well as any potential source cues/effects, and directly measures variation in the decision about what to share.  As in our other analyses, we complement the professional veracity ratings with crowd ratings. Specifically, N=8,527 participants in the Accuracy condition rated the accuracy of each of the headlines they were shown using a 6-point Likert scale. We calculate the average accuracy rating for each statement in each country, and classify statements as misinformation if that average rating is below the scale point.  Our main analyses then focus on the responses of the N=8,597 participants from the Sharing condition, in which participants indicated their likelihood of sharing each claim using a 6-point Likert scale. To calculate each user\u2019s level of misinformation sharing, we first discretize the sharing intentions responses such that choices of 1 (Extremely unlikely), 2 (Moderately unlikely), or 3 (Slightly unlikely) on the Likert scale are counted as not shared, whereas choices of 4 (Slightly likely), 5 (Moderately likely), or 6 (Extremely likely) are counted as shared. We then determine for each user, the fraction of shared articles that were (i) rated as false by fact-checkers, and (ii) rated as below the accuracy scale midpoint on average by respondents in the Accuracy condition. We then ask how misinformation sharing varies with ideology within each country. Specifically, we construct a conservatism measure by averaging responses to two items from World Values Survey that were included in the survey, which asked how participants would place their views on the scales of \u201cIncomes should be made more equal\u201d vs \u201cThere should be greater incentives for individual effort\u201d and \u201cGovernment should take more responsibility to ensure that everyone is provided for\u201d vs \u201cPeople should take more responsibility to provide for themselves\u201d using 10-point Likert Scales. Pilot data collected in the United States confirmed that responses to these two \nitems correlated with self-report conservatism (r(956)=0.32 for the first item and r(956)=0.40 for the second item).  Figure S10 shows the correlation between conservatism and fraction of shared content that is misinformation in each country, along with the results of a random effects meta-analysis. Both when using professional veracity assessments and country-specific crowd assessments, we see that more conservative users share more misinformation in the United States (r(439)=0.10, p=.027 for fact-checkers; r(439)=0.10, p=.028 for crowd ratings). We also see that these associations are not unique to the United States: many other countries also find significant associations, and the meta-analytic estimate across countries is highly significant for both sets of ratings.  \n  Figure S10. Correlation between self-reported endorsement of conservative principles and fraction of shared content that was misinformation. Overall effect calculated using random effects meta-analysis. Error bars indicate 95% confidence intervals. A downside of the data analyzed in this section, of course, is that the sharing decisions are hypothetical, and the study only examines a small fraction of all possible news (i.e., just 45 claims about COVID-19). Nonetheless, we offer them here as a complement to the Twitter and Facebook data; and we note that it is reassuring that the patterns observed above in the Twitter and Facebook sharing data are replicated in the U.S. sharing intentions data (and that prior work has found that, at the level of the article, self-report sharing intentions in survey experiments correlates highly with actual number of shares on Twitter, and also show similar correlation patterns with article-level features23).   Supplementary References \n1 Eady, G., Nagler, J., Guess, A., Zilinsky, J. & Tucker, J. A. How many people live in political bubbles on social media? Evidence from linked survey and Twitter data. Sage Open 9, 2158244019832705 (2019).  2 Guess, A., Nagler, J. & Tucker, J. Less than you think: Prevalence and predictors of fake news dissemination on Facebook. Science advances 5, eaau4586 (2019).  3 Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during the 2016 US presidential election. Science 363, 374-378 (2019).  4 Pennycook, G. et al. Shifting attention to accuracy can reduce misinformation online. Nature 592, 590-595 (2021).  5 Mosleh, M., Martel, C., Eckles, D. & Rand, D. G. in proceedings of the 2021 CHI Conference on Human Factors in Computing Systems.  1-13. 6 Coppock, A. & McClellan, O. A. Validating the demographic, political, psychological, and experimental results obtained from a new source of online survey respondents. Research & Politics 6, 2053168018822174 (2019).  7 Ad Fontes Media. http://adfontesmedia.com   8 Media Bias/Fact Check. http://mediabiasfactcheck.com/   9 Lasser, J. et al. Social media sharing of low-quality news sources by political elites. PNAS nexus 1, pgac186 (2022).  10 Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. Proceedings of the National Academy of Sciences 116, 2521-2526 (2019).  11 Barber\u00e1, P., Jost, J. T., Nagler, J., Tucker, J. A. & Bonneau, R. Tweeting from left to right: Is online political communication more than an echo chamber? Psychological science 26, 1531-1542 (2015).  12 Eady, G., Nagler, J., Bonneau, R. & Tucker, J. Political information sharing and ideological polarization. Midwest Political Science Association, Chicago (2019).  13 Using machine learning to reduce toxicity online. Google Prospective API   14 Socially responsible AI for online safety. Rewire Online   15 Hutto, C. & Gilbert, E. in Proceedings of the international AAAI conference on web and social media.  216-225. 16 Brady, W. J., McLoughlin, K., Doan, T. N. & Crockett, M. J. How social learning amplifies moral outrage expression in online social networks. Science Advances 7, eabe5641 (2021). https://doi.org/doi:10.1126/sciadv.abe5641 17 Social Media Account Classifier. Botsentinel   18 Mosleh, M., Pennycook, G., Arechar, A. A. & Rand, D. G. Cognitive reflection correlates with behavior on Twitter. Nature communications 12, 1-10 (2021).  19 Mosleh, M. & Rand, D. G. Measuring exposure to misinformation from political elites on Twitter. Nature Communications 13, 7144 (2022). https://doi.org/10.1038/s41467-022-34769-6 20 Ghezae, I. et al. Partisans neither expect nor receive reputational rewards for sharing falsehoods over truth online.    21 Pennycook, G., Binnendyk, J., Newton, C. & Rand, D. G. A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology 7 (2021). https://doi.org/10.1525/collabra.25293 22 Arechar, A. A. et al. Understanding and reducing online misinformation across 16 countries on six continents.  (2022).  23 Mosleh, M., Pennycook, G. & Rand, D. G. Self-reported willingness to share political news articles in online surveys correlates with actual sharing on Twitter. Plos one 15, e0228882 (2020).   ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Unbiased misinformation policies sanction conservatives more than liberals", "author": ["M Mosleh", "Q Yang", "T Zaman", "G Pennycook"], "pub_year": "2024", "venue": "Preprint at https://osf. io \u2026", "abstract": "In response to intense pressure from policy makers and the public, technology companies  have enacted a range of policies aimed at reducing the spread of misinformation online1-3."}, "filled": false, "gsrank": 376, "pub_url": "https://osf.io/preprints/psyarxiv/ay9q5/download", "author_id": ["DAivUTUAAAAJ", "", "SA6zXVIAAAAJ", "AIbJenwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:rRqZFboPJFEJ:scholar.google.com/&output=cite&scirp=375&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D370%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=rRqZFboPJFEJ&ei=SLWsaJjrIPnSieoPxKLpgQ0&json=", "num_citations": 4, "citedby_url": "/scholar?cites=5846815508134435501&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:rRqZFboPJFEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://osf.io/preprints/psyarxiv/ay9q5/download"}}, {"title": "Slippery beasts: Why academic freedom and media freedom are so difficult to protect", "year": "2021", "pdf_data": "Periodically, the academy, and its friends and critics, pause \nto consider the idea of academic freedom. This is often \nconnected with events outside the academy, as in the 1950s \nwhen \u2018loyalty oaths\u2019 were sometimes imposed on academics in the United States, or after 9/11, when security concerns \nwere leveraged to permit oversight of \u2018sensitive\u2019 scholarly \nand scientific enquiries. Thirty years ago, from the very place where we write, a series of \u2018managerial\u2019 changes to the \ngovernance of Australian universities (the so-called \u2018Dawkins \nReforms\u2019) prompted the Bulletin of the Australian Society of Legal Philosophy to devote a special issue to discussing \n\u2018 Academic Freedom T oday\u2019 (Moens, 1991). \nSo-called political correctness (in the form of things like \n\u2018de-platforming\u2019 , \u2018speech codes\u2019 , \u2018cancel culture\u2019 , and \u2018safe spaces\u2019) has recently provoked heated debate, while the \nCommonwealth government was so concerned about these matters that in 2018 the Minister for Education commissioned \nformer High Court Chief Justice Robert French AC to set up \nan inquiry. (And a subsequent 2020 inquiry into the results of the inquiry, led by Professor Sally W alker AM.) Justice \nFrench\u2019s findings yielded, among other things, a model code \nfor universities, some of which have adopted it, with or without modifications. On this topic we believe something already asserted by the \nNational T ertiary Education Union (NTEU), which said in \nits submission to a 2008 Parliamentary review, \u2018The dialogue \nabout protecting academic freedom needs to move beyond old debates about political correctness [already old thirteen \nyears ago!] to the real threats that incursions on academic \nfreedom can have for our universities and for our society more broadly\u2019 (2008, p. 8).  W e aim to show how to move \nthe debate beyond these hackneyed questions, though not, \nperhaps, in the direction that the NTEU had in mind in that earlier intervention.\nPublic airing of this topic frequently suggests that there is \nnothing more to the concept of academic freedom than the idea of freedom of speech (within a particular community), \nwhere this is read as a negative liberty, in the sense that \nIsaiah Berlin (1969) first proposed in 1958. Berlin thought \nof \u2018negative liberty\u2019 as an absence of enforced institutional \nconstraints such as laws and regulations that explicitly limit \ncertain behaviours. In this case it refers to the ability for people to say what they please, within broadly described legal \nlimits. However, some notable discussants have been careful \nto distinguish academic freedom from such a libertarian conception of freedom of speech. Professor Carolyn Evans, Slippery beasts\nWhy academic freedom and media freedom are so \ndifficult to protect\nFred D\u2019Agostino & Peter Greste\nUniversity of Queensland\nIt is easy to confuse academic freedom with freedom of speech, but it is illuminating to consider the responsibilities that \nframe academic freedom and thus distinguish it from the less constrained freedoms to speak that characterise our roles as citizens of democratic societies. In particular, scholars and scientists are subject to standards of rigour and integrity. While academics sometimes fail to live up to these standards, we consider a difficulty that arises even when they do. This is a collective action failure that arises because of the incentives that motivate choices of topics and approaches by scholars and scientists and it results in overconcentration of academic effort. Diversity within the academy is a potential antidote to this difficulty. W e explore these issues from within our different professional perspectives and note some analogies between the situation of academics on the one hand and journalists on the other.\nKeywords: Negative freedom, positive freedom, tragedy of the commons, groupthink, diversity\nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\nSlippery beasts   Fred D\u2019Agostino & Peter Greste    45\nVice-Chancellor of Griffith University, recently cautioned \n(2020): \u2018W e need to be careful \u2026 that we do not let absolute \nideas of freedom of speech undermine the core purposes of the \nuniversity\u2019 . French noted (2019, p. 116, emphasis added) that academic freedom confers a \u2018 qualified freedom of speech\u2019 and \nthat that was only \u2018one of its elements\u2019 . W e are with Evans and French on this issue. While there are issues about the proper domain of freedom of speech on campus, this is not what has \nusually been meant by academic freedom; free speech is not what we mean by academic freedom; and it is not a matter \nthat we will discuss, except, perhaps, glancingly. Indeed, we \nwill offer an account of academic freedom according to which \nscholars and scientists are free to explore and express ideas \nwithin the limits set by the stringent standards of rigour and objectivity to which they are subject.\nFrench\u2019s reference to \u2018qualified freedom of speech\u2019 as only \n\u2018one of [the] elements\u2019 of academic freedom is our starting point. What are the other  elements of academic freedom that \nlie just outside our line-of-sight, and what does consideration \nof this whole notion \u2013 the complex ideal, with multiple \nelements \u2013 enable us to understand about the threats to it? \nT o answer this question, we need to consider the telos  of \nacademic freedom. Why is that freedom valuable to us, not \njust as members of the academic community, but as citizens of \na democratic society?\nOne familiar kind of reason for academic freedom is an \ninstrumental one. If we have academic freedom (whatever that might turn out to encompass), then knowledge will grow and, with that growth, the human condition will be \nbettered in various ways. This is not restricted to those kinds \nof improvements brought to us by scientific and technological advances, but encompasses, just as surely (if sometimes more \nobscurely), advances in humanistic and social scientific \nunderstandings of our situation.\nIt is already apparent that academic freedom couldn\u2019t \npossibly deliver this if all it amounted to was the liberty of scientists and scholars to think, say or do whatever they wanted, without qualification \u2026 a radically libertarian \nconception of academic freedom. As Evans charmingly put \nit (2020), \u2018Just as academic freedom strongly protects the articulation of unpopular views, it also places more demands \non participants than a discussion in the campus bar.\u2019 \nAs is commonly acknowledged in discussions of academic \nfreedom, but alas rarely properly emphasised, academic freedom (NTEU, 2008, p. 3, quoting the Global Colloquium \nof University Presidents) is \u2018subject to the norms and standards of scholarly inquiry\u2019 and (Evans, 2020) should be exercised \u2018in \nthe spirit of a responsible and honest search for knowledge\u2019; \nits conduct and products (Bickel, 1975, p. 127) \u2018must be judged by professional criteria\u2019 , being (American Association \nof University Professors [AAUP] 1915), in quaintly archaic \ndiction, \u2018conclusions gained by scholarly method and held in a scholarly spirit \u2013 the fruits of competent and patient and sincere inquiry \u2026 set forth with dignity, courtesy and \ntemperance of language\u2019 .\nThese are (some of ) the elements that need to be added to \nthe idea on unencumbered freedom of scholarly discussion if we are to understand what is at stake with academic freedom. \nCrudely, these are the requirements of academic integrity, about which the T ertiary Education Quality and Standards \nAgency (TEQSA) has issued a Guidance Note that provides \na good summary of conventional wisdom \u2013 often hard won from scandalous failures in the past \u2013 about the fundamentals \nof (specifically) research integrity. As they put it (TEQSA, \n2019, p. 3-4):\nGood practice includes:\n\u2022 intellectual honesty in proposing, performing, and \nreporting research\n\u2022 accuracy in representing contributions to research pro-posals and reports\n\u2022 fairness in peer review\n\u2022 collegiality in scientific interactions, including commu -\nnications and sharing of resources\n\u2022 transparency in conflicts of interest or potential con -\nflicts of interest\n\u2022 protection of human subjects in the conduct of research\n\u2022 humane care of animals in the conduct of research, and\n\u2022 adherence to the mutual responsibilities between inves-tigators and research.\nBreaches of research integrity include:\n\u2022 plagiarism\n\u2022 falsifying or fabricating data\n\u2022 deliberately omitting data to obtain a desired result\n\u2022 using data from other researchers without due acknowl-edgement\n\u2022 representing observations as genuine when they are not, and\n\u2022 misleading attributions of authorship.\nBerlin would regard these ideas about good practice and the \navoidance of breaches as limits to negative freedoms. These \nclearly articulated norms and rules define the space in which an individual is able to operate. These formal requirements \nof the academy are often missed in debates about what can \nand can\u2019t be said, but when they are added to the libertarian \nideal of academic freedom (in a narrow, permissive sense), \nthey together give us an ideal of academic freedom that is \ndistinctive.\nT aking these ideas into account \u2013 and some of them of \ncourse have analogues in relation to university-level teaching \u2013 we can say, roughly, that academic freedom amounts to the freedom of academics to pursue their enquiries and propagate \nthe results of those enquiries in accordance with good practice \nand avoiding breaches of scholarly or scientific integrity. And here we can begin to see more clearly how academic \nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\n46   Slippery beasts   Fred D\u2019Agostino & Peter Greste\nfreedom, understood in this expanded sense, contributes to \nthe realisation of its own telos . Honesty, accuracy, fairness, \navoidance of fabrication and the like \u2026 all these are necessary conditions for the growth of knowledge through disciplined \nenquiry. \nThese principles find echoes in another institution \nthat also regards itself as a truth-making enterprise. While journalism has always been accused of imperfectly applying \nits own standards, its telos is strikingly similar to the \nacademy\u2019s. Both journalists and academics consider their \nvalue to be underpinned by a commitment to a set of rigorous \nprofessional practices and standards that valorise their roles in \ndeveloping and circulating useful and reliable knowledge. In \ncultural terms, journalism and the academy are worlds apart. Journalists tend to mock academics, especially journalism \nacademics (Anonymous, 2015), and few academics would \nconsider journalists to be in the same league when it comes \nto rigorous research and analysis. But while journalists would \nchoke on the purple prose of the 1915 AAUP statement, those phrases, invoking the ideals of \u2018honest search\u2019 , \u2018sincere inquiry\u2019 , \nand \u2018temperance of language\u2019 , might well have come from an \nantiquarian journalism textbook.\nIt has to be acknowledged that these professional self-\nunderstandings and institutional devices are the consequence of long and complex historical processes, some of which are influentially documented by Habermas (1989).  They \nare imperfectly embodied in actual practice, and they are \nincreasingly under pressure as \u2018legacy\u2019 practices from newer cultural forms. W e are not \u2018essentialising\u2019 the academy or the \nprofession of journalism, but we are taking a stand to defend \nsome hard-won institutional forms. \nIn essence, both professions idealise a search for \u2018truth\u2019; \nan attempt to brush away distracting \u2018noise\u2019 , to uncover an important reality. Both require rigorous scepticism \u2013 a willingness to question and challenge established \northodoxies \u2013 and the courage to ask deep, and often deeply \nuncomfortable questions about why things are as they are, and how they could be improved. That is why the challenges to \none should resonate powerfully with the other. The battles \nthat journalists have fought in defence of press freedom are only marginally removed from those the academy continues \nto struggle with over academic freedom. And both professions \nwill, if genuinely pursuing the truth, need to do so with an \nintegrity that itself puts limits on a purely libertarian approach \nto professional freedom.\nIf academic freedom is driven by its telos,  the same is true of \npress freedom. Its underlying purpose is to enable the media to act as a watchdog over the powerful, to interrogate disputes, \ncirculate ideas and facilitate public debate and understanding. That telos helps inform and describe its shape. A press without \nfreedom is little more than a propaganda machine, pushing particular ideologies and narratives that serve the interests of those who seek to control it. (The American newspaper mogul William Randolph Hearst famously once remarked ( JPROF, \n2019), \u2018news is something somebody doesn\u2019t want printed; all \nelse is advertising.\u2019) Journalism must be allowed the freedom to investigate almost all corners of society and government, \nwith the fairly narrow exception of those that hold sensitive \nprivate, commercial or security information. It should be allowed to interrogate the complete range of political views, \nto allow the best of them to win in free and open debate. \nConsider perhaps the most eloquent defence of press \nfreedom ever written, from John Stuart Mill (1998, ch. 2), who argued in 1859:\nThe peculiar evil of silencing the expression of an opinion \nis, that it is robbing the human race; posterity as well as the \nexisting generation; those who dissent from the opinion, still more than those who hold it. If the opinion is right, they are deprived of the opportunity of exchanging error for truth: if \nwrong, they lose, what is almost as great a benefit, the clearer \nperception and livelier impression of truth, produced by its \ncollision with error.\nThere is barely a coat of paint between Mill\u2019s argument, \nand Evans\u2019 (quoted above), that \u2018academic freedom strongly \nprotects the articulation of unpopular views\u2019 . But just as Evans \ngoes on to point out that academic freedom is not unqualified, \nthe same is true of press freedom. With the power of the press, comes great responsibility, and while not every journalist \nor editor has honoured that responsibility with complete \nintegrity, those higher standards of editorial independence, a bias towards transparency over secrecy, fidelity to the facts, \nand professional scepticism should all still apply. \nAnd, as already mentioned, these standards, whether of \nthe academy or of journalism are, crucially, superintended by a variety of institutional offices and processes. So, for \nexample, research ethics committees oversee conflicts of interests and the welfare of subjects (whether they be human \nor other animals), while gatekeepers work hard for academic \npublishers and funding agencies to ensure fairness in the peer review processes. There are comparable offices and processes \nin the work of journalists \u2013 the ombudsman, the Australian \nPress Council, the desk editor, sub-editors, managing editor, and the like. Journalists\u2019 codes of conduct establish much \nthe same ethical framework as is articulated in the TEQSA \nGuidance Note (2019). The Australian Press Council\u2019s \n(2014) \u2018General Principles\u2019 for example, cover \u2018accuracy and \nclarity\u2019 , \u2018fairness and balance\u2019 , \u2018privacy and avoidance of harm\u2019 , \nand \u2018integrity and transparency\u2019 . The Media, Entertainment and Arts Alliance\u2019s Journalist Code of Ethics (2018) \ncrucially mentions correction of errors, honesty, avoidance \nof conflict of interests and avoidance of plagiarism. See also the Australian Broadcasting Corporation\u2019s (2019) Principles \nand Standards. It is these institutional parallels, as well as \n(partially) shared teloi, that warrant our guiding principle that \nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\nSlippery beasts   Fred D\u2019Agostino & Peter Greste    47\nlooking at journalistic practice can illuminate issues about \nacademic freedom (and vice versa).\nNotwithstanding this institutional apparatus, we still \nfrom time to time witness scandalous failures of academic or journalistic integrity. There are infamous examples of \nmade-up evidence in support of a news story or a research \noutcome, accompanied by retraction, discipline of the offending professional, and soul-searching about the guiding \npolicies and the effectiveness of their implementation. For \nsome recent journalistic scandals, see ThoughtCo. (2019) and for some scientific scandals, see Fanelli (2009).\nThese failures of integrity are, of course, abuses of the \nfreedoms granted to journalists and/or scholars and scientists \nand they take a form that is itself easily and dramatically narrated, involving as they do individual miscreants and the \nfailure of other individuals, holding gatekeeping offices, to detect (in time to stop) their misbehaviour. Indeed, they are \nthe stuff of documentaries (e.g. The Crisis of Science 2019) \nor dramatisations (e.g. Absence of Malice 1981), so readily do \nthey fit into the contemporary mythos.\nThe canons of academic and journalistic integrity provide a \nframework of constraints on the liberty of individuals to do as they please \u2026 they represent constraints on freedom in Berlin\u2019s \nnegative sense. W e accept them because they are understood as \nmeans to the ends, the teloi , that define the relevant professions. \nThe pursuit of truth requires a commitment to integrity. And \nit is the application of this commitment that distinguishes the \nfreedom that the scholar or journalist expresses through their work, from the free-wheeling discussion in the pub (or Evans\u2019 \ncampus bar), just as the constraint on harm to others (as in \nMill\u2019s Liberty) distinguishes freedom in a civilised society \nfrom absolute negative freedom \u2026 i.e., the freedom from all \ninstitutional constraints that amounts to anarchy.\nOf course, within the constraints of academic or \njournalistic integrity, the widest possible freedom of enquiry \nand expression is also instrumental to the realisation of the \nteloi  of these practices. While they depend on restraint \u2013 the \ncommitment to \u2018objectivity\u2019 , for example \u2013 they also depend \non examination of the full variety of ideas and points of view. \nWhile there is objectivity, in some sense, there should be no \ninstitutionally enforced orthodoxy in the practice of scholarship \nor journalism. W e are rightly sceptical, for example, of news \nmedia or academic organisations that demand conformity to \na \u2018party line\u2019; they may think they already have  the truth, but \nexperience has taught us to be wary of such claims. (More on this point below.)\nAll this is pretty straightforward. On the account so \nfar sketched, we have academic or journalistic freedom when individual practitioners are free from overbearing institutional constraints to \u2018follow the story where it takes \nthem\u2019 , so long as they are guided by their professional \nstandards and ethics.But we are worried about something that can happen in \nboth professions, even when individuals act with integrity and \neven though they may experience themselves as being authors \nof their own destinies, and so \u2018free\u2019 in Berlin\u2019s (1969: Part II) \u2018positive\u2019 sense.\nIn many cases, failures of journalism and scholarship don\u2019t \ninvolve bad people acting, self-interestedly, in ways that cheat the system and violate professional integrity. They \nmay involve self-interest, but self-interest in terms that are \ndefined, indeed, precisely by \u2018the system\u2019 and internalised \nby the individual. The failures we want to add to the kinds \nthat people already know about aren\u2019t individual, so much \nas \u2018collective action failures\u2019 , of the kind familiar, perhaps, in \nthe \u2018tragedy of the commons\u2019 (Hardin, 1968). And, tragically, they don\u2019t typically erupt into scandals, though their effects \ncan be more damaging to the public good than more easily dramatised failures of personal integrity.\nThe tragedy of the commons involves three key ideas: (1) \nthe institutionally recognised freedom of individuals (their negative liberty) to do as they like with a common resource; \n(2) their own individual estimations of where their personal \ninterests lie; and (3) the degradation of the common resource that results as a joint effect from freedoms exercised in pursuit \nof (narrowly construed) self-interest. Hardin described an \nunregulated environment in which each farmer may graze their cattle on the commons ab libitum. Every individual \nfarmer sees that it is in their self-interest to do so, whatever the other farmers do. But when all act in their individual interests, even when each can plainly see the collective consequence, the \ncommons is overgrazed and tragically loses its value to each. \nNo-one has behaved without integrity, but the consequences of their individually sensible (and permitted) activities, are \nbad for the individual and for the collective.\nWhat has this got to do with the freedom of individual \nscholars and scientists to pursue their own research interests or, indeed, with the freedom of individual journalists to \nfollow the story as they understand it? \nConsider the situation of the individual scholar or scientist, \nat liberty, because of their (negative) academic freedom, to research whatever topic they consider it best to engage with, and hoping to express themselves, to author themselves, \nthrough their choices. How can they choose? W ell, with some \ntopics, they are  and with other topics they are not going \u2026\n\u2022 to be easily recognised as \u2018one of the gang\u2019;\n\u2022 to benefit directly from the work of others;\n\u2022 to have ready access to publication and grants opportunities;\n\u2022 to be sought out as a collaborator;\n\u2022 to have the quality of their work easily and reliably assessed \nby their peers.\nWhere these characteristics are present, the individual \nscholar or scientist has strong career-related incentives to \nseek them out and to make their selection of research topic \nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\n48   Slippery beasts   Fred D\u2019Agostino & Peter Greste\nand method on that basis. So, as scientists or scholars consider \nwhat topic to research, it is predictable (and indeed observable, \nempirically) that most will choose a topic that affords these \ncareer-enhancing opportunities. But if most do choose these highly salient options, then there is every prospect that there \nwill be, as was long ago observed (Chubin and Connolly \n1982, p. 294), an \u2018unproductive over-concentration on some few problems, while high-potential areas go underdeveloped.\u2019 \nThere will, in other words, be \u2018over-grazing\u2019 of the knowledge \ncommons in some areas at the same time that other areas of enquiry are neglected. And the logic is the same as in the \nenvironmental case. Each individual, acting within a domain \nof personal freedom, and expressing themselves as the author \nof their own professional narrative, is nevertheless steered, by compelling incentives that are built into their situation, \nto behave in a way that produces, as a resultant from the combined decisions of many such individuals, a collective \naction failure. If there had \nbeen a different, more diverse distribution of research activity \nacross the various topics of \npotential enquiry, then more knowledge, contributing to \nmore human betterment, could \nhave been produced. (See also D\u2019 Agostino, 2019.)\nSo, while issues of academic \nintegrity \u2013 not cheating the system \u2013 are important and already well-known limits to \nacademic freedom in a simplistic libertarian sense, we need \nto add another, less widely noted element in understanding what (responsible) academic freedom in fact requires . For \nthere are systemic effects involving common incentives (in Berlin\u2019s terms, limits to positive freedom rather than negative freedom), that can also limit the ability of free academic \nenquiry to deliver on the telos  of that activity.\nIf that is true in the academy, it is no less real for journalism.\nT ake the 9/11 attacks on the W orld T rade Centre in \nNew Y ork. Those shocking acts of mass murder made it all but impossible for US reporters to see their country as anything other than a victim, and the attackers as anything \nless than villainous. This is more than simple self-censorship. \nThe incentives to adopt this narrative \u2013 to be recognised \nas \u2018one of the gang\u2019 , to have publication opportunities \u2013 \nwere so powerful in the aftermath of the attacks that this \ninterpretation of events became a deeply embedded world view that catastrophically disrupted the ability of many journalists \nto ask difficult questions and challenge the government\u2019s \nnarrative. The phrase, \u2018the W ar on T error\u2019 became so resonant in the collective psyche, that it became impossible to see the \nUS response in anything other than military terms. Think \nhow different the world would have been if the US had described 9/11 as a heinous crime that needed to be dealt with by the criminal justice system, rather than an act of war that \ndemanded an armed invasion. In Berlin\u2019s terms, the structural \nforces that drove journalists \u2013 and indeed most of the W est \u2013 to see the attacks on the W orld T rade Center in military terms \nseverely limited journalists\u2019 positive freedom to see alternatives \nor to even challenge the orthodox view . In terms of \u2018fitting in\u2019 \nand \u2018getting recognition\u2019 , all the incentives were aligned with \nthis interpretation of the situation.\nIn 2003, in the wake of the invasion of Afghanistan, the \nUS Government claimed it had evidence that proved Iraq had \u2018weapons of mass destruction\u2019 . The then-US Secretary \nof State, Colin Powell, famously addressed the United \nNations to insist that Iraq was a threat to world peace and that invasion was necessary. In a stinging piece for \nCNN to mark the invasion\u2019s tenth anniversary, journalist Howard Kurtz wrote (2013), \u2018Major news organisations \naided and abetted the Bush administration\u2019s march to war on what turned out to be \nfaulty premises. All too often, \nscepticism was checked at the door, and shaky claims of top \nofficials and unnamed sources \nwere trumpeted as fact.\u2019 Kurtz found more than 140 front-\npage stories published from \nAugust 2002 until the war \nbegan on March 19 the following year that focused heavily on \nthe US administration\u2019s rhetoric against Iraq: \u2018Cheney says \nIraqi strike is justified\u2019 , for example, and \u2018Bush tells United Nations it must stand up to Hussein or US will\u2019 . Kurtz called \nit (2013), \u2018the media\u2019s greatest failure in modern times.\u2019 Kurtz \nwas perhaps being too hard on his colleagues. He implied it was a failure of professional integrity, rather than powerful \nstructural and social forces that simply made it too difficult \n(or too uncomfortable) to see the war in any other terms.  Like the tragedy of the commons, this groupthink wasn\u2019t so \nmuch a failure of individual integrity as it was an expression \nof the incentives in play, given a strong cultural bias towards interpreting the relevant events in a particular way. While \nthe Iraq war is a dramatic example, a terrorist attack isn\u2019t the \nonly thing capable of restricting Berlin\u2019s positive freedoms by \nputting on blinkers or channelling an individual\u2019s approach \nto self-authorship.\nThere is, perhaps, one dis analogy between the academic and \njournalistic professions. Both have constraints on freedom of practice that are related to the teloi  of the enterprises, and \nboth exhibit systemic failures because of the influence of \nprofessional incentives for recognition and participation. But \njournalism, though perhaps not the academy, also encourages \ninstitutional conformity; the organisations that hire The pursuit of truth requires a commitment \nto integrity. And it is the application of this \ncommitment that distinguishes the freedom \nthat the scholar or journalist expresses \nthrough their work, from the free-wheeling \ndiscussion in the pub...\nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\nSlippery beasts   Fred D\u2019Agostino & Peter Greste    49\njournalists often have an established and enforced corporate \n\u2018brand\u2019 or guiding (and enforced) ideological orientation.\nBut even those organisations that claim to have no particular \nideological position, are still vulnerable internal political cultures that in turn shape their world views. For example, \nChris Kenny, a conservative columnist for Sky News and The \nAustralian, often derides the ABC for \u2018groupthink\u2019 that he \nargues drives the national broadcaster to take socially liberal \napproaches to a whole range of issues, though he often singles \nout climate change (Kenny, 2018; 2020). The American sociologist William H. Whyte Jr described \u2018groupthink\u2019 thus \n(1952): \u2018W e are not talking about mere instinctive conformity \n\u2013 it is, after all, a perennial failing of mankind. What we are \ntalking about is a rationalised conformity \u2013 an open, articulate philosophy which holds that group values are not only \nexpedient but right and good as well.\u2019 \nIn Kenny\u2019s conception, the ABC\u2019s groupthink has pushed \nthe broadcaster and its staff to hire left-wing journalists from a narrow band of Australian society and has thus entrenched a narrow small-l liberal culture that is incapable of understanding \nwhy a significant proportion of Australian voters continues \nto support coal mining. He declared (Kenny, 2020) on Sky News that \u2018the taxpayer funded ABC opinion leaders suffer \nfrom ideological groupthink and avoid inconvenient facts\u2019 , \nespecially when it comes to climate change.\nIt is easy to dismiss Kenny and his colleagues at News Corp \nfor being guilty of exactly the same problem he accuses the ABC of. Either by accident or design, News Corp appears to have adopted a conservative ideological position, developing \nits own right-of-centre cultural world view.  For example, \nthe website mediabiasfactcheck.com rates The Australian \nas \u2018centre right\u2019 , Sky News and The Daily T elegraph as \u2018right\u2019 . \nW alkley Award-winning journalist T ony Koch wrote in The \nGuardian, 9 May 2019, \u2018For 30 years I worked for News Corp papers. Now all I see is shameful bias\u2019 . But in the heart of the \ncontradiction lies the legitimacy of the argument. The social \nand political structures of the institutions charged with freely developing our knowledge and understanding, of challenging \nthe status quo, and asking difficult questions, are encumbered \nby an institutionalised way of seeing and interpreting the world, which is only reinforced by the set of professional \nincentives, also in play in the academy, that tend to promote \n\u2018follow-the-leader\u2019 rather than \u2018be-the-leader\u2019 behaviour by \nindividual agents. Just as those institutional wheel ruts drive \nacademics to plough certain fields of research and ignore \nothers, so journalists are also pushed into particular ways of seeing that shape and direct the questions they ask, and the \nstories they tell. This is often a matter of corporate policy \nfor media companies, but the influence of culture on an academic\u2019s world view can be just as powerful as a journalist\u2019s. \nThe \u2018Foucault phenomenon\u2019 of the 1980s and 1990s is a \nstriking example, especially in the humanities and social sciences. Once Foucault\u2019s work was canonised, it became an \u2018attractor\u2019 for academic work on a variety of topics. Showing \nsome facility in deploying Foucauldian ideas became a sine \nqua non for those needing to appear up to date. Of course, \nthe mechanism was not the top-down one of corporate policy \nand its enforcement within a specific institutional context. \n(On this see D\u2019 Agostino, 2019.)\nOf course, it\u2019s no easy matter to suggest a way around this \nparticular difficulty, but the idea of diversity  holds the key. \nIn media, there has been a long debate about the need \nfor diversity in newsrooms. The theory will be familiar. If \nhomogeneous communities tend to develop homogeneous \nthinking, it follows that introducing people from different \nsocial, religious, ethnic or gendered groups is likely to keep the institution\u2019s mind open, if not each individual\u2019s. But \nwhile diversity in this sense undoubtedly has value, given \nthe way institutional incentives for recognition and \u2018fitting \nin\u2019 work, there is no guarantee that a person from an African \nbackground will magically see the world in a way that is radically different from a European or Asian, particularly if \nthey all grew up in the same schools, played football together, \nand shared university lectures. \nCulture is key; and not just the culture of those who \nget hired. (See Sunstein, 2003.) Corporate culture can be as stubborn a thing to shift as an individual\u2019s, and every employee is as involved in the culture as any other. All are \nvulnerable to the same structural and social pressures. Bosses \ntend to hire people who think like them because we are drawn to those who reflect our own values and world views. W e like \nworking with people who support our opinions; not those \nwho challenge them. (This is the central finding of \u2018social comparison theory\u2019 in psychology (Suls & Wheeler, 2000) \nand it is a very robust effect.) And anyone who doubts the \npower of a self-reinforcing culture to head off in dangerously \nnarrow-minded tangents needs only to look at the way one \nparticular unit of the Australian Special Air Service seems to \nhave convinced itself that war crimes were okay.\nIn the academy, the idea of \u2018tenure\u2019 , of \u2018jobs for life\u2019 in \neffect, was touted as an antidote to the risks of venturing into unpopular or unfashionable territory. Without the risk of losing their job, a researcher is theoretically free to explore \nthose territories without restraint. But tenure has turned \nout to be relatively weak, up against the power of cultural \nincentives to maintain conformity. \nThere are some areas, largely in the humanities and social \nsciences, where, because of ideological engagements, there is a diversity of realms in which recognition might be sought \nand hence, a potential structural solution to what is, after all, \na structural problem. If many scholars are likely to respond to incentive signals and to want recognition for their work, \nthen to secure diversity and sceptical challenges to taken-for-\ngranted thinking, it will help, indeed help a great deal, if there \nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\n50   Slippery beasts   Fred D\u2019Agostino & Peter Greste\nare different \u2018schools\u2019 of thought to which one might belong. \nThe individual scholar gets to be recognised within their \nfavoured school, but, because the schools are different and \noften indeed opposed, each will keep the other honest so long as they engage with one another.\nMuch the same principle animates ideas about diversity \nof media ownership. Former Prime Minister Kevin Rudd recently launched a petition calling for a Royal Commission \nto investigate the impact of Australia\u2019s highly concentrated \nmedia ownership. It was driven at least in part by his concern about the way Rupert Murdoch\u2019s News Corporation narrows \nand distorts public debate in Australia. At least according to \none landmark study (Noam, 2016), Australia ranks third in \nthe world for the degree of concentration, (behind China and Egypt), and that was in 2016, before the Nine Network \nbought the Fairfax papers in 2019. It would be fine if News \nCorp\u2019s \u2018right-wing\u2019 tilt cancelled out the ABC\u2019s \u2018left-wing\u2019 \nworld-view, but true media freedom requires more than \nsimply weighing one bias against another. It requires an aggressive approach to protecting diversity of ownership \nacross the media landscape and, within those organisations, \ndeliberate mechanisms to encourage dissident thinking, and, within the general public, a commitment to actively sampling \nthe diversity before forming the judgments that will engage \nthem in the voting booth or in other political action. \nOn this account, then, academic and journalistic freedom \nare in the service of something \u2026 the pursuit of the truth. And while each is subject to those limits on positive freedom that are inherent in any system of social incentives, the pursuit of \ntruth may still be possible if there is diversity in the approaches \nthat are taken to finding it. That is a matter of our institutional arrangements, not of our individual integrity.\nAcademic freedom, journalistic freedom \u2026 these are not \nsomething for the individual; they are something for the \nsociety, in the service of the society. But they are real only if \nthe social arrangements are in place that enable both integrity \nat the individual level and diversity at the collective level. Only in that way can they put honestly arrived at but always \nonly partial perspectives on the truth into contact with one \nanother in a productive way. This is the social precondition for the \u2018rigorous scepticism\u2019 that is expected of both individual \nacademics and journalists. It is too much to expect each \nindividual to step outside their own culturally defined world \nviews though. W e need, at a minimum, the diversity that Rudd \nis calling for in the Australian media landscape, but also an \naggressive approach to encouraging and rewarding dissidents and contrarians. But even that is not enough. W e also need \nthe civility among divergent parties \u2013 the \u2018dignity, courtesy \nand temperance of language\u2019 mentioned earlier \u2013 that will enable these parties to engage with one another in honest \ndebate, rather than hurling barbs at one another across the \nT wittersphere or, even worse, simply retreating to their social-media echo chambers and ignoring one another. Anything less is not true freedom, whether it is journalistic or academic.\nFred D\u2019 Agostino is Emeritus Professor of Humanities at the \nUniversity of Queensland, where he was President of the \nAcademic Board and Executive Dean of Arts. He edited \nthe Australasian Journal of Philosophy and PPE: Politics, Philosophy and Economics, and co-edited The Routledge \nCompanion to Social and Political Philosophy. A relevant \nbook is Free Public Reason (OUP , 1996).Contact: f.dagostino@uq.edu.au\nPeter Greste is UNESCO Chair in Journalism and \nCommunication at the University of Queensland. Before joining the university as professor in 2018, he spent 25 years \nas a foreign correspondent for the BBC and Al Jazeera. His memoir, The First Casualty, (Viking, 2017) explores what \nhe describes as the \u2018war on journalism\u2019 . \nContact: p.greste@uq.edu.au\nReferences\nAustralian Broadcasting Corporation. (2019). ABC\u2019s Principles and \nStandards. Retrieved from https://about.abc.net.au/wp-content/uploads/2016/05/CODE-final-15-01-2019.pdf \nAmerican Association of University Professors. (1915). General \nDeclaration of Principles. Retrieved from http://www.aaup-ui.org/Documents/Principles/Gen_Dec_Princ.pdf\nAnonymous. (2015). Journalism academics: mocked by the media and \nstifled by universities, The Guardian, 7 May.\nAustralian Press Council. (2014). The Australian Press Council\u2019s \nGeneral Principles. Retrieved from https://www.presscouncil.org.au/statements-of-principles/\nBerlin, I. (1969). Two Concepts of Liberty, in I. Berlin, Four Essays On \nLiberty. Oxford: Oxford University Press.\nBickel, A. (1975). The Morality of Consent. New Haven: Y ale \nUniversity Press.\nChubin, D. & Connolly, T . (1982). Research trails and science policies, \nin N. Elias, H. Martins & R. Whitley (eds.), Scientific establishments and hierarchies. Dordrecht and Boston: D. Reidel Pub. Co. \nD\u2019Agostino, F . (2019). Growth of knowledge: dual institutionalisation \nof disciplines and brokerage, Synthese , retrieved from https://doi.\norg/10.1007/s11229-019-02335-1\nEvans, C. (2020). Freedom of speech on campuses should never be \nconfused with undisciplined free-for-all rants, The Australian, 11 \nFebruary.\nFanelli, D. (2009). How many scientists fabricate and falsify research? \nPLOS ONE 4.\nFrench, R. (2019). Report of the Independent Review of Freedom \nof Speech in Australian Higher Education Providers. Canberra:  \nDepartment of Education and T raining.\nHabermas, J. (1989). The Structural Transformation of the Public \nSphere. Cambridge, MA: MIT Press.\nHansen, M. T . (2013). How John F . Kennedy Changed Decision \nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\nSlippery beasts   Fred D\u2019Agostino & Peter Greste    51\nMaking for Us All, Harvard Business Review, November 22, retrieved \nfrom https://hbr.org/2013/11/how-john-f-kennedy-changed-\ndecision-making\nHardin, G. (1968). The T ragedy of the Commons. Science  162, 1243-\n1248.\nJPROF . (2019). \u2018Journalism is printing what someone else does not \nwant printed. \u2019 Or maybe not. Retrieved from http://www.jprof.com/2019/05/28/journalism-is-printing-what-someone-else-does-not-want-printed-or-maybe-not/\nKenny, C. (2018). ABC groupthink distorts debate we need to have, \nThe Australian, September 15.\nKenny, C. (2020). ABC\u2019s \u2018ideological groupthink\u2019 is a bigger worry \nthan climate change. Sky News, April 9, retrieved from https://www.\nskynews.com.au/details/_6139636856001\nKurtz, H. (2013). Media\u2019s failure on Iraq still stings. CNN, March 11. \nRetrieved from https://edition.cnn.com/2013/03/11/opinion/kurtz-iraq-media-failure/index.html\nMedia, Entertainment and Arts Alliance. (2018).  Journalist Code of \nEthics. Retrieved from https://www.meaa.org/meaa-media/code-of-\nethics/\nMill, J.S. (1998). On Liberty. Harmondsworth: Penguin.\nMoens, G., (ed.). (1991). Bulletin of the Australian Society of Legal \nPhilosophy 8: Academic Freedom T oday.Noam, E. and the International Media Concentration Collaboration. (2016). Who Owns the World\u2019s Media: Media Concentration and Ownership around the World. Oxford: Oxford University Press.\nNTEU. (2008). Submission to the Senate Education, Employment \nand W orkplace Relations Committee Inquiry into Academic Freedom. \nRetrieved from https://www.nteu.org.au/indigenous_ed/article/\nInquiry-into-Academic-Freedom---August-2008-174\nSuls, J. & Wheeler, L., (eds.). (2000). Handbook of Social Comparison. \nNew Y ork: Kluwer Academic Publishers.\nSunstein, C. (2003). Why Societies Need Dissent. Cambridge: Harvard \nUniversity Press.\nTEQSA. (2019). Guidance Note on Academic Integrity. Retrieved from \nhttps://www.teqsa.gov.au/latest-news/publications/guidance-note-academic-integrity\nThoughtCo. (2019). The T op 12 Journalism Scandals Since 2000. \nRetrieved from https://www.thoughtco.com/the-top-journalism-scandals-2073750\nWhyte, W .H. (1952). Groupthink. Fortune (1952). Retrieved from \nhttps://fortune.com/2012/07/22/groupthink-fortune-1952/\nAUSTRALIAN UNIVERSITIES\u2019 REVIEW\nvol. 63, no. 1, 2021\n52   Slippery beasts   Fred D\u2019Agostino & Peter Greste", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Slippery beasts: Why academic freedom and media freedom are so difficult to protect", "author": ["F D'Agostino", "P Greste"], "pub_year": "2021", "venue": "TheAustralian Universities' Review", "abstract": "It is easy to confuse academic freedom with freedom of speech, but it is illuminating to  consider the responsibilities that frame academic freedom and thus distinguish it from the less"}, "filled": false, "gsrank": 380, "pub_url": "https://search.informit.org/doi/abs/10.3316/informit.743697799989327", "author_id": ["JQEB1tcAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:GObqjtGutykJ:scholar.google.com/&output=cite&scirp=379&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D370%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=GObqjtGutykJ&ei=SLWsaJjrIPnSieoPxKLpgQ0&json=", "num_citations": 1, "citedby_url": "/scholar?cites=3006063491362252312&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:GObqjtGutykJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.eric.ed.gov/fulltext/EJ1304839.pdf"}}, {"title": "Suspended accounts align with the Internet Research Agency misinformation campaign to influence the 2016 US election", "year": "2024", "pdf_data": "Sera\ufb01noetal. EPJDataScience           (2024) 13:29 \nhttps://doi.org/10.1140/epjds/s13688-024-00464-3\nRESEARCH OpenAccess\nSuspendedaccountsalignwiththeInternet\nResearchAgencymisinformationcampaign\ntoin\ufb02uencethe2016USelection\nMatteoSera\ufb01no1*\u2020,ZhenkunZhou2\u2020,Jos\u00e9S.AndradeJr .3,AlexandreBovet4,5andHern\u00e1nA.Makse1*\n*Correspondence:\nm.sera\ufb0100@ccny.cuny.edu ;\nhmakse@ccny.cuny.edu\n1LevichInstituteandPhysics\nDepartmen,CityCollegeofNew\nYork, New York, NY, USA\nFulllistofauthorinformationis\navailableattheendofthearticle\n\u2020EqualcontributorsAbstract\nTheongoingdebatesurroundingtheimpactoftheInternetResearchAgency\u2019s(IRA)\nsocialmediacampaignduringthe2016U.S.presidentialelectionhaslargely\novershadowedtheinvolvementofotheractors.Ouranalysisbringstolighta\nsubstantialgroupofsuspendedTwitterusers,outnumberingtheIRAusergroupbya\nfactorof60,whoalignwiththeideologiesoftheIRAcampaign.Ourstudy\ndemonstratesthatthisgroupofsuspendedTwitteraccountssigni\ufb01cantlyin\ufb02uenced\nindividualscategorizedasundecidedorweaksupporters,potentiallywiththeaimof\nswayingtheiropinions,asindicatedbyGrangercausality.\nKeywords: Socialnetwork;Disinformation;Election;Russiantrolls\n1 Introduction\nSocial media platforms have become increasingly prominent in shaping political events\nand social discussions. Political campaigns across the globe are heavily reliant on social\nmediaplatformstocommunicatewiththemassesandshapepublicopinion[ 1\u20135].How-\never,theriseofsocialmediahasalsoresultedindebatesabouttheirimpactonsocietyand\nthepotentialrisksassociatedwiththeiruse.\nSocialmediaplatforms,whileholdingthepotentialtofacilitatecommunicationandfos-\nterinformeddiscussions,arealsosusceptibletothedisseminationofmisinformationand\ndisinformationcampaigns[ 6\u20138].Thisissueextendsbeyondpoliticsandseepsintosensi-\ntivedomainslikepublichealth,asexempli\ufb01edbytheanti-vaccinemovementsduringthe\nCOVID-19 pandemic [ 9]. Compelling evidence abounds, pointing to the active exploita-\ntion of social media platforms by certain governments to subvert domestic social move-\nments and interfere in the democratic elections of foreign adversaries [ 10]. Noteworthy\ninstances of such foreign interventions include the case of the 2017 French presidential\nelection[ 11]andthehighlysigni\ufb01cantinterferencebytheInternetResearchAgency(IRA:\na Russian companyengaged in online in\ufb02uence operationson behalf of Russian business\nandpoliticalinterests)inthe2016USpresidentialelection[ 12,13].\nAsoutlinedintheU.S.SpecialCounsel\u2019sreport[ 14],theInternetResearchAgencyini-\ntiatedRussianinterferenceoperationsasearlyas2009.Theirstrategicapproachinvolved\n\u00a9TheAuthor(s)2024. OpenAccess ThisarticleislicensedunderaCreativeCommonsAttribution4.0InternationalLicense,which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit\ntotheoriginalauthor(s)andthesource,provide a linktotheCreative Commonslicence,and indicateifchangeswere made.The\nimagesorotherthirdpartymaterialinthisarticleareincludedinthearticle\u2019sCreativeCommonslicence,unlessindicatedotherwise\nin a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright\nholder.Toviewacopyofthislicence,visit http://creativecommons.org/licenses/by/4.0/ .\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page2of19\nthe creation of social network campaigns aimed at fueling and magnifying political and\nsocial divisions within the UnitedStates [ 14,15].Atthebeginning of2018,Twitter com-\nmitted to the United States Congress and the public to provide regular updates and in-formation regarding their investigation into foreign interference in U.S. political conver-\nsations on Twitter. In October 2018, Twitter openly released all the accounts and related\ncontentassociatedwithpotentialinformationoperationstheyhadfoundonTwittersince2016.Thisdatasetconsistsofmorethanthreethousandaccountsa\ufb03liatedwiththeIRA.Itcontainsmorethan9milliontweets,includingtheearliestTwitteractivityoftheaccountsconnectedwiththesecampaigns,datingbackto2009.TheTwittercorporationestimatesthat9%ofthetweetsfromIRAaccountswereelection-related.\nSincethen,thenumberofworksfocusingontheroletheIRAagencyplayedinthe2016\nUSpoliticalcampaignandsocialdebatesincreased.A.Badawy etal.[16]foundthatcon-\nservativesretweetedRussiantrollssigni\ufb01cantlymoreoftenthanliberalsandproduced36timesmoretweets.Amongthe5.7milliondistinctusersanalyzedbetweenSeptember16and November 9, 2016, about 4.9% and 6.2% of liberal and conservative users, respec-tively, were automated accounts (bots) used to share troll content. Text analysis of thecontent shared by trolls reveals that they had a mostly conservative, pro-Trump agenda.P. N. Howard etal.[17]concludedthattheRussianstrategiestargetedmanycommunities\nwithintheUnitedStates,particularlythemostextremeconservativesandthosewithpar-ticular sensitivities to race and immigration. They found that IRA used a variety of fakeaccountstoin\ufb01ltratepoliticaldiscussionsinliberalandconservativecommunities,includ-\ning black activist communities, to exacerbate social divisions and in\ufb02uence the agenda.\nBy combining network science and volumetric analysis, L. G. Stewart et al.found that\ntrollaccountssharedcontenttopolarizedinformationnetworks, likelyaccentuatingdis-agreement and fostering division [ 18]. The conclusions above align with the \ufb01ndings of\nR.DiResta etal.[19],whoobservedthattheIRAcampaignwasdesignedtoexploitsoci-\netalfractures,blurthelinesbetweenrealityand\ufb01ction,anderodetrustinmediaentitiesandtheinformationenvironment,ingovernment,ineachother,andindemocracyitself.IntheirstudyondisinformationS.Zannettou etal.[20],conductedaninvestigationinto\nthebehavioraldi\ufb00erencesbetweenIRAandrandomTwitterusers.The\ufb01ndingsrevealedthatIRAusersexhibitahighertendencytodisseminatecontentrelatedtopolitics.Addi-tionally, IRA employed multiple identities throughout the lifespan of their accounts andmade deliberate e\ufb00orts to amplify their impact on Twitter by increasing their number offollowers.\nThe studies mentioned above aim to characterize the IRA campaign. In an attempt to\nevaluatetheimpactoftheIRAcampaignonTwitterusers,C.Bail etal.conductedastudy\nusingalongitudinalsurveythatdescribestheattitudesandonlinebehaviorsofonethou-sand Republican and Democratic Twitter users in late 2017 [ 21]. Their \ufb01ndings suggest\nthat Russian trolls might have failed to sow discord because they mostly interacted with\nthosewhowerealreadyhighlypolarized.In[ 22],N.Grinberg etal.demonstratedthatex-\nposuretofakenewscontentduringthe2016electionswastypicallyconcentratedamongasmallgroupofusers,particularlythosewhoidentifythemselvesasstrongpoliticalparti-sans.IfexposuretosocialmediapostsfromRussianforeignin\ufb02uenceaccountsduringthe2016 USelectionwassimilarlyconcentrated,theirimpactonchanging candidate prefer-encesmayhavebeenminimal.Intheattempttoverifythishypothesis,Eady etal.[23]com-\nbined US longitudinal survey data from over 1496 respondents with Twitter data. They\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page3of19\nfoundthatexposuretotheRussianforeignin\ufb02uencecampaignwasheavily concentrated\namongasmallfractionofuserswhoidenti\ufb01edthemselvesasRepublicans.Moreover,theyfound no evidence of a signi\ufb01cant relationship between exposure to the campaign andchangesinattitudes,polarization,orvotingbehaviorinthe2016USelection.\nWhilepriorresearchextensivelyexploredthein\ufb02uenceofIRAaccountsonindividuals\u2019\nvoting intentions and Twitter discussions, it provided limited attention to the broaderset of suspended accounts not \ufb02agged as IRA. During the \u201cTwitter purge\u201d in May 2018,Twittersuspendednumerousaccounts,includingthoseunrelatedtotheIRA[ 24,25],with\nIRAaccountsconstitutingonlyasmallerfractionofthisoverallset.\nConsidering that all these accounts faced suspension for violating Twitter rules, it\nprompts the question of whether, beyond IRA accounts, other accounts might have at-\ntemptedtoin\ufb02uenceTwitterdiscourseandmorebroadlythe2016USelection.\nOur\ufb01ndingsprovideevidencesupportingthisnotion.Aconsistentgroupofsuspended\naccounts exhibits similarity with IRA accounts in terms of the information they interactwithanddisseminate tothebroaderTwittercommunity.Wedemonstratethatthegroup\nofsuspendedaccountsdidindeedin\ufb02uence,inaGranger-causalmanner,theretweetac-\ntivity of undecided users and weak supporters\u2014individuals uncertain about their votingdecisions\u2014intermsofpoliticalpolarization.\nThepaperisorganizedasfollows:Sect. 2outlinesthedatacollectionandanalysismeth-\nodsutilizedthroughoutthestudy.InSect. 3,wepresentthe\ufb01ndingsofourresearch,which\ninclude: (a) the characterization of users within our dataset based on the content theyshare; (b) the use of the IRA ego network as a means to identify a group of suspendedusers with similar behavioral patterns; and (c) an evaluation of how this speci\ufb01c group\nof suspended accounts in\ufb02uences Twitter discourse, utilizing Granger causality for as-\nsessment.Themanuscriptconcludeswithathoroughdiscussionandconclusionsection,summarizingthekeyinsightsgainedfromouranalysis.\n2M e t h o d s\n2.1 Dataset\nInthisstudy,wecombinetheIRAdatasetwithadatasetcontainingtweetspostedbetween\nJune1standelectionday,November8th,2016.ThedatawerecollectedcontinuouslyusingtheTwittersearchAPIwiththenamesofthetwopresidentialcandidates[ 3,26,27].The\n2016datasetconsistsof171milliontweetssentby11millionusers.\nOn the other hand, from June 1st to November 8th, 2016, 556 IRA accounts published\n391680tweetsinEnglish.Accordingto[ 17],thecontentofthesetweetsaimedtosowand\namplifypoliticalandsocialdiscordintheUnitedStatesandmanipulatethe2016American\npresidentialelection.SeeAdditional\ufb01le 1Sects.1and2formoreinformation.\nToretrievetheaccountstatusofeachuserinthe2016dataset,weusedtheTwitterusers\nAPI,asofOctober2023.Itallowsustoclassifyeachaccountassuspended,notfound,not\nveri\ufb01ed, or veri\ufb01ed. On Twitter, a suspended account refers to an account that has been\ntemporarily or permanently disabled by Twitter due to a violation of its rulesor policies.In contrast, a not found account is not deleted by Twitter but is no longer available be-cause the user has chosen to delete or deactivate it. A not veri\ufb01ed account on Twitter\nis an account that has not been o\ufb03cially con\ufb01rmed by Twitter. Veri\ufb01cation is a process\nthroughwhich Twitter veri\ufb01es theauthenticity andidentity ofnotablepublic\ufb01gures,or-ganizations, or brands. On the other hand, a veri\ufb01ed account on Twitter has undergone\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page4of19\ntheveri\ufb01cationprocessandhasbeencon\ufb01rmedbyTwitterasanauthenticrepresentation\nofanotablepublic\ufb01gure,organization,orbrand.Veri\ufb01edaccountsaredistinguishedbyablue checkmark badge next to their username, indicating their credibility and authentic-\nity.Importanttonotethatthisisnolongerthecase(asofNovember29th,2023),asnow\nanyonecanbuythebluecheckmark.\nAmong the 11 million users, 73.8% are not veri\ufb01ed, 17.7% are not found, 7.7% are sus-\npended, and 0.8% are veri\ufb01ed. In this dataset, the IRA accounts account for less than 1%oftheusers(554accounts).\n2.2 Newscategories\nIn order to control for the type of information under analysis, we focus on tweets that\ncontainatleastoneURL(UniformResourceLocator)pointingtoanewswebsiteoutsideof\nTwitter.Weclassi\ufb01edURLlinksforoutletsthatmostlyconformtoprofessionalstandards\nof fact-based journalism in \ufb01ve news media categories: right, right leaning, center, left\nleaning, and left. The classi\ufb01cations rely on the website allsides.com (AS), followed by\nthe bias classi\ufb01cation from the website mediabiasfactcheck.com (MBFC) for outlets not\nlisted in AS (both accessed on 7 January 2021 for the 2020 classi\ufb01cation) [ 3,22,26,27].\nWe also include three additional news media categories to include outlets that tend to\ndisseminatedisinformation:Extremebiasright,Extremebiasleft,andFakenews[ 3,22,26,\n27].Websitesinthefakenewscategoryhavebeen\ufb02aggedbyfact-checkingorganizations\nasspreadingfabricatednewsorconspiracytheories,whilewebsitesintheextremelybiased\ncategories have been \ufb02agged for reporting controversial information that distorts facts\nand may rely on propaganda, decontextualized information or opinions misrepresented\nasfacts.Additional\ufb01le 1Table1o\ufb00ersthelistofnewsoutletspercategoryconsideredin\nthiswork.\nIn the 2016 dataset, 2.3 million users shared 30.7 million tweets that contained URLs\ndirectingtonewsoutlets.IntheIRAdataset,334IRAaccountsposted23,806tweetsthat\nincludedhyperlinkstonewsoutlets.\n2.3 Retweetnetwork\nIn the context of a news category network, a link between two users occurs every time\nau s e ruretweets a user\u2019s tweet vthat contains a URL linking to a website belonging to\none of the news media categories. The direction of the connection goes from vtou, i.e.,\nthe direction of the information \ufb02ow between Twitter users. We do not include multiple\nlinksinthesamedirectionbetweenthesametwousers,nordoweincludeself-links.The\ndegree of a node in the network is de\ufb01ned as the number of edges connected to it. The\nout-degreeofanode u,ku\nout,representsthenumberofuniqueuserswhoretweeted u.On\nthe other hand, the in-degree of a node u,ku\nin, represents the number of users retweeted\nbynodeu.Itisworthnoticingthat,byconstruction,thesenetworksarebalanceddirected\nnetworks,andassuch, /angbracketleftkin/angbracketright=/angbracketleftkout/angbracketright=/angbracketleftk/angbracketright/2.\nWhenbuildingtheegonetworks,weproceedsimilarly.Weconstructseparatenetworks\nfor each of the four types of interactions: retweeting, mentioning, replying, and quoting.\nEachnodeinthenetworkrepresentseitheranIRAoranon-IRAuser.Alinkbetweentwo\nusersoccurseverytimeauser uinteractswithauser vthroughatypeofinteraction.The\ndirection of the connection goes from vtou, i.e., the direction of the information \ufb02ow.\nConnections are allowed between IRA nodes and between IRA and non-IRA nodes. We\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page5of19\ndo not consider interactions among non-IRA nodes. We consider multiple interactions\nbetweentwousers;thatis,networksareweightedbythenumberoftimesusersinteract.\nStarting from the four interaction networks, we build an aggregated network (referred\nto as IRA ego network or IRA aggregated ego network, interchangeably) by consider-\ning all types of interaction and removing self-loops. As usual, an edge connecting node\nuwithnode vmeanstherewasatleastonetypeofinteractionbetweenthem.Theedgeis\nweightedbythenumberofinteractionsamong uandv.Thedirectionsofthelinksareac-\ncordingtothe\ufb02owofinformation.Theresultingstructureisadirectedweightednetwork\nof179,783nodes(524ofwhichareIRAaccounts)and432,429edges(seeTable 2).\n2.4 Samplingstrategies\nTo avoid sample bias, we randomly extracted the same amount as the number of IRA\nusers for each group and category (making sure not to select the IRA users). We average\nthe in/out degree over 1000 realizations. For each realization, sampling was without re-\nplacement. We refer to them as (\u2212\u2212\u2192ks\ntypei,\u2212\u2212\u2192ks\ntypej), where the superscript sindicates that the\ndegree considered comes from the sampled nodes. Additional \ufb01le 1Table 7 displays the\nsampledaveragedegreeforeachgroupineachnewscategory,togetherwiththestandard\nerror.RefertoAdditional\ufb01le 1Table8foraviewofthenon-sampledcase.\n2.5 Two-sampleKolmogorov-Smirnovtest\nTotestfordi\ufb00erencesinthein/out-degreeactivity ofsuspended,notfound,notveri\ufb01ed,\nveri\ufb01ed, and IRA accounts, we employed a Two-sample Kolmogorov-Smirnov test with\nnull hypothesis H0:Fi(x)=Fj(x)w h e r ex=ks\ntype.T h es u p e r s c r i p t sindicates that the de-\ngreeconsideredcomesfromthesamplednodes, i,j\u2208(suspended,notfound,veri\ufb01ed,not\nveri\ufb01ed, IRA), and type \u2208(in, out).The null hypothesis, denoted as H0, assumes that the\nactivity of a given user in each interaction type, represented by x=(xout,xin), follows the\ncondition Fout(x)=Fin(x)f o re v e r y x. Here,Fout(x)a n dFin(x) represent the cumulative\ndensityfunctions(CDF)forthe\u201cout\u201dand\u201cin\u201ddirections,respectively.Thealternativehy-\npothesis, on the other hand, suggests that Fout(x)<Fin(x)( o rFout(x)>Fin(x)) for at least\nonex.\nIt is worth noting that these hypotheses describe the CDFs of the underlying distri-\nbutions, not the observed data values. For example, suppose xout\u223cFoutandxin\u223cFin.I f\nFout(x)>Fin(x)forallx,thevalues xouttendtobelessthan xin.W esetalevelof5%,mean-\ning that we will reject the null hypothesis and favor the alternative if the p-value is less\nthan0.05.\n2.6 Supportersidenti\ufb01cation\nSimilarly to [ 3] ,w eu s eas u p e r v i s e dc l a s s i \ufb01 e rt oc l a s s i f ye a c ht w e e ti nf a v o ro fD o n a l d\nTrump or Hillary Clinton. The training set was built using the hashtag co-occurrences\nnetworktoinvestigateTwitterusers\u2019opinionsonthetwopresidentialcandidates.Weclas-\nsi\ufb01ed a user as a supporter of Trump if the number of her/his tweets supporting Trump\nNpro-TisgreaterthanthenumberoftweetssupportingClinton Npro-C.W ede\ufb01nethesup-\nportofagivenusertowardthecandidatesas S=Npro-T\u2013Npro-C.IfS>0,theusersupports\nT rump.Otherwise,theuserislikelytosupportHillary .Thehighestthevalueof Sinabso-\nluteterms,thestrongestthesupport.Consideringalltheusersinthedataset,65%ofthem\nsupport Hillary Clinton while 28% are in favor of Donald Trump (7% are unclassi\ufb01ed as\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page6of19\ntheyhavethesamenumberoftweetsineachcamp)[ 3].Whenconsideringonlytheusers\ninteracting with IRA accounts, 25% of the users are classi\ufb01ed as Clinton supporters, and\n72.6%oftheusersareclassi\ufb01edasTrumpsupporters.\n2.7 Supportingclasses\nTodistinguishbetweenstrongandweaksupportersbasedontheir Svalues,weutilizethe\ninterquartile range (IQR) of S,d e \ufb01 n e da sI Q R= Q3\u2013Q1,w h e r eQ3represents the third\nquartileand Q1representsthe\ufb01rstquartile.Inthisanalysis,apositivevalueof Sindicates\na likelihood of supporting Trump, while a negative value of Ssuggests a preference for\nClinton. The magnitude of Squanti\ufb01es the degree of support for a particular candidate.\nUserswhoconsistentlyretweetinfavorofTrumpreferredtoasstrongsupporters,exhibit\nhigherSvalues. Conversely, users with signi\ufb01cantly negative Svalues can be associated\nwith strong supporters of Clinton. Users with S= 0 are categorized as undecided since\ntheydisplayanequalnumberoftweetssupportingbothcandidates.\nInadditiontotheundecidedcategory,wede\ufb01nefourclassesofsupportersbasedonthe\ninterquartile range (IQR) of Svalues. For Trump supporters, the IQR is calculated over\nthe values of S>0,whileforClintonsupporters,theIQRiscomputedusingtheabsolute\nvaluesof S<0.WeidentifyweakTrump(Clinton)supportersasuserswhose Svaluesfall\nbelowQ3+1.5IQR.Ontheotherhand,strongTrump(Clinton)supportersareindividuals\nwhoseSvalues exceed Q3+1.5IQR. This classi\ufb01cation scheme allows us to distinguish\nbetweendi\ufb00erentlevelsofsupport.\nAlternatively,wecanconsidertheentiredistributionof Sandde\ufb01nestrongTrumpsup-\np o r t e r sa su s e r sw i t h Svalues above Q3+ 1.5IQR. Similarly, strong Clinton supporters\narethosewith Svaluesbelow Q1\u20131.5IQR.WeakTrumpsupportersfallwithintherange\nQ1\u20131.5IQR \u2264S\u2264Q3+1.5IQRwith S>0,whileweakClintonsupportersfallwithin the\nsame range but with S<0. This alternative classi\ufb01cation, in the case of users interacting\nwith IRA, results in 12.7% of users identi\ufb01ed as strong Trump supporters, 60% as weak\nTrump supporters, 2.6% as strong Clinton supporters, and 22.5% as weak Clinton sup-porters.Thesepercentagesslightlydi\ufb00erfromtheonesobtainedusingtheotherapproach\nmentionedinthemainpaper.\n3R e s u l t s\n3.1 Accountscharacterization\nOur analysis commences with a general characterization of the accounts active on the\nTwitter platform around the topic \u201celection\u201d during the 2016 US presidential elections.\nRefertotheMethodssection,speci\ufb01callySect. 2.1foracomprehensivedescriptionofthe\ndataset.Usersinthisdatasetareclassi\ufb01edintodistinctgroups,encompassingIRA-\ufb02aggedaccountsbyTwitter,alongwithnotfound,notveri\ufb01ed,veri\ufb01ed,andsuspendedaccounts.\nThissectionaimstocharacterizethevariousaccountgroupsintermsoftheinformation\ntheyspreadonTwitter anddrawcomparisonswith theIRA-\ufb02aggedaccounts.The ratio-\nnaleforusingIRAasabenchmarkinouranalyses,asexplainedintheintroduction,isto\nassess theimpact ofotheraccountsdisplayingbehavior similartoIRA,speci\ufb01callythose\nfavoringtherightpoliticalcandidate.\nTheinitialdistinctionamongaccounttypesconcernsthekindofinformationusersen-\ngage with (see Sect. 2.2). Veri\ufb01ed accounts, as shown in Fig. 1a, have a higher fraction of\ncenterandleft-related(leftandleft-leaning)tweets,whileIRA,suspended,andnotfound\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page7of19\nFigure1 Distributionoftweetsandclients\u2019typeperaccounttype.(a)ThefractionoftweetswithaURL\npointingtoawebsitebelongingtooneofthecategories.Normalizationiscomputedpergroup,meaning\nthat,forexample,thefractionofnotveri\ufb01edtweetspercategorysumsuptoone.Ineachofthe\ufb01vegroups,\ntheorderofbarsiskeptthesame.Wealwaysdisplaybarsinthefollowingorders:fakenews,extremebias\nright,right,rightleaning,center,left-leaning,left,andextremebiasleft.SeeAdditional\ufb01le 1Table 2 for further\ndetails.(b)ThefractionoftweetswithaURLpointingtoawebsitebelongingtooneofthecategoriesposted\nthroughnono\ufb03cialsources.RefertoAdditional\ufb01le 1Table3foracompleteviewofthepercentages\naccounts exhibit a higher fraction of right-related tweets. Unlike IRA accounts, which\nshowasigni\ufb01cantpercentageofcenterandleft-leaningrelatednews,suspendedaccountshave the lowest fraction of left-related content and the highest fraction of fake-relatedcontent.Additional\ufb01le 1Tables2and3provideafullbreakdownofthesepercentages.\nInFig.1b,weshowthepercentageoftweetssharedthroughnono\ufb03cialclientsforeach\nmediacategory.Toensurecomparability,wenormalizethepercentagesperaccounttype\nbythetotalgroupactivity,includingbotho\ufb03cialandnono\ufb03cialclients.Foro\ufb03cialclient\ndetails, refer to Additional \ufb01le 1Table 5. Analyzing tweet clients o\ufb00ers valuable insights\nintotweetorigins,especiallytheirpotentialbot-generatednature.Nono\ufb03cialclients,en-compassingapplicationslike iftttanddlvrit,spanprofessionalautomationtoolstomanu-\nallyprogrammedbots.\nFigure1bshowsthatveri\ufb01edaccountsexhibitthehighestfractionoftweetsfromnonof-\n\ufb01cialclients,constituting22.9%oftheirtotalactivity.Themostfrequentlyusedclientsforveri\ufb01edaccounts,suchas Hootsuite andSocial\ufb02ow ,arerenownedforautomatinginterac-\ntionswithintheTwitterecosystem.Theseveri\ufb01edaccounts,oftenbelongingtojournalists\nor public \ufb01gures, utilize such tools for social media activities. Suspended accounts ranksecond at 23.9%, with Dlvritas their primary client, closely followed by IRA accounts at\n22.9%,mostlyrelyingon Twitterfeed forautomatedactivity.Notveri\ufb01edandnotfoundac-\ncountsexhibitbelow13%non-o\ufb03cialclientusage,with Twitterfeed beingthemostused\nclient. It is noteworthy that veri\ufb01ed accounts predominantly used non o\ufb03cial clients todisseminatecenter,left-leaning,andleftnews.Incontrast,IRAaccountsutilizednono\ufb03-cialclientsmainlyforright-relatedcontent,withasmallerpercentageofleft-leaningma-\nterial.Suspendedaccountsemployednon-o\ufb03cialclientsprimarilyforfakenewsdissem-\nination.\nFigure2shows the proportion of original tweets shared by each group and category.\nThe normalization is over the total activity of each account type, meaning that the sum\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page8of19\nFigure2 Shareoforiginaltweetspergroup.The\npercentageoforiginaltweetspergroupandnews\ncategoryispresented,withnormalizationconducted\noverthetotalactivityofeachgroup.Thismeansthat\nthesumofthepercentagespergrouprepresentsthetotalfractionoforiginaltweets.Furtherdetailscanbe\nfoundinAdditional\ufb01le 1Table 6\nTable 1Retweetcategories\u2019networks.Thetablecontainsthecharacteristicsofeachoftheeight\nretweetnetworks,suchasthenumberofnodes N,thenumberofedges E,andtheaveragedegree\n/angbracketleftkin/angbracketright=/angbracketleftkout/angbracketright=/angbracketleftk/angbracketright/2.WealsoreportthenumberofIRAusersineachretweetnetwork NIRA,aswell\nastheiraveragein-degree /angbracketleftkin/angbracketrightandout-degree /angbracketleftkout/angbracketright\nFull Network IRA\nNE /angbracketleftk/angbracketright/2 NIRA /angbracketleftkout/angbracketright/angbracketleft kin/angbracketright\nFake 175,605 1,143,083 6.5 54 32.5 5.4\nExtremebiasright 249,659 1,637,927 6.6 70 27.3 7.1\nRight 345,644 1,797,023 5.2 84 30.1 4.7\nRightleaning 216,026 495,307 2.3 67 6.3 1.7\nCenter 864,733 2,501,037 2.9 163 4.6 2.6\nLeftleaning 1,043,436 3,570,653 3.4 140 8.9 2.2\nLeft 536,903 1,801,658 3.4 105 4.3 2.4\nExtremebiasLeft 78,911 277,483 3.5 10 0.0 1.6\nof the percentages per each account type represents the total fraction of original tweets.\nThe group with the highest share of original tweets is the veri\ufb01ed one, with a value of71.2%.Thisgroupalsoshowsthelowestshareoforiginaltweetslinkingtofakenewsand\nthe highest share of original tweets related to the center, left-leaning, and left categories.\nIRAaccountsinsteadshowtogetherwithnotfoundaccounts,thelowestshareoforiginaltweets, with a percentage of 29.4% and 27.3%, respectively. Most of the original tweets\nshared by IRA belong either to the left leaning or center categories. Not found accounts\nhaveamorehomogeneousdistributionoforiginaltweetsamongthedi\ufb00erentcategories.Suspended accounts, with 38.6% of original tweets, show the highest percentage of orig-\ninal tweets related to the fake category and the extreme bias right category. Not veri\ufb01ed\naccounts(32%oforiginaltweets)showhigherpercentagesinthecenterandleftleaning.\nFinally, we test whether suspended, not found, veri\ufb01ed, not veri\ufb01ed, and IRA behave\ndi\ufb00erentlyintermsoftheirin/outactivityineachnewscategorynetwork(seeSect. 2.3and\nTable1).Weemployatwo-sampleKolmogorov-Smirnovtest[ 28,29](two-sidedversion,\nseeSect. 2.5)withnullhypothesis H\n0:thedataaredrawnfromthesamedistribution.We\nperformed the test for each two-pair combination of the groups (\u2212\u2212\u2192ktypei,\u2212\u2212\u2192ktypej), withi,j\u2208\n(suspended, not found, veri\ufb01ed, not veri\ufb01ed, IRA), and type \u2208(in, out). The\u2212\u2212\u2192ktypevector\ncontains the values of /angbracketleftktype/angbracketrightfor each category network. We adapt sampling strategies\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page9of19\nFigure3 Two-sampleKolmogorov-Smirnovtests.Results\nofthetwosampleKolmogorovSmirnovtestbetween\ngroupsbasedontheiroutdegree.Yellowboxesindicate\nrejectionofthenullhypothesisinfavorofthetwo-sided\nalternative,suggestingthatthedatawerenotdrawnfrom\nthesamedistribution.Weobservethat H0isonlyrejected\nbetweenIRAandsuspendedaccounts,indicatinga\nsimilarityintheout-degreeactivityofthesetwogroups.\nFurthermore,veri\ufb01edaccountsexhibitanout-degree\nactivitythatdi\ufb00ersfromthatoftheothergroups\nto avoid sampling bias error, as explained in Sect. 2.4. Refer to Additional \ufb01le 1Table 7\nfor a view of the sample degrees. While the news category networks considered here are\nnot weighted, we did check for di\ufb00erences in the weighted case and could not \ufb01nd any\nsigni\ufb01cantvariations.\nFigure3showstheresultsofthetestsfortheout-degreeandin-degree,respectively.We\nused a heatmap representation, where the yellow color indicates the rejection of the null\nhypothesis H0in favor of the default two-sided alternative, suggesting that the data were\nnotdrawnfromthesamedistribution.\nIncomparingout-degreeactivity,veri\ufb01edaccountsconsistentlyexhibitdistinctbehavior\nfrom other groups, rejecting the null hypothesis. IRA accounts, however, display similarbehaviortosuspendedaccountswhiledi\ufb00eringfromveri\ufb01ed,notfound,andnotveri\ufb01ed\naccounts.Intermsofin-degreeresults,veri\ufb01edaccountsdi\ufb00erfromsuspended,notfound,\nandnotveri\ufb01edaccounts,butalignwithIRAusers.\nAmongthevariousgroupsofaccounts,ouranalysesrevealthatIRAaccountsandsus-\npended accounts share similar interests in terms of the news outlets they reference, with\nsuspendedaccountsshowingahigherinterestinfakeandextremebiasrightrelatedcon-tent. Both groups also demonstrate a similar use of non-o\ufb03cial clients, though with dif-\nferencesintheinformationtransmittedthroughthem.Notverydissimilararenotfound\naccounts,which,however,displayverylowusageofnono\ufb03cialclients.\nNotably,ouranalysesuncoverparallelsinthebehaviorofIRAandsuspendedaccounts\nconcerning out-degree activity in each category. These resemblances might signify a\nshared e\ufb00ort by suspended accounts to steer Twitter discourse toward the right politi-cal agenda. However, it is crucial to emphasize that while this similarity with IRA does\nnotimplycollaboration,itishighlyimprobablethattheentiresetofsuspendedaccounts\nis involved in this endeavor. Therefore, identifying a representative subset of suspendedaccountsparticipatinginthisintentbecomesimperative.\n3.2 IRAegonetwork\nTo pinpoint a representative subset of suspended accounts employing strategies akin to\nIRA accounts, we look into the IRA ego network. This network encompasses all users\ninteractingwithIRAthroughretweets,mentions,quotes,orreplies(seeSect. 2.3).Table2\nsummarizesthekeyfeaturesofthesenetworks.\nWe analyze the interactions of users with di\ufb00erent account types, such as veri\ufb01ed, not\nveri\ufb01ed, suspended, and not found. Speci\ufb01cally, we focus on the top 1000 users involved\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page10of19\nTable 2Interactionsegonetworks.Thetablecontainsinformationabouteachtypeofinteraction\nnetwork,aswellasinformationabouttheiraggregatedversion.Wereportthenumberofnodes N,\nedgesE,theaveragedegree /angbracketleftk/angbracketright,andthenumberofIRAnodes NIRA,withtheirin/out-degree.\nRetweetingandmentioningarethetwomostfrequenttypesofinteractionsbetweenIRAandnon-IRAusers\nFullnetworks IRAusers\nNE /angbracketleftk/angbracketright NIRA /angbracketleftkout/angbracketright/angbracketleft kin/angbracketright\nRetweeting 154,366 360,265 2.3 497 468.4 262.0\nMentioning 70,926 197,644 2.8 508 353.1 41.7\nReplying 14,225 16,775 1.2 193 71.2 16.4\nQuoting 19,195 31,538 1.6 353 36.4 53.6\nAggregated 179,783 432,429 2.4 524 486.8 343.8\nFigure4 Accountstatus:top1000activeusers.Weshowthefractionofthetop1000activeusersperstatus\n(in%)ineachinteractionnetwork(retweetinblue,mentioninred,replyingreen,andquoteingray).Possible\nstatusesare:Veri\ufb01ed,Suspended,NotVeri\ufb01edandNotFound.(a)\u201cout\u201ddirection:usersareretweeted,\nmentioned,quoted,orrepliedtobyIRAusers.Onaverage,18.4%oftheseusershaveveri\ufb01edaccounts,49.4%\narenotveri\ufb01ed,18.9%aresuspended,and11.4%arenotfoundaccounts(b)\u201cin\u201ddirection:usersretweet,\nmention,quote,orreplytoIRAusers.Onaverage,45.1%ofthemarenotveri\ufb01ed,35.7%issuspended,and\n17.1%isnotfound\nineachinteractiontype(retweet,reply,quote,andtweet)byconsideringbothinandout\ndegrees. For instance, in the case of retweet interaction, we consider the top 1000 (most\nretweeted) non-IRA users who were retweeted by IRA accounts in the \u201cout\u201d direction.\nSimilarly,inthe\u201cin\u201ddirection,weexaminethetop1000(mostretweeting)non-IRAuserswhoretweetedIRAaccounts.\nFigure4adisplaysthedistributionoftheusersinteractedbyIRA(connectionsgofrom\nthe non-IRA users to IRA) into the di\ufb00erent account types. On average, 18.4% of these\nusers have veri\ufb01ed accounts, 49.4% are not veri\ufb01ed, 18.9% are suspended accounts, and11.4%arenotfoundaccounts.Notably,amongtheveri\ufb01edaccounts,weidenti\ufb01edtheof-\ufb01cialpro\ufb01leofPresident DonaldTrumpandpopularnewsoutletssuch asTheGuardianand FOX NEWS. See Additional \ufb01le 1Tables 9, 10, 11, and 12 for a list of the top 20\naccounts.Figure 4b,displaysthedistributionoftheuserswhointeractwithIRA(connec-\ntionsgofromtheIRAtonon-IRAusers).Noneofthetop1000userswhoengagewithIRAhaveveri\ufb01edaccounts.Onaverage,45.1%ofthemarenotveri\ufb01ed,35.7%issuspended,and17.1% is not found. See Additional \ufb01le 1Tables 13, 14, 15 and 16 for a list of the top 20\naccounts.\nItisworthnotingthatthenumberofsuspendedaccountsinteractingwithIRA(amount-\ningto30,622)isnearly60timeslargerthanthenumberofIRAaccounts.\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page11of19\nTable 3Groupsclasses.Thetablepresentsthedistributionofdi\ufb00erentusertypes,namelynotfound,\nnotveri\ufb01ed,suspended,veri\ufb01ed,andIRAusers,amongthevarioussupportingclasses.The\npercentagesinthetablearenormalizedperaccounttype,meaningthatthesumofpercentagesofa\ngivenaccounttypeforeachsupportingclassaddsupto100%\nStrong\nTrump\nsupportersWeak\nTrump\nsupportersStrong\nClinton\nsupportersWeak\nClinton\nsupportersUndecided\nNotFound 8.13 73.44 2.17 14.49 1.76\nNotVeri\ufb01ed 6.66 63.79 4.20 22.94 2.41\nSuspended 14.43 67.93 3.56 11.78 2.30\nVeri\ufb01ed 0.25 15.84 11.63 68.95 3.33\nIRA 0.32 34.62 0.00 60.26 4.81\nIt is noteworthy to observe that the majority of active users interacting with IRA are\nsuspendedusers.Moreover,giventhatthemostcommontypeofinteractionisretweeting,\nas indicated in Table 2, this suggests that most users tend to retweet IRA, likely with the\nintent to disseminate similar types of information. This ultimately con\ufb01rms the notionthatsuspendedaccountsandIRAsharesimilarviews.\nEgo polarization Analyzing user preferences in terms of political orientations (see\nSects.2.6and2.7) reveals, as expected, a higher presence of right supporters in the IRA\nego network. Speci\ufb01cally, 8.1% of users are strong supporters of Trump, 4% are strongsupportersofClinton,64.5%areweaksupportersofTrump,21.1%areweaksupportersofClinton, and the remaining 2.3% of users are categorized as undecided. It\u2019s important tonotethatwhencalculatinguserpolarizationincomputing,weconsiderallusers,regard-less of their account status. The majority of suspended accounts are classi\ufb01ed as Trumpsupporters, either weak or strong. This is detailed in Table 3, where we also provide the\npercentagesbrokendownbyaccountstatus.\nThisalignswiththenotionthatthissubsetofsuspendedaccountswasorientedtoward\ntherightagenda.Additionaldetailsabouttheusers\u2019classi\ufb01cationscanbefoundinAddi-tional\ufb01le 1Sect.4.\nIt is also worth noticing that we found a substantial number of IRA accountsclassi\ufb01ed\nas weak Clinton supporters. This suggests a dual strategy employed by the IRA in theircampaign,asalreadysuggestedintheexistingliterature[ 18,30].Oneaspectofthisstrat-\negy involves reinforcing the opinions of users classi\ufb01ed as strong Trump supporters. Ontheotherhand,anothersetofIRAaccountsaimstoexpandtheirreachwithinleft-leaningaccountsbymentioningveri\ufb01edaccountsclassi\ufb01edasweakandstrongTrumpsupporters.\nCommunity structure The exploration of this dual strategy and the role played by sus-\npendedaccountsinitcontinuesthroughtheidenti\ufb01cationofcommunitieswithintheag-gregatedIRAegonetwork.Thisnetworkisformedbymergingthenetworksforthefourtypesofinteraction,asdetailedinSect. 2.3.\nWeperformmultiscalecommunitydetectiontothelargestconnectedcomponentofthe\nundirectedweightedversionoftheaggregatednetwork,whichcontains99.9%oftheinitialnodes.Toassesscommunitystability,weutilizeMarkovstability,asdetailedinAdditional\ufb01le1Sect.5.\nWe reveal the existence of two prominent communities, a \ufb01nding that adds intrigue as\nit aligns with the notion that the IRA orchestrated two distinct micro-campaigns. These\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page12of19\nTable 4IRAegonetwork:partitioncharacteristics.CharacteristicsofthecommunitiesintheIRAego\nnetwork.Wedisplayinformationforthecommunitieswithatleast10%ofthenodesoftheoverall\nnetwork.Foreachcommunity,wereportthenumberofnodes,thenumberofIRAaccounts,the\nshareofsupportingclassesandthedistributionofusersamongdi\ufb00erentgroups\nCommunityright Communityleft\nn\u00b0nodes 135,846 24,318\nn\u00b0IRAnodes 160 114\nUndecided 1.8% 4.1%\nStrongTrumpsupporters 9.5% 2.1%\nWeakTrumpsupporters 76.6% 10.5%\nStrongClintonsupporters 1.8% 13.0%\nWeakClintonsupporters 10.3% 70.2%\nNotFound 21.2% 11.6%\nNotVeri\ufb01ed 56.6% 63.8%\nSuspended 20.3% 9.6%Veri\ufb01ed 1.7% 14.5%\nIRA 0.1% 0.5%\ncommunities re\ufb02ect the polarization of users. In the biggest community, 76.6% of users\nareclassi\ufb01edasweakTrumpsupportersand9.5%asstrongTrumpsupporters,whilethe\nsecond biggest community left has 70.2% of weak Clinton supporters users and 13% of\nstrong Clinton supporters users, see Table 4. These results align with the existing liter-\nature [18,30]. Moving forward, we will refer to these communities as the right and left\ncommunities.\nThe distinction in the political orientation of these two communities is further sup-\nported by analyses of the hashtag clouds constructed from the content shared by users,\nasdiscussedinAdditional\ufb01le 1Sect.6.Usersintherightcommunitytendtosharehash-\ntags in support of Trump and against Clinton, while the opposite holds true for the leftcommunity.\nWithintherightcommunity,suspendedaccountscomprise20%ofthetotalnodesinthe\ncommunity. This percentage decreases by more than half in the left community (refer to\nTable4).Thisoutcomesuggestsadi\ufb00erenceinstrategiesbetweensuspendedaccountsand\nIRA,withIRAimplementingadualstrategy(targetingbothrightandleftusers),whilesus-\npendedaccountspredominantlyfocusontargetingright-orientedusers.Thesesuspended\nusers account for 21.7% of the interactions, with the directions of the connections goingfrom IRA to suspended accounts, as indicated in Additional \ufb01le 1Fig. 7 and Additional\n\ufb01le1Table 20. In the case of the left community, the type of interaction is inverted, and\nin most cases, it is the IRA engaging with the other groups, particularly not veri\ufb01ed andveri\ufb01ed, with the connections going from suspended to IRA accounting for 12.5% of theoverallconnectionsinthecommunity.\nTheabove-presentedresultsdemonstratethatutilizingtheIRAegonetworkasaproxy\nto identify a contained group of suspended accounts aligning with the right ideologies isan e\ufb00ective strategy. We \ufb01nd that the majority of these suspended users are classi\ufb01ed as\nTrump supporters. By examining the dual strategies employed by the IRA campaign, we\nreveal that the majority of suspended accounts were following the strategies of the rightcommunity, speci\ufb01cally targeting Trump supporters. The directions of the connections\nsuggest that this was primarily done through interactions with IRA accounts, including\nretweets,mentions,quotes,andreplies.\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page13of19\nExpandedegonetwork TheIRAegonetworkservesasaproxyforidentifyingsuspended\naccountsthatsharesimilaritieswithIRAaccounts.However,thisdoesnotensurethatthissubset covers all suspended accounts involved in promoting right-related content. Addi-\ntional suspended accounts may exist in the dataset, but rather than interacting directly\nwith IRA, they might be interacting with the suspended accounts that are engaging withIRA.Toinvestigatethispossibility,weexpandedtheIRAaggregatednetworkfromtheear-\nliersectionbyincorporatinginteractionsinvolvingthissubsetofsuspendednodesandall\notherusers.Inessence,wecreatedthe\u201csuspended+IRA\u201degonetwork.Thisnetwork,akinto the previous section, was constructed based on the four types of Twitter interactions.\nAdditional\ufb01le 1Table17providescomprehensiveinformationregardingeachinteraction\nnetwork.\nTheinclusionofbothIRAaccountsandsuspendedaccountssigni\ufb01cantlyampli\ufb01esthe\ndimension of the aggregated network, increasing the number of nodes from 179,783 in\nthe IRA ego network to 1,723,477 in the expanded ego network. This expanded networkexhibits45timesmoreconnectionsthantheaggregatedegonetwork,withanaveragede-\ngreeof /angbracketleftk/angbracketright=11.SimilartotheIRAegonetwork,retweetingandmentioninginteractions\nremainthemostcommontypesofinteractionsintheexpandednetwork.\nNext,weperformedamulti-scalecommunitydetectionanalysisandexploreddi\ufb00erent\nparameter values to identify the optimal partition. The resulting partition (resulting in\ntwocommunities)preservesthecommunities\u2019polarization,asshowninTable 5,withthe\ntwo expanded communities being mostly composed of supporters of Trump and Clin-\nton. When scrutinizing the composition of these two communities, it becomes evident\nthat they are predominantly comprised of not veri\ufb01ed, veri\ufb01ed, and not found accounts.Suspended accounts,despite constituting a smaller percentage comparedto the IRA ego\nnetwork, also exhibit signi\ufb01cantly lower activity. Their number of connections in both\ndirectionsrepresentlessthan5%ofthetotalconnections,asillustratedinTable 5.\nThese \ufb01ndings indicate minimal and negligible interactions between suspended ac-\ncountswithintheIRAegonetworkandothersuspendedaccounts.Thisemphasizesthat\nthesuspendedaccountsidenti\ufb01edintheIRAegonetworkrepresentthemostsigni\ufb01cantgroup of suspended accounts disseminating right-related information, similar to IRA, in\ntheTwitterdiscourse.\nTable 5Expandedegonetwork:partitioncharacteristics.Characteristicsofthecommunities.We\ndisplayinformationforthecommunitieswithatleast10%ofthenodesoftheoverallnetwork.Foreachcommunity,wereportthenumberofnodes,thenumberofIRAaccounts,theshareofsupportingclasses,andthedistributionofusersamongdi\ufb00erentgroups\nCommunityE-right CommunityE-left\nn\u00b0nodes 718,825 314,559\nn\u00b0IRAnodes 25,565 4359\nUndecided 5.4% 4.1%\nStrongTrumpsupporters 10.2% 2.6%\nWeakTrumpsupporters 55.9% 16.0%\nStrongClintonsupporters 3.7% 10.6%\nWeakClintonsupporters 24.8% 66.6%\nNotFound 19.8% 15.9%\nNotVeri\ufb01ed 60.2% 69.8%\nSuspended 14.2% 8.9%\nVeri\ufb01ed 2.2% 4.0%\nIRA 3.6% 1.4%\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page14of19\n3.3 Causalnetworkpatterns:IRAnodesversussuspendednodes\nThissectioninvestigatestheimpactthatsuspendedaccountsandIRAhaveonshapingthe\nTwitterdiscourseduringthe2016USpresidentialelections.Speci\ufb01cally,wescrutinizethecausalrelationshipsbetweenIRA(andsuspendedaccounts)tweetactivityandtheactivityof supporting classes, namely weak Trump supporters, weak Clinton supporters, strong\nTrumpsupporters,strongClintonsupporters,andundecidedusers.\nWe employ a multivariate Granger causal network reconstruction approach to estab-\nlishlinksbetweentheactivityofIRA(suspended)nodesandthesupportingclasses.Thisis achieved using the causal discovery algorithm [ 31\u201333], which tests the independence\nof each pair of time series for several time lags conditioned on potential causal parentsusing a Partial Correlation Independence test and it removes spurious correlations. Weuse the algorithm for variable selection and perform a linear regression using only the\ntrue causal link discovered. We choose linear causal e\ufb00ects for their reliability and inter-\npretability, which allows us to compare causa l e\ufb00ects as \ufb01rst-order approximations, esti-\nmate the uncertainties of the model, and construct a causal-directed weighted network[34].Thecausale\ufb00ectbetweenatimeseries X\niandXjat a time delay \u03c4,ICE\ni\u2192j(\u03c4),isdeter-\nminedbytheexpectedvalueof Xj\nt(inunitsofstandarddeviation)if xi(t\u2013\u03c4)isperturbedby\nonestandarddeviation[ 26,34].However,anassumptionofcausaldiscoveryiscausalsuf-\n\ufb01ciency ,whichassumesthateverycommoncauseofanytwoormorevariablesispresent\ninthesystem[ 31].Inourcase,causalsu\ufb03ciencyisnotsatis\ufb01edbecauseTwitter\u2019sactivity\nisonlyapartofalargersocialsystem.Therefore,theterm\u201ccausal\u201dshouldbeunderstoodasrelativetothesystemunderstudy[ 26].\nWe created time series of Twitter activities by counting the number of tweets posted\nby each node belonging to one of the supporting classes at a 15-minute resolution. Weonlyconsiderusersthatbelongtotheveri\ufb01edandnotveri\ufb01edclasses,andonlyconsider\nthe tweets coming from o\ufb03cial clients. Instead, for the IRA (suspended) nodes, we con-\nsiderallthetweets,nomattertheclients.Toremovetrendandcircadiancyclesfromthetimeseries,weutilizedtheSTL(seasonaltrenddecompositionprocedurebasedonLoess)method[ 35],whichdecomposesatimeseriesintoseasonal(inthiscase,daily),trend,and\nremaindercomponents.WeusedtheresidualsoftheSTL\ufb01lteringofthe15-minutetweetvolumetimeseries.\nIn simpler terms, Granger causality examines whether past retweet behaviors in one\ngroupcanassistinforecastingtheretweetbehaviorsoftheothergroup.Itdoesn\u2019timplyadirectcause-and-e\ufb00ectrelationshipbutratherinvestigateswhetherchangesinonegroup\u2019sactivityprecedechangesintheothergroup\u2019sactivity.\nTables6and7present the causal relationships among di\ufb00erent groups in the two sce-\nnarios: one with only IRA nodes and the other with suspended nodes. The direction ofeachlinkisfromthecolumngrouptotherowgroup.Forexample,consideringthestrong\nTable 6CausalLinks:IRA.Weshowthevalueofthemaximalcausale\ufb00ect,\nICE,max\ni\u2192j=max0<\u03c4\u2264\u03c4max|ICE\ni\u2192j(\u03c4)|betweeneachpair( i,j)ofactivitytimeseries,where \u03c4max=18\u00d715\nmin=4.5histhemaximaltimelagconsidered,withstandarderrors.Thearrowsindicatethedirectionofthecausale\ufb00ect.Foreachactivitytimeseries,weindicateinboldthemostimportant\ndriversofactivity(excludingthemselves).Inblue,wehighlighttheauto-correlationofeachnode\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page15of19\nTable 7CausalLinks:Suspended.Weshowthevalueofthemaximalcausale\ufb00ect,\nICE,max\ni\u2192j=max0<\u03c4\u2264\u03c4max|ICE\ni\u2192j(\u03c4)|betweeneachpair( i,j)ofactivitytimeseries,where \u03c4max=18\u00d715\nmin=4.5histhemaximaltimelagconsidered,withstandarderrors.Thearrowsindicatethe\ndirectionofthecausale\ufb00ect.Foreachactivitytimeseries,weindicateinboldthethreemostimportantdriversofactivity(excludingthemselves).Inblue,wehighlighttheauto-correlationofeachnode\nFigure5 CausalNetworks.(a)Graphshowingthemaximalcausale\ufb00ectsbetweentheactivityoftheIRA\nnodesandthesupportingclassesofthepresidentialcandidates.Arrowsindicatethedirectionofthemaximal\ncausale\ufb00ect( \u22650.16)betweentwoactivitytimeseries.Thewidthofeacharrowisproportionaltothe\nstrengthofthecausation,andthesizeofeachnodeisproportionaltotheauto-correlationofeachtime\nseries.DarkblueanddarkredhighlightthecontributionofstrongClintonandTrumpsupporters,respectively.\nLightblueandlightredareassociatedwiththeweakClintonandTrumpsupporters,graywiththeundecided\nusers,andorangewiththeIRAnodes.Thecausalrelationprimarily\ufb02owsfromstrongsupportersofboth\nTrumpandClintontoweakandstrongsupportersofopposingpoliticalcandidates.Additionally,weak\nsupportersfrombothsidesplayaroleinin\ufb02uencingtheundecidedgroup,withweakTrumpsupporters\nreceivingsupportfromstrongTrumpsupportersintheire\ufb00orts.Notably,IRAnodesdonotplayasigni\ufb01cant\nroleinthiscausalnetwork,suggestingthattheyhavelimitedin\ufb02uenceonshapingTwitterdiscourse.(b)\nGraphshowingthemaximalcausale\ufb00ectsbetweentheactivityofthesuspendednodesandthesupporting\nclassesofthepresidentialcandidates.Arrowsindicatethedirectionofthemaximalcausale\ufb00ect( \u22650.2)\nbetweentwoactivitytimeseries.StrongTrumpsupportershaveacausale\ufb00ectonSuspendednodes,which,\ninturn,haveacausalin\ufb02uenceonbothweaksupportersandtheundecidedgroup.Additionally,weak\nsupporterscontinuetoexertacausale\ufb00ectontheundecidedgroup.StrongTrumpsupportershaveacausal\ne\ufb00ectonstrongClintonsupporters,butnotvice-versa\nTrumpsupporters,theircausale\ufb00ectontheweakClintonsupportersismeasuredat0.16\n\u00b10.011,asshowninTable 6.Theblueentriesinthetablesrepresenttheauto-correlation\nof each time series. In both scenarios, the auto-correlations exhibit the strongest causale\ufb00ectsforalltimeseries,exceptfortheundecidedgroup.\nToidentifythemostsigni\ufb01cantcausallinks,athresholdof0.16(0.20forthesuspended\nscenario)wassetonthecausalrelation,selectingconnectionsthataccountfor75%ofthetotal e\ufb00ect. These selected links are highlighted in bold in the tables. Figures 5aa n d5b\nvisualizethecausalnetworksconstructedusingtheseconnections.Thenodesarecolored\nasfollows:darkredforstrongTrumpsupporters,darkblueforstrongClintonsupporters,lightredforweakTrumpsupporters,lightblueforweakClintonsupporters,orangefortheIRA nodes, and gray for the undecided group. Arrows indicate the direction of maximalcausale\ufb00ect( \u22650.16and \u22650.20)betweentwoactivitytimeseries.Thewidthofeacharrow\nrepresents the strength of the causation, and the size of each node is proportional to theauto-correlationofeachtimeseries.\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page16of19\nFigures5aandb,illustratecontrastingscenariosintermsofthecausalnetworkstructure\nwhenconsidering IRAnodesaloneversussuspendednodes.In Fig. 5a,whichrepresents\nthecausalnetworkconsideringIRAnodesonly,thein\ufb02uenceprimarily\ufb02owsfromstrong\nsupportersof both Trump and Clinton to weak and strong supportersof opposing polit-\nical candidates. Additionally, weak supporters from both sides play a role in in\ufb02uencingtheundecidedgroup,withweakTrumpsupportersreceivingsupportfromstrongTrump\nsupportersintheire\ufb00orts.Notably,IRAnodesdonotplayasigni\ufb01cantroleinthiscausal\nnetwork,suggestingthattheyhavelimitedcausationonusers\u2019activity.\nOntheotherhand,inFig. 5b,whichrepresentsthecausalnetworkforsuspendednodes,\nthestructureshowssubstantialdi\ufb00erences.Suspendednodestakeonacentralrole,acting\nas a bridge between strong Trump supporters and the weak and undecided supporters.Strong Trump supporters have a causal e\ufb00ect on suspended nodes, which, in turn, have\nacausalin\ufb02uenceonbothweaksupportersandtheundecidedgroup.Additionally,weak\nsupporterscontinuetoexertacausale\ufb00ectontheundecidedgroup.Interestingly,strongTrumpsupportershaveacausale\ufb00ectonstrongClintonsupporters,butnotvice-versa.\n4 Discussionsandconclusions\nCurrent research focuses on the role and impact of the Internet Research Agency (IRA)\nin the 2016 US presidential elections. This emphasis on IRA\u2019s political interference may\nhave overshadowed other campaigns with similar aims that were not linked to Russianorigins. By merging the IRA public dataset with a collection of tweets spanning the \ufb01ve\nmonths leading up to the 2016 presidential elections, our objective is to investigate the\npresenceandimpactofsuspendedaccounts\u2014thosenot\ufb02aggedasIRA\u2014whichmighthavecontributedtothedisseminationofcontentalignedwiththeTrumppoliticalagenda.\nOuranalysisrevealsthattheIRAandsuspendedaccounts(not\ufb02aggedasIRAbyTwit-\nter) do share many similarities, in terms of the type of news they share, the clients theyuse and the way participate in the Twitter social discourse, as highlighted in Sect. 3.1.\nHowever,expectingallthesuspendedaccountsinourextensivedataset,comprisingover\n700,000 users (7.7%ofthe10 millionusers, asdetailed in Sect. 2.1), to exhibit such simi-\nlarityisimprobable.TopinpointarepresentativegroupmoreakintoIRA,weleveragethe\nIRAegonetwork.\nWithin the IRA ego network, we identi\ufb01ed 30,622 suspended accounts, a number 60\ntimes largerthan the IRAaccounts.These suspended accountsengaged throughvarious\ninteractions like retweeting, mentioning, replying, and quoting, with retweets and men-\ntions being the most common. Aligning with existing literature [ 36,37]t h a ta s s e r t st h e\nIRAaimedtosupportDonaldTrumpandsowdiscordintheU.S.,wefoundthatthema-jorityofnodesintheegonetwork,includingsuspendedaccounts,areclassi\ufb01edasTrump\nsupporters(discussedinSect. 3.2).\nIn the aggregated IRA ego network, approximately 2% of total users were directly ex-\nposed to IRA content, consistent with [ 23]. A multiscale community detection on this\nnetworkrevealedtwocommunities,encompassingalmost90%ofthetotalnodes,indicat-\ninguserpolarization.Thelargercommunity(communityright)aimedtosupportTrump,while the smaller one (community left) interacted directly with Clinton supporters, po-\ntentiallyattemptingtoin\ufb02uencetheiropinions.Thisdualstrategyalignswithcurrentlit-\neraturesuggestingamultifacetedapproachbytheIRA[ 18,30].\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page17of19\nContrary to the multifaceted strategy observed with the IRA, suspended accounts ex-\nhibitamorefocusedroleintherightcommunity.Theycontributesigni\ufb01cantly,compris-\ning over 20% of the connections in the community, with a majority of these connections\noriginating from IRA to suspended accounts. Building on earlier \ufb01ndings, this suggeststhat the suspended accounts in this group were primarily engaged in mentioning andretweetingIRAcontent,likelyaimingtoinundatethesocialplatformwithideasconsistentwiththerightpoliticalagenda.\nHaving identi\ufb01ed a group of suspended accounts resembling IRA behaviors (partially)\nandgaininginsightsintotheirintent,weproceedtomeasuretheimpactofbothsuspended\naccountsandIRAonshapingtheTwitterdiscourseduringthe2016USpresidentialelec-\ntions. This is achieved through the application of Granger causality to the tweet activityproducedbyIRAandsuspendedaccounts,andeachsupportingclass(refertoSect. 3.3).\nOur causal analyses reveal that the group of IRA accounts did not have a signi\ufb01cant\nimpactinin\ufb02uencingthecandidate\u2019ssupporters,asshowninFig. 5aanddetailedin[ 23].\nHowever,thesituationbecomesmoreintricatewhenweconsiderthesuspendedaccounts.We\ufb01ndthattheseuserswieldedasubstantialin\ufb02uenceonindividualscategorizedasun-\ndecidedorweaksupporters,potentiallywiththeintentionofswayingtheiropinions.This\ne\ufb00ect is graphically portrayed in Fig. 5b, illustrating the bridging e\ufb00ect that suspended\nnodes played between strong Trump supporters and the group of weak supporters andundecidedindividuals.\nIt\u2019simportanttonotethatwhileGrangercausalitysuggeststhatpastretweetbehaviors\nin one group can aid in predicting the retweet behaviors of the other group, it doesn\u2019timplyadirectcause-and-e\ufb00ectrelationship.Thedeterminationofsuchcausalitygoesbe-yond the scope of this study. Additionally, utilizing tweet activity provides insights into\nuser behavior, but conclusions regarding changes in users\u2019 vote intentions require longi-\ntudinaldata.Itis,however,noteworthythatthesimilarityobservedbetweentheInternetResearchAgency(IRA)andthegroupofsuspendedusers,coupledwiththefactthatsus-pended accounts in\ufb02uenced the activity of undecided users, opens up the possibility ofa new scenario, such as potential cooperation between the IRA and the identi\ufb01ed groupof suspended users. It\u2019s also conceivable that this group of suspended accounts was partoftheIRA\u2019scampaignandremainedundetectedbyTwitter.However,thisremainspurely\nspeculative,andfurtheranalysisanddataareneededtodrawmoreconcreteconclusions.\nFurthermore,thelackofdetailedinformationaboutthenatureofsuspendedaccounts,\nsuchaswhethertheyaretrollsorbots,isalimitation.Whileallpossibilitiesareconsidered,thelogisticalchallengesofcontrollingagroupofover30,000accountsmakeitmorelikelythatthissetofsuspendedaccountspredominantlyconsistsofbots.\nIn summary, this study suggests a scenario in which a signi\ufb01cant group of suspended\naccounts,oftenovershadowedbytheIRAnarrative,playedacrucialroleduringthe2016\nUS presidential elections. Further research is required to better understand their impact\nonpoliticaluserpreferences.\nSupplementaryinformation\nSupplementaryinformation accompaniesthispaperat https://doi.org/10.1140/epjds/s13688-024-00464-3 .\nAdditional\ufb01le1 .(PDF893kB)\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page18of19\nAbbreviations\nIRA,refertotheInternetResearchAgency.\nAcknowledgements\nNotapplicable.\nAuthorcontributions\nHAM,ABandMSconceivedtheresearch;MSandABdesignedandsupervisedtheresearch;MSandABcoordinatedandsupervisedtheanalysis;MSandZZperformedtheanalyses.MS,ZZ,JSA,AB,andHAManalyzedtheresults;MSandZZwrotethe\ufb01rstdraft.Allauthorseditedandapprovedthepaper.\nFunding\nHAMwassupportedbyNSF-HNDSAward2214217.JSAgratefullyacknowledgestheBrazilianagenciesFUNCAP,CNPqandCAPES,theNationalInstituteofScienceandTechnologyforComplexSystemsinBrazil,andthePRONEX-FUNCAP/CNPqAwardPR2-0101-00050.01.00/15for\ufb01nancialsupport.MSgratefullyacknowledgestheBrazilianagencyCAPESAward88887.899221/2023-00.ZZwassupportedbytheNationalNaturalScienceFoundationofChinaunderprojectNo.62302319andR&DProgramofBeijingMunicipalEducationCommission(GrantNo.KM202210038002).\nDataavailability\nTheTwitterdataareprovidedaccordingtoitstermsandareavailableat https://osf.io/g4hws/ and\nhttps://github.com/makselab/IRA-and-suspended-accounts .Analyticalcodesareavailableinthesamerepositories.\nDeclarations\nCompetinginterests\nTheauthorsdeclarethattheyhavenocompetinginterests.\nAuthordetails\n1LevichInstituteandPhysicsDepartmen,CityCollegeofNewYork,NewYork,NY,USA.2DepartmentofDataScience,\nSchoolofStatistics,CapitalUniversityofEconomicsandBusiness,Beijing,China.3PhysicsDepartment,Universidade\nFederaldoCear\u00e1,Fortaleza,Cear\u00e1,Brazil.4DepartmentofMathematicalModelingandMachineLearning,Universityof\nZurich,Zurich,Switzerland.5DigitalSocietyInitiative,UniversityofZurich,Zurich,Switzerland.\nReceived:25January2024 Accepted:13March2024\nReferences\n1. DiGraziaJ,McKelveyK,BollenJ,RojasF(2013)Moretweets,morevotes:socialmediaasaquantitativeindicatorof\npoliticalbehavior.PLoSONE8:e79449\n2. AnsteadN,O\u2019LoughlinB(2015)Socialmediaanalysisandpublicopinion:the2010ukgeneralelection.J\nComput-MediatCommun20:204\u2013220\n3. BovetA,MoroneF,MakseHA(2018)ValidationofTwitteropiniontrendswithnationalpollingaggregates:hillary\nClintonvsDonaldTrump.SciRep8:8673\n4. AhmedS,JaidkaK,ChoJ(2016)The2014IndianelectionsonTwitter:acomparisonofcampaignstrategiesof\npoliticalparties.TelematInform33:1071\u20131087\n5. Maj\u00f3-V\u00e1zquezS,CongostoM,NichollsT,NielsenRK(2021)Theroleofsuspendedaccountsinpoliticaldiscussionon\nsocialmedia:analysisofthe2017French,ukandGermanelections.SocMediaSoc7:20563051211027202\n6. HegelichS,JanetzkoD(2016)AresocialbotsonTwitterpoliticalactors?EmpiricalevidencefromaUkrainiansocial\nbotnet.In:ProceedingsoftheinternationalAAAIconferenceonwebandsocialmedia,vol10,pp579\u2013582\n7. RatkiewiczJetal(2011)Detectingandtrackingpoliticalabuseinsocialmedia.In:Proceedingsoftheinternational\nAAAIconferenceonwebandsocialmedia,vol5,pp297\u2013304\n8. BrunoM,LambiotteR,SaraccoF(2022)Brexitandbots:characterizingthebehaviourofautomatedaccountson\nTwitterduringtheukelection.EPJDataSci11:17\n9. BurkiT(2020)Theonlineanti-vaccinemovementintheageofCovid-19.LancetDigitHealth2:e504\u2013e505\n10. TuckerJA,TheocharisY,RobertsME,Barber\u00e1P(2017)Fromliberationtoturmoil:socialmediaanddemocracy.J\nDemocr28:46\u201359\n11. FerraraE(2017)Disinformationandsocialbotoperationsintherunuptothe2017frenchpresidentialelection.arXiv\npreprintarXiv:1707.00086\n12. DiRestaRetalThetactics&tropesoftheinternetresearchagency.\nhttps://www.documentcloud.org/documents/5632786-NewKnowledge-Disinformation-Report-Whitepaper .\nAccessed:2023-05-25\n13. JamiesonKH(2020)Cyberwar:howRussianhackersandtrollshelpedelectapresident:whatwedon\u2019t.Can\u2019t,anddo\nknow.OxfordUniversityPress,Oxford\n14. MuellerRS,CatMWA(2019)ReportontheinvestigationintoRussianinterferenceinthe2016presidentialelection,\nvol1.USDepartmentofJustice,Washington\n15. CarrollO(2017)St.Petersburgtrollfarmhad90dedicatedsta\ufb00workingtoin\ufb02uenceuselectioncampaign.The\nIndependent\n16. BadawyA,FerraraE,LermanK(2018)Analyzingthedigitaltracesofpoliticalmanipulation:the2016Russian\ninterferenceTwittercampaign.In:2018IEEE/ACMinternationalconferenceonadvancesinsocialnetworksanalysisandmining(ASONAM),pp258\u2013265\n17. HowardPN,GaneshB,LiotsiouD,KellyJ,Fran\u00e7oisC(2018)TheIRA,socialmediaandpoliticalpolarizationinthe\nUnitedStates,2012\u20132018.UniversityofOxford,Oxford\nSera\ufb01noetal. EPJDataScience           (2024) 13:29 Page19of19\n18. StewartLG,ArifA,StarbirdK(2018)Examiningtrollsandpolarizationwitharetweetnetwork.In:Proc.ACMWSDM,\nworkshoponmisinformationandmisbehaviorminingontheweb,vol70\n19. DiRestaRetal(2018)Thetactics&tropesoftheinternetresearchagency.NewKnowledge20. ZannettouSetal(2019)Disinformationwarfare:understandingstate-sponsoredtrollsonTwitterandtheirin\ufb02uence\nontheweb.In:Companionproceedingsofthe2019worldwidewebconference,pp218\u2013226\n21. BailCAetal(2020)AssessingtheRussianInternetresearchagency\u2019simpactonthepoliticalattitudesandbehaviors\nofAmericanTwitterusersinlate2017.ProcNatlAcadSci117:243\u2013250\n22. GrinbergN,JosephK,FriedlandL,Swire-ThompsonB,LazerD(2019)FakenewsonTwitterduringthe2016us\npresidentialelection.Science363:374\u2013378\n23. EadyGetal(2023)ExposuretotheRussianInternetresearchagencyforeignin\ufb02uencecampaignonTwitterinthe\n2016uselectionanditsrelationshiptoattitudesandvotingbehavior.NatCommun14:62\n24. BurszteinE,MarzuoliAQuantifyingtheimpactofthetwitterfakeaccountspurge-atechnicalanalysis.\nhttps://elie.net/blog/web/quantifying-the-impact-of-the-twitter-fake-accounts-purge-a-technical-analysis/ .\nAccessed:2023-05-25\n25. RothY,HarveyDHowtwitteris\ufb01ghtingspamandmaliciousautomation.\nhttps://blog.twitter.com/en_us/topics/company/2018/how-twitter-is-\ufb01ghting-spam-and-malicious-automation .\nAccessed:2023-05-25\n26. BovetA,MakseHA(2019)In\ufb02uenceoffakenewsinTwitterduringthe2016uspresidentialelection.NatCommun\n10:7\n27. FlaminoJetal(2023)Politicalpolarizationofnewsmediaandin\ufb02uencersontwitterinthe2016and2020us\npresidentialelections.NatHumBehav,1\u201313\n28. HodgesJL(1958)Thesigni\ufb01canceprobabilityoftheSmirnovtwo-sampletest.ArkMat3:469\u2013486\n29. MannHB,WhitneyDR(1947)Onatestofwhetheroneoftworandomvariablesisstochasticallylargerthantheother.\nAnnMathStat,50\u201360\n30. LinvillDL,WarrenPL(2020)Trollfactories:manufacturingspecializeddisinformationonTwitter.PolitCommun\n37:447\u2013467\n31. SpirtesP,GlymourC,ScheinesR(2000)Causation,predictionandsearch(2\u00aa)32. RungeJ,HeitzigJ,PetoukhovV,KurthsJ(2012)Escapingthecurseofdimensionalityinestimatingmultivariate\ntransferentropy.PhysRevLett108:258701\n33. RungeJ,NowackP,KretschmerM,FlaxmanS,SejdinovicD(2019)Detectingandquantifyingcausalassociationsin\nlargenonlineartimeseriesdatasets.SciAdv5:eaau4996\n34. RungeJetal(2015)Identifyingcausalgatewaysandmediatorsincomplexspatio-temporalsystems.NatCommun\n6:8502\n35. ClevelandRB,ClevelandWS,McRaeJE,TerpenningI(1990)Stl:aseasonal-trenddecomposition.JO\ufb00Stat6:3\u20137336. GolovchenkoY,BuntainC,EadyG,BrownMA,TuckerJA(2020)Cross-platformstatepropaganda:Russiantrollson\nTwitterandyoutubeduringthe2016uspresidentialelection.IntJPress/Polit25:357\u2013389\n37. LinvillDL,BoatwrightBC,GrantWJ,WarrenPL(2019)\u201cTherussiansarehackingmybrain!\u201dinvestigatingRussia\u2019s\nInternetresearchagencyTwittertacticsduringthe2016UnitedStatespresidentialcampaign.ComputHumBehav\n99:292\u2013300\nPublisher\u2019sNote\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsinpublishedmapsandinstitutionala\ufb03liations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Suspended accounts align with the Internet Research Agency misinformation campaign to influence the 2016 US election", "author": ["M Serafino", "Z Zhou", "JS Andrade", "A Bovet"], "pub_year": "2024", "venue": "EPJ Data \u2026", "abstract": "The ongoing debate surrounding the impact of the Internet Research Agency\u2019s (IRA) social  media campaign during the 2016 US presidential election has largely overshadowed the"}, "filled": false, "gsrank": 381, "pub_url": "https://epjds.epj.org/articles/epjdata/abs/2024/01/13688_2024_Article_464/13688_2024_Article_464.html", "author_id": ["YB_5JtoAAAAJ", "q34mzkwAAAAJ", "EwWccccAAAAJ", "rbHfk1EAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:OnfqTsR_twcJ:scholar.google.com/&output=cite&scirp=380&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=OnfqTsR_twcJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 4, "citedby_url": "/scholar?cites=556053560117851962&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:OnfqTsR_twcJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1140/epjds/s13688-024-00464-3.pdf"}}, {"title": "This is the accepted version and may differ from the final authoritative version published in Public Understanding of Science. For the final published article \u2026", "year": "NA", "pdf_data": "Anti-intellectualism on Twitter 1 This is the accepted version and may differ from the final authoritative version published in Public Understanding of Science. For the final published article, please visit: https://doi.org/10.1177/09636625221146269     Anti-intellectualism Amid the COVID-19 Pandemic: The Discursive Elements and Sources of Anti-Fauci Tweets  Yingying Chen1,2, Jacob Long1, Jungmi Jun1, Sei-Hill Kim1, Ali Zain1, Colin Piacentine1 1School of Journalism and Mass Communications, University of South Carolina 2 School of Journalism and Communication, Renmin University of China      Author Note Yingying Chen https://orcid.org/0000-0003-4278-8206 We have no known conflict of interest to disclose.  Correspondence concerning this article should be addressed to Dr. Yingying Chen, Renmin University of China, the School of Journalism and Communication, Mingde Building, 59 Zhongguancun Street, Haidian District, 100872, Beijing, China. Email:  yychen1911@homtmail.com  \n\nAnti-intellectualism on Twitter 2  Abstract Anti-intellectualism (resentment, hostility, and mistrust of experts) has become a growing concern that influences the public understanding of science during the pandemic. Using topic modeling and supervised machine learning, this study examines the elements and sources of anti-Fauci tweets as a case of anti-intellectual discourse on social media. Based on the theoretical framework of science-related populism, we identified three anti-intellectual discursive elements in anti-Fauci tweets: people-scientist antagonism, delegitimizing the motivation of scientists, and delegitimizing the knowledge of scientists. Delegitimizing the motivation of scientists appeared the most in anti-Fauci tweets. Politicians, conservative news media, and non-institutional actors (e.g., individuals and grassroots advocacy organizations) co-constructed the production and circulation of anti-intellectual discourses on Twitter. Anti-intellectual discourses still resurged under Twitter\u2019s content moderation mechanism. We discuss theoretical and practical implications for building public trust in scientists, effective science communication, and content moderation policies on social media. Keywords: anti-intellectualism, populism, Twitter, topic modeling, supervised machine learning    \nAnti-intellectualism on Twitter 3 Anti-intellectualism Amid the COVID-19 Pandemic: The Discursive Elements and Sources of Anti-Fauci Tweets 1. Introduction Anti-intellectualism, defined as the generalized dislike and distrust of experts (Motta, 2018), has become a major obstacle to public compliance with health policies and behaviors recommended by experts and governments (Merkley, 2021). In the COVID-19 context, anti-intellectualism, measured by the level of distrust in experts (e.g., doctors, scientists, economists) was associated with low levels of risk perceptions and preventive behaviors, such as social distancing, mask usage, and health information acquisition (Merkley and Loewen, 2021). Social media are platforms where anti-intellectual discourse is produced and spread. Research has found many tweets expressing distrust of scientists, especially in response to posts from medical/health experts or the Centers for Disease Control and Prevention (CDC) and other authoritative health organizations (Batova, 2021; Bonnevie et al., 2021). Exposure to anti-intellectual discourse online influences the public\u2019s trust in information and recommendations from experts (Merkley and Loewen, 2021). Despite the propagation of anti-intellectualism on social media and its negative consequences, current studies pay unbalanced attention to the source and outcome of anti-intellectualism. Most studies have focused on the outcome side. That is, the anti-intellectual attitudes held by the public (Merkley, 2020; Motta, 2018). Fewer studies explored the sources of anti-intellectualism on social media, although various studies have found that social media debates about scientific issues like climate change (Pearce et al., 2018), anti-vaccination (Bonnevie et al., 2021), and conspiracy theories (Mahl et al., 2020) expressed similar anti-intellectual sentiment. Researchers often treated anti-intellectualism as a component of populist discourse (Merkley and Loewen, 2021). The shortage of analysis about anti-intellectualism on \nAnti-intellectualism on Twitter 4 social media leads to two limitations in current anti-intellectualism research. First, the elements (i.e., underlying themes) of anti-intellectual discourse on its own, rather than as a component of populist discourse, are less clear. Second, there is minimal research investigating non-institutional sources of anti-intellectualism on social media. Early analysis of the source of anti-intellectualism focused on institutional sources, highlighting the role of politicians or political parties in providing anti-intellectual discourse in the public sphere (Hofstadter, 1963). However, in today\u2019s media landscape, social media has empowered non-institutional actors, which are individuals and grassroots advocacy organizations, to create and spread anti-intellectual voices in the public sphere.  The current study seeks to understand the formation and construction of anti-intellectualism on Twitter. We consider anti-intellectualism a communication style and focus on its two aspects: (1) the discursive elements that form the expressed anti-intellectual discourses and (2) the sources of different discursive elements of anti-intellectual discourse on Twitter. Drawing on the conceptualizations of science-related populism (Mede and Sch\u00e4fer, 2020), we propose that anti-intellectual discourse will be composed of three elements: people-scientist antagonism, delegitimizing the motivation, and the knowledge of scientists. Based on the networked model of science communication by van Dijck and Alinead (2020), we propose that both institutional actors (politicians and news media) and non-institutional actors (individuals and grassroots advocacy organizations) will collectively construct anti-intellectual discourse on social media. We provide empirical evidence to support our theoretical propositions by analyzing a case of anti-intellectual discourse on Twitter. Compared with other mainstream social media (e.g., Facebook, YouTube), Twitter has strength in disseminating information across online \nAnti-intellectualism on Twitter 5 networks quickly (Kwak et al., 2010). Various studies have shown the propagation of misleading information, anti-science information, and conspiracy theories on Twitter (e.g., Mahl et al., 2021; Rao et al., 2021). Twitter also claims to have content moderation policies to curb the spread of conspiracy theories and COVID-19 misinformation (Twitter, 2021). We monitor tweets expressing extreme distrust, opposition, and hatred against Anthony Fauci, the director of the National Institute of Allergy and Infectious Diseases (\u2018anti-Fauci tweets\u2019 hereafter, e.g., #firefauci, #arrestfauci, #faucifraud), posted during the pandemic. As a spokesperson for science, Fauci delivered scientific information to the public and handled public anxiety during national health crises, such as the HIV/AIDS epidemic in the 1980s, the H1N1 Swine flu outbreak in 2009, and the Ebola virus outbreak in 2014. In January 2020, Fauci became a member of the White House Coronavirus Task Force (Santucci, 2020) and the de facto spokesperson for the task force due to his expertise and experiences with disease outbreaks. He has also advocated public health measures (e.g., social distancing, face covering) in media briefings and interviews.  Many prominent political figures, including former U.S. President Donald Trump, publicly criticized Fauci and opposed his suggestions on several occasions (Evans and Hargittai, 2020). Trump retweeted his supporter\u2019s tweet saying Fauci should be fired and a video suggesting Fauci misled the public about the efficacy of hydroxychloroquine. Several Republican politicians have also expressed doubts or criticisms against Fauci\u2019s public health measures, policy suggestions, and scientific research on Twitter (Alba and Krenkel, 2020). Criticisms of Fauci continue circulating on Twitter, providing digital-trace data for us to observe the dynamics of anti-intellectual discourse in the public sphere.  2. Anti-intellectualism, Populism, and Science-related Populism \nAnti-intellectualism on Twitter 6 Hofstadter (1963) broadly defined anti-intellectualism as \u201ca resentment and suspicion of the life of the mind and of those who are considered to represent it; and a disposition constantly to minimize the value of that life.\u201d (p.7) Hofstadter identified three specific types of anti-intellectualism in American cultural history: Anti-rationalism (denial of the value of critical thinking), unreflective instrumentalism (disdain for ideas that do not provide immediate practical value), and anti-elitism (mistrust and dislike of elites) (Rigney, 1991). Each type links to a distinctive social-structural origin: Anti-rationalism originates from religious structures; unreflective instrumentalism relates to the commercial structures in American capitalism; and anti-elitism connects with populist political structures and movements (Rigney, 1991). Our study focuses on the anti-elite form of anti-intellectualism, which expresses resentment, hostility, and mistrust of experts (Merkley, 2020; Motta, 2018). Experts with superior knowledge, academic training, or credentials in a subject matter are often considered the elite class by anti-intellectuals (Motta, 2018). Experts merely apply intellect to benefit themselves or the upper class (Rigney, 1991). Anti-intellectuals also discredit the knowledge of experts and believe that common sense, personal experience, or intuitions of ordinary people can replace expertise (Hofstadter, 1963).  Political populism is one root of anti-intellectualism (Hofstadter, 1963; Merkley, 2020; Motta, 2018). Populist movements and politicians often have anti-intellectual tendencies (Rigney, 1991). In a survey study, Merkley (2020) found that exposure to populist discourse was associated with anti-intellectual sentiment and was further linked to skepticism toward scientific issues that have already reached expert consensus (e.g., anthropogenic climate change). Motta (2018) showed that support for populist movement events and anti-expert politicians predict anti-intellectualism. However, populism and anti-intellectualism are conceptually different for two reasons. First, populism is anti-elitism and anti-pluralism (M\u00fcller, 2016). Populism emphasizes \nAnti-intellectualism on Twitter 7 that society comprises two homogenous and antagonistic groups: the pure people versus the corrupted elites; politics should express the general will of the people (Mudde, 2017). The elites are corrupted; \u201cthe people\u201d\u2014an imagined homogenous group of ordinary people\u2014are morally superior and should fight against elites (M\u00fcller, 2016). Populists are the exclusive representatives of common people, ignoring that the latter is a composition of various groups, such as experts and racial minorities (M\u00fcller, 2016). Second, although anti-intellectualism and populism are anti-elite, populism is not necessarily anti-expert, especially when populists do not consider experts as the elite class (Rigney, 1991; Merkley and Loewen, 2021). For example, intellectuals who advocated social reforms received public acceptance during the U.S. Progressive era (Rigney, 1991). Anti-intellectualism has a closer conceptual relation with science-related populism than political populism. Unlike political populism, science-related populism (Mede and Sch\u00e4fer, 2020) is a distinctive type of populism targeting academic elites. Science-related populism is \u201ca set of ideas suggesting that the virtuous \u2018ordinary people\u2019 and their common sense\u2014and not allegedly corrupt academic elites\u2014should determine what is deemed \u2018true knowledge,\u2019 how it is produced, and on which topics scientific research should focus\u201d (Mede and Sch\u00e4fer, 2020, p.212). The \u201cordinary people\u201d are an imagined, homogenous group of people who share their values and \u201cepistemological sense;\u201d while the elites are the academic elites, such as scientists, researchers, experts, universities, and research institutions, who have authority to make science-related decisions (Mede and Sch\u00e4fer, 2020, p.480-481).  3. Three Elements of Anti-intellectual Discourse We expect that science-related populism and its components overlap with the key elements of the anti-intellectual discourse. Science-related populism has three key components: \nAnti-intellectualism on Twitter 8 people-scientist antagonism, science-related decision-making sovereignty, and truth-speaking sovereignty (Mede and Sch\u00e4fer, 2020, p. 473). Although science-related populism and anti-intellectualism both distrust and dislike academic elites, decision-making sovereignty and truth-speaking sovereignty are prerequisites for science-related populism conceptually (Mede et al., 2022). Therefore, we adapted from science-related populist components and proposed three discursive elements as the key components of anti-intellectual discourses: people-scientist antagonism, delegitimizing the motivation, and the knowledge of the scientists.  People-scientist Antagonism The core component of science-related populism is people-scientist antagonism: the virtuous people versus the unvirtuous academic elites (Mede and Sch\u00e4fer, 2020). Similarly, anti-intellectuals see a broader sense of people-elite conflict. They believe that elites are self-seeking, remote from the life of ordinary people, and thus disregard their true benefits and needs (Rigney, 1991). The people-scientist antagonism provides an element that forms anti-intellectual discourse in two ways. First, there is a moral juxtaposition between people and scientific experts. For example, people are good and innocent, while scientific experts are evil and ignore the common people (Mede and Sch\u00e4fer, 2020). Second, the consequences of relying on scientists\u2019 authority and scientists are the culprits for creating ordeal and trouble for common people. For example, Oliver and Rahn (2016) found that blaming experts for unfortunate circumstances is one of the lasting themes in populist discourse by candidates from the 2016 US presidential election. Overall, the people-scientist antagonism involves anger, hostility, opposition, or frustration towards scientists due to the perception that scientists have misaligned goals and priorities or cause problems for ordinary people. We expect to find a strong presence of people-scientist \nAnti-intellectualism on Twitter 9 antagonism in anti-intellectual discourse, but given that we know little about how much science-related populism constructs anti-intellectual discourse, we ask:   RQ1: How and to what extent is people-scientist antagonism present in anti-Fauci tweets? Delegitimizing the Motivation of scientists The second component of science-related populism is science-related decision-making sovereignty, meaning the authority to decide the research agenda, funding, and research designs (Mede and Sch\u00e4fer,2020). Science-related populism alleges that academic elites illegitimately hold science-related decision-making sovereignty; rather, ordinary people should have the authority to decide what will be studied, why, and how the subject should be studied (Mede and Sch\u00e4fer, 2020). Science-related populists are thus skeptical about the motivation of scientists. Science-related populists believe that scientists have a hidden agenda that only maximizes their interests or political influence by utilizing their knowledge and expertise rather than benefiting the public. In anti-intellectual discourse, a preoccupation with the extrinsic motives of scientists is expected to be a predominant form of populist appeals for decision-making sovereignty.  Recent studies using U.S. national surveys show that distrust in scientists correlates with challenges to their motivations in making science-related decisions. McLaughlin et al. (2021) found that the American public commonly believed political motives decided how scientific research about COVID-19 was conducted and that the objectivity of scientific research was questionable. They further showed that individuals who held these beliefs were likely to distrust scientists. In another study, Evans and Hargittai (2020) found that people who distrust scientists believed scientists did not represent the public\u2019s values. Thus, we expect that delegitimizing the scientists\u2019 motivations will be an element of anti-intellectual discourse. This element challenges \nAnti-intellectualism on Twitter 10 the motivation of scientists and questions what scientists should research, how, and why certain subjects should be studied.  RQ2: How and to what extent is the discursive element that delegitimizes the motivations of scientists present in the anti-Fauci tweets? Delegitimizing the Knowledge of Scientists Truth-speaking sovereignty, the third component of science-related populism, means the authority to make true claims about scientific issues (Mede and Sch\u00e4fer, 2020). Science populists believe ordinary people should have the authority of truth-speaking sovereignty that typically belongs to scientists; scientists do not have the authority to determine what constitutes valid knowledge because scientists rely on theories, models, and research methods that are disconnected from the real world (Mede and Sch\u00e4fer, 2020).  Similarly, recent studies show public distrust of scientists associated with uncertain and inconsistent scientific information on COVID-19. Kreps and Kriner (2020) conducted longitudinal surveys and found that COVID-19 predictive models and findings from scientific research often showed contradictory results due to limited data at the beginning of the pandemic. As a result, the public expressed distrust of scientists and less support for science-based policies. Evans and Hargittai (2020) also showed that knowledge-based distrust was prominent among Americans who were skeptical of scientists, particularly among the non-Democrats and Trump supporters. Hence, we expect to find delegitimizing scientists\u2019 knowledge as another element of anti-intellectual discourse. This element questions the knowledge of scientists and accuses them of providing inconsistent or incorrect information to the public. \nAnti-intellectualism on Twitter 11 RQ3: How and to what extent is the discursive element that delegitimizes the knowledge of scientists present in the anti-Fauci tweets? Social media users\u2019 engagement, such as retweets, likes, and comments tend to reinforce the production and circulation of anti-intellectual discourse on social media. Driven by the business model of social media platforms, content recommendation algorithms tend to propagate misinformation that elicits conflicts, disagreement, or emotions (van Dijck and Alinead, 2020). Compared with true news, false news often elicited fear, disgust, and surprise and was more likely to be retweeted by human users (Vosoughi et al.,2018). Following the platform logic, anti-intellectual discourses\u2014which express aversion, hostility, conflicts, and disagreement between the public and scientists\u2014are likely to capture user attention on social media platforms. Although Twitter claimed that its content moderation mechanisms had removed many accounts closely related to conspiracy theories and COVID-19 misinformation (Twitter, 2021), it is unknown how distinct types of anti-intellectual discursive elements remain and circulate on Twitter. Considering the joint influence of content recommendation and content moderation algorithms by Twitter, we ask:  RQ4: How has the total number of tweets and retweets of each type of anti-intellectual discursive element changed during the pandemic?  4. The Constructions of Anti-intellectual Discourses on Twitter van Dijck and Alinead (2020) proposed a networked model to explain the ebbs and flows of scientific information on social media during a public health crisis based on observation of information flows among different social actors. This model highlights two types of actors\u2014institutional and non-institutional\u2014and their role in building public trust in scientific experts on social media. The institutional actors include scientists (representing knowledge-making \nAnti-intellectualism on Twitter 12 institutions), politicians (representing policy-making institutions), and news media (representing sense-making institutions), and the non-institutional actors are ordinary citizens and advocacy groups that do not officially represent an institution but have mobilizing power (van Dijck and Alinead, 2020). They suggest that the production and circulation of scientific information from politicians, news media, scientists, and non-institutional actors can enhance and undermine public understanding of true knowledge in science.  Similarly, institutional and non-institutional actors may individually and collectively construct anti-intellectual social media discourse. We expect that politicians amplify anti-intellectual discourse on Twitter. In the early institutional analysis by Hofstadter (1963), left- and right-leaning politicians both provided social origins for anti-intellectualism in American history. They strategically used anti-elite discourse in election campaigns to win voters, capitalizing on the public\u2019s negative sentiment toward experts (Motta, 2018; Oliver and Rahn, 2016). During the pandemic, most criticisms of COVID-19 models came from Republican political elites, but a few Republican governors (such as Governors Baker from Massachusetts, DeWine from Ohio, and Hogan from Maryland) endorsed pro-science public policies (Kreps and Kriner, 2020). When political elites tweeted their stances on scientific issues, their tweets often generated spikes of public attention on scientific issues, placing politicians at the center of conversations. Analyzing 350 million COVID-19 tweets, Durazzi et al. (2021) found that tweets from scientists received considerable numbers of retweets at the beginning of the pandemic, but the number gradually decreased as tweets from political elites increasingly gained more retweets than scientists. Given the findings, we hypothesize: \nAnti-intellectualism on Twitter 13 H1: Anti-intellectual tweets from politicians will spark more retweets than those from news media and the non-institutional actors on Twitter. In addition to political elites, news media, particularly conservative news media and far-right populism media are institutional sources that influence the production and circulation of anti-intellectual discourses on social media. Although anti-intellectual discourse is likely to appear in both left- and right-wing news media, Yan et al. (2021) found that science skeptics were mostly associated with far-right populism websites. The far-right media often claim themselves as the alternative media, which are \u201ccorrective of \u2018traditional\u2019, \u2018legacy\u2019, or \u2018mainstream\u2019 news media in a given sociocultural and historical context\u201d (Holt et al., 2019). Studies have also found that reliance on conservative media like Fox News as a source of COVID-19 information was associated with fewer concerns about COVID-19 risk and more distrust of scientists (Clinton et al., 2021; Dhanani and Franz, 2020).  Conservative or far-right news media are likely to construct discourses on social media in two ways. First, such news media can directly post anti-intellectual tweets. For example, Boberg et al. (2020) showed that far-right news media in Germany were a generator of pandemic populism by posting Facebook content that was anti-establishment and against fact-based news covered by mainstream media. Second, social media users cite or share content from the websites of conservative or far-right alternative news media. For example, Bovet and Makse (2019) analyzed 171 million tweets related to the 2016 US presidential election and found that 30 million tweets contained a link to news outlets; 25% of tweets included a link to fake or extremely biased news. Based on empirical findings, we hypothesize:  \nAnti-intellectualism on Twitter 14 H2: Conservative news media will be more likely to post anti-intellectual tweets than liberal news media. H3: Anti-intellectual tweets will be more likely to cite conservative news media (by including a URL link to such news media) than liberal news media.   Social media has empowered non-institutional actors to influence the production and circulation of anti-intellectual discourse. Non-institutional actors directly post anti-intellectual discourse on social media. A study of 115 million tweets from accounts located in the US revealed that anti-science tweets came principally from individual Twitter users, particularly strong partisan identifiers from the Southern and Northwestern states (Rao et al., 2021). In general, most Twitter accounts belong to individual people, with only around 30 percent of accounts representing organizations (McCorriston et al., 2015). Non-institutional actors likely produce the most anti-intellectual tweets. H4: Most anti-intellectual tweets will come from non-institutional actors. In addition to posting tweets, the contents of the tweets from political elites tend to influence tweets from non-institutional actors and conservative media. Previous experiments showed that criticisms of scientists and COVID-19 models from political elites decreased perceptions of pandemic risk (Grossman et al., 2020) and trust in science, particularly for partisan identifiers (Kreps and Kriner, 2020). An analysis of U.S. news coverage of COVID-19 found that news media cited politicians more frequently than scientists (Hart et al., 2020). Therefore, it is likely that the discursive elements from the anti-Fauci tweets by non-institutional actors bear a resemblance to those by politicians and news media outlets. We ask:  RQ5: How do discursive elements in anti-Fauci tweets differ by the type of actor? 5. Materials and Methods \nAnti-intellectualism on Twitter 15 Data Collection We used four hashtags: #firefauci, #arrestfauci, #faucithefraud, and #faucifraud to collect our data (anti-Fauci tweets). Hashtags provide a tool for mobilizing public attention to social movements and indicating public framing of real-life events on Twitter (Lindgren, 2019). We used Brandwatch, a social monitoring tool to identify the four hashtags. Specifically, we monitored tweets that include \u201cfauci\u201d from January 2020 to September 2021 and found that the four hashtags were the most retweeted during the period. We excluded some hashtags (such as #maga, #scamdemic in Table S1) that co-occurred but did not directly express anti-Fauci sentiment to reduce irrelevant tweets. We collected 28,690 tweets including at least one of the four hashtags posted by accounts based in the U.S. between January 1, 2020, and September 30, 2021. We retrieved the data on October 21, 2021. We conducted an initial data cleaning by removing tweets that include contrasting hashtags that support Fauci (such as \u201cSaveFauci,\u201d \u201cFauciHero,\u201d \u201cKeepFauci\u201d) or against Trump (such as \u201cTrumpLies,\u201d \u201cWorstPresidentEver,\u201d \u201cTrumpIsALoser\u201d), because anti-Trump tweets supported Fauci. We also removed tweets that received no retweets and retained 7,960 tweets for further analysis.  Identify Anti-intellectual Discursive Elements We used an inductive and deductive approach to identify anti-intellectual discursive elements. An inductive analysis using unsupervised learning methods is often the first step in extracting concepts of theoretical interest from texts (Grimmer et al., 2022). We first conducted structural topic modeling (STM) (Roberts et al., 2014), an unsupervised machine learning method to preliminarily examine (1) the presence of the three elements we proposed may exist in the data and (2) how anti-intellectual discursive elements might be expressed through the text \nAnti-intellectualism on Twitter 16 data1. Please see the supplementary document (p.2-9) for the procedures and results of STM. Since topic modeling assumes the categories of texts are unknown, treating topics as proposed discursive elements violates the assumption and may produce less inaccurate results (Nelson et al., 2018). Therefore, we used supervised machine learning (SML), a deductive approach for measuring each element in anti-intellectual discursive elements. We built a data labeling instruction based on the definition of each discursive element and the topic modeling results. Then, we employed coders from Amazon Mechanical Turk (a crowdsourcing platform) to manually label 3,000 randomly selected tweets into one of the five labels: (1) people-scientist confrontation; (2) question the motivation of Fauci; (3) question the knowledge of Fauci; (4) support Fauci; and (5) none of the above categories. Table S3 shows the definitions and examples of each label in the instruction. Lastly, we built a multi-classification model using the value of TF-IDF (Term Frequency-Inverse Document Frequency) of each word and the proportion of each topic from STM. We explained the details of SML steps in the supplementary document (p.10-13). The results of SML showed how and to what extent anti-intellectual discursive elements were expressed in the anti-Fauci tweets (RQ1-3). To answer RQ4, we plotted the trendline to examine how the number of retweets of anti-Fauci tweets that included each discursive element varied over time. Identify Sources of Anti-intellectual Discursive Elements  We first automatically coded Twitter accounts into one of four categories: politicians, news media, non-institutional actors, and others. The news media category includes organizational accounts that mainly produce news for the public, including mainstream media,  1 We removed 813 tweets that were duplicated and 416 tweets with less than five words (excluding hashtags) in machine learning. Manual inspection showed many tweets simply mentioned uncivil words or hashtags as verbal attacks. They are less likely to address explicitly any of the three discursive elements we proposed. Examples are: \u201cThe Big Lie!! #ArrestFauci,\u201d \u201cFauci is a clown! #FirueFauci,\u201d and \u201cTime to #FireFauci.\u201d  \nAnti-intellectualism on Twitter 17 alternative media, online news websites, or news blogs. The category of non-institutional actors includes (1) individual Twitter users who are not politicians and (2) organizational accounts that mainly orchestrate advocacy work. Table S5 shows the steps in automatic coding. A post-hoc manual validation based on 237 randomly selected accounts (10% of total accounts) showed that the agreement between human coding and automatic coding was 98%. The validation indicated that the automatic coding produced reliable coding results. We first compared the average retweets of tweets by politicians, news media, and non-institutional actors using the Mann-Whitney tests (H1). Using a fact-checking tool (https://mediabiasfactcheck.com), we then manually inspected partisan bias and source credibility of news accounts on Twitter (H2) and the domain names of URLs that anti-intellectual tweets contained (H3). We manually labeled media bias and the source credibility of 26 domain names (from the 15 most common and the 15 most retweeted domain names). Lastly, we performed a chi-squared test to compare the total volume of tweets (H4) and the discursive elements tweeted by politicians, news media, and non-institutional actors (RQ5).  6. Findings Anti-intellectual Discursive Elements Present in Anti-Fauci Tweets (RQ1-4) The supervised machine learning results show that the most common element was delegitimizing the motivation of scientists (n=2,711, 40%). Tweets in this category alleged that Fauci and other scientists (e.g., Deborah Birx, a physician and White House Coronavirus Response Coordinator) were corrupted and had hidden political agendas. They also mentioned Bill Gates, Democratic politicians (such as Hilary Clinton), and conspiracy theories such as Big Pharma, Scamdemic, Plandemic, and QAnon (Figure S3B). Example tweets are: \u201cFauci is driven by big Pharma, Greed and Profit. He let millions die with AIDS because he wanted to tout his \nAnti-intellectualism on Twitter 18 Big Pharma agenda. Now he\u2019s pushing his vaccine agenda #FauciTheFraud\u201d, \u201cDr. Fauci, Gates, Clinton and billions to be made in vaccines. Fauci paid $3.75 Million to Wuhan to develop Covid19. #FireFauci/Birx\u201d, and \u201c#Qanons #FireFauci he has known all along and has the most to gain! #WWG1WGA #GreatAwakening.\u201d  Next was people-scientist confrontation (n=1,531, 23%). Tweets in this category expressed resistance to Covid-19 policies (e.g., shutdowns and mask mandates) and the opposition between Fauci and the Americans (Figure S3A). Example tweets are: \u201cYou need to #FIREFAUCI He is hurting YOU and AMERICA #ArmyForTrump #Trump2020\u201d, \u201cWake Up America!! #CDC is NOT a govt Agency! Why are we even following their guidelines at all\u201d, and \u201cAs elites profit from \u2018pandemic\u2019 in very huge ways...rest of America suffers. No job, no food, no necessities for many households.\u201d  Delegitimizing the knowledge of scientists (n=1,184, 18%) was the least common element. Tweets in this category alleged faulty evidence behind mask policies, hydroxychloroquine, and skepticism towards prediction models (Figure S3C). Example tweets are: \u201cDear Trump, it\u2019s time to #FireFauci. Fauci's Follies: US Coronavirus Field Hospitals Shut Down\u2014Most Without Treating a Single Patient\u2014Because Garbage Models Used by US \u2018Experts\u2019\u201d, \u201cNew #Hydroxychloroquine Study Vindicates President Trump and Should End Dr. Fauci\u2019s Career at NIAID and in Medicine #FireFauci #CDC\u201d, and \u201cscientific models were wrong! #FireFauci Discharges Outpace Hospitalizations in New York for 4th Straight Day.\u201d  In addition to tweets in the three anti-intellectual discursive categories, we found that the remaining tweets did not belong to any three discursive elements (Figure S3D). For example, we found tweets that support Fauci, express no clear attitudes about Fauci (e.g.,\u201cThe #firefauci hashtag was trending\u201d), or simply mention \u201c#firefauci\u201d with verbal attacks on scientists (e.g., \nAnti-intellectualism on Twitter 19 \u201cYou lying sack of poo! #FireFauci\u201d \u201cThis little nugget popped up just now... #FireFauci\u201d) or politicians (e.g., \u201cJoe lied & people died! #FireFauci\u201d). Many tweets also used anti-Fauci hashtags to promote far-right radio shows, podcasts, YouTube videos, and news programs. For example, a user tweeted \u201cMark Levin Show PODCAST Friday 8/13/2021\u2026 #TheGreat #Afganistan #BidenAdministration #coronavirus #FireFauci #masks #inflation #unemployment #teachersunions #reopenourschools #1776patriots #silent #majority #AmericaFirst #trump #BackToSchool.\u201d Such tweets were categorized in the \u201cother\u201d category (n=1,305, 19%).  We examined whether the retweets of anti-Fauci tweets that included three anti-intellectual discursive elements increased over time (RQ4). Although the volume of tweets that delegitimized motivation was consistently the most common (Figure 1A), the pattern of retweets of the three discursive elements differed over time (Figure 1B). Retweets of the three discursive elements first spiked in April 2020, when Trump retweeted a message from a supporter who questioned Fauci\u2019s early judgment and advocated for firing Fauci (Orr and Levine, 2020). Tweets that delegitimized the knowledge of scientists received the highest retweets then. The volume of retweets for all three discursive elements sharply decreased from May 2020 until February 2021, when Fox News reporter, Lisa Boothe, criticized Fauci for exploiting the pandemic for his benefit. Retweets that delegitimized the motivation of scientists received a growing number of retweets since April 2021 and peaked in June 2021, when Republican politicians proposed the so-called Fire Fauci Act.     \nAnti-intellectualism on Twitter 20 Figure 1. The Presence of three anti-intellectual discursive elements over time   \n  \n The Construction of Anti-intellectual Discourses (H1-H4, RQ5) We found a total of 2,685 accounts posted 5,425 tweets that included at least one of the three anti-intellectual discourses (excluding tweets in the \u201cother\u201d category). Politicians (n=47, 2%), news media (n=9, 0.3%), and non-institutional actors (n=2,308, 86%) accounted for nearly 89 percent of total accounts. Six accounts were coded as \u201cother\u201d (0.2%). They included religious groups (e.g., catholicisourco), bots, and local community organizations (e.g., Coal Region Canary). We dropped 315 accounts that were suspended by Twitter. We hypothesized that tweets from politicians spark more retweets than tweets from news media and non-institutionalized \nTrump retweeted \u201cFireFauci\u201d The first vaccine doses were administered on December 14, 2020. Congress women Majorie Taylor Greene mentioned The Fire Fauci Act on Twitter.  A group of congressmen/congress women introduced The Fire Fauci Act. Republican Senator Rand Paul questioned Fauci in a Senate hearing.  Del Bigtree, an antivaccinist, questioned the authenticity of COVID-19 case figures on Twitter.  \n\nAnti-intellectualism on Twitter 21 actors (H1). Tweets from politicians generated a greater number of retweets (Mean=1,489, Median=34, SD=6,254, Min=1, Max=41,987) than the tweets from news media (Mean=15, Median = 4, SD=24, Min=1, Max=76). The difference was significant in a Wilcoxon test to compare two samples that were not normally distributed (W=293.5, p=.01). Tweets from politicians gained significantly more retweets than non-institutional actors (Mean=43, Median=2, SD=450, Min=1, Max=14,481; W=84,868, p < .001). This finding supported H1.  We hypothesized that more conservative news media than liberal news media would post anti-intellectual tweets (H2). We identified nine news outlet accounts. Six were conservative news outlets (see Table S6 for full information). These include three far-right alternative news media with questionable credibility (The Colorado Herald, TruNews, The Western Journal) and three conservative news media (The College Fix, The Jewish Voice, Washington Examiner). Our methodology identified no liberal news media accounts on Twitter posting an anti-Fauci tweet. This finding supports H2. We hypothesized that anti-intellectual tweets would link more to conservative news media than liberal news media (H3). We found 2,335 tweets (43%) including a URL link. Out of the 26 domain names analyzed, 18 were conservative news outlets and four were liberal news outlets (Table S7 and S8). Particularly, 497 tweets (21% of tweets with a link) included a link to the 18 conservative news media, while only 31 (0.1 %) included a link to one of the four liberal news media. (\u03c72 = 607.11, p-value < .001). Thus, this finding supported H3. Many tweets included a link to far-right media or conspiracy/pseudoscience sources with questionable credibility (e.g., washingtontimes.com, truepundit.com). Two organizations (The Gateway Pundits, True Pundit) have been suspended by Twitter. Although four domains were also from moderate or liberal mainstream media (nytimes.com, today.com, msn.com, newsweek.com), \nAnti-intellectualism on Twitter 22 their stories were often misinterpreted or reframed to support anti-Fauci claims. For example, Peter Navarro, the assistant to former U.S. President Trump, shared a New York Times article but tweeted \u201cFauci racket. Create pandemic. Jam vaccine down kids throats. Profits for big pharma. Rinse and repeat. #firefauci.\u201d This generated 2,202 retweets. We expected more anti-intellectual tweets from non-institutional actors than politicians and news media (H4). We found that 4,656 anti-intellectual tweets (97.5 %) were from non-institutional actors, 99 from politicians (2.1%), and 11 tweets from news media (0.2%. \u03c72 = 13,403, p < .001). Six tweets were from accounts labeled as \u201cother.\u201d This finding supported H4. Some individual users were journalists affiliated with conservative news media, such as TV anchors working for conservative news media, and hosts for far-right radio shows. We also found several anti-Fauci medical \u201cexperts,\u201d such as Dr. Christiane Northrup, who is known for advocating alternative medicine, anti-vaccine claims, and the QAnon conspiracy theory. Lastly, we compared the prevalence of discursive elements by politicians, news media, and non-institutional actors (RQ5). As shown in Table 1, politicians were the most likely to express the delegitimization of scientists\u2019 motivations, followed by grassroots organizations, and then individual users. However, these differences in the use of discursive elements were not statistically significant (\u03c72 (6, 5424) = 8.27, p-value = .21).  Table 1. Comparing proportions of discursive elements by politicians, news media, grassroots advocacy organizations, and individuals.   Politicians News Media Non-institutional actors People-scientist confrontation 27% (n=27) 27% (n=3) 28% (n=1,323) Delegitimizing motivation 59% (n=58) 55% (n=6) 49% (n=2,292) Delegitimizing knowledge 14% (n=14) 18% (n=2) 22% (n=1,041)  7. Discussion, Implications, and Limitations \nAnti-intellectualism on Twitter 23 This study examined the elements and sources of anti-intellectual discourse in anti-Fauci tweets posted from 2020 to 2021, covering the period of the COVID-19 pandemic. We identified the presence of three discursive elements: people-scientist antagonism, delegitimizing the motivations of scientists, and delegitimizing the knowledge of scientists in anti-intellectual discourse, aligned with the theoretical conceptualization of science-related populism by Mede and Sch\u00e4fer (2020). Tweets expressing the three discursive elements accounted for most anti-Fauci tweets (81%). Politicians, news media, and non-institutional actors played distinct roles and jointly constructed anti-intellectual discourses on social media. Tweets from politicians received more retweets, while conservative and far-right news media were the main institutional sources cited in many anti-intellectual tweets. Non-institutional actors contributed to the majority (98%) of anti-intellectual tweets. The discursive elements used by politicians, news media, and non-institutional actors were not significantly different.  Our findings provide several theoretical and practical implications. First, the components of anti-intellectual discourse were highly correlated with science-related populism. Tweets that delegitimized the motivation of scientists had more presence than tweets that delegitimized the knowledge of scientists. This pattern is consistent with previous findings by Evans and Hargittai (2020), which showed that people who distrust scientists tend to believe that scientists do not represent public value. We also found that several conspiracy theories (e.g., plandemic, Big Pharma, Scamdemic) were expressed through this discursive element. This finding echoed previous studies, which showed that the beliefs in COVID-19 conspiracy theories were closely related to far-right ideologies and the low trust of scientific experts (Eberl et al., 2021). Additionally, our findings showed that Fauci\u2019s connection with Democratic politicians and the refutation from Republican politicians often became the reason for anti-intellectualists to \nAnti-intellectualism on Twitter 24 question the motivation of scientists. As an expert and leader of federal health organizations, Fauci was asked to inform the current scientific understanding of COVID-19 from policymakers and media and be involved in public health policymaking. However, the scientists\u2019 involvement with policymaking may create a dilemma for them in communicating science with the public. As shown in our findings, the anti-intellectualists often misinterpreted Fauci\u2019s communications with politicians and their involvement with policymaking.  We also found that tweets that included people-scientist antagonism express a strong objection against COVID-19 control policies (e.g., mask mandate, business restriction vaccination, quarantine policy). Fauci was blamed for the personal and economic challenges associated with policies, such as economic recession and violation of individual freedom. This finding echoes Merkley and Loewen (2020), which showed anti-intellectualism relates to low COVID-19 risk perceptions, social distancing, mask usage, and misperception. The empirical evidence opens a question of whether scientists should be the key spokesperson to deliver public health policy decisions and how to communicate public health policies with the public who show distrust in science/scientists. As Evans and Hargittai (2020) also show, a proscription about policies, rather than the description of scientific facts, is more likely to elicit anti-scientist sentiment. Along with our findings, scientists may consider explaining more scientific facts than public health policies. Policymakers, news media, or local community organizations should take more responsibility to boost the public understanding of health policies.  Over time, the volume of anti-intellectual tweets has decreased, likely because Twitter suspended accounts owned by a few politicians (Donald Trump, Marjorie Taylor Greene, Shiva Ayyadurai) and several anti-science Trump supporters. This finding echoes a recent study by Mede and Sch\u00e4fer (2021), which found that science-related populist attitudes decreased after the \nAnti-intellectualism on Twitter 25 pandemic; the public, even supporters of science-related populism before the pandemic, trust in science and science-related institutions more in Switzerland. However, the trend in retweets of anti-intellectual discourses was somewhat different in our analysis; the retweets of anti-Fauci tweets resurged and sustained after their volumes of retweets remained low for a long time. This trend correlates with the stances of U.S. political elites who brought back the anti-Fauci sentiment as they attempted to pass the Fire Fauci Act. This finding suggests that there may be a difference in the formation and construction of anti-intellectualism between the US and other countries. In the US, the lasting affective polarization leads to the politicization of COVID-19 and public trust in science and scientists (Hegland et al., 2022), whereas countries like Switzerland tend to have less polarized debates on scientific issues (Arlt et al., 2019).   Regarding the institutional and non-institutional sources that construct different anti-intellectual discursive elements on Twitter, we showed that the conservative news media, far-right groups, and fake news information sites were closely related to anti-intellectual discourse circulated on Twitter. The far-right media did not directly supply anti-intellectual discourse, probably because of Twitter\u2019s content moderation mechanism. Instead, Twitter users shared anti-intellectual content from their websites by containing the links in tweets. These findings provide us with two implications. First, the media environment for science communication is much more complex. The flows of anti-intellectual discourse have involved collaboration from both institutional and non-institutional actors in a networked model, but also inter-media transmission between social media and web media. Second, Twitter can remove problematic accounts (like far-right groups, and misinformation news media), but anti-intellectual information from external sources is still spreading on Twitter.  \nAnti-intellectualism on Twitter 26 We also found some anti-Fauci tweets from medical experts, which seems paradoxical to the definition of anti-intellectualism. This finding suggests that anti-intellectualists are selective in the kind of \u201cexpert\u201d to believe. Many conspiracy theories (Plandemic, QAnon) originated from medical experts (Judy Mikovits) who believed in pseudoscientists, anti-vaccine, and the practice of alternative medicine. As Peck (2019) pointed out, the relationship between populists and intellectual culture is complicated because people have different understandings of what an expert is. The far-right populists also rely on studies, facts, and scientific languages from experts to debunk science (Peck, 2019) and construct counter-knowledge, alternative science, or alternative fact to support right-wing populism (Yl\u00e4-Anttila, 2018). Along with these studies, our finding suggests that emphasizing scientific facts may be insufficient for scientists to communicate with the public because anti-intellectuals may only believe \u201cfacts\u201d and \u201cexperts\u201d that support their anti-establishment goals or are aligned with their partisanship. Individual trust in a scientist and the perception of their expertise may rely more on one\u2019s partisanship or ideologies than the knowledge or public value that the scientist has expressed to the public. We also showed that anti-intellectual discourse could only include verbal attacks on scientists and politicians. This finding aligned with the conceptual distinction between anti-intellectualism and science-related populism and indicates that anti-intellectualism has a broader meaning than science-related populism (Mede et al., 2022). Our study withholds several limitations. First, our analysis of Anti-Fauci tweets only examined the components and constructions of anti-intellectual discourses during the pandemic, using and applying a theoretical lens from science-related populism. We found that delegitimizing the motivation of scientists was much more popular than delegitimizing the knowledge of scientists, likely because of the impact of political elites and partisan conflicts in \nAnti-intellectualism on Twitter 27 the U.S. social and political context. The findings may be generalizable to countries where institutional actors like political elites sparked polarized debates on scientific issues, and scientists (like Fauci) closely participate in communicating science to the public. In other countries with lower affective polarization and high positive public views on science (e.g., Switzerland) (Mede et al., 2022), questioning the knowledge of scientists may be more prevalent than questioning their motivation in anti-intellectual discourse. As Merkley (2020) pointed out, anti-intellectualism is also related to several other reasons, such as religious fundamentalism, ideology, and individual characteristics (such as the tendency for rational thinking). At least in the European context, postmodernism shows an increasing impact on public trust in science and scientists, particularly for the younger generations (Kuntz, 2012). It remains an open question for future studies to explore and compare different components of anti-intellectual discourses on social media across countries and cultures. Second, although we showed homogeneity exists among the discursive elements produced by politicians, news media, and non-institutional actors, we did not analyze the contents of the news media websites that were embedded in anti-Fauci tweets. Our findings could be limited to the affordances and the content moderation mechanism of Twitter. As we have shown, the spread of anti-intellectual discourse is intermedia. Future studies need to consider web and social media platforms as an ecosystem and explore the coordinated propagation across platforms.   8. Conclusion  Despite the limitations, our study contributes to the scholarship in anti-intellectualism, science-related populism, and public science communication. First, theoretically, we bridge the studies in populism and anti-intellectualism. We enhanced the current understanding of the \nAnti-intellectualism on Twitter 28 components of anti-intellectualism and their connections to science-related populism. We also found distinct roles of institutional and non-institutional actors in producing and spreading anti-intellectual discourses on Twitter. To enhance the literature on anti-intellectualism and public science communication, future studies may consider examining: (1) effective content moderation mechanisms to curb the spread of anti-intellectual discourses on social media; (2) the trans-media diffusion of anti-intellectual discourse, especially those from the far-right media; and (3) the factors that drive multi-step flows of anti-intellectual discourse among institutional and non-institutional actors in a networked science communication model.    \nAnti-intellectualism on Twitter 29 References Alba D and Frenkel S (2020) Medical expert who corrects Trump is now a target of the far right. The New York Times, 28 March. Available at: https://www.nytimes.com/2020/03/28/technology/coronavirus-fauci-trump-conspiracy-target.html (accessed 25 March 2022). Arlt D, Rauchfleisch A and Sch\u00e4fer MS (2019) Between fragmentation and dialogue. Twitter communities and political debate about the Swiss \u201cNuclear Withdrawal Initiative.\u201d Environmental Communication, 13(4), 440\u2013456. https://doi.org/10.1080/17524032.2018.1430600 Batova T (2021) To wear or not to wear: A commentary on mistrust in public comments to CDC tweets about mask-wearing during COVID19. International Journal of Business Communication: 232948842110085. DOI: 10.1177/23294884211008584. Boberg S, Quandt T, Schatto-Eckrodt T and Frischlich L (2020) Pandemic populism: Facebook pages of alternative news media and the Corona crisis\u2014A Computational content analysis. arXiv:2004.02566 [cs]. Available at: http://arxiv.org/abs/2004.02566 (accessed 25 March 2022). Bonnevie E, Gallegos-Jeffrey A, Goldbarg J, Byrd B and Smyser J (2021) Quantifying the rise of vaccine opposition on Twitter during the COVID-19 pandemic. Journal of Communication in Healthcare 14(1): 12\u201319. DOI: 10.1080/17538068.2020.1858222. Bovet A and Makse H (2019) Influence of fake news in Twitter during the 2016 US presidential election. Nature Communications 10(1): 7. DOI: 10.1038/s41467-018-07761-2. \nAnti-intellectualism on Twitter 30 Clinton J, Cohen J, Lapinski J and Trussler M (2021) Partisan pandemic: How partisanship and public health concerns affect individuals\u2019 social mobility during COVID-19. Science Advances 7(2): eabd7204. DOI: 10.1126/sciadv.abd7204. Dhanani, LY and Franz B (2020) The role of news consumption and trust in public health leadership in shaping COVID-19 knowledge and prejudice. Frontiers in Psychology: p.2812. DOI: 10.3389/fpsyg.2020.560828 Durazzi F, M\u00fcller M, Salath\u00e9 M and Remondini D (2021) Clusters of science and health related Twitter users become more isolated during the COVID-19 pandemic. Scientific Reports 11(1): 19655. DOI: 10.1038/s41598-021-99301-0. Eberl J, Huber R and Greussing E (2021) From populism to the \u201cplandemic\u201d: Why populists believe in COVID-19 conspiracies. Journal of Elections, Public Opinion and Parties 31(sup1): 272\u2013284. DOI: 10.1080/17457289.2021.1924730. Evans J and Hargittai E (2020) Who doesn\u2019t trust Fauci? The public\u2019s belief in the expertise and shared values of scientists in the COVID-19 Pandemic. Socius: Sociological Research for a Dynamic World 6: 237802312094733. DOI: 10.1177/2378023120947337. Grimmer J, Roberts ME and Stewart BM (2022) Text as data: A new framework for machine learning and the social sciences. Princeton University Press. Grossman G, Kim S, Rexer JM and Thirumurthy H (2020). Political partisanship influences behavioral responses to governors\u2019 recommendations for COVID-19 prevention in the United States. Proceedings of the National Academy of Sciences, 117(39), 24144-24153. DOI: 10.1073/pnas.2007835117 Hart P, Chinn S and Soroka S (2020) Politicization and polarization in COVID-19 news coverage. Science Communication 42(5): 679\u2013697. DOI: 10.1177/1075547020950735. \nAnti-intellectualism on Twitter 31 Hegland A, Zhang AL, Zichettella B and Pasek J (2022) A partisan pandemic: How COVID-19 was primed for polarization. Annals of the American Academy of Political and Social Science, 700(1), 55\u201372. https://doi.org/10.1177/00027162221083686 Hofstadter R (1963) Anti-intellectualism in American Life. (3. Print.) (Vol. 713). Vintage.  Holt K, Ustad Figenschou T and Frischlich L (2019) Key dimensions of alternative news media. Digital Journalism 7(7): 860\u2013869. DOI: 10.1080/21670811.2019.1625715. Kreps S and Kriner D (2020) Model uncertainty, political contestation, and public trust in science: Evidence from the COVID-19 pandemic. Science Advances 6(43): eabd4563. DOI: 10.1126/sciadv.abd4563. Kuntz M (2012) The postmodern assault on science: If all truths are equal, who cares what science has to say? EMBO reports 13(10): 885\u2013889. DOI: 10.1038/embor.2012.130. Kwak H, Lee C, Park H and Moon S (2010) What is Twitter, a social network or a news media? Proceedings of the 19th International Conference on World Wide Web, WWW \u201910, 591\u2013600. https://doi.org/10.1145/1772690.1772751 Lindgren S (2019) Movement mobilization in the age of hashtag activism: Examining the challenge of noise, hate, and disengagement in the #MeToo campaign. Policy & Internet 11(4): 418\u2013438. DOI: 10.1002/poi3.212. Mahl D, Zeng J and Sch\u00e4fer MS (2021). From \u201cNasa Lies\u201d to \u201cReptilian Eyes\u201d: Mapping communication about 10 conspiracy theories, their communities, and main propagators on Twitter. Social Media and Society, 7(2). https://doi.org/10.1177/20563051211017482 McCorriston J, Jurgens D and Ruths D (2015) Organizations are users too: Characterizing and detecting the presence of organizations on Twitter. Proceedings of the International AAAI \nAnti-intellectualism on Twitter 32 Conference on Web and Social Media 9(1): 650\u2013653. Available at: https://ojs.aaai.org/index.php/ICWSM/article/view/14672 (accessed 25 March 2022). McLaughlin D, Mewhirter J and Sanders R (2021) The belief that politics drive scientific research & its impact on COVID-19 risk assessment. PLOS ONE 16(4): e0249937. DOI: 10.1371/journal.pone.0249937. Mede N and Sch\u00e4fer M (2020) Science-related populism: Conceptualizing populist demands toward science. Public Understanding of Science 29(5): 473\u2013491. DOI: 10.1177/0963662520924259. Mede N and Sch\u00e4fer M (2022) Science-related populism declining during the COVID-19 pandemic: A panel survey of the Swiss population before and after the Coronavirus outbreak. Public Understanding of Science 31(2): 211\u2013222. DOI: 10.1177/09636625211056871. Mede N, Sch\u00e4fer MS, Metag J and Klinger K (2022) Who supports science-related populism? A nationally representative survey on the prevalence and explanatory factors of populist attitudes toward science in Switzerland. PLoS ONE, 17(8 August), 1\u201320. https://doi.org/10.1371/journal.pone.0271204 Merkley E (2020) Anti-Intellectualism, populism, and motivated resistance to expert consensus. Public Opinion Quarterly 84(1): 24\u201348. DOI: https://doi.org/10.1093/poq/nfz053. Merkley E and Loewen PJ (2021) Anti-intellectualism and the mass public\u2019s response to the COVID-19 pandemic. Nature Human Behaviour 5(6): 706\u2013715. DOI: 10.1038/s41562-021-01112-w. Motta M (2018) The dynamics and political implications of anti-intellectualism in the United States. American Politics Research 46(3): 465\u2013498. DOI: 10.1177/1532673X17719507. \nAnti-intellectualism on Twitter 33 M\u00fcller JW (2016) What Populists Say? In: What Is Populism? University of Pennsylvania Press, pp. 7\u201341. Nelson, L. K., Burk, D., Knudsen, M., & McCall, L. (2018). The Future of Coding: A Comparison of Hand-Coding and Three Types of Computer-Assisted Text Analysis Methods. Sociological Methods and Research. https://doi.org/10.1177/0049124118769114 Oliver J and Rahn W (2016) Rise of the Trumpenvolk: Populism in the 2016 Election. The ANNALS of the American Academy of Political and Social Science 667(1): 189\u2013206. DOI: 10.1177/0002716216662639. Orr G and Levine M (2020) Trump\u2019s #FireFauci retweet spurs a cycle of outrage and a White House denial. Available at: https://www.politico.com/news/2020/04/13/trump-fauci-fire-tweet-coronavirus-183907 (accessed 25 March 2022). Pearce W, Niederer S, \u00d6zkula SM and Querub\u00edn NS (2019). The social media life of climate change: Platforms, publics, and future imaginaries. Wiley Interdisciplinary Reviews: Climate Change, 10(2), 1\u201313. https://doi.org/10.1002/wcc.569 Peck R (2018) Fox Populism: Branding Conservatism as Working Class. Communication, society and politics. Cambridge; New York, NY: Cambridge University Press. Rao A, Morstatter F, Hu M, Chen E, Burghardt K, Ferrara E and Lerman K (2021) Political partisanship and antiscience attitudes in online discussions about COVID-19: Twitter content analysis. Journal of Medical Internet Research 23(6): e26692. DOI: 10.2196/26692. Rigney D (1991) Three kinds of anti-intellectualism: Rethinking Hofstadter. Sociological Inquiry 61(4): 434\u2013451. DOI: 10.1111/j.1475-682X.1991.tb00172.x. \nAnti-intellectualism on Twitter 34 Roberts M, Stewart B, Tingley D, et al. (2014) Structural topic models for open\u2010ended survey Responses. American Journal of Political Science 58(4): 1064\u20131082. DOI: 10.1111/ajps.12103. Santucci J (2020) What we know about the White House coronavirus task force now that Mike Pence is in charge. Available at: https://www.usatoday.com/story/news/politics/2020/02/27/coronavirus-what-we-know-mike-pence-and-task-force/4891905002/ (accessed 26 March 2022). Twitter (2021, December) COVID-19 misleading information policy. Retrieved March 30, 2022 from https://help.twitter.com/en/rules-and-policies/medical-misinformation-policy  van Dijck J and Alinejad D (2020) Social Media and Trust in Scientific Expertise: Debating the Covid-19 Pandemic in The Netherlands. Social Media + Society 6(4): 205630512098105. DOI: 10.1177/2056305120981057. Vosoughi S, Roy D and Aral S (2018) The spread of true and false news online. Science. DOI: 10.1126/science.aap9559. Yan P, Schroeder R and Stier S (2021) Is there a link between climate change scepticism and populism? An analysis of web tracking and survey data from Europe and the US. Information, Communication & Society 0(0): 1\u201340. DOI: 10.1080/1369118X.2020.1864005. Yl\u00e4-Anttila T (2018) Populist knowledge: \u2018Post-truth\u2019 repertoires of contesting epistemic authorities. European Journal of Cultural and Political Sociology 5(4): 356\u2013388. DOI: 10.1080/23254823.2017.1414620. \nView publication stats", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "This is the accepted version and may differ from the final authoritative version published in Public Understanding of Science. For the final published article \u2026", "author": ["Y Chen", "J Long", "J Jun", "SH Kim", "A Zain", "C Piacentine"], "venue": "NA", "pub_year": "NA", "abstract": "Anti-intellectualism (resentment, hostility, and mistrust of experts) has become a growing  concern that influences the public understanding of science during the pandemic. Using topic"}, "filled": false, "gsrank": 382, "pub_url": "https://jacob-long.com/pdf/Chen_Long_et_al_PUOS_Post_Print.pdf", "author_id": ["", "fi-oVkIAAAAJ", "ZUZKK_EAAAAJ", "", "nW-ChhoAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:jorC0hEpLWEJ:scholar.google.com/&output=cite&scirp=381&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=jorC0hEpLWEJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:jorC0hEpLWEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://jacob-long.com/pdf/Chen_Long_et_al_PUOS_Post_Print.pdf"}}, {"title": "Individual misinformation tagging reinforces echo chambers; collective tagging does not", "year": "2023", "pdf_data": "Article https://doi.org/10.1038/s41467-025-55868-0\nDifferential impact from individual versus\ncollective misinformation tagging on thed i v e r s i t yo fT w i t t e r( X )i n f o r m a t i o nengagement and mobility\nJunsol Kim1, Zhao Wang2, Haohan Shi3, Hsin-Keng Ling4&\nJames Evans1,2,5\nFears about the destabilizing impact of misinformation online have motivated\nindividuals and platforms to respond. Individuals have increasingly challengedothers \u2019online claims with fact-checks in p ursuit of a healthier information\necosystem and to break down echo chamb ers of self-reinforcing opinion.\nUsing Twitter (now X) data, here we show the consequences of individualmisinformation tagging: tagged poste rs had explored novel political infor-\nmation and expanded topical interest s immediately prior ,b u tb e i n gt a g g e d\ncaused posters to retreat into informa tion bubbles. These unintended con-\nsequences were softened by a collective veri \ufb01cation system for misinforma-\ntion moderation. In Twitter \u2019s new feature, Community Notes, misinformation\ntagging was peer-reviewed by other fact -checkers before revelation to the\nposter. With collective misinformation tagging, posters were less likely toretreat from diverse information engagement. Detailed comparison demon-strated differences in toxicity, sentime nt, readability, and delay in individual\nversus collective misinformation tagging messages. These \ufb01ndings provide\nevidence for differential impacts from i ndividual versus collective moderation\nstrategies on the diversity of informat ion engagement and mobility across the\ninformation ecosystem.\nThe visibility of mis- and disinformation online have attracted sub-\nstantial attention around the world wi th demonstrations of their direct\nin\ufb02uence on major collective action in the world1\u20135. These actions\nrange from buying and selling stocks2and avoidance of vaccines3to\nthe attempted coup and occupation of the U.S. Capitol by rioters4.\nLegitimate fears about the destabilizing in \ufb02uence of false online\ninformation have inspired and put pressure on both individuals andplatforms to respond. Individuals proactively correct others \u2019claims by\ndeploying links to fact-checking websites, such as PolitiFact andSnopes\n6\u201310. With the potential for amplifying misinformation through\ufb01lter bubbles11,12, social media platforms like Twitter and Facebook\nhave come under public and political pressure to implement mis-information moderation strategies\n13\u201315.\nIndividuals have become empowered to challenge others \u2019online\nclaims with misinformation tags (or fact-checks) in pursuit of a healthyinformation ecosystem and to break down ideological echochambers\n6\u20138. These misinformation tags tend to target political\noutgroups6,7,9, exposing tagged posters to opposing ideological per-\nspectives. It is less clear, however, whether their misinformation tag-ging motivates targeted posters to explore diverse political contentsReceived: 2 December 2023\nAccepted: 2 January 2025\nCheck for updates\n1Department of Sociology, University of Chicago, Chicago, IL, USA.2Computational Social Science, University of Chicago, Chicago, IL, USA.3School of\nCommunication, Northwestern University, Evanston, IL, USA.4Department of Sociology, University of Michigan, Ann Arbor, MI, USA.5Santa Fe Institute, Santa\nFe, NM, USA. e-mail: jevans@uchicago.edu\nNature Communications |          (2025) 16:973 11234567890():,;\n1234567890():,;\nafterward. Earlier research on motivated reasoning suggests that\nmisinformation tags contradicting targeted poster \u2019s beliefs could\nback\ufb01re and reinforce preexisting beliefs16,17, which could discourage\npeople from exploring diverse information18.B yc o n t r a s t ,ag r o w i n g\nbody of research argues that misinformation tagging does not back-\n\ufb01re, but reduces engagement with misinformation and expands it with\ndiverse information13,14,19,20. These mixed \ufb01ndings suggest that the\neffects of misinformation tagging could depend on the method ofcorrecting misinformation. Individual misinformation tagging byother users often involves toxic and intolerant messages that dehu-manize targeted posters\n9,21, potentially hindering their willingness to\nexplore diverse information22.\nPlatforms have experimented with institutionalized systems that\nverify the accuracy of content through collective inputs from a widerdistribution of users. Notably, on Twitter \u2019s new platform, Community\nNotes (formerly Birdwatch), misinformation tags undergo a formal\npeer-review process by diverse users before being revealed to theo r i g i n a lp o s t e r sa n db r o a d e rT w i t t e ru s e rc o m m u n i t y\n8,13,14.O t h e r\nplatforms, including YouTube and Facebook, have recently tes-ted or announced plans to implement features similar to CommunityNotes\n23,24. Rather than indiscriminately exposing users to mis-\ninformation tags, Community Notes selectively exposes misinforma-tion tags that receive votes from heterogeneous user groups, ensuringthat they are veri \ufb01ed across a broad spectrum of perspectives\n13to\nactivate the wisdom of crowds25,26. The platform also assesses the\nalignment of users \u2019prior contributions with the crowd \u2019sd e c i s i o n s ,\n\ufb01ltering out voters who frequently oppose and backlash against valid\nfact-checks on misinformation. Although individual tags may be noisyand less effective, aggregating them collectively could lead to high-quality crowd judgments that align with expert fact-checks across arange of topics, from COVID-19 to politics\n14,27\u201329. Furthermore, the\nCommunity Notes platform has speci \ufb01cally instituted norms that deter\ntoxic and intolerant misinformation tagging messages30,p o t e n t i a l l y\nenhancing the ef \ufb01cacy of misinformation moderations and gently\nencouraging posters to leave their echo chambers and explore abroader world of diverse information.\nIn this study, we explore the impacts of individual and collective\nmisinformation tagging on tagged posters \u2019echo chambers. Echo\nchambers refer to \u201cbounded, enclosed media spaces that have the\npotential to both magnify messages delivered within them and insulatethem from rebuttal \u201d\n31,32, which could increase susceptibility to\nmisinformation11,33,34. One indicator of echo chambers is their lack of\ninteraction with politically diverse, cross-cutting sources of informa-tion. Prior research has measured echo chambers by selectiveengagement with like-minded news sources, which insulate peoplefrom opposing perspectives that could empower rebuttal\n35,36.T h i s\nmeasure strongly correlates with other echo chamber indicators, suchas intensive interactions with like-minded users (i.e., homophily)\n37,38.\nLiterature suggests that lack of exposure to and cross-veri \ufb01cation\nthrough opposing perspectives could erode the ability to \ufb01nd, evalu-\nate, and use information effectively11,39,40. It could provide users with\nthe illusion that their views are publicly supported41,42,w e a k e n i n gt h e i r\noverall immunity against misinformation.\nThe other key indicator of echo chambers is their absence of\ncontent diversity resulting from limited engagement with diverse,unfamiliar topics. Emerging literature has documented the rise ofsocio-political endogamy, noting that both left and right increasinglydevelop distinct topical interests, encompassing knowledge bases,cultural tastes, and lifestyles\n43\u201345. For example, left-leaning individuals\nare more likely to engage with basic science books about physics,\nastronomy, and zoology, while right-leaning individuals prefer those\nabout applied and commercial sciences like criminology, medicine,and geophysics\n45. In this way, political polarization spills over into a\nvariety of other topics, leading to multi-dimensional segregationwhere opposing political groups share progressively less commonground and inhabit different realities even in topics apparently unre-\nlated to politics\n43,46. Topical echo chambers, which magnify topics\nprevalent within one political group and insulate them from others,can problematize intergroup communication and interaction.\nDoes exposure to each type of misinformation tagging encou-\nrage or discourage posters from exploring diverse information andbreaking out of echo chambers? To answer this question, we uselarge-scale digital traces from the platform formerly known asTwitter ( Xas of July, 2023) to identify posters exposed to each\napproach of misinformation tagging. First, we identify posters tar-geted by individual misinformation tags. These posters \u2019tweets\nreceived other individuals \u2019voluntary replies, citing fact-checking\narticles from PolitiFact, one of the largest and most studied pro-fessional fact-checking organizations in the United States\n7,10. Sec-\nond, we examine posters targeted by collective misinformation\ntags. These posters \u2019tweets received notes that contain collectively\nveri\ufb01ed fact-checks through Twitter \u2019s Community Notes platform.\nFigure 1a visualizes the mechanism of each type of misinformation\ntagging, which represent the most prevalent misinformation mod-eration strategies on Twitter\n6\u201310,13\u201315. Supplementary Fig. 1 presents\nan example of individual and collective tags that correct topicallyidentical, COVID-19 misinformation.\nUsing 712,948 tweets that cite news sources \u2014including posts,\nretweets, and quotes \u2014posted by 7733 users before and after they were\ntargeted by misinformation tags, we estimate the effects of these tagson the posters \u2019echo chambers. Speci \ufb01cally, we measure echo cham-\nbers using political and content diversity in their posting and sharing\nbehavior (see Fig. 1b). Political diversity measures whether a poster \u2019s\ntweet cites a source with opposing political stance (e.g., a right-leaningposter references left-leaning articles)\n5,47. Content diversity measures\nwhether a tweet discusses novel topics unfamiliar in the poster \u2019s his-\ntorical tweets. We apply a transformer-based sentence embeddingmodel (SentenceBERT) to extract a high-dimensional, semantic vectorrepresentation for each tweet, and aggregate the vectors of eachauthor \u2019s historical tweets to produce an average semantic vector for\neach poster. We then measure the distance between a particular tweetand the poster to assess the degree to which this tweet expands the\nposter \u2019s content diversity. As our data focus on tweets citing news\nsources, we assume that the increase of content diversity indicates theexploration of novel political news topics. For example, consider a userwho regularly consumes and shares news about COVID-19 but beginsto discuss U.S. tax and labor issues as well. This shift indicates anincrease in the user \u2019s content diversity, as detailed in Supplementary\nTable 1. We consider both political and content diversity because theyrepresent different dimensions that could reinforce one another inlimiting exposure to information and exacerbating echo chambers onsocial media\n17,43,48.\nResults\nWe aim to investigate the effects of individual and collective mis-\ninformation tagging on political and content diversity using large-scaleTwitter data. In our observational data, treatments (i.e., exposure tomisinformation tagging), however, are not randomly assigned tomisinformation posters, which pose challenges for identifying thecausal effects of misinformation tagging. To address these concerns,we apply interrupted time series (ITS) and delayed feedback (DF)analysis, which help eliminate non-causal explanations under certainassumptions.\nInterrupted time series (ITS) analysis\nInterrupted Time Series (ITS) analysis investigates whether the trend inpolitical and content diversity shifts after misinformation tagging. ITSassumes that without the intervention of misinformation tagging, thepre-treatment trend (i.e., before misinformation tagging) would per-sist, and the immediate change in trend after misinformation tagging isArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 2\nattributed to effects from tagging. We control for user-level \ufb01xed\neffects to correct for time-invariant user characteristics.\nFigure 2aa n dT a b l e 1report results from our ITS analysis (Political\nDiversity: R2=0 . 1 7 3 ,C o n t e n tD i v e r s i t y : R2= 0.243). Posters manifest an\nincreasing tendency to explore novel political information beforebeing fact-checked by misinformation tags. Speci \ufb01cally, before indi-\nvidual and collective misinformation tagging, posters increase thepolitical diversity ( \u03b2= 0.237, 95% CI = [0.125, 0.349], t(418115) = 4.14,\np< 0.001) and content diversity ( \u03b2= 0.007, 95% CI = [0.004, 0.010],\nt(418115) = 4.79, p< 0.001) of their information engagement over time.\nHaving their posts criticized by individual misinformation tags,\nhowever, causes posters to retreat within an information bubble.Immediately after tagging, posters signi \ufb01cantly decrease the political\ndiversity ( \u03b2=\u22121.009, 95% CI = [ \u22121.447, \u22120.571], t(418115) = \u22124.52,Fig. 2 | Political and content diversity change with the intervention of indivi-\ndual and collective misinformation tagging. a Results from Interrupted Time\nSeries (ITS) analysis. The x-axis denotes the timeline of tweets posted before and\nafter tagging, with negative values representing the number of weeks before\nposting tagged tweets and positive values representing the number of weeks after.\nThe y-axis represents political and content diversity, with dots indicating thediversity score for each corresponding week as estimated by the ITS analysis, anderror bars showing 95% con \ufb01dence intervals. Solid lines connect the dots revealing\ntrends of political and content diversity before and after tagging, with gray dottedlines tracing the counterfactual trend if fact-checks had not occurred. The sample\nsize is 424,969 tweets. There is no control group in this analysis; however, a com-parative interrupted time series analysis with a control group can be found inSupplementary Method 3. bIllustration of political and content diversity dynamics\nbefore and after tagging. Before individual and collective tagging, posters exhibit\nincreased political and content diversity, which increases the likelihood ofencountering a fact-checker. After individual tagging, posters retreat into infor-mation bubbles; after collective tagging, they venture further beyond them.\nFig. 1 | Misinformation Tagging and Outcomes Measurement. a Individual mis-\ninformation tagging in which individuals cite PolitiFact fact-checking articles. Col-\nlective misinformation tagging through the Community Notes platform, which\nselectively exposes veri \ufb01ed misinformation tags that receive diverse votes as\nhelpful. bOperationalization of tweet political and content diversity. Political\ndiversity captures whether a poster cites a source with opposing political stance(binary 0/1), assessed from the aggregate stances of referenced sources. Content\ndiversity captures whether a post discusses topics unfamiliar to the author \u2019s his-\ntorical tweets (continuous), assessed with the distance between the poster \u2019sa v e r -\nage tweet and a particular tweet within a contextual embedding (sentenceBERTpre-trained on Twitter)\n74.Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 3\np< 0.001) and content diversity ( \u03b2=\u22120.030, 95% CI = [ \u22120.042,\n\u22120.019], t(418115) = \u22125.10, p< 0.001) of their posts. After tagging, the\nslope becomes nearly \ufb02at, indicating that posters \u2019future posts con-\ntinue to collapse in both political diversity ( \u03b2=0 . 0 8 7 , 9 5 % C I=\n[\u22120.020, 0.194], t(418115) = 1.60, p= 0.110) and content diversity\n(\u03b2=\u22120.003, 95% CI = [ \u22120.006, 0.000], t(418115) = \u22121.95, p= 0.51).\nBy contrast, there is no statistically signi \ufb01cant evidence that col-\nlective misinformation tagging causes individuals to retreat withint h e i rp r i o ri n f o r m a t i o nb u b b l e .T h ed a t ae v e nr e v e a l sas l i g h t ,a l t h o u g hnot signi \ufb01cant, increase in political diversity ( \u03b2=0 . 2 7 0 , 9 5 % C I=\n[\u22120.824, 1.363], t(418115) = 0.48, p= 0.629) and a signi \ufb01cant increase in\ncontent diversity ( \u03b2=0 . 0 4 0 , 9 5 %C I=[ 0 . 0 1 2 , 0 . 0 6 9 ] , t(418115) = 2.74,\np= 0.006) immediately after tagging. Nevertheless, collective mis-\ninformation tagging has only a temporary effect on individual posters.Especially, the slope for content diversity changes signi \ufb01cantly after\ntagging ( \u03b2=\u22120.014 ,9 5 %C I = [ \u22120.024, \u22120.003] ,t(418115) = \u22122.60 ,\np= 0.009), eventually converging to levels experienced before the\ninitial misinformation tags occur. Despite the steepness of the slopefollowing collective tagging, our analysis indicates that contentdiversity does not signi \ufb01cantly drop below the pre-tagged period (see\nSupplementary Method 1).\nWe\ufb01nd that the gap between the effects of individual and col-\nlective misinformation tagging is signi \ufb01cant, particularly regarding the\nimmediate intercept change in political diversity ( \u03b2\nIndividual =\u22121.009,\n\u03b2Collective =0 . 2 7 0 , \u03b2Collective \u2212\u03b2Individual = 1.279, 95% CI = [0.101, 2.457],\nt(418115) = 2.13, p= 0.033) and in content diversity ( \u03b2Individual =\u22120.030,\n\u03b2Collective =0 . 0 4 0 , \u03b2Collective -\u03b2Individual = 0.070, 95% CI = [0.039, 0.102],\nt(418115) = 4.44, p< 0.001).\nAdditional analyses reveal the effects of misinformation tagging\non the proximity between posters and misinformation taggers. Thissuggests that Twitter navigation likely makes posters more visible tofact-checkers as they venture into foreign territory (see Fig. 2b).\nExposure to fact-checks causes them to retreat back into their infor-mation bubbles, distancing them from the foreign stances that fact-\nchecked them (see Supplementary Method 2).\nBecause time-variant confounders (e.g., viral news, platform\nalgorithm changes, or signi \ufb01cant external events) can affect ITS out-\ncomes, we conduct additional analyses to control for these factors.First, we control for major events during the study period throughsensitivity analyses. Second, we apply comparative interrupted time\nseries (CITS) analyses. These additional analyses support our initial\ufb01ndings (see Supplementary Method 3). Additionally, to address\nautocorrelated posting behaviors among social media users, weinclude autoregressive terms in the ITS models, further enhancing therobustness of our \ufb01ndings (see Supplementary Method 4).\nTo better understand what happens when posters retreat to their\ninformation bubbles, we conduct a series of descriptive analyses (seeSupplementary Table 2). When posters reduce their political andcontent diversity, the number of tweets (comprising posts, retweets,and quotes) posted per day signi \ufb01cantly increases, indicating that\nusers are more active within their information bubbles. Speci \ufb01cally,\nthe number of tweets per day is negatively correlated with politicaldiversity ( r=\u22120.107, t(712946) = \u221290.87, 95% CI = [ \u22120.109, \u22120.105],\np< 0.001) and content diversity ( r=\u22120.052, t(712946) = -43.97, 95%\nCI = [ \u22120.054, \u22120.050], p<0 . 0 0 1 ) . S i m i l a r l y , w e \ufb01nd that the type of\nposting is different; the proportion of retweets (i.e., tweets simplysharing other users \u2019tweets) out of the entire tweets per day is nega-\ntively correlated with political diversity ( r=\u22120.046,\nt(712946) = \u221238.88, 95% CI = [ \u22120.048, \u22120.044], p< 0.001) but posi-\ntively correlated with content diversity ( r= 0.012, t(712946) = 10.13,\n95% CI = [0.010, 0.014], p< 0.001). This indicates that users actively\npost tweets rather than passively retweet other users \u2019tweets when\nthey exhibit low political diversity. To demonstrate the signi \ufb01cant\neffects of misinformation tagging on political and content diversity,irrespective of these factors, we have adjusted for the number oftweets posted per day. We have also controlled for the proportion ofretweets per day, which did not meaningfully change our results (seeSupplementary Table 3).\nDelayed feedback (DF) analysis\nWe employ delayed feedback (DF) analysis to further strengthen ourcausal inference\n49. In our DF analysis, we estimate baseline changes\n(i.e., changes in outcomes that occur without tags) to answer the\nquestion: \u201cAre shifts in political and content diversity attributable to\ntagging, or do similar changes occur even without tagging? \u201dPairs of\ntweets containing similar misinformation, targeted by misinformationtagging at different times, are matched to construct a control group,consisting of posters whose problematic tweets have not yet beenTable 1 | Interrupted Time Series (ITS) Model Results for Political and Content Diversity\nOutcome Political diversity (%) Content Diversity (z)\nType of misinformation\ntaggingIndividual Collective Difference\n(Collective - Individual)Individual Collective Difference\n(Collective - Individual)\nSlope before posting\nthe tweet0.237***\n[0.125, 0.349]t=4 . 1 4 , p<0 . 0 0 10.309*\n[0.041, 0.578]t=2 . 2 6 , p=0 . 0 2 40.072\n[\u22120.219, 0.363]\nt=0 . 4 8 0 , p=0 . 6 2 80.007***\n[0.004, 0.010]t=4 . 7 9 , p<0 . 0 0 10.003\n[\u22120.004, 0.010]\nt=. 7 4 , p= 0.461\u22120.005\n[\u22120.012, 0.003]\nt=\u22121.17,p=0 . 2 4 3\nImmediate intercept\nchange after tagging\u22121.009***\n[\u22121.447, \u22120.571]\nt=\u22124.52, p<0 . 0 0 10.270\n[\u22120.824, 1.363]\nt=0 . 4 8 , p= 0.6291.279*\n[0.101, 2.457]t=2 . 1 3 , p=0 . 0 3 3\u22120.030***\n[\u22120.042, \u22120.019]\nt=\u22125.10, p<0 . 0 0 10.040**\n[0.012, 0.069]t=2 . 7 4 , p=0 . 0 0 60.070***\n[0.039, 0.102]t= 4.44, p\n<0 . 0 0 1\nSlope after tagging 0.087\n[\u22120.020, 0.194]\nt=1 . 6 0 , p= 0.110\u22120.049\n[\u22120.334, 0.235]\nt=\u22120.34, p=0 . 7 3 4\u22120.136\n[\u22120.440, 0.167]\nt=\u22120.88, p=0 . 3 7 9\u22120.003\n[\u22120.0006, 0.000]\nt=\u22121.95, p=0 . 0 5 1\u22120.011**\n[\u22120.019, \u22120.004]\nt=\u22122.88, p=0 . 0 0 4\u22120.008*\n[\u22120.016, 0.000]\nt=\u22122.01, p=0 . 0 4 4\nSlope change\n(After - Before)\u22120.150\n[\u22120.306, 0.006]\nt=\u22121.89, p= 0.059\u22120.358\n[\u22120.749, 0.033]\nt=\u22121.80, p=0 . 0 7 2\u22120.208\n[\u22120.629, 0.213]\nt=\u22120.97, p=0 . 3 3 2\u22120.010***\n[\u22120.014, \u22120.006]\nt=\u22124.79, p< 0.001\u22120.014**\n[\u22120.024, \u22120.003]\nt=\u22122.60, p=0 . 0 0 9\u22120.004\n[\u22120.015, 0.007]\nt=\u22120.64, p= 0.520\nR20.173 0.243\nAdjusted R20.159 0.230\nObservations 424,969\ndf 418,115\nNotes: *** p<0 . 0 0 1* * p<0 . 0 1* p< 0.05. We multiply political diversity by 100 to interpret the estimates as absolute percentage point changes. We normalize content diversity to z-s cores (the number\nof standard deviations from the mean). All regressions control for user \ufb01xed effects and the number of tweets per day. The statistical signi \ufb01cance of regression coef \ufb01cients is tested using two-sided t-\ntests. Con \ufb01dence intervals (95%) are provided in brackets, along with the corresponding t-statistics, degrees of freedom, and exact p-values. More details can be found in Methods: Interrupted Time\nSeries (ITS) Analysis.Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 4\ntagged due to delayed feedback, and a treatment group of posters who\nhave. For instance, Supplementary Fig. 2 presents an illustrativeexample involving a pair of matched tweets and tags.\nIn Fig. 3a, post-treatment ( t\n1) represents the time window when\ntreatment tweets are tagged but c ontrol tweets are not, and pre-\ntreatment ( t0) represents the time window with equal duration t1when\nboth treatment and control tweets are untagged. Changes in the out-comes between t\n0andt1in the control group re \ufb02ect baseline changes,\nwhich indicate changes without tags. Changes between t0andt1in the\ntreatment group re \ufb02ect treated changes, which indicate changes with\nt a g s .W ec o m p a r et h ed i f f e r e n c ei np r e - p o s tc h a n g eb e t w e e nc o n t r o land treatment groups (i.e., baseline vs. treated changes) to identify theeffects of misinformation tagging on political and content diversity. DFanalysis assumes that, in the absence of treatment, both control andtreatment groups would exhibit parallel trends. We control for user-\nlevel \ufb01xed effects to control for time-invariant, user-speci \ufb01c\ncharacteristics.\nFigure 3ba n dT a b l e 2present results from the DF analysis (Poli-\ntical Diversity: R\n2= 0.274, Content Diversity: R2= 0.358). Our DF ana-\nlysis demonstrates that changes are indeed due to tagging, showingthat treated changes are signi \ufb01cant above and beyond baselinechanges. Consistent with the ITS \ufb01ndings, DF analysis indicates that\nindividual misinformation tags lead to a signi \ufb01cant decrease in poli-\ntical diversity ( \u03b2=\u22125.886, 95% CI = [ \u22129.633, \u22122.138], t(8182) = \u22123.08,\np= 0.002). Nevertheless, individual misinformation tagging does not\nsigni\ufb01cantly affect content diversity ( \u03b2=0 . 0 1 8 ,9 5 %C I=[ 0 . 1 4 5 ,0 . 4 0 3 ] ,\nt(8182) = 4.17, p= 0.652). Although ITS analyses show that content\ndiversity decreases after tagging, DF analyses indicate no statisticallysigni\ufb01cant evidence that content diversity decreases beyond baseline\nchanges observed without tags. Collective misinformation tags, bycontrast, do not produce a signi \ufb01cant decrease in political diversity\n(\u03b2=1 . 2 1 9 ,9 5 %C I=[ \u22124.777, 7.215], t(8182) = 0.40, p=0 . 6 9 0 )a n de v e n\nincrease content diversity following tagging ( \u03b2=0 . 2 7 4 ,9 5 %C I=[ 0 . 1 4 5 ,\n0.403], t(8182) = 4.17, p< 0.001). The gap between the effects of indi-\nvidual and collective tagging is signi \ufb01cant for both political\ndiversity ( \u03b2= 7.105, 95% CI = [0.069, 14.140], t(8182) = 1.98, p= 0.048)\nand content diversity ( \u03b2=0 . 2 5 6 , 9 5 % C I=[ 0 . 1 0 5 , 0 . 4 0 7 ] ,\nt(8182) = 3.32, p= 0.001).\nLinguistic characteristics of misinformation tags\nIndividual and collective misinformation tagging messages manifest\ndifferent linguistic characteristics. As shown in Fig. 4and Supplementary\nFig. 3 | Delayed feedback (DF) analysis. a Pre- and post-treatment periods. Post-\ntreatment ( t1) represents the time window when treated tweets are tagged but\ncontrol tweets are not. Pre-treatment ( t0) represents the time window with equal\nduration t1when both treatment and control tweets remain untagged. bThe effects\nof individual and collective misinformation tagging on political and contentdiversity are estimated by the difference in pre-post changes in outcomes betweenthe treatment and control groups. Dots represent the difference in pre-post\nchanges for each outcome between the treatment and control groups, with errorbars indicating 95% con \ufb01dence intervals. Pairs of tweets containing similar mis-\ninformation, targeted by misinformation tagging at different times, are matched toconstruct the control group. The control group consists of users whose proble-\nmatic tweets had not yet been tagged due to delayed feedback, while the treatment\ngroup consists of users whose problematic tweets had already been tagged (see\u201cMethods \u201d: Delayed Feedback (DF) Analysis for details). The sample size is 8901\ntweets.\nTable 2 | Delayed feedback (DF) model resul ts for political and content diversity\nOutcome Political diversity Content Diversity\nType of misinformation\ntaggingIndividual Collective Difference\n(Collective - Individual)Individual Collective Difference\n(Collective - Individual)\nDifference in Pre-Post Change\n(Treatment - Control)\u22125.886**\n[\u22129.633, \u22122.138]\nt=\u22123.08, p=0 . 0 0 21.219\n[\u22124.777, 7.215]\nt= 0.40, p= 0.6907.105*\n[0.069, 14.140]\nt= 1.98, p=0 . 0 4 80.018\n[\u22120.062, 0.099]\nt= 0.45, p= 0.6520.274***\n[0.145, 0.403]\nt=4 . 1 7 , p<0 . 0 0 10.256**\n[0.105, 0.407]\nt= 3.32, p= 0.001\nR20.274 0.358\nAdjusted R20.211 0.301\nObservations 8901df 8182\nNotes: *** p< 0.001 ** p<0 . 0 1* p< 0.05. Each cell presents the difference in pre-post change (treatment group - control group) in each outcome. We multiply political diversity by 100 to interpret the\nestimates as absolute percentage point changes. We normalize content diversity to z-scores (the number of standard deviations from the mean). All re gressions control for user \ufb01xed effects and the\nnumber of tweets per day. The statistical signi \ufb01cance of regression coef \ufb01cients is tested using two-sided t-tests. Con \ufb01dence intervals (95%) are provided in brackets, along with the corresponding t-\nstatistics, degrees of freedom, and exact p-values. More details can be found in Methods: Delayed Feedback (DF) Analysis.Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 5\nTable 4, we \ufb01nd that individual misinforma tion tags exhibit twice the\ntoxic content (Mean Individual =0 . 1 3 9 ,M e a n Collective = 0.076, Mean Collective -\nMean Individual =\u22120.063, t(7496) = 9.86, p< 0.001, Cohen \u2019sd=\u22120.228)\nand convey more negative sentiment compared to collective mis-information tags (Mean\nIndividual =\u22120.082, Mean Collective =\u22120.050,\nMean Collective -Mean Individual = 0.032, t(7731) = 2.14, p= 0.033, Cohen \u2019sd\n= 0.049). Collective tags express slightly higher positive sentiment andproduce messages with more neutral sentiment than individual tags.Furthermore, individual tag messages are much shorter(Mean\nIndividual =179.31, Mean Collective = 288.87, Mean Collective -\nMean Individual =1 0 9 . 5 6 , t(7731) = 26.95, p<0 . 0 0 1 ,C o h e n \u2019sd=0 . 6 1 3 )a n d\nmore readable ( \u03c72(7) = 155.32, p<0 . 0 0 1 , C r a m e r \u2019sV=0 . 1 5 5 ) t h a n c o l -\nlective tags. While 53.53% of individual tags necessitate a college-level\nreading comprehension or higher, 75.77% of collective tags demand\nthis level. Moreover, the delay between posting misinformation and re-ceiving fact-checks is shorter for individual than collectivetagging (Mean\nIndividual =3.037, Mean Collective = 6.322, Mean Collective -\nMean Individual =3 . 2 8 5 , t(7731) = 2.13, p= 0.033, Cohen \u2019sd=0 . 0 4 8 ) .T h e s e\n\ufb01ndings demonstrate that individual tags convey their messages quickly\nthrough messages that are succinct , straightforward, emotive, and\nsometimes toxic. In contrast, collective tags are more slowly commu-nicated through lengthy, complex messages, devoid of emotionalundertone or toxicity.\nBased on linguistic differences between individual and collective\ntags, we question whether gaps in the effects of individual versus\ncollective tags persist, even when the linguistic characteristics of thesetags are similar. First, we control for toxicity by excluding tags with atoxicity level higher than 0.4 and retrain only non-toxic tags. Second,we control for sentiment by removing tags with either positive (> 0.2)or negative (< \u22120.2) sentiments, keeping only neutral tags. Third, we\ncontrol for length by excluding tags longer than 400 characters andretaining short tags. Fourth, we control for readability by excludingtags that require college-level or higher readability and selecting tagsthat are relatively easy to read. Fifth, we control for delay by omittingany tags associated with delays longer than 48 hours (log-transformeddelay > 1.10) and focusing on quick tags.\nWe\ufb01nd that the gap between individual and collective tagging\nremains statistically signi \ufb01cant, except when controlling for length. As\nshown in Supplementary Table 5, the gap in political diversity is notstatistically signi \ufb01cant after controlling for length ( \u03b2= 1.071, 95% CI =\n[\u22120.231, 2.373], t(399236) = 1.61, p= 0.107). Nevertheless, controllingfor length only accounts for 16.26% of the gap between individual and\ncollective tagging in political diversity. This indicates that linguistic\ncharacteristics explain a modest but nontrivial portion of the differ-\nential impacts between individual and collective tagging. Nevertheless,these measured qualities do not account for the vast majority of thedifference.\nControl analyses\nIn this section, we identify systematic differences in misinformationthat receive individual versus collective tagging, as well as differencesin the posters corrected by each type. Even after controlling for thesedifferences in additional interrupted time series (ITS) analyses, indi-vidual and collective tagging have signi \ufb01cantly different effects in the\ndirections identi \ufb01ed by our unconstrained analysis.\nFirst, we observe that individual taggers focus more on political\ntopics, while collective taggers correct a more diverse range of topics(see Supplementary Table 6). As shown in Supplementary Table 7, thenine most frequent topics in our dataset include political topics knownto trigger divisive, polarized reactions in US politics (see \u201cMethods \u201d:\nTopic modeling). These topics account for 84.06% of the correctionsmade through individual tagging but only 59.49% of the correctionsmade through collective tagging.\nTherefore, we control for topics of the corrected misinformation,\n\ufb01nding that the gaps between individual and collective tags are sig-\nni\ufb01cant and even slightly larger when they correct identical topics of\nmisinformation. Speci \ufb01cally, we employ propensity score weighting\n(PSW) method (see Supplementary Method 5). The results demon-strate that even when individual and collective tagging correct topi-cally identical messages, the gap between individual and collectivetagging is signi \ufb01cant, both in the immediate change of political\ndiversity ( \u03b2= 2.380, 95% CI = [0.200, 4.560], t(296544) = 2.14,\np= 0.032) and content diversity ( \u03b2= 0.048, 95% CI = [0.003, 0.092],\nt(296544) = 2.11, p= 0.035). We note that collective tagging is less likely\nto correct political topics than individual tagging but is more effectivein causing original posters to explore diverse content when success-fully deployed on political topics. Refer to Supplementary Table 8 for\ndetails.\nSecond, we \ufb01nd that the proportion of right-leaning users cor-\nrected by individual tagging is 53.17% while right-leaning users cor-rected by collective tagging is 44.14%. We also analyze the distributionof political stance among taggers (i.e., those who write individual tags)Fig. 4 | Linguistic characteristics of fact-checking messages. a univariate kernel\ndensity function for toxicity. bunivariate kernel density function for sentiment.\ncunivariate kernel density function for length (characters). dhistogram for readingease ( e) univariate kernel density function for delay (log-transformed days). The\npurple line (or bar) represents the distribution within individual misinformation\ntags, while the yellow line (or bar) represents the distribution within collective tags.Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 6\nand voters (i.e., those who vote on the exposure of collective tags) (see\nSupplementary Method 6 and Supplementary Table 9). We comparethe effects of individual and collective tagging in the common scenariowhere right-leaning posters are corrected by left-leaning ones. Speci-\n\ufb01cally, we focus on cases where right-leaning posters are corrected\neither by individual tags from left-leaning taggers or by collective tagsapproved by a majority of left-leaning voters (i.e., Community notesapproved by voters, where at least 50% of those with identi \ufb01able\npolitical stances are left-leaning). In this analysis, the differencebetween the effects of individual and collective tagging is still sig-ni\ufb01cant, both in the immediate change of political diversity ( \u03b2=1 . 7 8 0 ,\n95% CI = [0.118, 3.441], t(238081) = 2.10, p= 0.036) and content diver-\nsity ( \u03b2= 0.076, 95% CI = [0.033, 0.119], t(238081) = 3.46, p= 0.001).\nRefer to Supplementary Table 10 for details.\nThird, we \ufb01nd that popular users are more likely to receive col-\nlective tags than individual tags, which is consistent with prior litera-\nture (see Supplementary Fig. 3)\n8. To examine the differences between\nindividual and collective tags when focusing on less popular, everydayusers, we exclude those whose number of followers exceeds 2967, theaverage number of followers among users corrected by individual tags.We\ufb01nd the results are consistent overall (see Supplementary Table 11),\nbut suggest that collective tagging of low popularity posters is slightlymore effective, relative to individual tagging, than with high popularityusers. In particular, the difference between individual and collectivetagging is signi \ufb01cant, both in the immediate change of political\ndiversity ( \u03b2= 3.612, 95% CI = [0.824, 6.399], t(235632) = 2.54, p= 0.011)\nand content diversity ( \u03b2= 0.081, 95% CI = [0.000, 0.162],\nt(238081) = 1.97, p= 0.049). This may indicate the inoculation of pop-\nular users to critique, an increased sensitivity among unpopular usersto collective nudges\n50, or both.\nRobustness checks\nWe verify our \ufb01ndings with a battery of robustness checks. First, we\nseek to avert concerns over the presence of bots on Twitter by rea-nalyzing our data excluding identi \ufb01ed bot accounts\n2,5.S e c o n d ,w e\nreanalyze the relationship controlling for potentially insincere infor-mational activities, such as citing sources of low credibility and\nintentionally spreading fake news. Third, we attempt to avoid situa-\ntions in which posters simply criticize distant information withouthonest consideration by \ufb01ltering out posts with negative sentiment.\nFourth, we identify all tweets with i nt h es a m p l et h a tm e n t i o nk e y w o r d s\nrelated to receiving community notes broadly and remove them, asthey could confound our measure of content diversity. To addressconcern regarding the effect of replying directly to individual taggers,which could confound the measure of political diversity, we alsoidentify and remove all tweets that reply directly to individual taggers.Fifth, to strictly identify individual tags (i.e., PolitiFact links) that cor-rect the original posters, we prompt ChatGPT to annotate whether the\nlinks are used to correct the original poster rather than support them.\nThen, we limit the sample to links that correct the original posters.Sixth, considering the low visibility of individual tags in Twitter \u2019s\nmessage-reply interface\n6,8, we restrict the sample to original posters\nwho replied to (and thereby read) the individual tags and remove non-responders. These alterations do not meaningfully impact our repor-ted outcomes (see \u201cMethod \u201d: Robustness Checks).\nDiscussion\nThis study provides empirical evidence regarding the impact of indi-\nvidual and collective misinformation tagging on echo chambers.Before misinformation tagging, posters show an increased curiosity in\ndiverse political and topical content. This challenges the conception\nthat misinformation is generated and corrected when people retreatinto echo chambers\n11,33. On the contrary, posters become fact-checked\nwhen they venture outside those bubbles. Why is exploration followedby misinformation tagging? First, posters could misinterpretunfamiliar and diverse information from a lack of information\nliteracy\n51, increasing the chance of posting the misinformation being\ntagged. Second, news feed algorithms may increase the probabilitythat posters \u2019tweets become visible to people from political outgroups,\nwho are highly motivated to fact-check foreign posters\n6,7,14.O u ra n a -\nlysis shows that posters increase the closeness to misinformationtaggers before fact-checks, which could increase the chance ofappearing in fact-checkers \u2019news feeds.\nIndividual misinformation tagging discourages posters from\nexploring diverse information. Posters tagged by individuals manifestan immediate drop in political diversity, as evidenced by both inter-rupted time series (ITS) and delayed feedback (DF) analyses. Contentdiversity also decreases in ITS analyses, although DF analyses do notreveal a signi \ufb01cant drop. This suggests that while content diversity\ndecreases after tagging, it does not fall below the baseline change\nexpected without tags. These unintended consequences are mitigated\nby collective misinformation tagging. Unlike individual tagging, thereis no statistically signi \ufb01cant evidence that collective tagging dimin-\nishes political and content diversity in both ITS and DF analsyzes;moreover, it results in a short-term rise in content diversity.\nOur analyses show that individual tagging involves short, toxic,\nand emotion-driven messages. Collective tagging, on the other hand,involves longer, less toxic, emotionally neutral, and deliberative mes-sages revealed to posters longer after their offending posts. Theseresults suggest the trade-off between the effectiveness of establishedsystems for promoting openness and mobility across the information\necosystem, but the ef \ufb01ciency of individuals in cleaning it. Low visibility\nof individual misinformation tagging in Twitter \u2019sm e s s a g e - r e p l y\ninterface\n6,8may motivate taggers to use short and potentially toxic\nmessages. Community Notes responded by implementing a morevisible interface for collaborative tagging, which reduces the tendencyto terseness, facilitating long and deliberate discussion. Also, normsand values underlying participation in Community Notes could pre-vent taggers from disseminating succinct yet in \ufb02ammatory messages\nviewed as unhelpful and instead source diverse perspectives\n13.\nWhat mechanisms drive differences in the effects of individual\nand collective misinformation tagging on echo chambers? We \ufb01nd that\nlinguistic characteristics, such as toxicity, sentiments, and length only\npartially explain differential impacts between individual and collectivetagging. This implies that differences in quality other than linguisticcharacteristics also exert a direct in \ufb02uence. Literature on the wisdom\nof crowds suggests that while individual tags are susceptible to biasesand noise, aggregating tags collectively could correct individual bias,increasing the quality of nonexpert fact-checks\n28,52,53. For example,\ncompared to individual tags, collective tags are more closely alignedwith professional fact-checks from experts on a variety of topics,ranging from COVID-19 to politics\n14,27\u201329. Even though we focus on\nindividual tags that cite professional fact-checks (i.e., PolitiFact), it is\npossible that interpretations within individual tags might be less\neffective when not cross-validated like collective tags. For example,individual tags might fail to convey the key points of PolitiFact articlesor clearly articulate the relevance of these articles to the original post.Additionally, when multiple fact-checkers co-validate collective tags,these decisions may be perceived as more legitimate and less sus-ceptible to biases, encouraging the original posters to seek out morediverse and cross-validating information\n28.\nOverall, our \ufb01ndings suggest that misinformation is posted and\nfact-checked when original posters who were accustomed to like-minded sources associated with low credibility (see SupplementaryTable 2) suddenly increase their political and content diversity. In the\nshort term, some might believe that pushing them back into their echo\nchambers with individual tags seems like an effective way to curbmisinformation. Nevertheless, over the long term, this approach couldexpand the cluster of users immersed in misinformation, deprivingthem of opportunities to educate themselves with opposingArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 7\nperspectives. The ethical and normative aspects of our research\nremain open questions, but we suggest that collective taggingencouraging exploration might be better for the long-term health ofthe information ecosystem.\nOur analyses have several notable limitations. First, our method\nfor assessing posters \u2019political stances is indirect, through their\nposting behavior\n5. This approach has been successfully applied to\npredict political party af \ufb01liation and self-described ideology in\nprevious literature53, but using a direct measure of political ideol-\nogy or af \ufb01liation with social media and survey data would\nstrengthen our assessments. Second, our quasi-experimentalmethodologies (ITS and DF) depend on assumptions for causalinference. We employ topic modeling and matching to enhancetweet comparability within treatment and control groups, butacknowledge that unobserved time-variant confounders may in \ufb02u-\nence posters \u2019responses. Third, although we have employed a\npopular bot detection algorithm, recent studies have suggestedthat algorithmic removal of bots is challenging and may introduceadditional bias\n54. Therefore, we report the full results with and\nwithout the algorithmic removal of bots, demonstrating that ourresults are consistent. To thoroughly remove bots, future researchcould match social media data with survey or administrative data(e.g., voter records) to ensure the authenticity of participants\n55.\nFourth, Twitter (X as of July, 2023) closed access to the AcademicResearch API, which had been freely available to eligible researchersuntil May 2023. This could limit other researchers \u2019ability to\nreproduce our \ufb01ndings with recent data after May 2023\n56. Collective\ntagging systems are increasingly being deployed across socialmedia platforms, such as Twitter \u2019s Community Notes and similar\nfeatures currently being tested on platforms like Facebook andYouTube\n23,24. Future research should examine whether our \ufb01ndings\nare reproducible across different platforms, time periods, and cul-tural contexts. Fifth, we employ the topic modeling and propensityscore weighting (PSW) method to control for semantic differencesbetween tweets tagged by individual and collective tagging (refer toSupplementary Method 5). Nevertheless, PSW might fail to addressthe confounding effects of unobserved semantic differences\nbeyond topics. Despite these limitations, our study uncovers a sig-\nni\ufb01cant and substantial relationship between fact-checks and\nreduced information diversity. We also demonstrate the power ofdesigned institutions, like collective fact-checking on Twitter, tomoderate the negative, narrowing effects of fact-checking oninformation exploration.\nMethods\nData\nOur study complied with the terms of all data sources used in the study(including but not limited to Twitter/X). Using the Twitter API v2.0 with\nacademic research access, we collected Twitter data to explore the\neffects of individual and collective misinformation tagging. First, weidenti \ufb01ed 9,372 users targeted by individual misinformation tagging\nfrom 2021/10/1 to 2022/3/25. We selected users whose tweets receivedfact-checking replies that contain URLs to fact-checking articles from\u201cpolitifact.com. \u201dSecond, we identi \ufb01ed 1,465 users targeted by collec-\ntive tagging from 2022/12/19 to 2023/3/31, when Community Noteswere made public to Twitter users globally\n57.I nC o m m u n i t yN o t e s ,\nusers can \ufb02ag any tweets as misinformation with notes, and other\nmembers vote for the helpfulness of the notes. (Users also have theoption to \ufb02ag tweets they believe are free from misinformation;\nhowever, these instances have been excluded from our analysis.)\nCollectively veri \ufb01ed notes that received the above-threshold help-\nfulness votes from a diverse set of users are then made public to theoriginal user (who posted the misinformation) and the broad Twitteraudience\n13. In our work, we only considered notes with above-\nthreshold helpfulness votes. Note that the platform also assesses thealignment of users \u2019prior contributions with the crowd \u2019sd e c i s i o n s ,\n\ufb01ltering out voters who frequently oppose and backlash against valid\nfact-checks on misinformation (see Supplementary Method 7).\nDue to the rate limit of Twitter API, we only collected data from\nregular Twitter users, excluding organizations \u2019and celebrities \u2019\naccounts with 50,000 or more followers. Additionally, to focus onindividual users, rather than organizational accounts (e.g., CNN, FoxNews, etc), we removed 1,659 users identi \ufb01ed as organization accounts\nby the M3Inference library\n58,59. We further removed 1445 users who\nwere fact-checked more than once within the period of data collectionto avoid the potential for them to become desensitized for repeatedfact-checks. After \ufb01ltering the data, our \ufb01nal dataset included 7733\nusers, where 6760 users were targeted by individual misinformationtagging and 973 users were targeted by collective misinformationtagging. We found that individual tagging is more frequent than col-\nlective tagging in our dataset due to the cross-validation process\nrequired to expose collective tags. This leads to an imbalance in groupsize between users corrected by individual and collective tags.Nevertheless, our statistical models (interrupted time series anddelayed feedback models) do not assume equal group size for com-parison between the effects of individual and collective tagging. Also,we found that 16.33% of tweets that received individual tags and 15.60%of tweets that received collective tags were removed by Twitter or bythe original poster. The probability of removal is similar betweenindividual and collective tags (Difference = 0.73%, z= 0.629, p=0 . 5 2 9 ) .\nFinally, we collected users \u2019historical tweets \u2014including posts,\nretweets, and quotes \u2014which span two months before posting tagged\ntweets and two months after exposure to misinformation tagging,resulting in 1,409,845 tweets in total. Posts typically indicate activeengagement with diverse political sources and topics, allowing users toexpress their opinions. In contrast, retweets and quotes \u2014which involve\nsharing others \u2019tweets \u2014suggest more passive engagement, not\nnecessarily re \ufb02ecting personal views. We utilize these three types of\nbehaviors for a more comprehensive measurement of users \u2019informa-\ntion engagement\n60,61. We assume that individual misinformation tag-\ngings are exposed to users when they are posted, and collectivemisinformation taggings are exposed to users when they are made\npublic following the above-threshold helpfulness votes. For our sta-\ntistical analyses, we included 712,948 tweets with observed politicaland content diversity scores. This research study received a determi-nation from the University of Chicago Social & Behavioral SciencesInstitutional Review Board that the study is not considered humansubjects research and does not require review (Institutional ReviewBoard Protocol IRB24-0051).\nPolitical diversity\nPolitical diversity measures whether a user posted a tweet that refer-enced sources having an opposite political stance. Speci \ufb01cally, we\ndetermine the political stance of the referenced source by extracting\nthe domain (e.g., cnn.com ) of the source and check it from MediaBias/\nFactCheck database (MBFC; https://mediabiasfactcheck.com/ )\n5,47.\nMBFC provides a continuous score for 4874 websites to indicate eachsource \u2019s political stance, ranging from -1 (extreme left) to 1 (extreme\nright). Our additional analysis shows that political stance scores fromMBFC show signi \ufb01cant inter-rater reliability with another database of\nthe political stance of news media, AllSides.com (see SupplementaryMethod 8).\nWe then calculate a user \u2019s political stance by averaging the poli-\ntical stance scores of sources referenced in their historical tweetswhich span two months before posting tagged tweets and two months\nafter misinformation tagging (see Supplementary Fig. 4). Users who\npredominantly cite left-leaning media are considered left, and thosewho cite right-leaning media are considered right. Speci \ufb01cally, users\nwith negative average political stance scores are categorized as left,while those with positive scores are categorized as right. Finally, weArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 8\nassign a binary value to represent a user \u2019s political diversity: 1 (diverse)\nif a user cited a source that has an opposite political stance from theuser \u2019s own political stance, 0 (not-diverse) if a user cited a source with\nthe same political stance.\nThe mean political diversity score is 0.166, and the standard\ndeviation is 0.372 ( N= 712,948). Political diversity is negatively corre-\nlated with the number of tweets posted per day ( r(712946) = \u22120.107,\n95% CI = [ \u22120.109, \u22120.105], p< 0.001) and the proportion of retweets\n(r(712946) = \u22120.046, 95% CI = [ \u22120.048, \u22120.044], p< 0.001). This indi-\ncates that users are more active within information bubbles, activelyposting tweets rather than passively retweeting other users \u2019tweets\nwithin these bubbles (see Supplementary Table 2).\nContent diversity\nContent diversity measures whether a user posted a tweet with a topic\nthat is rarely discussed in the user \u2019s historical tweets. We apply the\nTwitter4SSE model, a transformer-based sentence embedding model(SentenceBERT) that was initialized from BERTweet (a RoBERTa modeltrained on 850 million tweets from 2012/1 to 2019/8 and 5 milliontweets related to COVID-19 pandemic), to encode the meaning of atweet into a 768-dimensional vector\n62,63. The model was further opti-\nmized based on recent data (75 million tweets from 2020/11 to 2020/12) using Multiple Negatives Ranking Loss (MNRL) to identify semanticsimilarity based on the principle that tweets quoting or replying to thesame original tweet are likely discussing related ideas\n62. If a pair of\ntweets quoted or replied to the same tweet, the semantic similarity\nbetween them is assumed to be high.\nTo apply the Twitter4SSE model, we \ufb01rst conduct the identical\ndata preprocessing steps to clean the tweets, which includes: eliminateURLs and mentions and transform the text to lowercase to reduce thepresence of generic texts\n62. Next, we represent each tweet with a 768-\ndimensional semantic embedding (Supplementary Fig. 5 shows thevisualization). Finally, we measure the cosine distance between theuser embedding and tweet embedding (see Fig. 1b) to represent the\ncontent diversity of the current tweet. The user embedding is theaverage embedding of the user \u2019s historical tweets (see Fig. 1b). Esti-\nmating the distance in the embedding space has been frequently used\nto quantify the diversity of user activities in the online platform\n48,64.\nThe distance ranges from 0 to 0.835, with 0 representing homo-geneous content and 0.835 representing extremely diverse content.The mean content diversity score is 0.357, and the standard deviationis 0.109 ( N= 712,948). We \ufb01nd that political and content diversity are\nslightly correlated ( r(712946) = 0.020, 95% CI = [0.018, 0.022],\np< 0.001), assessing conceptually distinct aspects of diversity.\nTable 1shows an example of how content diversity scores are\nassigned. In this example, the user primarily shows interests in COVID-19 related misinformation. However, as the user explores diversetopics \u2014tax, LGBTQ + , international issues, and labor \u2014the content\ndiversity score increases.\nContent diversity is negatively correlated with the number of\ntweets posted per day ( r(712946) = \u22120.052, 95% CI = [ \u22120.054, \u22120.050],\np< .001) but positively correlated with the proportion of retweets\n(r(712946) = 0.012, 95% CI = [0.010, 0.014], p< 0.001). In other words,\nusers tend to retweet others \u2019tweets rather than posting their own\ntweets when increasing content diversity (see Supplementary Table 2).\nInterrupted time series (ITS) analysis\nWe apply Interrupted Time Series (ITS) analysis to examine how indi-vidual and collective misinformation tagging affect the trend of poli-tical and content diversity in posting behavior. We \ufb01tt h eI T Sm o d e lt o\nthe time series around fact-checking events, spanning \ufb01ve weeks\n(35 days) before posting the fact-checked tweet and \ufb01ve weeks after\nfact-checking. To compare the differential impacts of individual andcollective misinformation tagging, we formulate the following multi-group ITS model. We control for user \ufb01xed effects to eliminate theuser-related unobserved time-invariant heterogeneity that could pos-\nsibly affect the outcomes. Additionally, the number of tweets postedper day is negatively correlated with political diversity(r(712946) = \u22120.107, 95% CI = [ \u22120.109, \u22120.105], p< 0.001) and content\ndiversity ( r(712946) = \u22120.052, 95% CI = [ \u22120.054, \u22120.050], p<0 . 0 0 1 ) ,\nindicating that users are more active within information bubbles.Therefore, we control for the number of tweets posted per day toensure that our analysis focuses on variations in diversity rather thanengagement volume.\nFor each tweet, let Ybe the outcome variable (i.e., political or\ncontent diversity of a speci \ufb01c tweet), Wis the weeks before posting the\ntweet with misinformation (negative values) or after misinformationtagging (positive values). Note that we measure Wby dividing the days\nby 7. For example, if a particular tweet is posted 3 days before postingthe tweet, Wis\u22123/7.Tis an indicator of the treatment status where 0\nrepresents a tweet posted before misinformation tagging and 1\nrepresents after tagging. Cis an indicator of the type of misinformation\ntagging where 0 represents individual tagging and 1 represents col-lective tagging. Ncorresponds to the number of tweets per day (con-\ntrol variable), \u03b1corresponds to the user \ufb01xed effect, and and \u03f5is the\nerror term. Then the ITS model is de \ufb01ned:\nY=\u03b2\n0+\u03b21W+\u03b22T+\u03b23WT+\u03b24WC+\u03b25TC+\u03b26WTC +\u03b27N+\u03b1+\u03f5\u00f01\u00de\nHere, \u03b20is the intercept, \u03b21is the slope before individual mis-\ninformation tagging. \u03b22is the change in the outcome immediately after\nthe individual misinformation tagging. \u03b23is the slope change before\nand after individual misinformation tagging. \u03b21+\u03b24is the slope before\ncollective misinformation tagging. \u03b22+\u03b25is the change in the outcome\nimmediately after the collective misinformation tagging. \u03b23+\u03b26is the\nslope change before and after collective misinformation tagging. Thus,\n\u03b24,\u03b25,\u03b26are the terms that estimate the differences between the\neffects of individual and collective misinformation tagging. Supple-mentary Table 12 shows how these estimates correspond to each cell inTable 1for each outcome.\nBefore estimating the model, political diversity (binary variable)\nhas been multiplied by 100 so that the coef \ufb01cients are interpretable as\nabsolute percentage point changes. Content diversity has been nor-malized to z-scores (i.e., the number of standard deviations from the\nmean). When estimating the statistical signi \ufb01cance of the estimates, all\np-values are two-sided. The thresholds for statistical signi \ufb01cance is set\natp< 0.05, and marginal signi \ufb01cance is set at p<0 . 1 .\nDelayed feedback (DF) analysis\nIn addition to the interrupted time series (ITS) analysis, we conduct a\ndelayed feedback (DF) analysis to estimate the causal impacts. Webegin by establishing control and treatment groups: each tweet ispaired with another tweet that was subject to misinformation taggingat an earlier time. Speci \ufb01cally, for every tweet in a control group, we\nsearch for a corresponding treatment tweet using the following cri-teria: (1) They must have been fact-checked using the same approach,either individual or collective misinformation tagging. (2) They should\nhave been fact-checked prior to the control tweet. (3) They should\nhave the same topic, considering that distinct topics of misinformationcould lead to different levels of political and content diversity (see\u201cMethod \u201d: Topic Modeling for a detailed explanation of the topic\nmodeling process). (4) They should have been posted no more thanseven days apart from the control tweet. In cases where we havemultiple tweets that meet these criteria, we choose the one with theclosest posting time to the control tweet. This results in 476 pairs oftweets in control and treatment groups.\nFor each pair of tweets, we identify two time windows: pre-\ntreatment ( t\n0) and post-treatment ( t1).t1represents the time window\nwhen the treatment tweets are fact-checked but the control tweets are\nnot. If the duration of t1exceeds a seven-day window, we use the dataArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 9\nwithin the seven-day window after receiving the tags, considering that\nthe timing of the fact-check could affect the outcome. t0represents the\ntime window (with equal duration of t1) when both the treatment and\ncontrol tweets are not fact-checked. Then we design the following\ndifference-in-differences model to assess the impacts of misinforma-\ntion tagging.\nFor each tweet, let Ybe the outcome variable (i.e., political or\ncontent diversity of a speci \ufb01ct w e e t ) . Tis a binary variable indicating\nwhether the treatment tweet, but not control tweet, receives thetreatment (i.e., misinformation tagging). Gis a binary variable indi-\ncating whether the tweet is assigned in the treatment (i.e., 1) or controlgroup (i.e., 0). Cis an indicator of the type of misinformation tagging\nwhere 0 represents individual tagging and 1 represents collectivetagging. Ncorresponds to the number of tweets per day (control\nvariable), \u03b1corresponds to the user \ufb01x e de f f e c t ,a n da n d \u03f5is the error\nterm.\nY=\u03b2\n0+\u03b21TG+\u03b22TGC +\u03b23T+\u03b24TC+\u03b25N+\u03b1+\u03f5 \u00f02\u00de\n\u03b20is the intercept. \u03b21is the difference in pre-post change in the\noutcome between the control and treatment group for individualmisinformation tagging. \u03b2\n1+\u03b22is the difference in pre-post change for\ncollective misinformation tagging. Thus, \u03b22is the term that estimates\nthe difference between the effects of individual and collective mis-information tagging. \u03b2\n3and\u03b24account for the baseline changes in the\noutcomes. Supplementary Table 13 shows how these estimates cor-respond to each cell in Table 2for each outcome.\nLike ITS models, political diversity (binary variable) has been\nmultiplied by 100 so that the coef \ufb01cients are interpretable as absolute\npercentage point changes. Content diversity has been normalized to\nz-scores (i.e., the number of standard deviations from the mean). When\nestimating the statistical signi \ufb01cance of these coef \ufb01cients, all p-values\nare two-sided. The thresholds for statistical signi \ufb01cance is set at\np< .05, and marginal signi \ufb01cance is set at p<0 . 1 .\nSupplementary Fig. 6 illustrates day-to-day changes in the out-\ncome variables (political and content diversity) for the control andtreatment groups over the pre-intervention period, controlling fortime-invariant differences across users (i.e., user \ufb01xed effects). Sup-\nplementary Fig. 6 suggests that control and treatment groups followsimilar trends in the absence of the tagging intervention. To statisti-cally test this, we \ufb01tt a linear model: Diversity =\u03b2\n0+\u03b21Day +\n\u03b22IsTreatmentGroup + \u03b23Day \u22c5IsTreatmentGroup +\u03b5,w h e r e Dayis the\nnumber of days in the matched pre-intervention period, and IsTreat-\nmentGroup is 1 for the treatment group and 0 for the control group. If\nthe parallel trends assumption holds, we would \ufb01nd a non-signi \ufb01cant\nslope difference ( \u03b23). Our results show no signi \ufb01cant slope difference\nfor both political diversity ( \u03b23=\u22120.493, 95% CI = [ \u22121.644, 0.725],\nt(3) = \u22120.864, p= .408) and content diversity ( \u03b23= 0.011, 95% CI =\n[\u22120.036, 0.058], t(3) = 0.511, p= 0.620) (see Supplementary Table 14).\nSupplementary Fig. 7 illustrates average baseline changes of\npolitical and content diversity obtained from the control group in theDF analysis. According to the baseline changes, we \ufb01nd that political\ndiversity signi \ufb01cantly increases ( \u03b2= 1.956, 95% CI = [0.068, 3.843],\nt(8182) = 2.03, p= 0.042), but content diversity does not signi \ufb01cantly\ndecrease ( \u03b2=\u22120.039, 95% CI = [ \u22120.079, 0.002], t(8182) = \u22121.88,\np= 0.060) if the problematic tweet is not tagged. In other words, we\n\ufb01nd that political diversity consistently increases over time without\ntagging in the control group. On the other hand, we \ufb01nd that content\ndiversity does not signi \ufb01cantly change. Our results show that the\neffects of individual and collective tagging are above and beyond thesebaseline changes (see Results: Delayed Feedback (DF) Analysis).\nTopic modeling\nWe apply BERTopic to extract latent topics from tweets that receivedmisinformation tags\n65.S p e c i \ufb01cally, we \ufb01rst represent each tweet with a768-dimensional semantic embedding using Twitter4SSE. Then, we\nmap the embeddings to a 5-dimensional space via UMAP (UniformManifold Approximation and Projection) to mitigate the curse ofdimensionality\n66,67. Next, we apply HDBSCAN (Hierarchical Density-\nBased Spatial Clustering of Applications with Noise) to identify clusters\nof topics68. Unlike k-means algorithms, HDBSCAN does not require the\nuser to pre-specify the number of clusters, and HDBSCAN is adept atidentifying and handling noise, distinguishing between topics andoutliers, which is crucial for maintaining the integrity of the clusteredtopics.\nTraditional methods such as LDA extract topics based on bag-of-\nwords and often fall short when applied to short texts like tweets\n69.\nBERTopic emerges as particularly advantageous for analyzing datafrom Twitter and it preserves the semantic structure of the text\n63,t h u s\nenhancing its ability for short-text analysis compared to traditional\nmodels.\nWe generate 23 topics for 6660 fact-checked tweets, and 1073\ntweets are not assigned any topic and thus considered as outliers.These outliers are excluded from the process of assigning tweets intocontrol and treatment groups in the delayed feedback (DF) analysis.Most frequent topics with the keywords are shown in the Supple-mentary Table 7. As shown in Supplementary Table 7, the nine mostfrequent topics in our dataset include political topics that are known totrigger divisive, polarized reactions in US politics, such as COVID-19vaccine-related misinformation (Topic 1), election- and politician-related misinformation (Topic 4, 5, 7, 8), policy-related misinformation\n(Topic 3, 6), and environment and disaster-related misinformation\n(Topic 9). These topics account for 84.06% of the corrections madethrough individual tagging and 59.49% of the corrections madethrough collective tagging. Given the time period of collection, themost frequent topic is about COVID-19 pandemic and vaccination.\nLinguistic characteristics of misinformation tagging messages\nFor each misinformation tagging, we analyze the message \u2019s toxicity,\nsentiment, length, reading ease, and delayed response time to provideinsights into the qualitative differences between individual and col-lective misinformation tagging. Supplementary Table 4 shows the\ndescriptive statistics of the following variables.\n\u0081Toxicity: We apply Google Jigsaw Perspective API to measure the\nprobability that a particular message is toxic (range from 0to 1\n10,70).\n\u0081Sentiment: We conduct Vader sentiment analysis to estimate\nsentiment scores of messages (on a [ \u22121, 1] scale14,71). The scale\nspans from -1, denoting negative sentiment, to 1, denoting posi-tive sentiment.\n\u0081L e n g t h :W em e a s u r et h el e n g t ho fm e s s a g e sb a s e do nt h en u m b e r\nof characters\n14.\n\u0081Reading ease score: We evaluate the readability of messages with\nthe Flesch-Kincaid Reading Ease score (on a [1,100] scale, where\nlarge value indicates easier readability14,72). The Flesch \u2013Kincaid\nreading ease score was transformed into an 8-level categoricalvariable: \u201c5th grade \u201dfor scores 100 \u201390, \u201c6th grade \u201dfor 90 \u201380,\n\u201c7th grade \u201dfor 80 \u201370, \u201c8th & 9th grade \u201dfor 70 \u201360, \u201c10th to 12th\ngrade \u201dfor 60 \u201350, \u201cCollege \u201dfor 50 \u201330, \u201cCollege graduate \u201dfor\n30\u201310, and \u201cProfessional \u201dfor 10 \u20130.\n\u0081Delayed response time: We calculate it as the number of days\nbetween original tweets and misinformation tagging.\nRobustness checks\nWe verify our \ufb01ndings with a battery of robustness checks. First, there\nmight be concerns that our conclusions about the effects of mis-\ninformation tagging on human users may be biased by the presence ofbots on Twitter. Many studies have utilized bot detection algorithms toexclude users who are likely to be bots to address this concern\n2,5,b u t\nothers argue these algorithms lead to false negatives (i.e., botsArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 10\nmisclassi \ufb01ed as humans) and positives (i.e., humans misclassi \ufb01ed as\nbots) that could further bias analyses, even when used cautiously54.T o\nmitigate concerns of bot prevalence, we reanalyze our data excludingaccounts identi \ufb01ed as bots using BotometerLite API. Speci \ufb01cally, using\nBotometerLite API, we evaluate the likelihood of users in our dataset\nbeing bot accounts and remove 360 accounts that have a likelihoodhigher than 50%\n73, which do not meaningfully change our results. In\ninterrupted time series (ITS) models, after individual tagging, bothpolitical diversity ( \u03b2=\u22120.882, 95% CI = [ \u22121.326, \u22120.438],\nt(394654) = \u22123.89, p< 0.001) and content diversity ( \u03b2=\u22120.026, 95%\nCI = [ \u22120.037, \u22120.014], t(394654) = \u22124.27, p< 0.001) signi \ufb01cantly\ndecrease. After collective tagging, content diversity signi \ufb01cantly\nincreases ( \u03b2= 0.052, 95% CI = [0.020, 0.084], t(394654) = 3.16,\np= 0.002) (refer to Supplementary Table 15 and 10). In delayed feed-\nback (DF) models, the effects of individual tagging on political diver-\nsity ( \u03b2=\u22125.348, 95% CI = [ \u22129.154, \u22121.542], t(7766) = \u22122.75, p=. 0 0 6 )a n d\ncollective tagging on content diversity are signi \ufb01cant ( \u03b2=0 . 2 9 2 ,9 5 %\nCI = [0.149, 0.435], t(7766) = 4.00, p< 0.001) (refer to Supplementary\nTable 17).\nIn terms of applying BotometerLite API, some features are missing\nin our dataset collected with Twitter API 2.0: (1) default_pro \ufb01le(whe-\nther the user altered the theme or background of their user pro \ufb01le); (2)\npro\ufb01le_use_background_image (whether the user has a background\nimage or not); and (3) favourites_count (number of likes posted by the\nuser, which were only available in Twitter API 1.1). To address this issue,we conduct missing data imputation with the IterativeImputer in\nSklearn. We train an imputation model with 90,000 tweets randomly\nselected in August 2021 from the Twitter Stream Grab ( https://archive.\norg/details/twitterstream ). We then evaluate the model with a held-out\nsample of 10,000 tweets. The model performance for predicting themissing features is as follows: default_pro \ufb01le at 0.95 F-1score, pro \ufb01-\nle_use_background_image at 0.90 F-1\nscore, favourites_count was 0.10\nR2value. Finally, we apply this imputation model to recover the missing\nfeatures in our dataset.\nSecond, we control for potentially insincere informational\nactivities, such as citing sources of low credibility and intentionallyspreading fake news. Some might question whether the increase in\npolitical and content diversity is associated with these insincere\nactivities. Put simply, users might be engaging with diverse infor-mation that includes misleading claims and conspiracy theories. Foreach tweet posted by each poster, we measure the credibility of thereferenced source. Speci \ufb01cally, we use the binary credibility scores\n(1 = low credibility; 0=medium or high credibility) from the Media-Bias/FactCheck database. Our analysis indicates a strong negativecorrelation between the engagement of low-credibility sources andmeasures of political diversity ( r=\u22120.227, 95% CI = [ \u22120.229,\n\u22120.225], p< 0.001) and content diversity ( r=\u22120.030, 95% CI = [ \u2212\n0.032, \u22120.028], p< 0.001). This implies that the increase of diversity\nin information engagement re \ufb02ects engagement with a healthier\ninformation ecosystem, rather than the reverse. Furthermore, wereassess our data while controlling for credibility of sources, and\ufb01nd that our results remain unaffected. In ITS models, after indivi-\ndual tagging, both political diversity ( \u03b2=\u22120.972, 95% CI = [ \u22121.395,\n\u22120.549], t(418114) = \u22124.50, p< 0.001) and content diversity\n(\u03b2=\u22120.030, 95% CI = [ \u22120.042, \u22120.018], t(418114) = \u22125.08, p< 0.001)\nsigni\ufb01cantly decrease. After collective tagging, content diversity\nsigni\ufb01cantly increases ( \u03b2= .041, 95% CI = [0.012, 0.070],\nt(418114) = 2.76, p= 0.006) (refer to Supplementary Table 15 and 10).\nIn DF models, the effects of individual tagging on political diversity(\u03b2= -4.958, 95% CI = [ \u22128.591, \u22121.324], t(8181) = \u22122.67, p= 0.007) and\ncollective tagging on content diversity are signi \ufb01cant ( \u03b2= 0.279, 95%\nCI = [0.150, 0.407], t(8181) = 4.25, p< 0.001) (refer to Supplementary\nTable 17). This implies that posters \u2019\nexploration prior to being tag-\nged was likely well-intentioned and would have been ef \ufb01cacious had\nthey not been prompted to retreat.Third, we attempt to avoid situations in which posters simply\ncriticize distant information without honest consideration by \ufb01ltering\nout tweets with negative sentiment. For each tweet posted by eachposter, we conduct Vader sentiment analysis to estimate sentiment\nscores (on a [ \u22121, 1] scale\n14,71). Then we exclude tweets that have a sen-\ntimental score lower than 0, which do not meaningfully change ourresults, except for making the immediate change of content diversityafter collective misinformation tagging not signi \ufb01cant in ITS models\n(\u03b2=0 . 0 0 9 ,9 5 %C I=[ \u22120.031, 0.048], t(262015) = 0.43, p= 0.666). In ITS\nmodels, after individual tagging, both political diversity ( \u03b2=\u22121.470,\n95% CI = [-2.032, -.909], t(262015) = -5.13, p< .001) and content diver-\nsity ( \u03b2=\u22120.027, 95% CI = [ \u22120.042, \u22120.011], t(262015) = \u22123.35, p= 0.001)\nsigni\ufb01cantly decrease (refer to Supplementary Table 15 and 10). In DF\nmodels, the effects of individual tagging on political diversity(\u03b2=\u22128.075, 95% CI = [ \u221212.757, \u22123.394], t(4973) = \u22123.38, p=0 . 0 0 1 )a n d\ncollective tagging on content diversity are signi \ufb01cant ( \u03b2=0 . 2 9 4 ,9 5 %\nCI = [0.114, 0.474], t(4973) = 3.20, p= 0.001) (refer to Supplementary\nTable 17).\nFourth, we address concerns regarding the possibility of mis-\ncoding mentions of \u201ccommunity note. \u201dSpeci \ufb01cally, we identify all\ntweets that mention keywords about receiving community notesbroadly (i.e., community note, birdwatch, fact-check, factcheck, poli-tifact) within the sample and remove those tweets. To address theconcern regarding the effect of replying back to individual taggers, weidentify all tweets that reply directly to the individual taggers andremove them. We \ufb01nd that the effects on political and content diver-\nsity do not meaningfully change in both ITS and DF analyses. In ITS\nmodels, after individual tagging, both political diversity ( \u03b2=\u22121.048,\n95% CI = [ \u22121.488, \u22120.608], t(416183) = \u22124.67, p< 0.001) and content\ndiversity ( \u03b2=\u22120.030, 95% CI = [ \u2212\n0.041, \u22120.018], t(416183) = \u22125.00,\np< 0.001) signi \ufb01cantly decrease. After collective tagging, content\ndiversity signi \ufb01cantly increases ( \u03b2= 0.041, 95% CI = [0.012, .069],\nt(416183) = 2.75, p= 0.006) (refer to Supplementary Table 18). In DF\nmodels, the effects of individual tagging on political diversity(\u03b2=\u22125.329, 95% CI = [ \u22129.139, \u22121.519], t(8088) = \u22122.74, p= .006) and\ncollective tagging on content diversity are signi \ufb01cant ( \u03b2=0 . 2 7 6 ,9 5 %\nCI = [0.148, 0.405] t(8088) = 4.22, p< 0.001) (refer to Supplementary\nTable 19).\nFifth, to strictly identify individual tags (i.e., PolitiFact links) that\ncorrect the original posters, we submit original posts, replies con-taining PolitiFact links, and the cited PolitiFact fact-checking articles toChatGPT (gpt-4o-2024-05-13). We prompt the model to annotatewhether the PolitiFact link was used to correct the original posterrather than support them. Consequently, we identify 5592 PolitiFactl i n k so u to f6 7 6 0l i n k s( 8 2 . 7 2 % )a sc o r r e c t i v e( s e eS u p p l e m e n t a r yMethod 9). Subsequently, we limit the sample to the 5592 links iden-ti\ufb01ed by ChatGPT from the individual tagging data, which does not\nmeaningfully alter the results. In ITS models, after individual tagging,\nboth political diversity ( \u03b2=\u22121.086, 95% CI = [ \u22121.558, \u22120.614],\nt(363273) = \u22124.51, p< 0.001) and content diversity ( \u03b2=\u22120.039, 95%\nCI = [ \u22120.051, \u22120.026], t(363273) = \u22126.11, p< 0.001) signi \ufb01cantly\ndecrease. After collective tagging, content diversity signi \ufb01cantly\nincreases ( \u03b2= 0.041, 95% CI = [0.012, 0.069], t(416183) = 2.75, p=. 0 0 6 )\n(refer to Supplementary Table 20). In DF models, the effects of indi-vidual tagging on political diversity ( \u03b2=\u22127.135, 95% CI = [ \u221211.068,\n\u2212\n3.203], t(7508) = \u22123.56, p< 0.001) and collective tagging on content\ndiversity are signi \ufb01cant ( \u03b2=0 . 2 7 2 ,9 5 %C I=[ 0 . 1 4 3 ,. 4 0 1 ] t(7508) = 4.13,\np< 0.001) (refer to Supplementary Table 21).\nSixth, we restrict the sample to original posters who have replied\nto (and thereby read) the individual tags (i.e., fact-checking replies)\nand remove non-responders. Speci \ufb01cally, out of 6760 original posters\nwho received individual tags, we remove 4288 posters who did notreply to the tags, resulting in 2472 posters. After that, we comparethese 2472 posters with 973 posters who received collective tags. Even\nafter removing the non-responders, we \ufb01nd that results regardingArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 11\ntagging \u2019se f f e c t sr e m a i nc o n s i s t e n t .S p e c i \ufb01cally, as with the complete\nsample, we identically \ufb01nd that individual tagging causes immediate\ndecrease in political and content diversity. After individual tagging,both political diversity ( \u03b2=\u22121.481, 95% CI = [ \u22122.337, \u22120.626]\nt(164724) = \u22123.39, p= 0.001) and content diversity ( \u03b2=\u22120.026, 95%\nCI = [ \u22120.048, \u22120.004], t(164724) = \u22122.30, p=0 . 0 2 1 ) s i g n i \ufb01cantly\ndecrease. After collective tagging, content diversity signi \ufb01cantly\nincreases ( \u03b2= .040, 95% CI = [.010, .071], t(164724) = 2.59, p= 0.010)\n(refer to Supplementary Table 22)\nReporting summary\nFurther information on research design is available in the NaturePortfolio Reporting Summary linked to this article.\nData availability\nThe Twitter data collected and analyzed in this study have beendeposited in the Open Science Foundation (OSF) database at https://\ndoi.org/10.17605/OSF.IO/TXGSR . The data required to replicate our\nanalyses are available in the repository. However, in accordance withTwitter \u2019s privacy policy, we cannot disclose individual-level user\ninformation or the contents of tweets. Instead, processed and anon-ymized data are available in the repository.\nCode availability\nThe code required to replicate our results is available at https://doi.\norg/10.17605/OSF.IO/TXGSR .\nReferences\n1. Lazer, D. M. J. et al. The science of fake news. Science 359,\n1094 \u20131096 (2018).\n2. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news\nonline. Science 359,1 1 4 6 \u20131151 (2018).\n3. Loomba, S., de Figueiredo, A., Piatek, S. J., de Graaf, K. & Larson, H.\nJ. Measuring the impact of COVID-19 vaccine misinformation onvaccination intent in the UK and USA. Nat. Hum. Behav. 5,\n337 \u2013348 (2021).\n4. Green, J., Hobbs, W., McCabe, S. & Lazer, D. Online engagement\nwith 2020 election misinformation and turnout in the 2021 Georgia\nrunoff election. P r o c .N a t lA c a d .S c i .U S A 119, e2115900119 (2022).\n5. Bovet, A. & Makse, H. A. In \ufb02u e n c eo ff a k en e w si nT w i t t e rd u r i n gt h e\n2016 US presidential election. Nat. Commun. 10,7( 2 0 1 9 ) .\n6 . H a n n a k ,A . ,M a r g o l i n ,D . ,K e e g a n ,B .&W e b e r ,I .G e tb a c k !Y o ud o n \u2019t\nknow me like that: The social mediation of fact checking interven-tions in Twitter conversations. Proc. Int. AAAI Conf. Web Soc. Media\n8,1 8 7 \u2013196 (2014).\n7. Shin, J. & Thorson, K. Partisan selective sharing: the biased diffusion\nof fact-checking messages on social media. J. Commun. 67,\n233 \u2013255 (2017).\n8. Pilarski, M., Solovev, K. & Pr\u00f6ll ochs, N. Community notes vs. snop-\ning: how the crowd selects fact-checking targets on social media.Proc. Int. AAAI Conf. Web Soc. Media 18,1 2 6 2 \u20131275 (2023).\n9 . M i c a l l e f ,N . ,H e ,B . ,K u m a r ,S . ,A h a m a d ,M .&M e m o n ,N .T h er o l eo f\nthe crowd in countering misinformation: a case study of the COVID-19 infodemic. in 2020 IEEE International Conference on Big Data\n.https://doi.org/10.1109/bigdata50022.2020.9377956 (IEEE, 2020).\n10. Mosleh, M. & Rand, D. G. Measuring exposure to misinformation\nfrom political elites on Twitter. Nat. Commun. 13, 7144 (2022).\n11. Rhodes, S. C. Filter bubbles, echo chambers, and fake news: how\nsocial media conditions individuals to be less critical of politicalmisinformation. Polit. Commun. 39,1\u201322 (2022).\n12. Bhadani, S. et al. Political audience diversity and news reliability in\nalgorithmic ranking. Nat. Hum. Behav. 6, 495 \u2013505 (2022).\n13. Wojcik, S. et al. Birdwatch: Crowd Wisdom and Bridging Algorithms\ncan Inform Understanding and Reduce the Spread of Misinforma-tion. Preprint at https://arxiv.org/abs/2210.15723 (2022).1 4 . A l l e n ,J . ,M a r t e l ,C .&R a n d ,D .G . Birds Of A Feather Don \u2019t Fact-check\nEach Other: Partisanship And The Evaluation Of News In Twitter \u2019s\nBirdwatch Crowdsourced Fact-checking Program .i nProceedings of\nthe 2022 CHI Conference on Human Factors in Computing Systems\n1\u201319 (Association for Computing Machinery, 2022).\n15. Clayton, K. et al. Real solutions for fake news? Measuring the\neffectiveness of general warnings and fact-check tags in reducingbelief in false stories on social media. Polit. Behav. 42,\n1073 \u20131095 (2020).\n16. Nyhan, B. & Rei \ufb02er, J. When corrections fail: the persistence of\npolitical misperceptions. Polit. Behav. 32,3 0 3 \u2013330 (2010).\n17. Bail, C. A. et al. Exposure to opposing views on social media can\nincrease political polarization. Proc. Natl Acad. Sci. USA 115,\n9216 \u20139221 (2018).\n18. Mosleh, M., Martel, C., Eckles, D. & Rand, D. Perverse Downstream\nConsequences of Debunking: Being Corrected by Another User for\nPosting False Political News Increases Subsequent Sharing of LowQuality, Partisan, and Toxic Content in a Twitter Field Experiment. in\nProceedings of the 2021 CHI Conference on Human Factors inComputing Systems 1\u201313 (Association for Computing Machin-\nery, 2021).\n19. Swire-Thompson, B., DeGutis, J. & Lazer, D. Searching for the\nback\ufb01re effect: measurement and design considerations. J. Appl.\nRes. Mem. Cogn. 9,2 8 6 \u2013299 (2020).\n2 0 . W o o d ,T .&P o r t e r ,E .T h ee l u s i v eb a c k \ufb01re effect: mass attitudes \u2019\nsteadfast factual adherence. Polit. Behav. 41,1 3 5 \u2013163 (2019).\n21. Jiang, S. & Wilson, C. Linguistic signals under misinformation and\nfact-checking: evidence from user comments on social media.Proc. ACM Hum. -Comput. Interact. 2,1\u201323 (2018).\n22. Masullo, G. M. & Kim, J. Exploring \u2018angry \u2019and \u2018like \u2019reactions on\nuncivil facebook comments that correct misinformation in thenews. Digital Journalism 9, 1103 \u20131122 (2021).\n23. YouTube. Testing new ways to offer viewers more context and\ninformation on videos. YouTube Of \ufb01cial Blog https://blog.\nyoutube/news-and-events/new-ways-to-offer-viewers-more-context/ (2024).\n24. Kaplan, J. More Speech and Fewer Mistakes. Meta Newsroom\nhttps://about.fb.com/news/202 5/01/meta-more-speech-fewer-\nmistakes/ (2025).\n25. Page, S. E. The Difference: How the Power of Diversity Creates Better\nGroups, Firms, Schools, and Societies - New Edition .( P r i n c e t o n\nUniversity Press, 2008).\n26. Page, S. E. The Diversity Bonus: How G reat Teams Pay Off in the\nKnowledge Economy . (Princeton University Press, 2019).\n27. Saeed, M., Traub, N., Nicolas, M., Demartini, G. & Papotti, P.\nCrowdsourced Fact-Checking at Twitter: How Does the CrowdCompare With Experts? in Proceedings of the 31s t ACM International\nConference on Information & Knowledge Management 1736 \u20131746\n(Association for Computing Machinery, 2022).\n28. Allen, J., Arechar, A. A., Pennycook, G. & Rand, D. G. Scaling up fact-\nchecking using the wisdom of crowds. Sci. Adv. 7, eabf4393 (2021).\n2 9 . M a r t e l ,C . ,A l l e n ,J . ,P e n n y c o o k ,G .&R a n d ,D .G .C r o w d sc a n\neffectively identify misinformation at scale. Perspect. Psychol. Sci .\n19,4 7 7 \u2013488 (2023).\n30. Twitter. Values. Community Notes Guide https://communitynotes.\ntwitter.com/guide/en/contributing/values (2023).\n31. Jamieson, K. H. & Cappella, J. N. Echo Chamber: Rush Limbaugh and\nthe Conservative Media Establishment .( O x f o r dU n i v e r s i t y\nPress, 2008).\n32. Muller, D. Democracy Under Strain .i nJournalism and the Future of\nDemocracy 9-25 (Palgrave Macmillan, Cham, 2022).\n33. T\u00f6rnberg, P. Echo chambers and viral misinformation: modeling\nfake news as complex contagion. PLoS One 13,e 0 2 0 3 9 5 8( 2 0 1 8 ) .\n34. Del Vicario, M. et al. The spreading of misinformation online. Proc.\nNatl Acad. Sci. USA 113,5 5 4 \u2013559 (2016).Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 12\n35. Flamino, J. et al. Political polarization of news media and in \ufb02uencers\non Twitter in the 2016 and 2020 US presidential elections. Nat. Hum.\nBehav. 7,9 0 4 \u2013916 (2023).\n3 6 . S a m o r y ,M . ,A b n o u s i ,V .K .&M i t r a, T. Characterizing the social\nmedia news sphere through user co-sharing practices. Proc. Int.\nAAAI Conf. Web Soc. Media 14,6 0 2 \u2013613 (2020).\n37. Bessi, A. et al. Homophily and polarization in the age of mis-\ninformation. Eur. Phys. J. Spec. Top. 225,2 0 4 7 \u20132059 (2016).\n3 8 . C i n e l l i ,M . ,D eF r a n c i s c iM o r a l e s ,G . ,G a l e a z z i ,A . ,Q u a t t r o c i o c c h i ,W .\n& Starnini, M. The echo chamber effect on social media. Proc. Natl\nA c a d .S c i .U S A 118, e2023301118 (2021).\n39. Bode, L. Political news in the news feed: learning politics from social\nmedia. Mass Commun. Soc. 19,2 4 \u201348 (2016).\n4 0 . C o n o v e r ,M .D . ,G o n c a l v e s ,B . ,R a t k i e w i c z ,J . ,F l a m m i n i ,A .&\nMenczer, F. Predicting the Political Alignment of Twitter Users. in\n2011 IEEE Third International Conference on Privacy, Security, Risk\nand Trust and 2011 IEEE Third International Conference on SocialComputing 192 \u2013199 (IEEE, 2011).\n41. Luzsa, R. & Mayr, S. False consensus in the echo chamber: Exposure\nto favorably biased social media news feeds leads to increasedperception of public support for own opinions. Cyberpsychology\n15, 3 (2021).\n4 2 . C o o k e ,N .A . Fake News and Alternative Facts: Information Literacy in\na Post-Truth Era . (American Library Association, 2018).\n43. DellaPosta, D., Shi, Y. & Macy, M. Why Do Liberals Drink Lattes? Am.\nJ. Sociol. 120,1 4 7 3 \u20131511 (2015).\n44. Mutz, D. C. & Rao, J. S. The Real Reason Liberals Drink Lattes. PS\nPolit. Sci. Polit. 51,7 6 2 \u2013767 (2018).\n45. Shi, F., Shi, Y., Dokshin, F. A., Evans, J. A. & Macy, M. W. Millions of\nonline book co-purchases reveal partisan differences in the con-sumption of science. Nat. Hum. Behav. 1,1\u20139( 2 0 1 7 ) .\n46. Milbauer, J., Mathew, A. & Evans, J. A. Aligning multidimensional\nworldviews and discovering id eological differences. in Proceedings\nof the 2021 Conference on Empirical Methods in Natural LanguageProcessing 4832 \u20134845 (Association for Computational Linguis-\ntics, 2021).\n4 7 . G a l l o t t i ,R . ,V a l l e ,F . ,C a s t a l d o ,N . ,S a c c o ,P .&D eD o m e n i c o ,M .\nAssessing the risks of \u2018infodemics \u2019in response to COVID-19 epi-\ndemics. Nat. Hum. Behav. 4,1 2 8 5 \u20131293 (2020).\n48. Anderson, A., Maystre, L., Anderson, I., Mehrotra, R. & Lalmas, M.\nAlgorithmic Effects on the Diversi ty of Consumption on Spotify. in\nProceedings of the 2020 World Wide Web Conference 2155 \u20132165\n(Association for Computing Machinery, 2020).\n49. Srinivasan, K. B., Danescu-Niculescu-Mizil, C., Lee, L. & Tan, C.\nContent Removal as a Moderation Strategy: Compliance and OtherOutcomes in the ChangeMyView Community. Proc. ACM Hum.\n-Computer Interact. 3,1\u201321 (2019).\n50. Thaler, R. H. & Sunstein, C. R. Nudge: The Final Edition .\n(Penguin, 2021).\n51. Jones-Jang, S. M., Mortensen, T. & Liu, J. Does Media Literacy Help\nIdenti \ufb01cation of Fake News? Information Literacy Helps, but Other\nLiteracies Don \u2019t.A m .B e h a v .S c i . 65,3 7 1 \u2013388 (2021).\n52. Becker, J., Porter, E. & Centola, D. The wisdom of partisan crowds.\nP r o c .N a t lA c a d .S c i .U S A 116,1 0 7 1 7 \u201310722 (2019).\n53. Shi, F., Teplitskiy, M., Duede, E. & Evans, J. A. The wisdom of\npolarized crowds. Nat. Hum. Behav. 3,3 2 9 \u2013336 (2019).\n54. Rauch \ufb02eisch, A. & Kaiser, J. The False positive problem of automatic\nbot detection in social science research. PLoS One 15,\ne0241045 (2020).\n55. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer,\nD. Fake news on Twitter during the 2016 U.S. presidential election.\nScience 363,3 7 4 \u2013378 (2019).\n56. Ledford, H. Researchers scramble as Twitter plans to end free data\naccess. Nature 614,6 0 2 \u2013603 (2023).57. Community Notes. Beginning today, Community Notes are visible\naround the world. Twitter https://twitter.com/CommunityNotes/\nstatus/1601753552476438528 (2022).\n58. Wang, Z. et al. Demographic Inference and Representative Popula-\ntion Estimates from Multilingual Social Media Data. in Proceedings of\nthe 2019 World Wide Web Conference 2056 \u20132067 (Association for\nComputing Machinery, 2019).\n5 9 . B a g r o w ,J .P . ,L i u ,X .&M i t c h e l l ,L .I n f o r m a t i o n \ufb02ow reveals prediction\nlimits in online social activity. Nat. Hum. Behav. 3,1 2 2 \u2013128 (2019).\n60. Rao, A., Morstatter, F. & Lerman, K. Retweets Amplify the Echo\nChamber Effect. in Proceedings of the 2023 IEEE/ACM International\nConference on Advances in Social Networks Analysis and Mining30\u201337 (Association for Compu ting Machinery, 2024).\n61. Barber\u00e1, P., Jost, J. T., Nagler, J., Tucker, J. A. & Bonneau, R.\nTweeting From Left to Right: Is Online Political Communication\nMore Than an Echo Chamber? Psychol. Sci. 26\n,1 5 3 1 \u20131542 (2015).\n62. Di Giovanni, M. & Brambilla, M. Exploiting Twitter as Source of Large\nCorpora of Weakly Similar Pairs for Semantic Sentence Embeddings .\ninProceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing 9902 \u20139910 (Association for Compu-\ntational Linguistics, 2021).\n63. Nguyen, D. Q., Vu, T. & Nguyen, A. T . BERTweet: A pre-trained lan-\nguage model for English Tweets .i nProceedings of the 2020 Con-\nference on Empirical Methods in Natural Language Processing:System Demonstrations 9\u201314 (Association for Computational Lin-\nguistics, 2020).\n64. Waller, I. & Anderson, A. Generalists and Specialists: Using Com-\nmunity Embeddings to Quantify Activity Diversity in Online Plat-forms. inProceedings of the 2019 World Wide Web Conference\n1954 \u20131964 (Association for Computing Machinery, 2019).\n65. Grootendorst, M. BERTopic: Neural topic modeling with a class-\nbased TF-IDF procedure. Preprint at https://arxiv.org/abs/2203.\n05794 (2022).\n66. McInnes, L., Healy, J. & Melville, J. UMAP: uniform manifold\napproximation and projection for dimension reduction. J. Open\nSource Softw. 3,8 6 1( 2 0 1 8 ) .\n6 7 . H o u l e ,M .E . ,K r i e g e l ,H . - P . ,K r \u00f6 g e r ,P . ,S c h u b e r t ,E .&Z i m e k ,A . Can\nShared-Neighbor Distances Defeat the Curse of Dimensionality ?i n\nProceedings of the 22nd Interna tional Conference on Scienti \ufb01ca n d\nStatistical Database Management 482 \u2013500 (Springer, 2010).\n68. Ester, M., Kriegel, H.-P., Sander, J. & Xu, X. A Density-based Algo-\nrithm For Discovering Clusters In Large Spatial Databases WithNoise .i nProceedings of the Second International Conference on\nKnowledge Discovery and Data Mining 226 \u2013231 (AAAI, 1996).\n69. Tierney, G., Bail, C. & Volfovsky, A. Author clustering and topic\nestimation for short texts. Preprint at http://arxiv.org/abs/2106.\n09533 (2021).\n70. Lees, A. et al. A New Generation of Perspective API: Ef \ufb01cient Mul-\ntilingual Character-level Transformers. in Proceedings of the 28th\nACM SIGKDD Conference on Knowledge Discovery and Data Mining3197 \u20133207 (Association for Computing Machinery, 2022).\n71. Hutto, C. & Gilbert, E. VADER: a parsimonious rule-based model for\nsentiment analysis of social media text. Proc. Int. AAAI Conf. Web\nSoc. Media 8,2 1 6 \u2013225 (2014).\n72. Kincaid, J. P., Fishburne, R. P., Jr, Rogers, R. L. & Chissom, B. S.\nDerivation Of New Readability Formulas (Automated ReadabilityIndex, Fog Count And Flesch Reading Ease Formula) For NavyEnlisted Personnel . (US Naval Air Station, 1975).\n73. Yang, K.-C., Ferrara, E. & Menc zer, F. Botometer 101: social bot\npracticum for computational social scientists. J. Comput Soc. Sc. 5,\n1511 \u20131528 (2022).\n74. Reimers, N. & Gurevych, I. Sentence-BERT: Sentence Embeddings\nusing Siamese BERT-Networks .i n\nProceedings of the 2019 Con-\nference on Empirical Methods in Natural Language Processing andthe 9th International Joint Conference on Natural LanguageArticle https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 13\nProcessing 3982 \u20133992 (Association for Computational Linguis-\ntics, 2019).\nAcknowledgements\nWe are grateful for the Discovery Partners Institute of Illinois for a granton the topic of Misinformation Tagging to Kevin Leicht, PI. We thankDonghyun Kang, Yoosik Youm, and Byungkyu Lee for their helpfulfeedback on our manuscript. We also thank the members and alumni ofthe Knowledge Lab (University of Chicago) and Yonsei Social Networks &Neuroscience Lab for their comments.\nAuthor contributions\nJ.K., Z.W., and J.E. collaboratively conceived and designed the study,drafted, revised, and edited the manus cript. J.K. and H.S. performed the\nanalysis. J.K., H.S., and H.L. gathered and cleaned the data. J.K. and Z.W.\nproduced the visualizations.\nCompeting interests\nJ.E. has a commercial af \ufb01liation with Google, but Google had no role in\nthe design and analysis of this study. The authors declare no othercompeting interests.\nAdditional information\nSupplementary information The online version contains\nsupplementary material available athttps://doi.org/10.103 8/s41467-025-55868-0 .\nCorrespondence and requests for materials should be addressed to\nJames Evans.Peer review information Nature Communications thanks Sarah Shugar,\nJevin West and the other, anonymous, reviewer(s) for their contributionto the peer review of this work. A peer review \ufb01le is available.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher \u2019s note Springer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional af \ufb01liations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,adaptation, distribution and reproduction in any medium or format, aslong as you give appropriate credit to the original author(s) and thesource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article \u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is notincluded in the article \u2019s Creative Commons licence and your intended\nuse is not permitted by statutory re gulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyrightholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/ .\n\u00a9 The Author(s) 2025Article https://doi.org/10.1038/s41467-025-55868-0\nNature Communications |          (2025) 16:973 14", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Individual misinformation tagging reinforces echo chambers; collective tagging does not", "author": ["J Kim", "Z Wang", "H Shi", "HK Ling", "J Evans"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2311.11282", "abstract": "Fears about the destabilizing impact of misinformation online have motivated individuals  and platforms to respond. Individuals have become empowered to challenge others' online"}, "filled": false, "gsrank": 385, "pub_url": "https://arxiv.org/abs/2311.11282", "author_id": ["O__9HOwAAAAJ", "iqF0jskAAAAJ", "-MZ5LSEAAAAJ", "", "kV4N4zoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:2S-ac4r-ElwJ:scholar.google.com/&output=cite&scirp=384&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=2S-ac4r-ElwJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 2, "citedby_url": "/scholar?cites=6634645071668588505&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:2S-ac4r-ElwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2311.11282"}}, {"title": "The covid-19 infodemic: Can the crowd judge recent misinformation objectively?", "year": "2020", "pdf_data": "The COVID-19 Infodemic: Can the Crowd Judge\nRecent Misinformation Objectively?\nKevin Roitero\nroitero.kevin@spes.uniud.it\nUniversity of Udine\nUdine, ItalyMichael Soprano\nsoprano.michael@spes.uniud.it\nUniversity of Udine\nUdine, ItalyBeatrice Portelli\nportelli.beatrice@spes.uniud.it\nUniversity of Udine\nUdine, ItalyDamiano Spina\ndamiano.spina@rmit.edu.au\nRMIT University\nMelbourne, Australia\nVincenzo Della Mea\nvincenzo.dellamea@uniud.it\nUniversity of Udine\nUdine, ItalyGiuseppe Serra\ngiuseppe.serra@uniud.it\nUniversity of Udine\nUdine, ItalyStefano Mizzaro\nmizzaro@uniud.it\nUniversity of Udine\nUdine, ItalyGianluca Demartini\ndemartini@acm.org\nThe University of\nQueensland, Australia\nABSTRACT\nMisinformation is an ever increasing problem that is difficult to\nsolve for the research community and has a negative impact on\nthe society at large. Very recently, the problem has been addressed\nwith a crowdsourcing-based approach to scale up labeling efforts:\nto assess the truthfulness of a statement, instead of relying on a few\nexperts, a crowd of (non-expert) judges is exploited. We follow the\nsame approach to study whether crowdsourcing is an effective and\nreliable method to assess statements truthfulness during a pandemic.\nWe specifically target statements related to the COVID-19 health\nemergency, that is still ongoing at the time of the study and has\narguably caused an increase of the amount of misinformation that\nis spreading online (a phenomenon for which the term \u201cinfodemic\u201d\nhas been used). By doing so, we are able to address (mis)information\nthat is both related to a sensitive and personal issue like health and\nvery recent as compared to when the judgment is done: two issues\nthat have not been analyzed in related work.\nIn our experiment, crowd workers are asked to assess the truth-\nfulness of statements, as well as to provide evidence for the assess-\nments as a URL and a text justification. Besides showing that the\ncrowd is able to accurately judge the truthfulness of the statements,\nwe also report results on many different aspects, including: agree-\nment among workers, the effect of different aggregation functions,\nof scales transformations, and of workers background / bias. We\nalso analyze workers behavior, in terms of queries submitted, URLs\nfound / selected, text justifications, and other behavioral data like\nclicks and mouse actions collected by means of an ad hoc logger.\nACM Reference Format:\nKevin Roitero, Michael Soprano, Beatrice Portelli, Damiano Spina, Vincenzo\nDella Mea, Giuseppe Serra, Stefano Mizzaro, and Gianluca Demartini. 2020.\nThe COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation\nObjectively?. In The 29th ACM International Conference on Information and\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCIKM \u201920, October 19\u201323, 2020, Virtual Event, Ireland\n\u00a92020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-6859-9/20/10. . . $15.00\nhttps://doi.org/10.1145/3340531.3412048Knowledge Management (CIKM \u201920), October 19\u201323, 2020, Virtual Event, Ire-\nland. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3340531.\n3412048\n1 INTRODUCTION\n\u201cWe\u2019re concerned about the levels of rumours and misinfor-\nmation that are hampering the response. [. . . ] we\u2019re not just\nfighting an epidemic; we\u2019re fighting an infodemic. Fake news\nspreads faster and more easily than this virus, and is just as\ndangerous. That\u2019s why we\u2019re also working with search and me-\ndia companies like Facebook, Google, Pinterest, Tencent, Twitter,\nTikTok, YouTube and others to counter the spread of rumours\nand misinformation. We call on all governments, companies\nand news organizations to work with us to sound the appropri-\nate level of alarm, without fanning the flames of hysteria. \u201d\nThese are the alarming words used by Dr. Tedros Adhanom Ghe-\nbreyesus, the WHO (World Health Organization) Director General\nduring his speech at the Munich Security Conference on 15 Febru-\nary 2020.1It is telling that the WHO Director General chooses to\ntarget explicitly misinformation related problems.\nIndeed, during the still ongoing COVID-19 health emergency,\nall of us have experienced mis- and dis-information. The research\ncommunity has focused on several COVID-19 related issues [ 4],\nranging from machine learning systems aiming to classify state-\nments and claims on the basis of their truthfulness [ 23], search\nengines tailored to the COVID-19 related literature, as in the ongo-\ning TREC-COVID Challenge2[26], topic-specific workshops like\nthe NLP COVID workshop at ACL\u201920,3and evaluation initiatives\nlike the TREC Health Misinformation Track 2020.4More than the\nacademic research community, commercial social media platforms\nalso have looked at this issue.5Among all the approaches, in some\nvery recent work, Roitero et al . [27] , La Barbera et al . [17] , Roitero\net al. [29] have studied if crowdsourcing can be used to identify\nmisinformation. As it is well known, crowdsourcing means to out-\nsource to a large mass of unknown people (the \u201ccrowd\u201d), by means\n1https://www.who.int/dg/speeches/detail/munich-security-conference\n2https://ir.nist.gov/covidSubmit/\n3https://www.nlpcovid19workshop.org/\n4https://trec-health-misinfo.github.io/\n5https://www.forbes.com/sites/bernardmarr/2020/03/27/finding-the-truth-about-\ncovid-19-how-facebook-twitter-and-instagram-are-tackling-fake-news/ and\nhttps://spectrum.ieee.org/view-from-the-valley/artificial-intelligence/machine-\nlearning/how-facebook-is-using-ai-to-fight-covid19-misinformationarXiv:2008.05701v1  [cs.IR]  13 Aug 2020\nof an open call, a task that is usually performed by a few experts.\nThat recent work [ 17,27,29] specifically crowdsource the task of\nmisinformation identification, or rather assessment of the truthful-\nness of statements made by public figures (e.g., politicians), usually\non political, economical, and societal issues. That the crowd is able\nto identify misinformation might sound implausible at first\u2014isn\u2019t\nthe crowd the very mean to spread misinformation? However, on\nthe basis of recent research [ 17,27,29], it appears that the crowd\ncan provide high quality truthfulness labels, provided that adequate\ncountermeasures and quality assurance techniques are employed.\nIn this paper we address the very same problem, but focusing on\nstatements about COVID-19. This is motivated by several reasons.\nFirst, COVID-19 is of course a hot topic but, although there is a\ngreat amount of researchers efforts worldwide devoted to its study,\nthere is no study yet using crowdsourcing to assess truthfulness\nof COVID-19 related statements. To the best of our knowledge, we\nare the first to report on crowd assessment of COVID-19 related\nmisinformation. Second, the health domain is particularly sensitive,\nso it is interesting to understand if the crowdsourcing approach is\nadequate also in such a particular domain. Third, in the previous\nwork [ 17,27,29] the statements judged by the crowd were not re-\ncent. This means that evidence on statement truthfulness was often\navailable out there (on the Web), and although the experimental\ndesign prevented to easily find that evidence, it cannot be excluded\nthat the workers did find it, or perhaps they were familiar with the\nparticular statement because, for instance, it had been discussed\nin the press. By focusing on COVID-19 related statements we in-\nstead naturally target recent statements: in some cases the evidence\nmight be still out there, but this will happen more rarely. Fourth, an\nalmost ideal tool to address misinformation would be a crowd able\nto assess truthfulness in real time, immediately after the statement\nbecomes public: although we are not there yet, and there is a long\nway to go, we find that targeting recent statements is a step forward\nin the right direction. Fifth, our experimental design differs in some\naspects from that used in previous work, and allows us to address\nnovel research questions.\n2 BACKGROUND\n2.1 COVID-19 Infodemic\nThe number of initiatives to apply Information Access\u2014and, in gen-\neral, Artificial Intelligence\u2014techniques to combat the COVID-19\ninfodemic has been rapidly increasing (see Bullock et al . [4, p. 16 ]\nfor a survey). There is significant effort on analyzing COVID-19\ninformation on social media, and linking to data from external fact-\nchecking organizations to quantify the spread of misinformation\n[7,11,32]. Mejova and Kalimeri [19] analyzed Facebook advertise-\nments related to COVID-19, and found that around 5% of them\ncontain errors or misinformation. Crowdsourcing methodologies\nhave also been used to collect and analyze data from patients with\ncancer who are affected by the COVID-19 pandemic [ 8]. To the\nbest of our knowledge, there is no work addressing the COVID-19\ninfodemic using crowdsourcing.\n2.2 Crowdsourcing Truthfulness\nRecent work has focused on the automatic classification of truth-\nfulness or fact checking [ 2,9,15,20,22,24]. Zubiaga and Ji [33]investigated, using crowdsourcing, the reliability of tweets in the\nsetting of disaster management. CLEF developed a Fact-Checking\nLab [ 9,22] to address the issue of ranking sentences according to\nsome fact-checking property.\nThere is recent work that studies how to collect truthfulness\njudgments by means of crowdsourcing using fine grained scales\n[17,27,29]. Samples of statements from the PolitiFact dataset\u2014\noriginally published by Wang [31]\u2014have been used to analyze the\nagreement of workers with labels provided by experts in the origi-\nnal dataset. Workers are asked to provide the truthfulness of the\nselected statements, by means of different fine grained scales. Roi-\ntero et al . [27] compared two fine grained scales: one in the [0,100]\nrange and one in the (0,+\u221e)range, on the basis of Magnitude\nEstimation [ 21]. They found that both scales allow to collect reli-\nable truthfulness judgments that are in agreement with the ground\ntruth. Furthermore, they show that the scale with one hundred\nlevels leads to slightly higher agreement levels with the expert\njudgments. On a larger sample of PolitiFact statements, La Bar-\nbera et al . [17] asked workers to use the original scale used by the\nPolitiFact experts and the scale in the [0,100]range. They found\nthat aggregated judgments (computed using the mean function\nfor both scales) have a high level of agreement with expert judg-\nments. Recent work by Roitero et al . [29] found similar results in\nterms of external agreement and its improvement when aggregat-\ning crowdsourced judgments, using statements from two different\nfact-checkers: PolitiFact and RMIT ABC Fact Check ( ABC). Pre-\nvious work has also looked at internal agreement , i.e., agreement\namong workers [ 27,29]. Roitero et al . [29] found that scales have\nlow levels of agreement when compared with each other: corre-\nlation values for aggregated judgments on the different scales are\naround \u03c1=0.55\u22120.6forPolitiFact and \u03c1=0.35\u22120.5forABC,\nand\u03c4=0.4forPolitiFact and\u03c4=0.3forABC. This indicates that\nthe same statements tend to be evaluated differently in different\nscales.\nThere is evidence of differences on the way workers provide\njudgments, influenced by the sources they examine, as well as the\nimpact of worker bias. In terms of sources, La Barbera et al . [17]\nfound that that the vast majority of workers (around 73% for both\nscales) use indeed the PolitiFact website to provide judgments.\nDifferently from La Barbera et al . [17] , Roitero et al . [29] used a cus-\ntom search engine in order to filter out PolitiFact andABCfrom\nthe list of results. Results show that, for all the scales, Wikipedia\nand news websites are the most popular sources of evidence used\nby the workers. In terms of worker bias, La Barbera et al . [17] and\nRoitero et al . [29] found that worker political background has an\nimpact on how workers provide the truthfulness scores. More in\ndetail, they found that workers are more tolerant and moderate\nwhen judging statements from their very own political party.\n3 AIMS AND RESEARCH QUESTIONS\nWhen compared to previous work, in this paper we aim to focus on\nseveral novel aspects. With respect to La Barbera et al . [17] , Roitero\net al . [27,29], we focus on claims about COVID-19, which are\nrecent and interesting for the research community, and are arguably\non a more relevant/sensitive topic to the workers. We investigate\nwhether the health domain makes a difference in the ability of\ncrowd workers to identify and correctly classify (mis)information,\nand if the very recent nature of COVID-19 related statements has\nan impact as well. We focus on a single truthfulness scale, given the\nevidence that the scale used does not make a significant difference\n[17,27,29]. Another important difference is that we ask workers to\nprovide a textual justification for their decision: we analyze them\nto better understand the process followed by workers to verify\ninformation, and we investigate if they can be exploited to derive\nuseful information. Finally, we also exploit and analyze worker\nbehavior.\nWe investigate the following specific Research Questions:\nRQ1 Are the crowd workers able to detect and objectively catego-\nrize online (mis)information related to the medical domain\nand more specifically to COVID-19? Which are the rela-\ntionship and agreement between the crowd and the expert\nlabels?\nRQ2 Can the crowdsourced and/or the expert judgments be trans-\nformed or aggregated in a way that it improves the abil-\nity of workers to detect and objectively categorize online\n(mis)information?\nRQ3 Which is the effect of workers\u2019 political bias in objectively\nidentifying online misinformation? And the effect of work-\ners\u2019 background and Cognitive Reflection Test (CRT) perfor-\nmances?\nRQ4 Which are the signals provided by the workers while per-\nforming the task that can be recorded? To what extent are\nthese signals related to workers\u2019 accuracy? Can these signals\nbe exploited to improve accuracy and, for instance, aggregate\nthe labels in a more effective way?\nRQ5 Which sources of information does the crowd consider when\nidentifying online misinformation? Are some sources more\nuseful? Do some sources lead to more accurate and reliable\nassessments by the workers?\n4 METHODS\nIn this section we present the dataset used to carry out our experi-\nments (Section 4.1), and the crowdsourcing task design (Section 4.2).\nOverall, we considered one dataset annotated by experts, one crowd-\nsourced dataset, one judgment scale (the same for the expert and\nthe crowd judgments), and a total of 60 statements.\n4.1 Dataset\nWe considered as primary source of information the PolitiFact\ndataset [ 31] that was built as a \u201cbenchmark dataset for fake news\ndetection\u201d [ 31] and contains over 12k statements produced by pub-\nlic appearances of US politicians. The statements of the datasets are\nlabeled by expert judges on a six-level scale of truthfulness (from\nnow on referred to as E 6):pants-on-fire ,false ,mostly-false ,\nhalf-true ,mostly-true , and true . Recently, the PolitiFact web-\nsite (the source from where the statements of the PolitiFact\ndataset are taken) created a specific section related to the COVID-19\npandemic.6For this work, we selected 10 statements for each of the\nsixPolitiFact categories, belonging to such a COVID-19 section\nand with dates ranging from February 2020 to early April 2020.\nTable 1 contains some examples of the statements we used.\n6https://www.politifact.com/coronavirus/Table 1: Examples of COVID-19 fact-checked statements.\nStatement Source Year Label\n\u201cWe inherited a broken test for COVID-19.\u201d Donald\nTrump2020 pants-on-fire\n\u201cChurch services cannot resume until we are\nall vaccinated, says Bill Gates.\u201dBloggers 2020 false\n\u201cSays a 5G law passed while everyone was\ndistracted with the coronavirus pandemic\nand lists 20 symptoms associated with 5G\nexposure.\u201dFacebook\nPost2020 mostly-false\n\u201cSays a California surfer was alone, in the\nocean, when he was arrested for violating\nthe state\u00e2\u0102\u0179s stay-at-home order.\u201dFacebook\nPost2020 mostly-true\n\u201cPhoto shows a crowded New York City\nsubway train during stay-at-home order.\u201dViral\nImage2020 true\n4.2 Crowdsourcing Experimental Setup\nTo collect our judgments we used the crowdsourcing platform\nAmazon Mechanical Turk (MTurk). Each worker, upon accepting\nour HIT, is redirected to an external server to complete the task;\nwe set the payment to $1.5 for a set of 8 statements7. The task\nitself is as follows: first, a (mandatory) questionnaire is shown to\nthe worker, to collect his/her background information such as age\nand political views. Then, the worker needs to provide answers to\nthree Cognitive Reflection Test (CRT) questions, which are used to\nmeasure the personal tendency to answer with an incorrect \u201cgut\u201d\nresponse or engage in further thinking to find the correct answer\n[10].8After the questionnaire and CRT phase, the worker is asked to\nasses the truthfulness of 8 statements: 6 from the dataset described\nin 4.1 (one for each of the six considered PolitiFact categories)\nand 2 special statements called Gold Questions , one clearly true\nand the other clearly false, manually written by the authors of this\npaper and used as quality checks. We used a randomization process\nwhen building the HITs to avoid all the possible source of bias, both\nwithin each HIT and considering the overall task.\nTo assess the truthfulness of each statement, the worker is shown:\ntheStatement , the Speaker/Source , and the Year in which the state-\nment was made. We asked the worker to provide the following\ninformation: the truthfulness value for the statement using the\nsix-level scale adopted by PolitiFact , from now on referred to\nas C 6(presented to the worker using a radio button containing\nthe label description for each category as reported in the original\nPolitiFact website), a URL that s/he used as a source of infor-\nmation for the fact checking, and a textual motivation for her/his\nresponse (which can not include the URL, and should contain at\nleast 15 words). In order to prevent the user from using PolitiFact\nas primary source of evidence, we implemented a custom search\nengine, which is based on the Bing Web Search APIs9and filters\noutPolitiFact from the returned search results.\nWe logged the user behavior using a custom logger [ 12,13], and\nwe implemented in the task the following quality checks: (i) the\njudgments assigned to the gold questions have to be coherent (i.e.,\nthe judgment of the clearly false question should be lower than the\n7Before deploying the task on MTurk, we investigated the average time spent to\ncomplete the task, and we related it to the minimum US hourly wage.\n8We used the same CRT settings as Roitero et al. [29].\n9https://azure.microsoft.com/services/cognitive-services/bing-web-search-api/\none assigned to true question); and (ii) the cumulative time spent\nto perform each judgment should be of at least 10 seconds. Note\nthat the CRT (and the questionnaire) answers were not used for\nquality check, although the workers were not aware of that.\nOverall, we used 60 statements in total (10 for each PolitiFact\ncategory), and each statement has been evaluated by 10 distinct\nworkers. Thus, we deployed 100 MTurk HITs and we collected\n800 judgments in total. The crowd task was launched on May 1st,\n2020 and it completed on May 4th, 2020. All the data used to carry\nout our experiments can be downloaded at https://github.com/\nKevinRoitero/crowdsourcingTruthfulness.\n5 RESULTS AND ANALYSIS\nWe first report some descriptive statistics about the population of\nworkers and the data collected in our experiment (Section 5.1). Then,\nwe address crowd accuracy (i.e., RQ1) in Section 5.2, transformation\nof truthfulness scales (RQ2) in Section 5.3, worker background and\nbias (RQ3) in Section 5.4, worker behavior (RQ4) in Section 5.5;\nfinally, we study information sources (RQ5) in Section 5.6.\n5.1 Descriptive Statistics\n5.1.1 Worker Background, Abandonment, and Bias.\nQuestionnaire . Overall, 1113 workers resident in the United States\nparticipated in our experiment.10In each HIT, workers were first\nasked to complete a demographics questionnaire with questions\nabout their gender, age, education and political views. By analyzing\nthe answers to the questionnaire we derived the following demo-\ngraphic statistics. The majority of workers are in the 26\u201335 age\nrange (44%), followed by 36\u201350 (25%), and 19\u201325 (18%). The ma-\njority of workers are well educated: 47% of them have a four year\ncollege degree or a bachelor degree, 21% have a college degree, and\n17% have a postgraduate or professional degree. Only about 15%\nof workers have a high school degree or less. Concerning political\nviews, we had 28% of workers that identified themselves as liberals,\n28% as moderate, 24% as conservative, 11% as very conservative and\n9% as very liberal. Moreover, 44% of workers identified themselves\nas being Democrat, 31% as being Republican, and 22% as being\nIndependent. Finally, 46% of workers agree on building a wall on\nthe southern US border, and 42% of them disagree. Overall we can\nsay that our sample is well balanced.\nCRT Test . Analyzing the CRT scores, we found that: 31% of workers\ndid not provide any correct answer, 34% answered correctly to 1\ntest question, 18% answered correctly to 2 test questions, and only\n17% answered correctly to all 3 test questions.\nAbandonment . When considering the abandonment ratio (measured\naccording to the definition provided by Han et al . [12] , Han et al .\n[13]), we found that 100of the workers (about 9%) successfully\ncompleted the task, 991(about 87%) abandoned (i.e., voluntarily\nterminated the task before completing it), and 45(about 4%) failed\n(i.e., terminated the task due to failing the quality checks too many\ntimes). Most of the abandonment (80% of the 1091 workers, 85%\nof the 991workers that abandoned) happened before judging the\nfirst statement (i.e., before really starting the task); about 7.52% of\n10Workers provide proof that they are based in US and have the eligibility to work.\n012345\nScore04080120160Frequency\n0175350525700\nCumulative\n012345\nScore020406080Frequencylow\nhigh\n012345\nScore02468Frequency\n020406080\nCumulativeFigure 1: Distribution (in blue) and the cumulative distribu-\ntion (in red) of the individual (left), gold (middle), and aggre-\ngated with mean (right).\nthe 1091 workers (8% of the 991of the workers that abandoned)\nabandoned after the last statement (most likely once failed the\nquality check).\n5.1.2 Crowdsourced Scores. Figure 1 shows the distribution (in\nblue) and the cumulative distribution (in red) of the individual (left),\ngold (middle), and aggregated with mean (right) scores provided\nby the workers for the considered PolitiFact statements.\nIf we focus on the distribution of the individual scores (left plot),\nwe can see that the distribution is quite well balanced, just lightly\nskewed towards higher truthfulness values, represented in the right-\nmost part of the plot. This behavior is also remarked when focusing\non the red line representing the cumulative distribution, which\ndisplays almost evenly spaced steps. This is a first indication that\nsuggests that crowd judgments are overall of a decent quality; in\nfact, our empirical distribution is not distant from the ideal one:\nsince we considered 10 statements for each PolitiFact category,\nthe perfect distribution would have been the uniform distribution.\nTurning to the distribution of the gold scores (i.e., the two special\nstatements used for quality check, shown in the middle plot), we\nsee that the large majority of workers (i.e., 70% for High and 43%\nforLow) used the extreme values of the scale (i.e., pants-on-fire\nandtrue ); furthermore, we see that overall the High gold question\nhas been judged correctly more times than the Lowgold question,\nsuggesting the probably the workers found the former easier to\njudge than the latter.\nWe now turn to analyze the distribution of the scores when\naggregated using the mean function (shown in the right plot). The\ndistribution for the aggregated scores becomes roughly bell-shaped,\nand slightly skewed towards high truthfulness values\u2014this behavior\nis consistent with the findings of Roitero et al . [29] . In the following\nwe discuss both the external (i.e., between workers and experts)\nand internal (i.e., among workers) agreement of our dataset.\n5.2 RQ1: Crowd Accuracy\n5.2.1 External Agreement. To answer RQ1, we start by analyzing\nthe so called external agreement, i.e., the agreement between the\ncrowd collected labels and the experts ground truth. Figure 2 shows\nthe agreement between the PolitiFact experts (x-axis) and the\ncrowd judgments (y-axis). In the first plot, each point is a judgment\nby a worker on a statement, i.e., there is no aggregation of the\nworkers working on the same statement. In the next plots all work-\ners redundantly working on the same statement are aggregated\nusing the mean (second plot), median (third plot), and majority\nvote (right-most plot). If we focus on the first plot (i.e., the one\n012345\nE012345C\n012345\nE012345C\n012345\nE012345C\n012345\nE012345C\nFigure 2: The agreement between the PolitiFact experts (x-axis) and the crowd judgments (y-axis). From left to right: C 6\nindividual judgments; C 6aggregated with mean; C 6aggregated with median; C 6aggregated with majority vote.\nwith no aggregation function applied), we can see that, overall, the\nindividual judgments are in agreement with the expert labels, as\nshown by the median values of the boxplots, which are increasing\nas the ground truth truthfulness level increases. Concerning the\naggregated values, it is the case that for all the aggregation func-\ntions the pants-on-fire andfalse categories are perceived in a\nvery similar way by the workers; this behavior was already shown\nin previous work [ 17,29], and suggests that indeed workers have\nclear difficulties in distinguishing between the two categories; this\nis even more evident considering that the interface presented to the\nworkers contained a textual description of the categories\u2019 meaning\nin every page of the task.\nIf we look at the plots as a whole, we see that within each plot\nthe median values of the boxplots are increasing when going from\npants-on-fire totrue (i.e., going from left to right of the x-axis of\neach chart). This indicates that the workers are overall in agreement\nwith the PolitiFact ground truth, thus indicating that workers are\nindeed capable of recognizing and correctly classifying misinforma-\ntion statements related to the COVID-19 pandemic. This is a very\nimportant and not obvious result: in fact, the crowd (i.e., the work-\ners) is the primary source and cause of the spread of disinformation\nand misinformation statements across social media platforms [ 6].\nBy looking at the plots, and in particular focusing on the median\nvalues of the boxplots, it appears evident that the mean (second plot)\nis the aggregation function which leads to higher agreement levels,\nfollowed by the median (third plot) and the majority vote (fourth\nplot). Again, this behavior has already been noticed [ 17,28,29], and\nall the cited works used the mean as primary aggregation function.\nTo validate the external agreement, we measured the statis-\ntical significance between the aggregated rating for all the six\nPolitiFact categories; we considered both the Mann-Whitney\nrank test and the t-test, applying Bonferroni correction to account\nfor multiple comparisons. Results are as follows: when considering\nadjacent categories (e.g., pants-on-fire andfalse ), the difference\nbetween categories are never significant, for both tests and for all\nthe three aggregation functions. When considering categories of dis-\ntance 2 (e.g., pants-on-fire andmostly-false ), the differences\nare never significant, apart from the median aggregation function,\nwhere there is statistical significance to the p< .05level in 2/4\ncases for both Mann-Whitney and t-test. When considering cate-\ngories of distance 3, the differences are significant, for the mean, in\n3/3cases for the Mann-Whitney and 3/3cases for the t-test, for the\nmedian, in 2/3cases for the Mann-Whitney and 3/3cases for the\nt-test, for the majority vote, in 0/3cases for the Mann-Whitney and\npants-on-fire false mostly-false half-true mostly-true true\u22120.10.00.10.20.30.4agreement\nOverall  \u03b1\nOverall  \u03a6 \u03b1  \u03a6\n0.0 0.2 0.4 0.6 0.8 1.0\nPairwise Agreement0.000.250.500.751.00Freq.\nC6Figure 3: Workers agreement: \u03b1[16] and \u03a6[5] (top plot); pair-\nwise unit agreement (bottom plot).\n1/3cases for the t-test. When considering categories of distance 4\nand 5, the differences are always significant to the p>0.01level\nfor all the aggregation functions and for all the tests, apart from\nthe case of the majority vote function and the Mann-Whitney test,\nwhere the significance is at the p> .05level. In the following we\nuse the mean as being the most commonly used approach for this\ntype of data [29].\n5.2.2 Internal Agreement. Another standard way to address RQ1\nand to analyze the quality of the work by the crowd is to compute\nthe so called internal agreement (i.e., the agreement among the\nworkers). Figure 3 shows in the first plot the agreement measured\nwith \u03b1[16] and\u03a6[5], two popular measures often used to compute\nworkers\u2019 agreement in crowdsourcing tasks [ 18,27\u201329]. The x-axis\ndetails the PolitiFact categories, while the y-axis the level of\nagreement measured; while \u03b1is a punctual measure, \u03a6allows to\ncompute confidence intervals for the agreement measure; the plot\nshows the upper 97% and lower 3% confidence intervals as thinner\nlines. As we can see from the plot, the agreement levels measured\nwith the two scales is very similar for the pants-on-fire ,false ,\nmostly-false , and half-true categories: note that the \u03b1measure\nalways falls in the \u03a6confidence interval, and the little oscillations\nin the agreement value are not always indication of a real change in\nthe agreement level, especially when considering \u03b1[5]. Having said\nso, it appears that for all the two metrics the overall agreement falls\nin the[0.15,0.3]range, and the agreement level is similar for all\nthePolitiFact categories, with the exception of \u03a6, which shows\nhigher agreement levels for the mostly-true andtrue categories.\nThis confirms the finding, derived from Figure 2, that workers\nseem most effective in identifying and categorizing statements with\na higher truthfulness level. This remark is also supported by [ 5]\nwhich shows that \u03a6is better in distinguishing agreement levels\nin crowdsourcing than \u03b1, which is more indicated as a measure of\ndata reliability in non crowdsourced settings.\nFigure 3 also shows in the second plot a measure of the agreement\nat the HIT level (i.e., in the set of 8 statements judged by each\nworker) as detailed in [ 18,29]. More in detail, the plot shows the\nCCDF (Complementary Cumulative Distribution Function) of the\nrelative frequencies for the agreement of the 100 HITs considered\nin this experiment. The plot shows that around 20% of the hits\nhave a pairwise agreement which is very close to 1; this indicates\nthat around 20% of the workers judged statements almost in the\nsame way as the expert judges. Moreover, we see that 60% of the\nworkers have a pairwise agreement greater than 0.5. Again, this\nresult indicates a good overall agreement between crowd and expert\njudgments, confirming that the crowd is able to correctly identify\nand classify misinformation related to the COVID-19 pandemic.\n5.3 RQ2: Transforming Truthfulness Scales\nGiven the positive results presented above, it appears that the an-\nswer to RQ1 is overall positive, even if with some exceptions. There\nare many remarks that can be made: first, there is a clear issue that\naffects the pants-on-fire andfalse categories, which are very\noften mis-classified by workers. Moreover, while PolitiFact used\na six-level judgment scale, the usage of a two- (e.g., True/False) and\na three-level (e.g., False / In between / True) scale is also common\nwhen assessing the truthfulness of statements [ 17,29]. Finally, cat-\negories can be merged together to improve accuracy, as done for\nexample by Tchechmedjiev et al . [30] . All these considerations lead\nus to RQ2, addressed in the following.\n5.3.1 Merging Ground Truth Levels. For all the above reasons, we\nperformed the following experiment: we group together the six\nPolitiFact categories (i.e., E 6) into three (referred to as E 3) or two\n(E2) categories, which we refer respectively with 01,23, and 45for\nthe three level scale, and 012and234for the two level scale.\nFigure 4 shows the result of such a process. As we can see from\nthe plots, the agreement between the crowd and the expert judg-\nments can be seen in a more neat way. As for Figure 2, the median\nvalues for all the boxplots is increasing when going towards higher\ntruthfulness values (i.e., going from left to right within each plot);\nthis holds for all the aggregation functions considered, and it is\nvalid for both transformations of the E 6scale, into two and three\nlevels. Also in this case we computed the statistical significance\nbetween categories, applying the Bonferroni correction to account\nfor multiple comparisons. Results are as follows. For the case of\nthree groups, both the categories at distance one and two are always\nsignificant to the p<0.01level, for both the Mann-Whitney and\nthe t-test, for all three aggregation functions. The same behavior\nholds for the case of two groups, where the categories of distance 1\nare always significant to the p<0.01level.\n012345\nE012345C\n012345\nE012345C\n012345\nE012345C\n012 345\nE012345C\n012 345\nE012345C\n012 345\nE012345C\nFigure 4: The agreement between the PolitiFact experts\nand the crowd judgments. From left to right: C 6aggregated\nwith mean; C 6aggregated with median; C 6aggregated with\nmajority vote. First row: E 6to E 3; second row: E 6to E 2. Com-\npare with Figure 2.\nSummarizing, we can now conclude that by merging the ground\ntruth levels we obtained a much stronger signal: the crowd can\neffectively detect and classify misinformation statements related to\nthe COVID-19 pandemic.\n5.3.2 Merging Crowd Levels. Having reported the results on merg-\ning the ground truth categories we now turn to transform the crowd\nlabels (i.e., C 6) into three (referred to as C 3) and two (C 2) categories.\nFor the transformation process we rely on the approach detailed by\nHan et al . [14] , that also present a complete and exhaustive discus-\nsion on the effectiveness of the scale transformation methods. This\napproach has many advantages [ 14]: we can simulate the effect of\nhaving the crowd answers in a more coarse-grained scale (rather\nthan C 6), and thus we can simulate new data without running the\nwhole experiment on MTurk again. As we did for the ground truth\nscale, we choose to select as target scales the two- and three- levels\nscale, driven by the same motivations. Having selected C 6as being\nthe source scale, and having selected the target scales as the three-\nand two- level ones (C 3and C 2), we perform the following experi-\nment. We perform all the possible cuts11from C 6to C 3and from\nC6to C 2; then, we measure the internal agreement (using \u03b1and\u03a6)\nboth on the source and on the target scale, and we compare those\nvalues. In such a way, we are able to identify, among all the possible\ncuts, the cut which leads to the highest possible internal agreement.\nAlso in this case, a detailed discussion on the relationships between\ninternal agreement, effectiveness, and all the possible cuts can be\nfound in Han et al. [14].\nFigure 5 shows the results. The x-axis shows the cut performed\nto transform C 6into the target scale (C 3in the left-most plot, C 2in\nthe right-most plot), while the y-axis shows the internal agreement\nscore by means of either \u03b1or\u03a6. As we can see by inspecting the\nleft-most plot, (i.e., C 6to C 3) we can see that there is, both for \u03b1\n11C6can be transformed into C 3in 10 different ways, and C 6can be transformed into\nC2in 5 different ways.\n[[0], [1], [2, 3, 4, 5]]\n[[0], [1, 2], [3, 4, 5]]\n[[0], [1, 2, 3], [4, 5]]\n[[0], [1, 2, 3, 4], [5]]\n[[0, 1], [2], [3, 4, 5]]\n[[0, 1], [2, 3], [4, 5]]\n[[0, 1], [2, 3, 4], [5]]\n[[0, 1, 2], [3], [4, 5]]\n[[0, 1, 2], [3, 4], [5]]\n[[0, 1, 2, 3], [4], [5]]\ncut\u22120.3\u22120.2\u22120.10.00.10.20.3\u03b1/\u03a6\n\u03b1\n\u03a6\n[[0], [1, 2, 3, 4, 5]]\n[[0, 1], [2, 3, 4, 5]]\n[[0, 1, 2], [3, 4, 5]]\n[[0, 1, 2, 3], [4, 5]]\n[[0, 1, 2, 3, 4], [5]]\ncut\u22120.4\u22120.3\u22120.2\u22120.10.00.10.20.3\u03b1/\u03a6\n\u03b1\n\u03a6Figure 5: \u03b1and\u03a6cuts. From left to right: C 6cut into three\nlevels (C 3), C 6cut into two levels (C 2). The cut is detailed in\nthe x-label. The dotted line is \u03b1/\u03a6on C 6, the continuous\nline is the average \u03b1/\u03a6score measured among all the cuts.\n012345\nE0.00.51.01.52.0C\n012345\nE0.00.51.01.52.0C\n012345\nE0.00.20.40.60.81.0C\n012345\nE0.00.20.40.60.81.0C\nFigure 6: Comparison with E 6. C 6to C 3(first row) and to\nC2(second row), then aggregated with the mean function.\nBest cut selected according to \u03b1(left column) and \u03a6(right\ncolumn) (see Figure 5). Compare with Figure 2.\nand\u03a6, a single cut which leads to higher agreement levels with\nthe original C 6scale. On the contrary, if we focus on the rightmost\nplot (i.e., C 6to C 2), we can see that there is a single cut for \u03b1which\nleads to similar agreement levels as in the original C 6scale, and\nthere are no cuts with such a property when using \u03a6.\nHaving identified the best possible cuts for both transformations\nand for both agreement metrics, we now measure the external\nagreement between the crowd and the expert judgments, using\nthe selected cut. Figure 6 shows such a result when considering\nthe judgments aggregated with the mean function. As we can see\nfrom the plots, it is again the case that the median values of the\nboxplots is always increasing, for all the transformations. Never-\ntheless, inspecting the plots we can state that the overall external\nagreement appears to be lower than the one shown in Figure 2.\nMoreover, we can also state that also in the case of the transformed\nscales, the categories pants-on-fire andfalse are still not sep-\narable. Summarizing, we show that it is feasible to transform the\n01 23 45\nE0.00.51.01.52.0C\n01 23 45\nE0.00.51.01.52.0C\n012 345\nE0.00.20.40.60.81.0C\n012 345\nE0.00.20.40.60.81.0C\nFigure 7: C 6to C 3(first row) and to C 2(second row), then ag-\ngregated with the mean function. First row: E 6to E 3. Second\nrow: E 6to E 2. Best cut selected according to \u03b1(left column)\nand\u03a6(right column) (see Figure 5). Compare with Figures 2,\n4, and 6.\njudgments collected on a C 6level scale into two new scales, C 3and\nC2, obtaining judgments with a similar internal agreement as the\noriginal ones, and with a slightly lower external agreement with\nthe expert judgments.\n5.3.3 Merging both Ground Truth and Crowd Levels. It is now natu-\nral to combine the two approaches. Figure 7 shows the comparison\nbetween C 6transformed into C 3and C 2, and E 6transformed into\nE3and E 2. As we can see form the plots, also in this case the me-\ndian values of the boxplots are increasing, especially for the E 3case\n(shown in the first row). Furthermore, the external agreement with\nthe ground truth is present, even if for the E 2case (shown in the\nsecond row) the classes appear to be not separable. Summarizing,\nall these results show that it is feasible to successfully combine\nthe aforementioned approaches, and transform into a three- and\ntwo-level scale both the crowd and the expert judgments.\n5.4 RQ3: Worker Background and Bias\nTo address RQ3 we study if the answers to questionnaire and CRT\ntest have any relation to worker quality.\n5.4.1 Questionnaire. Table 2 (top) shows in the rows the answer\nto the workers political views, while on the columns the number of\ncorrectly classified statements (columns, max is 6). As we can see\nfrom the table, there is only one worker who successfully classified\nall 6 statements. Many workers correctly classified 1 or 2 statements\n(28 and 28, respectively). The next column summarizes, using Accu-\nracy (i.e., the fraction of exactly classified statements), the quality of\nworkers in each group. The number and fraction of correctly classi-\nfied statements are however rather crude measures of worker\u2019s qual-\nity, as small misclassification errors (e.g, pants-on-fire in place of\nfalse ) are as important as more striking ones (e.g., pants-on-fire\nin place of true ). Therefore, to measure the ability of workers to\nTable 2: Count of the number of workers depending on:\nnumber of statements correctly classified (columns, max is\n6), vs. (top table) the answers to the Political views question\n(rows) and vs. (bottom table) the number of correct answers\nto the CRT test (rows, max is 3). The last two columns show\nthe Accuracy (the fraction of correctly identified statements\nfor each group) and the CEMORDscore.\nCorrectly classified statements Acc CEMORD\n0 1 2 3 4 5 6 Sum Mean\nVery conservative 4 3 1 0 0 0 1 9 .13 .46\nConservative 0 9 2 3 1 0 0 15 .21 .51\nModerate 6 6 6 7 0 1 0 26 .20 .50\nLiberal 2 8 13 4 4 2 0 33 .16 .50\nVery Liberal 0 2 6 6 2 1 0 17 .21 .51\nSum 12 28 28 20 7 4 1 100\nCorrectly classified statements Acc CEMORD\n0 1 2 3 4 5 6 Sum Mean\nCRT 0 5 11 9 4 0 1 1 31 .14 .48\ncorrect 1 5 10 12 6 1 0 0 34 .22 .53\nanswers 2 1 6 1 6 3 1 0 18 .21 .51\n3 1 1 6 4 3 2 0 17 .15 .47\nSum 12 28 28 20 7 4 1 100\ncorrectly classify the statements, we also compute CEMORD, an effec-\ntiveness metric recently proposed for the specific case of ordinal\nclassification [ 1] (see Roitero et al . [29, \u00a73.3 ]for a more detailed\ndiscussion of these issues). The last column in the table shows the\naverage CEMORDvalue for the workers in each group. By looking\nat both Accuracy and CEMORD, it is clear that \u2018Very conservative\u2019\nworkers provide lower quality labels. The Bonferroni corrected two\ntailed t-test on CEMORDconfirms that \u2018Very conservative\u2019 workers\nperform statistically significantly worse than both \u2018Conservative\u2019\nand \u2018Very liberal\u2019 workers. The workers\u2019 political views affect the\nCEMORDscore, even if in a small way and mainly when considering\nthe extremes of the scale. An initial analysis of the other answers\nto the questionnaire (not shown due to space limitations) does not\nseem to provide strong signals; a more detailed analysis is left for\nfuture work.\n5.4.2 CRT Test. We now investigate the effect of the CRT test on\nthe worker quality. Table 2 (bottom) shows the count of the number\nof workers depending on: number of statements correctly classified\n(columns, max is 6), versus the number of correct answers to the\nCRT test (rows, max is 3). Concerning CRT scores, we see that the\nminority of workers (17) answered in a correct way to all the three\nquestions, and the majority of them answered correctly to only 1\nCRT question (34) or none (31). Although there is some variation in\nboth Accuracy and CEMORD, this is never statistically significant; it\nappears that the number of correct answers to the CRT test is not\ncorrelated with worker quality. We leave for future work a more\ndetailed study of this aspect.\n5.5 RQ4: Worker Behavior\nWe now turn to RQ4, and analyze the behavior of the workers while\nperforming the task.\n1 2 3 4 5 6 7 8\nstatement index150200250300350time elapsed (sec)\n012345\nE012345C\nFigure 8: Position of the statement in the task vs. time\nelapsed, cumulative on each single statement (left). Compar-\nison between E 6and C 6where the aggregation function is\nthe weighted mean and the weights are the political views\n(see Table 2 top) normalized to [0.5,1](right).\n5.5.1 Time. Figure 8 (left) shows that the amount of time spent\non average by the workers on the first statements is considerably\nhigher than on the last statements. This, combined with the fact\nthat the quality of the assessment provided by the workers does\nnot decrease for the last statements ( CEMORDscores per position are\n1: .61, 2: .60, 3: .64, 4: .58, 5: .59, 6: .54, 7: .61, 8: .62), is an indication\nof a learning effect: the workers learn how to assess truthfulness in\na faster way.\n5.5.2 Exploiting Worker Signals to Improve Quality. We have shown\nthat, while performing their task, workers provide many signals\nthat to some extent correlate with the quality of their work. These\nsignals could in principle be exploited to aggregate the individual\njudgments in a more effective way (i.e., giving more weight to work-\ners that possess features indicating a higher quality). For example,\nthe relationships between worker background / bias and worker\nquality (Section 5.4) could be exploited to this aim.\nWe thus performed the following experiment: we aggregated\nC6individual scores, using as aggregation function a weighted\nmean, where the weights are represented by the political views,\nnormalized to[0.5,1]. Figure 8 (right) shows the results. We also\naggregated C 6individual scores using as aggregation function the\nweighted mean function where the weights are represented by the\nnumber of correct answers to CRT, normalized to [0.5,1], which\nlead to similar results. Thus, it seems that leveraging quality-related\nbehavioral signals, like questionnaire answers or CRT scores, to\naggregate results does not provide a noticeable increase in the exter-\nnal agreement, although it does not harm. We have only scratched\nthe surface, though, as there are many other signals, and aggrega-\ntion functions, that can be tried; we leave for future work the in\ndepth analysis of how such behavioral signals can be leveraged to\nimprove external agreement.\n5.5.3 Queries. Table 3 shows query statistics for the 100 workers\nwhich finished the task. As we can see, the higher the statement\nposition, the lower the number of queries issued: 3.52 queries on\naverage for the first statement, down to 2.3 for the last statement.\nThis can indicate the attitude of workers to issue fewer queries the\nmore time they spend on the task, probably due to fatigue, boredom,\nor learning effects. Nevertheless, we can see that on average, for all\nthe statement positions each worker issues more than one query,\ni.e., workers often reformulate their initial query. This provides\nfurther evidence that they put effort in performing the task. The\nTable 3: Statement position in the task versus: number of\nqueries issued (top) and number of times the statement has\nbeen used as a query (bottom).\nStatement\nPosition1 2 3 4 5 6 7 8 Sum Mean\nNumber\nof Queries352\n16.8%280\n13.4%259\n12.4%255\n12.1%242\n11.6%238\n11.3%230\n11.0%230\n11.4%2095 261.9\nStatement\nas Query22\n9%32\n13%31\n12.6%33\n13.5%34\n13.9%30\n12.2%29\n11.9%34\n13.9%245 30.6\n0.0 0.1 0.2 0.3 0.4\nfrequency1\n2\n3\n4\n5\n6\n7\n8\n9\n10rank\nURL Percentage %\nsnopes.com 11.79%\nmsn.com 8.93%\nfactcheck.org 6.79%\nwral.com 6.79%\nusatoday.com 5.36%\nstatesman.com 4.64%\nreuters.com 4.64%\ncdc.gov 4.29%\nmediabiasfactcheck.com 4.29%\nbusinessinsider.com 3.93%\nFigure 9: On the left, distribution of the ranks of the URLs\nselected by workers, on the right, websites from which work-\ners chose URLs to justify their judgments.\nthird row of the table shows the number of times the worker used\nas query the whole statement. We can see that the percentage is\nrather low (around 13%) for all the statement positions, indicating\nagain that workers spend effort when providing their judgments.\n5.6 RQ5: Sources of Information\n5.6.1 URL Analysis. Figure 9 shows on the left the distribution\nof the ranks of the URL selected as evidence by the worker when\nperforming each judgment. URLs selected less than 1% times are\nfiltered out from the results. As we can see from the plot, about 40%\nof workers selected the first result retrieved by our search engine,\nand selected the remaining positions less frequent, with an almost\nmonotonic decreasing frequency (rank 8 makes the exception).\nWe also found that 14% of workers inspected up to the fourth\npage of results (i.e., rank =40). The breakdown on the truthfulness\nPolitiFact categories does not show any significant difference.\nFigure 9 shows on the right part the top 10 of websites from\nwhich the workers choose the URL to justify their judgments. Web-\nsites with percentage \u22643.9%are filtered out. As we can see from\nthe table, there are many fact check websites among the top 10\nURLs (e.g., snopes: 11.79%, factcheck 6.79%). Furthermore, medical\nwebsites are present, although in small percentage (cdc: 4.29%). This\nindicates that workers use various kind of sources as URLs from\nwhich they take information. Thus, it appears that they put effort\nin finding evidence to provide a reliable truthfulness judgment.\n5.6.2 Justifications. As a final result, we analyze the textual justifi-\ncations provided, their relations with the web pages at the selected\nURLs, and their links with worker quality. 54% of the provided\njustifications contain text copied from the web page at the URL\nselected for evidence, while 46% do not. Furthermore, 48% of the\n0 1 2 3 4 5\nJudgment absolute error0.00.10.20.30.40.5Percentage\ncopied\nno copied\n0.00.20.40.60.81.0\nCumulative\n-5 -4 -3 -2 -1 0 1 2 3 4 5\nJudgment error0.00.10.20.30.4Percentage\ncopied\nno copiedFigure 10: Effect of the origin of a justification (text\ncopied/not copied from the URL selected) on: the absolute\nvalue of the prediction error (left; cumulative distributions\nshown with thinner lines and empty markers), and the pre-\ndiction error (right).\njustification include some \u201cfree text\u201d (i.e., text generated and writ-\nten by the worker), and 52% do not. Considering all the possible\ncombinations, 6% of the justifications used both free text and text\nfrom web page, 42% used free text but no text from the web page,\n48% used no free text but only text from web page, and finally 4%\nused neither free text nor text from web page, and either inserted\ntext from a page of a different (not selected) web page or inserted\npart of the instructions we provided or text from the user interface.\nConcerning the preferred way to provide justifications, each\nworker seems to have a clear attitude: 48% of the workers used only\ntext copied from the selected web pages, 46% of the workers used\nonly free text, 4% used both, and 2% of them consistently provided\ntext coming from the user interface or random web pages.\nWe now correlate such a behavior with the workers quality. Fig-\nure 10 shows the relations between different kinds of justifications\nand the worker accuracy. The plots show the absolute value of the\nprediction error on the left, and the prediction error on the right.\nThe lines in the plots indicate if the text inserted by the worker\nwas copied or not from the web page selected. We did the same\nanalysis to investigate if the worker used or not free text, and the\nplots where almost indistinguishable.\nAs we can see from the plot , statements on which workers make\nless errors (i.e., where x-axis =0) tend to use text copied from the\nweb page selected. On the contrary, statements on which workers\nmake more errors (values close to 5 in the left plot, and values\nclose to +/- 5 in the right plot) tend to use text not copied from\nthe selected web page. The differences are small, but it might be\nan indication that workers of higher quality tend to read the text\nfrom selected web page, and report it in the justification box. To\nconfirm this result, we computed the CEMORDscores for the two\nclasses considering the individual judgments: the class \u201ccopied\u201d has\nCEMORD=0.62, while the class \u201cnot copied\u201d has a lower value, CEMORD\n=0.58. The behavior is consistent for what concerns the usage of\nfree text (not shown).\nBy looking at the right column of Figure 10 we can see that\nthe distribution of the prediction error is not symmetrical, as the\nfrequency of the errors is higher on the positive side of the x-\naxis ([0,5]). These errors correspond to workers overestimating\nthe truthfulness value of the statement (with 5 being the result of\nlabeling a pants-on-fire statement as true ). This is consistent\nwith what observed in Sect. 5.1.2. It is also noticeable that the\njustifications containing text copied from the selected URL have a\nlower rate of errors in the negative range, meaning that workers\nwhich directly quote the text avoid underestimating the truthfulness\nof the statement. These could be other useful signals to be exploited\nin future work to obtain more effective aggregation methods.\n6 CONCLUSIONS AND FUTURE WORK\nThe work presented in this paper is, to the best of our knowledge,\nthe first one investigating the ability of crowd workers to identify\nand correctly categorize recent health statements related to the\nCOVID-19 pandemic. The workers performed a task consisting\nof judging the truthfulness of 8 statements using our customized\nsearch engine, which allows us to control worker behavior. We\nanalyze workers background and bias, as well as workers cognitive\nabilities, and we correlate such information to the worker quality.\nWe publicly release the collected data to the research community.\nThe answers to our research questions can be summarized as\nfollows. We found evidence that the workers are able to detect\nand objectively categorize online (mis)information related to the\nCOVID-19 pandemic (RQ1). We found that while the agreement\namong workers does not provide a strong signal, aggregated work-\ners judgments show high levels of agreement with the expert labels,\nwith the only exception of the two truthfulness categories at the\nlower end of the scale ( pants-on-fire andfalse ). We found that\nboth crowdsourced and expert judgments can be transformed and\naggregated to improve label quality (RQ2). We found that worker\npolitical background, self-reported in a questionnaire, is indicative\nof label quality (RQ3). We found several promising behavioral sig-\nnals that are clearly related with worker quality (RQ4). Such signals\nmay effectively inform new ways of aggregating crowd judgments\n(e.g., see [ 3,25]), which we believe is a promising direction for\nfuture work. Finally, we found that workers use multiple sources\nof information, and they consider both fact-checking and health-\nrelated websites. We also found interesting relations between the\njustifications provided by the workers and the judgment quality\n(RQ5). Future work also includes reproducing our experiments in\nother crowdsourcing platforms to target other cohorts of workers.\nACKNOWLEDGMENTS\nThis work is partially supported by a Facebook Research award, by\nan Australian Research Council Discovery Project (DP190102141),\nand by the project HEaD \u00e2\u0102\u015e Higher Education and Development -\n1619942002 / 1420AFPLO1 (Region Friuli \u00e2\u0102\u015e Venezia Giulia).\nREFERENCES\n[1]Enrique Amig\u00f3, Julio Gonzalo, Stefano Mizzaro, and Jorge Carrillo-de-Albornoz.\n2020. An Effectiveness Metric for Ordinal Classification: Formal Properties and\nExperimental Results. In Proceedings of ACL . 3938\u20133949.\n[2]Pepa Atanasova, Preslav Nakov, Llu\u00eds M\u00e0rquez, Alberto Barr\u00f3n-Cede\u00f1o, Georgi\nKaradzhov, Tsvetomila Mihaylova, Mitra Mohtarami, and James Glass. 2019.\nAutomatic Fact-Checking Using Context and Discourse Information. J. Data and\nInformation Quality 11, 3, Article 12 (2019), 27 pages.\n[3]Yukino Baba and Hisashi Kashima. 2013. Statistical Quality Estimation for General\nCrowdsourcing Tasks. In Proceedings of KDD . 554\u2013562.\n[4]Joseph Bullock, Alexandra Luccioni, Katherine Hoffmann Pham, Cynthia Sin Nga\nLam, and Miguel Luengo-Oroz. 2020. Mapping the Landscape of Artificial Intelli-\ngence Applications against COVID-19. arXiv:2003.11336\n[5]Alessandro Checco, Kevin Roitero, Eddy Maddalena, Stefano Mizzaro, and Gian-\nluca Demartini. 2017. Let\u2019s Agree to Disagree: Fixing Agreement Measures for\nCrowdsourcing. In Proceedings of HCOMP . 11\u201320.[6]Xinran Chen, Sei-Ching Joanna Sin, Yin-Leng Theng, and Chei Sian Lee. 2015.\nWhy Students Share Misinformation on Social Media: Motivation, Gender, and\nStudy-level Differences. Journal of Academic Librarianship 41, 5 (2015), 583\u2013592.\n[7]Matteo Cinelli, Walter Quattrociocchi, Alessandro Galeazzi, Carlo Michele Valen-\nsise, Emanuele Brugnoli, Ana Lucia Schmidt, Paola Zola, Fabiana Zollo, and\nAntonio Scala. 2020. The COVID-19 Social Media Infodemic. arXiv:2003.05004\n[8]Aakash Desai, Jeremy Warner, Nicole Kuderer, Mike Thompson, Corrie Painter,\nGary Lyman, and Gilberto Lopes. 2020. Crowdsourcing a Crisis Response for\nCOVID-19 in Oncology. Nature Cancer 1, 5 (2020), 473\u2013476.\n[9]Tamer Elsayed, Preslav Nakov, Alberto Barr\u00f3n-Cede\u00f1o, Maram Hasanain, Reem\nSuwaileh, Giovanni Da San Martino, and Pepa Atanasova. 2019. Overview of the\nCLEF-2019 CheckThat! Lab: Automatic Identification and Verification of Claims.\nInProceedings of CLEF . 301\u2013321.\n[10] Shane Frederick. 2005. Cognitive Reflection and Decision Making. Journal of\nEconomic Perspectives 19, 4 (December 2005), 25\u201342.\n[11] Riccardo Gallotti, Francesco Valle, Nicola Castaldo, Pierluigi Sacco, and Manlio De\nDomenico. 2020. Assessing the Risks of \u201cInfodemics\u201d in Response to COVID-19\nEpidemics. arXiv:2004.03997\n[12] Lei Han, Kevin Roitero, Ujwal Gadiraju, Cristina Sarasua, Alessandro Checco,\nEddy Maddalena, and Gianluca Demartini. 2019. All those wasted hours: On task\nabandonment in crowdsourcing. In Proceedings of WSDM . 321\u2013329.\n[13] Lei Han, Kevin Roitero, Ujwal Gadiraju, Cristina Sarasua, Alessandro Checco,\nEddy Maddalena, and Gianluca Demartini. 2019. The Impact of Task Abandon-\nment in Crowdsourcing. IEEE TKDE (2019), 1\u20131.\n[14] Lei Han, Kevin Roitero, Eddy Maddalena, Stefano Mizzaro, and Gianluca Demar-\ntini. 2019. On Transforming Relevance Scales. In Proceedings of CIKM . 39\u201348.\n[15] Jooyeon Kim, Dongkwan Kim, and Alice Oh. 2019. Homogeneity-Based Trans-\nmissive Process to Model True and False News in Social Networks. In Proceedings\nof WSDM . 348\u2013356.\n[16] Klaus Krippendorff. 2011. Computing Krippendorff\u2019s Alpha-Reliability. (2011).\n[17] David La Barbera, Kevin Roitero, Damiano Spina, Stefano Mizzaro, and Gianluca\nDemartini. 2020. Crowdsourcing Truthfulness: The Impact of Judgment Scale\nand Assessor Bias. In Proceedings of ECIR . 207\u2013214.\n[18] Eddy Maddalena, Kevin Roitero, Gianluca Demartini, and Stefano Mizzaro. 2017.\nConsidering Assessor Agreement in IR Evaluation. In Proceedings of ICTIR . 75\u201382.\n[19] Yelena Mejova and Kyriaki Kalimeri. 2020. Advertisers Jump on Coronavirus\nBandwagon: Politics, News, and Business. arXiv:2003.00923\n[20] Tsvetomila Mihaylova, Georgi Karadjov, Pepa Atanasova, Ramy Baly, Mitra\nMohtarami, and Preslav Nakov. 2019. SemEval-2019 Task 8: Fact Checking in\nCommunity Question Answering Forums. In Proceedings of SemEval . 860\u2013869.\n[21] Howard R Moskowitz. 1977. Magnitude Estimation: Notes on What, How, When,\nand Why to Use It. Journal of Food Quality 1, 3 (1977), 195\u2013227.\n[22] Preslav Nakov, Alberto Barr\u00f3n-Cede\u00f1o, Tamer Elsayed, Reem Suwaileh, Llu\u00eds\nM\u00e0rquez, Wajdi Zaghouani, Pepa Atanasova, Spas Kyuchukov, and G Da San Mar-\ntino. 2018. Overview of the CLEF-2018 CheckThat! Lab on Automatic Identifica-\ntion and Verification of Political Claims. In Proceedings of CLEF . 372\u2013387.\n[23] Gordon Pennycook, Jonathon McPhetres, Yunhao Zhang, and David Rand. 2020.\nFighting COVID-19 Misinformation on Social Media: Experimental Evidence for\na Scalable Accuracy Nudge Intervention. PsyArXiv (2020). psyarxiv.com/uhbk9\n[24] Kashyap Kiritbhai Popat. 2019. Credibility Analysis of Textual Claims with Ex-\nplainable Evidence . Ph.D. Dissertation. Saarland University, Saarbr\u00fccken.\n[25] Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, Gerardo Hermosillo Valadez, Charles\nFlorin, Luca Bogoni, and Linda Moy. 2010. Learning From Crowds. Journal of\nMachine Learning Research 11, 43 (2010), 1297\u20131322.\n[26] Kirk Roberts, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman, Kyle Lo,\nIan Soboroff, Ellen Voorhees, Lucy Lu Wang, and William R Hersh. 2020. TREC-\nCOVID: Rationale and Structure of an Information Retrieval Shared Task for\nCOVID-19. Journal of the American Medical Informatics Association (2020).\n[27] Kevin Roitero, Gianluca Demartini, Stefano Mizzaro, and Damiano Spina. 2018.\nHow Many Truth Levels? Six? One Hundred? Even More? Validating Truthful-\nness of Statements via Crowdsourcing. In Proceedings of the CIKM Workshop on\nRumours and Deception in Social Media (RDSM\u201918) .\n[28] Kevin Roitero, Eddy Maddalena, Gianluca Demartini, and Stefano Mizzaro. 2018.\nOn Fine-Grained Relevance Scales. In Proceedings of SIGIR . 675\u2013684.\n[29] Kevin Roitero, Michael Soprano, Shaoyang Fan, Damiano Spina, Stefano Mizzaro,\nand Gianluca Demartini. 2020. Can The Crowd Identify Misinformation Objec-\ntively? The Effects of Judgment Scale and Assessor\u2019s Background. In Proceedings\nof SIGIR . 439\u2013448.\n[30] Andon Tchechmedjiev, Pavlos Fafalios, Katarina Boland, Malo Gasquet, Matth\u00e4us\nZloch, Benjamin Zapilko, Stefan Dietze, and Konstantin Todorov. 2019. ClaimsKG:\nA Knowledge Graph of Fact-Checked Claims. In Proceedings of ISWC . 309\u2013324.\n[31] William Yang Wang. 2017. \u201cLiar, Liar Pants on Fire\u201d: A New Benchmark Dataset\nfor Fake News Detection. In Proceedings of ACL . 422\u2013426.\n[32] Kai-Cheng Yang, Christopher Torres-Lugo, and Filippo Menczer. 2020. Prevalence\nof Low-Credibility Information on Twitter During the COVID-19 Outbreak.\narXiv:2004.14484\n[33] Arkaitz Zubiaga and Heng Ji. 2014. Tweet, but Verify: Epistemic Study of Infor-\nmation Verification on Twitter. SNAM 4, 1 (2014), 1\u201312.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The covid-19 infodemic: Can the crowd judge recent misinformation objectively?", "author": ["K Roitero", "M Soprano", "B Portelli", "D Spina"], "pub_year": "2020", "venue": "Proceedings of the 29th \u2026", "abstract": "Misinformation is an ever increasing problem that is difficult to solve for the research community  and has a negative impact on the society at large. Very recently, the problem has been"}, "filled": false, "gsrank": 386, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3340531.3412048", "author_id": ["1xd52jMAAAAJ", "ocK0qRUAAAAJ", "HQZd6wsAAAAJ", "sLzYrNYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:UU28XknhprMJ:scholar.google.com/&output=cite&scirp=385&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=UU28XknhprMJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 59, "citedby_url": "/scholar?cites=12945281884161330513&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:UU28XknhprMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2008.05701"}}, {"title": "LOCO: The 88-million-word language of conspiracy corpus", "year": "2022", "pdf_data": "LOCO: The 88-million-word language of conspiracy corpus\nAlessandro Miani1&Thomas Hills2,3&Adrian Bangerter1\nAccepted: 26 August 2021 /Published online: 25 October 2021\nAbstract\nThe spread of online conspiracy theories represents a serious threat to society. To understand the content of conspiracies, here we\npresent the language of conspiracy (LOCO) corpus. LOCO is an 88-million-token corpus composed of topic-matched conspiracy\n(N= 23,937) and mainstream ( N= 72,806) documents harvested from 150 websites. Mimicking internet user behavior,\ndocuments were identified using Google by crossing a set of seed phrases with a set of websites. LOCO is hierarchically\nstructured, meaning that each document is cross-nested within websites ( N= 150) and topics ( N= 600, on three different\nresolutions). A rich set of linguistic features ( N= 287) and metadata includes upload date, measures of social media engagement,\nmeasures of website popularity, size, and traffic, as well as political bias and factual reporting annotations. We explored LOCO \u2019s\nfeatures from different perspectives showing that documents track important societal events through time (e.g., Princess Diana \u2019s\ndeath, Sandy Hook school shooting, coronavirus outbreaks), while patterns of lexical features (e.g., deception, power, domi-\nnance) overlap with those extracted from online social media communities dedicated to conspiracy theories. By computing\nwithin-subcorpus cosine similarity, we derived a subset of the most representative conspiracy documents ( N= 4,227), which,\ncompared to other conspiracy documents, display prototypical and exaggerated conspiratorial language and are more frequently\nshared on Facebook. We also show that conspiracy website users navigate to websites via more direct means than mainstream\nusers, suggesting confirmation bias. LOCO and related datasets are freely available at https://osf.io/snpcg/ .\nKeywords \u25a0\u25a0\u25a0\nIntroduction\nConspiracy theories (CTs) are narratives that attempt to ex-\nplain significant social events as being secretly plotted by\npowerful and malicious elites at the expense of an unwitting\npopulation (Douglas et al., 2019 ; Samory & Mitra, 2018b ).\nBelief in CTs is widespread. In 2013, it was estimated that\nover 50% of the US population believed in at least one CT\n(Oliver & Wood, 2014 ), while in 2020, in the middle of the\nCOVID-19 pandemic, health-related misinformation attracted\nfour times as much traffic as official health sources on socialmedia (AVAAZ, 2020 ). The consequences associated with\nthe circulation of such theories are not trivial, potentially lead-\ning to detrimental social action (Franks et al., 2013 ;I m h o f f\net al., 2021 ; Sternisko et al., 2020 ). Belief in CTs is linked to\nrejection of official information and science (Raab, Auer,\net al., 2013a ; Raab, Ortlieb, et al., 2013b ; van der Linden,\n2015 ), decreased intentions to adopt vaccines (Jolley &\nDouglas, 2014b ; Lazarus et al., 2020 ;S a l m o ne ta l . , 2005 ),\nresistance to COVID-19 containment measures and vaccina-\ntion (Biddlestone et al., 2020 ; Lazarus et al., 2020 ), and re-\nduced protection against sexually transmitted diseases (Bogart\net al., 2010 ). CT belief is also related to general distrust and\npolitical alienation along with endorsement of nonnormative\n(vs. normative) political intentions (Einstein & Glick, 2015 ;\nImhoff et al., 2021 ;J o l l e y&D o u g l a s , 2014a ). Such beliefs\nalso provide justification for engaging in everyday crime\n(Jolley et al., 2019 ; Jolley & Paterson, 2020 )a n da n t i -\nSemitic and Islamophobic attitudes (Golec de Zavala &\nCichocka, 2012 ; Swami et al., 2018 ). Therefore, within psy-\nchology, research has typically focused on motivational and\ncontextual factors as well as individual differences underlying\nbelief in CTs (Butter & Knight, 2020 ; Douglas et al., 2019 ;\nDouglas & Sutton, 2018 ).*Alessandro Miani\nalessandro.miani@unine.ch\n1Institute of Work and Organizational Psychology, University of\nNeuch\u00e2tel, Rue Emile-Argand 11, 2000 Neuch\u00e2tel, Switzerland\n2Department of Psychology, University of Warwick, University Road,\nCoventry CV47AL, UK\n3The Alan Turing Institute, British Library, 96 Euston Road,\nLondon NW1 2DB, UKBehavior Research Methods (2022) 54:1794 \u20131817\nhttps://doi.org/10.3758/s13428-021-01698-z\n#The Author(s) 2021\nA more complete understanding of CTs requires under-\nstanding how they spread. The current focus on individual\nbeliefs, predispositions, and biases is of limited utility in thisrespect, for two reasons. First, beliefs are not straightforwardly\nconnected to CT transmission. For example, a skeptical-\nminded individual may share a CT document within adebunking community for critical purposes (Franks et al.,\n2017 ), or a credulous individual may hesitate to share such a\ndocument in a science-oriented community for fear of beingstigmatized (Lantian et al., 2018 ). Moreover, transmission can\nalso be motivated strategically, independently of belief, to\ninfluence constituencies, such as when CTs or fake news isintentionally shared on social media to affect outcomes like\nvoter behavior (Bangerter et al., 2020 ; Douglas et al., 2019 ).\nSecond, CT beliefs do not spread per se. Rather, CTs spread asmaterialized forms of belief, conveyed as narratives in the\nform of written text (e.g., from webpages or social media\nposts), video (e.g., from video-sharing platforms such asYouTube), images (e.g., internet memes), or eventually audio\n(e.g., podcasts or the recent audio-based social media\nClubhouse). Regardless of their form, CT beliefs emerge inthe minds of recipients when they interact with such content.\nFor whatever reasons CT narratives are created, they circulate,\nsticking in the mind of conspiracy-predisposed recipients and\npotentially motivating individual and collective action (Franks\net al., 2013 ; Imhoff et al., 2021 ; Jolley & Paterson, 2020 ).\nTherefore, to understand the spread of CTs and their out-\ncomes, research should investigate the content of CT\nnarratives.\nOn the internet, misinformation spreads faster, farther, and\ndeeper within groups of like-minded individuals (Del Vicario\net al., 2016a ,b;V o s o u g h ie ta l . , 2018 ,b u ts e eC l a r k e , 2007 ;\nUscinski et al., 2018 for a critical view). The internet consti-\ntutes a system of information proliferation by which many\npeople form opinions in regard to political parties, social is-sues, and health-related information (Betsch et al., 2011 ). In\nthe Web 2.0 version of the internet, information is produced\nand consumed in a horizontal fashion, allowing anyone tocreate and share content, with few editorial filters (Aupers,\n2012 ; Bessi et al., 2015a ,b). CT texts may thus have the same\nepistemological weight for many users as mainstream texts,and compete with them for attention (Bessi et al., 2014 ; Eicher\n&B a n g e r t e r , 2015 ; Hills, 2019 ). The perceived credibility of\nepistemic sources is also a function of belief in CTs (Imhoffet al., 2018 ). This makes epistemic authority difficult to eval-\nuate, especially when conspiratorial narratives are promoted\nby political leaders (Barkun, 2017 ), by scholars in prestigious\njournals (Wakefield et al., 1998 ), and by Nobel Prize winners\n(Perez & Montagnier, 2020 ).\nResearch on the content and circulation of CTs on the in-\nternet has focused on user-generated texts such as comments\nand posts gathered from social media such as Twitter (Mitra\net al., 2016 ; Wood, 2018 ), Facebook (Bessi, 2016 ; Bessi,Zollo, et al., 2015b ; Brugnoli et al., 2019 ;S m i t h&G r a h a m ,\n2019 ), Reddit (Klein et al., 2018 ,\n2019 ; Samory & Mitra,\n2018a ,2018b ), Gab (Zannettou et al., 2018 ), or comment\nsections of news websites (Wood & Douglas, 2013 ,2015 ).\nThis approach has the advantage of exploring large, ecologi-\ncally valid samples of text as a complement to psychologicalinvestigations of CT beliefs. However, it is difficult to reliably\nextract measures of individual belief from comments embed-\nded within the noisy and heterogeneous discussion threads ofconspiracy believers and debunkers (Wood & Douglas, 2013 ,\n2015 ; but see Klein et al., 2019 ). Moreover, discussion threads\nlimit the utility of extracted text because the comments andposts are brief, are contextualized in the discussion in which\nthey are embedded, and are incapable of spreading indepen-\ndently from the whole thread. As a matter of fact, discussionthreads are not conspiracy narratives per se. While the com-\nments and posts they contain might instill curiosity, reinforce\nexisting beliefs, or support conversion, they often do not con-stitute the actual source through which CTs are transmitted.\nTowards corpora of CT texts\nOne valuable source of CTs for academic research aimed atunderstanding the content and transmission of CTs is CTwebsites. Although social media sites engage more traffic\nand are overall more popular than other websites (Facebook,\nTwitter, and Instagram are respectively ranked as the third,fourth, and fifth most popular websites following Google\nand YouTube, according to similarweb.com ,a c c e s s e do n2 0\nMarch 2021), websites provide more in-depth and elaborateddiscourse than posts and tweets on social media, which are\nnevertheless crucial for the spread of webpages. Conspiracy\nwebsites, specifically, are specialized sources created for thepurpose of developing, collecting, and spreading CTs. These\nwebsites provide ample page space to showcase arguments\nthat discredit official narratives and function as trustworthyepistemic sources for CT believers. Analysis of CT webpages\noffers a series of advantages. Webpages constitute standalone,\nstructured texts nested within sources (i.e., websites) and assuch are accompanied by paratextual (i.e., metadata) informa-\ntion. As standalone documents, webpages can easily be shared\non social media and so can provide measures of spread.Appropriately identified webpages, therefore, would be bene-\nficial for studying the content of CTs, and a large corpus of\nsuch CTs could provide a solid grounding for CT research.\nOnly a handful of studies, focused on related phenomena\nsuch as anti-vaccine movements, rumors, and fake news, havebuilt corpora from online material (discussed below). Yet, to\nour knowledge, the field lacks a corpus specifically focused\non online CTs. In this section, we describe published work,stressing its strengths and weaknesses.\nGeneral-purpose linguistic corpora such as the WaCky cor-\npus (Baroni et al., 2009 ) and the British National CorpusBehav Res (2022) 54:1794 \u20131817 1795\n(BNC, Aston & Burnard, 1998 ), although composed of large\ncollections of texts, do not generally allow researchers to fo-\ncus on either the source type (e.g., conspiracy vs. mainstream)or a specific topic (e.g., an event that has generated a CT). It\nshould be noted, however, that documents in WaCky were\ngathered from a set of 2000 seeds consisting of randomlychosen pairs of content words selected from the BNC, mean-\ning that seeds were used as keywords to retrieve webpages.\nThis represents a useful approach which we use here: by cre-ating ad hoc seeds, data collection can be directed to a partic-\nular (set of) topic(s) encapsulated in the seed.\nOther corpora focus on specific themes. In the field of\nonline anti-vaccine movements, a few studies have collected\nwebpages gathered through search engines (Fu et al., 2016 ;\nOkuhara et al., 2017 ; Sak et al., 2015 ). This approach is con-\nvenient, as it allows researchers to obtain data by mimicking\nhow users retrieve information. However, because these cor-\npora were collected manually, sample sizes are limited, there-fore reducing generalizability. To a different degree, the\nCORPS corpus (Guerini et al., 2013 )i sc o m p o s e do f3 6 0 0\npolitical speeches gathered from the web. Nonetheless, beingcomposed of only one genre without any (matched) control\ngroup, CORPS does not enable comparisons beyond descrip-\ntive analyses.\nFocusing on rumors and fake news, other studies have built\ncorpora that include a control group that allows between-group comparisons (Castelo et al., 2019 ;K w o ne ta l . , 2017 ).\nKwon et al. ( 2017 ), for example, built two Twitter subcorpora\nfrom a list of rumor and non-rumor events (henceforthRumTweet). Castelo et al. ( 2019 ), on the other hand, collected\nmaterial (fake news vs. mainstream) via lists of reliable and\nunreliable websites compiled by independent fact checkers(henceforth FNweb). This approach is useful because it re-\nduces selection bias during dat a collection. However, al-\nthough these two studies allow us to narrow the samplingmethod to obtain either two- group sources (websites) or\ntwo-group themes (rumors), they present an important limita-\ntion. In fact, to systematically study phenomena related tolanguage (e.g., conspiracy, or fake news, or rumors) through\na corpus, many forms of analysis are likely to require\nsubcorpora matched by topic. This allows researchers to com-pare different versions of the same event to identify discrim-\ninating features. If not matched, the two subcorpora are treated\nas bags of words (as in Castelo et al., 2019 , and Kwon et al.,\n2017 ), ignoring the inherent structure emerging from different\nthemes or sources. Although some changes are expected\nto emerge systematically from a bag-of-words approach,there may also be important topic-specific differences. For\nexample, differences between CT and mainstream ac-\ncounts of Princess Diana \u2019s death are likely to differ in\ninformative ways from CT and mainstream accounts of\nCOVID-19. These differences can only emerge from a\ntopic-matched corpus.Overcoming this limitation, the PHEME dataset (Zubiaga\net al., 2016 ) focuses on predefined events that have generated\nrumors, allowing researchers to compare rumor with non-rumor tweets around specific events. Yet, the only work, to\nour knowledge, that has focused on CTs is that of Uscinski\nand collaborators (2011), who gathered 100,000 publishedletters to the editor of The New York Times (henceforth\nNYT) from 1897 to 2010. After the data were collected, each\ndocument was manually coded as either referring to a conspir-acy or not, of which 800 were identified as conspiracies. In\naddition, differently from the other works we reviewed above,\nthe authors coded several groups of actors post hoc (e.g.,left/right/foreign political actors, capitalists/communists, me-\ndia, government institutions, and other).\nHere, we present LOCO ,\n1our Language Of COnspiracy\ncorpus that was built upon the strengths and weaknesses of\nthe reviewed corpora.\nTable 1shows the corpora comparison, including LOCO,\nand summarizes each corpus \u2019key features, including the focus\n(i.e., the goal, e.g., general-purpose language or fake news),\nthe source of the material gathered (e.g., from webpages ortwitter), size expressed in number of documents and tokens\n(i.e., non-unique words), presence of topics (e.g., events or\nthemes) or grouping (e.g., rumors vs. non-rumors) structures,\nthe date range of documents expressed in years, and whether\nthe material is freely available.\nThe language of conspiracy (LOCO) corpus\nLOCO is a multilevel topic-matched corpus composed ofstandalone documents ( N= 96,743) gathered via ready-\nmade lists of conspiracy and mainstream websites (see\nLOCO \u2019s key feature in Table 2). LOCO has been built as a\nfreely available text source from which researchers can extract\nfeatures and/or generate predictive and classification models.\nPrevious studies of CT textual data have extracted lexicalfeatures (Del Vicario, Vivaldo, et al., 2016b ; Faasse et al.,\n2016 ; Klein et al., 2019 ; Mitra et al., 2016 ; Samory & Mitra,\n2018a ; Wood & Douglas, 2015 ), topic distributions (Bessi,\nZollo, et al., 2015b ; Klein et al., 2018 ; Mitra et al., 2016 ;\nSamory & Mitra, 2018b ), and narrative patterns (Samory &\nMitra, 2018b ). Such analyses can be replicated and extended\nwith LOCO due to its rich metadata.\n1The acronym LOCO might suggest the idea that conspiracy theories and\ntheorists are all crazy. Far from this position, we rather highlight the polarizing\nphenomenon by which, regardless of the belief position, the \u201cothers \u201dare con-\nsidered crazy. People with beliefs in CTs feel, and often are, stigmatized(Lantian et al., 2018 ). On the other hand, nonbelievers are also in some in-\nstances mocked as \u201cglobetards, \u201d\u201cvaxholes, \u201dor\u201ccovidiots. \u201dThe last expres-\nsion is emblematic as it is used by both sides of the belief spectrum to refer topeople who either believe or do not believe in COVID-19. And, of course,some conspiracy theories are true.1796 Behav Res (2022) 54:1794 \u20131817\nThe main goal of LOCO is to shed light on the language of\nconspiracy. To this aim, LOCO is built on documents that\nrevolve around CTs. Because we do not yet know what thelanguage of conspiracy is, i.e., to what extent conspiracy lan-\nguage differs from non-conspiracy language, selecting docu-\nments (e.g., from webpages) based on an a priori definition ofconspiracy would be difficult. At best, selecting documents\nbased on their content would result in both a limited sample\nsize (due to manual coding, see e.g. Fu et al., 2016 ;O k u h a r a\net al., 2017 ; Sak et al., 2015 ) and limited heterogeneity (due to\nselection criteria based on a specific linguistic/rhetoric style).\nWe therefore chose to categorize document selection startingfrom the source (i.e., websites).Not all content from conspiracy websites will contain CTs.\nIntuitively, it is unlikely that all ~93,000 webpages in www.\nglobalresearch.ca contain CTs, and some content might come\nfrom neighboring genres such as rumors, fake news, urban\nlegends, and pseudoscience. To provide an estimate of how\nwell conspiracy and mainstream documents reflect their truelabels and how well the two sources can be distinguished from\neach other, we have blindly coded a subset of LOCO \u2019s\ndocuments (60 documents from each subcorpus, seeSection SM1 in supplemental material ) as being either\nconspiratorial or not. With an overall accuracy of .88\n(Cohen \u2019sk= .77), we have correctly classified as\nconspiracy 85% of documents and correctly classified asTable 1 Key features of eight corpora relevant to conspiracy theory content\nResource BNC WaCky CORPS FNweb RumTweet PHEME NYT LOCO\nFocus Language language Political\nspeechesFake news Rumors Rumors Conspiracy Conspiracy\nObtained from Printed\nmaterialWeb\npagesWeb pages Webpages from list of\nwebsitesTwitter Twitter Newspaper Webpages from list of\nwebsites\nNumber of\ndocuments4 K 2.69 M 3.6 K 14 K (7 K fake) 192 K tweets\n(61 K rumor)7.5 K threads\n(35 K rumor\ntweets)100 K\n(800\nconspir-\nacy)96 K\n(24 K conspiracy)\nNumber of\ntokens100 M 1.9 B 7.9 M 7 M* 2.8 M* 100 K* 88 M\nTopic structure NO 2 K\nseedsNO NO YES\n111 events(60 rumors, 51\nnon-rumors)YES 9 events YES YES\n47 seeds600 topics\nGrouping\nstructureNO NO NO YES YES YES\n(matched)YES YES\n(matched)\nYear range 1917\n20102013\n20182006\n2009Events around\n2014 \u201320151897\n20101853\n2020\nFreely available YES YES YES YES YES YES NO YES\nNote. Resources: BNC (Aston & Burnard, 1998 ); WaCky (Baroni et al., 2009 ); CORPS (Guerini et al., 2013 ); FNweb (Castelo et al., 2019 ); RumTweet\n(Kwon et al., 2017 ); PHEME (Zubiaga et al., 2016 ); NYT (Uscinski et al., 2011). *Number of tokens calculated from studies \u2019freely available datasets\nTable 2 Summary statistics of mainstream, conspiracy, and all documents in LOCO\nMainstream Conspiracy Whole corpus\nNo. of documents 72,806 23,937 96,743\nNo. of websites 92 58 150Range of years 1853 \u20132020 2004 \u20132020 1853 \u20132020\nM(SD) [range] M(SD)[ r a n g e ] M(SD)[ r a n g e ]\nNo. of words per document 805.94 (939) [97 \u20139507] 1236.32 (1307) [100 \u20139428] 912.43 (1059) [97 \u20139507]\nTotal no. of words 58,677,322 29,593,678 88,271,000\nNo. of sentences per document 37.92 (47.89) [1 \u20131087] 59.63 (69.58) [1 \u20131047] 43.29 (54.88) [1 \u20131087]\nTotal no. of sentences 2,760,789 1,427,397 4,188,186\nNo. of paragraphs per document 16.56 (19.30) [1 \u2013829] 24.51 (32.83) [1 \u2013905] 18.53 (23.64) [1 \u2013905]\nTotal no. of paragraphs 1,205,904 586,748 1,792,652Behav Res (2022) 54:1794 \u20131817 1797\nmainstream 92% of documents. The lower classification\nperformance on conspiracy documents suggests that not all\ndocuments from conspiracy websites are in fact CTs, whilemainstream documents are less ambiguously classified as\nnon-conspiracy. An altern ative explanation is that\nconspiracy texts are difficult to distinguish from mainstreamtexts, at least via human inspection (meaning that future\nalgorithms might find features that help improve on human\nclassification). These results also suggest that conspiracy andmainstream texts overlap to some extent (suggesting a\ncontinuum).\nThe multilevel structure of LOCO allows us to take into\nconsideration natural hierarchical grouping of documents\ncross-nested within websites and topics. At the document,\nwebpage, and website levels, LOCO \u2019s metadata\n2allow re-\nsearchers to create subsets of documents or to add covariates\nduring analyses. In Table 3, we summarized the key variable\ntypes we provide with LOCO for each level. For example,each document is associated with topic labels that summarize\nits semantic content. These labels refer to the topics that have\nthe highest probability (among all topics extracted fromLOCO) of describing the document \u2019s content (see \u201cTopic ex-\ntraction \u201dsection). This is useful for tracking differences (e.g.,\nin lexical features) between conspiracy and mainstream texts\nwithin a specific topic (e.g., Princess Diana \u2019s death), within a\nset of related topics (e.g., coronavirus outbreak in China, co-ronavirus outbreak in the United States), between topics (e.g.,\nPizzagate vs. moon landing), or within and between topics,\ne.g., by using a 2 (e.g., Princess Diana, coronavirus) \u00d7 2(conspiracy, mainstream) factorial design. Similar analyses\ncan be performed using the data LOCO provides on website\ninformation about political bias, factual reporting, and websitecategory. For most (~67%) webpages, we gathered informa-\ntion about their upload/creation date (see \u201cDate\u201dsection). This\nallows researchers to test time-related hypotheses such as theevolution through time of topics or lexical features (e.g., co-\nronavirus topics over time). Other crucial features of LOCO\nare the spread and popularity metrics associated with bothwebsites and webpages. These metrics allow researchers to\ntest hypotheses about social media transmission, for example,\ntesting webpages \u2019spread and engagement while correcting for\nthe website \u2019s popularity. Last but not least, LOCO is provided\nwith a set of almost 300 lexical features (e.g., psychological\nprocesses associated with words) derived from two widelyused and validated text-analysis programs based on word-\nwithin-category counting.Method\nSeed selection\nSimilar to the construction of the WaCky corpus (Baroni et al.,\n2009 ), we used seeds (i.e., keywords) to retrieve the webpages\nthat provide the texts for LOCO. Seeds were extracted from\nthe items of two CT-based surveys: a national poll (Jensen,\n2013 ,S o u r c e1 ,e . g . , \u201cDo you believe that Lee Harvey Oswald\nacted alone in killing President Kennedy, or was there some\nlarger conspiracy at work? \u201d)a n dt h e1 7 - i t e m \u201cendorsement\nof conspiracy theories \u201dfrom Douglas and Sutton ( 2011 ,\nSource 2, e.g., \u201cThe American moon landings were faked \u201d).\nWe extracted the seeds from these surveys for two reasons.\nFirstly, these surveys on CTs encompass a broad set of well-known CTs, since they are supposed to measure specific be-\nliefs from a wide range of people. Secondly, these surveys\ncondense each theory within a short space, usually a sentence.These two surveys were chosen because, while they measure\nspecific theories, they are broad in scope, and encompass a\nlarge and heterogeneous set of CTs. Items from both surveyswere grouped to obtain a unique seed (e.g., \u201cPrincess Diana\nfaked her own death so she and Dodi could retreat into\nisolation ,\u201d\u201cPrincess Diana \u2019s death was an accident ,\u201dand\n\u201cOne or more rogue \u2018cells \u2019in the British Secret Service con-\nstructed and carried out a plot to kill Princess Diana \u201dwere\nmerged as \u201cPrincess Diana \u2019sd e a t h \u201d).\nWe further broadened the pool of seeds by manually\nadding 20 seeds corresponding to popular (e.g., Illuminati,genetically modified organisms, Pizzagate) and current (e.g.,\ncoronavirus, Bill Gates, 5G) CTs missing from Sources 1 and\n2. Note that seeds such as \u201cchemtrails, \u201dwhen applied to main-\nstream documents, in most if not all cases return documents\nreferring to CTs. We keep these documents in LOCO so as to\nhave a broad mainstream pool and allow users to create sub-sets of texts prior to analyses (e.g., by removing mainstream\ndocuments that mention CTs, see \u201cMentioning \u201cConspiracy \u201d\nandEffect of mentioning conspiracy \u201dsections). In order to\ninclude events that might be associated with different spel-\nlings, for some seeds we used synonyms (e.g., big pharma,\ndrug companies, and pharmaceutical industry; new world or-der and NWO; climate change and global warming). In\nTable 4, we show the full set of seeds used to retrieve docu-\nments and the final document count in LOCO by source type.Note that the seed count is larger than the number of docu-\nments. This is because a single webpage can be returned by a\nGoogle search using different keywords. For example, if adocument relates t oP r i n c e s sD i a n a \u2019sd e a t hd u et oa n\nIlluminati plot, then this document would be returned twice\nfor both \u201cPrincess diana death \u201dand\u201cilluminati \u201d\nsearches.\nNote that although we used seeds as keywords to retrieve\nwebpages, we do not intend seeds to serve as proxies for\ndocument content. This is because a webpage is returned by2Note that we make a distinction bet ween documents, webpages, and\nwebsites \u2019metadata. For document, we refer to the text and its intrinsic features\nsuch as title, topic, lexical features, etc. Differently, for webpage, we refer to aset of paratextual information related to the webpage (that contains the text)such as the URL, date, spread, and the website host. Websites \u2019metadata refer\nto the second level of paratextual information such as website \u2019s political bias,\nsize, and popularity.1798 Behav Res (2022) 54:1794 \u20131817\nGoogle if the seed is present in the webpage (but note, not\nnecessarily in the main text) at least once. The seed presencein the webpage, however, does not necessarily indicate that\nthe seed reflects the main topic of the document \u2019s text, be-\ncause the seed can be contained in boilerplate texts or in thecomments section of the webpage. Instead, we remind the user\nthat for a more precise content of documents, we offer a more\nfine-grained measure of document content (extracted from thecleaned text), namely topics (see \u201cTopic extraction \u201dsection).\nWe include the seed variable in the LOCO dataset, believing it\nmight be useful for answering other questions, e.g., regardingwebpage indexing.\nWebsite lists\nFollowing previous work (Pennycook & Rand, 2019 ),\nwe gathered a list of conspiracy websites from\nmediabiasfactcheck (MBFC).3Websites are labeled by\nMBFC as conspiracy if they publish unverifiable infor-\nmation related to known conspiracies such as the New\nWorld Order, Illuminati, false flags, aliens, anti-vaccination propaganda, etc. (for further details, see cat-\negory descriptions in \u201cWebsite category \u201dsection). From\nthe whole list of 241 conspiracy websites, we selected(in December 2019) those that scored the highest on theconspiracy rating (i.e., \u201ctin foil hat, \u201dN=6 8\n4). This\nincreased the chances of obtaining highly conspiratorialtexts, limiting contaminat ion by mainstream or less con-\nspiratorial texts.\nThe mainstream list of websites was created (in June 2020)\nin a data-driven fashion by extracting the websites returned by\nGoogle for each seed. While maximizing data acquisition, this\napproach also mimics users \u2019online behavior. We proceeded\nas follows. For each seed, we created a Google query, gath-\nered the resulting top 40 URLs, and extracted the websites \u2019\ndomains.\n5We repeated this operation with different IPs, mim-\nicking the searches from the UK (London), USA (New\nJersey), and Australia (Melbourne) to maximize English lan-\nguage domains as well as the heterogeneity of websites. Thisprocedure returned a total of 1453 unique domains. All do-\nmain counts were aggregated, and we computed two popular-\nity metrics per domain: (1) the number of times a domainappears overall for all seeds (absolute frequency), and (2)\nthe number of unique seeds associated with a specific domain\n(relative frequency). These two metrics were chosen to obtaina large portion of pages (absolute method) and a wide cover-\nage of seeds (relative method). The top 120 domains for each\nmetric were visually inspected to remove potential conspiracyTable 3 Types of variables included in LOCO\nLevel Variable type Example of variable Section\n1. Document Raw content Document ID Table 6\nTitle 3.4\nText 3.4\nFeatures Number of words, sentences, paragraphs 3.8.2Semantic content Topic 3.6\nLexical features 3.5\nConspiracy content Representativeness 3.7\nMention of conspiracy 3.8.1\n2. Webpage Information Website host 3.2\nURL 3.3Date 3.8.3Seeds 3.1\nSpread Facebook shares, comments, and reactions 3.8.4\n3. Website Classification Political orientation, factual reporting, category 3.8.5\nSize Number of webpages 3.8.6Popularity Visits, traffic, and rank 3.8.6Spread Facebook shares, comments, and reactions 3.8.4\n3https://mediabiasfactcheck.com/conspiracy/4Note that the final number of conspiracy websites in LOCO is 58. This is\nbecause during the data cleaning process for some websites we did not obtainany webpages (e.g., stormfront.org ,learntherisk.org ). Other websites were\nexcluded because they were either collections of tweets and videos or were\nCT search engines (e.g., qanon.pub, disclose.tv, and alternativenews.com ).\n5E.g., telegraph.co.uk from the URL https://www.telegraph.co.uk/news/\nuknews/1577644/MMR-vaccine-doesnt-cause-autism-says-study.html .Behav Res (2022) 54:1794 \u20131817 1799\nTable 4 List of seeds\nseed source No. of conspiracy documents No. of mainstream documents\n5g m 702 1664\naids 2 1025 2428alien 1, 2 813 1715barack obama 1 496 1485big foot 1 708 2019big pharma 1 716 1758bill gates m 717 1623cancer m 839 2098chemtrails 1 744 549cia cocaine 1 552 1030climate change 1, 2 889 2166coronavirus m 1104 2588covid 19 m 1004 2395drug companies 1 1024 2356ebola m 626 2140elvis death m 188 1386elvis presley m 132 1258\nflat earth m 605 1646\nfluoride water 1 395 1384george bush 1 844 1737george soros m 735 1178global warming 1, 2 896 1793gmo m 620 1924illuminati m 804 1479jfk assassination 1, 2 607 1344jonestown suicide 2 42 594mh370 m 167 1086michael jackson death m 616 1564mind control 1 949 2036moon landing 1, 2 349 1579new world order 1 1036 2162nwo 1 814 1350osama bin laden 1 645 1415paul mccartney death 1 149 1190pharmaceutical industry 1 828 1684pizzagate m 359 1012\nplanned parenthood m 626 1434\npopulation control m 972 2295princess diana death 2 309 1338reptilian 1 494 1418saddam hussein 1 677 1623sandy hook m 470 1500september 11 attack 1, 2 939 2207vaccine 1 803 2125vaccine autism 1 531 1654vaccine covid m 923 2031zika virus m 473 1675\nNote. Sources 1, 2, and m refer to: 1 = Jensen ( 2013 ); 2 = Douglas and Sutton ( 2011 ), and m = manual1800 Behav Res (2022) 54:1794 \u20131817\nwebsites (none appeared), less relevant websites such as those\nnot related to text content (YouTube, Amazon, Instagram,\nPinterest, LinkedIn, Shutter stock), websites with user-\ngenerated content (Blogger, Facebook, Twitter), and other\nwebsites such as those related to movie reviews, private com-\npanies, and online courses. Following these exclusion criteria,a total of 19 domains were removed. Keeping all domains\nappearing in both metrics ( N= 135), this list was visually\ninspected and subdomains were aggregated (e.g.,keith.seas.harvard.edu, sitn.hms.harvard.edu,\nhealth.harvard.edu, hsph.harvard.edu aggregated to\nharvard.edu) while removing mistakenly extracted domains(e.g., www) and non-English domain suffixes (e.g.,\nnationalgeographic.fr ). This left us with 93 domains.\n6\nURL extraction and cleaning\nOnce we had obtained the list of seeds and the two lists of\nwebsites, we proceeded with collecting the webpages \u2019URLs\nthrough Google. Besides being the most popular search en-\ngine (ranked # 1 worldwide according to www.similarweb.\ncom, accessed September 2020), we used Google Search\nbecause we were interested in mimicking user behavior.\nImportantly, while allowing us to automate URL extraction,this procedure also uses the same search criteria for all\nwebsites, without relying on website-specific search engines\nthat might have biased results (e.g., by using the search barwithin the website).\nURL scraping was performed in R (R Core Team, 2019 ),\nusing the curl package (Ooms, 2019 ). We formed Google\nqueries by crossing each seed with each website to search\nfor a specific seed within a specific website. For example,\nthe Google query site:bbc.com moon landing\n7returned results\nabout moon landing from the BBC website. The UK top-level\ndomain \u201cgoogle.co.uk \u201dwas chosen over \u201cgoogle.com \u201dto\nensure English language searches ( \u201c.com \u201din\nSwitzerland \u2014where the study was conducted \u2014automatically\nreturns results in either German, French, or Italian). We also\nprompted Google to extract results in the English language byadding \u201chl=en \u201dto the query. For each query, we extracted the\nfirst 60 results. Data collection occurred between May 20th\nand July 4th, 2020 (see workflow in SM2).\nOnce the URL collection was complete ( N\nconspiracy =\n67,813; Nmainstream = 163,488), we proceeded with removing\nduplicated and non-relevant URLs. This was performed bysearching (with regular expressions) and removing the URLs\nthat did not include the website searched, non-text files (pdf,\npictures, videos), video and photo galleries, feeds, forums, andblogs, dynamic pages (e.g., URL ending with \u201cphp,\u201d\u201c?\u201d),\ncollection pages and archives of links, shops and stores, and\nWikipedia lists and discussions. This procedure left us with29,885 conspiracy and 105,461 mainstream documents.\nText extraction and cleaning\nTo extract the HTML files and then the useful text from our\nlist of URLs, we tested several Python packages. These\nscripts, called \u201cboilerplate stripping, \u201dremove noise text from\nwebpages such as navigation links, header and footer sections,\netc. The Python Goose package returned the best performance\n(see SM3) and therefore was chosen for extracting the texts.Importantly, Goose can be set to return a series of meta-\ndescriptions and tags from the raw HTML file. Therefore,\nalong with the main body of the text, we used Goose to extract\nthe title of the document, the language tag (further capturing\nnon-English pages), and the date the file was uploaded on the\nwebsite or created (see discussion in \u201cDate\u201dsection).\nOnce all the texts were collected, we further cleaned the\nraw corpus using the following exclusion criteria: documents\nfor which the HTML meta-tag language was not set asEnglish, empty documents, exact duplicated texts, and texts\nshorter than 100 words.\n8In order to further remove non-\nEnglish documents that did not contain the language HTMLtag, we removed texts in which the percentage of top 1000\nEnglish words (Fry, 2000 ) was below 40% (threshold chosen\nafter visual inspection). Finally, we also removed texts whoseword count was 2.5 standard deviations above the mean of the\nwhole corpus. This procedure left us with the final LOCO\nsample of 23,937 conspiracy and 72,806 mainstream docu-ments (see Table 2for details).\nLexical feature extraction\nFor each document in LOCO, we extracted measures of lan-\nguage use with two word-counting tools, namely LIWC\n(Linguistic Inquiry and Word Count, see Tausczik &Pennebaker, 2010 ) and Empath (Fast et al., 2016 ). Both tools\nhave been used previously to investigate the language of con-\nspiracy on social media (Fong et al., 2021 ; Klein et al., 2019 ).\nThese tools work on the same principle: they analyze texts,\nword by word, and check whether the word is included in a\npredefined category; if so, the category value increases. Toextract LIWC categories, we used the LIWC standalone ap-\nplication (version 2015), while for Empath we relied on CLA\n(Custom List Analyzer version 1.1.1, see Kyle et al., 2015 ), a\nstandalone application that, along with the batch of texts, takes\n6Note that this number is different from the final N= 92 for mainstream\nwebsites. This is because after the cleaning section, the website\nurbandictionary.com was no longer present.\n7URL: https://www.google.co.uk/search?q=site%3Abbc.com+moon+\nlanding&hl=en8The discrepancy with Table 2, which shows the minimum word count as 97\nwords in a document, is due to the fact that at this stage (document cleaning)we counted words as portions of text separated by spaces, while LOCO \u2019sf i n a l\nword count was performed with TAACO (see \u201cText statistics \u201dsection).Behav Res (2022) 54:1794 \u20131817 1801\nas input an ad hoc list of dictionaries. Both tools provide\nstandardized outputs, that is, the number of words in a given\ncategory divided by the total number of words from the textfile. Note that the two tools provide different formats for their\noutput: while LIWC returns percentages (range: 0 \u2013100),\nEmpath returns ratios (range: 0 \u20131).\nAlthough these tools work on the same principle, they dif-\nfer in how they were built, making them somewhat comple-\nmentary. First, unlike Empath, LIWC detects grammaticalcategories such as articles, prepositions, pronouns, etc.\nSecond, while LIWC construction relied on human coding,\nEmpath categories were built in a data-driven fashion from asemantic database. For instance, by seeding terms such as\n\u201cfacebook \u201dand\u201ctwitter, \u201dEmpath generates the category la-\nbeled \u201csocial media. \u201dThe two methods by which these tools\nwere built explain why they compute slightly different values\nalong their categories, as shown in between-dictionary corre-\nlations (see Section SM4).\nTopic extraction\nFor each document in LOCO, we quantify the semantic con-\ntent by providing a fine-grained topical distribution. This rep-\nresents a vector containing the probabilities that each of aseries of topics is associated with each document. This was\nachieved with Latent Dirichlet Allocation, (LDA; Blei et al.,\n2003 , see SM5 for text preprocessing). LDA is an unsuper-\nvised probabilistic machine learning model capable of identi-\nfying co-occurring word patterns and extracting the underly-\ning topic distribution for each text document. By setting apriori the number of topics in a given corpus, LDA computes,\nfor each document in the corpus, the probabilities for all topics\nof being represented in the document. Meanwhile, each wordof the corpus has a probability of being part of a topic. In other\nwords, a word xhas probability \u03b2of being part of topic k;a\ntopic khas probability \u03b3of being part of document n. The sum\nof all the word probabilities within one topic is 1, and the sum\nof all the topic probabilities within one document is 1.\nIn LDA, the \u201cright\u201dnumber of topics is determined by the\ngoal of the task more than the data itself (Nguyen et al., 2020 ,\nbut see also clustering algorithms in general; von Luxburg\net al., 2012 ). LDA topics can be thought as the resolution of\na microscope (Barron et al., 2018 ;N g u y e ne ta l . , 2020 ): if a\nfine-grained resolution is required, then a large number of\ntopics is better; if the number of topics is small, these topics\nbecome more general (Allen & Murdock, 2020 ). Here, topic\nextraction was performed with the topicmodels R package\n(Gr\u00fcn & Hornik, 2011 ), using Gibbs sampling. We left the\nother LDA parameters set as default, while setting the same\nseed for reproducibility for all topic extractions. We per-formed topic extraction with three different levels of resolu-\ntion, setting kat 100, 200, and 300 topics. As a consequence,\nsumming all ktopics, we obtained 600 topics (seeSection SM6 for a thorough description of topics and\nSection SM7 for topic comparison between different ks). In\nSection SM7.1 of the supplemental material , we have sug-\ngested a way to assess topic specificity based on the position\nof a theme \u2019s keyword (e.g., \u201cDiana \u201dfor Princess Diana) with-\nin the beta weight-ordered topic \u2019st e r m s ,a n dt h ec o r r e l a t i o n\nwith lexical features. If the theme is event-based (e.g., disap-\npearance of Malaysia Airlines Flight 370 [MH370], 8\nMarch 2014), we also suggest visually inspecting the gammavalues plotted over time.\nAs a proxy for document topic, for each of the three sets of\nktopics, we extracted the topic that had the highest probability\nof representing the document, i.e., the highest gamma value\nwithin all topics within k, and included it in the LOCO dataset\n(see dataset description in \u201cData availability \u201dsection). This\nmeans that each document is associated with three topic la-\nbels, one for each k. We chose this option so as to offer LOCO\nusers a way to perform analyses on a specific topic resolution.\nNote that we did not provide labels for document topics.\nInstead, we provide the top 15 words for each topic that, taken\ntogether, summarize the topic \u2019s content (Nguyen et al., 2020 ,\nand see also beta weight distributions by kin Section SM6.1).\nWe provide with LOCO the matrix containing all gamma\nvalues for each document and topic pairs (see \u201cData availabil-\nity\u201dsection). This results in a matrix with a dimensionality of\n96,743 documents \u00d7 600 topics. This is useful for obtaining afine-grained topic description for each document. For exam-\nple, if a document nhas the topic with the highest \u0263=. 9 0 ,\nthen this topic has 90% probability of representing documentn, while the remaining 10% is distributed among all other\ntopics. Similarly, if the highest \u0263= .10, all the other topics,\nby exclusion, occupy the remaining 90% of probabilities.While in the first case we can say that document nis well\nrepresented by a topic k(where gamma is maximum), in the\nsecond case, the low gamma value shows that the document n\nis not well represented by a topic k. LOCO contains all \u0263\nvalues, allowing the user to select their own threshold when\nselecting documents based on topic.\nData associated with LOCO \u2019st o p i c s\nIn order to facilitate topic exploration prior to data analysis,\nwe attach additional files to LOCO that offer an in-depth de-\nscription of topic content. The first one is a matrix that con-\ntains all gamma values for each topic for each document\n(topic_gamma.json). Because there are three sets of ktopics\n(100, 200, and 300), we have named each topic adding the k\nresolution as prefix. For example, the fifth topic of k200 is\nlabeled \u201ck200_5, \u201dwhile the 134th topic of k300 is labeled\n\u201ck300_134. \u201dNote that, because we merged the three sets of\nks into a unique dataset, the sum of topic probabilities for each\ndocument is now 3 (1 for each kset of topics). The second file\n(topic_description.json, see also description in SM6) includes1802 Behav Res (2022) 54:1794 \u20131817\ndescriptions for each of the 600 topics. Descriptions include\nthe top 15 terms ordered by beta weight, the number of doc-\numents in which the topic has the highest gamma, the highestcorrelation with other topics and highest correlation with lex-\nical features (both LIWC and Empath). We also provide a\nseries of plots (in the file \u201ctopic_by_time.pdf, \u201dsee description\nin SM6), one for each topic, that track the evolution\nthrough time (from 1995 to 2020, see e.g. Fig. 2)o ft h e\ngamma values. Each plot also includes the topic name andthe list of the top 15 terms, ordered by beta values. We\nbelieve that these plots, along with the description of each\ntopic (and the actual matrix with gamma values), will helpresearchers not only in exploring topic associations and\nlexical features, but also in visually inspecting topics prior\nto data analysis.\nRepresentative conspiracy theories\nBecause one might be interested in what a prototypical con-spiratorial language is, we aimed at extracting a set of the mostrepresentative CT documents on the basis of the most fre-\nquently occurring words within the conspiracy subcorpus.\nWe believe that a set of representative documents may allow\nresearchers to make inferences about CTs more generally.\nAs such, a representative document should share morewords with the conspiracy subcorpus compared to a less\nrepresentative document. Recurrent word patterns such as\n\u201cthey are trying to KILL US! \u201d(from document C01b90)\nor\u201cknow the truth \u201d(document C073a0) might in fact be\nhighly shared across conspiracy documents; hence they\nwould be represented to a larger extent in the conspiracyuniverse.\nFollowing this reasoning, we extracted the documents that\nwere most similar to the entire conspiracy subcorpus. As ameasure of representativeness, we computed the cosine simi-\nlarity (CS) between words of each document against all words\nin the conspiracy subcorpus (for a similar procedure, see e.g.de Vries et al., 2018 ). Text preprocessing was the same as we\nused to extract LDA topics (see SM5). Documents \u2019CS was\ncomputed using the textstat_simil function from the R\npackage quanteda . Values range from 0 to 1, indicating either\nno overlap (0) or a perfect overlap (1) of terms. This returned a\nvector for each conspiracy document that indicated the simi-larity between it and all other conspiracy documents. We av-\neraged this vector to obtain a single value for each document.\nWe finally labeled as \u201cconspiracy representative \u201dthe doc-\numents whose CS value was higher than one standard\ndeviation above the mean. This resulted in a subset of\n4,227 documents, that is, 17.66% of the conspiracysubcorpus. In Section SM8 of the supplemental material ,\nwe report the top five documents with the highest and\nlowest cosine similarity.Metadata\nMentioning \u201cconspiracy \u201d\nWe marked documents that mentioned conspiracy in the text.\nThis was done by searching, via regular expressions, andcounting the occurrences of the word \u201cconspir*. \u201d\n9This mea-\nsure helps keep track of mainstream documents that mention\nconspiracy which may contaminate mainstream language withdetails about the corresponding conspiracy (e.g., Pizzagate or\nIlluminati, themes that rarely appear outside the context of\nCTs). Therefore, instead of removing these documents, asthey represent a special case of mainstream media whose fo-\ncus is on CTs, we left them in LOCO and annotated the num-\nber of instances of the word \u201cconspir*. \u201d\n10In the conspiracy\nsubcorpus, a total of 3520 documents mentioned conspiracies\nat least once, while in the mainstream subcorpus there were\n5031 documents. On average, conspiracy documents showmore instances of \u201cconspir* \u201dthan mainstream documents\n(conspiracy: M= 0.351, SD= 1.548, range: 0 \u201375; main-\nstream: M= 0.211, SD= 1.735, range: 0 \u2013182, t\n(45246) =\n11.773, p<. 0 0 1 , d= 0.09). However, when the instances\nwere normalized per word count (i.e., divided by numbers of\nwords in text), there were no differences, t(49107) =. 9 9 3 , p=\n.321, d=0 . 0 1 .\nText statistics\nFor each document, we calculated the number of words,\nsentences, and paragraphs using the Tool for the Automatic\nAnalysis of Cohesion, TAACO (Crossley et al., 2016 ,2019 ),\na freely available standalone application that allows batch\nprocessing of text files. Although LIWC also provides mea-\nsures of word count, which correlates highly with TAACOword count, r= .9996, we relied on TAACO measures for\ntwo reasons. First, based on the Python Natural Language\nToolkit (Bird et al., 2009 ), TAACO extracts the part of speech\nfor each word, from which it derives a text word count as well\nas the number of sentences and paragraphs. This, we believe,\nis a more sophisticated way than merely counting instances ofcharacters separated by spaces. Secondly, because the word-\nper-sentence measures of LIWC and TAACO correlate poor-\nly,r= .59, we visually inspected documents with the highest\ndiscrepancy between the two tools. We discovered that LIWC\nperforms poorly when full stop periods are missing from\nsentences, whereas TAACO considers the new line as a valid\n9The word \u201cconspir* \u201dwas chosen to be able to retrieve all conspiracy-related\nwords (conspiracies, conspiracist, conspiracy, conspiration, conspirator, con-spiratorial, conspiratorially, conspiratress, conspire, conspirer, and conspiring)\nbut not others (e.g., conspicuous). This was checked on both American and\nBritish Oxford English dictionaries.\n10From this count measure, a Boolean measure of \u201cmentioning conspiracy \u201d\ncan easily be derived by simply stating \u201cTRUE if mentions > 0. \u201dBehav Res (2022) 54:1794 \u20131817 1803\nsentence-separator marker. Therefore, in LOCO, we keep\nboth LIWC and TAACO word counts, but for consistency\nwith paragraph and sentence counts, we report here (seeTable 2)o n l yt h eT A A C Ow o r dc o u n t .\nDate\nInformation about document date was obtained primarily from\ntheGoose package, which extracts the upload date directly\nfrom the raw HTML document. When date was not available\n(i.e., Goose returned an empty cell), we extracted the upload\ndate with regular expressions from the URL of the document\n(e.g., \u201chttp://[ \u2026]/2018/01/23/[ \u2026].html \u201dwas coded as 23\nJanuary 2018). In LOCO, date data are provided for 63,868documents (67% of the entire corpus; 56.67% conspiracy and\n69.09% mainstream), see distribution of documents by date in\nFig.1.\nIt must be noted that date values reflect either the upload\ndate or the authoring date. Both types of information would be\ninformative for different purposes: texts that were authored onthe same date are based on a similar level of available\ninformation/evidence; texts that were published on the same\ndate compete for audience attention.\n11While dates before the\ninternet era (e.g., 1853) refer unambiguously to the authoring\ndate, this is less clear for more recent documents. We believe\nthat this information might be nevertheless useful, and there-fore we provide all dates available in LOCO. We warn re-\nsearchers to be aware of date ambiguity before testing any\ntime-related hypothesis. Researchers can either set a thresholdfor documents \u2019dates to keep (e.g., after the internet became\nwidespread or another arbitrary cutoff) or develop a method to\ndisentangle the two. However, although documents \u2019dates\nmay refer to either authoring or upload date, we show in\nFig.2that documents \u2019dates are nevertheless linked to the\nsocial events discussed in documents.\nLastly, date range differs between mainstream and conspir-\nacy subcorpora, see Table 2. We do not know the reason for\nthis difference, considering that our Google search was inde-pendent from documents \u2019upload date. One possible explana-\ntion is that conspiracy websites, being less popular (see\nTable 5), are also developed with less standardized protocols\n(see e.g., www.w3c.org ). This might have resulted in a less\nmethodical use of HTML meta-tags and therefore the lack of\ndate in some documents. This might also explain the higherpercentage of missing dates in conspiracy documents (56.\n67%). If this is the case, some documents predating 2004\n(i.e., the oldest conspiracy document in LOCO) might be inthis corpus yet lacking the date. Alternatively (or complemen-\ntarily), conspiracy websites might be younger, overall, than\nmainstream websites. For example, the infowars.com domain\nwas registered on 1999-03-07 (data obtained from https://who.is ),911truth.org on 2003-01-14, ahtribune.com (less\npopular in terms of monthly visits among LOCO \u2019s\nconspiracy websites) on 2015-08-23, and worldaffairsbrief.\ncom (most popular) on 2004-04-06. In contrast,\nscientificamerican.com was created on 1997-05-02,\nsciencemag.org on 1996-04-28, cnn.com on 1993-09-22,\nand bcc.com on 1989-07-15. Although not tested\nsystematically, those few observations suggest that, overall,\nconspiracy websites in LOCO might be younger thanmainstream ones, therefore explaining the different date\nranges.\nFacebook shares\nFor each webpage, we obtained information about spread\nfrom the web tool sharedcount.com (SC). Via an application\nprogramming interface, SC retrieves from Facebook\n12the\nnumber of shares, comments, and reactions for each\nwebpage URL. According to the website, SC reports \u201call\ntime statistics, \u201dwhich means that values refer to the overall\nshares since the creation of the URL tracked. All data from SC\nwere collected in September 2020.\nBesides single URL shares, we also computed an estima-\ntion of the total number of shares from the observed data we\ncollected for each website. To this end, we computed the sumof all webpage Facebook shares for each website and divided\nthem by the proportion of sampled LOCO webpage for each\nwebsite. For instance, in LOCO, there are 967 documentsextracted from the website www.infowars.com .I n f o w a r sh a s\n15,500 webpages indexed on Google (see \u201cWebsite metrics \u201d\nsection), which means that LOCO contains 6.24% of allInfowars webpages. The aggregated total Facebook shares\nof all 967 Infowars documents in LOCO is 89,639. By\ndividing the total shares (89,639) for the proportion of\nLOCO documents (0.0624), we obtain an estimation of total\nwebsite shares, which in this case is 1,436,820 times, a roughestimation of the grand total of shares of all Infowars\nwebpages. Once this measure was computed for all\nwebsites, we then tested the correlations of this measurewith other spread measures. The estimated Facebook shares\ncorrelates with website global rank ( r= -.81) and with\nwebsite monthly visits ( r= .81, see SM9 for more details).\nWebsite category\nWe relied on MBFC for obtaining metrics of political side and\nfactual reporting for each website. MBFC contains manual\nannotations and bias analyses for over 2,000 \u2014mostly\nnews\u2014websites. According to the MBFC method,\n13each\nwebsite \u2019s bias is evaluated on four criteria, including biased\n11We thank the anonymous reviewers for this suggestion.12see:https://developers.facebook.com/tools/debug/ )\n13https://mediabiasfactcheck.com/methodology/1804 Behav Res (2022) 54:1794 \u20131817\nwording headlines (e.g., the source uses loaded words to con-\nvey emotion to sway the reader), factual sourcing (e.g., the\nsource reports factually and backs up claims with well-\nsourced evidence), story choices (e.g., the source reports news\nfrom both sides), and political affiliation (e.g., the source en-\ndorses a particular political ideology). Factual reporting is\nbased on the factual sourcing used for assessing bias. For each\nwebsite, a minimum of 10 headlines and 5 news stories are\nassessed by MBFC experts. Low and very low factual\nreporting sources are those that need to be fact-checked for\nintentional fake news, conspiracy, and propaganda. Although\nMBFC states that their methodology has been not tested sci-\nentifically, they nevertheless adhere to the International Fact-\nChecking Network fact-checkers \u2019Code of Principles14and\nstrive for transparency. Furthermore, MBFC annotations have\nbeen used by other researchers to study fake news and con-\nspiracy websites (Baly et al., 2018 ; Cinelli et al., 2021 ;\nPennycook & Rand, 2019 ;R i s i u se ta l . , 2019 ).\nFor each of the LOCO websites that was reviewed in\nMBFC, we extracted measures of political orientation (left,\nleft center, least biased, right center, and right), factual\nreporting (from \u201cvery low \u201dto\u201cvery high \u201d), pseudoscience\nlevel (provided by MBFC only for conspiracy websites), and\nwhether the website was labeled as pro-science (i.e., relying\non legitimate science or evidence based on credible scientific\nsourcing). Note that pro-science websites do not have political\norientation labels. Data from MBFC were collected in\nJuly 2020.\nWebsite metrics\nWe have extracted a series of website metrics that, overall,\noffer an idea of popularity, engagement, and size for each\nwebsite. From the web tool similarweb.com15(SW), we\ncollected data about monthly total visits, global rank, andcategory. We also collected information about the type of\nincoming traffic. Expressed in percentage, these metrics\npartition each website's incoming traffic into direct (when a\nuser reaches the website directly by typing the URL on the\nweb browser or recalling it from bookmarks), from a search\nengine (when a website is reached through a search engine,\ne.g., Google), and from social media (when a website is\nreached through social media, e.g., a post on Facebook or\nTwitter). Other types of incoming traffic offered by SW,\nwhich we did not collect, are referrals, mail, and display,\nwhich overall account for about 7% (SD = 6.38) of\nremaining incoming traffic in our dataset (computed by\nsumming direct, search engine, and social media traffic and\nsubtracting it from 100).\nSW was chosen over Alexa.com (a web tool that provides\nsimilar services), mainly because SW updates its statistics\nevery month, whereas Alexa provides daily updates. While\nthe latter appears to be more fine-grained, it nevertheless\nposes some limitations in terms of data collection (which\nmanually spans several days) due to daily statistical\nfluctuations. In addition, SW offers a wide range of free\nfeatures, otherwise accessible in Alexa upon a monthly\nsubscription, and, importantly, the SW database is composed\nof ~50 million websites (vs. ~30 million websites in Alexa).\nThese data were collected in July 2020.\nIn addition, in order to obtain an estimation of the website\nsize, we extracted the total number of webpages per website\nindexed by Google. This was done by querying Google with\n\u201csite:\u201dfollowed by the website.16This data was collected in\nMarch 2021.\nData availability\nLOCO \u2019s data is freely available at https://osf.io/snpcg and\nincludes:\n14https://www.poynter.org/ifcn/\n15https://www.similarweb.com/corp/ourdata/16E.g., https://www.google.co.uk/search?q=site%3Abbc.com\nBehav Res (2022) 54:1794 \u20131817 1805\nFig. 1 Distribution of documents in LOCO by date .Distribution for aeach subcorpora (red: conspiracy; green: mainstream) and ball documents from\n1995 to the time of data collection (the red vertical line represents the mean, the boxplot on top displays the median and the interquartile ranges)\nFig. 2 LDA topic gamma values over time .The red dotted vertical lines\nrepresent the occurrences of significant events associated with the topic.\nIn the 9/11 topic, each vertical line represents September 11th in eachyear, starting from 2001. Coronavirus topics (bottom) are distributed over\nthe year 2020 (from January to July, when LOCO data collection ended).1806 Behav Res (2022) 54:1794 \u20131817\n1.LOCO.json (587.6 MB): a JSON (JavaScript Object\nNotation) file containing the LOCO corpus itself.\n96,746 rows (documents) \u00d7 20 columns (see Table 6)\n2.website_metadata.json (55.3 KB): a JSON file contain-\ning websites \u2019metadata. 150 rows (websites) \u00d7 18 col-\numns (see Table 7)\n3.LOCO_LFs.json (573.1 MB): a JSON file containing the\nfull set of lexical features. 96,746 rows (documents) \u00d7 288\ncolumns ( NEmpath =1 9 4 ; NLIWC =9 3 )\n4.topic_gamma.json (963.7 MB): a JSON file containing\ntopics \u2019gamma values. 96,746 rows (documents) \u00d7 600\ncolumns (topics)\n5.topic_by_time.pdf (169.6 MB): a PDF file containing\nplots of topics \u2019gamma values over time (from 1995 to\n2020). It contains 600 pages.\n6.topic_description.json (188.2 KB): a JSON file contain-\ning detailed descriptions of topics. 600 rows (topics) \u00d7 12\ncolumns (see SM6)\nExploring LOCO \u2019s features\nIn this section, we explore LOCO \u2019s features and provide ex-\namples on how to handle LOCO \u2019s variables and subset cor-\npus. Some of these analyses are descriptive in nature and offer\na way to visually explore to what extent LOCO \u2019s data relate to\nthe external world, such as visualizing the evolution of LDA\ntopics through time (see \u201cTopic analyses \u201dsection) or explor-\ning to what extent the language used in LOCO \u2019sd o c u m e n t s\noverlaps with the language used in social media (see\n\u201cTowards corpora of CT texts \u201dsection). Other analyses are\nmore explorative, such as testing whether mentioning conspir-\nacy in mainstream documents affects lexical features (see\n\u201cEffect of mentioning conspiracy \u201dsection) or whetherconspiracy-representative documents are in fact different from\nother conspiracy documents in terms of lexical features and\nspread (i.e., Facebook shares, see \u201cProperties of representative\nconspiracy documents \u201dsection). Lastly, we also explore to\nwhat extent LOCO \u2019s higher-level metadata might provide in-\nsights into psychological processes by analyzing the behavior\nof websites \u2019users (see \u201cWebsite incoming traffic \u201dsection).\nOverall, these analyses not only suggest how to use LOCO,\nbut also offer insights on the language of conspiracy and the\npsychology of conspiracy websites users.\nTopic analyses\nEach document in LOCO is associated with a vector that en-\ncapsulates and quantifies the semantic content, namely the\nLDA topics. While in the main dataset (LOCO.json) we pro-vide for each document only the label of the most prevalent\ntopic (one for each level of topic resolution, that is k=100, k\n=200, and k= 300), in a separate dataset\n(topic_gamma.json) each document is associated with the\ngamma values for all 600 LDA topics extracted. In this sec-\ntion, we explore how LDA topics reflects real-world events byvisually inspecting how these LDA topics develop through\ntime for documents whose date was recorded. This reasoning\nis supported by the fact that, because texts are capable ofshowing cultural patterns (Lansdall-Welfare et al., 2017 ;L i\net al., 2019 ,2020 ;M i c h e le ta l . , 2011 ), a significant social\nevent should be reflected in the texts \u2019topic time series. To\nexplore this possibility, we selected a set of topics that are\nassociated with a specific event (instead of non-event-specific topics such as AIDS or Illuminati) such as the death\nof societally significant people: Osama bin Laden (2011-05-\n02, topic k300_50), Michael Jackson (2009-06-25, k300_18),George H.W. Bush (2018-11-30, k300_146), and Saddam\nHussein (2006-12-30, k300_134); outbreaks of pandemics\nsuch as Zika virus (2016-02-01, k300_169) and coronavirusTable 5 Differences between conspiracy and mainstream website metrics\nMainstream Conspiracy t-test statistics (raw) t-test statistics (log)\nM (SD) NM (SD) Nt p d t p d\nTotal monthly visits 102,285,513 (191,306,614) 92 965,242 (2,115,315) 28 5.08 *** 1.10 14.00 *** 3.02\nGlobal rank 7313 (21,765) 89 211,904 (168,890) 28 \u22126.39 *** 1.39 \u201317.11 *** 3.71\nWebsite size 6,844,908 (16,049,205) 92 6224 (12,918) 58 4.09 *** 0.69 18.43 *** 3.09FB projected shares 3,213,458,353 (9,348,074,961) 92 27,11,190 (14,540,274) 58 3.29 ** 0.55 12.78 *** 2.14Traffic, direct\n\u202028.95 (13.45) 92 57.55 (21.57) 28 \u20136.63 *** 1.43\nTraffic, search\u202056.83 (17.49) 92 13.82 (10.44) 28 16.00 *** 3.45\nTraffic, social\u20208.08 (5.58) 92 18.4 (19.28) 28 \u20132.8 ** 0.60\nNote. Differences tested with Welch's unequal variances t-test. Log transformation was applied to highly skewed variables after having added a constant\n1 to avoid -Infinite values when the raw score was zero.\u2020Values expressed as percentages and not log-transformed. d:C o h e n \u2019sd. FB: Facebook. Website\nsize is expressed in number of webpagesBehav Res (2022) 54:1794 \u20131817 1807\nTable 6 LOCO dataset variables description\nVariable name (% empty/missing\nvalues, if any)Variable description\ndoc_id Six-character hexadecimal sequence of document unique identification number. The first character stores the source: C\nstands for conspiracy (e.g., C0004d) and M stands for mainstream (e.g., M095eb)\nURL URL associated with the documentWebsite The website from which the document was extractedseeds (2.26%) The seeds we used to gather documents. The page was returned by all the keywords listed in this variable (\nN=47)\ndate (33.98%) The date the webpage was uploaded or uploaded (format: YYYY-MM-DD)subcorpus Either conspiracy or mainstream (\nNconspiracy =23,937; Nmainstream =72,806).\ntitle (0.11%) Title of the documenttxt Document text (see text statistics in\nTable 2)\ntxt_nwords Number of words\ntxt_nsentences Number of sentencestxt_nparagraphs Number of paragraphstopic_k100 The topic ID with highest gamma value within k100 LDA (\nN=100 unique, e.g., k100_24)\ntopic_k200 The topic ID with highest gamma value within k200 LDA ( N=200 unique, e.g., k200_75)\ntopic_k300 The topic ID with highest gamma value within k300 LDA ( N=300 unique, e.g., k300_192)\nmention_conspiracy Occurrences count for the word \u201cconspir* \u201din text, see \u201cMentioning conspiracy \u201d\u201dsection\nconspiracy_representative Logical. TRUE ( N=4227) if the conspiracy document is representative\ncosine_similarity Cosine similarity values for conspiracy documents (values > mean + 1 SD are considered representative)\nFB_shares (0.01%) URL \u2019sF a c e b o o ks h a r e s\nFB_comments (0.01%) URL \u2019sF a c e b o o kc o m m e n t s\nFB_reactions (0.01%) URL \u2019s Facebook reactions\nNote. Percentages of empty/missing values are calculated on the list of documents ( N=9 6 , 7 4 3 )\nTable 7 LOCO \u2019s website metadata variables description\nVariable name (% empty/missing values, if\nany)Variable description\nWebsite Website name ( N=150)\nURL URL associated with the website domainn_webpages Overall number of webpages in website obtained by Google search (see \u201c\nWebsite metrics \u201dsection)\nMBFC_political_orientation (69%) Political orientation. Left ( N=4), left_center ( N=19), least_biased ( N=15), right_center ( N=4), right ( N=5)\nMBFC_factual_reporting (21%) Factual reporting. Very_low ( N=10), low ( N=43), mixed ( N=16), mostly_factual ( N=4), high ( N=35), very_high ( N=\n11)\nMBFC_conspiracy Logical. If TRUE ( N=58), website is conspiracy\nMBFC_pseudoscience (62%) For conspiracy websites only. Zero ( N=1), mild ( N=2), moderate ( N=9), strong ( N=16), quackery ( N=29)\nMBFC_proscience Logical. TRUE ( N=16) if website is labeled as pro-science\nSW_total_visits (20%) Total visits, desktop and mobile web aggregatedSW_global_rank (22%) Traffic rank of website, as compared to all other websites in the worldSW_Category (20%) Website category (e.g., news_and_media,\nN=60; health, N=16, science_and_education, N=13)\nSW_traffic_direct (20%) Percentage of direct desktop incoming traffic (from typing the URL in a browser)SW_traffic_search (20%) Percentage of search desktop incoming traffic (from a search engine)SW_traffic_social (20%) Percentage of direct desktop incoming traffic (from a URL on social media)FB_shares_homepage Facebook shares of homepage (see discussion in SM9)FB_shares_estimated Estimated overall Facebook shares given total number of website \u2019sw e b p a g e s( s e e \u201c\nFacebook shares \u201dsection)\nNote. Percentages of empty/missing values are calculated on the list of websites ( N=1 5 0 )1808 Behav Res (2022) 54:1794 \u20131817\n(2020-03-11, k300_200 and k300_288); and other significant\nsocietal events such as the 9/11 terroristic attack (2001-09-11,\nk300_72), the Sandy Hook school shooting (2012-12-14,k300_290), and Pizzagate (2016-11-01, when it went viral,\nk300_192). In Fig. 2, for all documents in LOCO provided\nwith upload/creation data, topic patterns (i.e., gamma valueson the Yaxis) are shown within a time span of 25 years, from\n1995 to 2020 (first three rows) and for 2020 (fourth row for\ncoronavirus-related topics) from January to July, whenLOCO \u2019s data collection ended.\nLexical features\nOverlap with Reddit users \u2019language\nIdeally, a corpus must be representative and replicable, mean-\ning that the sampled data should represent the full range of\nvariability of the population from which the sample is drawn.If our corpus successfully represents CTs, then its content\nshould mirror the content of comments and threads posted\nby conspiracy believers on social media. To this aim, we com-pared the lexical features extracted from LOCO \u2019sd o c u m e n t s\n(LOCO_LFs.json) with those extracted from comments on\nReddit by Klein et al. ( 2019 ). Although user discussions on\nconspiracy forums are not conspiracy per se, we expect a\ncertain overlap in language features with LOCO documents.\nThis is because, while forums do not offer adequate space tofully develop argumentative discourses, a conspiracy believer\ncan nevertheless express a conspiratorial worldview through\nlanguage use (e.g., deception: \u201cThey are hiding the cure from\nus for their own profit!! \u201d), even in discussion not related to\nconspiracy. In fact, Klein et al. ( 2019 ) compared language\nfeatures of a group of users who posted in the r/conspiracysubreddit with those from a carefully matched control group\nof users who never posted in r/conspiracy. Although we do\nnot know to what extent users who posted in the r/conspiracysubreddit endorse CTs, Klein and colleagues found language\ndifferences associated with a conspiratorial mindset (e.g.,\npower, deception, dominance) that sees hidden powerful andmalevolent enemies at work.\nWe proceeded with replicating the method of Klein et al.\n(2019 ) on LOCO by comparing our two subcorpora and ex-\nplored whether the same patterns emerged. Similar to their\nwork, we used the lexical features derived from Empath and\ntested differences between conspiracy and mainstream docu-\nments on the 194 Empath categories. Then, we used Welch \u2019s\nt-test and computed Cohen \u2019sdfor each test on the variables\nthat yielded a significant difference at p< .00026 (Bonferroni\ncorrection for 194 tests). Note that here we are not testing any\nparticular hypothesis, but provide this as exploratory analysisto guide future research. Results are shown in Fig. 3.O nt h e\ntop (A), only variables that produced an effect size of d>. 2 0\nare displayed, arranged in decreasing order. On the bottom(B), each variable was scaled to zvalues, and mean values\nare shown for different website categories:\nconspiracy_representative ( N= 4,227), other conspiracy ( N\n= 19,710), biased_LR (aggregating documents biased to-\nwards either the left or right, N= 31,928), least-biased ( N\n= 14,180), and pro-science ( N= 11,440).\n17\nLexical differences between LOCO conspiracy and main-\nstream documents overlap with those between Reddit groups\nfound by Klein and collaborators (Fig. 3a). Among the lexical\ncategories characterizing conspiracy language (i.e., positive\nvalues in Fig. 3a), half of them emerged as overlapping be-\ntween the two datasets. In LOCO, other lexical categorieswere higher in conspiracy (vs. mainstream), such as divine\nandworship that correlate with religion (r=. 9 2 , r=. 9 5 ,\nrespectively, in our dataset) found in Klein, and killand hate\nthat correlate with death (r=. 7 2 , r=. 4 4 ) a n d\nnegative_emotion (r=. 7 1 ; r= .76) found in Klein but not\nin LOCO. It is also worth noting that representative conspira-cy documents, on average, display an exaggeration of the\n\u201caverage \u201dconspiratorial language as exemplified from the\nmeans further departing from zero (this will be further ex-plored in \u201cProperties of representative conspiracy documents \u201d\nsection).\nEffect of mentioning conspiracy\nWe explored the possibility that mentioning conspiracy in the\ntext would increase conspiratorial language (see \u201cMentioning\n\u201cconspiracy \u201dsection). To this aim, we run multiple t-tests\nusing as dependent variables the 31 lexical categories that\nyielded an effect size d> .20 from the previous section (see\n\u201cOverlap with Reddit users \u2019\u201dsection). In doing so, we used\ntwo different LOCO subcorpora: one (raw) which is based on\nthe whole mainstream data ( N\nmainstream = 72,806) and one\n(cleaned) from which we removed all mainstream documentscontaining at least one instance of the word \u201cconspir* \u201d(Final\nN\nmainstream = 67,775). Note that we removed mentions of\nconspiracy only in the mainstream documents because weaimed to test the difference between the subcorpora removing\npotential conspiratorial language from mainstream docu-\nments, so as to obtain a mainstream subcorpus cleaned ofconspiratorial language. We reasoned that conspiracy docu-\nments deliver conspiracy language even without mentioning\nthe word \u201cconspir*. \u201dFrom each test, we extracted the effect\nsize (Cohen \u2019sd) and then compared the changes in d,w i t ha\npaired t-test, from the raw to the cleaned dataset. Results show\nan overall increase in the effect sizes, t\n(30)=5 . 0 8 , p<. 0 0 1 ,\nsuggesting that cleaning the mainstream subcorpus from\n17Note that the sum of pro-science, least-biased, and biased documents is\n57,575 (and not 72,806, the total of mainstream documents). This is becausenot all websites are rated by MBFC, and therefore documents from thesewebsites do not compare in plot B.Behav Res (2022) 54:1794 \u20131817 1809\ndocuments that mention conspiracies amplifies differences in\nlanguage features between the two subcorpora (see SM10 for\ndetails).\nWe finally explored whether mentioning conspiracy had an\neffect on lexical features. To this aim, we extracted the top\nfour Empath categories that in the previous analysis (see par-agraph above) had yielded the largest changes in effect size,\nnamely crime ,terrorism ,deception ,a n d stealing , and tested\nthe correlation (on log-transformed variables, but see SM10for non-log-transformed results) between the number of men-\ntions of conspiracy and lexical variables. The results showed a\npositive relationship: crime: r=. 3 1 ; t e r r o r i s m : r=. 3 3 ; d e -\nception: r= .21; and stealing: r= .13. Overall, these tests\nshow that mentioning conspiracy, even in mainstream docu-ments, affects language features. Therefore, we suggest that\nresearchers carefully evaluate whether or not to include main-\nstream documents containing the word \u201cconspir* \u201din their\nanalyses.Properties of representative conspiracy documents\nWe explored to what extent the representative set of conspir-\nacy documents ( N= 4,227) differs from the other conspiracy\ndocuments ( N= 19,710) in terms of lexical features. To this\naim, after subsetting LOCO to only conspiracy documents, werun a series of linear mixed-effects models using the lme4\n(Bates et al., 2015 )a n dt h e lmerTest (Kuznetsova et al.,\n2017 ) R packages. In each model, we specified as dependent\nvariables the LIWC ( N=9 3 ) a n d E m p a t h ( N=1 9 4 ) c a t e g o -\nries, and as fixed effects the dichotomous representativeness\npredictor. As random intercept, we specified both the websites\nfrom which documents were extracted and the topic label with\nthe highest gamma value for k= 100 because, being less\nspecific, it provides a more inclusive clustering that aggre-\ngates similar topics. In other words, while for k=3 0 0 w e\nwould have had several LDA topics revolving around atheme, with a lower topic resolution, topics are more general\nFig. 3 Differences in lexical features between conspiracy and mainstream\ndocuments aEffect sizes that yielded a Cohen \u2019sd> .20 from t-tests\nbetween conspiracy and mainstream documents on Empath lexical\ncategories. Positive effect sizes indicate that the category value is higherin conspiracy documents. A star indicates that the category emerged as\nhaving d> .20 also in Klein et al. ( 2019 ).bComparison of means [and\n95% CIs] for the same set of variables (scaled to zvalues) across different\ndocument categories1810 Behav Res (2022) 54:1794 \u20131817\n(we replicated the same analyses with k= 200 topics, and\nresults are not visibly different, see SM11). Before entering\nthe model, the dependent variables were scaled to zvalues.\nStandardized \u03b2estimates are displayed in Fig. 4for only the\ndependent variables that were significant at p< .00017\n(Bonferroni correction for 287 tests) by the dichotomous pre-dictor. Positive estimates indicate that the category is higher in\nthe representative subset of conspiracy documents.\nThe representative conspiracy subset is generally more\nemotionally charged than the other documents, as displayed\nby the higher value for the category related to affective pro-\ncesses (LIWC category affect ), and more specifically to neg-\native emotions (LIWC categories anger ,swear ,negemo ).\nRepresentative conspiracy documents, as compared with the\nnon-representative conspiracy documents, display a prototyp-ical language of conspiracy focused on power, dominance,\nand aggression (Empath categories deception ,dominant\nhierarchical ,kill,hate,order ,power ,aggression ,a n d rage).\nAs for the rhetorical style used by the representative subset,\nwe observe higher values for certainty (category certain ), and\ninterrogative (category interrog ) language, along with higher\nuse of question and exclamation marks (categories Exclam ,\nQMark ). This is in line with the observation that the rhetorical\nstyle of conspiracy narratives is built upon refutational strate-\ngies based on questioning the dubious version of the official\nstory while highlighting the lack of answers from officialsources (Oswald, 2016 ).\nIn line with research on social motives underlying belief in\nCTs (Douglas et al., 2019 ), the higher use of weandthey,along with affiliative (LIWC category affiliation ) and social\n(category social ) language, suggests a process of social iden-\ntification of the ingroup ( we) by exclusion from the outgroup\n(they).\nOverall, as already seen in Fig. 3and in the work of Klein\net al. ( 2019 ), the representative conspiracy documents seem to\nbe an exaggerated version of an average conspiracy docu-\nment, characterized by language of power, action, and domi-\nnance. They are at the same time less likely to display non-conspiratorial language as exemplified by lower values for\ncategories such as tourism ,vacation ,\nurban , and morning .\nInterestingly, these patterns overlap with those found onTwitter, in which lexical differences between conspiracy and\nscience influencers were identified in the use of negative emo-\ntion (e.g., anger) and a focus on topics such as death, religion,and power (Fong et al., 2021 ).\nIf the representative documents are rhetorically appealing\nand emotionally loaded, then we can expect that they willspread more successfully than the other, less representative\ndocuments. This reasoning is also in line with the fact that\nemotional content is a successful feature of narrative sticki-ness and transmission (Franks et al., 2013 ; Heath et al., 2001 ).\nTherefore, we tested whether the representative subset of con-\nspiracy documents spread more than non-representative con-\nspiracy documents. To this aim, we fit a linear mixed-effects\nmodel predicting Facebook shares (log-transformed). We setconspiracy representativeness as predictor along with website\ntotal visits as covariate while specifying a random intercept for\nwebsites. Results showed that the subset of representative\nFig. 4 Differences in lexical features between high- and low-\nrepresentative conspiracy documents. Positive \u03b2estimates indicate that\nthe category is higher among cons piracy documents that are morerepresentative of the conspiracy corpus as measured by their document\ncosine similarity with other conspiracy documents in the corpusBehav Res (2022) 54:1794 \u20131817 1811\nconspiracy documents was more shared on Facebook com-\npared to the other conspiracy documents, \u03b2=0 . 1 2 1 , SE=\n0.017, t=7 . 0 7 5 , p<. 0 0 1 .\nWebsite incoming traffic\nBesides the texts themselves and the documents and their\nmetadata, LOCO is also provided with higher-level metadata,\nnamely information about its constituent websites. Such a setof variables (contained in the file website_metadata.json)\nmight be useful for testing hypotheses at the website level.\nFor example, here, we describe the behavior of conspiracyand non-conspiracy communi ties from websites traffic\ninformation.\nAnalysis of online social media shows that users tend to\naggregate in echo chambers that are homogeneous clusters of\ncommunities of interest (Bessi, Coletto, et al., 2015a ; Brugnoli\net al., 2019 ; Del Vicario, Bessi, et al., 2016a ). Such clustering\nis reinforced in online and offline social networks (Del Vicario\net al., 2017 ) whereby a like-minded trusted node in the social\nnetwork (a friend or a page followed on Facebook) sharescontent that adheres to a system of beliefs. Moreover, within\nonline social networks, users access information through a\nnarrower spectrum of sources compared to web searches(Nikolov et al., 2015 ), meaning that being embedded within\na social bubble reduces exposure to different viewpoints.\nWhen users of conspiracy Facebook pages are exposed todebunking information, they increase traffic towards\nconspiracy-like content (Zollo et al., 2017 ). This behavior\nsuggests a confirmation bias: people avoid cognitive disso-nance while searching for rein forcement (Brugnoli et al.,\n2019 ;H i l l s , 2019 ).\nWebsite incoming traffic provides similar information\nabout user behavior. For example, direct traffic may indicate\na certain level of loyalty or at least that the user knows the\nwebsite or has learned about it through their social contacts(Pauwels et al., 2016 ). When a website is reached from a\nsearch engine, the website is not necessarily known to the\nuser. Put differently, how people arrive at a website may in-directly reveal information about their prior knowledge, be-\nliefs, and social community. If echo chambers provide links to\nbelief confirming content, then a confirmation bias theory ofconspiratorial thinking would predict that users of conspirato-\nrial websites are more likely to arrive there via a bookmarked\nURL or through online social networks than through impartial\nsearch engines.\nTo explore this possibility, we analyze user behavior\nthrough website incoming traffic (see \u201cWebsite metrics \u201dsec-\ntion). Because of a link between confirmation bias and belief\nin CTs (Del Vicario et al., 2017 ; Del Vicario, Bessi, et al.,\n2016a ; Marchlewska et al., 2018 ; Meppelink et al., 2019 ;\nZollo et al., 2017 ), we expect that conspiracy websites display\nhigher levels of direct traffic and lower levels of search traffic.Conspiracy ideas spread within homogeneous social media\ncommunities of like-minded believers who share conspiracy\nnarratives; thus we also expect that traffic from social media(i.e., incoming traffic from a social media link) is higher in\nconspiracy compared to non-conspiracy websites. Moreover,\nbecause of known links between partisanship polarization andecho chambers (Stroud, 2010 ), confirmation bias (Westen\net al., 2006 ), and belief in CTs (van Prooijen et al., 2015 )w e\nexplored whether politically polarized websites (on both leftand right sides of the spectrum) show patterns comparable to\nthose of conspiracy websites compared to least biased\nwebsites.\nWe selected the websites (for which traffic data were col-\nlected) labeled as conspiracy ( N= 28), least biased ( N=1 5 ) ,\nand pro-science ( N= 16), and aggregated the websites lean-\ning on either the left or right of the political spectrum, labeling\nthem \u201cbiased_LR \u201d(N\n= 32). Analysis of variance and post\nhoc comparisons using Tukey \u2019s honestly significant differ-\nence (HSD) test were used to test differences in traffic type\nbetween website categories. Direct traffic was highest for con-\nspiracy ( M=5 7 . 5 5 , SD= 21.57) and lowest for pro-science\n(M=1 3 . 3 5 , SD=1 2 . 1 2 ) , F(3,87) =2 3 . 4 1 , p< .001. All post\nhoc differences among the four categories were significant at\np< .01 except differences between least biased and biased\nwebsites ( p= .92) and between pro-science and least biased\nwebsites ( p= .09). As for traffic from search engines, the\nhighest rate was on pro-science websites ( M=7 0 . 8 0 , SD=\n14.80) and the lower on conspiracy ones ( M=1 3 . 8 2 , SD=\n10.44), F(3,87) =7 0 . 4 6 , p< .001. All differences were signif-\nicant ( ps < .001) except those between least biased and biased\nwebsites (p = .76). Incoming traffic from social media sites\nwas higher in conspiracy ( M=1 8 . 4 0 , SD=1 9 . 2 8 ) t h a n i n\npro-science ( M=5 . 4 4 , SD=4 . 7 6 ) , F(3,87) =4 . 9 3 , p<. 0 1 ;\nall other differences were nonsignificant. Results are shown in\nFig.5.\nThese results suggest that CT websites are predominantly\nreached by the users typing the URL on their browser (or by\nrecalling the URL from bookmarks) or following a link postedon social media. On the contrary, pro-science websites are\nmostly accessed from web searches. Differences in access\nroutes between biased and least-biased websites were not sig-nificant. This indicates that though users of conspiracy\nwebsites are most similar to users of biased websites, they\nare nonetheless in a category of their own.\nDiscussion and conclusions\nLOCO is a multilevel, richly annotated, topic-matched corpusof CTs composed of nearly 100,000 documents, with a total of88 million words. This represents a rich source of data for\nbetter understanding the content and spread of CTs. LOCO\nis also freely available ( https://osf.io/snpcg ). Being for the1812 Behav Res (2022) 54:1794 \u20131817\nmost part composed of texts with additional metadata and\nlexical features, LOCO is conceptualized as a turnkey\nresource from which researchers can test hypotheses, further\nextract features, and/or build classification and predictivemodels. To this end, while building LOCO, we aimed at\nobtaining a large yet representative set of documents that also\nprovided a set of metadata that could be used ad hoc to parti-\ntion LOCO prior to analysis.\nA large portion of the present paper has focused on thor-\noughly describing the methodology on which LOCO was\nbuilt. As we have built LOCO upon previous works \u2019strengths\nand weaknesses, we believe that a meticulous method descrip-tion will also allow future research to benefit from LOCO \u2019s\nstrengths and weaknesses, opening up possibilities for further\ndata collection in the field of CT studies.\nOur analysis of LOCO demonstrates its potential by mak-\ning a number of contributions to the conspiracy research liter-\nature: (1) By mapping topics on document dates, we show thatLOCO \u2019s documents track important social events. (2) We\nreplicated the lexical analysis of previous work, finding an\noverlap between LOCO documents and comments on onlinesocial media. (3) We find that mainstream documents that\nmention conspiracy display conspiratorial language. (4) We\nhave extracted and analyzed the language of prototypical con-spiracy documents and find that these amplify features of con-\nspiratorial language. (5) We find a pattern of website traffic\nindicating active online social media communities and thepotential for confirmation bias via direct traffic. And (6) we\nfind that conspiracy websites show statistically differentpatterns of web traffic than biased (politically left or right)\nwebsites, suggestive of a difference in their users. At the same\ntime, we have provided suggestions on how to use LOCO tomake new contributions.\nBecause we relied on a multitude of heterogeneous\nmethods, we also believe that each of our corpus constructionstages can benefit data collection for text analysis research in\ngeneral. While we built LOCO on a specific narrative genre,\nnamely CTs, the same methodology, or part of it, can beemployed for other purposes. For example, researchers may\nbe interested in comparing a list of websites against another\none, or comparing webpages returned by specific sets ofseeds, or, as we have done, do both at the same time by cross-\ning lists of websites and seeds. We have also shown that it is\npossible to rely on several tools to enrich a web-based set oftext with meta-data, such as political biases and fact accuracy\n(from MBFC), measures of spread (from SC), and popularity\nand traffic (from SW). Other freely available tools we haveemployed are available for text extraction ( Goose ) and analy-\nses such as Empath, TAACO, as well as the quanteda and the\ntopicmodels packages.\nBecause we also provided the URLs associated with each\ndocument, it is potentially possible to extract HTML data in\norder to analyze web markup features as previous work has\ndone on fake news (Castelo et al., 2019 ). Moreover, different\nsets of psycholinguistic measures can be extracted fromLOCO \u2019s texts, such as word norms for valence, arousal, and\ndominance (Warriner et al., 2013 ), imageability (Cortese &\nFugett, 2004 ), frequency (Brysbaert & New, 2009 ), concrete-\nness (Brysbaert et al., 2014 ), and age of acquisition\n(Kuperman et al., 2012 ).\nIn conclusion, LOCO is a rich source that helps to better\nunderstand the content of CTs. Here, we have explored how\nCT users behave online and which language features are associ-\nated with the spread of documents over social media, and wesketched a preliminary overview of the lexical fingerprint of the\n(prototypical) conspiratorial language. Therefore, LOCO \u2019sc o n -\ntribution is multiple: while providing data mainly for lexicalanalysis and document spread, it can also help to reveal psycho-\nlogical processes. For the sake of global public interest, given the\ndetrimental potential consequences associated with the endorse-ment of CTs, understanding how CTs spread is critical to ulti-\nmately limiting their negative consequences.\nSupplementary Information The online version contains supplementary\nmaterial available at https://doi.org/10.3758/s13428-021-01698-z .\nFunding Open Access funding provided by Universit\u00e9 de Neuch\u00e2tel.\nDeclarations\nFinancial Disclosure None of the authors have any financial relation-\nships relevant to this article to disclose.\nFig. 5 Types of incoming traff ic by website category .Average of\nwebsites \u2019percentages of incoming traffic (direct, from web search, and\nfrom social media) by website categories. Error bars represent the\nstandard error of the meanBehav Res (2022) 54:1794 \u20131817 1813\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-tation, distribution and reproduction in any medium or format, as long as\nyou give appropriate credit to the original author(s) and the source, pro-\nvide a link to the Creative Commons licence, and indicate if changes weremade. The images or other third party material in this article are includedin the article's Creative Commons licence, unless indicated otherwise in a\ncredit line to the material. If material is not included in the article's\nCreative Commons licence and your intended use is not permitted bystatutory regulation or exceeds the permitted use, you will need to obtainpermission directly from the copyright holder. To view a copy of this\nlicence, visit http://creativecommons.org/licenses/by/4.0/ .\nReferences\nAllen, C., & Murdock, J. (2020). LDA Topic Modeling: Contexts for the\nHistory & Philosophy of Science .http://philsci-archive.pitt.edu/\n17261/\nAston, G., & Burnard, L. (1998). The BNC Handbook: Exploring the\nBritish National Corpus with SARA. In: English Language and\nLinguistics . Edinburgh University Press.\nAupers, S. (2012). \u2018Trust no one \u2019: Modernization, paranoia and conspir-\nacy culture. European Journal of Communication ,27(1), 22 \u201334.\nhttps://doi.org/10.1177/0267323111433566\nAVAAZ. (2020). Facebook \u2019s Algorithm: A Major Threat to Public\nHealth .https://secure.avaaz.org/campaign/en/facebook_threat_\nhealth/\nBaly, R., Karadzhov, G., Alexandrov, D., Glass, J., & Nakov, P. (2018).\nPredicting Factuality of Reporting and Bias of News Media Sources.\nProceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing , 3528 \u20133539. https://doi.org/10.\n18653/v1/D18-1389\nBangerter, A., Wagner-Egger, P., & Delouv\u00e9e, S. (2020). The Spread of\nConspiracy Theories. In M. Butter & P. Knight (Eds.), Routledge\nHandbook of Conspiracy Theories (pp. 2016 \u20132218). Routledge.\nBarkun, M. (2017). President Trump and the \u201cFringe \u201d.Terrorism and\nPolitical Violence ,29(3), 437 \u2013443. https://doi. org/10.1080/\n09546553.2017.1313649\nBaroni, M., Bernardini, S., Ferraresi, A., & Zanchetta, E. (2009). The\nWaCky wide web: a collection of very large linguistically processedweb-crawled corpora. Language Resources and Evaluation ,43(3),\n209\u2013226. https://doi.org/10.1007/s10579-009-9081-4\nBarron, A. T. J., Huang, J., Spa ng, R. L., & DeDeo, S. (2018).\nIndividuals, institutions, and innovation in the debates of theFrench Revolution. Proceedings of the National Academy of\nSciences ,115(18), 4607 \u20134612. https://doi.org/10.1073/pnas.\n1717729115\nBates, D., M\u00e4chler, M., Bolker, B., & Walker, S. (2015). Fitting linear\nmixed-effects models using lme4. Journal of Statistical Software ,\n67(1), 1\u201348.https://doi.org/10.18637/jss.v067.i01\nBessi, A. (2016). Personality traits and echo chambers on facebook.\nComputers in Human Behavior ,65, 319\u2013324.\nhttps://doi.org/10.\n1016/j.chb.2016.08.016\nBessi, A., Scala, A., Rossi, L., Zhang, Q., & Quattrociocchi, W. (2014).\nThe economy of attention in the age of (mis)information. Journal of\nTrust Management ,1(1), 12. https://doi.org/10.1186/s40493-014-\n0012-y\nBessi, A., Coletto, M., Davidescu, G. A., Scala, A., Caldarelli, G., &\nQuattrociocchi, W. (2015a). Science vs Conspiracy: CollectiveNarratives in the Age of Misinformation. PLOS ONE ,10(2),\ne0118093. https://doi.org/10.1371/journal.pone.0118093\nBessi, A., Zollo, F., Del Vicario, M., Scala, A., Caldarelli, G., &\nQuattrociocchi, W. (2015b). Trend of Narratives in the Age ofMisinformation. PLOS ONE ,10(8), e0134641. https://doi.org/10.\n1371/journal.pone.0134641\nB e t s c h ,C . ,U l s h \u00f6 f e r ,C . ,R e n k e w i t z ,F . ,&B e t s c h ,T .( 2 0 1 1 ) .T h e\nInfluence of Narrative v. Statistical Information on PerceivingVaccination Risks. Medical Decision Making ,31(5), 742 \u2013753.\nhttps://doi.org/10.1177/0272989X11400419\nBiddlestone, M., Green, R., & Douglas, K. M. (2020). Cultural orienta-\ntion, power, belief in conspiracy theories, and intentions to reducethe spread of COVID-19. British Journal of Social Psychology ,\n59(3), 663 \u2013673. https://doi.org/10.1111/bjso.12397\nBird, S., Klein, E., & Loper, E. (2009). Natural language processing with\nPython: analyzing text with the natural language toolkit .\u201cO\u2019Reilly\nMedia, Inc. \u201d\nBlei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation.\nJournal of Machine Learning Research ,3,9 9 3\u20131022.\nBogart, L. M., Wagner, G., Galvan, F. H., & Banks, D. (2010).\nConspiracy Beliefs About HIV Ar e Related to Antiretroviral\nTreatment Nonadherence Among African American Men WithHIV. JAIDS Journal of Acquired Immune Deficiency Syndromes ,\n53(5), 648 \u2013655. https://doi.org/10.1097/QAI.0b013e3181c57dbc\nBrugnoli, E., Cinelli, M., Quattrociocchi, W., & Scala, A. (2019).\nRecursive patterns in online echo chambers. Scientific Reports ,\n9(1), 20118. https://doi.org/10.1038/s41598-019-56191-7\nBrysbaert, M., & New, B. (2009). Moving beyond Ku \u010dera and Francis: A\ncritical evaluation of current word frequency norms and the intro-\nduction of a new and improved word frequency measure forAmerican English. Behavior Research Methods ,41(4), 977 \u2013990.\nhttps://doi.org/10.3758/BRM.41.4.977\nBrysbaert, M., Warriner, A. B., & Kuperman, V. (2014). Concreteness\nratings for 40 thousand generally known English word lemmas.Behavior Research Methods ,46(3), 904 \u2013911. https://doi.org/10.\n3758/s13428-013-0403-5\nButter, M., & Knight, P. (2020). Routledge Handbook of Conspiracy\nTheories (M. Butter & P. Knight (eds.)). Routledge.\nCastelo, S., Santos, A., Almeida, T., Pham, K., Freire, J., Elghafari, A., &\nNakamura, E. (2019). A topic-agnostic approach for identifying fake\nnews pages. The Web Conference 2019 - Companion of the World\nWide Web Conference, WWW 2019 .https://doi.org/10.1145/\n3308560.3316739\nCinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, W.,\n& Starnini, M. (2021). The echo chamber effect on social media.\nProceedings of the National Academy of Sciences ,118(9),\ne2023301118. https://doi.org/10.1073/pnas.2023301118\nClarke, S. (2007). Conspiracy Theories and the Internet: Controlled\nDemolition and Arrested Development. Episteme ,4(2), 167 \u2013180.\nhttps://doi.org/10.3366/epi.2007.4.2.167\nCortese, M. J., & Fugett, A. (2004). Imageability ratings for 3,000 mono-\nsyllabic words. Behavior Research Methods, Instruments, &\nComputers ,36(3), 384 \u2013387. https://doi.org/10.3758/BF03195585\nCrossley, S. A., Kyle, K., & McNamara, D. S. (2016). The tool for the\nautomatic analysis of text cohesion (TAACO): Automatic assess-\nment of local, global, and text cohesion. Behavior Research\nMethods ,48(4), 1227 \u20131237. https://doi.org/10.3758/s13428-015-\n0651-7\nCrossley, S. A., Kyle, K., & Dascalu, M. (2019). The Tool for the\nAutomatic Analysis of Cohesion 2.0: Integrating semantic similarityand text overlap. Behavior Research Methods ,51(1), 14 \u201327.https://\ndoi.org/10.3758/s13428-018-1142-4\nde Vries, E., Schoonvelde, M., & Schumacher, G. (2018). No Longer\nLost in Translation: Evidence that Google Translate Works forComparative Bag-of-Words Text Applications. Political Analysis ,\n26(4), 417 \u2013430. https://doi.org/10.1017/pan.2018.26\nDel Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G.,\nStanley, H. E., & Quattrociocchi, W. (2016a). The spreading ofmisinformation online. Proceedings of the National Academy of1814 Behav Res (2022) 54:1794 \u20131817\nSciences ,113(3), 554 \u2013559. https://doi.org/10.1073/pnas.\n1517441113\nDel Vicario, M., Vivaldo, G., Bessi, A., Zollo, F., Scala, A., Caldarelli,\nG., & Quattrociocchi, W. (2016b). Echo Chambers: Emotional\nContagion and Group Polarization on Facebook. Scientific\nReports ,6(1), 37825. https://doi.org/10.1038/srep37825\nDel Vicario, M., Scala, A., Caldarelli, G., Stanley, H. E., &\nQuattrociocchi, W. (2017). Modeling confirmation bias and polari-zation. Scientific Reports ,7(1), 40391. https://doi.org/10.1038/\nsrep40391\nDouglas, K. M., & Sutton, R. M. (2011). Does it take one to know one?\nEndorsement of conspiracy theories is influenced by personal will-\ningness to conspire. British Journal of Social Psychology ,50(3),\n544\u2013552.\nDouglas, K. M., & Sutton, R. M. (2018). Why conspiracy theories matter:\nA social psychological analysis. European Review of Social\nPsychology ,29(1), 256 \u2013298. https://doi.org/10.1080/10463283.\n2018.1537428\nDouglas, K. M., Uscinski, J. E., Sutton, R. M., Cichocka, A., Nefes, T.,\nAng, C. S., & Deravi, F. (2019). Understanding ConspiracyTheories. Political Psychology ,40(S1), 3 \u201335.https://doi.org/10.\n1111/pops.12568\nEicher, V., & Bangerter, A. (2015). Social representations of infectious\ndiseases. In G. Sammut, E. Andreouli, G. Gaskell, & J. Valsiner\n(Eds.), The Cambridge Handbook of Social Representations (pp.\n385\u2013396). Cambridge University Press. https://doi.org/10.1017/\nCBO9781107323650.031\nEinstein, K. L., & Glick, D. M. (2015). Do I Think BLS Data are BS? The\nConsequences of Conspiracy Theories. Political Behavior ,37(3),\n679\u2013701. https://doi.org/10.1007/s11109-014-9287-z\nFaasse, K., Chatman, C. J., & Martin, L. R. (2016). A comparison of\nlanguage use in pro- and anti-vaccination comments in response to\na high profile Facebook post,. Vaccine ,34(47), 5808 \u20135814. https://\ndoi.org/10.1016/j.vaccine.2016.09.029\nFast, E., Chen, B., & Bernstein, M. S. (2016). Empath. Proceedings of the\n2016 CHI Conference on Human Factors in Computing Systems ,\n4647\u20134657. https://doi.org/10.1145/2858036.2858535\nFong, A., Roozenbeek, J., Goldwert, D., Rathje, S., & van der Linden, S.\n(2021). The language of conspiracy: A psychological analysis of\nspeech used by conspiracy theorists and their followers on Twitter.\nGroup Processes & Intergroup Relations ,24\n(4), 606 \u2013623. https://\ndoi.org/10.1177/1368430220987596\nFranks, B., Bangerter, A., & Bauer, M. W. (2013). Conspiracy theories as\nquasi-religious mentality: an integrated account from cognitive sci-ence, social representations theory, and frame theory. Frontiers in\nPsychology ,4,1\u201312.https://doi.org/10.3389/fpsyg.2013.00424\nFranks, B., Bangerter, A., Bauer, M. W., Hall, M., & Noort, M. C. (2017).\nBeyond \u201cMonologicality \u201d? Exploring Conspiracist Worldviews.\nFrontiers in Psychology ,8.https://doi.org/10.3389/fpsyg.2017.\n00861\nFry, E. (2000). 1000 instant words: the most common words for teaching\nreading, writing and spelling . Teacher Created Resources.\nFu, L. Y., Zook, K., Spoehr-Labutta, Z., Hu, P., & Joseph, J. G. (2016).\nSearch Engine Ranking, Quality, and Content of Web Pages That\nAre Critical Versus Noncritical of Human Papillomavirus Vaccine.\nJournal of Adolescent Health ,58(1), 33 \u201339.https://doi.org/10.1016/\nj.jadohealth.2015.09.016\nGolec de Zavala, A., & Cichocka, A. (2012). Collective narcissism and\nanti-Semitism in Poland. Group Processes & Intergroup Relations ,\n15(2), 213 \u2013229. https://doi.org/10.1177/1368430211420891\nGr\u00fcn, B., & Hornik, K. (2011). Topicmodels: An R package for fitting\ntopic models. Journal of Statistical Software ,40(13), 1 \u201330.https://\ndoi.org/10.18637/jss.v040.i13\nGuerini, M., Giampiccolo, D., Moretti, G., Sprugnoli, R., & Strapparava,\nC. (2013). The New Release of CORPS: A Corpus of PoliticalSpeeches Annotated with Audience Reactions. In: Lecture Notesin Computer Science (including subseries Lecture Notes in\nArtificial Intelligence and Lecture Notes in Bioinformatics) (pp.\n86\u201398).https://doi.org/10.1007/978-3-642-41545-6_8\nHeath, C., Bell, C., & Sternberg, E. (2001). Emotional selection in\nmemes: The case of urban legends. Journal of Personality and\nSocial Psychology ,81(6), 1028 \u20131041. https://doi.org/10.1037/\n0022-3514.81.6.1028\nHills, T. T. (2019). The Dark Side of Information Proliferation.\nPerspectives on Psychological Science ,14(3), 323 \u2013330. https://\ndoi.org/10.1177/1745691618803647\nImhoff, R., Lamberty, P., & Klein, O. (2018). Using Power as a Negative\nCue: How Conspiracy Mentality Affects Epistemic Trust in Sourcesof Historical Knowledge. Personality and Social Psychology\nBulletin ,44(9), 1364 \u20131379.\nhttps://doi.org/10.1177/\n0146167218768779\nImhoff, R., Dieterle, L., & Lamberty, P. (2021). Resolving the Puzzle of\nConspiracy Worldview and Political Activism: Belief in Secret Plots\nDecreases Normative but Increases Nonnormative PoliticalEngagement. Social Psychological and Personality Science ,12(1),\n71\u201379.https://doi.org/10.1177/1948550619896491\nJensen, T. (2013). Democrats and Republicans differ on conspiracy the-\nory beliefs . Public Policy Polling. http://www.publicpolicypolling.\ncom/polls/democrats-and-republicans-differ-on-conspiracy-theory-beliefs\nJolley, D., & Douglas, K. M. (2014a). The social consequences of\nconspiracism: Exposure to conspiracy theories decreases intentionsto engage in politics and to reduce one \u2019s carbon footprint. British\nJournal of Psychology ,105(1), 35 \u201356.https://doi.org/10.1111/bjop.\n12018\nJolley, D., & Douglas, K. M. (2014b). The Effects of Anti-Vaccine\nConspiracy Theories on Vaccination Intentions. PLoS ONE ,9(2),\ne89177. https://doi.org/10.1371/journal.pone.0089177\nJolley, D., & Paterson, J. L. (2020). Pylons ablaze: Examining the role of\n5G COVID-19 conspiracy beliefs and support for violence. British\nJournal of Social Psychology ,59(3), 628 \u2013640. https://doi.org/10.\n1111/bjso.12394\nJolley, D., Douglas, K. M., Leite, A. C., & Schrader, T. (2019). Belief in\nconspiracy theories and intentions to engage in everyday crime.British Journal of Social Psychology ,58(3), 534 \u2013549. https://doi.\norg/10.1111/bjso.12311\nKlein, C., Clutton, P., & Polito, V. (2018). Topic Modeling Reveals\nDistinct Interests within an Online Conspiracy Forum. Frontiers in\nPsychology ,9.https://doi.org/10.3389/fpsyg.2018.00189\nKlein, C., Clutton, P., & Dunn, A. G. (2019). Pathways to conspiracy:\nThe social and linguistic precursors of involvement in Reddit \u2019sc o n -\nspiracy theory forum. PLOS ONE ,14(11), e0225098. https://doi.\norg/10.1371/journal.pone.0225098\nKuperman, V., Stadthagen-Gonzalez, H., & Brysbaert, M. (2012). Age-\nof-acquisition ratings for 30,000 English words. Behavior Research\nMethods ,44(4), 978 \u2013990. https://doi.org/10.3758/s13428-012-\n0210-4\nKuznetsova, A., Brockhoff, P. B., & Christensen, R. H. B. (2017).\nlmerTest Package: Tests in Linear Mixed Effects Models. Journal\nof Statistical Software ,82(13). https://doi.org/10.18637/jss.v082.i13\nKwon, S., Cha, M., & Jung, K. (2017). Rumor Detection over Varying\nTime Windows. PLOS ONE\n,12(1), e0168344. https://doi.org/10.\n1371/journal.pone.0168344\nKyle, K., Crossley, S. A., & Kim, Y. J. (2015). Native language identi-\nfication and writing proficiency. International Journal of Learner\nCorpus Research ,1(2), 187 \u2013209. https://doi.org/10.1075/ijlcr.1.2.\n01kyl\nLansdall-Welfare, T., Sudhaha r, S., Thompson, J., Lewis, J., &\nCristianini, N. (2017). Content analysis of 150 years of British pe-\nriodicals. Proceedings of the National Academy of Sciences ,114(4),\nE457\u2013E465. https://doi.org/10.1073/pnas.1606380114Behav Res (2022) 54:1794 \u20131817 1815\nLantian, A., Muller, D., Nurra, C., Klein, O., Berjot, S., & Pantazi, M.\n(2018). Stigmatized beliefs: Conspiracy theories, anticipated nega-\ntive evaluation of the self, and fear of social exclusion. European\nJournal of Social Psychology ,48(7), 939 \u2013954. https://doi.org/10.\n1002/ejsp.2498\nLazarus, J. V., Ratzan, S. C., Palayew, A., Gostin, L. O., Larson, H. J.,\nRabin, K., Kimball, S., & El-Mohandes, A. (2020). A global survey\nof potential acceptance of a COVID-19 vaccine. Nature Medicine .\nhttps://doi.org/10.1038/s41591-020-1124-9\nLi, Y., Engelthaler, T., Siew, C. S. Q., & Hills, T. T. (2019). The\nMacroscope: A tool for examining the historical structure of lan-\nguage. Behavior Research Methods ,51(4), 1864 \u20131877. https://doi.\norg/10.3758/s13428-018-1177-6\nLi, Y., Hills, T., & Hertwig, R. (2020). A brief history of risk. Cognition ,\n203, 104344. https://doi.org/10.1016/j.cognition.2020.104344\nMarchlewska, M., Cichocka, A., & Kossowska, M. (2018). Addicted to\nanswers: Need for cognitive closure and the endorsement of con-spiracy beliefs. European Journal of Social Psychology .https://doi.\norg/10.1002/ejsp.2308\nMeppelink, C. S., Smit, E. G., Fransen, M. L., & Diviani, N. (2019). \u201cI\nwas Right about Vaccination \u201d: Confirmation Bias and Health\nLiteracy in Online Health Information Seeking. Journal of Health\nCommunication ,24(2), 129 \u2013140. https://doi.org/10.1080/\n10810730.2019.1583701\nMichel, J.-B., Shen, Y. K., Aiden, A. P., Veres, A., Gray, M. K., Pickett,\nJ. P., Hoiberg, D., Clancy, D., Norvig, P., Orwant, J., Pinker, S.,Nowak, M. A., & Aiden, E. L. (2011). Quantitative Analysis of\nCulture Using Millions of Digitized Books. Science ,331(6014),\n176\u2013182. https://doi.org/10.1126/science.1199644\nMitra, T., Counts, S., & Pennebaker, J. W. (2016). Understanding anti-\nvaccination attitudes in social media. Proceedings of the 10th\nInternational Conference on Web and Social Media, ICWSM 2016 .\nNguyen, D., Liakata, M., DeDeo, S., Eisenstein, J., Mimno, D., Tromble,\nR., & Winters, J. (2020). How We Do Things With Words:Analyzing Text as Social and Cultural Data. Frontiers in Artificial\nIntelligence ,3.https://doi.org/10.3389/frai.2020.00062\nNikolov, D., Oliveira, D. F. M., Flammini, A., & Menczer, F. (2015).\nMeasuring online social bubbles. PeerJ Computer Science ,1(12),\ne38.https://doi.org/10.7717/peerj-cs.38\nOkuhara, T., Ishikawa, H., Okada, M., Kato, M., & Kiuchi, T. (2017).\nReadability comparison of pro- and anti-HPV-vaccination online\nmessages in Japan. Patient Education and Counseling ,100(10),\n1859\u20131866. https://doi.org/10.1016/j.pec.2017.04.013\nOliver, J. E., & Wood, T. J. (2014). Conspiracy Theories and the Paranoid\nStyle(s) of Mass Opinion. American Journal of Political Science ,\n58(4), 952 \u2013966. https://doi.org/10.1111/ajps.12084\nOoms, J. (2019). curl: A Modern and Flexible Web Client for R .https://\ncran.r-project.org/package=curl\nOswald, S. (2016). Conspiracy and bias: argumentative features and per-\nsuasiveness of conspiracy theories. OSSA Conference Archive ,168,\n1\u201316.\nPauwels, K., Demirci, C., Yildirim, G., & Srinivasan, S. (2016). The\nimpact of brand familiarity on online and offline media synergy.\nInternational Journal of Research in Marketing ,33(4), 739 \u2013753.\nhttps://doi.org/10.1016/j.ijresmar.2015.12.008\nPennycook, G., & Rand, D. G. (2019). Fighting misinformation on social\nmedia using crowdsourced judgments of news source quality.Proceedings of the National Academy of Sciences ,116(7), 2521 \u2013\n2526. https://doi.org/10.1073/pnas.1806781116\nPerez, J. C., & Montagnier, L. (2020). Covid-19, Sars And Bats\nCoronaviruses Genomes Peculiar Homologous RNA Sequences.International Journal of Research -GRANTHAALAYAH ,8(7),\n217\u2013263. https://doi.org/10.29121/granthaalayah.v8.i7.2020.678\nR Core Team. (2019). R: A Language and Environment for Statistical\nComputing .https://www.r-project.org/Raab, M. H., Auer, N., Ortlieb, S. A., & Carbon, C.-C. (2013a). The\nSarrazin effect: the presence of absurd statements in conspiracy\ntheories makes canonical information less plausible. Frontiers in\nPsychology ,4,1\u20138.https://doi.org/10.3389/fpsyg.2013.00453\nRaab, M. H., Ortlieb, S. A., Auer, N., Guthmann, K., & Carbon, C.-C.\n(2013b). Thirty shades of truth: conspiracy theories as stories ofindividuation, not of pathological delusion. Frontiers in\nPsychology ,4.https://doi.org/10.3389/fpsyg.2013.00406\nRisius, M., Aydinguel, O., & Haug, M. (2019). Towards an understand-\ning of conspiracy echo chambers on Facebook. Proceedings of the\n27th European Conference on Information Systems (ECIS) .https://\naisel.aisnet.org/ecis2019_rip/36\nSak, G., Diviani, N., Allam, A., & Schulz, P. J. (2015). Comparing the\nquality of pro- and anti-vaccination online information: a content\nanalysis of vaccination-related webpages. BMC Public Health ,\n16(1), 38. https://doi.org/10.1186/s12889-016-2722-9\nSalmon, D. A., Moulton, L. H., Omer, S. B., DeHart, M. P., Stokley, S.,\n& Halsey, N. A. (2005). Factors associated with refusal of childhoodvaccines among parents of school-aged children: a case-controlstudy. Archives of Pediatrics & Adolescent Medicine ,159(5),\n470\u2013476. https://doi.org/10.1001/archpedi.159.5.470\nSamory, M., & Mitra, T. (2018a). Conspiracies online: User discussions\nin a conspiracy community following dramatic events. 12th\nInternational AAAI Conference on Web and Social Media,\nICWSM 2018 .\nSamory, M., & Mitra, T. (2018b). \u201cThe Government Spies Using Our\nWebcams: \u201dThe language of conspiracy theories in online discus-\nsions. Proceedings of the ACM on Human-Computer Interaction ,\n2(152). https://doi.org/10.1145/3274421\nSmith, N., & Graham, T. (2019). Mapping the anti-vaccination move-\nment on Facebook. Information, Communication & Society ,22(9),\n1310\u20131327. https://doi.org/10.1080/1369118X.2017.1418406\nSternisko, A., Cichocka, A., & Van Bavel, J. J. (2020). The dark side of\nsocial movements: social identity, non-conformity, and the lure of\nconspiracy theories. Current Opinion in Psychology ,35,1\u20136.\nhttps://doi.org/10.1016/j.copsyc.2020.02.007\nStroud, N. J. (2010). Polarization and Partisan Selective Exposure.\nJournal of Communication ,60(3), 556 \u2013576. https://doi.org/10.\n1111/j.1460-2466.2010.01497.x\nSwami, V., Barron, D., Weis, L., & Furnham, A. (2018). To Brexit or not\nto Brexit: The roles of Islamophobia, conspiracist beliefs, and inte-grated threat in voting intentions for the United Kingdom European\nUnion membership referendum. British Journal of Psychology ,\n109(1), 156 \u2013179. https://doi.org/10.1111/bjop.12252\nTausczik, Y. R., & Pennebaker, J. W. (2010). The psychological meaning\nof words: LIWC and computerized text analysis methods. Journal of\nLanguage and Social Psychology ,29(1), 24 \u201354.https://doi.org/10.\n1177/0261927X09351676\nUscinski, J. E., Parent, J. M., & Torres, B. (2011). Conspiracy Theories\nAre for Losers. APSA 2011 Annual Meeting Paper .https://ssrn.com/\nabstract=1901755\nUscinski, J. E., DeWitt, D., & Atkinson, M. D. (2018). A Web of\nConspiracy? Internet and Conspiracy Theory. In: Handbook of\nConspiracy Theory and Contemporary Religion (pp. 106 \u2013130).\nBRILL. https://doi.org/10.1163/9789004382022_007\nvan der Linden, S. (2015). The conspiracy-effect: Exposure to conspiracy\ntheories (about global warming) decreases pro-social behavior and\nscience acceptance. Personality and Individual Differences ,87,\n171\u2013173. https://doi.org/10.1016/j.paid.2015.07.045\nvan Prooijen, J.-W., Krouwel, A. P. M., & Pollet, T. V. (2015). Political\nExtremism Predicts Belief in Conspiracy Theories. Social\nPsychological and Personality Science ,6(5), 570 \u2013578. https://doi.\norg/10.1177/1948550614567356\nvon Luxburg, U., Williamson, R. C., & Guyon, I. (2012). Clustering:\nScience or Art? In I. Guyon, G. Dror, V. Lemaire, G. Taylor, & D.Silver (Eds.), Proceedings of ICML Workshop on Unsupervised and1816 Behav Res (2022) 54:1794 \u20131817\nTransfer Learning ( V o l .2 7 ,p p .6 5 \u201379). PMLR. http://proceedings.\nmlr.press/v27/luxburg12a.html\nVosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false\nnews online. Science ,359(6380), 1146 \u20131151. https://doi.org/10.\n1126/science.aap9559\nWakefield, A., Murch, S., Anthony, A., Linnell, J., Casson, D., Malik,\nM., Berelowitz, M., Dhillon, A., Thomson, M., Harvey, P.,\nValentine, A., Davies, S., & Walker-Smith, J. (1998).RETRACTED: Ileal-lymphoid-nodular hyperplasia, non-specificcolitis, and pervasive developmental disorder in children. The\nLancet ,351(9103), 637 \u2013641. https://doi.org/10.1016/S0140-\n6736(97)11096-0\nWarriner, A. B., Kuperman, V., & Brysbaert, M. (2013). Norms of va-\nlence, arousal, and dominance for 13,915 English lemmas. Behavior\nResearch Methods ,45(4), 1191 \u20131207. https://doi.org/10.3758/\ns13428-012-0314-x\nWesten, D., Blagov, P. S., Harenski, K., Kilts, C., & Hamann, S. (2006).\nNeural Bases of Motivated Reasoning: An fMRI Study of\nEmotional Constraints on Partisan Political Judgment in the 2004\nU.S. Presidential Election. Journal of Cognitive Neuroscience ,\n18(11), 1947 \u20131958. https://doi.org/10.1162/jocn.2006.18.11.1947\nWood, M. J. (2018). Propagating and Debunking Conspiracy Theories on\nTwitter During the 2015 \u20132016 Zika Virus Outbreak.Cyberpsychology, Behavior, and Social Networking ,21(8), 485 \u2013\n490. https://doi.org/10.1089/cyber.2017.0669\nWood, M. J., & Douglas, K. M. (2013). What about building 7? A social\npsychological study of online discussion of 9/11 conspiracy theo-ries.Frontiers in Psychology ,4,1\u20139.https://doi.org/10.3389/fpsyg.\n2013.00409\nWood, M. J., & Douglas, K. M. (2015). Online communication as a\nwindow to conspiracist worldviews. Frontiers in Psychology ,6.\nhttps://doi.org/10.3389/fpsyg.2015.00836\nZannettou, S., Bradlyn, B., De Cristofaro, E., Kwak, H., Sirivianos, M.,\nStringini, G., & Blackburn, J. (2018). What is Gab. Companion of\nthe Web Conference 2018 on The Web Conference 2018 - WWW\u201918,1 0 0 7 \u20131014. https://doi.org/10.1145/3184558.3191531\nZollo, F., Bessi, A., Del Vicario, M., Scala, A., Caldarelli, G., Shekhtman,\nL., Havlin, S., & Quattrociocchi, W. (2017). Debunking in a worldof tribes. PLoS ONE .https://doi.org/10.1371/journal.pone.0181821\nZubiaga, A., Liakata, M., Procter, R., Wong Sak Hoi, G., & Tolmie, P.\n(2016). Analysing How People Orient to and Spread Rumours in\nSocial Media by Looking at Conversational Threads. PLOS ONE ,\n11(3), e0150989.\nhttps://doi.org/10.1371/journal.pone.0150989\nPublisher \u2019sn o t e Springer Nature remains neutral with regard to jurisdic-\ntional claims in published maps and institutional affiliations.Behav Res (2022) 54:1794 \u20131817 1817", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "LOCO: The 88-million-word language of conspiracy corpus", "author": ["A Miani", "T Hills", "A Bangerter"], "pub_year": "2022", "venue": "Behavior research methods", "abstract": "The spread of online conspiracy theories represents a serious threat to society. To understand  the content of conspiracies, here we present the language of conspiracy (LOCO) corpus."}, "filled": false, "gsrank": 387, "pub_url": "https://link.springer.com/article/10.3758/s13428-021-01698-z", "author_id": ["zsMnlFgAAAAJ", "PXgw3lUAAAAJ", "YmgLQcIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:o8n7TrO3zusJ:scholar.google.com/&output=cite&scirp=386&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=o8n7TrO3zusJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 42, "citedby_url": "/scholar?cites=16991720424867613091&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:o8n7TrO3zusJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.3758/s13428-021-01698-z.pdf"}}, {"title": "UofA-Truth at Factify 2022: A Simple Approach to Multi-Modal Fact-Checking.", "year": "2022", "pdf_data": "UofA-Truth at Factify 2022 : A Simple Approach to\nMulti-Modal Fact-Checking\nAbhishek Dhankar1, Osmar R. Za\u00efane1and Francois Bolduc1\n1University of Alberta, Edmonton, Alberta, T6G 2E8, Canada\nAbstract\nIdentifying fake news is a very difficult task, especially when considering the multiple modes of conveying\ninformation through text, image, video and/or audio. We attempted to tackle the problem of automated\nmisinformation/disinformation detection in multi-modal news sources (including text and images)\nthrough our simple, yet effective, approach in the FACTIFY shared task at De-Factify@AAAI2022. Our\nmodel produced an F1-weighted score of 74.807%, which was the fourth best out of all the submissions.\nIn this paper we will explain our approach to undertake the shared task.\nKeywords\nfake news, multi-modal, De-Factify@AAAI2022, FACTIFY shared task\n1. Introduction\nHumankind has dealt with misinformation since time immemorial [ 1]. However, never in\nhuman history have people had access to the amount of information that they have today. The\nInternet is the primary reason for easy access to this information. It has given people the ability\nto access information from all over the world and from innumerable sources. However, this\ndeluge of information has brought with it the problem of misinformation/disinformation/fake\nnews. Never before have we had more efficacious means to disseminate deceptive fallacies and\nfalsehoods that are unfortunately believed and are wrongfully, and sometimes dangerously\nimpacting people.\nWhile there are many definitions of Fake News, for this paper Fake News can be defined as a\nnews piece, social media post, etc., which contains claim(s) that can be refuted by information\nput out by \u201creputable organizations\u201d. Such organizations may include, but are not limited to,\ngovernment bodies, news outlets that score high on Media Bias/Fact Check\u2019s Factual Reporting\nscale [ 2] or professional fact-checking organizations which are verified signatories of the\nInternational Fact-Checking Network (IFCN) code of conduct [ 3] [4]. This definition of fake news\noff-loads the responsibility of determining what exactly fake news is, on to expert fact-checkers\nor domain experts, and allows Artificial Intelligence (AI) to deal with the more manageable\nproblem of determining whether claim(s) made in a news piece is entailed, not entailed or\nDe-Factify: Workshop on Multimodal Fact Checking and Hate Speech Detection, co-located with AAAI 2022. 2022\nVancouver, Canada\n/envel\u2322pe-\u2322pendhankar@ualberta.ca (A. Dhankar); zaiane@ualberta.ca (O. R. Za\u00efane); fbolduc@ualberta.ca (F. Bolduc)\n/gl\u2322behttps://www.linkedin.com/in/abhishek-dhankar-928610140/ (A. Dhankar); https://www.cs.ualberta.ca/~zaiane/\n(O. R. Za\u00efane); http://www.bolduclab.com/page9.html (F. Bolduc)\n\u00a92021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\nCEUR\nWorkshop\nProceedingshttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings (CEUR-WS.org)\n\nrefuted by a corresponding news piece from a reputable source.\nFake news can cause real world harm as is being seen during the COVID-19 pandemic:\nmisinformation has led to vaccine hesitancy, which is directly tied to increased chances of\nmortality due to COVID-19 [ 5]. Fact-checking or determining whether a news piece contains\nfake claims is the first step in countering such fake news. Furthermore, it is not only important\nto detect and counteract fake news, but to do so in a timely manner. Given the large amount of\ninformation generated on social media sites every-day and the time constraints that online fact-\nchecking operates under, it is imperative that automated methods of misinformation detection\nare developed to aid in the manual fact-checking of fake news.\nIn general, the information generated and distributed on the Internet is multi-modal, i.e., con-\nsisting of text, images, audio-visual, etc. Often times information is conveyed via a combination\nof two or more modes, for instance, memes, pieces of information rapidly spread among users,\nare often a combination of text and image/short video, where text is overlaid on the image or\nshort video (also called a gif). Thus, an automated method should be able to take advantage of\nall the modes of information available to fact-check a claim.\nThe shared task FACTIFY, in conjunction with the AAAI conference, attempts to aid in the\ndevelopment of automated multi-modal fact-checking by introducing a dataset that consists of\nmulti-modal claims and corresponding supplementary information or documents, using which\nsaid claims need to be fact-checked [ 6] [7]. Each multi-modal \u201cclaim\u201d consists of a short sentence\nor phrase and an associated image, which may or may not have overlaid text. The corresponding\nsupplementary information or \u201cdocument\u201d consists of a sentence or sentences from a reputable\nsource with an accompanying image. The task is to determine whether the claim text and claim\nimage are individually entailed, not entailed, or refuted by the corresponding document text\nand image pair. Depending on that, and defined by the shared task organizers, there are five\npossible labels that each claim text and image pair can have:\n\u2022Support_Multimodal: Both claim text and image are entailed\n\u2022Support_text: Text is entailed, but the image is not\n\u2022Insufficient_Multimodal: Claim text is not entailed, but claim image is\n\u2022Insufficient_Text: Neither claim text nor claim image is entailed\n\u2022Refute: Both claim text and image are refuted\nOur team \u201cUofA-Truth\u201d participated in the shared task and secured the 4\ud835\udc61\u210eposition with a\nweighted F1-score of 74.807% , just\u22482F1 points behind the top submission. In this paper, we\nshall describe our simple yet effective automated fact-checking model.\n2. Related Works\nThe dataset used to train and test our model was released under the shared task FACTIFY, which\nis a part of the workshop De-Factify at the AAAI 2022 conference [ 6]. The dataset consists of a\ntotal of 50,000claim and document pairs, which are divided into train, validation and test sets\nof sizes 35,000(70%) ,7,500(15%) and7,500(15%) respectively.\nThe entailment aspect of the shared task is similar to \u201cStance Detection\u201d, which can be defined\nas the classification of the stance of the producer of a news piece concerning an unverified\nclaim [ 8]. In the context of the shared task, the unverified claim is the claim text and image\npair, and the news piece is the document text and image pair.\nStance Detection is an important part of Fake News detection and was notably used in the\nFake News Challenge - 1 (FNC-1) [ 9]. This challenge was similar to the FACTIFY shared task,\nexcept FNC-1 only dealt with text entailment or stance detection, unlike FACTIFY which deals\nwith multi-modal entailment. FNC-1 introduced a dataset that consisted of a headline and a\nbody of text, which may be from the same article or different articles. Depending on the stance\nof the body of text concerning the headline, the text-headline pairs were to be classified into\nany of the following classes:\n\u2022Agrees: The body of text agrees with the claim(s) made in the headline\n\u2022Disagrees: The body of text disagrees with the claim(s) made in the headline\n\u2022Discusses: The body of text and headline are referring to the same subject, but the body\ndoes not take any stance or position on the claim(s) made in the headline\n\u2022Unrelated: The body of text is not related to the claim(s) being made in the headline\nFACTIFY\u2019s not-entail class can be considered similar to a combination of Unrelated and\nDiscusses classes of FNC-1, while entails and refutes classes can be considered similar to\nFNC-1\u2019s Agrees and Disagrees classes respectively.\nThis similarity between the two tasks led us to draw inspiration from the UCL Machine\nReading team\u2019s submission to the FNC-1\u2019s challenge, which performed 3\ud835\udc5f\ud835\udc51best among the 50\nsubmissions to the challenge [ 10]. In their submission the UCL team, Riedel et al., describe their\napproach as a \u201csimple but tough-to-beat baseline\u201d for stance detection. As explained above,\nthere are two inputs for this task - a headline and a body of text. Riedel et al. calculated the\nTerm Frequency (TF) vectors and Term Frequency - Inverse Document Frequency (TF-IDF) for\nboth the headline and the body of text-based on the 5,000most frequent words. The TF vectors\nof the two inputs are concatenated with the result of the cosine similarity between the TF-IDF\nvectors of the headline and body, as shown in Figure 1. The resultant vector of length 10,001is\nthen fed as input into a shallow Multi Layer Perceptron (MLP) network, which has a softmax\noutput of length four, one for each class in the FNC-1 task.\nGiven the similarity of the tasks being solved in FNC-1 and FACTIFY, we adopted the manner\nof the concatenation of the cosine similarity and vector representations of the header and\nbody as explained in [ 10]. Instead of using TF for vector representations and TF-IDF for cosine\nsimilarity calculation, we used Sentence-BERT in lieu of both TF and TF-IDF vectors to determine\nentailment between the claim text and document text [ 11]. Sentence BERT is a transformer\nbased model which has been specifically trained to represent sentences and paragraphs and\ntherefore may be better for sentence representation than other methods which usually compute\nthe average across vector representations of individual words to obtain sentence or paragraph\nrepresentations. To determine entailment between claim and document images, we used a\npre-trained instantiation of the Xception architecture [ 12] available in Keras [ 13], which had\nbeen trained on JFT-300M dataset [14].\nThe FNC-1 challenge had two other submissions which performed better than [ 10], however,\nwe concluded that those were more complicated architectures and might hamper the scalability\nand time complexity of our model. For instance, Pan et al., who submitted the winning\nFigure 1: Concatenated Vector Representation. Adapted from \u201cA simple but tough-to-beat baseline for\nthe Fake News Challenge stance detection task\u201d, by Riedel et al.\nmodel [ 15], had an ensemble model which consisted of a deep learning model and a tree based\nensemble model as implemented in Xgboost [ 16]. The outputs of the two models were weighted\nequally to produce the final predictions. Hanselowski et al. also implemented an ensemble model\nwhich consisted of five Neural Network models. The final prediction was made through majority\nvoting. Despite the increased complexity, Team UCL Machine Reading\u2019s model performance\nwas within\u22481point of the top two submissions.\n3. Methodology\nThe FACTIFY shared task\u2019s classes (Support_Multimodal, Support_text, Insufficient_Multimodal,\nInsufficient_Text, Refute) are composed of a combination of text and image entailment classes.\nFor instance, if text entailment, non-entailment, and refutation are represented by \ud835\udcaf_0,\ud835\udcaf_1,\n\ud835\udcaf_2, and image entailment, non-entailment and refutation are represented by \u2110_0,\u2110_1,\u2110_2\nrespectively; then the shared task\u2019s classes can be reformulated as a combination of text and\nimage entailment labels as shown in Table 1. It is important to note here that all combinations\nof text entailment labels and image entailment labels are not present in Table 1. For instance,\ncombinations such as \ud835\udcaf_0 &\u2110_2 do not exist. The lacking combinations are treated when\nconsolidating the labels after classification. This is explained in Section 3.4.\nIt can be clearly seen that the shared task can now be broken down into two sub-tasks;\nnamely, text entailment and image entailment, where text entailment consists of classes \ud835\udcaf_0,\n\ud835\udcaf_1 and\ud835\udcaf_2, and image entailment consists of classes \u2110_0,\u2110_1,\u2110_2. These new classes\nare the combination of the original class labels as shown in Table 2 and Table 3 for the text\nentailment and image entailment tasks respectively. Once the dataset is rearranged according\nto the sub-task labels, we end up with one dataset for each sub-task.\nWe now define Text Entailment as a task of predicting the document text\u2019s stance towards the\nTable 1\nFACTIFY Task Labels & Corresponding Text and Image Entailment Labels\nFACTIFY Task Label Text Entailment Label Image Entailment Label\nSupport_Multimodal \ud835\udcaf_0 \u2110_0\nSupport_text \ud835\udcaf_0 \u2110_1\nInsufficient_Multimodal \ud835\udcaf_1 \u2110_0\nInsufficient_Text \ud835\udcaf_1 \u2110_1\nRefute \ud835\udcaf_2 \u2110_2\nTable 2\nText Entailment Task Labels in Terms of Original FACTIFY Task Labels\nText Entailment Label FACTIFY Labels\n\ud835\udcaf_0 Support_Multimodal & Support_text\n\ud835\udcaf_1 Insufficient_Multimodal & Insufficient_Text\n\ud835\udcaf_2 Refute\nTable 3\nImage Entailment Task Labels in Terms of Original FACTIFY Task Labels\nImage Entailment Label FACTIFY Labels\n\u2110_0 Support_Multimodal & Insufficient_Multimodal\n\u2110_1 Support_text & Insufficient_Text\n\u2110_2 Refute\nclaim text, and Image Entailment as a task of predicting the document image\u2019s stance towards\nthe claim image.\n3.1. Preprocessing\nImage preprocessing is done by resizing all the images to (256, 256, 3) size with bilinear interpo-\nlation as implemented in image_dataset_from_directory in Keras [ 13]. Thereafter, all the pixel\nvalues are scaled to a range of 0to1.\nText preprocessing involves removing URLs from all claim and document texts with the help\nof the Preprocessor library [18].\n3.2. Vector Representations\nThe preprocessed inputs (text and images) need to be converted into vector representations so\nthat they can be presented as input for a classifier.\nThe preprocessed images are converted into vectors of size 2048 each, by using the pre-trained\nXception model in Keras [ 13]. This can be achieved by setting include_top attribute to False\nand pooling attribute to \u2018avg\u2019. Setting include_top to False removes the fully connected layer at\nthe end of the model and exposes the output of the second to the last layer. Setting pooling to\nFigure 2: Image Entailment Classifier Architecture\n\u2018avg\u2019 ensures that a global pooling average is applied to the 3D output of the second last layer\nof Xception, to convert it into a 1D output. Since the Xception model has been trained on a\nmassive dataset for a general image classification task, it can be reasonably assumed that the\noutput of the second to the last layer captures information that may be useful for downstream\ntasks such as image entailment.\nThe preprocessed texts are converted into vectors of length 384each by using the pre-trained\nSentence-BERT model [11].\nThe cosine similarity of the vector representations of claim and corresponding document\nimages is calculated and concatenated in the manner shown in Figure 2. This creates a concate-\nnated representation for each claim and corresponding document image of size 4097 . Similarly,\nthe concatenated representation of claim and corresponding document text of size 769is created\nthrough the same procedure of cosine similarity calculation and subsequent concatenation as\nshown in Figure 3.\n3.3. Classifiers\nThe vector representations are now used for training the classifiers for the image and text\nentailment tasks. Different classifiers are used for the image and text entailment tasks.\nAs shown in Figure 2 the image entailment classifier consists of a single fully connected\nhidden MLP layer of 5000 units, ReLU activation with a dropout probability of 0.5. The output\nof this layer then feeds into a fully connected output layer of 3units, one for each class label\n(entailment, non-entailment and refute), and a sigmoid activation function.\nOn the other hand, as shown in Figure 3 the text entailment classifier consists of two fully\nconnected layers of 450units each, ReLU activation functions, \ud835\udc592activity regularizers, and a\nFigure 3: Text Entailment Classifier Architecture\ndropout probability of 0.55for the first layer and 0.4for the second layer. The output of the two\nhidden layers then feeds into the fully connected output layer 3units with sigmoid activation.\nThe Cross-Entropy loss is calculated after performing the softmax operation on the outputs\nof both the classifiers.\n3.4. Label Consolidation\nThe output of the image classifier classifies every pair of claims and document image into one\nof the three labels \u2110_0,\u2110_1 and\u2110_2. Similarly, for claim and document text pairs.\nThe pairs of image and text entailment labels belonging to the same data-point are com-\nbined and then converted into the original FACTIFY task labels (namely, Support_Multimodal,\nSupport_text, Insufficient_Multimodal, Insufficient_Text, Refute) according to Table 1.\nHowever, it is possible that the combination procedure may produce pairs of entailment\nlabels that do not have any corresponding FACTIFY task label. For instance, ( \ud835\udcaf_0,\u2110_2), (\ud835\udcaf_1,\n\u2110_2), (\ud835\udcaf_2,\u2110_0), (\ud835\udcaf_2,\u2110_1), are four such invalid pairs of labels. We thus have to change\nsuch label pairs into valid label pairs. We do so by using a heuristic as described in Table 4(A).\nIf one of either claim text or claim image is entailed, i.e., \ud835\udcaf_0 or\u2110_0, it is unlikely that the\nother claim mode will be refuted by the document, hence, the latter\u2019s label needs to be changed\nto not-entailed, i.e., \ud835\udcaf_1 or\u2110_1. If however, one of the claim text or image is refuted by the\ncorresponding document then it is unlikely that the other claim mode will have uncertain\nentailment, hence the latter\u2019s label should be converted to refuted as well, i.e., \ud835\udcaf_2 or\u2110_2.\nThereafter, we can calculate the final weighted F1 accuracy on the Test set.\nTable 4\nHeuristics for invalid label conversion\nInvalid Label Pair Valid Label Pair\n(\ud835\udcaf_0,\u2110_2) (\ud835\udcaf_0,\u2110_1)\n(\ud835\udcaf_1,\u2110_2) (\ud835\udcaf_2,\u2110_2)\n(\ud835\udcaf_2,\u2110_0) (\ud835\udcaf_1,\u2110_0)\n(\ud835\udcaf_2,\u2110_1) (\ud835\udcaf_2,\u2110_2)\nA:Invalid to Valid Label Pair ConversionInvalid Label Pair Valid Label Pair\n(\ud835\udcaf_0,\u2110_2) (\ud835\udcaf_0,\u2110_0)\n(\ud835\udcaf_1,\u2110_2) (\ud835\udcaf_1,\u2110_1)\n(\ud835\udcaf_2,\u2110_0) (\ud835\udcaf_2,\u2110_2)\n(\ud835\udcaf_2,\u2110_1) (\ud835\udcaf_2,\u2110_2)\nB:New Invalid to Valid Label Pair Conversion\n4. Results & Discussion\nOur team, UofA-Truth, secured the 4\ud835\udc61\u210eposition on the leaderboard, with an F1-score of 74.807%\non the final evaluation. However, the confusion matrix, shown in Figure 4, reveals more\nfine-grained details about our model\u2019s performance on the test set.\nThe model performed worst on the Insufficient_Multimodal category. It can be clearly\nseen from the matrix that a large number ( 304) of data points with ground truth Insuffi-\ncient_Multimodal were incorrectly classified as Support_Multimodal. Since the only difference\nbetween the two classes is text entailment, it is possible that the model maybe unable to dif-\nferentiate between text entailment and non-entailment. This may be because the claim and\ndocument texts might have common words or might even talk about tangential or similar topics,\nbut do not reach the threshold of text entailment.\nFurthermore, the model did not perform well on the Support_text class. A significant number\n(202) of data-points belonging to Support_Text were misclassified as Support_Multimodal.\nAgain, given that the only difference between the two classes is in image entailment, it follows\nthat a model would find it hard to differentiate between the two. Similarly, for the Support_Text\nand Insufficient_Text.\nThe model performs best on the Refute class despite the fact that the said class had the fewest\ndata points in the training set. Very few of its data points are misclassified as other classes, and\nvice-versa. This may be because a significant number of the data points belonging to the Refute\nclass have been taken from fact-checking websites. This fact may set such data points apart\nfrom other claim-document pairs. For instance, document images and corresponding claim\nimages of the Refute class tend to be identical because fact-checking websites almost always\nprovide a screenshot of the fake news/social media posts they debunk in their articles. They\nmay even overlay images of news pieces they fact-check with a digital stamp, indicating their\nlogo or whether the news piece was true or fake. They usually clearly state the gist of the fake\nnews they debunk, at the beginning of every article, often quoting said fake news verbatim.\nSuch peculiarities may make data points belonging to the Refute class easy to discern.\nHeuristics mentioned in Section 3.4 can be changed to improve the weighted F1-score on\nthe test set. It is possible that the image entailment model merely learns to determine the\nsimilarity between claim and document image pairs. Thus, it may be better to have a heuristic\nthat changes the invalid label pairs into valid label pairs by changing the image entailment label\nFigure 4: Confusion Matrix for Original Heuristic\nFigure 5: Confusion Matrix for Modified Heuristic\nto be the same as the text entailment label. Therefore, after the competition results, we changed\nthe heuristic for invalid label pair to valid label pair conversion as per the new heuristics shown\nin Table 4(B). These modified heuristics improve the final F1-score from 74.807% to75.183% .\nAs can be seen by the confusion matrix in Figure 5, the new heuristic reduces the classification\naccuracies of the Insufficient_Multimodal and Support_Text classes, for the benefit of the other\nclasses. Other than that, the overall dynamics remain the same as in Figure 4. It could be possible\nto continue adjusting these heuristics to obtain even better results but have not experimented\nfurther.\n5. Conclusion\nIn this paper, we introduced a simple, yet effective method of multi-modal fake news detection.\nWe divided the main task into two sub-tasks; namely, text entailment and image entailment.\nThereafter, we used pre-trained Xception network and Sentence-BERT to get vector repre-\nsentations of images and text respectively. We then used these vector representations for\nclassifications tasks of image and text entailment by adapting the approach introduced by\nRiedel et al. in their submission to the FNC-1 task. Finally, we consolidated the prediction of\nthe two sub-tasks of image and text entailment to get the final predictions. We used the model\nthus created to make predictions on the test set, and our team\u2019s submission achieved the 4\ud835\udc61\u210e\nposition on the leader board with a 74.807% weighted F1-score.\nAcknowledgments\nThis work was partially funded by a Collaborative Health Research Project grant from the\nCanadian Institutes of Health Research (CIHR) and the Natural Sciences and Engineering\nResearch Council of Canada (NSERC). Osmar Zaiane, a Canada CIFAR AI Chair, is also funded\nby the Canadian Institute for Advanced Research (CIFAR).\nReferences\n[1]J. Mansky, The age-old problem of \u201cfake news\u201d, 2018. URL: https://www.smithsonianmag.\ncom/history/age-old-problem-fake-news-180968945/, accessed on 2021-11-24.\n[2]Methodology, 2021. URL: https://mediabiasfactcheck.com/methodology/, accessed on 2021-\n11-24.\n[3]International fact-checking network, 2021. URL: https://www.poynter.org/ifcn/, accessed\non 2021-11-24.\n[4]Verified signatories of the ifcn code of principles, 2021. URL: https://ifcncodeofprinciples.\npoynter.org/signatories, accessed on 2021-11-24.\n[5]S. Xu, R. Huang, L. S. Sy, S. C. Glenn, D. S. Ryan, K. Morrissette, D. K. Shay, G. Vazquez-\nBenitez, J. M. Glanz, N. P. Klein, et al., Covid-19 vaccination and non\u2013covid-19 mortality\nrisk\u2014seven integrated health care organizations, united states, december 14, 2020\u2013july 31,\n2021, Morbidity and Mortality Weekly Report 70 (2021) 1520.\n[6]S. Mishra, S. Suryavardan, A. Bhaskar, P. Chopra, A. Reganti, P. Patwa, A. Das,\nT. Chakraborty, A. Sheth, A. Ekbal, C. Ahuja, Factify: A multi-modal fact verification\ndataset, in: Proceedings of the First Workshop on Multimodal Fact-Checking and Hate\nSpeech Detection (DE-FACTIFY), 2022.\n[7]P. Patwa, S. Mishra, S. Suryavardan, A. Bhaskar, P. Chopra, A. Reganti, A. Das,\nT. Chakraborty, A. Sheth, A. Ekbal, C. Ahuja, Benchmarking multi-modal entailment for\nfact verification, in: Proceedings of De-Factify: Workshop on Multimodal Fact Checking\nand Hate Speech Detection, CEUR, 2022.\n[8] D. K\u00fc\u00e7\u00fck, F. Can, Stance detection: A survey, ACM Computing Surveys 53 (2020) 1\u201337.\n[9]A. Hanselowski, A. PVS, B. Schiller, F. Caspelherr, D. Chaudhuri, C. M. Meyer, I. Gurevych,\nA retrospective analysis of the fake news challenge stance-detection task, in: Proceed-\nings of the 27th International Conference on Computational Linguistics, Association\nfor Computational Linguistics, Santa Fe, New Mexico, USA, 2018, pp. 1859\u20131874. URL:\nhttps://aclanthology.org/C18-1158.\n[10] B. Riedel, I. Augenstein, G. P. Spithourakis, S. Riedel, A simple but tough-to-beat baseline\nfor the fake news challenge stance detection task, arXiv preprint arXiv:1707.03264 (2017).\n[11] N. Reimers, I. Gurevych, Sentence-bert: Sentence embeddings using siamese bert-networks,\nin: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Process-\ning, Association for Computational Linguistics, 2019. URL: https://arxiv.org/abs/1908.10084.\n[12] F. Chollet, Xception: Deep learning with depthwise separable convolutions, in: Proceedings\nof the IEEE conference on computer vision and pattern recognition, 2017, pp. 1251\u20131258.\n[13] F. Chollet, et al., Keras, https://keras.io, 2015.\n[14] G. Hinton, O. Vinyals, J. Dean, Distilling the knowledge in a neural network, arXiv\npreprint arXiv:1503.02531 (2015).\n[15] Y. Pan, D. Sibley, S. Baird, Fake News Challenge - Team SOLAT IN THE SWEN, https:\n//github.com/Cisco-Talos/fnc-1, 2018.\n[16] T. Chen, C. Guestrin, XGBoost: A scalable tree boosting system, in: Proceedings of the\n22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\nKDD \u201916, ACM, New York, NY, USA, 2016, pp. 785\u2013794. URL: http://doi.acm.org/10.1145/\n2939672.2939785. doi: 10.1145/2939672.2939785 .\n[17] A. Hanselowski, A. PVS, B. Schiller, F. Caspelherr, athene_system, https://github.com/\nhanselowski/athene_system, 2018.\n[18] S. \u00d6zcan, santiagonasar, Rusty, Rushat, L. Lopez, Piotti, Preprocessor, https://github.com/\ns/preprocessor, 2020.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "UofA-Truth at Factify 2022: A Simple Approach to Multi-Modal Fact-Checking.", "author": ["A Dhankar", "O Za\u00efane", "F Bolduc"], "pub_year": "2022", "venue": "DE-FACTIFY@ AAAI", "abstract": "Identifying fake news is a very difficult task, especially when considering the multiple modes  of conveying information through text, image, video and/or audio. We attempted to tackle the"}, "filled": false, "gsrank": 388, "pub_url": "https://ceur-ws.org/Vol-3199/paper10.pdf", "author_id": ["ZICJU4QAAAAJ", "j-W_RNYAAAAJ", "5EFDWZ4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:hyq1JvmHc7sJ:scholar.google.com/&output=cite&scirp=387&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=hyq1JvmHc7sJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 4, "citedby_url": "/scholar?cites=13507289211580263047&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:hyq1JvmHc7sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ceur-ws.org/Vol-3199/paper10.pdf"}}, {"title": "An interactive framework for profiling news media sources", "year": "2023", "pdf_data": "An Interactive Framework for Profiling News Media Sources\nNikhil Mehta\nDepartment of Computer Science\nPurdue University\nWest Lafayette, IN 47907\nmehta52@purdue.eduDan Goldwasser\nDepartment of Computer Science\nPurdue University\nWest Lafayette, IN 47907\ndgoldwas@purdue.edu\nAbstract\nThe recent rise of social media has led to\nthe spread of large amounts of fake and bi-\nased news, content published with the intent\nto sway beliefs. While detecting and profiling\nthe sources that spread this news is important\nto maintain a healthy society, it is challenging\nfor automated systems.\nIn this paper, we propose an interactive frame-\nwork for news media profiling. It combines the\nstrengths of graph based news media profiling\nmodels, Pre-trained Large Language Models,\nand human insight, to characterize the social\ncontext on social media. Experimental results\nshow that with as little as 5 human interactions,\nour framework can rapidly detect fake and bi-\nased news media, even in the most challenging\nsettings of emerging news events, where test\ndata is unseen.\n1 Introduction\nThe recent rise of social media has enabled informa-\ntion to spread at a rapid pace, having the potential\nto very quickly impact a large number of people,\nespecially during key events, such as political elec-\ntions (V osoughi et al., 2018). While this rise of\nsocial media has many benefits, one downside is\nthat harmful information, i.e. fake or politically\nbiased news, can also spread rapidly, affecting peo-\nple\u2019s perspectives. Thus, detecting it is important.\nWhile one approach is to fact-check or detect\nthe bias of all content on social media (i.e. Twit-\nter), another is to focus on the source, and ask: Is\nthis source factual or politically biased? This task,\nprofiling news media sources , which we focus on,\ncan scale better, as often times a large amount of\nthe content sources\u2019 publish have the same factual-\nity/political bias as the source itself. We model this\non a 3-point scale: high, low, and mixed factuality,\nandleft, center, and right bias. Details: App. A.1.\nEven at the source level, it is difficult for humans\nto profile all news content, due to the large numberof sources online. Further, this task is still challeng-\ning for AI systems (Baly et al., 2018, 2020; Mehta\net al., 2022), especially in the emerging events set-\ntings , when the system is tested on its ability to\nadapt to new events , consisting of new sources,\ncontent they generate, and social media users en-\ngaging with them that were not seen at training\ntime (Yuan et al., 2020). For example, in a graph\nframework, test set nodes are not connected to train-\ning set nodes. In these settings, Large Language\nModels (LLMs) also struggle, even when enhanced\nwith extra knowledge (Whitehouse et al., 2022).\nDue to the struggles of AI systems to automati-\ncally profile news media, in this paper we propose\na different, interactive approach, for this task. We\nare inspired by recent results (Cinelli et al., 2021;\nVicario et al., 2016) showing that misinformation\nand highly biased content tends to spread in closely\nknit communities on social media. This leads us to\nask, whether better modeling of the social media\nrelationships that underlie content spread would\nimprove our ability to profile the content itself.\nSpecifically, we hypothesize that users on social\nmedia form information communities , or groups of\nusers, where certain themes circulate more in some\ncommunities vs. others. If we can identify these\nthemes and use them to identify information com-\nmunities , then we can better profile the content\ndiscussed by the communities. For example, a user\njoining a left-leaning community, is more likely\nto be left-leaning, and so is the content they share.\nThen, if that user shares content from a source, that\nsource is also more likely to be left-leaning.\nIn the settings of emerging events, we must be\nable to characterize and form the information com-\nmunities quickly, without using labeled training\ndata, so we can rapidly detect fake/biased news\nsources on unseen data. Unfortunately, using only\ninformation on social media to form information\ncommunities involves complex reasoning on un-\nseen data, and is thus challenging for automatedarXiv:2309.07384v2  [cs.CL]  26 Apr 2024\nA A\nS SU\nUU\n(a) Broad Event \nGraph (b) Graph Model (c) Clustering to form \ncandidate information \ncommunities (d) Using GPT-3 and humans, narrow \ndown communities based on user \nsimilarity, then humans connect users in \nthe same community to form validated \nones (light blue). (e) Validated Communities are iteratively \nexpanded, by clustering to form new \ncandidates (light red) and assigning their \nGPT-3 validated users to validated \ncommunities (light blue) GPT-3 GPT-3 R-GCN Cluster \nUsers Cluster \nUsers \nFigure 1: Our framework overview: Using Trained Graph Models, Large Language Models (GPT-3) and Human\nInteraction to Form Information Communities for News Media Profiling . (Key: U = Users, A = Articles, S = Sources, Light\nRed Background = Candidate information Communities, Light Blue Background = Validated Information Communities). From\nthe learned graph model (b), we find candidate information communities through k-means clustering. Using a LLM, GPT-3, we\nform a textual representation of the information community by summarizing its users, and then ask humans to narrow down the\ncommunity based on the user summaries (d), forming smaller, validated communities, whose users are then connected to each\nother. We then expand the validated communities, by again model clustering users, forming user summaries, but this time asking\nGPT-3 to place or not palce the users into validated communities, which can be done repeatedly (e). This entire process (c-e) can\nrepeat, starting with clustering of unassigned users (c), to form more validated communities, which can be expanded further.\nsystems, even LLMs (as we experimentally show).\nThus, instead, in this paper, we propose an inter-\nactive learning framework , to form information\ncommunities. We take advantage of minimal hu-\nman interactions, combining it with the strengths\nof news media profiling graph models and LLMs,\nto form the communities. We do this in an iterative\nprocess, showing how less than 5 human interac-\ntions, which do not label any additional data, can\nlead to significant improvements in both fake news\nand bias source detection, even in the challenging\nweakly supervised emerging events settings.\nSpecifically, to form the communities, we first\nform initial candidate communities by clustering\nsocial media users based on their graph model em-\nbeddings, capturing model beliefs. As news media\nprofiling is difficult, these candidate information\ncommunities are likely to be imperfect, i.e., some\nusers are likely to be inconsistent with their commu-\nnity assignment. Thus, these assignments need to\nbe validated, by examining their actual information\npreferences and the content they generate, rather\nthan using only relational information. This would\nhelp ensure that only users that are actually simi-\nlar to each other (i.e. have similar perspectives on\nsimilar content) make up each community. We use\nLLMs and human interaction to do this validation.\nFirst, we summarize each user in the community\nusing LLM\u2019s, mapping their profile to a short stat-\nment capturing their views. This representation fa-\ncilitates the human validation step, in which we ask\nhumans to determine which users are similar, and\nby that form validated communities (experimentsshow this is hard for LLMs, but simple for hu-\nmans). We then expand the validated communities,\nadding new users to them, based on model cluster-\ning. These assignments are again validated based\non users\u2019 summaries, but this time using LLMs\nto compare new users to users in human validated\ncommunities (we use human interactions as train-\ning examples for few-shot user similarity detection,\na simpler LLM task). For users not assigned to val-\nidated communities, the above process is repeated,\nexpanding the # of communities. Fig. 1 shows an\noverview. In short, humans interact to help form\ninitial communities, which are then automatically\nexpanded using graph and LLM similarity.\nIn summary, we make the following contribu-\ntions: (1): We formulate the task of interactive\nnews media profiling, by presenting a framework\nto build information communities. (2)We take ad-\nvantage of graph model, LLM, and human knowl-\nedge to perform this interactive task rapidly. (3)\nWe evaluate on one of the most challenging news\nmedia profiling settings, emerging news events,\nshowing how our interactive framework leads to\nperformance improvements with less than 5 human\ninteractions. More generally, our framework can\nbe used to rapidly profile news media, without any\nadditional labeling and minimal human effort.\nSec. 3 describes our graph, Sec. 4 our interactive\nframework, Sec. 5 results, and Sec. 6 analysis.\n2 Related Work\nOver the last few years, there has been a large inter-\nest in profiling news media. Baly et al. and Sakke-\ntou et al. proposed datasets for political bias detec-\ntion, while (Li and Goldwasser, 2019; Liu et al.,\n2021, 2022) study methods for it. Further, fake\nnews detection has also been a hot research topic,\nstudied in graphs (Nguyen et al., 2020; Mehta et al.,\n2022; Yang et al., 2023), cross-domain (Huang\net al., 2021; Zhu et al., 2022a,b; Mosallanezhad\net al., 2022), and low-resource (Lin et al., 2022)\nsettings, amongst others.\nWe focus specifically on news media profiling\nin the emerging events setting, which is extremely\nchallenging, as test data is unseen and does not in-\nteract with any train data. Thus, this setting is ideal\nfor us to measure the benefits of human interactions.\nIt also has received a lot of recent attention due to\nits\u2019 challenge (Liu and Wu, 2018; Li et al., 2022),\nand we hypothesize that some of these methods can\nbe combined with our work.\nLarge Language Models (LLMs) have been ap-\nplied to many tasks, as they can capture lots of\nknowledge (Qin et al., 2023). However, LLMs still\ncannot reason well, and thus struggle on harder\ntasks like fake news detection (Whitehouse et al.,\n2022). We instead use LLM\u2019s successful properties\nto amplify the impact of human interactions.\nInteractive ML has also been studied and ap-\nplied to many tasks (Wu et al., 2022; Dalvi et al.,\n2022; Kwon et al., 2023; Ramamurthy et al., 2023;\nPacheco et al., 2022, 2023; Mehta and Goldwasser,\n2023). Building information communities is also\na popular research area, whether it be through\nembeddings or DNN modeling approaches (Cav-\nallari et al., 2017; Su et al., 2022). Prior work\nalso shows misinformation spreads in communities\n(Bessi et al., 2016). We propose to interactively\nbuild information communities, by humans inter-\nacting with LLMs and graph models. We discuss\nmore related works in App. E.\n3 Graph Overview\nIn this paper, we focus on detecting the political\nbias and factuality of news media sources, which\nwe call news media profiling . We model sources\nfor factuality and political bias on a 3-point scale:\nlow,mixed , and high factuality, or left,center , and\nright political bias. More details about this task\nsetup and its importance are in (Baly et al., 2020)\nand Appendix A.1.\nWe use the public graph-based social media anal-\nysis model from Mehta et al.1, which they trained\n1https://github.com/hockeybro12/for fake news source detection. As we also evaluate\nnews source bias detection, we train the graph for\nboth objectives, on Twitter data. We refer to Mehta\net al. for the details of this graph model, but briefly\nexplain it here. Sec. 4 explains our interactive pro-\ntocol for identifying information communities.\nThe model uses a heterogeneous graph, encoded\nusing Relational Graph Conv. Networks (R-GCN),\nto capture the relationships between sources, arti-\ncles, and users. Based on the R-GCN representa-\ntions, factuality and bias of news sources can be\npredicted. R-GCNs allow us to better capture rela-\ntionships in the graph, such as a source represented\nin part by the users that follow it (which are also\nrepresented by their relationships to other nodes).\nGraph Creation using Twitter Social Context:\nOur graph (Fig.1a, Mehta et al.) consists of 3 node\ntypes: News Sources ( S), Articles ( A) they publish,\nand Twitter Users ( U) that interact with sources\nand articles. We connect sources to articles they\npublish, via edges. Further, users are connected to\nsources and other users they follow, and articles\nthey propagate (retweet or tweet the link of). The\nTwitter users provide the social information in the\ngraph, which we later aim to better learn.\nGraph Training using Social Context: Similar\nto Mehta et al., we train a R-GCN (Schlichtkrull\net al., 2018) to learn the graph. We train the classifi-\ncation objective of both fake news source detection\nand news source bias detection, using a separate\nFully Connected (FC) layer for each, optimizing\nthem jointly by summing the losses. Once the\nmodel is trained, we can use it to obtain meaning-\nful node embeddings for every node in the graph,\nand profile news sources. More details: App. A.3.\n4 Interactive Approach\nWhile the above graph-based model proposed by\nMehta et al. achieves strong performance on fake\nnews source detection when evaluated in transduc-\ntive settings (test data seen at training time), it strug-\ngles in the fully inductive settings (test data unseen),\nand in general performs well below human base-\nlines. We thus propose an interactive approach,\ncombining the strengths of graph models, large lan-\nguage models (LLMs i.e. GPT-3), and humans, to\nprofile content on social media better.\nOur approach hinges on the fact that if we can\nbetter model user preferences and thus user sim-\nilarity, we can better model the content they\nFakeNews_Inference_Operators\npropagate . This is because, similar users are likely\nto have similar interests, and thus share similar con-\ntent, which in turn is likely to have similar levels\nof factuality/bias. For example, a group of users\nsharing content in support of lowering taxes and\ndecreasing regulations are more likely to be right-\nbiased (i.e. Republican) vs. left-biased (i.e. Demo-\ncrat), and thus any source content they share is also\nmore likely to be right-biased. Thus, we hypothe-\nsize that the larger the groups of users with similar\ncontent preferences we can form, the higher our\nperformance is likely to be. Further, if we explicitly\ncreate new graph edges between these similar\ngroups of users , this information will flow to other\nusers not part of these groups, and eventually news\nsources, increasing classification performance.\nFortunately, while modeling user content pref-\nerences solely through AI models like LLMs is\ndifficult (Whitehouse et al., 2022), humans can\nquickly determine if two users are similar, forming\nan initial group. Then, we hypothesize, that LLMs\ncan be prompted using the human insight to extend\nthe group, by asking them if other users are similar\nin the same ways. Thus, in this paper, we propose\naninteractive framework , taking advantage of\nhuman and LLM strengths to better model user\ncontent preferences, and improve media profiling.\nSpecifically, in this Sec., we discuss the interac-\ntive approach we propose to form these groups of\nsimilar users, or information communities . We take\nadvantage of the strengths of trained graph model\nknowledge, LLM knowledge (GPT-3), and human\ninsight to design an iterative, interactive approach:\nWe first use the graph models\u2019 learned user similar-\nities to form initial candidate information commu-\nnities (Sec. 4.1), which are summarized by LLM\u2019s\n(Sec. 4.2), and then validated by a human interactor\n(Sec. 4.3). These validated communities are then\nexpanded upon to include more users in Sec. 4.4,\nby again using graph model knowledge and LLM\u2019s.\nHowever, this time LLM\u2019s are prompted based on\nthe human interaction, to validate user assignments\nto communities. This expansion step can be done\niteratively, i.e. assigning additional users to val-\nidated communities. Once enough users are not\nassigned to existing communities, we form an addi-\ntional set of human validated communities, repeat-\ning the the above process from Sec. 4.1-Sec. 4.4,\nand the number of total validated communities is\nincreased (Sec. 4.5). Finally, once enough infor-\nmation communities are formed, we can then learn\nthem (Sec 4.6), updating graph model parameters.We later show that through this iterative process,\nminimal human interactions can lead to significant\nperformance improvements for news media profil-\ning. Fig. 1 and Alg. 1 shows an overview.\nAlgorithm 1 Our Interactive Framework to Find\nValidated Information Communities\n1:Input: U(Users), UE(Graph User Embeddings), V\n(empty list to store validated information communities)\n2:Output: V(Validated Communities)\n3:Iteratively find information communities\n4:while not converged do\n5: c1...k=k-means (UE)K-means Cluster all Users\nbased on Graph User Embeddings\n6: c1, c2=max 2(purity (c1...k))Choose the highest\npurity clusters, that discuss the same entity\n7: s1, s2=GPT-3 summarize (c1, c2)Use GPT-3 to\nsummarize the users in each cluster\n8: V.append ([human (s1),human (s2)]) Validate\nclusters using humans to form validated\ncommunities\n9: Now, iteratively expand each validated\ncommunity\n10: while not converged do\n11: c1...k = k-means (UE)Again Cluster all\nUsers based on Graph User Embeddings\n12: c1...k = KNN(c1...k, V)For each cluster,\nfind the mnearest neighbors to each\nvalidated community, that\u2019s our new\ncluster\n13: V= ( GPT-3 (c1...k, V))For each cluster,\nask GPT-3 to assign or not assign users to\nvalidated clusters, expanding them\n14: end while\n15: end while\n16: return V(Validated Information Communities)\n4.1 Initial Communities from Graph Model\nThe first step in our process of forming information\ncommunities of similar users is forming candidate\nones. For this, we use learned graph model knowl-\nedge, and k-means cluster all graph user node em-\nbeddings, as similar nodes will be part of the same\ncluster (and thus community). We keep the two\n(determined empirically using the dev. set) highest\npurity clusters, as the model is likely most confi-\ndent about them, since it predicts similar users as\nhaving the same labels. To compute purity, each\ncluster is assigned to a class based on the most\npredicted user label in that cluster, and then the\naccuracy of this is measured. To get predicted user\nlabels, we assign each user the label of the most\ncommon source they follow + article they tweet.\nSince these communities are formed using graph\nlearned relationships, they are likely imperfect, and\nshould be analyzed to form better communities.\nThus, we ask humans to analyze them. However,\nas the communities have a lot of users which would\nrequire a lot of interactions, we narrow them down.\nWe only keep users that discuss the most common\nentity mentioned in the community, as discussion\naround this entity can represent the community\u2019s\nperspective. To do this, we run an Entity Recogni-\ntion system (Akbik et al., 2019) on the articles each\ncommunity user tweets, keeping users if they tweet\nan article containing the most frequent entity in the\ncommunity. We now have initial model predicted\ninformation communities of users that discuss the\nsame entity, and thus likely the same event.\n4.2 Characterizing Users Using GPT-3\nBefore asking humans to validate communities\nbased on user similarity, we form a textual repre-\nsentation for each user, that can be analyzed. While\nnot essential, this representation captures relevant\ncontent and user preferences, making human inter-\naction easier. To form it, we use LLMs (GPT-3),\nprompting them to create user summaries, as they\nhave historically done well on this task (Qin et al.,\n2023). The summary for each user is formed based\non their Twitter profile and a sample of their tweets\nrelated to the entity. An ex. of the prompt we\ndesigned is shown below in Tab. 1 and Fig. 2.\nFormat Language\nQuestionWhat is the user discussing\nand what is their perspective?\nTextBio: ... Tweet 1: ... Tweet 2:...\nSummary:\nOutput The user is discussing...\nTable 1: The question, text, and output format expected from\nGPT-3 in the prompt to create user summaries.\n4.3 Human Interaction to Form Community\nBased on the GPT-3 summaries of each user in the\ncommunities, we ask a human interactor to tighten\neach community, and only keep similar users. For\nthis, humans read the summaries, analyzing user\nperspective towards the entity . We say users have\nthe same perspective if they discuss the same entity\nin a similar way (i.e. all are against BLM protests).\nTo make this analysis easier for humans, we also\nprovide humans with an LLM\u2019s opinion on which\nusers are similar. While it is likely incorrect, as\nLLMs can\u2019t reason well about user similarity on\nunseen topics (see Sec. 6.2), it can help humans\nmake their decision quicker. To get it, we feed all\nuser summaries to a dialogue LLM, Chat-GPT2,\nasking it: Which users have the same perspective?\n2https://chat.openai.com/chatWe use Chat-GPT instead of GPT-3 as it is better\nsuited to respond without being prompted, and it is\nhard to create a general enough prompt for this.\nChat-GPT responds with a list of users that it\nthinks have the same perspectives, for ex.: User a,\nb, c, d discuss ... while e, f discuss ... , which the\nhuman then reads (along with the summaries) and\nuses to form a human validated community. For\nex., the human can decide users (a, b, c )are in the\nsame community, where dwas thought to be part\nof it by Chat-GPT, but not by the human. An ex. of\nthe exact text humans read is in Fig. 3.\n4.4 Automatically Expanding Communities\nSo far, we have formed small, human validated\ninformation communities, each of a single perspec-\ntive. Now, we amplify this human interaction by ex-\npanding these communities, while maintaining the\nsame perspective. We do this by identifying other\nusers that have the same perspective and adding\nthem to the community. These larger communities\ncan then be used to to profile news media better.\nWe first connect the users in each validated com-\nmunity to each other, which changes their and other\nusers\u2019 graph embeddings, without any training. We\nthenk-means cluster all user embeddings, ignoring\nany users already considered (to avoid redundancy).\nThis forms knew, unique clusters, based on learned\ngraph model knowledge. We hypothesize that if\nwe can accurately map some users from each of\nthese different clusters to validated communities,\nwe would have a lot more information about each\nof those clusters, which could help news media\nprofiling. (Aside: an alternative way to expand\ncommunities, which we do not pursue, is by assign-\ning users that have similar embeddings as validated\ncommunities to them. However, this would just\nreinforce existing model predictions, as the model\nalready believes these users similar, and thus likely\nnot lead to better news media profiling.)\nTo map users from clusters to validated commu-\nnities, for each cluster, we keep the top musers\nthat have similar embeddings to the centroids of\neach validated community, as these are the most\nlikely users to belong to the community. These m\nusers are now the candidate users for expansion\ninto the validated community.\nAs this user to community assignment is based\nonly on graph knowledge, it may be imperfect, so\nwe hypothesize to use LLMs to clean it up. While\nLLMs cannot reason about community assignments\non unseen news events (we experimentally show\nthis), which is why we used humans in Sec. 4.3,\nwe hypothesize that if prompted appropriately, they\ncan compare user summaries on a topic, which the\nhuman communities are already centered around.\nBuilding on this, we few-shot prompt LLMs, ask-\ning them to identify user similarity and determine\nwhich of the mnew users should be part of the\nvalidated community. To do this well, we prompt\nthe LLM using a training example, created auto-\nmatically from the human validated community. In\nit, community assignments humans chose when in-\nteracting are positive examples, while ones humans\nrejected are negative. LLMs now just have to make\nsimilar assignments as humans (i.e. determine if\nthe new users are more similar to human accepted\nor rejected ones), a much simpler task. Tab. 2\nshows an ex. of the test prompt for the community\nwith users (a, b), where user ais assigned to the\ncommunity and bis not. The same prompt format\nis used for the training example, except the sum-\nmaries and assignments are provided based on the\nhuman interaction. Fig. 4 shows the full prompt.\nFormat Language\nQuestionWhich users have the same\nperspective?\nTextUser A Summary: ...\nUser B Summary: ...\nRelated Users;;;;Not Related Users:\nOutput User A;;;;User B\nTable 2: The question, text, and output format expected from\nGPT-3 in the prompt to determine if users belong to a given\ninformation community. From the output, User A belongs,\nand User B does not.\n4.5 Iterative Community Expansion\nThe above process in Sec. 4.4 of expanding the\nvalidated communities can then be repeated until\nall users are assigned to or rejected for validated\ncommunities, defining convergence.\nIn addition, we also use a subset of rejected users\nto form a new set of human validated information\ncommunities. To do this, we repeat the above pro-\ncess from Sec. 4.1-Sec. 4.4: cluster rejected users,\nsummarize them, ask humans to form a new val-\nidated community, and then expand the validated\ncommunity. After each iteration, we have an addi-\ntional pair of human validated communities.\n4.6 Unsupervised Graph Training\nAbove, when we form communities, we create new\ngraph edges connecting users in the same com-\nmunity. We now further learn these edges/user\nrelationships, by fine-tuning the graph model fromSec. 3, all without using any additional gold labeled\ndata. For this, we train graph link prediction, which\ncaptures this new edge knowledge directly, encour-\naging connected nodes to have similar embeddings.\nWe do it only on the sub-graph of content that was\ninteracted on: the users and the articles/sources\nthey are directly connected to. Specifically, we\ntrain connected nodes to be closer together in the\nembedding space, while user nodes in different\ncommunities should be farther apart.\nAfter this training, the graph model captures the\nknowledge from the user communities identified\nby our framework, and can thus be directly used to\nbetter classify news sources for profiling. This is\nbecause, in the updated graph model, the new user\nembeddings directly affect the sources, through\neither direct or indirect edge connections.\n4.7 Framework Recap\nIn short, we aim to build user information com-\nmunities, used by the graph model for better news\nmedia profiling. Our framework first uses graph\nmodels to build candidate communities, which are\nvalidated by humans. Identifying the communities\nis hard for LLMs, but simple for humans and can be\ndone in a few minutes. Then, the communities are\nexpanded. The graph model generates candidates,\nwhich the LLM can validate, as it has training ex-\namples from the human validation, and just has to\nidentify the same user similarity, a much simpler\ntask. The entire process can be done iteratively and\nrapidly (under 10 minutes for 5 interaction steps).\n5 Experiments\n5.1 Evaluation Settings\nWe evaluate our framework\u2019s ability to improve\nfake news and news source bias detection. We fo-\ncus on one of the most challenging settings for a\ngraph framework, the fully inductive setting. Here,\nin addition to test data not being seen at training\ntime, all test nodes are not connected in any\nway to training set nodes . For ex., users inter-\nacting with test set articles do not interact with any\nsources/articles/users seen at train time. While this\nsetting is particularly difficult, as social media in-\nformation learned at training time can\u2019t be directly\nused to improve test performance, it can occur, such\nas when a new bot farm spreads content.\nIn addition to the inductive setting, we also focus\nour evaluation on emerging news events, where all\ntest data is from a specific event collected from a\nModel Baly\nAcc.Baly\nF1Test\nAccTest\nF1\nBaly 71.52 67.25 - -\nMehta R-GCN 68.90 63.72 - -\nMehta BEST 72.55 66.89 - -\nBL: Mehta R-GCN 65.82 53.19 41.89 28.48\nTable 3: Fake News Source Detection baseline Results on\nBaly (Baly et al., 2020) and the inductive future Black Lives\nMatter event (Test). Results show that despite achieving high\nperformance on (Baly et al., 2020), the Baseline from Mehta\net al. (BL: Mehta R-GCN) struggles in the inductive,\nemerging news events setting. This baseline is comparable to\nthe state of the art for fake news source detection from Mehta\net al. (Mehta BEST) on (Baly et al., 2020).\ntime period after the training time period. Not only\nis this one of the most common real-world applica-\ntions for fake news source and bias detection, but\nit is also very challenging, as test data focuses on\nsub-events not seen at training. In this work, we\nevaluate two important news events: Black Lives\nMatter (BLM) andAbortion/Feminism .\n5.2 Data Collection and Usage\nFake News and Bias Source Detection : In order\nto evaluate our framework\u2019s ability to improve fake\nnews and news source bias detection, we used the\nMedia Bias/Fact Check dataset, originally collected\nby Baly et al.. As we focus on specific events, many\nof which have occurred since the dataset was origi-\nnally collected, we expand it by scraping additional\nnews sources from Media Bias/Fact Check3. Ad-\nditionally, we scraped the data used to construct\nthe graph in Sec. 3 (articles sources publish, Twit-\nter users, Twitter interactions, etc.) following the\nprocess in Mehta et al.. As done in Baly et al., we\nlabel news sources on a 3-point factuality and 3-\npoint bias scale: high,mixed , orlowfactuality and\nleft,center , orright bias. Dataset details, including\nstatistics for number of sources is in App. D and\nTab. 6. Our code and anonymized data is available.4\nEvents: For each event that we tested on (Black\nLives Matter and Abortion/Feminism), we scraped\ndata for 2 different time periods (01/02/2019 -\n06/01/19; 06/02/19 - 05/06/22), searching relevant\nhashtags on Twitter. These time periods also cover\na broad range of sub-events, allowing us to test how\nour models would do on emerging news events. To\nlearn the graph model for fake news and bias source\ndetection from Sec. 3, we used the first period and a\nsubset of data from Baly et al. (training the model\n3https://mediabiasfactcheck.com\n4https://github.com/hockeybro12/\nInteractive_News_Media_Profilingon the event and general news). The other time\nperiod is our test data, and forms a fully inductive\ngraph, where none of the nodes in the test graph are\nconnected to training set nodes, making it hard.\n5.3 Evaluation\nWe evaluate our models primarily on Accuracy\nand Macro F1 score (the dataset is unbalanced),\nfor sources. We also evaluate the # of users and\nsources interacted on, the total # of edges added\nby all interactions, the # of expansion rounds done\n(defined in Sec 4.4), and the # of interactions done.\n5.4 Baselines\nOur first baseline is the strong graph based fake\nnews source detection model from Mehta et al.,\nwhich we also trained for and evaluated on bias de-\ntection. They also compared to multiple baselines\nin their work. Tab. 3 shows the performance of this\nmodel on Baly et al., but when evaluated on BLM\nin the inductive setting, it struggles (Tab. 3, Tab. 4).\nOur second baseline is our information com-\nmunity detection approach without humans and\nLLMs, creating the communities based only on\ngraph model embeddings (Graph Only). We k-\nmeans cluster user embeddings, and choose high\npurity clusters, keeping the top msimilar users. We\nchoose k=35 based on validation set performance.\nOur final baseline, LLM Only, is our frame-\nwork without humans, but still using LLM + graph\nknowledge. To remove the interaction step from\nSec. 4.3. where humans form validated communi-\nties by reading summaries and Chat-GPT\u2019s assign-\nments, we instead trust the Chat-GPT assignments\nand use these as the \u201cvalidated\u201d communities.\n5.5 Interactive Framework Results\nResults for Black Lives Matter fake news and bias\nsource detection are in Tab. 4. Abortion/Feminism\nresults are in Tab. 7 + Tab. 8. Results show how our\ninteractive framework (LLM + Humans) enables\nminimal human interactions (details about interac-\ntion process in App. C), sometimes only one, to\nlead to performance improvements for these tasks,\neven on emerging news events without additional\nlabels. We experimented with a varying # of val-\nidated communities and expansion rounds (using\nthe dev. set to find the #), and all showed improve-\nments in either Acc. or F1 score over baselines.\nSpecifically, we see \u223c33% improvement on fake\nnews source macro F1, and \u223c40% improvement\non bias news source macro F1. Our best models\nModel FN\nAccFN\nF1Bias\nAccBias\nF1# Users;\n# Sources# Edges # Inter-\nactions\nBaseline: (Mehta et al., 2022) 41.89 28.48 46.79 27.43 - - -\nGraph Only: High Purity 2 Communities (Comms.) 43.01 28.85 46.15 28.59 25; 25 1,200 -\nGraph Only: High Purity 4 Communities (Comms.) 41.89 27.23 48.71 21.83 - - -\nLLM Only: 2 Comms, 2 Expansion Rounds 42.70 28.05 45.01 27.84 38; 63 494 -\nLLM Only: 4 Comms, 2 Expansion Rounds 42.70 28.62 39.50 33.22 69; 56 1,791 -\nLLM Only: 6 Comms, 2 Expansion Rounds 40.54 26.88 37.03 29.22 73; 63 1,612 -\nLLM + Humans: 2 Comms, 2 Expansion Rounds 52.51 38.03 44.23 33.40 25; 26 367 1\nLLM + Humans: 2 Comms, 4 Expansion Rounds 46.36 35.03 49.35 45.13 72; 56 1,087 1\nLLM + Humans: 4 Comms, 2 Expansion Rounds 43.01 32.36 47.43 32.00 55; 43 808 2\nLLM + Humans: 6 Comms, 2 Expansion Rounds 41.34 32.36 48.07 33.91 82; 61 1,696 3\nTable 4: Fake News (FN) and Bias Source Detection on Black Lives Matter: We evaluate Test Set Accuracy, Macro F1, the # of\nusers and sources directly connected, the # of edges created, and the # of human interactions are performed (each forms 2\nvalidated communities). Results show that our proposed approach, the human interaction models (LLM + Humans, last group),\nachieve improvements over all other models in Acc. and/or F1. Also, human interactions are critical, as LLM Only models (third\ngroup; they still use graph insight) do not achieve significant improvements over baselines (first and second group). Moreover,\nour best performance is with only 1 single human interaction, creating 2 communities and then expanding them (2 expansion\nrounds for fake news source detection and 4 for bias source detection).\nfor each task and each event only needed up to\ntwo human interactions, showing the benefit of our\nframework to amplify human interactions. Also,\nall human interaction models outperform all non-\nhuman baselines, including LLM Only, showing\nthat both LLM and human insight (to sort out LLM\ninconsistencies) is critical for news media profiling.\nIn summary, these results shows how we are able\nto successfully decompose the task of finding in-\nformation communities: taking advantage of graph,\nLLM, and human strengths, to successfully profile\nnews media, even on emerging news events.\n6 Discussion\nIn this section, we evaluate our Black Lives Matter\ninteractive framework (Sec. 5.5) learned informa-\ntion communities. We begin by analyzing the cohe-\nsiveness of the communities, first human (Sec.. 6.1)\nand second automatically (App. F.1). We then show\nwhy human interactions are critical (Sec. 6.2). Fi-\nnally, we analyze the communities themselves, an-\nalyzing the topics discussed (App. F.2).\n6.1 Human Interactor Analysis\nIn this section, we manually analyze our human\ninteraction process, by asking the interactor how\nmany candidate users for each information commu-\nnity they used and did not use to represent it, in\neach human community validation round. Results\nin Tab. 5 show that as more interaction steps oc-\ncur, the candidate users become more similar, as\nhumans reject less users. This shows how our inter-\nactive process improves the model\u2019s understandingof the social media framework.\nInteraction Round Users Accepted Users Rejected\n1 3 9\n2 3 6\n3 4 2\n4 6 1\nTable 5: The number of users accepted and rejected by human\ninteractors in each new community creation step. As more\ninteractions occur, the # of rejected users decreases, as the\ngraph model learns to better capture similarity. Note that the #\nof users presented to humans changes based on cluster sizes.\n6.2 Importance of Humans\nAs the results in Sec. 5.5 show, the human inter-\naction step is critical to improve news media pro-\nfiling performance. This is because LLM\u2019s (i.e.\nChat-GPT) cannot accurately capture user similar-\nity, particularly for new news events, which leads\nto non-cohesive communities. However, humans\nwith general world knowledge can easily determine\nthis. As an ex. in Fig. 3 (more in App. F.3), Chat-\nGPT responds vaguely that all users share the same\nperspective, when User 3 is clearly more hostile.\nWithout cohesive initial communities, the train-\ning examples used to prompt the generation of\nfurther communities in Sec. 4.4 will also be\nnon-cohesive and thus incorrect, leading to non-\ncohesive expanded communities. Thus, the graph\nmodel wouldn\u2019t gain any insight about user per-\nspectives through the communities, which is why\ndownstream performance doesn\u2019t improve.\n7 Conclusion\nIn this paper, we proposed a framework for interac-\ntive news media source profiling. Our framework\ncombines the strengths of graph based news me-\ndia profiling models, LLMs, and humans, to build\nstronger information communities. We show how\nwithout any additional labeled data, and less than 5\nhuman interactions which can be done in under 10\nminutes, we can better detect fake news and bias\nsources, on two separate news events, even in the\nmost challenging setting of emerging news.\nOur future work is building larger and better\ncommunities, and having more human interaction\nrounds. We hypothesize that more data (users,\nsources, articles, and human interactions) could\nlead to lead to better communities, as our approach\ncan capture more perspectives on social media.\nThis would also likely lead to a better trend in\nthe results, leading to more consistent performance\nimprovements as the number of interaction rounds\nare increased.\n8 Acknowledgements\nWe thank the anonymous reviewers of this paper\nfor their vital feedback. The project was partially\nfunded by NSF award IIS-2135573 and NSF CA-\nREER award IIS-2048001.\n9 Ethics Statement\nFor the ethics statement, we first discuss limitations\nof our model (9.1), and then in Sec. 9.2 we discuss\nethics for deploying our models..\n9.1 Limitations\nIn this paper, we focus on news media profiling\n(fake news and bias source detection) on English\nand Twitter, specifically in the Black Lives Matter\ndomain. The experimental results we presented in\nthis paper showed our framework works in these\ndomains/tasks. We are hopeful and believe that\nour framework would generalize to other domains,\ntasks, and topics, but we leave the investigation of\nthis to future works.\nIn this paper, we also primarily focused on the\nevaluation setting of early detection of fake/biased\nnews sources, where we evaluate on unseen test\ndata that is not connected to any training set data\nin the graph. We believe that this is one of the\nmost challenging settings for news media profil-\ning, as shown by prior work. We thus believe thatour framework would generalize to other news me-\ndia profiling settings, including ones that are not\nin the early detection space. Our future work in-\nvolves testing this hypothesis, by combining our\nframeworks with other works in the early detection\nspace.\nOur framework utilizes Large Language Mod-\nels, specifically GPT-3, which the details are not\nyet fully known publicly. Although these models\nhave been shown to achieve strong performance\nin numerous NLP benchmarks (Qin et al., 2023),\nwe believe the community should still be careful in\ndeploying them.\nOur framework also utilizes human interactions,\nwhich in our paper are extremely simple, as humans\nmust just read short summaries to determine simi-\nlarity. Further, our framework needs an extremely\nsmall amount of human interactions. However, we\nstill caution that in a real world deployment of our\nframework, we should be careful of human inter-\nactors and make sure they do not have a malicious\nintent and are well educated for this task. Moreover,\nit would be better if numerous humans provided\njudgements on a single interaction sample, to con-\nfirm all the interactions across multiple experts.\nFor our experiments, we used a single GeForce\nGTX 1080 NVIDIA GPU, with 12 GB of memory.\nAs our models are largely textual based, they do\nnot require much GPU usage, but this could change\nin real world settings, where lots more data is avail-\nable, which could be a potential limitation. Our\nhyper-parameter search, mentioned was done man-\nually, based on dev set performance. The appendix\nprovides more model details.\n9.2 Ethics\nTo the best of our knowledge, we did not violate\nany code of ethics throughout the experiments done\nin this paper. We reported technical details neces-\nsary to reproduce our results, and will release the\ncode and dataset we collected, upon publication.\nWe evaluated our model on the datasets that we\ncollected in this paper, and was collected by prior\nwork, but it is possible that results may differ on\nother datasets. However, we believe our methodol-\nogy is solid and applies to any social media news\nprofiling setting, as shown by our performance on\nemerging news events.\nDue to lack of space, we placed some of the tech-\nnical details in the Appendix section. The results\nwe reported support our claims in this paper and\nwe believe that they are reproducible. Any qualita-\ntive result we report is an outcome from a machine\nlearning model that does not represent the authors\u2019\npersonal views.\nIn our future dataset release, we include sources,\nusers, and articles, so that our experiments can be\nreplicated. Each are in English, and are public\ninformation. We map each to an ID, for anonymity,\nand release Article textual representations. Article\ntexts are available for academic use, and can be\nprovided by requesting the authors and agreeing to\nappropriate conditions.\nOur framework in general is intended to be used\nto profile news media sources, and help identify the\nspread of misleading or perspective changing con-\ntent on social media. While our framework could\nbe used to build better methods of avoiding fake\nnews/bias detection by ML systems, our interactive\nframework can guard against that as well.\nIn general, we caution that our models and meth-\nods be considered and used carefully, as in an area\nlike news media profiling there are great conse-\nquences of wrong model decisions, such as unfair\ncensorship and other social related issues. Further,\nit is possible our models are biased, and this should\nalso be taken into consideration. An important\nfuture work is to investigate our models, interpret-\ning them and understanding their predictions even\nbetter than the analysis showed in the Discussion\nsection of this paper.\nThe interactive setting we proposed was success-\nful in this paper, particularly because the interac-\ntions were simple. However, in the real world,\nthere could be biased interactors with malicious\nmotives, and that is an important thing to consider\nwhen dealing with fake/bias news source detection\nsystems.\nThese and many other related issues are things\nto consider when using models such as the ones\nproposed in this work.\nReferences\nAlan Akbik, Tanja Bergmann, Duncan Blythe, Kashif\nRasul, Stefan Schweter, and Roland V ollgraf. 2019.\nFLAIR: An easy-to-use framework for state-of-the-\nart NLP. In NAACL 2019, 2019 Annual Conference\nof the North American Chapter of the Association for\nComputational Linguistics (Demonstrations) , pages\n54\u201359.\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda\nAskell, Anna Chen, Nova DasSarma, Dawn Drain,\nStanislav Fort, Deep Ganguli, Tom Henighan, et al.\n2022. Training a helpful and harmless assistant withreinforcement learning from human feedback. arXiv\npreprint arXiv:2204.05862 .\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing ,\nEMNLP \u201918, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020. What was written vs. who\nread it: News media profiling using text analysis\nand social media context. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics , ACL \u201920.\nAlessandro Bessi, Fabio Petroni, Michela Del Vicario,\nFabiana Zollo, Aris Anagnostopoulos, Antonio Scala,\nGuido Caldarelli, and Walter Quattrociocchi. 2016.\nHomophily and polarization in the age of misinforma-\ntion. The European Physical Journal Special Topics ,\n225:2047\u20132059.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems , 33:1877\u20131901.\nSandro Cavallari, Vincent W Zheng, Hongyun Cai,\nKevin Chen-Chuan Chang, and Erik Cambria. 2017.\nLearning community embedding with community de-\ntection and node embedding on graphs. In Proceed-\nings of the 2017 ACM on Conference on Information\nand Knowledge Management , pages 377\u2013386.\nMatteo Cinelli, Gianmarco De Francisci Morales,\nAlessandro Galeazzi, Walter Quattrociocchi, and\nMichele Starnini. 2021. The echo chamber effect on\nsocial media. Proceedings of the National Academy\nof Sciences , 118(9):e2023301118.\nBhavana Dalvi, Oyvind Tafjord, and Peter Clark. 2022.\nTowards teachable reasoning systems: Using a dy-\nnamic memory of user feedback for continual system\nimprovement. In Proceedings of the 2022 Confer-\nence on Empirical Methods in Natural Language\nProcessing , pages 9465\u20139480.\nYosh Halberstam and Brian Knight. 2016. Homophily,\ngroup size, and the diffusion of political information\nin social networks: Evidence from twitter. Journal\nof public economics , 143:73\u201388.\nYinqiu Huang, Min Gao, Jia Wang, and Kai Shu. 2021.\nDafd: Domain adaptation framework for fake news\ndetection. In International Conference on Neural\nInformation Processing , pages 305\u2013316. Springer.\nMinae Kwon, Sang Michael Xie, Kalesha Bullard, and\nDorsa Sadigh. 2023. Reward design with language\nmodels. In The Eleventh International Conference\non Learning Representations .\nChang Li and Dan Goldwasser. 2019. Encoding so-\ncial information with graph convolutional networks\nforpolitical perspective detection in news media. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 2594\u2013\n2604.\nKe Li, Bin Guo, Siyuan Ren, and Zhiwen Yu. 2022.\nAdadebunk: An efficient and reliable deep state space\nmodel for adaptive fake news early detection. In Pro-\nceedings of the 31st ACM International Conference\non Information & Knowledge Management , pages\n1156\u20131165.\nHongzhan Lin, Jing Ma, Liangliang Chen, Zhiwei Yang,\nMingfei Cheng, and Chen Guang. 2022. Detect ru-\nmors in microblog posts for low-resource domains\nvia adversarial contrastive learning. In Findings\nof the Association for Computational Linguistics:\nNAACL 2022 , pages 2543\u20132556.\nRuibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu,\nand Soroush V osoughi. 2022. Quantifying and alle-\nviating political bias in language models. Artificial\nIntelligence , 304:103654.\nRuibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu,\nLili Wang, and Soroush V osoughi. 2021. Mitigating\npolitical bias in language models through reinforced\ncalibration. In Proceedings of the AAAI Conference\non Artificial Intelligence , volume 35, pages 14857\u2013\n14866.\nYang Liu and Yi-Fang Wu. 2018. Early detection of\nfake news on social media through propagation path\nclassification with recurrent and convolutional net-\nworks. In Proceedings of the AAAI conference on\nartificial intelligence , volume 32.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nNikhil Mehta and Dan Goldwasser. 2023. Interac-\ntively learning social media representations improves\nnews source factuality detection. arXiv preprint\narXiv:2309.14966 .\nNikhil Mehta, Mar\u00eda Leonor Pacheco, and Dan Gold-\nwasser. 2022. Tackling fake news detection by con-\ntinually improving social context representations us-\ning graph neural networks. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n1363\u20131380.\nAhmadreza Mosallanezhad, Mansooreh Karami, Kai\nShu, Michelle V Mancenido, and Huan Liu. 2022.\nDomain adaptive fake news detection via reinforce-\nment learning. In Proceedings of the ACM Web Con-\nference 2022 , pages 3632\u20133640.\nVan-Hoang Nguyen, Kazunari Sugiyama, Preslav\nNakov, and Min-Yen Kan. 2020. Fang: Leveragingsocial context for fake news detection using graph\nrepresentation. In Proceedings of the 29th ACM In-\nternational Conference on Information & Knowledge\nManagement , pages 1165\u20131174.\nOpenAI. 2023. Gpt-4 technical report. ArXiv ,\nabs/2303.08774.\nMar\u00eda Leonor Pacheco, Tunazzina Islam, Monal Maha-\njan, Andrey Shor, Ming Yin, Lyle Ungar, and Dan\nGoldwasser. 2022. A holistic framework for analyz-\ning the covid-19 vaccine debate. In Proceedings of\nthe 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 5821\u20135839.\nMar\u00eda Leonor Pacheco, Tunazzina Islam, Lyle Ungar,\nMing Yin, and Dan Goldwasser. 2023. Interactive\nconcept learning for uncovering latent themes in large\ntext collections. In Findings of the Association for\nComputational Linguistics: ACL 2023 , pages 5059\u2013\n5080.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learning\nlibrary. In H. Wallach, H. Larochelle, A. Beygelz-\nimer, F. d 'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems\n32, pages 8024\u20138035. Curran Associates, Inc.\nChengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\nchatgpt a general-purpose natural language process-\ning task solver? arXiv preprint arXiv:2302.06476 .\nRajkumar Ramamurthy, Prithviraj Ammanabrolu,\nKiant\u00e9 Brantley, Jack Hessel, Rafet Sifa, Christian\nBauckhage, Hannaneh Hajishirzi, and Yejin Choi.\n2023. Is reinforcement learning (not) for natural\nlanguage processing?: Benchmarks, baselines, and\nbuilding blocks for natural language policy optimiza-\ntion. In The Eleventh International Conference on\nLearning Representations .\nBhavtosh Rath, Xavier Morales, and Jaideep Srivastava.\n2021. Scarlet: explainable attention based graph\nneural network for fake news spreader prediction. In\nPacific-Asia conference on knowledge discovery and\ndata mining , pages 714\u2013727. Springer.\nBhavtosh Rath, Aadesh Salecha, and Jaideep Srivas-\ntava. 2020. Detecting fake news spreaders in so-\ncial networks using inductive representation learn-\ning. In 2020 IEEE/ACM International Conference\non Advances in Social Networks Analysis and Mining\n(ASONAM) , pages 182\u2013189. IEEE.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nInProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP) , pages 3982\u20133992.\nFlora Sakketou, Joan Plepi, Riccardo Cervero,\nHenri Jacques Geiss, Paolo Rosso, and Lucie Flek.\n2022a. Factoid: A new dataset for identifying mis-\ninformation spreaders and political bias. In Proceed-\nings of the Thirteenth Language Resources and Eval-\nuation Conference , pages 3231\u20133241.\nFlora Sakketou, Joan Plepi, Henri-Jacques Geiss, and\nLucie Flek. 2022b. Temporal graph analysis of misin-\nformation spreaders in social media. In Proceedings\nof TextGraphs-16: Graph-based Methods for Natural\nLanguage Processing , pages 89\u2013104.\nMichael Schlichtkrull, Thomas N Kipf, Peter Bloem,\nRianne Van Den Berg, Ivan Titov, and Max Welling.\n2018. Modeling relational data with graph convolu-\ntional networks. In European semantic web confer-\nence, pages 593\u2013607. Springer.\nXing Su, Shan Xue, Fanzhen Liu, Jia Wu, Jian Yang,\nChuan Zhou, Wenbin Hu, Cecile Paris, Surya Nepal,\nDi Jin, et al. 2022. A comprehensive survey on com-\nmunity detection with deep learning. IEEE Transac-\ntions on Neural Networks and Learning Systems .\nMichela Del Vicario, Alessandro Bessi, Fabiana Zollo,\nFabio Petroni, Antonio Scala, Guido Caldarelli,\nH. Eugene Stanley, and Walter Quattrociocchi. 2016.\nThe spreading of misinformation online. Pro-\nceedings of the National Academy of Sciences ,\n113(3):554\u2013559.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nMinjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei\nLi, Xiang Song, Jinjing Zhou, Chao Ma, Lingfan Yu,\nYu Gai, et al. 2019. Deep graph library: A graph-\ncentric, highly-performant package for graph neural\nnetworks. arXiv preprint arXiv:1909.01315 .\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\net al. 2022. Chain-of-thought prompting elicits rea-\nsoning in large language models. Advances in Neural\nInformation Processing Systems , 35:24824\u201324837.\nChenxi Whitehouse, Tillman Weyde, Pranava Mad-\nhyastha, and Nikos Komninos. 2022. Evaluation\nof fake news detection with knowledge-enhanced\nlanguage models. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nvolume 16, pages 1425\u20131429.\nXingjiao Wu, Luwei Xiao, Yixuan Sun, Junhang Zhang,\nTianlong Ma, and Liang He. 2022. A survey of\nhuman-in-the-loop for machine learning. Future\nGeneration Computer Systems .Sin-han Yang, Chung-Chi Chen, Hen-Hsen Huang, and\nHsin-Hsi Chen. 2023. Entity-aware dual co-attention\nnetwork for fake news detection. In Findings of the\nAssociation for Computational Linguistics: EACL\n2023 , pages 106\u2013113.\nChunyuan Yuan, Qianwen Ma, Wei Zhou, Jizhong Han,\nand Songlin Hu. 2020. Early detection of fake news\nby utilizing the credibility of news, publishers, and\nusers based on weakly supervised learning. In Pro-\nceedings of the 28th International Conference on\nComputational Linguistics , pages 5444\u20135454.\nTianjun Zhang, Fangchen Liu, Justin Wong, Pieter\nAbbeel, and Joseph E Gonzalez. 2023. The wis-\ndom of hindsight makes language models better in-\nstruction followers. In International Conference on\nMachine Learning , pages 41414\u201341428. PMLR.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, et al. 2023. A\nsurvey of large language models. arXiv preprint\narXiv:2303.18223 .\nYongchun Zhu, Qiang Sheng, Juan Cao, Shuokai Li,\nDanding Wang, and Fuzhen Zhuang. 2022a. Gener-\nalizing to the future: Mitigating entity bias in fake\nnews detection. In Proceedings of the 45nd Inter-\nnational ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . Association\nfor Computing Machinery.\nYongchun Zhu, Qiang Sheng, Juan Cao, Qiong Nan,\nKai Shu, Minghui Wu, Jindong Wang, and Fuzhen\nZhuang. 2022b. Memory-guided multi-view multi-\ndomain fake news detection. IEEE Transactions on\nKnowledge and Data Engineering .\nA Experimental Settings\nA.1 Profiling News Media Sources Task\nDefinition and Importance\nIn this paper, we focused on detecting the political\nbias and factuality of news media sources, which\nwe call news media profiling . We focused on\nthese tasks as stopping misinformation is critical,\nand politically biased content can sway beliefs and\naffect important real-world events, such as political\nelections (V osoughi et al., 2018).\nWe model sources for factuality on a 3-point\nscale: low,mixed , and high. Similarly, we model\nsources for political bias on a 3-point scale: left,\ncenter , and right . More details about this task setup\nand its importance can be found in (Baly et al.,\n2020). Below, we also briefly discuss the impor-\ntance of profiling the source itself.\nFocusing on profiling the source itself, rather\nthan the content, can have several benefits, which\nis why we focused on this task work: (1)Most\nsources publish a large amount of content, and\nknowing the facutality/bias of the source can give\nus insight about all the content they publish. More-\nover, any new content that the source publishes\nis more likely to have a similar factuality/bias as\nthe source\u2019s historical content. Thus, knowing the\nsource\u2019s historical level of facutality/bias can pro-\nvide insight about the new content, which can help\nin rapidly profiling it. For example, a source pub-\nlishing mostly leftbiased content in the past is more\nlikely to be leftbiased in the future. (2)There are\na lot more sources than content on social media,\nso it can be easier to accurately profile sources,\nand our framework makes this task even easier. As\nmentioned above, doing this can then provide in-\nsights on all the content the source publishes. (3)\nThere are many new news sources arising daily, so\nmanually profiling all of them is extremely difficult.\nThus, developing an automated system is critical.\nA.2 Graph Initial Embeddings\nWe followed the released code and data from Mehta\net al., so we use their exact node embedding repre-\nsentations as our initial graph embeddings. The\nTwitter embedding is a 773 dimensional vector\nconsisting of the SBERT (Reimers and Gurevych,\n2019) RoBERTa (Liu et al., 2019) representation of\nthe user profile, consisting of features such as: user\nbio, user verification status, number of user fol-\nlowers/following, how many tweets they post, and\nhow many likes their tweets have received. We alsoused similar features for YouTube embeddings for\neach source: number of likes, dislikes, and number\nof comments on their videos. For the article fea-\nture vector, it was also a SBERT RoBERTa textual\nembedding.\nA.3 Models and Training\nWe used the ChatGPT models available via the\nOpenAI API5as of February 2023.\nFor our graph models, we used the publicly re-\nleased code and hyper-parameters of Mehta et al.,\nwhich uses the PyTorch (Paszke et al., 2019) and\nDGL (Deep Graph Library) (Wang et al., 2019)\nlibraries in Python. The R-GCN has 5 layers, 128\nhidden unites, a batch size of 128, and learning rate\n0.001.\nOur models are trained using a 12GB Titan XP\nGPU card, and intial training takes 2 hours. Link\nprediction training after human interactions is very\nquick, and can complete in under 30 minutes. Fur-\nther, doing the expansion step completes in under\n30 minutes. It took under 10 minutes for the hu-\nmans to do all the interactions.\nWe used the development set to evaluate model\nperformance, and choose the best hyper-parameters\nfor our experiments.\nOur models are trained for source classifica-\ntion, using a separate Fully Connected (FC) layer\nfor each fake news source classification and po-\nlitical bias source classification. The R-GCN\n(Schlichtkrull et al., 2018) model we use creates\ncontextualized graph embeddings for each node in\nthe graph. For example, source embeddings are\naffected by users and articles they are directly or\nindirectly connected to. This is why our approach\nto learn user communities, which leads to better\nuser embeddings (i.e. users with similar perspec-\ntives are closer together), leads to better source\nembeddings.\nAfter being passed through the FC layer for clas-\nsification, the R-GCN source embeddings are then\npassed through the Softmax activation function,\nand finally used to predict the source label. The\nmodel is trained like in Mehta et al., using a cat-\negorical cross-entropy loss, where the gold train-\ning labels are factuality or political bias. The two\nsource classification tasks are trained jointly, sum-\nming their losses.\n5https://openai.com/blog/openai-api\nB Prompts for GPT-3\nIn this section, we describe the prompts we use for\nGPT-3 and Chat-GPT, to utilize the large amounts\nof pre-trained knowledge contained in these models\nto help us in our interactive framework. It has been\nshown (Brown et al., 2020; Wei et al., 2022) that\nprompting can help utilize LLMs like GPT-3 for\nmany NLP tasks, as they cannot be trained directly.\nWhile these models cannot do complex reasoning\nto determine if sources are fake or biased news,\nthey can solve simpler tasks, such as determining\nif users have the same perspectives, which can help\nwith our tasks, that we built into our interactive\nframework. Specifically, they can summarize users\nbased on their content (Fig.2), help humans analyze\nperspectives (Fig. 3), and determine community\nmembership based on similarity (Fig. 4),\nAll the prompts used in this paper are human\ndesigned.\nC Human Interaction Details\nWe used a single human interactor for all our exper-\niments, who was a computer science PhD student,\nof Asian American descent. The student was com-\npensated in research credit hours, as the interaction\nprocess was part of their research credit work.\nWe used only a single human due to the fact that\nour interaction process is very simple, as humans\nonly read a few user summaries and determine con-\ntent similarity, which in all cases we evaluated on\nis fairly straight-forward. Moreover, the amount of\ninteractions done in this work was very small, as\nonly 5 interactions could lead to the formation of\n8 information communities and connect different\ncommunities together. The human we used was\nalso expertly trained. Thus, we did not explore\nusing additional interactors in this work, and it is\nsomething we leave for future work. For example,\nother setups could use multiple experts for human\ninteractions, taking their majority vote as the final\ninteraction.\nD Dataset Statistics\nTable 6 shows the statistics of the number of\nsources for the Black Lives Matter and Abor-\ntion/Feminism event we evaluate on.\nTo collect the data for Black Lives Matter and\nAbortion/Feminism, we searched hashtages on\nTwitter. The hashtags/search terms we used for the\nBlack Lives Matter event were: Black Lives Mat-\nter, BLM, blacklivesmatter, Floyd, George Floyd .The hashtags/search terms we used for the Abor-\ntion/Feminism event were: abortion, feminism,\nwomenempowerment, womensrights, metoo, pro-\nlife, prochoice .\nE Related Work Cont.\nWe now discuss additional related works we didn\u2019t\ncover in the main paper, due to space. Several ad-\nditional works aim to analyze fake news spreaders\non social media, some of them using graphs (Rath\net al., 2020, 2021; Sakketou et al., 2022b).\nE.1 Impact of Information Communities for\nNews Media Profiling\nPrior work has shown that misinformation tends\nto spread in groups on social media (Bessi et al.,\n2016; Halberstam and Knight, 2016; Cinelli et al.,\n2021). Specifically, they show that like-minded\nusers tend to form groups, that biased/false in-\nformation reaches the users in these groups more\nquickly, and that these groups are more likely to be\nbiased/spread misinformation.\nThis motivates our ideas to build better informa-\ntion communities for fake news and bias source\ndetection. We hypothesize that if we can identify\nthese like-minded users, i.e. our information com-\nmunities, then we can more easily identify their\nusers\u2019 bias and likeliness to spread misinforma-\ntion. This knowledge can then be used to profile\nnews media sources better, especially through our\ngraph model, where users, articles, and sources are\ndirectly connected and vary in similarity to each\nother. Thus, we aimed to build better information\ncommunities, and took advantage of minimal hu-\nman interactions to do this.\nE.2 Humans Interacting with LLMs\nHumans interacting with LLMs has gained pop-\nularity recently. One direction is Reinforcement\nLearning for Human Feedback (RLHF) (Bai et al.,\n2022; OpenAI, 2023), where humans preferences\nare used to train a Reinforcement Learning Agent\nreward model, which can then be used to improve\nthe LLM. An extension of this, which needs signif-\nicantly less human interactions, is having humans\nprovide a few training examples to a LLM prompt,\nwhich can be used by the LLM to generate rewards\n(Kwon et al., 2023). In another direction, human\ninteractions can be used to generate LLM prompt\ninstructions to better solve a variety of NLP Tasks\n(Zhang et al., 2023).\nWhat is this user discussing and what is their perspective? Please summarize in \none sentence. \nUsername: User 1 \nBIO: Email: \u2026; VERIFIED: 1; Follower count: 14568; Following  Count: 177; \nTweets Count: 23312; \nSome Tweets: \nTweet 0: I come from a police family. Absent excessive use of force , George \nFloyd would likely be alive today overdose or no overdose\u2026.Chauvi n had 18 \ncomplaints on his of\ufb01cial record. Should not have been on force.\nTweet 1: \u2026 \nTweet 2: \u2026 \nSummary: This user is discussing the death of George Floyd and the ir \nperspective is that Floyd's death was caused by excessive use of force  by the \npolice and that police unions protected Derek Chauvin, the of\ufb01cer who killed \nFloyd. \nWhat is this user discussing and what is their perspective? Please summarize in \none sentence. Figure 2: An example of the prompt we used to determine the user summary. Based on their bio, meta-data, and tweets, we\ncreate a summary.\nWhich users have the same perspective? \nUser 1 Summary: This user is discussing the death of a black man in Se attle who \nwas shot by police, as well as other topics related to race and  the Black Lives \nMatter movement. Their perspective appears to be critical of the Bl ack Lives \nMatter movement and they suggest that it is hypocritical for the movement to not \nbe speaking out about this man's death. \nUser 2 Summary: This user is discussing the Black Lives Matter movement and \ntheir perspective appears to be critical of the organization an d its goals.  \nUser 3 Summary: This user is discussing the Black Lives Matter movement and \ntheir perspective is that the movement is glorifying a convicted co p killer, making \nunrealistic demands, and causing problems for innocent people. \nBased on the information provided, User 1 and User 2 appear to  have a similar \nperspective that is critical of the Black Lives Matter movement. User 3  also \nappears to share a similar perspective. \nFigure 3: An example of the output shown by Chat-GPT when provided user summaries and asked to predict similarity. Note\nhow often times the output can be vague, which is why human interactions are necessary.\nIn contrast, in this work, we had humans inter-\nact with LLM and graph knowledge to build better\ninformation communities for news media profiling.\nTo do this, we first used LLMs to generate user\nand community summaries, which we presented\nto humans. Humans were then asked to use their\njudgement and reasoning skills, something that is\nsimple for them but hard for LLMs, to form initial\nvalidated communities. These validated communi-\nties consisted of users who had similar perspectives\non similar topics. Then, using graph knowledge,\nwe generated additional candidate communities,\nand asked LLMs if the users in these additional\ncommunities belonged to any of the the humanvalidated communities. As a prompt for this de-\ncision, we used the human validated community\nassignments.\nIn summary, we used LLMs to help humans (i.e.\ngenerate summaries) and amplify human interac-\ntions (i.e. determine if additional users are similar\nto users in any human validated communities).\nF Discussion Continued\nWe now continue our discussion from Sec. 6, ana-\nlyzing our Black Lives Matter human interaction\nmodels.\nWhich users have the same perspectives? \nUser 1: This user is discussing the Black Lives Matter protest and the ir \nperspectives is that these leaders are stealing money from the orga nization. \nUser 2: This user is discussing the death of a black man in Seatt le who was shot \nby police. Their perspective appears to be critical of the Black L ives Matter \nmovement, and suggest it is hypocritical for the movement to not be speaking out \nabout this man\u2019s death. \nUser 3: This is discussing the case of Shaun King, a civil rights a ctivist, and their \nperspective is that King is being unfairly attacked. They also e xpress support for \nthe Black Lives Matter movement. \nPositive Users;;;;Negative Users: \nUser 1, User 2;;;;User 3 \nWhich users have the same perspectives? \nUser 4: \u2026. \nUser 5: \u2026 \nUser 6: \u2026 \nPositive Users;;;;Negative Users: Figure 4: An example of the prompt we used to determine community membership for one of the human validated information\ncommunities. We use the first paragraph as a 1-shot example, to prompt the model. User 1 and 2 are both critical of the Black\nLives Matter movement protests, and thus part of the same community, while User 3 is in support of it, and thus shouldn\u2019t be in\nthe community. Based on this, we prompt GPT-3 with additional users (in this case User 4, 5, and 6), and ask it to determine\nwhich users belong in the community and which do not.\nDataset Low Factuality or\nLeft BiasMixed Factuality\nor Center BiasHigh Factuality or\nRight Bias\nBlack Lives Matter Bias 49 56 74\nBlack Lives Matter Factuality 35 45 76\nAbortion + Feminism Bias 38 50 91\nAbortion + Feminism Factuality 49 72 82\nTable 6: Number of sources in our datasets for each emerging news event we evaluate on.\nF.1 Community Cohesiveness Analysis\nIn this sub-section, we automatically analyze how\nmany users in each community have the same per-\nspectives. To do this, as an approximation, we hy-\npothesize that the communities of users with simi-\nlar perspectives likely have users with the same bias\nlabel. We use bias as an approximation as we have\ngold data for it, and users with the same political\nbias likely have similar perspectives (i.e. right bias\nusers likely want to lower taxes). Tab. 9 shows that\neven in the final expansion round (i.e. after multi-\nple steps of human interaction + model expansion -\nLLM + Humans Model) users in the communities\nlargely have the same bias label, both when chosen\nby humans and automatically expanded. Thus, this\napproximation shows that our communities are in\nsome ways cohesive.\nOn the contrary, in Tab. 9, the LLM Only model\ndoesn\u2019t have as many users having the same labels\nas the LLM + Humans model, showing that without\nhuman interactions it may be harder to learn userperspectives.\nF.2 Human Analysis of Community Topics\nWe now manually analyze the information com-\nmunities learned by our best performing model on\nthe Black Lives Matter event, by looking at the top\n5 user summaries, determined by user embedding\nsimilarity to the community centroid. We observe\nthat our communities capture meaningful perspec-\ntives. One community is against the Black Lives\nMatter protests, believing they are causing damage\nand the leaders are not condemning it. Another is\nin support of them, as they feel police do not treat\neveryone fairly. Other important sub-topics are also\ndiscussed, such as George Floyd murder, Ahmaud\nArbery murder, police brutality and unions. All\nthese are important BLM related topics.\nF.3 LLM Only Failure Cases\nIn this section, we provide a few more examples of\ncases where Chat-GPT couldn\u2019t find good informa-\ntion communities, and thus humans were needed,\nModel Test\nAccTest\nF1# Users; #\nSources# Edges # Inter-\nactions\nBaseline: (Mehta et al., 2022) 36.04 23.32 - - -\nGraph Only: High Purity 4 Communities 34.95 19.09 22; 11 176 -\nLLM + Humans: 2 Validated Comms, 2 Expansion Rounds 37.37 25.24 173; 16 280 1\nLLM + Humans: 4 Validated Comms, 2 Expansion Rounds 35.43 19.64 50; 32 628 2\nTable 7: Fake News Source Detection on Abortion/Feminism: We evaluate Test Set Accuracy, Macro F1, the number of users\nand sources directly connected/connected to, the number of edges created, and how many human interactions are performed.\nResults show both of our human interaction models (LLM + Humans) achieve improvements over other models (Baseline and\nGraph Only model). Specifically, creating two human validated communities and then expanding them over 2 expansion rounds\nachieves the highest fake news source detection performance. The final communities have 173 users, interact directly with 16\nsources, and create 280 edges. Moreover, this performance improvement is with only 1 single human interaction.\nModel Test\nAccTest\nF1# Users; #\nSources# Edges # Inter-\nactions\nBaseline: (Mehta et al., 2022) 46.92 33.21 - - -\nGraph Only: High Purity 4 Communities 47.86 34.02 22; 11 176 -\nLLM + Humans: 2 Validated Comms, 2 Expansion Rounds. 46.92 40.33 173; 16 280 1\nLLM + Humans: 4 Validated Comms, 2 Expansion Rounds 51.39 38.05 50; 32 628 2\nTable 8: Bias News Source Detection on Abortion/Feminism: We evaluate Test Set Accuracy, Macro F1, the number of users\nand sources directly connected/connected to, the number of edges created, and how many human interactions are performed.\nResults show both of our human interaction models (LLM + Humans) achieve improvements over other models (Baselines and\nGraph Only). Specifically, creating four human validated communities and then expanding them over 2 expansion rounds\nachieves the highest bias news source detection accuracy. The final communities have 50 users, interact directly with 32 sources,\nand create 628 edges. Moreover, this performance improvement is with only 2 human interactions.\nComm.\n#Dominant LLM +\nHumans LabelLLM Only: % Of Users with\nDominant LabelLLM + Humans: % Of Users with\nDominant Label\n1 Right \u223c50% \u223c60%\n2 Right \u223c37% \u223c58%\n3 Right \u223c43% 100%\n4 Center 40% 50%\n5 Left \u223c71% \u223c66%\nTable 9: At the final expansion round (i.e. after multiple steps of human interaction + model expansion) the majority of each\ncommunity\u2019s users for the LLM + Human Interaction Model (last column) have the same gold bias label as the dominant one in\nthe community, showing high cohesiveness (at least in gold bias label). On the contrary, the LLM Only model (third column) has\na lower percentage of users with the same gold bias label, showing that without human interactions it is harder to learn user\nperspectives, at least based on this approximation analysis.\nas in Sec. C. The examples are shown in Fig. 5 and\nFig. 6, and the captions of the figures describe the\nfailures.\nWhile in this paper we experimented with GPT-3\nand Chat-GPT as our LLMs of choice, we hypoth-\nesize that our results and framework would hold\ntrue for other strong LLMs as well. First, other\nLLMs are likely to also struggle at finding infor-\nmation communities on unseen data, as it is very\nchallenging for AI models to make inferences on\ndata and topics they have never seen before. Sec-\nond, it is likely that other LLMs that perform well\non determining text similarity can be used with our\nframework (Zhao et al., 2023). We primarily usedLLMs to expand communities, by asking them to\ndetermine if new users are similar to users chosen\nby humans to be part of validated communities. In\nsome ways, this is a text similarity problem, as user\nsummaries are compared. We leave the further in-\nvestigation of the choice of LLMs for use with our\nframework to future work.\nF.4 Finer Cases\nIn this sub-section, we discuss some finer cases that\ncould occur in our community analysis, and how\nthey would or would not affect our framework.\nCommunities spreading both fake news and\nbiased content: A group of users that spreads\nWhich users have the same perspectives? \nUser 1: This user believes the \ufb01nal autopsy on Floyd showed he had a bad heart, \nused drugs, had COVID-19, and did not have any life-threaten ing injuries.  \nUser 2: The user is discussing how the Black Lives Matter movement is b eing \nused to further a communist agenda. \nUser 3: This user is discussing the Black Lives Matter movement and the ir \nperspective seems to be critical of the organization and its lea ders. They also \nmention gun violence in Chicago and a brewery in the Hampto ns that has been \ntargeted with a boycott over its support for Black Lives Matter. \nPerspective: \nI'm sorry, but I cannot determine which users have the same perspect ive as the \ninformation provided is not suf\ufb01cient to make such a comparison. Th e three users \nseem to be discussing different topics and expressing different p erspectives on \nthose topics. Figure 5: LLM Failure Case: In this case, the LLM (Chat-GPT) can\u2019t find any communities, but it is clear that at least User 2\nand User 3 should be in the same community, as they are both against the Black Lives Matter movement.\nWhich users have the same perspectives? \nUser 1: This user is discussing the inauguration of Joe Biden an d Kamala Harris, \nwhich is taking place today. They are also sharing information  about how to watch \nthe event and some of the highlights that can be expected.\nUser 2: This user is discussing the election of Joe Biden and Kama la Harris as \nPresident and Vice President of the United States, respectively.  They seem to \nsupport Biden and Harris and believe that they are the best ch oice to lead the \ncountry. \nUser 3: This user is discussing the con\ufb01rmation of Judge Ketanji Brow n Jackson \nto the Supreme Court and Vice President Kamala Harris's role in it . They seem to \nsupport Harris and view her con\ufb01rmation vote as historic. \nPerspective: \nUser 1, User 2, and User 3 appear to be supportive of Kamala Ha rris\u2026 \nFigure 6: LLM Failure Case: In this case, the LLM (Chat-GPT) considers all 3 users as similar and in the same community.\nHowever, User 1 doesn\u2019t belong, as they are likely just reporting on the news of the inauguration. The LLM gets confused over\nthe word \u201chighlights\u201d, which could be positive or negative in this situation.\nboth fake news and biased content likely wouldn\u2019t\naffect our approach/results. Through the approach\nin Sec. 4, the group would be identified as a single\ninformation community. Then, the R-GCN graph\nmodel would learn that this community is both a\nfake news and political bias spreading information\ncommunity.\nSource Label Inconsistencies: In this paper, we\nobtained source labels for both factuality and polit-\nical bias from Media Bias/Fact Check6, a popular\nsource fact-checking and source political bias de-\ntection website. This website typically holistically\nevaluates sources, so it is likely a majority of the\ncontent we scraped for our experiments follows the\nfactuality/bias label provided by Media Bias/Fact-\nCheck. However, it is possible that some sources\nhave different levels of factuality/bias for different\n6https://mediabiasfactcheck.comevents that Media Bias/Fact Check doesn\u2019t capture\n(i.e. a source could be labeled as \u201cmixed\u201d factuality\nbut be completely factual on Black Lives Matter\nnews). While we leave the analysis of this to fu-\nture work, we hypothesize that these cases are rare\nand thus unlikely to significantly affect our results.\nMore importantly, it\u2019s possible that our framework\ncan actually make the correct prediction on these\nincorrectly labeled sources. This can happen as our\nformed information communities typically span\nmultiple sources and are very cohesive, so they are\nlikely to be accurate. Once we form our communi-\nties, we train the graph for link prediction, so we\naren\u2019t actually using the source labels but rather\nwe are capturing user perspectives through training.\nThus, if some sources are labeled incorrectly and\nthat leads to an initially biased graph model, our\ninteraction process can actually fix that by helping\nus learn a better model, improving performance on\nthose incorrectly labeled sources.\nHuman Interaction Inconsistencies: As men-\ntioned in the main paper, our interaction task is ex-\ntremely simple, as humans just have to determine\nuser similarity by reading a few short spans of user\ntext. This distinction is very clear-cut, as users\nthat are borderline similar should not be placed\nin the same community. Thus, different human\ninteractors are likely to make the same decisions,\nno matter their backgrounds/beliefs/etc., because\nidentifying this level of similarity is a fairly simple\ntask. Moreover, there are multiple ways to ensure\nthat the interactions are done accurately, such as\nhiring multiple experts and taking their majority\nvote. However, still, in this section we analyze the\nsituation in which humans incorrectly choose users\nas similar when they are not, or vice versa.\nThe strength of our framework is forming co-\nhesive information communities through the in-\nteractions, where users have similar perspectives.\nAssuming an interaction lead to a community that\nwasn\u2019t cohesive, it is likely that the trained graph\nmodel would learn to ignore it, as it wouldn\u2019t gain\nany significant insight from this \u201crandom\u201d com-\nmunity. Thus, this \u201cincorrect\u201d interaction is not\nlikely to significantly hurt our model. Further, on a\nlarge scale over many interactions and lots of com-\nmunities formed, a few \u201cincorrect\u201d interactions is\nunlikely to make huge negative difference to our\napproach, due to the fact that we always train for\nthem using link prediction, so the model can learn\nto ignore it if necessary. For example, even though\nthe link prediction training objective would pull\nthe non-similar users in this \u201cincorrect\u201d commu-\nnity closer together, the content these users are\nconnected to in a different \u201ccorrect\u201d community\nwould still be pulled closer together. If there are\nmore \u201ccorrect\u201d communities than incorrect, then\neven the users in the \u201cincorrect\u201d community would\nbe indirectly affected by other communities and\nend up with the correct representations (i.e. farther\napart if they are non-similar).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "An interactive framework for profiling news media sources", "author": ["N Mehta", "D Goldwasser"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2309.07384", "abstract": "The recent rise of social media has led to the spread of large amounts of fake and biased  news, content published with the intent to sway beliefs. While detecting and profiling the"}, "filled": false, "gsrank": 390, "pub_url": "https://arxiv.org/abs/2309.07384", "author_id": ["HxebdycAAAAJ", "u8358QgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:rcIvpYCEdesJ:scholar.google.com/&output=cite&scirp=389&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D380%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=rcIvpYCEdesJ&ei=SrWsaPmRKo6IieoP0sKRuAk&json=", "num_citations": 5, "citedby_url": "/scholar?cites=16966612859250262701&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:rcIvpYCEdesJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2309.07384"}}, {"title": "Understanding the Roles of Humans, algorithms, and cyborgs in political polarization", "year": "2019", "pdf_data": " -\nUnderstanding the Roles of Humans, algorithms,\nand cyborgs in political polarization\nLe, Huyen Thi Thanh\nhttps://iro.uiowa.edu/esploro/outputs/doctoral/Understanding-the-Roles-of-Humans-algorithms/9983779598302771/filesAndLinks?index=0\nLe, H. T. T. (2019). Understanding the Roles of Humans, algorithms, and cyborgs in political polarization\n[University of Iowa]. https://doi.org/10.17077/etd.005220\nDownloaded on 2025/08/25 14:50:45 -0500\nCopyright 2019 Huyen Thi Thanh Le\nFree to read and download\nhttps://iro.uiowa.edu\n -\n\nUNDERSTANDING THE ROLES OF HUMANS, ALGORITHMS, AND\nCYBORGS IN POLITICAL POLARIZATION\nby\nHuyen Thi Thanh Le\nA thesis submitted in partial ful\fllment of the\nrequirements for the Doctor of Philosophy\ndegree in Computer Science\nin the Graduate College of\nThe University of Iowa\nDecember 2019\nThesis committee: Zubair Sha\fq, Thesis Supervisor\nPadmini Srinivasan\nJames Cremer\nJuan Pablo Hourcade\nKang Zhao\nCopyright by\nHUYEN THI THANH LE\n2019\nAll Rights Reserved\nACKNOWLEDGEMENTS\nFirst of all, I would like to thank my advisor, professor Zubair Sha\fq, very\nmuch for supporting me these past \fve years. He gave me great guidance on vari-\nous research problems. I think I could not \fnish my PhD successfully without his\nguidance.\nI would like to thank professor Padmini Srinivasan who co-advised me in most\nof my research. I also would like to thank my collaborators in di\u000berent research prob-\nlems, including professor Bob Boynton, professor Brian Ekdale, professor Timothy\nHavens, professor Andrew High, Yelena Mejova, and Raven Maragh.\nI would like to thank my thesis committee members, professor Juan Pablo\nHourcade, professor Kang Zhao, and professor James Cremer for their valuable feed\nback and comments on my research.\nI am thankful to have an opportunity to work with great colleagues from\nthe Internet Research Lab, department of Computer Science. I would like to thank\nShehroze Farooqi, Adnan Ahmed, Hammad Mazhar, Umar Iqbal, and John Cook for\ntheir help and support.\nLast but not least, I would like to have special thanks to my family, especially\nmy husband Thanh Chu, for their love and support.\nii\nABSTRACT\nRecent studies revealed more increasingly political polarization in the distri-\nbution and consumption of political news. Political polarization demonstrates the\ndisagreement between people aligned with di\u000berent ideologies or political parties (e.g.\nleft vs. right, Democrats vs. Republicans). Increasingly political polarization can\nhave negative e\u000bects on our society; for example, extreme cases in\ruenced by the\nleft/right ideology can lead to massive bombing or shooting incidents. Thus, through\nfour di\u000berent research streams this thesis will help people to understand the roles of\nhumans, algorithms, and cyborgs in political polarization.\nIn terms of humans, prior research has shown that people are mainly consum-\ning news conforming to their pre-existing beliefs (a.k.a. selective exposure). People\nalso prefer to have homophilous social interactions. Both of these lead to political\npolarization. Thus, to help inform the political slant of news people consume, we\ndevelop a lightweight and scalable news slant measurement using Twitter. Moreover,\nutilizing this method to estimate each Twitter user as a Republican or Democrat, we\nanalyze political discourse on Twitter communications in the combination of three\naspects including political a\u000eliation, personality perception, and policy discussion\naround several presidential candidates from both parties during the 2016 U.S. presi-\ndential election.\nIn terms of algorithms, researchers have recently started to question whether\nalgorithms create distinct personalized experiences for users. While selective exposure\niii\nrequires deliberate acts of media choice, algorithmic personalization interprets past\nbehavior as precedent for future preference. In other words, algorithmic personaliza-\ntion can intensify selective exposure beyond a person's choice, resulting in a vicious\ncycle that can contribute to an increasingly polarized society. Thus, it is important to\nstudy the roles of personalization algorithms employed by search engines and social\nmedia in reinforcing pre-existing biases. To this end, we examine the personalization\nof Google News Search based on the users' browsing history, especially when it comes\nfrom the users with di\u000berent political biases. We discover that in fact Google News\nSearch personalized its returned search results, and surprisingly, did reinforce the\npresumed political biases of the users.\nIn terms of cyborgs, there have been numerous reports of widespread misin-\nformation campaigns during the 2016 U.S. presidential election. Of particular notes,\nthere are reports which identi\fed the e\u000borts to manipulate social media (e.g. Twitter,\nFacebook) by the Russian state-sponsored accounts. These external manipulations by\ncyborgs cause signi\fcant pressure on social media services to mitigate spam, abuse,\nand political polarization on their platforms. Speci\fcally, Twitter publicly acknowl-\nedged the exploitation of their platform and has since conducted aggressive cleanups\nto suspend the involved accounts. To shed light on Twitter's countermeasures, we\nconduct a postmortem analysis of about one million Twitter accounts who engaged\nin the 2016 U.S. presidential election but were later suspended by Twitter.\niv\nPUBLIC ABSTRACT\nRecent studies revealed more increasingly political polarization in the distri-\nbution and consumption of political news. Political polarization demonstrates the\ndisagreement between people aligned with di\u000berent ideologies or political parties (e.g.\nleft vs. right, Democrats vs. Republicans). Increasingly political polarization can\nhave negative e\u000bects on our society; for example, extreme cases in\ruenced by the\nleft/right ideology can lead to massive bombing or shooting incidents. Thus, through\nfour di\u000berent research streams this thesis will help people to understand the roles of\nhumans, algorithms, and cyborgs in political polarization.\nIn terms of humans, prior research has shown that people are mainly con-\nsuming news conforming to their pre-existing beliefs. People also prefer to have\nhomophilous social interactions. Both of these lead to political polarization. Thus,\nto help inform the political slant of news people consume, we develop a lightweight\nand scalable news slant measurement using Twitter. Moreover, utilizing this method\nto estimate each Twitter user as a Republican or Democrat, we analyze political\ndiscourse on Twitter communications in the combination of three aspects including\npolitical a\u000eliation, personality perception, and policy discussion around several main\ncandidates from both parties during the 2016 U.S. presidential election.\nIn terms of algorithms, researchers have recently started to question whether\nalgorithms create distinct personalized experiences for users, which can unintention-\nally contribute to a more polarized society. Thus, it is important to study the roles of\nv\npersonalization algorithms employed by search engines and social media in reinforc-\ning pre-existing biases. To this end, we examine the personalization of Google News\nSearch based on the users' browsing history, especially when it comes from the users\nwith di\u000berent political biases.\nIn terms of cyborgs, there have been numerous reports of widespread misin-\nformation campaigns during the 2016 U.S. presidential election. Of particular notes,\nthere are reports which identi\fed the e\u000borts to manipulate social media (e.g. Twitter,\nFacebook) by the Russian state-sponsored accounts. These external manipulations by\ncyborgs cause signi\fcant pressure on social media services to mitigate spam, abuse,\nand political polarization on their platforms. Speci\fcally, Twitter publicly acknowl-\nedged the exploitation of their platform and has since conducted aggressive cleanups\nto suspend the involved accounts. To shed light on Twitter's countermeasures, we\nconduct a postmortem analysis of about one million Twitter accounts who engaged\nin the 2016 U.S. presidential election but were later suspended by Twitter.\nvi\nTABLE OF CONTENTS\nLIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nLIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\nCHAPTER\n1 INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n2 UNDERSTANDING THE ROLES OF HUMANS IN POLITICAL PO-\nLARIZATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1 Scalable News Slant Measurement Using Twitter . . . . . . . . . 7\n2.1.1 Background, Motivation, and Research Statement . . . . 7\n2.1.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.1.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.1.3.1 Landmark Selection . . . . . . . . . . . . . . . . 10\n2.1.3.2 Slant Estimation . . . . . . . . . . . . . . . . . . 12\n2.1.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.1.4.1 Evaluation . . . . . . . . . . . . . . . . . . . . . 14\n2.1.4.2 Impact of Landmark Selection . . . . . . . . . . 15\n2.1.4.3 Slant of Neutral Articles . . . . . . . . . . . . . 16\n2.1.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.2 Revisiting The American Voter on Twitter . . . . . . . . . . . . 18\n2.2.1 Background, Motivation, and Research Statement . . . . 18\n2.2.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.2.2.1 The American Voter . . . . . . . . . . . . . . . . 20\n2.2.2.2 Party . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.2.3 Personality . . . . . . . . . . . . . . . . . . . . . 23\n2.2.2.4 Policy . . . . . . . . . . . . . . . . . . . . . . . 24\n2.2.2.5 Election Prediction . . . . . . . . . . . . . . . . 25\n2.2.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.2.3.1 Party . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.2.3.2 Personality . . . . . . . . . . . . . . . . . . . . . 28\n2.2.3.3 Policy . . . . . . . . . . . . . . . . . . . . . . . 29\n2.2.3.4 Sentiment . . . . . . . . . . . . . . . . . . . . . 30\n2.2.4 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n2.2.4.1 Data Collection . . . . . . . . . . . . . . . . . . 31\n2.2.4.2 Data Statistics . . . . . . . . . . . . . . . . . . . 32\n2.2.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n2.2.5.1 Party . . . . . . . . . . . . . . . . . . . . . . . . 36\nvii\n2.2.5.2 Personality . . . . . . . . . . . . . . . . . . . . . 38\n2.2.5.3 Policy . . . . . . . . . . . . . . . . . . . . . . . 42\n2.2.6 Impact of Party, Personality, and Policy on Voting Outcomes 45\n2.2.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n2.2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n3 UNDERSTANDING THE ROLES OF ALGORITHMS IN POLITI-\nCAL POLARIZATION . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n3.1 Background, Motivation, and Research Statement . . . . . . . . 54\n3.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n3.3.1 Identifying Pro- and Anti-immigration Hyperlinks . . . . 59\n3.3.2 Training Browser Pro\fles . . . . . . . . . . . . . . . . . . 60\n3.3.3 Searching Google News . . . . . . . . . . . . . . . . . . . 61\n3.3.4 Quantifying Search Personalization . . . . . . . . . . . . . 65\n3.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n3.5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n3.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n4 UNDERSTANDING THE ROLES OF CYBORGS IN POLITICAL\nPOLARIZATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n4.1 Background, Motivation, and Research Statement . . . . . . . . 76\n4.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n4.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n4.3.1 Data Collection . . . . . . . . . . . . . . . . . . . . . . . 81\n4.3.2 Suspended Communities . . . . . . . . . . . . . . . . . . 82\n4.3.3 Community-Level Features . . . . . . . . . . . . . . . . . 85\n4.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n4.4.1 Suspended and Regular Communities . . . . . . . . . . . 87\n4.4.2 Qualitative Analysis . . . . . . . . . . . . . . . . . . . . . 91\n4.4.2.1 Dominant Poster . . . . . . . . . . . . . . . . . 91\n4.4.2.2 Dominant Retweet Content Producer . . . . . . 92\n4.4.2.3 Burstiness . . . . . . . . . . . . . . . . . . . . . 93\n4.4.2.4 Dominant Domain . . . . . . . . . . . . . . . . . 94\n4.4.2.5 Dominant Hashtag . . . . . . . . . . . . . . . . 95\n4.4.2.6 Combination . . . . . . . . . . . . . . . . . . . . 96\n4.4.3 Twitter's Suspension Algorithm . . . . . . . . . . . . . . 97\n4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n5 CONCLUSION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nREFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\nviii\nLIST OF TABLES\nTable\n2.1 Confusion matrix of the match between crowdsourced news slant measured\nby [47] and our measured slant scores when the threshold is symmetric\n(b=\u0000a= 0:37). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.2 Confusion matrix of the match between crowdsourced news slant measured\nby [47] and our measured slant scores when the threshold is asymmetric\n(a=\u00000:48;b= 0:28). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.3 Statistics of candidate tweet collections from November, 15 2015 to Febru-\nary 29, 2016. Close to half the users and tweets in the dataset were post-\ning on Trump. Trump's numbers re\rect a 3X lead in tweets and users\ncompared to Clinton and Sanders. Negative sentiment tweets signi\fcantly\noutnumber positive and neutral ones. The sentiment charged nature of the\ndialog is also indicated by the low prevalence of sentiment neutral tweets\n(about 8%). Same party tweets outnumber competing party tweets for\nseven out of ten candidates. Democrats tweeted more about Trump than\nabout Clinton or Sanders. Republicans were more interested in Clinton\nthan in Sanders. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n2.4 Statistics of tweets conveying personality perceptions and their breakdown\nacross party a\u000eliation and sentiment. . . . . . . . . . . . . . . . . . . . 38\n2.5 Statistics of tweets discussing di\u000berent policies, and their breakdown across\nparty a\u000eliation and sentiment. . . . . . . . . . . . . . . . . . . . . . . . 42\n2.6 List of statistically signi\fcant variables ( p-value<0.001) in our regression\nmodel for Democratic candidates. The features are sorted in descending\norder with respect to estimated coe\u000ecient values. Adjusted R2= 0.908 . 47\n2.7 List of statistically signi\fcant variables ( p-value<0.001) in our regression\nmodel for Republican candidates. The features are sorted in descending\norder with respect to estimated coe\u000ecient values. Adjusted R2= 0.883 . 48\n3.1 Statistics of pro-immigration and anti-immigration Twitter accounts. . . 60\nix\n3.2 Personalization (quanti\fed using di\u000berence and edit distance) for 50 search\nterms. Note that E(P;A),E(P;C), andE(A;C) are pairwise edit distance\namong pro-immigration, anti-immigration, and control pro\fles. . . . . . . 68\n3.3 Average personalization for all 50 search terms according to top-k (k 2\nf10,20,...,100g) ranked search results. We normalize edit distance (as k-\nedit distance) to make a fair comparison across di\u000berent k values. . . . . 70\n3.4 Political bias for nine top-personalized search terms. Note that B(P),\nB(A), andB(P)\u0000B(A) respectively are political bias of personalized\nsearch results for the pro-immigration and anti-immigration pro\fles, and\nthe di\u000berence between their political bias. Table is sorted in ascending\norder ofB(P)\u0000B(A) values. A negative B(P)\u0000B(A) value indicates\nthe pro-immigration pro\fle received more Democratic-leaning personal-\nized search results, while a positive B(P)\u0000B(A) value indicates the pro-\nimmigration pro\fle received more Republican-leaning personalized search\nresults. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.1 Statistics of suspended users as of February 2018 in our tweet collection\naround Clinton and Trump during nearly four months, from June 01 to\nAugust 01 & from September 09 to November 08, 2016 (except September\n18-20, October 31, and November 1). . . . . . . . . . . . . . . . . . . . . 83\n4.2 Statistics of retweet and mention network from suspended and regular users. 84\n4.3 Statistics of six representative communities for qualitative analysis. . . . 91\nx\nLIST OF FIGURES\nFigure\n1.1 Factors leading to political polarization. . . . . . . . . . . . . . . . . . . 2\n2.1 Visualization of follower graph similarity among Democratic and Republi-\ncan landmark users. The value of a cell is the percentage overlap between\nfollowers of two landmarks. Brighter colors represent more similarity and\ndarker colors represent less similarity. . . . . . . . . . . . . . . . . . . . . 11\n2.2 Proposed method to measure political slant of news articles. . . . . . . . 12\n2.3 Impact of landmark selection on slant measurement accuracy and coverage. 15\n2.4 Time series of tweets for candidates. The vertical black lines indicate\nthe following major election events during the data collection period. (1)\nDebR1: CNN Republican debate, (2) DebR2: Fox Business Republican\ndebate, (3) DebD2: NBC News Democratic debate, (4) DebR3: Fox News\nRepublican debate, (5) IAD: Democratic Iowa caucus, (6) IAR: Repub-\nlican Iowa caucus, (7) DebD3: MSNBC Democratic debate, (8) DebR4:\nABC News Republican debate, (9) NHD: Democratic New Hampshire pri-\nmary, (10) NHR: Republican New Hampshire primary, (11) DebD4: PBS\nDemocratic debate, (12) DebR5: CBS Republican debate, (13) NVD:\nDemocratic Nevada caucus, (14) SCR: Republican South Carolina pri-\nmary, (15) NVR: Republican Nevada caucus, (16) DebR6: CNN Republi-\ncan debate, (17) SCD: Democratic South Carolina primary. . . . . . . . . 33\n2.5 Scores for four most discussed personality dimensions. Scores are in the\nrange [-1,+1]. -1 (+1) indicates the personality is viewed as absent (present)\nwith high con\fdence. The number of tweets for absence (presence) of each\npersonality dimension are provided on the left (right) of the bar plot. The\nnet score is included in the parenthesis. The bar plots are shown for can-\ndidates receiving a minimum of 100 tweets on a dimension. . . . . . . . . 39\n2.6 Number of tweets for the six most discussed policies with party a\u000eliation\nbreakdown. The blue and red regions indicate tweets from Democrats and\nRepublicans, respectively. The white region represents tweets from the\nremaining users. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\nxi\n2.7 Proportion of tweet volume about personality dimensions of Clinton (above)\nand Trump (below) from users identi\fed as Democrats (blue circles), Re-\npublican (red squares), and Other (grey triangles). . . . . . . . . . . . . 50\n3.1 Our sock puppet auditing system to measure political personalization of\nGoogle News search. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n3.2 Top-10 \frst-party domains for hyperlinks crawled from pro- and anti-\nimmigration Twitter accounts. . . . . . . . . . . . . . . . . . . . . . . . . 62\n3.3 Top-30 third-party domains identi\fed on the hyperlinks crawled from pro-\nand anti-immigration Twitter accounts. . . . . . . . . . . . . . . . . . . . 63\n4.1 CDFs of suspended and regular communities in \fve dimensions. The ver-\ntical line places at the threshold as 50% and 200 times. From this vertical\nline to the right in each plot are communities having high value for that\nrespective dimension. Speci\fcally, the percentage of communities having\nhigh values = 1 - Yvalue of the intersection between the CDF and the\nvertical line. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n4.2 The illustrative suspended communities in terms of burstiness: Vote!Black\nLivesMatter Community. . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n4.3 Two decals from Ebay URLs posted by EbayAds community. . . . . . . 94\n4.4 Two pictures opposing Clinton from tumblr.com posted by NoEthicsNoOf-\n\fce community. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\nxii\n1\nCHAPTER 1\nINTRODUCTION\nIn society, polarization can happen in multiple aspects such as economics (mid-\ndle class vs. upper class), race (black vs. white), and politics (Democrat vs. Repub-\nlican). Especially, in U.S. where two political parties (Democrat vs. Republican)\ncompete over many issues, political polarization is an interesting and important mat-\nter to study. Political polarization is when an individual's political stance is de\fned\nby his/her ideology or political party (e.g. left vs. right, Democrats vs. Republi-\ncans). For example, given a policy issue such as immigration, people who identify as\nDemocrats will be pro-immigration, which aligns with the Democratic party's stance\nwhile people who identify as Republicans will be anti-immigration, which aligns with\nthe Republican party's stance. Thus, political polarization highlights the disagree-\nment between people who align with di\u000berent ideologies or political parties.\nResearchers from Pew Research Center reported that American society is in-\ncreasingly becoming more politically polarized [53]. Researchers did two independent\nsurveys on nationally representative Democrats and Republicans, speci\fcally asked\nfor their ratings on 10 political items such as \\how do you feel about governments\ne\u000eciency?\". As a result, the score distribution showed the increasing disagreement\nbetween Democrats and Republicans over two decades. This increasing disagreement\nis even beyond dislike when one party views the other party as \\a threat to the nation's\nwell being.\" As a consequence, increasing political polarization can have negative ef-\nfects on our society when extreme cases in\ruenced by the left/right ideology can lead\n2\nto bombing or shooting incidents. For example, there was a bombing incident in\nFlorida in 2018 [196]. The suspect was arrested for sending explosive packages to at\nleast a dozen Democrats who are well-known critics of president Trump. The investi-\ngation revealed many pictures in the suspect's van showing that he was in\ruenced by\nright wing ideology and pro-Trump. These extreme and negative dangers are reasons\nwhy it is very important to study the factors that lead to political polarization.\nFrom our research, we recognize that three factors including humans, algo-\nrithms, and cyborgs1play signi\fcant roles in political polarization (Figure 1.1). While\nhumans' innate instincts directly lead to political polarization, algorithms can acci-\ndentally intensify the political polarization and cyborgs can intentionally worsen the\npolitical polarization. In terms of humans' roles, political polarization is partly ex-\nplained by the selective exposure theory [170], which suggests that users tend to be\n1which are human-assisted bots or bot-assisted humans and can be understood as bad\nactors that try to manipulate the interactions between humans and algorithms.\nFigure 1.1: Factors leading to political polarization.\n3\nattracted to, consume, and share news that conforms with their ideological beliefs.\nIt is also, in part, explained by user preference for homophilous social interactions\n[117]. Both of these are due to humans' innate instincts. In terms of algorithms'\nroles, researchers have recently started to question whether algorithms create dis-\ntinct personalized experiences for users, leading to so-called \\\flter bubbles\" or \\echo\nchambers\" [108, 151, 33]. While selective exposure requires deliberate acts of media\nchoice, algorithmic personalization interprets past behavior as precedent for future\npreference. In other words, algorithmic personalization can intensify selective expo-\nsure beyond a person's choice, resulting in a vicious cycle that can contribute to an\nincreasingly politically polarized society. In terms of cyborgs' roles, there have been\nnumerous reports of widespread misinformation campaigns and political propaganda\ncaused by cyborgs during elections. Of particular note, there are reports that have\nidenti\fed the e\u000borts of paid social media trolls by Russia's Internet Research Agency\n(RU-IRA) to manipulate social media platforms (e.g. Twitter, Facebook) in the 2016\nU.S. presidential election [105, 16]. These external manipulations by cyborgs cause\nsigni\fcant pressure on social media services to mitigate spam, abuse, and political\npolarization on their platforms.\nThis thesis explores di\u000berent research streams (including measuring the polit-\nical slant of individual news articles, revisiting the American voters in presidential\ncampaigns, measuring political personalization on Google News Search, and analyz-\ning suspended Twitter account activities) to help people better understand the roles\nof humans, algorithms, and cyborgs in political polarization.\n4\n\u000fUnderstanding the Roles of Humans in Political Polarization: To help discover\nhow imbalanced the political news that people might consume and share may\nbe, we develop a method to measure ideological slant of individual news arti-\ncles by monitoring their consumption on online social media. Speci\fcally, we\nmeasure an article's slant by analyzing the users tweeting about the article and\nevaluating their connectivity to a set of Republican and Democratic landmark\nusers. Our method takes advantage of the massive amount of news consumption\ndata available on online social media to measure news slant on a large scale.\nThis approach - while seemingly simple - is powerful enough to e\u000bectively gauge\narticle slant while overcoming the scalability limitations of prior research. This\nwork was published in The 2017 International AAAI Conference on Web and\nSocial Media (ICWSM). Furthermore, utilizing this method to estimate each\nTwitter user as a Republican or Democrat, we analyze political discourse in\nthe 2016 U.S. presidential campaigns on Twitter in the combination of three as-\npects including political a\u000eliation, personality perception, and policy discussion\naround several main candidates from both parties. Thus, while our work derives\nin a principled way from The American Voter - an established and long line of\nelection research in political science, our contribution is to move it forward from\nsurvey research to the realm of online social media by applying computational\nmethods for tracking political discourse about party, personality, and policy on\nTwitter. This work was published in The 2017 ACM Conference on Hyper-\ntext and Social Media (HyperText) and The 2017 ACM SIGCHI Conference on\n5\nHuman Factors in Computing Systems (CHI).\n\u000fUnderstanding the Roles of Algorithms in Political Polarization: It is impor-\ntant to study how personalization algorithms employed by search engines and\nsocial media reinforce pre-existing biases. To this end, we examine the person-\nalization of Google News Search based on the users' browsing history, especially\nwhen it comes from users with di\u000berent political biases. Speci\fcally, while con-\ntrolling for other factors, we train a pair of fresh browser pro\fles by visiting\nwebsites that re\rect pro-immigration and anti-immigration stances. We then\nexecute search queries on Google News related to a variety of political topics.\nWe analyze the search results to quantify the magnitude and direction of per-\nsonalization. We discover that in fact, Google News Search personalized its\nreturned search results, and surprisingly, did reinforce the presumed political\nbias of the users. These \fndings not only set the baseline for search personal-\nization based on political biases in browsing history, but also contribute to the\nbroader understanding of selective exposure and algorithmic personalization.\nThis work was published in The 2019 Web Conference (WWW).\n\u000fUnderstanding the Roles of Cyborgs in Political Polarization: Aligning with\nTwitter's e\u000borts to remove spam, fake, and political propaganda accounts in\norder to make their platform become a healthier environment for upcoming\nelections, we do a postmortem of our 2016 election-related tweet collection to\nshed light on activities of suspended Twitter accounts. To systematically ana-\nlyze the coordinated activities of these suspended accounts, we \frst group them\n6\ninto communities based on their retweet/mention network and then analyze\ndi\u000berent characteristics such as popular tweeters, domains, and hashtags. The\nresults show that suspended and regular communities exhibit signi\fcant di\u000ber-\nences in terms of popular tweeters and hashtags. Our qualitative analysis also\nshows that suspended communities are heterogeneous in terms of their charac-\nteristics (e.g. pro-Trump vs. pro-Clinton, bursty posting vs. constant posting).\nFurther more, we \fnd that accounts suspended by Twitter's new countermea-\nsures are closely connected to the original suspended communities. This work\nwas published in The 2019 IEEE/ACM International Conference on Advances\nin Social Networks Analysis and Mining (ASONAM).\nThe rest of this thesis is organized as follows: Chapter 2 presents details of\nour work in \\Scalable News Slant Measurement Using Twitter\" and \\Revisiting The\nAmerican Voter on Twitter\" to help understand the roles of humans in political po-\nlarization. Chapter 3 describes our work in \\Measuring Political Personalization on\nGoogle News Search\" to help understand the roles of algorithms in political polariza-\ntion. Chapter 4 shows our work in \\A Postmortem of Suspended Twitter Accounts in\nthe 2016 U.S. Presidential Election\" to help understand the roles of cyborgs in politi-\ncal polarization. Finally, Chapter 5 concludes the thesis and outlines some directions\nfor future work.\n7\nCHAPTER 2\nUNDERSTANDING THE ROLES OF HUMANS IN POLITICAL\nPOLARIZATION\n2.1 Scalable News Slant Measurement Using Twitter\n2.1.1 Background, Motivation, and Research Statement\nPeople increasingly rely on online social media to consume, share, and dis-\ncuss news. According the Pew Research Center's Journalism Project, more than\n50% of Facebook and Twitter users consume news on social media sites [143]. Ide-\nological polarization of news outlets is extensively reported in prior literature [106].\nRecent studies on Facebook [32] and Twitter [60] have revealed polarization in the\nconsumption and distribution of political news on social media sites. Political news\npolarization in online social media is partly explained by the selective exposure theory\n[170] which suggests that users tend to be attracted to, consume, and share news that\nconform with their ideological beliefs. It is also, in part, explained by user preference\nfor homophilous social interactions [117].\nSet in this context, we present a method to measure ideological slant of individ-\nual news articles by monitoring their consumption on online social media. Speci\fcally,\nour proposed method measures an article's slant by analyzing the users tweeting about\nthe article and analyzing their connectivity to a set of Republican and Democratic\nlandmark users. Landmark users are well-recognized individuals whose slants (or po-\nlitical a\u000eliations) are known with high con\fdence. A news article is assessed to have\nRepublican slant if it is shared more by users who follow Republican landmarks than\n8\nusers who follow Democratic landmarks. Similarly, a news article is assessed to have\nDemocratic slant if it is shared more by users who follow Democratic landmarks than\nusers who follow Republican landmarks. Our method exploits the massive amount of\nnews consumption data available on online social media to measure news slant at a\nlarge scale. This approach - while seemingly simple - is powerful enough to e\u000bectively\ngauge article slant while overcoming scalability limitations of prior research.\nPrior work used crowdsourcing to label political slant of news articles [47].\nHowever, large-scale news slant estimation using crowdsourcing requires the avail-\nability and monetary compensation for a large number of politically informed crowd\nworkers. We compare our news article slant estimates with prior work [47] that relies\non crowdsourcing. The comparison shows that our method can accurately estimate\narticle-level slant for 80% Democratic-leaning news articles and 76% Republican-\nleaning news articles.\n2.1.2 Related Work\nPrior methods for estimating slant can be broadly divided into two categories:\ncontent-based methods and audience-based methods.\nContent-based methods, as the name implies, address the problem more di-\nrectly by analyzing the content of news articles. For example, Groseclose et al. [87]\nmeasured media slant by monitoring the relative citation frequency of various policy\ngroups by news outlets and the members of Congress. As another example, Gentzkow\net al. [80] parsed congressional speeches to identify partisan phrases that are more\n9\ncommonly used by Republican or Democratic members of Congress. They then an-\nalyzed text content in newspaper articles and quanti\fed each newspaper's political\nslant by measuring the relative use of partisan phrases. More recently, researchers\nhave used crowdsourcing to estimate slant of individual news articles. Budak et al.\n[47] used crowd workers on Amazon Mechanical Turk (AMT) to identify slant of\nindividual news articles. Unfortunately, content-based methods that utilize crowd-\nsourcing for slant measurement do not scale well because they require non-trivial\nmonetary compensation to crowd workers for large-scale labeling. In contrast, our\nproposed method does not require explicit user participation to measure slant of news\narticles.\nAudience-based methods, in contrast, rely on the idea that news readers have\ntheir own ideological biases which are re\rected in their news consumption and sharing\nbehavior [170]. These methods analyze data about news consumption and sharing\nto indirectly measure slant of news articles. The widespread usage of online social\nmedia allows audience-based approaches to operate at a large scale. Our proposed\nslant measurement method falls in this latter category. Prior audience-based methods\n[80, 25, 200, 145, 83, 122] aim to measure slant of individual users or news outlets in\naggregate. Unlike prior audience-based methods which are dependent on manually\nlabeled ground truth [209] or self-reported user political alignments [32], our method\nrequires only a small set of pre-labeled landmarks. Our proposed method leverages\na small number of landmarks to accurately estimate slant of individual news articles\nat scale.\n10\n2.1.3 Methodology\nWe want to measure the political slant of news articles (towards Republicans\nor Democrats) by observing the patterns of sharing amongst users in online social\nmedia and the connectivity of these users to a set of landmark individuals. At a high\nlevel, our idea is that if a news article is tweeted/retweeted by more Democrats than\nRepublicans, it is likely to have a Democratic slant. It is the opposite for articles likely\nto have a Republican slant. This strategy is similar to Bakshy et al. [32], who used\nthe ratio of number of Democrats to Republicans for estimating slant on Facebook.\nThe key di\u000berence is that they relied on self-reported political a\u000eliations. However,\nonly 9% of adult Facebook users in the U.S. self-report their political a\u000eliation. Since\nsuch data is very limited, as explained next, we propose to estimate user a\u000eliation\nor slant with a di\u000berent strategy involving landmark users.\n2.1.3.1 Landmark Selection\nA landmark user is one whose slant, here political party a\u000eliation, is well\nrecognized. We manually identify a set of 30 popular Democrats (e.g., Rachel Mad-\ndow) and 30 popular Republicans (e.g., Sean Hannity) on Twitter as our \\landmark\"\nusers. We curated these landmarks in consultation with political scientists. We chose\nseveral journalists as landmarks because they have large followings on Twitter. On\naverage, each Democratic landmark user has 223,656 followers and each Republican\nlandmark user has 277,671 followers. The large following on Twitter provides us suf-\n\fcient coverage to quantify slant of news articles. Our coverage analysis showed that\n11\nDemocratic Landmark IndexDemocratic Landmark Index\n  \n246810121416182022242628302\n4\n6\n8\n10\n12\n14\n16\n18\n20\n22\n24\n26\n28\n30\n020406080100\n(a) Democrat-Democrat\nRepublican Landmark IndexRepublican Landmark Index\n  \n246810121416182022242628302\n4\n6\n8\n10\n12\n14\n16\n18\n20\n22\n24\n26\n28\n30\n020406080100 (b) Republican-Republican\nRepublican Landmark IndexDemocratic Landmark Index\n  \n246810121416182022242628302\n4\n6\n8\n10\n12\n14\n16\n18\n20\n22\n24\n26\n28\n30\n020406080100 (c) Democrat-Republican\nFigure 2.1: Visualization of follower graph similarity among Democratic and Republi-\ncan landmark users. The value of a cell is the percentage overlap between followers of\ntwo landmarks. Brighter colors represent more similarity and darker colors represent\nless similarity.\napproximately 95% of news articles in our data set have more than 10 connections to\none of the 60 landmarks (median is 115). Thus, our analysis shows that 60 landmarks\n(each with a large Twitter following) provide us reasonable coverage.\nNext, to validate our selection of landmarks, we examine the overlap in follow-\ners for pairs of landmarks. We compute the follower graph similarity (i.e., percentage\noverlap between their followers) for all pairs of landmarks. Figure 2.1(a) shows the\npercentage follower overlap between Democratic landmarks, Figure 2.1(b) shows the\npercentage follower overlap between Republican landmarks, and Figure 2.1(c) shows\nthe percentage follower overlap across Democratic and Republican landmarks. The\ncolorbar denotes the percentage follower overlap between two landmarks. Overall,\nwe note that Figures 2.1(a) and (b) are much brighter (more overlap) than Fig-\n12\nure 2.1(c). More speci\fcally, the average percentage of follower overlap amongst\nDemocrats is 32.4% and amongst Republicans is 43.6%. In contrast, the average\npercentage of follower overlap across Democrats and Republicans is only 8.8%. This\npattern demonstrates political polarization on Twitter and is consistent with [60], i.e.,\nDemocrats tend to make connections with other Democrats and Republicans tend to\nmake connections with other Republicans, while tending to not do so across party\nlines. Most importantly for us these results demonstrate that selective exposure the-\nory and homophily in social interactions are exhibited in the follower connections of\nour landmarks. This result also rea\u000erms our con\fdence in the selection of Democratic\nand Republican landmarks.\n2.1.3.2 Slant Estimation\nFigure 2.2 illustrates our proposed news slant estimation method. The top tier\ncontains the Democratic and Republican landmarks. The middle tier contains Twitter\n12Republicans Democrats\nFigure 2.2: Proposed method to measure political slant of news articles.\n13\nusers. The bottom tier represents news articles. Each article-user link indicates that\na user tweeted/retweeted a news article. Based on the selective exposure theory\n[170], we expect users to consume and share news that conform with their ideological\nbeliefs. Each user-landmark link indicates that a user follows a landmark. Again due\nto the natural preference for homophilous social interactions [117], we expect a large\nnumber of links from users to landmarks of the same political a\u000eliation and only a\nfew links to the opposite political a\u000eliation. Thus, we can compute a news article's\npolitical slant by monitoring its sharing activity on Twitter and user connectivity to\nthe landmarks.\nTo implement our proposed method, we \frst collect tweets which mention a\nnews article using Twitter's streaming API. From this sample of tweets, we get a list\nof all users who have tweeted about the news article. We then count the number\nof landmark Democrats and Republicans which each user follows. We use Twitter's\nREST API to collect the follower lists of landmark Democrats and Republicans. Using\nthe counts of landmark Democrats and Republicans that all users follow, we quantify\nthe political slant of a news article as: Slant =#Republicans \u0000#Democrats\n#Republicans +#Democrats:We quantify\nthe slant of a news article in the range of -1 to 1, where -1 indicates Democratic slant\nand +1 indicates Republican slant.\n14\n2.1.4 Results\n2.1.4.1 Evaluation\nBelow we compare our article-level slant estimation results with Budak et\nal. [47]. They used crowdsourcing to label political slant of 10,500 news articles\nas Republican-leaning, Center, or Democratic-leaning.1They recruited two crowd\nworkers to evaluate the political slant of each news article on a \fve-point scale (\\Pos-\nitive\", \\Somewhat Positive\", \\Neutral\", \\Somewhat Negative\", \\Negative\") for both\nDemocrats and Republicans. To mitigate noise and increase reliability of slant labels\nby crowd workers, we only consider the articles for which the evaluations by two crowd\nworkers match each other. After this \fltering, the data set contains 605 Democratic-\nleaning, 653 Republican-leaning, and 3,837 Neutral news articles. For comparison, we\ncompute the slant score for these Democratic- and Republican-leaning news articles\nusing our proposed method. The results show that our estimated slant scores are well\ncorrelated with the article set's political a\u000eliation. The average estimated slant score\nfor the Democratic-leaning article set is strongly Democratic-leaning (-0.40), while the\naverage estimated slant score for the Republican-leaning set is strongly Republican-\nleaning (0.44). Furthermore, 80% of Democratic-leaning articles have slant scores\nsmaller than 0 and 76% of Republican-leaning articles have slant scores larger than\n0.\n1We thank [47] for sharing their crowd labeled data set.\n15\n(a) Accuracy\n (b) Coverage\nFigure 2.3: Impact of landmark selection on slant measurement accuracy and cover-\nage.\n2.1.4.2 Impact of Landmark Selection\nWe next examine the impact of the selected landmarks on the accuracy (with\nrespect to crowdsourcing) and coverage (number of news articles) of slant measure-\nment.\nWe compute the accuracy for the sets of Democratic- and Republican-leaning\narticles respectively when the number of chosen landmarks is gradually increasing\nfrom 1 to 30. For this experiment, we select landmarks randomly from the full set\nof 30 landmarks for Democrats and Republicans. Figure 2.3 shows the results for\nthe average and standard deviation of the accuracy and coverage of our slant mea-\nsurements for 1,000 independent runs. Overall, we note that both average accuracy\nand coverage increase (while their standard deviations decrease) as we include more\nlandmarks. It is noteworthy that the accuracy and coverage start to plateau when we\n16\nreach around 10 landmarks. These results demonstrate the diminishing returns on\naverage slant accuracy and coverage as we include more landmarks. We conclude that\nour full set of 30 landmarks are su\u000ecient for achieving good accuracy and coverage\nfor both Democratic- and Republican-leaning news articles.\n2.1.4.3 Slant of Neutral Articles\nPreviously we showed that our estimated slant scores are well correlated with\neach article set's political a\u000eliation labeled using crowdsourcing.\nWe now want to categorize news articles into 3 categories of Democratic, Re-\npublican, and Neutral according to their measured slant scores. To do so, we need\nto decide suitable thresholds aandbsuch that\u00001\u0014a<b\u00141, and label the news\narticles with slant scores lying within ( a;b) as Neutral, the news articles with slant\nscores in the range [ \u00001;a] as Democratic-leaning, and the news articles with slant\nscores in the range [ b;1] as Republican-leaning. We experiment with multiple choices\nfor the thresholds aandb. For each choice, we compute a confusion matrix of the\nmatch between crowdsourced news article slant by [47] and our measured slant scores.\nTable 2.1 depicts the confusion matrix for symmetric thresholds b=\u0000a= 0:37 which\nmaximize the sum along the diagonal of the confusion matrix. Table 2.2 depicts that\nconfusion matrix for asymmetric threshold a=\u00000:48;b= 0:28 which maximize the\nsum along the diagonal of the confusion matrix.\n17\nCrowdsourced Slant Label Democratic Neutral Republican\nDemocratic-leaning 62.5% 26.8% 10.7%\nNeutral 34.1% 46.0% 19.8%\nRepublican-leaning 10.7% 23.6% 65.7%\nTable 2.1: Confusion matrix of the match between crowdsourced news slant measured\nby [47] and our measured slant scores when the threshold is symmetric ( b=\u0000a=\n0:37).\nCrowdsourced Slant Label Democratic Neutral Republican\nDemocratic-leaning 55.9% 31.6% 12.5%\nNeutral 26.5% 50.5% 23.0%\nRepublican-leaning 8.4% 22.8% 68.8%\nTable 2.2: Confusion matrix of the match between crowdsourced news slant mea-\nsured by [47] and our measured slant scores when the threshold is asymmetric\n(a=\u00000:48;b= 0:28).\n2.1.5 Summary\nWe presented a method to scalably measure the political slant of news articles.\nWe estimated the slant of individual news articles by analyzing the social connectivity\nof users who tweet about them. Our proposed method relies on a small set of Demo-\ncratic and Republican landmarks on Twitter. The results showed that our method\naccurately identi\fes slant of individual news articles.\n18\n2.2 Revisiting The American Voter on Twitter\n2.2.1 Background, Motivation, and Research Statement\nThe American Voter [51], published in 1960, demonstrated that the most\nimportant factors for voters when choosing their President were: party or partisanship ,\npolicy considerations , and personality of the person seeking o\u000ece. Partisanship {\nbeing a Democrat or a Republican { was extremely important and it was the one\nfactor that extended from one election to the next. Though policies shifted across\nelections, people's assessment of the importance of speci\fc policies in\ruenced their\nvotes. The third factor was how the candidates were perceived { their personality or\ncharacter. The American Voter was based on the largest collection of survey research\nof its day, covering presidential elections from 1948 through 1956. The study became\nan instant classic and set a research tradition that has extended to this point. The\nAmerican Voter Revisited [127] replicated the original research in the 2000s and found\namong other things that once again party, policy, and personality remain the three\nmost important factors in understanding who people vote for in presidential elections.\nOur aim is to use the classic The American Voter study as the basis for a\nprincipled analysis of Twitter conversations around the 2016 U.S. presidential elec-\ntion. Speci\fcally, we assess partisanship, discussions on policies, and perceptions of\ncandidates' personality using Twitter communications. While our approach derives\nin a principled way from The American Voter , our work is novel in that it bridges\nfrom traditional survey research to mining large-scale publicly available online social\nmedia communications.\n19\nSocial media has already played a signi\fcant role in elections in the U.S. and\nelsewhere [189, 102]. It was pivotal in the 2016 U.S. presidential election as well [21].\nGrowing numbers of the general public, especially the younger demographic, follow\nelections on social media [175, 84]. Given this trend, most candidates and their cam-\npaigns are actively trying to attract and engage social media users. Taking candidacy\nannouncement as an example, Ted Cruz was the \frst mainstream politician to o\u000e-\ncially announce his candidacy with a tweet. A few weeks later, Hillary Clinton also\ntook advantage of Twitter to announce she was running. Candidates di\u000ber in their so-\ncial media strategies and successes [101]. Donald Trump posted in\rammatory tweets\nto dominate the news cycle and drive up attendance at his rallies. Bernie Sanders's\ncampaign used #FeelTheBern to gather and rally a large grassroots movement.\nThe analysis of social media activity in prior literature has primarily focused\non counts (tweets, retweets, comments, likes, etc.) and sentiment as indicators of\npublic engagement, reach, and opinion. Content tends to be considered only in outlier\nconditions such as when a post goes viral. In contrast, our goal is to use computational\nmethods to explore content about policy discussions and personality perceptions in\naddition to party-speci\fc engagement on Twitter. Our key contributions are the\nfollowing.\n\u000fWe study Twitter communications around the 2016 U.S. presidential candidates\nusing 50 million tweets collected from November 15, 2015 to February 29, 2016.\nThis period covers Iowa, New Hampshire, Nevada, and South Carolina caucuses\nand primaries as well as several debates.\n20\n\u000fWe implement computational methods for tracking political discourse about\nparty, personality, and policy on Twitter.\n\u000fWe conduct statistical analysis of electoral polls to show the importance of\nparty, personality, and policy in the modeling of political deliberation.\nThe unique contribution of our work is in applying computational methods to\nan established and long line of election research in political science. Speci\fcally, we\ncontribute to the stream of research initiated by The American Voter by moving it\nforward from survey research to the realm of online social media.\n2.2.2 Related Work\n2.2.2.1 The American Voter\nAlthough published several decades ago, The American Voter [51] continues\nto serve as the baseline for researchers to understand voting behavior. The original\nstudy used survey data collected during three U.S. presidential elections (1948, 1952,\nand 1956). The central argument of the study is the funnel model, which claims that\nparty a\u000eliation shapes voters' attitude towards policy considerations and personality\nperception of presidential candidates. The study analyzed how voters form their own\nparty identi\fcation and how the psychological attachment between voters and their\nparty determines political attitudes.\nBased on the original study, The American Voter Revisited [127] in 2008 at-\ntempted to understand voting behaviors during the U.S. presidential elections in 2000\nand 2004. The authors found that, as compared to the 1950s, more voters identi\fed\n21\nwith their party a\u000eliations in the 2000s. More importantly, the authors also found\nthat voting outcomes are still explained by party identi\fcation, short-term policy\nissues, and perceptions of candidates. The authors concluded that even though the\nin\ruence of these factors on voting outcomes may have changed over time, the three-\npronged paradigm of party, policy, and personality remains intact.\nWe ask whether these dimensions are present in current social media data,\nwhether it is possible to track them, and whether they still relate to the politicians'\nsuccess at the polls. Below, we discuss prior research on measurement and analysis\nof party, policy, and personality, especially in online social media.\n2.2.2.2 Party\nIdenti\fcation of political a\u000eliations is a well-researched area. Prior political\nscience research primarily relies on interviews to explicitly ask users about their po-\nlitical a\u000eliations. On online social media, however, only a small fraction of users\nreport their political a\u000eliation. For example, less than 10% of U.S.-based adult Face-\nbook users self-report their political a\u000eliation [32]. It is challenging to infer users'\npolitical party a\u000eliations at a large scale using online social media data. Cohen and\nRuths [58] showed that it is di\u000ecult to infer political orientation for \\normal\" Twit-\nter users who rarely discuss politics. Some researchers have used machine learning\ntechniques such as LDA (Latent Dirichlet Allocation) [59], SVM (Support Vector Ma-\nchine) [59, 205, 153], and BDT (Boosted Decision Tree) [153] to infer users' political\na\u000eliations based on pro\fle features (e.g., name, location), linguistic features (e.g.,\n22\ntweet text, hashtags), and network features (e.g., followers, retweets, replies). Some\nresearchers have used label propagation techniques where a user's political a\u000eliation\nis inferred based on whether they post about well-known conservative/liberal issues\nor follow well-known conservative/liberal users. For example, Zhou et al. [209] in-\nferred political leaning of users on Digg based on how they voted (equivalent to like\nor share) on news articles with labeled political ideology using Amazon Mechanical\nTurk (AMT) workers. More recently, Golbeck et al. [83] inferred political leaning\nof Twitter users based on whether they follow a seed group of well-known political\npersonalities (e.g., Congress members). We use a similar method to infer political\na\u000eliation of Twitter users in our work.\nPrior political science research has shown that the political party a\u000eliation's\nimpact on voting outcomes may not be straightforward. Using survey data on political\n\fgures and events, Bartels [37] applied a Bayesian model to study opinion change with\nrespect to partisan bias. He found that partisanship is not just a simple \\running\ntally\", but rather shapes voters' attitudes and reactions to politics, resulting in sharp\ndi\u000berences in opinions between Democrats and Republicans towards various political\nevents. Other studies have also looked at the marginal and joint impact of political\na\u000eliation and other factors on voting preferences (e.g., [40, 69, 97]), which we also\nexamine here.\n23\n2.2.2.3 Personality\nPerception of politicians' personality re\rects both the campaign's success in\nframing their candidate and the values of the electorate projected onto these public\npersonas. Pew Research Center and the Washington Post conducted surveys to study\nhow personalities of political leaders are perceived by the public over time [74, 75].\nThrough phone interviews, U.S. adult voters were asked for the one word that comes\nto mind when a politician is named. Comparing Obama and Romney, voters' most\ncommon perception of Obama were Good ,Trying ,President , and also Failure and\nIncompetent and for Romney were Honest ,Businessman ,Rich,Good , and Conserva-\ntive. However, survey-based personality research cannot rival the scale of online social\nmedia. Prior studies on personality perceptions of presidential candidates from online\nsocial media communications have relied on broad categorization of sentiment such\nas positive, negative, and neutral [41, 113, 197, 139]. Tumasjan et al. [189] looked\nat more detailed sentiment aspects such as anxiety, anger, and sadness for di\u000berent\ncandidates in the 2009 German national election. More recently, Bhattacharya et al.\n[43] proposed a method to systematically measure personality traits suggested by The\nAmerican Voter [51] using a template-driven approach that measures the personality\ntrait on a continuum, measuring either its presence or absence. As state-of-the-art,\nwe use their method in our work.\nFurther, party a\u000eliation has been repeatedly shown to relate to the rhetoric\nof the politicians in question, as been shown by [64, 81, 76], who have studied the\nin\ruence of politicians' personality traits on their leadership and decision-making\n24\nstyles. For example, Gallagher et al. [76] found that the personality traits of political\nleaders shape their choices and their level of consistency in policy making. Further,\nBenoit [40] showed that Republicans discuss character more, and policy less, than\nDemocrats. While examining debates, television spots, and acceptance addresses from\n1948 to 2000, he found that Democrats emphasized more on traits like `empathy' and\n`drive' while Republicans emphasized more on traits like `sincerity' and `morality'.\nThe automated analysis framework we present in this paper provides parallel insights\nof the politicians' character as perceived by social media users.\n2.2.2.4 Policy\nPolicy issues have been examined at both the macro-level (nation or public as\na unit of analysis) [57, 38] and the micro-level (how individuals de\fne issues) [201,\n202]. In order to track policy-related discussions on online social media, researchers\ntypically create a lexicon of relevant terms of each policy and track their occurrences\nwithin the content [208, 181]. For example, Zhang et al. [208] manually identi\fed\nrelevant keywords, phrases, and hashtags related to same-sex marriage on Twitter,\ncommunity wikis, and news articles to predict policy changes on the issue. We follow\na similar high-precision approach, engaging political scientists' domain expertise to\nbuild vocabularies for each topic.\nPrior political science research has explored the impact of policies on voters'\nevaluation of presidential candidates. Benoit [40] investigated presidential elections\nbetween 1948 and 2000 by quantitatively analyzing the texts of primary and general\n25\ndebates, television spots, and acceptance addresses. The key conclusions were that\nDemocrats discuss policy more than Republicans, and that Democrats focus more\non issues such as education while Republicans focus more on issues such as national\nsecurity. Dolan [69] examined the American National Election Study (ANES) election\ndata between 1992-2006 and concluded that while voters may have a di\u000berent view on\nabortion than their party, people tend to go with their party a\u000eliation when voting\nin elections. Finding that more Democrats consider abortion an important issue than\nRepublicans, Dolan showed that the relationship between policy and party is not\nhomogeneous. A similar recent study by Highton [97] of ANES data spanning three\npresidencies (H.W. Bush: 90-92, Clinton: 92-96, and W. Bush: 00-04) further showed\na strong partisanship e\u000bect, but one which over time changes with economic and\ncultural attitudes. In this work we aim to capture the interplay between partisanship\nand views on policy and on politicians' characters, however incorporating economic\nand cultural variables (which is beyond the scope of this work) is an exciting future\ndirection.\n2.2.2.5 Election Prediction\nDue to the popularity of social media, using Twitter data to track public opin-\nion and speci\fcally to predict presidential elections has been an active research area.\nThere are con\ricting results reported in prior literature for election prediction using\nsentiment analysis of social media communications. In one of the seminal attempts,\nTumasjan et al. [189] analyzed the content of more than 100K tweets published prior\n26\nto the German national election. They found that the share of tweets for six di\u000berent\nparties closely matched the election results with an error of less than 2%. O'Connor\net al. [148] studied the correlation between public opinion measured from traditional\npolls and sentiment measured from Twitter. They found that while Twitter senti-\nment correlates with consumer con\fdence and presidential job approval polls, there\nis not a strong correlation with the 2008 presidential election poll. Gayo-Avello et\nal. [79] also evaluated the power of Twitter data in predicting the 2010 U.S. election\noutcomes. They also found that Twitter sentiment analysis is not accurate in pre-\ndiction and its performance is only slightly better than a random classi\fer. Other\nresearchers [113, 78, 174, 167] have also highlighted issues with using Twitter to pre-\ndict elections, such as the need of methodological justi\fcation in terms of accuracy,\nthe need to produce a true forecast (i.e. issued prior to the election), the need to\ncontrol for biases, etc. Later, some researches [41, 68, 55, 49] tried to address these\nproblems albeit with limited success. Due to these various issues, in this paper we do\nnot attempt to predict the outcome of the election. Quite the opposite, we provide\na complex view of the electorate's decision landscape that cannot be reduced to a\nsingle metric.\n2.2.3 Methodology\nOur aim is to use state-of-the-art computational approaches to track party,\npolicy, and personality in online social media communications. Each approach is\ndriven by a lexicon or a seed list, supplied by subject matter experts, and is then\n27\nexploited to produce quantitative measurements for further analysis. Aditionally,\nsearch templates are used for personality.\n2.2.3.1 Party\nWe infer political a\u000eliations of Twitter users using a method (having the\nsame logic of the method in our \frst work) that is both simple and e\u000ecient. This\nmethod is supported by the theory of selective exposure [170] which implies that\nonline social media users tend to follow other users with similar beliefs or ideology.\nSpeci\fcally, in the context of American politics, Democrats are more likely to follow\nother Democrats and Republicans are more likely to follow other Republicans [60].\nThus, a user following more Republicans than Democrats is likely to be a\u000eliated\nwith Republicans. Similarly, a user following more Democrats than Republicans is\nlikely to be a\u000eliated with Democrats. We manually curated sets of 30 well recognized\nDemocrat (e.g., Rachel Maddow) and 30 Republican (e.g., Sean Hannity) accounts\non Twitter as the \\landmarks.\" The curation was done in consultation with political\nscientists. We intentionally include several journalists with recognized a\u000eliations as\nlandmarks because of their large Twitter followings. On average, each Democratic\nlandmark has 223,656 followers and each Republican landmark has 277,671 followers.\nPolitical a\u000eliation is then a function of the number of landmark Democrats and Re-\npublicans that each user follows on Twitter:#Republicans \u0000#Democrats\n#Republicans +#Democrats:The output is in\nthe range of [\u00001;1], where\u00001 indicates Democratic a\u000eliation, +1 indicates Repub-\nlican a\u000eliation, and 0 indicates Other (independent or alternative). Our method to\n28\ninfer political a\u000eliation of Twitter users based on whether they follow well-recognized\nDemocratic and Republican landmarks is high precision and low recall. Therefore,\nthe \"Other\" category may include politically inactive Twitter users whose political\na\u000eliation cannot be inferred by our method [58].\n2.2.3.2 Personality\nTo characterize personality perceptions, Bhattacharya et al. [43] used the Ad-\njective Check List (ACL) [85], which has 300 adjectives or traits commonly used to\ncharacterize a person's personality. The ACL covers a wide variety of traits such as\nintelligent ,creative ,determined ,cheerful . Traits are viewed as either positive (e.g.,\nhonest), negative (e.g., anxious) or neutral (e.g., jolly). Simonton reduced them to\na core set of 110 traits with factor analysis and used these traits to characterize the\npersonality of 39 American presidents [173]. Simonton further consolidated these\n110 traits into 14 non-orthogonal personality dimensions, which include moderation ,\nfriendliness ,intellectual brilliance ,machiavellianism ,poise and polish ,achievement\ndrive ,forcefulness ,wit,physical attractiveness ,pettiness ,tidiness ,conservatism ,in-\n\rexibility , and paci\fsm . Subsets of the 110 traits are given loadings on a continuous\nscale of [-1,1] that show how traits positively or negatively contribute to a particular\npersonality dimension. For example, the intellectual brilliance dimension is composed\nofartistic (.84), inventive (.76), curious (.74), intelligent (.64), sophisticated (.62),\ninsightful (.54), wise (.46), dull(-.71 ), and commonplace (-.41).\nIn our study, we characterize perceptions on the personalities of the 2016\n29\npresidential candidates using Simonton's 110 traits and 14 personality dimensions.\nWe use a set of forty high-precision search templates [43] to identify tweets expressing\nthese personality perceptions. There are two types of templates, one to retrieve tweets\nstating that a trait is present and the other to retrieve tweets saying that a trait is\nabsent. An example template is: [P] is [A]? [T]. Here [P] is a variable representing a\nperson name such as Clinton or Hillary Clinton, [A] represents a class of high certainty\nwords (e.g., de\fnitely, very) and [T] is a speci\fc trait such as honest (or its synonyms).\nThe `?' designates item being optional. This template retrieves statements such\nas `Hillary Clinton is certainly smart' and `Hillary Clinton is intelligent'. Another\nexample is [P] is [S] [T], where [S] represents words that are only somewhat certain\n(e.g., sort of, somewhat, kinda). It retrieves statements such as `Hillary Clinton is\nsort of decisive' and `Hillary Clinton is somewhat friendly'. We consider negation\nin statements (`Hillary Clinton is not decisive') and trait antonyms (`Hillary Clinton\nis not unfriendly'). We further manually examine tweets retrieved by the search\ntemplates to eliminate false positives due to sarcasm. Using the tweets retrieved by\nthese search templates, we calculate a score for each trait. Since di\u000berent presidential\ncandidates may accumulate varying numbers of tweets, we normalize this score for\nthe number of tweets discussing the trait. Further details are in [43].\n2.2.3.3 Policy\nTo understand how policy preferences of candidates impact their perception,\nwe track tweets related to 11 di\u000berent policy categories for each candidate. The list\n30\nof policies includes abortion, gay rights, climate change, foreign policy, health care,\nimmigration, gun control, education, economy, veterans, and miscellaneous. While\nnot a complete list by any means, these are some of the key issues discussed in our\ndata, and were identi\fed as most commonly discussed around candidates on Twit-\nter by Rupar et al. [164]. In consultation with political scientists, we compiled the\nlist of keywords for each policy by starting with a few well recognized keywords for\neach policy, e.g., \\pro-life\" and \\pro-choice\" for abortion. We then identi\fed other\nrelated keywords with which they co-occurred (e.g., \\planned parenthood\" was fre-\nquently mentioned for abortion). Further, the miscellaneous policy category includes\nother keywords such as \\blacklivesmatter\" and \\sex discrimination\" which could not\nbe neatly included in other policy categories. Given the set of these highly precise\nkeywords for a policy, we extracted all tweets that contain at least one of the key-\nwords. Being the most topic-dependent dimension, policy tracking is most in need of\nexpert supervision and keyword curation, and we leave an automated keyword-based\nextraction of such topics to future work.\n2.2.3.4 Sentiment\nWhile our main points of focus are the three factors from The American Voter ,\nwe also analyze our data using the more common text mining strategy of sentiment\nanalysis. The goal here is to gauge the general negativity or positivity in the discus-\nsion surrounding each presidential candidate. Given the limited size of tweets (140\ncharacters), we can safely assume that the sentiment detected in political tweets con-\n31\ncerns the entities (in this case, the candidates) mentioned therein [148]. For sentiment\nanalysis, we rely on the SentiWordNet lexicon [30], which assigns positive and neg-\native scores to each synset (set of synonyms) of WordNet (containing around 117K\nsynsets). To this end, we split a tweet's text as separate sentences, remove symbols\nsuch as \\<[>]\u0003>\", tokenize, and stem before matching to the SentiWordNet lex-\nicon. To quantify the overall sentiment of each tweet, we use the common approach\nwhich is to sum up positive and negative sentiment scores of the matched tokens. If\nthe positive sentiment score is larger than the negative sentiment score, we label the\ntweet as positive, and similarly for negative. If both scores are equal, we label the\ntweet as neutral.\n2.2.4 Dataset\n2.2.4.1 Data Collection\nThis work uses Twitter collections around 10 major presidential candidates\nlisted in Table 2.3. Two of these candidates are running as Democrats (Clinton and\nSanders) and the remaining eight are running as Republicans. For each candidate, we\ncollected tweets posted from November 15, 2015 to February 29, 2016. The data were\ncollected using Twitter's streaming API with \flter keywords ( statuses/filter ) for\neach candidate. We used full names of candidates such as \\hillary clinton\" for Clinton.\nThis API provides all tweets related to the \flter keywords, but caps the tweets at\n1% of all public tweets. Since more than 500 million tweets per day are posted on\nTwitter [7], we are set to capture up to \fve million tweets per day for each candidate.\n32\nNote that the highest daily tweet count (for Trump) is less than one million, thus we\ncan safely assume that we are capturing a vast majority of tweets for all candidates.\nMoreover, for computing Twitter users' political a\u000eliation, we also used Twitter's\nREST API to crawl the follower lists for the sixty landmark accounts.\nWe decided not to discount retweets versus original tweets when counting\ntweets. We \fnd retweets to usually be quoted as-is, without modi\fcation from the\nuser { our data is 58.15% retweets, and of those 99% are quoted verbatim. It may\nbe the case that retweeting is less powerfully associated with user opinion. It would\nbe an interesting future work to \fnd a suitable discount factor for retweets. We did\nnot explicitly attempt to geographically \flter tweets because only a small fraction are\nGPS located. When examining the GPS located tweets in our data, we \fnd 85.3%\nto be from the USA and 3.3% from the UK in a distant second place. Our data may\ninclude some tweets from international Twitter users, although the lexicons used in\nour analysis should at least limit them to English language tweets.\n2.2.4.2 Data Statistics\nAs shown in Table 2.3, Trump has a clear lead with about 7 million tweets\nabout him from more than 5 million users. Moreover, about half of the users and\ntweets were posting about Trump. This is roughly 3X the Twitter attention given to\nClinton or Sanders who have similar numbers of tweets and users. Cruz follows with\nabout 6.5 million tweets from close to a million users. The remaining candidates trail\nbehind to varying degrees.\n33\n(a) Democratic candidates\n(b) Republican candidates\nFigure 2.4: Time series of tweets for candidates. The vertical black lines indicate\nthe following major election events during the data collection period. (1) DebR1:\nCNN Republican debate, (2) DebR2: Fox Business Republican debate, (3) DebD2:\nNBC News Democratic debate, (4) DebR3: Fox News Republican debate, (5) IAD:\nDemocratic Iowa caucus, (6) IAR: Republican Iowa caucus, (7) DebD3: MSNBC\nDemocratic debate, (8) DebR4: ABC News Republican debate, (9) NHD: Demo-\ncratic New Hampshire primary, (10) NHR: Republican New Hampshire primary, (11)\nDebD4: PBS Democratic debate, (12) DebR5: CBS Republican debate, (13) NVD:\nDemocratic Nevada caucus, (14) SCR: Republican South Carolina primary, (15) NVR:\nRepublican Nevada caucus, (16) DebR6: CNN Republican debate, (17) SCD: Demo-\ncratic South Carolina primary.\n34\nCandidateNumber Number Tweets from Republicans Tweets from Democrats Tweets from Others\nof Users of Tweets Positive Negative Neutral Total Positive Negative Neutral Total Positive Negative Neutral Total\nHillary Clinton 1,391,829 7,224,615 217,549 764,536 86,469 1,068,554 306,149 802,342 122,813 1,231,304 1,097,466 3,249,497 577,794 4,924,757\nBernie Sanders 1,500,362 7,215,240 88,652 291,246 34,781 414,679 402,260 1,079,684 158,993 1,640,937 1,239,066 3,348,727 571,831 5,159,624\nDonald Trump 5,096,698 21,351,629 423,049 1,508,704 172,275 2,104,028 333,269 1,447,187 133,512 1,913,968 2,956,020 12,968,070 1,409,543 17,333,633\nTed Cruz 995,067 6,478,005 223,283 1,398,221 111,358 1,732,862 86,020 693,479 41,525 821,024 399,699 3,298,447 225,973 3,924,119\nJohn Kasich 159,999 425,123 17,887 59,017 7,632 84,536 15,533 49,837 6,060 71,430 64,406 182,385 22,366 269,157\nBen Carson 510,513 1,518,287 52,007 157,262 18,537 227,806 62,615 162,681 19,452 244,748 279,862 677,408 88,463 1,045,733\nMarco Rubio 495,516 2,727,233 158,753 491,231 63,297 713,281 63,786 230,133 24,245 318,164 348,875 1,176,074 170,839 1,695,788\nJeb Bush 560,798 1,807,891 22,258 238,806 11,882 272,946 20,534 225,332 12,427 258,293 77,658 1,145,254 53,740 1,276,652\nChris Christie 199,998 522,164 19,833 51,696 6,665 78,194 28,108 78,277 8,234 114,619 86,414 218,409 24,528 329,351\nCarly Fiorina 132,672 294,669 9,701 30,878 3,951 44,530 14,015 52,480 5,962 72,457 37,794 123,691 16,197 177,682\nTotal 11,043,452 49,564,856 1,232,972 4,991,597 516,847 6,741,416 1,332,289 4,821,432 533,223 6,686,944 6,587,260 26,387,962 3,161,274 36,136,496\nTable 2.3: Statistics of candidate tweet collections from November, 15 2015 to Febru-\nary 29, 2016. Close to half the users and tweets in the dataset were posting on\nTrump. Trump's numbers re\rect a 3X lead in tweets and users compared to Clinton\nand Sanders. Negative sentiment tweets signi\fcantly outnumber positive and neu-\ntral ones. The sentiment charged nature of the dialog is also indicated by the low\nprevalence of sentiment neutral tweets (about 8%). Same party tweets outnumber\ncompeting party tweets for seven out of ten candidates. Democrats tweeted more\nabout Trump than about Clinton or Sanders. Republicans were more interested in\nClinton than in Sanders.\nFigure 2.4 shows the time series of tweets for all presidential candidates. We\nobserve sharp spikes for both Democratic and Republican candidates. These spikes\ntypically correspond to major election events. Our data collection covers the Iowa,\nNew Hampshire, Nevada and South Carolina caucuses and primaries as well as several\ndebates. Some events happened on the same day for both parties. For example, both\nDemocrats and Republicans held the Iowa caucus on February 1 and New Hampshire\nprimary on February 9. Others happened on di\u000berent days for each party. For\nexample, the Nevada caucus for Democrats was held on February 20 while that for\n35\nRepublicans was held on February 23. Di\u000berent events happened on the same day for\nboth parties as well. For example, the Nevada caucus for Democrats and the South\nCarolina primary for Republicans were held on February 20.\nWe observe that all candidates received spikes on major election event days.\nThe magnitudes of spikes di\u000ber depending on how well candidates performed at that\nevent. For example, Clinton received 51% more tweets than Sanders on the day she\ndefeated him at the South Carolina primary. As another example, Sanders received\n102% more tweets than Clinton when he defeated her in the New Hampshire primary.\nHowever, we also note that losing candidates sometimes received more tweets than\nwinning candidates. For example, even though Clinton won the Iowa caucus, Sanders\nreceived 8% more tweets. This di\u000berence is very small compared to the previous\nexamples possibly because Sanders lost to Clinton by a very small margin. While\nTrump received more spikes than other Republican candidates, Cruz received the\nlargest spike when he unexpectedly won the Iowa caucus instead of Trump. Cruz\nreceived 16% more tweets than Trump on the day of event. As another example,\nBush received the second largest spike for the South Carolina primary, even though\nRubio and Cruz are ranked second and third respectively after Trump. The spike\nwas because Bush announced that he would quit the race after his disappointing\nperformance in the South Carolina primary. Bush received 166% more tweets than\nRubio while only 32% fewer tweets than Trump on the event day.\nBesides the spikes for all candidates on days of major election events, candi-\ndates sometimes had spikes on speci\fc days based on their own campaign activities.\n36\nFor example, Trump received many more tweets than other candidates starting De-\ncember 7 (which then gradually faded after 5-6 days) when he called for a ban on\nMuslims entering the U.S. [8]. While not obvious in Figure 2.4 due to Trump's large\ntweet counts, Kasich had a spike on November 19 when he announced plans to create\na new federal agency that would promote Judeo-Christian values [71]. Fiorina also\nreceived many more tweets on November 29 when she told the Fox News that Obama\nis \\delusional\" for saying that climate change is a major national security threat [10].\nTable 2.3 also dissects the tweet data by detected sentiment. Negative tweets\nsigni\fcantly outnumber positive tweets for all candidates, but to a di\u000berent extent\nfor each candidate. For the whole time period, Bush received the highest ratio of\nnegative tweets to positive ones (13.4 \u0002), followed by Cruz (7.6 \u0002) and Trump (4.3\u0002)\nwhile Carson (2.5 \u0002), Christie (2.6\u0002), and Sanders (2.7 \u0002) received the lowest ratio.\n2.2.5 Results\n2.2.5.1 Party\nThe party a\u000eliation serves as a key factor in determining the electorate's\nperception of candidates and voting decisions. In the U.S., it is usually dichotomized\ninto Democrats vs. Republicans, although alternative or independent a\u000eliations have\nbeen on the rise [54]. For those a\u000eliated, prior literature has shown that only a small\nfraction of people vote against their party a\u000eliations [51, 127]. Here, we analyze\nthe breakdown of tweet volume and its sentiment with respect to party a\u000eliations\nof the users as Republicans, Democrats, and the catch all group: Others. In total,\n37\nour data contains almost 50 million tweets from more than 11 million Twitter users.\nIt is noteworthy that the total number of tweets from Republicans (6,741,416) and\nDemocrats (6,686,944) are almost equal.\nInterestingly, the breakdown of tweets by party in Table 2.3 shows that tweets\nfrom users a\u000eliated to the same party outnumber tweets from the competing party for\nall candidates, except for Fiorina, Christie, and Carson. For example, 23% (1,640,937)\ntweets mentioning Sanders are from Democrats while 6% (414,679) tweets are from\nRepublicans. As another example, 27% (1,732,862) tweets mentioning Cruz are from\nRepublicans while 13% (821,024) tweets are from Democrats. Overall, Trump received\nmost tweets across all political a\u000eliations as compared to other candidates.\nTable 2.3 also shows the presence of some \\crosstalk\". While Republican lean-\ning user tweets were mostly about Republican candidates (78%), Democrat leaning\nusers were tweeting slightly more (57%) about Republican candidates than about\ncandidates from their own party. Thus, we \fnd far more \\crosstalk\" from Demo-\ncratic leaning users than from Republican leaning users [35], suggesting an aggra-\nvated echo-chamber e\u000bect on the Republican side. Republican leaning users tweeting\nabout Democrats were far more intereseted in Clinton (2.6 \u0002more) than in Sanders.\nWhereas when tweeting about Republicans, Democrats mostly talked about Trump,\nfollowed Cruz in the distant second.\nTable 2.3 also provides the sentiment breakdown of tweets for all party a\u000el-\niations. As indicated earlier, negative tweets - almost three-fourths of all tweets -\ndominate. This observation holds for each candidate as well. The highly charged\n38\nPersonality Dimension #Tweets %TweetsRepublicans Democrats\n# %# Positive # Negative # %# Positive # Negative\nTweets Tweets Tweets Tweets Tweets Tweets Tweets Tweets\nModeration 103,671 32.8% 15,788 31.8% 1,738 (11%) 13,348 (85%) 16,521 35.3% 1,996 (12%) 11,971 (72%)\nFriendliness 65,041 20.6% 8,159 16.4% 1,394 (17%) 6,239 (76%) 10,334 22.1% 1,499 (15%) 8,203 (79%)\nMachiavellianism 41,692 13.2% 8,930 18.0% 1,873 (21%) 6,788 (76%) 6,091 13.0% 926 (15%) 4,985 (82%)\nIntellectual Brilliance 34,319 10.8% 5,694 11.5% 662 (12%) 4,787 (84%) 5,885 12.6% 755 (13%) 4,910 (83%)\nPaci\fsm 23,202 7.3% 3,879 7.8% 115 (3%) 3,737 (96%) 1,211 2.6% 67 (6%) 852 (70%)\nWit 12,751 4.0% 1,112 2.2% 150 (13%) 926 (83%) 1,769 3.8% 174 (10%) 1,540 (87%)\nOther Dimensions 35,717 11.3% 6,080 12.3% 668 (11%) 5,150 (85%) 4,966 10.6% 1,125 (23%) 3,666 (74%)\nTotal 316,393 100.0% 49,642 100.0% 6,600 (13%) 40,975 (83%) 46,777 100.0% 6,542 (14%) 36,127 (77%)\nTable 2.4: Statistics of tweets conveying personality perceptions and their breakdown\nacross party a\u000eliation and sentiment.\nnature of the Twitter election dialog is also seen in the low numbers of sentiment\nneutral tweets. Around 8% of the tweets posted by each user group is sentiment\nneutral.\n2.2.5.2 Personality\nTable 2.4 provides an overview of more than 316 thousand tweets in our data\nthat convey perceptions of candidates' personality along six out of fourteen person-\nality dimensions. The table is again broken down by party a\u000eliation, Republican\nleaning or Democrat leaning. The most discussed personality dimension is moder-\nation, which accounts for almost one-third of all personality-related tweets. This is\nfollowed by friendliness, machiavellianism, intellectual brilliance, paci\fsm, and wit.\nThe remaining personality dimensions are discussed infrequently and are therefore\nleft out of the table.\nComparing the types of posts made by users leaning towards each party we\n\fnd a few di\u000berences. For example, Democrats discuss friendliness of candidates more\nthan Republicans. In contrast, Republicans discuss machiavellianism and paci\fsm of\n39\n(a) Moderation\n (b) Friendliness\n(c) Machiavellianism\n (d) Intellectual Brilliance\nFigure 2.5: Scores for four most discussed personality dimensions. Scores are in the\nrange [-1,+1]. -1 (+1) indicates the personality is viewed as absent (present) with\nhigh con\fdence. The number of tweets for absence (presence) of each personality\ndimension are provided on the left (right) of the bar plot. The net score is included\nin the parenthesis. The bar plots are shown for candidates receiving a minimum of\n100 tweets on a dimension.\n40\ncandidates more than Democrats. Overlaying sentiment, we note that while negative\ntweets account for about four-\ffths of all personality-related tweets overall, Republi-\ncans tend to be more negative than Democrats (83% vs. 77%). Finally, as compared\nto Republicans, Democrats are more positive about paci\fsm and more negative about\nmachiavellianism and wit.\nFigure 2.5 shows the candidate-level breakdown of the four most frequently\ndiscussed personality dimensions. We excluded candidates with very few tweets for\nsome personality dimensions from our analysis. For systematic analysis, we divide\ncandidates into high-frequency and low-frequency groups based on their tweet counts\nfor each personality dimension and limit candidate comparisons to each group.\nModeration. Clinton and Rubio are perceived as moderate while Trump,\nSanders, and Cruz are perceived as not moderate in the high-frequency group. Clinton\nreceived the highest score of 0.28 for moderation. For example, Clinton received\nmore than 11 thousand tweets containing phrase \\Hillary Clinton Is Calm ,Cool and\nE\u000bective\". Keywords calm and cool are positively aligned with moderation. On\nthe other hand, Trump received -0.14 score for moderation { he received more than\na thousand tweets including \\Donald Trump is terrible for disrespecting Moslems\"\n(terrible being negatively aligned with moderation). In the low-frequency group,\nBush, Carson, and Kasich are perceived as moderate while Fiorina is perceived as\nnot moderate.\nFriendliness. Sanders is perceived as friendly, while Cruz and Trump not,\nwhereas Clinton is seen as neutral in the high-frequency group. Kasich and Carson are\n41\nperceived as friendly while others, led by Fiorina, are perceived as not friendly in the\nlow-frequency group. In particular, Sanders was considered by many as cute (\\Bernie\nSanders is so cute\"), whereas, for instance, Cruz received more than a thousand\ntweets saying \\Cruz is nasty \" and \\Ted Cruz isn't likeable \". Although having no\ndirect relation to the political strengths of the candidates, surprisingly, thousands of\ntweets referred to their personal amiability.\nMachiavellianism. On the opposite side we \fnd machiavellianism, associ-\nated with being deceitful and unscrupulous. In the high frequency group, Clinton\nand Cruz are perceived as machiavellian, while Sanders and then Trump are not.\nFor example, Cruz received hundreds of tweets such as \\Ted Cruz is untrustworthy \"\nand \\Ted Cruz is so dishonest that TV stations won't run his ads because they're\nworried about legal culpability\". On the other hand, Sanders received more than a\nthousand tweets such as \\100% of 18{29 year olds think Bernie Sanders is honest and\ntrustworthy \" which result in -0.37 machiavellian score for him.\nIntellectual Brilliance. In the high-frequency group, Trump and Cruz and\nboth are perceived as intellectually brilliant. For example, Trump received more\nthan six thousand tweets such as \\Donald Trump Is Smart To Remind Voters Of\nClinton Drama\". All other candidates are in the low frequency group and most\nof them (Clinton followed by Bush, Sanders, and then Fiorina) are perceived as\nintellectual brilliant. Only Kasich and Christie are perceived as not intellectually\nbrilliant. Kasich, for example, even received tweets like \\John Kasich is a very stupid\nman\" contributing to his low score.\n42\nPolicy #Tweets %TweetsRepublicans Democrats\n# %# Positive # Negative # %# Positive # Negative\nTweets Tweets Tweets Tweets Tweets Tweets Tweets Tweets\nForeign Policy 2,050,648 33.2% 307,254 28.4% 51,039 (17%) 239,913 (78%) 316,859 31.2% 51,856 (16%) 249,622 (79%)\nImmigration 1,416,459 22.9% 289,251 26.8% 30,712 (11%) 244,987 (85%) 207,076 20.4% 21,280 (10%) 178,188 (86%)\nHealthcare 884,371 14.3% 171,476 15.9% 31,931 (19%) 125,392 (73%) 134,343 13.2% 22,674 (17%) 102,493 (76%)\nEconomy 795,784 12.9% 120,462 11.1% 12,188 (10%) 104,678 (87%) 171,748 16.9% 16,780 (10%) 148,904 (87%)\nAbortion 265,593 4.3% 79,007 7.3% 11,060 (14%) 65,250 (83%) 49,127 4.8% 9,823 (20%) 36,389 (74%)\nGay Rights 232,515 3.8% 25,832 2.4% 10,641 (41%) 12,422 (48%) 40,310 4.0% 13,969 (35%) 23,760 (59%)\nOther Policies 537,551 8.6% 87,467 8.1% 30,101 (34%) 50,454 (58%) 97,239 9.5% 27,747 (29%) 60,542 (62%)\nTotal 6,182,921 100.0% 1,080,749 100.0% 177,672 (16%) 843,096 (78%) 1,016,702 100.0% 164,129 (16%) 799,898 (79%)\nTable 2.5: Statistics of tweets discussing di\u000berent policies, and their breakdown across\nparty a\u000eliation and sentiment.\n2.2.5.3 Policy\nTable 2.5 presents an overview of the more than six million tweets about policy\nin our data. The table is limited to the six most discussed policies and the remaining\n\fve policies are summarized under `Other Policies'. Foreign policy (33%), immigra-\ntion (23%), healthcare (14%), and the economy (13%) are the most discussed policies.\nDemocrat leaning users express most interest in foreign policy compared to immigra-\ntion which ranks second in drawing their attention (11% di\u000berence). In contrast, the\ntwo policies draw equal attention from Republican leaning users. Republicans tweet\nmore about abortion, health care and immigration (3-6% di\u000berence) than Democrats\nwhile Democrats tweet more about gay rights, foreign policy, and economy (2-6% dif-\nference) than Republicans. Overlaying sentiment, we again note that negative tweets\naccount for about four-\ffths of all policy-related tweets. While Republicans are more\npositive than Democrats for gun control, veterans, and gay rights (6-8% di\u000berence)\nthe order is reversed for abortion (6% di\u000berence).\nFigure 2.6 shows the candidate-level breakdown of the six most frequently\n43\n(a) Foreign policy\n (b) Immigration\n(c) Health care\n (d) Economy\n(e) Abortion\n (f) Gay rights\nFigure 2.6: Number of tweets for the six most discussed policies with party a\u000eliation\nbreakdown. The blue and red regions indicate tweets from Democrats and Republi-\ncans, respectively. The white region represents tweets from the remaining users.\n44\ndiscussed policies. We note that Clinton, Sanders, Trump, Cruz, and Rubio received\nmuch more policy-related tweets than the remaining candidates. Thus, we limit our\nanalysis to these top candidates.\nForeign policy. Trump is by far the most discussed candidate for foreign\npolicy, with almost twice relevant tweets than Clinton in the second place. The most\nmentioned foreign policy keyword is ISIS for both candidates, with Trump having\nabout 200 thousand tweets and Clinton having about 150 thousand matching tweets.\nHowever, after ISIS, the most mentioned keyword for Trump is Paris (78 thousand\ntweets) and that for Clinton is Benghazi (75 thousand tweets). This observation can\nbe explained by Clinton's email scandal as part of hearings conducted by the House\nSelect Committee on Benghazi.\nImmigration. Trump is the most discussed candidate for immigration, fol-\nlowed by Cruz, Rubio, and Clinton. In general, for these candidates three most men-\ntioned keywords are refugee and immigrants . However, immigration-related tweets\nfor Rubio mostly had the keyword amnesty . This observation can be explained by\nRubio's change his stance on amnesty. While the other Republican candidates were\nconsistently against amnesty, Rubio changed his stance on amnesty when he ran for\nthe presidency.\nHealthcare. Trump and Cruz received most healthcare related tweets, fol-\nlowed by Sanders and Clinton. The most mentioned keyword in healthcare is ACA\n(A\u000bordable Care Act) which outnumbers ObamaCare .\nEconomy. Democratic candidates are most discussed with respect to the\n45\neconomy, with Sanders leading Clinton. The most mentioned keywords in economy\nrelated tweets are Wall Street ,tax,social security , and poverty .\nAbortion. Three most discussed candidates about abortion are Cruz, Trump,\nand Clinton { they received roughly equal number of tweets. There most mentioned\nkeyword about abortion is Planned Parenthood . Each of the top three candidates\nreceived about 30 thousand tweets containing Planned Parenthood with much more\ntweets from Republicans than Democrats.\nGay rights. Republican candidates are the most discussed about gay rights,\nwith Cruz in the lead followed by Trump and Rubio. The most mentioned keyword\nin gay rights is gays, with Cruz and Trump each receiving more than 50 thousand\ntweets. Other popular keywords include gay marriage ,same-sex marriage , and mar-\nriage equality . All candidates received more tweets about gay rights from Democrats\nthan Republicans.\n2.2.6 Impact of Party, Personality, and Policy on Voting Outcomes\nHeretofore, we showed that the factors of party, personality, and policy out-\nlined in The American Voter can be tracked in social media using computational\nmethods, and that the output of these methods is directly interpretable in the con-\ntext of the ongoing presidential campaigns. However, to what extent do these signals\ncorrespond to the outcomes of electoral polls? To answer this question, by which we\nmay con\frm or discon\frm the validity of The American Voter 's framework in the\nsocial media-based electoral opinion modeling, we quantify the e\u000bect each factor has\n46\non electoral outcomes.\nUsing the methods described above, we build features for the factors of party,\npersonality, and policy:\n\u000f3 features for party (Democrat, Republican, Other),\n\u000f14 features for di\u000berent personality dimensions, which are separately computed\nfor presence and absence as well as for party a\u000eliations,\n\u000f11 features for di\u000berent policy categories, which are separately computed for\nparty a\u000eliations,\n\u000fraw tweet counts and sentiment-labeled tweet counts,\nin total resulting in 184 variables available to regress on poll numbers. Since a large\nnumber of polling organizations conduct polls at di\u000berent time intervals, we rely on\nthe RealClearPolitics (RCP) [9] aggregation of reputed national polls. Speci\fcally,\nwe use RCP's daily average of national polls for all presidential candidates.\nFirst, we preprocess this set of 184 variables for use in regression analysis. We\nlog-transform all volumetric variables (tweet counts) to alleviate the skew. Also, many\nof the features are interdependent, making any model built with such variables su\u000ber\nfrom multi-collinearity. Thus, we use a stepwise selection process to eliminate features\nwith high VIF (Variance In\ration Factor) and AIC (Akaike Information Criterion)\nscores. The process results in 72 variables for the Democratic candidates and 61 for\nthe Republican candidates.\nDue to data scarcity, we are not able to separately run regressions for indi-\nvidual candidates (however such models would be very interesting for individualized\n47\nFeature \fStd. Error\nTweets from Republicans on Abortion 1.48 0.20\nTweets from Republicans on Veterans 1.33 0.3\nTweets on presence of Paci\fsm 1.30 0.17\nTweets from Democrats on Gay rights 1.18 0.24\nTweets from Republicans on Healthcare 1.05 0.28\nTweets on presence of Machiavellianism 0.85 0.19\nTweets from Democrats on Gun control 0.58 0.16\nTweets from Democrats on Abortion -0.96 0.18\nTweets from Democrats on Miscellaneous -1.14 0.23\nTweets from Republicans on Climate change -1.55 0.21\nTweets from Others on Veterans -1.65 0.30\nScore of presence of Achievement Drive -2.78 0.79\nTweets from Republicans on absence of Intellectual Brilliance -3.37 0.96\nTable 2.6: List of statistically signi\fcant variables ( p-value<0.001) in our regression\nmodel for Democratic candidates. The features are sorted in descending order with\nrespect to estimated coe\u000ecient values. Adjusted R2= 0.908\nanalysis). Instead, we train linear regression models on RCP's average national poll\nnumbers separately for Democratic and Republican candidates. We then rerun the re-\ngression on the subset of features with p-value<0.05. The \fnal model for Democratic\ncandidates has 24 variables and that for Republican candidates 28 variables.\nThe model for Democratic candidates (Clinton and Sanders), which uses the\n24 variables, explains 0.908 proportion of variance (adjusted R2= 0.908).2Table\n2.6 lists the subset of 13 variables with p-value<0.001. The model includes 4\npersonality-based variables and 9 policy-based variables, most of which have inte-\ngrated the party aspect. For personality, we note that tweets on presence of paci\fsm\nand machiavellianism have a positive impact on poll numbers. Interestingly, tweets\nfrom Republicans on absence of Intellectual Brilliance have a negative impact on poll\n2Note that the goal of our regression model here is descriptive. Therefore, we tolerate\nsome degree of over-\ftting to the data.\n48\nFeature \fStd. Error\nTweets from Others on Miscellaneous 1.35 0.21\nTweets from Others on Climate Change 1.27 0.21\nTweets on absence of Conservatism 1.17 0.22\nTweets from Republicans on Foreign policy 1.12 0.14\nTweets from Others on Gun control 1.10 0.17\nTweets from Republicans on Abortion 0.95 0.16\nTweets from Democrats on Gay rights 0.54 0.13\nTweets from Others on Foreign policy -0.58 0.16\nTweets on presence of Paci\fsm -1.07 0.15\nTweets on absence of Forcefulness -1.07 0.31\nTweets from Democrats on Gun control -1.09 0.21\nTweets from Democrats on Climate change -1.15 0.20\nTweets from Democrats on absence of Moderation -2.65 0.80\nTable 2.7: List of statistically signi\fcant variables ( p-value<0.001) in our regression\nmodel for Republican candidates. The features are sorted in descending order with\nrespect to estimated coe\u000ecient values. Adjusted R2= 0.883\nnumbers. For policy, the impact of party aspect is more obvious on policy-related\nvariables with four from each party. It is noteworthy that tweets from Republicans\non abortion have a positive impact, whereas tweets from Democrats on abortion have\na negative impact on poll numbers. Similarly, tweets from Republicans on veterans\nhave a positive impact whereas those from Others have a negative impact on poll\nnumbers of Clinton and Sanders.\nThe model for Republican candidates, which uses the 28 variables, explains\n0.883 proportion of variance (adjusted R2= 0.883). Table 2.7 lists the subset of 13\nvariables with p-value<0.001. The model also includes 4 personality-based variables\nand 9 policy-based variables, most of which have integrated the party aspect. For\npersonality, we note that tweets on absence of conservatism has the most positive\nimpact on poll numbers, re\recting the preference for political outsiders. In contrast,\ntweets on presence of paci\fsm as well as on absence of forcefulness have a negative\n49\nimpact. It is interesting to note that tweets from Democrats on absence of moderation\nhas the most negative impact on poll numbers. For policy, we note that tweets from\nOthers on climate change and gun control have a positive impact, whereas those\nfrom Democrats have a negative impact on poll numbers. Moreover, tweets from\nRepublicans on foreign policy have a positive impact, whereas those from Others\nhave a negative impact on poll numbers.\nThe comparison of these models for both parties reveals several key similari-\nties and di\u000berences. Among the most signi\fcant variables with p-value<0.001, both\nmodels include 4 personality-based variables and 9 policy-based variables. Further-\nmore, both models include policy-based variables about abortion, gay rights, gun\ncontrol, and climate change. The interesting di\u000berences between these models are re-\nlated to the sign of variable coe\u000ecients. For example, tweets on presence of paci\fsm\nhave a positive impact ( \f= 1:30) on poll numbers of Democratic candidates while\nthey have a negative impact ( \f=\u00001:07) on poll numbers of Republican candidates.\nSimilarly, tweets from Democrats on gun control have a positive impact ( \f= 0:58) on\npoll number of Democratic candidates while they have a negative impact ( \f=\u00001:09)\non poll numbers of Republican candidates.\n2.2.7 Discussion\nIn our exploration of The American Voter factors on Twitter, we \fnd that\nall three factors still play an important role in the electoral discourse. The interplay\nbetween these factors is especially fruitful for further analysis and validation of estab-\n50\nlished political theories. For instance, in Figure 2.7 we plot the proportion of tweets\nfrom users of di\u000berent political a\u000eliations about personality dimensions of the two\neventual nominees { Clinton (above) and Trump (below). We can see that the per-\nsonality dimension of moderation is much more emphasized for Clinton, however it is\nonly the Other (perhaps more independent) and Republican users who emphasize her\npaci\fsm (which includes keywords such as weak ). Further, only users marked to be\nRepublican emphasize Trump's conservatism, whereas the Other group - potentially\nthe independent vote - not at all.\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf0.0000.0010.0020.0030.0040.005 \u25cfDemocrats\nRepublican\nOther\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf0.0000 0.0015\nModeration \nFriendliness \nIntellectual Brilliance\nMachiavellianism\nPoise and Polish\nAchievement Drive\nForcefulness\nWit   \nAttractiveness\nPettiness \nTidiness \nConservatism\nInflexibility \nPacificism \nFigure 2.7: Proportion of tweet volume about personality dimensions of Clinton\n(above) and Trump (below) from users identi\fed as Democrats (blue circles), Re-\npublican (red squares), and Other (grey triangles).\n51\nFurther examining partisanship, we were able to identify 572,316 and 893,048\nof the 11 million users as Republican leaning and Democrat leaning respectively.\nAlthough the seed list used in our approach limits the reach of our classi\fcation,\nthe Twitter conversation is dominated by a vast majority that is not following these\nestablished opinion leaders. Even among those we detected as interested in partisan\nopinion leaders, we observed considerable crosstalk about other party's candidates.\nHowever, when combined with the overall negative tone, this possibly indicates the\npresence of partisanship for those already aligned with a party, as found, for example\nby [17].\nMoreover, our study corroborates \fndings reported in prior literature and also\nhighlights some new trends. For example, Benoit [40] reported that Republicans em-\nphasized more on personality traits like `sincerity' while Democrats emphasized more\non `drive'. In corroboration, we also \fnd that Republicans discuss the personality\ndimension of machiavellianism (which includes sincere trait) more than Democrats,\nwho discuss the personality dimension of achievement drive more than Republicans.\nBenoit [40] also reported that Democrats focus more on policy issues such as edu-\ncation while Republicans focus more on national security. Our analysis shows that\nDemocrats not only discuss education more than Republicans, but also issues such as\ngay rights and climate change. On the other hand, Republicans discuss policy issues\nsuch abortion and veterans more than Democrats.\nMethods presented in this work were able to uncover more than 6 million\npolicy-related tweets and 316 thousand personality-related tweets, but we caution the\n52\nreader not to focus on raw volumes, as they depend on the sensitivity of the lexicons\nused wherein. Instead, cross-policy and cross-personality trait analyses would present\nmore insight, as presented in this work. The crafting of more accurate and up-to-date\nlexicons is a task involving subject-matter experts, and thus can be only partially\nautomated, however attempts have recently been made to automatically augment\nlexicons, such as in crisis situations [149].\n2.2.8 Summary\nThe multi-factor framework of The American Voter brings a structure to the\nrich political discourse on social media. Our use of computational methods allows the\nevolution from survey-based electoral research to encompass the automated analysis\nof new rich sources of user-generated media. Our \fndings reveal the partisan divides\nin the perceptions of policy positions and personality traits of the presidential candi-\ndates. Further, using statistical analysis of party ,personality , and policy factors we\nshow the importance of each one in the modeling of electoral deliberation.\nNo social media study would be complete without the standard cautionary\nstatement that social media analysis is not meant to replace the traditional survey\ntechniques, having neither comparable participant sampling, nor the a\u000bordances of a\n(sometimes long-form) survey. However, the fact that political \fgures are increasingly\nusing Twitter to reach their supporters indicates its increasing importance, at least\nin the eyes of the politicians themselves. This study establishes a baseline from which\nthe views of the candidates can be studied, views which we fully expect to change\n53\nnot only in this election cycle but also in future elections.\n54\nCHAPTER 3\nUNDERSTANDING THE ROLES OF ALGORITHMS IN POLITICAL\nPOLARIZATION\n3.1 Background, Motivation, and Research Statement\nResearchers have long been concerned about the e\u000bect of selective exposure|\nseeking information that reinforces preexisting beliefs while avoiding other information|\non democratic societies [183, 210]. Through selective exposure, people with racial and\npolitical biases seek out content that conforms with their preexisting beliefs. For ex-\nample, selective exposure to conservative news is associated with support for strict\nimmigration policies [211], and people who score high on a scale of modern racism\nare more likely to view non-traditional Internet sources as credible sources of news\n[140].\nMore recently, researchers have started to question whether algorithms create\ndistinct personalized experiences for users, leading to so-called \\\flter bubbles\" or\n\\echo chambers\" [108, 151, 33]. Algorithms re\rect the societies in which they are\nproduced, so it is unsurprising that they are encoded with racial and political biases\n[77]. For example, personalization algorithms have been found to discriminate against\nwomen [67] and people of color [147].\nWhile selective exposure requires deliberate acts of media choice, algorithmic\npersonalization interprets past behavior as precedent for future preference. In other\nwords, algorithmic personalization can intensify selective exposure beyond a person's\nchoice, resulting in a vicious cycle that can contribute to an increasingly polarized\n55\nsociety. According to Pew Research, Americans are more ideologically polarized now\nthan at any point in the last two decades [53]. This increase in polarization coincides\nwith the rise of search engines and social media sites as primary sources of information.\nThus, it is important to study the role of personalization algorithms employed by\nsearch engines and social media sites in reinforcing pre-existing biases.\nPrior research has reported signi\fcant personalization in online advertising\nbased on a user's browsing history. Personalization in online advertising [34, 198, 67,\n176] is not surprising because behavioral targeting is its key design feature. To target\nads, advertisers employ sophisticated online tracking techniques for pro\fling users'\nbrowsing habits across the Web [72]. Naturally, we would expect search engines to\nleverage browsing history information obtained by online tracking for search person-\nalization as well. However, prior studies [203, 91, 116] have reported signi\fcant search\npersonalization mainly based on location, not browsing history.\nIn fact, when a person looks up information on a search engine, the search\ndoes not occur in a vacuum. Before any particular search is made, the person has\nalready lived an active digital life|reading news stories, liking pages on online social\nmedia, and posting comments on blogs|activities that are tracked across the Web to\ntrain personalization algorithms. In the current divisive political climate [53], people\nmight be more likely to access content online that conforms to their political ideolo-\ngies, but little is known about whether accessing certain political content impacts\npersonalization of other elements of a person's online life. Set in this context, we\nask: If a person's digital life demonstrates a political bias, does that person receive\n56\npersonalized search results and do those search results re\rect that person's bias?\nThus, in this research we would like to study search personalization in Google\nNews using a \\sock puppet\" auditing system [166] in which we use computer programs\nto impersonate users with di\u000berent political ideologies. Our results show that Google\ncan infer browsing histories of our trained pro\fles through its pervasive online tracking\nnetwork and can leverage it to personalize search results based on recent changes in\nits privacy policy [6, 27]. To the best of our knowledge, this work presents the \frst\nempirical evidence of political personalization on Google News based on browsing\nhistory. The results not only set the baseline for search personalization based on\npolitical biases in browsing history, but also contribute to the broader understanding\nof selective exposure and algorithmic personalization.\n3.2 Related Work\nA long line of research has looked at web search personalization. Hannak\net al. [91] examined several features such as browser user-agent, user's ethnicity,\nbrowsing history, and search query that Google can use to personalize search results.\nHowever, they only found signi\fcant personalization based on Google account login\nstatus and IP geolocation. In a follow-up [92], the author extended this study to Bing\nand DuckDuckGo. They found that, on average, 15.8% search results on Bing are\ndi\u000berent due to personalization based on the same features as on Google. They found\nno signi\fcant personalization on DuckDuckGo.\nTo further examine the role of location in triggering personalization, Xing\n57\net al. [203] used a browser extension called Bobble and recon\frmed that a user's\nlocation (inferred by geolocating IP addresses) is the most dominant trigger factor for\npersonalization. Furthermore, Kliman-Silver et al. [116] examined the relationship\nbetween distance and location-based personalization, and the impact of location-\nbased personalization on di\u000berent types of queries. They found that the di\u000berences\nbetween search results grow as the physical distance between locations of the users\nincreases.\nPuschmann [155, 156] analyzed crowdsourced Google search results from ap-\nproximately 4,000 users for 16 terms related to German political parties and candi-\ndates [13]. He found that search results are personalized primarily based on location,\nlanguage, and time. He concluded that a small fraction of personalized search results,\nwhich could not be explained based on the aforementioned factors, may be trigged\nby latent (or non-observable) factors such as browsing history and Google account\ninformation that they did not collect from users.\nRobertson et al. [161] audited personalization on Google Search by asking\ncrowd workers to install a browser extension which collected Google search results\nfor a variety of political search queries in standard and incognito modes. They found\nsigni\fcant personalization based on Google account login status, self-reported usage\nof Google/Alphabet services such as YouTube, and self-reported rating of Trump but\nnot self-reported political party a\u000eliation. In a follow-up [160], the authors reported\nthat personalized search results have minimal di\u000berences in terms of political bias.\nIn short, prior research has found Google search personalization primarily due\n58\nto geolocation and account login status. In contrast to prior work, we believe that\nour sock puppet auditing system can help reveal the impact of browsing histories,\nwhich are explicitly designed to re\rect di\u000berent political ideologies, on search person-\nalization.\n3.3 Methodology\nBuilding on existing research focused on tracking and personalization, the\noverarching goal of our study is to examine the extent to which a user's web browsing\nhistory a\u000bects algorithmic personalization in web search. We seek to understand both\nwhether algorithmic personalization exists and whether it reinforces or dampens the\npreferences displayed in web browsing history. To this end, we design and implement\na sock puppet auditing system to train fresh browser pro\fles by visiting hyperlinks\nthat embody distinct political discourses and then compare Google News search re-\nsults for identical politically oriented search terms. Figure 3.1 depicts the four main\ncomponents of our system that are discussed below.\nanti-immigration\n@wginfonetorg Crawling \nTwitter\nTimelinesBrowser \nProfile\nTraining Searching \nGoogle Newshyperlinks\nbrowsing historysearch terms\ne.g. illegal immigrants\nsearch \nresults\n pro-immigration\n@DefineAmerican\nQuantifying \nPersonalization\nQuantifying \nBias\nFigure 3.1: Our sock puppet auditing system to measure political personalization of\nGoogle News search.\n59\n3.3.1 Identifying Pro- and Anti-immigration Hyperlinks\nWe aim to evaluate Google News personalization based on browsing histories\nthat re\rect di\u000berent stances on the topic of immigration. We focus on immigra-\ntion because it was a key campaign issue in the recent 2016 U.S. presidential election\n[26, 122]. Our goal was to \fnd a list of websites that re\rect pro- and anti-immigration\nstances in the context of U.S. politics. To this end, we rely on two popular Twitter ac-\ncounts that re\rect both discourse communities. Discourse communities are groups of\npeople that come together, whether physically or virtually, for the purpose of building\ncommunity through shared goals and forms of speech [185]. For the anti-immigration\nstance, we use @wginfonetorg, which belongs to a popular anti-immigrant website\nwhitegenocide.info that is dedicated to \\\fghting the crime of white genocide.\" For\nthe pro-immigration stance, we use @De\fneAmerican, which belongs to a popular\npro-immigrant website defineamerican.com that is dedicated to \\shift the conver-\nsation about immigrants, identity, and citizenship in a changing America.\" Both of\nthese Twitter accounts are very active and fairly popular. As listed in Table 3.1,\n@wginfonetorg has posted more than 63K tweets and has 9.4K followers while @De-\n\fneAmerican has posted more than 17K tweets and has 30.3K followers. Because\nboth accounts frequently share content from other websites that support their re-\nspective views on immigration, we collected the hyperlinks posted on the timelines of\nthese Twitter accounts over the duration of two weeks in March 2017. We treat these\ntwo sets of hyperlinks as representations of pro- and anti-immigration discourses.\n60\nScreen Name Favorites Followers Followings Tweets Account Creation\n@De\fneAmerican 10,043 30,253 1,776 17,350 May 2011\n@wginfonetorg 1,253 9,424 223 63,916 April 2014\nTable 3.1: Statistics of pro-immigration and anti-immigration Twitter accounts.\n3.3.2 Training Browser Pro\fles\nUsing the two sets of hyperlinks collected from pro- and anti-immigration\nTwitter accounts, we now train fresh browser pro\fles. Speci\fcally, to train the pro-\nimmigration browser pro\fle, we install a fresh copy of Firefox web browser and open\nhyperlinks from the timeline of the pro-immigration Twitter account. Similarly, to\ntrain the anti-immigration browser pro\fle, we install a fresh copy of Firefox web\nbrowser and open hyperlinks from the timeline of the anti-immigration Twitter ac-\ncount. We take several steps to imitate a real user during browser pro\fle training.\nFirst, we limit the number of hyperlinks that we use for training per day to 50. To this\nend, we randomly sample a subset of 50 hyperlinks from the hyperlinks posted on the\ntimelines of both Twitter accounts. Second, we add a random delay averaged at \fve\nminutes between opening consecutive hyperlinks during training. Finally, we conduct\nthe training between 9 am and 11 pm local time to re\rect diurnal user activity.\nIt is noteworthy that we do not create or log-in to a Firefox account during\ntraining because it can save bookmarks, passwords, browsing history, and cookie\ninformation. We also do not create or log-in to a Google account that may be used\nby Google to link our account information with browsing history. Therefore, the only\nway for Google to know about our browsing history during training would be via\n61\nthird-party tracking using its own advertising/analytics network (e.g., DoubleClick\nand Google Analytics) via cookies or browser \fngerprinting. As discussed in related\nwork, prior research has reported on the extensive third-party tracking capabilities of\nGoogle.\nOur analysis of the set of hyperlinks used for training browser pro\fles shows\nthat pro-immigration training hyperlinks belong to more mainstream news outlets\nsuch as Washington Post while anti-immigration training hyperlinks belong to more\nalternative news sites such as Breitbart and user-generated content sites such as\nYouTube and WordPress (Figure 3.2). We \fnd that several Google owned domains\nare top third-parties on these training hyperlinks. Figure 3.3 plots the popularity\ndistribution of third-party domains on the pro- and anti-immigration training hyper-\nlink sets. More speci\fcally, doubleclick.net is the top third-party tracker on both\nanti- and pro-immigration training hyperlink sets. Thus, we conclude that Google is\nable to learn the browsing histories of our trained pro- and anti-immigration browser\npro\fles and canlater use it for personalization of search results.\n3.3.3 Searching Google News\nAfter training fresh browser pro\fles using hyperlinks crawled from pro- and\nanti-immigration Twitter accounts, we are set to conduct Google News searches.\nWe are interested in testing if web browsing histories that re\rect these divergent\ndiscourses would result in search personalization along politically partisan lines.1\n1Note that the extreme anti-immigration position of those concerned about white geno-\ncide are not wholly aligned with the Republican Party's nor are the political views of our\n62\n     washingtonpost.com\nvox.com\nhuffingtonpost.com\nlatimes.com\nvice.com\nbuzzfeed.com\ncnn.com\nmijente.net\nthefederalist.com\nglaad.org05101520Percentage (%)\n(a) Pro-immigration\nyoutube.com\nwordpress.com\nbreitbart.com\nnarrative-collapse.com\nnewobserveronline.com\ngatesofvienna.net\nnumbersusa.com\nsouthafricatoday.net\nfreebeacon.com\nredice.tv05101520Percentage (%) (b) Anti-immigration\nFigure 3.2: Top-10 \frst-party domains for hyperlinks crawled from pro- and anti-\nimmigration Twitter accounts.\nIn other words, we want to test whether a user who consistently consumes anti-\nimmigration content would receive more or less Republican-leaning news stories in\nthe search results. We execute searches from three sets of browser pro\fles: (1) pro-\nimmigration, (2) anti-immigration, and (3) control. The control browser pro\fle, which\nis not trained (i.e., by visiting hyperlinks), provides us a \\neutral\" perspective to\njudge whether personalization occurs for pro- and/or anti-immigration pro\fles. We\nexecute Google News searches using di\u000berent search terms about a wide variety of\npro-immigration pro\fle identical to the Democratic Party platform. These two pro\fles are\nnot equally polarized even in terms of immigration position. In fact, after our experiment\nis \fnished, we discover that the anti-immigration pro\fle was suspended since it violated\nTwitter rules by involving into extremely hateful speeches.\n63\ndoubleclick.net\nfacebook.com\ngooglesyndication.com\nscorecardresearch.com\nmoatads.com\nchartbeat.net\ngoogle.com\nadnxs.com\ngoogleapis.com\nopenx.net\nadvertising.com\ncasalemedia.com\ndemdex.net\nquantserve.com\ngoogle-analytics.com\nkrxd.net\nadsrvr.org\nrlcdn.com\nrubiconproject.com\nagkn.com\nimrworldwide.com\n2mdn.net\namazon-adsystem.com\nyahoo.com\ncloudfront.net\ncrwdcntrl.net\nbluekai.com\nnexac.com\nmathtag.com\ngstatic.com020406080100% First-Parties\n(a) Pro-immigration\ndoubleclick.net\nfacebook.com\ngoogle-analytics.com\ngoogleapis.com\ngoogle.com\nyoutube.com\nscorecardresearch.com\ngooglesyndication.com\nadnxs.com\ngstatic.com\ncrwdcntrl.net\nadvertising.com\ndisqus.com\ntaboola.com\ncloudfront.net\namazonaws.com\naddthis.com\nrlcdn.com\ngravatar.com\nyahoo.com\nquantserve.com\nytimg.com\nbluekai.com\nadsrvr.org\ntwitter.com\nwp.com\nexelator.com\nfacebook.net\nbidswitch.net\npinterest.com020406080100% First-Parties\n(b) Anti-immigration\nFigure 3.3: Top-30 third-party domains identi\fed on the hyperlinks crawled from pro-\nand anti-immigration Twitter accounts.\npolitical topics. We decide to search for news related to the top-10 most discussed\npolicy issues on Twitter [122] during the 2016 U.S. presidential election campaign.\nWe use \fve di\u000berent search terms for each of these policy issues: Immigration, Foreign\n64\nPolicy, Healthcare, Economy, Abortion, Gay Rights, Gun Control, Climate Change,\nEducation, and Veterans. For each search term, we repeat the search process every\nday over the duration of one week.\nTo ensure that the search results returned by Google are not impacted by\nanything other than the browsing histories, our search process is designed as fol-\nlows. First, we use Selenium WebDriver [3] to automatically conduct searches using\nthe Google News web interface instead of Google's search API. We con\fgure Google\nNews to return up to 100 search results. Second, we use a wait period of 11 minutes\nbetween consecutive searches to eliminate any carry-over e\u000bect [91]. Third, we con-\nduct searches from pro-immigration, anti-immigration, and control browser pro\fles in\na synchronized fashion to eliminate any temporal e\u000bects. Fourth, each browser pro\fle\nconducts search queries on a separate Amazon EC2 cloud instance to avoid any inter-\ndependencies between di\u000berent pro\fles.2Fifth, we use a static DNS entry for Google\nNews to ensure that our search queries are routed to the same datacenter. Finally,\nto eliminate potential noise in search results due to A/B testing [150], we train four\nseparate pro\fles for pro-immigration, anti-immigration, and control browser pro\fles.\nIn the absence of A/B testing, we would expect the same search results for these four\npro\fles. When there is A/B testing, we can mitigate its e\u000bect by eliminating search\nresult di\u000berences. To this end, we compute the pairwise intersection of search results\namong the four pro\fles. We then use search results from a randomly selected pro\fle\n2Note that while each Amazon cloud instance has a di\u000berent IP address, they are all\nbelong to the same /24 IP pre\fx range geolocated in Oregon. Therefore, we do not expect\nany IP geolocation based search personalization as has been reported in prior work [91, 116].\n65\nfrom the pair with the maximum intersection.\n3.3.4 Quantifying Search Personalization\nWe use trained browser pro\fles for both pro- and anti-immigration stances\nas well as a control browser pro\fle to execute Google News searches. We can quan-\ntify personalization by comparing the presence and ranking of search results across\ndi\u000berent browser pro\fles. First, we quantify personalization simply in terms of the\ndi\u000berences in search results. Let PandArespectively denote the lists of search results\nfor the pro- and anti-immigration browser pro\fles. Let Cdenote the list of search re-\nsults for the control browser pro\fle. We can measure the di\u000berences in search results\nby comparing P,A, andCin a pairwise manner. To this end, let P\u0000Arepresent the\nset of unique search results for the pro-immigration pro\fle that do not appear for the\nanti-immigration pro\fle. Let P\u0000CandA\u0000Crespectively represent the set of unique\nsearch results for the pro-immigration and anti-immigration pro\fles with respect to\nthe control. We use jP\u0000Aj,jP\u0000Cj, andjA\u0000Cjto quantify the di\u000berences in search\nresults in the range of [0%,100%], where 0% indicates no personalized search results\nand 100% indicates all 100 search results are personalized. Note that since we get\n100 search results for each search term, we have jPj=jAj= 100. In this case, the\ndi\u000berence in search results is symmetric in terms of quantities (i.e. jP\u0000Aj=jA\u0000Pj)\nalthough it may be not be symmetric as the set (i.e. P\u0000A6=A\u0000P). Second, we\nquantify personalization while taking into account the ranking of search results across\ndi\u000berent browser pro\fles. To this end, we measure edit distance among P,A, and\n66\nCin a pairwise manner. Speci\fcally, we compute the Damerau-Levenshtein distance\n[66] which represents the number of deletions, insertions, or substitutions needed to\nmake a pair of lists identical. If two lists are identical, the edit distance is 0. The\ngreater the edit distance, the more di\u000berent the lists are in terms of their membership\nand ordering. Note that both the di\u000berence and edit distance are calculated based\non search results as URLs and we do not consider title or text of these URLs.\nIn addition to quantifying personalization, we also analyze whether personal-\nized search results re\rect political bias. To assess political bias, we prefer automatic\nmethods over manual coding because the latter are expensive and time consuming.\nThus, we \frst try to use methods in prior literature [120, 119] that can automatically\nmeasure political bias of URLs by analyzing their sharing patterns on Twitter. Since\nthese methods require a large number of tweets containing the news URLs, we cannot\nuse them because very few of the personalized search results (URLs) are frequently\ntweeted. Therefore, we use mediabiasfactcheck.com which provides the political bias\nof 1,540 media sources (identi\fed as domains) on a 5-point scale: left, left-center,\ncenter, right-center, and right [15]. For further quanti\fcation, we convert this 5-point\nscale to speci\fc scores as: left = -100, left-center = -50, center = 0, right-center =\n50, and right = 100. Note that mediabiasfactcheck.com provides the political bias for\ndomains (e.g., nytimes.com) not URLs. Since we cannot automatically measure the\npolitical bias of personalized news URLs, we estimate their political bias using their\ndomain's political bias from mediabiasfactcheck.com.\n67\n3.4 Evaluation\nTable 3.2 reports the personalization results quanti\fed as pairwise di\u000berence\nand edit distance across pro-immigration ( P), anti-immigration ( A), and control ( C)\npro\fles. In terms of di\u000berence, although it varies across di\u000berent search terms, the\naverage di\u000berence between pro-immigration and anti-immigration ( P\u0000A) is 3.2%,\nbetween pro-immigration and control ( P\u0000C) is 3.9%, and between anti-immigration\nand control ( A\u0000C) is 3.8%. Using the standard t-test, we are able to conclude that\nthese average di\u000berences are signi\fcantly di\u000berent from zero at 0 :0001 signi\fcance\nlevel. The average edit distance between pro-immigration and anti-immigration is\n8.4, between pro-immigration and control is 10.3, and between anti-immigration and\ncontrol is 10.3. Using the standard t-test, we are again able to conclude that these\nedit distances are signi\fcantly di\u000berent from zero at 0 :0001 signi\fcance level. The\nedit distance values are higher than the di\u000berence because edit distance not only\nconsiders the di\u000berence in two lists of search results but also the changes in relative\nrankings of the search results. Since di\u000berence and edit distance show the same trend\nin personalization across di\u000berent search terms, we focus on the di\u000berence metric for\ndiscussion in the rest of this section.\nTo analyze personalization across di\u000berent search terms, we sort search terms\nin Table 3.2 in descending order of P\u0000Avalues for each policy category. We focus\nour attention on search terms for which P\u0000Aaverage di\u000berence exceeds 5%. We \fnd\nthat a total of nine search terms meet this criterion: (1) comprehensive immigration\nreform, (2) uninsured Americans, (3) Medicare for all, (4) national debt, (5) \rat tax,\n68\nPolicies Search TermsDi\u000berence (%) Edit Distance\nP\u0000AP\u0000CA\u0000CE(P;A)E(P;C)E(A;C)\nImmigrationComprehensive immigration reform 6.3 18.2 13.5 14.7 38.5 26.5\nWhite nationalism 4.3 4.2 2.7 8.5 8.7 7.2\nDream Act 3.0 5.8 4.0 6.7 15.8 11.5\nAnchor babies 2.5 4.3 6.8 5.8 14.2 20.0\nIllegal immigrants 1.2 2.3 1.2 5.7 14.2 9.2\nForeign PolicyISIS 1.7 0.8 1.8 4.3 2.3 5.3\nBenghazi 1.3 5.7 6.0 4.8 13 15.8\nSyria war 1.0 1.2 1.0 3.0 2.7 3.3\nIran deal 0.5 0.5 0.3 0.8 1.0 0.5\nAleppo 0.0 0.2 0.2 0.0 0.2 0.2\nHealthcareuninsured Americans 7.2 11.3 10.5 15.7 24.2 22.5\nMedicare for all 6.2 10.0 4.8 16.2 26.0 11.5\nHealth insurance 4.3 2.0 3.0 15.3 7.2 9.5\nA\u000bordable Care Act 2.7 5.0 6.8 8.2 17.8 24.5\nObamacare 0.3 4.3 4.3 0.7 14.5 14.7\nEconomyNational debt 12.0 16.5 12.2 27.3 39.5 30.7\nFlat tax 6.7 6.2 1.0 13.0 12.0 2.0\nNAFTA 2.8 3.3 6.0 7.0 10.8 17.3\nWall street 2.8 0.3 2.5 6.8 0.7 6.2\nFederal budget 1.5 1.3 0.7 10.2 8.2 5.0\nAbortionPro-life 5.7 2.3 4.0 19.3 7.3 13.3\nPlanned parenthood 3.5 7.0 5.3 9.0 14.3 13.0\nRoe v. Wade 2.8 2.2 4.3 7.0 5.8 11.8\nPro-choice 1.7 3.0 4.0 4.8 6.7 10.7\nWomen's rights 0.5 2.8 2.8 2.0 16.0 16.2\nGay RightsLGBT 4.3 3.2 7.0 14.5 7.7 21.2\nTraditional marriage 4.2 2.8 2.8 9.7 6.2 6.0\nGay couple 3.8 3.3 4.3 10.2 8.0 11.7\nMarriage equality 3.0 2.8 4.3 8.2 7.2 11.8\nSame-sex marriage 2.0 1.8 1.7 5.0 4.7 3.5\nGun ControlGun license 4.3 2.2 5.7 10.8 5.0 14.3\nBackground checks 4.3 2.2 2.8 13.8 6.7 8.2\nNRA 3.0 0.3 3.0 8.8 0.7 8.7\nGun control 2.2 3.8 2.3 5.2 9.8 6.8\nGun accessibility 0.7 0.5 0.2 5.8 3.2 2.7\nClimate ChangeParis climate agreement 7.2 7.2 8.8 14.2 14.2 15.7\nCarbon footprint 5.2 5.3 3.0 11.8 12.3 5.8\nClimate debate 4.5 3.0 2.3 13.8 8.7 7.0\nGreenhouse gases 2.2 2.2 8.8 5.0 4.7 16.0\nGlobal warming 0.2 2.8 2.7 0.3 11.5 11.2\nEducationNo Child Left Behind 5.0 4.7 0.8 9.3 8.5 1.5\nDepartment of Education 3.3 2.7 1.5 12.2 9.7 6.8\nCollege a\u000bordability 2.8 3.0 0.2 10.3 10.2 0.7\nRace to the Top 1.0 1.8 2.3 3.8 6.5 9.2\nFree community college 0.3 2.7 2.8 0.7 6.0 6.3\nVeteranssupport our veterans 7.2 5.8 5.5 15.5 13.2 12.7\nVeterans a\u000bairs 3.5 3.7 1.3 9.7 11 3.7\nVeterans 1.2 1.3 1.3 3.7 3.7 4.5\nVeteran bene\fts 0.8 1.2 1.2 1.7 3.0 3.0\nPTSD 0.5 3.3 3.2 0.8 8.7 8.2\nAverage 3.2 3.9 3.8 8.4 10.3 10.3\nTable 3.2: Personalization (quanti\fed using di\u000berence and edit distance) for 50 search\nterms. Note that E(P;A),E(P;C), andE(A;C) are pairwise edit distance among\npro-immigration, anti-immigration, and control pro\fles.\n69\n(6) pro-life, (7) Paris climate agreement, (8) carbon footprint, and (9) support our\nveterans.\nThe comparison of pro-immigration versus anti-immigration and control pro-\n\fles for these search terms reveals interesting insights. First, we observe that \fve of\nthem (comprehensive immigration reform, uninsured Americans, national debt, Paris\nclimate agreement, and support our veterans) also have high P\u0000CandA\u0000Cdif-\nferences. For example, national debt search term has 12.0% P\u0000Adi\u000berence, 16.5%\nP\u0000Cdi\u000berence, and 12.2% A\u0000Cdi\u000berence. This shows that both pro- and anti-\nimmigration pro\fles receive personalized search results that are di\u000berent from each\nother as well as di\u000berent from the control. Second, we observe that three of them\n(\rat tax, medicare for all, and carbon footprint) have high P\u0000Cdi\u000berence but low\nA\u0000Cdi\u000berence. For example, \rat tax search term has 6.7% P\u0000Adi\u000berence, 6.2%\nP\u0000Cdi\u000berence, and 1.0% A\u0000Cdi\u000berence. This shows that the pro-immigration\npro\fle receives personalized search results that are di\u000berent from both the control\nand anti-immigration pro\fle. Third, we observe that only one of them (pro-life) has\na highA\u0000Cdi\u000berence but low P\u0000Cdi\u000berence. Speci\fcally, pro-life search term\nhas 5.7%P\u0000Adi\u000berence, 2.3% P\u0000Cdi\u000berence, and 4.0% A\u0000Cdi\u000berence. This\nshows that the anti-immigration pro\fle receives personalized search results that are\ndi\u000berent from both the control and pro-immigration pro\fle.\nNote that there are search terms for which P\u0000Adi\u000berence is not high (e.g., <\n1.5%), but it does not necessarily mean that there is no personalization because their\ndi\u000berences to control (both P\u0000CandA\u0000C) may be high. This is because both\n70\nTop-k Search ResultsDi\u000berence (%) k-Edit Distance\nP\u0000AP\u0000CA\u0000CE(P;A)E(P;C)E(A;C)\nk = 10 2.3 2.4 2.7 5.7 5.7 6.7\nk = 20 2.2 2.4 2.5 6.4 6.3 7.4\nk = 30 2.4 2.5 2.7 6.6 7.3 8.0\nk = 40 2.6 2.9 3.0 7.1 8.3 8.7\nk = 50 2.7 3.2 3.1 7.5 8.9 9.1\nk = 60 3.0 3.4 3.3 7.9 9.4 9.5\nk = 70 3.2 3.7 3.6 8.3 9.9 9.9\nk = 80 3.2 3.8 3.7 8.5 10.1 10.2\nk = 90 3.3 3.8 3.7 8.6 10.2 10.2\nk = 100 3.2 3.9 3.8 8.4 10.3 10.3\nTable 3.3: Average personalization for all 50 search terms according to top-k (k 2\nf10,20,...,100g) ranked search results. We normalize edit distance (as k-edit distance)\nto make a fair comparison across di\u000berent k values.\npro- and anti-immigration pro\fles receive similar personalized search results with\nrespect to the control so they are not much di\u000berent from each other. For example,\nBenghazi search term has only 1.3% P\u0000Adi\u000berence, but 5.7% P\u0000Cdi\u000berence and\n6.0%A\u0000Cdi\u000berence. We also note that minor changes in queries can trigger big\ndi\u000berences among search results. For example, veterans a\u000bairs search term has 3.5%\nP\u0000Adi\u000berence that are about three times those of veterans and veteran bene\fts\nsearch terms, which are 1.2% and 0.8% respectively.\nNext, we study the rank of personalized search results to gauge whether they\ndisproportionately appear at the top or bottom of the list of results. Table 3.3 reports\nthe average personalization for all search terms based on the top-k (k 2f10,20,...,100g)\nsearch results. We note that average P\u0000Adi\u000berence started at 2.3% for k=10,\nslightly increases for increasingly k values, and reaches 3.2% for k=100. We observe\na similar trend for P\u0000CandA\u0000Cdi\u000berences as well as in terms of edit distance.\n71\nSearch TermsPolitical Bias\nB(P)B(A)B(P)\u0000B(A)\nCarbon footprint -30.0 10.0 -40.0\nComprehensive immigration reform -35.3 -3.1 -32.2\nParis climate agreement -23.3 -5.9 -17.4\nPro-life 36.1 52.8 -16.7\nSupport our veterans 14.3 25.0 -10.7\nUninsured Americans -18.8 -10.9 -7.9\nFlat tax -4.5 -13.3 8.8\nMedicare for all -27.8 -37.0 9.2\nNational debt 11.5 -6.5 18.0\nAverage -8.6 1.3 -9.9\nTable 3.4: Political bias for nine top-personalized search terms. Note that B(P),\nB(A), andB(P)\u0000B(A) respectively are political bias of personalized search results for\nthe pro-immigration and anti-immigration pro\fles, and the di\u000berence between their\npolitical bias. Table is sorted in ascending order of B(P)\u0000B(A) values. A negative\nB(P)\u0000B(A) value indicates the pro-immigration pro\fle received more Democratic-\nleaning personalized search results, while a positive B(P)\u0000B(A) value indicates the\npro-immigration pro\fle received more Republican-leaning personalized search results.\nNote that we normalize edit distance as k-edit distance (edit distance/k) for a fair\ncomparison across di\u000berent k values. Overall, while personalization slightly increases\nat bottom ranks, we conclude that personalization remains substantial for top ranked\nsearch results. Since personalization (in terms of both di\u000berence and edit distance)\nfor several search terms exceeds the average by multiple factors, we gather that there\nexists signi\fcant personalization even in top-10 search results.\nWe further analyze political bias of the personalized search results for the\nnine most personalized search terms in Table 3.23Using mediabiasfactcheck.com, we\n3In fact, we also analyze political bias of the personalized search results for all 41 re-\nmaining search terms. Using mediabiasfactcheck.com, we are able to estimate the political\nbias of 626 news stories out of 1,235 (51%) personalized results for these search terms.\n72\nare able to estimate the political bias of 373 news stories out of 792 (47%) person-\nalized results for these nine most personalized search terms. Table 3.4 reports the\naverage political bias of personalized search results for the pro- and anti-immigration\npro\fles, and the di\u000berence between their political bias averages. The average po-\nlitical bias of pro-immigration pro\fle is -8.6 which is Democratic-leaning and that\nof anti-immigration pro\fle is 1.3 which is Republican-leaning (negative values repre-\nsent Democratic-leaning and positive values represent Republican-leaning). In other\nwords, the pro-immigration pro\fle receives more Democratic-leaning personalized\nsearch results than that of the anti-immigration pro\fle. We use the Kolmogorov-\nSmirnov test [136] to compare the political bias distributions of personalized search\nresults for pro- and anti-immigration pro\fles. We are able to reject the null hypothesis\nthat both distributions are the same at the 0 :05 signi\fcance level. Thus, we conclude\nthat the search terms receiving most personalization tend to get personalized results\nthat reinforce the presumed partisanship. Note that political bias of personalized\nsearch results varies across di\u000berent search terms. Personalization reinforces the pre-\nsumed partisanship for six out of nine (carbon footprint, comprehensive immigration\nreform, Paris climate agreement, pro-life, support our veterans, and uninsured Amer-\nicans) search terms that received most personalization. For the remaining search\nterms, it counters the presumed partisanship.\nHowever, we \fnd that the di\u000berence is not signi\fcant between two pro\fles. Speci\fcally,\nthe average political bias of pro-immigration pro\fle is -5.45 while that of anti-immigration\npro\fle is -5.26. Thus, we note that further research is needed to better understand political\npersonalization on speci\fc topics.\n73\n3.5 Discussion\nWe are the \frst to report political personalization on Google News search\nbased on browsing history. The explanation of why we found evidence of signi\fcant\nweb search personalization while past work did not could be the combination of three\nfollowing reasons.\nFirst, our research is di\u000berent from prior work in terms of the methodology\nin training browser pro\fles. While previous work [91, 90] trained browser pro\fles to\nre\rect di\u000berent demographics, we trained browser pro\fles to re\rect di\u000berent political\nstances. Speci\fcally, both Hannak et al. [91] and Haim et al. [90] trained browser pro-\n\fles to represent di\u000berent demographic groups such as gender, age, income, lifestyle,\nand ethnicity. In contrast, we trained browser pro\fles to explicitly re\rect opposing\nviews on the topic of immigration rather than di\u000berent demographics. Speci\fcally,\nwe trained browser pro\fles using news stories posted by Twitter accounts who clearly\ndemonstrated distinct political stances on the topic of immigration.\nThe second reason could be the di\u000berence in search terms that were used to\ntest personalization. Prior literature reported that di\u000berent search terms can trigger\ndi\u000berent magnitudes of personalization [91, 119]. As compared to both Hannak et\nal. [91] and Haim et al. [90], which used search terms covering a variety of topics\npopular at the time, we used search terms related to the training topic of immigra-\ntion. Speci\fcally, [90] used general search terms such as \\Germany\". Hannak et.\nal. [91] used general search terms about topics such as news sources and literature.\nIn contrast, after training browser pro\fles re\recting opposing views on the topic of\n74\nimmigration, we used immigration-related search terms such as \\comprehensive im-\nmigration reform\" and \\illegal immigrants\". We also used search terms about other\nrelevant political topics [122] such as foreign policy.\nLast but not least, the changing nature of Google's personalization algorithm\ncould be another reason. Google is known to continuously tinker personalization al-\ngorithms as well as update their data sources over time. For example, Google changed\nits privacy policy in 2012 [6] and more recently in 2016 [27] allowing them to combine\nuser data collected across all of its services (e.g., Search, Gmail, Google Analytics,\nDoubleClick) for targeted advertising and content personalization. Thus, Google can\nnow more e\u000bectively personalize search results based on a user's browsing history\ninferred from its third-party analytics and tracking network. Since personalization\nalgorithms are continuously being tweaked, we plan to longitudinally study person-\nalization for di\u000berent search terms over an extended period of time as part of our\nfuture work.\nPrior work using controlled experiments [91, 90] as well as surveys of real\nusers [155, 156] has been unable to \fnd evidence of search personalization on Google\nNews based on browsing history. While simulating behaviors of real users completely\nwill always be impossible, controlled experiments enable us to isolate the e\u000bect of\nbrowsing history on search personalization. Thus, in this work, we studied search\npersonalization on Google News in a controlled setting by using browser pro\fles that\nwere trained to re\rect strongly divergent opinions on the topic of immigration. Using\nthis strategy, we \fnd evidence of signi\fcant search personalization on Google News.\n75\nThis \fnding creates an opportunity to conduct further research on other factors that\ncan trigger search personalization.\n3.6 Summary\nIn short, while controlling for other factors, we train a pair of fresh browser pro-\n\fles by visiting websites that re\rect pro-immigration and anti-immigration stances.\nWe then execute search queries on Google News related to a variety of political topics.\nWe analyze the search results to quantify the magnitude and direction of personal-\nization. While the magnitude and direction of personalization varies depending on\nthe search term, overall we are able to conclude that pro\fles trained by browsing\nwebsites re\recting distinct political positions indeed receive signi\fcant personaliza-\ntion that tends to reinforce the presumed partisanship. Our \fndings provide further\nempirical evidence for the underlying causes of \flter bubbles or echo chambers. Given\nthe heightened political tensions in the United States, search returns reinforcing peo-\nple's pre-existing biases could further insulate, rather than unite, individuals.\n76\nCHAPTER 4\nUNDERSTANDING THE ROLES OF CYBORGS IN POLITICAL\nPOLARIZATION\n4.1 Background, Motivation, and Research Statement\nSocial media usage in elections. Social media sites such as Twitter and Facebook\nhave played a signi\fcant role in elections across the world (e.g., U.S. [68, 122], Aus-\ntralia [48], Britain [28], India [18]). Social media sites are used by people to discuss\nelection campaigns as well as by politicians to directly reach out to the electorate.\nA recent survey by the Pew Research Center shows that two-thirds of U.S. social\nmedia users discuss political issues on these sites [70]. Moreover, about a quarter of\nU.S. adults directly relied on social media sites to keep up with the 2016 presidential\nelection campaigns of Donald Trump and Hillary Clinton [172].\nSocial media manipulation and countermeasures during elections. Unfor-\ntunately, the open nature of social media platforms also makes them susceptible to\nmanipulation. Prior research has extensively reported on the widespread nature of\nspam and other types of abuses in popular online social networks [86, 182, 187, 204]. It\nis perhaps unsurprising that social media sites have been targeted during elections be-\nyond \\vanilla\" spam. There were reports of social media misinformation campaigns\ntargeting various political candidates going as far back as the 2010 U.S. midterm\nelection [158]. There have also been numerous reports of widespread misinformation\ncampaigns during the 2016 U.S. presidential election [130, 42], including reports by\nthe O\u000ece of the Director of National Intelligence [105] and the Senate Intelligence\n77\nCommittee [16] concluding Russian state-sponsored misinformation campaigns. Pop-\nular social media sites such as Twitter [191] and Facebook [178] publicly acknowl-\nedged the exploitation of their platforms during the 2016 U.S. presidential election\nby state-sponsored attackers. They have since announced a number of \\cleanups\"\n[163, 191, 179, 73], which have resulted in suspension of millions of accounts [188, 107].\nAnalysis of social media manipulation during elections. There is signi\f-\ncant interest in understanding the countermeasures deployed by social media sites\nto counter spam and misinformation campaigns speci\fcally targeting elections. One\nline of research has speci\fcally focused on characterizing state-sponsored misinforma-\ntion campaigns during the 2016 U.S. presidential election. For example, researchers\nshowed that RU-IRA (Russian Internet Research Agency) Twitter accounts system-\natically manipulated political discourse [130], were able to reach a substantial number\nof Twitter users [206], and produced content that had a mostly conservative agenda\n[31]. Another line of research has more broadly focused on measuring the impact\nof countermeasures deployed by Twitter and Facebook. For example, researchers\nfound that popular Twitter accounts in aggregate lost over half a billion followers due\nto a recent Twitter \\purge,\" in which former president Obama lost about 2 million\nfollowers and president Trump lost about a half million followers [50].\nGaps in prior work. There are two main gaps in prior research that we hope to\naddress in this work. First, prior research studying social media manipulation dur-\ning the 2016 U.S. presidential election is mostly limited to analyzing a few thousand\nRussian or Iranian state-sponsored accounts publicly disclosed by social media oper-\n78\nators [206, 31, 29, 207]. We argue that social media manipulation during the 2016\nU.S. presidential election was likely more diverse and at a much bigger scale. Second,\nwhile prior research has studied the impact of new countermeasures deployed by so-\ncial media platforms, there is dearth of research on understanding the inner-working\nof these new countermeasures. We argue that better understanding the newly de-\nployed countermeasures can shed light into their potential blind spots and lead to\ndevelopment of more e\u000bective solutions.\nProposed research. To address the \frst limitation, we propose to retrospectively\nanalyze the activities of suspended Twitter accounts that engaged in political dis-\ncourse during the 2016 U.S. presidential election. We believe that a postmortem\nanalysis of targeted cleanups (identi\fed using suspended accounts) provides a valu-\nable ground truth that can be leveraged to study a wide variety of social media\nmanipulation during the 2016 U.S. presidential election at scale. To address the sec-\nond limitation, we propose to utilize two sets of suspended accounts (identi\fed about\na year apart) before and after Twitter announced new countermeasures against spam\n[163, 94] to analyze Twitter's new countermeasures. We believe that an examination\nof how the newly suspended accounts connect to the older suspended accounts can\nshed light on the inner-working of Twitter's countermeasures.\nIn this work, we identify nearly a million suspended Twitter accounts that en-\ngaged with the presidential election campaigns of Donald Trump and Hillary Clinton\nover the duration of four months leading up to the 2016 U.S. presidential election.\nThen, to systematically analyze the coordinated behavior of a million suspended ac-\n79\ncounts, we group them into di\u000berent communities based on their retweet and mention\nactivities. Next, in order to examine the characteristics of suspended communities, we\ntransfer measures for individual-level features into community-level features along \fve\ndimensions: dominant poster (responsible for posting most tweets), dominant retweet\ncontent producer (responsible for producing content for other users to retweet), bursti-\nness (temporal bumps of tweets), dominant domain (which was tweeted most fre-\nquently), and dominant hashtag (which was tweeted most frequently).\nKey \fndings. We summarize our key observations as follows:\n\u000fBy systematically comparing characteristics of suspended account communities\nversus regular (not suspended) communities, we \fnd di\u000berences across all \fve\nde\fned dimensions, but most signi\fcantly for the dominant poster and dom-\ninant hashtag dimensions. Through community-level analysis along di\u000berent\ndimensions, we hope to provide insights to social media platforms as well as\nthe broader research community for developing e\u000bective methods of detecting\nmalicious accounts based on their group-level activities.\n\u000fBy qualitatively analyzing suspended communities along di\u000berent dimensions,\nwe \fnd that each of the \fve proposed dimensions is useful in identifying het-\nerogeneous themes across suspended communities. We \fnd communities that\ncontain a large number accounts engaged in state-sponsored propaganda, those\nengaged in selling of political merchandise, as well as pornographic materials.\nThis demonstrates that our analysis of targeted cleanups by Twitter through\nsuspended accounts provided a general ground truth to study political spam\n80\nand misinformation campaigns during the 2016 U.S. presidential election.\n\u000fBy analyzing suspended accounts before and after Twitter's deployment of new\ncountermeasures, we \fnd that more than 90% of the newly suspended accounts\nhave direct connections to the communities of suspended accounts that were\ndetected earlier. Moreover, a large fraction of the newly suspended account\nretweet or mention the top retweet content producers of old suspended commu-\nnities. These \fndings suggest that Twitter's new countermeasures are targeting\naccounts that are linked to previously suspended accounts. It also suggests that\nour community based methodology may potentially be used to identify more\nusers that are possibly eligible for suspension.\n4.2 Related Work\nThere are a variety of works related to the 2016 U.S. presidential election\non multiple topics, such as policy discussion [164, 26, 122], political disinformation\n[130, 111, 21], Russian trolls [206, 31, 29] and bot activities [42, 31, 159]. Overall,\nthey have shown that the 2016 U.S. presidential election has been manipulated by\nstate-sponsored propaganda as well as distorted by rumors and social bots.\nIn our work, we focus on the topic of suspended accounts on Twitter. Although\nthis topic is limited to a very small dataset (e.g. Russian trolls) in election-related\nanalysis, it has received large attention from research communities in terms of spam\nand fake account detection [182, 187, 129, 123, 195]. One of the most similar works\nto ours is by Thomas et. al. [187], who analyzed Twitter suspended accounts as\n81\nspammers. The authors examined these accounts as a whole on a number of properties\nsuch as active duration, tweet rates, relationships, domain usage and compared to\nnon-spam accounts in some cases. However, unlike their work, since our dataset is\nwithin four months before the 2016 U.S. presidential election day and directly related\nto two main candidates Donald Trump and Hillary Clinton, we suspect there can be\ndi\u000berent themes causing user suspension other than spam. In fact, the suspended\npercentage in our data collection is 9.5%, nearly triple theirs (3.3%). Moreover, we\ngroup suspended users into communities and analyze their activity at the community\nlevel rather than as a whole.\nMore recently, Volkova et al. [195] built classi\fers to distinguish deleted and\nsuspended accounts from active ones in three di\u000berent languages. The authors found\nthat neural network models trained on text and network features produce the highest\nperformance for most of tasks, despite the fact that the network features they used\nare very simple (e.g. number of mentions). Thus, although our goal is not to pre-\ndict suspended accounts, by analyzing suspended communities we can provide more\ninsights for researchers to develop a more e\u000bective method of predicting suspended\naccounts based on their community activities.\n4.3 Methodology\n4.3.1 Data Collection\nDuring the 2016 U.S. presidential election, as a part of our previous studies\non political discourse [122, 121], we collected tweets around two major presidential\n82\ncandidates Clinton and Trump. Speci\fcally, we used Twitter's streaming API with\n\flter keywords as full names of candidates (e.g. \\hillary clinton\" for Clinton) to\ncollect tweets for each candidate. Since this API caps the tweets at 1% of all public\ntweets and there are more than 500 million tweets posted per day on Twitter [7], we\nare set to capture up to \fve million tweets per day for each candidate. However, since\nin our data collection the highest daily tweet count (for Trump) was less than two\nmillion, we were still able to capture the vast majority of tweets for both candidates.\nIn this work, we are interested in analyzing Twitter suspended accounts during\nthe 2016 U.S. presidential election. Thus, in February 2018, using Tweepy - a Python\nlibrary to access the Twitter API - we were able to examine how many accounts were\nsuspended in our previous tweet collection around Clinton and Trump. Speci\fcally,\nTwitter API returns the request of the user status with the response code of 63 if\nthe user was suspended. Table 4.1 shows the statistics of our data during nearly\nfour months, from June 01 to November 08, 2016 (except for most of August and\nsome individual days due to the crash in our collecting process). In total, there were\n912,979 accounts suspended out of 9,572,020 which made the suspended percentage\nto be 9.5% on average.\n4.3.2 Suspended Communities\nMotivated by the lack of using network activities in understanding user sus-\npension, we decide to analyze suspended accounts based on their retweeting and\nmentioning activities. We decide to use retweet and mention activities because of\n83\nUsersunique 9,572,020\nsuspended 912,979\nTweetsunique 90,652,722\nsuspended 9,218,751\nTable 4.1: Statistics of suspended users as of February 2018 in our tweet collection\naround Clinton and Trump during nearly four months, from June 01 to August 01 &\nfrom September 09 to November 08, 2016 (except September 18-20, October 31, and\nNovember 1).\ntheir representativeness for tweeting interactions. Speci\fcally, retweet and mention\nactivities among accounts demonstrates explicit engagement, especially since users\ncan retweet/mention another user who they do not follow. In the case of follower net-\nwork the level of engagement may be regarded as weaker and more passive. Besides,\nwe are also unable to have their follower network since these are suspended users.\nTo this end, we \frst build the retweet and mention network starting from these sus-\npended users. Table 4.2 shows the statistics of this network's directed graph, with the\nfrequency weighted edge coming from the suspended user who retweeted/mentioned\nto the user who was retweeted/metioned. The total of nodes or users is nearly one\nmillion while the total of edges is more than 14 million.\nNext, suspecting that suspended users tend to act together (a.k.a synchro-\nnized or coordinated behaviors) or more strongly connected to each other, which was\nshown for spammers and malicious accounts in previous work [52, 110, 204], we want\nto analyze suspended accounts at the group level for better interpretation. To this\nend, we apply Louvain community detection algorithm [45] on the retweet and men-\n84\nRetweet + Mention Network Suspended Regular\nNodes 995,083 6,430,293\nEdges 14,321,863 38,728,400\nBiggest Community's Size 13,809 13,537\nNumber of Communities 72,864 690,337\nNumber of Communities (Size \u001510) 9,554 67,734\nTable 4.2: Statistics of retweet and mention network from suspended and regular\nusers.\ntion network to identify communities for these suspended users, so called suspended\ncommunities .1In general, this algorithm tries to build communities so that connec-\ntions are much more inside but less outside a community. Speci\fcally, it optimizes\nmodularity value which measures the density of edges inside communities to edges\noutside communities. Small communities are found at \frst by optimizing modularity\nvalue locally, then each small community is considered as one node and the process is\nrepeated. In this study, we aim to have a manageable size of a community for better\nanalysis so we constrain size of the biggest community at most 15K. To this end, the\nalgorithm results in 72,864 communities with the size of the biggest one as 13,809\n(suspended users). Moreover, we do not focus on very small communities (size <10)\nso we \fnally have 9,554 suspended communities to analyze.\n1Note that the retweet and mention network starting from our collection of suspended\nusers also contains other users who were retweeted/metioned and could be suspended or\nregular. However, after communities were \fnally built based on this retweet and mention\nnetwork, we study communities from members who are suspended users in our collection.\nThus, we call communities as suspended communities.\n85\n4.3.3 Community-Level Features\nPrevious works [98, 42] have reported the list of signs that could suggest a\nTwitter account is bot or automated such as very high posting rate, only a few\nsources or accounts are retweeted, mutiple tweets of the same link. While these\nsigns could be missed for an individual account, synchronized behaviors of users in a\ncommunity could reveal them. Thus, inspired by these previous observations as well\nas Twitter rules on account suspension [190], we de\fne analogous community-level\ncharacteristics to examine evidence of synchronized behaviors at the community level.\nIn essence, we are looking for community-level signals for account suspension. Follows\nare our \fve de\fned dimensions representing distinct community-level features.\n1. Dominant Poster: The highest percentage of tweets in a community that are\nposted by a single user. The higher this percentage, the more dominant a single\nuser.\n2. Dominant Retweet Content Producer: The highest percentage of tweets in a\ncommunity that are retweeted from a single user (tweets can be posted by\neither one or multiple users). The higher this percentage, the more dominant a\nsingle user.\n3. Burstiness: The highest times tweets posted in one hour are higher than the\naverage tweets per hour in a community. The higher this percentage, the more\nbursty tweets were posted.\n4. Dominant Domain: The highest percentage of tweets from a community that\ncontain URLs from a single domain. The higher this percentage, the more\n86\ndominant a single domain.\n5. Dominant Hashtag: The highest percentage of tweets from a community that\ncontain a single hashtag. The higher this percentage, the more dominant a\nsingle hashtag.\nWhile the \frst and second dimensions represent network features of these\nsuspended communities, the third dimension represents temporal features and the\ntwo last represent content features. In fact, we also analyze suspended communities\non other features such as tweet text and language. However, the \fndings either mostly\noverlap with these \fve dimensions (e.g. tweet text) or are almost meaningless (e.g.\nlanguage). Thus, in this work we only present our analysis and \fndings on these \fve\ndimensions.\nNote that since these proposed dimensions serve as collective means to measure\nthe characteristics of a community, the higher values in these \fve dimensions the more\ndistinct and possibly suspicious the community activities. Thus, we are interested in\ncommunities which have high values in these dimensions. Speci\fcally, we focus on\ncommunities having at least 50% of tweets posted by one user, or having at least 50%\nof tweets retweeted from one user, or having tweets posted in one hour which is at least\n200 times the average tweets per hour, or having at least 50% of tweets containing\nURLs from one domain, or having at least 50% of tweets containing the same hashtag.\nIn other words, we specify these high thresholds for our further analysis. While as\nan arbitrary choice, the thresholds as 50% and 200 times serve well as moving these\nvalues higher will not change the meaning of our analysis and \fndings. Further details\n87\ncan be seen in next section Results.\n4.4 Results\n4.4.1 Suspended and Regular Communities\nTo serve as a baseline for observing special characteristics of suspended ac-\ncounts' activities, we compare the activities of suspended accounts to those of regular\naccounts. Here regular accounts are users who Twitter API returns the request of\nuser status as \\regular\". In total, our data collection have 7,740,693 regular users\nwho posted nearly 48 million tweets. We apply our previous approach of building\nsuspended communities for these regular users. Speci\fcally, we \frst build the retweet\nand mention network starting from these regular users. Table 4.2 shows the statistics\nof this network's directed graph, with the frequency weighted edge coming from the\nregular user who retweeted/mentioned to the user who was retweeted/metioned. The\ntotal of nodes or users is nearly 6.5 million while the total of edges is nearly 39 million.\nWe then use the Louvain community detection algorithm with the same constraint\nfor the size of the biggest community (at most 15K). The algorithm results in 690,337\ncommunities with the size of the biggest one as 13,537 (regular users). Finally, we\nhave 67,734 regular communities with size\u001510.\nWe then analyze both suspended and regular communities along our proposed\ncommunity-level features. Figure 4.1 plots CDFs of suspended and regular communi-\nties for these \fve dimensions. We further use the Kolmogorov-Smirnov (KS) test to\ninvestigate whether the distributions of suspended and regular communities in each\n88\n5101520253035404550556065707580859095100\nPercentage0.00.20.40.60.81.0Communities\nPoster - Suspended\nPoster - Regular\nRetweet - Suspended\nRetweet - Regular\n(a) Dominant Poster and Dominant\nRetweet Content Producer\n1020304050607080901001101201301401501601701801902002102202302402502602702802902163\nTimes0.00.20.40.60.81.0Communities\nBurstiness - Suspended\nBurstiness - Regular(b) Burstiness\n5101520253035404550556065707580859095100\nPercentage0.00.20.40.60.81.0Communities\nDomain - Suspended\nDomain - Regular\nHaghtag - Suspended\nHaghtag - Regular\n(c) Dominant Domain and Dominant\nHashtag\nFigure 4.1: CDFs of suspended and regular communities in \fve dimensions. The\nvertical line places at the threshold as 50% and 200 times. From this vertical line to\nthe right in each plot are communities having high value for that respective dimension.\nSpeci\fcally, the percentage of communities having high values = 1 - Yvalue of the\nintersection between the CDF and the vertical line.\n89\ndimension are signi\fcantly di\u000berent. We are able to reject the null hypothesis that\nboth distributions are the same at the 0.02 signi\fcance level for the dominant hash-\ntagdimension and at the 0.0025 signi\fcance level for the dominant poster dimension.\nThus, among \fve investigated dimensions we \fnd that suspended and regular commu-\nnities exhibit signi\fcant di\u000berence in terms of hashtag dominance in posting content\nand very signi\fcant di\u000berence in terms of user dominance in posting behavior.\nMoreover, since we are interested in communities which have high values in\nthese \fve dimensions, we focus on communities contributing to the CDFs from the\nvertical line to the right in each plot of Figure 4.1. Due to the big di\u000berences between\nthe total number of suspended communities (9,554) and regular communities (67,734),\nwe only compare the level of suspended and regular communities having high values\nin these \fve dimensions in terms of percentage for a fair comparison. Speci\fcally:\n\u000fThe feature displaying the largest di\u000berence in percentages between suspended\nand regular communities is the dominant poster dimension. Figure 4.1(a) shows\nthat 38.3% suspended communities have at least 50% of tweets posted by a single\nuser while this type of user dominance occurs only in 3% regular communities.\nThus, the ratio of percentages for suspended to regular communities is 12.8.\n\u000fThe three features with the next highest ratio (i.e. 3 to 4) for suspended versus\nregular communities are dominant retweet content producer, dominant domain,\nand dominant hashtag dimensions. For example, Figure 4.1(c) shows that 8.6%\nsuspended communities have at least 50% of tweets containing URLs from one\ndomain while this type of domain dominance occurs only in 2.3% regular com-\n90\nmunities.\n\u000fThe suspended and regular communities are about the same on burstiness di-\nmension. Figure 4.1(b) shows that 17.2% suspended communities have tweets\nposted in one hour which is at least 200 times the average tweets per hour while\nthis type of bursty posting occurs in 13.7% regular communities. Thus, the\nratio of percentages for suspended to regular communities is only 1.3.\nNote that one community can have high values in multiple dimensions. In\ntotal, 57.6% suspended communities have high value in one or more of \fve investigated\ndimensions while that percentage is lower as 17.6% for regular communities. Thus,\nthe ratio of suspended communities to regular communities which have high value in\none or more of \fve investigated dimensions is 3.3. This suggests that high values in\nmultiple dimensions is a signal for the closer scrutiny on a community. Besides, in\nterms of users, these 57.6% suspended communities contain 668,573 suspended users\nwhich account for nearly 75% of all suspended users. Although these \fve dimensions\ncannot be used to explain completely why these users were suspended, it is noticeable\nthat they pertain to 75% of suspended users through their communities.\nTakeaway: Overall, our results show that suspended and regular communi-\nties exhibit di\u000berences on all \fve investigated dimensions. Especially these di\u000berences\nare signi\fcant in dominant hashtag dimension and very signi\fcant in dominant poster\ndimension. Moreover, compared to regular communities there are more suspended\ncommunities having high values on all \fve dimensions. Especially this can be up to\none order magnitude (12.8 times) for the dominant poster dimension.\n91\nDimension Community Name Users Tweets Retweets %Retweets\nDominant Poster Trump-IRA 28 201 172 85.6\nDominant Retweet Content Producer GayRights 1,578 2,935 2,850 97.1\nBurstiness Vote!BlackLivesMatter 1,544 2,313 2,000 86.5\nDominant Domain EbayAds 26 77,400 91 0.1\nDominant Hashtag NoEthicsNoO\u000ece 89 5,532 407 7.4\nAll except Dominant Poster PoliticalPorn 1,062 2,105 2,105 100.0\nTable 4.3: Statistics of six representative communities for qualitative analysis.\n4.4.2 Qualitative Analysis\nTo illustrate what is going on suspended communities' activities, we next do\nqualitative analysis on several representative communities which have high values in\nthese \fve dimensions. Speci\fcally, we \frst analyze one representative community\nwhich has a signi\fcant high value in only each dimension. Particularly, for content\ndimensions such as domain and hashtag, the analyzed community is one of suspended\ncommunities who posted unique and suspicious dominant domains and hashtags com-\npared to regular communities. We then analyze one representative community which\nhas high values in multiple dimensions. Table 4.3 shows statistics of these six sus-\npended communities.\n4.4.2.1 Dominant Poster\n\u000fTrump-IRA Community: Most tweets (147 out of 201) are from an account\n@td21241 (pro\fle name as terri in July, mainah4Trump in most of September,\nand DeplorableME4Trump for other times in our collection), who retweeted\nmultiple di\u000berent users (from outside the community) with contents supporting\nTrump and attacking Clinton. Aligned with this user's pro\fle description which\n92\nonly contains #MAGA, top hashtags used in the community include #MAGA,\n#Trump2016, and #NeverHillary. More interestingly, checking with the list of\n3.8K RU-IRA accounts on Twitter released by U.S. congress [171], we notice\nthat 11 out of 28 members in this community are RU-IRA accounts. Overall,\nwe see 295 RU-IRA accounts present in 165 di\u000berent suspended communities\n(out of the total 9,554 suspended communities). This community appears to be\nthe second top suspended community in containing the most RU-IRA accounts.\nLooking closely on the community's network, it reveals that the dominant poster\nhappened to play a role as \fltering messages from external users for some RU-\nIRA accounts to retweet.\n4.4.2.2 Dominant Retweet Content Producer\n\u000fGayRights Community: Most tweets (2,716 out of 2,935) were posted by an ac-\ncount @DCHomos and retweeted by this community's members. Aligned with\nthis account's pro\fle description which contains \\all things LGBT+ in DC\",\nthis community discussed mainly about Gay Rights policy, with most tweets\nincluding keywords as lgbt, gay, marriage equality. For example, more than\n100 retweets with content \\hillary clinton mention lgbt rights in her opening\nstatement! \\do not reverse marriage equality\"\" appeared shortly in two hours\nof October 20. Moreover, the community's messages show that they support\nClinton and oppose Trump. For example, nearly 100 retweets with content\n\\don't ever forget, republican nominee Donald Trump mocking a disabled re-\n93\nporter. #demconvention #demsinphilly\" appeared shortly for one hour in July\n26 - time of the Democratic National Convention.\n4.4.2.3 Burstiness\n06/0506/1006/15\n06/20\n06/25\n06/30\n07/0507/1007/1507/2007/2507/3008/0508/1008/1508/2008/2508/3009/0509/1009/1509/20\n09/25\n09/30\n10/0510/1010/1510/2010/2510/3011/05050100150200250300350400450Tweets per hour !#vote! @HillaryClinton: #humanrights \n w. @BernieSanders on #freecollege + #retrainpolice! ! \n #blacklivesmatter!\nFigure 4.2: The illustrative suspended communities in terms of burstiness: Vote!Black\nLivesMatter Community.\n\u000fVote!BlackLivesMatter Community: Most tweets (2K out of 2,313) are\nretweets from many di\u000berent users, of which 642 are retweets from a user\n@BernieSanders. The content of this community's tweets shows that they \frst\nsupported Sanders but then gave their support to Clinton after Sanders lost\nto Clinton for the Democratic nomination. Particularly, there is the highest\nspike in the late morning of September 22 including 862 retweets from a user\n@NadelParis with the content as \\!#vote! @hillaryclinton: #humanrights w.\n@berniesanders on #freecollege + #retrainpolice!! #blacklivesmatter!\" (Figure\n4.2).\n94\n(a) HILLARY CLINTON LOVE TRUMP\nHATE\n(b) CHICKEN TRUMP\nFigure 4.3: Two decals from Ebay URLs posted by EbayAds community.\n4.4.2.4 Dominant Domain\n\u000fEbayAds Community: Almost URL-posted tweets in this community (75K\nout of 77K) used Ebay platform (ebay.com) to promote selling stickers such\nas \\CHICKEN TRUMP\" or \\HILLARY CLINTON LOVE TRUMP HATE\"\n(Figure 4.3). This is community supporting the Democratic party, along with\nHillary Clinton and Bernie Sanders. Their top used hashtags contain mul-\ntiple Democrat-supported hashtags such as #dems, #blm (Black Lives Mat-\nter), #toporog (Top Progressives), #ctl (Connect The Left) as well as multiple\nTrump-opposed hashtags such as #trumpdrseuss, #chickentrump, #dumptrump.\nIt is also noticeable that this community posted mostly original tweets, with\nthe retweet rate of 0.1%.\n95\n(a) No Ethics No O\u000ece\n (b) She sold out Bernie, next she'll sell out\nAmerica\nFigure 4.4: Two pictures opposing Clinton from tumblr.com posted by NoEthic-\nsNoO\u000ece community.\n4.4.2.5 Dominant Hashtag\n\u000fNoEthicsNoO\u000ece Community: Their dominant hashtags include #hillaryclin-\nton, #hillary, #clinton, #election, #politics. The reason is that near the end\nof October, from di\u000berent users in this community about 3.2K tweets (out\nof 5.5K) contained these dominant hashtags. Moreover, these hashtags were\nmostly posted together with URLs from domain tumblr.com which conveyed\nmessages to oppose Hillary Clinton such as \\No Ethics No O\u000ece\" or \\She sold\nout Bernie, next she'll sell out America\" (Figure 4.4).\n96\n4.4.2.6 Combination\nThere is no community having high values on all \fve dimensions. Thus, our\nrepresentative community is the one having high values in four dimensions: dominant\nretweet contain producer, burstiness, dominant domain, and dominant hashtag.\n\u000fPoliticalPorn Community: Their dominant hashtags include #porn, #xxx,\n#makeamericagreatagain, #imwither (note that neither support Trump nor\nClinton). Their dominant domain is pornsite\rip.com. The reason is that\namong 2.1K retweets, 1,061 retweets are retweets from a user @forplayxxx with\ncontent \\donald trump, hillary clinton #porn...#xxx #makeamericagreatagain\n#imwither http://pornsite\rip.com/2016/08/04/donald-trump-and-hillary-clinton-\nfucking-bernie-sanders-and-megan-parody/\". Moreover, suspiciously these tweets\nwere shortly tweeted only from 6 to 9am in November 5. It is also noticeable\nthat this is a complete retweet community (retweet 100%).\nTakeaway: Overall, our qualitative analysis demonstrates that each of \fve\nproposed dimensions is very useful in identifying a single theme inside the community\nwhich re\rects the community's feature or characteristic. And despite being limited\nto very small set of suspended communities due to the di\u000eculty nature of qualitative\nanalysis, the results show that suspended communities are heterogeneous in terms\nof di\u000berent characteristics. Speci\fcally, some communities post content that is pro-\nTrump, anti-Clinton (e.g. Trump-IRA) while some are pro-Clinton, anti-Trump (e.g.\nGayRights) and some are even neither (e.g. Political Porn). The posting behav-\niors of some communities are bursty with noticeably bumps at certain times (e.g.\n97\nVote!BlackLivesMatter) while others are not. They include URLs pointing to various\ndomains such as ebay.com to sell bumper stickers (e.g. EbayAds) or tumblr.com to\nspread memes and quotes (e.g. NoEthicsNoO\u000ece). They use hashtags for di\u000berent\npurposes such as promoting votes (e.g. Vote!BlackLivesMatter) or spreading porn\n(e.g. PoliticalPorn). They engage in the discussion of a diverse set of issues ranging\nfrom foreign policy to gay rights (e.g. GayRights). Especially, some of communities\nappear to have connections to Russian trolls (e.g. Trump-IRA).\n4.4.3 Twitter's Suspension Algorithm\nAccounts that violate Twitter policies are constantly removed from the plat-\nform. We waited for more than one year after the 2016 U.S. presidential election\n(as of February 2018) to get the suspended account collection as described and an-\nalyzed in previous sections. However, since May 2018 Twitter announced a number\nof cleanups, so-called Twitter \\purge\" [50], which led to suspension of many more\nTwitter accounts. This happened because Twitter claimed to develop \\new measures\nto \fght abuse and trolls, new policies on hateful conduct and violent extremism,\nand ... new technology and sta\u000b to \fght spam and abuse\" during May-August 2018\n[163, 94]. Thus, in January 2019 we rechecked to see how many more accounts in our\nelection-related tweet collection were suspended. Although these newly suspended\naccounts may be suspended because of either actions during 2016 or actions taken\nsince the election, we assume these newly suspended accounts might be the result of\nthe new development in Twitter's suspension algorithm. We want to know whether\n98\nthese newly suspended users had connections to the original suspended ones. We hope\nour \fndings will shed light on Twitter's new development in their account suspension\nalgorithm.\nIn fact, our 2019 recheck has found an additional newly suspended accounts\nin our dataset. Speci\fcally, there are 192,415 suspended accounts that had not been\nsuspended earlier. This increases the percentage of suspended accounts in our dataset\nfrom 9.5% to 11.6%. We then determine if these newly suspended accounts have\nconnections to the 9,554 communities of the original suspended accounts. To this\nend, we calculate the maximum retweet/mention connection of each newly suspended\naccount to the original suspended communities. The result shows that more than 90%\nof the newly suspended accounts had at least one retweet/mention connection to an\noriginal suspended community.\nNext, since most of new suspended accounts have direct connections to old sus-\npended communities, we want to examine the strength of these connections. Speci\f-\ncally, we ask whether these new suspended accounts connected to major actors in the\noriginal suspended communities or is it that there is no pattern in the connections.\nTo this end, since the direct connections from new suspended users to old suspended\ncommunities are retweets or mentions, we examine what percentage of these newly\nsuspended users connected to the top-k retweet content producers of the original\ncommunities. Note that when k = 1, the top-k retweet content producers actually is\nthe dominant retweet content producer for that community, one of our \fve proposed\ndimensions. Besides, although a newly suspended account may be connected to more\n99\nthan one of the original communities, we consider only the strongest connection (i.e.\nsmallest k) for each newly suspended account. The result shows that 72% of the newly\nsuspended users retweeted or mentioned the dominant retweet content producer of an\nold suspended community. And this percentage increases to 85% with k = 5, which\nmeans that 85% had a connection to one of the top \fve active users in the original\ncommunity.\nTakeaway: Overall, we \fnd that Twitter's new development on their sus-\npension algorithm helps to detect more malicious users. However, our analysis on\nTwitter newly suspended users reveals that more than 90% of them have direct\n(retweet/mention) connections to communities of suspended users that Twitter de-\ntected before. More interestingly, a high percentage ( >72%) of these new suspended\nusers retweet or mention the top retweet content producers of the old suspended\ncommunities that they connect to.\n4.5 Summary\nIn this work, we retrospectively analyze the activities of suspended Twitter\naccounts that engaged in political discourse during the 2016 U.S. presidential election.\nBy developing community-based method and measures which are new to the \feld of\nanalyzing suspended accounts, we are able to characterize about a million suspended\naccounts. In short, we \fnd that (1) suspended communities are di\u000berent from regular\ncommunities in their posting behavior; (2) suspended communities exhibit heteroge-\nneous characteristics; and (3) newly suspended accounts connect tightly to the old\n100\nsuspended communities.\nTo the best of our knowledge, we are the \frst to conduct in-depth postmortem\nanalysis of accounts suspended by Twitter to study their community-level activities\nas well as assess the e\u000bectiveness of Twitter's new countermeasures. Our community-\nlevel analysis of suspended accounts highlights their coordinated behaviors which\ncan be leveraged to develop more e\u000bective countermeasures. Although the results in\nthis work are limited to the 2016 U.S. presidential election, our postmortem analysis\napproach is broadly applicable to any future election-related events for which social\nmedia sites are looking to develop more e\u000bective countermeasures.\n101\nCHAPTER 5\nCONCLUSION\nThis thesis explores four di\u000berent research streams to help understand the\nroles of humans, algorithms, and cyborgs in political polarization. Speci\fcally, we\nconduct two research studies, \\Scalable News Slant Measurement Using Twitter\" and\n\\Revisiting The American Voter on Twitter,\" to help understand the roles of humans\nin political polarization. An additional study \\Measuring Political Personalization\non Google News Search\" explores the roles of algorithms in political polarization\nand another study \\A Postmortem of Suspended Twitter Accounts in the 2016 U.S.\nPresidential Election\" investigates the roles of cyborgs in political polarization.\nIn terms of humans' roles in political polarization, humans' innate instincts\ndirectly lead to political polarization. Speci\fcally, people tend to share and consume\nnews conforming with their pre-existing ideology or political a\u000eliation. People also\ntend to follow and like people having the same ideology or political a\u000eliation. Thus,\nto help people know how imbalanced the political news that they might consume and\nshare, in our \frst research we propose a simple method to e\u000bectively measure the\npolitical slant of individual news articles at scale. Moreover, in our second research\nwe analyze political discourse on Twitter in the 2016 U.S. presidential election in\norder to inform people about how they have discussed the election according to their\npolitical a\u000eliation.\nIn terms of algorithms' roles in political polarization, in our third research we\ndesign a sock puppet auditing system that helps to discover political personalization\n102\non Google News Search based on a user's browsing history. More importantly, the\nmost personalized results tend to reinforce the presumed partisanship. Thus, algo-\nrithms designed to create personalized experience can inadvertently intensify political\npolarization. Since there is a growing concern about the extent to which algorithmic\npersonalization limits people's exposure to diverse viewpoints, thereby creating \\\fl-\nter bubbles\" or \\echo chambers\", our research provides further empirical evidence for\nthe underlying causes of \\\flter bubbles\" or \\echo chambers\" in the aspect of political\npolarization.\nIn terms of cyborgs' roles in political polarization, in our fourth research we\nretrospectively analyze the activities of suspended Twitter accounts that engaged\nin political discourse during the 2016 U.S. presidential election. By developing a\ncommunity-based method and measures that are new to the \feld of analyzing sus-\npended accounts, we are able to characterize about a million suspended accounts.\nSpeci\fcally, suspended communities exhibit heterogeneous characteristics such as pro-\nTrump vs. pro-Clinton or the involvement of Russian trolls which are well-known in\nprevious research for campaign/election manipulation. Thus, one of the suspended\naccounts' or cyborgs' negative impacts could be to increase the political polarization.\nFor the future works, we would like to focus on studying how to mitigate the\npolitical polarization. Speci\fcally, for the roles of humans in political polarization, our\nwork of measuring the individual news' political bias on online social media at scale\ncan help to improve the transparency of news. Future research can study di\u000berent\ndisclosure methods/designs of news political slant (which can make people more self-\n103\naware of their choices) as well as the impacts of these methods. Moreover, our work\nof analyzing political discourse can systematically identify the issues that people care\nabout. This information can be used by politicians or policy makers to prioritize their\nagendas. This information can also help people to have a better election forecasting\nmodel that can replace our current laborious poll systems. For the roles of algorithms\nin political polarization, personalization can create distinct experiences for di\u000berent\nusers so future studies should be aware of the potential for algorithmic unfairness\n[177], especially when the unfairness can come from the bias in data [133] or the\ndesign of the algorithm itself [82]. Moreover, browsers like Safari or Firefox have\nbuilt-in functionality to block trackers (thus block or obfuscate users' privacy data)\n[115, 180] so researchers should study how these privacy-enhancing technologies can\nhelp to reduce the algorithmic personalization. For the roles of cyborgs in political\npolarization, our analysis on Twitter's new countermeasures shows that the newly\nsuspended accounts are actually linked to the old suspended communities that we\nidenti\fed before. It suggests our network-based and community-level activities can\nhelp to detect cyborgs in a timely and accurate manner. This will be very helpful\nsince detecting cyborgs is much more complex than detecting purely bots or fake\naccounts.\n104\nBibliography\n[1] AllSides. http://www.allsides.com .\n[2] Amazon Mechanical Turk. https://www.mturk.com .\n[3] Selenium WebDriver. https://www.seleniumhq.org/projects/webdriver/ .\n[4] Twitter REST API. https://dev.twitter.com/rest .\n[5] Twitter Streaming API. https://dev.twitter.com/streaming .\n[6] Google user data to be merged across all sites under contentious plan. The\nGuardian. http://bit.ly/2DluqbV , 2012.\n[7] New Tweets per second record, and how! https://blog.twitter.com/2013/new-\ntweets-per-second-record-and-how, August 2013.\n[8] Donald Trump: Ban all Muslim travel to U.S.\nhttp://www.cnn.com/2015/12/07/politics/donald-trump-muslim-ban-\nimmigration/, December 2016.\n[9] Election 2016 Presidential Polls. http://www.realclearpolitics.com/\nepolls/latest_polls/president/ , 2016.\n105\n[10] Fiorina: Obama `delusional' about magnitude of climate change as se-\ncurity threat. http://www.foxnews.com/politics/2015/11/29/\forina-obama-\ndelusional-about-magnitude-climate-change-as-security-threat.html, November\n2016.\n[11] Full interview: Hillary Clinton, February 7.\nhttp://www.cbsnews.com/videos/full-interview-hillary-clinton-february-7/,\nFebruary 2016.\n[12] Voting Records. http://www.adaction.org/pages/publications/\nvoting-records.php , 2016.\n[13] Data donation - German Parliamentary Election 2017. http://bit.ly/\n2t9QcLf , 2017.\n[14] Gephi Toolkit. https://gephi.org/toolkit/ , 2018.\n[15] Media bias/fact check - the most comprehensive media bias resource. https:\n//mediabiasfactcheck.com/ , 2018.\n[16] The Intelligence Community Assessment: Assessing Russian Activities and\nIntentions in Recent U.S. Elections. https://www.burr.senate.gov/imo/\nmedia/doc/SSCI%20ICA%20ASSESSMENT_FINALJULY3.pdf , 2018.\n106\n[17] A. Abramowitz and S. Webster. All politics is national: The rise of negative\npartisanship and the nationalization of US house and senate elections in the\n21st century. In Annual Meeting of the Midwest Political Science Association\nConference , 2015.\n[18] S. Ahmed, K. Jaidka, and J. Cho. The 2014 Indian elections on Twitter: A com-\nparison of campaign strategies of political parties. Telematics and Informatics ,\n33:1071{1087, 2016.\n[19] J.-w. Ahn, P. Brusilovsky, J. Grady, D. He, and S. Y. Syn. Open user pro\fles for\nadaptive news systems: help or harm? In Proceedings of the 16th international\nconference on World Wide Web , 2007.\n[20] J. Aldrich, C. Gelpi, P. D. Feaver, J. Rei\rer, and K. T. Sharp. Foreign Policy\nand the Electoral Connection. Annual Review of Political Science , 9:477{502,\n2006.\n[21] H. Allcott and M. Gentzkow. Social Media and Fake News in the 2016 Election.\nNBER Working Paper No. 23089, January 2017.\n[22] W. Alorainy, P. Burnap, H. Liu, A. Javed, and M. Williams. Suspended ac-\ncounts: A source of Tweets with disgust and anger emotions for augmenting\nhate speech data sample. In International Conference on Machine Learning\nand Cybernetics (ICMLC) , 2018.\n107\n[23] C. Alvino and J. Basilico. Learning a Personalized Homepage. http://bit.\nly/2ujZ3Jm , 2015.\n[24] J. An, M. Cha, K. Gummadi, and C. Jon. Media Landscape in Twitter: A World\nof New Conventions and Political Diversity. In AAAI International Conference\non Weblogs and Social Media (ICWSM) , 2011.\n[25] J. An, M. Cha, K. P. Gummadi, J. Crowcroft, and D. Quercia. Visualizing\nMedia Bias through Twitter. In AAAI International Conference on Weblogs\nand Social Media (ICWSM) , 2012.\n[26] W. Andrews and T. Kaplan. Where the Candidates Stand on 2016's Biggest\nIssues. The New York Times. http://nyti.ms/2ERzPEn, 2016.\n[27] J. Angwin. Google Has Quietly Dropped Ban on Personally Identi\fable Web\nTracking. ProPublica. http://bit.ly/2eAjC9w , 2016.\n[28] N. Anstead. Social Media Analysis and Public Opinion: The 2010 UK General\nElection. Journal of Computer-Mediated Communication , pages 204{220, 2014.\n[29] A. Arif, L. G. Stewart, and K. Starbird. Acting the Part: Examining Infor-\nmation Operations Within #BlackLivesMatter Discourse. In The 21st ACM\nConference on Computer-Supported Cooperative Work and Social Computing\n(CSCW) , 2018.\n108\n[30] S. Baccianella, A. Esuli, and F. Sebastiani. SentiWordNet 3.0: An Enhanced\nLexical Resource for Sentiment Analysis and Opinion Mining. In LREC , vol-\nume 10, pages 2200{2204, 2010.\n[31] A. Badawy, E. Ferrara, and K. Lerman. Analyzing the Digital Traces of Political\nManipulation: The 2016 Russian Interference Twitter Campain. In The 2018\nIEEE/ACM International Conference on Advances in Social Networks Analysis\nand Mining (ASONAM) , 2018.\n[32] E. Bakshy, S. Messing, and L. Adamic. Exposure to Ideologically Diverse News\nand Opinion on Facebook. Science , 348(6239):1130{1132, May 2015.\n[33] E. Bakshy, S. Messing, and L. A. Adamic. Exposure to ideologically diverse\nnews and opinion on Facebook. Science , 2015.\n[34] R. Balebako, P. Leon, R. Shay, B. Ur, Y. Wang, and L. Cranor. Measuring\nthe e\u000bectiveness of privacy tools for limiting behavioral advertising. In Web 2.0\nWorkshop on Security and Privacy (W2SP) , 2012.\n[35] P. Barber, J. T. Jost, J. Nagler, J. A. Tucker, and R. Bonneau. Tweeting\nFrom Left to Right: Is Online Political Communication More Than an Echo\nChamber? Psychological Science , August 2015.\n109\n[36] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukrishnan. Ad-\nscape: Harvesting and analyzing online display ads. In ACM International\nConference on World Wide Web (WWW) , 2014.\n[37] L. M. Bartels. Beyond the Running Tally: Partisan Bias in Political Perceptions.\nPolitical Behavior , 24(2):117{150, Jun 2002.\n[38] F. R. Baumgartner, F. R.tner and B. D. Jones. Agendas and Instability in\nAmerican Politics . Chicago : University of Chicago Press, 1993.\n[39] P. Bayer, M. D. Casey, F. Ferreira, and R. McMillan. Estimating Racial Price\nDi\u000berentials in the Housing Market. National Bureau of Economic Research\n(NBER) , 2012.\n[40] W. M. Benoit. Political Party A\u000eliation and Presidential Campaign Discourse.\nCommunication Quarterly , 52(2):81{97, 2004.\n[41] A. Bermingham and A. F. Smeaton. On Using Twitter to Monitor Political\nSentiment and Predict Election Results. In Sentiment Analysis where AI meets\nPsychology , 2011.\n[42] A. Bessi and E. Ferrara. Social bots distort the 2016 U.S. Presidential election\nonline discussion. First Monday , 2016.\n110\n[43] S. Bhattacharya, C. Yang, P. Srinivasan, and B. Boynton. Perceptions of Pres-\nidential Candidates' Personality in Twitter. Journal of the Association for\nInformation Science and Technology , 2015.\n[44] G. O. Blog. Personalized Search for everyone. http://bit.ly/2mHY2Wi , 2009.\n[45] V. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of\ncommunities in large networks. Journal of Statistical Mechanics: Theory and\nExperiment , 2008.\n[46] S. Boyd and L. Vandenberghe. Convex Optimization . Cambridge University\nPress, 2004.\n[47] C. Budak, S. Goel, and J. M. Rao. Fair and Balanced? Quantifying Media Bias\nthrough Crowdsourcing Content Analysis. In AAAI International Conference\non Weblogs and Social Media (ICWSM) , 2015.\n[48] J. Burgess and A. Bruns. The dynamics of the #ausvotes conversation in\nrelation to the Australian media ecology. Journalism Pratice , 6:384{402, 2012.\n[49] P. Burnap, R. Gibson, L. Sloan, R. Southern, and M. Williams. 140 Characters\nto Victory?: Using Twitter to Predict the UK 2015 General Election. Cardi\u000b\nUniversity (working paper) , 2015.\n[50] E. Bursztein and A. Marzuoli. Quantifying the impact of the Twitter fake\naccounts purge - a technical analysis. https://bit.ly/2LVum4p, 2018.\n111\n[51] A. Campbell, C. Philip, M. Warren, and S. Donald. The American Voter .\nUniversity of Chicago Press, 1960.\n[52] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering Large Groups of Active\nMalicious Accounts in Online Social Networks. In The ACM Conference on\nComputer and Communications Security (CCS) , 2014.\n[53] P. R. Center. Political Polarization in the American Public: How Increasing\nIdeological Uniformity and Partisan Antipathy A\u000bect Politics, Compromise and\nEveryday Life. http://pewrsr.ch/2n8oI2I , 2014.\n[54] P. R. Center. A Deep Dive Into Party A\u000eliation. http://www.people-\npress.org/2015/04/07/a-deep-dive-into-party-a\u000eliation/, April 2015.\n[55] A. Ceron, L. Curini, and S. M. Iacus. Every tweet counts? How sentiment anal-\nysis of social media can improve our knowledge of citizens political preferences\nwith an application to Italy and France. New Media & Society , 16(2):340{358,\n2014.\n[56] J. Cho and S. Roy. Impact of Search Engines on Page Popularity. In ACM\nInternational Conference on World Wide Web (WWW) , 2004.\n[57] R. W. Cobb and C. D. Elder. Participation in American Politics: The Dynamics\nof Agenda Building . Johns Hopkins University Press, 1972.\n112\n[58] R. Cohen and D. Ruths. Classifying Political Orientation on Twitter: Its Not\nEasy! In Proceedings of the Seventh International AAAI Conference on Weblogs\nand Social Media (ICWSM) , 2013.\n[59] M. D. Conover, B. Goncalves, J. Ratkiewicz, A. Flammini, and F. Menczer.\nPredicting the political alignment of Twitter users. Proceedings of the Interna-\ntional Conference on Social Computing , 2011.\n[60] Conover, Michael D. and Ratkiewicz, Jacob and Francisco, Matthew and\nGoncalves, Bruno and Menczer, Filippo and Flammini, Alessandro. Political\nPolarization on Twitter. In Proceedings of the AAAI International Conference\non Weblogs and Social Media (ICWSM) , 2011.\n[61] J. Constine. How Facebook News Feed Works. TechCrunch. http://tcrn.ch/\n2c1QEQf , 2016.\n[62] J. Cook, H. Le, and Z. Sha\fq. Fake News Research Project Research Report.\nhttps://bit.ly/2PeLbsi, 2017.\n[63] G. W. Corder and D. I. Foreman. Nonparametric Statistics: A Step-by-Step\nApproach . Wiley, 2014.\n[64] E. Costantini and K. H. Craik. Personality and politicians: California party\nleaders, 19601976. Personality and Social Psychology , 38(4):641{661, 1980.\n113\n[65] P. Dahlgren. Media and political engagement: Citizens, communication, and\ndemocracy . Cambridge University Press, 2009.\n[66] F. J. Damerau. A technique for computer detection and correction of spelling\nerrors. Communications of the ACM (CACM) , 7:171{176, 1964.\n[67] A. Datta, M. C. Tschantz, and A. Datta. Automated Experiments on Ad\nPrivacy Settings: A Tale of Opacity, Choice, and Discrimination. In Privacy\nEnhancing Technologies Symposium (PETS) , 2015.\n[68] J. DiGrazia, K. McKelvey, J. Bollen, and F. Rojas. More tweets, more votes:\nSocial media as a quantitative indicator of political behavior. PLOS ONE ,\n11(8), 2013.\n[69] P. Dolan. Abortion and American Politics: Can a single policy issue lead\nto party switching? Breithaupt American Government Paper Competition,\nRoanoke College, April 2011.\n[70] M. Duggan and A. Smith. The Political Environment on Social Media, 2016.\n[71] A. Edelman. 2016 candidate John Kasich: I would create a\nNEW government agency that would `promote Judeo-Christian val-\nues'. http://www.nydailynews.com/news/politics/kasich-create-agency-push-\njudeo-christian-values-article-1.2439022, November 2016.\n114\n[72] S. Englehardt and A. Narayanan. Online Tracking: A 1-million-site Measure-\nment and Analysis. In ACM Conference on Computer and Communications\nSecurity (CCS) , 2016.\n[73] Facebook. Community Standards Enforcement Preliminary Report.\nhttps://transparency.facebook.com/community-standards-enforcement#fake-\naccounts, 2018.\n[74] P. R. C. for the People & the Press. Obama in a Word: From `In-\nexperienced' and `Change' to `Good' and `Trying'. http://www.people-\npress.org/2012/09/05/obama-in-a-word-from-inexperienced-and-change-to-\ngood-and-trying/, September 2012.\n[75] P. R. C. for the People & the Press. Romney in a Word: `Hon-\nest,' `Businessman,' `Rich'. http://www.people-press.org/2012/08/29/\nromney-in-a-word-honest-businessman-rich/ , August 2012.\n[76] M. E. Gallagher and S. H. Allen. Presidential Personality: Not Just a Nuisance.\nForeign Policy Analysis , 10(1):1{21, January 2014.\n[77] M. Garcia. Racist in the Machine: The Disturbing Implications of Algorithmic\nBias. World Policy Journal , 33(4):111{117, 2016.\n115\n[78] D. Gayo-Avello. \\I Wanted to Predict Elections with Twitter and all I got was\nthis Lousy Paper\" { A Balanced Survey on Election Prediction using Twitter\nData. arXiv: 12046441 , 2012.\n[79] D. Gayo-Avello, P. T. Metaxas, and E. Mustafaraj. Limits of Electoral Predic-\ntions Using Twitter. In AAAI International Conference on Weblogs and Social\nMedia (ICWSM) , 2011.\n[80] M. Gentzkow and J. M. Shapiro. What Drives Media Slant? Evidence from\nU.S. Daily Newspapers. Econometrica , 78(1):35{71, January 2010.\n[81] A. L. George and J. L. George. Presidential personality and performance . Boul-\nder, CO: Westview Press, 1998.\n[82] B. Glymour and J. Herington. Measuring the biases that matter: The ethical\nand casual foundations for measures of fairness in algorithms. In Proceedings of\nthe Conference on Fairness, Accountability, and Transparency (FAT*) , 2019.\n[83] J. Golbeck and D. Hansen. A method for computing political preference among\nTwitter followers. Social Networks , 2014.\n[84] J. Gottfried, M. Barthel, E. Shearer, and A. Mitchell. The\n2016 Presidential Campaign - a News Event That's Hard to Miss.\nhttp://www.journalism.org/2016/02/04/the-2016-presidential-campaign-a-\nnews-event-thats-hard-to-miss/, February 2016.\n116\n[85] H. G. Gough and A. B. Heilbrun. The Adjective Check List Manual. Consulting\nPsychologists Press, 1983.\n[86] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The Underground on\n140 Characters or Less. In The ACM Conference on Computer and Communi-\ncations Security (CCS) , 2010.\n[87] T. Groseclose and J. Milyo. A Measure of Media Bias. The Quarterly Journal\nof Economics , 120(4):1191{1237, November 2005.\n[88] T. Groseclose, L. D. Steven, and S. M. James Jr. Comparing Interest Group\nScores across Time and Chambers: Adjusted ADA Scores for the U.S. Congress.\nAmerican Political Science Association , 93(1):33{50, March 1999.\n[89] S. Guha, B. Cheng, and P. Francis. Challenges in measuring online advertising\nsystems. In ACM Internet Measurement Conference (IMC) , 2010.\n[90] M. Haim, A. Graefe, and H.-B. Brosius. Burst of the \flter bubble? e\u000bects of\npersonalization on the diversity of google news. Digital Journalism , 2017.\n[91] A. Hannak, P. Sapiezynski, A. M. Kakhki, B. Krishnamurthy, D. Lazer, A. Mis-\nlove, and C. Wilson. Measuring personalization of web search. In ACM Inter-\nnational Conference on World Wide Web (WWW) , 2013.\n117\n[92] A. Hannak, P. Sapiezynski, A. M. Khaki, D. Lazer, A. Mislove, and C. Wil-\nson. Measuring personalization of web search. https://arxiv.org/abs/1706.\n05011 , 2017.\n[93] A. Hannak, G. Soeller, D. Lazer, A. Mislove, and C. Wilson. Measuring price\ndiscrimination and steering on e-commerce web sites. In ACM Internet Mea-\nsurement Conference (IMC) , 2014.\n[94] D. Harvey and D. Gasca. Serving healthy conversation. https:\n//blog.twitter.com/official/en_us/topics/product/2018/Serving_\nHealthy_Conversation.html , 2018.\n[95] A. Hermida. #Journalism: Recon\fguring journalism research about Twitter,\none tweet at a time. Digital Journalism , 1(3):295{313, 2013.\n[96] D. Hicks and D. Gasca. A healthier Twitter: Progress and\nmore to do. https://blog.twitter.com/en_us/topics/company/2019/\nhealth-update.html , 2019.\n[97] B. Highton. Updating Political Evaluations: Policy Attitudes, Partisanship,\nand Presidential Assessments. Political Behavior , 34(1):57{78, March 2012.\n[98] M. Hindman and V. Barash. Disinformation, `Fake News' and In\ruence Cam-\npaigns on Twitter, 2018.\n118\n[99] D. E. Ho and K. M. Quinn. Measuring Explicit Political Positions of Media.\nQuarterly Journal of Political Science , 3:353{377, October 2008.\n[100] V. T. Hoang, A. Spognardi, F. Tiezzi, M. Petrocchi, and R. D. Nicola. Domain-\nspeci\fc queries and Web search personalization: some investigations. In Pro-\nceedings of the 11th International Workshop on Automated Speci\fcation and\nVeri\fcation of Web Systems (WWV) , 2015.\n[101] R. Holmes. How Bernie Sanders Beats Donald Trump at Social Media. http://\nfortune.com/2016/04/18/bernie-sanders-donald-trump-social-media/ ,\nApril 2016.\n[102] S. Hong and D. Nadler. Which candidates do the public discuss online in an elec-\ntion campaign? The use of social media by 2012 presidential candidates and its\nimpact on candidate salience. Government Information Quarterly , 29(4):455{\n461, 2012.\n[103] J. Howerton. Con\rict of Interest? MSNBC Hosts & Other 'In\ruential Progres-\nsives' Visit White House to Discuss Tax Policy, December 2012.\n[104] G. D. Hutcheson and L. A. Moutinho. Ordinary Least-Squares Regression.\nTechnical report, The SAGE Dictionary of Quantitative Management Research,\nManchester University, 2011.\n119\n[105] ICA. Background to \\Assessing Russian Activities and Intentions in Recent\nUS Elections\": The Analytic Process and Cyber Incident Attribution. https:\n//www.dni.gov/files/documents/ICA_2017_01.pdf , 2017.\n[106] S. Iyengar and K. S. Hahn. Red Media, Blue Media: Evidence of Ideological\nSelectivity in Media Use. Journal of Communication , 59, 2009.\n[107] J. Jacobs. In Twitter Purge, Top Accounts Lose Millions of Followers.\nhttps://nyti.ms/2FAHHhf, 2018.\n[108] K. H. Jamieson and J. N. Cappella. Echo chamber: Rush Limbaugh and the\nconservative media establishment . Oxford University Press, 2008.\n[109] E. S. Je\u000brey Gottfried, Michael Barthel and\nA. Mitchell. http://www.journalism.org/2016/02/04/\nthe-2016-presidential-campaign-a-news-event-thats-hard-to-miss/ .\n[110] M. Jiang, P. Cu, A. Beutel, C. Faloutsos, and S. Yang. CatchSync: Catching\nSynchronized Behavior in Large Directed Graphs. In ACM SIGKDD Conference\non Knowledge Discovery and Data Mining , 2014.\n[111] Z. Jin, J. Cao, H. Guo, Y. Zhang, Y. Wang, and J. Luo. Detection\nand Analysis of 2016 U.S. Presidential Election Related Rumors on Twitter.\nhttps://arxiv.org/abs/1701.06250, 2017.\n120\n[112] J. M. Jones. In U.S., New Record 43% Are Political Independents. Gallup.\nhttp://bit.ly/17uCqDC , January 2015.\n[113] A. Jungherr, P. Jrgens, and H. Schoen. Why the Pirate Party Won the German\nElection of 2009 or The Trouble With Predictions. Social Science Computer\nReview , 2(30):229{234, 2012.\n[114] F. Karimi. From Guinea to the U.S.: Timeline of \frst Ebola pa-\ntient in New York City. http://www.cnn.com/2014/10/24/health/\nnew-york-ebola-timeline/ , October 2014.\n[115] J. Kastrenakes. Firefox will begin blocking trackers by\ndefault. https://www.theverge.com/2019/6/4/18650363/\nfirefox-block-trackers-default-enhanced-tracking-protection ,\n2019.\n[116] C. Kliman-Silver, A. Hannak, D. Lazer, C. Wilson, and A. Mislove. Location,\nLocation, Location: The Impact of Geolocation on Web Search Personalization.\nInACM Internet Measurement Conference (IMC) , 2015.\n[117] D. Knoke. Networks of Political Action: Toward Theory Construction. Social\nForces , 68(4):1041{1063, 1990.\n121\n[118] M. Kosinski, D. Stillwell, and T. Graepe. Private traits and attributes are\npredictable from digital records of human behavior. Proceedings of the National\nAcademy of Sciences , 110(15):5802{5805, 2013.\n[119] J. Kulshrestha, M. Eslami, J. Messias, M. B. Zafar, S. Ghosh, K. P. Gummadi,\nand K. Karahalios. Quantifying search bias: Investigating sources of bias for\npolitical searches in social media. In The 20th ACM Conference on Computer-\nSupported Cooperative Work and Social Computing (CSCW) , 2017.\n[120] H. Le, Z. Sha\fq, and P. Srinivasan. Scalable News Slant Measurement Us-\ning Twitter. In AAAI International Conference on Weblogs and Social Media\n(ICWSM) , 2017.\n[121] H. T. Le, G. Boynton, Y. Mejova, Z. Sha\fq, and P. Srinivasan. Bumps and\nBruises: Mining Presidential Campaign Announcements on Twitter. In ACM\nConference on Hypertext and Social Media (HT) , 2017.\n[122] H. T. Le, G. Boynton, Y. Mejova, Z. Sha\fq, and P. Srinivasan. Revisiting\nThe American Voter on Twitter. In ACM Conference on Human Factors in\nComputing Systems (CHI) , 2017.\n[123] S. Lee and J. Kim. Early \fltering of ephemeral malicious accounts on Twitter.\nComputer Communications , (54):48{57, 2014.\n[124] M. Lewis. The Top 25 Conservatives on Twitter, http://aol.it/1OSbuBT.\n122\n[125] M. Lewis. The Top 25 Progressive Twitterers, http://aol.it/1OUOEDy.\n[126] M. Lewis, May 2015 - last accessed time.\n[127] M. Lewis-Beck, J. G. William, N. Helmut, and W. F. Herbert. The American\nVoter Revisited . University of Michigan Press, 2008.\n[128] T. Libert. Exposing the Invisible Web: An Analysis of Third-Party HTTP\nRequests on 1 Million Websites. International Journal of Communication , 2015.\n[129] P.-C. Lin and P.-M. Huang. A Study of E\u000bective Features for Detecting Long-\nsurviving Twitter Spam Accounts. In The 15th International Conference on\nAdvanced Communications Technology (ICACT) , 2013.\n[130] D. L. Linvill and P. L. Warren. Troll Factories: The Internet Research Agency\nand State-Sponsored Agenda Building, 2018.\n[131] B. Liu, A. Sheth, U. Weinsberg, J. Chandrashekar, and R. Govindan. AdReveal:\nimproving transparency into online targeted advertising. In ACM Workshop on\nHot Topics in Networks (HotNets) , 2013.\n[132] J. Liu, P. Dolan, and E. R. Pedersen. Personalized news recommendation based\non click behavior. In Proceedings of the 15th international conference on Intel-\nligent User Interfaces (IUI) , pages 31{40, 2010.\n123\n[133] D. Madras, E. Creager, T. Pitassi, and R. Zemel. Fairness through causal aware-\nness: Learning causal latent-variable models for biased data. In Proceedings of\nthe Conference on Fairness, Accountability, and Transparency (FAT*) , 2019.\n[134] A. Majumder and N. Shrivastava. Know your personalization: Learning topic\nlevel personalization in online services. In Proceedings of the 22nd international\nconference on World Wide Web , 2013.\n[135] J. Martin. Eric Cantor Defeated by David Brat, Tea Party Challenger, in\nG.O.P. Primary Upset. http://www.nytimes.com/2014/06/11/us/politics/\neric-cantor-loses-gop-primary.html , June 2014.\n[136] F. J. Massey Jr. The Kolmogorov-Smirnov Test for Goodness of Fit. Journal\nof the American Statistical Association , 46:68{78, 1951.\n[137] D. Mattioli. On Orbitz, Mac users steered to pricier hotels.\nhttps://on.wsj.com/2rthP28, 2012.\n[138] J. R. Mayer and J. C. Mitchell. Third-Party Web Tracking: Policy and Tech-\nnology. In IEEE Symposium on Security and Privacy , 2012.\n[139] Y. Mejova, P. Srinivasan, and B. Boynton. GOP Primary Season on Twitter:\n\\Popular\" Political Sentiment in Social Media. In WSDM , 2013.\n[140] D. B. Melican and T. L. Dixon. News on the net: Credibility, selective exposure,\nand racial prejudice. Journal of Communication Research , 35:151{168, 2008.\n124\n[141] J. Mikians, L. Gyarmati, V. Erramilli, and N. Laoutaris. Detecting price and\nsearch discrimination on the internet. In ACM Workshop on Hot Topics in\nNetworks (HotNets) , 2012.\n[142] J. Mikians, L. Gyarmati, V. Erramilli, and N. Laoutaris. Crowd-assisted search\nfor price discrimination in e-commerce: \frst results. In ACM Conference on\nemerging Networking EXperiments and Technologies (CoNEXT) , 2013.\n[143] A. Mitchell. State of the News Media 2015. http://www.journalism.org/\n2015/04/29/state-of-the-news-media-2015 , April 2015.\n[144] J. S. Morgan, C. Lampe, and M. Sha\fq. Is news sharing on Twitter ideologi-\ncally biased? In ACM Conference on Computer Supported Cooperative Work\n(CSCW) , 2013.\n[145] J. S. Morgan, C. Lampe, and M. Z. Sha\fq. Is News Sharing on Twitter Ideolog-\nically Biased? In ACM Conference on Computer-Supported Cooperative Work\n(CSCW) , 2013.\n[146] S. Mullainathan and A. Shleifer. The Market for News. American Economic\nReview , pages 1031{1053, 2005.\n[147] S. U. Noble. Algorithms of Oppression: How Search Engines Reinforce Racism .\n2018.\n125\n[148] B. O'Connor, R. Balasubramanyan, B. R. Routledge, and N. A. Smith. From\nTweets to Polls: Linking Text Sentiment to Public Opinion Time Series. In\nAAAI International Conference on Weblogs and Social Media (ICWSM) , 2010.\n[149] A. Olteanu, C. Castillo, F. Diaz, and S. Vieweg. CrisisLex: A Lexicon for\nCollecting and Filtering Microblogged Communications in Crises. In AAAI\nInternational Conference on Weblogs and Social Media (ICWSM) , 2014.\n[150] A. Pansari and M. Mayer. This is a test. This is only a test. Google O\u000ecial\nBlog. http://bit.ly/2DngZbg , 2006.\n[151] E. Pariser. The Filter Bubble: How the New Personalized Web Is Changing\nWhat We Read and How We Think . The Penguin Group, 2012.\n[152] S. Park, S. Kang, S. Chung, and J. Song. NewsCube: Delivering Multiple\nAspects of News to Mitigate Media Bias. In ACM CHI , 2009.\n[153] M. Pennacchiotti and A.-M. Popescu. A Machine Learning Approach to Twitter\nUser Classi\fcation. AAAI International Conference on Weblogs and Social\nMedia (ICWSM) , 2011.\n[154] D. V. Phuong and T. M. Phuong. Gender Prediction Using Browsing History.\nInInternational Conference on Knowledge and Systems Engineering (KSE) ,\n2013.\n126\n[155] C. Puschmann. How signi\fcant is algorithmic personalization in searches for\npolitical parties and candidates? http://bit.ly/2fEhDqK , 2017.\n[156] C. Puschmann. How signi\fcant is algorithmic personalization in searches for\npolitical parties and candidates? (Part II). http://bit.ly/2E7n5KL , 2017.\n[157] E. Rader and R. Gray. Understanding User Beliefs About Algorithmic Curation\nin the Facebook News Feed. In Proceedings of the 33rd Annual ACM Conference\non Human Factors in Computing Systems (CHI) , 2015.\n[158] J. Ratkiewicz, M. Conover, M. Meiss, B. Gon\u0018 calves, S. Patil, A. Flammini, and\nF. Menczer. Truthy: Mapping the Spread of Astroturf in Microblog Streams.\nInProceedings of the 20th International Conference Companion on World Wide\nWeb (WWW) , 2011.\n[159] M.-A. Rizoiu, T. Graham, R. Zhang, Y. Zhang, R. Ackland, and L. Xie. #De-\nbateNight: The Role and In\ruence of Socialbots on Twitter During the 1st 2016\nU.S. Presidential Debate. In Proceedings of the 12th International Conference\non Web and Social Media (ICWSM) , 2018.\n[160] R. E. Robertson, S. Jiang, K. Joseph, L. Friedland, D. Lazer, and C. Wil-\nson. Auditing partisan audience bias within google search. In The 21st ACM\nConference on Computer-Supported Cooperative Work and Social Computing\n(CSCW'18) , 2018.\n127\n[161] R. E. Robertson, D. Lazer, and C. Wilson. Auditing the personalization and\ncomposition of politically-related search engine results pages. In The 29th In-\nternational World Wide Web Conference Committee (IW3C2) , 2018.\n[162] Y. Roth. Empowering further research of potential information opera-\ntions. https://blog.twitter.com/en_us/topics/company/2019/further_\nresearch_information_operations.htm , 2018.\n[163] Y. Roth and D. Harvey. How Twitter is \fghting spam and malicious automa-\ntion. https://blog.twitter.com/official/en_us/topics/company/2018/\nhow-twitter-is-fighting-spam-and-malicious-automation.html , 2018.\n[164] T. Rupar, A. Blake, and S. Granados. The ever-changing issues of the 2016\ncampaign, as seen on Twitter. http://wapo.st/1OgbJ45, December 2015.\n[165] S. Salvado and P. Chan. Determining the Number of Clusters/Segments in\nHierarchical Clustering/Segmentation Algorithms. In Proceedings of the 16th\nIEEE International Conference on Tools with Arti\fcial Intelligence (ICTAI) ,\npages 576{584, 2004.\n[166] C. Sandvig, K. Hamilton, K. Karahalios, and C. Langbort. Auditing Algo-\nrithms: Research Methods for Detecting Discrimination on Internet Platforms.\nInData and Discrimination , 2014.\n128\n[167] E. T. K. Sang and J. Bos. Predicting the 2011 Dutch senate election results\nwith Twitter. In Workshop on Semantic Analysis in Social Media (SASN) ,\n2012.\n[168] E. Scarry. See Which Top Conservative Journalists Attended on O\u000b-the-Record\nMeeting with Obama. http://bit.ly/1Rylkrp, October 2013.\n[169] M. Schwartz. Guidelines for Bias-Free Writing . ERIC, Bloomington, IN, USA,\n1995.\n[170] D. O. Sears and J. L. Freedman. Selective Exposure to Information: A Critical\nReview. Public Opinion Quarterly , 31(2):194{213, 1967.\n[171] SenateIntelligenceCommittee. Exhibit B. https://intelligence.house.gov/\nuploadedfiles/exhibit_b.pdf , 2017.\n[172] E. Shearer. Candidates social media outpaces their websites and emails as an\nonline campaign news source, 2016.\n[173] D. K. Simonton. Presidential Personality: Biographical Use of the Gough Ad-\njective Check List. Journal of Personality and Social Psychology , 51(1):149{160,\n1986.\n[174] M. Skoric and N. Poor. Tweets and votes: A study of the 2011 Singapore general\nelection. In Hawaii International Conference on System Sciences (HICSS) ,\n2012.\n129\n[175] A. Smith. Cell Phones, Social Media and Campaign 2014. Pew Research Center,\nNovember 2014.\n[176] T. Speicher, M. Ali, G. Venkatadri, F. N. Ribeiro, G. Arvanitakis, F. Ben-\nevenuto, K. P. Gummadi, P. Loiseau, and A. Mislove. On the Potential for\nDiscrimination in Online Targeted Advertising. In Conference on Fairness,\nAccountability, and Transparency (FAT*) , 2018.\n[177] T. Speicher, H. Heidari, N. Grgic-Hlaca, K. P. Gummadi, A. Singla, A. Weller,\nand M. B. Zafar. A uni\fed approach to quantifying algorithmic unfairness:\nMeasuring individual &group unfairness via inequality indices. In Proceedings\nof the 24th ACM SIGKDD International Conference on Knowledge Discovery\n& Data Mining (KDD) , 2018.\n[178] A. Stamos. An Update On Information Operations On Facebook.\nhttps://newsroom.fb.com/news/2017/09/information-operations-update/,\n2017.\n[179] A. Stamos. Authenticity Matters: The IRA Has No Place on Facebook.\nhttps://newsroom.fb.com/news/2018/04/authenticity-matters/, 2018.\n[180] N. Statt. Advertisers are furious with apple for new tracking restrictions\nin safari 11. https://www.theverge.com/2017/9/14/16308138/apple-safari-11-\nadvertiser-groups-cookie-tracking-letter, 2017.\n130\n[181] S. Stieglitz and L. X. Dang. Social media and political communication: a social\nmedia analytics framework. Social Network Analysis and Mining , 4(4):1277{\n1291, December 2013.\n[182] G. Stringhini, C. Kruegel, and G. Vigna. Detecting Spammers on Social Net-\nworks. In Annual Computer Security Applications Conference (ACSAC) , 2010.\n[183] N. Stroud. Polarization and Partisan Selective Exposure. Journal of Commu-\nnication , (60):556{576, 2010.\n[184] J. Su, A. Shukla, S. Goel, and A. Narayanan. De-anonymizing Web Browsing\nData with Social Networks. In ACM International Conference on World Wide\nWeb (WWW) , 2017.\n[185] J. Swales. Genre analysis: English in academic and research settings . 1990.\n[186] L. Sweeney. Discrimination in Online Ad Delivery. Queue , (11), 2013.\n[187] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended Accounts in Ret-\nrospect: An Analysis of Twitter Spam. In Internet Measurement Conference\n(IMC) , 2011.\n[188] C. Timberg and E. Dwoskin. Twitter is sweeping out fake accounts like never\nbefore, putting user growth at risk. https://wapo.st/2AMDior, 2018.\n131\n[189] A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe. Predicting\nElections with Twitter: What 140 Characters Reveal about Political Sentiment.\nInAAAI International Conference on Weblogs and Social Media (ICWSM) ,\n2010.\n[190] Twitter. About Suspended Accounts. https://help.twitter.com/en/\nmanaging-your-account/suspended-twitter-accounts , 2018.\n[191] Twitter. Update on Twitters review of the 2016 US election.\nhttps://blog.twitter.com/official/en_us/topics/company/2018/\n2016-election-update.html , 2018.\n[192] Twitter. Were focused on serving the public conversation. https://about.\ntwitter.com/en_us/values/elections-integrity.html , 2019.\n[193] J. Valentino-Devries, J. Singer-Vine, and A. Soltani. Websites vary prices, deals\nbased on users' information. https://on.wsj.com/2PrDboJ, 2012.\n[194] T. Vissers, N. Nikiforakis, N. Bielova, and W. Joosen. Crying wolf? on the\nprice discrimination of online airline tickets. In Workshop on Hot Topics in\nPrivacy Enhancing Technologies (HotPETs ) , 2014.\n[195] S. Volkova and E. Bell. Identifying E\u000bective Signals to Predict Deleted and\nSuspended Accounts on Twitter across languages. In AAAI International Con-\nference on Weblogs and Social Media (ICWSM) , 2017.\n132\n[196] M. Wagner, V. Rocha, S. Tatum, E. Levenson, B. Ries, P. P. Mur-\nphy, and J. Yeung. Suspect arrested after explosive devices sent\nto trump critics and cnn. https://www.cnn.com/politics/live-news/\nclintons-obama-suspicious-packages/index.html , 2018.\n[197] H. Wang, D. Can, A. Kazemzadeh, F. Bar, and S. Narayanan. A System for\nReal-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle.\nIn50th Annual Meeting of the Association for Computational Linguistics , pages\n115{120, July 2012.\n[198] C. E. Wills and C. Tatar. Understanding what they do with what they know.\nInACM Workshop on Privacy in the Electronic Society (WPES) , 2012.\n[199] L. Winner. The Social Shaping of Technology , chapter Do artifacts have poli-\ntics?, pages 28{40. Open University Press, UK, 2nd edition, 1999.\n[200] F. M. F. Wong, C. W. Tan, S. Sen, and M. Chiang. Quantifying Political\nLeaning from Tweets and Retweets. In AAAI International Conference on\nWeblogs and Social Media (ICWSM) , 2013.\n[201] D. B. Wood and A. Doan. The Politics of Problem De\fnition: A Theory\nand Application to Sexual Harassment. American Journal of Political Science ,\n47(4):640{653, October 2003.\n133\n[202] D. B. Wood and A. Vedlitz. Issue De\fnition, Information Processing, and the\nPolitics of Global Warming. American Journal of Political Science , 51(3):552{\n568, July 2007.\n[203] X. Xing, W. Meng, D. Doozan, N. Feamster, W. Lee, and A. C. Snoeren. Ex-\nposing inconsistent web search results with Bobble. In International Conference\non Passive and Active Network Measurement (PAM) , 2013.\n[204] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers\nSocial Networks for Fun and Pro\ft. In Proceedings of the 20th International\nConference Companion on World Wide Web , 2012.\n[205] F. A. Zamal, W. Liu, and D. Ruths. Homophily and latent attribute inference:\nInferring latent attributes of Twitter users from neighbors. AAAI International\nConference on Weblogs and Social Media (ICWSM) , 2012.\n[206] S. Zannettou, T. Caul\feld, E. D. Cristofaro, M. Sirivianos, G. Stringhini, and\nJ. Blackburn. Disinformation Warfare: Understanding State-Sponsored Trolls\non Twitter and Their In\ruence on the Web. https://arxiv.org/abs/1801.09288,\n2018.\n[207] S. Zannettou, T. Caul\feld, W. N. Setzer, M. Sirivianos, G. Stringhini, and\nJ. Blackburn. Who Let The Trolls Out? Towards Understanding State-\nSponsored Trolls. https://arxiv.org/pdf/1811.03130.pdf, 2019.\n134\n[208] A. X. Zhang and S. Counts. Modeling Ideology and Predicting Policy Change\nwith Social Media: Case of Same-Sex Marriage. ACM Conference on Human\nFactors in Computing Systems (CHI) , 2015.\n[209] D. X. Zhou, P. Resnick, and Q. Mei. Classifying the Political Leaning of News\nArticles and Users from User Votes. In AAAI International Conference on\nWeblogs and Social Media (ICWSM) , 2011.\n[210] D. Zillmann and J. Bryant. Selective Exposure to Communication . Routledge,\n2013.\n[211] H. G. d. Zuniga, T. Correa, and S. Valenzuela. Selective Exposure to Cable\nNews and Immigration in the U.S.: The Relationship Between FOX News,\nCNN, and Attitudes Toward Mexican Immigrants. Journal of Broadcasting and\nElectronic Media , 2012.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Understanding the Roles of Humans, algorithms, and cyborgs in political polarization", "author": ["HTT Le"], "pub_year": "2019", "venue": "NA", "abstract": "Recent studies revealed more increasingly political polarization in the distribution and  consumption of political news. Political polarization demonstrates the disagreement between"}, "filled": false, "gsrank": 391, "pub_url": "https://search.proquest.com/openview/1428d2cd47548770a3aa22094515ee3b/1?pq-origsite=gscholar&cbl=18750&diss=y", "author_id": ["3XZjNBYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:S77tKZdvw4YJ:scholar.google.com/&output=cite&scirp=390&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=S77tKZdvw4YJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:S77tKZdvw4YJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://iro.uiowa.edu/view/delivery/01IOWA_INST/12731092310002771/13731092300002771"}}]