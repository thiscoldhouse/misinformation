[{"title": "Hidden biases in unreliable news detection datasets", "year": "2021", "pdf_data": "Hidden Biases in Unreliable News Detection Datasets\nXiang Zhou1, Heba Elfardy2, Christos Christodoulopoulos2\nThomas Butler2, Mohit Bansal1\n1UNC Chapel Hill2Amazon\nfxzh, mbansalg@cs.unc.edu\nfhelfardy, tombutl g@amazon.com, chrchrs@amazon.co.uk\nAbstract\nAutomatic unreliable news detection is a re-\nsearch problem with great potential impact.\nRecently, several papers have shown promis-\ning results on large-scale news datasets with\nmodels that only use the article itself without\nresorting to any fact-checking mechanism or\nretrieving any supporting evidence. In this\nwork, we take a closer look at these datasets.\nWhile they all provide valuable resources for\nfuture research, we observe a number of prob-\nlems that may lead to results that do not gen-\neralize in more realistic settings. Speci\ufb01cally,\nwe show that selection bias during data collec-\ntion leads to undesired artifacts in the datasets.\nIn addition, while most systems train and pre-\ndict at the level of individual articles, overlap-\nping article sources in the training and evalua-\ntion data can provide a strong confounding fac-\ntor that models can exploit. In the presence\nof this confounding factor, the models can\nachieve good performance by directly memo-\nrizing the site-label mapping instead of mod-\neling the real task of unreliable news detec-\ntion. We observed a signi\ufb01cant drop ( >10%)\nin accuracy for all models tested in a clean\nsplit with no train/test source overlap. Us-\ning the observations and experimental results,\nwe provide practical suggestions on how to\ncreate more reliable datasets for the unreli-\nable news detection task. We suggest future\ndataset creation include a simple model as a\ndif\ufb01culty/bias probe and future model develop-\nment use a clean non-overlapping site and date\nsplit.1\n1 Introduction\nThe proliferation of unreliable news is widely ac-\nknowledged (Del Vicario et al., 2016; Lazer et al.,\n2018; V osoughi et al., 2018), and its identi\ufb01cation\n1Our code is publicly available at https://owenzx.\ngithub.io/unreliable_newsis a socially important problem. In this work we use\nthe label unreliable news as a broad term for all un-\nveri\ufb01able and misleading news content, regardless\nof whether the content is malicious (targeted mis-\ninformation) or not. Accordingly, while speci\ufb01c\nde\ufb01nitions vary in different datasets used in this\nwork, we refrain from using the term \u201cfake\u201d since\nidentifying the intent of the author(s) is beyond the\nscope of this work. To mitigate the problem of sur-\nfacing unreliable news content, various websites\n(e.g., PolitiFact2, Media Bias/Fact Check (MBFC)3,\nGossipCop4, etc.) determine the reliability of news\nby manually fact-checking the important claims in\ngiven news articles. Beyond requiring investigative\nexpertise, manual fact-checking is time-consuming\nand is thus limited to only a small set of selected\nnews articles.\nRecent research has explored automating this\nprocess using machine learning methods to auto-\nmatically determine news veracity (P \u00b4erez-Rosas\net al., 2018; Baly et al., 2018; Nie et al., 2019;\nWright and Augenstein, 2020). These efforts were\nmade possible due to the availability of large-scale\nunreliable news detection datasets (Horne et al.,\n2018b; Shu et al., 2017; Wang, 2017). In our work,\nwe examine if these datasets accurately re\ufb02ect the\nreal dif\ufb01culty of this task or if there are any hidden\nbiases in the datasets. Speci\ufb01cally, we study dif-\nferent methods of dataset construction (e.g., how\nthe data was collected, how the data was split, etc.)\nand show that the assessed dif\ufb01culty of the task\nis sensitive to how carefully different factors are\nconsidered when building and using these datasets.\nOur investigation begins with data collection pro-\ncedures: we look at the source of news stories\n(news outlets, social media, fact-checking websites,\netc.) as well as the annotation process (number of\n2https://www.politifact.com/\n3https://mediabiasfactcheck.com/\n4https://www.gossipcop.com/arXiv:2104.10130v1  [cs.CL]  20 Apr 2021\nData Collection Dataset Construction Experiment Design\n1.Collect from less biased or unbiased\nresources (e.g. original news out-\nlets). (Sec. 3.2)\n2.Collect from diverse resources (in\nterms of sources, topics, time, etc.).\n(Sec. 3.2, 4)\n3.Collect precise article-level labels if\npossible. (Sec. 3.1)1.Examine the most salient words to\ncheck for biases in the datasets. (Sec.\n3.2)\n2.Run simple BoW baselines to check\nhow severe the bias is. (Sec. 4)\n3.Provide train/dev/test splits with\nnon-overlapping source/time.\n(Sec. 4.2, 4.3)1.Apply debasing techniques when de-\nveloping models on biased datasets.\n(Sec. 3.2)\n2.Check the performance on\nsources/dates not in your training\nset. (Sec. 4.2, Sec. 4.3)\n3.Check the performance on sources\nwith limited examples. (Sec. 4.4)\n4.Test your model on multiple comple-\nmentary datasets (e.g. with different\ndomains, styles, etc.). (Sec. 3.2, 4.4)\nTable 1: Suggestions for data collection, dataset construction and experiment design for unreliable news research.\nlabels, granularity of labels, article- or site-level\nannotation). We discuss the pros and cons of each\napproach and point out some hidden pitfalls. Using\nFakeNewsNet (Shu et al., 2017) as an example, we\ndemonstrate how selection biases in data collection\ncan lead to undesired biases in the created datasets.\nMoving beyond data collection, we examine two\ncommonly applied ways of splitting the dataset for\ntraining and testing that help the model achieve\nhigh performance without correctly modeling the\ntask. Speci\ufb01cally, we show that using a disjoint set\nof sites/news outlets for training and test data signif-\nicantly decreases the models\u2019 performance ( >10%)\nand that the drop in performance is related to how\nsimilar (or dissimilar) the sites in both sets are (re-\n\ufb02ected by various site-level distributional distance\nmetrics including L2, cos, EMD, etc.). Addition-\nally, we also examine the effect of time overlap\nbetween both train and test sets. We observe that\ndifferent news outlets are likely to have similar con-\ntent in a small time window (i.e., the same story\ngets covered by multiple outlets within a day or a\nfew days period). While we do not \ufb01nd any evi-\ndence that the studied models exploit this factor, we\nnevertheless suggest that future datasets are split\nboth by time and site/news outlet.\nIn summary, our main contributions are: (1)\nshowing how data collection procedures can lead\nto systematic biases in unreliable news datasets, (2)\ndemonstrating how confounding factors\u2013\u2014such as\nsite/news outlet and time\u2014\u2013in these datasets can\ndegrade their quality and lead to underestimating\nthe dif\ufb01culty of the task, and \ufb01nally (3) suggest-\ning possible mechanisms to avoid these biases and\nconfounding factors when building new datasets.\nTo facilitate future research, we also provide a listof practical suggestions for data collection, dataset\nconstruction, and experiment design in Table 1.\n2 Related Work\nUnreliable News Detection. Unreliable news\ndetection and other news veracity related tasks have\nbeen receiving an increasing focus as news sources\nhave become more accessible in recent years. A lot\nof effort has been put into collecting high-quality\ndatasets. Wang (2017); Shu et al. (2017) collected\nmanually labeled statements or news articles from\nfact-checking websites. The NELA datasets (Horne\net al., 2018b; N\u00f8rregaard et al., 2019; Gruppi et al.,\n2020) scrape news articles directly from news out-\nlets and use the manually annotated labels from\nMedia Bias/Fact Check (MBFC) as site-level anno-\ntations. Social media is also a popular resource for\ncollecting news stories (Nakamura et al., 2020; San-\ntia and Williams, 2018; Mitra and Gilbert, 2015).\nResearchers have also collected datasets for vari-\nous related topics, such as rumor detection (Kwon\net al., 2017; Ma et al., 2016), and propaganda de-\ntection (Martino et al., 2020; Barr \u00b4on-Cedeno et al.,\n2019). Besides classifying the veracity of news ar-\nticles, researchers have also explored related prob-\nlems, such as predicting the reliability of news\nsites (Baly et al., 2018), identifying fact-check\nworthy sentences (Wright and Augenstein, 2020),\namong other tasks. Several recent papers also focus\non measuring the trustworthiness of single state-\nments (Wang, 2017; Pomerleau and Rao, 2017;\nAlhindi et al., 2018). In this work, we focus on\narticle-level classi\ufb01cation because of its relevance\nto applications, like news feeds, that operate at the\narticle level.\nDataset Size Article Source Label Type\nNELA5136K/713K/1.12M News outlets Site-level\nFakeNewsNet6603K Fact-checking websites Article-level\nr/Fakeddit71.06M Social Media (Reddit) Site-level\nTable 2: Statistics and properties of three recent large-scale unreliable news datasets. The three statistics of NELA\ndataset sizes correspond to its three versions released in 2017, 2018 and 2019, respectively.\nPitfalls in Data Collection. Datasets collected\nthrough crowd-sourcing or scraping the Internet\nhave the advantage of much better scalability com-\npared to expert-annotated datasets. However, these\nautomatic processes are prone to hidden pitfalls.\nGururangan et al. (2018); Poliak et al. (2018) show\nthat crowd-sourcing \u201cNatural Language Inference\u201d\ndatasets leads to various dataset biases. Similar\nobservations have been made for \u201cFact Veri\ufb01ca-\ntion\u201d datasets (Schuster et al., 2019). Splitting data\u2013\n\u2014for training, testing, and validation\u2014\u2013is another\nimportant procedure in creating datasets that can\nlead to several problems. For example, Geva et al.\n(2019) show that models may just learn the pat-\nterns of certain annotators in a random split. Lewis\net al. (2020a) demonstrated a signi\ufb01cant overlap in\ncurrent open-domain QA datasets. When present,\nthese unexpected biases or overlaps in datasets can\nsigni\ufb01cantly undermine the utility of a dataset and\nlead to deceptively promising results that are in\npart due to artifacts of \ufb02aws in the dataset rather\nthan successfully modeling the intended task.\nAutomated Fact Checking for Statements. Au-\ntomated fact checking is an important task closely\nrelated to unreliable news detection, yet is con-\nstructed in a more controlled manner. This task\nfocuses on strictly judging the factuality of one sin-\ngle statement instead of an entire article. Vlachos\nand Riedel (2014) \ufb01rst constructed a dataset with\n106 claims from fact-checking websites with paired\nlabels. FEVER (Thorne et al., 2018) is currently\nthe largest scale fact-veri\ufb01cation dataset, where\n185,445 claims were generated by modifying sen-\ntences from Wikipedia. Both the altered claims and\nthe ground truth supporting evidence are included\nin the dataset. Existing effective approaches for\nfact-veri\ufb01cation include self-attention based net-\nworks (Nie et al., 2019), large-scale pretrained\ntransformers (Soleimani et al., 2020), neural re-\ntrieval methods (Lewis et al., 2020b), and reasoning\n5dataverse.harvard.edu/dataverse/nela\n6github.com/KaiDMML/FakeNewsNet\n7github.com/entitize/Fakedditon semantic-level graphs (Zhong et al., 2020).\n3 Unreliable News Datasets\nCollecting high-quality datasets plays an impor-\ntant role in automatic unreliable news detection\nresearch. Here we review dataset collection strate-\ngies used in constructing recent datasets and point\nout some hidden pitfalls in these procedures.\n3.1 Data Collection Strategies\nUnreliable news detection is usually formalized as\na classi\ufb01cation task. Accordingly, constructing a\ndataset requires collecting pairs of news articles\nand labels.\nNews Articles: Each individual news outlet has\nits own website where news articles are published.\nThe easiest way to collect a large number of these\narticles is to simply scrape these websites. Man-\nual annotation or some other mechanism must then\nbe incorporated in order to collect the correspond-\ning labels for each article. Another common way\nto collect articles is through fact-checking web-\nsites. While this approach provides both articles\nand article-level labels, it normally only provides a\nlimited set of articles. Additionally, scraping these\nfact-checking websites can lead to additional selec-\ntion bias in the dataset as highlighted in Section\n3.2.\nOne other recent trend is collecting posts and\ncorresponding labels from social media (Nakamura\net al., 2020; Santia and Williams, 2018; Mitra and\nGilbert, 2015). While large-scale datasets can be\ncollected through such an approach, they are of-\nten noisier than those collected through traditional\nnews sources, due to a more casual use of language,\nand a heavier dependency on the context.\nNews Labels: The largest challenge in collect-\ning these datasets lies in collecting labels. Man-\nually checking the factuality (or reliability) and\nbias of a single article is time-consuming and\nrequires non-trivial expertise. Modeling such a\ntask through a crowd-sourcing framework is dif\ufb01-\nFakeNewsNet r/Fakeddit\nPositive Features Negative Features Positive Features Negative Features\nseason trump psbattle clicks\nat brad says colorized\n2018 pitt sues 2018\nthe jenner accused 2019\nawards jenni\ufb01er sells mrw\nTable 3: Top \ufb01ve most salient features in the FakeNewsNet dataset and the r/Fakeddit dataset. The features are the\nhighest weighted Bag-of-Word features learned by a Logistic Regression model.\nNews Outlets Daily Mail\nSite Label Unreliable\nDates 2018/09/06\nTitle Roy Moore sues Sasha Baron Cohen\nArticle Failed Senate candidate Roy Moore is\nsuing comedian Sacha Baron Cohen for\n$95 million for tricking him into appear-\ning on his Showtime program \u2019Who is\nAmerica?\u2019 Moore, whose bid for the Al-\nabama failed in the wake of claims he\nmolested a 14-year-old, \ufb01led the lawsuit\nin Washington DC on Wednesday...\nTable 4: An example showing a reliable news article\nfrom the \u201c Daily Mail \u2019 site which has a \u201cLow\u201d factual\nreporting rate on MBFC. Despite coming from a source\nwith low reliability score, the shown article is reliable\nand very similar to the content on sites with high relia-\nbility scores (such as \u201cBBC\u201d and\u201cThe Week UK\u201d ) on\nthe same date.\ncult. As such, current research datasets almost\nexclusively rely on existing resources. As dis-\ncussed earlier, these resources either provide article-\nlevel or site-level labels. Article-level labels are\nonly available through a few fact-checking web-\nsites such as PolitiFact, GossipCop, etc., but the\nscale is limited since generating these labels is\ntime-consuming and costly. Site-/Outlet-level la-\nbels, on the other hand, available through web-\nsites such as MBFC, provide manual labels for\neach site/outlet. These websites often assign reli-\nable/unreliable or biased/unbiased labels to each\nnews outlet. Many datasets for unreliable news de-\ntection assign these site-level labels to all articles\nin a given site. While these weak or distant labels\nare not always accurate (one example is shown\nin Table 4) , they provide an easy way to create\nlarge-scale datasets. In Table 2, we highlight three\nrecent large-scale unreliable news datasets along\nwith their data collection procedure.3.2 Dataset Selection Biases\nDatasets annotated without expert veri\ufb01cation (e.g.,\nthrough crowdsourcing, automatic web scraping,\netc.) can have some undesired properties that under-\nmine their quality (Gururangan et al., 2018; Poliak\net al., 2018; Schuster et al., 2019). In the following\nanalysis, we choose the FakeNewsNet dataset (Shu\net al., 2017) as a representative example.\nWe \ufb01rst examine the most salient features in the\ndataset. To achieve this, we train a Logistic Re-\ngression (LR) model on the titles of FakeNewsNet\nusing Bag-of-Words features and show the word\nfeatures with the highest weights for each class\nin Table 3.8The features in the table show clear\npatterns: the top-features for the reliable (positive)\nclass are either stop words (e.g., \u2018at\u2019, \u2018the\u2019, etc.)\nor words presumably carrying neutral semantics\n(e.g. \u2018season\u2019, \u20182018\u2019, \u2018awards\u2019, etc.) while the top\nfeatures for the unreliable news (negative) class are\nmostly celebrity names. Using this basic model,\nwe achieve an accuracy of \u001878% , while using a\nBERT-based model that uses both the article and\ntitle as input only achieves an incremental improve-\nment yielding an accuracy of 81% (see Sec. 4.1\nfor detailed model descriptions). By examining the\narticles in the dataset, we attribute this to the selec-\ntion bias exhibited by fact-checking websites. Most\nunreliable (negative) articles contain click-bait ti-\ntles mentioning celebrities, while reliable sources\nusually have less sensational titles with fewer men-\ntions of celebrities and more diverse keywords.\nAnother potential problem is the articles\u2019 re-\ntrieval framework. FakeNewsNet uses Google\nsearch to retrieve the original news article (Shu\net al., 2017). Internet search engines have pro-\nprietary news ranking and veri\ufb01cation processes,\nwhich means that even when using the original ti-\ntle and source of a given article, the search results\n8We also calculated the PMI between the label and word\nfeatures as suggested by Gururangan et al. (2018) and found\nthe two lists to be very similar.\nLabel Resource GossipCop\nTitle NYC terror attack: Celebrities react on\nsocial media\nArticle Celebrities are sending their love and\nsupport to New York on social media\nfollowing a terror attack that left eight\npeople dead Tuesday when a truck\nplowed down pedestrians on a bicycle\npath near the World Trade Center in\nLower Manhattan...\nLabel Unreliable\nNews URL tinyurl.com/yxhvdne6\nTable 5: One example from the FakeNewsNet dataset\nwhere it is dif\ufb01cult for the article content to support the\nlabel. This article contains celebrities\u2019 reactions after\na terrorist attack. While the article itself does not look\nlike a standard news piece, the reactions in the article\nare all paired with tweets, so the unreliable label seems\nto be inconsistent.\nmight prioritize speci\ufb01c sites over others leading to\ninaccurate data collection. While Shu et al. (2017)\npropose several heuristics to handle these problems,\nit is unlikely that this noisy process is completely\n\ufb01xed. As a result, we \ufb01nd a few mis-matched title-\ncontent pairs where the retrieved article cannot sup-\nport the label, hence making the example confusing.\nWe show one example with a questionable label in\nTable 5, where we suspect the inconsistency is due\nto the noisy retrieval step.\nFinally, the informal nature of user-generated\ncontent on social media may be the source of addi-\ntional biases. In our preliminary experiments, we\nfound that in r/Fakeddit dataset, a simple Bag-of-\nWords(BoW)-based logistic regression model can\nreach equal\u2014or even better\u2014performance than the\nreported BERT-based models (86.91% vs. 86.44%\nin the text-only two-way classi\ufb01cation setting),\nhinting at the strong correlation between the la-\nbel and lexical inputs. This is also re\ufb02ected in\nthe equally confusing most salient features in this\ndataset shown in Table 3.\nSince different collection procedures and data\nresources will lead to different problems, there is\nno uniform solution to producing a completely bias-\nfree dataset. However, one good test is to check the\nperformance of a simple model such as a BoW-\nbased linear model. By analyzing the features\nlearned by the simple model as well as measuring\nthe gap between the performance of a state-of-the-\nart system and the simple model, one can get a\nhint of the dataset quality. Unreasonable features,together with small performance gaps, may reveal\nunwanted biases in the dataset. In practice, we also\nsuggest that when developing models using biased\ndatasets to use debiasing techniques (e.g. Schuster\net al. (2019)).\n4 Dataset Split Effect\nIn this section, we study the effect of time and\nsite/outlet overlap between the training and the eval-\nuation set on the model\u2019s performance and show\nhow these confounding factors can impact it.\n4.1 Baseline Models & Experimental Setup\nIn the following experiments, we use two models:\na logistic regression baseline and a state-of-the-\nart large-scale pretrained Transformer-based model\n(RoBERTa; Liu et al. (2019)).\nLogistic Regression (LR): We use scikit-learn\u2019s\n(Pedregosa et al., 2011) implementation of Logistic\nRegression along with TFIDF-based Bag-of-Words\nfeatures. We add L2 regularization to the model\nwith a regularization weight of 1:0and train the\nmodel using L-BFGS. In our experiments, the LR\nmodel uses only the title (and not the article body)\nas the input.\nRoBERTa: Our implementation is based on the\nTransformers library (Wolf et al., 2019) and Al-\nlenNLP (Gardner et al., 2017). We use RoBERTa\nin two different ways, one takes only the title as\nthe input, the other takes both the title and the arti-\ncle content as the input and formalizes the task as\npairwise sentence classi\ufb01cation. Speci\ufb01cally, we\nconcatenate the title and the article content with a\n[SEP] token in the middle and use different to-\nken type embeddings to differentiate between the\ntitle and the content. Articles are truncated to \ufb01t\nthe 512-token length limit. In the title-only setting,\nthe batch size is set to 32, the learning rate is set\nto 5e-5, and the model is trained for 3 epochs. In\nthe article+title setting, the batch size is set to 8,\nthe learning rate is set to 2e-5, and the model is\ntrained for 10 epochs. These hyperparameters are\nset empirically, and our preliminary experiments\nshow that the results are not sensitive to different\nsettings of these hyperparameters.\nDatasets: Here, our analysis focuses on the 2018\nversion of the NELA dataset (Horne et al., 2018b).\nUnlike FakeNewsNet, NELA gathers news directly\nfrom news outlets, so the in\ufb02uence of selection\nbias is insigni\ufb01cant. Thus we focus our analysis on\nModel Input Random Split Source Split (Article) Source Split (Site)\nMajority / 50 50 69.29 (0.56)\nLR Title 77.45 67.18 (4.13) 79.28 (5.27)\nRoBERTa Title 85.22 70.40 (4.28) 87.83 (10.44)\nRoBERTa Title+Article 96.94 80.36 (11.91) 85.14 (8.00)\nTable 6: Accuracy on validation sets with different split strategies. For \u201cSource Split\u2019, we report the mean and\nstandard deviation (in parentheses) of \ufb01ve different runs. The last column shows the aggregated site-level accuracy.\nother potentially confounding factors in the dataset.\nWe use the latest aggregated site-level labels pro-\nvided in NELA-GT-2019 (Gruppi et al., 2020) and\nreport both the article- and site-level accuracy. For\narticle-level accuracy, we assign the site-level label\nto all articles from that news outlet and calculate\nper-article accuracy. For the Source (Site) Split\nsetting (with no overlap between training and eval-\nuation sites), we also report the site-level accuracy:\nwe aggregate the predictions over individual arti-\ncles for a given outlet and use the majority predic-\ntion as the site-level prediction. We use a balanced\nlabel distribution for all dataset splits.\nThe results in the third column of Table 6 show\nthe models\u2019 performance on the random split,\nwhich is the default split method used in most pa-\npers, e.g. (Nakamura et al., 2020; Horne et al.,\n2018a). As the results show, even the simplest lo-\ngistic regression model achieves an accuracy of\nover 77% whereas the RoBERTa model using both\ntitle and the news article as the input reaches almost\n97% accuracy.\n4.2 Effect of Split by Source\nFor this experiment, instead of using the standard\nrandom split of all the news articles in the dataset,\nwe \ufb01rst randomly split all the sites in the dataset\ninto three disjoint sets (train/dev/test) before adding\nall articles from each site to their assigned set (train,\ndev or test). We believe this setup is closer to\nreal-world tasks. For instance, in order to block\nall unreliable news sources, one simple\u2014yet use-\nful\u2014approach is to maintain a list of questionable\nsources. All the news from those sources will be\nautomatically blocked. In this setting, the only re-\nmaining task is classifying sources with no or very\nfew annotated examples. As the results in Table 6\nshow, there is a signi\ufb01cant drop in performance\nfor all the models when compared to the random\nsplit. The logistic regression model\u2019s performance\ndrops from 77.5 to 67.2%, and even the more pow-\nerful RoBERTa model with both title and article\nas input drops from 96.9 to 80.4%, demonstratingModel Input Gold Label Rand. Label\nMajority / 50 50\nLR Title 77.45 66.29\nRoBERTa Title 85.22 74.37\nRoBERTa Title+Article 96.94 95.04\nTable 7: Article-level accuracy for the random label ex-\nperiments compared to gold site labels.\nthe task\u2019s signi\ufb01cantly increased dif\ufb01culty. While\naggregating article-level results to site-levels can\nsigni\ufb01cantly improve the accuracy, we also see a\nplateauing trend of the performance where adding\nthe article as additional input brings no further im-\nprovement to the RoBERTa model. Since we sub-\nsample the original dataset and balance the number\nof news articles for each label, the majority base-\nline (at the article level) is always 50%. But the\nsite-level majority baseline is well above random\n(69.29%). While a new 50% majority baseline can\nbe achieved by re-subsampling the dataset, the cur-\nrent number also indicates a severe imbalance of\ndataset size between reliable/unreliable sites which\ncan\u2014potentially\u2014be exploited by the models.\nRandom Label Experiments: For this experi-\nment, we use the original random split strategy.\nHowever, we permute all the site-level labels ran-\ndomly. Hence each label no longer represents the\nreliability of the site, and is just an arbitrary feature\nof the site itself. Therefore, the only way for the\nmodels to achieve good performance on this task is\nto memorize the arbitrary site-label mapping. The\nresults in Table 7 show that the models achieve very\nhigh accuracy with the more powerful RoBERTa\nmodel with both title and article showing only /tildelow2%\naccuracy loss when compared to the true labels.\nThese results demonstrate the models\u2019 ability to\nmemorize random site-labels, and the similarity\nbetween these results and the results on the random\nsplits suggest that the models are bypassing the real\ntask of reliable/unreliable news classi\ufb01cation and\nare just memorizing the site identities.\nDistance Top 10 Sites Bottom 10 Sites\nl2 11.59 5.79\ncosine 210.72 82.91\nMMD 7.78 4.20\nCORAL 29.07 14.95\nTable 8: Average similarity score between sites in the\nevaluation and training sets.\nPerformance Variance and Site Similarity Anal-\nysis: Another interesting observation from the re-\nsults in Table 6 is that while the performance on\nevery random split is fairly stable, the performance\nis much more unstable with respect to splitting by\nsource. For example, the RoBERTa (Title+Article)\nmodel results have a standard deviation larger than\n10 points, with the highest accuracy reaching over\n90% and the lowest one below 60%.\nOne potential factor behind the varying per-\nformance is the heterogeneity of different news\nsources (sites). News sites that are similar to those\nin the training set could be much easier to clas-\nsify than sites with completely different styles or\ncontent. In this case, even when splitting by site,\ncorrelations between the content of similar sites\nin the training and evaluation sets may drive the\ngeneralization performance. To assess this hypoth-\nesis, we measure the dependence on the distances\nbetween sites in the training and evaluation sets\nand the model performance at the site level in the\nevaluation set. Given a set sin the evaluation set,\nwe measure its similarity to all the sites in the train-\ning set t2Strain. Below we show that higher\naccuracy on the site sis associated with a higher\nsimilarity between sand sites in the training set\nwith the same label t2Ssame, providing evidence\nin favor of our hypothesis.\nIn order to measure the similarity between dif-\nferent sites, we take the representation learned by\nthe RoBERTa model as the representation of the\narticle with a focus on its reliability. Since the\nRoBERTa model feeds the whole sentence into the\nmulti-layer transformer architecture and feeds the\nrepresentation of [CLS] token to the downstream\nclassi\ufb01er (Devlin et al., 2019; Liu et al., 2019), we\nuse the same [CLS] representation as the repre-\nsentation for the whole title+article input.\nFor similarity-metrics between sites, we follow\nGuo et al. (2020) and calculate the l2-distance, co-\nsine distance, MMD (maximum mean discrepancy)\ndistance (Gretton et al., 2012; Li et al., 2015) and\nthe CORAL (correlation alignment) distance (Sunand Saenko, 2016; Sun et al., 2016). Following\nGuo et al. (2020), the l2 and cosine distances\nare calculated by \ufb01rst averaging all the exam-\nple representations to get the site representation\nand calculating the distance between site repre-\nsentations; the MMD distance is calculated using\nan unbiased \ufb01nite sample estimate from Li et al.\n(2015); and the CORAL distance is calculated by\nDCORAL =1\n4d2kCs\u0000Ctk2\nF, where dis the feature\ndimension, CsandCtare the co-variance of two\nsets andk\u0001k2\nFis the squared matrix Frobenius norm.\nTo simplify our analysis, we \ufb01lter out all the sites\ncontaining less than 100 examples (assuming the\narticles from these sites are too few to signi\ufb01cantly\nin\ufb02uence the model). For every site in the evalu-\nation set s, we calculate its distance with respect\nto every different site tin the training set, and then\ncompare its minimum distance w.r.t the subset of\nsites with the same gold label Ssame and the subset\nof sites with the opposite label Soppo,\nsim score s=min\nt2Soppofdist(s; t)g\nmin\nt2Ssamefdist(s; t)g\nWe compute this ratio using all four distances\nabove for the top and bottom 10 sites in the evalua-\ntion datasets (ranked based on their accuracy with\nRoBERTa) and report the mean over all the sites\nand over all \ufb01ve different random splits in Table 8.\nThe top 10 sites always have a much larger similar-\nity score than the bottom 10 sites, indicating that\nthey have a much larger similarity with sites in the\ntraining sets with the same label. This trend holds\nacross all of the distance metrics. The sensitivity of\nperformance on the site similarity raises additional\nconcerns about how the results in Table 6 may gen-\neralize in real-life. As newly emerged unreliable\nsites are likely to behave differently from old sites,\nthe model\u2019s performance may be on the lower end\nof the variance.\nAs a natural extension, we also explored build-\ning a model that directly optimizes these site-level\ndistance metrics in order to have better site-level\ngeneralization performance. However, in our pre-\nliminary results, our model does not show signi\ufb01-\ncant improvement from the baseline models. This\ncan also hint at the fact that it is very dif\ufb01cult for\nthese models to extract features that are useful to\nthe task of reliable/unreliable news classi\ufb01cation\nitself and instead learn site-speci\ufb01c features.\nJan. Feb. Mar. Apr. May June July Aug. Sept. Oct. Nov. Dec.\nMonths in 20196065707580859095Accuracy\nFigure 1: Accuracy of RoBERTa models trained on\nNELA-GT-2018 and tested on articles from the 12\nmonths covered in the NELA-GT-2019 dataset. The\n\ufb01ve different lines in the \ufb01gure represent models\ntrained using \ufb01ve different random site splits.\n4.3 Effect of Split By Time\nAnother potentially important factor to consider\nwhile creating train/test/dev splits for a news-based\ndataset is time. As news-worthy events happen\neveryday, multiple news articles from different out-\nlets can report the same event. For example, in\nthe NELA 2018 dataset (N\u00f8rregaard et al., 2019),\nwithin a period of two days (from 2018/10/01 to\n2018/10/02), there are more than 100 news articles\nfrom over 60 sources about the US-Canada-Mexico\ntrade accord. Therefore, by remembering the con-\ntent of the event from one article, the model can\neasily predict the label for any related news article.\nTo test the effect of time, we examine the\nmodel\u2019s performance on news articles from a\ntemporally disjoint dataset. Speci\ufb01cally, since\nall our models are trained on the NELA-GT-\n2018 (N\u00f8rregaard et al., 2019), we use the NELA-\nGT-2019 (Gruppi et al., 2020) as the evaluation\ndataset. We split the news articles in 2019 into\ntwelve months and plot the performance trend in\nFigure 1. We can see that, unlike the signi\ufb01cant per-\nformance drop in the source split experiments, we\ndo not observe a clear correlation between the per-\nformance and the length of the time gap. Therefore,\nat least for the current models and datasets, splitting\nby time does not signi\ufb01cantly in\ufb02uence the current\nresults. This \ufb01nding may result from that the fact\nthat the model is not memorizing the exact events in\nthe training set (this is not limited to the unreliable\nnews domain), or it could be attributed to the noise\nin the training set (similar events can be reportedboth in reliable and unreliable sources). However,\nwe do have to point out that our current observation\nonly holds for the current models, and it is possible\nfor more powerful models to memorize all events.\nIn addition, the widest time gap tested here is still\nwithin a couple of years, which is still a relatively\nshort time in terms of news events. A longer time\ngap (or a major event such as COVID-19) may lead\nto different behavior by the models. So in practice,\nwe nonetheless suggest splitting datasets by time\nto avoid these issues.\n4.4 Error Analysis\nHere, we conduct an error analysis to see how the\nmodel performs with respect to the variation of\nsome other factors of practical interest, such as\ntopic and site size.\nThe In\ufb02uence of Topic in Article-Level Predic-\ntion: In order to gain better insight on the per-\nformance drop in the source split experiments, we\nperform a deeper investigation of the numbers in\nTable 6. We \ufb01rst check whether the models show\ndifferent performance on different topics. To get\na high-level understanding of what the topics are,\nwe look at the titles of articles in the evaluation set\nand calculate words with the highest PMI with the\naccuracy of prediction of the RoBERTa model. We\nthen use these PMI values as weights and plot the\nword cloud \ufb01gures in Figure 2. In the word cloud\nof correct predictions, we observe many words re-\nlated to sports events, while words in the incorrect\npredictions cloud mostly appear in political news.\nThis is not surprising since there is much more of\nan incentive to interfere with political news than\nsports news \u2014 making the need for more robust\nmodels even more pressing for real-world applica-\ntions.\nThe In\ufb02uence of Size in Site-Level Prediction:\nFinally, we examine the effect of prediction aggre-\ngation from article-level to site-level. Unlike in cur-\nrent datasets where most sites can have hundreds or\neven thousands of articles, a newly-emerged news\noutlet waiting for classi\ufb01cation may only have a\nvery limited number of articles. Accordingly, while\nin Table 6, we see a general improvement of the\naggregation, it is also important to check the aggre-\ngation effect when the number of articles in a given\nsite is small.\nIn Figure 3 we plot the performance of 5 dif-\nferent runs of the RoBERTa (Title+Article) model\nagainst the number of articles on a given site. We\n(a) Word cloud of article titles with correct\npredictions.\n(b) Word cloud of article titles with incorrect\npredictions.\nFigure 2: Word cloud of article titles. The words with highest PMI to the prediction correctness of the RoBERTa\nmodel are selected.\n101102103104\nSite SizeWrong\nCorrectCorrect/Wrong Prediction\nFigure 3: Site-level prediction accuracy of the RoBERTa (Title+Article) model vs. numbers of article in the site\n(in all \ufb01ve random runs). Blue circles denote wrong predictions and red circles denote correct predictions.\ncan see that the performance is worse when the\nsize of the site is less than 100, demonstrating the\ndif\ufb01culty of predicting the reliability of a site given\nlimited resources. It is also surprising to see a sig-\nni\ufb01cant number of errors even when the site size is\nover 1000. This indicates the limitation of simply\naggregating the site-level prediction at test-time.\nCapturing the article-site hierarchy in a better way\nis a potential future research direction.\n5 Conclusion\nIn this paper, we took a closer look at current large-\nscale unreliable news detection datasets. We stud-\nied their collection procedures and dataset split\nstrategies, and pointed out important \ufb02aws in the\ncurrent approaches. Speci\ufb01cally, we demonstrated\nthat selection bias in dataset collection that often\nleads to undesired and signi\ufb01cant artifacts in these\ndatasets; highlighting confounding factors (e.g., ar-\nticle source, time) in news datasets that can lead to\nunderestimating the dif\ufb01culty of the task. Finally\nwe provide suggestions on how to better create and\nprocess such datasets in the future. We hope our\nwork leads to more high-quality news datasets and\nthat it inspires further work in this direction.Acknowledgments\nWe thank the reviewers for their helpful comments.\nXZ interned at Amazon. This work was also sup-\nported by ONR Grant N00014-18-1-2871, DARPA\nYFA17-D17AP00022, and DARPA KAIROS Grant\nFA8750-19-2-1004. The views contained in this ar-\nticle are those of the authors and not of the funding\nagency.\nReferences\nTariq Alhindi, Savvas Petridis, and Smaranda Mure-\nsan. 2018. Where is your evidence: Improving fact-\nchecking by justi\ufb01cation modeling. In Proceedings\nof the First Workshop on Fact Extraction and VER-\ni\ufb01cation (FEVER) , pages 85\u201390, Brussels, Belgium.\nAssociation for Computational Linguistics.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 3528\u20133539.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nMichela Del Vicario, Alessandro Bessi, Fabiana Zollo,\nFabio Petroni, Antonio Scala, Guido Caldarelli,\nH Eugene Stanley, and Walter Quattrociocchi. 2016.\nThe spreading of misinformation online. Pro-\nceedings of the National Academy of Sciences ,\n113(3):554\u2013559.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In NAACL-HLT (1) .\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind\nTafjord, Pradeep Dasigi, Nelson F. Liu, Matthew\nPeters, Michael Schmitz, and Luke S. Zettlemoyer.\n2017. Allennlp: A deep semantic natural language\nprocessing platform. arXiv:1803.07640 .\nMor Geva, Yoav Goldberg, and Jonathan Berant. 2019.\nAre we modeling the task or the annotator? an inves-\ntigation of annotator bias in natural language under-\nstanding datasets. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP) , pages 1161\u20131166.\nArthur Gretton, Karsten M Borgwardt, Malte J Rasch,\nBernhard Sch \u00a8olkopf, and Alexander Smola. 2012. A\nkernel two-sample test. The Journal of Machine\nLearning Research , 13(1):723\u2013773.\nMaur \u00b4\u0131cio Gruppi, Benjamin D Horne, and Sibel Adal\u0131.\n2020. Nela-gt-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. arXiv preprint arXiv:2003.08444 .\nHan Guo, Ramakanth Pasunuru, and Mohit Bansal.\n2020. Multi-source domain adaptation for text clas-\nsi\ufb01cation via distancenet-bandits. In AAAI , pages\n7830\u20137838.\nSuchin Gururangan, Swabha Swayamdipta, Omer\nLevy, Roy Schwartz, Samuel R Bowman, and\nNoah A Smith. 2018. Annotation artifacts in natu-\nral language inference data. In NAACL-HLT (2) .\nBenjamin D Horne, William Dron, Sara Khedr, and\nSibel Adali. 2018a. Assessing the news landscape:\nA multi-module toolkit for evaluating the credibility\nof news. In Companion Proceedings of the The Web\nConference 2018 , pages 235\u2013238.\nBenjamin D Horne, William Dron, Sara Khedr, and\nSibel Adali. 2018b. Sampling the news producers:\nA large news and feature data set for the study of\nthe complex media landscape. In Proceedings of the\nInternational AAAI Conference on Web and Social\nMedia .\nSejeong Kwon, Meeyoung Cha, and Kyomin Jung.\n2017. Rumor detection over varying time windows.\nPloS one , 12(1):e0168344.David MJ Lazer, Matthew A Baum, Yochai Ben-\nkler, Adam J Berinsky, Kelly M Greenhill, Filippo\nMenczer, Miriam J Metzger, Brendan Nyhan, Gor-\ndon Pennycook, David Rothschild, et al. 2018. The\nscience of fake news. Science , 359(6380):1094\u2013\n1096.\nPatrick Lewis, Pontus Stenetorp, and Sebastian Riedel.\n2020a. Question and answer test-train overlap in\nopen-domain question answering datasets. arXiv\npreprint arXiv:2008.02637 .\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K \u00a8uttler, Mike Lewis, Wen-tau Yih,\nTim Rockt \u00a8aschel, Sebastian Riedel, and Douwe\nKiela. 2020b. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In Advances in\nNeural Information Processing Systems 33: Annual\nConference on Neural Information Processing Sys-\ntems 2020, NeurIPS 2020, December 6-12, 2020,\nvirtual .\nYujia Li, Kevin Swersky, and Rich Zemel. 2015.\nGenerative moment matching networks. In Inter-\nnational Conference on Machine Learning , pages\n1718\u20131727.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nJing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon,\nBernard J Jansen, Kam-Fai Wong, and Meeyoung\nCha. 2016. Detecting rumors from microblogs with\nrecurrent neural networks. In 25th International\nJoint Conference on Arti\ufb01cial Intelligence, IJCAI\n2016 , pages 3818\u20133824. International Joint Confer-\nences on Arti\ufb01cial Intelligence.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00b4on-Cede \u02dcno, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020. A survey on computa-\ntional propaganda detection. In Proceedings of the\nTwenty-Ninth International Joint Conference on Ar-\nti\ufb01cial Intelligence, IJCAI 2020 , pages 4826\u20134832.\nijcai.org.\nTanushree Mitra and Eric Gilbert. 2015. Credbank: A\nlarge-scale social media corpus with associated cred-\nibility annotations. In ICWSM , pages 258\u2013267.\nKai Nakamura, Sharon Levy, and William Yang Wang.\n2020. Fakeddit: A new multimodal benchmark\ndataset for \ufb01ne-grained fake news detection. In Pro-\nceedings of The 12th Language Resources and Eval-\nuation Conference , pages 6149\u20136157.\nYixin Nie, Haonan Chen, and Mohit Bansal. 2019.\nCombining fact extraction and veri\ufb01cation with neu-\nral semantic matching networks. In Proceedings of\nthe AAAI Conference on Arti\ufb01cial Intelligence , vol-\nume 33, pages 6859\u20136866.\nJeppe N\u00f8rregaard, Benjamin D Horne, and Sibel Adal\u0131.\n2019. Nela-gt-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In Proceedings of the International AAAI Con-\nference on Web and Social Media , volume 13, pages\n630\u2013638.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research ,\n12:2825\u20132830.\nVer\u00b4onica P \u00b4erez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401, Santa Fe, New Mexico, USA.\nAssociation for Computational Linguistics.\nAdam Poliak, Jason Naradowsky, Aparajita Haldar,\nRachel Rudinger, and Benjamin Van Durme. 2018.\nHypothesis only baselines in natural language in-\nference. In Proceedings of the Seventh Joint Con-\nference on Lexical and Computational Semantics ,\npages 180\u2013191.\nDean Pomerleau and Delip Rao. 2017. The fake news\nchallenge: Exploring how arti\ufb01cial intelligence tech-\nnologies could be leveraged to combat fake news.\nFake News Challenge .\nGiovanni C Santia and Jake Ryland Williams. 2018.\nBuzzface: A news veracity dataset with facebook\nuser commentary and egos. In Twelfth International\nAAAI Conference on Web and Social Media .\nTal Schuster, Darsh Shah, Yun Jie Serene Yeo, Daniel\nRoberto Filizzola Ortiz, Enrico Santus, and Regina\nBarzilay. 2019. Towards debiasing fact veri\ufb01cation\nmodels. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n3410\u20133416.\nKai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and\nHuan Liu. 2017. Fake news detection on social me-\ndia: A data mining perspective. ACM SIGKDD Ex-\nplorations Newsletter , 19(1):22\u201336.\nAmir Soleimani, Christof Monz, and Marcel Worring.\n2020. Bert for evidence retrieval and claim veri\ufb01-\ncation. In European Conference on Information Re-\ntrieval , pages 359\u2013366. Springer.\nBaochen Sun, Jiashi Feng, and Kate Saenko. 2016. Re-\nturn of frustratingly easy domain adaptation. In Pro-\nceedings of the Thirtieth AAAI Conference on Arti\ufb01-\ncial Intelligence , pages 2058\u20132065.\nBaochen Sun and Kate Saenko. 2016. Deep coral:\nCorrelation alignment for deep domain adaptation.\nInEuropean conference on computer vision , pages\n443\u2013450. Springer.James Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFever: a large-scale dataset for fact extraction and\nveri\ufb01cation. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long Papers) , pages\n809\u2013819.\nAndreas Vlachos and Sebastian Riedel. 2014. Fact\nchecking: Task de\ufb01nition and dataset construction.\nInProceedings of the ACL 2014 Workshop on Lan-\nguage Technologies and Computational Social Sci-\nence, pages 18\u201322.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nWilliam Yang Wang. 2017. \u201cliar, liar pants on \ufb01re\u201d:\nA new benchmark dataset for fake news detection.\nInProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n2: Short Papers) , pages 422\u2013426.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R \u00b4emi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2019.\nHuggingface\u2019s transformers: State-of-the-art natural\nlanguage processing. ArXiv , abs/1910.03771.\nDustin Wright and Isabelle Augenstein. 2020. Fact\ncheck-worthiness detection as positive unlabelled\nlearning. arXiv preprint arXiv:2003.02736 .\nWanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu,\nNan Duan, Ming Zhou, Jiahai Wang, and Jian Yin.\n2020. Reasoning over semantic-level graph for fact\nchecking. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics ,\npages 6170\u20136180, Online. Association for Computa-\ntional Linguistics.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Hidden biases in unreliable news detection datasets", "author": ["X Zhou", "H Elfardy", "C Christodoulopoulos"], "pub_year": "2021", "venue": "arXiv preprint arXiv \u2026", "abstract": "Automatic unreliable news detection is a research problem with great potential impact.  Recently, several papers have shown promising results on large-scale news datasets with"}, "filled": false, "gsrank": 269, "pub_url": "https://arxiv.org/abs/2104.10130", "author_id": ["Q9gfhNMAAAAJ", "L6lzWrYAAAAJ", "oZORQtwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:0pMr0adDOVEJ:scholar.google.com/&output=cite&scirp=268&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D260%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0pMr0adDOVEJ&ei=M7WsaKqxMrXCieoP4PfQ0A8&json=", "num_citations": 22, "citedby_url": "/scholar?cites=5852783578792563666&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:0pMr0adDOVEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2104.10130"}}, {"title": "Using ATLAS.ti to interpret keyword co-occurrence analysis: a case study on the representation of vaccin* across pseudoscience and conspiracy websites", "year": "2025", "pdf_data": "Yuze Sha and Isobelle Clarke*\nUsing ATLAS.ti to interpret keyword\nco-occurrence analysis: a case study on therepresentation of vaccin* across\npseudoscience and conspiracy websites\nhttps://doi.org/10.1515/lingvan-2024-0066\nReceived April 15, 2024; accepted November 4, 2024; published online February 14, 2025\nAbstract: In this study we use ATLAS.ti to interpret the results of a keyword co-occurrence analysis (KCA) of fake\nvaccination news. Speci \ufb01cally, KCA is used to uncover the most dominant patterns of co-occurring keywords\nacross a corpus of 37,676 texts from 235 pseudoscience and conspiracy websites that mention vaccin* . KCA enables\nresearchers to examine linguistic patterns of fake news from multiple angles, including discourse, register, style,\nand attitude. Yet, the interpretation of KCA can be time-consuming, especially when texts are long. Consequently,\nin this study, we leverage ATLAS.ti \u2019s code co-occurrence analysis functionality, which streamlines and accelerates\nthe interpretation of KCA results by providing access to extended concordances that highlight the patterns of\nkeyword co-occurrence. Taking the second most prominent dimension as a demonstration, we interpret this\npattern of keyword variation across our vaccination corpus as distinguishing texts that are questioning theCOVID-19 pandemic, especially in relation to higher power control, from texts that are discussing childhood\nvaccines, especially with respect to the dangers they pose. The implications of these linguistic repertoires in\nrelation to fake news and anti-science strategies are discussed.\nKeywords: keyword co-occurrence analysis; ATLAS.ti; anti-vaccine conspiracies; fake news; corpus-assisted\ndiscourse analysis\n1 Introduction: fake news, anti-vaccination discourse,\nanti-vaccination websites\nThe rapid advancement of online communication technologies has expanded the public \u2019s daily access to a myriad\nof information sources. This in \ufb02ux of information can negatively impact the public \u2019s capacity to make rational\ndecisions (Van Zandt 2004). This challenge is further impeded by the presence of fake news (Zhang and Ghorbani\n2020). Fake news is deliberately fabricated content that mimics the form of news media but lacks adherence to\njournalistic processes or intentions (Lazer et al. 2018).\nIn recent times, fake news has permeated various spheres, including politics (e.g., Subramanian 2017) and\nscience, particularly concerning vaccination, a public health measure credited with preventing 4 \u20135 million deaths\nannually (WHO 2019). Studies have highlighted the detrimental e \ufb00ects of vaccine misinformation, including the\nresurgence of vaccine-preventable diseases (e.g., measles) in many countries (Hotez 2020). Consequently, ongoingresearch e \ufb00orts aim to delineate the discursive characteristics of anti-vaccination discourse (e.g., Bean 2011;\nHardaker et al. 2024), especially on social media (e.g., Maci 2019; Orlandi et al. 2022).\nAlthough recent anti-vaccination studies have focused on social media, the impact of anti-vaccination\nwebsites remains substantial. These platforms act as primary sources of much information quoted across anti-\nvaccination online communities and social media posts. Studies (e.g., Betsch et al. 2012; Finney Rutten et al. 2019;\n*Corresponding author: Isobelle Clarke , Lancaster University, Lancaster, UK, E-mail: i.clarke@lancaster.ac.uk. https://orcid.org/0000-\n0001-5541-6327\nYuze Sha, Lancaster University, Lancaster, UK, E-mail: y.sha2@lancaster.ac.uk. https://orcid.org/0000-0001-9788-8250Linguistics Vanguard 2025; aop\nOpen Access. \u00a9 2025 the author(s), published by De Gruyter. This work is licensed under the Creative Commons Attribution 4.0\nInternational License.\nFox 2011) have shown that individuals, especially patients and caregivers, consult the internet for health-related\ninformation, especially vaccination information. The Pew Internet and American Life Project (Fox 2011) found\nthat 80 percent of internet users seek health information online (Kata 2012). Among these seekers, a substantial 70\npercent report that their \ufb01ndings on such health information websites in \ufb02uenced their treatment decisions.\nWith the capacity of websites to in \ufb02uence health decisions, studies have sought to understand anti-\nvaccination websites \u2019content and persuasiveness (e.g., Bean 2011; Kata 2012; Moran et al. 2016; Sak et al. 2015). For\nexample, in a content analysis of 480 websites, Moran et al. (2016) uncovered that 66.9 percent of the websites used\npseudoscience as a persuasive strategy, such as confusing correlation for causation. Of the 480 websites, 59.2percent referred to expert opinions to give weight to their statements and persuade their readers. In another\nstudy, Bean (2011) drew on the \ufb01ndings from Davies et al. (2002), Kata (2010), and Wolfe et al. (2002), who explored\nthemes across anti-vaccination websites, to assess if the themes had evolved. Speci \ufb01cally, Bean (2011) used content\nanalysis to analyse 25 anti-vaccination websites for recurring and changing emphases in content, design, and\ncredibility. The content features were summarized into four categories: safety and e \ufb00ectiveness; civil liberties;\nalternative treatments; and conspiracy theories or search for truth. Compared to \ufb01ndings from Davies et al.\n(2002), Kata (2010), and Wolfe et al. (2002), Bean (2011) found that whilst much had remained the same, there were\nsome new themes in response to new emerging health trends and threats, such as the H1N1 outbreak. This study\nhighlights the importance of revisiting anti-vaccination websites, as is done in the present study, around a decade\nafter the aforementioned studies, especially following the COVID-19 pandemic.\nLike Bean (2011), many studies investigating anti-va ccination websites have employed content analysis,\nusing human coders allocated with prede \ufb01ned code sets from earlier studies (e.g., Sak et al. 2015), or integrating\nthese schemes with either a qualitative examination o f data samples (e.g., Moran et al. 2016) or the emerging\nthemes through an iterative examination process (e.g., Bean 2011). Whilst using human coders o \ufb00ers distinct\nadvantages, such as uncovering subtle thematic variations, it also risks a \ufb00ecting the objectivity of the results.\nAdditionally, the process can be time-consuming, especially for large datasets, which may limit the scope of the\nanalysis.\nTo address this, in the present study we applied the corpus-assisted discourse analytical approach known as\nkeyword co-occurrence analysis (KCA) to anti-vaccination website texts to uncover groups of keywords that\nco-occur across them, which we systematically explore for themes, discourses, registers, styles, and attitudes.\n2 Keyword co-occurrence analysis\nKCA is aimed at uncovering the dominant patterns of keyword co-occurrence across the texts of a corpus(Clarke et al. 2021, 2022). Keywords are terms appearing with unusual frequency compared to a reference\ncorpus. Keywords are instrumental in highlighting the aboutness of the dataset, such as discourses (Baker 2004)\nand register (McEnery 2016). Yet one challenge when it comes to keyword studies is aggregation \u2013the keywords\nin the keyword list may all point to the discourses, but prising apart the discourses is a task for the analyst (for a\ndetailed discussion, see Clarke et al. 2021). In previou s keyword studies, to interpret the keyword results,\nresearchers have often manually categorized keywo rds into semantic or thematic groups based on a close\nreading of corresponding concordances (e.g., Brookes 2022). While manual analysis o \ufb00ers depth, the categories\ncreated and the keywords assigned to the categories are susceptible to compromise, especially when corpora\nare large and when keywords occur frequently (Clarke et al. 2021).\nInstead, KCA uses a multivariate statistical technique, called multiple correspondence analysis (MCA) to\ngroup the keywords based on their frequent co-occurrence across a corpus, aiming to deliver rich, multidi-\nmensional insights. KCA is based on the notion of linguistic co-occurrence \u2013frequent patterns of co-occurring\nlinguistic features are not random, but instead point to at least one shared communicative function (Biber 1988).\nPrior research employing KCA has illuminated that patterns of keyword co-occurrence not only point to dis-\ncourses and functions, but also sub-registers (Clarke et al. 2021), argumentative repertoires, and manipulative\ndisinformation strategies (Clarke 2023). These applications of KCA have shown its capacity to account for the\nmultiple senses, topics, (sub)registers, functions, and discourses that keyword co-occurrence can express.2\nSha and Clarke\nKCA involves the following four broad steps: (i) compute keywords using a traditional keyword analysis\n(i.e., comparing the relative frequencies of the words in a target corpus to those in a reference corpus using a\nparticular statistic of one \u2019s choice, e.g., log-likelihood, log ratio, di \ufb00erence coe \ufb03cient); (ii) analyse each text in the\ncorpus for the occurrence of these keywords and record in a categorical data matrix; (iii) subject the data matrix\nto MCA to reveal dimensions comprising the most common patterns of co-occurring keywords; and \ufb01nally (iv)\ninterpret these dimensions of keyword co-occurrence, guided by the principles of linguistic co-occurrence (Biber\n1988) and the indicative nature of keywords in discourse (Baker 2006).\nDespite the method \u2019s strengths, the interpretation of dimensions in any dimension reduction method, such as\nMCA, is di \ufb03cult, especially in the context of KCA where the variables are linguistic features, and the goal is to\nselect a short, descriptive label that captures the crux of the dimension and the opposition of many features\n(Friginal and Hardy 2019). In previous KCA studies, analysts read texts most associated with each dimension and\nexplored each keyword associated with the dimension in these texts to understand the relevant keywords \u2019\ncontexts and uses. After labelling the co-occurrence pattern, they attempt to falsify it against less associated texts\nfollowing the same approach. Although e \ufb00ective, the interpretation process can be laborious, especially when\ntexts are long and dimensions comprise numerous keywords.\nTo address this, we explored technological solutions to expedite the interpretation process and found ATLAS.ti \u2019s\n(2023) code co-occurrence function to be complementary for KCA. In the rest of the paper, we present Dimension 2\nfrom a KCA of texts mentioning vaccination from pseudoscience and conspiracy websites to demonstrate how to use\nATLAS.ti for analysing KCA results. The reason for skipping Dimension 1 is because Dimension 1 \u2019s results oppose\nlong texts with short texts (for a more detailed description, see Clarke and Grieve 2019).\n3 Methodology\n3.1 Vaccination subcorpus of the pseudoscience and conspiracy sources corpus\nThe data for this study comes from a larger project investigating di \ufb00erent branches of anti-science (see Clarke 2023).\nThe general corpus for this project comprises texts (all content on a single web page \u2013i.e., article and comments)\nfrom 235 websites labelled as \u201cconspiracy-pseudoscience \u201dby Media Bias/Fact Check (https://mediabiasfactcheck.\ncom), which is a comprehensive and continuously updated resource of online media sites that have been rated for\nvarious levels of bias. The corpus was \ufb01ltered by retaining texts according to \u201cseed \u201dwords and phrases associated\nwith the anti-science branches relevant to the larger project. The present study drew on the vaccination subcorpus,\nwhich was \ufb01ltered based on the seed words vaxandvaccin* , which spans 21 years (from 2000 to 2021). Duplicated\ntexts were removed from the corpus using a Python script to avoid skewing the data. Table 1 presents the\ncomposition of the corpus before and after deduplication.\nTable 1 shows that nearly half of the anti-vaccination content is duplicated, demonstrating, like climate denial\nliterature (Dunlap and Jacques 2013), that anti-vaccination content is recycled and reposted across other websites\nwhenever convenient.\n3.2 Generation of keywords and MCA\nKeywords were computed in Sketch Engine by comparing the vaccination subcorpus to the English 2020 webcorpus (enTenTen20) using the simple maths method ( N= 100; Kilgari \ufb002009) and capping the number of\nkeywords to the top 1,000 results (Kilgari \ufb00et al. 2014). We further reduced this list according to the keywords that\nTable \uf131:Composition of the vaccination subcorpus of the pseudoscience and conspiracy sources corpus.\nNumber of texts Number of words (tokens)\nBefore deduplication \uf135\uf132,\uf131\uf131\uf131 \uf136\uf132 ,\uf134\uf134\uf139,\uf135\uf139\uf136\nAfter deduplication \uf133\uf137,\uf139\uf132\uf131 \uf133\uf131 ,\uf139\uf134\uf131,\uf137\uf134\uf137Using ATLAS.ti to interpret keyword co-occurrence analysis 3\nwere dispersed across more than 5 percent of the texts in the vaccination subcorpus, resulting in 177 keywords.\nEach text was then computationally analysed for the presence or absence of these 177 keywords, and this was\nrecorded in a categorical data matrix. This matrix was then subjected to MCA in R using the FactoMineR package\n(Husson et al. 2024).\nMCA produced a series of dimensions detailing the most common patterns of co-occurring keywords across\nthe corpus and which texts display those patterns (for a more detailed discussion, see Clarke et al. 2021).\nSpeci\ufb01cally, the MCA assigned each text and each category of a keyword (e.g., presence of RNA, absence of RNA) a\ncoordinate and contribution score for each dimension. Categories of keywords with contributions above theaverage contribution score on a dimension are the most important contributors to the dimension. All contri-\nbutions for a particular dimension add up to 100, so the average contribution is 0.28.\n1Coordinates indicate the\nnature of the association between the keywords in terms of proximity, where keywords that co-occur often across\nthe texts of the corpus will have coordinates closer to each other on one side of an axis. Keywords with strong\ncontributions and positive coordinates co-occur often together in many texts, while keywords with strong\ncontributions and negative coordinates co-occur often together in a di \ufb00erent set of texts with each set rarely or\nnever co-occurring with the other set. Thus, a dimension represents a pattern of keyword variation.\nWe interpreted these MCA results in ATLAS.ti by (i) creating subcorpora comprising the texts most associated\nwith each dimension, (ii) creating codes aligned with the keywords most associated with each dimension, and (iii)\nusing the code co-occurrence function to observe paragraphs in the texts where the keywords co-occur. This\nfacilitated a more systematic and expedited visualization of keyword co-occurrence in texts by pointing toparagraphs where the keywords most strongly associated with each side of the dimension co-occur rather than\nsearching each text one keyword at a time.\nFigure 1: User interface of ATLAS.ti.\n1100\u00f7(177 keywords, each with two categories, namely presence and absence) = 100 \u00f7354 = 0.28.4 Sha and Clarke\n3.3 Corpus construction on ATLAS.ti\n3.3.1 Creating the subcorpora\nTo build our subcorpora in ATLAS.ti, we selected the top 50 texts most associated with the positive and the\nnegative side of each dimension. These 100 texts were then imported into ATLAS.ti and we used the Group\nfunction to categorize them into two subcorpora based on their associative polarity (e.g., \u201cDimension 2_positive \u201d\nand \u201cDimension 2_negative \u201d; see Figure 1). These texts represent the most prototypical texts of the discourse (or\nshared function, etc.), tending to include many, if not all, of the keywords most strongly associated with the\nparticular pole of the dimension.\nFigure 2: The keywords most\nstrongly contributing to positive\nand negative Dimension 2 ( \u201c_P\u201d\nfor presence; \u201c_A\u201dfor absence).Using ATLAS.ti to interpret keyword co-occurrence analysis 5\n3.3.2 Creating the codes\nWe then created codes based on the keywords most associated with each pole of the dimension from the MCA\nresults. Figure 2 shows the keywords that are contributing above the average contribution ( \u201cctr\u201d) for Dimension 2\nand their respective coordinate ( \u201ccoord \u201d).\nWe employed the Text Search function (see Figures 3 and 4) of ATLAS.ti to pinpoint and code paragraphs\nwithin the texts most associated with Dimension 2 that contained the target keywords.\nSubsequently, we entered the target keyword for coding and set the query \u2019ss c o p e .D i \ufb00erent from\nprevious studies (e.g., Clarke et al. 2021), our inter pretation of the dimensions of keyword co-occurrence\nconcentrated on how the keywords co-occurred in ind ividual paragraphs (see Figures 5 and 6) rather than\nentire texts, for the purpose of accelerating the inter pretation process. This approach enables us to isolate\nspeci\ufb01c segments within the most strongly associated text s where the keywords associated with a particular\nside of a dimension appear together, facilitating a more d etailed examination of th e factors contributing to\ntheir co-occurrence.\nFor each side, we then used ATLAS.ti \u2019s Bulk Code function (top right in Figure 6) to mark every occurrence of\neach keyword within the top 50 texts. Once the coding process was completed, the instances of keywords within\nparagraphs were marked, thereby enabling the subsequent code co-occurrence analysis.\n3.3.3 Analytical framework\nAfter constructing and annotating our corpus, our obj ective, as with other KCA studies, was to delineate\nwhat the patterns of keyword co-occurrence point to. T o guide this interpretation, we used the analytical\nframework established in Clark e et al. (2025), which outlines \ufb01ve preliminary areas of enquiry (see Table 2).\nFigure 3: Text search functionality on ATLAS.ti.6 Sha and Clarke\nFigure 4: Selecting target document (groups).\nFigure 5: De\ufb01ning a query.Using ATLAS.ti to interpret keyword co-occurrence analysis 7\nFigure 6: Results and bulk coding on ATLAS.ti.\nTable \uf132:KCA analytical framework.\nConstruct De \ufb01nition Prompt\nTopic or subject\nmatterThe subject matter/aboutness of the text What do the texts concern? What are the texts about?\nDiscourse \u201c[S]et[s] of meanings, metaphors, representations, images,\nstories, statements and so on that in some way together produce\na particular version of events \u201d(Burr \uf132\uf130\uf131\uf135 :\uf137\uf134\u2013\uf137\uf135)Are the patterns of co-occurring keywords being used in\ntexts to focus on a particular event and/or aspect? If so,\nwhat?\nHow is vaccination being represented? What aspect ofvaccination is being zoomed in on?\nRegister A variety of language associated with both a particular situation\nof use and with pervasive linguistic features that serve important\nfunctions within that situation of use (Biber and Conrad \uf132\uf130\uf130\uf139 :\uf133\uf133)\n\u201cRegisters are described for their typical lexical and grammatical\ncharacteristics \u2026and also\u2026for their situational contexts, for\nexample whether they are produced in speech or writing,whether they are interactive, and what their primary communi-\ncative purposes are \u201d(Biber and Conrand \uf132\uf130\uf130\uf139 :\uf136)\nThe function of linguistic features in the situational contextHow are the keywords functioning in the texts?\nAre the keywords characteristic of a particular language\nvariety?What is/are the purpose(s) of the texts?\nDo the texts share a speci \ufb01c or primary communicative\npurpose?Are all the texts a particular register?\nStyle The use of linguistic features that re \ufb02ect aesthetic preferences,\nassociated with particular authors or historical periodsDo the keywords re \ufb02ect aesthetic preferences of\nparticular authors/historical periods?\nVaccineattitudeThe vantage point of vaccines and vaccination expressed in the\ntweetAre the texts overtly pro- or anti-vaccination?\nAre the texts disinterested in vaccination?8 Sha and Clarke\nThe interpretation process began by using the Global Filter function (see Figure 7) in ATLAS.ti to isolate the\ntarget Dimension 2 subcorpora for examination. We then utilized the Code Co-occurrence Analysis function in\nATLAS.ti to analyse and summarize the patterns of co-occurrence throughout the subcorpus (see Figure 8).\nFigure 9 displays the table of results from this analysis. The frequency with which two codes (representing\nkeywords in this study) co-occur in the same paragraph is displayed in the middle. The intensity of colouring\nindicates the strength of co-occurrence within the paragraphs of this subcorpus, with deeper colours signifying\nstronger associations. By selecting a speci \ufb01c column, the right side of the table reveals detailed concordances of\nthese co-occurrences.\nTo identify paragraphs where more than two keywords co-occurred, we used the Global Filter function\nto initially \ufb01lter concordances that had been coded with speci \ufb01c keywords. Subsequently, we used code co-\noccurrence analysis to explore their co-occurrences with other keywords. For instance, to explore how the\nkeywords associated with negative Dimension 2 (as presented in Figure 2) co-occur in texts we set \u201cDimension\n2_neg 50 \u201d(the document group) and MMR (one of the target keywords) as the Global Filter criteria (see Figure 10).\nWe then explored the code co-occurrence analysis table to view the co-occurrence of MMR with autism (another\ntarget keyword) and all other keywords associated with the negative side of Dimension 2 (see Figure 11). We\nrepeated this for all keywords strongly contributing to each dimension.\nFigure 7: Setting a Global Filter on ATLAS.ti.Using ATLAS.ti to interpret keyword co-occurrence analysis 9\nFigure 9: Code co-occurrence analysis table.\nFigure 8: Code co-occurrence analysis on ATLAS.ti.10 Sha and Clarke\nFigure 11: Co-occurrence analysis of more than two keywords (co-occurrence table).\nFigure 10: Co-occurrence analysis of more than two keywords (Global Filter setting).Using ATLAS.ti to interpret keyword co-occurrence analysis 11\n4 Results\nWe present our interpretation of Dimension 2 in this paper. It should be noted that whilst the interpretations and\nthe concordances presented below are based on the 50 most prototypical texts, these patterns were also observed\nin less strongly associated texts. After we had interpreted the top 50 texts, we sought to falsify our interpretations\nby exploring a random set of texts that were less strongly associated with the particular pole of the dimension. If\nthe interpretations were falsi \ufb01ed we re \ufb01ned the interpretation and repeated the process of falsi \ufb01cation until no\nmore re \ufb01nement was needed.\n4.1 Positive Dimension 2\nThe keywords most associated with the positive side of Dimension 2 co-occur in texts that discuss the COVID-19\npandemic and question the legitimacy of government regulations related to the pandemic, including thoseconcerning COVID-19 vaccines.\n4.1.1 Questioning the legitimacy of government regulations\nA prominent representational discourse found across positive Dimension 2 texts concerns governmental control\nand regulations during COVID-19. Figure 2 shows that many keywords strongly contributing to positive Dimen-sion 2 are related to COVID-19 ( COVID ,COVID-19 ,coronavirus , and SARS-CoV-2 ) and COVID-19-related policies\n(lockdown ,mask , and social distancing ). Additionally, names of prominent political \ufb01gures like Biden ,Trump , and\nFauci and keywords related to government actions, such as agenda and authorization , are prevalent. These\nkeywords are used to question the legitimacy and reasoning behind governmental interventions, including\nvaccination campaigns, accusing the government of a sinister agenda. Also, keywords such as fake and experi-\nmental frequently co-occur with both policy-related and virus-related keywords often to suggest that the\npandemic is not real, as illustrated in (1).\n(1)\n4.1.2 COVID vaccination\nCOVID vaccination is a prominent theme. This is realized by keywords related to di \ufb00erent COVID vaccine types\n(Moderna ,mRNA ,a n d P\ufb01zer). Notably, these vaccine-related keywords often co-occur with the keyword\nexperimental to directly describe the vaccine in phrases like \u201cexperimental mRNA technology \u201d(see (2)),\n\u201cexperimental test vaccine \u201d,o r \u201cexperimental gene therapy mRNA drugs \u201d, rather than simply referring to it as\na\u201cvaccine \u201d. Such texts describe the vaccines as being hastil y developed and question their need, safety, and\ne\ufb03cacy. Notably, the reference to mRNA vaccine as \u201cexperimental gene therapy \u201dis used to suggest that the\nvaccine is altering people \u2019s genetic code and poses damage to individuals \u2019health. Referring to the vaccine as\n\u201cexperimental \u201dcontributes further to the discourse of governmental control as those who get the vaccine are\npositioned as test subjects.12 Sha and Clarke\n(2)\nDespite references to di \ufb00erent types of COVID-19 vaccines, the only vaccination reference found in the keyword\nlist was jab. The keywords vaccine orvaccination were not strongly associated with positive or negative\nDimension 2. Whilst this is most likely because they are used fairly equally across the texts associated with the\npositive and the negative sides of Dimension 2 and thus do not contribute to this pattern of variation, the strong\nassociation of jabalongside COVID-19-related keywords introduces meaningful connotations. Unlike the more\nmedically oriented and neutral terms vaccine and vaccination ,jabcarries a more informal tone with violent\nconnotations. The selection of jabover the other choices might also aim to cast the COVID-19 vaccination in a more\nnegative or forceful light, contributing to ampli \ufb01ed scepticism or reluctance towards COVID-19 vaccination\ninitiatives. Furthermore, this linguistic choice may serve as a mechanism of delegitimization, attempting to\nweaken the discourse \u2019s connection to authoritative narratives (see (3)). By avoiding formal medical terminologies,\nit might serve to reduce the credibility and legitimacy of vaccination e \ufb00orts and foster doubt, fear of injury, and\ndiminish trust in scienti \ufb01c expertise and authority.\n(3)\n4.1.3 Negative consequences\nAnother prominent discourse stresses the negative consequences of governmental controls during the COVID-19\npandemic, including COVID-19 vaccinations. This narrative is underscored by the co-occurrence of the keywords\nelderly and deadly with policy-related keywords, such as lockdown(s) ,quarantine , and experimental (vaccines),\nwhich are used in texts often to dispute the need for such interventions by (i) blaming the high infection and death\nnumbers among the elderly as a direct consequence of government interventions, such as claiming that systems\nfor elderly care collapsed due to lockdowns, or (ii) accusing the COVID-19 death rates of being in \ufb02ated due to the\nsusceptibility of vulnerable populations to infections or death during the \ufb02u season, rather than as a direct\nconsequence of COVID-19 (see (4)).Using ATLAS.ti to interpret keyword co-occurrence analysis 13\n(4)\nConspiracies about the adverse e \ufb00ects of the COVID-19 vaccination are also promoted in positive Dimension 2\ntexts. For instance, (5) claims COVID-19 illnesses and deaths, especially those of \u201cthe weak and elderly \u201d, are not\nassociated with the virus, but the vaccine.\n(5)\n4.2 Negative Dimension 2\nBy contrast, the keywords most strongly associated with negative Dimension 2 co-occur in texts that are focused\non childhood vaccinations and the hazardous substances within them, which they claim cause numerous adverse\ne\ufb00ects.\n4.2.1 Childhood vaccination\nThe keywords associated with negative Dimension 2 reference children ( child, childhood ) and childhood vacci-\nnations ( measles ,mumps , and rubella ,polio ,pertussis , and tetanus ). Many texts also include the keyword Merck ,a\npharmaceutical company. Such texts accuse Merck of being irresponsible for not conducting long-term safety\ntests to highlight concerns regarding the quality of vaccines (e.g., Gardasil), as illustrated in (6).\n(6)\n14 Sha and Clarke\nAdditionally, the keyword pediatric is often used to cite studies from paediatric journals and associations, like\nPediatric Annals in (7), to lend professional credibility to their claims. Importantly, while the study mentioned\nexists, the quote discusses the aetiologies of autism, but the study does not corroborate the connection between\nvaccines and autism that the website asserts.\n(7)\n4.2.2 Hazardous substances\nNegative Dimension 2 texts also emphasize the presence of hazardous substances in vaccinations through\nkeywords like aluminum and mercury to assert that they can cause various health issues ( toxicity ), including\ninjuries ( injury ), diseases ( autoimmune ,neurological ), and disorders ( autism ). These texts question the safety of\nthe ingredients in childhood vaccines with phrases like \u201cvaccine-induced autism \u201dencapsulating these concerns.\nMany texts dispute scienti \ufb01c claims that vaccines do not cause autism by suggesting that there have been limited\nstudies investigating the impact of these aforementioned substances in other vaccines (see (8)).\n(8)\nA common narrative throughout negative Dimension 2 texts asserts that vaccinated children face higher risks and\nsu\ufb00er from more health issues than their unvaccinated counterparts. An illustrative case is provided in (9), where\nthe Children \u2019s Health Defense website quotes \u201cDr. Daniel Neides of the Cleveland Clinic \u201dto imply that vaccines\ncause children to develop neurological disorders, including autism and ADHD.\n(9)\nUsing ATLAS.ti to interpret keyword co-occurrence analysis 15\n4.3 Addressing the remaining interpretation angles\nSo far, we have explored the keyword co-occurrence patterns through the lens of topic and discourse. We now\nturn to the remaining interpretation angles, as detailed in Table 2. From a register perspective, positiveDimension 2 is characterized by an informal, argumentative register (see (4)) through texts which question\ngovernmental policies (see (1)) and comprise colloquial references to vaccinations (e.g., jab; see (3)). In contrast,\nnegative Dimension 2 texts are more academic, featuring scienti \ufb01c references to substances and quotes from\nresearch studies and experts (see (7), (8), and (9)).\nRegarding style, positive Dimension 2 is distinguished by political critiques of COVID-19 policies, re \ufb02ecting a\nmore provocative and contentious style. By contrast, negative Dimension 2 uses (pseudo)scienti \ufb01c and \u201cevidence-\nbased \u201darguments, suggesting a more analytical style.\nThe\ufb01nal aspect examines attitudes towards vaccina tions. We found evidence of negative attitudes\ntowards vaccinations on both the posi tive and negative sides o f Dimension 2. Yet, importantly, there was also\nevidence of actors within texts and authors of texts outr ight denying being anti-va ccination, as can be seen in\n(10). Such texts nevertheless continue to call in to question the safety of vaccinations, which in e \ufb00ect casts\ndoubt on vaccinations and contribute s to an anti-vaccination strategy. Rat her than being anti-vaccination,\nthey state that they are against unsafe vaccinations. This demonstrates that anti-vaccination is deemed by\nsome as being \u201canti-cure \u201dor\u201canti-antidote \u201dand when this sense is evoked, those accused of being anti-\nvaccination will deny this label.\n(10)\n5 Discussion and conclusions\nIn this study, we demonstrated the application process of ATLAS.ti for interpreting the results of a KCA of texts\nmentioning vaccination from websites known to promote pseudoscience and conspiracy theories.\nDue to length restrictions, it was not possible to present all dimensions of keyword variation. But by delving\ninto the second strongest pattern of keyword variation (i.e., Dimension 2), our analysis unveiled a dichotomy\nbetween discussions of COVID-19 vaccines and those on childhood vaccinations. Texts mentioning COVID-19\nvaccines positioned them under the broader discourse of governmental regulations and control. Such texts were\nfocused on questioning the need for government interventions, like lockdowns, mask wearing, and vaccinations,and promoting the conspiracy of an alternative sinister agenda. Texts delegitimized COVID-19 policies, including\nvaccination policy from two angles, by (i) stressing the safety of the unvaccinated by downplaying the virus \u2019s\nseverity and (ii) highlighting the risks to the vaccinated by overstating the adverse e \ufb00ects of vaccines. The\ndelegitimization is further achieved through the informal use of jabforvaccine , which could evoke concerns\nabout safety and e \ufb03cacy by distancing itself from the scienti \ufb01c term and register. The register of these texts is\npredominantly informal and argumentative, characterized by political critiques.\nTexts discussing childhood vaccines are more \u201cacademic \u201d, with frequent citations from researchers and\ndoctors and the use of technical terminology related to hazardous substances and associated illnesses. Yet,\nparadoxically, these texts also include emotional appeals, with many texts directly calling on parents to protect\ntheir children against alleged vaccine-induced diseases, disorders, and deaths.16\nSha and Clarke\nMany of these discourses and strategies are aligned with those found in previous research investigating anti-\nvaccination websites, such as Bean (2011), which noted the frequent mentions of vaccine ingredients and vaccine-\ninduced diseases and deaths, and accusations that vaccines violate civil liberties. Yet there are some di \ufb00erences,\nespecially within texts covering the COVID-19 pandemic. For example, unlike the \u201cdiseases have declined \u201d\nnarrative found in the websites examined in Bean (2011), the COVID-19 vaccination discussions minimize the\nseverity of the virus by claiming that the death and illness statistics are in \ufb02ated due to the elderly and the\nvulnerable. Also, rather than solely stressing the mandatory nature of vaccination (Bean 2011), the COVID-19 anti-\nvaccination discourses posit vaccinations within the framework of government control, delegitimizing thevaccination alongside other policies, such as lockdown and mask wearing, amplifying the scope of its target\naudience who disagreed with or disliked such regulations. These di \ufb00erences particularly in COVID-19 vaccine\ndiscourse thus point to the adaptive nature of anti-vaccination discourses.\nIn this study, we have illustrated how ATLAS.ti \u2019s code co-occurrence analysis function is complementary to\nKCA. Using ATLAS.ti we were able to specify the context for codes to co-occur as paragraphs as opposed to full\ntexts. This enabled the observation of patterns of keyword co-occurrence more systematically rather than\nmanually searching for the keywords in the full texts associated with the dimension.\nOur results have pointed to some of the ways in which fake news may mimic authentic news, such as through\nreferences to experts, genuine citations, technical terminology, and political critique (Lazer et al. 2018). But, as\nshown, this is coupled with additional strategies like overstating and downplaying, which can add to the challenge\nof distinguishing fake news. Moreover, some texts exploit vague language, prompting their readers to \u201c\ufb01ll in the\ngaps \u201d. For instance, by claiming that the COVID-19 pandemic is fake and that the government interventions are\nnot aimed at preventing the spread of the vaccine but are instead part of a vague, unspeci \ufb01ed agenda, readers can\ncreate what that agenda is and their own reasons for that agenda. Essentially, fake news can thus be moulded by\nthe reader, making it considerably di \ufb03cult to distinguish from real news.\nThe present study also reveals the in \ufb02uence of COVID-19 on anti-vaccination discussions. Even though our\ndataset spanned 21 years, the COVID-19 pandemic turned out to be dominant within our corpus. Future research\nshould therefore continue to track the evolution of anti-vaccination websites \u2019strategies to better equip the public\nto delineate fact from \ufb01ction.\nResearch funding: This research was funded by the Leverhulme Trust, grant number ECF-2020-590.\nReferences\nATLAS.ti Scienti \ufb01c Software Development GmbH. 2023. ATLAS.ti Mac (version 23.2.1) [Qualitative data analysis software]. https://atlasti.com.\nBaker, Paul. 2004. Querying keywords: Questions of di \ufb00erence, frequency, and sense in keywords analysis. Journal of English Linguistics 32(4).\n346 \u2013359.\nBaker, Paul. 2006. Using corpora in discourse analysis . London: Bloomsbury.\nBean, Sandra. 2011. Emerging and continuing trends in vaccine opposition website content. Vaccine 29(10). 1874 \u20131880.\nBetsch, Cornelia, Noel Brewer, Pauline Brocard, Patrick Davies, Wolfgang Gaissmaier, Niels Haase, Julie Leask, Frank Renkewitz, Britta Renner,\nValerie Reyna, Constanze Rossmann, Katharina Sachse, Alexander Schachinger, Michael Siegrist & Marybelle Stryk. 2012. Opportunities\nand challenges of Web 2.0 for vaccination decisions. Vaccine 30(25). 3727 \u20133733.\nBiber, Douglas. 1988. Variation across speech and writing . Cambridge: Cambridge University Press.\nBiber, Douglas & Susan Conrad. 2009. Register, genre and style . Cambridge: Cambridge University Press.\nBrookes, Gavin. 2022. \u201cLose weight, save the NHS \u201d: Discourses of obesity in press coverage of COVID-19. Critical Discourse Studies 19(6).\n629 \u2013647.\nBurr, Viven. 2015. Social constructionism , 3rd edn. London: Routledge.\nClarke, Isobelle. 2023. The discourses of climate change across conspiracy and pseudoscience websites. In Stefania M. Maci,\nMassimiliano Demata, Mark McGlashan & Philip Seargeant (eds.), The Routledge handbook of discourse and disinformation , 325 \u2013341.\nLondon: Routledge.\nClarke, Isobelle & Jack Grieve. 2019. Stylistic variation on the Donald Trump twitter account: A linguistic analysis of tweets posted between\n2009 and 2018. PLoS One 14(9). 1 \u201327.\nClarke, Isobelle, Elena Semino, Zs\u00f3 \ufb01a Demj\u00e9n, William Dance, Tara Coltman-Patel & Richard Gleave. 2025. HPV vaccine discourse online: A\ncorpus linguistic approach . London: Routledge.Using ATLAS.ti to interpret keyword co-occurrence analysis 17\nClarke, Isobelle, McEnery Tony & Brookes Gavin. 2021. Multiple correspondence analysis, newspaper discourse and subregister: A case study\nof discourses of Islam in the British press. Register Studies 3(1). 144 \u2013171.\nClarke, Isobelle, Gavin Brookes & Tony McEnery. 2022. Keywords through time: A study of representations of Islam in the British press.\nInternational Journal of Corpus Linguistics 27(4). 399 \u2013427.\nDavies, Paul, Simon Chapman & Julie Leask. 2002. Antivaccination activists on the World Wide Web. Archives of Disease in Childhood 87(1).\n22\u201325.\nDunlap, Riley & Peter Jacques. 2013. Climate change denial books and conservative think tanks: Exploring the connection. American Behavioral\nScientist 57(6). 699 \u2013731.\nFinney Rutten, Lila, Kelly Blake, Alexandra Greenberg-Worisek, Summer Allen, Richard Moser & Bradford Hesse. 2019. Online health\ninformation seeking among US adults: Measuring progress toward a healthy people 2020 objective. Public Health Reports 134(6).\n617\u2013625.\nFox, Susannah. 2011. 80% of internet users look for health information online . Pew Internet & American Life Project. https://www.pewresearch.\norg/internet/wp-content/uploads/sites/9/media/Files/Reports/2011/PIP_Social_Life_of_Health_Info.pdf (accessed 15 August 2024).\nFriginal, Eric & Jack Hardy. 2019. From factors to dimensions: Interpreting linguistic co-occurrence patterns. In Tony Berber Sardinha &\nMarcua Pinto (eds.), Multi-dimensional analysis: Research methods and current issues , 145 \u2013164. London: Bloomsbury.\nHardaker, Claire, Alice Deignan, Elena Semino, Tara Coltman-Patel, William Dance, Zs\u00f3 \ufb01a Demj\u00e9n, Chris Sanderson & Derek Gatherer. 2024.\nThe Victorian anti-vaccination discourse corpus (VicVaDis): Construction and exploration. Digital Scholarship in the Humanities 39(1).\n162\u2013174.\nHotez, Peter. 2020. Combating antiscience: Are we preparing for the 2020s? PLoS Biology 18(3). 1 \u20136.\nHusson, Francois, Julie Josse, Sebastien Le & Jeremy Mazet. 2024. FactoMineR, version 2.11 [R package] . https://cran.r-project.org/web/\npackages/FactoMineR/FactoMineR.pdf.\nKata, Anna. 2010. A postmodern Pandora \u2019s box: Anti-vaccination misinformation on the internet. Vaccine 28(7). 1709 \u20131716.\nKata, Anna. 2012. Anti-vaccine activists, Web 2.0, and the postmodern paradigm \u2013an overview of tactics and tropes used online by the anti-\nvaccination movement. Vaccine 30(25). 3778 \u20133789.\nKilgari \ufb00, Adam. 2009. Simple maths for keywords . https://www.sketchengine.eu/wp-content/uploads/2015/04/2009-Simple-maths-for-\nkeywords.pdf (accessed 15 August 2024).\nKilgari \ufb00, Adam, V\u00edt Baisa, Jan Bu \u0161ta, Milo \u0161Jakub\u00ed \u010dek, Vojt \u011bch Kov\u00e1 \u0159, Jan Michelfeit, Pavel Rychl\u00fd & V\u00edt Suchomel. 2014. The Sketch Engine: Ten\nyears on. Lexicography 1(1). 7 \u201336.\nLazer, David, Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan,\nGordon Pennycook, David Rothschild, Michael Schudson, Steven A. Sloman, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts &\nJonathan L. Zittrain. 2018. The science of fake news. Science 359(6380). 1094 \u20131096.\nMaci, Stefania Maria. 2019. Discourse strategies of fake news in the anti-vax campaign. Lingue Culture Mediazioni \u2013Languages Cultures\nMediation 6(1). 15 \u201343.\nMcEnery, Tony. 2016. Keywords. In Paul Baker & Jesse Egbert (eds.), Triangulating methodological approaches in corpus linguistic research ,\n20\u201332. London: Routledge.\nMoran, Meghan, Melissa Lucas, Kristen Everhart, Ashley Morgan & Erin Prickett. 2016. What makes anti-vaccine websites persuasive? A\ncontent analysis of techniques used by anti-vaccine websites to engender anti-vaccine sentiment. Journal of Communication in Healthcare\n9(3). 151 \u2013163.\nOrlandi, Ludovico, Gianluca Veronesi & Alessandro Zardini. 2022. Unpacking linguistic devices and discursive strategies in online social\nmovement organizations: Evidence from anti-vaccine online communities. Information and Organization 32(2). 100409.\nSak, Gabriele, Nicola Diviani, Allam Ahmed & Peter Schulz. 2015. Comparing the quality of pro- and anti-vaccination online information: A\ncontent analysis of vaccination-related webpages. BMC Public Health 16. 1 \u201312.\nSubramanian, Samanth. 2017. Inside the Macedonian fake-news complex. Wired . https://www.wired.com/2017/02/veles-macedonia-fake-\nnews/.\nVan Zandt, Timothy. 2004. Information overload in a network of targeted communication. The RAND Journal of Economics 35(3). 542 \u2013560.\nWHO. 2019. Immunization . World Health Organization. http://www.who.int/features/fact \ufb01les/immunization/en/ (accessed 23 March 2024).\nWolfe, Robert, Lisa Sharp & Martin Lipsky. 2002. Content and design attributes of antivaccination web sites. JAMA 287(24). 3245 \u20133248.\nZhang, Xichen & Ali Ghorbani. 2020. An overview of online fake news: Characterization, detection, and discussion. Information Processing &\nManagement 57(2). https://doi.org/10.1016/j.ipm.2019.03.004.18 Sha and Clarke", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Using ATLAS.ti to interpret keyword co-occurrence analysis: a case study on the representation of vaccin* across pseudoscience and conspiracy websites", "author": ["Y Sha", "I Clarke"], "pub_year": "2025", "venue": "Linguistics Vanguard", "abstract": "In this study we use ATLAS.ti to interpret the results of a keyword co-occurrence analysis (KCA)  of fake vaccination news. Specifically, KCA is used to uncover the most dominant"}, "filled": false, "gsrank": 273, "pub_url": "https://www.degruyterbrill.com/document/doi/10.1515/lingvan-2024-0066/html", "author_id": ["0SNnokcAAAAJ", "RrTJeH0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:z2nPd8bv9k0J:scholar.google.com/&output=cite&scirp=272&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D270%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=z2nPd8bv9k0J&ei=NbWsaP7HEuHUieoP9LKZ6AI&json=", "num_citations": 1, "citedby_url": "/scholar?cites=5617941220883917263&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:z2nPd8bv9k0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.degruyterbrill.com/document/doi/10.1515/lingvan-2024-0066/pdf"}}, {"title": "Information sharing and content framing across multiple platforms and functional roles that exemplify social processes of online hate groups", "year": "2024", "pdf_data": "\n\u201cHate speech is always with us, but the internet supercharged its \ndevelopmental process. Formerly, voices crying out in the desert of hate largely went unheard, but the internet now provides a ready audience of fellow haters. Learn about the birth, nourishment, life, and death of hate speech in this impressive book.\u201d\nWilliam Crano, Oskamp Distinguished Professor in Psychology, \nClaremont Graduate University, Claremont, California, USA\n\u201cThe very idea of a community of haters may seem paradoxical. Yet such is the extraordinary reality of our digital world. This carefully researched volume traces the emerging norms, innovative practices, and intensified cultures of online hate with which we must now contend, and challenges researchers\u00a0\u2013 and society\u00a0\u2013 to identify constructive new directions.\u201d\nSonia Livingstone, Professor, London School of Economics, and \nDirector of Digital Futures for Children, London, UK\n\u201cWith a novel focus on \u2018social process perspectives\u2019\u00a0\u2013 such as the ways in which online hate can be a bonding experience for the haters\u00a0\u2013 this timely book offers a vital resource for understanding and addressing the complexities of contemporary online discourse.\u201d\nJonathan Zittrain, Professor of Law, Computer Science, and  \nPublic Policy, Harvard University, Cambridge, Massachusetts, USA\n\nThis book explores the social forces among and between online aggressors \nthat affect the expression and perpetration of online hate. Its chapters illustrate how patterns of interactive social behavior reinforce, magnify, or modify this expression. It also considers the characteristics of social media that facilitate social interactions that promote hate and facilitate relationships among haters. Bringing together a range of international experts and covering an array of themes, including woman abuse, antisemitism, pornography, radicalization, and extreme political youth movements, this book examines the specific social factors and processes that facilitate these forms of hate and proposes new approaches for explaining them.\nCutting-edge, interdisciplinary, and authoritative, this book will be of \ninterest to sociologists, criminologists, and scholars of media, communication, and computational social science alike, as well as those engaged with hate crime, hate speech, social media, and online social networks.\nJoseph B. Walther  is the Bertelsen Presidential Chair of Technology and \nSociety, and Distinguished Professor of Communication at the University of \nCalifornia Santa Barbara, California, USA.\nRonald E. Rice is the Arthur N. Rupe Chair in Social Effects of Mass \nCommunication, and Distinguished Professor of Communication at the University of California Santa Barbara, California, USA.SOCIAL PROCESSES OF  \nONLINE HATE\n\nSOCIAL PROCESSES OF \nONLINE HATE\nEdited by Joseph B. Walther and Ronald E. Rice\n\nDesigned cover image: \u00a9 Graham Glass/Joseph B. Walther and Ronald E. Rice\nFirst published 2025\nby Routledge4 Park Square, Milton Park, Abingdon, Oxon OX14 4RN\nand by Routledge\n605 Third Avenue, New York, NY 10158\nRoutledge is an imprint of the Taylor\u00a0& Francis Group, an informa business\u00a9 2025 selection and editorial matter, Joseph B. Walther and  \nRonald E. Rice; individual chapters, the contributors\nThe right of Joseph B. Walther and Ronald E. Rice to be identified as the \nauthors of the editorial material, and of the authors for their individual chapters, has been asserted in accordance with sections 77 and 78 of the Copyright, Designs and Patents Act 1988.\nThe Open Access version of this book, available at www.taylorfrancis.com,  \nhas been made available under a Creative Commons Attribution-Non Commercial-No Derivatives (CC-BY-NC-ND) 4.0 International license.\nAny third party material in this book is not included in the  \nOA Creative Commons license, unless indicated otherwise in a credit line to the material. Please direct any permissions enquiries to the original rightsholder.\nTrademark notice: Product or corporate names may be trademarks \nor registered trademarks, and are used only for identification and explanation without intent to infringe.\nBritish Library Cataloguing-in-Publication Data\nA catalogue record for this book is available from the British Library\nISBN: 978-1-032-75047-7 (hbk)\nISBN: 978-1-032-75042-2 (pbk)ISBN: 978-1-003-47214-8 (ebk)\nDOI: 10.4324/9781003472148Typeset in Sabon\nby Apex CoVantage, LLC\nWe wish to express our immense gratitude to  \nSandra Walther and Claire B. Johnson, for their \npatience and support.\n\nList of Figures  xi\nList of Tables  xiii\nList of Contributors  xiv\nAcknowledgments  xxii\n 1 Introduction to Social Processes of Online Hate  1\nJoseph B. Walther and Ronald E. Rice\n 2 Making a Case for a Social Processes Approach to  \nOnline Hate  9\nJoseph B. Walther\n 3 Foundations, Definitions, and Directions  \nin Online Hate Research  37\nStephanie Tom Tong\n 4 Misogyny and Woman Abuse in the Incelosphere:  \nThe Role of Online Incel Male Peer Support  73\nWalter S. DeKeseredy\n 5 From Echo Chambers to Digital Campfires: The \nMaking of an Online Community of Hate in Stormfront  93\nAnton T\u00f6rnberg and Petter T\u00f6rnbergCONTENTS\nx Contents\n 6 \u201cDeal\u201d of the Day: Sex, Porn, and Political Hate on \nSocial Media  120\nSahana Udupa and Oeendrila Lahiri Gerold\n 7 Digitally Mediated Spillover as a Catalyst of \nRadicalization: How Digital Hate Movements Shape \nConservative Youth Activism  144\nAdam Burston\n 8 \u201cHate Parties\u201d: Networked Antisemitism from the \nFringes to YouTube  168\nStephen C. Rea, Binny Mathew, and Jordan Kraemer\n 9 Information Sharing and Content Framing across \nMultiple Platforms and Functional Roles That \nExemplify Social Processes of Online Hate Groups  193\nShruti Phadke and Tanushree Mitra\n10 Detecting Antisocial Norms in Large-Scale Online \nDiscussions  220\nYotam Shmargad, Stephen A. Rains, Kevin Coe,  \nKate Kenski, and Steven Bethard\n11 Understanding the Phases and Themes of Coordinated \nOnline Aggression Attacks  250\nGianluca Stringhini and Jeremy Blackburn\n12 Background Scholarship and a Synthesis of Themes in \nSocial Processes of Online Hate  273\nRonald E. Rice\nIndex  301\n 2.1 Antisemitic Meme  18\n 2.2 Stormfront.org Homepage  19\n 2.3 Welcome to Stormfront Discussion Board  19\n 2.4 Quoted Text from Welcome Screen for Gab\u2019s  \nNew N**ger Meme Repository  27\n 5.1 Convergence of Forum Posters\u2019 Language over Time  103\n 6.1 A\u00a0Tweet on Sulli Deal  129\n 6.2 Meme Shared in the Chat Group  131\n 8.1 Screenshot of Replies to a Gab Post Discussing a Mark \nDice YouTube Video  181\n 8.2 Screenshot of a Gab Post Celebrating the Antisemitic  \nComments on a Mark Dice YouTube Video  186\n 9.1 Information-Sharing Network by White Supremacy Groups  201\n 10.1 A\u00a0Framework for Using Online Discussion Data to Study \nSocialization Processes  224\n 10.2 Organizing Comments into Triplets  227\n 10.3 Correlation Matrix for Measures of in Online  \nNews Comments  230\n 10.4 Log-Log Plot of Down and Upvotes after Article  \nStandardization  231\n 10.5 Effects of Antisocial Commenting on Votes with 95% \nConfidence Intervals  232\n 10.6 Testing TNSB with Human Annotation and Automated \nClassification of Incivility  234\n 10.7 Testing TNSB with Google\u2019s Perspective API and  \nNew York Times  Attributes  235FIGURES\nxii Figures\n 10.8 Correlation Matrices for Initial Comments on Reddit  \nand Twitter  239\n 10.9 Effect of Antisocial Commenting on Votes across Reddit \nand Twitter  241\n 10.10  Testing TNSB on Reddit and Twitter during the \nJanuary 6th Capitol Riots  243\n 11.1 Software Architectural Design (\u201cPipeline\u201d)  \nof Crawler Processes  253\n 12.1 Growth in Occurrence of \u201conline hate\u201d in Google Books  275\n 12.2 Growth in News Coverage of \u201conline hate\u201d  279\n 12.3 Growth in Academic Articles Referring to \u201conline hate\u201d  280\n 3.1 A\u00a0Relational/Broadcast Taxonomy of Online Hate  43\n 6.1 Activities Related to Auctions and Pornified Content on \nDifferent Platforms  131\n 6.2 Corpus Description  134\n 6.3 Frequency of Themes  135\n 7.1 Informant Data  150\n 9.1 Frame Annotation Scheme  197\n 9.2 Features Used to Identify Roles in Online Extremist \nMovements on Facebook  206\n 9.3 Descriptive Statistics for the 4,876 Extremist Accounts in \nthe Dataset  207\n 9.4 Roles and the Corresponding Percent of Extremist \nAccounts in the Dataset  207\n 9.5 Link Posting Activities by Various Roles  210\n 10.1 Summary Statistics of Antisocial Commenting in the \nArizona Daily Star  228\n 10.2 Definitions and Examples of Antisocial Commenting in the \nArizona Daily Star  229\n 10.3 Effects of Antisocial Commenting on Downvotes and Upvotes  232\n 10.4 Means and Standard Deviations of Antisocial Commenting \non Reddit and Twitter  238\n 10.5 Effects of Antisocial Commenting on Votes in the Initial \nComments  240\n 12.1 Several Recent Books about (Primarily) Online Hate  275\n 12.2 Digital Media Affordances Facilitating Online Hate \nMentioned in Chapters  283\n 12.3 Venues for Online Hate Mentioned in the Chapters  290TABLES\nSteven Bethard  is Associate Professor at the School of Information at the \nUniversity of Arizona, Tucson, Arizona, USA, with courtesy appointments \nin linguistics, cognitive science, computer science, and applied mathematics. Steven Bethard previously worked as an assistant professor of computer and information science at the University of Alabama at Birmingham and as a postdoctoral researcher at Stanford University\u2019s Natural Language Process -\ning Group, Johns Hopkins University\u2019s Human Language Technology Center of Excellence, KULeuven\u2019s Language Intelligence and Information Retrieval group in Belgium, and the University of Colorado\u2019s Center for Language and Education Research. He got his Ph.D. in computer science and cognitive sci-ence from the University of Colorado Boulder, Colorado, USA. Bethard\u2019s research interests include natural language processing and machine learning theory and applications, including modeling the language of time and time -\nlines, normalizing text to medical and geospatial ontologies, and information extraction models for clinical applications.\nJeremy Blackburn  is Associate Professor, Department of Computer Science, \nBinghamton University, State University of New York, New York, USA. Jer -\nemy Blackburn joined the Department of Computer Science at Binghamton University in fall 2019. Jeremy is broadly interested in data science, with a focus on large-scale measurements and modeling. His largest line of work is in understanding jerks on the Internet. His research into understanding toxic behavior, hate speech, and fringe and extremist Web communities has been covered in the press by The Washington Post, the New York Times, \nThe Atlantic, The Wall Street Journal, the BBC, and New Scientist, among \nothers. Prior to his appointment at Binghamton, Jeremy was an assistant CONTRIBUTORS\nContributors  xv\nprofessor in the Department of Computer Science at the University of Ala -\nbama at Birmingham, USA. Prior to that, Jeremy was an associate researcher \nat Telefonica research in Barcelona, Spain.\nAdam Burston  is a Ph.D. candidate in sociology at the University of Califor -\nnia, Santa Barbara, USA, with an emphasis in information, technology, and society. His work lies at the intersection of social movements, technology, and identity. His dissertation, \u201cRadicalization vs. Resistance and Recommit -\nment: Why Conservative Youth Accept or Reject Extremism,\u201d focuses on the strategies that right-wing student activists employ to radicalize their moder -\nate peers as well as the ideological shifts in right-wing movements that enable formerly marginalized communities to participate. Before Adam came to UC Santa Barbara, he was a research associate with Carnegie Mellon University\u2019s Department of Engineering and Public Policy and a volunteer crisis counselor with Pittsburgh Action Against Rape.\nKevin Coe  is a professor in the Department of Communication at the Univer -\nsity of Utah, Utah, USA. Professor Coe\u2019s research employs both quantitative and qualitative methods to better understand political communication, news media, and public opinion. He is the coauthor of two books, The Ubiquitous \nPresidency: Presidential Communication and Digital Democracy in Tumul -\ntuous Times (Oxford, 2021, with Joshua Scacco) and The God Strategy: \nHow Religion Became a Political Weapon in America  (Oxford, 2010, with \nDavid Domke), as well as numerous research articles. Professor Coe teaches courses on media, strategic communication, political communication, and content analysis. He is from Tacoma, Washington, and is a product of the Tacoma Public Schools.\nWalter S. DeKeseredy  is Anna Deane Carlson Endowed Chair of Social Sci -\nences, Director of the Research Center on Violence, and Professor of Sociol-ogy at West Virginia University, West Virginia, USA. He is also an adjunct professor in Monash University\u2019s Gender and Family Violence Prevention Center. DeKeseredy has published 28 books, over 130 scientific journal arti -\ncles, and close to 120 scholarly book chapters on violence against women and other social problems. In 2008, the Institute on Violence, Abuse and Trauma gave him the Linda Saltzman Memorial Intimate Partner Vio -\nlence Researcher Award. He also jointly received the 2004 Distinguished Scholar Award from the American Society of Criminology\u2019s (ASC) Division on Women and Crime and the 2007 inaugural UOIT Research Excellence Award. In 1995, he received the Critical Criminologist of the Year Award from the ASC\u2019s Division on Critical Criminology\u00a0& Social Justice (DCCSJ), and in 2008, the DCCSJ gave him the Lifetime Achievement Award. In 2014, he received the Critical Criminal Justice Scholar Award from the Academy of \nxvi Contributors\nCriminal Justice Sciences\u2019 (ACJS) Section on Critical Criminal Justice, and in \n2015, he received the Career Achievement Award from the ASC\u2019s Division on Victimology (DOV). In 2017, he received the Impact Award from the ACJS\u2019s section on Victimology and the Robert Jerin Book of the Year Award from the ASC\u2019s Division on Victimology. In 2022, he was named an ASC Fellow, received the Praxis Award from the DCCSJ, and received the 2022 Robert Jerin Book Award from the ASC\u2019s DOV.\nOeendrila Lahiri Gerold  is a postdoctoral researcher in the online misogyny \nproject funded by the Bavarian Institute for Digital Transformation (BIDT) at the University of Munich (LMU), Munich, Germany. Her research focuses on feminist resistance and religious nationalism in the digital space. Her training is interdisciplinary, with a focus on colonial and postcolonial studies.\nKate Kenski  is a professor in the Department of Communication and School \nof Government and Public Policy at the University of Arizona, Tucson, Ari -\nzona, USA, where she teaches political communication, public opinion, and research methods. Prior to teaching at the University of Arizona, she was a senior analyst at the Annenberg Public Policy Center at the University of Pennsylvania. She is coauthor of\u00a0 The Obama Victory: How Media, Money, \nand Message Shaped the 2008 Election \u00a0 (2010, Oxford University Press) \nand\u00a0Capturing Campaign Dynamics: The National Annenberg Election Sur -\nvey\u00a0(2004, Oxford University Press). She is coeditor of\u00a0 The Oxford Hand-\nbook of Political Communication\u00a0 with Kathleen Hall Jamieson. Dr. Kenski \nhas over 70 publications in venues such as the\u00a0 American Behavioral Scien-\ntist,\u00a0Communication Research,\u00a0 Human Communication Research,\u00a0 the\u00a0Inter-\nnational Journal of Public Opinion Research , the\u00a0 Journal of Applied Social \nPsychology, and\u00a0 Public Opinion Quarterly . Her current research focuses on \nsocial media and incivility, gender and politics, and presidential campaigns. She is the vice chair of the International Communication Association\u2019s Politi -\ncal Communication Division.\nJordan Kraemer  is Director of Research at the Center for Technology and \nSociety, Anti-Defamation League (ADL). Jordan Kraemer is a media anthro-pologist, with expertise studying digital platforms, social inequality, gender, and urban life. She currently directs research on hate and harassment online at the ADL\u2019s Center for Technology and Society. She is the author of a forth -\ncoming book on social and mobile media among an emerging middle class in Berlin from Cornell University Press. Her work has also been published in Catalyst: Feminism, Theory, Technoscience; Global Perspectives; Anthro-\npological Quarterly; and Fast Company, among others. Previously, she was \nan SSRC Just Tech grantee and a Mellon Postdoctoral Fellow at Wesleyan University and taught feminist and queer technology studies at NYU Tandon \nContributors  xvii\nSchool of Engineering. Jordan holds a Ph.D. in cultural anthropology from \nUC Irvine.\nBinny Mathew  is Machine Learning Scientist at the Center for Technology \nand Society, ADL, New York, USA. Binny Mathew is a natural language pro -\ncessing researcher, with an interest in online hate speech and counter meas -\nures. Prior to joining the ADL, he was part of CNERG at the Indian Institute of Technology, Kharagpur, West Bengal, India. His work has been published in several top-tier computer science and data science conferences, including PNAS, AAAI, ECML-PKDD, The WebConf (WWW), CSCW, ICWSM, and WebSci. He has also contributed multiple high-quality datasets and models to the research community. Binny received his Ph.D. in social computing from IIT Kharagpur in 2022.\nTanushree Mitra  is an assistant professor in the Information School at Uni -\nversity of Washington. Her research interests are in social computing, where she combines ideas from both computer science and social science to uncover insights about social life online via large datasets. Currently, one major focus of her research is understanding and designing defenses against problematic information in online social platforms. Her work employs a range of interdis -\nciplinary methods from the fields of human computer interaction, data min -\ning, machine learning, and natural language processing. From August 2017 to 2020, she was an assistant professor in the Department of Computer Sci -\nence at Virginia Tech. She earned her Ph.D. in computer science from Georgia Tech. Currently, Dr. Mitra is also an adjunct affiliate of University of Wash -\nington Department of Computer Science and Engineering, an affiliate faculty of the Center for an Informed Public, and a cofounding director of RAISE, a Center for Responsibility in AI Systems and Experiences.\nShruti Phadke  is a researcher at the University of Texas at Austin, Texas, \nUSA, with a Ph.D. in information science from the University of Washington. Her research focuses on computationally understanding participation, social knowledge construction, and resource mobilization in online communities of problematic information. Her research benefits from multiple methodo -\nlogical approaches ranging from statistics, causal machine learning, natural language processing, and qualitative methods. Her research has received two Best Paper Honorable Mention awards at CSCW and the Best Paper Award at ICWSM 2022.\nStephen A. Rains  is a professor of Communication at the University of Ari -\nzona. His research is situated in the areas of health communication, social influence, and communication and technology. He is interested in bet -\nter understanding how and why messages influence people, particularly in \nxviii  Contributors\nhealth contexts and when using communication technologies. His work in \nrecent years has primarily focused on social support, though he routinely studies digital coping, incivility, persuasion resistance, and related topics. He is especially interested in leveraging computational social science tech -\nniques to explore the dynamic communication processes involved in these phenomena.\nStephen C. Rea  is a senior researcher with the Critical Internet Studies \nInstitute (https://www.publicinterestinter.net/). A\u00a0 cultural anthropologist, Stephen\u2019s research expertise is in digital culture, with a focus on trust and community. His projects have included multi-year ethnographic research on South Korean online gaming culture, digital consumer financial services in the global South and the United States credit union system, the social and legal implications of automated decision-making systems, fairness and ethics in crowd work labor markets, engineering ethics education, and online hate and harassment and digital extremism on social media. Stephen\u2019s work has been published in American Anthropologist, the Journal of the Royal Anthro -\npological Institute, Signs and Society, and Law\u00a0& Policy, among others. He \nhas held academic appointments as a visiting assistant professor at Bucknell University; a lecturer at the University of California, San Diego; a postdoc -\ntoral scholar at the University of California, Irvine, California, USA; and a research assistant professor at the Colorado School of Mines. He worked as a senior researcher for the Center for Technology and Society at the ADL. He received his Ph.D. in anthropology from the University of California, Irvine, California, USA, in 2015.\nRonald E. Rice  is Arthur N. Rupe Chair in Social Effects of Mass Communica -\ntion and Distinguished Professor of Communication at the University of Cal-ifornia Santa Barbara, Santa Barbara, California, USA. Ronald E. Rice has been an officer in both the International Communication Association and the Academy of Management and was elected president (2006\u20132007) and fellow (2010) of the International Communication Association (ICA). He was hon -\nored with the ICA Steven Chaffee Career Achievement Award (2015), a Ful -\nbright Award in Finland (2006), and was the Wee Kim Wee Visiting Professor, and then University Visiting Professor, of the School of Communication and Information at Nanyang Technological University in Singapore (2007\u20132010). He holds an honorary doctorate from the University of Montreal. He has conducted research and published widely in communication science, pub -\nlic communication campaigns, computer-mediated communication systems, research methodology, organizational and management theory, information systems, information science and bibliometrics, and social networks. His pub -\nlications have won awards for best dissertation from the American Society for Information Science, 17 times for best paper from the International Com -\nmunication Association, National Communication Association, Broadcast \nContributors  xix\nEducation Association, Conference on Computer-Supported Collaborative \nWork, Academy of Management, and Russian Communication Association, and a book award from the Health Communication Division of ICA. He has coauthored or coedited Public Communication Campaigns  (1st ed. in 1981, \n2nd ed. in 1989, 3rd ed. in 2001, and 4th ed. in 2012, Sage),\u00a0 The New Media: \nCommunication, Research and Technology \u00a0(1984, Sage),\u00a0Managing Organi-\nzational Innovation\u00a0(1987, Columbia University Press),\u00a0 Research Methods \nand the New Media\u00a0(1988, The Free Press),\u00a0 The Internet and Health Com-\nmunication\u00a0 (2001, Sage),\u00a0 Accessing and Browsing Information and Com-\nmunication\u00a0(2001, MIT Press),\u00a0 Social Consequences of Internet Use: Access, \nInvolvement and Interaction\u00a0 (2002, MIT Press),\u00a0 The Internet and Health \nCare: Theory, Research and Practice \u00a0(2006, Erlbaum),\u00a0 Media Ownership: \nResearch and Regulation\u00a0(2008, Hampton Press), Organizations and Unu-\nsual Routines\u00a0(2010, Cambridge University Press), and The Oxford Hand -\nbook of Digital Technology and Society (2020, Oxford University Press).\nYotam Shmargad  is an associate professor in the School of Government and \nPublic Policy at the University of Arizona. His research focuses on under -\nstanding how digital platforms shape social and political life in the United States. He uses a mix of statistical and computational techniques, includ -\ning social network analysis, online data collection, virtual experimentation, machine learning, and econometric methods. His research speaks to ques-tions about how social media dampen certain disparities while magnifying others and how social media can both fuel political polarization and incivility and extinguish their flames. Shmargad\u2019s work has appeared in the Journal \nof Politics, Political Communication, the Journal of Information Policy, the \nJournal of Political Marketing, the Journal of Interactive Marketing, PLOS \nOne, Social Science Computer Review, and the Journal of the Association for \nInformation Science and Technology, among other venues.\nGianluca Stringhini  is an associate professor in the Electrical and Computer \nEngineering Department at Boston University, holding affiliate appointments in the Computer Science Department, in the Faculty of Computing and Data Sciences, in the BU Center for Antiracist Research, and in the Center for Emerging Infectious Diseases Policy\u00a0& Research. In his research, Gianluca applies a data-driven approach to better understand malicious activity on the Internet. Through the collection and analysis of large-scale datasets, he develops novel and robust mitigation techniques to make the Internet a safer place. His research involves a mix of quantitative analysis, (some) qualitative analysis, machine learning, crime science, and systems design. Over the years, Gianluca has worked on understanding and mitigating malicious activities like malware, online fraud, influence operations, and coordinated online harassment. He received multiple prizes, including an NSF CAREER Award in 2020, and his research won multiple Best Paper Awards. Gianluca has \nxx Contributors\npublished over 100 peer-reviewed papers, including several at top computer \nsecurity conferences like IEEE Security and Privacy, CCS, NDSS, and USE -\nNIX Security, as well as at HCI, and Web conferences such as IMC, ICWSM, CHI, CSCW, and WWW.\nStephanie Tom Tong  is a professor in the Communication Department at \nWayne State University, Detroit, Michigan, USA. She is Director of the Social Media and Relational Technologies (SMART; http://www.smartlabswayne.\ncom/) Labs, which investigates how technology affects the ways people com -\nmunicate across a variety of contexts, including romance, families, friend-ships, personal health, and online hate. Her work has been supported by the National Science Foundation, the National Communication Association, and the Central States Communication Association.\nAnton T\u00f6rnberg  is an associate professor in the Department of Sociology and \nWork Science at the University of Gothenburg, Gothenburg, Sweden. His research chiefly focuses on the radical right movement online, particularly radicalization processes and violent extremism, by combining computational methods with qualitative approaches. He is currently involved in a research project that addresses the far right online and the interplay between online discourses and offline action.\nPetter T\u00f6rnberg  is an assistant professor of computational social science,\u00a0Uni -\nversity of Amsterdam, Amsterdam, the Netherlands. In addition to his work at the University of Amsterdam, Petter T\u00f6rnberg holds appointments at the University of Neuch\u00e2tel, Neuch\u00e2tel, Switzerland, and is Associate Professor of Complex Systems at Sweden\u2019s Chalmers University of Technology. His concerns revolve around how digital technology is reshaping our politics, media, and cities. He uses computational methods and digital data to exam -\nine the consequences of datafication, platformization, and AI from a critical perspective.\nSahana Udupa  is a professor of media anthropology at the University of \nMunich (LMU), Germany, where she directs the research program \u201cFor Digi-tal Dignity.\u201d She is the author of Making News in Global India (Cambridge \nUniversity Press) and Digital Unsettling: Decoloniality and Dispossession in the Age of Social Media  (New York University Press, with E.G. Dattatreyan) \nand is coeditor of Digital Hate: The Global Conjuncture of Extreme Speech (Indiana University Press) and Media as Politics in South Asia (Routledge). \nShe is the recipient of the Joan Shorenstein Fellowship at Harvard Univer -\nsity, the Francqui Chair in Belgium, and European Research Council grant awards.\nContributors  xxi\nJoseph B. Walther  holds the Bertelsen Presidential Chair in Technology and \nSociety at the University of California, Santa Barbara, where he is a dis -\ntinguished professor of communication and former director of the Center \nfor Information Technology and Society. A\u00a0Fulbright Scholar, Fellow of the International Communication Association, and Distinguished Scholar in the National Communication Association, he is one of the leading theorists in the area of computer-mediated communication, with numerous behavioral science studies to his credit. His research focuses on the impact of interper -\nsonal and intergroup dynamics on the attitudes and behaviors people develop via mediated interaction in personal relationships, groups, and interethnic conflict, as well as the reduction of prejudice. Prior to his position at UC Santa Barbara, he has held regular or visiting faculty positions at several prestigious universities in the United States, Europe, and Asia, in the fields of communication, social psychology, education, and information science. Professor Walther was recognized with the Charles Woolbert Awards from the National Communication Association on two occasions, for articles that have led to reconceptualizations of communication phenomena and have stood the test of time.\nWe wish to acknowledge the support of the following generous and extremely \ntalented people.\nThe Arthur N. Rupe Foundation and Mark C. Henrie, its President, pro -\nvided funding for the conference though its endowment of the Arthur N. Rupe Professor in the Social Effects of Mass Communication (held by Professor Rice), in the UCSB Department of Communication. Through the endowment, they have helped sponsor a diverse range of biennial Rupe Conferences (see http://www.comm.ucsb.edu/news-events/annual/rupe), covering environmen-tal communication, media industry and regulation, and the cosponsored Con-ference on Social Processes of Online Hate.\nMark and Susan Bertelsen and the President of the University of California \ngenerously helped to establish the Bertelsen Presidential Chair in Technology and Society (held by Professor Walther). The Bertelsens are UCSB alumni and UCSB Trustees and provide long-standing support of the Center for Informa -\ntion Technology and Society and other campus endeavors.\nAcknowledgments are also due to the Berkman Klein Center for the Inter -\nnet and Society at Harvard University, which supported Professor Walther as a visiting scholar in its Institute for Rebooting Social Media. Embedded in Harvard Law School, the Center\u2019s focus on the consequences of social media\u2019s design and governance, and the seeking of social justice through research, interaction with industry, policy, and the law, provided many use-ful lessons and outstanding connections that helped shape this work. So did many helpful conversations with scholars at nearby Boston University and at Northeastern University\u2019s Network Science Institute.\nProfessor Sharon Tettegah, Associate Vice Chancellor for Diversity, Equity, \nand Inclusion, and the Director of the Center for Black Studies Research at ACKNOWLEDGMENTS\nAcknowledgments  xxiii\nUCSB, supported this research and the May 2023 conference since they were \nbut a whisper and supported several students working with us on explora -\ntory research.\nWe are thankful to the following from the UC Santa Barbara Department of \nCommunication: Michelle Fredrich, Financial Assistant and event-planning wizard; Lindsay Miller, graduate student, conference assistant, and probably the fastest learner of the arcane UCSB financial and travel software; Audrey Francis, office assistant and a master of professional detail and cheerfulness; Vivian Hsaio, social media intern and creative designer of the conference posters and flyers; and Tammy Affifi, Professor and Chair, inspirational and energetic supporter and leader. Thanks to Graham Glass, Social Media Asso -\nciate, UC Santa Barbara, Department of Communication for producing the book cover image, from the initial design by Walther and Rice.\nWalter S. DeKeseredy, author of a chapter in this book, helped promote \nour book proposal to Routledge Books; Thomas Sutton, the publisher for the Criminology and Criminal Justice series for Routledge Books, provided immediate support and helpful advice, as did Jessica Phillips, Editorial Assis-tant, Criminology and Criminal Justice, Routledge Books; and the copyedi-tor Sutapa Mazumder and indexer Connie Angelo.\n\nDOI: 10.4324/9781003472148-1\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.In 1971, Murray Davis wrote an article in the American Journal of Sociol -\nogy, titled \u201cThat\u2019s Interesting!\u201d He argued that a lot of research may be good, \nand incrementally useful, but it is not necessarily interesting. What makes \nresearch interesting, he wrote, is when it defies intuition. When it asserts something that is the opposite of common knowledge. When it expresses a premise that conflicts with the accepted premises and then derives from these premises predictions and hypotheses that must be true if the premise is cor -\nrect. Among the ways that research can be interesting, according to Davis, are the following:\n\u2022 What seems to be a disorganized phenomenon is actually an organized \nphenomenon.\n\u2022 What seems to be an individual phenomenon is in reality a holistic \nphenomenon.\n\u2022 What seems uncorrelated is correlated.\n\u2022 What is bad is in some way good.\nThat\u2019s interesting, according to Davis. We would add, to investigate that, and substantiate it, is not only interesting, it\u2019s important as well. Potentially groundbreaking. Paradigm-shifting.\nEach of the scholars whose work appears in this volume is interesting. \nTheir work is groundbreaking and paradigm-shifting. Each of them has dis -\ncovered ways to prove that the production and propagation of hate messages on social media are not individual acts, not uncorrelated, not disorganized, but part of various social processes and systems. That people produce racist messages, sexist messages, and harassment, not only, or not even primarily, 1\nINTRODUCTION TO SOCIAL PROCESSES \nOF ONLINE HATE\nJoseph B. Walther and Ronald E. Rice\n2 Joseph B. Walther and Ronald E. Rice\nto inflict harm to victims. Hate posters do it to engage in collective behavior, \nto get attention and admiration, to fit in, to advance a comforting (if deviant) virtual community, to perpetuate and respond to the negotiation of social norms, to entertain each other, and even to share in the fun of disparaging other people. It seems distasteful and misguided, if not downright evil, even to think about this form of verbal terrorism as being a source of fun for those who do it, but once you think it and ask yourself if it makes sense, you can\u2019t unthink it anymore.\nThe scholars whose work follows have found different ways of under -\nstanding how the spreading of hate online is not necessarily something that is expelled from the inside out, from a person\u2019s inner core of racism, dis -\ntorted masculinity, personality, or that they are \u201cbad actors,\u201d or that their messages are necessarily directed at an individual or group target. Rather, we learn from their work what the gratifications are that might appeal to anyone whose ego is threatened, who could use a scapegoat, who is other -\nwise depleted materially or emotionally, or who is afraid (justifiably or not) of being replaced, contaminated, or eliminated. Who finds that taking the role of a victim, or a prospective victim among other prospective victims, is comforting. And that being snarky, or witty, or clever, or scary, gets them liked by others who are willing to echo their sentiments. Gets them upvoted. Retweeted. Friended. Followed.\nOf course, there has always been prejudice and there have always been \nhate messages, and social media didn\u2019t breathe them into existence. But social media changed the equation. The means of production. The affordances for exposing thoughts to others and being exposed to others\u2019 thoughts. The ease of collaboration. The ability to find and follow like-minded others. The abil-ity to craft spontaneous-looking messages, sometimes in sequence, quite stra -\ntegically and deliberately.\nFrom a social processes approach to online hate, in some respects, the \nbehavior is some weird manner of sport. A\u00a0sport that requires no particular training or ability (and as several chapters show, the skills can be learned as one progresses on the team), where the team members support one another, where there are dozens or hundreds or even thousands of cheering spectators who applaud the players with Likes and Hearts and Upvotes and Retweets and cross-platform links, and fans, many of whom take their turns on the field as well.\nAlthough we do not address what causes hate in the first place, we contend \nthat the ebb and flow of its expression online is primarily influenced through social processes, not individuals and not personality traits. We cannot afford to allow ourselves to explain the expression of online hate as a product of a specific person\u2019s psychopathology or any other individual characteristics. We cannot afford to consider it sufficient to explain online hatred as merely a modern manifestation of existing in-group/out-group antipathies that simply \nIntroduction to Social Processes of Online Hate  3\nmanifest in new digital ways. To assume that it is a small number of atypical \nindividuals. To assume that the people who write it and share it are evil. The reason we cannot afford to do this is that the mistake has been made before. If we simply dismiss its creators as bad actors or racists, we overlook subtle yet ultimately powerful social factors, magnified through social interactions and redistributed through digital social media, that can lead individuals into doing things they otherwise might not. A\u00a0recent study titled \u201cAnyone can become a troll: Causes of trolling behavior in online discussions\u201d ( Cheng \net\u00a0al., 2017) found that there are two triggers that can lead anyone to post hostile messages online: Being in a really bad mood and seeing other people posting hostile messages. So we do not dare attribute online aggression to a minority of inherently bad actors. We cannot afford to repeat the mis -\ntake of assuming there are only a small number of neo-Nazis ( Woolf, 2008); \nthere were only 60 Nazis in 1920, but there were 8.6 million Nazis by 1945, because of social pressures\u00a0\u2013 because the dark corners of defamation and denigration seep into the mainstream, and because the opportunity to par -\nticipate in a collective that allowed people to feel good about themselves by being superior to others can, for many, be almost too good to resist.\nNor do we address the question of whether online hate leads to offline \naggression, although that outcome, and other harms befalling the victims of hate, implicitly drive our concern over the phenomenon itself (see Tong, this volume, for considerations of other outcomes). Understanding the social bases and effects of hate was for a time the utmost preoccupation of post-WWII social sciences. Might online hate stimulate desensitization to human suffer -\ning, a reinforcement of a sense of moral superiority, rationalizing peremptory self-defense to imagined threats, or ultimately to murder and hate crimes? Is physical aggression a byproduct or an outgrowth of the cultivation of social acceptance, community, and attention that, as several chapters in this book argue, may be at the heart of online hate messaging? On these questions, unfortunately, the implications of a social processes approach to online hate are mixed.\nWe know that online hate messaging can certainly provide logistical and \noperational communication that facilitates real-world, physical confronta-tions (Wahlstr\u00f6m\u00a0& T\u00f6rnberg, 2021). Yet for all the bravado and calls for action that hate messages often express, as T\u00f6rnberg and T\u00f6rnberg (this vol -\nume) describe, the online discussions of White Nationalists more often reflect their resignation over the multiracial state of the society. Rather than plot offline aggression, Stormfront members verbally deconstruct just how the deplorable status quo came to be and what actions could have averted it but were not, in fact, taken.\nWe do not dismiss the possibility that participation in online hate mes -\nsaging increases the propensity for offline violence, although we think it is important to learn more about when and why such a linkage may exist. \n4 Joseph B. Walther and Ronald E. Rice\nOne possibility is that an individual\u2019s continued public espousal of hate in \nsocial media generates \u201cself-effects\u201d (see Valkenburg, 2017), a process by which individuals magnify the extremity of their own attitudes merely by expressing them to others, and by seeing those attitudes displayed in text and images. Add to self-effects the power of socially generated positive rein -\nforcement in the form of social approval messages from others online (see, e.g., Walther et\u00a0al., 2011 , 2022), and it is even more likely that the hateful \nbeliefs and attitudes one may have held mildly at some point become more extreme, even radicalized, through continued interaction (see, e.g., Burston, this volume).\nPerhaps participation in online hate triggers predispositions toward vio-\nlence that a small number of people possess (e.g., Dunbar\u00a0& Molina, 2004; \nLee et\u00a0al., 2022 ). Such is the prospect of \u201cstochastic terrorism\u201d ( Jones, in \npress; Nelson, 2022; Rae et\u00a0al., this volume) by which influential individual(s) \npublicly \u201cdemonize and dehumanize groups of people\u201d ( Jones, in press , p.\u00a01) \nin deliberate but implicit and ambiguous terms that hate group participants echo and amplify. Even if most participants do not perceive them as an actual call for violent action, a few extreme outliers do so, and it is these few who commit violence. According to Jones (in press, pp.\u00a01\u20132):\nResearchers theorize that stochastic terrorism is nevertheless capable of statistical analysis the results of which positively correlates violence to hate speech; murders increase even if it cannot be determined when, where or how a particular murder will occur. Stochastic terrorism is the raison d\u2019etre of hate groups.\nUnderstanding this complex causal chain, and the role of online hate mes -\nsages within it, is part of what makes an urgent case for understanding online hate as the culmination and reification of social processes.\nAlthough the mechanisms by which online hate leads to offline aggres -\nsion remain subject to further study, it appears that this kind of eventual -\nity is the exception and not the rule. The authors of the chapters in this book argue and illuminate that, to a great extent, online hate posters are in the online hate business largely to have their own kind of enjoyment, to compete for status, cultivate a community, immerse themselves in the sexu -\nally and religiously tinged aspects of their cultures, and even to provide comfort among themselves, and not necessarily with the primary intent to inflict harm and hurt onto others. We feel it deserves renewed priority now that the Internet and social media have resurrected and magnified by orders of magnitude the threat that hate presents to minorities in particular and to civil society at large. It\u2019s important. Potentially groundbreaking. Paradigm-shifting. It is interesting, as Murray Davis (1971) might say. And \nit is urgent.\nIntroduction to Social Processes of Online Hate  5\nBackground for the Book\nThis edited book is the product of our own various social processes and \nlong-term interests. On May 11, 2023, the coeditors held a full-day public con -\nference at University of California, Santa Barbara, involving leading scholars whose work addresses a \u201csocial processes\u201d approach to online hate (https://www.comm.ucsb.edu/news-events/annual/rupe#2023RupeCITS). The event was sponsored by the Center for Information Technology and Society, the Bertelsen Presidential Chair in Technology and Society (Professor Joseph B. Walther), the Arthur N. Rupe Chair in the Social Effects of Mass Media (Pro-fessor Ronald E. Rice), and the UCSB Center for Black Studies Research.\nWe carefully selected outstanding researchers to participate in the con -\nference, based on their prior work\u2019s consideration of social processes. Each participant presented their work in a half-hour session, followed by a question-and-answer session. As part of the overall project leading toward the book, the presenters provided drafts of their papers a week before the conference. After the one-day conference, we convened a workshop the next two days, during which we devoted considerable attention to deeper analysis and feedback for each chapter draft that participants had prepared. Each of these sessions involved the author\u2019s initial expansion about their work, followed by prepared reviews from two other participants, followed by addi -\ntional, open feedback amongst the group. These were not formal reviews as for a journal, nor were they required to be written. In the following months, the authors and editors shared multiple revisions with each other, refining the arguments and clarifying the analyses and results.\nThe Chapters\nThe result of this extensive process of personal and mediated interactions, comments and responses, clarifications and extensions, and digressions and elaborations is this collection of superb contributions on various aspects of the social processes of online hate. The chapters include:\n\u201cMaking a Case for a Social Processes Approach to Online Hate\u201d by Dr. \nJoseph B. Walther argues that the audience of online hate messaging is other online haters, more so than the ostensible victims who the messages refer to. Compelling anecdotes and empirical studies on the language, placement, and other characteristics of online hate suggest that its primary purpose is to entertain and nurture relations among haters. Social processes better explain online hate than do traditional, personality-based approaches.\n\u201cFoundations, Definitions, and Directions in Online Hate Research\u201d by \nDr. Stephanie Tom Tong provides a comprehensive overview of findings related to the prevalence of online hate, its various content and message char -\nacteristics, and the effects of online hate on those who experience it. It offers a \n6 Joseph B. Walther and Ronald E. Rice\nnew taxonomy of hate messaging behavior depending on the targets and the \npublicness of social media hate.\n\u201cMisogyny and Woman Abuse in the Incelosphere: The Role of Online \nIncel Male Peer Support\u201d by Dr. Walter S. DeKeseredy describes how incels, or involuntarily celibate males, use online community to share their invec-tives against \u201cStacys\u201d (women who resist their sexual advances) and \u201cChads\u201d (men who are sexually active). The chapter applies male peer support theory to explain how, online, participants console each other and rationalize one another\u2019s hatred toward others.\n\u201cFrom Echo Chambers to Digital Campfires: The Making of an Online \nCommunity of Hate in Stormfront\u201d by Drs. Anton T\u00f6rnberg and Petter T\u00f6rn -\nberg examines participation in one of the longest-standing interaction sites explicitly for White Nationalists, Stormfront.org. They describe how Storm -\nfront provides its participants community through storytelling, and how new participants\u2019 language converges over time toward that of veteran users, as their expressions and worldviews about other races and religions become uniformly extreme.\n\u201c \u2018Deal\u2019 of the Day: Sex, Porn, and Political Hate on Social Media\u201d by \nDr. Sahana Udupa and Oeendrila Lahiri Gerold begins with an account of fake auctions of Muslim women online in India unbeknownst to the women whose pictures were stolen. The essay and its original data analyses explore the overlapping social forces of religious majoritarianism, the pornification of online culture, and other factors that feed hatred toward Muslims and women online, veiled in techno-entertainment and fun.\n\u201cDigitally Mediated Spillover as a Catalyst of Radicalization: How Digital \nHate Movements Shape Conservative Youth Activism\u201d by Adam Burston offers an in-depth look at how college campus club members become radi-calized through the influence of new members who previously participated in alt-right social media. The evolution and ultimate dissolution of a college chapter parallel its adoption of and participation in online hate.\n\u201c \u2018Hate Parties\u2019: Networked Antisemitism from the Fringes to YouTube\u201d \nby Drs. Stephen C. Rea, Binny Mathew, and Jordan Kraemer investigates cross-platform hate, when users post messages on a fringe platform link -\ning to and encouraging comments on a different, mainstream platform. The strongest antisemitic fringe postings are linked not to Jewish messages but to antisemitic YouTube videos, where individuals posted additional disparaging remarks. The chapter shows how hate producers use multiple social media platforms to evade restrictions on message content that is prohibited on some platforms but not on others to keep a single conversation going in different social spaces.\n\u201cInformation Sharing and Content Framing Across Multiple Platforms and \nFunctional Roles That Exemplify Social Processes of Online Hate Groups\u201d by Dr. Shruti Phadke and Dr. Tanushree Mitra examines how traditional, \nIntroduction to Social Processes of Online Hate  7\noffline hate groups use Facebook and Twitter/X to create an online ecosphere \nof hate, misinformation, and conspiracies to grow their movements, cultivate new recruits, and spread their dogma.\n\u201cDetecting Antisocial Norms in Large-Scale Online Discussions\u201d by Drs. \nYotam Shmargad, Stephen A. Rains, Kevin Coe, Kate Kenski, and Steven Bethard look at antisocial commenting on news sites generally and on social network platforms during the January 6, 2020 attack on the U.S. Capitol. They describe how norms for toxic postings emerge through the patterns of encouragements, or \u201cupvotes,\u201d others\u2019 toxic comments receive, and the effects of upvotes on one\u2019s own continued toxic postings.\n\u201cUnderstanding the Phases and Themes of Coordinated Online Aggres -\nsion Attacks\u201d by Dr. Gianluca Stringhini and Dr. Jeremy Blackburn examines sequences of events and emergent activities that occur in organized, deliber -\nate, group-based efforts to attack victims with hate postings. They describe five stages of these attacks that are planned and managed on fringe platforms but carried out on mainstream platforms and the feedback loops that enhance and celebrate the attacks on YouTube or as \u201cZoombombing\u201d efforts.\nReferences\nBurston, A. (Chapter\u00a0 7 this volume). Digitally mediated spillover as a catalyst of \nradicalization: How digital hate movements shape conservative youth activism.\nCheng, J., Bernstein, M., Danescu-Niculescu-Mizil, C.,\u00a0& Leskovec, J. (2017).  Anyone \ncan become a troll: Causes of trolling behavior in online discussions. In Proceed-\nings of the 2017 ACM conference on computer supported cooperative work and \nsocial computing (pp.\u00a01217\u20131230). https://doi.org/10.1145/2998181.2998213\nDavis, M. S. (1971).  That\u2019s interesting! Towards a phenomenology of sociology and \na sociology of phenomenology. Philosophy of the Social Sciences , 1(2), 309\u2013344. \nhttps://doi.org/10.1177/004839317100100211\nDunbar, E.,\u00a0& Molina, A. (2004).  Opposition to the legitimacy of hate crime laws: \nThe role of argument acceptance, knowledge, individual differences, and peer influence. Analyses of Social Issues and Public Policy , 4(1), 91\u2013113. https://doi.\norg/10.1111/j.1530-2415.2004.00036.x\nJones, D. K. (in press). Stochastic terrorism, speech incantations, and federal tax \nexemption. New Mexico Law Review. Preprint available ahead of publication in \nSSRN. https://papers.ssrn.com/abstract=4343878\nLee, S. M., Lampe, C., Prescott, J. J.,\u00a0& Schoenebeck, S. (2022). Characteristics of \npeople who engage in online harassing behavior. In Extended abstracts of the 2022 \nCHI conference on human factors in computing systems  (pp.\u00a0 1\u20137). https://doi.\norg/10.1145/3491101.3519812\nNelson, B. (2022, November 5). How stochastic terrorism uses disgust to incite violence.  \nScientific American. https://www.scientificamerican.com/article/how-stochastic-terro  \nrism-uses-disgust-to-incite-violence/\nRae, S., Mathhew, B.,\u00a0& Kraemer, J. ( Chapter\u00a08 this volume). \u201cHate Parties\u201d: Net -\nworked antisemitism from the fringes to YouTube.\nStringhini, G.,\u00a0& Blackburn, J. ( Chapter\u00a011 this volume). Understanding the phases \nof coordinated online aggression attacks.\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). From echo chambers to digital \ncampfires: The making of an online community of hate within Stormfront.\n8 Joseph B. Walther and Ronald E. Rice\nValkenburg, P. (2017). Understanding self-effects in social media. Human Communi-\ncation Research, 43(4), 477\u2013490. https://doi.org/10.1111/hcre.12113\nWahlstr\u00f6m, M.,\u00a0 & T\u00f6rnberg, A. (2021).  Social media mechanisms for right-wing \npolitical violence in the 21st century: Discursive opportunities, group dynamics, \nand co-ordination. Terrorism and Political Violence , 33(4), 766\u2013787. https://doi.\norg/10.1080/09546553.2019.1586676\nWalther, J. B., Lew, Z., Edwards, A. L.,\u00a0 & Quick, J. (2022).  The effect of social \napproval on perceptions following social media message sharing applied to fake news. Journal of Communication , 72(6), 661\u2013674. https://doi.org/10.1093/joc/\njqac033\nWalther, J. B., Liang, Y. J., DeAndrea, D. C., Tong, S. T., Carr, C. T., Spottswood,  \nE. L.,\u00a0& Amichai-Hamburger, Y. (2011). The effect of feedback on identity shift in computer-mediated communication. Media Psychology, 14(1), 1\u201326. https://doi.\norg/10.1080/15213269.2010.547832\nWoolf, L. M. (2008).  The holocaust: Lessons not learned. Peace Psychology, 17(2), \n16\u201320. http://faculty.webster.edu/woolflm/HolocaustLessonsNotLearnedF08.pdf\nDOI: 10.4324/9781003472148-2\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.The production and dissemination of an online hate message in social media \nare typically thought of as acts of aggression, perpetrated by an individual, in order to antagonize certain targets. Although \u201cWe don\u2019t usually think of online harassment as a social activity,\u201d according to Sarkeesian (2012; as cited in Marwick\u00a0& Caplan, 2018, p.\u00a0545),\nwe do know from the strategies and tactics that they used that they were not working alone, that they were actually loosely coordinating with one another. The social component is a powerful motivating factor that works to provide incentives for perpetrators to participate and to actually esca -\nlate the attacks by earning the praise and approval of their peers.\nThe expression of hate online is recognized as one of the biggest problems with social media: \u201cmajor technology companies announced that they were taking unprecedented action against the hate speech\u00a0.\u00a0.\u00a0. that had long flour -\nished on their platforms\u00a0.\u00a0.\u00a0. (yet) the level of online hate and harassment reported by users barely shifted\u201d (Anti-Defamation League, 2018). Online hate includes racist, religious, anti-immigrant, or misogynistic comments and attacks on specific individuals\u2019 reputation, character, privacy, and safety. It takes forms indigenous to social media, such as doxxing, memes, and revenge porn, as well as conventional verbal attacks and threats based on race, eth -\nnicity, gender, sexual orientation, political orientation, or other identity or personal characteristics.\nThere appear to be four major foci of research about online hate\u2019s prolif -\neration in social media. These include (1) documenting the pervasiveness of online hate, (2) describing the contents and forms of hate messaging online, 2\nMAKING A CASE FOR A SOCIAL \nPROCESSES APPROACH TO  ONLINE HATE\nJoseph B. Walther\n10 Joseph B. Walther\n(3) analyzing the effects of online hate on its victims, and (4) identifying \nthe characteristics and motivations of people who propagate hate online, in efforts to explain the behavior. The first three areas appear to have occupied the most research attention to date. An overview of these foci and other trends in online hate research appears elsewhere in this collection (Tong, this volume). The focus of this chapter is on the fourth area\u00a0\u2013 in particular, social motivations.\nWhy people express and propagate hate online and what motivations and \ngratifications impel people to create and share hateful social media postings have been understudied relative to the other research areas. There may be less attention to this question because people think the answer is simple and obvious: There are simply malicious people acting out, and U.S. free speech principles preclude stopping them. It seems, at least as far as the three other perspectives assume, that the problem is inherent and intractable and that there are bigots, racists, and \u201cbad actors\u201d in the world and online, who express their innate hatred as a more or less uninhibited expression of their feelings, to inflict suffering on the targets that are identified or alluded to in the messages.\nAn emerging, alternative explanation focuses on other motives and pro -\ncesses. This chapter develops the argument that online hate is produced as part of complex social processes among the hate messengers themselves. Exploring various social processes may provide a more comprehensive understanding of the production of online hate in social media. This per -\nspective assumes that the patterns of interactive social behavior motivate, reinforce, magnify, and perpetuate the expression of hate online. Among its premises are the notion that online hate is socially organized; that is, it may be planned, managed, enacted, reinforced, diffused, and celebrated among networks of antagonists. It assumes that the production of hate messages has an audience, but it raises the question whether the audience is not only or even necessarily the ostensible victims of online hate messages but rather the \u201cvirtual community\u201d of haters, themselves. It considers that hate is nor -\nmalized and perpetuated through social support among hate posters. One line of argument even suggests that a primary purpose of hate messaging in social media is not necessarily to upset, insult, or terrorize those who appear to be the focus of the hate messages. Rather, the primary intended audience for online hate messages is other people who post online hate messages. The primary purpose of posting hate messages online is to garner social atten -\ntion and social approval from other hate producers, to provide a sense of validation to one another, nurture their relationships and communities, and provide support and encouragement for one another. From this perspective, the individuals and groups that are the victims of online hate are often, tragi -\ncally, collateral damage.\nA social processes approach also considers the characteristics of social \nmedia that facilitate the social interactions leading to the collaborative \nMaking a Case for a Social Processes Approach to Online Hate  11\ncreation and dispersion of hateful messages. Social media provide relatively \nunique methods and facilitate symbolic behaviors that streamline the genera-tion of affirmations and congratulations for one\u2019s fellows\u2019 hostility. These and other new and provocative approaches to online hate have the potential to change our understanding of its production and its prevalence.\nThis chapter explicates several features and processes of online hate that \ndemonstrate the vitality of a social processes approach to the phenomena. It will show that online hate messages often are delivered in venues and using symbolic codes that are unavailable or uninterpretable to the very targets that they denigrate, which supports the contention that hate messages\u2019 pri -\nmary purpose is to commune with other hate posters in addition to, or even more so, than to antagonize victims.\nThe chapter follows with a discussion about the social organization of \nonline hate, the existence of which gives further credence to the notion that hate is a social activity rather than the product of individuals\u2019 enmity. \u201cNet -\nworked harassment\u201d ( Marwick, 2021) and cross-platform raids (see Strin -\nghini\u00a0 & Blackburn, this volume) clearly indicate that online hate is often informally organized and coordinated among proponents, rather than being random, scattered, or coincidental dyadic activities, as one might expect them to be if online hate was simply intended to harm a victim or a social group. It will propose that a variety of socially based gratifications motivate, propel, and reinforce participation in the production and sharing of online hate. These include the suggestion that generating and spreading hate create enjoyment or fun, or solidarity and support, for those who engage in it. It describes the attraction to and easy conveyance of social approval signals in social media interactions, the getting of which may encourage the expres-sion of hate and outrage among homophilous networked peers. It also con -\nsiders research from related areas suggesting how beneficial social support processes emerge among hate producers in their encouragement and mutual exoneration of one another in hate communities. It follows by discussing how research that takes a social processes perspective may generate alterna -\ntive means to mitigate online hate, and, finally, it addresses the question of whether online hate, as a social process, leads to offline confrontations and violence. Before laying out these observations and suggestions, however, is a short description of some more traditional explanatory perspectives about why people generate online hate and the identification of some shortcomings of those perspectives.\nTraditional Explanations about the Production of Online Hate\nUnderstanding the generation of online hate from a social processes perspec -\ntive stands in contrast to a variety of individual-level trait-based and social identification-based approaches that are worth reviewing most briefly.\n12 Joseph B. Walther\nIndividual Differences\nThe promulgation of online hate messaging is often attributed to individual \ndifferences, that is, to personality characteristics of the perpetrators. These characteristics may be as simple as the assumption that some people hold malevolent impulses (Quandt, 2018) or sadistic desires (Phillips, 2015). In other cases, they are more clinical, considering individual factors such as emotional instability; certain demographic characteristics and attitudes; and biases, prejudices, or the holding of stigmatizing beliefs and stereotypes that are often suggested to prime individuals toward hatred. \u201cUnfortunately,\u201d according to a critique of trait-based research on hate production, \u201cmost of the literature on risk factors for hate-motivated behavior\u00a0.\u00a0.\u00a0. lacks rigorous testing and empirical support\u201d (Cramer et\u00a0al., 2020; cf. Lee et\u00a0al., 2022).\nSome research indicates that individual differences are irrelevant and that \n\u201canyone can become a troll\u201d; that is, ordinary people can easily be led to bully, harass, and insult others. As an example, an experiment by Cheng \net\u00a0al. (2017) employed 667 research participants recruited from Mechanical Turk and exposed them to comments from an online political discussion. Participants who they (1) exposed to other people\u2019s trolling, and (2) induced into a negative mood, were almost 200% more likely to write hate messages \n(e.g., \u201c  \u2018What a dumb c***\u2019 and\u00a0.\u00a0.\u00a0. \u2018Y ou\u2019re and idiot and one of the things \nthat\u2019s wrong with this country\u2019\u201d; p.\u00a0 1221) compared to participants in a control condition. This is not to suggest that online interaction causes indi -\nviduals to become racists or bigots who would never otherwise be open to such attitudes. Rather, it is to suggest that once an individual takes the step into posting a hate message online, social processes may be a strong influ -\nence\u00a0\u2013 perhaps the strongest\u00a0\u2013 on their subsequent level of hate messaging. At the very least, interaction effects between dispositional tendencies, social media affordances, and social processes online can magnify the propensity to express hate online (and offline; see Woolf\u00a0& Hulsizer, 2004).\nSocial Identification\nIn contrast to individual differences approaches lies social identification the -\nory, which, in its simplest form, contends that people favor their in-group and denigrate an out-group. Identification with an in-group and seeing one -\nself as a member of that group improve one\u2019s esteem ( Turner et\u00a0al., 1987). \nPeople are attracted to the in-group and, by derivation, to all other in-group members, not because they know and like each other personally but because they all embody the central characteristics that the group values. Some the -\norists contend that members of an in-group can recognize some degree of inter-individual differences among in-group members, whereas others con -\ntend that in-group identification is depersonalized, that is, there is no salient \nMaking a Case for a Social Processes Approach to Online Hate  13\nindividuality among in-group members, who are pragmatically interchange-\nable with one another, from this perspective. Attitudes and perceptions of out-groups, however, instill even greater depersonalization; out-groups seem homogenous, and their members are perceived to share (typically negative) stereotyped characteristics and motives uniformly ( Hogg\u00a0 & Reid, 2006). \nSocial identification moves a step further toward hate when the deperson-alization of the out-group goes so far as to involve dehumanization, or the relegation of an out-group, or a race or ethnicity or sexual identity, as inher -\nently inferior and subhuman (Haslam, 2006).\nThere is little question that in-group/out-group distinctions are strong and \npotentially powerful drivers of online hate perceptions and actions. Thus, for many online hate researchers, social identification theory suffices to explain the enmity that arises among haters toward those whom they hate. Hate messages that targets others, from this perspective, are the manifestation of in-group identification.\nIt can be said, however, that the social identification approach does not go \nfar enough to explain the social dynamics of online hate, for several reasons. The expression of hate messages, from a social identification perspective, can be self-serving rather than socially dynamic. That is, one\u2019s declarations and denigrations of the out-group or of prototypical out-group members need not be public or provoke anyone\u2019s response to achieve their function. They merely must be made, in order for authors to stake their identity claims and to self-categorize (see Turner et\u00a0al., 1987), that is, to perceive oneself as a group member like others. It is not necessary for social identification processes to occur for them to seek or participate in social interactions (although social interactions may reinforce the intergroup perceptions that have already been activated). Thus, hate messages in social media, from a strict interpretation of social identification theory, may be no more than soliloquies performed for oneself, or pubic testimonials, rather than influence messages. They may have esteem and belongingness value and affirm group membership, for one -\nself, whether or not they affect others, from a social identification perspec -\ntive.\n1 While numerous examples of online hate messages appear to satisfy \nthe parameters of social identification (see below regarding in-group slang and symbols), it is theoretically likely that writing those in-group expressions may have dual purposes, both rededicating oneself to in-group identification while also facilitating social and interpersonal interactions, not just social \nidentifications.\nIntent to Harm\nWhether more properly considered as a trait or as a state, the most common assumption in the literature and society at large is that individuals produce online hate messages out of an intention to antagonize, ostracize, or harm \n14 Joseph B. Walther\nsome target or victim. Aside from the group identification approach con -\nsidered above, this assumption accompanies almost every consideration of \nonline hate. The assumption seems to make so much intuitive sense that it is hardly challenged. Survey results about the prevalence of being victimized online suggest support for this contention:\nMore than half of Americans younger than 30 (64%) have experienced online harassment, as have half of 30\u201359 year-olds, and a quarter of Americans older than 50; half of women (47%) say they think they have encountered harassment online because of their gender, whereas 18% of men who have been harassed online say the same. Similarly, about half or more Black (54%) or Hispanic online harassment targets (47%) say they were harassed due to their race or ethnicity, compared with 17% of White targets\u00a0.\u00a0.\u00a0. 50% of lesbian, gay or bisexual adults who have been harassed online say they think it occurred because of their sexual orientation.\n(Vogels, 2021)\nNevertheless, the assumption that the sole or primary purpose of online hate is to harm victims becomes questionable when one considers other social motivations for the expression of hate. Alternative hypotheses come into view when we consider whether the primary audience for hate messages is other hate messengers.\nInsulation: Of Haters, by Haters, for Haters\nIf hate proponents post messages in order to antagonize various targets, it stands to reason that the content of their messages should offer clearly hostile meanings to those targets and that they are posted in a way that is visible to those targets. However, at least two counterarguments exist. First, the anatomy of hate messages reveals considerable in-group symbology that is often unknown or uninterpretable by the targets. Second, hate mongers often retreat into more insulated virtual enclaves in which to post and share hate messages, where their supposed targets may be less and less likely to see their messages.\nSymbology\nHate messages in social media often include symbols and phrases the mean -\ning of which is understood almost exclusively among like-minded partici -\npants. Examples can be found in the international, pancultural list of racial slurs in the Racial Slur Database ( http://rsdb.org/). A\u00a0catalog of symbols and \nabbreviations that are frequently used by White Supremacists appears in the ADL\u2019s hate symbols database ( ADL, n.d.; see also Qian et\u00a0al., 2019). Certain \nMaking a Case for a Social Processes Approach to Online Hate  15\ngraphics, such as the confederate flag or the Nazi swastika, are well recog -\nnized for White Supremacist connotations by insiders and outsiders alike. \nA\u00a0simple rendering of what looks like the Iron Cross ( \u2720) can suffice in the \nproper context. Other symbols, however, are more insidious and private, ren -\ndering them nearly indecipherable by outsiders, including the targets about whom the messages pertain. For instance:\nThe number 14 is used by white supremacists as a shorthand reference to the so-called \u201c14 Words,\u201d which is the most popular white supremacist slogan in the world:\u00a0\u201cWe must secure the existence of our people and a future for white children.\u201d\n(ADL, n.d.)\nThe number 88 \u201cis a white supremacist numerical code for \u2018Heil Hitler.\u2019 H is the eighth letter of the alphabet, so 88\u00a0= HH\u00a0= Heil Hitler. One of the most common White Supremacist symbols, 88 is used throughout the movement.\u201d These coded elements often appear in messages, hashtags, and in the \u201chan -\ndle\u201d or username associated with a writer (see also De Koster\u00a0& Houtman, \n2008). A\u00a0more subtle code construction consists of preceding and following someone\u2019s (((name))) with three parenthesis marks, which denotes that the subject is Jewish (see H\u00fcbscher\u00a0& von Mering, 2022).\nCartoonish caricatures are also frequently used. Some are more univer -\nsally understood, drawing on widespread, historical stereotypes, such as the so-called \u201cHappy Merchant\u00a0.\u00a0.\u00a0. a drawing of a Jewish man with heavily ste-reotyped facial features who is greedily rubbing his hands together\u201d ( ADL, \nn.d.). Others, such as Pepe the Frog, are more highly coded. Pepe the Frog is a green cartoonish character, often depicted as a sophisticate. Despite an emphatic disavowal of hate by the cartoon\u2019s original creator ( Furie, 2016), \nsocial media users frequently appropriate the image for insertion in memes, for example, with Pepe the Frog nonchalantly overseeing cruelty to immi -\ngrants, Mexicans, Jews, or other minorities. These culturally coded symbols reinforce the identities of those who share them while excluding those who do not, including those to whom the hate messages in which they appear often refer.\nPlacement Venues\nWidely accessible, mainstream social media platforms like X.com (formerly Twitter) and Facebook, with highly diverse user bases, are frequent venues for White Supremacist and other online hate promoters. \u201cFor white supremacists that want to make sport out of harassing people of color, Twitter is a \u2018target rich\u2019 environment\u00a0.\u00a0.\u00a0. [with] lots of people of color to target,\u201d according to Daniels (2017). If we question whether harassing people is the primary goal \n16 Joseph B. Walther\nof online hate and hypothesize that interaction among like-minded haters pro -\nvides the primary reward, then diverse \u201ctarget-rich\u201d social media environ -\nments may be, in fact, less desirable arenas in which to exchange online hate. \nSome trends suggest that online hate mongers favor more insulated messaging venues, where prospective victims are less likely, rather than more likely, to go.\nInsulation\nIndeed, research documents the migration of online hate production from wide open conversational spaces into more secluded enclaves. Attempts by various social media platforms to deter online hate messaging seem not to reduce the presence of online hate on the Internet but only to chase it from one venue to another, farther and farther from view by those to whom it refers. For instance, Facebook\u2019s attempts to eliminate hate speech (and other offensive postings) have led the purveyors of hate messaging into more insu -\nlated virtual bunkers within Facebook itself. In 2018, when the platform removed postings or suspended individuals who violated rules against hate messaging, the activity \u201cwent underground\u201d: Many hate messengers, con -\nspiracy mongers, and political extremists migrated from posting on public Facebook pages into posting within private Facebook groups (Albright, \n2018). Despite the size of their membership, sometimes in the thousands or tens of thousands, participation in Facebook groups is by invitation only. They can be hidden from the general Facebook-using public. According to Albright (2018), \u201cindividual posts, photos, events, and files shared within these groups are generally not discoverable through Facebook\u2019s standard search feature or through the APIs that allow content to be retrieved from public pages.\u201d In other words, by using private Facebook groups, hate mes -\nsages about various targets are hidden from likely being viewed by those very \ntargets.\nContent moderation and suspensions, or fear of them, drive whole com -\nmunities to alternative platforms where moderation is either lax or deliber -\nately nonexistent. Mitts (2021) reported that efforts by Facebook and Google to block or remove hateful and extremist content, and account suspensions on Twitter for similar reasons, corresponded to increased hate messaging on alternative, so-called \u201cfringe\u201d platforms that do not moderate the hate content (see Rae et\u00a0al., this volume), including Gab Social and others. Indi-viduals who had accounts both on Twitter and on Gab, Mitts showed, clearly showed migration from one platform to the other, accompanied by signifi -\ncant increases in messages that promote white supremacy and express hate toward minority groups. Gab welcomes people to the site by describing itself as \u201cthe home of free speech\u201d ( Gab.com\u00a0\u2013 Gab Social, n.d.). It \u201ctakes pride \nin its openness to all types of content, including hate speech,\u201d according to Mitts (2021, p.\u00a03). CNN described Gab as \u201ca favorite of bigots and hate groups. People who get banned from mainstream sites like Twitter for hate \nMaking a Case for a Social Processes Approach to Online Hate  17\nspeech or harassment sometimes end up on Gab\u201d ( Stetter\u00a0& Murphy, 2018). \nAlthough there are discussion groups and hashtags that appear to support \nothers, such as Jewish interests and BLM groups, there is easily found racist vitriol. As of this writing, for instance, there are seven discoverable variations on Gab of the username, HitlerWasRight, whose comments are, unsurpris -\ningly, hateful.\nOne might suspect that the seclusion and insulation of hate messages from \nthe targets that they denigrate is, for hate posters, merely an unfortunate byproduct of their needing to avoid stricter content moderation; that if hate posters had their preferences, they would post the same messages in more mainstream, \u201ctarget-rich\u201d environments rather than the fringe sites to which they have fled. The important point here, however, is that the hate messages persist in these fringe spaces, despite the far smaller likelihood that their targets will encounter them. If the sole purpose of online hate messages was to antagonize victims, then the scarce presence of prospective victims to read them would make posting hate messages quite moot and eventually extin -\nguish. Their persistence, away from ostensible victims\u2019 eyes, challenges the notion that they are siloed from their targets by necessity alone.\nIndeed, hate posters seem to take advantage of the relative separation from \nthe presence of their messages\u2019 ostensible targets. ElSherief et\u00a0al. (2018) dis-\ncovered differences in the language between directed hate messages (that are addressed to specific targeted individuals) versus generalized hate messages \n(that express hate about particular groups or persons). The researchers found \nthat, compared to directed hate, generalized hate messages more frequently used collective terms \u201csuch as Jews, Muslims, Christians, Hindus, Shia, Mad -\nina, and Hammas\u201d (p.\u00a047), as well as \u201cthey\u201d rather than \u201cwe,\u201d as would be expected. But there were other, less intuitively obvious language differences, as well. Generalized hate messages about rather than to the targets also con -\ntained more references to killing, murder, and extermination. These findings strongly suggest that hate posters know to whom they are writing and that their audience is not the same as their targets in many very clear cases.\nAudience Specification\nIt is also clear from hate messages\u2019 implicit and explicit indications of to whom they are addressed that they are meant for other hate posters. For instance, Gab hosts a variety of meme repositories the contents of which are often so derogatory about the people they target that it seems extremely unlikely that targeted groups and individuals would wish to peruse them. Beyond leaving it to chance, however, the visual and verbal contents of these entries often explicitly signal that they are addressed to an audience of white people, and what target group they denigrate. They are clearly labeled anti-Muslim, anti-Jewish, and the N**ger Meme Repository, among others. The example meme displayed in Figure\u00a0 2.1 explicitly specifies its audience \n18 Joseph B. Walther\nand its target quite clearly: It is explicitly addressed to \u201cWHITE MAN,\u201d say -\ning that the Zionist Jew is out to \u201cDESTROY YOU.\u201d\nThese virtual spaces clearly seem to be for the amusement of their crea-\ntors and admirers only; the meme repositories do not comprise interactive \nmessage postings but, rather, consist of a display of the memes. In other words, they are not posted in a way that would intrude upon and antagonize someone involuntarily or by surprise. They are not presented to the targets. \nFIGURE\u00a02.1   Antisemitic Meme\nMaking a Case for a Social Processes Approach to Online Hate  19\nIn these ways, extreme hate messengers migrate to channels that are more \ninsulated not only from the mainstream but also from the very targets of their messages\u2019 denigration.\nMore obvious, deliberate insulation appears in traditional White Suprem-\nacists\u2019 online territories. Stormfront.org is \u201cthe oldest and most visited \nweb-forum\u201d for racist hate messaging, where Jewish, Black, and LGBTQ communities are the primary \u201c\u2019racial enemies\u2019\u201d (Scrivens et\u00a0 al., 2020, p.\u00a0217).\n2 It displays a graphic on its homepage ( Figure\u00a02.2) saying, \u201cWHITE \nPRIDE WORLD WIDE\u201d; \u201cWe are White Nationalists,\u201d it says; \u201cWe are the voice of the embattled White minority!\u201d (stormfront.org/forum).\nThere is no ambiguity that White Supremacists are its intended contributors \nand consumers ( Figure\u00a0 2.3). Its discussion boards offer hundreds of topical \nFIGURE\u00a02.2   Stormfront.org Homepage\nFIGURE\u00a0 2.3  Welcome to Stormfront Discussion Board\n20 Joseph B. Walther\nchannels, including regional discussion boards in several national languages, \nand it claims to host over 13 million posts. The comments on the site focus primarily on Jewish; Black; and lesbian, gay, bisexual, transgender, and queer (LGBTQ) communities ( Scrivens et\u00a0al., 2020 ; T\u00f6rnberg\u00a0& T\u00f6rnberg, this vol -\nume); and range widely, from debates about history (e.g., about the actuality of the holocaust or \u201cholohoax\u201d), the character of Martin Luther King, Jr. (one of the mildest characterizations of whom is a \u201chalf-baked communist preacher\u201d), and even a women\u2019s forum (extolling motherhood, since the future depends on propagating more racially pure children). Although readership is open to anyone, it requires membership to post messages, and it admonishes prospective message posters to conform to its ideology, stating, \u201cIf you\u2019re here to argue with us, confine your posts to the \u2018Opposing Views\u2019 forum if you don\u2019t want them deleted\u201d (https://www.stormfront.org/forum/t4359/). The rare anti-racist message posting may be quickly deconstructed by other partici -\npants, point by point, followed by, in one case, a suggestion that the dissenting author should kill himself (https://www.stormfront.org/forum/t134087/).\nProvision of Community\nResearch on the appeal of Stormfront to its users suggests, again, that the social processes taking place among them are central. Positive social dynam -\nics among the White Supremacist users themselves drives the platform\u2019s mas -\nsive use, rather than any facility to antagonize minority targets within it. Research finds that some of its right-wing extremist users are stigmatized in their offline lives, when they espouse the views offline that Stormfront, in contrast, welcomes. As a result, Stormfront members \u201ccan express themselves freely, and generally feel accepted by the others\u201d ( De Koster\u00a0& Houtman, \n2008, p.\u00a01166), experience camaraderie, and enjoy a sense of community. In some cases, they come to know each other as individuals and develop interpersonal relationships online, in ways more refined than simple in-group identification; some members remember one another\u2019s birthdays and offer support and comfort to one another in response to \u201cunpleasant events in their offline lives\u201d (p.\u00a0 1167). We will return to the issue of relationships and community among hate producers later in this chapter. The platform is more dedicated to reciprocal discussion and denigration of others than to the delivery of messages or physical inflictions upon them. According to observers of a Dutch-speaking subgroup of Stormfront users, an occasional proponent who tries to recruit assistance among Stormfront colleagues to instigate offline harassment toward some target is rarely if ever successful in mobilizing accomplices. Other studies indicate that there may be two differ -\nent types of Stormfront extremists, all of whom seem to share similar ideo-logical beliefs: Those who are unlikely ever to engage in offline violence and a tiny minority who actually engage in physical violence offline. Interestingly, \nMaking a Case for a Social Processes Approach to Online Hate  21\nthose who evolve into physical violence tend to post relatively less frequently \nin publicly accessible venues like Stormfront (Scrivens et\u00a0al., 2023).\nThe point to be made here is that the online enclaves in which hate pro -\nducers and consumers do so much of their messaging are relatively isolated \nfrom those about whom they post. This arrangement leads to the conclusion that their messaging is socially motivated for the benefit and enjoyment of persons like themselves rather than being intended for delivery to victims. Although there remains abundant hate and harassment in the \u201ctarget-rich\u201d environments of X/Twitter and other mainstream social media sites, the exodus of hate posters into more fringe social media venues that welcome hate messages strongly suggests that target practice is not the only point of online hate messaging. It may not even be the main point, considering the sense of commonality, camaraderie, and connection that virtual communi-ties of hate mongers provide for each other. So, while a 2005 analysis of White Supremacist websites concluded that \u201cit is impossible to know who the White supremacist writers perceived their audience to be\u201d ( Douglas et\u00a0al., \n2005, p.\u00a0 70), that notion now seems implausible given the turn to social media and its ability to segment and insulate White Supremacists from both the mainstream and from their targeted populations. It seems far more likely that White Supremacists, in many online spaces, knowingly write for, and engage with, one another.\nThe Social Organization of Hate Attacks\nWhen considering that there may be different audiences for online messaging, it stands to reason that there may be two kinds of online hate messages with two different purposes. One kind, as suggested above, promotes rewarding social interactions among online hate purveyors. Another kind of messages are crafted intentionally to be delivered to and to terrorize their victims, which is the traditional assumption about all online hate. Regarding the lat -\nter, Munger (2017) describes a method for detecting an individually targeted \nhate message in Twitter. If a message includes an ampersat (@ sign) connected to a specific username, that user is likely to be notified that their handle has been mentioned. They will see that they have been identified as a subject of the message. In Munger\u2019s work, a Tweet that combined the n-word, a second-person \u201cyou,\u201d and a @username was classified as a hate message.\nWhile this type of message no doubt occurs frequently, it may not be as \nnarrowly focused as it seems. As was the case in Munger\u2019s study, a great deal of what appear to be individually directed hate messages may, in fact, be primarily intended for a greater audience of hate perpetrators.\nConsider how hashtags provide a means by which a hate poster can pub -\nlicly deride a specific, named target, in a way that reaches many onlookers. Hashtags can both attract like-minded peers and repel outsiders, too (e.g., \n22 Joseph B. Walther\n\u201c#whitepower, #blackpeoplesuck, #nomuslimrefugees\u201d; ElSherief et\u00a0 al., \n2018, p.\u00a044). Individuals also follow hashtags to get notifications (on their \ndevice\u2019s home screens, e.g., or each time they log into a platform) about the existence of new messages on the topic. In that manner, including a popular, controversial hashtag in a hate message increases the chances that targets as \nwell as accomplices will see it.\nMarwick (2021) provides compelling accounts showing how large groups \nof online haters collectively descend on individual targets in a coordinated manner, delivering \u201cnetworked harassment.\u201d Networked harassment occurs when a group of online friends, followers, or online acquaintances, held together by hashtags, gaming channels, or other social network structures, gangs up on, \u201cswarms,\u201d or \u201craids\u201d an individual victim (see also Han et\u00a0al., \n2023). The individually targeted forms of harassment executed by members of such a collective can be quite severe, such as \u201cdoxxing (publishing per -\nsonal information online), revenge porn (spreading intimate photos beyond their origins)\u00a0.\u00a0.\u00a0. social shaming, and intimidation\u201d (Marwick\u00a0& Caplan, 2018, p.\u00a0544), as well as rape threats and death threats.\nMarwick depicts networked harassment following these typical steps. It \nbegins when one agent accuses some specific target individual of some offense that deserves retribution. The accusation may be echoed by other agents who substantiate the offense for a social-network-connected, ideologically similar audience online. These audience members then \u201csend ad hominem attacks, insults, slurs, and in the worst cases, threats of death, rape, and violence to the accused (brigading, dogpiling, or \u2018calling out\u2019)\u201d ( Marwick, 2021, p.\u00a05). \nA\u00a0recent example describes how a university instructor scheduled a \u201cpro -\nvocatively titled\u00a0.\u00a0.\u00a0. anthropology course\u00a0.\u00a0.\u00a0. \u2018The Problem of Whiteness.\u2019\u201d A\u00a0student (who had thousands of Twitter followers) derided the prospective course online, along with posting the instructor\u2019s photo and email address. The instructor\u2019s \u201cinbox exploded\u00a0.\u00a0.\u00a0. with vitriolic messages from dozens of strangers. One wrote that she was \u2018deeply evil.\u2019 Another: \u2018Blow your head clean off\u2019\u201d (Patel, 2023). The instructor cancelled the course.\nAlthough these descriptions and anecdotes are compelling, the social \naspects of online hate and networked harassment at broad scale are also empirically reflected in studies that employ tools for formal social network analysis. Large-scale analyses of who follows whom, who retweets whom, and how specific linguistic combinations cascade through a social media platform show the abstract interconnection among users, sometimes tens of thousands at a time ( Jiang et\u00a0al., 2022 ). The degree to which many poten -\ntially connected participants observe one another\u2019s postings is most prob -\nably low and is affected by the selection algorithms within social media platforms (see Bartley et\u00a0al., 2021 ). Nevertheless, sophisticated \u201cinfodemio -\nlogical analysis\u201d has detected online hate communities within Twitter that exhibit greater organization over time, their degree of interconnectedness \nMaking a Case for a Social Processes Approach to Online Hate  23\nbeing influenced by events in the wider social and political world ( Uyheng\u00a0& \nCarley, 2021). Other network-analytic research that examined shared vocab -\nulary, retweets, and interactions among users discovered \u201can online commu -\nnity of over 22,000 Twitter users whose online behavior directly advocates \nsupport for ISIS or contributes to the group\u2019s propaganda dissemination through retweets\u201d (Benigni et\u00a0al., 2017, p.\u00a01). Facebook\u2019s hate detection and prediction systems analyze not only individuals\u2019 history of hate messaging to determine whether an account suspension might be appropriate but also the messaging of individuals\u2019 close social network ties to inform its predictions about the likelihood that an individual will violate behavioral standards by posting hate messages again (Halevy et\u00a0al., 2022).\nWhether networked harassment involves relatively small numbers of net -\nwork participants or exceptionally large ideological groups, the very existence of networked harassment is further evidence that online hate is generally not the action of unconnected and uncoordinated \u201clone wolves\u201d who may share the same ideology but who act autonomously motivated only by the desire for Schadenfreude. Even supposed lone-wolf terrorists, research shows, are \nconnected to hate communities online ( Weimann, 2012). The phenomenon \nof networked harassment demonstrates that online hate is a product of social processes, including normative social influences among and between hate posters, motivating them to act in systematic collective efforts, to preserve (their view of) the moral order in a loosely coordinated manner.\nSo far, this view of networked harassment describes the dynamics of par -\nticipation as one-way attacks by group members on single targets who are the only observers of the attacks. Marwick\u2019s analysis of networked harass -\nment does not consider that the mobilized network members do more than attack, concurrently but separately, when she says, \u201cNetworked harassment involves many individuals sending messages, emails, or phone calls within a relatively short amount of time\u201d ( Marwick, 2021, p.\u00a08; Marwick\u00a0& Caplan, \n2018). Each of these media facilitates dyadic one-to-one messaging. The social factors involved in networked harassment do more than facilitate a temporally bound barrage of one-way hate messages, however. Social media and network characteristics facilitate the observation of each attack by oth -\ners, displaying all antagonists\u2019 piled-on content. Indeed, elsewhere in Mar -\nwick\u2019s accounts, she suggests that audience members attack targets using channels that are public and in sight of one another. Said one of Marwick\u2019s \ninterview informants, \u201c  \u2018One time I\u00a0found a Reddit thread that was about \nbashing me\u2019\u201d (p.\u00a0 8). Elsewhere, a U.S. Congressional representative who \nhad criticized the prevalence of antisemitism on Twitter later reported, \u201c  \u2018the \nreply section of my post was flooded with hateful, antisemitic comments and images\u2019\u201d (Treene\u00a0& O'Sullivan, 2023). The promulgation of networked har -\nassment using social network sites clearly suggests that the participants are also part of the audience: They see how one another insults the target. It \n24 Joseph B. Walther\ncan only be by mutual observation that, as the quotation at the beginning of \nthis chapter suggested, they \u201cescalate the attacks by earning the praise and approval of their peers\u201d (Sarkeesian, 2012).\nCross-Platform Hate Demonstrates Social Coordination\nIn addition to Marwick\u2019s description of networked harassment, other research demonstrates that online hate often appears as collective action through social coordination. Several studies document the operation of hate activities that operated across social media platforms. When an instigator plans and recruits collaborators within one platform, and they carry out an attack against targets on another platform, it is again clear that online hate is not a spontaneous act by isolated individuals but a result of coordinated social processes (see the chapters by Phadke\u00a0& Mitra, this volume; and Rae et\u00a0al., this volume). One of the most notorious multiplatform hate incidents, in 2014, became known as #Gamergate, a thumbnail summary of which (Eckert\u00a0& Metzger-Riftkin, 2020 , p.\u00a0273) indicates that it was a coordinated \nonline harassment campaign\u00a0.\u00a0.\u00a0.\n.\u00a0.\u00a0. specifically targeting women through a release of their personal infor -\nmation online, leading to massive and sustained attacks online and offline. #Gamergate was a reaction by misogynist video game enthusiasts against perceived favoritism towards women in gaming journalism. For months, harassers sent feminist activists and game developers Zoe Quinn, Anita Sarkeesian, and Brianna Wu abusive messages, defaced their online spaces, and hacked their accounts.\nThe campaign involved interaction across a variety of social media platforms, including 4chan, Twitter, Reddit, and Internet Relay Chat ( Lewis et\u00a0al., 2021; \nTsapatsoulis\u00a0& Anastasopoulou, 2019).\nOther cases illuminate additional ways by which hate posters socially \ncoordinate across specific platforms in well-worn patterns, using tacit, highly recognized signals. Mariconti et\u00a0al. (2019) describe how \u201craids\u201d by multiple attackers are instigated on 4chan against specific YouTube videos:\nA prototypical raid begins with a user finding a YouTube video and post -\ning a link to it on a third party community, e.g., 4chan\u2019s /pol/.\n3 In some \ncases, the original poster, or another user, might also write comments like \u201cyou know what to do.\u201d Shortly after, the YouTube video starts receiving a large number of negative and hateful comments.\n(p.\u00a02)\nWhether or not it seems so to the recipient of the hate messages, it is \u201cobvi -\nous to an outside observer\u00a0.\u00a0.\u00a0. that these comments are part of an organized \nMaking a Case for a Social Processes Approach to Online Hate  25\nattack.\u201d Such patterns have been well-documented and illuminated using \ntemporal cross-platform analyses of postings ( Hine et\u00a0 al., 2017). Even \nmore social organization and social gratification may yet follow a raid: Raiders have been found to return to the 4chan space where the raid had originally been organized in order to brag to one another about their hate postings on YouTube ( Mariconti et\u00a0al., 2019; Stringhini\u00a0& Blackburn, this \nvolume). These findings indicate that many forms of networked harass -\nment are more circular than they are linear: On top of posting hate mes-sages where they are visible to the victim, the public, and one another, hate posters circle back to the original point where social organization instigated, presumably for \u201cexchanging online \u2018high fives\u2019\u201d ( Udupa, 2019, \np.\u00a03151).\nIn sum, a number of accounts and analyses point to the public nature of \notherwise \u201cdirected\u201d hate messages in which groups of hate posters act in a coordinated manner to instigate and execute a raid or swarm that targets a specific individual (see also Tong\u2019s typology, this volume). Even though they are created using affordances such as @usernames to increase the chances that their individual target sees them, in most cases they do not transmit their messages only privately to their target. They post them where others also see them, where others can observe, comment upon, \u201clike\u201d one anoth -\ner\u2019s hate postings, and even, at times, celebrate them together. It is therefore important to reconsider ElSherief et\u00a0al.'s (2018) classification of online hate messages as either generalized or directed. When hate messages that target \na specific target person are posted for an additional, wider audience, the reward from doing so comes not, or not only, from the infliction of trauma to a specific victim. Rather, the reward may also be the attention they get from like-minded peers, the social approval that they cull, and the enhancement to \nthe recognition and status they hold as they torture their target. \u201cBullies are aggregated together and (increase) their popularity by following each other,\u201d asserted Tsapatsoulis and Anastasopoulou (2019, p.\u00a0 3). Their \u201cdirected\u201d \nhate messages are, in that sense, performative.\nSocial Gratifications of Online Hate\nThis chapter has alluded to various gratifications that the creators and dis -\nseminators of online hate messages may enjoy, derived from social inter -\nactions among haters themselves. These social gratifications may be so influential that the anticipation of their acquisition is among the primary motivators for participation in online hate. Such social gratifications, more -\nover, may serve as a powerful reinforcer, impelling hate posters to continue and perhaps escalate their production of online hate messaging and the social benefits it garners. Among these potential gratifications, the literature suggests, are having fun, acquiring social approval, and sustaining social support.\n26 Joseph B. Walther\nFun\nIt is difficult to reconcile the revulsion most people experience when encoun -\ntering online hate messages, with the notion that they are fun or funny in any \nway. Udupa (2019), however, convincingly argues that, from the perspective \nof participants who engage in public online attacks against others, having fun with others is a primary motivation and reward. In the context of Indian Hindu nationalism, Udupa contends, adherents find that its \u201cexclusivist ide -\nology is rendered acceptable and enjoyable\u201d and it is made visible in online posts conveying \u201cthe visceral aspects of fun and enjoyment that constitute right-wing mobilization\u201d (Udupa, 2019, p.\u00a03144).\nThe efforts to have fun and be funny online, in the manner Udupa describes, \naccount very well for features of online hate messages we recognize in other contexts as well. The original site of Udupa\u2019s inquiry involves a conflation of majority politics with religious discrimination in India, and this under -\nlying dynamic may or may not be seen as strongly in other settings (such as far-right American Christian conservatives online). Nevertheless, in many online settings, antagonists lampoon, ridicule, or caricature their individual or identity group targets. They often attempt to be witty or over-the-top or make hyperbolic comparisons. Other examples in Udupa\u2019s account include publicly deriding an opponent by \u201ccreating memes, tweets, and Facebook texts to offer repetitive summaries of [one\u2019s own] ideology\u201d and confronting \u201copposing views with an arsenal of stinging ridicule, accusations, and abuse, riding on a wave of online vitriol\u201d ( Udupa, 2019, p.\u00a03150; see also Udupa\u00a0& \nGerold, this volume).\nThese fun activities are reinforced socially in several ways. Being funny \nis reflected in others\u2019 online comments and reactions to one\u2019s postings. Suc -\ncessfully impressing others is reflected in one\u2019s posts being shared, \u201cliked,\u201d and going viral. These practices of fun, such as \u201cfact-checking, argumenta -\ntive confrontations, assembly, and aggression\u201d ( Udupa, 2019, p.\u00a03144), it \nis worth noting, seem to describe very well many discussions within Storm-front, as well as in mainstream social media platforms when it is allowed to flourish there.\nThe meta-practice of fun in the propagation of online hate could hardly be \nclearer than in the cover screen introducing a meme collection on Gab, the \u201cnew n**ger meme repository\u201d ( Figure\u00a0 2.4). It describes the contents of the \ncollection as being \u201cFUNNY AS HELL,\u201d and it encourages people to ask their friends to join the group.\nThere are analogous frames and states, in addition to the notion of \u201cfun,\u201d \nwhich propel the exchange of ideas online that are repudiated by the public majority. Recent research suggests that participating in the propagation of online conspiracy theories garners emotional arousal and excitement. Moreo -\nver, \u201cconspiracy theory very often goes hand in hand with racism\u00a0\u2013 anti-Black racism, anti-immigrant racism, antisemitism and Islamophobia\u201d ( Schaefer, \nMaking a Case for a Social Processes Approach to Online Hate  27\n2022; see also Jolley\u00a0& Douglas, 2019). Conspiracy theorists revel in sharing \nwith each other clues and so-called evidence that, they claim, reveal hidden meanings in otherwise well-known public statements and events. In doing so, they feel as though they are smarter than the vast majority of other peo -\nple. They \u201cencourage their followers to see themselves as the only ones with their eyes open,\u201d according to Schaefer (2022), who observes that conspiracy \ntheorists endeavor not to find the most plausible interpretation of evidence but \u201cthe one that\u2019s most fun.\u201d\nSocial Approval Seeking and Getting\nRecent scholarship has advanced a new theory of online hate that highlights very specific social processes as providing certain motivation and reinforce -\nment for participating in hate messaging. A\u00a0social approval theory of online hate (Walther, 2022) focuses on the way haters receive confirmation and social rewards for their actions, particularly through the streamlined process of communicating social approval that social media platforms readily afford.\nSocial media allow users to transmit social approval signals in a variety \nof ways. One can always comment on another\u2019s posting, stating agreement or appreciation in verbal prose, which increases message posters\u2019 satisfac-tion with online interactions (Sannon et\u00a0 al., 2017). Social media also fre-quently offer \u201cone-click\u201d generation of iconic social approval signals, such as the thumbs-up \u201clike\u201d in Facebook, the heart-shaped \u201cfavorite\u201d in Twitter, the Upvote in Reddit, and similar signals (Hayes et\u00a0al., 2016). People are \nFIGURE\u00a02.4   Quoted Text from Welcome Screen for Gab\u2019s New N**ger Meme Reposi -\ntory, from https://gab.com/sopan123/posts/105431828772012713\n28 Joseph B. Walther\nmotivated to seek these gratifications online and react in positive ways, psy -\nchologically and physiologically, when their messages receive them ( Reich \net\u00a0al., 2022; Wolf et\u00a0al., 2015 ). They are \u201csocial rewards\u201d connoting \u201csocial \nacceptance\u201d (Rosenthal-von der P\u00fctten et\u00a0al., 2019 , p.\u00a076), improving one\u2019s \nsocial standing and emotional gratification (Hayes et\u00a0al., 2016).\nSeveral recent studies suggest support for the contention that receiving \nthese one-click social approval signals affects people\u2019s perceptions and behav -\nior with regard to destructive messages online. One of these studies immersed \nparticipants in an experimental mock-up online discussion and asked them to select among pre-written Tweets to post in those discussions. The Tweets reflected either moral outrage messages or neutral messages, and participants were requested to choose the Tweet that would maximize the number of Twitter-like hearts that their selections would receive. The more hearts the participants received when they selected moral outrage messages, the more outrage messages they selected subsequently ( Brady et\u00a0al., 2021). A\u00a0nonex-\nperimental field study replicated these findings by examining naturally occur -\nring patterns on Twitter. Researchers identified Tweets reflecting \u201cmoral outrage\u201d (comprising hate messages or other messages that also reflected \u201cemotions such as anger, disgust, and contempt\u00a0.\u00a0.\u00a0. blaming people/events/things, holding them responsible, or wanting to punish them\u201d; Brady et\u00a0al., 2021, p.\u00a02) and the number of hearts those messages spontaneously received from other Twitter users. Results indicated that the number of hearts the out -\nrage expressions received on one day was positively associated with the num -\nber of outrage messages their authors posted the next. A\u00a0somewhat similar study found that individuals who retweeted a negative fake news story about a politician from the opposite political party than their own came to dis -\nlike that politician more as a function of the number of hearts their retweet received (Walther et\u00a0al., 2022).\nAnother study examined the effect of receiving upvotes or downvotes to \none\u2019s toxic comments on Reddit. In short, upvotes encouraged more frequent toxic messages (Shmargad et\u00a0al., 2020). More detail and additional studies by the authors of that research appear in this volume\u2019s chapter by Shmargad et\u00a0 al. These studies provide important, empirical evidence suggesting that social factors impel the expression of online hate through the seeking and getting of social approval signals through symbols that are somewhat unique to social media platforms.\nSocial Support\nAnother form of social approval and affiliation that may arise in the pro-duction and propagation of online hate appears as social support among hate producers. In the research literature, social support is communication and deed-doing by which people provide help, consolation, information, and \nMaking a Case for a Social Processes Approach to Online Hate  29\nempathy toward other people facing trauma, illness, or distress. Social sup -\nport, effectively delivered, is associated with a number of psychosocial aspects \nof well-being and improvements in self-esteem and coping. This \u201cprosocial\u201d activity seems far-removed from the negativity of online hate, unless we con -\nsider the perceptions of threat and danger and the offline stigmatization expe-rienced by people who engage in conventionally antisocial behavior such as hate messaging.\nThe application of social support theory to those engaged in conven-\ntionally antisocial behavior is only recently coming into view. Previously, DeKeseredy and his associates (see DeKeseredy\u00a0 & Schwartz, 2013 ) have \ndeveloped a version of social support theory that explains the perpetration of domestic violence by men toward female relationship partners in offline set -\ntings. This line of work has been developed through expensive research, the complexities of which are beyond the bounds of this particular chapter. The crux of the theorizing may well apply beyond domestic violence, however. It holds that participants in these actions communicate with one another about the process. They teach each other how to do it. Most importantly, they help each other rationalize the actions and exonerate one another for engaging in them. They provide empathy and understanding to one another for behaviors that are often reacted to with disgust and abhorrence in their normal social circles.\nThese notions of social support among people who may be unlikely to \nfind support elsewhere in their lives, and the emotional benefits of receiving it, map onto some of what we see in online hate communities as well. Recall the description of Stormfront participants described earlier in this chapter, who \u201ccan express themselves freely, and generally feel accepted by the oth -\ners\u201d (De Koster\u00a0& Houtman, 2008 , p.\u00a01166), and, as we said, experience \ncamaraderie, and enjoy a sense of community. DeKeseredy and Schwartz \n(2016) applied these principles to one form of online hate, the exchange of image-based involuntary sexual abuse, commonly referred to as \u201crevenge porn.\u201d Although this phenomenon is frequently thought of as a dyadic tar -\ngeted phenomenon, in which one individual terrorizes a single victim, it is distinctly social in several respects: First, such photos are only effective in humiliating their target when they are widely shared and linked to a dis -\ntinctly social process. Second, as DeKeseredy and Schwartz discovered, there are online communities the members of which archive, curate, and mutually aid one another in their efforts to spread these specimens widely, and comple -\nment one another for having contributed. Recent research shows similar pat -\nterns of social support among incels\u00a0\u2013 involuntarily celibate men who resent and espouse violent derision toward women\u00a0\u2013 across multiple social media such as YouTube and discussion boards (DeKeseredy, this volume). These networks of support, empathy, and community provide significant attraction and gratification for engaging socially in online hate with other participants.\n30 Joseph B. Walther\nImplications for Intervention Research\nUnderstanding the social processes conducive to the production of online \nhate may provide potentially valuable insights for how to try to reduce its prevalence. As the opening of this chapter indicated, the three most fre -\nquently studied areas in online hate research include documenting its per -\nvasiveness, describing the contents, and examining its effects on recipients. These approaches follow from a presumption that the impetus to produce and post online hate is a given, a natural, and intractable outcome of per -\nsonalities and previously developed intergroup enmity. As such, research and development related to \u201ccontent moderation\u201d seek to discern what the most effective ways are of making it go away through persuasion (Hangartner et\u00a0al., 2021; Munger, 2017), deletion, and/or various punishments such as \naccount suspension (see for review Schoenebeck et\u00a0al., 2021; for a review of different countries\u2019 content restrictions and enforcements, see Gillespie, \n2018), rather than by intervening in or disrupting social processes.\nApproaching online hate as a social process suggests alternative approaches, \nand future research should investigate possible social-process-based interven -\ntions. For instance, if hate producers are motivated by attention and social approval, interventions such as \u201cshadow banning\u201d (see Jaidka et\u00a0al., 2023 ) \nmay thwart them, making a \u201cuser invisible to every other user, while to the offender it appeared as everything was functioning normally\u00a0.\u00a0.\u00a0. [but] get -\nting no reactions from anybody else\u201d ( Gillespie, 2022, p.\u00a0487) and thereby \ndepriving hate message posters of the social attention that fuels their activ -\nity.\n4 Such measures might be even more effective if they were to be coupled \nwith recommendations from social network analyses: Blocking a single, criti-cal individual\u00a0\u2013 a node in a hate network\u00a0\u2013 should reduce the propagation of hate messaging (Alorainy et\u00a0al., 2022).\nOther technical approaches might reduce cross-platform hate raids, fol-\nlowing suggestions by Rae et\u00a0al. (this volume): Social media platforms can \u201crefuse entry\u201d to their site by users from coming to their platform from a site that is known to foment raids. \u201cReferrer log data\u201d additionally show if such users arrive to one\u2019s site after typing in its address, or whether (as in the case of a cross-platform raid) users come via a link that was posted on their other site (see Burton\u00a0& Walther, 2001).\nIn contrast, at least in countries and on platforms where unfettered free-\ndom of expression is valorized, reducing the propagation of online hate mes -\nsaging may be beyond platforms\u2019 ability to affect. Remedies to online hate, especially hate toward women, may be needed in offline societal, legal, and educational mores (DeKeseredy, this volume). Attitudes leading to the pro -\nduction of online hate messaging may be embedded in complex, multilayered structures involving majoritarianism, religious stereotypes, cultural values, and pornification of gender relations, as argued by Udupa and Gerold (this volume). It may be that online hate is a reflection rather than a cause of \nMaking a Case for a Social Processes Approach to Online Hate  31\nincreasingly negative political partisanship ( Abramowitz\u00a0& Webster, 2016 ). \nThis is not a suggestion that the investigation of the causes and remedies of \nonline hate is futile. To give up the search is to give up on further understand -\ning of an undesirable side of human nature. To give up is to become compla -\ncent over the potential magnification of extremism, the continued acceptance of discrimination and injustice, and the potential for violence that may be an indirect result of increasingly hateful communication.\nA social processes approach to the social gratifications that play a large \nrole in individuals\u2019 motivations to post online hate can be criticized as draw-ing focus away from the real hurt and the damage that are done in the lived experiences of its victims, although the approach is not intended to devalue those individual experiences. The possibility was raised, above, that people who are the targets of socially organized online hate may be collateral dam -\nage, if indeed the production of online hate is largely about hate producers trying to impress, gain favor, develop solidarity, act like, and/or entertain others in a community of like-minded peers. It does not acknowledge the amount of pain that people feel and the endangerment to their life some-times, whether such outcomes were the non-primary motivations for online hate or fodder for collective Schadenfreude. The seriousness of the outcomes of online hate on its victims, individually, collectively, and societally, under -\nlies the very impetus for theorizing and studying the phenomenon, no matter what its motivational genesis is.\nAcknowledgments\nThis chapter was completed while the author was supported as Visiting Scholar to the Institute for Rebooting Social Media in the Berkman Klein Center for Internet\u00a0& Society at Harvard University. Sincere thanks to Ron Rice for generously detailed and invaluable feedback during several itera -\ntions of this chapter, and to Yotam Shmargad, Anton T\u00f6rnberg, and Jordi Weinstock for their constructive suggestions.\nNotes\n 1 Although the social identification literature occasionally references processes such \nas the interactive model of opinion formation  to describe how social interaction \ncan lead to self-categorization (Postmes et\u00a0al., 2005), the role of social interaction \nis neither necessary or sufficient for the activation of self-categorization within the general theory: As Thomas et\u00a0al. (2010, p.\u00a08) explain,\n[S]ocial identities shape individual behaviour not because of conformity to external pressures; they shape behaviour because they become internalized aspects of \u2018self\u2019, and because their normative dimensions shape our percep -\ntions of what is right and proper and thus our expectations of others\u2019 views and behaviour. Consistent with these points, we argue that similar processes underpin the formation of identities that are commonly seen as either prosocial \n32 Joseph B. Walther\n(those that promote inter-group cooperation, social harmony and/or social \nequality) or hostile (those that promote inter-group aggression, prejudice or hostility.\n  Although they later argue \u201cthat interaction plays a key role, as the medium \nthrough which social ideologies may be aired and socially validated\u201d (p.\u00a08), this assertion involves no different processes than those described elsewhere in an interpersonal communication process in which social identification plays no part (see Duck et\u00a0al., 1991).\n 2 For those unfamiliar with hate narratives against these groups, Scrivens et\u00a0 al. \n(2020, pp.\u00a0218\u2013219) note:\nJews, for example, have been subject to extensive criticism by the radical right, particularly by racist leaders who label Jews as \u201cthe source of all evil,\u201d the spawn of the Devil himself, conspiring to extinguish the White race and breed them out of existence\u00a0\u2013 through \u201cJew-controlled\u201d government, financial insti -\ntutions, and media\u00a0.\u00a0.\u00a0. Black communities, too, have been the primary target of much of the hateful sentiment expressed by the radical right. Blacks have been constructed as \u201cmud races\u201d and the descendants of animals created before Adam and Eve; \u201csavages\u201d who viciously rape White women and take jobs away from White communities; and the foot soldiers of conspiring Jews.\u00a0.\u00a0.\u00a0. Adherents of this male-dominated movement have also categorized anyone who is not heterosexual as \u201ccontaminated\u201d and \u201cimpure,\u201d by maintaining not only that the gay rights movement is the killer of the traditional White family and the cultural destruction of the White race.\n  In the views of some neo-Nazi and White Supremacist groups, Jews are \u201cthe cen -\ntral enemy, with African Americans, Latinos, and Asians as merely pawns of the Jews\u201d (p.\u00a0228).\n 3 4chan hosts anonymous messaging in a number of topical channels or discussion \nboards. The /pol/, or \u201cpolitically incorrect\u201d board, \u201chas often been linked to the alt-right movement and its rhetoric of hate and racism\u201d according to Hine et\u00a0al. \n(2017, p.\u00a01). Their analyses provide a sense of the nature of /pol/ by noting, among other findings, that posts containing the n-word appear about 120 times an hour.\n 4 In addition to shadow banning, there are similar but less extreme measures to \nreduce exposure of hateful messages using algorithmic \u201cinterventions surrepti-tiously made by the platform, leaving the user thinking they are participating nor -\nmally, while other users see less of them,\u201d thereby throttling the attention they might get. These include posts being \u201crecommended less; or only to certain kinds of users, such as to followers only; or for a shorter time\u201d (Gillespie, 2018, p.\u00a0487).\nReferences\nAbramowitz, A. I.,\u00a0& Webster, S. (2016, March).  The rise of negative partisanship \nand the nationalization of U.S. elections in the 21st century. Electoral Studies, 41, \n12\u201322. https://doi.org/10.1016/j.electstud.2015.11.001\nADL. (2021, March 22). Online hate and harassment: The American experience. https://www.\nadl.org/resources/report/online-hate-and-harassment-american-experience-2021\nADL. (n.d.). Hate on display: Hate symbols database . https://www.adl.org/resources/\nhate-symbols/search\nAlbright, J. (2018, November 16).  The shadow organizing of Facebook groups. Medium. \nhttps://medium.com/s/the-micro-propaganda-machine/the-2018-facebook-midterms-  \npart-ii-shadow-organization-c97de1c54c65\nAlorainy, W., Burnap, P., Liu, H., Williams, M.,\u00a0& Giommoni, L. (2022).  Disrupt-\ning networks of hate: Characterising hateful networks and removing critical \nMaking a Case for a Social Processes Approach to Online Hate  33\nnodes. Social Network Analysis and Mining , 12(1), 27. https://doi.org/10.1007/\ns13278-021-00818-z\nBartley, N., Abeliuk, A., Ferrara, E.,\u00a0& Lerman, K. (2021). Auditing algorithmic bias \non Twitter. In 13th ACM web science conference 2021  (pp.\u00a065\u201373). https://doi.\norg/10.1145/3447535.3462491\nBenigni, M. C., Joseph, K.,\u00a0& Carley, K. M. (2017).  Online extremism and the com -\nmunities that sustain it: Detecting the ISIS supporting community on Twitter. PLoS \nOne, 12(12), e0181405. https://doi.org/10.1371/journal.pone.0181405\nBrady, W. J., McLoughlin, K., Doan, T. N.,\u00a0 & Crockett, M. (2021).  How social \nlearning amplifies moral outrage expression in online social networks. Science \nAdvances, 7(33), eabe5641. https//doi.org/10.1126/sciadv.abe5641\nBurton, M. C.,\u00a0& Walther, J. B. (2001).  The value of web log data in use-based design \nand testing. Journal of Computer-Mediated Communication , 6(3), JCMC635. \nhttps://doi.org/10.1111/j.1083-6101.2001.tb00121.x\nCheng, J., Bernstein, M., Danescu-Niculescu-Mizil, C.,\u00a0 & Leskovec, J. (2017). \nAnyone can become a troll: Causes of trolling behavior in online discussions. In \nProceedings of the 2017 ACM conference on computer supported cooperative work and social computing  (pp.\u00a0 1217\u20131230). https://doi.org/10.1145/2998181. \n2998213\nCramer, R. J., Fording, R. C., Gerstenfeld, P., Kehn, A., Marsden, J., Deitle, C., King, \nA., Smart, S.,\u00a0& Nobles, M. R. (2020, November 9). Hate-motivated behavior: Impacts, risk factors, and interventions. Health Affairs Blog. https://www.healthaf-\nfairs.org/do/10.1377/hpb20200929.601434/full/\nDaniels, J. (2017, October 19).  Twitter and white supremacy, A\u00a0love story. Dame Mag-\nazine. https://www.damemagazine.com/2017/10/19/twitter-and-white-supremacy- \nlove-story/\nDe Koster, W.,\u00a0& Houtman, D. (2008).  \u2018Stormfront is like a second home to me\u2019: \nOn virtual community formation by right-wing extremists. Information, Com-munication\u00a0 & Society, 11(8), 1155\u20131176. https://doi.org/10.1080/136911808 \n02266665\nDeKeseredy, W. S. (Chapter\u00a04 this volume). Misogyny and woman abuse in the ince-\nlosphere: The role of incel male peer support.\nDeKeseredy, W. S.,\u00a0& Schwartz, M. D. (2013).  Male peer support and violence against \nwomen: The history and verification of a theory. Northeastern University Press.\nDeKeseredy, W. S.,\u00a0 & Schwartz, M. D. (2016).  Thinking sociologically about \nimage-based sexual abuse: The contribution of male peer support theory. Sexu-\nalization, Media,\u00a0 & Society, 2(4), Article 4. https://doi.org/10.1177/23746238 \n16684692\nDouglas, K. M., McGarty, C., Bliuc, A.-M.,\u00a0 & Lala, G. (2005).  Understanding \ncyberhate: Social competition and social creativity in online white supremacist groups. Social Science Computer Review , 23(1), Article 1. https://doi.org/10.1177/ \n0894439304271538\nDuck, S., Rutt, D. J., Hurst, M. H.,\u00a0 & Strejc, H. (1991). Some evident truths \nabout conversations in everyday relationships: All communications are not cre -\nated equal. Human Communication Research, 18(2), 228\u2013267. https://doi.org/ \n10.1111/j.1468-2958.1991.tb00545.x\nEckert, S.,\u00a0& Metzger-Riftkin, J. (2020).  Doxxing, privacy and gendered harassment. \nThe shock and normalization of veillance cultures. Medien\u00a0& Kommunikation-\nswissenschaft, 68\n(3), Article 3. https://doi.org/10.5771/1615-634X-2020-3-273\nElSherief, M., Kulkarni, V., Nguyen, D., Wang, W. Y.,\u00a0& Belding, E. (2018).  Hate \nlingo: A\u00a0target-based linguistic analysis of hate speech in social media. In Pro-\nceedings of the Twelfth International AAAI Conference on Web and Social Media (p.\u00a010). https://arxiv.org/pdf/1804.04257\nFurie, M. (2016, October 13).  Pepe the Frog\u2019s creator: He was never about hate. \nTIME. https://time.com/4530128/pepe-the-frog-creator-hate-symbol/\n34 Joseph B. Walther\nGab.com\u00a0\u2013 Gab Social. (n.d.). Retrieved April 6, 2023, from https://gab.com/\nGillespie, T. (2018). Regulation of and by platforms. In The SAGE hand-\nbook of social media (pp.\u00a0 254\u2013278). SAGE Publications Ltd. https://doi.org/10.4135/9781473984066\nGillespie, T. (2022). Reduction/borderline content/shadowbanning. Yale Journal of \nLaw and Technology, 24(1), 476\u2013492. https://heinonline.org/HOL/P?h=hein.\njournals/yjolt24&i=476\nHalevy, A., Canton-Ferrer, C., Ma, H., Ozertem, U., Pantel, P., Saeidi, M., Silvestri, \nF.,\u00a0& Stoyanov, V. (2022).  Preserving integrity in online social networks. Commu-\nnications of the ACM, 65(2), 92\u201398. https://doi.org/10.1145/3462671\nHan, C., Seering, J., Kumar, D., Hancock, J. T.,\u00a0& Durumeric, Z. (2023). Hate raids \non Twitch: Echoes of the past, new modalities, and implications for platform gov -\nernance (arXiv:2301.03946). arXiv. https://doi.org/10.48550/arXiv.2301.03946\nHangartner, D., Gennaro, G., Alasiri, S., Bahrich, N., Bornhoft, A., Boucher, \nJ., Demirci, B. B., Derksen, L., Hall, A., Jochum, M., Munoz, M. M., Rich -\nter, M., Vogel, F., Wittwer, S., W\u00fcthrich, F., Gilardi, F.,\u00a0& Donnay, K. (2021).  \nEmpathy-based counterspeech can reduce racist hate speech in a social media field experiment. Proceedings of the National Academy of Sciences , 118(50), \ne2116310118. https://doi.org/10.1073/pnas.2116310118\nHaslam, N. (2006). Dehumanization: An integrative review. Personality and Social Psy-\nchology Review, 10(3), 252\u2013264. https://doi.org/10.1207/s15327957pspr1003_4\nHayes, R. A., Carr, C. T.,\u00a0& Wohn, D. Y. (2016).\n One click, many meanings: Inter  pret ing \nparalinguistic digital affordances in social media. Journal of Broad  casting & \nElectronic Media, 60(1), Article 1. https://doi.org/10.1080/08838151.2015.  \n1127248\nHine, G. E., Onaolapo, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, \nR., Stringhini, G.,\u00a0& Blackburn, J. (2017).  Kek, cucks, and god emperor Trump: \nA\u00a0measurement study of 4chan\u2019s Politically Incorrect forum and its effects on the web (arXiv:1610.03452). arXiv. https://doi.org/10.48550/arXiv.1610.03452\nHogg, M. A.,\u00a0 & Reid, S. A. (2006).  Social identity, self-categorization, and the \ncommunication of group norms. Communication Theory, 16, 7\u201330. https://doi.\norg/10.1111/j.1468-2885.2006.00003.x\nH\u00fcbscher, M.,\u00a0& von Mering, S. (Eds.). (2022).  Antisemitism on social media . Rout-\nledge. https://doi.org/10.4324/9781003200499\nJaidka, K., Mukerjee, S.,\u00a0& Lelkes, Y. (2023).  Silenced on social media: The gatekeep -\ning functions of shadowbans in the American Twitterverse. Journal of Communi-\ncation, 73(2), 163\u2013178. https://doi.org/10.1093/joc/jqac050\nJiang, J., Ren, X.,\u00a0& Ferrara, E. (2022). Retweet-BERT: Political leaning detection \nusing language features and information diffusion on social networks . https://doi.\norg/10.48550/ARXIV.2207.08349\nJolley, D.,\u00a0 & Douglas, K. (2019, March 14).  Conspiracy theories fuel preju -\ndice towards minority groups. The Conversation. http://theconversation.com/\nconspiracy-theories-fuel-prejudice-towards-minority-groups-113508\nLee, S. M., Lampe, C., Prescott, J. J.,\u00a0& Schoenebeck, S. (2022). Characteristics of \npeople who engage in online harassing behavior. In Extended abstracts of the 2022 \nCHI conference on human factors in computing systems  (pp.\u00a0 1\u20137). https://doi.\norg/10.1145/3491101.3519812\nLewis, R., Marwick, A. E.,\u00a0& Partin, W. C. (2021).  \u201cWe dissect stupidity and respond \nto it\u201d: Response videos and networked harassment on YouTube. American Behav-\nioral Scientist, 65(5), 735\u2013756. https://doi.org/10.1177/0002764221989781\nMariconti, E., Suarez-Tangil, G., Blackburn, J., De Cristofaro, E., Kourtellis, N., \nLeontiadis, I., Serrano, J. L.,\u00a0& Stringhini, G. (2019). \u201cYou know what to do\u201d: Proactive detection of YouTube videos targeted by coordinated hate attacks. Pro-\nceedings of the ACM on Human-Computer Interaction , 3(CSCW), Article 207. \nhttps://doi.org/10.1145/3359309\nMaking a Case for a Social Processes Approach to Online Hate  35\nMarwick, A. E. (2021).  Morally motivated networked harassment as normative \nreinforcement. Social Media + Society, 7(2), 20563051211021378. https://doi.\norg/10.1177/20563051211021378\nMarwick, A. E.,\u00a0& Caplan, R. (2018). Drinking male tears: Language, the mano-\nsphere, and networked harassment. Feminist Media Studies, 18(4), Article 4. \nhttps://doi.org/10.1080/14680777.2018.1450568\nMitts, T. (2021). Banned: How deplatforming extremists mobilizes hate in the dark cor -\nners of the internet. https://www.dropbox.com/s/iatnxn5gtq48fxu/Mitts_banned.  \npdf?dl=0\nMunger, K. (2017).  Tweetment effects on the tweeted: Experimentally reducing \nracist harassment. Political Behavior, 39(3), Article 3. https://doi.org/10.1007/\ns11109-016-9373-5\nPatel, V. (2023, July 3). At UChicago, a debate over free speech and cyberbullying. The \nNew York Times. https://www.nytimes.com/2023/07/03/us/university-of-chicago- \nwhiteness-free-speech.html\nPhadke, S.,\u00a0& Mitra, T. (Chapter\u00a09 this volume). Inter-platform information sharing, \nroles, and information differences that exemplify social processes of online hate \ngroups.\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nPostmes, T., Haslam, S. A.,\u00a0& Swaab, R. I. (2005).  Social influence in small groups: \nAn interactive model of social identity formation. European Review of Social Psy -\nchology, 16(1), 1\u201342. https://doi.org/10.1080/10463280440000062\nQian, J., ElSherief, M., Belding, E.,\u00a0& Wang, W. Y. (2019).  Learning to decipher \nhate symbols. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: Human language tech -\nnologies (long and short papers)  (Vol. 1, 3006\u20133015). https://doi.org/10.18653/\nv1/N19-1305\nQuandt, T. (2018). Dark participation. Media and Communication, 6(4), 36\u201348. \nhttps://doi.org/10.17645/mac.v6i4.1519\nRae, S., Mathhew, B.,\u00a0& Kraemer, J. (Chapter\u00a08 this volume). \u2018Hate Parties\u2019: Net-\nworked antisemitism from the fringes to YouTube.\nReich, S., Schneider, F. M.,\u00a0& Heling, L. (2022, April 12).  Zero likes\u00a0\u2013 symbolic inter -\nactions and need satisfaction online. Computers in Human Behavior , 80, 97\u2013102. \nhttps://doi.org/10.1016/j.chb.2017.10.043\nRosenthal-von der P\u00fctten, A. M., Hastall, M. R., K\u00f6cher, S., Meske, C., Heinrich, \nT., Labrenz, F.,\u00a0& Ocklenburg, S. (2019).  \u201cLikes\u201d as social rewards: Their role in \nonline social comparison and decisions to like other people\u2019s selfies. Computers in \nHuman Behavior, 92, 76\u201386. https://doi.org/10.1016/j.chb.2018.10.017\nSannon, S., Choi, Y. H., Taft, J. G.,\u00a0& Bazarova, N. N. (2017).  What comments did \nI\u00a0get? How post and comment characteristics predict interaction satisfaction on Facebook. Proceedings of the International AAAI Conference on Web and Social \nMedia, 11(1), Article 1. https://doi.org/10.1609/icwsm.v11i1.14930\nSarkeesian, A. (2012, December 4).  Anita Sarkeesian at TEDxWomen 2012 . You-\nTube. https://www.youtube.com/watch?v=GZAxwsg9J9Q\nSchaefer, D. (2022, July 5). Buying into conspiracy theories can be exciting\u00a0 \u2013 \nthat\u2019s what makes them dangerous. The Conversation. http://theconversation.\ncom/buying-into-conspiracy-theories-can-be-exciting-thats-what-makes-them-   \ndangerous-184623\nSchoenebeck, S., Haimson, O. L.,\u00a0 & Nakamura, L. (2021).  Drawing from justice \ntheories to support targets of online harassment. New Media\u00a0& Society, 23(5), \n1278\u20131300. https://doi.org/10.1177/1461444820913122\nScrivens, R., Davies, G.,\u00a0 & Frank, R. (2020).  Measuring the evolution of radical \nright-wing posting behaviors online. Deviant Behavior, 41(2), 216\u2013232. https://\ndoi.org/10.1080/01639625.2018.1556994\n36 Joseph B. Walther\nScrivens, R., Wojciechowski, T. W., Freilich, J. D., Chermak, S. M.,\u00a0 & Frank, R. \n(2023). Comparing the online posting behaviors of violent and non-violent \nright-wing extremists. Terrorism and Political Violence , 35(1), 192\u2013209. https://\ndoi.org/10.1080/09546553.2021.1891893\nShmargad, Y., Coe, K., Kenski, K.,\u00a0 & Rains, S. A. (2020).  Social norms and the \ndynamics of online incivility. Social Science Computer Review , 40(3), Article 3. \nhttps://doi.org/10.1177/0894439320985527\nShmargad, Y., Coe, K., Kenski, K.,\u00a0& Rains, S. A. (Chapter\u00a010 this volume). Detecting \nanti-social norms in large-scale online discussions.\nStetter, B.,\u00a0 & Murphy, P. P. (2018, October 28). What\u2019s gab, the social platform \nused by the Pittsburgh shooting suspect? CNN Business. CNN. https://www.cnn.\ncom/2018/10/27/tech/gab-robert-bowers/index.html\nStringhini, G.,\u00a0& Blackburn, J. ( Chapter\u00a011 this volume). Understanding the phases \nof coordinated online aggression attacks.\nThomas, E., Smith, L., McGarty, C.,\u00a0 & Postmes, T. (2010).  Nice and nasty: The \nformation of prosocial and hostile social movements. Revue Internationale de \nPsychologie Sociale, 23(2\u20133), 17\u201355. https://www.academia.edu/30264950/\nNice_and_Nasty_The_Formation_of_Prosocial_and_Hostile_Social_Movements\nTong, S. T. ( Chapter\u00a03 this volume). Foundations, definitions, and directions in online \nhate research.\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). From echo chambers to digital \ncampfires: Constructing intimate community of hate within Stormfront.\nTreene, A.,\u00a0& O\u2019Sullivan, D. (2023, February 10).  Congressman who raised issue of anti -\nsemitism on Twitter says he was bombarded with antisemitic tweets. CNN. https://\nwww.cnn.com/2023/02/10/tech/congressman-antisemitism-twitter/index.html\nTsapatsoulis, N.,\u00a0& Anastasopoulou, V. (2019). Cyberbullies in Twitter: A\u00a0focused \nreview. In 2019 14th international workshop on semantic and social media adaptation and personalization (SMAP)  (pp.\u00a0 1\u20136). https://doi.org/10.1109/\nSMAP.2019.8864918\nTurner, J. C., Hogg, M. A., Oakes, P. J., Reicher, S. D.,\u00a0& Wetherell, M. S. (1987).  \nRediscovering the social group: A\u00a0self-categorization theory. Blackwell.\nUdupa, S. (2019). Nationalism in the digital age: Fun as a metapractice of extreme \nspeech. International Journal of Communication, 13(0), Article 0. https://ijoc.org/\nindex.php/ijoc/article/view/9105\nUdupa, S.,\u00a0& Gerold, O. L. (Chapter\u00a06 this volume). \u2018Deal\u2019 of the day: Sex, porn, and \npolitical hate on social media.\nUyheng, J.,\u00a0& Carley, K. M. (2021). Characterizing network dynamics of online hate \ncommunities around the COVID-19 pandemic. Applied Network Science, 6(1), \nArticle 1. https://doi.org/10.1007/s41109-021-00362-x\nVogels, E. A. (2021, January 13). The state of online harassment. Pew Research Center:  \nInternet, Science\u00a0& Tech. https://www.pewresearch.org/internet/2021/01/13/the-state-  \nof-online-harassment/\nWalther, J. B. (2022). Social media and online hate. Current Opinion in Psychology, \n45, 101298. https://doi.org/10.1016/j.copsyc.2021.12.010\nWalther, J. B., Lew, Z., Edwards, A. L.,\u00a0& Quick, J. (2022).  The effect of social approval \non perceptions following social media message sharing applied to fake news. Jour-\nnal of Communication, 72(6), Article 6. https://doi.org/10.1093/joc/jqac033\nWeimann, G. (2012).  Lone wolves in cyberspace. Journal of Terrorism Research , 3(2), \nArticle 2. https://doi.org/10.15664/jtr.405\nWolf, W., Levordashka, A., Ruff, J. R., Kraaijeveld, S., Lueckmann, J.-M.,\u00a0& Williams, \nK. D. (2015). Ostracism online: A\u00a0 social media ostracism paradigm. Behavior Research Methods, 47\n(2), 361\u2013373. https://doi.org/10.3758/s13428-014-0475-x\nWoolf, L. M.,\u00a0& Hulsizer, M. R. (2004).  Hate groups for dummies: How to build \na successful hate-group. Humanity\u00a0 & Society, 28(1), Article 1. https://doi.\norg/10.1177/016059760402800105\nDOI: 10.4324/9781003472148-3\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Although the advent of social media has helped people forge meaningful con -\nnections, it has also fueled an accompanying rise in online incivility, har -\nassment, hate, and extremism. Online hate has become a topic of concern \namong intellectuals, activists, organizations, and governments attempting to uncover its underlying causes and combat the effects it has on individ-ual well-being, online communities, and civic life. The public consideration being paid to this issue is paralleled by increased scholarly attention from researchers who have been investigating the role of the Internet\u00a0\u2013 and social media spaces more specifically\u00a0\u2013 in the generation, diffusion, and effects of online hate.\nThe research on online hate falls roughly into four foci: (1) Benchmarking \nits pervasiveness across social media, (2) describing the content and nature of the messaging, and how social media enable and promote it, (3) under -\nstanding the effects of online hate on its victims, and (4) uncovering the moti -\nvations and gratifications for generating online hate (Walther, this volume). Although most of the chapters in this book focus on the fourth domain\u00a0\u2013 the motivation and facilitation of hate through various social processes\u00a0 \u2013 the book would not be complete without an account of the other three, since it is the pervasiveness, nature, and effects of the phenomenon that make online hate the significant social problem that it is.\nThis chapter provides an overview of the first three foci. It begins by \nintroducing various definitions and a taxonomy that classifies and frames the various forms of online hate that are the objects of contemporary pub -\nlic and scholarly concern. It then examines current estimates regarding the prevalence of online hate. It proceeds to an overview of how the various features and affordances found in social media platforms contribute to the 3\nFOUNDATIONS, DEFINITIONS,  \nAND DIRECTIONS IN ONLINE  HATE RESEARCH\nStephanie Tom Tong\n38 Stephanie Tom Tong\nease of creating and disseminating hate messages. The chapter also explores \nthe effects of online hate on individual recipients and collective targets, as well as on observers who function alternatively as active responders or pas -\nsive bystanders to hate within social media audiences. It then concludes with an examination of the remedies and solutions to online hate that have been proposed both online and offline.\nBackground and Definitions\nThere is no widely accepted definition of online hate, as it often highly depends on the specific perpetrators, targets, and contexts involved. However, many governing bodies have offered definitions to guide public discussion on online hate and hate speech. The United Nations (n.d.b) defines hate speech as\nany kind of communication in speech, writing or behaviour, that attacks or uses pejorative or discriminatory language with reference to a person or a group on the basis of who they are, in other words, based on their religion, ethnicity, nationality, race, colour, descent, gender or other iden -\ntity factor.\nSimilarly, the United States Department of Justice (n.d .) notes that \u201chate\u201d \ndoes not refer to basic disagreement, anger, or rage but requires specific bias against people or groups that reflect particular identity characteristics such as \u201crace, color, religion, national origin, sexual orientation, gender, gender identity or disability.\u201d\nMany of these definitions harken back to prior attempts to define hate \nspeech offline, which is also notoriously difficult to do, especially against the backdrop of concerns about free speech in public discourse (see Paz et\u00a0al., \n2020; Siegel, 2020; Woods\u00a0& Ruscher, 2021). Terminology abounds within \nthe published research\u00a0 \u2013 online hate, cyberhate, toxicity, incivility, online aggression, extremism, and extreme speech are all used variably and (at times) interchangeably (see also Fox, 2023). At their core, many of these terms high -\nlight that hate\u00a0\u2013 both online and offline\u00a0\u2013 is a form of communication that promotes denigration or harm against targets based on their stigmatized, identity-based characteristics. While some perpetrators are motivated by a deep-seated hatred or anger with a specific individual target, more often hate perpetrators are motivated by more general intergroup conflict and antipathy toward minority groups. Others simply revel in the joy and pleasure they get from causing chaos in targets\u2019 online (and offline) lives.\nThough many scholars have wanted to understand, define, and document \nthe differences of these various forms of online hate, such a task has been dif -\nficult to execute as the larger problem of online hate has continued to grow. To address this issue, this chapter offers a relational taxonomy of online hate  \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  39\nthat offers two particular dimensions: The first is the perpetrator-to-target \nrelationship that can be one-on-one, many-to-one, and group-level. The sec-ond dimension is whether the hate messages are sent privately or if they are \nbroadcast publicly, a difference that can radically change the function of hate \nmessages with content that otherwise might appear identical. This is not the only way to parse online hate, and indeed many scholars have adopted differ -\nent emphases (see for review Bliuc et\u00a0al., 2018; Brown, 2018; Hassan et\u00a0al., \n2022; Siegel, 2020; Thomas et\u00a0al., 2021; Waqas et\u00a0al., 2019). However, this \ndefinitional taxonomy focuses on the perpetrator-to-target relationship and the nature of the audience, thus reflecting the social nature of online hate in \nwhich this book is grounded (see Walther, this volume).\nA Relational/Broadcast Taxonomy of Online Hate\nOne-on-One Online Hate and Hate-Based Harassment\nThe first level offered in the current taxonomy constitutes one-on-one acts \nof online hate. Also known as online harassment, cyberbullying, or cyberag-\ngression in the scholarly literature, one-on-one hate occurs when an indi-\nvidual perpetrator uses Internet communication technology to antagonize a selected individual target person through actions such as name-calling or insults, deliberate online shaming or embarrassment, threats, or (sexual) har -\nassment\u00a0\u2013 either in a single, one-time act, or repeated acts over a sustained period of time (Vogels, 2021).\nIn its private form, one-on-one online hate may involve a perpetrator send -\ning a target unwanted, inappropriate, or threatening mediated messages. Jane \n(2020) notes the gender-based nature of one-on-one harassment, and how the \u201ctenacity of misogyny\u201d migrates to the online sphere (p.\u00a02). Perpetrators may track their target\u2019s online behavior or hack into a target\u2019s social media accounts for personal information. In its public form, one-on-one hate mes-\nsaging may involve bullying someone in a manner that others can observe, or spreading rumors or other private information about a specific target indi -\nvidual to others in public online spaces. A\u00a0perpetrator may engage in exces -\nsive liking, tagging, or commenting on a target\u2019s social media posts or follow a target by joining the same social media groups. Generally, the same actions that can be done privately can be done publicly, with the public dimension adding embarrassment for individual targets and well-justified fear of dam-age to their reputation.\nCritical to the one-on-one level of online hate is its interpersonal nature. \nPerpetrators and targets involved in one-on-one hate are often acquainted, having some kind of prior or existing relationship either online or offline, or both. Akin to intimate partner violence ( Finkel\u00a0 & Eckhardt, 2013), much \noverlap exists between one-on-one offline and online hate and harassment. \n40 Stephanie Tom Tong\nFor example, cyberstalking\u00a0\u2013 defined as repeated unwanted online communi -\ncation by a perpetrator intended to instigate stress, alarm, or fear in a specific \ntarget\u00a0\u2013 is analogous to offline forms of stalking behaviors, through which perpetrators intend to create similar types of distress ( Wilson et\u00a0al., 2022 ), \nalbeit privately. A\u00a0public form of one-on-one hate is image-based sexual har -\nassment\u00a0\u2013 or nonconsensual sharing of intimate photographs\u00a0\u2013 which may involve a perpetrator hacking and controlling, and then exchanging or post-ing, a target\u2019s private intimate images, in order to deliberately damage their reputation (see DeKeseredy, this volume). More recently, researchers have been discussing the potential uses of artificial intelligence technology by per -\npetrators to fabricate realistic-looking images and deep fake videos to exploit and harass their targets (Flynn et\u00a0al., 2022). As Barth et\u00a0al. (2023) note, the boundary between one-on-one and other levels of online hate is the perpetra -\ntor\u2019s intent to directly harm a known individual, as opposed to specific groups.\nMany-to-One Online Hate\nThe second level is classified as many-to-one online hate, and although it is \nperformed using the same kinds of technology as one-on-one hate, it differs in its relational scope. What may have begun as an interpersonal one-on-one act can transform into a larger scale attack in which several perpetrators \u201cpile on\u201d to engage in campaigns of many-to-one online hate. This form of online hate involves collective strategies and tactics by which an instigator signals enmity toward a specific person, and others follow suit. Thus, it is a social process of online hate and is the focus of this book. An infamous example of a coordinated many-to-one online hate act was 2014\u2019s Gamergate in which numerous perpetrators delivered a storm of insults, rape threats, and death threats to video game developer Zoe Quinn. From its origins in a series of angry blog posts written by Quinn\u2019s ex-boyfriend, it morphed into a larger, organized, many-to-one online hate campaign. As Dewey (2014) noted in her Washington Post article, \u201cwhatever Gamergate may have started as, it is now an Internet culture war.\u201d The events of Gamergate also introduced the term doxxing into the public vocabulary and consciousness, as the hateful practice of openly publishing a target\u2019s personal information (such as their residential address, place of work, phone number, etc.) online (Tiffany, 2022).\nNotably because many-to-one online hate always involves a group of \nantagonists, many-to-one attacks have no form that is strictly private (unlike one-to-one hate messaging). However, the different perpetrators involved in many-to-one hate activity may nevertheless send their messages to a target using private channels (as doxxing may encourage) such as email, voicemail, or other means. Many-to-one hate may take place in more public spaces of social media such as comments or interactive threads, thereby adding a dimension of embarrassment, shaming, and potential isolation to the \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  41\ntargets\u00a0\u2013 although the terror of having many attackers reach a target through \nprivate channels cannot be overstated.\nThe coordinated nature of many-to-one hate is similar to Marwick's \n(2021) conceptual idea of networked harassment \u201cin which an individual is harassed by a group of people networked through social media\u201d (para 3). Marwick analyzes examples of \u201cmorally motivated\u201d networked harassment in which an initial perpetrator targets an (out-group) member by publicly singling out the target\u2019s actions as an attack or violation of the perpetrator\u2019s rights or the social norms of their community. In framing their own message as a defensive attack against the target\u2019s bad behavior, perpetrators get to \u201cportray themselves as defenders of enlightened public discourse and their targets as irrational and immoral\u201d ( Lewis et\u00a0al., 2021, p.\u00a0735). Marwick and \nher colleagues go on to argue that these perpetrators\u2019 initial instigation can trigger moral outrage among other members of their in-group, thus justifying increasing online hate messages toward the initial target. She describes the case of Walter Palmer, a dentist and big-game hunter, who was the target of \u201cworldwide harassment,\u201d after photos of a trophy lion he shot and killed in Zimbabwe were circulated on social media. Marwick (2021) points out that \nthe anger and moral outrage sparked by this instance of big-game hunting was genuine, as was the \u201cAmerican arrogance, meaning that people who par -\nticipated in the harassment believed they were in the right\u201d (para. 9). Even though Palmer did nothing illegal, he still became the target of networked harassment and received several many-to-one hate messages\u00a0\u2013 both publicly and privately, online and offline.\nAnother form of many-to-one online hate actions may or may not focus \non any particular target. That is, while antagonists swarm and pile on in a collective and coordinated attack, their actions are not necessarily prompted by familiarity or relational history with a specific target or a target\u2019s sup -\nposed misdeeds. Rather, such events can be opportunistic, spontaneous acts of mob-based hate, extemporaneous undertakings in which groups of per -\npetrators find each other online and band together to produce an orches-trated many-to-one hate event. In many cases, they fit the mold of typical many-to-one attacks, such as brigading or dogpiling events, in which perpe -\ntrators swarm the comment feed of specific targets\u2019 online posts, attempting to embarrass or shame them. Such many-to-one forms of hateful overloading reflect organized efforts \u201cwherein an attacker forces a target to triage hun-dreds of notifications or comments via amplification, or otherwise makes it technically infeasible for the target to participate online\u201d ( Thomas et\u00a0al., \n2021). This is also akin to toxic commenting streams in which perpetrators \nswarm an individual target\u2019s post with hateful comments and replies. This kind of many-to-one hate prompts targets to leave the ongoing discussions taking place in public Internet spaces, such as news websites (see Salminen \net\u00a0al., 2020).\n42 Stephanie Tom Tong\nOther extemporaneous, public attacks are more impersonal rather than \npersonal. Rather than focus on any specific victim, these \u201ccrimes of opportu -\nnity\u201d are primarily motivated to achieve disruption for the sake of disruption, \nresembling in purpose the act of trolling. (A troll \u201cbaits and provokes other group members, often with the result of drawing them into fruitless argu -\nment and diverting attention from the stated purposes of the group\u201d; Herring et\u00a0al., 2002, p.\u00a0371.) Recent examples include Zoombombing, when perpe -\ntrators hijack video conferences or classes and post hateful or obscene con -\ntent in order to disrupt the conduct of the meeting. Zoombombing became particularly problematic during the COVID-19 pandemic when much of the global workforce moved to telework and used videoconferencing technol -\nogy. Reports emerged of Zoombombers targeting K-12 and university online classrooms and remote religious services, taking control of screens to broad -\ncast pornography, racial slurs, and insults (see Lee, 2022). A\u00a0sign of its grow -\ning prevalence, in 2020, the U.S. Department of Justice was prompted to take the \u201cweaponization of Zoom\u201d more seriously and vowed to prosecute it as a crime at local, state, and federal levels (Statt, 2020; see also Stringhini\u00a0& Blackburn, this volume).\nGroup-Level or Intergroup Online Hate\nThe final category of this typology describes the most diffuse group-level \nor intergroup form of online hate. Due to its nature, this kind of hate most \nfully involves social processes among perpetrators and is therefore almost always broadcast publicly. The intergroup level is where much of the politi -\ncally motivated, extremist kinds of online hate content can be found and is also what much of the Internet-using public experiences more generally. At this level, perpetrators\u2019 goals are to demean, degrade, and insult, or to raise concerns over existential threats posed by members of some particular social group. Race, religion, gender, immigration, and other such social categories are the ultimate targets of this kind of hate.\nThere are, again, variants of intergroup online hate messages. Quite com -\nmonly, a scurrilous comment appears about the entire target group as a whole. In other cases, while it may appear as though a specific individual is the target of a hate message\u00a0\u2013 a politician or some well-recognized public figure\u00a0\u2013 there may be clues, or well-known linkages (factual or conspiratorial in nature), which associate the targeted person with a particular social group (see, e.g., https://www.ajc.org/translatehate/Soros). To attack the individual, who is a surrogate or prototype, is really to implicate the larger group with which the individual is associated. Because of its diffuse nature, many of the hate messages disseminated at the intergroup level appear in publicly acces -\nsible spaces online.\nAlthough perpetrators may initially focus their attention on one particular \ngroup, researchers note that they often shift their focus to target additional \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  43\ngroups. For example, in its report on American White Supremacy, the ADL \n(2018) noted that while the alt-right is still grounded in antisemitic hate foun -\ndations, the \u201cmodern\u201d White Supremacist resurgence taking place online is \nbeing dominated by young, white men who often attack many others, includ -\ning Blacks, women, and LGBTQ+ groups. This \u201cshifting\u201d nature of hate tar -\ngets suggests that at this intergroup level, degrading a specific identity-based group may not always be a galvanizing force for online hate; instead, it may be the underlying social processes provided by, and which reinforce, the act of hating itself that motivates and sustains perpetrators\u2019 behavior (Walther, this volume). Table\u00a03.1 summarizes this typology.\nMapping the Online Hate Landscape: How Much,  \nWho, and Where?\nMany recent large-scale surveys have attempted to document the prevalence, \nthe targets, and the venues of different kinds of online hate content that peo -\nple report observing and experiencing. Although the specific forms or levels of online hate are not always clearly defined within the survey data or results, the general conclusion drawn from this body of work is that public exposure to online hate of all levels is increasing, with much of that exposure occurring on social media.\nPrevalence: How Much?\nStudies find very high rates of people having experienced online hate. How -\never, like the variable definitions of online hate, researchers also lack con -\nsistency when defining what constitutes people \u201cexperiencing\u201d online hate. TABLE\u00a03.1   A\u00a0Relational/Broadcast Taxonomy of Online Hate\nBroadcast Private Public\nRelational Patterns\nOne-on-One (often Targeted Observable bullying; deep \ninterpersonal, known harassment; fake sexual harassment \ntarget) cyberstalking videos\nMany-to-One (collective Doxxing Gamergate; mob-based hate; \nstrategies toward known overloading, dogpiling, \ntarget, networked toxic commenting, \nharassment, both personal Zoombombing\nand impersonal)\nGroup or Intergroup \u00a0\u2013 Political, extremist, targeting \n(referencing groups, social categories; often \nindividual targets as shift to target other/\nsurrogates for group) multiple groups\n44 Stephanie Tom Tong\nExperience sometimes refers to individuals\u2019 direct encounters as a specific \ntarget of one-on-one online hate or hate-based harassment, while, at other times, it is mere exposure to hateful content as an observer or passive bystander in social media spaces. Despite these discrepancies, the broader landscape of online hate underscores its seemingly ubiquitous nature. Survey data from Pew Research (Vogels, 2021) suggests that in the United States, 41% of Americans have \u201cpersonally experienced some form of online har -\nassment\u201d\u00a0 \u2013 everything from forms of name-calling and deliberate embar -\nrassment to (cyber)stalking and sustained harassment. The ADL\u2019s annual online hate and harassment survey found similar estimates in 2022, with 40% of their American sample reporting some kind of personal experience with online hate.\nInternational survey results also emphasize online hate as a global prob -\nlem: Reichelmann et\u00a0al. (2021) asked respondents sampled from six countries \nabout their exposure to hate content online: \u201cIn the past 3 months, have you seen hateful or degrading writings or speech online that attacked cer -\ntain groups of people or individuals?\u201d (p.\u00a01102). They found Internet users from Finland reporting the greatest amount of online hate exposure (78.5%), followed by Spain (75.2%), the United States (73.2%), Poland (72%), the United Kingdom (65.6%), and France (64.8%). Overall, they conclude that the majority of their sample had \u201cbeen exposed to hateful or degrading writ-ings or speech online that attacked certain groups of people or individuals\u201d (p.\u00a01102) within the last three months.\nThese estimates, combined with public outcry of social media as a breed-\ning ground for violent extremism, would lead us to believe that hate is prevalent and just \u201ca click or two away\u201d in any online space ( Meyers\u00a0& \nThompson, 2022). Although the lack of consistent definitions makes it harder to definitively discern the specific kinds of online hate content, the public and scholarly consensus is that online hate is a pervasive, global, and increasing problem.\nWho is Targeted?\nSurvey data also highlight how perpetrators of online hate target people based on a variety of identity-based characteristics\u00a0\u2013 political beliefs, gen -\nder, sexuality, race/ethnicity/culture, nationality or national origin, religious beliefs, and disability status have all been documented. However, empirical trends indicate that younger individuals (i.e., 18 to 29) who spend more time online and identify as female, LBGTQ+, racial/ethnic minorities, or politically moderate-to-liberal are more likely to report being targets of online hate (Costello et\u00a0al., 2017, 2019; Kenski et\u00a0al., 2020 ; Obermaier\u00a0& \nSchmuck, 2022).\nMuch evidence points to the pervasiveness of gender-based online hate  \nthat occurs at all three levels of the relational taxonomy of online hate. For \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  45\nexample, in their Italian Hate Map project, Lingiardi et\u00a0al.'s (2020) auto-\nmated semantic content analysis of 2,659,879 Twitter tweets (as the plat -\nform X.com was then known) found that women were the most frequently insulted group\u00a0 \u2013 receiving 60.4% (roughly 71,000) of the hate tweets. Another survey by Amnesty International United Kingdom conducted in 2017, which included a sample of 504 women from the United Kingdom, the United States, New Zealand, Spain, Italy, Poland, Sweden, and Denmark, reported that \u201cone in five women reported experiencing online hate-based harassment.\u201d More than a quarter of these cases (27%) were characterized as one-on-one harassment, with targets knowing the perpetrators; but 59% said \nthat the perpetrator was a stranger, suggesting more anonymous forms \nof online hate. Sexuality or sexual orientation is also a frequent characteristic \nfor group-level hate online, with recent estimates suggesting anywhere from 51% to 64% of LGBTQ+ individuals experiencing hate-based harassment (ADL, 2022; Vogels, 2021). A\u00a0burgeoning area of scholarship further high -\nlights the extreme level of hate that occurs against women and LGBTQ+ indi -\nviduals in online gaming, an arena typically dominated by men ( Ballard\u00a0& \nWelch, 2017; Beres et\u00a0al., 2021; Ortiz, 2019).\nRace and ethnicity are also common factors in intergroup online hate. \nAccording to the UN, \u201c70 percent or more of those targeted by hate crimes or hate speech in social media are minorities\u201d ( United Nations, n.d.a). Though \nonline race-based hate is a global phenomenon, the specific racial-ethnic groups being targeted often change according to the region being examined. Unsurprisingly, most of the published studies of online racial hate have inves -\ntigated the United States or Europe: In their comprehensive meta-analysis, Waqas et\u00a0al. (2019) concluded that much of the published online racial hate scholarship reflects a \u201cglobal dominance and higher share of Western insti -\ntutions\u201d (p.\u00a0 16). This indicates that scholars know much about Western -\nized forms of online racial-ethnic hate and less about forms in other parts of the world. Yet, a more global focus is needed, especially because online race-based hate becomes more complex when it overlaps with nationality, \nreligion, and culture (e.g., Udupa\u00a0& Gerold, this volume). This creates inter -\nsectional contexts such as online Islamophobia or antisemitism that are dif-ficult to parse out. Out of convenience, most researchers tend to simplify online hate against \u201call Muslims\u201d or \u201call Jews\u201d\u00a0\u2013 even when targets have different racial-ethnic backgrounds, national origins, religions, or cultural traditions (see Sharif, 2018). Though more efficient, such definitional gener -\nalities often obscure the nuances in online race-based hate as a multifaceted communicative phenomenon.\nRecent research also reflects increasing levels of political online hate that \ncan coincide with other kinds of identity-based hate. In some instances, spe -\ncific offline political events serve as the inception point for discordant inter -\naction on popular social media spaces, which can then mutate into broader hateful exchanges of incivility and animosity. One example occurred during \n46 Stephanie Tom Tong\nthe 2016 Brexit referendum, a proposal for the United Kingdom to sever \nits relationship with the European Union. Evolvi's (2019) analysis of Twit -\nter hashtags demonstrated how the offline 2016 Brexit referendum pushed right-wing populism and nationalistic identity to the forefront of online political discourse, as seen in many #Brexit tweets. Political disagreements about whether to \u201cleave\u201d or \u201cremain\u201d later evolved into intergroup insults and name-calling, with nationalistic groups further touting non-European migrants as a threat to British culture. This position then paved the way for derogatory, post-Brexit Islamophobic tweets that \u201cframed Muslims as non-British foreigners that are \u2018different\u2019 from white British\u201d (p.\u00a0392). The Brexit case exemplifies how offline political events can also fuel group-level online hate on social media.\nIn spring 2020, American social media users saw a sharp rise in anti-Asian \nonline hate that coincided with the COVID-19 pandemic. Anger, fear, and frustration were high at the start of the pandemic when news outlets began reporting the origins of the coronavirus in Wuhan, China. At the time, prom -\ninent U.S. political leaders, including President Trump, blamed China (and Asian Americans by association) for causing the \u201ckung flu\u201d and the ensu-ing worldwide pandemic ( Lee, 2020). As preventative health behaviors such \nas mask-wearing and social distancing became increasingly politicized, so did the amount of Sinophobic slurs seen on Twitter and 4chan (Tahmasbi et\u00a0al., 2021). As members of the targeted group, Asian American social media users were generally more aware of the increasing anti-Asian online hate in 2020 compared to non-Asian Americans ( Tong et\u00a0al., 2022 ). Interestingly, \nthis cycle\u00a0\u2013 which began offline with the COVID-19 pandemic and led to increased online hate in social media\u00a0\u2013 further suggests how offline events can reverberate online, and back again, indicating social processes across venues and time.\nLupu and colleagues (2023 ) investigated the relationships between the \n2020 U.S. presidential election and online hate speech patterns on both main -\nstream (e.g., Facebook, Instagram) and less-moderated (e.g., Gab, Telegram, 4chan) social media platforms. They found that between November 3, 2020 (election day), and the ensuing announcement of Joe Biden as the winner by the Associated Press on November 7, a surprising spike in gender-based and LGBTQ+ online hate occurred. Although some of this online gender-based hate seemed to target Vice President-Elect Kamala Harris directly (suggesting deliberate acts of targeted many-to-one hate), Lupu et\u00a0al. (2023) concluded that \u201cthe ensuing wave of associated online hate speech appears to be largely a case of users employing anti-LGBTQ+ slurs in a generalized manner to malign a wide range of political targets, such as candidates, parties, and vot -\ners\u201d (p.\u00a08) or the more anonymous form of many-to-many online hate. These findings further demonstrate the comingling of multiple forms of intergroup online hate with politics\u00a0\u2013 in this case gender and sexual orientation.\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  47\nWhere Does Hate Happen Online?\nMainstream Social Media\nThe most recent surveys of U.S.-based samples indicate that the experience of \nonline hate is mostly occurring on mainstream social media . Most individu -\nals report that they don\u2019t seek out this content intentionally, but rather their exposure to hate content occurs accidentally. Of the 41% of respondents in the Pew Research (Vogels, 2021) sample who experienced online hate-based harassment, 75% of them reported that these incidents occurred on social media. The ADL\u2019s (2022) survey of American Internet users also found Face -\nbook to be the most frequent social media platform for online hate (68%), followed by Instagram (26%) and Twitter (23%; see also Phadke and Mitra, this volume). Other oft-cited spaces where Americans encounter online hate include discussion forums, online gaming platforms, and romantic dating platforms. Internationally, online hate also occurs mostly in mainstream social media, with Facebook being the \u201cmost common location where hate materials were viewed\u201d (Reichelmann et\u00a0al., 2021, p.\u00a01105).\nThis public focus on unintentional exposure to online hate in main -\nstream social media is also reflected in the published scholarship. Matamoros-Fern\u00e1ndez and Farkas\u2019 (2021) review of 104 academic English-language studies of online race-based hate published between 2014 and 2018 revealed an emphasis on hate in mainstream social media, with the majority of studies examining Twitter (54.81%), followed by Facebook (34.62%) and YouTube (8.65%). They note that the \u201cprominence of Twitter in the academic literature is likely tied to the relative historical openness of the platform\u2019s APIs\u201d (application programming interfaces) (p.\u00a0211) and the fact that much of this data was freely available and could be collected with -\nout requiring informed consent.\nFringe Platforms and Alt-Tech Media\nTracking the nature of online hate circulated in mainstream social media (Facebook, Twitter/X, YouTube, Instagram, etc.) has resulted in important insights, but more research is needed into hate content exchanged on other, fringe social media platforms. Spaces like 4chan, 8chan, Gab, Gettr, and \n Telegram are sometimes called fringe because they are not frequented by most \nof the online public. Their near-zero level of content moderation makes them exceptional breeding grounds for the exchange of hateful and extremist con -\ntent that is often banned within mainstream social media platforms. Recent work has attempted to examine the nature and spread of hate within fringe social media platforms. Rieger et\u00a0al.'s (2021 ) content analysis estimated that \nas much as 24% of comments on such platforms contain explicit or implicit hate speech (p.\u00a01). Hine et\u00a0al. (2017 ) collected 8 million posts from the 4chan \n48 Stephanie Tom Tong\n/pol/ image board over a 2.5-month period. Using the Hatebase dictionary \n(hatebase.org)\u00a0\u2013 \u201ca crowdsourced list of more than 1,000 terms from around \nthe world that indicate hate\u201d\u00a0\u2013 they found that 12% of the /pol/ posts con -\ntained hate speech terms (p.\u00a097). They compared their 4chan /pol/ dataset to a corpus of 60 million Twitter tweets collected over a one-month period and found that the tweets contained \u201conly\u201d 2.2% of the same hate terminology (see also Stringhini\u00a0& Blackburn, this volume).\nAnother popular fringe platform is Gab.com, a social media space that \nprovides features similar to those of Twitter but without the dramatically looser terms of use or content moderation control. Indeed, it has embraced its place within the \u201calt-tech\u201d movement: \u201cAt Gab, we believe\u00a0.\u00a0.\u00a0. that users of social networks should be able to control their social media experience on their own terms, rather than the terms set down by Big Tech\u201d (gab.com). Qualitative analyses of Gab posts indicate that much of its user-generated content contains far-right conspiracy theories and hate speech\u00a0\u2013 primarily antisemitism, Islamophobia, anti-Black racism, and misogyny ( Jasser et\u00a0al., \n2023). In their exploration of individual Gab user activities, Mathew et\u00a0al. \n(2020) created \u201ctemporal hate vectors\u201d that scored the \u201chatefulness of a user\u201d during a single, month-long period. They then used these temporal snapshots to calculate the hate intensity among individual users and also at the larger network level. They concluded that not only is the overall amount of hate on Gab steadily increasing but also that \u201cnew users are becoming hateful at an increased and faster rate\u201d (p.\u00a01). Much of this content was being posted by especially hateful, core users\u00a0\u2013 or hate mongers\u00a0\u2013 who occupied a more central position within the network and disseminated more hate -\nful content more frequently than \u201caverage hateful\u201d and \u201cnon-hateful\u201d Gab users (p.\u00a015; see also Goel et\u00a0al., 2023). Such analyses vividly demonstrate \nhow much hate is ingrained in fringe social media platforms, and how it is circulated within groups, reinforcing the primary theme of this book.\nFringe platforms (like Gab and others) are characterized by a lack of con -\ntent moderation, relative anonymity, ephemerality, and ease of multime -\ndia message exchange. Because they are enigmatic and relatively unknown among most social media users, fringe platforms are often used to form what Massanari (2017) calls \u201ctoxic technocultures\u201d or \u201cleaderless, amorphous\u201d cultures of hate that are \u201cenabled and propagated through the sociotechni -\ncal networks\u201d of spaces like Reddit, 4chan, and online gaming (p.\u00a0333). The specificity and often coded nature of the topics, meanings, and vocabulary exchanged among users of fringe platforms insulate them from the judgment of the general public, making them the perfect online environments for con-tinued hate:\n[M]any of these spaces remain relatively (and purposefully) inaccessible to the average internet user, often requiring technological expertise to set up proxies (in the case of the darknet) or cultural expertise to understand the \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  49\nmyriad memes, in-jokes, and linguistic short-hand that serves the lingua \nfranca of spaces like 4chan.\n(p.\u00a0334)\nThose who seek to join and participate in these fringe platforms must not \nonly adopt the group\u2019s extremist views and identity, they must also have the required technological and terminological expertise.\nNotably, scholars\u2019 use of terms like \u201cfringe\u201d or \u201calt-tech\u201d to describe these \nplatforms is relative and sometimes paints a misleading picture, portraying such usage as restricted to small sets of like-minded users (see also Rea et\u00a0al., this volume). However, in June 2022, Telegram (2022) reported that it had \n\u201cover 700 million monthly active users\u201d making it one of the most heavily trafficked social media platforms. This is particularly problematic, given that recent estimates indicate that Telegram is an \u201cactively growing environment for US-based hate speech and extremism with a range of ideologies present\u201d (Walther\u00a0& McCoy, 2021, p.\u00a0114; see also Udupa\u00a0& Gerold, this volume). Similarly, 4chan reported that it receives 22 million unique visitors per month, with 11 million coming from the United States ( 4chan, n.d.). There \nis also evidence pointing to the increasing numbers of new users who are downloading these fringe social media apps to their phones internationally\u00a0\u2013 Statista (2023) charted the growth in new Gettr users in 2022 and reported a 743% increase in the UK, 320% in Australia, and 266% in Brazil. Clearly, though such platforms may not be considered part of the mainstream social media ecosphere, they already have millions of users who function as a post -\ning and receiving audience for hate messages through both intentional and accidental exposure.\nInsular Extremist Sites and Forums\nFinally, researchers have also examined the content that occurs in more insu -\nlar social media spaces and websites that are founded, populated, and main -\ntained by hate perpetrators and extremists themselves. As Bliuc et\u00a0al. (2018) note, \u201cgroup-based cyber-racism is generated by racist and white supremacist organisations, so it predominantly occurs on the websites of these groups in various forms\u201d (p.\u00a0 81). Prominent examples include Stormfront.org, Iron March, and Fascist Forge\u00a0\u2013 online forums populated primarily (if not exclu -\nsively) by White Supremacists and right-wing extremists who deliberately seek out and exchange hateful content with like-minded others.\nSuch forums sometimes have rigorous application practices that screen for \nnew members. Scrivens et\u00a0al. (2021\n) describe the multistep process involved \nin gaining Fascist Forge membership in which candidates apply by stat -\ning their interests and goals in joining the forum. Site administrators then vet new candidates, admitting access only to those who are \u201ccommitted to the extremist cause\u201d (p.\u00a04). In the public, mainstream social media arena, \n50 Stephanie Tom Tong\nextremists and haters are a minority who often worry about violating the \nnormative rules and policies of majority platforms (i.e., posting racial/homo -\nphobic/sexist slurs, circulating extremist images, inciting/calling for physical violence, etc.) or risk sanctions such as suspension or deplatforming. Inter -\nestingly, within Fascist Forge, content is also heavily moderated, but in these insular forums, administrators ensure that members\u2019 posts conform to the hateful extremist ideology, or else those users get kicked out of the forum. Clear content moderation practices exist in these insular forums; however, in a perverse twist, the content is screened for continued hateful sentiment that bolsters the collective extremist identity.\nThough such insular forums are \u201cfringe\u201d in the sense that they are not \nspaces the general, Internet-using public might frequent, they are \u201cmain-stream\u201d to perpetrators who know each as a place that invites, accepts, and nurtures the advocacy of violent extremism and hate-fueled content. As such, the membership of these insular spaces may be (relatively) few, but they account for an outsized proportion of race-based hate content online (see also T\u00f6rnberg\u00a0& T\u00f6rnberg, this volume).\nVirtual Reality (VR) and the Metaverse\nSocial VR platforms like Meta\u2019s Metaverse (sometimes also called multi-user immersive experiences) provide a three-dimensional, immersive envi -\nronment where multiple users can meet and interact using head-mounted hardware. Research has indicated several advantages for users, such as enhanced self-expression and experience of identity through development of full-body avatars and the exchange of verbal and nonverbal behav -\niors that can quickly promote close relationships with others (Freeman\u00a0& Acena, 2021). However, there is also a darker side to social VR: Blackwell \net\u00a0 al. (2019) interviewed 25 users and found that like any other online space, users were exposed to hate and harassment that ranged from verbal  \nbehaviors such as insults, to physical behaviors like unwanted touching among avatars, as well as spatial harassment\u00a0\u2013 such as when \u201ccrashers\u201d \u201cflood\u201d users\u2019 VR environment with unwanted sexual or violent content (Schulenberg et\u00a0al., 2023).\nAlthough VR users are free to construct their own avatars, identity-based \ncharacteristics are still important self-presentational features. Blackwell et\u00a0al. \n(2019) found that among their sample of VR users, \u201ccertain types of people\u00a0\u2013 namely, women, children, people of color, and people with strong accents\u00a0\u2013 were much more likely to be harassed in VR than others, due to vocal cues and avatar appearance\u201d (p.\u00a01). In their interview study, Schulenberg et\u00a0al. (2023) found that women who presented avatars with gendered characteris -\ntics experienced hate in VR that was akin to (but experienced more viscerally than) the hate encountered in online gaming spaces.\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  51\n[T]he heightened sense of immersion and embodiment made all of our \nwomen participants feel significantly more harassed, anxious, and inse -\ncure when another user violates their personal physical space in social VR than when that same violation occurs in pre-existing online games and virtual worlds.\n(pp.\u00a09\u201310)\nIn some ways, the nature of one-on-one hate reported in social VR harkens \nback to the gender-based hate reported in text-based spaces like Lambda -\nMOO in the early days of the Internet ( Dibbell, 1993). However, as recent \nstudies suggest, the heightened sense of presence in VR seems to magnify the \neffects of one-on-one hate for many targets. Given its recent debut, there are few guidelines or policies being set by industry leaders like Meta (formerly Facebook), leaving users to grapple with the lack of social norms within such spaces: \u201cIt\u2019s kind of like the Wild West. There\u2019s no regulation, there\u2019s no moderation. People are just kinda doing their own thing\u201d ( Blackwell et\u00a0al., \n2019, p.\u00a0 855). Relying on users to self-govern their own behavior seems problematic, given the potential for hate already being seen and reported within social VR interaction, though at present, few media companies seem interested in providing any guardrails. However, recent prompts from the Biden presidential administration on the issue of cybersecurity suggest that American social media companies are being forced to consider taking more specific actions to protect their users (Shear et\u00a0al., 2023).\nThis review of the online hate landscape points to the nature of hate con -\ntent that is being posted and exchanged in mainstream, fringe, and insular social media platforms, as well as within novel VR in the Metaverse. Such content raises the question of which features and affordances embedded in popular and fringe social media platforms facilitate easy creation and rapid dissemination of online hate.\nThe Features and Affordances that Contribute to Online Hate\nThere are many features unique to online social media platforms that make them an exceptional breeding ground for hateful communication. These include system-based cues and paralinguistic digital affordances native to \nonline platforms. These cues and affordances not only provide information about user influence and sociometric status, they also contribute to the for -\nmation and furtherance of collective group identity.  Perpetrators also take \nadvantage of various kinds of identifiability: In some cases, they exploit \nanonymity and/or pseudonymity that shield them from offline sanctions for their hateful online expressions. In other cases, they manipulate their online self-presentation to create a persistent, identifiable presence and build both \nsocial and fiscal capital. Social media platforms also have features that enable \n52 Stephanie Tom Tong\nusers to organize and share content easily, while built-in recommender algo-\nrithms continue to feed users more deeply polarizing and hateful content in \nan effort to sustain their interest. These features all combine to make online platforms the ideal environment for easy and consistent dissemination of hate, and they pave the way for unique social dynamics that are often not found in offline interactions in such a direct and blatant way.\nSystem-Based Cues and Paralinguistic Affordances: Sociometric \nStatus, Influence, and Collective Identity Building\nAmong the most notable and unique features of social media platforms \nthat shape online hate are the system-based cues and paralinguistic digital \naffordances embedded in their architecture. System-based cues are embed-ded automatically and cannot be changed or edited by its users ( Walther\u00a0& \nJang, 2012). Prior work examining system-based cues in mainstream social media sites\u00a0\u2013 like Facebook\u2019s friend count, Instagram\u2019s and Twitter\u2019s follower counts\u00a0\u2013 has demonstrated that small cues provide important sociometric, or \nstatus-based, information about individuals\u2019 popularity and influence that can subsequently affect observers\u2019 judgments of their attractiveness and per -\nsonality (Tong et\u00a0al., 2008). Some platforms also provide what Hayes et\u00a0al. \n(2016) call paralinguistic digital affordances  (PDAs): \u201cCues in social media \nthat facilitate communication and interaction without specific language asso -\nciated with their messages\u201d (pp.\u00a0172\u2013173). Within mainstream social media sites, PDAs include cues such as Facebook\u2019s Like, Twitter\u2019s heart, and Red -\ndit\u2019s upvoting and downvoting. Because such affordances are a unique prod -\nuct of the relationship between the technical feature provided by the system and users\u2019 perceptions (Treem\u00a0& Leonardi, 2013), these lightweight PDAs can fulfill various communicative functions such as social support, relational closeness, or acknowledgment or interest in others\u2019 social media content (Hayes et\u00a0al., 2016).\nIn the context of online hate, system-based and PDA cues can sometimes \nreveal basic information about a user\u2019s background\u00a0\u2013 such as a flag that sig -\nnals a poster\u2019s country of origin in 4chan\u2019s /pol/ ( Hine et\u00a0al., 2017 ). More \noften, however, they are used to signal status, influence, interest, and com -\nmunity within online hate forums. Examination of the function of Reddit votes as a PDA shows that (in aggregate) votes have the effect of promoting and spreading toxic content. When a particular post receives several upvotes, it signals increased user interest, which boosts that post\u2019s visibility and ampli -\nfies its presence on the site, whereas downvotes signal decreased user engage -\nment and interest. The most sociometrically popular posts are featured on Reddit\u2019s front landing page (Gaudette et\u00a0al., 2020).\nIn this way, such PDAs also serve as vanity metrics, which are the unique \ncues built into social media that can help audiences distinguish the \u201cvalue\u201d \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  53\nof a piece of content within the platform and subsequently the importance \nof the user who generated the valuable content ( Rogers, 2018). Though their \noriginal intention was to measure user engagement on social media, vanity metrics can now serve a variety of purposes with respect to a user\u2019s social status and network influence. Ultimately, they have been co-opted as a way to place a literal numeric value on certain figures in virtual communities, including hate communities, which allows their status and influence to be \ntracked. Interestingly, \u00c5kerlund (2021) notes that such metrics can also be especially useful for researchers trying to explore the relatively anonymous and seemingly leaderless nature of online hate groups.\nPDAs can also bolster community identity and relational bonds among \nhate group members. Gaudette et\u00a0 al. (2020 ) analyzed how upvotes and \ndownvotes functioned within the subreddit r/The_Donald\u00a0\u2013 a board focused on former U.S. President, Donald Trump. Examining posts from 2017, they found that 11.6% of the 1,000 most highly upvoted comments in the sub -\nreddit contained Islamophobic and anti-immigration attitudes that instanti -\nated a sense of \u201cexternal threat\u201d and promoted the nationalistic \u201cAmerica First\u201d group mentality. Additionally, 13.4% of those comments rallied against the \u201cLeft\u201d and often painted subreddit members as victims. The downvoting feature also provided a way to filter out content that detracted from the \u201cus-against-them\u201d attitude: \u201cReddit\u2019s downvoting feature func -\ntioned to ensure that members were not exposed to content that challenged their right-wing beliefs, which functioned as an echo chamber for hate and may have also functioned to correct the behavior of dissenting members\u201d (p.\u00a03503). From this detailed analysis, Gaudette et\u00a0al. (2020 ) concluded that \nthe Reddit vote feature served as a way for r/The_Donald subreddit users to strengthen the collective identity by sociometrically validating hateful, extremist attitudes with upvotes and sociometrically punishing nonconform -\nist comments through downvotes (see Shmargad et\u00a0al., this volume). This is another illustration of the social processes fostering online hate.\nEven in the absence of system-based and PDA cues to officially track hate \non varying platforms, researchers have found that members of online hate communities find ways to show their social support and interest in each other\u2019s posts in a form of pseudo-metrics via their comments, responses, or manual \u201csharing\u201d of the content (\u00c5kerlund, 2021; see also Walther, 2022). \nFor instance, 4chan lacks specific PDA cues or vanity metrics to signal valida -\ntion, common identity, or social support, so users must directly engage with each other\u2019s posts by commenting. As such, there is a unique form of social \nlearning that seems to have emerged among the communities on platforms that lack PDA cues, with each developing its own unique sets of cultural norms, relational expectations, and social hierarchies around these metrics and the individual value placed upon these metrics by the members of each online hate community.\n54 Stephanie Tom Tong\nAnonymity, Pseudonymity, and Identifiability\nAcross social media, identity information varies. Some mainstream platforms \nlike Facebook operate on a \u201creal name\u201d policy (i.e., profiles are expected to contain one\u2019s real first and last names, identity, and photograph), and oth-ers, like Twitter, allow users to choose a pseudonym or username that may or may not reflect their offline identity. Pseudonyms and usernames still offer some identifiable information that distinguishes individual users and tracks \nand records their activity on the platform. Other platforms such as  Whisper \nor Secret offer even greater anonymity\u00a0\u2013 usernames are assigned by the plat -\nform, and individuals may choose to change them at any time, making it harder to track activities of specific users.\nPlatforms that promote total anonymity give individuals an easier pathway \nto get involved in online hate\u00a0\u2013 the lack of connection to one\u2019s outward-facing offline identity can embolden perpetrators to create and share extremely hateful or toxic content by reducing one\u2019s sense of personal responsibility (Brown, 2018). Even when operating with a pseudonym, the lack of connec -\ntion to corporeal identity still lends itself to lower inhibitions ( Suler, 2004) \nand decreased perceived social barriers, sanctions, and norms surrounding incivility and aggressive behavior (R\u00f6sner\u00a0& Kr\u00e4mer, 2016). Theoretically, the social identity model of deindividuation (see Postmes et\u00a0al., 2002) has \nlong posited that the (pseudo)anonymous nature of online platforms can prime a sense of deindividuation\u00a0\u2013 or a suppression of individual identity\u00a0\u2013 and an increased salience of group-level identity. The cognitive experience of deindividuation has been shown to be correlated with propensity for online hate participation through the intervening mechanism of moral disengage-\nment of the bullying behavior (i.e., vilifying a target of hate/maltreatment, disregarding consequences of the harassment, reconstruing the group\u2019s con -\nduct, and obscuring their own personal agency) ( Chan et\u00a0al., 2022 ), with the \nsimultaneous identification with a group with a norm of such behavior.\nSimilarly, some researchers contend that increased user identifiability can \nmitigate the extremity of online hate content. In their dataset of misogynistic tweets targeting Japanese female politicians on Twitter, Fuchs and Sch\u00e4fer \n(2021) point out that \u201cthe language of abusive or insulting tweets was not as harsh as assumed on Twitter, if compared to what can be observed on 2channel\u201d (p.\u00a0571). The authors suggest that perpetrators\u2019 fears of violating Twitter\u2019s conduct policies ( Twitter, 2023) and the threat of account suspen -\nsion resulted in relatively reduced nature of misogynistic tweets compared to the extremity of hate seen in 2chan. Note that this does not require specific individual identification; the pseudonym identifies the persistent user.\nInterestingly, perpetrators rely on the duality of pseudonymity (and the \nprivacy it offers) and the conspicuousness of public-facing online identity to create and circulate hate online. The duality of anonymity/identifiability \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  55\ndepends on a perpetrator\u2019s goals: In some cases, anonymity and message \nencryption are required for individual exchange of hate content and coordi -\nnation of and participation in hateful (potentially illegal) activities. In other cases, leaders of hate groups want to be identifiable, presenting themselves online to attract followers and court social influence. To build such status requires giving up full anonymity (to an extent) to create an outward-facing public identity using pseudonyms or avatars. In doing so, hate mongers can curate their identities, record their activities, archive their posts, and interact with members of their audience. Rogers (2020) describes this use of both pri -\nvate anonymity and public social identity as private sociality which reflects \nthe chimera-like nature of identity among perpetrators of online hate. The ways that anonymity and identifiability can impact individuals\u2019 feelings and behavior clearly contribute to their propensity to consume and disseminate online hate.\nAlgorithmic Recommendation, Commenting, and Multimedia \nHyperlinking/Content Sharing\nAnother factor involved in the circulation of online hate content is the algo-\nrithmic recommender systems found on many Internet platforms. In 1998, Amazon introduced item-based collaborative filtering that offered recom-mendations for its customers ( Smith\u00a0& Linden, 2017 ); in 2009, Facebook \nbecame one of the first mainstream social media companies to implement recommender algorithms when it introduced the Newsfeed that algorithmi -\ncally curated each user\u2019s content and, doing so, encouraged its users to con -\ntinue friending new people, while also avoiding the information overload associated with content from their growing networks (Smith et\u00a0al., 2022). Other popular platforms such as YouTube and TikTok implemented their own recommender algorithms that provide content tailored to users\u2019 interests and preferences in an attempt to gain their attention and continued loyalty. These recommender systems have been portrayed as providing \u201cradicaliza-tion by algorithm,\u201d which describes the process by which platforms like You -\nTube can \u201cdraw users into algorithmically induced encounters with more and more radical views\u201d (Forestal, 2021, p.\u00a0306), particularly among those with politically conservative and alt-right perspectives. Akin to the idea of \u201cfilter bubbles\u201d (Pariser, 2011), recommender algorithms feed content to users that aligns with their preexisting attitudes and reduces exposure to outside ideas, increasing polarization through so-called echo chambers.\nHowever, as Munger and Phillips (2022 ) note, though cases of online \nradicalization through filter bubbles have been documented in the popular press, most \u201cjournalistic evidence is fraught with a bias toward sensational -\nism\u201d (p.\u00a0192) that offers vivid description but lacks strong empirical trend evidence (see also Whittaker et\u00a0 al., 2021 ). Instead, they propose that the \n56 Stephanie Tom Tong\nproduction and consumption of online hate content are motivated by the \nprocess of supply and demand and are further facilitated by particular affor -\ndances of social media. Focusing on YouTube, they argue that on the supply \nside, producers are often motivated to create hateful or extremist content to make money\u00a0\u2013 the more substantial their audience, the greater their advertis -\ning revenue. The start-up cost for creating videos is relatively low, requiring minimal equipment and space. Second, on the demand side, YouTube videos \noffer a visual, multimedia experience that is easy for audiences to process\u00a0\u2013 much simpler than reading text-based news\u00a0\u2013 thus creating greater demand for easy-to-consume content. They also emphasize how affordances of You -\nTube amplify the supply and demand process. PDAs exist in the form of the \nYouTube Like that functions as a (private) way for users to indicate their preferences. These data are filtered by the recommender algorithm that sug -\ngests content for users made by the \u201csame creator or milieu of content crea -\ntors\u201d (p.\u00a0192). Another affordance is interactive commenting through which \nusers can not only discuss a particular video but also find a sense of com -\nmunity with others who share their extremist perspectives or hateful views.\nThus, recommender algorithms are not solely responsible for the problem \nof increasing polarization and radicalization of the online public. Person-alization is often a two-way street involving a user who self-selects certain content and the system that then preselects content for the user based on their data. Whittaker et\u00a0al. (2021) argue that few academics, critics, or political \nleaders note the nuance of this relationship, noting that past studies \u201chave frequently posited a causative relationship between online echo chambers and radicalization\u00a0\u2013 with little empirical evidence\u00a0\u2013 and they are rarely clear as to whether they refer to users\u2019 own choices or the effects of algorithms\u201d (p.\u00a05). This combination of quick supply, easy consumption, increasing demand, PDAs, recommender algorithms, comment exchange, and online community demonstrates how platforms like YouTube can motivate and facilitate the production, consumption, and amplification of online hate.\nThis review summarizes how the flexible nature of various online cues and \nfeatures afford not only the spread of hateful ideology but also the sharing of social and relational information that can strengthen bonds among members of larger hate groups. The hateful communication facilitated by these fea-tures and affordances also create harmful effects that spill over into targets\u2019 \nlives\u00a0\u2013 both online and offline.\nThe Effects of Online Hate: Individuals, Bystanders, and Civic Life\nJust as researchers have examined different patterns of online hate (e.g., one-on-one, many-to-one, and intergroup; public and private), similar attempts have been made to distinguish its effects on individual targets, audi -\nences of social media bystanders, and larger consequences on civic and social \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  57\nlife. We review each of these areas below and then expand on the potential \nsolutions that have been proposed by targets of hate, advocates and activists, and social media platforms themselves, as ways to curb, control, and remedy the harms of online hate.\nIndividual Victims and Targets: Effects and Preferred Remedies\nResearchers examining the deleterious effects of online hate have primarily focused on the effects reported by individual victims, what Woods and Ruscher \n(2021) call consequential harms \u201cthat occur as a result of hate speech\u201d that \n\u201chave historically received more empirical investigation\u201d (p.\u00a0 273). Com -\nmonly reported consequential harms toward victims\u2019 mental and emotional \nstates include increases in anxiety, anger, depression, fear, stress, sadness, and shame (e.g., Keighley, 2022). Less attention has been paid to physical health outcomes, such as trouble sleeping and concentrating on everyday activities, though they do occur (ADL, 2022). Such consequential harms are so fre -\nquently reported that mental health professionals have described the effects of online hate as a public health crisis, most often experienced by members of particularly vulnerable communities (Cramer et\u00a0al., 2020).\nResearchers have also documented less obvious effects of online hate that \nreverberate in targets\u2019 offline lives. Interference in offline behaviors, such as increased social isolation, can occur when victims internalize the hate as \na form of self-blame for being targeted in the first place ( Hubbard, 2020). \nIncreased relational problems with their family and friends can occur after \ndirect experiences with online hate, or problems at work may increase. For many people, part of the job application process includes employers screen -\ning applicants\u2019 online presence using social media and Google search, and the wide-ranging effects of hate-based harassment on an individual\u2019s reputation \nmay cost them new job offers or opportunities for career advancement ( Jane, \n2020). For example, Citron (2014) cites cases of female school teachers who have been fired after nude photos of them were posted on revenge porn sites as a form of image-based harassment.\nJust as individual targets report substantial variation in the amount and \nseverity of online hate effects, they also report desiring different remedies \nand solutions as a response to them. Schoenebeck et\u00a0 al. (2023) surveyed \n650 Internet users and asked them to indicate what kind of remedy they most preferred in response to (hypothetically) receiving some form of online hate-based harassment. Participants were allowed to choose from six poten -\ntial solutions; results indicated that banning a perpetrator from the social media platform where the harassment took place was most preferred, fol -\nlowed by removing the hate content , public listing (adding the perpetrator to \nan online public list of offenders), payment (paying the target or people who \nsupport the target), requiring public apology , and flagging the hate content \n58 Stephanie Tom Tong\nas inappropriate (p.\u00a05). Results also indicated that preferences varied as a \nfunction of the kind of hate the proposed solution was intended to remedy: Generally (and perhaps paradoxically), people reported lower preferences for any kind of remedy in response to those forms of hate-based harassment perceived to produce the greatest amounts of harm, including sharing sexual photos and doxxing.\nOnline Bystanders\nGiven the potential broadcast nature of online hate, while perpetrators may attack one specific victim or target a larger group with a hateful message, meme, or image, there is often a large public audience of online bystand-\ners or observers who may see that content, as well. As noted above, many bystanders report inadvertently encountering\u00a0\u2013 versus intentionally seeking out\u00a0\u2013 instances of hate online, but even unintentional exposure can negatively impact bystanders\u2019 mental and emotional state ( Bedrosova et\u00a0al., 2023). As \nBenesch (2023) notes, the cumulative nature of repeated exposure to hate produces differential effects among bystanders. There is work examining passive effects on bystanders, such as withdrawing from online interaction (Barnidge et\u00a0al., 2019) or becoming apathetic or desensitized to hate-fueled content (Schmid et\u00a0 al., 2022 ). In some cases, however, research points to \nactive responses, with repeated exposures to online hate sometimes motivat-ing bystanders to become active perpetrators of hate themselves (see Walther, \nthis volume) or engage in defensive counter-speech or social support of tar -\ngeted individuals and groups.\nPassive Effects: Observation and Passive Response\nSchmid et\u00a0al. (2022 ) denoted the difference in observers\u2019 perceptions of hate \nin social media feeds, with first-level perceptions referring to basic recogni -\ntion of online hate content and second-level perceptions referring to their \n\u201cfeelings, attitudes, and opinions regarding the content\u201d (p.\u00a04). From their qualitative interviews with 23 German social media users, they found that younger respondents were less sensitized to online hate content compared to older respondents, whose stronger first-level perceptual reaction was attrib -\nuted to their \u201clack of familiarity with hate speech on social media\u201d (p.\u00a011). In some cases, respondents reported not perceiving the nuances of posts that contained more indirect hate, such as those using humor, or those that con-tained more specific memes, language, or symbols that had coded references or meanings that they did not know. These first-level perceptual patterns, in turn, affected second-level perceptions\u00a0\u2013 those who deliberately chose to ignore or avoid hateful content, or could not discern the meanings, ended up not attending to nor having strong emotional responses to such posts.\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  59\nInterestingly, such passive first- and second-level reactions to online hate \namong social media bystanders are a frequently reported trend, but pin -\npointing their causes is difficult. Researchers often cite different reasons for \nbystander inaction, including overall desensitization to hate in social media (Schmid et\u00a0 al., 2022 ), individual differences in bystanders\u2019 apathy versus \nempathy with targets of hate, a diffused sense of personal responsibility online, reduced feelings of self-efficacy to combat hate speech, or reluctance to defend victims of hate for fear of retribution by perpetrators (see Ober -\nmaier, 2022; Rudnicki et\u00a0al., 2023). It is likely that all these factors contribute \nto bystanders\u2019 passive response to online hate, which in itself can help per -\npetuate the larger normative trends of verbal aggression, incivility, and hate present on many social media platforms (see Shmargad et\u00a0al., this volume).\nBystanders\u2019 Active Responses to Online Hate\nOne potential effect that exposure to online hate can produce is active counter-speech or counter-messages in which bystanders attempt to refute hateful content and its influence on social media audiences. Bystanders may engage in counter-speech as individuals, or as part of a larger collective. For example, the Sweden-based group, #jag\u00e4rh\u00e4r (\u201cI am here\u201d), consists of \u201cthousands of people who have made a regular practice of responding en masse to what they regard as hateful comments online\u201d as a form of collec-\ntive counter-speech (Buerger, 2020, p.\u00a02). The counter-speech process begins when a member of the volunteer collective identifies online hate content on a social media platform such as Facebook. They begin their counterre-sponse by commenting under the initial post to either correct misinforma -\ntion or criticize the hate. Other members of the collective then respond to those comments and use Facebook\u2019s PDAs to \u201clike\u201d each other\u2019s comments, thereby sociometrically pushing #jag\u00e4rh\u00e4r comments to the top. The #jag-\u00e4rh\u00e4r collective now consists of approximately 74,000 volunteer members (70% women) primarily based in Sweden, a team of 15\u201320 moderators who organize the day-to-day counter-speech campaigns and the group\u2019s Facebook presence, and six administrators who oversee the collective\u2019s larger work (Buerger, 2020). As an organized whole, #jag\u00e4rh\u00e4r represents an impressive, if unique, coordinated bystander counter-speech response to online hate that has yet to be replicated.\nIt may be surprising to learn that the bystanders who engage in \ncounter-speech do not usually intend to change the mind or behavior of perpetrators. Instead, the primary goals are to change the expectations and norms of other bystanders in the online audience and influence the aggres -\nsive rhetoric within the social media platforms ( Buerger, 2020); that is, this \napproach invokes a social process. This is similar to results from offline bystander influence, which has found individual intervention in physical \n60 Stephanie Tom Tong\nemergencies to be more likely when more bystanders are present in the situa -\ntion (see for review Lytle et\u00a0al., 2021; Nida, 2020). Some academics have also \nproposed automated counter-speech as a potential response to online hate \nin which AI-based social bots can be programmed to address perpetrators\u2019 \nhate posts with unique comments. Although some evidence suggests that automated counter-speech can persuade perpetrators to reduce their hate -\nful language at least in the short term (e.g., Munger, 2017), there are both \ntechnical and ethical issues that must be addressed before it can be a widely implemented practice on social media. Technically, how might bots be pro -\ngrammed to detect instances of online hate that use language and imagery in coded, subtle ways? Ethical challenges regarding censorship and expression in political discourse might also arise, as Cypris et\u00a0al. (2022 ) note: \u201cIf auto -\nmated counterspeech turns out to be an effective \u2018silencer\u2019 of online discus -\nsions, authoritarian regimes could exploit this technique to shift, re-frame, or subdue user discourse that they deem \u2018undesirable\u2019\u201d (p.\u00a07). While seemingly attractive, automated counter-speech remains a potential remedy rather than a current response to online hate.\nBystanders also respond to online hate through reappropriation or by \nreclaiming of the hateful hashtags, phrases, and memes coined by perpetra -\ntors to derogate targets. Cervone et\u00a0 al. (2021) summarize the philosophi-\ncal debate over varying models of hateful language reappropriation. Some adopt a polysemy perspective that describes the need for multiple people \nto recognize a slur\u2019s new meaning for it to be fully reclaimed, whereas oth -\ners offer an echoic perspective in which a slur can become separated from \nthe hate it induces, while still retaining its meaning: \u201cThus, according to a polysemy perspective, reclamation only takes place if several people use the new meaning, whereas according to the echoic perspective, small acts of reclamation are possible and can eventually lead to polysemy\u201d (p.\u00a091). The process of echoic reappropriation is further spelled out by Galinsky et\u00a0al.'s \n(2013) three-step model that begins with (1) individual\u2019s use of a slur for self-labeling\u00a0\u2013 a tactic that not only prevents outsiders from using word for derogation but also imbues it with new positive connotations and meaning; (2) self-labeling then moves to the collective level in which other members of \nthe targeted in-group begin to use the slur with its new, positive implications; and (3) in the final step, out-group members begin to acknowledge the transi -\ntion of the slur\u2019s meaning from negative to positive.\nApplying Galinsky et\u00a0 al.'s (2013 ) three-step process can help decipher \nthe ways in which meanings of hateful hashtags, memes, and images can be reclaimed by members of targeted groups who want to \u201cweaken\u201d the \u201cstigmatizing force\u201d of such content (p.\u00a02020). One illustrative example is the \u201cLet\u2019s Go Brandon\u201d meme, which was originally created as a right-wing coded slogan for \u201cFuck Joe Biden.\u201d In late summer of 2022, a small group of online Biden supporters reclaimed the meme, going so far as to create Biden\u2019s \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  61\nsuperhero online alter ego, #DarkBrandon. In the final step, #DarkBrandon \nwas fully embraced as a positive figure and was even featured in Biden\u2019s 2024 U.S. presidential campaign. As such, Let\u2019s Go Brandon reflects how echoic reappropriation can give rise to reclaimed polysemic usage and meaning.\nThough reclaiming hate memes seems like a potential path for bystand-\ners to intervene in instances of viral online hate, in her analysis of the Dark Brandon meme, Romano (2023) eloquently raises the point that by the time \nhate-fueled language, images, and phrases have \u201cmemed their way into the mainstream,\u201d the\naverage bystander is unlikely to know its original dark origins. It is doubt-ful the average internet user who picks up language like \u201csimp,\u201d \u201cChads and Beckys,\u201d \u201ccuck,\u201d \u201cnormie,\u201d \u201cwrongthink,\u201d or \u201credpilled\u201d really understands their deeply misogynistic and extremist\u00a0origins or cares that much if they do. Most of the time, this lack of a watchful attitude, if it serves anyone except the garbage-eating deities of the internet, serves the aims of the trolls and the right wing.\nDark Brandon may have been a welcome addition to Biden\u2019s 2024 cam-\npaign; however, at other times, bystanders can run into trouble when reclaim -\ning a hate meme, even if the motivation to do so is sincere: \u201cAttempting to use the memes without full context can often spread confusion instead of bringing clarity and purpose\u201d ( Romano, 2023). In such cases, the act of \nreclaiming can sometimes result in bystanders further disseminating online hate memes, which inadvertently does more harm than good.\nLike counter-speech campaigns, sometimes, bystanders\u2019 social support \nresponse to online hate can also be very well organized. Blackwell et\u00a0 al. \n(2017) interviewed members of the private Right To Be (righttobe.org) plat -\nform (formerly, HeartMob), that was launched in 2016 by Hollaback!\u00a0\u2013 a nonprofit organization dedicated to \u201cending harassment in all its forms\u201d\u00a0\u2013 which describes it as a \u201csafe space where you can share your harassment story, get support, and help others experiencing harassment.\u201d Individual targets share their stories of hate and hate-based harassment on the plat -\nform, and a team of vetted and trained bystanders then offer social support messages in response. Bystanders who participated in the Right To Be plat-form reported better understanding the problem of online hate in terms of its overall breadth, diversity, and frequency, as well as the severity of effects that hate-based harassment can have on individual targets. Offering support directly to targets was also a way for bystanders to gain a sense of agency toward combating online hate, which often feels like a vast, unsolvable prob -\nlem (Blackwell et\u00a0al., 2017).\nThe studies of collective counter-speech, reclaiming, and social support \nreviewed above offer interesting (if rare) glimpses into more organized, active \n62 Stephanie Tom Tong\nresponses to the harms that online hate can produce. Such campaigns require \ndedicated volunteer work, coordination, and sustained efforts that most aver -\nage social media bystanders are unlikely to expend. Though some work sim -\nply points to the innate empathy of active bystanders, more recent research is looking into the particular mechanisms that drive them to take action against \nhate when they encounter it online. For example, understanding bystand -\ners\u2019 emotional reactions to a specific hate post, or uncovering their expecta-\ntions about the communicative exchange of hate on social media ( Obermaier \net\u00a0al., 2021; Roden\u00a0& Saleem, 2022; Sch\u00e4fer et\u00a0al., 2023; Tong\u00a0& DeAndrea, \n2023), may provide more insight into the motivations of those particular bystanders who offer smaller but consistent, defensive actions against online hate. Though research points to a myriad of responses to online hate among bystanders, the primary response among most tends to be one of deliberate passivity.\nBig Tech Effects: Accountability, Methods of Moderation, and \nPlatform Governance Practices\nAccountability, Regulation, and Moderation\nOne particular effect of the ongoing problem of online hate, incivility, and \naggression is increasing public concern that social media companies are not doing enough to address it and its associated harms. A\u00a0recent Pew Research poll (Vogels, 2021) found that approximately 80% of Americans feel that Big Tech companies like Meta, Twitter, and Google \u201care doing an only fair to poor job\u201d attending to the harassment and hate that occur on their platforms (and after Twitter became X in 2023, things are even worse; Barrie, 2023). \nMany individual users, as well as U.S. politicians, have called for greater accountability among social media companies that have been shielded by legal policies, mainly Section\u00a0 230 of the United States\u2019 Communications Decency Act (CDA). Initially passed in 1996, Section\u00a0230 allows companies to moderate and govern their platforms, or not to, but it protects them from being liable for user-created content (which is itself protected by the First Amendment for free speech). Though Section\u00a0230 has enabled an open Inter -\nnet and facilitated the growth of contemporary social media, many argue that it has also allowed online hate to flourish, creating a double-edged sword for modern-day communication freedoms (see for review, Wakabayashi, 2020).\nOne impetus for the CDA\u2019s development was to give companies the freedom \nto develop their own rules and processes for platform governance: Examples include Google\u2019s implementation of the European Union\u2019s General Data Pro-tection Regulation or the Right to be Forgotten. Users can request, via web-form, that content be \u201cdelisted\u201d or removed from the search engine ( Google, \nn.d.). A\u00a0panel of reviewers manually examines the details and weighs \u201cthe \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  63\nrights of the individual and the public\u2019s interest in the content\u201d before decid -\ning whether to de-list the requested content. Other examples include Twitch\u2019s \nSafety Advisory Council formed in May 2020, designed to develop \u201cnew products and features to improve safety and moderation\u201d ( Twitch, n.d.). \nSuch attempts, though novel, seem difficult for Big Tech companies to imple -\nment effectively to combat the amount of problematic hate content on their platforms.\nAt present, most mainstream social media companies rely on principles \nof normative regulation in which they establish terms and conditions of use \nthat they then require users to abide by or risk various sanctions (Schoen-ebeck\u00a0& Blackwell, 2021). But such terms are notoriously vague and difficult to enforce and require much content moderation, which is in itself hard to perform effectively and often comes at great cost to the human moderators responsible for implementing it (see Sch\u00f6pke-Gonzalez et\u00a0al., 2022; Spence \net\u00a0al., 2023).\nBig Tech companies have proposed various moderation techniques that \ninvolve identifying and then deleting hate speech. Companies have embraced both human-based and automated detection methods, neither of which seem to have provided satisfying or effective ways to address the problem of curb -\ning hateful online content. There are real inefficiencies and ethical issues with requiring human moderators to view questionable content and make judg -\nments about its public harms; just as there are ongoing public, academic, and political debates about the transparency and overreach of artificial intel -\nligence algorithms being developed by Big Tech companies for the purposes of surveillance, as well as the accuracy of these algorithms to correctly dis -\ntinguish innocuous user-generated content from hate speech on social media (see commentary by Gillespie, 2020; Gillespie et\u00a0al., 2020 ; Schoenebeck\u00a0& \nBlackwell, 2021). Such debates highlight the intersections of the human and the technical, and the \u201cgray area\u201d of public opinion and individual judgments regarding offensive versus truly hateful content. However, there are clear-cut cases of users who routinely and deliberately disseminate hate on mainstream social media that Big Tech companies have been required to address, such as through deplatforming.\nThe Curious Case of Deplatforming\nA common approach that social media companies rely on to deal with par -\nticularly problematic users includes account suspension and deplatforming\u00a0\u2013 \nalso known as strategic network disruptions\u00a0\u2013 in which \u201cidentifiable \u2018core\u2019 members of a hate-based organization are removed from the platform all at once, eliminating the online leadership of the organization\u201d ( Thomas\u00a0& \nWahedi, 2023, p.\u00a0 1). By deplatforming leaders, social media companies like Meta and Google hope to disrupt hate groups\u2019 structures and sense of \n64 Stephanie Tom Tong\ncollective identity, which should in turn affect the amount of hateful content \nthat emerges from the groups\u2019 membership. This represents a sort of reversal of the social process of online hate.\nThough theoretically, the idea of deplatforming seems a promising way \nto address with online hate, in practice, its effectiveness is a hotly debated topic in ongoing scholarship. Some researchers point to the positive \u201ccausal effects\u201d of deplatforming hate group leaders on a platform\u2019s overall \u201chealth\u201d as reducing the amount of production and circulation of hate content, decreased group engagement among remaining members, and the reduced likelihood of those remaining members reconstituting the group\u2019s organiza-tion and structure (Thomas\u00a0& Wahedi, 2023). While this evidence suggests that deplatforming might help individual social media sites rid themselves of harmful content, other studies suggest that banned users simply migrate to other fringe platforms and are also motivated to spew even more toxic con -\ntent as a result (e.g., Ribeiro et\u00a0al., 2023). Other studies suggest that although banning or quarantining hateful content shared on platforms like Reddit might decrease hate activity initially, such efforts are ultimately responsible for a stronger \u201clong-term increase in toxicity,\u201d especially among the core leaders of hate groups (Trujillo\u00a0& Cresci, 2022).\nConclusions\nThe sprawling, multidisciplinary scope of online hate research published in recent years highlights the growing need for academic researchers to begin providing more detailed and deliberate organization of the various topical foci they investigate. The lack of conceptual definitions and organizational clarity can also lead to poor operationalization and measurement, inaccurate comparisons, or imprecise estimates of the prevalence and effects of each kind of online hate. This chapter offers a relational taxonomy as one heu -\nristic framework to categorize and define the differences among one-on-one/hate-based harassment, many-to-one, and many-to-many forms of online \nhate. The basis for each category is the relationship (or lack thereof) between perpetrators and targets and the channels used to disseminate hate messages, as a means of differentiating and classifying various acts of online hate.\nAnother advantage this taxonomy provides is the ability to delineate the \neffects that acts of online hate have at various levels\u00a0\u2013 on individuals, targeted groups or group-level identities, social systems, and civic discourse. Notably, with this taxonomy, acts of online hate may begin at one level and then transition into others over time and involve use of private and public chan -\nnels, such as Gamergate, or sometimes emerge simultaneously at different levels, such as the many-to-one attacks on Vice President Kamala Harris that also function as many-to-many intergroup (e.g., bipartisan) hatred. Examin -\ning and organizing the relational and communicative specifics of online hate \nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  65\nmight offer more nuance to current broad or general operational definitions \noften reflected in survey measurement. For example, researchers might be able to pinpoint differences in targets\u2019 \u201cdirect experience\u201d with one-on-one/private online harassment versus repeated \u201cexposure\u201d to many-to-one/public intergroup messages to see which are more extreme or problematic. Cross-category comparisons become applicable as well: Are bystanders more affected by observing coordinated, many-to-one hate-based campaigns against a particular target (or set of targets) versus the (pseudo)anonymous, many-to-many, intergroup kinds of ad hominem hate that is so common \non mainstream social media? Future work might also consider which affor -\ndances are most applicable in facilitating certain kinds of hate and effects at various levels as well as potential techniques that are used to combat those effects\u00a0 \u2013 among individual user and at larger group levels. Such compari -\nsons can only be made if we can clearly differentiate among various kinds of online hate and their associated effects.\nReferences\n4chan. (n.d.). Press. https://www.4chan.org/press\nADL. (2022). Online hate and harassment: The American experience 2022 . https://www.\nadl.org/resources/report/online-hate-and-harassment-american-experience-2022\nAmnesty International UK. (2017, November 20). More than a quarter of UK women \nexperiencing online abuse and harassment receive threats of physical or sexual assault\u00a0 \u2013 new research. https://www.amnesty.org.uk/press-releases/morequarter- \nuk-women-experiencing-online-abuse-and-harassment-receive-threats\nAnti-Defamation League (2018, September 20). New hate and old: The chang-\ning face of American White supremacy. https://www.adl.org/resources/report/new-hate-and-old-changing-face-american-white-supremacy\nBallard, M. E.,\u00a0& Welch, K. M. (2017).  Virtual warfare: Cyberbullying and cyber-  \nvictimization in MMOG play.\u00a0 Games and Culture,\u00a0 12(5), 466\u2013491. https://doi.org/  \n10.1177/1555412015592473\nBarnidge, M., Kim, B., Sherrill, L. A., Luknar, \u017d.,\u00a0 & Zhang, J. (2019).  Perceived \nexposure to and avoidance of hate speech in various communication settings.\u00a0 Tele-\nmatics and Informatics,\u00a044, 101263. https://doi.org/10.1016/j.tele.2019.101263\nBarrie, C. (2023, August 29). Did the Musk takeover increase contentious actors on \nTwitter? Harvard Kennedy School Misinformation Review, 4(4). https://doi.org/ \n10.37016/mr-2020-122\nBarth, N., Wagner, E., Raab, P.,\u00a0 & Wieg\u00e4rtner, B. (2023).  Contextures of hate: \nTowards a systems theory of hate communication on social media platforms.\u00a0 The \nCommunication Review, 26(3), 209\u2013252. https://doi.org/10.1080/10714421.202\n3.2208513\nBedrosova, M., Mylek, V., Dedkova, L.,\u00a0& Velicu, A. (2023).  Who is searching for \ncyberhate? Adolescents\u2019 characteristics associated with intentional or uninten-tional exposure to cyberhate.\u00a0 Cyberpsychology, Behavior, and Social Networking , \n26(7), 462\u2013471. https://doi.org/10.1089/cyber.2022.0201\nBenesch, S. (2023). Dangerous speech. In C. Strippel, S. Paasch-Colberg, M. \nEmmer,\u00a0& J. Trebbe (Eds.), Challenges and perspectives of hate speech research  \n(pp.\u00a0185\u2013197). Social Science Open Access Repository. https://doi.org/10.48541/\ndcr.v12.11\n66 Stephanie Tom Tong\nBeres, N. A., Frommel, J., Reid, E., Mandryk, R. L.,\u00a0& Klarkowski, M. (2021, May).  \nDon\u2019t you know that you\u2019re toxic: Normalization of toxicity in online gaming. \nIn\u00a0Proceedings of the 2021 CHI conference on human factors in computing sys -\ntems\u00a0(pp.\u00a01\u201315). ACM.\nBlackwell, L., Dimond, J., Schoenebeck, S.,\u00a0 & Lampe, C. (2017).  Classification \nand its consequences for online harassment: Design insights from Heartmob. In  \nK. Karahalios, G. Fitzpatrick,\u00a0& A. Monroy-Hern\u00e1ndez (Eds.), Proceedings of the \nACM on human-computer interaction: Vol. 1 (CSCW)  (pp.\u00a01\u201319). ACM. https://\ndoi.org/10.1145/3134659\nBlackwell, L., Ellison, N., Elliott-Deflo, N.,\u00a0& Schwartz, R. (2019, March).  Harass-\nment in social VR: Implications for design. In\u00a0 2019 IEEE conference on virtual \nreality and 3D user interfaces (VR) \u00a0(pp.\u00a0854\u2013855). IEEE. https://doi.org/10.1109/\nVR.2019.8798165\nBliuc, A. M., Faulkner, N., Jakubowicz, A.,\u00a0& McGarty, C. (2018). Online networks \nof racial hate: A\u00a0systematic review of 10 years of research on cyber-racism. Com-\nputers in Human Behavior, 87, 75\u201386. https://doi.org/10.1016/j.chb.2018.05.026\nBrown, A. (2018). What is so special about online (as compared to offline) hate \nspeech?\u00a0Ethnicities,\u00a018(3), 297\u2013326. https://doi.org/10.1177/1468796817709846\nBuerger, C. (2020, December 14). The anti-hate brigade: How a group of thousands \nresponds collectively to online vitriol. Dangerous Speech Project. https://danger -\nousspeech.org/anti-hate-brigade/\nCervone, C., Augoustinos, M.,\u00a0& Maass, A. (2021).  The language of derogation and \nhate: Functions, consequences, and reappropriation.\u00a0 Journal of Language and \nSocial Psychology,\u00a040(1), 80\u2013101. https://doi.org/10.1177/0261927X20967394\nChan, T. K., Cheung, C. M., Benbasat, I., Xiao, B.,\u00a0& Lee, Z. W. (2022).  Bystand-\ners join in cyberbullying on social networking sites: The deindividuation and moral disengagement perspectives.\u00a0 Information Systems Research . https://doi.\norg/10.1287/isre.2022.1161\nCitron, D. K. (2014, January 16). \u201cRevenge porn\u201d should be a crime in U.S. CNN. \nhttp://edition.cnn.com/2013/08/29/opinion/citron-revenge-porn\nCostello, M., Hawdon, J., Bernatzky, C.,\u00a0& Mendes, K. (2019). Social group identity \nand perceptions of online hate.\u00a0 Sociological Inquiry,\u00a0 89(3), 427\u2013452. https://doi.\norg/10.1111/soin.12274\nCostello, M., Hawdon, J.,\u00a0& Ratliff, T. N. (2017).  Confronting online extremism: \nThe effect of self-help, collective efficacy, and guardianship on being a target for hate speech. Social Science Computer Review, 35(5), 587\u2013605. https://doi.\norg/10.1177/0894439316666272\nCramer, R. J., Fording, R. C., Gerstenfeld, P., Kehn, A., Marsden, J., Deitle, C., King, \nA., Smart, S.,\u00a0& Nobles, M. R. (2020, November 9). Hate-motivated behavior: Impacts, risk factors, and interventions. Health Affairs Journal Health Policy Brief, 9, 1\u20136.\nCypris, N. F., Engelmann, S., Sasse, J., Grossklags, J.,\u00a0& Baumert, A. (2022).  Inter -\nvening against online hate speech: A\u00a0 case for automated counterspeech.\u00a0 IEAI \nResearch Brief, 1\u20138.\nDeKeseredy, W. S. (Chapter\u00a04 this volume). Misogyny and woman abuse in the ince-\nlosphere: The role of online incel male peer support.\nDewey, C. (2014, October 14).  The only guide to Gamergate you will ever need to \nread. The Washington Post. https://www.washingtonpost.com/news/the-intersect/\nwp/2014/10/14/the-only-guide-to-gamergate-you-will-ever-need-to-read/\nDibbell, J. (1993, December 21).  A\u00a0rape in cyberspace. The Village Voice. https://\nwww.juliandibbell.com/texts/bungle_vv.html\nEvolvi, G. (2019).  # Islamexit: Inter-group antagonism on Twitter.\u00a0 Information, \nCommunication\u00a0& Society,\u00a0\n22(3), 386\u2013401. https://doi.org/10.1080/1369118X. \n2017.1388427\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  67\nFinkel, E. J.,\u00a0& Eckhardt, C. I. (2013).  Intimate partner violence.\u00a0In J. A. Simpson\u00a0& \nL. Campbell (Eds.), The Oxford handbook of close relationships (pp.\u00a0452\u2013474). \nOxford University Press. https://doi.org/10.1093/oxfordhb/9780195398694.  \n001.0001\nFlynn, A., Powell, A., Scott, A. J.,\u00a0& Cama, E. (2022). Deepfakes and digitally altered \nimagery abuse: A\u00a0cross-country exploration of an emerging form of image-based sexual abuse.\u00a0The British Journal of Criminology,\u00a062(6), 1341\u20131358.\nForestal, J. (2021). Beyond gatekeeping: Propaganda, democracy, and the organi -\nzation of digital publics. The Journal of Politics , 83(1), 306\u2013320. https://doi.\norg/10.1086/709300\nFox, J. (2023).  Online social aggression: Harassment and discrimination. In R. \nNabi\u00a0& J. G. Myrick (Eds.), Emotions in the digital world  (pp.\u00a0193\u2013214). Oxford \nUniversity Press. https://doi.org/10.1093/oso/9780197520536.003.0011\nFreeman, G.,\u00a0& Acena, D. (2021, June).  Hugging from a distance: Building inter -\npersonal relationships in social virtual reality. In\u00a0 ACM international con -\nference on interactive media experiences \u00a0 (pp.\u00a0 84\u201395). ACM. https://doi.\norg/10.1145/3452918.3458805\nFuchs, T.,\u00a0& Sch\u00e4fer, F. (2021, October).  Normalizing misogyny: Hate speech and ver -\nbal abuse of female politicians on Japanese Twitter. Japan Forum,\u00a0 33(4), 553\u2013579. \nhttps://doi.org/10.1080/09555803.2019.1687564\nGalinsky, A. D., Wang, C. S., Whitson, J. A., Anicich, E. M., Hugenberg, K.,\u00a0 & \nBodenhausen, G. V. (2013). The reappropriation of stigmatizing labels: The recip -\nrocal relationship between power and self-labeling. Psychological Science, 24(10), \n2020\u20132029. https://doi.org/10.1177/0956797613482943\nGaudette, T., Scrivens, R., Davies, G.,\u00a0& Frank, R. (2020).  Upvoting extremism: Col -\nlective identity formation and the extreme right on Reddit. New Media\u00a0& Society, \n23(12), 3491\u20133508. https://doi.org/10.1177/1461444820958123\nGillespie, T. (2020).  Content moderation, AI, and the question of scale.\u00a0 Big Data\u00a0& \nSociety,\u00a07(2), 2053951720943234.\nGillespie, T., Aufderheide, P., Carmi, E., Gerrard, Y., Gorwa, R., Matamoros-Fern\u00e1ndez, \nA., Roberts, S. T., Sinnreich, A.,\u00a0& Myers West, S. (2020).  Expanding the debate \nabout content moderation: Scholarly research agendas for the coming policy debates. Internet Policy Review, 9(4). https://doi.org/10.14763/2020.4.1512\nGoel, V., Sahnan, D., Dutta, S., Bandhakavi, A.,\u00a0& Chakraborty, T. (2023).  Hate-\nmongers ride on echo chambers to escalate hate speech diffusion. PNAS Nexus, \n2(3), 1\u201310. https://doi.org/10.1093/pnasnexus/pgad041\nGoogle. (n.d.). Requests to delist content under European privacy law . https://trans \nparencyreport.google.com/eu-privacy/overview?hl=en\nHassan, G., Rabah, J., Madriaza, P., Brouillette-Alarie, S., Borokhovski, E., Pickup, \nD., Varela, W., Girard, M., Durocher-Corfa, L.,\u00a0 & Danis, E. (2022).  PROTO-\nCOL: Hate online and in traditional media: A\u00a0systematic review of the evidence for associations or impacts on individuals, audiences, and communities.\u00a0 Campbell \nSystematic Reviews,\u00a018(2), e1245. https://doi.org/10.1002/cl2.1245\nHayes, R. A., Carr, C. T.,\u00a0& Wohn, D. Y. (2016).  One click, many meanings: Interpreting \nparalinguistic digital affordances in social media. Journal of Broadcasting\u00a0& Elec-tronic Media, 60(1), 171\u2013187. https://doi.org/10.1080/08838151.2015.1127248\nHerring, S., Job-Sluder, K., Scheckler, R.,\u00a0& Barab, S. (2002).  Searching for safety \nonline: Managing \u201ctrolling\u201d in a feminist forum. The Information Society , 18\n(5), \n371\u2013384. https://doi.org/10.1080/01972240290108186\nHine, G., Onaolapo, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, R.,  \nStringhini, G.,\u00a0& Blackburn, J. (2017, May).  Kek, cucks, and god emperor trump: \nA\u00a0measurement study of 4chan\u2019s politically incorrect forum and its effects on the web. Proceedings of the International AAAI Conference on Web and Social Media , \n11(1), 92\u2013101. AAAI. https://doi.org/10.1609/icwsm.v11i1.14893\n68 Stephanie Tom Tong\nHubbard, L. (2020, June).  Online hate crime report 2020. Galop. https://galop.org.\nuk/resource/online-hate-crime-report-2020/\nJane, E. A. (2020).  Online abuse and harassment.\u00a0In K. Ross, I. Bachmann, V. Cardo, S. \nMoorti,\u00a0& C. M. Scarcelli (Eds.), The international encyclopedia of gender, media, \nand communication (Vol. 116). https://doi.org/10.1002/9781119429128.iegmc080\nJasser, G., McSwiney, J., Pertwee, E.,\u00a0& Zannettou, S. (2023). \u2018Welcome to# GabFam\u2019: \nFar-right virtual community on Gab. New Media\u00a0& Society, 25(7), 1728\u20131745. \nhttps://doi.org/10.1177/14614448211024\nKeighley, R. (2022). Hate hurts: Exploring the impact of online hate on LGBTQ+ \nyoung people.\u00a0 Women\u00a0& Criminal Justice ,\u00a032(1\u20132), 29\u201348. https://doi.org/10.108\n0/08974454.2021.1988034\nKenski, K., Coe, K.,\u00a0& Rains, S. A. (2020).  Perceptions of uncivil discourse online: An \nexamination of types and predictors.\u00a0Communication Research,\u00a047(6), 795\u2013814.\nLee, B. Y. (2020, June 24).  Trump once again calls COVID-19 coronavirus the  \n\u201ckung flu\u201d. Forbes. https://www.forbes.com/sites/brucelee/2020/06/24/trump-once-  \nagain-calls-covid-19-coronavirus-the-kung-flu/?sh=49eec66a1f59\nLee, C. S. (2022).  Analyzing Zoombombing as a new communication tool of cyber -\nhate in the COVID-19 era.\u00a0Online Information Review,\u00a046(1), 147\u2013163. https://\ndoi.org/10.1108/OIR-05-2020-0203\nLewis, R., Marwick, A. E.,\u00a0& Partin, W. C. (2021).  \u201cWe dissect stupidity and respond \nto it\u201d: Response videos and networked harassment on YouTube.\u00a0 American Behav-\nioral Scientist,\u00a065(5), 735\u2013756.\u00a0https://doi.org/10.1177/0002764221989781\nLingiardi, V., Carone, N., Semeraro, G., Musto, C., D\u2019Amico, M.,\u00a0 & Brena, S. \n(2020). Mapping Twitter hate speech towards social and sexual minorities: A\u00a0lexicon-based approach to semantic content analysis.\u00a0 Behaviour\u00a0& Information \nTechnology,\u00a039(7), 711\u2013721. https://doi.org/10.1080/0144929X.2019.1607903\nLupu, Y., Sear, R., Vel\u00e1squez, N., Leahy, R., Restrepo, N. J., Goldberg, B.,\u00a0& John -\nson, N. F. (2023). Offline events and online hate. PLoS One, 18(1), e0278511.\nLytle, R. D.,\u00a0 Bratton, T. M.,\u00a0 & Hudson, H. K.\u00a0 (2021).  Bystander apathy and \nintervention in the era of social media. In J. Bailey, A. Flynn,\u00a0 & N. Henry (Eds.)\u00a0 The emerald international handbook of technology-facilitated vio -\nlence and abuse (pp.\u00a0 711\u2013728). Emerald Publishing Limited.\u00a0 https://doi.\norg/10.1108/978-1-83982-848-520211052\nMarwick, A. E. (2021).  Morally motivated networked harassment as normative reinforce -\nment. Social Media + Society, 7(2). https://doi.org/10.1177/20563051211021378\nMassanari, A. (2017). #Gamergate and the fappening: How Reddit\u2019s algorithm, gov -\nernance, and culture support toxic technocultures.\u00a0 New Media\u00a0& Society, 19(3), \n329\u2013346.\u00a0https://doi.org/10.1177/1461444815608807\nMatamoros-Fern\u00e1ndez, A.,\u00a0 & Farkas, J. (2021). Racism, hate speech, and social \nmedia: A\u00a0systematic review and critique.\u00a0 Television\u00a0& New Media ,\u00a022(2), 205\u2013224. \nhttps://doi.org/10.1177/1527476420982230\nMathew, B., Illendula, A., Saha, P., Sarkar, S., Goyal, P.,\u00a0 & Mukherjee, A. (2020).  Hate begets \nhate: A\u00a0temporal study of hate speech.\u00a0 Proceedings of the ACM on Human-Computer \nInteraction,\u00a04 , Article 92, 1\u201324. ACM. https://doi.org/10.1145/3415163\nMeyers, S. L.,\u00a0& Thompson, S. A. (2022, June 1).  Racist and violent ideas jump from \nweb\u2019s fringes to mainstream sites. The New York Times. https://www.nytimes.\ncom/2022/06/01/technology/fringe-mainstream-social-media.html\nMunger, K. (2017).  Tweetment effects on the tweeted: Experimentally reducing \nracist harassment. Political Behavior, 39, 629\u2013649. https://doi.org/10.1007/\ns11109-016-9373-5\nMunger, K.,\u00a0& Phillips, J. (2022).  Right-wing YouTube: A\u00a0supply and demand per -\nspective.\u00a0 The International Journal of Press/Politics ,\u00a027(1), 186\u2013219. https://doi.\norg/10.1177/19401612209647\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  69\nNida, S. A. (2020). Bystander apathy. In I. Johnsrude (Ed.), Oxford research \nencyclopedia of psychology. Oxford University Press. https://doi.org/10.1093/\nacrefore/9780190236557.013.808\nObermaier, M. (2022). Youth on standby? Explaining adolescent and young adult \nbystanders\u2019 intervention against online hate speech.\u00a0 New Media\u00a0 & Society . \nAdvance online publication. https://doi.org/10.1177/14614448221125417\nObermaier, M.,\u00a0& Schmuck, D. (2022).  Youths as targets: Factors of online hate speech \nvictimization among adolescents and young adults.\u00a0 Journal of Computer-Mediated \nCommunication,\u00a027(4), zmac012. https://doi.org/10.1093/jcmc/zmac012\nObermaier, M., Schmuck, D.,\u00a0& Saleem, M. (2021).  I\u2019ll be there for you? Effects of \nIslamophobic online hate speech and counter speech on Muslim in-group bystand-\ners\u2019 intention to intervene.\u00a0 New Media\u00a0& Society, 25(9), 2339\u20132358. https://doi.\norg/10.1177/14614448211017527\nOrtiz, S. M. (2019).  \u201cYou can say I\u00a0got desensitized to it\u201d: How men of color cope \nwith everyday racism in online gaming.\u00a0 Sociological Perspectives,\u00a0 62(4), 572\u2013588. \nhttps://doi.org/10.1080/01639625.2020.1722337\nPariser, E. (2011). The filter bubble: What the Internet is hiding from you. Penguin \nPress.\nPaz, M. A., Montero-D\u00edaz, J.,\u00a0& Moreno-Delgado, A. (2020).  Hate speech: A\u00a0sys -\ntematized review.\u00a0Sage Open,\u00a010(4). https://doi.org/10.1177/2158244020973022\nPhadke, S.,\u00a0& Mitra, T. (Chapter\u00a09 this volume). Inter-platform information sharing, \nroles, and information differences that exemplify social processes of online hate groups.\nPostmes, T., Spears, R.,\u00a0& Lea, M. (2002).  Intergroup differentiation in computer-  \nmediated communication: Effects of depersonalization. Group Dynamics: Theory, \nResearch, and Practice, 6(1), 3\u201316. https://doi.org/10.1037/1089-2699.6.1.3\nRea, S., Mathew, B.,\u00a0 & Kraemer, J. ( Chapter\u00a0 8 this volume). \u2018Hate parties\u2019: Net -\nworked antisemitism from the fringes to YouTube.\nReichelmann, A., Hawdon, J., Costello, M., Ryan, J., Blaya, C., Llorent, V., Oksanen, \nA., R\u00e4s\u00e4nen, P.,\u00a0& Zych, I. (2021).  Hate knows no boundaries: Online hate in six \nnations.\u00a0 Deviant Behavior,\u00a0 42(9), 1100\u20131111. https://doi.org/10.1080/01639625\n.2020.1722337\nRibeiro, M. H., Hosseinmardi, H., West, R.,\u00a0& Watts, D. J. (2023).  Deplatforming \ndid not decrease Parler users\u2019 activity on fringe social media.\u00a0 PNAS Nexus,\u00a0 2(3), \npgad035. https://doi.org/10.1093/pnasnexus/pgad035\nRice, R. E. (Chapter\u00a012 this volume). Themes, challenges, and implications of social \nprocesses of online hate.\nRieger, D., K\u00fcmpel, A. S., Wich, M., Kiening, T.,\u00a0& Groh, G. (2021). Assessing the \nextent and types of hate speech in fringe communities: A\u00a0case study of alt-right communities on 8chan, 4chan, and Reddit.\u00a0 Social Media + Society ,\u00a07(4). https://\ndoi.org/10.1177/20563051211052906\nRoden, J.,\u00a0& Saleem, M. (2022). White apathy and allyship in uncivil racial social \nmedia comments.\u00a0 Mass Communication and Society ,\u00a025(3), 383\u2013406. https://doi.\norg/10.1080/15205436.2021.1955933\nRogers, R. (2018). Otherwise engaged: Social media from vanity metrics to critical \nanalytics. International Journal of Communication, 12, 450\u2013472. https://ijoc.org/\nindex.php/ijoc/article/view/6407/2248\nRogers, R. (2020).  Deplatforming: Following extreme Internet celebrities to Tel -\negram and alternative social media.\u00a0 European Journal of Communication,\u00a0\n35(3), \n213\u2013229. https://doi.org/10.1177/0267323120922066\nRomano, A. (2023, May 1). \u201cThe \u2018Dark Brandon\u2019 meme\u00a0\u2013 and why the Biden cam-\npaign has embraced it\u00a0\u2013 explained. Vox. https://www.vox.com/culture/23300286/\nbiden-dark-brandon-meme-maga-why-confusing-explained\n70 Stephanie Tom Tong\nR\u00f6sner, L.,\u00a0& Kr\u00e4mer, N. C. (2016).  Verbal venting in the social web: Effects of ano -\nnymity and group norms on aggressive language use in online comments.\u00a0 Social \nMedia + Society,\u00a02(3), https://doi.org/10.1177/2056305116664220\nRudnicki, K., Vandebosch, H., Vou\u00e9, P.,\u00a0& Poels, K. (2023). Systematic review of \ndeterminants and consequences of bystander interventions in online hate and \ncyberbullying among adults. Behaviour\u00a0 & Information Technology, 42(5), \n527\u2013544. https://doi.org/10.1080/0144929X.2022.2027013\nSalminen, J., Seng\u00fcn, S., Corporan, J., Jung, S. G.,\u00a0& Jansen, B. J. (2020).  Topic-driven \ntoxicity: Exploring the relationship between online toxicity and news topics. PLoS \nOne, 15(2), e0228723. https://doi.org/10.1371/journal.pone.0228723\nSch\u00e4fer, S., Rebasso, I., Boyer, M. M.,\u00a0& Planitzer, A. M. (2023).  Can we counter -\nact hate? Effects of online hate speech and counter speech on the perception of social groups. Communication Research . Advance online publication. https://doi.\norg/10.1177/00936502231201091\nSchmid, U. K., K\u00fcmpel, A. S.,\u00a0 & Rieger, D. (2022).  How social media users per -\nceive different forms of online hate speech: A\u00a0qualitative multi-method study. New \nMedia\u00a0& Society. https://doi.org/10.1177/14614448221091185\nSchoenebeck, S.,\u00a0& Blackwell, L. (2021).  Reimagining social media governance: Harm, \naccountability, and repair.\u00a0 SSRN Electronic Journal. https://doi.org/10.2139/\nssrn.3895779\nSchoenebeck, S., Lampe, C.,\u00a0 & Tri\u1ec7u, P. (2023). Online harassment: Assessing harms and \nremedies.\u00a0 Social Media + Society ,\u00a09(1). https://doi.org/10.1177/2056305123115729\nSch\u00f6pke-Gonzalez, A. M., Atreja, S., Shin, H. N., Ahmed, N.,\u00a0 & Hemphill, L. \n(2022). Why do volunteer content moderators quit? Burnout, conflict, and harm -\nful behaviors. New Media\u00a0 & Society.  Advance online publication. https://doi.\norg/10.1177/14614448221138529\nSchulenberg, K., Freeman, G., Li, L.,\u00a0& Barwulor, C. (2023). \u201cCreepy towards my \navatar body, creepy towards my body\u201d: How women experience and manage har -\nassment risks in social virtual reality. In Proceedings of the ACM on human com -\nputer interaction (PACM HCI), CSCW 23. ACM. https://guof.people.clemson.edu/papers/cscw23women.pdf\nScrivens, R., Osuna, A. I., Chermak, S. M., Whitney, M. A.,\u00a0& Frank, R. (2021).  \nExamining online indicators of extremism in violent right-wing extremist forums.\u00a0 Studies in Conflict\u00a0 & Terrorism , 35(6). https://doi.org/10.1080/10576\n10X.2021.1913818\nSharif, M. Z. (2018).  Islamophobia, health, and public health: A\u00a0systematic literature \nreview.\u00a0 American Journal of Public Health,\u00a0 108(6), e1\u2013e9. https://doi.org/10.2105/\nAJPH.2018.304402\nShear, M. D., Kang, C.,\u00a0& Sanger, D. E. (2023, July 21).  Pressured by Biden, A.I. \ncompanies agree to guardrails on new tools. The New York Times.  https://www.\nnytimes.com/2023/07/21/us/politics/ai-regulation-biden.html\nShmargad, Y., Coe, K., Kenski, K., Rains, S.,\u00a0& Bethard, S. ( Chapter\u00a010 this volume). \nDetecting anti-social norms in large-scale online discussions.\nSiegel, A. A. (2020).  Online hate speech. In N. Persily\u00a0& J. A. Tucker (Eds.) Social \nmedia and democracy: The state of the field, prospects for reform  (pp.\u00a056\u201388). \nOxford University Press.\nSmith, B.,\u00a0& Linden, G. (2017).  Two decades of recommender systems at Amazon.\ncom. IEEE Internet Computing, 21(3), 12\u201318. https://10.1109/MIC.2017.72\nSmith, J. J., Jayne, L.,\u00a0& Burke, R. (2022, September).  Recommender systems and \nalgorithmic hate. In J. Golbeck, F. M. Harper, V. Murdock, M. Ekstrand, B. Sha -\npira, J. Basilico, K. Lundgaard,\u00a0 & E. Oldridge (Eds.), Proceedings of the 16th \nACM conference on recommender systems\n (pp.\u00a0 592\u2013597). ACM. https://doi.\norg/10.1145/3523227.3551480\nOnline Hate Research: Foundations, Definitions,\u00a0and Directions  71\nSpence, R., Harrison, A., Bradbury, P., Bleakley, P., Martellozzo, E.,\u00a0 & DeMarco, J. \n(2023). Content moderators\u2019 strategies for coping with the stress of moderating content \nonline. Journal of Online Trust and Safety, 1(5). https://doi.org/10.54501/jots.v1i5\nStatista. (2023, April 17). Number of Gettr app downloads worldwide from \n3rd quarter 2021 to 4th quarter 2022, by region . https://www.statista.com/\nstatistics/1359898/gettr-number-of-worldwide-downloads-by-region/\nStatt, N. (2020, April 3). \u2018Zoombombing\u2019 is a federal offense that could result in imprison-\nment, prosecutors warn. The Verge. https://www.theverge.com/2020/4/3/21207260/\nzoombombing-crime-zoom-video-conference-hacking-pranks-doj-fbi\nStringhini, G.,\u00a0& Blackburn, J. ( Chapter\u00a011 this volume). Understanding the phases \nand themes of coordinated online aggression attacks.\nSuler, J. (2004). The online disinhibition effect. Cyberpsychology, Behavior,\u00a0& Social \nNetworking, 7(3), 321\u2013326. https://doi.org/10.1089/1094931041291295\nTahmasbi, F., Schild, L., Ling, C., Blackburn, J., Stringhini, G., Zhang, Y.,\u00a0& Zannettou, \nS. (2021, April). \u201cGo eat a bat, Chang!\u201d: On the emergence of Sinophobic behav-ior on web communities in the face of COVID-19. In Proceedings of the web con-\nference 2021 (pp.\u00a01122\u20131133). ACM. https://doi.org/10.1145/3442381.3450024\nTelegram. (2022, June 19).  700 million users and Telegram premium . https://tele-\ngram.org/blog/700-million-and-premium\nThomas, D. R.,\u00a0& Wahedi, L. A. (2023). Disrupting hate: The effect of deplatforming \nhate organizations on their online audience.\u00a0 Proceedings of the National Academy \nof Sciences,\u00a0120(24), e2214080120. https://doi.org/10.1073/pnas.2214080120\nThomas, K., Akhawe, D., Bailey, M., Boneh, D., Bursztein, E., Consolvo, S., Dell, \nN., Durumeric, Z., Kelley, P. G., Kumar, D., McCoy, D., Meiklejohn, S., Risten -\npart, T.,\u00a0& Stringhini, G. (2021, May).  Sok: Hate, harassment, and the chang -\ning landscape of online abuse. In\u00a0 2021 IEEE symposium on security and privacy \n(SP)\u00a0(pp.\u00a0247\u2013267). IEEE.\nTiffany, K. (2022, April 22). Doxxing means whatever you want it to. \nThe  Atlantic.  https://\nwww.theatlantic.com/technology/archive/2022/04/doxxing-meaning-libs-of-  \ntiktok/629643/\nTong, S. T. ( Chapter\u00a03 this volume). Foundations, definitions, and directions in online \nhate research.\nTong, S. T.,\u00a0& DeAndrea, D. C. (2023).  The effects of observer expectations on judg -\nments of anti-Asian hate tweets and online activism response. Social Media + Soci-ety, 9(1). https://doi.org/10.1177/2056305123115729\nTong, S. T., Stoycheff, E.,\u00a0& Mitra, R. (2022).  Racism and resilience of pandemic \nproportions: Online harassment of Asian Americans during COVID-19.\u00a0 Journal \nof Applied Communication Research ,\u00a050(6), 595\u2013612. https://doi.org/10.1080/00\n909882.2022.2141068\nTong, S. T., Van Der Heide, B., Langwell, L.,\u00a0& Walther, J. B. (2008).  Too much \nof a good thing? The relationship between number of friends and interpersonal impressions on Facebook.\u00a0 Journal of Computer-Mediated Communication,\u00a0 13(3), \n531\u2013549. https://doi.org/10.1111/j.1083-6101.2008.00409.x\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). From echo chambers to digital \ncampfires: The making of an online community of hate within Stormfront.\nTreem, J. W.,\u00a0& Leonardi, P. M. (2013).  Social media use in organizations: Exploring \nthe affordances of visibility, editability, persistence, and association.\u00a0 Annals of the \nInternational Communication Association,\u00a0 36(1), 143\u2013189. https://doi.org/10.10\n80/23808985.2013.11679130\nTrujillo, A.,\u00a0 & Cresci, S. (2022).  Make Reddit great again: Assessing community \neffects of moderation interventions on r/The_Donald. Proceedings of the ACM \non Human-Computer Interaction,\u00a0 6(CSCW2), Article 526. ACM. https://doi.\norg/10.1145/3555639\n72 Stephanie Tom Tong\nTwitch. (n.d.). Safety Advisory Council. https://safety.twitch.tv/s/article/Safety-Advisory-  \nCouncil?language=en_US\nTwitter. (2023, April). Hateful conduct. https://help.twitter.com/en/rules-and-policies/\nhateful-conduct-policy\nUdupa, S.,\u00a0& Gerold, O. L. (Chapter\u00a06 this volume). \u2018Deal\u2019 of the day: Sex, porn, and \npolitical hate on social media.\nUnited Nations. (n.d.a) Impact and prevention: Targets of online hate . www.un.org/\nen/hate-speech/impact-and-prevention/targets-of-hate\nUnited Nations. (n.d.b) Understanding hate speech . https://www.un.org/en/\nhate-speech/understanding-hate-speech/what-is-hate-speech\nUnited States Department of Justice. (n.d.) Learn about hate crimes. www.justice.gov/\nhatecrimes/learn-about-hate-crimes/chart\nVogels, E. (2021, January 13). The state of online harassment. Pew Research. https://\nwww.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/\nWakabayashi, D. (2020, May 28). Legal shield for social media is targeted by law -\nmakers. The New York Times. https://nytimes.com/2020/05/28/business/section- \n230-internet-speech.html\nWalther, J. B. (2022). Social media and online hate. Current Opinion in Psychology, \n45, 101298. https://doi.org/10.1016/j.copsyc.2021.12.010\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWalther, J. B.,\u00a0& Jang, J.-W. (2012).  Communication processes in participatory web \nsites. Journal of Computer-Mediated Communication , 18(1), 2\u201315. https://doi.\norg/10.1111/j.1083-6101.2012.01592.x\nWalther, S.,\u00a0& McCoy, A. (2021).  US extremism on Telegram.\u00a0 Perspectives on Terror -\nism,\u00a015(2), 100\u2013124. https://www.jstor.org/stable/e27007290\nWaqas, A., Salminen, J., Jung, S. G., Almerekhi, H.,\u00a0& Jansen, B. J. (2019).  Mapping \nonline hate: A\u00a0scientometric analysis on research trends and hotspots in research \non online hate.\u00a0 PLoS One,\u00a0 14(9), e0222194. https://doi.org/10.1371/journal.\npone.0222194\nWhittaker, J., Looney, S., Reed, A.,\u00a0& Votta, F. (2021).  Recommender systems and \nthe amplification of extremist content. Internet Policy Review, 10(2). https://doi.\norg/10.14763/2021.2.1565\nWilson, C., Sheridan, L.,\u00a0& Garratt-Reed, D. (2022). What is cyberstalking? A\u00a0review \nof measurements.\u00a0 Journal of Interpersonal Violence,\u00a0 37(11\u201312), NP9763\u2013NP9783. \nhttps://doi.org/10.1177/0886260520985489\nWoods, F. A.,\u00a0& Ruscher, J. B. (2021).  Viral sticks, virtual stones: Addressing anony -\nmous hate speech online.\u00a0 Patterns of Prejudice,\u00a0 55(3), 265\u2013289. https://doi.org/10\n.1080/0031322X.2021.1968586\n\u00c5kerlund, M. (2021).  Influence without metrics: Analyzing the impact of far-right \nusers in an online discussion forum. Social Media + Society , 7(2). https://doi.\norg/10.1177/20563051211008831\nDOI: 10.4324/9781003472148-4\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.There is now a voluminous body of social scientific knowledge about what \nLevin and Nolan (2017) refer to as \u201cthe violence of hate,\u201d1 one that focuses \nprimarily on face-to-face and online crimes against certain racial/ethnic and religious groups and members of the LGBTQ+ community. There is, how -\never, as Bates (2020) puts it, \u201can extremism that nobody is talking about\u201d and that is \u201cmen who hate women\u201d (p.\u00a02). She also reminds us that:\nWe do not use the word \u201cterrorism\u201d when describing a crime of mass murder committed by a white man with the explicit intention of creating terror and spreading hatred against a specific demographic group\u00a0\u2013 even though that is the definition of terrorism\u00a0\u2013 if the demographic in question is women.\u00a0.\u00a0.\u00a0. We do not call his online journey a \u201cradicalization\u201d or use the word \u201cextremism\u201d to label the online communities in which he immersed himself, though we would reach for those words in an instant when describing other, similar types of crimes, committed by other, differ -\nent types of men. We do not examine what led him to commit those acts or how he became so full of hate.\n(p.\u00a03)\nThere is a growing number of movements located in the digital world marked by extensive misogyny and male entitlement, as identified by various stud -\nies (Schwartz, 2021). One prime example is the incel movement. The hate spewed by incels predated the Internet, but this movement was splintered until the emergence of contemporary technology. The Internet now not only facilitates easy access to peaceful like-minded people, but it has also, to a 4\nMISOGYNY AND WOMAN ABUSE IN \nTHE INCELOSPHERE\nThe Role of Online Incel Male Peer Support\nWalter S. DeKeseredy\n74 Walter S. DeKeseredy\ncertain extent, created an environment that normalizes the hatred of women \nand racial/ethnic minority groups. Though the incel community is, as uncov -\nered by Bates (2020) and others, \u201cthe most violent corner of the so-called manosphere,\u201d most people have never heard of incels; thus, much more polit -\nical, scholarly, and media attention to the harms caused by them is crucial and important (p.\u00a07).\nThe main objective of this chapter is to identify how incel male peer sup -\nport contributes to in-person and digital variants of woman abuse. Male \npeer support refers to the attachments to male peers and the resources that these men provide that encourage and legitimate these gendered harms (DeKeseredy, 1988). Prior to covering empirical and theoretical social scien-tific work on the social processes associated with incel male peer support, it is first necessary to supply a brief history of the incel movement, also known as the incelosphere (Center for Countering Digital Hate, 2022).\nWhat Are Incels?\nThe term incel was originally created in the 1990s by a Canadian woman \nwho developed a website for lonely singles ( DeKeseredy\u00a0& Rennison, 2019; \nYang\u00a0 & Gillis, 2018). It now means \u201cinvoluntary celibate.\u201d Members of the incel movement are patriarchal men who assert that they cannot have sex with women but want to. An incel, according to Incels.Me,\n2 is a \u201cper -\nson who is not in a relationship nor has had sex in a significant amount of time, despite numerous attempts\u201d (p.\u00a01). Incels are also anti-feminist men who have sharp disdain for \u201cChads\u201d and \u201cStacys.\u201d Chads are, as Incels.Me describes them, \u201csexually satisfied men, charismatic, tall, good looking, confident, muscular,\u201d and \u201cStacys\u201d are stereotypically attractive women who reject incels\u2019 sexual advances (p.\u00a01). Further, the incel movement consists of what Kimmel (2017) defines as a \u201cnew breed of angry white men\u201d who are \nexperiencing aggrieved entitlement:\nIt is that sense that those benefits to which you believed yourself entitled have been snatched away from you by unseen forces larger and more pow -\nerful. You feel yourself to be the heir to a great promise, the American dream, which has turned into an impossible fantasy for the very people who were supposed to inherit it.\n(p.\u00a018, emphasis in original)\nIncels declare that: Inceldom has no relation with violence, misogyny, or illegal activities of any kind. Every once in a while, when a tragedy hap -\npens, the term incel is thrown around and we get an influx of guests. We do not advocate any illegal activity, nor do we allow it on the site.\n(Incels.Me, 2018, p.\u00a01)\nMisogyny and Woman Abuse in the Incelosphere  75\nYet, as the Center for Countering Digital Hate (2022 ) uncovered, incels and \nother online misogynistic all-male groups \u201cargue with each other, support \neach other, share ideas, promote each other\u2019s lexicon and values. In short, they are brothers-in-arms in a war against women\u201d (p.\u00a07). Also, countless online postings by incel members praise mass murderer Elliot Rodger, who is a hero and/or martyr in the incelosphere. For example, Alek Minassian, another mass murderer to be briefly discussed later in this section, ended a Facebook post before his 2018 rampage with the statement, \u201cAll hail the Supreme Gentleman Elliot Rodger\u201d (CNN U.S., 2018, p.\u00a01).\nOn May 23, 2014, in Isla Vista, California, the United States, Elliot Rodger \nmurdered a total of 6 people (2 of whom were women) and injured 13 oth -\ners before killing himself. Prior to shooting and killing the people outside a sorority house, he uploaded a video to YouTube titled \u201cElliot Rodger\u2019s \n Retribution,\u201d3 a misogynistic diatribe that includes these statements:\nGirls gave their affection and sex and love to other men, but never to me. I\u2019m 22-years-old and still a virgin. I\u2019ve never even kissed a girl. I\u2019ve been through college for two and a half years, more than that actually, and I\u2019m still a virgin. It\u2019s not fair. You girls have never been attracted to me. I\u00a0don\u2019t know why you girls aren\u2019t attracted to me, but I\u00a0will punish you all for it. It\u2019s an injustice, a crime, because I\u00a0don\u2019t know what you don\u2019t see in me. I\u2019m the perfect guy, and yet you throw yourselves at all these obnoxious men instead of me\u00a0\u2013 the supreme gentlemen. I\u00a0will punish all of you for it. If I\u00a0can\u2019t have you girls, I\u00a0will destroy you.\nYou forced me to suffer all my life, and now I\u2019ll make you suffer. I\u2019ve \nwaited a long time for this. I\u2019ll give you exactly what you deserve, all of you. All you girls who rejected me and looked down upon me and, you know, treated me like scum while you give yourselves to other men. All of you men, for living a better life than me\u00a0\u2013 all of you sexually active men, I\u00a0hate you. I\u00a0hate all of you and I\u00a0can\u2019t wait to give you exactly what you deserve: utter annihilation.\nSome of Rodger\u2019s words resemble those of many men who commit intimate \nfemicide during or after the process of separation/divorce (DeKeseredy\u00a0 & Rennison, 2019): \u201cIf I\u00a0can\u2019t have you, no one will\u201d (Polk, 2003, p.\u00a0134). Intimate femicide is the killing of females by male partners with whom they have, have had, or want to have, a sexual and/or emotional relationship (Ellis\u00a0& DeKeseredy, 1997).\nReturning to Alek Minassian, in Toronto, Ontario, Canada, on April 23, \n2018, he drove a rented van onto a curb on Young Street, south of Finch Avenue and deliberately ran down pedestrians, resulting in the worst mass murder thus far in Toronto\u2019s history (Yang\u00a0& Gillis, 2018). His attack left 10 people dead (8 of whom were women) and 16 people injured. Since then, \n76 Walter S. DeKeseredy\ndozens more have been murdered by self-proclaimed incels around the world. \nMoreover, the Center for Countering Digital Hate's (2022 ) recent study of \nthe incel forum found that its members post about rape every 29 minutes. The Center\u2019s study will also be referred to in subsequent sections of this chap -\nter, but the study does not name the incel forum it examined to \u201cavoid giving it publicity\u201d (p.\u00a06). The Center, however, claims that this forum is the largest one online.\nThe hatred of women is just one element of the incel ideology. Incels have \nstrong connections to other extreme right-wing movements such as those promoting unbridled gun ownership, homophobia, racist discourses and practices, and policies and laws aimed at ending women\u2019s control over their reproductive health (DeKeseredy, 2022). Below are some of the most popular threads located on the incel forum, which was founded in 2017 by Diego Joaquin Galante (also known as \u201cSergeant Incel\u201d) ( Nashrula, 2019) and \nstudied by the Center for Countering Digital Hate (2022):\n\u2022 American culture is centered around n*ggers.\n\u2022 Society should return to tradition.\n\u2022 I just want to go back to exploring new lands, killing enemies and raping \ncountless foids.4\n\u2022 With religion collapsing, foids celebrate the new age of globohomo, drag \nfags, pedos, and zoophiles.\n\u2022 Earth needs an extinction event.\n\u2022 I hate modern day.\n\u2022 Women, like most western governments, want to uphold the current hier -\narchy, want you to have nothing, and want you to be happy with it.\n\u2022 It\u2019s one of the Jews\u2019 tactics to control the world. And you can thank the \nJews for destroying and altering this culture into a negative connotation of its former self.\n\u2022 I think every virgin male should be granted a few guns, licenses, and \nunlimited van rentals paid for by the government.\n\u2022 The future is masculinity\u00a0\u2013 pure white masculinity. No weakness, no vul -\nnerability, no femininity, no sex. Just pure, glorious strength and might as we conquer the cosmos and enslave it to us (cited in Jgin, 2023, p.\u00a01).\nWhat types of social media are used by incels and what do they post? Turning to the first question, the Center for Countering Digital Hate (2022) examined \nthe number of links to websites from the incel forum between January 2021 and July 2022 and uncovered that links to YouTube were posted over 14,000 times, making it the most linked-to site on the platform. Reddit ranked sec -\nond with over 5,000 links; links to other popular social media networks were also frequently uploaded, with 1,149 links to Twitter and 862 to Tik -\nTok, respectively. Incel communities are also on Facebook, 4chan, and on \nMisogyny and Woman Abuse in the Incelosphere  77\nvarious sites run by incels themselves. Note, too, that the Center for Counter -\ning Digital Hate found that the United States accounted for the vast majority \n(43.8%) of web traffic to the incel forum, followed by the United Kingdom (7.5%) and Poland (4.2%). Moreover, the forum has 17,000 members and receives approximately 2.6 million visitors each month.\nWhat do incels post? The best answers to date are also provided by the \nCenter for Countering Digital Hate (2022 ), which found that the incel forum \nis a \u201cself-proclaimed heterosexual male-only forum\u201d that \u201cprohibits women and the LGBTQ+ community and non-incels from attaining membership\u201d (p.\u00a012). As has been observed in several chapters of this book, while there are clearly \u201ctargets\u201d of the hate that incels express online, the intended audi -\nence for such hate messages are not the targets they mention; it is other contributors to the hateful discussion (see, e.g., Walther, this volume). What is more,\n\u2022 Over a fifth of the posts in the forum feature misogynist, racist, antisemitic \nor anti-LGBTQ+ language, with 16% of posts featuring misogynist slurs (p.\u00a06).\n\u2022 Forum threads are mainly centered around frustration and relationships, \nand the \u201cblack pill ideology,\u201d which revolves around the core belief that the ability to establish romantic relationships is determined by appearance and therefore genetics (p.\u00a011).\nTranchese and Sugiura's (2021 ) linguistic analysis of the postings in the r/\nincels channel, or \u201cSubreddit\u201d within the Reddit social media platform, shows that there is also a strong connection between incel and mainstream pornography discourse. More specifically, these researchers found that in both discourses:\n[M]uch of the denigration of women focuses on their sexuality. Their imagery and language present women as objects who deserve and enjoy sexual abuse and submission, and sex (particularly through the penis and semen) as a weapon to inflict these and express their hate. On r/incels the fact that hatred is the motivation behind the abuse is explicit. In pornography, this motive is often covert and consequently, easier to justify.\u00a0.\u00a0.\u00a0. [T]he men in pornography are the embodiment of Chads. They have constant access to women despite hating them and treating them badly. While incels despise and envy Chads for this, for them these men (and their dominant sexuality) are the only way to obtain their revenge. What all these men have in common is the wish to see women suffer through sex, while drawing pleasure and satisfaction from it.\n(p.\u00a02728)\n78 Walter S. DeKeseredy\nIt should be mentioned in passing that violent porn is now mainstream. \nRoutine features are painful anal penetration; brutal gang rape; and men slapping, pushing, gagging, choking, and pulling women\u2019s hair while they penetrate them orally, vaginally, and anally ( Bridges et\u00a0al., 2010 ; DeKeseredy \net\u00a0al., 2023; Fritz et\u00a0al., 2020 ). Males constitute most of the perpetrators \nin porn videos, and the targets of their physical and verbal aggression are primarily female. What is more, female performers often show pleasure or respond neutrally to male aggression.\nTheorizing the Incelosphere: The Contribution of  \nMale Peer Support Theory\nMale Peer Support and the Incelosphere\nAlthough interdisciplinary research on incels is rapidly expanding, most of \nthe work done so far is descriptive and atheoretical. Even so, some lead -\ning experts in the field (e.g., Thorburn et\u00a0 al., 2023) recognize the value \nof male peer support theory . The theory was originally developed in my \nprior research (see DeKeseredy, 1988) to explain why some men, due to \ntheir attachments to patriarchal and abusive male peers, abuse women in offline contexts. The social processes associated with male peer support have received much empirical scrutiny. Today, we have a wealth of rigorous quali-tative and quantitative data supporting what Lee Bowker (1983) declared \n40 years ago:\nThis is not a subculture that is confined to a single class, religion, occupa -\ntional grouping or race. It is spread throughout all parts of society. Men are socialized by other subculture members to accept common definitions of the situation, norms, values, and beliefs about male dominance and the necessity of keeping their wives in line. These violence-supporting social relations may occur at any time and in any place.\n(pp.\u00a0135\u2013136)\nDocumented by a large sociological literature,\n5 male peer pressure that legit -\nimates the sexual objectification of women and the sexual, physical, and/or psychological abuse of them is found in male collegial and professional contact sports (DeKeseredy, 2023; DeKeseredy et\u00a0al., 2023), among African \nAmerican men in Chicago ( Wilson, 1996), among Puerto Rican drug dealers \nin East Harlem and poor African American boys in parts of St. Louis ( Bour-\ngois, 1995; Miller, 2008), on Canadian university/college campuses and their \nimmediate surroundings ( DeKeseredy\u00a0& Schwartz, 1998 ), in rural Ohio and \nKentucky (DeKeseredy, 2021; Websdale, 1998), and in rural New Zealand \nand rural South Africa (Campbell, 2000; Jewkes et\u00a0al., 2006).\nMisogyny and Woman Abuse in the Incelosphere  79\nAs uncovered by recent research on incels, sexual violence and harass -\nment in the Metaverse, and on patriarchal men\u2019s rights groups ( Center for \nCountering Digital Hate, 2022; DeKeseredy, 2022; SumOfUs, 2022), there is \nalso strong evidence of the emergence of pro-abuse male peer support groups \nin cyberspace and many men who abuse women consume electronic forms of pornography with their male friends ( DeKeseredy, 2020; DeKeseredy\u00a0& \nSchwartz, 2016).\nResearch on male peer support processes inside the incelosphere is in its \ninfancy, but based on the limited amount of empirical work done so far, we can conclude that there is a variety of sociological and social psychological processes by which male peers influence men to abuse women. Based on the writings of male peer support theorists DeKeseredy and Schwartz (2016 ), it \nappears that incels encourage, justify, and support violence against women as a means of repairing the damage done to their masculinity by Stacys and other women who fail to live up to their patriarchal standards ( Manne, \n2018). Incel male peer support influences men to \u201clash out\u201d against women they cannot control (Bourgois, 1995), and their digital communication pat -\nterns are effective ways to do so. Consider that the Center for Countering \nDigital Hate (2022) found that incel forum members frequently post about rape, and 89% of posters are supportive of such violent discussions. As Tran-chese and Sugiura (2021), discovered:\nWhat incels really hate\u00a0\u2013 and what they blame feminists for\u00a0\u2013 is women who refuse them, women who sleep with several men but say \u201cno\u201d to incels. It \nis these women who receive most online (sexualized) abuse (Lewis et\u00a0al., 2017), arguably in an attempt to control them through silencing. This generates a paradoxical situation, in which derogatory terms that refer to \u201cpromiscuous\u201d women are not being used for women who participate in sexual acts with numerous men, but for women who say \u201cno.\u201d\n(p.\u00a02723)\nThere are various types of male peer support in offline all-male patriar -\nchal cohorts, but decades of research show that the most powerful form is informational support, which is guidance and advice that influence men to abuse women. Male peer support theory sees such informational support as a motivational factor, allowing men to develop pro-abuse attitudes and behaviors as a result of the encouragement and support of other males, if not the broader culture at large ( Brubaker, 2019). However, in the case of the \nincel forum, the millions of visits to the forum greatly exceed the number of \u201cconversations,\u201d which appear to be driven by a relatively smaller number of \u201cpowerusers.\u201d For instance, the Center for Countering Digital Hate (2002) found that since January, 2021, postings were driven mainly by a \u201cdedicated core\u201d of roughly 400 such users who made nearly three-quarters of all posts.\n80 Walter S. DeKeseredy\nOnline communities with members who never come into face-to-face con -\ntact with each other but who often exchange written, audio, and visual infor -\nmation with their peers are growing every day. Currently, 76% of Internet \nusers take part in an online community ( Troiano, 2022). The incel coalition \nis a prime example, and, as noted by the Center for Countering Digital Hate \n(2022), it \u201chas developed its own intricate and extensive in-group language. Members extensively use specific terminology when interacting with each other and also employ it as a gatekeeping method that allows them to quickly identify who is welcome into the community\u201d (p.\u00a04). Such language exempli-fies informational support.\nIt is not uncommon for patriarchal male peer support networks like the \nincel community to have a small number of charismatic leaders who embody \nhegemonic masculine qualities  and offer the bulk of informational support \n(DeKeseredy, 2019; Joosse\u00a0& Willey, 2020). Hegemonic masculinity is the \ndominant form of masculinity in the United States and in many, if not most, other countries ( Connell, 1995; Katz, 2016), which is not surprising because \nmost societies around the world are patriarchal ( DeKeseredy, 2021; Ren-\nzetti, 2018). The basic components of hegemonic masculinity are: (1) Avoid all things feminine, (2) restrict emotions severely, (3) show toughness and aggression, (4) exhibit self-reliance, (5) strive for achievement and status, (6) exhibit nonrelational attitudes toward sexuality, and (7) engage in homo -\nphobia (Connell\u00a0& Messerschmidt, 2005; DeKeseredy, 2017; Levant, 1995; \nPtacek, 2023; Schwartz\u00a0& DeKeseredy, 1997 ). Masculinities studies show \nthat men are encouraged to live up to these ideals and are sanctioned for not doing so (DeKeseredy, 2019; West\u00a0& Zimmerman, 1987). Furthermore, as \nmasculinities theorist James Messerschmidt (1993) has argued, participating \nin the incel forum \u201cis a resource, when other resources are unavailable, for accomplishing masculinity\u201d (p.\u00a085).\nNot only do power users\u2019 peers publicly support the claim that sexual \nassault and other forms of abuse are legitimate means of reasserting patri-\narchy (Dragiewicz, 2008), they also serve as role models because some of them engage in lethal and nonlethal forms of violence against women who \u201cthey feel have wronged them\u201d ( Bates, 2020, p.\u00a0182). The precise number of \nincels who physically hurt women is thus far unclear, but what is known is that much of incel violence is digital and involves using image-based sexual \nabuse (sometimes referred to as revenge porn) against women they dislike, \nwho left or broke off with them, or who try to stop their misogynist activities (DeKeseredy\u00a0& Schwartz, 2016 ; Salter\u00a0& Crofts, 2015).\n6 For example, some \nstudies reviewed by Henry et\u00a0al. (2021) found that there are all-male forums that \u201cspecialize\u201d in the sharing and trading of nonconsensual photos and/or videos taken of current or former female partners.\nA more recent trend in image-based sexual abuse is, using artificial intel -\nligence, posting deepfake pornography. There is a major demand for such \nMisogyny and Woman Abuse in the Incelosphere  81\nporn as revealed by a growing number of online communities, forums, ser -\nvices, and websites (Ajder et\u00a0al., 2019). Deepfaking entails replacing the face \nof one person with another one\u2019s to make it appear that a person is featured in a porn video when they are not (Henry et\u00a0al., 2021; Okolie, 2023). Moreo-\nver, some deepfake tools are used to \u201cspit out\u201d constructed images depicting rape and child abuse because no one was hurt in the creation of such content, and thus it does not violate any laws (Hunter, 2023).\nIncel communities, of course, are not the only online male peer support sub -\ncultures. Extensive research done by DeKeseredy (2022), Dragiewicz (2008, \n2011, 2018), and others (e.g., Kimmel, 2017) show that some conservative \nmen\u2019s and fathers\u2019 rights groups encourage men to hurt their ex-partners by portraying image-based sexual abuse and physical violence as acceptable solu-tions to their problems. One should reflect, too, on the overwhelming amount of male misogynistic social media responses to actor Johnny Depp\u2019s 2022 defamation trial against his ex-wife Amber Heard. There was a concerted anti-feminist effort to ferociously mobilize against Heard, and, as Scott (2022) \nobserves, Depp\u2019s legal victory is also that of angry white men. \u201cThe rage of men whose grievances are inchoate and exhaustible found expression in a 58-year-old movie star\u2019s humiliation of his 36-year-old former wife\u201d (p.\u00a01).\nPatriarchy and Misogyny Also Matter\nHence, of the limited theoretical work done so far on all-male social networks\u2019 digital abuse of women (e.g., DeKeseredy\u00a0& Olsson, 2011; DeKeseredy\u00a0& \nSchwartz, 2016), male peer support theory seems the most promising. The data gathered to date tell us much, but there are still many unanswered ques -\ntion and new avenues to explore. As well, it is always important to keep in mind that the incelosphere is a reflection of patriarchal offline environ -\nments. The organic growth of the Internet, including its hurtful elements, has globalized access to misogynistic hate discourses in converged online and offline environments. Incel messages can be distributed to millions of people around the world in seconds due to faster means of disseminating digital media, as the Internet facilitates access for those seeking communication with like-minded patriarchal men. Online communities with members who never come into face-to-face contact with each other but who often exchange writ -\nten, audio, and visual information with their peers are growing every day. The incel coalition is a prime example.\nStill, based on their study of the connections between incels and porn, \nTranchese and Sugiura (2021) are right to direct us to the fact that while online incel communication processes reflect offline or \u201creal-world\u201d male peer support patterns and \u201cenable the exponential replication of misogyny by inventing, spreading, and reproducing techniques to attack women (online and offline), online misogyny is not a product of the technology, but a result \n82 Walter S. DeKeseredy\nof the society that shaped it\u201d (p.\u00a02729). In fact, just as racism is deeply rooted \nin the legal system, so is misogyny. Feminist legal scholar Julie Suk (2023), \nfor instance, shows:\nMisogyny is conventionally understood as woman-hatred, but it is much more, and much worse for women, than hatred. Misogyny is the set of [legal] practices that keep women down in order to keep everyone and everything else up.\u00a0 .\u00a0 .\u00a0 . Even in liberal constitutional democracies that celebrate the rule of law, enforce legal gender equality, criminalize vio -\nlence against women, and prohibit sex discrimination in the workplace and schools, the state fails persistently to investigate, punish, eradicate, and prevent violence against women, from rape to femicide to workplace sexual harassment to campus sexual assault. The law enables men, and the society designed to fulfill their vision, to benefit from keeping women down, albeit in ways that are hidden from view.\n(pp.\u00a02\u20133)\nPatriarchy, too, is an \u201cage-old structure\u201d born long before the advent of the Internet (Gilligan\u00a0 & Snider, 2018), and men have been physically, sexually, psychologically, and economically abusing women for centuries (DeKeseredy\u00a0 & Donnermeyer, 2023; Dobash\u00a0 & Dobash, 1979). Miller \n(2017) reminds us:\nPatriarchy\u00a0.\u00a0.\u00a0. as embedded in the Old and New Testaments in the Bible and in Roman legal precepts, has been a powerful organizing concept with which social order has been understood, maintained, enforced, contested, adjudicated and dreamt about over two millennia in Western history.\n(p.\u00a03)\nMen who hate women and the violence they use against women are not brand-new problems; the incelosphere exacerbates a long-standing condi -\ntion. It is, then, in this current era, \u201cpatriarchy enhancing\u00a0.\u00a0.\u00a0. and maintains or strengthens the given patriarchal order of a culture or society\u201d (Applin et\u00a0al., 2023, p.\u00a01103).\nWhat is to be Done about the Incelosphere?\nSex Robots?\nThere are a variety of courses that could be pursued to change the cultural \nand societal dynamics that promote the incel thinking and/or the online incelosphere or even approaches to redirect incels\u2019 frustration. Regarding the latter approach, one highly problematic option is to use another new technology\u00a0\u2013 sex robots\u00a0\u2013 which New York Times  columnist Ross Douthat \nMisogyny and Woman Abuse in the Incelosphere  83\n(2018) views as solutions to misogyny and related violent crimes committed \nby incels. Actually, artificially intelligent robots are highly likely to intensify male sexual violence (DeKeseredy\u00a0& Rennison, 2019). Take what happened to \u201cSamantha,\u201d a sex robot displayed at the 2017 Arts Electronic Festival in Linz, Austria. She was so savagely attacked by a group of men and \u201cbadly soiled\u201d that she had to be sent back to Barcelona for \u201crepairs and cleaning after being left so filthy and broken by the never-ending male attention\u201d ( Bar-\nrie, 2017, p.\u00a01). In other words, Samantha was gang raped. This behavior is labeled streamlining in South Africa. It is\nessentially a rape by two or more perpetrators. It is an unambiguously defiling and humiliating act, and is often a punishment, yet at the same time, it is an act that is often regarded by its perpetrators as rooted in a sense of entitlement.\n(Jewkes et\u00a0al., 2006, p.\u00a02950)\nSex robots are too new to allow for properly designed social scientific stud -\nies, but there are strong indicators that they eroticize non-consent ( Nor-\nris, 2017). For example, U.S. robotics company True Companion sells a sex robot\u00a0\u2013 \u201cRoxy\u201d\u00a0\u2013 with programmable personalities, including \u201cFrigid Farah,\u201d which allows it to resist men\u2019s sexual advances. According to Noel Sharkey, a professor of artificial intelligence at the University of Sheffield, the idea is that \u201crobots would resist your sexual advances so that you could rape them\u201d (cited in Shead, 2017, p.\u00a01). To make matters worse, there are \nnow child sex robots and sex dolls on the market, and some academics (e.g., Cheok\u00a0 & Levy, 2017 ) claim that they could provide men with legitimate \noutlets for their criminal sexual desires, thus reducing harm to women. This is especially troubling considering that incel communities promote and toler -\nate pedophilia. Truth be told, over a quarter of incel forum users have posted pedophilia keywords, and discussions of pedophilia show that 53% are sup -\nportive (Center for Countering Digital Hate, 2022).\nUnsurprisingly, sex robots also promote the sexual objectification of \nwomen. They leave men\nwith the impression that a good woman is just like their robotic sex toys; compliant, always ready to have sex and have a perfect, [in] their opinion, body.\u00a0.\u00a0.\u00a0. It teaches them that if a woman does not act like their ideal, desirable sex toy that they are not to be treated as equals to robots. As a result, the robots will be treated more humanely than women will be.\n(Kezer, 2019, p.\u00a01)\nAgain, more research is necessary, but it is fair to hypothesize that the nega -\ntive consequences of using sex robots will greatly outweigh the positive ones. For example, millions of people have grown up viewing online porn, and \n84 Walter S. DeKeseredy\nlarge numbers of them now regard violent sex in which women are humili -\nated and defiled as normal ( DeKeseredy et\u00a0al., 2023 ; Foubert, 2022). It is ter -\nrifying to think that, as Kleeman (2017 ) surmises, \u201cSimilarly, the generation \ngrowing up when sex robots are commonplace might see brutally selfish sex \nas both desirable and achievable\u201d (p.\u00a01).\nThere are much more effective and safer ways of responding to online incel \nmisogyny at the societal and cultural levels. The first step is to recognize it as a form of violent right-wing extremism, one that is strongly connected to other dangerous far-right organizations ( Bates, 2020; DeKeseredy, 2022). \nThe Canadian government has even gone so far as to categorize incel violence as terrorism, and law enforcement officials based in Canada and in the United States include incel activities in their threat assessments ( New America, 2023).\nThe second and equally important step is to develop a coalition of broader \nprogressive constituencies that prioritize gender and sexuality as well as race/ethnicity and social class in their efforts to curb hate crime. Reducing gun use and ownership, mass shootings, participation in racist and anti-immigration activities, and threats to women\u2019s access to the complete range of reproduc -\ntive rights means using resistance initiatives that connect the incelosphere to other forms of right-wing extremism ( DeKeseredy, 2022). This requires a \nmulti-pronged approach, one that must involve a dedicated effort to develop \u201ca new politics of sameness,\u201d a type of politics that recognizes that a diverse range of people, regardless of their gender, sexual identity, or race/ethnicity, are subordinated to the capitalist, patriarchal, and racist motives of neoliber -\nalism (Winlow et\u00a0al., 2019, p.\u00a043).\nProgressive coalitions called for here recognize that there is a strong associ -\nation between membership in organizations seeking to reassert male suprem -\nacy and intimate violence against women and girls ( Belew\u00a0& Gutierrez, 2021; \nDeKeseredy\u00a0& Rennison, 2019; Dhaliwal\u00a0& Kelly, 2020; Dragiewicz, 2018). \nViolence against women, in fact, is the background for a host of other harms caused/advocated by alternative right coalitions and other major social prob -\nlems that plague contemporary society (e.g., poverty) ( DeKeseredy, 2022; \nDePrince, 2022). It is also a social issue that helps to energize institutional change and helps break down boundaries across organizations, government agencies, and social sectors. Violence against women as a social issue is a cat -\nalyst for discovering new ways of working together and helping one another, and it encourages people to see how we are all affected by woman abuse and how we directly or indirectly contribute to its perpetration through our val -\nues, attitudes, and behaviors (DeKeseredy\u00a0& MacLeod, 1997).\nWell-Meaning Men\nDirectly relevant to the role of patriarchal male (in particular, online incel) peer support examined in this chapter is work that is addressing the \nMisogyny and Woman Abuse in the Incelosphere  85\nunderlying and all-too-common attitude, \u201cmen who hate men who hate \nwomen\u201d (Bates, 2020), also termed in some academic and activist circles as feminist, pro-feminist, or anti-sexist men (DeKeseredy et\u00a0al., 2017 ; Messner \net\u00a0al., 2015). Such men are involved in the ongoing process of changing them -\nselves, self-examination, and self-discovery (DeKeseredy et\u00a0al., 2017), with the ultimate goal of shedding their \u201cpatriarchal baggage\u201d (Thorne-Finch, 1992). Though constituting a relatively small but growing group, these men work individually and collectively to change other men. Depending on their time and energy, some feminist men work on the dual level of changing indi-vidual people and social institutions. Others have limited goals. Most limited of all are those who only privately support the principles of feminism and restrict their efforts to creating and maintaining egalitarian relationships. This separation of private and public attempts to eliminate patriarchy contin-ues to be one of the most central challenges for feminist men ( DeKeseredy\u00a0& \nSchwartz, 2013).\nBates (2020) recommends, and rightfully so, that feminist men\u2019s work \nshould be incorporated into mainstream education to prevent boys from becoming \u201cincels.\u201d It is, indeed, time for more male teachers, adminis -\ntrators, and athletic coaches to \u201cstep up to the plate\u201d and demonstrate some progressive leadership by offering programs on gender issues in their schools. They can also do things on a personal level ( Katz, 2006), such \nas talking to male students and faculty in assemblies, classes, at sport -\ning events, in faculty and school training, and in private conversations (DeKeseredy\u00a0& Corsianos, 2016 ). It would also be useful for school staff  \nto employ the following strategies informed by the work of Bates (2020), \nMesserschmidt (2012), Thorne-Finch (1992, pp.\u00a0236\u2013237), and Warshaw \n(1988, pp.\u00a0161\u2013164):\n\u2022 Confront students, teachers, and athletic staff who speak about violence \nagainst women and misogynistic social media in an approving manner.\n\u2022 Confront students and staff who perpetuate and legitimate rape myths.\n\u2022 Take every opportunity to speak out against misogynistic social media and \nother symptoms of gender inequality.\n\u2022 Create social media forums about the harms of misogyny and how men \nand boys can work together to curb patriarchal discourses and practices.\n\u2022 Develop school curricula that make gender, healthy relationships, and \nsexuality a core subject.\nFathers can help play a vital role in preventing young boys from joining the incel movement and thus need to do some anti-sexist work at home because their masculinity ideology is a powerful determinant of their son\u2019s expres -\nsions of masculinity (Perales et\u00a0al., 2023). It is unclear exactly how many North American men do this, but we can safely infer that most fathers are \n86 Walter S. DeKeseredy\n\u201cwell-meaning men\u201d and outnumber abusive men. A\u00a0 well-meaning man \nis one\nwho believes women should be respected. A\u00a0well-meaning man would not assault a woman. A\u00a0well-meaning man, on the surface, at least, believes in equality for women. A\u00a0well-meaning man believes in women\u2019s rights. A\u00a0well-meaning man honors the women in his life. A\u00a0well-meaning man, for all practical purposes, is a nice guy, a good guy.\n(Porter, 2006, p.\u00a01)\nHow many well-meaning men have long discussions with their sons about online misogyny, woman abuse, and sexism in general? The answer is prob-ably \u201cnot many.\u201d This is problematic and must change because preventative or remedial programs designed to foster young men\u2019s healthy masculinities are most successful if they involve fathers (Perales et\u00a0al., 2023). The adage \u201clike father, like son\u201d applies to this recommendation, and Katz's (2006) \nadvice reinforces it:\nClearly one of the most important roles a father\u00a0\u2013 or a father figure\u00a0\u2013 can play in his son\u2019s life is to teach by example. If men are always respectful toward women and never verbally or physically abuse them, their sons in all likelihood will learn to be similarly respectful. Nonetheless, every man who has a son should be constantly aware that how he treats women is not just between him and the women\u00a0\u2013 there is a little set of eyes that is always watching him and picking up cues about how a man is supposed to act. If a man says demeaning and dismissive things about women, his son hears it. If he laughs at sexist jokes and makes objectifying comments about women\u2019s bodies as he watches TV, his son hears it.\n(p.\u00a0234)\nTechnology Approaches\nSome technological work is also necessary in the struggle over digital misog-yny, but it is beyond the scope of this chapter to specify all that is needed. Some potentially effective means worth mentioning and a few of those rec -\nommended by the Center for Countering Digital Hate (2022 , pp.\u00a0 42\u201344) \ninclude:\n\u2022 Deplatforming incel YouTube channels.\n\u2022 Deranking incelosphere sites in Google searches.\n\u2022 Addressing digital harms to children that drive users to incelosphere \ncommunities.\n\u2022 Creating online\u2013offline referral mechanisms to offer support services and \nresources directly to at-risk individuals, offering reassurances on privacy.\nMisogyny and Woman Abuse in the Incelosphere  87\n\u2022 Infrastructure providers withdrawing their services from the incelosphere \nnetwork.\nThere are many other strategies that could easily be proposed in this chapter \nand that are informed by a rich gendered understanding of online hate. And, it is likely that even more new approaches will be required as we encounter both new technologies and various societal changes that will affect and shape gender relations. Certainly, 35 years ago, we would have never thought of \u201csexting\u201d becoming an integral part of peer culture. What is next? Many progressive scholars, practitioners, and activists are afraid to hear the answer, given the potential for major patriarchal harm to women (e.g., male violence) that has been mixed in with the tremendous changes for good provided by the Internet, smartphones, and other modern technology.\nConclusions\nThis chapter is not the first attempt to declare online misogyny like that per -\npetuated and legitimated by incels as a hate crime. Nonetheless, though there may be (and has been for a few decades) a strong international emphasis on naming face-to-face violence against women as a hate crime and as a viola -\ntion of human rights, there is still much work to do, and, thus far, little has been done to eliminate and prevent the creation of cyber communities like those populated by incels. This is partially the fault of the social scientific research community, which has thus far done a minimal amount of empirical and theoretical work to raise awareness about the incelosphere. Hopefully, this chapter demonstrates the value of applying male peer support theory, a perspective that has received much empirical support over the past 35 years.\nI would be remiss, though, if I\u00a0did not state that a growing number of \nfeminist scholars are helping to shed more light on the incelosphere and other misogynistic online communities. As well, the connections between Austral-ian and U.S. experts in the field are especially strong and will contribute to new global perspectives on gendered hate in this digital era. For instance, both Australian and U.S. scholars draw attention to the value of male peer support theory in sociological efforts to understand the damage done by incels.\n7 This is not surprising because male peer support for various types of \nwoman abuse seems to be ubiquitous and definitely has a long history. Still, male peer support theorists have yet to answer the important question of how all-male patriarchal collectives like the incel movement form or come together.\nAs Thorburn et\u00a0al. (2023 ) note, \u201cUltimately, there is much still unknown \nabout the nature, reach and impacts of incel subcultures, yet their prevalence across the Anglosphere speaks to the pervasion of a masculine group identity grounded in hierarchy, misogyny and aggrieved entitlement\u201d (p.\u00a0252). Both points are true, but the field will not advance unless rigorous research is done \n88 Walter S. DeKeseredy\noutside of the Global North and in non-English speaking communities, and \nthe results are featured in widely read and cited academic periodicals. This work will often require translators, and, hopefully, leading book and journal publishers will recognize the importance of covering the costs of transla -\ntional work. All the same, regardless of what new empirical and theoretical approaches are used to help develop a better understanding of incel subcul -\ntures in the Global North and Global South, we must keep this question at the forefront of our minds: \u201cWhat is to be done about the incelosphere?\u201d\nAcknowledgments\nI thank Joe Walther and Ronald Rice for their support and input.\nNotes\n 1 This is the main title of their book, which is now in its fourth edition.\n 2 Incels.Me was deplatformed on October 15, 2018, although it has been succeeded \nby the site INCELS.IS. Some of the content from the original Incels.Me site can be \nfound through the internet archive, https://web.archive.org/web/20180611074529/\nhttps://incels.me/; for more information see https://blog.nameshield.com/blog/2019/  \n01/10/the-shutting-down-of-incels-me-the-involuntary-single-website/\n 3 See https://www.nydailynews.com/news/national/elliot-rodger-retribution-santa-bar  \nbara-shooter-sick-words-article-1.1804761.\n 4 This term is short for \u201cfemale humanoids\u201d or \u201cfemales\u201d ( Jgin, 2023).\n 5 See DeKeseredy (2019, 2023) and DeKeseredy and Schwartz (2013 ) for in-depth \nreviews of the extant empirical and theoretical literature on the connection between male peer support and woman abuse.\n 6 Image-based sexual abuse websites and blogs first appeared on the internet in 2000 \nand started to gain U.S. national attention in 2010 following Hunter Moore\u2019s cre -\nating of IsAnyoneUp.com (Lamphere\u00a0& Pikciunas, 2016).\n 7 See, for example, DeKeseredy and Rennison (2019) and Thorburn et\u00a0al. (2023).\nReferences\nAjder, H., Patrini, G., Cavalli, F.,\u00a0& Cullen, L. (2019). The state of deepfakes: Land-\nscapes, threats, and impact. Deeptrace.\nApplin, S., Simpson, J. M.,\u00a0& Curtis, A. (2023). Men have gender and women are \npeople: A\u00a0structural approach to gender and violence. Violence Against Women , \n29(5), 1097\u20131118. https://doi.org/10.1177/10778012221104844\nBarrie, J. (2017, September 28).  Sex robot display model molested so much it breaks \nbefore anyone can actually use it: Sex doll Samantha was left filthy and in need of repairs after being mounted by excitable men. Mirror. https://www.mirror.co.uk/\nnews/weird-news/expensive-sex-doll-molested-much-11251239\nBates, L. (2020). Men who hate women: The extremism nobody is talking about . \nSimon\u00a0& Schuster.\nBelew, K.,\u00a0& Gutierrez, R. A. (Eds.). (2021).  A field guide to white supremacy . Uni-\nversity of California Press.\nBourgois, P. (1995). In search of respect: Selling crack in el barrio. Cambridge Uni-\nversity Press.\nMisogyny and Woman Abuse in the Incelosphere  89\nBowker, L. H. (1983). Beating wife-beating. Lexington Books.\nBridges, A. J., Wosnitzer, R., Scharrer, E., Sun, C.,\u00a0 & Liberman, R. (2010).  \nAggression and sexual behavior in best-selling pornography videos: A\u00a0 con -\ntent analysis update. Violence Against Women, 16(10), 1065\u20131085. https://doi.\norg/10.1177/1077801210382866\nBrubaker, S. J. (2019). Theorizing gender violence. Cognella.Campbell, H. (2000). The glass phallus: Pub(lic) masculinity and drink-\ning in rural New Zealand. Rural Sociology, 65(4), 562\u2013581. https://doi.\norg/10.1111/j.1549-0831.2000.tb00044.x\nCenter for Countering Digital Hate. (2022). The incelosphere: Exposing pathways \ninto incel communities and the harms they pose to women and children . Center for \nCountering Digital Hate. https://counterhate.com/research/incelosphere/\nCheok, A. D.,\u00a0& Levy, D. (Eds.). (2017). Love and sex with robots. Springer.CNN U.S. (2018, April 25).  The Toronto suspect apparently posted about an \n\u201cincel rebellion.\u201d Here\u2019s what that means. https://www.cnn.com/2018/04/25/us/\nincel-rebellion-alek-minassian-toronto-attack-trnd/index.html\nConnell, R. W. (1995). Masculinities. University of California Press.Connell, R. W.,\u00a0 & Messerschmidt, J. W. (2005). Hegemonic masculinity: \nRethinking the concept. Gender\u00a0 & Society, 19(6), 829\u2013859. https://doi.org/ \n10.1177/0891243205278639\nDeKeseredy, W. S. (1988).  Woman abuse in dating relationships: The relevance \nof social support theory. Journal of Family Violence, 3(1), 1\u201313. https://doi.\norg/10.1007/bf00994662\nDeKeseredy, W. S. (2017). Masculinities, aggression, and violence. In P. Sturmey \n(Ed.), The Wiley handbook of violence and aggression  (pp.\u00a01\u201312). John Wiley\u00a0& \nSons. https://doi.org/10.1002/9781119057574.whbva024\nDeKeseredy, W. S. (2019).  But why this man? Challenging hegemonic masculinity in \nan age of repression. In W. S. DeKeseredy\u00a0& E. Currie (Eds.), Progressive justice \nin an age of repression: Strategies for challenging the rise of the right (pp.\u00a011\u201325). Routledge.\nDeKeseredy, W. S. (2020).  Understanding the harms of pornography: The contribu -\ntions of social scientific knowledge. Culture Reframed.\nDeKeseredy, W. S. (2021). Woman abuse in rural places. Routledge.DeKeseredy, W. S. (2022).  Men\u2019s rights, gun ownership, racism, and the assault on \nwomen\u2019s reproductive health rights: Hidden connections. Dignity: A\u00a0Journal of \nAnalysis of Exploitation and Violence , 7(3). https://digitalcommons.uri.edu/cgi/\nviewcontent.cgi?article=1347&context=dignity\nDeKeseredy, W. S. (2023). Secret connections: Male collegial and professional contact \nsports, pornography, and violence against women. Culture Reframed.\nDeKeseredy, W. S.,\u00a0& Corsianos, M. (2016).  Violence against women in pornogra-\nphy. Routledge.\nDeKeseredy, W. S., Cowan, S.,\u00a0& Schwartz, M. D. (2023).  Skating on thin ice: Profes -\nsional hockey, rape culture, and violence against women. Aevo UTP.\nDeKeseredy, W. S.,\u00a0& Donnermeyer, J. F. (2023).  A\u00a0new theory of globablization, \nnatural resource extraction and violence against women: Toward solving the linkage problem. Critical Criminology, 31, 61\u201381. https://doi.org/10.1007/\ns10612-022-09668-3\nDeKeseredy, W. S., Dragiewicz, M.,\u00a0 & Schwartz, M. D. (2017).  Abusive endings: \nSeparation and divorce violence against women\n. University of California Press.\nDeKeseredy, W. S.,\u00a0& MacLeod, L. (1997).  Woman abuse: A\u00a0sociological story. Har -\ncourt Brace.\nDeKeseredy, W. S.,\u00a0& Olsson, P. (2011).  Adult pornography, male peer support, and \nviolence against women: The contribution of the \u201cdark side\u201d of the internet. In  \n90 Walter S. DeKeseredy\nM. Vargas Martin, M. A. Garcia-Ruiz,\u00a0& A. Edwards (Eds.), Technology for facili -\ntating humanity and combating social deviations: Interdisciplinary perspectives  \n(pp.\u00a034\u201350). IGI Global.\nDeKeseredy, W. S.,\u00a0& Rennison, C. M. (2019).  Key issues in the rape and sexual \nassault of women. In W. S. DeKeseredy, C. M. Rennison,\u00a0& A. K. Hall-Sanchez \n(Eds.), The Routledge international handbook of violence studies  (pp.\u00a0403\u2013418). \nRoutledge.\nDeKeseredy, W. S.,\u00a0& Schwartz, M. D. (1998).  Woman abuse on campus: Results \nfrom the Canadian national survey. Sage.\nDeKeseredy, W. S.,\u00a0& Schwartz, M. D. (2013).  Male peer support\u00a0& violence against \nwomen: The history\u00a0& verification of a theory. Northeastern University Press.\nDeKeseredy, W. S.,\u00a0 & Schwartz, M. D. (2016).  Thinking sociologically about \nimage-based sexual abuse: The contribution of male peer support theory. Sexuali-\nzation, Media,\u00a0& Society, 2(4). https://doi.org/10.1177/2374623816684692\nDePrince, A. P. (2022). Every 90 seconds: Our common cause ending violence against \nwomen. Oxford University Press.\nDhaliwal, S.,\u00a0& Kelly, L. (2020).  Literature review: The links between radicalization \nand violence against women and girls. London Metropolitan University.\nDobash, R. E.,\u00a0& Dobash, R. P. (1979).  Violence against wives: A\u00a0case against the \npatriarchy. Free Press.\nDouthat, R. (2018, May 2). The redistribution of sex. The New York Times. https://\nwww.nytimes.com/2018/05/02/opinion/incels-sex-robots-redistribution.html\nDragiewicz, M. (2008). Patriarchy reasserted: Fathers\u2019 rights and anti-VAWA activism. \nFeminist Criminology, 3(2), 121\u2013144. https://doi.org/10.1177/1557085108316731\nDragiewicz, M. (2011). Equality with a vengeance: Men\u2019s rights groups, battered \nwomen, and antifeminist backlash. Northeastern University Press.\nDragiewicz, M. (2018). Antifeminism and backlash: A\u00a0critical criminological impera -\ntive. In W. S. DeKeseredy\u00a0& M. Dragiewicz (Eds.), Routledge handbook of critical \ncriminology (2nd ed., pp.\u00a0334\u2013347). Routledge.\nEllis, D.,\u00a0 & DeKeseredy, W. S. (1997). Rethinking estrangement, interventions, \nand intimate femicide. Violence Against Women , 3(6), 590\u2013609. https://doi.\norg/10.1177/1077801297003006003\nFoubert, J. D. (2022).  Protecting your children from internet pornography: Under -\nstanding the science, risks, and ways to protect your kids. Northfield Publishing.\nFritz, N., Malic, V., Paul, B.,\u00a0& Zhou, Y. (2020).  A\u00a0descriptive analysis of the types, \ntargets, and relative frequency of aggression in mainstream pornography. Archives \nof Sexual Behavior, 49(8), 3041\u20133053. https://doi.org/10.1007/s10508-020-  \n01773-0\nGilligan, C.,\u00a0& Snider, N. (2018). Why does patriarchy persist? Polity Press.Henry, N., McGlynn, C., Flynn, A., Johnson, K., Powell, A.,\u00a0 & Scott, A. J. \n(2021). Image-based sexual abuse: A\u00a0 study on the causes and consequences of \nnon-consensual nude or sexual imagery. Routledge.\nHunter, T. (2023, February 13).  AI porn is easy to make now. For women, \nthat\u2019s a nightmare. The Washington Post. https://www.washingtonpost.com/\ntechnology/2023/02/13/ai-porn-deepfakes-women-consent/\nIncels.Me. (2018, October 11). https://web.archive.org/web/20180611074529/\nhttps://incels.me/\nJewkes, R., Dunkle, K., Koss, M. P., Levin, J. B., Nduna, M., Jama, N.,\u00a0& Sikweyiya, \nY. (2006). Rape perpetration by young rural South African men: Prevalence, pat -\nterns, and risk factors. Social Science and Medicine , 63(11), 2949\u20132961. https://\ndoi.org/10.1016/j.socscimed.2006.07.027\nJgin, K. (2023, March 14).  The problem with incels no one seems to talk about. \nThe Noosphere\n. https://medium.com/the-no\u00f6sphere/the-problem-with-incels-no- \none-seems-to-talk-about-fb03bd2dd135\nMisogyny and Woman Abuse in the Incelosphere  91\nJoosse, P.,\u00a0& Willey, R. (2020). Gender and charismatic power. Theory and Society, \n49(4), 533\u2013561. https://doi.org/10.1007/s11186-020-09392-3\nKatz, J. (2006). The macho paradox: Why some men hurt women and how all men \ncan help. Sourcebooks, Inc.\nKatz, J. (2016). Man enough? Donald Trump, Hillary Clinton and the politics of \npresidential masculinity. Interlink Books.\nKezer, T. (2019, April 26). The dangers of sex robots. Her Campus. https://www.\nhercampus.com/school/alaska/dangers-sex-robots/\nKimmel, M. (2017). Angry white men: American masculinity at the end of an era . \nNation Books.\nKleeman, J. (2017, September 25).  Should we ban sex robots while we have the chance?  \nThe Guardian. https://www.theguardian.com/commentisfree/2017/sep/25/ban-sex-  \nrobots-dolls-market\nLamphere, R. D.,\u00a0& Pikciunas, K. T. (2016).  Sexting, sextortion, and other internet \nsexual offenses. In J. N. Navarro, S. Clevenger,\u00a0& C. D. Marcum (Eds.), The inter -\nsection between intimate partner abuse, technology, and cybercrime: Examining \nthe virtual enemy (pp.\u00a0141\u2013165). Carolina Academic Press.\nLevant, R. (1995). Male violence against female partners: Roots in male socialization \nand development. In C. D. Spielberger, I. G. Sarason, J. M. T. Brebner, E. Green -\nglass, P. Laungani,\u00a0& A. M. O\u2019Roark (Eds.), Stress and emotion: Anxiety, anger, \nand curiosity (Vol. 15, pp.\u00a091\u2013100). Taylor\u00a0& Francis.\nLevin, J.,\u00a0& Nolan, J. (2017).  The violence of hate: Understanding harmful forms of \nbias and bigotry (4th ed.). Roman\u00a0& Littlefield.\nLewis, R., Rowe, M.,\u00a0& Wiper, C. (2017).  Online abuse of feminists as an emerging \nform of violence against women and girls.\u00a0 British Journal of Criminology , 57(6), \n1462\u20131481. https://doi.org/10.1093/bjc/azw073\nManne, K. (2018). Down girl: The logic of misogyny. Oxford University Press.Messerschmidt, J. W. (1993). Masculinities and crime. Roman\u00a0& Littlefield.Messerschmidt, J. W. (2012). Gender, heterosexuality, and youth violence: The strug-\ngle for recognition. Rowman\u00a0& Littlefield.\nMessner, M. A., Greenberg, M. A.,\u00a0& Peretz, T. (2015). Some men: Feminist allies\u00a0& \nthe movement to end violence against women. Oxford University Press.\nMiller, J. (2008). Getting played: African-American girls, urban inequality, and gen -\ndered violence. Oxford University Press.\nMiller, P. (2017). Patriarchy. Routledge.Nashrula, T. (2019, June 6).  Incels are running an online suicide forum that was \nblamed for a young woman\u2019s death. BuzzFeed.News. https://www.buzzfeednews.\ncom/article/tasneemnashrulla/incels-suicide-forum-woman-killed-herself\nNew America. (2023). Misogynist incels and male supremacism. https://www.newamer -\nica.org/political-reform/reports/misogynist-incels-and-male-supremacism/recommendations/\nNorris, S. (2017, September 28).  The damage to Samantha the sex robot shows male \naggression being normalized: These problematic dolls invite abusive treatment. NewStatesman. https://www.newstatesman.com/politics/2017/09/damage-samantha-sex-  \nrobot-shows-male-aggression-being-normalised\nOkolie, C. (2023).  Artificial intelligence-altered videos (deepfakes), image-based sexual \nabuse, and data privacy concerns. Journal of International Women\u2019s Studies , 25(4), \n1\u201316. https://vc.bridgew.edu/cgi/viewcontent.cgi?article=3079&context=jiws\nPerales, F., Kuskoff, E., Flood, M.,\u00a0& King, T. (2023).  Like father, like son: Empirical \ninsights into the intergenerational continuity of masculinity ideology. Sex Roles, \n88\n(9\u201310), 399\u2013412. https://doi.org/10.1007/s11199-023-01364-y\nPolk, K. (2003). Masculinities, femininities, and homicide: Competing explanations \nfor male violence. In M. D. Schwartz\u00a0& S. E. Hatty (Eds.), Controversies in critical \ncriminology (pp.\u00a0133\u2013146). Anderson.\n92 Walter S. DeKeseredy\nPorter, T. (2006).  Breaking out of the \u201cman box\u201d, a call to men: The next generation \nof manhood. Skyhorse Publishing.\nPtacek, J. (2023). Feeling trapped: Social class and violence against women. Univer -\nsity of California Press.\nRenzetti, C. M. (2018). Feminist perspectives. In W. S. DeKeseredy\u00a0& M. Dragie -\nwicz (Eds.), Routledge handbook of critical criminology  (2nd ed., pp.\u00a0 74\u201382). \nRoutledge.\nSalter, M.,\u00a0& Crofts, T. (2015). Responding to revenge porn: Challenges to online \nlegal impunity. In L. Comella\u00a0& S. Tarrant (Eds.), New views on pornography: \nSexuality, politics, and the law (pp.\u00a0223\u2013253). Praeger.\nSchwartz, M. D. (2021).  Masculinities, sport, and violence against women: The con -\ntribution of male peer support theory. Violence Against Women, 27(5), 688\u2013707. \nhttps://doi.org/10.1177/1077801220958493\nSchwartz, M. D.,\u00a0& DeKeseredy, W. S. (1997).  Sexual assault on the college campus: \nThe role of male peer support. Sage.\nScott, A. O. (2022, June 2). The actual malice of the Johnny Depp trial. The New York \nTimes. https://www.nytimes.com/2022/06/02/arts/depp-heard-trial-malice.html\nShead, S. (2017, July 5). A\u00a0new report showed all the different ways that sex robots \ncould be used in society. Businessinsider.com. https://www.businessinsider.com/\nour-future-with-sex-robots-noel-sharkey-report-2017-7\nSuk, J. C. (2023).  After misogyny: How the law fails women and what to do about it . \nUniversity of California Press.\nSumOfUs. (2022). Metaverse: Another cesspool of toxic content. SumOfUs.\nThorburn, J., Powell, A.,\u00a0 & Chambers, P. (2023). A\u00a0 world alone: Masculinities, \nhumiliation, and aggrieved entitlement on an incel forum. The British Journal of \nCriminology, 63(1), 238\u2013254. https://doi.org/10.1093/bjc/azac020\nThorne-Finch, R. (1992). Ending the silence: The origins and treatment of violence \nagainst women. University of Toronto Press.\nTranchese, A.,\u00a0& Sugiura, L. (2021).  \u201cI don\u2019t hate all women, just those stuck-up \nbitches\u201d: How incels and mainstream pornography speak the same extreme lan-guage of misogyny. Violence Against Women , 27(14), 2709\u20132734. https://doi.\norg/10.1177/1077801221996453\nTroiano, G. (2022, June 2).  40 statistics you should know about online communities \nin 2022. Amity. https://www.amity.co/blog/40-statistics-you-should-know-about- \nonline-communities\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWarshaw, R. (1988). I never called it rape. Harper\u00a0& Row.Websdale, N. (1998). Rural woman battering and the justice system: An ethnogra -\nphy. Sage.\nWest, C.,\u00a0 & Zimmerman, D. H. (1987).  Doing gender. Gender\u00a0 & Society, 1(2), \n125\u2013151. https://doi.org/10.1177/0891243287001002002\nWilson, W. J. (1996). When work disappears: The world of the new urban poor . \nKnopf.\nWinlow, S., Hall, S.,\u00a0& Treadwell, J. (2019).  Why the left must change: Right-wing \npopulism in context. In W. S. DeKeseredy\u00a0& E. Currie (Eds.), Progressive justice \nin an age of repression: Strategies for challenging the rise of the right (pp.\u00a026\u201341). Routledge.\nYang, J.,\u00a0& Gillis, W. (2018, April 28).  Shadowy online subculture in spotlight after \nToronto van attack. Toronto Star. https://www.thestar.com/news/gta/2018/04/28/\nshadowy-online-subculture-in-spotlight-after-toronto-van-attack.html?rf\nDOI: 10.4324/9781003472148-5\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Social media has emerged as a dominant mode of communication in con-\ntemporary society, eliciting concerns regarding its influence on political life. Social media platforms appear to encourage a more radical, conflict -\nual, and hateful form of politics and discourse, as fringe online spaces become home to cesspools of hateful discourses and extremist movements. Although there is mounting evidence that links social media with these polarized forms of politics, the underlying causal mechanisms remain elu -\nsive. Specifically, how does social media fuel political extremism and the rise of online hate?\nFor years, a leading explanation has centered on the \u201cecho chamber\u201d the -\nory, positing a feedback loop between isolation with like-minded individuals and more extreme politics. Captured in their echo chamber, individuals do not encounter opposing views, causing them to diverge toward more extreme opinions\u00a0\u2013 they fall into online \u201crabbit-holes\u201d and emerge as \u201clone-wolf\u201d terrorists. Through its emphasis on deliberation, the echo chamber notion implicitly builds on an assumption of politics as existing primarily in the realm of individual consumption of arguments and opinions, while leaving its more social dimensions to the side.\nIn this chapter, we propose a new perspective on how fringe online spaces \ncontribute to the rise of political extremism and online hate. Using our find -\nings from previous empirical and interpretive research, we draw on \u00c9mile Durkheim\u2019s work, which sought to identify the social mechanisms that bind communities together. We see online interactions in these spaces not as rational deliberation but as a form of \u201crituals\u201d that bind a community together around the opposition to an out-group. We thus propose a shift 5\nFROM ECHO CHAMBERS TO  \nDIGITAL CAMPFIRES\nThe Making of an Online Community of  \nHate in Stormfront\nAnton T\u00f6rnberg and Petter T\u00f6rnberg\n94 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nfrom understanding online extremism and hate through the lens of rational \nand critical discussions, to emphasizing underlying social and emotional processes.\nAs a case, we focus on what has been described as the most extreme space \nof online hate, Stormfront.org. Established in the mid-1990s, Stormfront is a White Supremacist and neo-Nazi online community and forum. It stands out as one of the earliest and most significant websites promoting far-right ideologies, racial supremacy, and hate speech on the Internet.\nThe community is built around participatory technology, with members \nengaging in user-generated message postings organized into numerous topics, or \u201csubforums.\u201d Overall, the forum is teeming with hate-related posts, pri -\nmarily concerning race and ethnicity, often using derogatory speech, describ -\ning Jews as \u201cparasites\u201d and Black people as \u201cinferior life forms.\u201d Holocaust denial, misogynistic remarks, and various antisemitic conspiracy theories\u00a0\u2013 claiming Jews control the world\u2019\ns financial system and the media\u00a0\u2013 are preva -\nlent. Some users openly glorify, endorse, or promote violence against the groups they target.\nIn contrast to mainstream sites like X (previously Twitter) or Facebook, \nStormfront is explicitly dedicated to White Nationalists. Consequently, the messages expressing hatred toward different races, religions, and immigrants are not framed as if they are intended for the targeted groups to see; rather, they are composed about those groups, meant for consumption by fellow White Nationalists (see Walther, this volume).\nWe have acquired a longitudinal database of Stormfront comments con -\ntaining 10,172,069 posts by 354,574 users, spanning over 20 years of discus -\nsions. This unique dataset enables us to examine the intricate social processes that shape the emergence and propagation of online hate.\nBuilding on the Durkheimian perspective, we argue for understanding iso -\nlated online hate communities such as Stormfront as constituting a type of \u201cdigital campfires.\u201d Within these spaces, participating members engage in discussions, drawing on shared experiences and interests to cultivate a sense of community and shared identity. Through recurrent interaction rituals, they elaborate a collective worldview, while simultaneously fostering a hyperper -\nsonal sense of intimacy within an unseen collective. These are grassroots, collective processes, often rife with conflict and fragility, and they materialize through interaction and discussion.\nThis chapter draws on three empirical research papers by the authors, \nfocusing on three interrelated dimensions of online community formation\u00a0\u2013 identity, worldview, and affect\u00a0\u2013 to elaborate a new theoretical framework for the mechanisms through which far-right extremism emerges on online media. By synthesizing these previous studies and complementing them with additional primary sources, the chapter provides a more social theoretical \nfoundation for understanding online hate.\nFrom Echo Chambers to Digital Campfires  95\nSocial Media and the Rise of the Politics of Hate\nThe rise of social media has transformed political life. Recent years have seen \nthe rise and mainstreaming of forms of politics that center around opposition to out-groups, such as the other political party or minorities (Chua, 2019; Mason, 2018). The literature on affective polarization suggests that this form of polarization should not be understood as merely diverging opinions but rather as a reinforcement of a sense of in-group based on political affiliation (Iyengar et\u00a0al., 2019 ; T\u00f6rnberg, 2022). While a vast body of literature has \nestablished a link between social media and political polarization, emerg -\ning findings increasingly indicate that this polarization is asymmetrical: It is primarily driven by the radicalization of the far right (e.g., Gonz\u00e1lez-Bail\u00f3n et\u00a0al., 2023; Soares et\u00a0al., 2019). Social media appears to have transformed \nthe far right, catapulting a previously fringe form of hate-driven politics into the political mainstream.\nIn this context, online hate can be viewed as a manifestation of out-group \nderogation, fueled by a desire for social validation and affirmation from like-minded peers ( Walther, 2022). Such behaviors thus aim to foster a sense \nof belonging and to solidify friendships online, with the detriment to vic-tims emerging as a secondary consequence of this approval-seeking behav -\nior. Far-right groups focus on building and nurturing their group identity, in part through attacking others. Hate messaging is pivotal in this process as it bolsters feelings and in-group cohesion through negative expressions and feelings toward an out-group. In this sense, group identity appears as the underlying bond of the nexus between racism, hate, and political worldviews.\nOnline hate movements cannot be understood as a strictly discursive phe -\nnomenon, however. Research has identified a close relationship between online hate and offline violence. Offline trigger events, such as protests and elections, are often followed by spikes in types of online hate activity that bear seemingly little connections to the underlying event itself ( Lupu et\u00a0al., 2023). \nSimilarly, online activity can fuel offline violence, such as the January 6th attack on the U.S. Capitol. Both experimental evidence and observational studies have furthermore demonstrated that passive and, particularly, active exposure to radical content online increases both willingness to use radical violence in the name of a cause or ideology and actual involvement in such violence (Hassan et\u00a0al., 2018 ; Wolfowicz et\u00a0al., 2022 ). For example, M\u00fcller \nand Schwarz (2021) have established a causal relationship between social media usage and hate crimes in their study on violent crimes against refugees in Germany, with anti-refugee sentiments on Facebook serving as predictors of crimes against refugees. Similar patterns have been observed in a study on Twitter, showing that a one standard deviation\u00a0\u2013 higher exposure to Twit -\nter\u00a0\u2013 is associated with a 32% larger increase in hate crimes within the 2016 presidential campaign period (M\u00fcller\u00a0& Schwarz, 2023).\n96 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nIn sum, this suggests understanding the role of social media at the nexus \nof political polarization, online hate, and violent extremism (see also Karell \net\u00a0al., 2023). Extremism has been transformed by the growing role of social \nmedia, leading to a shift from formal organizations to informal, networked bottom-up activities. We can point to two ways in which extremism has been transformed by social media.\nFirst, digitalization has led to more porous and ill-defined boundaries of \nmovements, as the previous importance of face-to-face encounters, physical gatherings such as street protests and white power concerts, and certain sub -\ncultural attire and artifacts symbolizing belonging is now diminishing. The most critical means of distinguishing insiders from outsiders now resides in the discursive realm: Specific words, themes, stories, ideas, or images func-tion as emblems and evidence of group membership (see e.g., Burston, this volume).\nSecond, digitalization has driven the decentralization of extremist move -\nments, resulting in a lack of explicit and clear leadership. In formal move -\nments, ideology and framing processes were primarily driven by movement leadership, who defined and diagnosed the problem, provided potential solu -\ntions, and suggested courses of action ( Benford, 1997; Benford\u00a0 & Snow, \n2000). Frames and ideologies were typically constructed and disseminated in a top-down process. However, we now see the emergence of a more fragmen -\ntary and decentralized type of radicalization, driven by social media users themselves. Traditional frames tended to be relatively consistent and inte -\ngrated packages, polished to avoid contradictions, and strategically designed both to garner the support of politicians and to attract sympathizers. In stark contrast, the construction of ideology and movement framing are now fragmented processes by and for movement actors. A\u00a0typical example is the right-wing QAnon conspiracy that emerged mainly from discussions on 4chan and later spread to mainstream media platforms and even into the U.S. Congress (Amarasingam\u00a0& Argentino, 2020).\nOne effect of this decentralization of extremist organization is, in part, \nthat the far right has become more unpredictable and, in many ways, more dangerous. Scholars have described the emergence of what has been referred \u201cstochastic terrorism\u201d in which the timing and specific targets of these attacks are probable but unpredictable ( Hamm\u00a0& Spaaij, 2017 ; Miller-Idriss, \n2022; Rae et\u00a0al., this volume; Tsesis, 2017). The absence of formal organiza-\ntions means that radical actors may be inspired to commit violent actions rather than channel their energy into more long-term strategic work, such as organization-building or collective manifestations. Data on far-right attacks in Europe from 1990 to 2021 supports this notion, showing that the majority of fatal attacks during this period were carried out by lone actors. In contrast, nonfatal attacks were predominantly executed by autonomous cells, informal groups, organized groups, and affiliated members (Ravndal, 2016, 2018).\nFrom Echo Chambers to Digital Campfires  97\nMechanisms of Radicalization: Echo Chambers\nWhile it is now broadly agreed among scholars that social media is associated \nwith the rise of a new hate-driven form of politics, the reason for the link between social media and political extremism remains poorly understood. Within media and communication studies, notions such as \u201cecho chambers\u201d and \u201cfilter bubbles\u201d have become dominant explanations for online radicali-zation (Pariser, 2011; Sunstein, 2002, 2007). The most influential version of \nthe echo chamber hypothesis suggests that these spaces isolate individuals from opposing viewpoints, resulting in a divergence of issue positions. Since the work of Habermas (1989), public sphere theorists have long argued that \nthe coming together of individuals with diverse ideas and perspectives is cen -\ntral to democracy, as it enables the formation of a public through rational deliberation. However, when such deliberation takes place in ideologically homogeneous spaces, the result is divergence toward political extrem -\nism (McPherson et\u00a0al., 2001 ), as individuals are \u201cself-radicalized\u201d through \nrepeated exposure to one-sided content, resulting in extreme political views that potentially lead them to even greater polarization (Sunstein, 2007). The related notion of \u201cfilter bubbles\u201d suggest that these effects are further reinforced by algorithmic personalization that automatically selects content based on viewers\u2019 preferences, while hiding opposing views and perspectives.\nThe concept of echo chambers builds on two main assumptions. The first \nis the notion that opinions and political views stem from rational under -\nstanding and interpretation of information and knowledge, presented in arguments. Accordingly, radicalization is thus cast as chiefly a question of opinions and issue positions and social media as chiefly a space for debate and the consumption of a curated subset of arguments and (mis)information. Although the processes occurring inside echo chambers may appear anything but \u201crational,\u201d this perspective treats politics to be intrinsic to individuals. The echo chambers approach is thus receiver-oriented, that is, its activation \ndepends only on reading what others post. It is passive in the sense that it is not about posting nor about interacting\u00a0\u2013 that is, not a social process. Sec -\nond, social media are presumed to further spur radicalization and polariza -\ntion by facilitating and accelerating isolation and keeping ideological groups separate from each other.\nHowever, accumulating empirical evidence suggests that neither of these \nassumptions holds. First, substantial empirical evidence demonstrates that while political information often circulates within specific channels and groups, groups also communicate with each other, allowing arguments and worldviews to permeate various environments (Bail, 2022; Dubois\u00a0& Blank, \n2018; Jungherr et\u00a0 al., 2020). For instance, Brundidge (2010) found that \nInternet usage actually contributes to an increased heterogeneity of political discussion networks through inadvertent exposure. This increased exposure \n98 Anton T\u00f6rnberg and Petter T\u00f6rnberg\noriginates from the Internet\u2019s capacity to facilitate access to political differ -\nences, even when the individuals do not actively seek them. Wojcieszak and \nMutz (2009) also found that an exposure to diverse networks and political \nviews frequently occurs unintentionally in spaces where political and nonpo -\nlitical discussions coexist.\nThis is also true for online extremist groups. Our previous studies have \nshown that far-right groups extensively link to mainstream media platforms and news sites, as well as to sites belonging to opposing groups ( T\u00f6rnberg\u00a0& \nNissen, 2022; see also Phadke\u00a0 & Mitra, this volume). Examining Twitter debates, our previous work has also found that user network clusters are characterized not by isolation, but by substantial negative interaction across the political divide ( Keuchenius et\u00a0al., 2021 ). Similarly, Bright et\u00a0al. (2022 ) \ndemonstrate in their study of Stormfront that engaging with oppositional views is in fact a core practice among its users. In fact, these posts tend to stimulate discussion within and encourage users to remain active on the site. We have observed similar results in far-right Facebook groups, where users extensively engage with both confirming and contradicting arguments: They distort, decontextualize, reinterpret, and ridicule these arguments in a process that might be more aptly described as \u201ctrench warfare\u201d rather than \u201cecho chamber\u201d (Karlsen et\u00a0al., 2017; T\u00f6rnberg\u00a0& Wahlstr\u00f6m, 2018). This sug -\ngests that these environments are not isolated, and that social media, in many cases, actually reinforce interaction, but not agreement, between groups and individuals. Thus, many \u201cechoes\u201d within these echo chambers are not core beliefs being restated but, rather, the sound of opposing viewpoints being undermined and marginalized.\nHowever, there is limited evidence to support the claim that exposing \nindividuals to opposing viewpoints results in more moderate and informed citizens. On the contrary, it may even reinforce their preexisting views ( Bail \net\u00a0al., 2018; Hemmingsen\u00a0& Castro, 2017; Schmitt et\u00a0al., 2018). Empirical \nstudies on counter-radicalization reveal that strategies based on increasing interaction between opposing groups can actually fuel conflicts and inten -\nsify radicalization among those who already harbor extreme views ( B\u00e9langer \net\u00a0al., 2020; Lewandowsky et\u00a0al., 2012 ). For instance, in a study on Twitter \nusers, Bail and colleagues (2018 ) exposed 1,200 users to content from the \nopposite political spectrum over a one-month period. The results showed that Republicans who followed a Democratic bot for this period expressed markedly more conservative views than before. In fact, the more attention they paid to the content, the stronger the effect. Many participants in the study described the experience of stepping outside their echo chamber and encountering opposing ideas and arguments as an attack upon their identity. Similar results have been observed in other de-radicalization strategies such as \u201cdebunking\u201d or \u201ccounter-messaging,\u201d which aim to correct factual inac -\ncuracies. For example, studies have shown that attempting to refute or quash \nFrom Echo Chambers to Digital Campfires  99\nrumors that vaccines cause autism may make those who believe in these \nrumors even more opposed to inoculating their children ( Berinsky, 2017; \nNyhan et\u00a0al., 2014 ). Overall, stepping outside one\u2019s echo chamber seems not \nto contribute to a better competition of ideas but rather a vicious competition of identities, sharpening the contrast between \u201cus\u201d and \u201cthem\u201d (T\u00f6rnberg, 2022).\nIf it is not the echo chamber mechanism of a feedback loop between isola -\ntion and diverging opinions, which drives polarization and radicalization, then what is? Why do social media\u00a0\u2013 and fringe digital spaces in particular\u00a0\u2013 seem to fuel a hate-driven form of politics?\nThe Case of Stormfront: White Pride, Worldwide\nTo examine the role of fringe digital spaces in online radicalization, we center our discussion on the case of Stormfront. Stormfront emerged as a commu -\nnity for White Nationalists in the mid-1990s. By the early 2000s, the forum was described in an article in USA Today as \u201cthe most visited white suprema-cist site on the net\u201d (McKelvey, 2001). Among these users were prominent White Supremacists, such as Thom Robb; the founder of National States Rights Party, Ed Fields; and former KKK leader, David Duke. The commu -\nnity is distinguished by its remarkable longevity: While the Internet went through waves of transformation\u00a0\u2013 the Dot-Com boom of the early 2000, Web 2.0, Facebook, Instagram, and TikTok\u00a0\u2013 Stormfront persisted.\nStormfront has been described as a bastion and breeding ground for vio -\nlent extremism and racially motivated hate. Over the years, members of the site have been linked to over 100 terrorist attacks, including the 2011 Norway attacks and the 2015 Charleston church shootings (Beirich, 2014). Stormfront members themselves describe the forum as an \u201conline refuge\u201d (de Koster\u00a0 & Houtman, 2008), a place where they connect and actively engage with others who share their racist and White Supremacist beliefs (Bowman-Grieve, 2009; Hartzell, 2020). The forum is marked by both radi -\ncal views and relative opinion homogeneity. Levin (2002) sees the website as the earliest \u201cweb-based hate entity\u201d that inspired many similar forums on the far right. About 14% of posts on the forum can be classified as explicit hate posts (Berglind et\u00a0al., 2019 ), and recent longitudinal studies on Stormfront \nhave also revealed patterns suggesting that, over time, members increasingly adopt more radical stances in their anti-Black and antisemitic narratives (Scrivens et\u00a0al., 2020 ; T\u00f6rnberg\u00a0& T\u00f6rnberg, 2022 ). While anyone can read \nthe Stormfront message boards, one must apply for and be granted member -\nship in order to post in most sub-forums. The architecture of the site itself not only presents listings of conversational threads within topics, but it also displays the linked, hierarchically threaded replies within those threads, indi -\ncating the dialogic nature of Stormfront participation.\n100  Anton T\u00f6rnberg and Petter T\u00f6rnberg\nThis chapter will elaborate a new perspective to explain how online media \nare linked to extremist radicalization. This perspective draws on Durkheim\u2019s \nresearch on the development of community through ritual activity and on previous empirical studies of our own that examine in detail the Stormfront community (T\u00f6rnberg\u00a0& T\u00f6rnberg, 2021, 2022, 2023). For these studies, we developed custom-made web crawlers in order to create a dataset comprising 10,172,069 posts and 354,574 members, spanning 20 years of discussions on Stormfront. This dataset offers a powerful view into the political lives of individual members and a way to explore empirically what takes place within these fringe communities. We used a combination of computational and interpretive methods to examine how individuals are affected by partici -\npating in the community.\nDurkheim and the Social Function of Campfires\nAs discussed above, the existing literature on echo chambers has implicitly treated online communities as spaces of rational debate and the deliberation over arguments\u00a0 \u2013 becoming poisoned by the fact that the arguments pre -\nsented stem from a narrow band of the political spectrum. Our work on Stormfront, over time, however, brought us to seek a different theoretical foundation, building on \u00c9mile Durkheim\u2019s study of communities, through which he sought to understand the social activities that bind communities and societies together.\nIn his work examining aboriginal communities in Australia, Durkheim \n(1912/1915) observed that most of the community\u2019s time was dedicated to routine activities involving a small group, such as food gathering and child -\ncare. However, the rare occasions where the entire tribe assembled for shared rituals were considered sacred. These rituals, characterized by synchronized movements and chanting, induced trance-like states of collective efferves-\ncence, imbuing participants with emotional energy and a sense of intersubjec-tivity. The community\u2019s focus on common objects, such as religious symbols and artifacts, flags and banners, or tribal artifacts, fostered shared feelings, unifying the group as a whole, a community, rather than just an aggregation \nof individuals. In our work with Stormfront, we began seeing online spaces such as Stormfront as the digital manifestations of the campfires around which aboriginals congregated, as described in Durkheim\u2019s research over a century ago.\nWhile the exchange of messages online may seem somewhat more mun -\ndane, the notion of a ritual in many ways captures the role and effects of \nthese online interactions. For the users on Stormfront, the content of the messages seems to carry less relevance than the act of interacting . The threads \nof discussion appear like drawn-out collective moments of shared energy and emotion. Such a broadening of the notion of ritual is consistent with other scholars who have built on the work of Durkheim. Collins (2004), \nFrom Echo Chambers to Digital Campfires  101\nfor instance, expanded and reinterpreted Durkheim\u2019s findings to apply to \nour understanding of contemporary society. Linking together Durkheim with the micro-sociology of Erving Goffman, Collins used the notion of rituals to examine how groups today establish social membership and intersub-jectivity\u00a0\u2013 that is, a shared sense of \u201cwe.\u201d The expanded notion of rituals pointed to the centrality of moments of shared attention and emotion that come to imbue objects with a sense of group belonging. Recent work has extended Collins\u2019s theoretical framework, arguing that these rituals can also occur in mediated environments ( DiMaggio et\u00a0al., 2018; Johannessen, 2023; \nWahlstr\u00f6m\u00a0& T\u00f6rnberg, 2021; W\u00e4sterfors et\u00a0al., 2023). According to these \nstudies, Collins\u2019 basic criterion of an interaction ritual is present online\u00a0\u2013 a gathering with shared focus under a dominant definition of the situation and a tendency to defend boundaries. As seen in other research, while mediated interaction rituals lack full bodily presence, they arguably make up for it through increased frequency (Walther\u00a0& Burgoon, 1992), especially in our age of \u201cdeep mediatization\u201d (Couldry\u00a0& Hepp, 2018), where mediated inter -\naction is ubiquitous.\nThe Durkheimian perspective on online communities suggests that the \nexchange of arguments in these online discussions should not be primar -\nily viewed as the rational exchange that it may superficially appear, but as content that serves the role of symbolic markers of identity and belonging. They aim not to rationally persuade but aim instead to highlight similarities and differences, to distinguish an \u201cus,\u201d separated from a \u201cthem.\u201d What takes place on social media is as much or more in the realm of identity, ritual, symbolisms, and belonging as it is in the realm of argumentation, opinion, and rationality.\nIn examining Stormfront through this Durkheimian lens, the community\u2019s \ndiscourse appears as a continuous chain of interaction rituals, which gradu -\nally weaves a web of symbolically imbued narratives that link the individuals together in a community. This narrative web is more than told\u00a0\u2013 they are viscerally felt, as part of the collective identity and self-understanding of the participants.\nThe Durkheimian notion of a ritual thus links together three dimensions \nof community life\u00a0\u2013 identity, narratives, and emotions\u00a0\u2013 in a single process. \nIn our empirical work, we came to structure the research according to these three dimensions, in order to support this theoretical foundation for under -\nstanding online extremist communities. We will therefore structure the sub-sequent discussion according to these dimensions.\nIdentity: Language as Process and Product\nThe Durkheimian perspective puts identity at center stage: Rituals create a \nsense of group solidarity, strengthening the collective identity by the gradual articulation of a common cultural system. As individual participants develop \n102  Anton T\u00f6rnberg and Petter T\u00f6rnberg\na stronger sense of solidarity and intersubjectivity, they come to also assume \nthe thoughts, morals, and behaviors internal to their group, viewing them-selves less as individuals and more as part of the community. The ritual, embodied in reciprocal and complementary messaging, transforms a group of individuals into a community, a shared sense of \u201cwe.\u201d The construction of a social and collective identity in digital spaces is thus entangled with the construction of an internal discourse and culture: A\u00a0community is made up of stories, and these stories intertwine its members with the community (Schwartz et\u00a0al., 2011).\nThis linkage between social identity and community speaks to a long \ntradition within psychology and sociology, according to which identity is constructed precisely through discursive activities\u00a0\u2013 it is negotiated among speaking subjects ( Polkinghorne, 1988; Sarbin, 1986). These and other schol -\nars place language in a central role in structuring our identities and our rela -\ntionship to our social groups. Central to socialization is the acquisition of a shared system of discourse, which provides the illusion of coherent and bounded identity by situating the individual in the social. Language contains  \nthe social, and its structure is the structure of the social. This suggests a broad notion of stories, as the cultural web that situates people in their social worlds.\nMeasuring Identity Formation on Stormfront\nThe suggestion of a link between discourse and identity raises the possibil-ity that we can study the formation of collective identities through the flow and shifts in linguistic patterns. The terms and words used by members on a community provide a link to examining how they are affected by engag -\ning in the interaction rituals, and how their understanding of themselves is transformed.\nTo study community formation through language, we examined how mem -\nbers\u2019 terminology changed as they engaged with the community (\n T\u00f6rnberg\u00a0& \nT\u00f6rnberg, 2022). We organized each member\u2019s messages, with the earliest message labeled as \u201cMessage 1\u201d and subsequent messages numbered in order. This allowed us to observe how their word choices shifted over time, reflecting the influence of engaging in continuous online interaction rituals on individual participants.\nWe first examined the overall similarity between the language used by new \nmembers and the community overall. To do so, we constructed a language model that represents the forum\u2019s overall language, based on a random sam -\nple of 20,000 messages. To measure the distance between two corpora, we used \u201cbag-of-words\u201d representations, that is, we captured the frequency of each word used in each corpus and used cosine similarity to measure the distance in terms of word frequency ( Joachims, 2002). In essence, this math -\nematical method helps us understand how related or distinct two collections \nFrom Echo Chambers to Digital Campfires  103\nof text are from each other by measuring the \u201cdistance\u201d in terms of the \nwords they use.\nFigure\u00a0 5.1 shows the cosine distance between the words used by new mem -\nbers and those written by the community as a whole, as a function of how many posts they have contributed. As we wanted to follow the same mem -\nbers over a longer time to see how their language use evolved, we focused on members who had sent at least 50 posts, since this selection effectively cap -\ntures active long-term members. The results are striking. The new members began far from the language of the forum as a whole, but new members rela -\ntively quickly converged as they engaged with the community. After about 20 posts, almost complete convergence had taken place. This suggests that members quickly absorb the defining discourse of the community.\nFIGURE\u00a05.1   Convergence of Forum Posters\u2019 Language over Time\nNote: This figure shows the cosine distance between members\u2019 posts, in posting order, with the overall community language, over time. As the figure shows, new members quickly converge on the forum discourse.\n104  Anton T\u00f6rnberg and Petter T\u00f6rnberg\nWe then turned more closely to the content of these linguistic shifts by \nusing inductive computational methods to compare the language of new ver -\nsus long-term members. These analyses point to two concurrent changes.\nFirst, the members picked up different slangs and vernacular that are par -\nticular to the community. For instance, while new members may speak of \n\u201cthe government,\u201d insiders instead use \u201czog\u201d\u00a0\u2013 short for \u201cZionist\u00a0Occupied Government\u201d\u00a0\u2013 a reference to a common White Supremacist belief that the U.S. government is controlled by Jews. The language of this acronym reflects the ideology and beliefs of the community. The use of these internal terms in their postings served to demarcate insiders from outsiders. The language changed from mainstream terms to community-specific vernacular and themes, which functioned as markers of community belonging, embracing the White Supremacist ideology of the forums.\nSecond, the language of the members also shifted in more subtle ways, \nrevealing a change in self-understanding in relation to the community. There was a shift toward the use of pronouns and \u201cindexical\u201d statements\u00a0\u2013 such as \u201cyou,\u201d \u201cme,\u201d \u201chere,\u201d and \u201cthis\u201d\u00a0\u2013 which both scholars of discourse analysis and ethnomethodologists point to as being important means through which identity and interpersonal relations are expressed ( Fairclough, 1989), reflect-\ning how the posters view themselves and their relationship with their audi-ence. The word \u201cI,\u201d for instance, suggests a sense of individuality, whereas the use of \u201cwe\u201d suggests that writers view themselves as representing some -\nthing larger than individuals or mere aggregations. A\u00a0clear example of this is that new users wrote of \u201cI,\u201d but, over time, they often used \u201cwn\u201d\u00a0\u2013 short for \u201cwhite nationalists\u201d\u00a0\u2013 instead.\nMaking of an Imagined Community of Hate\nThe example above reveals how engaging with online communities trans-forms the self-understanding of the participants. Their discussions matter less for their content than for their role in defining a shared identity\u00a0\u2013 the content acts not as rational arguments but as symbols for community becoming. Nar -\nratives, internal jargon, and discussion topics are cultural capital that help define the boundaries of the community. Individuals acquire the language of a community and absorb its symbols, in ways that also transform their political identities.\nInteraction rituals both use and produce discursive symbols: an inter -\nnal culture that defines the community. These symbols simultaneously form the linguistic capital and emblems of group membership (Collins, 2004). The language that is shared and understood within the commu -\nnity provides barriers to outsiders; although anyone can read Stormfront postings, only those who are \u201cin the know\u201d can participate meaningfully. This function can be seen in how meme culture tends to exhibit complex \nFrom Echo Chambers to Digital Campfires  105\nlayers of intertextual references and abstract and ironic styles, constantly \nin flux and innovation, requiring both literacy and dedication to decode and stay up-to-date with the latest trends ( Knobel\u00a0 & Lankshear, 2007 ; \n Shifman, 2013 ; see also Walther, this volume). This challenge is precisely \nthe point ( Phillips\u00a0&  Milner, 2017 ): Language functions to create a subcul-\ntural definition of cultural capital that stands in opposition to mainstream culture. The subcultures thus define forms of distinction through a linguis -\ntic market, conferring cultural capital and authority on those who master the language (Bourdieu, 1991). Subcultural literacy separates insiders from outsiders through deliberate semantic disorientation of those who are unfa -\nmiliar with the subcultural logic and the values of the community that are reified through secret linguistic codes.\nThe turn to a Durkheimian perspective on online communities therefore \nhighlights the role of identity in online extremism, in distinction to the more automatic and mechanical view assumed by the echo chamber approach. The discussions on Stormfront seek not to convey rational arguments but to activate and trigger markers of social identities\u00a0\u2013 denigrating the out-group and rallying the in-group. They seek not to convince but rather to highlight similarities and differences: To identify an \u201cus\u201d and to separate out a \u201cthem.\u201d They operate in the realm of identity, not of rationality.\nWorldviews: Spaces for Interpreting Reality\nThe discussions on Stormfront are not only important as expressions of com -\nmunity belonging and shared identity: They are also important in themselves, as ways of understanding the world. The stories they share define how the members of the community identify problems and suggest solutions. Reality itself is always filtered through the narratives that they share. This means that participants do not respond to \u201cobjective\u201d threats or advocate realis -\ntic solutions; rather, threats and advocacies pass through a process of social construction and attribution ( Snow, 2004). Reality does constrain these \ninventions, and the stories must be explained with some degree of internal consistency. Ultimately, however, people do not seek accurate stories but sto -\nries that work for them in the social world. No one wants to be the villain of their own story. People seek stories in which they play the hero\u00a0\u2013 or if that is not available, at least the victim.\nMeasuring how Stormfront Makes Sense of the World\nTo study these processes of sense and meaning-making on Stormfront, we examined the processes through which the community came to build a nar -\nrative around two events that were especially important for the community: The U.S. presidential elections of Barack Obama in 2008, and of Donald \n106  Anton T\u00f6rnberg and Petter T\u00f6rnberg\nTrump in 2016. We used close readings of Stormfront forum postings to gen -\nerate qualitatively based identification of narrative themes within the corpus. \nWe also subjected the text to computer-based natural language processing and analyzed changes in the numbers of members in the platform as well as related search engine records. These methods, together, showed how Storm -\nfront members created a collective understanding of these events and how they responded to them intellectually and emotionally.\nThe 2008 election of Obama was a decisive moment for Stormfront, spur -\nring an unprecedented increase in user activity on the forum. The day after the election alone saw the single highest number of new members in the his -\ntory of the forum (2,581 new users on November 5, 2008). In line with this, Google Trends shows a dramatic increase in Google searches for \u201cStorm-front forum\u201d in November 2008, for which the most activity occurred on the day of the election. Similarly, the number of postings within Stormfront skyrocketed in the days around the election.\nWhen investigating the content of the posts in the immediate aftermath \nof the election, a dominant narrative emerged framing Obama as a threat to the country, a national disaster that would lead to chaos. Many users expressed frustration, desperation, and hopelessness. As one member con -\ncisely put it, \u201cThis country is finished. This empire, this civilization, this cul -\nture.\u00a0.\u00a0.\u00a0. I\u00a0don\u2019t honestly believe there are nearly enough people who are, or ever will be willing to fight for its survival.\u201d Many members seemed to fear that chaos would ensue, and that \u201cnegro rule\u201d would drive American cities to become \u201ccrime-ridden, bankrupt slums.\u201d Along these lines, the election was described as a catalyst that would embolden the Black population in the United States, representing the start of \u201cwhite slavery\u201d that would ultimately lead to the end of the white race. (For instance, word frequency analysis showed that the usage of the terms \u201cslave\u201d and \u201cslavery\u201d increased by 50% during the days surrounding the election, compared to the average during the two prior weeks.)\nHowever, only a few days after the election, a competing narrative emerged \nin the Stormfront community, reconstructing Obama\u2019s election as a unique opportunity for the white people. The underlying idea in this narrative was that \u201cworse-is-better\u201d\u2013 that the threat of Obama\u2019s presidency would serve as a wake-up call or an eye-opener for white people, increasing racial awareness \nand contributing to racial polarization, thereby serving as a potential catalyst for radical change. As one user expressed this,\nI think we should see this as more of an opportunity to change the world in which we live for the better. Maybe this is a new chance to recruit and spread our message faster and further than ever before. Remember, things will get much worse before they begin to get better and Obama might speed this process for us.\nFrom Echo Chambers to Digital Campfires  107\nThis discursive shift in the community sparked a self-critical discussion \namong members to reconsider support for established strategies and meth -\nods within White Supremacist movements. Many subsequent discussions thus circulated around whether people should \u201cfight within the system\u201d or \u201cfight the system\u201d in which most users expressed skepticism toward the idea and feasibility of achieving radical political change through the system. One user summarized, \u201cWe cannot win by the ballot box.\u201d While few members believed that a political revolution would be realistic at the time, it was more common to advocate for creating autonomous, model, separatist communi-ties, a \u201cStormfront on the streets.\u201d\nIn contrast, the 2016 election of Trump sparked significantly less dramatic \nchanges in users\u2019 activity on Stormfront, with few newly registered users and only minor increases in posting activity. The discussions during the first days after the election were characterized by optimism and anticipation, with many triumphant and celebratory posts, typically framing the election as a victory for the white race. For instance:\nIt will be a major deterrent and a symbol that they [immigrants] are not as welcome as they thought they once were. The illegals will roam streets and be reported and arrested. The wall will inspire patriotism in several Whites. This election has been a turnaround for us.\nSome members remained more skeptical about Trump, emphasizing that he could not be trusted. More generally, however, we observed a general discur -\nsive shift in the community, moving from the worse-is-better narrative that dominated discourse after Obama\u2019s election to a better-is-better narrative, one that framed Trump\u2019s election as a positive opportunity and source of momentum. Simultaneously, we observed a related shift in political advo -\ncacy, from promoting extra-parliamentary methods that dominated discus -\nsions after Obama to an increasing belief in the possibilities of achieving radical change through the established political system. A\u00a0majority of the members now argued that Trump\u2019s presidency served to legitimize White Supremacist movements and to open (discursive) space within the established political system to air ideas that were previously banned and stigmatized. As one member expressed this: \u201cWe should be peaceful and solve our problems through the \u2018system,\u2019 abiding by all the laws, and setting examples such that we become role models for everyone to emulate.\u201d\nThis shift in perspective was accompanied with decreasing skepticism \ntoward the government and other established political institutions. Our word-embedding analysis of the representation of out-groups on Stormfront illustrated that \u201cBlacks,\u201d \u201cminorities,\u201d and \u201cJews\u201d were consistently the most frequently recurring oppositional categories on the forum. However, \u201cIllegals\u201d and \u201cinvaders\u201d became more salient as an out-group following \n108  Anton T\u00f6rnberg and Petter T\u00f6rnberg\nthe election of Trump, and, more intriguing, terms such as \u201cgovernment,\u201d \n\u201czog,\u201d and \u201cpolice\u201d decreased in significance as out-groups, indicating that members may have become less skeptical toward the government and estab -\nlished political institutions. Trump was seen as an entrance for people like them to political power, and members started to reformulate the optimal goals in relation to the government by defining their roles and functions as to \u201cinfluence Trump,\u201d to \u201cpush him to the right,\u201d and\u00a0\u2013 commonly\u00a0\u2013 to be \u201cfire to his feet.\u201d\nA Tribal Epistemology\nThe analysis above illustrates how communities collectively construct an understanding of political events. It is evident that the discursive creation of opportunity was a consistent driver of the framing process, aimed at iden -\ntifying an optimistic interpretation. Participants thus bend, reformulate, recontextualize, and narrativize events to make them appear beneficial. This can be referred to as a type of \u201ctribal epistemology.\u201d Contrary to the echo chamber thesis, political communities do not primarily develop their world -\nviews through rational deliberation and critical reasoning ( Roberts, 2017). \nInstead, their perception of the world is influenced by their specific interests and wishes\u00a0\u2013 what they want to be true. Communities do not choose their positions based on rational evaluation of evidence, arguments, and counter -\narguments; rather, they choose positions that support their tribe\u2019s values and goals. Their reasoning and comprehension of the world are inseparable from their identity and sense of community (Funkhouser, 2022).\nThis perspective also provides an explanation for the observed link \nbetween online communities and the rise of misinformation. These spaces allow for the growth of conspiracies that are detached from reality, as mem -\nbers strongly desire something to be true in order to maintain their connec -\ntion with their community. Truth is only perceived through the white-tinted lens of identity, as information is assessed not based on common standards of evidence applied to commonly accepted facts but on its alignment with the requirements of ones\u2019 community (see also, e.g., Kahan, 2013). The ways of \nknowing become defined by ones\u2019 identity and belonging, reducing what they know to merely another expression of who they are. \u201cGood for our side\u201d and \u201ctrue\u201d begin to blur into one.\nSpaces for Verbalizing and Transforming Emotions\nExchanging messages in Stormfront thus socially facilitates the construc -\ntion of a shared worldview among members. Since these messages are tightly entangled with the identities and self-understanding of the members, they are not merely descriptions of the world but are also deeply emotionally charged. Their stories are not only narrated but\u00a0\u2013 as reflected in their language\u00a0\u2013 are \nFrom Echo Chambers to Digital Campfires  109\nalso viscerally felt. As Durkheim emphasizes, rituals are highly emotional \nexperiences. Participants in rituals perceive them as pleasurable, filling them with what Durkheim refers to as collective effervescence: A\u00a0positive feeling of \nemotional energy that encourages participants to remain in the community, often manifested as confidence, warmth, and enthusiasm.\nCapturing Emotional Processes among White Supremacists\nIn exploring these emotional dimensions of online rituals, we revisited the Stormfront postings that followed the 2008 election of Barack Obama, using sentiment analysis and close reading (T\u00f6rnberg\u00a0& T\u00f6rnberg, 2023). As previ-ously noted, the election sparked an unprecedented surge in the entry of new members to Stormfront. For many of these members, the election was experi -\nenced as deeply unsettling\u00a0\u2013 a threat against something unspoken at the very core of who they understood themselves as white Americans. When compar -\ning the reactions to the election by these newly registered members to those of long-term members of Stormfront, we discovered a surprising pattern.\nLong-term members reflected a relatively well-established sense of col-\nlective identity. This sub-corpus was distinguished by the extensive use of \u201cwe,\u201d often found in word collocations such as \u201cWe whites,\u201d \u201cWe national -\nists,\u201d \u201cWe fighting,\u201d \u201cWe act,\u201d and \u201cWe want.\u201d Moreover, this group has a narrative in place in which Jews were portrayed as the master enemy, with top-ranked word pairs such as \u201cJews their,\u201d \u201cJewish media,\u201d \u201cJewish influ -\nence,\u201d \u201cJews us,\u201d and \u201cJews control.\u201d Consistent with this narrative, these members perceived the election as a regrettable yet anticipated event, a fore -\nseeable consequence of the \u201cprevailing Jewish order.\u201d As one user expressed,\nAre we losing sight of the fact that Obama is just a figurehead puppet? Do you really think that Obama controls anything? International jewry is the greatest threat, hands down. Obama is an impotent house negro, nothing more.\nThese members\u2019 messages presented long-established grievances, and the election did not challenge their identities or compel them to reevaluate fun -\ndamental beliefs. If anything, Obama\u2019s election enabled long-term members to (re-)enforce their worldviews, solidify their solidarity, and intensify their sense of \u201cwe-ness.\u201d This narrative focusing on Jews, along with the mem -\nbers\u2019 social and discursive integration within the community, seems to have functioned as a shock-absorber, shielding them from the adverse effects of the traumatic event. It provided meaning and coherence, narrating a story of what happened, who is culpable, and what needs to be done.\nThe postings by newly registered members, in contrast, suggest that they \nwere severely affected by the election. These individuals lacked the means to cope with the election\u2019s outcome; more specifically, their established \n110 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nworldview, which relied on viewing Blacks as belonging to a subordinated \nrace, was upended when a Black man was elected president, resulting in trauma. When examining keywords characterizing their sub-corpus, the sin-gle most frequent word collocation is \u201cI White,\u201d followed by \u201cI American,\u201d \u201cI People,\u201d \u201cI nationalist,\u201d \u201cI race,\u201d and \u201cI country.\u201d The absence of \u201cwe\u201d suggests that they are less inclined to identify themselves as part of a clearly defined in-group; instead, they describe themselves as individuals belonging to broader and more abstract categories or ethnic groups.\nComparative sentiment analysis showed that these new members expressed \nsignificantly more intense negative emotions, compared to the long-term members. Words indicating shame, disgust, and nausea were particularly prevalent in this sub-corpus, with expressions like: \u201cLast night made me sick to my stomach,\u201d \u201cI\u2019m heartsick and saddened,\u201d \u201cI vomit in my mouth a bit,\u201d and \u201cI want to puke.\u201d Many of these reports of strong visceral, bodily reactions were related to the members\u2019 observations that a person from an allegedly \u201cinferior\u201d race won the election and the possibility of white people being \u201csubordinated to Blacks.\u201d\nThe national disgrace! To elect a representative of a sub-human black race that is so hostile and hateful to the white people; that is the ENEMY of the white people; that is despicable and disgusting; that is so inferior to the white people; that is so destructive to the society; that never belonged among the white people. Shame on you!\nMany new members thus grappled with the contradiction that a person from an alleged \u201cinferior\u201d race could hold the same position of power as a series of \u201cdignified\u201d white presidents before him, framing the election result as a threat to the white race and expressing fears of becoming a minority and being discriminated against. As we have seen, while long-term members resolved this apparent contradiction by focusing on Jews as the primary tar -\nget and out-group (thus viewing Obama as merely a \u201cJewish puppet\u201d), new members identified Black people as the main concern and the most promi -\nnent out-group. In fact, there are no highly ranked words or word pairs relating to Jews in the sub-corpus of new members\u2019 postings. Consequently, the election posed a fundamental challenge to these new members who based their identity and self-value on social comparison with other races and the devaluation of Black people.\nThe election was repeatedly and explicitly described as a turning point for \nnew forum members, influencing their decision to register and actively post messages for one another within the Stormfront community. Many expressed a need to \u201ctake action\u201d and \u201cdo something\u201d in response to the event, while also seeking comfort, moral support, and a means of making sense of their distress. For instance: \u201cI have been reading for some time, but this was the \nFrom Echo Chambers to Digital Campfires  111\nfinal tipping point, I\u00a0felt compelled to register and post\u201d and \u201cover the years \nmy concerns has grown this was a tipping point.\u201d The election thus served as a trigger or a \u201cmoral shock\u201d ( Snow\u00a0& Soule, 2010 ; Warren, 2010) that pro -\npelled these individuals to join Stormfront in order to process their trauma, as well as to seek moral and social support and belonging.\nUpon joining the community, new members engaged in developing new \nnarratives to provide coherence and meaning to the situation. They achieved this by sharing personalized stories of past injustices, alleged offenses, assaults, and violence purportedly committed by Black people against white people, which served to ignite a sense of moral outrage. These stories often featured an idealized victim, such as a young woman or daughter, who had allegedly been assaulted. For instance:\nLast night made me so sick to my stomach. One of my female friends was robbed of all her things. I\u00a0saw black teens harassing white cops, saying they aren\u2019t **** [sic] and don\u2019t matter. I\u00a0think I\u00a0vomited in my mouth.\nBy sharing these stories, the new members of the community collectively cul-tivated anger and outrage toward outsiders. In their discussions, they iden -\ntified concrete and specific adversaries, shifting attention from the specific \u201cdisaster\u201d of the election and the resulting feelings of grief and despair to focus instead on the corruption and dangerous nature of their enemies. In this way, the indignities of daily life are transformed into a shared grievance with a focused target of collective action.\nImportantly, the social and interactive processes of formulating these new \nnarratives, in which members come together and synchronize their thoughts and actions, can itself be a powerful tool for healing and strengthening col -\nlective identity and in-group solidarity. These collective gatherings\u00a0\u2013 or com -\nmunity rituals\u00a0\u2013 involve both shared and reciprocal emotions (Jasper, 2008).\nShared emotions refer to the collective emotional experiences that arise \nfrom a common cause or event, such as a shared trauma or a victory. These emotions reflect how the group collectively nurtures anger toward outsid -\ners, such as outrage over government policies. This process is particularly evident in some of these narratives: While the stories depict concrete and actual events that involve Black people, they simultaneously emphasize that violence and immoral acts are inherent in the very nature of Black people. In this manner, members connect broader sociocultural forces with human agents who are appropriate targets of collective action. Through this type of cognitive reframing, the members thus transform passive emotions, such as dread, hopelessness, fear, resignation, shame, and disgust, into active emotions, such as moral indignation and outrage, which provide better foundations both for their demands of as well as for their collective iden -\ntity. While resignation can dampen the perceived opportunity for change, \n112 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nemotions like anger, indignation, and pride are commonly associated with \npolitical agency (Jasper, 2011). In contrast, the established, long-term members do not need this: Their grievances are firmly established\u00a0\u2013 they are already angry.\nReciprocal emotions include emotions individuals experience in response \nto others\u2019 emotions within a group or social context. When one person expresses anger or sadness about an issue, others may reciprocate these emo-tions, leading to a shared emotional experience that bolsters social bonds and strengthens group cohesion. On Stormfront, this can be seen in the expressions of social bonding and support among members. Members have thanked each other for receiving support and being welcomed to the forum. Many claimed that their reason for joining the forum was to find moral and social support and a protected space to discuss with like-minded people. As one user put it: \u201cI came here to converse and find solidarity with fellow White Nationalists.\u201d Through these posts and the ensuing discussions, mem -\nbers forged personal bonds of friendship and loyalty, and enhanced feelings of trust and solidarity, as expressed in these two posts: \u201cI\u2019d just like to thank everyone for responding to my posts and for the most part being respect-ful\u201d; \u201cVery happy to have joined SF, glad to have joined this site, the election has fired up my desire to reach out to other whites.\u201d Participating in these positively toned interactions reinforces a common identity and bolsters per -\nsonal and collective self-esteem\u00a0\u2013 similar to De Koster and Houtman\u2019s (2008) emphasis on Stormfront messages as sources of sociability, resulting in com -\nmunal solidarity among members. Both the notions of shared and recipro -\ncal emotions underscore the significance of emotional exchanges in shaping social interactions and collective action.\nOnline Therapy for White Supremacists\nOur analysis reveals that Stormfront serves not only as a refuge for the far-right to express conventionally distasteful opinions and ideas ( de Koster\u00a0& \nHoutman, 2008) but also as an \u201cemotional refuge\u201d (Reddy, 2001), providing space and legitimacy to their emotional experiences. This speaks to Ganesh's \n(2018, pp.\u00a033\u201334) suggestion that, for the far right, what unites communities online are \u201cforms of intimacy, sense, and feeling that are maligned or consid -\nered unacceptable in mainstream society.\u201d\nThe 2008 election of Obama drove a large number of individuals to join \nthe community, driven by an unarticulated sense of confusion, discomfort, and anxiety. A\u00a0Black president seemed to question not only something at the very core of their identity as white Americans but also something to which they had never put words\u00a0\u2013 a feeling that felt forbidden to utter in main -\nstream society. Stormfront offered a space to meet others who had the same experience and offered a new narrative\u00a0\u2013 White Supremacy\u00a0\u2013 to explain why \nit felt wrong and to legitimize their experience. The White Supremacy that is \nFrom Echo Chambers to Digital Campfires  113\npart of American history and culture\u00a0\u2013 and still rooted in its collective uncon -\nscious\u00a0\u2013 was thus put proudly forth, not as a shameful legacy of slavery, but \nas a proud badge of honor. Thus, while one may believe that communities such as Stormfront merely draw a collection of already radicalized extrem-ists, our analysis shows that it does not merely gather them but also trans-forms them as it brings them into an extremist community.\nBoth the trauma narratives themselves and the participation in the collec-\ntive processes that generate them impart meaning and coherence to feelings of pain, fear, and confusion. By supporting and encouraging each other (recip -\nrocal emotions) and collectively diagnosing and describing shared injustices and grievances (shared emotions), members on Stormfront created a sense of unity and solidarity, reinforcing their collective identity and commitment to a common goal. Through social rituals of online interaction, their feelings of shame, despair, depression, and disgust are thus transformed into solidarity in the community. They felt one with the community. The vague sense of dif -\nference was replaced by an articulated belief in the superiority of the white race. They were the heroes of their stories once again. In this experience of emotional communion, individuals forged a sense of social belonging and shared beliefs. Pain turned into anger, thence hatred.\nStormfront functioned as a form of online therapy group for White Suprem -\nacists, where members vented, articulated, and collectively made sense of their emotional reactions, thereby shaping an emotionally energized collec -\ntive with a focused target of collective action. Spaces like Stormfront can thus enable counterreactions and backlashes to events perceived as threatening to their community or identity, leading to emotionally charged mobilizations. These rituals of narrative construction are collective, bottom-up processes involving many members, rather than being strategically shaped by indi -\nvidual leaders, as is often described in social movement literature (see e.g. Oliver\u00a0& Johnston, 2000).\nConclusion: From Echo Chambers to Digital Campfires\nThe concept of the echo chamber emerged as a response to the suggestion that social media would usher in a new era of democratization by serving as new critical-rational public sphere. While the echo chamber thesis posited that the Internet might enable us to avoid engaging with political opponents, it never interrogated the underlying assumption that political life ultimately is constituted solely in rational debate. Throughout the many characteriza -\ntions of the nature of digital media participation, this rationalist assumption has been a widely accepted presupposition: Whether delivered by algorithms, sociometric choices, or both, politics primarily concerns opinions, and these opinions are in turn the product of rational arguments and information. These tenets have been the unchallenged foundations of analyses, focusing on the potential existence of online echo chambers.\n114 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nIn this chapter, we have laid the groundwork for an alternative paradigm \nfor understanding online extremism and hate messages. Politics is not merely \nabout opinions, we have argued, but exists in the social realm, encompassing identity, emotion, and discourse. Similarly, online interaction is not exclu-sively focused on the rational and individual consumption of information; it is a social process of mutual influence and co-creation. As an alternative to the rationalist paradigm, this chapter has proposed a Durkheimian inter -\npretation of digital media, viewing online interaction as a form of ritual. This casts online communities like Stormfront as a tribe gathered around a campfire, creating a shared narrative of belonging and identity through their stories and emotional exchanges. The content of the messages functions as a symbolic marker of identity rather than rational facts. As in Aboriginal chanting, the words are no more important than the rhythm, the feeling, and the sense of shared activity that the words convey.\nWhile the echo chamber hypothesis of radicalization emphasizes the \nimpact of reading and consuming others\u2019 posts, the perspective introduced in this chapter underscores participation\u00a0\u2013 actively conversing, posting, and sharing experiences\u00a0\u2013 as the primary driver of radicalization. Simply consum -\ning content related to a subject, whether through newspapers, television, or social media, can cultivate interest and shape opinions on it, but it does not foster a sense of community. On the other hand, active participation and dia -\nlogue online resonate at a deeper, emotional level, nurturing the emergence of shared identity through the articulation of a view of the world.\nOn Stormfront, the community is centered around a shared activity and \nmood defined by the unified hatred of Jews\u00a0\u2013 a totem that unites the com -\nmunity. On this foundation, an entire worldview is erected, simultaneously representing the shared identity of the members and distinguishing insiders from outsiders. Blacks are subhuman. Jews are engaged in a conspiracy to enslave and replace white people. To the extent that such views are linked to ostensibly rational arguments, the latter are expressions, not causes, of the \ncommunity belonging.\nBy considering the interactions within fringe extremist spaces as rituals \nrather than rational deliberations, we can better understand the emotional dynamics that drive individuals to participate in extremist communities and the social processes through which these communities maintain their cohesion and vitality. This approach also allows us to identify the ways in which online spaces can amplify and reinforce the narratives and symbols that underpin extremist ideologies, thus promoting their dissemination and persistence.\nReferences\nAmarasingam, A.,\u00a0 & Argentino, M. A. (2020).  The QAnon conspiracy theory: \nA\u00a0security threat in the making. CTC Sentinel, 13(7), 37\u201344.\nFrom Echo Chambers to Digital Campfires  115\nBail, C. (2022). Breaking the social media prism: How to make our platforms less \npolarizing. Princeton University Press.\nBail, C. A., Argyle, L. P., Brown, T. W., Bumpus, J. P., Chen, H., Hunzaker, M. F., Lee, \nJ., Mann, M., Merhout, F.,\u00a0& Volfovsky, A. (2018).  Exposure to opposing views on \nsocial media can increase political polarization. Proceedings of the National Acad -\nemy of Sciences, 115(37), 9216\u20139221. https://doi.org/10.1073/pnas.1804840115\nBeirich, H. (2014, May 24). White homicide worldwide: Stormfront, the leading \nwhite supremacist web forum has another distinction\u00a0\u2013 murder capital of the inter -\nnet. Southern Poverty Law Center Intelligence Report. https://www.splcenter.org/\nfighting-hate/intelligence-report/2014/white-homicide-worldwide\nB\u00e9langer, J. J., Nisa, C. F., Schumpe, B. M., Gurmu, T., Williams, M. J.,\u00a0& Putra, I. \nE. (2020). Do counter-narratives reduce support for ISIS? Yes, but not for their \ntarget audience. Frontiers in Psychology, 11, 1059. https://doi.org/10.3389/\nfpsyg.2020.01059\nBenford, R. D. (1997). An insider\u2019s critique of the social movement framing perspective. \nSociological Inquiry, 67(4), 409\u2013430. https://doi.org/10.1111/j.1475-682x.1997.\ntb00445.x\nBenford, R. D.,\u00a0& Snow, D. A. (2000).  Framing processes and social movements: An \noverview and assessment. Annual Review of Sociology , 26(1), 611\u2013639. https://\ndoi.org/10.1146/annurev.soc.26.1.611\nBerglind, T., Pelzer, B.,\u00a0& Kaati, L. (2019, August).  Levels of hate in online envi -\nronments. In\u00a0 Proceedings of the 2019 IEEE/ACM international conference \non advances in social networks analysis and mining \u00a0(pp.\u00a0842\u2013847). https://doi.\norg/10.1145/3341161.3343521\nBerinsky, A. J. (2017). Rumors and health care reform: Experiments in political \nmisinformation. British Journal of Political Science , 47(2), 241\u2013262. https://doi.\norg/10.1017/s0007123415000186\nBourdieu, P. (1991). Language and symbolic power. Harvard University Press.Bowman-Grieve, L. (2009). Exploring \u201cStormfront\u201d: A\u00a0 virtual community of the \nradical right. Studies in Conflict and Terrorism , 32(11), 989\u20131007. https://doi.\norg/10.1080/10576100903259951\nBright, J., Marchal, N., Ganesh, B.,\u00a0& Rudinac, S. (2022).  How do individuals in a \nradical echo chamber react to opposing views? Evidence from a content analy -\nsis of stormfront. Human Communication Research, 48(1), 116\u2013145. https://doi.\norg/10.1093/hcr/hqab020\nBrundidge, J. (2010).  Encountering \u201cdifference\u201d in the contemporary public \nsphere: The contribution of the Internet to the heterogeneity of political dis -\ncussion networks. Journal of Communication , 60(4), 680\u2013700. https://doi.\norg/10.1111/j.1460-2466.2010.01509.x\nBurston, A. (Chapter\u00a0 2 this volume). Digitally mediated spillover as a catalyst of \nradicalization: How digital hate movements shape conservative youth activism.\nChua, A. (2019).\u00a0Political tribes: Group instinct and the fate of nations. Penguin.Collins, R. (2004). Interaction ritual chains. Princeton University Press.Couldry, N.,\u00a0 & Hepp, A. (2018).  The mediated construction of reality . John \nWiley\u00a0& Sons.\nde Koster, W.,\u00a0& Houtman, D. (2008). \u2018STORMFRONT IS LIKE A SECOND HOME TO \nME\u2019 On virtual community formation by right-wing extremists. Information, Commu-\nnication\u00a0& Society, 11(8), 1155\u20131176. https://doi.org/10.1080/13691180802266665\nDiMaggio, P., Bernier, C., Heckscher, C.,\u00a0 & Mimno, D. (2018).\n Interaction ritual \nthreads: Does IRC theory apply online? In E. B. Weininger, A. Lareau,\u00a0& O. Liz-ardo (Eds.), Ritual, emotion, violence (pp.\u00a099\u2013142). Routledge.\nDubois, E.,\u00a0& Blank, G. (2018). The echo chamber is overstated: The moderating \neffect of political interest and diverse media. Information, Communication\u00a0& Soci-\nety, 21(5), 729\u2013745. https://doi.org/10.1080/1369118x.2018.1428656\n116 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nDurkheim, E. (1915). The elementary forms of the religious life . Free Press. (Les \nFormes \u00e9l\u00e9mentarires de la vie religieuse: le syst\u00e9me tot\u00e9meque en Australie, Paris: \nAlcan). (Original work published 1912)\nFairclough, N. (1989). Language and power. Longman.Funkhouser, E. (2022). A\u00a0tribal mind: Beliefs that signal group identity or commit-\nment. Mind\u00a0& Language, 37(3), 444\u2013464. https://doi.org/10.1111/mila.12326\nGanesh, B. (2018).  The ungovernability of digital hate culture. Journal of Interna -\ntional Affairs, 71(2), 30\u201349. https://www.jstor.org/stable/26552328\nGonz\u00e1lez-Bail\u00f3n, S., Lazer, D., Barber\u00e1, P., Zhang, M., Allcott, H., Brown, T., \nCrespo-Tenorio, A., Freelon, D., Gentzkow, M., Guess, A. M., Iyengar, S., Kim, Y. M., Malhotra, N., Moehler, D., Nyhan, B., Pan, J., Rivera, C. V., Settle, J., Thorson, E.,\u00a0.\u00a0.\u00a0.\u00a0& Tucker, J. A. (2023).  Asymmetric ideological segregation in \nexposure to political news on Facebook.\u00a0 Science,\u00a0 381(6656), 392\u2013398. https://doi.\norg/10.1126/science.ade7138\nHabermas, J. (1989).  The structural transformation of the public sphere: An inquiry \ninto a category of bourgeois society. Polity.\nHamm, M. S.,\u00a0& Spaaij, R. (2017).  The age of lone wolf terrorism . Columbia Uni -\nversity Press.\nHartzell, S. L. (2020). Whiteness feels good here: Interrogating white national -\nist rhetoric on stormfront. Communication and Critical/Cultural Studies , 17(2), \n129\u2013148. https://doi.org/10.1080/14791420.2020.1745858\nHassan, G., Brouillette-Alarie, S., Alava, S., Frau-Meigs, D., Lavoie, L., Fetiu, A., \nVarela, W., Borokhovski, E., Venkatesh, V.,\u00a0& Rousseau, C. (2018). Exposure to extremist online content could lead to violent radicalization: A\u00a0systematic review of empirical evidence. International Journal of Developmental Science , 12(1\u20132), \n71\u201388. https://doi.org/10.3233/dev-170233\nHemmingsen, A.-S.,\u00a0& Castro, K. I. (2017).  The trouble with counter-narratives . Dan-\nish Institute for International Studies Report. http://pure.diis.dk/ws/files/784884/\nDIIS_RP_2017_1.pdf\nIyengar, S., Lelkes, Y., Levendusky, M., Malhotra, N.,\u00a0 & Westwood, S. J. \n(2019). The origins and consequences of affective polarization in the United States.\u00a0 Annual Review of Political Science ,\u00a022, 129\u2013146. https://doi.org/10.1146/\nannurev-polisci-051117-073034\nJasper, J. (2008). The art of moral protest: Culture, biography, and creativity in social \nmovements. University of Chicago Press.\nJasper, J. (2011). Emotions and social movements: Twenty years of theory and \nresearch. Annual Review of Sociology, 37, 285\u2013303. https://doi.org/10.1146/\nannurev-soc-081309-150015\nJoachims, T. (2002). \u00a0Learning to classify text using support vector machines \u00a0(Vol. 668). \nSpringer Science\u00a0& Business Media.\nJohannessen, L. E. (2023, June). Interaction rituals and technology: A\u00a0review essay. \nPoetics, 98. https://doi.org/10.1016/j.poetic.2023.101765\nJungherr, A., Rivero, G.,\u00a0& Gayo-Avello, D. (2020). Retooling politics: How digital \nmedia are shaping democracy. Cambridge University Press.\nKahan, D. M. (2013).  Ideology, motivated reasoning, and cognitive reflec -\ntion.\u00a0 Judgment and Decision Making,\u00a0 8(4), 407\u2013424. https://doi.org/10.1017/\ns1930297500005271\nKarell, D., Linke, A., Holland, E.,\u00a0& Hendrickson, E. (2023). \u201cBorn for a storm\u201d: \nHard-right social media and civil unrest. \nAmerican Sociological Review, 88(2), \n322\u2013349. https://doi.org/10.1177/00031224231156190\nKarlsen, R., Steen-Johnsen, K., Wolleb\u00e6k, D.,\u00a0& Enjol ras, B. (2017). Echo chamber \nand trench warfare dynamics in online debates. European Journal of Communica-tion, 32(3), 257\u2013273. https://doi.org/10.1177/0267323117695734\nFrom Echo Chambers to Digital Campfires  117\nKeuchenius, A., T\u00f6rnberg, P.,\u00a0& Uitermark, J. (2021).  Why it is important to consider \nnegative ties when studying polarized debates: A\u00a0 signed network analysis of a \nDutch cultural controversy on Twitter. PLoS One, 16(8), e0256696. https://doi.\norg/10.1371/journal.pone.0256696\nKnobel, M.,\u00a0& Lankshear, C. (2007).  Online memes, affinities, and cultural produc -\ntion. In M. Knobel\u00a0& C. Lankshear (Eds.), A new literacies sampler  (pp.\u00a0199\u2013227). \nPeter Lang.\nLevin, B. (2002). Cyberhate: A\u00a0legal and historical analysis of extremists\u2019 use of com -\nputer networks in America. American Behavioral Scientist, 45(6), 958\u2013988.\nLewandowsky, S., Ecker, U. K., Seifert, C. M., Schwarz, N.,\u00a0 & Cook, J. (2012).  \nMisinformation and its correction: Continued influence and successful debias-ing. Psychological Science in the Public Interest , 13(3), 106\u2013131. https://doi.\norg/10.1177/1529100612451018\nLupu, Y., Sear, R., Vel\u00e1squez, N., Leahy, R., Restrepo, N. J., Goldberg, B.,\u00a0& John -\nson, N. F. (2023). Offline events and online hate.\u00a0 PLoS One,\u00a0 18(1). https://doi.\norg/10.1371/journal.pone.0278511\nMason, L. (2018).\u00a0 Uncivil agreement: How politics became our identity. University \nof Chicago Press.\nMcKelvey, T. (2001, October 31).  Father and son team on hate site. USA Today.com. \nhttps://www.usatoday.com/life/2001-07-16-kid-hatesites.htm\nMcPherson, M., Smith-Lovin, L.,\u00a0& Cook, J. M. (2001).  Birds of a feather: Homoph -\nily in social networks. Annual Review of Sociology , 27(1), 415\u2013444. https://doi.\norg/10.1146/annurev.soc.27.1.415\nMiller-Idriss, C. (2022).  Hate in the homeland: The new global far right . Princeton \nUniversity Press.\nM\u00fcller, K.,\u00a0& Schwarz, C. (2021). Fanning the flames of hate: Social media and hate \ncrime. Journal of the European Economic Association , 19(4), 2131\u20132167. https://\ndoi.org/10.1093/jeea/jvaa045\nM\u00fcller, K.,\u00a0 & Schwarz, C. (2023).  From hashtag to hate crime: Twitter and \nanti-minority sentiment. American Economic Journal: Applied Economics , 15(3), \n270\u2013312. https://doi.org/10.1257/app.20210211\nNyhan, B., Reifler, J., Richey, S.,\u00a0& Freed, G. L. (2014). Effective messages in vac-\ncine promotion: A\u00a0 randomized trial. Pediatrics, 133(4), e835-e842. https://doi.\norg/10.1542/peds.2013-2365\nOliver, P.,\u00a0& Johnston, H. (2000). What a good idea! Frames and ideologies in social \nmovements research. Mobilization: An International Journal , 5(1), 37\u201354. https://\ndoi.org/10.17813/maiq.5.1.g54k222086346251\nPariser, E. (2011). The filter bubble: What the Internet is hiding from you. Penguin.Phadke, S.,\u00a0& Mitra, T. ( Chapter\u00a09 this volume). Inter-platform information sharing, roles, \nand information differences that exemplify social processes of online hate groups.\nPhillips, W.,\u00a0& Milner, R. M. (2017).  Decoding memes: Barthes\u2019 punctum, feminist \nstandpoint theory, and the political significance of #yesallwomen. In S. Harrington (Ed.), Entertainment values: How do we assess entertainment and why does it \nmatter? (pp.\u00a0195\u2013211). Palgrave.\nPolkinghorne, D. E. (1988). Narrative knowing and the human sciences . SUNY Press.\nRavndal, J. A. (2016). Right-wing terrorism and violence in Western Europe: Intro-\nducing the RTV dataset. \nPerspectives on Terrorism, 10(3), 2\u201315. www.sv.uio.\nno/c-rex/english/groups/rtv-dataset/\nRavndal, J. A. (2018). Right-wing terrorism and militancy in the Nordic countries: \nA\u00a0comparative case study. Terrorism\u00a0& Political Violence, 30(5), 772\u2013792. https://\ndoi.org/10.1080/09546553.2018.1445888\nRea, S., Mathew, B.,\u00a0 & Kraemer, J. ( Chapter\u00a0 8 this volume). \u2018Hate parties\u2019: Net -\nworked antisemitism from the fringes to YouTube.\n118 Anton T\u00f6rnberg and Petter T\u00f6rnberg\nReddy, R. W. (2001).  The navigation of feeling: A\u00a0framework for the history of emo -\ntions. Cambridge University Press.\nRoberts, D. (2017, May 19).  Donald Trump and the rise of tribal epistemology. Vox Media . \nhttps://www.vox.com/policy-and-politics/2017/3/22/14762030/donald-trump-  \ntribal-epistemology\nSarbin, T. R. (1986).  Narrative psychology: The storied nature of human conduct. In \nT. R. Sarbin (Ed.), Narrative psychology: The storied nature of human conduct  \n(pp.\u00a03\u201321). Praeger.\nSchmitt, J. B., Rieger, D., Rutkowski, O.,\u00a0& Ernst, J. (2018).  Counter-messages as \nprevention or promotion of extremism?! The potential role of YouTube: Recom -\nmendation algorithms. Journal of Communication, 68(4), 780\u2013808. https://doi.\norg/10.1093/joc/jqy029\nSchwartz, S. J., Luyckx, K.,\u00a0& Vignoles, V. L. (Eds.). (2011).  Handbook of identity \ntheory and research. Springer.\nScrivens, R., Davies, G.,\u00a0 & Frank, R. (2020).  Measuring the evolution of radical \nright-wing posting behaviors online. Deviant Behavior, 41(2), 216\u2013232.\nShifman, L. (2013).  Memes in a digital world: Reconciling with a conceptual trouble -\nmaker. Journal of Computer-Mediated Communication , 18(3), 362\u2013377. https://\ndoi.org/10.1111/jcc4.12013\nSnow, D. (2004). Framing processes, ideology, and discursive fields. In D. Snow, \nS. A. Soule,\u00a0& H. Kriesi (Eds.), The Blackwell companion to social movements  \n(pp.\u00a0380\u2013412). John Wiley\u00a0& Sons.\nSnow, D.,\u00a0& Soule, S. (2010). A primer on social movements. W. W. Norton.\nSoares, F. B., Recuero, R.,\u00a0& Zago, G. (2019).  Asymmetric polarization on Twit -\nter and the 2018 Brazilian presidential elections. In\u00a0 Proceedings of the 10th \ninternational conference on social media and society \u00a0 (pp.\u00a0 67\u201376). https://doi.\norg/10.1145/3328529.3328546\nSunstein, C. (2002). Republic.com. Princeton University Press.Sunstein, C. (2007). Republic.com 2.0. Princeton University Press.T\u00f6rnberg, A.,\u00a0& Nissen, A. (2022).  Mobilizing against Islam on social media: Hyper -\nlink networking among European far-right extra-parliamentary Facebook groups. Information, Communication\u00a0 & Society, 1\u201319. https://doi.org/10.1080/13691\n18X.2022.2118546\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. (2021).  \u201cWake-up call for the white race\u201d: How Storm -\nfront framed the elections of Obama and Trump. Mobilization: An International \nQuarterly,\u00a026(3), 285\u2013302. https://doi.org/10.17813/1086-671x-26-3-285\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P.\u00a0(2023). White supremacists anonymous: How digital \nmedia emotionally energize far-right movements.\u00a0 Journal of Information Technol -\nogy\u00a0& Politics (Online First). https://doi.org/10.1080/19331681.2023.2262459\nT\u00f6rnberg, A.,\u00a0& Wahlstr\u00f6m, M. (2018).  Unveiling the radical right online: Exploring \nframing and identity in an online anti-immigrant discussion group. Sociologisk \nforskning, 55(2\u20133), 267\u2013292. https://doi.org/10.37062/sf.55.18193\nT\u00f6rnberg, P. (2022). How digital media drive affective polarization through partisan \nsorting. Proceedings of the National Academy of Sciences, 119(42), e2207159119. \nhttps://doi.org/10.1073/pnas.2207159119\nT\u00f6rnberg, P.,\u00a0 & T\u00f6rnberg, A. (2022). Inside a white power echo chamber: Why \nfringe digital spaces are polarizing politics. New Media\u00a0 & Society . https://doi.\norg/10.1177/14614448221122915\nTsesis, A. (2017). Terrorist speech on social media. Vanderbilt Law Review, 70\n(2), \n651\u2013708.\nWahlstr\u00f6m, M.,\u00a0 & T\u00f6rnberg, A. (2021).  Social media mechanisms for right-wing \npolitical violence in the 21st century: Discursive opportunities, group dynamics, and co-ordination. Terrorism and Political Violence , 33(4), 766\u2013787. https://doi.\norg/10.1080/09546553.2019.1586676\nFrom Echo Chambers to Digital Campfires  119\nWalther, J. B. (2022). Social media and online hate. Current Opinion in Psychology, \n45, 101298. https://doi.org/10.1016/j.copsyc.2021.12.010\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWalther, J. B.,\u00a0 & Burgoon, J. K. (1992). Relational communication in \ncomputer-mediated interaction. Human Communication Research, 19(1), 50\u201388. \nhttps://doi.org/10.1111/j.1468-2958.1992.tb00295.x\nWarren, M. R. (2010).  Fire in the heart: How white activists embrace racial justice . \nOxford University Press.\nW\u00e4sterfors, D., Burcar Alm, V.,\u00a0& Hannerz, E. (2023).  The bumpy paths of online \nsleuthing: Exploring the interactional accomplishment of familiarity, evidence, \nand authority in online crime discussions. New Media\u00a0 & Society. https://doi.\norg/10.1177/14614448221149909\nWojcieszak, M. E.,\u00a0& Mutz, D. C. (2009). Online groups and political discourse: Do \nonline discussion spaces facilitate exposure to political disagreement? Journal of \nCommunication, 59(1), 40\u201356. https://doi.org/10.1111/j.1460-2466.2008.01403.x\nWolfowicz, M., Hasisi, B.,\u00a0& Weisburd, D. (2022). What are the effects of different \nelements of media on radicalization outcomes? A\u00a0systematic review. Campbell Sys-\ntematic Reviews, 18(2), e1244. https://doi.org/10.1002/cl2.1244\nDOI: 10.4324/9781003472148-6\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.I had no idea about Sulli deals. And then finally I\u00a0saw this random girl\u00a0.\u00a0.\u00a0. \nwhen I\u00a0clicked on \u201cfind your sulli\u201d, [an image of] a girl popped up. I\u00a0had no idea. I\u00a0was still trying to understand. The second time I\u00a0clicked it, a friend of mine popped up. That\u2019s when I\u00a0realized ke yeh toh kuch galat he  \n[something is wrong]. Then the third or fourth time when I\u00a0checked, it was my picture [out] there! Aaargh, I\u00a0was disgusted, like what the hell!\n\u2013 Naziya\n[A]nd when my brother opened Twitter, he saw that there was a post where I\u00a0was being sold. It was written, \u201cenjoy, brother, enjoy this Sulli for 30 cents\u201d and some man was tagged. My brother was furious that we were being sold like prostitutes. And when I\u00a0say \u201cprostitute,\u201d I\u00a0don\u2019t say it in a derogatory way.\u00a0.\u00a0.\u00a0. It\u2019s just that we were seen as just a piece of meat. They didn\u2019t take our consent; they were just selling us like cows or buffaloes\u00a0.\u00a0.\u00a0. and for sexual trade! It was very bad\u00a0.\u00a0.\u00a0. my brother got mad.\u201d\n\u2013 Nadiya\nNaziya and Nadiya were recounting the horrific experiences of being \u201cauc -\ntioned\u201d online, two years after this incident erupted as a scandal in India in \n2021, stirring a nationwide media debate. The scandal revolved around a chain of events triggered by a \u201clive event\u201d on a YouTube channel, when a male right-wing \u2018celebrity\u2019 hosted what he described as an \u201cEid Special.\u201d The event paraded nonconsensually sourced images of Pakistani women, invit-ing the followers of the channel to survey the women\u2019s sexual worth and \u201cquench their lust with their eyes\u201d [\u201c aaj apni tharak bhari ankho se ladkiya \ntarenge,\u201d in Hindi].6\n\u201cDEAL\u201d OF THE DAY\nSex, Porn, and Political Hate on Social Media\nSahana Udupa and Oeendrila Lahiri Gerold\n\u201cDeal\u201d of the Day  121\nAfter the stream ended, numerous Twitter accounts proceeded to \u201cauc -\ntion\u201d Indian Muslim women, employing the same tactics by displaying non -\nconsensually obtained images and videos that were profiled as though they \nwere \u201citems on auction\u201d and encouraging users to browse and rate them. Prominent handles behind the auctions on Twitter were traced to the crea -\ntor of the first live event on YouTube and another Indian youth studying computer science at the time (Goyal, 2021; Taskin, 2022). Both were in their \ntwenties.\nIn a short span of time, the obscure online activity had snowballed. In \nJuly 2021, the media reported existence of a web application with the name \u201cSulli Deals\u201d on GitHub, an open-source software repository, which con -\nducted similar online auctions of minority Muslim women derisively labeled as \u201cSulli\u201d (Goyal, 2021).\n1 The app had been created almost a month earlier, \nand a Twitter handle with the same name and other allied handles shared screenshots of the \u201cdeals of the day\u201d and linked the GitHub page in their \u201cbio\u201d to promote the content ( Zubair et\u00a0al., 2021 ). The handles invited users \nto the landing page of the app \u201cSulli Deals,\u201d where a randomly selected photograph of a Muslim woman was showcased as \u201cSulli of the day\u201d ( Fazili, \n2022). Images were sourced from the web of over 90 Muslim women with -\nout their consent. Users could browse the application for the entire \u201ccollec -\ntion\u201d of Muslim women. A\u00a0slew of police complaints and law enforcement actions ensued.\nLaw and order actions and media exposures notwithstanding, the auction \npractice continued to persist. In January 2022, yet another \u201cauction\u201d app appeared on GitHub, listing over a 100 Indian Muslim women. It described itself as \u201cBulli Bai,\u201d another derogatory term for Muslim women. The police claimed that the creator of the app had copied and edited the code repository and graphics features of Sulli Deals to create the new Bulli Bai version of the auction app. Some of the key Twitter handles that promoted this new app had appeared in police complaints related to the 2021 Sulli Deals, indicat -\ning a close web of actors who seemed relentless despite disciplinary actions (Ojha, 2022; Shekhar, 2022).\nSoon after, the Delhi Commission for Women, a statutory body for protect -\ning women\u2019s rights, filed a complaint with the Delhi police drawing attention to the \u201cobscene comments against Muslim women\u201d on yet another platform, Clubhouse, which is branded as a social audio app ( Bhalla, 2022). Taking \nsuo moto (a court taking action of its own accord) cognizance of the snippet of such sexually offensive Clubhouse conversations made public on Twit -\nter, the police arrested three young men aged between 19 and 22 years. The fourth accused was the creator of the original YouTube auction, who was absconding at the time. The accused men had participated and moderated discussions in two Clubhouse rooms titled \u201cMuslim gals are more beautiful than Hindu gals\u201d and \u201cGirls don\u2019t have the privilege to marry upper caste \n122 Sahana Udupa and Oeendrila Lahiri Gerold\nboys.\u201d A\u00a0related First Information Report (FIR) was filed in relation to a \ncomplaint that a Hindu woman had lodged, providing details around how she had been \u201cauctioned\u201d on the two Clubhouse rooms.\nSecondary and Evolutionary Developments\nAs these activities rippled across various platforms, setting off a series of interconnected actions with a shared repertoire, a distinct digital practice began to crystallize. Thick with sexual degradation and \u201cpornification\u201d (Sarracino\u00a0& Scott, 2008), \u201conline auctions\u201d sought to perform a politics of masculine majoritarianism by peddling objectified female bodies of the minority religious community as online artifacts, without the knowledge or consent of the women. The crass dehumanizing act invited strong criticism, including the attention of the UN ( The Hindu, 2022), while also spotlighting \nan amalgam of murky practices that had been brewing on online channels among niche communities of extreme ideological tactics writ in an \u201cextended adolescence of video games, porn and pranks\u201d (Nagle, 2016, p.\u00a071).\nFollowing fragmented law and order measures and YouTube\u2019s decision to \nban the channels that featured this content, the creators sought alternative online avenues. A\u00a0leading figure reassembled his loyal audience on Telegram, an encrypted messaging application known for its lax content regulation (Semenzin\u00a0& Bainotti, 2020). Utilizing the platform\u2019s functionalities such as creating public or private groups with as many as 200,000 members, and public channels for broadcasting content (Khaund et\u00a0 al., 2021), auction actors launched both chat groups and channels. The newly created avenues, some of which were still active as of this writing, feature an archive of banned videos, new video creations, and interactive messaging and largely contains anti-Muslim content alongside graphic and explicit sexual \u201chumor.\u201d Sex and sexuality are indeed the running themes in the videos and chats. Muslim men are portrayed as having an uncontrolled appetite for bestiality, with no desire or ability to sexually gratify their many wives. In turn, Muslim women are portrayed as stuck in loveless marriages, often being forced to have sex with their fathers-in-law or brothers-in-law or enjoy \u201chalala\u201d (sexually suggestive in-group idiom with alleged scriptural reference). The Muslim woman is por -\ntrayed as young, with or without hijab; she is sexual and sexually vocal and seeks sexual gratification repeatedly. A\u00a0semi-clad and hijab-adorned picture of Mia Khalifa\u00a0\u2013 the Lebanese porn actress who is a vocal Muslim and liberal activist on social media with 4.8 million followers on Twitter\u00a0\u2013 is often used in the videos to refer to porn, virgins, and other references to sex, and so is another Indian porn star, Sunny Leone. The content is dotted with parodic Islamophobic shayaris (short verses in Urdu/Hindi with lyrical and seman -\ntic flourish) and occasional career tips for the youth in addition to sexual material. The news covered in the groups relays political ideologies of Indian \n\u201cDeal\u201d of the Day  123\nHindu nationalism, training its criticism against Muslim Pakistan as well \nas religious minorities, liberal media, and those seen as \u201cmoderate\u201d Hindu nationalist leaders in India.\nThe Focus of this Study\nIn this chapter, we navigate this corpus of volatile and provocative content and activities, to explore new social dynamics of hateful cultures emerging at the intersection of gender, religion, and platform affordances. We combine the analysis of Telegram posts and extracts from online auctions with ethno -\ngraphic interviews among women political actors who were affected by the auctions in several ways and journalists who investigated the episode. The goal is to better understand how online actors who espouse extreme forms of religious majoritarian ideologies distinguish themselves from other \u201cmod -\nerates\u201d; exhibit their masculine politics vis-\u00e0-vis the Muslim male \u201crivals\u201d through a rather contrived way of sexualizing Muslim women; and partici -\npate in homosocial networks in which porn, sexual innuendo, political mes-sages, and career advice comingle. Although direct interactions between the authors and the message perpetrators were not possible because of difficul -\nties in accessing that elusive group, we aim to gain a grasp of their manners, motivations, and gratifications by navigating the corpus of content they leave behind online, alongside an analysis of how targeted women and journalists who reported the incident recount describe and assess the dynamics of these \u201cauctions\u201d and related online activities.\nTaking a social dynamics and media practice approach to digitally medi -\nated forms of life and relatedness ( Couldry, 2012; Geismar\u00a0& Knox, 2021 ; \nWalther, this volume) and informed by speech act theory which posits con -\ntent and conduct as co-constitutive ( Butler, 1997), we advance three ana -\nlytical points around online hate dynamics that take a specifically gendered dimension. First, we dispute what the \u201ccute cat theory of Internet censor -\nship\u201d (to be described further, later in the chapter) considers as a neat sepa-ration between the seemingly apolitical activity of porn and online political activism (Zuckerman, 2008) and argue instead that digital sexual violence gets enmeshed with political aggression via the consumption of porn. Here, we engage with philosopher Rae Langton's (2012) arguments around struc -\ntural affinities between pornography and hate speech. Second, we suggest that such grave practices are shaped by digital environments which are con -\nsumed and articulated as \u201cfun\u201d through the specific affordances and playful interactional frames of online media (Udupa, 2019). Finally, these overlap-ping practices are embedded within a longer history of postcolonial politics of religious majoritarianism and recent manifestations of global Islamopho -\nbia (Hansen, 1999; van der Veer, 1994). In particular, we show how porni -\nfied abuse of Muslim women ironically complements the Hindu nationalist \n124 Sahana Udupa and Oeendrila Lahiri Gerold\nnarratives around \u201cmoral restraint\u201d and its conservative politics focused on \nregulating the sexuality of Hindu women (Sinha\u00a0& Fernandes, 2014).\nFor digital hate scholarship, the social interactional dynamics captured in \nthis study reveal the ways in which exclusionary ideologies with long his -\ntories perpetuate through niche groups of supporters as they draw strength from the viscerality of sharing, playing, and mashing up objects floating in the Internet world, charging some of them with widely consumed tropes of sex and porn.\nThe content we analyze, cite, and show is extremely offensive and pre -\nsenting them here bears the risks of amplifying the voices of online actors who circulate such content. However, by limiting the cited online texts to the defined objectives of content and ethnographic analyses carried out here, we seek to not only follow the data minimization principle but also evince the possibility of advancing a critical conversation around them.\nPorn, Politics, and Misogyny\nPornographic and sexual content in online political discourses has drawn the attention of various recent studies of digital communication. While feminists remain divided around questions of sex work and pornography\u00a0\u2013 reflecting the tension between exploitative and agentic views of porn among contesting feminist traditions (Patu\u00a0& Schrupp, 2017)\u00a0\u2013 a significant branch of recent scholarship has linked pornography with online misogyny and massive troves of anti-feminist, anti-women, and transphobic content in social media net -\nworks (Mantilla, 2015; Massanari, 2015; Tranchese\u00a0& Sugiura, 2021).\nAs studies attest, such practices are not contained within the silos of Inter -\nnet communities. They have seeped into and increasingly frame mainstream political cultures. Segarra and Anderson (2019) define this as a \u201cpornified \npolitical culture.\u201d Using the example of the 2015 Spanish elections, they argue that pornification of politics extends beyond the United States and is now a global phenomenon \u201cendemic to twenty first century democratic cultures shaped by the 24-hour news cycle, the reach of social media, the ubiquitous objectification of women, sophisticated image-editing technology, and political norms that are persistently patriarchal\u201d (p.\u00a0205). They draw on Nussbaum's (1999) concept of \u201cfungability\u201d to describe \u201cpornified political culture\u201d as political processes in which women are divested of their unique -\nness, suggested to be violable, and are treated as interchangeable objects.\nAlthough sexualized abuse arguably permeates and shapes different ide -\nological groups within diverse local and national contexts, studies of the alt-right and far-right in the West have highlighted that online anti-feminist discourses prominently figure in right-wing radicalization processes (\n Keskinen, 2013 ; Walton, 2012). Fuchs (2018) considers resurgent national -\nism in contemporary Europe as an articulation of racisms, misogyny, sexisms, \n\u201cDeal\u201d of the Day  125\nand xenophobia. Socially conservative sections within these groups express \nthe desire to preserve patriarchal and heteronormative families by allocat-ing traditional gender roles and reducing women \u201cto sexuality, biology and housework\u201d (Fuchs, 2018, p.\u00a0 240). Such utopias around heteronormative traditional families have found a renewed emphasis within newer movements such as QAnon\u00a0\u2013 a pro-Trump conspiracy movement with a large number of women supporters advocating for notions of femininity \u201ccentered on moth -\nerhood and maternal duty\u201d (Bracewell, 2021, p.\u00a01; Forberg, 2022).\nThe conservative \u201chappy family\u201d trope has reappeared at the same time \nwhen online worlds have seen a veritable expansion of explicit anti-women subcultures\u00a0\u2013 loosely defined as the \u201cManosphere\u201d\u00a0\u2013 ranging from \u201creaction -\nary and alt-right YouTubers who rage against the apparent current moral decline due to the sexual revolution and feminism\u201d and MGTOWs (Men Going Their Own Way) who advocate a \u201cmale lifestyle without women\u201d to \u201cNoFap members who abstain from pornography and masturbation but hold equally problematic views of women and feminism\u201d (Johanssen, 2022, p.\u00a04) and groups \u201cobsessed with rape statistics and false rape claims\u201d (\n Hawley, \n2017, p.\u00a062).\nWhile the Manosphere\u2019s contradictory strands pull the communities in dif -\nferent directions, posing conceptual quagmires to researchers, what emerges is the common thread of sexualization of women that runs through these var -\nied groups, as sex figures in deeply conflicting forms of anxiety, withdrawal, desire, fantasy, and morality. Psychoanalytical perspectives, to cite one stream of scholarship, have highlighted the contradictory impulses of fan -\ntasy, victimhood, and sexual anxiety of male perpetrators of the Manosphere (Johanssen, 2022). Hinting that such seemingly contradictory impulses are subsumed within a discourse that is already bounded and sexualized, studies have rightly drawn a comparison with pornography, arguing that\nboth pornography and incels [involuntary celibates; Dekeseredy, this vol -\nume] are different manifestations of the same misogyny\u00a0.\u00a0.\u00a0. both\u00a0.\u00a0.\u00a0. share discourses that reflect a broader societal misogyny in which sex is punitive and strictly connected with women\u2019s submission.\n(Tranchese\u00a0& Sugiura, 2021, pp.\u00a02709\u20132710)\nAll these leave us with a picture of sexualized anti-women discourses and \nalt-right discourses developing closely and almost inseparably in the trans -\natlantic context. Johannsen describes this relation as \u201cborrowing\u201d: \u201cThe Manosphere\u00a0.\u00a0.\u00a0. explicitly borrows from or makes use of alt-right discourses, ideas, images, and terminology\u201d (Johanssen, 2022, p.\u00a0 8). While Mano -\nsphere members \u201cborrow\u201d alt-right tropes, the reverse, as we demonstrate in this chapter, is equally true. Right-wing political ideological groups that are racist, anti-minority, and anti-immigrant rely on a particular form of \n126 Sahana Udupa and Oeendrila Lahiri Gerold\nmisogyny\u00a0\u2013 sexualized and pornographic visual-textual practices\u00a0\u2013 to sustain \ntheir practices, while what comes first and what follows is a chicken and egg question. It is in this context that the sexualized objectification of Indian Muslim women as items in an auction via social media takes on numerous layers of meaning.\nSexual Politics of the Hindu Right\nThe auctioning of Muslim women particularly reflects the ideology of Hindu nationalism, which frames the politics of the current ruling regime in India and has had a Janus-faced moral position on sexuality. Hindu national -\nism\u2019s advocacy for a Hindu-first India and repression of minority religions (Hansen, 1999; van der Veer, 1994 ) have shaped the schism around sexuality \nin ways that follow and replicate the religious divide (between majority Hin -\ndus and minority Muslims). Hindu nationalists have articulated patriotism in relation to conceptions of maryada [honor], which partly unfolds through a conservative politics focused exclusively on regulating sexuality and cel -\nebrating the heteronormative \u201chappy family\u201d seen as coextensive with the national community (Udupa, 2018). However, the gendered conception of maryada maps out in diametrically opposite ways for the Hindu and Muslim women.\n2\nStudies have shown that sexual violence has been a part of interreligious \nconflicts and riots in India, especially in the late colonial period and years fol -\nlowing its formal political independence in 1947 ( Agarwal, 1995; Das, 2007; \nSarkar, 2021). Examining gendered communal conflicts in India, Megha Kumar (2022) emphasizes the importance of the interaction of an elite ide-ology (Hindu nationalism) and the unique economic, social, and political dynamics at work within different conflict situations, tracing some of the motivations behind sexual violence to the founding texts of the ideologues of the Hindu nationalist movement. The founding members of Rashtriya Swayam Sevak Sangh (RSS),\u00a0the nodal Hindu nationalist organization estab -\nlished in 1925, articulated sexual violence against \u201cenemy women\u201d within a historical narrative of India\u2019s misery under a violent Muslim rule ( Kumar, \n2022). An image of sexually depraved yet physically powerful Muslim men was pitted against virtuous but weak Hindu men. Muslim women were condemned as complicit in the sexual and material exploitation of Muslim men. In contrast, Hindu women were portrayed as honorable who would rather commit suicide than fall prey to the lascivious marauding Muslims. Paola Bachetta (2004) similarly informs that the core and marginal informa -\ntional materials of RSS, which had an effective marketing machinery even as early as the 1990s, construed \u201cMuslim women as objects of potential and realized communal and sexual appropriation\u201d (p.\u00a098) vis-a-vis an idealized patriotic Hindu male and the alleged anti-national sexually violent Muslim \n\u201cDeal\u201d of the Day  127\nmale.\u00a0Representations of Muslim women in the Hindu nationalist discourse, \nBachetta states, draw on a long tradition of colonial and fascist discursive practices of gendered sexualized \u201cothering.\u201d However, instead of an assumed biological inferiority, Indian\u00a0Muslim women, she argues, are viewed as \u201clost property\u201d for the Hindus because of religious conversion that \u201ctook away\u201d women who were Hindus from their \u201coriginal\u201d religious community while their status in Islam is assumed to be of tradeable sexual objects. Such ideo -\nlogical justifications for cultivating an aggressive male sexuality have served to exempt sexual degradation of Muslim women from moral reproach within the Hindu nationalist thought.\nAgainst this historically fraught sexual politics of religious majoritar -\nian nationalism which has sought to \u201cdivide Muslims along gender lines, and to use Muslim women to denigrate Muslim men\u201d ( Bachetta, 2004, \np.\u00a0123), including through seemingly emancipatory legislations around ban -\nning the hijab and the tripal talaq (Piedalue et\u00a0 al., 2021), a broader cul-\nture of sexualized imagery and sexualization has swept mainstream politics in recent years. In an ethnographic conversation with the authors, Kavita Krishnan, a left-progressive feminist and staunch opponent of Hindu right politics, tells us:\nOne set [of people] will keep reacting by calling you a terrorist and a ter -\nrorist supporter, and these will always be sexualized because they will say you are the hoor who will be gifted to Muslim terrorists when they go to \nheaven. So [they chide us that] you want to sleep with Muslims, they ask you how did you like the taste of this guy\u2019s\u00a0.\u00a0.\u00a0. take this, that\u00a0.\u00a0.\u00a0. all that kind of thing. So there\u2019s a whole sexualization of that political angle.\nSexist and sexualized attacks of the kind Krishnan describes have become not only more common but also more sweeping, since women who come from the Hindu communities are also targeted by Hindu nationalists for their feminist and critical views about nationalist politics ( Amnesty International \nIndia, 2020). This enlarging of the ambit\u00a0\u2013 of who is considered as rightful targets for sexist and sexually violent attacks\u00a0\u2013 has upset, if not completely upturned, the schism in sexual politics along the religious divide. Simultane -\nously, it has accentuated the contradictions of a conservative politics of the \u201csave the family\u201d discourse of the Hindu right and the disruptive energies of sexualized epithets that drive the ideology.\nWe suggest that digital mediation is squarely at the center of this churn -\ning. As affordable Internet media and social media platforms have expanded, India has become the second-largest country in terms of Internet users (700 million in 2022; Farooqui, 2023). If thousands of newly minted nation-alistic ideologues are drawn into a recursive loop of digital influence strate -\ngies of the right-wing party\u00a0\u2013 blurring the boundaries between organic and \n128 Sahana Udupa and Oeendrila Lahiri Gerold\nmanufactured traction\u00a0\u2013 a bottom-up swelling of nationalist affect on digital \nplatforms has also led to a diversification of strategies, actors, and affects that compose this ideological space.\nA significant rupture exists along an emic divide between \u201ctrads\u201d (staunch \ntraditionalists) who have sought to revive practices deemed as \u201cproperly\u201d Hindu, versus \u201craitas\u201d (\u201cmoderates\u201d) who are blamed by the opposing camp for going soft on Hindutva (Hindu nationalism). Trads have taken up some of the most regressive tropes of gender, including the dehumanizing tradition of Sati\u00a0\u2013 the alleged voluntary and divinely sanctified sacrifice of a widow by ending her life on the burning pyre of the deceased husband\u00a0\u2013 which is now considered illegal. Much of their activities heavily hinge on digital work, as these tech-savvy actors charge up a panoply of digitally native tactics to assemble and articulate nationalist views and combat and counter those seen as hostile. In the next two sections, we examine digital activities (online auc -\ntions and Telegram chats) of a particular community of such niche extreme actors\u00a0 \u2013 the self-defined trads\u00a0 \u2013 to ask whether and how they renew and revamp key ideological tenets of exclusionary nationalism foremost by cen-tering the Muslim female body and ramping up gendered discourses with the vocabularies and visualities of Internet porn.\nOnline Auctions\nThe online auction scandal in 2021, with which we began this chapter, first came to public knowledge when journalists and members of Article-14, a legal advocacy group, reported about a \u201ctool\u201d called \u201cSulli Deals\u201d on GitHub (Jafri\u00a0& Aafaq, 2021). Fashioning itself as an \u201cauction\u201d tool, Sulli Deals showcased images of Muslim women largely sourced from Twitter without their consent or knowledge, inviting users to \u201ctake their pick\u201d from the stock of \u201cSullis\u201d as the \u201cdeal of the day.\u201d These pictures and more information about the auctions were shared on Twitter and other social media platforms, inviting more users to haggle their \u201cdeal of the day.\u201d Typi -\ncally, users would select the image, \u201crate\u201d the woman in the image, and \u201cauction\u201d her off to each other. Even before the tool appeared on GitHub, similar \u201cdeals\u201d were offered on some accounts of Twitter. Several Twit -\nter accounts with apparent pseudo names\u00a0\u2013 some with Muslim-sounding names and others sounding Sikh\u00a0\u2013 with a follower count ranging from 600 to 65,000 were actively promoting the auctions ( Jafri\u00a0& Aafaq, 2021). The \ndeals were also \u201cbroadcast\u201d live on YouTube. \u201cI saw it live on YouTube,\u201d said Nazia Ahmad, our interlocutor in Delhi; \u201cThey were talking like, \u2018 2 \nrupees ki #&*, khud ki paisa  [a #&* of 2 Indian rupees worth]\u2019. \u2018 iska yeh, \niska wo\u2019 [she\u2019s for him, she\u2019s for the other]. I\u00a0cannot even say the word they were using. I\u00a0saw them, I\u00a0saw them being auctioned like that\u201d (see Figure\u00a0 6.1).\n\u201cDeal\u201d of the Day  129\nFIGURE\u00a06.1   A\u00a0Tweet on Sulli Deal\nSource: Retrieved June 30, 2023, from https://twitter.com/ALeelwala/status/1393076401826  \n271239\n130 Sahana Udupa and Oeendrila Lahiri Gerold\nOnce images of \u201cauctioned\u201d women appeared on the screens, a typical \ninteraction unfolded as follows:\nUser 1: Like thoko bhaiyo [shower with likes, brothers]\nUser 2: Link do bhai [give me the link, bro]User 3: Edi inki nahi mili to unsubscribe kar denge molana  [If indeed I\u00a0don\u2019t \nget to take them, then I\u2019ll unsubscribe, maulana]\nUser 4: Band karo yeh chutiyapaa Kameeno [Stop this f***ery, scoundrels]User 5: Video utube se nikal Gaya toh firse upload karna warna unsubcribe \nkarenge n private bhi mat karna [If the video disappears from YouTube, then please upload again, otherwise we\u2019ll unsubscribe and don\u2019t even make it private]\nUser 6: Bhai inko bakri ki review karo tab khus hoke one hand dumble \nkarenge [Brother, do reviews of goats and only then they\u2019ll be happy to exercise their one hand]\nSoon after the incidents came to the attention of the media, journalists reported that a 23-year-old resident in a Northern Indian technology city, who maintained multiple accounts on Twitter and YouTube, was the central figure running the technical set up for the first of such auctions in May, 2021, and, thus, he was an influencer for the large social media following he com -\nmanded. Before facing suspension, the YouTube channels \u201cLiberal Doge\u201d and \u201cSecular Doge\u201d that he ran had a combined viewership of 200,000 (Goyal, 2021). The key protagonist of the videos on these channels was a caricaturized Muslim male in the image of a Cheems dog from the global memes world but with a Muslim skull cap ( Figure\u00a0 6.2). Auctions were argu -\nably the most insulting of what these channels produced. As Liberal Doge\u2019s posts created a stir, an auction \u201capp\u201d (Bulli Bai app) was subsequently cre -\nated by a group of youths in November 2021, and soon attracted more atten -\ntion (Garg, 2022).\nThe new controversy dragged opposing political parties into the fray, rais-\ning the political stakes of this obscure online practice that had now spanned different platforms (see Table\u00a0 6.1). The arrested youth were software engi -\nneering students from different cities of India, and, according to our journal -\nist interlocutor, who published detailed stories on the episode, the parents of the teenagers were unaware of what their children were up to. \u201cThey are from very simple middle class family,\u201d said the journalist, hinting that one might appreciate their teenage vulnerabilities without casting too harsh a light on them as masterminds of an elaborate criminal conspiracy. \u201cThey were really young chaps,\u201d he continued; \u201cThey did not get the bail in the beginning but after spending some months in the jail, they were released on bail.\u201d A\u00a0feminist politician who spoke to us added, \u201cThese 18-year-old, 19-year-old, 20-year-old youngsters who are behind the auctions are earning a buck as well as getting a kick out of doing this kind of thing.\u201d\n\u201cDeal\u201d of the Day  131\nFIGURE\u00a06.2   Meme Shared in the Chat Group\nTABLE\u00a06.1   Activities Related to Auctions and Pornified Content on Different Platforms\nTwitter YouTube GitHub Clubhouse Telegram\nAmplification Live broadcast Creation of Audio discus- Chat groups created \nand promotion of an \u201cauc- applications sions around for circulating polit-\nof auctions on tion\u201d of Paki- to \u201cauc- Muslim ical, communal, and other platforms stani women tion\u201d Muslim women and misogynistic content\nwomen their sexual \nworth\nTrolling and Misogynistic Hosting of such Auctions of Channels were \nauctioning and Islamo- applications both Hindu deleted; YouTube exclusively on phobic con- and Muslim videos are archived \nTwitter tent creation women and made acces-\nand hosting sible. Other new channels created at different intervals\n132 Sahana Udupa and Oeendrila Lahiri Gerold\n\u201cAuction\u201d as a form of online activity is not merely persistent individual \nheckling that typifies \u201ctrolling\u201d ( Hardaker, 2010). As the conversation thread \nand Figure\u00a0 6.1 illustrate, prankster perpetrators of Sulli/Bulli Deals offered it \ninstead as an activity where users can collaboratively \u201crate\u201d the images, ask \nfor more images, and express a sense of \u201cprocuring\u201d the women depicted in them. The activity bears a similarity with pornography in that they both work on the assumption that women could be rated, sold, and \u201cconsumed\u201d in a sexualized way. However, it sits oddly with generous readings of \u201ctra-ditional\u201d pornography as \u201cin a sense, a substitute for a sexual partner\u201d and harmless fiction (Burgess, 1970, p.\u00a08). With nonconsensually sourced images of real women thrown into a male virtual marketplace, the online auction recreates pornographic conditions that depict and endorse women\u2019s degrada-tion (Brownmiller, 1975). Even more, with its interactive features, the \u201cauc -\ntion\u201d transforms the seemingly solitary activity of porn consumption into group aggression laced with sexual innuendo and shaming and the pleasures of \u201crating\u201d and \u201cbidding\u201d for \u201citems\u201d tagged with real pictures of actual women. Thus, the exemplification of hate becomes a highly social process.\nSocial Organization\nAs Nur Akhtar, who was one of the Muslim women \u201cauctioned\u201d online, recounted to us:\nIt was not like any other. It wasn\u2019t even like a rape threat or whatever that you face online. It was more real, it was more real than mere trolling. It wasn\u2019t just saying something and moving on, because there was this ele -\nment of auctioning\u00a0.\u00a0.\u00a0. a whole activity around you where there are people now commenting on you and talking about you, objectifying you.\nThis \u201cwhole activity,\u201d as Nur says, suggests that what emerge in auctions are not just individual and isolated strings of comments to a pornified image but a \u201cporn event,\u201d a social interaction episode.\nClusters of users who congregated at the auctions were also simultane -\nously talking to one another and building up more cheerleaders. One of the women who were \u201cauctioned\u201d told us:\nBefore the auctions, I\u00a0 had probably taken it [online harassment] for granted. I\u00a0thought its okay, chaar panch log he jo troll karte byathte he \ntypes [it\u2019s just about four, five people trolling and suchlike]. After the auc -\ntions, I\u00a0realized they are very well connected, they talk to each other, they have all these DM [direct messaging] groups in which they are discussing, and they are constantly finding people, making lists of people whom they want to attack.\n\u201cDeal\u201d of the Day  133\nGroup Participation\nThe online uproar that erupted following the arrests of the auctions\u2019 creators \nis a vivid illustration of group camaraderie and tactical noise of support -\ners. While feminists and liberal progressive voices welcomed the originators\u2019 arrests and rallied against the grossly degrading online activity, right-wing patrons of the auction sites posted angry comments. Coining the hashtag \u201c#IamWithLiberalDoge\u201d and claiming that it was trending on Twitter, sup-porters urged fellow users to \u201cmake sure to tweet as much as you can. They are fighting alone, we must support them\u201d ( Goyal, 2021). \u201cThey have enter -\ntained us a lot,\u201d reminded another supporter, adding \u201cit\u2019s our payback time.\u201d Some of them were reeling with anger: \u201cIs freedom of speech for Muslims and leftists?\u201d asked a user; \u201cWhy can\u2019t someone from HINDU community express himself #IamWithLiberalDoge\u201d [original capitalization].\nIt was thus of little surprise that following the bans on YouTube and Twit -\nter, some of auction masterminds migrated to Telegram, one of the least regu-lated platforms, carrying with them the loyal tribe of gleeful hate mongers and the entire bank of deleted content to curate elsewhere. The next section turns to assess content that has been archived on a public Telegram channel run by these actors and samples of conversations among them in a Telegram chat group.\nTelegram Chat Worlds\nFor this analysis, following an initial search on Telegram for the keywords \u201cLiberal Doge,\u201d \u201cSecular Doge,\u201d and \u201cSulli Deals,\u201d three sites were selected for closer exploration: \u201cLiberal Doge All Videos\u201d (LDAV, a public channel with archived videos), \u201cSecular Doge\u201d (a music, discography public channel), and \u201cSecular Doge Chats\u201d (SDC, a public chat group). The sampled content gathered during observations of group activities between May and June 2022 contains videos, audio clips, chat texts, and still images. LDAV had 59 vid -\neos, out of which 2 were forwarded videos and the rest were \u201crestored\u201d from the YouTube channel after it was banned following the live auctions in May 2021. Although the creator of this channel appears to have many more videos scattered around social media channels, this corpus of videos presents an interesting sample of banned videos that are now archived and available using Telegram\u2019s unique affordances of encrypted and group messaging func -\ntionalities, as well as its radical free speech approach to regulation ( Rogers, \n2020). Aside from the 57 videos archived in this channel, 13 new videos that the channel owner created and shared on the chat group (SDC) were included in the sample of videos for annotation and analysis. Using the feature of Telegram exports of historical data, we also obtained 149 voice/audio clips from the chat group. The material from the chat group contains images (.png files), stickers (Telegram\u2019s own stickers and those created by users), video \n134 Sahana Udupa and Oeendrila Lahiri Gerold\nfiles (short and embedded videos), other files (shared on the group, including \npdfs), and text messages in html files.\nFor the final annotation, all 70 of \u201coriginal\u201d videos created by the chan -\nnel owner were selected for analysis (see Table\u00a0 6.2). From the large chat \ndata from SDC, only posts with explicit or indirect reference to sex/sexual -\nity, porn, women, and gendered violence were selected. With this selection, a total of 811 images in the chat group were reduced to 129 images for final annotation. Textual data in the chats helped to interpret the meanings of videos, still images, and audio files in the chat group and make sense of the contexts of sharing, but it was not included for coding.\nWe built two annotation schemes based on bottom-up coding and labels \nderived from previous work on Hindu nationalism, listing key themes in the corpus. The first list contained gender-based labels: (1) Porn, (2) Muslim femininity and female sexuality, (3) Muslim masculinity and male sexual -\nity, (4) homophobic, (5) morphing, (6) sexually explicit \u201chumor,\u201d (7) calls for violence, (8) allegations of sexualizing Hindu deities and motifs, and  \n(9) threats to Hindu masculinity and safety of Hindu women. The second list had \u201cgeneral\u201d themes: (10) Islamophobia, (11) extreme Islamophobia,  \n(12) Hindu nationalism and patriotism, (13) anger against liberal/secular/left politics, and (14) derogatory speech against religions other than Islam (a detailed description of the labels is available from the first author).\nProminent Themes\nTable\u00a0 6.3 shows the most frequently occurring themes in the dataset across \nvideos, voice, and images. It might be noted that coding here is based on its obviousness in the elements analyzed and not its contextual presence. As we gleaned from observations of group discourses during the two-month period, subtle calls for violence are running themes and constitute the ideological framing of the posts. The dataset contains no direct calls for violence, reveal -\ning that indirect expressions are employed to signal the desire for sexual and political aggression.TABLE\u00a06.2 Corpus Description\nData type Location Total number  Annotated items\nof items found\nVideo Telegram Channel + 72 70 (97.2%)\nChat Group\nVoice/audio Telegram Chat group 149 51 (34.2%)\nStill images Telegram Chat Group  811* 129 (15%)\n* Excluding duplicates and thumbnails  \n\u201cDeal\u201d of the Day  135\nIslamophobic and anti-Muslim minority speech constitutes a major part \nof the content. Masculinity and sexualized speech form core components \nwithin the discourse. Doge\u2019s videos draw on historical stereotypes of Mus -\nlim men as sexually and politically aggressive, and he expands their scope by claiming that Muslim men\u2019s hypermasculinity extends to animalistic ten -\ndencies including bestiality. Stereotypes of Muslim women are also regurgi -\ntated\u00a0\u2013 they are over-sexualized as well as shown to be oppressed. In the chat group, for instance, a user started an \u201canonymous poll\u201d with the question, \u201cMulli ki ch**t kaise hoti hai?\u201d [What does the vagina of a Muslim girl look like? \u201cMulli\u201d is an offensive term for Muslim women.] The question was fol -\nlowed by a list of options with sexually explicit descriptions on which users could vote.\nSubthemes of love-jihad, \u201cHindu khatre mein hain\u201d [Hindus are under \nthreat], notions of \u201cviolent Islam,\u201d and allegations that the ruling Hindu nationalist party (BJP) is too \u201csoft\u201d are prominent subthemes. Other sub -\nthemes include anti-caste politics and criticism of affirmative action (reserva -\ntion for oppressed castes) and anger against the \u201cliberals.\u201d In videos as well as chats, the language used is often abusive, lewd, and xenophobic. Ironi -\ncally, the tone is also almost always \u201chumorous\u201d and playful. Further analy -\nsis will reveal how diverse themes appear in relation to one another and how full conversational spaces emerge within the Telegram group. To address this lacuna in our content analysis, we conducted conversation analysis of an extract from the chat group, offering a glimpse of how a \u201ctypical\u201d exchange unfolds in the group.TABLE\u00a06.3   Frequency of Themes\nCode Theme Occurrences\n3 Muslim male sexuality 77\n10 Islamophobia 76\n12 Hindu nationalism 41\n9 Threats to Hindu masculinity 37\n11 Extreme Islamophobia 33\n1 Porn 32\n2 Muslim female sexuality 30\n13 Anger against liberal/secular/left politics 24\n6 Sexually explicit humor 22\n14 Derogatory speech against other religions 10\n4 Homophobia 8\n8 Allegations of sexualizing Hindu deities 6\n5 Morphing 3\n7 Direct call for violence 0\n136 Sahana Udupa and Oeendrila Lahiri Gerold\nConversation Analysis\n\u2022 15 June 2022: Starts like any other day for the group, but sadder. The \ndiscussion is sparked by news reports on the grim realities facing young \njobseekers from rural areas who had come to the expensive capital city of New Delhi, aspiring to find government and bureaucratic jobs. Members discuss how government jobs are mismanaged and scarce, pushing the youth to commit suicides over failed careers.\n\u2022 Soon, \u201cCK,\u201d a group admin, enters the conversation and launches a dia -\ntribe against a group member whom he accuses of blaming the youth for their fate. The messages to which CK replies are deleted already and therefore one cannot gauge the provocation. CK\u2019s abuses are packed with Islamophobic, sexist, and sexual punches, attacking Muslim women in particular.\n\u2022 \u201cGreen Bag\u201d intervenes and clarifies that CK has mistaken his target to be \na Muslim, when in fact he is a Hindu. He urges CK to calm down saying he is also about to start \u201craid training\u201d on the group.\n\u2022 CK clarifies that he was provoked by the person\u2019s irreverence toward the \ndeceased and continues to use sexual gifs and to hurl insults against the antagonist\u2019s mother, now combining graphic sexual violence against Mus -\nlim women with stereotypes around terrorism. A\u00a0meme with a possibly masturbating body with Leonardo DiCaprio\u2019s face pops up in the midst.\n\u2022 Green Bag suggests that CK and his opponent join forces in violating a \n\u201cmulli\u201d as a means to foster harmony between themselves. He then sug -\ngests that a second phone number, preferably a fake American one, will help dodge Telegram\u2019s bans.\n\u2022 Meanwhile, CK posts a meme that depicts a nude Mia Khalifa, a porn \nactress and activist of Lebanese origin, with the Pakistani flag painted on her. She is being penetrated by a muscular faceless man painted in the Indian flag. The still image used in the meme comes from one of Khalifa\u2019s movies, depicting her contorted face conveying in that moment seeming shock and unease.\n\u2022 The topic shifts. CK\u2019s next message is to Grain Bag asking why their tel -\nephone call is not connecting. Grain Bag replies to \u201cOlla Ubar,\u201d another active participant in the group, asking him to use the shared fake number to make a sham ID, posing as a Muslim girl.\n\u2022 CK chips in to suggest \u201c nudes bhi bhejna\u201d [send nude pics] and asks Grain \nBag to call again.\n\u2022 Grain Bag says he shall deliver [nude pics] and continues to elaborate on \nhis idea to infiltrate Muslim groups with fake ids. The idea is to act like an ex-Muslim, doxx them, and destroy their online presence. The matter of youth suicides is thus laid to rest for the day.\nThe mind-numbing mix of themes in the thread\u00a0\u2013 beginning with the sober story of youth suicide to a swift descent to sexualized abusive message to \n\u201cDeal\u201d of the Day  137\nviolating a \u201cMulli\u201d for group solidarity to a wacky cry for nude pics\u00a0\u2013 all \nostensibly for the noble cause of the nation\u00a0\u2013 reveals how masculine rage and revenge fantasies around a sexualized female Muslim body animate and hold up the groups. In a vital sense, these groups represent and tap an expanding uptake for porn in India, which has peaked since the advent of smartphones and affordable data plans ( Aulakh\u00a0& Sengupta, 2017; Singh, 2020). Accord-\ning to Porn Hub, India is one of the top consumers of porn (\u201cPornhub\u2019s Third Largest Customer Base Comes from India,\u201d 2018) and registered the greatest \nvisits during the pandemic (Kannan, 2020). In addition, India now boasts of amateur local porn productions as well as subscription-based mobile apps for porn (Jaiswal, 2021).\nSet in this context of digitally delivered porn riding on cheap data and smart -\nphones, the striking visuality of sexualization and occasional self-references to incels among the \u201cDoges\u201d might be tempting enough to conclude that they are like incels who \u201cdehumanize, yet desire, women\u201d (Johanssen, 2022, p.\u00a04). However, the affective charge of religious nationalism that animates and binds the social interactions among the members\u00a0\u2013 and the group ener -\ngies around the political ideology which they draw on and fuel\u00a0 \u2013 suggest that the confusing concoction of political, pornographic, and sexual matters within such communities holds some new lessons for digital hate scholarship. The next section raises some of these.\nOnline \u201cBasic Misogyny\u201d to Porn Fun\nIn his succinct and widely cited \u201ccute cat theory of Internet censorship,\u201d Ethan Zuckerman (2008) considers the Internet\u2019s immense potentiality for \nsocial movements as arising from its architecture that poses a deep dilemma for dictators inclined to control what flows through these channels. Authori -\ntarian will to control the Internet confronts a double bind. If regimes do not censor, all manner of speech, including resistance, will flood the public space. If they censor the Internet, they raise the risk of blanket banning the content, including content that has nothing to do with politics. Censoring the net risks politicizing publics who were until then unconcerned or unaware of what was going on. Worse still, it could antagonize them since they now cannot search the Internet for cute cat pictures and\u00a0\u2013 this is perhaps even more important\u00a0\u2013 pornography. Furthermore, the Internet\u2019s open architec -\nture allows for features that expand and improve regardless of the purpose to which they are put. He argues, \u201cSufficiently usable read/write platforms will attract porn and activists. If there\u2019s no porn, the tool doesn\u2019t work. If there are no activists, it doesn\u2019t work well.\u201d While much of this analysis holds true for the risks of censorship, the argument, although not intended, makes a sweeping distinction between porn and political activism, to the extent of suggesting that they represent two different social processes altogether or at the very least, two separate domains of online activities. The analysis \n138 Sahana Udupa and Oeendrila Lahiri Gerold\npresented in the preceding sections reveals how online porn and political \nactivity are not only intertwined but co-constitute one another.\nRooted in the pragmatics tradition, Langton (2012) offers some important \nclarifications. Bringing hate speech and pornography into the same analytical frame, she highlights how hate speech and pornography \u201cwork\u201d as speech acts in \u201ca perlocutionary, causal sense, and an illocutionary, constitutive sense\u201d (p.\u00a076). Extending speech act theory with the argument on \u201cpresupposition accommodation,\u201d Langton concludes that hate speech and pornography\nwork more subtly.\u00a0 .\u00a0 .\u00a0 . They implicitly presuppose certain facts and norms.\u00a0.\u00a0.\u00a0. Consumers then change their factual and normative beliefs by taking on board the common ground\u00a0.\u00a0.\u00a0. or the conversational score\u00a0.\u00a0.\u00a0. that is presupposed in the pornographic [or hateful] conversation.\n(p.\u00a083)\nThe pragmatic model offers an \u201cadequate story about how belief change \ncan be achieved,\u201d she points out, but what about \u201cfeelings and desire\u201d (p.\u00a085)? Here, Langton ventures to take a leap:\n[T]he phenomenon of accommodation might extend beyond belief\u00a0 \u2013 beyond conversational score, and common ground, as originally con -\nceived\u00a0\u2013 to include accommodation of other attitudes, including desire and hatred\u00a0.\u00a0.\u00a0. just as a hearer\u2019s belief can spring into being, after the speaker presupposes that belief, so too a hearer\u2019s desire can spring into being, after the speaker presupposes the hearer\u2019s desire; and so too a hearer\u2019s hatred can spring into being, after the speaker presupposes that hatred.\n(p.\u00a086)\nIn so doing, Langton puts emotion in an explanatory model that was origi -\nnally conceived to explain processes that apply reason to achieve belief. What this formal analysis in the pragmatic model lacks\u00a0\u2013 which makes the argu-ment seem like a leap\u00a0\u2013 can be addressed with a social interactional model and a media practice approach linked to it. The social interactional frame of \u201cfun\u201d as a \u201cmeta-practice of extreme speech\u201d ( Udupa, 2019) offers ways \nto account for how Doge and his followers are not merely reproducing reli -\ngious majoritarian nationalism as a cognitive script\u00a0\u2013 a belief\u00a0\u2013 but renewing it through the affective charge of participation, drawing support from one another, scheming \u201craids\u201d on opponents, and applauding the \u201chard work\u201d of fellow members, all while consuming and beseeching porn. Fun as a meta-practice of online extreme speech unfolds in four interconnected ways:\n\u2022 \u201cbeing \u2018funny\u2019 as a tactical way to enter and rise to prominence within \nonline debates and, by extension, the broader public domain\n\u201cDeal\u201d of the Day  139\n\u2022 deriving fun from the sheer freshness of colloquialism in political debates, \nwhich stands in contrast to the serious tone of political deliberation and \nofficial centricity, and by mainstreaming the witty political campaign styles as an everyday form of political communication\n\u2022 fun as satisfaction of achieving a goal by working with one\u2019s own resources \nand in finding tangible results such as hashtag trending, virality, and per -\nceived \u201creal world\u201d changes\n\u2022 as group identification and collective (if at times anonymous) celebration \nof aggression\u201d\n(Udupa, 2019, p.\u00a03144)\nWhile pornified hate groups share all these features, male homosociality\u00a0\u2013 \u201cperformance of manhood as staged in front of, and granted, by other men\u201d\u00a0\u2013 is a distinctively pronounced feature ( Semenzin\u00a0& Bainotti, 2020, \np.\u00a0 3). The sexualized nature of conversations builds on an appetite for porn, as ring leaders of the movement articulate disinhibition and open embrace, in distinction to a more conservative view of feeling secretive or even embarrassed about porn consumption. Homosociality can itself have disinhibiting effects as there is a performative aspect to such group gatherings with validating impacts, but what is significant, as the thematic mix in the chat groups illustrates, is that right-wing nationalist groups of Doge\u2019s kind indicate they need no further justification than the frame of the nation itself. Put differently, there is not just an \u201celective affinity\u201d or \u201cfamily resemblance\u201d ( Brubaker, 2017) between right-wing discourses \nand misogyny, but right-wing political cultures thrive on sexualized and pornified anti-women cultures as digitally savvy teenagers become their torchbearers.\nIn the Indian context, for right-wing nationalism, which today relies on \nextensive networks of digital propaganda and an army of seemingly spon -\ntaneous \u201cvolunteers,\u201d gendered abuse is a crucial tactic, strategy, and sen -\nsibility. As gendered abuse expands within different political groups in their online campaigns and confrontations, it has become not only more com-mon, as our interlocutors vouch and reports confirm (Amnesty International India, 2020; Gurumurthy\u00a0& Dasarathy, 2022), but it has also become more variegated. Trolling, slut-shaming, infantilizing, and ad hominem attacks \nthat make up what one of our interlocutors described rather piquantly as \u201cbasic misogyny\u201d are today digitally \u201cenhanced\u201d with the easy creation and devious circulation of \u201cdick pics,\u201d pornified images, and auctions, brewed as such within the caldrons of Internet fun and in service of nationalist majori -\ntarianism.\n3 While the content and manner of engagement around porn fun \nare not uncontested even among right-wing ideologues, they are absorbed within the vastly diversified digital antics, as one other activity that helps the purpose.\n140 Sahana Udupa and Oeendrila Lahiri Gerold\nAcknowledgments\nThis project has been supported by generous funding from the Bavarian \nResearch Institute for Digital Transformation (BIDT Project: Understanding, Detecting and Mitigating Against Politically Active Women, 2022\u201325).\nNotes\n 1 \u201cSulli\u201d and \u201cBulli\u201d are derivatives of \u201cMulli,\u201d a slang word for Muslim women. \nThese are considered as \u201cIslamophobic slurs\u201d which originate from the derogatory \nuse of the word \u201cMulla\u201d which refers to a Muslim male (Salim, 2022).\n 2 Politics around queer publics is also shifting within and beyond Hindu right ideo -\nlogical groups. This requires a separate discussion, which is beyond the scope of this chapter. The discussion here also leaves out questions of sexuality in relation to Christians, Sikhs, and other religious minorities.\n 3 Rape and death threats against women constitute another type of misogyny, which \nis recognized as a serious issue in contemporary digital politics ( Gurumurthy\u00a0& \nDasarathy, 2022; Iyer et\u00a0al., 2020; Kenya ICT Action Network, 2020).\nReferences\nAgarwal, P. (1995). Surat, Savarkar, and Draupadi: Legitimizing rape as a political \nweapon. In T. Sarkar\u00a0& U. Butalia (Eds.), Women and the Hindu right: A\u00a0collec -\ntion of essays (pp.\u00a029\u201357). Women for Kali.\nAmnesty International India. (2020). Troll patrol: Exposing online abuse faced by \nwomen politicians in India. Indians for Amnesty International Trust.\nAulakh, G.,\u00a0& Sengupta, D. (2017, June 2). Plunging mobile data costs present a \ndirty picture. The Economic Times. https://economictimes.indiatimes.com/article \nshow/58967964.cms?utm_source=contentofinterest&utm_medium=text&utm_campaign=cppst\nBachetta, P. (2004).  Gender in the Hindu nation: RSS women as ideologues . Women \nUnlimited.\nBhalla, G. (2022, January 19).  Obscene comments made against Muslim women on \nClubhouse App now, Delhi police file FIR. IndiaTimes. https://www.indiatimes.\ncom/news/india/obscene-comments-muslim-women-clubhouse-559731.html\nBracewell, L. (2021).  Gender, populism, and the QAnon conspiracy movement. Fron-\ntiers in Sociology, 5. https://doi.org/10.3389/fsoc.2020.615727\nBrownmiller, S. (1975). Against our will: Men, women and rape. Bantam.Brubaker, R. (2017). Why populism? Theory Society, 46, 357\u2013385.Burgess, A. (1970). What is pornography? In D. A. Hughes (Ed.), Perspectives on por -\nnography. St. Martin\u2019s Press. Cited in Langton, R. (2012). Beyond belief: Pragmat -\nics in hate speech and pornography. In I. Maitra\u00a0& M. K. McGowan (Eds.), Speech \nand harm: Controversies over free speech (pp.\u00a072\u201393). Oxford University Press.\nButler, J. (1997). Excitable speech: A\u00a0Politics of the performative. Routledge.Couldry, N. (2012). Media, society, world: Social theory and digital media practice . \nPolity.\nDas, V. (2007). Life and words: Violence and the descent into the ordinary . University \nof California Press.\nDeKeseredy, W. S. (Chapter\u00a04 this volume). Misogyny and woman abuse in the ince-\nlosphere: The role of incel male peer support.\nFarooqui, J. (2023, March 17). Report says over 700 million active internet users in India \nas of December 2022. The Economic Times . https://economictimes.indiatimes.com/\n\u201cDeal\u201d of the Day  141\ntech/technology/report-says-over-700-million-active-internet-users-in-india-as-of-\ndecember-2022/articleshow/98673654.cms\nFazili, S. (2022, January 2).  Months after Sulli deals, Bulli Bai app puts Muslim  \nwomen on \u201cAuction.\u201d BOOM. https://www.boomlive.in/explainers/muslim-women-  \nonline-auction-github-sulli-deals-bulli-bai-16236\nForberg, P. L. (2022).  From the fringe to the fore: An algorithmic ethnography of the \nfar-fight conspiracy theory group QAnon. Journal of Contemporary Ethnography , \n51(3), 291\u2013317. https://doi.org/10.1177/08912416211040560\nFuchs, C. (2018). Digital demagogue: Authoritarian capitalism in the age of Trump \nand Twitter. Pluto Press. https://doi.org/10.2307/j.ctt21215dw\nGarg, A. (2022, October 1). What is Bulli Bai app, what is its link to Sulli deals, and \nhow GitHub is involved: Story in 10 points. India Today. https://www.indiatoday. \nin/technology/features/story/what-is-bulli-bai-app-what-is-its-link-to-sulli-  \ndeals-and-how-github-is-involved-story-in-10-points-1898365-2022-01-10\nGeismar, H.,\u00a0& Knox, H. (Eds.). (2021). Digital anthropology (2nd ed.). Routledge. \nhttps://doi.org/10.4324/9781003087885\nGoyal, P. (2021, May 15). Ritesh Jha aka \u2018Liberal Doge\u2019: The man behind the lives -\ntream spewing hate against Pakistani women. Newslaundry. https://www.news  \nlaundry.com/2021/05/15/ritesh-jha-aka-liberal-doge-the-man-behind-the-livestream-  \nspewing-hate-against-pakistani-women\nGurumurthy, A.,\u00a0& Dasarathy, A. 2022.  A study on abuse and misogynistic trolling \non Twitter directed at Indian women in public-political life . https://itforchange.\nnet/a-study-of-abuse-and-misogynistic-trolling-on-twitter-directed-at-indian-women-public-political\nHansen, T. B. (1999). The saffron wave: Democracy and Hindu nationalism in mod-\nern India. Princeton University Press.\nHardaker, C. (2010).  Trolling in asynchronous computer-mediated communication: \nFrom user discussions to academic definitions. Journal of Politeness Research, 6(2), 215\u2013242. https://doi.org/10.1515/jplr.2010.011\nHawley, G. (2017). Making sense of the Alt-Right. Columbia University Press.The Hindu. (2022, January 12).  \u2018Sulli deals\u2019, form of hate speech in India, must be \ncondemned: UN official . https://www.thehindu.com/news/international/sulli-deals- \nform-of-hate-speech-in-india-must-be-condemned-un-official/article38247094.ece\nIyer, N., Nyamwire, B.,\u00a0& Nabulega, S. (2020).  Alternate realities, alternate Inter -\nnets: African feminist research for a feminist internet . https://ogbv.pollicy.org/ \nreport.pdf\nJafri, A.,\u00a0& Aafaq, Z. (2021, May 21).  Unchecked Tsunami of online sexual violence by \nHindu right against India\u2019s Muslim women . Article-14. https://www.article-14.com/\npost/unchecked-tsunami-of-online-sexual-violence-by-hindu-right-against-india-s-muslim-women\nJaiswal, P. B. (2021). Indians scoured the internet for porn during the pandemic. The  \nWeek. https://www.theweek.in/theweek/cover/2021/08/26/indians-scoured-the-inter  \nnet-for-porn-during-the-pandemic.html\nJohanssen, J. (2022).  Fantasy, online misogyny and the Manosphere: Male bodies of \ndis/inhibition. Routledge.\nKannan, S. (2020, April 11).  Pornography gets a pandemic boost, India reports 95 per \ncent rise in viewing. India Today. https://www.indiatoday.in/news-analysis/story/ \npornography-gets-a-pandemic-boost-india-reports-95-per-cent-rise-in-viewing-  \n1665940-2020-04-11\nKenya ICT Action Network. (2020). Trends of online violence against women  \nin politics during the COVID19 pandemic in Kenya\n. Retrieved March 2,  \n2021, from https://africaninternetrights.org/sites/default/files/Trends-of-Online  \nViolence-against-Women-in-Politics-During-the-COVID19-pandemic-in-  \nKenya.pdf\n142 Sahana Udupa and Oeendrila Lahiri Gerold\nKeskinen, S. (2013).  Antifeminism and white identity politics: Political antago -\nnisms in radical right-wing populist and anti-immigration rhetoric in Finland. \nNordic Journal of Migration Research , 3(4), 225\u2013232. https://doi.org/10.2478/\nnjmr-2013-0015\nKhaund, T., Hussain, M. N., Shaik, M.,\u00a0& Agarwal, N. (2021). Telegram: Data collec-\ntion, opportunities and challenges. In J. A. Lossio-Ventura, J. C. Valverde-Rebaza, E. D\u00edaz,\u00a0 & H. Alatrista-Salas (Eds.), Information management and big data  \n(pp.\u00a0513\u2013526). Springer. https://doi.org/10.1007/978-3-030-76228-5_37\nKumar, M. (2022). Communalism and sexual violence in India : The politics of gen-\nder, ethnicity and conflict. Bloomsbury Academic India.\nLangton, R. (2012).  Beyond belief: Pragmatics in hate speech and pornography. In \nI. Maitra\u00a0& M. K. McGowan (Eds.), Speech and harm: Controversies over free \nspeech (pp.\u00a072\u201393). Oxford University Press.\nMantilla, K. (2015). Gendertrolling: How misogyny went viral. ABC-CLIO, LLC.Massanari, A. (2015). #Gamergate and the fappening: How Reddit\u2019s algorithm, gov -\nernance, and culture support toxic technocultures. New Media and Society , 19(3), \n329\u2013346. https://doi.org/10.1177/1461444815608807\nNagle, A. (2016, March).  The new man of 4chan. The Baffler, 30, 64\u201376. https://\nthebaffler.com/salvos/new-man-4chan-nagle\nNussbaum, M. C. (1999). Sex and social justice. Oxford University Press.Ojha, A. (2022, January 8).  Bulli Bai app creator Niraj Bishnoi a repeat offender: \nHere\u2019s how Delhi cops nabbed him. India Today. https://www.indiatoday.in/india/\nstory/bulli-bai-app-creator-neeraj-bishnoi-delhi-police-1897033-2022-01\u201307\nPatu,\u00a0& Schrupp, A. (2017). A brief history of feminism. The MIT Press.Piedalue, A., Gilbertson, A.,\u00a0& Raturi, M. (2021).  A\u00a0majoritarian view of \u2018gender jus -\ntice\u2019 in contemporary India: Examining media coverage of \u2018triple Talaq\u2019 and \u2018love Jihad.\u2019 South Asia: Journal of South Asian Studies , 44(4), 739\u2013755. https://doi.org/ \n10.1080/00856401.2021.1951477\nRogers, R. (2020).\n Deplatforming: Following extreme internet celebrities to  Telegram \nand alternative social media. European Journal of Communication , 35(3), \n213\u2013229. https://doi.org/10.1177/0267323120922066\nSalim, M. (2022, January 16).  \u2018Bulli Bai\u2019, \u2018Sulli deals\u2019: On being put up for \u2018auc -\ntion\u2019 as an Indian Muslim woman. The Wire. https://thewire.in/communalism/\nindian-muslim-woman-auction-bulli-bai\nSarkar, T. (2021). Hindu nationalism in India. C Hurst and Company Pub Limited.Sarracino, C.,\u00a0& Scott, K. M. (2008).  The porning of America: The rise of porn cul -\nture, what it means, and where we go from here. Beacon Press.\nSegarra, I. M.,\u00a0& Anderson, K. V. (2019).  Political pornification gone global: Teresa \nRodr\u00edguez as fungible object in the 2015 Spanish regional elections. Quarterly \nJournal of Speech , 105(2), 204\u2013228. https://doi.org/10.1080/00335630.2019. \n1595102\nSemenzin, S.,\u00a0& Bainotti, L. (2020). The use of Telegram for non-consensual dissemina -\ntion of intimate images: Gendered affordances and the construction of masculinities. Social Media + Society, 6(4), 1\u201312. https://doi.org/10.1177/2056305120984453\nShekhar, R. (2022, January 7).  Bulli Bai app case: How BTech student from Assam \nlost his way. The Times of India . https://timesofindia.indiatimes.com/city/delhi/\nvirtual-harassment-how-student-lost-his-way/articleshow/88742860.cms\nSingh, R. (2020, January 2).  Are Indians obsessed with sex? Report says India leads  \nglobal porn consumption on smartphones. India.Com. https://www.india.com/viral/  \nindia-leads-global-porn-consumption-on-smartphones-at-89-says-report-3896539/\nSinha, M.,\u00a0& Fernandes, L. (2014).  Gendered nationalism: From women to gender \nand back again? In L. Fernandes (Ed.), Routledge handbook on gender in South \nAsia (pp.\u00a013\u201327). Routledge.\n\u201cDeal\u201d of the Day  143\nTaskin, B. (2022, January 7).  Bulli Bai \u201cmastermind\u201d part of Sulli deals too, \nmade Muslim alias to mislead: Delhi police. The Print. https://theprint.in/india/ \nbulli-bai-mastermind-part-of-sulli-deals-too-made-muslim-alias-to-mislead-  \ndelhi-police/798116/\nThe Times of India. (2018, December 27).  Pornhub\u2019s third largest customer base \ncomes from India. https://timesofindia.indiatimes.com/home/news/pornhubs-  \nthird-largest-customer-base-comes-from-india/articleshow/67268431.\ncms#:~:text=As%20per%20a%20report%2C%2035,Indians%20aged%20between%2018%2D34\nTranchese, A.,\u00a0& Sugiura, L. (2021).  \u201cI don\u2019t hate all women, just those stuck-up \nbitches\u201d: How incels and mainstream pornography speak the same extreme lan-guage of misogyny. Violence Against Women , 27(14), 2709\u20132734. https://doi.\norg/10.1177/1077801221996453\nUdupa, S. (2018). Gaali cultures: The politics of abusive exchange on social media. New \nMedia\u00a0& Society, 20(4), 1506\u20131522. https://doi.org/10.1177/1461444817698776\nUdupa, S. (2019). Nationalism in the digital age: Fun as a metapractice of extreme \nspeech. International Journal of Communication, 13, 3143\u20133163. https://doi.\norg/10.5282/ubm/epub.69633\nvan der Veer, P. (1994).  Religious nationalism: Hindus and Muslims in India . Univer -\nsity of California Press.\nWalther, J. B. ( Chapter\u00a02 this volume) Making a case for a social processes approach \nto online hate.\nWalton, S. J. (2012).  Anti-feminism and misogyny in Breivik\u2019s \u201cManifesto\u201d. \nNORA-Nordic Journal of Feminist and Gender Research, 20(1), 4\u201311.\nZubair, M., Sinha, P.,\u00a0& Chaudhuri, P. (2021, November 15). Sulli deals: Organised \nattempt to blame a Muslim youth for the app. Alt News. https://www.altnews.in/\nsulli-deals-organised-attempt-to-blame-a-muslim-youth-for-the-app/\nZuckerman, E. (2008, March 9). The cute cat theory of digital activism\n. World -\nChanging. https://web.archive.org/web/20120630231006/https://www.world-\nchanging.com/archives/007877.html\nDOI: 10.4324/9781003472148-7\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Between 2017 and 2023, American universities reported more than 1,000 \nincidents of white supremacist recruitment materials on college campuses (ADL, 2019, 2023), thousands of hate crimes ( Bauman, 2018), and myriad \ninstances of right-wing extremist mobilization ( Iannelli, 2018; Quintana, \n2018; SPLC, 2018). While the perpetrators behind extremist recruitment and \nhate crimes are rarely identified, right-wing extremist mobilization has been linked to rogue chapters of conservative youth organizations. These rogue chapters have espoused such extreme ideology that they were de-chartered by their parent organization and denounced by the Republican Party (Alonso, 2022; ND GOP, 2022; Polletta, 2019). Campus-based extremism carried out \nby conservative youth organizations is alarming because these organizations function as a bellwether of the Republican Party. Participation often leads to a political career ( Binder\u00a0& Kidder, 2022). James O\u2019Ryan Allsup ( SPLC, \n2022a), Kyle Bristol (SPLC, 2022b), and Crystal Clanton (Raymond, 2022) are examples of extremists who used participation in a conservative stu -\ndent organization to attain positions of power within the Republican Party. Extremism on college campuses represents a social problem and a potential national security threat. Yet, it is understudied.\nThis chapter provides an explanation for campus-based radicalization. It \nemerged from a four-year, multisite ethnography of College Conservatives for Freedom and Liberty, a national conservative youth organization with chapters in major universities across the United States. At each of the field sites, I\u00a0witnessed a phenomenon I\u00a0call digitally mediated spillover . Digitally \nmediated spillover occurs when activists who participated in a digital social movement enter a new movement, bringing their ideology and culture, tacti -\ncal repertoires, and social networks.7\nDIGITALLY MEDIATED SPILLOVER AS A \nCATALYST OF RADICALIZATION\nHow Digital Hate Movements Shape Conservative \nYouth Activism\nAdam Burston\nDigitally Mediated Spillover as a Catalyst of Radicalization  145\nDigitally mediated spillover began when right-wing extremists who had \nformerly participated in digital movements during high school began their \nuniversity career and joined moderate conservative youth groups. In the chapters where moderates remained a majority and retained leadership posi -\ntions, digitally mediated spillover was highly disruptive but did not result in radicalization. However, at one of the field sites, right-wing extremists obtained leadership positions and radicalized a sufficient number of moder -\nate activists to become the majority. There were three phases of digitally mediated spillover that ultimately yielded extremism. First, extremists altered the collective identity at W-CCFL by exposing their peers to extremist cyber -\nculture. Second, extremists rendered their peers ideologically extreme and transformed the Group Chat into a \u201cradical milieu,\u201d a social network in which sympathetic members of the public offer moral support to extremists. Third, W-CCFL activists became tactically extreme, and this led to organiza-tional implosion.\nDefining Key Terms\nIt is important to define key constructs for interdisciplinary audiences. Extremism and radicalization are terms that are highly contested across the social sciences (McCauley\u00a0 & Moskalenko, 2017). Ideological extremism entails sympathizing with and advocating for ideologies and practices that disturb a target (e.g., targeted online harassment, sharing racist conspiracy theories online), whereas behavioral extremism describes a willingness to organize or enact physical violence against perceived enemies or innocent civilians (e.g., hate crime, terrorism). Common elements of ideological and behavioral extremism include a shared disdain for democracy, pluralistic society, and the rule of law ( Lowe, 2017). Thus, for the purposes of this \nchapter, I\u00a0 define radicalization as the process in which a moderate social movement becomes ideologically or behaviorally extreme.\nA social movement is a social network that enacts \u201ccollective efforts, of \nsome duration and organization, using noninstitutionalized methods to bring about social change\u201d ( Flacks, 2005, p.\u00a0 5). Historically, successful social \nmovements have been dense, relatively closed social networks with strong ties among members and organizations at their center (e.g., community centers, nonprofit organizations). However, social media platforms have given rise to \u201cconnective action\u201d or social movements comprising loosely connected social networks with weak ties among members ( Kasimov, 2023). Social move -\nments based on connective action are less effective at coordinating offline protests and lobbying for policy reform, but more effective at disseminating movement ideology to the public (Malthaner\u00a0& Waldmann, 2014).\nSocial movement spillover is a phenomenon in which the \u201cthe ideas, tac -\ntics, style, participants, and organizations of one social movement spill over \n146 Adam Burston\nits boundaries to effect other social movements\u201d ( Meyer\u00a0& Whittier, 1994 , \np.\u00a0277). Originally, spillover was formulated to describe Second Wave Femi -\nnists joining and altering the trajectory of the Nuclear Freeze Movement in \nthe 1980s. Feminists left an indelible mark on that movement by infusing anti-nuclear ideology with feminist logics, teaching feminist protest tactics to Nuclear Freeze activists, and providing personnel and organizations to the fledgling movement.\nMy designation \u201cdigitally mediated\u201d refers to social processes that are \naltered by digital cultures. Digitally mediated social processes occur when \nideologies, social norms, and behaviors that originated in a particular online context shape social processes in a new online or offline context. Digitally mediated social processes are often but not always transacted through computer-mediated communication. Examples of digitally mediated social processes range from participation in Internet raids in which members of one digital community infiltrate another as a prank or cyber-attack, offline conventions in which fans of a web-based comic series meet to discuss their shared passion, to QAnon protests in which offline mobilization is governed by a community of web-based conspiracy theorists. This chapter examines digitally mediated spillover to explain the social processes through which extremist social movements transmit the culture of cyberhate into new online and offline spaces. Put differently, digitally mediated spillover illustrates that the social processes of online hate are transmissible.\nPathways to Radicalization\nIn response to the recent wave of right-wing extremism, a body of interdis -\nciplinary scholarship has emerged to explain the influence of social media technologies in radicalization. This research mostly addresses the influence of \u201cecho chambers,\u201d or ideologically homogenous social networks online, and filter bubbles in which algorithms assign certain users ideologically homog-enous and polarizing content (for review, see Zhuravskaya et\u00a0 al., 2020). \nDespite the strengths of this research, its approach to online radicalization is too narrowly focused on the \u201chow,\u201d not the \u201cwhy,\u201d of radicalization. Socio-logical insights about the macrostructural trends and interactional dynamics that produce the radicalization prove useful.\nRight-wing extremist social movements emerge in response to macrostruc -\ntural threats that undermine their political, cultural, and economic power (for review, see Simi et\u00a0al., 2024). In response to these threats, right-wing extremist movements form hidden spaces of hate and radical milieus. A\u00a0hid -\nden space of hate is a closed social network where activists cultivate col -\nlective identity and plan protest activity while avoiding outside interference from law enforcement and enemies ( Simi\u00a0& Futrell, 2015). Whether digital \nor physical, hidden spaces of hate are instrumental to right-wing movements, \nDigitally Mediated Spillover as a Catalyst of Radicalization  147\ngiven the time and resources required to transform members of the general \npublic into committed extremists (Atran, 2021; Simi\u00a0& Futrell, 2015). Move-\nment leaders create hidden spaces of hate to foment feelings of isolation, despair, and anger as well as a collective identity that supplants activists\u2019 individual identity ( Atran, 2021). A\u00a0radical milieu is a large social network \ncomprising extremists and sympathetic members of the general public, who encourage one another to adopt extremist ideology and employ violent or antisocial tactics. Radical milieus are the social environments that produce ideological and behavioral extremism (Malthaner\u00a0& Waldmann, 2014).\nTaken together, scholarship on pathways into radicalization suggests \nthat the recent wave of right-wing extremism is due to a combination of macrostructural trends that threatened white and male dominance, thereby incentivizing the formation of hidden spaces of hate for movement expan -\nsion and radical milieus for increased dialogue with the general public. The algorithms, features, and affordances of social media technology accelerated nationwide radicalization by conveying extremist ideology to segments of the population that did not seek it out voluntarily (Zhuravskaya et\u00a0al., 2020).\nHowever, despite the explanatory power of scholarship cited above, it does \nnot account for the mass radicalization of conservative student movements. Conservative student organizations have a preexisting commitment to the electoral process and social pluralism. They are not hidden spaces of hate, and their preexisting ideological commitments should\u00a0\u2013 in theory\u00a0\u2013 make mem -\nbers more resistant to extremist ideological appeals. Some social scientists offer a different explanation for this radicalization, although it is highly prob -\nlematic. A\u00a0recent body of scholarship explains the recent surge of right-wing extremism on college campuses with a theory of \u201centryism,\u201d which argues that right-wing extremist organizations like the Proud Boys and the American Identity Movement (formerly Identity Evropa) send members to college cam-puses to infiltrate and coopt conservative student organizations in the hopes of sending right-wing extremists into Congress ( ADL, 2019; Miller-Idriss, \n2020). The concept of entryism emerged in case studies of successful infiltra -\ntion attempts as well as in internal documents from extremist organizations. Although entryism provides a partial explanation for right-wing extremism in universities, it is inadequate. First, despite their outsized political influ -\nence, right-wing extremist organizations have insufficient personnel and funding to stage a national conspiracy. Moreover, the fractious nature of right-wing extremist movements often impedes their execution of complex plans (Simi\u00a0& Windisch, 2020 ). For instance, Patriot Front, the organization \nresponsible for the majority of reported white supremacist recruitment flyers on college campuses between 2017 and 2019, is now defunct ( ADL, 2019). \nSecond, the radicalization of conservative youth organizations has occurred in locations where there are no known extremist organizations that recruit on university campuses. Third, entryism assumes that a few infiltrators can \n148 Adam Burston\nfundamentally alter organizations that have a preexisting ideological com -\nmitment to moderate conservatism and civic engagement. Other literature \nsuggests that group radicalization is a time-consuming process that requires majority consensus ( Atran, 2021; Simi\u00a0& Futrell, 2015 ). Thus, infiltrating \nand radicalizing student organization en masse are beyond the capabilities of \ncontemporary hate organizations.\nIn light of the shortcomings of current explanations for radicalization on \ncollege campuses, this study sought, and developed, an alternative explana-tion. This alternative is the process of digital mediated spillover. This new notion was informed by a grounded theory analysis and interpretation of the results of a multisite ethnography of a right-leaning college conserva-tive movement student organization, the procedures and research methods of which are described as follows.\nMethod\nField Sites\nData for this study come from a multisite ethnography of a conservative \nsocial movement, College Conservatives for Freedom and Liberty (hereaf -\nter CCFL). CCFL is one of several organizations for politically conservative college and high school students who wish to participate in activism and electoral politics. CCFL\u2019s primary goals are spreading conservative values on university campuses and achieving electoral victories for Republican and Lib -\nertarian candidates. Every CCFL chapter meets weekly or biweekly and relies on digital chat platforms, like GroupMe and Facebook Messenger, to keep members connected between organizational meetings. I\u00a0entered the field in January 2018 and concluded my study in December 2021.\nMy initial goal in doing a multisite ethnography was to capture impor -\ntant variations in regional and local political culture. In order to understand these variations, I\u00a0studied a CCFL chapter in three U.S. census regions\n1: The \nWest, the Northeast, and the South. In each census region, I\u00a0studied a flag -\nship public university located in a mid-size city. I\u00a0selected public universi -\nties because they recruit heavily from the local population, enabling me to better understand the influence of local culture on activism. I\u00a0assigned each university and CCFL chapter a pseudonym based on their census region. West Coast University (hereafter W-CCFL)\n2 is situated in a progressive \ncity in a state that is considered a bulwark of Democratic party votership. East Coast University (hereafter E-CCFL) is located on the border of the Midwest and East Coast and attracts students from both census regions. East Coast University is located in a purple state that is hotly contested by Democrats and Republicans during election season. Southern University (hereafter S-CCFL) is located in a majority Republican city in a state that \nDigitally Mediated Spillover as a Catalyst of Radicalization  149\nhas a nationwide reputation as a bastion of Republican votership and con -\nservative culture.\nThe ethnographic research involved a mixture of 34 behavioral observa -\ntions, 64 interviews,3 and a review of organizational documents and social \nmedia activity at each field site.4 At Western University (January 2017 to \nMarch 2018), I\u00a0conducted 21 instances of observation and 24 interviews; \nat Eastern University, I\u00a0conducted 8 instances of observation and 22 inter -\nviews; at Southern University, I\u00a0conducted 5 instances of observation and 15 interviews. During interviews, I\u00a0offered informants a research laptop and asked them to show me how they use social media in their activism. Inform -\nants at W-CCFL, the most extreme field site and the primary focus of this chapter, refused to show me their social media activity, having sworn an oath of secrecy to leadership. At this field site, I\u00a0had to rely on my inform -\nants\u2019 descriptions of their social media behavior. Table\u00a0 7.1 summarizes basic \ndemographics of the informants.\nDuring the chapters\u2019 organizational meetings, activists met face to face for \n60 to 90 minutes. Because the majority of organizational meetings consisted of debates and strategy sessions, I\u00a0was able to take highly detailed records of dialogue which appear more like transcripts or meeting notes than typical ethnographic fieldnotes from dynamic settings. During fundraisers and cam -\npaigning events, my fieldnotes were more focused on behavior than dialogue. At each field site, I\u00a0began by introducing myself to the president and ask -\ning their permission to describe my research project to the members. In my announcement, I\u00a0gave members the opportunity to opt out of being included in my fieldnotes. I\u00a0did not audio record meetings due to a prohibition by my university\u2019s Institutional Review Board for the protection of human research participants. Below, interview and fieldnote excerpts with direct quotations are presented in double quotation marks (\u201c\u201d), while paraphrased statements are in single quotation marks (\u2018\u2019).\nCoding and Analysis\nMy concept of digitally mediated spillover was developed using grounded theory analysis ( Corbin\u00a0& Strauss, 2008 ; Salda\u00f1a, 2013). I\u00a0used Atlas.Ti to \napply codes to the data. In a preliminary round of \u201cprocess coding,\u201d I\u00a0labeled each sentence with gerunds to capture social action ( Salda\u00f1a, 2013). Exam-\nples of axial codes include \u201cencountering extremism online\u201d and \u201cenforc -\ning group hierarchy.\u201d Subsequently, I\u00a0 completed \u201caxial coding\u201d in which I\u00a0removed redundant codes and grouped thematically similar codes under a common heading. For instance, \u201cmemeing,\u201d \u201cmaking fun of peers,\u201d and similar codes were unified under the code: \u201cStrategic humor.\u201d I\u00a0completed the analysis by synthesizing the axial codes to develop my model of digitally mediated spillover.\n150 Adam BurstonTABLE\u00a07.1   Informant Data\nRadicalization \nSource\nDigital Movement\nNADigital MovementDigital MovementNANADigital MovementNACCFLNADigital MovementNANACCFLCCFLDigital MovementCCFLDigital MovementCCFLNANANACCFLPolitical Ideology at \nTime of Interview\nModerateModerateExtremistExtremistProgressiveModerateExtremistModerateExtremistModerateExtremistModerateModerateExtremistExtremistExtremistExtremistExtremistExtremistModerateModerateModerateModerateAnnual Parental \nIncome Range ($)\n50,000\u201369,999200,000\u2013249,999100,000\u2013149,99974,000\u201399,999\u201350,000\u201374,999\u2013250,000\u2013299,99925,000\u201350,00025,000\u201350,000200,000\u2013249,999\u2013150,000\u2013199,999150,000\u2013199,999200,000\u2013250,00025,000\u201349,999300,000+\u201350,000\u201375,00075,000\u201399,999300,000+75,000\u201399,999100,000\u2013149,999Religion\nAgnostic\nn\nAgnostic\nn\nnnnnnnn\nAgnostic\nnn\nn\nn\nn\nna\na\naaaaaaa\na\na\na\na\na\nai\ni\niiiiiii\ni\ni\ni\ni\ni\nit\nt\nttttttts\nAtheist\nts\ns\ns\ns\ns\nAtheist\ntt\ntt\nts\ns\ns\ns\ns\nssi\ni\nAgnostic\ns\nsi\ni\niiiii\ni\ni\ni\nir\nr\nrr\nr\nrrr\nr\nr\nAgnostic\ni\nir\nr\nr\nr\nrh\nh\nhhhhhhh\nh\nh\nh\nh\nh\nhC\nC\nCCCCCCC\nC\nC\nC\nCJewishCCRace\nWhite\nWhiteWhiteWhiteBlackWhiteHispanicWhiteHispanicWhiteWhiteWhiteWhiteWhiteWhiteHispanicSouth AsianWhiteMaleWhiteWhiteHispanicWhiteAge\n22\n212220\u201321\u201324192921221920182020212419182126Pseudonym\n-CCFL W\nAntonioAtticusBruceCalebChloeDaphneDavidDustinEddyGarrettJamesJoe\nJustin\nMartinMichaelSahil\nSebastianShoshana\naylorJosh\nScott\nSheilaSummer\nT\n(Continued)\nDigitally Mediated Spillover as a Catalyst of Radicalization  151)Radicalization \nContinuedSource\n(NA\nNANANANADigital MovementNANANANANANADigital MovementNANADigital MovementNADigital MovementDigital MovementNANAPolitical Ideology at \nime of InterviewT\nModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateAnnual Parental \nIncome Range ($)\n100,000\u2013149,000100,000\u2013149,00075,000\u201399,999300,000+150,000\u2013199,999300,000+75,000\u201399,999200,000\u2013249,999\u2013300,000+75,000\u201399,99925,000\u201349,99975,000\u201399,999300,000+300,000+100,000100,000\u2013149,999100,000\u2013149,999100,000\u2013149,99975,000\u201399,999100,000\u2013149,000Religion\nnnn\nn\nn\nnnnnnnn\nn\nnnnnaaa\nJewish\na\nJewishJewish\naaaaaaaa\nAtheist\naaaaaiii\ni\ni\niiiiiii\ni\niiiittt\nt\nt\nttttttt\nt\nttttsss\ns\ns\nsssssss\ns\nssssiii\ni\ni\niiiiiii\ni\niiiirrr\nr\nr\nrrrrrrr\nr\nrrrrhhh\nh\nh\nhhhhhhh\nh\nhhhhCCC\nC\nC\nCCCCCCC\nC\nCCCCRace\nWhite\nWhiteWhiteWhiteWhiteWhiteWhiteWhiteWhiteWhiteBlackWhiteWhiteWhiteWhiteWhiteWhiteWhiteWhiteWhiteSouth Asian(Continued)\nAge\n21\n1920201920212321201919202020221920202018 \n1 . TABLE 7\nPseudonym\nE-CCFL\nAaronAlekAlfredAsherConnorHaimIsaacJason\nMario\nMary\nPatrick\nPaul\nRobertThomas\nylerTimothy\ninayJon\nPamRich\nSmith\nT\nV\n152 Adam Burston\nRadicalization \nSource\nNA\nNANANANANANANANANANANANANA\n-CCFL. Seven were extremists at WPolitical Ideology at \nTime of Interview\nModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateModerateAnnual Parental \nIncome Range ($)\n50,000\u201374,999\u2013150,000\u2013199,999300,000+150,000\u2013199,99950,000\u201374,999300,000+200,000\u2013249,99925,000\u201349,000200,000\u2013249,999300,000+150,000\u2013199,999300,000+25,000\u201349,999Religion\nnnnnnnnnnnn\nn\nnaaaaaaaaaaa\na\naiiiiiiiiiii\ni\nittttttttttt\nt\ntsssssssssss\nDeist\nssiiiiiiiiiii\ni\nirrrrrrrrrrr\nr\nrhhhhhhhhhhh\nh\nhCCCCCCCCCCC\nC\nCRace\nWhite\nWhiteWhiteWhiteWhiteBlackWhiteWhiteHispanicWhiteWhiteHispanicAsianWhite(Continued)\nAge\n20\n\u201323182022\u20131922\u201322211919 \n1 TABLE 7.\nPseudonym\nS-CCFL\nBarryBethanyCharlesConnor\nilliamDavisElijahGeorgeIsabelleJacobo\nJoseph\nLocke\nony T\nNote: This table contains demographic information for interviewees at each of the three field sites. In total, there were 12 Jake\nW\nradicalized in digital social movements, and six were radicalized during their time at CCFL.\nDigitally Mediated Spillover as a Catalyst of Radicalization  153\nFindings\nComputer-mediated communication has enabled a new form of social move -\nment that operates primarily or exclusively online ( Kasimov, 2023). This new \ntype of social movement enables a new type of spillover\u00a0\u2013 digitally mediated \nspillover. Digitally mediated spillover occurs when activists who participated in a digital social movement enter a new movement, bringing their ideology and culture, tactical repertoires, and social networks. Thus far, instances of digitally mediated spillover have garnered too little social scientific attention save for a few high-profile instances such as the Unite the Right Rally (2017) and the January 6th insurrection (2021) in which activists belonging to digital hate movements coordinated lethal, offline protests. This study demonstrates that spillover from extremist digital movements into offline communities may actually be a common occurrence.\nThe following sections outline my theory of digitally mediated spillover. \nFirst, I\u00a0explain why digitally mediated spillover is a unique product of 21st century activism and a common occurrence on college campuses. I\u00a0explain that preexisting organizational dynamics at W-CCFL rendered it vulnera -\nble to digitally mediated spillover and radicalization. Lastly, I\u00a0explain that digitally mediated spillover facilitated radicalization in three phases. First, activists at W-CCFL developed an extremist collective identity. Second, as formerly moderate activists at W-CCFL began spending more time in extrem-ist digital spaces, they became ideologically extreme and transformed their Facebook Messenger chat into a radical milieu. Third, W-CCFL became a tactically extremist organization and adopted antisocial, nondemocratic \n tactics before imploding.\nDigitally Mediated Spillover on College Campuses\nDigitally mediated spillover occurred at each field site when former partici -\npants of the Manosphere and the Alt-Right joined CCFL. The Manosphere is a loose coalition of digital, male supremacist movements containing Gamer -\ngate, the redpill, and others, while the Alt-Right is a loose coalition of digi -\ntal, white supremacist and ethnonationalist movements. In total, 11 of my informants were extremists in high school, during which time they immersed themselves in cyberhate, shared extremist memes, and participated in online collective action such as harassment campaigns, disinformation campaigns, and helping Donald Trump gain popularity with \u201cmeme magic.\u201d I\u00a0refer to these individuals as \u201cagents of spillover.\u201d It is notable that none of these agents of spillover was raised in ideologically extreme households. All of them became extremists online in one of two ways: Via social media and via online multiplayer video games.\nThe first and primary sites of online radicalization were social media plat -\nforms with large user bases and lax content moderation policies, like 4chan, \n154 Adam Burston\nReddit, and YouTube. Aaron, an extremist new member of E-CCFL, discov -\nered right-wing cyberculture while exploring 4chan\u2019s /lit (literature) forum. \nHe showed me the literature forum, and he mentioned that it is common for /lit\u2019s members to post pictures of their bookshelves:\nAaron\n: This is pretty normal, they\u2019ll post pictures of their book stacks. \nThis guy seems to be a little edgy.\nResearcher : Oh, okay, sure. What do you mean edgy?\nAaron : He could just be a little extreme is what I\u2019m trying to get at, he has Mein Kampf on his shelf.\nResearcher\n: Oh, and How the West Won. Okay, Protocols of Zion.\nBy pursuing his passion for literature on 4chan, Aaron was continuously exposed to extremist ideology, which he shared with members of E-CCFL, a moderate social movement organization.\nSimilarly, Antonio, an activist at W-CCFL, participated in the Gamergate \nmovement. He described how his frustration with feminist critiques of the video game industry led him to join the male supremacist movement in high school:\nAntonio\n: It wasn\u2019t until my senior year when Gamergate broke out and \nI\u2019ve always been a big-game nerd.\u00a0.\u00a0.\u00a0. And then there was this big thing of people starting to say like, \u201cGames are promoting toxic masculinity. Games promote this evil image. They\u2019re not inclusive enough for women\u201d\u00a0.\u00a0.\u00a0. I\u00a0was alone, I\u00a0was an only child. My parents didn\u2019t care about video games. I\u00a0wasn\u2019t talking to people so\u00a0.\u00a0.\u00a0. Of course, the Internet\u2019s there\u00a0.\u00a0.\u00a0. and you start finding a community of people who are like, \u201cYeah, this is awful. What are they [feminists] doing to video games?\u201d\nLike Antonio, after prolonged participation in online right-wing movements, other individuals who would become agents of spillover began to believe that left-wing social movements posed an existential threat to American society.\nThe second site of online radicalization was multiplayer video games. \nThese game platforms were ideal for recruitment into extremist movements because of their chat functionality that enables players to communicate via instant messages and over audio chat without scrutiny from content modera -\ntors. For instance, James, a white supremacist at W-CCFL, explained that he discovered the Alt-Right after going through a breakup in high school. Seek -\ning to relieve his loneliness, he recruited people on 4chan\u2019s /pol/ board (a hub of Alt-Right activism) to play video games with him.\nJames\n: I\u2019ve never mentioned this, but I\u00a0met a lot of different alt-righters by \nplaying Minecraft. This is really deep lore, because I\u00a0went through \nDigitally Mediated Spillover as a Catalyst of Radicalization  155\na really bad breakup in high school. And then I\u00a0played a shit-ton of \nMinecraft.\u00a0.\u00a0.\u00a0. I\u00a0formed a town, and I\u00a0recruited off of the \u201cpol board.\u201d All of these right-wingers playing Minecraft and taking things way too seriously. Because it\u2019s so funny how the modern alt-right comes from so many different avenues.\nJames\u2019 new, white supremacist friends encouraged him to migrate from 4chan to websites exclusively dedicated to white supremacist movements. By the time James entered university, he was a committed white supremacist who sought to teach his fellow students about the biological superiority of White Christians over Black people and Jews.\nRobert, an activist at E-CCFL, developed a deep fascination with fascism \nafter accidentally joining a transnational, Alt-Right group chat in high school.\n[At War] is actually like a war game. And we got it, because myself, my brothers, my cousins\u00a0\u2013 we live far apart. And we went to a wedding my freshman year of high school and we were like, \u201chey wouldn\u2019t it be good if we found an online game to play together?\u201d\u00a0.\u00a0.\u00a0. but there\u2019s a forum on it\u00a0.\u00a0.\u00a0. [with a thread] called \u201coff topic forum.\u201d Certainly, I\u00a0knew about the alt-right before the media did\u00a0.\u00a0.\u00a0. you can read like paragraphs of them connecting Jewish businessmen from Germany and the Ottoman Empire and Armenia.\nAlthough Robert was not a committed extremist upon entering university, his fascination with fascism persisted. Upon joining E-CCFL, he created a pri -\nvate group chat on GroupMe in which he introduced his peers to pro-fascist content.\nDigitally mediated spillover began when extremists like Antonio, Aaron, \nJames, and Robert applied to their respective CCFL chapters after partici -\npating in extremist digital social movements in high school. CCFL chapters welcomed these activists into their midst with open arms. Although most agents of spillover were no longer active members of extremist digital move -\nments upon joining CCFL, they remained \u201clurkers\u201d who frequently browsed extremist online platforms. Thus, they were able to share with their new friends the latest memes, jargon, and ideological developments from extrem -\nist digital movements. Agents of spillover exposed their peers to the ideolo -\ngies and tactics from extremist digital movements in their chapters\u2019 digital group chats and in face-to-face organizational meetings.\nI witnessed digitally mediated spillover occur in CCFL chapters through-\nout the United States. Contrary to entryism, which assumes that extremists are deliberate and insidious infiltrators, the primary reason why extremists entered CCFL was a genuine desire for like-minded peers. Extremists entered CCLF the same way other freshman would: By contacting recruiters at the school-wide club fairs and on social media. Whereas entryism argues that \n156 Adam Burston\nextremists strategically share their ideology with the intention of radicalizing \nothers, agents of spillover began to spread extremist ideology at CCFL by honestly sharing their perspectives and trying to help with organizational activities.\nSusceptibility to Spillover and Radicalization\nThe remainder of this chapter will focus on W-CCFL, the field site situated in West Coast University. Agents of spillover came to radicalize W-CCFL because of two factors that differentiated them from their peers at other field sites. First, a comparatively large number of them were accepted to East Coast University and happened to join W-CCFL at the same time, making them a sizeable minority. Second, the moderate incumbent leaders at W-CCFL were incompetent and, by numerous accounts, too cowardly to mobilize in pursuit of CCFL\u2019s objectives: Spreading conservative culture on campus and cam -\npaigning for Republican and Libertarian candidates.\nThis cowardice was not without cause. Following the 2016 U.S. presi-\ndential election, W-CCFL activists were being constantly targeted and har -\nassed by vengeful progressive activists who were enraged by Trump\u2019s victory. Sheila, a moderate member of W-CCFL, recalls being tagged in a Facebook post with a picture of W-CCFL captioned: \u201cThese are the conservatives on campus. They don\u2019t deserve to feel safe.\u201d\n5 Similarly, Daphne was tagged \nin Facebook posts by progressive activists who encouraged others to shun her on- and offline because of her political beliefs. Worst of all, progressive activists routinely blocked W-CCFL activists\u2019 efforts to secure funding, even though this violated university policy. \nHardened by combative digital activism, agents of spillover were disgusted \nby the passivity of CCFL leadership. They had already experienced heated debates on 4chan, coordinated the pro-Trump meme campaigns that helped him ascend to office, and staged raids of progressive online communities that filled them with extremist memes and iconography. Agents of spillover believed that the pugnacious ideology and tactics they learned online would translate well offline.\nDavid, a former participant in the Gamergate and redpill movements, \nassumed an informal leadership position. He convinced other agents of spill-over to join him and coordinated a counter offensive. He explained:\nDavid\n: One of my gripes with the [former] board was that they didn\u2019t really \ncare about activism; they were afraid of offending people and they were afraid of seeming controversial. And I\u00a0would say the majority of the club agreed with that sentiment.\u00a0.\u00a0.\u00a0. I\u00a0was advocating \u201cwe should do more activism, we should be more controversial. Who cares what they think about us? They\u2019re always gonna hate us.\u201d\nDigitally Mediated Spillover as a Catalyst of Radicalization  157\nWith the help of other extremists, David led his fellow activists to the student \nunion to demand funding for the club. At the student union, David\u2019s peers watched with admiration as he faced dozens of angry progressives. Many hurled insults, and one threatened him with physical assault.\n6\nWhereas previous leaders saw misfortune in progressives\u2019 attacks against \ntheir club, David saw opportunity. Taking inspiration from \u201cBen Shapiro Owns the Libs\u201d videos on YouTube, he decided to turn his liberal oppo -\nsition into a viral laughingstock. He instructed his fellow CCFL members to remain calm as they endured harassment from liberal counter-protestors. He captured the contentious interaction on video and uploaded the footage to YouTube where viewers watched angry liberals harassing stoic W-CCFL activists. David ensured that his video garnered attention across the spec -\ntrum of right-wing politics, from conventional conservative news outlets to extremist corners of the Internet. The ensuing public outrage forced West Coast University to give W-CCFL funding, and it drove up recruitment. After this hard-won victory, everyone in W-CCFL begged David to run for an elected position. He ran uncontested for the presidency and filled his execu -\ntive board with other agents of spillover. In the following sections, I\u00a0explain how David\u2019s presidency and W-CCFL\u2019s newfound trust in extremists yielded three phases of radicalization.\nPhase 1: Immersion in Extremist, Digital Culture Leads to  \nan Edgy Collective Identity\nRadicalization began slowly at W-CCFL. Agents of spillover began to slowly expose their moderate peers to jargon and memes that originated in extrem -\nist segments of the Internet. This occurred both offline in organizational meetings and online in their Facebook Messenger group chat. While it is commonly understood that ideology and jargon can translate from online to offline contexts, memes are commonly understood as an exclusively digital phenomenon because they usually comprise a photo, video, or gif, with a text catchphrase. However, the W-CCFL informants explained that when a meme becomes ubiquitous, the imagery or idea behind the meme can be invoked simply by reciting its catchphrase. Examples of meme catchphrases include the phrases \u201c2\u20131\u201d (the idea that the second amendment upholds the first amendment) and \u201cno dox\u201d (a phrase indicating that the speaker is about to share an extremist perspective and does not want to be \u201cdoxed\u201d or exposed to the public as an extremist). By acclimating moderates to extremist memes, agents of spillover were also acclimating them to the underlying ideologies within the memes: White supremacy, ethnonationalism, and male supremacy. At this stage, moderates did not fully understand the extreme nature of the content they were being exposed to. For instance, Sheila casually mentioned that in group chats, her peers joked \u201cabout the future for white children \n158 Adam Burston\nor something like that.\u201d This is a direct reference to the white supremacist \ncreed, The Fourteen Words: \u201cWe must secure the existence of our people and \na future for white children\u201d (Simi\u00a0& Futrell, 2015, p.\u00a022).\nBy design, extremist memes did not alienate moderates. In extremist digital \ncultures, the individuals who post memes have plausible deniability (i.e., it\u2019s just a joke) when their peers are shocked and offended and receive acclaim when their peers find the meme humorous ( Milner, 2013; Windisch\u00a0& Simi, \n2023). In offline spaces where memes are divorced from their digital con -\ntext of origin, they still serve this purpose. This is illustrated in an exchange in which Sebastian, a former member of the redpill movement, argues that Catholic education should replace American public education. He was sup-ported by James, a white supremacist, and Silva, a Nazi sympathizer. These extremists disarmed moderates\u2019 shock with memes and hyperbolic rhetoric, staples of extremist digital culture.\nSebastian\n: Maybe I\u2019m too black pilled on this issue, but we need to turn \nschools over to the Catholic church. I\u2019m protestant, so I\u00a0would \nnormally advocate for protestant education, but the protestant church is too fragmented; there are too many heretics. If we can\u2019t bring Christian morals back into public schools, we are doomed. Also, we\u2019re forgetting that people can go to hell! Why aren\u2019t we worried about the moral salvation of American children? We are an Anglo-protestant nation, Christian morality in schools is the American way.\nJude\n: Um, excuse me? Does separation of church and state mean anything to you? Our founding fathers wanted a separation of church and state. Parents should teach morals at home. School should be where you learn that 2 plus 2 is four and how to read.\nSebastian\n: I\u00a0agree that they believed in the separation of church and state, but I\u00a0 think that there\u2019s a high wall between church and state and we need to lower it. Obviously, the state would be run by non-godly authorities, but students would have a good Catholic education. Look we\u2019re a Judeo-Christian nation.\nSilva\n: Judeo?\nSebastian : Okay, just Christian.\nJames : Based!\n [Club laughs]\nIn the above interaction, \u201cblack pilled\u201d is a redpill meme/designation indicat -\ning that one\u2019s hopes for a male supremacist future have been dashed, result -\ning in nihilism or a desire for violence (Preston et\u00a0 al., 2021). \u201cBased\u201d is cyberjargon, usually posted in response to memes, to indicate approval of an \nDigitally Mediated Spillover as a Catalyst of Radicalization  159\nunderlying idea. The use of such extreme language (e.g., heretics, doomed) is \na rhetorical strategy to cast doubt on the seriousness of the point being raised (Milner, 2013). Whereas moderates heard this statement and assumed Sebas-tian was being playfully hyperbolic, extremists understood he was expressing his true beliefs. Shoshana, a moderate Jewish member of W-CCFL, reflected on this interaction and explained that she found it funny:\nShoshana\n: Last week, one of the guys was like we should have a\u00a0.\u00a0.\u00a0. manda -\ntory Catholic school system. And then they talked about it, but \nthen after, I\u00a0was just like, \u201cWhat about the Jews?\u201d blah, blah, blah. But I\u00a0mean, that\u2019s a joke. I\u00a0mean he probably doesn\u2019t think so, but to everyone else it was a joke.\nThe plausible deniability afforded by memes was so strong that a misogynist, white supremacist, and Nazi sympathizer could belong to same organization as a Jewish woman without raising her suspicions.\nAs moderates became more accustomed to extremists\u2019 humor, extremists \nincreased the vitriol of their jokes. Numerous informants explained that their humor was racist, sexist, and often joked about acts of brutality and mass casualty violence. Michael, a former member of The redpill, simply described the humor as \u201ckill all of group x.\u201d Formerly moderate men began participat -\ning in this humor, because it was enjoyable to break the stifling, progressive norm of political correctness at West Coast University. The thrill of sharing hate content was exhilarating to these men, because the potential discovery of such extreme content within their Messenger posts could have serious ramifications (e.g., expulsion from school). Men in W-CCFL began referring to posting memes with terms like \u201cbonding\u201d and \u201cbrotherhood.\u201d In con-trast, many moderate women were shocked and offended by the denigrating content about women. Some of these offended women (e.g., Daphne, Chloe) demanded that the men change their posting behavior whereas others (Sheila, Taylor) tried to acclimate themselves to misogynist humor. Fights between extremists and aggrieved moderate women reached a fever pitch when Anto -\nnio, an extremist, found an innovative solution: He created a separate Face-book group chat for moderate women so that extremists could continue posting misogynist content.\nEventually, extremist digital content altered the culture of W-CCFL. Spe -\ncifically, immersion in cyberhate began to alter W-CCFL\u2019s collective identity or their \u201cshared definition of a group that derives from members\u2019 common interests, experiences, and solidarity\u201d ( Taylor\u00a0 & Whittier, 1992, p.\u00a0 105). \nAcross the nation, most CCFL activists refer to themselves as \u201cconservative,\u201d reflecting their commitment to moderate conservatism. At W-CCFL, activists began referring to themselves as \u201cedgy\u201d or \u201cedgy memelords,\u201d a designation \n160 Adam Burston\nthat signifies cultural competence in cyberhate. Informants described what is \nentailed in being edgy: \nSahil (extremist) : What is edgy? I\u00a0guess the easiest way to coin it is nonpo-\nlitically correct.\u00a0.\u00a0.\u00a0. If a liberal saw it\u00a0.\u00a0.\u00a0. They\u2019d be like \u201cWhat the fuck is that? That\u2019s racist and xenophobic!\u201d\nSheila (moderate)\n: What\u2019s edgy?\u00a0.\u00a0.\u00a0. The same stuff, I\u00a0could post on my nor -\nmal timeline, and people would be like, \u201cWhoa, that\u2019s not cool.\u201d Like, \u201cHow dare you joke about that? It\u2019s too soon,\u201d kind of stuff.\u00a0.\u00a0.\u00a0. And then there\u2019s context. So, if you post an anti-Semitic meme on a Jewish group\u2019s Face -\nbook page, that\u2019s pretty awful. But if you post it in your private shitposting group, it\u2019s received a lot better.\nGiven that collective identity determines a social movement\u2019s goals and the tactics deemed appropriate to achieve them, the widespread adoption of an edgy identity marked a significant step in W-CCFL\u2019s radicalization.\nTheir edgy collective identity led moderates and new members of W-CCFL \nto try and impress their peers by making increasingly offensive jokes on- and offline. Mimicking dynamics common in extremist digital forums, moderates felt frustrated when their attempts at edgy humor fell flat, because they felt like outsiders.\nSheila\n: I\u00a0could literally say some of the worst shit in our shitposting [chat] \ngroups, and it\u2019s not that edgy. They would call me out on it for not being that edgy.\u00a0.\u00a0.\u00a0. They just don\u2019t wanna admit the fact that a woman can meme just as hard as them.\nAnother aspect of edginess is that when someone is offended by extremist memes, they are subject to ridicule. Pressure on moderates to share extrem-ist memes and the looming threat of ridicule incentivized moderates to hide any residual discomfort they had with extremist humor. Pressure to ramp up extremism transformed W-CCFL\u2019s Facebook Messenger chat into a hidden space of hate, a closed social network that produces radicalization ( Simi\u00a0& \nFutrell, 2015).\nPhase 2: Ideological Extremism and Integration into a Radical Milieu\nUnder the guise of edginess, extremist activists began to strategically dissemi-nate their ideologies from the Manosphere and the Alt-Right. For instance, Max, a male supremacist, tried to popularize the idea that women should not be allowed to vote, while James, a white supremacist, wanted his peers to acknowledge the biological superiority of white Christians. James, one of \nDigitally Mediated Spillover as a Catalyst of Radicalization  161\nthe extremists, used the guise of edginess to paste memes directly from 4chan, \nReddit, and hate websites into W-CCFL\u2019s Facebook Messenger chat:\nJames : Already, these people [moderates] share Alt-Right memes, talking \npoints. Even about IQ [differences between racial groups]. Even if they disagree with what we\u2019re saying, the fact that they\u2019re even engaging is a sign of our influence.\nAs former moderates became increasingly interested in extremist ideology, agents of spillover advanced radicalization by introducing their peers to extremist social networks.\nWhile some extremists encouraged their peers to visit 4chan and Red-\ndit, others began inviting extremists from the online Manosphere and the Alt-Right directly into W-CCFL\u2019s Facebook Messenger chat. W-CCFL\u2019s group chat ballooned in size from several dozen members and alumni to more than 1,000 members at its peak. This drastic expansion of W-CCFL\u2019s social net -\nwork introduced former moderates into a radical milieu, an open social net -\nwork that brought CCFL activists into contact with extremist activists from other digital movements (Malthaner\u00a0& Waldmann, 2014).\nThe rapidly evolving culture on W-CCFL\u2019s group chats was disconcerting \nto the remaining moderates, now a minority, who were not used to interact -\ning with denizens of 4chan, Reddit, and cyberhate. For instance, a lot of the extremists who joined W-CCFL\u2019s group chat used fake names and fake profile pictures because they knew it would be catastrophic for their social lives and careers if the hate content they posted was linked to their identity. Daphne explained, \u201cIf you have to have a fake account to feel comfortable posting this, then maybe you just shouldn\u2019t be posting it. Because it\u2019s just not a good thing to be posting, you know?\u201d Daphne and other moderates longed for a return to the days when the chat was merely an extension of W-CCFL. Other W-CCFL activists began anonymizing their digital presence for fear that they would be unemployable if the group chat was exposed. The content in the group chat became so extreme that on numerous occasions, it was \u201cperma-Zucked,\u201d or permanently banned by Facebook\u2019s content moderators for violating their hate speech policies. Like most extremist digital communi -\nties, W-CCFL quickly reestablished their social media network on another platform after bans (Johnson et\u00a0al., 2019). \nAs W-CCFL\u2019s online social network continued to expand, they began to \nmake contact with high-profile extremists. Chloe, a Black, female, moderate, was enraged to learn that David was Facebook friends with George Zimmer -\nman, an outspoken white supremacist who stalked and killed Trayvon Mar -\ntin, an unarmed Black teenager, in 2012. In 2018, W-CCFL activists made digital contact with a prominent redpill activist and invited him to speak at their next meeting. This redpill blogger went by his screenname, GayLubeOil. \n162 Adam Burston\nEven some extremists were shocked when GayLubeOil spoke about his Red -\ndit posts advocating for physically disciplining women, \u201ctreating women like \nchildren,\u201d and celebrating the sexual prowess of Nazis. GayLubeOil\u2019s speech signified another milestone in digitally mediated spillover and radicalization at W-CCFL. By leveraging the ideologies and social networks from digital hate activism, extremists expanded the organization\u2019s social network to include high-profile extremists. All that remained to complete radicalization was for W-CCFL to adopt extreme and antisocial tactics.\nPhase 3: Tactical Extremism and Organizational Implosion\nAfter an extensive immersion in extremist digital communities, many W-CCFL members soured on democracy. They embraced the supremacist belief that an enfranchised, pluralistic electorate would plunge the nation into its \u201cdegeneracy.\u201d Even in Trump\u2019s America, W-CCFL activists no longer believed that the democratic process could bring about their desired future. W-CCFL activists adopted a new tactical repertoire which they described as \u201cwinning the culture war.\u201d In theory, this was a noble campaign to change the hearts and minds of young Americans. In practice, this involved antiso -\ncial and anti-democratic tactics.\nFirst, W-CCFL activists transitioned from being consumers of cyberhate \nto disseminators. In order to increase the number of American youth who sympathized with their cause, W-CCFL activists posted extremist content on popular social media platforms like 4chan, Reddit, and Facebook. Bruce, a white supremacist and antisemite, boasted about his ability to spread hate ideology on Facebook where his meme pages had cumulatively garnered hun -\ndreds of thousands of members and millions of likes.\nAs W-CCFL radicalized, members felt that even the most right-wing \nRepublicans were too moderate. These accusations even applied to their for -\nmer idol, Donald Trump:\nJames (extremist)\n: The Republican Establishment doesn\u2019t give a fuck about \nadvancing a conservative agenda\u00a0\u2013\nAtticus (moderate) : Trump is the establishment! He\u2019s president.\nMax (extremist) : That doesn\u2019t mean anything!\nJames (extremist) : Absolutely right, it doesn\u2019t mean anything. The Repub -\nlican establishment doesn\u2019t care anymore. They\u2019ve won. They have nothing more to gain, so they kowtow to the left. They\u2019re fucking worthless.\nOffline, W-CCFL\u2019s relationships with Republican and Libertarian politicians suffered.\nRoughly half of W-CCFL activists adopted an authoritarian ideology. One \ngroup of authoritarians believed that voting should be reserved for a privileged \nDigitally Mediated Spillover as a Catalyst of Radicalization  163\nsegment of the population. For instance, Martin suggested the United States \nshould implement rigorous IQ tests to determine voter eligibility:\nIt\u2019s not like I\u00a0want to take away voting rights from Black people, Women, Asians, or whatever.\u00a0.\u00a0.\u00a0. But to be honest, I\u00a0have a hot take. If it did dis-\nproportionately affect Black people because of mental deficiencies, maybe that\u2019s okay.\nOther activists like David believed that the United States should reconvene the House Un-American Activities Committee (HUAC) to prevent socialists, communists, and progressives from holding public office. A\u00a0second group of authoritarians wanted to abolish voting entirely. For instance, Caleb wanted Mussolini-style fascism; Silva wanted Nazi-inspired \u201cnationalist socialism;\u201d James supported a white supremacist regime; and Eddy wanted an authori-tarian surveillance state in which leaders \u201crule through fear.\u201d\nAs is the case with many extremist movements, W-CCFL activists felt \nthey had no direct pathway to create their desired totalitarian state ( Simi\u00a0& \n Windisch, 2020 ). Instead, they settled for a tactical repertoire based on \ntrolling their enemies and \u201cgaslighting the Dems.\u201d Trolling occurs when an antagonistic individual or group makes a target or another individual or group exhibit distress, then documents this distress, and posts the docu -\nmentation on social media. W-CCFL activists held strategy sessions where they debated how best to adapt this digital strategy for offline use to \u201crustle some jimmies\u201d [meme speak for causing anger] and \u201cfreak out the femi -\nnists.\u201d W-CCFL activists laughed and cheered as they recalled previous suc -\ncess and imagined future victories trolling undocumented immigrants and feminists. They also began entering classes taught by progressive professors and speaking engagements featuring progressive intellectuals in order to ask questions designed to enrage, befuddle, and publicly humiliate their targets. Subsequently, W-CCFL activists enjoyed posting these interactions on social media, eliciting a wave of support.\nAlthough many W-CCFL activists no longer believed in the electoral sys -\ntem, they continued to campaign for Republican and Libertarian candidates. This is because they had a vested interest in \u201cgaslighting the Dems\u201d or inten -\ntionally making stops at Democratic households to share heavily skewed if not entirely false information about Democratic candidates. This included exaggerated rumors about Democratic taxes on fossil fuels, to conspiracy theories suggesting that Democrats had a racist hidden agenda. In meetings, extremists justified this tactic by explaining that, \u201ca Democrat that stays home is like a vote for the Republican party!\u201d\nAfter repeatedly adapting digital ideologies and tactics for offline use, \nW-CCFL leaders grew careless and released a public statement on their website replete with memes and references to extremist digital movements. This state-ment condemned local politicians for failure to act against \u201ctransgenderism\u201d \n164  Adam Burston\nand \u201cdegeneracy.\u201d This criticism of local politicians was met with outrage \nfrom their political sponsors and parent organization. Local politicians sev -\nered ties with W-CCFL, replacing them with a different conservative youth organization. W-CCFL was also de-chartered from its parent organization.\nSome of the remaining moderates grew enraged that extremists had ren -\ndered W-CCFL financially and politically impotent. They began \u201cdoxxing\u201d extremists and leaking excerpts of the group chat to university administra -\ntors and the student newspaper in the hopes of getting their former allies expelled. Fearing for their careers, extremists in W-CCFL deleted their group chat and other digital evidence of their extremism. In doing so, they effec -\ntively disbanded their online community and deleted the digital platforms that enabled them to fight the culture war. Like many extremist organiza -\ntions, W-CCFL imploded (Simi\u00a0& Futrell, 2015; Simi\u00a0& Windisch, 2020).\nConclusion\nThis chapter introduces the concept of digitally mediated spillover . This con -\ncept advances our understanding of both the social processes of online hate and social movement dynamics, namely the nationwide radicalization and extremism of formerly moderate conservative youth groups. Digitally medi -\nated spillover advances theory about the social processes of online hate by demonstrating that these social processes are easily translated to new on- and offline contexts. To radicalize their peers, agents of spillover imported digital cultures, ideologies, and tactics from the Alt-Right and the Manosphere to a Facebook Messenger chat and offline CCFL meetings.\nSkeptics may claim that there is nothing innately digital about the culture, \nideologies, and tactics utilized by agents of spillover. After all, what differenti -\nates the redpill ideology from other manifestations of virulent sexism, memes from traditional forms of humor, and trolling from harassment? While each of these digital phenomena bear a strong resemblance to their offline coun -\nterparts, they also contain referents to extremist digital movements. Redpill ideology trains men to seek community in digital forums; memes cannot be understood without exposure to the original, digital content; and trolling is not finished until evidence has been posted online. These referents to digital culture acclimate activists to digital extremist cultures and incentivize them to participate more deeply. Acculturation to online extremism incentivized W-CCFL activists to invite extremists into their Facebook Messenger chat and flock to extremist digital movements on 4chan and Reddit. Thus, in addition to adapting online social processes and practices from digital culture for offline applications, digitally mediated spillover also encourages individu -\nals to seek out and participate in digital culture.\nJust as 20th-century feminism left an indelible mark on the nuclear freeze \nmovement, the Manosphere and the Alt-Right have left an indelible mark \nDigitally Mediated Spillover as a Catalyst of Radicalization  165\non many chapters of conservative youth movements throughout America. \nCaleb, an extremist, attended a CCFL convention for every major chapter located in the West Coast. He saw multiple activists carrying flags for \u201cKeki -\nstan,\u201d a fictitious nation which symbolizes membership in the Alt-Right. This indicates that extremists have indoctrinated future generations of Republican and Libertarian leadership. Scholars and policy experts who wish to under -\nstand and prevent further campus-based radicalization must gain a deeper understanding of digitally mediated spillover and the diffuse social processes by which extremist digital movements shape offline life.\nNotes\n 1 https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n 2 Not to be confused with the actual West Coast University, a for-profit graduate \ninstitution (https://westcoastuniversity.edu/).\n 3 Three of my interviews were follow-up interviews.\n 4 My ability to collect data at each site was mediated by a variety of factors such as \nbalancing coursework and teaching, limited and sporadic grant funding, the fre -\nquency of meetings at each field site, and COVID-19.\n 5 Although CCFL activists did not show me their own social media posts, they had \nno qualms about showing me antisocial tactics employed by their progressive \nopponents.\n 6 Video coverage shows progressive antagonists insulting and threatening W-CCFL \nactivists.\nReferences\nADL. (2019). White supremacists increase college campus recruiting efforts for third \nstraight year. Anti-Defamation League. https://www.adl.org/resources/press-release/white-supremacists- increase- college- campus-recruiting- efforts-third\nADL. (2023). White supremacist propaganda incidents reach all-time high in 2022.  \nAnti-Defamation League. https://www.adl.org/resources/press-release/ white-suprem  \nacist-propaganda- incidents- reach- all-time- high-2022\nAlonso, J. (2022, October 14).  College GOP President resigns over hateful Instagram \nposts. Inside Higher Ed. https://www.insidehighered.com/quicktakes/2022/10/14/\ncollege-gop-president-resigns-over-hateful-instagram-posts\nAtran, S. (2021). Psychology of transnational terrorism and extreme political con -\nflict. Annual Review of Psychology, 72(1), 471\u2013501. https://doi.org/10.1146/\nannurev-psych-010419-050800\nBauman, D. (2018). After 2016 election, campus hate crimes seemed to jump. Here\u2019s \nwhat the data tell us. The Chronicle of Higher Education. https://www.chronicle.\ncom/article/After-2016-Election-Campus/242577\nBinder, A. J.,\u00a0& Kidder, J. L. (2022).  The channels of student activism: How the left \nand right are winning (and losing) in campus politics today . University of Chicago \nPress.\nCorbin, J. M.,\u00a0& Strauss, A. (2008).  Basics of qualitative research: Techniques and \nprocedures for developing grounded theory. SAGE Publications.\nFlacks, R. (2005).\n The question of relevance in social movement studies. In D.  Croteau, \nW. Hoynes,\u00a0& C. Ryan (Eds.), Rhyming hope and history: Activists, academics, \nand social movement scholarship (pp.\u00a03\u201320). University of Minnesota Press.\n166 Adam Burston\nIannelli, J. (2018, October 16). Chats show FIU turning point USA members sharing \nracist memes and rape jokes. Miami New Times. https://www.miaminewtimes.com/\nnews/turning-point-usa-fiu-chapter-shares-racist-sexist-pepe-memes-10827433\nJohnson, N. F., Leahy, R., Restrepo, N. J., Velasquez, N., Zheng, M., Manrique, P., \nDevkota, P.,\u00a0& Wuchty, S. (2019).  Hidden resilience and adaptive dynamics of the \nglobal online hate ecology. Nature, 573(7773), 261\u2013265. https://doi.org/10.1038/\ns41586-019-1494-7\nKasimov, A. (2023). Decentralized hate: Sustained connective action in online far-right \ncommunity. Social Movement Studies, 1\u201319. https://doi.org/10.1080/14742837. \n2023.2204427\nLowe, D. (2017). Prevent strategies: The problems associated in defining extrem -\nism: The case of the United Kingdom. Studies in Conflict\u00a0& Terrorism, 40(11), \n917\u2013933. https://doi.org/10.1080/1057610X.2016.1253941\nMalthaner, S.,\u00a0& Waldmann, P. (2014). The radical milieu: Conceptualizing the sup -\nportive social environment of terrorist groups. Studies in Conflict\u00a0& Terrorism , \n37(12), 979\u2013998. https://doi.org/10.1080/1057610X.2014.962441\nMcCauley, C.,\u00a0 & Moskalenko, S. (2017).  Understanding political radicalization: \nThe two-pyramids model. American Psychologist, 72(3), 205\u2013216. https://doi.\norg/10.1037/amp0000062\nMeyer, D. S.,\u00a0 & Whittier, N. (1994).  Social movement spillover. Social Problems, \n41(2), 277\u2013298. https://doi.org/10.2307/3096934\nMiller-Idriss, C. (2020).  Hate in the homeland: The new global far right . Princeton \nUniversity Press.\nMilner, R. M. (2013). FCJ-156 Hacking the social: Internet memes, identity \nantagonism, and the logic of lulz. The Fibreculture Journal, 22 2013: Trolls \nand The Negative Space of the Internet . https://twentytwo.fibreculturejournal.\norg/fcj-156-hacking-the-social-Internet-memes-identity-antagonism-and-the-\nlogic-of-lulz/\nND GOP. (2022). NDGOP response to offensive statements by a group of young \nRepublicans. North Dakota Republican Party. https://ndgop.org/ndgop-response-  \nto-offensive-statements-by-a-group-of-young-republicans/\nPolletta, M. (2019). Conservative group at ASU apologizes for racist, anti-Semitic post -\nings online. The Arizona Republic. https://www.azcentral.com/story/news/politics/ \narizona/2019/03/25/college-republicans-united-arizona-state-university-apology-racist-materials/3271365002/\nPreston, K., Halpin, M.,\u00a0& Maguire, F. (2021).  The black pill: New technology and \nthe male supremacy of involuntarily celibate men. Men and Masculinities. https://\ndoi.org/10.1177/1097184X211017954\nQuintana, C. (2018, October 21).  \u2018Degenerate and murderous\u2019: California campus Repub -\nlicans\u2019 platform attacks college culture. The Chronicle of Higher Education, 65(9). \nhttps://www.chronicle.com/article/degenerate-and-murderous-california-campus-  \nrepublicans-platform-attacks-college-culture/\nRaymond, N. (2022, July 11). U.S. judicial panel orders probe into hiring of clerk accused \nof racism. Reuters. https://www.reuters.com/legal/government/us-judicial-panel- \norders-probe-into-hiring-clerk-accused-racism-2022-07-08/\nSalda\u00f1a, J. (2013). The coding manual for qualitative researchers (2nd ed.). SAGE.Simi, P.,\u00a0& Futrell, R. (2015).\n American Swastika: Inside the white power movement\u2019s \nhidden spaces of hate. Rowman\u00a0& Littlefield.\nSimi, P., Futrell, R.,\u00a0& Burston, A. (2024). How threat mobilizes the resurgence and \npersistence of US white supremacist activism: The 1980s to the present. Annual \nReview of Sociology.\nSimi, P.,\u00a0& Windisch, S. (2020). Why radicalization fails: Barriers to mass casualty \nterrorism. Terrorism and Political Violence , 32(4), 831\u2013850. https://doi.org/10. \n1080/09546553.2017.1409212\nDigitally Mediated Spillover as a Catalyst of Radicalization  167\nSPLC. (2018). Turning point USA\u2019s blooming romance with the alt-right (Hate Watch). \nSouthern Poverty Law Center. https://www.splcenter.org/hatewatch/2018/02/16/\nturning-point-usas-blooming-romance-alt-right\nSPLC. (2022a). James Orien Allsup (extremist files). Southern Poverty Law Center.  \nhttps://www.splcenter.org/ fighting-hate /extremist-files /individual/ james- orien - \nallsup\nSPLC. (2022b). Kyle Bristow (extremist files) . Southern Poverty Law Center. https://\nwww.splcenter.org/fighting-hate/extremist-files/individual/kyle-bristow\nTaylor, V.,\u00a0& Whittier, N. (1992). Collective identity in social movement communi-\nties: Lesbian feminist mobilization. In A. D. Morris\u00a0& C. M. Mueller (Eds.), Fron-\ntiers in social movement theory (pp.\u00a0104\u2013130). Yale University Press.\nWindisch, S.,\u00a0& Simi, P. (2023). More than a joke: White Supremacist humor as a \ndaily form of resistance. Deviant Behavior, 44, 381\u2013397. https://doi.org/10.1080/\n01639625.2022.2048216\nZhuravskaya, E., Petrova, M.,\u00a0& Enikolopov, R. (2020).  Political effects of the Inter -\nnet and social media. Annual Review of Economics, 12(1), 415\u2013438. https://doi.\norg/10.1146/annurev-economics-081919-050239\nDOI: 10.4324/9781003472148-8\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Hate is a widespread, pernicious feature of contemporary life online that \nspreads via the interweaving of hateful ideologies, the influencers who pro -\nmote them, and the digital tools influencers use for communicating with their followers\u00a0\u2013 and that those same followers use to communicate amongst them -\nselves. Understanding online hate as a social process entails accounting for how these elements interact and reinforce each other in facilitating the for -\nmation of virtual communities organized around shared values and practices, much as more positive virtual communities do as well. For instance, online social spaces have become indispensable resources for activism and demo -\ncratic social movements from the Arab Spring ( Gerbaudo, 2012) to Black \nLives Matter ( Freelon et\u00a0al., 2016). Yet hate groups have also weaponized \nthese tools to their own ends; Daniels (2018) characterizes white nationalists in particular as \u201cinnovation opportunists\u201d (p.\u00a063) who have long been at the bleeding edge of digital technology adoption. No online social space\u00a0\u2013 online games, virtual worlds, social media, livestreaming, messaging apps, etc.\u00a0\u2013 is immune to hate, and none is a purely closed system that can prevent its spread from one space to another.\nPrevious research has focused on online hate purveyors\u2019 presumed instru -\nmental goals, that is, how they deploy hateful messaging in order to terrorize targets or otherwise disrupt out-group activities. Such research presumes that online hate messages, when instigated by groups rather than \u201clone wolves,\u201d are transmitted unidirectionally in two complementary ways: They are pro -\nduced on one platform and deployed on another ( Hine et\u00a0al., 2017; Velasquez \net\u00a0al., 2020), and they travel linearly from instigators through other aggres -\nsors toward targets (e.g., Marwick, 2021). In this chapter, we present research \nthat complicates the received wisdom about online hate\u2019s unidirectionality, 8\n\u201cHATE PARTIES\u201d\nNetworked Antisemitism from the  \nFringes to YouTube\nStephen C. Rea, Binny Mathew, and Jordan Kraemer\n\u201cHate Parties\u201d  169\nas well as its instrumentality. Purveyors of online hate maintain presences in \nmultiple online social spaces and often fall into call-and-response patterns between influencers and rank-and-file followers that extend conversations across platforms. Moreover, the correspondence between their activities on different platforms is not solely dedicated to harassment and disruption but also includes celebrating and amplifying would-be \u201cfellow travelers.\u201d\nWe came to this research while working with the Anti-Defamation League\u2019s \n(ADL) Center for Technology and Society (CTS), which advocates for targets of online hate and harassment and recommends policy and technological interventions aimed at mitigating the harms that result from these kinds of activities. In this original study, we investigated how sharing links to You -\nTube videos on so-called \u201calt-tech\u201d platforms ( Donovan et\u00a0al., 2019) such as \nGab, Telegram, and 4chan in turn affected comment activity on YouTube. We identified a distinct, unanticipated circularity in hate messengers\u2019 reciprocal switching among multiple platforms that appeared strategic, networked, and at times self-reflexive. In dozens of cases, we found a significant increase in antisemitic comments on the YouTube videos in the period directly after their links had been shared on other platforms. The comments were not written to victimize the YouTube creator, nor were they even addressed to the crea -\ntor. Rather, the messages were written for one another. While other recent research suggests that social media hate perpetrators are often the implicit audience for their hate postings (Walther, this volume), our analyses suggest that other hate promoters are the explicit audience, and in fact, the intended participants in an interactive conversation.\nThe types of videos whose links were shared were not by Jewish creators, \nor Judaism-related, as would typically be expected in the literature on online hate (e.g., Hine et\u00a0al., 2017; Stringhini\u00a0& Blackburn, this volume). The com-menters did not target YouTube creators for harassment, as researchers have documented in cases of online \u201chate raids\u201d ( Mariconti et\u00a0al., 2019 ; Meisner, \n2023; Saaed et\u00a0al., 2023 ). Rather, commenters appeared to form bonds and \nreinforce conspiratorial, hateful worldviews common to their communities beyond YouTube while seeking to amplify content they perceived to con-firm their antisemitic beliefs. The comment sections for these videos became, in effect, host to what we call \u201chate parties\u201d: Threads of hateful rhetoric that are not significantly different from content found in the darkest corners  \nof the Internet. Crucially, the majority of such comments expressed approval of the YouTube channels and their content; hence the party-like character -\nistic. The videos that attracted the greatest volume of antisemitic comments were produced by professional influencers, some of whom were explicit pro -\nmoters of online hate and others who were more mainstream figures whose content overlapped with topics of interest in online hate communities. Our research suggests that online hate purveyors often post messages across plat-forms for their own consumption rather than to harass targets, an example \n170 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nof the main thesis of this book\u00a0\u2013 that is, that social processes are central to \nunderstanding how hate propagates online.\nAdditionally, hate messengers appear to exploit known differences in \ncontent moderation policies and practices on platforms like YouTube by strategically offloading elements of conversations across media systems\u00a0 \u2013 and explicitly articulating those strategies for their peers. To mitigate hate parties\u2019 harms, social media platforms like YouTube will need to consider cross-platform constellations of user behaviors and thread-level phenomena rather than strictly local, within-platform messaging and individual posts iso -\nlated from their surrounding contexts.\nVirtual Communities and Online Hate\nIn their critical analysis of Silicon Valley\u2019s sociocultural antecedents, Bar-\nbrook and Cameron (1996) argue that the social Internet emerged from a \u201cheterogeneous orthodoxy\u201d (p.\u00a044) combining New Left utopianism with a libertarian emphasis on personal freedoms. From these strange ideological bedfellows sprang the first \u201cvirtual communities,\u201d such as Stewart Brand\u2019s Whole Earth \u2018Lectronic Link (WELL), an online bulletin-board system (BBS) organized around a counterculture magazine and product catalog ( Rhein-\ngold, 2000; Turner, 2005). Electronic Frontier Foundation co-founder John \nPerry Barlow\u2019s \u201cA Declaration of the Independence of Cyberspace\u201d (1996) offered a concise articulation of Silicon Valley\u2019s heterogeneous orthodoxy and its vision of virtual communities as digital utopias: \u201cWe [citizens of cyberspace] believe that from ethics, enlightened self-interest, and the com-monweal, our governance will emerge\u201d (para. 10).\nFrom today\u2019s vantage point, Barlow\u2019s declaration appears either woefully \nnaive or a dream deferred, depending on one\u2019s appetite for cynicism. Some spaces within contemporary social media platforms may represent the kind of digital utopia Barlow imagined, but most are also apparatuses of surveillance capitalism (Zuboff, 2019) or the targets of state censorship ( Zittrain et\u00a0al., \n2017). And in many ways, the libertarian ethos that Barlow and his contem -\nporaries espoused has\u00a0\u2013 albeit unintentionally\u00a0\u2013 helped facilitate online hate\u2019s propagation through virtual communities.\nOnline hate has been a feature of virtual communities since their incep -\ntion. In fact, one could argue that hate communities were the original net-\nworked virtual communities. In January 1985, one month before Stewart Brand launched The WELL, ADL published a report about far-right extrem -\nist organizations Aryan Nations and Liberty Bell Publishing using BBSes to network with other neo-Nazis and white supremacists in North America (ADL, 1985).\n1 BBSes afforded groups like the Aryan Nations the ability to \nbypass national embargoes on imported hate literature\u00a0\u2013 such as that exist -\ning in Canada and much of Western Europe\u00a0\u2013 and circulate their materials in \n\u201cHate Parties\u201d  171\nplaces that had previously been unreachable. While digital telecommunica -\ntions afforded more expansive dissemination than previous communication \ntechnologies such as pamphlets or leafleting (see Perry, 2000), BBS commu-nities were still relatively contained at the time by the cost of access and dif -\nficulty of discovery; users could typically only find a BBS via word of mouth or by seeking out existing topics of interest. Moreover, hate BBS operators limited access to member\u00a0\u2013 and enemy\u00a0\u2013 lists only to paying subscribers who had been vetted, likely due to fears of infiltration and surveillance by law enforcement agencies, not to mention the opportunity for collecting revenue.\nThe advent of the public Internet in the 1990s proved to be an even greater \nboon for hate groups. In 1995, Ku Klux Klan Grand Wizard and Ameri-can Nazi Party member Don Black created Stormfront, the first and oldest dedicated hate website. Stormfront grew out of a BBS but was able to reach a much wider audience as a public website in no small part because it was indexed by search engines. By 1999, more than 2,000 white supremacy web -\nsites were online, a clear indication of the opportunities that hate groups like Black\u2019s saw in the Internet for recruitment, mobilization, and spreading propaganda. As Black told an interviewer in the early 2000s, \u201cthe Net has certainly provided our movement, and other movements like ours with only limited resources, with the ability for the first time to compete with what we consider to be a very biased and controlled news media\u201d (quoted in Swain\u00a0& Nieli, 2003, p.\u00a0155). To this day, Stormfront functions as a clearinghouse of sorts for online hate resources by helping visitors to its site navigate to less prominent sites (Swain\u00a0& Nieli, 2003; see also T\u00f6rnberg\u00a0& T\u00f6rnberg, this volume).\nThe social networking services that emerged in the early 2000s represented \nthe next great innovation in virtual communities, as well as a new era for online hate. User-generated content had always been a feature of hate BBSes and web forums like Stormfront\u2019s, but social media platforms like Facebook, YouTube, and Twitter built their entire operations around users and their creations in ways that previous online services had not. Whereas the likes of Liberty Bell and Stormfront had catered directly to extremists and their niche interests, social media platforms\u2019 sophisticated data harvesting and algorithmic recommendation systems made it possible for online hate pur -\nveyors to reach even wider audiences. Instead of relying on users to seek out hate content intentionally or to be referred via others in their offline social networks, social media serve up hate to anyone whose combination of search history, friend connections, and topic interest signals trigger a plat -\nform\u2019s recommender. This is not to say that algorithmic recommenders are wholly responsible for supercharging online hate and thereby perpetuating the \u201cmodern myth\u201d (Lim, 2020, p.\u00a0186) that algorithms determine ever nar -\nrower aspects of daily life. Rather, following Daniels (2018), online hate in \nthe age of social media must be understood as a sociotechnical phenomenon \n172 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nrooted in long organizational histories that complement how social media\u2019s \nadvertising-driven business model privileges content that attracts the most engagement and boosts its visibility (Shaffer, 2017).\nSocial media also helped empower less-established hate purveyors by \nmaking it possible for independent influencers to build audiences without the help of communications infrastructures from groups like the Ku Klux Klan or the American Nazi Party. As a subset of the influencer economy and phenomenon of the social media celebrity ( Abidin, 2018; Marwick, 2013), \nmany contemporary hate messengers have leveraged social media platforms\u2019 affordances to attract followers without having to tie themselves directly to more conventional hate group \u201cbrands.\u201d Nor do they have to rely on their actual-world identities: Pseudonymous influencers like Bronze Age Pervert (Gray, 2023) or GhostEzra ( Gilbert, 2021) have successfully amassed follow -\nings based entirely on their online handles and the hateful or hate-adjacent content that they post. Online hate in the age of social media need not be tied to any single group or personality, either. Simple online image boards like 4chan and 8kun facilitate the kind of \u201cleaderless resistance\u201d that Aryan Nations founder Louis Beam saw as an advantage in moving white suprem -\nacy online ( SPLC, n.d.), occupying a similar role as discussion forums like \nStormfront\u2019s, but for loose collectivities of anonymous Internet users who are plugged into current digital culture trends ( Hagen\u00a0& Tuters, 2021). All of \nthese factors have shifted the relationship between leaders and followers and professionals and amateurs in social processes of online hate, as we explore in what follows.\nContemporary social media are varied and numerous, affording users dif-\nferent degrees of privacy, customization, modes of expression, and mone -\ntization opportunities. Social media taxonomies are also plentiful (e.g., El \nOuirdi et\u00a0al., 2014; Koukaras et\u00a0al., 2020; Zuckerman, 2023), though no \nconsensus exists for how best to categorize different platforms and services. For our purposes, we draw an analytical distinction between YouTube and platforms such as 4chan, Gab, Gettr, and Telegram based on content mod -\neration. While YouTube\u2019s and other \u201cmainstream\u201d social media platforms\u2019 content moderation policies and enforcement have not been entirely effective at quarantining hate or mitigating its spread, they are nonetheless far more robust than the services we refer to here as \u201cfringe\u201d\u00a0\u2013 and others have called \u201calt-tech\u201d (see B\u00e4r et\u00a0al., 2023 )\u00a0\u2013 that are promoted directly to hard-right \naudiences. Despite its flaws, the mainstream/fringe distinction is relevant for our analysis for two reasons. First, it helps capture the emic values that online hate messengers assign to different social spaces: It is common to see influential hate messengers on the fringes refer to mainstream platforms as \u201cthe battlefield\u201d where they expect to encounter resistance from other users and the platforms\u2019 moderation teams, and must be strategic about the con -\ntent they post so as to avoid penalties. By contrast, they typically address \n\u201cHate Parties\u201d  173\ntheir followers on the fringes as like-minded allies who share their hateful \nworldviews. Second, mainstream platforms\u2019 more stringent content modera -\ntion policies signal to advertisers that their services are \u201csafe,\u201d which in turn helps those platforms build and maintain scale. Even if their participation risks suspension or expulsion, hate messengers recognize the importance of being active on mainstream platforms because of the audience reach that they afford, made possible in large part by those platforms\u2019 relationships with advertisers. Mainstream platforms\u2019 dependence on advertisers also makes them, in theory, more amenable to removing hateful content, thereby mak -\ning our findings all the more troubling.\nAs our data show, mainstream platforms\u2019 content moderation policies \nhave not relegated online hate to virtual communities on the fringes of social media. Rather, the fringes are intimately connected to the mainstream not only as sites on which to deploy attacks but more importantly as platforms where they can connect with other and with sympathetic users via hate par -\nties, and together promote their hateful messages to audiences that otherwise may not encounter them.\nResearch Methods\nInitially, we set out to identify examples of cross-platform hate and har -\nassment targeting YouTube videos. Our goal was to show how individu -\nals and groups operating on mainstream and fringe social media platforms exploit differences in content moderation and to apply our insights toward suggestions for improving safety mechanisms on YouTube. We used the Social Media Analysis Toolkit (SMAT)\u00a0\u2013 an open-source platform designed to facilitate research on trends in online hate\u00a0\u2013 to collect message postings on fringe platforms (and collateral data) that had shared links to YouTube videos. Using the SMAT API, we queried for posts or messages containing links to YouTube. We restricted our search to one month (December 24, 2022 to January 24, 2023) but did not selectively sample videos or channels based on political affiliation or ideology. In early February 2023, we col -\nlected data from the following \u201cfringe\u201d platforms: 4chan, 8kun, Bitchute, Gab, Gettr, LBRY, MeWe, Minds, Parler, Poal, Rumble, Truth Social, Wim -\nkin, and Win.\n2 The final dataset consisted of over 153,000 messages with at \nleast one YouTube link. We extracted the YouTube links from the messages, resulting in nearly 86,000 unique links to YouTube videos. Since collecting the comments and their replies for each video would be a daunting task, we decided to analyze activity only for links that appeared on at least 3 of the 14 fringe platforms (1840 total videos). For each of the selected videos, we used the YouTube data API to collect all of the comments and their replies. Our final dataset consisted of 3,257,299 comments and 1,481,544 replies to these comments.\n174 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nWe then used ADL\u2019s in-house antisemitism classifier, the Online Hate Index \n(OHI), to assign each YouTube comment a score regarding the likelihood of \nit being antisemitic.3 The OHI is a machine learning-based model that uses \nnatural language processing and human annotation to evaluate social media content. It was trained on a dataset of over 80,000 social media items anno-tated by ADL volunteers with topic expertise in antisemitism. Scores range from 0.0, not at all likely to have the antisemitic qualities the classifier is looking for, to 1.0, high probability that the content is antisemitic. After scor -\ning the YouTube comments and replies, we separated out all of the antisem -\nitism scores above a threshold of 0.9. We found 7,969 total comments on 805 YouTube videos\u00a0\u2013 representing 44% of the total video dataset\u00a0\u2013 that scored above 0.9 for antisemitism using the OHI, an average of nearly ten comments per video (with a median of 4). By applying this high threshold, however, we likely underestimated the prevalence of antisemitism in the comments. In fact, upon manual review, several comments that were clearly antisemitic in their intent and contributed to the hate party phenomenon we have identified in this study fell below the 0.9 threshold; for example, \u201c[Star of David emoji] Zelensky [menorah emoji] doing shady business? Call me not even remotely surprised\u201d has clear antisemitic dog whistles\u00a0 \u2013 insinuating that Ukrainian President Volodymyr Zelensky\u2019s alleged corruption is due to his Jewish herit -\nage\u00a0\u2013 yet scored only 0.019475 on the OHI, possibly because the classifier is not well trained to interpret emojis and other symbols.\nTwenty-five videos had 50 or more antisemitic comments that scored above \nthe 0.9 threshold, accumulating 2,844 total comments and average of almost 57 per video (with a median of 77). In other words, 36% of all the highly antisemitic comments in our dataset appeared on just 3% of the videos, with comments scoring above 0.9 on the OHI (and just 1.3% of all videos whose links were shared to at least three fringe platforms). This figure indicates that while antisemitic comments were widespread on YouTube, they clustered around particular videos and channels. We then performed manual, qualita -\ntive analysis of these 25 videos and their comments.\nWith these data in hand, we tried to ascertain the extent to which shar -\ning YouTube video links on fringe platforms affected comment activity on those specific videos. We cross-referenced the times when comments were left on the YouTube videos with times when the links had been shared on fringe platforms, in order to assess probable causal relationships between sharing links and posting hateful comments (see Davis, 1979 on the validity \nof this method). For a selection of videos that received a higher percentage of antisemitic comments than the others (between 0.7% and 16% of all com -\nments left on the videos at the time of data collection), we manually reviewed the fringe platform posts that had shared links to the videos and the com -\nmentary and replies\u00a0\u2013 if any\u00a0\u2013 that those posts received. Some videos expe -\nrienced a spike in antisemitic comments that was nearly simultaneous with \n\u201cHate Parties\u201d  175\ntheir posting date on YouTube, while others had waves of spikes weeks and \nmonths after their initial posting. We speculate that these differences were due to a combination of the relative popularity of the YouTube video chan -\nnels and the degree to which the videos\u2019 authors\u00a0\u2013 the channel operators\u00a0\u2013 shared the links to their own fringe social media accounts. Popular creators who are known to make borderline antisemitic content may be more likely to attract \u201corganic\u201d antisemitism on YouTube, while accounts that share links to the fringes at the same time as they post their videos make identifying causal relationships more difficult. Without access to YouTube\u2019s referrer URL data or the commenters\u2019 IP addresses, we cannot prove absolutely that these comments were written by the same individuals who saw the link postings on fringe platforms. However, the temporal correlation between link sharing and commenting demonstrated a strong relationship. So, too, were the asso-ciations between the content of the comments across platforms, using nearly identical language and references in many instances in both the comments on YouTube and on the fringe posts where the links were shared.\nParty over Here\nIn 526 cases\u00a0\u2013 65% of the 805 total videos with the highest-scoring antise -\nmitic comments\u00a0\u2013 we found that YouTube videos experienced a nearly 18% increase in the share of antisemitic comments in the first 48 hours after they had been shared on a fringe platform, a pattern that would appear to sup -\nport previous studies about hate raids being coordinated from the fringes. However, we did not find any examples of explicit coordination or direc -\ntions being issued to followers; even in cases where a fringe platform user encouraged their followers to watch the video and share it with others, they did not call for flooding the comments sections on YouTube. For instance, a 4chan thread discussing one of the channels analyzed in the following sec -\ntions praised the channel\u2019s operator and told others, \u201cWe also need to protect him whatever the costs for whenever he does get a bigger audience.\u201d\n4\nThe findings that the videos that attracted hateful comments were, them -\nselves, similarly or somewhat hateful, and that videos were congenial to hate comments rather than being the targets of hate themselves, complicate the currently accepted wisdom about online hate and its social processes. Rather than being examples of hate moving purposefully and unidirectionally from the fringes to the mainstream as forms of harassment in hate raids, the cases we observed could be more accurately characterized as broader discussions taking place simultaneously and interactively in different online social spaces, like groups of people clustered together in conversation in different parts of a room at the same party\u00a0\u2013 hence our term, hate parties. The lack of any clear direction or coordination can be explained in large part by the differences between hate raids and hate parties regarding their respective goals. While \n176 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nthe purpose of a hate raid is to disrupt and harass a specific target or targets, \nwe want to suggest that hate parties are not motivated by antagonism; their \ngoal is to share and promote hateful world views on mainstream platforms like YouTube that afford the possibility of reaching a relatively large audience of like-minded individuals, connecting with others online who share similar perspectives, a deeply social process.\nThe users who participated in these hate party conversations often had \nsophisticated understandings of the informal \u201crules\u201d governing their engage -\nment. They articulated certain expectations regarding content moderation on different platforms that they and others could exploit in order to extend conversations into mainstream spaces and \u201ckeep the party going,\u201d so to speak, without having their content removed. According to its hate speech policy, YouTube will remove content, including comments, that \u201cpromot[es] violence or hatred against individuals or groups\u201d based on protected attrib -\nutes including ethnicity, race, and religion. This policy covers content that dehumanizes individuals, uses slurs and stereotypes to incite or promote hatred, and forwards conspiracy theories about individuals or groups being \u201cevil, corrupt, or malicious\u201d (YouTube, 2019). The descriptions in this policy  \ncan, in theory, be interpreted quite broadly, but in practice, YouTube\u2019s mod -\nerators apply them narrowly. As such, ambiguous and borderline content often escapes detection and remains on the platform. Users are adept at using slang, symbols, or deliberate misspellings to avoid automated detection and to toe the line of acceptability. Fringe platforms, on the other hand, have branded themselves as \u201cfree speech alternatives\u201d where content moderation is more relaxed or nonexistent. For example, Gab claims that it will \u201censure that all content moderation decisions and enforcement of these terms of service does not punish user for exercising their God-given right to speak freely\u201d (Gab, 2023); Gettr prohibits \u201ccontent that endorses violence against, or promotes segregation of, individuals or groups\u201d based on protected class characteristics, but \u201cdiscussions and comments of sensitive topics relating to these characteristics\u201d are allowed ( Gettr, n.d.); and 4chan has some global \nrules prohibiting activities that violate local and U.S. laws, but enforcement is inconsistent at best. Each 4chan board has its own rules as well, such as the \u201cPolitically Incorrect\u201d or \u201c/pol/\u201d board where anything is permitted except attacking other users or posting pornography (4chan, n.d.).\nIn the following, we analyze three YouTube channels and their operators \nthat stood out in our data as different ideal types of hate party hosts and describe how they are situated in broader social processes of online hate: (1) \u201cRedpill\u201d opportunities, that is, more mainstream voices that followers on the fringes designate as potential gateways to hate; (2) channels and operators whose hateful subtext is clear for audiences who are primed to hear it, but whose content does not violate any of YouTube\u2019s rules; and (3) more extreme creators who push the boundaries of acceptable content on YouTube.\n\u201cHate Parties\u201d  177\nRedpills\nThe term \u201credpill\u201d is inspired by the 1999 action sci-fi blockbuster movie \nThe Matrix, in which the redpill allows the film\u2019s protagonist to see that he has been living in an elaborate simulated reality. Many extremists describe becoming aware of media and political institutions\u2019 supposed lies as \u201cbeing redpilled.\u201d They also express the need to redpill others, that is, help them see the world from a different\u00a0 \u2013 and in this case, more conspiratorial\u00a0 \u2013 \n perspective.5 Users on the fringes look to mainstream sources for possible \nredpill opportunities: Influential figures with large followings who can func -\ntion as gateways to more extreme talking points.\nEnglish comedian Russell Brand is one example of a potential redpill. \nOn his YouTube channel, which had over 6.56 million subscribers as of August 2023, Brand gives his takes on current events and pitches himself as an anti-establishment \u201cfree thinker,\u201d often from a left-leaning perspective.\n6 \nSince the COVID-19 pandemic, his videos have increasingly embraced con-spiracy theories that merge with far-right talking points and have garnered Brand respect on the fringes (see Merlan, 2022). As one 4chan user com -\nmented, \u201crussell brand is the new gateway redpill now, [Tucker] carlson is old hat. even my mom watches that cockney faggot spout shit you would have only heard on 4chan a few years back.\u201d\nOn January 12, 2023, Brand posted a video to his YouTube channel titled \n\u201cIT\u2019S STARTING\u201d about an agreement between Ukrainian president Volo -\ndymyr Zelensky and the investment company BlackRock to coordinate efforts rebuilding Ukraine ( Brand, 2023). In the video, Brand insinuated that \nthe agreement\u00a0\u2013 and the United States\u2019 support of Ukraine in its war with Russia war more broadly\u00a0\u2013 was all part of a plan for powerful financial inter -\nests like BlackRock to profit from the conflict. By August 1, 2023, the video had received more than two million views and 13,011 comments. While none of Brand\u2019s commentary was explicitly antisemitic, 290 comments received a high antisemitism score from the OHI (2.2% of all comments at that time).\nSeveral commenters picked up on Brand\u2019s emphasis on conspiratorial busi -\nness opportunities, and the fact that both Zelensky and BlackRock CEO Larry Fink are Jewish, to repeat well-worn antisemitic tropes about Jews controlling global finance. However, most comments were careful to use coded language and signals that other antisemites would recognize but that would avoid YouTube\u2019s content moderation rules. For example, \u201cEverything Russel talked about here is JU owned and controlled. End ZOG in Washing -\nton!\u201d uses \u201cJU\u201d in place of \u201cJew\u201d and the acronym ZOG, which stands for \u201cZionist-occupied government,\u201d is commonly used by antisemites on- and offline. While this comment could be interpreted as violating YouTube\u2019s pro-hibition against conspiracy theories based on protected attributes, it can only be identified as such if one has the requisite contextual knowledge. Another \n178 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nuser wrote, \u201c(((BlackRock)))? (((Zelensky)))? If only there was some kind of \nconnection\u00a0.\u00a0.\u00a0. [thinking face emoji],\u201d using the triple parentheses symbol to identify someone or something as Jewish ( Smith\u00a0& Fleishman, 2016 ). This \ncomment, too, was ambiguous enough to avoid removal by YouTube.\nBrand posted the same video to his Rumble account, a YouTube competitor \nwith less stringent content moderation. The video received far less engage -\nment on Rumble than on YouTube (only 30,800 views and 188 total com -\nments), but some commenters were more overt in their antisemitism. One wrote, \u201c2 more thieving Jews,\u201d while another opined, \u201cBlackRock C.E.O. Larry Flink? Jewish by any chance? Or is that antisemitic to point out Jew -\nish elites and Israel are responsible for wars?\u201d Another commenter, however, was more hesitant, writing, \u201cAll gews,\u201d before adding as a threaded reply, \u201cI can\u2019t I\u00a0have to stay incognito. sry Russ [kissing face emoji].\u201d Notably, one of the YouTube commenters had left a similar reply\u00a0\u2013 \u201cAll bloody Gews\u201d\u00a0\u2013 demonstrating the shared lexicon in this loose community.\nComments responding to Brand\u2019s same videos appeared on fringe plat -\nforms such as Gab, Gettr, Twitter, and Truth Social as well, with links to the respective videos. This inter-platform cross talk was so prevalent that it suggested that the comments arising on these various platforms, anchored by a common referent (the video), are part of a continuous conversation going on among several social media platforms. The participants in these conver -\nsations traverse the different platforms with considerable facility in order to exploit respective variations in content moderation practices within the social media ecosystem, about which they are clearly cognizant, as reflected in their comments. For instance, some of the posts revealed users\u2019 aware -\nness of the different restrictions on hate speech on alternative platforms. In a secondary thread on Gab, one user noted with regard to YouTube, \u201cI sug -\ngest people dont say whatthey think inn the comments. Russell seems to be leading everyone to reveal their thoughts on a highly monitoored medium.\u201d\nWhile some social media users identified antisemitic subtext in Russell \nBrand\u2019s video about BlackRock and Ukraine, it would be unfair to say that Brand intended for his words to be interpreted that way (he has elsewhere denied accusations of antisemitism; Brand, 2014). In fact, the absence of \nintentional subtext in Brand\u2019s videos is among the reasons that extremists describe him as a redpill: His content should, theoretically, appeal to \u201cnor -\nmies\u201d while seeding talking points, including antisemitism, that they might encounter again in more extreme content.\nFocus on the Subtext\nBeyond figures like Brand are influencers whose far-right bona fides are more obvious, but who do not fully commit to overtly extremist positions lest they lose their accounts on mainstream platforms. Mark Dice is one such YouTu -\nber. A\u00a0far-right conspiracy theorist, Dice joined YouTube in 2007 and boasts \n\u201cHate Parties\u201d  179\nthat his was \u201cthe first conservative YouTube channel to reach 1 million sub -\nscribers\u201d (Dice, n.d.). On his channel, Dice covers political and pop culture \nnews and adds his own commentary and analysis. As of August 2023, his channel had over 1.86 million subscribers.\nOne of Dice\u2019s videos, titled \u201cThe Truth About Steven Crowder\u2019s $50 \nMILLION DOLLAR Feud with Ben Shapiro\u2019s Daily Wire,\u201d was posted on January 19, 2023. By August 1, 2023, it had received 433,345 views and 13,151 comments, including 347 that scored highly on the OHI (2.6% of the total). In the video, Dice commented on a high-profile dispute\n7 over a \nterm sheet offer between two of the most popular conservative YouTubers: comedian-turned-pundit Steven Crowder and Ben Shapiro, cofounder of the hardline conservative news and opinion outlet The Daily Wire. Shapiro\u2019s \nOrthodox Jewish heritage is a core part of his public identity. In Dice\u2019s video commentary, he described Shapiro as being \u201cin bed with Big Tech\u201d because he spends millions of dollars on Facebook advertising annually and had a \u201csecret dinner\u201d with Meta CEO Mark Zuckerberg, who, Dice noted, is also Jewish.\nThe video\u2019s antisemitic subtext was clearest, however, in Dice\u2019s reference to \n\u201ccultural Marxism\u201d as a threat to American society and his use of the phrase \u201cdual loyalty\u201d to describe Crowder\u2019s relationship with leaders of American conservatism. Both of these phrases are common antisemitic dog whistles, the former part of a conspiracy theory about Jewish control of entertainment media (Braune, 2019), and the latter an accusation often made of Jewish Americans who express support for Israel ( Elman, 2022). Dice argued that \nYouTubers like himself would be unable to criticize Israel if they signed a contract with a major conservative media outlet, thereby insinuating Jewish influence over the topics conservative media covers (Dice, 2023).\nNone of the ambiguous language that Dice used in his video would likely \nbe considered hate speech by YouTube regulations. But many of the video\u2019s commenters picked up on the subtext implicit in Dice\u2019s targeting of conserva -\ntive Jewish individuals and his references to antisemitic tropes. Commenters, too, used strategic language and symbols to communicate antisemitic rheto-ric covertly. For instance, one commenter wrote, \u201cCrowder is right, ((())) took control of conservatism,\u201d using the triple parentheses as a metonym for Jews. Another wrote, \u201cShapiro. Rubin. Connect the dot goy,\u201d using the Yiddish/modern Hebrew word for non-Jew that is popular among far-right antisemites (Friedman, 2017). Others were less hesitant, leaving comments that would appear to violate YouTube\u2019s prohibitions against promoting con -\nspiracy theories about a group based on protected attributes, but without explicitly inciting violence. To wit, one commenter wrote, \u201cWho the hell trusts Shapiro? He\u2019s a Zionist puppet in a big big world ruled by his kosher uncles.\u201d\nNine comments included some variation of the phrase \u201cname the Jew,\u201d \na rallying cry of sorts (ADL, 2018) that online antisemites often use as a \n180 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nmeasuring stick to evaluate how far an influencer like Dice is willing to go; \nif they \u201cwon\u2019t name the Jew,\u201d they are either still compromised by Jewish media censorship or not yet \u201cawakened\u201d to the antisemitic worldview in its totality. One commenter picked up on Dice\u2019s \u201ccultural Marxism\u201d dog whis -\ntle and wrote, \u201cAnd who are these cultural Marxists? What ethnic group is pushing the cultural Marxism? If you won\u2019t name the Jew you are subservi -\nent to them.\u201d Most comments in this vein lamented what they saw as Dice\u2019s failure to adequately name the Jew, but one voiced their approval: \u201cJews out -\njewing each other\u00a0.\u00a0.\u00a0. nothing new, the only one I\u00a0trust is mark dice because he calls out the Jew.\u00a0.\u00a0.\u00a0. Alway remember kids, \u2018if they don\u2019t name the Jew, their message isn\u2019t true.\u2019\u201d\nThe discussion in the YouTube comments about whether or not Dice \nwas willing to name the Jew closely mirrored conversations taking place more or less simultaneously on fringe platforms where the video\u2019s link had been shared. Dice posted the link to his own Gab account, where nearly one-quarter of the replies to his post were antisemitic. Four sequential replies all chided Dice for not explicitly naming the Jew, including one that posted an antisemitic infographic created by the hate group the Goyim Defense League (see Figure\u00a08.1).\nIn addition to its discussion on Gab, it was a topic on 4chan\u2019s /pol/ board. \nThere, one commenter drew a distinction between Dice and Crowder on this issue, writing, \u201cMark Dice called out the kikes. Crowder doesn\u2019t [.] crowder is not the \u2018right.\u2019\u201d Another in the same thread disagreed: \u201cShow me one video where [Dice] names the Jew. I\u00a0will wait. Protip: You can\u2019t.\u201d The /pol/ board has hosted similar discussions about Dice and his subtextual antisem -\nitism in other threads that were unrelated to the video about Crowder and Shapiro. In one thread titled simply \u201cMark Dice,\u201d the original poster asked, \u201cHow is this guy still kicking? He names the Jew in almost every video now,\u201d to which another user replied, \u201cSaying \u2018a certain group of people\u2019 is not naming them.\u201d Whether 4chan users lauded Dice for his antisemitic tropes or criticized him for not going far enough, several noted his savvy in avoid -\ning being suspended by YouTube; as one commenter put it, \u201cLooks like he\u2019s studied how to sidestep the censorship.\u201d\nThese comments and others like them are strong indications of the affirm-\ning cross-platform dynamics in which certain figures serve as gathering points. Nearly identical conversations (save for the slurs) unfold in the com-ments sections on YouTube videos and in reply threads on fringe platforms where links to those videos are shared.\nSaying the Quiet Part Out Loud\nFor many antisemites on the fringes, YouTubers like Russell Brand and Mark Dice are useful for redpilling or as fellow travelers who attract like-minded \n\u201cHate Parties\u201d  181\ncommunities with their content. But they are still seen as relative outsiders, \neither because they are not actually antisemitic themselves (Brand) or not antisemitic enough (Dice). A\u00a0third, rarer category of YouTuber includes those who produce channels with multiple videos that contain overtly antisemitic content but have thus far avoided suspension. The videos in these channels \u201csay the quiet part out loud,\u201d that is, turn what is subtext in videos like Dice\u2019s into explicit verbiage. For this reason, they are also more obviously integrated with antisemitic cross-platform conversations.\nFIGURE\u00a08.1   Screenshot of Replies to a Gab Post Discussing a Mark Dice You -\nTube Video\nNote: Taken by the authors, September 11, 2023.\n182 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nLeather Apron Club is one such channel. Its creator goes by \u201cAlex\u201d in \ninterviews with other far-right YouTubers. He produces pseudoscientific \nessay-style videos from a distinctly anti-democratic worldview, including a series on \u201cJewish overrepresentation\u201d in media. A\u00a0comment on a 4chan thread about Leather Apron Club\u2019s YouTube channel on January 2, 2023, stated, \u201cJust found this guy today, underrated channel. Names the Jew and calls out the controlled opposition such as [Jordan] Peterson, Alex Jones, and [Lex] Fridman.\u201d\nThe first video in Leather Apron Club's Jewish overrepresentation series \naddressed the idea that Jewish people hold many influential positions because of they supposedly have high IQ scores. Alex's video claimed to debunk this notion. In this October 24, 2022  video, he reviewed academic publications \nabout IQ scores and how they correlate with racial and ethnic categories.\n8 \nAlex asked his audience to question, even if they accept the IQ data, does that mean that it is \u201cgood\u201d for Jews to be overrepresented in positions of power, especially in the media? Alex also insinuated that Jews do not have the best interests of American society in mind and that Jews are an outsider group that has usurped political power in the United States. He concluded with an argument that could reasonably be interpreted as promotion of hatred based on a conspiracy theory about alleged Jewish malice, and therefore in viola-tion of YouTube\u2019s hate speech policy: \u201cWe should no longer allow ourselves to be browbeaten by this false sense of inferiority, nor should we be made to accept what is obviously an astroturfed media landscape\u201d ( Leather Apron \nClub, 2022).\nAs of August 1, 2023, the video had been viewed over 200,000 times and \nreceived 5,859 comments, 711 (12%) of which scored above 0.9 on the OHI. As with the Brand and Dice videos, many commenters used coded language and implicit references to communicate antisemitic sentiments, such as \u201cSyn-agogue of satan,\u201d a reference to a line in Revelation 3:9 in the Christian Bible that antisemites often quote to one another; \u201cOY VEY THE GOYIM KNOWS!!!\u201d another phrase common among online antisemites for commu -\nnicating beliefs about a secretive Jewish cabal controlling power from behind the scenes ( ADL, n.d.); and \u201c[Jordan] Peterson is a j3w shill,\u201d using the num -\nber \u201c3\u201d in place of \u201ce\u201d to avoid detection.\nThere were also a handful of comments that took issue with the claims \nabout Jewish IQ in the video from a perspective embedded in a broader, more esoteric antisemitic conversation. While Alex expressed skepticism that Jews actually have higher average IQs than other groups in his video, a different faction of antisemites and white supremacists are committed to that belief because it helps explain their antisemitic conspiracy theories about Jew -\nish control of business, media, and politics (see Welton, 2023, responding \ndirectly to Leather Apron Club\u2019s video in an antisemitic, white supremacist online publication). For example, one commenter wrote:\n\u201cHate Parties\u201d  183\nJew IQ didn\u2019t get debunked. Anymore than IQ did or Asian IQ did. It\u2019s \n3% racially of the US population but yes. They seem to have lots of $$$ like, 30% of US wealth compared to 3% of the population. But Asians don\u2019t overrepresent anywhere near that much of the wealth holdings? Note I\u00a0don\u2019t say that their high IQ is why the wealth holdings exist.;)\nThe same contours of this conversation were evident on the fringe platforms where the link to Leather Apron Club\u2019s video was shared. For instance, in a 4chan /pol/ thread praising the video, one dissenter commented, \u201cfact is, Jews actually aren\u2019t smarter than Europeans,\u201d to which another replied, \u201cThen what is your theory on why they are overrepresentated in powerful and influential positions?\u201d Another commenter in the same thread asked, \u201cIf Jews aren\u2019t smarter then why are they so successful?\u201d which received this reply: \u201cBecause they groom their kids to have PTSD from an imaginary prosecution and set them up with both nepotism and a highly competitive mindset.\u201d In a Telegram channel linking to the video and another far-right YouTube video criticizing Leather Apron Club, a user wrote:\nJewish high IQ is an objective fact.\u00a0.\u00a0.\u00a0. That alone explains a huge (though not all) amount of Jewish power and influence.\u00a0.\u00a0.\u00a0. [All this] is supported by other figures such as [former evolutionary psychology professor] Kevin MacDonald and [professor and YouTuber] Edward Dutton.\nSimilar discussions unfolded on Gab, where the Leather Apron Club video\u2019s link was shared 42 times.\n9 In one thread, users defended the validity of the \nhigh Jewish IQ claim by referencing similar arguments made by Jared Taylor, the white supremacist founder of American Renaissance. One commenter skirted the alleged factuality of the IQ question entirely, writing, \u201cJew\u2019s IQ is not the issue; high or low\u00a0\u2013 No it is their consuming hatred for the White Race that is germane to White Survival under the Tyranny of the Jew.\u201d Nota-bly, YouTube commenters referenced both MacDonald and Taylor as well in their criticisms of Alex\u2019s argument, further demonstrating the shared conver -\nsation across platforms of the Leather Apron Club hate party.\nMore so than the other types of video in our analysis, channels like Leather \nApron Club attract antisemitic comment spikes on YouTube not because of organized hate raids or as organic reactions from antisemites to their content, but rather because their channels are recognized on the fringes and in the mainstream as social spaces where antisemitism is welcome. Since it was first posted, the \u201cHigh Jewish IQ Debunked\u201d video has received multiple waves of antisemitic engagement in the comments, almost always accompanied by its link being posted yet again to a fringe platform. To wit, it has been shared on Gab at least 30 different times and on 4chan at least 208 times at the time of this writing (August 13, 2023). The video\u2019s staying power speaks to its \n184  Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nstatus, and Leather Apron Club\u2019s, as touchstones for online hate; by contrast, \nBrand\u2019s and Dice\u2019s video links were shared within the first few days of their release, but never subsequently.\nKeeping the Party Going\nSome fringe platform commenters speculated that Leather Apron Club could not possibly remain on YouTube for much longer; as one 4chan user put it, \u201cThis dude is keyed as hell. Enjoying him before schlomo kicks him to [You -\nTube competitor] bitchute.\u201d In an interview with fellow far-right YouTuber Keith Woods on cozy.tv\u00a0\u2013 a livestreaming platform created by white suprem -\nacist Nick Fuentes\u00a0\u2013 Leather Apron Club\u2019s Alex explained that YouTube is necessary for pushing his extremist messaging out to a wider audience, but that this means being careful about how he packages his videos to avoid their removal or YouTube suspending his account.\n10 His comments and the com -\nmentary from the fringes about his channel reveal two important insights about the social media ecosystem and social processes of hate: Hate purvey -\nors are acutely aware of content moderation differences and work to exploit them, and they value their ability to remain on mainstream platforms. Their relationship to YouTube and how they approach it strategically also help to explain the hate party phenomenon, why partygoers participate, and what\u00a0\u2013 if anything\u00a0\u2013 can be done to mitigate its harms.\nWhy Do They Come, and Why Do They Stay?\nThere is a clear throughline from Don Black\u2019s comments about the impor -\ntance he saw in bringing Stormfront to the public Internet to contemporary online hate on the fringes and its relationship to mainstream social media like YouTube. Outside observers may question why antisemites, white suprema -\ncists, and others would want to be active on platforms where they face the possibility of suspension when there are plenty of viable fringe alternatives where they can network. While we can only speculate as to individual moti -\nvations, a few key possibilities bear mentioning.\nFirst, fringe social media users, from garden variety conspiracy theorists \nto the true extremists, often talk of the need to be on the \u201cdigital battle -\nfield\u201d where they can \u201credpill normies\u201d and potentially recruit new followers to their causes (Hannah, 2023; Munn, 2023). To wit, in his interview with \nKeith Woods, Alex of Leather Apron Club agreed with Woods\u2019 assessment that YouTube is \u201cobviously bad\u201d regarding alleged censorship, but added, \u201cThere\u2019s no better platform to be on than YouTube. We need to get [our message] out there in order to bring in new followers, as it were\u201d ( Woods, \n2023). Some hate messengers may also believe that their presence in the mainstream can help \u201cpush open the Overton window,\u201d that is, expand the range of politically acceptable positions to include more and more extreme \n\u201cHate Parties\u201d  185\nideas (Marwick\u00a0& Lewis, 2017 ). In other words, their ability to normalize \nhateful worldviews and influence policy depends upon their continued access \nto communication platforms with the largest audiences, rather than broad -\ncasting to a relatively narrow group of users on the fringes.11\nSecond, from the channel operators\u2019 perspective, YouTube affords oppor -\ntunities for making money that other platforms do not or cannot. While financial incentives were beyond the scope of this particular study, all three of the channels we analyzed here were able to collect revenue from their presence on YouTube in a variety of ways. The first and most obvious way was via the platform\u2019s monetization system, the YouTube Partner Program. While we cannot say for certain that Brand, Dice, and Leather Apron Club applied to be YouTube Partners, all three met the basic eligibility require -\nments\u00a0\u2013 at least 1,000 subscribers and 4,000 public watch hours in the last 12 months\u00a0\u2013 and a look at the page source code revealed that monetization was enabled for both their channels and the individual videos we analyzed in this piece.\n12 All three also collected modest sums on each of the videos \nwe looked at with \u201cSuper Thanks,\u201d a feature that allows viewers to donate directly to the channel operator when they leave a comment. And all three shared links in the video descriptions to websites where viewers could pur -\nchase their merchandise or donate to their crowdfunding accounts (e.g., Patreon, SubscribeStar, and Buy Me a Coffee). Brand, Dice, Leather Apron Club, and others have a clear financial interest in remaining on YouTube, and while we can only speculate, their followers and supporters may also want to be active in the mainstream to lend material support to the influ -\nencers they see as being instrumental in advancing their ideological and political causes. By contrast, fringe sites like Gab and 4chan do not enable monetization.\nFinally, some hate partiers may derive pleasure from spreading hate \u201cout \nin the open\u201d and pushing the boundaries of what mainstream platforms allow. As in hate raids and other forms of malicious trolling\u00a0\u2013 where the goal is to disrupt the target\u2019s normal life or \u201cdo it for the lulz,\u201d that is, to revel in the target\u2019s suffering or protestations ( Phillips, 2015)\u00a0\u2013 there is a libidinal \ndimension to hate parties ( Matheson, 2022; see also Hook, 2017). But while \nthe pleasures of trolling or sadistic cruelty come in large part from observing targets\u2019 reactions\u00a0\u2013 for example, \u201ctriggering the libs\u201d ( Aspray, 2019)\u00a0\u2013 the \npleasure of participating in a hate party may be more complex, akin to what Udupa (2019) calls \u201cfun as a metapractice\u201d in extreme speech communities. For hate partiers, there appears to be some joy in seeing and being seen in a loose community of others who share their worldview and in knowing that they are doing or saying something they expect would get them banned. To wit, a Gab user highlighted and celebrated the hate party phenomenon in a YouTube comment section on another of Mark Dice\u2019s videos (see Figure\u00a0 8.2). \nFuture research could address jouissance\n13 in social processes of online hate \nand how it manifests, such as in hate parties.\n186 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nWhat Can Be Done?\nIn a sense, hate parties are the contemporary equivalent of hate BBSes like \nAryan Nations and Liberty Bell Publishing: Virtual mini-communities where users can connect over shared hateful worldviews and forge social bonds. Two key differences, however, make YouTube hate parties more concerning. First, they are embedded in larger, looser communities that span multiple platforms and are somewhat ephemeral, coalescing around certain pieces of content or specific events but without any formal or stable membership. These communities\u2019 multi-locality and ephemerality make it more difficult to fully appreciate the scope and impact of hate parties, which serve as digital artifacts of their existence. Second, hate parties are examples of how broader online hate communities exploit the reach that mainstream platforms afford, which is magnitudes greater than anything they could hope to achieve on the fringes. Whereas hate BBSes had to rely on word of mouth to build their \nFIGURE\u00a08.2   Screenshot of a Gab Post Celebrating the Antisemitic Comments on \na Mark Dice YouTube Video\nNote: Taken by the authors, September 11, 2023.\n\u201cHate Parties\u201d  187\naudiences, and hate websites like Stormfront are dependent on their own \nplatforms and being indexed by search engines for their reach, YouTube hate parties and the channels that make space for them have the world\u2019s second-largest social media platform and its sophisticated recommendation algorithms at their disposal.\nThe hate party phenomenon exposes the limits of YouTube\u2019s content mod -\neration policies specifically and of social media platforms more generally. Platforms typically detail content moderation approaches in their terms of service or community guidelines, all of which currently treat offenders indi -\nvidually and look for clear evidence of intention before taking action against any potentially violative behavior. No platform considers an account\u2019s indi -\nrect impacts and influence or the networked characteristics of online hate and harassment, not to mention how such harms unfold across different plat -\nforms. One could say that they do not take social processes of online hate into account. And although platforms can detect spikes in inbound traffic from fringe sites via referrer URL data, they have no power over where and when links to content on their sites are shared.\nResearchers at ADL have called such indirect and networked activity \n\u201c stochastic\u201d hate and harassment ( 2022, 2023a, 2023b; see also Abdul \n Rahman (forthcoming)), a riff on the concept of \u201cstochastic terrorism\u201d \n(Amman\u00a0& Meloy, 2021). YouTube hate parties are prime examples of sto -\nchastic hate: Unlike hate raids, they are not explicitly coordinated, and none of the channel operators implore their viewers to take action or engage hate -\nfully with their content. Moreover, the influential accounts whose content attracts hate parties do not, in most cases, violate any content moderation rules. Even Leather Apron Club, arguably the most antisemitic of the three channels we analyzed for this chapter, produces content that is borderline at worst and which YouTube has determined does not break its hate speech policy. Yet when accounting for the surrounding context, it is clear that chan -\nnels and video pages are facilitating social spaces for hate to flourish.\nIf the content is not violative, and no one is being targeted for harassment, \nwhat, then, is harmful about hate parties? We contend that the implicit nor -\nmalization of hate they represent is itself harmful and is one of the unexam-ined consequences of narrowly considered content moderation. Adding to that sense of normalization is the fact that hate party videos are monetized and recommended to viewers by YouTube\u2019s algorithm; as one user posted on Y Combinator\u2019s Hacker News forum, they were unaware of Leather Apron Club or its content until the \u201cHigh Jewish IQ Debunked\u201d video appeared in their \u201cUp Next\u201d recommendations (Hacker News, 2023). In other words, it is not just that the YouTube platform has questionable content but also that it actively promotes such content and empowers hate purveyors to profit from it. Additionally, hate parties may work as tools for radicalization, though more research is needed to test this hypothesis. So long as they leverage their understanding of content moderation rules to avoid removal, hate partiers \n188 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nand the accounts that host them can continue to insert fringe talking points \ninto the mainstream and, potentially, lead viewers from the mainstream fur -\nther into the fringes.\nNotes\n 1 Extremism researcher Chip Berlet estimates that the Liberty Bell BBS first went \nonline in March 1984 (2001, p.\u00a02).\n 2 These platforms represent the fringe platforms that we had access to via SMAT\u2019s \nAPI and data scraping tools, and on which users primarily post in English. They \nare not an exhaustive list of fringe platforms.\n 3 Since our primary interest for an advocacy research project we were working on \nat ADL was documenting and measuring online antisemitism, this motivated our decision to use the OHI and to narrow the focus of our analysis. Future research could use the same methods and different classifiers to identify similar patterns in anti-Black, anti-LGBTQ+, or other forms of hate that coalesce into hate parties.\n 4 Unless otherwise noted, all direct quotes from social media comments and posts \nare presented verbatim and retain spelling and grammar errors.\n 5 Redpilling is often a gradual process, as Rebecca Lewis details here in the case of \nwhite nationalists specifically: \nWhite nationalists often describe [redpilling] as a stepwise process. For exam -\nple, in one possible pathway, they may start by rejecting the mainstream media and \u201cPC culture\u201d; then embrace anti-feminist ideas; then embrace scientific racism of the idea that racial oppression is not real; and then finally, the idea that Jewish people wield positions of influence and harbor malicious intents against white people. (They often refer to these processes as addressing the \u201cwoman question,\u201d the \u201crace question,\u201d and the \u201cJewish question,\u201d or alter -\nnatively as \u201cgetting redpilled\u201d on any of these individual issues.)\n (2018, p.\u00a035)\n 6 In September 2022, Brand announced that he would be moving his daily lives -\ntream from YouTube to its fringe video hosting competitor Rumble, accusing You -\nTube of \u201ccensorship\u201d after one of his videos that violated YouTube\u2019s policies on medical misinformation was removed. However, Rumble does not afford Brand the same reach as YouTube: his Rumble channel has only 1.34 million subscribers, and his videos receive fewer views (just 136,000 views for a conspiratorial video about the Centers for Disease Control and COVID-19 vaccine mandates posted on August 4, 2023, compared to 852,000 views for the same video posted the same day on YouTube).\n 7 See Ramirez (2023) for a more detailed explanation of the dispute.\n 8 White Nationalists in particular fixate on IQ scores as evidence in support of their \nso-called \u201crace realist\u201d arguments that posit fundamental biological differences in the human species according to race (see Panofsky et\u00a0al., 2021).\n 9 In fact, one commenter wrote, \u201cBe sure to get on gab there is a lot of people \nthat would love to know about the Jews,\u201d further demonstrating hate parties\u2019 cross-platform dynamics.\n 10 His approach appears to be working for now. ADL\u2019s online incident response \ncenter reported Leather Apron Club\u2019s video using our status in YouTube\u2019s Trusted Partner Program, which provides faster escalation paths for reports of violative content. YouTube replied, \nWe have determined that the video does not violate our Hate Speech policy and will remain live on the platform. While this channel may contain controversial or inflammatory views on topics related to stereotypes that incite or promote \n\u201cHate Parties\u201d  189\nhatred based on protected group status, we did not identify content violating \nour Hate Speech policies.\n 11 Though beyond the purview of this chapter, there is also a strain within fringe hate \nand conspiracy theory groups that frames the digital battlefield in eschatological terms, that is, as the site of a spiritual struggle between the forces of good and evil that portends Biblical end times ( Hannah, 2021; Macklin, 2018). For adher -\nents to this worldview, their participation on mainstream platforms assumes a religious valence to which they may feel \u201ccalled\u201d to fulfill a purpose greater than themselves.\n 12 Notably, YouTube does not run ads before or during any of the three videos.\n 13 We are indebted to Brock (2020) for the application of jouissance to virtual com -\nmunities and cybercultures. However, it is important to note the incommensura -\nbility of culture-specific affect between the communities Brock writes about and online hate purveyors.\nReferences\n4chan. (n.d.). Rules: /pol/\u00a0\u2013 politically incorrect. 4chan Community Support LLC. \nhttps://4chan.org/rules#pol/\nAbdul Rahman, E. (forthcoming). The anatomy of indirect swarming. In K. Barker\u00a0& \nO. Jurasz (Eds.), Routledge handbook of social media, law and society. Routledge.\nAbidin, C. (2018).  Internet celebrity: Understanding fame online . Emerald Publish -\ning, Ltd.\nAmman, M.,\u00a0& Meloy, J. R. (2021).  Stochastic terrorism: A\u00a0linguistic and psycho -\nlogical analysis. Perspectives on Terrorism, 15(5), 2\u201313.\nAnti-Defamation League (ADL). (1985).  Computerized networks of hate: An ADL \nfact finding report. ADL.\nAnti-Defamation League (ADL). (2018, August 23).  Patrick Little\u2019s \u201cname the Jew\u201d \ntour spreads anti-semitic hate nationwide . ADL. https://www.adl.org/resources/\nblog/patrick-littles-name-jew-tour-spreads-anti-semitic-hate-nationwide/\nAnti-Defamation League (ADL). (2022, December 15).  The reality of how harassment  \nspreads on Twitter . ADL. https://www.adl.org/resources/blog/reality-how-harass  \nment-spreads-twitter/\nAnti-Defamation League (ADL). (2023a, May 24).  Threads of hate: How Twitter\u2019s \ncontent moderation misses the mark.  ADL. https://www.adl.org/resources/blog/\nthreads-hate-how-twitters-content-moderation-misses-mark/\nAnti-Defamation League (ADL). (2023b, September 14). Hate parties: Sharing links \non fringe platforms drives antisemitic comments on YouTube . ADL. https://\nwww.adl.org/resources/report/hate-parties-sharing-links-fringe-platforms-drives-  \nantisemitic-comments-youtube/\nAnti-Defamation League (ADL). (n.d.). The goyim know/shut it down . ADL. www.\nadl.org/resources/hate-symbol/goyim-knowshut-it-down/\nAspray, B. (2019). On trolling as comedic method. Journal of Cinema and Media \nStudies, 58(3), 154\u2013160. https://doi.org/10.1353/cj.2019.0030\nB\u00e4r, D., Pr\u00f6llochs, N.,\u00a0& Feuerriegel, S. (2023).  New threats to society from free-speech \nsocial media platforms. arXiv. https://doi.org/10.48550/arXiv.2302.01229\nBarbrook, R.,\u00a0& Cameron, A. (1996). The Californian ideology. Science as Culture, \n6(1), 44\u201372. https://doi.org/10.1080/09505439609526455\nBarlow, J. P. (1996, February 8).  A declaration of the independence of cyberspace . \nElectronic Frontier Foundation. https://www.eff.org/cyberspace-independence/\nBerlet, C. (2001, April 28).  When hate went online  [Paper presentation]. Northeast \nSociological Association, Spring Conference, Fairfield, CT, United States.\nBrand, R. (2014, August 20).  Why I\u00a0 oppose anti-semitism. Huffington Post. https://www.\nhuffingtonpost.co.uk/russell-brand/why-i-oppose-anti-semitism_b_5694864.html\n190 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nBrand, R. (2023, January 12).  It\u2019s starting [Video]. YouTube. www.youtube.com/\nwatch?v=4v_aC1ZTlOg&ab_channel=RussellBrand/\nBraune, J. (2019). Who\u2019s afraid of the Frankfurt School? \u201cCultural Marxism\u201d as an \nantisemitic conspiracy theory. Journal of Social Justice, 9(1), 1\u201325.\nBrock, A. (2020). Distributed blackness: African American cybercultures . NYU Press.\nDaniels, J. (2018). The algorithmic rise of the \u201calt-right\u201d. Contexts, 17(1), 60\u201365. \nhttps://doi.org/10.1177/1536504218766547\nDavis, J. A. (1979). The logic of causal order. Sage.\nDice, M. (2023, January 19). The truth about Steven Crowder\u2019s $50 million dollar \nfeud with Ben Shapiro\u2019s daily wire [Video]. YouTube. https://www.youtube.com/watch?v=_t5cHVMEqbE/\nDice, M. (n.d.). Description. YouTube. https://www.youtube.com/@markdice/about/Donovan, J., Lewis, B.,\u00a0& Friedberg, B. (2019).  Parallel ports: Sociotechnical change \nfrom the alt-right to alt-tech. In M. Fielitz\u00a0& N. Thurston (Eds.), Post-digital cul-\ntures of the far right: Online actions and offline consequences in Europe and the US  \n(pp.\u00a049\u201365). Transcript-open.de. https://doi.org/10.14361/9783839446706-004\nEl Ouirdi, M., El Ouirdi, A., Segers, J.,\u00a0& Henderickx, E. (2014).  Social media con -\nceptualization and taxonomy: A\u00a0 Lasswellian framework. Journal of Creative \nCommunications, 9(2), 107\u2013126. https://doi.org/10.1177/0973258614528608\nElman, R. A. (2022). The mainstreaming of American antisemitism: The defeat of \nan ideal. Journal of Contemporary Antisemitism , 5(1), 105\u2013120. https://doi.\norg/10.26613/jca/5.1.104\nFreelon, D., McIlwain, C. D.,\u00a0& Clark, M. D. (2016).  Beyond the hashtags: #Fergu -\nson, #Blacklivesmatter, and the online struggle for offline justice . Social Science \nResearch Network. https://doi.org/10.2139/ssrn.2747066\nFriedman, D. (2017, August 25). Why I\u00a0won\u2019t stop using the term \u2018goy\u2019. The Forward. \nhttps://forward.com/life/381035/why-i-wont-stop-using-the-term-goy/\nGab. (2023). Website terms of service. Gab AI Inc. https://gab.com/about/tos/Gerbaudo, P. (2012). Tweets and the streets: Social media and contemporary activism. \nPluto Press.\nGettr. (n.d.). Hateful behavior. GETTR USA, Inc. https://gettr.com/communityguidel\nines#hateful-behavior/\nGilbert, D. (2021, August 20).  One of QAnon\u2019s most antisemitic influencers is actually \na 39-year-old Baptist from Florida. Vice. https://www.vice.com/en/article/93yvmv/\nqanon-ghostezra-is-robert-randall-smart/\nGray, R. (2023, July 16). How bronze age pervert built an online following and \ninjected anti-democracy, pro-men ideas into the GOP. Politico. https://www.polit-\nico.com/news/magazine/2023/07/16/bronze-age-pervert-masculinity-00105427\nHacker News. (2023, January 20). Dear YouTube AI, I\u00a0am not a Nazi. Y Combinator. \nhttps://news.ycombinator.com/item?id=34452863\nHagen, S.,\u00a0& Tuters, M. (2021).  The internet hate machine: On the weird collectiv -\nity of anonymous far-right groups. In M. Devries, J. Bessant,\u00a0& R. Watts (Eds.), Rise of the far-right: Technologies of recruitment and mobilization  (pp.\u00a0171\u2013192). \nRowman\u00a0& Littlefield.\nHannah, M. N. (2021). A\u00a0 conspiracy of data: QAnon, social media, and infor -\nmation visualization. Social Media + Society , 7(3). https://doi.org/10.1177/ \n20563051211036064\nHannah, M. N. (2023). Information literacy in the age of internet conspiracism. Jour-\nnal of Information Literacy, 17(1), 204\u2013220. https://doi.org/10.11645/17.1.3277\nHine, G. E., Onaolapo, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, \nR., Stringhini, G.,\u00a0& Blackburn, J. (2017).  Kek, cucks, and god emperor Trump: \nA\u00a0measurement study of 4chan\u2019s politically incorrect forum and its effects on the web. Proceedings of the International AAAI Conference on Web and Social Media , \n11(1), 92\u2013101. https://doi.org/10.1609/icwsm.v11i1.14893\n\u201cHate Parties\u201d  191\nHook, D. (2017). What is \u201cenjoyment as a political factor\u201d? Political Psychology, \n38(4), 605\u2013620. https://doi.org/10.1111/pops.12417\nKoukaras, P., Tjortjis, C.,\u00a0& Rousidis, D. (2020).  Social media types: Introducing \na data driven taxonomy. Computing, 102(1), 295\u2013340. https://doi.org/10.1007/\ns00607-019-00739-y\nLeather Apron Club. (2022, October 24). High Jewish IQ debunked\u00a0\u2013 Joe Rogan \nfollow-up [Video]. YouTube. https://www.youtube.com/watch?v=stLCurXu0fc/\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on You -\nTube. Analysis\u00a0& Policy Observatory. https://apo.org.au/node/193281\nLim, M. (2020).  Algorithmic enclaves: Affective politics and algorithms in the neo -\nliberal social media landscape. In M. Boler\u00a0& E. Davis (Eds.), Affective politics of \ndigital media: Propaganda by other means (pp.\u00a0186\u2013203). Routledge.\nMacklin, G. (2018). \u2018Only bullets will stop us!\u2019\u00a0\u2013 the banning of National Action in \nBritain. Perspectives on Terrorism, 12(6), 104\u2013122.\nMariconti, E., Suarez-Tangil, G., Blackburn, J., De Cristofaro, E., Kourtellis, N., \nLeontiadis, I., Serrano, J. L.,\u00a0& Stringhini, G. (2019). \u201cYou know what to do\u201d: Proactive detection of YouTube videos targeted by coordinated hate attacks. Pro-\nceedings of the ACM on Human-Computer Interaction , 3(CSCW), 1\u201321. ACM. \nhttps://doi.org/10.1145/3359309\nMarwick, A. E. (2013).  Status update: Celebrity, publicity, and branding in the social \nmedia age. Yale University Press.\nMarwick, A. E. (2021).  Morally motivated networked harassment as normative reinforce -\nment. Social Media + Society, 7(2). https://doi.org/10.1177/20563051211021378\nMarwick, A. E.,\u00a0& Lewis, R. (2017, May 15).  Media manipulation and disinforma-\ntion online. Data\u00a0 & Society. https://datasociety.net/library/media-manipulation- \nand-disinfo-online/\nMatheson, C. L. (2022).  Liberal tears and the rogue\u2019s yarn of sadistic conservatism. \nRhetoric Society Quarterly, 52(4), 341\u2013355. https://doi.org/10.1080/02773945.2\n022.2061587\nMeisner, C. (2023).  Networked responses to networked harassment? Creators\u2019 coor -\ndinated management of \u201chate raids\u201d on Twitch. Social Media + Society , 9(2). \nhttps://doi.org/10.1177/20563051231179696\nMerlan, A. (2022, September 12). Russell Brand tries to promote ivermectin, gets \ninstantly fact-checked by his own followers. Motherboard/Vice. https://www.vice.\ncom/en/article/z34zd9/russell-brand-ivermectin/\nMunn, L. (2023). Red pilled\u00a0\u2013 The allure of digital hate. Bielefeld University Press.Panofsky, A., Dasgupta, K.,\u00a0& Iturriaga, N. (2021).  How white nationalists mobi -\nlize genetics: From genetic ancestry and human biodiversity to counterscience and metapolitics. American Journal of Physical Anthropology , 175(2), 387\u2013398. \nhttps://doi.org/10.1002/ajpa.24150\nPerry, B. (2000). \u201cButton-down terror\u201d: The metamorphosis of the hate movement. \nSociological Focus, 33(2), 113\u2013131. https://doi.org/10.1080/00380237.2000.\n10571161\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nRamirez, N. M. (2023, January 19).  Far-right blowhard calls $50 million Daily Wire  \noffer a \u2018slave contract\u2019. Rolling Stone. https://www.rollingstone.com/politics/politics-\n \nnews/steven-crowder-feuds-daily-wire-50-million-offer-1234664277/\nRheingold, H. (2000).  The virtual community: Homesteading on the electronic fron -\ntier (Rev. ed.). MIT Press.\nSaaed, M. H., Papadamou, K., Blackburn, J., De Cristofaro, E.,\u00a0 & Stringhini, G. \n(2023). TUBERAIDER: Attributing coordinated hate attacks on YouTube \n videos to their source communities . arXiv. https://doi.org/10.48550/arXiv.2308. \n05247\n192 Stephen C. Rea, Binny Mathew, and Jordan Kraemer\nShaffer, K. (2017, April 24). The business of hate media. Data for Democracy/\nMedium.\u00a0 https://medium.com/data-for -democracy/ the-business- of-hate- media-  \n47603a5de5f4/\nSmith, A.,\u00a0& Fleishman, C. (2016, June 1). (((Echoes))), exposed: The secret symbol \nneo-Nazis use to target Jews online. Mic. https://www.mic.com/articles/144228/\nechoes-exposed-the-secret-symbol-neo-nazis-use-to-target-jews-online/\nSouthern Poverty Law Center (SPLC). (n.d.). Louis beam. SPLC. https://www. \nsplcenter.org/fighting-hate/extremist-files/individual/louis-beam/\nStringhini, G.,\u00a0& Blackburn, J. ( Chapter\u00a011 this volume). Understanding the phases \nand themes of coordinated online aggression attacks.\nSwain, C. M.,\u00a0& Nieli, R. (Eds.). (2003).  Contemporary voices of white nationalism \nin America. Cambridge University Press.\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). From echo chambers to digital \ncampfires: The making of an online community of hate in Stormfront.\nTurner, F. (2005). Where the counterculture met the new economy: The WELL and \nthe origins of virtual community. Technology and Culture, 46(3), 485\u2013512.\nUdupa, S. (2019). Nationalism in the digital age: Fun as a metapractice of extreme \nspeech. International Journal of Communication , 13(2019), 3143\u20133163. https://\ndoi.org/10.5282/ubm/epub.69633\nVelasquez, N., Leahy, R., Restrepo, N. J., Lupu, Y., Sear, R., Gabriel, N., Jha, \nO., Goldberg, B.,\u00a0 & Johnson, N. F. (2020).  Hate multiverse spreads mali-\ncious\u00a0 COVID-19 content online beyond individual platform control . arXiv. \nhttps://doi.org/10.48550/arXiv.2004.00673\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWelton, L. (2023, January 28).  Yes Leather Apron Club, Jews DO have higher aver -\nage IQ. And they are more ethnocentric. The Unz Review. https://www.unz.com/ \narticle/yes-leather-apron-club-jews-do-have-higher-average-iq-and-they-are-  \nmore-ethnocentric/\nWoods, K. (2023, January 24).  Leather Apron Club on effective messaging  [Video]. \nYouTube. https://www.youtube.com/watch?v=sHOqSKMNHao/\nYouTube. (2019). Hate speech policy. YouTube Help. https://support.google.com/\nyoutube/answer/2801939?sjid=17062414790824244739-NA/\nZittrain, J., Faris, R., Noman, H., Clark, J., Tilton, C.,\u00a0& Morrison-Westphal, R. \n(2017). The shifting landscape of global internet censorship . Berkman Klein \nCenter for Internet and Society. https://hls.harvard.edu/bibliography/the-shifting- \nlandscape-of-global-internet-censorship/\nZuboff, S. (2019).  The age of surveillance capitalism: The fight for a human future at \nthe new frontier of power. PublicAffairs.\nZuckerman, E. (2023, February 19). A\u00a0social network taxonomy. New_ Public/Sub-\nstack. https://newpublic.substack.com/p/a-social-network-taxonomy/\nDOI: 10.4324/9781003472148-9\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Since their earliest days, information and communication technologies have \nserved as attractive conduits for hate groups\u2019 operations ( Gerstenfeld et\u00a0al., \n2003; Levin, 2002). The rise of social media has opened additional avenues \nfor hate groups to profess extreme ideologies, champion their causes, recruit members, and spread hateful content. According to the Southern Poverty Law Center (SPLC), the number of active, offline hate groups has increased over the last few years ( Beirich\u00a0& Buchanan, 2018). Prior work investigating \nhate groups\u2019 online activities has primarily focused on examining individual websites run by recognized hate groups ( Chau\u00a0& Xu, 2007; Schafer, 2002; \nZhou et\u00a0al., 2005 ). However, more recent research finds that the web-based \noutposts of hate online do not operate in isolation: Nearly 72% of hate group websites contain links to other extremist blogs and sites that are primarily used to sell extremist products online ( Schafer, 2002). Research on link shar -\ning across extremist blogs has reported that information communities exist across various hate ideologies (Zhou et\u00a0 al., 2005). Even more concerning is that hate groups\u2019 online presence has progressed from being limited to a dedicated website (a single platform) to multiple social media platforms. The ecosystem of online hate movements is complex, involving thousands of online accounts on numerous social media.\nMost of the chapters in this book focus on how casual, unaffiliated, or \ninformally organized hate messages operate on particular sites (such as Stormfront.org; T\u00f6rnberg\u00a0& T\u00f6rnberg, this volume) or hop from one social media site (where attacks are planned) to another (where attacks are exe -\ncuted; e.g., Rae et\u00a0al., this volume; Stringhini\u00a0& Blackburn, this volume). This chapter, instead, examines how existing, recognized hate groups that are rooted in offline organizations use social media, and what practices they 9\nINFORMATION SHARING AND \nCONTENT FRAMING ACROSS MULTIPLE PLATFORMS AND FUNCTIONAL ROLES THAT EXEMPLIFY SOCIAL PROCESSES OF ONLINE HATE GROUPS\nShruti Phadke and Tanushree Mitra\n194 Shruti Phadke and Tanushree Mitra\ndeploy to strategically intertwine social media, websites, blogs, and news \nmedia to spread their messages.\nThis chapter summarizes our research that investigated how extremist \norganizations exploit social media.1 The approaches, methods, and results \nrelied on research that scrutinized three months\u2019 of postings on the public Twitter and Facebook page profiles of 72 SPLC-designated U.S.-based hate groups, spanning five hate ideologies (e.g., white supremacy, anti-LGBTQ+) and five URL content types (e.g., information domains, recruitment web -\nsites). The research examined the strategies of framing and information shar -\ning employed by hate groups based in the United States, both within and across online platforms such as Facebook and Twitter (now renamed \u201cX\u201d). The research uncovered the different approaches that hate groups take when utilizing different social media platforms. Collectively, these findings suggest that hate groups are tailoring their content and information-sharing practices to address certain differences in the relative diversity (or homogeneity) of the audiences on these platforms.\nInter-Platform Content Framing and Information  \nSharing by Online Hate Groups\nThe first set of research draws upon the scholarship of Social Movement \nOrganizations (SMO; Zald\u00a0& Ash, 1966 ). Although hate messaging online \nis often considered to reflect some kind of social movement (see the explana -\ntion in Burston, this volume), despite the parallels between hate groups and SMOs, research has not yet positioned hate group operations within the SMO perspective. Doing so, however, provides a useful approach, bringing to bear background on collective action framing and information sharing by SMOs. Our research addresses these research questions: (RQ1) How do hate groups frame content across platforms? (RQ2) How do hate groups share information across platforms? And (RQ3) how do the framing and information-sharing efforts differ across multiple ideologies of hate across platforms?\nFor instance, Facebook appeared to serve as a platform for radicalizing \nlike-minded followers, while Twitter was employed for maintaining a posi -\ntive self-image and a broader educational outreach to diverse audiences. A\u00a0deeper analysis of the information-sharing network on Twitter revealed a higher proportion of news sources. Notably, some of these sources have been classified as mainstream with a right-leaning bias, according to fact-checking organizations. Given their mainstream status, these sources may be consid-ered more suitable for a general audience compared to the extreme blogs or websites often associated with hate groups. In essence, hate groups appeared to be leveraging the broadcasting capabilities of both Facebook and Twit -\nter while adapting their content framing and information-sharing strategies based on the diversity of their Twitter audience and the relative homogeneity of their Facebook following.\nInformation Sharing and Content Framing across Platforms  195\nHate Groups and Online Information Sharing\nThis research investigated hate group information-sharing activities across \ntwo popular social media platforms\u00a0\u2013 Twitter and Facebook. The empirical study comprised five phases: (1) Developing a framing annotation scheme, (2) identifying and mapping hate groups and their ideologies across plat -\nforms, (3) identifying content framing across platforms, (4) analyzing URL domains shared across platforms, and (5) describing communication within disparate ideologies. The next sections describe how this work analyzes con -\ntent framing by hate groups through the lens of social movement and collec -\ntive action framing theories.\nHate Groups as Social Movement Organizations\nSocial Movement Organizations (SMOs) are purpose-driven organizations with societal reconstruction agendas (McCarthy\u00a0& Moskalenko, 2003). An SMO is activated when changes in a society are misaligned with an organi-zation\u2019s goals (Zald\u00a0& Ash, 1966). Thus, in the case of hate groups, when society witnesses increased racial, sexual, or religious diversity, hate groups tend to be more active and aggressive in their efforts to target the respec -\ntive marginalized communities or minorities ( Zald\u00a0& Ash, 1966 ). SMOs use \nsocial media for various purposes, such as knowledge sharing, recruitment, collective action, and political advocacy ( Auger, 2013; Bozarth\u00a0 & Budak, \n2017; Guo\u00a0& Saxton, 2014; Obar et\u00a0al., 2012). Hate groups, like any other \nSMO, are increasingly shifting their information dissemination operations to online communication channels and social media platforms ( Donovan, 2019; \nJohnson et\u00a0al., 2019; O'Callaghan et\u00a0al., 2013).\nLike other approaches to intergroup conflict, in the case of online extrem-\nism, participants in hate groups relate as \u201cin-groups\u201d\u00a0\u2013 a population inter -\nnal to the extremist social movement\u00a0 \u2013 and their targets as \u201cout-groups\u201d (\n Costello et\u00a0al., 2019 ; Hewstone et\u00a0al., 2002 ). Returning to the SMO perspec -\ntive, organizations need to \u201cframe\u201d their communication to legitimatize their actions, inspire potential recruits, negotiate a shared understanding of the problematic societal condition that needs change, offer alternative arrange -\nments to promote change, and finally, urge others to act so as to effect that change (Benford\u00a0& Snow, 2000).\nCollective Action Frames and Hate Group Communication\nThe SMO perspective is further informed by the collective action fram -\ning scholarship. Framing refers to portraying an issue from one particular perspective, emphasizing certain aspects while de-emphasizing competing perspectives, in order to influence people\u2019s interpretation of the issue ( Boyds-\ntun et\u00a0al., 2014; Entman, 1993; Goffman, 1974). One type of framing uses \n196 Shruti Phadke and Tanushree Mitra\ncollective action frames, a widely used sociological approach that identi -\nfies framing approaches adopted by social movements, including diagnostic \n(which states the social movement\u2019s problem), prognostic (which offers a solu-\ntion), and motivational (which serves as a call to action) frames (  Benford\u00a0& \nSnow, 2000; Snow\u00a0& Benford, 1988).\nDeveloping a Framing Annotation Scheme\nThe first research question aims to discover how hate groups utilize collec -\ntive action frames (Snow\u00a0& Benford, 1988) to diagnose the problems, offer \n(prognostic) solutions, and provide motivations for action. We employed a \nmultistage annotation scheme development process (described in detail by Phadke\u00a0& Mitra, 2020; see prior work by Phadke et\u00a0al., 2018). Specifically, a small sample of the dataset of tweets generated by online hate groups was annotated through theory-guided inductive and deductive coding, which resulted in 23 coding categories spread across the three collective action frames. Through multiple rounds of coding and discussions, this framework was consolidated into 13 categories (see Table\u00a09.1, with examples).\nIdentifying and Mapping Hate Groups and Their  \nIdeologies across Platforms\nThis phase began by using the hate group list published by SPLC on their \nHate Map web page ( SPLC, 2019a), which enumerates the names of 367 \nhate groups (e.g., VDare, Patriot Front, Strormfront, Oath Keepers) along with their ideologies. We manually identified and verified the social media accounts of each. The majority of the hate groups had a public Facebook page as well as a Twitter handle\u00a0\u2013 a total of 75 organizations representing 5 extremist ideologies with accounts. The official social media handles of other groups were not found on Facebook or Twitter. The research gathered public Twitter tweets and posts from the public Facebook profile pages of these accounts, between March 31, 2019, and July 1, 2019, accumulating three months of hate group activities. The dataset comprised 16,963 tweets and 14,642 Facebook messages across 72 accounts.\nAfter consulting with an expert sociologist, we grouped some of the ide -\nologies described by the SPLC (2019b) directory into five broader categories \nor groups based on the overlap in their beliefs: White Supremacy, Religious \nSupremacy, anti-Muslim, anti-LGBT group, and anti-Immigration.\nHow active were the 72 hate groups on Facebook and Twitter? Hate groups \ncontributed significantly more tweets than Facebook posts, but hate group members produced significantly more Facebook Likes compared to Twitter \nfollowers\u2019 hearts postings. There was no significant difference between the two platforms in terms of the overall distribution of messages per organiza-tion, or the levels of posting activity within individual ideologies.\nInformation Sharing and Content Framing across Platforms  197\nTABLE\u00a09.1   Frame Annotation Scheme\nDiagnostic\nOppression: In-group complains about being oppressed through violent or repres-\nsive action, infringement on their rights or resources, or through indictment or \nsanctions\nEx: \u201cForced to abandon biblical principles\u201dFailure: In-group assesses that the government, the system, or other agencies such as \nmedia have failed to protect them from the problems caused by the out-group\nEx: \u201cGovernment placing Americans in danger\u201dImmorality: In-group indicates that the out-group demonstrates immorality though \nunethical, immoral, or uncivil behavior or values dissonance.\nEx: \u201cIslam teaches and Muslims practice deception\u201dInferiority: In-group believes that the out-group is inherently inferior to them based \non the political influence, genetics, or the collective failure of the out-group\nEx: \u201cAnti-border liberals are of inferior intellect than pro-enforcement Americans\u201d\nPrognostic\nViolence: In-group promotes violent actions toward the out-groupEx: \u201cChoose to be a dangerous man for Christ, wear your cross-hat\u201dHatred: In-group advocates\u2019 protests, criticism, or the show of disdain toward the \nout-group\nEx: \u201cDon\u2019t take feminism or the women who support it seriously. She thinks being \nan obnoxious bitch with a chip on her shoulder is empowerment\u201d\nDiscrimination: In-group promotes avoidance, segregation, or disassociation toward \nthe out-group\nEx: \u201cSeparation of the races is the only perfect preventive of amalgamation\u201dPolicy: In-group suggests formal or hypothetical legislation and promotes politi-\ncal party candidates or other legal measures that would negatively affect the out-group\nEx: \u201c1. Mandatory E-Verify for all the workers hired, 2. No federal funding for \njurisdictions/entities blocking ICE\u201d\nMembership: In-group demands active association, participation in events or funds \ntoward solving the problem\nEx: \u201cJoin us at DC rally in support and solidarity\u201d\nMotivation\nFear: In-group emphasizes on severity and urgency of the problem by mentioning \nexistential or infringement threats\nEx: \u201c There is no way mumps is not being spread outside ICE facilities\u201dEfficacy: In-group emphasizes the effectiveness of the action or the solution pro-\nposed at the individual or organizational level\nEx: \u201cMajor pro-family victory!!! Washington MassResistance strategically helped to \nstop terrible comprehensive sex ed bill\u201d\nMoral: In-group discusses the moral responsibility of the audience for taking the \naction suggested\nEx: \u201cSurvival of people. That is the mission that matters the most\u201dStatus: In-group discusses increased privilege, social class, or benefit from being \nassociated with the in-group or by following the solution provided\nEx: \u201cOur people are destined to have a prosperous future, but only by bearing fruits \nworthy of repentance\u201d\n198 Shruti Phadke and Tanushree Mitra\nRQ1: Identifying Content Framing across Platforms\nIn order to address the question of how hate groups frame content across \nplatforms, sub-samples of the social media postings were annotated with respect to their collective action frames. The annotations applied to 1,440 Facebook posts and 1,440 tweets (approximately 10% of the total), compris -\ning 20 randomly sampled messages from each of the 72 accounts in a pro -\ncedure similar to that of Starbird (2017). The following sections summarize \nresults by each of the three collective action frames.\nHow do Hate Groups Diagnose the Problem?\nOn Facebook, oppression and failure are more popularly used than they are \nin Twitter (oppression: 22% versus 14%; failure: 15% versus 8%). On the other hand, immorality is more commonly used on Twitter than Facebook (27% versus 19%). Immorality frames appeared to be used to educate the audience about the target groups\u2019 stereotypically negative qualities. Derogat -\ning the out-group via immorality frames may also help to reinforce the hate group\u2019s identity (McNamee et\u00a0al., 2010).\nWhat Prognostic do Hate Groups Offer?\nComments that advocated for hatred, violence, or discrimination are more \nextreme, and use extreme language, and as a result such comments are more likely to be removed from the platform by content moderators. For that reason, it was not surprising that on both Facebook and Twitter, hatred, \nviolence, and discrimination subframes were relatively less common. Policy \nframes were more commonly used across Twitter than in Facebook (25% versus 17%). Policy-related comments ranged from demanding a general political action from the President, to signing specific petitions. Membership messages, however, involve calls for direct association with the in-group. Facebook had relatively more membership calls compared to Twitter (29% versus 14%), asking the audience to join events, meetings, and web confer -\nences organized by the group.\nHow do Hate Groups Motivate their Audience?\nFear was the most prominent motivator found on Facebook (27%), followed by status enhancement (11%). Fear appeals describing existential threats \nwere commonly used to motivate like-minded audiences ( McNamee et\u00a0al., \n2010). Fear provides a negative incentive to follow the solution, whereas \nmoral, status enhancement, and efficacy offer positive motivation. Particu-\nlarly, messages with status enhancement and efficacy attempt to maintain a \npositive self-image of the in-group. On Twitter, more messages contained the \nInformation Sharing and Content Framing across Platforms  199\nstatus enhancement category compared to Facebook. Further, other positive \nmotivators (efficacy and moral) were also more frequent on Twitter com -\npared to Facebook. Hate groups often strategically construct messages with self-valorizing views in order to strengthen their group identity ( Duffy, 2003).\nRQ2: Analyzing Information Sharing across Platforms\nIn order to address the second research question, analysis involved examining the nature of the URL links that appeared in the social media messages asso -\nciated with the hate groups. The objective was to categorize the URLs into different types of content they usually host, which can indicate which infor -\nmation gets shared across platforms. After excluding Facebook posts and Tweets that contained links to other posts and tweets within the same plat-form, 12,290 links from Twitter and 11,926 links from Facebook reflected 1,021 distinct information types. In order to identify the type of information shared, we conducted inductive qualitative content analysis to categorize the nature of each URL, based on what content the websites primarily hosted and the descriptions that they provided (i.e., the \u201cAbout Us\u201d or equivalent page of each website). From these numerous content domains, further analy -\nsis organized them into five more meaningful categories: streaming (audio/\nvideo streaming, podcasts, radio shows), promotion (petition sign-ups, mem -\nbership forms, merchandise, and links to various social networks), informa-\ntion (issue-specific news, information watchdogs, reports, and websites of concerned organizations), opinion (commentaries, opinion pieces, and per -\nsonal blogs), and news (online newspapers and general news forums).\nThe findings show that sharing links in their social media postings provides \na sizable opportunity for hate groups to redirect their followers toward their own websites and other extremist blogs. The articles to which links pointed often contained more toxic language and extremist propaganda than is typi -\ncally presented on content-moderated mainstream social media.\nAlmost 50% of the links shared on Twitter led to general news, whereas \nless than 20% of Facebook links did. Instead, Facebook posts hosted more links to focused information websites (37%) and blogs (30%). Often, these domains hosted extreme views. For example, Facebook\u2019s most frequently linked domain, drrichswier.com, is a conservative blog citing Barry Gold -\nwater, saying \u201cextremism in the defense of liberty is no vice and moderation in the pursuit of justice is no virtue.\u201d Similarly, the next most popular links on Facebook pointed to theworldview.com and standinthegapradio.com, \nwhich host radio and talk shows with extremist attitudes. There were many references to right-biased news domains (according to mediabiasfactcheck.\ncom). For example, breitbart.com and frontpagemag.com are extreme right biased, and foxnews.com is far-right biased. Almost 10% of Facebook links fell under the promotion category, hosting links to other social media sites, \n200  Shruti Phadke and Tanushree Mitra\npetitions, and membership forums, and promoting online merchandise. Links \nto various streaming websites, although present, were less popular in both Twitter and Facebook.\nRQ3: How Framing and Information-Sharing Differ across  \nIdeologies and Platforms\nInvestigating the nuances of framing and URL-sharing within individual ide-\nologies took into consideration the Facebook and Twitter frames annota-tions. Combined with the types of information links, the research developed \u201cdomain networks\u201d: Graphs representing URL content domains co-shared within and across platforms. A\u00a0domain network graph depicts URL domains where every domain constitutes a network node, connected to other nodes based on some predetermined criteria, such as number of common users and frequency of sharing. Previous research employing domain network graphs depicted the ecosystem of alternative news domains on Twitter ( Starbird, \n2017). Our research connected two domains (i.e., nodes in a graph) if they were shared by a hate group account, with edge weights representing the number of accounts that shared them.\n2 Visualizations of domain co-sharing \n(i.e., shared only on Twitter, only on Facebook, or shared on both plat-forms) by the various ideologies\u00a0\u2013 White Supremacy, anti-Muslim, Religious \nSupremacy, anti-LGBT, and anti-Immigration\u00a0\u2013 appear in Phadke and Mitra \n(2020), with specific examples illustrating how the processes differed between every ideology. The findings regarding collective action content framing and website content/information sharing for two of those five ideologies\u00a0\u2013 White \nSupremacy and anti-LBGT\u00a0\u2013 follow.\nWhite Supremacy\nContent Framing: On both Facebook and Twitter, White Supremacy groups frequently discussed racial and political issues. However, their diagnostic and prognostic discussions varied. On Facebook, they complained how white culture is being oppressed (17.8%), for example, \u201cIf White Genocide is an unfounded conspiracy, why is it so heavily censored and suppressed?\u201d On Twitter, messages primarily described how people of other races are immoral (17.64%) and inferior (16.2%), for example, \u201cby debasing themselves they are acting entirely within their class interest retaining the very privilege they are criticizing.\u201d Messages advocating discrimination (4%), hatred (2%), and \nviolence (2%) appeared only on Facebook, for example, \u201cSay \u2018no\u2019 to their way of dress, \u2018no\u2019 to their entertainment, \u2018no\u2019 to their degenerate culture. To love all equally is not to love at all.\u201d Concerning motivational categories, Facebook had more fear appeals (14%), for example, \u201cWhen America is \nno more, future generations are going to want to know who murdered our country,\u201d while Twitter contained more status enhancement (21.5%), for \nInformation Sharing and Content Framing across Platforms  201\nexample, \u201cReview: On Edward Dutton\u2019s RACE DIFFERENCES IN ETH -\nNOCENTRISM\u00a0\u2013 And Why White Ethnocentrism Will Return.\u201d\nInformation Sharing: A\u00a0 mix of news sources, from alternative (rt.com, \nbreitbart.com) to mainstream (nytimes.com), was prominently shared on \nTwitter (57%), whereas on Facebook there were more links to promotion \ndomains (35%), such as those offering subscriptions to content creators\u2019 crea -\ntion. Among these, Patreon.com and Subscriberstar.com are known to house extreme right-wing activists ( Coulter, 2018). Other promotion domains \ninclude foreign and U.S. websites that host extremist books and literature (e.g., logik.se, kirkusreviews.com) and talk shows (thepoliticalcesspool.org). There were also links pointing to other social media platforms (gab, tele-gram, bitchute) emanating across both Twitter and Facebook. In the light of recent censorship of white nationalism on Facebook ( Facebook, 2019), white \nsupremacy hate groups seem to adapt by moving their online operations to alternative platforms that champion free speech and little content modera-tion (see also Walther, this volume). Figure\u00a0 9.1 portrays information shared \nwithin and across both platforms.\nAnti-LGBT\nContent Framing: On both Facebook and Twitter, anti-LGBT groups dis -\ncussed sexual and gender identity the most. However, there appeared rela -\ntively more discussions focused on the immorality of LGBT life on Twitter \nFIGURE\u00a0 9.1  Information-Sharing Network by White Supremacy Groups\n202  Shruti Phadke and Tanushree Mitra\n(34%). Facebook postings discussed how the LGBT agenda oppresses peo -\nple with traditional values (23%), for example, \u201cThis legislation is specifi -\ncally designed to place \u2018sexual liberty\u2019 above \u2018Religious Liberty\u2019 and our First \nAmendment civil rights!\u201d Similarly, there are more calls for membership \non Facebook (37%) to join anti-LGBT groups in their rallies and seminars: \u201cCome and meet like-minded people that are concerned about our coun -\ntry. We want to restore honor, respect, civility, and hope for our children\u2019s future.\u201d Twitter hosted more demands for changes in policy through general \nsocial action (24%), for example, \u201cThe work we have to do is clear. We must train people to make them active in establishing a godly society, and that takes work, sweat, sacrifice.\u201d Twitter messages also promoted the efficacy (18%) of anti-LGBT policies and heightened social status (19%) achieved by \nfollowing them: \u201cTexas MassResistance pressure causes pro-LGBT church to cancel Drag Queen reading in public library. Antifa backs down! Another big win!\u201d Facebook, however, mostly contained messages motivating by fear, \nwarning about the effects of LGBT lifestyle on child development, religious liberty, and society (29%), for example, \u201cIf the \u2018Equality Act\u2019 becomes law, women and girls would instantly forfeit equality rights and opportunities gained over decades.\u201d\nInformation Sharing: Similar to other hate ideologies, anti-LGBT \naccounts also shared more news on Twitter (54%) compared to Facebook \n(34%). However, Facebook contained more links to opinion blogs (12%) and informational forums (26%) (e.g., resources for parenting such as \nfatherly.com, dadsguidetowdw.com, childdevelopmentinfo.com) compared to Twitter. Like the Religious Supremacy accounts, links to several websites in the promotion category host petitions (e.g., endbirthdayabortion.com, focusonthefamily.com).\nDo Hate Groups Use Facebook and Twitter Differently?\nIt does appear that hate groups used the two platforms differently. Generally, they used Facebook to radicalize an already like-minded audience and used Twitter to educate a more ideologically diverse set of followers. On Face -\nbook, fear was prominent as a motivating agent, a strategy that is common \namong hate groups to strategically recruit like-minded people (McNamee et\u00a0al., 2010). Further, hate groups claimed to be oppressed, and they issued calls for membership, at a higher rate on Facebook compared to Twitter. On Twitter, hate groups\u2019 messages often focused on the out-groups, portraying them as immoral or inferior. This is a common strategy to imbue deliberate, \nnegative perceptions of the out-group, regardless of how inaccurate or dis -\ntorted those are (McNamee et\u00a0al., 2010).\nThe analyses suggest that hate groups use social media platforms to pur -\nsue different goals in furtherance of their extremist agenda: Radicalization/recruitment and education/image control. Radicalization is associated with \nInformation Sharing and Content Framing across Platforms  203\nbeliefs like being oppressed, suffering from failure of the system, or fear \nof extinction (McCauley\u00a0& Moskalenko, 2008; see also Kruglanski et\u00a0al., \n2014). This rhetoric of oppression-failure-fear appeared to be more fre -\nquent on Facebook than on Twitter. Moreover, Facebook had more calls for membership and links to personal mailing lists and recruitment forums. The Facebook audience of hate group members or prospective members might be more susceptible to extremist radicalization and successful recruitment, compared to Twitter. Hate groups used Twitter predominantly to share news from various news media. Hate groups spread negative news that addressed (educated) the problems associated with the out-groups and that stressed positive aspects (image) of themselves (Douglas, 2007; Gerstenfeld et\u00a0 al., \n2003; McNamee et\u00a0 al., 2010). They dehumanized out-groups by describ-\ning them as inferior or immoral, while presenting themselves with a positive image through status enhancement and effectiveness (efficacy) of their pro-\nposed solutions (e.g., \u201cdoing the god\u2019s work in fighting the LGBT mafia\u201d).\nCharacterizing Roles and News Sources in Online  \nExtremist Movements\nIn addition to the extremist content stemming from the social media accounts \nof established extremist organizations, the landscape of online hate extends far beyond these sources. The participatory nature of social media encourages users to contribute to the dissemination of extremist information through sim -\nple actions such as liking and sharing content. Moreover, the nature of partic -\nipation in online movements could be organic, with the users being unaware of the fact that they may be advancing an extremist movement. Therefore, to gain a deeper understanding of the participatory information-sharing dynam -\nics within online extremist movements, research has endeavored to charac -\nterize various social roles that emerge within Facebook groups that espouse extremist ideologies, helping to understand the ecosystem of online hate.\nA Facebook group is created by a number of Facebook users who establish \na closed interaction space\u00a0\u2013 that is, one that can be made available to specific members that the organizers invite and/or approve but is unavailable to the Facebook public (Facebook, 2023). According to the Southern Poverty Law Center, Facebook groups serve as the primary avenue for extremists to recruit new members and spread extremist propaganda ( Hatewatch Staff, 2020). By \nsharing links from the websites of known extremist organizations, extrem -\nist groups and extremist accounts become participants in the extremist eco -\nsystem on Facebook and operate as key players in sustaining and growing extremist movements.\nYet, not all groups and participating members are the same. In order to \ndevelop a better-informed assessment of the contributions they make to hate in social media, research examined how U.S.-based extremist accounts played different social roles in advancing extremist movements online. The \n204  Shruti Phadke and Tanushree Mitra\nstudy involved records from 4,876 extremist accounts that shared links from \n289 SPLC-designated extremist groups, data that were obtained using Face -\nbook\u2019s CrowdTangle API. Our study labels Facebook groups and pages as extremist accounts based on the general content shared by such groups and accounts. Further, the research described deduces roles played by Facebook groups and pages, and the roles\u2019 dynamics and influence, to understand the online participatory ecosystem of hate.\nParticipatory Activism and Extremist Movements\nPrevious research presents opposing perspectives on the effectiveness and the legitimacy of using the web and social media to encourage participation in social movements and activities. The terms \u201cclicktivism\u201d and \u201cslacktivism\u201d refer to users\u2019 superficial engagement in political action through low-cost activities such as liking or sharing the content in order to raise awareness (Rotman et\u00a0al., 2011; Vromen, 2017). Writers on popular press comment that \n\u201cclicktivism\u201d or \u201cslacktivism\u201d is largely unproductive and ephemeral\u00a0\u2013 an ideal type of activism for a lazy generation ( Gladwell, 2010; Morozov, 2009; \nWiebe et\u00a0al., 2005 ). However, communication and political science scholars \nargue that such low-cost and low-risk participation is not only widespread but is also becoming a legitimate channel for political activism ( Halupka, \n2018). Specifically, Obar et\u00a0 al. (2012) interviewed advocacy groups and found that all the groups viewed online participation as an effective tool for civic engagement and collective action.\nResearchers have mostly investigated participatory activism in the context \nof positive social change (see, e.g., Arda, 2015; Keller, 2012; N\u00fa\u00f1ez Puente \net\u00a0al., 2017; Rahimi, 2016), empowering populations in social justice causes. \nHowever, antisocial movements, for example those advocating for terrorism and extremism, can also benefit from similar practices. Researchers have pro-posed a variety of theoretical roles that members may adopt in social move-ments (e.g., Edwards\u00a0& McCarthy, 2004 ; McCarthy\u00a0& Zald, 1977 ; Owen, \n2019; Turner, 1969; Wahlstr\u00f6m et\u00a0al., 2018). What are the different roles \nplayed by extremist accounts in extremist social movements? How stable or transitory are these roles? And how influential are these roles in spreading mis- and disinformation? The research specifically focused on U.S. domestic extremism, such as White Supremacy and anti-LGBT movements (analyzed above) to identify a variety of roles through the lens of social movement theories.\nExtremism, Social Movements, and Roles\nSocial movements are collective efforts to bring about a specific goal or ide -\nology, and they emerge when the constitution and function of society are \nInformation Sharing and Content Framing across Platforms  205\nmisaligned with the movement\u2019s goals ( McCarthy\u00a0& Zald, 2003 ). By this \nlogic, extremist movements such as white supremacy become more active and \naggressive when there is an increased racial diversity in the society ( Zald\u00a0& \nAsh, 1966).\nIt is difficult to adopt directly the theoretical taxonomies of roles in the \nliterature cited above to the context of online extremist movements, as the roles are based on physical social movement participation and commitment (Owen, 2019; Rodan\u00a0& Mummery, 2017; Wahlstr\u00f6m et\u00a0al., 2018), unlike \nonline participation. Consequently, drawing on taxonomies and theories of social movement participation, this research derived a new taxonomy of roles for the online setting: Solicitors, Educators, Flamers, Motivators, and \nSympathizers. Before discussing the constellations of behaviors that typify each role, the next paragraph summarizes the processes used to identify these roles. In order to identify roles in the extremist movements, the research drew on theories in social movement participation, which suggested three basic dimensions to investigate: Drives for participation, engagement in the move -\nment, and strategies of mobilization . These three dimensions, and the com -\nputational features derived from them, formed the crux of the methodology for identifying roles in the extremist movements. Phadke and Mitra (2021 ) \nprovide succinct literature and conceptual reviews of the three dimensions and related models. The first two columns in Table\u00a0 9.2 summarize several \nrelevant theoretical models, with central citations in the third column, and associated behaviors in the fourth column. The next step was to identify how occupants of these roles disseminate different types of information, such as extremist content, fake news, biased news, and conspiracies.\nThe analysis of roles involved extremist accounts\u00a0\u2013 public Facebook pages \nand Facebook groups that share links pointing to extremist websites. The analyses also involved verifying the extremist websites; there were 289 web -\nsites hosted by extremist groups as denoted by the SPLC. For each website, they also note the extremist domain ideology type, such as anti-Immigration, \nReligious Supremacy, anti-Muslim, White Supremacy, and anti-LGBTQ ide-\nologies. Analyses also involved parsing the sample of accounts into those that shared a significant number of links over time, and then content analyzing the posts to classify them as extremist, biased, fake news, or conspiracy-oriented. The sample contained 450,000 posts, as generated by 71,430 unique Face -\nbook pages or group accounts. Further limiting the sample to those accounts that shared at least ten messages with links to an extremist website domain, the final number was 4,876 Facebook pages/groups (see Table\u00a0 9.3 for descrip -\ntive statistics).\nFinally, the data were reviewed for interpretive analysis by seven social \npsychology and social movement experts not related to the project. These experts labeled the roles and their descriptions. The author and the experts worked together to select the most descriptive label for every cluster of roles \n206  Shruti Phadke and Tanushree MitraOperationalization\n% LIWC achievement words \nlinks posts per month\nProportion of extremist link posts containing \n-% LIWC risk words (e.g., caution, crisis, \naward)\n% MFD fairness words (e.g., parity, fair, \n failure)\n% LIWC reward words (e.g., benefit, bonus, \njustice)\n(e.g., accomplish, ability, attain)\n% LIWC we words (e.g., we, ours, us)% LIWC anger words (e.g., resent, argue, \nangry)\nRatio of links from extremist domains to total \nlink posts\nRatio of links from extremist domains to total \nlink posts\nProportion of likes on extremist links to likes \non the rest of the link posts\nProportion of comments on extremist links to \ncomments on the rest of the link posts\nrend line fitted on the number of extremist \nopinion patterns; based on % LIWC think\ning, perception, expression words\nProportion of extremist link posts containing \nsolicitation patterns (donations, invitations, policy advocacy words, based on % LIWC social and affiliation words)TFeatures Used to Identify Roles in Online Extremist Movements on Facebook\nBehavior\nRisk\nRewardInjusticeAchievementGroup IdentityAnger% links from \nextremist domains\nLikesSharesComments\nrend\nExpressions of \nopinions\nExpressions of \nsolicitationTan Stekelenburg\u00a0& \nMcCarthy\u00a0& References\nKlandermans, 1984; \nood, \n1975; Oberschall, \nKlandermans, 2013b\nGamson, 1992; 22\nSimon\u00a0& Klandermans, \n  Marx\u00a0& W1973\n2001V\nan Stekelenburg\u00a0& \nKlandermans, 2017\nZald, 1977\nMcCarthy\u00a0& \nZald, 1977VMcCarthy\u00a0& \nCorrigall-Brown, 2011\nalenzuela, 2013V\nBromley\u00a0& Shupe, \n1980; \nZald, 1977Theoretical Models\nExpectancy-value\nSocial psychology\nDegrees of participation\nDegrees of participation(popularity)\nTrends in participation\nOpinions\nSolicitation  \n9.2 ABLE\u00a0\nparticipation\nEngagement in\nmobilizationT\nCharacteristics \nof Participation\nDrives for\nthe movement\nStrategies of \nInformation Sharing and Content Framing across Platforms  207\nTABLE\u00a09.3   Descriptive Statistics for the 4,876 Extremist Accounts in the Dataset\nStatistics  Min Max M SD\n(Per Account)\nPosts 71 932K 7,067 30,574\nLink posts 23 78,571 1,614 3,915\nExtremist link posts 10 5,129 207 528\nEngagement\nPage likes 206 1.8 M 7,241 36,576\nGroup members 35 2.2 M 2,827 13,603\nand associated behaviors. Table\u00a0 9.4 presents the five roles played by extrem -\nist accounts and their typical behaviors.\nSolicitors\nThese are the accounts that solicit participation from their readers for sign -\ning petitions, attending rallies, etc. On average, around 20% of their links \ncame from extremist domains, and users posted extremist content fairly TABLE\u00a09.4   Roles and the Corresponding Percent of Extremist Accounts in the Dataset\nRole % Frequency Example Texts Used by the Accounts While \nSharing Links from Extremist Websites\nSolicitors  5.2% \u201cSign here to demand her {Rep. Maxine Waters} \nimmediate resignation\u201d\n\u201cJoin us in signing thank you card for President \nTrump\u201d\nEducators 10.6 \u201cEscaping from motherhood: how it destroys \nsociety\u201d\n\u201cWe believe that we have the duty to instruct peo-\nple in the truth of Tradition. Even if it destroys their party\u201d\nFlamers 18.4 \u201cGenuine Christians know that homosexuality is \nan abomination before GOD!\u201d\n\u201cMURDERED in cold blood. Emergency: Gunfire, \nbodies, and BLM murderers\u201d\nMotivators 29.4 \u201cSenator Dan Halls stands with us in a passionate \ncommitment to strengthening religious freedom\u201d\n\u201cFREE SPEECH WINS!!! Supreme court rules \npregnancy centers can\u2019t be forced to advertise abortion\u201d\nSympathizers 36.4 \u201cWhite South Africans petition Trump to allow \nthem to migrate to the US\u201d\n\u201cA jihadi cult member running for Congress as \nDemocrat from Alaska\u201d\n208  Shruti Phadke and Tanushree Mitra\nconsistently over time. These accounts frequently used group identity lan -\nguage such as \u201cwe,\u201d \u201cour,\u201d and \u201cus,\u201d compared to other roles. One expert \nanalyst mentioned: \u201cThese groups appear to be soliciting action for their hate. To some extent, they seem pretty keen on motivating action against the groups they hate.\u201d\nEducators\nEducators have a distinctively high amount of extremist content in their link sharing. On an average, 50% of their links came from extremist domains. Additionally, the extremist links posts received more likes and comments compared to other material on these pages/groups. They posted the extrem -\nist content with consistently high rates over time. According to one expert analyst, \u201cthey seem to take effort to make logical arguments. They are not necessarily showing anger toward other groups but are instead more focused on highlighting their own group\u2019s worth logically/analytically.\u201d\nFlamers\nThese accounts tended to spew toxic and inflammatory content. Around 5% of their links belonged to extremist web domains, and the messages on the links and the link text itself often contained language suggesting anger and injustice. The extremist links posted on these accounts got a higher num-ber of shares compared to the rest of the content. Immediately after looking through the posts, one evaluator commented, \u201cThese are clearly very strong, divisive and toxic posts.\u201d\nMotivators\nAround 7% of the links by motivators were from extremist web domains. The expert analysts pointed out that motivators used exceptionally positive language. While posting extremist content, they emphasized the achievements and rewards associated with extremist activities and exhibited the highest proportions of opinions. Experts noted that these accounts engaged in policy activism focusing on policies protecting and defending cultural and moral values. Experts also mentioned, \u201cIt almost looks like they are celebrating the in-group (people and organization involved in the extremist movement) and the sensationalized news about the in-group.\u201d\nSympathizers\nThese accounts posted extremist content links at the lowest rates (2% of their Facebook link posts) and sporadically over time. They also showed low \nInformation Sharing and Content Framing across Platforms  209\nengagement in terms of likes, shares, and comments on the extremist link \nposts. According to the experts, these groups were on the fringe of extremist ideology and might have been only slightly interested in extremist causes. One expert described sympathizers by saying, \u201cThey look more like general conservative interest groups.\u201d\nRelations and Information-Sharing Influence among Roles\nAlthough they tend to exhibit certain distinct clusters of activities and func -\ntions within the online presence of their respective hate groups, these roles are not isolated from each other. Indeed, additional modeling revealed how influential the different roles are in spreading extremist content, fake news, biased news, and conspiracy sources. Influence in this case refers to a meas -\nurable probability that a link posting by an occupant of one role affects a link posting by members of other roles in the future. An example of how different roles behave and influence one another appears in the case of an anti-immigration organization\u2019s effort to affect regional legal matters.\nOn June 10, 2018, ALIPAC\u00a0\u2013 an anti-immigration political action organi-\nzation (Shanmugasundaram, 2018)\u00a0\u2013 put out a call for action to stop the amnesty deal for immigrants in California. This included calls for donations and participation to help support ALIPAC\u2019s operational costs. A\u00a0link pointing to this call for action was posted on Facebook on the same day at 9:59 PM by a verified page managed by the president of ALIPAC. This Facebook page was also known for posting fake news from websites hosting plagiarized con -\ntent (Kaplan, 2018). The analysis suggests that the poster is a solicitor. Three \nminutes after the initial post by page 1, another Facebook page\u00a0\u2013 identified as flamer\u00a0\u2013 posted the same link. Following the post by page 2, a sympathizer \npage (fringe supporter of the extremist content) as well as another recruiter page also posted the same link. Following these four link posts, another 32 pages posted the same link containing the anti-immigration group\u2019s call for action over the next three days.\nThe degree of cross-role influence can be seen against the baseline rates \nat which different roles tend to generate link postings for each type of infor -\nmation. Table\u00a0 9.5 summarizes these base rates. Looking at the number of \nevents, sympathizers made up the largest percent of link-posting events of \nall types of sources. This is not surprising, given that 36.4% of the accounts were sympathizers. Along the same lines, solicitors (who actively solicit par -\nticipation by posting extremist links) and educators (who share the larg-\nest proportion of extremist links) contributed to a high percent of posting extremist links. Interestingly, flamers (accounts that often post inflamma-tory and violent content) were also among the highest in posting links from the fake news sources. Moreover, motivators (who focus on the efficacy of \npolicy changes and use opinionated language) generated 23% of the biased \n210 Shruti Phadke and Tanushree Mitra\nnews postings. Educators, solicitors, and motivators all posted links from \nconspiracy sources with similar rates, while flamers posted the fewest and \nsympathizers the most.\nAnalysis of the relative influence attributed to posts from these different \nrole occupants showed that some roles were more influential than others. Of the 289 extremist website domains that verifiably were linked by Facebook posts, solicitors and educators posted the largest proportion of links. How -\never, solicitors and educators also generated significant influence on other roles, triggering the spread of extremist content by others. Among other roles, flamers generated greater influence than motivators and sympathiz -\ners. Overall, solicitors, educators, and flamers were the most influential in spreading links from extremist sources.\nTypes of News Sources Shared among Roles\nThat said, there were differences between roles in terms of the kind of linked information each role was more or less likely to share and the influence that sharing those information types had on occupants of other roles. A\u00a0more fine-grained picture of information-sharing and influence emerges when different kinds of news sources are examined distinctly from one another. Additional analyses drew on the analytic typology provided by the Rand Corporation\u2019s \u201cOpenSources\u201d classifications,\n3 and evaluations of particular \nnews sites by mediabiasfactcheck.org, which describe the particular kinds of information distortions\u00a0\u2013 biased, fake, and conspiratorial\u00a0\u2013 associated with specific news sources.\nBiased Sources\nBiased news sources not only hold a very specific point of view but also pre -\nsent propaganda, decontextualizing information, and opinions as though they are facts. For example, 100percentfedup.com presents stories with extreme right-wing bias, and dailywire.com is strongly biased toward conservative TABLE\u00a09.5   Link Posting Activities by Various Roles\nSource #Domains #Labeled #Events % Link Posts Made By\nType Labeled domains (Link \nSolicitors Educators Flamers Motivators Sympa-Present Posts)\nthizersin T1\nExtremist 289 231 758 12% 28  9  5 44\nBiased 133 94 1279 11  9 19 23 36\nFake 304 107 380  9 20 23 13 34\nConspiracy 154 68 936 20 20 10 21 29\nNote: Example\u00a0\u2013 solicitors contribute to 12% of the link posts from the extremist domains.\nInformation Sharing and Content Framing across Platforms  211\ncauses and/or political affiliation. Overall, the influence of all roles was rela -\ntively lower when sharing links from biased sources. However, in comparison \nto other roles, motivators were more influential in triggering other roles to \nshare information from biased sources.\nFake News Sources\nFake news sources fabricate information or grossly distort actual news \nreports. Flamers frequently posted links that were flagged as fake/misinfor -\nmation by Facebook fact checkers, possibly with the intention of spreading hate and outrage. Both educators and flamers had greater influence on solici-\ntors in spreading links from fake news sources than the other three roles. However, fake news sources had the lowest number of links and link posting events among all source types.\nConspiratorial Sources\nSympathizers were most influenced by conspiracy information from solici-tors and educators, while flamers were susceptible to conspiratorial informa-tion sharing by motivators.\nDiscussion and Implications\nFor those who object to and detest online hate and extremism, it can be easy to view their perpetrators monolithically. Through their own in-group/out-group perspective, there is an us and a them, and in-group members may \nconsider them to be undifferentiated \u201cbad actors,\u201d bigots, or as some other \ncategory among whom there is no need to see any difference in who they are or what they do. This is not to argue that their objectives and behaviors are not objectionable or repugnant. In order to advance our understanding of how online hate operates, and the social processes that facilitate its propaga -\ntion, it is important to recognize that participants in these online movements do different things by different means and that these differences are not ran -\ndom but rather are systematic social processes, involving collective action frames (diagnostic, prognostic, motivational), content domains (streaming, promotion, information, opinion, news), roles (solicitor, educator, flamer, motivator, sympathizer), information sharing (such as biased, fake, or con -\nspiratorial sources), and interactions among all of these.\nInter-Platform Content Framing and Information Sharing\nUnderstanding the patterns of the extremist dark side of social media in gen -\neral leads to meaningful inferences about antisocial behavior, some of which may lead to offline violence (The Telegraph, 2015). Yet, failing to discriminate \n212 Shruti Phadke and Tanushree Mitra\nbetween different social media platforms is to ignore how hate groups envi -\nsion and exploit them.\nFrames, Content Domains, Roles, and New Sources\nThe first part of this chapter summarizes analyses applying collective action \nframes and shared links. By annotating the collective action frames embed -\nded in Tweets and Facebook posts, as well as the links from these messages to other sites and services, research can refine the theoretical understanding of the hate groups\u2019 actions online. Scholars studying collective action fram -\ning state that messages rich with frames have a strong mobilizing potential (Snow\u00a0& Benford, 1988 ). Such messages combined with information from \nvarious biased news sources, informational guides, and blogs can make for influential narratives of online hate.\nThe second part of the research summarizes our research on the identifica -\ntion of five functional roles ( educators, solicitors, flamers, motivators, and \nsympathizers) in online extremist movements, and the differences between these roles in their influence in spreading links from four types of news sources (extremist, biased news, fake news,  and conspiracy). As part of a \nlong-standing approach to social movements of many kinds, scholars have connected the advancement of movements to the successful distribution of resources through its participants ( McCarthy\u00a0& Zald, 1977). Similarly, the \noperators of extremist accounts, enacting various roles, use social media to distribute information resources. For example, educators and solicitors dedi-\ncate a large proportion of their Facebook activity to distributing extremist content for educating and soliciting the readers into extremist movements. They also influence other roles in spreading information from extremist websites. By disseminating information through their Facebook accounts, attempting to educate readers about their agenda, and soliciting funds and participation in the movements, educators and solicitors create human and material resources (see McCarthy\u00a0& Zald, 1977). By prominently sharing \nmisinformation and using toxic language, flamers arouse emotional resources that create opportunities for public outrage and, eventually, collective action (Van Stekelenburg\u00a0& Klandermans, 2017 ) to advance the hateful agendas \nof their extremist movements. This distributed system of online information mobilization\u00a0\u2013 the distribution of various information resources through var -\nious roles online\u00a0\u2013 can be compared to the process of participatory activism (Krona, 2019).\nTheoretical Implications: Parallels between Theoretical  \nand Online Roles\nSome of the roles uncovered in this research correspond to the categories of \nparticipants identified in theoretical analyses of physical protest events and \nInformation Sharing and Content Framing across Platforms  213\nsocial movements, with some important exceptions. For example, the edu-\ncators\u00a0\u2013 accounts that primarily focus on distributing links from extremist \ndomains\u00a0\u2013 seem to correspond to constituents, as described by McCarthy and \nZald (1977); constituents are primary distributors of resources. Similarly, solicitors\u00a0\u2013 who actively solicit participation via donations and gatherings\u00a0\u2013 correspond to beneficiary constituents (McCarthy\u00a0& Zald, 1977) who stand to gain from the success, funds, and connections emerging from the move -\nment. The sympathizers\u2019 category may be similar to bystanders\u00a0\u2013 a group \nof third-party participants, as defined by Turner (1969)\u00a0\u2013 who acknowledge \ngrievances related to the issues of social movement and take a sympathetic stand. Two of the roles discovered to exist in online hate, however, do not resemble any of the theoretically described categories of prior, offline protests and movements. The motivator role seems specifically suited to the online set -\nting, relaying positive news and successes related to extremist causes. Flamers \nalso do not correspond to prior theoretical roles. The emergence of these new roles that characterize online participation in extremist social movements extends previous theories to incorporate the relatively novel social processes embedded in and facilitated by social media.\nPractical Implications: Interventions for Online  \nExtremism Engagement\nThe research reported here can also inform the design of interventions for \ncountering extremism. Our results suggest that while account roles core to the extremist movements\u00a0\u2013 educators and solicitors\u00a0\u2013 tend to retain their roles, others are more likely to transition to different roles. For example, flamers and motivators become sympathizers with high probability. Flam -\ners, motivators, and sympathizers also show more sporadic engagement with sharing extremist links compared to the educators and solicitors. A\u00a0study by Siegel and Badaan (2020) revealed that targeted interventions \nagainst hate speech, such as sanctions on hateful messages, lead users to tweet less hateful content, especially if the individuals are less engaged with the hate speech in the first place. On the other hand, accounts that fre -\nquently see or produce hostile language are less likely to get deterred by sanctions and may even express backlash. Other researchers report that rather than conforming to the community norms upon receiving sanctions, the producers of hostile content are more likely to move to other platforms (Newell et\u00a0al., 2016 ; see also Walther, this volume) or find creative ways of \ncontinuing their hate speech ( Chancellor et\u00a0al., 2016 ). Considering this, our \nresults suggest that flamers, motivators, and sympathizers\u00a0\u2013 accounts infre-quently exposed to extremist content\u00a0\u2013 might benefit most from targeted interventions designed to counter extremism. On the contrary, educators and solicitors may retaliate or relocate to alternate platforms in response to an intervention.\n214 Shruti Phadke and Tanushree Mitra\nLimitations\nThis research has some limitations that are important to acknowledge. First, \nthe dataset contained only U.S.-based extremist websites, most of which hold a far-right political ideology. This skew may not represent the political scenarios of other countries (e.g., Counter Extremism Project, 2020; Jun-\ngkunz, 2019). Second, it compiled extremist accounts based on the number of unique links they shared from known SPLC-designated extremist websites. While this is a common methodological choice made while choosing users/accounts for studying social media activity, there are reasonable alternatives. Extremist accounts can be selected on the basis of the topics discussed in the posts or on other criteria. Third, observations about the influence of various roles in spreading information on Facebook were based on the posting of links to other websites. This approach does not account for other modes of information sharing, such as images, memes, screenshots, videos, and other forms, and how those might affect role dynamics.\nFuture Directions\nDespite these limitations, this research reveals the information ecosystem of extremist movements among Facebook and Twitter in the first part of this chapter, and on Facebook in the second part. Indeed, extremist movements leverage different social media platforms toward different goals, and it is hoped that future research may extend the methods and findings described herein to extremist movements on other platforms or even across platforms. Future research using cross-platform studies of both content and informa -\ntion\u00a0\u2013 such as the work reviewed in this chapter\u00a0\u2013 may provide insights for building automated or semiautomated tools to detect potentially mobilizing hate narratives online.\nConclusion\nThe social processes associated with participatory activism seem to be advanc -\ning extremist movements through various collective action frames, website content types, account roles, and types of information shared. The existence of roles and the variegated patterns of influence they exert clearly demon -\nstrates that there is a social order to online hate, involving a variety of social processes. Different kinds of actors do not draw in an unintentional man -\nner from some undifferentiated black box of hate messages. They manifest social goals and objectives through a variety of social activities. Their aims, at least in the short run, have less to do with accomplishing real-world action but, rather, to educate, motivate, participate, and orchestrate the evolution of their social movement itself. That is, their efforts are both manifestations of, \nInformation Sharing and Content Framing across Platforms  215\nand efforts directed toward, the social processes that enable the expression \nand propagation of online hate.\nNotes\n 1 This chapter integrates three related publications: Phadke and Mitra (2020 , 2021) \nand Phadke et\u00a0al. (2018), which provide extensive analytical and methodological \ndetails.\n 2 Removed from further analysis were edges with weights less than 2 and nodes \nthat were shared fewer than five times or were connected with less than two other \nnodes.\n 3 https://www.rand.org/research/projects/truth-decay/fighting-disinformation/search/items/opensources.html\nReferences\nArda, B. (2015).  The construction of a new sociality through social media: The case of \nthe Gezi uprising in Turkey. Conjunctions: Transdisciplinary Journal of Cultural \nParticipation, 2(1), 72\u201399. https://doi.org/10.7146/tjcp.v2i1.22271\nAuger, G. A. (2013). Fostering democracy through social media: Evaluating diametri-\ncally opposed nonprofit advocacy organizations\u2019 use of Facebook, Twitter, and YouTube. Public Relations Review, 39(4), 369\u2013376. https://doi.org/10.1016/j.\npubrev.2013.07.013\nBeirich, H.,\u00a0& Buchanan, S. (2018).  2017: The year in hate and extremism . Techni-\ncal Report. Southern Poverty Law Center. https://www.splcenter.org/fighting-hate/\nintelligence-report/issues/2017-spring-year-hate-extremism\nBenford, R. D.,\u00a0& Snow, D. A. (2000).  Framing processes and social movements: An \noverview and assessment. Annual Review of Sociology , 26(1), 611\u2013639. https://\ndoi.org/10.1146/annurev.soc.26.1.611\nBoydstun, A. E., Card, D., Gross, J. H., Resnik, P.,\u00a0& Smith, N. A. (2014, August).  \nTracking the development of media frames within and across policy issues . Ameri-\ncan Society for Public Administration Annual Meeting.\nBozarth, L.,\u00a0& Budak, C. (2017).  Social movement organizations in online move -\nments. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3068546\nBromley, D. G,\u00a0& Shupe Jr., A.D. (1980).  Financing the new religions: A\u00a0resource \nmobilization approach. Journal for the Scientific Study of Religion , 19(3), 227\u2013239.\nBurston, A. (Chapter\u00a0 2 this volume). Digitally mediated spillover as a catalyst of \nradicalization: How digital hate movements shape conservative youth activism.\nChancellor, S., Pater, J. A., Clear, T., Gilbert, E.,\u00a0& De Choudhury, M. (2016, Feb -\nruary). #thyghgapp: Instagram content moderation and lexical variation in pro-eating disorder communities. In Proceedings of the 19th ACM conference on computer-supported cooperative work\u00a0& social computing  (pp.\u00a01201\u20131213). \nACM. https://doi.org/10.1145/2818048.2819963\nChau, M.,\u00a0& Xu, J. (2007). Mining communities and their relationships in blogs: \nA\u00a0study of online hate groups. International Journal of Human-Computer Studies , \n65(1), 57\u201370. https://doi.org/10.1016/j.ijhcs.2006.08.009\nCorrigall-Brown, C. (2011).  Patterns of protest: Trajectories of participation in social \nmovements. Stanford University Press.\nCostello, M., Hawdon, J., Bernatzky, C.,\u00a0& Mendes, K. (2019). Social group identity \nand perceptions of online hate. Sociological Inquiry, 89(3), 427\u2013452. https://doi.\norg/10.1111/soin.12274\n216 Shruti Phadke and Tanushree Mitra\nCoulter, M. (2018, December).  PayPal shuts Russian crowdfunder\u2019s account after \nalt-right influx. Financial Times. Retrieved September 13, 2019, from https://\nwww.ft.com/content/7c4285b2-fe2f-11e8-ac00-57a2a826423e\nCounter Extremism Project. (2020).  Germany: Extremism\u00a0 & counter-extremism . \nCounter Extremism Project. Retrieved January 14, 2021, from https://www.counter \nextremism.com/countries/germany\nDonovan, J. (2019, March 17). Extremists understand what tech platforms have built. The \nAtlantic. Retrieved September 11, 2019, from https://www.theatlantic.com/ideas/\narchive/2019/03/extremists-understand-what-tech-latforms-have-built/585136/\nDouglas, K. M. (2007). Psychology, discrimination, and hate groups online. In A. \nJoinson, K. McKenna, T. Postmes,\u00a0& U.-D. Reips (Eds.), The Oxford handbook \nof internet psychology (pp.\u00a0155\u2013163). Oxford University Press.\nDuffy, M. E. (2003).  Web of hate: A\u00a0fantasy theme analysis of the rhetorical vision of \nhate groups online. Journal of Communication Inquiry , 27(3), 291\u2013312. https://\ndoi.org/10.1177/0196859903252850\nEdwards, B.,\u00a0& McCarthy, J. D. (2004).  Resources and social movement mobiliza -\ntion. In D. A. Snow, S. A. Soule, H. Kriesi,\u00a0& H. J. McCammon (Eds.), The Black-\nwell companion to social movements (pp.\u00a0116\u2013152). Wiley Blackwell.\nEntman, R. M. (1993). Framing: Toward clarification of a fractured paradigm. Jour-\nnal of Communication, 43(4), 51\u201358. https://doi.org/10.1111/j.1460-2466.1993.\ntb01304.x\nFacebook. (2019, March). Standing against hate. Facebook Newsroom. Retrieved  \nSeptember 13, 2019, from https://newsroom.fb.com/news/2019/03/standing-against-  \nhate/\nFacebook. (2023, September). Difference between public and private Facebook \ngroups. Retrieved September 17, 2023, from https://www.facebook.com/help/220336891328465?ref=hc_about&helpref=about_content\nGamson, W. A. (1992). Talking politics. Cambridge University Press.Gerstenfeld, P. B., Grant, D. R.,\u00a0& Chiang, C. P. (2003).  Hate online: A\u00a0content analy -\nsis of extremist Internet sites. Analyses of Social Issues and Public Policy , 3(1), \n29\u201344. https://doi.org/10.1111/j.1530-2415.2003.00013.x\nGladwell, M. (2010, September 27). Small change. The New Yorker, 4, 42\u201349. https://\nwww.newyorker.com/magazine/2010/10/04/small-change-malcolm-gladwell\nGoffman, E. (1974).  Frame analysis: An essay on the organization of experience.  \nHarvard University Press.\nGuo, C.,\u00a0& Saxton, G. D. (2014). Tweeting social change: How social media are \nchanging nonprofit advocacy. Nonprofit and Voluntary Sector Quarterly , 43(1), \n57\u201379. https://doi.org/10.1177/0899764012471585\nHalupka, M. (2018). The legitimisation of clicktivism. Australian Journal of Political \nScience, 53(1), 130\u2013141. https://doi.org/10.1080/10361146.2017.1416586\nHatewatch Staff. (2020).  Facebook\u2019s strategy for taking down hate groups is spotty \nand ineffective. Southern Poverty Law Center. Retrieved September 15, 2020, from https://www.splcenter.org/hatewatch/2020/04/07/facebooks-strategy-taking-  \ndown-hate-groups-spottyand-ineffective\nHewstone, M., Rubin, M.,\u00a0& Willis, H. (2002).  Intergroup bias. Annual Review of \nPsychology, 53(1), 575\u2013604. https://doi.org/10.1146/annurev.psych.53.100901. \n135109\nJohnson, N. F., Leahy, R., Restrepo, N. J., Vel\u00e1squez, N., Zheng, M., Manrique, P., \nDevkota, P.,\u00a0& Wuchty, S. (2019).  Hidden resilience and adaptive dynamics of the \nglobal online hate ecology. Nature, 573(7773), 261\u2013265. https://doi.org/10.1038/\ns41586-019-1494-7\nJungkunz, S. (2019). Towards a measurement of extreme left-wing attitudes. German \nPolitics, 28(1), 101\u2013122. https://doi.org/10.1080/09644008.2018.1484906\nInformation Sharing and Content Framing across Platforms  217\nKaplan, A. (2018). The head of an anti-immigration PAC runs Facebook pages that \nshare fake news from plagiarized sites. Media Matters for America. Retrieved \nOctober 15, 2020, from https://www.mediamatters.org/facebook/head-anti- \nimmigration-pac-runs-facebookpages-share-fake-news-plagiarized-sites\nKeller, J. M. (2012). Virtual feminisms: Girls\u2019 blogging communities, feminist activ-\nism, and participatory politics. Information, Communication\u00a0 & Society, 15(3), \n429\u2013447. https://doi.org/10.1080/1369118X.2011.642890\nKlandermans, B. (1984). Mobilization and participation: Social-psychological expan-\nsions of resource mobilization theory. American Sociological Review , 49(5), \n583\u2013600. https://doi.org/10.2307/2095417\nKrona, M. (2019).  ISIS\u2019s media ecology and participatory activism tactics. In M. \nKrona\u00a0& R. Pennington (Eds.), The media world of ISIS  (pp.\u00a0101\u2013124). Indiana \nUniversity Press.\nKruglanski, A. W., Gelfand, M. J., B\u00e9langer, J. J., Sheveland, A., Hetiarachchi, M.,\u00a0& \nGunaratna, R. (2014).  The psychology of radicalization and deradicalization: \nHow significance quest impacts violent extremism. Political Psychology, 35, \n69\u201393. https://doi.org/10.1111/pops.12163\nLenz, R. (2013). Following the White Rabbit. Southern Poverty Law Center. \nRetrieved October 15, 2020, from https://www.splcenter.org/fightinghate/\nintelligence-report/2013/following-white-rabbit\nLevin, B. (2002). Cyberhate: A\u00a0 legal and historical analysis of extremists\u2019 use of \ncomputer networks in America. American Behavioral Scientist, 45(6), 958\u2013988. \nhttps://doi.org/10.1177/0002764202045006004\nMarx, G. T.,\u00a0& Wood, J. L. (1975).  Strands of theory and research in collective behav -\nior. Annual Review of Sociology, 1(1), 363\u2013428.\nMcCarthy, J. D.,\u00a0& Zald, M. N. (1977).  Resource mobilization and social move-\nments: A\u00a0partial theory. American Journal of Sociology, 82(6), 1212\u20131241. https://\ndoi.org/10.1086/226464\nMcCarthy, J. D.,\u00a0& Zald, M. N. (2003). Social movement organizations. In J. Good-\nwin\u00a0& J. M. Jasper (Eds.), The social movements reader: Cases and concepts (1st \ned., pp.\u00a0169\u2013186). Blackwell.\nMcCauley, C.,\u00a0 & Moskalenko, S. (2008).  Mechanisms of political radicalization: \nPathways toward terrorism. Terrorism and Political Violence, 20(3), 415\u2013433. \nhttps://doi.org/10.1080/09546550802073367\nMcNamee, L. G., Peterson, B. L.,\u00a0 & Pe\u00f1a, J. (2010).  A\u00a0 call to educate, participate, invoke, \nand indict: Understanding the communication of online hate groups. Communica-\ntion Monographs, 77(2), 257\u2013280. https://doi.org/10.1080/03637751003758227\nMorozov, E. (2009, May 19). The brave new world of slacktivism. Foreign Policy. \nhttps://foreignpolicy.com/2009/05/19/the-brave-new-world-of-slacktivism/\nNewell, E., Jurgens, D., Saleem, H., Vala, H., Sassine, J., Armstrong, C.,\u00a0& Ruths, D. \n(2016). User migration in online social networks: A\u00a0case study on Reddit during a period of community unrest. Proceedings of the International AAAI Confer -\nence on Web and Social Media, 10(1), 279\u2013288. https://doi.org/10.1609/icwsm.\nv10i1.14750\nN\u00fa\u00f1ez Puente, S., Fern\u00e1ndez Romero, D.,\u00a0 & V\u00e1zquez Cupeiro, S. (2017).  Online  \nfeminist practice, participatory activism and public policies against gender-based violence in Spain. Feminist Theory, 18(3), 299\u2013321. https://doi.org/10.1177/ \n1464700117721881\nObar, J. A., Zube, P.,\u00a0& Lampe, C. (2012).  Advocacy 2.0: An analysis of how advo -\ncacy groups in the United States perceive and use social media as tools for facilitat -\ning civic engagement and collective action. Journal of Information Policy , 2, 1\u201325. \nhttps://doi.org/10.2139/ssrn.1956352\nOberschall, A. (1973). Social conflict and social movements. Prentice Hall.\n218 Shruti Phadke and Tanushree Mitra\nO\u2019Callaghan, D., Greene, D., Conway, M., Carthy, J.,\u00a0 & Cunningham, P. (2013, \nMay). Uncovering the wider structure of extreme right communities spanning pop -\nular online networks. In Proceedings of the 5th annual ACM web science confer -\nence (pp.\u00a0276\u2013285). ACM. https://doi.org/10.1145/2464464.2464495\nOwen, N. (2019). Chapter\u00a01: The conscience constituent reconsidered. In Other peo-\nple\u2019s struggles: Outsiders in social movements. Oxford University Press.\nPhadke, S., Lloyd, J., Hawdon, J., Samory, M.,\u00a0& Mitra, T. (2018, October).  Framing \nhate with hate frames: Designing the codebook. In CSCW \u201918: Companion of the \n2018 ACM conference on computer supported cooperative work and social com-\nputing (pp.\u00a0201\u2013204). ACM. https://doi.org/10.1145/3272973.3274055\nPhadke, S.,\u00a0& Mitra, T. (2020). Many faced hate: A\u00a0cross platform study of content \nframing and information sharing by online hate groups. In CHI \u201920: Proceedings \nof the 2020 CHI conference on human factors in computing systems  (pp.\u00a01\u201313). \nACM. https://doi.org/10.1145/3313831.3376456\nPhadke, S.,\u00a0& Mitra, T. (2021).  Educators, solicitors, flamers, motivators, sympathiz -\ners: Characterizing roles in online extremist movements. Proceedings of the ACM \nConference on Human-Computer Interaction, 5(CSCW2), 310 (pp.\u00a01\u201335). ACM. \nhttps://doi.org/10.1145/3476051\nPhillips, W. (2018, May).  The oxygen of amplification: Better practices for report -\ning on extremists, antagonists and manipulators. Data\u00a0 & Society. Retrieved September 23, 2020, from https://datasociety.net/library/oxygen-ofamplification\nRahimi, B. (2016).  Vahid online: Post-2009 Iran and the politics of citizen media \nconvergence. Social Sciences, 5(4), 77. https://www.mdpi.com/2076-0760/5/4/77\nRea, S., Mathew, B.,\u00a0 & Kraemer, J. ( Chapter\u00a0 8 this volume). \u2018Hate parties\u2019: Net -\nworked antisemitism from the fringes to YouTube.\nRodan, D.,\u00a0& Mummery, J. (2017). Activism and digital culture in Australia. Row-\nman\u00a0& Littlefield.\nRotman, D., Vieweg, S., Yardi, S., Chi, E., Preece, J., Shneiderman, B., Pirolli, P.,\u00a0& \nGlaisyer, T. (2011). From slacktivism to activism: Participatory culture in the age of social media. In CHI\u201911 extended abstracts on human factors in computing systems (pp.\u00a0819\u2013822). ACM. https://doi.org/10.1145/1979742.1979543\nSchafer, J. A. (2002). Spinning the web of hate: Web-based hate propagation by \nextremist organizations. Journal of Criminal Justice and Popular Culture, 9 (2), \n69\u201388.\nShanmugasundaram, S. (2018).  Anti-immigrant roundup: 7/6/18 . Southern Pov -\nerty Law Center. Retrieved October 15, 2020, from https://www.splcenter.org/\nhatewatch/2018/07/06/anti-immigrant-roundup-7618\nSiegel, A. A.,\u00a0& Badaan, V. (2020).  # No2Sectarianism: Experimental approaches to \nreducing sectarian hate speech online. American Political Science Review , 114(3), \n837\u2013855. https://doi.org/10.1017/S0003055420000283\nSimon, B.,\u00a0& Klandermans, P. G. (2001).  Toward a social psychological analysis of \npoliticized collective identity: Conceptualization, antecedents and consequences. American Psychologist 56, 319\u2013331.\nSnow, D. A.,\u00a0& Benford, R. D. (1988).  Ideology, frame resonance, and participant \nmobilization. International Social Movement Research, 1(1), 197\u2013217.\nSPLC. (2019a, September). Hate map. Southern Poverty Law Center. Retrieved \nSeptember 13, 2019, from https://www.splcenter.org/hate-map\nSPLC. (2019b, September).  Ideologies. Southern Poverty Law Center. Retrieved \nSeptember 14, 2019, from https://www.splcenter.org/fighting-hate/extremist-files/\nideology\nSPLC. (2020a). Alliance defending freedom. Southern Poverty Law Center. Retrieved \nOctober 15, 2020, from https://www.splcenter.org/fightinghate/extremist-files/\ngroup/alliance-defending-freedom\nInformation Sharing and Content Framing across Platforms  219\nSPLC. (2020b). National vanguard. Southern Poverty Law Center. Retrieved \nOctober 15, 2020, from https://www.splcenter.org/fighting-hate/extremistfiles/\ngroup/national-vanguard\nStarbird, K. (2017, May). Examining the alternative media ecosystem through the \nproduction of alternative narratives of mass shooting events on Twitter. Proceed-\nings of the International AAAI Conference on Web and Social Media , 11(1), \npp.\u00a0230\u2013239. https://doi.org/10.1609/icwsm.v11i1.14878\nStringhini, G.,\u00a0& Blackburn, J. (this volume). Understanding the phases of coordi -\nnated online aggression attacks.\nThe Telegraph. (2015, June 19).  Charleston church shooting: Gunman kills nine in \nSouth Carolina\u00a0\u2013 latest pictures. The Telegraph. Retrieved September 18, 2019, from https://www.telegraph.co.uk/news/picturegalleries/worldnews/11688917/Charleston-  \nchurch-shooting-Gunman-kills-nine-people-in-South-Carolina.html\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). From echo chambers to digital \ncampfires: The making of an online community of hate within Stormfront.\nTurner, R. H. (1969).  The public perception of protest. American Sociological Review , \n34(6), 815\u2013831. https://doi.org/10.2307/2095975\nUdupa, S.,\u00a0& Gerold, O. L. (this volume). \u2018Deal\u2019 of the day: Sex, porn, and political \nhate on social media.\nValenzuela, S. (2013).  Unpacking the use of social media for protest behavior: The \nroles of information, opinion expression, and activism. American Behavioral Sci-entist, 57(7), 920\u2013942.\nVan Stekelenburg, J.,\u00a0& Klandermans, B. (2013a).  Social psychology of movement \nparticipation. In D. Della Porta, B. Klandermans, D. McAdam,\u00a0& D. A. Snow (Eds.). The Wiley-Blackwell encyclopedia of social and political movements  (pp \n1\u20136). Wiley-Blackwell.\nVan Stekelenburg, J.,\u00a0& Klandermans, B. (2013b). The social psychology of protest. \nCurrent Sociology, 61(5\u20136), 886\u2013905.\nVan Stekelenburg, J.,\u00a0& Klandermans, B. (2017).  Individuals in movements: A\u00a0social \npsychology of contention. In C. Roggeband\u00a0& B. Klandermans (Eds.), Handbook \nof social movements across disciplines (pp.\u00a0103\u2013139). Springer.\nVromen, A. (2017). Chapter\u00a01: Digital citizenship and political engagement. Digital \ncitizenship and political engagement (pp.\u00a09\u201349). Springer.\nWahlstr\u00f6m, M., Peterson, A.,\u00a0 & Wennerhag, M. (2018). \u201cConscience adherents\u201d \nrevisited: Non-LGBT pride parade participants. Mobilization: An International \nQuarterly, 23(1), 83\u2013100. https://doi.org/10.17813/1086-671X-23-1-83\nWalther, J. ( Chapter\u00a02 this volume). Making a case for a social processes approach to \nonline hate.\nWiebe, J., Wilson, T.,\u00a0& Cardie, C. (2005). Annotating expressions of opinions and \nemotions in language. Language Resources and Evaluation, 39(2\u20133), 165\u2013210. \nhttps://doi.org/10.1007/s10579-005-7880-9\nZald, M. N.,\u00a0& Ash, R. (1966). Social movement organizations: Growth, decay and \nchange. Social Forces, 44(3), 327\u2013341. https://doi.org/10.1093/sf/44.3.327\nZhou, Y., Reid, E., Qin, J., Chen, H.,\u00a0& Lai, G. (2005).  US domestic extremist groups \non the Web: Link and content analysis. IEEE Intelligent Systems, 20(5), 44\u201351. \nhttps://doi.org/10.1109/mis.2005.96\nDOI: 10.4324/9781003472148-10\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.Online discussions are fundamentally social. Participants are engaged audi -\nences of the messages that other contributors post and are concurrently \nexposed to the social approval and disapproval (as seen in \u201cvotes\u201d) that those (and their own) messages receive. These two sources of social informa -\ntion are deeply intertwined\u00a0\u2013 messages receive votes based on their contents (Rains et\u00a0al., 2017), while votes shape the content that future messages con -\ntain (Shmargad et\u00a0al., 2022). Posts and votes differ, however, in the kind of information that they tend to communicate. Information within a post often reveals the descriptive norms of a discussion setting, or signals of what other people do, while votes reflect the injunctive norms, or signals of what people ought to do (Cialdini et\u00a0al., 1990). Because people rely on descriptive and injunctive information to guide their behavior ( Rimal\u00a0& Real, 2005), online \ndiscussion data are uniquely suited for the study of social norm formation and evolution, compliance, and deviance. Historical records of online discus-sions are often readily available, enabling a better understanding of online socialization processes at both the collective level (e.g., by tracking aggregate trends in posting and rating behaviors) and individual level (e.g., by analyz -\ning a person\u2019s posting and rating behavior over time). Lapinski and Rimal \n(2005) label these two analytical levels collective and perceived social norms, \nrespectively.\nUsing the lens of social norms can help to shed light on the various forms \nof antisocial commenting that are prevalent online, including incivility  \n(Coe et\u00a0 al., 2014), trolling (Cheng et\u00a0 al., 2017), and online hate speech (ElSherief et\u00a0al., 2018 ). These forms of commenting have been of increasing \nconcern, with nearly a third of adults (and over half of those between the ages of 18 and 29) reporting they have been called an offensive name online 10\nDETECTING ANTISOCIAL NORMS IN \nLARGE-SCALE ONLINE DISCUSSIONS\nYotam Shmargad, Stephen A. Rains, Kevin Coe,  \nKate Kenski, and Steven Bethard\nDetecting Antisocial Norms in Large-Scale Online Discussions  221\n(Vogels, 2021). This increase in public concern has been met with an increase \nin research into the topic, with much of it focusing on the automated detec -\ntion of antisocial commenting (Tontodimamma et\u00a0 al., 2021). One project that offers free access to several automated classifiers is called Perspective, which originates from Google\u2019s Jigsaw lab ( Lees et\u00a0al., 2022). We authors \nhave built an additional classifier that identifies name-calling specifically (and it is available to others via the platform Hugging Face\n1; Sadeque et al., 2019; \nOzler et al., 2020). Automated classifiers make it possible to detect text fea -\ntures such as name-calling at scale and to discover variations in their deploy -\nment across time and individuals (e.g., Rains et\u00a0al., 2021 ; Rains et\u00a0al., 2023a ; \nRains et\u00a0al., 2023b).\nThis chapter is about how the Internet shapes social processes that fos -\nter the expression of incivility, hate, and other antisocial language on the one hand and how scientists study these processes on the other. We make a modest contribution to knowledge by analyzing antisocial commenting by both human-coded annotations and automated classification techniques in order to identify the extent that automated classifiers are suitable for the large-scale study of online (anti-)social norms. To do so, we replicated results from previous work that relied on human-coded annotations ( Rains et\u00a0al., \n2017; Shmargad et\u00a0 al., 2022), here using automated classifiers instead of \nhuman coders. Our findings are mixed, with some classifiers more reliably replicating prior work than others. In general, however, there was a mean -\ningful overlap between using human annotations and automated classifiers. To show how our framework can be applied to contemporary online discus -\nsions, we applied automated classifiers to discussions on Reddit and Twitter during the January 6th Capitol riots, and we compared the norms surround -\ning antisocial commenting across these two platforms. Using these multi -\nple approaches, several important points became clear. First, that antisocial commenting is promoted through at least two social processes, one in which people mimic others and another in which people who get rewarded for anti -\nsocial messages subsequently generate more of them. Second, that automated classification is a measurement advancement that can aid in the study of both the collective and perceived norms surrounding antisocial commenting.\nSocial Norms in Online Communities\nTheorizing about deviance from societal normative boundaries goes at least as far back as Durkheim's (1893) work on the topic\u00a0\u2013 for more informal \nexamples, you can go back as far as The Epic of Gilgamesh  or Shakespeare \nfor relevant discussions. Durkheim argued that deviance is a necessary, even beneficial, part of society because it clarifies the norms (thereby encouraging compliance), strengthens bonds among those reacting to deviance, and can lead to positive social change by challenging people\u2019s existing views. Lofland \n222  Yotam Shmargad et\u00a0al.\n(1969) clarifies the process by which deviance is socially constructed, becomes \ningrained in a society\u2019s view of itself, and creates a dual process whereby deviants increasingly associate deviance with their own identity. Maratea \nand Kavanaugh (2012) update these classic sociological ideas to provide a modern understanding of online deviance, specifically. They point out that emerging information and communication technologies allow \u201cscholars to study deviant subcultures that did not exist, or were too hidden to access, prior to the advent of the internet\u201d (p.\u00a0107). As a site of contemporary devi -\nance, online discussion threads thus represent a promising venue for investi -\ngating anti-normative behavior.\nWhile incivility and other forms of antisocial commenting are sometimes \nconceptualized as deviance from socially accepted manners of speech (Jamie-son et\u00a0al., 2017), one would be hard pressed to find societal benefits for some of the speech that can be found online. And yet, in addition to the (sometimes circular) arguments about one\u2019s rights to freedom of speech, unsavory online language cannot be uniformly treated as \u201cbad\u201d as it can serve positive, even necessary, societal and democratic functions (e.g., Edyvane, 2020; Rossini, \n2022). Such considerations, ethical in nature, are central to recent debates about how digital platforms should be moderating, and whether and when they should be censoring information that circulates on the web ( Forestal, \n2021). Proposed solutions, such as focusing only on the most extreme forms of commenting such as hate speech (Jiang et\u00a0 al., 2020) or paying special attention to the targets of such speech ( Zampieri et\u00a0 al., 2019), showcase \nhow politically fraught these considerations can become\u00a0\u2013 particularly when automated methods are employed (Udupa et\u00a0al., 2023). For example, Haim-son et\u00a0al. (2021 ) find that the people most likely to report that their posts \nwere removed from online platforms were either ideologically conservative, transgender, or Black. The reasons provided for removal, however, varied substantially across these groups, with the latter two groups having more of their posts removed that either did not violate platform policies or fell under moderation gray areas.\nDespite clarifying ethical nuances surrounding the censorship of antiso -\ncial comments and the groups that engage in or are targeted by such lan -\nguage, discussions of content moderation often ignore the underlying social processes that culminate in specific communication patterns. The work that exists often treats antisocial commenting as either a contagious process ( Song \net\u00a0al., 2022), one in which particular people are drawn into contentious dis -\ncussion (Bor\u00a0& Peterson, 2021), or both ( Kim et\u00a0al., 2021). While their work \nstarts to unpack the mechanisms behind antisocial behavior, they still leave much to ponder. Is such language always contagious or are there social con -\ntexts that are more conducive to mimetics? If specific people are primarily responsible for its spread, how does one become (or learn to respond to) such a person? These questions suggest a focus on social processes as critical forces \nDetecting Antisocial Norms in Large-Scale Online Discussions  223\nimpacting the expression of antisocial content. It is important to focus on both \nthe relational drivers of behavior as well as a longer time window through which to witness the socialization of antisocial expressions take place. The very platforms often blamed for fueling antisocial behavior also provide such a relational and temporal view of human interaction and development.\nMost traces of behavior generated by everyday online activity are intrinsi-\ncally relational (Golder\u00a0& Macy, 2014). For example, on Twitter alone, peo -\nple share or retweet messages that others post, show approval of a post with \na favorite, respond to a post with a reply, inform other users of their message \nwith a mention, or quote a post by sharing it with additional commentary. On platforms such as Reddit and YouTube, people provide comments and videos, respectively, with up and downvotes to signal their approval and dis -\napproval. While platforms may provide various ways for people to register their feedback about other users\u2019 posts, we refer in this chapter to clicks of approval or disapproval as votes. Votes can be said to be relational because \nthey have meaning not just for voters but also for receivers of the vote, for audience members who can view aggregated statistics of votes, and for plat-forms that use votes to filter posts in and out of people\u2019s content streams via algorithms (Burrell\u00a0& Fourcade, 2021 ). From the perspective of a researcher \nstudying online behavior, votes are understood differently depending on whether the sender or receiver of the vote is the focus. For example, retweet -\ning a message can be interpreted as a signal of homophily, or similarity, with the person who posted the message ( Barbera, 2015). Receiving retweets, on \nthe other hand, can imply that a message has resonated ( McDonnell et\u00a0al., \n2017) and was influential in getting people to pay attention to the poster (Shmargad, 2022).\nIn addition to reflecting the relational aspects of human behavior, digital \ntrace data are also inherently temporal in nature. For example, timestamps \ntypically accompany post data that are collected from social media platforms, so that it is possible to construct sequential timelines among comments. For the study of antisocial commenting, the temporal nature of digital trace data can be used to understand macroscopic trends ( Rains et\u00a0al., 2021) on the \none hand and microscopic dynamics ( Shmargad et\u00a0al., 2022) on the other. \nRains et\u00a0al. (2021) used a dataset of Russian troll tweets (Linvill\u00a0& Warren, 2020) to study their use of antisocial commenting across different periods of the 2016 U.S. presidential election cycle. Shmargad et\u00a0al. (2022) used the \ntemporal nature of digital trace data to understand the dynamics of antisocial commenting as a discussion thread evolves. They found that anti-sociality is more likely after prior anti-sociality by other commenters as well as votes of approval for one\u2019s own antisocial commenting. These two applications of temporality\u00a0\u2013 analyzing macroscopic trends and microscopic dynamics\u00a0\u2013 can aid researchers in the study of the collective and perceived norms (\n Lapinski\u00a0& \nRimal, 2005) surrounding antisocial commenting, respectively.\n224  Yotam Shmargad et\u00a0al.\nWe build here on our prior work ( Shmargad et\u00a0al., 2022 ) to argue that \nthe tone of online contributors\u2019 posts at a particular point in time depends \nin large part on two factors: The tone of other users\u2019 previous posts and the up or downvotes that they have seen posts receiving. These factors reflect the descriptive and injunctive norms, respectively, that users perceive. Each of these norms, in turn, has two further components: They can be either self- or \nother-focused (see Figure\u00a0 10.1). One\u2019s self-focused descriptive norms are their \nperceptions of contributions they themselves have made in the past, while their self-focused injunctive norms  are their perceptions of how those contri -\nbutions were rewarded or penalized. One\u2019s other-focused descriptive norms \nare perceptions of the contributions others have made, while other-focused \ninjunctive norms are perceptions of how those contributions were rewarded or penalized (either by the focal user or by others).\nFigure\u00a0 10.1 depicts in dotted lines the immediate signals that will inform \nan individual\u2019s posting behavior at a particular point in time. These are the signals that not only will matter but also represent what a first attempt at a test of our framework might look like. The total number of the votes, or clicks of approval and disapproval, reflect the aggregated feedback of other users. Because votes provide the person posting with feedback about what is and is not appropriate (i.e., self-focused injunctive norms), we might expect that a person will continue to post in ways that provide positive feedback and stop posting in ways that yield negative feedback. However, this is not always the case; for example, Cheng et\u00a0al. (2014) show that negative feedback can \nFIGURE\u00a010.1   A\u00a0Framework for Using Online Discussion Data to Study Socializa -\ntion Processes\nDetecting Antisocial Norms in Large-Scale Online Discussions  225\nbackfire and increase the likelihood of future posts that also receive negative \nfeedback. As such, the role that votes play in discouraging or encouraging particular behaviors, such as antisocial commenting, is an empirical question that our framework can help to address.\nThe extent that language in other people\u2019s posts will shape the language \nthat is chosen by a subsequent user depends on various factors. Goldberg \nand Stein (2018 ) argue that the spread of information relies on the mental \nframes of the receiver, a process they call associative diffusion. In-group status \n(Rimal\u00a0& Real, 2005), social tie strength ( Bakshy et\u00a0al., 2012), online ano-\nnymity (Kim et\u00a0al., 2019), identity performance (Freelon et\u00a0al., 2020), politi-cal influence (Shmargad, 2022), elite status ( Rains et\u00a0al., 2023b ), and many \nother factors will likely shape how contagious a person\u2019s language might be. The content in another commenter\u2019s posts can be viewed as contributing to a descriptive norm because it represents what another user is doing. A\u00a0subset of posts may also include injunctive information, however, and the large-scale extraction of such information is a worthwhile direction for future research. Moreover, the full set of posts that constitute the descriptive norms guiding a person\u2019s posting behavior at a specific point in time could be large and varied, and identifying the bounds of this evolving set is also an important research direction.\nWhile votes provide people with quantitative measures of feedback, the \ntext contained within a post is \u201cunstructured data,\u201d and meaning must be extracted from posts by discussion participants and behavioral researchers alike. Automated ways for extracting meaning from text have increased both in number and ease of use, with the most recent advancements evident in the large language models (LLMs) that may represent the future of data anno -\ntation (Ding et\u00a0al., 2022 ). The primary advantage of automated classifica -\ntion techniques is that one can process large amounts of text quickly and cheaply\u00a0\u2013 which, for the study of socialization, implies that a broader set of people, discussions, and contexts can be studied. However, to be influenced by the behavior of another requires that discussant participants are able to extract information from another person\u2019s post (e.g., the presence of antiso -\ncial commenting) and use that information in their own posting decisions. For example, if a person does not pick up on a particular name-call (e.g., the capitalization of the R in democRat; see Sadeque et\u00a0al., 2019), they may not take it as an insult and may thus not return in kind. To test the extent that automated techniques pick up on human interpretations, we compare human-coded annotations and automated classification techniques to study the collective and perceived norms surrounding antisocial commenting. This allows us to both evaluate the framework in Figure\u00a0 10.1 and to validate the \nuse of automated classification techniques in the detection of antisocial nor -\nmative behavior.\n226  Yotam Shmargad et\u00a0al.\nComparing Human Annotation to Automated Classification of \nAntisocial Commenting\nOnline Comments in The Arizona Daily Star\nThe data that we discuss in this section are similar to those analyzed in Coe \net\u00a0al. (2014), Rains et\u00a0al. (2017), and Shmargad et\u00a0al. (2022) and include all \nof the online comments made on news articles published in the online website for the Arizona Daily Star (ADS) over a three-week period in October and November of 2011. These news articles, along with their comments, were printed as PDF files, and the text of the comments was then manually anno -\ntated by human coders for five different measures of incivility ( name-calling, \naspersion, accusations of lying, vulgarity, and pejorative speech). The anno-\ntation process was designed to increase intercoder reliability. It began by hav-ing trained coders independently annotate the same set of comments, then discuss disagreements in their annotations, and finally to update a codebook that further clarified how annotations were to be made. When the coders reached sufficient intercoder reliability in their annotations, they then inde -\npendently coded the actual comments on the ADS articles. Further details \nabout the methodology, including intercoder reliability scores for the dif -\nferent measures of incivility and specific examples of each measure, can be found in Coe et\u00a0al. (2014).\nAn independent research effort ( Sadeque et\u00a0al., 2019) developed an auto -\nmated classifier using the coded data for name-calling, specifically, the appli -\ncation of which required the extraction of text from the comments in the original ADS discussion files. We use those data, which include the text of the \ncomments in addition to information in the original dataset (e.g., comment numbers, counts of the down and upvotes that comments received). We thus had the human annotations of incivility alongside the comment text, the lat -\nter of which was prepared for automated classification. We applied our own classifier for name-calling to the comment text, which was built by Ozler \net\u00a0al. (2020) and trained on several annotated datasets in addition to the ADS \ncomments. We also processed the text in the comments using Google\u2019s Per -\nspective API (Lees et\u00a0al., 2022) to obtain scores for several additional attrib -\nutes, including toxicity, severe toxicity, identity attack, insult, profanity, and \nthreat. The Perspective API also provided text attributes that were trained on a set of comments from New York Times articles, and we used these as well, \ngiven their similarity to our data.\n2 These attributes include attack on author , \nattack on commenter, and inflammatory language. The various classifiers \nprovided different measures of antisocial commenting, each of which was a possible candidate for the detection of normative behavior (i.e., for evidence of mimetics and/or response to social votes). Automated classifiers each pro -\nvided scores between 0 and 1, and we converted these scores into binary variables using a threshold of .5.\nDetecting Antisocial Norms in Large-Scale Online Discussions  227\nFIGURE\u00a0 10.2  Organizing Comments into Triplets\nTo test the framework from the previous section ( Figure\u00a0 10.1), we adopted \na data preparation strategy first outlined in Shmargad et\u00a0al. (2022 ) to trans -\nform the comment data into triplets such that: (1) The three comments in \na triplet were on the same news article, (2) the second comment in a triplet followed immediately after the first, (3) the first and second comments were authored by different contributors, and (4) the first and third comments were authored by the same contributor. This empirical strategy let us test how three factors highlighted in Figure\u00a0 10.1 above\u00a0\u2013 a person\u2019s prior comment, \nthe votes that person\u2019s comment received, and another person\u2019s comment\u00a0\u2013 contribute to the nature of a person\u2019s subsequent comment. Figure\u00a0 10.2 \ndepicts the empirical strategy that we adopted as a test of the framework in Figure\u00a0 10.1. The votes that Person i received on their initial comment capture \nself-focused injunctive norms, while the presence of antisocial commenting in Person i\u2019s and j\u2019s comments captures self- and other-focused descriptive \nnorms, respectively. Because this empirical strategy allowed us to investigate the (possibly interactive) effects of descriptive and injunctive norms, it could also be construed as a partial test of Rimal and Real's (2005) theory of nor -\nmative social behavior (TNSB) according to Shmargad et\u00a0 al. (2022 ). (We \nleave the study of other-focused injunctive norms for future research.)\nCollective Descriptive Norms in the Arizona Daily Star\nShmargad et\u00a0al. (2022) used a single, collapsed measure of antisocial com -\nmenting, which was set to 1 for comments that included name-calling, asper -\nsion, accusations of lying, vulgarity, or pejorative speech, and 0 for comments \nthat lacked those message features. The classifier in Ozler et\u00a0al. (2020) was \ntrained on the name-calling annotations only, so that in addition to Shmar -\ngad et\u00a0al.'s (2022) collapsed measure, we also defined two new measures\u00a0\u2013 \u201cname-calling\u201d tracked the presence of name-calling, specifically, while \u201cnot name-calling\u201d tracked the presence of any of the other incivility measures. \n228  Yotam Shmargad et\u00a0al.\nTable\u00a0 10.1 includes summary statistics for these three measures as well as \nthose obtained from the Perspective API and New York Times attributes. \nThese statistics capture the collective descriptive norms surrounding antiso-\ncial commenting in this community. We include statistics for all comments, \nas well as for the subset of comments that started a triplet. The latter will serve as a useful comparison in the next section, where only comments that were included as parts of a triplet were classified for the presence of antiso -\ncial commenting. Table\u00a0 10.2 includes definitions and examples of the various \nforms of antisocial commenting that we classified using automated methods.\nSeveral observations in Table\u00a0 10.1 are worth discussing. First, the rate of \nanti-sociality in comments that started a triplet did not deviate much from the rate across all comments. Since the focus later will be on triplets to provide a test of our theoretical framework, it is reassuring that these triplets did not begin in an atypically pro- or antisocial manner.\n3 Second, the name-calling \nclassifier successfully recovered the rate of name-calling that was coded by human coders (i.e., the means were identical or close). This result highlights the utility of classifiers that are trained on properly annotated data as a means of evaluating name-calling behavior at scale. Third, the scores obtained from TABLE\u00a010.1   Summary Statistics of Antisocial Commenting in the Arizona Daily Star\nAll Comments First Comment in Triplet\nN M SD N M SD\nAnnotated incivility 6,165 0.20 0.40 2,672 0.19 0.39\nName-calling 0.14 0.35 0.12 0.33\nNot name-calling 0.09 0.28 0.08 0.28\nAutomated name-calling 6,121 0.14 0.35 2,620 0.13 0.33\nPerspective API 5,998 2,534\nToxicity 0.05 0.21 0.04 0.20\nSevere toxicity 0.00 0.00 0.00 0.00\nIdentity attack 0.01 0.08 0.01 0.07\nInsult 0.05 0.22 0.04 0.20\nProfanity 0.00 0.06 0.00 0.07\nThreat 0.01 0.08 0.00 0.06\nAny perspective 0.06 0.24 0.05 0.22\nNew York Times 5,998 2,534\nAttack on author 0.10 0.30 0.10 0.30\nAttack on commenter 0.22 0.41 0.25 0.43\nInflammatory 0.33 0.47 0.30 0.46\nNote: M and SD values are in percent.\nDetecting Antisocial Norms in Large-Scale Online Discussions  229  Definitions and Examples of Antisocial Commenting in the Arizona Daily Star\n, you W \u201cY\nsevere toxicity score, but at .45 did not meet \nthe .5 threshold to be classified as such)\nADERS to our \nony to turn a \u2018news\u2019 story into a \u201cMexico sending more INV\n\u201cAll of what you said just shows that you \nt grown up yet.\u201dnation.\u201d\n\u201cJust build the damn mine already!\u201d\n\u201cLeave it to T\none-sided bleeding heart opinion piece.\u201d\nhaven\u2019\u201cYou are truly an IDIOT.\u201d\u201cUseful idiots!\u201d\n\u201cArizona voters are stupid and they get what \nthey deserve by electing these scum sucking \nsleaze balls.\u201d (Note: This had the highest \n\u201cEvery person on their death-bed should die \nant a government in pain.\u201d\nant a chance at a job, get rid of Obama, \u201cW\nPelosi, and the rest. Whandout like the OWS clowns, then vote for Obama. Simple enough.\u201d\nhttps://developers.perspectiveapi.com/s/about-the-api- Example\nou ARE BREAKING THE LA\ndopes.\u201dDefinition\nMean-spirited or disparaging words directed at a person or \ngroup of people\nA rude, disrespectful, or unreasonable comment that is likely to \nmake people leave a discussion\nto more mild forms of toxicity, such as comments that include \n measures of incivility (i.e., name-calling, aspersion, accusations of lying, vulgarity, and pejorative for A very hateful, aggressive, disrespectful comment or otherwise \nvery likely to make a user leave a discussion or give up on \nsharing their perspective. This attribute is much less sensitive \nNegative or hateful comments targeting someone because of \ntheir identity\nInsulting, inflammatory, or negative comment toward a person \nor a group of people\nSwear words, curse words, or other obscene or profane languageDescribes an intention to inflict pain, injury, or violence against \n features were obtained from an individual or group\nAttack on the author of an article or post\nimespositive uses of curse words\nAttack on fellow commenter.\nIntending to provoke or inflame.\nork T New Y\nannotated . For examples of the \n). Coe et\u00a0al. (20141 in imes\nable\u00a00.2 1\nork T\ncommenter\nTToxicityABLE\u00a0 T\nForm of Anti-Sociality\nName-calling\nPerspective API\nSevere toxicity\nIdentity attack\nInsultProfanity\nThreat\nNew Y\nAttack on author\nAttack on Inflammatory\nNote: Definitions for the Perspective API and \nattributes-and-languagesspeech), see \n230  Yotam Shmargad et\u00a0al.\nthe Perspective API measures were low for these data, with severe toxicity \nnot appearing in any of the comments. This finding raises questions about \nthe sensitivity of the Perspective measures. We thus also constructed a col -\nlapsed measure across the six Perspective API measures, which is 1 if toxicity, \nsevere toxicity, identity attack, insult, profanity,  and threat were present, \nand 0 otherwise. Using the collapsed Perspective API measure, only 6% of the comments included at least one of these forms of antisocial comment -\ning, compared to 20% that included at least one of the incivility measures coded by Coe et\u00a0al. (2014 ). Although the types of behaviors captured in the \nPerspective API appear broader, they are less sensitive to common forms of incivility. Finally, the rates of the New York Times attributes were higher than measures obtained with the Perspective API, with a third of the com -\nments containing instances of inflammatory language. Figure\u00a0 10.3 presents \nthe correlation matrix of these measures of antisocial commenting.\nCollective Injunctive Norms in the Arizona Daily Star\nAs previously mentioned, in addition to measures of incivility, the ADS data-\nset includes counts of the down and upvotes that comments received from other readers. Figure\u00a0 10.4 presents a plot of the relationship between the \nFIGURE\u00a010.3   Correlation Matrix for Measures of in Online News Comments\nDetecting Antisocial Norms in Large-Scale Online Discussions  231\ndown and upvotes that comments received. We standardize the number of \ndown and upvotes for each article by subtracting the article-specific mean and dividing by the article-specific standard deviation. This controls for correlations across down and upvotes that result from some articles sim -\nply drawing more attention. We then transform the standardized down and upvote measures by taking a logarithm to remove skew. As we can clearly see in Figure\u00a0 10.4, down and upvotes were highly correlated even after con -\ntrolling for the specific news article, suggesting that comments frequently divided the community (i.e., a given comment received a proportional num -\nber of down and upvotes). These rankings thus reflect in- and out-group dynamics in a broad sense, some of which can be explained by partisanship (Rains et\u00a0al., 2017 ). Papakyriakopoulos et\u00a0al. (2023 ) show that discussions \non forums with both up and downvote capabilities are less civic-natured than forums that only allow upvotes (though, notably, more civic-natured than forums that allowed neither up nor downvotes).\nThe next set of analyses relates the presence of antisocial commenting to \nthe number of down and upvotes that comments received, which reflect col-\nlective injunctive norms around antisocial commenting in this community. Table\u00a0 10.3 reports results for the various measures of antisocial commenting. \nEach coefficient was obtained with a multilevel model that included random effects for the news article and for the contributor who posted the comment. The random effects were included to remove variation from specific articles that drew more antisocial commenting or from people who were more likely to deploy antisocial commenting. We also included an additional control variable, the numerical order of the comment in the set for that article. As reported in Rains et\u00a0al. (2017 ), comments that included incivility were more \nlikely to draw both downvotes and upvotes. Interestingly, name-calling was \nprimarily responsible for the increases in upvotes, while the other incivility measures were responsible for increases in downvotes. Among the Perspec-tive API measures, only insult showed a positive relationship with upvotes. \nAttacks on commenters were associated with fewer upvotes, while inflam-\nmatory language was associated with more downvotes. Figure\u00a0 10.5 portrays \nthese effects.\nFIGURE\u00a010.4   Log-Log Plot of Down and Upvotes after Article Standardization\n232  Yotam Shmargad et\u00a0al.\nTABLE\u00a010.3   Effects of Antisocial Commenting on Downvotes and Upvotes\nN Downvotes: Upvotes: \nCoefficient Coefficient \n(S.E.) (S.E.)\nAnnotated incivility 5,665 0.65* (0.26) 1.20** (0.43)\nName-calling 0.34 (0.30) 1.16* (0.51)\nNot name-calling 0.79* (0.37) 0.84 (0.55)\nAutomated name-calling 5,621 0.55 (0.30) 0.44 (0.50)\nPerspective API 5,506\nToxicity 0.90 (0.56) 1.53 (1.03)\nSevere toxicity 0.00 (0.00) 0.00 (0.00)\nIdentity attack 1.15 (2.78) 0.48 (2.55)\nInsult 0.37 (0.51) 1.74* (0.95)\nProfanity 0.76 (2.29) 1.80 (2.91)\nThreat 2.21 (2.04) \u22122.17 (2.38)\nAny Perspective API 5,506 0.32 (0.45) 1.62* (0.85)\nNew York Times 5,506\nAttack on author 0.59 (0.36) 1.13 (0.59)\nAttack on commenter 0.19 (0.25) \u22121.26** (0.40)\nInflammatory 0.96*** (0.24) 0.69 (0.39)\nNote: * p < .10, ** p < .05, *** p < .001.\nFIGURE\u00a010.5   Effects of Antisocial Commenting on Votes with 95% Confidence \nIntervals\nDetecting Antisocial Norms in Large-Scale Online Discussions  233\nPerceived Descriptive and Injunctive Norms in the Arizona Daily Star\nThe final set of analyses in this section replicated Shmargad et\u00a0al.'s (2022) \non the effects of perceived descriptive and injunctive norms on the spread of \nincivility (Figure\u00a0 10.2). The purpose of these analyses was to examine how \ncommunity responses to incivility influence the degree to which it is perpetu-ated in online discussion. We used multilevel models with random effects for article and commenter and included control variables for the numerical order of the comment as well as the \u201cgap\u201d (i.e., number of comments) between the first and last comment in a triplet. Note that the triplets, as constructed, allow for several comments to occur between the first and last comment, so far, as none of these comments was contributed by the author of the first and last comment. We did not run the model for the six Perspective API meas -\nures separately (toxicity, severe toxicity, identity attack, insult, profanity , or \nthreat) as they were not prevalent enough. Instead, we report results for a collapsed measure that tracked if any of these six Perspective API attributes were present (0 for no, 1 for yes). We do not report numerical estimates here but instead provide images of the marginal effects in Figures\u00a010.6 and 10.7.\nFigure\u00a0 10.6 provides estimates for the human-coded measures of incivil-\nity as well as for the automated classifier for name-calling. The right pan -\nels depict the effects of downvotes while the left panels depict the effects of upvotes. The first row in Figure\u00a0 10.6 replicates the results from Shmar -\ngad et\u00a0al. (2022 ): The effect of incivility in another user\u2019s comment depends, \nin part, on the number of upvotes that a user\u2019s initial comment received. When the user was initially uncivil and received no upvotes, the presence of incivility in another user\u2019s comment decreased the likelihood of incivility in the initial user\u2019s subsequent comment. However, as the number of upvotes a user received increased, the effect of another commenter\u2019s incivility also increased. This implies that incivility was met with incivility when it was initially rewarded. Downvotes, on the other hand, did not influence the effect of another commenter\u2019s incivility.\nWhen we break up the collapsed human-annotated incivility measure into \ntwo categories, name-calling and all other measures ( not name-calling), the \neffect of proximate incivility increased as the number of upvotes increased for other incivility measures but not for name-calling itself. When the same \nanalyses were conducted using the automated name-calling classifier (Ozler \net\u00a0al., 2020) rather than the human-annotated measures, results matched. The results suggest that the effect of other users\u2019 name-calling on one\u2019s own name-calling was not shaped by how many upvotes the initial name-calling received. This suggests that different forms of incivility may elicit different normative responses, with name-calling showing less sensitivity to mimet-ics and social rewards. The results (as also seen in Shmargad et\u00a0al., 2022) \nreplicate with the collapsed Perspective API measures (the presence of any \n234  Yotam Shmargad et\u00a0al.\nFIGURE\u00a0 10.6  Testing TNSB with Human Annotation and Automated Classifica -\ntion of Incivility\nDetecting Antisocial Norms in Large-Scale Online Discussions  235\nFIGURE\u00a010.7   Testing TNSB with Google\u2019s Perspective API and New York Times  \nAttributes\n236  Yotam Shmargad et\u00a0al.\ntoxicity, severe toxicity, identity attack, insult, profanity , or threat) but \nnot with any of the New York Times attributes. Interestingly, for both the \ncollapsed Perspective API measure and inflammatory language, the effect \nof proximate anti-sociality was positive when a user\u2019s initial anti-sociality received no downvotes\u00a0\u2013 an effect that went away as downvotes increased. The Perspective API thus picks up on forms of antisocial commenting that are sensitive to both descriptive and injunctive norms.\nComparing Reddit and Twitter Discussions of the  \nJanuary 6th Capitol Riots\nIn an effort to apply the norms-based framework we developed\u00a0\u2013 the poten -\ntial effects of others\u2019 antisocial commenting as well as social approval \nvotes\u00a0\u2013 to a more contemporary online context, we employed a novel data -\nset consisting of discussions surrounding the insurrection that followed the 2020 U.S. presidential election. The collective that raided the United States Capitol building on January 6th, 2021, was, in part, a product of online socialization processes (Ng et\u00a0al., 2022). Given this, we looked for norms surrounding antisocial commenting as the events of January 6th unfolded. Data from both Reddit and Twitter highlight both the broad applicability of our framework as well as the nuanced understanding of social norms that it can provide. These two platforms differ in the way that social interactions are structured, with Reddit organizing discussions in topic-based forums and Twitter employing a network graph of follower relations. Moderation also works differently across these two platforms, with Reddit relying on com-munity members and Twitter on algorithmic solutions. Norms may be more influential on platforms like Twitter, where out-of-community interactions are more likely and moderation is less specific to one\u2019s own community. The analysis of the Capitol riots provides an opportunity to examine antisocial commenting norms ten years after the ADS dataset was constructed, during \nan especially contentious time and across these different platforms.\nReddit data are organized into \u201csubmissions\u201d and \u201ccomments.\u201d Sub-\nmissions are prompts and comments are responses either to prompts or to other comments. We first collected all of the submissions that mentioned the word \u201cCapitol\u201d between 11 am on January 6th and 11 am on January 7th EST (i.e., Washington, D.C. time, where the insurrection took place). We then filtered down the set of submissions to include only those that had between 100 and 500 comments. This set reflects 3% of submissions and 9% of comments, respectively. This was done not only to constrain the amount of comment data we analyzed for anti-sociality on the one hand but also to ensure that (1) there were enough comments per submission to model submission-specific random effects and (2) all of the comments for each submission were obtained, as the Reddit API (which was used for data \nDetecting Antisocial Norms in Large-Scale Online Discussions  237\ncollection) only allows for 500 comments per submission to be collected. We \nthen collected all of the comments posted on the submissions in our filtered set, organized the comments into triplets similar to those discussed in the previous section, and applied several automated classifiers of antisocial com-menting (i.e., name-calling, toxicity, severe toxicity, identity attack, insult, threat, attack on author, attack on commenter, and inflammatory) to each of the comments in these triplets.\nData collection for Twitter proceeded in much the same way. Since tweet \nvolume is much larger than that of Reddit submissions, we sampled one, ten-second interval per minute for the same 24-hour period and collected all of the tweets in these intervals that included the word \u201cCapitol.\u201d We removed retweets and replies that matched our query (i.e., we constrained the data to original tweets) and filtered down the tweets to those that had between 100 and 500 replies, in order to be consistent with the Reddit data collection. The filtered set of original tweets and replies captures .3% and 17% of the respective totals. We then collected the replies to the tweets in our filtered set, created triplets, and processed the tweets in these triplets using the automated classifiers. One additional detail is that discussions on Reddit and Twitter are organized in tree-like threads rather than single-comment streams as in the ADS dataset. Our triplets thus reflect any three sequential \nreplies in which the initial and final comments were made by the same user. Unlike the triplets constructed from the ADS dataset, we did not allow for a \u201cgap\u201d of multiple comments separating the first and third comment, as these are not well-specified in tree-like threads because each comment can split into separate sub-threads. In all, we analyzed 12,594 triplets on Reddit and 6,303 triplets on Twitter. Table\u00a0 10.4 presents summary statistics for the three \ncomments in each triplet.\nCollective Descriptive Norms on Reddit and Twitter\nThese first set of analyses we report reveal the collective descriptive norms \nsurrounding antisocial commenting on Reddit and Twitter. Name-calling was \nprevalent in these data, with 21% and 19% of the initial comments includ -\ning name-calling on Reddit and Twitter, respectively (compared to just 13% in the ADS comments). Scores on the Perspective API measures were sub -\nstantial, with 41% and 35% of comments on Reddit and Twitter including at least one of the six measures, compared to just 6% of the comments in the ADS. While these differences between the 2011 ADS dataset and 2021 \nCapitol dataset are notable, recent work acknowledges the limitations of the Perspective API for making comparisons over time ( Pozzobon et\u00a0al., 2023). \nThe New York Times  attributes\u2019 scores were not particularly high\u00a0\u2013 in fact, \nattacks on author  were less common than in the ADS analyses, at 5% and \n2% for Reddit and Twitter, respectively (compared to 10% in the ADS). \n238  Yotam Shmargad et\u00a0al.\nTwitter\n.17 (.38)\n.22 (.42)\n.10 (.30).10 (.30).22 (.42).13 (.34).11 (.31).32 (.46)\n.03 (.16)\n.45 (.50).30 (.46)Means and Standard Deviations of Antisocial Commenting on Reddit and Twitter\nSubsequent Comment\nReddit.18 (.38)\n.24 (.42)\n.12 (.32).09 (.28).23 (.42).16 (.37).14 (.35).35 (.48)\n.05 (.23)\n.29 (.45).34 (.47)Proximate Comment\nTwitter\n.18 (.39)\n.24 (.43)\n.11 (.31).11 (.31).23 (.42).14 (.34).13 (.33).35 (.48)\n.03 (.16)\n.46 (.50).33 (.47)Reddit\n.20 (.40)\n.26 (.44)\n.13 (.34).10 (.30).25 (.43).17 (.37).17 (.37).38 (.49)\n.05 (.23)\n.29 (.45).37 (.48)witter T\n.19 (.39)\n.23 (.42)\n.10 (.31).11 (.32).23 (.42).13 (.33).14 (.35).35 (.48)\n.02 (.15)\n.45 (.50).33 (.47)Initial Comment\nReddit.21 (.40)\n.28 (.45)\n.15 (.36).12 (.32).27 (.45).19 (.39).19 (.39).41 (.49)\n.05 (.21)\n.24 (.43).41 (.49)  \n0.4\nPerspective API\noxicity TTABLE\u00a01\nalues are in percent.Name-calling\nSevere toxicityIdentity attack\nProfanity\nThreatAll perspective\nimes ork TInsult\nNew Y\nAttack on authorAttack on commenterInflammatory\n V Note:\nDetecting Antisocial Norms in Large-Scale Online Discussions  239\nAntisocial comments were typically more prevalent on Reddit than on Twit-\nter. One exception was attacks on other commenters, which occurred in a staggering 45% of initial comments on Twitter, compared to 24% of those on Reddit. Understanding the reasons for these cross-platform differences is beyond the scope of this chapter but is a worthwhile direction for future research.\nFigure\u00a0 10.8 shows correlations for these different forms of antisocial \ncommenting. The bottom panels report correlations for Reddit comments and Twitter replies separately. The upper left panel includes both platforms together. Finally, the upper right panel includes differences in the correlations across the two platforms. The classifier for name-calling was consistently \ncorrelated with the Perspective API measures, aside from threat. This was \nnot the case in the ADS comments, which featured relatively low rates of \nthe Perspective API measures, in contrast to which comments on Reddit and Twitter frequently included several forms of antisocial commenting. Finally, \nthere tended to be stronger correlations among the Perspective API measures \nFIGURE\u00a0 10.8  Correlation Matrices for Initial Comments on Reddit and Twitter\n240  Yotam Shmargad et\u00a0al.\non Reddit (more positive) and higher correlations between the New York \nTimes attributes and Perspective API measures on Twitter (more negative). \nThe correlations among the New York Times attributes were split, with Red -\ndit showing a stronger correlation between attacks on author and attacks on \ncommenter, and Twitter showing a stronger correlation between attack on \ncommenter and inflammatory language. Multiple forms and variations of antisocial commenting were often used in harmony, with slight differences in co-occurrence rates between the two platforms.\nCollective Injunctive Norms on Reddit and Twitter\nNext, we analyze the collective injunctive norms across the two platforms by modeling the effects of anti-sociality on how many votes comments received. On Twitter, comments can be favorited (or not rated at all), while on Red -\ndit, comments can receive down or upvotes (or neither). However, the Red -\ndit API only provides a single \u201cscore,\u201d which captures the difference in the number of up and downvotes and can thus be negative. As such, we use a linear model specification with fixed effects for the submission (on Reddit) or conversation ID (on Twitter), as well as for the specific commenter. We do not include a control variable for the order of the comment, as this is not clearly defined for a tree-like thread structure. We report the results of these analyses in Table\u00a0 10.5 and depict them in Figure\u00a0 10.9. The name-calling \nTABLE\u00a010.5   Effects of Antisocial Commenting on Votes in the Initial Comments\nName-Calling Reddit Twitter\nN  Coeff. (S.E.) N Coeff. (S.E.)\n2,982 4.91 (3.37) 4,939 \u22120.27 (1.42)\nPerspective API 9,300 4,939\nToxicity 6.73** (1.89) \u22121.45* (0.76)\nSevere toxicity 9.32*** (2.18) \u22120.56 (0.58)\nIdentity attack 3.21 (2.87) \u22121.30 (0.84)\nInsult 8.54*** (1.99) \u22121.71** (0.70)\nThreat 0.13 (1.84) 1.65 (1.53)\nAny Perspective API 6.16*** (1.72) \u22121.00 (0.93)\nNew York Times 9,300 4,939\nAttack on author \u22121.62 (2.14) \u22120.02 (1.48)\nAttack on commenter \u22123.27* (1.71) \u22122.82** (1.17)\nInflammatory  6.50* (2.83) \u22121.04 (1.12)\nNote: * p < .10, ** p < .05, *** p < .001.\nDetecting Antisocial Norms in Large-Scale Online Discussions  241\nclassifier annotated only about a third of the Reddit comments because many \nof them exceeded the default input length limitations of the tool.4 This not \nonly introduces bias in our analysis toward shorter comments but also makes the comparison to Twitter more apt. All of the Twitter tweets were coded properly as they tend to be shorter than Reddit comments. Several measures of anti-sociality were rewarded (i.e., received relatively more upvotes than downvotes) on Reddit, including toxicity, severe toxicity, insult, and inflam-\nmatory language. In contrast, toxicity and insult were associated with fewer \nvotes (i.e., \u201cfavorites\u201d) on Twitter. Attacks on other commenters  were con-\nsistently associated with lower social rewards on both platforms.\nPerceived Descriptive and Injunctive Norms on Reddit and Twitter\nWe close this section with a set of analyses investigating the role of per-\nceived descriptive and injunctive norms on the spread of antisocial com -\nmenting across the two platforms. While the previous analyses of collective norms focused on aggregate rates of antisocial comments and their associ -\nated social rewards, an analysis of perceived norms investigates instead the effects on individuals\u2019 postings due to their exposure to antisocial comment -\ning and associated rewards within a conversational thread. We modeled the outcomes, or dependent variables, using several of the antisocial features that were used in the previous analyses, above, but as they appeared in the \nFIGURE\u00a010.9   Effect of Antisocial Commenting on Votes across Reddit and Twitter\n242  Yotam Shmargad et\u00a0al.\nfinal triplet comment. We tested whether antisocial comments resulted from \na statistical interaction between (1) anti-sociality in the triplet\u2019s initial com-ment, (2) anti-sociality in the proximate comment, (3) the number of votes of approval that the initial comment received, and (4) whether the comments were on Reddit or Twitter. A\u00a0multilevel modeling procedure specified a ran -\ndom effects variable representing the submission number (on Reddit) or con -\nversation ID (on Twitter), as well as a random effects variable representing each contributor. The full numerical results are available from the first author upon request, but the marginal effects depicted in Figure\u00a0 10.10 reflect defini-\ntive patterns.\nAcross a range of antisocial features, proximate anti-sociality on Reddit \nwas associated with a greater likelihood of anti-sociality in the final comment. However, we found no effects of votes on Reddit, and the rate of anti-sociality in a Redditor\u2019s final comment did not differ due to anti-sociality in that user\u2019s initial comment. On Twitter, on the other hand, the rate of anti-sociality in the final comment was regularly associated with anti-sociality in prior posts as well as votes that a triplet\u2019s initial comment received for anti-sociality. This result suggests that the theory of normative social behavior (Rimal\u00a0& Real, 2005) applies to Twitter\u2019s dynamics more than Reddit\u2019s. The theory predicts an interaction between descriptive and injunctive norms (in this case, between proximate anti-sociality and votes for initial anti-sociality). Insult \non Twitter, in particular, appears partially caused by such an interaction effect and, to a lesser extent, so do severe toxicity, identity attacks, profan-\nity, and threat. An unexpected finding was that, on Twitter, votes for initial \nanti-sociality were associated with lower rates of subsequent name-calling \nand inflammatory language, suggesting a possible satiation effect whereby \nrewards for anti-sociality filled a need that no longer must be met, a thresh -\nold effect, providing an interesting direction for future research.\nTo summarize, we found notable differences between Reddit and Twit-\nter in the constitution of norms surrounding antisocial commenting. At the collective level, discussions on Reddit tended to feature higher rates of anti -\nsocial commenting than Twitter, except for attacks on commenters  which \nwere greater on Twitter. These aggregate descriptive norms are useful for understanding the kinds of language that users are exposed to on the two platforms, albeit at a very abstract level. Rewards for antisocial comment -\ning were more common on Reddit than Twitter, suggesting that (collective) injunctive norms are more favorable to anti-sociality on Reddit. However, when shifting from collective to perceived norms, a slightly different picture emerges. In particular, while votes for anti-sociality were more common on Reddit, they may be more influential on Twitter. Being rewarded for anti-social comments on Twitter increased a contributor\u2019s likelihood of repeat-ing antisocial behavior, while the same rewards did not produce additional antisocial messaging on Reddit. Injunctive norms surrounding anti-sociality \nDetecting Antisocial Norms in Large-Scale Online Discussions  243\nFIGURE\u00a010.10   Testing TNSB on Reddit and Twitter during the January 6th \n Capitol Riots\n244  Yotam Shmargad et\u00a0al.\nare thus more incendiary on Twitter than Reddit, possibly due to the afore -\nmentioned differences in their interaction structure or moderation practices. \nThe platforms do not appear to differ, however, in the impact of descriptive norms\u00a0\u2013 on both platforms, being exposed to antisocial language is associ-ated with higher rates of antisocial language use, suggesting that mimetics perpetuate anti-sociality across both platforms.\nDiscussion\nIf online antisocial language use is based in normative considerations, then the combination of online discussion thread data and automated text clas -\nsification techniques together is the equivalent of a microscope and telescope (i.e., macroscope) for the study of social norm formation and evolution. A\u00a0 microscope because individual-level behavior can be tracked over time to study the formation and evolution of perceived norms, and a telescope because aggregate trends in antisocial commenting can be tracked to under -\nstand the formation and evolution of collective norms at scale. By providing behavioral researchers with a rich set of relational artifacts as well as a long \nand granular temporal frame, online discussion data can be used to track when and why people and collectives conform to their social surroundings. This study validates and applies text-based classification methods to uncover normative dynamics that underlie the use and spread of antisocial language online. In addition to distinguishing between collective and perceived norms at the analytical level ( Lapinski\u00a0& Rimal, 2005), we also separate descriptive \nand injunctive norms (Cialdini et\u00a0al., 1990) at the measurement level. We argue that the inter-relations of series of texts among online comments can capture descriptive norms surrounding anti-sociality, while the allocation of social votes reflects the injunctive norms and that both can play a role in fueling antisocial comments.\nThis chapter offers several contributions to understanding the social pro -\ncesses that underlie antisocial commenting. First and foremost, it maps the widely used social scientific constructs, descriptive and injunctive norms, \nonto features of digital trace data that are increasingly useful for contem-porary understanding of human behavior. In particular, we argue that descriptive norms can be measured using the text contained within a com -\nment, while injunctive norms can be assessed using data about the social \u201cvotes\u201d that comments receive. Second, we demonstrated how automated classification techniques can capture the presence of antisocial commenting within a comment, yielding similar results as human-coded data in many cases (and especially for the measures obtained with the Perspective API). Using human-coded data, Shmargad et\u00a0al. (2022 ) show that antisocial com -\nmenting is sensitive to descriptive and injunctive norms, and we show here, using comments from the online Arizona Daily Star, that the Perspective API \nDetecting Antisocial Norms in Large-Scale Online Discussions  245\n(Lees et\u00a0al., 2022) can be used to replicate these findings. Finally, we ana -\nlyzed the collective and perceived norms around antisocial commenting as \nthe January 6th Capitol riots unfolded and showed how these differed across the social media platforms Reddit and Twitter. While antisocial language was more likely to be rewarded on Reddit than Twitter, rewards were more influ -\nential for the spread of antisocial language on Twitter. The presence and influ -\nence of antisocial norms can thus vary widely across sociotechnical contexts.\nThe broad theoretical approach we introduce, which delineates self- and \nother-focused signals of descriptive and injunctive information available in online discussion data, can be used in a variety of ways that go beyond the analyses that we present. One direction worth pursuing is the adoption of a longer time window of individual-level behavior (e.g., Rains et\u00a0al., 2021) and \nthe social contexts from which it emerges. In contrast, the temporal dimen -\nsion we study here is short and focuses more on the dynamics of comments in a single thread. A\u00a0longer view of how an individual\u2019s contributions change over time could yield new knowledge about how antisocial personalities develop (Bor\u00a0& Peterson, 2021) and, more importantly, knowledge about when and why people evolve out of antisocial patterns. This will help to \ninform moderation policies that are less myopic than those that focus on the removal of specific comments, and to provide more sustainable solutions for how we might design public spaces that yield the kinds of discussions (and deviance) that achieve a balance between individual and collective ambi -\ntions, thereby being more accommodating to the inherent social processes that underlie online posting and commenting.\nNew applications in automated text analysis are likely to propel even more \nadvances. Text similarity techniques such as TF-IDF ( Bail, 2016) could be \nused to measure the extent that one\u2019s posting behavior conforms to or devi -\nates from their previous posts or from other people\u2019s posts on the same dis -\ncussion thread. Large language models, such as those created by OpenAI, can be used to construct more nuanced annotations and interpretations of text that are then applied at scale.\n5 For example, a large language model \ncan be prompted to detect whether or not two sequential comments are in agreement or disagreement, which can be an important moderator in addi -\ntion to social votes for whether descriptive norms are propagated. This could provide more contextual information that can be used to investigate both moderators and catalysts of antisocial language spread. The validation of such language models for large-scale annotation is an important direction for future research.\nDespite the aforementioned advantages of these new data sources and text \nclassification techniques, there of course remain many barriers to their suc -\ncessful application in social science research. The findings we report here suggest that automated classifiers, and especially those obtained with the Per -\nspective API, can be used to generate similar behavioral findings as human \n246  Yotam Shmargad et\u00a0al.\nannotations on average. There will, however, inevitably remain variation in \nhow people interpret the contents of online messages and incivility in par -\nticular (Kenski et\u00a0al., 2020 ). One risk of the kinds of automated techniques \nwe deploy is that, by providing central tendencies in text interpretation, they \nremove variation in human interpretation, especially infrequent or extreme content, that may very well be informative sources or sites of social deviance. Finally, we note that people do not live their entire lives online, and there is an enduring variation across (as well as within) people in their engagement with online platforms. Our framework should thus be viewed as a starting point for incorporating online discussion data into the study of anti-sociality, and we encourage the concurrent investigation of multiple platforms, offline activities, and other measures obtained through more traditional instruments such as interviews and surveys.\nNotes\n 1 Retrieved November 22, 2023, from https://huggingface.co/civility-lab\n 2 More information on the attributes from the Perspective API, including those \ntrained on the New York Times comments, can be found here: Retrieved \nNovember 22, 2023, from https://developers.perspectiveapi.com/s/about-the-api- \nattributes-and-languages\n 3 That the rate of anti-sociality in comments starting a triplet does not differ sub -\nstantially from that of comments in general should not be viewed as evidence for a lack of social influence. This is because early comments will not necessarily start a triplet, as the triplets we constructed have the particular structure that allows for a test of our framework (that is, they originate and end with the same commenter with a different commenter sandwiched between them). For example, if the identi -\nties of the contributors of a string of comments are 1234546, then there will only be one applicable triplet (454) and it will not be found at the beginning of the set.\n 4 Upon further investigation, we discovered that the default input length limitations \ncan be circumvented with additional code. However, a complete reanalysis of the data was not possible at the time of this writing.\n 5 More information about OpenAI\u2019s API can be found here: Retrieved November 22, \n2023, from https://platform.openai.com/overview\nReferences\nBail, C. A. (2016). Combining natural language processing and network analysis to \nexamine how advocacy organizations stimulate conversation on social media. Pro-\nceedings of the National Academy of Sciences , 113(42), 11823\u201311828. https://doi.\norg/10.1073/pnas.1607151113\nBakshy, E., Rosenn, I., Marlow, C.,\u00a0& Adamic, L. A. (2012). The role of social networks \nin information diffusion. In Proceedings of the 21st international conference on \nworld wide web  (pp.\u00a0519\u2013528). ACM. https://doi.org/10.1145/2187836.2187907\nBarbera, P. (2015).  Birds of the same feather tweet together: Bayesian ideal point \nestimation using Twitter data. Political Analysis, 23(1), 76\u201391. https://doi.\norg/10.1093/pan/mpu011\nBor, A.,\u00a0 & Peterson, M. B. (2021).  The psychology of online political hostility: \nA\u00a0comprehensive, cross-national test of the mismatch hypothesis. American Politi-cal Science Review, 116(1), 1\u201318. https://doi.org/10.1017/S0003055421000885\nDetecting Antisocial Norms in Large-Scale Online Discussions  247\nBurrell, J.,\u00a0& Fourcade, M. (2021).  The society of algorithms. Annual Review of Soci-\nology, 47, 213\u2013237. https://doi.org/10.1146/annurev-soc-090820-020800\nCheng, J., Danescu-Niculescu-Mizil, C.,\u00a0 & Leskovec, J. (2014).  How community \nfeedback shapes user behavior. Proceedings of the Eighth International AAAI Con -\nference on Weblogs and Social Media (ICWSM) , 8(1), 41\u201350. Association for the \nAdvancement of Artificial Intelligence. https://doi.org/10.48550/arXiv.1405.1429\nCheng, J., Danescu-Niculescu-Mizil, C.,\u00a0& Leskovec, J. (2017). Antisocial behavior \nin online discussion communities. Proceedings of the Eleventh International AAAI \nConference on Web and Social Media (ICWSM) , 9(1), 61\u201370. Association for \nthe Advancement of Artificial Intelligence. https://doi.org/10.48550/arXiv.1504. \n00680\nCialdini, R. B., Reno, R. R.,\u00a0& Kallgren, C. A. (1990).  A\u00a0focus theory of norma -\ntive conduct: Recycling the concept of norms to reduce littering in public places. Journal of Personality and Social Psychology, 58(6), 1015\u20131026. https://doi.\norg/10.1037/0022-3514.58.6.1015\nCoe, K., Kenski, K.,\u00a0& Rains, S. A. (2014).  Online and uncivil? Patterns and deter -\nminants of incivility in newspaper website comments. Journal of Communication, \n64(4), 658\u2013679. https://doi.org/10.1111/jcom.12104\nDing, B., Qin, C., Liu, L., Bing, L., Joty, S.,\u00a0& Li, B. (2022).  Is GPT-3 a good data \nannotator? arXiv. https://doi.org/10.48550/arXiv.2212.10450\nDurkheim, E. (1893). The division of labor in society. The Free Press.Edyvane, D. (2020). Incivility as dissent. Political Studies, 68(1), 93\u2013109. https://doi.\norg/10.1177/0032321719831983\nElSherief, M., Kulkarni, V., Nguyen, D., Wang, W. Y.,\u00a0& Belding, E. (2018).  Hate \nlingo: A\u00a0target-based linguistic analysis of hate speech in social media . Proceed-\nings of the Twelfth International AAAI Conference on Web and Social Media (ICWSM), 12(1). Association for the Advancement of Artificial Intelligence. \nhttps://doi.org/10.48550/arXiv.1804.04257\nForestal, J. (2021). Beyond gatekeeping: Propaganda, democracy, and the organi -\nzation of digital publics. Journal of Politics, 83(1), 306\u2013320. https://doi.\norg/10.1086/709300\nFreelon, D., Bossetta, M., Wells, C., Lukito, J., Xia, Y.,\u00a0 & Adams, K. (2020). \nBlack trolls matter: Racial and ideological asymmetries in social media dis -\ninformation. Social Science Computer Review , 40(3), 560\u2013578. https://doi.\norg/10.1177/0894439320914853\nGoldberg, A.,\u00a0& Stein, S. K. (2018).  Beyond social contagion: Associative diffusion \nand the emergence of cultural variation. American Sociological Review, 83(5), \n897\u2013932. https://doi.org/10.1177/0003122418797576\nGolder, S. A.,\u00a0& Macy, M. W. (2014).  Digital footprints: Opportunities and challenges \nfor online social research. Annual Review of Sociology , 40, 129\u2013152. https://doi.\norg/10.1146/annurev-soc-071913-043145\nHaimson, O. L., Delmonaco, D., Nie, P.,\u00a0 & Wegner, A. (2021).  Disproportionate \nremovals and differing content moderation experiences for conservative, transgen-der, and black social media users: Marginalization and moderation gray areas. Proceedings of the ACM on Human-Computer Interaction (CSCW) , 5, 1\u201335. \nhttps://doi.org/10.1145/3479610\nJamieson, K. H., Volinsky, A., Weitz, I.,\u00a0 & Kenski, K. (2017).  The political uses \nand abuses of civility and incivility. In The Oxford handbook of political com-\nmunication\n (pp.\u00a0 205\u2013218). Oxford University Press. https://doi.org/10.1093/\noxfordhb/9780199793471.013.79_update_001\nJiang, S., Robertson, R. E.,\u00a0& Wilson, C. (2020). Reasoning about political bias in \ncontent moderation. Proceedings of the 34th AAAI Conference on Artificial Intel -\nligence, 34(9), 13669\u201313672. Association for the Advancement of Artificial Intel -\nligence. https://doi.org/10.1609/aaai.v34i09.7117\n248  Yotam Shmargad et\u00a0al.\nKenski, K., Coe, K., Rains, S. A. (2020). Perceptions of uncivil discourse online: An \nexamination of types and predictors. Communication Research, 47(6), 795\u2013814. \nhttps://doi.org/10.1177/0093650217699933\nKim, J. W., Guess, A., Nyhan, B.,\u00a0& Reifler, J. (2021). The distorting prism of social \nmedia: How self-selection and exposure to incivility fuel online comment toxicity. \nJournal of Communication, 71(6), 922\u2013946. https://doi.org/10.1093/joc/jqab034\nKim, K. K., Lee, A. R.,\u00a0& Lee, U. (2019).  Impact of anonymity on roles of personal \nand group identities in online communities. Information\u00a0 & Management, 56, \n109\u2013121. https://doi.org/10.1016/j.im.2018.07.005\nLapinski, M. K.,\u00a0& Rimal, R. N. (2005). An explication of social norms. Communica-\ntion Theory, 15(2), 127\u2013147. https://doi.org/10.1111/j.1468-2885.2005.tb00329.x\nLees, A., Tran, V. Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D.,\u00a0& Vasserman, L. \n(2022). A\u00a0new generation of perspective API: Efficient multilingual character-level transformers. In Proceedings of the 28th ACM SIGKDD conference on knowl-edge discovery and data mining (KDD 2022)  (pp.\u00a0 3197\u20133207). https://doi.\norg/10.1145/3534678.3539147\nLinvill, D. L.,\u00a0& Warren, P. L. (2020).  Troll factories: Manufacturing specialized dis -\ninformation on Twitter. Political Communication, 37(4), 447\u2013467.\nLofland, J. (1969). Deviance and identity. Prentice-Hall.Maratea, R. J.,\u00a0& Kavanaugh, P. R. (2012). Deviant identity in online contexts: New \ndirections in the study of a classic concept. Sociology Compass, 6(2), 102\u2013112. \nhttps://doi.org/10.1111/j.1751-9020.2011.00438.x\nMcDonnell, T. E., Bail, C. A.,\u00a0& Tavory, I. (2017).  A\u00a0theory of resonance. Sociologi-\ncal Theory, 35(1), 1\u201314. https://doi.org/10.1177/0735275117692837\nNg, L. H. X., Cruickshank, I. J.,\u00a0& Carley, K. M. (2022).  Cross-platform information \nspread during the January 6th Capitol riots. Social Network Analysis and Mining, 12(1), 133. https://doi.org/10.1007/s13278-022-00937-1\nOzler, K. B., Kenski, K., Rains, S. A., Shmargad, Y., Coe, K.,\u00a0& Bethard, S. (2020).  \nFine-tuning for multi-domain and multi-label uncivil language detection. Proceed-ings of the Fourth Workshop on Online Abuse and Harms , 28\u201333. https://doi.\norg/10.18653/v1/2020.alw-1.4\nPapakyriakopoulos, O., Engelmann, S.,\u00a0& Winecoff, A. (2023).  Upvotes? Downvotes?  \nNo votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit. Proceedings of the 2023 CHI Conference on \nHuman Factors in Computing Systems, 549, 1\u201328. ACM. https://doi.org/10.1145/  \n3544548.3580644\nPozzobon, L., Ermis, B., Lewis, P.,\u00a0& Hooker, S. (2023).  On the challenges of using \nblack-box APIs for toxicity evaluation in research. arXiv. https://doi.org/10.48550/\narXiv.2304.12397\nRains, S. A., Harwood, J., Shmargad, Y., Kenski, K., Coe, K.,\u00a0& Bethard, S. (2023a).  \nEngagement with partisan Russian troll tweets during the 2016 US presidential election: A\u00a0social identity perspective. Journal of Communication, 73(1), 38\u201348. \nhttps://doi.org/10.1093/joc/jqac03\nRains, S. A., Kenski, K., Dajches, L., Duncan, K., Yan, K., Shin, Y., Barbati, J. L., \nBethard, S., Coe, K.,\u00a0 & Shmargad, Y. (2023b).  Engagement with incivility in \ntweets from and directed at local elected officials. Communication and Democ-\nracy, 57(1), 143\u2013152. https://doi.org/10.1080/27671127.2023.2195467\nRains, S. A., Kenski, K., Coe, K.,\u00a0& Harwood, J. (2017). Incivility and political iden-\ntity on the internet: Intergroup factors as predictors of incivility in discussions of news online. Journal of Computer-Mediated Communication\n, 22(4), 163\u2013178. \nhttps://doi.org/10.1111/jcc4.12191\nRains, S. A., Shmargad, Y., Coe, K., Kenski, K.,\u00a0 & Bethard, S. (2021).  Assessing \nthe Russian troll efforts to sow discord on Twitter during the 2016 US election. \nDetecting Antisocial Norms in Large-Scale Online Discussions  249\nHuman Communication Research, 47(4), 477\u2013486. https://doi.org/10.1093/hcr/\nhqab009\nRimal, R. N.,\u00a0& Real, K. (2005).  How behaviors are influenced by perceived norms: \nA\u00a0test of the theory of normative social behavior. Communication Research, 32(3), \n389\u2013414. https://doi.org/10.1177/0093650205275385\nRossini, P. (2022). Beyond incivility: Understanding patterns of uncivil and intoler -\nant discourse in online political talk. Communication Research, 49(3), 399\u2013425. \nhttps://doi.org/10.1177/0093650220921314\nSadeque, F., Rains, S. A., Shmargad, Y., Kenski, K., Coe, K.,\u00a0& Bethard, S. (2019). \nIncivility detection in online comments. In Proceedings of the eighth joint confer -\nence on lexical and computational semantics (SEM 2019)  (pp.\u00a0283\u2013291). Associa -\ntion for Computational Linguistics. https://doi.org/10.18653/v1/S19-1031\nShmargad, Y. (2022). Twitter influencers in the 2016 US Congressional races. Jour -\nnal of Political Marketing, 22(1), 23\u201340. https://doi.org/10.1080/15377857.2018. \n1513385\nShmargad, Y., Coe, K., Kenski, K.,\u00a0 & Rains, S. A. (2022).  Social norms and the \ndynamics of online incivility. Social Science Computer Review , 40(3), 717\u2013735. \nhttps://doi.org/10.1177/0894439320985527\nSong, Y., Lin, Q., Kwon, K. H., Choy, C. H. Y.,\u00a0& Xu, R. (2022).  Contagion of offen -\nsive speech online: An interactional analysis of political swearing. Computers in \nHuman Behavior, 127, 107046. https://doi.org/10.1016/j.chb.2021.107046\nTontodimamma, A. Nissi, E., Sarra, A.,\u00a0 & Fontanella, L. (2021). Thirty years of \nresearch into hate speech: Topics of interest and their evolution. Scientometrics, \n126, 157\u2013179. https://doi.org/10.1007/s11192-020-03737-6\nUdupa, S., Maronikolakis, A.,\u00a0 & Wisiorek, A. (2023). Ethical scaling for content \nmoderation: Extreme speech and the (in)significance of artificial intelligence. Big \nData\u00a0& Society, 10(1). https://doi.org/10.1177/20539517231172424\nVogels, E. A. (2021). The state of online harassment. Pew Research Center. https://\nwww.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/\nZampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N.,\u00a0& Kumar, R. (2019). \nPredicting the type and target of offensive posts in social media. In Proceedings of \nthe 2019 conference of the North American chapter of the association for compu -\ntational linguistics: Human language technologies (pp.\u00a01415\u20131420). Association \nfor Computational Linguistics. https://doi.org/10.18653/v1/N19-1144\nDOI: 10.4324/9781003472148-11\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.In the middle of the day, on an early summer Sunday in 2016, an anonymous \nuser on 4chan\u2019s Politically Incorrect Board (/pol/) posts a link to a music video on YouTube which portrays the romantic story between a young female pop star and an African American man. The poster, outraged by the fact that the singer is normalizing interracial relationships, says \u201cshe\u2019s blatantly burning coal right in front millions of kids. When will this degeneracy end?\u201d and urges others on the board to manifest their outrage too. Soon after, other anonymous users start piling on in the 4chan thread, posting racist com -\nments about the pop star and the actor in the video, wondering why they hate America, and worrying about young girls following her example. At the same time, the anonymous users start posting hateful and harassing messages on the YouTube page where the video appears, in a coordinated attack.\nIt is March 2020. On /pol/, a bored high school student forced to attend \nschool remotely posts the link to the Zoom room for his English lecture: \u201cAnyone wanna crash our online lesson?\u201d Shortly after, a mob of anony -\nmous trolls storms the meeting room, shouting profanities and slurs, hijack-ing the share screen function to display pornography to the horrified teacher and students, and changing their profile names to those of other students in the class to make it more difficult to be identified and kicked out. The shocked teacher is helpless and resorts to ending the Zoom call to avoid fur -\nther disruption. Meanwhile, the attackers head back to the original thread on /pol/, posting screenshots of the meeting and reporting about what they did: \u201cAnyone heard me farting?\u201d \u201cHAHAHA that was great.\u201d Other messages celebrating the hilarity of the situation soon follow.\nThese are just two examples of coordinated aggression attacks. As part \nof our work studying polarized online communities for the past decade, we 11\nUNDERSTANDING THE PHASES AND \nTHEMES OF COORDINATED ONLINE AGGRESSION ATTACKS\nGianluca Stringhini and Jeremy Blackburn\nPhases and Themes of Coordinated Online Aggression Attacks  251\nhave seen hundreds of similar instances, and we have developed automated \nsystems to identify these attacks and collect data about them. In this chapter we discuss what coordinated aggression attacks look like, analyze the phases that attackers follow while carrying them out, and discuss common themes observed in our data. We focus on attacks originating from 4chan\u2019s Politi -\ncally Incorrect Board (/pol/) as previous work has shown that this site and its devotees are particularly active in this practice ( Hine et\u00a0al., 2017). We look at \nattacks targeting YouTube videos and online meeting rooms (e.g., Zoom and Google Meet), as they appear particularly frequently on the 4chan platform (Hine et\u00a0al., 2017; Ling et\u00a0al., 2021).\nLike previous research on networked harassment, we find that online \naggression is a social activity ( Marwick, 2021), in accord with the social pro-\ncesses theme of this volume. Unlike previous work that identified attackers selecting their targets within the same platform ( Lewis et\u00a0al., 2021 ), we find \nthat attackers usually target victims on secondary platforms. Like previous work, we find that online aggression attacks often appear to be motivated by misogyny and racism (Antunovic, 2019; Tynes et\u00a0al., 2018 ). At the same \ntime, we also find that disruption for the sake of it (and for its \u201centertain -\nment\u201d value) is often the focus of these attacks, particularly in the case of coordinated attacks against Zoom meetings (i.e., Zoombombing). In these \ninstances, we find that inflammatory language like racist and hateful speech is an efficient tactic to cause havoc instead of being the apparent focus of \nthe attack. Similarly, while hurting the victim is the apparent goal in some instances, many attackers seem to be motivated by some perverse enjoy-ment in unleashing chaos; that is, they do it \u201cfor the lulz\u201d (for amusement, for laughs; see Phillips, 2015). This resonates with previous work studying the underlying psychological elements of online attackers, which found that trolls often act for the sake of enjoyment (Buckels et\u00a0al., 2014).\nContrary to previous work on networked harassment ( Marwick\u00a0& Caplan, \n2018), we find that coordinated harassment is not only made up of explicitly hateful content but also that, often, attackers attempt to cause disruption by pretending to be legitimately concerned parties in the conversation. This concern trolling is designed to bait real users into conversations that have the goal of shutting down legitimate discussion and potentially lure them into endless arguments (DiFranco, 2020).\nWe also discuss important challenges faced by the research community and \nby practitioners when trying to mitigate coordinated online aggression and online hate activity in general.\nThe rest of the chapter is structured as follows: First, we present our meth -\nods, comprising computational techniques that we developed that detect coordinated attacks and the synchronization of indicators that exemplify them, and we describe our data that illuminate the activities that comprise the attacks. We then identify the phases by which coordinated aggression attacks \n252  Gianluca Stringhini and Jerem y Blackburn\nevolve and show some examples and general themes that we have observed. \nNext, we dig deeper into these themes, discussing, for example, what might be the attackers\u2019 motivations as well as the minimal influence of anonymity on attacking behavior. Finally, we discuss challenges and opportunities for researchers and practitioners working toward mitigating coordinated online harassment, including the unintended consequences of deplatforming.\nDetecting Coordination\nMethods and Data\nThis work is the culmination of over a decade\u2019s worth of effort to under -\nstand the modus operandi and motivation of coordinated online attackers. \nTo identify social media posts and threads that call for coordinated online aggression attacks, we use a combination of quantitative and qualitative techniques. However, before continuing, it is important to discuss a compo -\nnent of our research efforts that usually goes unreported: Our data collection systems.\nWe have developed tools to automatically collect data from a variety of \nsocial media platforms (e.g., 4chan, Reddit, Twitter, and YouTube). Since 2016, we have collected billions of social media posts ( Baumgartner et\u00a0al., \n2020; Papadamou et\u00a0al., 2020; Papasavva et\u00a0al., 2020). Building these types \nof reliable and robust systems is as much of an art as it is an engineering exer -\ncise. For example, consider that 4chan is an ephemeral platform: By design, posts expire and are deleted. What this means is that, in practice, we must design a system that collects all data, not just data that we think is relevant or available at the time of collection. To complicate things further, the pro -\ncess that controls when a post is deleted is driven by activity on the site, as opposed to being a preordained expiration date. In practice, this means that our systems must be dynamic and adapt to changes in user activity.\nOver the years, we have arrived at an extensible and powerful crawler \nconstruction toolkit of programmatic building blocks that enable the rapid development of new crawlers. A\u00a0crawler is an automated, continuous data collection system that dynamically adjusts a variety of parameters related to the data collection process itself. For example, a crawler for 4chan must regularly discover new content that needs to be collected while at the same time being robust with respect to the ephemeral nature of 4chan as well as the typical errors that occur when dealing with large-scale data traversing the Internet. One of the key insights behind this toolkit is that social media plat -\nforms, regardless of difference in affordances, have a lot in common, at least when it comes to data collection. For example, most social media platforms have rate limits that we must work within. That is, we are only able to make \nPhases and Themes of Coordinated Online Aggression Attacks  253\nrequests for data a certain number of times per second. Even for platforms \nthat do not have strict rate limits, we aim to be neutral observers and thus do our best to minimize the impact our crawlers might impose on the systems\u2019 performance. To this end, we have built a relatively complicated, reusable rate limiting subsystem. When writing new crawlers, we simply hook into our rate limiting subsystem, instead of having to write custom code for every crawler we build.\nIn addition to our crawler construction toolkit, we have, over the years, \ndeveloped a robust architectural software architecture design (a \u201cpipeline\u201d) that we build our crawlers around (see Figure\u00a0 11.1 for a high-level overview). \nThis architecture treats the crawling process as a series of jobs. For example, \nFIGURE\u00a011.1   Software Architectural Design (\u201cPipeline\u201d) of Crawler Processes\n254  Gianluca Stringhini and Jeremy Blackbur n\none job could be collecting all the posts made in given 4chan thread, and \nanother job could be collecting the images the posts link to. Once the crawl -\ning process is broken up into different logical jobs, we can then use a sched -\nuler to independently control how and when each job is executed. Because each job is independent, we can run many instances of the same type of job concurrently. That is, we can collect the posts from several threads at once, while at the same time collecting images from other threads. Furthermore, we can adapt to changing conditions (e.g., more or less posting activity) by adjusting when a job is scheduled to run. As an added bonus, this archi -\ntecture, while being \u201ccloud native\u201d and scaling to multiple worker servers, also scales down to run on cheap computer hardware, making it suitable for rapid development and testing before deployment into our production environment.\nDetecting Synchronization\nCoordinated aggression attacks take place through traceable collaborative activities and coordination mechanisms. Our observations indicate that attackers usually start a post calling for an attack, within a certain platform, and that this post generates an aggregation thread where users partaking in \nthe attack elsewhere return to share insights about the raid, provide feedback about what is happening, and to help others circumvent mitigation steps put in place by the platforms and the content creators. Coordinated aggression attacks often target content on other platforms. For example, the inception of an attack appears on 4chan, from which an attack is directed at YouTube videos, online meetings, or Twitch streams, toward which attackers have been invited to harass the video\u2019s creator and/or other meeting participants. Our data analysis challenge is to identify many of these aggregation threads and to decipher the patterns of behavior across sites that confirm and illus -\ntrate the cross-platform coordination of aggression attacks.\nAs part of our approach, we first look for posts that contain links to sec -\nondary platforms that are often targeted by these attacks. In this chapter, we limit our present analysis to YouTube videos and links to online meet -\nings, since YouTube is by far the most linked to from polarized online com-munities like 4chan (Hine et\u00a0al., 2017), and to online meetings because of the emergence of disruptive Zoombombing attacks observed early in the COVID-19 pandemic (Ling et\u00a0al., 2021). For YouTube, we look for social media posts containing links to youtube.com or youtu.be. We also expand shortened URLs, identifying the final landing page. For online meeting tools, we identify ten popular platforms (Zoom, Google Meet, Cisco Webex, Jitsi, Skype, Citrix GoToMeeting, Microsoft Teams, Google Hangouts, Bluejeans, and Starleaf) and look for links to those platforms (e.g., zoom.us). Since Zoom meetings can also be shared by ID instead of by links, we also look for \nPhases and Themes of Coordinated Online Aggression Attacks  255\nposts that include a meeting ID and potentially a passcode for a Zoom meet -\ning, even without an explicit link.\nOf course, most posts containing a link to a YouTube video or to an online \nmeeting platform are not calling for a coordinated aggression attack. To fur -\nther refine our investigations, we use two different techniques that we devel -\noped in our previous work (Hine et\u00a0al., 2017; Ling et\u00a0al., 2021).\nIn the case of YouTube videos, we have access to both the thread on 4chan \nthat called the attack and to the publicly visible user-generated comments \nthat were written in the YouTube videos\u2019 pages. By analyzing the timing of the comments posted on the video pages, we observed that the number of comments on YouTube increases immediately after the link to a video is posted on 4chan. Additionally, since 4chan threads are ephemeral, the thread discussing a certain video will be visible to other users only for a limited time, and we observed that comments spike during the lifetime of the thread and die off after the thread is removed. However, while this pattern is indicative of an increased activity on YouTube generated by 4chan, the phenomenon is not unique to aggression attacks. On the one hand, we expect that most content linked on social media will generate an increase in activity on the linked plat -\nform (Kujur\u00a0& Singh, 2016). What is unique about coordinated aggression attacks, on the other hand, is that attackers use the thread that calls for the coordinated attack as an aggregation point; they post comments related to the attack in real time, reporting back, for example, on their actions and the outcomes of them (Hine et\u00a0al., 2017). Based on this observation, comparing the timing of the posts made in the initial thread and in the attacked YouTube video\u2019s page shows specific cross-correlational timing patterns: Attacked videos show a higher degree of synchronization with the 4chan thread that linked to it, compared to videos that were linked on 4chan for purposes other than coordinated aggression. The strongest possible synchronization would occur when someone posts a comment on YouTube and instantly reports back on 4chan about what they just did. Obviously, this seldom happens, but we expect synchronization to be stronger for videos that are being attacked than for videos that are not being attacked, where people are just posting more innocuous comments without much coordination going on.\nTo further enhance confidence that videos that see a high synchronization \nin their comments to the 4chan thread that links to them indicate a coordi -\nnated aggression attack, we ran the following experiment. For each of the 19,568 YouTube videos linked on 4chan in our dataset (Hine et\u00a0al., 2017), we first calculated the lag of their comments in YouTube with the comments on the 4chan thread. Then, for each comment in the YouTube videos, we determined whether it contains hate speech by looking up its words against Hatebase.org, a crowdsourced hate speech lexicon (discontinued now but still available when this analysis took place). We considered a comment to contain hate speech if one or more words in it appeared in the Hatebase \n256  Gianluca Stringhini and Jerem y Blackburn\nlexicon. Our results indicated that a lower lag was associated with more \nhateful comments, showing that the cross-correlation metric is a good indica -\ntor of coordinated aggression attacks (Mariconti et\u00a0al., 2019). Manual analy-sis of the 4chan threads that included links to those videos confirmed that they were indeed calls for coordinated aggression.\nIn the case of threads calling to attack online meetings (e.g., Zoombomb -\ning), we cannot apply the same techniques adopted for YouTube video pages, since we do not have access to the meetings (and the concept of persistent comments does not really apply in this context). For this reason, to identify threads calling for Zoombombing, we apply a qualitative approach: Four annotators performed thematic coding, identifying which threads are likely calls for attacks, and resolving disagreements through discussion (Ling et\u00a0al., 2021). We find that identifying these kinds of threads is easy for trained anno -\ntators, who achieve perfect agreement (Cohen\u2019s \u03ba\u00a0= 1.0). In total, we identi -\nfied 123 online meetings that were disrupted through calls for coordinated online aggression on 4chan, in addition to 428 YouTube videos, accounting for 551 confirmed calls for coordinated aggression attacks.\nWhat Attackers Do and How: A\u00a0Taxonomy of the Phases  \nof Online Coordinated Attacks\nOur study of the social process surrounding coordinated online aggression \nbetween 4chan\u2019s /pol/ and their targets on secondary platforms has allowed us to discover and describe several phases that these attacks go through. We identify five phases that characterize coordinated aggression attacks: (1) Call for attack, (2) preparation, (3) execution, (4) reporting back, and (5) wrap up/celebration. This section analyzes these phases in detail, identifying dif -\nferences and commonalities between the attacks that target YouTube videos and those that target online meetings. Later in the chapter, we further analyze different themes that emerge from our data.\nCall for Attack\nAs illustrated in the two examples at the beginning of this chapter, a coor -\ndinated aggression attack begins with a user starting a new thread in which the user calls for the attack. This initial post both identifies the target and makes it known to other members of the community, and the thread that evolves from that post serves as an aggregation and discussion point for the further phases of the attack. The post containing the call for attack usually comes with a link to the online resource to target and a short message. This message can be a clear indication of what the user wants others to do (e.g., \u201cMy English class, come in and trolley for a while\u201d), an inflammatory mes -\nsage designed to enrage other users and encourage them to join (e.g., \u201cGod \nPhases and Themes of Coordinated Online Aggression Attacks  257\nfucking dammit! She\u2019s blatantly burning coal right in front millions of kids. \nWhen will this degeneracy end?\u201d), or a dog whistle (e.g., \u201cYou know what to do\u201d) designed to evade content moderation, which often forbids these calls for attacks. In many cases, the call for attack only contains the external resource (e.g., the YouTube link) and a picture of the victim (e.g., a female influencer), which, we have observed, are often enough for /pol/\u2019s users to understand what is wanted of them.\nIn some cases, the attacker posts some details about the victim(s) with the \ngoal of encouraging others to pile on and target them based on their gender, sexual orientation, race, etc., as well as making the purpose of the attack more explicit (e.g., \u201cAnyone wanna join our online lesson? Our teacher is Black. Its gonna be in 20 mins,\u201d \u201cwe must invade this class of lib shills!,\u201d \u201cWhat\u2019s your opinion on this kosher conservative?\u201d).\nIn other cases, however, the calls for attack offer no indication of the spe -\ncific qualities of the victims. In those cases, instead, the goal of the attack seems to be the attack itself. The presence of these types of attacks suggests that coordinated aggression is sometimes performed in order to provide some entertainment value (\u201cfor the lulz\u201d) which transcends the aim of causing harm to the victims (e.g., \u201cif you want to come fuck with my apartment com -\nplexes yoga class be my guest. It\u2019s also being recorded so have at it\u201d), giving an easy distraction to the person calling for the attack from the mundane tasks of daily life (e.g., \u201cFeel free to fuck with my working meeting. Bored as fuck\u201d).\nPerhaps surprisingly, we have found that most calls for attacks are not \nplanned ahead of time but are called for in conjunction with events that are happening in real time or in the near future (e.g., scheduled Zoom meetings). Even those that do not target real-time content are carried out shortly after the call is made, although this might be a particular characteristic of 4chan threads, which are ephemeral in nature, which persist for 47 minutes on aver -\nage (Hine et\u00a0al., 2017 ) and make it challenging to elaborate long-term plans.\nFinally, it is important to note that any issues or resentments between the \nuser that called for the attack and the victim are not always disclosed. In fact, we have seen instances of failed calls for attack where the response from other users is not just unenthusiastic or even subdued but quite explicit statements that they are not interested in participating in attacks that directly benefit the caller (e.g., we\u2019re \u201cnot your personal army.\u201d)\nPreparation\nBefore an attack, offenders often coordinate to improve their effectiveness. We often see anonymous users post additional information about the vic -\ntim on the coordination thread, which goes beyond aspects of the particu -\nlar resource being attacked such as their YouTube video. The additional \n258  Gianluca Stringhini and Jerem y Blackburn\ninformation may include personal information (i.e., doxxing) or the victim\u2019s \nother social media handles. In many instances, attackers spend considerable effort posting offensive comments about the victims on the original 4chan thread, either to further motivate the attack or for the enjoyment of other attackers, rather than to use as ammunition against the victim, since the vic -\ntim will probably never see them (an important point emphasized by Walther, this volume). In the case of Zoombombing, the person who called for the attack is often an insider, who also provides additional information to help other attackers stay under the radar and to make it difficult for the meeting host to identify them and kick them out. For example, attackers are often instructed to adopt certain names, which belong to the legitimate students of the remote class being attacked, so that the teacher will have a hard time identifying who is a real student and who is an attacker and will allow the attack to continue for a longer time.\nExecution\nWhen an attack starts, attackers will carry out their disruptive activity. We find that these actions are often disjointed, and we do not observe much coordination between attackers with respect to the specific hateful content they post. Actions seem to have the goal of maximizing chaos and disruption and potentially to harm the victims. This is in contrast with other types of trolling activity, like state-sponsored trolling, where multiple attackers coor -\ndinate closely to build arguments and sow discord in online groups ( Saeed \net\u00a0al., 2022).\nThe way in which the attack is carried out largely depends on the affor -\ndances offered by the target platform. On YouTube, attackers post hate-ful comments below the video that they are targeting. With online meeting platforms, they make use of the variety of modalities that are available to them, from annotating on-screen content, to screaming audible obscenities through the microphone, to taking over the screen-sharing function and showing pornography. During the attack, we observe that attackers fre-quently ask others to perform certain actions to maximize disruption, for example, to perform lewd acts on camera (e.g., \u201cSomeone join with their dick out and make this interesting. I\u2019m bored\u201d), show pornography (e.g., \u201cSomeone can also print out a hardcore pic and hold it up for screenshot \u201d),  \nor shout profanities (e.g., \u201cuse your damn mic\u201d). These requests are usually not targeted at any particular victim but seem to be encouraged due to their efficiency in shocking legitimate participants, which in turn is more enter -\ntaining to the attackers. There are certain relatively standardized tactics that become specialized for the given platform of an attack, and these tactics align with the overall strategy of achieving chaos, in large part simply for its entertainment value.\nPhases and Themes of Coordinated Online Aggression Attacks  259\nReporting Back\nCoordinated aggression attacks are not unidirectional. As we have explained, \nthe thread that called for the attack tends to become an aggregation point that attackers use to discuss the attack itself, how it is unfolding, and eventu -\nally (as we will discuss) to celebrate and congratulate each other. We have observed many instances of attackers reporting back in the original thread about the disrupting actions that they just carried out, indicating that the social gratification surrounding coordinated aggression itself, more than harming a victim, might be their goal (see also Walther, 2022).\nThe attackers often write about their victims in the thread. In the case of \nZoombombing, this can span from general remarks (e.g., \u201cThere\u2019s a couple of lookers, a couple of old ones too,\u201d \u201che\u2019s probably the kind of teacher who sits reverse on a chair and is up to date with the cool kids\u201d) to gender-based attacks (e.g., \u201cthat is definitely a he\u201d). In the case of YouTube, where the attack activity is more asynchronous than in an online meeting, attackers often post hate speech in the original thread on /pol/ in addition to com -\nmenting on the video\u2019s page itself. These comments are often unsavory (e.g., \u201cShe looks like her face is made of solidified candle wax\u201d), misogynistic (e.g., \u201cCasting couch reject\u201d), or homophobic (e.g., \u201cHe likes dicks in his cereal\u201d).\nIn addition to comments about the victims, we find that attackers often \nreport back about what they themselves just did or about what happened in the attack. This is more common for Zoombombing than for YouTube attacks, which, we hypothesize, is due to the different level of openness and persistence between the two platforms: While hateful comments on a You -\nTube videos are there for everyone to see forever, disruptive activities in an online meeting are only visible to those that are participating in the meeting at that moment, and any evidence of them is gone once the meeting ends. Attackers targeting online meetings often report back about what they did (e.g., \u201cI hopped in and told them I\u00a0was spanking one out,\u201d \u201cI earraped all of them lol\u201d) or discuss notable events in the meeting (e.g., \u201csomeone started farting and the class was just dying of laughter,\u201d \u201cWho is roleplaying the pope?\u201d). This is usually done through text, but sometimes attackers even include screenshots from the secondary platform showing their contributions to the attack itself, providing more vivid testimony of their disruption.\nWhen executing coordinated aggression, attackers have to deal with the \nlegitimate owners of the resources that they target, who (sensibly) try their best to end the attack and reduce harm. In the case of YouTube attacks, hate -\nful messages are often caught and removed by the platform\u2019s moderation sys -\ntem, whether it is in real time or after the fact. In the case of Zoombombing, attackers often must deal with a meeting host who actively tries to defend the meeting, who is usually trying to figure out what is going on and how to regain control of the call. We have observed many posts from attackers dis -\ncussing how they had been kicked out of the Zoom room (e.g., \u201cHe banned \n260  Gianluca Stringhini and Jerem y Blackburn\nme the second I\u00a0joined and got my video set up,\u201d \u201cTried to join as Nate Hig -\ngers and got removed again wtf\u201d). Again, due to the private and ephemeral \nnature of online meetings, these threads become the only testimony to show the broader community that the attack happened at all and are the only way that attackers can signify to their community that they carried out a success -\nful attack.\nThe fact that this hate is shared among like-minded peers on /pol/ and is \nnot directly visible to the victims (unlike comments on the video or direct actions in the online meeting) might once again indicate that these hateful activities are aimed at building social capital within the community, exceed -\ning the wish to cause harm, orchestrated to gain recognition from their peers and enhance their status within the group.\nWrap up/Celebration\nWhen the attack has concluded, we find that attackers often continue discus -\nsion in the original /pol/ thread. They often congratulate each other over a job well done (e.g., \u201cClass ended. Good raid boys,\u201d \u201cGood job you got my class cancelled\u201d). As we will discuss later in the chapter, this is an essential element of the camaraderie aspect that characterizes coordinated aggression attacks. The other anonymous users usually react with hilarity and giving \u201chigh fives,\u201d often praising specific attackers (e.g., \u201cYou will be remembered\u201d).\nThemes from the Observed Attack Threads\nIn this section, we dig deeper into some of the common themes that we have observed in the instances of coordinated aggression attacks. We find tension between the anonymous nature of 4chan and the need for attackers to receive recognition for their nefarious actions. In fact, we find that the main reason why attackers seem to be carrying out coordinated online aggression attacks is to feel part of and contribute to a community and to enjoy themselves. In this setting, reporting back to the 4chan thread about the outcome of an attack and celebrating each other become key in enjoying the fruits of their labors. While certainly causing harm to the victims, the harm caused to the victims is often secondary, a sort of collateral damage (see Walther, this vol -\nume). We also find that 4chan\u2019s /pol/ board is not a monolith, but rather that its users have different sensibilities and goals. As such, calls for attacks often fail, with users openly disagreeing with the practice of coordinated aggres -\nsion as a whole or with the chosen victim.\nThe Impact of Anonymity on Coordinated Online Aggression\n4chan epitomizes the concept of anonymous platforms. While most platforms require accounts for users to post content, there are no accounts whatsoever \nPhases and Themes of Coordinated Online Aggression Attacks  261\non 4chan. This means that it is not possible for outside parties or even for \nthe users of the platform to know who posted what, aside from a temporary identifier that is given to each user in threads to identify different parties in the conversation. After the thread is gone from view, these identifiers lose any meaning, and the same user posting on a different thread will get a different identifier (Hine et\u00a0al., 2017).\nPrior research has argued that anonymity facilitates online hateful activ -\nity (Lapidot-Lefler, 2012; Rohlfing, 2014), and we tend to concur. Being \ncompletely anonymous allows attackers to be almost entirely free from con -\nsequences; other users will not be able to identify the perpetrators of coor -\ndinated aggression attacks and hold them accountable for their actions. The absence of accounts also makes it harder for the platform to suspend a par -\nticular user (although tightly policing the platform is not practiced in 4chan to begin with).\nEven where accounts do exist, such as on YouTube, attackers often create \nthrow-away accounts, whose suspension is more of a nuisance than a deter -\nrence, let\u00a0alone a solution. The main pain point in losing such a social media account is that any reputation associated with that account or connections built over time is also lost. In the case of coordinated aggression attacks, it is more appropriate to think of participation as hobby. Attackers just want to have fun. Considering that 4chan caters to the \u201cgamer\u201d demographic in general, we speculate that having to create a new account is not terribly dis-similar to having to create a new character in a free-to-play video game.\nThe case of Zoombombing is slightly different, because the hosts of online \nmeetings often have the ability of mandating that participants are logged in, sometimes even restricting participation to only users within an organization (e.g., those with a university email account) ( Ling et\u00a0al., 2021). If set up this \nway, online meetings become protected from the kind of aggression attacks that we describe in this chapter. This is not feasible for all meetings, though, since some gatherings need to be open to the public. Also, our study looked at online meetings at the beginning of the pandemic, when the entire world was forced to move activities online, and is therefore a testimony about what happens when abrupt technological changes are forced on people without adequately preparing them. Most hosts of online meetings had no training, or indeed any clue, about how to secure their meetings, opening them to attacks.\nAnonymity can also be a double-edged sword for attackers, because with-\nout explicit accounts, it is not possible for them to later claim credit about their actions and build their reputation among other haters. There is no con -\ncept of likes, follows, or retweets on 4chan. For this reason, attackers go out of their way to make sure that their nefarious actions are recognized and celebrated by the community. As a side effect of anonymity, actions are what is celebrated on 4chan, rather than who performs them. It is almost \n262  Gianluca Stringhini and Jerem y Blackburn\nas if the community is a hive mind, and faceless attackers are celebrated for \ntheir contribution in carrying out the greater goal of causing havoc. When a thread eventually dies, so do any relationships its users might have forged. In turn, this means that the full richness of these fleeting relationships must be savored quickly, before they are lost to the ether forever. Unlike most social media platforms, and indeed the human experience in general, relationships on 4chan are explicitly ephemeral and, in this way, is a rather unique social \nprocess. This, along with anonymity, exposes a facet of what it means to be a social creature that is seldom experienced in the real world. On the Internet, nobody knows you\u2019re a dog, but on 4chan, they don\u2019t know or care. You shared the experience. That\u2019s enough.\nThis lack of persistent fame can be reconciled when considering how /pol/ \n(and 4chan at large) has a (mostly) unwritten lore, akin to an oral tradition. Things like screenshots of threads that are later posted in other threads as well as spreading to mainstream media, having direct knowledge of previous successful attacks, an ability to share this knowledge with (and potential direct the actions of) future attackers, etc., are thus likely to serve as proxies for some of the ways that social capital is spent in scenarios with long-lasting relationships. While it is not possible to keep track of who did what when carrying out an attack, the actions of attackers can become part of the com -\nmunity\u2019s culture (see DeKeseredy, this volume).\nCoordinated Aggression as a Form of Camaraderie\nPrevious notions of networked harassment considered attacks to be a one-way street, with attackers directing hate toward their victims presum-ably with the exclusive goal of causing harm ( Marwick, 2021; Snyder et\u00a0al., \n2017). This assumes that once the attack is done, people will just move on and stop discussing it.\nOur results, however, paint a different picture: The social process of carry -\ning out a coordinated aggression attack seems to be as important or perhaps even more important than the harm it causes (see also Walther, this volume). Attackers pile messages on their victims on the 4chan thread, too, but this is for the other aggressors to see and further comment upon, as those mes-sages are never expected to reach the victim to cause additional harm. In the case of Zoombombing, we observe that attackers often report back about what they did during the attack and provide each other advice on how to be more successful in disrupting the meeting, making the practice of aggres -\nsion look like a form of bonding. Its purpose is to be part of a community and to see oneself as a successful member of it. This resonates with previous work that observed that harassers on social media are motivated by earning approval and praise from their peers ( Marwick\u00a0& Caplan, 2018; Walther, \nPhases and Themes of Coordinated Online Aggression Attacks  263\n2022). Our work shows that approval seeking explicitly manifests in 4chan \nthreads, where even though attackers are essentially finished once they have executed the attack, they are as much interested in celebrating the harm they caused as they were in causing it.\nConcern Trolling\nTraditional definitions of networked harassment consider explicit hateful or otherwise harmful activities toward a victim like hate speech, doxxing, and revenge porn (Marwick\u00a0& Caplan, 2018). This is reflected in our data, where we see attackers directing hateful speech toward their victims. However, coordinated aggression does not have to be explicitly hateful to cause disrup -\ntion. In our work, we find that attackers of YouTube videos often express what looks like legitimate concern about a sensitive topic, with the goal of baiting the content creator into replying to them or luring unwitting users into a conversation that could later be derailed by the attackers.\nWe often observe our attackers post YouTube comments, raising concerns \nabout censorship and free speech (e.g., \u201cWhat a joke! Everyone you don\u2019t agree with is a Nazi,\u201d \u201cLuckily there are places on the Internet where free speech still exists\u201d) or generic comments designed to attract responses by other users (e.g., \u201cI\u2019m shocked this video is still up,\u201d \u201che must be proud of himself\u201d). These comments look completely harmless, but they take on a completely different meaning when viewed not in isolation but rather as part of a larger coordinated aggression attack. Identifying these comments as potentially harmful is very hard (if not impossible) to do for a human, but our automated techniques (which look for synchronization of seemingly unrelated comments) can help expose them.\nVictim Targeting as a Vehicle for Disruption\nCoordinated aggression attacks against YouTube videos are usually directed at the video\u2019s creator, who is often singled out because of their gender, race, sexual orientation, or political opinion. We find similar elements in Zoom -\nbombing attacks, where the person calling for the attack sometimes points out demographic elements of the victims and participants in the targeted meeting (e.g., \u201cHurry hurty join and yell. Teacher is black\u201d). We also observe instances of participants joining online meetings and commenting on specific traits of the meetings\u2019 participants (\u201cIs the teacher Jewish?,\u201d \u201cThat is defi -\nnitely a dude\u201d).\nAnalyzing the discussion on the 4chan thread, however, one gets the \nimpression that these expressions of hate against women, queer people, and racial minorities are primarily used as a tool to maximize disruption; the \n264  Gianluca Stringhini and Jerem y Blackburn\nharm it causes to the victims is just a secondary goal, where the primary one \nis the enjoyment of the attackers\u2019 mischief. Hate speech and slurs are easy vehicles for laughter and have a strong shock factor and are therefore likely to cause a vehement response by victims, which in turn increases enjoyment among the perpetrators, who go back to the 4chan thread to make fun of it (e.g., \u201chave you seen their face?\u201d).\nPremediated or Opportunistic?\nPerhaps motivated by this need for instant gratification, we find that coordi -\nnated aggression attacks are rarely premeditated, but are assembled ad hoc, \nspontaneously in real time. In the case of online meeting, the calls are made to target meetings that are either already in progress or that are about to start. In fact, we only found one instance calling for an attack on a live streamed political rally scheduled for a later time (i.e., formally planned), and we have no indication that the attack was successful. In the case of You-Tube, attackers could potentially post their hateful comments at any point in time, but we observe a tendency for attackers to stick together and post their comments in waves, correlating with the lifetime of the 4chan thread. This might be a side effect of 4chan threads being ephemeral: If the thread is not available anymore, attackers no longer have a reference to the target. It could also mean that what attackers are after is the social camaraderie that comes with attacking a victim together and that sending hateful comments in isolation outside of the time when the attack is supposed to happen is less social and unentertaining.\nShort Attention Span\nMost of the Zoombombing attacks that we observed are not very long lived. This seems to be the case for several reasons. First and foremost, if an attack does not immediately provoke a response from other attackers or victims, attackers deem any additional effort a waste of their time; this is a form of entertainment, and if the attack does not provide instant gratification, attack-ers will move on and find a different victim. There are plenty of other online interactions on which to spend energy. Second, even when a response does come from victims, and attackers get something interesting to report back on the 4chan aggregation thread, the responses might cease being \u201centertaining\u201d at some point. In that case, attackers might lose interest and move on, to look for more rewarding targets.\nAnother interesting aspect that we observe is that the community does not \nseem to keep a collective \u201cmemory\u201d of past attacks, possibly because threads on 4chan are ephemeral. For this reason, we sometimes see the same You -\nTube videos being picked as targets multiple times, perhaps because they are easy targets that provide a high entertainment value.\nPhases and Themes of Coordinated Online Aggression Attacks  265\nNot Your Personal Army\u00a0\u2013 NYPA\nFrom our description and analysis, it might appear that coordinated online \naggression works like a perfectly oiled machine, with attackers collaborating to deliver harm and disruption with great effectiveness. While this is often the case, we observe that users on /pol/ are far from uniform and do not always act upon calls for coordinated attacks. For the Zoombombing threads in our dataset, we find that 46 out of 123 calls for attack did not receive any further replies, likely becoming moot. This can be explained by the fact that most calls for Zoombombing attacks are made for meetings that are happening in real time, and there might not have been any user on the /pol/ board looking for that kind of thrill at the time. From a theoretical perspective, this aligns with the Routine Activities Theory framework of environmental criminology, where a suitable target and a motivated offender need to converge for a crime to happen ( Mir\u00f3, 2014). With Zoom meetings having a short duration and the \nmedian thread lifetime on /pol/ being 47 minutes ( Hine et\u00a0al., 2017), it is plau-\nsible that many potential attackers would not see the call for attack in time to act upon it. Note that we could not perform a similar analysis for the calls for attacks against YouTube videos since the cross-correlation method that we used to extract the threads needs more than one post per thread to work.\nIn addition to calls for Zoombombing that never receive a response, we \nfind 20 cases where /pol/ users actively refuse to participate in an attack, calling it unethical, or simply insulting the person who called for it instead (e.g., \u201cYour teacher works hard to give you an education and this is what you give them,\u201d \u201cI\u2019m too lazy. And disagree with your morals you are in college you want us to troll other people who are having to spend their own money to attend school to do better in life\u201d). In one case, an anonymous user stated opposition because of disagreement with the choice of the victim (\u201cNo because your teacher looks young and hard working so fuck you. Post a Boomer teacher\u201d). A\u00a0common phrase that we encounter in this setting is \u201cNYPA\u00a0\u2013 not your personal army,\u201d indicating that the user who is calling for the attack should handle their dirty work instead of asking for help on the /pol/ board. This shows that not all /pol/ users are motivated to carry out coordinated aggression attacks or enjoy the entertainment factor of it, giv -\ning us a glimpse at a more variegated set of motivations and interests than one might have originally anticipated. We find similar opposition messages posted in calls for attacks against YouTube videos, too (e.g., \u201cmust suck to live a life of impotent rage over shit that doesn\u2019t matter like music videos how much of a fucking loser are you, OP?\u201d)\nChallenges in Automatically Moderating Coordinated  \nAggression Attacks\nWe conclude this chapter by discussing potential challenges that we identi -\nfied in effectively moderating coordinated aggression attacks. We first discuss \n266  Gianluca Stringhini and Jerem y Blackburn\nthe fact that the coordinated behavior studied in this chapter is not unique \nto online hate, and that 4chan\u2019s Politically Incorrect Board has in the past carried out coordinated operations to subvert the actual functionality of Internet Platforms. We then reason about deplatforming, which is a popular countermeasure against online hate but could have potentially unintended consequences, creating new safe havens for attackers to coordinate and carry out inter-platform attacks. Finally, we discuss the challenges in dealing with concern trolling, stemming from the fact that the content moderation process developed by social media companies is geared toward identifying and block -\ning explicit hate.\nCoordinated Attacks Can Go beyond Harassment\nThis chapter showed that the coordination by anonymous users on /pol/ plays an important role in the success of coordinated aggression attacks. The same social dynamics are at play in other endeavors embarked on by /pol/ users, which go beyond targeting a single victim or a small group but have the more ambitious goal of subverting the entire order of online platforms.\nIn mid-2016, Jigsaw, a Google-affiliated nonprofit focusing on sociotechni-\ncal issues, announced the development of a machine learning tool to detect toxicity. 4chan\u2019s /pol/, being a nexus of online toxicity, was understandably alarmed. Instead of taking this threat sitting down, /pol/ participants devised a response they called \u201cOperation Google.\u201d The idea was to use words like \u201cGoogle\u201d and \u201cSkype\u201d in place of racial slurs when posting online. While this might seem like an odd response, it is a form of attack known \u201cdata poi -\nsoning\u201d in computer security circles ( Fang et\u00a0al., 2020 ; Si et\u00a0al., 2022 ). The \ncore idea is that machine learning models are trained on large amounts of data, and that by using innocuous words like \u201cGoogle\u201d and \u201cSkype\u201d instead of actual slurs, a model to detect toxicity would learn that \u201cGoogle\u201d and \u201cSkype\u201d are toxic themselves.\nThis operation resulted in a massive spike in the use of replacement words \non /pol/ for about a week, at which point, for some reason, they returned to their normal levels. When looking for an explanation within the empirical data, we saw that there was almost no adoption of the replacement words outside of 4chan itself. When looking at posts, qualitatively, we discovered that 4chan users themselves decided that Operation Google was not a suc -\ncess. Even in response to its initial proposal, users had lamented that it was dumb and destined to failure. This is a strong indication that while trolls\u2019 swarming behavior might make it look like they operate as a hive mind, there is dissent even down to the level of whether or not a particular campaign is worth pursuing in the first place.\nAlso in 2016, Microsoft released an artificial intelligence chatbot called \nTay, which was designed to learn from its audience and reply to queries on Twitter (Neff\u00a0& Nagy, 2016 ). The users of /pol/ took it upon themselves to \nPhases and Themes of Coordinated Online Aggression Attacks  267\nhijack the bot and turn it racist. Through online coordination similar to the \nones observed in the attacks described in this chapter, 4chan users managed to teach the bot to state that the Holocaust was made up, and to post other inflammatory statements, forcing Microsoft to take it down only 16 hours after its release.\nAt the time of writing this chapter, /pol/\u2019s users are targeting the new tech -\nnological frontier of artificial intelligence in the forms of large language mod -\nels (Wei et\u00a0al., 2022) and vision models (Khan et\u00a0al., 2022). The developers of these models have put safeguards in place to prevent them from generat -\ning hateful and racist content ( Shen et\u00a0al., 2023 ). However, it is possible to \ncircumvent these restrictions by either issuing specific requests (i.e., prompts) (Shen et\u00a0al., 2023) or finding words that, albeit harmless, generate a toxic response (Si et\u00a0al., 2022 ). This can be done due to the fact that these models \nare trained on huge real-world datasets from the Internet and are therefore bound to contain explicit or implicit hate. This type of attack on large lan -\nguage models, even at small scale, has only recently become a focus of the computer security research community (Shen et\u00a0al., 2023; Si et\u00a0al., 2022). At \nthe time of this writing, however, building AI models to defend against this type of attack appears to be a Sisyphean task. We believe that we will witness successful attacks against these models being orchestrated by /pol/ and simi -\nlar communities not just in the coming months but also for the entire deploy -\nment lifespan of current state-of-the-art large language model architectures.\nThese examples show that research into online hate should continue study -\ning the social dynamics of polarized communities on /pol/, not only those geared toward harassment but also those that have a different goal.\nDealing with Deplatforming\nA common solution against aggressors is to suspend their accounts, and we have seen platforms like YouTube and Twitter adopt this solution often. This makes sense when the attackers and their victims reside on the same plat-form; suspending someone\u2019s real account makes it difficult for them to keep operating. In fact, previous work on networked harassment operated under this assumption that attackers would both be members and perpetrators in the same online community (Marwick, 2021).\nHowever, our analyses show that these attacks are often orchestrated on \nplatforms where moderation is virtually nonexistent, and as we have men -\ntioned, the accounts that attackers must use to post and cause harm on main -\nstream platforms like YouTube are usually throwaway ones. In this context, suspending the accounts that are used to deliver the attacks on the secondary platform would merely be a nuisance to the attackers, who could regroup and create new ones. Account suspension would have a very limited effect.\nAnother popular countermeasure adopted by platforms against online \nhate is deplatforming, where entire communities are suspended (Buntain \n268  Gianluca Stringhini and Jerem y Blackburn\net\u00a0al., 2023; Chandrasekharan et\u00a0al., 2022 ). Following assumptions in pre -\nvious work on networked harassment, suggesting that attackers operate \nwithin a single online platform, deplatforming should work, and in fact research shows that this mitigation strategy reduces hate speech on the origi-nal social media platform ( Jhaver et\u00a0al., 2021). However, our research has \nfound that deplatformed communities do not disappear but rather migrate and create their own platforms, out of the eye of moderators (Horta-Ribeiro et\u00a0al., 2021). After these migrations, we have found, although the size of the community decreases, remaining users become more active and more toxic (Horta-Ribeiro et\u00a0al., 2021). This raises the question of whether these communities, rather than specific platforms, become safe havens for aggres-sors, providing a place for aggregation and as the origination point for fur -\nther coordinated aggression attacks, similar to what we have seen in /pol/. Another way to conceptualize this is that social processes are distinct from their technological platforms.\nDealing with Concern Trolling\n\u201cDo not feed the troll\u201d is a popular adage ( Center for Countering Digital Hate, \n2019), but it becomes challenging to live by this when the line between what is trolling and what is legitimate activity becomes almost indistinguishable. Concern trolling is designed to make attackers appear like concerned users, and victims themselves. This type of trolling is difficult to identify even by a trained eye, as it is not easy to distinguish between complaints made in good versus bad faith. This impairs the effectiveness of content moderation, which has been designed to identify explicitly hateful content or other explicitly pro -\nhibited content such as nudity and calls for violence ( Karabulut et\u00a0al., 2023 ). \nMore research is needed to better understand concern trolling and to develop suitable approaches to identify it and block it on social media platforms.\nWe have been personal victims of this type of attack, when trolls faked \nbeing concerned about a particular topic or discussion point but with the goal of causing harm. For example, trolls have sent emails to university admin -\nistration in which they pose as transgender people and claim that our work is transphobic. Concern trolling exploits the tendency of humans to believe or be moved by others who are espousing a view that they already held. In this specific example, the troll was exploiting the administration\u2019s presumed desire to protect a marginalized group. Universities are not well equipped to deal with this type of malicious activity and neither are online platforms.\nConclusion\nOnline hate in the form of coordinated aggression attacks has become one of the core threats enabled by the social media. Instant communication, where \nPhases and Themes of Coordinated Online Aggression Attacks  269\nphysical distance is meaningless, and anonymous communication, where \nusers are unidentifiable, have provided unheard-of opportunities to reach out and hurt someone. Moreover, the same tools used to cause harm act as a force \nmultiplier for attackers, enabling them to easily share tactics and celebratory feedback. In this chapter, we leveraged our years of experience exploring fringe online communities to look at the phases followed by attackers when carrying out online aggression stemming from 4chan\u2019s Politically Incorrect Board and analyzed themes and challenges that emerge from our data.\nWe found that although online hate targeted toward one or more victims is \none of the prevalent themes, attackers seem to be motivated by the camara -\nderie resulting from the social process of online aggression in and of itself. In addition to posting explicit hate, they record testimony on the 4chan threads calling for the attack about the disruptive activities that they took elsewhere, for the perusal and enjoyment of other anonymous users on the platform. This also indicates that attackers are looking for social approval, provided in part when attacks often terminate with a collective celebration of the havoc that was caused.\nWhile studying two forms of coordinated aggression attacks, targeting \nYouTube videos and online meeting rooms such as those on Zoom, we find that although the two types of attacks share many commonalities, they also present differences, mostly due to the different time constraints of the two platforms (i.e., asynchronous versus synchronous) and because of the differ -\nent level of openness (i.e., public versus private settings). In particular, attack -\ners targeting online meetings appear even more compelled to come back to the 4chan thread and post evidence of what they have done to disrupt the meeting, which otherwise would not be visible to other users who did not take part in the attack.\nThis work paints a multifaceted overview of coordinated aggression \nattacks on 4chan and identifies a set of open challenges in moderating them. We hope that these challenges will serve as an inspiration for other research -\ners studying online content moderation and will help the identification and development of more effective moderation practices.\nAcknowledgments\nThis work was partially supported by the National Science Foundation under Grants CNS-1942610, CNS-2114407, CNS-2114411, CNS-2247867, CNS-2247868, and IIS-2046590.\nReferences\nAntunovic, D. (2019).  \u201cWe wouldn\u2019t say it to their faces\u201d: Online harassment, women \nsports journalists, and feminism.\u00a0 Feminist Media Studies,\u00a0 19(3), 428\u2013442. https://\ndoi.org/10.1080/14680777.2018.1446454\n270  Gianluca Stringhini and Jeremy Blackbur n\nBaumgartner, J., Zannettou, S., Keegan, B., Squire, M.,\u00a0& Blackburn, J. (2020).  The \nPushshift Reddit dataset. Proceedings of the AAAI International Conference on \nWeb and Social Media, 14, 830\u2013839. https://doi.org/10.1609/icwsm.v14i1.7347\nBuckels, E. E., Trapnell, P. D.,\u00a0& Paulhus, D. L. (2014). Trolls just want to have \nfun.\u00a0Personality and Individual Differences,\u00a0 67, 97\u2013102. https://doi.org/10.1037/\ne520722015-006\nBuntain, C., Innes, M., Mitts, T.,\u00a0& Shapiro, J. (2023). Cross-platform reactions to \nthe post-January 6 deplatforming.\u00a0 Journal of Quantitative Description: Digital \nMedia,\u00a03. https://journalqd.org/article/download/4030/2985\nCenter for Countering Digital Hate. (2019, September 16).  Don\u2019t feed the trolls: \nA\u00a0practical guide to dealing with hate on social media . https://counterhate.com/\nwp-content/uploads/2022/05/Dont-Feed-the-Trolls.pdf\nChandrasekharan, E., Jhaver, S., Bruckman, A.,\u00a0& Gilbert, E. (2022).  Quarantined! \nExamining the effects of a community-wide moderation intervention on Red -\ndit.\u00a0ACM Transactions on Computer-Human Interaction (TOCHI) ,\u00a029(4), 1\u201326. \nhttps://doi.org/10.1145/3490499\nDeKeseredy, W. S. (Chapter\u00a04 this volume). Misogyny and woman abuse in the ince-\nlosphere: The role of online incel male peer support.\nDiFranco, R. (2020). I\u00a0 wrote this paper for the lulz: The ethics of Internet troll -\ning.\u00a0Ethical Theory and Moral Practice ,\u00a023, 931\u2013945. https://doi.org/10.1007/\ns10677-020-10115-x\nFang, M., Cao, X., Jia, J.,\u00a0& Gong, N. (2020).  Local model poisoning attacks to \nByzantine-Robust federated learning. In 29th USENIX security symposium (USE -\nNIX security 20)\u00a0(pp.\u00a01605\u20131622). https://www.usenix.org/system/files/sec20sum-\nmer_fang_prepub.pdf\nHine, G., Onaolapo, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, R., \nStringhini, G.,\u00a0& Blackburn, J. (2017).  Kek, Cucks, and God Emperor Trump: \nA\u00a0measurement study of 4chan\u2019s politically incorrect forum and its effects on the \nweb. Proceedings of the AAAI International Conference on Web and Social Media , \n11, 92\u2013101. https://doi.org/10.1609/icwsm.v11i1.14893\nHorta-Ribeiro, M., Jhaver, S., Zannettou, S., Blackburn, J., Stringhini, G., De Cris -\ntofaro, E.,\u00a0& West, R. (2021).  Do platform migrations compromise content mod -\neration? Evidence from r/the_donald and r/incels.\u00a0 Proceedings of the ACM on \nHuman-Computer Interaction,\u00a0 5(CSCW2), 1\u201324. https://doi.org/10.1145/3476057\nJhaver, S., Boylston, C., Yang, D.,\u00a0& Bruckman, A. (2021). Evaluating the effective-\nness of deplatforming as a moderation strategy on Twitter.\u00a0 Proceedings of the \nACM Conference on Human-Computer Interaction ,\u00a05(CSCW2), Article 381. \nhttps://doi.org/10.1145/3479525\nKarabulut, D., Ozcinar, C.,\u00a0& Anbarjafari, G. (2023).  Automatic content moderation \non social media.\u00a0 Multimedia Tools and Applications,\u00a0 82(3), 4439\u20134463. https://\ndoi.org/10.1007/s11042-022-11968-3\nKhan, S., Naseer, M., Hayat, M., Zamir, S. W., Khan, F. S.,\u00a0& Shah, M. (2022).  Trans-\nformers in vision: A\u00a0 survey.\u00a0 ACM Computing Surveys (CSUR),\u00a0 54(10s), 1\u201341. \nhttps://doi.org/10.1145/3505244\nKujur, F.,\u00a0& Singh, S. (2016). Social networking sites as a multimedia tool for brand \npopularity\u00a0\u2013 an exploratory study. Indian Journal of Science and Technology ,\u00a09, \n45. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2951553\nLapidot-Lefler, N.,\u00a0& Barak, A. (2012). Effects of anonymity, invisibility, and lack of \neye-contact on toxic online disinhibition.\u00a0 Computers in Human Behavior ,\u00a028(2), \n434\u2013443. https://doi.org/10.1016/j.chb.2011.10.014\nLewis, R., Marwick, A. E.,\u00a0& Partin, W. C. (2021).  \u201cWe dissect stupidity and respond \nto it\u201d: Response videos and networked harassment on YouTube.\u00a0 American Behav-\nioral Scientist,\u00a065(5), 735\u2013756. https://doi.org/10.31235/osf.io/veqyj\nPhases and Themes of Coordinated Online Aggression Attacks  271\nLing, C., Balci, U., Blackburn, J.,\u00a0& Stringhini, G. (2021). A\u00a0first look at zoombomb-\ning. Proceedings of the IEEE Symposium on Security and Privacy , 42, 1452\u20131467. \nhttps://doi.org/10.1109/sp40001.2021.00061\nMariconti, E., Suarez-Tangil, G., Blackburn, J., De Cristofaro, E., Kourtellis, N., \nLeontiadis, I., Serrano, J. L.,\u00a0& Stringhini, G. (2019). \u201cYou know what to do\u201d: \nProactive detection of YouTube videos targeted by coordinated hate attacks.\u00a0 Pro-\nceedings of the ACM on Human-Computer Interaction ,\u00a03(CSCW), 1\u201321. https://\ndoi.org/10.1145/3359309\nMarwick, A. E. (2021).  Morally motivated networked harassment as normative reinforce -\nment.\u00a0Social Media+Society,\u00a07(2). https://doi.org/10.1177/20563051211021378\nMarwick, A. E.,\u00a0& Caplan, R. (2018). Drinking male tears: Language, the mano-\nsphere, and networked harassment.\u00a0 Feminist Media Studies ,\u00a018(4), 543\u2013559. \nhttps://doi.org/10.1080/14680777.2018.1450568\nMir\u00f3, F. (2014). Routine activity theory. In M. Miller (Ed.), The encyclopedia of  \ntheoretical criminology (pp.\u00a01\u20137). Wiley-Blackwell. https://doi.org/10.1002/978111  \n8517390.wbetc198\nNeff, G.,\u00a0 & Nagy, P. (2016). Talking to bots: Symbiotic agency and the case of \nTay.\u00a0 International Journal of Communication , 10. https://ijoc.org/index.php/ijoc/\narticle/view/6277\nPapadamou, K., Papasavva, A., Zannettou, S., Blackburn, J., Kourtellis, N., Leon -\ntiadis, I., Stringhini, G.,\u00a0& Sirivianos, M. (2020). Disturbed YouTube for kids: Characterizing and detecting inappropriate videos targeting young children. Pro-\nceedings of the AAAI International Conference on Web and Social Media , 14, \n522\u2013533. https://doi.org/10.1080/14680777.2018.1450568\nPapasavva, A., Zannettou, S., De Cristofaro, E., Stringhini, G.,\u00a0 & Blackburn, J. \n(2020). Raiders of the Lost Kek: 3.5 years of augmented 4chan posts from the politically incorrect board. Proceedings of the AAAI International Conference on \nWeb and Social Media, 14, 885\u2013894. https://doi.org/10.1609/icwsm.v14i1.7354\nPhillips, W. (2015).  This is why we can\u2019t have nice things: Mapping the relation -\nship between online trolling and mainstream culture . MIT Press. https://doi.\norg/10.7551/mitpress/10288.003.0015\nRohlfing, S. (2014). Hate on the internet. In N. Hall, A. Corb, P. Giannasi,\u00a0& J. Grieve \n(Eds.),\u00a0 The Routledge international handbook on hate crime \u00a0(pp.\u00a0293\u2013305). Rout-\nledge. https://doi.org/10.4324/9780203578988-25\nSaeed, M. H., Ali, S., Blackburn, J., De Cristofaro, E., Zannettou, S.,\u00a0& Stringhini, G. \n(2022, May). Trollmagnifier: Detecting state-sponsored troll accounts on reddit. In 2022 IEEE symposium on security and privacy (SP) \u00a0(pp.\u00a02161\u20132175). IEEE. \nhttps://doi.org/10.1109/sp46214.2022.9833706\nShen, X., Chen, Z., Backes, M., Shen, Y.,\u00a0 & Zhang, Y. (2023).  \u201cdo anything \nnow\u201d: Characterizing and evaluating in-the-wild jailbreak prompts on large language models.\u00a0 arXiv preprint arXiv:2308.03825; https://doi.org/10.48550/\narXiv.2308.03825\nSi, W. M., Backes, M., Blackburn, J., De Cristofaro, E., Stringhini, G., Zannettou, \nS.,\u00a0& Zhang, Y. (2022, November). Why so toxic? Measuring and triggering toxic behavior in open-domain chatbots. In Proceedings of the 2022 ACM SIGSAC \nconference on computer and communications security \u00a0(pp.\u00a02659\u20132673). https://\ndoi.org/10.1145/3548606.3560599\nSnyder, P., Doerfler, P., Kanich, C.,\u00a0& McCoy, D. (2017, November).  Fifteen min-\nutes of unwanted fame: Detecting and characterizing doxing. In Proceed-\nings of the 2017 Internet measurement conference\u00a0 (pp.\u00a0 432\u2013444). https://doi.\norg/10.1145/3131365.3131385\nTynes, B. M., Lozada, F. T., Smith, N. A.,\u00a0& Stewart, A. M. (2018).  From racial \nmicroaggressions to hate crimes: A\u00a0 model of online racism based on the lived \n272  Gianluca Stringhini and Jeremy Blackbur n\nexperiences of adolescents of color. In G. C. Torino, D. P. Rivera, C. M. Capo -\ndilupo, K. L. Nadal,\u00a0& D. W. Sue (Eds.),\u00a0 Microaggression theory: Influence and \nimplications (pp.\u00a0194\u2013212). Wiley. https://doi.org/10.1002/9781119466642.ch12\nWalther, J. B. (2022). Social media and online hate. Current Opinion in Psychology, \n45, 101298. https://doi.org/10.1016/j.copsyc.2021.12.010\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., \nBosma, M., Zhou, D., Metzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, \nP., Dean, J.,\u00a0& Fedus, W. (2022).  Emergent abilities of large language models.\u00a0arXiv \npreprint arXiv:2206.07682. https://arxiv.org/abs/2206.07\nDOI: 10.4324/9781003472148-12\nThis chapter has been made available under a CC-BY-NC-ND 4.0 license.This volume began with the observation that prior research on online hate \nresearch falls into four areas: Describing the prevalence and extensiveness of online hate, summarizing forms and content of online hate (its typical content in terms of symbols, lexicons, and discourse), assessing online hate\u2019s effects on victims (whether as targets or observers), and analyzing the individual attrib-utes of and influences on online hate propagators (Walther, 2, and Tong, 3).\nThis book specifically examines the fourth focus: The (social) processes \nthat motivate and propel individuals and groups to generate, coordinate, and propagate hate messages online . Not only is this perspective different than \nand complementary to the other major foci, it also fills a critical gap in the literature about the causes that lead to, promote, and shape online hate in the first place and reinforce and disseminate it in the second place. Further, the other three approaches generally do not open up the theoretical under -\npinnings about the creation and gratifications of online hate and therefore provide little direct basis for the development of specific and effective mitiga -\ntion strategies rather than brute force punishments, removals, and account suspensions that may incur boomerang effects and make the problems associ -\nated with online hate even worse.\nA comprehensive view of online hate research deserves some mention \nof the history of, and alternative methodological approaches to, its study, as well as highlighting the cross-cutting trends and themes within this col -\nlection. So, this chapter describes the outside and the inside of the book\u2019s research. That is, it summarizes what has been going on in other popular and scholarly literature, outside of these chapters, and then it attempts to sum-marize and synthesize various aspects of the scholarship that emerge within and across these chapters, offering a general model and descriptions of the 12\nBACKGROUND SCHOLARSHIP  \nAND A SYNTHESIS OF THEMES IN  SOCIAL PROCESSES OF ONLINE HATE\nRonald E. Rice\n274 Ronald E. Rice\noverlapping landscapes that these chapters have mapped, methodologically, \nthematically, etc.\nEach chapter focuses on one or several such social processes and provides \nextensive, focused coverage of the relevant literature. This chapter steps back a bit, first briefly noting the growth not of online hate per se but, rather, of coverage of the topic by books, print news, and academic research. This back -\nground then provides context for an integrated review of themes across the chapters in Social Processes of Online Hate, which is also not about the prev-alence of online hate but, rather, the arguments and evidence about the role of social processes in online hate posting. The first section provides an overview of the growth in coverage of online hate in books, news, and research articles. The second explores the main themes of the book. That analysis synthesizes an overall social processes model: Propositions, affordances, concepts, and theory related to the model and chapter results supporting the model. It also briefly summarizes contexts for social processes that emerged in previous chapters, related to perpetrators, venues, targets/victims, mechanisms, and effects. And it highlights three of the main methodological themes of the chap -\nters: Content analysis, big data, and lexical and computational approaches. The chapter ends by noting some challenges and interventions.\nCoverage of \u201cOnline Hate\u201d in Books, Print News,  \nand Academic Articles\nWith the rise of online hate (summarized by Tong, Chapter\u00a03) came growth \nin coverage of the phenomenon, including descriptions of its perpetrators; \ndigital sources; motivations; types; effects; and attempts to regulate, manage, or counter it. The increased attention to the issue is summarized here, to situ -\nate our studies on the social processes of online hate within the phenomenon of its increasing coverage corresponding to its increasing prevalence.\nBooks\nTo find when online hate first appeared in books and how its appearance has increased since then, Google Ngram Viewer (https://books.google.com/ngrams/info) was searched using \u201conline hate,\u201d \u201cOnline hate,\u201d and \u201cOnline Hate\u201d (i.e., case insensitive). This analysis is highly constrained, however. First using only these two words limits related results (however, \u201conline anti -\nsemitism\u201d or \u201conline Islamophobia\u201d did not return any books). Second, cur -\nrently Ngram Viewer only includes digitized Google books, and only through 2019; third, it only considers Ngrams that occur in at least 40 books. The first entry appeared in 1991 (however, as any of the terms appeared in at least 40 books, the first actual date is unknown). While the appearance of \u201conline hate\u201d slowly increased and plateaued through 2010, its frequency has been rising quickly since then (see Figure\u00a012.1).\nBackground Scholarship and a Synthesis of Themes in the Book  275\nFIGURE\u00a012.1   Growth in Occurrence of \u201conline hate\u201d in Google Books\nNote: Using Google Ngram Viewer.Table\u00a0 12.1 summarizes several books that deal with the notion of online \nhate. These works tend to presume that the prevalence and harm due to \nonline hate provide sufficient justification for intervention by technology companies and legislative requirements on those companies. The list is of course limited, as it includes only recent books and those with a title or sum -\nmary containing the words \u201conline hate.\u201d\nTABLE\u00a012.1   Several Recent Books about (Primarily) Online Hate\nAssimakopoulos, S., Baider, F. H.,\u00a0& Millar, S. (Eds.). (2017). Online hate speech in \nthe European Union: A\u00a0discourse-analytic perspective. Springer Nature.\nhttps://library.oapen.org/bitstream/handle/20.500.12657/27755/1/1002250.pdf\nThis open-access volume is a product of the European Union co-funded \nC.O.N.T.A.C.T. (Creating an On-line Network, monitoring Team and phone App to Counter hate crime Tactics; http://www.reportinghate.eu) program on hate crime and hate speech in several EU states. The book relies primarily on analyzing online comments to news reports, discourse analysis, corpus linguistics techniques, and semi-structured interviews to illustrate the kinds of messages and their contents that Europeans encounter in online hate messages. Its primary arena is political discussions that are hostile and that sometimes turn toward racism, anti-LGBTQ, and bullying. Using discourse analytic methods, it offers the authors\u2019 interpretations of hate messages and the meanings of interview comments with targets and observers of hate messages.\nBarker, K.,\u00a0& Jurasz, O. (2018). Online misogyny as hate crime: A\u00a0challenge for \nlegal regulation? Routledge.\nBarker and Jurasz focus on legal aspects of online misogyny (see Ging\u00a0& Siapera, \nand Richardson-Self, in this table; and DeKeseredy, and Udupa\u00a0& Gerold, this volume), in particular in the EU, England, and Wales. They note that legal approaches overlook foundational causes of and ways to prevent online abuse, since legal approaches emphasize punishment. Chapters consider legal and femi-nist approaches to online misogyny, the way that social media heighten misogyny, the challenges and complexities of regulating online communications, hate crimes and legal limits, and implications for law and regulation.\n(Continued)\n276 Ronald E. Rice\nTABLE 12.1  (Continued)\nCitron, D. K. (2016). Hate crimes in cyberspace. Harvard University Press.\nThis volume archives a number of harrowing anecdotes in which specific individuals \nwere attacked virtually and threatened physically. These attacks focused primarily on women and often involved rape fantasies, explicit photographs, and reputation- damaging lies. Based on these incidents, the author frames cyberharassment as a matter of civil rights law, promotes advocacy, and provides recommendations for readers to take political action. Its strong point is its description of online hate as a rippling-out from one to many among coordinated aggressors (c.f. chapters by Udupa\u00a0& Gerold, Burston, Rea et\u00a0al., Phadke\u00a0& Mitra, and Stringhini\u00a0& Black-burn, this volume) rather than individual actions\u00a0\u2013 that is, a social process.\nDaniels, J. (2009). Cyber racism: White supremacy online and the new attack on \ncivil rights. Rowman\u00a0& Littlefield.\nWith insightful analyses of the allure of Twitter and other platforms to white \nsupremacists, Daniels\u2019 book is easy to read and illustrates the offensiveness of online racism. The book focuses on formally organized movements and the online activities associated with long-standing offline organizations such as the KKK and neo-Nazi groups moreso than a focus on ordinary individuals\u00a0\u2013 that is, on more social processes (cf. Burston). Further, it reveals direct linkages from the print-only era, such as printed publications, to online sites.\nDonovan, J., Dreyfuss, E.,\u00a0& Friedberg, B. (2022). Meme wars: The untold story of \nthe online battles upending democracy in America. Bloomsbury Publishing.\nMeme Wars focuses on the cartoons, images, and electronic posters (memes) created \nby amateur users and professional political campaigns, generally by groups hating the media and liberal government, to ridicule opponents, encourage virality, pro-mote ideologies, and recruit participants. In particular, it analyzes the case of the evolution and migration of the \u201cStop the Steal\u201d conspiracy movement from online to offline through the epidemic influence of memes.\nGing, D.,\u00a0& Siapera, E. (Eds.). (2019). Gender hate online: Understanding the new \nanti-feminism. Palgrave Macmillan.\nGing and Siapera take a processual look at online misogyny, grounded in a femi-\nnism perspective (see Barker\u00a0& Jurasz, and Richardson-Self in Ging\u00a0& Siapera, and DeKeseredy, and Udupa\u00a0& Gerold in this volume). This involves the diffusion of online misogyny, technological affordances that facilitate or constrain it, how cross-cultural appropriation of it has diverse effects in different cultures (such as India, Pakistan, and Russia), and how women may resist such activity and take back online spaces in the virtual world. The 13 chapters explore theorizing about techno-capitalism, digital gender politics, and consent; provide case studies of transcultural, race, revenge porn, and ideological news sites; and discuss ways in which women respond, resist, and experience online gender hate.\nHerz, M.,\u00a0& Molnar, P. (Eds.). (2012). The content and context of hate speech: \nRethinking regulation and responses. Cambridge University Press.\nHerz and Molnar focus strictly on law and policy in the context of different nations\u2019 \ndefinitions and protection of free speech with respect to online hate. For example, what are the tradeoffs and boundaries among freedom of speech, control of hate speech, and concern over different social groups? To what extent does criminal-izing hate speech generate benefits or harms in different contexts? How does or might international case law apply to hate speech?\n(Continued)\nBackground Scholarship and a Synthesis of Themes in the Book  277\nTABLE 12.1  (Continued)\nKeipi, T., N\u00e4si, M., Oksanen, A.,\u00a0& R\u00e4s\u00e4nen, P. (2016). Online hate and harmful \ncontent: Cross-national perspectives. Routledge.\nThis book elucidates features and affordances of social media platforms that facili-\ntate the spread of online hate messaging, such as easy access, anonymity, vast \ncontent, and freedom from time and geography. It also describes negative effects of online hate, particularly for young people, using cross-national survey data to report effects of online hate on well-being, self-image, trust, and relationships. It relies on several theories from criminology, social psychology, and sociology, especially social identification (in-group/out-group) theory in a way that does acknowledge that theory\u2019s strong limitations in this domain (as does Walther\u2019s chapter in our volume).\nMarantz, A. (2020). Antisocial: Online extremists, techno-utopians, and the hijack-\ning of the American conversation. Penguin Random House.\nThis is a fascinating examination of the deliberate creation and targeted placement \nof disinformation into social media within a larger narrative describing how pro-fessional political campaign operatives maximize damage to political opponents. It is not focused on hate as much as on politics and so-called fake news. It discusses the by-now familiar argument that the initial vision of the Internet as a means of freedom, democracy, civil discourse, and participation has been corrupted as a source for alt-right, white supremacist, extreme, propagandistic, and rapidly dif-fused political content.\nMitts, T. (2022). Moderating extremism: The challenge of combating online harms. \n(under contract, Princeton University Press.)\nMitts suggests an insightful approach to online aggressors, which is consistent with \nsome of the perspectives in our volume. Mitts argues that online antagonists who have their postings removed and/or their accounts suspended escalate their anger and adopt various evasion strategies, rather than desist, leading to an increase in velocity of hate messaging as hate posters migrate across social media platforms. Mitts develops a \u201ctheory of digital resilience\u201d which strongly argues that the main reason for recidivism through platform migration is the variation in social media platform content moderation policies and procedures. Essentially, what she calls \u201cdangerous organizations\u201d evolve or migrate to online niches that are more sup-portive of online hate.\nPhillips, W. (2016). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. The MIT Press.\nPhillips is a classic source on the subject of trolling, akin to hate messaging. Phillips \nsituates the emergence of trolling as a subcultural phenomenon, originally among computer programmers, which accompanied the development and evolution of the early Internet. She looks at online hate as one form of intentional disrup-tion by cynical and lonely cybergeeks against \u201cnormies\u201d\u00a0\u2013 normal people who are ignorant about how technology works (and the companies who exploit their ignorance)\u00a0\u2013 who are easily unsettled by uncivil taunting behavior. Phillips shows that trolling and hating are not only a sport or leisure activity, and thus a social process, but also mirror in some ways socially dominant cultural tropes concern-ing gender roles (similar to Richardson-Self\u2019s argument, below), success, and entitlement and are related to sensationalist media.\n(Continued)\n278 Ronald E. Rice\nTABLE 12.1  (Continued)\nRichardson-Self, L. (2021). Hate speech against women online: Concepts and coun-\ntermeasures. Rowman\u00a0& Littlefield.\nThis volume focuses on online misogyny. It theoretically develops and explicates the \nsurrounding \u201csocial imaginary\u201d (patterns of interconnected symbols that bound \ninterpretations of the world, social beliefs, and narratives) that both foster this hate speech but which is also strengthened and reproduced by that hate speech (in some ways similar to the approaches of Ging and Siapera, noted above, and DeKeseredy, this volume). Importantly, online hate speech is not typically interac-tive or communicative with the targets, as the hate speech is intended to silence or dismiss the targets, and not intended to initiate discussions or debates with them. The author asks how can these social beliefs be resisted and repelled, and how can counter and positive imaginaries and alternative norms be developed and imple-mented? Richardson-Self suggests six conditions for such re-imaginings.\nSimi, P.,\u00a0& Futrell, R. (2015). American Swastika: Inside the white power move-\nment\u2019s hidden spaces of hate (2nd ed.). Rowman\u00a0& Littlefield.\nSimi and Futrell concentrate on formally organized white power movements\u00a0\u2013 hate \ngroups such as neo-Nazis and KKK chapters\u00a0\u2013 that have offline bases. Their research methods include case studies, first-person accounts, and interviews. The book focuses on how members of these organizations recruit members offline (through conventional media including roadside billboards and music festivals) as well as online, and how these groups plan and commit violence in the physical world. The work stands in contrast to informally organized social networks that reside entirely online (as analyzed by chapters by T\u00f6rnberg\u00a0& T\u00f6rnberg, Udupa\u00a0& Gerold, Stringhini\u00a0& Blackburn, and Shmargad et\u00a0al., in our volume).\nStrippel, C., Paasch-Colberg, S., Emmer, M.,\u00a0& Trebbe. J. (Eds.). (2023). Challenges \nand perspectives of hate speech research. Digital Communication Research, 12. Open Access. https://www.digitalcommunicationresearch.de/v12/\nThis valuable and free resource with 26 chapters presents three distinct parts. The \ninitial seven chapters focus primarily on the first of the three approaches to online hate that Tong describes (this volume)\u00a0\u2013 what is the content and shape of online hate messaging. The analyses consider different social schisms within specific nationalities (Brazil, India, Lebanon, Nigeria, and Poland). The second group of chapters approaches definitions of different types of messaging/content that are related to online hate, in terms of various social inequalities that have led to them and different kinds of harms they are presumed to effect (described in critical/soci-etal rather than empirical terms). The third section explains, applies, and critiques a variety of methodological approaches to the analysis of online hate messaging.\nUdupa, S., Gagliardone, I.,\u00a0& Hervik, P. (Eds.). (2021). Digital hate: The global \nconjuncture of extreme speech. Indiana University Press. Open Access. https://publish.iupress.indiana.edu/system/resource/4/3/c/43cf237a-65c7-4c5e-9807-4290125ff2a8/attachment/6cdcbd08b6e30d0debc93b36de8a002b.pdf\nThe chapters in this excellent, edited compendium focus on the content and shape \nof online hate messaging as those messages appear in different nationalities. The essays focus on distinctive incarnations of content, and how those forms of hate discourse evoke cultural significance in different contexts around the world such as India, Denmark, Islamophobia in China, Bolivian immigrants in Chile, Pakistan, Germany, Indonesia, and Turkey. The discussions are embedded on assumptions that hate messaging is a modern-day incarnation of colonialism and racism. The collection evokes cultural anthropological themes of exploitation and dominance.\n(Continued)\nBackground Scholarship and a Synthesis of Themes in the Book  279\nTABLE 12.1  (Continued)\nWachs, S., Koch-Priewe, B.,\u00a0& Zick, A. (Eds.). (2021). Hate speech\u00a0\u2013 Multi-\ndisziplin\u00e4re Analysen und Handlungsoptionen (Hate Speech\u00a0\u2013 Multidiscipli-\nnary analyses and options for action. Theoretical and empirical approaches to an interdisciplinary phenomenon). Springer VS. https://pub.uni-bielefeld.de/record/2957520\nThis book treats hate speech generally but also has chapters specifically about online \nhate. All but 2 of the 18 chapters in this edited book are in German. The first section includes models, research, and theories of hate speech from disciplinary perspectives of communication and media, linguistics and speech, pedagogy and psychology, and computer science. The second section offers four chapters on effects and potential prevention of, mitigation of, or responses to, hate speech, especially online.\nNews Coverage\nA search for \u201conline hate\u201d in news articles in Nexis Uni (which includes over \n17,000 news, business, and legal sources, with coverage beginning in 1995) revealed a few such news stories with the term initially, but then a rise in 2009 and rapid growth from 2017 on (see Figure\u00a0 12.2), with 21,691 entries \nas of this writing.\nPrevalent topics in 2009 included debates between advocates of free speech \nversus regulation of online hate, and which regulatory agency has how much power to do so; reporting the rise in online hate posting; venues (web, Facebook); and a variety of specific instances and targets. In 2017, news emphasized calls for more general societal responses; the European Union\u2019s criticisms of and agreements with Internet platforms; platforms\u2019 responses with new actions or features; more regulations, legislation, and legal actions against online hate; the rise in online hate incidents and support for online \nFIGURE\u00a012.2   Growth in News Coverage of \u201conline hate\u201d\nNote: Using Nexis Uni.\n280  Ronald E. Rice\nhate, especially associated with Brexit and the Trump campaign/election; and \nrecommendations for individuals to help protect against online hate.\nAcademic Articles\nTo portray the coverage of the issue in academic research articles, the Pro-Quest Social Sciences Database (includes 22 bibliographic databases) was searched for the presence of the phrase \u201conline hate\u201d in any location (e.g., title, abstract) in peer-reviewed articles. (As with the Ngram viewer, using only these two words limits results.) Through 2022, 408 articles included the phrase, with growth beginning in 2013, accelerating in 2017, and even more in 2020 (see Figure\u00a0 12.3). Articles published in 2017 investigated the crimi-\nnalization of online hate speech, online victimization, and confronting online extremism. Articles from 2020 covered psychological influences on online hate, experiences of online hate by different minority or nationality groups, challenging or counter-strategies to deter online hate, relationships of social media use to acceptance of hate speech, and textual or rhetorical analyses.\nMany academic books and articles include comprehensive reviews of \nrelevant literature. Among the most relevant ones, Casta\u00f1o-Pulgar\u00edn et\u00a0al. \n(2021) assessed 67 studies that were published between 2015 and 2019 on the extent to which the Internet and social media may facilitate hate speech, cyberhate types, and triggers such as terrorism. Online hate speech, they found, focuses on gender, racism, politics, and religion and is often moti -\nvated by a variety of respective ideologies. The article also reviewed meth -\nodological approaches in prior studies. Common methods used to analyze online hate included grounded theory, discourse analysis, thematic analysis, computational methods, and network analysis, with most studies using a \nFIGURE\u00a012.3   Growth in Academic Articles Referring to \u201conline hate\u201d\nNote: Using ProQuest Social Sciences Database.\nBackground Scholarship and a Synthesis of Themes in the Book  281\ncombination of methods. They conclude that \u201cthere are many theoretical \ngaps on the explanation of this behavior and there are not enough empirical data to understand this phenomenon and its relation with the use of Inter -\nnet\u201d (p.\u00a02).\nTontodimamma et\u00a0al. (2021) also describe the growth in research on the \ntopic, using a different approach. They overview prior analyses of research (especially detection and identification of hate speech by automated computer-based analyses). Then, using knowledge mapping, topic modeling, and bibliometric data, they analyze 1,614 academic publications over 30 years (1992\u20132019) in the Scopus database, using a broad range of terms to describe the components, topics, and trends of online hate research. The analysis reveals two phases, with slow growth in publications from 1992 to 2010, and more rapid growth from 2010 to 2019. Using keyword co-occurrence, Tontodi-\nmamma et\u00a0al. (2021) identify three clusters of concepts: (1) Religion and poli -\ntics: Hate speech related to religion, human rights, democracy; (2) the social sphere: Hate speech related to the more common and unfortunately familiar topics such as Islamophobia, racism, gender, misogyny, radicalization, censor -\nship, freedom of speech, and holocaust denial, on YouTube, Facebook, etc.; and (3) methods: Deep machine learning, text classification, sentiment analy -\nsis, and social network analysis. The authors note a slight shift over the years from more general themes to more technical and analytical emphases.\nWaqas et\u00a0al. (2019) used a broad and diverse set of search terms and com-\nbinations in titles, abstracts, and keywords to identify research publications on online hate and their foci, indexed in the Web of Science core database. Their queries yielded 3,371 articles with 33,721 non-self citations. Analyses revealed clusters of articles (each with multiple sub-clusters) in four domains: Cyberbullying; sexual solicitation and intimate partner violence, including seeking social support; deep learning and automation (cyber defense, neural network learning); and extremist and online hate groups (recruitment, dis -\ncourse, misogyny, Islamophobia).\nThemes in Social Processes of Online Hate\nWithin this background of increased attention to online hate, in books, the press, and research articles, employing a variety of analytic methods, little previous research took a decidedly social explanatory approach. The contri -\nbutions to this volume, in contrast, have a common focus on how interac -\ntions and relationships among online hate producers facilitate their socially organized hate behavior. Nevertheless, the chapters also present considerable variation in the form, emphases, and contexts of those behaviors. One goal of this final chapter is to organize, synthesize, highlight, and identify the main themes and foci of the chapters that collectively offer and largely support a model of the social processes of online hate.\n282  Ronald E. Rice\nA Social Processes of Online Hate Model\nWalther\u2019s chapter (Chapter\u00a02) clearly sets the stage, and the other chapters \nelaborate or extend the underlying theme and concepts of a model of the social process of online hate. The following sections set out to advance the model in several ways: To present a set of propositions about the role of social processes, identify the range and importance of social media affor -\ndances in facilitating or constraining those processes, highlight concepts and theory related to the model, and summarize results supporting the model.\nPropositions\nThe book\u2019s arguments offer the following propositions:\n\u2022 A focus on individual behaviors and solutions is incomplete and ineffec -\ntive, theoretically and practically. While theories of social identity and out-group derogation play a large part in the social process proposed here, they do not sufficiently identify, focus on, or analyze social interac -\ntions and gratifications. Diverse and continued interaction among perpe -\ntrators is a key process in the creation and dissemination of online hate (Chapter\u00a02).\n\u2022 A primary purpose of online hate activity is to engage in social processes \nand activities with, and receive social approval from, fellow perpetrators, in addition to complementing or, even in place of, antagonizing or harm -\ning victims. Social gratifications (such as approval), entertainment, con -\nnectedness, support, visibility and sharing of fellow perpetrators\u2019 content and actions, and identity development are all key social processes. The act of interacting and sharing opinions and ideologies among hate posters and their admirers may be sufficient motivations (Chapters\u00a02, 5, 8, 11).\n\u2022 Perpetrators share in-group symbology, post to venues accessible to fellow \nactors, and engage in behaviors that may not be seen by or even involve \u201ctargets\u201d (Chapter\u00a06).\n\u2022 Analyzing social and emotional processes is crucial for understanding \nonline hate (Chapter\u00a05).\n\u2022 Perpetrators occupy different social movement roles to provide different \ninformation resources, in varying ways, across different social media plat-forms (Chapter\u00a09).\n\u2022 Social processes of descriptive and injunctive norms, represented in differ -\nent social media features and measures (such as \u201cvotes\u201d), shape the type of antisocial messages posted and comments received (Chapter\u00a010).\n\u2022 Some kinds of online hate attacks are more or less coordinated, reflecting \nsocial interactions and collective action (Chapters\u00a08, 11).\n\u2022 The affordances of digital/social media also play a complex role in facili -\ntating or constraining online hate content and social processes (Chapter\u00a02; see next section).\nBackground Scholarship and a Synthesis of Themes in the Book  283\nAffordances\nA complementary but perhaps underemphasized aspect of the social processes \nargument is that various affordances (features, capabilities, multi-model con -\ntent, options, restrictions) of different social media platforms and discussion forums both facilitate and constrain particular social processes. Table\u00a0 12.2 \nlists the features specifically mentioned in the chapters, grouped (loosely applied) by a common set of affordances. Rice et\u00a0al. (2017 ) reviewed various \nTABLE\u00a012.2   Digital Media Affordances Facilitating Online Hate Mentioned in Chapters\nAwareness\n\u2022 Advertising and monetizing nature of many websites reinforces content that \nattracts and engages attention, such as extremist content and misinformation\n\u2022 Filter bubbles and echo chambers limit exposure to diverse opinions and \ninformation\n\u2022 Online platforms have fragmented boundaries and decentralized leadership of \n formerly organized movements, bypassing the role of face-to-face interactions, public gatherings, and visual artifacts\n\u2022 Recommender algorithms that can funnel polarizing content to stimulate interest \nor reinforce group ideology\n\u2022 Structuring of online interactions (topic forums, follower relations)\nEditability\n\u2022 Allows mashed-up memes combining a range of satire, insult, and denigration\u2022 Content moderation by users, algorithms, platform monitors\u2022 Digital tools and platforms allow the creation and distribution of deepfake por-\nnography, often used for misogynist hate postings\n\u2022 Memes, with photo, video, gif, and text, perhaps familiar enough to be referred to \nby a catchphrase\n\u2022 Open architecture and open source promote evolution and adaptation of online \naffordances; that is, some sites, apps, and platforms are more structurally editable or customizable than others\n\u2022 Tailoring content and information-sharing to specific and diverse segments of both \nsupporters and targets, such as on Facebook and Twitter\nPervasiveness (including accessibility)\u2022 Bottom-up influence from users instead of or in addition to control by formal \norganizations or platforms leads to greater access by and diversity of strategies and actors\n\u2022 Creating social media or chat groups, designated channels, or playlists helps \norganize, maintain, and increase accessibility of content in multiple ways\n\u2022 Crowdfunding to generate resources for otherwise not publicly supported actions \nand content increases access\n\u2022 Doxxing and public publishing of a target\u2019s personal information\u2022 Financial incentives or monetizing (such as on YouTube) for producing extremist \nor hateful content, which increases pervasiveness of content\n\u2022 Flexibility and access also pose challenges to authoritarian figures and \ngovernments\n\u2022 Globalized access to otherwise specific and localized hate groups\n(Continued)\n284  Ronald E. Rice\nTABLE 12.2  (Continued)\n\u2022 Hate can now be expressed and diffused by orders of magnitude more compared \nto offline exposure and remain online, vastly increasing the pervasiveness of hate\n\u2022 Networked harassment, where perpetrators find and collaborate with others to \ntarget an individual; also brigading, dogpiling, overloading\n\u2022 Online multi-player video games commenting can foster online hate groups and \nrecruitment\n\u2022 Social media have provided an immense array of spaces supporting all kinds \nof views, including the normalizing of hate toward women and racial or ethnic \ngroups\n\u2022 Using links and forwarding hashtags to disseminate content across sites\u2022 Variations in hate content restrictiveness or supportiveness across platforms facili-\ntating migration\n\u2022 YouTube\u2019s \u201cSuper Thanks\u201d, which allows commenters to make instant donations \nto a channel operator\n\u2022 Zoombombing, hijacking video meetings\nSearchability (including association)\n\u2022 Hashtags, serving both as reference links to as well as representations of ideas and \nactions, increasing likelihood that both targets and fellow hate perpetrators can find the content\n\u2022 Indexing by search engines allows interested users to find content and sites pro-\nmoting online hate\n\u2022 Tweets that can be followed or forwarded/retweeted\u2022 Use of @usernames in tweets to direct content to, and refer others to, targets\nSelf-presentation (including others\u2019 feedback, likes, etc.)\nThe chapters describe and analyze a broad array of ways that users can manage \ntheir online presentations, others can provide signals of social approval/disap-proval of one\u2019s or a group\u2019s presentations, a user or group can indicate or refer to their status or influence, and which can portray and strengthen collective group identity. These include: Comments, embedded hashtags, emojis, favorites, follow-ers, friends, hearts, likes, quotes, reply, retweets, sharing, votes (up/down), etc.\nVisibility (including anonymity)\u2022 Anonymity (voluntary or platform-imposed) and pseudonymity, shielding the \nperpetrators; allows perpetrators to delete or abandon accounts and set up new accounts without the identification of the same actor, making it difficult to sanc-tion or suspend users\n\u2022 Encryption and private group messaging limit visibility for out-groups\u2022 Exposing hate content to others who did not seek or want it, intentionally or not\u2022 In VR, display of both verbal and nonverbal behaviors directed toward a tar-\nget, or satirizing/offending an identity, including virtual touching and spatial harassment\n\u2022 Inclusion of visual, auditory, and textual hate symbols and phrases\u2022 Messages or screen grabs that document and make visible victims\u2019 distress over \ntrolling, baiting, and provocation incidents\n\u2022 Multiple media modes, such as images, stickers, video, sound, and pop-ups, \nenhance the visibility of specific content\n(Continued)\nBackground Scholarship and a Synthesis of Themes in the Book  285\nconceptualizations of and debates about affordances, leading to this defini-\ntion of media affordances: \u201crelationships among action possibilities to which agents perceive they could apply a medium (or multiple media), within its potential features/capabilities/constraints, relative to the agent\u2019s needs or pur -\nposes, within a given context\u201d (p.\u00a0109). Here, we apply the six affordances identified as having reliable and valid measures: Awareness, editability, per -\nvasiveness (including accessibility), searchability (including association), self-presentation (including feedback, likes, etc.), and visibility (including anonymity). While Stringhini and Blackburn (Chapter\u00a011) explicitly distin-guish social processes from their technological platforms conceptually, the processes and platform affordances are nonetheless highly interrelated.\nEach affordance is illustrated by an example of how that affordance \n( features, capabilities, or aspects of digital media) fosters or shapes social \nprocesses of online hate. Awareness: Recommender algorithms funnel polar -\nizing content to stimulate interest or reinforce group ideology. Editability: \nDigital tools and platforms allow the creation and distribution of deep -\nfake pornography, often used for misogynist hate postings. Pervasiveness:  \nCreating social media or chat groups, designated channels, or playlists helps organize, maintain, and increase the accessibility of content in multiple ways. Searchability: Indexing by search engines allows interested users to find con -\ntent and sites promoting online hate. Self-presentation: Votes, likes, follows, \netc., provide signals of approval of the identity or status of a poster or a group. Visibility: Messages or screen grabs that document and make visible \nvictims\u2019 distress over trolling, baiting, and provocation incidents.\nConcepts and Theories Related to the Model\nThe chapters introduce, advance, and apply a variety of concepts and theo -\nries that also support or help explain the social processes of online hate. The section highlights those contributions, generally ordered by chapter. The range of such concepts and theories underscores the heuristic value of the social processes approach: There are many facets of such social processes, TABLE 12.2  (Continued)\n\u2022 Opportunistic Zoombombing, via image, text, audio, video\n\u2022 Persistent visible user comments on YouTube video pages\u2022 Posters can easily expose their thoughts to others\u2022 Posting within private groups\u2022 Some postings are ephemeral and disappear in a short time (e.g., 4chan; most \nvideo meetings)\n\u2022 Threaded conversations make visible relationships among comments, replies, \n posters, and rationales\nNote: Affordances from Rice et\u00a0al. (2017), expanded here as noted in parentheses.\n286  Ronald E. Rice\nand research can continue to enhance our understanding of them through \ncomplementary concepts and theories.\nTong (Chapter\u00a0 3 ) presents a relational taxonomy of online hate, cate -\ngorizing it by private/public and by one-on-one/many-to-one/group or intergroup-level. DeKeseredy (Chapter\u00a04) applies male peer support theory to the case of the incelosphere, helping to explain incels\u2019 motivations and support for, and engagement in, abuse of women and in other forms of misogyny. Males provide support to peers in fostering abusive attitudes and behaviors. In particular, charismatic leaders with prototypical hegemonic masculine qualities attract and sustain their peers.\nAlthough a common explanation for online hate invokes the concepts of \n\u201cecho chambers\u201d and \u201cfilter bubbles\u201d where users passively find themselves with like-minded others, and their views and networks are reinforced through algorithmic notifications, news, and recommendations ( Chapters\u00a05, 6), T\u00f6rn-\nberg and T\u00f6rnberg ( Chapter\u00a05) eschew these receiver-oriented approaches. \nThey invoke deeper social processes by applying Durkheim\u2019s community for -\nmation theorizing, especially the importance of rituals in creating group iden -\ntity. Thus, one way to understand the enduring nature of the Stormfront site is to frame their online behaviors as \u201cdigital campfires\u201d\u00a0\u2013 an in-group space for extremists to discuss and share identity, feel a sense of belonging and support, and defend their group and ideological boundaries, again reflect -\ning a social process approach to online hate. One form of ritual is the use of \u201csubcultural literacy\u201d or terms, jargon, memes, and symbols understandable only by insiders. Another is to interpret events and events in ways that rein -\nforce the group identity and ideology, even when counter to external objec -\ntive reality. Participating in such rituals creates \u201ccollective effervescence\u201d (\n Collins, 2014 ), strengthening the community.\nUdupa and Gerold ( Chapter\u00a06) craft a theory about the interrelationship of \npolitical aggression, consumption of porn, and speech act theory, as a way to describe and explain particularly sexualized online hate, especially of Muslim women by young Hindi males, reflecting Islamophobia, and larger socio -\nlogical forces of objectification, digital image manipulation, and patriarchal political norms. This form of online hate embeds the Manosphere, more gen -\neral than the incelosphere as discussed by DeKeseredy ( Chapter\u00a04). Burston \n(Chapter\u00a07) and Phadke and Mitra (Chapter\u00a09) apply social movement theory to social media platforms, arguing that online hate groups are often a part of social movements and, as such, engage in familiar movement strategies and goals. In particular, Burston (Chapter\u00a07) introduces the term \u201cdigitally mediated spillover,\u201d a social process whereby members of one online move-ment introduce their ideologies, culture, and networks into another online group or an offline group. This spillover involved three phases of (success -\nful or unsuccessful) radicalization. His analyses of three conservative college groups show that the notion of digitally mediated spillover provides a better \nBackground Scholarship and a Synthesis of Themes in the Book  287\nexplanation than \u201centryism,\u201d which is an intentional and organized strategy \nto send extremists to conservative college groups to groom right-wing candi -\ndates for Congress.\nPhadke and Mitra ( Chapter\u00a09) conceptualize online hate groups as social \nmovement organizations, which frame their communication to legitimatize their behavior, recruit members, work toward develop shared perspectives on needed social change, and motivate others to engage in that change. They content-analyze a wide range of Facebook posts and Twitter tweets to iden-tify three types of collective action framing, five ideologies, five sources of information sharing, and five social roles. Then they show how content is shared across these categories, to understand how hate groups attract and redirect their followers, in different ways across the two platforms. Theo -\nretically, they refer to three dimensions of social movement participation, each motivated by specific theoretical models (for participation, engagement, and mobilization), to derive the social roles and indicators of each based on online content and platform features.\nRea et\u00a0al. (Chapter\u00a08) develop the concept of \u201chate parties,\u201d whereby the \nactivity on fringe sites inspires sharing of links to YouTube videos, where members extend the hateful rhetoric of those videos and then migrate to other sites to continue and elaborate their discussions. Their unique contri -\nbution appears in their discovery that participants in hate conversations carry on their discussions across multiple platforms simultaneously, opportunisti -\ncally choosing the platforms that allow more extreme and offensive hateful language, in order to evade content moderation in any one particular plat -\nform. Again, this conceptualization rejects the traditional conceptualization of online hate as unidirectional attacks on specific targets for nonstrategic purposes. Like DeKeseredy ( Chapter\u00a04) and Udupa and Gerold ( Chapter\u00a06), \nRea et\u00a0al. also refer to larger sociological and economic forces as influences on the nature of social media and the prevalence of online hate.\nShmargad et\u00a0al. (10) turn to foundational social norms theory to under -\nstand the magnification of antisocial comments in response to preceding norms and sanctions in a large set of comments to an online newspaper and discussions in Reddit and Twitter about the January 6th Capitol riot. They explicate the theory to identify four types of perceived social norms: Self-focused or other-focused, by descriptive or injunctive. Moreover, they develop sophisticated measures of each based on content and relational and temporal usage data. Stringhini and Blackburn ( Chapter\u00a0 11) also develop \na temporal approach to online hate, identifying the stages through which coordinated cross-platform online attacks progress: Call for attack, prepara -\ntion, execution, reporting back, and wrap up/celebration. Social processes are fundamental to each of these stages. For example, a \u201ccall for attack\u201d may be motivated by the goal of amusement, as well as by racism and misog -\nyny. They argue that \u201ccoordination\u201d may be too strong a word, with its \n288  Ronald E. Rice\nimplications of planning and instrumentality; rather, applying routine activi -\nties theory, Stringhini and Blackburn explain that many such attacks are an \nunplanned convergence of the content or individual in a YouTube video, a perpetrator on another (perhaps fringe) site trying to inspire others to post aggressive comments (whether to disrupt a system or a zoom meeting) and then returning to enjoy the process (if successful).\nChapter Evidence Supporting the Model\nThroughout the book, authors provide various forms of results (here, in the form of summary results) illuminating or supporting the social process of online hate model. Membership in, or the ability to comment on other mem -\nbers\u2019 posts on, hate sites may require explicit commitment to the cause, not only protecting the group from outside disapproval but also underscoring group identity and connection (Chapter\u00a03). Male peers influence others, via social psychological and sociological processes, to abuse women (Chapter\u00a04). The language of new entrants to online groups quickly converges to con -\ntent, memes, discourse, jargon, and emotions from veteran group members, indicating semantic and collective social influence. Members of Stormfront provide support to each other for their experiences, marginalization, and beliefs (Chapter\u00a05).\nHindu posters are embedded in a \u201cclose web of actors\u201d or clusters of \nusers, strengthening their resilience in spite of online or legal disciplining (Chapter\u00a06). Rating of \u201conline auctions\u201d is a collective, participatory activ -\nity, a \u201csocial interaction episode,\u201d which reinforces those bonds ( Chapter\u00a06). \nThey also share in the performance of male homosociality, manhood, mascu -\nlinity. Resonating with Walther\u2019s argument, much content on the online auc -\ntions and related sites involves humor and a sense of fun, at least among the perpetrators (Chapter\u00a06). Stringhini and Blackburn highlight that the purpose of many coordinated online attacks seems to be primarily for entertainment. Burston (Chapter\u00a07) similarly describes how online hate activists celebrated and laughed for successful antagonization of feminists and undocumented immigrants.\nRea et\u00a0al. ( Chapter\u00a08) also describe how antisemitic comments on YouTube \nvideos were often intended for fellow perpetrators, not the video creator or the target in the video. Further, social interactions among such actors occurred within and across platforms, a form of \u201ccontinuous conversation\u201d or \u201chate party.\u201d Stringhini and Blackburn ( Chapter\u00a011) also remark on how much of \na coordinated attack process is not directly visible to a target, again empha -\nsizing how such behavior is intended for fellow perpetrators. These actors intentionally link information across multiple sources and sites, creating a \u201cparticipatory ecosystem of online hate\u201d (9). Phadke and Mitra note that \u201csharing links in their social media postings provides a sizable opportunity \nBackground Scholarship and a Synthesis of Themes in the Book  289\nfor hate groups to redirect their followers toward their own websites and \nother extremist blogs.\u201d Further, two of the five social movement roles they identify in online hate groups are explicitly social. Solicitors motivate other \nusers to engage in action and use group words such as \u201cwe\u201d and \u201cus.\u201d Moti-\nvators highlight and celebrate the accomplishments of fellow actors and pro -\ntect and defend group values. Shmargad et\u00a0al. find that online contributors tend to imitate prior posters and are reinforced by approval \u201cvotes,\u201d sup -\nporting the theory of normative social behavior, there, in terms of fostering antisocial content ( Chapter\u00a0 10). Cross-platform raids ( Chapter\u00a0 11), along \nwith collective action and networked harassment, are informally coordi-nated, rather than individual or random attacks. Posters or disseminators of harassment may return to the originating site or aggregation thread to con -\ngratulate each other and boast of their actions ( Chapters\u00a02, 11). Interestingly, \nStringhini and Blackburn ( Chapter\u00a011) also note that not all fellow members \nwill engage in, or even support, some attacks and Zoombombing, indicating diverse social norms.\nContexts for Social Processes of Online Hate\nThe chapters consider a variety of online hate or harassment perpetrators, and how they aim at a wide range of targets or fellow perpetrators, directly or indirectly, individually or collectively, through many venues on multiple topics using diverse mechanisms with a range of effects, all supported by, and providing contexts for, social processes. The following sections summarize the extensive range of instances of the contexts of social processes of online hate noted by the authors: Perpetrators, venues, targets/victims, topics, mech -\nanisms, and effects. Thus, comprehensive analyses of the social processes of online hate could identify additional instances of these contexts and assess how the combinations of the contexts manifest online hate in different ways.\nPerpetrators\nThe many online perpetrators in the chapters include (but are not limited to): ALIPAC, anti-LGBTQ+ advocates, anti-Semites, Aryan Nations, conservative youth organizations carrying out campus-based extremism, conspiracy theo -\nrists, cyberstalkers, Goyim Defense League, Hindu \u201ctrads\u201d (staunch tradi -\ntionalists who have sought to revive practices deemed as \u201cproperly\u201d Hindu), incel movement, Leather Apron Club, Liberty Bell Publishing, male suprema-cist movements, male entitlement proponents, misogynists, neo-Nazis, pro -\nfessional influencers who explicitly promote online hate, racists, religious supremacists, \u201ctoxic technocultures\u201d or \u201cleaderless, amorphous\u201d cultures of hate, trolls, (explicitly self-labeled) \u201cWhite Christians,\u201d white nationalists, white supremacists, and so on.\n290  Ronald E. Rice\nVenues\nThe Internet in general and social media in particular facilitate the produc -\ntion and dissemination of online hate, enabled or constrained by each medi -\num\u2019s affordances (see above). Windisch et\u00a0al.'s (2022) review noted how the \nInternet and various platforms can disseminate hate speech and connect users \nsharing those perspectives, whereby such content and interaction become normalized, leading to radicalization and intergroup violence. Table\u00a0 12.3 \nlists the numerous online hate venues mentioned in the chapters. The major platforms are well known and apply multiple and changing approaches to minimize online hate (e.g., Facebook), while others engage in only minimal monitoring and management (X, formerly Twitter), while still others are explicit shelters for and even foundational sites for some online hate groups (e.g., Stormfront).\nTABLE\u00a012.3   Venues for Online Hate Mentioned in the Chapters\n2channel Minds\n4chan online gaming\n8kun Parler\nBBSes Poal\nBitchute Reddit\nBluejeans RightToBe\nClubhouse Rumble\ncozy.tv Secret\nFacebook Skype\nFacebook group chat Starleaf\nFacebook Messenger Stormfront\nFacebook page Telegram\nFascist Forge Telegram Chat Worlds\nGab Social The incelosphere\nGab The Manosphere\nGettr The Metaverse\nGitHub TikTok\nGoogle Truth Social\nGroupMe Twitch\nInstagram Twitter\nInternet virtual reality or virtual worlds\nInternet communities Whisper\nIron March Wimkin\nJitsi Win\nLBRY Y Combinator\u2019s Hacker News forum\nlivestreaming YouTube\nmessaging apps Zoom\nMeWe\nBackground Scholarship and a Synthesis of Themes in the Book  291\nTargets/Victims\nThe chapters consider many types of targets/victims. These include: Race/  \nethnicity (Asian Americans, Blacks, Hispanics, people of color), sex and \nsexual orientation (bisexuals, gays, lesbians, queer, women, and women in gaming), nationality and citizenship (\u201cillegals,\u201d immigrants, Mexicans, people with strong accents), religion (Jews, Muslim male \u201crivals,\u201d Muslim women, other specific religions), disability, as well as online bystanders/unintentionally exposed individuals. As Tong ( Chapter\u00a03) reviews, and the \nsources in the section on Coverage identify, many others are targets as well, for an extensive range of reasons and perceived provocations.\nTopics\nThe topics of the online hate analyzed in these chapters are also extensive. They include: Anti-Black racism, anti-immigrant racism, antisemitism, con -\nspiracy theories, discrimination, education/image control, gender, hatred (of particular targets), Holocaust denial, identity attack, immorality of LGBT life, \u201cinvaders\u201d (immigrants), Islamophobia, misogyny, nationality or national origin, political beliefs, race/ethnicity/culture, races as immoral or inferior, radicalization/recruitment, religious beliefs, sexuality, violence, and whites (as a threatened race).\nMechanisms\nThe chapters note a host of mechanisms through which perpetrators engage in online hate. These include: Accusing a target of lying, attack on commenter, casting aspersion, concern trolling, cyberstalking, doxxing, group linking to and commenting on YouTube videos, hashtags, hate parties, inflammatory language, insult, memes, name-calling, networked harassment, nonconsensu-ally sourced women\u2019s images, online auctions, pejorative speech, profanity, revenge porn, threat, toxicity, and vulgarity. Each of these may facilitate different aspects of social processes, leading to different effects for both per -\npetrators and targets/victims and shaped by different platform affordances.\nEffects\nWhile the chapters in this book highlight the various motivations, attrac -\ntions, and social processes that facilitate online hate, they do so in the context of a critical presumption: That online hate has negative effects or influences on its targets, its perpetrators, or both. The authors note a wide variety of such effects. For perpetrators, these include: Becoming active perpetrators \nof hate or being recruited to hate groups themselves, becoming desensitized, \n292  Ronald E. Rice\ngratification such as entertainment and social support, in-group cohesion and \nidentification, increased willingness to use and actual involvement in radical ideology-based violence, mobilization, and normalization of hate.\nFor targets/victims, these include: Being terrorized, collateral damage \n(where the main intent was not necessarily to harm specific individuals but who were nonetheless negatively affected such as unintended observ -\ners or passive bystanders), disruption of/or chaos/havoc in online activities (e.g., online meetings or school classes), harm to an individual\u2019s reputation, increased problems with relationships, increased social isolation, offline aggression/violence/murder, terrorist attacks, victims\u2019 mental and emotional states (anger, anxiety, depression, fear, sadness, shame, stress, trouble sleep -\ning, and difficulty concentrating on everyday activities), and withdrawing from online interaction.\nMethod\nEach of the chapters includes their own reviews of data sources and collec -\ntion, research design, and analytical methods relevant to their studies. This section identifies three main types of data and analytical methods used by the authors to describe, explain, analyze, and test their respective aspects of the social processes of online hate model. They include content analy -\nsis, big data, and lexical and computational analyses. Other methods are also used, such as ethnography (Chapter\u00a07) and image analysis (Chapter\u00a06). The methods here are a subset of the broad range of methods reviewed by Casta\u00f1o-Pulgar\u00edn et\u00a0al. (2021) noted above and Strippel et\u00a0al. (2023). One of the implications of the range of methods used by the chapters is that insights can be gained from a variety of methods and that computational analysis of big data and qualitative approaches can complement each other ( Chapters\u00a05, \n6, 9, and 10).\nContent Analysis\nThough computational lexical approaches (see below) do analyze content, here we use the term to refer to manual, reliable human coding of content to categories, whether a priori, emergent, or a combination. Such content analysis has considered explicit or implicit hate speech, Islamophobic and anti-immigration attitudes, identification of target groups, etc. Content analysis may be applied not only to words but also to symbols (such as the ampersat @), other information (usernames), and particular terms to identify individually targeted tweets as hate messages (Chapter\u00a03).\nUdupa and Gerold (Chapter\u00a06) developed coding typologies for gender-based \nthemes (homophobic, threats to Hindu masculinity, and safety of Hindu \nBackground Scholarship and a Synthesis of Themes in the Book  293\nwomen, etc.) and for general themes (primarily religious). Phadke and Mitra \n(Chapter\u00a09) generated a multistage coding scheme, beginning with annotating \na small sample of tweets based on both a priori and emergent coding, leading to 13 codes within three collective action frames. Stringhini and Blackburn (Chapter\u00a011) took a more interpretive approach to identify discussion threads \ninvoking online attacks. Several of the researchers compared human coding/annotation with automated classifiers to establish reliability and validity so that the computer-based tools could be applied to large-scale data, and that subtle differences in content identification can be documented (Chapter\u00a010).\nBig Data\nMany studies of online hate collect and study \u201cbig data,\u201d or large sets of content, threads, links, etc. (for some reviews, see Chapters\u00a03 and 10). Such \nlarge-scale data allow for analyses of changes over time, comparisons across types of content and platforms, and detection of specific roles and sources. Several of these chapters report on their own big data ( Chapters\u00a08, 9, 10, and \n11). For example, Rea et\u00a0al. ( Chapter\u00a08) assessed over 3 million comments \nand nearly 1.5 million replies to locate and identify what they call \u201chate parties.\u201d Phadke and Mitra ( Chapter\u00a09) analyzed large numbers of Twitter \ntweets, Facebook messages, links from those to the same and other plat -\nforms, extremist accounts, and extremist groups, showing how hate groups promote their interests in interlocking webs of selectively sourced news posts, comments, and memes. Shmargad et\u00a0al. ( Chapter\u00a010) described how \nstreams of data can be parsed into three-message triplets to detect over-time changes in antisocial commenting in large-scale discussion threads during the January 6th Capitol riots, showing how prior postings and the levels of social approval they beget affect later one. Stringhini and Blackburn ( Chapter\u00a011) \nanalyzed \u201cbillions\u201d of social media posts to show how perpetrators coordi -\nnate online aggression attacks.\nLexical and Computational Analyses\nThe big data available from social media and other online media not only provide increasingly robust and sophisticated opportunities for analysis but also require appropriately scaled and parameterized computational tools. Researchers may apply meaning, linguistic, and speech dictionaries (a lexical approach), or train algorithms to infer reliable meaning (a machine learning approach, whether supervised or unsupervised), or develop and standardize multiple stages (pipelines) in such analyses.\nThe chapters refer to and specifically apply some of these tools, includ -\ning ADL\u2019s antisemitism classifier the Online Hate Index (OHI), CrowdTangle \n294  Ronald E. Rice\nAPI, custom-built classifier and modular pipeline, evaluations of particular \nnews sites by mediabiasfactcheck.org, Google\u2019s Jigsaw lab\u2019s Perspective, Hatebase.org (no longer operational), recent large language models, Reddit API, the Rand Corporation\u2019s \u201cOpenSources\u201d classifications, and YouTube data API, etc. (Chapters\u00a08, 9, and \n10). Several of the authors, such as T\u00f6rn-\nberg and T\u00f6rnberg (Chapter\u00a05), and Phadke and Mitra (Chapter\u00a09), combine one or more computational tools with qualitative/interpretive methods.\nChallenges and Interventions\nChallenges, tensions, and limitations pervade the study of online hate. While not the focus of this book, a crucial dimension of the online hate phenom -\nenon is how to deal with it, with the chapters and much other literature sug -\ngesting and evaluating various interventions.\nChallenges\nPerhaps the most central challenge, for researchers, policymakers, and online discussion boards and social media platforms, is defining \u201conline hate\u201d itself. Tong (Chapter\u00a03), as do others (e.g., Arora et\u00a0al., 2023; Baider, 2020; \nHietanen\u00a0& Eddebo, 2023; Siegel, 2020; Srba et\u00a0al., 2021), remarks on the wide variation and ambiguities in terms (such as antisocial norms, cyberhate, extreme speech, extremism, incivility, online aggression, online hate, toxic -\nity) and definitions of online (and offline) hate. However, as Tong concludes:\nAt their core, many of these terms highlight that hate\u00a0\u2013 both online and \noffline\u00a0\u2013 is a form of communication that promotes denigration or harm \nagainst targets based on their stigmatized, identity-based characteristics. \n(p.\u00a038)\nThis vagueness in terminology makes it difficult to generate accurate com -\nparisons, prevalence, or effects.\nA fundamental tension in dealing with online hate is between protection \nfrom hate speech and protection of free speech ( Chapters\u00a03 and 10). The bal -\nance between the two takes a wide range of forms depending on national and regional ideology and politics (see, e.g., Benesch, 2023). The expression of \nspeech that is deemed unacceptable in some contexts may even serve valuable civil and political functions in others, such as allowing dissent and identifying disagreement.\nThere are many problems and obstacles in obtaining and using big data. \nDifferent platforms provide different levels and types of access to their con -\ntent. Limits and formats of platform content and research tools may not correspond (Chapter\u00a010). Different platforms constrain the amount and type of content that can be collected in any one attempt. Stringhini and Black -\nburn (Chapter\u00a011) note the particular challenges of collecting 4chan content \nBackground Scholarship and a Synthesis of Themes in the Book  295\nbecause it is by design not only completely anonymous but also ephemeral, \nwith posts being automatically deleted quickly.\nThe chapters also mention various challenges and limitations of the lexical \nand computational approaches. For example, the meaning of some content may be ambiguous or misleading in isolation but revealed only in the con -\ntext of a threaded conversation, shared symbology and terms, or measured synchronization with other actions ( Chapter\u00a0 10). Arora et\u00a0 al. (2023) and \nSrba et\u00a0al. (2021 ) provide extended discussions of such challenges, such as \nconstantly changing forms and implicitness of such content; diffusion across platforms; distinguishing hate speech from offensive, abusive, socially unac -\nceptable, or protected content; difficulties, harm, and ambiguities of manual coding; analyzing multilingual or minor language content; integrating con -\ntext; passive, sarcastic, or satiric hate speech; understanding machine learn -\ning algorithms; and the need for effective, especially real-time, mitigation mechanisms.\nInterventions\nResearchers, computer and data scientists, tech companies, policymak-ers, legislators, and the public all have varying suggestions for responses and interventions (see, e.g., Barker\u00a0& Jurasz, 2018; Herz\u00a0& Molnar, 2012; \nMitts, 2022; Richardson-Self, 2021; Wachs et\u00a0 al., 2021 ). Based on a sys -\ntematic review, Blaya (2019) explained and critiqued three key intervention approaches toward cyberhate (legal, technological, and educational through the empowerment of the individuals such as through counter-speech) but found few evaluations of those interventions. Siegel\u2019s (2020) comprehensive review of online hate includes a detailed section on interventions intended to combat online hate speech and their effectiveness.\nA number of interventions receive mention within this book\u2019s chapters as \nwell, and as they appear, they are supported or challenged on the basis of the social processes that they may implicate. One explicit and common interven -\ntion is to suspend an account or deplatform (remove) it. As described in sev -\neral chapters, one problem with content moderation and suspensions is that users and groups can migrate to more lax platforms ( Chapters\u00a02, 6, 8, and 9). \nIndeed, some sites have no moderation and are supportive of \u201chate speech\u201d and may even moderate or filter out oppositional content ( Chapter\u00a03). Most \ndeplatforming attempts are aimed at an individual or group of users, or spe -\ncific content, rather than on the social processes underscored in this book. Because of the interdependent and interrelated social aspects of online hate, interventions need to take into account cross-platform coordination and relationships within and across comment threads ( Chapter\u00a08). Though not \nmuch discussed in the literature, perpetrators, accounts, or groups may be re-platformed. For example, although still exceedingly popular, with the change in ownership and name, X (formerly Twitter) has relaxed or removed constraints on misinformation (climate change, COVID-19 and vaccines, \n296  Ronald E. Rice\ngrooming, Russian state media, Trump, war, etc.) and hate speech (slurs, \nneo-Nazi, antisemitic, etc.) (Myers et\u00a0al., 2023). Myers et\u00a0al. list 19 articles or reports reporting increases in these problematic message types after reducing such limitations.\nBeyond human and AI content monitoring and deletion, more delayed \nand reactive approaches include restricting, quarantining, suspending, and deplatforming (banning or removing users and accounts; see Trujillo\u00a0 & \nCresci, 2022). Mitts (2022; Rae et\u00a0al., Chapter\u00a08; Walther, Chapter\u00a02) notes \nhow restricting, blocking, removing, and deplatforming may not have a sub -\nstantial effect, as posters go to other platforms or online groups that do not moderate hate content, or may even support (e.g., Gab Social), though these platforms have relatively less reach and membership. Unfortunately, even interventions such as counter-narratives can boomerang: A\u00a0review and study by Poole et\u00a0al. (2021) found that dense interconnected right-wing networks \nand platform affordances limited the effects of counter-narratives and even stimulated the perpetrators to intensify their voices. Deplatforming may be considered an individually oriented approach, rather than a social processes approach\u00a0\u2013 that is, it targets the individual user or content.\nHowever, underlying the general deplatforming approach lurk various \nlarger social processes. Van Dijck et\u00a0al. (2023 ) provide a deep and systemic \nanalysis of the technical, social, and infrastructural aspects and implications of deplatformization. They distinguish between deplatforming and deplat -\nformization. Deplatforming \u201csimply\u201d removes and bars single offenders (individuals or groups), though it is often part of a phased increasingly strin -\ngent approach (warnings, flagging, removal of content, quarantining, restric-tion, temporarily suspension, banning). Deplatformization moves beyond content moderation, taking a more integrated ecosystem approach, attempt -\ning to limit such actors to the online fringe by preventing them from access -\ning infrastructural resources. These may include banning associated accounts and groups from a specific platform, removing platforms from online app stores, demonetization, disabling analytics, removing links to mainstream sites and platforms, denying advertising and commercial transaction ser -\nvices, limiting the use of domain name services, implementing algorithms that demote their content, etc. There is no one consistent set of deplatformi -\nzation practices across providers, however. The concept of deplatformiza -\ntion expands our awareness of the broader interconnections among not only perpetrators\u2019 venues but also with the background infrastructural resources and legal landscape. These may be considered large social and economic processes involving sites, platforms, service providers, and financial actors. Deplatformizations, while being substantial and responsible responses to online hate also raise questions of Internet neutrality, control by tech compa -\nnies over access, what constitutes sufficiently unacceptable or illegal content and acceptable and allowable governance processes (Van Dijck et\u00a0al., 2023).\nBackground Scholarship and a Synthesis of Themes in the Book  297\nThe online hate interventions literature is vast and is not the focus of our \nchapters. However, several of the authors do refer to possible actions. An \nintriguing approach is \u201cshadow banning,\u201d where a user\u2019s posts are set by the platform to be not visible to anyone else, removing reinforcement from other users and preventing linking to those posts ( Chapter\u00a02). Tong ( Chapter\u00a03) \nreviews other interventions. One is preventing entry to users from extremist or raiding sites or via external links ( Chapter\u00a08). Another is engaging in (col-\nlective) counter-speech (perhaps generated through AI social bots), designed to influence bystanders and undecided users. Tong further discusses how some active viewers have attempted to reappropriate or reclaim hashtags, memes, phrases, or slurs. There has been, of course, extensive pressure on social media companies to more actively monitor and moderate, but they are somewhat free of responsibility for the content as legislated in section 230 of the United States\u2019 Communications Decency Act (3; see also Kosseff, 2019).\nTech companies have implemented a variety of changing techniques to \nprevent, identify, flag, remove, or punish online hate, with varying levels of effectiveness (Chapter\u00a03). These include extensive and rapid evaluation of content as it appears, using both algorithms and human monitors. Using human moderators is not only inefficient and subjective but also imposes substantial harm on the workers who are continuously exposed to such content (Chapter\u00a03). Yet Stringhini and Blackburn (Chapter\u00a011) feel that AI models to confront online attacks will not be able to stay ahead of the evolving hate process and are often even subverted themselves. Identifying, moderating, and removing hate content are difficult because of perpetra-tors\u2019 deliberate use of metaphor, misspellings, slang, symbols, and contex -\ntual material designed to evade content detection schemes ( Chapter\u00a08). Also, \nperpetrators can also create and abandon accounts, avoiding tracing and suspension.\nDeKeseredy advocates for more fundamental societal changes, such as \nchanging gender and sexuality norms, changing access to women\u2019s health resources, and fathers modeling behavior of \u201cwell-meaning men\u201d ( Chapter\u00a04). \nHe particularly argues that interventions should target incelosphere accounts, sites, and platforms.\nA perhaps even more subtle issue is that most platforms survive based on \neither direct advertising or sale of user information, so even hateful content can attract attention and generate revenue for the perpetrators (Chapter\u00a08).\nConclusion\nThis chapter and this book end with the underlying goal explained in the Introduction (Walther & Rice, this volume). The motivations for this book are to conceptualize, analyze, and interpret a crucial yet understudied aspect of online hate: the social processes generating, reinforcing, shaping, and \n298  Ronald E. Rice\ndiffusing that content. The chapters focus on diverse contexts, platforms, \ndata, methodologies, and processes of online hate. They are groundbreak -\ning, thoughtful, well-justified, rigorous, and detailed. The elements of these chapters as synthesized here (social processes, contexts, methods, and chal -\nlenges and interventions) not only provide broad and deep insights into and analyses of such social processes but also offer a rich foundation for further research into, and interventions about, online hate.\nAcknowledgments\nI am exceptionally grateful for Dr. Joe Walther\u2019s detailed, insightful, and challenging comments, edits, and questions on prior versions of this chapter.\nNote\nFor parsimony, chapter authors are either referenced explicitly or by their chapter \nnumber (2\u201311) as listed in the References. Other authors are referenced as usual.\nReferences\nArora, A., Nakov, P., Hardalov, M., Sarwar, S. M., Nayak, V., Dinkov, Y., Zlatkova, \nD., Dent, K., Bhatawdekar, A., Bouchard, G.,\u00a0.\u00a0.\u00a0.\u00a0& Augenstein, I. (2023).  Detect-\ning harmful content on online platforms: What platforms need vs. where research efforts go. ACM Computing Surveys , 56(3), 1\u201317. https://doi.org/10.48550/\narXiv.2103.00153\nBaider, F. (2020).  Pragmatics lost? Overview, synthesis and proposition in defin -\ning online hate speech. Pragmatics and Society, 11(2), 196\u2013218. https://doi.\norg/10.1075/ps.20004.bai\nBarker, K.,\u00a0& Jurasz, O. (2018).  Online misogyny as hate crime: A\u00a0challenge for legal \nregulation? Routledge.\nBenesch, S. (2023).  Content moderation needs auditing at scale, starting with Israel \nand Palestine. University of the Pacific Law Review , 54(4), 604\u2013611. https://schol-\narlycommons.pacific.edu/uoplawreview/vol54/iss4/6\nBlaya, C. (2019).  Cyberhate: A\u00a0 review and content analysis of intervention strat -\negies. Aggression and Violent Behavior, 45, 163\u2013172. https://doi.org/10.1016/j.\navb.2018.05.006\nBurston, A. (Chapter\u00a0 7 this volume). Digitally mediated spillover as a catalyst of \nradicalization: How digital hate movements shape conservative youth activism.\nCasta\u00f1o-Pulgar\u00edn, S. A., Su\u00e1rez-Betancur, N., Vega, L. M. T.,\u00a0& L\u00f3pez, H. M. H. \n(2021). Internet, social media and online hate speech. Systematic review. Aggression \nand Violent Behavior, 58, 101608. https://doi.org/10.1016/j.avb.2021.101608\nCollins, R. (2014). Interaction ritual chains and collective effervescence. In C. von \nScheve\u00a0& M. Salmela (Eds.), Collective emotions: Perspectives from psychology, \nphilosophy, and sociology (pp.\u00a0 299\u2013311). Oxford University Press. https://doi.\norg/10.1093/acprof:oso/9780199659180.003.0020\nDeKeseredy, W. S. (Chapter\u00a04 this volume). Misogyny and woman abuse in the ince-\nlosphere: The role of online incel male peer support.\nHerz, M.,\u00a0 & Molnar, P. (Eds.). (2012). The content and context of hate speech: \nRethinking regulation and responses. Cambridge University Press.\nBackground Scholarship and a Synthesis of Themes in the Book  299\nHietanen, M.,\u00a0& Eddebo, J. (2023). Towards a definition of hate speech\u00a0\u2013 with a \nfocus on online contexts. Journal of Communication Inquiry , 47(4), 440\u2013458. \nhttps://doi.org/10.1177/01968599221124309\nKosseff, J. (2019). The twenty-six words that created the internet . Cornell University \nPress.\nMitts, T. (2022). Moderating extremism: The challenge of combating online harms.  \n(under contract, Princeton University Press. (under contract))\nMyers, S. L., Thompson, S. A.,\u00a0& Hsu, T. (2023, October 28).  Swirl of vitriol and \nfalse posts. The New York Times , (B1, B6, B7). https://eeditionnytimes.pressreader.\ncom/the-new-york-times/20231028\nPhadke, S.,\u00a0& Mitra, T. ( Chapter\u00a09 this volume). Inter-platform information sharing, roles, \nand information differences that exemplify social processes of online hate groups.\nPoole, E., Giraud, E. H.,\u00a0& de Quincey, E. (2021). Tactical interventions in online \nhate speech: The case of # stopIslam. New Media\u00a0& Society , 23(6), 1415\u20131442. \nhttps://doi.org/10.1177/1461444820903319\nRae, S., Mathhew, B.,\u00a0 & Kraemer, J. ( Chapter\u00a0 8 this volume). \u201cHate Parties\u201d: \n Networked antisemitism from the fringes to YouTube.\nRice, R. E., Evans, S. K., Pearce, K. E., Sivunen, A., Vitak, J.,\u00a0& Treem, J. W. (2017).  \nOrganizational media affordances: Operationalization and associations with media \nuse. Journal of Communication, 67(1), 106\u2013130. https://doi.org/10.1111/jcom.12273\nRichardson-Self, L. (2021).  Hate speech against women online: Concepts and coun -\ntermeasures. Rowman\u00a0& Littlefield.\nShmargad, Y., Doe, K., Kenski, K., Rains, S.,\u00a0& Bethard, S. ( Chapter\u00a010 this volume). \nDetecting anti-social norms in large-scale online discussions.\nSiegel, A. A. (2020). Online hate speech. In N. Persily\u00a0& J. A. Tucker (Eds.), Social \nmedia and democracy: The state of the field, prospects for reform  (pp.\u00a056\u201388). \nOxford University Press. https://doi.org/10.1017/9781108890960\nSrba, I., Lenzini, G., Pikuliak, M.,\u00a0& Pecar, S. (2021).  Addressing hate speech with \ndata science: An overview from computer science perspective. In S. Wachs, B. Koch-Priewe,\u00a0 & A. Zick (Eds.), Hate speech\u00a0 \u2013 Multidisziplin\u00e4re Analysen und \nHandlungsoptionen (Hate speech\u00a0 \u2013 Multidisciplinary analyses and options for action. Theoretical and empirical approaches to an interdisciplinary phenome -\nnon). (pp.\u00a0317\u2013336). Springer VS. https://doi.org/10.1007/978-3-658-31793-5_14\nStringhini, G.,\u00a0& Blackburn, J. ( Chapter\u00a011 this volume). Understanding the phases \nof coordinated online aggression attacks.\nStrippel, C., Paasch-Colberg, S., Emmer, M.,\u00a0& Trebbe, J. (Eds.). (2023). Challenges \nand perspectives of hate speech research. Digital Communication Research , 12. \nOpen Access. https://www.digitalcommunicationresearch.de/v12/\nTong, S. T. ( Chapter\u00a03 this volume). Foundations, definitions, and directions in online \nhate research.\nTontodimamma, A., Nissi, E., Sarra, A.,\u00a0& Fontanella, L. (2021).  Thirty years of \nresearch into hate speech: Topics of interest and their evolution. Scientometrics, \n126, 157\u2013179. https://doi.org/10.1007/s11192-020-03737-6\nT\u00f6rnberg, A.,\u00a0& T\u00f6rnberg, P. ( Chapter\u00a05 this volume). from From echo chambers to \ndigital campfires: The making of an online community of hate within Stormfront.\nTrujillo, A.,\u00a0 & Cresci, S. (2022, November).  Make Reddit great again: Assessing \ncommunity effects of moderation interventions on r/The_Donald. Proceedings of \nthe ACM on hHuman-cComputer iInteraction,\u00a0 6, (CSCW2), 1\u201328, Article 526, \npp.\u00a01\u201328 (November). ACM. https://doi.org/10.1145/3555639\nUdupa, S.,\u00a0& Gerold, O. L. ( Chapter\u00a06\n this volume). \u201c  \u2018Deal\u201d\u2019 of the day: Sex, porn \nand political hate on social media.\nVan Dijck, J., de Winkel, T.,\u00a0& Sch\u00e4fer, M. T. (2023).  Deplatformization and the \ngovernance of the platform ecosystem. New Media\u00a0& Society , 25(12), 3438\u20133454. \nhttps://doi.org/10.1177/14614448211045662\n300  Ronald E. Rice\nWachs, S., Koch-Priewe, B.,\u00a0& Zick, A. (Eds.). (2021). Hate speech\u00a0\u2013 Multidisziplin\u00e4re \nAnalysen und Handlungsoptionen (Hate Speech\u00a0\u2013 Multidisciplinary analyses and \noptions for action. Theoretical and empirical approaches to an interdisciplinary phenomenon). Springer VS. https://pub.uni-bielefeld.de/record/2957520\nWalther, J. B. ( Chapter\u00a02 this volume). Making a case for a social processes approach \nto online hate.\nWalther, J. B.,\u00a0& Rice, R. E. ( Chapter\u00a01 this volume). Introduction to social processes \nof online hate.\nWaqas, A., Salminen, J., Jung, S. G., Almerekhi, H.,\u00a0& Jansen, B. J. (2019).  Mapping \nonline hate: A\u00a0scientometric analysis on research trends and hotspots in research on online hate.\u00a0 PLoS One,\u00a0 14(9), e0222194. https://doi.org/10.1371/journal.\npone.0222194\nWindisch, S., Wiedlitzka, S., Olaghere, A.,\u00a0& Jenaway, E. (2022).  Online interven -\ntions for reducing hate speech and cyberhate: A\u00a0systematic review. Campbell Sys-\ntematic Reviews, 18(2), e1243. https://doi.org/10.1002/cl2.1243\nNote: Page numbers in italic indicate a figure and page numbers in bold indicate a \ntable on the corresponding page.INDEX\n2channel 544chan 46, 53, 96, 161, 169, 172, 173, \n176; cross-platform hate and 24, 25; digitally mediated spillover 153\n \u2013 154; \nas fringe platform 47, 48; incels and 76\n \u2013 77; Leather Apron Club link 183; \nOperation Google 266; Politically Incorrect Board (/pol/) 250, 251; see also coordinated online aggression attacks\n\u201c14 Words\u201d 15, 1588chan 478kun 172, 17388 15\nacademic articles, growth of online hate \ncoverage in 280, 280\n \u2013 281\naccount suspension 63\nADL see Anti-Defamation League (ADL)\nagents of spillover 153aggregation threads, detecting 254\n \u2013 256\nAhmad, N. 128Akhtar, N. 132Albright, J. 16algorithmic recommender systems \n55\n \u2013 56\nALIPAC 209Allsup, J. O. 144alt-Right 153, 154\n \u2013 155, 160, 164alt-tech media 47  \u2013 49\nalt-tech platforms 169, 172Amazon.com 55American Identity Movement 147American Nazi Party 172American Renaissance 183Amnesty International United \nKingdom 45\namorphous cultures of hate 48Anastasopoulou, V . 25\nAnderson, K. V . 124\nanonymity 54\n \u2013 55\nanti-Asian online hate 46Anti-Defamation League (ADL) 170, \n187; American White Supremacy report 43; Center for Technology and Society 169; Hate on Display: Hate Symbols Database 14; Online Hate and Harassment Survey 44; Online Hate Index 174; survey of American Internet users 47\nanti-sexist men 85antisocial commenting in online \ndiscussions 220\n \u2013 246; Arizona Daily \nStar study 226  \u2013 228, 227, 228, \n229, 230, 230  \u2013 231, 231, 232, 232, \n233, 234  \u2013 235, 236; censorship \nof 222  \u2013 223; human annotation/\nautomated classification comparisons \n302  Index\nfor 226  \u2013 244; overview of 220  \u2013 221; \nReddit/Twitter January 6th Capitol \nriots comparison 236  \u2013 237, 238, \n239, 239  \u2013 240, 240, 241, 241  \u2013 242, \n243, 244; social norms in online communities 221\n \u2013 225\nArab Spring 168Arizona Daily Star online discussions \nstudy 226\n \u2013 236; collective descriptive \nnorms in 227  \u2013 230, 228, 229, \n230; collective injunctive norms in 230\n \u2013 231, 231, 232, 232; overview of \n226 \u2013 227, 227; perceived descriptive \nand injunctive norms in 233, 234\n \u2013 235, 236\nArora, A. 295Arts Electronic Festival 83Aryan Nations 170, 172, 186Assimakopoulos, S. 275Associated Press 46associative diffusion 225audience specification, hate messengers \nand 17\n \u2013 20, 18, 19\nawareness 285\nBachetta, P. 126\nBadaan, V . 213\nBaider, F. H. 275Bail, C. 98Barbrook, R. 170Barker, K. 275Barlow, J. P. 170Barth, N. 40Bates, L. 73, 74, 85BBS see bulletin-board system (BBS)Beam, L. 172behavioral extremism: defined 145; \nelements of 145; radical milieus and 147\nBenesch, S. 58biased news sources 210\n \u2013 211\nbiases 12Biden, J. 46Big Tech accountability, regulation, and \nmoderation 62\n \u2013 63\nBitchute 173Black, D. 171, 184Black Lives Matter 168black pilled 158BlackRock 177\n \u2013 178\nBlackwell, L. 50, 61Blaya, C. 295Bliuc, A. M. 49books, growth of online hate coverage \nin 274\n \u2013 275, 275, 275  \u2013 279\nBowker, L. 78Brand, R. 177\n \u2013 178, 180\nBrand, S. 170brigading 22, 41Bright, J. 98Bristol, K. 144Bronze Age Pervert (pseudonymous \ninfluencer) 172\nBrundidge, J. 97\n \u2013 98\nbulletin-board system (BBS) \n170 \u2013 171, 186\nBulli Bai 121bystanders 213\ncalling out 22\nCameron, A. 170cartoonish caricatures 15Casta\u00f1o-Pulgar\u00edn, S. A. 280, 292CCFL see College Conservatives for \nFreedom and Liberty (CCFL)\nCenter for Countering Digital Hate 75, \n76\n \u2013 77, 79  \u2013 80, 86  \u2013 87\nCenter for Technology and Society \n(CTS) 169\nCervone, C. 60Chads 74Cheng, J. 12, 224\n \u2013 225\nCitron, D. K. 57, 276civic and social life, effects of online hate \non 62\n \u2013 64\nClanton, C. 144clicktivism 204Clubhouse (social audio app) 121CNN 16Coe, K. 226, 230collective action frames 196; White \nSupremacy content framing 200\n \u2013 201\ncollective counter-speech 59collective effervescence 109collective group identity 51collective social norms 220College Conservatives for Freedom and \nLiberty (CCFL) 144, 148; census regions described 148\n \u2013 149; digitally \nmediated spillover at 153; see also digitally mediated spillover\nCollins, R. 100\n \u2013 101\nCommunications Decency Act (CDA) 62\ncommunity identity 53community provision, hate messaging \nand 20\n \u2013 21\nIndex  303\nconcern trolling 251, 263, 268\nconfederate flag 15connective action 145consequential harms of online  \nhate 57\nconspiratorial news sources 211content framing across social media \nplatforms, identifying 198\n \u2013 199, \n200 \u2013 202\ncoordinated online aggression attacks \n250 \u2013 269; anonymity impact on \n260 \u2013 262; attention span of 264; \nbeyond harassment 266  \u2013 267; call for \nattack phase of 256  \u2013 257; challenges \nin moderating 265  \u2013 268; concern \ntrolling and 263, 268; deplatforming and 267\n \u2013 268; detecting \nsynchronization 254  \u2013 256; examples \nof 250; execution phase of 258; as form of camaraderie 262\n \u2013 263; \noverview of 250  \u2013 252; premediated \nvs. opportunistic 264; preparation phase of 257\n \u2013 258; reporting back \nphase of 259  \u2013 260; research methods \nand data 252  \u2013 254; unanswered \nZoombombing calls for 265; victim targeting and 263\n \u2013 264; wrap up/\ncelebration phase of 260\ncounter-messaging 59, 98  \u2013 99\ncounter-speech 59cozy.tv 184crawlers 252\n \u2013 253, 253\ncross-platform hate 24  \u2013 25\ncross-platform raids 11Crowder, S. 179cute cat theory of Internet censorship \n123, 137\ncyberaggression 39cyberbullying 39cyberstalking, defined 40Cypris, N. F. 60\nDaily Wire, The 179\nDaniels, J. 15, 168, 171, 276#DarkBrandon 60\n \u2013 61\nDavis, M. 1, 4debunking 98deepfake pornography 80\n \u2013 81\ndeindividuation 54DeKeseredy, W. S. 29, 79, 81de Koster, W. 112Delhi Commission for Women 121demographic characteristics/attitudes 12deplatforming 63\n \u2013 64, 252, \n267 \u2013 268, 296\nDepp, J. 81descriptive norms of discussion 220Dewey, C. 40diagnostic social movements 196, 197Dice, M. 178\n \u2013 180, 181\ndigital campfires 100  \u2013 101\ndigitalization, extremism and 96digitally mediated spillover 144\n \u2013 165; \nbehavioral extremism, defined 145; on college campuses 153\n \u2013 156; \nconnective action, defined 145; described 144\n \u2013 145; digitally \nmediated, defined 146; extremist collective identity developed 157\n \u2013 160; ideological extremism, \ndefined 145; ideologically extreme transformation 160\n \u2013 162; overview \nof 144  \u2013 145; radicalization, defined \n145; and radicalization 156  \u2013 157; \nradicalization and 146  \u2013 148; \nresearch field sites 148  \u2013 149, \n150 \u2013 152; social movement, defined \n145; social movement spill over, defined 145\n \u2013 146; study coding/\nanalysis described 149, 153; tactical extremism and organizational implosion 162\n \u2013 164\ndirected hate messages 17, 25dogpiling 22, 41domain networks 200Donovan, J. 276Douthat, R. 82\n \u2013 83\ndoxxing 22, 40, 58, 164Dragiewicz, M. 81Dreyfuss, E. 276Duke, D. 99Durkheim, E. 93, 221; digital campfires \nand 100\n \u2013 101\necho chambers 93, 97  \u2013 99, 113; \nradicalization and 146; as  receiver-oriented 97\nechoic reappropriation 60edgy/edginess 160editability 285educator\u2019s role in online extremist \nmovements 207, 208\neffects of online hate 56\n \u2013 64; on civic \nand social life 62  \u2013 64; on individual \nvictims/targets 57  \u2013 58; on online \nbystanders 58  \u2013 62; overview of \n304  Index\n56 \u2013 57; remedies and solutions as \nresponse to 57  \u2013 58\nElectronic Frontier Foundation 170\n\u201cElliot Rodger\u2019s Retribution\u201d (YouTube \nvideo) 75\nElSherief, M. 17, 25Emmer, M. 278emotional instability 12emotions: online hate communities and \n108\n \u2013 113; reciprocal 111, 112; shared \n111 \u2013 112\nentryism theory 147  \u2013 148\nEpic of Gilgamesh, The 221ethnicity and intergroup online hate 45European Union General Data \nProtection Regulation 62\n \u2013 63\nEvolvi, G. 46experiencing online hate, described \n43\n \u2013 44\nextremist movements roles and \nnews sources 203  \u2013 211, 212  \u2013 213; \nfeatures of 206  \u2013 207; interventions \nfor online extremism 213; news source types shared 210\n \u2013 211; \noverview of 203  \u2013 204; participatory \nactivism and 204; relations and information-sharing influence 209\n \u2013 210, 210; social movements and \n204 \u2013 205, 207  \u2013 209; theoretical and \nonline roles, implications between 212\n \u2013 213\nextremist sites/forums for online hate \n49 \u2013 50\nFacebook 76, 94, 98; anonymity/\npseudonymity and 54; anti-LGBT content framing 201\n \u2013 202; hate \nBBSes 171; hate detection and prediction systems 23; hate-driven politics 95; hate group information-sharing activities 195, 199\n \u2013 200, \n201, 202  \u2013 203; identifying/mapping \nhate groups and ideologies 196, 198\n \u2013 199; online hate occurrences on \n47; as platform for radicalizing like-minded followers 194; recommender algorithms 55; social approval seeking/getting on 27; system-based cues 52; as venue for White Supremacist/online hate promoters 15\n \u2013 16; White Supremacy content \nframing 200  \u2013 201\nFacebook Messenger 148fake news sources 211Farkas, J. 47Fascist Forge 49\n \u2013 50\nfeatures/affordances contributing to \nonline hate 51  \u2013 56; algorithmic \nrecommender systems 55  \u2013 56; \nanonymity 54  \u2013 55; identifiability \n54 \u2013 55; interactive commenting 56; \nmultimedia hyperlinking/content sharing 55\n \u2013 56; overview of 51  \u2013 52; \nparalinguistic digital affordances 52\n \u2013 53; pseudonymity 54  \u2013 55; \nsystem-based cues 52  \u2013 53\nfeminist men 85Fields, E. 99filter bubbles 97; radicalization and 146Fink, L. 177flamer\u2019s role in online extremist \nmovements 207, 208\nframing: defined 195; hate group \ncommunication and 195\n \u2013 196\nFridman, L. 182Friedberg, B. 276fringe social media platforms 16, 17, \n47\n \u2013 49, 173, 176, 184  \u2013 185\nFuchs, C. 124  \u2013 125\nFuchs, T. 54Fuentes, N. 184fun: as meta-practice of online extreme \nspeech 138\n \u2013 139, 185; as social \ngratification of online hate 26  \u2013 27, 27\nFutrell, R. 278\nGab 47, 48, 169, 173; as fringe platform \n16 \u2013 17, 172, 176, 178; Leather Apron \nClub link 183; new n**ger meme \nrepository 26, 27\nGagliardone, I. 278Galante, D. J. 76Galinsky, A. D. 60#Gamergate 24, 40, 64Ganesh, B. 112Gaudette, T. 53gender-based online hate 44\n \u2013 45\ngeneralized hate messages 17, 25Gerold, O. L. 30Gettr 47, 49, 172, 173, 176, 178GhostEzra (pseudonymous \ninfluencer) 172\nGing, D. 276GitHub 121, 128Goffman, E. 101Goldberg, A. 225\nIndex  305\nGoogle 16, 62; deplatforming and \n63 \u2013 64; Jigsaw 221, 266; Ngram \nViewer 274\nGoyim Defense League 180, 181\ngroup-level/intergroup online hate \n42 \u2013 43, 43\nGroupMe 148, 155\nHabermas, J. 97\nHaimson, O. L. 222halala 122happy family trope 125Happy Merchant (cartoonish \ncaricature) 15\nharmful intentions, online hate messages \nand 13\n \u2013 14\nHarris, K. 46, 64hashtags 21\n \u2013 22\nhate: messaging 95; United States \nDepartment of Justice definition of 38\nhate attacks, social organization of \n21 \u2013 24\nHatebase dictionary 48hate groups: content framing, identifying \n198\n \u2013 199; Facebook/Twitter use by \n202 \u2013 203; identifying and mapping \n196; problem diagnosing techniques 198; prognostic offered by 198; as social movement organizations 195\nhate parties 168\n \u2013 188; Dice and \n178 \u2013 180, 181; vs. hate raids \n175 \u2013 176; Leather Apron Club \n180 \u2013 184; motivations for visiting \n184 \u2013 185, 186; overview of 168  \u2013 170; \nredpills and 177  \u2013 178; research \nmethods described 173  \u2013 175; \nsolutions to 186  \u2013 188; virtual \ncommunities and 170  \u2013 173; YouTube \n175 \u2013 176\nhate posters, described 1  \u2013 2\nhate raids 169, 185; vs. hate parties \n175 \u2013 176\nhate speech, United Nations \ndefinition of 38\nHayes, R. A. 52Heard, A. 81hegemonic masculinity 80Henry, N. 80Hervik, P. 278Herz, M. 276Hindu nationalism, sexual politics of \n126\n \u2013 128\nHine, G. 47  \u2013 48Hollaback! 61homosociality 139House Un-American Activities \nCommittee (HUAC) 163\nHoutman, D. 112Hugging Face 221\n#IamWithLiberalDoge 133\nidentifiability 54\n \u2013 55\nidentity: making imagined community of \nhate 104  \u2013 105; measuring, formation \non Stormfront 102  \u2013 104, 103; online \nhate communities and 101  \u2013 105\nideological extremism: defined 145; \nelements of 145; radical milieus and 147, 160\n \u2013 162\nimage-based involuntary sexual abuse \n(revenge porn) 29, 80\nimage-based sexual harassment 40, 57incel(s) 29; communities 76\n \u2013 77; \ndescribed 74  \u2013 75; ideology 75  \u2013 76; \nand porn connections, study of 81\n \u2013 82; posts 77; see also misogyny \nand woman abuse in incelosphere\nincel male peer support, woman abuse \nand 74\nincel movement 73, 74; Kimmel \ndefinition of 74; see also misogyny and woman abuse in incelosphere\nincelosphere 74; see also misogyny and \nwoman abuse in incelosphere\nIncels.Me 74individual differences approach to online \nhate 12\nindividual victims/targets, online hate \neffects on 57\n \u2013 58\ninfluence among roles 209  \u2013 210, 210\ninformation sharing across social media \nplatforms, analyzing 199  \u2013 202\ninformation sharing and framing \nstrategies 193  \u2013 215; extremist \nmovements roles and news sources 203\n \u2013 211, 212  \u2013 213; future research \ndirections 214; inter-platform, by online hate groups 194\n \u2013 203, \n211 \u2013 212; overview of 193  \u2013 194; \nresearch limitations 214; see also individual headings\nin-groups 195; members of 12\n \u2013 13\ninjunctive norms of discussion 220Instagram 47insular extremist sites/forums for online \nhate 49\n \u2013 50\n306  Index\ninsulation 14  \u2013 21; audience specification \nand 17  \u2013 20, 18, 19; community \nprovision and 20  \u2013 21; of hate \nmessages 16  \u2013 17; placement venues \nand 15  \u2013 16; symbology and 14  \u2013 15\nintentions to harm, online hate messages \nand 13  \u2013 14\ninteractive commenting 56\nintergroup online hate 42  \u2013 43, 43\nInternet Relay Chat 24inter-platform framing/information \nsharing by online hate groups 194\n \u2013 203, 211  \u2013 212; analyzing \ninformation sharing 199  \u2013 200; \ncollective action frames, hate group communication and 195\n \u2013 196, 197; \ncollective action frames analysed 212; differences across ideologies and platforms 200\n \u2013 202; Facebook \nand Twitter use 202  \u2013 203; hate \ngroup information-sharing activities 195; identifying and mapping 196, 198\n \u2013 199; news sources \nshared among roles 210  \u2013 211; \noverview of 194; social movement organizations 195\nintimate femicide 75intimate partner violence 39intimidation 22Iron Cross (\u2720) 15Iron March 49Islamophobic shayaris 122Italian Hate Map project 45\n#jag\u00e4rh\u00e4r (\u201cI\u00a0am here\u201d) 59\nJane, E. A. 39January 6th insurrection 153, 221; see \nalso Reddit/Twitter discussions of January 6th Capitol riots comparison\nJohanssen, J. 125Jones, A. 182Jones, D. K. 4jouissance 185Jurasz, O. 275\nKatz, J. 86\nKavanaugh, P. R. 222Keipi, T. 277Khalifa, M. 122Kimmel, M. 74Kleeman, J. 84Koch-Priewe, B. 279Krishnan, K. 127Ku Klux Klan 171, 172Kumar, M. 126\nLambda-MOO 51\nLangton, R. 123, 138Lapinski, M. K. 220LBRY 173leaderless cultures of hate 48Leather Apron Club 180\n \u2013 184, 187\nLeone, S. 122Levin, B. 99Levin, J. 73LGBTQ+ individuals hate-based \nharassment 43, 45, 46, 73, 77, 289\nLiberty Bell Publishing 170, 186Lingiardi, V . 45\nlocations for online hate 47\n \u2013 51; alt-tech \nmedia 47  \u2013 49; fringe social media \nplatforms 47  \u2013 49; insular extremist \nsites/forums 49  \u2013 50; mainstream \nsocial media 47; Metaverse virtual reality platforms 50\n \u2013 51\nLofland, J. 221  \u2013 222\nlone-wolf terrorists 93Lupu, Y. 46\nmainstream social media online hate 47\nmale entitlement see misogyny and \nwoman abuse in incelosphere\nmale homosociality 139male peer support theory 74, 78\n \u2013 81; \ninformational support and 79  \u2013 80\nmalevolent impulses 12Manosphere 125, 153, 160, 164many-to-one online hate 40\n \u2013 42, 43\nMarantz, A. 277Maratea, R. J. 222Mariconti, E. 24Martin, T. 161Marwick, A. E. 22, 23, 24, 41Massanari, A. 48Matamoros-Fern\u00e1ndez, A. 47Mathew, B. 48Matrix, The (film) 177McCarthy, J. D. 213Mechanical Turk 12Messerschmidt, J. 80, 85Meta 63\n \u2013 64\nMetaverse 62; for online hate 50  \u2013 51; \nsexual violence and harassment in 79\nMeWe 173MGTOWs (Men Going Their Own \nWay) 125\nIndex  307\nMicrosoft 266  \u2013 267\nMillar, S. 275\nMiller, P. 82Minassian, A. 75\n \u2013 76\nMinds 173misogyny 124\n \u2013 126, 139\nmisogyny and woman abuse in \nincelosphere 73  \u2013 88; ideology \nexamples of 75  \u2013 76; incels defined \n74 \u2013 75 (see also incel(s)); male peer \nsupport theory and 78  \u2013 81; overview \nof 73  \u2013 74; patriarchy and 81  \u2013 82; sex \nrobots and 82  \u2013 84; social media used \nby 76  \u2013 78; technology and 86  \u2013 87; \nwell-meaning men and 84  \u2013 86\nMitra, T. 205Mitts, T. 16, 277, 296mob-based hate 41Moderating extremism: The challenge of \ncombating online harms (Mitts) 277\nMolnar, P. 276motivational social movements 196, 197motivator\u2019s role in online extremist \nmovements 207, 208, 289\nM\u00fcller, K. 95multimedia hyperlinking/content sharing \n55\n \u2013 56\nmulti-user immersive experiences 50Munger, K. 21, 55\n \u2013 56\nMutz, D. C. 98Myers, S. L. 296\nN\u00e4si, M. 277\nNational States Rights Party 99neo-Nazi forum 94networked harassment 11, 22, 23, \n25, 41\nnews, growth of online hate coverage in \n279, 279\n \u2013 280\nNew York Times 82, 228, 230, 237, 240Nexis Uni 279no dox 157NoFap 125Nolan, J. 73not your personal army (NYPA) 265Nuclear Freeze Movement 146Nussbaum, M. C. 124\nObama, B. 105\n \u2013 106, 109  \u2013 111\nObar, J. A. 204\noffline aggression, online hate and 3  \u2013 4\nOksanen, A. 277one-click social approval signals 27\n \u2013 28one-on-one hate/hate-based harassment \n39 \u2013 40, 43; interpersonal nature of \n39 \u2013 40; private form of 39; public \nform of 39, 40\nonline auctions of Indian women \n121 \u2013 123, 128, 129, 130, 131, \n132 \u2013 133; activities related to 131\nonline bystanders, online hate effects on \n58 \u2013 62; active responses to 59  \u2013 62; \npassive effects 58  \u2013 59\nonline discussions 220  \u2013 246; antisocial \ncommenting in 220  \u2013 221; Arizona \nDaily Star study 226  \u2013 228, 227, \n228, 229, 230, 230  \u2013 231, 231, 232, \n232, 233, 234  \u2013 235, 236; automated \nclassifiers for 221; censorship of antisocial comments 222\n \u2013 223; \nlanguage and 225; posts vs. votes in 220; Reddit/Twitter January 6th Capitol riots comparison 236\n \u2013 237, \n238, 239, 239  \u2013 240, 240, 241, \n241 \u2013 242, 243, 244; relational \naspects of human behavior in 223; socialization processes and, data 224, 224\n \u2013 225; social norms in 221  \u2013 225; \ntemporal nature of digital trace data and 223\n \u2013 224\nonline harassment 39online hate: forms of 9; offline \naggression and 3\n \u2013 4; and offline \nviolence 95; research foci of 9  \u2013 10; \nsocial gratifications of 25  \u2013 29; \ntypes of 9; virtual communities and 170\n \u2013 173; see also coordinated \nonline aggression attacks; hate parties; one-on-one hate/hate-based harassment; online hate communities; online hate research; social gratifications of online hate; social processes of online hate\nonline hate, generation of 11\n \u2013 14; \nindividual differences and 12; intentions to harm and 13\n \u2013 14; social \nidentification and 12  \u2013 13\nonline hate, relational/broadcast \ntaxonomy of 39  \u2013 43, 43; \ngroup-level/intergroup acts 42  \u2013 43, \n43; many-to-one acts 40  \u2013 42, \n43; one-on-one hate/hate-based harassment 39\n \u2013 40, 43; overview of \n38 \u2013 39\nonline hate communities 93  \u2013 114; digital \ncampfires and 100  \u2013 101; Durkheim \n308  Index\nand 100 \u2013 101; echo chambers concept \nand 97  \u2013 99; emotions and 108  \u2013 113; \nidentity and 101  \u2013 105; inter-platform \nframing/information sharing by \n194 \u2013 203, 211  \u2013 212; overview of \n93 \u2013 94; reality and worldviews in \n105 \u2013 108; social media, rise of hate \npolitics and 95  \u2013 96; Stormfront.org \nand 99  \u2013 100; see also information \nsharing and framing strategies; Stormfront.org\nonline hate coverage, growth of \n273\n \u2013 298; in academic articles 280, \n280 \u2013 281; in books 274  \u2013 275, 275, \n275 \u2013 279; in news 279, 279  \u2013 280; \noverview of 274\nOnline Hate Index (OHI) 174online hate landscape 43\n \u2013 51; locations \nfor hate 47  \u2013 51; overview of 43; \nprevalence of experiencing 43  \u2013 44; \ntargets of hate 44  \u2013 46\nonline hate research 37  \u2013 65; background \nand definitions 38  \u2013 43; difficulties \nunderstanding/defining/documenting forms of online hate 38\n \u2013 39; effects \nof online hate 56  \u2013 64; features/\naffordances contributing to online hate 51\n \u2013 56; foci of 37; online hate, \nrelational/broadcast taxonomy of 39\n \u2013 43, 43; online hate landscape \n43 \u2013 51; overview of 37  \u2013 38; see also \nindividual headings\norganizational implosion, tactical \nextremism and 162  \u2013 164\nother-focused descriptive norms \n224, 224\nother-focused injunctive norms 224, 224out-groups 13, 195Ozler, K. B. 226, 227\nPaasch-Colberg, S. 278\nPalmer, W. 41Papakyriakopoulos, O. 231paralinguistic digital affordances (PDAs) \n52\n \u2013 53, 56\nParler 173participatory activism, extremist \nmovements and 204\npatriarchy 80, 81\n \u2013 82; well-meaning \nmen and 84  \u2013 86\nPatriot Front 147Pepe the Frog (cartoonish character) 15perceived social norms 220perma-Zucked 161Perspective API 221, 226, 228, 230, \n231, 233, 236, 237, 239\n \u2013 240\npervasiveness 285Peterson, J. 182Pew Research 44, 47, 62Phadke, S. 205Phillips, J. 55\n \u2013 56\nPhillips, W. 277placement venues 15\n \u2013 21; audience \nspecification and 17  \u2013 20, 18, 19; \ncommunity provision and 20  \u2013 21; \ninsulation and 16  \u2013 17\nPoal 173political online hate 45\n \u2013 46\npolitics, pornography, misogyny and \n124 \u2013 126\nPoole, E. 296Porn Hub 137pornified political culture 124posts 220prejudices 12private sociality 55pro-feminist men 85prognostic social movements  \n196, 197\nPro-Quest Social Sciences Database 280Proud Boys 147pseudonymity 54\n \u2013 55\nQAnon conspiracy 96, 125, 146Quinn, Z. 24, 40\nrabbit-holes 93\nrace and intergroup online hate 45Racial Slur Database 14radicalization: by algorithm 55; defined \n145; digitally mediated spillover and 146\n \u2013 148; hate groups social media \nuse and 202  \u2013 203; mechanisms of \n97 \u2013 99; spillover and, at W-CCFL \n156 \u2013 157\nradical milieu 147Rae, S. 30raids 24, 25Rains, S. A. 223, 226, 231raitas 128Rand Corporation \u201cOpenSources\u201d \nclassifications 210\n \u2013 211\nR\u00e4s\u00e4nen, P. 277Rashtriya Swayam Sevak Sangh \n(RSS) 126\nReal, K. 227\nIndex  309\nreality, online hate communities and \n105 \u2013 108\nreappropriation 60\nreciprocal emotions 111, 112Reddit 48, 64, 76, 154, 161; automated \nclassifiers used on 221; detecting individually targeted hate message in 23, 24; social approval seeking/getting on 27, 28; system-based cues 52\nReddit/Twitter discussions of \nJanuary 6th Capitol riots comparison 236\n \u2013 244; collective descriptive norms \non 237, 239, 239  \u2013 240; collective \ninjunctive norms on 240, 240, 240\n \u2013 241; overview of 236  \u2013 237, 238; \nperceived descriptive and injunctive norms on 241\n \u2013 244, 243\nredpill 164; described 177; hate parties \nand 177  \u2013 178; opportunities 176\nReichelmann, A. 44relational problems after online hate \nexperiences 57\nRepublican Party, campus-based \nextremism and 144\n \u2013 145; see also \ndigitally mediated spillover\nrevenge porn 22, 29Rice, R. E. 283, 285Richardson-Self, L. 278Rieger, D. 47Right To Be platform 61right-wing extremist social movements \n146\n \u2013 147; see also digitally mediated \nspillover\nRimal, R. N. 220, 227Robb, T. 99Rodger, E. 75Rogers, R. 55Romano, A. 61Rumble 173, 178Ruscher, J. B. 57\nsadistic desires 12\nSarkeesian, A. 9, 24Schaefer, D. 27Sch\u00e4fer, F. 54Schmid, U. K. 58Schoenebeck, S. 57Schulenberg, K. 50\n \u2013 51\nSchwartz, M. D. 29, 79Schwarz, C. 95Scott, A. O. 81Scrivens, R. 49searchability 285Second Wave Feminists 146Secret 54Segarra, I. M. 124self-categorize 13self-effects 4self-focused descriptive norms  \n224, 224\nself-focused injunctive norms 224, 224self-presentation 51, 285sex, porn, and political hate on social \nmedia 120\n \u2013 139; Internet censorship, \ncute cat theory of 137  \u2013 139; \nmisogyny and 124  \u2013 126, 139; Naziya \nand Nadiya experiences 120  \u2013 122; \nonline auctions 120  \u2013 123, 128  \u2013 133; \nsexual politics of Hindu nationalism and 126\n \u2013 128; study overview \n123 \u2013 124; Telegram chat 133  \u2013 137, \n134, 135\nsex robots 82  \u2013 84\nsexuality 45sexual orientation 45shadow banning 30, 297Shakespeare, W. 221Shapiro, B. 179shared emotions 111\n \u2013 112\nSharkey, N. 83Shmargad, Y. 223, 226, 227, 233, 244Siapera, E. 276Siegel, A. A. 213, 295Simi, P. 278slacktivism 204social approval seeking and getting \n27\n \u2013 28\nsocial gratifications of online hate \n25 \u2013 29; fun as 26  \u2013 27, 27; jouissance \nand 185; overview of 25; social approval seeking/getting as 27\n \u2013 28; \nsocial support as 28  \u2013 29\nsocial identification theory of online \nhate 12  \u2013 13\nsocial identity model of \ndeindividuation 54\nsocial isolation 57social media: online hate and 93; \nplatforms 15\n \u2013 16; political extremism \nand 93, 96; politics of hate and 95\n \u2013 96; social processes approach \nand 10  \u2013 11; see also online hate \ncommunities\nSocial Movement Organizations (SMOs) \n194; hate groups as 195\n310 Index\nsocial movements: connective action \nand 145; defined 145; extremism and \n204 \u2013 205\nsocial movement spill over, defined \n145 \u2013 146\nsocial organization of hate attacks \n21 \u2013 24\nsocial processes of online hate 9  \u2013 31, \n281 \u2013 298; affordances identified \n283, 283  \u2013 285, 285; background \n5; big data use 293; challenges and interventions 294\n \u2013 297; concepts and \ntheories 285  \u2013 288; content analysis \nmethods 292  \u2013 293; contexts of \n289 \u2013 292; cross-platform hate 24  \u2013 25; \neffects 291  \u2013 292; evidence supporting, \nmodel 288  \u2013 289; growth of online \nhate coverage 274  \u2013 281; insulation \nand 14  \u2013 21; intervention research \nimplications 30  \u2013 31; introduction \nto 1 \u2013 4; lexical and computational \nanalyses of 293  \u2013 294; mechanisms \n291; model 282  \u2013 289; overview of \n9 \u2013 11, 273  \u2013 274; perpetrators 289; \nplacement venues 15  \u2013 21; production \nof online hate 11  \u2013 14; propositions \noffered 282; social gratifications of online hate 25\n \u2013 29; social \norganization of hate attacks 21  \u2013 24; \nsymbology and 14  \u2013 15; targets/\nvictims 291; topics 291; venues 290, 290\nsocial shaming 22social support as social gratification \n28\n \u2013 29\nsocial support response 61solicitor\u2019s role in online extremist \nmovements 207, 207\n \u2013 208, 289\nSouthern Poverty Law Center (SPLC) \n193, 203; Hate Map (web page) 196\nspatial harassment 50Srba, I. 295Stacys 74, 79Statista 49Stein, S. K. 225stigmatizing beliefs/stereotypes 12stochastic hate and harassment 187stochastic terrorism 4, 96, 187Stormfront.org 19, 19\n \u2013 21, 29, 49, \n99 \u2013 100, 171; described 94, 99; \nemotions, post Obama election 109\n \u2013 112; identity formation on \n102 \u2013 104, 103; as online therapy for White Supremacists 112  \u2013 113; as \nspace to verbalize/transform emotions 108\n \u2013 113; terrorist attacks 99; \nworldviews, reality interpretations and 105\n \u2013 108; see also online hate \ncommunities\nstrategic network disruptions 63  \u2013 64\nstreamlining 83Strippel, C. 278, 292Sugiura, L. 77, 79, 81\n \u2013 82\nSuk, J. 82Sulli Deals 120\n \u2013 121, 128, 129\nswastika 15symbology, hate messages and 14\n \u2013 15\nsympathizer\u2019s role in online extremist \nmovements 207, 208  \u2013 209\nsystem-based cues 52  \u2013 53\ntactical extremism and organizational \nimplosion 162  \u2013 164\ntarget-rich social media environments \n15 \u2013 16, 17, 21\ntargets of online hate 44  \u2013 46\nTaylor, J. 183technology, digital misogyny and 86\n \u2013 87\nTelegram 47, 49, 122, 169, 172; chat \ndata themes 133  \u2013 137, 134, 135; \nLeather Apron Club link 183\nterrorism, defined 73theory of normative social behavior \n(TNSB) 227\nThorburn, J. 87Thorne-Finch, R. 85three parenthesis marks 15TikTok 55, 76Tontodimamma, A. 281T\u00f6rnberg, A. 3T\u00f6rnberg, P. 3toxic commenting 41toxic technocultures 48trads 128Tranchese, A. 77, 79, 81\n \u2013 82\nTrebbe, J. 278trench warfare 98tribal epistemology 108troll(ing) 12, 42True Companion 83Trump, D. 53, 105\n \u2013 106, 107  \u2013 108, \n153, 162\nTruth Social 173, 178Tsapatsoulis, N. 25Turner, R. H. 213Twitch 63\nIndex  311\nTwitter 62, 76, 98; anonymity/\npseudonymity and 54; anti-LGBT \ncontent framing 201  \u2013 202; automated \nclassifiers used on 221; comments to Brand BlackRock video 178; detecting individually targeted hate message in 21, 23, 24; hate BBSes 171; hate-driven politics 95; hate targets on 45, 46; identifying/mapping hate groups and ideologies 196, 198\n \u2013 199; information-sharing \nnetwork on 194, 195, 201, 202  \u2013 203; \nonline auctions of Indian Muslim women and 121, 128, 129; online hate occurrences on 47, 48; social approval seeking/getting on 27\n \u2013 28; \nsystem-based cues 52; as target rich social media environment 15\n \u2013 16; \nWhite Supremacy content framing 200\n \u2013 201; see also Reddit/Twitter \ndiscussions of January 6th Capitol riots comparison\nUdupa, S. 26, 30\n, 185, 278\nUnited Nations: hate speech definition \n38; on targets of hate crimes/speech 45\nUnited States Department of Justice: \nhate definition 38; Zoombombing and 42\nUnite the Right Rally 153USA Today 99\nVan Dijck, J. 296\nvanity metrics 52\n \u2013 53\nverbal harassment 50\n\u201cviolence of hate, the\u201d 73violent porn 78virtual communities: making of 170; \nonline hate and 170\n \u2013 173\nvirtual reality (VR) platforms for online \nhate 50  \u2013 51\nvisibility 285votes 220\nWachs, S. 279\nWaqas, A. 45, 281Warshaw, R. 85Washington Post 40well-meaning men 84\n \u2013 86; fathers as \n85 \u2013 86\nwe-ness 109  \u2013 110\nWhisper 54White Supremacists 14  \u2013 15, 49; emotions \nof, post Obama election 109  \u2013 112; \ninformation-sharing network by 201, 201; online therapy for 112\n \u2013 113; \nStormfront.org and 94; target-rich platforms for 15\n \u2013 16, 17, 21\nWhittaker, J. 56Whole Earth \u2018Lectronic Link \n(WELL) 170\nWimkin 173Win 173\nWojcieszak, M. E. 98women and hate-based harassment 45; \nsee also misogyny and woman abuse in incelosphere\nWoods, F. A. 57Woods, K. 184worldviews, Stormfront reality \ninterpretations and 105\n \u2013 108; as \ntribal epistemology 108\nWu, B. 24\nX (Twitter) 94\nYouTube 24, 25, 29, 47, 55, 56, 75, \n76, 154; \u201cBen Shapiro Owns the \nLibs\u201d videos 157; Brand channel on 177\n \u2013 178; Dice conservative channel \non 178  \u2013 180; hate parties 169, 171, \n172, 175  \u2013 176; hate speech policy \n176; Leather Apron Club channel 182\n \u2013 184; online auctions of Indian \nMuslim women and 121  \u2013 122, 128; \nvideos, coordinated aggression attacks targeting 251, 255\nYouTube Partner Program 185\nZald, M. N. 213\nZelensky, V . 174, 177\n \u2013 178\nZick, A. 279Zimmerman, G. 161\u201cZionist-occupied government\u201d \n(ZOG) 177\nZoombombing 42, 254, 256; anonymity \nand 261; attention span of 264; as form of camaraderie 262; preparation \nphase of 258; reasoning behind 251; reporting back phase of 259\n \u2013 260; \nvictim targeting and 263\nZuckerberg, M. 179Zuckerman, E. 137\n\u00c5kerlund, M. 53", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Information sharing and content framing across multiple platforms and functional roles that exemplify social processes of online hate groups", "author": ["S Phadke", "T Mitra"], "pub_year": "2024", "venue": "Hate speech is always with us, but the internet \u2026", "abstract": "This chapter summarizes our research that investigated how extremist organizations exploit  social media. 1 The approaches, methods, and results relied on research that scrutinized"}, "filled": false, "gsrank": 276, "pub_url": "https://library.oapen.org/bitstream/handle/20.500.12657/92521/9781040121573.pdf?sequence=1#page=218", "author_id": ["2ntdPF4AAAAJ", "5q_BkVAAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:k1M1dW5QQOYJ:scholar.google.com/&output=cite&scirp=275&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D270%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=k1M1dW5QQOYJ&ei=NbWsaP7HEuHUieoP9LKZ6AI&json=", "num_citations": 2, "citedby_url": "/scholar?cites=16591349462575960979&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:k1M1dW5QQOYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://library.oapen.org/bitstream/handle/20.500.12657/92521/9781040121573.pdf?sequence=1#page=218"}}, {"title": "Detecting incongruity between news headline and body text via a deep hierarchical encoder", "year": "2019", "pdf_data": "The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)\nDetecting Incongruity between News Headline and Body Text\nvia a Deep Hierarchical Encoder\nSeunghyun Yoon,1,2Kunwoo Park,3,4Joongbo Shin,1Hongjun Lim4\nSeungpil Won,1Meeyoung Cha,4,5Kyomin Jung1,2\n1Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea\n2Automation and Systems Research Institute, Seoul National University, Seoul, Korea\n3Qatar Computing Research Institute, Doha, Qatar4School of Computing, KAIST, Daejeon, Korea\n5Data Science Group, Institute for Basic Science (IBS), Daejeon, Korea\nAbstract\nSome news headlines mislead readers with overrated or false\ninformation, and identifying them in advance will better as-\nsist readers in choosing proper news stories to consume. This\nresearch introduces million-scale pairs of news headline and\nbody text dataset with incongruity label, which can uniquely\nbe utilized for detecting news stories with misleading head-\nlines. On this dataset, we develop two neural networks with\nhierarchical architectures that model a complex textual rep-\nresentation of news articles and measure the incongruity be-\ntween the headline and the body text. We also present a data\naugmentation method that dramatically reduces the text in-\nput size a model handles by independently investigating each\nparagraph of news stories, which further boosts the perfor-\nmance. Our experiments and qualitative evaluations demon-\nstrate that the proposed methods outperform existing ap-\nproaches and efficiently detect news stories with misleading\nheadlines in the real world.\nIntroduction\nMisleading or false information in journalism has posed a\ncritical social problem (Kwon et al. 2013). Much of the in-\nformation shared online lacks verification and thus can put\nour society to unseen threats. News headlines are known to\nplay an important role in making first impressions to read-\ners, and thereby deciding the viral potential of news stories\nwithin social networks (Reis et al. 2015). In digital environ-\nments under information overload, people are less likely to\nread or click on the whole contents but just read news head-\nlines (Gabielkov et al. 2016). Likewise, much of news shar-\ning is headline-based; people circulate news headlines with-\nout necessarily having read the full news story. On the other\nhand, an initial impression gained from the headline is per-\nsistent such that its stance remains even after reading the\nwhole news content (Ecker et al. 2014). Therefore, if a news\nheadline does not correctly represent the news story \u2014 or\nis incongruent \u2014 it could mislead readers into advocating\noverrated or false information, which then becomes hard to\nrevoke.\nIdentifying incongruent headlines in advance will better\nassist readers to choose which news stories to consume, and\nCopyright c\u20dd2019, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.thus decrease the chance of encountering unwanted infor-\nmation. Most previous research tackling this problem has\ntried to detect incongruity in news headlines either by an-\nalyzing linguistic features of news headlines (Blom and\nHansen 2015; Chen, Conroy, and Rubin 2015) or by analyz-\ning the textual similarities between news headlines and body\ntext (Ferreira and Vlachos 2016; Wang, Hamza, and Florian\n2017). However, lack of large-scale public dataset makes\nit difficult to develop sophisticated deep learning models\nthat are better suited for such challenging detection tasks,\nwhich usually require million-scale dataset across various\ndomains (Lowe et al. 2015; Go, Bhayani, and Huang 2009).\nThis paper, in an attempt to tackle the incongruent news\nheadline problem, presents a million-scale dataset that is\nbuilt on real news articles published over the course of two\nyears. We propose deep learning approaches that learn the\ncomplex textual relationship between the news headline and\nthe full news content, which turned out to be critical for clas-\nsifying incongruent headlines. Our models were tested on\nboth synthetic data as well as real news stories in the wild.\nOur contributions are summarized as follows:\n1. We release a million-scale dataset for the incongruent\nheadline problem, which covers almost all of the news ar-\nticles published in a nation over two years. The corpus is\ncomposed of pairs of news headlines and body text along\nwith the annotated incongruity label.\n2. We propose deep hierarchical models that encode the\nfull news article from a word-level to a paragraph-level.\nExperiments show our models outperform baseline ap-\nproaches. We also present a data augmentation method\nthat splits news paragraphs and annotates each of them\nseparately. This method not only reduces the data size that\na model handles but also increases the number of training\ninstances, which further boosts the performance.\n3. We extensively evaluate our models with real data. Man-\nual verification successfully demonstrates the efficacy of\nour dataset in training of incongruent headlines. In addi-\ntion, a crowdsourced experiment suggests the perceived\nlevel of incongruence could differ for certain news topics\n(e.g., politics) by individual beliefs and media outlets.\n791\nDataset# Samples Headline (Avg.) Body Text (Avg.)\nTrain Dev. Test # tokens # chunk # tokens # tokens # chunk # tokens\n/ chunk / chunk\nwhole 1.70M 100,000 100,000 13.71 1 13.71 518.97 8.37 62.00\nparagraph 14.20M 834,064 100,000 13.71 1 13.71 62.00 2.03 30.05\nTable 1: Properties of the dataset. The chunk in the body text implies paragraphs and sentences for the whole and the paragraph\ndataset, respectively.\nRelated Work\nThere has been a growing interest in detecting false infor-\nmation online. Various fake news datasets have been re-\nleased for developing AI approaches that make a social im-\npact (Kwon, Cha, and Jung 2017). One line of studies has\nfocused on detecting clickbait headlines , a type of web con-\ntent that attracts an audience and encourages them to click\non a link to a particular web page (Chen, Conroy, and Ru-\nbin 2015). One study (Chakraborty et al. 2016) released a\nmanually labeled dataset and developed an SVM model to\npredict clickbait based on linguistic patterns of news head-\nlines. Using this dataset, researchers suggested a neural net-\nwork approach that measures textual similarities between\nthe headline and the first paragraph (Rony, Hassan, and\nYousuf 2017). A national-level clickbait challenge was held,\nwhere the goal was to identify social media posts that entice\nits readers into clicking a link (cli 2017).\nThe Fake News Challenge 2017 was held to develop\nmethods that aim to estimate the stance of a news article (fnc\n2017). This challenge tackles the stance detection problem,\nwhose aim is to estimate the polarity of body text against\nits headline. This dataset provides 50,000 pairs of headline\nand body text that were generated from 1,683 original news\narticles. Each data entry is annotated with one of the four\nstances: agrees, disagrees, discusses, and unrelated. Several\ndeep learning models have been utilized for the task (Riedel\net al. 2017; Chopra, Jain, and Sholar 2017). Among them,\nthe winning model was a stacked ensemble approach that\ncombines predictions from XGBoost (Chen and Guestrin\n2016) based on hand-designed features and a deep convolu-\ntion dual encoder that independently learns word represen-\ntations from headline and body text through convolutional\nneural networks.\nThis current research tackles the headline incongruence\nproblem, which is a major kind of misinformation due to\nthe discrepancy in news headline and body text. A previous\nstudy proposed co-training approaches for a similar problem\nof detecting ambiguous headlines from the pair of title and\nbody text (Wei and Wan 2017). However, the researchers\nutilized a small set of news articles that are manually labeled\nand not shared for the public. Until today we notice there has\nbeen no million-scale data openly available.\nProblem and Dataset\nThe specific problem we tackle is the Headline Incongru-\nence Problem (Chesney et al. 2017), where a headline of\nnews article holds unrelated or distinct claims with the sto-\nries across its body text. Such incongruity in news stories is\nFigure 1: A news article with incongruent headline.\na major characteristic as clickbait. Figure 1 demonstrates a\nrepresentative example of such misinformation. The catchy\nnews headline promises to tell certain benefits of yoga, yet\nthe body text mainly is an advertisement for a new yoga pro-\ngram. Such incongruent headlines not only make a wrong\nimpression on readers (Ecker et al. 2014), but also become\nworse when it is shared on social media where most users\njust share without reading its actual contents (Gabielkov et\nal. 2016). Therefore, it is crucial to develop automated ap-\nproaches that detect incongruent headlines in news articles.\nTo create a new dataset, we crawled a nearly complete set\nof news articles published in South Korea from January of\n2016 to October of 2017. From over 4 million news articles,\nwe performed a series of cleansing steps such as removing\nnon-critical information (e.g., reporter name, non-textual in-\nformation such as photos and videos). Next, we transformed\nword tokens to integers, which will be released with vocab\nto help researchers utilize the dataset without the language\nbarrier.\nFollowing the above process, we generated the English-\nversion of dataset based on a large corpus of 0.12m news ar-\nticles (Horne et al. 2018). In this paper, we do not report any\nresults from the English version of the dataset for brevity, yet\nwe release the two datasets together on this github page1for\nthe research community.\nTraining Set Creation: It is almost impossible to man-\nually investigate million-scale news articles for any task.\nHere, we automatically generated labels on crawled news\n1http://github.com/david-yoon/detecting-incongruity/\n792\narticles. Rather than crafting new headlines, we implanted\nunrelated or topically-inconsistent content into body text of\noriginal news articles. This process can make a pair of the\n{headline }and{body text }where the headline tells dis-\ntinct stories with its article content. Hence, the automation\nprocess for creating incongruent-labeled data involves the\nfollowing steps: (1) sampling a target article from the cor-\npora (which may be on similar topics), (2) sampling part-of-\ncontent from another article of the corpora, and (3) inserting\nthis part-of-content to the target article.\nWe created congruent-labeled data by choosing them\nfrom the appropriate corpora. No single headline in this\nset overlaps with the incongruent-labeled data. Nonetheless,\nthis process may incur false-negative instances when a real\narticle having incongruent headline is chosen inappropri-\nately as a target. We took additional steps to reduce any Type\nII error via rule-based pre-processing such as inspecting ad-\nvertising phrases with an n-gram dictionary. We also hired\nhuman annotators to manually read 1,000 randomly sampled\narticles from the created dataset and check whether their\nheadlines are incongruent with the article content. Above\nmanual inspections demonstrated that our method success-\nfully generates news articles where its headline is incongru-\nent with its whole article content. We refer to this dataset as\nwhole for comparison with another dataset described below.\nParagraph Set Creation: The task of detecting incon-\ngruent headlines can be converted into a set of sub-problems\nthat inspect the textual relationship between a headline and\neach paragraph respectively, rather than examining the re-\nlationship between the headline and whole article content\nat once. Thus we created the paragraph dataset that trans-\nforms a pair of {headline }and{body text }into multiple\nsub-pairs of {headline }and{paragraph }. This conversion\nprocess not only reduces the length of text that a model\nshould process but also increase the total number of training\ninstances. In generating incongruent-labeled data, we sam-\npled{headline }and{paragraph }from different articles and\nthen matched them as pairs.\nIn this way, we created incongruent- and congruent-\nlabeled datasets and maintained train, development, and test\ndatasets that do not overlap each other. All datasets and their\ndetailed description including the original news articles and\nthe indexed version are made publicly available for the re-\nsearch community.\nMethodology\nOur objective is to determine whether a news article con-\ntains an incongruent headline, given a pair of {headline }and\n{body text }. We call the output probability being incongru-\nent headline incongruence score in this paper.\nBaseline approaches\nWe introduce four baseline approaches that have been ap-\nplied to the headline incongruence problem. Feature-based\nensemble algorithms have been widely utilized for their sim-\nplicity and effectiveness. Among various methods, the XG-\nBoost algorithm has shown superior performance across var-\nious prediction tasks (Chen and Guestrin 2016). For exam-ple, in a recent challenge on determining the stance of news\narticles at FNC-1, the winning team applied this algorithm\nbased on multiple features to measure similarities between\nthe{headline }and{body text }(Talos 2017). As a baseline,\nwe implemented the XGBoost (XGB) classifier by utiliz-\ning the set of features described in the winning model, such\nas the cosine similarities between the {headline }and{body\ntext}. In addition to this model, we also trained Support\nVector Machine (SVM) classifiers based on the same set of\nfeatures.\nRecurrent Dual Encoder (RDE) A recurrent dual en-\ncoder that is consisted of dual RNNs has been utilized to\ncalculate a similarity between two text inputs (Lowe et al.\n2015). We apply this model to the headline incongruence\nproblem via dual RNNs that encode the {headline }and\n{body text }, respectively. When RNN encodes word se-\nquences, each word is passed through a word-embedding\nlayer that converts a word index to a corresponding 300-\ndimensional vector. After the encoding step, the probability\nof being incongruent headline is calculated by using the final\nhidden state of each {headline }and{body text }RNNs. The\nincongruence score in the training objective is as follows:\np(label) =\u03c3((hH\nth)|M hB\ntb+b),\nL=\u2212logN\u220f\nn=1p(label n|hH\nn,th, hB\nn,tb),(1)\nwhere hH\nthandhB\ntbare last hidden state of each {headline }\nand{body text }RNN with the dimensionality h\u2208Rd. The\nM\u2208Rd\u00d7dand bias bare learned model parameters. Nis\nthe total number of samples used in training and \u03c3is the\nsigmoid function.\nConvolution Dual Encoder (CDE) Following the CNN\narchitecture for text understanding (Kim 2014), we ap-\nply Convolutional Dual Encoder to the headline incongru-\nence problem. Taking the word sequence of {headline }and\n{body text }as input to the convolutional layer, we obtained\na vector representation v={vi|i= 1,\u00b7\u00b7\u00b7, k}for each part\nof the article through the max-over-time pooling after com-\nputing convolution with kfilters as follows:\nvi=g(fi(W)), (2)\nwhere gis max-over-time pooling function, fiis the CNN\nfunction with i-th convolutional filter, and W\u2208Rt\u00d7dis a\nmatrix of the word sequence. We use dual CNNs to encode\nthe{headline }and the {body text }into vector representa-\ntions. After encoding each part of the news article, the prob-\nability that a given article has the incongruent headline is\ncalculated in a similar way to the equation (1).\nProposed methods\nWhile existing approaches perform reasonably for short text\ndata, dealing with a long sequence of words in news articles\nwill result in degraded performance (Pascanu, Mikolov, and\nBengio 2013; Bengio, Simard, and Frasconi 1994). For ex-\nample, the recurrent neural network utilized in RDE is poor\nin remembering information from the distant past. While\n793\nFigure 2: A diagram of the AHDE model. Entire text input\nis encoded from the word-level to the paragraph-level via\nemploying a two-level hierarchy. The model can learn the\nimportance of each paragraph in body text according to the\nheadline of the article from an attention mechanism.\nCDE learns local dependencies between words, its typical\nlength of convolutional filter keeps the model from captur-\ning any relationship between the words in distinct positions.\nThe inability to handle long sequences is a critical drawback\nof applying the standard deep approaches to the headline in-\ncongruence problem because a news article can be very long.\nThe average word count in our news corpus is 518.97.\nTherefore, we fill this gap by proposing neural architec-\ntures that efficiently learn hierarchical structures of long text\nsequences. We also present a data augmentation method that\nefficiently reduces the length of the target content while in-\ncreasing the size of the training set.\nAttentive Hierarchical Dual Encoder (AHDE) Inspired\nby a previous approach that models textual similarity\namong question-answer pairs using a hierarchical architec-\nture (Yoon, Shin, and Jung 2018), this model splits text into\na list of paragraphs and encodes the entire text input from\nthe word-level to the paragraph-level via employing a two-\nlevel hierarchy of the RNN architecture. Attention mecha-\nnism is added in paragraph-level RNN so that the model can\nlearn the importance of each paragraph in {body text }ac-\ncording to {headline }of the article. Additionally, we adopt\nbi-directional RNNs in paragraph-level RNN to exploit in-\nformation both from the past and the future.\nFigure 2 depicts a diagram of the model. For each para-\ngraph, the word-level RNN encodes the word sequences\nwp={wp,1:t}tohp={hp,1:t}. Next, the hidden states\nof the word-level RNN are fed into the next-level RNN that\nmodels a sequence of paragraphs while preserving the or-\nder. The hierarchical architecture can learn textual patterns\nof news articles with fewer sequential steps for RNNs com-\npared to the steps required for RDE. While RDE requires an\naverage of 518.97 steps to learn news articles in our dataset,\nAHDE only accounts for 62.0 and 8.37 steps for each level\nof RNN, on average. The hidden states of hierarchical RNNs\nFigure 3: Diagram of the independent paragraph method. A\ngiven news article is split by its paragraphs, each of which\nis compared to the headline to calculate incongruence score.\nThe maximum value is taken as the final incongruence score.\nare as follows:\nhp,t=f\u03b8(hp,t\u22121, wp,t),\nup=g\u03b8(up\u22121, hp),(3)\nwhere upis the paragraph-level RNN\u2019s hidden state at the p-\nth paragraph sequence, and hpis the word-level RNN\u2019s last\nhidden state of each paragraph hp\u2208 {h1:p,t}. Then, each up\nof{body text }is aggregated according to its correspondence\nwith the {headline }as follows:\nsp=v|tanh(WB\nuuB\np+WH\nuuH),\nai=exp(si)/\u2211\npexp(sp),\nuB=\u2211\niaiuB\ni,(4)\nwhere uB\npindicates the p-th hidden state of the paragraph-\nlevel RNN that learns the representation of {body text }.\nTheuHindicates the last hidden state of the paragraph-level\nRNN with the {headline }. We use the same training objec-\ntive as the RDE model, and the incongruence score is calcu-\nlated as follows:\np(label) =\u03c3((uH)|M uB+b) (5)\nHierarchical Recurrent Encoder (HRE) The AHDE\nmodel uses two hierarchical RNNs for encoding text from\nword-level to paragraph-level. The model requires higher\ncomputation resources in training and inference compared\nto those of non-hierarchical alternatives such as RDE and\nCDE. Therefore, we investigate an intermediate approach\nthat models hierarchical structures of news articles with a\nsimpler neural architecture. The text in the news {body text }\nis split into paragraphs, each of which is embedded by aver-\naging the word-embedding vector from its containing words.\nIn other words, HRE calculates hpin equation (3) by aver-\naging the word embedding among the words in paragraph\np,hp=\u2211\niembedding (wi), wi\u2282p-th paragraph. Then,\nparagraph-level RNN is applied with the paragraph-encoded\nsequence input, hp, for retrieving the final encoding vector\nof the whole {body text }.\nIndependent Paragraph (IP) Method In addition to the\nneural architecture, we propose a data augmentation method\nthat splits paragraphs in the {body text }and learns the re-\nlationship between each paragraph and headline indepen-\ndently.\n794\n(a) without IP method\n (b) with IP method\nFigure 4: Prediction performances across a different number of paragraphs in body text of the test dataset (a) without Indepen-\ndent Paragraph (IP) method and (b) with IP method. Line plots demonstrate prediction accuracies with increases in the number\nof paragraphs, and gray bars present the frequency of the test instances having a same number of paragraphs.\nFigure 3 depicts the diagram of the IP method, which\ncomputes incongruence score for each paragraph from its\nrelationship with the news headline. The final incongruence\nscore for the pair of {headline }and{body text }is deter-\nmined as the maximum score of incongruence scores as fol-\nlows:\np(label) =max(s1:p), (6)\nwhere spis the incongruence score calculated from the p-\nth paragraph of the {body text }and{headline }. The selec-\ntion of the maximum score can better identify news articles\nwhich contain a paragraph that is highly unrelated to the\nnews headline.\nFor training models with IP method, we use the para-\ngraph dataset and incongruence scores are calculated in the\nfollowing ways:\n\u2022XGB/SVM with IP: Extracting features from {headline }\nand each paragraph of {body text }, XGB/SVM measures\nthe incongruence score for each paragraph.\n\u2022RDE/CDE with IP: Both models encode word sequences\nin each paragraph of {body text }and compare them with\nthe encoded {headline }.\n\u2022AHDE with IP: To encode each paragraph in {body\ntext}, the first-level RNN encodes word sequences for\neach sentence and the second-level RNN takes a sequence\nof sentences as input, which is retrieved from the first-\nlevel RNN.\n\u2022HRE with IP: To obtain the incongruence score for each\nparagraph, HRE first calculates the mean of word vectors\nfor each sentence. Then, RNN encodes a sequence of sen-\ntences by taking the averaged word vectors as input.\nExperiments\nWe conduct a series of experiments to compare baseline\nmethods with the newly proposed models. All codes devel-ModelWithout IP With IP\nAcc. AUROC Acc. AUROC\nSVM 0.640 0.703 0.677 0.809\nXGB 0.677 0.766 0.729 0.846\nCDE 0.812 0.900 0.870 0.959\nRDE 0.845 0.939 0.863 0.955\nAHDE 0.904 0.959 0.895 0.977\nHRE 0.850 0.927 0.873 0.952\nTable 2: Model performance (top-2 scores marked as bold).\noped for this research will be made available via a public\nweb repository along with the dataset. We provide further\nimplementation details in the Appendix, which are neces-\nsary to reproduce the results in this paper.\nPerformance Comparison\nTable 2 presents performances of all approaches. Perfor-\nmances using whole dataset is also compared with those\nwith the IP method on paragraph dataset. We report accu-\nracy and the AUROC (Area Under Receiver Operating Char-\nacteristic) value, which is a balanced metric with regard to\nthe label distribution.\nWe first find that the four deep learning models outper-\nform feature-based machine learning models. Among the\ndeep learning models, the newly proposed AHDE achieved\nthe best performance with regard to accuracy and AUROC\n(0.904 and 0.977, respectively). Second, prediction perfor-\nmance increased significantly when the IP method was ap-\nplied. RDE and CDE got the advantage of the IP method\nmost, such that they even showed the performances com-\nparable to the hierarchical models. Even though those sim-\nple models do not have an appropriate structure to handle\nlengthy news data (i.e., news posts and news paragraphs on\naverage contain 518.97 and 62.00 words respectively in Ta-\n795\nFigure 5: Precision values for detecting news articles with\nincongruent headlines in the newly gathered dataset. The x-\naxis shows the top-N articles by incongruence scores, and\nthe y-axis presents its corresponding precision.\nble 1), the IP method did help them examine the relationship\nbetween the headline and each paragraph more efficiently.\nPerformance over Long Text Input\nOne major limitation of standard deep learning approaches\nis difficulty in processing very long text. To verify the abil-\nity of our models in handling lengthy news articles, we mea-\nsured the model performance under increasing input size.\nFigure 4 shows the result.\nFirst, as observed in Figure 4a, newly proposed models\n(AHDE and HRE) showed consistently higher performance\nover baseline approaches (e.g., XGB, RDE). When the IP\ndata augmentation method was applied, all six models bene-\nfit and show an increase in performance as shown in Fig-\nure 4b. Second, the figure suggests the robustness of our\nproposed models in handling long sequential input by their\nown hierarchical structures. Whether using the IP method\nor not, the newly proposed HRE and AHDE model consis-\ntently showed competitive performance irrespective of the\nparagraph size in {body text }. While AHDE performs better\nthan HRE when the number of paragraphs is a few, the per-\nformance gap became narrower as paragraph size increases\nand HRE achieves the best score for extremely long input\n(i.e., a news article containing 19-20 paragraphs). This trend\ncould be explained by the fact that HRE has a fewer number\nof trainable parameters compared to AHDE.\nWe present detailed results describing the model perfor-\nmance over varying content types in the Appendix.\nReal World Evaluation\nTo see the efficacy of our dataset and proposed models for\ndetecting incongruent headlines in the wild, we evaluated\nour pre-trained models on more recent news articles. We\nnewly gathered 232,261 news articles that were published\nfrom January to April of 2018. Testing our model with the\nnewly gathered dataset can show the generalizability of our\napproach in the real world.\nAt first, we manually inspected random samples of news\narticles to see whether they have incongruent headlines. Yet,\nwe could not retrieve enough number of articles having\nincongruent headlines for evaluation. This is possibly dueto the sparse number of incongruent headlines in the real\nworld. Therefore, instead of looking into the randomly sam-\npled dataset and labeling them for evaluation, we decided to\nmanually validate top Narticles by incongruence scores that\nare given by model prediction. Since models give incongru-\nence scores (i.e., output probability) based on its confidence\nfor classification, we believe such evaluation successfully\nestimates precision scores of prediction models. This type\nof evaluation is widely used in the tasks where it is impos-\nsible to count the true cases in a dataset such as question\nanswering system (Ferrucci 2012).\nFigure 5 shows the precision scores for AHDE models\nthat are trained with- and without the IP method, respec-\ntively. The x-axis presents the top-N articles by incongru-\nence scores that are retrieved by the models out of the newly\ngathered articles over 4 months. The y-axis demonstrates the\nprecision value corresponding to the top N articles.\nHere we make three observations. First, the AHDE model\nwith the IP augmentation consistently shows higher preci-\nsion than the AHDE model without the IP method. This\nfinding supports the superior performance of the IP method\nacross different evaluations. Second, the AHDE model with\nIP achieved the precision of 1.0 for the top 25 articles. Even\nthough the model was trained by a separate dataset, it suc-\ncessfully filtered out real cases where its headline conveys\ndifferent stories with associated body text. Third, when we\nevaluate the top 250 articles, the precision of the AHDE\nmodel with IP reduced to 0.82. Nevertheless, this precision\nvalue is high enough to be utilized for detection in real news\nplatforms.\nThe above observations suggest that our approach and\ndataset could be applied for the headline incongruence prob-\nlem in the wild. Based on application scenarios, one could\ncontrol the trade-off between precision and recall by chang-\ning the model thresholds.\nDiscussion\nVarying perceptions on headline incongruence\nSo far, we have treated incongruence score as an inherent\nvalue that is fixed for each news article. We conducted addi-\ntional surveys using the Amazon Mechanical Turk (MTurk)\nservice to understand whether the general public would also\nconsider the news articles predicted by our models to con-\ntain incongruent headlines. We also tested whether people\u2019s\nperception on incongruence score varies by individuals\u2019 par-\ntisanship, hypothesizing from a previous finding that peo-\nple\u2019s perception on the veracity of news varies by political\nstance (Allcott and Gentzkow 2017).\nWe first manually gathered news articles from two me-\ndia outlets. In order to retrieve as many incongruent news\nheadlines as possible, we selected two media outlets that\nare considered not trustworthy by common journalistic stan-\ndards (referring to mediabiasfactcheck.com): one was cho-\nsen from conservative media ( Media A ) and another from\nliberal media (we call Media B ). We do not reveal these\nmedia names, as the particular choice of a media outlet is\nless of a concern to our study. Given the definition of incon-\ngruent headline and article selected by the model from each\n796\nFigure 6: MTurk results indicating political stances of sur-\nvey participants (the x-axis) and their responses to articles\nof high incongruence score (the y-axis).\nmedia, we asked 100 Amazon Mechanical Turk workers to\nanswer the following question \u201cDo you think the headline of\nthe above article is incongruent with its body text?\u201d\nFigure 6 confirms that MTurk workers tend to find arti-\ncles of high incongruence scores to contain misleading head-\nlines. One interesting trend to note is the change in per-\nceived incongruence score by individual belief. While non-\nliberal participants considered news samples in Media B to\nhave a similar level of incongruence to Media A samples,\nliberal participants found Media B to be less incongruent.\nThis finding suggests that while our approach is applicable\nin general the perceived incongruence level may be judged\ndifferently for certain news topics (like politics). This im-\nplies that news service providers should be cautious when\nemploying human coders and crowdsourcing workforce to\nget a fair label on misinformation and fake news.\nHierarchical Encoders for Stance Detection\nTo further the generalizability of deep approaches proposed\nin this paper, we conducted an additional experiment on the\nFNC-1 dataset (fnc 2017), aimed for stance detection . This\nproblem is similar to the headline incongruence problem in\nthat one needs to compare the textual relationship between\nnews headline and its whole content, but different in that its\ntarget label consists of four different cases (i.e., unrelated,\nagree, disagree, and discuss). To have a similar setting with\nour task, we transformed these four labels into binary, which\nis \u201cunrelated\u201d and \u201cothers\u201d and trained models.\nWe compared our hierarchical deep learning approaches\n(i.e., AHDE, HRE) with feature-based approaches and stan-\ndard deep learning models. We also included ensemble mod-\nels that combine the predictions of XGB and each deep\nlearning models, because an ensemble of XGB and CDE\nwas the winning model of the FNC-1 challenge (Talos\n2017). Among single models, XGB outperformed the other\nmodels with the accuracy of 0.9279. Among deep learning\nmodels, the AHDE model was the best with the accuracy of\n0.8444. Better performance of XGB over deep approaches\nmight be caused by insufficient variations of training in-\nstances in the FNC-1 dataset. We noticed that even though\nthe training set includes around 50k instances, many news\narticles of the unrelated label were generated from 1,683\noriginal news articles by swapping headlines with one an-\nother and thus 29.7 instances had identical body text.Above reasons might lead the challenge winners to use\nensemble models that combine predictions of feature-based\napproaches and deep neural networks. The XGB+CDE en-\nsemble model achieved the accuracy of 0.9304, outperform-\ning all of the single models. When we combined the pre-\ndiction of AHDE with XGB, the ensemble model achieved\nthe best accuracy of 0.9433. Incorporating with the results\nin Table 2, this finding suggests that the proposed hier-\narchical neural networks effectively learn textual relation-\nships between two texts rather than standard approaches. We\nstrongly believe the highest accuracy of XGB among single\nmodels is due to the aforementioned limitation of the FNC-1\ndataset, and hence the ensemble approach may not be neces-\nsary if given dataset is large enough to train neural networks.\nIn additional experiments on our dataset proposed in this pa-\nper, we found that the AHDE model solely achieved the best\naccuracy than any combinations of other approaches for the\nensemble.\nFuture Directions\nA natural extension of this study is to develop and improve\nprediction models for detecting news articles with incongru-\nent headlines by considering syntactic features. A simple\nway is to apply NLP pipelines such as part-of-speech tag-\nging or named entity recognition to reduce the complexity\nof raw text input. It would be also possible to develop tree-\nshaped deep neural architectures similar to LSTM-tree (Tai,\nSocher, and Manning 2015) to understand the textual rela-\ntionship between headline and body text more sophisticat-\nedly.\nAnother study could extend this work to measure the in-\ncongruence of title and content across other types of online\ncontents. The title plays a crucial role in attracting users into\nclicking and consume digital contents such as blog articles,\nonline videos, and even scientific papers. Similar to the in-\ncongruent headline problem, automatically identifying such\nincongruent titles of various contents will assist people to be\nhappier. To this end, future researchers could share different\ntypes of the dataset and improve AI approaches that measure\nthe incongruity of title and content.\nConclusion\nIn this paper, we study the problem of incongruent headline\ndetection. To this end, we release a million-scale data cor-\npus suitable for detecting news articles where its body text\ndisagrees with the headline. We also propose two neural net-\nworks that efficiently learn the textual relationship between\nheadline and body text via a hierarchical recurrent architec-\nture. The experiments demonstrate that the models trained\non our released corpus show decent performances both on\nthe synthetic dataset and on the real-world dataset. More-\nover, we introduce a data augmentation method, called In-\ndependent Paragraph, that makes headline-paragraph pairs\nby splitting the whole body text into separate paragraphs\nwhich improves the performance of the models. We hope\nthat our dataset and approach will help detect news articles\nwith a misleading headline that can bait readers\u2019 attention\nand hence contribute to the emerging threats of misinforma-\ntion to our society.\n797\nAcknowledgments\nSeunghyun Yoon and Kunwoo Park equally contributed to\nthis work. Majority of this work was done while Kun-\nwoo Park was at KAIST. We sincerely thank Taegyun Kim\nfor preparation of dataset and the reviewers for their in\ndepth feedback that helped improve the paper. This research\nwas supported by the Ministry of Trade, Industry & En-\nergy (MOTIE, Korea) under Industrial Technology Innova-\ntion Program (No. 10073144), the National Research Foun-\ndation of Korea (NRF) funded by the Korea government\n(MSIT) (No. 2016M3C4A7952632), Basic Science Re-\nsearch Program (No. NRF-2017R1E1A1A01076400) and\nNext-Generation Information Computing Development Pro-\ngram (No. NRF-2017M3C4A7063570) through the Na-\ntional Research Foundation of Korea (NRF) funded by the\nMinistry of Science, ICT.\nImplementation Details\nRecurrent Dual Encoder (RDE)\nAmong variants of RNN functions, the Long Short-Term\nMemory (LSTM) architecture is commonly used for its ef-\nficiency in addressing the exploding and vanishing gradient\nproblem that arises from standard recurrent units (Hochre-\niter and Schmidhuber 1997). Instead of that, we used the\nGated Recurrent Unit (GRU), because it shows compatible\nperformance to the LSTM with a fewer number of weight\nparameters (Chung et al. 2014). We used a two single-layer\nGRU with 300 hidden units. The {headline }and{body text }\nwere independently encoded using dual GRUs, which share\nweights. The hidden states were initialized using orthogo-\nnal weights (Saxe, McClelland, and Ganguli 2013), and the\nembedding layer was randomly initialized from the Gaus-\nsian distribution with 300 dimensions. The vocabulary size\nin the news dataset was 253,067. We used the Adam opti-\nmizer (Kingma and Ba 2014) including gradient clipping by\nnorm at a threshold of 1. For the purpose of regularization,\nwe applied Dropout (Srivastava et al. 2014) with the ratio of\n0.2.\nConvolution Dual Encoder (CDE)\nWe used two single-layer CNNs with a total of 1,000 filters,\nwhich involved five types of filters K\u2208R{1,3,5,7,9}\u00d7d,\n200 per type. The weight matrices for the filters were\ninitialized using the Xavier method (Glorot and Bengio\n2010) and weights for the two CNNs were shared. Adam\noptimizer (Kingma and Ba 2014) was used with the initial\nlearning rate of 0.001. Other implementation details are\nsimilar to the RDE model.\nAttentive Hierarchical Recurrent Dual Encoder\n(AHDE)\nWe used two single-layer GRU with 300 hidden units for\nthe word-level RNN portion to encode the word sequence\nin each {headline }and{body text }. We used another two\nsingle-layer bidirectional GRU with 100 hidden units for the\nparagraph-level RNN portion to encode the final hidden statesequences from each word-level RNN of the {headline }and\n{body text }. The weights of the GRU are shared within the\nsame hierarchical portion, word-level and paragraph-level.\nFor regularization, dropout was applied with the ratio of 0.3\nfor the word-level RNN portion in AHDE. The other settings\nwere the same with RDE.\nHierarchical Recurrent Encoder (HRE)\nThe dimension of the word-embedding vector was set to be\n300, which was pre-trained from the training corpus with the\nskip-gram model (Mikolov et al. 2013). Parameter settings\nfor the paragraph-level RNN in the HRE model were same\nas those of the AHDE model.\nMore Analysis of Models for Types of Articles\nIn order to cover various cases in which incongruent head-\nlines can occur, we put three different cases for the gener-\nation as described below. In all cases, we set the portion of\nimplanted part-of-contents to take up less than 50% of the\narticle length.\n1. Sample nconsecutive paragraphs from an article and in-\nsert them into the {body text }of the target article.\n2. Sample nnon-consecutive paragraphs from one article\nand insert them randomly into the {body text }of the tar-\nget article.\nTo better understand how the models work, we used four\ndifferent types of test datasets generated separately by the\nrule 1 and 2.\n\u2022Type 1 : Applying rule (1) with only one paragraph ( n=\n1)\n\u2022Type 2 : Applying rule (1) with two or more consecutive\nparagraphs ( n > 1)\n\u2022Type 3 : Applying rule (2) without random arrangement\n(maintaining the ordering of the sampled paragraphs)\n(n > 1)\n\u2022Type 4 : Applying rule (2) ( n > 1)\nThe difference between the Type 1 and Type 2 data lies in the\nnumber of paragraphs implanted into a target article. Type 2\ndata represents the cases that contain a larger portion of im-\nplanted contents. With comparisons of Type 3 and Type 4\ndata, we could understand how the models perform when\nthey examine an article that has implanted chunks of text\nscattered in the {body text }whether keeping the original or-\nder of its context or not. The evaluation results of each model\nwith the 4 types of test dataset are presented in Figure 7.\nAHDE/RDE: These RNN-based approaches performed\nbetter in all types compared to the others, which is attributed\nto the ability to use sequential information. In our experi-\nments, when implanted contents appeared at the beginning\nor the end, AHDE and RDE were highly accurate (\u2018with-\nout IP method\u2019 case, 0.15 - 0.2 higher than average), while\nthe others yielded scores similar to their averages. Further-\nmore, these models achieved a relatively high-performance\ngain by randomly shuffling the order of implanted contents\n(comparing Type 3 with Type 4 data). Additionally, we can\n798\n(a) without IP method\n(b) with IP method\nFigure 7: Analysis of the models. Top performance is\nmarked as bold for each type.\nsee the effect of the hierarchical architecture by comparing\nType 1 to Type 2 data. AHDE and RDE achieve similar ac-\ncuracy for Type 2 data, yet AHDE performed better on Type\n1 data (i.e., fewer polluted sentences). This indicated that\nthe model could memorize the article more systematically\nvia the hierarchical architecture.\nCDE: CDE is a CNN-based model that uses a specific win-\ndow of words as contextual information. Local features are\ncomputed using filters of various sizes and the model finds\nthe max value over time. In this way, CDE extracts one of the\nmost effective features to determine whether the article has\nincongruent headlines. Thus CDE depends upon the number\nof incongruent words, rather than the patterns of implanted\nparagraphs, such as the order or the insertion position, to in-\nvestigate the relationship between headline and body text.\nIn Type 2, CDE produced results comparable to the others.\nThis is because the article has more numbers of incongruent\nwords, so there is a higher chance of the model extracting\nuseful features. However, this is not guaranteed when im-\nplanted contents covered a similar topic.\nHRE: HRE performance is degraded when the portion of\nimplanted news contents becomes larger. This is because\nthe number of commonly used words increases with the sen-\ntence length. This leads to a dilution of the detection features\non the word embedding, and then the model does not work\nwell. As with AHDE/RDE, HRE is an RNN-based model,\nwhich means it also utilizes sequential information. This ef-\nfect is particularly noticeable when implanted paragraphsare scattered throughout the article (as in Type 3 and Type 4\ndata).\nWith Independent Paragraph method: For each type, we\nhave conducted experiments using both with- and without-\nIP methods. From Figure 7a and 7b, we find that the IP\nmethod improves the performance compared to the without-\nIP method and such a trend is particularly pronounced when\nthe portion of implanted content is relatively small. This\nis because when news content is divided into several para-\ngraphs, the model can analyze each part in more detail. The\nhierarchical architecture enables the model to produce simi-\nlar effects even on the whole text. With multiple systematic\nencoding, it can help the model remember the lengthy or\ncomplex things that might be missed when using a simple\nmodel.\nReferences\nAllcott, H., and Gentzkow, M. 2017. Social media and fake\nnews in the 2016 election. Journal of Economic Perspectives\n31(2):211\u201336.\nBengio, Y .; Simard, P.; and Frasconi, P. 1994. Learning\nlong-term dependencies with gradient descent is difficult.\nIEEE transactions on neural networks 5(2):157\u2013166.\nBlom, J. N., and Hansen, K. R. 2015. Click bait: Forward-\nreference as lure in online news headlines. Journal of Prag-\nmatics 76:87\u2013100.\nChakraborty, A.; Paranjape, B.; Kakarla, S.; and Ganguly,\nN. 2016. Stop clickbait: Detecting and preventing clickbaits\nin online news media. In Proceedings of the ASONAM .\nChen, T., and Guestrin, C. 2016. Xgboost: A scalable tree\nboosting system. In Proceedings of KDD .\nChen, Y .; Conroy, N. J.; and Rubin, V . L. 2015. Misleading\nonline content: Recognizing clickbait as false news. In Pro-\nceedings of the ACM Workshop on Multimodal Deception\nDetection .\nChesney, S.; Liakata, M.; Poesio, M.; and Purver, M. 2017.\nIncongruent Headlines: Yet Another Way to Mislead Your\nReaders. In Proceedings of the EMNLP Workshop: Natural\nLanguage Processing meets Journalism , 56\u201361.\nChopra, S.; Jain, S.; and Sholar, J. M. 2017. Towards Auto-\nmatic Identification of Fake News: Headline-Article Stance\nDetection with LSTM Attention Models.\nChung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y . 2014. Em-\npirical evaluation of gated recurrent neural networks on se-\nquence modeling. arXiv preprint arXiv:1412.3555 .\n2017. Clickbait Challenge. http://www.clickbait-challenge.\norg. [Online; accessed 10-Feb-2019].\nEcker, U. K.; Lewandowsky, S.; Chang, E. P.; and Pillai,\nR. 2014. The effects of subtle misinformation in news\nheadlines. Journal of experimental psychology: applied\n20(4):323.\nFerreira, W., and Vlachos, A. 2016. Emergent: a novel data-\nset for stance classification. In Proceedings of the NAACL-\nHLT.\nFerrucci, D. A. 2012. Introduction to \u201cthis is watson\u201d. IBM\nJournal of Research and Development 56(3.4):1\u20131.\n799\n2017. Fake News Challenge. http://www.\nfakenewschallenge.org/. [Online; accessed 10-Feb-2019].\nGabielkov, M.; Ramachandran, A.; Chaintreau, A.; and\nLegout, A. 2016. Social clicks: What and who gets read on\ntwitter? ACM SIGMETRICS Performance Evaluation Re-\nview 44(1):179\u2013192.\nGlorot, X., and Bengio, Y . 2010. Understanding the diffi-\nculty of training deep feedforward neural networks. In Pro-\nceedings of the AISTATS .\nGo, A.; Bhayani, R.; and Huang, L. 2009. Twitter sentiment\nclassification using distant supervision.\nHochreiter, S., and Schmidhuber, J. 1997. Long short-term\nmemory. Neural computation 9(8):1735\u20131780.\nHorne, B. D.; Dron, W.; Khedr, S.; and Adali, S. 2018. Sam-\npling the News Producers: A Large News and Feature Data\nSet for the Study of the Complex Media Landscape. In Pro-\nceedings of the ICWSM .\nKim, Y . 2014. Convolutional neural networks for sentence\nclassification. In Proceedings of the EMNLP , 1746\u20131751.\nKingma, D., and Ba, J. 2014. Adam: A method for stochastic\noptimization. arXiv preprint arXiv:1412.6980 .\nKwon, S.; Cha, M.; Jung, K.; Chen, W.; and Wang, Y . 2013.\nProminent features of rumor propagation in online social\nmedia. In Proceedings of the ICDM .\nKwon, S.; Cha, M.; and Jung, K. 2017. Rumor detection\nover varying time windows. PloS one 12(1):e0168344.\nLowe, R.; Pow, N.; Serban, I. V .; and Pineau, J. 2015. The\nubuntu dialogue corpus: A large dataset for research in un-\nstructured multi-turn dialogue systems. In Proceedings of\nthe SIGDIAL .\nMikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and\nDean, J. 2013. Distributed representations of words and\nphrases and their compositionality. In Advances in neural\ninformation processing systems , 3111\u20133119.\nPascanu, R.; Mikolov, T.; and Bengio, Y . 2013. On the diffi-\nculty of training recurrent neural networks. In Proceedings\nof the ICML .\nReis, J.; Benevenuto, F.; de Melo, P. V .; Prates, R.; Kwak,\nH.; and An, J. 2015. Breaking the news: First impressions\nmatter on online news. In Proceedings of the ICWSM .\nRiedel, B.; Augenstein, I.; Spithourakis, G. P.; and Riedel,\nS. 2017. A simple but tough-to-beat baseline for the\nFake News Challenge stance detection task. arXiv preprint\narXiv:1707.03264 .\nRony, M. M. U.; Hassan, N.; and Yousuf, M. 2017. Diving\ndeep into clickbaits: Who use them to what extents in which\ntopics with what effects? In Proceedings of the ASONAM ,\n232\u2013239. ACM.\nSaxe, A. M.; McClelland, J. L.; and Ganguli, S. 2013. Ex-\nact solutions to the nonlinear dynamics of learning in deep\nlinear neural networks. arXiv preprint arXiv:1312.6120 .\nSrivastava, N.; Hinton, G. E.; Krizhevsky, A.; Sutskever, I.;\nand Salakhutdinov, R. 2014. Dropout: a simple way to pre-\nvent neural networks from overfitting. Journal of machine\nlearning research 15(1):1929\u20131958.Tai, K. S.; Socher, R.; and Manning, C. D. 2015. Im-\nproved semantic representations from tree-structured long\nshort-term memory networks. In Proceedings of the ACL ,\nvolume 1, 1556\u20131566.\nTalos, C. 2017. Fake News Challenge - Team SOLAT IN\nTHE SWEN. https://github.com/Cisco-Talos/fnc-1. [On-\nline; accessed 10-Feb-2019].\nWang, Z.; Hamza, W.; and Florian, R. 2017. Bilateral multi-\nperspective matching for natural language sentences. In Pro-\nceedings of the ICJAI , 4144\u20134150. AAAI Press.\nWei, W., and Wan, X. 2017. Learning to identify ambiguous\nand misleading news headlines. In Proceedings of the IJCAI ,\n4172\u20134178. AAAI Press.\nYoon, S.; Shin, J.; and Jung, K. 2018. Learning to rank\nquestion-answer pairs using hierarchical recurrent encoder\nwith latent topic clustering. In Proceedings of NAACL-HLT ,\nvolume 1, 1575\u20131584.\n800", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Detecting incongruity between news headline and body text via a deep hierarchical encoder", "author": ["S Yoon", "K Park", "J Shin", "H Lim", "S Won", "M Cha"], "pub_year": "2019", "venue": "Proceedings of the AAAI \u2026", "abstract": "Some news headlines mislead readers with overrated or false information, and identifying  them in advance will better assist readers in choosing proper news stories to consume. This"}, "filled": false, "gsrank": 278, "pub_url": "https://aaai.org/ojs/index.php/AAAI/article/view/3756", "author_id": ["UpymOMwAAAAJ", "xiZ1ImoAAAAJ", "xzJSvJcAAAAJ", "Vc0R_NMAAAAJ", "d7-TUHkAAAAJ", "iFlnVCoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:nOv50Wm-CIMJ:scholar.google.com/&output=cite&scirp=277&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D270%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=nOv50Wm-CIMJ&ei=NbWsaP7HEuHUieoP9LKZ6AI&json=", "num_citations": 69, "citedby_url": "/scholar?cites=9442005980485905308&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:nOv50Wm-CIMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aaai.org/ojs/index.php/AAAI/article/download/3756/3634"}}, {"title": "aedFaCT: scientific fact-checking made easier via semi-automatic discovery of relevant expert opinions", "year": "2023", "pdf_data": "aedFaCT: Scienti\ufb01c Fact-Checking Made Easier\nvia Semi-Automatic Discovery of Relevant Expert Opinions\nEnes Altuncu1*, Jason R.C. Nurse1, Meryem Bagriacik2, Sophie Kaleba2, Haiyue Yuan1, Lisa\nBonheme2, Shujun Li1*\n1Institute of Cyber Security for Society (ICSS) & School of Computing, University of Kent\n2School of Computing, University of Kent\nAbstract\nIn this highly digitised world, fake news is a challenging\nproblem that can cause serious harm to society. Considering\nhow fast fake news can spread, automated methods, tools and\nservices for assisting users to do fact-checking (i.e., fake news\ndetection) become necessary and helpful, for both profession-\nals, such as journalists and researchers, and the general public\nsuch as news readers. Experts, especially researchers, play an\nessential role in informing people about truth and facts, which\nmakes them a good proxy for non-experts to detect fake news\nby checking relevant expert opinions and comments. There-\nfore, in this paper, we present aedFaCT , a web browser ex-\ntension that can help professionals and news readers perform\nfact-checking via the automatic discovery of expert opinions\nrelevant to the news of concern via shared keywords. Our ini-\ntial evaluation with three independent testers (who did not\nparticipate in the development of the extension) indicated that\naedFaCT can provide a faster experience to its users com-\npared with traditional fact-checking practices based on man-\nual online searches, without degrading the quality of retrieved\nevidence for fact-checking. The source code of aedFaCT is\npublicly available at https://github.com/altuncu/aedFaCT.\n1 Introduction\nThe digital age has evolved into an infodemic age, with the\nrapid propagation of false and misleading information in this\nhighly digitised world, mixed with true and reliable infor-\nmation. As part of this, fake news prevents society from\nobtaining accurate information based on real evidence. The\nCOVID-19 pandemic has demonstrated how fake news can\nseriously cause harm to people (BBC News 2020).\nConsidering the amount of information available online\nand how fast information can be widely disseminated with\nthe help of digital communication technologies, detecting\nfake news at scale is an important task. Therefore, many\nresearchers have studied automated fact-checking meth-\nods (Zhou and Zafarani 2020). However, automated fact-\nchecking solutions are yet to be suf\ufb01cient to adapt to various\ncontexts, languages, and modalities. In addition, they insuf-\n\ufb01ciently consider human factors, such as trust and usability,\n*Corresponding co-authors: Enes Altuncu (ea483@kent.ac.uk)\nand Shujun Li (S.J.Li@kent.ac.uk).\nCopyright \u00a9 2023, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.which is crucial for practical use (Das et al. 2023). These\npaved the way for semi-automated solutions that attempt to\ncombine human and machine intelligence. With this respect,\nthe literature involves many fact-checking systems leverag-\ning human-machine teaming in different ways (Guo et al.\n2020; Das et al. 2023). Besides, there exists a wide range of\ntools and services that can assist professionals and common\nreaders with fake news detection (Nakov et al. 2021).\nExperts play a crucial role in the \ufb01ght against fake sci-\nenti\ufb01c news by enlightening society with truths and facts\nthrough various communication channels, especially the\nnews media. In the complicated landscape of the infodemic\nage, people are likely to seek help from experts they trust,\nsuch as scientists and professionals, since they are often con-\nsidered the highly trusted groups in society (Ipsos MORI\n2022). This makes them a proxy for non-experts to fact-\ncheck suspicious scienti\ufb01c claims. Other than giving expert\ncomments and being interviewed, experts support journal-\nists in reporting online false information to bridge gaps in\ntheir contextual understanding and methodological exper-\ntise (McClure Haughey, Povolo, and Starbird 2022). Be-\nsides, experts are a crucial element of the fact-checking pro-\ncess conducted by human fact-checkers (Graves 2017). With\nthis respect, there has been much effort to engage with ex-\nperts for scienti\ufb01c fact-checking. To exemplify, Science Me-\ndia Centre1aims to build bridges between experts and jour-\nnalists so that scienti\ufb01c information covered in the media\nbecomes accurate and evidence-based. Another example is\nMeedan\u2019s Digital Health Lab2, which is composed of scien-\ntists, content moderation experts, and journalists to support\nevidence-based responses to health misinformation.\nHowever, this expert-journalist collaboration could be\ninsuf\ufb01cient to combat fake scienti\ufb01c news due to sev-\neral reasons, including challenges in scienti\ufb01c communica-\ntion (Bucchi 2017), the existence of outlier experts who do\nnot share the majority opinions, and the selection of experts\nwith incompatible expertise (Palmer 2020). These problems\nindicate the need and potential usefulness of tools that can\nleverage multiple experts\u2019 opinions as evidence for fact-\nchecking purposes. Therefore, in this work, we present aed-\nFaCT , a web browser extension that can help professionals\n1https://www.sciencemediacentre.org/\n2https://meedan.com/programs/digital-health-labarXiv:2305.07796v1  [cs.IR]  12 May 2023\nand common readers to discover the opinions of multiple ex-\nperts on relevant topics of a particular scienti\ufb01c news article\nin a semi-automated manner. aedFaCT extracts expert opin-\nions from several credible news sources based on a num-\nber of candidate keywords automatically extracted from the\ntarget news article, and it also automatically retrieves rel-\nevant peer-reviewed scienti\ufb01c publications based on such\nkeywords. Based on the results, users can make a decision\non the veracity of suspicious claims on their own by con-\nsidering the retrieved evidence. Moreover, aedFaCT enables\nusers to see a list of researchers with relevant expertise based\non their publications in order to inform them about who to\nfollow and to approach on a speci\ufb01c topic. In a nutshell,\naedFaCT is a \u201csmart search assistant\u201d for fact-checkers to\nhelp minimise the manual work they have to do using online\nsearch engines and other known information sources.\nThe rest of the paper is organised as follows. Section 2\nbrie\ufb02y reviews related work. Then, Section 3 presents a fo-\ncus group study to understand the mental process of users\nduring scienti\ufb01c fact-checking. The architecture of the pro-\nposed system is introduced in Section 4, and the details of\nits evaluation are provided in Section 5. Finally, the paper is\nconcluded with a brief discussion in Section 6 and the con-\ncluding remarks in Section 8.\n2 Related Work\n2.1 Human-Machine Teaming Approaches in\nFact-Checking\nAutomated fact-checking at scale is a challenging task.\nHence, recent research includes hybrid solutions based on\nhuman-machine teaming to assist fact-checkers and the gen-\neral public with a level of automation in the process of fact-\nchecking. For example, Nguyen et al. (2018) designed a\nmixed-initiative approach to fact-checking where the sys-\ntem predicts the veracity of a claim based on relevant ar-\nticles with their stance towards the veracity of the claim and\nthe reputation of each source. The users\u2019 role in this de-\nsign is to change the source reputation and stance of each\narticle for more accurate prediction. More recently, Gupta\net al. (2021) introduced an evidence retrieval approach to\nsearch for semantically-similar news articles to assist users\nwhen validating news articles. This system leaves the fact-\nchecking decision to the user. Moreover, La Barbera, Roi-\ntero, and Mizzaro (2022) proposed a hybrid human-in-the-\nloop framework for the veracity assessment of claims, rely-\ning on three major components: AI, crowdsourcing, and ex-\nperts. The veracity of the claim is considered as correctly\nclassi\ufb01ed if any component produces a prediction with a\nhigh con\ufb01dence score. Otherwise, the claim is forwarded\nto the next component. Another human-in-the-loop AI sys-\ntem is HAMLET, a conceptual framework leveraging AI-\nexpert teaming in multiple fact-checking tasks, such as the\ncollection of expert data annotations and expert feedback,\nAI system performance monitoring, and life cycle manage-\nment (Bandhakavi, Hoffmann, and Lear 2022). Finally, Ar-\nroyo Guarde \u02dcno et al. (2021) introduced a toolbox, namely\nMs.W, combining several publicly available services and\ntools that help users with fact-checking and source credi-bility assessment.\nAs another way of human-machine teaming, several fact-\nchecking systems utilise crowd intelligence in different\nstages. For instance, V o and Lee (2018) leveraged guardians,\nwho are social media users correcting false information\nby referring to fact-checking URLs, and presented a fact-\nchecking URL recommendation model to motivate them to\nengage more in fact-checking activities. Furthermore, so-\ncial media companies enable users to \ufb02ag posts containing\nfalse information and sent them to fact-checkers for further\ninvestigation if there are suf\ufb01cient \ufb02ags. Recently, Twitter\nlaunched Community Notes3(previously known as Bird-\nwatch), where users can add context to tweets to prevent the\nplatform from false information.\n2.2 Web Browser Extensions for Fact-Checking\nWeb browser extensions are quite useful for fact-checking,\nespecially for web-based documents and articles. For exam-\nple,BRENDA allows users to perform automatically fact-\nchecking a news article or a snippet from the article (Bot-\nnevik, Sakariassen, and Setty 2020). It identi\ufb01es the check-\nworthy claims, classi\ufb01es them with a deep neural network,\nand then, shows the results to the user along with the evi-\ndence found from top-10 Google Search results. Another au-\ntomated solution is FADE , which discovers multiple sources\ncontaining the same news story and performs automated\nfact-checking according to the trustworthiness of the news\nsources and the cited sources in the article (Jabiyev et al.\n2021). Other than the solutions developed in academia, The\nFactual4automatically rates news articles based on several\ncharacteristics, including their source quality and bias, au-\nthor expertise, and tone.\nThere also exist Web browser extensions helping users\nwith content analysis and evidence retrieval for fact-\nchecking. One such tool is InVID , which helps users ver-\nify videos and images with a number of tools it con-\ntains (Teyssou 2019). As another example, News2PubMed\nretrieves relevant health research papers given a news arti-\ncle (Wang and Yu 2021). Another tool is called News Scan ,\nwhich shows several characteristics of the source and con-\ntent of news articles, such as source popularity, sentiment,\nobjectivity, and bias, to assist users to make a judgement on\nthe source and content credibility (Kevin et al. 2018). Fi-\nnally, NewsGuard5shows manually assigned source credi-\nbility ratings next to links on search engines and social me-\ndia platforms.\n3 Mental Process of Users During\nFact-Checking\nIn this study, our aim is to develop a semi-automated fact-\nchecking system for both professionals and common read-\ners, which automates, at least, part of the users\u2019 claim in-\nvestigation process. To this end, we need to understand how\nusers manually perform fact-checking and what strategies\n3https://help.twitter.com/en/using-twitter/community-notes\n4https://www.thefactual.com/\n5https://www.newsguardtech.com/\nthey normally use to investigate a claim. From a general per-\nspective, content is the most important factor for users dur-\ning fact-checking (Pidikiti et al. 2020). Users mainly rely\non their own knowledge and sense of judgement to make\na decision, and they perform external acts of authentication\n(e.g., searching for more information via Google, family and\nfriends, and experts) only if the \ufb01rst phase fails (Tandoc Jr.\net al. 2018; Freiling 2019). When users seek external infor-\nmation, they commonly prefer information that they con-\nsider credible, such as peer-reviewed scienti\ufb01c papers, fact-\nchecking reports, mainstream news articles, and Wikipedia\nentries (He and He 2022).\nSince the current literature lacks a systematical discussion\nof how different processes that fact-checkers and common\nreaders follow to verify scienti\ufb01c information, we conducted\na focus group discussion between the \ufb01rst author and three\nother co-authors (the third, fourth and sixth) of this paper,\nwho were all PhD students in Computer Science focusing on\na relevant research topic (AI, NLP, and/or cyber security),\nto understand how users verify the veracity of news con-\ntent. At the time of the discussion, only the \ufb01rst co-author\nknew about the details of the study as the initialiser of the\nwork. During the discussion, an example news article con-\ntaining a false claim about COVID-19 was provided to the\nparticipants, and the investigation of the claim has been per-\nformed by discussing each step of the fact-checking process.\nThe discussion was conducted with three fact-checking sce-\nnarios, separately: (1) the participants (as researchers) per-\nformed fact-checking themselves; (2) the participants sim-\nulated how common readers with less domain knowledge\nwould perform fact-checking without using expert opinions\nas a proxy; and (3) the participants simulated how common\nreaders would perform fact-checking by using expert opin-\nions as a proxy. For all the scenarios, the discussion was\nmade with the same participants instead of separate groups\nof researcher and common reader participants, for the sake\nof simplicity and to allow cross-scenario alignment. Using\nresearchers as common readers is not necessarily a prob-\nlematic setup, since researchers are effectively like common\nreaders for research areas beyond their own expertise (e.g.,\nhealth and medicine for all the authors of this paper).\nIn the \ufb01rst scenario, the participants suggested identifying\nsome keywords about the investigated claim and using them\nto search for relevant research papers on Google Scholar.\nThen, they suggested reading the abstracts of the \ufb01rst few\npublications to make a decision, provided that they trust the\npublisher. In the second scenario, however, they preferred\nto use Google Search to search for relevant material with\nthe same set of keywords, assuming that common readers\nwould have been unfamiliar with scienti\ufb01c papers and re-\nsearch databases. Then, they wanted to check out the search\nresults that are trustable for them, e.g., a news article from a\nnews outlet they trusted, or a post from a university\u2019s of\ufb01cial\nwebsite advertising their research. Finally, in the third sce-\nnario, the participants suggested identifying multiple rele-\nvant domain experts through the websites of the correspond-\ning institution or departments of well-known universities.\nMoreover, they found relevant news articles useful to iden-\ntify some domain experts by checking who has been inter-viewed in the article.\nThe focus group discussion provided three major con-\nclusions on users\u2019 scienti\ufb01c fact-checking process, support-\ning the \ufb01ndings of existing literature on the general fact-\nchecking practices of fact-checkers and laypeople (Juneja\nand Mitra 2022; Micallef et al. 2022; He and He 2022):\n(1) domain experts were generally at the core of the fact-\nchecking process, either explicitly, or implicitly through\ntheir publications; (2) only the sources they trusted were\nconsidered; and (3) multiple sources were taken into account\nfor cross-checking what has been obtained.\n4 System Design\n4.1 Overview\nThe overview architecture of aedFaCT is shown in Figure 1.\nThe system involves three main parts: (i) keyword extraction\nand selection; (ii) expert opinion discovery; (iii) scienti\ufb01c\nevidence retrieval.\n4.2 Keyword Extraction and Selection\nAs the \ufb01rst step, the system needs to learn the context of\nthe given news article by extracting a number of descrip-\ntive keywords. We designed this process as a human-in-the-\nloop mechanism to avoid topic drift while using the obtained\nkeywords in searching. The system \ufb01rst fetches and parses\nthe news content using the Newspaper3k6library. Then, it\nperforms automatic keyword extraction (AKE) with a state-\nof-the-art AKE algorithm, SIFRank+ (Sun et al. 2020), to\nobtain the initial set of keywords. Based on the \ufb01ndings of\nour previous study (Altuncu et al. 2022), we used our own\nversion of SIFRank+, enhanced with post-processing. More\nprecisely, the enhancement involves PoS-tagging-based \ufb01l-\ntering, and prioritising keywords contained in the corre-\nsponding domain thesaurus or Wikipedia as an entry. This\nensures that only noun phrases are considered keywords,\nand contextual keywords are given priority. As AKE meth-\nods are incapable of providing suf\ufb01cient accuracy (Papa-\ngiannopoulou and Tsoumakas 2020), we ask users to se-\nlect the keywords relevant to the article out of ten identi-\n\ufb01ed keywords through the pop-up window shown in the Web\nbrowser, as depicted in Figure 2. Users are also allowed to\nadd and select their own keywords through the user inter-\nface.\n4.3 Expert Opinion Discovery\nThis step aims to explore the scienti\ufb01c views or comments\nof domain experts in the news media on the identi\ufb01ed topic.\nThe system combines the keywords selected by the user\nin the previous step with the AND operator to generate a\nsearch query to search for relevant news items. Although\na more useful query can be formed with a combination of\ndifferent logical operators, we simply used the AND oper-\nator for the sake of simplicity. The searches are done via\nGoogle\u2019s search APIs by considering the following types of\nnews sources:\n6https://newspaper.readthedocs.io/en/latest/\nNews Article\nNews from\nCredible Sources\nCo-authorsoutput\nKeywords\nPeer-reviewed\nPublicationsAbstracts\noutput Researcher Profilesfinal selection\nUser\nExpert OpinionsSearch12\n3\n4\n56\n6\n67Figure 1: The architecture of aedFaCT\n1.Mainstream News Outlets: This includes credible news\noutlets with high traf\ufb01c and wide news coverage. We\nset up a Google site-restricted search engine, which al-\nlows 10 websites for inclusion, and covered 10 news out-\nlets with high credibility in English-language and hav-\ning no paywall. For the source credibility measure, we\nconsidered the Media Bias/Fact Check (MBFC) credibil-\nity ratings7since it has been utilised by several recent\nstudies (Krieg et al. 2020; Chen and Freire 2020; Weld,\nGlenski, and Althoff 2021). The included news outlets\nare shown in Table 1.\n2.Scienti\ufb01c News Outlets: This type involves credible pro-\nscience news websites, featuring scienti\ufb01c views and re-\ncent research \ufb01ndings. For this part, we set up another\nGoogle site-restricted search engine with 10 selected\nnews websites. The selection was made according to the\nMBFC credibility ratings with the help of bias, credibil-\nity, and traf\ufb01c \ufb01lters, and the websites with pro-science\nbias, wide news coverage, higher traf\ufb01c, and no paywall\nwere preferred. Table 1 indicates the list of selected web-\nsites of this type.\n3.Other Credible News Sources: In addition to the pre-\nvious types, there are other types of news sources that\nmight include expert opinions, such as news released\nby institutions and domain-speci\ufb01c news websites (e.g.,\nMedscape, News Medical). To cover these, we set up a\nGoogle custom search engine without any site restriction\nto augment the search results containing the other two\ntypes of news sources. Since Google can also show re-\nsults from non-news websites, we limited the search re-\nsults with the NewsArticle8Schema.org type to include\nonly news articles. Furthermore, we utilised the Iffy In-\ndex of Unreliable Sources9, which is based on MBFC,\nto exclude untrustworthy news sources from the search\nresults.\n7https://mediabiasfactcheck.com/\n8https://schema.org/NewsArticle\n9https://iffy.news/index/The search results obtained from the three search engines\nare aggregated with the given order. Although it is possi-\nble to merge the three search engines into a single custom\nsearch engine, we preferred to use site-restricted engines for\nthe \ufb01rst two types of news sources since we observed that\nsite-restricted search engines provide more reliable results,\nand custom search engines con\ufb01gured to search the entire\nWeb are limited to a subset of the Google Web Search cor-\npus10. Hence, we bene\ufb01ted from a custom search engine as\na secondary source to populate the obtained results from the\nsite-restricted search engines.\nOnce the aggregated set of search results is obtained,\nthe system tries to capture expert opinions from each ar-\nticle, which are mostly in the form of reported speeches,\nsince they contain the most indicative elements (e.g., re-\nported speeches, named entities, and quotes) of page useful-\nness for fact-checking (Hasanain and Elsayed 2022). In this\nmanner, it \ufb01rst downloads the news article with the Newspa-\nper3k library. Then, the article is tokenised with two consec-\nutive newline characters to obtain its paragraphs. Finally, for\neach paragraph, named entities are extracted with the spaCy\nlibrary\u2019s NER feature. Only the paragraphs which contain\nat least one person name, one academic organisation name\n(containing an indicative word or phrase, such as university ,\ninstitute ,academy , and research centre ) and a pair of sin-\ngle or double quotation marks (indicating a reported speech)\nare selected. As an exception, the summary extracted by the\nNewspaper3k library is shown to users for the The Conver-\nsation news articles instead of retrieved expert opinions as\nthey are already written by researchers and academics. As\nshown in Figure 3, the selected paragraphs are combined\nand shown to users in an individual box that also contains\nthe source type (icon on the top-left), source name, and pub-\nlish date. If the shown expert opinions are insuf\ufb01cient for\na judgement and require further reading, users can click on\nthe box to see the full article. Furthermore, a green clickable\n10https://support.google.com/programmable-search/answer/\n70392\nFigure 2: The user interface of the keyword extraction step in aedFaCT\nTable 1: News outlets covered by the site-restricted search engines\nMainstream News Outlets Scienti\ufb01c News Outlets\nNPR (www.npr.org) Science (www.science.org)\nNBC News (www.nbcnews.com) EurekAlert (www.eurekalert.org)\nSky News (news.sky.com) The Scientist (www.the-scientist.com)\nABC News (www.abcnews.go.com) Science News (www.sciencenews.org)\nEuronews (www.euronews.com) MIT Technology Review (www.technologyreview.com)\nReuters (www.reuters.com) Popular Science (www.popsci.com)\nBBC News (www.bbc.com) Science Daily (www.sciencedaily.com)\nPBS NewsHour (www.pbs.com/newshour) Science Alert (www.sciencealert.com)\nAssociated Press (www.apnews.com) Live Science (www.livescience.com)\nCBS News (www.cbsnews.com) The Conversation (www.theconversation.com)\ntick directing to the corresponding MBFC credibility rating\nwebpage is added next to the names of the mainstream and\nscience news sources for better explainability.\n4.4 Scienti\ufb01c Evidence Retrieval\nScienti\ufb01c publications can also be considered a source of ex-\npert opinions as they are written by domain experts. There-\nfore, this step aims to retrieve research papers relevant to the\ntopic of the input article.\nSimilar to the previous step, we try to include only the\nrecords with high credibility. With this respect, we utilised\nScopus API (with the help of the Pybliometrics library (Rose\nand Kitchin 2019)) to search for relevant peer-reviewed pub-\nlications. The searches are made by combining the selected\nkeywords with an AND operator, similar to the previous step.\nIn addition, each keyword is surrounded by double quota-tion marks since it enables the inclusion of loose matches\nby allowing for wildcards and lemmatisation (Beatty 2022).\nAs shown in the upper side of Figure 4, the obtained search\nresults are shown to the user inside individual boxes contain-\ning the title, source, publication year, and abstract, with an\norder of relevance and publication year.\nIn addition to the scienti\ufb01c evidence provided by the tool,\nusers, especially fact-checkers and journalists, might want\nto know the experts on the topic themselves to follow their\nresearch and/or make contact with them. To enable this, our\nproposed tool pro\ufb01les the co-authors of the publications re-\ntrieved in the previous step, by obtaining relevant informa-\ntion, e.g., pro\ufb01le links, from their Scopus and ORCID pro-\n\ufb01les. The obtained researcher pro\ufb01les are ordered by their\nnumber of publications in the search result. In the case that\nthis number is equal, they are ranked based on the amount\nFigure 3: An example output from aedFaCT showing some of the retrieved news articles.\nof information their pro\ufb01le contains to prioritise more con-\ntactable researchers. The bottom side of Figure 4 shows an\nexample output from the user interface showing a list of re-\nsearchers.\n5 Evaluation\nTo check the functionality and validity of the proposed Web\nbrowser extension, we conducted an initial evaluation as a\npilot study with three co-authors (the third, fourth, and \ufb01fth)\nof this paper (one male and two female researchers), who\nwere not included in the design and implementation phases\nof the tool. They were provided with 20 health news arti-\ncles released by multiple sources with different credibility\nlevels. The health domain was selected in order for a bet-\nter simulation of common readers since it was outside the\nparticipants\u2019 areas of expertise. Then, the participants were\nasked to investigate the veracity of each news article and\nprovide ratings for the shown output, in two rounds: 1) man-\nually by following the investigation practices in their daily\nlives, such as using a Web search engine, and/or using a re-\nsearch database; 2) by using our proposed tool, aedFaCT.\nFor collecting the ratings from the participants, we set up\na survey on Google Forms, containing a rating scale for each\nprocessed news article in both rounds together with a \ufb01gure\nexplaining each option in the scale. In addition, the survey\nincluded two questions to assess the perceived success of\naedFaCT in terms of which approach had been faster and\nmore helpful (with the options manual investigation ,inves-\ntigation with aedFaCT , and no difference ). Finally, it con-\ncluded with an open-ended question for comments and feed-\nback.\nIn terms of the evaluation criteria in the rating scale,\nwe followed Google\u2019s search quality guidelines (Google\n2022), which was proposed for evaluating Google search\nengine results with human raters. Although there are criti-\ncisms regarding the inadequacy of such retrieval effective-\nness tests (Lewandowski 2015), similar approaches are stillbeing used in the literature (Ciccone and Vickery 2015). The\nguidelines involve mainly two tasks: determining to what\nextent the page achieves its purpose (\u201c Page Quality \u201d) and\ndetermining if search results are useful (\u201c Needs Met \u201d). Be-\ncause our tool only bene\ufb01ts from credible news outlets and\npeer-reviewed publications, the former task is redundant in\nour case. Therefore, we only covered the latter task in our\nevaluation.\nThe \u201cNeeds Met\u201d task involves two steps, which are about\ndetermining the user intent and the rating. Since all users\nof our tool will have the same intent, i.e., veracity assess-\nment, the \ufb01rst step is redundant. Therefore, we only asked\nour evaluators to determine the rating of the search results\nby following the scale shown in Table 2.\nAs a result of the evaluation, the average rating of the\nthree raters when they manually investigated the given news\narticles was 4.35. This average has risen to 4.57 when they\nutilised aedFaCT in their investigations. In addition, the\nraters were in moderate agreement that aedFaCT provided\nbetter or similar results with respect to what they were able\nto obtain with their manual investigations, with a Fleiss\u2019\nKappa of 53.33%. However, the raters have all agreed that\nfact-checking with aedFaCT was faster than their own prac-\ntices. These results indicate that aedFaCT can help users per-\nform fact-checking faster without degrading the quality of\nretrieved evidence for fact-checking. However, more exten-\nsive experiments are needed to evaluate its performance.\n6 Further Discussions\n6.1 Comparing aedFaCT with Existing Tools\naedFaCT differs from existing fact-checking systems in sev-\neral ways. To begin with, to the best of our knowledge, it\nis the \ufb01rst fact-checking system completely based on expert\nopinion discovery although there exist studies leveraging ex-\nperts in fact-checking (La Barbera, Roitero, and Mizzaro\n2022; Bandhakavi, Hoffmann, and Lear 2022; Wang and Yu\n2021). Secondly, it is an evidence retrieval tool, and the \ufb01-\nFigure 4: An example output from aedFaCT showing some of the retrieved scienti\ufb01c publications and their co-authors, respec-\ntively\nTable 2: Rating scale for the Needs Met task (Google 2022)\nRating Description\nFully Meets ( FullyM ) All or almost all users would be immediately and fully satis\ufb01ed by the result and would not need\nto view other results to satisfy their need.\nHighly Meets ( HM) Very helpful for many or most users. Some users may wish to see additional results.\nModerately Meets ( MM) Helpful for many users OR very helpful for some users. Some or many users may wish to see\nadditional results.\nSlightly Meets ( SM) Helpful for fewer users. There is a connection between the query and the result, but not a strong\nor satisfying connection. Many or most users would wish to see additional results.\nFails to Meet ( FailsM ) Completely fails to meet the needs of the users. All or almost all users would wish to see addi-\ntional results.\nNot Applicable ( N/A) The evaluator was unable to evaluate the result.\nnal decision on the veracity is given by the user. Thus, it\ncan establish trust among the users more easily unlike many\nfact-checking tools with a black-box design and fully au-\ntomated decision-making mechanism, due to scepticism to-wards automation (Juneja and Mitra 2022). Another strength\nof aedFaCT is that it targets both common readers and pro-\nfessionals by retrieving both news articles and scienti\ufb01c pub-\nlications. This enables users to consider information sources\nthat they are more familiar with, depending on their level\nof expertise. In addition, it provides users with evidence\nfrom multiple sources and experts, which is a bene\ufb01cial ap-\nproach to breaking users out of their echo chambers. Finally,\nits overall work\ufb02ow aligns with the common practices of\nhuman fact-checkers, in which engaging with experts is a\nkey element, meaning that fact-checkers can use the tool\nto accelerate their claim investigation processes (Juneja and\nMitra 2022; Micallef et al. 2022). To be more precise, an\noverview of different characteristics of aedFaCT and other\nexisting tools is provided in Table 3. As a result, we believe\nthat aedFaCT can be made a new useful tool for \ufb01ghting\nagainst false information and has the potential to be a part of\nstandard fact-checking processes performed by both human\nfact-checkers and common readers.\n6.2 Limitations and Future Work\nThe existing version of the proposed tool has a number\nof limitations. Firstly, it depends on external APIs (i.e.,\nGoogle and Scopus) having quotas for the number of re-\nquests. Google Custom Search API11allows 10,000 requests\nper day while Scopus Search APIs12have a weekly quota\nbetween 5,000 and 20,000 requests, depending on the used\nAPI service. This makes it quite dif\ufb01cult to deploy aedFaCT\nfor a wider community. Another limitation of the tool is\nits relatively low speed during keyword extraction. Since\nAKE methods already suffer from poor accuracy (Papa-\ngiannopoulou and Tsoumakas 2020), we preferred accuracy\nover speed when selecting the AKE method and used the one\n(i.e., SIFRank+) providing the best accuracy although there\nexist various lightweight AKE algorithms. Besides, the in-\nformation retrieval process was based on the selected key-\nwords combined simply with the AND operator. This causes\nfewer records as a result of the searches, especially when\ntoo many keywords were chosen by the user. Therefore, a\nsmarter approach utilising a combination of logical opera-\ntors (e.g., using the ORoperator for similar keywords) is\nneeded for obtaining better search results. Lastly, the evalu-\nation of aedFaCT has been conducted as a pilot study with\na small number of participants having similar backgrounds.\nHence, more extensive experiments with a more diverse\nand representative participant population, covering both pro-\nfessionals (e.g., fact-checkers and journalists) and common\nreaders, are required.\nApart from resolving the limitations, for future work, we\naim to improve the capabilities of aedFaCT. The existing\nversion does not speci\ufb01cally consider retrieving results from\nof\ufb01cial websites, e.g., governmental organisations, NGOs,\nand academic institutions. These can be retrieved by check-\ning the URL extensions of the general Web results. More-\nover, we plan to incorporate research on claim detection into\naedFaCT so that extracted keywords can be more focused on\nspeci\ufb01c claims in the input article.\n11https://developers.google.com/custom-search/v1/overview#\npricing\n12https://dev.elsevier.com/api keysettings.html6.3 Broader Impact\nThis work has some potential outcomes from a broader per-\nspective. Since it accelerates the fact-checking process for\nusers, it might encourage them to make fact-checking a daily\nactivity and increase awareness in society for tackling false\ninformation online. However, users should be conscious\nwhen assessing the veracity of news items with the expert\nopinions shown by aedFaCT. Although aedFaCT retrieves\nevidence only from trustworthy sources, the displayed ex-\npert opinions might contradict each other due to disagree-\nments between different experts. Therefore, aedFaCT does\nnot eliminate the need for critical thinking ability for its\nusers.\n7 Research Ethics Considerations\nThe work reported in this paper involved a focus group dis-\ncussion participated and a validation experiment participated\nby some co-authors of the paper only. According to the re-\nsearch ethics guidelines of the University of Kent\u2019s Central\nResearch Ethics Advisory Group and general advice given\nby the School of Computing\u2019s Research Ethics Of\ufb01cer, such\nuser studies involving researchers who are part of the re-\nsearch only were exempted from going through a research\nethics review process. Both user studies did not involve any\nexplicit collection of personal data or other sensitive data,\nand all participants explicitly consented to participate. Par-\nticipating in the studies did not cause any noticeable harm to\nparticipants, but brought some bene\ufb01ts to them \u2013 they could\nall achieve a better understanding of how to conduct fact-\nchecking as a common reader and researcher.\n8 Conclusion\nFake news is a challenging problem in society and causes se-\nrious harm. Its speed of propagation with the help of digital\ntechnologies suggests the need for automated solutions that\ncan help people combat fake news at scale. Although there\nhas been much effort to detect fake news, existing tools and\nservices overlooked engaging with experts, who are com-\nmonly consulted during standard fact-checking processes.\nTherefore, this paper proposed aedFaCT , a Web browser ex-\ntension that retrieves expert opinions related to a news article\nto help fact-checkers and the general public perform fact-\nchecking. Our initial evaluation suggested that it can accel-\nerate fact-checking process without negatively affecting the\nsearch quality.\nCRediT authorship contribution statement Enes Al-\ntuncu : Conceptualization, Methodology, Software, Writ-\ning \u2013 original draft, Writing \u2013 review & editing. Jason\nNurse : Methodology, Writing \u2013 review & editing, Super-\nvision. Meryem Bagriacik : Investigation, Validation, Writ-\ning \u2013 review & editing. Sophie Kaleba :Investigation, Val-\nidation, Writing \u2013 review & editing. Haiyue Yuan : Valida-\ntion, Writing \u2013 review & editing. Lisa Bonheme : Investiga-\ntion, Writing \u2013 review & editing. Shujun Li : Conceptualiza-\ntion, Methodology, Supervision, Writing \u2013 review & editing.\nAcknowledgements We would like to thank all the re-\nviewers for their valuable feedback. The \ufb01rst and third co-\nTable 3: The comparison between aedFaCT and other existing web browser extensions for fact-checking\nTool Approach Task Output Domain\nBRENDA Automatic Veracity Prediction News articles Any\nFADE Automatic Veracity Prediction News articles Any\nThe Factual Automatic Credibility Assessment Source & content credibility Any\nInVID Semi-automatic Content Analysis Additional information about content Any\nNews2PubMed Automatic Evidence Retrieval Research papers Health only\nNewsGuard Automatic Credibility Assessment Source credibility Any\nNews Scan Semi-automatic Credibility Assessment Source & content credibility Any\naedFaCT Semi-automatic Evidence Retrieval News articles, research papers & researchers Any\nauthors, E. Altuncu and M. Bagriacik, were supported by\nfunding from the Ministry of National Education, Republic\nof Turkey, through the MoNE-YLSY scholarship program.\nReferences\nAltuncu, E.; Nurse, J. R. C.; Xu, Y .; Guo, J.; and Li, S.\n2022. Improving Performance of Automatic Keyword Ex-\ntraction (AKE) Methods Using PoS-Tagging and Enhanced\nSemantic-Awareness. arXiv:2211.05031 [cs.CL].\nArroyo Guarde \u02dcno, D.; G \u00b4omez Esp \u00b4es, A.; Palmero Mu \u02dcnoz,\nS.; and Degli Esposti, S. 2021. On the design of a misin-\nformation widget (Ms.W) against cloaked science. Tech-\nnical report, Instituto de F \u00b4\u0131sica Aplicada (IFA), Ciencia y\nTecnolog \u00b4\u0131as F \u00b4\u0131sicas.\nBandhakavi, A.; Hoffmann, H.; and Lear, P. 2022. Tackling\nMisinformation with HAMLET (Human and Machine in the\nLoop Evaluation and Training). Technical report, Logically.\nBBC News. 2020. \u2018Hundreds dead\u2019 Because of Covid-19\nMisinformation.\nBeatty, S. 2022. 6 Simple Search Tips: Lessons Learned\nfrom the Scopus Webinar.\nBotnevik, B.; Sakariassen, E.; and Setty, V . 2020. BRENDA:\nBrowser Extension for Fake News Detection. In Proceed-\nings of the 43rd International ACM SIGIR Conference on\nResearch and Development in Information Retrieval , 2117\u2013\n2120. ACM.\nBucchi, M. 2017. Credibility, Expertise and the Challenges\nof Science Communication 2.0. Public Understanding of\nScience , 26(8): 890\u2013893.\nChen, Z.; and Freire, J. 2020. Proactive Discovery of Fake\nNews Domains from Real-Time Social Media Feeds. In\nCompanion Proceedings of the Web Conference 2020 , 584\u2013\n592. ACM.\nCiccone, K.; and Vickery, J. 2015. Summon, EBSCO\nDiscovery Service, and Google Scholar: A Comparison of\nSearch Performance Using User Queries. Evidence Based\nLibrary and Information Practice , 10(1): 34\u201349.\nDas, A.; Liu, H.; Kovatchev, V .; and Lease, M. 2023.\nThe State of Human-Centered NLP Technology for Fact-\nChecking. Information Processing & Management , 60(2):\n103219:1\u2013103219:25.Freiling, I. 2019. Detecting misinformation in online social\nnetworks: A think-aloud study on user strategies. SCM Stud-\nies in Communication and Media , 8(4): 471\u2013496.\nGoogle. 2022. Search Quality Rater Guidelines: An\nOverview.\nGraves, L. 2017. Anatomy of a Fact Check: Objective\nPractice and the Contested Epistemology of Fact Checking.\nCommunication, Culture & Critique , 10(3): 518\u2013537.\nGuo, B.; Ding, Y .; Yao, L.; Liang, Y .; and Yu, Z. 2020. The\nFuture of False Information Detection on Social Media: New\nPerspectives and Trends. ACM Computing Surveys , 53(4):\n68:1\u201368:36.\nGupta, V .; Beckh, K.; Giesselbach, S.; Wegener, D.; and\nWirtz, T. 2021. Supporting Veri\ufb01cation of News Articles\nwith Automated Search for Semantically Similar Articles.\nInProceedings of the 2021 Workshop Reducing Online Mis-\ninformation through Credible Information Retrieval . CEUR\nWorkshop Proceedings.\nHasanain, M.; and Elsayed, T. 2022. Studying Effectiveness\nof Web Search for Fact Checking. Journal of the Association\nfor Information Science and Technology , 73(5): 738\u2013751.\nHe, L.; and He, C. 2022. Help Me #DebunkThis: Unpacking\nIndividual and Community\u2019s Collaborative Work in Infor-\nmation Credibility Assessment. Proceedings of the ACM on\nHuman-Computer Interaction , 6(CSCW2): 413:1\u2013413:31.\nIpsos MORI. 2022. Ipsos MORI Veracity Index.\nJabiyev, B.; Pehlivanoglu, S.; Onarlioglu, K.; and Kirda, E.\n2021. FADE: Detecting Fake News Articles on the Web. In\nProceedings of the 16th International Conference on Avail-\nability, Reliability and Security , 15:1\u201315:10. ACM.\nJuneja, P.; and Mitra, T. 2022. Human and Technological In-\nfrastructures of Fact-Checking. Proceedings of the ACM on\nHuman-Computer Interaction , 6(CSCW2): 418:1\u2013418:36.\nKevin, V .; H \u00a8ogden, B.; Schwenger, A., Claudia andS \u00b8ahan;\nMadan, N.; Aggarwal, P.; Bangaru, A.; Muradov, F.; and\nAker, A. 2018. Information Nutrition Labels: A Plugin for\nOnline News Evaluation. In Proceedings of the 1st Work-\nshop on Fact Extraction and VERi\ufb01cation , 28\u201333. ACL.\nKrieg, S. J.; Schnur, J. J.; Marshall, J. D.; Schoenbauer,\nM. M.; and Chawla, N. V . 2020. Pandemic Pulse: Unravel-\ning and Modeling Social Signals During the COVID-19 Pan-\ndemic. Digital Government: Research and Practice , 2(2):\n19:1\u201319:9.\nLa Barbera, D.; Roitero, K.; and Mizzaro, S. 2022. A Hy-\nbrid Human-In-The-Loop Framework for Fact Checking. In\nProceedings of the 6th Workshop on Natural Language for\nArti\ufb01cial Intelligence , 4:1\u20134:10. CEUR Workshop Proceed-\nings.\nLewandowski, D. 2015. Evaluating the Retrieval Effective-\nness of Web Search Engines Using a Representative Query\nSample. Journal of the Association for Information Science\nand Technology , 66(9): 1763\u20131775.\nMcClure Haughey, M.; Povolo, M.; and Starbird, K. 2022.\nBridging Contextual and Methodological Gaps on the \u201cMis-\ninformation Beat\u201d: Insights from Journalist-Researcher Col-\nlaborations at Speed. In Proceedings of the 2022 ACM\nSIGCHI Conference on Human Factors in Computing Sys-\ntems, 244:1\u2013244:15. ACM.\nMicallef, N.; Armacost, V .; Memon, N.; and Patil, S. 2022.\nTrue or False: Studying the Work Practices of Profes-\nsional Fact-Checkers. Proceedings of the ACM on Human-\nComputer Interaction , 6(CSCW1): 127:1\u2013127:44.\nNakov, P.; Corney, D.; Hasanain, M.; Alam, F.; Elsayed, T.;\nBarr\u00b4on-Cede \u02dcno, A.; Papotti, P.; Shaar, S.; and Da San Mar-\ntino, G. 2021. Automated Fact-Checking for Assisting Hu-\nman Fact-Checkers. In Proceedings of the 30th International\nJoint Conference on Arti\ufb01cial Intelligence , 4551\u20134558. IJ-\nCAI.\nNguyen, A. T.; Kharosekar, A.; Krishnan, S.; Krishnan, S.;\nTate, E.; Wallace, B. C.; and Lease, M. 2018. Believe\nIt or Not: Designing a Human-AI Partnership for Mixed-\nInitiative Fact-Checking. In Proceedings of the 31st Annual\nACM Symposium on User Interface Software and Technol-\nogy, 189\u2013199. ACM.\nPalmer, A. 2020. Scienti\ufb01c Facts in the Space of Public Rea-\nson: Moderate Idealization, Public Justi\ufb01cation, and Vac-\ncine Policy Under Conditions of Widespread Misinforma-\ntion and Conspiracism . Ph.D. thesis, Bowling Green State\nUniversity.\nPapagiannopoulou, E.; and Tsoumakas, G. 2020. A Review\nof Keyphrase Extraction. WIREs Data Mining and Knowl-\nedge Discovery , 10(2): e1339:1\u2013e1339:45.\nPidikiti, S.; Zhang, J. S.; Han, R.; Lehman, T.; Lv, Q.; and\nMishra, S. 2020. Understanding How Readers Determine\nthe Legitimacy of Online News Articles in the Era of Fake\nNews. In Proceedings of the 2020 IEEE/ACM International\nConference on Advances in Social Networks Analysis and\nMining , 768\u2013775. IEEE.\nRose, M. E.; and Kitchin, J. R. 2019. pybliometrics: Script-\nable Bibliometrics Using a Python Interface to Scopus. Soft-\nwareX , 10.\nSun, Y .; Qiu, H.; Zheng, Y .; Wang, Z.; and Zhang, C. 2020.\nSIFRank: A New Baseline for Unsupervised Keyphrase Ex-\ntraction Based on Pre-Trained Language Model. IEEE Ac-\ncess, 8: 10896\u201310906.\nTandoc Jr., E. C.; Ling, R.; Westlund, O.; Duffy, A.; Goh,\nD.; and Wei, L. Z. 2018. Audiences\u2019 Acts of Authentication\nin the Age of Fake News: A Conceptual Framework. New\nMedia & Society , 20(8): 2745\u20132763.Teyssou, D. 2019. Applying Design Thinking Methodology:\nThe InVID Veri\ufb01cation Plugin , 263\u2013279. Springer.\nV o, N.; and Lee, K. 2018. The Rise of Guardians: Fact-\nChecking URL Recommendation to Combat Fake News. In\nProceedings of the 41st International ACM SIGIR Confer-\nence on Research & Development in Information Retrieval ,\n275\u2013284. ACM.\nWang, J.; and Yu, B. 2021. News2PubMed: A Browser\nExtension for Linking Health News to Medical Literature.\nInProceedings of the 44th International ACM SIGIR Con-\nference on Research and Development in Information Re-\ntrieval , 2605\u20132609. ACM.\nWeld, G.; Glenski, M.; and Althoff, T. 2021. Political\nBias and Factualness in News Sharing Across More Than\n100,000 Online Communities. Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media , 15(1):\n796\u2013807.\nZhou, X.; and Zafarani, R. 2020. A Survey of Fake News:\nFundamental Theories, Detection Methods, and Opportuni-\nties. ACM Computing Surveys , 53(5): 109:1\u2013109:40.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "aedFaCT: scientific fact-checking made easier via semi-automatic discovery of relevant expert opinions", "author": ["E Altuncu", "JRC Nurse", "M Bagriacik", "S Kaleba"], "pub_year": "2023", "venue": "arXiv preprint arXiv \u2026", "abstract": "In this highly digitised world, fake news is a challenging problem that can cause serious  harm to society. Considering how fast fake news can spread, automated methods, tools and"}, "filled": false, "gsrank": 282, "pub_url": "https://arxiv.org/abs/2305.07796", "author_id": ["TP64mowAAAAJ", "nZbb6xwAAAAJ", "44PCezkAAAAJ", "jpzJR0MAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:a3FHG8FGdO4J:scholar.google.com/&output=cite&scirp=281&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=a3FHG8FGdO4J&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 4, "citedby_url": "/scholar?cites=17182436273525584235&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:a3FHG8FGdO4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2305.07796"}}, {"title": "Lateral reading and monetary incentives to spot disinformation about science", "year": "2022", "pdf_data": "1\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreportsLateral reading and monetary \nincentives to spot disinformation \nabout science\nFolco Panizza1,2*, Piero Ronzani2, Carlo Martini2,3, Simone Mattavelli4, Tiffany Morisseau5,6 & \nMatteo Motterlini2\nDisinformation about science can impose enormous economic and public health burdens. A recently \nproposed strategy to help online users recognise false content is to follow the techniques of \nprofessional fact checkers, such as looking for information on other websites (lateral reading) and \nlooking beyond the first results suggested by search engines (click restraint). In two preregistered \nonline experiments (N = 5387), we simulated a social media environment and tested two \ninterventions, one in the form of a pop-up meant to advise participants to follow such techniques, \nthe other based on monetary incentives. We measured participants\u2019 ability to identify whether \ninformation was scientifically valid or invalid. Analysis of participants\u2019 search style reveals that both \nmonetary incentives and pop-up increased the use of fact-checking strategies. Monetary incentives \nwere overall effective in increasing accuracy, whereas the pop-up worked when the source of \ninformation was unknown. Pop-up and incentives, when used together, produced a cumulative effect \non accuracy. We suggest that monetary incentives enhance content relevance, and could be combined \nwith fact-checking techniques to counteract disinformation.\nScientific disinformation is the intentional spreading of misleading or outright false content purporting to have a \nbasis in scientific methods and practices. Circulation of inaccurate scientific information can damage both insti-\ntutions and individuals, further affecting the relation of trust between science and  society1. Successful misconcep-\ntions influence the public debate on decisions regarding the effectiveness of a vaccine, the adoption of solutions \nmitigating climate change, or the cost of a social policy. A prime example of the detrimental effects of scientific \ndisinformation comes from the use of ivermectin, an oral drug that has been widely used in several countries \nas a treatment against COVID-19 disease, despite no evidence of clinical  efficacy2. The sharing of false informa -\ntion is easily fuelled by political or social motivations that disregard the best scientific evidence on the matter.\nThere are structural challenges to fighting the spread of false or misleading information on social media. \nOne key issue is that companies often perceive a trade-off between engaging users and monitoring viral but \npotentially fake content, to the point of favouring the former over the  latter3. Contrasting disinformation is made \neven more difficult when there is a deliberate intent behind the dissemination. For example, at the peak of the \ncoronavirus infodemic, only 16% of fact-checked disinformation was labelled as such by Facebook\u2019s algorithms, \npartly because content creators were able to simply repost content with minor changes, thus escaping  detection4. \nIt is therefore essential that, in combination with a systematic change in policy, users themselves are empowered \nagainst malicious or false content. Lay evaluation of science-related disinformation is harder than other forms \nof disinformation (e.g. political) because in the former case the lines between expertise and pseudoexpertise \nare blurred, and incompetent or otherwise biased sources pose as expert sources on topics like epidemiology \nor climate  change5.\nResearch on countering disinformation has developed substantially over the last decade, bringing a wealth of \ndifferent  approaches6\u201310. These include debunking, the systematic correction of false claims after they have been \nseen or  heard11, 12, pre-bunking, preventive measures before exposure to  disinformation7, 13, nudging, interven -\ntions affecting users\u2019 choices without limiting their freedom of  choice14, and boosting, the empowering of users \nby fostering existing competences or instilling new  ones14. All of the above approaches have proven to be useful OPEN\n1Molecular Mind Laboratory, IMT School for Advanced Studies Lucca, Lucca, Italy. 2Centre for Applied and \nExperimental Epistemology, Vita-Salute San Raffaele University, Cesano Maderno, Italy. 3TINT \u2013 Centre for \nPhilosophy of Social Science, Department of Political and Economic Studies, University of Helsinki, Helsinki, \nFinland. 4Department of Psychology, Bicocca University, Milano, Italy. 5Universit\u00e9 de Paris and Universit\u00e9 Gustave \nEiffel, LaPEA, Boulogne-Billancourt, France. 6Strane Innovation, Gif -sur -Yvette, France. *email: folco.panizza@\nimtlucca.it\n2\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/in a social media context, not least by adopting ingenious and innovative adaptations of classical paradigms. \nDebunking has been extensively studied, with several experiments focusing on the  source15\u201318 and the  timing19 \nof fact checking. Research has also explored whether evaluations of the quality of contents and sources can be \ndelegated to the so-called wisdom of crowds, with encouraging  results20\u201323 (for a less optimistic perspective, \n see24, 25). Studies on pre-bunking have largely focused on the concept of  inoculation7, 26, namely exposing users \nto disinformation strategies in order to ease their recognition in future settings. Inoculation has demonstrated \npronounced and lasting effects when introduced through  games27\u201330. Nudging was also tested by showing warn-\ning labels for unchecked or false  claims31\u201334, but also by priming users to pay attention to the accuracy of content \nthey might be willing to  share35\u201337 (however  see38 for a critique of this approach). Finally, boosting was tested by \npresenting users with a list of news/media literacy tips or guidelines on how to evaluate information on-line39\u201343, \nproducing some remarkable results and some non-significant ones.\nA promising example of media literacy intervention has been carried out by researchers interested in under -\nstanding how fact checkers navigate information when evaluating unfamiliar  sources44. Researchers catalogued \nfact checkers\u2019 strategies and distilled them into an educational curriculum called Civic Online  Reasoning45, 46. \nIn particular, fact checkers adopt two core strategies to avoid being biased in their search. The first strategy is \nlateral reading, namely leaving a website and opening new tabs along a horizontal axis to use the resources of the \nInternet to learn more about a site and its claims. Appearance of websites can sometimes mislead about their reli-\nability, hence reading laterally helps to identify potential issues such as undisclosed interests or false credentials. \nThe second core strategy is click restraint, that is, to sift through search results of a browser search before click -\ning on any link. Given the well-documented tendency to open the first results without looking  further47, order \nof appearance is vulnerable to manipulation: websites can in fact improve their rank in the results to increase \nincoming traffic, a process called search engine optimisation. A restraint from clicking thus prompts users to \nexplore the various sources to discern which ones are the most trustworthy. Lateral reading and click restraint \nseem particularly fit when a content has unknown origins that are hard to identify or that appear legitimate on \nthe surface, a feature that has been associated with content creators spreading scientific  disinformation48.\nIn the absence of expertise and content knowledge, users can rely on a number of external cues to infer \nwhether information presented as scientific is  reliable49. Lateral reading and click restraint can thus be used when \nscientific disinformation is deceptively sophisticated and difficult to detect. Indeed, training on Civic Online \nReasoning has proven effective in countering disinformation among high school and college  students50\u201352, as \nwell as elderly  citizens53. Despite extensive research on Civic Online Reasoning, so far little attention has been \npaid to the application of these techniques on social media. It is therefore unclear how effective presenting these \nstrategies on a social network can actually be.\nCritical thinking strategies might not be the only potentially effective tools in evaluating scientific (dis)infor -\nmation. For instance users might not be sufficiently motivated to evaluate the truthfulness of the content they \n see6, 54, 55. Many users might share news simply because they come from a source they trust or like, or because \nthose news align with their values, without paying much attention to accuracy. The spread of scientific disin-\nformation then is not only related to false beliefs, but also to motivated behavior, paired with strong personal \nidentities and values. In order to better exploit the benefits of critical thinking tools, it is therefore also important \nto identify the respective effects of being aware of truth-motivated strategies; i.e., being motivated to know the \ntruth about a given topic. It may be that people, while being somehow familiar with fact-checking techniques, are \nonly eager to apply them when identifying the truthfulness of the information is reinforced by specific incentives.\nOne way to test the effect of motivation then is the use of monetary incentives. In other words, does paying \nparticipants for their being accurate increase their accuracy in the evaluation of content? The idea behind this \nintervention is that money increases motivation, and thus the attention paid to otherwise ignored cues about the \naccuracy of content. A 40-year meta-analysis56 points out that both monetary incentives and intrinsic motivation \npredict performance, and that incentives are particularly relevant when they are directly tied to performance. \nMoreover, a study conducted in a setting comparable to the present experiment showed that monetary incentives \nare the main driver for people to spend time solving online tasks even in the face of small average  earnings57.\nMonetary incentives have been proven to be a cost effective tool to modify behavior in domains such as health \nand human  development58, where often an early boost in motivation promotes the adoption of cheap preventive \nbehaviours, avoiding this way costly  consequences59. From a psychological perspective, the use of incentives \nbuilds on the attention-based account of disinformation spread. This account posits that certain features of social \nnetworks favour the dissemination of interesting and unexpected content at the expense of  accuracy6, 60. Recent \nresearch in this field has found both laboratory and field evidence that accuracy of content is often overlooked \nand that simple cues reminding participants to evaluate the accuracy of content reduce participants\u2019 willingness \nto share fake  news35, 37, 61\u201363 (or possibly increase true news  sharing38). Increasing accuracy through incentives is \nnot an entirely novel idea in social media either, as shown in a recent initiative promoted by  Twitter64. Although \nthese premises indicate that this type of intervention can be effective, it is not a given that economic incentives \nwill have a positive effect on scientific content evaluation. In an experimental setting in particular, social media \ncontent is subject to higher scrutiny than when users scroll through their news  feed35. It is therefore possible \nthat additional incentives may not further increase participants\u2019 accuracy.\nThe aim of the present study was to test and compare the effectiveness of Civic Online Reasoning techniques \nand monetary incentives in contributing to the recognition of science-related content on social media. We \nconducted two pre-registered experiments where participants observed and interacted with one out of several \nFacebook posts that linked to an article presenting science-themed information. Participants were free to conduct \nfurther research on external websites in order to form a more accurate idea of the scientific validity of the post. \nOnce satisfied with the information they gathered, participants rated how scientifically valid the claims contained \nin the post were. To test for the usefulness of Civic Online Reasoning techniques, we designed a pop-up that \npreceded the post presenting the lateral reading and click restraint strategies Fig.\u00a0 1. The use of a pop-up ensured \n3\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/that participants processed the content before observing the post, an approach that has also been adopted in \nprevious  research62. A pop-up could be easily adapted in a social media setting as regular reminders with the \nnecessary precautions to avoid the reduction of their salience with  time65, 66. To test the effect of monetary incen-\ntives instead, we doubled the participation fee (equivalent to an average +\u00a38.40/hour) if participants guessed \ncorrectly the validity of the post they were evaluating.\nExperiment 1\nIn Experiment 1, we tested separately the efficacy of pop-up and monetary incentives, and compared their effects \nto a control condition with no interventions. To assess that the effect of the interventions is effective over the \nwidest possible range of contexts, we used a set of 9 different Facebook posts varying in various properties, such \nas the scientific topic, the source reputation, and its level of factual reporting. The original pre-registration of \nthis experiment can be retrieved from osf.  io/ gsu9j .\nMaterials and methods. Ethics statement. All participants gave their written informed consent for par -\nticipating in the experiment. The experimental protocols were approved by the Research Ethics Committee \n(CER) at the University of Paris (IRB No: 00012021-05), and all research was performed in accordance with the \nrelevant guidelines and regulations.\nParticipants. We recruited 2700 U.K. residents through the online platform prolific.co on 11 March 2021 (for a \nrationale of sample size, see S1 Methods ). Average age was 36 ( SD=13.5 , 8 not specified), 60.7% of participants \nwere female, (39.1% male, 0.2% other), and 55.6% had a Bachelor\u2019s degree or higher. Although recruitment \nexplicitly specified that the experiment was supported only on computers or laptops, 316 participants (11.7%) \ncompleted the experiment on a mobile device. As our hypotheses were based on the assumption that search \nwould happen on a computer (where internet browsing easily allows to read laterally), both stimuli and measures \nwere not designed for mobile use. We therefore had to exclude these participants from the analyses. Analyses \nwere thus conducted on 2384 participants.\nDesign.  We conducted the experiment on Qualtrics and lab.js67. During the experiment, participants observed \nand were able to interact with one out of several Facebook-like posts (Fig.\u00a0 2 shows three examples; click  here for \nan interactive example from Experiment 2). Participants\u2019 task was to rate the scientific validity of the statements \nreported in the title, subtitle, and caption of the post (\u201chow scientifically valid would you rate the information \ncontained in the post?\u201d; 6-point likert scale from (1) \u201cdefinitely invalid\u201d to (6) \u201cdefinitely valid\u201d). Research-\ners rated independently the scientific validity of the posts\u2019 content in terms of valid/invalid according to pre-\nspecified criteria (see S3 Methods ). Participants could take as much time as they wanted in giving their rating. \nCrucially, participants were also explicitly told that they were allowed to leave the study page before evaluating \nthe post. After the rating, participants completed a questionnaire and were paid \u00a30.70 for their time. Median \ncompletion time of the experiment was 5 minutes.\nExperimental conditions Participants were randomly assigned to one of three experimental conditions: con -\ntrol, incentive, and pop-up. In the control condition, participants completed the task as described above. In the \nincentive condition, participants were doubled their participation fee if their rating matched that given by the \nexperimenters. Unknown to participants, the correctness of the answer depended only on whether the answer \nwas valid or invalid, and not on the extremity of the answer (e.g. having answered 4 instead of 5), even though we \nselected unambiguously valid or invalid content. In the pop-up condition, presentation of the post was preceded \nFigure\u00a01.  Screenshot of the pop-up presented to participants.\n4\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/by a pop-up (Fig.\u00a0 1) presenting a list of civic online reasoning techniques (e.g., lateral reading, click restraint) as \ntips to verify the information in the post.\nStimuli  Each participant observed one out of nine possible Facebook posts (Fig.\u00a0 2; see S1 File for a full list). \nPosts varied in terms of: (i) scientific validity of the content (i.e., six valid and three invalid posts, either with \nverified or debunked information; S3 Methods ); (ii) topic (i.e., three on climate change, three on the coronavi -\nrus pandemic, three on health and nutrition); (iii) factual reporting of the source, based on ratings from media \nbiasf  actch  eck. com (i.e., three high/very high versus six low/very low); (iv) source reputation, as measured in a \nscreening survey (S4 Methods ; three categories: trusted (2 posts), distrusted (4), unknown source (3)). Posts \nwere balanced to have three posts for each topic, one from a source with high factual reporting displaying valid \ninformation, one from a source with low factual reporting displaying valid information, and one from a source \nwith low factual reporting displaying invalid information.\nWe standardised emoji reactions across all posts to control for their influence. In addition, post date, number \nof reactions and shares were blurred. The rest of the post was instead accessible to the participant, who could click \non different links to access the source Facebook page, the original article, and the Wikipedia page (if present). \nText and images were taken from the article and are publicly available (original links: osf. io/ ces8g for Experiment \n1 and osf. io/ xsr43 for Experiment 2). Captions were short statements of a scientific nature, i.e. facts or events \npertaining to some scientific mechanism.\nMeasures. Accuracy  We computed two measures of accuracy\u2013correct guessing and accuracy score. Correct \nguessing refers to a dichotomous variable that tracks whether participant gave a \u2019valid\u2019 (vs. \u2019invalid\u2019) rating when \nthe post content was actually scientifically valid (vs. invalid). Accuracy score instead is a standardised measure \nranging from zero to one, with 0 indicating an incorrect \u201c1\u201d or \u201c6\u201d validity rating, 0.2 indicating an incorrect \u201c2\u201d \nor \u201c5\u201d rating, 0.4 an incorrect \u201c3\u201d or \u201c4\u201d rating, 0.6 a correct \u201c3\u201d or \u201c4\u201d rating, 0.8 a correct \u201c2\u201d or \u201c5\u201d rating, and \n1 a correct \u201c1\u201d or \u201c6\u201d rating. Accuracy score allows to distinguish validity evaluations that are associated with \ndifferent behaviours: for instance, not all participants would be willing to share content that they rated as 4 in \nterms of scientific validity. In addition, accuracy score is statistically more powerful than correct guessing as it \nincludes more possible  responses68. We thus considered accuracy score as our main index.\nSearch behaviour  During the evaluation of the post, we tracked participants\u2019 behaviour on the study page. We \nmeasured the time spent both inside and outside the page, and a series of dummy variables tracking whether \nparticipants had clicked on any of the links present (e.g., Facebook page, article page, Wikipedia page). Based \non these calculations we were able to estimate participants\u2019 response times and search behaviour.\nCivic online reasoning  After having rated the scientific validity of the post, participants completed a question -\nnaire investigating those factors that could have influenced their choice. In order to test our hypotheses, we asked \nparticipants whether they engaged in lateral reading and click restraint. Participant were said to have used lateral \nreading if they reported having searched for information outside the study page (yes/no question), and if they \nspecifically searched on a search engine among other destinations (multiple selection question). Participants \nwere said to have used click restraint if they further reported looking beyond the first results suggested by the \nsearch engine (multiple choice question). Critically, questions were formulated in such a way as to avoid any \nexpectation as to which answer to select, and thus reduce the influence of the experimenter.\nControl measures  In addition to measures of accuracy and civic online reasoning, we included a series of \ncontrol measures for our analyses (S5 Methods ). Other questions included self-report measures of confidence \nin the validity rating, plausibility of the post content, subjective relevance of obtaining accurate information \nabout the post, familiarity with the source, perceived trustworthiness of the source, subjective knowledge of \nthe topic, trust in scientists, conspiratorial beliefs, and a scientific literacy test. In addition to responses in the \nquestionnaire, we obtained information about participants from the recruiting platform, such as their level of \neducation, socio-economic status, social media use, and belief in climate change.\nFigure\u00a02.  Examples of the stimuli presented, varying in topic (Climate Change, Health and Nutrition, COVID-\n19), factual reporting (high, low, low), scientific validity (high, low, low), and source reputation (trusted, \nuntrusted, unknown source).\n5\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/Analyses. Statistical tests were conducted using base  R69. We adopted the standard 5% significance level to \ntest against the null hypotheses. All tests were two-tailed unless otherwise specified. Post-hoc tests and multiple \ncomparisons were corrected using the Benjamini-Hochberg procedure, and 95% confidence intervals were also \nfamily-wise corrected. Non-parametric statistics were log-transformed for conciseness. For probability differ -\nences, the lower boundary indicates the 2.5% quantile of the effect of the target variable starting from the 2.5% \nquantile of the baseline probability estimate, whereas the upper boundary indicates the 97.5% quantile of the \neffect of the target variable starting from the 97.5% quantile of the baseline probability estimate. Given the small \nnumber of stimuli ( N<10 ), we do not cluster errors by Facebook post in our regression analyses. The use of \nrandom effects yields however comparable results in magnitude and statistical significance unless otherwise \nreported.\nDeviations from the pre\u2011registered protocol. Although we tried to be as faithful as possible to the original pre-\nregistered protocol, we made some changes which we report here:\n\u2022 Scientific validity labels: labels for 1 and 6 responses were changed from \u201ccompletely\u201d to \u201cdefinitely\u201d invalid/\nvalid\n\u2022 Exclusion of mobile users: we anticipated that participants would have accessed the experiment exclusively \nthrough a computer or laptop, and we explicitly defined this as a requirement to participate in the study. \nSome participants however did participate using a mobile device. For this reason we had to introduce an \nadditional exclusion criterion, use of a mobile device (see\u00a0Participants).\n\u2022 Effect of interventions on accuracy score: we report an ordinary logistic regression (Effect of interventions), \noriginally listed as exploratory analysis, in lieu  of the pre-registered ANOV A test. We deemed preferable to \nreport a non-parametric test due to the strong violation of normality of the dependent variable. The ANOV A \nanalysis yields the same results; it is reported in S1 Analyses.\n\u2022 Effect of interventions on correct guessing: to test correct guessing, preregistered analyses proposed the use \nof a probit regression. We chose however to report results of a logistic regression for ease of comparison with \nthe other tests reported, considering that the two regressions yielded the same results.\nWith the exception of the above-mentioned deviations, we conducted our analyses as described in the original \npre-registration.\nResults. Participant randomisation was balanced across conditions (Chi squared test, \u03c72(2)=0.016  , \np=.99 ). Median time to evaluate the Facebook post was 33 seconds in the control condition (incentive condi-\ntion: 45 seconds; pop-up condition: 35 seconds; minimum overall time: 2 seconds, maximum overall time: 40 \nminutes). In the pop-up condition, participants spent an additional median time of 11 seconds on the pop-up. \nOn a scale from 1 to 6 (3.5 response at chance level), average accuracy score in the control condition was 4.35 \n( SD=1.20 ; incentive condition 4.48, SD=1.32 ; pop-up condition 4.35, SD=1.19 ). In the control condition, \n78.2% of participants correctly guessed the scientific validity of the post (incentive condition: 80.1%; pop-up \ncondition: 78.1%).\nEffect of interventions. To test the effect of our interventions on accuracy, we adopted two tests, one for the \naccuracy scores, and one for correct guessing (original preregistered analyses are presented in S1 Analyses ; \nse also Deviations from the pre-registered protocol). Since accuracy scores were clearly non-normally distrib-\nuted (Shapiro-Wilk test, all p<0.001  ), we used an ordinal logistic regression in place of the linear regression \nto test the effect of condition on accuracy scores. Results showed a significant effect of incentive ( \u03b2=0.293  \n[0.092,\u00a00.494], z=3.225  , p=0.003  ) and a lack of significance for the pop-up ( \u03b2=\u2212 0.009  [\u22120.207, 0.188]  , \nz=\u2212 0.103  , p=.918 ). According to the model, the probability of giving a \u201cdefinitely valid\u201d (\u201cdefinitely inva-\nlid\u201d) correct response increases by 4.4% [1.5%,8.2%] in the incentive condition compared to the control condi-\ntion. Exploratory analyses suggest that incentives were particularly effective in increasing accuracy scores in \nvalid posts (against control: \u03b2=0.3582  [0.07329,\u00a00.6431], z=3.268  , p=0.003  ; against pop-up: \u03b2=0.3713  \n[0.0913,\u00a00.6514], z=3.447  , p=0.003  ; S5 Analyses ). These last results should be taken with caution however, \nas posts from trusted sources were all presenting valid content.\nTechnique adoption.  To compare the adoption of Civic Online Reasoning techniques between experimental \nconditions (pre-registered hypothesis 2) we used a logistic regression with technique use (adoption of both lateral \nreading and click restraint) as predicted variable and experimental condition as predictor. Results revealed that \nboth incentive and pop-up increased technique adoption (Fig.\u00a0 3; incentive: \u03b2=1.042  [0.527,\u00a01.556], z=4.728  , \np<0.001  ; pop-up: \u03b2=1.556  [1.065,\u00a02.046], z=7.405  , p<0.001  ), but that the increase was markedly higher \nwith the presence of the pop-up than with monetary incentives ( \u03b2=0.514  [0.157,\u00a00.871], z=3.362  , p<0.001 ).\nExploratory: technique adoption.  Since our measure of technique use is based on self-reporting, responses \nmight have been biased by external expectations. We therefore checked whether participants who reported the \nuse of techniques actually left the study by tracking their behaviour on the post\u2019s web page. According to our \nmeasures, 80% of these participants left the study in the control condition, compared to 87% in the pop-up and \n90% in the incentive conditions. This result, if anything, suggests that our interventions did not increase the rate \nof false reporting. Moreover, even after accounting for false reports, results did not differ (incentive: \u03b2=1.156  \n[0.594,\u00a01.719], z=4.791  , p<0.001  ; pop-up: \u03b2=1.626  [1.087,\u00a02.166], z=7.024  , p<0.001  ; pop-up > incen-\n6\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/tive: \u03b2=0.467  [0.095,\u00a00.845], z=2.920  , p=0.004  ; see sections\u00a0S2 Analyses and S6 Analyses for an in-depth \nexploration of participants\u2019 search behaviour).\nDid the use of lateral reading and click restraint actually improve post evaluation? And did the use of tech -\nniques mediate the effect of our interventions? To test our first question, we ran an ordinal logistic regression with \naccuracy score as predicted variable, and a standard logistic regression with correct guessing as predicted variable, \nboth tests including adoption of techniques as the sole predictor. Results showed that accuracy score improved \nsignificantly if a participant reported using Civic Online Reasoning techniques ( \u03b2=0.526  [0.274,\u00a00.778], \nz=4.090  , p<0.001  ). According to the model, the use of Civic Online Reasoning Techniques increased the \nprobability of giving a \u201cdefinitely valid\u201d (\u201cdefinitely invalid\u201d) correct response by 8.8% [4.0%,14.7%]. This result \nhowever was not confirmed by the standard logistic regression on correct guessing, which instead found no \nsignificant effect of technique adoption (  \u03b2=0.219  [\u22120.121, 0.580]  , z=1.228  , p=0.220 ).\nBased on these results, we proceeded to test whether pop-up and incentives had some mediated impact on \naccuracy score through technique adoption. To test mediation we used the R package  MarginalMediation70. \nTechnique adoption was found to mediate the effect of both incentive and pop-up on accuracy score (incentive: \nunstandardised \u03b2=0.004  [0.001,\u00a00.006], z=4.728  , p<0.001  ; pop-up: unstandardised \u03b2=0.007  [0.003,\u00a00.012], \nz=7.405  , p<0.001  ). Although testing for one mediator cannot exclude countless other explanatory variables, \nthis analysis suggests an indirect relation between both interventions and accuracy scores.\nExploratory: response times. As we expected monetary incentives to increase motivation, we tested whether \nresponse times (a common proxy for increased deliberation and attention) were affected by our interventions. \nWe compared participants\u2019 evaluation time of the post (excluding the time spent on the pop-up) across condi-\ntions by way of a Kruskal-Wallis rank sum test. The test was significant ( \u03c72(2)=67.63  , p<0.001  ), thus we \nconducted post hoc comparisons. All comparisons were significant, with participants in the incentive condition \ntaking significantly more time than control ( log(V )=8.02 , p<0.001  ) and pop-up ( log(V )=5.54 , p<0.001  ) \nparticipants, and pop-up participants taking more time than control ( log(V )=2.41 , p=0.016 ).\nWe tested whether longer evaluation times predicted higher accuracy scores by means of an ordinal logistic \nregression with log-transformed evaluation time as predictor and accuracy score as predicted variable. Results \nrevealed a significant and positive association ( \u03b2=0.182  [0.095,\u00a00.268], z=4.12 , p<0.001  ). The result was \nconfirmed also for correct guessing (logistic regression, \u03b2=0.242  [0.120,\u00a00.366], z=3.87 , p<0.001 ).\nWe additionally looked at how much time participants spent outside the study page when they left without \nclicking any link (a proxy of lateral reading). The Kruskal-Wallis test was again significant ( \u03c72(2)=13.482  , \np=0.001  ): of those participants who performed such external searches, control participants spent less time \noutside the page than participants in both the incentive (  log(V )=2.85 , p=0.006  ) and the pop-up condi-\ntions ( log(V )=3.58 , p=0.001  ), whereas we found no significant difference between incentive and pop-up \n( log(V )=.92 , p=0.360 ).\nExploratory: source reputation.  Civic Online Reasoning techniques were originally designed for helping to \nevaluate content from seemingly legitimate but unknown  websites44. We thus analysed differences in our inter -\nventions based on the recognisability and perceived trustworthiness of the posts\u2019 sources. The importance of a \nsource\u2019s perceived trustworthiness was exemplified by two posts covering the same scientific article, one from \nBBC News (a source trusted by most participants), and another one from the Daily Mail (a source barely trusted \nby most participants). Despite the posts covered the same content and presented similar wording, participants\u2019 \nevaluation of the two posts differed considerably: average accuracy score was 4.7 for the BBC piece ( SD=1.05 ) Article \nSearch engine  \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nSearch engine  \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nSearch engine  \nWebsite \nFacebook  \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%control pop-up incen tive\nFigure\u00a03.  Race chart of self-report external search behaviour. Bars indicate the proportion of participants \nin each experimental condition reporting to have searched in either category of websites. Lateral reading is \nidentified with the proportion of participants searching information on a search engine (light red), whereas click \nrestraint is the subset of these participants who reported not stopping at the first algorithmically-ranked results \nof the search (dark red).\n7\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/and 4.05 for the Daily Mail piece ( SD=1.08 ; ordinal regression: \u03b2=1.255  [.926,\u00a01.584], z=7.470  , p<0.001  ), \nand the proportion of correct guesses was 90.7% and 77.3%, respectively (logistic regression: \u03b2=1.059  \n[0.568,\u00a01.576], z=4.132  , p<0.001 ).\nPerhaps not surprisingly, we observed that, in the pop-up condition, adoption of lateral reading and click \nrestraint was strongly linked with source type (Chi squared test with technique adoption and source category \nas variables, \u03c72(2)=15.407  , p<0.001  ): when the source was trusted, only 6.7% of participants used these \ntechniques, whereas the proportion was 20% when the source was unknown. We then tested differences of \nthe interventions by source type in accuracy scores and correct guessing. Likelihood-ratio tests confirmed the \nimportance of this variable for both analyses ( p<0.001  ), however family-wise corrected contrasts revealed only \none significant result, the effect of incentive on accuracy scores for unknown sources ( \u03b2=0.558  [0.114,\u00a01.001], \nz=3.445  , p=0.005  ; Fig.\u00a0 4; see S4 Analyses for results about the uncorrected contrasts).\nDiscussion. Results from Experiment 1 suggest that paying participants to be accurate does increase the \naccuracy score but not the proportion of participants correctly guessing the scientific validity of the posts. \nExploratory analyses suggest that, compared to control, participants with an incentive gave more extreme \nanswers, reported engaging in Civic Online Reasoning techniques more often (and did leave the page more \noften), spent more time in searching information outside the study page, and took longer to evaluate the post \n(even compared to pop-up participants). These results support the idea that monetary incentives affect accuracy, \npossibly by increasing motivation and attention in the task, although this hypothesis would need further testing.\nBy contrast, the presence of the pop-up seemed not to affect directly any indicator of accuracy. In spite of that, \nparticipants in the pop-up condition reported more lateral reading and click restraint, as well as the frequency \nof searches outside the study page. In turn, this increment of Civic Online Reasoning techniques (up to +13.5% \nwhen source is unknown) seems to mediate a small but significant increase in accuracy scores (exploratory \nmarginal mediation analysis), suggesting an indirect effect of the pop-up. An effect of pop-up is possibly seen in \nposts produced by unknown sources, where correct guessing (but not accuracy scores) is slightly higher in the \npop-up condition than in control (S4 Analyses).\nThese results suggest that monetary incentives might have more consistent effects over the presentation \nof Civic Online Reasoning techniques. At the same time, we observe considerable variability in participants\u2019 \nbehavior depending on specific features of the posts. For instance, source reputation seems to have a remarkable \neffect on the adoption of Civic Online Reasoning techniques, which were (foreseeably) overlooked by almost all \nparticipants when looking at posts from generally trusted sources.\nOne potential takeaway from these findings is that some prior beliefs might affect the rate at which partici -\npants look for information outside the content provided (e.g. familiarity and opinion about the source), as well as \nin the way they look for such information. To explore this possibility, we designed a second experiment in which \nwe tried to reduce the influence of prior beliefs by presenting posts from generally unknown sources. Lack of \nsource knowledge is indeed common on social media (e.g., sponsored content), and it should arguably increase \nthe rate at which participants rely on external information. In addition, we included a fourth condition where *****\n*contro l\nincentiv epop-up4.37\n4.624.53\n*\n*random respons e\nincentivecontro l\npop-u p\n4.304.16\n4.15\ncontro l\nincentivepop-up4.69\n4.624.52unknown distrusted trusted\n3456\naccuracy scoreSource reputation\nFigure\u00a04.  Bootstrap estimates of the average accuracy score by experimental condition and source reputation \n(Min. 1, Max. 6, random response: 3.5). Asterisks refer to significance of contrasts in the ordinal logistic \nregression. Black: family-wise corrected contrasts; dark grey: uncorrected contrasts. * p<0.05 , **p<0.01 , \n***p<0.001 .\n8\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/we test the combination of monetary incentives and Civic Online Reasoning techniques, to explore whether \nand how the two interact.\nExperiment 2\nIn line with evidence in the literature, we expected an increased impact of our interventions in a context where \nparticipants could rely on less prior information. We thus conducted a second experiment that was statistically \npowered to test for this possibility. In the Experiment 2 we replicated the format of the first one, with two main \nmodifications: 1) we ran a pre-screening survey to identify lesser-known sources of information and only used \nthose sources as the basis for the Facebook posts the participants were asked to evaluate; 2) we added an experi-\nmental condition that included both incentive and pop-up interventions, to test the interaction between the \ntwo. we advanced the idea that the two intervention strategies might trigger distinct behavioral outcomes (i.e., \nincreased time spent on the task and use of Civic Online Reasoning). If this is the case, then combining the two \ninterventions should produce even stronger effects on accuracy. The original pre-registration of this experiment \ncan be retrieved from osf. io/  w9vfb .\nMaterials and methods. Ethics statement. All participants gave their written informed consent for par -\nticipating in the experiment. The experimental protocols were approved by the Research Ethics Committee \n(CER) at the University of Paris (IRB No: 00012021-05), and all research was performed in accordance with the \nrelevant guidelines and regulations.\nParticipants. 3004 U.K. residents were recruited through the online platform prolific.co on 24 May 2021 (for \na rationale of sample size, see S2 Methods ). All participants gave their informed consent for participating in \nthe experiment. Average age was 36 ( SD=13.2 , 6 not specified), 63.1% of participants were female, (36.7% \nmale, 0.2% other), and 59.4% had a Bachelor\u2019s degree or higher. Per our pre-registered criteria, we excluded one \nparticipant who was not a resident in the United Kingdom. Analyses were thus conducted on 3003 participants.\nDesign.  The major difference from the first experiment was that sources of the Facebook posts were unknown \nto most participants. In addition, we included a fourth condition where we gave participants a monetary incen-\ntive and also showed them the pop-up with the Civic Online Reasoning techniques. Thus, the experiment had \na between-subjects design with 2 factors, pop-up (present, absent) and monetary incentive (present, absent). \nMedian completion time of the experiment was 5 minutes.\nStimuli.  Participants observed one out of 6 posts that varied in terms of: the scientific validity of the content, \ni.e. the validity of the scientific statements in the title, subtitle, and caption of the post; the topic (climate change, \ncoronavirus pandemic, and health and nutrition); factual reporting of the source, based on ratings from media \nbiasf actch  eck. com (3 high/very high versus 3 low/very low). All posts came from sources relatively unknown to \nparticipants, as measured in a preliminary survey and confirmed by participants\u2019 familiarity ratings. There were \ntwo distinct posts for each topic, one from a source with high factual reporting displaying valid information, one \nfrom a source with low factual reporting displaying invalid information.\nSome titles, subtitles and captions of the posts included references to governmental or academic institutions. \nTo prevent that these references could affect the evaluation of the content, we slightly rephrased some sentences \nto remove this information. In addition, we corrected also grammatical mistakes in the text that could have given \naway the reliability of the source.\nAdherence to pre\u2011registration. We conducted our analyses as described in the original pre-registration, but \nsome of the results for the pre-registered hypotheses are presented in the Supplementary materials. Results of \npre-registered hypothesis 1 are presented in two forms, in S7 Analyses in its original formulation, and in the \nmain text as a logistic regression (Technique adoption). Result of pre-registered hypothesis 6 is instead presented \nin S7 Analyses.\nResults. Participant randomisation was balanced across conditions (Chi squared test, \u03c72(1)=0.409  , \np=0.52 ); average N per post, per condition was 125, minimum 106, maximum 146. Median time to evaluate \nthe Facebook post was 33 seconds in the control condition, 48 seconds in the incentive condition, 34 seconds \nin the pop-up condition, and 58 seconds in the incentive + pop-up (minimum overall time: 2.5 seconds, maxi-\nmum overall time: 22 minutes). When the pop-up was present, participants spent an additional median time of \n11 seconds on the pop-up. On a scale from 1 to 6 (3.5 response at chance level), average accuracy score in the \ncontrol condition was 3.96 ( SD=1.33 ; incentive condition: 4.20, SD=1.41 ; pop-up condition: 4.07, SD=1.33 ; \nincentive + pop-up: 4.29, SD=1.44 ; Fig.\u00a0 5). In the control condition, 64.6% of participants correctly guessed the \nscientific validity of the post (incentive condition: 71.2%; pop-up condition: 66.2%; incentive + pop-up: 72.9%). \nOverall performance was generally lower than in Experiment 1, most likely due to the use of relatively unknown \nnews sources that forces participants not to rely on source knowledge to evaluate content.\nEffect of interventions. To test the individual and combined effects of pop-up tips and monetary incentives \n(pre-registered hypothesis 3, 4, and 5) we conducted two tests, one for each accuracy index. For accuracy scores, \nwe used two ordinal logistic regression models, one with pop-up, monetary incentive as predictors, and another \nregression including the same variables and the interaction between pop-up and incentive as an additional pre-\ndictor. For correct guessing, we compared two logistic regressions, one with correct guessing as dependent vari-\n9\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/able and pop-up, monetary incentive as predictors, and another regression including the same variables and the \ninteraction between pop-up and incentive as an additional predictor. For both the indices, we then adopted the \nmodel fitting data best according to a likelihood-ratio test. Perhaps surprisingly, model comparison favoured \nmodels without the interaction term (accuracy score: \u03c72(1)=0.032  , p=0.858  ; correct guessing: \u03c72(1)=0.007  , \np=.931 ); we thus tested the effect of incentives and pop-up assuming that they are (approximately) orthogonal. \nResults revealed a significant effect of incentive on both accuracy scores ( \u03b2=0.350  [0.194,\u00a00.505], z=5.371  , \np<0.001  ) and correct guessing ( \u03b2=0.313  [0.124,\u00a00.501], z=3.954  , p<0.001  ), and a significant effect of pop-\nup on accuracy scores ( \u03b2=0.137  [\u22120.018, 0.292]  , z=2.115  , p=0.034  ; Mixed-effects regression with errors \nclustered by post: p=0.052  ), but not on correct guessing ( \u03b2=0.076  [\u22120.112, 0.265]  , z=0.966  , p=0.334  ). \nIn addition, we found that the combination of the two interventions significantly increased both accuracy \nindices compared to control (accuracy score: \u03b2=0.487  [0.268,\u00a0 0.705], z=5.315  , p<0.001  ; correct guess-\ning: \u03b2=0.389  [0.123,\u00a00.654], z=3.496  , p<0.001  ), and that the contribution of incentive was greater than \nthe contribution of pop-up (accuracy score: \u03b2=0.213  [\u22120.007, 0.432]  , z=2.307  , p=0.028  ; correct guess-\ning: \u03b2=0.2362  [\u22120.032, 0.504 ] , z=2.103  , p=0.047  ). According to the ordinal logistic regression model, the \ncombination of the two interventions led to a 10.4% [5.4%,14.2%] increase in correct guessing, and a 6.9% \n[2.8%,12.4%] increase in \u201cdefinitely\u201d correct responses compared to control.\nTechnique adoption.  We tested whether technique adoption was influenced by either interventions follow-\ning a similar procedure to our test for correct guessing (comparison of two logistic regressions with/without \ninteraction; pre-registered hypothesis 1). likelihood-ratio tests again favoured the model without interaction \n( \u03c72(1)=0.245  , p=0.621  ). Model contrasts revealed several significant differences (Fig.\u00a0 6): both incentive \n( \u03b2=0.725  [0.471,\u00a0.978], z=6.829  , p<0.001  ) and pop-up ( \u03b2=1.191  [.926,\u00a01.455], z=10.736  , p<0.001  ) \nincreased significantly the use of Civic Online Reasoning techniques, but pop-up effect was significantly stronger \nthan the effect of the incentive ( \u03b2=0.466  [0.106,\u00a00.826], z=3.093  , p=0.002  ). In addition, the combined effect \nof pop-up and incentive was also significant ( \u03b2=1.915  [1.542,\u00a02.288], z=12.263  , p<0.001  ), leading to an \nestimated 16.5% [8.6%,26.0%] increase in technique use compared to control.\nTo test the robustness of these findings, we checked as in Experiment 1 the rate of false reporting (i.e., \nparticipants who said they used fact-checking techniques while they did not even leave the study page). False \nreporting was 22.2% in the control condition, 16% in the pop-up condition, 15.3% in the incentive condition, \nand 12.8% in the condition with both interventions. Exploratory analyses suggest that results did not differ after \naccounting for false reporting (pop-up: \u03b2=1.210  [.924,\u00a01.496], z=10.094  , p<0.001  ; incentive: \u03b2=0.761  \n[0.488,\u00a01.033], z=6.669  , p<0.001  ; pop-up>incentive: \u03b2=0.449  [0.061,\u00a00.838], z=2.759  , p=0.006  ; pop-up \n+ incentive: \u03b2=1.971  [1.570,\u00a02.372], z=11.729  , p<0.001  ; see S8 Analyses for an exploration of participants\u2019 \nsearch behaviour).\nTo test whether participants who adopted civic online reasoning techniques performed better in the task \n(pre-registered hypothesis 2) we run two tests, one for each accuracy index. For accuracy scores, since accuracy \nscores were non-normally distributed (Shapiro-Wilk test, all p<0.001  ) we used a ordinal logistic regression \nmodel, with accuracy score as dependent variable and adoption of techniques as a dummy predictor variable. \nFor correct guessing, we used a logistic regression, with correct guessing as dependent variable and adoption \nof techniques as a dummy predictor variable. According to the models, participants adopting Civic Online \nReasoning techniques were more accurate in terms of both accuracy score ( \u03b2=0.591  [0.414,\u00a00.767], z=6.560  , \np<0.001  ) and correct guessing ( \u03b2=0.506  [0.281,\u00a00.738], z=4.345  , p<0.001  ). According to the ordinal \nregression model, technique adoption increased the probability of giving a \u201cdefinitely valid\u201d (\u201cdefinitely invalid\u201d) \ncorrect response increases by 9.5% [5.9%,13.7%].\nWe also tested whether the use of Civic Online Reasoning techniques mediated the effect of the interventions \nwith two marginal mediation analyses on accuracy score and correct guessing. Technique adoption was found \nto mediate the effect of both incentive and pop-up on accuracy score (incentive: unstandardised \u03b2=0.007  *\n*******random responsecontrol\npop-up\nincentive\npop-up +\nincentive4.073.97\n4.294.20\n3456\naccuracy score\nFigure\u00a05.  Bootstrap estimates of the average accuracy score by experimental condition (Min. 1, Max. 6, \nrandom response: 3.5). Asterisks refer to significance of contrasts in the ordinal logistic regression. * p<0.05 , \n**p<0.01 , ***p<0.001 .\n10\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/[0.003,\u00a00.010], z=6.829  , p<0.001  ; pop-up: unstandardised \u03b2=0.011  [0.006,\u00a00.015], z=10.736  , p<0.001  ) \nand correct guessing (incentive: unstandardised \u03b2=0.008  [0.004,\u00a00.013], z=6.829  , p<0.001  ; pop-up: unstand-\nardised \u03b2=0.014  [0.007,\u00a00.021], z=10.736  , p<0.001 ).\nExploratory: response times. We compared participants\u2019 evaluation time of the post across conditions using \nlinear regressions with rank-transformed time as dependent variable and pop-up and incentives as predictors, \nwith and without interaction. Again, model comparison favoured the model without interaction ( F(1)=1.104  , \np=0.293  ). All contrasts were significant: both incentives ( \u03b2=370 [297,\u00a0443], t(2928) =12.127  , p<0.001  ) \nand pop-up ( \u03b2=61 [\u221212, 134 ] , t(2928) =2.011  , p=0.044  ) increased evaluation times, however incentives did \nso to a greater extent ( \u03b2=309 [205,\u00a0413], t(2928) =7.105  , p<0.001  ). Also, the combination of incentives and \npop-up led to higher evaluation times than control ( \u03b2=431 [329,\u00a0534], t(2928) =10.070  , p<0.001  ). We tested \nwhether longer evaluation times were associated with higher accuracy scores by means of an ordinal logistic \nregression with log-transformed evaluation time as predictor and accuracy score as predicted variable. Results \nrevealed a significant and positive association association ( \u03b2=0.152  [0.081,\u00a00.223], z=4.22 , p<0.001  ). The \nresult was confirmed also for correct guessing (logistic regression, \u03b2=0.204  [0.117,\u00a00.292], z=4.56 , p<0.001  ). \nWe also compared the duration of non-click external searches across conditions with the same procedure as \ntotal evaluation times, again finding no interaction between interventions ( F(1)=0.1746  , p=0.676  ). Results \nshowed a significant effect of incentive ( \u03b2=52 [15,\u00a090], t(726)=3.355  , p=0.001  ), pop-up ( \u03b2=80 [43,\u00a0116], \nt(726)=5.170  , p<0.001  ), and their combination ( \u03b2=132 [80,\u00a0184], t(726)=6.100  , p<0.001  ), but found no \nsignificant difference between the interventions ( \u03b2=27 [\u221226, 80]  , t(726)=1.217  , p=0.224 ).Article \nSearch engine  \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nSearch engine  \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%Article \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%\nArticle \nSearch engine \nWebsite \nFacebook \nWikipedia \nOther 0%\n10%\n20%\n30%\n40%\n50%60%70%80%90%incentive pop-up + incentiv econtrol pop-up\nFigure\u00a06.  Race chart of self-report external search behaviour. Bars indicate the proportion of participants \nin each experimental condition reporting to have searched in either category of websites. Lateral reading is \nidentified with the proportion of participants searching information on a search engine (light red), whereas click \nrestraint is the subset of these participants who reported not stopping at the first algorithmically-ranked results \nof the search (dark red).\n11\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/Discussion. Results from Experiment 2 confirmed the effectiveness of monetary incentives on accuracy, and \npresented evidence in favour of the potential usefulness of fact-checking tips when the post\u2019s source is unknown. \nMonetary incentives increased both accuracy scores and correct guessing (pre-registered hypothesis 4), the rate \nof (self-reported) Civic Online Reasoning techniques, as well as the frequency and duration of non-link searches \noutside the study page. Participants offered with a monetary incentive spent more time evaluating the post than \nthose who were not. Lastly, incentives seem to increase the sharing intentions of valid information compared to \ncontrol (S11 Analyses ).\nContrary to the Experiment 1, the pop-up intervention seems to increase accuracy scores, but not correct \nguessing (pre-registered hypothesis 3). We observed that the presence of the pop-up dramatically increased \ntechnique adoption (even compared to the presence of incentives; pre-registered hypothesis 1) and the rate of \nnon-link external searches, which in turn were linked to an increase in both measures of accuracy (pre-registered \nhypothesis 2). Exploratory marginal mediation analyses confirm an indirect effect of pop-up on accuracy meas -\nures via an increase of search outside the post page.\nIn this experiment, we also tested the interaction between incentive and pop-up (pre-registered hypothesis 5). \nModel comparison showed no interaction between the two interventions, suggesting that pop-up and monetary \nincentives contributed separately to the increase in accuracy. We additionally observe that monetary incentives \nincreased participants\u2019 time spent on reading the pop-up: median time is 12.3 seconds with incentive compared \nto 9.6 when incentive is absent (pre-registered hypothesis 6, S7 Analyses ). Despite this increase in reading times, \nour statistical tests do not detect an increased pop-up effects by any other metric.\nGeneral discussion\nIn this research, we studied whether presenting fact-checking tips and monetary incentives increases the correct \nevaluation of science-themed Facebook posts. In two experiments, participants rated the scientific validity of the \ncontent of one out of several posts, with some participants receiving a monetary reward when they responded \ncorrectly and other participants being shown a pop-up window (superimposed on the Facebook post itself) that \ncontained a list of fact-checking techniques proposed in the literature (Civic Online Reasoning). Results showed \nthat monetary incentives work as an accuracy booster. Moreover, data on search times and extremity of validity \nratings corroborated the hypothesis that incentives operate by increasing motivation and, subsequently, attention \non the content and other features of the post. This effect is particularly remarkable given the strong benchmark \nagainst which it was compared: a control condition were we simply asked participants to assess the scientific \nvalidity of the content of the post. In fact, just by reading the instructions, participants in the control condition \nlikely exerted a greater degree of attention than when routinely browsing social  media35. The effectiveness of \nthe pop-up as a way of introducing participants to fact-checking techniques received support in cases where the \nsource of the post was relatively unknown, i.e. when participants could rely on low prior information to evaluate \nposts. Furthermore, given that the presence of the pop-up significantly increases the adoption of Civic Online \nReasoning techniques, and that the use of these techniques is, in turn, a strong predictor of participants\u2019 perfor -\nmance on the task, marginal mediation analyses support the hypothesis that the pop-up may have an indirect \npositive effect on performance.\nOne of the original aims of this study was to establish whether incentives and techniques could be compared \nin their effectiveness in improving the evaluation of scientific content, even when not directly accessible with -\nout technical expertise. In this respect, our results suggest that the presence of the pop-up has less impact on \nsubsequent evaluation than monetary incentives. We suspect that the effectiveness of fact-checking advice may \nbe hampered by several factors. A first explanation is that the adoption of the techniques might not have been \neffective enough to avoid the influence of previous beliefs about the content or of the search style. For example, \nif participants considered a content to be plausible in the first place, they might have selectively ignored conflict-\ning information even when it was clearly present in the search results (i.e. confirmation  bias71); similarly, if a \nparticipant relied primarily on certain sources of information, consulting these sources might have steered the \ninterpretation in the wrong direction. It is unclear however how such biases might have meaningfully reduced \nthe effectiveness of the pop-up but not of the monetary incentives. A second possibility is that participants did \nnot engage in click restraint and instead relied only on the first few sources favoured by ranking algorithms, \nwith the risk of not getting enough contextual information to make a correct assessment. Although we cannot \nbe certain that more extensive searches lead to more reliable information sources, we argue that they facilitate \na more balanced evaluation of the information  available72. Lastly, the reduced impact of the pop-up may derive \nfrom its brevity: Civic Online Reasoning techniques have in fact been tested so far after being taught in extensive \ncourses. It is therefore possible that simply presenting a condensed set of tips on the best techniques is not enough \nto fully understand and master them. This possibility is in line with similar unsuccessful previous interventions \npresenting news literacy  tips40, 65, 73. Thus, true ability to recognise pseudo-scientific information might only \ncome from a minimal mastery of critical-thinking skills, which cannot be achieved by simply adding a snippet \nof information to a post, in the form of a pop-up.\nDespite the asymmetric contribution of monetary incentives and fact-checking techniques, our results also \nindicate that the interventions may work in a complementary way. In particular, Experiment 2 shows that these \ntwo interventions do not appear to interact with each other. This result, which was replicated by testing different \nvariables of interest, suggests that the working mechanisms of the interventions are largely orthogonal, and thus \ncan be combined to achieve an even stronger evaluation performance by participants.\nOur results on incentives are in line with an attention-based account of information processing on social \nmedia; that is, increased deliberation is sufficient to decrease belief in false  content6. Our results add to the litera-\nture of attention-based interventions by showing how monetary incentives can additionally modulate motivation \nand attention and increase performance.\n12\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/These promising results were not self-evident, as several experiments have cautioned against the universal \neffectiveness of monetary incentives as a behavioural  driver74\u201376. In fact, incentives that are either too small or \ntoo large have been shown to decrease rather than increase  motivation77.\nMoreover, when explicit incentives seek to modify behaviour in areas such as education, environmental \nactions, and the formation of healthy habits, a conflict arises between the direct extrinsic effect of incentives \nand how these incentives may crowd out intrinsic motivations. Seeking accuracy in judging news is certainly \ndriven by the intrinsic motivations of individuals. In all likelihood, however, these intrinsic motivations do not \nconflict with monetary incentives. Seeking accuracy, unlike deliberately adopting ecological behaviour or going \non a diet, is a largely automatic process.\nAnother concern was that motivation and attention might not have been sufficient for content that is hardly \naccessible to non-experts. It was thus unexpected to observe how incentives were effective even when participants \nevaluated information based on scientific and technical reports, and thus had to rely external knowledge and \nintuition when claims and data were not immediately available.\nCompared to work on Civic Online  Reasoning44, our study finds correlational and causal evidence support -\ning the importance of lateral reading and click restraint as predictors of accurate information, especially (as \ninitially intended) when the information about the source is scarce. Notably, this is the first reported evidence \nof a general population intervention in a social media context, extending the evidence for its applicability. We \nnote however that the connection between our intervention (the pop-up) and technique use is only indirect, as \nparticipants were free to ignore recommendations. Stronger evidence for the efficacy of Civic Online Reasoning \ntechniques could come from within-subject studies that could limit selectively the use of the techniques to assess \ntheir direct impact on users\u2019 behaviour.\nOur results also partly support literature on media and news  literacy39. Previous successful attempts at \nusing fact-checking tips relied on presenting participants with some of the Facebook guidelines for evaluating \n information41, 42. Critically, these tips acted by reducing post engagement (liking, commenting, sharing) and \nperceived accuracy of headlines by hyper-partisan and fake news sources. Given that our results highlight the \neffectiveness of fact-checking tips when participants are less familiar with the source, we suspect that the use of \nsuch tips is inversely associated to its knowledge and reputation: the more the source is well-known and widely \nrespected, the less participants will rely on guidelines and recommendations. This interpretation is in line with \nresearch on media credibility cues: a site\u2019s credentials are often seen as a sign of  expertise78, and experimental \nevidence suggests that users rely on  expertise79 and source  reputation80 to guide their judgement. At the same \ntime, however, studies have shown how in contexts like social media peripheral cues can be disregarded, such as \nclear \u2019sponsored content\u2019  labels81. Similarly, previous studies on disinformation claim that source information \nhas little impact on judging the accuracy of social media  content82\u201384. Although we did not directly test for the \npresence/absence of source information, we did find that familiarity with and trust in a source largely affected \nthe search style and evaluation of the content, suggesting that providing this information to participants had a \nmeaningful effect on their validity evaluations. One way to reconcile these apparently antithetical conclusions is \nby considering the relative capability of participants to assess the plausibility of information: source knowledge \ncan be a viable heuristic when information is harder to evaluate. Indeed, we suspect that in our experiment \ninformation about the source was often easier to assess than the plausibility of the content itself. In addition, \ncompared to previous experiments, participants could open the original article of the post to confirm that it had \nactually been produced by the source and not fabricated, a factor that probably increased reliance on the source. \nThese considerations and our findings are not sufficient to ascertain whether and under what circumstances \nreliance on the source is beneficial or detrimental; however, we argue that source information is important in \nmany  situations85, 86.\nOur study does not come without limitations. Possibly the most critical issue is the limited number of stimuli \nthat were used across experiments (15), which did not allow us to properly control for many features that could \nimpact the evaluation of the posts. Even though we cannot exclude confounding variables and biases in the \nselection of stimuli, we tried as much as possible to follow a standardised procedure with pre-defined criteria in \norder to exclude stimuli that could be considered problematic. Moreover, even though most of the literature and \nthe present study have focused on standardised stimuli reporting content from news sources, we recognize that \nscientific (dis)information comes in several formats that also depend on the topic, the audience, and the strategy \nof the creator. We decided to exclude other types of formats (e.g. videos or screenshots) to try to minimise the \ndifferences in experience between users, we think however that future research should explore more in depth \nthe impact of varying media on the impact of disinformation spread and on possible counteracting interven-\ntions. Another limitation to the extendibility of our results comes from the nature of the samples, consisting \nof UK residents recruited from an online platform, which also suggests a certain versatility with technology. \nIndeed, one large obstacle to the use of Civic Online Reasoning techniques is the limited or selective accessibility \nto Internet in several  countries87, where navigation plans can be limited to messaging apps only. Morover, tips \nabout lateral reading and click restraint should vary to adapt to audiences with different digital literacy, as a one-\nsize-fit all messages have shown to be ineffective in samples with low familiarity with the online  environment41. \nFuture research should explore how these techniques can be proposed in contexts with limited resources, and \nwhat alternative approaches can be taken to bypass Internet constraints. Future research should explore how \nthese techniques can be proposed in contexts with limited resources, and what alternative approaches can be \ntaken to bypass Internet constraints. Lastly, the study explored the effectiveness of interventions when using a \ncomputer, as the very concept of lateral reading is based on browsing horizontally through internet tabs on a \ncomputer. Although nothing precludes the use of such techniques on other devices such as a mobile phone or \ntablet, the user interface is often not optimised to search for different contents at the same time, making their use \nmore cumbersome. This is particularly problematic considering that social media are predominantly accessed \nthrough mobile devices. A promising direction in the fight to disinformation will be to study the influence of the \n13\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/device and UI in the ability of users to access high-quality information. Further studies should also investigate \nhow much easiness of accessing information from within a specific app could prompt users to fact-check what \nthey see. For example, many apps allow to check information on the internet via an internal browser without \nleaving the app itself.\nConclusion\nThis study set out to assess the relative effectiveness of monetary incentives and fact-checking tips in recognising \nthe scientific validity of social media content. We found strong evidence that incentivising participants increases \naccuracy evaluations; we also found evidence that fact-checking tips increase accuracy evaluation when the \nsource of the information is unknown. These results suggest a promising role of attention and search strategies, \nand open the way to the test of multiple approaches in synergy to achieve the most effective results.\nReceived: 1 October 2021; Accepted: 15 March 2022\nReferences\n 1. Academies AAE. Trust in Science and Changing Landscapes of Communication. 2019. https://  allea.  org/ portf  olio-  item/  trust-  in- \nscien  ce- and-  chang  ing- lands  capes-  of- commu  nicat  ion/.\n 2. \u00c1lvarez-Moreno, C., Valderrama-Beltr\u00e1n, S., & Rodriguez-Morales, A. J. Implications of antibiotic use during the covid-19 pan -\ndemic: the example of associated antimicrobial resistance in Latin America (2021).\n 3. Roose, K., Isaac, M., & Frenkel, S. Facebook Struggles to Balance Civility and Growth. https://  www.  nytim  es. com/  2020/  11/ 24/ \ntechn  ology/ faceb  ook-  elect  ion- misin  forma  tion.  html  (2020).\n 4. AV AAZ. Facebook\u2019s Algorithm: A Major Threat to Public Health. (2020). https:// secure. avaaz. org/ campa  ign/ en/ faceb  ook_ threat_  \nhealth/ .\n 5. Martini, C. & Andreoletti, M. Genuine versus bogus scientific controversies: The case of statins. History Philos. Life Sci. 43(4), 1\u201323 \n(2021).\n 6. Pennycook, G. & Rand, D. G. The psychology of fake news. Trends Cognit. Sci.  (2021).\n 7. Lewandowsky, S. & Van Der Linden, S. Countering misinformation and fake news through inoculation and prebunking. Eur. Rev. \nSoc. Psychol. 1\u201338 (2021).\n 8. Kozyreva, A., Lewandowsky, S. & Hertwig, R. Citizens versus the internet: Confronting digital challenges with cognitive tools. \nPsychol. Sci. Public Interest. 21(3), 103\u2013156 (2020).\n 9. Lorenz-Spreen, P ., Lewandowsky, S., Sunstein, C. R. & Hertwig, R. How behavioural sciences can promote truth, autonomy and \ndemocratic discourse online. Nat. Hum. Behav. 1\u20138 (2020).\n 10. Lewandowsky, S., Ecker, U. K. & Cook, J. Beyond misinformation: Understanding and coping with the post-truth Era. J. Appl. Res. \nMem. Cognit.  6(4), 353\u2013369 (2017).\n 11. Lewandowsky, S., Ecker, U. K., Seifert, C. M., Schwarz, N. & Cook, J. Misinformation and its correction: Continued influence and \nsuccessful debiasing. Psychol. Sci. Public Interest.  13(3), 106\u2013131 (2012).\n 12. Lewandowsky, S. et al. The Debunking Handbook  (2020).\n 13. Cook, J., Lewandowsky, S. & Ecker, U. K. Neutralizing misinformation through inoculation: Exposing misleading argumentation \ntechniques reduces their influence. PloS One.  12(5), e0175799 (2017).\n 14. Hertwig, R. & Gr\u00fcne-Y anoff, T. Nudging and boosting: Steering or empowering good decisions. Perspect. Psychol. Sci. 12(6), \n973\u2013986 (2017).\n 15. Walter, N., Brooks, J. J., Saucier, C. J. & Suresh, S. Evaluating the impact of attempts to correct health misinformation on social \nmedia: a meta-analysis. Health Commun.  1\u20139 (2020).\n 16. Bode, L. & Vraga, E. K. See something, say something: Correction of global health misinformation on social media. Health Com \u2011\nmun.  33(9), 1131\u20131140 (2018).\n 17. Bode, L. & Vraga, E. K. In related news, that was wrong: The correction of misinformation through related stories functionality in \nsocial media. J. Commun.  65(4), 619\u2013638 (2015).\n 18. Colliander, J. This is fake news: Investigating the role of conformity to other users\u2019 views when commenting on and spreading \ndisinformation in social media. Comput. Hum. Behav. 97, 202\u2013215 (2019).\n 19. Brashier, N. M., Pennycook, G., Berinsky, A. J. & Rand, D. G. Timing matters when correcting fake news. Proc. Natl. Acad Sci.  \n118(5), (2021).\n 20. Resnick, P ., Alfayez, A., Im, J., & Gilbert, E. Informed crowds can effectively identify misinformation. arXiv preprint arXiv: 21080  \n7898 . (2021).\n 21. Allen, J., Arechar, A. A., Pennycook, G. & Rand, D. G. Scaling up fact-checking using the wisdom of crowds. Sci. Adv. 7, 1\u201310 \n(2021).\n 22. Allen, J., Arechar, A. A., Rand, D. G. & Pennycook, G. Crowdsourced Fact\u2011Checking: A Scalable Way to Fight Misinformation on \nSocial  (Media, 2020).\n 23. Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. \nProc. Natl. Acad Sci.  116(7), 2521\u20132526 (2019).\n 24. Godel, W . et al. Moderating with the mob: Evaluating the efficacy of real-time crowdsourced fact-checking. J. Online Trust Saf.  \n1(1), (2021).\n 25. Allen, J. N. L., Martel, C., & Rand, D. Birds of a feather don\u2019t fact-check each other: Partisanship and the evaluation of news in \nTwitter\u2019s Birdwatch crowdsourced fact-checking program (2021).\n 26. McGuire, W . J. Inducing resistance to persuasion. Some Contemporary Approaches, in Advances in Experimental Social Psychology  \nVol.\u00a01. (ed. Berkowitz, L.) 191\u2013229 (Academic Press, 1964).\n 27. Roozenbeek, J. & Van Der Linden, S. The fake news game: Actively inoculating against the risk of misinformation. J. Risk Res.  \n22(5), 570\u2013580 (2019).\n 28. Roozenbeek, J., van der Linden, S. & Nygren, T. Prebunking interventions based on \u201cinoculation\u201d theory can reduce susceptibility \nto misinformation across cultures. Harvard Kennedy School Misinformation. Review.  1(2), (2020).\n 29. Roozenbeek, J., & van\u00a0der Linden, S. Breaking Harmony Square: A game that \u201cinoculates\u201d against political misinformation. The \nHarvard Kennedy School Misinformation Review. (2020).\n 30. Cook, J. Cranky Uncle Vs  (How to Understand and Respond to Climate Science Deniers, Climate Change, 2020).\n 31. Clayton, K. et al. Real solutions for fake news? Measuring the effectiveness of general warnings and fact-check tags in reducing \nbelief in false stories on social media. Political Behav.  1\u201323 (2019).\n14\nVol:.(1234567890) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/ 32. Mena, P . Cleaning up social media: The effect of warning labels on likelihood of sharing false news on Facebook. Policy Int.  12(2), \n165\u2013183 (2020).\n 33. Gaozhao, D. Flagging Fake News on Social Media: An Experimental Study of Media Consumers\u2019 Identification of Fake News. \nAvailable at SSRN 3669375. (2020).\n 34. Pennycook, G., Bear, A., Collins, E. T. & Rand, D. G. The implied truth effect: Attaching warnings to a subset of fake news headlines \nincreases perceived accuracy of headlines without warnings. Manag. Sci. (2020).\n 35. Pennycook, G. et al. Shifting attention to accuracy can reduce misinformation online. Nature.  1\u20136 (2021).\n 36. Pennycook, G., Epstein, Z., Mosleh, M., Arechar, A. A., Eckles, D., & Rand, D. Understanding and reducing the spread of misin -\nformation online. arxiv:  https://  psyar  xivcom/  3n9u8 . (2019).\n 37. Pennycook, G., McPhetres, J., Zhang, Y ., Lu, J. G. & Rand, D. G. Fighting COVID-19 misinformation on social media: Experimental \nevidence for a scalable accuracy-nudge intervention. Psychol. Sci.  31(7), 770\u2013780 (2020).\n 38. Roozenbeek, J., Freeman, A. L., & van\u00a0der Linden, S. How accurate are accuracy-nudge interventions? A preregistered direct \nreplication of Pennycook et\u00a0al. (2020). Psychol. Sci. , 09567976211024535 (2021).\n 39. Tully, M., Maksl, A., Ashley, S., Vraga, E. K. & Craft, S. Defining and conceptualizing news literacy. Journalism.  14648849211005888 \n(2021).\n 40. Vraga, E. K., Bode, L. & Tully, M. Creating news literacy messages to enhance expert corrections of misinformation on Twitter. \nCommun. Res. 0093650219898094 (2020).\n 41. Guess, A. M. et al. A digital media literacy intervention increases discernment between mainstream and false news in the USA \nand India. Proc. Natl. Acad. Sci.  117(27), 15536\u201315545 (2020).\n 42. Lutzke, L., Drummond, C., Slovic, P . & \u00c1rvai, J. Priming critical thinking: Simple interventions limit the influence of fake news \nabout climate change on Facebook. Global Environ. Change.  58, 101964 (2019).\n 43. Jones-Jang, S. M., Mortensen, T. & Liu, J. Does media literacy help identification of fake news? Information literacy helps, but \nother literacies don\u2019t. Am. Behav. Sci. 0002764219869406 (2019).\n 44. Wineburg, S., & McGrew, S. Lateral reading: Reading less and learning more when evaluating digital information. (2017).\n 45. Breakstone, J., Smith, M., Wineburg, S., Rapaport, A., Carle, J., & Garland, M., et\u00a0al . Students\u2019 civic online reasoning: A national \nportrait. Educ. Res.  0013189X211017495 (2019).\n 46. McGrew, S., Ortega, T., Breakstone, J. & Wineburg, S. The challenge that\u2019s bigger than fake news: Civic reasoning in a social media \nenvironment. Am. Educ.  41(3), 4 (2017).\n 47. Shelton, K. The value of search results rankings. (2017). https:// www. forbes. com/ sites/ forbe sagen  cycou ncil/ 2017/ 10/ 30/ the- value- \nof- searc  hresu  lts- ranki  ngs/ .\n 48. Del Vicario, M. et al. The spreading of misinformation online. Proc. Natl. Acad. Sci. 113(3), 554\u2013559 (2016).\n 49. Martini, C. Ad hominem arguments, rhetoric, and science communication. Studies in logic. Grammar Rhetoric.  55(1), (2018).\n 50. McGrew, S., Breakstone, J., Ortega, T., Smith, M. & Wineburg, S. Can students evaluate online sources? Learning from assessments \nof civic online reasoning. Theory Res. Soc. Educ.  46(2), 165\u2013193 (2018).\n 51. McGrew, S., Smith, M., Breakstone, J., Ortega, T. & Wineburg, S. Improving university students\u2019 web savvy: An intervention study. \nBr. J. Educ. Psychol. 89(3), 485\u2013500 (2019).\n 52. McGrew, S. & Byrne, V . L. Who Is behind this? Preparing high school students to evaluate online content. J. Res. Technol. Educ.  \n1\u201319 (2020).\n 53. Moore, R. C., & Hancock, J.T. The Effects of Online Disinformation Detection Training for Older Adults. (2020).\n 54. Chen, C. X., Pennycook, G. & What, Rand D. Makes News Sharable on Social Media?  (2021).\n 55. Altay, S., de Araujo, E. & Mercier, H. If this account is true, it is most enormously wonderful: Interestingness-if-true and the sharing \nof true and false news. Digital. Journalism.  1\u201322 (2021).\n 56. Cerasoli, C. P ., Nicklin, J. M. & Ford, M. T. Intrinsic motivation and extrinsic incentives jointly predict performance: A 40-year \nmeta-analysis. PPsychol. Bull. 140(4), 980 (2014).\n 57. Kaufmann, N., Schulze, T. & Veit, D. More than fun and money: Worker motivation in crowdsourcing-a study on Mechanical \nTurk. Working paper.  (2011).\n 58. Gneezy, U., Meier, S. & Rey-Biel, P . When and why incentives (don\u2019t) work to modify behavior. J. Econ. Perspect.. 25(4), 191\u2013210 \n(2011).\n 59. Rickard, J. A. & Russell, A. M. Interest in Advance and Other Up\u2011front Incentives. Graduate School of Management (University of \nMelbourne, 1986).\n 60. Pennycook, G. & Rand, D. G. Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than \nby motivated reasoning. Cognition. 188, 39\u201350 (2019).\n 61. Pennycook, G., & Rand, D. Reducing the spread of fake news by shifting attention to accuracy: Meta-analytic evidence of replica-\nbility and generalizability. (2021).\n 62. Epstein, Z., Berinsky, A.J., Cole, R., Gully, A., Pennycook, G., & Rand, D.G. Developing an accuracy-prompt toolkit to reduce \nCOVID-19 misinformation online. Harvard Kennedy School Misinformation Review. (2021)\n 63. Jahanbakhsh, F. et al. Exploring lightweight interventions at posting time to reduce the sharing of misinformation on social media. \nProc. ACM Hum. \u2011Comput. Interact. 5(1), 1\u201342 (2021).\n 64. Crawford E. Introducing Tip Jar. (2021). https://  blog.  twitt  er. com/ en_ us/  topics/  produ  ct/ 2021/  intro  ducing-  tip- jar.\n 65. Tully, M., Vraga, E. K. & Bode, L. Designing and testing news literacy messages for social media. Mass Commun. Soc. 23(1), 22\u201346 \n(2020).\n 66. Vraga, E. K. & Tully, M. Media literacy messages and hostile media perceptions: Processing of nonpartisan versus partisan political \ninformation. Mass Commun. Soc. 18(4), 422\u2013448 (2015).\n 67. Henninger, F., Shevchenko, Y ., Mertens, U., Kieslich, P . J., Hilbig, B. E.  Lab. js: A free, open, online study builder. PsyArXiv. (2019).\n 68. Taylor, A. B., West, S. G. & Aiken, L. S. Loss of power in logistic, ordinal logistic, and probit regression when an outcome variable \nis coarsely categorized. Educ. Psychol. Meas.  66(2), 228\u2013239 (2006).\n 69. R Core Team. R: A Language and Environment for Statistical Computing. (2018). https:// www.R-  proje  ct. org/\n 70. Barrett, T.S. MarginalMediation: Marginal Mediation. (2019). https://  CRAN.R- proje  ct. org/ packa  ge= Margi  nalMe  diati  on.\n 71. Nickerson, R. S. Confirmation bias: A ubiquitous phenomenon in many guises. Rev. Gener. Psychol. 2(2), 175\u2013220 (1998).\n 72. Klurfeld, J. & Schneider, H. News literacy: Teaching the internet generation to make reliable information choices. Brookings Institu \u2011\ntion Research Paper. (2014).\n 73. Vraga, E., Tully, M. & Bode, L. Assessing the relative merits of news literacy and corrections in responding to misinformation on \nTwitter. New Media Soc.  1461444821998691 (2021).\n 74. Frey, B. S. & Oberholzer-Gee, F. The cost of price incentives: An empirical analysis of motivation crowding-out. Am. Econ. Rev.  \n87(4), 746\u2013755 (1997).\n 75. Fryer, R. G. Jr. Financial incentives and student achievement: Evidence from randomized trials. Q. J. Econ. 126(4), 1755\u20131798 \n(2011).\n 76. Chao, M. Demotivating incentives and motivation crowding out in charitable giving. Proc. Natl. Acad. Sci. 114(28), 7301\u20137306 \n(2017).\n 77. Gneezy, U. & Rustichini, A. Pay enough or don\u2019t pay at all. Q. J. Econ. 115(3), 791\u2013810 (2000).\n15\nVol.:(0123456789) Scientific Reports  |         (2022) 12:5678  | https://doi.org/10.1038/s41598-022-09168-y\nwww.nature.com/scientificreports/ 78. Metzger, M. J., Flanagin, A. J., Eyal, K., Lemus, D. R. & McCann, R. M. Credibility for the 21st century: Integrating perspectives \non source, message, and media credibility in the contemporary media environment. Ann. Int. Commun. Assoc. 27(1), 293\u2013335 \n(2003).\n 79. Flanagin, A. J., Winter, S. & Metzger, M. J. Making sense of credibility in complex information environments: The role of message \nsidedness, information source, and thinking styles in credibility evaluation online. Inform. Commun. Soc. 23(7), 1038\u20131056 (2020).\n 80. Tandoc, E. C. Jr., Ling, R., Westlund, O., Duffy, A. & Goh, D. Zheng Wei L. Audiences\u2019 acts of authentication in the age of fake \nnews: A conceptual framework. New Media Soc. . 20(8), 2745\u20132763 (2018).\n 81. Wineburg, S. & McGrew, S. Evaluating Information: The Cornerstone of Civic Online Reasoning (2016).\n 82. Dias, N., Pennycook, G. & Rand, D. G. Emphasizing publishers does not effectively reduce susceptibility to misinformation on \nsocial media. Harvard Kennedy School Misinformation. Review.  1(1), (2020).\n 83. Pennycook, G. & Rand, D. G. Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic \nthinking. J. Personal. 88(2), 185\u2013200 (2020).\n 84. Tsang, S. J. Motivated fake news perception: The impact of news sources and policy support on audiences\u2019 assessment of news \nfakeness. Journalism & Mass. Commun. Q.  1077699020952129 (2020).\n 85. Kim, A., Moravec, P . L. & Dennis, A. R. Combating fake news on social media with source ratings: The effects of user and expert \nreputation ratings. J. Manag. Inform. Syst.  36(3), 931\u2013968 (2019).\n 86. Nadarevic, L., Reber, R., Helmecke, A. J. & K\u00f6se, D. Perceived truth of statements and simulated social media postings: An experi -\nmental investigation of source credibility, repeated exposure, and presentation format. Cognit. Res. Princ. Implic. 5(1), 1\u201316 (2020).\n 87. Belli, L. WhatsApp skewed Brazilian election, showing social media\u2019s danger to democracy. (2018). https://  theco  nvers  ation. com/  \nwhats  app-  skewed-  brazi  lian-  elect  ion- showi  ng- social-  medias- danger- to-  democ  racy-  106476.\nAcknowledgements\nThis project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme \nunder grant agreement No 870883. The information and opinions are those of the authors and do not neces-\nsarily reflect the opinion of the European Commission. We would like to thank Torbj\u00f8rn Gundersen, Philipp \nLorenz-Spreen, David J. Gr\u00fcning, and the members of the Prosocial Design Network for their insightful com -\nments and advice.\nAuthor contributions\nC.M. and S.M. provided materials for the experiment; F.P ., P .R., C.M., S.M. and T.M. designed the experiment; \nF.P . and P .R. conducted the experiment; F.P . analysed the data; F.P ., P .R., C.M., wrote the manuscript; All authors \nreviewed the manuscript.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 022- 09168-y .\nCorrespondence and requests for materials should be addressed to F.P .\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article\u2019s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat  iveco  mmons. org/ licen  ses/ by/4. 0/.\n\u00a9 The Author(s) 2022", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Lateral reading and monetary incentives to spot disinformation about science", "author": ["F Panizza", "P Ronzani", "C Martini", "S Mattavelli"], "pub_year": "2022", "venue": "Scientific Reports", "abstract": "Disinformation about science can impose enormous economic and public health burdens. A  recently proposed strategy to help online users recognise false content is to follow the"}, "filled": false, "gsrank": 283, "pub_url": "https://www.nature.com/articles/s41598-022-09168-y", "author_id": ["3Czlt7sAAAAJ", "WivYW0gAAAAJ", "eY7rqmIAAAAJ", "Dg1tCoIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:izNCxtH3ImAJ:scholar.google.com/&output=cite&scirp=282&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=izNCxtH3ImAJ&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 49, "citedby_url": "/scholar?cites=6927371657195697035&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:izNCxtH3ImAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-022-09168-y.pdf"}}, {"title": "Social media sharing by political elites: An asymmetric American exceptionalism", "year": "2022", "pdf_data": "SOCIAL MEDIA SHARING BY POLITICAL ELITES : AN\nASYMMETRIC AMERICAN EXCEPTIONALISM\nPREPRINT\nJana Lasser\nGraz University of Technology\nComplexity Science Hub Vienna\nSegun Taofeek Aroyehun\nGraz University of Technology\nAlmog Simchon\nUniversity of Bristol\nFabio Carrella\nUniversity of Bristol\nDavid Garcia\nGraz University of Technology\nComplexity Science Hub Vienna\nStephan Lewandowsky\nUniversity of Bristol\nUniversity of Western Australia\nABSTRACT\nIncreased sharing of untrustworthy information on social media platforms is one of the main chal-\nlenges of our modern information society. Because information disseminated by political elites is\nknown to shape citizen and media discourse, it is particularly important to examine the quality of\ninformation shared by politicians. Here we show that from 2016 onward, members of the Republican\nparty in the U.S. Congress have been increasingly sharing links to untrustworthy sources. The\nproportion of untrustworthy information posted by Republicans versus Democrats is diverging at\nan accelerating rate, and this divergence has worsened since president Biden was elected. This\ndivergence between parties seems to be unique to the U.S. as it cannot be observed in other western\ndemocracies such as Germany and the United Kingdom, where left-right disparities are smaller and\nhave remained largely constant.\nKeywords misinformation \u0001elites \u0001political discourse\nIntroduction\nElite cues are important drivers of public public opinions and discourse [ 7]. For example, public concern about climate\nchange is largely in\ufb02uenced by opinions and information shared by elites [ 5]. The public\u2019s increased polarisation over\nclimate change re\ufb02ects the retreat of the Republican leadership from the scienti\ufb01c evidence [ 15]. The power of elites\nto set the agenda of public conversations extends to mainstream media. For example, Donald Trump has been shown\nto successfully divert media attention away from topics that were potentially harmful to him [ 14]. Notwithstanding\nthe importance of elite discourse, research attention has only recently shifted to investigating the information sharing\npractices of a broader range of members of the political elite [ 16]. Here we contribute to these analyses by investigating\nthe quality of information shared on social media by members of the U.S. Congress. We \ufb01nd that the trustworthiness\nof information shared by members of the Republican party is declining and that this decline has accelerated after the\nelection of Joe Biden as president. We contrast these \ufb01ndings with information sharing practices of political elites in\ntwo other western democracies, Germany and the United Kingdom. In both cases, although parties on the political right\ntend to share somewhat less trustworthy information, the rapid decline of information quality shared by Republicans\nduring the last 6 years is unique to the U.S. and is not observed in other countries.\nResults\nTo assess the trustworthiness of information shared by politicians with the general public, we retrieve three corpora of\ntweets: by former and active members of the U.S. Congress, the German parliament and the British parliament. For\neach corpus, we retrieve all tweets posted between January 1, 2016 and March 16 2022. We do not include retweets. WearXiv:2207.06313v1  [cs.CY]  13 Jul 2022\nSocial media sharing by political elites: An asymmetric American exceptionalism PREPRINT\nextract all URLs included in the tweets. We follow an approach employed by similar research in this domain [ 10,20]\nand use a trustworthiness assessment by professional fact checkers of the domain a link points to. To this end, we\nuse the NewsGuard database [ 18]. As of March 2022, NewsGuard indexes 6860 English and 145 German language\ndomains. Each domain is scored on a scale of 0 (very poor) to 100 (exceptional quality journalism) points. Domains\nwith less than 60 points are considered \u201cnot trustworthy\u201d [ 18]. The majority of indexed domains (62.8% for English,\n74.5% for German) are considered trustworthy. After excluding links to social media websites (Twitter, YouTube,\nFacebook, Instagram) and search engines (Google, Yahoo), the database covers 50.5% of links posted by members of\nthe U.S. Congress, 54.6% of links posted by members of the German parliament and 44.2% of links posted by members\nof the British parliament. Coverage generally increases slightly over time and is similar between parties (see Materials\nand Methods for details).\nWe report the overall proportion of links that point to domains that are considered untrustworthy, as well as the\nNewsGuard score. Figure 1 A-Cshows the proportion of links to untrustworthy domains for the three countries. For\nthe U.S., we report values over ideology scores provided by GovTrack [ 9], for Germany and the United Kingdom we\nreport values broken down by parties. Republicans share more untrustworthy information than Democrats (note the\nlogarithmic scale). For Germany, parties on the extreme left and extreme right share more untrustworthy information\nthan parties in the centre. Overall, Republicans share 9.1 times more links to websites considered unstrustworthy\nthan Democrats (Republicans 3.87%, Democrats 0.42%, difference 3.45%, 1.83 SD). For Germany, members of the\nCDU/CSU post 6.1 times more links to such websites than members of the SPD (CDU/CSU 0.19%, SPD 0.03%,\ndifference 0.16%, 0.02 SD). For the UK, members of the Tories post 4.7 times more links to untrustworhty domains\nthan members of the Labour party (Tory 0.23%, Labour 0.05%, difference 0.18%, 0.07 SD). For both Germany and the\nUK, the conservative parties post more links to untrustworthy domains than their counterparts on the left, but overall\nthey post about half as many such links as the Democrats in the U.S. We also note that numbers for Germany and the\nUK are based on very low overall counts of links to untrustworthy domains.\nIn Fig. 1 D-Fwe show the temporal trend of the NewsGuard score, averaged over all links posted in a given month\nbroken down by party. Links posted by Republicans show a notable decrease in trustworthiness, from on average\n89:9\u00060:1(mean \u0006SD) points in the years 2016-2018 to 85:2\u00061:7points in the years 2020-2022. The score of\nlinks posted by Democrats stays remarkably stable ( 94:2\u00060:4in 2016-2018 and 94:9\u00060:1in 2020-2022). This\ndevelopment is not re\ufb02ected in the trustworthiness scores of links posted by conservative or far-right parties in other\ncountries. In Germany, the scores of links posted by the AfD and members of the CDU/CSU stays stable with an\naverage score of 83:4\u00061:0and 92:2\u00060:7in 2016-2018 and a score of 83:2\u00061:4and 91:6\u00060:9in 2020-2022,\nrespectively. Similarly, the scores of the Democratic Unionist Party and Conservatives in the British parliament stay\nstable or slightly improve, with 83:4\u00061:0and89:1\u00060:6in 2016-2018 and 85:6\u00065:4and88:2\u00060:3in 2020-2022,\nrespectively. These overall trends are also re\ufb02ected in the proportion of links to domains considered untrustworthy\n(score<60), shown in Fig. 1 G-I. The proportion of links to these domains posted by Republicans doubles, from\n2:4\u00060:2% in 2016-2018 to 5:5\u00060:6% in 2020-2022. The proportion of untrustworthy links posted by Democrats\nshows no change, from 0:4\u00060:3% in 2016-2018 to 0:4\u00060:1% in 2020-2022. For the German AfD, the proportion\ndecreases from 8:8\u00062:2% to 6:8\u00062:0%. The proportion of links to untrustworthy domains of all other parties in\nGermany and the United Kingdom is similar to the proportion posted by Democrats and does not change over time.\nAs a robustness check, we reproduced our main result (viz. the increase in the proportion of links to untrustworthy\ndomains by Republicans) using a second database of domain trustworthiness, compiled independently of NewsGuard\n(see Materials and Methods for details). The observed temporal trend of the proportion of links to untrustworthy\ndomains is displayed in the inset of Fig. 1 G, and shows a similar trend in the proportion of untrustworthy domains\nposted by Republicans (from 5:8\u00060:3% in 2016-2018 to 11:3\u00062:7% in 2020-2022), while the proportion of links to\nuntrustworthy domains posted by Democrats slightly decreases ( 1:0\u00060:9% and 0:4\u00060:1%).\nDiscussion\nSeveral recent analyses have shown that American conservatives are more likely to encounter and share untrustworthy\ninformation than their counterparts on the political left [ 10,12,11]. Although the reasons for this apparent asymmetry\nare still debated, one possible explanation appeals to partisan motivations. Evidence suggests that derogatory content\ntowards the political outgroup increases sharing intentions among partisans [ 22]. According to a recent study,\ngreater negativity towards Democrats is mostly found in lower-quality outlets, which may explain conservatives\u2019\nover-representation in sharing untrustworthy information [ 19]. Another possibility is that right-wing actors leverage\ncontroversial outlets in order to get more traction on social media, as has been evident in the US, UK, and Germany [ 13].\nHere we contribute to a potential explanation by showing that Republican members of Congress have become increas-\ningly likely to share untrustworthy information on Twitter. This pattern can contribute to the observed asymmetry\namong the public in at least two ways: \ufb01rst, by directly providing misinformation to Republican partisans and, second,\n2\nSocial media sharing by political elites: An asymmetric American exceptionalism PREPRINT\n101\n100101102proportion of links to\nuntrustworthy domains [%]\n0 0.2 0.8 1 ideology scorenone\n859095\nNewsGuard score\n2016 2017 2018 2019 2020 2021 20220510\nuntrustworthy\ndomains [%]\nRepublican Democrat\n101\n100101102proportion of links to\nuntrustworthy domains [%]\nLINKE Greens SPD FDP CDU/CSU AFDnone\n6080\nNewsGuard score\n2016 2017 2018 2019 2020 2021 202202040\nuntrustworthy\ndomains [%]\nThe Left Party\nAlliance 90/The Greens\nSPDFDP\nCDU/CSU\nAFD\n101\n100101102proportion of links to\nuntrustworthy domains [%]\nLabour SNP LibDem T ory DUPnone\n80100\nNewsGuard score\n2016 2017 2018 2019 2020 2021 20220510\nuntrustworthy\ndomains [%]\nLabour\nScottish National Party\nLiberal DemocratT ory\nDemocratic Unionist Party\n2016 2018 2020 202201020\nA\nB\nCD\nG\nE\nH\nF\nI\nFigure 1: Proportion of links to untrustworthy domains posted by Twitter accounts associated with Democratic and\nRepublican former (dots) and active (triangles) members of the U.S. Congress ( A), members of the German ( B) and\nBritish parliament ( C). Average NewsGuard score of links posted by members of the U.S. Congress ( D), members of\nthe German parliament ( E) and members of the British parliament ( F) between 2016 and 2022. Proportion of links\nto untrustworthy domains posted by members of the U.S. Congress ( G), members of the German parliament ( H) and\nmembers of the British parliament ( I) between 2016 and 2022. The inset in Gshows a reproduction of the result using\nan independently compiled list of untrustworthy domains (see materials and methods). Scores and proportions of\nuntrustworthy domains were averaged over monthly intervals with a rolling average of three months, and are broken\ndown by party, colour-coded by commonly used party colours. The 95% con\ufb01dence intervals were computed with\nbootstrap sampling over 1,000 iterations.\nby legitimizing the sharing of untrustworthy information more generally. Notably, this pattern is less pronounced in two\nmajor western democracies: although politicians from mainstream conservative parties in both Germany and the UK\ntend to share information that is of slightly lower quality than information shared by their counterparts on the left, the\ngap is not large and there is no evidence of it widening. We are thus experiencing a uniquely American dilemma.\n3\nSocial media sharing by political elites: An asymmetric American exceptionalism PREPRINT\nMethods\nTwitter corpus\nA corpus of tweets from former and present members of the U.S. Congress, the German parliament and the British\nparliament was collected by scraping all tweets from accounts associated with the respective politicians between January\n1, 2016 and March 16, 2022. Lists of Twitter handles of the 114thto 117thCongress were collected from a number of\nsources123. For the 114thand 115thCongress, only handles of senators were available. This resulted in a total of 1,143\nunique Twitter handles, which includes congressional staff and congress member campaigns. 108 accounts were not\naccessible because they had been deleted, suspended, or set to \u201cprivate\u201d. Lists of Twitter handles for members of the\nGerman and British parliament were collected from two online sources4and the Twitter Parliamentarian Database [ 24],\nresulting in a total of 823 and 727 unique Twitter handles, respectively. To build the text corpus, all tweets posted by the\ncollected Twitter accounts in the speci\ufb01ed time frame were obtained via the Twitter API. We chose January 1, 2016 as\nthe earliest date because before this date very few tweets by parliamentarians in Germany and the United Kingdom\nwere available. This resulted in a total of 1,696,626, 754,233 and 960,114 tweets for the US, Germany, and U.K.,\nrespectively. To determine the trustworthiness of information posted by the politicians, we extracted all URLs linking\nexternal sites contained in the tweets (shortened links such as bit.ly were expanded to determine the actual domain).\nNewsGuard scores\nFollowing the methods of prominent research concerned with the trustworthiness of information [ 10,20], we use source\ntrustworthiness as an estimator for the trustworthiness of an individual piece of shared information. Speci\ufb01cally, we\nclassi\ufb01ed the trustworthiness of links tweeted by politicians based on the trustworthiness of the domain rather than\nspeci\ufb01c items of content. We used nutrition scores provided by NewsGuard, a company that offers professional fact\nchecking as a service and curates a large data base of domains. The trustworthiness of a domain is assessed on a scale\nof 0 to 100 points, where domains with a score of 60 or higher are labelled as \u201cgenerally adhering to basic standards of\ncredibility and transparency\u201d [ 18]. Similar to [ 1], we use this value as a threshold below which we classify a domain as\n\u201cnot trustworthy\u201d.\nIndependent data base of domain trustworthiness\nTo validate our use of NewsGuard we compiled an independent data base of domain trustworthiness from a range of\nacademic and journalistic fact checking sites. Most of these sources were also used by [ 8]. The list includes Bufale [ 2],\nBufalopedia [ 3], Butac [ 4], Buzzfeed News [ 17], Columbia Journalism Review [ 23], Fake News Watch [ 25], Media\nBias Fact Check [ 6], Politifact [ 21], and Melissa Zimdars [ 26]. After merging these lists and removing duplicates, the\ncombined list contains 4767 domains. A total of 1677 of these domains are also contained in the NewsGuard data base,\nas of March 1, 2022.\nThe main challenge in combining lists from different fact checkers lies in unifying the labels the fact checkers assign\nto the domains. To address this, we devise a scheme where we rate each domain on two dimension that we consider\nto be important to assess reliability and trustworthiness of information: \"accuracy\" and \"transparency\". We devise\nan accuracy scale that varies from 1 (false information) to 5 (scienti\ufb01c) and a transparency scale that varies from 1\n(no transparency) to 3 (transparent). We provide a more detailed description of the \ufb01ve accuracy levels as well as\nmappings of the labels of individual fact checking sites to accuracy and transparency scores and the full list of domains\nathttps://doi.org/10.5281/zenodo.6536692 .\nAfter mapping all individual lists to the \"accuracy\" and \"transparency\" dimensions, we label every domain that has\nan accuracy score of 1 (False Information) or 2 (Clickbait) and/or a transparency score of 1 (No Transparency) as\n\"unreliable\". This results in a total of 2170 domains being labelled as \"unreliable\" and 2597 as \"reliable\". For the\n1677 domains that are contained in both data bases, the Krippendorff\u2019s \u000bbetween \"untrustworthy\" (score <60in\nNewsGuard) and \"unreliable\" in the independently compiled data base is 0.84, which shows a very high agreement\nbetween the two data bases. The independent list contains 4,767 unique domains, of which 2,170 are labelled as\n\u201cuntrustworthy\u201d. Less then half of the domains ( N= 1;677, of which 615 are untrustworthy) are also contained in the\nNewsGuard data base. We publish the independently compiled domain list for other researchers to use5.\n1https://www.socialseer.com/resources/us-senator-twitter-accounts/\n2https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/MBOJNS\n3https://triagecancer.org/congressional-social-media\n4https://twitter.com/i/lists/912241909002833921 |https://www.politics-social.com/list/followers\n5https://doi.org/10.5281/zenodo.6536692\n4\nSocial media sharing by political elites: An asymmetric American exceptionalism PREPRINT\nAcknowledgements\nJL acknowledges funding by the Marie Sk\u0142odowska-Curie grant No. 101026507. SL, AS, STA and DG received support\nfrom the European Research Council (ERC Advanced Grant 101020961 PRODEMINFO). SL and AS acknowledge\nsupport from the V olkswagen Foundation (grant \u201cReclaiming individual autonomy and democratic discourse online:\nHow to rebalance human and algorithmic decision making\u201d), and SL, DG, and FC also acknowledge funding from the\nJohn Templeton Foundation (through the Honesty program awarded to Wake Forest University). SL was also supported\nby the Humboldt Foundation through a research award.\nData Archival\nFull reproduction materials including data (tweet IDs, party labels, independently compiled list of domain labels) and\nanalysis code but excluding the NewsGuard data base which is proprietary are accessible at https://doi.org/10.\n17605/OSF.IO/MQHGP .\nReferences\n[1]S. Bhadani, S. Yamaya, A. Flammini, F. Menczer, G. L. Ciampaglia, and B. Nyhan. Political audience diversity\nand news reliability in algorithmic ranking. Nature Human Behaviour , pages 1\u201311, 2022.\n[2] Bufale. The black list. https://www.bufale.net/, 2022. Accessed: 2022-05-01.\n[3]Bufalopedia. Un catalogo di indagini e risorse antibufala. https://bufalopedia.blogspot.com/p/siti-creatori-di-\nbufale.html, 2020. Accessed: 2022-05-01.\n[4] Butac. The black list. https://www.butac.it/the-black-list/, 2022. Accessed: 2022-05-01.\n[5]J. T. Carmichael and R. J. Brulle. Elite cues, media coverage, and public concern: an integrated path analysis of\npublic opinion on climate change, 2001\u20132013. Environmental Politics , 26(2):232\u2013252, 2017.\n[6] M. B. F. Check. Media bias fact check. https://mediabiasfactcheck.com/, 2022. Accessed: 2022-05-01.\n[7]D. Chong and J. N. Druckman. A theory of framing and opinion formation in competitive elite environments.\nJournal of communication , 57(1):99\u2013118, 2007.\n[8]R. Gallotti, F. Valle, N. Castaldo, P. Sacco, and M. De Domenico. Assessing the risks of \u2018infodemics\u2019 in response\nto covid-19 epidemics. Nature Human Behaviour , 4(12):1285\u20131293, 2020.\n[9]GovTrack.us. Govtrack.us - tracking the united states congress. https://www.govtrack.us/ , 2022. Accessed:\n2022-04-20.\n[10] N. Grinberg, K. Joseph, L. Friedland, B. Swire-Thompson, and D. Lazer. Fake news on twitter during the 2016 us\npresidential election. Science , 363(6425):374\u2013378, 2019.\n[11] A. M. Guess, J. Nagler, and J. Tucker. Less than you think: Prevalence and predictors of fake news dissemination\non Facebook. Science Advances , 5:eaau4586, 2019. doi:10.1126/sciadv.aau4586.\n[12] A. M. Guess, B. Nyhan, and J. Rei\ufb02er. Exposure to untrustworthy websites in the 2016 U.S. election. Nature\nHuman Behavior , 4:472\u2013480, 2020. doi:10.1038/s41562-020-0833-x.\n[13] F. Husz\u00e1r, S. I. Ktena, C. O\u2019Brien, L. Belli, A. Schlaikjer, and M. Hardt. Algorithmic ampli\ufb01cation of politics on\ntwitter. Proceedings of the National Academy of Sciences , 119(1), 2022.\n[14] S. Lewandowsky, M. Jetter, and U. K. Ecker. Using the president\u2019s tweets to understand political diversion in the\nage of social media. Nature communications , 11(1):1\u201312, 2020.\n[15] E. Merkley and D. A. Stecula. Party elites or manufactured doubt? the informational context of climate change\npolarization. Science Communication , 40(2):258\u2013274, 2018.\n[16] M. Mosleh and D. Rand. Falsehood in, falsehood out: A tool for measuring exposure to elite misinformation on\ntwitter. PsyArXiv , 2021.\n[17] B. News. Inside the partisan \ufb01ght for your news feed. https://www.buzzfeednews.com/article/craigsilverman/\ninside-the-partisan-\ufb01ght-for-your-news-feed, 2017. Accessed: 2022-05-01.\n[18] I. NewsGuard. Rating process and criteria. Internet Archive, https://web.archive.org/web/\n20200630151704/https://www.newsguardtech.com/ratings/rating-process-criteria/ , 2020. Ac-\ncessed: 2022-04-20.\n5\nSocial media sharing by political elites: An asymmetric American exceptionalism PREPRINT\n[19] M. Osmundsen, A. Bor, P. B. Vahlstrup, A. Bechmann, and M. B. Petersen. Partisan polarization is the primary\npsychological motivation behind political fake news sharing on twitter. Am. Polit. Sci. Rev. , 115(3):999\u20131015,\nAug. 2021.\n[20] G. Pennycook, Z. Epstein, M. Mosleh, A. A. Arechar, D. Eckles, and D. G. Rand. Shifting attention to accuracy\ncan reduce misinformation online. Nature , 592(7855):590\u2013595, 2021.\n[21] Politifact. Politifact\u2019s guide to fake news websites and what they peddle.\nhttps://www.politifact.com/article/2017/apr/20/politifacts-guide-fake-news-websites-and-what-they/, 2017.\nAccessed: 2022-05-01.\n[22] S. Rathje, J. J. Van Bavel, and S. van der Linden. Out-group animosity drives engagement on social media. Proc.\nNatl. Acad. Sci. U. S. A. , 118(26), June 2021.\n[23] C. J. Review. CJR index of fake-news, clickbait, and hate. http://web.archive.org/web/20210720140548/https://www.\ncjr.org/fake-beta, 2021. Accessed: 2022-05-01.\n[24] L. van Vliet, P. T\u00f6rnberg, and J. Uitermark. The twitter parliamentarian database: Analyzing twitter politics across\n26 countries. PLoS one , 15(9):e0237073, 2020.\n[25] F. N. Watch. Fake news watch. https://web.archive.org/web/20180213181029/http://www.fakenewswatch.com/,\n2018. Accessed: 2022-05-01.\n[26] M. Zimdars. My \"fake news list\" went viral. but made-up stories are only part of the prob-\nlem. https://www.washingtonpost.com/posteverything/wp/2016/11/18/my-fake-news-list-went-viral-but-made-\nup-stories-are-only-part-of-the-problem/, 2016. Accessed: 2022-05-01.\n6", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Social media sharing by political elites: An asymmetric American exceptionalism", "author": ["J Lasser", "ST Aroyehun", "A Simchon", "F Carrella"], "pub_year": "2022", "venue": "arXiv preprint arXiv \u2026", "abstract": "Increased sharing of untrustworthy information on social media platforms is one of the main  challenges of our modern information society. Because information disseminated by political"}, "filled": false, "gsrank": 284, "pub_url": "https://arxiv.org/abs/2207.06313", "author_id": ["vVrhda0AAAAJ", "88FdOd0AAAAJ", "HTQXYFQAAAAJ", "c99Fq90AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:IltwgTkpMR8J:scholar.google.com/&output=cite&scirp=283&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=IltwgTkpMR8J&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 11, "citedby_url": "/scholar?cites=2247623015996087074&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:IltwgTkpMR8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2207.06313"}}, {"title": "Credible, unreliable or leaked?: Evidence verification for enhanced automated fact-checking", "year": "2024", "pdf_data": "CREDIBLE , UNRELIABLE OR LEAKED ?: E VIDENCE\nVERIFICATION FOR ENHANCED AUTOMATED FACT-CHECKING\nZacharias Chrysidis1, Stefanos-Iordanis Papadopoulos1, 2, Symeon Papadopoulos2, and Panagiotis C. Petrantonakis1\n1Department of Electrical & Computer Engineering, Aristotle University of Thessaloniki.\n2Information Technology Institute, Centre for Research & Technology, Hellas.\nzachoschrissidis@gmail.com , {stefpapad,papadop}@iti.gr, ppetrant@ece.auth.gr\nABSTRACT\nAutomated fact-checking (AFC) is garnering increasing attention by researchers aiming to help\nfact-checkers combat the increasing spread of misinformation online. While many existing AFC\nmethods incorporate external information from the Web to help examine the veracity of claims, they\noften overlook the importance of verifying the source and quality of collected \u201cevidence\u201d. One\noverlooked challenge involves the reliance on \u201cleaked evidence\u201d, information gathered directly from\nfact-checking websites and used to train AFC systems, resulting in an unrealistic setting for early mis-\ninformation detection. Similarly, the inclusion of information from unreliable sources can undermine\nthe effectiveness of AFC systems. To address these challenges, we present a comprehensive approach\nto evidence verification and filtering. We create the \u201cCREDible, Unreliable or LEaked\u201d (CRED-\nULE) dataset, which consists of 91,632 articles classified as Credible, Unreliable and Fact-checked\n(Leaked). Additionally, we introduce the EVidence VERification Network (EVVER-Net), trained on\nCREDULE to detect leaked and unreliable evidence in both short and long texts. EVVER-Net can\nbe used to filter evidence collected from the Web, thus enhancing the robustness of end-to-end AFC\nsystems. We experiment with various language models and show that EVVER-Net can demonstrate\nimpressive performance of up to 91.5% and 94.4% accuracy, while leveraging domain credibility\nscores along with short or long texts, respectively. Finally, we assess the evidence provided by\nwidely-used fact-checking datasets including LIAR-PLUS, MOCHEG, FACTIFY , NewsCLIPpings+\nand VERITE, some of which exhibit concerning rates of leaked and unreliable evidence.\nKeywords Deep Learning, Misinformation Detection, Automated Fact-Checking, Evidence Filtering, Information\nLeakage\n1 Introduction\nMisinformation has become an increasingly prevalent issue today, causing negative impacts to individuals and society\n[1]. With the rapid spread of online platforms and social media, fake or misleading information has become alarmingly\nwidespread, posing significant challenges to informed decision-making and societal trust [ 2]. In the battle against\nmisinformation, many fact-checking platforms such as Snopes1, PolitiFact2and Reuters3have emerged, where\njournalists manually review a plethora of claims sourced from news articles and social media. Nonetheless, manual\nfact-checking is time-consuming and can not always keep pace with the rate at which misinformation spreads. Recently,\nresearchers in natural language processing [ 3], computer vision [ 4] and multimodal learning [ 5] have begun exploring\nAutomated Fact-Checking (AFC). AFC involves tools and systems that help professional fact-checkers to combat\nmisinformation more efficiently by automating pivotal aspects of fact-checking including claim detection, evidence\nretrieval and claim verification [6].\n1Snopes: https://www.snopes.com/\n2Politifact: https://www.politifact.com/\n3Reuters: https://www.reuters.com/fact-check/arXiv:2404.18971v1  [cs.CL]  29 Apr 2024\nEvidence Verification Network\nFact Checking\nCredible Leaked UnreliableEvidence Retrieval\"President Obama banned\nimmigration fr om Iraq for  six\nmonths in 201 1.\"\nRetrieved Evidence:\n- \"Obama, Out of Of fice 10 Days, Speaks Out Against Immigration Ban\" \n(source: nytimes.com)\n- \"Obama Rejects T rump Immigration Orders, Backs Protests\"\n(source: nbcnews.com)- \"Did President Obama Ban Muslims from Entering the United States in\n2011?\" (source: snopes.com)\n- \"MORE HYPOCRISY : Obama Banned all Iraqi Refugees for 6 Months in 201 1 \u2013\nLiberals SAID NOTHING (source: thegatewaypundit.com)Claim under  Verification\nVerdict: False\nShort Texts\n(DeBER Ta)Full Articles\n(Longformer)\n\u00a9 ShutterstockFigure 1: Pipeline of automated fact-checking leveraging the proposed Evidence Verification Network.\nTo further improve AFC, some systems leverage external evidence extracted from the Web using search engines. By\ntapping the potential of the entire Web as a knowledge source to help support or refute a claim, these models enhance\ntheir ability to verify news pieces more accurately. However, a prevalent issue in external knowledge retrieval from\nthe Web is the lack of evidence filtering mechanisms. Inadequate or rudimentary filtering results in the inclusion of\nirrelevant or unreliable information, potentially compromising the accuracy of fact-checking systems. Furthermore,\nGlockner et al. [ 7] define \u201ctwo requirements that the evidence in datasets must fulfill for realistic fact-checking: It must\nbe (1) sufficient to refute the claim and (2) not leaked from existing fact-checking articles\u201d . Otherwise the AFC model\nwould learn to rely on previously fact-checked information when trying to detect new emerging misinformation, where\nfact-checks are not yet available. The problem of \u201cleaked evidence\u201d is quite under-researched yet crucial for realistic\nand effective fact-checking.\nMotivated by these observations, we propose a new evidence verification and filtering approach to address the issue\nof leaked and unreliable evidence in AFC. Firstly, we construct the \u201cCREDible, Unreliable or LEaked\u201d (CREDULE)\ndataset, by modifying, merging, and extending MultiFC [ 8], Politifact [ 9], PUBHEALTH [ 10], NELA-GT [ 11,12,13,\n14,15,16], Fake News Corpus [ 17], and Getting Real About Fake News [ 18]. These established datasets contain short\ntexts (titles) as well as the long texts (full articles) of the news articles. We extract the article bodies, where they are not\ngiven, and other meta-data to better balance the classes. The final CREDULE dataset consists of 91,632 pieces, equally\ndistributed in three classes: \u201cCredible\u201d, \u201cUnreliable\u201d and \u201cFact-checked\u201d (or Leaked).\nThe goal is to develop a model capable of detecting the information that a model retrieves from the Web so as to avoid\nleakage and unreliable sources, as seen in Figure 1. To this end, we also propose EVVER-Net a neural network that\ndetects leaked (fact-checked) and unreliable evidence pieces during the evidence retrieval process and only allows\ncredible information to pass to the AFC model. We experiment with various pre-trained Transformer-based encoders\nfor both short texts, such as DeBERTa [ 19], CLIP [ 20], T5 [ 21], and long texts, Long T5 [ 22] and Longformer [ 23], as\nwell as baseline methods like Count Vectorizer and TF-IDF. Additionally, we integrate domain credibility scores from\nthe Media Bias/Fact Check (MBFC) website4to enhance classification accuracy.\nTo show the efficacy and usefulness of the classifier, we examine the collected evidence in widely used AFC datasets\nsuch as the LIAR-PLUS [ 24], FACTIFY [ 25], MOCHEG [ 26], VERITE [ 27] datasets and the evidence collected by\nAbdelnabi et al. [ 28] for the NewsCLIPpings dataset; referred to as NewsCLIPpings+ for simplicity. Our analysis\nshows that the collected evidence often contain information leaked from fact-checking articles or provide unreliable\ninformation.\nThe contributions of our work can be summarized as follows:\n4https://mediabiasfactcheck.com/\n2\n\u2022We propose a novel approach to detecting and filtering out leaked evidence and unreliable information in AFC\nsystems.\n\u2022We construct CREDULE, a large-scale, balanced and diverse dataset comprising \u201cCredible\u201d, \u201cUnreliable\u201d and\n\u201cFact-checked\u201d news articles5.\n\u2022We introduce EVVER-Net which demonstrates impressive performance of up to 91.5% and 94.4% accuracy\non CREDULE while leveraging domain credibility scores along with short or long texts, respectively.\n\u2022We use EVVER-Net to examine the evidence of widely used fact-checking datasets, where we identify\nconcerning rates of leaked and unreliable evidence.\n2 Related Work\n2.1 Fact-checking Datasets\nA plethora of datasets have been curated to facilitate fact-checking tasks and train robust misinformation detection\nmodels. One widely used text-based dataset is FEVER [ 29]. It consists of 185,445 pieces generated by human annotators\nextracting claims from Wikipedia and mutating them in various ways, some of which alter their meaning. Many datasets\nalso contain claims extracted from fact-checking websites. For instance, Alhindi et al. [ 24] created the LIAR-PLUS\ndataset, comprising 12,836 statements taken from Politifact and labeled by humans for truthfulness. The authors also\nautomatically extracted justifications provided in the associated fact-checking articles. Others include FakeNewsNet\n[30], MultiFC [ 8], Politifact Fact Check [ 9] or WatClaimCheck [ 31] and some specialize in various domains such as\npolitics (ClaimBuster [ 32] or Truth of Varying Shades [ 33]) or health (PUBHEALTH [ 10]). Additionally, researchers\nhave created datasets containing both credible and fake news pieces. For example, the NELA-GT Datasets (2017-\n2022) [ 11,12,13,14,15,16] are large corpora containing articles from both credible and non-credible news outlets.\nFakeNewsCorpus [ 17] contains both credible and fake news scraped from a curated list of 1001 non-credible domains.\nConversely, the Getting Real about Fake News Dataset [ 18] extracted articles from 244 websites tagged as \u201cbullshit\u201d by\nthe BS Detector Chrome Extension.\nMultimodal datasets play a vital role in AFC by incorporating diverse types of information. They offer a more\ncomprehensive representation of real-world claims, enabling fact-checking models to consider a broader range of\nevidence sources. MOCHEG [ 26] is a dataset consisting of 21,184 textual claims from Politifact and Snopes that\nalso provides image and textual evidence collected from fact-checking articles. Focusing on social media content,\nBoididou et al. [ 34] built a dataset for the MediaEval 2016 Verifying Multimedia Use (VMU) challenge that comprises\ntweets and images. Another notable multimodal dataset is FACTIFY [ 25], containing 50,000 claims accompanied by\n100,000 images. Collected from reliable US and Indian sources, as well as reputable fact-check websites, FACTIFY\nprovides a diverse range of real-world data for fact-checking purposes. Researchers have also been experimenting\nwith synthetically created multimodal misinformation. Aneja et al. [ 35] curated COSMOS, a dataset comprising 200K\nimages with 450K textual captions from various news websites (credible and fact-check), blogs, and social media posts\nand randomly sampled negative \u201cde-contextualized\u201d samples. Similarly, the NewsCLIPpings dataset [ 36] comprises\nboth pristine and convincing falsified (\u2018out-of-context\u2019) image-caption pairs, providing examples of how misinformation\ncan be spread through visual content. But instead of relying on \u201cnaive\u201d random negative samples, the authors leverage\nCLIP [ 20] as well as Person and Scene Matching models to create \u201chard\u201d negative samples. Built on the VisualNews\ncorpus [ 37], NewsCLIPpings contains examples that misrepresent the context, place, or people in the image. Finally,\nthe VERITE dataset was recently developed as an evaluation benchmark for multimodal misinformation detection and\naccounts for unimodal biases [27].\n2.2 Evidence Collection\nIn the pursuit of enhancing the effectiveness of AFC, researchers have recognized the value of gathering and utilizing\nexternal information from the Web. Models often leverage popular search engines to access a vast repository of\ninformation that can supplement existing datasets. Popat et al. [ 38] utilized claims from Snopes and information about\nhoaxes and fictitious persons from Wikipedia to conduct their experiments, employing these claims and hoaxes as\nqueries to the Google search engine. In subsequent work, the authors attempted to rank results based on the credibility\nof their sources [ 39]. Samarinas et al. [ 40] extended the FEVER dataset [ 29] to create the Factual-NLI+ dataset,\nincorporating synthetic examples and noise passages from web search results. Retrieving the top 30 results from the\nBing Search engine for each claim in the FEVER dataset, they retained results with the highest BM25 score. Similarly,\nAbdelnabi et al. [ 28] collected external information from the Web to verify image-caption claims in the NewsCLIPpings\n5We release our code at: https://github.com/mever-team/credule-dataset\n3\n[36] dataset. Employing an inverse search mode via the Google Vision APIs, they retrieved textual evidence such as\ntext snippets and image captions and then utilized the caption as textual queries to search for images using the Google\nCustom Search API. More recently, a similar approach was adopted to augment the VERITE evaluation benchmark\n[27] with external information from the Web [41].\n2.3 Addressing Leaked Evidence\nWhile leveraging external evidence from the Web holds promise for enhancing the accuracy of AFC systems, it also\npresents challenges, particularly concerning the presence of leaked evidence. The criteria outlined by [ 7] stress the\nimportance of ensuring that evidence used is not leaked from existing fact-checking articles. However, relying on\nsearch engines to retrieve external evidence often results in leaked information being included unintentionally. Even\nafter excluding search results that point to the claim\u2019s fact-checking article, leaked evidence persists. This can occur\nwhen different organizations verify the same claims or disseminate fact-checkers\u2019 verifications. Khan et al. [ 31] also\nhighlight this issue, noting that \u2018premise\u2019 articles may indirectly leak the veracity label. Glockner et al. [ 7] express\ndoubts on whether automated approaches can realistically refute harmful real-world misinformation as many of existing\napproaches fail to overcome the information leakage problem. This underscores the need for robust mechanisms to\nfilter out leaked evidence and maintain the credibility of AFC processes.\n2.4 Evidence Filtering\nFiltering and verifying external evidence pose significant challenges for AFC systems. Many existing models lack\nrobust filtering mechanisms or rely on rudimentary approaches, potentially resulting in the inclusion of irrelevant,\nuntrustworthy, or leaked evidence. Addressing this challenge requires the development of advanced filtering techniques\ncapable of discerning reliable sources and accurate information. For example, Abdelnabi et al. [ 28] implemented a\nfiltering method that discards evidence items matching the query and originating from the same website, utilizing\ntechniques such as removing punctuation and converting captions to lowercase for textual evidence and employing\nperceptual hashing for images. Karadzhov et al. [ 42], focusing on the trustworthiness of the source, disregarded\nevidence from domains considered unreliable based on manual checks of the most frequent domains in search results.\nHowever, this approach may not effectively identify unreliable sources that appear less frequently. Popat et al. [ 38]\nadopted an approach to assess the reliability of Web sources by determining the AlexaRank and PageRank of each\nsource. AlexaRank measures website popularity based on its unique visitors and page views, while PageRank assesses\nwebsite importance by considering the number and quality of links to and from the website. While such approaches\nprovide valuable insights into the authority and popularity of Web sources, they may not accurately reflect their\ncredibility from a fact-checking standpoint. In their recent study, Schlichtkrull et al. [ 43], employed a custom Google\nsearch tool to mitigate temporal leaks, ensuring that only documents published before the claim date were retrieved.\nHowever, this approach can introduce noise, as the dates provided by Google Search are not consistently accurate.\n3 METHODOLOGY\n3.1 Problem Formulation\nThe AFC process typically unfolds through three sequential stages: claim detection, evidence retrieval, and claim\nverification, as outlined by Guo et al. [ 6]. However, a fundamental challenge arises in the evidence retrieval stage,\nas not all available information can be considered trustworthy. Guo et al. [ 6] underscore this issue, highlighting that\nreliance on single authoritative sources may overlook contradicting or untrustworthy evidence. Additionally, Glockner\net al. [ 7] emphasize the problem of information leakage, where existing AFC models incorporate leaked evidence,\ncompromising the integrity and realism of the fact-checking process.\nIn response to these challenges, we construct CREDULE, a large scale dataset containing news articles from various\nsources. These articles are classified in three classes: \u201cCredible\u201d, \u201cUnreliable\u201d and \u201cFact-checked\u201d. We also create the\nEVidence VERification Network (EVVER-Net) and train it on CREDULE, with the aim to detect leaked and unreliable\nevidence and only allow credible information to be examined by an AFC system. Specifically, the EVVER-Net G(\u00b7)\naims to classify each textual evidence snippet eias fact-checked(0), credible(1), or unreliable(2), denoted by G(ei).\nLetCdenote the claim under scrutiny, ET={e1, e2, . . . , e N}represents the set of Ntextual evidence pieces and EI\nsymbolizes the collection of image evidence related to C. After applying the classifier G(\u00b7), we obtain the filtered set\nof textual evidence pieces E\u2032\nT, denoted as:\nE\u2032\nT={ei| \u2200ei\u2208ET,G(ei) = 1} (1)\n4\n/uni00000015/uni00000013/uni00000014/uni00000019 /uni00000015/uni00000013/uni00000014/uni0000001a /uni00000015/uni00000013/uni00000014/uni0000001b /uni00000015/uni00000013/uni00000014/uni0000001c /uni00000015/uni00000013/uni00000015/uni00000013 /uni00000015/uni00000013/uni00000015/uni00000014 /uni00000015/uni00000013/uni00000015/uni00000015\n/uni0000003c/uni00000048/uni00000044/uni00000055/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000003/uni00000052/uni00000049/uni00000003/uni00000024/uni00000055/uni00000057/uni0000004c/uni00000046/uni0000004f/uni00000048/uni00000056/uni00000026/uni0000004f/uni00000044/uni00000056/uni00000056\n/uni00000029/uni00000044/uni00000046/uni00000057/uni00000010/uni00000026/uni0000004b/uni00000048/uni00000046/uni0000004e/uni00000048/uni00000047\n/uni00000026/uni00000055/uni00000048/uni00000047/uni0000004c/uni00000045/uni0000004f/uni00000048\n/uni00000038/uni00000051/uni00000055/uni00000048/uni0000004f/uni0000004c/uni00000044/uni00000045/uni0000004f/uni00000048Figure 2: Number of articles per year in CREDULE.\nSubsequently, the veracity prediction mechanism F(\u00b7)can be applied to the claim Cwith the filtered text evidence E\u2032\nT\nand the image evidence EI:\ny=F(C, E\u2032\nT, EI) (2)\nwhere yrepresents the predicted veracity label. G(\u00b7)serves as a critical component in mitigating the impact of\ntrustworthiness issues and information leakage in AFC systems.\n3.2 Constructing the CREDULE dataset\nCREDULE comprises three distinct classes: Fact-Checked, Credible, and Unreliable, tailored for the classification of\nnews articles to facilitate evidence filtering during the fact-checking process. Ensuring a balanced representation, each\nclass encompasses a similar number of articles, consistent distributions in publication year, title length, and thematic\ncontent. Maintaining an even distribution of articles across years ensures comprehensive coverage of events over time.\nEntries in our dataset are presented in both article title and full-text formats whenever available.\nTo construct CREDULE, we merge information from six distinct sources: MultiFC [ 8], Politifact Fact-Check [ 9],\nPUBHEALTH [ 10], NELA-GT [ 11,12,13,14,15,16], Fake News Corpus [ 17], and Getting Real About Fake News\n[18] datasets. These diverse datasets provide a rich and comprehensive foundation for our dataset creation process.\n3.2.1 Fact-checked class\nIn order to construct the fact-checked class, we leverage the following dataset: 1) MultiFC: encompassing 36,534\nclaims sourced from 24 Fact-checked domains, spanning until 2019. Each claim is accompanied by its respective\nveracity label, publication date, article title, URL, and additional metadata. 2) PUBHEALTH: comprising 11,832\nclaims within the health domain, sourced from various fact-checking websites, this dataset offers valuable insights.\nAlongside each claim, the dataset provides the article\u2019s URL, publication date, and the main text body. 3) Politifact: We\nincorporate 21,152 statements from Politifact, spanning the years 2008 to 2022, sourced from the Politifact Fact Check\ndataset on Kaggle. Each entry includes URLs, truthfulness labels, and additional metadata. To ensure data consistency,\nwe extract article titles from the URLs, omitting the term \u201cPolitifact\u201d to mitigate biases.\nFrom our collection of fact-checking articles, we retain only those published between 2016 and 2022. We also filter out\nduplicate and empty entries, resulting in 30,209 articles. Additionally, we employ a pre-trained DistilBert model, trained\non the News Category Dataset6, to extract article topics based on their titles. This process yields a comprehensive\nset of 42 categories, which we further consolidate into 12 distinct groups for clarity. Furthermore, we extract the full\ntext-body of articles where unavailable. First, we utilize the Beautiful Soup package to obtain the full article texts from\nthe Politifact Fact Check dataset. Similarly, we develop domain-specific scripts to extract articles from the MultiFC\ndataset, excluding those already present in the Politifact dataset. The PUBHEALTH dataset provides full-text articles,\nobviating the need for extraction.\n6HuggingFace Model: https://huggingface.co/Yueh-Huan/news-category-classification-distilbert\n5\nTable 1: CREDULE dataset statistics, constructed by combining and filtering various datasets.\nDataset Class Used Entries Full-Texts\nMultiFC Fact-checked 16,057 70.5%\nPUBHEALTH Fact-checked 3,683 All\nPolitifact Fact-checked 10,469 99.7%\nFake News Corpus Credible 22,245 91.4%\nNELA-GT Credible+Unreliable 31,636 All\nGRAFN Unreliable 7,542 All\n3.2.2 Credible and Unreliable Classes\nTo construct the Credible and Unreliable classes, we leverage the following datasets: 1) Fake News Corpus: It\ncomprises millions of news articles, including both credible and non-credible sources. We specifically utilize the\ncredible subset, extracted from reputable news outlets. To ensure data integrity, we extract article titles and dates\ndirectly from URLs, addressing issues with inaccuracies and duplicates. Additionally, we remove domain names\nfrom titles and employ the topic-extraction model to categorize the articles. 2) NELA-GT Datasets: Spanning from\n2017 to 2022, these contain articles sourced from various domains, classified based on their credibility and bias. We\nextract pertinent information such as article titles, dates, domains, and topics using the topic-extraction model. These\ndatasets are instrumental in constructing both the credible and non-credible classes. 3) Getting Real about Fake News\nDataset: The Getting Real about Fake News dataset (GRAFN), sourced from Kaggle, features non-credible articles\nfrom 2016, scraped from 244 websites labeled as \u201cbullshit\u201d by the BS Detector Chrome Extension. We filter the dataset\nto include only English articles categorized as \u2018bs\u2019 (bullshit), \u2018conspiracy\u2019, \u2018satire\u2019, \u2018junksci\u2019, and \u2018fake\u2019. Obtaining\narticle metadata, including titles, dates, domains, and main text bodies, enables us to further categorize articles based on\ntheir topics.\nTo ensure class balance across different years (2016-2022) and topics, we supplement articles from the Fake News\nCorpus and, if necessary, the NELA-GT datasets for the Credible class. We ensure an equal distribution of articles\nacross various topics to align with the Fact-checked class, extracting the same number of articles per topic. Furthermore,\nfor the Unreliable class, we incorporate articles from both NELA-GT and Getting Real About Fake News datasets.\nThe distribution of articles across different years and classes, can be seen in Figure 2. CREDULE is balanced across\nclasses in terms of articles per year and in terms of the length of titles within each class. We make use of the full text\narticles provided by NELA-GT and Getting Real About Fake News datasets. For the Fake News Corpus, we utilize the\nBeautiful Soup library and develop custom scripts to extract the content of full articles.\n3.2.3 Domain Credibility Scores (DCS)\nWe augment CREDULE by integrating external domain credibility scores (DCS) from the Media Bias/Fact Check\n(MBFC) website. MBFC is an independent platform dedicated to combating media bias and misinformation and\nemploys a rigorous evaluation combining objective metrics and subjective analysis to rate media sources based on\nfactors such as bias, factual accuracy, and overall credibility. Bias assessments range from least biased to extreme bias\non a scale of 0 to 10, while factuality scores vary from very high to very low based on fact-checking frequency and\ninclusion of critical information. Categorized into three tiers\u2014high, medium, and low credibility\u2014the final MBFC\nrating identifies highly credible sources with a score of 6 or above, medium credibility for scores ranging from 3 to\n5, and low credibility for scores of 0 to 2 or sources rated as questionable, conspiracy, or pseudoscience. For each\ndomain in CREDULE, we obtain DCS including \u2018Bias Rating\u2019, \u2018Factual Reporting\u2019 and \u2018MBFC Credibility Rating\u2019.\nThis process involves querying the MBFC website for each domain, accessing the corresponding page, and extracting\nthe relevant scores. We are able to extract domain credibility scores for 92.2% of the articles in CREDULE.\n3.2.4 CREDULE Final Statistics\nThe CREDULE comprises a total of 91,632 articles, spanning the years 2016 to 2022 and classified into three distinct\ncategories: Fact-checked (30,209), Credible (31,230), and Unreliable (30,193). Each article entry includes its title,\npublication date, URL, assigned topic, and classification label. Moreover, 92.7% of the articles in the dataset are\naccompanied by their full-text content. Notably, the dataset exhibits balanced distribution across all classes in terms of\narticles per year, topics, and title lengths. The statistics of the dataset are summarized in Table 1.\n6\n3.3 Evidence Verification Network\nAfter constructing CREDULE, we develop an EVidence VERification Network (EVVER-Net) which can be used to\ndiscern between credible, unreliable and leaked evidence. EVVER-Net is a neural network classifier, which can be\nexpressed as follows:\n\u02c6yi=Softmax (W1\u00b7GELU (W0\u00b7[T(ei)[< EOS > ];si]))) (3)\nwhere T(\u00b7)stands for a Transformer backbone encoder, [< EOS > ]for the position of the end-of-sentence (EOS)\nor classification token (CLS), depending on the encoder, of T(\u00b7),si\u2208R1is the \u201cdomain credibility score\u201d of ei,[; ]\nstands for concatenation, W0\u2208R1\u00d7h+1is a GELU activated fully connected layer with hhidden dimensions and\nW1\u2208Rh+1\u00d73is the final classification layer activated with Softmax for 3 classes. Equation 3 represents the case\nwhere the network only has a single hidden layer l.\nWe develop three different versions of EVVER-Net. The first handles short texts (title articles), the second long texts\n(full articles), and the third also leverages domain credibility scores.\nFor \u201cshort text\u201d experiments, we explore pre-trained Transformer-based language models such as T5 [ 21], DeBERTa\n[19] and CLIP [ 20]. For our experiments on full article texts, we employ transformer-based models tailored for\nprocessing larger text sequences. More specifically, we utilize Longformer [ 23], a model that integrates both local\n(window-based) and global attention mechanisms. For feature extraction, we utilize the [CLS] token to capture\ncontextual information and train our classifier. Finally, we similarly employ LongT5 [ 22], an extension of the T5 model,\nsuitable for long texts.\nIn order to incorporate DCS into EVVER-Net, we encode Factuality Scores categories \u2018satire\u2019(-3), \u2018very low\u2019(-2),\n\u2018low\u2019(-1), \u2018mostly factual\u2019(2), \u2018high\u2019(3) and \u2018very high\u2019(4). Articles without factuality scores are assigned a value of 0.\nFor articles with a \u2018mixed\u2019 score, we consider the MBFC Credibility Rating. If it indicates \u2018medium credibility\u2019, \u2018mixed\u2019\nis mapped to 1. Conversely, if it is \u2018high credibility\u2019 or \u2018low credibility\u2019, \u2018mixed\u2019 is mapped to 2 or -1, respectively.\nThis differentiation ensures that we account for each case of \u2018mixed\u2019 credibility and the absence of data. Finally, we\nnormalize DCS into a range of (0,1), concatenate them with the text embeddings and pass the combined input through\nEVVER-Net.\n3.4 Implementation Details\nWe implement EVVER-Net using the PyTorch deep learning framework, leveraging its efficiency for training neural\nnetworks. To ensure reproducibility, we set the random seed to 42 before conducting any experiments. The dataset is\ndivided into three subsets using an 80/10/10 training/validation/test split.\nFor both short- and long-text models, we utilize 3-fold Cross Validation and Grid Search, respectively to optimize and\nfine-tune EVVER-Net. In both cases, we explore various configurations including hidden sizes h\u2208 {512,1024}and\nnumber of layers l\u2208 {1,2,3}. We employ the Adam optimizer with learning rates lr\u2208 {1e\u22123,5e\u22124,1e\u22124,5e\u22125}\nand batch sizes b\u2208 {512,1024,2048}. Additionally, we experiment with dropout rates d\u2208 {0.1,0.2,0.25}and L2\nregularization r\u2208 {0,1e\u22122,1e\u22123}to prevent overfitting and improve generalization.\nFinally, we experiment with baseline models, namely Logistic Regression, Naive Bayes, Decision Trees and Multi-\nlayer Perceptron (MLP) trained only on domain credibility scores or on statistical feature extraction methods like\nCountVectorizer and TF-IDF.\n4 Results\n4.1 Quantitative Results\nTable 2 demonstrates the results of the baseline classifiers. We observe that Count Vectorizer achieves 66.3% accuracy\nwith Logistic Regression and 69.4% with the MLP Classifier while TF-IDF yields 67.0% accuracy with Naive Bayes\nand 69.5% with an MLP classifier. When only leveraging DCS, a Decision Tree classifier reaches 68.5% accuracy,\nclosely competing with text-based models.\nTable 3 illustrates the performance of EVVER-Net while leveraging different transformer-based encoders. We observe\nthat with short texts (titles) and without DCS, EVVER-Net reaches the best performance of 79.5% accuracy while\nemploying embeddings from DeBERTa7and having hidden dimensions h= [512 ,1024,1024] , learning rate lr=\n5e\u22125, dropout d= 0.1, l2 regulation of r= 1e\u22123and batch size b= 1024 . This performance is followed by\n7https://huggingface.co/microsoft/deberta-base\n7\nTable 2: Baseline Experiments on CREDULE.\nInput Classifier Accuracy\nCount Vectorizer Logistic Regression 66.3%\nCount Vectorizer MLP Classifier 69.4%\nTF-IDF Naive Bayes 67.0%\nTF-IDF MLP Classifier 69.5%\nDomain Scores Only Decision Trees 68.5%\nTable 3: Performance of EVVER-Net on CREDULE for short or long texts, with different backbone encoder and with\nor without Domain Credibility Scores (DCS).\nEncoder Accuracy w/o DCS Accuracy w/ DCS Input\nT5 78.3% 88.6% short texts\nClip Text 79.3% 91.0% short texts\nDeBERTa 79.5% 91.5% short texts\nLong T5 79.1% 89.5% long texts\nLongformer 89.0% 94.4% long texts\nintegrating CLIP\u2019s text encoder8reaching 79.3% accuracy and then T59reaching 78.3% accuracy. When employing\nlong texts (full articles), EVVER-Net with Longformer10as the backbone encoder, achieves 89% accuracy with\nh= [1024 ,1024,1024] ,lr= 5e\u22124,d= 0.2,r= 1e\u22123andb= 2048 .\nFurthermore, incorporating DCS from MBFC, can significantly and consistently enhance the classification accuracy of\nEVVER-Net across all 5 Transformer encoders. For short texts, the accuracy of EVVER-Net with DeBERTa increases\nto 91.5%, reflecting a notable relative improvement of +12% while for long texts, Longformer facilitates a substantial\nboost, reaching 94.4%, a +5.4% relative improvement. Overall, these results demonstrate notable improvements in\nclassification accuracy across all backbone model encoder, highlighting the effectiveness of incorporating domain-\nspecific characteristics into EVVER-Net.\n4.2 Qualitative Analysis and Inference\nIn this section, we apply EVVER-Net to existing datasets, encompassing various text, multimodal, and Web-sourced\ndatasets. We do not use DCS in this section because the domain names from which the evidence was collected are not\nprovided by these datasets. By examining the classifier\u2019s performance across diverse datasets, we aim to assess its\nrobustness and applicability in different contexts. Specifically, we focus on datasets containing fact-checked articles,\nas well as those incorporating external evidence from various sources on the Web. Our evaluation begins with testing\non text datasets, where the classifier\u2019s ability to discern credible information from unreliable is put to the test. We\nthen extend our analysis to multimodal datasets and finally, we explore datasets that aggregate evidence from the Web,\nmirroring the real-world application scenario of EVVER-Net. Results are summarized in Table 4\n8https://huggingface.co/openai/clip-vit-base-patch32\n9https://huggingface.co/google-t5/t5-large\n10https://huggingface.co/allenai/longformer-base-4096\nTable 4: Inference Results: Applying EVVER-Net on evidence from various datasets.\nDataset Data Type Fact-checked Credible Unreliable Samples\nLIAR-PLUS Ruling statements of fact-checked articles 98.5% 1.0% 0.5% 10,238\nMOCHEG Evidence snippets from fact-checked articles 83.6% 2.4% 14.0% 27,528\nFACTIFY Article from \u201cSupport\u201d & \u201cInsufficient\u201d classes 6.4% 88.0% 5.6% 34,000\nFACTIFY Articles from \u201cRefute\u201d class 95.0% 3.5% 1.5% 8,500\nNewsCLIPpings+ Article titles (Web) 14.1% 64.5% 21.4% 45,907\nVERITE Article titles (Web) - across 3 classes 35.3% 42.6% 22.1% 1,611\nVERITE Article titles (Web) - \u2018True\u2019 and \u2018Miscaptioned\u2019 classes 45.2% 35.2% 19.6% 1,094\nVERITE Article titles (Web) - \u2018Out-of-Context\u2019 class 14.5% 58.2% 27.3% 517\n8\n\"Food company Fr eeza Meats fined \u00a370,000 costs\"\n(sour ce: BBC News)NewsCLIPpings+ \"We did not assign cr edit to Kasich for his statement in Mar ch that\nOhioans' wages have risen by mor e than $10 billion since 2010. But\nwe rated the statement as T rue. [...]\" \n(sour ce: Politifact)LIAR-PLUS\n\"If a political party does not have its foundation in the\ndetermination to advance a cause that is right and that is moral,\nthen it is not a political party; it is mer ely a conspiracy to seize\npower .\" (sour ce: Snopes)MOCHEG \n\"Pope Francis wraps up Brazil trip with Mass for 3 million\"\n(sour ce: CBS News)\nVERITE\"Does This NASA  Photo Show a 'Portal' and 'W all' on\nMars?\"  (sour ce: Snopes)\n\"Time T raveling to Pompeii : r/T ikTokCringe\"\n(sour ce: Reddit )CLAIM EVIDENCE EVVER-Net\nCredibleFact-Checked\nFact-Checked\nUnreliableCredible\nFact-Checked\n\"California Sen. Kamala Harris announced Monday that she will run for\npresident in 2020, joining an incr easingly cr owded field of Democrats\nseeking to challenge Pr esident Donald T rump. [...] Booker and Sanders\nwill also speak at a rally at South Car olina's state house, and Castr o, the\nformer mayor of San Antonio, is mar ching in the city's Martin Luther\nKing Jr . Day parade. \" (sour ce: ABC News)\n\"A satir e article claiming that Micr osoft has bought Sony for $130 billion\nhas gone viral with some media outlets r eporting it as true.  BOOM found\nthe original article in a Spanish website was intended to be a prank. [...]\nFurthermor e, considering Micr osoft and Sony ar e two of the biggest\nbrands in the world, any news of one acquiring the other would make\nheadlines.  However , we found no news r eports on Micr osoft buying\nSony .\" (sour ce: BOOM Live)FACTIFY  - \"Support\"\nFACTIFY - \"Refute\"Credible\nFact-Checked\"Just about everyone everywher e is spending mor e hours on the job,\nless time with their families, bringing home smaller and smaller\npaychecks, while they'r e paying mor e and mor e at the gas pump and\nthe gr ocery stor es\" Verdict: \"Mostly T rue\"\n\"President Eisenhower said that a political party must be dedicated to\nthe advancement of a moral cause, otherwise it is just a conspiracy to\nseize power .\" Verdict: \"Correct Attribution\"\n\"Freeza Meats of Newry said it had been asked by an Irish company\nto stor e the meat after they had declined to buy it\"\nVerdict: \"Pristine\"\n\"An image shows a lar ge cr owd gather ed on the Rio de Janeir o\nseafr ont to celebrate a Mass deliver ed by Pope Francis in\n2013.\" Verdict: \"T ruthful\"\n\"A photograph captur ed by NASA \u2019s Mars Curiosity Rover on May 7,\n2022, showed an artificial portal nearby .\" \nVerdict: \"Out-Of-Context\"\n\"A photograph shows plaster cast of a victim in Pompeii during the\nvolcanic eruption in 79 A.D.\" Verdict: \"T ruthful\"\n\"Now that Sen. Kamala Harris is in, her e are the\nDemocrats who've said they'r e running for pr esident .\" \nVerdict: Support-T ext\n\"Micr osoft bought Sony for $121 billion. \"\nVerdict: RefuteDA T ASETFigure 3: Inference examples from EVVER-Net applied on the evidence of various datasets. We manually included the\ndomain names from which the evidence originates, as they are not provided by the datasets.\n4.2.1 LIAR-PLUS Dataset\nWe initiate our evaluation with the LIAR-PLUS dataset [ 24], a well-known repository of fact-checked articles. LIAR-\nPLUS provides not only labeled articles but also detailed justifications for the veracity of each claim, which are\nsentences extracted from the section \u2018Our Ruling\u2019 of each fact-checked article. Therefore, we would expect high rates\nof \u201cfact-checked\u201d class. Indeed, when we extract features with DeBERTa and apply EVVER-Net on the \u201cjustification\nevidence\u201d, it successfully recognizes fact-checked evidence pieces, with 98.5% being classified as Fact-checked, 1% as\ncredible, and 0.5% as Unreliable. These findings underscore EVVER-Net ability to discern information from fact-check\nwebsites, affirming its utility in real-world fact-checking applications.\n4.2.2 MOCHEG Dataset\nWe further extend our evaluation by applying EVVER-Net to the MOCHEG dataset [ 26], which aggregates data from\nPolitifact and Snopes websites. Specifically, we focus on the \u2018evidence\u2019 column of Corpus 2, comprising highlighted\ntext snippets from fact-checked articles. Again, we observe consistent performance, with rate of 83.6% of evidence\npieces being classified as fact-checks.\n4.2.3 FACTIFY Dataset\nThe next dataset we evaluate is the FACTIFY dataset [ 25]. This comprises textual and image claims, each associated\nwith a reliable source of information referred to as a \u2018document\u2019. Claims are categorized into three classes: support,\ninsufficient, and refute, based on their relationship with the corresponding document. Authors collected and scraped\nnews articles from various credible sources in the US and India to compile data for the support and insufficient categories.\nWe extract features with Longformer from the full-text article bodies and pass them through our classifier. Articles from\nthe \u201cSupport\u201d and \u201cInsufficient\u201d classes were collected from credible sources while articles in the \u201cRefute\u201d classes\nwere collected from fact-checking websites. Our analysis reveal that 88% of the contents categorized as \u201cSupport\u201d or\n\u201cInsufficient\u201d are classified as credible by the classifier, while only 6.4% and 5.6% are classified as Fact-checked and\nUnreliable, respectively. Notably, EVVER-Net correctly identifies that 95% of the documents in the \u201cRefute\u201d class as\nFact-checked.\n9\n4.2.4 NewsCLIPpings+ Dataset\nWe extend our evaluation to include the evidence sourced from [ 28], referred to as NewsCLIPpings+, which consists\nof external information collected from the Web. Abdelnabi et al. [ 28] utilized the NewsCLIPpings dataset [ 36],\nwhich contains both pristine and falsified (algorithmically decontextualized) image-caption pairs. In this setup, textual\nevidence was obtained by querying images in an inverse search mode using the Google Vision API. For our analysis,\nwe utilize the test set of NewsCLIPpings+, comprising 7,264 image captions and 51,799 scraped text evidence pieces.\nAfter removing inaccurately scraped entries, such as image file names or \u2018Page Not Found\u2019 entries, we are left with\n45,907 textual evidence pieces. EVVER-Net estimates that 64.5% of the evidence is Credible, 21.4% Unreliable, and\n14.1% Fact-checked. Despite the majority of the evidence being considered credible, the presence of some pieces\nsourced from unreliable or leaked origins in NewsCLIPpings+ may not only compromise the accuracy of the veracity\npredictions but also introduce unrealistic elements into the assessment process.\n4.2.5 VERITE Dataset\nWe also assess evidence extracted in [ 41] for the VERITE dataset [ 27], which integrates image-caption pairs similar to\nthe previous dataset. In this dataset, \u2018MisCaptioned\u2019 pairs sourced from fact-checked articles like Snopes and Reuters\nwere considered. The authors collected misleading claims along with their associated images, utilizing the Google API\nto retrieve textual and visual evidence. After cleaning the gathered evidence, we obtain 1,611 text snippets, gathered\nfrom querying 1,000 image captions, classified as \u2018True\u2019, \u2018Miscaptioned\u2019, or \u2018Out-of-Context\u2019. Our classifier categorizes\nthese snippets with 42.6% labeled as Credible, 35.3% as Fact-checked, and 22.1% as Unreliable. It is important to\nnote that the higher percentage of Fact-checked snippets in this dataset is due to sourcing claims and images directly\nfrom fact-checked articles in the \u2018Miscaptioned\u2019 class. When these claims are searched using the Google API, it often\nreturns the original or similar fact-checking articles, resulting in leaked evidence. For image-caption pairs classified as\n\u2018Out-of-Context\u2019, we observe a lower Fact-checked (14.5%) and a higher Unreliable percentage (27.3%) compared\nto the other categories. In this case, the claims are taken from fact-checked articles but the out-of-context images are\nretrieved from the Web. Thereafter, these images are used to retrieve textual information from a Google API thus\nincreasing the likelihood of unreliable evidence.\n4.2.6 Inference\nOur findings reveal that widely-used datasets incorporate leaked and unreliable evidence during the AFC process. This\nhighlights the critical need for robust filtering mechanisms, like EVVER-Net, to identify and exclude such information\neffectively. Figure 3 provides examples sourced from LIAR-PLUS, MOCHEG, NewsCLIPpings+, VERITE, and\nFACTIFY datasets, alongside their classification by EVVER-Net. For instance, consider how \u201c[...] But we rated the\nstatement as True.\u201d (LIAR-PLUS) or \u201cA satire article [...] intended to be a prank [...]\u201d (FACTIFY) - taken directly from\nwithin fact-checked articles - provide information curated by fact-checkers that directly support or refute the claim, thus\ncreating an unrealistic scenario for early detection of new misinformation. On the other hand, short article titles such\nas \u201cDoes This NASA Photo Show a \u2018Portal\u2019 and \u2018Wall\u2019 on Mars?\u201d or \u201cTime Traveling to Pompeii: r/TikTokCringe\u201d\n(VERITE), does not necessarily provide any unreliable or leaked information by themselves. However, if the articles\u2019\ncontent were to be collected and analysed, they would be problematic for AFC systems.\n5 Conclusion\nIn this study, we address the critical but overlooked challenges associated with verifying the quality of external\ninformation used as evidence in existing datasets, particularly the presence of leaked and unreliable information. We\ndevelop the CREDULE dataset, comprising 91,632 news articles classified as Fact-checked, Credible, and Unreliable.\nAdditionally, we introduce the Evidence Verification Network (EVVER-Net), a robust solution for evidence verification\nand filtering, and conducted experiments with various language models. EVVER-Net reaches 79.5% and 89.0%\naccuracy for short and long texts, respectively, without utilizing domain credibility scores. By utilizing domain\ncredibility scores, the performance of EVVER-Net further improves to 91.5% and 94.4%. Furthermore, our analysis\non widely used datasets, including LIAR-PLUS, MOCHEG, FACTIFY , NewsCLIPpings+ and VERITE, reveals that\ncollected evidence often contain leaked and unreliable information, thereby diminishing the effectiveness and realism\nof building robust AFC systems. These findings underscore the importance of implementing evidence verification and\nfiltering solutions such as EVVER-Net during the evidence retrieval task of AFC systems.\nWhile our study offers valuable insights into evidence verification in AFC, it has certain limitations. First, it solely\nfocuses on textual evidence, overlooking the potential influence of images and videos. Visual elements can also\ncontain unreliable information (e.g., by being fabricated, manipulated or synthetically generated) or having artifacts that\nindirectly indicate that they are sourced from fact-checked articles (e.g., watermarks). Future research should aim to\n10\nenhance the robustness of evidence verification and filtering methods like EVVER-Net by expanding the CREDULE\ndataset to include a more diverse range of articles and sources, including multimedia content. Furthermore, we refrain\nfrom collecting new external information from the Web and filtering them with EVVER-Net in order to examine its\nimpact on AFC systems. We hypothesize that the performance of AFC systems would decrease if they previously\nprimarily relied on leaked evidence, which would afterwards be removed by EVVER-Net. On the other hand, we\nhypothesize that removing unreliable information would improve performance, thus somewhat balancing out the\ndecrease in performance from removing leaked evidence. Overall, this would result into a more realistic and reliable\nframework for training and evaluating AFC systems, especially on new and emerging misinformation. Nevertheless,\nfuture research should systematically examine these effects.\nAcknowledgements\nThis work is partially funded by the Horizon Europe projects vera.ai under grant agreement no. 101070093 and DisAI\nunder grant agreement no. 101079164.\nReferences\n[1]Andrew Duffy, Edson Tandoc, and Rich Ling. Too good to be true, too good not to share: the social utility of fake\nnews. Information, Communication & Society , 23(13):1965\u20131979, 2020.\n[2]Femi Olan, Uchitha Jayawickrama, Emmanuel Ogiemwonyi Arakpogun, Jana Suklan, and Shaofeng Liu. Fake\nnews on social media: the impact on society. Information Systems Frontiers , pages 1\u201316, 2022.\n[3]Ray Oshikawa, Jing Qian, and William Yang Wang. A survey on natural language processing for fake news\ndetection. arXiv preprint arXiv:1811.00770 , 2018.\n[4]Hanqing Zhao, Wenbo Zhou, Dongdong Chen, Tianyi Wei, Weiming Zhang, and Nenghai Yu. Multi-attentional\ndeepfake detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ,\npages 2185\u20132194, 2021.\n[5]Firoj Alam, Stefano Cresci, Tanmoy Chakraborty, Fabrizio Silvestri, Dimiter Dimitrov, Giovanni Da San Martino,\nShaden Shaar, Hamed Firooz, and Preslav Nakov. A survey on multimodal disinformation detection. arXiv\npreprint arXiv:2103.12541 , 2021.\n[6]Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos. A survey on automated fact-checking. Transactions\nof the Association for Computational Linguistics , 10:178\u2013206, 2022.\n[7]Max Glockner, Yufang Hou, and Iryna Gurevych. Missing counter-evidence renders NLP fact-checking unrealistic\nfor misinformation. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022\nConference on Empirical Methods in Natural Language Processing , pages 5916\u20135936, Abu Dhabi, United Arab\nEmirates, December 2022. Association for Computational Linguistics.\n[8]Isabelle Augenstein, Christina Lioma, Dongsheng Wang, Lucas Chaves Lima, Casper Hansen, Christian Hansen,\nand Jakob Grue Simonsen. Multifc: A real-world multi-domain dataset for evidence-based fact checking of claims.\narXiv preprint arXiv:1909.03242 , 2019.\n[9]Rishabh Misra. Politifact Fact Check Dataset. https://www.kaggle.com/datasets/rmisra/\npolitifact-fact-check-dataset , 2022.\n[10] Neema Kotonya and Francesca Toni. Explainable automated fact-checking for public health claims. arXiv preprint\narXiv:2010.09926 , 2020.\n[11] Benjamin Horne, Sara Khedr, and Sibel Adali. Sampling the news producers: A large news and feature data set\nfor the study of the complex media landscape. In Proceedings of the International AAAI Conference on Web and\nSocial Media , volume 12, 2018.\n[12] Jeppe N\u00f8rregaard, Benjamin D Horne, and Sibel Adal\u0131. Nela-gt-2018: A large multi-labelled news dataset for the\nstudy of misinformation in news articles. In Proceedings of the international AAAI conference on web and social\nmedia , volume 13, pages 630\u2013638, 2019.\n[13] Maur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131. Nela-gt-2019: A large multi-labelled news dataset for the\nstudy of misinformation in news articles, 2020.\n[14] Maur\u00edcio Gruppi, Benjamin D Horne, and Sibel Adal\u0131. Nela-gt-2020: A large multi-labelled news dataset for the\nstudy of misinformation in news articles. arXiv preprint arXiv:2102.04567 , 2021.\n11\n[15] Maur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131. Nela-gt-2021: A large multi-labelled news dataset for the\nstudy of misinformation in news articles, 2021.\n[16] Maur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131. Nela-gt-2022: A large multi-labelled news dataset for the\nstudy of misinformation in news articles, 2023.\n[17] Maciej Szpakowski. FakeNewsCorpus Dataset. https://github.com/several27/FakeNewsCorpus , 2020.\n[18] Megan Risdal. Getting real about fake news, 2016.\n[19] Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with disentan-\ngled attention. arXiv preprint arXiv:2006.03654 , 2020.\n[20] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\nAmanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language\nsupervision. In International conference on machine learning , pages 8748\u20138763. PMLR, 2021.\n[21] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of\nMachine Learning Research , 21(1):5485\u20135551, 2020.\n[22] Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, and Yinfei Yang.\nLongt5: Efficient text-to-text transformer for long sequences. arXiv preprint arXiv:2112.07916 , 2021.\n[23] Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv preprint\narXiv:2004.05150 , 2020.\n[24] Tariq Alhindi, Savvas Petridis, and Smaranda Muresan. Where is your evidence: Improving fact-checking by\njustification modeling. In James Thorne, Andreas Vlachos, Oana Cocarascu, Christos Christodoulopoulos, and\nArpit Mittal, editors, Proceedings of the First Workshop on Fact Extraction and VERification (FEVER) , pages\n85\u201390, Brussels, Belgium, November 2018. Association for Computational Linguistics.\n[25] Shreyash Mishra, S Suryavardan, Amrit Bhaskar, Parul Chopra, Aishwarya Reganti, Parth Patwa, Amitava\nDas, Tanmoy Chakraborty, Amit Sheth, Asif Ekbal, et al. Factify: A multi-modal fact verification dataset. In\nProceedings of the First Workshop on Multimodal Fact-Checking and Hate Speech Detection (DE-FACTIFY) ,\n2022.\n[26] Barry Menglong Yao, Aditya Shah, Lichao Sun, Jin-Hee Cho, and Lifu Huang. End-to-end multimodal fact-\nchecking and explanation generation: A challenging dataset and models. In Proceedings of the 46th International\nACM SIGIR Conference on Research and Development in Information Retrieval , pages 2733\u20132743, 2023.\n[27] Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, and Panagiotis C Petrantonakis. Verite:\na robust benchmark for multimodal misinformation detection accounting for unimodal bias. International Journal\nof Multimedia Information Retrieval , 13(1):4, 2024.\n[28] Sahar Abdelnabi, Rakibul Hasan, and Mario Fritz. Open-domain, content-based, multi-modal fact-checking of\nout-of-context images via online resources. In Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition , pages 14940\u201314949, 2022.\n[29] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for\nfact extraction and VERification. In Marilyn Walker, Heng Ji, and Amanda Stent, editors, Proceedings of the 2018\nConference of the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long Papers) , pages 809\u2013819, New Orleans, Louisiana, June 2018. Association for\nComputational Linguistics.\n[30] Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. Fakenewsnet: A data repository\nwith news content, social context, and spatiotemporal information for studying fake news on social media. Big\ndata, 8(3):171\u2013188, 2020.\n[31] Kashif Khan, Ruizhe Wang, and Pascal Poupart. Watclaimcheck: A new dataset for claim entailment and inference.\nInProceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers) , pages 1293\u20131304, 2022.\n[32] Naeemul Hassan, Gensheng Zhang, Fatma Arslan, Josue Caraballo, Damian Jimenez, Siddhant Gawsane, Shohedul\nHasan, Minumol Joseph, Aaditya Kulkarni, Anil Kumar Nayak, et al. Claimbuster: The first-ever end-to-end\nfact-checking system. Proceedings of the VLDB Endowment , 10(12):1945\u20131948, 2017.\n[33] Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana V olkova, and Yejin Choi. Truth of varying shades: Analyzing\nlanguage in fake news and political fact-checking. In Proceedings of the 2017 conference on empirical methods in\nnatural language processing , pages 2931\u20132937, 2017.\n12\n[34] Christina Boididou, Stuart E Middleton, Zhiwei Jin, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia\nBoato, and Yiannis Kompatsiaris. Verifying information with multimedia content on twitter: a comparative study\nof automated approaches. Multimedia tools and applications , 77:15545\u201315571, 2018.\n[35] Shivangi Aneja, Chris Bregler, and Matthias Nie\u00dfner. Cosmos: Catching out-of-context misinformation with\nself-supervised learning. arXiv preprint arXiv:2101.06278 , 2021.\n[36] Grace Luo, Trevor Darrell, and Anna Rohrbach. Newsclippings: Automatic generation of out-of-context multi-\nmodal media. arXiv preprint arXiv:2104.05893 , 2021.\n[37] Fuxiao Liu, Yinghan Wang, Tianlu Wang, and Vicente Ordonez. Visual news: Benchmark and challenges in news\nimage captioning. arXiv preprint arXiv:2010.03743 , 2020.\n[38] Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, and Gerhard Weikum. Credibility assessment of textual\nclaims on the web. In Proceedings of the 25th ACM international on conference on information and knowledge\nmanagement , pages 2173\u20132178, 2016.\n[39] Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, and Gerhard Weikum. Declare: Debunking fake news and\nfalse claims using evidence-aware deep learning. arXiv preprint arXiv:1809.06416 , 2018.\n[40] Chris Samarinas, Wynne Hsu, and Mong Li Lee. Latent retrieval for large-scale fact-checking and question\nanswering with nli training. In 2020 IEEE 32nd International Conference on Tools with Artificial Intelligence\n(ICTAI) , pages 941\u2013948, 2020.\n[41] Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, and Panagiotis C Petrantonakis. Red-\ndot: Multimodal fact-checking via relevant evidence detection. arXiv preprint arXiv:2311.09939 , 2023.\n[42] Georgi Karadzhov, Preslav Nakov, Llu\u00eds M\u00e0rquez, Alberto Barr\u00f3n-Cede\u00f1o, and Ivan Koychev. Fully automated\nfact checking using external sources. arXiv preprint arXiv:1710.00341 , 2017.\n[43] Michael Schlichtkrull, Zhijiang Guo, and Andreas Vlachos. Averitec: A dataset for real-world claim verification\nwith evidence from the web. Advances in Neural Information Processing Systems , 36, 2024.\n13", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Credible, unreliable or leaked?: Evidence verification for enhanced automated fact-checking", "author": ["Z Chrysidis", "SI Papadopoulos"], "pub_year": "2024", "venue": "Proceedings of the 3rd \u2026", "abstract": "Automated fact-checking (AFC) is garnering increasing attention by researchers aiming to  help fact-checkers combat the increasing spread of misinformation online. While many"}, "filled": false, "gsrank": 286, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3643491.3660278", "author_id": ["G7qFy-0AAAAJ", "ZSFB6vcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:QFx1jFHs64kJ:scholar.google.com/&output=cite&scirp=285&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=QFx1jFHs64kJ&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 15, "citedby_url": "/scholar?cites=9938296837716139072&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:QFx1jFHs64kJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2404.18971?"}}, {"title": "The discourses of climate change denialism across conspiracy and pseudoscience websites", "year": "2024", "pdf_data": " THE ROUTLEDGE \nHANDBOOK OF DISCOURSE \nAND DISINFORMATION \n Edited by Stefania M. Maci, Massimiliano Demata, \nMark McGlashan and Philip Seargeant \nFirst published 2024\n ISBN: 978-1-032-12425-4 (hbk) \n ISBN: 978-1-032-12428-5 (pbk) \nISBN: 978-1-003-22449-5 (ebk)\n 20 \n THE DISCOURSES OF CLIMATE \nCHANGE DENIALISM \nACROSS CONSPIRACY AND \nPSEUDOSCIENCE WEBSITES \n Isobelle Clarke \n(CC-BY-NC-ND 4.0)\n DOI: 10.4324/9781003224495-24 \nThe funder of the Open Access version of this chapter is The Leverhulme Trust.\nResearch was funded by the Leverhulme Trust. Grant number ECF-2020-590.\n 325  Introduction \n Despite the growing body of scienti\ufb01  c evidence supporting the notion of anthropogenic global warm-\ning (AGW) and climate change, there remains a persistent sceptic and denialist movement \u2013 comprised of and in\ufb02  uenced by the fossil fuel industry, conservative think-tanks, politicians, contrarian scientists, some news media, and self-interested corporations and individuals, among others. The movement\u2019s endurance is largely a consequence of their employment of discourses ( McCright and Dunlap, 2010 ). \nSome of the discourses that have been consistently reported on across studies (e.g.  Dunlap and Mc-Cright, 2010 ,  2015 ; Washington and Cook, 2011) investigating the denialist movement include (1) stating that climate scientists are in a global conspiracy that they pro\ufb01  t from, (2) referring to fake \nexperts that deny AGW, (3) stating calls for action on climate change are unsubstantiated because of uncertainties in climate models and disagreements between climate scientists, and (4) outright denial. \n Much attention has been paid to the roots of climate change denial, which has demonstrated the \nrole of the fossil fuel industry (e.g.  Lahsen, 2005 ), conservative think-tanks (e.g.  Lahsen, 2005 ), politicians (e.g.  McCright and Dunlap, 2003 ), contrarian scientists (e.g.  McCright and Dunlap, 2003 ), and the press (e.g.  Boyko\ufb00   and Boyko\ufb00  , 2004 ). More recently, research has focused on the role of climate denier blogs, which are blogs by self-described climate sceptics and contrar-ian scientists dedicated to disputing climate science and questioning the reality and signi\ufb01  cance of climate change ( Dunlap and McCright, 2010 ,  2015 ). Denier blogs have passionate audiences with new posts often inciting hundreds of comments expressing contempt for climate scientists, activists, and policy proponents ( Dunlap and McCright, 2015 ). Whilst the community of deniers is smaller than that of science-based bloggers, denier-based bloggers and their community are more closely linked and supportive of one another ( Bloom\ufb01  eld and Tillery, 2018 ). For example, Dunlap and McCright note that \n virtually any claim uttered by a contrarian scientist \u2013 whether it be a \u201c\ufb01  nding\u201d that chal-lenges anthropogenic climate change or the discovery of a weakness in a mainstream scien-tist\u2019s work or an allegation of suppression \u2013 immediately zooms around the internet via the climate change blogosphere.  \n ( 2010 : 253)  20 \n THE DISCOURSES OF CLIMATE \nCHANGE DENIALISM \nACROSS CONSPIRACY AND \nPSEUDOSCIENCE WEBSITES \n Isobelle Clarke \nDOI: 10.4324/9781003224495-24\nThis chapter has been made available under a CC-BY-NC-ND 4.0 international license.\nIsobelle Clarke\n326 In addition to the mechanisms behind the circulation of denial  content, research has investi-\ngated the content of denier blogs. Harvey  et al . (2018), for example, compared the representation \nof polar bears and Arctic Sea ice by science-based and denier-b ased bloggers. They found that the \ntwo groups represent the facts di\ufb00  erently. Science-based blogs were found to use the frame of es -\ntablished scienti\ufb01  c certainties, drawing on published literature concerning the reduction of Arctic \nSea ice extent, which is threatening polar bears, whereas denie r blogs were found to emphasise the \nuncertainties around AGW to cast doubt on the population trends  of polar bears. \n In another study,  Br\u00fcggemann et al. (2020 ) analysed science- based and denier-based blog posts \nfor evidence of the hoax discourse, which they de\ufb01  ne as calling into question the truthfulness of \nsomeone else. In a sample of the posts referring to hoax-relate d terms, they found science-based \nposts refer to \u201cdenial\u201d and \u201cdenier\u201d, whilst sceptic blog posts  referred to \u201calarmist\u201d and \u201cfraud\u201d. Both \ngroups use \u201cfake\u201d, \u201choax\u201d, \u201cpropaganda\u201d, and \u201cconspiracy\u201d to re fer to the other. Overall, they found \nthat the hoax discourse impeded deliberation and open exchange of arguments. Instead, they argue \nthat it served identity purposes as one was able to situate the mselves as supporting a particular group. \n The Internet has changed the ways in which science is communic ated, enabling \u201cvoices to ap-\npear equally credible\u201d and \u201creach many people\u201d ( Tillery and Bl oom\ufb01  eld, 2022 : 1). Climate change \ndenial views are both visible and proliferate on the Internet, meaning that they can have consider-\nable in\ufb02  uence. Because the Internet is a hub for science and environme ntal communication,  Dunlap \n(2013 ) called for more research into sceptic and denier blogs.  While previous research has explored \nthe communication strategies of blogs, existing research is lim ited to either (1) providing a detailed \naccount of the strategies employed by a single or small number of sites (e.g.  Bloom\ufb01  eld and Tillery, \n2018 ;  Tillery and Bloom\ufb01  eld, 2022 ), (2) providing an account of how a larger number o f denier \nblogs frame a small number of entities (e.g. polar bears and se a ice in Harvey  et al ., 2018), or (3) \nexploring the use of a single strategy across the denier blogs (e.g.  Br\u00fcggemann  et al ., 2020 ). As \na result, there lacks a large-scale exploratory linguistic anal ysis of the common discourses used \nacross many climate denier websites and blogs. This chapter see ks to \ufb01  ll that gap by analysing the \nmajor representations of climate change and global warming acro ss 186 websites and blogs known \nto promote pseudoscience and conspiracy. \n Methodology \n Data: the pseudoscience and conspiracy sources (PaCS) corpus \n This research reported on in this chapter forms part of a larg er project investigating numerous \nbranches of antiscience, including climate change denialism. In  this project, a corpus has been built \ncomprising texts (all content on a single webpage \u2013 i.e. articl e and comments) from 235 websites \nlabelled as \u201cconspiracy-pseudoscience\u201d by mediabiasfactcheck.co m, which is a comprehensive \nand continuously updated resource of online media sites which h ave been rated for various levels \nof bias. The corpus was then \ufb01  ltered by retaining texts according to \u201cseed\u201d words and phrase s as-\nsociated with the branches of antiscience relevant to the large r project. The present chapter drew \non the climate change sub-corpus of the pseudoscience and consp iracy sources (PaCS) corpus, \nwhich was \ufb01  ltered according to the seed phrases \u201cclimate change\u201d and/or \u201c global warming\u201d. \n Duplicated texts were removed from the corpus using a Python s cript to avoid skewing the data. \n Table 20.1  presents the composition of the climate change sub -corpus before and after the removal \nof duplicates. This table shows that nearly 27% of texts were r eproduced from other sites.  Table \n20.1  shows that the climate change sub-corpus analysed compris es 19,961 texts, totalling over \n38-million-word tokens. These texts come from 186 di\ufb00  erent sites. \nThe discourses of climate change denialism \n327  It should be noted that not all the sites included in this an alysis are denying climate change. \nSome websites are dedicated to antiscience strands, which menti on the impact of climate change \n(e.g. anti-genetically modi\ufb01  ed organisms). Unfortunately, no further \ufb01  ltering of the data was com-\npleted to ensure that the texts analysed are only those which d eny climate change. This was in part \ndue to (1) the large number of texts in the corpus and the leng ths of some of these, which would \ntake a considerable amount of time to read to assess the presen ce of denial; (2) the complexity, \nsophistication, and persuasiveness of denial, which, for a gene ral novice in climatology (such as \nmyself), can make it hard to assess if denial is present in the  texts, and; (3) for reasons of replica-\nbility. Because of this, it is important to note that while I l abel the discourses identi\ufb01  ed as climate \nchange denial (for matters of convenience), they are more speci \ufb01 cally characterised as the repre-\nsentations of climate change on pseudoscience and conspiracy we bsites. \n Keyword co-occurrence analysis \n To identify the discourses of climate change denialism, this c orpus is analysed using keyword \nco-occurrence analysis (KCA;  Clarke, McEnery and Brookes, 2021  ). KCA is an approach aimed \nat identifying patterns of co-occurring keywords across a corpu s of texts. In corpus linguistic \nresearch, keywords are words which occur with a statistically m arked frequency in one corpus \n(focus corpus) when compared with another (reference corpus). K eywords can allow access to dis-\ncourses associated with some object of study ( Baker, Gabrielat os and McEnery, 2013 ). KCA draws \non the notion that keywords point to discourses ( Baker, Gabrie latos and McEnery, 2013 ), as well \nas the notion of linguistic co-occurrence ( Biber, 1988 ) \u2013 tha t is, that frequent patterns of co-occur ring \nlinguistic features tend to reveal an underlying communicative function \u2013 to hypothesise that \npatterns of co-occurring keywords may point to discourses ( Cla rke, McEnery and Brookes, 2021 ). \n The keyword analysis was completed in Sketch Engine, which use s the simple maths method \nfor the computation of keywords (see  Kilgari\ufb00  , 2009 ). Speci\ufb01  cally, the climate change sub-corpus \nwas uploaded to Sketch Engine and de\ufb01  ned as the focus corpus. This focus corpus was then com-\npared to the English Web 2020 corpus (enTenTen2020), which serv ed as the reference corpus. The \nenTenTen20 corpus is a 38-billion-word corpus comprising online  texts collected between 2019 \nand 2021. This reference corpus was selected as it represents a  general sample of web content \nthroughout these years and because the bulk of the focus corpus \u2019 texts are from this period (nearly \n30% spread across these 3 years, with the remaining 70% spread across 20 years; see  Figure 20.1 ). \nHowever, this reference corpus is limited in that the climate c hange sub-corpus spans a wider \ntimeframe (from 1999 to 2021) and comparisons against it may th us lead to some time-sensitive \nwords being de\ufb01  ned as key. \n The keyword analysis produced a list of 1,000 keywords. KCA us es multiple correspondence \nanalysis (MCA) to group keywords based on how they co-occur in the texts of the corpus. Very \ninfrequent features are given unfair weight in MCA, and so  Le Roux and Rouanet (2010 ) advise \nthat features occurring in less than 5% of the data are removed . Consequently, the list of 1,000   Table 20.1  The climate change denial sub-corpus \n       Number of Texts    Number of Word Tokens  \n Before removal of duplicates  27,302  46,739,379 \n After removal of duplicates  19,961  38,510,518 \nIsobelle Clarke\n328keywords was reduced, retaining only those that occurred in mor e than 5% of the texts (135 key-\nwords). These keywords can be found in  Appendix 1 . \n To complete KCA, each text in the corpus was analysed for the presence/absence of each of the \n135 keywords using a script, written in R, which records this i nformation in a data matrix. This \nmatrix was then subjected to MCA. \n MCA is a geometric data analytic method which identi\ufb01  es relationships between three or more \ncategorical variables. In KCA, MCA is used to identify keywords  that co-occur often in the texts \nof the corpus. It also reveals which texts exhibit these patter ns of co-occurring keywords. Speci\ufb01  -\ncally, MCA produces a series of dimensions where each category of a keyword (e.g. presence of \n climate  , absence of  climate  ), and each text in the corpus is assigned a coordinate and a contribu-\ntion for each dimension. Coordinates re\ufb02  ect the nature of the association between the categories \nof the keywords in terms of proximity, where keywords distribut ed in similar ways in the texts \nhave coordinates closer to each other on the same side of the o rigin, and keywords not distributed \nin similar ways are positioned on opposite sides of the origin (i.e. one will have a positive coor-\ndinate and the other a negative one). Hence, coordinates signal  co-occurrence patterns. Contribu-\ntions show which categories of keywords are the most important contributors to the dimensions. \nContributions do not have polarity, and so the coordinates of t he keywords need to be interpreted \nin conjunction with their contributions. Speci\ufb01  cally, keywords with strong contributions and posi-\ntive coordinates need to be interpreted in opposition to keywor ds with strong contributions and \nnegative coordinates. In line with  Le Roux and Rouanet (2010 ) , only the categories of keywords \nwhose contribution exceeds the average were analysed, as these represent the most distinguishing \npatterns of variation. Each dimension represents a distinct pat tern of co-variation. Dimension 1 \nrepresents the best \ufb01  t of the data with each subsequent dimension representing the next most com-\nmon pattern of variation (i.e. set co-occurring keywords). \nFigure 20.1  The number of texts in the climate change sub-corpus per year\nThe discourses of climate change denialism \n329 Each dimension was interpreted until the dimensions were no lo nger readily interpretable (i.e. it was \nnot possible to make sense of the patterns of co-occurring keyw ords), beginning with the \ufb01  rst dimen-\nsion. Overall, eight dimensions were interpreted. Like other st udies employing KCA (e.g.  Clarke, \nMcEnery and Brookes, 2021 ), the \ufb01  rst dimension opposed the  presence   of keywords with the  ab-\nsence   of keywords and had a strong correlation to the length of the  text ( r  = .70). This is a result of \ninvestigating the presence/absence of keywords, as opposed to t he texts\u2019 relative frequency, as text \nlength is not controlled for. The relative frequencies of featu res are often analysed so that texts of \ndi\ufb00 erent lengths can be compared reliably. The relative frequenci es of keywords in each text are not \nanalysed in this study because most texts (63%) analysed contai n under 1,000 words. The relative \nfrequencies of features in texts with less than 1,000 words ten d to be unreliable estimates. Moreover, \nthe relative frequencies of keywords are also not analysed in K CA because keywords are typically in-\nfrequent in comparison to high-frequency grammatical features, meaning there will be lots of zeros. \nWhen datasets comprised of many zeros are analysed by multivari ate statistical techniques for con-\ntinuous data (i.e. not MCA, but techniques such as factor analy sis or principal component analysis), \nthen the correlation coe\ufb03   cients can be misleading. As a result, the presence/absence o f keywords \nare analysed using MCA (a multivariate statistical technique fo r categorical data). However, because \ntext length is not controlled for, and because the length of th e text in words is the greatest in\ufb02  uence \non the presence of keywords (i.e. the more words a text has, th e more likely the keywords will be \npresent), the \ufb01  rst dimension re\ufb02  ects text length. No other dimensions are associated with text  length. \nFor this reason, Dimension 1 is not interpreted further. In the  next section, I present the patterns of \nco-occurring keywords and sample texts that are most associated  with Dimensions 2 to 8 and provide \nmy interpretations of the discourses to which the patterns poin t. \n Results \n Dimension 2: political versus science discourses \n The keywords associated with positive Dimension 2 point to pol itical discourses. Politicians ( clin-\nton, obama, trump  ), political ideologies ( socialist, capitalism, activist  ), and organisations ( UN ,  \n EP A ) are referenced to discuss policies (calls for), political ac tion, and programmes related to AGW, \nsuch as calls to control energy production, storage and consump tion ( energy, grid, electricity, fuel, \nnuclear, gas  ), limiting the burning of fossil fuels ( fossil, coal, fuel  ) due to their e\ufb00  ects ( pollution, \nemission, carbon, dioxide  ), and switching to renewable energy sources ( wind  ,   renewable  ). These \nkeywords co-occur with keywords signalling hoax discourses ( scam, corrupt, agenda, propaganda, \nfraud, fake)  , ignorance ( ignorant, stupid, ignorance, nonsense  ), and cost ( trillion  ), frequently to \nevaluate such political calls for action against the threat of AGW as a scam and stupid, as the actions \n(e.g. renewable energy) cost a huge amount, pro\ufb01  t particular individuals, especially those calling \nfor climate action, and are unreliable. There are also argument s suggesting that limiting the burning \nof fossil fuels impacts economic growth and is pointless as oth er countries do not make reductions. \nFor example, Text 1, taken from the corpus, is strongly associa ted with positive Dimension 2. This \ntext covers various American presidents\u2019 actions and policies o n AGW. The text describes Clinton\u2019s \nclimate change policies as a \u201cweapon\u201d for scaremongering. Addit ionally, it presents the view that \nother countries are producing more CO 2 , rendering any reductions by America pointless.  \n Text 1: Green New Deal \u2013 Boldest Tactic Yet to Advance U.N. Ag enda 21 ( https://wattsupwiththat.\ncom/2019/03/29/green-new-deal-boldest-tactic-yet-to-advance-u-n -agenda-21/ , 29 March 2019) \nIsobelle Clarke\n330 Alternatively, the keywords associated with negative Dimension  2 draw on scienti\ufb01  c discourses. \nThere are keywords associated with places and areas ( antarctica, antarctic, greenland, hemi-\nsphere, arctic, atlantic, polar, sea, ocean, surface  ), changes in state ( warm, warmer, melt, melting, \ncooling, freezing, snow, ice, temperature  ), natural processes ( variability, volcanic  ,   el  (Ni\u00f1o),  win-\nter, weather, tropical, precipitation  ), and scienti\ufb01  c data analysis ( forecast, trend, graph, satellite  ,  \n NOAA  ). These keywords co-occur in articles to discuss the poor pre dictions of scienti\ufb01  c models \non the impact of future climate change, to suggest that they sh ould not be trusted, especially the \nmodel\u2019s conclusions that man-made CO 2  levels are to blame. These keywords also co-occur in ar-\nticles suggesting that any changes in temperature, weather, sea  level, and ice thickness are not due \nto man-made carbon emissions, but rather due to natural process es, such as volcanic eruptions, el \nni\u00f1o, and natural variability, which occur in periodic cycles. Records of growing ice in Antarctica \nand Greenland are also referred to as a form of \u201cwhataboutery\u201d to disprove global warming, as in \nText 2. This text draws on evidence showing ice gain in Greenla nd to suggest that climatologists \nare lying about ice loss and fabricating data to align with the ir theory of climate change.   [. . .] \n The main weapon used by  Clinton   for his call for action was the threat of Environmental Ar-\nmageddon, particularly manifested through the charge of manmade  global warming, later \nto becoming \u201cclimate change\u201d. It didn\u2019t matter if true science refused to cooperate in the \nscheme, as actual global temperatures are not rising and there continues to be no evidence \nof any appreciable manmade e\ufb00  ects on the climate. \n [. . .]  And even if Americans did stop producing CO \n2 , Earth\u2019s CO 2  levels would continue to rise be-\ncause China, India, and other countries are building  coal - \ufb01 red plants by the dozen, which \nwill like more than o\ufb00  set any reductions Americans make. \n [. . .] \n Text 2: If The Data Doesn\u2019t Match Theory, Change The Data ( ht tps://realclimatescience.\ncom/2017/04/if-the-data-doesnt-match-theory-change-the-data/ , 25 April 2017) \n Professional climate fraudsters claim that  Greenland   is losing  ice  600% faster than predicted. \n As of yesterday, the Danish Meteorological Institute (DMI) sho wed  Greenland surface   mass \ngain for the  winter   at a record high. This is a direct contradiction to the lies being spread by \nclimate alarmists. \n The DMI data was being widely cited by skeptics as evidence ag ainst global warming fraud, so \ntoday DMI changed the  graph  . They changed their baseline dates, and no longer show 2017 \nas being a record high. \n We have seen this identical story hundreds of times. Climate d ata being altered to avoid criti-\ncism from global warming alarmists. [. . .] \n This dimension indicates that the second most common pattern o f keyword variation distinguishes \nbetween texts drawing on political discourses with those drawin g on scienti\ufb01  c discourses. This \ndemonstrates that climate change and climate change denial are both political and scienti\ufb01  c issues. \nThe discourses of climate change denialism \n331 Dimension 3: the discreditation of public institutions versus \nthe discreditation of renewable energy \n The keywords associated with positive Dimension 3 are used in the texts for the purpose of discredit-\ning public institutions. The mainstream media ( msm, mainstream  ), politicians ( Clinton, Gore, Trump, \nObama  ,   UN) , political ideologies ( socialist, activist  ), and scientists ( mann, scientist, met  ) are often \ncritiqued in the texts for promoting bias, fake news, and alarm ism about AGW ( bias, corrupt, cagw, \nfraud, fake, alarmism, alarmist, warmist, propaganda, hoax, ignorance, ignorant, scam, scare, stu-pid, nonsense, agenda  ). Such texts emphasise that global warming is a  conspiracy  , that there is no \n consensus   on  AGW  , and that they are sceptical ( skeptical, skeptic  ) of claims that humans are to  blame   \nand of graphs and data. For example, Text 3 reports on \u201cClimate gate\u201d \u2013 a case where hackers broke \ninto email exchanges between researchers within the Climate Res earch Unit at East Anglia University, \nwhich supposedly involved researchers colluding on manipulating  data to conceal evidence against \nglobal warming \u2013 to suggest that man-made global warming is a c onspiracy. Some texts reject the \ncommon accusation of climate change sceptics/denialists as havi ng capitalist interests ( capitalism  ) .   \n Text 3: Climategate: CATO\u2019s Pat Michaels and Center for Americ an Progress Dan Weiss on \nFox News ( https://wattsupwiththat.com/2009/11/25/catos-pat-mic haels-and-center-for-ameri-\ncan-progress-dan-weiss-on-fox-news/ , 25 November 2009) \n Hackers broke into thousands of emails and documents from the Climate Research Unit at East \nAnglia University last week and uncovered the global warming co nspiracy. \n [. . .]  Calls for an independent inquiry into what is being dubbed \u201cCl imategate\u201d are growing as the \nfoundation for man-made global warming implodes following the r elease of emails which \nprove researchers colluded to manipulate data in order to \u201chide  the decline\u201d in global \ntemperatures. \n [. . .] \n The keywords associated with negative Dimension 3 are used to discredit renewable energy. No-\ntably, renewable energy sources ( renewable, solar, wind, sun, gas  ) are described as expensive, \nunpredictable, unreliable, and unable to cope with demand, as i n Text 4. Such texts describe fossil \nfuels ( fossil, fuel, gas)   as being more reliable than renewable energy sources, as the electric grid is \ndescribed as requiring a constant and stable \ufb02  ow of electrons and is damaged by the unpredictabil-\nity of renewable energy ( energy, electricity, grid  ). There are also keywords associated with atmos-\npheric CO 2  levels ( atmospheric, atmosphere, CO2, carbon, dioxide, heat, pollution, greenhouse, \nheating, emission  ), and these often co-occur to emphasise that natural gas (whi ch has been a solu-\ntion to burning less coal and can be viewed as a bridge to a cl ean energy future) still produces a \nlarge amount of carbon dioxide and pollution. Additionally, atm ospheric CO 2  levels are often men-\ntioned to emphasise that CO 2  is a trace gas and therefore cannot be the cause of climate c hange.  \n Text 4: Endless Subsidies For Unreliable Wind & Solar are an E conomic Suicide Pact ( https://\nstopthesethings.com/2021/08/01/endless-subsidies-for-unreliable -wind-solar-are-an-econom-\nic-suicide-pact/ , 1 August 2021) \nIsobelle Clarke\n332 Overall, this dimension indicates that the next most common pa ttern of variation across the texts \nin the climate change denial corpus distinguishes texts that ar e discrediting believers of climate \nchange or discrediting initiatives for combating the e\ufb00  ects of climate change. Oreskes and Con-\nway (2010) similarly found that climate denial strategies are d esigned to question the credibility of \nmainstream scientists and simultaneously boost the appearance o f scienti\ufb01  c credibility for the de-\nnial countermovement. This dimension marks the overt questionin g, undermining, and damaging \nof the reputation of climate scientists, other public instituti ons, and renewable energy, suggesting \nthat climate change denial is a kind of smear campaign. \n Dimension 4: the discourse of extremism versus the \u201cconsensus\u201d \n The keywords associated with positive Dimension 4 often co-occ ur in texts to point to a discourse \nof extremism. Speci\ufb01  cally, there are keywords associated with extreme cold weather  ( freezing, \nsnow, winter, storm, cold, forecast, \ufb02 ooding, polar, weather, ice, extreme, atlantic, melt, melting)  .  \nThese keywords often occur in texts reporting on cold weather t o suggest that global warming is \na hoax and that an ice age is imminent, as in Text 5. Many text s emphasise that the mainstream \nmedia ( msm ) reports are sensationalistic,  extreme   and  stupid   for blaming ( blame  ) the cold weather \non AGW, as a  warm winter   would indicate AGW, rather than a  cold winter  . The impact of the cold \nweather on renewable energy sources ( renewable, wind  ) is also discussed in some of the texts, \nwhere heaters drawing on fossil fuel energy ( grid, electricity, nuclear, coal  ) are required during \ncold weather to pump  warm   air onto the blades, thereby suggesting that renewable energy  is un-\nreliable. Plans to curb rising temperatures and extreme weather  \u2013 for example, as the \u201cGreen New \nDeal\u201d, which proposes a reduction of CO 2  emissions by switching to renewables \u2013 are deemed \n socialist  ,   extreme  , and unrealistic. Additionally, the use of renewable energy i n  Germany   is also \nmentioned and critiqued as extreme and extremely expensive. Pol itical actors ( clinton, trump, \nobama  ) are also referenced, often to report on actions deemed as ex treme. For example, Obama \nshutting down power plants as the country goes into winter.   Australia\u2019s  renewable   energy target has subsidised  wind   and  solar   to the tune of more \nthan $60 billion, wrecked its  grid  and driven power prices through the roof. \n [. . .]  And, in a country heavily reliant upon  wind   and  solar  , power becomes scarce when \nthe sun sets and/or calm weather sets in. \n Couple that with a period of peak demand (breathless 42\u00b0C days , for example) and \n energy   intensive industries are simply chopped from the grid under t he euphemism \nof \u201cdemand management\u201d. \n Suicidal doesn\u2019t cover it.  [. . .] \n Text 5: Polar V ortex of Stupidity (https://climatechangedispat ch.com/polar-vortex-of-stupidity/, \n30 January 2019) \n A few years ago, the Washington Post said global warming would  cause cherry trees to start \nblooming in January. \n That didn\u2019t work out for them, so now they are  blaming   the record  cold  on global warming. \n If the  Polar   V ortex is caused by global warming, why does it mimic the pat tern of the last  ice  age? \nThe discourses of climate change denialism \n333 By contrast, the keywords associated with negative Dimension 4  are used to discuss the consensus of \nthe role of CO 2  in global warming. Notably, many of the texts mention sceptic ism ( skeptical, skeptic  )  \nof the  consensus   promoted by the Intergovernmental Panel on Climate Change ( IPCC  ) \u2013 that climate \nchange ( anthropogenic, man-made  ) is a result of increasing levels of atmospheric carbon dioxi de \n( CO 2 , carbon, dioxide, concentration, greenhouse, emission, atmosphere, atmospheric  ) produced by \nhumans through the burning of fossil fuels. For example, some t exts note that there is no  correlation   \nbetween  emissions   and  atmospheric concentrations   of  CO 2   to suggest that something else is in\ufb02  uenc-\ning global warming. Additionally, many texts cite scienti\ufb01  c articles ( science, NASA, scientist, scienti \ufb01 c, \nradiation, planetary, physics, magnitude, earth, surface, cloud, atmosphere, atmospheric  ), observa-\ntions ( observed  ), \ufb01 ndings, and principles to demonstrate particular aspects of th e climate where there \nis uncertainty and debate. These conclusions are used to sugges t that there is no consensus and that \nman-made climate change is a  hypothesis  , as in Text 6. Instead, many of the texts emphasise the role \nof natural in\ufb02  uences on the climate ( volcanic, variability, magnitude, surface, radiation, cloud  ) .   \n Text 6: On Consensus (https://notrickszone.com/2013/12/18/clim ate-sciences-constant-appeals-\nto-authority-only-con\ufb01  rm-its-total-fallacy/, 18 December 2013) \n We are constantly told that there is a  consensus   in climate  science   that  CO 2   is warming the \nplanet, or the deep ocean, (or something) and that if we do not  limit  CO 2   something bad \nwill happen. As one can easily see, there is no  consensus   on the two \u201csomethings\u201d in that \n\ufb01 rst sentence. We are told that  CO 2   is responsible for warming, cooling, less rainfall, more \nrainfall, less snow, more snow, less ice, more ice, more hurric anes, fewer hurricanes, more \ntornados, fewer tornados, and so on. Each of those things can a lso be good or bad, (but \nmostly bad) depending on where and when they happen. The \u201c consensus  \u201d seems to morph \nto whatever bad thing the writer wants to prove. This isn\u2019t cli matology, it\u2019s calamitology. \n [. . .] \n This dimension indicates that the next most common pattern of variation in the corpus distin-\nguishes texts that are drawing on the discourse of extremism wi th texts that are emphasising that \nthere is no consensus. This dimension shows that refutation is an important strategy in climate \nchange denials, as global warming is refuted due to extreme col d weather, and the consensus is \nrefuted by showing areas of climate science which are debated t o persuade others to disbelieve hu-\nman\u2019s in\ufb02  uence on climate change. Additionally, the seriousness of glob al warming is downplayed \nby suggesting green policies are extreme. \n Dimension 5: the role of CO 2  versus natural variation \n The keywords associated with positive Dimension 5 co-occur in texts to describe the role of carbon \ndioxide in global warming. Speci\ufb01  cally, there are keywords associated with global warming ( global, \nwarming, earth, planet  ), its causes ( carbon, dioxide, pollution  ), and its e\ufb00  ects, such as melting ice \nin the Arctic, Greenland, and Antarctica ( melting, antarctica, antarctic, melt, greenland, arctic, ice  ) ,  \nleading to sea levels rising ( sea, rise, ocean  ) and the extinction of species ( extinction, polar  ). Interest-\ningly, some texts with these keywords present research \ufb01  ndings which indicate the impact of global \nwarming, but they then go on to criticise the cited report for perceived \ufb02  aws. This is arguably for the \npurpose of instilling doubt in parts or all the conclusions (se e  Dunlap and McCright, 2010 ). Some texts \nacknowledge global warming, describing the di\ufb00  erent explanations for why the globe is warming \nIsobelle Clarke\n334(including anthropogenic, natural causes, and aliens), and its di\ufb00 erent e\ufb00  ects, often to downplay the \nrole of humans. Some other texts, especially those containing t he keywords used to mark deception \n( propaganda, agenda, hoax  ) emphasise that global warming is a hoax. Some of these texts  state that \nglobal warming is only partially caused by human production of CO 2 , but that the  mainstream   media, \npoliticians, and organisations ( clinton, UN, obama, trump, mainstream, activist  ) make it out to be \nmore. Keywords associated with hysteria ( catastrophe, catastrophic, unprecedented  ) are used both \nto ridicule believers of AGW and to emphasise the seriousness o f it. Notably, some texts associated \nwith this side of the dimension refer to growing ice cover, as opposed to melting ice and poor model \npredictions on sea level rise which overstate the actual measur ements. Additionally, many texts claim \nthat carbon dioxide plays no role in global warming, as the pla net was warmer before industrialised \nlevels of CO 2 , or because the global temperatures are not rising, as in Tex t 7.  \n Text 7: Highest CO 2  levels recorded in 3 million years still don\u2019t budge global t emperatures \n. . . o\ufb03   cial climate change narrative collapses in the face of real s cience ( www.newstarget.\ncom/2019-05-03-highest-co2-levels-recorded-in-3-million-years-s till-dont-budge-global-\ntemperatures.html , 3 May 2019) \n Is  carbon dioxide   the driving force behind climate change? That\u2019s what many cli mate change \nalarmists would have you believe, but when you look at real-wor ld data, that narrative collapses. \n [. . .]   Put quite simply,  carbon dioxide   is not a poison that we should fear. Instead, what we should \nfear is a dramatic reduction in it because it\u2019s what gives our planet life. Without  carbon di-\noxide  , we wouldn\u2019t have plants, which means there wouldn\u2019t be oxyge n and humans would \neventually die out. \n In the past,  carbon dioxide   levels have been signi\ufb01  cantly higher than they are now, yet life still \nmanaged to exist and plants, not surprisingly, thrived. Indeed,  experts say that if  carbon \ndioxide   levels drop too much, many plants and other vegetal species w ould become extinct. \n [. . .] \n The keywords associated with negative Dimension 5 are used to refer to natural processes ( vari-\nability, cloud, precipitation, sun, wind, el   (Ni\u00f1o),  physics, heating, cycle, solar, sun, winter, mag-\nnitude  ) as a cause of climate change, as in Text 8. Additionally, th ere are keywords associated \nwith AGW ( AGW, CAGW  ) and denigrating terms for people who believe in it ( warmist  ), which \nco-occur in texts often stating that there is  zero  evidence for the  hypothesis   of  AGW  . There are \nalso keywords associated with energy ( electricity, grid  ). These co-occur in texts that are critiquing \nrenewable energy policies and the shutting down of power plants . According to the authors, these \nactions are pointless given that climate change is due to natur al causes.  \n Text 8: New Met O\ufb03   ce study suggests natural factors, including the sun, are the  biggest reason \nbehind \u201cthe pause\u201d ( https://wattsupwiththat.com/2018/06/07/new -met-o\ufb03   ce-study-suggests-\nnatural-factors-including-the-sun-are-the-biggest-reason-behind -the-pause/ , 7 June 2018) \n [. . .] \nThe discourses of climate change denialism \n335 Overall, Dimension 5 shows that the next strongest pattern of variation distinguishes texts men-\ntioning the role of CO 2  in global warming with texts mentioning natural variation as the reason for \nclimate change. This dimension indicates that climate change de niers often appeal to the fallacy of \nlack of proportion, where the role of CO 2  in climate change is downplayed, and the role of natural \nprocesses in climate change are exaggerated. Both sides of the dimension align with  Cohen\u2019s (2001 ) \ninterpretative denial and may be positioned as climate sceptics , given that both repertoires tend to \nacknowledge climate change as happening but assign an alternati ve cause to climate change. \n Dimension 6: counterevidence versus no evidence \n The keywords associated with positive Dimension 6 co-occur in texts to provide counterevi-\ndence against the arguments of AGW. In particular, there are ke ywords associated with Antarc-\ntica and Greenland ( antarctica, antarctic, greenland, hemisphere  ), which occur in texts to state \nthat the ice sheet is not  melting   but in fact it is growing, despite CO 2   emissions   and  concentra-\ntion  levels rising. These texts provide counterevidence, including   satellite   images of growing \nice to suggest that there is no relation between CO 2  and global warming. There are keywords \nassociated with scienti\ufb01  c analysis ( graph, observed, physics)  , which co-occur in texts discuss-\ning scienti\ufb01  c models predicting the impacts of climate change over time ( decade  ), such as \npredictions of sea levels ( sea, ocean, surface, melt, melting, atlantic  ), the extinction of species \n( extinction  ), and extreme weather events ( tropical  ). These texts often provide counterevidence \ncontrasting the scienti\ufb01  c models\u2019 predictions with observed reality to suggest that th e models \nare wrong. There are also keywords associated with natural vari ability ( el  (Ni\u00f1o),  cloud, radia-\ntion, volcanic, magnitude  ), which occur in texts to provide counterevidence against AGW  to \nsuggest that climate change is due to natural causes, as oppose d to human\u2019s production of CO 2 .  \nSome texts refer to  Trump  \u2019s actions in pulling out of green policies and the \u201cevidence\u201d  that sup-\nports these policy changes. Such evidence is positioned as coun terevidence against the impact \nof CO 2  on climate change. The argument that  capitalism   is to blame for AGW  is introduced, so \nas to counter it. Such texts instead emphasise the good of capi talism and reinforce the \u201cactual\u201d \ncauses of climate change. Finally, the keyword  unprecedented   is associated with positive Di-\nmension 6, and this occurs in the texts to critique the \u201cunprec edented\u201d label applied to evidence \nof AGW. Such texts describe the uses of the word \u201cunprecedented \u201d as hysteria, providing coun-\nterevidence, including warmer temperatures in the past (before industrialised levels of CO 2 ) and \nnatural processes, as in Text 9, which emphasises that the warm ing in the Arctic is natural and \nnot a result of CO 2 .   A team of researchers from the U.K. Met O\ufb03   ce, Sweden and Australia has found that three \nperiods of global warming slowdown since 1891 were likely due t o natural causes rather \nthan disruptions to the factors causing global warming.  \n [. . .]  The team asserts that the third slowdown, aka \u201cthe pause\u201d whic h is also the one on which many \nglobal warming skeptics like us here at WUWT follow, was likely  caused by a combination \nof La Ni\u00f1a events and volcanism. \n They also claim that the third slowdown period wasn\u2019t a stoppi ng point, and they say tempera-\ntures continued to rise, they just did so at a slower pace. \n [. . .] \nIsobelle Clarke\n336  The keywords associated with negative Dimension 6 co-occur in  texts to indicate that there is no \nevidence of AGW. Speci\ufb01  cally, texts associated with this side of the dimension note t hat  global \nwarming   is a theory and that claims of the role of  carbon dioxide   in global warming are not sub-\nstantiated, as in Text 10. Some of the texts use the derogatory  labels  warmist   and  alarmist   when \nreferring to those that advocate global warming is  man-made   (  AGW  ), to position such views as \ndi\ufb00 erent to theirs. Such texts suggest that the theory of AGW is a  hoax  , exaggerated and intended \nto  scare  , as there is no evidence to support the theory. Many of the t exts draw on examples of \ncold weather and temperature ( weather, snow, forecast, temperature, winter, cooling, cold  ) to sug-\ngest that there is no evidence of global warming. Some of the k eywords are used to refer to the \nindividuals emphasising AGW (e.g.  IPCC, gore, science, scienti \ufb01 c, scientist  ) in order to discredit \nthem. For example, Al  Gore   is referenced to suggest that he is pro\ufb01  teering from climate policies. \n Scientists   and the  IPCC   are accused of going against  science   and the traditional  scienti \ufb01 c  method \nby (1) not challenging climate change theory, (2) not publishin g dissenting views or counterevi-\ndence against AGW, and (3) accepting and promoting that there i s a consensus on human\u2019s role \nin global warming. Additionally, some texts mention particular scientists as holding views against \nthe consensus, as in Text 10, which depicts professors, researc hers, and scientists who are in sup-\nport of Senator Roberts report \ufb01  nding that the CSIRO could neither con\ufb01  rm nor prove that carbon \ndioxide is dangerous or the cause of climate change.   Text 9: The Real Arctic Story ( https://alarmistclaimresearch. \ufb01 les.wordpress.com/2019/02/\namo-pdo-solar-and-arctic-v2.pdf , 8 March 2019) \n  Arctic   warming and the  melting   of the arctic ice are not at all  unprecedented   (they happen predict-\nably on multidecadal scales with a period of around 60 years) a nd are in fact entirely natural.  \n [. . .]  \n Text 10: Australian Sen Malcolm Roberts Exposes The Climate Ch ange Scam ( www.australi-\nannationalreview.com/state-of-a\ufb00  airs/australian-sen-malcolm-roberts-exposes-the-climate-\nchange-scam/ , 19 January 2020) \n [. . .]  \n The key \ufb01  ndings of Senator Roberts\u2019 report shows that CSIRO: 1. Refuses  to state that  carbon \ndioxide   from human activity is a danger 2. Does not have empirical ev idence proving that \n carbon dioxide   from human activity e\ufb00  ects climate 3. Have used evidence in their presenta-\ntion that contradicts the empirical climate evidence. 4. Uses c limate computer models that \nare neither appropriate nor recommended to be used to inform go vernment policy. . . . Those \nsupporting the senator at his press conference were Internation ally eminent Canadian clima-\ntologist, geographer and environmentalist Professor Tim Ball, e xpert on the United Nations\u2019 \nunfounded and politically motivated climate claims cited by CSI RO. \n [. . .] \n Overall, this dimension indicates that the texts in the corpus  can be distinguished according to \nthose providing counterevidence to climate change believers wit h those stating that there is no \nevidence for climate change. This dimension reveals common argu mentation strategies employed \nby climate change deniers: rebutting and denying. \nThe discourses of climate change denialism \n337 Dimension 7: the discourse of weather manipulation versus anti-alarmism \n The keywords on the positive side of Dimension 7 co-occur in t exts signalling the discourse of weather \nmanipulation. There are keywords associated with weather and we ather forecasts ( \ufb02 ooding, drought, \nstorm, weather, forecast, cloud, tropical, cool, extreme, precipitation, sun  ), which co-occur in texts \noften to describe the disparity between the current weather and  that which was forecasted. The texts \naccuse those higher up ( obama, fake, socialist, trump, mainstream, clinton  ) of being part of a conspir-\nacy ( conspiracy, corrupt, blame, agenda  ), which is aimed at manipulating the earth\u2019s ( earth, planet  )  \nclimate  cycle  . Notably, they suggest planes are spraying chemicals into the  atmosphere ( atmosphere, \natmospheric  ) to manipulate weather events \u2013 often referred to in the text s as geo-engineering. Weather \nmanipulation is described as being, among others, for the purpo se of pro\ufb01  ting from various climate \npolicies and taxes, which have been enforced at an unprecedente d scale, as in Text 11. Weather ma-\nnipulation is often described in these texts as a threat to lif e on earth ( extinction, civilization  ) .   \n Text 11: Meteorologists And Climate Engineering Denial, Perpet uating The Lie For A Paycheck \nAnd A Pension ( www.geoengineeringwatch.org/meteorologists-and- climate-en gineering-denial-\nperpetuating-the-lie-for-a-paycheck-and-a-pension/ , 22 Februar y 2016) \n [. . .] How many so called \u201cexperts\u201d have long since sold any shred of honor and honesty they may \nhave once possessed in exchange for a paycheck and a pension? T he blatant criminal denial of \nthe climate engineering atrocities so visible in skies around t he globe is the greatest deception \never perpetrated on populations of the planet. The majority of the masses have unfortunately so \nfar been all too willing to accept a constant parade of lies fr om the power structure and their paid \nminions on an endless list of issues. \n [. . .] \n The keywords associated with negative Dimension 7 co-occur in articles expressing the discourse \nof anti-alarmism. Speci\ufb01  cally, the texts most associated with this dimension are often  critiquing and \nmocking believers of AGW (e.g.  mann  ,   IPCC  ) as  alarmists   (  alarmism, alarmist, CAGW  ). The texts \nassociated with this dimension critique sensationalist reports and headlines emphasising that West \nAntarctica is melting and sea levels are rising ( antarctic, antarctica, greenland, melt, melting, sea, \nice, arctic, polar  ), as can be seen in Text 12. The texts instead state that it is not melting, despite \nrising levels of carbon dioxide ( co2)  from the burning of fossil fuels ( fossil, coal  ), or they state that \nit is melting, but due to natural processes. Keywords associate d with renewable energy ( renewable, \nelectricity, grid)   and places where there has been a big push for renewable ener gy ( Germany  ) are \nmentioned. These co-occur in texts to denounce alarmists\u2019 impul sion for renewable energy. Such \ntexts describe the unsustainability of renewable energy, due to  the cost and shelf life of wind tur-\nbines and their impact on birds, as well as the unreliability o f renewable energy on the grid.  \n Text 12: BIAS BY OMISSION: No Mention Of Mother Nature\u2019s Under sea V olcanoes In The \nLatest Antarctic \u201cGlobal Warming\u201d Scare Story ( https://climati sm.wordpress.com/2018/05/10/\nbias-by-omission-no-mention-of-mother-natures-undersea-volcanoe s-in-the-latest-antarctic-\nglobal-warming-scare-story/ , 10 May 2018) \n  ANTARCTICA   has always been a thorn in the side of the Climate Crisis Ind ustry. It simply has \nnot behaved as global warming  alarmists   would have liked or as climate models predicted. \nIsobelle Clarke\n338 Overall, this dimension indicates that the next major pattern of variation distinguishes texts that \npromote the conspiracy of weather manipulation with texts that mock climate change believers as \n\u201calarmists\u201d. It can be argued that promoting the conspiracy of weather manipulation serves as a \nde\ufb02 ection strategy. Proponents of the conspiracy do not deny AGW but instead divert the attention \naway from human\u2019s CO 2  production and instead focus the attention on the dangers of the manipula-\ntion of the weather to block solar radiation. Consequently, the  impact of human\u2019s CO 2  production is \narguably presented as less severe than the dangers and e\ufb00  ects associated with climate manipulation. \nThe negative side of this dimension marks that name-calling and  responding to the tone are com-\nmon strategies in climate change denials, as climate change bel ievers are accused of exaggerating \nand being hysterical. This dimension may therefore be seen as o pposing texts that are engaged in \nemphasising an alternative concern, often in a hysterical manne r, with those that are de-emphasising \na mainstream concern, often by critiquing the manner of climate  activists as hysterical. \n Dimension 8: extreme weather as climate scaremongering \nversus global warming is fraud/scam \n The keywords associated with positive Dimension 8 are used in texts to criticise reports of extreme \nweather as climate scaremongering. Speci\ufb01  cally, there are keywords associated with extreme \nweather ( \ufb02 ooding, drought, tropical, storm, precipitation, extreme, weather, forecast, predict  ) in \nspeci\ufb01  c areas ( atlantic  ). There are also keywords that co-occur to critique AGW belie vers as cli-\nmate scaremongering ( climate, climatic, alarmism, catastrophe, catastrophic, alarmist  ), such as \nText 13. Such texts mock scientists\u2019 ( EP A, mann  ) use of the word  unprecedented   and  blame   the \nscientists for overstating and exaggerating the impact of  carbon dioxide   (  greenhouse, fossil, fuels  ,  \n pollution  ) and causing alarm and scare. Natural  variability   is also often mentioned in the texts to \nindicate that the extreme weather is nothing new and just a par t of the earth\u2019s climate cycle.   HISTORICALLY , Antarctica has been cooling and growing ice mass , despite rising carbon \ndioxide emissions. Emissions that, according to \u201cglobal warming  theory\u201d, are meant to ef-\nfect the poles greater than mid latitude regions due to the lac k of humidity enhancing the \ntheorised  CO 2   feedback. \n [. . .]  \n Text 13: \u201cThe Science\u201d Proves Extreme Weather Events Are NOT I ncreasing ( www.climat-\nedepot.com/2020/02/20/the-science-that-proves-extreme-weather-e vents-are-not-increasing/ , \n20 February 2020) \n COGNITIVE BIAS:  Climate   Change  Alarmists   Refuse To Accept \u201cThe Science\u201d That Proves \n Extreme Weather   Events Are NOT Increasing \n [. . .]   COGNITIVE BIAS fuelled by an era of mass hysteria, delusion, g roupthink and panic has \nhelped foster dark and far-fetched clich\u00e9s of a current \u201c climate   crisis\u201d, that is an \u201cexistential \nthreat\u201d which will \u201cend civilisation by 2030\u201d. \n [. . .] \n By contrast, the keywords associated with negative Dimension 8  co-occur in texts emphasising \nthat climate change, that data supporting it, and policies and incentives associated with combating \nThe discourses of climate change denialism \n339it are fraudulent. There are keywords used to mark that climate  change is a hoax ( conspiracy, hoax, \nfake, scam, fraud, propaganda  ), that there is  zero  evidence behind CO 2  and global warming, and \nthat people who believe in it are ignorant ( ignorance, ignorant, stupid  ) to the other reasons for the \n planet  \u2019s ( earth, planet  )   cooling   and  heating   (  cloud, sun, volcanic  ,   solar, cycle, surface, cool, cold, \nradiation  ).  NASA   is often mentioned to accuse them of adjusting graphs to supp ort AGW, such as \nText 14, or to describe the views of a  NASA   employee as going against the consensus.  \n Text 14: 1975 Documentary \u201cThe Weather Machine\u201d: Climate \u201cKeep s Changing Gear\u201d . . . \n\u201cIce Age Now Due Any Time\u201d! ( https://notrickszone.com/2018/03/ 18/1975-documentary-the-\nweather-machine-climate-keeps-changing-gear-ice-age-now-due-any -time/ , 18 March 2018) \n A  documentary dubbed \u201cThe Weather Machine\u201d produced in 1975 \u2013  long before  NASA   \ufb01 d-\ndled with the data \u2013 warned of an impending ice age (10:35), an d maintained that the globe \nis  cooling  . Hat-tip: reader The Indomitable Snowman. \n The documentary attempted and succeeded at presenting the late st on climate change at the time. \n Changing climate accepted as normal  It is true that back in 1975 climatologists already knew that the climate behaved  cyclically  , as \nevidenced by the ice cores and tree ring sets extracted from th e American Southwest. \n [. . .] \n Overall, Dimension 8 shows that the \ufb01  nal major pattern of variation in the corpus distinguishes \ntexts that depict global warming as a scam with texts that crit ique people who accuse extreme \nweather events to be a consequence of AGW. This dimension demon strates that many texts in the \ncorpus are involved in accusing. For example, the texts associa ted with the positive side accuse \npeople linking extreme weather events to climate change as scar emongering and the texts associ-\nated with the negative side accuse people of making up AGW, adj usting graphs to suit the theory, \nand for being ignorant to the real causes of global warming. \n Conclusion \n Responding to calls for more research into sceptic and denier blogs ( Dunlap, 2013 ), the present \nstudy aimed to conduct a large-scale analysis of 19,961 texts m entioning global warming or cli-\nmate change, taken from 186 websites/blogs known to promote con spiracy and pseudoscience. \nUsing corpus linguistic tools, a list of keywords that occur wi th a signi\ufb01  cantly higher frequency in \nthis corpus in comparison to a 38-billion-word corpus of web te xts (EnTenTen20) was computed. \nUsing this list of keywords, the corpus was analysed for the mo st common patterns of co-occurring \nkeywords across the texts using KCA ( Clarke, McEnery and Brook es, 2021 ; Clarke, Brookes \nand McEnery, 2021). Previous research has noted that climate sc ience receives \u201cmultifaceted, \ncomplex, and nuanced opposition\u201d ( Bloom\ufb01  eld and Tillery, 2018 : 32). Thus, given that KCA is a \nmultidimensional approach, KCA was deemed appropriate for uncov ering such patterns. \n KCA revealed the most common patterns of keyword variation in the dataset, which were \ninterpreted as pointing to common representations and discourse s associated with climate change \nacross these conspiracy and pseudoscience sites. The analysis h as not only revealed the common \ndiscourses of climate change scepticism, but it has also shown the order of prominence in terms of \nfrequency \u2013 which discourses are most common across the blogs, with each dimension represent-\ning the next strongest pattern of keyword variation across the texts in the corpus. As a result, it is \nIsobelle Clarke\n340possible to say that the texts in the corpus most commonly are either critiquing political calls for \naction against climate change as a scam or they are critiquing scienti\ufb01  c research, such as by point-\ning out faults and \ufb02  aws with climate models and scienti\ufb01  c measurements. In this way, the analysis \nhas provided a richer account of the most common mechanisms and  repertoires of climate scepti-\ncism by structuring these co-occurrence patterns in order of fr equency. \n The results indicate that all the tactics and arguments known to have been developed and prom-\nulgated by conservative think tanks (funded by the fossil fuel industry) have permeated online \nblogs and websites promoting pseudoscience and conspiracy. This  lends support to  Dunlap and \nJacques\u2019 (2013 ) observation that, unlike scienti\ufb01  c knowledge, which accumulates through test-\ning, rejecting, and modifying hypotheses and theories, the deni al literature accumulates \u2013 claims \nare \u201cretained and reused whenever convenient\u201d ( 2013 : 713). On line blogs and websites provide \nanother home for these claims to be repeated. The major goals o f social movement activists are \nto make their causes publicly visible, resonant, and legitimate  ( Koopmans, 2004 ). Because the \nInternet has enabled \u201cvoices to appear equally credible\u201d and \u201cr each many people\u201d ( Tillery and \nBloom\ufb01  eld, 2022 : 1), these recycled arguments arguably have a consi derable amount of in\ufb02  uence, \nas the Internet a\ufb00  ords public visibility, resonance, and to some degree, legitim acy. \n Overall, the analysis has revealed the most common discourses and argumentation strategies \nused for disputing AGW across websites known to promote pseudos cience and conspiracy. These \ndiscourses can be compelling. For example, whilst there is evid ence of outright denial in texts \nassociated with negative Dimension 6 (\u201cNo evidence\u201d) and negati ve Dimension 9 (\u201cGlobal warm-\ning is a scam\u201d), other dimensions show that texts do not necess arily deny climate change. Instead, \ntexts are focused on downplaying the seriousness of climate cha nge. For example, the seriousness \nof climate change is lessened in texts associated with positive  Dimension 4 (the discourse of ex-\ntremism) when the authors critique climate policies as extreme.  Additionally, the seriousness of \nclimate change is downplayed in texts associated with negative Dimension 7 and positive Dimen-\nsion 8, when the authors label climate activists as \u201calarmists\u201d  and \u201cscaremongers\u201d respectively. \nThese strategies present climate change as being not as bad as climate activists present it, which \nconsequently creates doubt about the reality of climate change.  In comparison to outright denial, \nwhich is harder to believe in the face of growing scienti\ufb01  c evidence of AGW, downplaying the \nseriousness of climate change is arguably a subtler and more be lievable strategy. As in law, rather \nthan prove innocence, the defence attorney need only create rea sonable doubt in the narrative be-\ning promulgated by the prosecutor. In the context of the climat e change debate, the climate denial \nmovement has created an exceptional amount of doubt. This doubt  has the potential to delay e\ufb00  ec-\ntive climate action, which will likely have disastrous conseque nces for life on earth. Studies aimed \nat uncovering and understanding the discourses of disinformatio n, such as the one presented here \nin and throughout this collection, are well-positioned to pave the way for the creation of e\ufb00  ective \ncounterstrategies to prevent such negative consequences from ha ppening. \n Appendix \n Keywords occurring in more than 5% of the texts in the focus c orpus: \n activist, agenda, agw, alarmism, alarmist, antarctic, antarcti ca, anthony, anthropogenic, arctic, \natlantic, atmosphere, atmospheric, average, bias, blame, btw, c agw, capitalism, carbon, catastrophe, \ncatastrophic, civilization, climate, climatic, clinton, cloud, co2, coal, cold, concentration, consen-\nsus, conspiracy, cool, cooling, correlation, corrupt, cycle, de cade, dioxide, drought, earth, el, elec-\ntricity, emission, energy, epa, extinction, extreme, fake, \ufb02  ooding, forecast, fossil, fraud, freezing, \nfuel, gas, germany, global, gore, graph, greenhouse, greenland,  grid, heat, heating, hemisphere, \nThe discourses of climate change denialism \n341hoax, hypothesis, ice, ignorance, ignorant, ipcc, magnitude, ma instream, man-made, mankind, \nmann, melt, melting, met, msm, nasa, noaa, nonsense, nuclear, o bama, observed, ocean, physics, \nplanet, planetary, polar, pollution, precipitation, predict, pr ediction, propaganda, radiation, renew-\nable, rise, satellite, scam, scare, science, scienti\ufb01  c, scientist, sea, skeptic, skeptical, snow, socialist, \nsolar, storm, stupid, sun, surface, temperature, trend, trillio n, tropical, trump, un, unprecedented, \nvariability, volcanic, warm, warmer, warming, warmist, weather,  wind, winter, wuwt, zero \n References \n Baker, P., Gabrielatos, C. and McEnery, T. (2013)  Discourse analysis and media attitudes: The representation \nof Islam in the British Press  . Cambridge: Cambridge University Press. \n Biber, D. (1988)  Variation across speech and writing  . Cambridge: Cambridge University Press. \n Bloom\ufb01  eld, E.F. and Tillery, D. (2018) \u2018The circulation of climate c hange denial online: Rhetorical and net-\nworking strategies on Facebook\u2019,  Environmental Communication  , 13(1), pp. 23\u201334. \n Boyko\ufb00  , M.T. and Boyko\ufb00  , J.M. (2004) \u2018Bias as balance: Global warming and the US pres tige press\u2019,  Global \nEnvironmental Change  , 14, pp. 125\u2013136. \n Br\u00fcggemann, M., Elgesem, D., Bienzeisler, N., Gertz, H.D. and Walter, S. (2020) \u2018Mutual group polarization \nin the blogosphere: Tracking the hoax discourse on climate chan ge\u2019,  International Journal of Communica-\ntion , 14, pp. 1025\u20131048. \n Clarke, I., Brookes, G. and McEnery, T. (2021) \u2018Keywords throu gh time\u2019,  International Journal of Corpus \nLinguistics,   27(4), pp. 399\u2013427. \n Clarke, I., McEnery, T. and Brookes, G. (2021) \u2018Multiple corre spondence analysis, newspaper discourse and \nsubregister: A case study of discourses of Islam in the British  press\u2019,  Register Studies  , 3(1), pp. 144\u2013171. \n Cohen, S. (2001)  States of Denial: Knowing about Atrocities and Su \ufb00 ering  . Cambridge: Polity Press. \n Dunlap, R.E. (2013) \u2018Climate change skepticism and denial: An introduction\u2019,  American Behavioral Scien-\ntist , 57(6), pp. 691\u2013698. \n Dunlap, R.E. and Jacques, P.J. (2013) \u2018Climate change denial b ooks and conservative think tanks: Exploring \nthe connection\u2019,  American Behavioral Scientist  , 57(6), pp. 699\u2013731. \n Dunlap, R.E. and McCright, A.M. (2010) \u2018Climate change denial:  Sources, actors and strategies\u2019, in C. Le-\nver-Tracy (ed.),  Routledge handbook of climate change and society  . London and New York: Routledge, \npp. 240\u2013259. \n Dunlap, R.E. and McCright, A.M. (2015) \u2018Challenging climate ch ange: The denial countermovement\u2019, in \nR.E. Dunlap and R.J. Brulle (eds.),  Climate Change and Society: Sociological Perspectives  . New York: \nOxford University Press, pp. 300\u2013332. \n Harvey, J.A., Van Den Berg, D., Ellers, J., Kampen, R., Crowth er, T.W., Roessingh, P., Verheggen, B., Nui-\njten, R.J.M., Post, E., Lewandowsky, S., Stirling, I., Balgopal , M., Amstrup, S.C. and Mann, M.E. (2018) \n\u2018Internet blogs, polar bears, and climate-change denial by prox y\u2019,  Bioscience  , 68(4), pp. 281\u2013287. \n Kilgari\ufb00  , A. (2009) \u2018Simple maths for keywords\u2019, in M. Mahlberg, V . Go nz\u00e1 lez-D\u00ed az and C. Smith (eds.), \n Proceedings of corpus linguistics conference CL2009  . Liverpool: University of Liverpool. \n Koopmans, R. (2004) \u2018Movements and media: Selection processes and evolutionary dynamics in the public \nsphere\u2019,  Theory and Society  , 33, pp. 367\u2013391. \n Lahsen, M. (2005) \u2018Technocracy, democracy and U.S. climate pol itics\u2019,  Science Technology and Human \nValues  , 30, pp. 137\u2013169. \n Le Roux, B. and Rouanet, H. (2010)  Multiple correspondence analysis  . Thousand Oaks, CA: SAGE Publica-\ntions Inc. \n McCright, A.M. and Dunlap, R.E. (2003) \u2018Defeating Kyoto: The c onservative movement\u2019s impact on U.S. \nclimate change policy\u2019,  Social Problems  , 50, pp. 348\u2013373. \n McCright, A.M. and Dunlap, R.E. (2010) \u2018Anti-re\ufb02  exivity: The American Conservative movement\u2019s success \nin undermining climate science and policy\u2019,  Theory, Culture and Society  , 26, pp. 100\u2013133. \n Oreskes, N. and Conway, E.M. (2010)  Merchants of doubt: How a handful of scientists obscured the truth on \nissues from tobacco smoke to global warming  . New York: Bloomsbury Press. \n Tillery, D. and Bloom\ufb01  eld, E.F. (2022) \u2018Hyperrationality and rhetorical constellatio ns in digital climate \nchange denial: A multi-methodological analysis of the discourse  of watts up with that\u2019,  Technical Com-\nmunication Quarterly  , Ahead-of-Print, pp. 1\u201318. \n Washington, H. and Cook, J. (2011)  Climate change denial: Heads in the sand  . 1st edition. London: Earthscan.                        ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The discourses of climate change denialism across conspiracy and pseudoscience websites", "author": ["I Clarke"], "pub_year": "2024", "venue": "The Routledge handbook of discourse and \u2026", "abstract": "This handbook offers a comprehensive overview of research into discourses of disinformation,  misinformation, post-truth, alternative facts, hate speech, conspiracy theories, and \"fake"}, "filled": false, "gsrank": 287, "pub_url": "https://library.oapen.org/handle/20.500.12657/88620", "author_id": ["RrTJeH0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:MZ_iAoDAI-IJ:scholar.google.com/&output=cite&scirp=286&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=MZ_iAoDAI-IJ&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 12, "citedby_url": "/scholar?cites=16295079532793339697&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:MZ_iAoDAI-IJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://library.oapen.org/bitstream/handle/20.500.12657/88620/1/9781003224495_10.4324_9781003224495-24.pdf"}}, {"title": "Impact of Stricter Content Moderation on Parler's Users' Discourse", "year": "2023", "pdf_data": "Causal Insights into Parler\u2019s Content Moderation Shift:\nEffects on Toxicity and Factuality\nNihal Kumarswamy\u2217\nThe University of Texas at Arlington\nArlington, Texas, USA\nnihal.kumarswamy@mavs.uta.eduMohit Singhal\u2020\u2021\u2217\nNortheastern University\nBoston, Massachusetts, USA\nm.singhal@northeastern.eduShirin Nilizadeh\nThe University of Texas at Arlington\nArlington, Texas, USA\nshirin.nilizadeh@uta.edu\nAbstract\nSocial media platforms employ various content moderation tech-\nniques to remove harmful, offensive, and toxic content, with moder-\nation levels varying across platforms and evolving over time. Parler,\na fringe platform popular among conservative users, initially had\nminimal moderation, promoting itself as a space for open discussion.\nHowever, in 2021, it was removed from the Apple and Google App\nStores and suspended from Amazon Web Services due to inadequate\nmoderation of harmful content. After a month-long suspension,\nParler returned with stricter guidelines, offering a unique opportu-\nnity to study the impact of platform-wide policy changes on user\nbehavior and content outcomes. In this paper, we analyzed Parler\ndata to assess the causal associations of these moderation changes\non content toxicity and factuality. Using a longitudinal dataset of\n17M posts from 432K users, who were active both before and after\nreplatforming, we employed quasi-experimental analysis, control-\nling for confounding factors. We introduced a novel approach by\nusing data from another social media platform, Twitter, to account\nfor a critical confounding factor: offline events. This allowed us to\nisolate the effects of Parler\u2019s replatforming policies from external\nreal-world influences. Our findings demonstrate that Parler\u2019s mod-\neration changes are causally associated with a significant reduction\nin all forms of toxicity ( \ud835\udc5d<0.001). Additionally, we observed an\nincrease in the factuality of the news sites shared and a reduction\nin the number of conspiracy/ pseudoscience sources.\nCCS Concepts\n\u2022Information systems \u2192Web mining ;Social networking\nsites .\nKeywords\nParler; Content Moderation Effectiveness; Causal Inference\nACM Reference Format:\nNihal Kumarswamy, Mohit Singhal, and Shirin Nilizadeh. 2025. Causal\nInsights into Parler\u2019s Content Moderation Shift: Effects on Toxicity and\nFactuality. In Proceedings of the ACM Web Conference 2025 (WWW \u201925), April\n28-May 2, 2025, Sydney, NSW, Australia. ACM, New York, NY, USA, 10 pages.\nhttps://doi.org/10.1145/3696410.3714865\n\u2217Both authors contributed equally to the paper\n\u2020Corresponding author.\n\u2021Work done at The University of Texas at Arlington\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nWWW \u201925, Sydney, NSW, Australia\n\u00a92025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1274-6/25/04\nhttps://doi.org/10.1145/3696410.3714865This paper has been accepted at WWW 2025, please\ncite accordingly.\n1 Introduction\nSocial media has become a powerful tool that reflects the best\nand worst aspects of human communication. On one hand, they\nallow individuals to freely express opinions, engage in interpersonal\ncommunication, and learn about new trends and stories. On the\nother hand, they have also become fertile grounds for several forms\nof abuse, harassment, and the dissemination of misinformation [ 11,\n51,58,79]. Social media platforms, hence, continue to adopt and\nevolve their content moderation techniques and policies to address\nthese issues while trying to respect freedom of speech and promote\na healthier online environment.\nSocial media platforms, however, do not follow unified methods\nand policies for content moderation [ 80]. While some social media\nplatforms adopt more stringent content moderation rules, others,\nlike Parler, pursue a laissez-faire approach. Parler, launched in 2018,\nadhered to this hands-off moderation philosophy, contending that\nit promoted richer discussions and protected users\u2019 freedom of\nspeech [ 74]. This was until January 6th, 2021, when Parler gained\nmuch notoriety for being home to several groups and protesters\nwho stormed Capitol Hill [ 38,73]. Subsequently, due to its content\nmoderation policies and concerns about the spread of harmful or\nextremist content, Parler faced significant consequences. It was\nnot only terminated by its cloud service provider, Amazon Web\nServices but also removed from major app distribution platforms,\nincluding the App Store and the Google Play store [35].\nFor Paler to return, it had to enact substantial revisions to its\nhate speech policies .1This included a complete removal of the abil-\nity for users on iOS devices to access objectionable and Not Safe\nfor Work (NSFW) content. As a result, Parler\u2019s updated policies\nintroduced more stringent moderation policies aimed at curbing\nhate speech on the platform [ 52]. While prior studies have focused\non the impact of dealtforming a small subset of users or specific\ncommunities [ 8,20,50,69,71,72], or have examined how content\nmoderation affects the activities of problematic users [ 8,86], our\nwork evaluates the impact of new platform-wide policy changes on\nthe \u201cwithin-platform\u201d dynamics of all users who were active during\nboth the pre- and post-policy periods. This inclusive approach offers\na comprehensive perspective on the broader ecosystem, moving\nbeyond the limited focus on dealtformed users or specific audi-\nences. Furthermore, while prior research has predominantly ex-\namined hard content moderation measures\u2014such as suspensions\nor removals\u2014our study shifts the focus to replatforming , a distinct\n1Example of changes in Parler CG: https://tinyurl.com/yda6pfmj.arXiv:2310.08844v2  [cs.SI]  4 Feb 2025\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Nihal Kumarswamy, Mohit Singhal, & Shirin Nilizadeh\nscenario involving the reinstatement of a platform accompanied by\na series of progressive policy changes. In particular, we investigated\ntwo research questions:\nRQ1: Did changes to Parler\u2019s content moderation guidelines had\nany significant impact on the user-generated content?\nRQ2: How have Parler\u2019s content moderation revisions changed\nits existing users\u2019 characteristics?\nTo assess these effects, we conducted a quasi-experimental analy-\nsis, called Difference-in-Difference (DiD) [ 5], monitoring user posts\nfor toxic content, insults, identity attacks, profanity, and threats.\nIn addition, we explored shifts in users\u2019 characteristics and con-\nversation topics, and quantified the presence of biased posts and\nposts with non-factual links, utilizing data sourced from Media\nBias Fact Check (MBFC) [ 2]. We used the data from Aliapoulios et\nal. [9] as the seed dataset (we call this dataset a pre-policy change\ndataset), and we tried to collect the posts for the same sample of\n4M users. Developing our custom build crawler, we collected about\n17M parleys of a subset of 432K users who were active from Febru-\nary 2021 to January 2022. We labeled our dataset as a post-policy\npolicy change dataset. To the best of our knowledge, ours is the\nfirst dataset that was collected after Parler came back online. To\nmeasure the effect of Parler\u2019s content moderation changes, we used\nthe Difference-in-Difference (DiD) regression analysis, which is\narguably one of the strongest and widely used quasi-experimental\nmethods in causal inference [ 26,34,42,46]. This analysis helped\nus understand how and if the outcomes, e.g., the number of toxic\nposts, have changed after Parler changed its moderation guidelines.\nIn DiD analysis, to account for the potential influence of offline\nevents, such as social or political unrest, on platform toxicity, we\nused data from another social media platform\u2014Twitter\u2014as a con-\ntrol group. Our reasoning is that offline events, such as elections,\nwould likely increase toxicity across all platforms, regardless of\ntheir content moderation policies. For example, even with strict\nmoderation, Twitter would probably experience heightened toxicity\nduring periods of unrest compared to calmer times. To minimize\nbias, we analyzed a random sample of Twitter discussions, rather\nthan specifically targeting far-right conversations or incorporating\ndata from other fringe platforms.\nThus, this paper has the following contributions and findings:\n(1)Our work demonstrates how the effectiveness of content\nmoderation policies can be evaluated through data-driven\nanalysis using platform-specific data, in this case, Parler,\nbefore and after its moderation policy changes.\n(2)We collected the first-ever post-replatforming dataset from\nParler.\n(3)Using the Difference-in-Differences (DiD) approach, we found\nthat Parler was effective in reducing various types of toxicity.\n(4)While most related studies fail to account for external of-\nfline events that may influence user activity or toxicity, we\nused trends from a random sample of Twitter data as a con-\ntrol group in our DiD analysis to isolate the effects of the\nreplatforming policies.\n(5)Our findings showed an increase in both follower and fol-\nlowing counts, along with a rise in users with verified and\ngold badges. This suggests potential growth in Parler\u2019s userbase, as well as the continued presence of older users who\nwere active before the moderation policy changes.\n(6)We observed an improvement in factuality and credibility\nscores from the pre-moderation dataset to the post-moderation\ndataset. Additionally, there was a reduction in the sharing\nof conspiracy and pseudoscience source links. However, an\nincrease was noted in the sharing of questionable source\nlinks in the post-moderation dataset.\n2 Related Works\nFringe Communities: Over the past few years, scholars have ex-\ntensively studied various fringe platforms such as Gab and 4chan [ 16,\n45,49,81,91]. In contrast, Parler is a relatively younger platform,\nresulting in fewer studies focusing on collecting data or establishing\nframeworks for data collection from Parler [ 10,68]. Some studies\nhave compared topics of discussion on Parler and Twitter [ 68,81],\nmost focusing on the presence or prevalence of a single topic. Hitkul\net al.[ 68] examined the Capitol riots\u2014a pivotal event in Parler\u2019s\nhistory\u2014to compare discussions on Parler and Twitter. Other works\nhave analyzed language use on Parler across various topics, such\nas QAnon content [ 13,81] and COVID-19 vaccines [ 12]. Our work\ndiffers in that we specifically study changes within Parler itself,\nfocusing on how users reacted to the platform\u2019s temporary hiatus.\nStudies about Deplatforming: All existing studies on deplat-\nforming examine a defined group of deplatformed users and their\naudiences. Some studies focus on a small number of users (e.g.,\nthree users [ 50]), while others analyze users from specific subred-\ndits (e.g., two subreddits [ 47,86] or 15 subreddits [ 20]) or certain\nTelegram channels [ 72]. Since these users are already deplatformed,\nthese studies focus on how their behavior changed after migrating\nto a new platform. For example, they examine whether activity\nlevels were affected or if there was any change in the use of hate\nspeech [ 8,46,47,69,72,75]. Some studies also track the behavior\nof audiences across the original and new platforms, investigating\nquestions such as whether followers also migrated to the second\nplatform [ 69,72,75] and, if so, whether they became more ex-\ntreme in their language [ 8,46,47]. A common finding across these\nstudies is that deplatforming significantly reduces the reach of de-\nplatformed users; however, it also tends to intensify hateful and\ntoxic rhetoric within their new online spaces.\nWhile most of these studies examine user behavior across plat-\nforms, only a few focus on \u201cwithin-platform\u201d dynamics [ 47,86].\nThese works investigate the deplatforming of a small set of sub-\nreddits on Reddit, analyzing whether and how the deplatformed\nusers migrated to other subreddits within the same platform. In\nother words, even when focusing on \u201cwithin-platform\u201d effects, these\nstudies primarily aim to understand the behavior of a set of deplat-\nformed users and their audiences.\nHate Speech Detection and Classification: Empirical work\non toxicity has employed machine learning-based detection algo-\nrithms to identify and classify offensive language, hate speech, and\ncyberbullying [ 28,67]. Features including lexical properties, such\nas n-gram features [ 60], character n-gram features [ 57], charac-\nter n-gram, demographic and geographic features [ 88], sentiment\nscores [ 29,82], average word and paragraph embeddings [ 31,60],\nand linguistic, psychological, and affective features inferred using\nCausal Insights into Parler\u2019s Content Moderation Shift:\nEffects on Toxicity and Factuality WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nan open vocabulary approach [ 32] have been used to detect hate\nspeech. Google\u2019s Perspective API[ 37] has been widely utilized in\nprior studies[ 7,32,39,44,63,76,78,92] to assess the toxicity of\nonline content. Developed by Jigsaw, the API employs ML models\nto assign toxicity scores to text based on various attributes, such\nas insult, threat, identity attack, and profanity. Despite its wide-\nspread adoption, studies have also critiqued its biases, particularly\nits tendency to over-penalize certain linguistic styles and dialects,\nraising concerns about fairness and reliability in automated moder-\nation [48].\nMedia Bias Fact Check (MBFC): MBFC is widely used to\nassess the credibility and factuality of news sources for downstream\nanalysis [ 18,21,22,27,33,43,54,59,83,89] and serves as ground\ntruth for prediction tasks [ 19,30,40,66,84]. Gruppi et al. [ 41]\nused MBFC service to label websites and the tweets pertaining to\nCOVID-19 and 2020 Presidential elections embedded inside these\narticles. Weld et al. [ 89] analyzed more than 550M links spanning 4\nyears on Reddit using MBFC.\n3 Methodology\nTo address our research questions, we first utilized the existing\nParler data collected before the policy change [ 9] and then devel-\noped a framework for collecting longitudinal data following the\npolicy change. Second, we utilized Google\u2019s perspective API [ 37]\non all the posts to measure various types of toxicity. Third, we\nanalyzed all the links provided in the posts for bias and factuality,\nusing MBFC services. Fourth, we employed Difference-in-difference\n(DiD) model [ 5], a quasi-experimental approach, to measure the\ncausal associations of Parler\u2019s content moderation change on toxi-\ncity attributes . In this DiD analysis, we proposed using data from\nTwitter as a control group to account for a key confounding vari-\nable: offline events. Major and contentious events, such as the U.S.\npresidential election, often drive significant spikes in online activ-\nity and can influence toxicity levels across social media platforms.\nWe hypothesize that similar trends in toxicity may be observed\non Twitter, which did not implement any policy changes during\nthe same period. By comparing these trends with those observed\non Parler, we could assess whether the observed shifts in toxicity\nlevels are unique to Parler\u2019s content moderation adjustments or\npart of broader online dynamics. Therefore, we gathered a sample\nof Twitter data from the same timeframe and analyzed the trends\nbefore and after Parler\u2019s policy changes. This approach allows us\nto isolate the effects of Parler\u2019s policy shifts and draw more robust\nconclusions about their impact on toxicity.\nFinally, we examined factors such as the number of followers,\nfollowing, badge changes, the topics of conversation, and any shifts\nin the biasandcredibility of the URLs being shared.\n3.1 Data Collection\nPre Policy Change Dataset: Aliapoulios et al. [ 9] developed a data\ncollection tool to gather user information from Parler, capturing\ndata from nearly all active users at the time. The study collected\nuser information from over 13.25M users and randomly selected\n4M users for further analysis. For these users, approximately 99M\nposts (or \u201cparleys\u201d) and 85M comments were gathered from August\n1, 2018, to January 11, 2021. In our study, we refer to this datasetas the pre-policy change dataset. We used these 4M users as a seed\ndataset to collect data following the policy changes.\nPost Policy Change Parler Dataset: We obtained the list of\n4M users provided in the pre-policy change dataset for which the\nauthors collected posts and comments [ 10] and used our custom-\nbuild framework to get the content posted by the same users. Using\nour framework, we collected information about the post body, any\nURLs posted, a URL to the location of any media posted, the date\nposted, the number of echoes, and other metadata, such as the\nbadges of the poster. Authors in [ 9] obtained the metadata of 13.25M\nusers, hence we also tried to collect the metadata of these users.\nPost Policy Change Dataset Statistics: From the 4M users,\nwe could collect 17,389,610 parleys from 432,654 active users. Our\ndataset consists of parleys from February 1st, 2021 to January 15th,\n2022. We used the /pages/feed endpoint, which returns the parleys\n(posts) posted by a specific user using their username. Note that,\nthis endpoint is different from the endpoint that is used to collect\nthe 13.25M users\u2019 metadata, and hence we were only able to ob-\ntain 432K users\u2019 parleys. Several users from the initial seed dataset\nof 4M were no longer active. Manually checking these accounts\nwe found that they had either deleted their accounts, or changed\ntheir usernames, or did not post any parley after Parler\u2019s return, or\nswitched to private accounts. Note, we did not include any users\u2019\npost if their account was private. We label them as missing users.\nEven though we are unsure if these users were suspended by Parler\nor they decided to leave Parler, we nevertheless analyzed and com-\npared these users with those that remained active. Since we only\ncollected posts from 432,654 users, we acknowledge that certain\ntrends and analyses conducted might not be accurately reflected on\nthe platform. However, as of January 2022, months after returning\nto the Apple app store, Parler disclosed that they estimate to have\naround 700K to 1M active users [ 3]. This ensures that we have\ncollected a significant part of the data.\nThese parleys (17M) consisted of users posting around 9M links\nand plain text in the body. A majority of these posts were primary\nposts that had no parent. If a parley is an original parley and is not\nan echo of another parley, it is known as a primary post with no\nparent. We collected the full-text body, a URL if a link was shared,\nthe title of the parley, the date of creation, flags for trolling, sensitive\nand self-reported, an upvoted flag, a counter of echoes and likes. We\nnoticed that Parler has a trolling flag, which might be set manually\nby moderators or automatically by the platform.\nWe also tried to collect profile information for 13.25M users\nfrom the pre-policy change dataset. We used the pages/profile/view\nendpoint, that returns the metadata of the user. We found that\n12,497,131 of these users still had a valid Parler account, so we\ncould collect metadata for these users. For a vast majority of the\naccounts, Parler returned the number of followers, the number\nof following, status (account available or deleted), the number of\nand types of badges given to the user, a description of all badges\navailable on Parler at the time of collection, date of parley creation,\nwhether the account is private or public, and also whether the\naccount is being followed by or a follower of the user logged in. A\nminority of profiles have one or more of these fields missing due\nto changes on the Parler platform from when the user created the\naccount and the time of data collection.\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Nihal Kumarswamy, Mohit Singhal, & Shirin Nilizadeh\nTwitter Data Collection: For a comparative baseline, we gath-\nered a sample of Twitter data from the same timeframe and analyzed\nthe trends before and after Parler\u2019s policy changes. To collect the\ndata, we used Twitter V2 API [ 87] and collected posts daily using the\nexact timeline of the datasets. To circumvent the API restrictions,\nwe collected 27K posts daily and restricted the posts to English.\nAfter the data collection was done, we were able to collect 24.16M\nposts for a pre-policy timeline and 9.69M for a post-policy timeline.\nEthical consideration. We only gathered posts from Parler\nprofiles set to public and did not attempt to access private accounts.\nWe used the same backend APIs that a user browser would request\ndata from. We only obtained the random sample from Twitter API\nand did not collect any metadata information about the users whose\nprofiles were set as private.\n3.2 Measuring Toxicity Scores\nWe utilized the Google Perspective API, which is a state-of-the-\nart toxicity detection tool [ 37]. This AI-based tool investigates the\nprovided text and assigns a score between 0 to 1, with a higher\nscore indicating more severity for a particular attribute. We ob-\ntained the following attributes: Severe toxicity ,Profanity ,Identity\nAttacks ,Threats ,Insults ,Toxicity . For our study, we collected the\nlikelihood scores for each attribute. While collecting the scores,\nEnglish was used as the default language for all posts since previ-\nous studies showed us that a large majority of Parler\u2019s userbase\nwas using English as their language of choice to communicate with\nother Parler users [ 9]. Before sending the posts to Perspective API,\nwe pre-processed the posts by removing URLs, hashtags, etc. as\nthese can lead to wrong scores or errors computing the scores by\nthe API. We also pre-processed our Twitter dataset and obtained\nthe scores via Perspective API. While we acknowledge that the\nPerspective API has limitations in detecting toxicity [ 48], prior re-\nsearch has demonstrated its effectiveness in identifying various\nforms of toxic language in generated text [ 62]. Additionally, sev-\neral studies have successfully used the Perspective API for toxicity\ndetection [ 7,32,44,78]. To validate the API\u2019s performance, two\nindependent coders labeled 200 randomly selected Parleys. The\ninter-coder reliability, measured by the Cohen\u2019s Kappa score, was\n0.7, indicating substantial agreement with the Perspective API\u2019s\ntoxicity assessments.\n3.3 Causal Inference\nWe employed a causal inference strategy known as the Difference-\nin-Differences (DiD) model [ 5] to measure the impact of Parler\u2019s\ncontent moderation changes. In our DiD analysis, we assess the\ncausal effect of our dependent variable\u2014toxicity attributes\u2014over\ntime using regression. This is done by comparing two groups: the\ntreatment group (i.e., Parler, where changes in content moderation\npolicies occurred after its return) and the control group (i.e., Twitter,\nwhere no such policy changes took place). It is crucial to account\nfor time in the regression; otherwise, we risk misinterpreting a con-\nsistent trend (increasing or decreasing) as a treatment effect when\nsimply comparing averages before and after the treatment [15].\nTo have a balanced dataset, and since our post-moderation dataset\nspans approximately 11 months, we filtered the pre-moderation\ndataset for 11 months (i.e., February 2020 to January 2021). We alsoemployed the same step for our Twitter dataset. After filtering the\ndata, we clustered the data points based on the day the parley or\nthe tweet was posted. After clustering the data per day, we set the\nPerspective Score for all the tweets\u2019 or parleys\u2019 as 0 if they were\nbelow 0.5, values above or equal to 0.5 and we kept the absolute\nvalue. We choose a threshold of 0.5, because prior research has used\nthis threshold to distinguish if a post is toxic or not [ 7,78]. We then\naveraged the scores per day to get a final score that we passed to\nour DiD regression model. To check the robustness of our method,\nwe ran a regression model, where we did not use a threshold, and\nobtained the same results as we obtained when using the threshold,\nhence our model is robust.\nTo estimate the effect of the content moderation changes, we\nemploy a linear regression model to estimate the impact ( \ud835\udeff) of these\npolicy adjustments following Parler\u2019s return:\n\ud835\udc4c=\ud835\udefd1\ud835\udc47+\ud835\udefd2\ud835\udc43+\ud835\udeff\ud835\udc47 \ud835\udc43+\ud835\udf16 (1)\nIn this model, \ud835\udc4crepresents the toxicity score; \ud835\udc47is a binary vari-\nable indicating the treatment group (=1) and control group (=0);\nand\ud835\udc43is a binary variable indicating whether the observation was\ncollected before (=0) or after (=1) the treatment. We estimate the\ncoefficient \ud835\udeff, which corresponds to the interaction between the\nvariables \ud835\udc47and\ud835\udc43, using Ordinary Least Squares (OLS) to obtain\nthe average treatment effect. \ud835\udefd1captures the difference between\nthe treatment and control groups prior to the changes in Parler\u2019s\ncontent moderation guidelines, \ud835\udefd2reflects the change in the out-\ncome over time for the control group (i.e., Twitter, post-treatment),\nand\ud835\udeffrepresents the effect of Parler\u2019s content moderation policy\nchanges on toxicity levels.\nWe chose the DiD method over Interrupted Time Series (ITS)\nanalysis because DiD is widely recognized in the econometrics\nand causal inference community for handling quasi-experimental\ninterventions [ 14,90]. Additionally, DiD provides a single causal\nestimate (i.e., \ud835\udeff), simplifying the interpretation of results, whereas\nITS generates six separate estimates (three for Parler and three for\nTwitter), making the interpretation more complex.\n3.4 Examining Changes in User Characteristics\nand Content\nTo answer RQ2 and understand if Parler\u2019s moderation change had\nan impact on its user base beyond users\u2019 speech, we performed\nadditional analyses on factors such as the number of followers,\nfollowing, badge changes, the topics of conversation, and any shifts\nin the biasandcredibility of the URLs being shared.\n3.4.1 User Characteristics. We extracted following andfollowers\ncounts from both datasets to understand if any of these metrics\nhave changed significantly after the moderation policy changes.\nSince these variables are not captured in time, and we have two\ndifferent distributions, we cannot perform DiD regression analy-\nsis. The resulting values did not form a normal distribution, so\nwe used the Mann-Whitney test. We also analyzed the number\nof badges assigned to each user in the pre- and post-moderation\nchange datasets.\n3.4.2 Content Analysis. We used textual data collected from Par-\nleys to investigate what users were discussing in both the pre- and\nCausal Insights into Parler\u2019s Content Moderation Shift:\nEffects on Toxicity and Factuality WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\npost-policy change datasets. To identify the most popular topics,\nwe applied the Latent Dirichlet Allocation (LDA) topic modeling\ntechnique [ 17]. Before running LDA, we preprocessed the text by\nremoving all URLs, Unicode characters, and stopwords. We also\nused a stopword corpus from the Natural Language Toolkit (NLTK)\nto filter out common words from our dataset.\n3.4.3 Assessing Bias and Factuality. We examined the links shared\nin Parleys to identify trends and align them with the rhetoric of on-\nline communities, providing a clearer understanding of the changes.\nTo extract external links, we examined every Parley in both the\npre- and post-policy change datasets for valid URLs. We then ex-\ntracted the top-level domain names from each URL and recorded\nthe frequency of each domain\u2019s occurrence to measure website\npopularity in each dataset. Then, we analyzed these links using the\nMedia Bias Fact Check (MBFC) service [ 2]. MBFC is an independent\norganization that uses volunteer and paid contributors to rate and\nstore information about news websites [ 2]. MBFC can be used to\nmeasure the factuality of the URL, the presence of any bias, the\ncountry of origin, and the presence of conspiracy or pseudoscience,\nquestionable sources, and pro-science sources. We used a list of\nlinks shared from both of our datasets to obtain labels for:\nFactuality : Referred to as how factual a website is. Scored be-\ntween 0-5, where a score of 0 means that a website is not factual\nand a five is very factual. MBFC defines that for a website to be\nvery factual and get a score of 5, it should pass its fact-checking\ntest as well as make sure that critical information is not omitted.\nBias : MBFC assigns a bias rating of Extreme left, left, left-center,\nleast biased, right-center, right, and extreme right. To assign a\nbias rating to a website, MBFC contributors check the website\u2019s\nstance on American issues, which divides left-biased websites\nfrom right-biased websites [1].\nPresence of conspiracy-pseudoscience : Websites that publish\nunverified information related to known conspiracies such as the\nNew World Order, Illuminati, False flags, aliens, anti-vaccine, etc.\nUsage of questionable sources : MBFC defines this as a ques-\ntionable source exhibits any of the following: extreme bias, overt\npropaganda, poor or no sourcing to credible information, a complete\nlack of transparency, and/or is fake news. Fake News is the deliber-\nate attempt to publish hoaxes and/or disinformation for profit or\ninfluence .\n4 Results\n4.1 Impact of Stricter Content Moderation\nTable 1 presents the results of our DiD analysis. We observe a causal\nassociation between Parler\u2019s return online and the implementation\nof changes to its content moderation guidelines, leading to signifi-\ncant decreases in Toxicity ,Severe Toxicity ,Profanity ,Threat ,Insult ,\nandIdentity Attack (\ud835\udc5d<0.001). Additionally, our Treatment vari-\nable, which indicates whether Parler and Twitter differed in their\nmoderation effectiveness for each dependent variable prior to the\npolicy changes, shows that, on average, Parler had higher levels of\nToxicity ,Severe Toxicity ,Profanity ,Threat ,Insult , and Identity Attack\ncompared to Twitter ( \ud835\udc5d<0.001). Interestingly, our Post Treat-\nment variable shows that Twitter users\u2019 Threat posts also decreased\n(\ud835\udc5d<0.05). This suggests that there could have been a general trendof reduced threatening posts, which could potentially challenge the\nfindings for Threat on Parler ( \ud835\udeff). However, when examining Insult\nandIdentity Attack , we observed a statistically significant increase\non Twitter ( \ud835\udc5d<0.001), while the opposite trend was observed for\nParler ( \ud835\udeff). This indicates that despite the general decrease in Threat\nposts, the changes to Parler\u2019s content moderation guidelines had a\npositive effect overall, leading to a reduction in abusive content on\nthe platform. Additionally, Table 1 presents the confidence intervals\nfor all our variables. As observed, for all our dependent variables ,\n95% of the time we would expect the effect of DiD (\ud835\udeff) on the var-\nious dependent variables to fall within the respective lower and\nupper bounds. This further demonstrates that the differences in the\nproposed changes are statistically significant, particularly when\nexamining Parler pre- and post-moderation changes.\nTo further disentangle these findings, we plotted the results from\nour DiD model in Figure 1. The red solid line represents \ud835\udeff(i.e., the\nDiD estimate), while the green line indicates when Parler changed\nits content moderation guidelines and returned after its hiatus.\nAs observed, across all attributes, the model reveals a statistically\nsignificant decrease, with the red line ( \ud835\udeff) dropping after the inter-\nvention in Parler. Notably, we can visually identify that Profanity\n(Fig.1c), Severe Toxicity (Fig.1d), and Toxicity (Fig. 1f) exhibit the\nmost significant decreases compared to other attributes. Moreover,\nwe observe that the Twitter pre-intervention time series exhibits\nmuch more variability compared to the post-intervention period.\nWe found that this variability was largely due to the difference in\nthe amount of data collected: 24.16 million posts in the pre-policy\ntimeline versus 9.69 million posts in the post-policy timeline dataset.\nAdditionally, we identified fewer posts that were toxic (i.e., above\nthe 0.5 threshold) in the post-policy dataset. We also note a signif-\nicant peak for all the perspective attributes, except for Profanity ,\naround days 600\u2013620. This spike was attributed to the appointment\nof Jack Smith as the special counsel in the investigations involving\nFormer President Donald Trump [23, 36].\nSummary: In summary, our DiD model revealed a statistically\nsignificant causal association between Parler\u2019s stricter moderation\nguidelines and a decrease across all toxicity attributes. We observed\nthat the Treatment variable (i.e., \ud835\udefd1) was positive for all attributes, in-\ndicating that, on average, Parler users posted more abusive content\nthan Twitter users before the intervention. Additionally, Threat was\nthe only variable that showed a statistically significant decrease\nin both Parler and Twitter. Thus, we can conclude that Parler\u2019s\nchanges to its content moderation policies had a positive causal\neffect in decreasing the toxic and abusive content produced by its\nusers, which directly addresses our RQ1.\n4.2 User Characteristics and Content\n4.2.1 Comparing Users\u2019 Characteristics in Pre- and Post-Policy Change\nDatasets. We employed the Mann-Whitney test and could reject\nthe null hypothesis that users in the pre and post-policy change\ndatasets have the same distribution for followers and followings .\nWe found an increase in the number of followings (\ud835\udc40\ud835\udc52\ud835\udc51 \ud835\udc5d\ud835\udc5f\ud835\udc52=6vs.\n\ud835\udc40\ud835\udc52\ud835\udc51 \ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc61=8) and followers (\ud835\udc40\ud835\udc52\ud835\udc4e\ud835\udc5b \ud835\udc5d\ud835\udc5f\ud835\udc52=20.65vs.\ud835\udc40\ud835\udc52\ud835\udc4e\ud835\udc5b \ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc61=34.8),\n\ud835\udc5d<0.0001, hence indicating that users are still active on Parler.\nTable 3 presents the number of badges assigned to users in the\npre- and post-moderation policy datasets. We observed a significant\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Nihal Kumarswamy, Mohit Singhal, & Shirin Nilizadeh\n0100 200 300 400 500 600 700\nDays0.000.050.100.150.200.250.300.350.40Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention\n(a) Identity Attack\n0100 200 300 400 500 600 700\nDays0.00.10.20.30.40.50.60.7Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention (b) Insult\n0100 200 300 400 500 600 700\nDays0.00.10.20.30.4Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention (c) Profanity\n0100 200 300 400 500 600 700\nDays0.000.050.100.150.200.250.300.35Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention\n(d) Severe Toxicity\n0100 200 300 400 500 600 700\nDays0.00.10.20.30.40.50.60.7Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention (e) Threat\n0100 200 300 400 500 600 700\nDays0.00.10.20.30.40.50.6Average Values Per DayActual (Parler)\nPredicted (Parler)\nT witter\nIntervention (f) Toxicity\nFigure 1: Difference in Difference (DiD) plots for Perspective Attributes. X-axis denotes the days, and y-axis denotes the average\nPerspective API scores.\nTable 1: DiD regression results for toxicity attributes.\nEvent Dependent variable: Toxicity Confidence Intervals\nTreatment 0.1058 (0.000)\u2217\u2217\u2217[0.099, 0.113]\nPost Treatment -0.0028 (0.411) [-0.010, 0.004]\nDiD ( \ud835\udeff) -0.0814 (0.000)\u2217\u2217\u2217[-0.091, -0.072]\nEvent Dependent variable: Severe Toxicity Confidence Intervals\nTreatment 0.1173 (0.000)\u2217\u2217\u2217[0.114, 0.120]\nPost Treatment -0.0024 (0.099) [-0.005, 0.000]\nDiD ( \ud835\udeff) -0.0570 (0.000)\u2217\u2217\u2217[-0.061, -0.053]\nEvent Dependent variable: Profanity Confidence Intervals\nTreatment 0.0691 (0.000)\u2217\u2217\u2217[0.063, 0.075]\nPost Treatment 0.0012 (0.702) [-0.005, 0.007]\nDiD ( \ud835\udeff) -0.0693 (0.000)\u2217\u2217\u2217[-0.078, -0.061]\nEvent Dependent variable: Threat Confidence Intervals\nTreatment 0.1605 (0.000)\u2217\u2217\u2217[0.157, 0.164]\nPost Treatment -0.0044 (0.025)\u2217[-0.008, -0.001]\nDiD ( \ud835\udeff) -0.0414 (0.000)\u2217\u2217\u2217[-0.047, -0.036]\nEvent Dependent variable: Insult Confidence Intervals\nTreatment 0.1479 (0.000)\u2217\u2217\u2217[0.143, 0.153]\nPost Treatment 0.0082 (0.000)\u2217\u2217\u2217[0.004, 0.013]\nDiD ( \ud835\udeff) -0.0820 (0.000)\u2217\u2217\u2217[-0.089, -0.075]\nEvent Dependent variable: Identity Attack Confidence Intervals\nTreatment 0.1282 (0.000)\u2217\u2217\u2217[0.125, 0.131]\nPost Treatment 0.0087 (0.000)\u2217\u2217\u2217[0.006, 0.012]\nDiD ( \ud835\udeff) -0.0382 (0.000)\u2217\u2217\u2217[-0.042, -0.034]\nNote:\u2217p<0.05;\u2217\u2217p<0.01;\u2217\u2217\u2217p<0.001\nincrease in the number of users undergoing Parler\u2019s verification\nprocess to confirm that their accounts were not bots. This sharp rise\nin verified users may reflect concerns about an influx of bots as Par-\nler expanded. Additionally, we found an increase in the number of\nGold badges, suggesting that some users gained enough popularity\npost-moderation changes to qualify for this status. These increases\nindicate that users remained active on the platform following theTable 2: Comparison of Users Characteristics\nPre Policy Change Post Policy Change\nMin Max Mean Median Min Max Mean Median\nFollowers 0 2,300,000 20.65 1 0 6,048,750 34.8 1\nFollowing 0 126,000 28.28 6 0 479,412 33.4 8\npolicy changes. Interestingly, the number of users with the Private\nbadge decreased in the post-moderation dataset. Notably, we did\nnot attempt to collect parleys from users with the Private badge;\nrather, badge information was extracted from user metadata.\n4.2.2 Content Analysis. We observed significant interest in the\n2020 U.S. elections in the pre-policy change dataset, because the\nelections took place during the data collection period [ 10]. Addition-\nally, we noticed a decline in the usage of phrases like Where We Go\nOne, We Go All (WWG1WGA), which is associated with the QAnon\nconspiracy movement. Parler-specific terms, such as Parleys, were\nalso more prevalent in the earlier dataset. Conversely, we observed\nan increased use of the word patriots, a term Republican lawmakers\nused to describe the rioters [53].\n4.2.3 Links Shared in Parleys. From Table 4, we observe a sharp rise\nin the popularity of Rumble links (64%). This increase is likely due to\nRumble\u2019s stance on not removing content related to misinformation\nand election integrity, with MBFC labeling the website as Right\nBiased and Questionable [56,80]. In contrast, we observed a decline\nin the number of Twitter links being shared on Parler. These trends\nmay be attributed to the increasing rhetoric surrounding censorship\non Twitter and other popular social media platforms [ 4]. We also\nobserved a sharp increase in the number of The Blaze links (97%)\nbeing shared. According to the MBFC service, this website is labeled\nasStrongly Right Biased and Questionable [55].\nCausal Insights into Parler\u2019s Content Moderation Shift:\nEffects on Toxicity and Factuality WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nTable 3: Badges assigned to users in the pre and post-policy policy change datasets\nBadge Description Pre Change Post Change\nVerified This badge means Parler has verified the account belongs to a real person and not a bot. Since verified users can change their\nscreen name, the badge does not guarantee one\u2019s identity.25,734 236,431\nGold A Gold Badge means Parler has verified the identity of the person or organization. Gold Badges can be influencers, public\nfigures, journalists, media outlets, public officials, government entities, businesses, or organizations (including nonprofits). If\nthe account has a Gold Badge, its parleys and comments come from real people.589 668\nIntegration Partner Used by publishers to import articles and other content from their websites 64 N/A\nRSS feed These accounts automatically post articles directly from an outlet\u2019s website 99 13\nPrivate If you see this badge, the account owner has chosen to make the account private. This badge may also be applied to accounts\nthat are locked due to community guideline violations596,824 337,717\nVerified Comments Users with a verified badge who are restricting comments to only other verified users. 4,147 N/A\nParody Parler approved parody accounts. 37 N/A\nParler Employee This badge is applied to Parler employees\u2019 personal accounts, should they wish. Their parleys are their own views and not\nParler\u2019s.25 28\nReal Name Users using their real name 2 N/A\nParler Early Signifying Parler\u2019s earliest members, this badge appears on accounts opened in 2018. 81 822\nParler Official These accounts - @Parler, @ParlerDev, and others - issue official statements from the Parler team. N/A 5\nTable 4: Most Popular Websites Shared on Parler\nWebsite Pre Policy Post Policy Change(%)\nimage-cdn.parler.com 7,318,992 1\u221299.99\nyoutube.com 2,499,198 225,562\u221283.44\nyoutu.be 1,812,871 19\u221299.99\nbit.ly 893,603 5\u221299.99\ntwitter.com 803,514 42,638\u221289.92\nmedia.giphy.com 539,389 545\u221299.79\ni.imgur.com 532,365 5,779\u221297.85\nfacebook.com 520,796 318\u221299.87\nthegatewaypundit.com 469,855 610,512+13.01\nbreitbart.com 328,953 240,547\u221215.52\nfoxnews.com 298,285 136,956\u221237.06\ninstagram.com 168,160 22,932\u221275.99\nrumble.com 164,949 744,132+63.71\ntheepochtimes.com 136,294 33,937\u221260.12\nhannity.com 13,017 148,026+83.83\njustthenews.com 50,638 147,984+49.01\nwww.theblaze.com 2,006 122,111+96.76\nwww.westernjournal.com 6,399 119,551+89.83\nbongino.com 17,251 114,334+73.77\nwww.bitchute.com 104,462 87,672\u22128.73\nFurthermore, we analyzed the links shared on Parler using the\nMBFC service. We were able to collect labels for 3,937 (2.59%) and\n1,081 (1.75%) of the total links shared on Parleys from the pre- and\npost-moderation policy change datasets, respectively. However, we\ncould not collect labels for all URLs, as many were from websites,\nsuch as YouTube, Twitter, and Instagram, for which MBFC does\nnot provide labels (see Table 4). Despite this, our results are still\ngeneralizable, as we were able to capture the majority of websites\nfor which MBFC does provide labels, allowing us to assess the\nimpact of the policy change on users\u2019 speech.\nFigure 2 presents our results. We observe a decrease in the num-\nber of conspiracy-pseudoscience news articles, as shown in Fig-\nure 2c. However, interestingly, there is an increase in the number of\nquestionable source articles being shared in the post-policy change\ndataset, as depicted in Figure 2d. This suggests that Parler con-\ntinues to allow URLs spreading overt propaganda and fake news,\nVery Low Low Mixed Mostly Factual High Very High\nLabels0510152025303540Frequency(% of total domains)Post Policy Change\nPre Policy Change(a) Histogram of Factuality Scores\nLeft Left Center Center Right Center Right\nLabels0510152025303540Frequency(% of total domains)Post Policy Change\nPre Policy Change (b) Histogram of Bias\nPre Policy Change Post Policy Change010203040Frequency(% of total domains)\n(c) Histogram of\nConspiracy-Pseudoscience\nPre Policy Change Post Policy Change0.02.55.07.510.012.515.017.520.0Frequency(% of total domains)(d) Histogram of Questionable\nSources\nFigure 2: Histogram of MBFC Labels\naligning with the findings of [ 80]. In Figure 2a, we observe that\nmost links with a score between Very Low andLow are from the\npre-policy change dataset, while post-moderation links are more\nevenly distributed across higher ranges, from Low toHigh . Interest-\ningly, in Figure 2b, we observe that Parler users are sharing more\nURLs from Left Center andRight websites. This is notable, consid-\nering that the majority of Parler users are highly conservative [ 24].\nIn summary, using the labels provided by MBFC, we found that\nthe credibility (factuality) of the URLs being shared did increase.\nAdditionally, there was a substantial decrease in the number of\nconspiracy-pseudoscience news articles. This is particularly inter-\nesting, as in 2022, notable conspiracy theories circulated, such as\nthe claims that mpox (monkeypox) was orchestrated by vaccine\nmanufacturers, that Bill Gates was involved in the outbreak, that it\nwas transmitted solely via sexual interactions, and that the WHO re-\nleased the virus to gain more power [ 6,93]. However, despite these\nshifts, Parler users were now sharing more URLs from questionable\nsources than before.\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Nihal Kumarswamy, Mohit Singhal, & Shirin Nilizadeh\nSummary: We observed a statistically significant increase in the\nnumber of followings after Parler came back online. Additionally,\nwe found that Parler users were more likely to have their accounts\nVerified compared to the pre-moderation change dataset. Interest-\ningly, the term patriots became increasingly prevalent in users\u2019\nposts. We found an increase in the credibility (factuality) of the\nURLs being shared. Moreover, we noticed a substantial decrease in\nthe number of conspiracy and pseudoscience news articles. How-\never, Parler users were sharing more questionable source URLs\npost-moderation than before. These findings indicate substantial\nchanges in Parler users\u2019 behavior, effectively answering our RQ2.\n5 Discussion and Future Work\nOur results indicate a positive impact of the changes to Parler\u2019s con-\ntent moderation guidelines following its ban. Our quasi-experimental\nanalysis revealed that, after the policy changes, all Perspective at-\ntributes experienced a statistically significant decrease ( \ud835\udc5d<0.001).\nAs shown in Table 1, we observed that Severe Toxicity ,Threat , and\nIdentity Attack saw the largest decreases compared to other at-\ntributes. This is particularly interesting as it contrasts with findings\nfrom prior studies, which observed an increase in toxic rhetoric\namong users. In contrast, our research highlights that when Par-\nler adjusted its guidelines, the toxic rhetoric from existing users\nactually decreased. Additionally, using MBFC, we found that the\ncredibility (factuality) of URLs shared by Parler users increased,\nwhich directly contradicts the observations made in [86].\nEffectiveness of moderation policy. Our results demonstrate\nthat stricter content moderation policies can significantly reduce\nthe toxic rhetoric of existing users. However, an important consid-\neration is the migration of some users from Parler to other fringe\nsocial media platforms, such as Rumble, Gab, and Telegram. Stud-\nies have shown that users often become more active on fringe\nplatforms after being deplatformed [ 46], underscoring the need\nfor tailored moderation strategies [ 25,80]. Moreover, the migra-\ntion to fringe platforms can have unintended consequences, with\nsome users exhibiting even more extreme or toxic behavior in these\nspaces [ 47]. This raises the question of how content moderation\ncan be effectively managed across multiple platforms, given the risk\nof users shifting to less regulated environments. Future research\nshould focus on developing coordinated, cross-platform moderation\nstrategies that not only target harmful behavior within individual\nplatforms but also consider the broader ecosystem of social media.\nImportance of this study. To the best of our knowledge, this\npaper is the first study to assess the effectiveness of platform-wide\npolicy changes on all active users present during both the pre- and\npost-policy periods. This inclusive analysis provides a comprehen-\nsive view of the broader ecosystem, as opposed to a limited focus\non deplatformed users or specific audiences. Second, while prior\nresearch primarily examines hard content moderation measures\n(e.g., suspensions or removals), our study focuses on replatform-\ning\u2014 a unique scenario involving the reinstatement of a platform\nunder a series of progressive policy changes. Third, evaluating the\neffectiveness of platform-wide moderation is typically challenging\ndue to limited platform transparency and access to comprehensive\ndatasets. However, the unique context of Parler\u2019s replatforming\nallowed us to use a custom crawler to collect data from all activeusers post-replatforming and to conduct robust comparisons of\nplatform-wide activity and content trends.\nMoreover, this study provides the first-ever Parler dataset fol-\nlowing its replatforming, along with a framework that can be used\nto gather data from Parler. This dataset presents a unique opportu-\nnity for researchers to examine user behavior, interactions, and the\ntopics discussed within a specific group of users who share particu-\nlar ideological or political leanings. It offers valuable insights into\nthe dynamics of online communities with more defined mindsets,\nhelping to deepen our understanding of how content moderation\nand platform policies influence user engagement and discourse.\nFurthermore, Parler was acquired by Starboard in 2023 and tem-\nporarily shut down on the same day [ 70]. However, the platform has\nsince returned online, rebranded as Parler 3.0 [ 65], and implemented\nsignificant changes to its content moderation guidelines [ 64]. As a\nresult, both our dataset and the accompanying framework offer a\nunique opportunity for researchers to assess the evolution of Par-\nler\u2019s policy changes, from its inception in 2018 (Parler 1.0), to the\nfirst major policy overhaul in 2021 (Parler 2.0), and now to the cur-\nrent iteration, Parler 3.0. Additionally, Singhal et al.[ 80] previously\nfound that Parler lacked any form of soft moderation. However,\nwith the introduction of Time Out\u2014a new soft moderation tool\nunder Parler 3.0\u2019s updated guidelines[ 64]\u2014our dataset provides an\nideal resource for studying the effectiveness of this intervention in\nmoderating user behavior.\nLimitations In our current dataset, i.e., the post-policy change\ndataset, we were unable to collect a random sample of users, which\nlimits the generalizability of our analysis and may not fully capture\nthe complete impact of the moderation policy change. Another\nlimitation of our study is that some users may have changed their\nusernames when Parler was reinstated, possibly to evade detection.\nAdditionally, we acknowledge that Google\u2019s Perspective API, used\nfor toxicity detection, has certain limitations and biases [ 61,77,85].\nFurthermore, our work does not account for the impact of users\u2019\nhateful rhetoric when they migrated to other platforms after Par-\nler was taken offline. In future research, we plan to investigate\nuser comments on posts to assess whether the moderation changes\nare reflected in these interactions. Comments may provide addi-\ntional insights into the effects of the moderation changes Parler\nimplemented.\n6 Conclusion\nOn January 12, 2021, Parler was removed from the Apple and Google\nApp Stores, and Amazon Web Services stopped hosting Parler\u2019s\ncontent shortly thereafter. This action was attributed to Parler\u2019s\nrefusal to remove posts inciting violence following the 2021 U.S.\nCapitol riots. Parler was later reinstated after strengthening its\nmoderation policies to address hateful content. Our study inves-\ntigates the impact of these policy changes on user discourse by\ncomparing user rhetoric in pre- and post-policy change datasets.\nOur quasi-experimental analysis shows that, following the modera-\ntion changes, all forms of toxicity experienced a significant decrease\n(\ud835\udc5d<0.001). Additionally, we observed an increase in the factuality\nof the news sites being shared, along with a decrease in the number\nof conspiracy or pseudoscience sources being shared.\nCausal Insights into Parler\u2019s Content Moderation Shift:\nEffects on Toxicity and Factuality WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nAcknowledgments\nThis paper is based upon work supported by NSF CNS 2309318\naward. Any opinions, findings, conclusions or recommendations\nexpressed in this material are those of the author(s) and do not\nnecessarily reflect the views of the National Science Foundation.\nReferences\n[1]2021. Left vs. right bias: How we rate the bias of media sources.\nhttps://mediabiasfactcheck.com/left-vs-right-bias-how-we-rate-the-bias-\nof-media-sources/\n[2] 2022. About MBFC. https://mediabiasfactcheck.com/about/\n[3]2022. From the flag-bearer for free speech to \u2018scapegoat\u2019, Parler is fighting\nback. https://www.thetimes.co.uk/article/from-the-flag-bearer-for-free-speech-\nto-scapegoat-parler-is-fighting-back-bmwcdfgf5.\n[4]Emily A. Vogels, Andrew Perrin, and Monica Anderson. 2020. Most\nAmericans Think Social Media Sites Censor Political Viewpoints.\nhttps://www.pewresearch.org/internet/2020/08/19/most-americans-think-\nsocial-media-sites-censor-political-viewpoints/\n[5]Alberto Abadie. 2005. Semiparametric difference-in-differences estimators. The\nreview of economic studies 72, 1 (2005), 1\u201319.\n[6]ADL. 2022. Right Wing Lies About Monkeypox Target LGBTQ+ Commu-\nnity. https://www.adl.org/resources/article/right-wing-lies-about-monkeypox-\ntarget-lgbtq-community.\n[7]Ana Aleksandric, Mohit Singhal, Anne Groggel, and Shirin Nilizadeh. 2022. Un-\nderstanding the Bystander Effect on Toxic Twitter Conversations. arXiv preprint\narXiv:2211.10764 (2022).\n[8] Shiza Ali, Mohammad Hammas Saeed, Esraa Aldreabi, Jeremy Blackburn, Emil-\niano De Cristofaro, Savvas Zannettou, and Gianluca Stringhini. 2021. Understand-\ning the Effect of Deplatforming on Social Networks. In 13th ACM Web Science\nConference 2021 . 187\u2013195.\n[9]Max Aliapoulios, Emmi Bevensee, Jeremy Blackburn, Barry Bradlyn, Emiliano\nDe Cristofaro, Gianluca Stringhini, and Savvas Zannettou. 2021. An early look\nat the parler online social network. arXiv preprint arXiv:2101.03820 (2021).\n[10] Max Aliapoulios, Emmi Bevensee, Jeremy Blackburn, Barry Bradlyn, Emiliano\nDe Cristofaro, Gianluca Stringhini, and Savvas Zannettou. 2021. A Large Open\nDataset from the Parler Social Network. In Proceedings of the International AAAI\nConference on Web and Social Media , Vol. 15. 943\u2013951.\n[11] Ashley A Anderson, Sara K Yeo, Dominique Brossard, Dietram A Scheufele,\nand Michael A Xenos. 2016. Toxic talk: How online incivility can undermine\nperceptions of media. International Journal of Public Opinion Research 30, 1 (2016),\n156\u2013168.\n[12] Annalise Baines, Muhammad Ittefaq, and Mauryne Abwao. 2021. # Scamdemic,#\nplandemic, or# scaredemic: What parler social media platform tells us about\nCOVID-19 vaccine. Vaccines 9, 5 (2021), 421.\n[13] Dominik B\u00e4r, Nicolas Pr\u00f6llochs, and Stefan Feuerriegel. 2023. Finding Qs: Profiling\nQAnon supporters on Parler. In Proceedings of the International AAAI Conference\non Web and Social Media , Vol. 17. 34\u201346.\n[14] Allen N Berger and Raluca A Roman. 2020. TARP and other bank bailouts and\nbail-ins around the world: Connecting Wall Street, Main Street, and the financial\nsystem . Academic Press.\n[15] James Lopez Bernal, Steven Cummins, and Antonio Gasparrini. 2017. Interrupted\ntime series regression for the evaluation of public health interventions: a tutorial.\nInternational journal of epidemiology 46, 1 (2017), 348\u2013355.\n[16] Michael Bernstein, Andr\u00e9s Monroy-Hern\u00e1ndez, Drew Harry, Paul Andr\u00e9, Katrina\nPanovich, and Greg Vargas. 2011. 4chan and/b: An Analysis of Anonymity and\nEphemerality in a Large Online Community. In Proceedings of the international\nAAAI conference on web and social media , Vol. 5. 50\u201357.\n[17] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.\nJournal of machine Learning research 3, Jan (2003), 993\u20131022.\n[18] Alexandre Bovet and Hern\u00e1n A Makse. 2019. Influence of fake news in Twitter\nduring the 2016 US presidential election. Nature communications 10, 1 (2019), 7.\n[19] Lia Bozarth, Aparajita Saraf, and Ceren Budak. 2020. Higher ground? How\ngroundtruth labeling impacts our understanding of fake news about the 2016 US\npresidential nominees. In Proceedings of the International AAAI Conference on\nWeb and Social Media , Vol. 14. 48\u201359.\n[20] Lorenzo Cima, Amaury Trujillo, Marco Avvenuti, and Stefano Cresci. 2024. The\nGreat Ban: Efficacy and Unintended Consequences of a Massive Deplatforming\nOperation on Reddit. (2024), 85\u201393.\n[21] Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter\nQuattrociocchi, and Michele Starnini. 2021. The echo chamber effect on social\nmedia. Proceedings of the National Academy of Sciences 118, 9 (2021), e2023301118.\n[22] Matteo Cinelli, Walter Quattrociocchi, Alessandro Galeazzi, Carlo Michele Valen-\nsise, Emanuele Brugnoli, Ana Lucia Schmidt, Paola Zola, Fabiana Zollo, and\nAntonio Scala. 2020. The COVID-19 social media infodemic. Scientific reports 10,\n1 (2020), 1\u201310.[23] Zachary Cohen, Scannell Kara, Jeremy Herb, Katelyn Polantz, and Chandelis\nDuster. 2022. Who is Jack Smith, the special counsel named in the Trump\ninvestigations. https://www.cnn.com/2022/11/18/politics/jack-smith-special-\ncounsel/index.html.\n[24] Ben Collins. 2021. Increasingly militant \u2019parler refugees\u2019 and Anxious\nQanon adherents prep for Doomsday. https://www.nbcnews.com/tech/\ninternet/increasingly-militant-parler-refugees-anxious-qanon-adherents-\nprep-doomsday-n1254775\n[25] Stefano Cresci, Amaury Trujillo, and Tiziano Fagni. 2022. Personalized inter-\nventions for online moderation. In Proceedings of the 33rd ACM Conference on\nHypertext and Social Media . 248\u2013251.\n[26] William H Crown. 2014. Propensity-score matching in economic analyses:\ncomparison with regression models, instrumental variables, residual inclusion,\ndifferences-in-differences, and decomposition methods. Applied Health Economics\nand Health Policy 12 (2014), 7\u201318.\n[27] Kareem Darwish, Walid Magdy, and Tahar Zanouda. 2017. Trump vs. Hillary:\nWhat went viral during the 2016 US presidential election. In International confer-\nence on social informatics . Springer, 143\u2013161.\n[28] Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017.\nAutomated hate speech detection and the problem of offensive language. In\nEleventh international aaai conference on web and social media .\n[29] Karthik Dinakar, Birago Jones, Catherine Havasi, Henry Lieberman, and Rosalind\nPicard. 2012. Common sense reasoning for detection, prevention, and mitigation\nof cyberbullying. ACM Transactions on Interactive Intelligent Systems (TiiS) 2, 3\n(2012), 18.\n[30] Yoan Dinkov, Ahmed Ali, Ivan Koychev, and Preslav Nakov. 2019. Predicting\nthe leading political ideology of YouTube channels using acoustic, textual, and\nmetadata information. arXiv preprint arXiv:1910.08948 (2019).\n[31] Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavl-\njevic, and Narayan Bhamidipati. 2015. Hate speech detection with comment\nembeddings. In Proceedings of the 24th international conference on world wide web .\nACM, 29\u201330.\n[32] Mai ElSherief, Vivek Kulkarni, Dana Nguyen, William Yang Wang, and Elizabeth\nBelding. 2018. Hate lingo: A target-based linguistic analysis of hate speech in\nsocial media. In Twelfth International AAAI Conference on Web and Social Media .\n[33] Gabriele Etta, Matteo Cinelli, Alessandro Galeazzi, Carlo Michele Valensise,\nWalter Quattrociocchi, and Mauro Conti. 2022. Comparing the impact of social\nmedia regulations on news consumption. IEEE Transactions on Computational\nSocial Systems (2022).\n[34] Anders Fredriksson and Gustavo Magalh\u00e3es de Oliveira. 2019. Impact evaluation\nusing Difference-in-Differences. RAUSP Management Journal 54 (2019), 519\u2013532.\n[35] Brian Fung. 2021. Parler has now been booted by Amazon, Apple and Google |\nCNN business. https://www.cnn.com/2021/01/09/tech/parler-suspended-apple-\napp-store/index.html.\n[36] Office of Attorney General. 2022. APPOINTMENT OF JOHN L. SMITH AS\nSPECIAL COUNSEL . https://www.justice.gov/d9/press-releases/attachments/\n2022/11/18/2022.11.18_order_5559-2022.pdf.\n[37] Google Perspective API. 2020. https://www.perspectiveapi.com/.\n[38] Lena V Groeger, Jeff Kao, Al Shaw, Moiz Syed, and Maya Eliahou. 2017. What\nParler saw during the attack on the Capitol. Propublica. New York: ProPublica, Inc\n(2017).\n[39] Tommi Gr\u00f6ndahl, Luca Pajola, Mika Juuti, Mauro Conti, and N Asokan. 2018. All\nYou Need is\" Love\" Evading Hate Speech Detection. In Proceedings of the 11th\nACM Workshop on Artificial Intelligence and Security . 2\u201312.\n[40] Maur\u00edcio Gruppi, Benjamin D Horne, and Sibel Adal\u0131. 2021. NELA-GT-2020: A\nlarge multi-labelled news dataset for the study of misinformation in news articles.\narXiv preprint arXiv:2102.04567 (2021).\n[41] Maur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131. 2021. NELA-GT-2020: A\nLarge Multi-Labelled News Dataset for The Study of Misinformation in News\nArticles. doi:10.48550/ARXIV.2102.04567\n[42] Bing Han and Hao Yu. 2019. Causal difference-in-differences estimation for\nevaluating the impact of semi-continuous medical home scores on health care for\nchildren. Health Services and Outcomes Research Methodology 19 (2019), 61\u201378.\n[43] Aarash Heydari, Janny Zhang, Shaan Appel, Xinyi Wu, and Gireeja Ranade. 2019.\nYouTube Chatter: Understanding Online Comments Discourse on Misinformative\nand Political YouTube Videos. arXiv preprint arXiv:1907.00435 (2019).\n[44] Daniel Hickey, Matheus Schmitz, Daniel Fessler, Paul E Smaldino, Goran Muric,\nand Keith Burghardt. 2023. Auditing elon musk\u2019s impact on hate speech and\nbots. In Proceedings of the International AAAI Conference on Web and Social Media ,\nVol. 17. 1133\u20131137.\n[45] Gabriel Emile Hine, Jeremiah Onaolapo, Emiliano De Cristofaro, Nicolas Kourtel-\nlis, Ilias Leontiadis, Riginos Samaras, Gianluca Stringhini, and Jeremy Blackburn.\n2017. Kek, cucks, and god emperor trump: A measurement study of 4chan\u2019s\npolitically incorrect forum and its effects on the web. In Eleventh International\nAAAI Conference on Web and Social Media .\n[46] Manoel Horta Ribeiro, Homa Hosseinmardi, Robert West, and Duncan J Watts.\n2023. Deplatforming did not decrease Parler users\u2019 activity on fringe social media.\nPNAS nexus 2, 3 (2023), pgad035.\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Nihal Kumarswamy, Mohit Singhal, & Shirin Nilizadeh\n[47] Manoel Horta Ribeiro, Shagun Jhaver, Savvas Zannettou, Jeremy Blackburn,\nGianluca Stringhini, Emiliano De Cristofaro, and Robert West. 2021. Do platform\nmigrations compromise content moderation? evidence from r/the_donald and\nr/incels. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2 (2021),\n1\u201324.\n[48] Hossein Hosseini, Sreeram Kannan, Baosen Zhang, and Radha Poovendran. 2017.\nDeceiving google\u2019s perspective api built for detecting toxic comments. arXiv\npreprint arXiv:1702.08138 (2017).\n[49] Greta Jasser, Jordan McSwiney, Ed Pertwee, and Savvas Zannettou. 2023. \u2018Wel-\ncome to# GabFam\u2019: Far-right virtual community on Gab. New Media & Society\n25, 7 (2023), 1728\u20131745.\n[50] Shagun Jhaver, Christian Boylston, Diyi Yang, and Amy Bruckman. 2021. Eval-\nuating the effectiveness of deplatforming as a moderation strategy on Twitter.\nProceedings of the ACM on Human-Computer Interaction 5, CSCW2 (2021), 1\u201330.\n[51] Sayeed Ahsan Khan, Mohammed Hazim Alkawaz, and Hewa Majeed Zangana.\n2019. The use and abuse of social media for spreading fake news. In 2019 IEEE\nInternational Conference on Automatic Control and Intelligent Systems (I2CACIS) .\nIEEE, 145\u2013148.\n[52] Rachel Lerman. 2021. Parler\u2019s revamped app will be allowed back on Apple\u2019s App\nStore. https://www.washingtonpost.com/technology/2021/04/19/parler-apple-\napp-store-reinstate/.\n[53] Bess Levin. 2021. REPUBLICAN LAWMAKERS CLAIM JANUARY 6 RIOT-\nERS WERE JUST FRIENDLY GUYS AND GALS TAKING A TOURIST TRIP\nTHROUGH THE CAPITOL. https://www.vanityfair.com/news/2021/05/capitol-\nattack-tourist-visit.\n[54] Thomas J Main. 2018. The rise of the alt-right . Brookings Institution Press.\n[55] MBFC. 2023. The Blaze \u2013 Bias and Credibility. https://mediabiasfactcheck.com/\nthe-blaze/\n[56] MBFC. 2023. Rumble \u2013 Bias and Credibility. https://mediabiasfactcheck.com/\nrumble/\n[57] Yashar Mehdad and Joel Tetreault. 2016. Do characters abuse more than words?.\nInProceedings of the 17th Annual Meeting of the Special Interest Group on Discourse\nand Dialogue . 299\u2013303.\n[58] Trend Micro. 2017. Fake news and Cyber Propaganda: The use and abuse of\nsocial media. https://www.trendmicro.com/vinfo/pl/security/news/cybercrime-\nand-digital-threats/fake-news-cyber-propaganda-the-abuse-of-social-media\n[59] Matti Nelimarkka, Salla-Maaria Laaksonen, and Bryan Semaan. 2018. Social\nmedia is polarized, social media is polarized: towards a new design agenda for\nmitigating polarization. In Proceedings of the 2018 Designing Interactive Systems\nConference . 957\u2013970.\n[60] Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang.\n2016. Abusive language detection in online user content. In Proceedings of the\n25th international conference on world wide web . International World Wide Web\nConferences Steering Committee, 145\u2013153.\n[61] Gianluca Nogara, Francesco Pierri, Stefano Cresci, Luca Luceri, Petter T\u00f6rnberg,\nand Silvia Giordano. 2023. Toxic bias: Perspective api misreads german as more\ntoxic. arXiv preprint arXiv:2312.12651 (2023).\n[62] Anaelia Ovalle, Palash Goyal, Jwala Dhamala, Zachary Jaggers, Kai-Wei Chang,\nAram Galstyan, Richard Zemel, and Rahul Gupta. 2023. \u201cI\u2019m fully who I am\u201d:\nTowards Centering Transgender and Non-Binary Voices to Measure Biases in\nOpen Language Generation. In Proceedings of the 2023 ACM Conference on Fairness,\nAccountability, and Transparency . 1246\u20131266.\n[63] Antonis Papasavva, Savvas Zannettou, Emiliano De Cristofaro, Gianluca Stringh-\nini, and Jeremy Blackburn. 2020. Raiders of the lost kek: 3.5 years of augmented\n4chan posts from the politically incorrect board. In Proceedings of the International\nAAAI Conference on Web and Social Media , Vol. 14. 885\u2013894.\n[64] Parler. 2024. Community Guidelines: User Commitment and Content Stan-\ndards. https://help.parler.com/en/hc/90853520/40/community-guidelines-user-\ncommitment-and-content-standards?category_id=33.\n[65] Parler. 2024. Parler 3.0. https://parler.com/.\n[66] Victoria Patricia Aires, Fabiola G. Nakamura, and Eduardo F. Nakamura. 2019.\nA link-based approach to detect media bias in news websites. In Companion\nProceedings of The 2019 World Wide Web Conference . 742\u2013745.\n[67] Georgios K Pitsilis, Heri Ramampiaro, and Helge Langseth. 2018. Detecting\noffensive language in tweets using deep learning. arXiv preprint arXiv:1801.04433\n(2018).\n[68] Avinash Prabhu, Dipanwita Guhathakurta, Mallika Subramanian, Manvith Reddy,\nShradha Sehgal, Tanvi Karandikar, Amogh Gulati, Udit Arora, Rajiv Ratn Shah,\nPonnurangam Kumaraguru, et al .2021. Capitol (Pat) riots: A comparative study\nof Twitter and Parler. arXiv preprint arXiv:2101.06914 (2021).\n[69] Adrian Rauchfleisch and Jonas Kaiser. 2021. Deplatforming the far-right: An\nanalysis of YouTube and BitChute. Available at SSRN (2021).\n[70] Reuters. 2023. https://www.reuters.com/markets/deals/parler-shut-down-\ntemporarily-after-starboard-buys-social-media-platform-2023-04-14/.\n[71] Manoel Horta Ribeiro, Shagun Jhaver, Savvas Zannettou, Jeremy Blackburn, Emil-\niano De Cristofaro, Gianluca Stringhini, and Robert West. 2020. Does PlatformMigration Compromise Content Moderation? Evidence from r/The_Donald and\nr/Incels. arXiv preprint arXiv:2010.10397 (2020).\n[72] Richard Rogers. 2020. Deplatforming: Following extreme Internet celebrities to\nTelegram and alternative social media. European Journal of Communication 35, 3\n(2020), 213\u2013229.\n[73] Candace Rondeaux, Ben Dalton, Cuong Nguyen, Michael Simeone, Thomas\nTaylor, and Shawn Walker. 2022. Parler and the Road to the Capitol At-\ntack. https://www.newamerica.org/future-frontlines/reports/parler-and-the-\nroad-to-the-capitol-attack/. (2022).\n[74] Mike Rothschild. 2021. Parler wants to be the \u2019free speech\u2019 alternative to Twit-\nter. https://www.dailydot.com/debug/what-is-parler-free-speech-social-media-\napp/\n[75] Giuseppe Russo, Luca Verginer, Manoel Horta Ribeiro, and Giona Casiraghi.\n2023. Spillover of antisocial behavior from fringe platforms: The unintended\nconsequences of community banning. In Proceedings of the International AAAI\nConference on Web and Social Media , Vol. 17. 742\u2013753.\n[76] Nazanin Salehabadi, Anne Groggel, Mohit Singhal, Sayak Saha Roy, and Shirin\nNilizadeh. 2022. User Engagement and the Toxicity of Tweets. doi:10.48550/\nARXIV.2211.03856\n[77] Maarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and\nNoah A. Smith. 2022. Annotators with Attitudes: How Annotator Beliefs And\nIdentities Bias Toxic Language Detection. In Proceedings of the 2022 Conference\nof the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies , Marine Carpuat, Marie-Catherine de Marneffe,\nand Ivan Vladimir Meza Ruiz (Eds.). Association for Computational Linguistics,\nSeattle, United States, 5884\u20135906. doi:10.18653/v1/2022.naacl-main.431\n[78] Martin Saveski, Brandon Roy, and Deb Roy. 2021. The structure of toxic conver-\nsations on Twitter. In Proceedings of the Web Conference 2021 . 1086\u20131097.\n[79] Mohit Singhal, Nihal Kumarswamy, Shreyasi Kinhekar, and Shirin Nilizadeh.\n2023. Cybersecurity Misinformation Detection on Social Media: Case Studies on\nPhishing Reports and Zoom\u2019s Threat. In Proceedings of the International AAAI\nConference on Web and Social Media , Vol. 17. 796\u2013807.\n[80] Mohit Singhal, Chen Ling, Pujan Paudel, Poojitha Thota, Nihal Kumarswamy,\nGianluca Stringhini, and Shirin Nilizadeh. 2023. SoK: Content moderation in\nsocial media, from guidelines to enforcement, and research to practice. In 2023\nIEEE 8th European Symposium on Security and Privacy (EuroS&P) . IEEE, 868\u2013895.\n[81] Andrea Sipka, Aniko Hannak, and Aleksandra Urman. 2022. Comparing the\nLanguage of QAnon-related content on Parler, Gab, and Twitter. In 14th ACM\nWeb Science Conference 2022 . 411\u2013421.\n[82] Sara Sood, Judd Antin, and Elizabeth Churchill. 2012. Profanity use in online com-\nmunities. In Proceedings of the SIGCHI Conference on Human Factors in Computing\nSystems . ACM, 1481\u20131490.\n[83] Kate Starbird. 2017. Examining the alternative media ecosystem through the\nproduction of alternative narratives of mass shooting events on Twitter. In Pro-\nceedings of the International AAAI Conference on Web and Social Media , Vol. 11.\n230\u2013239.\n[84] Peter Stefanov, Kareem Darwish, Atanas Atanasov, and Preslav Nakov. 2020.\nPredicting the topical stance and political leaning of media using tweets. In\nProceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics . 527\u2013537.\n[85] Nathan TeBlunthuis, Valerie Hase, and Chung-Hong Chan. 2023. Misclassification\nin Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes\nWe Can! arXiv preprint arXiv:2307.06483 (2023).\n[86] Amaury Trujillo and Stefano Cresci. 2022. Make reddit great again: assessing\ncommunity effects of moderation interventions on r/the_donald. Proceedings of\nthe ACM on Human-computer Interaction 6, CSCW2 (2022), 1\u201328.\n[87] Twitter. 2022. Twitter API. https://developer.twitter.com/en/docs/twitter-api\n[88] Zeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predic-\ntive features for hate speech detection on twitter. In Proceedings of the NAACL\nstudent research workshop . 88\u201393.\n[89] Galen Weld, Maria Glenski, and Tim Althoff. 2021. Political Bias and Factualness\nin News Sharing across more than 100,000 Online Communities. ICWSM (2021).\n[90] Longqi Yang, David Holtz, Sonia Jaffe, Siddharth Suri, Shilpi Sinha, Jeffrey Weston,\nConnor Joyce, Neha Shah, Kevin Sherman, Brent Hecht, et al .2022. The effects\nof remote work on collaboration among information workers. Nature human\nbehaviour 6, 1 (2022), 43\u201354.\n[91] Savvas Zannettou, Barry Bradlyn, Emiliano De Cristofaro, Haewoon Kwak,\nMichael Sirivianos, Gianluca Stringini, and Jeremy Blackburn. 2018. What is gab:\nA bastion of free speech or an alt-right echo chamber. In Companion Proceedings\nof the The Web Conference 2018 . 1007\u20131014.\n[92] Savvas Zannettou, Mai ElSherief, Elizabeth Belding, Shirin Nilizadeh, and Gi-\nanluca Stringhini. 2020. Measuring and Characterizing Hate Speech on News\nWebsites. In 12TH ACM WEB SCIENCE CONFERENCE . ACM.\n[93] Marco Zenone and Timothy Caulfield. 2022. Using data from a short video social\nmedia platform to identify emergent monkeypox conspiracy theories. JAMA\nNetwork Open 5, 10 (2022), e2236993\u2013e2236993.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Impact of Stricter Content Moderation on Parler's Users' Discourse", "author": ["N Kumarswamy", "M Singhal", "S Nilizadeh"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2310.08844", "abstract": "Social media platforms employ various content moderation techniques to remove harmful,  offensive, and hate speech content. The moderation level varies across platforms; even over"}, "filled": false, "gsrank": 290, "pub_url": "https://arxiv.org/abs/2310.08844", "author_id": ["KiZgYGoAAAAJ", "8MNR5Y8AAAAJ", "UaSo4BoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:8n28BNz7ua0J:scholar.google.com/&output=cite&scirp=289&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D280%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=8n28BNz7ua0J&ei=NrWsaNekOvnSieoPxKLpgQ0&json=", "num_citations": 3, "citedby_url": "/scholar?cites=12518313561643843058&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:8n28BNz7ua0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2310.08844"}}]