[{"title": "Propaganda-based Classification of Arabic Newspapers", "year": "2019", "pdf_data": "Propaganda-based Classification of Arabic Newspapers\nPropaganda-based Classification of Arabic Newspapers\nWafa Saeed Murshid Al-Ziyadi\nItem type\nItem type\nThesis\nTerms of use\nTerms of use\nThis work is licensed under a \nIn Copyright\n license\nThis version is available at\nThis version is available at\nhttps://manara.qnl.qa/articles/thesis/Propaganda-based_Classification_of_Arabic_Newspapers/28471154/1\nAccess the item on Manara for more information about usage details and recommended citation.\nPosted on Manara \u2013 Qatar Research Repository on\nPosted on Manara \u2013 Qatar Research Repository on\n2019-05-07\n  \n \nHAMAD BIN KHALIFA UNIVERSITY  \n \nCOLLEGE OF HUMANITIES AND SOCIAL STUDIES  \n \nPROPAGANDA -BASED CLASSIFICATION  \nOF ARABIC NEWSPAPERS  \n \n \nBY \n \n \nWAFA SAEED MURSHID AL -ZIYADI  \n \n \nA Project  Submitted to the Faculty of  \nCollege of Humanities and Social Studies  \nIn Partial Fulfillment  \nof the Requirements  \nfor the Degree of  \nMaster of Science  \n \nJune 2019  \n\u00a9 Wafa Saeed Al -Ziyadi .  All Rights Reserved  \n\u0003\n\u0003\n\u0003\n\u0003\nProQuest Number:\n\u0003\n\u0003\n\u0003\n\u0003\nAll rights reserved\n\u0003\nINFORMATION TO ALL USERS\nThequality of this reproduction is dependent upon thequality of the copy submitted.\n\u0003\nIn the unlikely event that  the author did not send a complete manuscript\nand  there  are missing pages, these will be noted. Also, if material had  to be removed,\nanote willindicate the deletion.\n\u0003\n\u0003\n\u0003\n\u0003\u0003\nProQuest\n\u0003\nPublished  by ProQuest LLC (  ). Copyright of the Dissertation is held  by the Author.\n\u0003\n\u0003\nAll rights reserved.\nThiswork is protected against unauthorized copying under  Title 17, United  States Code\nMicroform Edition \u00a9 ProQuest LLC.\n\u0003\n\u0003\nProQuest LLC.\n789 East Eisenhower Parkway\nP.O. Box 1346\nAnn Arbor,  MI 48106 -13461381438513814385\n2019\niiii\n \n iii ABSTRACT  \nIn this project, we explore the  factuality of and the bias of Arabic news media. We \nemploy  a quantitative measure of political leaning and bias of a set of the most \npopular newspapers in the Middle East and North Africa. Previous studies have \nfocus ed on classifying the news based on a single factor, for examp le, fake/true news. \nIn this project, we  analyze and characterize most of the well -known Arabic \nnewspapers based on multiple factors of political polarization such as Islamist, liberal, \npro-government, independent, \u2026 etc. The labels that are assigned to eac h newspaper \nhave been collected from three reliable sources, namely; (i) Media Bias/Fact Check  \n(MB/FC); (ii) Wikipedia (Arabic); and (iii) Wikipedia English. The labels from the \nthree sources are aggregated to get a reliable and accurate classification of the Arabic \nnewspapers. Our findings will be used to build a media bias tool that allows the user \nto get the political polarization of any given Arabic newspaper .   \n  \n \n iv TABLE OF CONTENTS  \nLIST OF TABLES ............................ .............................. .................................... .................................. v   \nLIST OF FIGURES ................................ .............................. .............................. ................. ................ vi   \nACKNOWLEDGMENTS ......................... .............................. ......................... .................. ................vii   \nDEDICATION ....................................................................................................... ................. ............. vii  \nCHAPTER 1: Introduction  ............................... ..................................... ............................... ........... 2  \n     1.1 Background  .................................................................... ............................. ................ ........... 2   \n     1.2 Preliminaries ............................................... ................................. ............. .......... ................ ... 3  \n              1.2.1 Political Polarization  ................................................... ......... ................... .............. 3   \n             1.2.2 Political Ideology ................................. ................................... ................................... 4   \n             1.2.3 Media Bias  ................................................ ....................... ............. ........................... .... 4  \nCHAPTER 2: Related Work  ............................... .................... ............................... .............. ............5  \n2.1 Related Researches  ........................... ................. ........................... ......................................5  \n2.2 Related Projects  ............................ .................................................... .................... ............. ...8 \nCHAPTER 3: Me thodology  ............................... ................... ........................... ......................... .... 10 \n3.1 Collecting the data  ............................ .................................................... ............ .................10 \n3.2 Norma lizing The Labels  ............................ .................................................... .................. 12 \nCHAPTER 4: Results and Discussions ........................... ................. ................................ ......... 15 \nCHAPTER 5: Limitations and Difficultie s................ ................ ............................................... 18 \nCHAPTER 6: Conclusion and Future Work ............ ....................... .............. .................... .......20  \nReferences  ............................ .............................. ............... ..................... .................................... ......... 21 \n \n  \n \n v  \nLIST OF TABLES  \n \nTable 1 The frequency of languages of newspapers ................................ ............... ............. ...11 \nTable 2  The Normalizing Labels Process .......................... ................................... ................... ..13 \nTable 3  The Number of Printed Newspapers of Each Country in The Study  ...............15 \nTable 4  The Frequency of the Labels  ................................. ................................................. .......16 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n vi LIST  OF FIGURES  \n \nFigure 1 Arabic -Prints Spreadsheet ........................................... ............................................. .....12  \nFigure 2  The Frequency of the Labels That Describes the Newspapers  ........... ..............17  \n \n \n \n \n vii ACKNOWLEDGMENTS  \n \nI would like to thank everyone who helped and supported me during this work \nespecially my supervisor, Wajdi Zaghouani . \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n viii DEDICATION  \n \n \nTo my mum who  taught me to love school , despite  not having access to education . \n \nTo my father who showed me that the knowledge I have is the only thing , I should be \nproud of . \n \nTo my small family, the cave of light that provides me with love and warmth to help \nme survive . \n \nTo my sisters and br others, the pillars that I lean on when my legs get weak.  \n \nTo my friends who make this world\u2019s colors look more vibrant . \n \nTo those who are proud of my degree, even more , than I am.  \n \nTo all of them, I dedicate this humble project.  \n \n  \n \n \n  \n \n 2 CHAPTER 1 : INTRODUCTION  \n1.1 Background  \nPropaganda can be defined as misleading information broadcasted through a given \nmedium to influence people towards specific opinion. Most of the time, it is used to \npromote a political agenda. Propaganda is common in the media. Media use multiple \ntechniques to promote their  agenda, which include selective use of information, \nrepeatability, and concentration on a specific portion of the story and censorship of \nimportant facts. In a few cases, the propaganda of a media source reflects the beliefs of \nthe workers as people have different views of what is happening in the world. In short, \nthe different propaganda of the media sources allows them to survive and coexist.  \nPromoting the propaganda of the ruling authorities in Arabic media is not optional. \nMedia in the Arabic world fac e many challenges and complex problems as a result of the \ndomination of government agencies on the media. Most of the ruling authorities in the \nArab world have intentionally limited the freedom of people\u2019s opinions and apply strict \ncontrol on media institu tions, whether they are TV channels, newspapers or social media. \nBecause of the fact that the Arab world suffers from many confl icts, some reports show \nthat press freedom in this r egion has declined (Street, 2010). Many journalists and media \nprofessionals were victims of harassment, threats, and accusations by governments. \nRuling authorities adapt laws to exercise a complete supervisory role on the media and \ndetermine the allowed freedom of opinion. They prosecute and arrest any political \nopponents or media  professionals who have different opinions than the government. \nTherefore, because the political polarization weakens democracy, it is important to \ndetermine to what extent these newspapers, publishing houses, editors and writers get \ninfluenced by this pre ssure.  \n \n 3 This project is important as it tries to find the school of thoughts of most Arab \nnewspapers , such as  political polarization, med ia bias, and political ideology . Knowing \nthese affiliations of the sources that we get the news from will prevent us from being \ncaught in the trap of prejudice and exaggeration of emotions and reactions. Also, it will \nallow  us to detect  biased, politicized and unnatural  or irrational an alysis of some of the \nevents that abound in the region. Hence, we will be wary of the source from which we \nreceive the news.  \nThis project is a result of the collaboration between HBKU and QCRI. It aims to \nunderstand the  Arabic newspapers  bias if exists , which is unique and not found in \nprevious works especially in the Middle East and North Africa ( MENA ) region.  \nIn this project, we focus on Arabic new spapers . We follow an empirical method to \nclassify most of the Arabic newspapers and to identify the political or religious bias for \neach one. The findings of this project will help us to generate a unique tool for \ncharacterizing Arabic newspapers in which the pu blic can easily use this tool.    \n1.2. Preliminaries  \n1.2.1 Political Polarization   \nIn politics, polarization refers to the cases in which people's judgment is determined by \nthe political party they support or by the ideology that they believe in. It could refer also \nto divergence in public opinion or even within specific  groups. Polariza tion happens  \nwhen public follow one of two opposing views without a moderate view in between . \nIn (DiMaggio, Evans & Bryson, 1996), Polarization can be seen both as a state and as a \nprocess. The first type of polarization could be defined as the extent at which opinions are \nopposed to some theories on a given issue . The second type  increases the opposition \nbetween the different opinions over time.  Palonen (Palonen, 2009), considered the \n \n 4 polarization as a political articulated tool in order t o dema rcate boundaries between \u201cus\u201d \nand \u201c them \u201d and to stake out societies seen as moral orders. He defined polarization as a \nsituation in which two societies create each other through the definition of the boundaries \nbetween them.  \n \n1.2.2 Political Ideology  \nThe ideology is what we think and believe in and the way we see the world. Therefore, \nideology is a bunch of values that affect our view of the world. The political ideology has \nbeen defined as a set of opinions on the role of the government and p olitics. A political \nideology is determined by the consistency of a range of issues.  \n \nFormally, political ideologies have been represented as systems for political thoughts. \nThose ideologies such as liberalism, Marxism, fascism, and conservatism have texts  that \nproduce elaborate explanations of economic, social, and political arrangements and \ndevelop prescriptions for political works (Feldman, 2013).  \n \n1.2.3 Media Bias \nThe word \u201cbias\u201d could be defined as the fact of giving an unfair inclination toward \nsomeone or something . There are several types of media bias techniques (Allen, 2015). \nThe most common ones are biased by omission, bias by the selection, and bias by story \nplacement. Whereas bias by omission refers to the case when media ignore one side of  \nthe story, bias by selection refers to the cases of selecting the source of the story or \nselecting the story itself to be highlighted. In story placement  bias, media select stories to \nbe told first or to have a more visible place in the newspaper such as the cover page. \nMedia bias serves to promote either political or ideological agendas.  \n \n 5  \nMedia bias serve s either political or ideological agendas. Here , we discuss the \nideolog ical agenda and how newspaper s affect the reader \u2019s opinion in a particular \ndirection. In very simple words, media bias refers to an unjustifiable inclin ation of the \nmedia as they convey  the news. When t he media transfer biased news , that news  affect \nthe readers' judgment to have unbalanced, inaccurate, an d/or unfair opinion of the world \n(Levasseur, 2008).  \nAccording to Hawkins, media bias refers to the way in which journalists in print and \nmedia deliberately - and sometimes not deliberately - report or cover stories such that \nthese stories are favorable to one side and unfavorable to the other. Journalists who \nexpress themselves as unbiased writers, their biases could be presented by delivering one \nside of the story (Hawkins, 2018).  \nCHAPTER 2: RELATED WORK  \nIn this chapter, we discuss the related work  to classify  newspapers based on their bias. \nWe start by discussing the research papers and books that studied the media . After that, \nwe discuss the different projects that can be used to help the reader discover the bias in \nthe media.  \n2.1 Related Research  \nThe Middle East and North Africa (MENA) region is strategically located in the global \nsystem and clearly highlights the geopolitical dimension of this region. At the same time, \nMENA  is an unstable area and full of events and daily variables. Hence , it is full of news \nand rumors. It is expected that there will be many studies that attempt to discriminate  \nnews coverage in this region in terms of credibility, political affiliation, bias , etc. \n \n 6 The book  \u201cArab media: Globalization and emerging media industries \u201d, by (Mellor, \nRinnawi, Dajani, & Ayish, 2011) , provides a reliable and clear background of the current \nArab media industry in term of globalization and their impact. The authors focus on the \npress, publishing, cinema, broadcasting, and new media. The book discu sses the \neconomics and the regulation of them. The authors claim that the Arab media has been \nreorganized based on the technological, political, and cultural changes on the global \nmedia.  The book gives a general overview of the media industry and discusses its \nimplications. However,  this book  talks about the Arab media from a very specific angle , \nwhich is the issue of political affiliations and bias.  \nAnother book by Sak r (Sakr, 2007) explores the political movements and enterprises that \nemerged recently in the region in term of media developments. The book gives answers to \nsome raised questions about the connections between political changes and the media in \nthe Arab world. It studies the interacti on between journalists, Internet users, and \nproducers of reality TV. Moreover, it investigates what affects public opinion at the polls \nand on the streets.           \n In the new Arab media book (Zweiri, Murphy, 2012), the authors  give an important \noverview and precious analysis for some of the most critical issues that belong to the new \nmedia in the Middle East. The book investigates the role of the media and how it \nintroduces the Middle East to the rest of the world.  \nThere are al so some researches with limited coverage for particular countries in the \nregion like \u201cMedia practice in Iraq\u201d. This book investigates the role of the media in Iraq  \nfrom its beginning until 2010. It focuses on Iraqi media and its effects on the public \nespec ially after 2003.  (Al-Rawi, 2012).  \n \n 7 Also , Webb in his book \u201cMedia in Egypt and Tunisia\u201d explores the media in Egypt and \nTunisia in the period before Arab uprising. It also discusses how the m edia adapt to \npolitical changes (Webb, 2014).  \nPotthast  examines the fake news and the hyper -partisan news by analyzing and \ncomparing their styles  (Potthast, Kiesel, Reinartz, Bevendorff & Stein, 2017) .  \nThere are a few publications that try to classify the political ideology of news outlets. For \nexample, a rec ent study by Baly that predicts the bias in news media (Baly, Karadzhov, \nAlexandrov, Glass & Nakov, 2018).  \nAnother study by a group of authors (Kulkarni, Ye, Skiena & Wang, 2018) tried to know \nthe ideology displayed by a news article and not the whole newspaper.  This study \ndetected the ideology of news articles and hence estimate the ideological leaning of \nsources as a whole. Unlike our project which uses a large and diverse dataset of about \nmore than 160 sources, this study conducted on only 50 sources . \nIyyer et. al. (Iyyer, Enns, Boyd -Graber, & Resnik, 2014) created a very technical way to \nidentify the political ideology of a newspaper. This method has been applied on a limited \nscale which is the phrase level.  \nThere are also publications that tried to identify the political polarization over social \nmedia, particularly Twitter. For example, a study has been conducted by Pietro explored \nthe political ideology of the users of a specific platform in order to classify the users to \ngroups for politic al purposes (Preo\u0163iuc -Pietro, Liu, Hopkins, & Ungar, 2017).  \n \n 8 Prior  (Prior, 2013)  in his article  tried to explore if the hyper -partisan media contributes to \npolitical polarization , hence changes public opinion and he assumed that it has no real \neffects on the people's opinion.  \nHong & Kim have explored to what extent  social media platforms contributes  to political \npolarization. their study showed strong evidence that there is a clear polarization on \nTwitter users (Hong & Kim, 2016).  \nIn another study  (Conover, Ratkiewicz, Francisco, Gon\u00e7alves, Menczer, & Flammini, \n2011) , the authors investigated the rol e of social media platforms in promoting \ncommunication between different societies with  different political leanings. They \nexplained the possibility of using these platforms to orient the groups of users who have \nopposing political ideologies.  \nThe last stu dy that we discuss in this Section is from the Middle East . This study worked \non a dataset from the social media platform, Twitter, in two languages, Arabic and \nEnglish to study Islamist and secular polarization. To fulfill that goal, it studied the tweets \nof a particular group of users to determine the ideological  orientation of that group. \n(Weber, Garimella, & Batayneh, 2013).  \n2.2 Related Projects  \nIn this section, we discuss related projects that target annotating the different media based \non their agenda.  \n2.2.1 Media Bias/ Fact check . It is the most known media bias resource on the Internet. \nIts dataset con tains over 2600 media sources (Media Bias/Fact Check , 2019). Even \nthough  this project covers most of the famous international newspapers, it does not \n \n 9 include sources from the MENA r egion. Moreover, it classifies media sources based on  \nonly one ideology factor, which is determining whether the source is \u201cLeft\u201d or \u201cRight\u201d.  \n2.2.2 All Sides Media Bias Ratings . This project helps the readers to identify different \nperspectives regarding the media sources. Its dataset covers over 600 media outlets and \nwriters (\"All Sides Media Bias Ratings\", 2019). Although it offers information about the \npolitical leanings of many  media sources, All Sides has built its analysis based on the \nwriters and the outlets in the American community only. Moreover, it does not provide \ninformation about the content of the prints . \n 2.2.3 Tanbih . It is another application that tries to determine the political ideologies for \nwell-known newspapers from all over the world. It tries to predict the possibility of a \nnewspaper to deliver fake news or not. It checks some Arab newspapers' ideologies if \nthey are left or right.  \nDespite the good coverage of some Arab newspapers, it lacks the classification of Arab \nnewspapers in terms of more important ideologies in this region of the world.  \nLooking at previous studies, we observed  two types of studies. The first type discusses \nthe reality of the media in the Arab world as an industry and focuses on it from multiple  \nangles. It did not try to classify media from any perspective.  The second type of studies or \nprojects discuss the class ification of the media but those studies are limited because of the \nareas they cover. They either are confined to areas other than the Arab region or use \nlabels that do not match with the Arab reality.  \nOur study is unique since  it tries to classify the media in the entire Middle East. It will \nfocus on one type of media, namely, newspapers. Moreover,  it will try to classify those \nnewspapers in terms of their political affiliation  and based on multiple ideological factors .  \n \n 10  CHAPTE R 3: METHODOLOGY  \nThis project explores the bias in the news coverage in the Arab region. The goal of this \nproject  is to try to investigate the political polarization of Arab newspapers. This project \nconsists of two sides, a theoretical and a n empirical side. Therefore, its type is a \nqualitative and quantitative  analysis  at the same time.  \nIn the qualitative part, we will try to explain some of the terms that will be used in the \npaper for this project. Those terms are political polarization, media b ias, and political \nideology. Many primary and secondary sources have been used to collect information. \nPublications, conference papers, books, and articles from scientific journals are used as \nprimary sources. Secondary sources such as online websites, mag azines , and articles from \nexperts in this field are used to get more accurate and more detailed analysis information \nfor a better understanding of the topic.    \nFor the quantitative part of this project, we have to follow an approach that consists of \ntwo d ifferent stages : (i) collecting the data, and (ii) normalizing the labels. Each stage had \nits own approach and timeline that I follow and stick on it.  \n3.1 Collecting the Data  \nFor this study, we collected a sample of 162 newspapers  from 19 countries from all \naround the MENA region.  We covered prints between 1990 and 2019, which are still \nongoing. We were more focused on prints that emerged after the Arab Spring.  \nWe collected newspapers that distribute in the MENA region in several different  \nlanguages, most of them are Arabic and English followed by French and Armenian and \nfinally Kurdish.  Some newspapers have more than one version, in different languages, \nand both versions of the same newspaper included in the dataset for this project. \nThere fore, the total number of newspapers in table 1 is bigger than the actual dataset.  \n \n \n 11  \nTable 1. The frequency of languages  of newspapers  \nLanguage  Frequency  Country  \nArabic  112 MENA region  \nEnglish  39 MENA region  \nFrench  19 North Africa, Lebanon  \nArmenian  3 Lebanon  \nKurdish  1 Iraq \nTotal  174  \n \nWe have collected most of the prints distributed in the Arab world including major news \nmedia  with a  big number of readers, and those that reflect the minorities and represent \ntheir political and social voice.  \nWe have followed a certain sampling strategy. We started collecting data from the \nArabian Peninsula  then we collected it from North Africa to ensure covering the entire \nregion. First, we focused on all prints in a certain country (A) and do not cover a print \nfrom another country (B) until it is confirmed that we have completed covering all prints \nin this country  (A). Then we move on to the neighboring country,  and so on till we \ncovered all the region.  \nWe arranged the data we obtained in an Excel spreadsheet. Each row in this document - \neach entry - represents a single Arabic newspaper. The columns represent two types of \ndata. The first type is the features of this newspaper, such as the l anguage and the country \nin which it is distributed, and information about the political affiliation of the newspaper. \nThe second type of those columns is the sources from which we obtained information \nregarding the newspaper's policies or strategy of deliv ering and analyzing the news \n(Figure 1 ). \n \n 12  \nFigure 1 . Arabic -prints spreadsheet.  \nFrom the figure above , we clearly see the names of the Arabic prints on the left side as \nentries for this table. To the right of the newspaper's name are its website, its language \nand its country. Then we see the name of the first source of information about this print. \nThis si te is the Media Bias Fact Check. Next, there are two columns, the first column is \nfor the page\u2019s URL of the newspaper on this site and the other column for its political \norientation. If the information is available, then it is included in the table. Otherw ise, the \ncell is filled with a symbol (N/A) which means not available.  \nWe then move on to the second source, the Wikipedia encyclopedia in English. The \nnewspaper is examined in this site, but, in this case, we have added another column to \ndifferentiate whe ther we have obtained information from the text written on the page of \nthe newspaper on this site or from the quick -access information box on the same page.  \nFinally, the newspaper is tested in the third source, the Arabic Wikipedia site. Also, we \nget the i nformation from both, the text and the quick -access information box. As thus, all \nprints were examined and the information obtained and arranged in the table.  \n \n3.2 Normalizing  the Labels  \n \nThis is the second stage of this project. In the first stage, the collecting data stage, we \nobtained more than 45 different labels (features, words) that describe the political leaning \nof the different Arab prints. Those labels are similar in meaning but d ifferent in naming \n\n \n 13 and in most cases, the same newspaper has multiple labels, sometimes up to four labels. \nTherefore, we had to do a normalizing process for those labels.  \nIn this process , we chose a number of key labels that were more pronounced in meaning \nand more frequent among the labels. Then we began examining each of the original labels \nand we convert ed it to the nearest key label, normalized label (Table  2).  \nTable 2. The normalizing labels process.   \nOriginal label  Normalized label  \nCenter -left left \nindependent  independent  \nliberal democrat  liberal  \nliberal  liberal  \nuncritical approach towards the government's policies  pro-government  \nConservative and pro -Islamic; pro -government  pro-government,  Islamist  \nArab nationalist view  nationalist  \npro-West and pro -Saudi  pro-government, liberal  \nreligiously conservative  Islamist  \ncultural, pro -reform  independent  \nIslamic, pro -reform  Islamist  \nliberal, pro -reform  liberal  \npro-Saudi  pro-government  \npro-reform, liberal  liberal  \nindependent political stance \u060c pro-government (BBC)  independent  \nIndependent Arab nationalist  nationalist  \nNeutral  Neutral  \n \nFor example, we have this label  uncritical approach towards the government's \npolicies , which  is turned to be pro-government. Another example,  Conservative and \npro-Islamic; pro -government turned to be  Islamist; pro -government  and religiously \nconservative turned to be  Islamist. Those labels are not mutually exclusive, so different \nlabels could be applied to the same newspaper  (Table 2 ). \n \n 14 Eventually, we came up with the following  ten labels : neutral, right, pro -government, \nanti-government, liberal, Islamist, secular, nationalist, independent, socialist, and \ncommunist .  \nAfter that, we calculated the percentage of the frequency of each label . Knowing the \npercentag es of these labels gives us a background on to what extent a certain ideology \nspread among the public. For example, knowing the percentag e of the label (Islamist)  is \nvery important in a region accused of extremism and terrorism .  \n \n 15 CHAPTER 4: RESULTS AND DISCU SSION  \n In this project, we examined 162 prints from most countries of the MENA region. 94 \nprints from twelve countries from the Arab Peninsula and 68 prints from seven countries \nfrom North Africa. Those prints are in five languages: Arabic, English, French , \nArmenian, and Kurdish which emphasize that we study all newspapers that affect the \nArab world , not just Arab prints.  \nThe following table shows the number of newspapers studied and examined from each \ncountry, see Table  3. This does not mean that there is  a country in which newspapers are \nabundant and others do not.  There are hundreds of newspapers that we studied, but which \nwere excluded from this study because of the lack of clear political classification.  \nThe newspapers, whose political leanings were e vident according to the perspective of the \nthree sources through whose  newspapers were examined, were chosen.  \nTable 3. The number of printed newspapers in each country in the study.  \nCountry  Frequency  Country  Frequency  \nQatar  8 Lebanon  14 \nSaudi Arabia  12 Palestine  7 \nUnited Arab Emirates  12 Egypt  7 \nOman  6 Sudan  5 \nKuwait  10 Libya  4 \nBahrain  8 Tunisia  4 \nYemen  8 Morocco  11 \nJordan  13 Algeria  8 \nIraq 10 Mauritania  8 \nSyria  7 Total  162 \n \nGiven the results we obtained in the second stage of this study, which is the normalization \nof the labels, we can make several interesting observations. First, most newspapers in the \nMENA region are owned by the governments, affiliated with or loyal to the m, but not the \n \n 16 opposition. This is seen by looking at the proportion of opposition newspapers (anti -\ngovernment label), 2.50%, compared to pro -governments (28.40%), see table 4 . \nTable 4. The frequency of the lab els. \nLabels  Frequency  percentage  \npro-government  46 28.40%  \nindependent  39 24% \nnationalist  18 11.10%  \nliberal  17 10.50%  \nneutral  9 5.60%  \nIslamist  9 5.60%  \nleft 8 4.90%  \nSocialist  6 3.70%  \nright  4 2.50%  \nanti- government  4 2.50%  \nsecular  2 1.20%  \nTotal  162 100.00%  \n \nSecond, most of these pro -government newspapers are from the GCC. However, Kuwait \nis the only country in the Gulf that we can find some prints that show clear and critical \nagenda against the government. Moreover, we find the liberal approach evident in \nKuw ait, nearly 40  of the local newspapers are liberal and 10% are secular.  \nIn the second place , after pro -government newspapers, the independent newspapers come \nin, with 24%. However, during the research and study, we found that most of these \nnewspapers do n ot show a real  independent approach against  the government. Either they \nare owned by the government or they are bilingual, so the Arabic version is pro -\ngovernment and the other version is shown as  an independent.  \n \n 17  \nFigure 2. The frequency of the labels that describes the newspapers.  \n \nSince the region suffers from a constant conflict since the beginning of the last century \nabout the existence of a non -Arab entity in the region, the Zionist entity, we find a \nnumber of newspapers that show a strong n ational approach about 11%.  \nWe also note that the percentage of newspapers that show conservative religious \nideologies is barely reasonable (5.6 %) and often belongs to political parties of a religious \nnature.  \nFinally, it is clear that ideologies such as left, right, and secular, which are used to \nclassify newspapers in other regions of the world and have been focused on by some \nprevious studies and similar projects, do not appear to be very important in the MENA \nregion. Although there is a reasonable numb er of newspapers classified as left (4.9% ). \n \n\n \n 18 CHAPTER 5: LIMITATIONS AND DIFFICULTIES  \nRegarding the difficulties That I encountered during this study, most of them were related  \nto the data collection stage. However,  the difficulties began early, especially in the stage \nof reviewing previous literature. The most important one was the lack of  Arab studies that \ntalk about classify ing the Arab media, especially newspapers in terms of political \naffiliation. There are many studies but their focus,  for example, is on the effective ness of  \nthe Arab media , as an industry , in influencing the masses, or the freedom of the Arab \nmedia in general. Most of  these studies are general studies that do not come even close to \ntrying to clas sify the Arab media, especially the prints in terms of their political leanings \nand whether they are independent or subordinate to the government, as well as the \nclassification of their political and ideological directions.  \nThere were very few foreign sit es or studies that tried to classify the world -known \nnewspapers on the basis of ideologies, but they covered only very few Arab newspapers \ncompared to the number of existing Arab prints that affect the people in the Arab world . \nSince we did not rely on per sonal opinions or personal analysis of the Arab newspapers, \nand because of the lack of scientific studies in this field, we have a lack of reliable \nsources on which we can rely on to take information on the ideologies of Arab \nnewspapers.  \nEven Wikipedia, th e only Arabic site that can provide information about Arab \nnewspapers, often provides only information about the history of the newspaper and its \neditors and does not mention any political and ideological classification of the newspaper. \nHere we must raise  awareness in the Arab world about the importance of participating in \nthe editing of the Wikipedia site.  \nAmong the difficulties that we encountered, the information in the Arabic site of \nWikipedia  differs from the information in the English site of Wikipe dia for the same \n \n 19 newspaper. And that is due to the number of editors in the Wikipedia site as each editor \nexpresses their own  personal opinion in the newspaper.  \nSome Arab newspapers have changed their political leanings, for example from pro -\ngovernment to  the opposition. This happened in the countries of the Arab Spring and \nspecifically after 2011, according to Wikipedia itself. This is normal, as some \ngovernments have changed completely.  \nFinally, I found several newspapers classified as independent and pr o-government at the \nsame time. The problem that I faced is the  difficulty in classif ying the newspaper whether \nthey are  pro-government or independent.  \n  \n \n 20 CHAPTER 6: CONCLUSION AND FUTURE WORK  \nIn this project, we follow ed a systematic approach to analyzing the political leaning of the \nnewspapers in the Middle East and their affiliations. This project is unique and it differs \nfrom previous projects and studies in that it worked on collecting data from one specific \nregion. I t studied trends and policies concerning the ideological and political reality of t he \nregion. We have gathered a large collection of newspapers from most countries of the \nMENA region, 19 countries, in five different languages. We have adopted a methodology  \nto obtain data from three reliable sources. After the label normaliz ation  phase, we \nobtained  eleven  different labels. We found that most newspapers in the region follow \ngovernments and the independent prints do not necessarily contradict government \npolici es as they are often essentially government -owned. Through the previous findings, \nit is clear to us that democracy in the Middle East still has a lot to go, and that the \npublications still suffer from the censorship of the authorities.  \nIn the future, worki ng on this project will be continued in terms of studying and covering \nmore newspapers in the region, and searching for other reliable sources to obtain \ninformation about the political leaning of the newspapers , in order to confirm the \nprevious results or to obtain more accurate ones.  \nThese results could then be used to build an application to let the user check the political \naffiliation of any print ed medi um in this region.  \n \n  \n \n 21 REFERENCES  \nAllen, S. (2015). Media bias: 8 types [a classic, kinda] Retrieved from \nhttps://capitalresearch.org/article/media -bias-8-types -a-classic -kinda/  \nAllSides Media Bias Ratings. (2019). Retrieved from  https://www.allsides.com/media -\nbias/media -bias-ratings  \nAl-Rawi, A. K. (2012). Media practice in Iraq . Palgrave Macmillan.  \nAlt, J. E., & Lassen, D. D. (2006). Transparency, political polarization, and political \nbudget cycles in OECD countries. American Journal of Political Science , 50(3), 530 -550. \nBaldassarri, D., & Bearman, P. (2007). Dynamics of political polarization. Ameri can \nsociological review , 72(5), 784 -811. \nBaly, R., Karadzhov, G., Alexandrov, D., Glass, J., & Nakov, P. (2018). Predicting \nfactuality of reporting and bias of news media sources. arXiv preprint arXiv:1810.01765 . \nBernhardt, D., Krasa, S., & Polborn, M. (20 08). Political polarization and the electoral \neffects of media bias. Journal of Public Economics , 92(5-6), 1092 -1104.  \nConover, M., Ratkiewicz, J., Francisco, M. R., Gon\u00e7alves, B., Menczer, F., & Flammini, \nA. (2011). Political polarization on twitter. Icwsm , 133, 89-96. \nDiMaggio, P., Evans, J., & Bryson, B. (1996). Have American's social attitudes become \nmore polarized? . American journal of Sociology, 102(3), 690 -755. \nDixit, A. K., & Weibull, J. W. (2007). Political polarization. Proceedings of the National \nAcademy of Sciences , 104(18), 7351 -7356.  \n \n 22 Dorn, D., Hanson, G., & Majlesi, K. (2016). Importing political polarization? The \nelectoral consequences of rising trade exposure  (No. w22637). National Bureau of \nEconomic Research.  \nFeldman, S. (2013). Political id eology.  \nFiorina, M. P., & Abrams, S. J. (2008). Political polarization in the American public . \nAnnu. Rev. Polit. Sci. , 11, 563 -588. \nGruzd, A., & Roy, J. (2014). Investigating political polarization on Twitter: A Canadian \nperspective. Policy & Internet , 6(1), 28-45. \nHawkins, M. (2018). Liberal Media Bias - a Definition. ThoughtCo . Retrieved from \nhttps://www.thoughtco.com/liberal -media -bias-a-definition -3303632  \nHong, S., & Kim, S. H. (2016). Political polarization on Twitter: Implications for the use \nof social media in digital governments . Government Information Quarterly, 33(4), 777 -\n782. \nIyyer, M., Enns, P., Boyd -Graber, J., & Resnik, P. (2014). Political ideology detection \nusing recursive neural networks. In Proceedings of the 52nd Annual Meeting of the  \nAssociation for Computational Linguistics (Volume 1: Long Papers)  (Vol. 1, pp. 1113 -\n1122).  \nKulkarni, V., Ye, J., Skiena, S., & Wang, W. Y. (2018). Multi -view Models for Political \nIdeology Detection of News Articles. arXiv preprint arXiv:1809.03485 . \nLevass eur, D. G. (2008). Media bias. In L. L. Kaid, Encyclopedia of political \ncommunication. Thousand Oaks, CA: Sage Publications. Retrieved from  \nhttps://search.credoreference.com/content /topic/media_bias  \n \n 23 Media Bias/Fact Check - Search and Learn the Bias of News Media. (2019). Retrieved \nfrom  https://mediabiasfactcheck.com  \nMellor, N., Rinnawi, K., Dajani, N., & Ayish, M. I. (2011). Arab media:  Globalization \nand emerging media industries . (Vol. 1). Polity.  \nMorris, J. S. (2007). Slanted objectivity? Perceived media bias, cable news exposure, and \npolitical attitudes.  Social Science Quarterly, 88(3), 707 -728. \nPalonen, E. (2009). Political polarizat ion and populism in contemporary Hungary. \nParliamentary Affairs, 62(2), 318 -334. \nPotthast, M., Kiesel, J., Reinartz, K., Bevendorff, J., & Stein, B. (2017). A stylometric \ninquiry into hyper -partisan  and fake news. arXiv  preprint arXiv:1702.05638 .  \nPreo\u0163iuc -Pietro, D., Liu, Y., Hopkins, D., & Ungar, L. (2017). Beyond binary labels: \npolitical ideology prediction of twitter users. In Proceedings of the 55th Annual Meeting \nof the Association for Computational Linguistics (Vo lume 1: Long Papers)  (Vol. 1, pp. \n729-740).  \nPrior, M. (2013). Media and political polarization. Annual Review of Political Science , \n16, 101 -127. \nSakr, N. (2007). Approaches to exploring media -politics connections in the Arab world  \n(No. 68, pp. 1 -12). IB Ta uris. \nStreet, J. (2010). Mass media, politics, and democracy . Macmillan International Higher \nEducation.  \nTANBIH NEWS. (2019). Retrieved from  https://www.tanbih.org  \n \n 24 Webb, E. (2014). Media in Egypt and Tunisia: From Con trol to Transition? . Springer.  \nWeber, I., Garimella, V. R. K., & Batayneh, A. (2013, August). Secular vs. Islamist \npolarization in Egypt on Twitter. In Proceedings of the 2013 IEEE/ACM International \nConference on Advances in Social Networks Analysis and Mi ning (pp. 290 -297). ACM.  \nZweiri, M., & Murphy, E. C. (Eds.). (2012). The new Arab media: Technology, image, \nand perception . Apollo Books.  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Propaganda-based Classification of Arabic Newspapers", "author": ["WSM Al-Ziyadi"], "pub_year": "2019", "venue": "NA", "abstract": "In this project, we explore the factuality of reporting and the bias of Arabic news media. We  use a quantitative measure of political leaning and bias of a set of the most popular"}, "filled": false, "gsrank": 595, "pub_url": "https://search.proquest.com/openview/bb041df897e548b8e274793d426662d0/1?pq-origsite=gscholar&cbl=2026366&diss=y", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:0RyUiEXrI6wJ:scholar.google.com/&output=cite&scirp=594&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D590%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0RyUiEXrI6wJ&ei=cbWsaOqkD7TWieoP1pCJ2AY&json=", "num_citations": 2, "citedby_url": "/scholar?cites=12404016482585156817&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:0RyUiEXrI6wJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://manara.qnl.qa/articles/thesis/Propaganda-based_Classification_of_Arabic_Newspapers/28471154/1/files/52564487.pdf"}}, {"title": "Variation between credible and non-credible news across topics", "year": "2024", "pdf_data": "Variation between credible and non-credible news across topics\nEmilie Marie Carreau Francis\nSpr\u00e5kbanken Text\nUniversity of Gothenburg, Sweden\nBox 200, SE 405 30 Gothenburg\nemilie.francis@gu.se\nAbstract\n\u2018Fake News\u2019 continues to undermine trust in\nmodern journalism and politics. Despite con-\ntinued efforts to study fake news, results have\nbeen conflicting. Previous attempts to analyse\nand combat fake news have largely focused on\ndistinguishing fake news from truth, or differ-\nentiating between its various sub-types (such as\npropaganda, satire, misinformation, etc.) This\npaper conducts a linguistic and stylistic analy-\nsis of fake news, focusing on variation between\nvarious news topics. It builds on related work\nidentifying features from discourse and linguis-\ntics in deception detection by analysing five\ndistinct news topics: Economy, Entertainment,\nHealth, Science, and Sports. The results em-\nphasize that linguistic features vary between\ncredible and deceptive news in each domain\nand highlight the importance of adapting clas-\nsification tasks to accommodate variety-based\nstylistic and linguistic differences in order to\nachieve better real-world performance.\n1 Introduction\nThe term \u2018Fake News\u2019 catapulted to popularity\naround the 2016 U.S. Presidential election and\nhas continued to cast a shadow of mistrust over\njournalism and politics (Ram, 2023; V olz and Gor-\ndon, 2023). Global trust in social media as a news\nsource remains low and has been on a decline for\nthe past decade (Bersoff and Ries, 2024). Despite\nthis, many still turn to social media as a means to\nstay informed. Half of the U.S. adult population\nreport getting their news from social media at least\nsome of the time (Wang and Forman-Katz, 2024;\nMatsa, 2023). However, most users express con-\ncerns about quality, accuracy, and bias (Wang and\nForman-Katz, 2024).\nThe effort to combat the spread and influence of\n\u2018fake\u2019 or \u2018non-credible\u2019 news has been reflected in\nthe large body of academic research on fake news\ndetection and analysis. However, there has beenlittle large scale practical implementation of this re-\nsearch. In part, this can be attributed to conflicting\nobservations in the literature. This paper takes a\nvariety specific approach to non-credible news anal-\nysis by investigating linguistic and stylistic differ-\nences for five common news topics: economy, en-\ntertainment, health, science/technology, and sports.\n1.1 Contributions\nPrevious approaches to fake news analysis and de-\ntection have taken either a broad view of news, by\ndisregarding or combining news categories, or fo-\ncusing only on hard news. The inclusion of linguis-\ntic and stylistic features in automatic classification\nis promising, but results remain lacklustre. Models\nmay be sensitive to genre/domain attributed differ-\nences and could benefit from more targeted classi-\nfication approaches. This research investigates dif-\nferences between credible and non-credible news\nacross a variety of contexts to provide support for\nthis assumption, in addition to the introduction of a\nnovel topic-based \u2018fake news\u2019 dataset. The follow-\ning questions will be addressed:\n1.What are the stylistic differences of non-\ncredible and credible news for each topic?\n2.What differences (if any) are observed across\ntopics?\nThe goal of these questions is to determine the\ngeneralisability of stylistic based fake news detec-\ntion and identify features which may be used in\nclassification models. This research will also con-\nsider how such cues agree or contradict previous\nliterature on deceptive and persuasive language in\njournalism and politics.\n2 Related work\nDeceptive and persuasive language: In political\ncommunication, advocates attempt to manipulatearXiv:2411.12458v1  [cs.CL]  19 Nov 2024\nthe public in many ways. Arguments can be clas-\nsified into four types depending on whether it is\npro, con, easy, or hard to comprehend (Cobb and\nKuklinski, 1997). To assess the persuasive power\nof each argument type, Cobb and Kuklinski (1997)\nstudied opinions on the North American Free Trade\nAgreement (NAFTA) and healthcare at three points\nin time. Oppositional arguments held more weight,\nand for NAFTA the effect was stronger for hard\narguments. However, easy arguments were more\npersuasive for healthcare. In policy proposal, Lau\net al. (1991) observed that persuasion can be in-\nfluenced by the formulation and presentation of\ninterpretations. An argument is more persuasive,\nregardless of a voter\u2019s political beliefs, if one can\ncontrol the environment to allow for only one inter-\npretation.\n\u2018Control over the narrative\u2019 is often a factor in\nidentifying propaganda. Journalism uses four fac-\ntors to distinguish persuasion from propaganda:\nvolition, transparency, manipulation, and the shield-\ning of listeners from opposing facts (Bard, 2017).\nPropagandists exploit audience beliefs and values\nto promote self-interest, attempt to block opposing\narguments from reaching the audience, and often\nhide the true intent of their message. Simpson\n(1992) argues that lying involves three levels: de-\nception regarding a state of affairs, regarding one\u2019s\nbeliefs, and regarding the sincerity of one\u2019s presen-\ntation as believing. The third level distinguishes\nsimply being untruthful from legitimate deception,\nas to be untruthful is not necessarily to lie. This\nthird level differentiates satire from simple mis-\ninformation, but can also be used to occlude the\nintents of many fake news creators who claim there\nis no reason for readers to believe their content is\nsincere.\nStudies on lying have revealed that certain cues\ncan be used to indicate deception. It has been\nshown that the psychological burden of lying,\nwhether due to guilt or the challenge of remem-\nbering the lie, may cause liars to avoid language\nthat takes ownership of the statement or portray\ncertainty (Newman et al., 2003; Sarzynska-Wawer\net al., 2023; Dzindolet and Pierce, 2005). New-\nman et al. (2003) found that, in addition to using\nmore words that elicit negative emotion, liars dis-\ntance themselves from claims by using fewer first\nand third person pronouns. In a study of true and\nfalse statements in Polish and English, Sarzynska-\nWawer et al. (2023) also observed that lying in En-glish triggered an increase of words with negative\ntone, as well as a general increase in negation.\nDeception in news text: While there have been\nseveral studies investigating linguistic and stylistic\nfeatures in news text, results are often contradictory.\nPotthast et al. (2018) used style analysis, including\nreadability scores and dictionary features, to dis-\ntinguish hyper-partisan from mainstream news. It\nwas found that left and right-wing news share more\nstylistic similarities with each other than with main-\nstream. Writing style on its own was discovered to\nbe sufficient for distinguishing hyper-partisan news\narticles from more balanced news. Mahyoob et al.\n(2020) found that proper nouns and passive voice is\nmore frequent in credible news, while non-credible\nnews uses more superlatives. While identifying\nlinguistic features to use in automatic classification,\nKasseropoulos and Tjortjis (2021) noted that fake\narticles are shorter in length and use fewer technical\nwords, quotes, punctuation, and have more lexical\nredundancy. They also use simpler language with\nshorter words, as well as more personal pronouns\nand adverbs.\nIn satire, surface level features such as sentence\nlength and average word frequency, in addition to\nsemantic features and causal connectives vital to\ntext comprehension are considered predictors (Levi\net al., 2019). Disinformation is also prone to gram-\nmatical and orthographical mistakes, erratic punc-\ntuation, and idiosyncratic typography (Sousa-Silva,\n2022). Another study investigated variation be-\ntween credible and deceptive hard news and found\nthat credible news was more informationally dense,\nwhile deceptive news was more narrative (Francis,\n2018). It was also observed that credible news used\nmore adjectives, intensifiers, and clausal coordina-\ntion.\nAddawood et al. (2019) used interpersonal de-\nception theory (IDT) and reality monitoring (RM)\nto analyse the language used by Russian trolls dur-\ning 2016 U.S. Presidential election. They identified\n49 linguistic cues used by deceivers which indi-\ncated uncertainty, including hedges, modal verbs,\nauxiliary verbs, and expressions of possibility. It\nwas also observed that deceivers attempted to dis-\ntance themselves from the lies by using less self-\nreference in the form of pronouns. In research on\nclimate change news and editing of international\nnews, a trend of misreporting illustrated by errors\nsuch as overstatement, misquotation, misattribu-\ntion, and over-assertion, was revealed (Bell, 1991).\nIt also appears that differences between fake and\ncredible news vary across languages and dialects.\nIn a study of English and Portuguese fake news\ntexts, Sousa-Silva (2022) noticed that variation be-\ntween fake news and mainstream media differ de-\npending on the corpus. The longest words are used\nby fake news in the English corpus, whereas the\nlongest words are used by mainstream media in\nPortuguese. In a study of false statements in Brazil-\nian Portuguese news, Vargas and Pardo (2021) used\nword and sentence level analysis to discover that\ntrue statements used more nouns and verbs, while\nfalse statements were found to contradict previous\nliterature in their pronoun usage.\nIn depth discourse and linguistic analysis of\ndeceptive text has also revealed some interest-\ning trends throughout the various forms of fake\nnews. Using van Leeuwen\u2019s discourse model of\nlegitimation and de-legitimation, Igwebuike and\nChimuanya (2021) analysed the legitimation strate-\ngies used for justification of fake news posts on\nNigerian WhatsApp, Facebook, and Twitter. Find-\nings revealed that creators convey messages to read-\ners and validate disinformation through appeals to\nauthority, emotion, moralisation, and rationalisa-\ntion.\nDeception detection: Verma et al. (2021) used\nlinguistic features to classify the veracity of news\ncontent by organizing the features into sets and\nmerging them with word embeddings. The 20 most\nsalient features were selected and applied to a vot-\ning classifier. Burgoon et al. (2003) employed 16\nlinguistic features categorized into four classes in a\ndecision tree algorithm, achieving an accuracy of\n60.72%. Vicario et al. (2018) used a variety of fea-\ntures from text (e.g. number words, sentences, and\ncharacters), along with user and message specific\nfeatures to identify hoaxes and fake news on social\nmedia with various machine learning models.\nIntroducing the small novel UNBiased dataset,\nGravanis et al. (2019) tested 57 linguistic fea-\ntures embedded with word-to-vector embedding\nin several popular ML classifiers for deception.\nKasseropoulos and Tjortjis (2021) identified an op-\ntimal set of 23 features out of 87 which performed\nwell with CNN and LSTM classifiers. LUX (Lan-\nguage Under eXamination), is a text classifier that\nmakes use of linguistic analysis to infer the likeli-\nhood of an input being fake-news (Azevedo et al.,\n2021). Linguistic metrics were included as model\nfeatures to improve classification performance inNews Type Total Articles\nEconomy 15,672\nEntertainment 5,000\nHealth 5,258\nScience & Technology 8,400\nSports 6,842\nTable 1: Total articles per topic. The number of articles\nper label is equal to the total divided by two.\nidentifying fake news.\nMany other approaches to automatic deception\ndetection have made use of shallow text features\nand semantics in their models with reasonable suc-\ncess in the task at hand (Bharadwaj and Shao, 2019;\nKurasinski and Mihailescu, 2020). Kuzmin et al.\n(2020) used models trained on bag-of-n-grams and\nbag-of-RST (Rhetorical Structure Theory) features\nto detect satire, real, and fake news in Russian and\ndiscovered that unigrams were the most important\nfeature for detection. In a survey of supervised\nlearning approaches to deception detection with\ndiscourse and structural features, the results of such\napproaches were mixed, but showed promise (Var-\ngas et al., 2022).\nThe results from previous literature show a con-\nflicting landscape of deceptive language in writing\nand news text. Likely due to this inconsistency,\nautomatic deception detection methods which have\nutilised linguistic features exclusively typically\nachieve lukewarm performance. One of the limit-\ning factors of the previous approaches is that analy-\nsis has been broadly based on hard news and pol-\nitics with little investigation into other news top-\nics. The research presented in this paper adds to\nthe existing body of literature by including under-\nrepresented news topics, such as entertainment and\nsports. The results of this paper will reference the\nprevious findings detailed above, identifying sim-\nilarities and differences. The following sections\nwill introduce the data utilised in this study and\nthe methodology through which they have been\nanalysed.\n3 Data\nA novel dataset was created in order to ensure\na balanced sample size with consistent topic la-\nbelling. Texts are limited to English news from\nthe United States and Canada during the period of\n2011 to 2018. Article annotation was carried out\nautomatically as data was collected. Articles were\nlabelled \u2018non-credible\u2019 or \u2018credible\u2019 based on pub-\nlisher intent, similar to the approach taken by Lazer\net al. (2018). Articles from publishers whose mis-\nsion is perceived as providing accurate information\nwith high reliability are categorized as \u2018credible\u2019,\nwhereas articles from publishers who intentionally\nproduce fabricated stories or have mixed/lower fac-\ntuality ratings are categorized as \u2018non-credible\u2019.\nLabels are determined based on bias and relia-\nbility scores provided by Media Bias-Fact Check,1\nAllSides,2and Ad Fontes Media.3Bias ratings are\ndetermined using a numerical scale, based on vari-\nous factors (including political leaning, factuality,\nspin/framing, and several types of bias), averaged\nfrom a survey of articles from the outlet. While\nthese companies have slightly different approaches\nto rating, all employ a panel based system where\na selection of articles and headlines from an outlet\nis reviewed regularly by a balanced panel of raters\nwho have self reported their political biases. As\nthese organisations are private companies, specific\nguidelines are not publicly available. However,\nassessment criteria are described in detail on the\nrespective websites.\nThe labels \u2018credible\u2019 and \u2018non-credible\u2019 were\nchosen based on the definition of \u2018credibility\u2019 as\nsomething trustworthy or worthy of belief. This la-\nbel covers the range of deceptive topics in the anal-\nysis, including satire. Despite the primary intent of\nsatire being entertainment, it is still considered non-\ncredible due its potential to mislead readers and\nits lack of trustworthiness as a source of informa-\ntion. Furthermore, while automatic classification\nbetween hard news and satire has been somewhat\nsuccessful (Horne and Adali, 2017; Rubin et al.,\n2015), it is often challenging to distinguish satire\nfrom other forms of deceptive news (Rashkin et al.,\n2017).\nSources for the credible corpus are Reuters, the\nNew York Times, Global News, Business Insider,\nCBC, and the New Yorker. Non-credible news\nsources include the Beaverton, Breitbart, Global\nResearch, If You Only News, Your Newswire, Mad-\nWorld News, and Liberty Writers. There is a total\nof 41,172 articles in the combined non-credible\nand credible news corpus, with a 50:50 split of de-\nceptive and credible news for each topic. Table 1\nshows the number of articles for each topic, where\n1https://mediabiasfactcheck.com/\n2https://www.allsides.com/\n3https://adfontesmedia.com/the number of articles per label is equal to the topic\ntotal divided by two. Smaller numbers for topics\nsuch as entertainment and health can be attributed\nto lower publication rates for those topics in gen-\neral, especially compared to more hard news like\neconomy. This is compounded for non-credible\nnews which typically has a lower overall publica-\ntion rate compared to credible news outlets.\n4 Methodology\n4.1 Multi-dimensional analysis (MDA)\nMDA is a means of measuring textual variation in\ntext types based on a collection of linguistic fea-\ntures. Six dimensions, each associated with under-\nlying communicative functions, were established\nto group texts based on similarity of composition\n(Biber, 1988). A text is analysed by tagging linguis-\ntic features and calculating a factor score, which is\nused to represent groupings of linguistic variables\nobserved to have high co-occurrence. Features with\na factor magnitude of 1.95 or greater are considered\nsignificant to the corpus.\nDimension scores, calculated from the aforemen-\ntioned factor scores, determine to which text-type\na piece of text is most similar in style. Dimen-\nsions one through five are described in Table 2.\nDimensions one, two, and four are fairly straight-\nforward, but dimensions three and five may be un-\nclear without further explanation. For dimension\nthree, low scores indicate context dependence and\nare typical of texts like sports broadcast, whereas\ncontext independence is a feature of academic writ-\ning. High scores on dimension five indicate that a\ntext presents information in a technical and abstract\nmanner, such as scientific discourse. Dimension\nsix, used to measure informational texts produced\nunder time constraints, is not relevant for this task\nand has been omitted.\n4.2 Multi-dimensional analysis tagger (MAT)\nimplementation\nTagging and score calculation were performed with\nversion 1.3.1 of MAT (Nini, 2019). MAT is based\non the Stanford Part-Of-Speech Tagger and de-\nsigned to replicate the tagger used in Biber (1988)\nfor multi-dimensional functional analysis of En-\nglish texts. MAT generates a grammar annotated\nversion of the corpus, in addition to statistics for\ntext-type and genre analysis. Nini (2019) utilises\nz-scores instead of factor scores, which serve the\nsame function. New tags, such as indefinite pro-\nHigh Score (H) Low Score (L)\nD1: Involved vs. Informational Involved verbs, pronouns Informational nouns, adjectives\nD2: Narrative vs. Non-Narrative Narrative past tense, third person Non-narrative synthetic negation\nD3: Context-Independent vs. Dependent Independent nominalisations Dependent adverbs, pied-piping\nD4: Overt Expression of Persuasion Explicit modal adverbs Absent suasive verbs, infinitives\nD5: Abstract vs. Non-Abstract Information Abstract passive clauses, conjuncts Non-abstract agentless passives\nTable 2: Five of the six dimensions used in this paper. The \u2018H\u2019 and \u2018L\u2019 tags represent the text-type associated with\nhigh or low scores for the dimension, including characteristic high frequency features for the type.\nnoun ,quantifier , and quantifier pronoun , have been\nintroduced to expand on the original set of features.\nNini (2019) asserts that MAT provides a good\nreplication of Biber\u2019s analysis and has achieved\nan accuracy of 90% in similar studies (Grieve and\nWoodfield, 2023). Only the first 400 tokens of an\narticle are used in the analysis, as was the standard\nused in Biber (1988). This number may be adjusted,\nbut was determined sufficient to cover the majority\nof content in the average article. Comparison be-\ntween credible and deceptive news are discussed\nusing effect size with Cohen\u2019s dand Pearson\u2019s r,\nassuming the standard guidelines.4\n5 Analysis\n5.1 Dimension scores\nThe corpus with the highest average difference\nacross all dimensions was health news, with econ-\nomy and entertainment news in a relatively close\nsecond. D1 shows the most variation across topics,\nwith the exception of economy news where there\nis almost no difference. The credible corpus dis-\nplayed a consistently low D1 score, which indicates\nthat information density is a trait of credible news.\nWhile scores for D5 were fairly low for all news\ntopics, non-credible news generally scored higher\non D5 compared to credible news. This suggests\nthat non-credible news typically expresses informa-\ntion in a more abstract/technical manner compared\nto credible news. While this observation appears to\ncontradict research on readability and complexity,\nit is consistent with Cobb\u2019s observations on the per-\nsuasive power of hard arguments and previous re-\nsearch on political news discourse (Kasseropoulos\nand Tjortjis, 2021; Sarzynska-Wawer et al., 2023;\nCobb and Kuklinski, 1997; Francis, 2018). Fig-\nure (1) shows the mean score for each dimension\nby topic and numbers in parentheses below report\nCohen\u2019s d.\n4Pearson\u2019s r= .10, .30, and .50, and Cohen\u2019s d= 0.20,\n0.50, and 0.80 as small, medium, and large, respectivelyEconomy: The most noticeable difference be-\ntween deceptive and credible news is in D2. This\nwas also the dimension which showed the greatest\neffect size (0.87) when comparing means. This\nsuggests that credible economy news language is\nmore narrative while non-credible news is non-\nnarrative. D5 was the other dimension which\nshowed a medium-small (0.45) difference between\nthe corpora, which indicates that non-credible econ-\nomy news is more formal and technical. There was\nalso a small effect (0.42) in D3, suggesting that\nnon-credible news is moderately more context in-\ndependent (as the case is with academic prose).\nEntertainment: Credible entertainment news re-\nceived a noticeably more negative mean score for\nD1 compared to non-credible news (Fig.1). The\neffect on this dimension is medium-large (0.75), in-\ndicating that information in credible entertainment\nnews text is more dense. In contrast to economy\nnews, credible entertainment news demonstrated\nmore context independence than deceptive news.\nEntertainment also saw a medium-small effect size\non D4 (0.45), revealing a difference in expression\nof persuasion between non-credible and credible\nnews. Overall, credible news employs mildly less\npersuasion and is somewhat less dependent on con-\ntext compared to non-credible.\nHealth: Health news had the biggest difference\nbetween the credible and non-credible corpora al-\ntogether, especially between D1 and D3 which\nshowed a medium-large effect (0.69 and 0.73 re-\nspectively). This suggests that information in cred-\nible health news is more dense and less dependent\non context, similar to academic texts. Once again,\nnon-credible news had a higher mean score on D5\ncompared to credible news, indicating more tech-\nnical and formal writing. Unlike the other news\ntopics, a medium-small effect was also observed on\nD2 and D4 (0.41 and 0.42 respectively). Credible\nhealth news is mildly less narrative and exhibits less\npersuasion. The more abstract style taken in non-\ncredible health news may be explained by Cobb\u2019s\nFigure 1: The mean dimension scores for each news type organized by topic. Non-credible and credible news, with\nthe exception of Economy, scored similarly to the text-type \u2018General Narrative Exposition\u2019 defined by Biber (1988).\nThis is expected, as \u2018General Narrative Exposition\u2019 canonically contains news discourse, among other types.\nfindings on hard arguments.\nScience: Differences between credible and non-\ncredible science news were minimal, with most\ndimensions demonstrating only a small effect. D3\ndisplayed the strongest difference between corpora\nwithin this topic, a medium-small effect (0.43).\nWhile both received a positive mean score, indi-\ncating context independence, the score received by\nthe non-credible corpus was notably higher.\nSports: Differences between credible and non-\ncredible sports news were mostly non-existent, but\nD1 and D4 had a small effect on the corpus (0.34\nand 0.30). Although both credible and non-credible\nnews scored low on D1, the mean for credible\nsports news was noticeably lower. This suggests\nthat credible sports news may contain more infor-\nmation compared to non-credible. A small effect\nwas also observed on D4, indicating that author\npoint of view may be slightly more present in cred-\nible sports news. This may be due to the higher\nlikelihood that credible sources attract professional\nsports writers who offer expert opinions on sport-\ning outcomes, whereas deceptive news writers are\nmore likely to be amateurs. Additionally, since the\ntopic of sports is generally accessible to a wider\naudience, it is more challenging to present alterna-\ntive interpretations due to its familiarity (Lau et al.,\n1991).\n5.2 Linguistic features\nAs there are 66 linguistic variables included by\nMAT, it is unfeasible to discuss all for each newsFeature Cohen\u2019s dCredible Mean Non-Credible Mean\nConjuncts (CONJ) 0.66 0.09 0.91\nAdjectives (JJ) 0.71 0.29 0.93\nPublic Verbs (PUBV) 1.20 1.24 -0.13\nSubordinator \u2018that\u2019 deletion (THATD) 0.77 -0.17 -0.34\nPast Tense Verbs (VBD) 1.00 0.03 -0.48\nTable 3: Features which have a notable effect in the\nEconomy news type. PUBV verbs are identified by\nQuirk et al. (1985) as those which indicate speech acts.\nTHATD is added when the subordinator is missing from\na subordinate clause preceded by a public, private, or\nsuasive verb.\ntopic. Only features with an unexpected relation-\nship or large difference will be given specific at-\ntention. Some strong correlations among linguistic\nfeatures are what one would expect based on gram-\nmar (e.g., a strong negative correlation between\nadverbs and nouns), so they have been omitted.\nNouns and nominalisations were the most frequent\nacross all topics for both corpora, which is expected\nof general narrative exposition.\nEconomy: Differences between linguistic fea-\ntures were the most striking in economy news (Ta-\nble 3). The frequency of public verbs was consider-\nably higher in credible economy news compared to\nnon-credible news, and demonstrated the strongest\neffect in the entire study. Public verbs, such as\n\u2018say\u2019 or \u2018claim\u2019, are a major stylistic difference be-\ntween credible and deceptive economy news. Past\ntense verbs were also far more frequent in credible\nnews. Subordinator \u2018that\u2019 deletion demonstrated\na medium effect, which is likely due to the higher\nfrequency of public verbs in the credible news cor-\npus.\nFeature Cohen\u2019s dCredible Mean Non-Credible Mean\nPrepositional Phrases (PIN) 0.49 -0.45 -0.81\nType-Token Ratio (TTR) 0.49 0.00 -0.97\nSecond Person Pronouns (SPP2) 0.38 -0.46 -0.26\nDemonstrative Pronouns (DEMP) 0.37 -0.44 -0.17\nTable 4: The features with a notable effect in Entertain-\nment news. The preposition \u2018to\u2019 is distinguished from\nthe infinitive marker \u2018to\u2019 by MAT, receiving the PIN tag.\nTTR is a measurement of the number of types within\nthe first 400 tokens of a text.\nIn non-credible economy news, there was a con-\nsiderably greater frequency of conjuncts and ad-\njectives. This observation opposes the findings of\nNewman et al. (2003), but is consistent with the\nopposing observations of Addawood et al. (2019).\nA moderate positive relationship was revealed be-\ntween second person pronouns and conditionals\n(0.46) and third person pronouns and past tense\nverbs (0.43) in credible news. In non-credible news,\nadjectives had the largest effect on average word\nlength (0.53), which is similar to previous observa-\ntions on hard news (Francis, 2018). There is also a\nmild positive correlation between private verbs and\nwh-clauses (0.31).\nEntertainment: Unlike the other genres, no sin-\ngle feature was remarkably more frequent in credi-\nble or non-credible entertainment news (Table 4).\nHowever, more features overall showed a small to\nmedium effect. A medium effect was observed on\nthe difference between prepositional phrases and\ntype-token ratio, indicating they are more frequent\nin non-credible news. Second person and demon-\nstrative pronouns were also more frequent in non-\ncredible news, but the difference is much smaller. A\nmoderate positive relationship between first person\npronouns and private verbs (0.38) was observed in\ncredible news, suggesting that opinions are more of-\nten stated through the first person in credible news.\nThese observations appear consistent with the the-\nory that liars attempt to distance themselves from\nthe lie by avoiding inclusive pronouns, whereas\ntruth-tellers do not (Sarzynska-Wawer et al., 2023;\nAddawood et al., 2019; Newman et al., 2003; Dzin-\ndolet and Pierce, 2005).\nHealth: The frequency of public verbs was much\nhigher in credible than deceptive health news. Em-\nphatics were more frequent in credible news, which\nmay be surprising considering similar features (i.e.\nsuperlatives and intensifiers) have been linked with\nunreliable news (Mahyoob et al., 2020; Francis,\n2018). Passive constructions and private verbs areFeature Cohen\u2019s dCredible Mean Non-credible Mean\nEmphatics (EMPH) 0.40 0.66 0.18\nPublic Verbs (PUBV) 0.67 1.31 0.43\nAgentless Passives (PASS) 0.48 -0.14 0.33\nPrivate Verbs (PRIV) 0.44 -0.55 -0.24\nThird Person Pronouns (TPP3) 0.39 -0.39 -0.06\nTime Adverbials (TIME) 0.39 -0.55 -0.15\nSplit Auxiliaries (SPAU) 0.40 -0.80 -0.25\nTable 5: Features which show the greatest effect size in\nHealth news. PRIV verbs refer to a mental activity or\nsensation of which an external observer is not directly\naware (e.g., \u2018think\u2019 or \u2018feel\u2019). TIME includes temporal\nadverbs, such as \u2018now\u2019 or \u2018shortly\u2019.\nFeatures Cohen\u2019s dCredible Mean Non-credible Mean\nPronoun \u2018it\u2019 (PIT) 0.64 0.44 -0.19\nEmphatics (EMPH) 0.36 0.27 -0.27\n\u2018That\u2019 Verb Complements (THVC) 0.45 0.07 0.55\nPresent Participle Whiz-Deletion (WZPRES) 0.42 0.55 1.39\nAgentless Passives (PASS) 0.48 -0.39 0.00\nTable 6: Linguistic features which show the greatest\ndisparity in Science news. WZPRES refers to whiz-\ndeletion, where a wh-word and \u2018be\u2019 are deleted in a\nrelative clause.\nmore frequent in non-credible health news (Table\n5), which also contradicts Mahyoob et al. (2020).\nSeveral other features, such as split auxiliaries, ad-\nverbs of time, and third person pronouns, were\nmildly more frequent in non-credible text. There\nis a moderate positive relationship between condi-\ntionals and present tense verbs (0.32), present tense\nverbs and second person pronouns (0.41), and sec-\nond person pronouns and possibility modals (0.34)\nin credible health news texts.\nNon-credible health news showed a moderate\nnegative relationship between average word length\nand past tense verbs (-0.41), while there was\na stronger positive relationship between average\nword length and pure nouns (0.48).\nScience: Emphatics are more common in cred-\nible news, although the effect size is somewhat\nsmall. Credible news also contrasted with non-\ncredible news in frequency of the pronoun \u2018it\u2019 (Ta-\nble 6). Non-credible science news displayed more\npassive constructions, whiz-deletion, and verb com-\nplements with \u2018that\u2019. This is contradictory to Mahy-\noob et al. (2020), where passive voice was found to\nbe more frequent in credible news. Demonstratives\nand demonstrative pronouns have a mild positive\nrelationship between adverbs (0.36 and 0.33 respec-\ntively), present tense verbs (0.32), and main verb\n\u2018be\u2019 (0.31) in credible news text.\nCredible news also showed a moderate relation-\nship positive correlation between adverbs and em-\nphatics (0.37), present tense (0.39), and the main\nverb \u2018be\u2019 (0.38). Similar to economy news, adjec-\nFeature Cohen\u2019s dCredible Mean Non-credible Mean\nEmphatics (EMPH) 0.43 0.28 -0.23\nAdjectives (JJ) 0.43 -0.07 -0.46\n\u2019That\u2019 Verb Complements (THVC) 0.57 -0.56 0.13\nType-Token Ratio (TTR) 0.49 -0.41 -1.40\nTable 7: Linguistic features which show the greatest dis-\nparity between deceptive and credible news for Sports\nnews.\ntives were positively correlated with average word\nlength in the non-credible corpus (0.42). Modi-\nfiers, especially adjectives, have also been found to\nbe features of non-credible news in other studies\n(Addawood et al., 2019; Francis, 2018).\nSports: There is a medium effect on the differ-\nence for type-token ratio, indicating that credible\nsports writing may be slightly more linguistically\ndiverse (Table 7). There was an opposite trend ob-\nserved in the frequency of emphatics, with credible\nnews reporting a positive mean and deceptive a neg-\native mean. Verb complements with \u2018that\u2019 are also\nmuch more frequent in non-credible news. Adjec-\ntives were less common in non-credible sports news\nthan credible, which contradicts observations for\nthe previous topics and existing literature (Adda-\nwood et al., 2019; Francis, 2018). A mild positive\ncorrelation between present tense verbs, demon-\nstrative pronouns (0.34), and first person pronouns\n(0.31) was observed in non-credible sports news.\n5.3 Discussion\nThe higher frequency of past tense verbs, public\nverbs, and subordinate \u2018that\u2019 deletion, combined\nwith the positive correlation between past tense\nverbs and third person pronouns, implies that the\nhigher D2 score for credible economy news may be\nfrom quotations or paraphrasing. Credible content\non the economy may reference experts who explain\nand interpret economic concepts and trends for the\nreader. The relationship between conditionals and\nsecond person pronouns suggests that economic im-\npact on the audience and society may be discussed.\nIn this regard, credible economy news may con-\ntradict previous deception research claiming that\nfeatures like quotations and expressions of possi-\nbility reveal uncertainty.\nThe relationship between private verbs and wh-\nclauses, along with the low frequency of past tense\nverbs, non-credible economy news might express\nuncertainty and employ more appeals to emotion.\nAs mentioned, evocation of emotion and uncer-\ntainty are features typically utilised in deceptivelanguage (Igwebuike and Chimuanya, 2021; New-\nman et al., 2003; Sarzynska-Wawer et al., 2023;\nDzindolet and Pierce, 2005).\nThe correlation between first person pronouns\nand private verbs implies that credible entertain-\nment news includes more conjecture. The lower\nscore for D4 indicates that author opinion is not\novertly expressed in credible entertainment news,\nso the correlation between these two linguistic fea-\ntures may be due to reporting on rumours. The\nslightly higher frequency of second person and\ndemonstrative pronouns in non-credible entertain-\nment news may be explained by the presence of sen-\nsationalist statements often employed in tabloids.\nThe frequency of emphatics and public verbs,\nalong with the correlation between present tense\nverbs, conditionals, and second person pronouns\nsuggests that credible health news may include\nadvice to readers. Furthermore, the positive re-\nlationship between second person pronouns and\npossibility modals suggests that credible news may\ndiscuss the effects of health related content on the\nreader. A general survey of credible health related\nheadlines reveals that content often covers medi-\ncal advancements and changes in legislation which\ncould potentially impact readers. Deceptive health\nnews showed more passive constructions and pri-\nvate verbs than credible, which appears to oppose\nMahyoob et al. (2020)\u2019s findings.\nThe higher frequency of emphatics and pronoun\n\u2018it\u2019, in addition to the relationship between demon-\nstratives and adverbs, suggests that credible science\nnews enthusiastically discusses concepts and ob-\njects more than individuals.\nNon-credible sports news uses more \u2018that\u2019 verb\ncomplements and public verbs. It also demon-\nstrated a positive relationship between present tense\nverbs, demonstrative, and first person pronouns.\nThis may hint that non-credible sports news in-\ncludes more commentary. The use and misuse of\nquotations has been identified as a feature of decep-\ntive writing that conveys uncertainty (Kasseropou-\nlos and Tjortjis, 2021; Bell, 1991). Given the low\nscore for expression of persuasion, comments in\nthe first person may be attributed to quotes from\nathletes or sports officials.\nOverall, notable differences were observed be-\ntween non-credible and credible news in all top-\nics. Perhaps unsurprisingly, sports news showed\nthe least difference between the corpora. As ar-\ngued by Fowler (1991), conversation is a vehicle\nof ideology. Ideological values are likely more\nreadily expressed through the topics of economy\nand health rather than sports. Dimension scores for\ndeceptive news indicate a generally higher level of\ntechnical language and formality. Although some\nresearch has found fake news to be less complex\n(Kasseropoulos and Tjortjis, 2021; Sousa-Silva,\n2022), this is consistent with Fowler\u2019s analysis.\nFowler (1991) noted that aspects of hysterical style\ninclude an excess of negative emotion conveyed\nthrough technical jargon, metaphor, and quantifica-\ntion.\n6 Conclusions and future work\nAlthough differences between credible and non-\ncredible news were observed in all topics, details\nvaried considerably. Importantly, while not all\ncues of deception identified in previous literature\nwere present in every domain, most topics showed\nat least one characteristic of deceptive language.\nPlank (2016) argues that many NLP models suffer\nwhen applied to the real world because they are\ntrained on canonical data. While there appears to\nbe some characteristics of deceptive news text that\nare shared, primarily technical language, topic dif-\nferences between credible and non-credible news\nare too varied for tasks involving canonical \u2018fake\nnews\u2019. For non-credible news classification tasks,\nit is beneficial to focus on adapting approaches to\nspecific topics.\nAppeals to emotion and language that elicits\nnegative emotion have been identified as features\nof deceptive language and text (Newman et al.,\n2003; Sarzynska-Wawer et al., 2023; Igwebuike\nand Chimuanya, 2021). In the future, it will be use-\nful to investigate negativity in non-credible news\ntopics by using psycholinguistic features with Lin-\nguistic Inquiry and Word Count (LIWC). In light\nof recent technological advancements, it would\nalso be interesting to compare LLM generated non-\ncredible news to see if features of deception are\nalso present in generated news. Further research\nmay also look into stylistic differences in news\nfrom other regions as deception cues are likely to\nvary based on culture and language.\n7 Limitations\nThe analysis would benefit from further investiga-\ntion with discourse processing and the inclusion of\npsycholinguistic features. While it is not possible\nto investigate all latent variables that may affectdifferences between genres and deceptive writing,\nit would be beneficial to include an analysis on the\nimpact of negation and negativity in non-credible\nnews text. Additionally, as the data is limited to\nEnglish from North America, it is possible that cul-\ntural differences related to deception might result\nin different patterns. Relatedly, writer demographic\n(e.g. age, sex, nationality, etc.) may affect decep-\ntion cues in a text. However, such information is\noften difficult to discover and may be ethically trou-\nblesome to include. The features investigated in\nthis paper are a good focal point, as they have been\nwell studied and are easily accessible.\n8 Ethical concerns\nThe decision to consider a piece or source of news\nmedia deceptive can be problematic. Relying on\nsimple falsity is often not reliable, as being untruth-\nful is not always to lie (Simpson, 1992). Further-\nmore, labels like \u2018fake news\u2019 are often used as polit-\nical tools to discredit unfavourable interpretations.\nEven efforts to protect readers from legitimate dis-\ninformation can be perceived as censorship. Bias\nis an inherent part of news, as institutions always\nreport from an angle which is socially, politically,\nand economically situated (Fowler, 1991).\nAs a researcher of non-credible news, it is im-\nportant to consider the implications of attaching\nlabels to media. This is even more important for\nautomatic classification, where false positives and\nnegatives can be particularly damaging. An argu-\nment can also be made that exposing character-\nistics which differentiate credible from deceptive\nnews may assist nefarious actors in creating more\nconvincing fakes. While this is a possibility, it\nis probably more likely that \u2018fake news\u2019 creators\nare already aware of these differences. Even if re-\nsearch on non-credible news can be exploited, the\npotential misuse of one\u2019s research is not a sufficient\nargument against the pursuit of knowledge.\n9 Data and code availability\nMany deceptive news sites used in the corpus have\nbecome defunct or are no longer updated, but ac-\ncess may be possible through internet archives. To\nrespect copyright, data has not been made public.\nCode and a description of the data are available on\nGithub. Interested parties are encouraged to reach\nout to the authors for more information.\nReferences\nAseel Addawood, Adam Badawy, Kristina Lerman, and\nEmilio Ferrara. 2019. Linguistic cues to deception:\nIdentifying political trolls on social media. Proceed-\nings of the International AAAI Conference on Web\nand Social Media , 13:15\u201325.\nLucas Azevedo, Mathieu d\u2019Aquin, Brian Davis, and\nManel Zarrouk. 2021. Lux (linguistic aspects un-\nder examination): Discourse analysis for automatic\nfake news classification. Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021 ,\npages 41\u201356.\nMitchell T. Bard. 2017. Propaganda, persuasion, or jour-\nnalism?: Fox news\u2019 prime-time coverage of health-\ncare reform in 2009 and 2014. Electronic News ,\n11:100\u2013118.\nAllan Bell. 1991. The Language of News Media . Lan-\nguage in society. Blackwell.\nDavid M. Bersoff and Tonia E. Ries. 2024. 2024 edel-\nman trust barometer global report. Technical report,\nEdelman Trust Institute.\nPranav Bharadwaj and Zongru Shao. 2019. Fake news\ndetection with semantic features and text mining. In-\nternational Journal on Natural Language Computing\n(IJNLC) , 8.\nDouglas Biber. 1988. Variation across Speech and Writ-\ning. Cambridge University Press.\nJudee K. Burgoon, J. P. Blair, Tiantian Qin, and Jay F.\nNunamaker. 2003. Detecting deception through lin-\nguistic analysis. In International Conference on In-\ntelligence and Security Informatics , volume 2665,\npages 91\u2013101. Springer Verlag.\nMichael D. Cobb and James H. Kuklinski. 1997. Chang-\ning minds: Political arguments and political persua-\nsion. American Journal of Political Science , 41:88.\nMary T. Dzindolet and Linda G. Pierce. 2005. Using a\nlinguistic analysis tool to detect deception. Proceed-\nings of the Human Factors and Ergonomics Society\nAnnual Meeting , 49:563\u2013567.\nRoger Fowler. 1991. Language in the news: Discourse\nand Ideology in the Press . Routledge.\nEmilie Francis. 2018. Misinfowars: A linguistic analy-\nsis of deceptive and credible news. Master\u2019s thesis,\nSimon Fraser University.\nGeorgios Gravanis, Athena Vakali, Konstantinos Dia-\nmantaras, and Panagiotis Karadais. 2019. Behind the\ncues: A benchmarking study for fake news detection.\nExpert Systems with Applications , 128:201\u2013213.\nJack Grieve and Helena Woodfield. 2023. The Lan-\nguage of Fake News . Cambridge University Press.Benjamin D. Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repeti-\ntive content in text body, more similar to satire than\nreal news. Proceedings of the International AAAI\nConference on Web and Social Media , 11:759\u2013766.\nEbuka Elias Igwebuike and Lily Chimuanya. 2021. Le-\ngitimating falsehood in social media: A discourse\nanalysis of political fake news. Discourse and Com-\nmunication , 15:42\u201358.\nDimitrios Panagiotis Kasseropoulos and Christos\nTjortjis. 2021. An approach utilizing linguistic fea-\ntures for fake news detection. IFIP Advances in In-\nformation and Communication Technology , 627:646\u2013\n658.\nLukas Kurasinski and Radu Casian Mihailescu. 2020.\nTowards machine learning explainability in text clas-\nsification for fake news detection. Proceedings - 19th\nIEEE International Conference on Machine Learning\nand Applications, ICMLA 2020 , pages 775\u2013781.\nGleb Kuzmin, Daniil Larionov, Dina Pisarevskaya, and\nIvan Smirnov. 2020. Fake news detection for the\nrussian language. In Proceedings of the 3rd Inter-\nnational Workshop on Rumours and Deception in\nSocial Media (RDSM) , pages 45\u201357. Association for\nComputational Linguistics.\nRichard R. Lau, Richard A. Smith, and Susan T. Fiske.\n1991. Political beliefs, policy interpretations, and\npolitical persuasion. The Journal of Politics , 53:646\u2013\n675.\nDavid M.J. Lazer, Matthew A. Baum, Yochai Ben-\nkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo\nMenczer, Miriam J. Metzger, Brendan Nyhan, Gor-\ndon Pennycook, David Rothschild, Michael Schud-\nson, Steven A. Sloman, Cass R. Sunstein, Emily A.\nThorson, Duncan J. Watts, and Jonathan L. Zittrain.\n2018. The science of fake news: Addressing fake\nnews requires a multidisciplinary effort. Science ,\n359:1094\u20131096.\nOr Levi, Pedram Hosseini, Mona Diab, and David A.\nBroniatowski. 2019. Identifying nuances in fake\nnews vs. satire: Using semantic and linguistic cues.\nInProceedings of the Second Workshop on Natural\nLanguage Processing for Internet Freedom: Censor-\nship, Disinformation, and Propaganda , pages 31\u201335.\nAssociation for Computational Linguistics (ACL).\nMohammad Mahyoob, Jeehaan Al-Garaady, and\nMusaad Alrahaili. 2020. Linguistic-based detection\nof fake news in social media. International Journal\nof English Linguistics , 11:99.\nKatarina Eva Matsa. 2023. More americans are getting\nnews on tiktok, in contrast with most other social\nmedia sites.\nMatthew L. Newman, James W. Pennebaker, Diane S.\nBerry, and Jane M. Richards. 2003. Lying words:\nPredicting deception from linguistic styles. Personal-\nity and Social Psychology Bulletin , 29:665\u2013675.\nAndrea Nini. 2019. The Multi-Dimensional Analysis\nTagger , pages 67\u201394. Bloomsbury Publishing PLC.\nBarbara Plank. 2016. What to do about non-standard (or\nnon-canonical) language in nlp. Conference on Natu-\nral Language Processing (KONVENS 2016) , pages\n13\u201320.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Janek\nBevendorff, and Benno Stein. 2018. A stylometric\ninquiry into hyperpartisan and fake news. ACL 2018\n- 56th Annual Meeting of the Association for Compu-\ntational Linguistics, Proceedings of the Conference\n(Long Papers) , 1:231\u2013240.\nRandolph Quirk, Sidney Greenbaum, Geoffrey Leech,\nand Jan Svartvik. 1985. A Comprehensive Grammar\nof the English Language . Longman.\nArun Ram. 2023. As elections approach, parties re-\nactivate their fake news departments. The Times of\nIndia .\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In EMNLP 2017 - Conference\non Empirical Methods in Natural Language Process-\ning, Proceedings , pages 2931\u20132937. Association for\nComputational Linguistics (ACL).\nVictoria Rubin, Nadia Conroy, and Yimin Chen. 2015.\nTowards news verification: Deception detection meth-\nods for news discourse. In The Hawaii International\nConference on System Sciences (HICSS48)5 , pages\n5\u20138.\nJustyna Sarzynska-Wawer, Aleksandra Pawlak, Julia\nSzymanowska, Krzysztof Hanusz, and Aleksander\nWawer. 2023. Truth or lie: Exploring the language\nof deception. PLOS ONE , 18:e0281179.\nDavid Simpson. 1992. Lying, liars and language. Phi-\nlosophy and Phenomenological Research , 52:623.\nRui Sousa-Silva. 2022. Fighting the fake: A forensic lin-\nguistic analysis to fake news detection. International\nJournal for the Semiotics of Law , 35:2409\u20132433.\nFrancielle Vargas, Jonas D \u2019Alessandro, Zohar Rabi-\nnovich, Fabr\u00edcio Benevenuto, and Thiago A S Pardo.\n2022. Rhetorical structure approach for online de-\nception detection: A survey. In Proceedings of the\nThirteenth Language Resources and Evaluation Con-\nference (LREC) , pages 5906\u20135915.\nFrancielle Alves Vargas and Thiago Alexan-\ndre Salgueiro Pardo. 2021. Studying dishonest\nintentions in brazilian portuguese texts. Communica-\ntions in Computer and Information Science , 1296\nCCIS:166\u2013178.\nPawan Kumar Verma, Prateek Agrawal, Ivone Amorim,\nand Radu Prodan. 2021. Welfake: Word embed-\nding over linguistic features for fake news detection.\nIEEE Transactions on Computational Social Systems ,\n8:881\u2013893.Michela Del Vicario, Walter Quattrociocchi, Antonio\nScala, and Fabiana Zollo. 2018. Polarization and\nfake news: Early warning of potential misinformation\ntargets. ACM Transactions on the Web , 13.\nDustin V olz and Michael R. Gordon. 2023. China is\ninvesting billions in global disinformation campaign,\nu.s. says. The Wall Street Journal .\nLuxuan Wang and Naomi Forman-Katz. 2024. What\namericans like and dislike about getting news on\nsocial media.\nDave Van Zandt, Aaron O\u2019Leary, Kenneth White, Jim\nFowler, Dennis Kelley, Michael Allen, McKenzie\nHuitsing, Jemal Corliss, and Mike Crowe. 2023.\nGlobal research \u2013 bias and credibility.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Variation between credible and non-credible news across topics", "author": ["E Francis"], "pub_year": "2024", "venue": "arXiv preprint arXiv:2411.12458", "abstract": "'Fake News' continues to undermine trust in modern journalism and politics. Despite continued  efforts to study fake news, results have been conflicting. Previous attempts to analyse and"}, "filled": false, "gsrank": 596, "pub_url": "https://arxiv.org/abs/2411.12458", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:ZQC90KoFm3QJ:scholar.google.com/&output=cite&scirp=595&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D590%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZQC90KoFm3QJ&ei=cbWsaOqkD7TWieoP1pCJ2AY&json=", "num_citations": 2, "citedby_url": "/scholar?cites=8402315760994418789&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZQC90KoFm3QJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2411.12458?"}}, {"title": "Account credibility inference based on news-sharing networks", "year": "2024", "pdf_data": "Truong et al. EPJDataScience           (2024) 13:10 \nhttps://doi.org/10.1140/epjds/s13688-024-00450-9\nRESEARCH OpenAccess\nAccountcredibilityinferencebasedon\nnews-sharingnetworks\nBaoTranTruong1*,OliverMelbourneAllen1,2andFilippoMenczer1\n*Correspondence: baotruon@iu.edu\n1ObservatoryonSocialMedia,\nIndianaUniversity,Bloomington,\nUSA\nFulllistofauthorinformationis\navailableattheendofthearticleAbstract\nThespreadofmisinformationposesathreattothesocialmediaecosystem.E\ufb00ective\ncountermeasurestomitigatethisthreatrequirethatsocialmediaplatformsbeableto\naccuratelydetectlow-credibilityaccountsevenbeforethecontenttheysharecanbe\nclassi\ufb01edasmisinformation.Herewepresentmethodstoinferaccountcredibility\nfrominformationdi\ufb00usionpatterns,inparticularleveragingtwonetworks:thereshare\nnetwork,capturinganaccount\u2019strustinotheraccounts,andthebipartite\naccount-sourcenetwork,capturinganaccount\u2019strustinmediasources.Weextend\nnetworkcentralitymeasuresandgraphembeddingtechniques,systematically\ncomparingthesealgorithmsondatafromdiversecontextsandsocialmedia\nplatforms.Wedemonstratethatbothkindsoftrustnetworksprovideusefulsignalsfor\nestimatingaccountcredibility.Someoftheproposedmethodsyieldhighaccuracy,\nprovidingpromisingsolutionstopromotethedisseminationofreliableinformationin\nonlinecommunities.Twokindsofhomophilyemergefromourresults:accountstend\ntohavesimilarcredibilityiftheyreshareeachother\u2019scontentorsharecontentfrom\nsimilarsources.Ourmethodologyinvitesfurtherinvestigationintotherelationship\nbetweenaccountsandnewssourcestobettercharacterizemisinformationspreaders.\nKeywords: Informationspread;Socialmedia;Misinformation;Networkanalysis;\nCredibility\n1 Introduction\nManypeoplearenowgettingnewsfromsocialmedia[ 1].Withjustaclickonthe\u201cShare\u201d\nbutton,anyonecanbeabroadcasterofnewsontheseplatforms.Suchalowbarrier,com-\nbinedwithunevenjournalisticstandardsinonlinenews,hasfacilitatedthespreadofmis-\ninformationintheinformationecosystem[ 2].Suchproliferationofmisinformationposes\ngravethreatstodemocracy[ 3],theeconomy[ 4],andpublichealth[ 5\u20138].\nExistingmethodstocurbmisinformationfocusonclassifyingeitherthecontentorthe\naccountpostingit.However,multiplechallengesexistforcontent-basedmethods,posing\naneedformethodstoevaluatesourcesinsteadof(orinadditionto)thecontentitself.In\nparticular, traditional fact-checking methods involving human e\ufb00orts to manually verify\ntheaccuracyofclaimscannotscalewiththesheervolumeandspeedofinformationbeing\nsharedonline.Automaticmisinformationdetectioncouldpotentiallyovercometheprob-\nlemofscale.Butwhentheywork,thesemethodsrelyonextensivelanguagefeaturessuch\n\u00a9TheAuthor(s)2024. OpenAccess ThisarticleislicensedunderaCreativeCommonsAttribution4.0InternationalLicense,which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit\ntotheoriginalauthor(s)andthesource,provide a linktotheCreative Commonslicence,and indicateifchangeswere made.The\nimagesorotherthirdpartymaterialinthisarticleareincludedinthearticle\u2019sCreativeCommonslicence,unlessindicatedotherwise\nin a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright\nholder.Toviewacopyofthislicence,visit http://creativecommons.org/licenses/by/4.0/ .\nTruong et al. EPJDataScience           (2024) 13:10 Page2of19\naswriting style,lexicon,andemotion[ 9].Thereforethey needto beconstantlyretrained\ntore\ufb02ectnewknowledgeandevolvingtacticsemployedbypurveyorsoffalseinformation.ThesechallengesareexacerbatedbytheriseofcontentcreatedbygenerativeAI.Theavail-ability of open-source large language models (LLMs) brings down the cost of generating\ncontent,creatingopportunitiesformaliciousactorstospreadmisleadingcontentandin-\n\ufb02uence public opinion [ 10,11]. Worse yet, LLMs\u2019 ability to mimic writing styles makes\nthistypeofcontentpersuasiveyetverychallengingtodetect[ 12].\nIn this paper, we propose several methods to infer the credibility of news-sharing ac-\ncountsonsocialmediatodetectlow-credibilityaccountslikelytospreadmisinformation.Thecredibilityofanewssourceoraccountmaydependonmanyfactors,includingreputa-tionandadherencetofactualreportingandtransparency.Moreprecisely,wede\ufb01ne high-\ncredibility news sources to be those that meet objective journalistic criteria as assessed\nby third-party fact-checking organizations [ 13,14]. Following that, credible accounts are\nthosewhoshareorresharehigh-credibilitysources.Credibilityindicators provideusefulsignals for consumers to navigate the information landscape: they not only help peopleseeking information outlets [ 15] but can also decrease the propensity to share misinfor-\nmation[16]byraisinguserawareness.Knowingunreliable,in\ufb02uentialaccountsmightalso\naidplatformsinmitigatingtheirimpact.\nNews-sharingdecisionsonsocialmediadependontheactualcontentaswellason trust\ninwhosharesit[ 15,17]andwhatmediaoutletitoriginatesfrom[ 18].Wheninformation\nsharing on social media is represented as a network connecting accounts and/or news\nsources, we can apply network analysis methods to infer node properties by propagating\nlabelsacrosslinks[ 19\u201321].Mostexistingnetwork-basedmethodstodetectlow-credibility\naccounts[ 20]focussolelyoninteractionsbetweenaccounts.However,bipartitenetworks\ncapturing the reinforcing relationship between news outlets and consumers have beenshowntobee\ufb00ectiveforclassifyingmisinformationcontent[ 22].Thismeritsfurtherex-\naminationoftheinteractionsbetweenaccountsandsourcestobetterunderstandthechar-acteristicsofmisinformationspreaders.\nSocial context is useful in detecting fake news [ 23]. Generalizing this observation, we\nhypothesize that it is possible to infer the credibility of an account by looking at eitherthe sources or the other accounts they trust. The fundamental assumption underlyingsuchinferenceistheexistenceof credibilityhomophily amongmisinformationspreaders.\nHomophily can be de\ufb01ned based on di\ufb00erent network relationships, such as following,resharing,co-sharing,andsoon.Forexample,adjacentnodesintheresharenetwork(ac-counts that reshare each other) trust each other, so they should have similar credibility.Whiletrustinaccounts andtrustinsources arebothreasonableassumptionsforthetask,\nnootherworkhascomparedtheire\ufb00ectivenessinthesamesettings.\nWeexplorethreeresearchquestions:\n\u2022Q1:Istherecredibilityhomophilyintheresharenetwork?\n\u2022Q2:Istherecredibilityhomophilyintheco-sharenetwork?\n\u2022Q3:Canweinferthecredibilityofaccountsbyleveragingsuchhomophilyand\nlookingatneighbornodesinthereshareorbipartite/co-sharenetworks,i.e.,byexaminingthetrustrelationshipsamongaccountsorbetweenaccountsandsources?\nIn this paper, we propose several network-based methods \u2014 including centrality mea-\nsuresandgraphembeddings\u2014toinferthecredibilityofnews-sharingaccountsonsocialmedia.Weexplore Q1usingtheresharenetwork,whereadirectededgerepresentstrust\nTruong et al. EPJDataScience           (2024) 13:10 Page3of19\nbyoneaccountinanother.Weexplore Q2usingthebipartitenetworkwhereaccountsare\nconnectedtothenewssourcestheyshare.Thepapermakesthreecontributions:\n1. Weintroduceseveralmethodstomeasurethecredibilityofaccountsbyleveraging\ndi\ufb00erentkindsofinformation-sharingnetworks.\n2. Weintroduceanevaluationframeworktosystematicallyestimateandcomparethe\naccuracyofouralgorithmsusingempiricaldatafrommultiplecontextsandsocialmediaplatforms.\n3. Weshowthattherearetwokindsofhomophilyamonginformationspreaders:\naccountstendtoresharecontentfromindividualswithsimilarcredibility( Q1)and\ntosharecontentfromthesamesourcesasindividualswithsimilarcredibility( Q2).\nThesedi\ufb00usionpatternsexplainthee\ufb00ectivenessofnetworkmethodsthatestimateanaccount\u2019scredibilityusingtheirtrustinotheraccountsorinsources( Q3).\nAfter reviewing related work, we present our methodology, including the de\ufb01nition of\nthe credibility inference task and algorithms leveraging an account\u2019s trust in other ac-countsandinsources,respectively.Wethendescribetheexperimentalsetupanddiscuss\ntheevaluationresults.\n2 Relatedwork\nOne approach to detect credible accounts uses heuristics such as the assumption that\nonline opinion leaders are credible [ 24]. This assumption is violated by misinformation\nsuperspreaders [ 8,25,26] and leaves out potentially credible ordinary users. Therefore\nthis paper focuses on network-based approaches that leverage accounts\u2019 connectivity inadditiontoheuristics.\nPageRank [27]isawidelyusedcentralitymeasurethatassignsscoresfornodesinadi-\nrected network by simulating a di\ufb00usion process through the network analogous to ran-domsur\ufb01ngamongwebpages. PersonalizedPageRank [28]incorporatespriorknowledge\nabout the importance of some nodes by constraining the random surfer to stay close to\nthosenodes.MethodsextendingPageRankandPersonalizedPageRankhavebeenapplied\nto measure trust in peer-to-peer (P2P) networks. EigenTrust was used to obtain global\nreputationvaluesforeachuser[ 29];PowerTrust [30]andTrustRank [31,32]wereusedto\nranksearchresults.Di\ufb00erentfromexistingwork,oneofourproposedmethodsattempts\ntoinferaccountcredibilityby\ufb01ndingthehighest-rankingnodesinanetworkwheremis-\ninformation, rather than trust, propagates. Methods have been introduced that similarlymodel the spread of \u201cdistrust\u201d to measure trustworthiness in P2P networks [ 33\u201335]. To\nourknowledge,nopriorworkhasexploreddistrustinsocialnews-sharingnetworks.\nAnother well-known network centrality method is Hyperlink-Induced Topic Search\n(HITS)[36]. This method ranks the web pages returned by a search query by assuming\nthat hubs are useful in leading a web surfer to authoritative pages. Several algorithms\nextend HITS. Co-HITS [37]a n dBipartite Graph Reinforcement Model (BGRM) [38]i n -\ncorporate pre-existing information about the relevance of some web pages to constrain\nthe \ufb01nal scores. BiRank[39] is a similar extension developed for n-partite graphs. In the\ncontextofsocialmedia,HITShasbeenusedto\ufb01ndin\ufb02uentialusers[ 40]aswellashigh-\nqualitycontent[ 41].OneofourproposedmethodsextendsHITSwhilemaximizingprior\nknowledge about accounts to produce accurate credibility scores. The intuition is thatmisinformationsharersarehubsleadingtounreliablenewssources,andviceversa.\nMachinelearningmethodshavebeenemployedtoclassifysocialmediaaccountsbased\non their credibility. Previous studies have trained models on features engineered from\nTruong et al. EPJDataScience           (2024) 13:10 Page4of19\nau s e rp r o \ufb01 l e[ 42,43] or the content they post [ 44,45]. Graph embedding methods are\npopularmeanstoobtain acompactrepresentation ofnodes inanetwork.Sincenetwork\nstructureinformationispreserved,nodeswithsimilarpositionsinthenetworkhavevec-\ntors that are close together in the embedding space [ 46\u201348]. These methods have been\napplied to classify rumor-spreading accounts in retweet networks, in combination with\nadditional features such as an account\u2019s inferred believability [ 20], screen name, pro\ufb01le\ndescription,andactivitylevel[ 49].Weexploresimplermethodsthatonlyusevectorscap-\nturinganaccount\u2019spositioninthenetworkinsomeofthealgorithmsproposedhere.\n3M e t h o d s\nThe task is formalized as follows: given (i) a set of posts with links to news articles and\n(ii) credibility labels for a subset of accounts, assign credibility scores to the unlabeled\naccounts.\nAn overview of the pipeline for mining social media for this task is presented in Fig. 1.\nThepipelineconsistsof\ufb01vesteps:\n1. Socialmediadataiscollectedandcleaned.Thedataincludesasetofknownlabels\nandalistofinteractionsbetweenaccounts,forexample,viatweetsorretweets.\n2. Di\ufb00erentnetworkscanbeconstructedtocapturedistinctpotentialsignals.The\nresharenetworkcapturesanaccount\u2019strustinotheraccounts.Someofour\nalgorithmsusethetrustnetwork\u2014thetransposeofthisresharenetwork.The\nbipartite account-sourcenetworkcapturesanaccount\u2019strustinsources.The\nco-sharenetworkisobtainedbyprojectingthebipartitenetworkontoaccount\nnodes.\n3. Welabelasubsetofaccountnodesinthenetwork.Theselabelsarederivedfrom\nsourcecredibilityscoresprovidedbyafact-checkingorganization,suchas\nNewsGuard1orMediaBiasFactCheck.2Toobtainanaccountlabel,wecalculate\nFigure1 Pipelineforminingtrustpatternsfrominformation-sharingdata .Trustinaccountsismodeledbythe\nresharenetwork(top);trustinsourcescanbemodeledbythebipartiteaccount-sourcenetwork(middle),ora\nprojectionofit,theco-sharenetworks(bottom).Colorsrepresentcredibilitylabels:orangeandpurplefor\nhigh-andlow-credibility,respectively\n1newsguardtech.com .\n2mediabiasfactcheck.com .\nTruong et al. EPJDataScience           (2024) 13:10 Page5of19\ntheweightedmeanofallthesourcestheysharedandthenapplyathresholdtothis\nmeanscore,followingtheorganization\u2019sstandardforthecredibilitythreshold.\n4. Eachalgorithmisappliedtopropagateorcomputecredibilityscoresforallnodes.\n5. Lastly,unlabeledaccountsarerankedbytheircredibilityscoresforevaluation.\nIn the next subsections, we present several methods to infer account credibility based\nontrustinaccountsorsources.Ineachcase,weevaluatecentrality-basedmethodsandan\nembeddingalgorithm.Centrality-basedmethodsarelesssophisticatedbutmoree\ufb03cientandinterpretable.\n3.1 Trustinaccounts\nWe describe algorithms to calculate an account\u2019s credibility by leveraging their trust inother accounts. Trustworthiness can be inferred from the trust network G\nT,i nw h i c ha\nlink goes from Alice\u2192Bobif Alice follows or reshares Bob. In line with previous work,\ntheseactionscanbeconsideredendorsementsthatsignaltrustbythesharingaccountintheaccountbeingshared[ 20,50\u201352].\nThetrustnetworkisthetransposeofthe resharenetwork G ,aweighted,directedgraph\nwherethenodesrepresentaccountsandedgescorrespondtoreshareinteractionsamong\naccounts. Edges follow the direction of information spread (from reshared to resharing\naccount)andareweightedbythenumberofreshares.Let G\nij=nifjretweets intimes.\nFinally, we assume that some accounts have credibility labels. Let Hbe a set of nodes\nthatareknowntohavehighcredibilityand Lasetofnodesknowntohavelowcredibility.\n3.1.1 PageRankTrust\nThe PageRank family of algorithms can be used to calculate account trustworthinessscores based on this signal. An account\u2019s PageRank Trust score is calculated iteratively\nusingaweightedversionofPageRank:\n\u03c4\nt+1\ni=(1\u2013 \u03b1)/summationdisplay\njGT\nji/summationtext\n/lscriptGT\nj/lscript\u03c4t\nj+\u03b1\nN,( 1 )\nwheretis the iteration step, \u03b1is the teleportation factor. The intuition of this method\nisthataccountswithmanyincominglinksaretrustedandthereforehavehighPageRank\nTrustscores,indicatinghighcredibility.\n3.1.2 PersonalizedPageRankTrust\nInformation about some high-credibility nodes may be available. To incorporate this in-\nformation,anaccount\u2019sPersonalizedPageRankTrustiscalculatedasfollows:\n\u03c4t+1\ni=(1\u2013 \u03b1)/summationdisplay\njGT\nji/summationtext\n/lscriptGT\nj/lscript\u03c4t\nj+\u03b1\u03c40\ni,( 2 )\nwhere \u03c40\niisde\ufb01nedby:\n\u03c40\ni=\u23a7\n\u23a8\n\u23a91\n|H|ifi\u2208H,\n0o t h e r w i s e .(3)\nTruong et al. EPJDataScience           (2024) 13:10 Page6of19\nUnder this scheme, accounts that are trusted by credible accounts ( Hlist) have higher\nPersonalizedPageRankTrust,indicatinghighcredibility.\n3.1.3 TrustRank\nThis method \ufb01rst creates a quality seed set, ideally to be evaluated by experts, then usesthislisttopropagatescores.Toapplythemethodinourcontext,PageRankTrust(Eq.( 1))\nis \ufb01rst used to select a set Sof seed accounts with highest PageRank Trust scores, where\n|S|isaparameter.Theseseedsarelabeledas\u201cgood\u201dor\u201cbad\u201ddependingonavailablecred-\nibilitylabels:\n\u03c4\n0\ni=\u23a7\n\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23a91i fi\u2208H\u2229S,\n0i fi\u2208L\u2229S,\n1\n2otherwise.(4)\nTrustRank scores are then calculated using Personalized PageRank Trust (Eq. ( 2)) with\nthese\u03c40\nivalues.\n3.1.4 LoCred\nThemethodsmentionedsofarrelyontheobservationthatgoodpagesseldompointtobadones[31].Decisionstocirculatenewsonlinearenotasstraightforward\u2014badcontentis\ndesignedtomisleadandpeoplecouldbesociallymotivated.Therefore,wecannotassumethat\u201cgoodpeopleseldomtrustbadones,\u201dorbesurethatcredibleaccountsdonotresharefromlow-credibilityaccounts.\nWe propose a method that uses the di\ufb00usion of information to capture an account\u2019s\ncredibility without the assumption that accounts have good judgment. This method isperformedontheresharenetwork.Ifanoderesharesalot,itmightbegullible.Theseac-countsmightnotspreadmisinformationintentionallybutshouldbedistrustednonethe-less. The Lo\nwC r e dibility Account Estimation ( LoCred) score is devised to capture such\nspreadersofmisinformation.\nThe LoCred score sifor each node iis calculated iteratively until convergence as a\nweightedversionofpersonalizedPageRank:\nst+1\ni=(1\u2013 \u03b1)/summationdisplay\njGji/summationtext\n/lscriptGj/lscriptst\nj+\u03b1s0\ni,( 5 )\nwheretistheiterationstep, \u03b1istheteleportationfactor,andtheinitialvalue s0\niisde\ufb01ned\nasfollows:\ns0\ni=\u23a7\n\u23a8\n\u23a91\n|L|ifi\u2208L,\n0o t h e r w i s e .(6)\nAccounts close to nodes in Lhave higher LoCred scores, indicating low credibility. Note\nthat the initial values in Eqs. ( 3)a n d(6) are di\ufb00erent. But even if they were the same, the\nrankingsbasedonEqs.( 2)and(5)wouldnotsimplybethereverseofeachotherbecause\ntheeigenvectorsofamatrixandthoseofitstransposearedi\ufb00erentforasymmetricmatri-ces.\nTruong et al. EPJDataScience           (2024) 13:10 Page7of19\n3.1.5 Reputationscaling\nLastly,weintroduce ReputationScaling ,ameasurethatbalancestheperceivedtrustwor-\nthiness of anaccountand its spreading of misinformation. This methodbuilds onan ap-\nplicationfordistributedP2Psystems[ 33].\nThereputationofanaccountis\u201cscaled\u201dbycombiningbothitsLoCredandPersonalized\nPageRank Trust score. We calculate both of these scores, then rank accounts based on a\nreputationscorecalculatedasfollows:\nri=\u03c4i(1\u2013si), (7)\nwhere \u03c4iis the trust of icalculatedwithEq.( 2)a n dsiis its LoCred score calculated with\nEq.(5).Anaccountwithhighreputationisconsideredcredible.\n3.1.6 Node 2veconresharenetwork\nWe investigate whether an account\u2019s network position provides predictive signals about\nits credibility, i.e., accounts with similar network positions are similarly credible. To this\nend, we use node2vec [ 46] to obtain embedding vectors of accounts from the retweet\nnetwork G. We use the typical values for node2vec parameters. Speci\ufb01cally, vector di-\nmension, window size, numberofwalks, andwalklengthare128, 10, 10, and80, respec-\ntively. The optimization is run for ten epochs. Account node2vec vectors are then used\nin ak-Nearest Neighbors (KNN) classi\ufb01er [ 53]w i t hk= 10 to rank unlabeled accounts.\nWe \ufb01nd the best results by performing a grid search over the random walk bias parame-\ntersp,q\u2208{0.25,0.50,1,2,4 }.Weevaluateeachparametercombinationusing5-foldcross-\nvalidationwith20%labeleddataineachfold.\n3.2 Trustinsources\nWedescribealgorithmstocalculatethecredibilityofaccountsbyleveragingtheirtrustinsources (websites or domains in our case). We hypothesize that the mutually reinforcing\nrelationship between news websites and news consumers can be applied in our bipartite\naccount-sourcenetworktoinferaccountcredibility.Consideraccountsashubsandnews\ndomainsasauthorities:a \u201cgood\u201d accountisonepointing to many\u201cgood\u201d \u2014authoritative,\nhigh-credibility\u2014websites;andviceversa,agoodwebsiteisanodesharedbymanygood\naccounts[ 36].\nLet us de\ufb01ne the account-source network as a weighted bipartite graph where nodes\nconsist of two disjoint sets UandDthat represent accounts and sources, respectively. A\nweighted edge represents the number of times an account shares links to a source. For-\nmally, let Gbe the adjacency matrix such that G\nij=nif account i\u2208Ushares links from\nsourcej\u2208Dntimes.Similartopreviousalgorithms,weassumethatsomeaccountshave\ncredibilitylabels.\n3.2.1 HITS\nHITS[36]updatesaccountandsourcescoresaccordingto\nut+1\ni=/summationdisplay\nj\u2208DAijdt\nj,( 8 )\ndt+1\nj=/summationdisplay\ni\u2208UAijut\ni,( 9 )\nTruong et al. EPJDataScience           (2024) 13:10 Page8of19\nrespectively, where Aij=1ifGij>0 and zero otherwise. The scores are normalized after\neachstep t.\n3.2.2 Co-HITS\nInformationaboutsomehigh-credibilitysourcesmaybeavailable.Co-HITSincorporatesthis information into the propagation to calculate node scores [ 37]. Account and source\nscores are calculated iteratively according to the strength of interactions between nodes\nfromthetwonetworkpartitions,untilconvergence:\nu\nt+1\ni=\u03b1u0\ni+(1\u2013 \u03b1)/summationdisplay\njGijdt\nj/summationtext\n/lscriptGi/lscript, (10)\ndt+1\nj=\u03b2d0+(1\u2013 \u03b2)/summationdisplay\niGijut\ni/summationtext\n/lscriptG/lscriptj, (11)\nrespectively,where \u03b1and\u03b2aretheteleportationfactorsforaccountsandsourcesrespec-\ntively,d0=1 /|D|is the initial value for sources, and u0\niis the initial value for account i,\nde\ufb01nedas:\nu0\ni=\u23a7\n\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23a90i f i\u2208H,\n1i f i\u2208L,\n1/|U|otherwise.(12)\nTheseinitialvaluesarefurthernormalizedsuchthat/summationtext\ni\u2208Uu0\ni=1.Thescoresarenormal-\nized,sonofurthernormalizationisnecessary.\n3.2.3 BGRM\nBGRM[38]issimilartoCo-HITS.Themaindi\ufb00erenceisinthewaytheynormalizenode\nscoresateachiteration(seeTable1in[ 39]formoredetails).\n3.2.4 BiRank\nBiRank [39] is also similar to Co-HITS and BGRM, di\ufb00ering in the way node scores are\nnormalizedateachiteration(seeTable1in[ 39]formoredetails).\n3.2.5 CoCred\nWe propose Co -sharing network-based Cred ibility (CoCred), a measure that, like Co-\nHITS, BGRM, and BiRank, incorporates existing knowledge about some accounts\u2019 cred-\nibility into the credibility estimation of other accounts. The di\ufb00erence is that those algo-rithmsapplytheupdaterulestolabeledaccounts,whereasCoCredpreservestheknownlabels, only rescaling them in the normalization step \u2014 we believe the accounts labels\ncontainverystrongsignals.\nTheCoCredscore u\niforeachaccount iandthecorrespondingscore djforeachsource\njareupdatedateachtimestep taccordingto\nut+1\ni=\u23a7\n\u23a8\n\u23a9u0\ni ifi\u2208H\u222aL,\n\u03b1u0\ni+(1\u2013 \u03b1)/summationtext\njGijdt\nj/summationtext\n/lscriptGi/lscriptotherwise,(13)\nTruong et al. EPJDataScience           (2024) 13:10 Page9of19\ndt+1\nj=\u03b2d0+(1\u2013 \u03b2)/summationdisplay\niGijut\ni/summationtext\n/lscriptG/lscriptj, (14)\nwhere \u03b1and\u03b2are the teleportation factors for accounts and sources, respectively; d0=\n1/|D|is theinitial value forsources, and u0\niis the initial valueforaccount i,asd e \ufb01 n edi n\nEq.(12).NotethatEq.( 14)isthesameasEq.( 11).\nAfter each update, the scores are normalized so that/summationtext\ni\u2208Uui=/summationtext\nj\u2208Ddj=1.Ouralgo-\nrithmconsiderslow-credibilityaccountsasthosesharingunreliablenewssourcesandviceversa.Low-credibilityaccountshavehigherCoCredscores.\n3.2.6 Node 2veconco-sharenetwork\nThebipartiteaccount-sourcenetworkmayalsoprovideinformationaboutsimilarnews-sharingpatternsbetweenaccounts.Toexplorethis,weprojectthebipartitenetworkontoaccount nodes. Speci\ufb01cally, the co-share network is obtained by connecting accounts if\nthey share links to the same sources. It is thus a weighted, undirected graph where thenodes are accounts having at least one shared source in common with another account.\nEachaccountisrepresentedasavectorofshareddomains.Tomitigatethee\ufb00ectofpop-\nular sources on the similarity among accounts, we use Term Frequency \u2014 Inverse Doc-ument Frequency (TF-IDF) vector representations [ 54] where each dimension is a news\nsource. Edges correspond to co-share interactions and are weighted by the cosine simi-larity between the TF-IDF vectors of the two connected accounts. Account embeddingvectors obtained from the co-share network may reveal whether individuals who share\ninformation from the same sources have similar credibility. We use node2vec to obtain\naccountvectorsandusetheminaKNNclassi\ufb01erwith k=10torankunlabeledaccounts.\nThe evaluation of this method uses the same parameter set and optimization procedureasthatofnode2vecontheresharenetworkdescribedabove.\n4 Evaluation\nOur evaluation framework only requires a set of social media posts, and not fol-lower/friend data. We de\ufb01ne the task of classifying low-credibility accounts as follows:\ngiven(i)asetofsocialmediapostswithlinkstonewsarticles,and(ii)credibilitylabelsfor\nasubsetofaccounts,assignabinarylabel\u2014 credibleornotcredible \u2014totheunlabeledac-\ncounts.Thealgorithmsareevaluatedonnetworksextractedfromsocialmediadata.Thedatasets,correspondingnetworks,experimentalsetup,andresultsaredescribedbelow.\n4.1 Data\nWeconsiderthreesocialmediadatasets.\n\u2022 TheTwitter_CoviddatasetincludestweetsaboutCOVID-19,collectedwiththe\nhashtags#coronavirus and#covid19 from9\u201329March2020[ 55].\n\u2022 TheTwitter_Midtermdatasetincludestweetscontaininghashtagsandkeywords\nabouttheU.S.2022Midtermelections[ 56].Weuseasubsetofthiscollection,from8\nOctober\u201318November2022.\n\u2022 TheFacebook_MidtermdatasetcontainsFacebookpostscollectedthesamewayand\nspanningthesameperiodasTwitter_Midterm[ 56].\nWe extract the data \ufb01elds of interest from each social media post, including the user\nID, post ID, and domain names of the shared links. If a link is shortened when shared\nTruong et al. EPJDataScience           (2024) 13:10 Page10of19\nTable 1Retweetnetworkdescriptions\nDataset Nodes Edges Avg.degree Credibilityassortativitycoe\ufb00.\nTwitter_Covid 322,208 382,499 1.2 0.83\nTwitter_Midterm 410,914 762,534 1.9 0.73\nontheseplatforms,apre-processingstepisperformedtoextractthedomainnamefrom\ntheexpandedURL.Postswithdomainnamesofplatformssuchas amazon.com ,yelp.com,\nyoutube.com ,etc.arenotconsidered.Tolimitnoise,wefurtherretainonlyaccountsshar-\ningatleast\ufb01velinksandpostscontainingdomainsthataresharedatleast\ufb01vetimesacrossthe dataset. To assign scores to accounts, we start from source credibility scores, which\nare domain ratings obtained from NewsGuard in April 2021 for the Twitter_Covid and\nOctober2022fortheTwitter_MidtermandFacebook_Midterm.Wethencomputeanac-count score as a weighted mean of the scores of the sources they share. Note that not all\naccountshaveascoreasaresult.Finally,followingNewsGuard\u2019srubric,weuseathreshold\nof60forlabelingaccountswithascorebelow/above60aslow/high-credibility.\n4.2 Networkdescription\n4.2.1 Resharenetwork\nSincereshareinformationisnotincludedinFacebookdata,theresharenetworkcanonly\nbe constructed from the two Twitter3datasets out of the three datasets considered. The\nstatisticsoftheseretweetnetworksaresummarizedinTable 1.Thetablereportsonnet-\nworkassortativitycoe\ufb03cients[ 57]usingaccountcredibilityscores.Thehighcoe\ufb03cients\nareindicativeofcredibilityhomophily(answering Q1).\nThe homophilycan also be observed in the coreof the retweet network (Fig. 2), where\nlow-credibilityaccountstendtoresharefromlow-credibilityaccounts,andviceversa.\n4.2.2 Bipartitenetwork\nThestatisticsofthebipartitenetworksaresummarizedinTable 2.Thecoreofabipartite\nnetworkisvisualizedinFig. 3.\n4.2.3 Co-sharenetwork\nDescriptive statistics of the co-share networks are presented in Table 3.T h e r ei sa na s -\nsortativemixingofcredibilityamongaccounts,suggestingtheexistenceofcredibilityho-\nmophilyintheco-sharenetworks(answering Q2).Thecorebackboneoftheco-sharenet-\nwork,showninFig. 4,illustratesthisothertypeofhomophily:similarlycredibleaccounts\ntendtosharecontentfromsimilarsources.\n4.3 Experimentalsetup\nWe employ the area under the receiver operating characteristic curve (ROC_AUC) andF1 score as metrics for low-credibility account classi\ufb01cation. The maximum value ofROC_AUC, one, indicates that all low-credibility accounts are ranked before other ac-\ncounts, whereas a value of 0.5 corresponds to random ranking. F1 is the harmonic mean\nof precision and recall. An F1 value of one means that the model correctly classi\ufb01es all\n3BecauseourdatawascollectedfromTwitterbeforeitwasrenamed\u2018X,\u2019wecontinuetorefertotheplatformbyitsoriginal\nname.\nTruong et al. EPJDataScience           (2024) 13:10 Page11of19\nFigure2 RetweetnetworkconstructedfromtheTwitter_Coviddataset. Tovisualizethenetwork,we\ufb01lternodes\nandedgesusingk-coredecomposition[ 58](k=3).Colorsrepresentcredibilityscore:orangeandpurplefor\nhigh-andlow-credibilityaccounts,respectively,andgrayforunlabeledaccounts.Nodesizerepresents\nin-strength,i.e.,thenumberofretweetsbytheaccount.Largepurplenodesareknownmisinformation\nsuper-spreaders\nTable 2Bipartitenetworkdescriptions\nDataset Accounts Domains Edges Avg.degree\nTwitter_Covid 474,094 55,539 613,609 1.3\nTwitter_Midterm 126,445 13,415 1,190,390 9.4\nFacebook_Midterm 6950 4141 26,252 17.1\nclasses; zero means all samples are wrongly classi\ufb01ed. The F1 score requires converting\ntheaccountcredibilityscoresprovidedbythealgorithmsintobinarylabelsusingathresh-\nold. We calculate precision and recall for a thousand threshold values spanning the unit\nintervalandselecttheoptimalthresholdthatmaximizestheF1score.\nTruong et al. EPJDataScience           (2024) 13:10 Page12of19\nFigure3 Bipartiteaccount-sourcenetworkconstructedfromtheTwitter_Covid. Forvisualization,onlythe k=4\ncoreofthenetworkisshown.Nodecolorsrepresentaccountcredibilityscores:orangeandpurpleforhigh-\nandlow-credibilityaccounts,respectively,andgrayforunlabeledaccounts.Sourcenodesareinwhite.Node\nsizerepresentsthestrengthofanaccountnode,i.e.,thenumberofpostswithlinksbythataccount\nTable 3Co-sharenetworkdescriptions\nDataset Nodes Edges Avg.degree Credibilityassortativitycoe\ufb00.\nTwitter_Covid 67,657 434,963 1441.7 0.5\nTwitter_Midterm 115,461 59,491,099 515.3 0.8\nFacebook_Midterm 3488 59,653 34.2 0.7\nSinceNewsGuardratingsareavailableforonlyasubsetofdomainssharedinadataset,\nwe assign a label con\ufb01dence score to an account by calculating the fraction of known do-\nmainsthattheyshared;thisnumberisbetweenzeroandone.Themoststringentthreshold\nisusedinourevaluation\u2014onlyaccountswithacon\ufb01dencescoreofoneareusedas known\naccounts tocalculateevaluationmetrics.\nThe evaluation uses 5-fold cross-validation. We hold out a random subset of 20% of\nknown accounts(the test set). For centrality-based methods on the reshare and bipartite\nnetwork, the initial scores of the remaining 80% of accounts are set to their true scores,\nwhilethetestsetstartswithdefaultscoresatthebeginningofpropagation.Similarly,for\nclassi\ufb01cationusingembeddings,wetraintheclassi\ufb01erontheremaining80%ofaccounts.\nTruong et al. EPJDataScience           (2024) 13:10 Page13of19\nFigure4 Co-sharenetworkconstructedfromtheTwitter_Covid .Giventhedensityofthisnetwork,we\naggressively\ufb01lteritforvisualization.We\ufb01rstkeepthe10%ofedgeswiththehighestweightsandthe10%of\nnodesintheinnermostcore( k=4).Thenweapplythemultiscalebackbonemethod[ 59](signi\ufb01cancelevel\n0.3)andretainthegiantcomponentofthebackbonenetwork.Colorsrepresentcredibilityscore:orangeand\npurpleforhigh-andlow-credibilityaccounts,respectively;unlabeledaccountsareingray.Nodesizes\nrepresentcorenumbers:smallernodesareintheperipheryofthenetwork\nFinally,forbothcases,predictedlabelsforaccountsinthetestsetarecheckedagainstthe\ntruelabels.Thereportedmetricsareaveragesofvaluesacross\ufb01vefolds.\nWe use \u03b1=\u03b2= 0.85 for the teleportation factors in all network centrality algorithms.\nThe best node2vec parameters for the retweet networks are p=q= 1.0. For the co-\nshare network, the best node2vec parameters are p=2 . 0,q=0 . 5f o rt h eT wi t t e r _ C o vi d\ndataset,p=q= 1.0 for the Twitter_Midterm dataset, and p=0 . 2 5,q=4 . 0f o rt h eF a c e -\nbook_Midtermdataset.\n4.4 Results\nEvaluation results for the low-credibility account classi\ufb01cation task are summarized inTables4(basedonROC_AUC)and 5(basedonF1scores).Thetrendsinperformanceare\nsimilarforbothmetrics,thereforewefocusonROC_AUC.\nTheresultsshowthatthetrustrelationshipsamongaccountsprovideusefulinformation\ntoe\ufb00ectivelyinfertheircredibility.Inparticular,thebest-performingmethodisnode2veconresharenetworks,withaROC_AUCscoreofmorethan0.88acrossdatasets.Thenext\nTruong et al. EPJDataScience           (2024) 13:10 Page14of19\nTable 4Accountclassi\ufb01cationROC_AUC.Bestresultsforeachdatasetarehighlightedindarker\nshades\nTable 5Accountclassi\ufb01cationF1.Bestresultsforeachdatasetarehighlightedindarkershades\nbest-performing algorithms are LoCred and Reputation Scaling; these algorithms con-\nsiderresharesasinformationdi\ufb00usionchannelswithoutassuminggoodjudgmentbyac-counts.TrustRank,PersonalizedPageRankTrust,andPageRankTrust,whichassumethat\nresharescapturetrustandhencereputation,performonlymarginallybetterthanrandom\natthetask.Theseresultsreinforcethedi\ufb00erencebetweenweb-sur\ufb01ngbehaviorandnews-sharingbehavioronsocialmedia,wheretheassumptionthatgoodaccountsseldomtrust\nbadonesmightnothold.\nThe bipartite/co-share networks capturing account trust in sources also provide ef-\nfective information to estimate account credibility. The best-performing algorithm ineachdatasetachievesaROC_AUCscoreofmorethan0.8(CoCredintheTwitter_Covid\ndatasetandnode2vecintheTwitter_MidtermandFacebook_Midtermdatasets).Among\nthecentrality-basedalgorithmsonthebipartitenetwork,ourproposedalgorithmCoCredperforms the best, followed by Co-HITS and HITS; BGRM and BiRank perform close torandom. CoCred\u2019s high ROC_AUC score con\ufb01rms our intuition that the known account\nlabels provide strong signals and should be preserved in score propagation to produce\naccurateratings.\nIn summary, account credibility can be estimated accurately using trust signals from\nnews-sharingnetworks.Whileallnetworksprovideusefulsignals,theresharenetworkis\nslightlymoreinformativeforthetaskthanthebipartite/co-sharenetworks,basedonthebest-performingalgorithmineachdataset.\nTruong et al. EPJDataScience           (2024) 13:10 Page15of19\nFigure5 AccountembeddingvectorsfortheTwitter_Coviddataset. Node2vecvectorsrepresentingaccounts\nareprojectedontoatwo-dimensionalspaceusingPCAfor(a)reshareand(b)co-sharenetworks.Colors\nrepresentaccountcredibilityscores:orangeandpurpleforhigh-andlow-credibilityaccountsrespectively\nFigure5showsnode2vecembeddingvectorsofaccounts,withtheirdimensionalityre-\nducedusingPrincipleComponentAnalysis(PCA)[ 60].Weobservethattheembeddings\nintheresharenetworkmoree\ufb00ectivelyclusteraccountswithsimilarcredibility,compared\ntotheembeddingsintheco-sharenetwork.\n5 Discussion\nThis paper suggests ways to mitigate misinformation on social media by detecting low-credibility accounts likely to spread misinformation. To this end, we introduce methods\nto infer account credibility based on two information-sharing networks: a reshare net-\nworkcapturingaccounttrustinotheraccountsandabipartitenetworkre\ufb02ectingaccounttrust in information sources. A systematic evaluation shows that the proposed methods\nare e\ufb00ective in detecting low-credibility accounts. The most successful method utilizes\nnode2vec embeddings of accounts on reshare networks, with both ROC_AUC and F1\naround 0.9. Our proposed network centrality algorithms, LoCred and CoCred, consis-\ntently perform well across the three datasets considered, with ROC_AUC and F1 both\naround 0.8. We \ufb01nd two kinds of credibility homophily in the news-sharing networks,\nwhichhelpexplainthee\ufb00ectivenessofthesemethods:unreliableaccountstendtoresharecontent from one another ( Q1), and share content from similar sources ( Q2). These re-\nsultscon\ufb01rmourhypothesisthatthestructureofthereshareorco-sharenetworkprovides\nstrongsignalstoe\ufb00ectivelyinferaccountcredibility( Q3).Whilethepresenceofcredibility\nhomophily has also been observed in prior analyses of di\ufb00erent Twitter data [ 61], future\nwork might consider whether these results generalize to information-sharing networksderivedfromothersocialmediaplatforms.\nWhile our framework detects potential misinformation spreaders regardless of inten-\ntion,itcanhelptobettercharacterizedisinformationspreadersincombinationwithother\ne\ufb00ective methods, such as bot and inauthentic coordinated campaign detection [ 62,63].\nInparticular,oneofourproposedmethods,CoCred,providessourcerankingssimultane-\nouslywithaccountrankings.Thesesourcerankingscanbeusedtoestimatethecredibility\nof emerging news media outlets. Such source credibility scores can be used as a feature\nTruong et al. EPJDataScience           (2024) 13:10 Page16of19\nin misinformation classi\ufb01cation, complementing extant content-based methods to curb\nmisinformation.\nOur work has some limitations. First, we only label and investigate accounts sharing\nsources with ratings by NewsGuard. Additio nal sources of misinformation that are not\nlabeled by NewsGuard, as well as false/misleading claims in individual posts that do notincludealinktosomesource,aremissedinouranalysis.However,sincethecriteriaused\nby NewsGuard to label sources are independent from the methods we evaluate, there is\nno reason to believe that our accuracy measurements are biased. Still, complementary\nanalysesusingothersourcesofgroundtruth,suchaspost-leveloraccount-levelannota-\ntions,couldprovideadditionalinsights.Second,classi\ufb01cationresultsdependonthenews-\nsharingdatafromwhichanetworkisderived.Assuch,accountcredibilityscoresmayvary\nacrosscontexts.Forexample,usershaveahighertendencytosharelinkstouncon\ufb01rmedsources[64] when information is scarce,diverging fromtheir usualnews-sharing behav-\nior. Accounts might be classi\ufb01ed as unreliable in these situations, despite being reliable\ninothers.Onewaytoaddressthisconcernmightbetoaggregateanaccount\u2019scredibility\nscoresacrossdi\ufb00usionnetworksfromdi\ufb00erenttopics.Lastly,algorithmsusingthereshare\nnetworkcannotbeevaluatedontheFacebookplatform,asthedatadoesnotprovideinfor-mationaboutreshares.Furthermore,Twitter/Xhasrecentlyremovedfreedataaccessfor\nresearchers,makingthiskindofanalysisdi\ufb03culttoreplicateinthefuture.Note,however,\nthattheproposedmethodsareplatform-agnostic.Theoutlinedanalysescanbeappliedto\ndata from any platform that allows for the construction of reshare or bipartite networks,\nsuchasMastodonandBluesky.Weurgeallsocialmediaplatformstomakedataavailable\ntoallowfortransparentanalyses[ 65].\nOverall, this work enriches the understanding of misinformation spreaders on social\nmedia by investigating trust signals in di\ufb00erent information-sharing networks. The ob-\nserved credibility homophily invites further exploration of misinformation di\ufb00usion and\nspreader dynamics. The proposed methods can be used to identify accounts of interest\nbasedontheirestimatedcredibilitybyconsideringonlysharingmetadata,beforefurther\nscrutiny (or even without any scrutiny) of the speci\ufb01c content they share. Platforms can\nreadily apply our proposed methods to enhance their moderation e\ufb00orts. These insights\nare crucial to social media platforms and policymakers in the debate on ways to combatonlinemisinformation.\nAcknowledgements\nWearegratefultoKai-ChengYangforhelpwiththedatacollectionandmanyhelpfulcomments.RujAkavipatand\nPik-MaiHuiprovidedhelpfuldiscussions.WealsothankNewsGuardforlicensingtheirsourcecredibilityscores.\nFunding\nThisresearchissupportedinpartbytheKnightFoundation,CraigNewmarkPhilanthropies,DARPA(awardsW911NF-17-C-0094andHR001121C0169),andtheLuddySchoolofInformatics,Computing,andEngineeringatIndiana\nUniversity,Bloomington.\nAbbreviations\nBGRM,BipartiteGraphReinforcementModel;CoCred,Co-sharingnetwork-basedCredibility;HITS,Hyperlink-Induced\nTopicSearch;KNN,k-NearestNeighbors;LoCred,LowCredibilityAccountEstimation;P2P,peer-to-peer;PCA,PrincipleComponentAnalysis;PPRTrust,PersonalizedPageRankTrust;PRTrust,PageRankTrust;ROC_AUC,receiveroperating\ncharacteristiccurve;TF-IDF,TermFrequency\u2014InverseDocumentFrequency.\nDataavailability\nForreproducibility,wemakethedataandcodeavailableinapublicrepository\nhttps://github.com/osome-iu/credibility-inference .\nTruong et al. EPJDataScience           (2024) 13:10 Page17of19\nDeclarations\nEthicsapprovalandconsenttoparticipate\nThisresearchisbasedonanalysesofpublicsocialmediadatawithminimalriskstoparticipants.ThisstudyhasbeengrantedexemptionfromreviewbytheIndianaUniversityIRB(protocol17036).Thecollectionandreleaseofthedatasetareincompliancewiththeplatforms\u2019termsofservice.\nConsentforpublication\nNotapplicable.\nCompetinginterests\nTheauthorsdeclarethattheyhavenocompetinginterests.\nAuthorcontributions\nFMandBTformulatedtheresearch,developedthemethodology,andpreparedthemanuscript.BTcollectedthedata.BTandOAperformedanalyses.Allauthorsreadandapprovedthe\ufb01nalmanuscript.\nAuthordetails\n1ObservatoryonSocialMedia,IndianaUniversity,Bloomington,USA.2NetworkScienceInstitute,NortheasternUniversity,\nBoston,USA.\nReceived:11September2023 Accepted:22January2024\nReferences\n1. GottfriedJ,ShearerE(2016)Newsuseacrosssocialmediaplatforms2016.\npewresearch.org/journalism/2016/05/26/news-use-across-social-media-platforms-2016/\n2. ZarocostasJ(2020)Howto\ufb01ghtaninfodemic.Lancet395(10225):6763. WoolleySC,HowardPN(2018)Computationalpropaganda:politicalparties,politicians,andpoliticalmanipulationon\nsocialmedia.OxfordUniversityPress,London\n4. FisherM(2013)SyrianhackersclaimAPhackthattippedstockmarketby$136billion.Isitterrorism.\nwashingtonpost.com/news/worldviews/wp/2013/04/23/syrian -hackers-claim-ap-hack-that-tipped-stock-market-\nby-136-billion-is-it-terrorism/\n5. TasnimS,HossainMM,MazumderH(2020)ImpactofrumorsandmisinformationonCOVID-19insocialmedia.JPrev\nMedPublicHealth53(3):171\u2013174\n6. AllingtonD,Du\ufb00yB,WesselyS,DhavanN,RubinJ(2021)Health-protectivebehaviour,socialmediausageand\nconspiracybeliefduringtheCOVID-19publichealthemergency.PsycholMed51(10):1763\u20131769.\nhttps://doi.org/10.1017/S003329172000224X\n7. PierriF,PerryBL,DeVernaMR,YangK-C,FlamminiA,MenczerF,BrydenJ(2022)Onlinemisinformationislinkedto\nearlyCOVID-19vaccinationhesitancyandrefusal.SciRep12(1):5966\n8. YangK-C,PierriF,HuiP-M,AxelrodD,Torres-LugoC,BrydenJ,MenczerF(2021)TheCOVID-19infodemic:Twitter\nversusFacebook.BigDataSoc8(1):20539517211013861\n9. ZhouX,JainA,PhohaVV,ZafaraniR(2020)Fakenewsearlydetection:atheory-drivenmodel.DigitTreatsResPract\n1(2):1\u201325\n10. GoldsteinJA,SastryG,MusserM,DiRestaR,GentzelM,SedovaK(2023)Generativelanguagemodelsandautomated\nin\ufb02uenceoperations:emergingthreatsandpotentialmitigations.arXivpreprint. arXiv:2301.04246\n11. MenczerF,CrandallD,AhnY-Y,KapadiaA(2023)AddressingtheharmsofAI-generatedinauthenticcontent.Nat\nMachIntell. https://doi.org/10.1038/s42256-023-00690-w\n12. KirchnerJH,AhmadL,AaronsonS,LeikeJ(2023)NewAIclassi\ufb01erforindicatingAI-writtentext.OpenAI.\nopenai.com/blog/new-ai-classi\ufb01er-for-indicating-ai-written-text/\n13. HovlandCI,WeissW(1951)Thein\ufb02uenceofsourcecredibilityoncommunicatione\ufb00ectiveness.PublicOpinQ\n15(4):635\u2013650\n14. WestermanD,SpencePR,VanDerHeideB(2014)Socialmediaasinformationsource:recencyofupdatesand\ncredibilityofinformation.JComput-MediatCommun19(2):171\u2013183\n15. TurcotteJ,YorkC,IrvingJ,SchollRM,PingreeRJ(2015)Newsrecommendationsfromsocialmediaopinionleaders:\ne\ufb00ectsonmediatrustandinformationseeking.JComput-MediatCommun20(5):520\u2013535\n16. YaqubW,KakhidzeO,BrockmanML,MemonN,PatilS(2020)E\ufb00ectsofcredibilityindicatorsonsocialmedianews\nsharingintent.In:Proc.2020CHIconf.onhumanfactorsincomputingsystems,pp1\u201314.https://doi.org/10.1145/3313831.3376213\n17. TheMediaInsightProject(2017)\u201cWhoSharedIt?\u201d:howAmericansdecidewhatnewstotrustonsocialmedia.\napnorc.org/projects/who-shared-it-how-americans-decide-what-news-to-trust-on-social-media/\n18. SterrettD,MalatoD,BenzJ,KantorL,TompsonT,RosenstielT,SondermanJ,LokerK(2019)Whosharedit?:deciding\nwhatnewstotrustonsocialmedia.DigJournal7(6):783\u2013801\n19. MishraA,BhattacharyaA(2011)Findingthebiasandprestigeofnodesinnetworksbasedontrustscores.In:Proc.\n20thintl.conf.onWorldWideWeb(WWW),pp567\u2013576. https://doi.org/10.1145/1963405.1963485\n20. RathB,GaoW,MaJ,SrivastavaJ(2018)UtilizingcomputationaltrusttoidentifyrumorspreadersonTwitter.SocNetw\nAnalMin8(1):1\u201316\n21. BildDR,LiuY,DickRP,MaoZM,WallachDS(2015)AggregatecharacterizationofuserbehaviorinTwitterandanalysis\noftheretweetgraph.ACMTransInternetTechnol15(1):1\u201324\n22. ShuK,BernardHR,LiuH(2019)Studyingfakenewsvianetworkanalysis:detectionandmitigation.In:Emerging\nresearchchallengesandopportunitiesincomputationalsocialnetworkanalysisandmining,pp43\u201365\n23. ShuK,WangS,LiuH(2019)Beyondnewscontents:theroleofsocialcontextforfakenewsdetection.In:Proceedings\nofthetwelfthACMinternationalconferenceonwebsearchanddatamining,pp312\u2013320\nTruong et al. EPJDataScience           (2024) 13:10 Page18of19\n24. Al-SharawnehJ,SinnappanS,WilliamsM-A(2013)Credibility-basedTwittersocialnetworkanalysis.In:Proc.\nAsia-Paci\ufb01cwebconf.,pp323\u2013331\n25. GrinbergN,JosephK,FriedlandL,Swire-ThompsonB,LazerD(2019)FakenewsonTwitterduringthe2016U.S.\npresidentialelection.Science363(6425):374\u2013378. https://doi.org/10.1126/science.aau2706\n26. DeVernaMR,AiyappaR,PachecoD,BrydenJ,MenczerF(2022)Identi\ufb01cationandcharacterizationofmisinformation\nsuperspreadersonsocialmedia.Preprint. arXiv:2207.09524 .https://doi.org/10.48550/ARXIV.2207.09524\n27. PageL,BrinS,MotwaniR,WinogradT(1999)Thepagerankcitationranking:bringingordertotheweb.Technical\nreport,StanfordInfoLab\n28. HaveliwalaTH(2003)Topic-sensitivepagerank:acontext-sensitiverankingalgorithmforwebsearch.IEEETrans\nKnowlDataEng15(4):784\u2013796\n29. KamvarSD,SchlosserMT,Garcia-MolinaH(2003)Theeigentrustalgorithmforreputationmanagementinp2p\nnetworks.In:Proc.12thintl.conf.onWorldWideWeb(WWW),pp640\u2013651. https://doi.org/10.1145/775152.775242\n30. ZhouR,HwangK(2007)Powertrust:arobustandscalablereputationsystemfortrustedpeer-to-peercomputing.\nIEEETransParallelDistribSyst18(4):460\u2013473. https://doi.org/10.1109/TPDS.2007.1021\n31. GyongyiZ,Garcia-MolinaH,PedersenJ(2004)Combatingwebspamwithtrustrank.In:Proc.30thintl.conf.onvery\nlargedatabases(VLDB). http://ilpubs.stanford.edu:8090/770/\n32. WangG,WuJ(2011)Flowtrust:trustinferencewithnetwork\ufb02ows.FrontComputSci5(2):181.\nhttps://doi.org/10.1007/s11704-011-0323-4\n33. AkavipatR(2009)DistrustreputationsystemforP2Pinformationsharing.PhDthesis,IndianaUniversity.UMINumber:\n3390252. https://proxyiub.uits.iu.edu/login?qurl=https\n34. OrtegaFJ,TroyanoJA,CruzFL,VallejoCG,Enr\u00edquezF(2012)Propagationoftrustanddistrustforthedetectionof\ntrollsinasocialnetwork.ComputNetw56(12):2884\u20132895. https://doi.org/10.1016/j.comnet.2012.05.002\n35. GuhaR,KumarR,RaghavanP,TomkinsA(2004)Propagationoftrustanddistrust.In:Proc.13thintl.conf.onWorld\nWideWeb(WWW),pp403\u2013412. https://doi.org/10.1145/988672.988727\n36. KleinbergJM(1999)Authoritativesourcesinahyperlinkedenvironment.JACM46(5):604\u201363237. DengH,LyuMR,KingI(2009)Ageneralizedco-hitsalgorithmanditsapplicationtobipartitegraphs.In:Proc.15th\nACMSIGKDDintl.conf.knowledgediscoveryanddatamining,pp239\u2013248\n38. RuiX,LiM,LiZ,MaW-Y,YuN(2007)Bipartitegraphreinforcementmodelforwebimageannotation.In:Proc.15th\nACMintl.conf.onmultimedia,pp585\u2013594\n39. HeX,GaoM,KanM-Y,WangD(2016)Birank:towardsrankingonbipartitegraphs.IEEETransKnowlDataEng\n29(1):57\u201371\n40. RomeroDM,GalubaW,AsurS,HubermanBA(2011)In\ufb02uenceandpassivityinsocialmedia.In:Proc.jointEuropean\nconf.onmachinelearningandknowledgediscoveryindatabases(ECMLPKDD),pp18\u201333.https://doi.org/10.1007/978-3-642-23808-6_2\n41. AgichteinE,CastilloC,DonatoD,GionisA,MishneG(2008)Findinghigh-qualitycontentinsocialmedia.In:Proc.\n2008intl.conf.onwebsearchanddatamining,pp183\u2013194\n42. CastilloC,MendozaM,PobleteB(2013)Predictinginformationcredibilityintime-sensitivesocialmedia.InternetRes\n23(5):560\u2013588. https://doi.org/10.1108/IntR-05-2012-0095\n43. GuptaA,KumaraguruP,CastilloC,MeierP(2014)Tweetcred:real-timecredibilityassessmentofcontentonTwitter.\nIn:Proc.intl.conf.onsocialinformatics,pp228\u2013243\n44. SetiawanEB,WidyantoroDH,SurendroK(2020)Measuringinformationcredibilityinsocialmediausingcombination\nofuserpro\ufb01leandmessagecontentdimensions.IntJComputElectrEng10(4):3537\u20133549.https://doi.org/10.11591/ijece.v10i4.pp3537-3549\n45. BarbierG,LiuH(2011)Informationprovenanceinsocialmedia.In:Proc.intl.conf.onsocialcomputing,\nbehavioral-culturalmodeling,andprediction,pp276\u2013283\n46. GroverA,LeskovecJ(2016)Node2vec:scalablefeaturelearningfornetworks.In:Proc.22ndACMSIGKDDintl.conf.\nknowledgediscoveryanddatamining,pp855\u2013864. https://doi.org/10.1145/2939672.2939754\n47. PerozziB,Al-RfouR,SkienaS(2014)Deepwalk:onlinelearningofsocialrepresentations.In:Proc.20thACMSIGKDD\nintl.conf.knowledgediscoveryanddatamining,pp701\u2013710. https://doi.org/10.1145/2623330.2623732\n48. TangJ,QuM,WangM,ZhangM,YanJ,MeiQ(2015)Line:large-scaleinformationnetworkembedding.In:Proc.24th\nintl.conf.onWorldWideWeb,pp1067\u20131077\n49. HamdiT,SlimiH,BounhasI,SlimaniY(2020)AhybridapproachforfakenewsdetectioninTwitterbasedonuser\nfeaturesandgraphembedding.In:Proc.intl.conf.ondistr.comp.andInternettechnology,pp266\u2013280\n50. RoyA,SarkarC,SrivastavaJ,HuhJ(2016)Trustingness&trustworthiness:apairofcomplementarytrustmeasuresina\nsocialnetwork.In:Proc.ACM/IEEEintl.conf.onadvancesinsocialnetworksanalysisandmining(ASONAM),pp549\u2013554. https://doi.org/10.1109/ASONAM.2016.7752289\n51. ZhaoL,HuaT,LuC-T,ChenI-R(2016)Atopic-focusedtrustmodelforTwitter.ComputCommun76:1\u201311.\nhttps://doi.org/10.1016/j.comcom.2015.08.001\n52. AdaliS,EscrivaR,GoldbergM,HayvanovychM,Magdon-IsmailM,SzymanskiB,WallaceW,WilliamsG(2010)\nMeasuringbehavioraltrustinsocialnetworks.In:Proc.IEEEintl.conf.onintelligenceandsecurityinformatics,pp150\u2013152. https://doi.org/10.1109/ISI.2010.5484757\n53. AltmanNS(1992)Anintroductiontokernelandnearest-neighbornonparametricregression.AmStat46(3):175\u201318554. JonesKS(1972)Astatisticalinterpretationoftermspeci\ufb01cityanditsapplicationinretrieval.JDoc28(1):11\u20132155. YangK-C,Torres-LugoC,MenczerF(2020)Prevalenceoflow-credibilityinformationonTwitterduringtheCOVID-19\noutbreak.In:Proc.ICWSMintl.workshoponcybersocialthreats(CySoc). https://doi.org/10.36190/2020.16\n56. AiyappaR,DeVernaMR,PoteM,TruongBT,ZhaoW,AxelrodD,PessianzadehA,KachwalaZ,KimM,SeckinOCetal\n(2023)Amulti-platformcollectionofsocialmediapostsaboutthe2022usmidtermelections.In:ProceedingsoftheinternationalAAAIconferenceonwebandsocialmedia,vol17,pp981\u2013989\n57. NewmanME(2003)Mixingpatternsinnetworks.PhysRevE67(2):02612658. Alvarez-HamelinJI,Dall\u2019AstaL,BarratA,VespignaniA(2006)Largescalenetworks\ufb01ngerprintingandvisualization\nusingthek-coredecomposition.In:Advancesinneuralinformationprocessingsystems,pp41\u201350\n59. SerranoM\u00c1,Bogun\u00e1M,VespignaniA(2009)Extractingthemultiscalebackboneofcomplexweightednetworks.Proc\nNatlAcadSci106(16):6483\u20136488\nTruong et al. EPJDataScience           (2024) 13:10 Page19of19\n60. Labr\u00ednC,UrdinezF(2020)Principalcomponentanalysis.In:Rforpoliticaldatascience,pp375\u2013393\n61. NikolovD,FlamminiA,MenczerF(2021)Rightandleft,partisanshippredicts(asymmetric)vulnerabilityto\nmisinformation.HKSMisinformRev1(7). https://doi.org/10.37016/mr-2020-55\n62. YangK-C,VarolO,DavisCA,FerraraE,FlamminiA,MenczerF(2019)Armingthepublicwitharti\ufb01cialintelligenceto\ncountersocialbots.HumBehavEmergTechnol1(1):48\u201361\n63. PachecoD,HuiP-M,Torres-LugoC,TruongBT,FlamminiA,MenczerF(2021)Uncoveringcoordinatednetworkson\nsocialmedia:methodsandcasestudies.In:Proc.intl.AAAIconf.onwebandsocialmedia(ICWSM),vol15,\npp455\u2013466\n64. OhO,KwonKH,RaoHR(2010)Anexplorationofsocialmediainextremeevents:rumortheoryandTwitterduring\ntheHaitiearthquake2010.In:ICIS\n65. PasquettoIV,Swire-ThompsonBetal(2020)Tacklingmisinformation:whatresearcherscoulddowithsocialmedia\ndata.HKSMisinformRev1(8). https://doi.org/10.37016/mr-2020-49\nPublisher\u2019sNote\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsinpublishedmapsandinstitutionala\ufb03liations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Account credibility inference based on news-sharing networks", "author": ["BT Truong", "OM Allen", "F Menczer"], "pub_year": "2024", "venue": "EPJ Data Science", "abstract": "The spread of misinformation poses a threat to the social media ecosystem. Effective  countermeasures to mitigate this threat require that social media platforms be able to accurately"}, "filled": false, "gsrank": 597, "pub_url": "https://epjds.epj.org/articles/epjdata/abs/2024/01/13688_2024_Article_450/13688_2024_Article_450.html", "author_id": ["tng76dgAAAAJ", "smER9lYAAAAJ", "f_kGJwkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:4SydweoM-iUJ:scholar.google.com/&output=cite&scirp=596&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D590%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=4SydweoM-iUJ&ei=cbWsaOqkD7TWieoP1pCJ2AY&json=", "num_citations": 5, "citedby_url": "/scholar?cites=2736513925991181537&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:4SydweoM-iUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1140/epjds/s13688-024-00450-9.pdf"}}, {"title": "Don't burst blindly: for a better use of natural language processing to fight opinion bubbles in news recommendations", "year": "2022", "pdf_data": "Proceedings of the First Workshop on Natural Language Processing for Political Sciences (PoliticalNLP) , pages 79\u201385\nMarseille, 24 June 2022\n\u00a9 European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0\n79Don\u2019t Burst Blindly: For a Better Use of Natural Language Processing to\nFight Opinion Bubbles in News Recommendations\nEvan Dufraisse\u2020*, C\u00b4elina Treuillier*, Armelle Brun*,\nJulien Tourille\u2020, Sylvain Castagnos*, Adrian Popescu\u2020\n\u2020Universit \u00b4e Paris-Saclay, CEA, List, F-91120, Palaiseau, France\n*Universit \u00b4e de Lorraine - CNRS - Loria, Vandoeuvre les Nancy Cedex, France\n{evan.dufraisse, julien.tourille, adrian.popescu }@cea.fr\n{celina.treuillier, armelle.brun, sylvain.castagnos }@loria.fr\nAbstract\nOnline news consumption plays an important role in shaping the political opinions of citizens. The news is often served by\nrecommendation algorithms, which adapt content to users\u2019 preferences. Such algorithms can lead to political polarization as the\nsocietal effects of the recommended content and recommendation design are disregarded. We posit that biases appear, at least\nin part, due to a weak entanglement between natural language processing and recommender systems, both processes yet at work\nin the diffusion and personalization of online information. We assume that both diversity and acceptability of recommended\ncontent would benefit from such a synergy. We discuss the limitations of current approaches as well as promising leads of\nopinion-mining integration for the political news recommendation process.\nKeywords: Political polarization, News processing, Recommender systems, Opinion bubbles\n1. Introduction\nThe ubiquitous use of social media has revolutionized\nthe way people consume news and get exposed to in-\nformation. Social media give users access to a huge\namount of news, and opportunities to engage with di-\nverse opinions. However, the access to such a rich in-\nformation landscape comes with important challenges.\nIn particular, personalization tools, designed to help\nusers access content they are interested in, filter and\nhide information, offering only news in line with a\nuser\u2019s opinion. This selective exposure limits the pre-\nsentation of contrasting viewpoints, leading to the cre-\nation of opinion bubbles (Pariser, 2011; Bozdag and\nvan den Hoven, 2015). In the political domain, such an\nexposure tends to polarize citizens\u2019 opinions (Pariser,\n2011; Zuiderveen Borgesius et al., 2016), often drift-\ning them towards extreme viewpoints (Sunstein, 2009).\nOn the long run, polarization is detrimental to the polit-\nical debate and ultimately to democratic societies. The\nHigh Level Expert Group on Media Diversity and Plu-\nralism highlights that people need to confront opinions\nthat differ from their own to develop themselves fully1.\nIn this context, opinion bubbles are a growing concern\nfor researchers from different disciplines (e.g. polit-\nical science, economics, computer science or media),\nwith interests ranging from assessing the real impact of\npersonalization (Zuiderveen Borgesius et al., 2016) to\nbursting these bubbles (Burbach et al., 2019). In this\nwork, we focus on computer science research on opin-\nion bubbles in two distinct but related domains. The\nNews Recommender System (NRS) community has a\nlong-term interest in designing recommendation algo-\nrithms that broaden users\u2019 view about a given topic. To\nthis end, researchers focus on forming a diversified set\nof news articles to make sure that users can access di-versified opinions. These research efforts mainly differ\nin the way they measure diversity and how they use\nit (Kunaver and Po \u02c7zrl, 2017; Raza and Ding, 2021;\nM\u00a8oller et al., 2018). However, as we will show, the\nnews content analysis and the way diversity is man-\naged are not adapted to the specificity of political NRS,\nwhich limits the impact of diversification.\nFor its part, the Natural Language Processing (NLP)\ncommunity focuses on news content understanding\nthrough different tasks such as topic modeling, opinion\nmining or argument mining (Hemmatian and Sohrabi,\n2019 10; Lawrence and Reed, 2020). The most effec-\ntive strategies in those fields are supervised and heavily\nrely on annotated data. This makes the elaboration of\nsolutions even more challenging considering the highly\ndynamic nature of news in terms of topics and opinions.\nIn this paper, we discuss the importance of a fine-\ngrained analysis of the opinions expressed in the news,\ncombined with a NRS that handles these opinions, and\nnot only topics, to create personalized sets of recom-\nmendations and efficiently burst bubbles. From an ethi-\ncal point of view, the NRS should not favor any specific\nopinion but should guarantee that the recommendations\nare representative of the diversity of the opinions ex-\npressed about the topic (Helberger, 2019).\nThe rest of the paper is organized as follows. After\npresenting a review of the literature of NRS (Section 2),\nwe focus on news content analysis in NLP (Section 3).\nIn Section 4 we present our view of the characteristics\nthat a system designed to burst bubbles should have, as\nwell as the way it should be designed.\n2. News Recommender Systems\nOnline platforms offer access to a vast amount of con-\ntent, which needs to be ranked according to the pref-\n80erences of each reader. In this context, NRS are de-\nsigned to help readers find relevant information among\nthe large quantity of news available (Raza and Ding,\n2021). The news recommendation task has three main\ncharacteristics that distinguish it from other recommen-\ndation tasks: news articles quickly become obsolete (1)\nand are characterized by a high turnover (2) as a large\nnumber of news articles is published every second (Lu-\nnardi et al., 2020). This induces the need for recom-\nmendation models that can be updated on the fly and\nthat do not require many interactions between news and\nreaders. Besides, news consumption tends to influence\nusers\u2019 opinion (3) (Helberger, 2019). This is highly\ncritical when it comes to politics, as NRS have been\nshown to contribute to the creation of opinion bubbles,\nrepresenting a threat to democracy (Pariser, 2011).\nAs a consequence, sets of recommendations have to\nbe properly balanced to ensure that users can access\nnews that convey diverse opinions. This refers to the\naccuracy-diversity dilemma (Zhou et al., 2010), which\nrefers to the search of an optimal balance between a\nhigh level of accuracy, to keep users\u2019 trust, and a suf-\nficient diversification among recommendations. In the\nnews domain, diversity is often viewed as mandatory\nsince it represents a core principle for the development\nof a democratic society (Helberger, 2019). However,\nthe literature does not offer a unique way to represent\nthe news, to evaluate the diversity, nor to recommend\ndiversified sets of news articles.\n2.1. News representation\nBefore measuring their diversity, news articles are often\npre-processed in order to build a representation of their\ncontent (e.g. body, title, preamble or keywords). This\nrepresentation must be designed to precisely character-\nize news. Recent models in NRS use deep-learning\napproaches such as named entity recognition, entity-\nlinking, or knowledge-graph to provide a complete rep-\nresentation of news (Wang et al., 2018; Joseph and\nJiang, 2019; Zhang et al., 2021). These representations\nare optimized for high accuracy but do not meet the\nneeds for a precise control of recommendation diver-\nsification. Moreover, NRS mainly promote diversity\nthrough the use of topic modeling, and rely on simple\nbag-of-words representation. For instance, they rep-\nresent the discriminating power of each word in the\nnews using TF-IDF (Gao et al., 2020) or build topic\nrepresentation using LDA (Tintarev et al., 2018). Few\nstudies focus on Sentiment Analysis (Wu et al., 2020)\nby identifying and representing positive and negative\nsentiments in the news. The authors hypothesize that\ntopic and sentiment analysis can increase the diversity\nof recommended opinions, but no empirical evidence\nis provided. Models that focus on topic diversification\nand coarse sentiment diversification can barely capture\nopinions, even less their nuances. Their use to foster\nopinion diversity in NRS is thus limited. Apart from\ntopics and opinions, particularities of textual contentsuch as the style of the authors or the use of irony, are\nnot processed by NRS either.\n2.2. Diversity measures in NRS\nNRS differ in their definition of diversity and its associ-\nated metrics. For the simplest cases, diversity is consid-\nered as the opposite of similarity. The similarity mea-\nsure can be instantiated by cosine similarity or based\non distance (e.g. Jaccard or Euclidean) (M \u00a8oller et al.,\n2018; Lunardi et al., 2020). In rare cases, other met-\nrics are used, such as entropy (Shannon index, Rao\u2019s\nquadratic entropy) (M \u00a8oller et al., 2018).\nGenerally, diversity metrics are derived from other\nfields, but the literature rarely adapt them to the news\ndomain, which may result in meaningless values. More\nimportantly, as mentioned above, diversities computed\nfrom simple representations of news can hinder even\nmore their accuracy.\n2.3. Diversification processes\nDiversity measures constitute the basis for diversifica-\ntion processes. Diversification is often implemented as\na post-processing step which re-ranks a list of recom-\nmended contents by prioritizing contents with a high\nvariety of topics (Lunardi et al., 2020; Ziegler et al.,\n2005). An important downside of this approach is that\ndiversity cannot be improved if the initial list is homo-\ngeneous. To answer this limitation, researchers propose\nto incorporate diversity into the core of the recommen-\ndation algorithm. (Raza and Ding, 2020) presents a\nrecommendation algorithm that weights both diversity\nand accuracy in a personalized way, and tries to answer\nthe accuracy-diversity dilemma. As a result, diversi-\nfication among recommendations is not simply based\non the re-ranking of the news, but relies on the prior\nparameter optimization of the recommendation model.\nTo summarize, existing diversification processes are in-\nteresting, but their potential is limited by the use of sim-\nplistic news representations. Representations which are\nmore adapted to the specificity of news \u2013 in particular\npolitical news \u2013 and diversification are needed. They\ncan be obtained by applying advanced NLP techniques.\n3. Natural Language Processing\nDiversifying news content opinions requires a fine-\ngrained understanding of articles\u2019 stances. Several\nNLP sub-fields have developed approaches to meet this\nend. In the following, we distinguish proxy measures,\nthat extract opinion cues, from finer-grained strategies.\n3.1. Proxy strategies to stance detection\nA system able to extract fine-grained opinions from ar-\nbitrary textual contents is still an object of research.\nFacing this challenge, proxy measures that are easier\nto obtain can serve as coarse opinion indicators. The\nmethods presented in this subsection are often gathered\nunder the umbrella term of \u201cmedia bias detection\u201d. We\nrefer the reader to (Nakov et al., 2021) for a complete\nsurvey of the subject.\n813.1.1. Content-based strategies\nMedia biases can take several forms: (i) a subjective\nstylometry, (ii) a coverage restricted to a subset of top-\nics (topic diversity), (iii) an unequal attention paid to\ncertain aspects or facts in events (framing), or (iv) a\nconstant leaning towards a political group.\nStylometry-based detection approaches revolve around\nthe detection of subjective expressions using dictionar-\nies. The latter are usually gathered using an unsu-\npervised strategy (Riloff and Wiebe, 2003). Recently,\n(Patankar et al., 2019) used (Recasens et al., 2013) lex-\nicon to make a bias-aware NRS. However, this strategy\nonly detects a lack of stylometric neutrality but cannot\nhelp determine an article\u2019s stance. Topic diversity bias\nis already discussed in the NRS literature, we redirect\nto Section 2 for further information.\nFraming (Entman, 1993) implies a consistent focus on\nsome aspects of an issue that leads to its partial com-\nprehension and biased interpretation by the reader. An\nearly NRS strategy implemented to counter this bias\nused keyword extraction and unsupervised clustering\nof articles (Park et al., 2009). Later, automatic ap-\nproaches for framing identification have been devel-\noped around the detection of so-called frames, which\nare characteristic aspects of a particular issue. Con-\nsidering a representative set of articles that address a\nsame topic, the aim is to detect significant deviations in\naspects distribution as an indicator of bias. However,\nthe issue-specificity of aspects prevent their widespread\ncomputational use. (Boydstun et al., 2014) solves this\nissue by developing a set of 15 generic frames that are\npervasive in most subjects. This approach was later\nconsolidated with a dataset (Card et al., 2015). More\nrecently, (Kwak et al., 2021) offered a new approach\naround the use of \u201cmicro-frames\u201d. They construct\nsemantic axes based on the Glove embeddings (Pen-\nnington et al., 2014) of 1,621 antonyms selected from\nWordNet (Miller, 1995). Using the Glove embeddings\nof words within a text, they compute their cosine dis-\ntances to the semantic axes, and derive bias indicators\nfrom the score distribution. Nonetheless, frame identi-\nfication for stance detection is limited, as two articles\ncould defend opposite views over the same set of as-\npects but with the same polarities.\nIf one can derive clues on a source\u2019s political lean-\ning using its topic diversity and framing, other cues\nbased on semantically loaded expressions have proved\ntheir efficiency. Several methods use the U.S congress-\nman\u2019s speeches as source data to extract politically dif-\nferentiating expressions (Groseclose and Milyo, 2005;\nGentzkow and Shapiro, 2010; Bayram et al., 2019).\nRecently, (D\u2019Alonzo and Tegmark, 2021) led a com-\nparative study over several media, solely using articles\nto extract such expressions.\n3.1.2. Audience-based strategies\nStance detection through audience analysis is a com-\nplementary approach to text-based methods that stems\nfrom the homophily principle, which postulates thatusers principally interact with content they agree with.\nThe overall political stance of a media can be derived\nby analyzing those interactions. Most research in this\nfield revolves around the use of Twitter follow/retweet\ninteractions to map media or entities in the political\nspectrum (Wong et al., 2016; Stefanov et al., 2020;\nDarwish et al., 2020). Other approaches use readily\navailable media bias analyses from News Guard2, All-\nSides3, or Media Bias/Fact Check4to consolidate su-\npervised datasets of articles (Baly et al., 2020).\nThe derived political stances could be used to diversify\nopinions through the diversification of news sources.\nTwo underlying assumptions could preclude the suc-\ncess of such an approach, namely, that \u201cNews articles\nfollow the political leaning of their source outlet\u201d and\nthat \u201cPolitical leanings of news outlets do not change\nacross topics\u201d. (Ganguly et al., 2020) has recently\nshown that both of these assumptions are often violated\non an article basis. To fully grasp the political stance of\nan article, one needs to rely on the content itself.\n3.2. Opinion-Mining for stance detection\nIn computer science, \u201cOpinion Mining\u201d and \u201cSen-\ntiment Analysis\u201d are often used interchangeably.\nNonetheless, in everyday language, an opinion is rather\ndefined as a \u201cjudgment formed about something\u201d.\nChoices of subjective and sentimentally expressive\nwords are indicative of such judgments, and form the\nbasis of stance detection.\nAmong the three levels of sentiment-analysis usually\ndistinguished (document, sentence and entity), only the\nfiner-grained one is suitable for stance detection, as\nthe document and sentence levels of analyses are too\ncoarse to be informative of a writer\u2019s stance. A docu-\nment or a sentence could contain several entities upon\nwhich opinions are expressed.\n3.2.1. Aspect-Level Opinion Mining\n(Liu, 2010) defines opinions as quintuples\n(ei, aij, sijkl, hk, tl), where eiis the ithentity\nconsidered, aijis the jthaspect of that entity, and sijkl\nis the sentiment that the opinion holder hkexpresses\ntowards the aspect aijat time tl. Opinion mining at\nthe aspect level is interested in extracting, sometimes\npartially, those quintuples. The two most studied\nextraction frames are \u201cproduct aspect mining\u201d, with\nthe extraction of (ei, aij, sij)triplets, and \u201cstance\ndetection\u201d with the extraction of (ei, si)tuples. These\nframes can be split into two steps: Aspect-Extraction\n(AE), and Aspect-Based Sentiment Classification\n(ABSC). Aspect-based Opinion Mining has mostly\nbeen applied to product reviews datasets (Pontiki et\nal., 2014; Pontiki et al., 2015; Pontiki et al., 2016),\nbut also to financial (Jangid et al., 2018; Gaillat et al.,\n2018) , and more recently, news datasets (Steinberger\net al., 2017; Hamborg and Donnay, ).\nAspect-Extraction (AE) Given an opinionated-text\ncontent as input, AE aims at extracting the targets\n82and aspects (( aij,ei) orei) towards which a senti-\nment might be expressed. Approaches can be grouped\ninto four types. Frequency-based approaches extract\nmost frequent nouns and noun phrases after Part-of-\nSpeech (PoS) tagging, notably missing less frequent\naspects, and generating a large number of noisy tar-\ngets. Other approaches such as (Qiu et al., 2011) ex-\ntract domain-specific opinion words and targets using\nsyntactic relationships. They alternatively expand both\nan opinion word lexicon and a set of candidate tar-\ngets in a bootstrapping fashion. Supervised methods,\nby formalizing AE as a sequence-labeling task have\nalso been implemented. Finally, non-lexicon-based un-\nsupervised methods make use of topic-modeling ap-\nproaches (e.g. LDA, PLSA). An example of such an\napproach is (Titov and McDonald, 2008), which mod-\nels a document as a mixture of both local and global\ntopics, local topics are derived at a window scale to\ncapture target aspects. The above approaches assume\nexplicitly mentioned aspects, however, aspects can also\nbe implicit. We refer the reader to literature sur-\nveys (Hemmatian and Sohrabi, 2019 10; Nazir et al.,\n2020) for further information on the topic.\nAspect-Based Sentiment Classification (ABSC)\nOnce extracted aspects and entities, we need to deter-\nmine the sentiment expressed towards them. In this\ncontext, machine learning methods are often distin-\nguished from rule-based ones. Rule-based methods\nmostly rely on PoS tagging and the adjective-noun\nproximity heuristic to associate adjectives to aspects.\nThese methods have been supplanted by machine\nlearning methods, among which Deep-Learning re-\ncently took the lead. Most approaches are supervised\nbut getting annotated data is expensive. This lack\nof annotated datasets is often balanced using hybrid\napproaches that integrate external knowledge using\nsentiment lexicons, ontologies, or discourse parser\nfeatures. Datasets are scarce in the news domain, and\na recently (Hamborg and Donnay, ) supplied a high-\nquality dataset for the task. A challenge in the field, as\nin many, is the development of frugal approaches that\nrequire less or no annotations, especially regarding the\ndifficulty of transferring ABSC capabilities between\ndomains (Nazir et al., 2020).\nIf aspect-based opinion mining can help derive an ar-\nticle\u2019s stance, it cannot explain its underlying reasons.\nArgument Mining (see the survey (Lawrence and Reed,\n2020)) fills this gap by extracting argumentation struc-\ntures in texts. Improvements in irony and sarcasm de-\ntection, or even negation handling could also be of use.\n4. Towards a NLP-RS Hand-to-Hand\nApproach for Political NRS\nWe highlighted some limits in both NRS and NLP\nfields, that show existing approaches to be unsuitable\nto reduce the impact or to burst filter bubbles, by ensur-\ning a diversity of themes and opinions in NRS. First,\nthe diversity measures used in RS mostly evaluate thenews content differences, only ensuring that the set of\nrecommendations are not too similar. This is due to\nthe simple representations of articles used, which do\nnot allow accurate representation of opinions, and are\nthus inadequate to ensure fair recommendations by in-\nclusively representing diverse opinions. Recent lines\nof thought promote the plurality of opinions in NRS\nusing representation metrics (Vrijenhoek et al., 2021).\nNevertheless, the notion of opinion is still treated basi-\ncally in the form of a positive, negative or neutral but\nintangible opinion on a statement. A step further, we\nsupport the idea of a temporal diversification to adapt\nto the shifts in opinion and the evolving needs of users\nduring the recommendation process.\nSecond, due to the highly dynamic nature of news,\nopinion mining techniques must be generic and adapt-\nable to new sources and opinions. State-of-the-art\naspect-based opinion analysis systems implement su-\npervised machine learning algorithms and need anno-\ntated data to be trained. This hinders the capabilities of\nsuch systems to adapt quickly on new topics and their\nassociated aspects. Semi-supervised approaches need\nto be further investigated to remedy this issue and to\ncope with the dynamic nature of news.\nThese limitations show the need for a stronger coopera-\ntion between RS and NLP communities. News opinion\nmining tasks have to be driven by the need of a specific\ndiversity/similarity temporal evaluation. Recommen-\ndation tasks have to rely on precise opinion representa-\ntions to enable content diversification.\nFuture developments resulting from such a cooperation\nneed to be extensively evaluated. However, NRS eval-\nuation is a difficult and sensitive task. Especially when\nit comes to opinionated content diversification. Evalua-\ntion protocols should include both qualitative and quan-\ntitative metrics to build a complete view of the NRS\nperformances. Quantitatively, topic and aspect-based\nopinion extraction models need to be evaluated through\nstandard benchmarks available in the NLP commu-\nnity (Hamborg et al., 2021). This step guarantees that\nnews representations contain all necessary information\nfor diversification. If several RS benchmarks exist in\nthe community, none has been developed to quantita-\ntively evaluate diversification as defined in this paper.\nQualitatively, effectiveness of NRS in bursting opinion\nbubbles must be evaluated. Longitudinal studies, en-\nrolling several groups of people with different social\nand cultural backgrounds, could shed light on the per-\nformance and acceptability of such a system through\ntime, but also on the evolution of the opinions of peo-\nple. However, these questions are not discussed in ei-\nther domain and requires an expansion of collaboration\nwith political science researchers in the study.\n5. Acknowledgements\nThis work has been funded by the BOOM ANR Project\n- ANR-20-CE23-0024.\n836. Bibliographical References\nBaly, R., Da San Martino, G., Glass, J., and Nakov, P.\n(2020). We can detect your bias: Predicting the po-\nlitical ideology of news articles. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 4982\u2013\n4991. Association for Computational Linguistics.\nBayram, U., Pestian, J., Santel, D., and Minai, A. A.\n(2019). What\u2019s in a word? detecting partisan affil-\niation from word use in congressional speeches. In\n2019 International Joint Conference on Neural Net-\nworks (IJCNN) , pages 1\u20138. IEEE.\nBoydstun, A. E., Card, D., Gross, J. H., Resnik, P., and\nSmith, N. A. (2014). Tracking the development of\nmedia frames. Work. Pap. , pages 1\u201325.\nBozdag, E. and van den Hoven, J. (2015). Breaking\nthe filter bubble: democracy and design. Ethics and\nInformation Technology , 17(4):249\u2013265.\nBurbach, L., Halbach, P., Ziefle, M., and\nCalero Valdez, A. (2019). Bubble trouble: Strate-\ngies against filter bubbles in online social networks.\nInDigital Human Modeling and Applications in\nHealth, Safety, Ergonomics and Risk Management.\nHealthcare Applications , volume 11582, pages\n441\u2013456. Springer International Publishing.\nD\u2019Alonzo, S. and Tegmark, M. (2021). Machine-\nlearning media bias. arXiv:2109.00024 [cs] .\nDarwish, K., Stefanov, P., Aupetit, M., and Nakov, P.\n(2020). Unsupervised user stance detection on twit-\nter.Proceedings of the International AAAI Confer-\nence on Web and Social Media , 14(1):141\u2013152.\nEntman, R. M. (1993). Framing: Toward clarification\nof a fractured paradigm. Journal of Communication ,\n43(4):51\u201358.\nGanguly, S., Kulshrestha, J., An, J., and Kwak, H.\n(2020). Empirical evaluation of three common as-\nsumptions in building political media bias datasets.\nProceedings of the International AAAI Conference\non Web and Social Media , 14(1):939\u2013943.\nGao, Y ., Zhao, H., Zhou, Q., Qiu, M., and Liu, M.\n(2020). An improved news recommendation algo-\nrithm based on text similarity. In 2020 3rd Inter-\nnational Conference on Smart BlockChain (Smart-\nBlock) , pages 132\u2013136. IEEE.\nGentzkow, M. and Shapiro, J. M. (2010). What drives\nmedia slant? evidence from u.s. daily newspapers.\nEconometrica .\nGroseclose, T. and Milyo, J. (2005). A measure of\nmedia bias. The Quarterly Journal of Economics ,\n120(4):1191\u20131237.\nHamborg, F., Donnay, K., and Gipp, B. (2021). To-\nwards target-dependent sentiment classification in\nnews articles. In Diversity, Divergence, Dialogue ,\nvolume 12646, pages 156\u2013166. Springer Interna-\ntional Publishing.\nHelberger, N. (2019). On the democratic role of news\nrecommenders. Digital Journalism , 7(8):993\u20131012.Hemmatian, F. and Sohrabi, M. K. (2019-10). A sur-\nvey on classification techniques for opinion mining\nand sentiment analysis. Artificial Intelligence Re-\nview, 52(3):1495\u20131545.\nJoseph, K. and Jiang, H. (2019). Content based news\nrecommendation via shortest entity distance over\nknowledge graphs. In Companion Proceedings of\nThe 2019 World Wide Web Conference , pages 690\u2013\n699. ACM.\nKunaver, M. and Po \u02c7zrl, T. (2017). Diversity in recom-\nmender systems \u2013 a survey. Knowledge-Based Sys-\ntems, 123:154\u2013162.\nKwak, H., An, J., Jing, E., and Ahn, Y .-Y . (2021).\nFrameAxis: characterizing microframe bias and in-\ntensity with word embedding. PeerJ Computer Sci-\nence, 7.\nLawrence, J. and Reed, C. (2020). Argument mining:\nA survey. Computational Linguistics , 45(4):765\u2013\n818.\nLiu, B. (2010). Sentiment analysis and subjectivity. In\nHandbook of Natural Language Processing , pages\n627\u2013666.\nLunardi, G. M., Machado, G. M., Maran, V ., and\nde Oliveira, J. P. M. (2020). A metric for filter bub-\nble measurement in recommender algorithms con-\nsidering the news domain. Applied Soft Computing ,\n97.\nM\u00a8oller, J., Trilling, D., Helberger, N., and van Es, B.\n(2018). Do not blame it on the algorithm: an em-\npirical assessment of multiple recommender systems\nand their impact on content diversity. Information,\nCommunication & Society , 21(7):959\u2013977.\nNakov, P., Sencar, H. T., An, J., and Kwak, H. (2021).\nA survey on predicting the factuality and the bias of\nnews media. arXiv:2103.12506 [cs] .\nNazir, A., Rao, Y ., Wu, L., and Sun, L. (2020). Issues\nand challenges of aspect-based sentiment analysis:\nA comprehensive survey. IEEE Transactions on Af-\nfective Computing .\nPariser, E. (2011). The filter bubble: what the Internet\nis hiding from you . Penguin Press.\nPark, S., Kang, S., Chung, S., and Song, J. (2009).\nNewsCube: delivering multiple aspects of news to\nmitigate media bias. In Proceedings of the SIGCHI\nConference on Human Factors in Computing Sys-\ntems, pages 443\u2013452. ACM.\nPatankar, A., Bose, J., and Khanna, H. (2019). A bias\naware news recommendation system. In 2019 IEEE\n13th International Conference on Semantic Comput-\ning (ICSC) , pages 232\u2013238. IEEE.\nQiu, G., Liu, B., Bu, J., and Chen, C. (2011). Opinion\nword expansion and target extraction through double\npropagation. Computational Linguistics , 37(1):9\u2013\n27.\nRaza, S. and Ding, C. (2020). A regularized model to\ntrade-off between accuracy and diversity in a news\nrecommender system. In 2020 IEEE International\n84Conference on Big Data (Big Data) , pages 551\u2013560.\nIEEE.\nRaza, S. and Ding, C. (2021). News recommender\nsystem: a review of recent progress, challenges,\nand opportunities. Artificial Intelligence Review ,\n55(1):749\u2013800.\nRecasens, M., Danescu-Niculescu-Mizil, C., and Ju-\nrafsky, D. (2013). Linguistic models for analyzing\nand detecting biased language. In Proceedings of the\n51st Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n1650\u20131659. Association for Computational Linguis-\ntics.\nRiloff, E. and Wiebe, J. (2003). Learning extraction\npatterns for subjective expressions. In Proceedings\nof the 2003 Conference on Empirical Methods in\nNatural Language Processing , pages 105\u2013112.\nStefanov, P., Darwish, K., Atanasov, A., and Nakov,\nP. (2020). Predicting the topical stance and political\nleaning of media using tweets. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics , pages 527\u2013537. Association for\nComputational Linguistics.\nSunstein, C. R. (2009). Going to extremes: how like\nminds unite and divide . Oxford University Press.\nTintarev, N., Sullivan, E., Guldin, D., Qiu, S., and\nOdjik, D. (2018). Same, same, but different: Al-\ngorithmic diversification of viewpoints in news. In\nAdjunct Publication of the 26th Conference on User\nModeling, Adaptation and Personalization , pages 7\u2013\n13. ACM.\nTitov, I. and McDonald, R. (2008). Modeling online\nreviews with multi-grain topic models. In Proceed-\ning of the 17th international conference on World\nWide Web - WWW \u201908 . ACM Press.\nVrijenhoek, S., Kaya Independent Researcher, M.,\nMetoui Delft, N. T., M \u00a8oller, J., Odijk, D., and\nHelberger, N. (2021). Recommenders with a Mis-\nsion: Assessing Diver-sity in News Recommenda-\ntions. 11.\nWang, H., Zhang, F., Xie, X., and Guo, M. (2018).\nDKN: Deep knowledge-aware network for news rec-\nommendation. In Proceedings of the 2018 World\nWide Web Conference on World Wide Web - WWW\n\u201918, pages 1835\u20131844. ACM Press.\nWong, F. M. F., Tan, C. W., Sen, S., and Chiang, M.\n(2016). Quantifying political leaning from tweets,\nretweets, and retweeters. IEEE Trans. Knowl. Data\nEng., 28(8):2158\u20132172.\nWu, C., Wu, F., Qi, T., and Huang, Y . (2020). Sen-\ntiRec: Sentiment diversity-aware neural news rec-\nommendation. In Proceedings of the 1st Confer-\nence of the Asia-Pacific Chapter of the Associa-\ntion for Computational Linguistics and the 10th In-\nternational Joint Conference on Natural Language\nProcessing , pages 44\u201353. Association for Computa-\ntional Linguistics.Zhang, X., Yang, Q., and Xu, D. (2021). Combining\nexplicit entity graph with implicit text information\nfor news recommendation. In Companion Proceed-\nings of the Web Conference 2021 , pages 412\u2013416.\nACM.\nZhou, T., Kuscsik, Z., Liu, J.-G., Medo, M., Wakel-\ning, J. R., and Zhang, Y .-C. (2010). Solving the ap-\nparent diversity-accuracy dilemma of recommender\nsystems. Proceedings of the National Academy of\nSciences , 107(10):4511\u20134515.\nZiegler, C.-N., McNee, S. M., Konstan, J. A., and\nLausen, G. (2005). Improving recommendation lists\nthrough topic diversification. In Proceedings of the\n14th international conference on World Wide Web -\nWWW \u201905 , page 22. ACM Press.\nZuiderveen Borgesius, F. J., Trilling, D., M \u00a8oller, J.,\nBod\u00b4o, B., de Vreese, C. H., and Helberger, N.\n(2016). Should we worry about filter bubbles? In-\nternet Policy Review , 5(1).\n7. Language Resource References\nCard, D., Boydstun, A. E., Gross, J. H., Resnik, P., and\nSmith, N. A. (2015). The media frames corpus: An-\nnotations of frames across issues. volume 2, pages\n438\u2013444.\nGaillat, T., Stearns, B., Sridhar, G., McDermott, R.,\nZarrouk, M., and Davis, B. (2018). Implicit and ex-\nplicit aspect extraction in financial microblogs. In\nProceedings of the First Workshop on Economics\nand Natural Language Processing , pages 55\u201361. As-\nsociation for Computational Linguistics.\nHamborg, F. and Donnay, K. ). NewsMTSC: A dataset\nfor (multi-)target-dependent sentiment classification\nin political news articles. In Proceedings of the 16th\nConference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Vol-\nume, pages 1663\u20131675. Association for Computa-\ntional Linguistics.\nJangid, H., Singhal, S., Shah, R. R., and Zimmermann,\nR. (2018). Aspect-based financial sentiment analy-\nsis using deep learning. In Companion of the The\nWeb Conference 2018 on The Web Conference 2018\n- WWW \u201918 , pages 1961\u20131966. ACM Press.\nMiller, G. A. (1995). WordNet: a lexical database for\nenglish. volume 38, pages 39\u201341.\nPennington, J., Socher, R., and Manning, C. (2014).\nGlove: Global vectors for word representation. In\nProceedings of the 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 1532\u20131543. Association for Computational\nLinguistics.\nPontiki, M., Galanis, D., Pavlopoulos, J., Papageor-\ngiou, H., Androutsopoulos, I., and Manandhar, S.\n(2014). SemEval-2014 task 4: Aspect based senti-\nment analysis. In Proceedings of the 8th Interna-\ntional Workshop on Semantic Evaluation (SemEval\n2014) , pages 27\u201335. Association for Computational\nLinguistics.\n85Pontiki, M., Galanis, D., Papageorgiou, H., Manand-\nhar, S., and Androutsopoulos, I. (2015). SemEval-\n2015 task 12: Aspect based sentiment analysis. In\nProceedings of the 9th International Workshop on\nSemantic Evaluation (SemEval 2015) , pages 486\u2013\n495. Association for Computational Linguistics.\nPontiki, M., Galanis, D., Papageorgiou, H., Androut-\nsopoulos, I., Manandhar, S., AL-Smadi, M., Al-\nAyyoub, M., Zhao, Y ., Qin, B., De Clercq, O., Hoste,\nV ., Apidianaki, M., Tannier, X., Loukachevitch, N.,\nKotelnikov, E., Bel, N., Jim \u00b4enez-Zafra, S. M., and\nEryi\u02d8git, G. (2016). SemEval-2016 task 5: Aspect\nbased sentiment analysis. In Proceedings of the\n10th International Workshop on Semantic Evalua-\ntion (SemEval-2016) , pages 19\u201330. Association for\nComputational Linguistics.\nSteinberger, R., Hegele, S., Tanev, H., and Della Rocca,\nL. (2017). Large-scale news entity sentiment analy-\nsis. In RANLP 2017 - Recent Advances in Natural\nLanguage Processing Meet Deep Learning , pages\n707\u2013715. Incoma Ltd. Shoumen, Bulgaria.\nNotes\n1http://ec.europa.eu/digital-agenda/\nsites/digital-agenda/files/HLG%20Final\n2https://www.newsguardtech.com/\n3https://www.allsides.com/\n4https://mediabiasfactcheck.com/", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Don't burst blindly: for a better use of natural language processing to fight opinion bubbles in news recommendations", "author": ["E Dufraisse", "C Treuillier", "A Brun", "J Tourille"], "pub_year": "2022", "venue": "\u2026 2022-First Workshop \u2026", "abstract": "Online news consumption plays an important role in shaping the political opinions of citizens.  The news is often served by recommendation algorithms, which adapt content to users\u2019"}, "filled": false, "gsrank": 600, "pub_url": "https://cea.hal.science/cea-04562587/", "author_id": ["YeWwlxgAAAAJ", "SZr9Tb0AAAAJ", "QhjK8KoAAAAJ", "99ywuNMAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:kE8uukE7LH8J:scholar.google.com/&output=cite&scirp=599&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D590%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=kE8uukE7LH8J&ei=cbWsaOqkD7TWieoP1pCJ2AY&json=", "num_citations": 7, "citedby_url": "/scholar?cites=9163764495274626960&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:kE8uukE7LH8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://cea.hal.science/cea-04562587/document"}}, {"title": "SoK: Machine Learning for Misinformation Detection", "year": "2023", "pdf_data": "This paper is included in the Proceedings of the \n34th USENIX Security Symposium.\nAugust 13\u201315, 2025 \u2022 Seattle, WA, USA\n978-1-939133-52-6\nOpen access to the Proceedings of the \n34th USENIX Security Symposium is sponsored by USENIX.SoK: Machine Learning for Misinformation Detection\nMadelyne Xiao and Jonathan Mayer, Princeton University\nhttps://www.usenix.org/conference/usenixsecurity25/presentation/xiao-madelyne\nSoK: Machine Learning for Misinformation Detection\nMadelyne Xiao\nPrinceton UniversityJonathan Mayer\nPrinceton University\nAbstract\nWe examine the disconnect between scholarship and prac-\ntice in applying machine learning to trust and safety problems,\nusing misinformation detection as a case study. We survey\nliterature on automated detection of misinformation across a\ncorpus of 248 well-cited papers in the \ufb01eld. We then examine\nsubsets of papers for data and code availability, design mis-\nsteps, reproducibility, and generalizability. Our paper corpus\nincludes published work in security, natural language process-\ning, and computational social science. Across these disparate\ndisciplines, we identify common errors in dataset and method\ndesign. In general, detection tasks are often meaningfully dis-\ntinct from the challenges that online services actually face.\nDatasets and model evaluation are often non-representative\nof real-world contexts, and evaluation frequently is not inde-\npendent of model training. We demonstrate the limitations of\ncurrent detection methods in a series of three representative\nreplication studies. Based on the results of these analyses and\nour literature survey, we conclude that the current state-of-the-\nart in fully-automated misinformation detection has limited\nef\ufb01cacy in detecting human-generated misinformation. We\noffer recommendations for evaluating applications of machine\nlearning to trust and safety problems and recommend future\ndirections for research.\n1 INTRODUCTION\nOnline services face a daunting task: There is an unceasing\ndeluge of user-generated content, on the order of hundreds\nof thousands of posts per minute on popular social media\nplatforms [ 1]. Some of that content is false, hateful, harassing,\nextremist, or otherwise problematic. How can platforms reli-\nably and proactively identify these \u201ctrust and safety\u201d issues?\nMachine learning has proved an attractive approach in the\nacademic literature, leading to large bodies of scholarship on\nmisinformation detection [ 2], toxic speech classi\ufb01cation [ 3],\nand other core trust and safety challenges (e.g., [ 4]). The con-\nceptual appeal of machine learning is that it could address themassive scale of user-generated content on large platforms\nandthe capacity constraints of small platforms. Recent work\non ML-based approaches to automated misinformation detec-\ntion claims impressive performance statistics: In the literature\nreview that we conduct for this work, among publications that\nreport performance metrics, about 70% of papers report over\n80% accuracy on at least one detection task; some of these\nworks report near-perfect accuracy [ 5,6].\nIn recent years, disclosures from major tech companies\nhave tempered these expectations. In 2023, Twitter\u2019s former\nhead of trust and safety stated that large-scale automated de-\ntection of misinformation remains a hard problem, and that no\ngeneralizable automated solutions are currently available [ 7].\nAutomated misinformation detection and fact-checking tools\nare in development at Google and OpenAI; both companies\nhave disclaimed that these tools still require human interven-\ntion in deployment [ 8]. These disclosures accord with our\nobservation that, in practice, trust and safety functions at on-\nline services are driven by manual interventions such as user\nreports and human moderators.\nIn this work, we investigate the disconnect between schol-\narship and practice in applications of machine learning to\ntrust and safety problems. Our project is inspired by recent\nresearch that has identi\ufb01ed shortcomings in machine learning\napplications for many problem domains, including informa-\ntion security, social science, and medicine [ 9\u201312]. We use\nmisinformation detection as a case study for trust and safety\nproblems because the topic has recently generated a rich litera-\nture with diverse methods and claimed successes. Misinforma-\ntion detection has substantive complexities that are common\nfor trust and safety problems: linguistic and cultural nuance,\nsensitivity to context, and rapidly evolving circumstances.\nWe seek to answer four discrete research questions, which\ncollectively shed light on the research-practice gap in auto-\nmated misinformation detection.\nRQ1. How responsive are misinformation detection methods\nin the academic literature to the needs of online ser-\nvices, speci\ufb01cally social media platforms that host user-\ngenerated content?\nUSENIX Association 34th USENIX Security Symposium    5247\nRQ2. How do ML-based detection methods select targets, cu-\nrate datasets, and evaluate performance? Are there identi-\n\ufb01able missteps related to these design steps in ML-based\nmisinformation detection studies?\nRQ3. How reproducible are published ML-based misinforma-\ntion detection methods?\nRQ4. How generalizable are published ML-based misinfor-\nmation detection methods to out-of-domain data (i.e.,\nto data types, time periods, and topics not present in\ntraining data)?\nWe address these research questions in three ways. First,\nwe conduct a broad literature review and synthesis of the full\npaper corpus (248 papers), with a focus on detection targets\nand evaluation. For a subset of papers (87 works) that address\neach aspect of our design taxonomy, we provide an in-depth\nreview of design methods: dataset design, feature engineering,\nand model selection. Second, we attempt to obtain code and\ndata for well-cited works. Third, we test several representative\napproaches for replication and generalizability. We arrive at\nthe following results by applying these methods.\n1.Detection targets in scholarship are often steps removed\nfrom the misinformation content moderation challenges\nthat platforms face. Instead, methods frequently target\nproxies for the presence of misleading content; methods\nrisk over\ufb01tting to these proxies.\n2.Datasets used in publications are often non-\nrepresentative of real-world contexts. Model evaluation\noften lacks independence from training and rarely\ninvolves close emulation of a real-world deployment.\n3.Data and code availability problems pervade the litera-\nture, inhibiting replication. Where these are available,\nwe are generally able to replicate prior work.\n4.Prior work has poor generalizability when classifying\ncontent beyond what was included in training data.\nWe organize this work as follows: In Section 2, we situate\nthis project within existing security literature and academic\nliterature that critiques machine learning-driven methods. We\nmotivate our choice of automated misinformation detection\nas a representative case study and highlight the particular rele-\nvance of this problem to the security community. In Section 3,\nwe discuss detection goals and de\ufb01nitional inconsistencies\nand present the information taxonomies developed from our\ninductive coding of papers. We discuss \ufb01ndings from our read-\ning and coding of papers in Section 4. Our systematization of\nliterature progresses along two axes: 1) from unimodal to in-\ncreasingly multi-modal methods, and 2) tracking design steps.\nSpeci\ufb01cally, we discuss issues pertaining to method-target \ufb01t,\ndataset curation and feature selection, model selection, and\nmethod evaluation ( RQ1,RQ2). In Section 5, we illustrate\nthe issues identi\ufb01ed in our literature review with a series of\nreplication studies, with a focus on reproducibility and gener-\nalizability of results ( RQ3,RQ4). InSection 6, we conclude\nwith a discussion of \ufb01ndings from our literature review andreplication studies and recommendations for evaluating ML-\nbased interventions for trust and safety. Appendices can be\nfound in our online supplement [ 13]. Based on these observa-\ntions and analyses, we propose directions for future work that\nuses ML to address trust and safety concerns.\nThrough this work, we hope to underscore 1) the preva-\nlence and severity of reproducibility and ML-based method\ndesign issues in the existing misinformation detection liter-\nature, 2) the need for careful and preemptive evaluation of\nML-based methods at the point of problem formulation, and\n3) the importance of method explainability and data acces-\nsibility. We contribute taxonomies, our annotated corpus\nof 248 research papers, recent datasets, and recommenda-\ntions for evaluating ML-based trust and safety tasks.\n2 Motivation\nPlatforms have been motivated to move toward ML-based con-\ntent moderation systems in response to the burgeoning volume\nand diversity (in terms of language, topic, and medium) of so-\ncial media content [ 14]. These systems would ideally be able\nto process large volumes of content and be robust to distribu-\ntional shifts in data, including those caused by real-time events\n(e.g., natural disasters or mass casualty events). These sys-\ntems should also be resistant to circumvention and attempts\nto \u201cgame\u201d moderation [ 15]. Taken together, we summarize\nthese desiderata as generalizability ,versatility in real-time ,\nandrobustness to distributional shifts and attacks .\nResearch-practice gap. Whereas much of the academic\nliterature on ML-based misinformation detection describes\nfully automated methods, we observe that, in practice, online\nplatforms and security research organizations use hybrid pro-\ncesses [ 13]. These hybrid pipelines use automated methods\nandhuman moderators to perform detection at scale or pro-\nvide specialized detection tailored to language or geography.\nAn objective of this work is to understand why deployment\nof fully automated detection approaches has been limited.\nIntended audience. The detection of misinformation and\n\u201cin\ufb02uence operations\u201d (IOs) is a topic of convergent interest in\nsecurity, social science, and AI/ML; researchers in these areas\nand trust & safety practitioners in industry are the intended\naudience for this work. Methods developed for the detection\nof in\ufb02uence operations (e.g., astrotur\ufb01ng and coordinated mis-\ninformation campaigns) resemble techniques previously used\nby security researchers to detect botnets, advanced persistent\nthreats (APTs), and malware [ 16\u201318]. These security-oriented\napproaches target anomalous network traf\ufb01c, code semantics,\nmisleading and inauthentic content, and evidence of coordi-\nnated activity. In general, security research requires adaptive\nresponses to rapidly changing, possibly adversarial conditions\nnot unlike those on social media platforms. Misinformation\nresearch may also bene\ufb01t from the formal structure of se-\ncurity research methodology: Human fact-checkers have ex-\npressed interest in adopting threat modeling practices similar\n5248    34th USENIX Security Symposium USENIX Association\nto those found in security literature [ 19]. As such, the security\ncommunity is well-positioned to shepherd the responsible\ndevelopment of misinformation detection methods.\n3 Preliminaries\nWe present terminology and taxonomies used in this work\nand describe our criteria for evaluating reported detection\ngoals and performance. We also discuss assumptions inherent\nto much of the work we review, such as the feasibility of\nmisinformation detection using weak semantic signals only.\nDe\ufb01nitions. De\ufb01nitions of misinformation, disinformation,\nmalinformation, andin\ufb02uence operations vary across the lit-\nerature; as such, for each paper we review, we consider the\npaper authors\u2019 working de\ufb01nitions of these terms (if such\nde\ufb01nitions are provided) and evaluate model performance\nwith respect to the de\ufb01nitions set forth [ 20\u201324]. We note that\nthe nature of misinformation narratives and misinformation\nspread varies with language and geography. We limit our\nanalysis to text-based English-language content to facilitate\nindependent veri\ufb01cation of classi\ufb01cation results (English is\nthe primary language of both paper authors). We addition-\nally note that disinformation is commonly used to refer to\nincorrect information written with the intent to deceive, while\nmisinformation refers to incorrect information in general; for\ncompleteness and concision, we refer to intentionally andun-\nintentionally false information as misinformation unless other-\nwise quali\ufb01ed. We occasionally use false rumors, false news,\nandfalse information interchangeably, but avoid fake news ,a\npolitically charged term [ 25]. We use \u201cin\ufb02uence operations\u201d\n(IOs) or \u201ccoordinated campaigns\u201d to discuss collaborative\nattempts to disseminate misinformation across networks [ 26].\nIn this work, a \u201cpositive\u201d detection result means that a piece\nof content has been \ufb02agged as misinformative.\nDetection goals. We evaluate the experimental methods\nin our paper corpus for generalizability across topics and\ntime; performance in real-time settings; and robustness to\nevasion and distributional shifts . These desiderata re\ufb02ect real-\nworld platform needs, as discussed in Section 2. Methods that\nexhibit \u201cgood\u201d performance on out-of-distribution, real-time,\nand adversarial detection tasks are \u201cresponsive\u201d to the needs\nof actual platforms. We consider method performance with\nrespect to the metrics, datasets, and detection settings reported\nby authors. These metrics include accuracy, precision and\nrecall, AUC, and F1 scores. Though we provide guidelines for\nevaluating these metrics in the next subsection, we emphasize\nthat, with few exceptions, differences in dataset and target\nchoice inhibit direct comparisons between papers. We discuss\ntarget misalignment in Limitations ( 6.2).\nEvaluation metrics. Precise thresholds for \u201cgood\u201d perfor-\nmance on these metrics are hard to determine. Performance\non common evaluation metrics must be weighed against\nthe needs of the deployment setting. These considerations\u2014\nwhich include the potential impacts of a correct or incorrectclassi\ufb01cation, class distributions in test and training data, and\nthe semantic content of datasets\u2014should in\ufb02uence interpreta-\ntion of quantitative measurements, and authors should clearly\nstate any thresholds for acceptable performance and their\nrationale for these thresholds. For instance, if the detection\nsetting concerns sensitive information for which a false nega-\ntive is potentially high-risk (e.g., COVID symptoms), higher\nperformance on recall will be important.\nWhile higher reported scores on common metrics for ML\nperformance (e.g., precision, recall, F1) are generally prefer-\nable, readers should remain mindful of data over\ufb01tting and\nimbalanced class distributions, which might yield deceptively\nhigh scores. (We include information about some common\ndatasets used for misinformation detection tasks in Appendix\nB[13].) As such, it is inadvisable to compare performance\nbetween papers with different target formulations and dataset\nchoices. In our literature review, we show how pervasive these\ndifferences are between papers and discuss their impact on\ncomparison. Published works use these metrics to suggest\nthat, given assumptions about generalizability of performance\nanddataset choice , these algorithms perform suitably well\nfor real world uses. We challenge these assumptions.\nTaxonomies. Through iterative inductive coding of papers,\nwe develop a taxonomy of \ufb01ve \u201cinformation scopes.\u201d As we\nread each paper in our corpus, we noted the smallest semantic\nor organizational unit of information classi\ufb01ed as true or false\nand sorted each paper into emergent categories. We identify\n\ufb01ve information scopes: claims ,articles ,users ,networks ,\nandwebsites . We consider these scopes in the context of on-\nline services\u2014for instance, articles and websites whose links\nmight be posted to a platform. A work whose target impli-\ncates multiple scopes receives multiple labels. For instance, a\nwork targeting the virality of arumoring topic will receive N\nandAlabels, corresponding to virality ( N.i) and topic (A.ii)\ntargets. A summary of takeaways, organized by design steps,\nis in Figure 3. By-scope takeaways are in the gray boxes at\nthe end of each subsection in Section 4. Targets are speci\ufb01c to\ninformation scope: we present them, with scope de\ufb01nitions,\nin Figure 1. In our literature review, we consider the stated\nversus actual target of the classi\ufb01cation task that paper au-\nthors describe: While the goal of misinformation detection is\nthe identi\ufb01cation of incorrect information , we \ufb01nd that many\nmethods instead target sentiment and virality, for instance, as\nproxies for the presence of misinformation [ 27,28].\nWe also describe methodological errors with respect to\nthe step of the ML experiment design in which they occur:\ndataset curation ,model choice ,feature selection andmodel\nevaluation . These design considerations are generally scope-\nagnostic: We present them in Figure 2. Deep coding of these\ndesign aspects is available for a subset of works (see \u201cFull\nand focus paper corpora\u201d).\nFeasibility of detection. Most of the work we review pre-\nsupposes that automated detection of misinformation without\nsemantic reasoning is possible at all. We note that this is, in\nUSENIX Association 34th USENIX Security Symposium    5249\nInformation scopes and detection targets.\nTargets are speci\ufb01c to scope. Target discussion sec-\ntions in the literature review are denoted by a\n .\nCClaim. The smallest semantic unit of fact or mis-\ninformation, comprising a subject, predicate, and\nobject, at minimum.\nDetection targets:\ni.Veracity of semantic content.\nii.Path length on a knowledge graph topology.\niii.\u201cCheckability\u201d or \u201ccheckworthiness.\u201d\nAArticle. News-oriented writing of length 100\nwords or more.\nDetection targets:\ni.Sentiment and style (e.g., tone and genre).\nii.Stance with respect to known rumoring topics.\nUUser. All data and metadata associated with a\nsingle user\u2019s account, as de\ufb01ned by a social me-\ndia platform (e.g., an account corresponding to\na handle on Twitter/X or a page or pro\ufb01le corre-\nsponding to one business, individual, or organi-\nzation on Facebook).\nDetection targets:\ni.Suspicious account metadata, including bio text,\nimages, and account age.\nii.Suspicious single-account behaviors, including\ncomments on posts and published content.\nNNetwork. A set of users, and interactions be-\ntween those users, as represented by a social\ngraph.\nDetection targets:\ni.Degree of virality.\nii.Anomalous interactions between users.\nWWebsite. A news site, including its hosting in-\nfrastructure and text and image contents.\nDetection targets:\ni.Suspicious text and URL/domain semantics.\nii.Site visitor demographics.\niii.Suspicious UI elements, including ads.\niv.Hosting infrastructure, including DNS certi\ufb01-\ncates and site age.\nFigure 1: When referenced elsewhere, scope targets are as-\nsigned alphanumeric labels comprising the scope abbreviation\nand the Roman numeral corresponding to the target. C.ii, for\ninstance, references the second target in the Claim -scoped\nsection of this taxonomy (\u201cPath length on a knowledge graph\ntopology).\u201dDesign taxonomy.\nDesign steps are scope-agnostic. Design discussions\nare in the literature review are denoted by a circled\nnumber (e.g., 1).\n1Dataset curation. The source, size, and contents\nof datasets used for model training and testing.\nDataset properties:\ni.Dataset age.\nii.Evidence of temporal or feature leakage.\niii.Dependencies, including those relating to author-\nship, source, and topic.\niv.Availability of original data.\n2Model choice. The choice of ML model used\nfor the detection task, as well as the motivation\nfor this choice.\nModels and approaches:\ni.Distance calculations on embeddings;\nii.\u201cTraditional\u201d ML, including KNN, naive Bayes,\nand gradient boosting.\niii.Deep learning.\niv.Graph algorithms.\nv.Ensemble classi\ufb01ers.\n3Feature selection. The choice of feature(s) that\npaper authors use to train their ML models, as\nwell as their motivation for this choice.\nFeature types:\ni.Textual features, including semantics and syntax;\nii.Network-based features, including user interac-\ntions and posting behaviors.\niii.User-based features (e.g., bios and account age).\niv.Infrastructural features, including site UI.\n4Model evaluation. Paper authors\u2019 approach to\nbenchmarking method performance after initial\ntraining and reported scores. These codes re\ufb02ect\ncommon desiderata for social media platforms.\nEvaluation criteria:\ni.Evidence of real-time testing on live feeds.\nii.Generalizability to topic domains and times-\ntamps not included in training data.\niii.Robustness to evasion and distributional shifts.\niv.Justi\ufb01cation for quantitative benchmarks, includ-\ning false positive/negative rate, AUC, and F1.\nFigure 2: When referenced elsewhere, these codes are as-\nsigned Arabic-Roman numeric labels comprising the design\nstep and subtaxa code. For instance, 4.ireferences the \ufb01rst\ncode in the Model evaluation section, or \u201cEvidence of real-\ntime testing on live feeds.\u201d\n5250    34th USENIX Security Symposium USENIX Association\nDesign Step Takeaways\n1Dataset curation Data availability issues pervade the literature across all \ufb01ve scopes .Claim -scoped methods rely on outdated\ndatasets and inconsistent taxonomies for classi\ufb01cation tasks. Article -scoped methods assign single labels to\nnewswriting where more granular labels would be more descriptive. User- and network -scoped methods\nrely on social media data and human-annotated data that has since become inaccessible to the public.\nWebsite -scoped data is necessarily multimodal and is dif\ufb01cult to control for distribution shifts over time.\n2Model choice Claim -scoped methods that use knowledge graph search have limited ef\ufb01cacy when performing detection\non novel information domains. Improvements achieved by unsupervised methods at the article scope\nmight be due to dependencies in text data. At the user andnetwork level, models that are agnostic to\ntext semantics cannot infer the intent (malicious or otherwise) of suspicious behavior. We observe that\nwebsite -scoped methods that use traditional supervised ML models outperform unsupervised models on\ntwo-way classi\ufb01cation tasks.\n3Feature selection Claim -scoped methods require structured inputs that are frequently unavailable in late-breaking scenarios.\nArticle -scoped methods rarely control for author- and source-induced dependencies. User-scoped methods\nthat use political af\ufb01liation and demographic characteristics as features risk reinforcing existing biases.\nNetwork -scoped methods make strong assumptions about the behaviors of users in a graph, including the\nlikelihood that users will believe misinformative online content. Multimodal feature sets in website -scoped\nmethods are not normalized, despite differences in distribution, prevalence, and medium.\n4Model evaluation Across all \ufb01ve scopes , testing in real-time is rare, though many authors cite the slow pace of human fact-\nchecking as motivation for their work. In addition, all scopes have generalizability issues. Claim -scoped\nmethods on knowledge graphs are limited by the contents of known relationships between graph nodes.\nArticle -scoped methods that perform stance detection depend on a priori knowledge of known rumoring\ntopics. Network - and user-scoped methods can only detect behaviors that emulate known suspicious\nbehaviors. Website -scoped methods are susceptible to shifts in distributions of hosted content.\nFigure 3: Primary takeaways from our literature review, organized by design step.\nitself, a strong assumption to make: Published work in lin-\nguistics and philosophy of language has previously called into\nquestion the feasibility of using weak semantic and syntactic\nfeatures to determine the veracity of text statements [ 29,30].\nOn the other hand, some researchers maintain that misinfor-\nmative texts are characterized by indelible \u201c\ufb01ngerprints\u201d that\ndistinguish them from non-misinformative texts: for instance,\nemotional language and reduced lexical diversity [ 31,32].\nThis debate motivates our discussion of non-textual features.\n4 Systematization of Literature\nIn this section, we describe our methodologies for collecting\nan initial pool of eligible papers, developing a rubric for inclu-\nsion or exclusion, and annotating the \ufb01nal corpus. A summary\nof our \ufb01ndings, organized by design step, appears in Figure 3.\n4.1 Corpus Development and Annotation\nPaper selection. To seed our paper corpus and identify de-\ntection methods that have been well-received by the research\ncommunity, we manually curated a selection of 23 highly-\ncited survey papers that provide comprehensive overviews ofthe state of automated misinformation detection at the time of\nwriting [ 2,33\u201354]. We queried Google Scholar with the fol-\nlowing terms: \u201c survey misinformation detection \u201d and\n\u201csurvey fake news detection .\u201d We collected the most\nfrequently cited papers within the past 10 years.1\nWe then inspected each paper\u2019s references for related\nwork; we read the abstracts of these works in order to con\ufb01rm\nrelevance. We supplemented this corpus of papers with\npublications surfaced by Google Scholar queries. We queried\nthe following terms: \u201c misinformation detection\n[x]\u201d and \u201c automated fact checking [x],\u201d where\nx\u2192{ claims, news articles, users, networks,\nwebsites, influence operations }.2For each x, we\ntook the union of papers resulting from both search queries,\nthen selected the 50 most highly cited papers in this combined\nset. To counter potential bias toward older publications,\nwe collected papers with the highest citation rates per\nyear. These search terms are deliberately overinclusive; we\nmanually review all works for relevance after the initial\nsampling step. This manual review yielded a set of 250\n1This timeframe was naturally enforced by a lack of well-cited older\npublications, and was not \ufb01xed before we began our sampling process.\n2We include \u201cin\ufb02uence operations\u201d as a separate search term because this\nterm of art is relatively new.\nUSENIX Association 34th USENIX Security Symposium    5251\npapers. After applying our inclusion criteria (see In- and\nout-of-scope work ), 219 papers remained. To ensure that\nsecurity-oriented approaches to detection were represented\nin our corpus, we conducted a separate snowball sampling\nsearch for work published in four A* security research venues\n(USENIX Security, IEEE S&P, NDSS, and ACM CCS),\nusing the keywords listed previously [ 55]. This resulted in\nthe addition of 29 works, mostly addressing the detection of\naccounts and networks that spread misinformation. Our \ufb01nal\ncorpus comprises 248 papers published between 2009 and\n2024, inclusive.\nIn- and out-of-scope work. To be included in our liter-\nature corpus, papers must discuss ML-based approaches to\ndetection of online misinformation, rumors, or in\ufb02uence oper-\nations. The ML-based methodology may form all or only part\nof the whole detection pipeline (e.g., hybrid methods are also\neligible for inclusion). By these criteria, papers that propose\ndetection novel methods andpapers that present critiques and\nreviews of existing methods (e.g., survey papers in our seed\nset) are eligible for inclusion.\nWe also consider a number of security-oriented approaches\nto misinformation detection in this work. Sybil and botnet\ndetection methods that target IOs are categorized as account-\nand network-scoped detection methods in our corpus. Com-\nmercial approaches to misinformation detection are in-scope\nfor this project. In view of data access issues, we are unable\nto provide an in-depth analysis of commercial methodologies\nin our literature review, and include a market survey of com-\nmercial fact-checking providers in Appendix A [ 13]. LLM-\npowered detection is in-scope for this work. Accessibility to\ncode bases for LLMs is similarly limited, and inhibits evalua-\ntion by researchers [ 56,57]. While we do not provide analysis\nspeci\ufb01c to LLMs, our survey includes systems that involve\nLLMs, and our takeaways are applicable to these systems.\nCorpus curation and coding. We used automated\nkeyword matching to con\ufb01rm that all collected papers\naddress misinformation and automated fact-checking\nmethods (keywords were each element of the set\n{machine learning, misinformation, detection }\nand all combinations thereof); we read the abstracts of papers\nsurfaced by this check to con\ufb01rm relevance. We annotated\nresearch papers that passed this check in accordance with\nour taxonomy. One reader made three coding passes over\nthe corpus: First, she identi\ufb01ed a taxonomy of information\nscopes; second, she noted actual versus stated detection\ntargets and approaches to evaluation; \ufb01nally, she noted\nmethod design approaches and errors. Two coders read and\nindependently coded a random subset (30 papers) of the full\ncorpus. Fleiss\u2019s kappa for annotations of this subset was 0.84,\nindicating strong agreement.\nFull and focus paper corpora. We complete our paper\ncoding at two different levels of granularity. We develop our\ntarget and design taxonomies from iterative coding of the\nfull paper corpus. To develop our focus corpus, we identi\ufb01edpapers with suf\ufb01cient responses to each coding \ufb01eld in our de-\nsign taxonomy: One coder manually reviewed annotations for\nthe full corpus and noted papers that provide at least general\ndescriptions of their choice of dataset, features, and model.\nFrom these papers, we then sampled works from each scope\nin proportion to that scope\u2019s representation in the full corpus,\noversampling within each scope for diverse methods and data.\nThis corpus comprised 87 papers. For each of these, we per-\nform deep-coding of methods: We additionally note dataset\nage, availability, and contents (including evidence of leakage\nor dependencies); motivation for model choice; and feature\ntypes (respectively, steps 1,2, and 3in Section 3).3Our\nmotivation for developing this focus set is practical: Many of\nthe works we review do not include complete discussions of\nevery section of our overall coding taxonomy. For all papers\nin the full corpus (248 works), we note targets and evaluation.\nNotation. Targets are generally unique to information\nscope and are denoted by an alphanumeric label (e.g., (A.i)).\nDesign steps are notscope-speci\ufb01c. In Section 4, design steps\nare denoted by circled icons (e.g., 1,4) and subtaxa within\nthose categories are denoted by Roman numerals ( iv). As\nan example, the stated target of [ 61] is \u201ctroll\u201d accounts on\nReddit. The actual target of this work is (U.ii) frequency of\ninteractions with known troll accounts . Account identi\ufb01ers\nhave been scrubbed, impeding manual veri\ufb01cation of perfor-\nmance; this is a (1.iv) data accessibility issue . The method\nuses a random forest classi\ufb01er, (2.ii) a classic ML model , and\nconsiders counts of posts and replies\u2014these are (3.ii) network-\nbased features . The method is not(4.i)tested in real-time ,\nand the paper does not evaluate (4.ii) model generalizability\nto behavior not captured in a known trolls list.\n4.2 Claims\nWe de\ufb01ne a single \u201cclaim\u201d as the smallest semantic unit of fact\nor misinformation, minimally comprising a subject, predicate,\nand object. Claim-scoped papers form 15% of our corpus.\nAbout 70% of paper authors within this scope cite the 2016\nU.S. presidential election as motivation for the development\nof their methods [ 62\u201364]; about 30% cite COVID-19 misinfor-\nmation [ 65\u201367]. A majority of works mention the speed and\nvolume of social media misinformation [ 68]. 30% cite the rel-\natively slow pace of manual fact-checking [ 63,68,69]\u2014and\nthe need for faster, automated approaches\u2014as motivation.\nDetection targets. Claim-scoped detection methods\ngenerally target the semantic contents of text statements. This\nis done in the following ways: (C.i) distance calculations on\nsemantic embeddings to perform textual entailment or stance\ndetection [ 70,71]; and (C.ii) search on a knowledge graph\ntopology [69,72] to determine if these reference sources cor-\nroborate or refute the claim to be checked. A small class\nof approaches explicitly detect (C.iii) \u201ccheckworthiness ,\u201d4\n3We take inspiration from [ 58\u201360], which perform similar deep-coding.\n4We include these works in our corpus because they dotake topic and\n5252    34th USENIX Security Symposium USENIX Association\nand are intended to surface checkable statements to human\nfact-checkers for manual veri\ufb01cation [ 63,68,72].\nTargets such as author credibility are proxy targets for the\npresence of misinformation: non-semantic signals which do\nnot directly indicate text veracity, but suggest (lack of) ve-\nracity by association with an external heuristic. About 60%\nof papers at this scope use proxy targets, including the (A.i)\nsyntactic and/or stylometric qualities of text [73],(U.i) source\nreputation [74], or(U.ii) contextual indicators , such as com-\nmenter responses [ 75], to classify social media posts.\n1Dataset curation. Claim-scoped papers in our corpus\nthat propose to perform fact veri\ufb01cation (1.i) rely on out-\ndated existing datasets of labeled statements in order to es-\ntablish ground truth. LIAR [ 76] and PolitiFact [ 77] were\nthe most popular datasets among claim-scoped works, and,\ntaken together, were used by approximately half of all papers\nwithin this scope [ 78,79]. LIAR is a static political news\ndataset that was published in 2017; on average, papers that\ncite LIAR were published two years after LIAR\u2019s release.\nTopic detection and word frequency models trained on LIAR\nare likely ineffective in contemporary fact-checking contexts\nand for non-political subject matter [ 62,74]. Additionally,\nclass labels across datasets are inconsistent: PolitiFact uses\na six-point labeling scale (pants-on-\ufb01re; false; barely-true;\nhalf-true; mostly-true; true), FEVER uses a three-point scale\n(supported; refuted; notenoughinfo), and GossipCop uses an\neleven-point scale (0 to 10). Rescaling is insuf\ufb01cient for these\ndifferent label sets, some of whose criteria don\u2019t translate to\nother labeling regimes (e.g., FEVER\u2019s \u2018notenoughinfo\u2019 clas-\nsi\ufb01cation addresses information availability, not factuality).\n2Model selection. For methods that pre-construct knowl-\nedge graphs or other reference databases, models perform\nsome form of (2.i) shortest-path search on the KG topol-\nogy [ 72] and approximate logical inference via transitive\nclosure on graph edges [ 69]. For methods that perform infor-\nmation retrieval at query time\u2014e.g., to match corroborating\nsources to a claim\u2014text statements are \ufb01rst converted to bag-\nof-words or TF-IDF embeddings [ 80,81]. For methods that\nperform detection of misinformative posts on social media,\n(2.v) stacked ensemble classi\ufb01ers are a common approach to\nincorporating multiple feature modalities [ 82,83].\n3Feature selection. Semantic feature analysis is limited\nto the (3.i) identi\ufb01cation of structured statements as a precur-\nsor to knowledge graph (KG) construction. These claims take\nthe form of subject-predicate-object (SPO) statements (e.g.,\n\u201cI like pie\u201d) [ 69,72,84]. Detection versatility is determined\nby the size of the source dataset and the granularity of the re-\nlationships encoded by graph edges [ 72]. Supervised methods\nthat detect linguistic cues use (3.i)hand-crafted word or topic\nlists[68]). Papers describing supervised methods claim that\nthis approach permits highly customized targeting of speci\ufb01c\nrumoring narratives [ 68], though this also assumes that users\nsource credibility into consideration in the process of ranking checkability.will have prior knowledge of the contents of test data; papers\nusing unsupervised methods claim that their approaches detect\ncontext that cannot be easily extracted by common features\nsuch as word frequency or sentiment [ 78]. Methods trained\non social media data consider (3.ii) network and(3.iii) user\ninteraction features (likes, shares, comments) [ 85\u201387].\n4Evaluation. Though a majority of claim-scoped meth-\nods cite the speed of social media misinformation as mo-\ntivation, (4.i) only one method within this scope reported\nresults from testing in real time [88]. KG-based methods are\n(4.ii) non-generalizable by design : the approaches we sur-\nvey require structured inputs for graph construction and rely\non published datasets for ground truth [ 69,72]. Though this\napproach permits semantic veri\ufb01cation of statements, it is\ndif\ufb01cult to perform iterative updates to source databases in\nreal-time, particularly in the types of online settings where\nclaim-checking might be most usefully deployed (e.g., during\nbreaking news events, where no source of ground truth is\nimmediately available). We observe that a majority of works\nat this scope do not test on novel or out-of-domain data; we\ndiscuss over\ufb01tting issues in greater detail in the next section.\nTakeaways :\n For KG-based methods, classi\ufb01er ef\ufb01cacy is\ndetermined by the coverage conferred by reference databases.\n1Datasets are often out-of-date, and taxonomies are inconsis-\ntent. 2Models at this scope attempt to approximate knowledge\nretrieval and fact veri\ufb01cation processes. 3Knowledge graph-\nbased methods require structured inputs, which might not be\nreadily available in a breaking news setting where ground truth\nreferences are unavailable. 4Few papers test in real time, de-\nspite citing the slow pace of manual fact-checking as motivation.\n4.3 Articles\nThis scope includes news-oriented writing of length 100\nwords or more and comprises 24% of our paper corpus. 25%\nof papers within this scope cite growing distrust of main-\nstream news media outlets as motivation for their methods,\nwhich promise to deliver fast labeling of news stories that\nappear on social media [ 54]. Text-based credibility classi\ufb01ers\nhave been shown to have limited ef\ufb01cacy, however: while\nunsupervised approaches can identify biaswith high reported\naccuracy, this performance degrades in misinformation and\ncredibility classi\ufb01cation tasks [ 89,90].\nDetection targets. In contrast to single claims, full-\nlength news articles have suf\ufb01cient text contents to make\nsemantic veri\ufb01cation dif\ufb01cult and some off-the-shelf NLP\napproaches practicable. These approaches are distinct from\ndirect claim veri\ufb01cation and perform proxy detection: For\ninstance, Bhutani et al. associate strongly negative sentiment\nwith the presence of false information [ 80], and Horne et al.\n\ufb01nd that satire and misinformation share stylistic similari-\nties [ 91]. Article-scoped methods detect proxy targets and\nadopt at least one of the following approaches to detection:\nUSENIX Association 34th USENIX Security Symposium    5253\n(A.i) NLP analysis of article contents to identify language fea-\ntures particular to writing styles heuristically associated with\nmisinformation (genre detection, sentiment analysis) [ 92]; and\n(A.ii) analysis of article contents and headlines to identify\nstance with respect to known misinformation narratives (topic\ndetection) [ 43,68]. Respectively, these approaches 1) simul-\ntaneously assume and detect a heuristic (e.g., strong emotion\nindicating the presence of misinformation); and 2) assume\nprior knowledge of misinformative or false rumoring topics.\n1Dataset curation. While well-annotated and current\ndatasets are in short supply across all scopes, this de\ufb01cit is\nparticularly glaring at the article scope. This is due in part to\nde\ufb01nitional ambiguities that prevent \ufb01ne-grained labeling of\nlonger texts. We observe that 44% of papers within this scope\n(1.i)use public datasets released years prior to the start of\nresearch [76,91,93,94]. These datasets (e.g., LIAR [ 76])\ninclude news links, speaker credibility scores, and other meta-\ndata that (1.ii) constitute sources of leakage for methods that\nuse contextual features to infer true/false labels. The remain-\ning 56% of papers use corpora curated by asking crowdwork-\ners to generate misinformative text [ 95], selectively editing\ntrue news articles (e.g., via verb inversion) [ 96], or compiling\narticles from news sources and known satire sites [ 97]. These\ntechniques (1.iii) may introduce additional dependencies to\ntext datasets for which such variables are already dif\ufb01cult to\ncontrol. Style, for instance, is an emergent quality that cannot\nbe easily marginalized out of a text embedding [ 90].\n2Model selection. Among papers that report testing with\nmultiple models on the same dataset\u2014including (2.ii) classi-\ncal ML models [98],(2.iii) unsupervised NN models [93], and\n(2.v) stacked ensemble classi\ufb01ers [99]\u2014there is no clear cor-\nrelation between model choice and actual performance. We\nnote that, in instances where papers report testing on binary\nandmulti-class classi\ufb01cation tasks, performance generally\ndeclines in the latter case [ 100].\n3Feature selection. Among supervised methods that dis-\nclose feature sets, we \ufb01nd that (3.i)word frequency, sentiment,\nand genre were among the most commonly used features, and\nwere used by about 80% of works within this scope; these\nfeatures can also be sources of dependency-induced noise.\nIt is dif\ufb01cult to quantify the impact of dependencies related\nto tone and source on classi\ufb01er performance, particularly in\nthe case of unsupervised learning methods, which comprise\n59% of methods at this scope. We evaluate an unsupervised\nlearning method (and consider style-related dependencies) in\nour replication of Nasir et al. ( 5.1)[101].\n4Evaluation. Article-scoped methods risk over\ufb01tting to\nsingle topics: 42% of authors select (4.ii) one or more narra-\ntives of interest (e.g., the 2016 presidential election), train a\nclassi\ufb01er on these topics, then test this classi\ufb01er on a differ-\nent set of texts that discuss the same topic [ 101\u2013103]. This\napproach, while valid for evaluating performance on closed\ndatasets, lacks ecological validity for the use cases that these\nworks claim that their methods will address: high-qualityannotations of relevant articles are generally unavailable in\nbreaking news scenarios [ 104]. 60% of papers at this scope\ncompare the performance of their detection method to pub-\nlished approaches or ML models, but (4.ii) neglect to test\non novel datasets . These methods do well when tested on\nin-domain texts, and in comparison to a selection of older ML\nmodels; many report accuracy well above 80% [ 105,106].\nOne paper within the article scope tested in an adversarial set-\nting. In that work, stylometry-based misinformation detection\nhad an accuracy rate greater than 80% on routine tasks, but\nthis score dropped to about 50% in adversarial cases [ 100].\nTakeaways :\n In the absence of semantic de\ufb01nitions of\nmisinformation, proxy detection targets are common but\neasy to evade. 1Well-labeled datasets are rare; those\ndatasets that are available are at least several years old at\ntime of writing. 2Unsupervised methods show marginal\nimprovements over classical ML models in some cases; it\nis unclear if these improvements are 1) signi\ufb01cant or 2)\nsustainable across different datasets. 3Detection methods\nat the article scope are especially susceptible to text-based\ndependencies. 4In\ufb02ated performance scores can often be\nattributed to testing on same-topic news articles.\n4.4 Users\nAccount-scoped works consider user account metadata and\ncontent output. This scope forms approximately 15% of our\ncorpus (40 papers). Evidence of foreign interference during\nthe 2016 U.S. presidential election triggered a resurgent inter-\nest in malicious account detection [ 61,107]. As such, about\n90% of security- and social-science-oriented works that we\ninclude within this scope (12 papers) explicitly discuss Rus-\nsian trolls or other in\ufb02uence operations conducted by nation-\nstate actors and train classi\ufb01ers on published lists of such\naccounts [ 19,61,108\u2013110].\nDetection targets. Papers within this scope target\nsource reputation and (U.i) inspect account metadata , such\nas bios, account age, and pro\ufb01le images; or distinguish sus-\npicious accounts by (U.ii) a user\u2019s social behaviors , such as\ntheir comments on posts. The security literature we review\ndiscusses trolls and bots deployed for astrotur\ufb01ng, misinfor-\nmation campaigns, and IOs [ 61,111\u2013114]. Absent rigorous\nde\ufb01nitions of these account types, however, actual detection\ntargets are tautological: A troll is an account that exhibits troll-\nlike behavior, or that interacts with known troll accounts [ 61].\n1Dataset curation. All troll and bot account detection\nworks we review rely on published lists of \u201cknown\u201d troll ac-\ncounts for model training, but (1.iv) neglect to emphasize the\nheavily manual investigation required to produce these origi-\nnal lists [115,116]. Researchers who compile some of these\naccount lists, including a set of several hundred Twitter ac-\ncounts with possible links to a known Russian troll farm (the\nInternet Research Agency), manually examine suspicious ac-\n5254    34th USENIX Security Symposium USENIX Association\ncounts and tweet contents in order to produce detailed account\nand content taxonomies; notably, these lists require nonpublic\ninformation about account activity [ 116]. Two well-cited troll\nlists compiled by the U.S. government, comprising thousands\nof suspicious Twitter and Facebook accounts, were curated\nusing proprietary nonpublic information [ 117].\n2Model selection. We note that, regardless of model\nchoice, if classi\ufb01er training data andfeature selection re\ufb02ect\na heuristic about suspicious behavior, the resulting classi\ufb01er\nwill simply learn this heuristic: The methods we review can be\nused to detect accounts whose behaviors conform to heuristic\nassumptions, but cannot be used to surface novel malicious\nbehaviors and are not resistant to attacks or evasion [ 118]. We\nexplore this further in our replication analysis of Saeed et al.\n(Section 5.2)[61]. Additionally, some methods at this scope\nand the network scope formulate detection as a ( 2.iv)graph\ncut problem , and describe approaches to identifying optimal\ncuts for isolating suspicious accounts [ 119,120].\n3Feature selection. Methods that de\ufb01ne suspicious ac-\ncounts by properties of these accounts target the (3.iii) se-\nmantic contents of bios, pro\ufb01le images, and user handles and\ndetect evidence of manipulation in these elements or text\noutputs, such as posts and links [ 121,122]. Methods that\nde\ufb01ne suspicious accounts by account activity target (3.ii) net-\nworked behaviors , such as liking and resharing statistics [ 123].\nFeature sets for some methods in the \ufb01rst category include\ndemographic data for users, such as inferred political party\naf\ufb01liation or race [ 124] (these nth order assumptions are dan-\ngerous to make [ 125]; see our discussion about proxy signals,\nin Section 4.3).\n4Evaluation. We observe accuracy scores above 80% for\n(4.ii) con\ufb01rmatory detection of like accounts for all methods\nthat reference a seed list of known trolls [ 61,107,126]; de\nnovo detection of behaviors not represented within training\ndata is not possible, as noted by 10% of works within this\nscope [ 18,61]. As we discuss further in the next subsection\n(Networks ), the increasingly hybrid nature of IOs requires\nmore nuanced taxonomies for classi\ufb01cation: extent of coor-\ndination, rather than existence , might be a more appropriate\nmeasure of possible manipulation. Some works proposing\nbot detection methods acknowledge that their approaches are\n(4.iii) trivially easy to evade if account holders 1) avoid in-\nteracting with known suspicious accounts or 2) vary their\naccount identity and posting semantics [ 111,127].\nTakeaways :\n Targets are often tautological. 1Manu-\nally annotated training datasets are the result of intensive\nfact-\ufb01nding on the part of human researchers, and often\nrequire information that is not publicly available. 2Classi-\n\ufb01ers can only detect accounts resembling those in seed lists.\n3Features that attempt to infer user credibility from de-\nmographic information risk reinforcing existing biases. 4\nCurrent methods cannot detect novel malicious behaviors.4.5 Networks\nNetworked scoped methods attempt to identify groups of\naccounts acting in concert to promote misinformative narra-\ntives. These methods, including relevant security literature,\nform 20% of our corpus. In the security literature, a growing\nawareness of hybrid networks, which use a combination of\nautomated and manual approaches to disseminate content, has\nencouraged a turn toward network-based bot detection meth-\nods and away from detection of individual accounts [ 111,128].\nWe observe a parallel turn toward network-based methods in\nAI, ML, and NLP venues as a result of growing recognition\nof over\ufb01tting and generalizability issues in purely text-based\ndetection methods (see Articles )[129]. The common assump-\ntion, across disciplines, is that coordinated networks leave\nmore detectable evidence of manipulation than do individual\naccounts and that these \ufb01ngerprints should be identi\ufb01able\nregardless of attack type or rumoring topic [ 16,129].\nDetection targets. Allmethods at this scope target\nanomalous patterns of (N.i) content propagation and (N.ii)\nuser interaction; these methods associate virality with the\nexistence of rumoring narratives [ 28,94,130] and tempo-\nrally anomalous activity with evidence of coordination [ 18,\n109,111]. Within non-security misinformation literature, we\nnote that virality assumptions disallow early detection of mis-\ninformation [ 131,132]. Similarly, in the security literature,\nanomalous patterns of account registration and user interac-\ntion serve as proxies for the presence of Sybils and bots [ 127,\n133]; early detection requires a priori assumptions about the\nnature of these patterns.\n1Dataset curation. We conducted an author outreach\nsurvey for works within this scope in an attempt to locate\nhard-to-\ufb01nd social media datasets. We found that (1.v) ac-\ncessibility issues were exacerbated by the shutdown of the\nTwitter API [ 134]. In total, we attempted to locate datasets\nand code for 50 papers (see Section 5for our methods). Thirty-\nsix (72%) of these analyzed tweet corpora, and 42 (84%) of\nthese are scoped to social media users and posts. We were\nable to independently source complete methods or data for\nfourteen (28%) of these. Of the 36 remaining publications\nwhose authors we contacted about providing partial or dehy-\ndrated datasets of social media content, authors of nine papers\nresponded; authors of six of those works were able to provide\nmethod code or partial datasets.\n2Model selection. The network-scoped methods we re-\nview formulate detection as 1) a structured content classi-\n\ufb01cation problem [ 114,135] or 2) a clustering problem on\nsocial graphs [ 38,136]. In the former case, authors use an\nassortment of ( 2.ii, 2.iii )supervised and unsupervised mod-\nelsto detect suspicious language across multiple accounts.\nIn the latter case, authors use (2.vi) Louvain or K-means\nclustering or K-nearest neighbors to detect neighborhoods\nof suspicious accounts, as determined by user-user interac-\ntions. Though methods in the latter category are described\nUSENIX Association 34th USENIX Security Symposium    5255\nas content-agnostic approaches, we note that published meth-\nods [ 137,138] access datasets of social media posts that were\nalready sorted by rumoring topic or event [ 139,140].\n3Feature selection. 55% of papers within this scope\nmake strong assumptions about user behaviors: In keep-\ning with an epidemiological model5of misinformation\nspread [ 143,144], for instance, [ 145] assumes a homogeneous\npopulation of newsreaders, with (3.ii) identical probabilities\nof \u201cinfection\u201d and reinfection . Similarly, in the security lit-\nerature, techniques for detecting bots and Sybils identify be-\nhaviors that align with heuristics determined a priori by re-\nsearchers: These methods assume, for instance, that Sybils\nwill form well-connected neighborhoods [ 133] or that com-\npromised Sybils will refrain from connecting with additional\nSybils, to avoid detection [ 127].\n4Evaluation. Assumptions about the prevalence of auto-\nmated accounts prevent ecologically valid evaluation at this\nscope. Ferrara et al. called attention to the false positive rate\nproblem in social bot detection in 2016, noting that classi-\n\ufb01ers for bot detection only work when there is a clear-cut\ndistinction between bot and non-bot accounts [ 146]. This dis-\ntinction is becoming increasingly blurred, however. Sophisti-\ncated network-based attacks try to engage non-bot accounts\nin organic interactions with bot accounts (e.g., astrotur\ufb01ng\nattacks) [ 18,111],(4.iv) rendering even positive detection re-\nsults insuf\ufb01cient or meaningless : coordinated activity need not\nbe inauthentic, and inauthentic activity need not be malicious.\nTakeaways :\n Pattern- and virality-based detection ap-\nproaches disallow early detection of rumors. 1Current\nsocial media data is dif\ufb01cult to obtain. 2\u201cTopic-agnostic\u201d\nclassi\ufb01er design occurs downstream of topic-aware dataset\ndesign. 3Epidemiological models of information spread\nmake strong assumptions about opinion formation and user\nbehaviors; feature sets re\ufb02ect these notions. 4Though\nnetwork-scoped methods are less susceptible to content-\nbased dependencies than are content-aware methods, they\ncannot infer intent of the behaviors they detect.\n4.6 Websites\nMethods within this scope apply credibility, factuality, or po-\nlitical bias scores to news sites, which comprise infrastructural\nand hosting elements, text contents (e.g., published articles),\nand UI elements (e.g. ad banners); authors claim that site-wide\nlabels can be used to quickly infer the quality of individual\nnews articles produced by these sites [ 129,147\u2013149]. As with\narticle-scoped methods, we noted intervention \ufb01t issues at the\nwhole website scope. Asr et al. found that source labels were\ninsuf\ufb01cient proxies for the factuality of single articles, and\nelided subject-speci\ufb01c variations in reporting quality [ 150].\n5Some authors have argued that the disease metaphor promotes an overly\nsimplistic model of information spread [ 141,142].\nDetection targets. 50% of works that we review in\nthis scope reduce the task of whole-site credibility label-\ning to a signi\ufb01cantly smaller, unimodal classi\ufb01cation task:\nChen et al. [ 149](W.i) detect suspicious domain semantics\n(in essence, a text classi\ufb01cation task on URLs); Ribeiro et\nal. [124](W.ii) infer site bias from site visitor demographics ;\nCastillo et al. [ 132](W.iii) detect suspicious site UI ; ef\ufb01cacy\nof the method of Baly et al. [ 5,148] is strongly determined\nby performance on the text classi\ufb01cation task alone (thus,\nin practice, the method closely resembles the article-scoped\ndetection methods we examine, and is susceptible to the same\ndependencies that we observe in that scope). We demonstrate\nthis via an ablation analysis in our replication study of their\nmethod (see Section 5.3).\n1Dataset curation. For both training and testing, all meth-\nods scoped to whole website detection rely on published lists\nof websites with credibility scores [ 5,129,147,148]; com-\nmon reference sites include Media Bias/Fact Check, Snopes,\nand FactCheck.org [ 151\u2013153]. As discussed in Section 4.2,\nhowever, these references do not have uniform taxonomies\nfor classifying site credibility. Additionally, pre-labeled lists\nare 1) (1.i)biased towards older, more visible real news and\nfake news outlets [152], 2) (1.iii) are restricted to speci\ufb01c\ninformation domains [5], or 3) (1.i)include inactive websites\nwithin their labeled datasets [151]. Some papers perform in-\nfrastructure analysis on contemporaneous snapshots (circa\n2019) of websites in their corpora, even though the text-based\nfeatures for the same analysis were drawn from datasets pub-\nlished in 2016 and 2017 [ 129]. This constitutes a source of\n(1.ii) temporal leakage .\n2Model selection. Four of the seven methods we re-\nviewed within this scope used ( 2.ii)SVM classi\ufb01ers ; in two\nof those cases, SVMs outperformed other, more complex un-\nsupervised models [ 129,150]. These results accord with our\nearlier observation, in Section 4.3, that SVM classi\ufb01ers are\ncomparatively performant on two-way classi\ufb01cation tasks.6\n3Feature selection. Works within this scope use\nmulti-modal feature sets comprising a mix of (3.i)textual ,\n(3.ii) network-based , and (3.iv) infrastructural signals . For\ninstance, Baly et al. [ 148] consider network traf\ufb01c, URL se-\nmantics, and site contents; and Hounsel et al. [ 147] consider\nTLS/SSL certi\ufb01cates, web hosting con\ufb01gurations, and domain\nregistrations. None of the detection methods we reviewed dis-\ncusses the computational costs of deploying their methods at\nscale. Though all works discuss their feature selection process\n(via leave-one-out and use-one-only evaluations), no works\naccount for uneven distributions in training data or shifts in\nbaseline distributions during the lifecycle of a website. Houn-\nsel et al. train their classi\ufb01er on a reference list in which\n34% of misinformation training set sites were active and all\nwebsites in the real news training set were active, possibly\n6In a reproducibility study of civil war prediction, Kapoor et al. similarly\nshow that more complex ML models do not necessarily outperform older\nlogistic regression models [ 154].\n5256    34th USENIX Security Symposium USENIX Association\nresulting in over\ufb01tting to features speci\ufb01c to inactive web-\nsites [ 147].\n4Evaluation. Methods within this scope that propose\nto perform whole-site labeling from analysis of a selection\nof news articles or infrastructural features are susceptible to\ndistributional imbalances (e.g., between news verticals repre-\nsented in an article corpus). Baly et al. train their model on\n(4.ii) political news websites only , and their credibility labels\nare strongly correlated with political bias scores. Hounsel et\nal. perform (4.i)testing in real time \u2014one of the few studies\nwe reviewed, and one of two studies at this scope, that did so\n[147,149]. Both of these works report signi\ufb01cant performance\ndropoffs between experimental and real-time tests, most likely\nas a result of distributional differences between real-world\nand experimental datasets: In practice, most websites do not\nhost news-related content at all, and website content changes\nwith the passage of time [ 147,149].\nTakeaways :\n Methods claiming to classify news sites gen-\nerally reduce this task to simpler, unimodal tasks, such as URL\nclassi\ufb01cation. 1The works we review use datasets with incom-\npatible taxonomies; many of these prepublished datasets include\ninactive older sites. 2We note that SVM classi\ufb01ers perform\nwell on two-way classi\ufb01cation tasks, and even outperform more\nsophisticated unsupervised models. 3Distributional shifts in\nbaseline distributions are largely undiscussed. 4Authors who\nconduct testing in separate real-time settings report signi\ufb01cant\nperformance dropoffs with respect to experimental results.\n5 Replication Studies\nWe attempted to replicate a representative work from each\nof our \ufb01ve information scopes; ultimately, we were unable\nto complete a network-scoped replication in light of social\nmedia data inaccessibility issues. We present replications for\nour article, user, and website scopes and present our claim-\nscoped replication in our online supplement (we chose to\npresent replications for the three most recent papers in the\nmain body of this work). We discuss our selection process\nwithin each scope in the next subsection. Our targets are\n1) (A.i) syntax-based text features; 2) ( U.ii) user behaviors;\nand 3) ( W.iv) whole site factuality. These works are highly\nrepresentative of their respective information scopes: Nasir\net al. [ 101] (Section 5.1) train a neural network on corpora\nof true and misinformative news articles; Saeed et al. [ 61]\n(Section 5.2) use published lists of trolls to infer the pres-\nence of other troll accounts on Reddit; and Baly et al. [ 5]\n(Section 5.3) examine a multimodal feature set comprising\ninfrastructure, content, and network-based features in order to\ninfer whole-site credibility. For each work, we evaluate repli-\ncability and generalizability ( RQ3,RQ4). Where possible, we\n1) replicate reported results; 2) inspect datasets for potential\ndependencies; 3) perform ablation analyses to understand\nindividual feature performance; and 4) test on current data.We are grateful to the authors who responded to our requests\nfor code and data. We emphasize that these replications are\nintended to be critiques of the work, not of the authors.\nPaper selection criteria and author outreach. We sorted\nour full text corpus by information scope. Within each scope,\nwe sorted papers in order of decreasing citation count. We\nthen proceeded as follows:\n1.We attempted to source the full methods and datasets for\nthe most cited paper within each information scope.\n2.If we were unable to \ufb01nd this information during an\nindependent web search, we reached out to the paper\u2019s\nlead author(s) to request access.\n3.If this request was unsuccessful\u2014if the author did not\nrespond, or con\ufb01rmed that the dataset or code was no\nlonger available\u2014we returned to step 1 for the next most\nhighly-cited paper in our corpus within that scope.\nReplication analyses. We reproduced results reported in\neach paper on the datasets mentioned, contacting authors\nwhen necessary to obtain datasets and code. We evaluated\nreproducibility and generalizability as follows:\n\u2022Reproducibility. We reproduce published results with\ncode and data reported in the original publication. We\nevaluate availability of code and data and, where possi-\nble, compare our analysis outcomes with those reported\nin the original paper ( RQ3).\n\u2022Explainability. Toward understanding the contributions\nof speci\ufb01c feature types to overall classi\ufb01er performance,\nand why certain approaches work, we perform feature\nablation studies when appropriate.\n\u2022Replicability and generalizability. Model performance\non novel datasets is useful for determining the generaliz-\nability of existing detection methods to different contexts\n(RQ4). For models that were explicitly tested on speci\ufb01c\nmisinformation narratives (e.g., 2020 stolen election nar-\nratives), on speci\ufb01c timeframes, or on speci\ufb01c types of\nmisinformation (e.g., parody or satire), we develop up-\ndated datasets to test method performance on diverse\ninformation domains.\n5.1 Detection of suspicious language\nWe reproduced results from a study published in 2021 by\nNasir et al [ 101]. The paper proposes a neural net-based ap-\nproach to the classi\ufb01cation of news articles . The method\nemploys a hybrid deep learning model that combines convo-\nlutional and recurrent neural networks for the classi\ufb01cation\nof real and fake news. Results are reported for tests on two\ndatasets: the ISOT dataset (44,890 news stories, equally dis-\ntributed across true and false categories, as labeled by Poli-\ntiFact) and the FA-KES dataset (804 news stories about the\nSyrian war, 426 true and 378 false) [ 155,156]. We were able\nto replicate original paper results and run the method on up-\ndated datasets of news articles. Motivated by the prevalence\nof methods trained on few- or single-source datasets in the\nUSENIX Association 34th USENIX Security Symposium    5257\nDataset Acc. ( !2) FPR ( !2) FNR ( !2)\nISOT 1.00 (0.00) 0.34 (0.22) 0.33 (0.22)\nFA-KES 0.58 (0.00) 0.50 (0.25) 0.50 (0.25)\nReuters- original 0.60 (0.02) 0.40 (0.02) \u2013\nReuters- modified 0.47 (0.02) \u2013 0.53 (0.02)\nNYTimes- original 0.49 (0.03) 0.51 (0.03) \u2013\nNYTimes- modified 0.52 (0.04) \u2013 0.48 (0.04)\nTable 1: Replication analysis of [ 101]. We tested this method\non both datasets discussed in the original paper and on novel\ndatasets from Reuters and the New York Times.\narticle scope, we test possible dependencies related to jour-\nnalistic house style, as all true articles in the ISOT dataset\nwere sourced from Reuters.\nHouse style as a confounder. To investigate house style\nas a possible confounder for misinformation detection, we\nexcerpted 100 articles from both Reuters and the New York\nTimes, two news outlets with distinctive reporting styles. We\nrandomly selected these articles from both outlets\u2019 RSS feeds\nin May 2023. We sourced articles for both corpora from the\nfollowing verticals: U.S. and world politics, economics, sci-\nence, and entertainment. Excerpt lengths ranged from 100\nto 300 words. These corpora, each comprising 100 true\nnews stories, are labeled \u201cReuters- original \u201d and \u201cNYTimes-\noriginal \u201d in Table 1. Over 30 independent trials, the clas-\nsi\ufb01er attained 0.60 average accuracy on Reuters- original\nand 0.49 average accuracy on NYTimes- original ; this dif-\nference is signi\ufb01cant ( p< 0.05 on a paired t-test).\nWe then selectively edited 50% of the news articles within\neach corpus. We changed proper nouns, negated verbs, and al-\ntered reported statistics so that the factual content of these arti-\ncles was no longer accurate but house style and tone were pre-\nserved. We call these altered text corpora \u201cReuters- modified \u201d\nand \u201cNYTimes- modified \u201d in Table 1. We found that classi\ufb01-\ncation results remained relatively consistent across original\nand modi\ufb01ed versions of both datasets. On average, 48.57\nout of 50 modi\ufb01ed NYTimes excerpts received the same clas-\nsi\ufb01cation result as their corresponding unmodi\ufb01ed excerpt\n(1.43 excerpts toggled their classi\ufb01cation labels, on average);\nsimilarly, about 49 of 50 modi\ufb01ed Reuters excerpts received\nthe same classi\ufb01cation label as their unmodi\ufb01ed counterpart\n(1.1 excerpts toggled their label, on average).\nThese results, combined with the statistically signi\ufb01cant\ndifference in performance on both original datasets noted pre-\nviously, lead us to conclude the following: 1) A news outlet\u2019s\nhouse style appears to affect classi\ufb01er sensitivity . It seems\nlikely that style signals associated with Reuters-sourced arti-\ncles in the training dataset led to signi\ufb01cant discrepancies in\nperformance on excerpts sourced from a different news outlet.\nFigure 4: Partial dependence plots for each TrollMagni\ufb01er\nfeature. Respectively, x1 = \u201ccomments on posts that trolls\ncommented on,\u201d x2 = \u201ccomments on posts that trolls started,\u201d\nx3 = \u201cdirect comment in reply to troll post,\u201d x4 = \u201cthreaded\ncomment in reply to troll comments,\u201d x5 = \u201cthreaded com-\nment in reply to troll comments on a troll post,\u201d and x6 =\n\u201csame title post as troll.\u201d\nAdditionally, 2) there was no real semantic understanding\nof news excerpt contents. Across original and modi\ufb01ed cor-\npora for each news source, the classi\ufb01er did not effectively\ndifferentiate between true and untrue news articles.\n5.2 Detection of suspicious accounts\nWe reproduce results from a study published in 2022 [ 61].\nIn summary, the authors propose a method, called TrollMag-\nni\ufb01er, for the identi\ufb01cation of Reddit accounts that exhibit\ntroll-like behaviors. Like all other account-scoped methods\nwe analyze in the security literature, TrollMagni\ufb01er is trained\non posting and reply statistics for non-troll and known Rus-\nsian troll accounts (as identi\ufb01ed by Reddit) [ 61].\nReproducibility of published results. Study authors pro-\nvided us with pre-processed datasets and classi\ufb01er code upon\nemail request. Both troll and non-troll datasets include six\nfeatures related to account-level interactions with known troll\naccounts: these include the count of posts made on threads\nstarted by trolls and the count of direct comments made in\nreply to a troll comment. The full feature list appears in Fig-\nure4. The full Reddit Pushshift dataset is freely available\nonline [ 157]. We were able to replicate original paper re-\nsults using these materials. Original account handles were\nanonymized; as such, we were unable to verify if the accounts\nidenti\ufb01ed in the original study appeared to be troll-like.\nTautological targets. As described in preceding sections\n(Section 4.4), suspicious account detection suffers from a\nlack of clear and consistent de\ufb01nitions. Troll accounts cannot\n5258    34th USENIX Security Symposium USENIX Association\nbe described by degree of automation (while some trolls are\nbot-like, many others are operated by humans) [ 111] or the\nnature of the information they spread (this might be political\nmisinformation, ads, or anything in between) [ 158]. As such,\nthe de\ufb01nition implicitly offered is that a troll is an account that\nexhibits troll-like behavior : i.e., interacts with known troll\naccounts, or appears on the same posts or threads as these\naccounts. The paper notes that this approach cannot be used\nto detect novel trolling behaviors, and requires a seed list of\nknown troll accounts for every new detection task.\nImplied versus actual data dimensionality. While the\noriginal TrollMagni\ufb01er paper suggested that the proposed\nmethod would use networked behaviors to identify troll ac-\ncounts acting in coordination online, we found that, in actu-\nality, the features under analysis lacked any sort of temporal\ncomponent and were limited in scope. There were six fea-\ntures in all (described in full in Figure 4), each corresponding\nto an aggregate engagement statistic. Longitudinal data and\ntimestamps were not available; as such, it was not possible\nto perform time series analysis. Account names were not\navailable, disallowing construction of user graphs.\nMarginal feature effects. We perform a partial depen-\ndence analysis in order to understand the effects of individual\nfeatures on overall classi\ufb01er performance. We \ufb01nd that fea-\nture x1\u2014commenting statistics\u2014was the sole feature that\nappeared to induce positive marginal change in prediction\nsuccess. All other features, considered individually, do not\nappear to have a noticeable effect on overall performance\u2014\nand, in fact, \u201csame title post as troll\u201d appears to have negative\neffects on classi\ufb01er performance. We do not perform a multi-\nfeature dependence analysis here, but note that many of these\nfeatures interact with one another. For instance, x4 and x5 are\nlikely related, as a comment made in reply to a troll comment\nreplying to a troll post (x5) is arguably also a comment made\nin reply to a troll comment (x4). As such, it is possible that\nthese interacting features might \u201cexplain away\u201d one another,\nthough we defer a more extensive analysis to future work.\n5.3 Detection of suspicious websites\nWe reproduce results from a study published in 2018 by Baly\net al [ 5]. In summary: the authors propose a multimodal ap-\nproach to the classi\ufb01cation of news websites . This method is\nparticularly representative of works within this information\nscope: 50% of works within this scope use a similar mixed-\nmodalities approach to detecting misinformation websites,\nand Baly et al. include site-speci\ufb01c feature types, including\ndomain and traf\ufb01c-based features, in their analysis. Baly et al.\nanalyzed website contents, associated social media accounts,\nand Wikipedia pages in order to perform two classi\ufb01cation\ntasks: fact and political bias classi\ufb01cation. We were able to re-\nproduce original study results and perform ablation analyses\non existing datasets. We were unable to run the method on an\nupdated dataset, as feature extraction code was not available.Reproducibility of published results. All features ex-\ntracted for the original analysis were captured in a series\nof JSON \ufb01les. While we were able to readily reproduce re-\nsults reported in the paper, certain elements of the dataset\n(e.g., follower counts on social media, and Wikipedia page\ncontents) were out of date. As we did not \ufb01nd documentation\nin the method repository for re-extraction of these features,\nwe were restricted to conducting our tests on data that were\nalready available. We binned bias labels into left,center , and\nright categories, as the seven-way taxonomy initially applied\nto the dataset by MBFC yielded small label classes. Classi\ufb01er\nperformance on the resulting three-way bias classi\ufb01cation\ntask accords with the results reported by Baly et al.\nMultimodal features: help or hindrance? We performed\nan ablation study of the method on the EMNLP18 dataset and\nanalyzed the method\u2019s bias andfact-checking classi\ufb01cation\nfunctions separately [ 5]. Speci\ufb01cally, we strati\ufb01ed the origi-\nnal EMNLP18 dataset by political leaning and credibility, as\nlabeled by MBFC, and analyzed the performance of 1) the\nfull feature set, 2) individual features and 3) ablated feature\nsets (removing one feature type per test). Our results are sum-\nmarized in Appendix D [ 13]. We \ufb01nd that, on 11 out of 12 test\ndatasets, classi\ufb01er performance using only text-based features\n(articles andwikipedia , derived from articles randomly\nsampled from the website in question, and the site\u2019s corre-\nsponding Wikipedia page, respectively) was comparable to\nperformance on the full feature set. On \ufb01ve out six datasets,\nbias classi\ufb01cation accuracy on text-only features actually out-\nperformed bias classi\ufb01cation on the whole feature set (see\nthe bottom half of Table 3 [ 13]), suggesting that the full-site\nclassi\ufb01er of Baly et al. was effectively a text content classi\ufb01er.\n6 Discussion\nWe present conclusions, discuss limitations of this work, and\npropose possible directions for future research.\n6.1 Observations\nRQ1:Fit.Very few methods that claimed to detect misin-\nformation performed semantic veri\ufb01cation: Instead, they tar-\ngeted proxy signals that were frequently steps away from\npromised detection targets. These differences were particu-\nlarly noticeable in methods that relied heavily on text- and\nnetwork-based features to perform classi\ufb01cation. In those\ncases, semantic/syntactic signatures and propagation patterns\nserved as proxies for the existence of misinformation. We\ndemonstrated, through our own replication studies, that it is\neasy to circumvent approaches that rely on style-based cues\nto perform proxy detection.\nRQ2:ML design. Lack of access to current, well-annotated\ndatasets remains a serious problem for misinformation re-\nsearch. Across existing datasets, taxonomies for classify-\ning misinformation were inconsistent. Testing on contem-\nUSENIX Association 34th USENIX Security Symposium    5259\nporaneous data was uncommon among those papers we\nannotated, and testing in real-time settings was even rarer.\nProof-of-concept experiments oftentimes did not control for\ndata dependencies. Authors describing black-box methods\u2014\nparticularly those using neural nets or other forms of unsuper-\nvised learning\u2014did not consistently disclose model weights.\nRQ3:Reproducibility. We noted widespread code and data\navailability issues: Fewer than 30% of our attempts to locate\ncode anddata, or obtain this information from authors, were\nsuccessful. The code and datasets we were able to retrieve\nwere frequently unusable or out of date. We were able to re-\nproduce and replicate results on published andcurrent data for\nonly one of our replication studies. In that case, we found that\nthe article-scoped method performed no better than random\n(0.50 accuracy) on a current, mixed-domain dataset ( 5.1).\nRQ4:Generalizability. Methods that were trained on\nsingle-source or single-domain datasets appeared to perform\nwell on data from the same source, or within the same do-\nmain; these methods, unsurprisingly, performed poorly on\nmulti-source or out-of-domain topics. These discrepancies\nare closely tied to undisclosed or uncontrolled-for data depen-\ndencies, which we discuss in RQ2.\n6.2 Limitations\nAs we completed this work, we were limited by data inacces-\nsibility and de\ufb01nitional inconsistencies across papers. As a\nresult of inaccessible or incomplete datasets, we were usu-\nally unable to generalize our replication analyses to newer\ndatasets, as authors did not always include feature extraction\ncode. We were unable to perform in-depth analysis of detec-\ntion algorithms deployed in commercial settings owing to a\nsimilar lack of data and code transparency. Finally, the use\nof different proxy targets across works led to inconsistent\ntask formulations that hindered apples-to-apples comparisons\nbetween papers in our full literature corpus.\n6.3 Recommendations for future research\nIn order to address issues of generalizability, robustness, and\ntarget formulation, we recommend that future research con-\nsider the needs of real world deployment settings, measure\nperformance drift resulting from distributional shifts, and test\nproposed detection methods in real time. We propose the\nstudy of hybrid detection as a fruitful area for future work.\nDesigning for intervention \ufb01t. All article-scoped methods\ndetect proxy targets for misinformation. Some of these proxy\ntargets, including house style and text sentiment, are easily\ncircumvented (Section 5.1).Published work should clearly\nstate the intended deployment scenarios and explain why hu-\nman annotation is infeasible or inadequate in those settings.\nPapers should clearly state and justify the detection target with\nrespect to the intended deployment scenarios. If the detection\ntarget is a proxy, papers should provide justi\ufb01cation for whythe proxy closely approximates the true target, will continue\nto closely approximate it throughout the intended deploy-\nment, and can\u2019t be evaded. Finally, papers should clearly state\nand justify the performance targets required for deployment\nscenarios. In setting these goals, papers should explain the\npotential impact of each type of correct and incorrect output.\nEvaluating dependencies and distributional shifts.\nFewer than 10% of methods within our whole corpus tested\non contemporaneous data, and fewer than 5% tested in a real-\ntime setting. To understand how an ML intervention might\nwork in practice , researchers must understand how robust\ntheir methods are to longitudinal changes in the distribution\nof available data during training versus testing. These shifts\nare particular to medium (for instance, whole site classi\ufb01ers\nare susceptible to \ufb02uctuations in news vertical coverage and\nauthor). Papers should report potential drift due to temporal\nand distributional shifts. Ideally, methods would be evaluated\non real time data. If a deployment on real time data is not\npossible, researchers might instead train a model on a sliding\nwindow of historical timestamps, t1through tn\u21911, testing on tn,\nand recording any change in performance as a result of these\ntime progressions. In supervised models, researchers can un-\nderstand the marginal effects of individual feature classes\non performance through a partial dependence analysis (see,\nfor instance, Section 5.2) or by clustering datasets based on\nknown dependencies (e.g., authorship), selecting whole clus-\nters for inclusion in training or testing data, and ensuring no\noverlap between test and train.\nUnderstanding hybrid detection. While academic mis-\ninformation detection favors fully automated methods, com-\nmercial checking services and online platforms use hybrid\nmethods. A longstanding problem in usability research con-\ncerns the role of the automated system in human-computer\ninteractions: should the ML method augment or supplant\nthe abilities of the human moderator? Further research on\nhybrid methods could address the threshold for automated\nintervention, the nature of this intervention, and how broadly\nan automated intervention should be applied. The automated\nintervention could take many forms: for instance, detection\nof misinformative posts resembling content already identi-\n\ufb01ed by human annotators, similar to Facebook\u2019s SimSearch-\nNet++ [ 159]; \u201ctriaging\u201d content by topic [ 160]; or scheduling\nmoderation tasks for human review [ 161].\nAddressing nuanced detection challenges. Many detec-\ntion methods elide subtleties that are particular to medium :\nFor instance, article-level detection methods generally apply\nbroad true/false classi\ufb01cations to a text where only single\nsentences might be slightly inaccurate. Additionally, the lan-\nguage signals that most methods detect are fairly unsubtle.\nSuggestion, insinuation, and leading questions are powerful\nrhetorical tools that might render a newsreader more suscep-\ntible to actual misinformation, or that might suggest misin-\nformative ideas using indirect means; no works within our\nliterature corpus targeted these signals, however.\n5260    34th USENIX Security Symposium USENIX Association\n7 Ethics considerations\nOur author outreach survey design was approved by the\nPrinceton University IRB; papers with freely available\ndatasets or datasets made available by their authors were\neligible to be selected for replication. All statistics published\nfrom those communications are in aggregate, with no personal\nidenti\ufb01ers attached to individual author responses. Datasets\nused for this work were already publicly available or were\nobtained with permission from study authors.\n8 Open science\nCode and data used for our replication analyses, as well as our\nfull paper corpus, reference list, and appendices, are included\nin our online supplement (available at http://doi.org/10.\n5281/zenodo.15613696 ).\nAcknowledgments\nThe authors would like to thank Anne Kohlbrenner for\nassisting with paper coding; Ben Kaiser and Sarah Schef\ufb02er\nfor productive conversations, and for reviewing multiple\ndrafts of this manuscript; and Mona Wang for retrieving data\nused for a replication study.\nReferences\n[1] Prateek Dewan and Ponnurangam Kumaraguru. \u201cTowards\nautomatic real time identi\ufb01cation of malicious posts on\nFacebook\u201d. In: 2015 13th Annual Conference on Privacy,\nSecurity and Trust (PST) . IEEE. 2015, pp. 85\u201392.\n[2] Firoj Alam et al. \u201cA Survey on Multimodal Disinformation\nDetection\u201d. en. In: arXiv:2103.12541 [cs] (Mar. 2021).\n[3] Darko Androcec. \u201cMachine learning methods for toxic com-\nment classi\ufb01cation: a systematic review\u201d. In: Acta Univer-\nsitatis Sapientiae, Informatica 12.2 (2020), pp. 205\u2013216.\n[4] Hee-Eun Lee et al. \u201cDetecting child sexual abuse material:\nA comprehensive survey\u201d. In: Forensic Science Interna-\ntional: Digital Investigation 34 (2020), p. 301022.\n[5] Ramy Baly et al. \u201cPredicting Factuality of Reporting and\nBias of News Media Sources\u201d. In: EMNLP 2018 (2018),\npp. 3528\u20133539.\n[6] Numa Dhamani et al. \u201cUsing Deep Networks and\nTransfer Learning to Address Disinformation\u201d. en. In:\narXiv:1905.10412 [cs] (May 2019).\n[7] Yoel Roth. Generalizing scaled misinformation detection .\n2023.\n[8] Ina Fried. \u201cOpenAI touts GPT-4 for content moderation\u201d.\nIn: (2023).[9] Daniel Arp et al. \u201cDos and Don\u2019ts of Machine Learning in\nComputer Security\u201d. In: 31st USENIX Security Symposium\n(USENIX Security 22) . Boston, MA: USENIX Association,\nAug. 2022, pp. 3971\u20133988. ISBN : 978-1-939133-31-1.\n[10] A. S. Jacobs et al. \u201cAI/ML and Network Security: The\nEmperor has no Clothes\u201d. In: CCS \u201922. Los Angeles, CA,\nUSA: Association for Computing Machinery, 2022.\n[11] Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fair-\nness and machine learning: Limitations and opportunities .\nMIT press, 2023.\n[12] Stephanie Chan et al. \u201cMachine learning in dermatology:\ncurrent applications, opportunities, and limitations\u201d. In:\nDermatology and therapy 10 (2020), pp. 365\u2013386.\n[13] Madelyne Xiao. Online Supplement .URL:http://doi.\norg/10.5281/zenodo.15613696 .\n[14] Tomas Apodaca and Natasha Uzc\u00e1tegui-Liggett. \u201cHow\nAutomated Content Moderation Works (Even When It\nDoesn\u2019t)\u201d. In: The Markup (2024).\n[15] Rosalie Gillett, Joanne E Gray, and D Bondy Valdovinos\nKaye. \u201c\u2018Just a little hack\u2019: Investigating cultures of content\nmoderation circumvention by Facebook users\u201d. In: New\nMedia & Society 26.11 (2024), pp. 6183\u20136204.\n[16] Sadegh M Milajerdi et al. \u201cHolmes: real-time APT detec-\ntion through correlation of suspicious information \ufb02ows\u201d.\nIn:2019 IEEE Symposium on Security and Privacy (SP) .\nIEEE. 2019, pp. 1137\u20131152.\n[17] Samuel T King and Peter M Chen. \u201cSubVirt: Implementing\nmalware with virtual machines\u201d. In: 2006 IEEE Symposium\non Security and Privacy (S&P\u201906) . IEEE. 2006, 14\u2013pp.\n[18] Brett Stone-Gross et al. \u201cYour botnet is my botnet: analysis\nof a botnet takeover\u201d. In: ACM CCS . 2009, pp. 635\u2013647.\n[19] Shujaat Mirza et al. \u201cTactics, threats & targets: Modeling\ndisinformation and its mitigation\u201d. In: NDSS 2023 . 2023.\n[20] Liang Wu et al. \u201cMisinformation in Social Media: De\ufb01ni-\ntion, Manipulation, and Detection\u201d. en. In: ACM SIGKDD\nExplorations Newsletter 21.2 (Nov. 2019), pp. 80\u201390. ISSN:\n1931-0145, 1931-0153.\n[21] Axel Gelfert. \u201cFake News: A De\ufb01nition\u201d. en. In: Infor-\nmal Logic 38.1 (Mar. 2018), pp. 84\u2013117. ISSN: 0824-2577,\n0824-2577.\n[22] Leonie Haiden and Jente Althuis. \u201cThe De\ufb01nitional Chal-\nlenges of Fake News\u201d. In: SBP-BRiMS 18 . June 2018.\n[23] David Klein and Joshua Wueller. Fake News: A Legal Per-\nspective . en. SSRN Scholarly Paper ID 2958790. Rochester,\nNY: Social Science Research Network, Mar. 2017.\n[24] Edson C. Tandoc, Zheng Wei Lim, and Richard Ling.\n\u201cDe\ufb01ning \u201cFake News\u201d: A typology of scholarly de\ufb01ni-\ntions\u201d. en. In: Digital Journalism 6.2 (Feb. 2018), pp. 137\u2013\n153. ISSN: 2167-0811, 2167-082X.\n[25] Joshua Habgood-Coote. \u201c\u201cThe term \u201cfake news\u201d is doing\ngreat harm\u201d\u201d. In: The Conversation (July 2018).\n[26] Jasper Jackson. \u201cWhat are in\ufb02uence operations and why\nare we investigating them?\u201d In: The Bureau of Investigative\nJournalism (July 2023).\nUSENIX Association 34th USENIX Security Symposium    5261\n[27] Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad\nZargari. \u201cSentiment Aware Fake News Detection on Online\nSocial Networks\u201d. In: ICASSP . ISSN: 2379-190X. May\n2019, pp. 2507\u20132511.\n[28] Marcella Tambuscio et al. \u201cFact-checking Effect on Vi-\nral Hoaxes: A Model of Misinformation Spread in Social\nNetworks\u201d. In: WebConf . WWW \u201915 Companion. New\nYork, NY, USA: Association for Computing Machinery,\nMay 2015, pp. 977\u2013982. ISBN : 978-1-4503-3473-0.\n[29] Sille Obelitz S\u00f8e. \u201cAlgorithmic detection of misinformation\nand disinformation: Gricean perspectives\u201d. In: Journal of\nDocumentation 74.2 (2017), pp. 309\u2013332.\n[30] Aldert Vrij. Detecting lies and deceit: Pitfalls and opportu-\nnities . John Wiley & Sons, 2008.\n[31] Barbara G Amado, Ram\u00f3n Arce, and Francisca Fari\u00f1a. \u201cUn-\ndeutsch hypothesis and Criteria Based Content Analysis: A\nmeta-analytic review\u201d. In: The European Journal of Psy-\nchology Applied to Legal Context 7.1 (2015), pp. 3\u201312.\n[32] Carlos Carrasco-Farr\u00e9. \u201cThe \ufb01ngerprints of misinformation:\nhow deceptive content differs from reliable sources in terms\nof cognitive effort and appeal to emotions\u201d. In: Humanities\nand Social Sciences Communications 9.1 (2022), pp. 1\u201318.\n[33] Junaed Younus Khan et al. \u201cA benchmark study of machine\nlearning models for online fake news detection\u201d. en. In: Ma-\nchine Learning with Applications 4 (June 2021), p. 100032.\nISSN: 2666-8270.\n[34] Don Fallis. \u201cA Functional Analysis of Disinformation\u201d.\nIn:iConference 2014 Proceedings (Mar. 2014). Publisher:\niSchools.\n[35] Xinyi Zhou and Reza Zafarani. \u201cA Survey of Fake News:\nFundamental Theories, Detection Methods, and Opportu-\nnities\u201d. In: ACM Computing Surveys 53.5 (Sept. 2020),\n109:1\u2013109:40. ISSN: 0360-0300.\n[36] Ray Oshikawa, Jing Qian, and William Yang Wang. \u201cA\nSurvey on Natural Language Processing for Fake News\nDetection\u201d. In: arXiv:1811.00770 [cs] (Nov. 2018).\n[37] Nadia K. Conroy, Victoria L. Rubin, and Yimin Chen.\n\u201cAutomatic deception detection: Methods for \ufb01nding fake\nnews\u201d. en. In: Proceedings of the Association for Informa-\ntion Science and Technology 52.1 (2015), pp. 1\u20134. ISSN :\n2373-9231.\n[38] Karishma Sharma et al. \u201cCombating Fake News: A Survey\non Identi\ufb01cation and Mitigation Techniques\u201d. In: ACM\nTransactions on Intelligent Systems and Technology 10.3\n(Apr. 2019), 21:1\u201321:42. ISSN: 2157-6904.\n[39] Md Ra\ufb01qul Islam et al. \u201cDeep learning for misinformation\ndetection on online social networks: a survey and new per-\nspectives\u201d. en. In: Social Network Analysis and Mining 10.1\n(Sept. 2020), p. 82. ISSN: 1869-5469.\n[40] Alim Al Ayub Ahmed et al. \u201cDetecting Fake News using\nMachine Learning: A Systematic Literature Review\u201d. In:\nPsychology (Savannah, Ga.) 58 (Jan. 2021), pp. 1932\u20131939.\n[41] Kai Shu et al. \u201cFake News Detection on Social Media: A\nData Mining Perspective\u201d. en. In: ACM SIGKDD Explo-\nrations Newsletter (2017), p. 15.[42] Ammara Habib et al. \u201cFalse information detection in online\ncontent and its role in decision making: a systematic litera-\nture review\u201d. en. In: Social Network Analysis and Mining\n9.1 (Sept. 2019), p. 50. ISSN: 1869-5469.\n[43] Jiawei Zhang et al. \u201cFake News Detection with Deep Dif-\nfusive Network Model\u201d. In: arXiv:1805.08751 [cs, stat]\n(May 2018).\n[44] Nicollas R. de Oliveira et al. \u201cIdentifying Fake News on\nSocial Networks Based on Natural Language Processing:\nTrends and Challenges\u201d. en. In: Information 12.1 (Jan.\n2021). Number: 1 Publisher: Multidisciplinary Digital Pub-\nlishing Institute, p. 38. ISSN: 2078-2489.\n[45] Kai Shu et al. \u201cMining Disinformation and Fake News:\nConcepts, Methods, and Recent Advancements\u201d. en. In:\nDisinformation, Misinformation, and Fake News in Social\nMedia: Emerging Research Challenges and Opportunities .\nEd. by Kai Shu et al. Lecture Notes in Social Networks.\nCham: Springer International Publishing, 2020, pp. 1\u201319.\nISBN : 978-3-030-42699-6.\n[46] Fernando Mir\u00f3-Llinares and Jes\u00fas C. Aguerri. \u201cMisinfor-\nmation about fake news: A systematic critical review of\nempirical studies on the phenomenon and its status as a\n\u2018threat\u2019\u201d. en. In: European Journal of Criminology (Apr.\n2021), p. 1477370821994059. ISSN: 1477-3708.\n[47] Yimin Chen, Nadia K. Conroy, and Victoria L. Rubin.\n\u201cNews in an online world: The need for an \u201cautomatic crap\ndetector\u201d\u201d. en. In: Proceedings of the Association for Infor-\nmation Science and Technology 52.1 (2015), pp. 1\u20134. ISSN:\n2373-9231.\n[48] Miriam Fernandez and Harith Alani. \u201cOnline Misinforma-\ntion: Challenges and Future Directions\u201d. en. In: Companion\nof the The Web Conference 2018 on The Web Conference\n2018 - WWW \u201918 . Lyon, France: ACM Press, 2018, pp. 595\u2013\n602. ISBN : 978-1-4503-5640-4.\n[49] Diego A Martin, Jacob N Shapiro, and Michelle\nNedashkovskaya. \u201cRecent Trends in Online Foreign In-\n\ufb02uence Efforts\u201d. en. In: Journal of Information Warfare\n(2019), p. 34.\n[50] Sushila Shelke and Vahida Attar. \u201cSource detection of ru-\nmor in social network \u2013 A review\u201d. en. In: Online Social\nNetworks and Media 9 (Jan. 2019), pp. 30\u201342. ISSN: 2468-\n6964.\n[51] Bin Guo et al. The Future of Misinformation Detection:\nNew Perspectives and Trends . arXiv:1909.03654 [cs]. Sept.\n2019.\n[52] James Thorne and Andreas Vlachos. \u201cAutomated Fact\nChecking: Task Formulations, Methods and Future Direc-\ntions\u201d. en. In: Proceedings of the 27th International Con-\nference on Computational Linguistics . Santa Fe, NM, USA,\nAug. 2018, pp. 3346\u20133359.\n[53] Arkaitz Zubiaga et al. \u201cAnalysing How People Orient to\nand Spread Rumours in Social Media by Looking at Con-\nversational Threads\u201d. en. In: PLOS ONE 11.3 (Mar. 2016).\nPublisher: Public Library of Science, e0150989. ISSN: 1932-\n6203.\n5262    34th USENIX Security Symposium USENIX Association\n[54] Victoria L. Rubin, Yimin Chen, and Nadia K. Conroy. \u201cDe-\nception detection for news: Three types of fakes\u201d. en. In:\nProceedings of the Association for Information Science and\nTechnology 52.1 (2015), pp. 1\u20134. ISSN: 2373-9231.\n[55] L Padgham et al. \u201cCORE Rankings. \u201d DOI:https://www.\ncore.edu.au/conference-portal .\n[56] Steve Mollman. OpenAI is getting trolled for its name after\nrefusing to be open about its A.I. Mar. 2023.\n[57] Matteo Wong. \u201cThere was never such a thing as \u201cOpen\u201d\nAI\u201d. In: The Atlantic (Jan. 2024).\n[58] Miranda Wei et al. \u201c\u2018SoK (or SoLK?): On the Quantitative\nStudy of Sociodemographic Factors and Computer Security\nBehaviors\u2019\u201d. In: USENIX Security (2024).\n[59] Sarah Schef\ufb02er and Jonathan Mayer. \u201cSoK: Content Mod-\neration for End-to-End Encryption\u201d. In: Proceedings on\nPrivacy Enhancing Technologies (2023).\n[60] Noel Warford et al. \u201cSoK: A Framework for Unifying At-\nRisk User Research\u201d. In: IEEE S&P (2021).\n[61] Mohammad Hammas Saeed et al. \u201cTrollmagni\ufb01er: Detect-\ning state-sponsored troll accounts on reddit\u201d. In: 2022 IEEE\nSymposium on Security and Privacy (SP) . IEEE. 2022,\npp. 2161\u20132175.\n[62] Amar Debnath et al. \u201cA Hierarchical Learning Model for\nClaim Validation\u201d. en. In: Conference on Computational\nIntelligence . Ed. by Mohammad Shorif Uddin and Jagdish\nChand Bansal. Algorithms for Intelligent Systems. Springer\nSingapore, 2020, pp. 431\u2013441. ISBN : 9789811375644.\n[63] Naeemul Hassan et al. \u201cData in, fact out: automated mon-\nitoring of facts by FactWatcher\u201d. In: Proceedings of the\nVLDB Endowment 7.13 (Aug. 2014), pp. 1557\u20131560. ISSN:\n2150-8097.\n[64] Dimitrios Katsaros, George Stavropoulos, and Dimitrios\nPapakostas. \u201cWhich machine learning paradigm for fake\nnews detection?\u201d In: International Conference on Web In-\ntelligence (WI) . Oct. 2019, pp. 383\u2013387.\n[65] Ziyi Kou et al. \u201cHC-COVID: A Hierarchical Crowdsource\nKnowledge Graph Approach to Explainable COVID-19\nMisinformation Detection\u201d. In: Proceedings of the ACM\non Human-Computer Interaction 6.GROUP (Jan. 2022),\n36:1\u201336:25.\n[66] Kevin Roitero et al. \u201cCan the Crowd Judge Truthfulness?\nA Longitudinal Study on Recent Misinformation about\nCOVID-19\u201d. en. In: arXiv:2107.11755 [cs] (July 2021).\n[67] Max Glockner, Yufang Hou, and Iryna Gurevych. Missing\nCounter-Evidence Renders NLP Fact-Checking Unrealistic\nfor Misinformation . arXiv:2210.13865 [cs]. Oct. 2022.\n[68] Yavuz Selim Kartal, Busra Guvenen, and Mucahid Kutlu.\n\u201cToo Many Claims to Fact-Check: Prioritizing Po-\nlitical Claims Based on Check-Worthiness\u201d. en. In:\narXiv:2004.08166 [cs] (Apr. 2020).\n[69] Ciampaglia GL et al. \u201cComputational Fact Checking from\nKnowledge Networks\u201d. In: PLoS ONE 10.6 (June 2015).[70] Tanik Saikh et al. \u201cA Novel Approach Towards Fake News\nDetection: Deep Learning Augmented with Textual Entail-\nment Features\u201d. en. In: Natural Language Processing and\nInformation Systems . Ed. by Elisabeth M\u00e9tais et al. Lecture\nNotes in Computer Science. Springer International Publish-\ning, 2019, pp. 345\u2013358. ISBN : 978-3-030-23281-8.\n[71] Lu\u00eds Borges, Bruno Martins, and P\u00e1vel Calado. \u201cCombining\nSimilarity Features and Deep Representation Learning for\nStance Detection in the Context of Checking Fake News\u201d.\nIn:arXiv:1811.00706 [cs, stat] (Nov. 2018).\n[72] Prashant Shiralkar et al. \u201cFinding Streams in Knowledge\nGraphs to Support Fact Checking\u201d. In: ICDM (Nov. 2017),\npp. 859\u2013864.\n[73] Shrutika S. Jadhav and Sudeep D. Thepade. \u201cFake\nNews Identi\ufb01cation and Classi\ufb01cation Using DSSM\nand Improved Recurrent Neural Network Classi-\n\ufb01er\u201d. In: Applied Arti\ufb01cial Intelligence 33.12\n(Oct. 2019). Publisher: Taylor & Francis _eprint:\nhttps://doi.org/10.1080/08839514.2019.1661579, pp. 1058\u2013\n1068. ISSN: 0883-9514.\n[74] Tayyaba Rasool et al. \u201cMulti-Label Fake News Detection\nusing Multi-layered Supervised Learning\u201d. In: Proceedings\nof the 2019 11th International Conference on Computer\nand Automation Engineering . ICCAE 2019. New York, NY ,\nUSA: Association for Computing Machinery, Feb. 2019,\npp. 73\u201377. ISBN : 978-1-4503-6287-0.\n[75] Lin Tian et al. \u201cEarly Detection of Rumours on Twitter\nvia Stance Transfer Learning\u201d. en. In: Advances in Infor-\nmation Retrieval . Ed. by Joemon M. Jose et al. Lecture\nNotes in Computer Science. Cham: Springer International\nPublishing, 2020, pp. 575\u2013588. ISBN : 978-3-030-45439-5.\n[76] William Yang Wang. \u201c\"Liar, Liar Pants on Fire\": A New\nBenchmark Dataset for Fake News Detection\u201d. en. In: Pro-\nceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 2: Short Papers) . Van-\ncouver, Canada: Association for Computational Linguistics,\n2017, pp. 422\u2013426.\n[77] PolitiFact .URL:https://www.politifact.com/ .\n[78] Yangqian Wang et al. \u201cLearning Contextual Features with\nMulti-head Self-attention for Fake News Detection\u201d. en.\nIn:Cognitive Computing \u2013 ICCC 2019 . Ed. by Ruifeng\nXu, Jianzong Wang, and Liang-Jie Zhang. Lecture Notes in\nComputer Science. Springer International Publishing, 2019,\npp. 132\u2013142. ISBN : 978-3-030-23407-2.\n[79] Michael Soprano et al. \u201cThe Many Dimensions of Truth-\nfulness: Crowdsourcing Misinformation Assessments on\na Multidimensional Scale\u201d. en. In: arXiv:2108.01222 [cs]\n(Aug. 2021).\n[80] Bhavika Bhutani et al. \u201cFake News Detection Using Senti-\nment Analysis\u201d. In: 2019 Twelfth International Conference\non Contemporary Computing (IC3) . ISSN: 2572-6129. Aug.\n2019, pp. 1\u20135.\nUSENIX Association 34th USENIX Security Symposium    5263\n[81] Kai Shu et al. \u201cdEFEND: Explainable Fake News Detec-\ntion\u201d. In: Proceedings of the 25th ACM SIGKDD Interna-\ntional Conference on Knowledge Discovery & Data Mining .\nKDD \u201919. New York, NY, USA: Association for Comput-\ning Machinery, July 2019, pp. 395\u2013405. ISBN : 978-1-4503-\n6201-6.\n[82] Simone Leonardi, Giuseppe Rizzo, and Maurizio Mori-\nsio. \u201c\u2018Automated Classi\ufb01cation of Fake News Spreaders to\nBreak the Misinformation Chain\u2019\u201d. In: Information (2021).\n[83] Iftikhar Ahmad et al. \u201cFake News Detection Using Machine\nLearning Ensemble Methods\u201d. en. In: Complexity 2020\n(Oct. 2020). Publisher: Hindawi, e8885861. ISSN : 1076-\n2787.\n[84] Amr Magdy and Nayer Wanas. \u201cWeb-Based Statistical Fact\nChecking of Textual Documents\u201d. In: Proceedings of the\n2nd International Workshop on Search and Mining User-\nGenerated Contents . SMUC \u201910. Toronto, ON, Canada:\nAssociation for Computing Machinery, 2010, pp. 103\u2013110.\nISBN : 9781450303866.\n[85] Pujan Paudel et al. \u201c\u2018LAMBRETTA: Learning to Rank for\nTwitter Soft Moderation\u2019\u201d. In: IEEE Security & Privacy\n(2023).\n[86] Aditi Gupta et al. TweetCred: Real-Time Credibility Assess-\nment of Content on Twitter . arXiv:1405.5490 [physics]. Jan.\n2015.\n[87] Limeng Cui, Suhang Wang, and Dongwon Lee. \u201cSAME:\nSentiment-Aware Multi-Modal Embedding for Detecting\nFake News\u201d. In: 2019 IEEE/ACM International Confer-\nence on Advances in Social Networks Analysis and Mining\n(ASONAM) . ISSN: 2473-991X. Aug. 2019, pp. 41\u201348.\n[88] Naeemul Hassan et al. \u201cToward Automated Fact-Checking:\nDetecting Check-worthy Factual Claims by ClaimBuster\u201d.\nen. In: Proceedings of the 23rd ACM SIGKDD Interna-\ntional Conference on Knowledge Discovery and Data Min-\ning - KDD \u201917 . Halifax, NS, Canada: ACM Press, 2017,\npp. 1803\u20131812. ISBN : 978-1-4503-4887-4.\n[89] James Fairbanks et al. \u201cCredibility assessment in the news:\ndo we need to read\u201d. In: Proc. of the MIS2 Workshop held\nin conjuction with 11th Int\u2019l Conf. on Web Search and Data\nMining . ACM. 2018, pp. 799\u2013800.\n[90] Martin Potthast et al. \u201cA Stylometric Inquiry into Hyperpar-\ntisan and Fake News\u201d. In: Proceedings of the 56th Annual\nMeeting of the Association for Computational Linguistics\n(Volume 1: Long Papers) . Melbourne, Australia: Associ-\nation for Computational Linguistics, July 2018, pp. 231\u2013\n240.\n[91] Benjamin D. Horne and Sibel Adali. \u201cThis Just In: Fake\nNews Packs a Lot in Title, Uses Simpler, Repetitive Content\nin Text Body, More Similar to Satire than Real News\u201d. In:\nAAAI CWSM\u201917 . Mar. 2017.\n[92] Rada Mihalcea and Carlo Strapparava. \u201cThe Lie Detector:\nExplorations in the Automatic Recognition of Deceptive\nLanguage\u201d. In: Proceedings of the ACL-IJCNLP 2009 Con-\nference Short Papers . Suntec, Singapore: Association for\nComputational Linguistics, Aug. 2009, pp. 309\u2013312.[93] Adrian M. P. Bra\u00b8 soveanu and R \u02d8azvan Andonie. \u201cSemantic\nFake News Detection: A Machine Learning Perspective\u201d.\nen. In: Advances in Computational Intelligence . Ed. by\nIgnacio Rojas, Gonzalo Joya, and Andreu Catala. Lecture\nNotes in Computer Science. Springer International Publish-\ning, 2019, pp. 656\u2013667. ISBN : 978-3-030-20521-8.\n[94] Kai Shu, Suhang Wang, and Huan Liu. \u201cBeyond News\nContents: The Role of Social Context for Fake News Detec-\ntion\u201d. en. In: Proceedings of the Twelfth ACM International\nConference on Web Search and Data Mining - WSDM \u201919 .\nMelbourne VIC, Australia: ACM Press, 2019, pp. 312\u2013320.\nISBN : 978-1-4503-5940-5.\n[95] Ver\u00f3nica P\u00e9rez-Rosas et al. \u201cAutomatic Detection of Fake\nNews\u201d. In: arXiv:1708.07104 [cs] (Aug. 2017).\n[96] Rada Mihalcea and Carlo Strapparava. \u201cThe lie detector:\nexplorations in the automatic recognition of deceptive lan-\nguage\u201d. en. In: Proceedings of the ACL-IJCNLP 2009 Con-\nference Short Papers on - ACL-IJCNLP \u201909 . Suntec, Sin-\ngapore: Association for Computational Linguistics, 2009,\np. 309.\n[97] Victoria Rubin et al. \u201cFake News or Truth? Using Satirical\nCues to Detect Potentially Misleading News\u201d. In: Proceed-\nings of the Second Workshop on Computational Approaches\nto Deception Detection . San Diego, California: Association\nfor Computational Linguistics, June 2016, pp. 7\u201317.\n[98] Hadeer Ahmed, Issa Traore, and Sherif Saad. \u201cDetecting\nopinion spams and fake news using text classi\ufb01cation\u201d. en.\nIn:SECURITY AND PRIVACY 1.1 (2018), e9. ISSN: 2475-\n6725.\n[99] Natali Ruchansky, Sungyong Seo, and Yan Liu. \u201cCSI: A\nHybrid Deep Model for Fake News Detection\u201d. In: Pro-\nceedings of the 2017 ACM on Conference on Information\nand Knowledge Management . CIKM \u201917. New York, NY,\nUSA: ACM, 2017, pp. 797\u2013806. ISBN : 978-1-4503-4918-5.\n[100] Sadia Afroz, Michael Brennan, and Rachel Greenstadt. \u201cDe-\ntecting Hoaxes, Frauds, and Deception in Writing Style On-\nline\u201d. In: 2012 IEEE Symposium on Security and Privacy .\nISSN: 2375-1207. May 2012, pp. 461\u2013475.\n[101] Jamal Abdul Nasir, Osama Subhani Khan, and Iraklis Var-\nlamis. \u201cFake news detection: A hybrid CNN-RNN based\ndeep learning approach\u201d. en. In: International Journal of\nInformation Management Data Insights 1.1 (Apr. 2021),\np. 100007. ISSN: 2667-0968.\n[102] Kate Starbird et al. \u201cRumors, False Flags, and Digital Vig-\nilantes: Misinformation on Twitter after the 2013 Boston\nMarathon Bombing\u201d. en. In: iConference 2014 Proceedings .\niSchools, Mar. 2014. ISBN : 978-0-9884900-1-7.\n[103] Zhiwei Jin et al. \u201cDetection and Analysis of 2016 US Presi-\ndential Election Related Rumors on Twitter\u201d. en. In: Social,\nCultural, and Behavioral Modeling . Ed. by Dongwon Lee\net al. Lecture Notes in Computer Science. Cham: Springer\nInternational Publishing, 2017, pp. 14\u201324. ISBN : 978-3-319-\n60240-0.\n[104] Kai Shu et al. \u201cDetecting fake news with weak social super-\nvision\u201d. In: IEEE Intelligent Systems 36.4 (2020), pp. 96\u2013\n103.\n5264    34th USENIX Security Symposium USENIX Association\n[105] Chaowei Zhang et al. \u201cDetecting Fake News for Reducing\nMisinformation Risks Using Analytics Approaches\u201d. In:\nEuropean Journal of Operational Research (June 2019).\nISSN: 0377-2217.\n[106] Amila Silva et al. \u201cEmbracing Domain Differences in Fake\nNews: Cross-domain Fake News Detection using Multi-\nmodal Data\u201d. en. In: arXiv:2102.06314 [cs] (Feb. 2021).\n[107] Fatima Ezzeddine et al. \u201cExposing in\ufb02uence campaigns\nin the age of LLMs: a behavioral-based AI approach to\ndetecting state-sponsored trolls\u201d. In: EPJ Data Science 12.1\n(2023), p. 46.\n[108] Savvas Zannettou et al. \u201cDisinformation warfare: Under-\nstanding state-sponsored trolls on Twitter and their in\ufb02u-\nence on the web\u201d. In: Companion proceedings of the 2019\nworld wide web conference . 2019, pp. 218\u2013226.\n[109] Josephine Lukito. \u201cCoordinating a multi-platform disin-\nformation campaign: Internet Research Agency Activity\non three US Social Media Platforms, 2015 to 2017\u201d. In:\nPolitical Communication 37.2 (2020), pp. 238\u2013255.\n[110] Franziska B Keller et al. \u201cPolitical astrotur\ufb01ng on twitter:\nHow to coordinate a disinformation campaign\u201d. In: Political\ncommunication 37.2 (2020), pp. 256\u2013280.\n[111] Stefano Cresci. \u201cA Decade of Social Bot Detection\u201d. In:\nCommun. ACM 63.10 (Sept. 2020), pp. 72\u201383. ISSN: 0001-\n0782.\n[112] Zi Chu et al. \u201cDetecting automation of twitter accounts: Are\nyou a human, bot, or cyborg?\u201d In: IEEE Transactions on\ndependable and secure computing 9.6 (2012), pp. 811\u2013824.\n[113] Jinxue Zhang et al. \u201cThe rise of social botnets: Attacks and\ncountermeasures\u201d. In: IEEE Transactions on Dependable\nand Secure Computing 15.6 (2016), pp. 1068\u20131082.\n[114] M. Alizadeh et al. \u201cContent-based features predict social\nmedia in\ufb02uence operations\u201d. In: Science Advances (July\n2020).\n[115] Craig Silverman et al. \u201cFacebook groups topped 10,000\ndaily attacks on election before Jan. 6, analysis shows\u201d. In:\nThe Washington Post (Jan. 2022).\n[116] Darren L Linvill and Patrick L Warren. \u201cTroll factories:\nManufacturing specialized disinformation on Twitter\u201d. In:\nPolitical Communication 37.4 (2020), pp. 447\u2013467.\n[117] Exhibit B .URL:https://democrats- intelligence.\nhouse.gov/uploadedfiles/exhibit_b.pdf .\n[118] Gang Wang et al. \u201cMan vs. machine: Practical adversarial\ndetection of malicious crowdsourcing workers\u201d. In: 23rd\nUSENIX Security Symposium (USENIX Security 14) . 2014,\npp. 239\u2013254.\n[119] Huiling Zhang et al. \u201cMisinformation in Online Social Net-\nworks: Detect Them All with a Limited Budget\u201d. In: ACM\nTransactions on Information Systems 34.3 (Apr. 2016),\n18:1\u201318:24. ISSN: 1046-8188.\n[120] Qiang Cao et al. \u201c\u2018Aiding the detection of fake accounts\nin large scale social online services\u2019\u201d. In: USENIX NSDI\n(2012).[121] Stefan Helmstetter and Heiko Paulheim. \u201cWeakly Super-\nvised Learning for Fake News Detection on Twitter\u201d. In:\nIEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM) (Aug. 2018).\n[122] Giuseppe Sansonetti et al. \u201c\u2018Unreliable Users Detection in\nSocial Media: Deep Learning Techniques for Automatic\nDetection\u2019\u201d. In: IEEE Access (2020).\n[123] Diogo Pacheco et al. \u201cUncovering Coordinated Networks\non Social Media\u201d. en. In: arXiv:2001.05658 [physics] (Jan.\n2020).\n[124] Filipe Ribeiro et al. \u201cMedia Bias Monitor: Quantifying\nBiases of Social Media News Outlets at Large-Scale\u201d. en.\nIn:Proceedings of the International AAAI Conference on\nWeb and Social Media 12.1 (June 2018). Number: 1. ISSN:\n2334-0770.\n[125] Deen Freelon et al. \u201cBlack Trolls Matter: Racial and Ide-\nological Asymmetries in Social Media Disinformation\u201d.\nen. In: Social Science Computer Review (Apr. 2020),\np. 0894439320914853. ISSN: 0894-4393.\n[126] Aseel Addawood et al. \u201cLinguistic Cues to Deception: Iden-\ntifying Political Trolls on Social Media\u201d. en. In: Proceed-\nings of the Thirteenth International AAAI Conference on\nWeb and Social Media . 2019, p. 11.\n[127] George Danezis and Prateek Mittal. \u201cSybilinfer: Detecting\nsybil nodes using social networks.\u201d In: NDSS . San Diego,\nCA. 2009, pp. 1\u201315.\n[128] Christian Grimme, Dennis Assenmacher, and Lena Adam.\n\u201cChanging perspectives: Is it suf\ufb01cient to detect social bots?\u201d\nIn:Social Computing and Social Media. User Experience\nand Behavior: 10th International Conference, SCSM 2018,\nHeld as Part of HCI International 2018, Las Vegas, NV,\nUSA, July 15-20, 2018, Proceedings, Part I 10 . Springer.\n2018, pp. 445\u2013461.\n[129] Sonia Castelo et al. A Topic-Agnostic Approach for Identi-\nfying Fake News Pages . San Francisco, USA, 2019.\n[130] Soroush V osoughi, Deb Roy, and Sinan Aral. \u201cThe spread\nof true and false news online\u201d. In: Science 359.6380 (Mar.\n2018), pp. 1146\u20131151.\n[131] Federico Monti et al. Fake News Detection on Social Me-\ndia using Geometric Deep Learning . 2019. arXiv: 1902.\n06673 .\n[132] Carlos Castillo, Marcelo Mendoza, and Barbara Poblete.\n\u201cInformation credibility on twitter\u201d. In: Proceedings of the\n20th international conference on World wide web . WWW\n\u201911. New York, NY , USA: Association for Computing Ma-\nchinery, Mar. 2011, pp. 675\u2013684. ISBN : 978-1-4503-0632-\n4.\n[133] Dong Yuan et al. \u201cDetecting fake accounts in online so-\ncial networks at the time of registrations\u201d. In: Proceedings\nof the 2019 ACM SIGSAC conference on computer and\ncommunications security . 2019, pp. 1423\u20131438.\n[134] Developer policy \u2013 twitter developers | twitter developer\nplatform .URL:https://developer.twitter.com/en/\ndeveloper-terms/policy#4-e .\nUSENIX Association 34th USENIX Security Symposium    5265\n[135] Jacob Ratkiewicz et al. \u201cDetecting and tracking political\nabuse in social media\u201d. In: Proceedings of the International\nAAAI Conference on Web and social media . V ol. 5. 1. 2011,\npp. 297\u2013304.\n[136] Dennis Assenmacher et al. \u201cA two-phase framework for\ndetecting manipulation campaigns in social media\u201d. In: So-\ncial Computing and Social Media. Design, Ethics, User\nBehavior, and Social Network Analysis: 12th International\nConference, SCSM 2020, Held as Part of the 22nd HCI In-\nternational Conference, HCII 2020, Copenhagen, Denmark,\nJuly 19\u201324, 2020, Proceedings, Part I 22 . Springer. 2020,\npp. 201\u2013214.\n[137] Yang Liu and Yi-Fang Brook Wu. \u201cEarly Detection of Fake\nNews on Social Media Through Propagation Path Classi\ufb01-\ncation with Recurrent and Convolutional Networks\u201d. en. In:\nAAAI (2018), p. 8.\n[138] Jing Ma, Wei Gao, and Kam-Fai Wong. \u201cDetect Rumors in\nMicroblog Posts Using Propagation Structure via Kernel\nLearning\u201d. en. In: Proceedings of the 55th Annual Meeting\nof the Association for Computational Linguistics (Volume\n1: Long Papers) . Vancouver, Canada: Association for Com-\nputational Linguistics, 2017, pp. 708\u2013717.\n[139] Jing Ma et al. \u201cDetecting rumors from microblogs with\nrecurrent neural networks\u201d. In: Proceedings of the Twenty-\nFifth International Joint Conference on Arti\ufb01cial Intelli-\ngence (2016).\n[140] Xiaomo Liu et al. \u201cReal-time Rumor Debunking on Twit-\nter\u201d. In: Proceedings of the 24th ACM International on\nConference on Information and Knowledge Management\n(CIKM \u201915) (2015).\n[141] Daniel Williams. \u201cMisinformation is the symptom, not the\ndisease: Daniel Williams\u201d. In: IAI TV (Dec. 2023).\n[142] Li Qian Tay et al. \u201cThinking clearly about misinformation\u201d.\nIn:Communications Psychology 2.1 (2024), p. 4.\n[143] Fang Jin et al. \u201cEpidemiological modeling of news and\nrumors on Twitter\u201d. en. In: Proceedings of the 7th Workshop\non Social Network Mining and Analysis . Chicago Illinois:\nACM, Aug. 2013, pp. 1\u20139. ISBN : 978-1-4503-2330-7.\n[144] Sander van der Linden. \u201cMisinformation: Susceptibility,\nspread, and interventions to immunize the public\u201d. In: Na-\nture Medicine (Mar. 2022).\n[145] Nam P. Nguyen et al. \u201cContainment of misinformation\nspread in online social networks\u201d. In: Proceedings of the 4th\nAnnual ACM Web Science Conference . WebSci \u201912. New\nYork, NY, USA: Association for Computing Machinery,\nJune 2012, pp. 213\u2013222. ISBN : 978-1-4503-1228-8.\n[146] Emilio Ferrara et al. \u201cThe rise of social bots\u201d. In: Commu-\nnications of the ACM 59.7 (2016), pp. 96\u2013104.\n[147] Austin Hounsel et al. \u201cIdentifying Disinformation Websites\nUsing Infrastructure Features\u201d. In: FOCI (2020).[148] Ramy Baly et al. \u201cWhat Was Written vs. Who Read It:\nNews Media Pro\ufb01ling Using Text Analysis and Social Me-\ndia Context\u201d. In: Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics . On-\nline: Association for Computational Linguistics, July 2020,\npp. 3364\u20133374.\n[149] Zhouhan Chen and Juliana Freire. \u201cProactive Discovery of\nFake News Domains from Real-Time Social Media Feeds\u201d.\nIn:Companion Proceedings of the Web Conference 2020 .\nWWW \u201920. Taipei, Taiwan: Association for Computing\nMachinery, Apr. 2020, pp. 584\u2013592. ISBN : 978-1-4503-\n7024-0.\n[150] Fatemeh Torabi Asr and Maite Taboada. \u201cThe Data Chal-\nlenge in Misinformation Detection: Source Reputation vs.\nContent Veracity\u201d. In: Proceedings of the First Workshop\non Fact Extraction and VERi\ufb01cation (FEVER) . Brussels,\nBelgium: Association for Computational Linguistics, Nov.\n2018, pp. 10\u201315.\n[151] Media Bias/Fact Check News . July 2021. URL:https :\n//mediabiasfactcheck.com/ .\n[152] Snopes .URL:https://www.snopes.com/ .\n[153] FactCheck.org .URL:https://www.factcheck.org/ .\n[154] Sayash Kapoor and Arvind Narayanan. \u201cLeakage and the\nReproducibility Crisis in ML-based Science\u201d. In: Patterns\n(2023).\n[155] Fake news detection datasets .URL:https : / /\nonlineacademiccommunity.uvic.ca/isot/2022/11/\n27/fake-news-detection-datasets/ .\n[156] Fatima K. Abu Salem et al. FA-KES: A fake news dataset\naround the Syrian War . Jan. 2019. URL:https://zenodo.\norg/record/2607278 .\n[157] Jason Baumgartner et al. \u201cThe pushshift reddit dataset\u201d. In:\nProceedings of the international AAAI conference on web\nand social media . V ol. 14. 2020, pp. 830\u2013839.\n[158] Kai-Cheng Yang, Emilio Ferrara, and Filippo Menczer.\n\u201cBotometer 101: Social bot practicum for computational\nsocial scientists\u201d. In: Journal of Computational Social Sci-\nence 5.2 (2022), pp. 1511\u20131528.\n[159] Tekla S. Perry. \u201cHow Facebook\u2019s AI Tools Tackle Misin-\nformation\u201d. In: IEEE Spectrum (2020).\n[160] Connie Moon Sehat et al. \u201cMisinformation as a harm:\nstructured approaches for fact-checking prioritization\u201d. In:\nProceedings of the ACM on Human-Computer Interaction\n8.CSCW1 (2024), pp. 1\u201336.\n[161] Thodoris Lykouris and Wentao Weng. \u201cLearning to defer\nin content moderation: The human-AI interplay\u201d. In: arXiv\npreprint arXiv:2402.12237 (2024).\n[162] Giovanni Santia, Munif Mujib, and Jake Williams. \u201c\u2018De-\ntecting Social Bots on Facebook in an Information Veracity\nContext\u2019\u201d. In: ICWSM (2019).\n[163] Weiling Chen et al. \u201c\u2018Unsupervised rumor detection based\non users\u2019 behaviors using neural networks\u2019\u201d. In: Pattern\nRecognition Letters (2018).\n5266    34th USENIX Security Symposium USENIX Association", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "SoK: Machine Learning for Misinformation Detection", "author": ["M Xiao", "J Mayer"], "pub_year": "2023", "venue": "arXiv e-prints", "abstract": "We examine the disconnect between scholarship and practice in applying machine learning  to trust and safety problems, using misinformation detection as a case study. We survey"}, "filled": false, "gsrank": 601, "pub_url": "https://www.usenix.org/system/files/usenixsecurity25-xiao-madelyne.pdf", "author_id": ["6NrmktMAAAAJ", "qRFx7E8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:RJv-adZAuokJ:scholar.google.com/&output=cite&scirp=600&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D600%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=RJv-adZAuokJ&ei=c7WsaKrNI5XUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:RJv-adZAuokJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.usenix.org/system/files/usenixsecurity25-xiao-madelyne.pdf"}}, {"title": "Are You Trying to Convince Me or Are You Trying to Deceive Me? Using Argumentation Types to Identify Deceptive News", "year": "2025", "pdf_data": "Proceedings of the The 9th Workshop on Online Abuse and Harms (WOAH), pages 355\u2013372\nAugust 1, 2025 \u00a92025 Association for Computational Linguistics\nAre You Trying to Convince Me or Are You Trying to Deceive Me?\nUsing Argumentation Types to Identify Deceptive News\nRicardo Mu\u00f1oz S\u00e1nchez Emilie Francis Anna Lindahl\nSpr\u00e5kbanken Text, University of Gothenburg, Sweden\n{ricardo.munoz.sanchez,emilie.francis,anna.lindahl}@gu.se\nAbstract\nThe way we relay factual information and the\nway we present deceptive information as truth\ndiffers from the perspective of argumentation.\nIn this paper, we explore whether these differ-\nences can be exploited to detect deceptive po-\nlitical news in English. We do this by training\na model to detect different kinds of argumen-\ntation in online news text. We use sentence\nembeddings extracted from an argumentation\ntype classification model as features for a de-\nceptive news classifier. This deceptive news\nclassification model leverages the sequence of\nargumentation types within an article to deter-\nmine whether it is credible or deceptive. Our ap-\nproach outperforms other state-of-the-art mod-\nels while having lower variance. Finally, we\nuse the output of our argumentation model to\nanalyze the differences between credible and\ndeceptive news based on the distribution of ar-\ngumentation types across the articles. Results\nof this analysis indicate that credible political\nnews presents statements supported by a variety\nof argumentation types, while deceptive news\nrelies on anecdotes and testimonial.\n1 Introduction\nThe spread of disinformation has taken a toll on\npublic trust in news media (Lee, 2024). The effects\nof this are reflected in social and political unrest,\nsuch as the 2016, 2020, and 2024 United States\npresidential elections (see Allcott and Gentzkow,\n2017; Benkler et al., 2020; Ar\u0131soy Gedik, 2025,\nrespectively) and the COVID-19 pandemic (Rocha\net al., 2021). There is a widespread perception that\njournalists have not only failed to shield the public\nfrom disinformation, but have also contributed to\nits spread by aligning themselves with bad actors\n(Harrington et al., 2024). On top of that, there\nis a belief that news media prioritizes profit over\nveracity, treating it as some sort of advertisement\n(Amazeen and Wojdynski, 2019).Although disinformation takes many forms, we\nfocus on deception based on the definitions of\nnews media watchdog organizations, such as Me-\ndia Bias/Fact Check.1These are often determined\nbased on political bias and on the amount of false\ninformation, be it of the articles themselves or of\nthe outlets that publish them. We focus on polit-\nical news, as it has become a loci of public con-\ncerns over the role that news media plays in global\npolitics and the influence disinformation has in it\n(Benkler et al., 2020; Harrington et al., 2024).\nPolitical persuasion and disinformation are\nclosely related (Gil de Z\u00fa\u00f1iga et al., 2025). We\nassume that credible news aims to inform, while de-\nceptive news attempts to persuade readers in favour\nof a certain viewpoint. We hypothesize that this\nwill be reflected in the argumentation within the\narticles themselves. Our research questions are as\nfollows:\nRQ1: Can argumentation features be used to de-\ntect deceptive news?\nRQ2: What insights can we acquire by comparing\nargumentation types in credible and deceptive\nnews?\nWe implement a two-step approach to test this.\nWe start by training a BERT (Devlin et al., 2019)\nmodel to identify argumentation types in English\nnews articles. We extract argumentation features\nfrom this model and feed them to a Bi-LSTM\n(Hochreiter and Schmidhuber, 1997) to identify\ndeceptive news. We go into more detail of our\narchitecture and related design choices in Section\n3.\nWe report the results of our experiments in Sec-\ntion 6. Our approach outperforms other models\nfrom the literature, having less variance compared\nto the other non-deterministic methods used in our\n1https://mediabiasfactcheck.com/methodology/355\nexperiments. We also show that feature-based mod-\nels can outperform simple transformer baselines.\nWe do an analysis of the argumentation types\nbetween credible and deceptive news in Section\n7. We show that deceptive news tends to present\nmore anecdotes and testimonies, while credible\nnews tends to have more assumptions supported\nthrough evidence.\n2 Related Work\n2.1 Misinformation and Deception Detection\nMisinformation detection is a task that has arisen in\norder to combat the influence of false or misleading\ninformation. Oshikawa et al. (2020) note that, even\nthough it is often framed as a binary veracity clas-\nsification, it has also been framed using scales of\ntruth (Rashkin et al., 2017; Wang, 2017) or through\npolitical bias (Potthast et al., 2018).\nResearch from psychology has shown that liars\nattempt to relieve the cognitive burden of decep-\ntion by distancing themselves from their false state-\nments (Newman et al., 2003). Similar effects have\nbeen reported when looking at \u201ctrolls\u201d on social\nmedia (Addawood et al., 2019). However, it is im-\nportant to note that veracity can be complicated to\nestablish, which can lead to issues such as sampling\nbiases (Zhou et al., 2021).\nRuffo et al. (2023) note that a lot of terminol-\nogy in this area tends to have fuzzy or ambiguous\ndefinitions. They argue that terms such as \u201cfake\nnews\u201d are often ill-defined, even in an academic\nsetting. They mention that this blurs the lines be-\ntween misinformation detection and similar tasks,\nsuch as automated fact-checking, propaganda, and\nhyper-partisan bias detection.\nAlthough automated fact-checking is a distinct\ntask that has been applied to various types of me-\ndia,2it is also used in knowledge-based approaches\nto detect misinformation. An example of this is\nKumar et al. (2025), who used factual statements\nto form knowledge graphs to provide models with\nupdated contextually relevant information for fact-\nchecking.\nSeveral other approaches have used features\nwithin the text, such as syntactic (Huang et al.,\n2020) or discourse features (Karimi and Tang,\n2019) One such approach by Ghanem et al. (2021)\nmodelled emotional shifts throughout an article and\n2See Thorne and Vlachos, 2018 for an overview of the task\nup to 2018 or the yearly FEVER Workshop, organized since\n2018: https://fever.ai/employed the information as features for fake news\ndetection. Oshikawa et al. (2020) note that the\nmost commonly used content features tend to be\nbag-of-words features, frequency of punctuation,\nand psycholinguistic features from LIWC.3\nAnother common way to tackle misinformation\ndetection uses metadata, such as social media in-\nteraction or web traffic. An example of this is a\nstudy by Baly et al. (2018), which establishes a link\nbetween news article reliability and publisher cred-\nibility by checking for the existence of a Wikipedia\npage or Twitter account.\nCredibility, partisanship, and misinformation\nhave also been investigated in prediction and de-\ntection tasks. Rather than explicit fact-checking,\nPotthast et al. (2018) argue that stylistic differences\nin partisan news are sufficient to detect disinforma-\ntion. Potthast et al. (2018) and Baly et al. (2019)\nnoted that hyper-partisan news articles across the\npolitical spectrum are more similar to each other in\nterms of style than to more balanced news.\nFurthermore, the political orientation of a reader\ncan affect how believable or factual a piece of in-\nformation is perceived to be. Landreville and and\n(2019) note that if the political orientation of a news\noutlet aligns with that of its reader, it is considered\nto be more reliable. This is the case even if said\nstatements are opinions instead of facts. On the\nother hand, Morris et al. (2020) point out that news\nreaders in the United States tend to consider a news\noutlet more trustworthy if it is critical of the op-\nposing political party. Even though this effect is\npresent across the whole political spectrum, they\nnote that it is stronger in conservative readers. Both\nof these studies point out that these effects increase\nthe likelihood of believing disinformation as long\nas it aligns with our political values or is critical to\nthose perceived to be opposing.\n2.2 Argumentation Mining of News\nArgumentation mining is a subfield of NLP that\nstudies argumentation, ranging from identifying\nargumentative passages to analyzing argumenta-\ntive structures and reasoning (Stede and Schneider,\n2019; Lawrence and Reed, 2019). Argumentation\nmining of news media has generally focused on\nannotation of editorials and opinion pieces. Rocha\net al. (2022) created a dataset of opinion articles in\nPortuguese annotated with argumentative discourse\n3Linguistic Inquiry Word Count, originally introduced by\nPennebaker and Francis (1999).356\nunits,4argumentative components, and relations.\nAnother corpus created by Habernal and Gurevych\n(2017) annotated user comments on news articles,\ndiscussion forums, and blog posts related to contro-\nversial issues in education. Similarly, Goudas et al.\n(2014) collected documents in Greek from social\nmedia (including news articles) and annotated them\nto identify sentences containing argumentation and\nwhether they are claims or premises.\nSeveral studies have bridged misinformation\nand argument mining. Rhetorical structure the-\nory (RST) has been used to detect deceptive con-\ntent (Vargas et al., 2022), while stance detec-\ntion has close ties with argumentation mining\n(Weinzierl and Harabagiu, 2024; Saha et al., 2024)\nand has often been studied alongside news credibil-\nity (e.g.Kotonya and Toni, 2019 and the Fake News\nChallenge5shared task).\nIn this study, we use the Webis-16 dataset (Al-\nKhatib et al., 2016). It consists of news editorials\nannotated with argumentation types and informa-\ntion for the argumentative role they play. The paper\nthat introduced the dataset used it to investigate\npatterns in argumentation strategies across various\nnews topics. It has also been used by Ajjour et al.\n(2017) to identify argumentative segments in writ-\nten news media.\n2.3 Arguments and Persuasion in News and\nPolitics\nIn a study of news editorials, El Baff et al. (2018)\nclassified articles as challenging or reinforcing.\nChallenging editorials make the reader rethink their\nprior stance, while reinforcing editorials strengthen\ntheir prior stance. They show in a later paper\n(El Baff et al., 2020) that persuasive reinforcing\neditorials often start and end with negative tone.\nThey also observe that persuasive articles often\nstart with an engaging hook and fortify arguments\nwith a \u2018punchy\u2019 closing. On the other hand, they\nnote that ineffective articles tend to feel inauthentic\nand have positive tone in the article body.\nYu et al. (2021) focuses on the emotional aspect\nof news articles. They show that persuasive arti-\ncles leverage the reader\u2019s emotions by using loaded\nlanguage and logical fallacies, such as straw-man\narguments and ad-hominem attacks.\nPolitical speech in online news media often takes\nthe form of advertisement, mimicking the style\n4Argumentative units are categorized according to the role\nthey play in argumentation.\n5http://www.fakenewschallenge.org/Type Explanation\nAnecdote Provides evidence through ex-\namples or personal experi-\nences.\nAssumption Assumptions that need sup-\nport to be accepted by the\nreader.\nTestimony Provides evidence by quoting\na figure of authority.\nOther Establishes shared knowl-\nedge, presents statistics, or\ndoes not add to the argument.\nTable 1: Argument types and their definitions.\nand format of the platform on which it appears\n(Amazeen and Wojdynski, 2019). Nelson et al.\n(2021) show that readers are not very successful\nat identifying this type of advertising. They also\nnote that, unlike commercial ads, regulations guid-\ning truth in advertising are typically not applied to\npolitical content (Nelson et al., 2021). Given the\nimpact that news media has on society, this makes\nfor a powerful political tool (Konieczny, 2023).\n3 Our Approach\nAs we want to analyze whether the argumentative\nstructure of an article can be used to identify de-\nception, we perform a two-step process inspired by\nAlhindi et al. (2021). This allows us to determine\nwhether our model learns from argumentation in\nthe text and provides us with information about the\ntypes of argumentation in news articles, which we\nanalyze in Section 7. We use argumentation types\ninstead of argumentation roles (such as premise\nand conclusion), as Al-Khatib et al. (2016) note\nthat the latter encode the strategy an author uses to\npersuade readers.\nWe split the articles into an ordered set of sen-\ntences and assign them an argumentation type with\nBERT. We use four argumentation types: anecdote ,\nassumption ,testimony , and other . Table 1 explains\nthe different argumentation types, while Section\n4.1 details why these specific ones were chosen.\nWe use the final transformer layer from this model\nto generate sentence embeddings, which are fed to\na Bi-LSTM model to classify news articles as cred-\nible or deceptive. The architecture of this process\nis represented in Figure 1.357\nFigure 1: Diagram of our proposed approach and its different components. The argumentation type classifier (on\ntop) assigns an argumentation type to each sentence. The deceptive news detection model (on the bottom) uses\nsentence embeddings to determine whether an article is credible or deceptive. These embeddings are taken from the\nfrozen argumentation type model, represented in the diagram by a snowflake.\nWhile decoder-only models6have been shown\nto work well with argumentation (El Baff et al.,\n2024), they have give mixed results in disinforma-\ntion detection tasks (Hu et al., 2024; Su et al., 2024).\nWe do not use them for this study to avoid the in-\ntroduction of artifacts in any part of our pipeline.\nWe use BERT over similar but larger models to\navoid overfitting as our argumentation type dataset\nis quite small. Exploratory experiments revealed\nthat BERT struggles with the least represented ar-\ngument type (see Section 4.1). This issue is likely\nto be more prominent in larger models.\nvan Dijk (1989) and Yarlott et al. (2018) note\nthat ordering is important for the argumentative\nrole of text in written news media. We chose a\nBi-LSTM for the deceptive news detection task, as\nthese models will intrinsically take into account the\nordering of the argumentation types.\nWe explain each model and how they are imple-\nmented in more detail throughout the rest of this\nsection. The specific hyper-parameters used for our\nexperiments can be found in Appendix A.\nArgumentation Type Classifier: We fine-tune\na BERT model7on the argumentation type dataset.\nThis model is shown individual sentences and must\nassign an argumentation type to each of them. We\nuse the output of the [CLS] token from the final\ntransformer layer for classification. As the latter\nBERT layers typically learn task-specific features\n(Rogers et al., 2020), we expect the final layer to en-\ncode argumentation-related features for the whole\nsentence. This model is then frozen for the rest of\nthe experiments to prevent its weights from chang-\ning later on, thus making sure that it retains its\n6Such as OpenAI\u2019s GPT line of models.\n7https://huggingface.co/google-bert/bert-bas\ne-uncasedknowledge about argumentation types intact.\nDeceptive News Classifier: Given a news arti-\ncle, we split it into sentences. These sentences\nare passed through the now-frozen argumentation\ntype classifier. We use the output of the final trans-\nformer layer corresponding to the [CLS] token as\na sentence embedding. These embeddings are then\nfed to a Bi-LSTM model to determine whether the\narticle is credible or deceptive.\n4 Datasets\nIn this section, we describe the different datasets\nused in our two tasks. For the argumentation type\nclassification task, we use the Webis-Editorials-16\ndataset (Section 4.1). For the deceptive news de-\ntection task, we use two datasets: one with article-\nlevel annotations (Section 4.2) and another with\nsource-level annotations (Section 4.3).\nAll three datasets contain news articles in En-\nglish collected prior to 2020. Although the land-\nscape of deceptive news and misinformation is\nlikely to have changed since these articles were\noriginally published, these datasets are still valu-\nable as they only contain human-generated news.\nMachine-generated mis- and disinformation is very\ndifferent from that generated by humans (Tewari\net al., 2021) and detecting it is another task in and\nof itself (Beigi et al., 2024). Therefore, we choose\nestablished datasets from before content produced\nby generative language models flooded the web.\n4.1 Webis-16 Dataset\nThe Webis-Editorials-16 dataset (or Webis-16 for\nshort) was originally introduced by Al-Khatib et al.\n(2016). It consists of news editorials in English\nfrom three established news sources. One hun-\ndred editorials were selected for each of the three358\nClass PolitiFact FakeNews-2018\nCredible 131 8,117\nDeceptive 242 14,962\nCredible 372 23,079\nTable 2: Number of articles for each class after having\nfiltered the datasets for length.\npublishers. The included texts were originally pub-\nlished between December 2014 and January 2015\nand were selected such that they would have a\nlength of at least 250 word and had at least five\ncomments. This dataset does not to distinguish be-\ntween true and false statements, which is beneficial\nfor our task as it reduces the risk of introducing\nartifacts into the deceptive news classification task.\nEach token in the text was assigned one of eight\nlabels. Six of these labels correspond to argumen-\ntation types, namely common ground ,assumption ,\ntestimony ,statistics ,anecdote , and other . The con-\ntinuation label means that a token has the same\nargumentation type as the next argumentation type\nlabel that appears, thus forming spans of argumen-\ntative units. Some tokens, such as punctuation,\nare labelled as non-argumentative as they do not\nform part of an argumentative unit, regardless of\nsurrounding tokens.\nIt is important to note that argumentative units\ndo not necessarily correspond to sentences. A sen-\ntence may contain multiple clauses, each its own\nargumentative unit. It is also possible for argumen-\ntative units to span two or more sentences. This\nposes a problem for our task. Although token-level\nclassification is useful for studying argumentative\nunits in the context of argumentation types, the dif-\nference in granularity can harm our downstream\ntask as it is document-level classification.\nBecause of this, we cast the argumentation type\nlabels so that each sentence has one and only one.\nWe do this in the following way: (i) continuation\nlabels take on the same label as the next argumen-\ntation type label; (ii) sentences with more than\none argumentation type label are discarded; and\n(iii) if all tokens in a sentence not labelled non-\nargumentative share an argumentation type label,\nthe whole sentence gets that label.\nOne issue that arose during exploratory analysis\nwas that models performed very well on the ma-\njority class, but very poorly on under-represented\nclasses. This was still the case when applying earlystopping and keeping the best performing check-\npoint. A model that severely under-performs on\none or more of the classes will not allow for good\nanalysis of the data. To get around this issue, we\ncollapsed some of the minority classes together.\nThe labels for assumption ,anecdote , and testimony\nwere preserved, while common ground andstatis-\nticswere grouped into other . This resulted in better\nperformance of the deceptive news classifier and\nallowed us to conduct a more accurate analysis of\nargumentation in the articles. Appendix B goes\ninto more detail on how the number of labels was\nchosen.\n4.2 PolitiFact\nFakeNewsNet, originally introduced by Shu et al.\n(2020), contains the PolitiFact and GossipCop\ndatasets. They have article-level annotations ob-\ntained from their name-sake fact-checking web-\nsites.8The labels are binary and represent veri-\nfiable truth. As our analysis focuses on political\nnews, only the PolitiFact dataset is used in our\napproach. It originally contained 948 articles ac-\ncessible through links provided by the authors to\npreserve copyright. Unfortunately, many articles\nare no longer retrievable due to broken links.\nArticle length has been shown to be a strong in-\ndicator of deceptive news (Levi et al., 2019). We\nfilter the dataset to ensure both credible and de-\nceptive articles are within an range of 100 to 800\ntokens. This helps make sure the model learns from\nargumentative structure rather than length. Motiva-\ntion for these bounds can be found in Appendix C.\nThe final number of articles after filtering can be\nfound in Table 2.\n4.3 FakeNews-2018 Dataset\nThe FakeNews-2018 dataset, originally introduced\nby Francis (2018), contains over 81,000 political\nnews articles in English collected from various\nsources from the U.S., Canada, and the U.K. pub-\nlished between 2013 and 2017. Articles are la-\nbelled as credible or deceptive based on the source,\naccording to the factuality and credibility scores\nfrom Media Bias/Fact Check,9AllSides,10and Ad-\nFontes Media11to categorize sources as credible or\ndeceptive.\n8https://www.politifact.com/ andhttp://www.go\nssipcop.com/ , now defunct.\n9https://mediabiasfactcheck.com/\n10https://www.allsides.com/\n11https://adfontesmedia.com/359\nSome sources labelled as deceptive in the dataset\nare described as satire. Even though satirical news\ndiffer from non-satirical news (Horne and Adali,\n2017), research has shown it is challenging to dis-\ntinguish satire from deceptive news (Horne and\nAdali, 2017; Rubin et al., 2015). While satirical\nnews are meant to be entertainment, disinforma-\ntion outlets often present themselves as satire to\nprotect themselves from legal consequences (Gol-\nbeck et al., 2018). Even when this is not the case,\nsatirical news has the potential to mislead readers\nthrough its mimicry of actual news (Francis, 2024).\n5 Baselines\nWe compare our argumentation type classifier\nagainst a random classifier and a majority class\nbaseline. This is done to ensure the model is actu-\nally learning from the data and not simply assigning\nlabels arbitrarily. We focus on both general per-\nformance and performance on the lowest scoring\nlabel.\nWe compare our approach to three models: a\nBERT classifier, an SVM using LIWC12features,\nand FakeFlow (Ghanem et al., 2021). We choose\nBERT as it has been shown to perform well for a\nvariety of tasks and is simple to implement. Classi-\ncal machine learning models using LIWC features\nhave been used successfully for deceptive news\ndetection in the past (e.g. Che et al., 2018; P\u00e9rez-\nRosas et al., 2018). We follow the implementation\nof Horne and Adali (2017), using an SVM classifier\nand the same feature selection process. The final\nmodel used for comparison is FakeFlow, which\nuses a CNN (Kim, 2014) to model article topics\nand a Bi-GRU (Cho et al., 2014) to model emotions\nin the text.\n6 Results and Discussion\nThroughout this section we present the quantitative\nresults of both the argumentation type and decep-\ntive news classification tasks. Appendix D contains\nadditional tables with more detailed results from\nour experiments.\nEach experiment was run multiple times in order\nto assess not only the performance of the mod-\nels, but also their variance across runs. Only the\nrandom seed was changed across runs, all other hy-\nperparameters remained the same. We performed\n12Linguistic Inquiry Word Count, originally introduced by\nPennebaker and Francis (1999).\n(a) Weighted F1 scores for the\nPolitiFact dataset.\n(b) Weighted F1 scores for the\nFakeNews-2018 dataset.\nFigure 2: Weighted F1 scores for the deceptive news\nclassification task. Our model (in red) outperforms the\nother models on average.\nfive runs for each argumentation type classifica-\ntion model. The deceptive news models were also\ntrained an additional five times for each, resulting\nin a total of 25 runs. This allows us to assess the\nvariance of the deceptive news model not only in\nterms of the training process but also of the repre-\nsentations it was fed.\nArgumentation Type Classifier: Our classifier\nachieves an average weighted F1 score of 0.84,\nwhich is significantly higher than those of the ran-\ndom and majority baselines (0.56 and 0.61, respec-\ntively). It is important to verify the F1 score of the\nworst-performing label at this step. This is used in\nanalyzing the argumentation types of news articles\n(see Section 7) and is the motivation for collapsing\nsome of the labels into a single one (see Section 4.1\nand Appendix B). The lowest F1 score observed is\n0.47 for the other class, which is a large improve-\nment over 0.04 for the same class using the random\nbaseline.\nDeceptive News Classifier: As shown in Figure\n2, using argumentation features outperforms the\nother models. There is a noticeable improvement\nover BERT and the SVM with LIWC features for\nboth datasets.\nWe notice different patterns when comparing our\nmodel with FakeFlow. For the PolitiFact dataset,\nboth models show an overlap in performance. How-360\n(a) Distribution of the assumption label\n (b) Distribution of the testimony label\nFigure 3: Distributions for the ratios of the argumentation types assumption andtestimony in the FakeNews-2018\ndataset. Deceptive news tends to make less assumptions and presents more testimonies.\never, the three lower quartiles for FakeFlow are\nlower than the higher three ones for the model\nwith argumentation features, meaning that the latter\nperforms better on average. When looking at the\nFakeNews-2018 dataset, we notice that FakeFlow\nperforms much worse than on any of the other mod-\nels. Previous research has shown that features of\ndeceptive news can be topic dependent, which may\nexplain why some models under-perform on spe-\ncific deception detection datasets (Francis, 2024).\nOverall, our approach showed a lower variance\nin its performance when compared to the other\nstatistical models (i.e. BERT and FakeFlow). This\nindicates it is more stable and less prone to the\neffects of randomness, such as the chosen random\nseed.\n7 How Do People Argue in Deceptive\nNews?\nGiven an argumentation type label and an article,\nwe look at the fraction of sentences within the arti-\ncle with that label. We then compare how these val-\nues are distributed in each deceptive news dataset\n(see Figure 3). To ensure balanced sample sizes for\nthe analysis, we under-sample the most represented\nclass for each dataset.\nWe use a two-tailed Kolmogorov\u2013Smirnov test\n(Hodges, 1958) to determine whether the distribu-\ntions for credible and deceptive news are different13\nand, if so, how much they differ. It is important to\nnote that all four distributions are related to each\nother as the ratios for a given article must sum up\nto one.14Thus, we must apply a Bonferroni cor-\nrection for n= 4. That means that we need a\np-value of 0.0125 instead of 0.05 to be able to re-\n13Given that we are dealing with distributions of ratios, we\ncan safely assume that they are not normally distributed.\n14This is because each of the sentences in an article must\nhave one and only one of the four argumentation type labels.Label PolitiFact FakeNews-2018\nAnecdote 0.23 0.02\nAssumption 0.10 0.10\nTestimony 0.24 0.17\nOther 0.27 0.15\nTable 3: Values of the Kolmogorov\u2013Smirnov test, de-\nnoting the largest difference in the cumulative distri-\nbution functions. Statistically significant results are\nhighlighted. Due to the Bonferroni correction, we need\na p-value of 0.0125 to reject the null hypothesis.\nject the null hypothesis that the distributions for the\ncredible and deceptive news articles are the same.\nThe Kolmogorov\u2013Smirnov statistic, shown in\nTable 3, tells us the largest difference between the\ntwo cumulative distribution functions. Excluding\nanecdote in the FakeNews-2018 dataset and as-\nsumption in PolitiFact, the results are statistically\nsignificant and show a large difference.\nWe will go over the differences between the\ndistributions of the four labels, focusing on the\nFakeNews-2018 dataset as we consider that these\ndistributions can give us potentially interesting in-\nsights.\nWhen looking at the distribution of the anecdote\nargumentation type, we notice that anecdotes ap-\npear more often in articles labelled fake in the Poli-\ntiFact dataset. Usage of anecdotes may be a strat-\negy used by deceptive news outlets to strengthen\narguments in lieu of factual evidence. Previous lit-\nerature has also noted that more persuasive articles\nuse logical fallacies, such as arguments from anec-\ndote, which leverage readers\u2019 emotions (Yu et al.,\n2021). Meanwhile the Komogorov-Smirnov statis-\ntic shows that the difference on the FakeNews-2018\ndataset is small and not statistically significant.\nIn general, the label assumption is the most361\nevenly distributed across the articles, regardless\nof the dataset or whether they are deceptive or not.\nAs we can see in Figure 3, assumptions are less rep-\nresented in deceptive news in the FakeNews-2018\ndataset.\nThe label assumption appears more often in ar-\nticles, regardless of whether they are deceptive or\nnot. In contrast, the other labels tend to represent\na small proportion of the sentences of an article.\nThis does not mean that there are no differences\nbetween credible and deceptive news, as assump-\ntions are less represented in deceptive news in the\nFakeNews-2018 dataset (as shown in Figure 3).\nGelfert (2018) notes that the modern wave of dis-\ninformation stems partly from conspiracy theories.\nConspiracy theorists avoid making explicit assump-\ntions to avoid accountability for their claims, using\nthe excuse of \u201cjust asking questions\u201d (Egelhofer\nand Lecheler, 2019). As mentioned previously, the\ndifference between the distribution for credible and\ndeceptive news is not statistically significant for\nthe PolitiFact dataset, likely due to the small size\nof the dataset.\nThetestimony label is represented more in decep-\ntive news for both datasets. Figure 3 shows this for\nthe FakeNews-2018 dataset. This may be related\nto the use of news as a medium for political adver-\ntising (Nelson et al., 2021). Studies have shown\nthat testimonials positively impact consumer bias\nand that consumers identify more strongly with\ntestimonials from individuals they consider peers\n(Shimp et al., 2007; Appiah, 2007). It has also\nbeen observed that partisan loyalty has an effect on\nbelievability, as readers are more likely to report in-\nformation from sources that share their political af-\nfiliation as factual (Morris et al., 2020; Landreville\nand and, 2019). On the other hand, this could also\nbe due to deceptive news using fallacious strategies\nsuch as appealing to authority (Yu et al., 2021).\nTheother label is represented the least in both\ndatasets and both types of news, but appears more\nin credible news articles than in deceptive ones. It\nis important to note that the other label contains the\nstatistics andground-truth labels from the original\nWebis-16 dataset (as noted in Section 4.1). This\nsuggests that credible news substantiates claims\nmore often than deceptive.\nAs mentioned previously in this section, Figure\n3 shows the distributions for the labels assump-\ntionandtestimony in the FakeNews-2018 dataset.\nThe histograms comparing the distributions for all\nthe argumentation type labels can be found in Ap-pendix E.\n8 Conclusions\nFactuality in news media is closely related to simi-\nlar phenomena, such as partisan bias, propaganda,\nand satire (Ruffo et al., 2023). The rapid spread\nof deceptive news and misinformation has been\nlinked to instability in the global political climate,\nas well as erosion of trust in news media (Lee,\n2024). (Gelfert, 2018) and (Harrington et al., 2024)\nargue that it is important to study these complex\nphenomena in order to mitigate the risks and con-\nsequences they engender.\nIn this paper we hypothesized that argumenta-\ntion in credible and deceptive political news arti-\ncles would differ as a reflection of their role as\ninformers or vectors for ideology. We proposed\nan approach exploiting argumentation types of sen-\ntences within an article to detect deceptive news.\nOn average, our approach outperformed three mod-\nels from the existing literature, namely BERT, an\nSVM with LIWC features, and FakeFlow. It also\nshows a lower variance than the non-deterministic\nbaselines.\nSome interesting patterns appear when analyz-\ning the distributions of argumentation types. We\nfound that deceptive articles tend to use more testi-\nmonies and, for one of the datasets, more anecdotes.\nAlthough credible news tend to have more assump-\ntions, they appear to support them with evidence\nor by establishing shared knowledge. This matches\nprevious findings from the literature that point out\nthat deceptive news uses logical fallacies, such as\noverusing anecdotes or by appealing to authority\n(Yu et al., 2021).\nIt is important to note that the work we present\nin this paper is not any sort of \u201ctruth detector\u201d. Our\nmodel was trained and tested to be used in news\narticles and should only be used for that kind of\nmedia. The datasets have binary truth annotations\nand were curated with that purpose in mind. This\nmeans that things living in the in-between of truth\nand falsehood might potentially be misrepresented.\nMoreover, there are different kinds of mis- and dis-\ninformation (such as propaganda or hyper-partisan\nnews) that are not explicitly studied in the present\npaper to better isolate features pertaining deceptive\nnews.\nThe results of this study show that stylistic fea-\ntures, such as argumentation type, can improve\nclassification performance and enrich our under-362\nstanding of complex phenomena such as deceptive\nnews and misinformation. Not only that, but they\ncan also help develop systems that are both more\ninterpretable and perform as well as other classifi-\ncation systems, if not better.\nIt is also important to note that we focus on the\nstyle of the text rather than on its content. One of\nour assumptions is that outlets publishing deceptive\ncontent online do so knowingly. This ignores the\npossibility that people who write deceptive news\narticles legitimately believe what they are writing.\nIt also ignores propaganda in news media that is\noften regarded as trustworthy, be it backed by the\nState and/or by for-profit organizations.\nLimitations\nA possible limitation of our work could be the\nscope of the data. To the best of our knowl-\nedge, the Webis-16 dataset is one of the most thor-\noughly annotated news media datasets for argumen-\ntation types. However, the editorials it contains\ncome from only three publishers. Despite this, we\nachieve good results in our downstream applica-\ntion. It is also important to note that Lindahl (2024)\nargues that it can be complicated to annotate ar-\ngumentation in text due to ambiguity or multiple\nplausible interpretations.\nMoreover, the annotations of this dataset do not\ntake veracity into account. This makes it so that\nwe can properly model argumentation on its own,\nwithout introducing biases in the deceptive news\nclassification task. It is not possible to do joint\ntraining for the whole pipeline for that reason.\nIn a similar vein, the data we use for the decep-\ntive news detection task comes predominantly from\nEnglish outlets in the United States, Canada, and\nthe United Kingdom. Furthermore, previous stud-\nies show that features of deceptive news can vary\ndepending on news topic Francis (2024). There-\nfore our results might not generalize well to other\nlanguages, cultural contexts, or topics.\nRegardless of these limitations, we consider our\nresults to be useful in showcasing how other areas\nof NLP can give us a deeper insight into how de-\nceptive news works. We encourage people using\nour methodology in different linguistic or cultural\ncontexts to verify that is is an appropriate approach\nbefore doing any sort of implementation.Ethical Considerations\nThe study of automatic detection of disinformation\ncan be a complicated task. There is always the risk\nof the models being misused due to maliciousness,\nlack of information, or misinterpreting the purpose\nof the model.\nAn example of the first case could be a govern-\nment or company looking to censor news articles\nthat show them in an unfavourable light. Even\nthough some of the assumptions we made in this\npaper might not hold true in this case, models that\nclassify news articles could potentially be repur-\nposed for other tasks.\nAnother issue could be blindly trusting the out-\nputs of the model. Given that our model statisti-\ncally selects the class that an article is most likely\nto belong to, there is always the risk of it being\nwrong. Because of this, it is important to always\nkeep a human-in-the-loop approach when using\nthese kinds of models.\nPeople may also mistakenly use these kinds of\nmodels as a \u201ctruth detector\u201d with other kinds of me-\ndia. We have discussed this issue in the Limitations\nSection.\nOn top of that, there are the issues of where we\nget the data from and how it is annotated. Even\nthough the datasets we used obtain their anno-\ntations from independent fact-checking organiza-\ntions, there is always the risk of conflicts of interest\nor unstated agendas.\nEven though we take steps to mitigate these is-\nsues, we are aware that some of them might still\nlinger, especially those regarding possible misuse\nof the model.\nReferences\nAseel Addawood, Adam Badawy, Kristina Lerman, and\nEmilio Ferrara. 2019. Linguistic cues to deception:\nIdentifying political trolls on social media. Proceed-\nings of the International AAAI Conference on Web\nand Social Media , 13(01):15\u201325.\nYamen Ajjour, Wei-Fan Chen, Johannes Kiesel, Hen-\nning Wachsmuth, and Benno Stein. 2017. Unit seg-\nmentation of argumentative texts. In Proceedings of\nthe 4th Workshop on Argument Mining , pages 118\u2013\n128, Copenhagen, Denmark. Association for Compu-\ntational Linguistics.\nKhalid Al-Khatib, Henning Wachsmuth, Johannes\nKiesel, Matthias Hagen, and Benno Stein. 2016.\nA news editorial corpus for mining argumentation\nstrategies. In Proceedings of COLING 2016, the363\n26th International Conference on Computational Lin-\nguistics: Technical Papers , pages 3433\u20133443, Osaka,\nJapan. The COLING 2016 Organizing Committee.\nTariq Alhindi, Brennan McManus, and Smaranda Mure-\nsan. 2021. What to fact-check: Guiding check-\nworthy information detection in news articles through\nargumentative discourse structure. In Proceedings\nof the 22nd Annual Meeting of the Special Inter-\nest Group on Discourse and Dialogue , pages 380\u2013\n391, Singapore and Online. Association for Compu-\ntational Linguistics.\nHunt Allcott and Matthew Gentzkow. 2017. Social\nmedia and fake news in the 2016 election. Journal of\nEconomic Perspectives , 31(2):211\u2013236.\nMichelle A. Amazeen and Bartosz W. Wojdynski. 2019.\nReducing native advertising deception: Revisiting the\nantecedents and consequences of persuasion knowl-\nedge in digital news contexts. Mass Communication\nand Society , 22(2):222\u2013247.\nOsei Appiah. 2007. The effectiveness of \u201ctypical-\nuser\u201d testimonial advertisements on black and white\nbrowsers\u2019 evaluations of products on commercial\nwebsites: Do they really work? Journal of Advertis-\ning Research , 47:14\u201327.\nCansu Ar\u0131soy Gedik. 2025. The role of ai-driven con-\ntent, smart technologies, and disinformation in the\n2024 u.s. presidential elections. UPA Strategic Af-\nfairs, 6(1):177\u2013202.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 3528\u20133539, Brussels, Belgium. Association\nfor Computational Linguistics.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames Glass, and Preslav Nakov. 2019. Multi-task\nordinal regression for jointly predicting the trustwor-\nthiness and the leading political ideology of news\nmedia. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n2109\u20132116, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nAlimohammad Beigi, Zhen Tan, Nivedh Mudiam,\nCanyu Chen, Kai Shu, and Huan Liu. 2024. Model\nattribution in llm-generated disinformation: A do-\nmain generalization approach with supervised con-\ntrastive learning. In 2024 IEEE 11th International\nConference on Data Science and Advanced Analytics\n(DSAA) , pages 1\u201310.\nYochai Benkler, Casey Tilton, Bruce Etling, Hal\nRoberts, Justin Clark, Robert Faris, Jonas Kaiser,\nand Carolyn Schmitt. 2020. Mail-in voter fraud:\nAnatomy of a disinformation campaign.Xunru Che, Dana\u00eb Metaxa-Kakavouli, and Jeffrey T.\nHancock. 2018. Fake news in the news: An analysis\nof partisan coverage of the fake news phenomenon.\nInCompanion of the 2018 ACM Conference on Com-\nputer Supported Cooperative Work and Social Com-\nputing , CSCW \u201918 Companion, page 289\u2013292, New\nYork, NY , USA. Association for Computing Machin-\nery.\nKyunghyun Cho, Bart van Merrienboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using rnn encoder-decoder for\nstatistical machine translation.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nJana Laura Egelhofer and Sophie Lecheler. 2019. Fake\nnews as a two-dimensional phenomenon: A frame-\nwork and research agenda. Annals of the Interna-\ntional Communication Association , 43(2):97\u2013116.\nRoxanne El Baff, Khalid Al Khatib, Milad Alshomary,\nKai Konen, Benno Stein, and Henning Wachsmuth.\n2024. Improving argument effectiveness across ide-\nologies using instruction-tuned large language mod-\nels. In Findings of the Association for Computational\nLinguistics: EMNLP 2024 , pages 4604\u20134622, Mi-\nami, Florida, USA. Association for Computational\nLinguistics.\nRoxanne El Baff, Henning Wachsmuth, Khalid Al-\nKhatib, and Benno Stein. 2018. Challenge or em-\npower: Revisiting argumentation quality in a news\neditorial corpus. In Proceedings of the 22nd Confer-\nence on Computational Natural Language Learning ,\npages 454\u2013464, Brussels, Belgium. Association for\nComputational Linguistics.\nRoxanne El Baff, Henning Wachsmuth, Khalid\nAl Khatib, and Benno Stein. 2020. Analyzing the Per-\nsuasive Effect of Style in News Editorial Argumenta-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics , pages\n3154\u20133160, Online. Association for Computational\nLinguistics.\nEmilie Francis. 2018. MisInfoWars: A linguistic anal-\nysis of deceptive and credible news. Master Thesis.\nSimon Fraser University .\nEmilie Francis. 2024. Variation between credible and\nnon-credible news across topics. In The First Interna-\ntional Conference on Natural Language Processing\nand Artificial Intelligence for Cyber Security , pages\n86\u201396.364\nAxel Gelfert. 2018. Fake news: A definition. Informal\nLogic , 38(1):84\u2013117.\nBilal Ghanem, Simone Paolo Ponzetto, Paolo Rosso,\nand Francisco Rangel. 2021. FakeFlow: Fake news\ndetection by modeling the flow of affective infor-\nmation. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Main Volume , pages 679\u2013689,\nOnline. Association for Computational Linguistics.\nHomero Gil de Z\u00fa\u00f1iga, Pablo Gonz\u00e1lez-Gonz\u00e1lez, and\nManuel Goyanes. 2025. Pathways to political per-\nsuasion: Linking online, social media, and fake news\nwith political attitude change through political discus-\nsion. American Behavioral Scientist , 69(2):240\u2013261.\nJennifer Golbeck, Matthew Mauriello, Brooke Aux-\nier, Keval H. Bhanushali, Christopher Bonk, Mo-\nhamed Amine Bouzaghrane, Cody Buntain, Riya\nChanduka, Paul Cheakalos, Jennine B. Everett,\nWaleed Falak, Carl Gieringer, Jack Graney, Kelly M.\nHoffman, Lindsay Huth, Zhenya Ma, Mayanka Jha,\nMisbah Khan, Varsha Kori, Elo Lewis, George Mi-\nrano, William T. Mohn IV , Sean Mussenden, Tam-\nmie M. Nelson, Sean Mcwillie, Akshat Pant, Priya\nShetye, Rusha Shrestha, Alexandra Steinheimer,\nAditya Subramanian, and Gina Visnansky. 2018.\nFake news vs satire: A dataset and analysis. In\nProceedings of the 10th ACM Conference on Web\nScience , WebSci \u201918, page 17\u201321, New York, USA.\nAssociation for Computing Machinery.\nTheodosis Goudas, Christos Louizos, Georgios Petasis,\nand Vangelis Karkaletsis. 2014. Argument extrac-\ntion from news, blogs, and social media. In Aristidis\nLikas, Konstantinos Blekas, and Dimitris Kalles, ed-\nitors, Artificial Intelligence: Methods and Applica-\ntions , volume 8445, pages 287\u2013299. Springer Inter-\nnational Publishing. Series Title: Lecture Notes in\nComputer Science.\nIvan Habernal and Iryna Gurevych. 2017. Argumenta-\ntion mining in user-generated web discourse. Com-\nputational Linguistics , 43(1):125\u2013179.\nStephen Harrington, Axel Bruns, Phoebe Matich, Daniel\nAngus, Edward Hurcombe, and Nadia Jude. 2024.\n\u2018big lies\u2019: understanding the role of political actors\nand mainstream journalists in the spread of disinfor-\nmation. Media International Australia .\nSepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long\nshort-term memory. Neural Computation , 9(8):1735\u2013\n1780. Conference Name: Neural Computation.\nJ. L. Hodges. 1958. The significance probability of\nthe smirnov two-sample test. Arkiv f\u00f6r Matematik ,\n3(5):469\u2013486.\nBenjamin D. Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real\nnews. In Eleventh International AAAI Conference on\nWeb and Social Media .Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li,\nDanding Wang, and Peng Qi. 2024. Bad actor, good\nadvisor: exploring the role of large language models\nin fake news detection. In Proceedings of the Thirty-\nEighth AAAI Conference on Artificial Intelligence\nand Thirty-Sixth Conference on Innovative Applica-\ntions of Artificial Intelligence and Fourteenth Sym-\nposium on Educational Advances in Artificial Intelli-\ngence , AAAI\u201924/IAAI\u201924/EAAI\u201924. AAAI Press.\nYen-Hao Huang, Ting-Wei Liu, Ssu-Rui Lee, Fer-\nnando Henrique Calderon Alvarado, and Yi-Shin\nChen. 2020. Conquering cross-source failure for\nnews credibility: Learning generalizable representa-\ntions beyond content embedding. In Proceedings of\nThe Web Conference 2020 , pages 774\u2013784. Associa-\ntion for Computing Machinery.\nHamid Karimi and Jiliang Tang. 2019. Learning hier-\narchical discourse-level structure for fake news de-\ntection. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n3432\u20133442, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nYoon Kim. 2014. Convolutional neural networks\nfor sentence classification. In Proceedings of the\n2014 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP) , pages 1746\u20131751,\nDoha, Qatar. Association for Computational Linguis-\ntics.\nDiederik P. Kingma and Jimmy Ba. 2019. Adam: A\nmethod for stochastic optimization. In 3rd Interna-\ntional Conference on Learning Representations .\nMarcin Konieczny. 2023. Ignorance, disinformation,\nmanipulation and hate speech as effective tools of\npolitical power. Policija i sigurnost , 32(2):123\u2013134.\nNeema Kotonya and Francesca Toni. 2019. Gradual\nargumentation evaluation for stance aggregation in\nautomated fake news detection. In Proceedings of\nthe 6th Workshop on Argument Mining , pages 156\u2013\n166, Florence, Italy. Association for Computational\nLinguistics.\nAnuj Kumar, Pardeep Kumar, Abhishek Yadav,\nSatyadev Ahlawat, and Yamuna Prasad. 2025. KG-\nFakeNet: A knowledge graph-enhanced model for\nfake news detection. In Proceedings of the Workshop\non Generative AI and Knowledge Graphs (GenAIK) ,\npages 109\u2013122, Abu Dhabi, UAE. International Com-\nmittee on Computational Linguistics.\nKristen D. Landreville and Cassie Niles and. 2019. \u201cand\nthat\u2019s a fact!\u201d: The roles of political ideology, psrs,\nand perceived source credibility in estimating factual\ncontent in partisan news. Journal of Broadcasting &\nElectronic Media , 63(2):177\u2013194.\nJohn Lawrence and Chris Reed. 2019. Argument min-\ning: A survey. Computational Linguistics , 45(4):765\u2013\n818.365\nFrancis L. F. Lee. 2024. Disinformation perceptions and\nmedia trust: The moderating roles of political trust\nand values. International Journal of Communication ,\n18:23.\nOr Levi, Pedram Hosseini, Mona Diab, and David Bro-\nniatowski. 2019. Identifying nuances in fake news\nvs. satire: Using semantic and linguistic cues. In\nProceedings of the Second Workshop on Natural\nLanguage Processing for Internet Freedom: Censor-\nship, Disinformation, and Propaganda , pages 31\u201335,\nHong Kong, China. Association for Computational\nLinguistics.\nAnna Lindahl. 2024. Disagreement in argumentation\nannotation. In Proceedings of the 3rd Workshop on\nPerspectivist Approaches to NLP (NLPerspectives)\n@ LREC-COLING 2024 , pages 56\u201366, Torino, Italia.\nELRA and ICCL.\nDavid S. Morris, Jonathan S. Morris, and Peter L. Fran-\ncia and. 2020. A fake news inoculation? fact check-\ners, partisan identification, and the power of misin-\nformation. Politics, Groups, and Identities , 8(5):986\u2013\n1005.\nMichelle R. Nelson, Chang Dae Ham, and Eric Haley.\n2021. What do we know about political advertising?\nnot much! political persuasion knowledge and ad-\nvertising skepticism in the united states. Journal of\nCurrent Issues & Research in Advertising , 42(4):329\u2013\n353.\nMatthew L. Newman, James W. Pennebaker, Diane S.\nBerry, and Jane M. Richards. 2003. Lying words:\nPredicting deception from linguistic styles. Personal-\nity and Social Psychology Bulletin , 29(5):665\u2013675.\nRay Oshikawa, Jing Qian, and William Yang Wang.\n2020. A survey on natural language processing for\nfake news detection. In Proceedings of the Twelfth\nLanguage Resources and Evaluation Conference ,\npages 6086\u20136093, Marseille, France. European Lan-\nguage Resources Association.\nJames Pennebaker and M Francis. 1999. Linguistic\ninquiry and word count: LIWC, 1999. Erlbaum Pub-\nlishers.\nVer\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401, Santa Fe, New Mexico, USA.\nAssociation for Computational Linguistics.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Janek\nBevendorff, and Benno Stein. 2018. A stylometric\ninquiry into hyperpartisan and fake news. In Proceed-\nings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 231\u2013240, Melbourne, Australia. Association\nfor Computational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varyingshades: Analyzing language in fake news and po-\nlitical fact-checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 2931\u20132937, Copenhagen,\nDenmark. Association for Computational Linguis-\ntics.\nGil Rocha, Lu\u00eds Trigo, Henrique Lopes Cardoso, Rui\nSousa-Silva, Paula Carvalho, Bruno Martins, and\nMiguel Won. 2022. Annotating arguments in a cor-\npus of opinion articles. In Proceedings of the Thir-\nteenth Language Resources and Evaluation Confer-\nence, pages 1890\u20131899, Marseille, France. European\nLanguage Resources Association.\nYasmim Mendes Rocha, Gabriel Ac\u00e1cio de Moura,\nGabriel Alves Desid\u00e9rio, Carlos Henrique\nde Oliveira, Francisco Dantas Louren\u00e7o, and\nLarissa Deadame de Figueiredo Nicolete. 2021.\nThe impact of fake news on social media and its\ninfluence on health during the COVID-19 pandemic:\na systematic review. Journal of Public Health .\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in BERTology: What we know about\nhow BERT works. Transactions of the Association\nfor Computational Linguistics , 8:842\u2013866.\nVictoria Rubin, Nadia Conroy, and Yimin Chen. 2015.\nTowards news verification: Deception detection meth-\nods for news discourse. In Proceedings of the\nHawaii International Conference on System Sciences\n(HICSS48) , pages 5\u20138.\nGiancarlo Ruffo, Alfonso Semeraro, Anastasia Gi-\nachanou, and Paolo Rosso. 2023. Studying fake news\nspreading, polarisation dynamics, and manipulation\nby bots: A tale of networks and language. Computer\nScience Review , 47:100531. Publisher: Elsevier.\nRudra Ranajee Saha, Laks V . S. Lakshmanan, and Ray-\nmond T. Ng. 2024. Stance detection with explana-\ntions. Computational Linguistics , 50(1):193\u2013235.\nTerence A. Shimp, Stacy L. Wood, and Laura Smaran-\ndescu. 2007. Self-generated advertisements: Tes-\ntimonials and the perils of consumer exaggeration.\nJournal of Advertising Research , 47:453\u2013461.\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-\nwon Lee, and Huan Liu. 2020. FakeNewsNet: A data\nrepository with news content, social context, and spa-\ntiotemporal information for studying fake news on\nsocial media. Big Data , 8(3):171\u2013188.\nManfred Stede and Jodi Schneider. 2019. Argumenta-\ntion Mining , 1st edition. Number 40 in Synthesis\nlectures on human language technologies. Morgan &\nClaypool Publishers.\nJinyan Su, Claire Cardie, and Preslav Nakov. 2024.\nAdapting fake news detection to the era of large\nlanguage models. In Findings of the Association\nfor Computational Linguistics: NAACL 2024 , pages\n1473\u20131490, Mexico City, Mexico. Association for\nComputational Linguistics.366\nShubhra Tewari, Renos Zabounidis, Ammina Kothari,\nReynold Bailey, and Cecilia Ovesdotter Alm. 2021.\nPerceptions of human and machine-generated articles.\nDigital Threats , 2(2).\nJames Thorne and Andreas Vlachos. 2018. Automated\nfact checking: Task formulations, methods and fu-\nture directions. In Proceedings of the 27th Inter-\nnational Conference on Computational Linguistics ,\npages 3346\u20133359, Santa Fe, New Mexico, USA. As-\nsociation for Computational Linguistics.\nTeun A. van Dijk. 1989. Dimensions of discourse. In\nHandbook of Discourse Analysis , 3. print edition,\npages 104\u2013112. Academic Press.\nFrancielle Vargas, Jonas D\u2018Alessandro, Zohar Rabi-\nnovich, Fabr\u00edcio Benevenuto, and Thiago Pardo.\n2022. Rhetorical structure approach for online de-\nception detection: A survey. In Proceedings of the\nThirteenth Language Resources and Evaluation Con-\nference , pages 5906\u20135915, Marseille, France. Euro-\npean Language Resources Association.\nWilliam Yang Wang. 2017. \u201cliar, liar pants on fire\u201d:\nA new benchmark dataset for fake news detection.\nInProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 2:\nShort Papers) , pages 422\u2013426, Vancouver, Canada.\nAssociation for Computational Linguistics.\nMaxwell Weinzierl and Sanda Harabagiu. 2024. Discov-\nering and articulating frames of communication from\nsocial media using chain-of-thought reasoning. In\nProceedings of the 18th Conference of the European\nChapter of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 1617\u20131631,\nSt. Julian\u2019s, Malta. Association for Computational\nLinguistics.\nW. Victor Yarlott, Cristina Cornelio, Tian Gao, and\nMark Finlayson. 2018. Identifying the discourse\nfunction of news article paragraphs. In Proceedings\nof the Workshop Events and Stories in the News 2018 ,\npages 25\u201333, Santa Fe, New Mexico, U.S.A. Associ-\nation for Computational Linguistics.\nSeunghak Yu, Giovanni Da San Martino, Mitra Mo-\nhtarami, James Glass, and Preslav Nakov. 2021. In-\nterpretable propaganda detection in news articles.\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing\n(RANLP 2021) , pages 1597\u20131605, Held Online. IN-\nCOMA Ltd.\nXiang Zhou, Heba Elfardy, Christos Christodoulopou-\nlos, Thomas Butler, and Mohit Bansal. 2021. Hidden\nbiases in unreliable news detection datasets. In Pro-\nceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 2482\u20132492, Online.\nAssociation for Computational Linguistics.367\nA Hyperparameters of the Models\nIn this appendix we present the hyperparameters\nand other implementation details from our models.\nA.1 Argumentation Type Classifier\nThe argumentation type classifier we used was im-\nplemented using the HuggingFace15package for\npython16using a PyTorch17backend.\nWe used the model bert-base-uncased from\nthe Transformers package. For this, we used the\nclass AutoModelForSequenceClassification .\nThe hyperparameters used were the default ones\nexcept for the following ones:\n\u2022 Evaluation strategy: steps\n\u2022 Evaluation steps: 100\n\u2022 Evaluation delay: 1\n\u2022 Number of training epochs: 3\n\u2022 Load best model at the end: True\n\u2022 Per device training batch size: 8\nA.2 Deceptive News Classifier\nThe deceptive news classifier was implemented in\nPyTorch using the Adam (Kingma and Ba, 2019)\noptimizer. We used a single Bi-LSTM layer fol-\nlowed by a linear layer. The last hidden states from\neach direction were concatenated and then fed to\nthe linear layer for classification.\nThe hyperparameters we used were the follow-\ning:\n\u2022 Learning rate: 1e-4\n\u2022 LSTM hidden dimension: 64\n\u2022 Batch size: 32\n\u2022 Dropout: 0.5\n\u2022 Max number of epochs: 2000\n\u2022 Early stopping at n steps: 15\n15https://huggingface.co/\n16https://www.python.org/\n17https://pytorch.org/B Number of Labels of the\nArgumentation Dataset\nDuring our preliminary exploration of the argumen-\ntation type classifier that the least represented class\nwas getting misclassified in all of our experiments.\nThus we decided to explore the possibility of col-\nlapsing some of the least represented labels into a\nsingle one.\nWe took into account the macro and weighted\nscores of the model, as well as the F1 score of\nthe least represented class. An important criterion\nwhen selecting the number of labels was to keep as\nmany labels as possible. This is particularly impor-\ntant as we want both our deceptive news classifier\nto learn the most out of the argumentative structure\nof the articles. Moreover, we want to be able to\nlook at the argumentation types in the articles to\nget further insights.\nAs we can see from Figure 4, the less labels we\nkeep, the better the performance of the model. This\nwas to be expected given that the more labels there\nare available, the less likely a model is to get a\ncorrect result if it is choosing randomly.\nWhen looking a the validation scores (see Fig-\nure 5) for the deceptive news classification task,\nwe realize that the models that kept just four la-\nbels model does slightly better than the others in\naverage. However, it is important to note that the\nboxplots for all groups overlap.\nWe decided to keep four labels as opposed to\ntwo or three as we believe that it would help with\nwhen qualitative analysis from Section 7, while\nkeeping more labels would mean that there is a risk\nthat neither the argumentation nor the deceptive\nnews classifiers would work as well as they would\notherwise.\nC Analyzing the Length of News Articles\nWhile looking through the datasets during our pre-\nliminary exploration we noticed that the length of\nthe articles varied greatly between credible and de-\nceptive ones. The distributions of the lengths of\narticles can be seen in Figure 6. This length is\nseen in terms of tokens according to the sentence\ntokenizer from NLTK.18\nWe decided to only maintain articles up to a\ncertain length for two reasons. The first one is\nthat we want to focus on the argumentation types\nwithin an article as a way of identifying whether\n18https://www.nltk.org/api/nltk.tokenize.sent_\ntokenize.html368\n(a) Macro F1 scores\n (b) Weighted F1 scores\n (c) Lowest F1 score among the classes\nFigure 4: Performance on the validation split when comparing different numbers of labels for the argumentation\ntype dataset. Unexpectedly, the fewer labels we keep, the better the performance of the model, excluding outliers.\nit is deceptive or not. One way to ensure this is\ncontrolling for variables that are not relevant to our\nhypothesis but that a model might pick up and learn\nspurious correlations from, such as the length of\nan article. The other reason is that the length of\nan article impacts how its discourse units interlock\n(van Dijk, 1989; Yarlott et al., 2018), meaning that\nargumentation will differ from shorter to longer\ntexts.\nWe decided to maintain articles from 100 to 800\nfor the PolitiFact dataset those from 100 to 500\nfor the FakeNews-2018 dataset as this is where the\nsummary statistics for both distributions start to\nconverge.\nD Detailed Results for the Classification\nTasks\nThis appendix contains tables presenting the nu-\nmerical results from our models. It is meant to\ncomplement the plots and values reported in Sec-\ntion 6, as well as the analyses contained within.\nThe results from the argumentation type classifi-\ncation task are reported in Table 4. The results for\nthe deceptive news classification task are reported\nin Tables 5 and 6 for the Politifact and FakeNews-\n2018 datasets, respectively.E Argumentation Types in Deceptive\nNews Articles\nHere we present the histograms comparing the dis-\ntributions of the ratio of argumentation type labels\nof the articles between credible and deceptive news.\nThe analysis of how these distributions vary can be\nfound in Section 7.\nThere is a plot for each argumentation type label\nand for each dataset. We have grouped them by\nargumentation type in order to more easily allow\ncomparisons across datasets. Figure 7 contains the\nhistograms for the anecdote label, Figure 8 those\nforassumption , Figure 9 those for testimony , and\nFigure 10 those for other .369\nFigure 5: Boxplot from the F1-score in the validation set of the PolitiFact dataset. While the boxes overlap across\nall groups, we see that the one with four labels performs slightly better than the others.\nF1 Macro F1 Weighted Accuracy Min F1 Score\nMajority\nBaseline0.21 0.605 0.722 0\nRandom\nBaseline0.249\u00b10.006 0.556 \u00b10.008 0.558 \u00b10.01 0.038 \u00b10.01\nBERT 0.69\u00b10.003 0.842 \u00b10.001 0.844 \u00b10.002 0.465\nTable 4: Results from our argumentation type classification task. We report the average accuracy and both the\nmacro and weighted F1 scores across 5 runs, as well as the standard deviation. We also report the F1 score for the\nminimum class to ensure the model works reasonably well across all labels.\n(a) Distribution of the lengths of the articles in the Politi-\nFact dataset.\n(b) Distribution of the lengths of the articles in the\nFakeNews-18 dataset.\nFigure 6: Lengths of the articles in both datasets for the deceptive news detection task. As we can see, there is a\nstrong tendency for deceptive news to be shorter.370\nF1 Macro F1 Weighted Accuracy\nBERT 0.486\u00b10.054 0.537 \u00b10.047 0.540 \u00b10.046\nSVM with\nLIWC Features0.747 0.772 0.773\nFakeFlow 0.780\u00b10.094 0.806 \u00b10.075 0.814 \u00b10.056\nArgumentation\nFeatures (ours)0.868\u00b10.027 0.880 \u00b10.024 0.881 \u00b10.024\nTable 5: Results from the deceptive news classification task on the PolitiFact dataset. We report the average accuracy,\nboth the average F1 macro and weighted scores across 25 runs, and the standard deviation. Our approach (in bold)\noutperforms all the baselines we compared to. Of note is that the standard deviation of our model is also smaller\nthan that of the other probabilistic models we are comparing with.\nF1 Macro F1 Weighted Accuracy\nBERT 0.496\u00b10.007 0.557 \u00b10.006 0.570 \u00b10.014\nSVM with\nLIWC Features0.856 0.870 0.873\nFakeFlow 0.407\u00b10.021 0.427 \u00b10.030 0.415 \u00b10.027\nArgumentation\nFeatures (ours)0.957\u00b10.009 0.961 \u00b10.008 0.961 \u00b10.008\nTable 6: Results from the deceptive news classification task on the FakeNews-2018 dataset. We report the average\naccuracy and both the average F1 macro and weighted scores across 25 runs, as well as the standard deviation. Our\napproach (bold) outperforms all the baselines we compare it to. The standard deviation of our model is also smaller\nthan that of the other models we compare it with.\n(a) Distribution for anecdote in the PolitiFact dataset.\n(b) Distribution for anecdote in the FakeNews-2018\ndataset.\nFigure 7: Histograms showing the distribution of the ratio of sentences labelled anecdote for both credible and\ndeceptive news. Anecdotes are more represented on deceptive articles on the PolitiFact dataset, while they appear at\nroughly the same rate the FakeNews-2018 dataset.371\n(a) Distribution for assumption in the PolitiFact dataset.\n(b) Distribution for assumption in the FakeNews-2018\ndataset.\nFigure 8: Histograms showing the distribution of the ratio of sentences labelled assumption for both credible\nand deceptive news. Assumptions appear less often on deceptive articles on the FakeNews-2018 dataset. There\ndifference for the distributions of the PolitiFact dataset is not statistically significant, meaning that we cannot rule\nout random chance as the reason behind this.\n(a) Distribution for testimony in the PolitiFact dataset.\n(b) Distribution for testimony in the FakeNews-2018\ndataset.\nFigure 9: Histograms showing the distribution of the ratio of sentences labelled testimony for both credible and\ndeceptive news. Testimonies appear more often on deceptive articles, regardless of the dataset.\n(a) Distribution for other in the PolitiFact dataset.\n (b) Distribution for other in the FakeNews-2018 dataset.\nFigure 10: Histograms showing the distribution of the ratio of sentences labelled other for both credible and\ndeceptive news. This label appears more often in credible articles, regardless of the dataset. This label includes the\nlabels statistics andcommon-ground from the Webis-16 dataset, as noted in Section 4.1.372", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Are You Trying to Convince Me or Are You Trying to Deceive Me? Using Argumentation Types to Identify Deceptive News", "author": ["RM S\u00e1nchez", "E Francis", "A Lindahl"], "pub_year": "2025", "venue": "\u2026 of the The 9th Workshop on \u2026", "abstract": "The way we relay factual information and the way we present deceptive information as truth  differs from the perspective of argumentation. In this paper, we explore whether these"}, "filled": false, "gsrank": 603, "pub_url": "https://aclanthology.org/2025.woah-1.31/", "author_id": ["QyAFAtMAAAAJ", "", "Bl8YcEMAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:yGgtVXa3oSkJ:scholar.google.com/&output=cite&scirp=602&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D600%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=yGgtVXa3oSkJ&ei=c7WsaKrNI5XUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:yGgtVXa3oSkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2025.woah-1.31.pdf"}}, {"title": "The COVID-19 social media infodemic", "year": "2020", "pdf_data": "1\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreportsThe COVID\u201119 social media \ninfodemic\nMatteo Cinelli1,2, Walter Quattrociocchi1,2,3*, Alessandro Galeazzi4, Carlo Michele Valensise5, \nEmanuele Brugnoli1, Ana Lucia Schmidt2, Paola Zola6, Fabiana Zollo1,2,7 & Antonio Scala1,3\nWe address the diffusion of information about the COVID\u201119 with a massive data analysis on Twitter, \nInstagram, YouTube, Reddit and Gab. We analyze engagement and interest in the COVID\u201119 topic and provide a differential assessment on the evolution of the discourse on a global scale for each \nplatform and their users. We fit information spreading with epidemic models characterizing the basic \nreproduction number \nR0 for each social media platform. Moreover, we identify information spreading \nfrom questionable sources, finding different volumes of misinformation in each platform. However, information from both reliable and questionable sources do not present different spreading patterns. \nFinally, we provide platform\u2011dependent numerical estimates of rumors\u2019 amplification.\nThe World Health Organization (WHO) defined the SARS-CoV-2 virus outbreak as a severe global  threat\n1. As \nforeseen in 2017 by the global risk report of the World Economic forum, global risks are interconnected. In \nparticular, the case of the COVID-19 epidemic (the infectious disease caused by the most recently discovered human coronavirus) is showing the critical role of information diffusion in a disintermediated news  cycle\n2.\nThe term infodemic3,4 has been coined to outline the perils of misinformation phenomena during the man -\nagement of disease  outbreaks5\u20137, since it could even speed up the epidemic process by influencing and frag-\nmenting social  response8. As an example, CNN has recently anticipated a rumor about the possible lock-down \nof Lombardy (a region in northern Italy) to prevent  pandemics9, publishing the news hours before the official \ncommunication from the Italian Prime Minister. As a result, people overcrowded trains and airports to escape from Lombardy toward the southern regions before the lock-down was put in place, disrupting the government initiative aimed to contain the epidemics and potentially increasing contagion. Thus, an important research challenge is to determine how people seek or avoid information and how those decisions affect their  behavior\n10, \nparticularly when the news cycle\u2014dominated by the disintermediated diffusion of information\u2014alters the way information is consumed and reported on.\nThe case of the COVID-19 epidemic shows the critical impact of this new information environment. The \ninformation spreading can strongly influence people\u2019s behavior and alter the effectiveness of the countermeas -\nures deployed by governments. To this respect, models to forecast virus spreading are starting to account for the behavioral response of the population with respect to public health interventions and the communication dynamics behind content  consumption\n8,11,12.\nSocial media platforms such as Y ouTube and Twitter provide direct access to an unprecedented amount of \ncontent and may amplify rumors and questionable information. Taking into account users\u2019 preferences and atti-tudes, algorithms mediate and facilitate content promotion and thus information  spreading\n13. This shift from the \ntraditional news paradigm profoundly impacts the construction of social  perceptions14 and the framing of narra-\ntives; it influences policy-making, political communication, as well as the evolution of public  debate15,16, especially \nwhen issues are  controversial17. Users online tend to acquire information adhering to their  worldviews18,19, to \nignore dissenting  information20,21 and to form polarized groups around shared  narratives22,23. Furthermore, when \npolarization is high, misinformation might easily  proliferate24,25. Some studies pointed out that fake news and \ninaccurate information may spread faster and wider than fact-based  news26. However, this might be platform-\nspecific effect. The definition of \u201cFake News\u201d may indeed be inadequate since political debate often resorts \nto labelling opposite news as unreliable or  fake27. Studying the effect of the social media environment on the \nperception of polarizing topics is being addressed also in the case of COVID-19. The issues related to the cur -\nrent infodemics are indeed being tackled by the scientific literature from multiple perspectives including the open\n1CNR-ISC, Rome, Italy. 2Universit\u00e0 Ca\u2019 Foscari di Venezia, Venice, Italy. 3Big Data in Health Society, Rome, \nItaly. 4Universit\u00e0 di Brescia, Brescia, Italy. 5Politecnico di Milano, Milan, Italy. 6CNR-IIT, Pisa, Italy. 7Center for the \nHumanities and Social Change, Venice, Italy. *email: w.quattrociocchi@unive.it\n2\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/dynamics of hatespeech and conspiracy  theories28,29, the effect of bots and automated  accounts30, and the threats \nof misinformation in terms of diffusion and opinions  formation31,32.\nIn this work we provide an in-depth analysis of the social dynamics in a time window where narratives and \nmoods in social media related to the COVID-19 have emerged and spread. While most of the studies on misin-\nformation diffusion focus on a single  platform17,26,33, the dynamics behind information consumption might be \nparticular to the environment in which they spread on. Consequently, in this paper we perform a comparative analysis on five social media platforms (Twitter, Instagram, Y ouTube, Reddit and Gab) during the COVID-19 outbreak. The dataset includes more than 8 million comments and posts over a time span of 45 days. We analyze user engagement and interest about the COVID-19 topic, providing an assessment of the discourse evolution \nover time on a global scale for each platform. Furthermore, we model the spread of information with epidemic \nmodels, characterizing for each platform its basic reproduction number ( \nR0 ), i.e. the average number of second-\nary cases (users that start posting about COVID-19) an \u201cinfectious\u201d individual (an individual already posting on COVID-19) will create. In epidemiology, \nR0\u00a0=\u00a01 is a threshold parameter. When R0<1 the disease will die \nout in a finite period of time, while the disease will spread for R0>1 . In social media, R0>1 will indicate the \npossibility of an infodemic.\nFinally, coherently with the classification provided by the fact-checking organization Media Bias/Fact  Check34 \nthat classifies news sources based on the truthfulness and bias of the information published, we split news outlets \ninto two groups. These groups are either associated to the diffusion of (mostly) reliable or (mostly) questionable contents and we characterize the spreading of information regarding COVID-19 relying on this classification. We find that users in mainstream platforms are less susceptible to the diffusion of information from question -\nable sources and that information deriving from news outlets marked either as reliable or questionable do not present significant difference in the way it spreads.\nOur findings suggest that the interaction patterns of each social media combined with the peculiarity of the \naudience of each platform play a pivotal role in information and misinformation spreading. We conclude the paper by measuring rumor\u2019s amplification parameters for COVID-19 on each social media platform.\nResults\nWe analyze mainstream platforms such as Twitter, Instagram and Y ouTube as well as less regulated social media platforms such as Gab and Reddit. Gab is a crowdfunded social media whose structure and features are Twitter-inspired. It performs very little control on content posted; in the political spectrum, its user base is considered to be far-right. Reddit is an American social news aggregation, web content rating, and discussion website based on collective filtering of information.\nWe perform a comparative analysis of information spreading dynamics around the same argument in differ -\nent environments having different interaction settings and audiences. We collect all pieces of content related to COVID-19 from the 1st of January to the 14th of February. Data have been collected filtering contents accord -\ningly to a selected sample of Google Trends\u2019 COVID-19 related queries such as: coronavirus , coronavirusout -\nbreak , imnotavirus , ncov , ncov -19, pandemic , wuhan . The deriving dataset is then composed of 1,342,103 posts \nand 7,465,721 comments produced by 3,734,815 users. For more details regarding the data collection refer to Methods.\nInteraction patterns. First, we analyze the interactions (i.e., the engagement) that users have with COVID-\n19 topics on each platform. The upper panel of Fig.\u00a0 1 shows users\u2019 engagement around the COVID-19 topic. \nDespite the differences among platforms, we observe that they all display a rather similar distribution of the users\u2019 activity characterized by a long tail. This entails that users behave similarly for what concern the dynamics of reactions and content consumption. Indeed, users\u2019 interactions with the COVID-19 content present attention \npatterns similar to any other  topic\n35. The highest volume of interactions in terms of posting and commenting can \nbe observed on mainstream platforms such as Y ouTube and Twitter.\nThen, to provide an overview of the debate concerning the disease outbreak, we extract and analyze the topics \nrelated to the COVID-19 content by means of Natural Language Processing techniques. We build word embed -\nding for the text corpus of each platform, i.e. a word vector representation in which words sharing common contexts are in close proximity. Moreover, by running clustering procedures on these vector representations, we \nseparate groups of words and topics that are perceived as more relevant for the COVID-19 debate. For further details refer to Methods. The results (Fig.\u00a0 1, middle panel) show that topics are quite similar across each social \nmedia platform. Debates range from comparisons to other viruses, requests for God blessing, up to racism, while the largest volume of interaction is related to the lock-down of flights.\nFinally, to characterize user engagement with the COVID-19 on the five platforms, we compute the cumulative \nnumber of new posts each day (Fig.\u00a0 1, lower panel). For all platforms, we find a change of behavior around the \n20th of January, that is the day that the World Health Organization (WHO) issued its first situation report on the COVID-19\n36. The largest increase in the number of posts is on the 21st of January for Gab, the 24th January for \nReddit, the 30th January for Twitter, the 31th January for Y ouTube and the 5th of February for Instagram. Thus, social media platforms seem to have specific timings for content consumption; such patterns may depend upon the difference in terms of audience and interaction mechanisms (both social and algorithmic) among platforms.\nInformation spreading. Efforts to simulate the spreading of information on social media by reproducing \nreal data have mostly applied variants of standard epidemic  models37\u201340. Coherently, we analyze the observed \nmonotonic increasing trend in the way new users interact with information related to the COVID-19 by using \nepidemic models. Unlike previous works, we do not only focus on models that imply specific growth mecha-nisms, but also on phenomenological models that emphasize the reproducibility of empirical  data\n41.\n3\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Most of the epidemiological models focus on the basic reproduction number R0 , representing the expected \nnumber of new infectors directly generated by an infected individual for a given time  period42. An epidemic \noccurs if R0>1,\u2014i.e., if an exponential growth in the number of infections is expected at least in the initial \nphase. In our case, we try to model the growth in number of people publishing a post on a subject as an infec -\ntive process, where people can start publishing after being exposed to the topic. While in real epidemics R0>1 \nhighlights the possibility of a pandemic, in our approach R0>1 indicates the emergence of an infodemic. We \nmodel the dynamics both with the phenomenological model  of43 (from now on referred to as the EXP model) \nand with the standard SIR (Susceptible, Infected, Recovered) compartmental  model44. Further details on the \nmodeling approach can be found in Methods.\nAs shown in Fig.\u00a0 2, each platform has its own basic reproduction number R0 . As expected, all the values of R0 \nare supercritical\u2014even considering confidence intervals (Table\u00a0 1)\u2014signaling the possibility of an infodemic. This \nobservation may facilitate the prediction task of information spreading during critical events. Indeed, according \nto this result we can consider information spreading patterns on each social media to predict social response when implementing crisis management plans.\nWhile \nR0 is a good proxy for the engagement rate and a good predictor for epidemic-like information spread-\ning, social contagion phenomena might be in general more  complex45\u201347. For instance, in the case of Instagram, \nwe observe an abrupt jump in the number of new users that cannot be explained with continuous models like the standard epidemic ones; accordingly, the SIR model estimates a value of \nR0\u223c102 that is way beyond what \nhas been observed in any real-world epidemic.\nFigure\u00a01.  Upper panel: activity (likes, comments, reposts, etc.) distribution for each social media. Middle panel: \nmost discussed topics about COVID-19 on each social media. Lower panel: cumulative number of content (posts, tweets, videos, etc.) produced from the 1st of January to the 14th of February. Due to the Twitter API limitations in gathering past data, the first data point for Twitter is dated January 27th.\n4\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Questionable VS reliable information sources. We conclude our analysis by comparing the diffusion \nof information from questionable and reliable sources on each platform. We tag links as reliable or question-\nable according to the data reported by the independent fact-checking organization Media Bias/Fact  Check34. In \norder to clarify the limits of an approach that is based on labelling news outlets rather than single articles, as for instance performed  in\n33,48, we report the definitions used in this paper for questionable and reliable information \nsources. In accordance with the criteria established by MBFC, by questionable information source we mean a news outlet systematically showing one or more of the following characteristics: extreme bias, consistent promo-tion of propaganda/conspiracies, poor or no sourcing to credible information, information not supported by evidence or unverifiable, a complete lack of transparency and/or fake news. By reliable information sources we \nmean news outlets that do not show any of the aforementioned characteristics. Such outlets can anyway produce \ncontents potentially displaying a bias towards liberal/conservative opinion, but this does not compromise the overall reliability of the source.\nFigure\u00a0 3 shows, for each platform, the plots of the cumulative number of posts and reactions related to reliable \nsources versus the cumulative number of posts and interactions referring to questionable sources. By interactions we mean the overall reactions, e.g. likes or other form or endorsement and comments, that can be performed with respect to a post on a social platform. Surprisingly, all the posts show a strong linear correlation, i.e., the number of posts/reactions relying on questionable and reliable sources grows with the same pace inside the same social media platform. We observe the same phenomenon also for the engagement with reliable and questionable \nsources. Hence, the growth dynamics of posts/interactions related to questionable news outlets is just a re-scaled \nversion of the growth dynamics of posts/reactions related to reliable news outlets; however, the re-scaling factor \n\u03c1 (i.e., the fraction of questionable over reliable) is strongly dependent on the platform.\nIn particular, we observe that in mainstream social media the number of posts produced by questionable \nsources represents a small fraction of posts produced by reliable ones; the same thing happens in Reddit. Among less regulated social media, a peculiar effect is observed in Gab: while the volume of posts from questionable sources is just the \n\u223c70% of the volume of posts from reliable ones, the volume of reactions for the former ones \nis \u223c3 times bigger than the volume for the latter ones. Such results hint the possibility that different platform \nreact differently to information produced by reliable and questionable news outlets.\nTo further investigate this issue, we define the amplification factor E as the average number of reactions to a \npost; hence, E is a measure that quantifies the extent to which a post is amplified in a social media. We observe \nthat the amplification EU (for unreliable posts posts produced by questionable outlets) and ER (for reliable posts \nFigure\u00a02.  Growth of the number of authors versus time. Time is expressed in number of days since 1st January \n2020 (day 1). Shaded areas represents [5%, 95%] estimates of the models obtained via bootstrapping least square estimates of the EXP model (upper panels) and of the SIR model (lower panels). For details the SIR and the EXP model, see SI.\nTable 1.  [5%, 95%] interval of confidence R0 as estimated from bootstrapping the least square fits parameter \nof the EXP and of the SIR model. Notice that, due to the steepness of the growth of the number of new authors in Instagram, \nR0 assumes unrealistic values \u223c102 for the SIR model.Gab Reddit You Tub e Instagram Twitter\nREXP\n0[1.42, 1.52] [1.44, 1.51] [1.56, 1.70] [2.02, 2.64] [1.65, 2.06]\nRSIR\n0[2.2, 2.5] [2.4, 2.8] [3.2, 3.5] [1.1\u00d7102, 1.6\u00d7102] [4.0, 5.1]\n5\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/posts produced by reliable outlets) vary from social media platform to social media platform and that assumes \nthe largest values in Y ouTube and the lowest in Gab. To measure the permeability of a platform to posts from questionable/reliable news outlets, we then define the coefficient of relative amplification \n\u03b1=EU/ER . It is a \nmeasure of whether a social media amplifies questionable ( \u03b1> 1 ) or reliable ( \u03b1< 1 ) posts. Results are shown in \nTable\u00a0 2. Among mainstream social media, we notice that Twitter is the most neutral ( \u03b1\u223c1 i.e. EU\u223cER ), while \nY ouTube amplifies questionable sources less (  \u03b1\u223c4/10 ). Among less popular social media, Reddit reduces the \nimpact of questionable sources (  \u03b1\u223c1/2 ), while Gab strongly amplifies them (  \u03b1\u223c4).\nTherefore, we conclude that the main drivers of information spreading are related to specific peculiarities of \neach platform and depends upon the group dynamics of individuals engaged with the topic.\nFigure\u00a03.  Upper panels: plot of the cumulative number of posts referring to questionable sources versus \nthe cumulative number of posts referring to reliable sources. Lower panel: plot of the cumulative number of engagements relatives to questionable sources versus the cumulative number of engagements relative to reliable sources. Notice that a linear behavior indicates that the time evolution of questionable posts/engagements is just a re-scaled version of the time evolution of reliable posts/engagements. Each plot indicates \nthe regression coefficients \n\u03c1 , representing the ratio among the volumes of questionable and reliable posts ( \u03c1post ) \nand engagements ( \u03c1eng ). In more popular social media, the number of questionable posts represents a small \nfraction of the reliable ones; same thing happens in Reddit. Among less popular social media, a peculiar effect \nis observed in Gab: while the volume of questionable posts is just the \u223c70% of the volume of reliable ones, the \nvolume of engagements for questionable posts is \u223c3 times bigger than the volume for reliable ones. Further \ndetails concerning the regression coefficients are reported in Methods.\nTable 2.  The average engagement of a post is the number of reactions expected for a post and is a measure of \nhow much a post is amplified in each social media platform. The average engagement EU (for unreliable post) \nand ER (for reliable post) vary from platform to platform, and are the largest in Twitter and the lowest in Gab. \nThe coefficient of relative amplification \u03b1=EU/ER measures whether a social media amplifies more unreliable \n( \u03b1> 1 ) or reliable ( \u03b1< 1 ) posts. Among more popular social media platforms, we notice that Twitter is the \nmost neutral ( \u03b1\u223c1% i.e. EU\u223cER ), while Y ouTube amplifies unreliable sources less ( \u03b1\u223c4/10 ). Among less \npopular social media platforms, Reddit reduces the impact of unreliable sources ( \u03b1\u223c1/2 ) while Gab strongly \namplifies them ( \u03b1\u223c4).EUER\u03b1\nGab 5.6 1.4 3.9\nReddit 22.7 40.1 0.55\nTwitter 15.1 15.6 0.97\nYou Tu b e 1.4\u00d71043.9\u00d71040.35\n6\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Conclusions\nIn this work we perform a comparative analysis of users\u2019 activity on five different social media platforms during \nthe COVID-19 health emergency. Such a timeframe is a good benchmark for studying content consumption dynamics around critical events in a times when the accuracy of information is threatened. We assess user engagement and interest about the COVID-19 topic and characterize the evolution of the discourse over time.\nFurthermore, we model the spread of information using epidemic models and provide basic growth param-\neters for each social media platform. We then analyze the diffusion of questionable information for all channels, finding that Gab is the environment more susceptible to misinformation dissemination. However, information deriving from sources marked either as reliable or questionable do not present significant differences in their its spreading patterns. Our analysis suggests that information spreading is driven by the interaction paradigm imposed by the specific social media or/and by the specific interaction patterns of groups of users engaged with the topic. We conclude the paper by computing rumor\u2019s amplification parameters for social media platforms.\nWe believe that the understanding of social dynamics between content consumption and social media plat -\nforms is an important research subject, since it may help to design more efficient epidemic models accounting for social behavior and to design more effective and tailored communication strategies in time of crisis.\nMethods\nData collection. Table\u00a0 3 reports the data breakdown of the five social media platforms. Different data col-\nlection processes have been performed depending on the platform. In all cases we guided the data collection by a set of selected keywords based on Google Trends\u2019 COVID-19 related queries such as: coronavirus, pandemic, coronaoutbreak, china, wuhan, nCoV , IamNotAVirus, coronavirus_update, coronavirus_transmission, corona-virusnews, coronavirusoutbreak.\nThe Reddit dataset was downloaded from the Pushi ft.io archive, exploiting the related API. In order to filter \ncontents linked to COVID-19, we used our set of keywords.\nIn Gab, although no official guides are available, there is an API service that given a certain keyword, returns \na list of users, hashtags and groups related to it. We queried all the keywords we selected based on Google Trends and we downloaded all hashtags linked to them. We then manually browsed the results and selected a set of hashtags based on their meaning. For each hashtag in our list, we downloaded all the posts and comments linked to it.\nFor Y ouTube, we collected videos by using the Y ouTube Data API by searching for videos that matched our \nkeywords. Then an in depth search was done by crawling the network of videos by searching for more related \nvideos as established by the Y ouTube algorithm. From the gathered set, we filtered the videos that matched \ncoronavirus, nCov, corona virus, corona-virus, corvid, covid or SARS-CoV in the title or description. We then collected all the comments received by those videos.\nFor Twitter, we collect tweets related to the topic coronavirus by using both the search and stream endpoint \nof the Twitter API. The data derived from the stream API represent only 1% of the total volume of tweets, further filtered by the selected keywords. The data derived from the search API represent a random sample of the tweets containing the selected keywords up to a maximum rate limit of 18000 tweets every 10 minutes.\nSince no official API are available for Instagram data, we built our own process to collect public contents \nrelated to our keywords. We manually took notes of posts, comments and populated the Instagram Dataset.\nMatching ability. We consider all the posts in our dataset that contain at least one URL linking to a website \noutside the related social media platfrom (e.g., tweets pointing outside Twitter). We separate URLs in two main categories obtained using the classification provided by MediaBias/FactCheck (MBFC). MBFC provides a clas-sification determined by ranking bias in four different categories, one of them being Factual/Sourcing. In that category, each news outlet is associated to a label that refers to its reliability as expressed in three labels, namely \nConspiracy-Pseudoscience, Pro-Science or Questionable. Noticeably, also the Questionable set include a wide \nrange of political bias, from Extreme Left to Extreme Right.\nUsing such a classification, we assign to each of these outlets a binary label that partially stems from the \nlabelling provided by MBFC. We divide the news outlets into Questionable and Reliable. All the outlets already classified as Questionable or belonging to the category Conspiracy-Pseudoscience are labelled as Questionable, the rest is labelled as Reliable. Thus, by questionable information source we mean a news outlet systematically showing one or more of the following characteristics: extreme bias, consistent promotion of propaganda/con -\nspiracies, poor or no sourcing to credible information, information not supported by evidence or unverifiable, a Table 3.  Data breakdown of the number of posts, comments and users for all platforms.Posts Comments Users Period\nGab 6,252 4,364 2,629 01/01\u201314/02\nReddit 10,084 300,751 89,456 01/01\u201314/02\nYou Tu b e 111,709 7,051,595 3,199,525 01/01\u201314/02\nInstagram 26,576 109,011 52,339 01/01\u201314/02\nTwitter 1,187,482 \u2013 390,866 27/01\u201314/02\nTotal 1,342,103 7,465,721 3,734,815\n7\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/complete lack of transparency and/or fake news. By reliable information sources we mean news outlets that do not \nshow any of the aforementioned characteristics. Such outlets can anyway produce contents potentially displaying a bias towards liberal/conservative opinion, but this does not compromise the overall reliability of the source.\nConsidering all the 2637 news outlets that we retrieve from the list provided by MBFC we end up with 800 \noutlets classified as Questionable 1837 outlets classified as Reliable. Using such a classification we quantify our \noverall ability to match and label domains of posts containing URLs, as reported in Table\u00a0 4.The matching ability \nthat is low doesn\u2019t refer to the ability of identifying known domain but to the ability of finding the news outlets \nthat belong to the list provided by MBFC. Indeed in all the social networks we find a tendency towards linking to other social media platforms, as shown in Table\u00a0 5.\nText analysis. To provide an overview of the debate concerning the virus outbreak on the various platforms, \nwe extract and analyze all topics related to COVID-19 by applying Natural Language Processing techniques to the written content of each social media platform. We first build word embedding for the text corpus of each platform, then, to assess the topics around which the perception of the COVID-19 debate is concentrated, we cluster words by running the Partitioning Around Medoids (PAM) algorithm on their vector representations.\nWord embeddings, i.e., distributed representations of words learned by neural networks, represent words as \nvectors in \nRn bringing similar words closer to each other. They perform significantly better than the well-known \nLatent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) for preserving linear regularities among words and computational efficiency on large data  sets\n49. In this paper we use the Skip-gram  model50 to construct \nword embedding of each social media corpus. More formally, given a content represented by the sequence of words \nw1,w2,...,wT , we use stochastic gradient descent with gradient computed through backpropagation \n rule51 for maximizing the average log probability\nwhere k is the size of the training window. Therefore, during training the vector representations of closely related \nwords are pushed to be close to each other.\nIn the Skip-gram model, every word w is associated with its input and output vectors, uw and vw , respectively. \nThe probability of correctly predicting the word wi given the word wj is defined as\nwhere V is the number of words in the corpus vocabulary. Two major parameters affect the training quality: the \ndimensionality of word vectors, and the size of the surrounding words window. We choose 200 as vector dimen-\nsion\u2014that is typical value for training large dataset\u2014and 6 words for the window.(1)1\nTT\ufffd\nt=1\uf8ee\n\uf8f0k\ufffd\nj=\u2212klogp(wt+j|wt)\uf8f9\n\uf8fb\n(2)p(wi|wj)=exp/parenleftBig\nuT\nwivwj/parenrightBig\nV/summationdisplay\nl=1exp/parenleftBig\nuT\nlvwj/parenrightBigTable 4.  Number of posts containing a URL, matching ability and classification for each of the five platforms.Gab Reddit You Tub e Instagram Twitter\nPosts containing a URL 3,778 10,084 351,786 1,328 356,448\nMatched 0.47 0.55 0.035 0.09 0.27\nQuestionable 0.38 0.045 0.064 0.05 0.10\nReliable 0.62 0.955 0.936 0.95 0.90\nTable 5.  Fraction of URLs pointing to social media. Table should be read as entries in each row link to entries \nin each column. For example, Gab links to Reddit 0.003.Gab Reddit You Tub e Instagram Twitter Facebook\nGab 0.003 0.002 0.001 0.002 0.138 \u223c\u00a00\nReddit 0.043 0.006 0.009 0.001 \u223c\u00a00 0\nYou Tu b e 0 \u223c\u00a00 0.292 \u223c\u00a00 0.088 0.081\nInstagram 0 0 0.003 0 0.001 0.001\nTwitter 0.059 0.001 0.257 0.003 \u223c\u00a00 \u223c\u00a00\n8\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Before applying the tool, we reduced the contents to those written in English as detected with cld3 . Then we \ncleaned the corpora by removing HTML code, URLs and email addresses, user mentions, hashtags, stop-words, \nand all the special characters including digits. Finally, we dropped words composed by less than three characters, words occurring less than five times in all the corpus, and contents with less than three words.\nTo analyze the topics related to COVID-19, we cluster words by PAM and using as proximity metric the cosine \ndistance matrix of words in their vector representations. In order to select the number of clusters, k, we calculate \nthe average silhouette width for each value of k . Moreover, for evaluating the cluster stability, we calculate the \naverage pairwise Jaccard similarity between clusters based on 90% sub-samples of the data. Lastly, we produce word clouds to identify the topic of each cluster. To provide a view about the debate around the virus outbreak, we define the distribution over topics \n/Theta1c for a given content c  as the distribution of its words among the word \nclusters. Thus, to quantify the relevance of each topic within a corpus, we restrict to contents c  with max\ufffdc>0.5 \nand consider them uniquely identified as a single topic each. Table\u00a0 6 shows the results of the text cleaning and \ntopic analysis for all the data.\nEpidemiological models. Several mathematical models can be used to analyse potential mechanisms that \nunderline epidemiological data. Generally, we can distinguish among phenomenological models that emphasize the reproducibility of empirical data without insights in the mechanisms of growth, and more insightful mecha-nistic models that try to incorporate such  mechanisms\n41.\nTo fit our cumulative curves, we first use the adjusted exponential model  of43 since it naturally provides an \nestimate of the basic reproduction number R0 . This phenomenological model (from now on indicated as EXP) has \nbeen successfully employed in data-scarce settings and shown to be on-par with more traditional compartmental models for multiple emerging diseases like Zika, Ebola, and Middle East Respiratory  Syndrome\n43.\nThe model is defined by the following single equation:\nHere, I is incidence, t  is the number of days, R0 is the basic reproduction number and d  is a damping factor \naccounting for the reduction in transmissibility over time. In our case, we interpret I  as the number Cauth of \nauthors that have published a post on the subject.\nAs a mechanistic model, we employ the classical SIR  model44. In such a model, a susceptible population can \nbe infected with a rate \u03b2 by coming into contact with infected individuals; however, infected individuals can \nrecover with a rate \u03b3 . The model is described by a set of differential equations:\nwhere S is the number of susceptible, I  is the number of infected and R  is the number of recovered. In our case, \nwe interpret the number I+R as the number Cauth of authors that have published a post on the subject.\nIn the SIR model, the basic reproduction number R0=\u03b2/\u03b3 corresponds to the ration among the rate of \ninfection by contact \u03b2 and the rate of recovery \u03b3 . Notice that for the SIR model, vaccination strategies correspond \nto bringing the system in a situation where S<N/R0 ; in such a way, both the number of infected will decrease.\nTo estimate the basic reproduction numbers REXP\n0 and RSIR\n0 for the EXP and the SIR model, we use least square \nestimates of the models\u2019  parameters42. The range of parameters is estimated via  bootstrapping41,52.\nLinear regression coefficients. Table\u00a0 7 reports the regression coefficient \u03c1 , the intercept and the R2 values \nfor the linear fit of Fig.\u00a0 3. High values of R2 confirm the linear relationship between reliable and questionable \nsources in information diffusion.(3) I=/bracketleftbiggR0\n(1+d)t/bracketrightbiggt\n(4)\u2202tS=\u2212\u03b2S\u00b7I/N\n\u2202tI=\u03b2S\u00b7I/N\u2212\u03b3I\n\u2202tR=\u03b3ITable 6.  Results of text cleaning and analysis for all the corpora.Cleaned contents Vocabulary size Topics Contents with max\ufffd> 0.5\nInstagram 21,189 posts 15,324 17 4,467\nTwitter 638,214 posts 22,587 21 369,131\nGab 5,853 posts 3,024 19 2,986\nReddit 10,084 posts 1,968 34 6,686\nYou Tu b e 815,563 comments 35,381 30 679,261\n9\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Data availability\nThe datasets generated during and/or analysed during the current study are available from the corresponding \nauthor on reasonable request.\nReceived: 11 April 2020; Accepted: 15 September 2020\nReferences\n 1. Organization, W .\u00a0H. Naming the coronavirus disease (COVID-19) and the virus that causes it. https  ://www.who.int/emerg  encie  \ns/disea  ses/novel -coron  aviru  s-2019/techn ical-guida  nce/namin  g-the-coron  aviru  s-disea  se-(covid -2019)-and-the-virus -that-cause  \ns-it (2020 (accessed April 9, 2020)).\n 2. Quattrociocchi, W . Part 2-social and political challenges: 2.1 western democracy in crisis? In Global Risk Report World Economic \nForum  (2017).\n 3. WHO Situation Report 13. https ://www.who.int/docs/defau  lt-sourc  e/coron  aviru  se/situa  tion-repor  ts/20200  202-sitre p-13-ncov-v3.\npdf?sfvrs  n=195f4  010_6. Accessed: 2010-09-30.\n 4. Zarocostas, J. How to fight an infodemic. Lancet  395, 676 (2020).\n 5. Organization, W .\u00a0H. Director-general\u2019s remarks at the media briefing on 2019 novel Coronavirus on 8 February 2020. https ://www.\nwho.int/dg/speec  hes/detai  l/direc  tor-gener al-s-remar  ks-at-the-media -briefi  ng-on-2019-novel -coron  aviru  s---8-febru  ary-2020  (2020 \n(accessed April 9, 2020)).\n 6. Mendoza, M., Poblete, B. & Castillo, C. Twitter under crisis: Can we trust what we RT?. Proceedings of the first workshop on social \nmedia analytics  71\u201379 (2010).\n 7. Starbird, K., Maddock, J., Orand, M., Achterman, P . & Mason, R.\u00a0M. Rumors, false flags, and digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing. IConference 2014 Proceedings (2014).\n 8. Kim, L., Fast, S. M. & Markuzon, N. Incorporating media data into a model of infectious disease transmission. PLoS ONE 14, 1 \n(2019).\n 9. John, T. & Ben\u00a0Wedeman, C. Italy prohibits travel and cancels all public events in its northern region to contain Coronavirus. https  \n://editi  on.cnn.com/2020/03/08/europ  e/italy  -coron  aviru  s-lockd own-europ  e-intl/index  .html  (2020 (accessed April 9, 2020)).\n 10. Sharot, T. & Sunstein, C. R. How people decide what they want to know. Nat. Hum. Behav.  2020, 1\u20136 (2020).\n 11. Shaman, J., Karspeck, A., Y ang, W ., Tamerius, J. & Lipsitch, M. Real-time influenza forecasts during the 2012\u20132013 season. Nat. \nCommun.  4, 1\u201310 (2013).\n 12. Viboud, C. & Vespignani, A. The future of influenza forecasts. Proc. Natl. Acad. Sci. 116, 2802\u20132804 (2019).\n 13. Kulshrestha, J. et\u00a0al.  Quantifying search bias: Investigating sources of bias for political searches in social media. In Proceedings of \nthe 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, 417\u2013432 (2017).\n 14. Schmidt, A. L. et al.  Anatomy of news consumption on Facebook. Proc. Natl. Acad. Sci. 114, 3035\u20133039 (2017).\n 15. Starnini, M., Frasca, M. & Baronchelli, A. Emergence of metapopulations and echo chambers in mobile agents. Sci. Rep. 6, 31834 \n(2016).\n 16. Schmidt, A. L., Zollo, F., Scala, A., Betsch, C. & Quattrociocchi, W . Polarization of the vaccination debate on Facebook. Vaccine  \n36, 3606\u20133612 (2018).\n 17. Del Vicario, M. et al. The spreading of misinformation online. Proc. Natl. Acad. Sci. 113, 554\u2013559 (2016).\n 18. Bessi, A. et al. Science vs. conspiracy: collective narratives in the age of misinformation. PLoS ONE 10, e0118093 (2015).\n 19. Cinelli, M. et al. Selective exposure shapes the Facebook news diet. PLoS ONE 15, e0229129 (2020).\n 20. Zollo, F. et al. Debunking in a world of tribes. PLoS ONE 12, 1 (2017).\n 21. Baronchelli, A. The emergence of consensus: a primer. R. Soc. Open Sci. 5, 172189 (2018).\n 22. Del Vicario, M. et al. Echo chambers: emotional contagion and group polarization on Facebook. Sci. Rep. 6, 37825 (2016).\n 23. Bail, C. A. et al.  Exposure to opposing views on social media can increase political polarization. Proc. Natl. Acad. Sci.  115, \n9216\u20139221 (2018).\n 24. Vicario, M. D., Quattrociocchi, W ., Scala, A. & Zollo, F. Polarization and fake news: early warning of potential misinformation targets. ACM Trans. Web (TWEB) 13, 1\u201322 (2019).\n 25. Wardle, C. & Derakhshan, H. Information disorder: Toward an interdisciplinary framework for research and policy making. \nCouncil of Europe report  27 (2017).\n 26. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science  359, 1146\u20131151 (2018).\n 27. Ruths, D. The misinformation machine. Science  363, 348\u2013348 (2019).\n 28. Schild, L. et\u00a0al.  \u201c go eat a bat, chang!\u201d: An early look on the emergence of sinophobic behavior on web communities in the face of \ncovid-19. arXiv preprint arXiv  :2004.04046   (2020).\n 29. Vel\u00e1squez, N. et\u00a0al. Hate multiverse spreads malicious COVID-19 content online beyond individual platform control. Preprint arXiv  \n:2004.00673   (2020).\n 30. Ferrara, E. What types of COVID-19 conspiracies are populated by twitter bots? First Monday  (2020).\n 31. Alam, F. et\u00a0al. Fighting the COVID-19 infodemic: modeling the perspective of journalists, fact-checkers, social media platforms, policy \nmakers, and the society . Preprint arXiv  :2005.00033   (2020).Table 7.  Coefficients and R2 of the linear regressions displayed in Fig.\u00a03.Dataset Type Intercept Coefficient ( \u03c1)R2\nGab Posts \u2212 22.321 0.695 0.996\nReddit Posts \u2212 4.111 0.047 0.997\nYoutu b e Posts 4.529 0.073 0.998\nTwitter Posts \u2212 151.44 0.110 0.998\nGab Reactions 74.577 2.721 0.981\nReddit Reactions \u2212 70.677 0.026 0.990\nYoutu b e Reactions \u2212 8854.33 0.025 0.986\nTwitter Reactions \u2212 2136.978 0.107 0.987\n10\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/ 32. Shahi, G.\u00a0K., Dirkson, A. & Majchrzak, T.\u00a0A. An exploratory study of COVID-19 misinformation on twitter . Preprint arXiv \n:2005.05710   (2020).\n 33. Bovet, A. & Makse, H. A. Influence of fake news in twitter during the 2016 us presidential election. Nat. Commun.  10, 1\u201314 (2019).\n 34. (MBFC), M. B.\u00a0C. Media bias/fact check, the most comprehensive Meida bias check resource. https ://media  biasf actch  eck.com/  \n(2020 (accessed April 9, 2020)).\n 35. Romero, D.\u00a0M., Meeder, B. & Kleinberg, J. Differences in the mechanics of information diffusion across topics: idioms, political \nhashtags, and complex contagion on twitter. In Proceedings of the 20th international conference on World wide web, 695\u2013704 (2011).\n 36. Organization, W .\u00a0H. Novel Coronavirus (2019-NCOV) situation report-1 21 January 2020. https ://www.who.int/docs/defau  lt-sourc  \ne/coron  aviru  se/situa  tion-repor  ts/20200  121-sitre  p-1-2019-ncov.pdf?sfvrs  n=20a99  c10_4  (2020 (accessed April 9, 2020)).\n 37. Pellis, L. et al. Eight challenges for network epidemic models. Epidemics  10, 58\u201362 (2015).\n 38. Liu, Y. et al. Characterizing super-spreading in microblog: an epidemic-based information propagation model. Physica A 463, \n202\u2013218 (2016).\n 39. Skaza, J. & Blais, B. Modeling the infectiousness of twitter hashtags. Physica A  465, 289\u2013296 (2017).\n 40. Davis, J. T., Perra, N., Zhang, Q., Moreno, Y . & Vespignani, A. Phase transitions in information spreading on structured popula-\ntions. Nat. Phys.  2020, 1\u20137 (2020).\n 41. Chowell, G. Fitting dynamic models to epidemic outbreaks with quantified uncertainty: a primer for parameter uncertainty, \nidentifiability, and forecasts. Infect. Dis. Model. 2, 379\u2013398 (2017).\n 42. Ma, J. Estimating epidemic exponential growth rate and basic reproduction number. Infectious Disease Modelling  (2020).\n 43. Fisman, D. N., Hauck, T. S., Tuite, A. R. & Greer, A. L. An idea for short term outbreak projection: nearcasting using the basic reproduction number. PLoS ONE  8, 1 (2013).\n 44. Bailey, N.\u00a0T. et\u00a0al.  The mathematical theory of infectious diseases and its applications  (Charles Griffin & Company Ltd, 5a Crendon \nStreet, High Wycombe, Bucks HP13 6LE, 1975).\n 45. Centola, D. The spread of behavior in an online social network experiment. Science  329, 1194\u20131197 (2010).\n 46. Del Vicario, M., Scala, A., Caldarelli, G., Stanley, H. E. & Quattrociocchi, W . Modeling confirmation bias and polarization. Sci. \nRep. 7, 40391 (2017).\n 47. Baumann, F., Lorenz-Spreen, P ., Sokolov, I. M. & Starnini, M. Modeling echo chambers and polarization dynamics in social net -\nworks. Phys. Rev. Lett. 124, 048301 (2020).\n 48. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during the 2016 us presidential \nelection. Science  363, 374\u2013378 (2019).\n 49. Mikolov, T., Yih, W .-T. & Zweig, G. Linguistic regularities in continuous space word representations. In Proceedings of the Con -\nference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 746\u2013751 (Association for Computational Linguistics  2013 (Georgia, Atlanta, 2013).\n 50. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J. Distributed representations of words and phrases and their compo-\nsitionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems\u2014Volume 2, NIPS\u201913, \n3111\u20133119 (Curran Associates Inc., Red Hook, NY , USA, 2013).\n 51. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by back-propagating errors. Nature  323, 533\u2013536. https  \n://doi.org/10.1038/32353  3a0 (1986).\n 52. Efron, B. & Tibshirani, R. J. An Introduction to the Bootstrap  (CRC Press, London, 1994).\nAuthor contributions\nM.C., A.G., C.M.V ., A.L.S., P .Z. collected and prepared the data. All authors conceived the experiments. M.C., \nA.G., C.M.V ., A.L.S., E.B., and A.S. conducted the experiments. All authors analysed the results, wrote and reviewed the manuscript.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to W .Q.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat  iveco  mmons .org/licen  ses/by/4.0/.\n\u00a9 The Author(s) 2020", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The COVID-19 social media infodemic", "author": ["M Cinelli", "W Quattrociocchi", "A Galeazzi"], "pub_year": "2020", "venue": "Scientific reports", "abstract": "We address the diffusion of information about the COVID-19 with a massive data analysis on  Twitter, Instagram, YouTube, Reddit and Gab. We analyze engagement and interest in the"}, "filled": false, "gsrank": 607, "pub_url": "https://www.nature.com/articles/s41598-020-73510-5", "author_id": ["3qOq_28AAAAJ", "_OCIc6UAAAAJ", "DK0tXAIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Wkw9MHsziXAJ:scholar.google.com/&output=cite&scirp=606&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D600%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Wkw9MHsziXAJ&ei=c7WsaKrNI5XUieoPmrax2A8&json=", "num_citations": 2837, "citedby_url": "/scholar?cites=8109069208240606298&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Wkw9MHsziXAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-020-73510-5.pdf"}}, {"title": "'Is climate science taking over the science?': A corpus-based study of competing stances on bias, dogma and expertise in the blogosphere", "year": "2020", "pdf_data": "ARTICLE\n\u2018Is climate science taking over the science? \u2019:A\ncorpus-based study of competing stances on bias,\ndogma and expertise in the blogosphere\nLuis P\u00e9rez-Gonz\u00e1lez1\u2709\nClimate change science has become an increasingly polarized site of controversy, where\ndiscussions on epistemological rigour are dif \ufb01cult to separate from debates on the impact\nthat economic and political interests have on the production of evidence and the constructionof knowledge. Little research has been conducted so far on the antagonistic discursiveprocesses through which climate knowledge is being contested and traditional forms ofexpertise are being (de-)legitimized \u2014whether by members of the scienti \ufb01c community or\nnon-scientist actors. This corpus-based study contributes to previous scholarship on theclimate science controversy in a number of respects. Unlike earlier studies based on theanalysis of mainstream media articles, this paper interrogates a corpus of climate change blogposts published by scientists, journalists, researchers and lobbyists laying claim to core,contributory and interactional forms of expertise \u2014as conceptualized within the third wave of\nscience studies. Further, the corpus informing this study has been designed to re \ufb02ect the\ncomplex and multivoiced nature of the climate knowledge production process. Drawn from\ufb01ve different blogs, the views represented are not con \ufb01ned to the two poles between which\nthe entrenched dialectic of \u2018alarmists \u2019versus \u2018deniers \u2019is typically played out in the climate\nscience debate. Following a systemic functional conceptualization of dialogic engagement asa means of positioning authorial voices vis-\u00e0-vis competing perspectives construed andreferenced in a text, this paper reports on bloggers \u2019use of three lexical items ( bias,dogma and\npeer review ) to expose their reliance on (non-)epistemic values. Concordances and a range of\nvisualization tools are used to gain systematic insights into the network of lexical choices thatobtain around these items, and to gauge whether/how bloggers construct coherent authorialsubjectivities in a bid to claim expert status and/or question the recognition of other playersin the debate.https://doi.org/10.1057/s41599-020-00582-z OPEN\n1Centre for Translation and Intercultural Studies, University of Manchester, Manchester, UK.\u2709email: Luis.Perez-Gonzalez@manchester.ac.uk\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 1\n1234567890():,;\nIntroductionTheGenealogies of Knowledge Internet corpus is a collection\nof English texts published in a range of online news outlets\nand blogs written by journalists, academics and activists\nsituated mainly on the radical right and left of the political\nspectrum. The Internet corpus features texts where these engaged\nonline actors challenge and rede \ufb01ne key cultural concepts per-\ntaining to the body politic, whether along populist or pre-\n\ufb01gurative lines; alongside this material, it also holds a body of\ntexts problematizing concepts that underpin established scienti \ufb01c\ndiscourses and the role they currently play in the construction\nand circulation of knowledge.1Among the outlets included in the\nlatter group, this study focuses on climate change blogs, con-\nceptualized here as increasingly politicized and polarized sites of\ncontroversy, where epistemological discussions on the quality of\nthe science are dif \ufb01cult to separate from questions of scienti \ufb01c\nknowledge construction. Whether by raising suspicions of\nestablished forms of expertise, advocating new epistemic frame-\nworks of environmental governance, or even denouncing gov-\nernments \u2019interference with the work of scientists employed by\npublic bodies, this collection of texts exposes forms of contesta-\ntion against \u201cpower at its extremities, in its ultimate destinations\n\u2026where it becomes capillary \u201d(Foucault, 1980 , p. 96). Exercising\nthese forms of resistance through blogs favours the emergence of\nlocal communities of social practice as alternative regimes of\nexpertise governance and knowledge construction \u2014often outside\nthe control of national and supranational structures of political\nand/or corporate power.\nOver the last decade, a growing body of research within the\n\ufb01eld of science communication has investigated how media shape\npublic perceptions of the impact of anthropogenic climate change\nand facilitate the \u201ctransitioning from [public] awareness and\nconcern to action \u201d(Moser, 2016 , p. 345). Studies gauging the\nimpact of media coverage on the public understanding of climate\nchange (e.g. Feldman et al., 2015 ; Brevini and Lewis, 2018 ) have\nexplored how political, corporate or consumerist discourses are\ncontesting the weight of evidence about the causes and con-sequences of this phenomenon in the public arena; recent\nresearch has also revealed the extent to which collective percep-\ntions of climate change re \ufb02ect the considerable ground that\npolitical actors have gained vis-\u00e0-vis their scienti \ufb01c counterparts\nin climate news coverage over the last three decades (Chinn et al.,\n2020 ). As digital media outlets continue to increase the public \u2019s\nexposure to a widening range of competing climate change dis-\ncourses animated by an ever more varied array of participants\nand stakeholders, the reasons why individuals \u201cchoose news\noutlets where they expect to \ufb01nd culturally congruent arguments\nabout climate change \u201dthat are consistent with their \u201ccultural way\nof life \u201d(Newman et al., 2018 , p. 985) are becoming an object of\nincreasing research interest.\nThe discursive frames, narratives and metaphors used by the\nmedia to represent climate change knowledge have also been\nstudied by linguists seeking to gain a better understanding of their\nimpact on people \u2019s\u201cunderstanding of the phenomenon, their\nperception of the risks involved, the value judgements they make,\nand the emotional reactions they experience \u201d(Fl\u00f8ttum, 2017 ,\np.1). Among these language-centred approaches to the study of\nthe climate change debate, corpus-based analyses have offered\nuseful quantitative insights into various aspects of this site of\nknowledge production. Dayrell and Urry (\n2015 ) draw on a large\nBrazilian Corpus on Climate Change to test the hypothesis that\nBrazilian news media take and promote \u201ca consensus or gradu-\nalist view of climate change \u201d(2015 , p. 265) that leaves very little\nroom for sceptical voices. By quantifying the occurrence of key\nlexical items (including names of selected organizations, scientists\nand public \ufb01gures aligned with the consensus view), theydemonstrate that gradualism2prevails over climate change\nscepticism in Brazilian media discourses. Similarly, a corpus of\nBrazilian daily newspaper articles extracted from the newsaggregator service Factiva informs Dayrell \u2019s(2019 ) study of the\nevolution of Brazilian media \u2019s climate discourses over a 10-year\nperiod. After measuring the distribution of a selection of key\nlexical items and phrases such as \u2018mudan\u00e7a clim\u00e1tica \u2019and\n\u2018emiss\u00f5es de carbono \u2019and their respective collocates across time,\nDayrell interprets the \ufb01ndings against a range of opinion polls on\npublic perceptions of climate change. Her analysis reveals how\nBrazilian media discourses have shifted over time, \u201cengendering a\nstriking level of climate change concern \u201d(2019 , p. 164) and\n\u201cencouraging engagement with the debate, especially in relation\nto deforestation \u201d(2019 , p. 167). Beyond these corpus-based stu-\ndies of mainstream media discourses, researchers have turned to\ncorpora of other types of textual material \u2014including social media\nfeeds (Sch\u00e4fer, 2012 ; Auer et al., 2014 ;O\u2019Neill et al., 2015 ) and\nblogs (Salway et al., 2016 ; Salway, 2017 )\u2014to conduct automatic\ntext analyses. Salway \u2019s grammar induction algorithm, a new\ntechnique for elucidating linguistic patterning, \u201cinduces salient\ninformation structures from unannotated corpora \u201d(2017 , p. 161)\nto highlight discursive features of individual blogs using statistical\nrather than linguistic information.\nThe present study also adopts a corpus-based methodology\nbut, unlike earlier analyses of corpora holding mainstream media\narticles, it interrogates a collection of posts on climate change\ndrawn from \ufb01ve blogs, i.e. a subset of the Genealogies of Knowl-\nedge Internet corpus referred to in this article as the Climate\nScience Blogger Corpus (CSBC).3In focusing on blogs, this paper\nalso intersects with a fast developing body of scholarship within\nthe wider \ufb01eld of science communication that investigates climate\nchange debates held in online public arenas between scienti \ufb01c\nexpert bloggers and their readers (L\u00f6rcher and Taddicken, 2017 );\nand explores how commenters on controversial science blogs are\nconsolidating increasingly polarized publics, rather than fostering\na more deliberative engagement across mutually opposing con-stituencies (Metcalfe, 2020 ). In order to facilitate the study of the\nmultivoiced debate on climate science, CSBC features material\nwritten from a range of competing perspectives, not con \ufb01ned to\nthe two poles between which the entrenched dialectic between\n\u2018alarmists \u2019and \u2018deniers \u2019is played out (Howarth and Sharman,\n2015 ). This compilation of posts published by scientists, jour-\nnalists, researchers and lobbyists therefore seeks to represent the\nviews through which various individuals and organizations lay\nclaim to traditionally sanctioned forms of expertise, purport to\npossess alternative forms of expertise, and narrate others \u2019per-\nspectives as belonging to the realm of pseudoscience. By fore-\ngrounding the range of experiences and narratives voiced in this\nselection of blog posts, CSBC provides an optimal vantage point\nto observe how climate science knowledge, where science is pitted\nagainst science, is fought in the public arena.\nAfter outlining a series of developments that have warranted\nthe characterization of climate science as a site of controversy\n(section \u201cClimate science as a site of controversy \u201d), this paper\ndraws on disciplinary insights from the \ufb01eld of expertise and\nexperience studies to gain a better understanding of ongoing\nnegotiations of expertise in the climate science blogosphere\n(section \u201cNegotiating contrasting certainties in the climate science\nblogosphere \u201d). While previous waves of science studies, notably\nthe sociology of scienti \ufb01c knowledge, have contributed to\ndemocratizing science by extending participation in technical\ndecision-making beyond the control of accredited scientists,\nstudies of expertise and experience set out to widen expert debate\nwithout diluting the notion of technical expertise by including the\ngeneral public. Under this framework, the negotiation ofARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n2 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\ncontrasting certainties in the climate science blogosphere is\naccounted for in terms of a struggle between different forms of\nexpertise and the dialectic between the epistemic and non-\nepistemic values embraced by different expert constituencies inthe public debate. As this paper is primarily interested in\nrevealing how bloggers engage with alternative stances construed\nas competing or complementary in the climate science debate, the\n\ufb01nal part of section \u201cNegotiating contrasting certainties in the\nclimate science blogosphere \u201dexplains how Martin and White \u2019s\n(2005 ) notion of \u2018engagement \u2019informs the analysis of online\ndebates in this alternative network of scienti \ufb01c knowledge pro-\nduction. After providing a full description of the composition of\ntheClimate Science Blogger Corpus in section \u201cInvestigating\nbloggers \u2019stances: Data and conceptual framework \u201d, section\n\u201cAnalysing CSBC bloggers \u2019construction of intersubjectivity: Bias,\ndogma, peer review \u201dmakes use of a concordance browser and a\nsuite of visualization tools developed as part of the Genealogies of\nKnowledge project to produce both quantitative and qualitative\ninsights into the language deployed by different actors in the\nclimate change debate. Ultimately, in keeping with the wider\nresearch agenda of the Genealogies of Knowledge project, of which\ncontestation of established knowledge is a main strand, the aim is\nto investigate the construction of intersubjectivity through which\nactors claim expert status and/or question the recognition of\nother players in the debate.\nClimate science as a site of controversy\nSince 1998, the assessment of the growing evidence base available\non the impact of anthropogenic climate change has been\nentrusted to the Intergovernmental Panel on Climate Change(IPCC), a United Nations body tasked with scrutinizing published\nresearch to \u201cidentify where there is agreement in the science\ncommunity \u201d(IPCC, n.d.). The panel \u2019s reports translate scienti \ufb01c\nevidence into \u201cpolicy-relevant but not policy-prescriptive \u201d\nrecommendations (IPCC, n.d.) for member governments, effec-\ntively providing an internationally accepted authority on climate\nchange. But while a commitment to objectivity and neutrality\nunderpins IPCC \u2019s\u201cadaptation and mitigation \u201dproposals (IPCC,\nn.d.), the \u201centanglement of cultural meanings and policy-relevant\nfacts\u201d(Kahan et al., 2017 , p. 79) that frames the climate science\ndebate has unleashed a growing partisan polarization both among\npolitical elites and the public (Beck et al., 2014 ). In this context,\nthe recommendations issued by IPCC in 2016 to professionalize\nits communication strategies and enhance the readability of its\nof\ufb01cial reports as a way of reinforcing the trustworthiness of\nclimate science (Hulme, 2017 ) have failed to effect meaningful\nchange. With the politicization of climate science and environ-\nmental governance continuing to rise unabated (Carrozza, 2015 ),\neven compelling evidence endorsed by IPCC reports is routinely\nchallenged in the public arena, as new agents become involved in\nthe production of climate knowledge and \u201cmore convoluted\nroutes to the construction of facts \u201dgain traction (Epstein, 1995 ,\np. 411).\nSince it made its appearance in the early 1970s, the sociology of\nscienti \ufb01c knowledge (SSK) \u2014also known as the second wave of\nscience studies \u2014has paid much closer attention to issues of\nlegitimacy, participation and transparency in the context of\nevidence-based environmental policy-making. Notably, SSK\nadvocates an epistemic shift towards social constructivism,\nunderstood as \u201cthe study of how complex scienti \ufb01c claims and\ntechnological products are put together out of heterogeneous\nconstruction materials \u201d(Jasanoff, 1999 , p. 66). From a SSK per-\nspective, science-based decisions should not be driven only by\nscienti \ufb01c practices that sever evidence from the social environ-\nment in which credentialed scientists are embedded (Jasanoff,2010 , p. 235). Indeed, as is generally acknowleged, policy-making\ninvolves \u201cmany steps, including devising the policy as an execu-\ntable plan, involving administration and implementation, goals\nand values, and interests that are bene \ufb01tted or harmed \u201d(Turner,\n2014 , p. 4). This constructivist turn in science studies and the\nreconceptualization of climate science as a social activity that it\nentails represent a major departure from mid-20th century\nsociology of science, which postulated that \u201csociological\naccounting had to stop at the door of scienti \ufb01c method and sci-\nenti\ufb01c knowledge \u201d(Shapin, 1995 , pp. 294 \u2013295) and propped up\nan information de \ufb01cit or linear model approach to science\ncommunication (Jasanoff and Wynne, 1998 ). Instead, SSK\nempowers citizens and stakeholders with relevant experience to\nbecome involved in decision-making where science intersects\nwith the political domain (Wynne, 1989 ). By blurring the dis-\ntinction between science and society and acknowledging the\ncentral role that social judgements play in environmental gov-\nernance, SSK brings into sharp relief the constitutive role of\ncitizen participation in the production of scienti \ufb01c evidence. This\nprocess of democratization ultimately seeks to enable a more\nproductive dialectic between the \u201clarger scales of scienti \ufb01c\nrepresentations \u201dand\u201csmaller scales of social meaning \u201d(Jasanoff,\n2010 , p. 238), and to recognize the contribution and \u201cvalue of\nlocal, indigenous, or other experiential knowledge \u201d(Collins and\nEvans, 2020 , p. 86).\nThe insight that climate science re \ufb02ects the struggle between\nscience and democracy at the point where evidence is brought to\nbear on policy decisions and governance is particularly pertinent\nin digital media culture \u2014where the blogs posts held in CSBC\noriginate. Under the knowledge aggregation logic that prevails in\nthe networked public sphere, \u201ca more connected, science-aware\n(and often sceptical) public \u201d(Gluckman, 2014 ) is capitalizing on\nthe affordances of digital technology to lay a claim to various\ncauses and asking more challenging questions from scientists and\ndecision-makers around issues that \u201cinvolve signi \ufb01cant values-\nbased judgements \u201d(Gluckman, 2014 ). But while the construtivist\nturn has set out a clear rationale to recognize the grounded typesof evidence provided by non-scientists and the challenge that\nexperience poses to credentialed expertise, SSK \u2019s conceptualiza-\ntion of expertise is not nuanced enough to inform an analysis of\nhow contrasting certainties are negotiated in the climate science\nblogosphere. Ultimately, the sociology of scienti \ufb01c knowledge\nfalls short of explaining \u201cwhat expertise consists of, the kinds of\ndecisions for which it is relevant \u201d(Collins and Evans, 2020 , p. 89)\nand\u201cthe reason for using the advice of scientists and technolo-\ngists in virtue of the things they do as scientists and technologists,\nrather than as individuals or as members of certain institutions \u201d\n(Collins and Evans, 2002 , p. 236).\nNegotiating contrasting certainties in the climate science\nblogosphere\nThe second wave of science studies and its push to democratize\nexpertise by opening up the construction of scienti \ufb01c knowledge\nto a wider group of citizens aptly recognizes the social judgements\nthat underpin scienti \ufb01c controversy and the extent to which the\nclimate science blogosphere challenges technocratic decision-\nmaking by consensus scientists. However, the logic behind the\nemergence of the constructivist approach can hardly be extended\nto account for a signi \ufb01cant development in the vibrant Anglo-\nphone climate crisis blogosphere. The growing participation of\nmembers of the scienti \ufb01c community in blogged debates with\nnon-scientists (Sharman, 2015 ) can be more productively regar-\nded as a reaction against a loose understanding of the \u2018citizen\nscientist \u2019notion and, more widely, as an attempt to \u201cdraw a\nboundary around the body of \u2018technically quali \ufb01ed-by-experience \u2019HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 3\ncontributors to technical decision-making \u201d(Collins and Evans,\n2002 , p. 237). With Anglophone mainstream media often giving\nsceptical voices more prominent coverage than would be war-\nranted by the weight of the evidence supporting their claims,blogs provide scientists with an opportunity to retain control over\nthe knowledge circulating in the public arena (Poliakoff and\nWebb, 2007 ). Signi \ufb01cantly, scientists \u2019active engagement in public\ndebate through blogging (Nisbet and Markowitz, 2015 ) has also\nbeen fostered by instances of Governmental meddling in the work\nof credentialed experts. Under George W. Bush \u2019s administration,\nfor example, \u201cpolitical appointees and staffers were accused of\nimproperly editing and censoring scienti \ufb01c agency reports; con-\ntrolling the public and media statements of government scientists;\nand manipulating the use of scienti \ufb01c expertise and evidence \u201d\n(Nisbet and Markowitz, 2015 , p. 136). The widely held perception\nby climate scientists, among other experts, that the White House\nwas tampering with their work to strengthen the administration \u2019s\nanti-regulatory stance on fossil fuel industries, and to cast doubt\namong the public about the credibility of climate science, sig-\nni\ufb01cantly contributed to the emergence of a community of sci-\nentists who took to the blogosphere to advocate the virtues of the\npositivist scienti \ufb01c tradition. In doing so, they effectively chose to\nleave behind\ntraditional approaches to communication that emphasize\nthe translation and dissemination of expert knowledge\n[and] are unlikely to reduce con \ufb02ict and promote\nconsensus. Simply focusing on the dissemination of\nscienti \ufb01c evidence tends to reinforce entrenched positions,\nsince such evidence is often suf \ufb01ciently tentative to\ninde\ufb01nitely support the values-based arguments and world-\nviews of competing sides (Nisbet and Markowitz, 2015 ,\np. 138).\nAmid the growing enmeshment of politics with science, the\nadoption of a more adversarial stance to intervene in public debate\nis emerging as the preferred strategy by scientists involved in public\noutreach and dissemination activities, including but not limited toblogging\n4.A sO p p e n h e i m e re ta l .( 2019 ) note, scientists used to\nfavour univocality as a means to assert their epistemic dominance,\neven when this self-imposed demand for watertight professional\nconsensus led them to downplay the likely effects of climate change\nin their exchanges with policy-makers and the public. However, as\nother actors have become involved in the construction of con-\nsensus and the management of knowledge disputes (Oppenheimer\net al., 2019 ), differences of opinion \u2014even within the scienti \ufb01c\ncommunity \u2014must now be actively exposed and debated.\nThe advent of the third wave of science studies \u2014also referred\nto as studies of expertise and experience (SEE) \u2014at the turn of this\ncentury provides a framework under which this development can\nbe explored more productively. While accepting that policy-\nmaking in controversial domains of science should not be\ninformed exclusively by formally accredited evidence, the pro-\nponents of SEE effectively query how far the right of \u2018experience-\nbased experts \u2019\u2014i.e. ordinary citizens in possession of grounded\nexpertise \u2014to participate in technical decision-making should\nextend (Collins and Evans, 2002 ). Under SEE, the analytical focus\ntherefore shifts away from the construction of truth toward the\nacquisition and conceptualization of multiple forms of expertise.\nA\u2018realist model of expertise \u2019is thus proposed to\ndifferentiate \u201cthe scienti \ufb01c and technical input to decision-\nmaking from the political input \u201d(Collins and Evans, 2002 , p. 249)\nin a bid to \u201cexplain what expertise consists of, the kinds of\ndecisions for which it is relevant, and a way of telling who is and\nwho is not an expert \u201d(Collins and Evans, 2020 , p. 89).5\nThe theory underpinning the third wave of science studies\nrevolves around a categorization of expertise that was \ufb01rstoutlined by Collins and Evans ( 2002 ) and then elaborated into a\nmore detailed taxonomy presented as a \u2018periodic table of exper-\ntises\u2019in Collins and Evans ( 2007 ,2020 ). Under this taxonomy,\n\u2018specialist experts \u2019in a given \ufb01eld, whether they are formally\ntrained or not, are separated from non-specialists \u2014a category\ncomprised of certi \ufb01ed scientists whose specialism lies in a dif-\nferent \ufb01eld and the lay public. Not only does this division avoid\ncharacterizing the scienti \ufb01c community as the sole possessor of\ntechnical expertise. Apart from acknowledging the socially and\npolitically situated identity of scientists, it recognizes \u201cthe exis-\ntence of pockets of expertise among the citizenry \u201d(Collins and\nEvans, 2002 , p. 249), regardless of whether such experience-based\nexperts are credentialed or not. Ultimately, SEE \u2019s taxonomy of\nexpertise tries to draw a clearer boundary around those indivi-\nduals who can provide the best expert advice on a given issue, but\nwithout con \ufb02ating technical knowledge and political rights.\nUnder SEE \u2019s taxonomy, the climate change blogosphere fea-\ntured in CSBC can be seen as a site of struggle between competing\nforms of expertise. The \u2018core\u2019set of experts in the \ufb01eld would\nconsist of those scientists \u201cwho have actually done relevant\nexperiments, or who have developed or worked with theories \u201d\npertaining to climate science (Collins and Evans, 2002 , p. 260).\nUnlike members of the core set, experience-based bloggers (e.g.\npolitical lobbyists, journalists or specialists in other areas of sci-\nence) strive to acquire various degrees of specialist expertise by\nimmersing themselves in the climate change community. As\nCollins and Evans put it, \u201c\u2019[e]nculturation \u2019is the only way to\nmaster an expertise which is deeply laden with tacit knowledge\nbecause it is only through common practice with others that the\nrules that cannot be written down can come to be understood \u201d\n(2007, p. 24). From a SEE \u2019s perspective, those individuals who,\nthrough sustained enculturation, accrue enough expertise to\ncontribute to climate science with suf \ufb01cient competence are\ndeemed to hold \u2018contributory expertise \u2019(Collins and Evans, 2002 ,\np. 254). Although there is a considerable overlap between the\nnotions of core and contributory expertise (most individuals\nholding contributory expertise tend to be trained scientists),\nhighly quali \ufb01ed experience-based experts can also acquire con-\ntributory expertise (Caudill et al., 2019 , p. 6). By contrast, an\nindividual with \u2018interactional expertise \u2019, the second variety mas-\ntered through immersion in a community of practice, \u201cmay be\nable to understand scienti \ufb01c things, and to discuss scienti \ufb01c\nthings, but is still not able to doscienti \ufb01c things (Collins and\nEvans, 2007 , p. 35; emphasis in original). In their most recent\ncritique of these concepts, Collins and Evans ( 2020 ) reinforce\ntheir earlier view that all contributory experts are also interac-\ntional experts, but they also go on to claim that \u201cit is possible to\nacquire interactional expertise to the level of that possessed by a\ncontributory expert without mastering or even experiencing the\nphysical practices that de \ufb01ne the [relevant] domain of expertise \u201d\n(Collins and Evans, 2020 , p. 93).\nThe climate blogosphere can therefore be productively con-\nceptualized as a \u201c\u2019trading zone \u2019where questions over data,\nresearch priorities, participation and methodological approaches \u201d\n(Jasanoff and Wynne, 1998 , p. 61) have been negotiated among\nindividuals holding a range of expertises for a number of decades.\nThroughout the 1990s, the uncertainties arising from their\ndiverging perspectives on the \u2018co-production \u2019(Jasanoff and\nWynne, 1998 ), weighing and application of climate knowledge for\nthe purposes of environmental governance were accounted for\nunder the framework of \u2018post-normal science \u2019(Funtowicz and\nRavetz, 1991 ,1992 ,1993 ; Bremer et al., 2018 ). However, as the\ncontributory and interactional forms of expertise of non-certi \ufb01ed\nexperts have become widely recognized under SSK and SSE, cli-\nmate change science has thematized the legitimate role that\nexperts \u2019values play at various decision-points in the researchARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n4 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\nprocess, from problem-selection to hypothesis choice (Douglas,\n2009 ). The notions of \u2018(non-)epistemic \u2019or\u2018(non-)cognitive\nvalues \u2019that were once associated with the value-free ideal of\nscience have been therefore superseded by an alternative classi-\ufb01cation under its value-laden counterpart. In their direct role,\nvalues act as the reasons why experts accept a given set of pre-\nmises, draw upon a speci \ufb01c theory or declare that the evidence\navailable to substantiate a claim is suf \ufb01cient. By contrast, in their\nindirect role values are mobilized to manage uncertainty about\nthe quantity or epistemic quality of the evidence available to\nexperts, and to gauge the consequences of suboptimal decisions\nthat may arise when uncertainty is present in the \ufb01nal stages of\nthe research process (Douglas, 2009 , p. 96). The implications of\nthis focus on values for public perceptions of climate change have\nbeen laid bare in the work that Tangney ( 2017 ,2019a ,2019b ) has\nconducted from a policy-making perspective. Although the\nlegitimate role of ethical and social values in the research process\nis now widely recognized, the fact that certain types of experts\ntend to rely exclusively on speci \ufb01c types of evidence and values\ncan only serve to \u201cin\ufb02ame polarized climate change debate \u201dand\n\u201cidentity-de \ufb01ning group commitments \u201d(2019a , p. -s132). As\nTangney notes, the clash between rhetorical policy-making tactics\nemployed by competing expert constituencies driven by their\npreferred values has failed to \u201cresolve environmental controversy\nand the pressing need for a pragmatic reframing of policy pro-\nblems to allow for solutions based on bipartisan values \u201d(Tang-\nney, 2019a , p. 131).\nThis paper interrogates the CSBC corpus to study how bloggers\nholding competing views on climate change go about negotiating\nthe intersubjective stance that they mobilize in their posts to\nclaim relevant expertise and contest the voices of other actors in\nthe debate. Adopting a SEE perspective that recognizes a legit-\nimate role for core, contributory and interactional experts in the\nclimate change debate, this CSBC-based study will analyse how\nthe dialectic between evidence and values is mediated by bloggers\nholding varying forms of expertise; explore how bloggers attempt\nto (de-)legitimize other voices; and examine how alternativetranslations of evidence into policy are proposed and negotiated.\nJust as experience-based experts may feel that core experts over-\nrely on epistemic values to \u201cpromote risk-based decision-making\nunder erroneous ideals of linear-instrumental-rationality \u201d\n(Tangney, 2019b , p. 1), credentialed experts will oppose \u2018politi-\ncized \u2019science when non-epistemic values play an indirect role at\nearly stages of the research process that should be informed\nexclusively by evidence (Douglas, 2009 , pp. 112 \u2013113).\nAmong the various approaches that have been used by scholars\nin the past to investigate how writers express their \u201cattitude or\nstance towards, viewpoint on, or feelings about the entities or\npropositions \u201dthat they write about (Thompson and Hunston,\n2000 , p. 5), I draw on Martin and White \u2019s(2005 ) con-\nceptualization of \u2018engagement \u2019, developed as part of their wider\ntheory of the language of evaluation in English within thetradition of systemic functional linguistics. Concerned with the\nstudy of \u201csourcing attitudes and the play of voices around opi-\nnions in discourse \u201d(Martin and White, 2005 , p. 35), the concept\nof engagement \ufb01ts within a heteroglossic understanding of dis-\ncourse informed by Bakhtin ( 1981 ). From this social dialogic\nperspective, speakers and writers engage with previous written or\nspoken locutions or anticipate potential reactions from other\nauthorial voices that have previously expressed or could choose to\narticulate contentious value positions on the issue under con-\nsideration. The notion of engagement therefore encompasses \u2014\nalthough it is not limited to \u2014\u201call those locutions which provide\nthe means for the authorial voice to position itself with respect to,\nand hence to \u2018engage \u2019with, the other voices and alternative\npositions construed as being in play in the current commu-\nnicative context \u201d(Martin and White, 2005 , p. 94). This frame-\nwork of intersubjective positioning is adopted here in recognition\nof the heteroglossic nature of climate science blogs as sites of\ncontroversy where traditional understandings of evidence and\nexpertise can be reinforced or undermined. Additional informa-\ntion on the way in which the notion of engagement is oper-\nationalized in this study is provided throughout section\n\u201cAnalysing CSBC bloggers \u2019construction of intersubjectivity: Bias,\ndogma, peer review \u201d.\nInvestigating bloggers \u2019stances: Data and conceptual\nframework\nThe Climate Science Blogger Corpus (CSBC) used in this study\nwas compiled with a view to capture varied shades of opinion\nalong the spectrum between the two polar extremes of the climate\nchange debate. The selection of blogs included in CSBC wasguided by three main criteria. As be \ufb01ts a corpus built to study\nhow traditional understandings of expertise and evidence are\ncontested in sites of techno-scienti \ufb01c dispute, the selected blogs\nadopt a clear and explicit stance on the climate change con-\ntroversy. They also represent various blogging agendas, in terms\nof motivations and the individual or collective authorship of the\nchosen outlets. Importantly, CSBC includes only blogs whose\nauthors granted their consent for the inclusion of their posts in\ntheGenealogies of Knowledge Internet corpus, which placed\nadditional constraints on the selection process.6\nCSBC consists of 448,608 tokens extracted from \ufb01ve blogs\ndealing with climate change issues in the US, UK and Australia.\nTable 1displays the composition of the corpus in terms of the\nblog\u2019s name, URL, number of posts and number of tokens for\neach blog. The bulk of the posts \u2014typically between 500 and 1500\ntokens each \u2014were published between 2007 and 2019, although\nthe vast majority were posted between 2014 and 2018. For the\npurposes of analysis and discussion, the \ufb01ve blogs included in\nCSBC are divided into two groups. The \u2018contrarian \u2019subset\n(CSBC-CON) comprises three blogs \u2014Australian Climate Mad-\nness,Science De \ufb01es Politics and Climate Depot . These seek to\nchallenge, to varying degrees, the scienti \ufb01c consensus embodied\nTable 1 Composition of the Genealogies of Knowledge Climate Science Blogger Corpus (CSBC).\nBlog URL # posts # tokens\nCONTRARIAN SUBSET (CSBC-CON)\nAustralian Climate Madness https://australianclimatemadness.com 169 34,080\nScience De \ufb01es Politics https://defyccc.com/ 49 48,414\nClimate Depot https://www.climatedepot.com/ 9 8,527\nTotal CSBC-CON 91,021\nACCEPTOR SUBSET (CSBC-ACC)\nDeSmog UK https://www.desmog.co.uk/ 218 252,968\nUnion of Concerned Scientists https://www.ucsusa.org/ 89 104,619\nTotal CSBC-ACC 357,587HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 5\nin the IPCC reports and the national policies emanating from the\npanel \u2019s recommendations. The \u2018acceptor \u2019subset (CSBC-ACC), on\nthe other hand, consists of two blogs \u2014DeSmog UK andUnion of\nConcerned Scientists of the United States of America (UCSUSA) \u2014\naligned with mainstream consensus.7In light of the present\nstudy \u2019s goals, the relatively modest overall size of this data set vis-\n\u00e0-vis the collections that often underpin large-scale corpus-based\nstudies does not constitute a major limitation. While capitalizing\nto some extent on the quantitative insights yielded by corpus\nanalysis tools, this paper ultimately aims to offer a framework for\nanalysing the linguistic expressions of intersubjective positioning\ndeployed by bloggers in the climate change debate rather than\nidentifying statistically salient linguistic patternings, as explained\nin section \u201cAnalysing CSBC bloggers \u2019construction of inter-\nsubjectivity: Bias,dogma ,peer review \u201d.\nThe contrarian subset (CSBC-CON) .Australian Climate Mad-\nness,8run by Simon Turnill, is an Australian blog carrying the\nsubheading \u201cJust don \u2019t tell me the debate is over \u201d. An engineer\nand lawyer by training, Turnill makes claims to contributory and\ninteractional expertise and boasts the capacity to offer more\nreliable reportage on climate change matters than specialist\njournalists. As a self-proclaimed expert, he acknowledges that\n\u201cclimate change is happening \u2014just like it has happened for 4.5\nbillion years, and will continue to happen \u201d(Australian Climate\nMadness, n.d.); despite his lukewarm acceptance of the funda-\nmentals of climate change, several sections of his blog feature\nlinks to sceptic material elsewhere. Signi \ufb01cantly, Turnill calls for\nthe need to \u201creview the evidence for and against anthropogenic\nglobal warming dispassionately \u201d(Australian Climate Madness,\nn.d.), thus tacitly hinting at the emotional dimension of the\nclimate change debate. Of note is Turnill \u2019s concern about \u201cthe\npoliticization of the scienti \ufb01c process \u201d(Australian Climate\nMadness, n.d.) at the hands of both the Australian government\nand mainstream media which, in his view, is skewing the results\nof climate science. Turnill has been quoted as saying that he\n\u201creally want[s] to see the integrity of the process upheld \u201d\n(Bachelard, 2011 ), which signals the extent to which he favours\nprocess over output legitimacy.9\nThe interplay between climate change and politics is also one of\nthe driving forces behind Science De \ufb01es Politics ,10a blog run by\nauthor, start-up founder, mathematician and cyber-security\nexpert Leo Goldstein. This blogger \u2019s concern over the \u201cpseudo-\nscience of climate alarmism \u201din the US (Science De \ufb01es Politics,\nn.d.) arises from what he perceives as the country \u2019s rapid\nintellectual degeneration, which \u201chas been especially pronounced\nin science, and [ \u2026] coincided with the erosion of the basic\nfreedoms that have existed [in the US] for more than 200 years,\nlike freedom of speech, religion, the press, and association \u201d\n(Science De \ufb01es Politics, n.d.). Goldstein lays a claim to the\npossession of interactional and contributory expertise by claiming\nto have created his blog \u201cwith the goal of using scienti \ufb01c and\ntechnological knowledge, applying the scienti \ufb01c method, [and]\nbeing non-partisan and non-political \u2014in this order \u201d(Science\nDe\ufb01es Politics, n.d.). Despite having acquired core expertise in\nother areas of science, he has reportedly funded denialist online\nads proclaiming that global warming is a hoax, that climate\nscience is not settled, and that there is no correlation between\nrising levels of greenhouse gases and higher temperatures all over\nthe planet (Tabuchi, 2017 ).\nClimate Depot ,11the third of the blogs included in the CSBC-\nCON subcorpus, presents itself as a US-based \u201cinformation\nclearinghouse and one stop shopping [sic] for reporters, policy-\nmakers, students, scientists and concerned citizens to get the\nlatest information on global warming and other keyenvironmental and energy issues \u201d(Climate Depot, 2009 ). In\npractice, however, media reports on the work of Climate Depot\ncon\ufb02ate the project with its executive director. Having run the\ncommunication operations of Republican politicians in the past,Marc Morano is well-known for courting controversy through his\nfrequent media appearances. The director of Climate Depot \u2019s\nstance vis-\u00e0-vis climate scientists and their expertise is articulated\non the depot \u2019s website, as well as in the documentary Merchants\nof Doubt12(Kenner, 2014 ), where Morano goes on record saying:\nI\u2019m not a scientist, but I do play one on TV occasionally.\nOk, hell, more than occasionally. [ \u2026] You go up against\nscientists, most of them are going to be in their own little\nsort of policy wonk world or area of expertise. Very arcane,\nvery hard to understand, hard to explain, and very boring\n(Merchants of Doubt Trailer, 2015 ).\nThe visibility of Climate Depot at the interface between science,\npolitics and media is such that, despite being widely regarded as a\nsource of unveri \ufb01able information seeking to undermine core\nexperts and the scienti \ufb01c consensus on climate science,13leading\nmainstream media14acknowledge its outstanding capacity to fuel\npublic climate change scepticism in the US.\nThe acceptor subset (CSBC-ACC) . The Union of Concerned\nScientists \u2019blog15\u2014the\ufb01rst of the two outlets included in the\nCSBC-ACC subcorpus \u2014bears witness to the increasingly fric-\ntional relations between US scientists, in their capacity as core\nexperts, and the White House administration. As was also the\ncase during G.W. Bush \u2019s presidency, Trump \u2019so f\ufb01cials have been\nknown to \u2018sanitize \u2019scienti \ufb01c reports on the environmental and\neconomic effects of climate change after delaying their release for\nseveral months (Waldman, 2019 ). They have also been known to\nblock the submission of written testimony on the implications of\nclimate change for national security before the United States\nHouse Permanent Select Committee on Intelligence because \u201cthe\nscienti \ufb01c foundation of the analysis did not comport with the\nadministration \u2019s position on climate change \u201d(Schoonover, 2019 ).\nUnderstandably, these practices have been contested by the 250-\nstrong community of scientists, communication specialists and\npolicy analysts whose remit is to \u201cuse rigorous, independent\nscience to solve our planet \u2019s most pressing problems \u201d(Union of\nConcerned Scientists, n.d.) or, as their blog subtitle states, to \u201cuse\nscience to make change \u201d. The Union of Concerned Scientists \u2019blog\nis therefore a good example of a virtual advocacy network driven\nby an activist agenda under which American core experts are now\n\u201corganizing protests, educating the public, and shaming their\nlocal governments and national representatives into action \u201dwhile\nstepping up their efforts to \u201ccommunicate their science \u201damid the\ngrowing politicization of the climate change debate (Meyer,\n2016 ). Their desire to assert their political agency in this debate is\nre\ufb02ected in the content of their posts, which often launch speci \ufb01c\nattacks against speci \ufb01c politicians and governmental bodies.\nFinally, DeSmog UK16was launched in 2014, as part of the\nwider DeSmog Blog initiative, \u201cto expose lobbying and spin\naround climate change and other environmental issues \u201d(DeSmog\nUK, n.d.). Bound by the UK \u2019s National Union of Journalists code\nof conduct, the journalists and researchers blogging through the\nDeSmog UK platform seek to \ufb01ght climate change misinformation\nby drawing on facts and hard evidence \u2014ultimately working, as\nthe blog subtitle proclaims, to \u201cclear the PR pollution that clouds\nclimate science \u201d. The premise underpinning DeSmog UK \u2019s\nblogging is that much of the climate denialism movement is\nfunded by the fossil fuel industry as part of a wider attack on\ndemocracy. Delaying remedial action on climate change requires\ngaining in \ufb02uence over environmental and energy policy makersARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n6 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\nas well as creating doubts in the minds of the public about the\nreliability of science \u2014hence the need to stand up for scienti \ufb01c\nevidence as a means to protect our political institutions and\npublic processes of deliberation from the interference of corporate\nlobbying (DeMelle, 2014 ).17\nAnalysing CSBC bloggers \u2019construction of intersubjectivity:\nBias,dogma ,peer review\nThe study of engagement as a way of positioning one \u2019s authorial\nvoice or dialogic perspective (Martin and White, 2005 ) has ten-\nded to focus on the analysis of grammatically marked stance and,\nless commonly, on paralinguistic devices and value-laden lexis\n(Biber, 2006 ). This paper contributes to redressing this imbalance\nby focusing on the bloggers \u2019use of lexical items for the purposes\nof dialogic engagement. A list of the most frequent tokens in\nCSBC was generated to assist with the selection of the lexicalitems to be analysed. Having set a cut-off point of at least 15\noccurrences, the list was scrutinized to identify relevant evaluative\ntokens. To ensure that the analysis of my two relatively small\nsubcorpora retained a strong focus on the most productive lexical\nexpressions of engagement, I concentrated on selected nouns and\nitems that function as pre-modi \ufb01ers within noun phrases. Based\non the frequency list, pre-modifying items within noun phrases\nwere used in CSBC much more frequently than other word\nclasses to negotiate intersubjectivity. Tokens belonging to more\nthan one syntactic category (e.g. \u2018objective \u2019, which can potentially\nact as a noun or an adjective) were also discarded to ensure that\nthe lexical items under analysis were semantically and syntacti-\ncally comparable. Finally, the list was \ufb01ltered to retain only those\nitems used to qualify perceptions and applications of climate\nscience, leaving out labels that can be used to refer both to\nindividuals and policies (e.g. \u2018warmist \u2019,\u2018sceptic \u2019). Among the\nitems featuring in the \ufb01nal list to be considered for analysis (Table 2),\nand in consideration of space limitations, this paper explores only\ninstances of engagement realized through lexical items pertaining\nto the exercise of scienti \ufb01c expertise, i.e. bias/biases ,dogma and\npeer review . Consequently, it leaves out tokens like misinforma-\ntionorconspiracy that, while evaluative, do not refer primarily to\nstandards of epistemological value. The centrality of peer review\nsystems in the production of expert knowledge by weeding out\nscienti \ufb01c biases and dogmatic premises accounts for its selection\nalongside the other two items.\nMy analysis of bloggers \u2019alignment with their putative reader-\nship and the issues construed as matters of contention in their\nblog posts will examine the construction of engagement primarily\nthrough \u2018dialogically contractive \u2019structures (Martin and White,\n2005 ).18Dialogically contractive approaches to the negotiation of\nintersubjectivity \u201cchallenge, fend off or restrict the scope \u201dof\nalternative positions and voices within heteroglossic contexts\n(Martin and White, 2005 , p. 102). While they do not acknowledge\nexplicitly what others may think about the proposition at hand,contraction-oriented resources make an important contribution\ntowards the construction of dialogic positioning. By framingtextual propositions as being up for discussion, dialogically con-\ntractive lexis construes a readership that is receptive to further\nargumentation and discussion, whether it agrees or disagrees with\nthe blogger \u2019s stance. Bias/-es,peer-review anddogma are examples\nof dialogically contractive lexical items featuring in CSBC that\nwill now be analysed in turn. Speci \ufb01cally, they fall under the\nsubcategory of \u201cpronouncing \u201dresources, for they allow bloggers\nto foreground their own subjectivity, while implying \u201cthe pre-\nsence of some resistance, some contrary pressure of doubt or\nchallenge against which the authorial voice asserts itself \u201d(Martin\nand White, 2005 , p. 128).\nA Metafacet visualization19(Fig. 1) for a concordance listing\n102 occurrences of bias,biases andbiased in CSBC reveals that\nthese tokens are used in four of the \ufb01ve blogs included in the\ncorpus. Considering that the size of CSBC-ACC is approximately\nfour times that of CSBC-CON, the fact that the occurrence of\nthese tokens, measured in absolute terms, is similar across the two\nsubcorpora shows that their frequency is signi \ufb01cantly higher in\nthe contrarian subset in proportional terms.\nA search for bias*in the CSBC-CON corpus returns 34\noccurrences of bias orbiases \u2014once the lines where these tokens\nare used as a verb have been removed from the concordance\nusing a \u2018Delete Line \u2019function available through the GoK inter-\nface.20As the number of occurrences retrieved is relatively low,\nthe collocational patterns captured by the Mosaic visualization21\n(Fig. 2) for this search are not scrutinized primarily with a view to\ndiscriminate between patterns on the basis of their statistical\nsaliency. Instead, this visualization is used to examine the asso-\nciations that the search item establishes with other lexical choicesTable 2 Key lexical items for the study of intersubjective\nengagement in CSBC.\nPosition in frequency list Token # Occurrences\n227 consensus 214\n1080 bias 55\n1250 misinformation 48\n1567 conspiracy 37\n1987 controversy 28\n2672 peer-review 19\n2941 biases 17\n3200 dogma 16\nFig. 1 Metafacet visualization for a concordance featuring bias/-es/-edin\nCSBC (102 lines), \ufb01ltered by Internet outlet and sorted by frequency.\nFig. 2 Mosaic visualization of bias/-es in CSBC-CON (34 lines).\nCollocation strength: Local, MI3 (EXP Scale).22HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 7\nin its environment \u2014as displayed in the Mosaic tiles on both sides\nof the search item. Ultimately, the network of lexical choices\nobserved around the search item is analysed to establish whether\nor not the authorial voices in CSBC-CON and CSBC-ACC seek\nand manage to construct coherent authorial subjectivities through\nwhich bloggers can position themselves in the debate vis-\u00e0-vis\ntheir dialogic adversaries.\nAs the mosaic in Fig. 2shows, contrarian outlets label biases\nrelating to climate change science as \u2018pro-alarmist \u2019in L1 position\n(i.e. in the \ufb01rst column to the left of the search node) or attribute\nthem to the \u2018warmist \u2019stance associated with scienti \ufb01c consensus,\nalso in L1 position. Further contrarian outlets present such biases\nas\u2018intentional \u2019in L3 position (i.e. in the \ufb01rst column to the left of\nthe search node) and hence partisan. Crucially, CSBC-CON\noutlets are keen to expose the \u2018institutionalized \u2019(position L1)\nnature of biases in major institutions and corporations, some of\nwhich \u2014like IPCC (example 1) and Google (multiple concordance\nlines) \u2014are captured in the Mosaic display in Fig. 2(positions L2\nand L1/L2, respectively. Other corporations such as Wikipedia\n(example 2) and ABC (example 3) do not appear in the Mosaic\ndisplay but \ufb01t the same pattern. The contrarian authorial voice\nalso seeks to assert itself against what it perceives as the ideolo-\ngical and political nature of climate change biases, which are\nframed as \u2018anti-conservative \u2019(L1), \u2018heavy leftist \u2019(L1) and hence\n\u2018anti-American \u2019(L1) (example 2).\n(1) Text int001459 | He is healthily sceptical of the AGW\nscaremongers (and has written books on the subject) and\nthis week takes apart the crumbling edi \ufb01ce that is the IPCC\n[\u2026] John McLean has written a superb expos\u00e9 of the\ninherent bias of the IPCC: Climate Science Corrupted [ \u2026]\nit is an eye-opening read.23\nSource : Turnill ( 2010a ), published in Australian Climate\nMadness .\n(2) Text int001292 | Wikipedia has well known problems that\ninclude: the unexplained exit of respected executives and\ndirectors; the foreign control of the Board of Wikimedia\nFoundation and its corporate body; the leftist background\nof the CEO and key members of the executive team; heavy\nleftist and anti-American bias ; tight control by the Board\nof the nomination, election, and certi \ufb01cation of the editorial\nhierarchy; and susceptibility of the nomination and electionprocess to fraud by the executives and/or the Board\nmembers.\nSource : Goldstein ( 2017b ), published in Science De \ufb01es\nPolitics .\n(3) Text int001410 |\u2026the ABC (Australian Broadcasting\nCorporation) is a mouthpiece for Labor, the Left in general\nand the Green agenda. OK, you \u2019re saying, tell me something\nI didn \u2019t know. Yes, yes, true, but these two examples\nperfectly encapsulate the blatant and institutionalized bias\nof the ABC , which \ufb02ies in the face of its legal obligations as\nan impartial public broadcaster, but somehow it escapesany sanction for doing so.\nSource : Turnill ( 2012 ), published in Australian Climate\nMadness .\nSearching for bias*in the CSBC-ACC corpus returns 38\nconcordance lines where bias orbiases are used as nouns. The\nscrutiny of collocates featured in the Mosaic visualization of this\nsubcorpus (Fig. 3) indicates that a signi \ufb01cant number of the\noccurrences of bias andbiases in CSBC-ACC can be observed in\ndiscussions on scienti \ufb01c methodology (e.g. \u2018datasets \u2019, position R4\nin the Fig. 3Mosaic) in example 4; research equipment (e.g.\nvarious types of instruments that do not appear in the Mosaic\ndisplay but \ufb01t the same pattern) in example 5; research metrics \u2014\ne.g.\u2018bias ef \ufb01\nciency \u2019(position R1) versus \u2018mean-media approaches \u2019\n(position R3) and the science \u2018publication \u2019system (position L1).\nOf particular note is the role that \u2018industry-funded \u2019(position L1)\nresearch plays in the production of biased climate science\nknowledge, as is further illustrated in example 6.\n(4) Text int002567 | Moreover, each instance of the presumed\nonset was not randomly chosen but chosen speci \ufb01cally\nbecause of the low subsequent warming. We describe this as\nselection bias \u2026some of the biases that affect the datasets\nand projections were known, or knowable, at the time.\nSource : Kirby ( 2018 ), published in DeSmog UK .\n(5) Text int001332 | In fact, NOAA scientists were using the\nscienti \ufb01cm e t h o dt oi d e n t i f yt h e biasthat exists in temperature\nmeasuring instruments and making their data more accurate\nby taking this bias into account. We all apply this same\nprocess when we compare the results of different bathroom\nscales, time pieces, meat thermometers, or fuel gauges in cars.\nFig. 3 Mosaic visualization of bias/-es in CSBC-ACC (38 lines). Collocation strength: Local, MI3 (EXP Scale).ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n8 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\nSource : Gunther ( 2018 ), published in Union of Concerned\nScientists .\n(6) Text int001354 |\u2026American Coal Council, the U.S.\nChamber of Commerce, Monsanto, the American Enter-prise Institute, and, of course, the Alliance. The report\nfollows a familiar pattern, generally calling into question the\nscience behind the health impacts of [insert pollutant here],\nfrequently based on a convoluted and biased modeling\neffort masquerading as science. If you \u2019re familiar with the\nDisinformation Playbook, then what \u2019s in the Alliance \u2019s\npaid-for report will sound familiar \u2026\nSource : Cooke ( 2018 ), published in Union of Concerned\nScientists .\nIn the preceding examples, CSBC-ACC bloggers make use of\n\u2018pronouncing \u2019lexical items like bias to acknowledge the\nheteroglossic diversity of approaches to the study of climate\nscience, and construct a coherent authorial voice to challenge\nthe biased nature of the dialogic alternative at play, i.e.\ncontrarian science. Such accusations of bias, however, are\narticulated differently in each subcorpus. Contrarian bloggers\nplace particular emphasis on the ideological dimension of the\nbiases underpinning the mainstream scienti \ufb01c consensus\nendorsed by institutions and corporations \u2014mobilizing non-\nepistemic values in an indirect role (Douglas, 2009 ). By\ncontrast, CSBC-ACC voices seek to legitimize their own\nstance by foregrounding the unsavoury sources of contrarian\nscienti \ufb01c funding, and the weaknesses of the methods and\nprotocols used by climate change deniers. But with core\nexperts having to play an increasingly activist role in defense\nof their work, CSBC-ACC bloggers occasionally draw\nattention to the ideological and/or political dimension of\ncontrarian biases. In example 7, for example, biases are\nreframed as desirable strategies to rede \ufb01ne social values and\naccelerate the pace of progress in public life.\n(7) Text int000181 | Are our water resources managed by\nwhat \u2019s measurably in the reservoir, or whether we feel that\nglass is half full or half empty? Did the US Department ofDefense develop a climate change strategy based on\nwhimsy, or on data and analysis? Yes, bias can be\nintroduced when values come in to play, and this can be\na good thing (e.g., when society decides to recognize the\nintrinsic value of species or landscapes, or intangibles like\nwell-being) or a bad thing (e.g., when we only value what\ncertain messengers have to say and devalue all others).\nSource : Spanger-Siegfried ( 2016 ), published in Union of\nConcerned Scientists .\nMy analysis has so far shown how each group \u2019s authorial\nsubjectivity is underpinned by a distinctive line of attack against\nalternative positions. CSBC-CON voices conceptualize climate\nscience biases as value-driven \ufb02aws; for CSBC-ACC bloggers, on\nthe other hand, biases result from the use of unsuitable instru-\nments, poorly designed protocols or modelling exercises \u2014as\nillustrated in examples 4 \u20136. In the remainder of this section, I aim\nto test whether the corpus-assisted methodology adopted in this\nstudy can yield further insights into the differences between the\nstrategies that contrarian and acceptor bloggers deploy to con-\nstruct intersubjectivity, focusing on two additional pronouncing\nlexical resources, dogma and peer-review \u2014both of which are\ndirected at tacitly or explicitly identi \ufb01ed counter positions.\nA search for dogma *in CSBC returns a 16-line concordance.\nThe Metafacet visualization in Fig. 4brings into sharp relief the\nuneven distribution of dogma across subcorpora. 12 occurrences\nof the term are found in two CSBC-CON blogs ( Science De \ufb01es\nPolitics and Australian Climate Madness ), even though their\ncombined size in terms of numbers of tokens is approximately athird of the size of DeSmog UK , the only CSBC-ACC blog where\ndogma is used.\nThe full concordance of dogma in the CBSC-CON corpus (Fig.\n5) provides further evidence that contrarian bloggers seek to\ndiscredit climate science by framing this form of knowledge as\nvalue-laden, rather than evidence-driven. Climate science is\ncon\ufb02ated with \u2018dogma \u2019(line 1) or, more elaborately, with \u2018climate\n(change) (cult) dogma \u2019(lines 2 \u20135). The fact that these lexical\nitems are often preceded by the article \u2018the\u2019(lines 2 \u20134, 9\u201311), the\npossessive adjective \u2018its\u2019(lines 5 \u20137), or the demonstrative deter-\nminer \u2018this\u2019(line 12) emphasizes that a single, unquestioning\nbelief has taken over the systematically organized body of\nknowledge and practices that scientists would be normally\nexpected to subject to critical scrutiny and revision. It can be\nfurther observed that contrarian bloggers occasionally use \u2018sci-\nence\u2019and\u2018dogma \u2019in each other \u2019s co-textual vicinity as a strategy\ndirected against their dialogic adversaries. Speci \ufb01cally, contrarians\nframe the use of \u2018science \u2019\u2014complete with the strong connotations\nof respectability that the term typically evokes \u2014by mainstream\nclimate change experts as a cloak to conceal the \ufb02aws of their\n\u2018dogma \u2019(e.g. line 5: \u2018calls its dogma science \u2019; line 6: \u2018calling it\n\u201csettled science \u201d\u2019). As understood by the contrarians \u2019authorial\nvoice, the climate change dogma is politicized and does not lend\nitself to scrutiny; on the contrary, it demands being accepted as\nundisputed truth and stands in opposition to sound research\nwhere values are used in a direct role (e.g. line 6: \u2018refuses to debate\nits dogma \u2019; line 7: \u2018declared its dogma to be the undisputed truth \u2019;\nand 12: \u2018prohibiting scienti \ufb01c research that contradicts this\ndogma \u2019). As a result, those subscribing to the climate change\ndogma are \u2018blinded \u2019(line 1) and \u2018brainwashed \u2019by it (line 9).\nThe argument that warmist biases are \ufb01rmly embedded in\npolicy-making processes and corporate strategies \u2014as articulated\nin CSBC-CON discourses \u2014is consistent with the dialogic con-\nstruction of climate change dogma by contrarian bloggers. CSBC-\nCON voices, for example, attribute the responsibility for the\ndevelopment and reinforcement of the climate change dogma to\nministers (e.g. line 1, \u2018she\u2019\u2014which refers back to Australian\nSenator Penny Wong); multilateral institutions and organizations\n(e.g. line 2: \u2018lawless UN agencies \u2019; and line 3: \u2018the IPCC or\nUNFCC \u2019); corporations (e.g. line 4: \u2018Google \u2019); and climate alar-\nmists (e.g. line 6: \u2018alarmist movement \u2019; line 7: \u2018climate alarmism \u2019\nand line 9: \u2018global warming alarmism \u2019). Interestingly, the con-\ntrarian trope that business giants are aligned with left-wing\nstances on climate change, as discussed in my earlier analysis of\nCSBC-CON discourses on scienti \ufb01c biases, is also used here to\ndecry the pervasiveness of the climate dogma (see line 4,\nexpanded in example 8). In trying to contest their dialogic\nFig. 4 Metafacet visualization for a concordance featuring dogma in CSBC\n(16 lines), \ufb01ltered by Internet outlet and sorted by frequency.HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 9\nalternative, CSBC-CON voices take the characterization of cli-\nmate science as a value-driven form of knowledge one step fur-\nther, framing it along religious lines \u2014whether by presenting\nglobal emissions as a \u2018sin\u2019requiring \u2018repentance \u2019(line 3, expanded\nin example 9), or comparing the contrarians \u2019challenge to climate\nscience with Galileo \u2019s actions in de \ufb01ance of the \u2018Catholic Church \u2019\n(line 8, expanded in example 10).\n(8) Text int001050 |\u2026the Main Part of the San Francisco AI\nGoogle Search has an internal state which includes a huge\nknowledge base that \u2019s probably heavily skewed toward the\nleft and is certainly accepting climate cult dogma as fact.\nSince 2011, Google Search has been demoting in search\nresults websites that disagreed with its \u201cfacts. \u201d\nSource : Goldstein ( 2017a ), published in Science De \ufb01es\nPolitics .\n(9) Text int001034 | The climate change cult has its own\neschatology \u2014calamities, catastrophes, and the end of the\nworld caused by global warming. To avoid this horrible end,\nwe have to repent (i.e., accept the climate change cult\ndogma ), stop sinning (releasing CO2), and generously pay\nwhomever the IPCC or UNFCC will tell us to pay.\nSource : Goldstein ( 2015 ), published in Science De \ufb01es Politics .\n(10) Text int001575 | If Rudd had any idea of the history of\nscience (or in fact about anything at all), he would have\nrealized that it was Galileo who was in the position of\ntoday \u2019s climate sceptics, bravely proposing a scandalous\nsun-centred model of the solar system in the face of the\nreligious dogma of the Catholic church (or in the present\nanalogy, the High Church of Global Warming), which\nstood \ufb01rmly by the biblical, faith-based, earth-centred\nmodel. And for this (ultimately correct) interpretation of\nthe workings of the solar system, Galileo was sentenced by\nthe Pope to house arrest \u2026\nSource : Turnill ( 2009 ), published in Australian Climate\nMadness .\nThe three concordance lines featuring occurrences of dogma in\nCSBC-ACC come from blogs posted in DeSmog UK . The fact that\ndogma is presented in these three instances (examples 11 \u201313) as\npart of quoted statements enclosed in double quotation marks\nsignals that this lexical resource is being used to construct a\n\u2018dialogically expansive \u2019position (Martin and White, 2005 )\u2014in\ncontrast to contrarian bloggers \u2019efforts to head off alternative\nviews through contractive strategies. The use of dogma byDeS-\nmog UK voices represented in CSBC-ACC through dialogically\nexpansive structures can therefore be said to \u201cactively make\nallowances for dialogically alternative positions and voices \u201d\n(Martin and White, 2005 , p. 102), decoupling \u201cthe proposition\nfrom the text \u2019s internal authorial voice by attributing it to some\nexternal source \u201d(Martin and White, 2005 , p. 111). By using this\nexpansive strategy, CSBC-ACC bloggers engage directly with\nindividual contrarian voices, foregrounding the extent to whichthe latter \u2019s involvement in this heteroglossic setting is driven by\nideology and prejudice. Climate change acceptors thus manage to\nground the viewpoints of contrarian authoritarian voices (repre-\nsented by a former Australian Prime Minister in example 11; a\nBritish political strategist and lobbyist associated with the Vote\nLeave campaign in example 12; and a Brazilian diplomat\nappointed by President Jair Bolsonaro in example 13) in overt\nmanifestations of subjectivity \u2014ultimately exposing the extent to\nwhich the resources deployed to construct CSBC-CON \u2019s dialogic\nstance are at odds with discursive conventions in scienti \ufb01c debate.\n(11) Text int002583 | In 2013, Howard said climate \u201czealots \u201dhad\nturned the issue into a \u201csubstitute religion \u201d. Abbott, who\ntrained to be a Roman Catholic priest, called climate change\na\u201cpost-Christian theology \u201dand said the decline of religion\nin society had left a hole in which other forms of \u201cdogma \u201d\ncould take root. Measures to deal with climate change,\nwhich Abbott said would damage the economy, likened to\n\u201cprimitive people once killing goats to appease the volcano\ngods\u201d.\u201cAt least so far, \u201dhe said, \u201cit\u2019s climate change policy\nthat\u2019s doing harm. Climate change itself is probably doing\ngood; or at least, more good than \u2026\nSource : Mathiesen ( 2017 ), published in DeSmog UK .\n(12) Text int002562 |\u2026contemporary cultural debates in the\nUK and was founded by Ukip Assembly Member Peter\nWhittle. The New Culture Forum argues that the right has\nwon the economic argument but that the liberal left still\ndominates the cultural space, with its website saying the\ngroup was created to \u201cchallenge the dogma and relativism\nof the establishment and rede \ufb01ne the parameters of the\ncultural and political debate \u201d.\nSource : Farand and Hope ( 2018 ), published in DeSmog UK .\n(13) Text int002594 |\u2026the point of paroxysm over the last 20\nyears with the ideology of climate change, the climatism, \u201d\nhe wrote in the blog post. This movement gathered data\n\u201csuggesting a correlation \u201dbetween rising temperatures and\nCO2, he claimed. They \u201cignored data suggesting the\nopposite \u2026and created a \u2018scienti \ufb01c\u2019dogma that no one\nelse can contest or he will be excommunicated from good\nsociety \u2014exactly the opposite of the scienti \ufb01c spirit. \u201dHis\nclaims contradict not only the vast majority of climate\nscientists but also the consensus among world leaders.\nSource : Mathiesen ( 2018 ), published in DeSmog UK .\nMoving on to peer review , the analysis examines how the\ncontrarian and acceptor dialogic positions align themselves with\nthe very system designed to recognize and confer expertise on\nindividual scientists and organizations. Technically, references to\npeer review systems should not serve to advance pronouncing\nstrategies, whether contractive or expansive. While the term\ninvokes a backdrop of heteroglossic diversity where certain views\nprevail over others, peer reviews are envisaged to help holders of\ndifferent views to negotiate an agreed intersubjective stance based\nFig. 5 Concordance lines ( dogma ) extracted from CSBC-CON and ordered alphabetically by the word in position 1 to the left.ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n10 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\non widely accepted epistemic traditions. In other words, the\nintegrity of the peer review system should in principle remain\noutside the bounds of dialogic confrontation, insofar as it should\nmobilize epistemic values in a direct role. Consequently, exam-\nining how authors in each subcorpus choose to characterize the\nimpact of peer review evaluations on policy-making and social\nperceptions of climate change should reveal whether bloggers\nengage with the peer review culture (process) in the same way as\nthey do with the science that peer reviewers choose to endorse or\ncontest (output).\nA Metafacet visualization (Fig. 6) for a concordance listing 19\noccurrences of peer review in CSBC shows that this lexical item is\npresent in both subcorpora and that its frequency is pro-\nportionally higher in the contrarian blogs, given that the size of\nthe CSBC-CON subcorpus is only a fourth of its CSBC-ACC\ncounterpart. A Mosaic visualization based on a 7-line con-\ncordance of peer review in the CSBC-CON blogs (Fig. 7) indicates\nthat references to the peer review system are strongly associated\nwith \u2018alarmism \u2019(position L1 in Fig. 7mosaic) in general, and\n\u2018IPCC \u2019(position R4) in particular. The biased nature of peer\nreviews, as perceived by contrarian bloggers, explains the occur-\nrence of lexical items like \u2018corruption \u2019(position L3) or \u2018skewing \u2019\n(position L2) in the vicinity of the search term, and the labelling\nof these instruments of evaluation as \u2018schmeer-reviews \u2019(position\nR1, expanded in example 14). Contrarians \u2019scepticism towards\npeer reviewing also accounts, for example, for the differentiation\nmade between \u2018proper \u2019(position L1) peer reviews and \u2018pal\nreviews \u2019(not captured in the mosaic display in Fig. 7)\u2014the latter\nbeing an important tool to quash scienti \ufb01c dissent (example 15).\n(14) Text int001469 | IPCC quotes WWF (again) \u2026gets it\nwrong (again) Peer-review ,schmeer-review . Half of the\nIPCC \u2019s last report was based on stuff like this, papers from\ndeep green advocacy groups like WWF which happened to\n\ufb01t nicely with the IPCC \u2019s pre-conceived agenda of climate\nalarmism. And they \u2019ve been caught with their pants down\nyet again, this time on the \u2026\nSource : Turnill ( 2010b ), published in Australian Climate\nMadness .\n(15) Text int001400 |\u2026that one of the key scienti \ufb01cr e p o r t s\non which that conclusion was based was not subjected to\nthose proper, rigorous processes and that \u201ccorners were\ncut\u201din order to rush it through. But that \u2019sO Ki s n \u2019ti t ,\nbecause the consensus boys don \u2019th a v et ob o t h e rw i t h\ntedious inconveniences like proper peer-review .J u s ta s k\nthe IPCC. Anyway, they can rely on \u201cpal-review \u201dif they\nget stuck. And the hypocrisy of the EPA is breathtaking,casually brushing aside the criticisms as a trivial\nirrelevance. Can you imagine the outrage if this had\nbeen a sceptical report? Double standards exempli \ufb01ed.\nSource : Turnill ( 2011 ), published in Australian Climate\nMadness .\nA Mosaic visualization based on the output of the 12-line\nconcordance for peer review in the CSBC-ACC corpus (Fig. 8),\non the other hand, features peer review at the centre of a very\ndifferent network of lexical relations. A detailed scrutiny of the\nconcordance con \ufb01rms that acceptor bloggers associate peer review\nwith the established process of academic publishing, under which\nscientists submit and publish their work in journals that uphold\nrigorous standards and editorial policies based on epistemic values\n\u2014unlike the case reported on in example 16, involving a journal\nrun by a \u2018climate science denier editor \u2019. The occurrence of items\nevoking more negative connotations \u2014e.g.\u2018sloppy \u2019(position R3 in\nFig. 8mosic) and \u2018corruption \u2019(position R4) \u2014in the vicinity of\npeer review is, again, attributable to the use by CSBC-ACC blog-\ngers of an expansive engagement strategy to convey the speech of a\ndirectly referenced dialogic adversary (example 17: \u2018Melanie\nPhillips \u2026argues that \u2026the peer-review process gets sloppy \u2026\u2019).\n(16) Text int001997 | The publisher of an academic journal\nbeloved by climate science deniers has been revamped to\nensure it meets industry standards of peer-review and\neditorial practice. Its climate science denier editor has also\nstepped down. Long a home for papers that cast doubt on\nclimate science and the seriousness of climate change,\nEnergy and Environment was recently bought by publish-\ning behemoth SAGE. As part of the acquisition process, \u2026\nSource : Hope ( 2018 ), published in DeSmog UK .\n(17) Text int002589 | Science is Turning Back to the Dark Ages\nIn this comment piece by Melanie Phillips, a right-wing\nBritish journalist and commentator, she argues that science\nhas lost much of its academic integrity and rigour as\nscientists cut corners: the peer-review process gets sloppy ,\ncorruption pervades institutions, and conformity drives\nbiases. However, this piece itself somewhat fails in its\n\u2018scienti \ufb01c integrity \u2019and\u2018rigour \u2019as it echoes the above Times\narticle on the \u201cexaggeration \u201dof ocean acidi \ufb01cation.\nSource : Mandel ( 2016 ), published in DeSmog UK .\nOn the whole, the contrarian stance on peer reviewing is\nconsistent with its pronouncements on biases and dogmas.\nChallenges are mounted against the interference of the sci-\nenti\ufb01c and political establishment with climate science, and\nthe instrumentalization of peer reviews to legitimize a partisan\n\u201cconduct of the climate science system \u201d(van Rensburg, 2015 ,\np. 141) \u2014rather than against the material practices that\nembody the work of producing climate science knowledge\nbefore it is submitted for peer sc rutiny. Consistency can also\nbe observed in the way acceptor bloggers construct their\ndialogic position on peer reviewing, drawing attention to the\npractices that underpin the production of knowledge in\nlegitimized knowledge networks and exposing the subjective\npronouncements that voices on the contrarian side of the\ndebate mobilize to construct their intersubjective stance.\nConclusion\nThe use of selected \u2018pronouncing \u2019lexis like bias,dogma andpeer\nreview by contrarian actors to negotiate their intersubjective\npositioning within the blogosphere reveals a mismatch between\nsome of their avowed intentions and their actual authorial voices\nas bloggers. As discussed in section \u201cInvestigating bloggers \u2019\nstances: Data and conceptual framework \u201d, CSBC-CON bloggers\npresent themselves as endowed with the cultural competence\nFig. 6 Metafacet visualization for a concordance featuring peer review in\nCSBC (19 lines), \ufb01ltered by Internet outlet and sorted by frequency.HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 11\nrequired to master interactional and contributory expertise in the\n\ufb01eld of climate science; accordingly, they claim to be driven by\nthe need to assess evidence for and against climate change dis-\npassionately, as a way to uphold the integrity of the climate sci-\nence, and purport to provide a non-partisan and non-political\ncritique of relevant developments. However, the analysis of this\nsubcorpus shows that, in positioning themselves with respect to\nthe acceptors \u2019stance, contrarian bloggers resort to characterizing\nmainstream scienti \ufb01c consensus precisely in terms of the latter \u2019s\nalignment with institutional policies, corporate interests or left-wing agendas at odds with national interests. As shown by the\nanalysis, the inherent biases of the \u2018consensus science \u2019, that con-\ntrarian bloggers frame as value-driven \ufb02aws, are elevated to the\ncategory of church dogma in CSBC-CON discourses. By pur-\nportedly exposing the centrality of non-epistemic values in con-\nsensus climate science, CSBC-CON bloggers \u2019stance becomes\nimbued with political overtones, which facilitates the derivation\nand communication of their sceptic perspective. On the surface,\ncontrarian bloggers \u2019pledge to uphold process legitimacy would\nappear to be somewhat more congruous with their stance on the\nFig. 7 Mosaic visualization of peer review in CSBC-CON (7 lines). Collocation strength: Local, MI3 (EXP Scale).\nFig. 8 Mosaic visualization of peer review in CSBC-ACC (12 lines). Collocation strength: Local, MI3 (EXP Scale).ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n12 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\npeer review system. As shown in section \u201cAnalysing CSBC blog-\ngers\u2019construction of intersubjectivity: Bias, dogma, peer review \u201d,\nthe CSBC-CON authorial voice questions the reliability of peer\nreviews insofar as these are conducted exclusively by core experts(without the involvement of their contributory or interactional\ncounterparts) in \ufb02uenced by pervasive institutional and corporate\nvested interests. Ultimately, however, contrarian bloggers do not\nsingle out any speci \ufb01c procedural \ufb02aw of the evaluation process,\nopting instead to decry the unacceptable politicization of con-\nsensus science \u2014where values, they argue, shape the research\nprocess from its very early stages.\nBy contrast, the biases identi \ufb01ed by CSBC-ACC bloggers refer\nprimarily to the consequences of ill-informed conceptual or\nmethodological decisions, and of skewed calibration and mea-\nsurements while gathering evidence. In other words, the analysis\nshows that acceptor bloggers are normally bound by values used\nin a direct role (Douglas, 2009 ), i.e. they are more likely to\nmobilize epistemic values circumscribed by the methodological\nnorms of the certi \ufb01ed scienti \ufb01c community. This understanding\nof scienti \ufb01c biases as relatively unintentional consequences of\nnon-partisan exercises of agency is consistent with the complete\nabsence of references to climate science dogma in the Union of\nConcerned Scientists blog. Signi \ufb01cantly, it also brings into sharp\nrelief the fact that occurrences of this lexical item in Desmog UK\nare con \ufb01ned to statements by public \ufb01gures in the sceptic camp,\nthat are quoted verbatim to expose their prejudiced nature. The\ncoherence of the CSBC-ACC \u2019s authorial voice is reinforced\nthrough their characterization of peer reviews as gate-keeping\ninstruments underpinned by established epistemic frameworks \u2014\nwhere values are deployed in a direct role \u2014and forms of exper-\ntise. The analysis shows how, on occasions, core experts adopt a\nmore adversarial stance in their blog posts that mobilizes non-\nepistemic values to discredit contrarian voices.\nAlthough their readership in absolute terms is often small,\nclimate change blogs attract a relatively high number of in \ufb02u-\nential readers, including journalists, who facilitate the penetration\nof bloggers \u2019views and their policy disputes into mainstream\nreporting and public discourse (Farrell and Drezner, 2008 ). This\nstudy has advocated the need to compile and interrogate corpora\nconsisting of climate blogs, an increasingly in \ufb02uential genre\ncomplementing previous research on scienti \ufb01c controversy as\nreported in traditional media. The \ufb01ndings outlined here reveal\nthe value-laden character of contrarian views, and show how\nacceptor bloggers attempt to construct an authorial voice driven\nby\n\u2018the science \u2019, while drawing on dialogically expansive strategies\nto foreground their opponents \u2019prejudiced voices for strategic\nreasons. This relatively small corpus therefore con \ufb01rms that, in\naddition to prompting re \ufb02ection on the use of knowledge in\nvarious forms of public decision-making, both contrarian and\nacceptor bloggers seek to manage public perceptions of climate\nchange using different approaches. More work is needed to\nestablish how other types of evaluative lexis in \ufb02uence the blog-\ngers\u2019engagement with alternative stances, and whether these are\nconsistent with the discourses that this paper has reported\non. Exploring the similarities and differences between the\nauthorial voices constructed in blog posts and in the wider range\nof online genres included in the Genealogies of Knowledge\nInternet corpus would yield further insight into the negotiation of\nintersubjectivity and expertise in an increasingly multivoiced\ndebate.\nReceived: 29 November 2019; Accepted: 19 August 2020;\nNotes\n1 An itemized list of the articles included in the Genealogies of Knowledge Internet\ncorpus is available at http://genealogiesofknowledge.net/corpora/internet-corpus/ .\n2 Unlike \u2018sceptic \u2019and\u2018catastrophist \u2019discourses, \u2018gradualism \u2019postulates that climate\nchange is happening gradually and that economic activities can be adjusted tominimize the impact of human impact on the environment (Dayrell and Urry, 2015 ).\n3 Full details on the composition of CSBC are provided in section \u201cInvestigating\nbloggers \u2019stances: Data and conceptual framework \u201d.\n4 Recent studies show that climate change scientists are also taking to Twitter to\ninteract with fellow scientists, journalists, civil society and politicians \u2014and adjusting\ntheir communication style to their target audience (Walter et al., 2019 ).\n5 SEE \u2019s normative theory of expertise has been strongly criticized by advocates of the\nsocial constructivist approach, who have characterized it as a reversion towardstechnocracy (Wynne, 2003 ). Although Collins and Evans intended their theory to be\n\u201ccompatible with SSK \u201d(2002 , p. 239), critics argue that it opens up opportunities for\nscientists to \ufb02out democratic norms of transparency and escape oversight from civil\nsociety, thereby putting the epistemics of public deliberation in jeopardy (Jasanoff,2003 , p. 158). Acting as \u201cinadvertent agents of the reproduction of an established set\nof institution re \ufb02exes\u201d(Wynne, 2006 , p. 217), scientists may remove the political\nfrom the policy-making equation (Wynne, 2016 , p. 101), in what would amount to an\nact of \u201cscienti \ufb01c denial [or] dishonesty \u201d(Wynne, 2016 , p. 106). Other critics have\ndrawn attention to various aspects of the dialectic between scientists and experience-based experts, noting that SEE does not set out to explain how the right of non-credentialed specialists to participate in technical decision-making accrues or isrecognized by trained experts (Rip, 2003 ). In their view, under SEE \u2019s normative\ntheory of expertise, scientists \u2019dogmatism challenges and undermines the socially\nsensitive and adaptable reasoning displayed by lay publics, effectively turning policy-\nmaking on contentious issues into an activity where \u201ctechnical and social criteria\nconfront each other without a common metric \u201d(Fischer, 2009 , p. 45).\n6 Although the research carried out by the Genealogies of Knowledge project is\ncompliant with the spirit of the 2014 UK copyright exception for text and datamining for non-commercial research (Borghi, n.d.), the project team has actively\nsought to secure informed written permission from bloggers before including their\nmaterial in the corpus. As is also the case with the publishers and authors of other\nonline material held in the\nGenealogies of Knowledge Internet corpus, bloggers who\nagreed to have posts sourced from their websites are listed in the Credits page of theproject \u2019s website \u2014available at https://genealogiesofknowledge.net/credits/ .\n7 Although their aims and methodology are very different from those driving the\npresent study, the dichotomy between \u2018contrarians \u2019and\u2018acceptors \u2019proposed by\nDiakopoulos et al. ( 2014 ) is adopted here to bundle the various sensitivities without\nnecessarily presenting them as outsiders/insiders, or in terms of their majoritarian/\nminoritarian status.\n8 The itemized list of the Australian Climate Madness posts included in CSBC-CON is\navailable at https://genealogiesofknowledge.net/credits/australian-climate-madness/ .\n9 Social recognition of traditional framings of expertise is normally predicated on\noutput legitimacy, which prioritizes the production of valuable knowledge over the\nenforcement of the checks and balances required to minimize the impact of biases\nand vested interests in the construction of scientists \u2019authoritative evidence. By\ncontrast, participatory approaches to the governance of expertise prioritize processlegitimacy \u2014i.e. creating an environment where experts \u2019claims, recommendations\nand interests can be challenged and resisted, and other voices can become involved inthe translation of evidence into policies at the earliest possible opportunity. This\nepistemic shift towards process legitimacy calls for a better understanding of the\nneeds of non-academic research users, including policy-makers (Nutley et al., 2007 ,\np. 63) and, more widely, charitable organizations, business, professionals andpractitioners, and the general public.\n10 The itemized list of the Science De \ufb01es Politics posts included in CSBC-CON is\navailable at https://genealogiesofknowledge.net/credits/defyccc/ .\n11 The itemized list of the Climate Depot posts included in CSBC-CON is available at\nhttps://genealogiesofknowledge.net/credits/climate-depot/ .\n12 The synopsis available on the documentary \u2019s promotional website ( https://\nsonyclassics.com/merchantsofdoubt/ ) states that Merchants of Doubt aims to lift \u201cthe\ncurtain on a secretive group of highly charismatic, silver-tongued pundits-for-hirewho present themselves in the media as scienti \ufb01c authorities \u2014yet have the contrary\naim of spreading maximum confusion about well-studied public threats ranging from\ntoxic chemicals to pharmaceuticals to climate change \u201d.\n13 The Media Bias/Fact Check website, for example, places Climate Depot under the\n\u2018Conspiracy-Pseudoscience \u2019category and rates this blog as a \u201cstrong Pseudoscience\nsource based on promotion of human in \ufb02uenced climate denialism propaganda and\nthe use of poor sources who have failed numerous fact checks \u201d(https://\nmediabiasfactcheck.com/climate-depot/ ).\n14 Freedman \u2019\ns(2009 ) article in The Washington Post is a case in point.\n15 The itemized list of the Union of Concerned Scientists posts included in CSBC-ACC is\navailable at https://genealogiesofknowledge.net/credits/ucsusa/ .HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 13\n16 The itemized list of the DeSmog UK posts included in CSBC-ACC is available at\nhttps://genealogiesofknowledge.net/credits/desmoguk/ .\n17 The Media Bias/Fact Check website rates DeSmog UK as\u201cleft biased based on its\npolitical stance regarding climate change \u201d, and presents it as \u201can excellent source for\nresearching who is funding climate science denial \u201d(https://mediabiasfactcheck.com/\ndesmog/ ).\n18 Contractive dialogic structures have also been the focus of recent studies of reader\ncomments posted in response to climate change blogs (Metcalfe, 2020 ).\n19 The Metafacet tool (Sheehan and Luz, 2019 ; Luz and Sheehan, 2020 ) draws on\nconcordances generated while conducting searches for lexical items such as \u2018bias\u2019to\ngenerate visualizations that display the number of concordance lines associated with a\nparticular facet of the metadata \u2014in this case, speci \ufb01c blogs. The list of blogs\ndisplayed in the output of the Metafacet visualizations used in this study are verticallyordered by the frequency of the search word in each of these outlets. The \ufb01gures in\nthex-axis state the number of occurrences in each of the listed outlets. For further\ndetails, see the relevant section of the Genealogies User Manual , available at http://\ngenealogiesofknowledge.net/software/manual/#facets .\n20 Only tokens that can be used as noun phrases or parts of noun phrases are considered\nin my analysis, as not all the proclaiming markers of intersubjectivity studied in thispaper can be used as verbs.\n21 Based on the concordance output generated following a speci \ufb01c lexical search (e.g.\n\u2018bias\u2019), the Mosaic visualization (Luz and Sheehan, 2014 ) produces positional word\nstatistics. The MI3 score, one of several available under Mosaic \u2019s\u2018Collocation\nStrength \u2019operating mode, is calculated by cubing the observed frequency of a term\nco-occurring with the search word, dividing this by its expected frequency in thecorpus (i.e. the frequency one would expect if no factor other than random chancewere affecting the frequencies), and then taking the logarithm to the base 2 of theresult. The higher the MI3 score, the stronger the signi \ufb01cance of a collocational\nrelationship. For further details on this and other scores are available at http://\ngenealogiesofknowledge.net/software/manual/#mosaic .\n22 The \u2018Collocation Strength (Local) \u2019operating mode has been chosen here because, by\npresenting each column of the Mosaic in full height, it makes it easier for the readerto gain visual access to more of the collocates that the search node attracts. The\u2018Collocational Strength (Global) \u2019view would have delivered a scaled representation of\nthe collocates based on their statistical signi \ufb01cance. The height of the Mosaic titles in\nthe global view is directly proportional to the MI3 score for each collocation, which\ncan make it more dif \ufb01cult to access some of the collocate tiles in printed Mosaic\nvisualizations.\n23 Each of the examples provided in this section features a concordance line within a\nwider fragment of the relevant online blog post. This expanded context can beretrieved by clicking on a concordance line and then pressing the \u2018\nExtract \u2019button on\nthe concordancer \u2019s interface.\nReferences\nAuer MR, Zhang Y, Lee P (2014) The potential of microblogs for the study of\npublic perceptions of climate change. WIREs Clim Change 5:291 \u2013296\nAustralian Climate Madness (n.d.) About. https://australianclimatemadness.com/\nabout/ . Accessed 22 Nov 2019.\nBachelard M (2011) Witches, god, climate change \u2026It\u2019s a matter of belief. The\nSydney Morning Herald, 23 October. https://www.smh.com.au/environment/\nclimate-change/witches-god-climate-change-its-a-matter-of-belief-20111022-1mdpq.html . Accessed 22 Nov 2019\nBakhtin MM (1981) The dialogic imagination (trans: Emerson C, Holquist M).\nUniversity of Texas Press, Austin\nBeck S, Borie M, Esguerra A, Chilvers J, Heubach K, Hulme M, Lidskog R, L\u00f6v-\nbrand E, Marquard E, Miller C, Nadim T, Nessh\u00f6ver C, Settele, Turnhout E,Vasileiadou E, G\u00f6rg C (2014) Climate change and the assessment of expertknowledge: does the IPCC model need updating? \u2019. Bridges 40. https://\nostaustria.org/bridges-magazine/item/8244-climate-change-and-the-\nassessment-of-expert-knowledge-does-the-ipcc-model-need-updating .\nAccessed 22 Nov 2019\nBiber D (2006) Stance in spoken and written university registers. J Engl Acad Purp\n5:97\u2013116\nBorghi M (n.d.) Text and data mining. Copyrightuser.org website. https://www.\ncopyrightuser.org/understand/exceptions/text-data-mining/ . Accessed 22\nNov 2019\nBremer S, Stiller-Reeve M, Blanchard A, Mamnun N, Nazning Z, Kariser M (2018)\nCo-producing \u2018post-normal \u2019climate knowledge with communities in\nNortheast Bangladesh. Wea. Climate Soc 10(2):259 \u2013268\nBrevini B, Lewis J (eds) (2018) Climate change and the media. Peter Lang, New\nYork and Berlin\nCarrozza C (2015) Democratizing expertise and environmental governance: dif-\nferent approaches to the politics of science and their relevance for policyanalysis. J Environ Policy Plan 17(1):108 \u2013126\nCaudill D S, Conley S N, Gorman M E, Weinel M (eds) (2019) Introduction. in:\nThe Third Wave in Science and Technology Studies. Palgrave Macmillan,\nCham, p 1 \u201313Chinn S, Sol Hart P, Soroka S (2020) Politicization and polarization in climate\nchange news content, 1985 \u20132017. Sci Commun 42(1):112 \u2013129\nClimate Depot (2009) Climate Depot launch press release. https://www.climatedepot.\ncom/2009/04/06/climate-depot-aims-to-rede \ufb01ne-global-warming-reporting/ .\nAccessed 22 Nov 2019\nCollins H, Evans R (2002) The third wave of science studies: studies of expertise\nand sxperience. Soc Stud Sci 32(2):235 \u2013296\nCollins H, Evans R (2007) Rethinking expertise. University of Chicago Press, ChicagoCollins H, Evans R (2020) Studies of expertise and experience. A sociological\nperspective on expertise. In: Ward P, Schraagen JM, Gore J, Roth E (eds) The\nOxford handbook of expertise. Oxford University Press, New York, pp.85\u2013102\nCooke D (2018) Automakers turn to climate deniers in quest to lower fuel econ-\nomy regulations. Union of Concerned Scientists, 19 March. Available to view\nat https://blog.ucsusa.org/dave-cooke/automakers-turn-to-climate-deniers-\nin-quest-to-lower-fuel-economy-regulations\nDayrell C (2019) Discourses around climate change in Brazilian newspapers:\n2003\u20132013. Discourse Commun 13(2):149 \u2013171\nDayrell C, Urry J (2015) Mediating climate politics: the surprising case of Brazil.\nEur J Soc Theory 18(3):57 \u2013273\nDeMelle B (2014) DeSmog UK launches to combat climate denial in Europe ahead\nof Paris climate talks. The Narwhal, 1 September. https://thenarwhal.ca/\ndesmog-uk-launched-combat-climate-denial-europe-ahead-paris-climate-\ntalks/ . Accessed 22 Nov 2019\nDeSmog UK (n.d.) About us.\nhttps://www.desmog.co.uk/about-us . Accessed 22\nNov 2019\nDiakopoulos N, Zhang A, Elgesem D, Salway A (2014) Identifying and analyzing\nmoral evaluation frames in climate change blog discourse. In: Proceedings of theeighth international AAAI conference on weblogs and social media, pp. 583 \u2013586.\nhttps://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8064/\n8085. Accessed 22 Nov 2019\nDouglas H (2009) Science, policy and the value-free ideal. University of Pittsburgh\nPress, Pittsburgh\nEpstein S (1995) The construction of lay expertise: AIDS activism and the forging\nof credibility in the reform of clinical trials. Sci Technol Hum Values 20\n(4):408 \u2013437\nFarrell H, Drezner DW (2008) The power and politics of blogs. Public Choice\n134:15 \u201330\nFarand C, Hope M (2018) Matthew and Sarah Elliott: How a UK power couple\nlinks US libertarians and fossil fuel lobbyists to Brexit. DeSmog UK, 19\nNovember. Available to view at https://www.desmog.co.uk/2018/11/18/\nmatthew-sarah-elliott-uk-power-couple-linking-us-libertarians-and-fossil-fuel-lobbyists-brexit\nFeldman L, Sol Hart P, Milosevic T (2015) Polarizing news? Representations of\nthreat and ef \ufb01cacy in leading US newspapers \u2019coverage of climate change.\nPublic Underst Sci 26(4):481 \u2013497\nFischer F (2009) Democracy and expertise: reorienting policy inquiry. Oxford\nUniversity Press, Oxford\nFl\u00f8ttum K (2017) Language and climate change. In: Fl\u00f8ttum K (ed.) The role of\nlanguage in the climate change debate. Routledge, London and New York, pp.1\u20139\nFoucault M (1980) Two lectures. Power/knowledge. Random House, New York\nand Toronto, pp. 78 \u2013108\nFreedman A (2009) Obama needs to give a climate speech \u2014ASAP. The Washington\nPost, 1 September. http://voices.washingtonpost. com/capitalweathergang/2009/\n09/obama_needs_to_give_a_climate.html . Accessed 22 Nov 2019\nFuntowicz SO, Ravetz JR (1991) A new scienti \ufb01c methodology for global environmental\nissues. In: Costanza R (ed.) Ecological economics: the science and management ofsustainability. Columbia University Press, New York, pp. 137 \u2013152\nFuntowicz SO, Ravetz JR (1992) Three types of risk assessment and the emergence\nof post-normal science. In: Krimsky S, Golding D (eds) Social theories of risk.\nGreenwood, Westport, pp. 251 \u2013273\nFuntowicz SO, Ravetz JR (1993) Science for the post-normal age. Futures 25\n(7):739 \u2013755\nGluckman P (2014) Brokering knowledge: giving science advice to government. Public\nSector July/August(4). https://search.informit.c om.au/documentSummary;\ndn=510236468569156;res =IELBUS . Accessed 22 Nov 2019\nGoldstein L (2015) Cult of climate change. Science De \ufb01es Politics. Available to view\nathttps://defyccc.com/cult-of-climate-change/\nGoldstein L (2017a) Seeing the world through the matrix and accidental AI?.\nScience De \ufb01es Politics, 16 August. Available to view at https://defyccc.com/\none-nation-under-accidental-arti \ufb01cial-intelligence/\nGoldstein L (2017b) Google anti-conservative bias unchanged since 2015. Aus-\ntralian Climate Madness, 30 September. Available to view at https://defyccc.\ncom/google-anti-conservative-bias-unchanged-since-2015/\nGunther A (2018) Rep. Lamar Smith misunderstands science. Union of Concerned\nScientists, 16 March. Available to view at https://blog.ucsusa.org/guest-\ncommentary/rep-lamar-smith-misunderstands-scienceARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n14 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z\nHope M (2018) Climate science deniers \u2019favourite journal just got \u2018overhauled \u2019\u2019and\nit could lead to a skeptic shutout. DeSmog UK, 23 February. Available to viewathttps://www.desmog.co.uk/2018/02/23/climate-science-deniers-favourite-\njournal-just-got-overhauled-and-it-could-lead-skeptic-shutout\nHowarth C, Sharman A (2015) Labeling opinions in the climate debate: a critical\nreview. WIREs Clim Change 6:239 \u2013254\nHulme M (2017) Foreword. In: Fl\u00f8ttum K (ed.) The role of language in the climate\nchange debate. Routledge, London and New York, pp. ix \u2013xii\nIPCC (n.d.) The Intergovernmental Panel on Climate Change. https://www.ipcc.\nch/. Accessed 22 Nov 2019\nJasanoff S (1999) STS and public policy. Getting beyond deconstruction. Sci\nTechnol Soc 4(1):59 \u201372\nJasanoff S (2003) (No?) Accounting for expertise. Sci Public Policy 30(3):157 \u2013162\nJasanoff S (2010) A new climate for society. Theory Cult Soc 27(2-3):233 \u2013253\nJasanoff S, Wynne B (1998) Science and decision making. In: Rayner S, Malone EL\n(ed) Human choice and climate change. Batelle Press, Columbus, pp. 1 \u201387\nKahan D, Peters E, Cantrell Dawson E, Slovic P (2017) Motivated numeracy and\nenlightened self-government. Behav Public Policy 1(1):54 \u201386\nKenner R (2014) Merchants of doubt. IMDb entry. https://www.imdb.com/title/\ntt3675568/ . Accessed 22 Nov 2019\nKirby A (2018) Global warming did not pause. Desmog, 19 December. Available to view\nathttps://www.desmog.co.u k/2018/12/19/global-warming-did-not-pause-study\nL\u00f6rcher I, Taddicken M (2017) Discussing climate change online. Topics and\nperceptions in online climate change communication in different online-public arenas. J Sci Commun 16(02):A03\nLuz S, Sheehan S (2014) A graph based abstraction of textual concordances and\ntwo renderings for their interactive visualisation \u2019. In: Proceedings of the 2014\ninternational working conference on advanced visual interfaces. ACM, NewYork, pp. 293 \u2013296\nLuz S, Sheehan S (2020) Methods and visualization tools for the analysis of\nmedical, political and scienti \ufb01c concepts in genealogies of knowledge. Pal-\ngrave Commun 6, article 49. https://www.nature.com/articles/s41599-020-\n0423-6\nMandel K (2016) The top 10 climate change articles in The Times, debunked.\nDeSmog UK, 24 April. Available to view at https://www.desmog.co.uk/2016/\n04/24/top-10-climate-change-articles-times-debunked\nMartin JR, White PR (2005) The language of evaluation. Appraisal in English.\nPalgrave Macmillan, Basingstoke and New York\nMathiesen K (2017) Climate change \u2018probably doing good \u2019, says former Australian\nPrime Minister Tony Abbott. DeSmog UK, 9 October. Available to view at\nhttps://www.desmog.co.uk/2017/10/09/climate-change-probably-doing-good-says-former-australian-prime-minister-tony-abbott\nMathiesen K (2018) Brazil \u2019s new foreign minister is a climate science denier.\nDeSmog UK, 15 November. Available to view at https://www.desmog.co.uk/\n2018/11/15/brazil-s-new-foreign-minister-climate-science-denier\nMerchants of Doubt Trailer (2015) Merchants of doubt of \ufb01cial trailer 1 (2014) \u2014\ndocumentary HD. https://www.youtube.com/watch?v =j8ii9zGFDtc . Acces-\nsed 22 Nov 2019\nMetcalfe J (2020) Chanting to the choir: the dialogical failure of antithetical climate\nchange blogs. J Sci Commun 19(02):A04\nMeyer R (2016) Are climate scientists ready for Trump? Maybe not. The Atlantic,\n27 December. https://www.theatlantic.com/science/archive/2016/12/are-\nclimate-scientists-ready-for-trump/511604/ . Accessed 22 Nov 2019\nMoser SC (2016) Re\n\ufb02ections on climate change communication research and\npractice in the second decade of the 21st century: what more is there to say?WIREs Clim Change 7(3):345 \u2013369\nNewman TP, Nisbet EC, Nisbet MC (2018) Climate change, cultural cognition, and\nmedia effects: worldviews drive news selectivity, biased processing, andpolarized attitudes. Public Underst Sci 27(8):985 \u20131002\nNisbet MC, Markowitz EM (2015) Expertise in an age of polarization: evaluating\nscientists \u2019political awareness and communication behaviors. Ann Am Acad\nPolitical Soc Sci 658:136 \u2013154\nNutley S, Walter I, Davies H (2007) Using evidence: how research can inform\npublic services. Policy Press, Bristol\nO\u2019Neill S, Williams HP, Kurz T, Wiersma B, Boykoff M (2015) Dominant frames\nin legacy and social media coverage of the IPCC \ufb01fth assessment report. Nat\nClimate Change 5:380 \u2013385\nOppenheimer M, Oreskes N, Jamieson D, Brysse K, O \u2019Reilly J, Shindell M, Wazeck\nM (2019) Discerning experts. The practices of scienti \ufb01c assessment for\nenvironmental policy. The University of Chicago Press, Chicago\nPoliakoff E, Webb TL (2007) What factors predict scientists \u2019intentions to parti-\ncipate in public engagement of science activities? Sci Commun 29:242 \u2013263\nRip A (2003) Constructing expertise: In a third wave of science studies? Soc Stud\nSci 33(3):419 \u2013434\nSalway A (2017) Data-driven approaches to climate change discourse, illustrated\nthrough case studies of blogs and international climate negotiation. In:Fl\u00f8ttum K (ed.) The role of language in the climate change debate. Routledge,\nLondon and New York, pp. 151 \u2013170Salway A, Elgesem D, Ho \ufb02and K, Reigem \u00d8, Steskal L (2016) Topically-focused\nblog corpora for multiple languages. In: Proceedings of the 10th web ascorpus workshop (WAC-X), ACT 2016. https://www.aclweb.org/anthology/\nW16-2603/ . Accessed 22 Nov 2019\nSch\u00e4fer M (2012) Online communication on climate change and climate politics: a\nliterature review \u2019. WIREs Climate Change 3:527 \u2013543\nSchoonover R (2019) The White House blocked my report on climate change and\nnational security. NY Times 30 July. https://www.nytimes.com/2019/07/30/\nopinion/trump-climate-change.html . Accessed 22 Nov 2019\nScience De \ufb01es Politics (n.d.) About. https://defyccc.com/about/ . Accessed 22 Nov\n2019\nShapin S (1995) Here and everywhere: sociology of scienti \ufb01c knowledge. Annu Rev\nSociol 21:289 \u2013321\nSharman A (2015) The impact of controversy on the production of scienti \ufb01c\nknowledge. Centre for Climate Change Economics And Policy working paperno. 233. http://www.lse.ac.uk/GranthamInstitute/wp-content/uploads/2015/\n09/Working-Paper-207-Sharman.pdf . Accessed 22 Nov 2019\nSheehan S, Luz S (2019) Text visualization for the support of lexicography-based\nscholarly work. In: Proceedings of eLex 2019. https://elex.link/elex2019/wp-\ncontent/uploads/2019/09/eLex_2019_40.pdf . Accessed 22 Nov 2019\nSpanger-Siegfried E (2016) Lies hurt. Facts matter. And so does resistance. Union\nof Concerned Scientists, 12 December. Available to view at https://blog.\nucsusa.org/erika-spanger-siegfried/lies-hurt-facts-matter-and-so-does-\nresistance\nTabuchi H (2017) How climate change deniers rise to the top in Google searches.\nNY Times, 29 December. https://www.nytimes.com/2017/12/29/climate/\ngoogle-search-climate-change.html . Accessed 22 Nov 2019\nTangney P (2017) Climate adaptation policy and evidence: understanding the\ntensions between politics and expertise in public policy. Routledge-Earthscan,London\nTangney P (2019a) Between con \ufb02ation and denial \u2014the politics of climate expertise\nin Australia. Aust J Political Sci 54(1):131 \u2013149\nTangney P (2019b) Does risk-based decision-making present an \u2018epistemic trap \u2019for\nclimate change policymaking? Evid Policy. https://doi.org/10.1332/\n174426419X1557747600211\nThompson G, Hunston S (2000) Evaluation: an introduction. In: Hunston S,\nThompson G (eds) Evaluation in text. Authorial stance and the constructionof discourse. Oxford University Press, Oxford, pp. 1 \u201327\nTurner SP (2014) The politics of expertise. Routledge, London and New York\nTurnill S (2009) Hilarious: Rudd enlists Galileo \u2019s\u2018help\u2019. Australian Climate Mad-\nness, 19 November. Available to view at https://australianclimatemadness.\ncom/2009/11/19/hilarious-rudd-enlists-galileos-help/\nTurnill S (2010a) Christopher Booker on the IPCC. Australian Climate Madness, 6\nSeptember. Available to view at https://australianclimatemadness.com/2010/\n09/06/christopher-booker-on-the-ipcc/\nTurnill S (2010b) IPCC quotes WWF (again) \u2026and gets it wrong (again). Aus-\ntralian Climate Madness, 13 March. Available to view at https://\naustralianclimatemadness.com/2010/03/13/ipcc-quotes-wwf-again-gets-it-\nwrong-again/\nTurnill S (2011) Yet more bad science. Australian Climate Madness, 29 September.\nAvailable to view at https://australianclimatemadness.com/2011/09/29/us-\nyet-more-bad-science/\nTurnill S (2012) ABC: institutionalised bias. Australian Climate Madness, 26\nNovember. Available to view at https://australianclimatemadness.com/2012/\n11/26/abc-institutionalised-bias/\nUnion of Concerned Scientists (n.d.) Who we are. https://www.ucsusa.org/about .\nAccessed 22 Nov 2019\nVan Rensburg W (2015) Scepticism about anthropogenic climate disruption: a\nconceptual exploration. Unpublished doctoral thesis, The University ofQueensland. https://core.ac.uk/download/pdf/43380080.pdf . Accessed 22\nNov 2019\nWaldman S (2019) Trump of \ufb01cials deleting mentions of \u2018climate change \u2019from U.S.\nGeological survey press releases. Science. https://www.sciencemag.org/news/\n2019/07/trump-of \ufb01cials-deleting-mentions-climate-change-us-geological-\nsurvey-press-releases . Accessed 22 Nov 2019\nWalter S, L\u00f6rcher I, Br\u00fcggemann M (2019) Scienti \ufb01c networks on Twitter: ana-\nlyzing scientists \u2019interactions in the climate change debate. Public Underst Sci\n28(6):696 \u2013712\nWynne B (1989) Sheep farming after Chernobyl: a case study in communicating\nscienti \ufb01c information. Environment 31(2):10 \u201339\nWynne B (2003) Seasick on the Third Wave: subverting the hegemony of pro-\npositionalism. Soc Stud Sci 33(3):401 \u2013417\nWynne B (2006) Public engagement as a means of restoring public trust in science\n\u2014hitting the notes, but missing the music. Community Genet 9(3):211 \u2013220\nWynne B (2016) Ghosts in the machine: publics, meanings and a social science in a\ntime of expert dogma in denial. In: Chilvers J, Kearnes M (eds) Remaking\nparticipation: science, environment and emergent public. Routledge, London\nand New York, pp. 99 \u2013120HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z ARTICLE\nHUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z 15\nAcknowledgements\nThis research was supported by the Arts and Humanities Research Council, UK (Grant\nnumber: AH/M010007/1).\nCompeting interests\nThe author declares no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to L.P.-G.\nReprints and permission information is available at http://www.nature.com/reprints\nPublisher \u2019s note Springer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional af \ufb01liations.Open Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the CreativeCommons license, and indicate if changes were made. The images or other third partymaterial in this article are included in the article \u2019s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle \u2019s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly fromthe copyright holder. To view a copy of this license, visit http://creativecommons.org/\nlicenses/by/4.0/ .\n\u00a9 The Author(s) 2020ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-020-00582-z\n16 HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS |            (2020) 7:92 | https://doi.org/10.1057/s41599-020-00582-z", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "'Is climate science taking over the science?': A corpus-based study of competing stances on bias, dogma and expertise in the blogosphere", "author": ["L P\u00e9rez-Gonz\u00e1lez"], "pub_year": "2020", "venue": "Humanities and Social Sciences Communications", "abstract": "Climate change science has become an increasingly polarized site of controversy, where  discussions on epistemological rigour are difficult to separate from debates on the impact that"}, "filled": false, "gsrank": 608, "pub_url": "https://www.nature.com/articles/s41599-020-00582-z", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:tiu7wS4s29IJ:scholar.google.com/&output=cite&scirp=607&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D600%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=tiu7wS4s29IJ&ei=c7WsaKrNI5XUieoPmrax2A8&json=", "num_citations": 14, "citedby_url": "/scholar?cites=15193786347194887094&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:tiu7wS4s29IJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41599-020-00582-z.pdf"}}, {"title": "The link between reported cases of COVID-19 and the Infodemic Risk Index: A worldwide perspective", "year": "2023", "pdf_data": "TYPEBrief Research Report\nPUBLISHED /one.tnum/seven.tnum January /two.tnum/zero.tnum/two.tnum/three.tnum\nDOI/one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nOPENACCESS\nEDITEDBY\nGabriella Punziano,\nUniversity of Naples Federico II, Italy\nREVIEWEDBY\nAlessandro Provetti,\nBirkbeck, University of London,\nUnited Kingdom\nSara Rubinelli,\nUniversity of Lucerne, Switzerland\n*CORRESPONDENCE\nFederico Pilati\nfederico.pilati@studenti.iulm.it\nRiccardo Gallotti\nrgallotti@fbk.eu\nPier Luigi Sacco\npierluigi.sacco@unich.it\nSPECIALTYSECTION\nThis article was submitted to\nSociological Theory,\na section of the journal\nFrontiers in Sociology\nRECEIVED /zero.tnum/eight.tnum November /two.tnum/zero.tnum/two.tnum/two.tnum\nACCEPTED /two.tnum/three.tnum December /two.tnum/zero.tnum/two.tnum/two.tnum\nPUBLISHED /one.tnum/seven.tnum January /two.tnum/zero.tnum/two.tnum/three.tnum\nCITATION\nPilati F, Gallotti R and Sacco PL (/two.tnum/zero.tnum/two.tnum/three.tnum)\nThe link between reported cases of\nCOVID-/one.tnum/nine.tnum and the Infodemic Risk\nIndex: A worldwide perspective.\nFront. Sociol. /seven.tnum:/one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nCOPYRIGHT\n\u00a9/two.tnum/zero.tnum/two.tnum/three.tnum Pilati, Gallotti and Sacco. This\nis an open-access article distributed\nunder the terms of the Creative\nCommons Attribution License (CC BY) .\nThe use, distribution or reproduction\nin other forums is permitted, provided\ntheoriginalauthor(s)and thecopyright\nowner(s) are credited and that the\noriginal publication in this journal is\ncited, in accordance with accepted\nacademicpractice.Nouse,distribution\nor reproduction is permitted which\ndoes not comply with these terms.The link between reported cases\nof COVID-/one.tnum/nine.tnum and the Infodemic\nRisk Index: A worldwide\nperspective\nFederico Pilati/one.tnum*, Riccardo Gallotti/two.tnum*and Pier Luigi Sacco/three.tnum*\n/one.tnumUniversit\u00e0 IULM, Milan, Italy,/two.tnumBruno Kessler Foundation (FBK), Trento, Italy,/three.tnumUniversity of Studies\nG. d\u2019Annunzio Chieti and Pescara, Chieti, Italy\nIn this brief report we followed the evolution of the COVID-/one.tnum/nine.tnum Info demic\nRisk Index during /two.tnum/zero.tnum/two.tnum/zero.tnum and clari\ufb01ed its connection with the epidem ic waves,\nfocusing speci\ufb01cally on their co-evolution in Europe, South Amer ica, and\nSouth-eastern Asia. Using /six.tnum/four.tnum/zero.tnum million tweets collected by the Inf odemic\nObservatory and the open access dataset published by Our World in Data\nregarding COVID-/one.tnum/nine.tnum worldwide reported cases, we analyze the COVID-/one.tnum /nine.tnum\ninfodemic vs. pandemic co-evolution from January /two.tnum/zero.tnum/two.tnum/zero.tnum to Decembe r /two.tnum/zero.tnum/two.tnum/zero.tnum.\nWe \ufb01nd that a characteristic pattern emerges at the global scale: a decrease\nin misinformation on Twitter as the number of COVID-/one.tnum/nine.tnum con\ufb01rmed cases\nincreases.Similarlocalvariationshighlighthowthispatter ncouldbein\ufb02uenced\nboth by the strong content moderation policy enforced by Twitter after the\n\ufb01rstpandemicwaveandbythephenomenonofselectiveexposure thatdrives\nusers to pick the most visible and reliable news sources availabl e.\nKEYWORDS\nCOVID-/one.tnum/nine.tnum,Twitter,InfodemicRiskIndex,selectiveexposure,c ontentmoderation\nIntroduction\nThe COVID-19 pandemic crisis has turned the issue of (mis)information creation\nand circulation into a major cause of public concern. As the crisis unfolded, it has\nbecome clear that the actual rise of COVID-19 infections has been anticipa ted by large\nwaves of potentially unreliable information that sowed mistrust and confusion in t he\npublic opinion ( Gallotti et al., 2020 ). As people\u2019s behavioral response to a pandemic\ncrisis is a crucial factor of success (or failure) of public health prescriptions ( such as\nwearing masks), circulating misleading information and undermining the credibility of\npublichealthauthoritiescancauseconsiderabledamageanddisrupttoalargeextent the\ne\ufb00ectivenessofpolicymeasures.\nSuch a loop between information acquisition and processing and adoption of\nmore or less e\ufb00ective health-related behaviors may be at the core of di\ufb00e rent country\nperformances in mitigating the outcomes of the global pandemic. For example,\nthe spread of click-bait content or the prevalence of non-specialist, misleading\nopinions over those of scientists and public institutions on key public health matters\nare two dangers that are looming behind the COVID-19 communicational crisis\nFrontiersin Sociology /zero.tnum/one.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\n(Damian and Gallo, 2020 ;O\u2019Connor and Murphy, 2020 ).\nA key challenge that the pandemic poses to our society is\ntherefore ensuring that correct, easily digestible information\nis received by citizens as a reliable guide to health-preserving\nchoices(Zarocostas,2020 ).Socialmediaplatformsarefullypart\nof this process. As it has been shown, online conversations\nhave a big impact upon the construction and perception of\nsocial reality, leading people to experience emotions without\nawareness ( Kramer et al., 2014 ) and in\ufb02uencing the opinions of\nmillions( Bond,2012 ).\nA fundamental key aspect of infodemic waves\u2014i.e., an\noverabundance of information that makes it di\ufb03cult for the\nmajority of the public opinion to distinguish between reliable\nand unreliable sources\u2014is their enormous pervasiveness both\nin news media and in the public\u2019s search for information\n(Eysenbach,2002 ,2009).WhentheCOVID-19crisisstruck,the\nwholemediaecosystemunderwentaninitialshock.Beingavery\npowerful public attention pointer, COVID-19 quickly became\nthecentraltopicofglobalconversationsatanyscale( Saccoetal.,\n2021). However, the rewards associated to the promotion of\nviral content by media outlets ( Bakir and McStay, 2018 ), and\ntheconsequentincentivesrelatedtothetradingofhighlyvisible\ndigital content for advertising and persuasive communication\n(Graham, 2017 ), has inevitably pushed the creation and\ncirculation of sensationalistic, unreliable information able to\ncapturetheattentionoflargenumbersofonlineusers( Donovan,\n2020). As a result, in the \ufb01rst months of 2020a huge number of\nscienti\ufb01c hoaxes \ufb02ourished and were disseminated on the web\n(McGintyandGyenes,2020 ).\nNevertheless, after the initial shock, extended surveys have\npartially changed the whole picture, showing how, faced with\na serious crisis and potentially deadly threats, people were\ncompelled to search and trust the information held by news\nsources considered reliable and familiar ( Nielsen et al., 2020 ;\nAltayetal.,2022 ).Ourresearchseemstocon\ufb01rmthese\ufb01ndings.\nBy analyzing a very large and heterogeneous dataset our results\nreveal the existence of a general negative correlation between\nthe Infodemic Risk Index and reported COVID-19 cases, when\nconsidered both at global and regional scale. Signi\ufb01cant local\nvariations are however observed across di\ufb00erent geographical\nmacro-areas a\ufb00ected by the pandemic. Indeed, comparing the\ncasesofEurope,SouthAmerica,andSouth-easternAsia,wehave\nbeenabletohighlightdi\ufb00erentco-evolutionarypathsaccording\ntodi\ufb00erentlocalconditions.\nMethods\nData collection\nThisarticleisbasedontheanalysisofTweetscollectedacross\n187 countries between 22nd January and 31st of December\n2020. We automatically collected Twitter data from the TwitterStreaming API by selecting tweets containing terms associated\nwith the COVID-19 epidemic, the virus that causes it and\nthe city where it was \ufb01rst discovered (coronavirus, ncov,\n#Wuhan, COVID19, COVID-19, SARS-CoV-2 and COVID).\nThe Streaming API limits our analysis to a random sample of\n1%ofthetotalnumberoftweetscirculating.Thislimithasbeen\nreached, for the keywords we selected, on February 25th 2020.\nStarting from that date, only a random subsample of about 4M\ntweets/day are collected. All tweets are then processed in order\ntoidentifythecountryoforiginandthetypeofnewscirculating.\nTheidenti\ufb01cationforthecountryoforiginisstraightforwardfor\na small fraction of \u223c0.8% of the total, for which the user shares\nthe coordinates of the location from which the tweet has been\nposted.Toextendthisidenti\ufb01cation,weconsidertheuser\u2019sself-\nde\ufb01ned location and derive the user\u2019s area of origin through a\ngeocodingservice. Afterspeci\ufb01c\ufb01ltering,thismethodallowsus\nto associate about 50% of all tweets to a country of origin. Our\ndatacollectionispossiblya\ufb00ectedbyaselectionbias,asTwitter\u2019s\nuser population skews the analysis toward well-educated males.\nInaddition,bycross-checkingwiththenewsreliabilitydatabase,\nthis bias can be further exacerbated by an overrepresentation\nof users tweeting in English, as English web domains are better\nclassi\ufb01ed in the databases we aggregated. However, in Gallotti\net al.(2020) it has been shown how, regardless of these possible\nbiases,ourmethodologyisappropriatetostudytheevolutionof\nthe COVID-19 infodemic in both time and space. In particular:\ni)therecallrateoftweetsassociatedwiththeCOVID-19topicis\nhigherthan16%andprobablyranginginthe40%-60%rangein\ntheearlierdaysofthepandemic;thetemporalpatternsobserved\nonthetweetswhoseprovenienceisfromtheU.S.A.asidenti\ufb01ed\nviageocodingservicesmatchthoseobservedfromtweetswhose\nexact coordinates fall within the American territory: the results\nofthemisinformationanalysisappearrobusttoTwitter\u2019spolicies\nto promote authoritative content by prioritizing the visibility of\no\ufb03cialsources.\nNews enrichment\nTo identify the type of news circulating, we cross-\ncheck the URL shared in tweets with a database that\naggregates di\ufb00erent sources and categorizes the reliability of\nnews web domains. To create the database we collected\na list of manually checked web domains from multiple\npubliclyavailabledatabases,includingscienti\ufb01candjournalistic\nones. Speci\ufb01cally, we considered data shared by the sources\nlistedin:\n\u2013 Zimdar, M. My fake news list went viral but made up stories\nare only part of the problem. The Washington Post (18\nNovember2016).\n\u2013 Silverman, C. Inside the partisan \ufb01ght for your news feed.\nBuzzFeedNews(8August2017).\nFrontiersin Sociology /zero.tnum/two.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\n\u2014 FakeNewsWatch(2015).Retrievefrom: https://web.archive.\norg/web/20180213181029/http://www.fakenewswatch.com/\n\u2014 Politifacts guide to fake news and what they peddle.\nPolitifacts.com (20April2017).\n\u2014 The black list. La lista nera del web. Bufale.net (2018).\nRetrievefrom: https://www.bufale.net/the-black-list-la-lista-\nnera-del-web/\n\u2014 Starbird, K., Arif, A., Wilson, T., Van Koevering, K.,\nYe\ufb01mova, K., and Scarnecchia, D. (2018). Ecosystem or\nEcho-System? Exploring Content Sharing across Alternative\nMedia Domains. Proceedings of the International AAAI\nConference on Web and Social Media , 12(1).https://doi.org/\n10.1609/icwsm.v12i1.15009\n\u2014 Nielsen, R. K., Fletcher, R., Cornia, A., and Graves, L.\n(2018). Measuring the reach of \u201cfake news\u201d and online\ndisinformation in Europe. ( https://reutersinstitute.politics.\nox.ac.uk/our-research/measuring-reach-fake-news-and-\nonline-disinformation-europe )\n\u2014 Grinberg, N. et al. Fake news on Twitter during the 2016 US\npresidentialelection.Science363,374\u2013378(2019).\n\u2014 MediaBias/FactCheck( https://mediabiasfactcheck.com/ ).\nWe found a total of 4,988 domains, reduced to 4,417 after\nremoving hard duplicates across databases. Note that a domain\nis considered a hard duplicate if its name and its classi\ufb01cation\ncoincideacrossdatabases.\nA second level of \ufb01ltering was applied to domains which\nare classi\ufb01ed di\ufb00erently across databases (e.g., xyz.com might\nbe classi\ufb01ed as FAKE/HOAX in a database and as SATIRE in\nanotherdatabase).Todealwiththesecases,weadoptedourown\nclassi\ufb01cation method, by assigning to each category a \u201cHarm\nScore\u201d between 1 and 9. When two or more domains were\nsoftduplicates,wekepttheclassi\ufb01cationwiththehighestHarm\nScore,asaconservativechoice.Thisphaseofprocessingreduced\ntheoveralldatabaseto3,920uniquedomains.\nTheHarmScoreclassi\ufb01essourcesintermsoftheirpotential\ncontributiontothemanipulativeandmis-informativecharacter\nof an infodemic. As a general principle, the more systematic\nandintentionallyharmfultheknowledgemanipulationanddata\nfabrication,thehighertheHarmScore(HS).\nA third level of \ufb01ltering concerned poorly de\ufb01ned domains,\ne.g., the ones explicitly missing top-level domain names, such\nas.com.org etc, as well as the domains not classi\ufb01able by means\nofourproposedscheme.Thisactionreducedthedatabasetothe\n\ufb01nalnumberof3,892entries.\nInfodemic Risk Index\nThe Infodemic Risk Index (IRI) represents an estimate of\nthe relative exposure of users to unreliable information. To\nestimate the exposure to unreliable news (Eu), we aggregate\nthe number of followers who are potentially reached by tweetscontainingunreliablenews.Conversely,theexposuretoreliable\nnews (Er), is obtained by aggregating the number of followers\npotentiallyreachedbytweetscontainingreliablenews.TheIRIis\n\ufb01nallycomputedasIRI =Eu/(Er+Eu).SeeGallottietal. (2020)\nfor further details, in particular on how analyzing an indirect\nmeasure of exposure using followers is largely equivalent to\nestimatingexposureusingactions(retweets,replies,quotes).\nCorrelation and regression analysis\nThe regressions presented in this article have been made\nusingthe statsmodels pythonlibrary.Weperformedlogarithmic\nregressions [y =log(x)], as this curve has been seen to\nmaximize the Akaike Information Criterion against possible\nalternativeforms(linear,powerlaw,logistic).Akaikeisnormally\nchosensincethealternativecurvesarecharacterizedbydi\ufb00erent\nnumbersofparameters.Curveswithmoreparametersnaturally\nadapt better to data, but are more prone to over\ufb01tting. Akaike\nconsiders this in a weight that accounts for the likelihood\nof a model considering the degrees of freedom. For this\ndata, the Akaike weights were: logarithmic 4.933530e-01; linear\n2.959338e-01; logistic 1.053566e-01; power law 5.690409e-\n136. The Spearman correlations and associated p-values are\ncomputed using the scipypython library. The Spearman\ncorrelation has been chosen as it is robust in the analysis of\nquantitiesrangingacrossseveralordersofmagnitudes.\nResults\nFinding1:Worldcountriesmosta\ufb00ectedbyCOVID-19have\nlowerinfodemicrisk./one.tnum\nAt a worldwide level (see Figure1), we found a weak\nanticorrelation between reported cases of COVID-19 and index\nof infodemic risk. This link is all the more evident as the size of\nthecountriesconsideredinthesampleincreases:infact,alarger\nsize of the population implies a larger number of cases and also\na larger statistical base to accurately and extensively count the\nimpactofCOVID-19.\nFinding2:ThenegativecorrelationbetweenIRIandcasesin\nSouth-EasternAsiaappearstobestrong.TheSpearman-rindex\nisequalto \u22120.42andtheassociatedp-valueis0.23.\n/one.tnum To test the increased correlation of IRI vs Number of Uncorrelat ed\nCases without rescaling by local population we repeatedly (/two.tnum/zero.tnum/zero.tnum/zero.tnum times)\nsample/one.tnum/zero.tnum/zero.tnumrandomcountriesamongthoseanalyzedthathadpopulat ion\ndatacorrectlyindicatedbytheOECDfortheyear/two.tnum/zero.tnum/two.tnum/zero.tnum.In\ufb01gure\u201c IRIvs.p-\nvalue\u201dofthe Supplementary material weplotthep-valueoftheSpearman\ncorrelation for P.C. and total cases against the Infodemic Risk Ind ex. In\nonly /one.tnum/two.tnum./five.tnum% of the samples the p-value is smaller using the per- capita\nnumber of cases, while in /two.tnum/four.tnum./two.tnum% of samples the p-value associa ted with\nthe total number of cases is lower than /zero.tnum./zero.tnum/five.tnum.\nFrontiersin Sociology /zero.tnum/three.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nFIGURE/one.tnum\nCorrelation between IRI and total number of COVID-/one.tnum/nine.tnum cases world wide. Description: scatterplot showing a moderate but signi\ufb01can t\nanti-correlation between COVID-/one.tnum/nine.tnum cases and IRI across the /one.tnum/seven.tnum/seven.tnum countries considered (Spearman-r is \u2212/zero.tnum./one.tnum/six.tnum and the p-value is /zero.tnum./zero.tnum/three.tnum/three.tnum). The\ncorrelation is strongly reduced as compared to the early days of th e pandemic as analyzed in Gallotti et al. (/two.tnum/zero.tnum/two.tnum/zero.tnum), where Spearman-r was \u2212/zero.tnum./three.tnum/three.tnum\nand thep-value is /zero.tnum./zero.tnum/zero.tnum/zero.tnum/nine.tnum. The regression curve shown here and in all graph s is a logarithmic regression, which was selected using an Akaike\ncriterion against a linear and a logistic regression. The shaded ar ea represents the /nine.tnum/five.tnum% con\ufb01dence interval, and the size of the c ircle represents\nthe number of Tweets collected. Two countries (Peru and Kosovo) ar e not visualized in the plot as they have IRI >/zero.tnum./nine.tnum.\nSouth-Eastern Asian countries present from the beginning\nofthepandemicamarkeddi\ufb00erenceinthepatternofinfodemic\nrisk. The IRI directly re\ufb02ects the extent to which each single\nstateintheregionhasbeenexposedtothepandemicwaves(see\nFigure2).Oncetheinitialcrisisstabilizesandthecasesincrease\nall over the region, even in the less risky countries there is a\ngeneral increase of possibly harmful contents circulating in the\nTwittersphere(see Supplementarymaterial ).\nFinding3:ThenegativecorrelationbetweenIRIandcasesin\nEurope is as strong as in South-Eastern Asia. The Spearman-r\nindexisequalto \u22120.50andtheassociated p-valueis0.007.\nUnlike Asean countries, in Europe the \ufb01rst wave of\npandemic has been anticipated by a big, generalized surge of\ninfodemic risk. As the number of cases increases, particularly\nin the most a\ufb00ected countries, the IRI visibly decreases (see\nFigure3). This phenomenon could be observed in all countries\nthataregraduallya\ufb00ectedbythewavesofinfectionandremains\nstableovertime(see Supplementarymaterial ).\nFinding 4: The correlation between IRI and cases in South\nAmerica follows a positive pattern. The Spearman-r index is\nequalto+0.46withanassociated p-valueof0.13.Finally, in South America the evolution of the relationship\nbetween IRI and COVID-19 cases directly re\ufb02ects the trend of\nthe pandemic (see Supplementarymaterial ). With an increase\nin the number of cases, countries experience an increase in\ndisinformationcontentcirculatingonTwitter(see Figure4).\nDiscussion\nFrom its very beginning, the COVID-19 crisis immediately\nraised concerns for risks generated by a possible infodemic of\ninaccurate information and how social media users would have\ndealt with it. In this brief report using the Tweets collected\nthrough the Infodemic Observatory\u2019s and the COVID-19 cases\nreportedbyOurWorldinData,weanalyzedtheco-evolutionof\nthe Infodemic Risk Index and the pandemic from January 2020\ntoDecember2020.Our\ufb01ndingsdescribeaworldwidepatternof\nongoinganti-correlationbetweenInfodemicRiskIndexandthe\nreported cases of COVID-19. This relationship clearly emerges\nas the size of the countries in the sample increases: larger\ncountrypopulationimpliesalargernumberofcasesandalarger\nstatisticalbasistoassesstheimpactofIRIandCOVID-19.\nFrontiersin Sociology /zero.tnum/four.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nFIGURE/two.tnum\nCorrelation between IRI and number of COVID-/one.tnum/nine.tnum cases in South-E astern Asia.\nEach of the macro-areas examined shows a distinctive\npattern of its own. South-eastern Asian countries present,\nfrom the beginning of the pandemic, a marked di\ufb00erence in\ninfodemic risks as compared to other countries. Furthermore,\ntheir IRI directly re\ufb02ects a speci\ufb01c country\u2019s exposure to the\npandemic waves. However, once the initial crisis stabilizes\nand the cases increase all over one region, even in the less\nrisky countries there is a general increase of possibly harmful\ncontents circulating in the Twittersphere. For example, unlike\ntheAseancountriestrends,inEuropethe\ufb01rstwaveofpandemic\nis preceded by a big, generalized surge of infodemic risk. As\nthe number of cases increases, however, and particularly in\nthe most a\ufb00ected countries, the IRI visibly decreases. This\nphenomenon could be observed in all countries that are\ngradually a\ufb00ected by the waves of infection and remain stable\nover time. Finally, in South America the relation between IRI\nand COVID cases is proportional to the trend of the pandemic:\nas countries experience an increase in the number of cases,\na corresponding increase in misleading content circulating on\nTwitterfollows.\nThe negative correlation trend identi\ufb01ed at a global scale\ncan be partially explained by two di\ufb00erent characteristics of the\nonline and communication environments recorded since the\nonsetofthepandemic.The\ufb01rstistheso-calledselectivetrustor\nselective exposure phenomenon observedby Altay et al. (2022).Ourdatasupportsuchatheory:asthepandemicgrows,citizens\nand the broader media ecosystem seem to be driven to pay\nmore attention to reliable sources such as mainstream media.\nThis e\ufb00ect could be further strengthened by an information\ncascadephenomenon,whichisverycommoninTwitter.Indeed,\ntheknowledgecommunitiesrelatedtoCOVID-19thatpopulate\nTwitter are extremely hierarchical and mutually disconnected\n(Sacco et al., 2021 ). Therefore, a shift toward more reliable\nsourcesbythetopandmiddlein\ufb02uencersofthesecommunities\ncould trigger a cascade e\ufb00ect on the entire \ufb02ow of information\nregardingCOVID-19.\nAnother possible reason behind the IRI decrease is a\nstronger focus on moderating conversations about COVID-19\nby social media. This process may have been accelerated by\nthe U.S. election\u2014which triggered several monitoring projects\nregarding the politicization of COVID-19 issues ( Chen et al.,\n2021)\u2014with possible spillovers worldwide. For example, in the\ncase of Indonesia, we could observe how most of the trolls\nand bots polluting the conversation in the early months of the\npandemic were promptly removed from Twitter ( Sacco et al.,\n2021).\nAs for the di\ufb00erences in patterns across the macro-\nregions, they may depend on two di\ufb00erent factors. The \ufb01rst,\nand most obvious, are cultural di\ufb00erences that determine\nmedia consumption habits and attitudes toward the pandemic.\nFrontiersin Sociology /zero.tnum/five.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nFIGURE/three.tnum\nCorrelation between IRI and number of COVID-/one.tnum/nine.tnum cases in Europe.\nIn fact, as suggested by Gelfand et al. (2021), di\ufb00erent\ncultures at national levels may have a big in\ufb02uence upon\nindividual behavioral responses to COVID-19. A second factor\nrelates to the politicization of the COVID-19 topic, and this\nwould explain, for example, the positive correlation trend in\nSouth America. Indeed, a direct consequence of information\nmanipulation strategies used by populist leaders, such as\nBolsonaro ( Ricard and Medeiros, 2020 ), can reinforce the\nsharing of misinformation. On the contrary, the bottom-up\nmovements of fact-checking emerged in countries such as\nSouth Korea ( Chang et al., 2021 ) could have impacted in its\ncirculationreduction.\nTo sum up, our \ufb01ndings advance scienti\ufb01c literature on\nthe infodemic in two di\ufb00erent and complementary ways. First,\nas claimed by other empirical measures of Twitter ( Yang\net al., 2021 ), our results highlight how the e\ufb00ort on content\nmoderation might have helped to drastically reduce the spread\nof COVID-19 misinformation. Second, our report supports the\nidea that when social media users face high health risks these\nvery same users are compelled to search and trust information\nheld by reliable news sources ( Nielsen et al., 2020 ;Altay et al.,\n2022).\nFinally it is important to conclude with a postilla regarding\nthe methodological limitations of our research. As it is wellknown, the demographics of Twitter users are biased toward\nwell-educated males (65 percent of Twitter users) between the\nages of 18 and 34 (58 per cent of Twitter users, according to\nStatista GmbH). Our results therefore have to be interpreted\nkeeping such demographic limitations in mind. Another\nimportant limitation is the necessarily restricted choice of\nhashtags which, although carefully designed, inevitably miss\nthosepartsofthesocialmedia\ufb02owthatarenottaggedaccording\nto the most common signi\ufb01ers. However, it is important to\nconsiderthattothecurrentstateofknowledgethereisnowayto\nbuildapotentiallyunbiased,representativesampleofthepublic\nopinion at the regional, national or global level, and to track\nits time evolution for relatively long periods. It will however be\nimportanttoexpandthesemethodstocoverseveralsocialmedia\nat once, whose combined demographics and trend topics allow\nthecoverageofdi\ufb00erentportionsofthepublicopinion.\nOur results are just a \ufb01rst step in understanding the\nloop between communications and the COVID-19 epidemic.\nNevertheless, the recorded decrease for the Infodemic Risk\nIndex as COVID-19 cases rise implies that pandemic-related\nmisinformation can be successfully dealt with and that\nunderstanding the social and behavioral mechanisms behind\nits di\ufb00usion are essential building blocks for a successful\nmisinformationcurbingstrategy.\nFrontiersin Sociology /zero.tnum/six.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nFIGURE/four.tnum\nCorrelation between IRI and number of COVID-/one.tnum/nine.tnum cases in South Am erica.\nData availability statement\nPublicly available datasets were analyzed in this study. This\ndatacanbefoundhere: https://covid19obs.fbk.eu/#/ .\nAuthor contributions\nFP, RG, and PS designed the research and interpreted the\nresults and wrote the brief report. RG collected and analyzed\nthedata.Allauthorscontributedtothearticleandapprovedthe\nsubmittedversion.\nFunding\nThis research received partial funding from the\nWHO to help assist and build the COVID-19 Infodemic\nObservatory( https://COVID19obs.fbk.eu/ ).\nAcknowledgments\nWe would like to thank Manlio De Domenico and the\nCoMuNeLabfortheircollaborationintheresearch.Con\ufb02ict of interest\nThe authors declare that the research was conducted in\nthe absence of any commercial or \ufb01nancial relationships\nthat could be construed as a potential con\ufb02ict\nofinterest.\nPublisher\u2019s note\nAll claims expressed in this article are solely those\nof the authors and do not necessarily represent those\nof their a\ufb03liated organizations, or those of the publisher,\nthe editors and the reviewers. Any product that may be\nevaluated in this article, or claim that may be made by\nits manufacturer, is not guaranteed or endorsed by the\npublisher.\nSupplementary material\nThe Supplementary Material for this article can be\nfound online at: https://www.frontiersin.org/articles/10.3389/\nfsoc.2022.1093354/full#supplementary-material\nFrontiersin Sociology /zero.tnum/seven.tnum frontiersin.org\nPilati et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fsoc./two.tnum/zero.tnum/two.tnum/two.tnum./one.tnum/zero.tnum/nine.tnum/three.tnum/three.tnum/five.tnum/four.tnum\nReferences\nAltay, S., Nielsen, R. K., and Fletcher, R. (2022). Quantifying the \u201cinfodemic\u201d:\nPeopleturnedtotrustworthynewsoutletsduringthe2020coron aviruspandemic.\nJ.Quant.Descrip.DigitalMedia 2.doi:10.51685/jqd.2022.020\nBakir, V., and McStay, A. (2018). Fake news and the economy\nof emotions: Problems, causes, solutions. Digital J. 6, 154\u2013175.\ndoi:10.1080/21670811.2017.1345645\nBond, R. M. (2012). A 61-million-person experiment in social in\ufb02u ence and\npoliticalmobilization. Nature489,295\u2013298.doi:10.1038/nature11421\nChang,H.C.H.,Pham,B.,andFerrara,E.(2021).KPopFandom sdrivecovid-19\nPublicHealthMessagingonSocialMedia. arXivpreprintarXiv: 2110,04149.\nChen, E., Chang, H., Rao, A., Lerman, K., Cowan, G., and Ferrar a, E.\n(2021).COVID-19misinformationandthe2020U.S. presidentialelection.Harvard\nKennedySchool(HKS)Misinform.Rev .doi:10.37016/mr-2020-57\nDamian,A.J.,andGallo,J.J.(2020).Promotinghealthliteracy duringthecovid-\n19pandemic:acalltoactionforhealthcareprofessionals. HarvardKennedySchool\nMisinform.Rev .doi:10.37016/mr-2020-027\nDonovan, J. (2020). Social-media companies must \ufb02atten the cur ve of\nmisinformation. Nature.doi:10.1038/d41586-020-01107-z\nEysenbach, G. (2002). Infodemiology: The epidemiology of (mis) information.\nAm.J.Med. 113,763\u2013765.doi:10.1016/S0002-9343(02)01473-0\nEysenbach, G. (2009). Infodemiology and infoveillance: framew ork for\nan emerging set of public health informatics methods to analyze s earch,\ncommunicationandpublicationbehaviorontheInternet. J.Med.InternetRes. 11,\ne11.doi:10.2196/jmir.1157\nGallotti, R., Valle, F., Castaldo, N., Sacco, P., and De Domenico, M. (2020).\nAssessingtherisksof\u2018infodemics\u2019inresponsetocovid-19e pidemics. Nat.Human\nBehav.4,1285\u20131293.doi:10.1038/s41562-020-00994-6\nGelfand, M. J., Jackson, J. C., Pan, X., Nau, D., Pieper, D., Deni son, E.,\net al. (2021). The relationship between cultural tightness\u2013loo seness and covid-19cases and deaths: a global analysis. Lancet Planet. Health . 5, E135\u2013E144.\ndoi:10.1016/S2542-5196(20)30301-6\nGraham, R. (2017). Google and advertising: digital capitalism in the context\nof PostFordism, the rei\ufb01cation of language, and the rise of fa ke news. Palgrave\nCommun. 3,1\u201319.doi:10.1057/s41599-017-0021-4\nKramer, A. D.,Guillory, J. E., and Hancock, J. T. (2014). Experim ental evidence\nof massive-scale emotional contagion through social networ ks.Proc. Natl. Acad.\nSci.111,8788\u20138790.doi:10.1073/pnas.1320040111\nMcGinty, M., and Gyenes, N. (2020). A Dangerous Misinfodemic Spreads\nAlongsidetheSARS-CoV-2Pandemic .HarvardKennedySchool(HKS)Misinform.\nRev.\nNielsen, R., Fletcher, R., Newman, N., Brennen, J., and Howard , P. (2020).\nNavigating the \u2018infodemic\u2019: How people in six countries access and rat e news\nand information about coronavirus .https://reutersinstitute.politics.ox.ac.uk/\ninfodemic-how-people-six-countries-access-and-rate-new s-and-information-\nabout-coronavirus\nO\u2019Connor, C., and Murphy, M. (2020). Going viral: doctors must t ackle fake\nnewsintheCOVID-19pandemic. BMJ24,m1587.doi:10.1136/bmj.m1587\nRicard, J., and Medeiros, J. (2020). Using Misinformation a s a political weapon:\ncovid-19andBolsonaroinBrazil. HarvardKennedySchool(HKS)Misinform.Rev.\ndoi:10.37016/mr-2020-013\nSacco, P. L., Gallotti, R., Pilati, F., Castaldo, N., and De Domen ico,\nM. (2021). Emergence of knowledge communities and informati on\ncentralization during the COVID-19 pandemic. Soc. Sci. Med. 285, 114215.\ndoi:10.1016/j.socscimed.2021.114215\nYang, K. C., Pierri, F., Hui, P. M., Axelrod, D., Torres-Lugo, C., Bryden, J.,\net al. (2021). The covid-19 infodemic: Twitter versus facebo ok.Big Data Soc. 8,\n20539517211013861.doi:10.1177/20539517211013861\nZarocostas, J. (2020). How to \ufb01ght an infodemic. Lancet395, 676.\ndoi:10.1016/S0140-6736(20)30461-X\nFrontiersin Sociology /zero.tnum/eight.tnum frontiersin.org", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The link between reported cases of COVID-19 and the Infodemic Risk Index: A worldwide perspective", "author": ["F Pilati", "R Gallotti", "PL Sacco"], "pub_year": "2023", "venue": "Frontiers in Sociology", "abstract": "In this brief report we followed the evolution of the COVID-19 Infodemic Risk Index during  2020 and clarified its connection with the epidemic waves, focusing specifically on their co-"}, "filled": false, "gsrank": 609, "pub_url": "https://www.frontiersin.org/articles/10.3389/fsoc.2022.1093354/full", "author_id": ["3uMf-TQAAAAJ", "3XaGvR0AAAAJ", "xnwu184AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:wxmC6SppCokJ:scholar.google.com/&output=cite&scirp=608&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D600%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=wxmC6SppCokJ&ei=c7WsaKrNI5XUieoPmrax2A8&json=", "num_citations": 1, "citedby_url": "/scholar?cites=9874820765990394307&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:wxmC6SppCokJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.frontiersin.org/journals/sociology/articles/10.3389/fsoc.2022.1093354/pdf"}}, {"title": "Understanding high-and low-quality URL Sharing on COVID-19 Twitter streams", "year": "2020", "pdf_data": "Vol.:(0123456789)Journal of Computational Social Science (2020) 3:343\u2013366\nhttps://doi.org/10.1007/s42001-020-00093-6\n1 3\nRESEARCH ARTICLE\nUnderstanding high\u2011 and\u00a0low\u2011quality URL Sharing \non\u00a0COVID\u201119 Twitter streams\nLisa\u00a0Singh1\u00a0\u00b7 Leticia\u00a0Bode1\u00a0\u00b7 Ceren\u00a0Budak2\u00a0\u00b7 Kornraphop\u00a0Kawintiranon1\u00a0\u00b7 \nColton\u00a0Padden1\u00a0\u00b7 Emily\u00a0Vraga3\nReceived: 16 July 2020 / Accepted: 23 October 2020 / Published online: 27 November 2020 \n\u00a9 The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. part of Springer Nature 2020\nAbstract\nThis article investigates the prevalence of high and low quality URLs shared on Twitter when users discuss COVID-19. We distinguish between high quality health sources, traditional news sources, and low quality misinformation sources. We find that misinformation, in terms of tweets containing URLs from low quality misin-formation websites, is shared at a higher rate than tweets containing URLs on high quality health information websites. However, both are a relatively small proportion of the overall conversation. In contrast, news sources are shared at a much higher rate. These findings lead us to analyze the network created by the URLs referenced on the webpages shared by Twitter users. When looking at the combined network formed by all three of the source types, we find that the high quality health informa-tion network, the low quality misinformation network, and the news information net-work are all well connected with a clear community structure. While high and low quality sites do have connections to each other, the connections to and from news sources are more common, highlighting the central brokerage role news sources play in this information ecosystem. Our findings suggest that while low quality URLs are not extensively shared in the COVID-19 Twitter conversation, a well connected community of low quality COVID-19 related information has emerged on the web, and both health and news sources are connecting to this community.\nKeywords COVID-19\u00a0\u00b7 Coronavirus\u00a0\u00b7 Twitter conversation\u00a0\u00b7 Misinformation\u00a0\u00b7 Low \nquality domains\n * Lisa Singh \n lisa.singh@georgetown.edu\n1 Georgetown University, Washington,\u00a0DC, USA\n2 University of\u00a0Michigan, Ann\u00a0Arbor, USA\n3 University of\u00a0Minnesota, Minneapolis, USA\n344 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nIntroduction\nSocial media are a significant conduit for news and information in the modern \nmedia environment, with one in three people in the world engaging in social media, and two thirds of those on the Internet using it\u00a0 [44]. The popularity is higher in the United States with 68% of American adults reporting that they get their news on social media\u00a0[37]. This is particularly true for health and science information, with a third of people reporting that social media are an \u201cimportant\u201d source of science news\u00a0[29]. Twitter, in particular, is known for sharing and con-suming news: 59% of its users describing it as \u201cgood\u201d or \u201cextremely good\u201d for sharing preventive health information\u00a0[63].\nOf course, there is a great deal of research that examines the existence and \nspread of misinformation on Twitter \u00a0 [3 , 14, 53], including that spread by \nbots \u00a0[21, 50]. Most notably, several researchers took interest in this phenomenon \nfollowing the 2016 US Presidential Election \u00a0 [8 , 14, 25]. Clearly, misinforma-\ntion abounds on Twitter, and the problem may be growing relative to other plat-forms \u00a0[3 ]. Given its prevalence on Twitter, we would expect to see it proliferate \nduring a pandemic as well.\nMore specifically, social media are also rife with health misinformation. \nHealth misinformation\u2014often defined as information that counters best available evidence from medical experts at the time ([62]; see also\u00a0[23, 43, 56])\u2014has been \ndocumented across almost all social media platforms, including Facebook, Twit-ter, YouTube, Pinterest, and Instagram\u00a0[12, 13, 20, 27, 45, 52]. Moreover, health \nmisinformation is not limited to any one issue, and may be of special concern for global health crises like the Ebola outbreak in 2014 and the spread of Zika in 2016, where research documented high prevalence and popularity of health mis-information topics\u00a0[20, 45, 52].\nOne illustrative example of misinformation on social media relates to the \nemergence of online communities around anti-vaccination attitudes and beliefs. Although so-called \u201canti-vaxxers\u201d are a minority of the population, they are a vocal and growing community on social media platforms like Twitter \u00a0 [28]. The communities that form around these sentiments also tend to be \u201chighly clustered\u201d \u00a0 [66], engaging with one another, but not with other networks of users \u00a0[28]. They are also vulnerable to misinformation, which spreads easily on social media \u00a0[6 ], and is most rampant among the overconfident \u2013 that is, those \nwho think they know more than experts \u00a0[39].\nUnfortunately, there is reason to be even more concerned about the quality \nof such information in today\u2019s news ecosystem compared to that of earlier epi-demics. As recent research shows, trust in institutions is eroding\u00a0 [58] and this is accompanied by renewed concern about the spread of misinformation online. In response, the World Health Organization raised alarms about an \u201cinfodemic\u201d regarding the novel coronavirus that causes COVID-19, which they defined as \u201coverabundance of information\u2014 some accurate and some not\u2014that occurs during an epidemic. It can lead to confusion and ultimately mistrust in govern-ments and public health response\u201d\u00a0[65]. Citing social media as a key driver in the \n345\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \ninfodemic, the WHO called upon researchers to better define and understand the \nscope of high and low quality information spread on social media.\nThis article attempts to answer this call. We investigate webpages (information \nsources) being shared on Twitter when users discuss COVID-19, distinguishing between high quality health sources, traditional news sources, and low quality infor -\nmation sources. We then investigate the networks that exist among the information sources. This gives us insight into whether or not communities are emerging around sources of high quality, low quality, and news information, or between them, and more generally what these ecosystems look like. We find that (1) misinformation, in terms of URL links to low quality information sites, is shared at a higher rate than links to high quality health information, but remains a relatively small proportion of the COVID-19 Twitter conversation; (2) news sources are shared at a higher volume than either low or high quality sources; (3) the networks of each group of informa-tion sources are well connected, with clear community structure, indicating an emer -\ngence of both a high quality information subnetwork and a low quality information subnetwork; and (4) while high and low quality sites do have connections to each other, the number of connections to and from news sources is larger, highlighting the central role news sources play in the sharing of both high and low quality infor -\nmation. These findings suggest that even though low quality misinformation sources related to COVID-19 are not shared extensively on Twitter, the community structure that connects these sources to credible sources provides pathways for individuals to be exposed to low quality content related to COVID-19, or vice versa.\nResearch questions\nDuring a pandemic or other emerging crisis, public interest in news and information tends to be quite high\u00a0[5], and the COVID-19 pandemic is no exception\u00a0[4]. How -\never, the nature of these crises\u2013especially in terms of the uncertainty surrounding a rapidly emerging infectious disease like COVID-19 - may lead people to share sub-optimal information.\nTypes and\u00a0frequency of\u00a0shared URL content\nWhile we might want the public to be relying on health information shared by rep-\nutable health organizations, we do not know if this is the case. Likewise, people are expected to depend heavily on the news media during crisis situations to orient themselves to new information and build community\u00a0[5]. Finally, low quality infor -\nmation and misinformation may also be prevalent online. While the 2016 election brought attention to this issue\u00a0[7], it is nothing new-especially in the health domain. For instance, a 2010 study by\u00a0[47] examined 1000 randomly selected tweets men-tioning antibiotics and found that 700 of them contained medical misinformation or malpractice.\nTherefore, it is not surprising that similar trends appear to be emerging when con-\nsidering the prevalence of misinformation on social media surrounding COVID-19 \n346 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\n[1, 33, 51, 55]. While the type of misinformation being studied varies in these stud-\nies, all the studies show that misinformation sharing is occurring. According to a \nEuropean Union External Action Committee Report, \u201csubstantive amount of both misinformation and disinformation are spreading on- and offline\u201d [22]. Kousy and colleagues [33] used a random sample of tweets containing different coronavirus keywords and hashtags, and found that misinformation and unverifiable content within the tweets was being shared at a high rate, particularly by individual and informal group accounts (33.8%). Researchers have identified a number of conspir -\nacy theories being shared [1, 51, 55], e.g., linking 5G to COVID-19, but the levels \nof sharing, the information cascades related to some of these conspiracies, and the belief in the conspiracy vary depending upon the user group studied and the specific conspiracy. [30] analyzed a set of misinformation claims identified by Google Fact Check Explorer and found that 88% of these claims were posted on social media sites, and that most of the information was recontextualization or \u2018spinning\u2019 of fac-tual information. The focus of these mentioned studies has been on studying content of a tweet and identifying specific pieces of misinformation in that content. We take a different yet complementary approach by focusing on the URLs being shared and categorizing them according to their web-domains. This allows us to focus on the original producers of content being shared.\nOur first descriptive analysis thus focuses on understanding the original producers \nof content that users are sharing with each other when using a COVID-19 hashtag. Twitter is generally a low trust environment (for example, in 2020 54% of those who had heard of Twitter said they distrusted it\u00a0[32]), which might suggest that much of the content is low-quality. How does that apply when it comes to COVID-19? Are individuals who share URLs linking to sources that generally share misinfor -\nmation, traditional news sources, or health organizations\u2019? Which are shared most frequently, and how does this change over time?\nCOVID\u201119 information ecosystem\nEarlier work on Twitter networks focused on how to model message diffusion and \npropagation [15, 31]. Later, scholars focused on characterizing specific networks of \nmisinformation using Twitter data\u00a0[19, 57, 67]. More recently, researchers moved \nbeyond case studies and investigated the diffusion of true and false information, and found that lies spread faster than truths on Twitter [15]. This previous work leads us to consider relationships among the sources/domains of the shared URL content.\nThe second descriptive analysis, therefore, focuses on understanding the eco-\nsystem of the information sources shared by Twitter users. Specifically, our goal is to understand the connectivity (URL link structure) of the domains of the shared URLs. This allows us to investigate the following questions: Do different catego-ries of sources link to each other? Which categories link to one another most often? Understanding these dynamics begins to gives us insight into whether or not net-works of subgroups in the ecosystem have formed, and the pathways that exist between high and low quality information.\n347\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nMethodology\nThis section begins by describing our Twitter data set. We then explain the method-\nology used for each analysis.\nDescription of\u00a0data set\nUsing the Twitter Streaming API, we began collecting tweets related to COVID-\n19 on January 16, 2020. Data collection continues, but the data we present in this study is from January 16, 2020 to April 15, 2020. Table\u00a0 6 in Appendix A shows the \nEnglish hashtags we used to collect data and the date we began collecting data for the hashtag. Most of the data collection began in January, and additional hashtags were added in mid-March to reflect the changing nature of the conversation around COVID-19 online.\u00a0\n1 During the study period of January 16 through April 15, 11.2 \nmillion tweets, 1.5 million quotes, and 54.5 million retweets were shared.\nURL shares methodology\nWe begin by identifying all of the URLs that are shared in each tweet, retweet, and \nquote in our data set. Our tweets are not truncated and the data from the API is a JSON record. We extract the URLs from the JSON record, they are a separate field in the JSON record. If we have a retweet or a quote, we extract the URLs in the par -\nent tweet and remove URLs to the original tweets.\nWe then reduce each URL to the web domain and count the frequency of each \ndomain to determine the most popular domains. Considering only the domain, rather than the content itself, is a relatively blunt measure of misinformation, but one that is commonly used for similar research purposes \u00a0[8, 9, 25, 50]. As one arti-\ncle described it, \u201cthe attribution of \u201cfakeness\u201d is thus not at the level of the story but at that of the publisher\u201d \u00a0[25].\nTo differentiate the quality of the information shared, we categorize the sources \nor webpage domains of the shared content, and focus on three relevant groups for understanding information quality: high-quality health sources, news sources, and low-quality/questionable content providers. While there are other groups that may be relevant, we focus on traditional information sources that the general public are more likely to find and share on social media.\nHigh-Quality Health Sources (HQHS): In April 2020, we identified the set of \nreputable web domains that publish health information as follows. We first deter -\nmined all the countries identified by the CDC as a Level 3 travel health notice country (that is, with the recommendation to \u201cavoid all non-essential travel\u201d). For each of these countries, we identify the web domain of each country\u2019s equiva-lent to a Center for Disease Control. Next, we augmented this list by including \n1 Note that due to a data collection glitch with the Twitter Streaming API, some of the hashtags were \nunavailable between March 13, 2020 and March 15, 2020.\n348 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\ntop medical journals and hospitals, and by identifying additional US government \nagencies that had official COVID-19 related recommendations (for example, while not a public health organization, the EPA released information about effec-tive disinfectants). After the White House announcement regarding the America\u2019s Health Insurance Plan\u2019s collaboration with the White House Coronavirus Task Force, the AHIP Statement page clarifying the free testing plan was also included on this list. In total, there are 39 sources included in this list.\nTraditional News Sources (TNS) To identify reputable news sources, we adopt \nthe definition and list of traditional news sites shared by MediaBias FactCheck\u2014an independent online media outlet maintained by a small team of researchers and journalists\u00a0[38]. This list has over one thousand three hundred web domains listed as reliable news sources. We distinguish these from HQHS because we want to understand the relationship between links in articles they post and HQHS and LQMS sites.\nLow-quality/Misinformation Sources (LQMS) We identify the set of low-qual-\nity/questionable sources in two ways. First, we aggregate information using a list curated by NewsGuard\u00a0[42]. NewsGuard is a journalistic organization that gener -\nally rates websites on their tendency to spread true or false information. Since the COVID-19 outbreak, they have kept a separate list of websites identified as prop-agating misinformation specifically related to the virus. Second, we rely on lists of low-quality and fake news producers aggregated by various scholars and fact-checking organizations\u00a0[11]. A short summary of the lists are described below: \n1. ZIMDARS: Zimdars et\u00a0al.\u00a0[68] tag websites with at most 3 of the following sub-\ncategories: fake, satire, bias, conspiracy, rumor, state, junksci, hate, clickbait, \npolitical, reliable, unidentified, and unreliable.\n2. MBFC: Media Bias/Fact Check is an independent online media outlet maintained by a small team of researchers and journalists\u00a0[61]. Similar to [68], the list they create assigns domains to subcategories. Their list uses the following three sub-categories: fake, conspiracy, satire.\n3. POLITIFACT : The staff of PolitiFact, in collaboration with Facebook, created a \nlist of the most-shared fake news sites leading up to the 2016 U.S. Presidential election on Facebook\u00a0[46]. This list labels sites using the following categories: fake, imposter, some fake, or parody.\n4. DAILYDOT: the Daily Dot\u2014a mainstream online news site created a list by ref-\nerencing other pre-existing fake news lists.\n5. ALLCOTT: Allcott et\u00a0al.\u00a0[2 ] aggregated the following five lists shared by: Politi-\nfact, Grinberg et\u00a0al.\u00a0[24], Silverman\u00a0[54], Schaedel\u00a0[48], and Guess et\u00a0al.\u00a0[26]. The subcategorization process is as follows: Politifact subcategories were ignored and all the domains were relabeled as fake. The subcategories black, red, orange  \n(black: completely false, red/orange: has unreliable claims) of\u00a0[24] were main-tained. All domains from other referenced lists were labeled as fake.\nBecause these lists have different subcategories of low quality information, for consistency, we focus on using the fake category across the different sources. We \n349\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nperform robustness checks to understand how consistent our results are across \nthe various lists since past work shows results can vary depending on the list used\u00a0[11]. In total, our list contains 1249 low quality sources.\nTo determine the set of HQHS, TNS, and LQMS domains observed in our Twit-\nter data set, we first identify all of the URLs that are shared in our data set. We resolve redirects to determine the base web address. We then download the refer -\nenced webpage. We initially downloaded webpages in March 2020 and then added the remaining webpages in late April 2020.\n2 Finally, we identify all of the URLs that \nare embedded on the downloaded webpage, e.g. a link to the CDC site in a particular New York Times article. We then aggregate this information to determine how often different sources are shared. In total, 92% of the URL content was downloaded and analyzed using this process. The remaining content resulted in URLs that were not resolved or resolved to different file types such as gifs or pdfs. The largest portion of the unlabeled data was bit.ly addresses that did not resolve to a valid URL.\nInformation sources network methodology\nFor each webpage we downloaded, we extracted all the URLs that were embedded \nin the webpage. We then reduced them to their domains. We construct a directed, weighted network by identifying domain source and destination pairs. For example, if three CNN news articles reference a CDC webpage, we would construct a directed edge from the CNN domain node to the CDC domain node. The edge weight of the directed edge would be three. We built an overall network of all the different types of information sources to determine whether or not there was connectivity across all of them. We then built separate networks for each of the information groups: HQHS, TNS, and LQMS. We compute standard network statistics, including degree, betweenness, eigenvector, and clustering coefficients. We also use the modularity clustering algorithm [41] to better understand the community structure for each information group. We used the NetworkX implementation of the algorithm and conducted an extensive sensitivity analysis to determine the final number of clusters.\nFindings and\u00a0analysis\nSocial media users commonly rely on external information to convey ideas, sup-port claims, and serve information needs. Social media use around COVID-19 is no exception. Our analysis of tweets related to the disease shows that 40.04% of origi-nal tweet content, 4.85% of the retweeted content, and 10.76% of the overall content includes a URL. While we do not have a random sample of tweets to compare this to, studies of different user groups have shown high levels of information sharing among the group, e.g. computer scientists [49]. While those levels are higher than the levels in our data set, it is clear that URL information sharing is occurring and \n2 Note that some of the content may have changed between the initial sharing of the webpage on Twitter \nand the moment we downloaded the page.\n350 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nmay reflect the incredible need for information in this uncertain time\u00a0[4, 5]. Uncer -\ntainty is strongly related to information seeking, and this has been shown specifi-\ncally in the realm of health information seeking and sharing online: \u201cWhen there is a lack of sufficient information from traditional medical professionals, uncertainties arise and online media provide individuals with an opportunity for further informa-tion seeking and sharing so as to evaluate, verify, or even challenge the prescrip-tions\u201d\u00a0[35]. We also acknowledge that not all the URLs being shared are motivated by information seeking behavior. As we will show, some of the top domains shared are social media sources.\nIt is also interesting to note the large difference in tweets and retweets containing \na URL. Specifically, Twitter users appear less likely to retweet content containing a URL. This is a rather unexpected finding. Social media users turn to social media for a variety of needs, including emotional, informational, and instrumental sup-port\u00a0[16]. This observed pattern may result because different types of needs are driv -\ning tweeting versus retweeting behavior. This is only speculation, but informational needs may be driving COVID-19 tweeting behavior, while emotional needs may be driving COVID-19 retweeting behavior\u00a0[17].\nPopular domains\nWe begin by examining these shared links to determine the most popular domains. \nIn this data set, there are over two hundred and thirty seven thousand unique domains that people share in their tweets. Table\u00a0 1 presents the top-10 domains with \nrespect to their tweet frequency. We focus on those domains that are not only fre-quently tweeted, but also have more than 100 user accounts tweeting the domain. By setting a threshold of 100 users sharing a URL of a specific domain, we focus on content that a substantial number of users chose to share, as opposed to content that was frequently shared by only a handful of users.\nInspecting these top-10 domains reveal some interesting patterns. First, people are \nlinking to other social media platforms from Twitter. Indeed, the top two domains linked to in these URLs are both competing social media platforms (YouTube and Table 1  Most frequent domains \nshared by at least 100 user \naccountsCBCEFB CBCEFB Domain Tweet frequency User frequency\nyoutube.com 357,717 145,929\ninstagram.com 214,001 93,605\ntwitter.com 129,031 29,867\nnytimes.com 67,314 30,034\ntheguardian.com 63,744 23,950\nbbc.co.uk 38,871 14,338\nfacebook.com 38,297 20,596\ncnn.com 33,262 13,960\nlinkedin.com 32,613 15,066\nchange.org 32,456 21,012\n351\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nInstagram). Other social media platforms in the top-10 domains include Facebook \nand LinkedIn. This is consistent with research showing that disinformation cam-paigns link across social media platforms in their efforts\u00a0[64]. Second, news media sites tend to round out the top-10 in terms of web domains shared in tweets, with the New York Times, the Guardian, the BBC, and CNN. This is an indication that these news organizations are important for informing Twitter users about the pan-demic. The tenth most popular domain shared is change.org. As of mid-July, over 4500 petitions related to the COVID-19 epidemic have been shared\u00a0[18]. Petition topics range from giving every American extra money during this crisis to mandat-ing schools say closed within a county in the United States until no new cases are identified in the county.\nWe also took a closer look at the most shared URL (not including retweets or \nquotes) within the Twitter domain to see the types of information people shared when posting a Twitter URL (Table\u00a0 1 shows that Twitter is in 3rd place). We found \nthat this is a reflection of the information Twitter is sharing about COVID-19: the most shared Twitter URL links to the official announcements about COVID-19 from Twitter\u00a0[60].\nIn general, Table \u00a0 1 highlights the lack of diversity in external sources shared \nwith respect to COVID-19. Instead of linking to different types of sources, they link predominantly to social media and news media. Moreover, the dominance of cross-platform sharing reinforces the important role that social media needs to play in information sharing on Twitter.\nSharing of\u00a0high quality health, traditional news, and\u00a0low\u2011quality sources\nTable\u00a0 2 provides a high level description of the overall prevalence of HQHS, TNS, \nand LQMS domains mentioned during Twitter conversation about COVID-19. We \nsee that the tweets containing a link to reputable health sources (HQHS) account for 0.55% of tweets and 0.12% of retweets. Traditional news (TNS) accounts for 7.6% of tweets and 1.2% of retweets. Finally, low-quality/fake news sources (LQMS) \naccount for 0.83% of original tweets and 0.19% of retweets.\nA few important patterns can be seen. First, we see that reliance on HQHS \nlinks is minimal, despite limiting our analysis to tweets that explicitly relate to the Table 2  Frequency of HQHS, TNS, and LQMS URLs shared in tweets, retweets, and quotes\nData set Tweet Count Tweets with \nURLsHQHS URL CountTNS URL CountLQMS URL Count\nOriginal Tweets 11,276,874 4,515,469 \n(40.0%)62,539 (0.6%) 857,601 (7.6%) 93,894 (0.8%)\nQuotes 1,500,099 101,240 (6.7%) 1,853 (0.1%) 7764 (0.5%) 760 (0.05%)\nRetweets 54,825,063 2,658,933 \n(4.8%)64,229 (0.1%) 654,513 (1.2%) 104,680 (0.2%)\nCombined 67,602,036 7,275,642 \n(10.8%)128,621 (0.2%) 1,519,878 \n(2.2%)199,334 (0.3%)\n352 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\ncoronavirus\u2014a health topic. Indeed, the reliance on LQMS is comparable to HQHS, \nwith LQMS having an edge in terms of both original tweets and retweets. But while there are more tweets and retweets with a URL link to LQMS than HQHS domains, together, LQMS and HSHS account for less than one percent of the combined over -\nall shared content and less than 5% of the overall shared URL content. We also see that traditional news source content is shared at much larger rates compared to either HQHS or LQMS, representing 7.6% of tweets and 1.2% of retweets. While the news media still are not a large part of the overall conversation, these sources fare better when compared against only those tweets that contain a link. Here, links to TNS comprise over 20% of links in our dataset, while LQMS represent 2.7% and HQHS account for 1.8%. One possible explanation for this discrepancy is that users may follow online news sources as part of their regular information gathering process and have confidence sharing articles from those news sources they trust.\nWe next inspect the breakdown of the LQMS shares in Table\u00a0 3 and their Pearson \ncorrelation among each of the low quality lists in Table\u00a0 4. We see that the preva-\nlence of low quality content depends significantly on which list is chosen to make that judgement. This finding is in line with past work\u00a0[11]. Unsurprisingly, lists such as Politifact and DailyDot that have a strong emphasis on political fake news do not identify a large number of shares. Most low quality sources are identified when considering lists shared by MediaBias/FactCheck and NewsGuard. One important finding is that even though the frequency of tweets associated with each list varies considerably, all of the lists\u2019 frequency are highly correlated to the NewsGuard fre-quency (between 0.61 and 0.82) and the MediaBias/FactCheck frequency (between Table 3  Frequency of low-quality URLs from different blacklists shared in tweets, retweets, and quotes\nCBCEFBData set NewsGuard ALLCOTT DAILYDOT MBFC POLITIFACT ZIMDARS\nOriginal Tweets 31,999 5654 2446 64,677 893 1455\nQuotes 345 23 8 446 10 17\nRetweets 28,855 1244 5298 84,009 338 1000\nCombined 61,199 6921 7752 149,132 1241 2472\nTable 4  Pearson correlation among daily tweet counts of low quality information identified on different \nblacklists\n Pearson Cor -\nrelation Coef-\nficientNEWSGUARD ALLCOTT DAILYDOT MBFC POLITIFACT ZIMDARS\nNEWSGUARD \u2013 0.7588 0.6696 0.8215 0.6120 0.7398\nALLCOTT 0.7588 \u2013 0.7271 0.9317 0.5399 0.7765\nDAILYDOT 0.6696 0.7271 \u2013 0.7851 0.4318 0.6225\nMBFC 0.8215 0.9317 0.7851 \u2013 0.5238 0.8082\nPOLITIFACT 0.6120 0.5399 0.4318 0.7851 \u2013 0.7318\nZIMDARS 0.7398 0.7765 0.6225 0.9317 0.7318 \u2013\n353\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \n0.78 and 0.93). Focusing in on only the Fake News parts of the lists, some correla-\ntions go up and others go down. DailyDoT has a high correlation to ZDARS (0.97), as does Alcott and Politifact (0.98). However, all the other correlations drop to between 0.14 and 0.57. In general, when the volume of tweets containing misinfor -\nmation sources listed on these lists increases, so do the volume of tweets containing misinformation from low quality sources identified on the other lists. This may be an indication that webpages associated with low quality information sources have URLs embedded to other types of low quality information sources, e.g. a health fake news site may reference a political fake news site.\nFinally, we want to understand how the volume of high quality, low quality, and \nnews sources change over time. Figure\u00a0 1 shows the daily volume of high quality \n(HQHS), low quality (LQMS) and news sources (TNS). The x axis is the date and the y axis is the volume. We see that the volume of all the sources are increasing, but \nthe sharing of news sources is increasing at a greater rate than the sharing of high and low quality information sources.\n3 The general increase is not surprising since the \noverall volume of conversation about COVID-19 increased during this time period. If we instead look at the share of overall conversation of these sources, we see a dif-ferent trend. Figure\u00a0 2 shows the daily proportion of the overall conversation of each \nof these sources. We see that the shares of HQHS, LQMS, and TNS all decreased as the crisis continued and plateaued in April. This decreasing trend is also similar for URL sharing as a whole. This may result because there is a larger need for informa-tion at the onset of the pandemic and it decreases as more information is available \nFig. 1  Daily Tweet Volume of High Quality (HQHS\u2014blue), Low Quality (LQMS\u2014red), and News \nSources (TNS\u2014yellow). The x axis is the date and the y axis is the volume\n3 As a reminder, there was a data glitch between March 13, 2020 and March 15, 2020\n354 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nfrom other sources. Still, it is important to remember that even though the share has \ndecreased, the increase in volume means that more people are viewing/sharing more low quality URLs in April than in February or March. The impact could be signifi-cant given the magnitude of the pandemic.\nCOVID\u201119 information ecosystem\nIn an effort to characterize the COVID-19 information ecosystem, we examine the \ncontent of the shared URLs to determine which sources are being linked to within the webpages themselves. We focus our discussion on the high, low, and news domains described in the previous section. However, we pause to mention that the webpages shared by Twitter users contained links to over 70 million webpages across 1.1 million domains. Future work will investigate ways to include more of these sources in new analyses.\nTraditional news source content When checking the content of the shared web-\npages of traditional news sources for URLs to high and low quality sources, we find that over 112,447 of the tweets have links to webpages from high quality sources, over 110,390 have links to webpages from low quality sources, and over 526,069 have links to webpages from news or other sources. This indicates that a comparable amount of news content links to both high and low quality sources, although we cannot speak to the nature of the links. For example, it is possible that some of these news sites are debunking the information posted on the LQMS.\nFocusing on more frequently shared news sources (news domains), we find \nthat 478 news domains were mentioned in at least 100 tweets. Of those, 407 news \nFig. 2  Daily proportion of high quality (HQHS\u2014blue), Low Quality (LQMS\u2014red), and News Sources \n(TNS\u2014yellow) in Tweets\n355\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \ndomains contain at least one article that links to at least one HQHS site or LQMS. \nWe want to classify these news sources based on the proportion of high quality and low quality information they share. We say a news site has high reliability if it refer -\nences high quality information sources at least 80% of the time. The news site has mixed reliability if it references between 50 and 80% high quality content, it has low reliability if it references less than 50% high quality content, and it has no reli-ability if it links to only low quality content. We evaluated this subset and found that 272 out of 407 (66.83%) of these sources have high reliability, 31 (7.62%) have mixed reliability, 38 (9.34%) have low reliability and 66 (16.22%) have no reliabil-ity. In other words, those news domains that are mentioned most frequently in tweets generally link to high quality domains, with over half being highly reliable news sources, but a reasonable fraction link to low quality misinformation domains, with over 16% only linking to low quality misinformation.\n4\nFor the long tail of less popular domains (mentioned in less than 100 tweets), \nthe results are somewhat comparable. There are 850 news domains with at least one article containing at least one link to a HQHS site or LQMS site. Of those, 567 out of 850 (66.71%) of these sources have high reliability, 26 (3.06%) have mixed reli-ability, 15 (1.76%) have low reliability and 242 (28.47%) have no reliability.\nEven though the majority of sources have high reliability, a significant proportion \nhave no reliability, an indication that the quality of news sources varies considerably with regards to COVID-19 information.\nThe last part of this analysis focuses on the connectivity structure of each of our \ninformation sources, i.e., HQHS, LQMS, and TNS, in order to understand if com-munities have begun forming. When sources conveying similar information about the pandemic reference each other, it may give more legitimacy to the information if the information is not being debunked.\nTable\u00a0 5 shows the network properties of each of our information source networks. \nAll of these statistics are computed after removing self-edges. The number of nodes in each information group varies considerably, with few nodes in HQHS and many nodes in TNS and LQMS. The overall density for all three networks is considered high relative to random networks, with HQHS being the highest of our group. In other words, webpages of high quality health sources connect to or reference each other most frequently. This is confirmed when looking at the average clustering coefficient. For HQHS, it is 0.61, well above random connectivity. TNS and LQMS are 0.43 and 0.26, respectively. While not as high as HQHS, they are still high. This tells us that many nodes have neighbors connected to each other, indicating a sub-stantial community structure within each of these information sharing groups.\nAll three networks are disassortative, meaning they exhibit a hub-and-spoke pat-\ntern. This finding is in line with analyses of the Web, but all three three networks have more disassortativity than most technological and biological networks studied \n4 Note that the reliability labels used here solely describe the reliability of content from those sources \nshared on Twitter. It is entirely possible, for instance, for a low-reliability site to link to high quality \ndomains more often than 50% through other articles not shared on Twitter. But Twitter users show a pref-erence for their articles with more connections to low-quality sites.\n356 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3Table 5  Network statistics for each group of information sources\nNetwork Nbr nodes (con-\nnected nodes)Nbr edges Avg degree Avg Eigen vector Avg clusters coefficientGraph density Avg betweenness Avg assortativity Gini coefficient of node degree\nHQHS 39 (38) 172 9.05 0.12 0.61 0.12 0.023 \u2013\u00a00.5476 0.5219\nTNS 1198 (1003) 31,489 62.79 0.018 0.43 0.031 0.0011 \u2013\u00a00.2922 0.6516\nLQMS 1249 (351) 1,845 10.51 0.025 0.26 0.015 0.0030 \u2013\u00a00.2306 0.6560\n357\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nin the past\u00a0 [40]. Assortativity has a direct relationship with network robustness. \nDisassortative graphs are less robust to targeted vertex removal\u00a0 [40]. In assor -\ntative graphs, a failure of a central node would be less detrimental to the overall connectedness of the overall ecosystem since high degree nodes are connected to one another, creating plentiful paths to allow dissemination of information and/or pathways for web users to explore the information space. In disassortative networks, however, high degree nodes are less connected to one another. As such, failure of a high degree node in a disassortative network, e.g dailymail.co.uk or rt.com in our data set, would have a larger impact on the connectedness of the network. Recent work has focused on strategies to take down misinformation sites\u00a0[10]. In disassorta-tive networks, such a strategy can have a broader impact on the overall misinforma-tion ecosystem. It is interesting to note that the HQHS is the most disassortative network, suggesting that they are less robust to vertex removal\u00a0[41]. In other words, if certain central nodes do not continue to link to the smaller health agencies and journals, the information shared by those organizations will not be disseminated as broadly since redundant pathways do not exist.\nWe also examine the centralization of the networks to determine the degree to \nwhich centrality is evenly distributed in these networks. Our analysis shows that the networks are highly skewed, more similar in structure to power law networks than to random networks. This high heterogeneity of the nodes in the network can also be seen by examining the values of the gini index, where a gini index of zero indicates more homogeneous connectivity structure. All of our networks have a similar gini index with LQMS having the highest (0.6560), i.e. having the most heterogeneity of the nodes.\nFig. 3  Directed connectivity among different source Types. The percentage of information sources that \nconnect to different types of information sources. A singe source can connect to multiple source types\n358 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nLooking at the overall landscape, Fig.\u00a0 3 shows the percentage of information \nsources that connect to different types of sources. For example, articles from 55% \nof TNS sources connect to one or more articles from HQHS, 34% connect to one or more articles from LQMS, 68% connect to one or more articles from other TNS, and 24% do not connect to HQHS, LQMS, or TNS.\n5 At a high level, we see that news \nsources are connected to most from HQHS (46%), and 21% of LQMS. LQMS and HQHS do connect to each other, but at lower rates than the other group connects. LQMS tend to contain URLs to sources that are not HQHS or TNS (71%). This could be an indication that part of the LQMS network is not being shared through Twitter, so it is not visible in this study. It could mean that links to information not connected to COVID-19 are also shared on these LQMS. While we are uncertain about the other sources that are linked to, it is clear that HQHS and TNS are more connected to each other than to LQMS.\nTo get a better sense of how the different sources connect to each other individu-\nally, Fig.\u00a0 4 shows the network based on webpage URL links across all the sources. \nThe purple nodes are TNS, the orange nodes are the LQMS, and the green nodes are the HQHS. The edges are the color of the source and the node size is based on \nFig. 4  TNS-HQHS-LQMS Network. The size of the node is based on the number of connections (node \ndegree), and the edge color is based on the source node: TNS (purple), HQHS (green), and LQMS \n(orange)\n5 Because a single article can connect to multiple source types, the percentages will total more than \n100%.\n359\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \noverall degree. The figure highlights two things. Not surprisingly, the news sources \nare dominant in the network. With regards to HQHS, this makes sense since there are many more news sources. However, the number of news sources and misinfor -\nmation sources are comparable, thereby reinforcing our previous finding that high and low quality information sources have less connectivity to each other than to news sources. Second, the subnetworks corresponding to LQMS, HQHS, and TNS are not well separated. There are many individual sources across source types that are connecting to each other. While most LQMS sites are being connected to the broader network through their connections with TNS, some LQMS domains on the periphery are surprisingly more closely clustered with HQHS. Perhaps connections from TNS and HQHS are a result of refuting claims, but even if that is the case, clear pathways exist between the two types of sources. Overall, the figure reinforces the important role news organizations play for those sharing and seeking informa-tion on social media. Previous work has suggested that when traditional news covers fake news, it gives the fake news oxygen, even if they are trying to refute the content [37]\nFigure\u00a0 5 focuses on the connectivity between the HQHS (green nodes) and the \nLQMS (orange nodes). While there is some connectivity between them, the majority of nodes in the network do not have edges across source types, recall that there are 39 HQHS and 1249 LQMS. What is interesting is that while there are some LQMS connecting to HQHS, most of the nodes have very few connections and the few they have are to the more prominent health sources, i.e. the large nodes. Most of the con-nections from the high degree HQHS are to other HQHS. A small number are to LQMS. This again highlights that the weakest pathways across the different source types are between HQHS and LQMS.Fig. 5  Network between HQHS \n(green) and LQMS (orange). \nThe size of the node is based on the number of connections (node degree), and the edge color is based on the source node\n\n360 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nFigures\u00a0 6 and\u00a0 7 show the clusters generated when using modularity cluster -\ning for the HQHS, and the LQMS, respectively. Figure\u00a0 6 has three clusters. Each \ncluster is shown as a different color, and node size is based on node degree. The \npink cluster mainly contains the WHO, CDC, and other health/government organ-izations. The green cluster contains predominantly reliable research journals, including Nature and the Lancet, as well as some international agencies. The third small, blue cluster contains medical journals and groups, including JAMA and AMA. We do see strong ties across clusters, with the strongest being between the WHO and Lancet. While the high clustering coefficient was an indication that high levels of connectivity existed in this network, the modularity clustering Fig. 6  HQHS network cluster -\ning using modularity, three \nclusters are each shown in a different color. The node size is based on node degree\nFig. 7  LQMS network cluster -\ning using modularity. the network contains 10 clusters, each shown in a different color. The node size is based on node degree\n\n361\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nalgorithm showcases that there are two larger subgroups and one small one that \nhave higher than expected connectivity structures.\nFigure\u00a0 7 contains ten clusters. Again, each cluster is shown as a different color, \nand node size is based on node degree. Focusing on the larger clusters, the orange and yellow clusters contain low quality health websites, while the pink and green contain fake news about COVID-19 identified by MediaBias/FactCheck. Each community contains stronger connectivity and more pathways within the cluster than outside the cluster. This may result because of prevalent themes in the infor -\nmation shared or reciprocal link agreements. Future research will investigate the similarities and differences in content across the clusters.\nLimitations\nThis study has a number of limitations worth noting. First, our results are purely based on domain level analysis. In other words, all URLs from the same domain are classified under the same category. However, high-quality sites can sometimes, albeit rarely, share misinformation. For example, during the early stages of the pan-demic, the CDC recommended not wearing masks\u00a0[30]. Similarly, sites that aim to misinform can at times share reliable information. Despite these rare cases, in this paper, we opt for this simplification for two main reasons: (i) a domain level analysis allows us to focus on producers and therefore intent to deceive\u00a0[35] and (ii) identify -\ning factualness/low quality information is a notoriously difficult task that is hard to scale to the size of our corpus\u00a0[9].\nOur next limitation has to do with the identified sources. The lists used to identify \nthe set of health, traditional news, and misinformation sites are heavily US and Eng-lish based. As such, our analysis has that particular bias.\nFinally, we collected our Twitter data using a set of COVID-19 related hashtags. \nWhile this provides a rich dataset to examine information sharing behavior related to the pandemic, hashtag focused data collection has its limitations. For instance, tweets including different hashtags can differ in important cultural and socio-polit-ical dimensions\u00a0[60]. To address this point, we rely on multiple relevant hashtags instead of only one. However, this list will still not identify all COVID-19 related conversations. Some of the hashtags were also added after the beginning of the study period. If misinformation levels vary according to hashtag, we may miss that. Hashtag usage also has important temporal implications. For instance, \u00a0[60] exam-ined the Gezi Uprising and found that movement related hashtag usage was drop-ping while the protests were intensifying. The interviews revealed that this was at least partially due to hashtags becoming less useful, and thus a wasteful use of char -\nacters allocated to a tweet, once everyone knew the topic. A similar pattern could be observed for a phenomena as widely spread and impactful as COVID-19. Encourag-ingly, we do not see a drop-off in activity in our analysis other than the days we had data collection issues.\n362 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\nConclusions and\u00a0future directions\nThis article attempts to understand the types of URLs that are being shared \non Twitter within the COVID-19 conversation. Our analysis focuses on health related domains, news domains, and domains containing misinformation. We find that while domains containing misinformation are shared at a higher rate than domains containing high quality health information, neither is prevalent in the COVID-19 conversation. Even though they are not tweeted at a high rate, a network analysis of links between webpages shared by misinformation sources shows that the network is dense, well connected, and disassortative. This means that even though community exists, the network is not robust to the removal of nodes and can be fragmented with the right interventions. While the networks we created based on the web content shared involving the HQHS and TNS are con-nected to nodes/sources in one of our source groups, the majority of links in the LQMS webpages are linking to other sources outside of our source groups. This may represent a part of the misinformation ecosystem that was not captured by following links from Twitter. This highlights that understanding the entire con-nectivity structure of the COVID-19 information ecosystem requires following all these links to other sources and identifying other links shared on other social media sites. Without question, this is a larger ecosystem than the 2000+ sources we focused on.\nThere are also future directions with regards to misinformation about COVID-\n19 on Twitter. For example, while this paper investigates the link structure of the webpages, we do not analyze the content of each webpage shared. Future work will build topic models to understand how the topics relate to the types of infor -\nmation being shared more broadly using the COVID-19 hashtags and the net-work structure of the different categories of web domains. Another direction of research would investigate misinformation shared in the content of the tweet and understand its prevalence. Finally, not only is the misinformation being shared, but correcting information is also being shared. We need to find ways to measure how much correcting information is being shared and whether or not it propa-gates at the same rate as the misinformation.\nAcknowledgements This research is funded by National Science Foundation awards #1934925 and \n#1934494, and the Massive Data Institute (MDI) at Georgetown University. We would like to thank our \nfunders. We would also like to thank the MDI staff and the members of the DataLab for their support. We would also like to thank the anonymous reviewers for the very detailed and thoughtful reviews.\nCompliance with ethical standards \nConflicts of interest On behalf of all authors, the corresponding author states that there is no conflict of \ninterest.\n363\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \nAppendix A\nSee Table\u00a06.\nReferences\n 1. Ahmed, W., Vidal-Alaball, J., Downing, J., & Segu\u00ed, F. L. (2020). Covid-19 and the 5g conspiracy \ntheory: social network analysis of twitter data. Journal of Medical Internet Research, 22(5), e19458.\n 2. Allcott, H., Gentzkow, M., & Yu, C. (2019). Trends in the diffusion of misinformation on social media. Research & Politics, 6(2), 2053168019848554.\n 3. Amy\u00a0Mitchell, J.B.O. (2020). Americans immersed in covid-19 news; most think media are doing fairly well covering it (03/18/2020). https ://www.journ alism .org/2020/03/18/ameri cans-immer sed-in-covid -19-news-most-think  -media -are-doing -fairl  y-well-cover  ing-it/\n 4. Ball-Rokeach, S. J., & DeFleur, M. L. (1976). A dependency model of mass-media effects. Commu-\nnication Research, 3(1), 3\u201321.\n 5. Bandari, R., Zhou, Z., Qian, H., Tangherlini, T. R., & Roychowdhury, V. P. (2017). Trends in the diffusion of misinformation on social media. Computer, 50(11), 60\u201367.\n 6. Bode, L., Budak, C., Ladd, J. M., Newport, F., Pasek, J., Singh, L. O., et\u00a0al. (2020). Words that matter: How the news and social media shaped the 2016 Presidential campaign. Washington, DC: Brookings Institution Press.\n 7. Bovet, A., & Makse, H. A. (2019). Influence of fake news in twitter during the 2016 us presidential election. Nature Communications, 10(1), 1\u201314.\n 8. Bozarth, L., & Budak, C. (2020). Toward a better performance evaluation framework for fake news classification. Proceedings of the International AAAI Conference on Web and Social Media, Atlanta, \nGeorgia, U.S. 14, 60\u201371.\n 9. Bozarth, L., & Budak, C. (2001). Market forces: Quantifying the role of top credible ad servers in the fake news ecosystem. In: Proceedings of the International AAAI Conference on Web and Social Media (2021, Forthcoming)Table 6  Hashtags and start date \nof collection\nHashtag Date of first collection\n#2019nCoV 1/16/2020\n#ChinaPneumonia 1/16/2020\n#ChinesePneumonia 1/16/2020\n#Corona 1/16/2020\n#WuhanCoronavirus 1/16/2020\n#WuhanPneumonia 1/16/2020\n#CoronavirusOutbreak 1/20/2020\n#VirusChina 1/21/2020\n#Coronavirus* 1/23/2020\n#CoronaOutbreak 3/02/2020\n#COVID 3/02/2020\n#CoronavirusUpdate 3/11/2020\n#COVID_19 3/11/2020\n#COVID19** 3/11/2020\n364 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\n 10. Bozarth, L., Saraf, A., & Budak, C. (2020). Higher ground? How ground truth labeling impacts our \nunderstanding of fake news about the 2016 us presidential nominees. Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media, Atlanta, Georgia, U.S. 14, 48\u201359.\n 11. Briones, R., Nan, X., Madden, K., & Waks, L. (2012). When vaccines go viral: An analysis of hpv \nvaccine coverage on youtube. Health Communication, 27(5), 478\u2013485.\n 12. Broniatowski, D. A., Jamison, A. M., Qi, S., AlKulaib, L., Chen, T., Benton, A., et\u00a0al. (2018). Weap-\nonized health communication: Twitter bots and Russian trolls amplify the vaccine debate. American Journal of Public Health, 108(10), 1378\u20131384.\n 13. Budak, C. (2019). What happened? the spread of fake news publisher content during the 2016 us \npresidential election. In: Proceedings of the International on the World Wide Web, pp. 139\u2013150.\n 14. Budak, C., Agrawal, D., & El\u00a0Abbadi, A. (2011). Limiting the spread of misinformation in social \nnetworks. In: Proceedings of the International Conference on the World Wide Web, pp. 665\u2013674.\n 15. Budak, C., & Agrawal, R. (2013) On participation in group chats on twitter. In: Proceedings of the \nInternational Conference on World Wide Web, pp. 165\u2013176.\n 16. Chen, G. M. (2011). Tweet this: A uses and gratifications perspective on how active twitter use \ngratifies a need to connect with others. Computers in Human Behavior, 27(2), 755\u2013762.\n 17. Coronavirus epidemic. (2007). https ://www.chang  e.org/t/coron aviru s-epide mic-en-us.\n 18. De Domenico, M., Lima, A., Mougel, P., & Musolesi, M. (2013). The anatomy of a scientific rumor. \nScientific Reports, 3, 2980.\n 19. Dredze, M., Broniatowski, D. A., & Hilyard, K. M. (2016). Zika vaccine misconceptions: A social media analysis. Vaccine, 34(30), 3441\u20133442.\n 20. Ferrara, E., Varol, O., Davis, C., Menczer, F., & Flammini, A. (2016). The rise of social bots. Commu-\nnications of the ACM, 59(7), 96\u2013104.\n 21. Eeas special report update: Short assessment of narratives and disinformation around the covid-19 pan-demic (update 23 april\u201318 may). (2020). https ://euvsd isinf  o.eu/eeas-speci al-repor  t-updat e-short -asses  \nsment -of-narra tives -and-disin forma tion-aroun d-the-covid 19-pande mic-updat ed-23-april -18-may/.\n 22. Garrett, R. K., Weeks, B. E., & Neo, R. L. (2016). Driving a wedge between evidence and beliefs: How online ideological news exposure promotes political misperceptions. Journal of Computer-Mediated \nCommunication, 21(5), 331\u2013348.\n 23. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B., & Lazer, D. (2018). Fake news on twitter during the 2016 us presidential election. Tech. rep.\n 24. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B., & Lazer, D. (2019). The rise of social bots. Science, 363(6425), 374\u2013378.\n 25. Guess, A., Nyhan, B., & Reifler, J. (2018). Selective exposure to misinformation: Evidence from the consumption of fake news during the 2016 us presidential campaign. European Research Council, 9, 4.\n 26. Guidry, J. P. D., Carlyle, K., Messner, M., & Jin, Y. (2015). On pins and needles: How vaccines are portrayed on pinterest. Vaccine, 33(39), 5051\u20135056.\n 27. Gunaratne, K., Coomes, E. A., & Haghbayan, H. (2019). Temporal trends in anti-vaccine discourse on twitter. Vaccine, 37(35), 4867\u20134871.\n 28. Hitlin, P., & Olmstead, K. (2019). The science people see on social media. Pew Research Center (12/30/2019). https ://www.pewre searc  h.org/scien ce/2018/03/21/the-scien ce-peopl e-see-on-socia  \nl-media . Accessed 16 July 2020.\n 29. Hollowood, E., Mostrous, A., Cummings, B., Newell, C., Bothwell, O., Macintyre, B., Kes-sler, J., & Nyenwa, T. (2020). Fake news in the time of c-19 (2020). https ://membe rs.torto iseme dia.com/2020/03/23/the-infod emic-fake-news-coron aviru s/conte nt.html. Accessed 16 July 2020.\n 30. Jingnan H, Aubrey, A, Wroth, C. (2020) Should We All Be Wearing Masks In Public? Health Experts Revisit The Question. https ://www.npr.org/secti ons/healt  h-shots /2020/03/31/82456 0471/shoul d-we-all-\nbe-weari ng-masks -in-publi c-healt  h-exper  ts-revis it-the-quest ion. Accessed 31 Mar 2020.\n 31. Jin, F., Dougherty, E., Saraf, P., Cao, Y., & Ramakrishnan, N. (2013). Epidemiological modeling of news and rumors on twitter. In: Proceedings of the Workshop on Social Network Mining and Analysis, pp. 1\u20139.\n 32. Jurkowitz, M., Mitchell, A., Shearer, E., & Walker, M. (2020). U.s. media polarization and the 2020 election: A nation divided. Washington, DC: Pew Research Center.\n 33. Kouzy, R., Abi Jaoude, J., Kraitem, A., El Alam, M. B., Karam, B., Adib, E., et\u00a0al. (2020). Coronavirus goes viral: quantifying the covid-19 misinformation epidemic on twitter. Cureus, 12(3), e7255.\n 34. Lazer, D. M., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F., et\u00a0al. (2018). The science of fake news. Science, 359(6380), 1094\u20131096.\n365\n1 3 Journal of Computational Social Science (2020) 3:343\u2013366 \n 35. Lin, W. Y., Zhang, X., Song, H., & Omori, K. (2016). Health information seeking in the web 2.0 age: \nTrust in social media, uncertainty reduction, and self-disclosure. Computers in Human Behavior, 56, \n289\u2013294.\n 36. Marwick, A., Lewis, R. (2020). Media manipulation and disinformation online (2020). https ://datas  \nociet y.net/libra ry/media -manip ulati on-and-disin fo-onlin e. Accessed 16 July 2020.\n 37. Matsa, K.E., Shearer, E. (2018). News use across social media platforms 2018. Pew Research Center (2018). https ://www.journ alism .org/2018/09/10/news-use-acros s-socia l-media -platf  orms-2018. \nAccessed 16 July 2020.\n 38. Media Bias/Fact Check: Media bias/fact check: The most comprehensive media bias recourse. (2018). https ://media biasf  actch eck.com/. Accessed 16 July 2020.\n 39. Motta, M., Callaghan, T., & Sylvester, S. (2018). Knowing less but presuming more: Dunning-kruger effects and the endorsement of anti-vaccine policy attitudes. Social Science & Medicine, 211, 274\u2013281.\n 40. Newman, M. E. (2002). Assortative mixing in networks. Physical Review Letters, 89(20), 208701.\n 41. Newman, M. E. (2006). Modularity and community structure in networks. Proceedings of the National \nAcademy of Sciences, 103(23), 8577\u20138582.\n 42. Newsguard: Coronavirus misinformation tracking center. (2020). https ://www.newsg uardt ech.com/coron aviru s-misin forma tion-track ing-cente r . Accessed 16 July 2020.\n 43. Nyhan, B., & Reifler, J. (2010). When corrections fail: The persistence of political misperceptions. Political Behavior, 32(2), 303\u2013330.\n 44. Ortiz-Ospina, E. (2020). The rise of social media https ://ourwo rldin data.org/rise-of-socia l-media . Accessed 16 July 2020.\n 45. Oyeyemi, S. O., Gabarron, E., & Wynn, R. (2014). Ebola, twitter, and misinformation: a dangerous combination? BMJ (Clinical research ed.), 349, g6178.\n 46. Politifact staff. (2018). Politifact guide to fake news websites and what they peddle\n 47. Scanfeld, D., Scanfeld, V., & Larson, E. L. (2010). Dissemination of health information through social networks: twitter and antibiotics. American Journal of Infection Control, 38(3), 182\u2013188.\n 48. Schaedel, S (2017) Websites that post fake and satirical stories. FactCheck. Available at https ://www.factc heck.org/2017/07/websi tes-post-fake-satir  ical-stori es/. Accessed 3 Sept 2018.\n 49. Schmitt, M., & J\u00e4schke, R. (2017). What do computer scientists tweet? Analyzing the link-sharing prac-tice on twitter. PLoS One, 12(6), e0179630.\n 50. Shao, C., Ciampaglia, G. L., Varol, O., Yang, K. C., Flammini, A., & Menczer, F. (2018). The spread of low-credibility content by social bots. Nature Communications, 9(1), 1\u20139.\n 51. Sharma, K., Seo, S., Meng, C., Rambhatla, S., & Liu, Y. (2020). Covid-19 on social media: Analyzing misinformation in twitter conversations. arXiv preprint arXiv  :2003.12309  \n 52. Sharma, M., Yadav, K., Yadav, N., & Ferdinand, K. C. (2017). Zika virus pandemic-analysis of face-book as a social media health information platform. American Journal of Infection Control, 45(3), \n301\u2013302.\n 53. Shin, J., Jian, L., Driscoll, K., & Bar, F. (2018). The diffusion of misinformation on social media: Tem-poral pattern, message, and source. Computers in Human Behavior, 83, 278\u2013287.\n 54. Silverman, C. (2016). Here are 50 of the biggest fake news hits on facebook from 2016.\n 55. Singh, L., Wahedi, L., Wang, Y., Wei, Y., Kirov, C., Martin, S., Donato, K., Liu, Y., & Kawintiranon, K. (2019). Blending noisy social media signals with traditional movement variables to predict forced migration. In: Proceedings of the ACM International Conference on Knowledge Discovery & Data Mining, pp. 1975\u20131983. ACM.\n 56. Southwell, B. G., Niederdeppe, J., Cappella, J. N., Gaysynsky, A., Kelley, D. E., Oh, A., et\u00a0al. (2019). Misinformation as a misunderstood challenge to public health. American Journal of Preventive Medi-cine, 57(2), 282\u2013285. https ://doi.org/10.1016/j.amepr  e.2019.03.009.\n 57. Starbird, K., Maddock, J., Orand, M., Achterman, P., & Mason, R.M. (2014). Rumors, false flags, and digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing. In: Proceedings of IConference.\n 58. Swift, A. (2016). Americans\u2019 trust in mass media sinks to new low. Gallup. https ://news.gallu p.com/poll/19554 2/ameri cans-trust -mass-media -sinks -new-low.aspx. Accessed 16 July 2020.\n 59. Tufekci, Z. (2014). Big questions for social media big data: Representativeness, validity and other methodological pitfalls. In: E.\u00a0Adar, P.\u00a0Resnick, M.D. Choudhury, B.\u00a0Hogan, A.H. Oh (eds.) Proceed-ings of the Eighth International Conference on Weblogs and Social Media, ICWSM 2014, Ann Arbor, Michigan, USA, June 1-4, 2014. The AAAI Press. http://www.aaai.org/ocs/index .php/ICWSM /ICWSM  \n14/paper /view/8062. Accessed 16 July 2020.\n366 Journal of Computational Social Science (2020) 3:343\u2013366\n1 3\n 60. Twitter. (2020). Covid-19: Latest news updates from around the world (2020). https ://twitt er.com/i/\nevent s/12190 57585 70731 5201. Accessed 16 July 2020.\n 61. Van Zandt, D. (2018). Media bias/fact check (mbfc news). https ://media biasf  actch eck.com/about /. \nAccessed 16 July 2020.\n 62. Vraga, E. K., & Bode, L. (2020). Defining misinformation and understanding its bounded nature: Using \nexpertise and evidence for describing misinformation. Political Communication, 37(1), 136\u2013144.\n 63. Wilford, J., Osann, K., & Wenzel, L. (2018). Social media use among parents of young childhood can-cer survivors. Journal of Oncology Navigation & Survivorship, 9(1).\n 64. Wilson, T., & Starbird, K. (2020). Cross-platform disinformation campaigns: lessons learned and next steps. Harvard Kennedy School Misinformation Review, 1(1), 399\u2013405.\n 65. World Health Organization. (2020). Coronavirus disease 2019 (covid-19) situation report. https ://www.who.int/docs/defau lt-sourc e/coron aviru se/situa tion-repor  ts/20200 415-sitre p-86-covid -19.pdf. Accessed \n16 July 2020.\n 66. Yuan, X., Schuchard, R. J., & Crooks, A. T. (2019). Examining emergent communities and social bots within the polarized online vaccination debate in twitter. Social+ Media Society, 5(3), \n2056305119865465.\n 67. Zhou, Z., Bandari, R., Kong, J., Qjan, H., & Roychowdhury, V. (2020). Information resonance on twit-ter: watching iran. In: Proceedings of the Workshop on Social Media Analytics.\n 68. Zimdars, M. (2016). My \u00e2fake news list\u00e2 went viral. But made-up stories are only part of the problem. Washington, DC: The Washington Post.\nPublisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published \nmaps and institutional affiliations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Understanding high-and low-quality URL Sharing on COVID-19 Twitter streams", "author": ["L Singh", "L Bode", "C Budak", "K Kawintiranon"], "pub_year": "2020", "venue": "Journal of computational \u2026", "abstract": "This article investigates the prevalence of high and low quality URLs shared on Twitter when  users discuss COVID-19. We distinguish between high quality health sources, traditional"}, "filled": false, "gsrank": 611, "pub_url": "https://link.springer.com/article/10.1007/s42001-020-00093-6", "author_id": ["", "e0i3HvIAAAAJ", "wIhJS60AAAAJ", "xY2oO2QAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:9QG5yo2KwfAJ:scholar.google.com/&output=cite&scirp=610&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D610%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=9QG5yo2KwfAJ&ei=dbWsaILdNb_SieoPzJnloAQ&json=", "num_citations": 95, "citedby_url": "/scholar?cites=17348299581204005365&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:9QG5yo2KwfAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1007/s42001-020-00093-6.pdf"}}]