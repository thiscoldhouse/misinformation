[{"title": "Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis", "year": "2025", "pdf_data": "arXiv:2505.15563v1  [cs.CL]  21 May 2025Semantic-based Unsupervised Framing Analysis (SUFA): A Novel\nApproach for Computational Framing Analysis\nMohammad Ali\nCollege of Information\nUniversity of Maryland\nCollege Park, USA\nmali24@umd.edu\naliusacomm@gmail.comNaeemul Hassan\nPhilip Merrill College of Journalism\nCollege of Information\nUniversity of Maryland\nCollege Park, USA\nnhassan@umd.edu\nAbstract\nThis research presents a novel approach to computational fram-\ning analysis, called Semantic Relations-based Unsupervised Framing\nAnalysis (SUFA). SUFA leverages semantic relations and depen-\ndency parsing algorithms to identify and assess entity-centric em-\nphasis frames in news media reports. This innovative method is\nderived from two studies\u2014qualitative and computational\u2014using\na dataset related to gun violence, demonstrating its potential for\nanalyzing entity-centric emphasis frames. This article discusses\nSUFA\u2019s strengths, limitations, and application procedures. Overall,\nthe SUFA approach offers a significant methodological advance-\nment in computational framing analysis, with its broad applicability\nacross both the social sciences and computational domains.\nKeywords\nComputational framing analysis, semantic relations, dependency\nparsing, natural language processing, communication method, com-\nputational method\nReference:\nMohammad Ali and Naeemul Hassan. 2023. Semantic-based Unsupervised\nFraming Analysis (SUFA): A Novel Approach for Computational Framing\nAnalysis. Presented at the Association for Education in Journalism and Mass\nCommunication Conference, August 07\u201310, 2023. AEJMC, Washington, DC,\nUSA, 14 pages.\n1 Introduction\nFrames are predominantly explored using qualitative methods [e.g.,\nMorin 2016] and quantitative methods [e.g., McKeever et al .2022]\nthrough manual labor and analysis of small datasets. The recent\nproliferation of online news reports and social media posts has\nresulted in the generation of a vast amount of digital data that is\ndifficult to analyze manually. To overcome this challenge, scholars\nhave started using various computational methods, broadly divided\ninto two parts: supervised and unsupervised [Ali and Hassan 2022].\nThe supervised methods require pre-determined labels and substan-\ntial human labor, while the unsupervised methods that this current\nresearch focuses on need little human effort and are applicable\nacross domains.\nExisting unsupervised methods (e.g., topic modeling) in framing\nanalysis mainly rely on the frequency and co-occurrence of words,\nThis research received the Top Method Paper Award at AEJMC 2023.\nAEJMC, Washington, DC\n\u00a92023 Copyright held by the owner/author(s). Published under Creative Commons\nCC-BY 4.0 License.leading to the exploration of topics instead of deeper framing in-\nsights [Ali and Hassan 2022; Entman 1993; Nicholls and Culpepper\n2021]. An improved unsupervised computational solution to this\nlongstanding communication challenge is becoming essential in\nthis era of big data. Scholars [e.g., Ali and Hassan 2022] advocate\nfor methods to capture semantic relationships between words, mov-\ning beyond the traditional bag-of-words approach to enhance the\nmethodological framework. In response to these calls, this arti-\ncle examines semantic relationships between words, presenting a\nnovel unsupervised approach for computational framing analysis\nbased on dependency parsing, a natural language processing (NLP)\ntechnique largely overlooked in framing analysis.\nThis mixed-method article involves two studies. Study 1 employs\na qualitative textual analysis to inductively examine a sample of\nnews reports published by four major U.S. news media outlets on the\n2022 Uvalde school mass shooting in Texas, as a case study. While\nthe political impasse and public debate continue over gun violence,\nit is important to understand how news media outlets frame the\nissue, as media framing determines how people \u201cchoose to act\nupon [the problem]\u201d [Entman 1993, p. 54]. Study 1 examines how\nindividual words, such as adjectives and adverbs, convey different\nmeanings related to the shooter, victims, and the shooting event.\nThis helps us understand how these words and their semantic\nrelationships work together to construct frames. Study 2 employs\nthe computational technique of dependency parsing to analyze\nthe same dataset. Specifically, we investigate dependency parsing,\nalong with word embedding, k-means clustering, and manual input,\nestablishing this method as a viable approach for capturing semantic\nrelationships and analyzing the entity-centric emphasis frames.\nIntegrating qualitative and quantitative approaches in this project\nprovides complementary strengths essential for developing the\nmethodological approach. The qualitative analysis in Study 1 of-\nfers interpretive depth by first manually uncovering whether and\nhow specific words and their semantic relationships contribute to\nframe construction in natural language. This inductive insight helps\nground the methodological design. Through quantitative computa-\ntional techniques, Study 2 validates and extends this insight from\nStudy 1 by systematically extracting these patterns computation-\nally. Together, the two studies demonstrate that semantic structures,\ncaptured through dependency parsing, can reliably identify em-\nphasis frames, laying the foundation for a scalable, unsupervised\ncomputational framing analysis model.\n1\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\nThe outcomes of both studies are discussed. Importantly, this\nmixed-method project solidified and proposed the semantic relations-\nbased approach for framing analysis, named \u201cSemantic Relations-\nbased Unsupervised Framing Analysis.\u201d The step-by-step procedure\nfor applying this approach, along with its strengths, limitations,\nand future research directions, is also discussed.\n2 Literature Review\n2.1 Framing\nScholars have not reached a consensus on a unified definition of\nframing [Goffman 1974; Hertog and McLeod 2001]. However, one of\nthe most widely cited definitions in framing studies comes from Ent-\nman [1993], who posits:\nTo frame is to select some aspects of a perceived reality\nand make them more salient in a communicating text,\nin such a way as to promote a particular problem defi-\nnition, causal interpretation, moral evaluation, and/or\ntreatment recommendation for the item described. (p.\n52)\nIn the news media context, a frame is \u201ca central organizing\nidea\u201d [Tankard et al .1991], and it \u201cdenotes how journalists, their\nsources, and audiences work within conditions that shape the mes-\nsages they construct as well as the ways they understand and in-\nterpret these messages\u201d [D\u2019Angelo and D\u2019Angelo 2018, p. xxiv].\nGoing beyond the idea of a simple topic, news framing is \u201clike\nmoving a telescope into position\u201d [Fairhurst 2005, p. 125], where\nselected aspects are coherently organized in a way that makes an\nargument, promoting a particular interpretation, evaluation, and\nsolution [Fairhurst 2005]. Importantly, a frame \u201coperates by selecting\nand highlighting some features of reality while omitting others\u201d [Ent-\nman 1993, p. 53]. Echoing with this, Fairhurst and Sarr [1996] notes\nthat a frame is \u201cto choose one particular meaning (or set of meanings)\nover another\u201d (p. 3).\n2.2 Emphasis vs. Equivalency Framing\nThe concept of framing revolves around two broad competing as-\npects: emphasis framing and equivalency framing. Equivalency\nframing involves presenting two or more alternatives with logically\nequivalent phrases (e.g., loss versus gain) Kahneman and Tversky\n[1984]; Levin et al .[1998]. In contrast, emphasis framing refers to\nthe act of repeatedly highlighting or associating certain pieces of\ninformation about an issue or topic, while omitting other relevant\naspects D\u2019Angelo [2017]. This article focuses on analyzing emphasis\nframing with the newly proposed computational approach.\n2.3 Words in Constructing Frames\nScholars have long identified words and phrases that construct\nframes. Prior studies revealed that using certain words helps iden-\ntify frames [Entman 1993; Fairhurst and Sarr 1996; Gamson and\nModigliani 1989; Hertog and McLeod 2001]. For example, \u201cthe use\nofbaby versus fetus signals a very different approach to the topic of\nabortion\u201d [Hertog and McLeod 2001, p. 150]. Prior framing studies\nlooked at various parts of speeches, including verbs, adverbs, and\nadjectives, which enhances researchers\u2019 ability to identify frameboundaries and relationships [Hertog and McLeod 2001]. The fre-\nquent use of verbs such as \u201cfalsifying,\u201d \u201cforging,\u201d and \u201cmanipulating\u201d\nwas found to have been utilized in news reports to frame scien-\ntists [Boesman and Van Gorp 2018]. News reporters also use various\nverbs of attribution (e.g., accused, charged, blamed) to create worth\nfor one person while devaluing another [Dickerson 2001].\n2.4 Conceptualization and Operationalization\nof the Framing Component\nPrior studies provide evidence for using words in constructing\nframes [Hertog and McLeod 2001; Miller 1995]. When a particular\nword is selected or coded as part of a frame, this word directly\nor indirectly operates in relation to other words to express the\nintended framing meaning. In other words, framing meanings are\noften produced not by isolated words but through their associative\nuse with surrounding words, particularly when an entity is modified\nby adjectives, adverbs, or verbs.\nFor example, Bantimaroudis and Ban [2001] reported how Somali\nleaders were framed by U.S. news media through the repeated use\nof the term \u201cwarlords\u201d in contrast to their opposition, the United\nNations forces. They interpreted the frame by exposing how ex-\ntensively the word \u201cwarlords\u201d was used in the news media cover-\nage. This current research argues that the word \u201cwarlords\u201d alone\ndoes not sufficiently convey a practical meaning for understanding\nthe frame about Somali leaders. Instead, we better understand the\nintended frame when the word \u201cwarlords\u201d is seen as an adjective\nmodifier to its noun, \u201cMohammed Siad Barre, \u201d forming a phrase like\n\u201cwarlord Barre.\u201d In this context, the framing component emerges\nfrom a meaningful semantic pair, a modifying word and its head\nnoun, which together construct the framing meaning.\nCrucially, this pair of words is bound by a meaningful semantic\nrelation. For example, in the dependency parsing output of natural\nlanguage processing, the noun \u201cBarre\u201d and its modifier \u201cwarlord\u201d\nare linked by an adjectival modifier relation (known as \u201camod\u201d).\nBased on this linguistic structure, this current research conceptu-\nalizes a framing component as \u201ca pair of words connected by a\nmeaningful semantic relation.\u201d The modifying word may belong\nto various parts of speech, such as adjectives (e.g., young shooter),\nverbs (e.g., shooter kills), or even participles and modal verbs (e.g.,\nshooter accused of [killing]).\nIn qualitative textual and quantitative content analyses that rely\non manual labor, scholars might code the keyword \u201cwarlord,\u201d keep-\ning other parts (e.g., noun and semantic relation) in mind, and con-\nsider its semantic context during interpretation to explore meaning-\nful insights. However, for computational analysis, capturing such\nsemantic structures explicitly becomes essential for scaling framing\nanalysis to large datasets.\nTo this end, this current research operationalizes a framing com-\nponent as a pair of words connected by a meaningful semantic re-\nlation, specifically identified using dependency parsing techniques.\nFor instance, adjective-noun (amod) or verb-subject (nsubj) relation-\nships are used to detect modifier-entity structures, such as \u201cteenage\ngunman\u201d or \u201cshooter kills.\u201d These semantic relations are compu-\ntationally extracted from the dependency tree of each sentence.\nBy identifying the framing components in the semantic relations-\nbased structure, this approach allows for systematic extraction of\n2\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\nentity-modifier pairs in large datasets, ensuring both consistency\nand scalability. This operationalization is particularly well-suited\nfor analyzing entity-centric frames, as it captures how individuals,\norganizations, or groups are framed through specific modifying\nwords in large datasets.\n2.5 Framing Analysis with Computational\nApproaches\nTraditionally, researchers utilize qualitative and quantitative meth-\nods to analyze frames, relying on manual labor and small amounts\nof data [D\u2019Angelo and D\u2019Angelo 2018; Reese et al .2001]. To tackle\nthe challenge of analyzing frames in large-scale datasets, scholars\nhave begun using computational approaches\u2014both supervised and\nunsupervised\u2014in the last two decades [e.g., Card et al .2015; Liu\net al. 2019; Van Atteveldt and Peng 2018; Walter and Ophir 2019].\nSupervised. A supervised approach needs pre-labeled datasets.\nIn this approach, a model is first trained on the labeled data and then\napplied to a new dataset to classify or predict each instance [Kot-\nsiantis et al .2007]. Under the supervised framing analysis ap-\nproach, [Liu et al .2019] proposed a deep learning-based model\ndeveloped with manual codes of headlines of news reports relating\nto gun violence.\nUnsupervised. An unsupervised approach does not require any\npre-annotated datasets. Instead, it inductively explores all unlabeled\ndata [Kotsiantis et al .2007]. Existing unsupervised approaches used\nto analyze frames include topic modeling [DiMaggio et al .2013],\nstructural topic modeling [Gilardi et al .2021], hierarchical topic\nmodeling [Nguyen 2015], cluster analysis [Burscher et al .2016],\nfrequency-based models [Sanderink 2020], and FrameAxis [Kwak\net al.2021]. Compared to supervised models, unsupervised ones\ndemand less time and can be replicated across domains.\nSemantic relations. Existing unsupervised computational ap-\nproaches for framing analysis are mainly based on the ideas of\nfrequency and co-occurrences of words, resulting in the identifi-\ncation of discussion topics or themes, instead of frames [Ali and\nHassan 2022]. Such topics do not provide a coherent framing in-\nterpretation. As per the framing conceptualization [Entman 1993;\nReese et al .2001], semantic relations among words are a key to\ngoing deeper into frames, compared to the current bag-of-words-\nbased practices, such as topic modeling. This limitation calls for\nexploring an unsupervised technique to capture semantic relations\namong words for better identifying frames. This article intends\nto fill the gap by focusing on unsupervised methods of framing\nanalysis.\nAlthough a few studies attempted to address the task with seman-\ntic relations, their approaches are not sufficiently comprehensive or\nsupervised from the data analysis perspective. For example, [Stur-\ndza et al .2018] describes an approach of operationalizing frames\nusing a rule-based system with a software named TurboParser.\nHowever, the author did not execute it using a dataset, leaving its\nusefulness unclear. A recent study by Ziems and Yang [2021] pro-\nposes an NLP framework to understand the frames of an entity or\nissue (e.g., victims in police violence) with relevant attributes (e.g.,\nage, gender, race). However, they pre-determined the attributes and\nthen string-matched relevant tokens as a way of framing particular\nentities, which is also considered supervised.Another study by van Atteveldt et al .[2013] presents a computa-\ntional framing analysis method based on semantic relations. Their\napproach is also a kind of supervised task, as it first determines\nand labels particular frames and then identifies occurrences of each\npre-determined frame in the dataset. Framing analysis scholars in\nrecent studies [e.g., Ali and Hassan 2022; Nicholls and Culpepper\n2021] call for exploring semantic relations for improved framing\nnuances.\nTherefore, this research seeks to fill the gap by offering and\nadvancing a semantic relations-based unsupervised approach for\nframing analysis through two studies\u2014qualitative textual analysis\nand computational analysis. Both studies examine a sample of 100\nnews reports published by four major U.S. news media outlets on\nthe 2022 Texas school mass shooting.\n2.6 Gun Violence and Framing Analysis\nGun violence is a widely studied area in the U.S., as the mass shoot-\ning problem has been on the rise for years [El-Bawab 2022]. The\nbody of gun violence research involves various other issues, such\nas mental illness [McGinty et al .2014], frames [Morin 2016], and\npublic health issues [McKeever et al .2022]. Analyzing a sample of\nnews articles on serious mental illness and gun violence, McGinty\net al.[2014] found that \"dangerous people\" with serious mental\nillness were more likely to be mentioned as a cause of gun vio-\nlence than \u201cdangerous weapons. \u201d A recent study by McKeever et al .\n[2022] conducted an online survey (N=510) and found gun control\nand gun rights as the two salience frames. They also revealed that\npeople held individuals responsible for gun violence and identified\nbackground checks as the most salient solution.\n2.7 Attribution Theory\nThe root of frames is drawn from the assumptions outlined in attri-\nbution theory (AT) [Heider 2013; Kelley 1973; Pan and Kosicki 1993].\nSo, this research analyzes and explains frames through the lens of\nAT. Originally developed within social psychology, the theory pri-\nmarily describes how people explain and perceive the causes of an\nindividual\u2019s behavior [Heider 2013; McLeod 2010]. While defining\nthe theory, Kelley [1973] says:\nAttribution theory is a theory about how people make\ncausal explanations, about how they answer questions\nbeginning with \"why?\" It deals with the information\nthey use in making causal inferences, and with what\nthey do with this information to answer causal ques-\ntions. (p. 107).\nAs na\u00efve psychologists, people tend to make two broad types of\ncausal attributions: a) dispositional attributions and b) situational\nattributions [Heider 2013; Kelley 1973]. Dispositional attributions\npoint to an individual\u2019s internal factors as being responsible for\nan incident. For example, in a car crash, labeling people\u2019s reckless\ndriving behavior as a cause could be a dispositional attribution.\nSituational attributions refer to factors that exist outside an indi-\nvidual and are prevalent in specific situations. In the same example,\nattributing the snowy road as a cause could be considered a situa-\ntional factor. Two prominent frameworks provide potential factors\nand insights that shape people\u2019s perceptions of dispositional and\n3\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\nsituational attributions. These are the covariation model [Kelley\n1973] and the correspondent inference [Jones and Davis 1965].\n2.8 Covariation model\nThe covariation model of Kelley [1973] identified three potential\nfactors leading to causal perceptions. These are consensus, distinc-\ntiveness, and consistency. 1) Consensus is related to a person or\nentity that explains how many individuals behave in the same way.\nHigh consensus indicates a higher level of situational attribution.\n2) Distinctiveness is related to the situations that explain how an\nindividual behaves in other similar situations. High distinctiveness\nindicates a higher level of situational attribution. 3) Consistency\nis related to time, which explains how frequently an individual\u2019s\nbehavior occurs. High consistency indicates a higher level of dispo-\nsitional attributions [Kelley 1973].\n2.9 Correspondent inference\nJones and Davis [1965] offered three key factors in inferring causal\nattributions. 1) People\u2019s degree of choice: A freely chosen behav-\nior is considered to infer an individual\u2019s dispositional attributions\ncompared to forced behavior. 2) Social desirability of behavior:\nAn individual\u2019s behavior that is low in social desirability or so-\ncial expectedness is more likely to make dispositional attributions\ncompared to high social desirability. 3) Intended consequence of\nbehavior: People infer an individual\u2019s behavior as dispositional,\nespecially when the behavior\u2019s intended consequence is negative\nand harmful to people.\n2.10 Case: 2022 Uvalde School Shooting\nThis study analyzes media coverage of a mass shooting that oc-\ncurred on May 24, 2022, in Uvalde, Texas. An 18-year-old former\nstudent named Salvador Ramos entered Robb Elementary School\nwith an AR-15-style rifle and opened fire [Peck and Goodman 2022;\nSandoval 2023]. The shooting resulted in the deaths of 19 students\nand two teachers and the injuries of 17 others [Jacobo and El-Bawab\n2022; Peck and Goodman 2022; Shooting nd]. The Uvalde school\nshooting is one of the deadliest shootings in the United States in\nterms of the number of casualties Shooting [nd].\nThe mass shooting incident received extensive coverage in local,\nnational, and international news media [Kellner 2025], sparking\noutrage and reigniting long-standing debates over gun control and\nschool safety and calls for action [Livingston 2022]. News media\ncoverage of the Uvalde shooting evolved over time [Kellner 2025].\nSoon after the incident, the then-President of the United States, Joe\nBiden, visited Texas to console the victims and pledged to act [Liv-\ningston 2022; The Biden White House Achieve 2022]. Within a\nmonth of the Uvalde school mass shooting that occurred 10 days\nafter another shooting in Buffalo, New York, a gun safety legisla-\ntion was passed by the Senate and Congress and then signed by\nthe President on June 25, 2022. The gun safety law is reported as\nthe first of its kind in the previous 30 years [Clyde and Miranda\n2022]. As the deadliest mass shooting in recent years and drawing\nwidespread media coverage, the Uvalde elementary school shooting\nhas been purposively selected for this study.3 Study 1: Qualitative Textual Analysis\nThis study focuses on an in-depth examination of the usage pat-\nterns of specific words, such as adjectives and adverbs, and their\nsemantic relations in constructing frames. Typically, computational\ntools and traditional research methods, such as qualitative and\nquantitative methods, are broadly pursued as separate lines of in-\nquiry into frames. However, this study seeks to bridge this divide\nby utilizing the insights of inductive qualitative research to inform\ncomputational approaches in framing analysis.\nFor this analysis, we purposively selected the 2022 mass shooting\nas a case that took place at Robb Elementary School. Specifically,\nwe looked at how news media outlets in the right-leaning (a.k.a.\nWSJ and Fox News) and left-leaning categories (a.k.a. NYT and\nCNN) use selected modifying words (e.g., adjectives and adverbs)\nstructured in a semantic pattern to frame the shooter, victims, and\nthe event.\nTherefore, the following research questions are asked for explo-\nration:\nRQ1: How do right-leaning and left-leaning news media outlets\nuse words and phrases to construct frames while covering the 2022\nmass shooting at Robb Elementary School in Texas?\nRQ2: How do the right-leaning and left-leaning news media\noutlets frame the shooter, victims, and the mass shooting event at\nthe Robb Elementary school in Texas?\nRQ3: How do the semantic relations of words in the Texas mass\nshooting news reports inform the computational analysis of frames?\n4 Study 1 Method\nTo answer RQs, study 1 used qualitative textual analysis, a widely\nused approach to analyze frames inductively [Hertog and McLeod\n2001]. It fits with the study\u2019s purpose of inductively analyzing news\nreports to gain an in-depth understanding of frames, word usage\npatterns, and their semantic relations to constructing frames [Ent-\nman 1993]. Qualitative textual analysis is \u201call about language, what\nit represents and how we use it to make sense of our [social reali-\nties]\u201d [Brennen 2017, p. 203]. While exploring \"how texts operate\nto produce meaning\u201d [Browne 2009, p. 53], the qualitative anal-\nysis helps \u201cmake an educated guess at some of the most likely\ninterpretations that might be made of that text\u201d [McKee 2001, p. 1].\n4.1 Data Collection\nWe collected a total of 100 news reports, including 600 news head-\nlines and paragraphs, published by four news media outlets on the\n2022 Robb Elementary School shooting in Texas. Each of them in-\ncludes ten news reports on the shooting that took place on May 24,\n2022. Of the news outlets, The New York Times (NYT) and Cable News\nNetwork (CNN) are selected as the left-leaning news media, and the\nWall Street Journal (WSJ) and Fox News as the right-leaning news\nmedia [Check nd]. The news media outlets were categorized based\non their bias scores provided by Media Bias/Fact Check (MBFC). The\nMBFC is a non-partisan American independent site that provides\nbias scores for media outlets [Check nd; Odhner 2022].\nIt is important to acknowledge that although Fox News andThe\nWall Street Journal are both considered right-leaning according to\nMBFC scores, they differ in tone and editorial focus. As noted by\nAd Fontes Media (2024), Fox News tends to be more partisan in its\n4\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\nopinion content, whereas The Wall Street Journal is comparatively\nmore centrist in its news reporting [Media nd] (\u201cAd Fontes Media,\u201d\nn.d.). For the purposes of this study, both outlets were categorized\non the right side of the media bias spectrum.\nUsing purposive sampling, we used the keywords \u201c(Texas OR\nUvalde) AND (\u201cshoot*\u201d)\u201d and searched articles on Factiva, a global\nnews database, for these four news media outlets separately from\nMay 24 to 31, 2022. After downloading all news reports identified\nduring the period, we manually scrutinized and removed articles\nthat are not specifically relevant to this Uvalde mass shooting and\nare other types of content, such as editorials. This continued un-\ntil 25 news reports were selected for each new media. Collecting\nnews reports continued until the dataset seemed saturated with\nrelevant words and phrases coded in this study. Data saturation is\nconsidered a useful guide for sampling data in a qualitative study\nthat deals with a relatively small amount of information [Brennen\n2017; Sandelowski 1995]. With this process, a sample of 100 news\narticles was finally selected for this analysis. Since the lead and ini-\ntial paragraphs(s) generally represent the most important messages\nin a news story [Liu et al .2019; Van Dijk 1985], we purposively\nselected the headlines and first five paragraphs of each news report,\ntotaling 600 headlines and paragraphs, for an in-depth analysis.\n4.2 Data Analysis\nThis study analyzed the news reports with word-by-word coding in\nthree phases\u2014open coding, axial coding, and selective coding [Sal-\nda\u00f1a 2021] using NVivo, a qualitative data analysis software. The\ncoding process was guided by the three research questions, framing\ntheory [Entman 1993], and attribution theory [Heider 2013; Kel-\nley 1973]. Following the research purpose and questions, the data\nanalysis focused on using words and their semantic relations in\nconstructing frames [Entman 1993] in the case of the Robb Elemen-\ntary School shooting. The analysis explores whether and how the\nnews reports used various words and phrases to promote particular\ninterpretations or evaluations relating to the shooter, victims, and\nthe event.\nDuring the open coding phase, we specifically looked at the use\nof words and phrases that promoted or highlighted four aspects:\na) the shooter, Salvador Ramos; b) victims, such as school children\nand teachers; c) the shooting incident, in certain ways. Each type of\nword and phrase was coded into a separate code. For instance, the\nwords \u201ckills, \u201d \u201ckilling,\u201d and \u201ckilled\u201d were coded into a single code. In\nthe axial coding phase, where related codes are grouped into broader\ncategories, we organized initial codes into similar categories based\non shared framing purposes. Finally, during the selective coding,\nwhere central theme(s) are refined, a few broad themes emerged\nwith adequate exemplars (Table 1. To ensure validity, we used two\nstrategies: data triangulation (drawing from multiple data sources)\nand disconfirming evidence (intentionally seeking and considering\nboth supporting and opposing evidence from data) [Creswell and\nB\u00e1ez 2016].\n5 Study 1 Findings\nRQ1 and RQ2: The analysis identifies distinct sets of specific words\nand phrases in left-leaning news outlets, such as NYT and CNN,and right-leaning outlets, such as WSJ and Fox News (see Table 1,\nthat frame the shooter, victims, and the shooting event differently.\n5.1 Shooter\n\u201cAccused\u201d killer. The analysis shows that both right-leaning and\nleft-leaning media outlets use some common verbs (e.g., kills, left\ndead, opened fire, and shot) while attributing the shooter\u2019s act. Im-\nportantly, right-leaning media outlets use weaker verbs and modi-\nfiers (e.g., \u201cis accused of shooting,\u201d \u201cclaimed lives,\u201d and \u201callegedly\ncommitted by\u201d), which casts doubt on Salvador Ramos\u2019 crime and\nweakens the gravity of killing people. In contrast, left-leaning me-\ndia use stronger verbs and modifiers (e.g., \u201cshot and killed,\u201d \u201cburst\nin and killed,\u201d and \u201chorrifically\u201d), which presents the incident with\na higher gravity of the mass shooting act.\nDifferences in identifying the shooter also exist between the two\ngroups of media outlets. In contrast to the left-leaning media outlets,\nthe right-leaning ones use weaker terms like \u201calleged gunman\u201d and\n\u201calleged shooter. \u201d For example, a news report published by Fox News\non May 27 said, \u201cSalvador Ramos, the alleged gunman accused of\nshooting his grandmother and then targeting dozens of victims. . . .\u201d\nThis seems to have cast doubts regarding Salvador Ramos\u2019 act of\nkilling people, at least to some extent.\nMental instabilities. In terms of attributing the responsibility\nor blame to Salvador for the mass shooting, both groups of news\nmedia outlets showed their own bias. In contrast to left-leaning\nnews media outlets, the right-leaning ones selected and highlighted\nSalvador\u2019s mental and family-related instabilities, drawing attention\nto the social factors while presenting Salvador as responsible for the\nshooting. For example, the WSJ reported, \u201cSalvador Ramos. . . came\nfrom a broken family and unsettled classmates and co-workers with\nsometimes aggressive behavior and disturbing social-media posts.\u201d\n5.2 Shooting Incident\nLow vs. high severity. The shooting incident has been found to\nhave been presented differently in terms of its severity between the\nright-leaning and left-leaning news media outlets. The former has\nemployed specific words and phrases to portray the incident as a\nless severe one than the latter. The event modifier columns of Table\n1 demonstrate that while some words and phrases are common\nto both groups of news outlets, others are used to attribute the\nshooting incident differently. For example, the NYT used the word\n\u201cslaughter\u201d to describe the incident, while Fox News and the WSJ\ndid not. The left-leaning media also used \u201cterrorist attack,\u201d which\nwas not used by their right-leaning counterparts. In contrast, right-\nleaning media outlets identified the shooting as a \u201csenseless crime. \u201d\nThe use of words such as \u201cterrorist attack\u201d and \u201cslaughter\u201d might\ntrigger nodes in the human brain related to other deadly terrorist\nincidents, portraying the shooting as a more severe act [Collins and\nLoftus 1975]. On the other hand, the use of the phrase \u201csenseless\ncrime\u201d suggests a typical type of crime. Therefore, differences in\nthe use of words have contributed to defining the mass shooting as\na problem in terms of its severity between the right-leaning and\nleft-leaning news media outlets.\n5\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\n6 Victims\nTeenager vs. older. Divergent portrayals of the victims in the\nnews media outlets were observed, with both left-leaning and right-\nleaning news media using distinct words and phrases, although\nsome terms were commonly employed. The left-leaning media\noutlets specifically employed phrases such as \u201cschool children,\u201d \u201cel-\nementary school children,\u201d and \u201ckids,\u201d whereas the right-leaning\noutlets used \u201cchildren\u201d and \u201cstudents.\u201d For instance, the NYT re-\nported on \u201cthe killing of at least 19 elementary school children in\nsecond, third, and fourth grades.\u201d Although subtle, this contrast in-\ndicated the left-leaning outlets\u2019 emphasis on the word \u201celementary, \u201d\nframing the shooting incident as an attack on young children of\nthis age group. The word \u201celementary\u201d distinguishes the age range\nof 5-10 years from \u201cchildren\u201d and \u201cstudents. \u201d The word \u201celementary\u201d\nemphasizes the victims\u2019 age range more clearly, whereas terms like\n\u201cstudents\u201d and \u201cchildren\u201d are more general and can apply across\nvarious age groups, including older youth. By promoting the ages of\nthe victims in distinct ways, both the left-leaning and right-leaning\nnews media outlets presented the severity of the shooting incident\nand drew attention to the shooting problem differently.\nRQ3: Answers to RQ1 and RQ2 highlight the use of words in\nconstructing relevant frames. The RQ3 serves the main purpose of\nStudy 1, which is to investigate the semantic patterns or semantic\nrelations of those words in creating frames. As a way of answering\nit, this analysis provides various groups of words and phrases cen-\ntering on the shooter, victims, and the event, illustrating semantic\nrelations among the words (see Table 1.\n7 Semantic Relations\nThe above results and Table 1 provided in the analysis present\ntwo crucial aspects that contribute to the understanding of frames.\nFirstly, the words used to construct frames are crucial in identify-\ning the framing components utilized by the news media outlets.\nSecondly, the semantic relations among the words are crucial in es-\ntablishing the frames\u2019 meaning. Semantic relations indicate how the\nwords are interrelated and which entity the words are attributed to.\nReading through only the words might provide some insights into\nrelevant framing components, but the insights are not fully mean-\ningful without the words\u2019 semantic relations. When the words are\nread with their semantic relations, it renders particular meanings to\nconstruct frames. For instance, in the excerpt \u201cAn 18-year-old gun-\nman on Tuesday fatally shot 19 children and two adults\u201d from an\nNYT article, the semantic relation between the phrase \u201c18-year-old\u201d\nand the \u201cgunman\u201d (Salvador) highlights that the modifier refers to\nthe gunman and not the children. Without considering the seman-\ntic relations, it appeared challenging to comprehend the relevant\nmeanings of the words and subsequently construct frames.\n8 Study 1 Discussion\n8.1 Highlight and Hide\nAs the findings indicate, both left-leaning and right-leaning news\nmedia highlighted some common and different words regarding\nthe Texas mass shooting, conforming to the framing strategy of\nhighlighting and hiding certain aspects of the event [D\u2019Angelo\nand D\u2019Angelo 2018; Entman 1993; Greussing and Boomgaarden2017]. As a frame functions to purvey various judgments about\nreality [D\u2019Angelo and D\u2019Angelo 2018; Entman 1993], the frames\nconstructed by left-leaning and right-leaning news outlets may\nshape how people perceive and understand the causes of the mass\nshooting and influence their attitudes toward it.\n8.2 Attribution of Responsibility\nLeft-leaning news media outlets attributed more responsibility to\nSalvador for the mass shooting compared to right-leaning ones. As\nthe attribution theory [Kelley 1973] and framing theory [Entman\n1993] suggests, with highlighted salience in situational factors (e.g.,\nbroken family) in right-leaning outlets, people are more likely to\nattribute the shooting\u2019s causes to situational factors. This is sup-\nported by the phrase \u201caccused of\u201d that right-leaning news used in\npresenting Salvador\u2019s shooting.\nRight-leaning news media highlighted aspects of Salvador\u2019s so-\ncial factors, such as his broken family, which may have made his\nactions appear more situationally driven. As per the correspondent\ninference model [Jones and Davis 1965], such social desirability can\nreduce attributions of personal responsibility by shifting away from\ndispositional factors. Overall, the left-leaning news media reports\nfocused on attributing the causal responsibility of the mass shooting\nmore to Salvador, while the right-leaning news media reports went\nbeyond Salvador\u2019s individual responsibility to his family factors.\nSuch causal interpretation is supported by the study of [McGinty\net al.2014], which shows \u201cdangerous people\u201d with mental illness\nwere more likely mentioned as a cause of gun violence than \u201cdan-\ngerous weapons.\u201d The study by [McKeever et al .2022] also extends\nevidence in support of this current study\u2019s findings.\n8.3 Semantic Relations for Computational\nFraming Analysis\nUnsupervised computational methods mostly rely on the ideas of\nfrequencies and co-occurrences of words [Blei 2012; DiMaggio et al .\n2013]. These bag-of-words-based approaches are not designed to\nlook at the semantic relations of words and end up with identifying\ntopics, instead of frames [Ali and Hassan 2022]. The study 1 findings\ndemonstrate that capturing semantic relations helps discern in-\ndepth nuances in the texts through word relations and, thus, identify\nrelevant frames. For example, in the following excerpt from a New\nYork Times article, \u201cAn 18-year-old gunman on Tuesday fatally\nshot 19 children and two adults,\u201d the semantic relations show that\nthe phrase \u201c18-year-old\u201d modifies the \u201cgunman\u201d (aka Salvador),\nnot children. Without knowing this semantic relation, relevant\nmeanings of the words and, subsequently, frames do not emerge\n(see Table 1).\nManual data analysis enables the researchers to identify such se-\nmantic relations and relevant frames, as presented above. Therefore,\nsemantic relations appeared essential for having relevant meanings\nand frames in a text. In a computational method, being able to\ncapture the semantic relations seems to be a one-step advancement\ntoward better identification and analysis of frames. As identified\nin this study 1, the lists of words, their attributes, and semantic\nrelations for the shooter, victims, and the event are so specific that\nthese can be incorporated into an algorithmic model. So, this study\nsuggests incorporating these semantic relations into computational\n6\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\ntechniques (e.g., dependency parsing) for better automatic framing\nanalysis. As envisioned in Nicholls and Culpepper [2021] and Ali\nand Hassan [2022], this current study\u2019s findings extended additional\nevidence of how semantic relations among words and phrases, in-\nstead of just bag-of-words, can better explain nuances of frames,\nespecially in an unsupervised model.\n9 Study 2: Computational Analysis\nStudy 2 of computational analysis builds on the insights and recom-\nmendations from Study 1 of qualitative textual analysis. It focuses\non the potential of using dependency parsing, an NLP technique\nthat analyzes the grammatical structure of a sentence by identify-\ning relationships between words, such as which word modifies or\ndepends on another. This approach aims to enhance the identifica-\ntion and analysis of frames computationally. Examining the same\ndataset of news articles from Study 1, this computational analysis\nexplores how dependency parsing can capture the semantic rela-\ntions of words and understand relevant frames. We also compare\nthe results of the unsupervised computational model (Study 2) with\nthose obtained through manual data analysis (Study 1) to evalu-\nate the effectiveness of the computational approach. The findings\ncontribute to a better understanding of the role of the semantic\nrelations-based computational approach in analyzing frames and\noffer insights into the potential of using dependency parsing as a\nmethodological approach for framing analysis.\nSince it is one of the first studies to use semantic relations in\nanalyzing frames, we offer similar research questions established\nin study 1, consistent with the objectives of study 2.\nRQ1: How do right-leaning and left-leaning news media outlets\nuse words and phrases to construct frames at the Robb Elementary\nschool in Texas?\nRQ2: How do the right-leaning and left-leaning news media\noutlets frame the shooter, victims, and the mass shooting event at\nthe Robb Elementary school in Texas?\n10 Study 2 Method\n10.1 Dataset\nTo answer the research questions, we analyzed the same news\nreport dataset as study 1. Parsed by the spaCy NLP language model,\nthe dataset contains a total of 24604 tokens, with 4768 for CNN, 6282\nfor Fox, 6759 for NYT, and 6795 for WSJ. We used the same dataset\nto compare the frames provided by the computational approach\nwith those of the qualitative study.\n10.2 Analysis\nThe data analysis involved the following seven steps:\n1) Coreference resolution: As this study aims to identify mod-\nifying words centering three entities, the shooter, victims, and the\nevent, we needed to identify and resolve the coreferences (e.g., \u201che\u201d\nor \u201csuspect\u201d for the shooter) to capture all possible modifying words\nof both \u201creferences\u201d and \u201cco-references.\u201d To accomplish this, we\napplied NeuralCoref, an extension of the spaCy NLP library that\nprovides coreference resolution.\n2) Token extraction: We then applied a dependency parser of\nthe spaCy language model that parsed all the news reports andgenerated a dependency parse tree. This tree provides the syntactic\nstructure of a sentence that includes nodes, such as heads (e.g.,\ngunman) and children (e.g., suspect), representing words, and edges\nrepresenting the semantic relationships between those heads and\nchildren. Each edge is labeled with a specific dependency relation,\nsuch as \u201camod\u201d (adjective modifier).\n3) Determining keywords: To capture all possible words that\nrefer and co-refer to each of the three entities, we determined\nrelevant keywords for each entity (e.g., Salvador, gunman, shooter).\nThese keywords were determined based on study 1 insights and\nthen refined through manual checking of some tokens in the output\nproduced in step 2 (see Table 2 for details).\n4) Filtering heads and children: Based on the keywords, we\nfiltered out all relevant \u201cheads\u201d and \u201cchildren\u201d of each entity, all\ntheir dependency relations, and associated news outlets.\n5) Determining and refining dependency relations: This\nstep determines and refines useful dependency relations based on\nthis study\u2019s purpose. We removed some dependency relations (e.g.,\ncc, punc) that were not useful in making meanings in relation to\nthe RQs, by manual checking of the relations grouped in the output\nproduced in step 4 (see Table 2 for details).\n6) Filtering \u201cframing components\u201d: We consider each pair\nof head and child with certain dependency relation (e.g., the pair\nof \u201cshooting\u201d keyword and \u201cdeadly\u201d child with \u201camod\u201d relation) as\na framing component that provides a particular attribution to an\nentity. This step filtered out all framing components for each entity\nby the news outlets.\n7) Framing components to frames: Until the last step, we an-\nalyzed the data computationally using spaCy and Pandas, a popular\ndata analysis library for Python. In this step, we followed both com-\nputational and manual qualitative explorations. 7a) Computational:\nWe computationally grouped the framing components for each\nentity by dependency relations. To achieve this goal, we used BERT\nword embedding and k-means clustering of the modifying words\n(also known as children). 7b) Qualitative: We inductively coded the\nmodifying words and categorized them into groups following the\nresearch questions manually. Here, we consider a single framing\ncomponent as a candidate for being included in multiple groups\n(Salda\u00f1a, 2016), and triangulation and disconfirming evidence were\nutilized to ensure the validity (Creswell, 2016). In both parts, each\ngroup is considered as a frame. With the process, a number of\nframes emerged with exemplars.\n11 Study 2 Findings\nThis section reports the findings of the qualitative analysis in step 7,\nfollowed by the computational analysis from steps 1 to 6. The results\nof the computational exploration in step 7 are not reported here,\nas we found that the findings from manual analysis outperformed\nthem. The clusters revealed through k-means clustering were not\nfound to be coherent and adequately insightful for understanding\nthe nuances of frames, as we examined the results manually. The\nfindings of the qualitative analysis reveal that right-leaning and\nleft-leaning news media outlets use different words to construct\nframes of the shooter, victims, and the mass shooting event at the\nRobb Elementary school in Texas differently, as presented in Tables\n3, 4, and 5 respectively.\n7\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\n11.1 Shooter: \u201cAccused\u201d killer\nThe shooter was characterized with some words that create doubt\nover the shooter\u2019s killing action. Comparing the attributions used\nby right-leaning and left-leaning news outlets, it was found that the\nformer used the words \"alleged [shooter]\" and \u201csuspected [shooter]\u201d\nmore frequently than the latter. Furthermore, a right-leaning news\noutlet referred to the shooter as \u201caccused [of shooting]\u201d, which was\nnot used by the left-leaning outlets. These attribution differences\nsuggest that the two media outlets utilized different priorities in\nframing the shooter.\n11.2 Shooter: Diversity of attributes\nAs depicted in Table 3, right-leaning news outlets used a greater\nvariety of attributes to highlight various aspects of the shooter than\nleft-leaning outlets. For example, right-leaning outlets used words\nsuch as \u201cunhappy,\u201d \u201cdeceased,\u201d \u201ccivilized,\u201d and \u201cactive\u201d to describe\nthe shooter, which left-leaning outlets did not use. However, these\nwords appear scattered and do not seem to form a coherent ar-\ngument. This may be due to the small dataset used in this study.\nA larger dataset in future research could reveal more modifying\nwords and categorize them into relevant groups, providing further\ninsights into framing strategies.\n11.3 Shooter & Victims: Teenager vs. Older\nRight-leaning news media outlets tend to use words depicting the\n\u201cshooter\u201d as comparatively younger than left-leaning outlets. For\ninstance, words used by the right-leaning outlets to attribute to\nthe shooter include \u201cteenage,\u201d \u201cyoung,\u201d and \u201cstudent,\u201d which left-\nleaning outlets did not mention. Another example is that the shooter\nwas identified as \u201c18-year-old\u201d 26 times in the left-leaning outlets\nand only 10 times in the right-leaning ones (see Table 3. In contrast,\nthe victims were attributed with the word \u201cyoung,\u201d an adjective\nmodifier, five times by the left-leaning outlets and zero times by the\nright-leaning ones. Overall, right-leaning outlets frame the shooter\nas younger and the victims as older, and the scenario is the opposite\nin left-leaning outlets (see Table 4.\n11.4 Victims: Our Kids vs. Your Kids\nThere is not much difference between left-leaning and right-leaning\nnews outlets in using personal pronouns to modify the victims (see\nTable 4. Pronouns addressing victims are important to perceive how\nthe news media outlets stand with them. The left-leaning outlets\nstill used a greater variety of personal words, such as my (2), our\n(2), and your (2), while the right-leaning ones used two such words,\nher (2) and our (3).\n11.5 Shooting Event: Low vs. High Severity\nTo describe the shooting, left-leaning news media outlets tend to\nuse more severe and emotionally charged words, such as deadliest\n(6), deadly (6), horrific (1), horrifying (1), heinous (1), tragic (1),\nand fatally [shot] (1), which frames the issue as a more significant\nproblem. Such words used by right-leaning outlets include deadly\n(4), deadliest (3), awful (4), horrific (3), senseless (2), and devastated\n(1). This shows the right-leaning outlets use less intense words like\n\u201csenseless\u201d and \u201cawful,\u201d which suggests a less severe framing of the\nissue (see Table 5. Overall, the mass shooting framing is constructedby the language deployed by news media outlets, and the severity\nof the framing can differ based on the political leaning of the outlet,\nwhich is aligned with framing aspects suggested by [Entman 1993].\n12 Study 2 Discussion\nStudy 2 investigates how news outlets frame the shooter, victims,\nand the Texas school shooting, applying a new computational ap-\nproach based on semantic relations.\n12.1 Attribution of Responsibility\nFraming the shooter as \u201cyoung\u201d or \u201colder\u201d can have significant\nimplications for how people perceive the shooting and the level\nof responsibility attributed to the shooter [Entman 1993]. The use\nof the \u201cyoung\u201d attribute by right-leaning outlets could soften the\nshooter\u2019s image and create a more sympathetic portrayal, thereby\nreducing the level of responsibility attributed to him [Jones and\nDavis 1965]. On the other hand, the left-leaning outlets\u2019 focus on\nthe victims\u2019 youth could create a greater sense of tragedy and\nurgency and, therefore, a higher level of responsibility attributed to\nthe shooter [Decety et al .2012]. As per attribution theory, people\ntend to attribute a person\u2019s behavior to internal or external factors\nbased on internal and external factors [Heider 2013; Kelley 1973]. In\nthis case, the framing of the shooter and victims differently by the\nnews outlets might shape how people attribute responsibility for\nthe shooting. The framing differences among news media outlets\nmight have been shaped more by established media routines and\npractices [Reese and Shoemaker 2018] than by the specifics of this\nparticular mass shooting event.\n12.2 Taking Actions\nThe news media outlets\u2019 different approaches to highlighting se-\nlected \u201csevere\u201d words might have significant implications for how\nthe public perceives the incident and \u201cchoose[s] to act upon\u201d the\nproblem [Entman 1993, p. 54]. The left-leaning news outlets\u2019 higher\nsalience on words like \u201cdeadly\u201d and \u201cdeadliest\u201d might activate the\n\"amygdala\u201d node in people\u2019s brains, potentially leading them to take\nactions like protest and advocacy [Barry et al .2013; Phelps 2006].\nAt the same time, highlighting more on the words \u201caccused\u201d and\n\u201calleged\u201d regarding the shooter\u2019s act, the right-leaning news outlets,\ncompared to left-leaning ones, offered doubt in people\u2019s perception\nregarding Ramos\u2019s mass shooting. Such higher salience on these\nwords in right-leaning outlets seems to have weakened people\u2019s\nperception of the shooter\u2019s dispositional factors in committing the\noffense [Kelley 1973].\n12.3 Highlight and Hide\nTaking some meanings or words over others as discussed above\nconforms the framing technique of highlight and hide, as proposed\nby Entman [1993] and Fairhurst and Sarr [1996]. Both right-leaning\nand left-leaning news outlets utilized distinct ways of framing the\nshooter, victims, and the event despite some common depictions\nbetween the groups. Overall, the left-leaning outlets attempt to\nelicit people\u2019s sympathy for \u201cvictims\u201d while right-leaning ones\nsympathize with the shooter, as evidenced above.\n8\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\n13 Integrated Discussion of Both Studies\nThis research\u2019s primary objective is to introduce and explore a new\napproach to computational framing analysis. Our initial qualitative\ninquiry in study 1 revealed in-depth insights into the role of seman-\ntic relations in frame construction and suggested that dependency\nparsing, a computational method, could potentially serve as a prac-\ntical unsupervised approach to frame analysis. Based on study 1\u2019s\nfindings and recommendations, study 2 applied dependency parsing\nto the same dataset as an approach to computationally analyzing\nframes. A comparison of the findings of both studies demonstrates\nthe potential of this proposed semantic relations-based approach to\nautomate the identification and analysis of frames in large datasets.\nAs the study 2 discussion suggests, its findings on framing the\nshooter, victims, and the event are well interpretable with relevant\ntheoretical frameworks, and the interpretations are mostly aligned\nwith those of study 1 and prior gun violence research. With that, this\narticle proposes a novel computational framing analysis approach\nbased on dependency parsing named \u201cSemantic Relations-based\nUnsupervised Framing Analysis\u201d (SUFA).\n14 Semantic Relations-based Unsupervised\nFraming Analysis (SUFA)\n14.1 Novelty of SUFA\nThe SUFA is novel in analyzing frames in several ways. First, it is\nbased on semantic relations that extend beyond the bag-of-words\napproach utilized by most existing unsupervised computational\nframing analysis methods, such as topic modeling. Second, as dis-\ncussed above, a few studies have employed semantic relations in\nframing analysis [e.g., van Atteveldt et al .2013; Ziems and Yang\n2021]. However, they did not present it as an unsupervised method.\nIn contrast to these studies, our approach demonstrates its distinc-\ntion as an unsupervised method. Researchers do not need to define\na frame in advance to explore frames within a dataset. Third, our\napproach provides flexibility in using qualitative manual coding\nor computational tools like word embedding and k-means clus-\ntering in step 7 of its data analysis process. In this sense, it is a\nmixed-method approach that prior studies did not include.\n14.2 Data Analysis in SUFA.\nThe procedure for analyzing data in SUFA is outlined in seven\nsteps in the study 2\u2019s method section. To effectively apply SUFA,\nwe recommend following these steps along with a few additional\nconsiderations. If news media outlets have specific identities, such\nas left or right-leaning, we suggest labeling these identities in the\ndata. Steps 3 and 5 require human intelligence. For example, step\n3 involves providing keywords for each entity, which can be in-\nformed by domain knowledge, researchers\u2019 little manual data ex-\nploration, or with the assistance of WordNet [Miller 1995]. In step\n5, researchers may need to manually review the output to identify\nuseful semantic relations for analysis. For step 7, either qualitative\nor computational analyses can be used, depending on the research\ngoals and the number of modifying words derived from the dataset.\nThe computational analysis, such as word embedding and k-means\nclustering, may generally be more appropriate as SUFA is meant\nto analyze large datasets. However, if the size of modifying wordsis small enough to manage manually, a qualitative analysis might\nbe more suitable for step 7, as research suggests that human intelli-\ngence often outperforms machines in tasks that require contextual\ninterpretation and subjective judgment [Lazer et al. 2009].\n14.3 Strengths\nThe SUFA is an unsupervised approach that does not require any\nprior labeling or defining of data frames. Instead, it uses an induc-\ntive approach to explore and group attributions together to reveal\nframing components or frames. One advantage of SUFA is that it\nallows for the flexibility of utilizing both human intelligence and\ncomputational techniques to emerge frames and their interpreta-\ntions, particularly in cases where the size of modifying words is\nsmall enough to be managed manually. Moreover, SUFA can induc-\ntively analyze frames in large datasets in an unsupervised manner.\n14.4 Weaknesses\nThe approach requires manual input in determining relevant key-\nwords (step 3) and semantic relations (step 5), which can be time-\nconsuming and subjective. It is limited to analyzing frames centered\naround entities, such as an individual (e.g., shooter), a group of peo-\nple or community (e.g., victims), and an incident or phenomenon\n(e.g., a shooting event). Since this study focuses on exploring em-\nphasis frames through a semantic relations-based approach, it is\nbetter suited for analyzing emphasis frames [D\u2019Angelo 2017] rather\nthan equivalency frames [Kahneman and Tversky 1984].\nAdditionally, like other computational framing analysis approaches,\nthis study only considers words and phrases, while other framing\ncomponents like metaphor, placement, and visual elements are not\nanalyzed. During coreference resolution (step 1), some words useful\nas framing components could be replaced with co-references (e.g.,\nreplacing the word \u201cgunman\u201d with \u201cSalvador\u201d), which might lead\nto the loss of some words with important nuances.\n15 Conclusion\nThis research introduces a new computational approach called\nSemantic Relations-based Unsupervised Framing Analysis (SUFA),\nwhich utilizes semantic relations to analyze news frames. While the\nmethod has some limitations, such as the need for manual input and\nits focus on emphasis frames, it provides a useful tool for exploring\nframing components in news media coverage. The mixed-method\napproach of SUFA offers researchers the flexibility to use entirely\ncomputational tools or couple it with qualitative manual coding,\nwhere applicable, for data analysis. Overall, SUFA is a valuable\naddition to the field of computational framing analysis, enabling\nmore comprehensive and nuanced analysis of news media frames.\n16 Limitations and Future Research\nThe SUFA was developed and tested on a single dataset of news re-\nports on gun violence in Study 1 and Study 2. However, the approach\ncan be applied to other domains with the provision of relevant key-\nwords and relations. Further research can be conducted to explore\nthe applicability of this method in other domains and to improve\nits performance. Currently, SUFA only considers words when ana-\nlyzing frames. However, the computational framing analysis needs\n9\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\nto include other framing components such as metaphor, visual con-\ntent, placement, differences between headline and body texts, and\nexemplars. Such advancements will provide a more comprehensive\nunderstanding of framing effects in news media.\nReferences\nMohammad Ali and Naeemul Hassan. 2022. A survey of computational framing\nanalysis approaches. In Proceedings of the 2022 conference on empirical methods in\nnatural language processing . 9335\u20139348.\nPhilemon Bantimaroudis and Hyun Ban. 2001. Covering the crisis in Somalia: Framing\nchoices by the New York Times and the Manchester Guardian. Framing public life:\nPerspectives on media and our understanding of the social world (2001), 175\u2013184.\nColleen L Barry, Emma E McGinty, Jon S Vernick, and Daniel W Webster. 2013. After\nNewtown\u2014public opinion on gun policy and mental illness. New England journal\nof medicine 368, 12 (2013), 1077\u20131081.\nDavid M Blei. 2012. Probabilistic topic models. Commun. ACM 55, 4 (2012), 77\u201384.\nJan Boesman and Baldwin Van Gorp. 2018. Driving the frame: How news values, news\npegs, and story angles guide journalistic frame building. In Doing news framing\nanalysis II . Routledge, 112\u2013134.\nBonnie S Brennen. 2017. Qualitative research methods for media studies . routledge.\nStephen Howard Browne. 2009. Close textual analysis: Approaches and applications\n(J. Kuypers, Eds.). Rhetorical criticism: Perspectives in action (pp. 63\u201376) . Lexington\nBooks.\nBjorn Burscher, Rens Vliegenthart, and Claes H de Vreese. 2016. Frames beyond words:\nApplying cluster and sentiment analysis to news coverage of the nuclear power\nissue. Social Science Computer Review 34, 5 (2016), 530\u2013545.\nDallas Card, Amber Boydstun, Justin H Gross, Philip Resnik, and Noah A Smith. 2015.\nThe media frames corpus: Annotations of frames across issues. In Proceedings of\nthe 53rd Annual Meeting of the Association for Computational Linguistics and the\n7th International Joint Conference on Natural Language Processing (Volume 2: Short\nPapers) . 438\u2013444.\nMedia Bias Fact Check. n.d.. MediaBiasFactCheck.com as a Tool for Lateral Reading .\nhttps://mediabiasfactcheck.com/ Media Bias Fact Check.\nDon Clyde and Shauneen Miranda. 2022. Biden signs gun safety bill into law. https:\n//www.npr.org/2022/06/25/1107626030/biden-signs-gun-safety-law The National\nPublic Radio.\nAllan M Collins and Elizabeth F Loftus. 1975. A spreading-activation theory of semantic\nprocessing. Psychological review 82, 6 (1975), 407.\nJohn W Creswell and Johanna Creswell B\u00e1ez. 2016. 30 essential skills for the qualitative\nresearcher . Sage Publications.\nPaul D\u2019Angelo. 2017. Framing: Merua frames. In International encyclopedia of media\neffects , Patrick R\u00f6ssler (Ed.). WileyBlackwell, NJ, 634\u2013644.\nPaul D\u2019Angelo and Paul D\u2019Angelo. 2018. Doing news framing analysis II . Routledge.\nJean Decety, Kalina J Michalska, and Katherine D Kinzler. 2012. The contribution of\nemotion and cognition to moral sensitivity: a neurodevelopmental study. Cerebral\ncortex 22, 1 (2012), 209\u2013220.\nDonna L Dickerson. 2001. Framing \u201cpolitical correctness\u201d: The New York Times\u2019 tale\nof two professors. Framing public life: Perspectives on media and our understanding\nof the social world (2001), 163\u2013174.\nPaul DiMaggio, Manish Nag, and David Blei. 2013. Exploiting affinities between topic\nmodeling and the sociological perspective on culture: Application to newspaper\ncoverage of US government arts funding. Poetics 41, 6 (2013), 570\u2013606.\nNadine El-Bawab. 2022. America\u2019s gun violence problem by the num-\nbers. https://abcnews.go.com/US/americas-gun-violence-problem-\nnumbers/story?id=85136358 The ABC News.\nRobert M Entman. 1993. Framing: Toward clarification of a fractured paradigm. Journal\nof communication 43, 4 (1993), 51\u201358.\nGail Fairhurst and Robert Sarr. 1996. The art of framing . San Francisco: Jossey-Bass.\nGail T Fairhurst. 2005. Reframing the art of framing: Problems and prospects for\nleadership. Leadership 1, 2 (2005), 165\u2013185.\nWilliam A Gamson and Andre Modigliani. 1989. Media discourse and public opinion\non nuclear power: A constructionist approach. American journal of sociology 95, 1\n(1989), 1\u201337.\nFabrizio Gilardi, Charles R Shipan, and Bruno W\u00fcest. 2021. Policy diffusion: The\nissue-definition stage. American Journal of Political Science 65, 1 (2021), 21\u201335.\nErving Goffman. 1974. Frame analysis: An essay on the organization of experience.\nHarvard University Press.\nEsther Greussing and Hajo G Boomgaarden. 2017. Shifting the refugee narrative? An\nautomated frame analysis of Europe\u2019s 2015 refugee crisis. Journal of ethnic and\nmigration studies 43, 11 (2017), 1749\u20131774.\nFritz Heider. 2013. The psychology of interpersonal relations . Psychology Press.\nJames K Hertog and Douglas M McLeod. 2001. A multiperspectival approach to framing\nanalysis: A field guide. In Framing public life . Routledge, 157\u2013178.\nJulia Jacobo and Nadine El-Bawab. 2022. Timeline: How the shooting at a Texas el-\nementary school unfolded . https://abcnews.go.com/US/timeline-shooting-texas-elementary-school-unfolded/story?id=84966910 The ABC News.\nEdward E Jones and Keith E Davis. 1965. From acts to dispositions the attribution\nprocess in person perception. In Advances in experimental social psychology . Vol. 2.\nElsevier, 219\u2013266.\nDaniel Kahneman and Amos Tversky. 1984. Choices, values, and frames. American\npsychologist 39, 4 (1984), 341.\nHarold H Kelley. 1973. The processes of causal attribution. American psychologist 28,\n2 (1973), 107.\nDouglas Kellner. 2025. The Uvalde, Texas school shooting massacre. Educational\nPhilosophy and Theory 57, 2 (2025), 91\u201395.\nSotiris B Kotsiantis, Ioannis Zaharakis, P Pintelas, et al .2007. Supervised machine\nlearning: A review of classification techniques. Emerging artificial intelligence\napplications in computer engineering 160, 1 (2007), 3\u201324.\nHaewoon Kwak, Jisun An, Elise Jing, and Yong-Yeol Ahn. 2021. FrameAxis: character-\nizing microframe bias and intensity with word embedding. PeerJ Computer Science\n7 (2021), e644.\nDavid Lazer, Alex Pentland, Lada Adamic, Sinan Aral, Albert-L\u00e1szl\u00f3 Barab\u00e1si, Devon\nBrewer, Nicholas Christakis, Noshir Contractor, James Fowler, Myron Gutmann,\net al. 2009. Computational social science. Science 323, 5915 (2009), 721\u2013723.\nIrwin P Levin, Sandra L Schneider, and Gary J Gaeth. 1998. All frames are not created\nequal: A typology and critical analysis of framing effects. Organizational behavior\nand human decision processes 76, 2 (1998), 149\u2013188.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and Derry Tanti Wijaya. 2019. Detecting\nframes in news headlines and its application to analyzing news framing trends\nsurrounding US gun violence. In Proceedings of the 23rd conference on computational\nnatural language learning (CoNLL) . 504\u2013514.\nAbby Livingston. 2022. Uvalde school shooting: \u2018Do something!\u2019 Biden is urged as he\nleaves Uvalde church . https://www.texastribune.org/2022/05/29/biden-uvalde-visit/\nThe Texas Tribune.\nEmma E McGinty, Daniel W Webster, Marian Jarlenski, and Colleen L Barry. 2014.\nNews media framing of serious mental illness and gun violence in the United States,\n1997-2012. American journal of public health 104, 3 (2014), 406\u2013413.\nAlan McKee. 2001. A beginner\u2019s guide to textual analysis. Metro Magazine: Media &\nEducation Magazine 127/128 (2001), 138\u2013149.\nBrooke W McKeever, Minhee Choi, Denetra Walker, and Robert McKeever. 2022. Gun\nviolence as a public health issue: Media advocacy, framing and implications for\ncommunication. Newspaper research journal 43, 2 (2022), 138\u2013154.\nSaul McLeod. 2010. Attribution theory . https://www.simplypsychology.org/attribution-\ntheory.html Simply Psychology.\nAd Fontes Media. n.d.. . https://adfontesmedia.com/\nGeorge A Miller. 1995. WordNet: a lexical database for English. Commun. ACM 38, 11\n(1995), 39\u201341.\nAysel Morin. 2016. Framing terror: The strategies newspapers use to frame an act as\nterror or crime. Journalism & Mass Communication Quarterly 93, 4 (2016), 986\u20131005.\nViet-An Nguyen. 2015. Guided probabilistic topic models for agenda-setting and framing .\nPh. D. Dissertation. University of Maryland, College Park.\nTom Nicholls and Pepper D Culpepper. 2021. Computational identification of media\nframes: Strengths, weaknesses, and opportunities. Political Communication 38, 1-2\n(2021), 159\u2013181.\nKatie Odhner. 2022. MediaBiasFactCheck.com as a Tool for Lateral Read-\ning. https://newsliteracy.psu.edu/news/mediabiasfactcheck-com-as-a-tool-for-\nlateral-reading The News Literacy Institute at Pennsylvania State University.\nZhongdang Pan and Gerald M Kosicki. 1993. Framing analysis: An approach to news\ndiscourse. Political communication 10, 1 (1993), 55\u201375.\nJosh Peck and J. David Goodman. 2022. Uvalde elementary school shoot-\ning: Shooting at elementary school devastates community in South Texas .\nhttps://www.nytimes.com/live/2022/05/24/us/shooting-robb-elementary-\nuvalde#shooting-texas-elementary-school The New York Times.\nElizabeth A Phelps. 2006. Emotion and cognition: insights from studies of the human\namygdala. Annu. Rev. Psychol. 57, 1 (2006), 27\u201353.\nStephen D Reese, Oscar H Gandy Jr, and August E Grant. 2001. Framing public life:\nPerspectives on media and our understanding of the social world . Routledge.\nStephen D Reese and Pamela J Shoemaker. 2018. A media sociology for the networked\npublic sphere: The hierarchy of influences model. In Advances in foundational mass\ncommunication theories . Routledge, 96\u2013117.\nJohnny Salda\u00f1a. 2021. The coding manual for qualitative researchers . SAGE publications\nLtd.\nMargarete Sandelowski. 1995. Sample size in qualitative research. Research in nursing\n& health 18, 2 (1995), 179\u2013183.\nLisa Sanderink. 2020. Shattered frames in global energy governance: Exploring frag-\nmented interpretations among renewable energy institutions. Energy research &\nsocial science 61 (2020), 101355.\nEdgar Sandoval. 2023. A year after the Uvalde massacre: Did anything change? https:\n//www.nytimes.com/2023/05/24/us/uvalde-shooting-fallout.html The New York\nTimes.\nMass Shooting. n.d.. . https://www.gunviolencearchive.org/mass-shooting?sort=\ndesc&order=Victims%20Killedl The Gun Violence Archive.\n10\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\nMihai D Sturdza et al .2018. Automated framing analysis: A rule based system for\nnews media text. Journal of Media Research-Revista de Studii Media 11, 32 (2018),\n94\u2013110.\nJW Tankard, L Hendrickson, J Silberman, K Bliss, and S Ghanem. 1991. Media frames:\nApproaches to conceptualization and measurement (Paper presented to the annual\nmeeting of the Association for Education in Journalism and Mass Communication).\nBoston, Massachusetts (1991).\nThe Biden White House Achieve. 2022. Remarks by President Biden on the school\nshooting in Uvalde, Texas . https://bidenwhitehouse.archives.gov/briefing-\nroom/speeches-remarks/2022/05/24/remarks-by-president-biden-on-the-school-\nshooting-in-uvalde-texas/ The Biden White House Achieve.\nWouter Van Atteveldt and Tai-Quan Peng. 2018. When communication meets com-\nputation: Opportunities, challenges, and pitfalls in computational communication\nscience. Communication Methods and Measures 12, 2-3 (2018), 81\u201392.\nWouter van Atteveldt, Tamir Sheafer, and Shaul Shenhav. 2013. Automatically extract-\ning frames from media content using syntacting analysis. In Proceedings of the 5th\nAnnual ACM Web Science Conference . 423\u2013430.\nTeun A Van Dijk. 1985. Structures of news in the press. Discourse and communication:\nNew approaches to the analysis of mass media discourse and communication 10 (1985),\n69.\nDror Walter and Yotam Ophir. 2019. News frame analysis: An inductive mixed-method\ncomputational approach. Communication Methods and Measures 13, 4 (2019), 248\u2013\n266.\nCaleb Ziems and Diyi Yang. 2021. To protect and to serve? analyzing entity-centric\nframing of police violence. arXiv preprint arXiv:2109.05325 (2021).\n11\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\nA Appendix\nTable 1: Words, Phrases, and Their Relations in News Reports of Two Media Groups: NYT and CNN vs. WSJ and FOX.\nSalvador\nModifiersNYT, CNN 18-year-old, 18-year-old man, Armored, Gunman, He, Shooter, Suspect\nWSJ, FOX18-year-old, 18-year-old man, A resident of Uvalde, Active shooter, Alleged gunman, Alleged\nshooter, Alone, Former student at Uvalde High school, Gunman, He, Mass shooter, Now-deceased,\nnow-deceased suspect, Shooter, Suspect, Suspected lone gunman, Suspected shooter, Suspected\nUvalde school shooter, Texas school shooting suspect\nSalvador\nHistoryNYT, CNN\nWSJ, FOX Broken family, Hostile, Unsettled classmates, Violent, was \u2019flashing red\u2019\nGunNYT, CNNA long rifle, Assault rifle, Semiautomatic rifle, Semiautomatic weapons, Semitauonic firearms,\nTactical vest, With a rifle\nWSJ, FOX AR-platform rifle, Handgun, Legally purchased, Two rifles\nVerbNYT, CNNBurst in and killed, Came in an opened fire, in [in custody], Kills, Left, Left dead, Left killing,\nOpened fire, Shoots, Shot and killed, Shot dead, Stormed into\nWSJ, FOXAccused of shooting, Allegedly committed by, Broke into the school, Claimed the lives . . . ,\nEntering [the school], Shot, Gunned down, Is accused of, Kills, Left, Left dead, Left killing,\nOpened fire, Walking into [school]\nVerb modifierNYT, CNN After . . . [another event], Fatally, Horrifically, Incomprehensibly\nWSJ, FOX Fatally\nVictimNYT, CNN18, 19, Adults, Age between 6 and 7 years old, At least, Children, Elementary school children,\nElementary school students, Kids, One, School children, Students, Teachers, Two, Victims\nWSJ, FOX 14, 19, Adults, At least, Children, Children, One, Students, Teacher(s), Two, Victims, Xavier Lopez\nEvent modifierNYT, CNN30th K-12 shooting, 6-year-old son, Aftermath, Attack, Deadliest mass shooting, Deadly shooting,\nDevastating, Elementary school shooting, Horrific mass murder, Mass school shooting,\nMass shooting, Massacre, Nation reeling, School massacre, School shooting, Second deadliest,\nShakes a nation, Slaughter, Slayings, Stealing their lives, Terrorism, Terrorist attack, Tragedy,\nTragic, Violent, Worst school shooting\nWSJ, FOXAftermath, Attack, Deadliest, Deadliest shooting, Deadly, Deadly [shooting], Devastated the\ntown, elementary school shooting, Horrific shooting, Horrific tragedy, Later discovered to be the\nshooting, Local elementary-school shooting, Mass casualty incident, Mass murder, Mass shooting,\nMassacre, murders, School shooting, Senseless crime, Shocked the country, Shooting, Texas\nelementary, school shooting, Texas mass shooting, Texas school shooting, third most deadly,\ntragedy\nTable 2: Keywords and Dependency Relations Used for the Shooter, Victims, and the Event\nKeywords Relations\nShooter\u2018gunman\u2019, \u2018gunmen\u2019, \u2018man\u2019, \u2018Salvador\u2019, \u2018Ramos\u2019,\n\u2018shooter\u2019, \u2018shooters\u2019, and \u2018suspect\u2019.\u2019acl\u2019, \"amod\", \u2019appos\u2019,\n\"compound\", \"relc\", \u2019nsubj\u2019,\u2019dobj\u2019, and \u2019nsubjpass\u2019..\nVictims\u2018adult\u2019, \u2018adults\u2019, \u2018child\u2019, \u2018children\u2019, \u2018kids\u2019, \u2018schoolchildren\u2019, \u2018student\u2019,\n\u2018students\u2019, \u2018teacher\u2019, \u2018teachers\u2019, \u2018victim\u2019, and \u2018victims\u2019.\u2019acl\u2019, \u2019compound\u2019, \u2019nummod\u2019, \u2019relcl\u2019, \u2019amod\u2019, \u2019dobj\u2019,\n\u2019nsubj\u2019, \u2019nsubjpass\u2019, and \u2019poss\u2019\nEvent\u2018shooting\u2019, \u2018shootings\u2019, \u2018attack\u2019, \u2018massacre\u2019, \u2018event\u2019, \u2018tragedy\u2019,\n\u2018terrorism\u2019, \u2018slaughter\u2019, \u2018crime\u2019, \u2018slayings\u2019, \u2018murder\u2019, and \u2018aftermath\u2019.\u2019amod\u2019, \u2019advmod\u2019, \u2019compound\u2019, \u2019nummod\u2019, and \u2019relcl\u2019\n12\nSemantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis AEJMC, August 07\u201310, 2023, Washington, DC\nTable 3: Framing Components (with Frequencies) Deployed by Each News Media Outlet to Attribute the SHOOTER, Grouped\nunder Different Associated Semantic Relations.\nLeft CNNacl:clad (2), identified (2);\namod: active (3), old (21), deranged (1), many (1), other (1), suspected (1), alleged (1), grandmother (1);\nappos: Ramos (2);\ncompound: Salvador (7), mass (1)\nLeft-center NYTacl:approaching (2), barricaded (2), driven (1);\namod: shooting (1), angry (1), armed (2), old (5);\ncompound: shooting (2), Salvador (2)\nRight-center WSJacl:named (1);\namod: grandmother (1), old (8), teenage (1), unhappy (1), young (1), deceased (2), civilized (2), active (4);\nappos: himself (1), student (1), resident (1), old (1), man (1), birthday (1), Ramos (2);\ncompound: school (1), mass (4), Salvador (12)\nRight FOXacl:accused (1), identified (1);\namod: active (1), alleged (2), bureaudefined (1), deceased (4), lone (2), old (1), suspected (4), upstate (1), red (1);\nappos: resident (2), ones (1), gunman (1), Romas (1), Ramos (2), 18 (1);\ncompound: suspect (1), York (1), resident (1), mass (1), Texas (1), Salvador (14), Ramos (1), school (1)\nTable 4: Framing Components (with Frequencies) Used by Each News Media Outlet to Attribute VICTIMS, Grouped under\nDifferent Associated Semantic Relations.\nLeft CNNacl:aged (1);\namod: local (1), young (2);\ncompound: Parents (1), parents (1), school (1);\nnummod: 13 (3), 14(4), 18 (1), 19(13), 20 (2), 26 (2), 535 (1), Eighteen (1), Nineteen (5), Two(2), one(3), two(17);\nrelcl: treated (1)\nLeft-center NYTacl:killed (1);\namod: dead (1), other (2), several (2), young (3);\ncompound: Hook (1), Uvalde (1), daughter (1), grade (1), parents (2), roll (1), school (7);\nnummod: 14 (2), 18 (1), 19 (14), 20 (3), one (1), two (12);\nposs: America (1), Her (1), my (2), our (2), your (2);\nrelcl: killed (1)\nRight-center WSJacl:celebrating (1), killed (1);\namod: former (1), other (1), small (1);\ncompound: Elementary (1), Robb (1), Trump (1), adult (1), mother (1);\nnummod: 16 (1), 17 (1), 19 (15), 20 (1), 21 (3), four (1), two (13);\nposs: her (2)\nRight FOXamod: dead (1), innocent (1), little (1), ofentry (1), old (1);\ncompound: School (1), asa (1), center (1), school (1);\nnummod: 14 (2), 18 (3), 19 (8), 4,000 (1), Two (1), eight (1), one (3), two (7);\nposs: our (3);\nrelcl: missing (1)\n13\nAEJMC, August 07\u201310, 2023, Washington, DC Ali and Hassan\nTable 5: Framing Components (with Frequencies) Used by Each News Media Outlet to Attribute the EVENT, Grouped under\nDifferent Associated Semantic Relations.\nLeft CNNadvmod: ago (1), fatally (1), least (2),\namod: 30th (2), American (2), Deadly (3), deadliest (2), deadly (2), heinous (1), horrific (1), previous (1),\nsecond (2), tragic (1);\ncompound: Hook (2), mass (5), school (10);\nnummod: 39 (2), three (1);\nrelcl: happened (1), left (4)\nLeft-center NYTadvmod: ago (3), far (1);\namod: Latest (1), deadliest (6), deadly (1), horrifying (1), immediate (1), mass (7), next (1), previous (1),\nrecent (1), reported (1), such (1);\ncompound: Buffalo (1), Newtown (1), School (2), mass (9), school (14);\nnummod: 2012 (1), 215 (1), 693 (1), two (1);\nrelcl: killed (3), say (1), took (1)\nRight-center WSJadvmod: away (2);\namod: awful (4), deadliest (1), horrific (1), latest (2), local (1), mass (2), new (2), next (1);\ncompound: Mass (1), mass (20), school (8);\nnummod: 2011 (1), claimed (1), died (1), have (1), is (1), rises (1), targeted (1), tolerated (1)\nRight FOXamod: deadliest (2), deadly (4), fourth (1), horrific (2), last (1), major (1), mass (1), recent (1), senseless (2);\ncompound: Parkland (1), Texas (1), Tuesday\u2019smass (1), mass (16), preventmass (1), school (9);\nnummod: 20 (1), 2018 (1);\nrelcl: devastated (1), had (1), happened (1), left (2)\n14", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis", "author": ["M Ali", "N Hassan"], "pub_year": "2025", "venue": "arXiv preprint arXiv:2505.15563", "abstract": "This research presents a novel approach to computational framing analysis, called Semantic  Relations-based Unsupervised Framing Analysis (SUFA). SUFA leverages semantic"}, "filled": false, "gsrank": 392, "pub_url": "https://arxiv.org/abs/2505.15563", "author_id": ["5Lh1i7UAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:3H8aN908iHwJ:scholar.google.com/&output=cite&scirp=391&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=3H8aN908iHwJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 1, "citedby_url": "/scholar?cites=8973489178345635804&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:3H8aN908iHwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2505.15563"}}, {"title": "Analysis of Propaganda in Tweets From Politically Biased Sources", "year": "2025", "pdf_data": "ANALYSIS OF PROPAGANDA IN TWEETS FROM POLITICALLY BIASED SOURCES\nVIVEK SHARMA1, MOHAMMAD MAHDI SHOKRI1, SARAH ITA LEVITAN2,1, ELENA FILATOV A3,1, SHWETA\nJAIN4,1\n1THE GRADUATE CENTER, CUNY {VSHARMA,MSHOKRI }@GRADCENTER.CUNY.EDU\n2HUNTER COLLEGE, CUNY SARAH.LEVITAN@HUNTER.CUNY.EDU\n3NEW YORK CITY COLLEGE OF TECHNOLOGY , CUNY EFILATOVA@CITYTECH.CUNY.EDU\n4JOHN JAY COLLEGE OF CRIMINAL JUSTICE, CUNY SJAIN@JJAY.CUNY.EDU\nABSTRACT . News outlets are well known to have political associations, and many national outlets culti-\nvate political biases to cater to different audiences. Journalists working for these news outlets have a big\nimpact on the stories they cover. In this work, we present a methodology to analyze the role of journal-\nists, affiliated with popular news outlets, in propagating their bias using some form of propaganda-like\nlanguage. We introduce JMBX(Journalist Media Bias on X), a systematically collected and annotated\ndataset of 1874 tweets from Twitter (now known as X). These tweets are authored by popular journalists\nfrom 10 news outlets whose political biases range from extreme left to extreme right. We extract several\ninsights from the data and conclude that journalists who are affiliated with outlets with extreme biases are\nmore likely to use propaganda-like language in their writings compared to those who are affiliated with\noutlets with mild political leans. We compare eight different Large Language Models (LLM) by OpenAI\nand Google. We find that LLMs generally performs better when detecting propaganda in social media\nand news article compared to BERT-based model which is fine-tuned for propaganda detection. While the\nperformance improvements of using large language models (LLMs) are significant, they come at a notable\nmonetary and environmental cost. This study provides an analysis of both the financial costs, based on\ntoken usage, and the environmental impact, utilizing tools that estimate carbon emissions associated with\nLLM operations.\nIntroduction\nAs defined by Barron et al.Barr \u00b4on-Cedeno et al. 2019 and Da San Martino et al. Da San Martino et al.\n2020, propaganda involves the deliberate expression of opinion with the intent to influence the opinion\nor to invoke some action. In recent years, the use of social media platforms to spread propaganda and\nmisinformation has become increasingly prevalent. According to a 2021 StatistaStatista 2021, identified\nstate actors spreading propaganda and misinformation increased to 81 from 28 in 2017. Propaganda in\nsocial media is not limited to state actors. In fact, news outlets often utilize some form of propaganda to\nreach their audience by slanting their report toward the consumers\u2019 expectations, also known as media\nbias Gentzkow and Shapiro 2006. A study by Baron Baron 2006 shows that there is an established\narrangement between the media house and the journalist. The study presents a theory that journalists\ncan deliberately express biased opinions in their stories to advance their career prospects and news\noutlets choose to be biased to boost their profits. Paul et al. Paul and Elder 2006 point out that it is often\nnot up to journalists to determine what their reader wants to read. Instead, it is the public who wants\ntheir belief extolled and confirmed. Media bias affects public opinion causing polarization.\n1arXiv:2507.08169v1  [cs.SI]  10 Jul 2025\n2 2 INTRODUCTION\nNews outlets and the journalists associated with them often interact with the public through social\nmedia. The micro-blogging platform, X (formerly Twitter), is a popular medium of such communi-\ncation which helps news outlets and their affiliates engage directly with their readers. According to a\nsurvey conducted in 2021 by Pew Research Center 2022 seven in ten journalists prefer Twitter for their\nwork-related communications and 79% of them believe that social media help them to better engage\nwith their audience. A study of 22,000 tweets conducted in 2011 by Lasorsa et al. Lasorsa, Lewis,\nand Holton 2012 shows that journalists freely express their opinions on the X microblogging platform.\nThis study highlights that engagement with social media followers promotes \u201cend-user journalism\u201d.\nThe extent of the end-user journalism is evident from the results presented in the study by Noguera et\nal Noguera-Vivo 2013. This study points out that 5% of the tweets directly request information from\nthe followers, 27% are direct replies to the followers and 32% of the tweets contain links to sources that\nare more often external to the news outlet.\nIn Section 3 we introduce a publicly available dataset, JMBX1, that contains 1,874 annotated tweets\nfrom several news outlets. These tweets are labeled as either \u201cpropaganda\u201d (containing a certain type\nof propaganda technique) or \u201cnon propaganda\u201d. Given this annotation, we explore the relationship\nbetween propaganda and the bias of the affiliated news outlet.\nIn Section 4 we present experiments using a fine-tuned BERT model and eight different Large Lan-\nguage Models (LLMs) on the task of propaganda detection. Our findings indicate that LLMs outperform\nthe BERT model, with further improvements observed when employing the Chain of Thought prompt-\ning technique Wei et al. 2022 in the data set.\nIn Sections 5, we provide an estimate of environmental impact in running LLMs for propaganda\ndetection offering a holistic evaluation of the study\u2019s implications.\nThus, we introduce a novel dataset for propaganda detection and answer the following research\nquestions.\nRQ1: How frequently do journalists from news outlets with varying degrees of known biases (left,\nright, or center) exhibit characteristics indicative of propaganda in their tweets, and are those affiliated\nwith organizations that have extreme biases more likely to use propaganda compared to their counter-\nparts in moderately biased organizations?\nRQ2: Can Large Language Models (LLM) be used to detect propaganda in text? How does the\nperformance of LLM compare with the performance of BERT model fine-tuned to detect propaganda.\nFurthermore, do prompt engineering techniques help improve performance of LLM in detecting propa-\nganda?\nRQ3: What is the environmental cost of using LLMs to detect propaganda?\nFIGURE 1. A sample of the JMBX dataset.\n1https://figshare.com/s/349c826391f77c0a4899\n3\nTheoretical Background\nIn 1939, social scientists Alfred and Elizabeth Lee described seven propaganda techniques in their\nbook \u201cThe Fine Art of Propaganda\u201d Lee and Lee 1939. More recently, Da San Martino et al. Martino\net al. 2020b defines 18 propaganda techniques that are found in digital media. The most frequently\nused propaganda techniques are: loaded language, name calling, repetition, and slogans Martino et al.\n2020a. Other propaganda techniques include: doubt, appeal to fear, flag-waving, bandwagon, reduc-\ntion ad hitlerum, causal oversimplification, black-and-white fallacy, whataboutism, thought terminating\ncliches, and, exaggeration or minimization. According to Huang et al. Huang et al. 2022, people often\nuse appeal to authority as a propaganda technique. Huang et al. use this technique in their generative AI\nmodel which generates synthetic texts closely resembling examples of human-written disinformation.\nAmong the less frequently used propaganda techniques are: strawman, red herring, and obfuscation Yu\net al. 2021.\nResearchers have created several datasets to study text-based propaganda. These datasets contain\nnews articles, social media blogs and limited-length microblogs. Some datasets are topical such as the\nCOVID-19 pandemic Naseem et al. 2021 Memon and Carley 2020, the UK General elections Nizzoli\net al. 2021, and the Russia-Ukraine war Haq et al. 2022.\nPTC (Propaganda Technique Corpus) Da San Martino et al. 2019 dataset contains 550 articles anno-\ntated with 18 propaganda techniques. These articles are extracted from news sources of various political\nbias determined by Media Bias Fact Check (MBFC), an independent website that relies on human eval-\nuators and a methodical approach Check 2024 to determine the bias of media sources. This data set\nis suitable for training and testing natural language processing models that perform both fragment and\nsentence level classifications as well as span identification and identifying the propaganda technique.\nQCRI\u2019s propaganda corpus Barr \u00b4on-Cedeno et al. 2019 contains 51.3K articles from 104 news sources\nthat appeared between October 2017 and December 2018. The articles are classified as propaganda or\ntrustworthy. All articles from a news outlet are labeled based on their bias level (left, right, center)\nreported on MBFC. A total of 94 news sources are considered as sources for trustworthy articles while\n10 sources are used for articles that contained propaganda. The following information is recorded for\neach article: title, text, average sentiment, publication date, and official source name. Geographical\ninformation is added to the dataset with the help of data made available by the Global Database of\nEvents, Language and Tone Project (GDELT) Leetaru and Schrodt 2013.\nThe TWEETSPIN dataset Vijayaraghavan and V osoughi 2022 contains 210,392 tweets in the English\nlanguage. All tweets in the dataset have at least one reply calling out the tweet with propaganda along\nwith the technique of propaganda used. Currently, this dataset is not publicly available.\nRecently researchers explore the use of LLMs as a tool to classify text and draw insights. LLMs\nuse large amounts of training data and the power of transformers to learn relations between sentences\nand predict the next sentence, generating highly accurate pieces of text. Consequently, researchers\nexperiment with using LLMs to detect bias in text Lin et al. 2024; Fan et al. 2024, identifying subjective\nlanguage Shokri et al. 2024; Suwaileh et al. 2024, and detecting fake news Liu et al. 2024. Another\nresearch direction deals with various prompt engineering techniques Wei et al. 2022; Zhang et al. 2022;\nBrown 2020 and evaluation of the performance of LLMs as a classification tool compared to traditional\nNatural Language Models such as BERT. This is a paradigm shift from using models trained to perform\na specialized task to using a generalized model in a variety of classification tasks. Jones et al. Jones 2024\nused GPT 3.5 turbo to detect propaganda in SemEval-2020 Task 11 dataset, which is also known as PTC\ndataset. Sprenkamp Sprenkamp, Jones, and Zavolokina 2023 extend this approach by experimenting\nwith five different GPT-3 and GPT-4 models. However, these studies are limited to news articles and\n4 3 OVERVIEW OF THE JMBX DATASET\nuse an LLM from a single provider. With the introduction of Google\u2019s Gemini models, competition\nin the LLM market has increased. Therefore, it is worthwhile to compare the performance of LLMs\nagainst each other. In our study, we introduce a new social media sourced dataset JMBX and evaluate\neight LLM models, including five from OpenAI\u2019s GPT series and three from Google\u2019s Gemini. To the\nbest of our knowledge, this is the largest known comparison of models in this domain. We measure\nthe performance of these models in detecting propaganda in news articles and social media microblogs.\nAdditionally, we provide an estimate of the carbon footprint of any product that could be based on this\nresearch.\nOverview of the JMBX Dataset\nThe microblogging site X, formerly known as Twitter, provides access to APIs that researchers can\nuse to curate tweets and their replies for social media analysis. In this paper, our goal is to demonstrate\na methodical approach to extract tweets by journalists who are affiliated with news organizations that\nare known to have certain political biases. Using this dataset we analyze the prevalence of propaganda\nlanguage in the tweets posted by authors affiliated with biased news outlets.\nThe dataset consists of 1874 annotated tweets from journalists affiliated with 10 news outlets. The\ndata was downloaded from Twitter between September 27, 2022 and October 3, 2022, using the Twitter\nStreaming API. Each record contains the tweet id, number of likes, retweet count, retweeted status. The\nlast column contains the label, which is the propaganda technique used in the tweet. The tweet text is\nredacted to comply with twitter\u2019s data sharing policy. In addition to this, each record has a bias column\nwith values left, right, lean right, lean left, and center labeled through distant supervision as per the\nratings on AllSides Media Bias.2\n3.1 Data Collection Methodology\nAllSides Media Bias is an independent, multi-partisan agency that uses multi-partisan editorial re-\nviews by trained experts and Blind Bias Surveys by readers to assign political lean (left, lean left, center,\nlean right, right) to news outlets. AllSides describes a transparent mechanism for generating these rat-\nings which incorporates community feedback where the general public can agree or disagree with the\nratings. While the community feedback does not change the original bias rating, it helps to confirm\nor refute the ratings based on public opinion. The community feedback is a 8-point Likert scale from\n\u201cAbsolutely agree\u201d to \u201cAbsolutely Disagree\u201d. Figure 2 shows a sample screenshot.\nWe used the bias ratings from AllSides to begin collecting our data. First, we select news outlets\nwhose bias ratings received a majority of \u201cAbsolutely agree\u201d, \u201cStrongly agree\u201d and \u201cAgree\u201d ratings\nfrom the public. Next, we select news outlets with the highest number of followers on Twitter as this\nnumber is a well known measure of influence in a social network Kim 2020. The following 10 news\noutlets are the result of the above filtering procedure. The results are as of September 2022 from each\nbias category, as reported on AllSides Media Bias RatingTM.\n\u2022Left: MSNBC, The New Yorker\n\u2022Lean left: ABC News, The Guardian\n\u2022Center: Forbes, Reuters\n\u2022Lean right: The New York Post, The Epoch Times\n\u2022Right: Breibart News, The Daily Wire\nWe performed a keyword search to find the profiles of journalists affiliated with each outlet by using\nthe news outlet\u2019s official name as the keyword. In this work, we assume that a journalist associated with\n2https://www.allsides.com/media-bias/ratings\n3.2 Annotation of the JMBX Dataset 5\nFIGURE 2. Sample ratings from Allsides media bias.\na particular news organization is aligned with the political beliefs of that organization. The criteria used\nto select the journalists associated with the aforementioned news outlets are:\n\u2022The profile must have had some activity in the past three months.\n\u2022The journalist\u2019s bio must contain the name of the news outlet they are associated with.\n\u2022Journalists who covered political news are prioritized over sports, lifestyle, and travel journal-\nists.\n\u2022The journalist have the Twitter legacy verified checkmark at the time of data collection. (This\ndata was collected before the checkmark\u2019s became available for purchase.)\nUsing the above methodology, five journalists from each selected news outlet, who have the highest\nnumber of followers among their peers affiliated with the same outlet, are chosen with the exception of\nthe news outlets considered centrist i.e., Forbes and Reuters. Twitter searches for journalists affiliated\nwith Forbes and Reuters do not provide any results that match the above criteria. Therefore, instead of\nindividual journalists, the official Twitter handle of Reuters and Forbes are used to collect tweets and\nare labeled as political center. We use Twitter Streaming API to obtain 1,500 most recent tweets by\neach journalist. For Reuters and Forbes, we collect 5,000 most recent tweets from the official Twitter\nhandles. Data is cleaned by removing URLs, mention (@) symbols, and some tweets that abruptly\nended with \u201c...\u201d. To focus solely on text, we remove emojis.\n3.2 Annotation of the JMBX Dataset\nWe use the annotation services provided by A Data Pro3, the organization that annotated the Se-\nmEval 2020 dataset which is widely used by researchers in the domain of text-based propaganda de-\ntection. The dataset comprises a balanced set of 2000 tweets, each with an equal number of instances\nfeaturing positive and negative sentiment scores. The annotation process follows the guidelines pro-\nvided by Martino et al. Martino et al. 2020a. Two annotators and one consolidator, who serves as the\nsubject matter expert, are employed to classify the dataset at a fine-grained level, providing each tweet\nwith a label from the 18 propaganda techniques Martino et al. 2020a. If any strategy from the list pre-\ndefined propaganda strategies is detected in a tweet then the annotators label the tweet as propaganda ,\n3https://adata.pro\n6 3 OVERVIEW OF THE JMBX DATASET\nFIGURE 3. Propaganda in each bias category\notherwise it is labeled non-propaganda . If the two independently and asynchronously-working annota-\ntors agree, then their label is used as the final label for the tweet. If the two annotators disagree then the\nlabel provided by the consolidator is used as the final label. The inter-rater agreement on this labeling\ntask is found to be substantial, with a Cohen\u2019s Kappa coefficient of 0.79. To resolve any discrepan-\ncies, a consolidator reviewed the annotations and facilitated discussions with the annotators to achieve\nconsensus on all entries. After removing duplicates and incomplete or meaningless entries, the final\nannotated dataset comprised 1,874 tweets.\n3.3 Initial Insights from the JMBX Dataset\nFigure 3 demonstrates that tweets labeled as non-propaganda are most prevalent in the center bias\ncategory, which aligns with expectations given that many of these tweets originate from centrist out-\nlets. In contrast, tweets from sources with extreme bias exhibit a higher proportion of propaganda as\ncompared to non-propaganda.\nWe conduct a sentiment analysis of the tweets using the TextBlob package, which assigns each tweet\na continuous sentiment score ranging from -1 to 1. Tweets with negative sentiment are assigned values\nbetween -1 and -0.33, while positive sentiment tweets are assigned values between 0.34 and 1. Neutral\nsentiment is defined by values between -0.32 and 0.33. Figure 4 illustrates the percentage distribution\nof tweets across different sentiment values (negative, neutral, positive) for different bias categories.\nThe fourth pie chart shows the overall distribution of tweets across bias categories. The fourth chart\nshows that in the dataset, 19.5% of tweets are from outlets with left and right biases, 22% and 21%\nrespectively from lean left and lean right, and 18% from centrist outlets. The most interesting insights\nfrom this figure is that the tweets with neutral sentiments are posted exclusively by the centrist outlets.\nTweets posted by journalists affiliated with left and right biased outlets tend to carry positive sentiments\n4.1 Experiment 1: BERT model 7\nmore often than negative sentiments while the reverse is found for those with lean left and lean right\nbiases.\nFIGURE 4. Sentiments vs Political Bias in JMBX dataset\nWe present the frequency distribution of various propaganda techniques in the annotated dataset in\nFigure 5. The results indicate that loaded language is the most commonly used propaganda technique,\nappearing in 48% of the tweets containing propaganda. Exaggeration or minimization is the second\nmost common technique, found in 21% of the tweets, while name calling or labeling is the third most\nfrequent, present in 9% of the tweets.\nExperiments and Results\nWe analyze a sample of 200 tweets to evaluate the performance of various LLM models using differ-\nent prompts. The sample under analysis includes 100 propaganda and 100 non-propaganda tweets. The\nsample 100 propaganda tweets follow the propaganda type distribution in the corpus (see Figure 5).\nWe run two sets of experiments. Within one set of experiments (Experiment 1) we evaluate the per-\nformance of the the trained BERT model on PTC and JMBX dataset. Within the other set of experiments\n(Experiment 2) we compare the outputs of eight LLMs on same datasets.\n4.1 Experiment 1: BERT model\nWe use Purdue Anvil GPU system hosted by RCAC4Song et al. 2022 utilizing a 3rd Gen AMD\nEPYCTM7763 CPU and NVIDIA A100 GPU for this experiment. We fine-tune the pre-trained BERT\nuncased model5on the PTC dataset Martino et al. 2020a, which is widely used for detecting propaganda\nin news articles. The data is split with stratified technique for 70-10-20 train, validation, and test\ndistributions.\nTable 1 contains the precision, recall, and F1-score for the classification task on both the PTC\nand JMBX datasets. With default hyperparameters, employing the Adam optimizer and binary cross-\nentropy as the loss function, the BERT-base model achieves an F1-score of 0.71 on the PTC test set.\nOn the JMBX dataset, the model yields an F1-score of 0.62. Both experiments are conducted with the\nPTC dataset as the training set, utilizing 10 epochs and 7 different random seeds. Additionally, a default\nhyperparameterized RoBERTa model Liu et al. 2019 is trained but it achieves a lower F1-score (0.66)\ncompared to the BERT-base model.\n4https://www.rcac.purdue.edu/\n5https://www.kaggle.com/models\n8 4 EXPERIMENTS AND RESULTS\nFIGURE 5. Propaganda types in annotated JMBX\nDataset Labels P/R/F F1(avg.)\nPTC0 0.72/0.69/0.700.711 0.70/0.73/0.71\nJMBX0 0.60/0.84/0.700.621 0.73/0.40/0.54\nTABLE 1. Performance of the BERT-base-uncased model on PTC and JMBX dataset.\n0 represents \u201cnon propaganda\u201d while 1 represents \u201cpropaganda\u201d\n4.2 Experiment 2: Large Language Model\nWe perform Zero-Shot prompting Radford et al. 2019 on a sample of 200 tweets from the annotated\ndataset. Eight different Large Language Models from two most popular LLM providers, OpenAI and\nGoogle, are used. Five latest models from OpenAI are chosen namely: GPT 3.5 turbo, GPT 4, GPT\n4 turbo, GPT 4o, GPT 4o-mini. Three models are selected from Google, Gemini 1 pro, Gemini 1.5\npro, Gemini 1.5 flash. As of August 2024, these are the latest models provided by these organizations.\n4.2 Experiment 2: Large Language Model 9\nTo the best of our knowledge, this is the first study that includes Google Gemini in the propaganda\ndetection task while earlier studies were performed only on OpenAI\u2019s ChatGPT.\nExperiment 2A: The experiment relies on the Large Language Model\u2019s definition of propaganda.\nExperiment 2B: This experiment includes the definitions of 18 propaganda techniques used by Mar-\ntino et al. 2020a in the prompt. The LLM is asked to output \u201cpropaganda\u201d if at least one of the propa-\nganda technique is found in the tweet, otherwise the LLM outputs the \u201cnon- propaganda\u201d label. The\nLLM can output \u201cnot sure\u201d if it is unable to perform the classification.\nLLM Model 2A 2B\nP/R/F P/R/F\nGPT3.5 .70/.56/.61 .75/.57/.63\n40613 .74/.74/.74 .79/.79/.78\n4 turbo .71/.69/.70 .73/.72/.72\n4o .79/.47/.59 .79/.59/.67\n4o mini .76/.56/.64 .78/.69/.73\nGemini1 pro .68/.57/.62 .71/.69/.69\n1.5 Pro .72/.54/.57 .77/.56/.63\n1.5 Flash .69/.59/.63 .70/.69/.69\nTABLE 2. Performance of LLMs on PTC news dataset\nLLM Model 2A 2B\nP/R/F P/R/F\nGPT3.5 .68/.41/.51 .71/.48/.57\n40613 .74/.64/.60 .78/.71/.69\n4 turbo .72/.61/.58 .74/.66/.63\n4o .80/.45/.53 .80/.56/.64\n4o mini .72/.50/.53 .76/.61/.63\nGemini1 pro .71/.53/.54 .71/.64/.61\n1.5 Pro .70/.52/.59 .79/.51/.61\n1.5 Flash .69/.57/.62 .74/.68/.67\nTABLE 3. Performance of LLMs on JMBX dataset\nFigure 6 shows the average number of \u201cnot sure\u201d returned by the models in experiment 2B. Results\npresented in Table 1 show that adding definition of propaganda increases the performance on all LLMs.\nExperiment 2C: In experiment 2C, we use Chain of Thought (CoT) Wei et al. 2022 prompting tech-\nnique. The LLMs are prompted with the definition of propaganda techniques similar to Experiment 2B\nwith an additional \u201cthink step by step\u201d type strategy at the end. We select two best performing models\nfrom each organization that produced fewer instances of \u201cnot sure\u201d classifications when categorizing\ntweets. As shown in Table 4, the recall and F-score increased on the JMBX dataset with the use of CoT\nprompting. However, this improvement is not observed in the PTC dataset. Notably, for the Gemini 1.5\nFlash model, CoT prompting yields improved performance on both the datasets.\n10 6 EXPERIMENTS AND RESULTS\nFIGURE 6. Number of \u201dnot sure\u201d output by various LLMs on experiment 2B.\nModel PTC JMBX\nGPT 4 0613 .77/.77/.76 .75/.73/.73\nGemini 1.5 flash .76/.73/.72 .73/.73/.73\nTABLE 4. Results of Experiment 2C on GPT 4 and Gemini 1.5 models\nEnvironmental Impact\nWe estimate the carbon footprint of this research and of any product that utilizes the techniques we\npropose. This research tasks involves classifying 200 tweets with prompts to LLM, averaging runtime\nto 4 minutes per task. Assuming the task ran on GPT-3/4 models hosted on Microsoft Azure servers\n(utilizing a single Nvidia A100 GPU), for a total of 2 hours (4 minutes per model, 5 models, 3 runs,\n2 datasets), the estimated carbon emission was 0.28 kg, based on the mlCO2 calculator by Lacoste\net.al. Lacoste et al. 2019. Similarly, for the Gemini model, hosted on Google Cloud Platform, with a\nruntime of 1.2 hours (4 minutes per model, 3 models, 3 runs, 2 datasets), the estimated carbon emission\nwas 0.11 kg. The total emission for this research is 0.39 kg.\nSince the mlCO2 calculator does not factor in the Power Usage Effectiveness (PUE) of data cen-\nters, we apply an average PUE of 1.12, based on recent studies Faiz et al. 2023, and reports from\nGoogle Google 2024 and Microsoft Azure 2024, which adjusts the total carbon emission to 0.44 kg.\n11\nWhile this value might seem negligible, according to the EPA calculator Environmental Protection\nAgency 2024, it is roughly equivalent to driving a car for a mile, or charging 29 smartphones.\nConclusion & Future work\nWe present an annotated dataset containing tweets posted by highly followed journalists and insights\ninto the relationship between the propaganda in their tweets and the political bias of their affiliation. We\nfine-tune a BERT base model on a well-known propaganda dataset, as well as use zero-shot and CoT\nLLM prompting techniques to measure propaganda detection by eight LLM models on these datasets.\nOur primary insight in this work is that journalists affiliated with extremely biased news outlets tend\nto use more propaganda in their writings than those affiliated with moderately biased organizations.\nWe also report that zero-shot prompting on LLMs shows better performance in detecting propaganda\nthan the BERT model, and with Chain of Thought prompting, the performance is further improved.\nWe estimate the environmental impact of using LLMs in this research. Future research will focus\non evaluating the performance of large language models in the fine-grained detection of individual\npropaganda techniques.\nLimitations & Discussion\nWe recognize that there are limitations to this research due to various issues related to data collection\nand data sharing. Even with paid subscription, the number of tweets one can retrieve using the API is\nlimited. Additionally, the tweets classified under the \u201dcenter\u201d category are sourced from official media\naccounts, which complicates direct comparison with the personalized tweets from journalists associated\nwith biased media outlets. Another limitation involves the environmental impact estimates. These esti-\nmates are derived from related studies, online reports, and publicly available tools designed to calculate\nemissions and energy consumption. However, these sources acknowledge a degree of inaccuracy in\ntheir results, as various factors, such as data center efficiency and hardware specifications, can influence\nthe final calculations.\nEthical Considerations\nThis study addresses several ethical considerations especially when dealing with data from social\nmedia platforms. To mitigate potential privacy violations, we anonymized all user data and ensured\nthat personally identifiable information was not included by redacting journalist\u2019s name, their affilia-\ntion, their meta information in the dataset. Additionally, the potential biases due to selection of certain\njournalists in data must be acknowledged. To address this, we ensured a balanced representation of\nperspectives within the dataset. However, we recognize that no dataset or model is entirely free of bias,\nand thus our findings should be interpreted with caution. Another critical aspect is the ethical implica-\ntions of propaganda detection. Identifying and labeling content as propaganda could have significant\nsocietal impacts, including influencing public perception and discourse. Therefore, we included sub-\nject matter experts to understand nuanced interpretations of the content. Furthermore, we emphasize\ntransparency in the model\u2019s decision-making process and make the dataset publicly available, ensuring\nthat the detection results can be replicated, scrutinized and understood by stakeholders. Finally, energy\n12 8 ETHICAL CONSIDERATIONS\nconsumption and environmental impact were considered throughout the research. Training LLMs are\ncomputationally intensive and contributes to carbon emissions Strubell, Ganesh, and McCallum 2020.\nWe aimed to mitigate this by being aware and optimal use of Large Language Model and sampling a\nsubset of dataset in our experiments. Future research should continue exploring greener alternatives for\nmodel training and deployment.\nReferences\nAzure, Microsoft (2024). Microsoft Azure PUE, WUE .https://azure.microsoft.com/en-\nus/blog/how-microsoft-measures-datacenter-water-and-energy-use-\nto-improve-azure-cloud-sustainability/ [Accessed: (09/3/24)].\nBaron, David P (2006). \u201cPersistent media bias\u201d. In: Journal of Public Economics 90.1-2, pp. 1\u201336.\nBarr\u00b4on-Cedeno, Alberto et al. (2019). \u201cProppy: Organizing the news based on their propagandistic\ncontent\u201d. In: Information Processing & Management 56.5, pp. 1849\u20131864.\nBrown, Tom B (2020). \u201cLanguage models are few-shot learners\u201d. In: arXiv preprint arXiv:2005.14165 .\nCenter, Pew Research (2022). Twitter is the go-to social media site for U.S. journalists, but not for the\npublic . Accessed: 1/26/25. URL:https : / / www . pewresearch . org / short - reads /\n2022 / 06 / 27 / twitter - is - the - go - to - social - media - site - for - u - s -\njournalists-but-not-for-the-public/ .\nCheck, Media Bias Fact (2024). Methodology . Accessed: 1/26/25. URL:https://mediabiasfactcheck.\ncom/methodology/ .\nDa San Martino, Giovanni et al. (2019). \u201cFine-grained analysis of propaganda in news article\u201d. In:\nProceedings of the 2019 conference on empirical methods in natural language processing and the\n9th international joint conference on natural language processing (EMNLP-IJCNLP) , pp. 5636\u2013\n5646.\nDa San Martino, Giovanni et al. (2020). \u201cPrta: A system to support the analysis of propaganda tech-\nniques in the news\u201d. In: Proceedings of the 58th Annual Meeting of the Association for Computa-\ntional Linguistics: System Demonstrations , pp. 287\u2013293.\nEnvironmental Protection Agency (2024). EPA calculator .https://www.epa.gov/energy/\ngreenhouse-gas-equivalencies-calculator [Accessed: (09/3/24)].\nFaiz, Ahmad et al. (2023). \u201cLlmcarbon: Modeling the end-to-end carbon footprint of large language\nmodels\u201d. In: arXiv preprint arXiv:2309.14393 .\nFan, Zhiting et al. (2024). \u201cBiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\u201d. In:\narXiv preprint arXiv:2407.10241 .\nGentzkow, Matthew and Jesse M Shapiro (2006). \u201cMedia bias and reputation\u201d. In: Journal of political\nEconomy 114.2, pp. 280\u2013316.\nGoogle (2024). Google Datacenter Efficiency .https://www.google.com/about/datacenters/\nefficiency/ [Accessed: (09/3/24)].\nHaq, Ehsan-Ul et al. (2022). \u201cTwitter dataset for 2022 russo-ukrainian crisis\u201d. In: arXiv preprint arXiv:2203.02955 .\nHuang, Kung-Hsiang et al. (2022). \u201cFaking Fake News for Real Fake News Detection: Propaganda-\nloaded Training Data Generation\u201d. In: arXiv preprint arXiv:2203.05386 .\nJones, Daniel Gordon (2024). \u201cDetecting propaganda in news articles using large language models\u201d. In:\nEng. Open Access 2, pp. 1\u201312.\nKim, Rae Yule (2020). \u201cThe value of followers on social media\u201d. In: IEEE Engineering Management\nReview 48.2, pp. 173\u2013183.\nLacoste, Alexandre et al. (2019). \u201cQuantifying the carbon emissions of machine learning\u201d. In: arXiv\npreprint arXiv:1910.09700 .\nREFERENCES 13\nLasorsa, Dominic L, Seth C Lewis, and Avery E Holton (2012). \u201cNormalizing Twitter: Journalism\npractice in an emerging communication space\u201d. In: Journalism studies 13.1, pp. 19\u201336.\nLee, Alfred and Elizabeth Briant Lee (1939). \u201cThe fine art of propaganda.\u201d In.\nLeetaru, Kalev and Philip A Schrodt (2013). \u201cGdelt: Global data on events, location, and tone, 1979\u2013\n2012\u201d. In: ISA annual convention . V ol. 2. 4. Citeseer, pp. 1\u201349.\nLin, Luyang et al. (2024). \u201cInvestigating Bias in LLM-Based Bias Detection: Disparities between LLMs\nand Human Perception\u201d. In: arXiv preprint arXiv:2403.14896 .\nLiu, Ye et al. (2024). \u201cDetect, Investigate, Judge and Determine: A Novel LLM-based Framework for\nFew-shot Fake News Detection\u201d. In: arXiv preprint arXiv:2407.08952 .\nLiu, Yinhan et al. (2019). \u201cRoberta: A robustly optimized bert pretraining approach\u201d. In: arXiv preprint\narXiv:1907.11692 .\nMartino, G et al. (2020a). \u201cSemEval-2020 task 11: Detection of propaganda techniques in news arti-\ncles\u201d. In: arXiv preprint arXiv:2009.02696 .\nMartino, Giovanni Da San et al. (2020b). \u201cA survey on computational propaganda detection\u201d. In: arXiv\npreprint arXiv:2007.08024 .\nMemon, Shahan Ali and Kathleen M Carley (2020). \u201cCharacterizing covid-19 misinformation commu-\nnities using a novel twitter dataset\u201d. In: arXiv preprint arXiv:2008.00791 .\nNaseem, Usman et al. (2021). \u201cCOVIDSenti: A large-scale benchmark Twitter data set for COVID-19\nsentiment analysis\u201d. In: IEEE transactions on computational social systems 8.4, pp. 1003\u20131015.\nNizzoli, Leonardo et al. (2021). \u201cCoordinated behavior on social media in 2019 UK general election\u201d.\nIn:Proceedings of the International AAAI Conference on Web and Social Media . V ol. 15, pp. 443\u2013\n454.\nNoguera-Vivo, Jos \u00b4e Manuel (2013). \u201cHow open are journalists on Twitter? Trends towards the end-user\njournalism\u201d. In.\nPaul, Richard and Linda Elder (2006). \u201cHow to detect media bias & propaganda\u201d. In: Dillon Beach,\nCA: Foundation for Critical Thinking .\nRadford, Alec et al. (2019). \u201cLanguage models are unsupervised multitask learners\u201d. In: OpenAI blog\n1.8, p. 9.\nShokri, Mohammad et al. (Aug. 2024). \u201cSubjectivity Detection in English News using Large Language\nModels\u201d. In: Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sen-\ntiment, & Social Media Analysis . Association for Computational Linguistics.\nSong, X Carol et al. (2022). \u201cAnvil-System Architecture and Experiences from Deployment and Early\nUser Operations\u201d. In: Practice and Experience in Advanced Research Computing , pp. 1\u20139.\nSprenkamp, Kilian, Daniel Gordon Jones, and Liudmila Zavolokina (2023). \u201cLarge language models\nfor propaganda detection\u201d. In: arXiv preprint arXiv:2310.06422 .\nStatista (2021). Number of countries with evidence of using social media to spread computational pro-\npaganda and disinformation about politics from 2017 to 2020 . Accessed: 1/26/25. URL:https:\n/ / www . statista . com / statistics / 1023881 / organized - social - media -\nmanipulation-campaigns-worldwide/ .\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum (2020). \u201cEnergy and policy considerations for\nmodern deep learning research\u201d. In: Proceedings of the AAAI conference on artificial intelligence .\nV ol. 34. 09, pp. 13693\u201313696.\nSuwaileh, Reem et al. (2024). \u201cThatiAR: Subjectivity Detection in Arabic News Sentences\u201d. In: arXiv\npreprint arXiv:2406.05559 .\nVijayaraghavan, Prashanth and Soroush V osoughi (2022). \u201cTWEETSPIN: Fine-grained propaganda de-\ntection in social media using multi-view representations\u201d. In: Proceedings of the 2022 Conference\n14 REFERENCES\nof the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies , pp. 3433\u20133448.\nWei, Jason et al. (2022). \u201cChain-of-thought prompting elicits reasoning in large language models\u201d. In:\nAdvances in neural information processing systems 35, pp. 24824\u201324837.\nYu, Seunghak et al. (2021). \u201cInterpretable propaganda detection in news articles\u201d. In: arXiv preprint\narXiv:2108.12802 .\nZhang, Zhuosheng et al. (2022). \u201cAutomatic chain of thought prompting in large language models\u201d. In:\narXiv preprint arXiv:2210.03493 .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Analysis of Propaganda in Tweets From Politically Biased Sources", "author": ["V Sharma", "MM Shokri", "SI Levitan", "E Filatova"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "News outlets are well known to have political associations, and many national outlets cultivate  political biases to cater to different audiences. Journalists working for these news outlets"}, "filled": false, "gsrank": 393, "pub_url": "https://arxiv.org/abs/2507.08169", "author_id": ["MXG4VgcAAAAJ", "o0OKC_oAAAAJ", "-U_XtWsAAAAJ", "NeOqk2kAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:e0Rd8bJi7iMJ:scholar.google.com/&output=cite&scirp=392&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=e0Rd8bJi7iMJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:e0Rd8bJi7iMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2507.08169"}}, {"title": "SciLander: Mapping the scientific news landscape", "year": "2023", "pdf_data": "SciLander: Mapping the Scientific News Landscape\nMaur\u00edcio Gruppi1, Panayiotis Smeros2, Sibel Adal\u01311, Carlos Castillo3, Karl Aberer2\n1Rensselaer Polytechnic Institute, USA\n2\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland\n3Universitat Pompeu Fabra, Spain\ngouvem@rpi.edu, panayiotis.smeros@epfl.ch, adalis@cs.rpi.edu, chato@acm.org, karl.aberer@epfl.ch\nAbstract\nThe COVID-19 pandemic has fueled the spread of misinfor-\nmation on social media and the Web as a whole. The phe-\nnomenon dubbed \u2018infodemic\u2019 has taken the challenges of in-\nformation veracity and trust to new heights by massively in-\ntroducing seemingly scientific and technical elements into\nmisleading content. Despite the existing body of work on\nmodeling and predicting misinformation, the coverage of\nvery complex scientific topics with inherent uncertainty and\nan evolving set of findings, such as COVID-19, provides\nmany new challenges that are not easily solved by exist-\ning tools. To address these issues, we introduce SciLander,\na method for learning representations of news sources report-\ning on science-based topics. SciLander extracts four hetero-\ngeneous indicators for the news sources; two generic indi-\ncators that capture (1) the copying of news stories between\nsources, and (2) the use of the same terms to mean different\nthings (i.e., the semantic shift of terms), and two scientific in-\ndicators that capture (1) the usage of jargon and (2) the stance\ntowards specific citations. We use these indicators as signals\nof source agreement, sampling pairs of positive (similar) and\nnegative (dissimilar) samples, and combine them in a unified\nframework to train unsupervised news source embeddings\nwith a triplet margin loss objective. We evaluate our method\non a novel COVID-19 dataset containing nearly 1M news ar-\nticles from 500 sources spanning a period of 18 months since\nthe beginning of the pandemic in 2020. Our results show that\nthe features learned by our model outperform state-of-the-art\nbaseline methods on the task of news veracity classification.\nFurthermore, a clustering analysis suggests that the learned\nrepresentations encode information about the reliability, po-\nlitical leaning, and partisanship bias of these sources.\nIntroduction\nThe COVID-19 pandemic has resulted in a significant in-\ncrease in information production and consumption at the\nsame time. With this came a large increase in unreliable in-\nformation, dubbed \u2018infodemic\u2019 (Buchanan 2020). This in-\ncrease was also coupled with the growing scrutiny of me-\ndia sources and purposeful amplification of any errors they\nmade. As the readers sought correct, timely, and trustworthy\ninformation, many news and media sources worked hard to\ndiscredit others and create confusion (Van Bavel et al. 2020).\nCopyright \u00a9 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: Overview of SciLander, including agreement indi-\ncator extraction (\u00a7 & \u00a7), triplet sampling and unsupervised\nsource embeddings training (\u00a7), and evaluation on the down-\nstream tasks of classification and clustering (\u00a7).\nGovernments and public health agencies have the respon-\nsibility to respond to the crisis and protect the public from\nmisinformation by utilizing the power of social and news\nmedia (Castillo 2016). Yet, the same social and news media\nwork as a catalyst for the infodemic, allowing disinforma-\ntion to be dispersed on a large scale, regardless of the signif-\nicant effort to hinder its spread (McKay and Tenove 2021).\nDespite the existing body of work on modeling and pre-\ndicting misinformation, coverage of a complex scientific\ntopic with inherent uncertainty and evolving set of findings,\nsuch as COVID-19, provides many new challenges that are\nnot easily solved by existing tools (Zarocostas 2020). On\nthe article level, the evaluation of news stories may be chal-\nlenging as they may contain information that cannot be eas-\nily verified. Furthermore, many sources may not have the\nnecessary staffing for the proper communication of science-\nrelated topics, they may be known to have published incor-\nrect information, this information may also have changed\nover time, or the source may have later corrected it.\nOften, language-based methods fail in such a task because\ndifferent sources may use the same terms to mean different\nthings. Furthermore, many sources may use scientific ref-\nerences to back up their claims; however, the validity of\nthese references is not easily verifiable. Being able to map\nout the consequential and systematic patterns of behavior of\nsuch sources in terms of both content andreferences would\nProceedings of the Seventeenth International AAAI Conference on Web and Social Media (ICWSM 2023)\n269\nbe particularly useful in such scenarios (Chung, Nam, and\nStefanone 2012). It would allow sources to be compared to\nother known sources in terms of their coverage, and develop\nexplanations to the aspects in which they are similar to or\ndifferent from each other.\nTo address these challenges, we introduce a novel method\ncalled SciLander. SciLander builds on a set of novel fea-\ntures, based on the deep processing of news articles pub-\nlished by a set of sources, producing a vector representation\nof these news sources. To build this, we incorporate mea-\nsures of similarity and difference between the sources based\non their citation behavior, the republishing of articles from\neach other, and their general language usage. In particular,\nwe use the coverage of COVID-19 to show that this em-\nbedding has many desirable features that can help multiple\ndownstream tasks.\nOur Contribution. The technical contributions we intro-\nduce are the following:\n\u2022 We propose four news agreement indicators for sources:\ni) the shared content or republished articles, ii) the seman-\ntic shift of terms in the common vocabulary, iii) the usage\nof scientific jargon, and iv) the citation stance of the news\nsources (\u00a7 & \u00a7);\n\u2022 We combine these indicators in a unified framework for\ntraining unsupervised news source embeddings (\u00a7);\n\u2022 We evaluate our method using a dataset of news publi-\ncations related to COVID-19. Sources in this dataset are\nlabeled with respect to reliability and political leaning;\n\u2022 We compare our method to strong baselines on the prob-\nlem of veracity classification of news sources and show a\nsignificant gain in performance when combining the indi-\ncators proposed in this paper;\n\u2022 We test the applicability of our method in an online learn-\ning experiment, showing that it can be used to learn fea-\ntures from sources even if little data is available or if new\ncoming sources are presented in the landscape;\n\u2022 We show that the learned features encode information\nabout the sources\u2019 reliability level, partisanship bias, and\npolitical leaning through a clustering analysis experiment.\nRelated Work\nWe distinguish three levels of granularity for misinformation\nin news and social media: claims, articles, and sources. This\nis a broad research area where results are scattered through\nmultiple disciplines and venues; below we present studies\nrelevant to each of the three aforementioned levels.\nClaims & Articles Veracity. Many of the computational\nmethods for veracity assessment of news articles employ\nmachine learning techniques in supervised binary or multi-\nlabel classification settings (Baly et al. 2019; Reis et al.\n2019; Zhang et al. 2018; Yang et al. 2019; Vishwakarma,\nVarshney, and Yadav 2019). In this setting, a news article is\ngiven as the input to a model and it must predict whether the\narticle contains false information. Other studies aim at de-\ntecting the veracity of information at a more granular level\nby working with claims and rumors (Zubiaga et al. 2018;\nShaar et al. 2020; Hansen et al. 2019; Jiang et al. 2020;Smeros, Castillo, and Aberer 2021). This approach consists\nin detecting fragments of text, e.g., sentences or paragraphs,\nworthy of fact-checking. Thus, a single document or news\narticle may contain several claims, some of which may be\ninaccurate or deceiving.\nSource Veracity. Source-based approaches are holistic ap-\nproaches that evaluate the quality of a news source as a\nwhole, without focusing on individual claims or articles ex-\ntracted from it. Baly et al. (2018, 2019); Li and Goldwasser\n(2019) highlight the importance of features beyond text to\nevaluate the veracity of news sources, such as the presence\nin social media and the existence of a Wikipedia page about\na source. Furthermore, Shu, Wang, and Liu (2019) explore\nthe interactions between users, authors, and sources, while\nGruppi, Horne, and Adal\u0131 (2021) observe content sharing\ntrends among news publishers. Finally, Bourgeois, Rappaz,\nand Aberer (2018); Rappaz, Bourgeois, and Aberer (2019)\nstudy the selection bias in the topic coverage of news sources\nby exploring the co-references of these sources to the same\nnews events, while Ribeiro et al. (2018) infer the biases of\nnews sources by utilizing their advertiser insights into the\ndemographics of their social media audience.\nBoth claim- and article-level veracity assessments require\ndata labeling at a very large scale (e.g., individual claims or\narticles labeled as reliable orunreliable) and heavily rely on\ntext-specific features these short pieces of text provide. Our\napproach is, to the best of our knowledge, the first approach\nthat aggregates information about the writing style and cita-\ntion behavior of news sources to learn unsupervised source\nrepresentations, that is aware of the science-related content\npublished by them.\nCorpus\nOur study targets the reliability of sources when reporting\nnews related to science. Thus, we use a corpus of news ar-\nticles targeted on the emerging scientific topic of COVID-\n19, and a corpus of scientific references, also targeted on\nCOVID-19. We summarize the basic statistics of both cor-\npora in Table 1.\nNELA-GT-2020. The collection of news articles contains\na total of 1.78 million articles published by 519 sources\n(Gruppi, Horne, and Adali 2021). Each article in the dataset\ncontains a title, full text, name of the publishing source, and\npublication timestamp. We use a subset containing only arti-\ncles related to COVID-19, resulting in 991,116 news articles\nfrom 493sources, published over 18 months, between Jan-\nuary 1st 2020 and July 1st 2021. We obtain this subset by\napplying keyword-based filtering using the COVID-19 ter-\nminology from Shugars et al. (Shugars et al. 2021), selecting\narticles that contain at least one COVID-related keyword in\nthe title or body text.\nMedia Bias/Fact Check Labels. We retrieve labels for\nsources in the corpus from the news assessment agency Me-\ndia Bias/Fact Check1. We obtain the political leaning of\nnews sources, represented by direction (left or right) and\nmagnitude (mild, moderate, extreme). These are encoded\n1https://mediabiasfactcheck.com\n270\nNELA-GT-2020\nTotal Articles ~1.8M\nCOVID-19 Articles ~1M\nTotal Sources 493\nLabeled Sources 316\nReliable Sources 122\nUnreliable Sources 194\nPartisan Sources 162\nScientific References\nCOVID-19 Papers (CORD-19) ~300K\nScientific Domains (SciLens) ~1K\nReferences in NELA-GT-2020 ~200K\nTable 1: Summary of the used corpora. We see that more\nthan half of the articles in NELA-GT-2020 are related to the\ntopic of COVID-19. The labels for reliable, unreliable and\npartisan sources are obtained from Media Bias/Fact Check.\nas integer numbers in [\u22123,3], negative values indicate left-\nbias, positive values indicate right bias, and 0represent cen-\nter sources. Furthermore, we obtain a conspiracy-theory la-\nbel, a binary indicator denoting whether a source publishes\nconspiracy theories and/or pseudoscience content. These are\noften highly unreliable sources and may or may not exhibit\npolitical leaning. Finally, we obtain factual reporting, an in-\nteger score from 0 to 5 assigned to each source, where 0\nindicates the least credible score and 5 is the most credible\nscore. A source that constantly publishes misleading con-\ntent, fails to fact-check its publications, and does not dis-\nclose an editorial board tends to be associated with a lower\nfactual reporting score.\nBased on the factual reporting score, we divide news\nsources into two reliability classes, namely the Reliable\nNews Sources and the Uneliable News Sources. The rules\ndefining each class are described as follows:\n\u2022Reliable News Sources: sources whose factual reporting\nscore is greater than 2.\n\u2022Unreliable News Sources: sources flagged as conspiracy-\ntheory news producers or sources whose factual report-\ningscore is less than or equal to 2.\nScientific References. We enhance the news collection de-\nscribed above, by extracting the external scientific refer-\nences of news articles, i.e., the outgoing hyperlinks from\nthe main body of the news articles. We also extract the con-\ntext of each reference, i.e., the passage of the news article\nthat surrounds this reference. We consider two repositories\nof references provided by CORD-19 andSciLens.\nOne of the most prominent collection of papers related\ntoCOVID-19, consisting of peer-reviewed papers as well\nas preprints and other historical coronavirus research, is\nCORD-19 (Wang et al. 2020). We use the 2021-06-14 re-\nlease of CORD-19, which contains a total of 310,833 papers.\nThe second source of scientific references comes from\nSciLens (Smeros, Castillo, and Aberer 2019). SciLens pro-\nvides a list of the top-1000 university domains (as indi-\ncated by CWUR.org), enhanced with a manually curated list\nof open-access publishers and grey literature databases. In-\ndeed, these scientific references are more prevalent in news\nWashington PostWashington PostCharlotte ObserverCharlotte ObserverUS NewsUS NewsCBS NewsCBS NewsRaw StoryRaw Story\nVeterans TodayVeterans TodayGlobal ResearchGlobal Research\nThe Greanville PostThe Greanville PostRussophileRussophile\nBreitbartBreitbartThe Epoch TimesThe Epoch TimesWhat Really HappenedWhat Really HappenedFigure 2: Example of a subgraph of the Content Sharing Net-\nwork where nodes, representing sources, are connected by\ndirected edges denoting the direction of the copied content\nbetween sources. Node color indicates the reliability class of\nthe source (green for Reliable, purple for Unreliable), and\nedge width indicates the amount of content copied.\nthan the CORD-19 papers, because their writing style and\nterminology used is typically more oriented towards a non-\nexpert audience.\nContent Indicators\nIn this section, we introduce two content-based indicators\nthat we use to align news sources. Particularly, we introduce\nan indicator regarding the shared content and an indicator\nregarding the semantic shift of terms between sources.\nCopy Indicator\nContent Sharing Network (CSN) is a model of content repli-\ncation by sources in the news landscape. The sharing of\nnews articles has been shown to be a common factor be-\ntween news sources that adopt similar narratives around cer-\ntain topics, which also correlates with the credibility of these\nsources (Horne, N\u00f8rregaard, and Adal\u0131 2019). Figure 2 illus-\ntrates how sources are related in a CSN, where articles are\ncopied from source to source.\nThe CSN is modeled as a directed graph where nodes rep-\nresent news sources and edges indicate sources that copy\narticles verbatim from one another. Edges weights are pro-\nportional to the amount of content copied between the con-\nnected sources. The adjacency matrix Cof such network\nrepresents the affinity between the news sources. We obtain\nthis matrix using the method proposed by Horne et al. (2019)\nwhich consists of computing document vector representa-\ntions for news articles using a TF-IDF bag-of-words repre-\nsentation. Articles are considered verbatim copies of each\nother if the cosine similarity between their vectors is greater\nthan a threshold of 0.85, and the direction of the copying is\ndetermined by the publication date of the article. The sim-\nilarity threshold is defined following the recommendations\nfrom Horne, N\u00f8rregaard, and Adal\u0131 (2019).\nThe final adjacency matrix is obtained by aggregating all\ncopied articles at the source level. Thus, a directed edge from\nnode itojexists if source jcopies articles from source i.\nThe complement of the degree of relatedness distance be-\ntween sources iandj, is given as a function of the weight of\nthe edge (i, j)and is defined as:\ndcpy(i, j) = 1\u2212|Ai\u2229Aj|\n|Aj|\n271\nSource Usage\nModern Alternative\nMama{...} these specific herbs have strong\nantiviral actions, including against\nother strains of coronavirus.\nHealthy Holistic\nLiving{...} Garlic is known to have potent an-\ntibacterial, antiviral, antifungal and an-\ntiprotozoal abilities.\nThe Guardian {...} overwhelming emergency depart-\nments and causing governments to over-\nspend on antiviral medications.\nThe Washington\nPost{...} although the antiviral drug remde-\nsivir has been shown to help some pa-\ntients {...}\nTable 2: Semantic shift of the term \u201cantiviral\u201d. We observe\na contextual shift of the word. In the top two cases, the term\nis used to describe alternative medicine with herbs, while\nin the bottom two cases, the term is used with its ordinary\n(scientific) connotation.\nwhere AiandAjare articles published by sources iandj;\nthus, their intersection should contain articles from source\nicopied by source j. The value of dcpyincreases as fewer\narticles are copied from itojand decreases as more articles\ninjare copied from i.\nShift Indicator\nWe analyze how specific technical terms are used differently\nbetween news sources. Different uses of a certain term in\ntwo pieces of text can occur if that same term is used in\na different context in each of the texts. Semantic shift is the\nprocess through which the usage of a given word drifts when\ncompared across different sources. Specifically, we consider\nthe lexical semantic shift, which posits the semantics of a\nword to be defined by its contextual relationships to other\nlexicons (Cruse et al. 1986). We argue that significant con-\ntextual shifts of topic-related words may serve as a signal\nof source disagreement, i.e., two sources using a certain tar-\nget word in significantly different contexts may indicate that\nthey use such words with different intents. An illustrative\nexample is shown in Table 2. Note, in both examples, the\nword antiviral is still used to indicate \u201csomething that is ef-\nfective against viruses\u201d; however, the contexts give different\nconnotations to what the antiviral product is.\nSemantic shift has been used extensively in computa-\ntional linguistics studies of language evolution (Hamilton,\nLeskovec, and Jurafsky 2016) and, more recently, in stud-\nies quantifying the linguistic differences across domains\n(Yin, Sachidananda, and Prabhakar 2018; Schlechtweg et al.\n2019). In our method, we use semantic shift as an indi-\ncator of agreement among sources as it helps to uncover\nunique narratives created by unreliable sources, especially\nthose based on conspiracy theories, deviating significantly\nfrom the narratives from reliable media.\nThe semantic shift between two sources iandjis mea-\nsured by the deviation in the usage of words they have in\ncommon. Specifically, we define semantic shift as the aggre-gated distance between word embeddings for terms in the\ncommon vocabulary of sources iandj. However, because\nthe word embeddings are trained independently from each\nother, they cannot be directly compared. For example, sup-\npose that vaandvbdenote word vectors for the word virus\nlearned from the sources The Washington Post andGlobal\nResearch, respectively. The cosine distance dcos(va, vb)is\nnot meaningful unless we first create a mapping between\nthe embedding spaces of each source. This mapping can be\nachieved by applying an orthogonal transformation to one\nof the embedding spaces to minimize the sum of the pair-\nwise Euclidean distances between word vectors of the com-\nmon vocabulary. Being orthogonal means that this transfor-\nmation preserves the inner product of the embeddings in\nthe transformed space; for that reason, this mapping is also\ncalled embedding alignment (Hamilton, Leskovec, and Ju-\nrafsky 2016; Joulin et al. 2018).\nFinding the best alignment of two embedding spaces\nis not a trivial task. Learning a transformation from all\nthe words in the common vocabulary is often undesired,\nas the objective of the mapping is to minimize the dis-\ntance between every pair of word vectors, hence minimiz-\ning the distance between words that are potentially semanti-\ncally distinct (Yin, Sachidananda, and Prabhakar 2018). To\nlearn alignments between word embeddings, we employ the\nstate-of-the-art self-supervised semantic shift (S4) method\n(Gruppi, Chen, and Adali 2021), which is designed to select\nthe best words for generating a mapping between two em-\nbeddings. This procedure is applied to embeddings trained\nusing Word2Vec (Mikolov et al. 2013).\nOnce we train and align the embeddings, we compute the\nsemantic distance between sources iandjas the average\ncosine distance between the top 10% most frequent words\niniandj(stop words excluded). Thus, the distance between\nsources iandjis defined as:\ndsem(i, j) =P\nv\u2208Vi\u2229Vjcos(emb i(v), emb j(v))\n|Vi\u2229Vj|\nwhere ViandVjare the vocabularies of sources iandj,\nembi(v)andembj(v)compute the embeddings representa-\ntion of word v, and coscomputes the cosine distance be-\ntween the embeddings. Additionally, ViandVjmay be re-\nplaced with subsets of the common vocabulary to avoid us-\ning every word in the analysis (e.g., filter for the most fre-\nquent words).\nReference Indicators\nIn this section, we introduce the reference indicators that we\nused to align news sources. Particularly, we introduce two\ndedicated scientific indicators, namely, the usage of scien-\ntific jargon and the citation stance. These indicators are ref-\nerence indicators, i.e., they define a distance among sources\ngiven a common (scientific) reference.\nReference Context Extraction\nTo compute the reference indicators, we need the textual\ncontext of the references, i.e., the paragraph in which these\nreferences are cited. To extract this context, we: i) locate the\n272\nSource Reference Context\nTheNewYorker In June, just three months into a historic health cri-\nsis, a survey by the Center for Disease Control and\nPrevention found that forty per cent of Americans\nwere already struggling with at least one mental-\nhealth issue.\nRedState It is no wonder that many Americans have lost\ntheir faith throughout 2020. Too many leaders\nhave been inconsistent in their actions minus their\ncontinued breaches of the public trust.\nReference Title\nCDC Mental Health, Substance Use, and Suicidal\nIdeation During the COVID-19 Pandemic \u2014\nUnited States, June 24\u201330, 2020.\nTable 3: Usage of scientific jargon when citing a report by\nCDC (Czeisler et al. 2020). We highlight that the citation\ncontext of TheNewYorker is semantically closer to the report\nthan the citation context of RedState.\nreferences by parsing the raw HTML page of each news ar-\nticle of our data collection, and ii) traverse the structural tree\nof the page to discover the most fine-grained text passage\nthat contains the reference. Currently, we do not support\nend-notes within articles, i.e., anchors at the bottom of ar-\nticles where all the scientific references are listed, because it\nis a journalistic practice rarely appearing in our corpus.\nJargon Indicator\nThis indicator quantifies the scientific nature of the context\nin which a reference is used. To estimate this indicator, we\nneed a lexicon of terms (jargon _terms in the following)\nthat are considered jargon in the scientific domain of our\ncorpus. Since, as we explain in \u00a7, our corpus contains news\narticles related to COVID-19, we use the vocabulary of CDC\nA-Z Index2, manually enhanced with common COVID-19\nterminology. After applying standard cleaning (e.g., punctu-\nation removal), we compute the following distance:\ndjar(i, j) =|ctxr(i)\u2229ctxr(j)\u2229jargon _terms|\nwhere ctxr(i)andctxr(j)are the terms in the citation con-\ntexts of sources iandjfor each common reference r.\nWe note that we do not aggregate for all common refer-\nences between sources iandj; hence, we do not limit to a\nsingle distance between these sources. In this way, we en-\ncode the co-citation volume between sources iandj, which\nis useful for our triplet sampling strategy (details in ). Af-\nter computing djar(i, j), we apply Min-Max Normalization\nin the interval [0,1]to comply with the previously-defined\ndistances. As we observe in Table 3, even such a simplistic\nmetric is able to capture cases in which news sources com-\npletely distort the scientific message of the cited reference.\nStance Indicator\nThis indicator quantifies the sentiment charge of the con-\ntext in which a reference is cited. To measure this sentiment\n2https://www.cdc.gov/azSource Reference Context\nFiveThirtyEight {...} based on current CDC guidelines {...} ex-\nperts said that undercounting (deaths) was still\nmore likely than overcounting.\nThe Truth\nAbout CancerPerhaps worst, the CDC has continued to lie\nabout the death count by artificially inflating\nit. CDC guidelines for determining COVID-19\ndeaths include: Anyone who tests positive, even\nif they died from other causes. Anyone who had\nCOVID-19 symptoms, even if they aren\u2019t tested.\nReference Title\nCDC Guidance for Certifying Deaths Due to Coron-\navirus Disease 2019 (COVID-19).\nTable 4: Stance of news sources when citing (using the\nunderlined hypertext) a webinar by CDC (Anderson et al.\n2020). We highlight that The Truth About Cancer uses more\nemotionally loaded words than FiveThirtyEight.\ncharge, we use the Multi-Genre Natural Language Inference\nmodel BART for zero-shot classification (Lewis et al. 2020).\nThis model3computes the probability that we infer a cer-\ntainhypothesis given a premise. Thus, the model needs no\nexplicit training on the downstream task of stance classifi-\ncation since the desired classes are provided implicitly in\nthehypothesis. After experimenting with various templates\nforpremise andhypothesis, we report the ones that yield the\nmost reliable results:\npremise =reference context\nhypothesis =\u201cThe stance of this example is negative\u201d\nThe output of this model is a value in the interval [0,1], de-\nnoting the probability a given premise implies our hypoth-\nesis. We note that, by using this premise and hypothesis,\nwe treat neutral andpositive stances similarly, i.e., as non-\nnegative stances, because we want to highlight extremely\nnegative stances (Table 4). Using this model we compute\nthe following distance:\ndref(i, j) =|stance(ctx r(i))\u2212stance(ctx r(j))|\nwhere stance(.) computes the stance of the citation contexts\nof sources iandjfor each common reference r.\nSimilarly as above, after computing dref(i, j), we apply\nMin-Max Normalization in the interval [0,1]. As we observe\nin Table 4, this indicator distinguishes between the sentiment\nof sources towards a common reference.\nUnsupervised Source Embeddings\nThe previous section described the heterogeneous indicators\nthat we extract from each news source. In this section, we de-\nscribe how we combine these indicators in a unified frame-\nwork to learn unsupervised representations of news sources.\nThe triplet loss function aims at coupling different parts of\nthe input spaces (here, our indicators) into a single repre-\nsentation (Weinberger and Saul 2009). The triplets sampling\n3https://huggingface.co/facebook/bart-large-mnli\n273\nand embeddings training methods employed in this frame-\nwork are well-established methods (Hoffer and Ailon 2015)\nused mainly in learning-to-rank recommendation systems\n(Chen et al. 2016; Wang et al. 2021).\nTriplets Sampling\nOur goal is, using the distances defined by the indicators,\nto discover pairs of similar sources and pairs of dissimilar\nsources. By joining these two sets of pairs, we create triplets\nof the form (anchor, positive, negative), where anchor is the\ncommon element of the pairs, positive is the element simi-\nlar to the anchor, and negative is the element dissimilar to\ntheanchor. For simplicity, in the following, we will refer to\nthese triplets as (a, p, n).\nWe note that these triplets may not occur from the same\nindicator, i.e., the positive pair may occur from an indicator\nthat is more appropriate for capturing the affinity between\nsources, and the negative pair may occur from an indica-\ntor that is more appropriate for capturing the disparity be-\ntween sources. In our experimental evaluation (\u00a7), we evalu-\nate each indicator in its ability to produce good positive and\nnegative pairs as well as full triplets.\nPositive Pair Sampling. We use the distances computed\nfor each indicator to generate pairs of similar sources. For\nall indicators we introduce in \u00a7 & \u00a7, short distance denotes\nsimilarity. Given an indicator f(copy, shift, jargon, or\nreference), we generate a positive pair of similar sources\ni, jwith a probability inversely proportional to the distance\nbetween iandj:\nppf(i, j) =d\u22121\nf(i, j)\nP\nkd\u22121\nf(i, k)\u2200j\u0338=i\nWe draw lpositives samples from this distribution for each\nindicator and each source in the dataset, producing a total of\nlpositive source pairs (a, p).\nNegative Pair Sampling. For negative sampling, we em-\nploy two strategies. For some indicators (e.g., the stance in-\ndicator), a large distance between sources denotes opposing\nsentiment, thus disagreement (e.g., the sources in Table 4).\nHence, we use the inverse distribution we used for generat-\ning positive pairs to generate negative pairs:\nnpf(i, j) = 1\u2212ppf(i, j)\u2200j\u0338=i\nSimilarly as above, we draw lnegative samples from this\ndistribution for each indicator and each source in the dataset,\nproducing a total of lnegative source pairs (a, n).\nNonetheless, there are indicators (e.g., the copy indicator)\nfor which a large distance between sources does not neces-\nsarily denote disagreement; it only denotes the absence of\nagreement. In these cases, we draw the negative pairs uni-\nformly from the set of sources.\nFinally, we employ a cleaning heuristic to increase the ac-\ncuracy of our triplets (detailed experiment in \u00a7). Specifically,\nwe make sure that we do not select a negative pair (a, n)\nwhich we have already selected as positive pair (a, p):\n(a, p)\u2227(a, n)\u21d2p\u0338=nEmbeddings Training\nOnce we extract all the triplets, we use them for training a\ndense representation model for news sources with the Triplet\nMargin Loss (Balntas et al. 2016). The learning objective of\nTriplet Margin Loss is to minimize the distance between an\nanchor and a positive sample while maximizing the distance\nbetween the anchor and the negative sample.\nThe procedure we employ is the following. First, we\ninitialize the embeddings for all the sources into a low-\ndimensional, dense vector space by randomly setting the\nweights in the embedding layer following a normal distri-\nbution N(0,1). Then, given the input triplets (a, p, n ), we\ntrain these embeddings by minimizing the loss function L:\nL(a, p, n) = max{d (a, p)\u2212d(a, n) + M,0}\nwhere dis the distance function, and Mis the margin pa-\nrameter that controls the gap between positive and negative\ndistances. The larger Mis, the larger is the gap between\nd(a, p) andd(a, n). We train the embeddings over several\nepochs until convergence and then use them as the represen-\ntation of the news sources.\nThe parameters of this method are the margin M, the dis-\ntance function d, and the size of the output vectors s. We\nrelease the optimal training parameters as well as the trained\nsources embeddings in our code release (\u00a7).\nExperiments\nOur experimental evaluation is three-fold; first, we evaluate\nthe indicators individually, then we evaluate the source em-\nbeddings on the downstream task of source reliability classi-\nfication, and finally, we perform an unsupervised clustering\nwhere we analyze the patterns in the news sources captured\nby the learned features. In the following experiments, the\nlabels from Media Bias/Fact Check are used, and word em-\nbeddings for the semantic shift are trained using Word2Vec\nwith dimension 100, context window of 10, and minimum\nword count of 20. The parameters for SciLander are margin\nM= 1, vector size s= 50, and distance dused in the loss\nfunction is the cosine distance.\nIndicator Coverage\nIn our first experiment, we measure the overlap of the intro-\nduced indicators in terms of source and triplet coverage. We\nalso measure the accuracy of the triplets computed by these\nindicators.\nWe define the source coverage (sc ) and the triplet cover-\nage (tc) between two indicators i, jas follows:\nsc(i, j ) =|src(i)\u2229src(j)|\n|src(i)|, tc (i, j) =|trpl (i)\u2229trpl(j)|\n|trpl (i)|\nwhere src(.)andtrpl(.)compute the distinct set of sources\nand triplets covered by a given indicator. We note that scand\ntcare non-symmetric; consequently, the heatmaps in Fig-\nure 3 are also non-symmetric.\nTo measure the accuracy of the computed triplets, we use\nthe metric Area Under the Receiver Operating Characteris-\ntics(AUROC), which measures the True Positive Rate over\ntheFalse Positive Rate. We also break down the AUROC\nof the triplets into i) the AUROC pof the positive part of\n274\nthe triplets (a, p), ii) the AUROC nof the negative part of\nthe triplets (a, n), and iii) the AUROC fof the full triplets\n(a, p, n ). Specifically, for each individual AUROC, we con-\nsider the following as true positives:\nAUROC p:{(a, p) s.t. label (a) =label (p)}\nAUROC n:{(a, n) s.t. label (a)\u0338=label (n)}\nAUROC f:{(a, p, n) s.t. label (a) =label (p)\n\u2227label (a)\u0338=label (n)}\nAs we observe in Figure 3, although the sources covered\nby some indicators heavily overlap, the contributed triplets\nare quite unique. Indicatively, the stance indicator covers\n27.5% of the sources, totally overlapping with the copy indi-\ncator. However, the contributed triplets of the stance indica-\ntor are different from the contributed triplets of all the other\nindicators and also more accurate. Indeed, we see that there\nis a trade-off between the source coverage of the indicators\nand the AUROC. Hence, the more specific the indicator is\n(e.g., the stance indicator), the better AUROC it has.\nFinally, we observe that the overall AUROC for positive\nand negative pairs (AUROC pand AUROC n, respectively)\nare above the 50% baseline of a random positive (or nega-\ntive) pair selection is truly positive (or negative).\nIt should be noted that the AUROC for complete triplets\n(AUROC f) is lower than 50%. This happens because the\nchoice of the final triplets involves two independent deci-\nsions: the choice of the positive sample, and the choice of the\nnegative sample. As noted above, each choice has a chance\nof success of 50% if chosen at random. Thus, for a triplet to\nbe correctly selected, the random baseline is that a correct\npositive pair is chosen anda correct negative pair is chosen,\nwhich results in a 0.5\u00d70.5 = 0 .25, or 25% baseline chance.\nAs we see in the following experiments, the model for train-\ning source embedding is robust to noisy triplets as it yields\nhighly accurate results in all the downstream tasks we use it.\nOffline Source Classification\nIn this experiment, we evaluate the computed embeddings\non a downstream classification task. We assume that, for all\nsources in our corpus, we have (offline) access to a signifi-\ncant fraction of their history of published articles.\nBaselines. For this task, we implement baselines using\nStylistic Text Features, Contextualized Embeddings, and Co-\ncitation Embeddings, as well as combinations of the above.\nStylistic Text Features. We utilize stylistic text features\nfrom Horne et al. (Horne and Adali 2017) aggregated at\nthe source level as representations. These features include,\namong others, the number of: part of speech tags, punctua-\ntion symbols, and capitalized words, which are the features\nthat are typically used in news classifiers.\nContextualized Embeddings. We compute BERT (Devlin\net al. 2019) embeddings for a total of 32tokens from the title\nand the opening paragraph of the article, and average them\nfor each source. Similarly, we compute SciBERT (Beltagy,\nLo, and Cohan 2019) instead of BERT embeddings, which\nhave been shown to lead to better performance in tasks in-\nvolving scientific text. The configuration parameters of both\ncopy shift jargon stancecopyshift jargonstance100.00% 72.46% 39.13% 27.54%\n80.91% 100.00% 41.42% 28.16%\n98.54% 93.43% 100.00% 64.23%\n100.00% 91.58% 92.63% 100.00%\ncopy shift jargon stancecopyshift jargonstance100.00% 0.16% 0.13% 0.26%\n0.11% 100.00% 0.02% 0.03%\n0.79% 0.17% 100.00% 7.03%\n1.38% 0.25% 6.23% 100.00%Indicator AUROC pAUROC nAUROC f#sources\ncopy 72.7% 51.0% 36. 3% 257\nshift 61.9% 60.8% 41. 8% 308\nstance 89.7% 73.3% 68. 3% 87\njargon 81.9% 51.0% 42. 9% 126\noverall 77.0% 69.7% 57. 5% 316\nFigure 3: Overlap of indicators in terms of source coverage\n(top left) and triplet coverage (top right); AUROC of the pos-\nitive part, negative part, and full triplets (bottom). Although\nthe sources covered by most indicators heavily overlap, their\ntriplets are quite unique. Also, there is a trade-off between\nthe source coverage of the indicators and their AUROC.\nBERT and SciBERT are those suggested in a widely used\nrelease of this model (Wolf et al. 2019).\nCo-Citation Embeddings. We compute a co-citation graph\nof sources based on their scientific references. We weight\nthis graph either uniformly for each common reference,\nor by emphasizing the uniquely used references, using\ntheir TF-IDF score. In the overall graph, we run node2vec\n(Grover and Leskovec 2016) to extract source embeddings.\nJoint Embeddings. TheContextualized Embeddings and\ntheCo-Citation Embeddings capture two different modal-\nities of news sources; their content and citation behavior.\nThus, we create a joint representation by concatenating the\ntwo embeddings. Since the dimensionality of the joint em-\nbeddings is high, we apply Principal Component Analysis to\nreduce it and compare it with other baseline representations.\nEvaluation. We test the usefulness of the learned repre-\nsentations in the problem of source veracity classification.\nWe use the embeddings computed by i) SciLander trained\non all indicators, ii) SciLander trained only on content indi-\ncators (shift or copy), and iii) the aforementioned baseline\nmodels, to train a Nearest Neighbors classifier in a 10-fold\ncross-validation setting. Figure 4 shows the F1 score of each\nmodel for increasing values of k.\nRelying uniquely on textual features limits classifiers to a\nrestricted set of signals. Our framework combines stylistic,\nsemantic, and behavioral indicators to produce a represen-\ntation that improves the separation of reliable and unreli-\nable sources. Thus, compared to traditional baselines such\nas stylistic features or features extracted by BERT, our em-\nbeddings show significant performance improvement. Our\nmethod obtains the best F1 score (87%) for k=37.\n275\nFigure 4: F1 scores using k-nearest neighbors classifiers\nover the source embeddings representations computed by\nSciLander and the various baselines described in \u00a7. SciLan-\nder obtains the best F1 score (87%) for k=37.\nOnline Source Classification\nIn this experiment, we assume that we have two types of\nsources: i) offline (known) sources, for which we have ac-\ncess to a significant fraction of their publication history, and\nii) online (newcomer) sources, for which we have access to\na limited fraction of their publication history. As assessing\narticles from newcomer sources might be a time-consuming\ntask, we inspect the lowest fraction of articles that is needed\nto accurately classify these sources.\nThe procedure that we employ is the following: i) we\ntrain embeddings for the offline sources (as we explain in\n\u00a7); ii) we freeze these embeddings for the offline sources;\niii) we train embeddings for online sources, in the already\nshaped by the offline sources embeddings space.\nWe conduct the experiment on a 10-fold cross-validation\nsetting. In Figure 5, we report the learning curve (F1 score)\nfor increasing fractions of articles from newcomer sources in\nthe same classification task described in \u00a7. We note that the\ntemporal axis is not in chronological order but sampled ran-\ndomly from the entire corpus (e.g., we sample articles rep-\nresenting a 3-month publishing activity of an online source\nfrom the entire publishing activity of that source). In that\nway, each temporal interval is independent of external events\n(e.g., the development of the vaccines), which affects the ac-\ntivity of most sources. As we observe in Figure 5, SciLander\nis able to reliably (F1>85%) classify sources, using only\nthree months of their publishing activity.\nSource Clustering Analysis\nWe conduct an unsupervised clustering experiment to inves-\ntigate potential trends revealed by the features learned by\nSciLander. Using the same embeddings from the previous\nexperiments (50 dimensions, M= 1), we apply DBSCAN\nclustering to the source vectors with the cosine distance as\ndistance metric, minimum distance parameter \u03f5= 0.1 and\nminimum cluster size n= 1. The resulting clusters are\nshown in Figure 6; each of the 7 clusters is shown in dif-\nferent color shades and labeled from AtoG.\nWe characterize the clusters quantitatively with respect to\nthe density of unreliable sources, political leaning, and the\nlevel of partisanship bias aggregated across the news sources\nFigure 5: Learning curve (F1 score) for increasing fractions\nof articles from newcomer sources. SciLander is able to reli-\nably (F1>85%) classify sources using only 3months of their\npublishing activity.\nwithin them. For each cluster, we compute the proportion of\nunreliable sources to the total number of sources in the clus-\nter. Figure 7a shows the density of unreliable sources within\neach cluster. This result suggests that the source embeddings\ncarry information about source credibility when grouping\nthem, even though credibility labels or related features were\nunknown to the model during training.\nClusters CandEcontain no unreliable sources and hold\nmostly mainstream news sources such as The Washington\nPost, V ox, National Public Radio (NPR), and the Chicago\nTribune. The clusters containing the largest proportions of\nunreliable sources are the clusters A,B, and G, and most\nsources in these clusters are websites that propagate con-\nspiracy theories and promote pseudoscience. Details on the\ndiscovered clusters are shown in Table 5.\nThese results show that the SciLander embeddings are\nable to group sources based on similar reliability. Multi-\nple clusters of relatively high purity with respect to reliabil-\nity are created, some reliable (75%-100% reliable sources),\nsome unreliable (0%-30% reliable sources).\nWe compute the overall political leaning of a cluster by\naveraging the political leaning scores of the sources within\nthat cluster. Partisanship bias is obtained by the absolute\nvalue of leaning, scaled to a value in [0,1], with 0indicating\nthat there is no partisanship bias in the cluster, and 1in-\ndicating the maximum partisanship bias, where all sources\nin the cluster exhibit a strong political leaning. The parti-\nsanship bias describes the agreement between the political\nleanings of sources within the cluster, and the magnitude of\nsuch leanings. The distribution of political leanings and par-\ntisanship bias are shown in Figures 7b and 7c. There is a\nnoticeable disparity between the partisanship bias found in\nthe two biggest unreliable clusters AandB. Sources in clus-\nterAexhibit a strong bias, which is nearly absent in cluster\nB. We explore the particularities of these clusters next.\nDifferent Types of Conspiracy Theories\nWe observe two clusters with high density of unreliable\nsources (clusters AandB). Both clusters include many un-\nreliable news sources, and there exist qualitative differences\nbetween them, which we describe in this section.\nTo uncover qualitative differences between sources in\nclusters AandB, we measure the shift in context between\n276\n1\n 0 1\nPC12\n1\n012PC2Cluster\nA\nB\nC\nD\nE\nF\nGFigure 6: Kernel Density Estimation of the clusters\nCl. (U) (P) Core Sources\nA.70 .25 NewsWars, Vets. Today, The D.C. Clothesline\nB.84 .03 Mercola, Healthy Hol. Living, Vaccine React.\nC.00 .11 The Washington Post, V ox, NPR\nD.25 .00 The American Cons., Roll Call\nE.00 .20 Chicago Tribune\nF.12 .03 Wash. Monthly, FiveThirtyEight, Atlantic\nG.80 .00 Ice Age Now\nTable 5: (U)nreliability score (proportion of unreliable\nsources), average (P)artisanship bias score, and core sources\n(nearest neighbors to the centroid) of the identified clusters.\nthese clusters and the mainstream cluster C. Specifically, we\ncomputed the semantic shift across clusters of sources by\ntraining Word2Vec models EA,EB, and ECusing articles\nfrom the core sources of each cluster and using the same\nhyper-parameters as in the previous experiments. Then, we\nextract the words with the highest cosine distance between\npairs (EC, EA)and(EC, EB)to find the terms that most\ncontribute to the deviation in the news from sources in Cto\neach of the unreliable clusters AandB.\nLetSAandSBbe the lists of the 100words most shifted\ntoC, from AandB, respectively. We find that there is only\none word in common between the SAandSB: \u201cnatural\u201d.\nTo characterize the words in both lists, we identify words\nthat refer to people, entities and places, political issues, and\nhealth and nutrition. Examples of these words are given be-\nlow and listed on Table 6.\nThe largest group of words shifted in cluster A are re-\nlated to individuals, entities, places (25%), and political top-\nics (12%). Almost all individuals found are political figures\n(with a few exceptions). There are only 1.5% of terms re-\nlated to health and nutrition. Many of these news outlets are\nconspiracy theory websites such as NewsWars, Veterans To-\nday, and InfoWars. According to a Media Bias/Fact Check\nanalysis4, these sites often publish hate-speech-filled content\nin addition to misleading or false information.\nIn contrast, the largest group of shifted words was de-\ntected in cluster B (21.5%), with only 2% people and 1%\nrelated to political topics. According to MBFC journalists5,\nthese sources promote alternative health notions, sell ques-\ntionable products and supplements, and promote antivacci-\nnation positions with pseudoscience-based arguments.\n4https://mediabiasfactcheck.com/veterans-today\n5https://mediabiasfactcheck.com/mercolaPeople and Places Political Terms Health\nKamala Harris BLM (Black Lives Matter) Coronavirus\nBernie Sanders Patriot Food\nNancy Pelosi V oting Vaccines\nMike Pence Abortion Doctors\nAlex Jones Partisan Mask\nTable 6: List of words from clusters AandBthat are most\nshifted from the mainstream cluster C. People and Places,\nand Political Terms appear as the most shifted words in clus-\nterA, suggesting that its sources push politically-oriented\nmisinformation, while sources in cluster Bfocus more on\nalternative health solutions.\nBased on this, we conclude that while cluster A is a clus-\nter of mostly politically-unreliable news sources covering\nCOVID-19 stories mixed with other political topics, cluster\nB is much more focused on covering alternative medicine-\nbased misinformation with slight political leaning, presum-\nably to appeal to individuals with different political opin-\nions. On these sites, health-based information is often mixed\nwith promotion and affiliate links to sites selling alternative\nmedicine products and supplements. Our method is able to\nproperly distinguish these different types of COVID-19 mis-\ninformation, without explicitly training on related features.\nDiscussion\nSciLander is a method for embedding news sources. The\nresults of the experiments (\u00a7) show that the representations\nlearned from SciLander outperform other state-of-the-art\nfeature models. Despite the final representation being a set\nof autoencoded features (i.e., embeddings learned from a\nneural network), it is directly explained by the product of\na combination of the aforementioned indicators.\nThe applications of these learned features are not re-\nstricted to classification tasks. They can be used in any sce-\nnario where similarities between news sources are needed,\nsuch as in clustering analysis (details in \u00a7) and recommen-\ndation systems.\nSciLander, like most other AI/ML methods, is heavily\ndata-driven. It uses signals found in the text of news arti-\ncles to infer the relationships between sources. The above\ncan cause SciLander to make biased decisions, especially if\nthe input data is biased towards/against societal groups, such\nas underrepresented minorities and other vulnerable groups.\nWe argue that SciLander, when deciding what content to\nrecommend or promote, can provide assistance in human\ndecision-making but not replace human judgment.\nThe indicators used by SciLander complement each\nother. The experiments shown in \u00a7 demonstrate that the\nembeddings performed better in classification tasks when\nall four indicators are combined (copy, shift, jargon, and\nstance). The latter suggests that the indicators worked in a\ncomplementary manner, where a mistake made by one in-\ndicator is corrected by the other indicators. Furthermore, as\nseen in Figure 3, some indicators were better suited to de-\ntect negative pairs. For example, the indicator copy had a\n277\n1\n 0 1\nPC12\n1\n012PC2\n0.00.20.40.60.81.0\n(a) Density of Unreliable Sources\n1\n 0 1\nPC12\n1\n012PC2\nLeftUnknownRight\n (b) Density of Political Leaning\n1\n 0 1\nPC12\n1\n012PC2\nWeakStrong\n (c) Density of Partisanship Bias\nFigure 7: Density analysis of the clusters computed by SciLander. Components PC1 and PC2, obtained from Principal Compo-\nnent Analysis (PCA) on the source embeddings, are the components with the highest explained variance ratio.\nAUROC score of 72.7% for positive samples and 51% for\nnegative samples. This result can be explained by the fact\nthat while the presence of copy behavior between sources\nxandyis an indicator of similarity between xandy, its\nabsence does not necessarily imply that xandyare very\ndistinct. In short, source xnot copying from ydoes not im-\nply that xis distant from y. Conversely, the stance indicator\nhad a higher negative pair score (73.3%), suggesting that this\nindicator would perform better in finding negative samples.\nSciLander has the potential to be extended to general do-\nmains. We based SciLander on features that work as indica-\ntors of source similarity or dissimilarity, motivated by pre-\nvious research on language and misinformation (Chambers\nand Schilling 2018; Horne, N\u00f8rregaard, and Adal\u0131 2019;\nSmeros, Castillo, and Aberer 2019). The shift andcopy in-\ndicators are agnostic to the news domain since they only re-\nquire the presence of text. However, the stance andjargon\nindicators are closely tied to scientific news.\nTo extend the application of SciLander to other, including\nnon-scientific, domains, a topic of choice must be specified\nprior to the application of the method. The chosen topic must\ninclude a set of entities referred to by news sources, such as\npolitical figures in the political news domain. In this case,\nthe stance towards scientific references would be replaced\nby the stance towards such political figures, and the scien-\ntific jargon would be replaced by political jargon. Topics can\nbe manually defined via a set of keywords and entities, or au-\ntomatically defined, such as by applying topic modeling to\nextract the relevant keywords from the news documents.\nLimitations. Our methodology was only applied and eval-\nuated on an English dataset; extending to other languages\nwould only require translation/adaptation of the domain-\nspecific lexicon used to compute the jargon indicator or sim-\nply skipping this indicator and training using the other three.\nAll the other indicators as well as the introduced embed-\nding model, are based either on language-agnostic or already\nmultilingual models.\nFurthermore, our methodology supports only explicit ci-\ntations, i.e., direct outgoing links to scientific papers, and not\nimplicit mentions of science-related entities (e.g., universi-\nties) because the latter design choice introduces ambiguity\nand noisy source triplets.\nFinally, we implicitly filter the scientific references re-lated to COVID-19 as we filter the news corpus citing\nthese references. Explicit filtering would require download-\ning and parsing the references from different formats, e.g.,\npdf, which is a demanding task not in the scope of this work.\nConclusions\nWe have introduced SciLander, a method for learning a rep-\nresentation of news sources reporting science-related con-\ntent. Our method uses a combination of signals to estimate\nthe similarity between news sources. We have shown that\nthese signals complement each other, capturing relationships\nbetween distinct sets of sources from a dataset of news arti-\ncles related to COVID-19. Furthermore, the features learned\nby our model demonstrated superior performance to base-\nlines for the task of source credibility detection, both in\nan offline and an online setting, requiring as little as three\nmonths of publication activity to accurately classify news\nsources. Lastly, we have shown that the learned source rep-\nresentations encode information of credibility and political\nleaning, forming clusters of sources that show similar reli-\nability and political bias. In particular, we discovered two\nlarge clusters of unreliable sources to which different types\nof conspiracy news sources flock. One of them concentrates\non alternative health misinformation, and the other promotes\nhyper-partisan political conspiracies.\nReproducibility. All the data, code, and models used for this\npaper are publicly available for research purposes in the fol-\nlowing repository: https://github.com/mgruppi/SciLander.\nEthics Statement\nOur work aims at finding representations that capture the\nsimilarities and differences between news sources in their\ncoverage of the COVID-19 pandemic. Our proposed method\nbases this representation on the language usage, content\ncopy/sharing behavior, and their stance towards scientific\nreferences. We show that the representations learned from\nthese signals are useful for several downstream tasks, in-\ncluding understanding the reliability of a source. This is ac-\ncomplished by using proxies to trust scientific references,\nlanguage, and content. One must be careful when applying\nthis method to untested dimensions, such as the presence of\nlanguage usage by minority groups. These groups may be\nunderrepresented in the training data, which may cause the\n278\nmodel to make biased predictions about them. We propose\nthat this method aids the decision-making process as a com-\nplement to human judgment rather than a replacement.\nAcknowledgements\nThis work was supported by the Rensselaer-IBM AI Re-\nsearch Collaboration (http://airc.rpi.edu), part of the IBM AI\nHorizons Network (http://ibm.biz/AIHorizons).\nReferences\nAnderson, R. N.; Warner, M.; Flagg, L. A.; and Ahmad, F.\n2020. Guidance for Certifying Deaths Due to Coronavirus\nDisease 2019 (COVID-19). https://stacks.cdc.gov/view/cdc/\n87029. Accessed: 2021-03-15.\nBalntas, V .; Riba, E.; Ponsa, D.; and Mikolajczyk, K. 2016.\nLearning local feature descriptors with triplets and shallow\nconvolutional neural networks. In BMVC 2016, York, UK,\nSeptember 19-22, 2016. BMV A Press.\nBaly, R.; Karadzhov, G.; Alexandrov, D.; Glass, J. R.; and\nNakov, P. 2018. Predicting Factuality of Reporting and Bias\nof News Media Sources. In EMNLP , Brussels, Belgium, Oc-\ntober 31 - November 4, 2018, 3528\u20133539. ACL.\nBaly, R.; Karadzhov, G.; Saleh, A.; Glass, J. R.; and Nakov,\nP. 2019. Multi-Task Ordinal Regression for Jointly Predict-\ning the Trustworthiness and the Leading Political Ideology\nof News Media. In NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, 2109\u20132116. ACL.\nBeltagy, I.; Lo, K.; and Cohan, A. 2019. SciBERT: A Pre-\ntrained Language Model for Scientific Text. In EMNLP-\nIJCNLP 2019, Hong Kong, China, November 3-7, 2019 ,\n3613\u20133618. ACL.\nBourgeois, D.; Rappaz, J.; and Aberer, K. 2018. Selection\nBias in News Coverage: Learning it, Fighting it. In WWW\n2018, Lyon , France, April 23-27, 2018, 535\u2013543. ACM.\nBuchanan, M. 2020. Managing the infodemic. Nature Pub-\nlishing Group, 16(9): 894\u2013894.\nCastillo, C. 2016. Big crisis data: social media in disasters\nand time-critical situations. Cambridge University Press.\nChambers, J. K.; and Schilling, N. 2018. The handbook of\nlanguage variation and change. John Wiley & Sons.\nChen, X.; Qin, Z.; Zhang, Y .; and Xu, T. 2016. Learning\nto Rank Features for Recommendation over Multiple Cate-\ngories. In Perego, R.; Sebastiani, F.; Aslam, J. A.; Ruthven,\nI.; and Zobel, J., eds., SIGIR 2016, Pisa, Italy, July 17-21,\n2016, 305\u2013314. ACM.\nChung, C. J.; Nam, Y .; and Stefanone, M. A. 2012. Explor-\ning Online News Credibility: The Relative Influence of Tra-\nditional and Technological Factors. Journal of Computer-\nMediated Communication, 17(2): 171\u2013186.\nCruse, D. A.; Cruse, D. A.; Cruse, D. A.; and Cruse, D. A.\n1986. Lexical semantics. Cambridge university press.\nCzeisler, M. \u00c9.; Lane, R. I.; Petrosky, E.; Wiley, J. F.; Chris-\ntensen, A.; Njai, R.; Weaver, M. D.; Robbins, R.; Facer-\nChilds, E. R.; Barger, L. K.; et al. 2020. Mental health,\nsubstance use, and suicidal ideation during the COVID-19pandemic\u2014United States, June 24\u201330, 2020. Morbidity and\nMortality Weekly Report, 69(32): 1049.\nDevlin, J.; Chang, M.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In NAACL-HLT 2019, Minneapo-\nlis, MN, USA, June 2-7, 2019, Volume 1, 4171\u20134186. ACL.\nGrover, A.; and Leskovec, J. 2016. node2vec: Scalable Fea-\nture Learning for Networks. In SIGKDD, San Francisco,\nCA, USA, August 13-17, 2016, 855\u2013864. ACM.\nGruppi, M.; Chen, P.; and Adali, S. 2021. Fake it Till\nYou Make it: Self-Supervised Semantic Shifts for Monolin-\ngual Word Embedding Tasks. In AAAI 2021, Virtual Event,\nFebruary 2-9, 2021, 12893\u201312901. AAAI Press.\nGruppi, M.; Horne, B. D.; and Adali, S. 2021. NELA-\nGT-2020: A Large Multi-Labelled News Dataset for The\nStudy of Misinformation in News Articles. CoRR,\nabs/2102.04567.\nGruppi, M.; Horne, B. D.; and Adal\u0131, S. 2021. Tell Me\nWho Your Friends Are: Using Content Sharing Behavior for\nNews Source Veracity Detection. CoRR, abs/2101.10973.\nHamilton, W. L.; Leskovec, J.; and Jurafsky, D. 2016. Cul-\ntural Shift or Linguistic Drift? Comparing Two Computa-\ntional Measures of Semantic Change. In EMNLP 2016,\nAustin, Texas, USA, November 1-4, 2016, 2116\u20132121. ACL.\nHansen, C.; Hansen, C.; Alstrup, S.; Simonsen, J. G.; and\nLioma, C. 2019. Neural Check-Worthiness Ranking with\nWeak Supervision: Finding Sentences for Fact-Checking. In\nWWW \u201919, San Francisco, CA, USA, May 13-17, 2019, 994\u2013\n1000. ACM.\nHoffer, E.; and Ailon, N. 2015. Deep Metric Learning Using\nTriplet Network. In Feragen, A.; Pelillo, M.; and Loog, M.,\neds., SIMBAD 2015, Copenhagen, Denmark, October 12-14,\n2015, Proceedings, volume 9370 of LNCS, 84\u201392. Springer.\nHorne, B. D.; and Adali, S. 2017. This Just In: Fake News\nPacks a Lot in Title, Uses Simpler, Repetitive Content in\nText Body, More Similar to Satire than Real News. CoRR,\nabs/1703.09398.\nHorne, B. D.; N\u00f8rregaard, J.; and Adal\u0131, S. 2019. Different\nSpirals of Sameness: A Study of Content Sharing in Main-\nstream and Alternative Media. In ICWSM 2019, Munich,\nGermany, June 11-14, 2019, 257\u2013266. AAAI Press.\nJiang, S.; Baumgartner, S.; Ittycheriah, A.; and Yu, C. 2020.\nFactoring Fact-Checks: Structured Information Extraction\nfrom Fact-Checking Articles. In WWW \u201920, Taipei, Taiwan,\nApril 20-24, 2020, 1592\u20131603. ACM / IW3C2.\nJoulin, A.; Bojanowski, P.; Mikolov, T.; J\u00e9gou, H.; and\nGrave, E. 2018. Loss in translation: Learning bilingual\nword mapping with a retrieval criterion. arXiv preprint\narXiv:1804.07745.\nLewis, M.; Liu, Y .; Goyal, N.; Ghazvininejad, M.; Mo-\nhamed, A.; Levy, O.; Stoyanov, V .; and Zettlemoyer, L.\n2020. BART: Denoising Sequence-to-Sequence Pre-training\nfor Natural Language Generation, Translation, and Compre-\nhension. In ACL 2020, Online, July 5-10, 2020, 7871\u20137880.\nACL.\n279\nLi, C.; and Goldwasser, D. 2019. Encoding Social Infor-\nmation with Graph Convolutional Networks forPolitical Per-\nspective Detection in News Media. In ACL 2019, Florence,\nItaly, July 28- August 2, 2019, 2594\u20132604. ACL.\nMcKay, S.; and Tenove, C. 2021. Disinformation as a Threat\nto Deliberative Democracy. Political Research Quarterly,\n74(3): 703\u2013717.\nMikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013. Ef-\nficient Estimation of Word Representations in Vector Space.\nInICLR 2013, Scottsdale, Arizona, USA, May 2-4, 2013.\nRappaz, J.; Bourgeois, D.; and Aberer, K. 2019. A Dy-\nnamic Embedding Model of the Media Landscape. In WWW\n2019, San Francisco, CA, USA, May 13-17, 2019, 1544\u2013\n1554. ACM.\nReis, J. C. S.; Correia, A.; Murai, F.; Veloso, A.; Ben-\nevenuto, F.; and Cambria, E. 2019. Supervised Learning for\nFake News Detection. IEEE Intell. Syst., 34(2): 76\u201381.\nRibeiro, F. N.; Lima, L. H. C.; Benevenuto, F.; Chakraborty,\nA.; Kulshrestha, J.; Babaei, M.; and Gummadi, K. P. 2018.\nMedia Bias Monitor: Quantifying Biases of Social Media\nNews Outlets at Large-Scale. In ICWSM 2018, Stanford,\nCalifornia, USA, June 25-28, 2018, 290\u2013299. AAAI Press.\nSchlechtweg, D.; H\u00e4tty, A.; Tredici, M. D.; and im Walde,\nS. S. 2019. A Wind of Change: Detecting and Evaluating\nLexical Semantic Change across Times and Domains. In\nACL 2019, Florence, Italy, July 28- August 2, 2019, 732\u2013\n746. ACL.\nShaar, S.; Babulkov, N.; Martino, G. D. S.; and Nakov, P.\n2020. That is a Known Lie: Detecting Previously Fact-\nChecked Claims. In ACL 2020, Online, July 5-10, 2020,\n3607\u20133618. ACL.\nShu, K.; Wang, S.; and Liu, H. 2019. Beyond News Con-\ntents: The Role of Social Context for Fake News Detection.\nInWSDM 2019, Melbourne, VIC, Australia, February 11-\n15, 2019, 312\u2013320. ACM.\nShugars, S.; Gitomer, A.; McCabe, S.; Gallagher, R. J.;\nJoseph, K.; Grinberg, N.; Doroshenko, L.; Welles, B. F.; and\nLazer, D. 2021. Pandemics, Protests, and Publics: Demo-\ngraphic Activity and Engagement on Twitter in 2020. Jour-\nnal of Quantitative Description: Digital Media, 1.\nSmeros, P.; Castillo, C.; and Aberer, K. 2019. SciLens: Eval-\nuating the Quality of Scientific News Articles Using So-\ncial Media and Scientific Literature Indicators. In WWW\n2019, San Francisco, CA, USA, May 13-17, 2019, 1747\u2013\n1758. ACM.\nSmeros, P.; Castillo, C.; and Aberer, K. 2021. SciClops:\nDetecting and Contextualizing Scientific Claims for Assist-\ning Manual Fact-Checking. In CIKM \u201921, Queensland, Aus-\ntralia, November 1 - 5, 2021, 1692\u20131702. ACM.\nVan Bavel, J. J.; Baicker, K.; Boggio, P. S.; Capraro, V .; Ci-\nchocka, A.; Cikara, M.; Crockett, M. J.; Crum, A. J.; Dou-\nglas, K. M.; Druckman, J. N.; et al. 2020. Using social\nand behavioural science to support COVID-19 pandemic re-\nsponse. Nature human behaviour, 4(5): 460\u2013471.\nVishwakarma, D. K.; Varshney, D.; and Yadav, A. 2019. De-\ntection and veracity analysis of fake news via scrapping andauthenticating the web search. Cogn. Syst. Res., 58: 217\u2013\n229.\nWang, L. L.; Lo, K.; Chandrasekhar, Y .; Reas, R.; Yang, J.;\nEide, D.; Funk, K.; Kinney, R.; Liu, Z.; Merrill, W.; Mooney,\nP.; Murdick, D. A.; Rishi, D.; Sheehan, J.; Shen, Z.; Stil-\nson, B.; Wade, A. D.; Wang, K.; Wilhelm, C.; Xie, B.; Ray-\nmond, D.; Weld, D. S.; Etzioni, O.; and Kohlmeier, S. 2020.\nCORD-19: The Covid-19 Open Research Dataset. CoRR,\nabs/2004.10706.\nWang, R.; Shivanna, R.; Cheng, D. Z.; Jain, S.; Lin, D.;\nHong, L.; and Chi, E. H. 2021. DCN V2: Improved Deep &\nCross Network and Practical Lessons for Web-scale Learn-\ning to Rank Systems. In Leskovec, J.; Grobelnik, M.; Na-\njork, M.; Tang, J.; and Zia, L., eds., WWW \u201921, Ljubljana,\nSlovenia, April 19-23, 2021, 1785\u20131797. ACM / IW3C2.\nWeinberger, K. Q.; and Saul, L. K. 2009. Distance met-\nric learning for large margin nearest neighbor classification.\nJournal of machine learning research, 10(2).\nWolf, T.; Debut, L.; Sanh, V .; Chaumond, J.; Delangue, C.;\nMoi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; and\nBrew, J. 2019. HuggingFace\u2019s Transformers: State-of-the-\nart Natural Language Processing. CoRR, abs/1910.03771.\nYang, S.; Shu, K.; Wang, S.; Gu, R.; Wu, F.; and Liu, H.\n2019. Unsupervised Fake News Detection on Social Media:\nA Generative Approach. In AAAI 2019, Honolulu, Hawaii,\nUSA, January 27 - February 1, 2019, 5644\u20135651. AAAI\nPress.\nYin, Z.; Sachidananda, V .; and Prabhakar, B. 2018. The\nGlobal Anchor Method for Quantifying Linguistic Shifts\nand Domain Adaptation. In NeurIPS 2018, December 3-8,\n2018, Montr\u00e9al, Canada, 9434\u20139445.\nZarocostas, J. 2020. How to fight an infodemic. The Lancet,\n395(10225): 676.\nZhang, A. X.; Ranganathan, A.; Metz, S. E.; Appling, S.;\nSehat, C. M.; Gilmore, N.; Adams, N. B.; Vincent, E.; Lee,\nJ.; Robbins, M.; Bice, E.; Hawke, S.; Karger, D. R.; and\nMina, A. X. 2018. A Structured Response to Misinfor-\nmation: Defining and Annotating Credibility Indicators in\nNews Articles. In WWW 2018, Lyon , France, April 23-27,\n2018, 603\u2013612. ACM.\nZubiaga, A.; Kochkina, E.; Liakata, M.; Procter, R.;\nLukasik, M.; Bontcheva, K.; Cohn, T.; and Augenstein, I.\n2018. Discourse-aware rumour stance classification in so-\ncial media using sequential classifiers. Inf. Process. Man-\nage., 54(2): 273\u2013290.\n280", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "SciLander: Mapping the scientific news landscape", "author": ["M Gruppi", "P Smeros", "S Adal\u0131", "C Castillo"], "pub_year": "2023", "venue": "Proceedings of the \u2026", "abstract": "The COVID-19 pandemic has fueled the spread of misinformation on social media and the  Web as a whole. The phenomenon dubbedinfodemic'has taken the challenges of information"}, "filled": false, "gsrank": 394, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/22144", "author_id": ["MHHYhXwAAAAJ", "S96SbW0AAAAJ", "Jk3gxBEAAAAJ", "D4NJsXEIh1cJ"], "url_scholarbib": "/scholar?hl=en&q=info:25HU2GPmeNkJ:scholar.google.com/&output=cite&scirp=393&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=25HU2GPmeNkJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 7, "citedby_url": "/scholar?cites=15670528219949601243&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:25HU2GPmeNkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/22144/21923"}}, {"title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "year": "2025", "pdf_data": "Tracking the Takes and Trajectories of English-Language News Narratives across\nTrustworthy and Worrisome Websites\nHans W. A. Hanley\nStanford UniversityEmily Okabe\nStanford UniversityZakir Durumeric\nStanford University\nAbstract\nUnderstanding how misleading and outright false informa-\ntion enters and spreads within news ecosystems remains a\ndifficult challenge that requires tracking how stories spread\nacross thousands of fringe and mainstream news websites.\nTo take this challenge, we introduce a novel system that\nutilizes encoder-based large language models and zero-shot\nstance detection to scalably identify and track news stories and\ntheir attitudes to different topics across thousands of factually\nunreliable, mixed-reliability, and factually reliable English-\nlanguage news websites. Deploying our system over an 18-\nmonth period, we track the spread of 146K news stories across\nover 4,000 websites. Using network-based interference via\nthe NETINF algorithm, we show that the paths of news sto-\nries and the stances of websites toward particular entities can\nbe used to uncover slanted propaganda networks ( e.g., anti-\nvaccine and anti-Ukraine) and to identify the most influential\nwebsites in spreading these attitudes in the broader news\necosystem. We hope that the increased visibility into news\necosystems that our system provides assists with the reporting\nand fact-checking of propaganda and disinformation.\n1 Introduction\nMisinformation has promoted dangerous fake health\ncures [16], promoted jingoism and propaganda during\nwars [84, 109, 121], and incited violence [6, 17]. While there\nhas been significant investigation into how misleading in-\nformation spreads across social media platforms and fringe\nwebsites [80, 81, 127], recent work has emphasized the de-\ngree to which the vast majority of people do not visit fringe\nwebsites or regularly encounter misinformation on social me-\ndia [10,101]; rather, most people consume news through more\nmainstream platforms like television news [10]. However, sys-\ntematically tracking how misleading, propagandistic, and out-\nright false information spreads from untrustworthy websites\ninto mainstream media and how fringe websites influence\nthe broader news ecosystem remains a significant technicalchallenge due to the magnitude and distributed nature of the\nnews ecosystem [9, 19, 61, 127].\nIn this work, we introduce and validate a system for\nscalably identifying and tracking potentially unreliable news\nstories across different English-language media ecosystems.\nBuilding on past work [3,62,92,145], our proposed approach:\n(1) collects articles by continually crawling news websites\nfrom across media ecosystems; (2) extracts semantic stories\nand articles\u2019 stances towards different topics using a fine-\ntuned version of the e5-base-v2 large language model [138],\nDP-Means clustering [38], and zero-shot stance detection [8];\nand (3) identifies the relationships between news websites\nand broader ecosystems using the NETINF algorithm [49].\nWe note that our approach does not make factual assessments\nof individual stories, which is a deeply nuanced task. Rather,\nour system allows us to shed light on how stories travel\nacross the distributed news ecosystem.\nWe analyze the results from our deployed system across an\n18-month period during which we collected articles from pre-\ncurated lists of 1,003 factually unreliable news websites ( e.g.,\ntwisted.news), 1,012 mixed factuality reliability websites ( e.g.,\nfoxnews.com), and 2,061 factually reliable news websites\n(e.g., washingtonpost.com) maintained by Media-Bias/Fact-\nCheck [33] and Hanley et al., [60]. Analyzing 146K stories\nthat our system extracted from 29M articles on these news\nwebsites, we observe significant crossover in the stories cov-\nered by different news ecosystems [136]. We show that reli-\nable and mixed-reliability news websites play the largest role\nin setting the stories and stories addressed by other websites.\nHowever, despite covering similar topics, our stance analysis\nreveals that each type of website adopts distinctive stances\ntowards shared topics, with factually reliable news websites,\nfor example, generally being left-leaning and pro-Ukraine and\nunreliable websites being the right-leaning and anti-Ukraine.\nFraming our story clusters as cascades, our system uses\nthe NETINF [49] algorithm to uncover relationships between\nnews websites and to detect potential networks of coordinat-\ning websites that spread particular slanted content and sto-\nries. For example, using this approach, we identify a network\nof right-leaning news websites that ostensibly act as local-\nnews websites, all operated by Metric Media, LLC. Using\nthis algorithm, we further identify the websites most influ-\nential in spreading stories amongst unreliable websites ( e.g.,\nthegatewaypundit.com) and the websites from which both re-\nliable and unreliable news websites most commonly adopt sto-\nries ( e.g., dailymail.co.uk and ussanews.com). Additionally,\nwe identify the websites that most effectively promote spe-\ncific types of information across ecosystems like anti-vaccine\nmisinformation (naturalnews.com, theepochtimes.com, and\nvaccines.news) and anti-Ukrainian propaganda (rt.com, sput-\nniknews.com, and news-front.info).\nUltimately, our work introduces an end-to-end system for\nbuilding a wide perspective of the English-language news\necosystem and explores how tracking how stories travel within\nit can help us understand how misleading information en-\nters mainstream news and uncover previously unknown re-\nlationships between news websites. We hope that our ap-\nproach can serve as the foundation for further studies of\nhow information spreads online. Our code and URL data\nare available at https://github .com/hanshanley/tracking-takes\nand https://zenodo .org/records/14656479.\n2 Related Work\nSignificant prior work has studied news ecosystems and an-\nalyzed how information and misinformation spread online.\nHere, we summarize the prior work that our study builds on:\nTracking Narratives on News Websites. Several studies\nhave utilized online document clustering [22,142] for tracking\nnews stories. For example, Zhang et al. [146] identify poten-\ntial events by monitoring the appearance of specific phrases or\nkeywords, clustering identified phrases that may indicate news\nevents, and training a series of classifiers to assign news arti-\ncles to identified clusters. Similarly, by clustering a collection\nof short phrases or \u201cmemes\u201d across news websites and blogs,\nLeskovec et al. find that smaller blogs often play a definitive\nrole in encouraging the adoption of particular language onto\nmainstream websites [85]. Rodriguez et al. [49,50] further ex-\namine the changing relationships between websites during the\ndiscussion of news events, finding that connections between\nwebsites increase during periods of high activity.\nIn a similar vein, while many studies have analyzed topics\nand their spread using statistical word-association approaches\nlike Latent Dirichlet Allocation (LDA) and Dynamic Topic\nModels [5, 100, 147], recent works such as those by Meng\net al. [96], Hanley et al. [56, 61], and Grootendorst [52] have\nused large language models (LLMs) for more granular topic\nmodeling. In line with our work, Nakshatri et al. [104] utilize\npeak detection and HDBSCAN [93] on news article embed-\ndings to identify the most prominent news events in a stream\nof news articles. Saravanakumar et al. [119] similarly uti-\nlize an external named entity recognition system to embedentity knowledge into a BERT language model to differen-\ntiate between news articles about different events. Beyond\nthese quantitative approaches, many prior works have qual-\nitatively investigated the spread of individual news stories\n(e.g., [112, 120, 127]).\nMost similar to our work, Hanley et al. [62], using MP-\nNet and DP-Means clustering, track news narratives across a\nsmaller number of fringe websites to determine the role that\nindividual unreliable news websites play in originating and\namplifying news narratives. Their work finds that less-popular\nwebsites oftentimes play an outsized role in promoting narra-\ntives that reverberate across the unreliable news ecosystem.\nIn contrast to these prior works, our study accounts for\nthestance towards each topic in order to better differentiate\nbetween articles that cover the same topic. Tracking stance\nenables our work to understand the widespread understanding\nof individual websites\u2019 ideological skew, changes in cover-\nage of individual topics, and the detection of websites that\ncoordinate in spreading particular types of propaganda.\nAnalyzing the Spread of Misinformation. While our\napproach is one of the first to track both topics and va-\nlence/stance towards those topics programmatically in service\nof understanding misinformation and propaganda, several\nprior works have focused on the peculiarities, detection, and\nspread of misinformation. For example, Ma et al. [88] and\nJin et al. [71] utilize recurrent neural networks to analyze\nand detect the spread of unreliable rumors on social media.\nAbdali [1] et al., taking a domain-based approach, use website\nscreenshots to assess the credibility of news websites. In addi-\ntion to analyzing the spread of general misinformation on par-\nticular social platforms, other works have further investigated\nthe spread of specific narratives, including those concerning\nthe Syrian White Helmets [127], QAnon [11, 58, 107], the\nRusso-Ukrainian War [59,61,109], and COVID-19 [4,31,89].\nWe note that because work utilizes topic analysis followed by\nstance detection, our system can be used to quickly identify\nwebsites and topics that deserve in-depth investigation, further\nenabling studies of these kinds.\nBuilding off these studies, several works have analyzed the\ncharacteristics of misinformation. Juul and Ugander find that\noften false information on Twitter spreads faster and wider\nthan factual information [73]. Indeed, Kwon et al. [81], utiliz-\ning the distinct temporal differences between reliable informa-\ntion and unreliable rumors, are able to classify these rumors\nwith an F1-score as high as 0.878. In a different work [80],\nKwon et al. analyze the semantic and structural characteristics\nof rumors on Twitter. In a similar vein, using a learning-to-\nrank-based approach and ClaimBuster API, Paudel et al. [108]\nidentify potential claims that should be fact-checked on Twit-\nter [64].\nBeyond studying the dynamics of misinformation, Bak\net al. [15] have proposed concrete steps to ameliorate the\nspread of misinformation, including removal and nudges. Fi-\nnally, Kaiser et al. [74] have studied how borrowing tech-\nNews Article Daily Document StreamArticle T ext and Date Extraction \nCalculate Passage\nEmbeddingsWebsite\nScrapes,\nRSS feeds\nSeparate Document into Passages\nNarrative 1\nNarrative 3Narrative 2\nUpdate Cluster Centers or Create New\nCluster based on Semantic Similarity to\nCurrent ClustersNarrative 402-24-22Russia\ninvaded...\nUkraine\nresponded ...\nRussia\ninvaded...Narrative 2\n Stance\n Detect \nDetermine Stance of T exts within\nNarrative Clusters with Respect \nto Extracted KeywordsPro Neutral AgainstUpdate Cluster Keywords\nwith Pointwise Mutual\nInformation and Extract\nSummaryNews Article\nWebsites\nBias EstimationFigure 1: Our pipeline for identifying, labeling, and extracting the stance of story clusters from the daily publications of news websites.\nniques from the security warning landscape might help inform\nusers of potential misinformation.\nUnlike the past approaches outlined above, by utilizing\nfine-tuned encoder-based large language models, our work\nscalably tracks and identifies unique news stories across thou-\nsands of news websites without depending on particular key-\nwords or by limiting analysis to a subset of unreliable websites\npreviously fact-checked or curated by experts [62, 127]. By\nutilizing network analysis combined with stance detection,\nour work further provides a highly interpretable means of\nunderstanding the spread and dynamics of propagandistic,\nbiased, or factually unreliable stories across multiple media\necosystems.\n3 Methodology\nIn this section, we provide an overview of our data collec-\ntion methodology as well as our approach for extracting and\ntracking stories across different types of news websites.\n3.1 News Websites\nOur study analyzes articles collected from three sets of\nEnglish-language news websites of varying factual reliability.\nWe specifically track stories on websites rated by Media-\nBias/Fact-Check [33], a media monitoring website founded\nby Dave M. Van Zandt to assess the factual reliability of in-\ndividual websites. We use Media-Bias/Fact-Check given its\nwidespread use in prior work [14,62,103,139] and its ratings\u2019\nhigh agreement with other organizations like NewsGuard.\nUnreliable News Websites. We collect news articles from\n1,003 websites labeled as having \u201clow\u201d or \u201cvery low\u201d fac-\ntual reporting by Media-Bias/Fact-Check [33]. We extend\nthis list with conspiracy theory-promoting websites identified\nby Hanley et al. [60]. Our list of unreliable news websites\nincludes pseudo-science websites like vaccine.news, state-\npropaganda outlets such as rt.com, and partisan websiteswith low-factuality ratings like the liberal-leaning occupy-\ndemocrats.com.\nMixed-Reliability News Websites. We collect articles from\n1,012 mixed-reliability news websites labeled as having\n\u201cmixed\u201d factual reporting by Media-Bias/Fact-Check [33].\nThis list includes websites across the political spectrum, such\nas foxnews.com, nypost.com, and theguardian.com.\nReliable News Websites. We collect articles from 2,061 re-\nliable news websites labeled as having \u201chigh\u201d, \u201cvery high\u201d,\nor \u201cmostly factual\u201d reporting by Media-Bias/Fact-Check [33].\nThe category \u201cmostly factual\u201d is included to capture sources\nwith strong reputations like The Washington Post. This list\nalso features websites such as reuters.com and apnews.com.\nWe lastly note that we utilize the full set of English-language\nnews websites from the lists of Media-Bias/Fact-Check [33]\nand Hanley et al. [60] that were accessible to us from the\nbeginning of our study.\n3.2 Definition of a News Story\nOur approach tracks specific news stories and their propaga-\ntion across websites rather than analyzing broader themes as\ncaptured by methods like LDA [7,36,70]. Following previous\nresearch [61, 62], we adopt Event Registry\u2019s definition of a\nnews story as \u201ccollections of documents that seek to address\nthe same event orissue \u201d [83, 98]. It is important to note that\neven if two ideas are related, they may not constitute the same\nnews story. For example, while \u201cFlorida Governor Ron De-\nSantis declares for President\u201d and \u201cNikki Haley surpasses\nRon DeSantis in the polls\u201d are related, they are considered\nseparate news stories in our work.\n3.3 System Architecture\nOur approach for capturing and tracking news stories builds\non the LLM-based story tracking methodology introduced\nby Hanley et al. [62]. However, while Hanley et al.\u2019s method\nall-mpnet all-mpnet e5-base-v2\nBERT USE specious peft+lora peft+lora\n0.464 0.749 0.856 0.860 0.866\nTable 1: Model Performance on SemEval STS Benchmark. Our\nPEFT+LoRA models fine-tuned using unsupervised contrastive loss\nperform better than prior work [26, 27, 37, 62, 114].\nscalably tracks individual topics, their work does not incor-\nporate articles\u2019 attitudes towards a topic. While this was not\nproblematic for their work, which focused on the spread of\nstories amongst unreliable news websites, their approach can-\nnot track news stories across a broader set of news websites\nthat present stories in dramatically different ways. We expand\ntheir method to additionally account for the stance /valence\nof news articles towards a topic ( i.e., we distinguish between\narticles that cover vaccines positively vs. negatively).\nAs shown in Figure 1, our system identifies stories by:\n(1) scraping articles from news websites, (2) splitting arti-\ncles into passages of 100 words [62, 110], (3) embedding\npassages with a fine-tuned LLM [138], and (4) clustering\nnews articles using an optimized version of the DP-Means\nalgorithm [38, 72]. To describe clusters that each represent a\nstory, we extract keywords from the resulting cluster using\npointwise mutual information (PMI) and performing multi-\ndocument summarization with an open-source LLM. Build-\ning on the clusters, we utilize network inference techniques\nto identify website relationships and zero-shot stance detec-\ntion [8, 55] to determine the stance/position of individual\npassages within each cluster. Finally, based on individual\nwebsites\u2019 stances toward their given topics, we perform bias\nestimation to quantify websites\u2019 biases along various political\nand non-political axes. We detail each stage below:\nCollecting and Preparing News Articles. We crawl our\nset of 4,076 websites daily using the Go Colly library [125]\nfrom January 1, 2022 to July 1, 2023. Each day, we collect\nevery website\u2019s homepage, RSS feeds, and linked articles. We\ncollected a total 29.0M articles: 17.9M articles from reliable\nnews websites (median 2,467 articles/site), 8.7M articles from\nmixed-reliability news websites (median 964 articles/site),\nand 2.5M articles from unreliable news websites (median\n219 articles/site). We provide to URLs researchers on request.\nTo prepare our news article data for embedding, we first\nremove any URLs, emojis, and HTML tags from the text.\nThen, in line with prior work, after first separating articles into\nparagraphs by splitting text on ( \\n) or tab ( \\t) characters [57],\nwe subsequently divide paragraph into constituent passages\nwith at most 100 words [57, 61, 110]. This enables us to fit\npassages into the context window of our LLM embedding\nmodel. Further, given that articles often address multiple ideas,\nembedding passages allows us to track the often single idea\npresent within the passage [57, 110]. Our dataset consists of\n428M passages. For additional details, see Appendix A.Embedding Passages. Before embedding our articles\u2019 pas-\nsages, to ensure that our embedding model is attuned to the\nlanguage of news articles, we tailor our model to our do-\nmain of our collected articles using Parameter Efficient Fine-\nTuning /PEFT [86] through Low-Rank Adaption /LoRA [69]\nwith an unsupervised contrastive learning loss based on\nSimCSE [47]. Rather than directly fine-tuning the original\nmodel\u2019s weights as in Hanley et al. [62], this approach freezes\nthe originally trained large language model and introduces an\nadditional set of parameters of reduced dimensionality that are\nthen fine-tuned, allowing for better generalizability [69]. We\nutilize default LoRA hyperparameters of rank=8 and \u03b1=16.1\nSee Appendix B and C for additional details. We utilize cosine\nsimilarity of embeddings to determine passages\u2019 estimated\nsemantic similarity [28, 47, 52, 110].\nWe specifically fine-tune and evaluate two public open-\nsource large language models, e5-base-v2 [138] and\nMPNet [126] using this approach. We benchmark these two\nfine-tuned models on the SemEval STS-benchmark (Table 1)\nand find that our models outperform prior work as gen-\neral models for semantic similarity. We use the fine-tuned\ne5-base-v2 model in this work given its top performance.\nStory Identification. We base our story-identification algo-\nrithm on Dinari et al.\u2019s optimized and parallelizable version\nof the DP-Means algorithm, a non-parametric version of K-\nmeans [38] (see Appendix E). We utilize this approach as\nit is highly scalable (able to cluster our 428M embeddings)\nunlike other LLM-based approaches [52] while also allow-\ning us to identify stories without a priori knowledge. To\nfurther scale the approach, we re-implement DP-Means [38]\nto use the GPU-enhanced FAISS library [72] to perform the\nembedding-to-cluster assignments and similarity calculations\nrequired by DP-Means. To determine a suitable threshold\nfor clustering two news passages together, after fine-tuning\ne5-base-v2 , we benchmark our model on the English portion\nof the SemEval 2022 Task 8 dataset [29] (see Appendix F).\nThe SemEval 2022 Task 8 dataset consists of two parallel\nlists of news articles where each pair is graded on whether\nthey are about the same news story. Our model achieves a\nmax F1-score of 0.793 on this dataset near a cosine similarity\nthreshold of 0.50, which we use in this work. We provide\nexamples of passage pairs in the Supplementary Material.2\nFrom January 1, 2022 to July 1, 2023, clustering all our em-\nbeddings required the equivalent of 12 days using an NVIDIA\nA100 GPU. After clustering, like in other works [62, 85], we\nfilter out clusters where 50% or more of the passages are from\nonly one website ( e.g., website-specific headers or author\nbios). After this pruning, we identified 146,212 story clusters.\nWe provide 30 cluster examples in Appendix G and evaluate\nthese 30 clusters to ensure that they contain coherent stories\nusing the method outlined by Hanley et al. [62]. We achieve\n1https://huggingface .co/docs/peft/task_guides/semantic-similarity-lora\n2https://www .hanshanley .com/files/tracking_supp_material .pdf\nan estimated precision of 99.3% of assigning passages to\nappropriate story clusters where each passage matches the\nsummary, keywords, and other passages in the cluster.\nStory Summarization and Labeling. To build human-\nunderstandable representations of our clusters, we extract\nkeywords using pointwise mutual information (PMI), an\ninformation-theoretic for uncovering associations [23], to un-\ncover the words most associated with each story cluster [59].\nTo make these words more uniform, we lemmatize each word\nin each cluster. For additional details, see Appendix D. In\naddition to keyword extraction, we perform multi-document\nsummarization utilizing an instruction fine-tuned version of\nLlama 3 [39].3This enables us to summarize the different\nperspectives of the passages within a given cluster, while also\nallowing humans to easily understand a story cluster\u2019s con-\ntents. We utilize the following prompt to summarize the con-\ntents of each of our clusters: You work for a news researcher\nand your job is to summarize articles. Write a single concise\ncollective abstractive summary of the texts, where individual\ntexts are separated by |||||, and return your response as a\nsingle summary that covers the key points of the text.\nWebsite Relationship Inference. To further understand the\nrelationships between news websites, we analyze how sto-\nries spread across websites over time. We consider the set\nof articles in a cluster as a time cascade based on the date\nthat each article was published, and we use an open-source\nversion of NETINF [49] to infer the underlying structure and\nrelationship amongst our set of news websites.4Given a set\nof time cascades ( e.g., the time steps for when a particular\nwebsite posts an article within a given story cluster), while\nassuming that each node in a particular cascade is influenced\nby exactly one other node, the NETINF algorithm attempts to\ninfer the optimal network to explain the observed posting be-\nhavior [49]. Based on each website\u2019s posting behavior across\nthe different cascades, NETINF estimates the number of times\nthat each website copied information from another as well as\nthe time delay between copies. We provide additional details\nabout the NETINF algorithm in the Supplementary Material.5\nStance Detection. While passages may cover the same\nstory, they often adopt different stances [61,78,99] in address-\ning the same event. After identifying the stories on our set\nof news websites, we employ stance detection to understand\nhow different websites address each story. More concretely,\nstance detection methods determine the attitude of an author\ntoward a specific topic or target [20]. Typically, stance de-\ntection involves taking a passage piand a topic or target ti,\nand outputting the stance si\u2208 {Pro,Against ,Neutral }of the\npassage pitowards the target ti, where the target is a noun or a\nnoun phrase . Given that most stance detection methods heav-\nily rely on the topic or target, with many models struggling to\n3https://huggingface .co/meta-llama/Meta-Llama-3 .1-8B-Instruct\n4https://snap .stanford .edu/netinf/\n5https://www .hanshanley .com/files/tracking_supp_material .pdfgeneralize to topics or targets outside their domain, various\nmodels have been developed to perform stance detection in\nzero-shot (where the tested topics or targets are not in the\ntraining data) and few-shot (where very few examples of the\ntested topics or targets are in the training data) settings [8,87].\nTo perform this stance detection, we utilize the current state-\nof-the-art zero-shot TATA model [55], which was trained on\nthe V AST dataset [8]. We note that the size of our dataset of\nstance pairs precluded us from using popular large language\nmodel services like GPT-4 or Claude Sonnet. To enhance this\nmodel, we retrained it on both the V AST dataset and news-\nspecific stance detection NewsMTSC dataset [53]. By training\nthe TATA model using this extended dataset, we achieved\nstate-of-the-art F1scores of 0.781in the zero-shot setting and\n0.741in the few-shot setting on the V AST test dataset, and a\nmacro F1score of 0 .849 on the NewsMTSC test dataset.\nRather than performing stance detection on a pre-\ndetermined set of topics [51,78,82], we leverage our topic and\nstory modeling to conduct stance detection across each story\ncluster. This is such that, after we extract story keywords us-\ning PMI, we utilize the Python NLTK library\u2019s Part-of-Speech\n(POS) tagging function to identify the most distinctive noun\nkeywords [21], capturing the topic addressed in each pas-\nsage. We further use the NLTK library to filter out common\nfirst names ( e.g., Michael, Jessica) from our stance detection\nalgorithm and employ the Python spaCy library [135] to ex-\nclude nouns that fall into the following categories: FAC, LOC,\nWORK_OF_ART, DATE, TIME, PERCENT, MONEY, QUAN-\nTITY, ORDINAL, CARDINAL . This approach ensures that\npassages are not erroneously categorized as ProorAgainst\nparticular dates or monetary amounts. To ensure robust mea-\nsurements of ecosystems\u2019 and websites\u2019 stances toward spe-\ncific entities, we gather the top 5,000 noun entities ( i.e. popu-\nlar topics ) from our data and perform stance detection on each\npassage within each cluster where it appears among the top\n10 PMI keywords. Altogether, this process involves running\nstance detection on 96.3M passage and keyword pairs.\nInterpretable Mapping of Websites\u2019 Biases. A simplistic\napproach to understanding a website\u2019s overall bias ( i.e., how\nanti or pro) toward an entity such as \u201cUkraine\u201d would in-\nvolve aggregating the percentage of their articles that had pro-\n\u201cUkraine\u201d and anti-\u201cUkraine\u201d stances ( i.e., % pro-Ukraine\narticles \u2212%anti-Ukraine articles). However, this approach\ncould potentially fail given that some websites may not have\nan abundance of articles focused on Ukraine or may only\ndiscuss Ukraine-related entities to obfuscate their bias. As\nsuch, taking inspiration from Waller et al. [137] who train\nWord2Vec models to predict subreddit\u2019s biases, we instead\ntake a holistic approach by aggregating each website\u2019s respec-\ntive stances to all their written-about entities and predicting\nbias via Bayesian regression models.\nTo estimate websites\u2019 bias toward a given subject along an\naxis, we first gather a seed set of websites with at least 250 ar-\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Pro-Democrat -> Pro-Republican)wethepeopledaily.comgopdailybrief.comfreespeech.orgblackpressusa.comReliable (\u00b5=-0.21)\nMixed (\u00b5=0.24)\nUnreliable (\u00b5=0.58)Figure 2: Partisanship of our websites based on their stances to their\narticles\u2019 topics; estimated by Bayesian regression.\nticles6discussing the entity and compute their simplistic bias\nscore ( i.e., % pro-entity articles \u2212% anti-entity articles). To\nmake these values more interpretable, we normalize these\nscores as z-scores ( i.e., mean 0 and variance 1), such that\na score of 1.0 can be interpreted as bias in favor of entity\none standard deviation above the mean [137]. Following this\ncalculation, we subsequently train a linear Bayesian regres-\nsion model with L2regularization to predict this bias score\nby utilizing our seed set of websites\u2019 stances to other entities\n(besides the one in question). Finally, once trained, using the\nmodel, we estimate the rest of our websites\u2019 bias scores to the\ngiven entity. We adopt a Bayesian approach as this directly\nenables us to quantify how individual stances contribute to\nour prediction of a website\u2019s bias to a particular entity.\nTo validate this approach, we mapped our websites to par-\ntisanship scores along the U.S. left\u2013right political spectrum\n(Figure 2) using the keywords \u201cdemocrat\u201d and \u201crepublican,\u201d\nand a seed set of 105 websites. The partisanship scores from\nthe resulting model had a \u03c1=0.51Spearman correlation with\nthe partisanship labels (Far-Right, Right, Right-Center, Cen-\nter, Left-Center, etc.) provided by Media-Bias/Fact-Check.\nAs seen in Table 2, some of the most right-leaning partisan\nstances included positive stances towards Dinesh D\u2019Souza, a\nright-leaning commentator [140] and America, while having\na negative stance toward communism. On the Democratic\nside, the associated stances include being against Texas, con-\nservatives, and the former Republican congressman George\nSantos. Similarly, as seen in Figure 2, matching the partisan\nlabels from Media-Bias/Fact-Check, we broadly observe that\nour set of reliable websites is left-leaning and the unreliable\nwebsites are right-leaning.\n4 Characterizing News Ecosystems\nHaving detailed our methodology, we now characterize the\necosystems of reliable, mixed reliability, and unreliable news\n6This ensures that the margin of error for probabilities is below 0.10 with\na 95% confidence interval based on the normal distribution.Republican Stances Coeff. Std.\nPro Souza 0.311 0.083\nPro America 0.245 0.122\nAgainst Communist 0.215 0.102\nDemocratic Stances Coeff. Std.\nAgainst Santos -0.323 0.105\nAgainst Texas -0.315 0.075\nAgainst Conservative -0.282 0.098\nTable 2: The stances most associated with U.S. partisan factions;\nestimated by Bayesian regression.\nReliable News Mixed News Unreliable News\nPro CDC Against Kardashian Against Pfizer\nPro Quantum Pro Gunnar Against Vaccine\nPro Senate Pro Alnassar Against Wuhan\nTable 3: Keywords most associated with each news ecosystem;\nestimated using PMI.\nwebsites. Visualized in Figure 3, the most heavily discussed\nstories among our set of reliable news websites included\nthe U.S. Republican primary (62,911 articles), business\nnews quarterly revenue (57,453 articles), the U.S. Supreme\nCourt\u2019s decision to overturn federal abortion rights (Roe v.\nWade) (38,358 articles), and the Russian invasion of Ukraine\n(35,135 articles). Looking at the top stories spread by un-\nreliable news websites, we observe many of the same sto-\nries, most notably one concerning the U.S. Republican pri-\nmary (13,393 articles). Indeed, across all shared story clusters\n(91,390 stories, 62.5%), we observe an average Pearson cor-\nrelation of 0.501 between the volume of articles from our\nunreliable and reliable news websites. Beyond these shared\nstories, we observe on unreliable websites a focus on corrup-\ntion and government failures (9,094 articles), the U.S. Federal\nBureau of Investigation\u2019s (FBI) search of President Donald\nTrump\u2019s Mar-a-Lago estate (7,678 articles), and the investi-\ngation into Hunter Biden\u2019s (U.S. President Joe Biden\u2019s son)\nlaptop (7,509 articles) [105]. For our set of mixed-reliability\nnews websites, we observe a heavy focus on sports and pop\nculture; two of the top five stories focus on the celebrity Kar-\ndashian family and one on the footballer Cristiano Ronaldo.\nMixed-reliability news volume is also highly correlated with\nthe volume of stories on reliable (127,106/86.9% shared sto-\nries with a \u03c1=0.689Pearson correlation for the story vol-\numes) and unreliable news websites (91,205/62.4% shared\nstories with a \u03c1=0.646). We detail each ecosystem\u2019s stories\n(i.e., the number of articles about each story as well as their\nsummaries) in the Supplementary Material.7\nUsing the stance of each website toward the top 5,000 enti-\nties in our dataset, as output by our augmented TATA model,\nwe further characterize the attitudes of our reliable, mixed-\n7https://www .hanshanley .com/files/tracking_supp_material .pdf\nThe indictment of Donald Trump comes as his Super PAC spends $1.3 million to attack potential 2024 Republican primary challenger Ron DeSantis. Meanwhile, DeSantis has been focusing on his own presidential campaign, taking a confrontational stance against Trump\nKey companies in the financial sector reported significant year-over-year growth in 2022, with some suffering a significant COVID-19 hitThe international community, particularly the U.S. and Europe, has pledged unwavering support to Ukraine in upholding its sovereignty and territorial integrity, and in defending itself against Russian aggression.Symptoms of respiratory illnesses such as COVID-19, the flu, and common colds often overlap, including fever, cough, sore throat, runny or stuffy nose, and fatigue, making it difficult to determine the specific infection. Tests are necessary to confirm the diagnosis, as symptoms can be similar to other common illnesses like allergies or respiratory conditions. The US Supreme Court's overturning of the landmark 1973 Roe v. Wade decision has given individual states the authority to decide whether abortion should be legal within their borders\nUkrainian President Volodymyr Zelenskyy is facing pressure to protect his troops and maintain public support as Russia gains ground in the Donbas region. Artificial Intelligence (AI) is a complex topic that refers to the simulation of human intelligence in machines, enabling them to think, act, and learn like humans. Small businesses are facing significant challenges due to rising inflation, supply chain issues, and labor shortages, making it harder for them to succeed. The match was characterized by a mix of dominant and even halves, with both teams creating chances but struggling to convert them into goals.Elon Musk's acquisition of Twitter for $44 billion has been tumultuous, with the company's stock value plummeting 65% in 2022 and a 44% drop in December.Figure 3: The most commonly discussed stories on reliable news websites labeled with their LLM-generated summaries.\nreliability, and unreliable news websites. To do this, we utilize\nPMI to determine the non-neutral stances most associated\nwith each ecosystem (we limit this analysis to stances rep-\nresented in at least 500 total articles within each ecosystem\nto avoid spurious values). As seen in Table 3, reliable news\nwebsites are more pro-CDC (Centers for Disease Control),\npro-Quantum, and pro-Senate (than mixed-reliability and un-\nreliable websites). The most distinctive stances of mixed-\nreliability websites concern pop culture and football (Gunnar\nis a Norwegian football manager and Al Nassr Football Club\nis a Saudi-Arabian football team). In contrast, the most dis-\ntinctive stances among the unreliable news websites primarily\nconcern the COVID-19 pandemic, with these websites dis-\ntinctly opposing vaccines, Pfizer (one of the leading compa-\nnies that developed a COVID-19 vaccine), and Wuhan, China\n(the origin of COVID-19) [102].\nThe stances between different news ecosystems are fairly\ndistinctive. Indeed, by fitting a random forest classifier to 80%\n(3,260 websites) of the websites\u2019 stance data based on their\npercentage for and against different entities (using 10% of\nthe websites as validation (408 websites) and 10% as test\ndata), we achieve an accuracy of 85.9% and an AUC of 0.889\nin differentiating unreliable news websites from reliable and\nmixed-reliability websites. This illustrates the ease of differ-\nentiating between types of websites by their stances and the\nability to predict a potentially unlabeled website\u2019s reliability\nbased on its stance towards popular news stories.\nBias Case Study: Ukraine and Vaccines. Beyond the most\ndistinctive stances that each website has, to further understandthe underlying attitudes within each ecosystem, we perform\na case study on each website ecosystem\u2019s attitudes towards\nUkraine andVaccines \u2014two of the most commonly covered\ntopics in our dataset\u2014using the methodology outlined in\nSection 3.3. While this analysis specifically addresses Ukraine\nand vaccines, similar to how we analyzed U.S.-based political\npartisanship in Section 3.3, this approach can be applied to\nany popular entity within our dataset. We additionally present\nanalyses for America, China, and Iran in the Supplementary\nMaterial.8\nPro-Ukraine Stances Coeff. Std.\nPro Zelenskyy 0.378 0.114\nPro Zelensky 0.368 0.110\nAgainst Syria 0.225 0.114\nAnti-Ukraine Stances\nAgainst Zelenskiy -0.500 0.111\nAgainst Biden -0.370 0.103\nAgainst DHS -0.345 0.119\nTable 4: Stances associated with Ukraine; estimated by Bayesian\nregression.\nFitting our Bayesian regression models for both Ukraine\nand vaccines, we map all of our news articles to a bias latent\nfor both entities in Figure 4. We observe that reliable news\nwebsites express higher support for Ukraine and vaccines\n(\u00b5vaccine =0.32, \u00b5ukraine =0.36), while unreliable news web-\nsites oppose both ( \u00b5vaccine =-0.82, \u00b5ukraine =-0.87), and mixed-\n8https://www .hanshanley .com/files/tracking_supp_material .pdf\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Anti-Ukraine -> Pro-Ukraine)europereloaded.comzerohedge.com\nbipartisanpolicy.org\nconservativefighters.coReliable (\u00b5=0.36)\nMixed (\u00b5=0.04)\nUnreliable (\u00b5=-0.87)\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Anti-Vaccines -> Pro-Vaccines)vaccines.newspatrioticviralnews.com\nwho.int\nhopkinsmedicine.orgReliable (\u00b5=0.32)\nMixed (\u00b5=-0.11)\nUnreliable (\u00b5=-0.82)Figure 4: Distribution of Ukraine and vaccine bias across unreliable, mixed-reliability, and reliable news websites; estimated by Bayesian\nregression.\nPro-Vaccine Stances Coeff. Std.\nPro Ukraine 0.343 0.111\nPro Trans 0.259 0.110\nPro Healthcare 0.233 0.093\nAnti-Vaccine Stances\nAgainst COVID -0.360 0.144\nAgainst FDA -0.334 0.122\nAgainst Pfizer-BioNTech -0.333 0.143\nTable 5: Stances associated with vaccines; estimated by Bayesian\nregression.\nreliability websites in the middle ( \u00b5vaccine =\u22120.11,\u00b5ukraine =\n0.04). This largely matches the original article stance distri-\nbution where we found that 31.9% of unreliable news articles\nwere anti-Ukraine and 23.8% were anti-vaccine; for mixed-\nreliability websites, 17.8% were anti-Ukraine and 8.5% were\nanti-vaccine; and for reliable news websites 12.9% of articles\nwere anti-Ukraine and 7.1% were anti-vaccine.\nAmong our dataset, the news websites most anti-Ukraine\ninclude rt.com ( zukraine = -2.36), strategic-culture.org ( zukraine\n= -2.54), and southfront.org ( zukraine = -2.41) \u2014 three web-\nsites known for spreading Russian propaganda [106]. Some of\nthe most pro-Ukraine websites include nationaljournal.com\n(zukraine = +2.53), a U.S. political policy-oriented website,\nkyivpost.com ( zukraine = +0.80), a Ukrainian website, as well\nas a selection of NBC and ABC affiliate websites including\nwbaltv.com ( zukraine = +2.04), wvtm13.com ( zukraine = +2.14),\nand ketv.com ( zukraine = +2.55) [33]. The most anti-vaccine\nwebsites include vaccineimpact.com ( zvaccine = -3.41) and\npantsonfirenews.com ( zvaccine = -2.56), both known for spread-\ning misinformation [33]. Conversely, the most pro-vaccine\nwebsites include Johns Hopkins ( zvaccine = +1.28) and the\nWorld Health Organization ( zvaccine = +0.94).\nExamining the stances most associated with each topic\nlatent (Tables 4 and 5), we observe that for Ukraine, this in-\ncludes stances concerning the current president of Ukraine,V olodymyr Zelensky [131]. Beyond this entity, we further\nobserve the entities associated with attitudes towards toward\nUkraine include other Ukrainian allies ( e.g., Biden and DHS)\nand countries in the Global South that have battled for atten-\ntion and aid following the Russian invasion of Ukraine [25].\nFor the vaccine latent, we observe that the stances most associ-\nated with being pro vaccines have to do with being pro-health\ninterventions like healthcare, as well as left-leaning causes\nlike transgender rights and Ukraine [75, 77]. In contrast, we\nobserve that being against vaccines is associated with being\nagainst COVID (the cause of the polarization of vaccina-\ntion [75]), the U.S. Food and Drug Administration (FDA),\nand Pfizer, one of the companies that developed COVID-19\nvaccines [75, 122].\n5 Underlying Website Relationships\nAs observed in Section 4, unreliable, mixed-reliability, and\nreliable news websites often cover the same stories simultane-\nously, suggesting an interdependence [127]. To further under-\nstand these relationships, we utilize an open source version\nof the NETINF [49] algorithm to infer the underlying struc-\nture and relationships amongst our sets of news websites [85].\nSpecifically, we first run NETINF using all of the extracted\nstories within our dataset as time cascades. To determine the\nappropriate number of iterations to run NETINF algorithm, as\nin Gomez et al. [49], we utilize the point at which the marginal\ngain within the algorithm of adding new edges plateaus (90%\nof the total marginal gain; see Supplemental Material9for\nadditional details).\nEcosystem Relationships Across All News Stories. Using\nthe estimated number of copies between websites and the\ntime delay between copies as found by NETINF, we first\nexamine the overall relationships between ecosystems. We\nfind that reliable and mixed-reliability news websites have\na large role in introducing stories adopted by the rest of the\n9https://www .hanshanley .com/files/tracking_supp_material .pdf\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.6 0.29 0.1\n0.43 0.44 0.13\n0.32 0.41 0.27\n0.20.30.40.50.6(a) Copies for All Stories\nReliable Mixed Unreliable\nCopied fromReliable Mixed UnreliableCopied to-1.07 days -0.44 days 7.81 days\n-1.87 days -1.51 days 4.64 days\n2.41 days 0.71 days 2.08 days\n0246 (b)\u2206-Copy Times for All Stories\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.22 0.34 0.44\n0.12 0.35 0.53\n0.041 0.21 0.75\n0.10.20.30.40.50.60.7 (c) Copies for Unrel. Stories\nReliable Mixed Unreliable\nCopied fromReliable Mixed UnreliableCopied to1.67 days 2.96 days 8.40 days\n0.17 days -3.47 days 2.16 days\n-3.40 days -5.35 days -2.09 days\n4\n2\n02468 (d)\u2206-Copy Times for Unrel. Stories\nFigure 5: The percentage of each ecosystem\u2019s copied stories that came from each different ecosystem as well as the change in the average time\ndelay between website copy/reposting of stories depending on the combination of news ecosystems.\nnews ecosystem. As seen in Figure 5a, 60% of the news\narticles on reliable news websites that were copied/influenced\nfrom elsewhere came from other reliable news websites, 43%\non mixed-reliability websites came from reliable websites,\nand 32% on unreliable websites came from reliable websites.\nUnreliable news websites had significantly less influence;\nonly 10% of the copied stories on reliable news websites\noriginated from unreliable news websites (13% for mixed-\nreliability, 27% for unreliable).\nLooking at the set of reliable websites that are the most\ncommon sources of copied stories throughout the entire news\necosystem, we see several popular websites including ya-\nhoo.com (1.19%), apnews.com (0.73%), abcnews.go.com\n(0.60%), and cnn.com (0.60%). Despite popular reliable news\nwebsites being common sources, website popularity had only\na slight Pearson correlation with their percentage of copies.\nUsing data from the Google Chrome User Report (CrUX)\nfrom October 2022 (which Ruth et al. [116,117] showed to be\nthe most reliable website popularity metric), we find that for\nunreliable news websites copying from reliable websites, the\ncorresponding reliable websites\u2019 popularity had a correlation\nof\u03c1=0.225 ( \u03c1=0.189 for reliable websites copying from reli-\nable websites, \u03c1=0.311 for mixed-reliability news websites\ncopying from reliable websites).\nAs seen in Figure 5b, reliable news websites adopt the\nstories of other reliable news websites more quickly (-1.07\ndays) compared to the average copy delay (38.4 days). Mann-\nWhitney U-tests indicate that these differences are all signif-\nicant. This compares to a nearly +7.81 day additional delay\nof reliable news websites picking up the stories from unre-\nliable news websites and -0.44 days from mixed-reliability\nwebsites. We find a similar pattern amongst mixed-reliability\nwebsites, which adopt stories from reliable news websites\n(-1.87 days) more quickly than from unreliable news websites\n(+4.64 days).\nInfluence on the Full News Ecosystem. Having examined\nthe website copies and rates of adoption between the different\necosystems, we next consider which websites are the most\ninfluential using the graph of the edge connections between\nindividual news websites. Eigenvector centralities are oftenutilized to determine the relative influence of nodes within\ngraphs [115] and, as such, we utilize this metric to understand\nwebsites\u2019 influence. We further compute hub centralities as a\nmetric for websites\u2019 influence in originating stories that spread\nto other websites (given the directionality of the arrows in\nour graph, this metric determines the most important websites\nfor supplying content [76]). We show the most influential\nwebsites in Table 6 and Figure 6.\nAll stories Hub Eign.\nyahoo.com 0.149 0.111\napnews.com 0.101 0.092\ndailymail.co.uk 0.097 0.099\nnypost.com 0.052 0.076\nindependent.co.uk 0.049 0.097\nTable 6: Websites with the largest influence in the underlying influ-\nence graph determined by NETINF with all stories considered.\nWe find that website popularity is moderately correlated\nwith the relative influence of websites within the news ecosys-\ntems (when looking at all news websites compared to only\nreliable websites in the last section). Again using website pop-\nularity data from the Google Chrome User Report (CrUX),\nwe find that a website\u2019s eigenvector centrality/influence has a\nSpearman correlation of \u03c1=0.571 (0.396 for hub centrality)\nwith that website\u2019s popularity rank.\nDespite making up 24.6% of the news websites in our\ndataset, unreliable news websites do not make up a propor-\ntional percentage amongst the most influential news websites.\nDirectly comparing the eigenvector centralities of the reli-\nable news websites to those of the unreliable news websites,\nwe find that reliable news websites are significantly more\ninfluential in this ecosystem than unreliable news websites\n(Cohen\u2019s D = 0.64, p-value \u22480),10with mixed reliability\nwebsites having comparable influence to reliable ones (no sig-\nnificant difference through Mann Whitney U-test). In terms of\norigination (hub centralities), we observe a slightly different\ntrend with mixed-reliability websites having slightly more\n10The p-value is computed using the Mann-Whitney U-test.\ndailymail.co.ukdailymail.co.ukyahoo.comyahoo.com\nindependent.co.ukindependent.co.uktheguardian.comtheguardian.com\nthe-sun.comthe-sun.com\nthesun.co.ukthesun.co.ukmetro.co.ukmetro.co.uk\ndailystar.co.ukdailystar.co.uknypost.comnypost.comcnn.comcnn.com\napnews.comapnews.com\ntheepochtimes.comtheepochtimes.combusinessinsider.combusinessinsider.com\ncbsnews.comcbsnews.comabcnews.go.comabcnews.go.com\nbreitbart.combreitbart.com\nnewsweek.comnewsweek.comwashingtonpost.comwashingtonpost.com\nforbes.comforbes.comheadtopics.comheadtopics.comupi.comupi.com\nusatoday.comusatoday.comreuters.comreuters.comwn.comwn.comnewsbreak.comnewsbreak.com latimes.comlatimes.com\nthehill.comthehill.comindianexpress.comindianexpress.com\nfoxnews.comfoxnews.com\nnecn.comnecn.comthenationalnews.comthenationalnews.commercurynews.commercurynews.com\nsandiegouniontribune.comsandiegouniontribune.comkhon2.comkhon2.com\nabovetopsecret.comabovetopsecret.comibtimes.comibtimes.combostonglobe.combostonglobe.comwavy.comwavy.comFigure 6: The most influential websites and their interactions. The\nsizes of nodes are proportional to their hub centrality. Reliable news\nwebsites are colored blue, mixed-reliability websites are colored\ngrey, and unreliable news websites are colored red.\ninfluence in originating stories compared to reliable news\nwebsites (Cohen\u2019s D = 0.04, p-value \u22480) and unreliable\nnews websites (Cohen\u2019s D = 0.05, p-value \u22480).\nSpread by Unreliable News Stories. To understand the\ndynamics of the spread of potentially factually unreliable sto-\nries, we run the NETINF algorithm on the set of 6,762 news\nstories where unreliable news websites posted a plurality\nof articles about those stories. The most popular story\namongst these clusters was about government censorship and\ncontrol (9,094 articles) summarized as: There is censorship,\npropaganda, and government control in the U.S. Cancel\nculture is a form of censorship, and that government-funded\nmedia outlets can exercise control over editorial content.\nThe text also warns about the influence of the \u201cDeep State\u201d\nand far-left communists in U.S. institutions, including the\ngovernment, media, education, and Big Business.\nAs expected, given how we narrow our set of stories, as\nseen in Figure 5c, relative to all news stories, unreliable news\nwebsites had significantly more influence in originating po-\ntentially unreliable content. For example, while for all sto-\nries, reliable news websites sourced less than 10% of all of\ntheir copied stories from unreliable news websites, within\nthis specific set of news stories, the figure was 44%. Simi-\nlarly, for mixed-reliability websites, this percentage increased\nfrom 13% to 53%. Furthermore, we find that unreliable web-\nsites source the majority of their influenced or copied stories\nfrom other unreliable news websites, at a rate of 75%. Look-\ning at the set of websites that are the common source for\nother websites to copy from (Table 7), we find a heavy re-\nliance on dailymail.co.uk, a United Kingdom-based tabloidReliable Propor.\ndailymail.co.uk 0.140\nabovetopsecret.com 0.039\nussanews.com 0.035\nMixed\ndailymail.co.uk 0.062\nthegatewaypundit.com 0.030\nussanews.com 0.027\nUnreliable\nnaturalnews.com 0.025\nussanews.com 0.021\ntheburningplatform.com 0.020\nTable 7: Websites that are the most common source of unreliable\nnews stories for each news ecosystem.\nthat Media-Bias/Fact-Check describes as having \u201clow\u201d fac-\ntual reporting due to \u201cnumerous failed fact checks and poor\ninformation sourcing.\u201d We also find that ussanews.com, de-\nscribed by Media-Bias/Fact-Check as promoting \u201centirely\nfalse, so-called facts,\u201d was a common source of potentially\nunreliable news stories.\nFor this selection of news stories predominately published\nby unreliable news websites, comparing the copy times of\nthese stories in Figure 5d to those in Figure 5b, we find that\nreliable news websites are slower to adopt the stories, regard-\nless of from which news ecosystem the story originated. We\nthus observe a reticence amongst our reliable news websites\nto report on the news stories primarily spread by unreliable\nnews outlets. However, we find that for mixed-reliability web-\nsites, if the news story began amongst other mixed-reliability\nnews outlets, these news outlets are faster to adopt the story\n(-3.47 days). We further observe that unreliable news websites\nare the fastest at picking up these news stories comparatively,\npicking them up quicker if they initially came from a mixed-\nreliability (-5.35 days) or a reliable news website (-3.40 days).\nPredom. Unreliable News Stories Hub Eign.\nthegatewaypundit.com 0.129 0.109\ndailymail.co.uk 0.075 0.125\ntheburningplatform.com 0.060 0.103\nTable 8: Websites with the largest influence in the underlying influ-\nence graph for stories predominately spread by unreliable websites.\nInfluence in the Unreliable News Ecosystem. To under-\nstand which websites are the most influential in the unreli-\nable news ecosystem, we utilize the eigenvector centrality\nof each website in the resultant graph created by running\nNETINF on our set of predominantly unreliable news sto-\nries (Table 8). For this ecosystem, we find the popularity\nof websites is only slightly correlated with eigenvector cen-\ntrality/influence ( \u03c1= 0.158) and hub centrality ( \u03c1= 0.175).\nnaturalnews.comnaturalnews.comnoqreport.comnoqreport.com\nsurvivethenews.comsurvivethenews.combeforeitsnews.combeforeitsnews.comsgtreport.comsgtreport.comlewrockwell.comlewrockwell.com\nussanews.comussanews.comthelibertybeacon.comthelibertybeacon.comlifesitenews.comlifesitenews.com\ntheepochtimes.comtheepochtimes.comtheburningplatform.comtheburningplatform.comchildrenshealthdefense.orgchildrenshealthdefense.org\nwelovetrump.comwelovetrump.comfreerepublic.comfreerepublic.com\nfoxnews.comfoxnews.comthegatewaypundit.comthegatewaypundit.com\nyahoo.comyahoo.com\ndailymail.co.ukdailymail.co.ukdailycaller.comdailycaller.com\nwesternjournal.comwesternjournal.comzerohedge.comzerohedge.com\nnewswars.comnewswars.comabovetopsecret.comabovetopsecret.com\nindependent.co.ukindependent.co.uk\nthesun.co.ukthesun.co.ukbreitbart.combreitbart.comnypost.comnypost.comredstate.comredstate.comwnd.comwnd.comFigure 7: Most influential websites and their interaction for stories\nthat are predominantly spread by unreliable news websites. Nodes\u2019\nsizes are proportional to their hub centralities.\nExamining the set of websites that are most prominent within\nthe unreliable news ecosystem (Table 8 and Figure 7), we\nfind that many well-documented websites known for spread-\ning unreliable information are among the most prominent,\nincluding theepochtimes.com, dailymail.co.uk, and thegate-\nwaypundit.com [127].\nComparing the eigenvector centralities of the unreliable\nnews websites to those of the reliable news websites, we\nfind that unreliable news websites are more influential within\nthis ecosystem (Cohen\u2019s D = 0.219, p-value <0.001), but\nthat unreliable and mixed-reliability websites had comparable\ninfluence (no significant difference via the Mann-Whitney\nU-test). However, most notably, we observe that among the\ntop influencers within this ecosystem are the reliable news\nwebsite, Yahoo News, and the mixed-reliability Fox News (not\nshown in the table). Yahoo News primarily serves as a news\naggregator, gathering reports from various sources including\nFox News, the BBC, and Reuters [143]. Given its role as an\naggregator, Yahoo News appears to have a prominent role\nin disseminating current events that are reported by other\noutlets. Classified as mixed-reliability, Fox News similarly\nhas been widely commented upon for its role in disseminating\nhyperpartisan news and misinformation [18, 34, 67].\nCase Study: News Website Coordination. To identify po-\ntential coordination among our websites in spreading unre-\nliable news, we finally utilize NETINF to discern the rela-\ntionships between websites involved in stories predominantly\npublished articles spread by unreliable and mixed-reliability\nnews websites (encompassing 40,325 news stories). After\nrunning the NETINF algorithm, we clustered the resulting\ngraph using the Louvain clustering algorithm [35]. Qualita-\ntively, the largest of these clusters was comprised of 885 rel-\natively mainstream and tabloid websites that report on gen-\neral news ( e.g., wpxi.com, nbc29.com, wvva.com), with the\ntop stories concerning the Kardashians ( Keywords: Kourt-ney, Kardashian, Travis, Khloe, Barker ). The second largest\ncluster consisted of 492 locally-oriented news websites ( e.g.,\ncbs4local.com, idahostatejournal.com), where the top stories\nfocused on immigration ( Migrant, Border, Patrol, Customs,\nSmuggling ) and the U.S. Constitution ( Constitution, Oath,\nAmendment, Constitutional ). The fourth largest cluster ( Crore,\nYoy, Profit, FY23, Quarter ) included 334 international web-\nsites ( e.g., sputniknews.com, alarabiya.net), where the top\nstory involved international companies\u2019 profits.\nMost notably, however, among our clusters was a set of\n338 websites, all with seemingly innocuous names such\nas southindynews.com and northalaskanews.com, which ap-\npeared to be dedicated to local news. Upon further investiga-\ntion through querying WHOIS, we discovered that each of\nthese websites was registered by the domain registrar Epik,\nInc., a popular provider for misinformation and online hate\nwebsites [54]. We find that this set of 338 ostensibly local\nwebsites is owned and operated by the same entity, Metric\nMedia LLC, which produces algorithmically generated con-\ntent and promotes right-wing views [144]. Indeed, using our\nmapping of websites to their respective political partisanship,\nwe found that despite these websites rarely writing articles\nabout Republicans or Democrats, they have an average parti-\nsanship \u00b5politics =0.22, indicating a slight right-leaning bias,\nwith 88.2% of these websites being classified as right-leaning.\nThese websites largely repeat the same text including arti-\ncles promoting herd immunity from COVID-19 in the United\nStates: More than 50 percent of U.S. citizens are considered\nfully vaccinated against COVID-19, nearing the target for\n\u201cherd immunity\u201d Herd immunity happens when enough of the\npopulation has become immune to the virus from the previous\ninfection that it effectively protects those who are not immune.\n6Propaganda and Slanted Influence Networks\nAs seen in the last sections, news websites, regardless of\ntheir factual reliability, often report on the same stories, with\nunreliable news websites, in select cases, influencing both\nreliable and mixed-reliability news platforms. Furthermore,\nwhile reliable and mixed-reliability news websites predomi-\nnantly adopt stories from other reliable and mixed-reliability\nsources (Figure 5a), for topics primarily spread by unreliable\nnews websites, these specious sources often act as the origina-\ntors of the content (Figure 5c). Within this vein, tracking the\nspread of unreliable news and propaganda and determining\nwhich sources are most effective at seeding these stories into\nthe mainstream media is critical for fact-checkers, journalists,\nand researchers [62, 127]. To this effect, in this section, we\nutilize our system to understand the websites originating and\nspreading specific propaganda and influence campaigns.\nTo map the influence networks targeting specific entities (ei-\nther positively or negatively), we gather news articles and the\nassociated websites that exhibit a particular valence towards\na given entity ( e.g., anti-vaccine articles). Upon gathering this\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.23 0.24 0.53\n0.17 0.22 0.61\n0.12 0.18 0.7\n0.20.30.40.50.60.7Figure 8: Anti-Ukraine Copy Matrix.\nsubset of news articles, we run the NETINF algorithm over\nthese cascades of news article clusters with specific stances.\nWe subsequently perform network analysis using eigenvec-\ntor centrality and hub centrality, as discussed in the previous\nsection, to identify the most prominent and influential web-\nsites promoting a given stance towards a particular subject.\nBy further examining day-to-day increases in news stories\nwith specific stances and comparing their spread in reliable\nand unreliable news ecosystems, we further document new\nindividual stories meant to spread particular views or stances.\nThis programmatic approach can help identify stories that\nare receiving renewed focus from unreliable news websites\nand which websites are influential in propagating stances to-\nwards entities of interest in a particularly damaging manner,\nthereby facilitating the identification and mitigation of misin-\nformation [62, 113, 118, 141]. To illustrate, we perform this\nanalysis for anti-vaccine and anti-Ukraine news stories.\nAnti-Ukraine Hub Eign.\nrt.com 0.155 0.210\nsputniknews.com 0.073 0.129\nnews-front.info 0.054 0.163\nAnti-Vaccine\nnaturalnews.com 0.141 0.179\ntheepochtimes.com 0.086 0.196\nvaccines.news 0.049 0.170\nTable 9: Websites with the largest influence in the underlying influ-\nence graph of anti-vaccine and anti-Ukraine news.\nAnti-Ukraine Messaging. As seen in Figure 9 and Table 9,\nthe most prominent anti-Ukrainian news websites during\nour study included well-known Russian propaganda web-\nsites such as Russia Today (RT), Sputnik News, and News-\nFront [106]. Beyond known Russian propaganda websites,\nwe also find that antiwar.com, described as a \u201clibertarian non-\ninterventionist website\u201d [33], was one of the most prominent\nwebsites in spreading anti-Ukrainian content. Altogether, as\nseen in Figure 8, unreliable news websites largely supply the\nrt.comrt.comtheautomaticearth.comtheautomaticearth.com\nbeforeitsnews.combeforeitsnews.comnews-front.infonews-front.info\ntheburningplatform.comtheburningplatform.comsott.netsott.netzerohedge.comzerohedge.com\nstrategic-culture.orgstrategic-culture.org\nantiwar.comantiwar.com\nussanews.comussanews.commoonofalabama.orgmoonofalabama.orgveteranstoday.comveteranstoday.com\nsputniknews.comsputniknews.comdefenddemocracy.pressdefenddemocracy.press\nbiggovernment.newsbiggovernment.newsasiatimes.comasiatimes.comconservapedia.comconservapedia.com\ntass.comtass.comindependentsentinel.comindependentsentinel.com\nthegatewaypundit.comthegatewaypundit.comthemoscowtimes.comthemoscowtimes.com\ninvestmentwatchblog.cominvestmentwatchblog.com\nfreerepublic.comfreerepublic.comtheduran.comtheduran.com\nabovetopsecret.comabovetopsecret.comnaturalnews.comnaturalnews.com\nsouthfront.orgsouthfront.org\nlewrockwell.comlewrockwell.comnationandstate.comnationandstate.com\nhotair.comhotair.comtelesurenglish.nettelesurenglish.net\ntheconservativetreehouse.comtheconservativetreehouse.comFigure 9: Anti-Ukraine Influence Network determined by the NET-\nINF algorithm. The nodes\u2019 sizes are proportional to their hub cen-\ntralities.\nmajority of the stories used across the entire news ecosys-\ntem, with reliable websites copying 53% of their copied anti-\nUkrainian stories from unreliable outlets, mixed-reliability\nwebsites copying 61%, and unreliable websites 70%.\nThe most common story pushed in this ecosystem of web-\nsites concerned justifications for Russia\u2019s invasion of Ukraine,\nwith one Russia Today article writing [132]: Moscow attacked\nthe neighboring state in late February, following Ukraine\u2019s\nfailure to implement the terms of the Minsk agreements signed\nin 2014, and Russia\u2019s eventual recognition of the Donbass\nrepublics of Donetsk and Lugansk . Further, the anti-Ukrainian\nnews story that received the largest increase in relative popu-\nlarity among our unreliable news websites in the last week of\nour study (June 25 to July 1, 2023) featured a series of articles\nwith the keywords Ukraine, MacGregor, Douglas, Colonel,\nZelensky , showing a ratio of 9 articles in the unreliable news\necosystem for every 1 article in the reliable news ecosystem.\nThis story, which predominantly spread within the unreli-\nable news ecosystem, concerned an interview with retired\nU.S. Colonel Douglas MacGregor suggesting that the war be-\ntween Ukraine and Russia was unwinnable and that Ukrainian\nPresident Zelensky was a puppet of Western powers: \u201cThe\nwar is really over for the Ukrainians. I don\u2019t see anything\nheroic about the man. And I think the most heroic thing he\ncan do right now is to come to terms with reality,\" retired\nArmy Colonel Douglas MacGregor told Fox Business News.\n\"I think Zelensky is a puppet, and he is putting huge numbers\nof his own population in unnecessary risk,\" he said. The web-\nsite that spread this story the most was paulcraigroberts.org\n(zukraine =-3.59, 3 articles).\nBeyond the set of unreliable news websites spreading anti-\nUkrainian messaging, we further observe several international\nnews websites including asiatimes.com ( zukraine =-1.13), the-\nmoscowtimes.com ( zukraine =-0.67), and the right-leaning web-\nsite hotair.com ( zukraine =-1.21) as purveyors of influential\nnaturalnews.comnaturalnews.com\ntheepochtimes.comtheepochtimes.combeforeitsnews.combeforeitsnews.com\nvaccines.newsvaccines.news\npandemic.newspandemic.newstheautomaticearth.comtheautomaticearth.com\nvaccineimpact.comvaccineimpact.com\ntheburningplatform.comtheburningplatform.com\nhealth.newshealth.newsexpose-news.comexpose-news.comlewrockwell.comlewrockwell.comthelibertybeacon.comthelibertybeacon.com\nsurvivethenews.comsurvivethenews.comabovetopsecret.comabovetopsecret.com\naustraliannationalreview.comaustraliannationalreview.comsgtreport.comsgtreport.comnewswars.comnewswars.com\nlifesitenews.comlifesitenews.comchildrenshealthdefense.orgchildrenshealthdefense.orgFigure 10: Anti-Vaccine Influence Network determined by NETINF.\nThe nodes\u2019 sizes are proportional to their hub centralities.\nanti-Ukrainian content in this ecosystem. Based on the inward-\nweighted edges, the most influenced mainstream news website\nin this ecosystem was haaretz.com, an Israeli outlet ( zukraine\n=+0.002 for Ukraine bias), and the most influenced mixed-\nreliability news website was salon.com ( zukraine = -0.056),\na US-based left-leaning news outlet. We thus observe that\neven relatively neutral and pro-Ukrainian websites can be\npotentially influenced by anti-Ukrainian news articles.\nAnti-Vaccine Messaging. As seen in Figure 10 and Ta-\nble 9, the largest source of anti-vaccine stories was natural-\nnews.com, while the most influential anti-vaccine website was\ntheepochtimes.com, both known for spreading anti-vaccine\nmisinformation [33, 111]. As with anti-Ukraine stories, we\nobserve that each website category predominantly sourced\ntheir content from unreliable news websites: 51% for reliable\nnews websites, 66% for mixed-reliability news websites, and\n81% for unreliable news websites (Figure 11). In addition\nto the theepochtimes.com and naturalnews.com, we find that\nchildrenshealthdefense.org, a website associated with former\npresidential candidate Robert F. Kennedy Jr., had a major\ninfluence on spreading anti-vaccine content, including one\narticle suggesting that a vaccine was not as safe as the U.S.\nFood and Drug Administration claimed [30].\nThe most prominent-anti-vaccine story in terms of article\nvolume raised concerns about children receiving COVID-19\nvaccines, as highlighted by childrenshealthdefense.org [97]:\nPfizer, at the urging of federal health officials, is hustling to\nget infants and toddlers injected with experimental COVID\nvaccines . The story that saw the largest relative increase in\nnews articles in the last week of our study (14 articles in\nthe unreliable news ecosystem for every 1 in the reliable\nnews ecosystem) was one with the keywords Pfizer, Batch,\nDanish, Bnt162b2, Adverse . This story concerned Danish\nscientists ostensibly discovering that batches of Pfizer vac-\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.27 0.22 0.51\n0.11 0.23 0.66\n0.031 0.16 0.81\n0.10.20.30.40.50.60.70.8Figure 11: Anti-Vaccine Copy Matrix.\ncines were actually placebos: The Danish scientists uncov-\nered \u201ccompelling evidence\u201d that a significant percentage of\nthe batches distributed in the EU likely consisted of \u201cplace-\nbos and non-placebos, \u201d prompting the researchers to call for\nfurther investigation. . The top websites that spread this story\nwere sgtreport.com ( zvaccine =-1.31 for vaccine-bias), theauto-\nmaticearth.com ( zvaccine =-1.08), and theburningplatform.com\n(zvaccine =-1.86) with two articles each.\nWe find that the reliable news website most influenced (by\nthe weighted in-degree within the resulting NETINF graph)\nwas sciencebasedmedicine.org ( zvaccine = +0.06), which fre-\nquently reports on and quotes anti-vaccine information [94],\ndetected by our system. Additionally, the most influenced\nmixed-reliability website (besides theepochtimes.com) was\nthelibertyloft.com ( zvaccine =-0.81), a right-leaning website\nthat Media-Bias/Fact-Check has identified as spreading\nCOVID-19 related misinformation [33].\n7 Limitations and Future Work\nOur work shows the promise of mapping the trajectories of\nnews stories and the takes of news websites towards specific\nentities. However, we emphasize the complexity of the news\necosystem and the considerable future work that remains to\nunderstand how information travels online. Below, we discuss\nthe limitations of our work and potential future research.\nEnglish-Language Websites. Our work is limited to\nEnglish-language news articles and focuses predominantly\non US, UK, and Australian websites. As a result, our analy-\nsis of the spread of particular stories is limited largely to the\nEnglish-speaking world and could miss other sources of news\n(i.e., a Russian-language website for example may be more\ninfluential in spreading pro-Russian propaganda than the web-\nsites in our dataset). This restriction is largely due to our use\nof PMI for identifying keywords for stance detection amongst\nour story clusters, which does not directly work in a multi-\nlingual setting. Similarly, we currently lack highly accurate\nmultilingual topic-agnostic stance-detection models [55, 63].\nWe leave to future work to consider how to semantically map\nboth news topics and stances towards them in multilingual\nsettings, as well as to consider how to source news content\nfrom websites in additional languages.\nAutomated Fact-Checking of Narratives. As previously\nnoted, we do not fact-check individual news stories, which we\nargue is a journalistic task beyond the scope of our automated\napproach. While our system can be utilized to uncover net-\nworks of websites pushing potentially unreliable news narra-\ntives allowing journalists to prioritize which stories need to be\nfact-checked by their relative spread, these stories still require\nhuman investigation to determine their veracity. However, we\nnote that for stories that have already been fact-checked on\nreputable websites, it may be possible to incorporate the ap-\nproaches of Hanley et al. [62], Zhou et al. [148], and others to\nautomatically label particular stories. Hanley et al.\u2019s approach\ninvolves gathering fact-checks from reputable sources and\nusing a DeBERTa-based model [65] to identify unreliable\nnews stories that directly contradict these fact-checks [62]. In\na similar fashion, Zhou et al.\u2019s [148] approach involves using\nan LLM agent and Google Search to identify which unreliable\nnews stories contradict fact-checks.\nEphemeral Unreliable News Websites. Factually unreli-\nable news websites tend to be ephemeral [32, 58, 68, 101],\noften only being active long enough to spread misinformation\nto other platforms before shutting down themselves. As such,\nfinding news websites as soon as they come online is criti-\ncal long term. We note that while our current system relies\non previously curated lists of websites, it can easily incor-\nporate new websites as they appear ( e.g., using the methods\noutlined by Hounsel et al. [68] for identifying new unreli-\nable news websites based on their domain registration and\nnetwork infrastructure characteristics). This inclusion would\nenable our system to surface potentially unreliable news sto-\nries that have not spread onto more popular websites. Similar\nto past work that has detected phishing and malware domains,\nit would also potentially enable uncovering malicious Doppel-\ng\u00e4nger websites that masquerade as ordinary local websites\nbut that actually spread propaganda as soon as they come\nonline [12, 13, 46, 90, 134].\n8 Discussion and Conclusion\nIn this work, we investigated the spread and stance of news\nstories across 4,076 news websites from January 1, 2022, to\nJuly 1, 2023. Our approach, which advances previous method-\nologies for understanding news flows by incorporating stance\ninto how we understand stories, allows us to track stories\nacross a mix of reliable, mixed-reliability, and unreliable news\nwebsites. (Neglecting stance in understanding the spread of\nnarratives, while helpful for examining a singular ecosystem\n[62, 127], would likely lead to misrepresentations of the inter-\nactions between websites for particular stories.)\nOur work demonstrates the key role that reliable newsplatforms play in dictating the stories covered by the entire\nnews ecosystem. These popular and largely factual websites\nmaintain the largest degree of influence on the broader news\necosystem (Figure 6) and are the source of much content\non mixed-reliability and unreliable websites (Figure 5). To\nunderstand which stories unreliable websites will spin or con-\ntort, researchers should consider reliable outlets as agenda-\nsetters [24, 45, 91]. However, we simultaneously highlight\nthat while a minimum of 62.4% of stories are shared between\ndifferent types of news websites (Section 4), different ecosys-\ntems often have distinctive attitudes towards stories. For ex-\nample, using our analysis, inline with prior work [44, 48], we\nshow that current lists of unreliable websites, in contrast to\nreliable news websites, among other biases, tend to be more\nconservative and have distinctive biases against COVID-19\nvaccines and Pfizer (Table 3).\nFinally, our work demonstrates how, by analyzing the\nstance of articles towards specific topics, we can uncover and\nunderstand influence networks directed at specific entities,\nfacilitating the tracking of propaganda ( e.g., anti-Ukraine) or\nmisinformation ( e.g., anti-vaccine) within the news ecosys-\ntem. This method also aids in identifying which otherwise\nreliable news sources may be influenced by disinformation\nand propaganda campaigns. Our approach, which considers\nthe context of authentic and mainstream websites, provides\na valuable tool for identifying dubious networks of websites\nspreading particular types of slanted information, which we\nargue can assist fact-checkers, journalists, and researchers in\nbetter understanding potential online misinformation.\nWe hope that our work encourages further quantitative anal-\nysis of the distributed news ecosystem, particularly as social\nmedia platforms become more opaque to researchers. Prior se-\ncurity research has uncovered weaknesses and attacks through\nlarge-scale analysis ( e.g., [2, 40, 42, 66, 95, 128 \u2013130]), and we\nargue that there is significant potential for future work within\nthe security community on understanding attacks against and\nstrengthening the resilience of news ecosystems.\nAcknowledgments\nThis work was supported in part by the NSF Graduate Fellow-\nship DGE-1656518, a Meta Ph.D. Fellowship, and a Sloan\nResearch Fellowship. Any opinions, findings, conclusions, or\nrecommendations expressed in this paper are those of the au-\nthors and do not necessarily reflect the views of the National\nScience Foundation or other funding agencies.\nEthical Considerations\nTrustworthy news media is fundamental to a democratic so-\nciety. Previously, false information has incited real-world\nviolence and had major consequences on public health and\nelections. Disinformation and propaganda are attacks , and it\nbehooves the security community to understand how these at-\ntacks are conducted and how to build better defenses against\nthem. Advances in this space help both citizens and news\noutlets themselves, who regularly fact-check articles. At the\nsame time, like all active measurements, web crawling and\nprogrammatic analysis of online content have potential ethical\nramifications that we must carefully consider.\nOur work collects only publicly available news content\nin line with prior work ( e.g., [60, 123, 124]). We follow best\npractices when scraping websites by slowly collecting content\nover time to reduce load. Our scraping also includes built-in\nsafety mechanisms to prevent making requests more often\nthan once every 10 seconds. We never attempt to access any\nprivileged or private data but rather focus on public stories\nthat are linked from news platforms\u2019 public homepages.\nWe also adhere to the best practices set forth for conducting\nactive Internet measurements [2, 41, 43]. The servers we use\nfor collecting content are identified as part of a research study\nthrough WHOIS, reverse DNS, and informational websites\nthat indicate how to reach us researchers. Our IT and security\nteams are also informed about how to route any questions,\nrequests, or complaints to our team. We received no requests\nto opt out of our data collection during our study.\nOur study does not generate any new content or redistribute\nexisting content. Instead, we analyze how context spreads.\nWe emphasize that while we utilize labels of individual web-\nsites as unreliable ormixed-reliability from Media-Bias/Fact-\nCheck [33] and on existing previously-curated lists, this does\nnot necessarily mean that every news story spread by these\nwebsites is misinformation. Many unreliable news websites\nreport factual information [127], and at times, otherwise re-\nliable websites may mistakenly report incorrect information.\nWe only label stories that have been previously and individu-\nally expertly labeled as misinformation .\nOpen Science\nWe are committed to sharing our data with other researchers at\nacademic or non-profit institutions seeking to conduct future\nwork or re-implement our approach. We will publicly release\nthe weights and the code for the models used in this study.\nAdditionally, we will supply the URLs of crawled news stories\nused in this study upon request.\nReferences\n[1]S. Abdali, R. Gurav, S. Menon, D. Fonseca, N. Entezari, N. Shah,\nand E. E. Papalexakis. Identifying misinformation from website\nscreenshots. In Proceedings of the International AAAI Conference on\nWeb and Social Media , volume 15, pages 2\u201313, 2021.\n[2]G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, and\nC. Diaz. The web never forgets: Persistent tracking mechanisms in the\nwild. In ACM SIGSAC Conference on Computer and Communications\nSecurity , 2014.[3]S. Afroz, A. C. Islam, A. Stolerman, R. Greenstadt, and D. McCoy.\nDoppelg\u00e4nger finder: Taking stylometry to the underground. In IEEE\nSymposium on Security and Privacy , 2014.\n[4]H. Aghababaeian, L. Hamdanieh, and A. Ostadtaghizadeh. Alcohol\nintake in an attempt to fight covid-19: A medical myth in iran. Alcohol ,\n88:29\u201332, 2020.\n[5]R. Albalawi, T. H. Yeap, and M. Benyoucef. Using topic modeling\nmethods for short-text data: A comparative analysis. Frontiers in\nartificial intelligence , 3:42, 2020.\n[6]M. Aliapoulios, A. Papasavva, C. Ballard, E. De Cristofaro, G. Stringh-\nini, S. Zannettou, and J. Blackburn. The gospel according to q: Un-\nderstanding the qanon conspiracy from the perspective of canonical\ninformation. In The 16th International AAAI Conference on Web and\nSocial Media (ICWSM 2022) , 2022.\n[7]J. Allan. Detection as multi-topic tracking. Information Retrieval ,\n5(2-3):139\u2013157, 2002.\n[8]E. Allaway and K. McKeown. Zero-Shot Stance Detection: A Dataset\nand Model using Generalized Topic Representations. In Empirical\nMethods in Natural Language Processing , 2020.\n[9]H. Allcott and M. Gentzkow. Social media and fake news in the 2016\nelection. Journal of economic perspectives , 31(2), 2017.\n[10] J. Allen, B. Howland, M. Mobius, D. Rothschild, and D. J. Watts.\nEvaluating the fake news problem at the scale of the information\necosystem. Science advances , 6(14), 2020.\n[11] A. Amarasingam and M.-A. Argentino. The qanon conspiracy theory:\nA security threat in the making. CTC Sentinel , 13(7):37\u201344, 2020.\n[12] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.\nBuilding a dynamic reputation system for {DNS}. In19th USENIX\nSecurity Symposium (USENIX Security 10) , 2010.\n[13] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou II, and D. Dagon.\nDetecting malware domains at the upper {DNS}hierarchy. In 20th\nUSENIX Security Symposium (USENIX Security 11) , 2011.\n[14] M. Babaei, J. Kulshrestha, A. Chakraborty, E. M. Redmiles, M. Cha,\nand K. P. Gummadi. Analyzing biases in perception of truth in news\nstories and their implications for fact checking. IEEE Transactions\non Computational Social Systems , 9(3):839\u2013850, 2021.\n[15] J. B. Bak-Coleman, I. Kennedy, M. Wack, A. Beers, J. S. Schafer,\nE. S. Spiro, K. Starbird, and J. D. West. Combining interventions to\nreduce the spread of viral misinformation. Nature Human Behaviour ,\n6(10):1372\u20131380, 2022.\n[16] P. Ball and A. Maxmen. The epic battle against coronavirus mis-\ninformation and conspiracy theories. Nature , 581(7809):371\u2013375,\n2020.\n[17] S. Banaji, R. Bhat, A. Agarwal, N. Passanha, and M. Sadhana Pravin.\nWhatsapp vigilantes: An exploration of citizen reception and circu-\nlation of whatsapp misinformation linked to mob violence in India.\n2019.\n[18] A. Bauer, A. Nadler, and J. L. Nelson. What is fox news? partisan jour-\nnalism, misinformation, and the problem of classification. Electronic\nNews , 16(1):18\u201329, 2022.\n[19] P. Biancovilli, L. Makszin, and C. Jurberg. Misinformation on social\nnetworks during the novel coronavirus pandemic: a quali-quantitative\ncase study of Brazil. BMC Public Health , 21(1):1\u201310, 2021.\n[20] D. Biber and E. Finegan. Adverbial stance types in english. Discourse\nprocesses , 11(1), 1988.\n[21] S. Bird, E. Klein, and E. Loper. Natural language processing with\nPython: analyzing text with the natural language toolkit . 2009.\n[22] D. M. Blei, T. L. Griffiths, and M. I. Jordan. The nested chinese\nrestaurant process and bayesian nonparametric inference of topic\nhierarchies. Journal of the ACM (JACM) , 57(2):1\u201330, 2010.\n[23] G. Bouma. Normalized (pointwise) mutual information in collocation\nextraction. Proceedings of GSCL , 30:31\u201340, 2009.\n[24] G. R. Boynton and G. W. Richardson Jr. Agenda setting in the twenty-\nfirst century. New Media & Society , 18(9):1916\u20131934, 2016.\n[25] M. Brosig and R. Verma. The war in ukraine, the global south and\nthe evolving global order. Global Policy , 2024.\n[26] D. Cer, M. Diab, E. Agirre, I. Lopez-Gazpio, and L. Specia. Semeval-\n2017 task 1: Semantic textual similarity multilingual and crosslingual\nfocused evaluation. In Proceedings of the 11th International Workshop\non Semantic Evaluation (SemEval-2017) , pages 1\u201314, 2017.\n[27] D. Cer, Y . Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. S. John, N. Con-\nstant, M. Guajardo-Cespedes, S. Yuan, C. Tar, et al. Universal sentence\nencoder for English. In Conference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations , 2018.\n[28] D. Chandrasekaran and V . Mago. Evolution of semantic similarity\u2014a\nsurvey. ACM Computing Surveys (CSUR) , 54(2):1\u201337, 2021.\n[29] X. Chen, A. Zeynali, C. Camargo, F. Fl\u00f6ck, D. Gaffney, P. Grabowicz,\nS. Hale, D. Jurgens, and M. Samory. Semeval-2022 task 8: Multilin-\ngual news article similarity. In Proceedings of the 16th International\nWorkshop on Semantic Evaluation (SemEval-2022) , pages 1094\u20131106,\n2022.\n[30] J. Comber. Fda authorizes \u00b4traditional \u00b4novavax covid vaccine,\nbut critics question safety claims. https://web .archive .org/web/\n20220713202551/https://childrenshealthdefense .org/defender/fda-\nauthorize-traditional-novavax-covid-vaccine-safety-claims/, 7 2022.\n[31] J. Y . Cuan-Baltazar, M. J. Mu\u00f1oz-Perez, C. Robledo-Vega, M. F.\nP\u00e9rez-Zepeda, and E. Soto-Vega. Misinformation of covid-19 on the\ninternet: infodemiology study. JMIR public health and surveillance ,\n6(2):e18444, 2020.\n[32] R. Dahlke, D. Kumar, Z. Durumeric, and J. T. Hancock. Quantifying\nthe systematic bias in the accessibility and inaccessibility of web\nscraping content from url-logged web-browsing digital trace data.\nSocial Science Computer Review , page 08944393231218214, 2023.\n[33] Dave Van Zandt. Media bias/fact check. https:\n//mediabiasfactcheck .com/, 2023.\n[34] R. C. David Bauder and G. Mulvihill. Fox, dominion reach 787m\nsettlement over election claims. https://web .archive .org/web/\n20230418103714/https://apnews .com/article/fox-news-dominion-\nlawsuit-trial-trump-2020-0ac71f75acfacc52ea80b3e747fb0afe, 4\n2023.\n[35] P. De Meo, E. Ferrara, G. Fiumara, and A. Provetti. Generalized\nlouvain method for community detection in large networks. In 2011\n11th international conference on intelligent systems design and appli-\ncations , pages 88\u201393. IEEE, 2011.\n[36] P. Devine and K. Blincoe. Unsupervised extreme multi label classifi-\ncation of stack overflow posts. In Proceedings of the 1st International\nWorkshop on Natural Language-based Software Engineering , pages\n1\u20138, 2022.\n[37] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training\nof deep bidirectional transformers for language understanding. In\nNorth American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1 , 2019.\n[38] O. Dinari and O. Freifeld. Revisiting dp-means: fast scalable algo-\nrithms via parallelism and delayed cluster creation. In Uncertainty in\nArtificial Intelligence , pages 579\u2013588. PMLR, 2022.\n[39] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman,\nA. Mathur, A. Schelten, A. Yang, A. Fan, et al. The llama 3 herd of\nmodels. arXiv preprint arXiv:2407.21783 , 2024.\n[40] Z. Durumeric, D. Adrian, A. Mirian, J. Kasten, E. Bursztein,\nN. Lidzborski, K. Thomas, V . Eranti, M. Bailey, and J. A. Halder-\nman. Neither snow nor rain nor mitm... an empirical analysis of email\ndelivery security. In Proceedings of the 2015 Internet Measurement\nConference , pages 27\u201339, 2015.[41] Z. Durumeric, D. Adrian, P. Stephens, E. Wustrow, and J. A. Halder-\nman. Ten years of zmap. In Proceedings of the 2024 ACM on Internet\nMeasurement Conference , pages 139\u2013148, 2024.\n[42] Z. Durumeric, J. Kasten, M. Bailey, and J. A. Halderman. Analysis of\nthe https certificate ecosystem. In Proceedings of the 2013 conference\non Internet measurement conference , pages 291\u2013304, 2013.\n[43] Z. Durumeric, E. Wustrow, and J. A. Halderman. {ZMap}: Fast\ninternet-wide scanning and its security applications. In 22nd USENIX\nSecurity Symposium (USENIX Security 13) , pages 605\u2013620, 2013.\n[44] U. K. Ecker and L. C. Ang. Political attitudes and the processing\nof misinformation corrections. Political Psychology , 40(2):241\u2013260,\n2019.\n[45] L. Erbring, E. N. Goldenberg, and A. H. Miller. Front-page news and\nreal-world cues: A new look at agenda-setting by the media. American\njournal of political science , pages 16\u201349, 1980.\n[46] EU Disinfo Lab. What is the doppelganger operation? https:\n//www .disinfo .eu/doppelganger-operation/.\n[47] T. Gao, X. Yao, and D. Chen. Simcse: Simple contrastive learning\nof sentence embeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Processing , pages 6894\u2013\n6910, 2021.\n[48] R. K. Garrett and R. M. Bond. Conservatives\u2019 susceptibility to politi-\ncal misperceptions. Science Advances , 7(23):eabf1234, 2021.\n[49] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. Inferring net-\nworks of diffusion and influence. ACM Transactions on Knowledge\nDiscovery from Data (TKDD) , 5(4):1\u201337, 2012.\n[50] M. Gomez Rodriguez, J. Leskovec, and B. Sch\u00f6lkopf. Structure and\ndynamics of information pathways in online media. In Proceedings\nof the sixth ACM international conference on Web search and data\nmining , pages 23\u201332, 2013.\n[51] L. Grimminger and R. Klinger. Hate towards the political opponent: A\ntwitter corpus study of the 2020 us elections on the basis of offensive\nspeech and stance detection. In Proceedings of the Eleventh Workshop\non Computational Approaches to Subjectivity, Sentiment and Social\nMedia Analysis , pages 171\u2013180, 2021.\n[52] M. Grootendorst. Bertopic: Neural topic modeling with a class-based\ntf-idf procedure. arXiv preprint arXiv:2203.05794 , 2022.\n[53] F. Hamborg and K. Donnay. Newsmtsc: A dataset for (multi-) target-\ndependent sentiment classification in political news articles. In Pro-\nceedings of the 16th Conference of the European Chapter of the Associ-\nation for Computational Linguistics: Main Volume , pages 1663\u20131675,\n2021.\n[54] C. Han, D. Kumar, and Z. Durumeric. On the infrastructure providers\nthat support misinformation websites. In Proceedings of the interna-\ntional aaai conference on web and social media , volume 16, pages\n287\u2013298, 2022.\n[55] H. Hanley and Z. Durumeric. Tata: Stance detection via topic-agnostic\nand topic-aware embeddings. In Proceedings of the 2023 Conference\non Empirical Methods in Natural Language Processing , pages 11280\u2013\n11294, 2023.\n[56] H. W. Hanley and Z. Durumeric. Machine-made media: Monitoring\nthe mobilization of machine-generated articles on misinformation and\nmainstream news websites. In Proceedings of the International AAAI\nConference on Web and Social Media , volume 18, pages 542\u2013556,\n2024.\n[57] H. W. Hanley and Z. Durumeric. Partial mobilization: Tracking\nmultilingual information flows amongst russian media outlets and\ntelegram. In Proceedings of the International AAAI Conference on\nWeb and Social Media , volume 18, pages 528\u2013541, 2024.\n[58] H. W. Hanley, D. Kumar, and Z. Durumeric. No calm in the storm:\ninvestigating qanon website relationships. In Proceedings of the\ninternational AAAI conference on Web and social media , volume 16,\npages 299\u2013310, 2022.\n[59] H. W. Hanley, D. Kumar, and Z. Durumeric. \"A special operation\":\nA quantitative approach to dissecting and comparing different media\necosystems\u2019 coverage of the russo-ukrainian war. In Proceedings\nof the International AAAI Conference on Web and social media , vol-\nume 17, pages 339\u2013350, 2023.\n[60] H. W. Hanley, D. Kumar, and Z. Durumeric. A golden age: Conspiracy\ntheories\u2019 relationship with misinformation outlets, news media, and\nthe wider internet. Proceedings of the ACM on Human-Computer\nInteraction , 7(CSCW2):1\u201333, 2023.\n[61] H. W. Hanley, D. Kumar, and Z. Durumeric. Happenstance: utilizing\nsemantic search to track russian state media narratives about the russo-\nukrainian war on reddit. In Proceedings of the international AAAI\nconference on web and social media , volume 17, pages 327\u2013338,\n2023.\n[62] H. W. Hanley, D. Kumar, and Z. Durumeric. Specious sites: Tracking\nthe spread and sway of spurious news stories at scale. In 2024 IEEE\nSymposium on Security and Privacy (SP) , pages 1609\u20131627. IEEE,\n2024.\n[63] M. Hardalov, A. Arora, P. Nakov, and I. Augenstein. Few-shot cross-\nlingual stance detection with sentiment-based pre-training. In Pro-\nceedings of the AAAI Conference on Artificial Intelligence , volume 36,\npages 10729\u201310737, 2022.\n[64] N. Hassan, G. Zhang, F. Arslan, J. Caraballo, D. Jimenez, S. Gawsane,\nS. Hasan, M. Joseph, A. Kulkarni, A. K. Nayak, et al. Claimbuster:\nThe first-ever end-to-end fact-checking system. Proceedings of the\nVLDB Endowment , 10(12):1945\u20131948, 2017.\n[65] P. He, J. Gao, and W. Chen. Debertav3: Improving deberta using\nelectra-style pre-training with gradient-disentangled embedding shar-\ning. In 11th Intl. Conf. on Learning Representations , 2022.\n[66] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman. Mining\nyour ps and qs: Detection of widespread weak keys in network devices.\nIn21st USENIX Security Symposium (USENIX Security 12) , pages\n205\u2013220, 2012.\n[67] J. Hoewe, K. C. Brownell, and E. C. Wiemer. The role and impact\nof fox news. In The forum , volume 18, pages 367\u2013388. De Gruyter,\n2020.\n[68] A. Hounsel, J. Holland, B. Kaiser, K. Borgolte, N. Feamster, and\nJ. Mayer. Identifying disinformation websites using infrastructure\nfeatures. In USENIX Workshop on Free and Open Communications\non the Internet , 2020.\n[69] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang, W. Chen,\net al. Lora: Low-rank adaptation of large language models. In Inter-\nnational Conference on Learning Representations , 2021.\n[70] H. Jelodar, Y . Wang, C. Yuan, X. Feng, X. Jiang, Y . Li, and L. Zhao.\nLatent dirichlet allocation (lda) and topic modeling: models, applica-\ntions, a survey. Multimedia Tools and Applications , 2019.\n[71] Z. Jin, J. Cao, H. Guo, Y . Zhang, and J. Luo. Multimodal fusion\nwith recurrent neural networks for rumor detection on microblogs. In\nProceedings of the 25th ACM international conference on Multimedia ,\npages 795\u2013816, 2017.\n[72] J. Johnson, M. Douze, and H. J\u00e9gou. Billion-scale similarity search\nwith GPUs. IEEE Transactions on Big Data , 7(3), 2019.\n[73] J. L. Juul and J. Ugander. Comparing information diffusion mech-\nanisms by matching on cascade size. Proceedings of the National\nAcademy of Sciences , 118(46), 2021.\n[74] B. Kaiser, J. Wei, E. Lucherini, K. Lee, J. N. Matias, and J. Mayer.\nAdapting security warnings to counter online disinformation. In 30th\nUSENIX Security Symposium (USENIX Security 21) , pages 1163\u2013\n1180, 2021.\n[75] J. Kerr, C. Panagopoulos, and S. Van Der Linden. Political polarization\non covid-19 pandemic response in the united states. Personality and\nindividual differences , 179:110892, 2021.[76] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and A. S.\nTomkins. The web as a graph: Measurements, models, and methods. In\nComputing and Combinatorics: 5th Annual International Conference,\nCOCOON\u201999 Tokyo, Japan, July 26\u201328, 1999 Proceedings 5 , pages\n1\u201317. Springer, 1999.\n[77] P. Kreko. Political tribalism, polarization, and the motivated rejection\nof science. In The Tribal Mind and the Psychology of Collectivism ,\npages 169\u2013185. Routledge, 2024.\n[78] D. K\u00fc\u00e7\u00fck and F. Can. Stance detection: A survey. ACM Computing\nSurveys (CSUR) , 53(1):1\u201337, 2020.\n[79] B. Kulis and M. I. Jordan. Revisiting k-means: new algorithms via\nbayesian nonparametrics. In International Conference on Machine\nLearning , 2012.\n[80] S. Kwon, M. Cha, K. Jung, W. Chen, and Y . Wang. Aspects of rumor\nspreading on a microblog network. In Social Informatics: 5th Inter-\nnational Conference, SocInfo 2013, Kyoto, Japan, November 25-27,\n2013, Proceedings 5 , pages 299\u2013308. Springer, 2013.\n[81] S. Kwon, M. Cha, K. Jung, W. Chen, and Y . Wang. Prominent features\nof rumor propagation in online social media. In 2013 IEEE 13th\ninternational conference on data mining , pages 1103\u20131108. IEEE,\n2013.\n[82] M. Lai, V . Patti, G. Ruffo, and P. Rosso. Stance evolution and twit-\nter interactions in an italian political debate. In Natural Language\nProcessing and Information Systems: 23rd International Conference\non Applications of Natural Language to Information Systems, NLDB\n2018, Paris, France, June 13-15, 2018, Proceedings 23 , pages 15\u201327.\nSpringer, 2018.\n[83] G. Leban, B. Fortuna, J. Brank, and M. Grobelnik. Event registry:\nlearning about world events from news. In Proceedings of the 23rd\nInternational Conference on World Wide Web , pages 107\u2013110, 2014.\n[84] D. Leonhardt. Revisiting the gaza hospital explosion.\nhttps://www .nytimes .com/2023/11/03/briefing/gaza-hospital-\nexplosion .html, 11 2023.\n[85] J. Leskovec, L. Backstrom, and J. Kleinberg. Meme-tracking and\nthe dynamics of the news cycle. In Proceedings of the 15th ACM\nSIGKDD international conference on Knowledge discovery and data\nmining , pages 497\u2013506, 2009.\n[86] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for\nparameter-efficient prompt tuning. In Proceedings of the 2021 Confer-\nence on Empirical Methods in Natural Language Processing , pages\n3045\u20133059, 2021.\n[87] B. Liang, Q. Zhu, X. Li, M. Yang, L. Gui, Y . He, and R. Xu. Jointcl:\nA joint contrastive learning framework for zero-shot stance detection.\nInProceedings of the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , volume 1, pages\n81\u201391. Association for Computational Linguistics, 2022.\n[88] J. Ma, W. Gao, P. Mitra, S. Kwon, B. J. Jansen, K.-F. Wong, and\nM. Cha. Detecting rumors from microblogs with recurrent neural\nnetworks. 2016.\n[89] G. Madraki, I. Grasso, J. M. Otala, Y . Liu, and J. Matthews. Charac-\nterizing and comparing covid-19 misinformation across languages,\ncountries and platforms. In Companion proceedings of the web con-\nference 2021 , pages 213\u2013223, 2021.\n[90] A. Martin. Russians impersonate washington post and fox news with\nanti-ukraine stories. https://therecord .media/russians-fake-news-anti-\nukraine.\n[91] M. McCombs and D. Shaw. The agenda-setting function of the press.\nThe Press. Oxford, England: Oxford University Press Inc , pages 156\u2013\n168, 2005.\n[92] D. McCoy, A. Pitsillidis, J. Grant, N. Weaver, C. Kreibich, B. Krebs,\nG. V oelker, S. Savage, and K. Levchenko. {PharmaLeaks }: Under-\nstanding the business of online pharmaceutical affiliate programs. In\n21st USENIX Security Symposium (USENIX Security 12) , pages 1\u201316,\n2012.\n[93] L. McInnes, J. Healy, S. Astels, et al. hdbscan: Hierarchical density\nbased clustering. J. Open Source Softw. , 2(11):205, 2017.\n[94] S. B. Medicine. Vaccines. https://sciencebasedmedicine .org/category/\nvaccines/, 2024.\n[95] S. Meiklejohn, M. Pomarole, G. Jordan, K. Levchenko, D. McCoy,\nG. M. V oelker, and S. Savage. A fistful of bitcoins: characterizing\npayments among men with no names. In Proceedings of the 2013 con-\nference on Internet measurement conference , pages 127\u2013140, 2013.\n[96] Y . Meng, Y . Zhang, J. Huang, Y . Zhang, and J. Han. Topic discovery\nvia latent space clustering of pretrained language model represen-\ntations. In Proceedings of the ACM web conference 2022 , pages\n3143\u20133152, 2022.\n[97] J. Mercola. Fda anxious for pfizer to rush covid shots for babies and\ntoddlers. but why? https://web .archive .org/web/20220208225347/\nhttps://childrenshealthdefense .org/defender/fda-pfizer-rush-covid-\nshots-babies-toddlers/, 2 2022.\n[98] S. Miranda, A. Znotins, S. B. Cohen, and G. Barzdins. Multilingual\nclustering of streaming news. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Processing , pages 4535\u2013\n4544, 2018.\n[99] S. Mohammad, S. Kiritchenko, P. Sobhani, X. Zhu, and C. Cherry.\nSemeval-2016 task 6: Detecting stance in tweets. In Proceedings of\nthe 10th international workshop on semantic evaluation (SemEval-\n2016) , pages 31\u201341, 2016.\n[100] E. Momeni, S. Karunasekera, P. Goyal, and K. Lerman. Modeling\nevolution of topics in large-scale temporal text corpora. In Proceed-\nings of the International AAAI Conference on Web and Social Media ,\nvolume 12, 2018.\n[101] R. C. Moore, R. Dahlke, and J. T. Hancock. Exposure to untrustworthy\nwebsites in the 2020 us election. Nature Human Behaviour , 7(7):1096\u2013\n1105, 2023.\n[102] B. Mueller and S. G. Stolberg. Fauci grilled by law-\nmakers on masks, vaccine mandates and lab leak theory.\nhttps://web .archive .org/save/https://www .nytimes .com/2024/\n06/03/science/fauci-hearing-covid-origins .html, 6 2024.\n[103] P. Nakov and G. Da San Martino. Fake news, disinformation, propa-\nganda, and media bias. In Proceedings of the 30th ACM International\nConference on Information & Knowledge Management , pages 4862\u2013\n4865, 2021.\n[104] N. Nakshatri, S. Liu, S. Chen, D. Roth, D. Goldwasser, and D. Hopkins.\nUsing llm for improving key event discovery: Temporal-guided news\nstream clustering with event summaries. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2023 , pages 4162\u20134173,\n2023.\n[105] D. Ng. Left-wing guardian triggered by my son hunter:\nStop trying to make hunter biden conspiracy theories hap-\npen. https://web .archive .org/web/20220903140730/https:\n//www .breitbart .com/entertainment/2022/09/03/leftwing-guardian-\ntriggered-by-my-son-hunter-stop-trying-to-make-hunter-biden-\nconspiracy-theories-happen/, 9 2022.\n[106] U. D. of State Global Engagement Center. Gec special report: Russia\u2019s\npillars of disinformation and propaganda - united states department\nof state. https://www .state .gov/russias-pillars-of-disinformation-and-\npropaganda-report/, 8 2020.\n[107] A. Papasavva, J. Blackburn, G. Stringhini, S. Zannettou, and E. D.\nCristofaro. \u201cis it a qoincidence?\u201d: An exploratory study of qanon on\nvoat. In Proceedings of the Web Conference 2021 , pages 460\u2013471,\n2021.\n[108] P. Paudel, J. Blackburn, E. De Cristofaro, S. Zannettou, and G. Stringh-\nini. Lambretta: learning to rank for twitter soft moderation. In 2023\nIEEE Symposium on Security and Privacy (SP) , pages 311\u2013326. IEEE,\n2023.[109] F. Pierri, L. Luceri, N. Jindal, and E. Ferrara. Propaganda and mis-\ninformation on facebook and twitter during the russian invasion of\nukraine. In Proceedings of the 15th ACM web science conference\n2023 , pages 65\u201374, 2023.\n[110] A. Piktus, F. Petroni, V . Karpukhin, D. Okhonko, S. Broscheit, G. Izac-\nard, P. Lewis, B. O \u02d8guz, E. Grave, W.-t. Yih, et al. The web is your\noyster\u2013knowledge-intensive nlp against a very large web corpus. arXiv\npreprint arXiv:2112.09924 , 2021.\n[111] T. A. Press. Not real news: A look at what didn\u2019t happen\nthis week. https://web .archive .org/web/20231124154018/\nhttps://apnews .com/article/fact-check-misinformation-\nf3c1d54f2d059de0532360d638335e99, 11 2023.\n[112] S. Prochaska, K. Duskin, Z. Kharazian, C. Minow, S. Blucker,\nS. Venuto, J. D. West, and K. Starbird. Mobilizing manufactured\nreality: How participatory disinformation shaped deep stories to cat-\nalyze action during the 2020 us presidential election. Proceedings of\nthe ACM on Human-Computer Interaction , 7(CSCW1):1\u201339, 2023.\n[113] M. Rajdev and K. Lee. Fake and spam messages: Detecting mis-\ninformation during natural disasters on social media. In 2015\nIEEE/WIC/ACM International Conference on Web Intelligence and\nIntelligent Agent Technology (WI-IAT) , volume 1, pages 17\u201320. IEEE,\n2015.\n[114] N. Reimers and I. Gurevych. Sentence-BERT: Sentence embeddings\nusing Siamese BERT-networks. In K. Inui, J. Jiang, V . Ng, and\nX. Wan, editors, Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP) ,\npages 3982\u20133992, Hong Kong, China, Nov. 2019. Association for\nComputational Linguistics.\n[115] B. Ruhnau. Eigenvector-centrality\u2014a node-centrality? Social net-\nworks , 22(4):357\u2013365, 2000.\n[116] K. Ruth, A. Fass, J. Azose, M. Pearson, E. Thomas, C. Sadowski, and\nZ. Durumeric. A world wide view of browsing the world wide web.\nInProceedings of the 22nd ACM Internet Measurement Conference ,\npages 317\u2013336, 2022.\n[117] K. Ruth, D. Kumar, B. Wang, L. Valenta, and Z. Durumeric. Toppling\ntop lists: Evaluating the accuracy of popular website lists. In Pro-\nceedings of the 22nd ACM Internet Measurement Conference , pages\n374\u2013387, 2022.\n[118] M. H. Saeed, S. Ali, J. Blackburn, E. De Cristofaro, S. Zannettou,\nand G. Stringhini. Trollmagnifier: Detecting state-sponsored troll\naccounts on reddit. In 2022 IEEE symposium on security and privacy\n(SP), pages 2161\u20132175. IEEE, 2022.\n[119] K. K. Saravanakumar, M. Ballesteros, M. K. Chandrasekaran, and\nK. Mckeown. Event-driven news stream clustering using entity-aware\ncontextual embeddings. In Proceedings of the 16th Conference of the\nEuropean Chapter of the Association for Computational Linguistics:\nMain Volume , pages 2330\u20132340, 2021.\n[120] M. S. Sch\u00e4fer and J. Painter. Climate journalism in a changing media\necosystem: Assessing the production of climate change-related news\naround the world. Wiley Interdisciplinary Reviews: Climate Change ,\n12(1):e675, 2021.\n[121] G. K. Shahi. Warclaim: A dataset for fake news on 2023 Israel\u2013Hamas\nwar. In ACM Web Science Conference , 2024.\n[122] L. Silver and A. Connaughton. Partisanship colors\nviews of covid-19 handling across advanced economies.\nhttps://www .pewresearch .org/global/2022/08/11/partisanship-\ncolors-views-of-covid-19-handling-across-advanced-economies/, 8\n2022.\n[123] V . Singrodia, A. Mitra, and S. Paul. A review on web scrapping\nand its applications. In 2019 international conference on computer\ncommunication and informatics (ICCCI) , pages 1\u20136. IEEE, 2019.\n[124] J. R. Smith, H. Saint-Amand, M. Plamada, P. Koehn, C. Callison-\nBurch, and A. Lopez. Dirt cheap web-scale parallel text from the\ncommon crawl. Association for Computational Linguistics, 2013.\n[125] V . Smith. Go Web Scraping Quick Start Guide: Implement the power\nof Go to scrape and crawl data from the web . 2019.\n[126] K. Song, X. Tan, T. Qin, J. Lu, and T.-Y . Liu. Mpnet: Masked and\npermuted pre-training for language understanding. Adv. in Neural\nInformation Processing Systems , 2020.\n[127] K. Starbird, A. Arif, T. Wilson, K. Van Koevering, K. Yefimova, and\nD. Scarnecchia. Ecosystem or echo-system? exploring content sharing\nacross alternative media domains. In Proceedings of the International\nAAAI Conference on Web and Social Media , volume 12, 2018.\n[128] R. Sundara Raman, L.-H. Merino, K. Bock, M. Fayed, D. Levin,\nN. Sullivan, and L. Valenta. Global, passive detection of connection\ntampering. In Proceedings of the ACM SIGCOMM 2023 Conference ,\npages 622\u2013636, 2023.\n[129] R. Sundara Raman, P. Shenoy, K. Kohls, and R. Ensafi. Censored\nplanet: An internet-wide, longitudinal censorship observatory. In\nproceedings of the 2020 ACM SIGSAC conference on computer and\ncommunications security , pages 49\u201366, 2020.\n[130] K. Thomas, E. Bursztein, C. Grier, G. Ho, N. Jagpal, A. Kapravelos,\nD. McCoy, A. Nappa, V . Paxson, P. Pearce, et al. Ad injection at\nscale: Assessing deceptive advertisement modifications. In 2015\nIEEE Symposium on Security and Privacy , pages 151\u2013167. IEEE,\n2015.\n[131] F. Timotija. Ukraine defense minister presses us to allow use\nof long-range weapons on russia. https://web .archive .org/web/\n20240831192927/https://thehill .com/policy/international/4857208-\nukraine-defense-minister-rustem-umerov-long-range-missiles-\nrestriction/, 8 2024.\n[132] R. Today. Finland rules on fate of seized russian art-\nwork. https://web .archive .org/web/20220524233445/https:\n//www .rt.com/russia/553529-finland-russia-art-decision/, 4 2022.\n[133] P. D. Turney. Mining the web for synonyms: Pmi-ir versus lsa on\ntoefl. In European conference on machine learning , pages 491\u2013502.\nSpringer, 2001.\n[134] U.S. Department of Justice. Justice department disrupts\ncovert russian government-sponsored foreign malign influence\noperation targeting audiences in the united states and else-\nwhere. https://www .justice .gov/opa/pr/justice-department-disrupts-\ncovert-russian-government-sponsored-foreign-malign-influence.\n[135] Y . Vasiliev. Natural language processing with Python and spaCy: A\npractical introduction . No Starch Press, 2020.\n[136] S. V osoughi, D. Roy, and S. Aral. The spread of true and false news\nonline. science , 359(6380):1146\u20131151, 2018.\n[137] I. Waller and A. Anderson. Quantifying social organization and\npolitical polarization in online platforms. Nature , 600(7888):264\u2013268,\n2021.\n[138] L. Wang, N. Yang, X. Huang, B. Jiao, L. Yang, D. Jiang, R. Majumder,\nand F. Wei. Text embeddings by weakly-supervised contrastive pre-\ntraining. arXiv preprint arXiv:2212.03533 , 2022.\n[139] G. Weld, M. Glenski, and T. Althoff. Political bias and factualness\nin news sharing across more than 100,000 online communities. In\nProceedings of the International AAAI Conference on Web and Social\nMedia , volume 15, pages 796\u2013807, 2021.\n[140] C. Wilkie. Dinesh d \u00b4souza election fraud film, book \u00b42000 mules pulled\nafter defamation suit. https://web .archive .org/web/20240601000808/\nhttps://www .cnbc .com/2024/05/31/dinesh-dsouza-election-film-\n2000-mules-pulled .html, 5 2024.\n[141] L. Wu, F. Morstatter, K. M. Carley, and H. Liu. Misinformation in\nsocial media: definition, manipulation, and detection. ACM SIGKDD\nExplorations Newsletter , 21(2):80\u201390, 2019.[142] J. Yin, D. Chao, Z. Liu, W. Zhang, X. Yu, and J. Wang. Model-based\nclustering of short text streams. In Proceedings of the 24th ACM\nSIGKDD international conference on knowledge discovery & data\nmining , pages 2634\u20132642, 2018.\n[143] D. V . Zandt. Media-Bias/Fact-Check. https://\nmediabiasfactcheck .com/yahoo-news/, 2022.\n[144] D. V . Zandt. Media-Bias/Fact-Check. https://\nmediabiasfactcheck .com/north-alaska-news/, 2022.\n[145] E. Zeng, T. Kohno, and F. Roesner. Bad news: Clickbait and deceptive\nads on news and misinformation websites. In Workshop on Technology\nand Consumer Protection , pages 1\u201311, 2020.\n[146] Y . Zhang, F. Guo, J. Shen, and J. Han. Unsupervised key event de-\ntection from massive text corpora. In Proceedings of the 28th ACM\nSIGKDD conference on knowledge discovery and data mining , pages\n2535\u20132544, 2022.\n[147] D. Zhou, H. Xu, and Y . He. An unsupervised Bayesian modelling\napproach for storyline detection on news articles. In Conference on\nEmpirical Methods in Natural Language Processing , 2015.\n[148] X. Zhou, A. Sharma, A. X. Zhang, and T. Althoff. Correcting misinfor-\nmation on social media with a large language model. arXiv preprint\narXiv:2403.11169 , 2024.\nA Article Preprocessing\nAfter collecting each page\u2019s HMTL, we then parse the con-\ntent to extract the news article text and publication date using\nthe Python libraries newspaper3k andhtmldate . We subse-\nquently remove any leftover boilerplate language ( i.e., nav-\nigation links, headers, and footers) from the text using the\njustext Python library and remove any non-English articles\nbased on labels provided by the Python langdetect library.\nWe embed the constituent passages , rather than full articles\ngiven the context window size limitations of the large lan-\nguage that we use in this work. Furthermore, as argued by\nHanley et al. [62] and shown by Pikbus et al. [110], given that\narticles often address multiple ideas, embedding passages\nallows us to track the often single idea present within the\npassage. Our dataset consists of 428,051,085 passages.\nB PEFT through LoRA\nWe utilize Parameter Efficient Fine-Tuning /PEFT [86]\nthrough Low-Rank Adaption /LoRA [69] to fine-tune and\nadapt pre-trained models to our datasets and to better their\nperformance. LoRA, specifically, after freezing the weights\nof the original pre-trained model learns pairs of low-rank-\ndecomposition matrices, reducing the amount of parameters\nthat need to be learned. LoRA has been shown to often out-\nperform other types of adaptions including full-tuning [69].\nOnce learned, these matrices are merged with the original\nfrozen weights. LoRA requires the specification of the rank\nof the matrices learned and an \u03b1value that scales the learned\nparameters. Within this work, we learn LoRA matrices for\nthe attention and the dense/linear layers of our models and\nutilize the commonly used defaults of rank=8 and \u03b1=16 [69].\nCTraining with Unsupervised Contrastive Loss\nTo adapt our embedding models to our news dataset, we uti-\nlize unsupervised contrastive learning [47]. For training, this\nis such that we embed each example xi= (passage i)\u2208DNews\n(where passage iis the passage text) twice (with dropout both\ntimes) with a given model by inputting [CLS]text i[SEP]and\naveraging the contextual word vectors of the resulting outputs\nas hidden vectors hiand\u02dchiforpassage ias its representations.\nThen, given a set of hidden vectors {hi}Nb\ni=0and{\u02dchj}Nb\nj=0(dif-\nferent dropout), where Nbis the size of the batch, we perform\na contrastive learning step for each batch. This is such that\nfor each Batch B, for an anchor hidden embedding hiwithin\nthe batch, the set of hidden vectors hi,\u02dchj\u2208B, vectors where\ni=jare positive pairs. Other pairs where i\u0338=jare considered\nnegative pairs. Within each batch B, the contrastive loss is\ncomputed across all positive pairs in the batch:\nLsim=\u22121\nNb\u2211\nhi\u2208Blc(hi)\nlc(hi) =log\u2211j\u2208B 1[i=j]exp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\n\u2211j\u2208Bexp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\nwhere, as in prior work [62, 87], we utilize a temperature\n\u03c4=0.07. When performing fine-tuning, we utilize default\nhyperparameters (learning rate 3\u00d710\u22125, batch size=128, and\n1M examples) specified in Gao et al. [47].\nD Pointwise Mutual Information\nThe PMI of a word word iin a cluster Cjis calculated:\nPMI(word i,Cj) =log2P(word i,Cj)\nP(word i)P(Cj)\nwhere Pis the probability of occurrence and a scaling parame-\nter\u03b1=1is added to the counts of each word per cluster. This\nscaling parameter \u03b1prevents low-frequency words in each\ncluster from having the highest PMI value [133].\nE Optimized DP-Means\nDP-Means [79] is a non-parametric extension of the K-means\nalgorithm that does not require the specification of the number\nof clusters a priori . Within DP-Means, when a given datapoint\nis a chosen parameter \u03bbaway from the closest cluster, a new\ncluster is formed. Dinari et al. [38] parallelize this algorithm\nbydelaying cluster creation until the end of the assignment\nstep. Namely, instead of creating a new cluster each time a\nnew datapoint is discovered, the algorithm determines which\ndatapoint is furthest from the current set of clusters and thencreates a new cluster with that datapoint. By delaying cluster\ncreation, the DP-means algorithm can be trivially parallelized.\nFurthermore, by delaying cluster creation, this version of DP-\nMeans avoids over-clustering the data ( i.e.,only the most\ndisparate datapoints create new clusters) [38].\nF Evaluation on SemEval22 Task 8\n0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80\nCosine Similarity Threshold0.00.10.20.30.40.50.60.70.80.91.0Metric on STS22-ENPrecision\nRecall\nF1-Score\nFigure 12: Evaluation of our model\u2019s precision, recall, and F1scores\non the English portion of the SemEval22 test dataset [29] (using 3.0\nas the cut-off for the two articles being about the same event [57]).\nG Evaluation of Clusters\nPassages\nKeywords Checked Prec.\nlaissez-faire, progressivism, liberalism, laissez, corpus 193 96.89%\nquake, earthquake, aftershock, turkey, rubble 500 100.00%\nsinema, manchin, filibuster, kyrsten, senate 500 100.00%\nwilliamson, marianne, self-help, williamsons, sander 500 97.40%\ndysphoria, puberty, blocker, crosssex, hormone 500 100.00%\nsudan, anand, evacuation, sudanese, khartoum 500 100.00%\nrioter, slogan, bearing, capitol, drum 500 99.20%\nteixeira, dighton, guardsman, teixeiras, massachusetts 500 99.40%\nfdny, firefighter, firehouse, klein, kavanagh 500 97.00%\nbragg, alvin, rouser, nypd, rabble 500 95.60%\ntaliban, afghan, afghanistan, hunger, malnutritio 500 100.00%\neyesight, blindness, blind, eye, sight 500 99.40%\nmaralago, classified, ballroom, fundraiser, document 500 100.0%\ncarolina, vetoproof, map, raleigh, cooper 500 99.80%\ntarantino, quentin, pulp, cinema, filmmaker 500 99.20%\nseoul,korea, posco, compensate, keb 500 100.00%\nmiscarriage, pregnant, pregnancy, csection, motherhood 500 100.00%\nfaucis, niaid, anthony, gain-of-function, allergy 500 100.00%\ncrump, arbery, breonna, ahmaud, trayvon 500 99.08%\nportuguese, slave, plantation, colony, dutch 500 100.00%\ncadet, guard, harassment, assault, adjutant 500 100.00%\nspam, bot, musk, twitter, elon 500 98.80%\nufo, roswell, sighting, saucer, alien 500 100.00%\ncpu, intel, x86, processor, amd 500 96.40%\nchappelle, comedian, isaiah, onstage, attacker 500 100.00%\nburisma, pozharskyi, vadym, hunter, zlochevsky 500 100.00%\nbridgerton, penelope, featherington, daphne, coughland 500 100.00%\nnaloxone, narcan, over-the-counter, emergent, nasal 500 100.00%\nschmitt, greitens, hartzler, missouri, trudy 100 99.20%\ncurrency, dollar, yuan, reserve, de-dollarization 500 99.80%\nPrec. 99.26%", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "author": ["HWA Hanley", "E Okabe", "Z Durumeric"], "pub_year": "2025", "venue": "34th USENIX Security Symposium \u2026", "abstract": "Understanding how misleading and outright false information enters and spreads within news  ecosystems remains a difficult challenge that requires tracking how stories spread across"}, "filled": false, "gsrank": 395, "pub_url": "https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-487-hanley.pdf", "author_id": ["ewdWfOoAAAAJ", "", "TxPSRHIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:oOyDranV6BgJ:scholar.google.com/&output=cite&scirp=394&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=oOyDranV6BgJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=1794919376244436128&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:oOyDranV6BgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-487-hanley.pdf"}}, {"title": "Fact-checking meets fauxtography: Verifying claims about images", "year": "2019", "pdf_data": "Fact-Checking Meets Fauxtography: Verifying Claims About Images\nDimitrina Zlatkova\nSo\ufb01a University\n\u201cSt. Kliment Ohridski\u201d\nSo\ufb01a, Bulgaria\ndvzlatkova@uni-sofia.bgPreslav Nakov\nQatar Computing Research Institute,\nHBKU\nDoha, Qatar\npnakov@qf.org.qaIvan Koychev\nSo\ufb01a University\n\u201cSt. Kliment Ohridski\u201d\nSo\ufb01a, Bulgaria\nkoychev@fmi.uni-sofia.bg\nAbstract\nThe recent explosion of false claims in social\nmedia and on the Web in general has given\nrise to a lot of manual fact-checking initia-\ntives. Unfortunately, the number of claims that\nneed to be fact-checked is several orders of\nmagnitude larger than what humans can han-\ndle manually. Thus, there has been a lot of\nresearch aiming at automating the process. In-\nterestingly, previous work has largely ignored\nthe growing number of claims about images.\nThis is despite the fact that visual imagery\nis more in\ufb02uential than text and naturally ap-\npears alongside fake news. Here we aim at\nbridging this gap. In particular, we create a\nnew dataset for this problem, and we explore\na variety of features modeling the claim, the\nimage, and the relationship between the claim\nand the image. The evaluation results show\nsizable improvements over the baseline. We\nrelease our dataset, hoping to enable further re-\nsearch on fact-checking claims about images.\n1 Introduction\nAs social media become a bigger part of our daily\nlives, their in\ufb02uence over the way people think and\nmake decisions increases. Inevitably, this has of-\nfered opportunities for fake content to arise and to\nspread faster than ever, e.g., recent research has\nshown that fake news spreads six time faster than\nreal news (V osoughi et al., 2018). Sometimes such\ncontent is created for pure entertainment or for \ufb01-\nnancial gain from advertisement shown alongside\nthe fake content, but more often and especially re-\ncently it has been used to spread disinformation,\ne.g., with the aim to in\ufb02uence political elections\n(Atanasov et al., 2019). To deal with the prob-\nlem, a number of manual fact-checking initiatives\nhave been launched, but they remain insuf\ufb01cient\nto cope with the ever growing number of check-\nworthy claims. Thus, automated methods have\nbeen proposed as a more scalable solution.\n(a) A series of images show\na Tesla vehicle in space.\n(b) Photograph shows a \ufb01re\nrainbow over Idaho.\nFigure 1: Examples of Real images and True claims.\nRecently, a growing number of claims have\nbeen about images. The word Fauxtography has\nbeen used to describe images, especially news\nphotographs, that convey a questionable, or out-\nright false, sense of the events they seem to depict.\nThe term was coined over a decade ago (Cooper,\n2007), and there is growing research interest in the\ntopic in the Computer Vision community (Bayar\nand Stamm, 2016; de Carvalho et al., 2016). Given\nthe recent proliferation of fake news, and given\nthat many of the questionable claims are about im-\nages, it would be natural to expect similar interest\nin the Computational Linguistics community, es-\npecially given the fact that visual imagery is more\nin\ufb02uential than text and naturally appears along-\nside fake news. Yet, computational fact-checking\nhas mostly ignored the growing number of claims\nabout images. Here we aim at bridging this gap.\nIn particular, we create a new dataset for this prob-\nlem, and we explore a variety of features modeling\nthe claim, the image, and the relationship between\nthe claim and the image.\nLet us look at some examples. Figure 1 shows\ntwo images that look surrealistic, and thus spark\ninterest and raise natural suspicion. Yet, they are\nin fact real.1;2\n1http://www.snopes.com/fact-check/\ntesla-car-really-space\n2http://www.snopes.com/fact-check/\nfire-rainbowarXiv:1908.11722v1  [cs.CL]  30 Aug 2019\n(a) A photograph shows a\nmountain resembling a tur-\ntle.\n(b) A photograph shows\nRussian president Vladimir\nPutin aggressively pulling\non U.S. president Barack\nObama\u2019s tie.\nFigure 2: Examples of Fake images and False claims.\nFigure 2 contains fake images accompanied by\nfalse claims. On the left, in Figure 2a, we see an\nimage from a Facebook page that claims to show\na turtle mountain. It turns out that this is not a\ngenuine photograph of a real-world location, but\na digital artwork comprising altered versions of\nat least two different photographs.3On the right,\nFigure 2b displays an image purportedly showing\nPutin aggressively grabbing President Obama by\nthe tie and pulling him close. This image has been\ndigitally manipulated.4\nFinally, Figure 3 shows original photographs\nwith false claims about them. The image in Fig-\nure 3a shows Trump with his \ufb01sts in the air, but\nhis gesture is not a greeting to a cancer victim as\nthe claim states. The real image was used as a part\nof a meme5that was designed to make it seem that\nway. The photo in Figure 3a was posted by a Twit-\nter account in an attempt to go viral, claiming that\nit shows a real bunny sitting in the palm of some-\none\u2019s hand. It actually shows a plush doll.6\nAs we have seen above, there are a number of\nreasons why an image may be deemed fake. In\nmost cases, this involves some kind of digital ma-\nnipulation, e.g., cropping, splicing, etc. However,\nthere are cases when an image is completely legit-\nimate, but it is published alongside some text that\ndoes not re\ufb02ect its content accurately. This is our\nmain focus here: we study the factuality of image-\nclaim pairs.\n3http://www.snopes.com/fact-check/\nturtle-mountain-photo/\n4http://www.snopes.com/fact-check/\nputin-obama-tie-pull/\n5http://www.snopes.com/fact-check/\ntrump-fistpump-cancer-greeting/\n6http://www.snopes.com/fact-check/\nbunny-toy-photograph/\n(a) President Trump\u2019s notorious\n\u2018\ufb01st pump\u2019 at a Pennsylvania\nairport on 9/11 was offered as a\ngreeting to a cancer victim.\n(b) A photograph shows\na palm-sized rabbit.\nFigure 3: Examples of True images and False claims.\nThe contributions of this paper can be summa-\nrized as follows:\n\u000fWe study a new problem: predict the factual-\nity of a claim with respect to an image.\n\u000fWe create a new dataset for this problem,\nwhich we release to the research community\nin order to enable further work.\n\u000fWe explore a variety of features, and we\ndemonstrate sizable improvements over the\nbaseline.\nThe remainder of this paper is organized as fol-\nlows: Section 2 presents some relevant related\nwork. Section 3 describes in depth our method and\nthe various features we experimented with. Sec-\ntion 4 gives details about the datasets we created\nand used. Section 5 describes our experimental\nsetup and presents the evaluation results. Section 6\ngives additional details about the performance of\nthe individual features, both in isolation and in\nvarious combinations, and further describes some\nunsuccessful attempts at extracting better features.\nFinally, Section 7 presents our conclusions and\nsome ideas for future work.\n2 Related Work\n2.1 Fact-checking Claims\nThere has been a lot of research in the last few\nyears in automatic fact-checking of claims and ru-\nmors, which can be classi\ufb01ed into two general cat-\negories. The \ufb01rst approach focuses on the social\naspects of the claim and how users in social me-\ndia react to it (Canini et al., 2011; Castillo et al.,\n2011; Ma et al., 2016; Zubiaga et al., 2016; Ma\net al., 2017; Dungs et al., 2018). This is re\ufb02ected\nby user comments, likes/dislikes, views and other\ntypes of reactions, which are collected and used as\nfeatures.\nOther methods use the Web and try to \ufb01nd in-\nformation that proves or disproves the claim\n(Mukherjee and Weikum, 2015; Popat et al., 2017;\nKaradzhov et al., 2017; Mihaylova et al., 2018;\nBaly et al., 2018b). In either case, what is impor-\ntant is the stance (Riedel et al., 2017; Thorne et al.,\n2017; Hanselowski et al., 2018; Mohtarami et al.,\n2018, 2019): whether the opinion expressed in a\ntweet or in an article by a particular user/source\nagrees/disagrees with the claim, and the reliability\nof the source, i.e., can we trust this source (Baly\net al., 2018a, 2019).\nWe should note that all these approaches are\nlimited to textual claims, while we are interested\nin claims about images.\n2.2 Detecting Fake/Manipulated Images\nThe task of detecting fabricated images falls under\nthe area of image forensics. Such tasks are usually\nsolved using traditional statistical methods mod-\neling color, shape, and texture features (Bayram\net al., 2006; Stamm and Liu, 2010; de Carvalho\net al., 2016). More recently, with the rise of\nDeep Learning, modern approaches and architec-\ntures have been applied to tackle the problem (Ba-\nyar and Stamm, 2016). However, most existing\nwork uses datasets with generic images and very\nfew papers specialize in the area of news and so-\ncial media (Jin et al., 2016). Detecting manipu-\nlation in the images is relevant for us, but is not\nenough, since often the image is original, but the\nclaim about it is false.\n2.3 Fact-Checking Claims about Images\nLittle research exists on the topic of fact-checking\nclaims about images, where the input to be an-\nalyzed is an image-claim pair. To the best of\nour knowledge, there is only one work closely re-\nlated to ours: a recent paper (Zhang et al., 2018)\npresents a system called FauxBuster which aims to\n\ufb01ght against Fauxtography. We differ from them\nin that we use the Web as a source of information.\nIn contrast, they focus on the social aspects of the\nproblem and use comments on Twitter and Reddit\nto extract features, which makes our work com-\nplementary to theirs. Unfortunately, direct com-\nparison to their approach is not feasible, as their\ndataset is not freely accessible.3 Method\nThis section describes the different approaches we\napplied towards engineering and extracting fea-\ntures from the image-claim pair.\nWe start with reverse image search . The classi-\ncal image search allows users to search for images\nbased on a text with speci\ufb01c words or phrases. In\ncontrast, reverse image search takes as input an\nimage and returns Web pages that include this ex-\nact image or images that are very similar to it. This\nprocess can be easily automated and applied to a\nlarge number of images via Google\u2019s Vision API.7\nIt can also return other information related to the\nimage, e.g., tags, the text on the image, some ob-\nject detection, explicit content, etc.\nUsing reverse image search, for each image we\nobtain a maximum of 50 Web pages that con-\ntain it. We remove pages that are known to be\nfrom fact-checking Web sites such as snopes.com,\nfactcheck.org, using open-source code.8For the\nremaining Web pages, we crawl the article and we\nget its title and text.\n3.1 Features about the Image\nGoogle tags : This is a list of tags that Google as-\nsociates with the image. We decided to use this list\nbecause it contains words and phrases about events\nand people related to the image, which might give\nus an insight about what the image contains and\nwhat it is about. For example, the image in Fig-\nure 1a has the following tags: SpaceX, Falcon\nHeavy, Rocket, Rocket launch, Falcon, Company,\nLaunch pad, Booster, Thrust, Entrepreneur, Elon\nMusk . After lowercasing them and removing stop\nwords, we use them directly as bag-of-words fea-\ntures.\nURL domains : The Web pages that contain\nthe image usually come from media sources and\nrepresent articles on a topic related to the image\nand/or the claim attached to it. However, in some\ncases they might point to an image-hosting ser-\nvice or a social network Web site such as Pinterest,\nImgur, Twitter, etc. In an effort to use this fact, we\nextracted the top-level domain names from the list\nof URLs and we used them as TF.IDF features.\nURL categories : In order to get more insight\nabout what types of websites write about fake and\ngenuine images, we classify them in several pre-\nde\ufb01ned URL categories.\n7http://cloud.google.com/vision/\n8github.com/clef2018-factchecking\nWe use open-source code9to classify URLs,\nwhich performs rule-based matching of tokens\nfrom the URL against a prede\ufb01ned list of words.\nGiven a URL, it assigns it a tuple of one higher-\nlevel and one lower-level category. For example,\nwhen we run the algorithm on the Web sites re-\nturned for the image in Figure 1a we get category\ntuples such as: (\u2018arts & entertainment\u2019, \u2018general\u2019),\n(\u2018sports\u2019, \u2018general\u2019), (\u2018society\u2019, \u2018general\u2019), (\u2018tech-\nnology & computing\u2019, \u2018general\u2019), (\u2018science\u2019, \u2018gen-\neral\u2019), (\u2018automotive\u2019, \u2018general\u2019) and (\u2018business\u2019,\n\u2018marketing\u2019). To transform those into features, we\ntake all Web sites returned by the reverse image\nsearch for the image, and we merge the lists of\ntheir category tuples. We do not differentiate be-\ntween high- and low-level categories; rather, we\njust apply TF.IDF on the combined list.\nTrue/False/Mixed media percentage : In order\nto determine whether an image is fake or not, we\ncan also check the reliability of the sources that\nwrote about it. Media Bias/Fact Check10(MBFC)\nis a Web site that provides factuality information\nabout 2700+ media sources. We use their database\nto classify each Web page that is returned by the\nreverse image search into the following categories:\nTrue (high factuality), False (low factuality) and\nMixed (mixed factuality). Then, we use the per-\ncentage of Web pages from each category returned\nby the reverse image search as a feature.\nKnown media percentage : If a URL is not on\nthe MBFC list, we label it as Unknown and we use\nthe percentage of known Web pages as a feature.\nTrue/False/Mixed media titles : We use the ti-\ntles of the articles from a True, False or Mixed me-\ndia as bag-of-words features.\n3.2 Features about the Claim\nSo far, in our feature extraction process we have\nonly used the image from the image-claim pair,\nwhich means we might be missing crucial infor-\nmation. After manual inspection of a few exam-\nples, we realized that about half of them can be\nclassi\ufb01ed only using the image, e.g., because it is\na collage, was photoshopped, or manipulated in\nsome way. The other half contain legitimate im-\nages that might appear on trustworthy Web sites,\nbut the claim associated with them was false.\nClaim text : We transform the text of the claim\ninto a TF.IDF vector, which we use as a feature.\n9http://github.com/matthewruttley/\nmozclassify\n10http://mediabiasfactcheck.com/3.3 Features about the Image-Claim pair\nIn addition to using the claim text, we want to\ncheck how it is related to the image and whether\nthe claim is true with respect to it. We model that\nby comparing the text of the claim to the articles\nreturned by the Reverse Image Search of the im-\nage. We use only the articles from trustworthy me-\ndia sources, according to our MBFC labels. We\napproach the task of computing the similarity of\nthose texts in two different ways.\nCosine similarity : We perform the compari-\nson on the TF.IDF representations of the claim and\neach article\u2019s title. We compute a smoothed aver-\nage on the list of cosine similarities to get the \ufb01nal\nfeature value.\nEmbedding similarity : We use pretrained em-\nbeddings of size 512 (Cer et al., 2018) as a way to\nvectorize the claim and the title sentences. Then, it\nis trivial to calculate the similarity as a dot product,\nas they are already in a normalized form. Again,\nwe use a smoothed average to reduce the list of\nsimilarities to a single number.\n4 Data\nAs we have a new task, we needed to create our\nown dataset. In fact, we created two datasets from\ntwo separate sources, but with similar qualities and\nformat. The main idea behind the data collec-\ntion process was to \ufb01nd viral, interesting and even\ncontradictory images with some text that describes\nthem, i.e., the claim . Both datasets are in English.\n4.1 The Snopes Dataset\nSnopes.com is arguably the oldest and the largest\nfact-checking Web site online. It aims to \ufb01ght\nmisinformation by investigating different pieces of\nnews. The site has a special section for image-\nrelated fact-checking, called Fauxtography11. It\nuses an extensive list of labels to classify each\npiece of news as True,False ,Miscaptioned ,Mix-\nture,Undetermined ,Unproven ,Outdated , etc. For\nthe purpose of our dataset, we gather only image-\nclaim pairs that were labeled as either True or\nFalse . The collected data consists of 838 exam-\nples of which 197 True and 641 False . The huge\nimbalance of the classes might be surprising at\n\ufb01rst, but it makes sense for fact-checkers to pre-\nfer to spend their time fact-checking news pieces\nthat have a higher chance of being fake.\n11http://www.snopes.com/fact-check/\ncategory/photos\n(a) South Korean President\nMoon Jae-in and North Ko-\nrean leader Kim Jong Un\nshake hands at the truce vil-\nlage of Panmunjom inside\nthe demilitarized zone sepa-\nrating the two Koreas.\n(b) Lava erupts from a \ufb01s-\nsure east of the Leilani Es-\ntates subdivision during on-\ngoing eruptions of the Ki-\nlauea V olcano.\nFigure 4: Examples of image-claim pairs from The\nReuters Dataset.\nYet, this lack of True-labeled examples can pose\nsome challenges for classi\ufb01cation models and the\nevaluation process as well. This is why we de-\ncided to invest some time in gathering more True\nexamples as we explain below.\n4.2 The Reuters Dataset\nAt the end of each year, Reuters publishes a list of\nabout 100 photos, called Pictures of the Year . Con-\nveniently for us, each photo comes with a short\ntextual description, which we can use as a claim .\nWe collected all of these pictures from four con-\nsecutive years: 2015, 2016, 2017, and 2018. As a\nresult, we ended up with a total of 395 True image-\nclaim pairs. Some examples are shown in Fig-\nure 4. We further performed close manual inspec-\ntion, and we did not \ufb01nd any obvious differences\nbetween these images compared to the ones from\nThe Snopes Dataset . In terms of the claim, texts\nfrom Reuters seem to be longer, but this should\nnot be a problem, since we do not use the length\nas a feature.\n5 Experiments and Evaluation\n5.1 Setup\nNote that the above two datasets contain 1,233\nexamples combined, and these examples are rel-\natively well-balanced: 592 True and 641 False .\nAs this is a small size, we chose to test the per-\nformance of the models using cross-validation. If\nwe mix the data from the two sources having in\nmind that the Reuters dataset has examples from\ntheTrue class only, we fear that the models might\nimplicitly learn each example\u2019s source, not its fac-\ntuality. Hence, we designed the following two\ncross-validation experiments:Testing on Snopes-only data. Ten times, using\na different random seed, we do the following:\n1. Randomly choose 50 True and 50 False\nSnopes examples and use them as a test set.\n2. Use the rest of the True Snopes data plus all\nReuters data as True training examples.\n3. Randomly sample the necessary number of\nexamples from the False Snopes data, so that\nthe training set is balanced.\nFinally, we compute the average of the evalua-\ntion measures for all ten folds.\nTesting on Snopes + Reuters data. Ten times,\nusing a different random seed, we perform the fol-\nlowing steps:\n1. Combine all Snopes and Reuters data into a\nsingle dataset.\n2. Balance the resulting dataset by randomly\nchoosing the necessary number of False ex-\namples.\n3. Do a random train-test split, so that the test\nset contains 100 examples.\nAs in the previous experiment, we compute\nthe average of the evaluation measures for all ten\nfolds.\n5.2 Classi\ufb01cation model\nWe used a Linear SVM with the default value of\nC=1. We trained a separate SVM model for each\nfeature type, then we applied a softmax to normal-\nize the values, and \ufb01nally we averaged the con\ufb01-\ndences of the classi\ufb01ers to make the \ufb01nal decision.\n5.3 Results\nWe used the following evaluation measures:\n\u000fAccuracy , because the classes are balanced,\nand the majority-class baseline for all experi-\nments is 50.0.\n\u000fAverage Precision , since it is useful if we\nwant to have a ranking task, e.g., to priori-\ntize which claims about images human fact-\ncheckers should check \ufb01rst. Again, the ran-\ndom baseline for all experiments is 50.0.\nFeature Acc (S) AP (S) Acc (S+R) AP (S+R)\nAll 63.2 73.0 80.1 90.3\nTrue media percentage 62.1 59.3 74.6 69.8\nEmbedding similarity of claim & true media titles 61.1 62.5 74.0 69.0\nCosine similarity of claim & true media titles 61.1 58.4 73.8 69.0\nKnown media percentage 60.4 58.6 74.6 71.9\nURL domains 60.3 67.3 78.6 89.7\nGoogle tags 58.5 63.9 71.5 82.1\nMixed media percentage 58.0 56.1 62.4 60.8\nClaim text 57.1 60.8 74.9 83.8\nTrue media titles 55.8 63.1 73.6 81.4\nMixed media titles 55.4 58.5 63.1 67.2\nURL categories 53.7 56.0 70.3 76.2\nFalse media titles 50.3 50.8 50.6 50.4\nFalse media percentage 49.9 51.1 50.4 50.4\nBaseline 50.0 50.0 50.0 50.0\nTable 1: Accuracy and Average Precision for individual feature types, calculated using 10-fold cross-validation\nusing the Snopes dataset ( S), and the Snopes+Reuters dataset ( S+R).\nTable 1 illustrates the importance of each fea-\nture type in isolation. We can see that almost all\nindividual feature types manage to outperform the\ntwo 50% baselines. The only weak features are\nthose related to false sources of information: per-\ncentage of unreliable media writing about the im-\nage and the words used in the titles of the articles.\nMoreover, using all features (with a model com-\nbination as explained above) works best: 63.2%\nand 80.1% Accuracy, 73.0% and 90.3% Average\nPrecision for S and S+R, respectively. The top-3\nfeature types for the Snopes test set are true me-\ndia percentage (62.1% for S and 74.6% for S+R),\nembedding similarity (61.1% for S and 74.0%\nfor S+R), and cosine similarity (61.1% for S and\n73.8% for S+R). In either experiment, Average\nPrecision is higher than Accuracy. Larger im-\nprovements are achieved for the Snopes + Reuters\ntest set, which could be due to the model making\nmore mistakes on the True examples from Snopes\nand being better on True examples from Reuters.\nFigure 5 shows combinations of the top- nfea-\ntures using each feature\u2019s performance in terms\nof Average Precision. Note that these top fea-\ntures for the two experiments are different: we use\nthe scores in the AP(S) column in Table 1 for the\nSnopes dataset, and the AP(S+R) column for the\nSnopes+Reuters dataset. We can see that selecting\nthe top 4 to 5 features works best, yielding 65.4%,\n75.1%, 84.1% and 92.5%.Note that the Average Precision scores are\nhigher than those for Accuracy, and the scores for\nthe Snopes+Reuters dataset are higher.\n6 Discussion\n6.1 Most Important Individual Features\nAbove, we explored the performance of individ-\nual feature groups. Here we try to understand\nwhat the most important individual features are.\nFor this purpose, we trained a model on all fea-\ntures, and then we analyzed the weight of each fea-\nture in this full model. Note that this is different\nfrom the setup in the previous section, where we\ntrained a separate model for each feature group,\nand then we combined the predictions of these\nmodels in an ensemble; in contrast, here we just\nput all features from all groups together. The re-\nsults are visualized in Figure 6. We can see that\nsome of them seem random, e.g., adventures of\nhuckleberry \ufb01n oreverything trump touches dies .\nHowever, there are a few that signal false infor-\nmation, e.g., words like fake andviral mentioned\nin the title of a trustworthy medium, or tags like\nhoax andfact-checking . The existence of images\nin the dataset that were modi\ufb01ed for artistic pur-\nposes can explain tags such as artand\ufb01lm. Also,\naccording to our best features, we should not trust\nmuch images that appear on Twitter or ones related\nto sensitive topics like african americans orislam .\nFigure 5: Accuracy and Average Precision on 10-fold cross-validation using top- nfeatures.\nFigure 6: The most informative features: 20 positive\nand 20 negative. Pre\ufb01xes indicate feature types.6.2 What Did Not Work\nMetadata from images : In an attempt to capture\npossible manipulation of the input image, we gath-\nered meta information using an open-source tool12\nfor image forensics. The tool extracts metadata in\nthe form of about 100 features such as size, reso-\nlution, GPS location. However, most of this meta-\ndata turns out to be missing from our images: only\n\ufb01ve features could be extracted for more than half\nof the images from the Snopes dataset.\nImage Splice Detection : As we have already\nmentioned, one of the reasons why an image could\nbe fake is that it has been digitally manipulated.\nA common manipulation is splicing, i.e., cropping\nand stitching together parts of the same image or\nmultiple different images. We explored an ap-\nproach that looks for the lack of self-consistency\nin images and outputs clusters of the predicted im-\nage parts using two algorithms: MeanShift and\nDBSCAN (Huh et al., 2018). An illustration on\nhow it works is shown in Figure 7. We decided to\nvalidate the method by using a pretrained model,13\nwhich we applied to some images from the Snopes\ndataset that were obvious cases of splicing.\n12http://github.com/redaelli/\nimago-forensics\n13http://github.com/minyoungg/\nselfconsistency\nFigure 7: Predicted clusters for one of the images in\nthe Self-Consistency paper. Keanu Reeves has been\nspliced into the photo and his body was separated cor-\nrectly by both MeanShift and DBSCAN.\nFigure 8: Predicted clusters for one of the images in\nthe Snopes Dataset. The original image depicts an ele-\nphant; the lion and the cub have been photoshopped on\ntop (Source). The clustering algorithms did not detect\nthis splicing.\nUnfortunately, this seemed not to work for us.\nFigure 8 shows an example where the model could\nnot \ufb01nd the spliced regions. Eventually, we aban-\ndoned this direction as the inference time and the\nrequired resources were signi\ufb01cant, and the per-\nformance was not very good on our dataset.\nError Level Analysis : Error Level Analysis\n(ELA) helps to identify areas within an image that\nare at different compression levels. With JPEG\nimages such as the ones in our Snopes and Reuters\ndatasets, the entire image should be at roughly the\nsame level. If a section of the image is at a signif-\nicantly different error level, this would indicate a\nlikely digital modi\ufb01cation.\nELA works by intentionally resaving the image\nat a known error rate such as 95%, and then com-\nputing the difference between the images. If there\nis virtually no change, then the cell has reached its\nlocal minima for error at that quality level. How-\never, if there is a large change, then the pixels are\nnot at their local minima and are effectively origi-\nnal. This method can be used to identify splicing,\nbecause stitched regions will appear brighter on\nthe ELA version of the image. This is illustrated\nin Figure 9. After manual inspection of ELA ver-\nsions of images from our dataset, we did not \ufb01nd\nthe method to be very promising, see Figure 10.\nFigure 9: One of the ELA examples on http://\nfotoforensics.com . The part of the image with a\n\ufb02oppy disk appears brighter on the ELA map, as it was\nspliced on top of the original.\nFigure 10: ELA applied to one of the images from the\nSnopes dataset. The spliced regions, i.e., the lion and\nthe cub, could not be identi\ufb01ed.\n6.3 Testing on New Data\nAll of the experiments described so far were per-\nformed on claim-image pairs from Snopes that\nwere published in the period between November\n20, 2000 and February 1, 2019. The data from\nFebruary up until April 29, 2019 has been left un-\ntouched, which makes it suitable for performing\none \ufb01nal test of the developed system. In these\nthree months, 64 articles were published in the\nFauxtography section, of which 14 were labeled as\nTrue and 25 as False . To balance this new test set,\nwe subsampled 14 False examples randomly. The\ntraining was performed on all previously collected\ndata from Snopes and Reuters, balanced in the\nsame way. For better certainty of the performance,\nwe sampled randomly the training and the test sets\nten times, and we report the average scores.\nThe results when using the top features based\non the Average Precision for the Snopes dataset\nare shown in Table 2. We can see that the best\nAverage Precision is achieved by using the single\ntop feature of URL domains: 71.7%. When we\nadd to this the second best one, i.e., the Google\ntags, we get an Accuracy of 64.3%. The scores of\nthe models that use more than three features are\nnot displayed since they were not as good.\nThe best-performing features across the exper-\niments differ, but as Table 1 shows, the URL do-\nmains are top-1 in three out of four experiments,\nandclaim text is top-2 in two out of four experi-\nments.\nFeatures Acc AP\nAll 59.3 69.7\nTop 1 62.9 71.7\nTop 2 64.3 70.4\nTop 3 57.5 70.6\nBaseline 50.0 50.0\nTable 2: Accuracy and Average Precision on the New\ntest dataset.\n7 Conclusion and Future Work\nWe have presented our efforts towards \ufb01ghting\nFauxtography, namely detecting fake claims about\nimages, which is an under-explored research di-\nrection. In particular, we created a new dataset\nfor this problem, and we explored a variety of fea-\ntures modeling the claim, the image, and the rela-\ntionship between the two. The evaluation results\nhave shown sizable improvements over the base-\nline. We release our dataset,14hoping to enable\nfurther research on fact-checking claims about im-\nages.\nIn future work, we plan to extend the dataset\nwith more examples, to try other features,\ne.g., from social media and from metadata,15and\nto adapt the system to work with other languages.\nWe further plan experiments with fact-checking\nclaims about videos.\nAcknowledgements\nThis research is part of the Tanbih project,16which\naims to limit the effect of \u201cfake news\u201d, propa-\nganda and media bias by making users aware of\nwhat they are reading. The project is developed\nin collaboration between the Qatar Computing\nResearch Institute (QCRI), HBKU and the MIT\nComputer Science and Arti\ufb01cial Intelligence Lab-\noratory (CSAIL).\n14http://gitlab.com/didizlatkova/\nfake-image-detection\n15The lack of metadata that we observed can be explained\nby the fact that Snopes.com is not the original source of the\nimage \ufb01les; it collected images from various external sources.\nThose sources might not be the original creator either and\nmultiple downloading and uploading of \ufb01les, with possible\nreformatting could mean loss of metadata as many Web sites\nreformat images and/or delete/change the metadata of the im-\nages uploaded to it. Finally, we could not extract any EXIF\nmetadata for the Reuters images, even though we got them\nfrom Reuters. Yet, maybe the metadata can be recovered us-\ning Reverse Image Search.\n16http://tanbih.qcri.org/References\nAtanas Atanasov, Gianmarco De Francisci Morales,\nand Preslav Nakov. 2019. Understanding the roles\nof political trolls in social media. In Proceed-\nings of the 2019 SIGNLL Conference on Compu-\ntational Natural Language Learning , CoNLL \u201919,\nHong Kong, China.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018a. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing ,\nEMNLP \u201918, pages 3528\u20133539, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames Glass, and Preslav Nakov. 2019. Multi-task\nordinal regression for jointly predicting the trustwor-\nthiness and the leading political ideology of news\nmedia. In Proceedings of the 17th Annual Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201919, pages 2109\u2013\n2116, Minneapolis, MN, USA.\nRamy Baly, Mitra Mohtarami, James Glass, Llu \u00b4\u0131s\nM`arquez, Alessandro Moschitti, and Preslav Nakov.\n2018b. Integrating stance detection and fact check-\ning in a uni\ufb01ed corpus. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , NAACL-HLT \u201918, pages\n21\u201327, New Orleans, LA, USA.\nBelhassen Bayar and Matthew C. Stamm. 2016. A\ndeep learning approach to universal image ma-\nnipulation detection using a new convolutional\nlayer. In Proceedings of the 4th ACM Workshop\non Information Hiding and Multimedia Security ,\nIH&MMSec \u201916, pages 5\u201310, Vigo, Spain.\nSevinc \u00b8 Bayram, Ismail Avcibas, B \u00a8ulent Sankur, and\nNasir D Memon. 2006. Image manipulation detec-\ntion. Journal of Electronic Imaging , 15(4):041102.\nKevin R. Canini, Bongwon Suh, and Peter L. Pirolli.\n2011. Finding credible information sources in so-\ncial networks based on content and social structure.\nInProceedings of the IEEE International Confer-\nence on Privacy, Security, Risk, and Trust, and the\nIEEE International Conference on Social Comput-\ning, SocialCom/PASSAT \u201911, pages 1\u20138, Boston,\nMA, USA.\nTiago Jose de Carvalho, F \u00b4abio Augusto Faria, H \u00b4elio\nPedrini, Ricardo da Silva Torres, and Anderson\nRocha. 2016. Illuminant-based transformed spaces\nfor image forensics. IEEE Transactions on Informa-\ntion Forensics and Security , 11:720\u2013733.\nCarlos Castillo, Marcelo Mendoza, and Barbara\nPoblete. 2011. Information credibility on Twitter. In\nProceedings of the 20th International Conference on\nWorld Wide Web , WWW \u201911, pages 675\u2013684, Hy-\nderabad, India.\nDaniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua,\nNicole Limtiaco, Rhomni St. John, Noah Constant,\nMario Guajardo-Cespedes, Steve Yuan, Chris Tar,\nBrian Strope, and Ray Kurzweil. 2018. Universal\nsentence encoder for English. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201918, pages 169\u2013174,\nBrussels, Belgium.\nStephen Cooper. 2007. A concise history of the faux-\ntography blogstorm in the 2006 Lebanon war. Amer-\nican Communication Journal , 9.\nSebastian Dungs, Ahmet Aker, Norbert Fuhr, and\nKalina Bontcheva. 2018. Can rumour stance alone\npredict veracity? In Proceedings of the 27th In-\nternational Conference on Computational Linguis-\ntics, COLING \u201918, pages 3360\u20133370, Santa Fe, NM,\nUSA.\nAndreas Hanselowski, Avinesh PVS, Benjamin\nSchiller, Felix Caspelherr, Debanjan Chaudhuri,\nChristian M. Meyer, and Iryna Gurevych. 2018. A\nretrospective analysis of the fake news challenge\nstance-detection task. In Proceedings of the 27th\nInternational Conference on Computational Lin-\nguistics , COLING \u201918, pages 1859\u20131874, Santa Fe,\nNM, USA.\nMinyoung Huh, Andrew Liu, Andrew Owens, and\nAlexei A. Efros. 2018. Fighting fake news: Im-\nage splice detection via learned self-consistency. In\nComputer Vision \u2013 ECCV 2018 , pages 106\u2013124,\nCham. Springer International Publishing.\nZhiwei Jin, Juan Cao, Yongdong Zhang, Jianshe Zhou,\nand Qi Tian. 2016. Novel visual and statistical im-\nage features for microblogs news veri\ufb01cation. IEEE\nTransactions on Multimedia , PP:1\u20131.\nGeorgi Karadzhov, Preslav Nakov, Llu \u00b4\u0131s M `arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, and Ivan Koychev. 2017.\nFully automated fact checking using external\nsources. In Proceedings of the Conference on Re-\ncent Advances in Natural Language Processing ,\nRANLP \u201917, pages 344\u2013353, Varna, Bulgaria.\nJing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon,\nBernard J. Jansen, Kam-Fai Wong, and Meeyoung\nCha. 2016. Detecting rumors from microblogs with\nrecurrent neural networks. In Proceedings of the\n25th International Joint Conference on Arti\ufb01cial In-\ntelligence , IJCAI \u201916, pages 3818\u20133824, New York,\nNY , USA.\nJing Ma, Wei Gao, and Kam-Fai Wong. 2017. De-\ntect rumors in microblog posts using propagation\nstructure via kernel learning. In Proceedings of the\n55th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201917, pages 708\u2013717, Van-\ncouver, Canada.\nTsvetomila Mihaylova, Preslav Nakov, Llu \u00b4\u0131s M`arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, Mitra Mohtarami, Georgi\nKaradjov, and James Glass. 2018. Fact checking incommunity forums. In Proceedings of the Thirty-\nSecond AAAI Conference on Arti\ufb01cial Intelligence ,\nAAAI \u201918, pages 879\u2013886, New Orleans, LA, USA.\nMitra Mohtarami, Ramy Baly, James Glass, Preslav\nNakov, Llu \u00b4\u0131s M `arquez, and Alessandro Moschitti.\n2018. Automatic stance detection using end-to-\nend memory networks. In Proceedings of the 16th\nAnnual Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , NAACL-HLT \u201918,\npages 767\u2013776, New Orleans, Louisiana, USA.\nMitra Mohtarami, James Glass, and Preslav Nakov.\n2019. Contrastive language adaptation for cross-\nlingual stance detection. In Proceedings of the 2019\nConference on Empirical Methods in Natural Lan-\nguage Processing , EMNLP \u201919, Hong Kong, China.\nSubhabrata Mukherjee and Gerhard Weikum. 2015.\nLeveraging joint interactions for credibility analy-\nsis in news communities. In Proceedings of the\n24th ACM International on Conference on Informa-\ntion and Knowledge Management , CIKM \u201915, pages\n353\u2013362, Melbourne, Australia.\nKashyap Popat, Subhabrata Mukherjee, Jannik\nStr\u00a8otgen, and Gerhard Weikum. 2017. Where the\ntruth lies: Explaining the credibility of emerging\nclaims on the Web and social media. In Proceedings\nof the 26th International Conference on World Wide\nWeb Companion , WWW \u201917, pages 1003\u20131012,\nPerth, Australia.\nBenjamin Riedel, Isabelle Augenstein, Georgios P Sp-\nithourakis, and Sebastian Riedel. 2017. A simple but\ntough-to-beat baseline for the Fake News Challenge\nstance detection task. ArXiv:1707.03264 .\nMatthew C Stamm and KJ Ray Liu. 2010. Forensic\ndetection of image manipulation using statistical in-\ntrinsic \ufb01ngerprints. IEEE Transactions on Informa-\ntion Forensics and Security , 5(3):492\u2013506.\nJames Thorne, Mingjie Chen, Giorgos Myrianthous,\nJiashu Pu, Xiaoxuan Wang, and Andreas Vlachos.\n2017. Fake news stance detection using stacked en-\nsemble of classi\ufb01ers. In Proceedings of the EMNLP\nWorkshop on Natural Language Processing meets\nJournalism , pages 80\u201383, Copenhagen, Denmark.\nSoroush V osoughi, Deb Roy, and Sinan Aral.\n2018. The spread of true and false news online.\n359(6380):1146\u20131151.\nDaniel Yue Zhang, Lanyu Shang, Biao Geng, Shuyue\nLai, Ke Li, Hongmin Zhu, Md Tanvir Amin, and\nDong Wang. 2018. Fauxbuster: A content-free faux-\ntography detector using social media comments. In\n2018 IEEE International Conference on Big Data ,\nBigData \u201918, pages 891\u2013900. IEEE.\nArkaitz Zubiaga, Maria Liakata, Rob Procter, Geral-\ndine Wong Sak Hoi, and Peter Tolmie. 2016.\nAnalysing how people orient to and spread rumours\nin social media by looking at conversational threads.\nPLoS ONE , 11(3):1\u201329.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fact-checking meets fauxtography: Verifying claims about images", "author": ["D Zlatkova", "P Nakov", "I Koychev"], "pub_year": "2019", "venue": "arXiv preprint arXiv:1908.11722", "abstract": "The recent explosion of false claims in social media and on the Web in general has given rise  to a lot of manual fact-checking initiatives. Unfortunately, the number of claims that need to"}, "filled": false, "gsrank": 396, "pub_url": "https://arxiv.org/abs/1908.11722", "author_id": ["lqrAOcYAAAAJ", "DfXsKZ4AAAAJ", "o5YAI9wAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:OktUlLXJbY0J:scholar.google.com/&output=cite&scirp=395&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=OktUlLXJbY0J&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 125, "citedby_url": "/scholar?cites=10191023313524116282&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:OktUlLXJbY0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1908.11722"}}, {"title": "Metaliteracy in the Developmental Classroom", "year": "2024", "pdf_data": " \n \nVolume 1, Issue 1               Fall 2024  \nMetaliteracy in the Developmental Classroom \n \nHeather Michelle McGrew  \nUniversity of Wisconsin- Superior  \n \nAbstract  \n \nThis paper investigates the origins of metaliteracy with a focus on media bias, misinformation, and disinformation and their pedagogical implications for information literacy (IL) in the writing classroom. Grounding the conversation in cognitive dissonance theory and confirmation bias \ntheory, the paper offers an overview of multiple web- based IL tool s\u2014including media bias \ncharts and scales, fact -checking sites, and self -directed tools such as the CRAAP test and Jack \nCaulfield\u2019s SIFT method (aka The Four Moves) \u2014and suggests pedagogical practices \nspecifically for developmental writing classrooms. Concepts and practices that fall under the \numbrella of metaliteracy including digital literacy, cyberliteracy, visual literacy, and transliteracy  \nare discussed as ski lls that are increasingly important for college students as they interact with \ninformation  dynamically in the landscape of today\u2019s complex digital age . \n Keywords:  metaliteracy, information literacy (IL), media bias, misinformation, disinformation, \ndevelopmental writing  \n Recommended Citation  \n McGrew, H. M. (2024). Metaliteracy in the developmental classroom. Journal of the National \nOrganization for Student Success , 1(1), 55- 69. https://doi.org/10.61617/jnoss.14 \n \n  \n\nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  56 \n Introduction \n \nToday\u2019s college students must wade through an unprecedented amount of information \nwhich they are expected to assess daily \u2014some of which legitimately qualifies as \n\u201cmisinformation\u201d and/or \u201cdisinformation.\u201d The techniques required to identify a source\u2019s credi bility, veracity, and lack of bias have become increasingly complex. The need for such \nskills is further heightened for students who arrive at college underprepared and place into developmental reading and/or writing courses. Therefore, higher -education pr actitioners, \nparticularly those who teach developmental courses, must be prepared to dedicate adequate time and resources to teach students effective and robust strategies to make evidence -based decisions \nabout a source\u2019s relevance and usefulness to them as researchers as well as to thoughtfully produce their own content in online communities . Effective metaliteracy instruction requires \npractitioners to familiarize themselves with useful resources, recognize their own biases, and regularly update their approaches to respond to the dynamic nature of how we share, consume, and respond to information in today\u2019s complex world.  \nThe purpose of this paper is to briefly discuss the histories, theories, and current \nresources associated with information literacy (IL) and metaliteracy along with implications for pedagogical practice in higher education, specifically in the developmental classroom. We will look at the background of IL, including the evolution of the term itself and two useful theories that undergird IL i nstruction , as well as the general educational shift to focus more on the \npractice of metaliteracy, which \u201c is a unified construct that supports the acquisition, production, \nand sharing of knowledge in collaborative online communities \u201d (Mackay & Jacobson, 2 011, p. \n62). We will also consider the current state of media bias , how the prevalence of \n\u201cmisinformation,\u201d and \u201cdisinformation\u201d have impacted the metaliteracy practices,  and \ncommon/best classroom practices for IL  and metaliteracy  instruction. Then we will  consider the \nmethodologies, benefits and drawbacks of various resources for classroom use including media bias charts, fact -checking tools , and self -directed evaluation tools . Finally, we will consider \nimplications for the developmental classroom and draw  some conclusions that can inform \npractitioners as we move forward in this rapidly changing field. \n \nBackground: History of Information Literacy and Metaliteracy  \n \nOriginally coined in Australia in 1964, the term \u201cinformation literacy\u201d was first used in \nthe United States in 1974 by Paul G. Zurkowski, the then- president of the Software and \nInformation Industry Association. The term was adopted three years later by the American Librarian Association (ALA) as a key instructional component , and in 2009, President  Obama \nestablished October as National Information Literacy Awareness month. Now half a decade old, the term has survived multiple iterations and definitions as the ways in which information is created, shared, and consumed have changed profoundly.  \nIL ski lls have long been a fundamental component of the higher education curriculum. \nNearly 30 years ago, Shapiro and Hughes (1996) explained the importance of IL in the context of a liberal arts education:  \n[I]nformation  literacy should in fact be conceived more broadly as a new liberal art that \nextends from knowing how to use computers and access information to critical reflection on the nature of information itself, its technical infrastructure, and its social, cultural and \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  57 \n even philosophical context and impact -  as essential to the mental framework of the \neducated information- age citizen as the trivium of basic liberal arts (grammar, logic and \nrhetoric) was to the educated person in medieval society. (p. 2)  \nOver the years, as the search for information has shifted primarily from books and physical \nartifacts to electronic resources, the critical thinking practices required for information literacy have necessarily shifted as well.  \nIn response to this notable shift, Mackey and Jacobs on (2011) suggested a revised term to \nreframe  information literacy: metaliteracy. T o distinguish between traditional IL and \nmetaliteracy, t hey a sserted , \u201cWhile information literacy prepares individuals to access, evaluate, \nand analyze information, metaliteracy prepares individuals to actively produce and share content through social media and online communities \u201d (Mackey & Jacob son, 2011, p. 76). This revised \ndefinition takes into account the dynamic nature of how information in the c urrent age is actively \nand collaboratively produced and distributed. The term also refers to a learner\u2019s ability to regularly reflect on their own thinking processes and adapt to a host of new and emerging technologies such as social media platforms and ot her open spaces where information is shared \nand consumed (Jacobson & Mackey, 2013). Ultimately, then, metaliteracy is an expansion of information literacy that takes into account four domains of learning\u2014cognitive, metacognitive, behavioral, and affective (Jacobson et al., 2021) \u2014and considers new and emerging tools used to \nproduce and share information in a shifting online environment. Metaliteracy is an umbrella term that encompasses concepts and practices such as digital literacy, cyberliteracy, visual li teracy, \nand transliteracy \u2014all skills that are increasingly important for college students as they interact \nwith information in our current digital age. \n \nIL and metaliteracy skills are complicated further by this current era in which the terms \n\u201cdisinformation\u201d and \u201cmisinformation\u201d are widely\u2014and arguably rather liberally \u2014used ; as a \nresult,  today\u2019s college students must understand how to assess sources for reliability, credibility, \nand accuracy as they consume, create, and respond to the copious amount of information that is available to them daily. Indeed, as Pachtman (2012) argues, today\u2019s  students need to \u201cidentify \nimportant questions, locate information, critically evaluate that information, and then communicate it to others\u201d (p. 39). Compounding these existing challenges is the reality that students tend to believe they have more sophist icated IL strategies than objective assessments of \ntheir abilities show (Gross & Latham, 2012; Latham & Gross, 2013). T herefore, educators must \nprioritize the teaching of metaliteracy skills and be prepared to regularly update their pedagogical methods to respond to the ongoing and dynamic nature of information dissemination \nand consumption.\n \nMetaliteracy skills are particularly important for students who arrive at college \nunderprepared and place into developmental courses as first -year students. Cantrell et  al. (2013) \nfound in their study of 100 first -year college students attending a midsized regional public \nUniversity in the southeastern United States that those who were placed into developmental reading courses possessed lower levels of reading self -efficacy compared to their mainstreamed \npeers. Since effective IL and metaliteracy skills hinge on a student\u2019s abilities to read, comprehend, and assess text in various formats, any deficiencies in this area can be profoundly detrimental. Indeed, the process of  developing IL and metaliteracy skills is sophisticated and \nmultifaceted. Diehm and Lupton (2014) describe a hierarchical process that begins with learning to access and process information; from there, the individual uses the information gathered to creat e a product. Final steps in the progression involve the use of new information to build a \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  58 \n personal knowledge base; to inform one\u2019s disciplinary knowledge; and to grow personally as \nwell as to contribute to society. Diehm and Lupton (2014) use the term information literacy exclusively, but it is clear that the later stages of the process they describe require metaliteracy skills, as the individual  moves from being a consumer of information to an active producer of content within collaborative communities. S uch a process requires high -level cognitive skills that \ntake time to develop, which is especially challenging for developmental students who are still honing their basic reading and writing skills as first -order tasks. Finally, the rapid pace of change \nin regards to metaliteracy also complicates the process for students who are already underprepared\u2014in other words, already working to catch up with their mainstream peers\u2019 reading, writing, and/or math skills.  \nClearly, today\u2019s developmental educators have an  increasingly important responsibility to \nadvance students\u2019 metaliteracy skills in a complex age of media bias, \u201cmisinformation,\u201d and \u201cdisinformation\u201d; this requires knowledge of available tools \u2014including their methodologies, \nbenefits, and limitations \u2014along with a willingness to commit adequate time and energy into \nrecursive active learning practices and activities in the developmental classroom.  \n \nTheories that Inform Metaliteracy  \n \nMultiple theories can lay the groundwork for metaliteracy instruction in the  classroom \nincluding cognitive dissonance theory and confirmation bias theory. Cognitive dissonance theory, developed in the 1950s by American psychologist Leon Festinger (1962), \u201ccenters around the idea that if a person knows various things that are not psychologically consistent with one another, he [or she/they] will, in a variety of ways, try to make them more consistent\u201d (p. 93). To relieve the tension created by the dissonance, individuals may avoid or rebuff the conflicting information or even convi nce themselves somehow that there is no actual conflict \n(Duignan, 2022). Humans naturally seek stability, so they may even engage in such practices knowingly. \nOne of the  dissonance -reducing behaviors people employ is confirmation bias, which is \nrooted in c ognitive dissonance. As aforementioned, confirmation bias is the tendency to seek out \nand favor information that aligns with one\u2019s existing beliefs or worldview, especially when an issue is of primary importance and carries emotional relevance for an individual. Due to the sheer volume of information that is available to us today, we need an approach that allows us to process the information quickly, and interpreting information from our existing viewpoint helps us to do so in a way that is self -preserving (Casad, n.d.). The practice of confirmation bias can be \ndetrimental, however, as it can cause individuals to ignore or discount potentially valuable information that could enhance their comprehensive understanding of an issue. Therefore, learning about cognitive dissonance and confirmation bias theories, as well as ways to combat the often -knee -jerk reactions to information that conflicts with people\u2019s own biases, can be an \neffective classroom approach to metaliteracy  as students practice the process of ref lecting on \ntheir own learning.  \n \nMedia Bias, Misinformation, and Disinformation  \n \nTheories such as those discussed above help us to understand and grapple with media \nbias, which is a particularly stark reality in this age of increasing political polarization . \nIllustratively, citing mounting challenges presented by a proliferation of misinformation, \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  59 \n Dictionary.com announced in 2018 that it had chosen \u201cmisinformation\u201d as the word of the year. \nThe online dictionary defines the term as follows: \u201cfalse information  that is spread, regardless of \nwhether there is intent to mislead\u201d (Dictionary.com, 202 3). On the other hand, Dictionary.com \n(2023) defines \u201cdisinformation\u201d as \u201cdeliberately misleading or biased information; manipulated narrative or facts; propaganda.\u201d Intent, therefore, is the key difference between the two terms. Writing for UNESCO (United Nations Education Science and Culture Organization), Abuhmaid (2021) argues that it has become increasingly difficult to filter content with the amount of information w e encounter and cites an infodemic with the rapid spread of inaccurate information, \nparticularly on social media. Abuhmaid (2021) emphasizes the importance of schools teaching critical thinking skills to students through extensive media education so they c an be empowered \nto distinguish between what is true and false, fact versus opinion.  \nEcho chambers and confirmation bias can plague even the most perceptive readers. \nIndividuals do not consume information in a vacuum, and all readers possess a worldview that influences how they receive and analyze new information. Ling (2020) describes confirmation bias as a propensity to center our attention on information that reinforces our social or political  perspectives. Ling (2020) also discusses how the disjointed,  superficial browsing of news on our \nsmartphones can exacerbate the problem. These practices can result in further polarization and hyper partisanship, which can erode our ability to engage thoughtfully and respectfully in the public square. Since young adults frequently access their news via online news sources (Antunovic et al., 2018), IL and metaliteracy skills are increasingly important for today\u2019s \nscholars.  \n \nMetaliteracy in the Classroom  \n \nJust as the definition of information literacy has changed with time, so have the practices \nfor teaching and practicing IL and metaliteracy in the classroom. Kevin McGrew, Director of the Library at the College of Saint Scholastica in Duluth, Minnesota, ha s been working in the library \nscience field for 3 5 years. McGrew recognizes a significant shift in how information is accessed \nand vetted. Early in McGrew\u2019s career, librarians would vet information and ensure that only high- quality, reputable materials tha t supported the institution\u2019s curriculum would be found in an \nacademic library. Now, McGrew observes, the responsibility to find quality, authoritative sources has shifted to the shoulders of the end user (K. W. McGrew, personal communication, June 16, 2022)\n. This process of accessing and analyzing sources for credibility, authority, and \nrelevance is complex; therefore, instructors must be willing to commit adequate time and resources to the task.  \nOne foundational tool that instructors can use is the Framework for Information Literacy \nfor Higher Education, which was adopted by the Association of College and Research Libraries (ACRL) Board in January of 2016. The document puts forth six frames (including Research as Inquiry, Scholarship as Conversation, and Searching as Strategic Exploration); suggestions for faculty to implement the Framework and administrators to support it; background information on how the Framework was developed; and suggested sources for further reading. In addition, the document i ncludes knowledge practices and dispositions that learners should possess as they are \ndeveloping their IL skills. Emphasized in the appendix on faculty implementation of the  \nFramework is the importance of integrating the IL program systemically throughout students\u2019 academic programs. The ACRL encourages faculty to provide contextualized, targeted IL sessions that meet students\u2019 particular needs for specific assignments or tasks related to their \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  60 \n coursework. McGrew agrees, citing the importance of meeting stu dents in the moment and \nproviding them with practices that can help them at their point of need (K. W. McGrew, personal \ncommunication, June 16, 2022) . \nThe Framework has garnered its share of criticism, including concerns about its use of \njargon and, theref ore, lack of accessibility to some audiences; its emphasis on theory, which \nmakes it difficult to assess measurable outcomes; and a misalignment between the Framework  \nand the tenets of critical information literacy, which seeks to challenge existing power structures \n(Beilin, 2015). Concerns have also been voiced over the phasing out of the ACRL Information Literacy Competency Standards for Higher Education, which were adopted in January of 2000. If practitioners share these concerns, they certainly can init iate discussions about these critiques \nshould they want to include that as part of their metaliteracy curriculum, especially in higher -\nlevel classes where  the metaliteracy curriculum has been scaffolded.  \nA related and ongoing conversation centers on whose  job it is to teach  IL and/or  \nmetaliteracy to students. Many models have been employed over the years with a combination of academic librarians and faculty members taking the lead. McGrew argues that academic librarians are the best trained and equipped to teach IL  but acknowledges that most institutions \ndo not have the staffing required to do this on the scale needed. McGrew  et al. (2015) conducted \na study to assess the \u201cability of classroom faculty to support and amplify the instruction given by library faculty.\u201d Results showed that both students and faculty predicted a higher level of \nconfidence and skill in their ability to use the library for their research needs than their performance on the assessment demonstrated. Among the implications of their study was the suggestion that training sessions for faculty by library staff may be beneficial in enhancing classroom metaliteracy instruction.  \n \nClassroom Tools for Metaliteracy  \n \nAlthough training sessions such as those encouraged by McGrew are a key componen t of \neffective classroom metaliteracy instruction, it is also important for the practitioners to proactively analyze a variety of helpful tools that are readily available for classroom use. The Internet offers abundant resources for teaching IL and  metaliteracy skills including many charts \nand scales that rate media bias using multiple techniques. The tools vary in methodology, rigor, and usefulness, so it is best practice for practitioners to familiarize themselves with as many as possible to determine whi ch tools work best for which tasks. Although we cannot discuss every \ntool available here, we will investigate several of the most popular tools available for classroom use. Table 1 below offers a general overview of several of the most common tools, including their methodology/approach, pros/benefits, and cons/limitations. Following the table is a more thorough discussion of each of those individual tools.  \n       \n  \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  61 \n Table 1  \nComparison of IL Tools  \n \nType of Source  Examples  Methodology/Approach  Pros Cons/Limitations  \nMedia bias \ncharts and rating \nscales  Media Bias Fact \nCheck (MBFC)  \n \nAd Fontes Media \nChart  \n Media Bias \nAllSides  Teams of researchers, \nwriters, and/or contributors rate bias (primarily \npolitical) and/or reliability of sources  \n Most include rating scales \n(e.g., 1 -10) to represent \nlevels of bias (e.g., least to \nmost)  \n \nMost ensure a variety of raters from across the \npolitical continuum (left \nleaning, moderate, and right leaning)  \n   Creators of these \ntools e mploy \nmethodologies that have progres sed to \nfurther alleviate \ninternal bias  \n \nCharts and scales are visual and \nrelatively easy to use and navigate  \n \nThey c over a \nwide variety of sources (e.g., the \nstatic Ad Fontes \nMedia Chart \nincludes ratings \nfor over 150 \nsources , and the \nteam has rated over 68,000 \nindividual \narticles ) Methodologies are \ndeveloped by the creators and \ngenerally not tested scientific \napproaches  \n Some do not \nadequately allow for nuance/can be \nreductive  \n \nThey d o not require \ncritical thinking from the user\n \nFact-checking \ntools/sites  PolitiFact  \n Snopes  \n FactCheck.\n \norg A panel of writers, \nresearchers, and/or editors check the veracity of \nspecific reports  \n \nThe t eam focuses on \nexposing questionable or deceptive claims  \n \nMost of these sites reach out \nto original /primary  source s \nto request  evidence and/or \nback -up data to support \nclaims(s)  \n \nMany of these sites refer to \nexperts and/or nonpartisan \nsources  \n \nSome, but not all, use rating \nscales or systems  \n These are u seful \nfor checking \nparticular claims \nfor research \npurposes  \n \nThese tools often \nhelp to dispel \nlegitimate \ndisinformation  \n \nThey h elp to \ndiscourage  \nindividuals (especially \npoliticians) from \nmaking false \nclaims  These sites c heck \nonly particular \nclaims (very \nlimited)  \n \nThey c an be \ninherently biased  \nNote.  Methodology practices as well as pros and cons may vary among the examples listed in the second column.   \n \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  62 \n  \nType of Source  Examples  Methodology/Approach  Pros Cons/Limitations  \nSelf-directed \ntools CRAAP test  \n \nJack Caulfield\u2019s SIFT method (aka \nThe Four Moves)  \n \nCheck, Please: \nStarter Course  \n \nP.R.O.V.E.N.  \n  These tools rely on a self -\ndriven process that requires users to evaluate sources  \n \nMost consider factors such \nas currency, accuracy, \nauthority, and purpose  These tools d o \nnot do the work \nfor the user  \n \nThey r equire \ncritical thinking \nskills  These tools c an be \nreductive for \nexperienced users  \n \nThey c an, on the \nother hand, be overly complex for \ninexperienced users \n(e.g., some users are \nnot ready to \nrecognize conflicts \nof interest, the complex \ncharacteristics  that \ndetermine a source\u2019s \nauthority, etc.)  \nNote.  Methodology practices as well as pros and cons may vary among the examples listed in the second column.   \n \nIt is worth noting here that although the tools listed above in Table 1 appear to aid \nstudents only with the development of more traditional IL skills, they form the foundation for metaliteracy, as they can and often do extend into the creation and product ion of original content \nin dynamic collaborative environments. Also, as McCoy (2022) asserts, there is a profound connection between IL and metaliteracy, as \u201c[i]nformation literacy requires an understanding of \nhow you are thinking about and evaluating the information that is being found and consumed; this is a metacognitive act that can be explicitly taught and practiced in the information literacy classroom \u201d (p. 45) . Indeed, instructors can extend classroom IL lessons into the metaliteracy \ndomain by requiring metacognitive reflection (e.g., consider what kinds of resources they are preferring over others and why; what types of sources are finding the way to the top of  their \nfeeds and why; and what types of sources they are more likely to believe and share and why). Instructors may also require the production of original content within an online community in response to IL learning.  \n \nMedia Bias Charts and Rating Scales  \n \nMedia Bias Fact Check (MBFC). Arguably one of the most comprehensive tools \navailable (the database includes over 7,400 politicians, journalists, and media sources) , Media \nBias Fact Check (MBFC) was created in 2015 by Dave Van Zandt, the source\u2019s primary editor. This tool offers a transparent and comprehensive description of its methodology and \nacknowledg es that there is no possible way to ensure 100% objectivity. To calculate bias, the \nteam of nine researchers, writers, and contributors assesses sources b y considering political bias, \nuse of factual information, and links to other credible sources. Using a 10- point scale, MBFC \nrates sources from least biased (0 -2) to left/right center bias (2 -5), left -right biased (5 -8), and \nextremely biased (8 -10). In its evaluations, the team contemplates, among other things, the \nsource\u2019s use of loaded words; well -sourced evidence; and story selection (i.e., reporting news \nfrom both sides or only one) along with political affiliations, including any organizations or causes which the owners donate to or support. More specifically, the  team  consider s many \ndifferent types of bias (bias by omission, by labeling, by spin, by story or source selection) as \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  63 \n well as how many fact checks a source has failed. Other considerations incl ude connotation and \ndenotation as well as the use of what the site refers to as \u201cpurr words\u201d (\u201cwords that are used to \ndescribe something that is favored or loved\u201d) and \u201csnarl words\u201d (\u201c words used when describing \nsomething that a person is against or hates\u201d)  (MBFC, 2023) . Consideration of these kinds of \nelements generally expands the concept of news bias for most students.  \nMBFC also adheres to the International Fact -Checking Network Fact -checkers' Code of \nPrinciples, which were developed by the Poynter Instit ute to encourage excellence in the practice \nof fact -checking. In addition, MBFC commits to nonpartisanship; transparency of funding, \norganization, and methodology; and a regular practice of authentic and intentional corrections. Other benefits of this tool  are that it includes definitions of important terminology (e.g., \n\u201cpseudoscience,\u201d \u201csatire,\u201d and \u201cquestionable sources\u201d), a list of least -biased sources, a list of \nsources that have been re -evaluated/updated, and a detailed report for each source that incl udes \nits history and funding sources. Finally, MBFC received a perfect rating (100/100) in credibility \nfrom Newsguard, one of its competitors.  \nAlthough MBFC is relatively well  respected, no tool alone is perfect. The site contains a \ndisclaimer on its own limitations, including the fact that the MBFC team developed its own \nmethodology that is not a tested scientific approach. Still, the team commits to correcting any \nfactual err ors it may make and working toward the goal of achieving a \u201cleast -biased\u201d rating \nusing the very criteria it established.  \nAd Fontes Media Bias Chart. Another well -known online bias -checking tool is the Ad \nFontes Media Bias Chart, which employs two axes: rel iability and bias. Articles are individually \nreviewed and rated by at least three analysts (out of 60 total) with varying political leanings: one \nright leaning, one left leaning, and one centrist/moderate. Individuals assign a rating and then \ncompare; if t here is disagreement on a rating, scores may be fine- tuned after discussion. The \nfinal rating for the article represents an average of the three analysts\u2019 scores. If necessary, more \nthan three analysts may be called upon to rate a specific article. The mai n tenets of the bias score \nare an article\u2019s level of political advocacy, both selection and omission of topics, and language use. \nThe methodology described above was created by Ad Fontes Media\u2019s founder, Vanessa \nOtero, who originally analyzed resources alo ne. Since the advent of the Media Bias Chart in \n2016, Otero\u2019s methodology has progressed in response to suggestions from other experts. The revised methodology is an attempt to alleviate bias and commit to a more data -driven approach.  \nThe Ad Fontes Media Bias Chart is wide ranging  with the availability of two charts: one \nstatic and one interactive. The static chart includes ratings for over 150 news sources, while the \ninteractive chart has the capacity to search from thousands of divers e sources (web, print, \npodcast, and TV). Finally, like the MBFC contributors, Otero acknowledges that complete objectivity is impossible to achieve but is transparent about the team\u2019s attempt to lessen bias.  \nNot surprisingly, the Ad Fontes Media Bias Chart  has attracted a fair share of criticism. \nWriting for ACRLog , Benjes -Small and Elwood (2021), for instance, argue d that the Chart \nelevates the political midpoint as if it were entirely unbiased, t ook issue with Otero\u2019s lack of \ninformation literacy training  or expertise, question ed the actual value of a bipartisan analysis, \nchallenge d the Chart\u2019s framing of what constitutes \u201cright- \u201d vs. \u201cleft -\u201d leaning, argue d that the \nChart does not allow for necessary nuance, and asserted  the tool simply reinforces confirm ation \nbias. Otero responded at length to the original post by Benjes -Small and Elwood (2021), \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  64 \n acknowledging that some nuance is sacrificed with the use of a graphic and discouraging users \nfrom relying too much on such charts. Still, Otero argues, it can be  a useful tool, especially for \nthose who may not have access to an academic library or a course in metaliteracy.  \nMedia Bias AllSides. The Media Bias AllSides chart rates only political bias and assigns \nsources to one of five categories: \u201cLeft,\u201d \u201cLean Left ,\u201d \u201cCenter,\u201d \u201cLean Right\u201d and \u201cRight.\u201d \nMedia Bias AllSides considers various types of bias such as \u201cslant, spin, sensationalism, and story choice.\u201d Unlike MBFC and the Ad Fontes Media Bias Chart, Media Bias AllSides recruits unpaid public readers to rate articles in the aforementioned categories. These readers (six to nine per review) self-report their own political leanings through a bias rating test and see only the text \nof the articles they are reviewing, not the outlets that published them. Like the methodology used for the Ad Fontes Media Bias Chart, AllSides employs staffers who identify as left leaning, right leaning, and center.  \nTo offer an example of its rating system, Media Bias AllSides shared the results of its \nMay 2022 blind bias survey. The  team  recruited over 1,300 individuals of various political \nleanings to blindly rate the bias of online content, which had been stripped of any identifying characteristics, derived from  the following sources: The Daily  Wire, The Epoch Times, Forbes, \nThe Hill, and Politico . AllSides calculated the weighted average for each source and determined \nthat The Daily Wire fell on the right, The Epoch Times leaned right, The Hill and Politico fell in the center, and Forbes leaned  left. \nMedia Bias AllSides (2024)  has a mission statement of sorts to \u201c[f]ree people from filter \nbubbles [a term much like confirmation bias] so they  can better understand the world \u2014and each \nother.\u201d  The site offer s an editorial philosophy; biographies of  its founders and team members; \nYouTube videos that explain the tool\u2019s methodology; a news link on its menu that includes \ncontent from the left, center, and right; and AllSides Talks, which bring together people from \ndifferent sides of the political spectr um for respectful dialogue. Finally, Media Bias AllSides \nrecognizes its limitations and acknowledges that no methodology is perfect; therefore, the team welcomes  community feedback on agreement or disagreement with current ratings and public \nparticipation in blind bias surveys.  \n \nFact-Checking Tools  \n \nFact-checking sites and tools are also widely available online and can be used in \nconjunction with the rating charts and scales. Fact -checking sites are designed specifically to \ncheck the veracity of specific reports, so their use as a research tool is a b it more limited, but \nthey can be particularly helpful for current topics and events. Common fact -checking sites \ninclude PolitiFact, which applies Truth -O-Meter ratings to determine a claim\u2019s accuracy; Snopes, \nwhich researches and reports on questionable cl aims; and FactCheck.org, which focuses \nspecifically on exposing deceptive claims and information in the realm of U.S. politics.  \nFact-checking sites may also be susceptible to bias, of course, so extra steps may be taken \nby the user to determine a fact -checking site\u2019s partiality. For instance, MBFC rates PolitiFact and \nSnopes.com as having a left -center bias and FactCheck.org as being \u201cleast biased\u201d with a very \nhigh level of factual reporting. Cross -checking sources in this fashion can help to ensure rigoro us \nIL strategies that add a layer of accountability for the researcher.  \n  \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  65 \n Self-Directed Evaluation Tools  \n \nAlthough media bias charts and fact -checking sites are clearly helpful to students who are \nlearning IL and metaliteracy skills, these tools do the wor k for the researcher by assigning ratings \nto sources primarily through the use of an editorial team that uses a specific methodology. It is \nimportant that students move beyond that, however, to also utilize resources that actively engage them in the proces s of analyzing such important elements as a source\u2019s credibility  and veracity. \nThese strategies also cross over from basic IL skills (accessing and evaluating information) to the metacognitive practices that undergird metaliteracy.  \nCRAAP Test . A common tool used to this end in many composition classrooms is the \nCRAAP test (CRAAP test administrators, 202 3). CRAAP is an acronym that stands for currency, \nrelevance, authority, accuracy, and purpose. Many iterations of the CRAAP test are available online, som e of which pose questions for the researcher under each category (for instance, how \nrelevant is this source to your topic or claim?) and rating scales that help students determine if the source is acceptable or appropriate for their classroom research.  \nThe CRAAP test has received a fair amount of criticism for being reductive. Some argue \nthat students oversimplify the tool, as there is simply too much nuance for them to understand under each category including potential conflicts of interest, sources of funding, and levels/types of authority. Still, many instructors find it a useful tool, especially for 100-  and 200- level \nundergraduate courses.  \nSIFT.  Mike Caulfield, a research scientist for the UW Research Center for an Informed \nPublic, has been an outspoke n critic of the CRAAP test and developed the SIFT (aka The Four \nMoves) model as an alternative (Caulfield, 2019). SIFT is an acronym for Stop, Investigate, Find better coverage, and Trace the original content. Caulfield also offers a three -hour minicourse \ncalled Check, Please: Starter Course (n.d.). The material is free and editable, and Caulfield\u2019s goal is to create a curricular community around metaliteracy practices.  \nP.R.O.V.E.N . Caulfield\u2019s \u201cFour Moves,\u201d in conjunction with the ACRL Framework, has \nalso been used as the foundation for  a source evaluation tool titled P.R.O.V.E.N . (purpose, \nrelevance, objectivity, verifiability, expertise, and newness), available at an Open Educational \nResource titled CORA , an acronym for Community of Online Research Assignments  (Carey, \n2017). The process is designed to get students to consider carefully how sources might meet their unique needs. Embedded in the P.R.O.V.E.N. model is consideration of whether or not the source has been fact checked by sites such as PolitiFact or Snopes. In addition, the model asks researchers to check their own emotions and biases, recognizing how these may influence their analyses of sources.  \n \nApplications for the Developmental Classroom  \n \nAs already mentioned, students who place into developmental classes often face more \nbarriers to academic success than their college -ready peers. It follows, then, that helping this \npopulation develop critical thinking and metaliteracy skills is especially important. A study done \nby Zimmerer et al. (2018) analyzed two groups of students \u2014those who were working through an \ninnovative, contextualized reading curriculum and those who were learning from a traditional reading curriculum with the default course text book\u2014for reading and information literacy skills, \npersistence, course completion, and subsequent registration in the gateway course. Students who \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  66 \n learned via the contextualized reading curriculum (described as an approach that connected \nreading skills with  disciplinary content, required students to develop their reading strategies by \naccessing various types of resources, and gave students task -specific, project -based \nopportunities) performed better than those who learned via the traditional curriculum on information literacy skills, while students in both groups saw gains in their reading strategies. \nAdditionally, course completion, persistence, and successive course registration were similar for the population that used the contextualized curriculum, which consisted of students who scored one or more levels below college ready, and those who used the traditional curriculum, which consisted of only students who had scored a single level below college ready. Zimmerer et al. (2018) concluded that the use of int entional and recursive information literacy practices in a \ndevelopmental reading course can help our most at -risk students to achieve academic success. \n \nStudies such as Zimmerer et al.\u2019s (2018) can help practitioners implement successful \nmetaliteracy lesso ns and activities to allow students in developmental courses to catch up to their \npeers with the use of effective research practices. Designing in -class lectures and activities \naround specific assignments or tasks, using a variety of resources for different tasks, and allowing students plenty of time for practice and discussion during class time can help this population develop confidence in this area.  \n \nSuggested Classroom Lessons  \nA typical metaliteracy unit that uses the resources shared herein may begin with students \nchoosing topics for a research paper. The instructor can start with a basic introduction to Boolean logic and offer in- class opportunities for students to experiment with various search terms/strings \nto identify potential sources using Google, Google Scholar, and library databases. Embedded in this step should be explicit instruction and practice activities to help students understand the \ncharacteristics of scholarly v s. popular sources. Next, the instructor can introduce various graphs \nand charts (e.g., MBFC, the Ad Fontes Media Bias Chart, and/or Media Bias AllSides) so \nstudents can check their non- scholarly sources for bias. At this point, students should consider \nthe potential effectiveness of the sources they have accessed with their audience in mind, asking \nthemselves, will my audience consider this a reputable, credible source based on what I have learned so far?   \nNext, with a basic understanding of some biases that may exist in some of the sources \nthey have accessed and the criteria most often used to determine a source\u2019s reliability, students can move on to the self -directed tools, such as the CRAAP test or Caulfield\u2019s SIFT model. At \nthis point, students should be well poised to determine which sources they should incorporate in their papers and which they should reject based on the processes described above. They also \nshould possess some fundamental skills for subsequent IL tasks as they continue to seek out, \nassess, and use sources throughout their academic careers.  \nFor instructors who are willing and able to move further into metaliteracy (rather than \nstrictly IL) practices, many options exist beyond the basic strategies listed above. One of the most natural and obvious approaches that arises organically from any of the IL practices listed above is asking students to reflect on their news -gathering practices and consider how their \npersonal biases may influence how they access, consume, and share information. Indeed, Stanton et al. (2021) describe metacognition as awareness of and control over one\u2019s thinking and learning processes, so an intentional consideration of one\u2019s owns preferences and prejudices can help \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  67 \n raise students\u2019 self -awareness around their informat ion gathering and sharing practices. Stanton \net al. (2021) also encourage the practice of social metacognition, wherein students share ideas \nwith classmates and both give and receive feedback on these ideas. Starting with individual reflection and then moving into small group discussions and finally asking groups to share some thoughts with the entire class could help to reinforce that everyone has mindsets, worldviews, and preconceptions that shape how they consume and produce information. \nFinally, if an i nstructor wishes to move students beyond metacognition into information \nproduction \u2014the part of metaliteracy that involves the sharing of information in collaborative \nonline communities \u2014there are many resources available to guide them into preparing \nmeaningful experiences in their classrooms. For instance, assignments, articles, prompts, and other materials are available at Metaliteracy.org (n.d.), a blog dedicated to providing open metaliteracy -based resources intended for educators who are dedicated to met aliteracy practices \nin their classrooms. The team at Metaliteracy.org includes Thomas P. Mackey and Trudi Jacobsen who, as mentioned earlier, coined the term and have collaboratively written four books and many articles on the topic of metaliteracy. Other valuable metaliteracy resources can be found online at various library and education sites as well as in scholarly articles available on Google Scholar and through library databases.  \n Conclusion  \nMetaliteracy skills are f oundational  to a modern liberal art s education. Since these skills \nare interw oven  throughout the curriculum and used in most \u2014if not all \u2014disciplines, practitioners \nmust be ready to provide targeted and task- based instruction to help students effectively search \nfor, access, and evaluate a variety of types of sources for credibility, relevance, and usefulness to their research processes; reflect on their learning processes and their own biases; and practice \nsharing information responsibly across a wide spectrum of available online platforms. As argued here, students who place into developm ental courses are especially at risk and need dedicated \nmetaliteracy instruction so they do not fall behind their college -ready peers. Finally, the need for \nrobust metaliteracy instruction is likely to intensify as we find innovative ways to create, share,  \nrespond to, and use information as a society; therefore, institutions would benefit from serious conversations about how, when, and where such instruction will show up in the curriculum.  \n \n \n             \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  68 \n References  \n \nAbuhmaid, H. (2021). Growing up in the age of fake news. The UNESCO Courier: Many Voices, \nOne World. https://en.unesco.org/courier/2021- 2/growing- age-fake-news  \nAd Fontes Media. (2023). Interactive media bias chart . https://adfontesmedia.com/interactive -\nmedia -bias-chart/   \nAntunovic, D., Parsons, P., & Cooke, T. R. (2018). \u2018Checking\u2019  and googling: Stages of news \nconsumption among young adults. Journalism , 19(5), 632- 648. \nhttps://doi.org/10.1177/1464884916663625 \nBeilin , I. G. (2015). Beyond the threshold: Conformity, resistance, and the ACRL information \nliteracy framework for higher education.  https://doi.org/10.7916/D8RR1XDC  \nBenjes- Small, C., & Elwood, N. (2021, Feb. 23). Complex or clickbait?: The problematic Media \nBias Chart. ACRLog . https://acrlog.org/2021/02/23/complex- or-clickbait -the-\nproblematic -media -bias-chart/comment -page -1/ \nCantrell, S. C., Correll , P., Clouse, J., Creech, K., Bridges, S., & Owens, D. (2013). Patterns of \nself-efficacy among college students in developmental reading. Journal of College \nReading and Learning, 44 (1), 8- 34. https://doi.org/10.1080/10790195.2013.10850370 \nCarey, E. (2017, September 15). P.R.O.V.E.N. source evaluation process. Community of Online \nResearch Assignments. https://www.projectcora.org/assignment/proven- source -\nevaluation- process  \nCasad, B. J. (n.d.). Confirmation bias. In Britannica. \nhttps://www.britannica.com/scien ce/confirmation -bias \nCaulfield, M. (2019, June 19). Sift (The four moves). Hapgood. \nhttps://hapgood.us/2019/06/19/sift -the-four-moves/  \nCheck, please! Starter course. (n.d.) https://www.notion.so/checkpleasecc/Check- Please- Starter-\nCourse -ae34d043575e42828dc 2964437ea4eed  \nCRAAP test administrators. (2021). CRAAP Test . https://craaptest.net/  \nDictionary.com, LLC. (2023). Disinformation. In Dictionary.com. Retrieved June 7, 2022, from  \nhttps://www.dictionary.com/browse/ disinformation  \nDictionary.com, LLC. (2023). Misinformation. In Dictionary.com. Retrieved June 7, 2022, from \nhttps://www.dictionary.com/browse/misinformation  \nDiehm, R. A., & Lupton, M. (2014). Learning information literacy. Information Research, 19(1), \n1-15. https://informationr.net/ir/19 -1/paper607.html  \nDuignan, B. (2022, June 23). Cognitive dissonance. In Britannica. \nhttps://www.britannica.com/science/cognitive -dissonance  \nFestinger, L. (1962). Cognitive dissonance. Scientific American , 207(4), 93- 106. \nhttps: //www.jstor.org/stable/24936719  \nFramework for information literacy for higher education. (2016). Association of College & \nResearch Libraries. https://www.ala.org/acrl/standards/ilframework  \nMETALITERACY IN THE DEVELOPMENTAL CLASSROOM  \nJournal of the National Organization for Student Success , 1(1)  69 \n Gross, M., & Latham, D. (2012). What's skill got to do with it?: Information literacy skills and \nself\u2010views of ability among first\u2010year college students.  Journal of the American Society \nfor Information Science and Technology , 63(3), 574-583. \nhttps://doi.org/10.1002/asi.21681  \nJacobson, T. E., & Mackey, T. P. (2013). Proposing a metaliteracy model to redefine information \nliteracy.  Communications in Information L iteracy, 7(2), 84-91. \nhttps://doi.org/10.15760/comminfolit.2013.7.2.138 \nJacobson, T. E., Mackey, T. P., & O'Brien, K. L. (2021). Visualizing the convergence of \nmetaliteracy and the information literacy framework. University Libraries Faculty \nScholarship. 149. https://scholarsarchive.library.albany.edu/ulib_fac_scholar/149 \nLatham, D., & Gross, M. (2013). Instructional preferences of first-year college students with \nbelow-proficient information literacy skills: A focus group study. College & Research Libraries, 74 (5), 430-449. https://doi.org/10.5860/crl-343  \nLing, R. (2020). Confirmation bias in the era of mobile news consumption: The social and \npsychological dimensions. Digital Journalism , 8(5), 596-604. \nhttps://doi.org/10.1080/21670811.2020.1766987 \nMackey, T. P., & Jacobson, T. E. (2011). Reframing information literacy as a metaliteracy. \nCollege & R esearch Libraries , 72(1), 62 -78. https://doi.org/10.5860/crl-76r1  \nMBFC. (2023). Media bias/Fact check. https://mediabiasfactcheck.com/  \nMcCoy, E. J. (2022). Teaching and assessment of metacognition in the information literacy \nclassroom.  Communications in Information Literacy , 16(1), 5. 42-52. \nhttps://doi.org/10.15760/comminfolit.2022.16.1.5 \nMcGrew, K., Bogue, E., & Else, I. (2015, June). Unschooled and unaware: Authentic assessment \nof faculty and student information literacy  [Poster presentation] . American Library \nAssociation (ALA) Annual Conference, San Francisco, California . \nMedia Bias \u2014AllSides. (2024). AllSides . https://www.allsides.com/media- bias. \nMetaliteracy Learning Collaborative. (n.d.). Metaliteracy.org. https://metaliteracy.org/  \nPachtman, A. B. (2012). Developing c ritical thinking for the internet. Research & Teaching in \nDevelopmental Education, 29(1), 39\u201347. https://www.jstor.org/stable/42802400 \nShapiro, J. J., & Hughes, S. K. (1996). Information literacy as a liberal art? Educom R eview , 31, \n31-35. https://wikis.evergreen.edu/selfstudy/images/6/67/Educom_review.pdf \nStanton, J. D., Sebesta, A. J., & Dunlosky, J. (2021). Fostering metacognition to support student \nlearning and performance. CBE \u2014Life Sciences Education, 20 (2), 1-7. \nhttps://doi.org/10.1187/cbe.20-12-0289 \nZimmerer, M., Skidmore, S. T., Chuppa-Cornell, K., Sindel-Arrington, T., & Beilman, J. (2018). \nContextualizing developmental reading through information literacy. Journal of Developmental Education, 41(3),  2-8. https://www.jstor.org/stable/44987487 \n \n \nThis work is licensed under  Creative Commons BY 4.0  \n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Metaliteracy in the Developmental Classroom", "author": ["HM McGrew"], "pub_year": "2024", "venue": "Journal of the National Organization for Student \u2026", "abstract": "This paper investigates the origins of metaliteracy with a focus on media bias, misinformation,  and disinformation and their pedagogical implications for information literacy (IL) in the"}, "filled": false, "gsrank": 397, "pub_url": "https://www.jnoss.org/article/id/14/", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:uLJlR_ZkSLQJ:scholar.google.com/&output=cite&scirp=396&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=uLJlR_ZkSLQJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:uLJlR_ZkSLQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.jnoss.org/article/id/14/download/pdf/"}}, {"title": "We can detect your bias: Predicting the political ideology of news articles", "year": "2020", "pdf_data": "We Can Detect Your Bias:\nPredicting the Political Ideology of News Articles\nRamy Baly1, Giovanni Da San Martino2, James Glass1, Preslav Nakov2\n1MIT Computer Science and Arti\ufb01cial Intelligence Laboratory\n3Qatar Computing Research Institute, HBKU\nfbaly,glassg@mit.edu\nfgmartino,pnakov g@hbku.edu.qa\nAbstract\nWe explore the task of predicting the lead-\ning political ideology or bias of news articles.\nFirst, we collect and release a large dataset of\n34,737 articles that were manually annotated\nfor political ideology \u2013left, center, or right\u2013,\nwhich is well-balanced across both topics and\nmedia. We further use a challenging exper-\nimental setup where the test examples come\nfrom media that were not seen during train-\ning, which prevents the model from learning\nto detect the source of the target news arti-\ncle instead of predicting its political ideology.\nFrom a modeling perspective, we propose an\nadversarial media adaptation, as well as a spe-\ncially adapted triplet loss. We further add\nbackground information about the source, and\nwe show that it is quite helpful for improv-\ning article-level prediction. Our experimental\nresults show very sizable improvements over\nusing state-of-the-art pre-trained Transformers\nin this challenging setup.\n1 Introduction\nIn any piece of news, there is a chance that the\nviewpoint of its authors and of the media organiza-\ntion they work for, would be re\ufb02ected in the way\nthe story is being told. The emergence of the Web\nand of social media has lead to the proliferation of\ninformation sources, whose leading political ide-\nology or bias may not be explicit. Yet, systematic\nexposure to such bias may foster intolerance as\nwell as ideological segregation, and ultimately it\ncould affect voting behavior, depending on the de-\ngree and the direction of the media bias, and on the\nvoters\u2019 reliance on such media (DellaVigna and Ka-\nplan, 2007; Iyengar and Hahn, 2009; Saez-Trumper\net al., 2013; Graber and Dunaway, 2017). Thus,\nmaking the general public aware, e.g., by track-\ning and exposing bias in the news is important for\na healthy public debate given the important role\nmedia play in a democratic society.Media bias can come in many different forms,\ne.g., by omission, by over-reporting on a topic, by\ncherry-picking the facts, or by using propaganda\ntechniques such as appealing to emotions, preju-\ndices, fears, etc. (Da San Martino et al., 2019,\n2020a,b) Bias can occur with respect to a spe-\nci\ufb01c topic, e.g., COVID-19, immigration, climate\nchange, gun control, etc. (Darwish et al., 2020;\nStefanov et al., 2020) It could also be more system-\natic, as part of a political ideology, which in the\nWestern political system is typically de\ufb01ned as left\nvs. center vs. right political leaning.\nPredicting the bias of individual news articles\ncan be useful in a number of scenarios. For news\nmedia, it could be an important element of internal\nquality assurance as well as of internal or external\nmonitoring for regulatory compliance. For news\naggregator applications, such as Google News, it\ncould enable balanced search, similarly to what\nis found on AllSides.1For journalists, it could\nenable news exploration from a left/center/right\nangle. It could also be an important building block\nin a system that detects bias at the level of entire\nnews media (Baly et al., 2018, 2019, 2020), such\nas the need to offer explainability, i.e., if a website\nis classi\ufb01ed as left-leaning, the system should be\nable to pinpoint speci\ufb01c articles that support this\ndecision.\nIn this paper, we focus on predicting the bias\nof news articles as left-, center-, or right-leaning.\nPrevious work has focused on doing so at the level\nof news media (Baly et al., 2020) or social me-\ndia users (Darwish et al., 2020), but rarely at the\narticle level (Kulkarni et al., 2018). The scarce\narticle-level research has typically used distant su-\npervision, assuming that all articles from a given\nmedium should share its overall bias, which is not\nalways the case. Here, we revisit this assumption.\n1http://allsides.com/arXiv:2010.05338v1  [cs.CL]  11 Oct 2020\nOur contributions can be summarized as follows:\n\u2022We create a new dataset for predicting the po-\nlitical ideology of news articles. The dataset\nis annotated at the article level and covers\na wide variety of topics, providing balanced\nleft/center/right perspectives for each topic.\n\u2022We develop a framework that discourages the\nlearning algorithm from modeling the source\ninstead of focusing on detecting bias in the\narticle. We validate this framework in an ex-\nperimental setup where the test articles come\nfrom media that were not seen at training time.\nWe show that adversarial media adaptation is\nquite helpful in that respect, and we further\npropose to use a triplet loss, which shows siz-\nable improvements over state-of-the-art pre-\ntrained Transformers.\n\u2022We further incorporate media-level representa-\ntion to provide background information about\nthe source, and we show that this information\nis quite helpful for improving the article-level\nprediction even further.\nThe rest of this paper is organized as follows:\nWe discuss related work in Section 2. Then, we\nintroduce our dataset in Section 3, we describe\nour models for predicting the political ideology of\na news article in Section 4, and we present our\nexperiments and we discuss the results in Section 5.\nFinally, we conclude with possible directions for\nfuture work in Section 6.\n2 Related Work\nMost existing datasets for predicting the political\nideology at the news article level were created\nby crawling the RSS feeds of news websites with\nknown political bias (Kulkarni et al., 2018), and\nthen projecting the bias label from a website to all\narticles crawled from it, which is a form of distant\nsupervision. The crawling could be also done us-\ning text search APIs rather than RSS feeds (Horne\net al., 2019; Gruppi et al., 2020).\nThe media-level annotation of political leaning\nis typically obtained from specialized online plat-\nforms, such as News Guard,2AllSides,3and Media\nBias/Fact Check,4where highly quali\ufb01ed journal-\nists use carefully designed guidelines to make the\njudgments.\n2http://www.newsguardtech.com\n3http://allsides.com/\n4http://mediabiasfactcheck.comAs manual annotation at the article level is very\ntime-consuming, requires domain expertise, and\nit could be also subjective, such annotations are\nrarely available at the article level. As a result,\nautomating systems for political bias detection have\nopted for using distant supervision as an easy way\nto obtain large datasets, which are needed to train\ncontemporary deep learning models.\nDistant supervision is a popular technique for\nannotating datasets for related text classi\ufb01cation\ntasks, such as detecting hyper-partisanship (Horne\net al., 2018; Potthast et al., 2018) and propa-\nganda/satire/hoaxes (Rashkin et al., 2017). For\nexample, Kiesel et al. (2019) created a large cor-\npus for detecting hyper-partisanship (i.e., articles\nwith extreme left/right bias) consisting of 754,000\narticles, annotated via distant supervision, and ad-\nditional 1,273 manually annotated articles, part of\nwhich was used as a test set for the SemEval-2019\ntask 4 on Hyper-partisan News Detection. The win-\nning system was an ensemble of character-level\nCNNs (Jiang et al., 2019). Interestingly, all top-\nperforming systems in the task achieved their best\nresults when training on the manually annotated\narticles only and ignoring the articles that were la-\nbeled using distant supervision, which illustrates\nthe dangers of relying on distant supervision.\nBarr \u00b4on-Cedeno et al. (2019) extensively dis-\ncussed the limitations of distant supervision in a\ntext classi\ufb01cation task about article-level propa-\nganda detection, in a setup that is similar to what\nwe deal with in this paper: the learning systems\nmay learn to model the source of the article instead\nof solving the task they are actually trained for.\nIndeed, they have shown that the error rate may\ndrastically increase if such systems are tested on\narticles from sources that were never seen during\ntraining, and that this effect is positively correlated\nwith the representation power of the learning model.\nThey analyzed a number of representations and ma-\nchine learning models, showing which ones tend\nto over\ufb01t more, but, unlike our work here, they fell\nshort of recommending a practical solution.\nBudak et al. (2016) measured the bias at the\narticle level using crowd-sourcing. This is risky\nas public awareness of media bias is limited (Ele-\njalde et al., 2018). Moreover, the annotation setup\ndoes not scale. Finally, their dataset is not freely\navailable, and their approach of randomly crawling\narticles does not ensure that topics and events are\ncovered from different political perspectives.\nLin et al. (2006) built a dataset annotated with\nthe ideology of 594 articles related to the Israeli-\nPalestinian con\ufb02ict published on bitterlemons.\norg. The articles were written by two editors and\n200 guests, which minimizes the risk of modeling\nthe author style. However, the dataset is too small\nto train modern deep learning approaches.\nKulkarni et al. (2018) built a dataset using distant\nsupervision and labels from AllSides. Distant su-\npervision is \ufb01ne for the purpose of training, but they\nalso used it for testing, which can be problematic.\nMoreover, their training and test sets contain arti-\ncles from the same media, and thus models could\neasily learn to predict the article\u2019s source rather\nthan its bias. In their models, they used both the\ntext and the URL contents of the articles.\nOverall, political bias has been studied at the\nlevel of news outlet (Dinkov et al., 2019; Baly et al.,\n2018, 2020; Zhang et al., 2019), user (Darwish\net al., 2020), article (Potthast et al., 2018; Saleh\net al., 2019), and sentence (Sim et al., 2013; Saez-\nTrumper et al., 2013). In particular, Baly et al.\n(2018) developed a system to predict the political\nbias and the factuality of news media. In a follow-\nup work, Baly et al. (2019) showed that bias and\nfactuality of reporting should be predicted jointly.\nA \ufb01ner-grained analysis is performed in (Horne\net al., 2018), where a model was trained on 10K\nsentences from a dataset of reviews (Pang and Lee,\n2004), and used to discriminate objective versus\nnon-objective sentences in news articles. Lin et al.\n(2006) presented a sentence-level classi\ufb01er, where\nthe labels were projected from the document level.\n3 Dataset\nIn this section, we describe the dataset that we cre-\nated and that we used in our experiments. While\nmost of the platforms that analyze the political\nleaning of news media provide in-depth analysis of\nparticular aspects of the media, AllSides stands out\nas it provides annotations of political ideology for\nindividual articles, which ensures high-quality data\nfor both training and testing, which is in contrast\nwith distant supervision approaches used in most\nprevious research, as we have seen above. In All-\nSides, these annotations are made as a result of a\nrigorous process that involves blind bias surveys,\neditorial reviews, third-party analysis, independent\nreviews, and community feedback.5\n5http://www.allsides.com/media-bias/\nmedia-bias-rating-methodsFurthermore, AllSides uses the annotated arti-\ncles to enable its Balanced Search , which shows\nnews coverage on a given topic from media with\ndifferent political bias. In other words, for each\ntrending event or topic (e.g., impeachment orcoro-\nnavirus pandemic ), the platform pushes news ar-\nticles from all sides of the political spectrum, as\nshown in Figure 1. We took advantage of this and\ndownloaded all articles along with their political\nideology annotations ( left,center , orright ), their\nassigned topic(s), the media in which they were\npublished, their author(s), and their publication\ndate. Thus, our dataset contains articles that were\nmanually selected and annotated, and that are rep-\nresentative of the real political scenery. Note that\nthecenter class covers articles that are biased to-\nwards a centrist political ideology, and not articles\nthat lack political bias (e.g., sports andtechnology ),\nwhich commonly exist in news corpora that were\nbuilt by scraping RSS feeds.\nWe collected a total of 34,737 articles published\nby 73 news media and covering 109 topics.6In this\ndataset, a total of 1,080 individual articles (3.11%)\nhave a political ideology label that is different from\ntheir source\u2019s. This suggests that, while the distant\nsupervision assumption generally holds, we would\nstill \ufb01nd many articles that defy it. Table 1 shows\nsome statistics about the dataset.\nPolitical Ideology Count Percentage\nLeft 12,003 34.6%\nCenter 9,743 28.1%\nRight 12,991 37.3%\nTable 1: Statistics about our dataset.\nFigure 2 illustrates the distribution of the differ-\nent political bias labels within each of the most\nfrequent topics. We can see that our dataset is able\nto represent topics or events from different political\nperspectives. This is yet another advantage, as it\nenables a more challenging task for machine learn-\ning models to detect the linguistic and the semantic\nnuances of different political ideologies in news\narticles, as opposed to cases where certain topics\nmight be coincidentally collocated with certain la-\nbels, in which case the models would be actually\nlearning to detect the topics instead of predicting\nthe political ideology of the target news article.\n6In some cases, an article could be assigned to multiple\ntopics, e.g., it could go simultaneously into coronavirus ,public\nhealth , and healthcare .\nFigure 1: AllSides: balanced search on the topic of reopening after the coronavirus lockdown .\nFigure 2: Political ideology for the most frequent top-\nics:elections ,immigration ,coronavirus , and politics .\nIt is worth noting that since most article labels\nare aligned with their source labels, it is likely that\nmachine learning classi\ufb01ers would end up model-\ning the source instead of the political ideology of\nthe individual articles. For example, a model would\nbe learning the writing style of each medium, and\nthen it would associate it with a particular ideology.\nTherefore, we pre-processed the articles in a way\nthat eliminates explicit markers such as the name of\nthe authors, or the name of the medium that usually\nappears as a preamble to the article\u2019s content, or in\nthe content itself. Furthermore, in order to ensure\nthat we are actually modeling the political ideol-\nogy as it is expressed in the language of the news,\nwe created evaluation splits in two different ways:\n(i) randomly, which is what is typically done (for\ncomparison only), and ( ii) based on media, where\nall articles by the same medium appear in either\nthe training, the validation, or the testing dataset.The latter form of splitting would help us indi-\ncate what a trained classi\ufb01er has actually learned.\nFor instance, if it modeled the source, then it would\nnot be able to perform well on the test set, since all\nits articles would belong to sources that were never\nseen during training. In order to ensure fair one-to-\none comparisons between experiments, we created\nthese two different sets of splits, while making sure\nthat they share the same test set, as follows:\n\u2022Media-based Split: We sampled 1,200 arti-\ncles from 12 news media (100 per medium)\nand used them as the testset, and we excluded\nthe remaining 5,470 articles from these media.\nThen, we used the articles from the remaining\n61 media to create the training and the vali-\ndation sets, where all articles from the same\nmedium would appear in the same set: train-\ning, development, or testing. This ensures that\nthe model is \ufb01ne-tuned and tested on articles\nwhose sources were not seen during training.\n\u2022Random Split: Here, the testset is the same\nas in the media-based split. The 5,470 articles\nthat we excluded from the 12 media are now\nadded to the articles from the 61 remaining\nmedia. Then, we split this collection of arti-\ncles (using strati\ufb01ed random sampling) into\ntraining andvalidation sets. This ensures that\nthe model is \ufb01ne-tuned and evaluated only on\narticles whose sources were observed during\ntraining.\nTable 2 shows statistics about both splits, includ-\ning the size of each set and the number of media\nand topics they cover. We release the dataset, along\nwith the evaluation splits, and the code,7which can\nbe used to extend the dataset as more news articles\nare added to AllSides.\n7http://github.com/ramybaly/\nArticle-Bias-Prediction\nTrain Valid. Test\nMedia-basedCount 22,969 5,098 1,200\nMedia 46 15 12\nTopics 108 105 93\nRandomCount 26,828 6,709 1,200\nMedia 73 73 12\nTopics 108 107 93\nTable 2: Statistics about our dataset and its two splits:\nmedia-based andrandom .\n4 Methodology\n4.1 Classi\ufb01ers\nThe task of predicting the political ideology of\nnews articles is typically formulated as a classi-\n\ufb01cation problem, where the textual content of the\narticles is encoded into a vector representation that\nis used to train a classi\ufb01er to predict one of C\nclasses (in our case, C= 3:left,center , and right ).\nIn our experiments, we use two deep learning archi-\ntectures: ( i)Long Short-Term Memory networks\n(LSTMs), which are Recurrent Neural Networks\n(RNNs), which use gating mechanisms to selec-\ntively pass information across time and to model\nlong-term dependencies (Hochreiter and Schmid-\nhuber, 1997), and ( ii)Bidirectional Encoder Rep-\nresentations from Transformers (BERT), with a\ncomplex architecture yielding high-quality contex-\ntualized embeddings, which have been successful\nin several Natural Language Processing tasks (De-\nvlin et al., 2019).\n4.2 Removing Media Bias\nUltimately, our goal is to develop a model that can\npredict the political ideology of a news article. Our\ndataset, along with some others, has a special prop-\nerty that might stand in the way of achieving this\ngoal. Most articles published by a given source\nhave the same ideological leaning. This might con-\nfuse the model and cause it to erroneously associate\nthe output classes with features that characterize en-\ntire media outlets (such as detecting speci\ufb01c writing\npatterns, or stylistic markers in text). Consequently,\nthe model would fail when applied to articles that\nwere published in media that were unseen during\ntraining. The experiments in Section 5 con\ufb01rm this.\nThus, we apply two techniques to de-bias the mod-\nels, i.e., to prevent them from learning the style of\na speci\ufb01c news medium rather than predicting the\npolitical ideology of the target news article.4.2.1 Adversarial Adaptation (AA)\nThis model was originally proposed by Ganin et al.\n(2016) for unsupervised domain adaptation in im-\nage classi\ufb01cation. Their objective was to adapt a\nmodel trained on labelled images from a source\ndomain to a novel target domain, where the images\nhave no labels for the task at hand. This is done\nby adding an adversarial domain classi\ufb01er with\na gradient reversal layer to predict the examples\u2019\ndomains. The label predictor\u2019s is minimized for\nthe labelled examples (from the source domain),\nand the adversarial domain classi\ufb01er\u2019s loss is max-\nimized for all examples in the dataset. As a result,\nthe encoder can extract representation that is ( i) dis-\ncriminative for the main task and also ( ii) invariant\nacross domains (due to the gradient reversal layer).\nThe overall loss is minimized as follows:\nX\ni=1:N\ndi=0Li\ny(\u0012f;\u0012y)\u0000\u0015X\ni=1:NLi\nd(\u0012f;\u0012d); (1)\nwhereNis the number of training examples,\nLi\ny(\u0001;\u0001)is the label predictor\u2019s loss, the condi-\ntiondi= 0 means that only examples from the\nsource domain are used to calculate the label pre-\ndictor\u2019s loss,Li\nd(\u0001;\u0001)is the domain classi\ufb01er\u2019s loss,\n\u0015controls the trade-off between both losses, and\nf\u0012f;\u0012y;\u0012dgare the parameters of the encoder, the\nlabel predictor, and the domain classi\ufb01er, respec-\ntively. Further details about the formulation of this\nmethod is available in (Ganin et al., 2016).\nWe adapt this architecture as follows. Instead of\nadomain classi\ufb01er , we implement a media clas-\nsi\ufb01er , which, given an article, tries to predict the\nmedium it comes from. As a result, the encoder\nshould extract representation that is discriminative\nfor the main task of predicting political ideology,\nwhile being invariant for the different media. This\napproach was originally proposed as an unsuper-\nvised domain adaptation, since labelled examples\nwere available for one domain only, whereas in our\ncase, all articles from different media were labelled\nfor their political ideology. Therefore, we jointly\nminimize the losses of both the label predictor and\nthemedia classi\ufb01er over the entire dataset. The\nnew objective function to minimize is as follows:\nX\ni=1:NLi\ny(\u0012f;\u0012y)\u0000\u0015X\ni=1:NLi\nm(\u0012f;\u0012m);(2)\nwhereLi\nm(\u0001;\u0001)is the loss of the media classi\ufb01er ,\nand\u0012mis its set of parameters.\n4.2.2 Triplet Loss Pre-training (TLP)\nIn this approach, we pre-train the encoder using\na triplet loss (Schroff et al., 2015). The model is\ntrained on a set of triplets, each composed of an\nanchor, a positive, and a negative example. The\nobjective in Eq. 3 ensures that the positive example\nis always closer to the anchor than the negative\nexample is, where a,pandnare the encodings\nof the anchor, of the positive, and of the negative\nexamples, respectively, and D(\u0001;\u0001)is the Euclidean\ndistance:\nL= max (D(a;p)\u0000D(a;n) +\u000f;0):(3)\nFigure 3 shows an example of such a triplet. The\npositive example shares the same ideology as the\nanchor\u2019s, but they are published by different media.\nThe negative example has a different ideology than\nthe anchor\u2019s, but they are published by the same\nmedium. In this way, the encoder will be cluster-\ning examples with similar ideologies close to each\nother, regardless of their source. Once the encoder\nhas been pre-trained, its parameters, along with\nthe softmax classi\ufb01er\u2019s, are \ufb01ne-tuned on the main\ntask by minimizing the cross-entropy loss when\npredicting the political ideology of articles.\nFigure 3: An example triplet used for de-biasing.\n4.3 Media-level Representation\nFinally, we explore the bene\ufb01ts of incorporating\ninformation describing the target medium, which\ncan serve as a complementary representation for\nthe article. While this seems to be counter-intuitive\nto what we have been proposing in Subsection 4.2,\nwe believe that medium-level representation can be\nvaluable when combined with an accurate represen-\ntation of the article. Intuitively, having an accurate\nunderstanding of the natural language in the article,\ntogether with a glimpse into the medium it is pub-\nlished in, should provide a more complete picture\nof its underlying political ideology.Baly et al. (2020) proposed a comprehensive set\nof representation to characterize news media from\ndifferent angles: how a medium portrays itself, who\nis its audience, and what is written about it. Their\nresults indicate that exploring the Twitter bios of a\nmedium\u2019s followers offers a good insight into its\npolitical leaning. To a lesser extent, the content\nof aWikipedia page describing a medium can also\nhelp unravel its political leaning. Therefore, we\nconcatenated these representations to the encoded\narticles, at the output of the encoder and right be-\nfore the SOFTMAX layer, so that both the article\nencoder and the classi\ufb01cation layer that is based on\nthe article and the external media representations\nare trained jointly and end-to-end.\nSimilarly to (Baly et al., 2020), we retrieved\nthe pro\ufb01les of up to a 1,000 Twitter followers for\neach medium, we encoded their bios using the\nSentence-BERT model (Reimers and Gurevych,\n2019), and we then averaged these encodings to\nobtain a single representation for that medium. As\nfor the Wikipedia representation, we automatically\nretrieved the content of the page describing each\nmedium, whenever applicable. Then, we used\nthe pre-trained base BERT model to encode this\ncontent by averaging the word representations ex-\ntracted from BERT\u2019s second-to-last layer, which is\ncommon practice, since the last layer may be biased\ntowards the pre-training objectives of BERT.\n5 Experiments and Results\nWe evaluated both the LSTM and the BERT mod-\nels, assessing the impact of ( i) de-biasing and\n(ii) incorporating media-level representation.\n5.1 Experimental Setup\nWe \ufb01ne-tuned the hyper-parameters of both models\non the validation set using a guided grid search\ntrial while \ufb01xing the seeds of the random weights\ninitialization. For LSTM, we varied the length of\nthe input (128\u20131,024 tokens), the number of layers\n(1\u20133), the size of the LSTM cell (200\u2013400), the\ndropout rate (0\u20130.8), the learning rate ( 1e\u00003to\n1e\u00005), the gradient clipping value (0\u20135), and the\nbatch size (8\u2013256). The best results were obtained\nwith a 512-token input, a 2-layer LSTM of size\n256, a dropout rate of 0.7, a learning rate of 1e\u00003,\ngradient clipping at 0.5, and a batch size of 32.\nThis model has around 1.1M trainable parameters,\nand was trained with 300-dimensional GloVe input\nword embeddings (Pennington et al., 2014).\nFor BERT, we varied the length of the input, the\nlearning rate, and the gradient clipping value. The\nbest results were obtained using a 512-token input,\na learning rate of 2e\u00005, and gradient clipping at 1.\nThis model has 110M trainable parameters.\nWe trained our models on 4 Titan X Pascal GPUs,\nand the runtime for each epoch was 25 seconds for\nthe LSTM-based models and 22 minutes for the\nBERT-based models. For each experiment, the\nmodel was trained only once with \ufb01xed seeds used\nto initialize the models\u2019 weights.\nFor the Adversarial Adaptation (AA), we have\nan additional hyper-parameter \u0015(see Equation 2),\nwhich we varied from 0 to 1, where 0 means no\nadaptation at all. The best results were obtained\nwith\u0015= 0:7, which means that we need to pay\nsigni\ufb01cant attention to the adversarial classi\ufb01er\u2019s\nloss in order to mitigate the media bias.\nFor the Triplet Loss Pre-training (PLT), we sam-\npled 35,017 triplets from the training set, such that\nthe examples in each triplet discuss the same topic\nin order to ensure that the change in topic has mini-\nmal impact on the distance between the examples.\nTo evaluate our models, we use accuracy and\nmacro-F1score (F1averaged across all classes),\nwhich we also used as an early stopping criterion,\nsince the classes were slightly imbalanced. More-\nover, given the ordinal nature of the labels, we\nreport the Mean Absolute Error (MAE), shown in\nEquation (4), whereNis the number of instances,\nandyiand^yiare the number of correct and of\npredicted labels, respectively.\nMAE =1\nNNX\ni=1jyi\u0000^yij (4)\n5.2 Results\nBaseline Results The results in Table 3 show the\nperformance for LSTM and for BERT at predicting\nthe political ideology of news articles for both the\nmedia-based and the random splits. We observe\nsizable differences in performance between the two\nsplits. In particular, both models perform much\nbetter when they are trained and evaluated on the\nrandom split, whereas they both fail on the media-\nbased split, where they are tested on articles from\nmedia that were not seen during training. This\nobservation con\ufb01rms our initial concerns that the\nmodels would tend to learn general characteristics\nabout news media, and then would face dif\ufb01culties\nwith articles coming from new unseen media.Model Split Macro F1Acc. MAE\nMajority 19.61 41.67 0.92\nLSTMMedia-based 31.51 32.30 0.97\nRandom 65.50 66.17 0.52\nBERTMedia-based 35.53 36.75 0.90\nRandom 80.19 79.83 0.33\nTable 3: Baseline experiments (without de-biasing or\nmedia-level representation) for the two splits.\nRemoving the Source Bias In order to further\ncon\ufb01rm the bias towards modeling the media, we\nran a side experiment of \ufb01ne-tuning BERT on the\ntask of predicting the medium given the article\u2019s\ncontent, which is a 73-way classi\ufb01cation problem.\nWe used strati\ufb01ed random sampling to create the\nevaluation splits and to make sure each set contains\nall labels (media). The results in Table 4 con\ufb01rm\nthat BERT is much stronger than the majority class\nbaseline, despite the high number of classes, which\nmeans that predicting the medium in which a target\nnews article was published is a fairly easy task.\nModel Macro F1 Acc.\nMajority 0.25 10.21\nBERT 59.72 80.12\nTable 4: Predicting the medium in which a target news\narticle was published.\nIn order to remove the bias towards modeling the\nmedium, we evaluated the impact of the adversarial\nadaptation (AA) and the Triplet Loss Pre-training\n(TLP) with the media-based split. The results in\nTable 5 show sizeable improvements when either\nof these approaches is used, compared to the base-\nline (no de-biasing). In particular, TLP yields an\nimprovement of 14.12 points absolute in terms of\naccuracy, and 12.73 points in terms of macro- F1.\nModel De-bias Macro F1Acc. MAE\nLSTMNone 31.51 32.30 0.97\nAA 40.33 40.57 0.69\nTLP 45.44 46.42 0.62\nBERTNone 35.53 36.75 0.90\nAA 43.87 46.22 0.59\nTLP 48.26 51.41 0.51\nTable 5: Impact of de-biasing (adversarial adaptation\nand triplet loss) on article-level bias detection.\nLSTM BERT\n# Representation Macro F1Acc. MAE Macro F1Acc. MAE\n1Article (baseline) 31.51 32.30 0.97 35.53 36.75 0.90\n2Article with TLP 45.44 46.42 0.62 48.26 51.41 0.51\n3Wikipedia 41.39 41.86 0.92 41.39 41.86 0.92\n4Wikipedia +Article 40.49 40.79 0.92 42.33 41.90 0.90\n5Wikipedia +Article with TLP 48.25 46.47 0.69 51.16 49.75 0.32\n6Twitter bios 60.30 62.69 0.42 60.30 62.69 0.42\n7Twitter bios +Article 60.30 62.69 0.42 60.42 63.12 0.40\n8Twitter bios +Article with TLP 62.02 70.03 0.32 64.29 72.00 0.29\nTable 6: Impact of adding media-level representations to the article-level representations (with and without de-\nbiasing). Note that the results in rows 3 and 6 are the same for both LSTM and BERT because no articles were\ninvolved, and the media-level representations were directly used to train the classi\ufb01er.\nImpact of Media-Level Representation Fi-\nnally, we evaluated the impact of incorporating the\nmedia-level representation (Twitter followers\u2019 bios\nand Wikipedia content) in addition to teh article-\nlevel representation. Table 6 illustrates these re-\nsults in an incremental way. First, we evaluated\nthe performance of the media-level representation\nalone at predicting the political ideology of news\narticles (see rows 3 and 6). We should note that\nthese results are identical for the LSTM and the\nBERT columns since no article was encoded in\nthese experiments, and the media representation\nwas used directly to train the logistic regression\nclassi\ufb01er. Then, adding the article representation\nfrom either model, without any de-biasing, had\nno or little impact on the performance (see rows\n4 vs. 3, and 7 vs. 6). This is not surprising, since we\nhave shown that, without de-biasing, both models\nlearn more about the source than about the bias in\nthe language used by the article. Therefore, the\nill-encoded articles do not provide more informa-\ntion than what the medium representation already\ngives, which is why no or too little improvement\nwas observed.\nWhen we use the triplet loss to mitigate the\nsource bias, the resulting article representation is\nmore accurate and meaningful, and the medium rep-\nresentation does offer complementary information,\nand eventually contributes to sizeable performance\ngains (see rows 5 and 8 vs. 2). The Twitter bios rep-\nresentation appears to be much more important than\nthe representation from Wikipedia, which shows\nthe importance of inspecting the media followers\u2019\nbackground and their point of views, which is also\none of the observations in (Baly et al., 2020).Overall, comparing the best results to the base-\nline (rows 8 vs. 1), we can see that ( i) using the\ntriplet loss to remove the source bias, and ( ii) in-\ncorporating media-level representation from Twit-\nter followers yields 30.51 and 28.76 absolute im-\nprovement in terms of macro F1on the challenging\nmedia-based split.\n6 Conclusion and Future Work\nWe have explored the task of predicting the leading\npolitical ideology of news articles. In particular, we\ncreated a new large dataset for this task, which fea-\ntures article-level annotations and is well-balanced\nacross topics and media. We further proposed an\nadversarial media adaptation approach, as well as a\nspecial triplet loss in order to prevent modeling the\nsource instead of the political bias in the news arti-\ncle, which is a common pitfall for approaches deal-\ning with data that exhibit high correlation between\nthe source of a news article and its class, as is the\ncase with our task here. Finally, our experimental\nresults have shown very sizable improvements over\nusing state-of-the-art pre-trained Transformers.\nIn future work, we plan to explore topic-level\nbias prediction as well as going beyond left-center-\nright bias. We further want to develop models that\nwould be able to detect speci\ufb01c fragments in an\narticle where the bias occurs, thus enabling explain-\nability. Last but not least, we plan to experiment\nwith other languages, and to explore to what extent\na model for one language is transferable to another\none given that the left-center-right division is not\nuniversal and does not align perfectly across coun-\ntries and cultures, even when staying within the\nWestern political world.\nAcknowledgments\nThis research is part of the Tanbih project8, which\naims to limit the effect of \u201cfake news,\u201d propaganda\nand media bias by making users aware of what\nthey are reading. The project is developed in col-\nlaboration between the Qatar Computing Research\nInstitute, HBKU and the MIT Computer Science\nand Arti\ufb01cial Intelligence Laboratory.\nReferences\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201918, pages 3528\u20133539, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020. What was written vs. who\nread it: News media pro\ufb01ling using text analysis and\nsocial media context. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics , ACL \u201920, pages 3364\u20133374.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames Glass, and Preslav Nakov. 2019. Multi-task\nordinal regression for jointly predicting the trustwor-\nthiness and the leading political ideology of news\nmedia. In Proceedings of the 17th Annual Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201919, pages 2109\u2013\n2116, Minneapolis, MN, USA.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nCeren Budak, Sharad Goel, and Justin M Rao. 2016.\nFair and balanced? Quantifying media bias through\ncrowdsourced content analysis. Public Opinion\nQuarterly , 80(S1):250\u2013271.\nGiovanni Da San Martino, Alberto Barr \u00b4on-Cede \u02dcno,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 task 11: Detection\nof propaganda techniques in news articles. In Pro-\nceedings of the International Workshop on Semantic\nEvaluation , SemEval \u201920, Barcelona, Spain.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00b4on-Cede \u02dcno, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020b. A survey on compu-\ntational propaganda detection. In Proceedings of\n8http://tanbih.qcri.org/the 29th International Joint Conference on Arti\ufb01-\ncial Intelligence and the 17th Paci\ufb01c Rim Interna-\ntional Conference on Arti\ufb01cial Intelligence , IJCAI-\nPRICAI \u201920, pages 4826\u20134832, Yokohama, Japan.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarron-Cedeno, Rostislav Petrov, and Preslav\nNakov. 2019. Fine-grained analysis of propaganda\nin news articles. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201919, pages 5636\u20135646, Hong\nKong, China.\nKareem Darwish, Michael Aupetit, Peter Stefanov, and\nPreslav Nakov. 2020. Unsupervised user stance de-\ntection on Twitter. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nICWSM \u201920, pages 141\u2013152, Atlanta, GA, USA.\nStefano DellaVigna and Ethan Kaplan. 2007. The Fox\nNews effect: Media bias and voting. The Quarterly\nJournal of Economics , 122(3):1187\u20131234.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, MN, USA.\nYoan Dinkov, Ahmed Ali, Ivan Koychev, and Preslav\nNakov. 2019. Predicting the leading political ide-\nology of YouTube channels using acoustic, textual,\nand metadata information. In Proceedings of the\n20th Annual Conference of the International Speech\nCommunication Association , INTERSPEECH \u201919,\npages 501\u2013505, Graz, Austria.\nErick Elejalde, Leo Ferres, and Eelco Herder. 2018. On\nthe nature of real and perceived bias in the main-\nstream media. PloS one , 13(3):e0193765.\nYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,\nPascal Germain, Hugo Larochelle, Franc \u00b8ois Lavi-\nolette, Mario Marchand, and Victor Lempitsky.\n2016. Domain-adversarial training of neural net-\nworks. The Journal of Machine Learning Research ,\n17(1):2096\u20132030.\nDoris A Graber and Johanna Dunaway. 2017. Mass\nmedia and American politics . SAGE Publications.\nMaur \u00b4\u0131cio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131.\n2020. NELA-GT-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. arXiv preprint arXiv:2003.08444 .\nSepp Hochreiter and J \u00a8urgen Schmidhuber. 1997.\nLong Short-Term Memory. Neural Computation ,\n9(8):1735\u20131780.\nBenjamin D. Horne, William Dron, Sara Khedr, and\nSibel Adali. 2018. Assessing the news landscape:\nA multi-module toolkit for evaluating the credibility\nof news. In Proceedings of the The Web Conference ,\nWWW \u201918, pages 235\u2013238, Lyon, France.\nBenjamin D Horne, Jeppe N\u00f8rregaard, and Sibel Adal\u0131.\n2019. Different spirals of sameness: A study of con-\ntent sharing in mainstream and alternative media. In\nProceedings of the International AAAI Conference\non Web and Social Media , ICWSM \u201919, pages 257\u2013\n266, Munich, Germany.\nShanto Iyengar and Kyu S Hahn. 2009. Red media,\nblue media: Evidence of ideological selectivity in\nmedia use. Journal of communication , 59(1):19\u201339.\nYe Jiang, Johann Petrak, Xingyi Song, Kalina\nBontcheva, and Diana Maynard. 2019. Team Bertha\nvon Suttner at SemEval-2019 Task 4: Hyperpartisan\nnews detection using ELMo sentence representation\nconvolutional network. In Proceedings of the 13th\nInternational Workshop on Semantic Evaluation , Se-\nmEval \u201919, pages 840\u2013844, Minneapolis, MN, USA.\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. SemEval-\n2019 Task 4: Hyperpartisan news detection. In Pro-\nceedings of the 13th International Workshop on Se-\nmantic Evaluation , SemEval \u201919, pages 829\u2013839,\nMinneapolis, Minnesota, USA.\nVivek Kulkarni, Junting Ye, Steven Skiena, and\nWilliam Yang Wang. 2018. Multi-view models for\npolitical ideology detection of news articles. In Pro-\nceedings of the Conference on Empirical Methods in\nNatural Language Processing , EMNLP \u201918, pages\n3518\u20133527, Brussels, Belgium.\nWei-Hao Lin, Theresa Wilson, Janyce Wiebe, and\nAlexander Hauptmann. 2006. Which side are you\non? Identifying perspectives at the document and\nsentence levels. In Proceedings of the Tenth Confer-\nence on Computational Natural Language Learning ,\nCoNLL \u201906, pages 109\u2013116.\nBo Pang and Lillian Lee. 2004. A sentimental edu-\ncation: Sentiment analysis using subjectivity sum-\nmarization based on minimum cuts. In Proceed-\nings of the 42nd Annual Meeting of the Association\nfor Computational Linguistics , ACL \u201904, pages 271\u2013\n278, Barcelona, Spain.\nJeffrey Pennington, Richard Socher, and Christopher D\nManning. 2014. GloVe: Global vectors for word rep-\nresentation. In Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP \u201914, pages 1532\u20131543, Doha, Qatar.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A stylo-\nmetric inquiry into hyperpartisan and fake news. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics , ACL \u201918,\npages 231\u2013240, Melbourne, Australia.Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, Yejin Choi, and Paul G Allen. 2017. Truth\nof varying shades: Analyzing language in fake news\nand political fact-checking. In Proceedings of the\n2017 Conference on Empirical Methods in Natu-\nral Language Processing , EMNLP \u201917, pages 2931\u2013\n2937, Copenhagen, Denmark.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Nat-\nural Language Processing , EMNLP-IJCNLP \u201919,\npages 3973\u20133983, Hong Kong, China.\nDiego Saez-Trumper, Carlos Castillo, and Mounia Lal-\nmas. 2013. Social media news communities: Gate-\nkeeping, coverage, and statement bias. In Proceed-\nings of the 22nd ACM International Conference on\nInformation & Knowledge Management , CIKM \u201913,\npage 1679\u20131684, San Francisco, CA, USA.\nAbdelrhman Saleh, Ramy Baly, Alberto Barr \u00b4on-\nCede \u02dcno, Giovanni Da San Martino, Mitra Mo-\nhtarami, Preslav Nakov, and James Glass. 2019.\nTeam QCRI-MIT at SemEval-2019 Task 4: Propa-\nganda analysis meets hyperpartisan news detection.\nInProceedings of the 13th International Workshop\non Semantic Evaluation , SemEval \u201919, pages 1041\u2013\n1046, Minneapolis, MN, USA.\nFlorian Schroff, Dmitry Kalenichenko, and James\nPhilbin. 2015. FaceNet: A uni\ufb01ed embedding for\nface recognition and clustering. In Proceedings\nof the IEEE Conference on Computer Vision and\nPattern Recognition , CVPR \u201915, pages 815\u2013823,\nBoston, MA, USA.\nYanchuan Sim, Brice D. L. Acree, Justin H. Gross, and\nNoah A. Smith. 2013. Measuring ideological pro-\nportions in political speeches. In Proceedings of the\n2013 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201913, pages 91\u2013101,\nSeattle, Washington, USA.\nPeter Stefanov, Kareem Darwish, Atanas Atanasov,\nand Preslav Nakov. 2020. Predicting the topical\nstance and political leaning of media using tweets.\nInProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , ACL \u201920,\npages 527\u2013537.\nYifan Zhang, Giovanni Da San Martino, Alberto\nBarr\u00b4on-Cede \u02dcno, Salvatore Romeo, Jisun An, Hae-\nwoon Kwak, Todor Staykovski, Israa Jaradat, Georgi\nKaradzhov, Ramy Baly, Kareem Darwish, James\nGlass, and Preslav Nakov. 2019. Tanbih: Get to\nknow what you are reading. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing ,\nEMNLP-IJCNLP \u201919, pages 223\u2013228, Hong Kong,\nChina.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "We can detect your bias: Predicting the political ideology of news articles", "author": ["R Baly", "GDS Martino", "J Glass", "P Nakov"], "pub_year": "2020", "venue": "arXiv preprint arXiv:2010.05338", "abstract": "We explore the task of predicting the leading political ideology or bias of news articles. First,  we collect and release a large dataset of 34,737 articles that were manually annotated for"}, "filled": false, "gsrank": 400, "pub_url": "https://arxiv.org/abs/2010.05338", "author_id": ["zJuI3D8AAAAJ", "URABLy0AAAAJ", "pfGI-KcAAAAJ", "DfXsKZ4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:49oi5S-3UeEJ:scholar.google.com/&output=cite&scirp=399&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D390%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=49oi5S-3UeEJ&ei=TLWsaPrDJsDZieoPqdqh8QU&json=", "num_citations": 207, "citedby_url": "/scholar?cites=16235959547982961379&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:49oi5S-3UeEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2010.05338"}}, {"title": "Explaining Website Reliability by Visualizing Hyperlink Connectivity", "year": "2022", "pdf_data": "Explaining Website Reliability by Visualizing Hyperlink Connectivity\nSeongmin Lee1Sadia Afroz2Haekyu Park1Zijie J. Wang1Omar Shaikh1\nVibhor Sehgal2Ankit Peshin2Duen Horng (Polo) Chau1\nInformation flow among websites \nvisualized by animations over the edges\n1Graph View 2Summary ViewMain Window CExplanation BHeader A\nFigure 1: MISVIShelps users assess a website\u2019s reliability and understand how the site may be involved in spreading false\ninformation by visualizing its hyperlink connectivity. When a user visits a website, MISVISis displayed interstitially over the website,\nblurring its contents and blocking user interactions. The MISVISuser interface consists of (A)aHeader message about the reliability\nof the website being visited by the user, (B)brief Explanation about how to interpret the MISVISvisualization, and (C) the Main\nWindow that visualizes the connectivity of the visited website in two coordinated views: Graph View andSummary View .(1)The\nGraph View shows how the website connects to other websites via hyperlinks. Dots are websites, and edges are hyperlinks; the site\nbeing visited is shown in the middle. MISVISvisualizes the information \ufb02ow among sites through animation. (2)TheSummary View\nshows the site\u2019s overall reliability by summarizing the reliability of its connected sites. In both views, controversial sites are shown\nin orange, veri\ufb01ed in purple, and unlabeled in gray.\nABSTRACT\nAs the information on the Internet continues growing exponentially,\nunderstanding and assessing the reliability of a website is becoming\nincreasingly important. Misinformation has far-ranging repercus-\nsions, from sowing mistrust in media to undermining democratic\nelections. While some research investigates how to alert people to\nmisinformation on the web, much less research has been conducted\non explaining how websites engage in spreading false information.\nTo \ufb01ll the research gap, we present MISVIS, a web-based interactive\nvisualization tool that helps users assess a website\u2019s reliability by\nunderstanding how it engages in spreading false information on the\nWorld Wide Web. MISVISvisualizes the hyperlink connectivity\nof the website and summarizes key characteristics of the Twitter\naccounts that mention the site. A large-scale user study with 139\nparticipants demonstrates that MISVISfacilitates users to assess and\nunderstand false information on the web and node-link diagrams can\nbe used to communicate with non-experts. MISVISis available at\nthe public demo link: https://poloclub.github.io/MisVis .\n1Georgia Tech. fseongmin jhaekyu jjaywjoshaikh jpolog@gatech.edu\n2A V AST Software. fsadia.afroz jvibhor.sehgal jankit.peshin g@avast.comIndex Terms: Human-centered computing\u2014Visualization\u2014Visu-\nalization systems and tools\u2014Visualization toolkits;\n1 I NTRODUCTION\nAs the information on the Internet continues growing exponentially,\nunderstanding and assessing the reliability of a website is becoming\nincreasingly important. Misinformation has far-ranging repercus-\nsions, from sowing mistrust in media to undermining democratic\nelections [36, 42]. For example, in the 2016 U.S. election, the top\n20 fake news stories on Facebook had higher engagement than\nthe top 20 true ones [43]. Some research investigates how to alert\npeople to fake news on the web [12, 22, 24]. Yet, warning about\nfake news alone does not necessarily help people learn about how\nto assess information reliability [32, 40]. Little research has been\nconducted on explaining how websites engage in spreading the false\ninformation [16, 31].\nTo \ufb01ll this research gap, we present MISVIS, a web-based inter-\nactive visualization tool that helps users assess a website\u2019s reliability\nby understanding how it engages in spreading false information on\nthe web and social media. Built on top of our early prototype [25],\nwe design and develop MISVISfollowing the design study method-\nology by Sedlmair et al. [38]. MISVIS\u2019s design is inspired by\nthe recent \ufb01ndings from Sehgal et al. [39] that the reliability of a\nwebsite is closely related to how it is connected to other websitesarXiv:2210.00160v1  [cs.SI]  1 Oct 2022\nthrough hyperlinks and how it is shared on social media. We de\ufb01ne\nfalse information to encompass all types of fake or inaccurate in-\nformation on the web, such as misinformation, disinformation and\nconspiracy [48]. Our M ISVISresearch contributes:\n\u2022Abstracting the Problem of Explaining Website Reliability.\nIn collaboration with A V AST, a large cybersecurity company,\nwe characterize the problem of explaining website reliability to\nnon-expert users as the task of visualizing and summarizing web-\nsites\u2019 hyperlink connectivity and Twitter mentions. We design\nand develop the web-based interactive MISVIStool (Fig. 1) to ac-\ncomplish that task, helping users better understand how websites\nengage in spreading false information.\n\u2022Evaluation of Visualization Design of M ISVIS.A large-\nscale user study with 139 participants shows that MISVIS\neffectively helps users identify and understand false infor-\nmation on the web. For a demo video of MISVIS, visit\nhttps://youtu.be/BRp3tedaNeg .\n\u2022Re\ufb02ection and Design Lessons. Our iterative design process\nand study results have made discoveries relating to the larger\nresearch area of visualization, adding to the body of knowledge\nthat bene\ufb01ts researchers, e.g., our large-scale user study shows\nthat non-experts can easily comprehend node-link diagrams for\nunderstanding hyperlink connectivity; and that displaying inter-\nstitial [22] visualization could increase its ease of use.\n2 R ELATED WORKS\nReliability assessment of web information. To help people as-\nsess the factualness of web information, online platforms, such as\nSnopes [20], FAIR [3], FactCheck.org [2], and PolitiFact [4] focus\non helping people manually validate information, while Ciampaglia\net al. [9] introduces a computational fact-checking technique. To\ncurb misinformation on social media, Facebook [27] and Twitter [35]\nhave been adding warning labels to alert users to false information,\nand web-browser extensions have been developed to detect fake news\non social media [1,29]. However, most existing techniques primarily\nfocus on alerting people to false information [11, 12, 22 \u201324]. Much\nless research has been conducted on explaining how websites engage\nin spreading false information [16, 31].\nHyperlink connectivity visualization. While the visualization\ncommunity has developed techniques for understanding graph struc-\ntures [10, 44, 45, 49], cybersecurity researchers primarily focus on\nstudying hyperlink graphs to better understand website relation-\nships [6, 16, 37]. However, little research has focused on visualizing\nhyperlink connectivity to accomplish the goal of explaining website\nreliability [6]. Furthermore, to the best of our knowledge, there\nhave not been large-scale studies that evaluate whether non-experts\ncan easily comprehend node-link diagrams for understanding hy-\nperlink connectivity [10, 45]. To \ufb01ll the above research gaps, we\ndesign, develop, and evaluate MISVISto help the general public bet-\nter understand how websites engages in spreading false information\nthrough visualizing website connections as node-link diagrams.\n3 D ESIGN GOALS\nWe have been collaborating closely with security and misinformation\ndomain experts at A V AST since August 2021, iteratively designing\nand developing M ISVIS; we identi\ufb01ed three design goals (G1-G3):\nG1. Easily Understandable Visualization. While graph visual-\nizations has been developed to better understand hyperlink\nconnectivity [47], there has been little research on whether\nnon-experts can easily understand them [45]. MISVISaims to\nvisualize hyperlink connectivity in a way that is easy for the\ngeneral public to understand.\nG2. Credibility Identi\ufb01cation. For users to trust MISVIS\u2019s visu-\nalizations about websites that they may visit (or to turn awayfrom, as they spread false information), it is important for MIS-\nVISto maintain high credibility [8, 19]. We design MISVISto\nbe transparent and neutral in terms of website reliability labels.\nG3. Easy to Use. To prevent warnings about false information\nfrom being ignored [22, 40], we aim to design MISVISnot to\nrequire users any extra efforts to use and understand.\n4 S YSTEM DESIGN\n4.1 Overview\nWe design MISVISto help users assess a website\u2019s reliability by\nvisually explaining how the website engages in spreading false infor-\nmation on the web and social media. Based on our discussion with\nA V AST cybersecurity experts and building on previous work [39],\nwe characterize the problem of explaining website reliability to non-\nexpert users as the task of visualizing and summarizing websites\u2019\nhyperlink connectivity and Twitter mentions.\nDataset. For website reliability and connectivity, we employ the\ndataset collected by Sehgal et al. [39], which consists of 1,059 mis-\ninformational and 1,059 informational websites that are collected\nand labeled by combining four publicly available datasets, BS De-\ntector [34], Columbia Journalism Review, FakeNewsNet [41], and\nMedia Bias Fact Check [5]. We reveal these label sources in MISVIS\nfor better transparency (G2). MISVISlabels the misinformational\nwebsites as controversial to encompass all types of false informa-\ntion, such as misinformation, disinformation, and conspiracy (G2).\nThe informational and unlabeled domains are labeled as veri\ufb01ed\nandunlabeled , respectively.\nFor the Twitter user data, Twitter\u2019s Search Tweets API1has been\nused with the query \u201cwhich websites are shared by which Twitter\nusers\u201d. Then, the Twitter users who have recently mentioned at least\none of the websites in the website reliability dataset described above\nhave been added to the Twitter user dataset. Among these Twitter\nusers, we identi\ufb01ed bot accounts using the botometer-python API2.\nUser Interface. MISVISis displayed interstitially when a\nuser visits a website [22] (G3). We implement MISVISus-\ning the standard HTML/CSS/JavaScript web technology stack\nand the D3.js visualization library [7]. MISVISis available at\nhttps://poloclub.github.io/MisVis .\n4.2 Main Window\nMISVIS\u2019s Main Window (Fig. 1C) visualizes the connectivity of the\nvisited website in two coordinated views: Graph View (Fig. 1 1\r)\nand Summary View (Fig. 1 2\r). The Graph View shows how a\nwebsite is connected with other websites by hyperlinks and how\nthe information would \ufb02ow through the links. The Summary View\npresents the visited site\u2019s overall reliability by summarizing the\nreliability distributions of its connected sites.\n4.2.1 Graph View\nThe Graph View (Fig. 1 1\r) explains how a user-visited website\nengages in spreading false information. Speci\ufb01cally, it shows how\na visited website is connected to other websites by hyperlinks and\nhow false information would \ufb02ow through the links.\nEach website is represented by a circular node, whose color\nindicates the site\u2019s reliability; orange forcontroversial ,purple for\nveri\ufb01ed , and gray forunlabeled . The label unlabeled is assigned\nto content aggregators (e.g., google.com ) or sites whose labels are\nnot yet available. The nodes are arranged along two concentric\nrings, based on how they are connected to the visited website. The\nwebsite being visited is shown in the center. The visited site\u2019s 1-\nhop (directly linked) and 2-hop neighbors are positioned on the\n1https://developer.twitter.com/en/docs/twitter-\napi/v1/tweets/search/guides/standard-operators\n2https://github.com/IUNetSci/botometer-python\nCurrently visited site zerohedge.com is controversial\nzerohedge.com are botszerohedge.com are controversialof the other websites shared by the\nTwitter users mentioning\nof theTwitter users mentioningAt least\nFigure 2: Twitter Window presents two key characteristics of the Twitter\naccounts that mention the visited website (e.g., zerohedge.com [13,\n17]): (1) the reliability distributions of the other sites shared by those\nTwitter accounts and (2) the number of bots among those accounts.\ninner and outer ring, respectively. We include neighbors up to 2\nhops away, because a 2-hop neighborhood provides rich connectivity\ninformation for understanding the spread of false information [16,39]\nwithout creating overwhelming visual complexity.\nHyperlinks between two sites are represented as edges. When a\nuser hovers over a node, M ISVISvisualizes how information \ufb02ows\nto or from that node. When a website A links to website B ,MISVIS\nshows an animated line going from AtoB. When none of the nodes\nis hovered, the hyperlinks between the visited website and its 1-hop\nneighbors are animated by default to draw the user\u2019s attention to the\nvisited site shown in the center (Fig. 1 1\r)\nTo enhance the readability of the node-link diagram by arranging\nthe nodes to reduce edge crossings (G1), we lay out the nodes using\nthe force-directed layout [14] via the d3-force API3. Also, we use\na straight line to connect two nodes that are on different rings (e.g.,\nconnecting a 1-hop neighbor and a 2-hop neighbor) and a curved\nline to connect two nodes that are on the same ring (e.g., connecting\ntwo 1-hop nodes).\n4.2.2 Summary View\nThe Summary View (Fig. 1 2\r) helps users understand the visited\nsite\u2019s reliability by providing a quantitative summary of its connected\nsites\u2019 reliability. The Summary View displays a summary statement\n(e.g., \u201c 22 controversial websites are linking to the site you are vis-\niting\u201d) and a doughnut chart that shows the reliability distributions\nof the sites linked with the visited site. As it is common for the sites\nwith false information to link to each other via hyperlinks [46], the\nsummary statement raises the user\u2019s awareness of the visited site\u2019s\nrisk by highlighting the number of linked controversial sites.\nThe doughnut chart summarizes the reliability distributions of its\nconnected sites in two rings; the inner and outer rings represent the\nvisited site\u2019s 1-hop and 2-hop neighbors, respectively. In the center\nof the rings, we display the percentage of controversial sites among\nall the sites in the chart. The number and percentage that an arc in\nthe doughnut chart stands for can be viewed by hovering the arc.\nThe Summary View visualizes the neighboring sites\u2019 reliability\nin two modes: normalized andabsolute mode. In the normalized\nmode, one full ring is for 100% of the sites in the ring; for example,\nif 5 out of 10 directly connected sites are controversial , half of the\ninner ring is colored in orange. In the absolute mode, each ring is\nevenly divided into 100 arc segments, and each segment corresponds\nto one website; for example, 5 controversial sites are represented\nby 5 orange arc segments. We experimented with the number of\nsegments beyond 100 but decided not to use more than 100 segments\nas they became illegible. If there are more than 100 sites in a ring,\nMISVISshows a pop-up message informing that the limit has been\nreached and reverts to the normalized mode.\n3https://github.com/d3/d3-force\nShow the websites that thegatewaypundit.com is linking toShow outer ringFigure 3: The Settings Panel allows users to switch the view of the\nMain Window between the Graph View and the Summary View; switch\nthe Summary View mode between normalized andabsolute ; select\nwhich reliability labels to visualize in the Main Window; show or hide\nthe outer ring for 2-hop neighbors; and show or hide the visualization\nfor the websites that the visited website contains hyperlinks to.\n4.3 Twitter Window\nAs false information is often shared and propagates on social me-\ndia [26, 30], the Twitter Window (Fig. 2) informs users of how the\nvisited website is shared on Twitter. At the top of the Twitter Win-\ndow, users can see the percentage of the controversial websites\namong the sites shared by the Twitter users that have mentioned\nthe visited website. If the percentage of controversial sites men-\ntioned by the common Twitter users with the visited website is high,\nthe visited site is likely to be controversial as well, since proli\ufb01c\nspreaders of false information often mention multiple controversial\nsites on Twitter. Below, the number of bot Twitter accounts that\nhave mentioned the visited website is displayed. As bot accounts\nare commonly deployed to spread false information [18, 28], a high\nnumber of bots strongly implies that the site would contain false\ninformation. The Twitter Window can be shown and hidden by\nclicking the social media button at the top-right corner of the Main\nWindow.\n4.4 Settings Panel\nThe Settings Panel (Fig. 3) is used to (1) switch the view of the Main\nWindow between the Graph View and the Summary View (Sect. 4.2),\n(2) switch the Summary View mode between normalized andabso-\nlute(Sect. 4.2.2), (3) include or exclude certain reliability labels to\nor from the visualization in the Main Window, (4) show or hide the\nouter ring for 2-hop neighbors, and (5) show or hide the visualization\nfor the websites that the visited website contains hyperlinks to , in\naddition to the websites with hyperlinks to the visited website . By\ndefault, we display both 1-hop and 2-hop neighbors of the visited\nwebsite as 2-hop neighborhood can provide rich information for the\nconnectivity [16, 39]. On the other hand, the sites that the visited\nwebsite has hyperlinks to is not shown in the default setting as a con-\ntroversial site can deliberately link to a large number of reputable\nsites to falsely in\ufb02ate its credibility and mislead users [15].\n5 D ESIGN VALIDATION BY USERSTUDY\nTo validate the effectiveness of MISVIS, we conducted a large-scale\nuser study. We recruited 150 U.S.-based participants from Proli\ufb01c4,\nan online platform designed for academic research. The participants\u2019\nages range from \u201c18-24 years old\u201d to \u201c65 or older\u201d. They consume\nnews from a variety of sources, including news websites, social\nmedia, and television. The study for each participant lasted for\naround 15 minutes and we compensated each participant with $2.50;\nwe paid a $1.00 bonus to the participants who provided feedback for\nthe open-ended survey questions.\n5.1 Procedure\nWe \ufb01rst asked participants to watch a 2-minute tutorial video about\nhow to use MISVIS. After that, to ensure high quality result, we\nasked the participants to answer 3 simple questions about the video.\n4https://www.proli\ufb01c.co/\nOverall,itwaseasytoAverage Usability and Usefulness Ratings from 139 Participants\nOverall,thetoolhelpsmelearnabout\nItwaseasytounderstand\nItwashelpfulforassessingthevisitedwebsites'reliabilitytoknow\nthe outer ring in addition to the inner ring\nreliability of the sites shared by Twitter users mentioning visited website\nthe number of bot Twitter accounts mentioning the visited sites\nI am interested in recommending the tool to my family or friends\nI am interested in using the tool in the futureuse the tool\nthe reliability of the websites I visited\nthe connectivity of the websites I visited\nanimated lines in the Graph View\nSummary View\nTwitter Windowunderstand website reliabilityunderstand how to use the tool\nunderstand website connectivity\nOverall, I enjoyed using the tool\nAgree (5) Disagree (1)4.32\n4.19\n4.12\n4.09\n4.13\n4.27\n4.53\n4.34\n4.37\n4.06\n3.92\n4.04\n4.01\n3.57\n3.83Figure 4: Average ratings from 139 participants about MISVIS. Most\nparticipants found M ISVISand its features easy to use and helpful.\nThen, we asked participants to use MISVISin a hypothetical sce-\nnario where they were using a search engine to look up information\nto write an essay about the \u201cislands in the East China Sea with terri-\ntorial dispute\u201d , a topic that is less likely to evoke extreme emotions\namong most U.S.-based participants. We provided the participants\nwith the hypothetical search result page showing a list of websites\n(similar to those returned by search engines). They were asked to\nvisit the \ufb01rst two websites in sequence. To prevent exposing the\nparticipants to false information and to help them focus on the visu-\nalization, when they clicked on a website, MISVISwas displayed\ninterstitially [22]; the website contents were blurred, user interac-\ntions were blocked, and the website name was masked (Fig. 1). After\nvisiting each website, the participants were asked to determine if the\nsite was a reliable information source: yes,maybe ,no.\nEvery participant visited one controversial site and one veri\ufb01ed\nsite, so that we could evaluate how participants interact with MISVIS\nin both cases. The two websites were presented in random order to\nguard against order effect (i.e., controversial !veri\ufb01ed , orveri\ufb01ed\n!controversial ) We sampled 10 controversial and 10 veri\ufb01ed sites\nwith at least one 1-hop and 2-hop neighbor, to allow us to evaluate\nwhether the participants could easily use and understand MISVIS\neven with more complex connectivity (G1).\n5.2 Results\nAfter using MISVIS, the participants were asked to answer 5-point\nLikert-scale questions about MISVIS\u2019s usability and usefulness for\nassessing website reliability [21, 22]. Fig. 4 summarizes the results\nfrom the 139 participants who correctly answered at least two of\nthe three quality-check questions (we excluded 11 participants who\nincorrectly answered two or all questions). Overall, participants\nrated MISVISfavorably. They enjoyed using MISVIS, and found it\nhelpful and was easy to use and understand.\nParticipants could easily use and understand M ISVIS.The aver-\nage ratings for all the questions about the overall usability of MISVIS\nand its features were above 4. In particular, many participants com-\nmented that MISVISwas easy to use. (e.g., \u201c It was laid out nicely\nand easy to understand. \u201d)\nNode-link diagrams for hyperlink connectivity were easy to un-\nderstand and helpful (G1). The understandability and helpfulness\nofMISVIS\u2019s node-link diagram design received high ratings. We\nare excited that non-experts could easily understand such graph\nbased visualization, because this discovery contributes to the body\nof knowledge of the larger area of visualization, in addition to misin-\nformation research; such a large-scale study has not been performedbefore. Many participants found the animated edges enhanced their\nunderstanding. (e.g., \u201c It showed the connections instantly and easily.\nIt was fun to use, and the animation helped easier understanding\nand was relaxing. \u201d)\nMISVIShelped participants assess website reliability and con-\nnectivity. Many participants gave high ratings to the questions about\nthe helpfulness of MISVIS. After visiting the controversial web-\nsites, 95 out of 139 participants determined the sites to be indeed\ncontroversial, 30 were undecided; only 14 thought they were reliable.\nFor the veri\ufb01ed websites, 88 determined the sites to be reliable, 40\nwere undecided. Our results provided strong empirical evidence for\nMISVIS\u2019s effectiveness in helping assess website reliability.\nHyperlink connectivity helped participants assess website relia-\nbility. Participants commented that knowing a website\u2019s hyperlink\nconnectivity enhanced their assessment con\ufb01dence (e.g., \u201c Legiti-\nmacy of a website\u2019s connections bolsters its trust. \u201d, \u201cKnowing that\na website is connected to reliable websites gives me comfort. \u201d).\nThis \ufb01nding validated our problem abstraction of explaining website\nreliability via visualizing hyperlink connectivity.\nInterstitial visualization enhances M ISVIS\u2019s ease of use (G3).\nMISVISwas displayed interstitially [22], over the website\u2019s blurred\ncontents. One of the participants said \u201c I found this tool useful as\nI could see the reliability of the website without clicking anything,\ntherefore save me time \u201d, echoing the bene\ufb01t of the interstitial design.\n6 R EFLECTION AND DESIGN LESSONS\nLabel Wording for Website Reliability. Through close discussion\nwith domain experts, we established three criteria to provide accurate\nand unbiased labels for website reliability (G2): (1) the labels should\nbe easily understandable for general users, (2) they should encom-\npass all types of false information, and (3) they should be neutral,\nnot to offend users. For example, at \ufb01rst, we labeled each website\u2019s\nreliability as misinformation ,reliable , orunlabeled . However, the\ndomain experts pointed out that the term misinformation might not\ncover all types of false information (e.g., disinformation), and that\nusers could feel offended if the sites they often visited were labeled\nasmisinformation . Thus, we adopted the controversial label, which\nis more neutral than misinformation . Likewise, we adopted the\nveri\ufb01ed label to convey that labels had veri\ufb01able sources.\nRevealing Reliability Label Sources. We learned that revealing\nthe sources for the website reliability labels signi\ufb01cantly increases\nthe credibility of MISVIS[19, 33] (G2). The earlier designs of\nMISVISdid not mention where the reliability labels came from.\nOn a pilot study, multiple participants were concerned about the\npotential biases in the reliability labels and wondered how the labels\nwere determined. We therefore added a statement at the bottom of\nthe Main Window to clearly state the sources: \u201cReliability labels\nare based on credible sources: Columbia Journalism Review, Media\nBias Fact Check, FakeNewsNet.\u201d (Clicking the sources would bring\nthe users to their websites.) In our large-scale study, as a result, far\nfewer participants were concerned about the credibility of M ISVIS.\n7 C ONCLUSION AND FUTURE WORK\nWe present MISVIS, a web-based interactive visualization tool to\nhelp users assess the reliability of a website and understand how the\nwebsite is involved in spreading false information on the World Wide\nWeb and social media, by visualizing hyperlink connectivity of the\nwebsite and summarizing key characteristics of the Twitter accounts\nthat mention the site. Through a large-scale user study, we validate\nthatMISVISsuccessfully facilitates users to identify and understand\nfalse information on the web. We plan to deploy MISVISas a web\nbrowser extension for broader impact and improved usability.\nREFERENCES\n[1] Bot sentinel. https://botsentinel.com . Accessed: 2022-04-28.\n[2] Factcheck.org. www.factcheck.org . Accessed: 2022-04-28.\n[3] Fair. fair.org . Accessed: 2022-04-28.\n[4] Politifact. www.politifact.com . Accessed: 2022-04-28.\n[5]Questionable sources. mediabiasfactcheck.com/fake-news . Ac-\ncessed: 2022-04-28.\n[6]T. Aoki and A. Goto. Graph visualization of the dark web hyperlink. In\n2020 Eighth International Symposium on Computing and Networking\n(CANDAR) , pp. 89\u201394. IEEE, 2020.\n[7]M. Bostock, V . Ogievetsky, and J. Heer. D3data-driven docu-\nments. IEEE transactions on visualization and computer graphics ,\n17(12):2301\u20132309, 2011.\n[8]P. B. Brandtzaeg and A. F\u00f8lstad. Trust and distrust in online fact-\nchecking services. Communications of the ACM , 60(9):65\u201371, 2017.\n[9]G. L. Ciampaglia, P. Shiralkar, L. M. Rocha, J. Bollen, F. Menczer, and\nA. Flammini. Computational fact checking from knowledge networks.\nPloS one , 10(6):e0128193, 2015.\n[10] M. Douma, G. Ligierko, O. Ancuta, P. Gritsai, and S. Liu. Spicynodes:\nRadial layout authoring for the general public. IEEE Transactions on\nVisualization and Computer Graphics , 15(6):1089\u20131096, 2009.\n[11] D. A. Eccles and T. Dingler. Three prophylactic interventions to counter\nfake news on social media. arXiv preprint arXiv:2105.08929 , 2021.\n[12] R. Ennals, B. Trushkowsky, and J. M. Agosta. Highlighting disputed\nclaims on the web. In Proceedings of the 19th international conference\non World wide web , pp. 341\u2013350, 2010.\n[13] A.-M. Fraser. Google bans website zerohedge from its ad platform\nover comments on protest articles. NBC News , 2020.\n[14] T. M. Fruchterman and E. M. Reingold. Graph drawing by force-\ndirected placement. Software: Practice and experience , 21(11):1129\u2013\n1164, 1991.\n[15] Z. Gyongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam\nwith trustrank. In Proceedings of the 30th international conference on\nvery large data bases (VLDB) , 2004.\n[16] H. W. A. Hanley, D. Kumar, and Z. Durumeric. No calm in the storm:\nInvestigating qanon website relationships. ICWSM , 2022.\n[17] D. Hawkins. Twitter bans zero hedge account after it doxxed a chinese\nresearcher over coronavirus. The Washington Post , 2020.\n[18] M. Himelein-Wachowiak, S. Giorgi, A. Devoto, M. Rahman, L. Ungar,\nH. A. Schwartz, D. H. Epstein, L. Leggio, B. Curtis, et al. Bots and\nmisinformation spread on social media: Implications for covid-19.\nJournal of Medical Internet Research , 23(5):e26933, 2021.\n[19] C. I. Hovland and W. Weiss. The in\ufb02uence of source credibility on\ncommunication effectiveness. Public opinion quarterly , 15(4):635\u2013650,\n1951.\n[20] S. M. G. Inc. Snopes. www.snopes.com . Accessed: 2022-04-28.\n[21] F. Jahanbakhsh, A. X. Zhang, A. J. Berinsky, G. Pennycook, D. G.\nRand, and D. R. Karger. Exploring lightweight interventions at posting\ntime to reduce the sharing of misinformation on social media. Proc.\nACM Hum.-Comput. Interact. , 5(CSCW1), apr 2021. doi: 10.1145/\n3449092\n[22] B. Kaiser, J. Wei, E. Lucherini, K. Lee, J. N. Matias, and J. Mayer.\nAdapting security warnings to counter online disinformation. In 30th\nUSENIX Security Symposium (USENIX Security 21) , pp. 1163\u20131180,\n2021.\n[23] J. Kirchner and C. Reuter. Countering fake news: A comparison of pos-\nsible solutions regarding user acceptance and effectiveness. Proceed-\nings of the ACM on Human-computer Interaction , 4(CSCW2):1\u201327,\n2020.\n[24] C. Lanius, R. Weber, and W. I. MacKenzie. Use of bot and content\n\ufb02ags to limit the spread of misinformation among social networks: a\nbehavior and attitude survey. Social Network Analysis and Mining ,\n11(1):1\u201315, 2021.\n[25] S. Lee, S. Afroz, H. Park, Z. J. Wang, O. Shaikh, V . Sehgal, A. Peshin,\nand D. H. Chau. MisVis: Explaining web misinformation connections\nvia visual summary. In Extended Abstracts of the 2022 CHI Conference\non Human Factors in Computing Systems . ACM, 2022. doi: 10.1145/\n3491101.3519711\n[26] P. Meel and D. K. Vishwakarma. Fake news, rumor, information pollu-tion in social media and web: A contemporary survey of state-of-the-\narts, challenges and opportunities. Expert Systems with Applications ,\n153:112986, 2020. doi: 10.1016/j.eswa.2019.112986\n[27] Meta. Combating misinformation, 02 2022.\n[28] C. Metz. Twitter bots poised to spread disinformation before election.\nThe New York Times , 2020.\n[29] M. C. Nabanita De, Anant Goel and Q. Chen. Project \ufb01b, 01 2022.\n[30] S. B. Naeem, R. Bhatti, and A. Khan. An exploration of how fake news\nis taking over social media and putting public health at risk. Health\nInformation & Libraries Journal , 38(2):143\u2013149, 2021.\n[31] V . Patricia Aires, F. G. Nakamura, and E. F. Nakamura. A link-based\napproach to detect media bias in news websites. In Companion Pro-\nceedings of The 2019 World Wide Web Conference , pp. 742\u2013745, 2019.\n[32] S. Pluviano, C. Watt, and S. Della Sala. Misinformation lingers\nin memory: failure of three pro-vaccination strategies. PloS one ,\n12(7):e0181640, 2017.\n[33] C. Pornpitakpan. The persuasiveness of source credibility: A critical\nreview of \ufb01ve decades\u2019 evidence. Journal of applied social psychology ,\n34(2):243\u2013281, 2004.\n[34] M. Risdal. Getting real about fake news, 2016. doi: 10.34740/\nKAGGLE/DSV/911\n[35] Y . Roth and N. Pickles. Updating our approach to misleading informa-\ntion, 05 2020.\n[36] M. M. H. Samia Tasnim and H. Mazumder. Impact of rumors and\nmisinformation on covid-19 in social media. Journal of Preventive\nMedicine & Public Health , 53:171\u2013174, 2020. doi: 10.3961/jpmph.20.\n094\n[37] N. S. Sattar, S. Arifuzzaman, M. F. Zibran, and M. M. Sakib. Detecting\nweb spam in webgraphs with predictive model analysis. In 2019 IEEE\nInternational Conference on Big Data (Big Data) , pp. 4299\u20134308.\nIEEE, 2019.\n[38] M. Sedlmair, M. Meyer, and T. Munzner. Design study methodology:\nRe\ufb02ections from the trenches and the stacks. IEEE transactions on\nvisualization and computer graphics , 18(12):2431\u20132440, 2012.\n[39] V . Sehgal, A. Peshin, S. Afroz, and H. Farid. Mutual hyperlinking\namong misinformation peddlers. CoRR , abs/2104.11694, 2021.\n[40] F. Sharevski, R. Alsaadi, P. Jachim, and E. Pieroni. Misinformation\nwarnings: Twitter\u2019s soft moderation effects on covid-19 vaccine belief\nechoes. Computers & security , 114:102577, 2022.\n[41] K. Shu, D. Mahudeswaran, S. Wang, D. Lee, and H. Liu. Fakenews-\nnet: A data repository with news content, social context and dynamic\ninformation for studying fake news on social media. arXiv preprint\narXiv:1809.01286 , 2018.\n[42] F. Siddiqui and S. Svrluga. N.c. man told police he went to d.c. pizzeria\nwith gun to investigate conspiracy theory. The Washington Post , 2016.\n[43] C. Silverman. Viral fake election news outperforms real news on\nfacebook, 2022.\n[44] M. A. Smith, C. A., N. Milic-Frayling, B. Shneiderman, E. Mendes Ro-\ndrigues, J. Leskovec, and C. Dunne. Nodexl: a free and open\nnetwork overview, discovery and exploration add-in for excel\n2007/2010/2013/2016. 2010.\n[45] L. South, M. Schwab, N. Beauchamp, L. Wang, J. Wihbey, and M. A.\nBorkin. Debatevis: Visualizing political debates for non-expert users.\nIn2020 IEEE Visualization Conference (VIS) , pp. 241\u2013245. IEEE,\n2020.\n[46] K. Starbird, A. Arif, T. Wilson, K. Van Koevering, K. Ye\ufb01mova, and\nD. Scarnecchia. Ecosystem or echo-system? exploring content sharing\nacross alternative media domains. In Proceedings of the International\nAAAI Conference on Web and Social Media , vol. 12, 2018.\n[47] O. Turetken and R. Sharda. Visualization of web spaces: state of the\nart and future directions. ACM SIGMIS Database: the DATABASE for\nAdvances in Information Systems , 38(3):51\u201381, 2007.\n[48] L. Wu, F. Morstatter, K. M. Carley, and H. Liu. Misinformation in\nsocial media: de\ufb01nition, manipulation, and detection. ACM SIGKDD\nExplorations Newsletter , 21(2):80\u201390, 2019.\n[49] S. Zhang, R. Yang, X. Xiao, X. Yan, and B. Tang. Pprviz: Effective and\nef\ufb01cient graph visualization based on personalized pagerank. arXiv\npreprint arXiv:2112.14944 , 2021.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Explaining Website Reliability by Visualizing Hyperlink Connectivity", "author": ["S Lee", "S Afroz", "H Park", "ZJ Wang"], "pub_year": "2022", "venue": "\u2026 and Visual Analytics \u2026", "abstract": "As the information on the Internet continues growing exponentially, understanding and  assessing the reliability of a website is becoming increasingly important. Misinformation has far-"}, "filled": false, "gsrank": 401, "pub_url": "https://ieeexplore.ieee.org/abstract/document/9973216/", "author_id": ["EA4jKm4AAAAJ", "u4epKYoAAAAJ", "Nsmmp-cAAAAJ", "eouAYvcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:LCOREC4jizIJ:scholar.google.com/&output=cite&scirp=400&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=LCOREC4jizIJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 1, "citedby_url": "/scholar?cites=3642043404412592940&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:LCOREC4jizIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2210.00160"}}, {"title": "6 Dutch junk news on Reddit and 4chan/pol", "year": "2020", "pdf_data": "Rogers & Niederer (eds) The Politics of Social Media Manipulation\nThe Politics of  \nSocial Media Manipulation\n\nThe Politics of  \nSocial Media Manipulation\nEdited by  \nRichard Rogers  \nand Sabine Niederer\nAmsterdam University Press\nCover design: Co\u00f6rdesign, Leiden\nTypesetting: Crius Group, Hulshout\nisbn  9\n78 94 6372 483 8\ne-isbn  9\n78 90 4855 167 5 (pdf)\ndoi \n10.5117/9789463724838\nnur  \n670\nCreative Commons License CC BY NC ND (http://creativecommons.org/licenses/by-nc-nd/3.0)\n All authors / Amsterdam University Press B.V., Amsterdam 2020\nSome rights reserved. Without limiting the rights under copyright reserved above, any part of \nthis book may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any form or by any means (electronic, mechanical, photocopying, recording or otherwise).\n T able of Contents\n1 Th e politics of social media manipulation  19\nRichard Rogers and Sabine Niederer\n2 P olitical news on Facebook during the 2019 Dutch elections  71\nStijn Peeters and Richard Rogers\n3 P olitical news in search engines  97\nExploring Google\u2019s susceptibility to hyperpartisan sources during \nthe Dutch elections\nGuill\u00e9n Torres and Richard Rogers\n4 Th e circulation of political news on Twitter during the Dutch \nelections  123\nSabine Niederer and Maarten Groen\n5 D utch political Instagram  147\nJunk news, follower ecologies and artificial amplification\nGabriele Colombo and Carlo De Gaetano\n6 D utch junk news on Reddit and 4chan/pol  169\nSal Hagen and Emilija Jokubauskait\u0117\n7 F ake news and the Dutch YouTube political debate space  217\nMarc Tuters\n8 C onclusions  239\nMainstream under fire\nRichard Rogers and Sabine Niederer\n9 E pilogue  253\nAfter the tweet storm\nRichard Rogers and Sal Hagen\nReferences  257\nIndex  287\nList of figures and tables\nFigures\nFigure\u00a01.1\n C\nartoon that ridicules the fake news taskforce, stating: \n\u201cinternet trolls are best countered by internet hobbits\u201d\n 3\n7\n S\nource: Reid et al. (2018)\nFigure\u00a01.2\n \u201c\nDetected and eliminated\u201d fake news, with a warning \nissued by NU.nl and Nieuwscheckers\n 3\n8\n S\nource: NOS (2017a)\nFigure\u00a01.3\n T\nhe birth of the fake news crisis, or \u2018fake news\u2019 \noutperforms \u2018mainstream news\u2019 on Facebook, in the run-up to the U.S. elections in 2016\n 4\n3\n S\nource: Silverman (2016)\nFigure\u00a01.4\n F\nacebook political ad library tool, results for Britain\u2019s \nFuture, 13\u00a0March\u00a02019\n 5\n0\nFigure\u00a02.1\n E\nngagement of mainstream (blue) and junk-like news \n(pink) articles found through provincial elections-related BuzzSumo queries, per week, between 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engagement scores have been normalised.\n 8\n0\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.2\n T\notal Facebook Engagement of fake versus mainstream \nnews. Results from election-related queries on BuzzSu-mo, for the 20 most-engaged with articles between February and November 2016, per three-month period\n 8\n1\n S\nource: Silverman (2016)\nFigure\u00a02.3\n P\ner-query engagement of mainstream (blue) and junk \n(pink) articles found through provincial elections-related BuzzSumo queries, per week, between 18\u00a0February and 25\u00a0March\u00a02019. Engagement scores have been normalised.\n 8\n2\n L\nine graphs; visualisation by Federica Bardelli\nFigure\u00a02.4\n E\nngagement of mainstream and junk-like articles \nfound through EU elections-related queries on BuzzSumo, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalised.\n 8\n4\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.5\n P\ner-query engagement of mainstream (blue) and \njunk (pink) articles found through EU parliamentary election-related BuzzSumo queries, per week, between \n19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have \nbeen normalised.\n 8\n5\n L\nine graphs; visualisation by Federica Bardelli\nFigure\u00a02.6\n E\nngagement of mainstream, hyperpartisan, \nconspiracy and clickbait articles found for provincial elections-related queries on BuzzSumo, between 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engagement scores have been normalised. GeenStijl is considered \u2018mainstream\u2019 here, while The Post Online is classified as \u2018hyperpartisan\u2019.\n 8\n8\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.7\n E\nngagement of mainstream, tendentious, hyper-\npartisan, conspiracy and clickbait articles found for provincial elections-related queries on BuzzSumo, between 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engage-ment scores have been normalised. GeenStijl and The Post Online are considered \u2018tendentious\u2019 here.\n 8\n8\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.8\n E\nngagement of mainstream, tendentious, hyperpar-\ntisan, conspiracy and clickbait articles found for EU parliamentary elections-related queries on BuzzSumo, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalised. GeenStijl is considered \u2018mainstream\u2019 here while The Post Online is classified as \u2018hyperpartisan\u2019.\n \n89\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.9\n E\nngagement of mainstream, tendentious, hyperpar-\ntisan, conspiracy and clickbait articles found for EU parliamentary elections-related queries on BuzzSumo, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalised. GeenStijl and The Post Online are considered \u2018tendentious\u2019 here.\n 8\n9\n L\nine graph; visualisation by Federica Bardelli\nFigure\u00a02.10\n R\nelative engagement of content categories across \n4chan /pol/, Reddit, Twitter and Facebook. GeenStijl is considered \u2018mainstream\u2019 here while The Post Online is classified as \u2018hyperpartisan\u2019.\n 9\n2\n 4\nchan and reddit data from 1 Dec 2015 until 1\u00a0June; \nTwitter and Facebook data from 18 Feb 2019-25 Mar 2019 and 19 Apr 2019-23\u00a0May\u00a02019\nFigure\u00a02.11  R elative engagement of content categories across \n4chan /pol/, Reddit, Twitter and Facebook.\n 9\n2\n 4\nchan and reddit data from 1 Dec 2015 until 1\u00a0June; \nTwitter and Facebook data from 18 Feb 2019-25 Mar \n2019 and 19 Apr 2019-23\u00a0May\u00a02019\nFigure\u00a03.1\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to foreign affairs, 13-22\u00a0March\u00a02019\n 1\n07\nFigure\u00a03.2\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to polarizing topics, 13-22\u00a0March\u00a02019\n 1\n07\nFigure\u00a03.3\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to the environment, 13-22\u00a0March\u00a02019\n \n109\nFigure\u00a03.4\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to the economy, 13-22\u00a0March\u00a02019\n \n113\nFigure\u00a03.5\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to societal issues, 13-22\u00a0March\u00a02019\n \n112\nFigure\u00a03.6\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to future innova-tion, 13-22\u00a0March\u00a02019\n 1\n12\nFigure\u00a03.7\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to the environment, using language from the Facebook comment space of the political parties, 13-22\u00a0March\u00a02019\n 1\n13\nFigure\u00a03.8\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to foreign affairs, using language from the Facebook comment space of the political parties, 13-22\u00a0March\u00a02019\n 1\n14\nFigure\u00a03.9\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to polarizing topics, using language from the Facebook comment space of the political parties, 13-22\u00a0March\u00a02019\n 1\n14\nFigure\u00a03.10\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to migration, using language from the Facebook comment space of the political parties, 13-22\u00a0March\u00a02019\n 1\n15\nFigure\u00a03.11  P resence of junk news in Google.nl search engine \nresults for political queries related to migration and \nEuropean Union issues, 22-24\u00a0May\u00a02019\n 1\n17\nFigure\u00a03.12\n P\nresence of junk news in Google.nl search engine \nresults for political queries related to climate and economic issues, 22-24\u00a0May\u00a02019\n 1\n17\nFigure\u00a04.1\n P\nolitical party leaders as trolling targets on Twitter \nduring the 2017 Dutch general elections. Each dot represents one mention (by a user mentioning political leaders at least 100 times). Red represents an attack, green represents a favourable mention.\n 1\n26\n S\nource: Borra et al., 2017\nFigure\u00a04.2\n E\nngagement of mainstream (blue) and junk news \n(pink) articles during the Dutch Provincial election campaign (left) and the European Election campaign period (right)\n 1\n29\n L\nine graphs; visualisation by Federica Bardelli\nFigure\u00a04.3\n E\nngagement with mainstream news (blue) and junk \nnews (pink) for the issue of MH17 (top right) and Zwarte Piet (top left) during the Provincial elections, and the EU elections (bottom right and left)\n 1\n30\n L\nine graphs; visualisation by Federica Bardelli\nFigure\u00a04.4\n T\nweet and user counts, top hashtags, and most-\nretweeted tweets during the Dutch provincial election period of 2019\n 1\n34\n D\nashboard; visualisation by Carlo De Gaetano\nFigure\u00a04.5\n G\nephi visualisation of Zwarte Piet host-user network \nduring the provincial elections campaign period, depicting only junk and tendentious hosts and the user accounts that circulate these sources\n 1\n36\n V\nisualisation by Carlo De Gaetano\nFigure\u00a04.6\n G\nephi visualisation of MH17 host-user network during \nthe provincial elections campaign period, depicting only junk and tendentious hosts and the user accounts that circulate these sources\n 1\n37\n V\nisualisation by Carlo De Gaetano\nFigure\u00a04.7\n G\nephi visualisation of Utrecht shooting host-user \nnetwork during the provincial elections campaign period, depicting only junk and tendentious hosts and the user accounts that circulate these sources\n 1\n38\n V\nisualisation by Carlo De Gaetano\nFigure\u00a04.8  G ephi visualisation of PS2019 host-user network \nduring the provincial elections campaign period, \ndepicting only junk and tendentious hosts and the users that circulate these sources\n 1\n39\n V\nisualisation by Carlo De Gaetano\nFigure\u00a04.9\n G\nephi visualisation of Party Leadership host-user \nnetwork during the provincial elections campaign period, depicting only junk and tendentious hosts and the users that circulate these sources\n 1\n40\n V\nisualisation by Carlo De Gaetano\n T\nhese line graphs visualise the engagement with \nmainstream news (blue) and junk news sources (pink) during the Dutch provincial election campaign (PS) and the European Election campaign period (EU), similar to Figure\u00a02, but excluding the tendentious-hyperpartisan sources.\n 1\n43\n V\nisualisation by Federica Bardelli\n T\nhese line graphs visualise the engagement with \nmainstream news (blue) and junk news sources (pink) for the issues of MH17 and Zwarte Piet during the provincial elections (PS), and the EU elections (EU), similar to Figure\u00a03, but excluding the tendentious-hyperpartisan sources.\n 1\n30\n V\nisualisations by Federica Bardelli\nFigure\u00a05.1\n D\niagram of the research protocol, showing the type of \nhashtags and accounts used for querying Instagram, and the tools used to collect, visualize and analyze the data\n 1\n51\nFigure\u00a05.2\n P\nroportions of most liked content shared around the \n2019 Dutch provincial elections, categorised as fake, satire, and not fake\n 1\n54\n D\nata source: Instagram Scraper; data collection: \n25-28\u00a0March\u00a02019; pie charts\nFigure\u00a05.3\n 2\n0 most liked posts per hashtag shared around the \n2019 Dutch provincial elections, sorted from right (most junk) to left (least junk)\n 1\n55\n D\nata source: Instagram Scraper; data collection: \n25-28\u00a0March; image wall\nFigure\u00a05.4\n E\nxamples of the posts flagged as hyperpartisan or satire\n D\nata source: Instagram Scraper; data collection: \n25-28\u00a0March; image wall\n 1\n56Alternate  figure\u00a04.2\nAlternate  \nfigure\u00a04.3\nFigure\u00a05.5  P roportions of most liked content shared around the \n2019\u00a0European elections, categorised as junk and not junk\n 15\n7\n D\nata source: Instagram Scraper; data collection: \n22\u00a0May\u00a02019; pie charts\nFigure\u00a05.6\n 2\n0 most liked posts per hashtag shared around the \n2019\u00a0European elections, sorted from right (most junk) \nto left (least junk) and grouped by type (elections, issues, political leaders, and parties). Posts flagged as hyperpartisan are colored in red.\n 1\n58\n D\nata source: Instagram Scraper; data collection: \n22\u00a0May\u00a02019; image wall\nFigure\u00a05.7\n F\nollower ecologies in the Dutch political space, visual-\nized as a co-follower network and manually annotated. In the network, accounts with higher amounts of shared followers (pink) are placed closer to each other.\n 1\n61\n D\nata source: Phantombuster; data collection: 25-\n28\u00a0March; network graph\nFigure\u00a05.8\n D\negree of account fakeness according to report by the \nHypeAuditor tool. Accounts on the further right have more suspected \u2018fake followers\u2019 than accounts on the left side of the graphs.\n 1\n62\n D\nata source: HypeAuditor; data collection:  \n25-28\u00a0March\u00a02019; bee swarm plot\nFigure\u00a05.9\n V\nisualization of the follower base of Mark Rutte\u2019s \npersonal and work accounts and Geert Wilders\u2019 account, based on results from the HypeAuditor tool. Each follower base is segmented based on \u2018audience type\u2019 and geographical provenance. Popular suspicious countries, that may suggest an inauthentic follower base, are coloured in red.\n 1\n63\n D\nata source: HypeAuditor; data collection:  \n25-28\u00a0March\u00a02019; pie charts\nFigure\u00a06.1\n T\nhe frontpage of Reddit (retrieved 11-Jun-2019)\n 1\n75\nFigure\u00a06.2\n T\nhe index page of 4chan/pol/ (retrieved 11-Jun-2019)\n 1\n75\nFigure\u00a06.3\n T\notal amount of posts and comments on one of the \nDutch subreddits (appendix I)\n 1\n81\n D\nata source: 4CAT and Pushshift; timeframe: 1-Dec-\n2015 to 1-Jun-2019; line graph; visualisation by Gabriele Colombo\nFigure\u00a06.4  F requency of posts linking to Dutch junk news \ndomains on Reddit\n 1\n82\n D\nata source: Google BigQuery; timeframe: 1-Dec-2015 \nto 1-Jun-2019; stream graph; visualisation by Gabriele \nColombo\nFigure\u00a06.5\n D\nutch versus non-Dutch subreddits in which Dutch \njunk news appears. Size of circle represents the overall number of posts in that subreddit within the timeframe, and colour represents the relative amount of posts with junk news.\n 1\n83\n D\nata source: Google BigQuery; timeframe: 1-Dec-2015 \nto 31-Jan-2019; circle pack diagram; visualisation by Gabriele Colombo\nFigure\u00a06.6\n D\nutch subreddits where Dutch junk news appear \ncompared to the size of all Dutch subreddits. Size of circle represents the overall number of posts in that subreddit, and colour represents the relative amount of posts with junk news.\n 1\n84\n D\nata source: Google BigQuery; timeframe: 1-Dec-2015 \nto 31-Jan-2019; circle pack diagram; visualisation by Gabriele Colombo\n A\nll Dutch and non-Dutch subreddits where Dutch \njunk news appear compared to the size of all of Reddit. Size of circle represents the overall number of posts in that subreddit, and colour represents the relative amount of posts with junk news.\n 1\n85\n D\nata source: Google BigQuery; timeframe: 1-Dec-2015 \nto 31-Jan-2019; circle pack diagram; visualisation by Gabriele Colombo\nFigure\u00a06.9\n L\nine graph of posts with Dutch country flags on \n4chan/pol/  \n187\n D\nata source: 4CAT; timeframe: 1-Dec-2015 to 01-Jun-\n2019; line graph; visualisation by Gabriele Colombo\nFigure\u00a06.10\n F\nrequency of posts linking to Dutch junk news \ndomains on 4chan/pol/\n 1\n88\n D\nata source: 4CAT; timeframe: 1-Dec-2015 to 01-Jun-\n2019; streamgraph; visualisation by Gabriele Colombo\nFigure\u00a06.11\n L\ninks to news (red) and non-news (blue) sources in \nposts in Dutch subreddits\n 1\n89Figures 6.7 & 6.8\n D ata source: 4CAT and Pushshift; timeframe: from \n1-Dec-2015 to 01-Jun-2019; treemap diagram; visualisa-\ntion by Gabriele Colombo\nFigure\u00a06.12\n L\ninks to news (red) and non-news (blue) sources in \nDutch posts on 4chan/pol/\n 1\n91\n D\nata source: 4CAT; timeframe: 1-Dec-2015 to 1-Jun-\n2019; treemap diagram; visualisation by Gabriele Colombo\nFigure\u00a06.13\n L\ninks to Dutch (orange) and non-Dutch (blue) news on \nDutch subreddits\n 1\n91\n D\nata source: 4CAT and Pushshift; timeframe: 1-Dec-\n2015 to 01-Jun-2019; treemap diagram; visualisation by Gabriele Colombo\nFigure\u00a06.14\n L\ninks to Dutch (orange) and non-Dutch (blue) news on \nDutch subreddits\n 1\n92\n D ata source: 4CAT; timeframe: from 1-Dec-2015 to 01-Jun-\n2019; treemap diagram; visualisation by Gabriele Colombo\nFigure\u00a06.15  C ategories of news domains in posts on Dutch subreddits  1 93\n D\nata source: 4CAT and Pushshift; timeframe: 1-Dec-\n2015 to 01-Jun-2019; treemap diagram; visualisation by Gabriele Colombo\nFigure\u00a06.16\n C\nategorised types of news from news sources posted \n4chan/pol/  \n194\n D ata source: 4CAT; timeframe: 1-Dec-2015 to 1-Jun-2019; \ntreemap diagram; visualisation by Gabriele Colombo\nFigure\u00a06.17  M ean Reddit posts scores by Dutch junk news propa-\ngators (users who posted a link to a Dutch junk news domain at least twice) as reported by Pushshift API\n 1\n97\n D\nata source: 4CAT and Pushshift; timeframe: \n1-Dec-2015 to 01-Jun-2019; bar graph; visualisation by Gabriele Colombo\nFigure\u00a06.18\n S\nubreddits where Dutch junk news domains are most \noften posted in\n 1\n98\n D\nata source: 4CAT and Pushshift; timeframe: 1-Dec-\n2015 to 31-Jun-2019; circle pack diagram; visualisation by Gabriele Colombo\nFigure\u00a06.19\n M\nost linked to junk news domains on all of Reddit\n 1\n99\n D\nata source: 4CAT and Pushshift; timeframe: 1-Dec-\n2015 to 1-Jun-2019; circle pack diagram; visualisation by Gabriele Colombo\nFigure\u00a06.20  T he top 1008 most posted YouTube videos in Dutch \nsubreddits. Black labels denote deleted videos/chan-\nnels. Ranked left to right, top to bottom\n 2\n04\n D\nata source: 4CAT, Pushshift, and YouTube API; image \nwall\nFigure\u00a06.21\n T\nhe top 1008 most posted YouTube videos in Dutch \nsubreddits, with video categories as an overlay. Black labels denote deleted videos/channels. Ranked left to right, top to bottom\n 2\n04\n D\nata source: 4CAT, Pushshift, and YouTube API; image wall\nFigure\u00a06.22\n T\nhe top 1008 most posted YouTube videos in 4chan/\npol/in posts with a Dutch country flag. Black labels denote deleted videos/channels. Ranked left to right, top to bottom\n 2\n05\n D\nata source: 4CAT and YouTube API; image wall\nFigure\u00a06.23\n T\nhe top 1008 most posted YouTube videos in 4chan/\npol/in posts with a Dutch country flag, with video categories as an overlay. Ranked left to right, top to bottom. Black labels denote deleted videos/channels\n 2\n05\n D\nata source: 4CAT and YouTube API; image wall\nFigure\u00a07.1\n R\nelated channels on YouTube. Table where the top \nrow displays the name of each Dutch political party and the columns below each of these are the media organizations associated with each party\u2019s YouTube channel. 29\u00a0March\u00a02019\n 2\n22\nFigure\u00a07.2\n T\nheLvkrijger post: Translated into English: \u201cHe who \nis silent agrees! Don\u2019t shut up anymore! This is your country! Claim it!\u201d\n 2\n24\nFigure\u00a07.3\n R\nelated channels on YouTube. Panoramic graph of \nlarger Dutch YouTube media sphere. This graph was reproduced two months apart on 29\u00a0March\u00a02019 and again on 22\u00a0May\u00a02019 with nearly identical outcomes.\n 2\n25\n V\nisualisation by Federica Bardelli using Gephi (Basian \net al., 2009)\nFigure\u00a07.4\n T\nhumbnail diagram of the \u2018fringe channels\u2019\u2019 top ten \nmost popular videos\n 2\n29\n V\nisualisation by Federica Bardelli\nFigure\u00a07.5\n S\ncreenshot from the \u201cAbout\u201d page on Cafe \nWeltschmertz\u2019s YouTube channel which includes a sarcastic \u201ctrigger warning\u201d for viewers whom might \nbe angered by its frank approach to political debate, \nas well as crypto-normative espousal of \u201cdemocratic hygiene processes\u201d.\n 2\n29\nFigure\u00a07.6\n W\neighted word lists of the titles of all the videos from \nthe political commentary channels  2\n31\n V\nisualisation by Federica Bardelli\nFigure\u00a07.7\n S\ncreenshot of a comment under the video of \u2018Leukste \nYT Fragmenten\u2019, referring to a \u2018hopeless debate\u2019 and the lack of consensus on the definition of \u2018nepnieuws\u2019\n 2\n32\nFigure\u00a07.8\n R\nelated channels on YouTube, 22\u00a0May\u00a02019\n 2\n37\n T\nable where the top row displays the name of each \nDutch political party who ran candidates in the EU election. As with figure\u00a01, the columns below each of these are the media organizations associated with each party\u2019s YouTube channel. The related channels for the parties are identical to figure\u00a01 apart from a few minor differences and the fact that D66 now no longer returns any related channels, as with PvdA. Note also that of the two EU parties that return channels are categorized quite differently than the other national Dutch political parties.\nTables\nTable\u00a01.1\n O\nverview of 2016 fake rallies planned and promoted, \nas listed in the US indictment of 13 Russian nationals concerning foreign election interference\n 2\n6\n S\nource: Parlapiano and Lee (2018)\nTable\u00a02.1\n T\nop 10 sites per category (provincial elections), for all \nqueries combined, sorted by overall engagement scores as reported by BuzzSumo\n 8\n7\nTable\u00a02.2\n T\nop 10 sites per category (EU parliamentary elections), \nfor all queries combined, sorted by overall engagement scores as reported by BuzzSumo\n 8\n7\nTable\u00a02.3\n T\nop 10 \u2018hyperpartisan\u2019 sites for both data sets (provin-\ncial and EU elections), sorted by overall engagement scores as reported by BuzzSumo\n 8\n7\nTable\u00a03.1\n L\nist of Dutch political parties under study\n 1\n03\nTable\u00a03.2\n L\nist of categories and political keywords used in the \nstudy  \n104\nTable\u00a04.1\n Q\nuery overview showing the election campaign period \n(Provincial, EU or both), the political or issue space and the query made resulting in Twitter data sets\n 1\n28\nTable\u00a05.1\n L\nists of hashtags pertaining to political leaders and \npolitically charged discussions used to demarcate the Dutch political space on Instagram around the 2019 provincial elections\n 1\n54\nTable\u00a05.2\n L\nists of hashtags pertaining to political leaders and \npolitically charged discussions used to demarcate the Dutch political space on Instagram during the months before the 2019\u00a0European elections\n 1\n57\nTable\u00a06.1\n T\nhe top 3 best performing posts linking to a Dutch \njunk comain on Reddit\n 1\n97\n D\nata source: 4CAT and Pushshift; timeframe: 01-Dec-\n2015 to 01-Jun-2019\nTable\u00a06.2\n M\netrics of users who shared the Dutch junk news on \nReddit  \n200\n D\nata source: 4CAT and Pushshift; timeframe: 01-Dec-\n2015 to 01-Jun-2019\nTable\u00a06.3\n T\nhe most occurring YouTube channels from all YouTube \nlinks posted in the Dutch Reddit and 4chan/pol/ samples\n 2\n06\n D\nata source: 4CAT, Pushshift, and YouTube API; \ntimeframe: 01-Dec-2015 to 01-Jun-2019\nTable\u00a06.4  C ompiled list of Dutch subreddits  2 11\nTable\u00a06.5\n J\nunk news categorisation (expert list)\n E\ndited and enhanced list originating from Hoax-Wijzer\n 2\n12\nTable\u00a06.6\n M\netrics for the proportions of news, Dutch news, \nDutch junk news, and categories in posts on Dutch \nlanguage subreddits, 01-Dec-2015 to 01-Jun-2019  2\n14\nTable\u00a06.7\n M\netrics for the proportions of news, Dutch news, \nDutch junk news, and categories in posts on 4chan/pol/ with a country flag from the Netherlands, 01-Dec-2015 to 01-Jun-2019\n 2\n15\nTable\u00a06.8\n M\nost occurring URLs from posts containing links to \nRT.com and Sputnik by posts with a Dutch country flag on 4chan/pol/\n 2\n15\n D\nerived with 4CAT\n\n1 T he politics of social media \nmanipulation\nRichard Rogers and Sabine Niederer\nAbstract\nThis chapter gives an overview of the contemporary scholarship surround -\ning \u2018fake news\u2019. It discusses how the term has been deployed politically \nas a barb against the free press when publishing inconvenient truths \nsince the mid-nineteenth century. It also addresses how such notions \nhave been used in reaction to novel publishing practices, including to the \ncurrent social media platforms. More generally, the scholarship could be \ndivided into waves, whereby the first related to the definitional issues \nand the production side, whilst the second has been concerned with its \nconsumption, including the question of persuasion. There is additionally \ninterest in solutions, including the critique of the idea that automation \neffectively addresses the problems. It concludes with research strategies \nfor the study of the pervasiveness of problematic information across the \ninternet.\nKeywords:  fake news, junk news, disinformation, clickbait, hyperpartisan, \npost-truth\nIntroduction: Influence campaigning in political spaces online \nand the question of persuasion\nIn reviewing the scholarship surrounding so-called fake news, one would \nout of necessity make a distinction between the dominant work on the art \nof influence campaigning and computational propaganda online and the \nconsequences to date for its consumers, but also the few findings, often \njournalistic, in the relatively understudied case of the Dutch political \nspace online, both on the web as well as in social media. Much work has \nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch01\n20 R icha Rd R oge R S  and Sabine ni ede ReR \nbeen undertaken on the influence of Russian (and Russian-style) influ -\nence campaigning in the US, and the presence or absence thereof during \nelections in Germany, France, Sweden and elsewhere. With respect to \nthe Netherlands, the case studies have been reserved to the early Russian \ninfluence campaigning around the downing of the MH17 Malaysian airliner \n(beginning in 2014) and the suicide bombings in the Brussels airport and \nmetro (2016), discovered through the use of Twitter data sets of Russian \ntrolls, or influence campaigners. Other work has been performed on the \nexistence of home-grown troll networks that are at times \u2018pro-Russian\u2019 but \ndo not seem to have had foreign input.\nCrucially, in the studies and journalistic treatments to date it is in -\ncreasingly remarked that there has been a shift in Russian disinformation \ncampaigning from inflaming conflict with the West to stirring it within the \nWest. It is also argued that disinformation could be said to be \u2018Russifying\u2019, \ni.e., the borrowing of so-called Russian techniques by domestic actors. The \ncampaigning, whether foreign or domestic, does more than create narratives \nthat divide; it also employs computational means to inflate and amplify \nthem through bot work, fake following, astroturfing, the creation of front \ngroups and other artificial publicity tactics.\nIt is also argued that more attention ought to be paid to the rise of extreme \nand divisive media on social media platforms, where the point is often \nmade that great emphasis is being placed on foreign disinformation when \nby comparison it performs poorly in European news spheres. The growth of \n\u2018hyperpartisan\u2019 news and commentary also may be viewed as an alternative \nfact or knowledge infrastructure, contributing to discussions of a post-truth \ncondition and the contention that established institutions are under threat.\nIt is of equal importance to examine the critique on persuasion, or \nthe extent to which the influence campaigning strategies, artificiality \nand hyperpartisan sources have discernible impacts on their consumers, \nespecially the voters. They appear to be minimal. Indeed, there is a small, \nbut growing literature critiquing transfer models, also known as hypodermic \nneedle or magic bullet theories which themselves could be considered part \nand parcel of the fake news hype and fascinations with so-called psyops \nactivities such as in the Cambridge Analytica case.1 Transfer models do \n1 T he Cambridge Analytica case or scandal refers to the illegitimate use of over 80 million \nFacebook users\u2019 information to develop micro-targeted advertising (Cadwalladr and Graham-\nHarrison, 2018). It prompted US Congressional and UK Parliamentary investigations, and also \nled to Facebook\u2019s tightening its data access for academics and public scrutiny more generally \n(Bruns et al., 2018).\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  21\nnot take into account the active filtering of media users or phatic sharing, \nit is argued, whereby one circulates dubious media more to connect with \nothers or for amusement than to pass along substantive information. Such \nmodels also would discount hardened attitude, and studies finding that \ncampaigns generally have minimal effects.\nAs for the measures to be taken, the literature both describes and oc -\ncasionally questions fact-checking and media literacy efforts because of the \nassumption that corrected information would assuage knowledge deficits, for \nattitudes often remain the same. Nonetheless, among the policy recommen -\ndations most frequently put forward are bolstering media literacy initiatives, \ntogether with flagging questionable content, manually and automatically, \nfor further scrutiny. Social media platforms are facing regulation and are \nasked to address extreme content and create public archives.\nOne aspect of the literature review relevant to empirical work concerns \nthe methods employed to demarcate political space online for the subsequent \nstudy of the scope and impact of problematic content, junk news and compu -\ntational propaganda \u2013 to use some of the terms for the larger phenomenon \nunder study. Under consideration here are largely mixed (quanti-quali) \ntechniques and digital methods from media studies and data journalism. \nThese provide distinctive political space demarcation strategies for the web \nas well as social media per platform as well as approaches for cross-platform \nanalysis. They query engines and platforms, measure significant political \nstories (in terms of engagement) and determine construals of dubiousness \nthrough news criticism, categorizing significantly engaged-with stories \ninto genres such as disinformation, conspiracy, clickbait, hyperpartisan \nand (automated) amplification. While often practiced on a story level, the \ndetermination of dubiousness also may be made through source criticism, \naccording to the extent to which publishers\u2019 output repeatedly accords with \njunk news definitions, discussed in the next section. It is also worth studying \nhow signal-based or algorithmic determinations of problematic content \ncomport with qualitative methods that are based on source (provenance) criticism.\nFake news, junk news and computational propaganda\nHistorically, fake news proclamations could be thought of as linked to \nparticular novel publishing practices both \u2018when old media were new\u2019 but \nalso nowadays through social media platforms (Marvin, 1988; Gitelman, \n2006). The term \u2018canard\u2019, meaning unfounded rumour or story, refers to \n22 R icha Rd R oge R S  and Sabine ni ede ReR \nthe contents printed in the French broadsheets of the eighteenth century; \n\u2018scandal sheets\u2019 are the British term for the same era of publishing (Darnton, \n2010). In the U.S., in particular, \u2018fake news\u2019 as a term recently experienced \na revival and travelled internationally, in the numerous senses in which \nit has been deployed historically: \u2018news satire, news parody, fabrication, \nmanipulation, advertising, and propaganda\u2019 (Tandoc et al., 2018: 137). As \ndirected towards contemporary social media platforms, the charge of \nfake news and similar terms often has been uttered as a lament after the \nintroduction of new media technologies, where there are concomitant calls \nfor new journalistic standards, as witnessed with the competing tabloids \nand their sensationalist, yellow journalism in the late 1890s and into World \nWar I as well as the radio and newswire in the 1920s (Opper, 1894; Lippmann, \n1922; McQueen, 2018).\nWith the rise of corporate public relations, the blurring of the distinction \nbetween the editorial and the advertisement sent over the wire or into \nthe airwaves prompted the use of the moniker, \u2018news fakers\u2019 (McKernon, \n1925; Lazer et al., 2018). Similarly, the contents of the early, unedited web, \npopulated by self-publishers, and later the blogosphere, were often described \nas \u2018too fresh to be true\u2019, given the speed of news production and the potential \nfor those looking for a scoop to convert unsubstantiated rumour into news \n(Hall, 2001; Rogers, 2005). More recently, the notion would be routinely \ndeployed by satirical news sources such as Saturday Night Live!  in the US (Day \nand Thompson, 2012); in fact, The Daily Show , the progressive comedy news \nprogram, described itself proudly as a \u2018fake news program\u2019 (Newman, 2010; \nHarsin, 2018). Parody, it should be recalled, was behind the origination of the \nmost circulated \u2018fake news\u2019 story during the US presidential campaigns of \n2015-2016, \u2018Pope Francis Shocks World, Endorses Donald Trump for President\u2019 \n(Allcott and Gentzkow, 2017). While many definitions concentrate on the \nfalseness of content, they may have the \u2018trappings of news\u2019 through the use \nof the news apparatus, including the style, formats and containers employed \n(Laquintano and Vee, 2017; Grinberg et al., 2019). Indeed, narrower definitions \ntake as their point of departure how the sources \u2018falsely claim to be news \norganizations,\u2019 though they may well look the part (Tucker et al., 2018: 3).\nFake news also has been deployed politically as a barb against the free \npress when publishing inconvenient truths, or speaking \u2018truth to power\u2019 \n(Cary, 1955; Darnton, 2017). Since the mid-nineteenth century, labelling \nthe news media generally and disagreeable reporting specifically as the \nproduct of der L\u00fcgenpresse or the lying press is a discrediting ploy or even \ncommunication strategy, still practiced today by far-right social move -\nments as Pegida in Germany, chanting at street rallies L\u00fcgenpresse, halt \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  23\ndie Fresse (lying press, shut your mouth) (Beiler and Kiesler, 2018). It was \nthe German Unwort des Jahres (notorious word of the year) in 2014, in the \ncompetition organized by TU Darmstadt. Fake news is also a label, used in \nhighly conservative political circles in the US, for particular news sources, \nnotably CNN, MSNBC, The  New York Times, and The Washington Post ; the \ndesignation is similar, albeit perhaps more extreme, to past portrayals of \nthe agenda-setting \u2018elite media\u2019 in contrast to conservative upstarts as Fox \nNews  (Marwick, 2018; Tripodi, 2018; Peck, 2019). In this respect, one could \ncall the current situation just the latest fake news scare, or even moral \npanic (Brennen, 2017; Morozov, 2017).\nWhen discussing the phenomenon in relation to social media and other \nonline sources, researchers at the computational propaganda project at the \nOxford Internet Institute (OII) often offer the umbrella term \u2018junk news\u2019, \ndefined as \u2018extremist, sensationalist, conspiratorial, masked commentary\u2019 \n(Howard et al., 2017, 1). Other catch-all\u2019s include \u2018problematic information\u2019, \n\u2018information disorders\u2019 and \u2018false news\u2019 (Jack, 2017; Wardle and Derakhshan, \n2017). Apart from sensationalist, conspiratorial and masked \u2013 features that \nhave been a part of fake news ontologies for centuries \u2013 the OII defini-\ntion emphasizes another element, extremist, which cuts to the heart of \ncontemporary concern for the phenomenon when studied not only as a \npractice of media and public opinion manipulation but also a trigger for \nsocietal unrest.\nWith respect to the growing anxiety over fake news as harbinger of unrest, \none may refer to the distinctions made between a variety of information \ndisorders, as well as the coinage of new terminology that captures excitable, \nInternet-related media and speech (Wardle, 2018). First, disinformation and \nmisinformation are both false, but the latter is unintentionally so, whilst the \nformer is fashioned for the purposes of intentional disruption and causing \nharm. A third term, \u2018mal-information\u2019 (a neologism), seemingly borrowed \nfrom malware or malicious software categorizations, has been introduced \nto describe accurate information released for the purposes of harassment \nsuch as doxing, or publishing private details (Wardle and Derakhshan, 2017).\nThese are the tools for the so-called \u2018weaponization\u2019 of social media \nplatforms to foment discord through seeding the news and public opinion \nwith divisive content. Indeed, \u2018extreme speech\u2019 is a term that has been offered \nas a nuancing of the hate speech discourse as it is applied to online toxicity. \nIt is meant to capture a form of charged language and cultural conflict that \nstops short of hate, and has emerged with social media, defined as \u2018vitriolic \nexchange on Internet-enabled media\u2019 (Pohjonen and Udupa, 2017: 1173). \nIts rise has prompted social media companies as Facebook, Twitter and \n24 R icha Rd R oge R S  and Sabine ni ede ReR \nAlphabet (owners of YouTube) to expand their content reviewer pools as \nwell as widen their internal mandates to identify and remove more than \nviolence, pornography and hate (Gillespie, 2018). Google also installed a \nfeedback system for its web search to report inappropriate autosuggestions, \nafter reports of queries for the \u2018holocaust\u2019 autocompleting with \u2018is a hoax\u2019 \n(Solon and Levin, 2016; Hern, 2017).\nAs with new media technologies of old, social media platforms currently \nare said to enable the \u2018supercharging\u2019 or the acceleration of the spread of \nfake news (Bounegru et al., 2018). Two terms have been used to capture the \nweb and subsequently social media as accelerationist media: clickbait and \ncomputational propaganda. Clickbait connotes titillating and sensational \ncontent and is formulaic in its presentation, often containing numbered lists \n(sometimes referred to as a \u2018listicle\u2019) as well as a cliff-hanger or \u2018information \ngap\u2019 that sparks curiosity, e.g., \u2018twenty things you should not do when visiting \nJapan\u2019. Facebook, in seeking to identify and downgrade clickbait in its news \nfeed, defines it as \u2018a posted link with a headline that encourages people \nto click to see more, without telling them much information about what \nthey will see\u2019 (O\u2019Donovan, 2018). Generally social media companies seek to \noperationalize substantive definitions into computational signals. Thus, to \nFacebook, brief attention (or short \u2018time-on-site\u2019) is a signal of clickbait, for \nreaders, having been lured in to the \u2018junk food of content consumption\u2019, are \nsubsequently dissatisfied with the low-quality content, and leave the page \nquickly (DeAmicis, 2014). Clickbait, often innocuous, can be combined with \ndivisive content (Burger and Schenk, 2019). \u2018Extreme clickbait\u2019 was a part of \nthe story behind the allegedly apolitical Macedonian teens based in Veles, \nwho used \u2018spammy techniques\u2019 in optimizing pro-Trump sites to make \nmoney, in the run-up to the US presidential elections of 2016 (Silverman and \nAlexander, 2016). Follow-up reporting has sought to debunk that narrative, \nfinding that the clickbait campaign was orchestrated by political operatives \n(Wendling, 2018; Silverman et al., 2018).\nComputational propaganda, the second term, refers to \u2018the assemblage of \nsocial media, autonomous agents and algorithms tasked with the manipula -\ntion of opinion\u2019 (Neudert, 2017: 3). The breadth of the definition is intended \nto capture the bots that amplify content, the advertising platforms that \nenable micro-targeting and personalization of influence messaging, and \nthe click farms that inflate the follower counts and engagement scores, \ngranting posts higher \u2018vanity metrics\u2019 and thus greater symbolic power \nthrough fake support (Rogers, 2018a). For computational propaganda, bots \nincrease the spread or reach of the posts and inflate their metric counts \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  25\n(Woolley and Howard, 2016). \u2018Low-credibility content\u2019 is spread dispropor -\ntionately by \u2018social bots,\u2019 which refer to bots or autonomous agents tasked \nwith influencing discussion and public opinion; such a finding has led to \ncalls for curtailing their use (Shoa et al., 2018). As a part of the \u2018assemblage\u2019 \nof actors and software practicing computational propaganda, the work of \nsoftware-assisted, political operatives has come under scrutiny, especially \nin the run-up to elections. Sock puppets, assuming the false identity of a \ngrassroots organizer or a concerned individual, create and circulate political \ncontent, organize events and mobilize audiences, making interventions in \nthe physical world through hashtags, internet memes and Facebook events \n(Mina, 2019). \u2018Front groups\u2019 or even faux \u2018hashtag publics\u2019 also mobilize \nfollowings and organize demonstrations (see Table\u00a01.1); one notorious case \nconcerned an anti-Islam protest and counter-protest in Houston, Texas, in \n2016, where both groups were mobilized by Russian campaigners operating \nunder the names of the Blacktivists and the Heart of Texas, respectively \n(Shane, 2018).\nA related term for disingenuous content insertion for political ends is \nastroturfing. It is the artificial seeding of newspapers and other content \nproviders with political (or corporate) advertising disguised as genuine \ncitizen concern. Such content is a different category than sponsored political \ncontent, where there are regulations that mandate labelling it as \u2018paid for \nby\u2019 a particular candidate or campaign (Vaidhyanathan, 2017). Nonetheless \nthere have been calls to have \u2018masked\u2019 political content unmasked and \nmarked as sponsored, however much in the case of a pro-Brexit group, \nBritain\u2019s Future, investigative journalists were long not able to unearth the \nfunding source, despite the transparency of its being labelled.\nParticular forms of native social media advertising have prompted \nthe calls for further public scrutiny of political ads, and also perhaps an \nexpansion of the definition of such. \u2018Dark posts\u2019 (aka \u2018promoted posts\u2019) \non Facebook refer to micro-targeted advertisements, without a referral \npage anchoring the content for further investigation (Bump, 2017). Used by \npolitical operatives, including foreign influence campaigners, in the US in \n2014-2017 and beyond, such campaigning tactics assemble \u2018keyword publics\u2019 \nalgorithmically by querying the Facebook advertising platform for words \nsuch as \u2018second amendment\u2019 or other pro-gun terminology and sending \nadvertisements to the news feeds of the tens or hundreds of thousands of \nthose users determined to have such an interest (Angwin et al., 2017). These \npublics are targeted not so much because they are persuadable voters but \nrather to have them circulate and amplify messaging.\n26 R icha Rd R oge R S  and Sabine ni ede ReR \nTable\u00a01.1   O verview of 2016 fake rallies planned and promoted, as listed in the \nUS indictment of 13 Russian nationals concerning foreign election \ninterference\n2016 fake rallies planned and promoted\nDate Fake rally Location\n25\u00a0June March for Trump ne\nw York\n9\u00a0July Support \nhi\nllary. Save \nam\nerican Muslims Washington, \nd.c.\n2\n3\u00a0July do\nwn with \nhi\nllary ne\nw York\n20 \na\nug. flor\nida goes Trump Several \nfl\norida cities\n2 \noc\nt. Miners for Trump Several Pennsylvania cities\n12 \nno\nv. Show your support for President- ele\nct \ndon\nald Trump ne\nw York\n12 \nno\nv. Trump is \nnoT m\ny president ne\nw York\n19 \nno\nv. char\nlotte against Trump c\nharlotte, \nn.c.\nSource: Parlapiano and le e (2018)\nApart from particular social media advertising products such as dark posts, \nother formats have been identified as energizing publics with divisive \nmessages. \u2018Image macros\u2019, also known as memes, are photos with two lines of \ntext, one opening and one closing line, that are a popular format for political \nmessaging on Facebook and have been among the most shared and otherwise \nmost engaged-with content on the platform (Renner, 2017). Indeed, in the \ndata analysis of the most shared posts of the \u2018fake\u2019 (or astroturfing) activist \ngroup pages set up by the Russian Internet Research Agency (Blacktivists, \nUnited Muslims of America, Being Patriotic, Heart of Texas, Secured Borders \nand LGBT United), the image macros and other meme material scored \nparticularly well (Chen, 2015; Albright, 2017; Timberg, 2017).\nRussian influence campaigning, Russification and the \n\u2018hyperpartisan\u2019 style\n\u2018Dark globalization\u2019 is a term put forward by the historian Timothy Snyder to \nrefer to how knowledge of western societal problems provides opportunities \nto influence campaigners from abroad, or Russia in particular (2018). In the \nUS Snyder refers to the complex of race, gerrymandering and the electoral \ncollege, and the capacity to target voters in specific geographical areas (such \nas counties in \u2018swing states\u2019) with divisive political messaging that amplify \nor provide \u2018oxygen\u2019 to viewpoints. There have been detailed analyses of the \nRussian influence campaign of 2014-2017 commissioned by the US Congress, \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  27\nboth of which benefited from data provided by Facebook, Twitter and \nAlphabet (Google) that previously had not been made available for research \n(Howard et al., 2018; New Knowledge, 2018). They are a part of a litany of \nliterature that has appeared since the commissioning by governments to \nstudy the \u2018tactics\u2019 of the influence campaigners as well as the contemporary \nart of propaganda and the development of counter-narratives more generally. \nThese studies also have led to recommendations concerning how to combat \nthe effects.\nThe study by the cybersecurity firm, New Knowledge, emphasizes the \ncollective cognitive dissonance that effective propaganda achieves, introduc -\ning (and popularizing) language from intelligence and counterintelligence \nwork (2018). Among the goals of the propagandists is to create \u2018a wilderness \nof mirrors\u2019, originally a phrase from a T.S. Eliot poem but mobilized by the \nintelligence community (Holzman, 2008). It refers to an environment where \ntruth (and its establishment) are no longer self-evident (Groll, 2018).\nTo achieve that goal, New Knowledge argues, one particular tactic is the \ncreation of a similarly termed \u2018media mirage,\u2019 or \u2018interlinked information \necosystems designed to immerse and surround targeted audiences\u2019 (2018: 42). \nThey are enveloped in an \u2018information cacophony\u2019, where stories from the \npress are repurposed, and given another author (\u2018blacktivists\u2019), interpretation \nand tone. Here is one example, taken from an original newspaper story about \nhow an \u201811-Year-Old Texas Boy Invents Device to Prevent Hot Car Deaths\u2019 \n(Dahlgren and Arkin, 2017). It was reworked as follows: \u2018[T]hese are stories \nof Black children the media don\u2019t want you to see\u2019; \u2018White people invent \ntools for killing, this Black child is inventing a tool for saving lives\u2019 (New \nKnowledge, 2018: 62). The divisiveness and the effectiveness ascribed to \nthe sample post derives not only from the transformation of the feel-good \nnews story into a contrived in-group and out-group divide based on race. \nNote, too, the format used; the second sentence is a two-liner, to be cast \ninto an image macro or meme, the popular format for sharing and further \ncirculation of grievance, outrage as well as mockery. The story also brings together categories of problematic information. It is both clickbait as well as rather extreme content, and it invites the consumer to read more about the grievance. It is also packaged to be shared.\nThe purpose of such campaigning is to sow discord and enmity, but it is \nonly one of a variety of tactics where the overall goal is to remove a sense of \na collective and shared experience of the world, as analysts have phrased it, \nand reify group formation (Gessen, 2018). Apart from the creation of a media \nmirage, the other tactics listed are as follows: \u2018targeting, asset development, \ncross-platform brand building, memetics, inflecting a common message for \n28 R icha Rd R oge R S  and Sabine ni ede ReR \ndifferent audiences, narrative repetition and dispersal, repurposing and \nre-titling pages and brands, manipulating journalism, amplify conspiratorial \nnarratives, sow literal division, and dismiss and redirect\u2019 (New Knowledge, \n2018: 2). With respect to social media, as discussed above, targeting could \nrefer to the audience segmentation available in platforms for advertising \npurposes, and memetics to the use of both the image macro to formulate \na punchy message as well as to build the meme as an additive content \ncontainer for narrative reinforcement.\nIt is worthwhile to mention that the expert studies are snapshots, but \nthese as well as subsequent reporting have pointed to the \u2018ongoing efforts\u2019 \nof the influence campaigners, and their global spread. While social media \ncompanies \u2013 since the Cambridge Analytica and fake news scandals \u2013 have \nbecome more active in identifying and suspending accounts of known Rus -\nsian and other state-sponsored trolls (e.g., Iranian), similarly named accounts \nare active and can be traced to known networks of political operatives \n(New Knowledge, 2018; FireEye, 2018). New accounts are continually made \n(Vaidhyanathan, 2018); the Chief Technology Officer at Facebook speaks \nof \u2018blocking more than one million fake accounts every day, sometimes \njust when they are created\u2019 (O\u2019Brien, 2019). The percentage of influence \ncampaigner accounts in that large number is not known.\nRecently, there has been growing concern not only about the ongoing \nefforts of Russian influence campaigners but also the uptake by other groups \n(or \u2018domestic actors\u2019) of the so-called \u2018Russian playbook\u2019 (Frenkel et al., \n2019). Journalistic coverage was prompted by the announcement by Twitter \nthat prior to the US Congressional elections of 2018 it removed accounts \nof Americans posing as members of state Republican parties (Harvey and \nRoth, 2018). Facebook also announced that hyperpartisan pages on both \nsides of the political spectrum in the US would be removed. Discussions \nof the \u2018Russification\u2019 of online political campaigning also historicized \ndisinformation, pointing to the classic examples, such as the claim that \nthe HIV virus was the leaked product of a US bioweapons lab; it was planted \nin news outlets beginning in 1983 by Soviet dezinformatsiya  campaigners \nin \u2018Operation Infektion\u2019 and ultimately spread four years later to national US TV news (Boghardt, 2009; Ellick and Westbrook, 2018). Comparing the \ntime span of such news spread to the dynamics of reach in the hybrid media \nsystem nowadays is how one may describe how the \u2018platform press\u2019 has \nsupercharged fake news (Chadwick, 2013; Bell and Owen, 2017).\nIn a well-cited article in the New York Times, Facebook, as a leading \nexample of the \u2018platform press\u2019, was described as a \u2018totally insane, unin -\ntentionally gigantic, hyperpartisan political-media machine\u2019 (Herrman, \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  29\n2016). The author spends some time describing the manner in which \nFacebook mixes posts in its news feed from both family members and \nfaint acquaintances, but also discusses the presence of upstart media \norganizations and self-styled advocacy groups that only exist online, many \nonly in social media. Most are described as \u2018hyperpartisan\u2019. These sources \npopulating the platform with content are defined as \u2018openly ideological \nweb operations\u2019 (Herrman, 2016). They also are successful, not just because \nmore extreme and sensational content spreads faster than more sober -\ning truth (Vosoughi et al., 2018). It is also because they employ formats \nthat engage large numbers of users and learn from their engagement and \nreach. \u2018Operating\u2019 in a continuous feedback loop of metrics data, posts are \noptimized to perform well in social media. The performance measures are \nbased on the virality of posts, and those that work well are emulated. There \nare particular formats as well as styles that drive engagement. Memes and \nclickbait such as listicles, cliff-hanger headlines and human-interest stories \nare among the formats used, as mentioned above. The hyperpartisan style \nhas a variety of substantive features, not all of which are equally applied, \nbut many appear to be working well. Often anti-establishment as well \nas positioned as against or in competition with the truth-seeking and \nfact-finding of the mainstream media, the media operations post stories \nthat are alternatives. These alternatives may be interpretations, facts and \neditorial commentary on events. They become media layers on the news. \nThe presentation is often edgy, both in terms of being knowledgeably on \ntrend but also sharp in tone. The posts are regular, and as such are part of \nthe permanent updating culture, providing a competing \u2018feed\u2019 about what \nis happening in the world and in media.\nThe post-truth condition\nThere is a series of contemporary utterances that have contributed to public \ndiscourse about a post-truth condition. One is the satirical notion of \u2018truthi -\nness\u2019 (Colbert Report, 2005). Developed as political news commentary \nand comedy, it refers to having the appearance of being true, but without \nevidentiary basis. Another \u2013 \u2018alternative facts\u2019 \u2013 is a term that initially \nreferred to the insistence by a member of the US Trump administration that \nthe number of attendees at the presidential inauguration in 2016 was higher \nthan reported and measured by crowd science (Still, 2017). The subsequent \nclarification of the meaning behind \u2018alternative facts\u2019 is more to the point: \n\u2018additional facts, alternative interpretation\u2019 (Nuzzi, 2017). Compared to \n30 R icha Rd R oge R S  and Sabine ni ede ReR \ntruthiness, here facticity does not derive from eye-witnessing or additional \nmethodological authority but rather from other fact-making.\nIn response to what is sometimes considered first-order objectivity battles, \nor disputes over matters of fact (Margolis, 1995; Latour, 2008), newspaper \nreporting with such headlines as \u2018Here Are the Real [Facts]\u2019 as well as the \nwork by fact-checking bureaus and initiatives are contesting fact claims with \nincreasing urgency (Fandos, 2017). These are public debates about facts, in-\nputs into which include fact-checking, a common practice of journalists and \nuniversity research groups seeking to confirm the basis behind particular \nstatements by politicians and others (Graves, 2016). Recently, scholarship on \nthe effectiveness of fact-checking has developed in at least two directions: \nthe extent to which fact-checking corrects the record as well as factual \nbeliefs, and whether it changes attitudes (Barrera et al., 2017). Both are part \nof the decades-long discussion and critique of the \u2018information deficit\u2019 and \n\u2018diffusion\u2019 models, which challenge ideas that providing correctives clears \nup controversies (Wynne, 1991; McNeil, 2013).\nIn the fake news scholarly discourse, it has been found that there are \ndistinct audiences for \u2018alternative facts\u2019 and \u2018fact-checked facts\u2019 (Bounegru \net al., 2018). Whilst there may be a correction to the record, the original \naudience may not have been exposed to it. Fact-checked stories also have \nsimilar circulation patterns to alternative facts; they are forwarded to \nlike-minded audiences (Shin and Thorson, 2017). Though it does not tell the \nentire story about exposure, both the original as well as the fact-checking \npublications are outlets with distinctive audiences or subscriber bases, with \nfact-checking newsletters often with smaller, specialty circulations, though \ntheir visibility may increase as they are built into platform interfaces such \nas Facebook\u2019s. In the other strand of work, it is asked, does exposure to \nfact-checked facts change factual beliefs as well as attitudes? Here one set of \nfindings is in keeping with the critiques of the effectiveness of fact-checking \nand the information deficit model more generally, for respondents saw their \nfactual accuracy improve, but their attitudes remain unchanged (Nyhan et \nal., 2019). Fact-checking, however, could be understood as a documenting \nprocess that corrects the record by capturing a dubious story and committing \nit, and its debunking or exposure, to searchable databases and other media.\nThe post-truth condition, though, has been described as a competition with \nrespect to not first-order but second-order objectivity. In such a circumstance \nthere is a rise of competing regimes of truth (Fuller, 2018). Expertise becomes \n\u2018sectarian\u2019 (Turner, 2001). The idea of the media mirage (evoked to describe \neffective disinformation campaigns) does not in itself create a competing truth \nregime or infrastructure. Rather, it introduces noise into an infrastructure. \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  31\nBut when propagandists, or in a different reading of the contemporary situ-\nation, a populist radical right media ecology, create an alternative news and \ninformation infrastructure, those efforts fit with descriptions of the post-truth \ncondition (Benkler et al., 2017; Sa\u0308ngerlaub et al., 2017).\nIn other words, post-truth is a term that should not be construed as \nsignifying hoodwinked (or radicalized) consumers, or the \u2018wholesale \ncheapening\u2019 of fact-making (Sismondo, 2017). Rather, in asking whether \n\u2018we can have our facts back\u2019, the debate concerns whether (or when) publics \ncan agree on the \u2018facticity infrastructure\u2019 or even the modernist project of \nknowledge institutions (Marres, 2018). As a case in point, there are ideologi -\ncally distinctive alternatives to Wikipedia (such as Infogalactic, Metapedia \nand Conservapedia), producing encyclopaedias challenging not only what \nis known or settled fact, but also the sources rooting it (Fitts, 2017).\nElections, disinformation, and the Dutch case\nThree recurring topics are often discussed in the news and (commissioned) \nresearch on disinformation and fake news in the Dutch context. First of all, \nof particular concern are Russian trolls and their spreading of disinformation \nin the Netherlands. Secondly, there are the (non-Russian) fake accounts \nand fake fans that that inflate the popularity of a campaign or a prominent \nfigure, granting them greater symbolic power. And thirdly, publications \nare addressing its discernibility and possible countermeasures. How to \nrecognize it and combat it? Each of these discussions is often set against \nthe backdrop of a changing news media landscape, whereby mainstream \nnews is increasingly competing with more tendentious and hyperpartisan \noutlets, and digitization is leading to user-driven and algorithm-driven \npersonalization. That may narrow the horizon of news that users encounter \nand perhaps increase fringe consumption, though in empirical studies \nsuch has not been found (Wieringa et al., 2017). Comparisons of the Dutch \nsituation are also drawn with the US.\nWhile digitization may be changing how people consume news, a study \nof online news behaviour, disinformation, and personalization of the news \nby the Rathenau Institute stresses that in the Netherlands, the traditional \nnews media still hold a firm and stable position in the media landscape (van \nKeulen et al., 2018). The study also finds that there is not (yet) widespread \nalgorithmic personalization in Dutch media sites. And, in stark contrast to \nthe current situation in the US, Dutch news consumers tend to use a variety \nof sources and have trust in the traditional news media (and less so in social \n32 R icha Rd R oge R S  and Sabine ni ede ReR \nmedia). Lastly, the report underlines that the Netherlands does not have \nsuch a particularly polarized media landscape as the US.\nOverall, there is a strikingly moderate tone of voice in the literature on \nthe Dutch case, both in news reporting and research reports. Since 2016, \nseveral studies have looked at disinformation practices in the Dutch political \nlandscape, and each of them has concluded that neither is there any large-\nscale disinformation activity in the Dutch media nor does disinformation \nhave a significant impact on Dutch citizens. However, in the Summer of 2017, \nWilfred Rietdijk, a Dutch general and national security advisor, announced \nin an interview with Dutch newspaper de Volkskrant  that the Netherlands \ncould no longer deal with the digital threat (van Zijl and Modderkolk, 2017). \nA \u2018landslide of fake news\u2019, as the subsequent tabloid headline read, would \nlead the country into chaos and division (Jonker, 2017). Including breaches \nand intrusions in his threat assessment (thereby widening the scope beyond \ndisinformation), Rietdijk explained how Dutch companies are \u2018in the line \nof fire\u2019 from \u2018thousands of hackers from Russia, China, and countries such as Iran and even Sudan\u2019 (van Zijl and Modderkolk, 2017). The general is not the first to warn of foreign interference in the Dutch online space, though case studies were lacking, at least in the public domain.\nRussian trolling and its perceived insignificance in the Netherlands\nWhen the Minister of Internal Affairs, Kajsa Ollongren, warned the Dutch \ngovernment of Russian disinformation in the Netherlands, she initially was \ncriticized for not having compelling examples (Pleijter, 2017; Kist and Was -\nsens, 2018a). Two journalistic studies that have looked into Russian tweets \nhave found activity in the Dutch online realm, however. A study by NRC \nHandelsblad  mined 200,000 tweets from Russian Internet Research Agency \n(IRA) accounts and found disinformation campaigning beginning in 2014 \nand another spate in 2016. The weekly magazine De Groene Amsterdammer  \ncombined the NRC Handelsblad  data with larger collections of Russian troll \naccounts, made available on the American public opinion analysis website, \nFiveThirtyEight as well as the lists published by American Congress (van \nder Noordaa and van de Ven, 2018a). Both studies found a peak in trolling \nactivity after the downing of MH17 in July of 2014. The NRC Handelsblad  \nstudy finds that Russian trolls posted 57,500 tweets, most of which were \nin Russian and aimed to influence public opinion in Russia and Ukraine, \nand only four of the tweets were in Dutch (Kist and Wassens, 2018b). The \nstudy by De Groene Amsterdammer  confirms that most tweets on MH17 \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  33\nwere in Russian but finds more mentions of Dutch \u2018conspiracy theorists \nand activists\u2019, indicating a shift from challenging Western narratives (for \nRussian-speaking audiences) to seeking to stir conflict within the West.\nA second event revealed more coordinated Russian troll activity in the \nDutch language Twitter space (in Belgium and the Netherlands), and a \nfurther example of striving to foment unrest, albeit unsuccessfully (accord -\ning to engagement measures) (van der Noordaa and van de Ven, 2018b). It \nconcerned the spreading of anti-Islam content directly following the terrorist \nattacks in the Brussels airport and metro in March\u00a02016, and in the two years \nafter the attacks. This anti-Islam \u2018campaign\u2019 involved about 950 tweets in \nthe Dutch language that were circulated by some 150 IRA-related accounts. \nThese tweets were rarely retweeted, however. In the event, Russian trolls are \nmore successful in the Netherlands with the circulation of English-language \ncontent. While these tweets are not related to Dutch issues and focus on for \ninstance the US elections, they have been shared widely by over 6,000 Dutch \nTwitter users with a total of 9.5 million followers (Kist and Wassens, 2018a).\nPerhaps counterintuitively, there was only minimal Russian interference \nwith the Ukraine referendum in the Netherlands in April of 2016 (NOS, 2017). \nThere was the Russian video capturing fake Ukrainian far-right militia \nmembers threatening terrorist attacks in the Netherlands and burning a \nDutch flag, but it was readily recognized as propaganda (Bellingcat, 2016). \nOtherwise, only a handful of tweets propagating a \u2018No\u2019 vote was found in \nthe larger set of tweets under study (van der Noordaa and van de Ven, 2018a).\nThe NRC Handelsblad concludes its work on the Twitter data set by noting \nthat it is possible there is larger scale Russian activity in the Netherlands; it \nshould be studied beyond just Twitter to include other platforms with known \ntroll activity, such as Facebook, Instagram, YouTube and Reddit. Indeed, \nespecially after Trump\u2019s victory in the US presidential elections of 2016, many \nnews outlets pointed towards Facebook. As discussed in some detail below, \na study by BuzzFeed News  compiled the most engaged-with posts in the nine \nmonths prior to the elections and found that so-called fake news during \nthat time was circulating more than mainstream news. Journalists from the \nNRC Handelsblad  replicated the study\u2019s general method for the Netherlands, \nbut with a narrower definition of fake news. They determined that the one \nhundred most-shared political news articles from January and February of \n2017, in the run-up to the Dutch general elections, did not contain fake news \n(Kist and Zantingh, 2017). Certain articles could be considered misleading \nor biased, they thought, for they exaggerated news facts or took them out of \ncontext. The themes that were most resonant during the campaign period \nin the Netherlands were immigration, Islam and Geert Wilders.\n34 R icha Rd R oge R S  and Sabine ni ede ReR \nDutch fake followers and trolls\nUntil November of 2017 much of the reporting has insisted that the Nether -\nlands \u2013 and the Dutch elections in particular \u2013 have been largely unaffected \nby disinformation or fake news. Much of the news coverage that speaks of \nit concerns \u2018fake followers\u2019. For instance, in 2015, there was a small scandal \nabout Geert Wilders concerning a dubious increase in his followers on \nTwitter. Indeed, when Twitter addressed the issue of fake followers and \nfollower count inflation through a mass removal of suspect accounts in \n2018, Wilders as well as other Dutch politicians (including from the political \nparty Denk) saw their metrics decline (NOS, 2018). In perhaps the most \nwell-known case, the Dutch singer-songwriter Dotan was found to have a \nfake following of 140 user accounts, which were used between 2011 and 2017 \nto like the musician on social media, edit the Wikipedia article on the artist, \nrequest his songs at radio stations and circulate heart-warming stories about \nhim across social media platforms. One of the profiles declared how Dotan\u2019s \nmusic helped her through a period of grief after a miscarriage; another tells \nhow Dotan welcomed one fan\u2019s terminally ill brother in a meet-and-greet, \nthroughout which the singer held the boy\u2019s hand. Both testimonials were \nfalse, as reporters of de Volkskrant  found and Dotan later confirmed (Mis\u00e9rus \nand van der Noordaa, 2018a; 2018b).\nIn 2018 the first large-scale global study of computational propaganda \nwas published, examining organized social media manipulation such as \nthe use of fake followers in 48 countries, including the Netherlands (Brad-\nshaw and Howard, 2018). The study describes the different computational \ntactics employed not so much by Russian influence campaigners but by \npolitical parties to influence voters and the elections.2 It was found that \nthe use of social media as an infrastructure for the spread of propaganda \nand disinformation has become widespread. Under examination is \u2018cyber \ntroop activity,\u2019 defined as \u2018government or political party use of social media \nto manipulate public opinion\u2019 (Bradshaw and Howard, 2018: 9).\nWhile in more authoritarian regimes, social media manipulation fits \ninto larger scheme of voter suppression and election rigging, in \u2018emerging \n2 T he research conducted a content analysis of news articles reporting on cyber troop activity \nin a sample of 48 countries, supplemented by an in-depth secondary literature review. To collect \nthe news articles, the researchers used the following keywords in combination, in queries across \nGoogle, Yahoo!, Bing and LexisNexis: astroturf*; bot; Cambridge Analytica; Facebook; fake; \nfake account; disinformation; government; information warfare; intelligent agent; military; \nmisinformation; persona management; pro-government; propaganda; psychological operations; \npsyops; social media; sock puppet*; troll*; Twitter (2018: 8).\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  35\nand Western democracies, sophisticated data analytics, and political bots \nare being used to poison the information environment, promote scepticism \nand distrust, polarize voting constituencies, and undermine the integrity of \ndemocratic processes\u2019 (Bradshaw and Howard, 2018: 5). The tactics described \ninclude the use of three kinds of fake accounts. First, there is the creation \nof online commentator accounts that attack and troll genuine users, spread \ndivisive content, or \u2018[divert] conversations or criticism away from important \nissues\u2019 (Bradshaw and Howard, 2018: 11). A second tactic entails automated \naccounts or political bots to automatedly flood particular hashtags, and \nastroturf by faking a follower base. The bots also troll genuine users by \nreporting them and flag organic content thereby having both suspended \nuntil a human moderator checks them. A third tactic is the use of hybrid \naccounts, which are those that make use of automation (for the sake of speed \nand convenience) but are actively curated by human users, who commonly \nmanage multiple fake accounts or sock puppets. This type of fake account is \ndifficult to recognize, and thus to combat. The study finds that automation \nis the most recurring tactic, seen in 38 of the 48 countries under study.\nBesides fake accounts, other strategies involve the use of political ads \nand the involvement of search engine optimization and activity on chat \napplications and across social media platforms. Where Twitter is proven to \nbe the platform most friendly to automation, the study finds \u2018cyber troop \nactivity on chat applications or other platforms (Instagram, LINE, SnapChat, \nTelegram, Tinder, WeChat, WhatsApp)\u2019 in one-quarter of the countries under \nstudy (Bradshaw and Howard, 2018: 13). In the European countries in their \nsample, they find distinct junk news footprints per country. In Germany, \nit is rather marginal and was mostly circulated by far-right political actors \nduring the 2017 federal elections. In Italy on the other hand, a large and \nactive \u2018ecosystem\u2019 of it is connected to political forces such as the Lega \nNord (Northern League) and the Movimento Cinque Stelle (M5S, 5 Stars \nMovement), which were at work during the 2017 constitutional referendum \nand the elections of 2018. Here, junk news connects national politics to \nEuroscepticism, conspiracy theory, aliens and pro-Putin propaganda. In \nthe Netherlands, the analysis finds that it revolves around politician Geert \nWilders and in particular the spread of his anti-Islam video, which was \nbroadcast on television and shared in social media in the lead-up to the \n2017 Dutch national elections. In particular, the study finds that automated \naccounts have amplified Geert Wilders\u2019 campaign hashtags.\nThese results match the findings in a study that looked at troll-like \nbehaviour on Twitter, leading up to the 2017 Dutch general elections, where \nsock puppets were found (Bounegru et al., 2018). The study collected over \n36 R icha Rd R oge R S  and Sabine ni ede ReR \n500,000 tweets mentioning at least one of the Twitter accounts of the 28 \npolitical leaders a month before the 2017 Dutch general elections. To retain \nthe users that demonstrated troll-like behaviour, it narrowed down the \nset to only the 25 users who consistently targeted one or more political \nrepresentative.3 The analysis showed that there was a notable asymmetry in \nthe distribution of targets of troll-like behaviour and sock puppetry across \nthe political spectrum, where left-wing politicians are most often targeted \nby negative mentions, while right-wing politicians receive support. Troll \ncontent extended to reputable news sources which cited it at least thirty \ntimes. Among the cited troll accounts were fake news organizations with \nnames as \u2018Today in Syria\u2019 and \u2018WorldNewsPolitics\u2019, political parties (including \nmultiple fake accounts for the Republican party in Tennessee) and concerned \ncitizens, most of whom were fiercely pro-Trump and anti-Islam (Kist and \nWassens, 2017). In another analysis by the NRC Handelsblad , a Dutch political \nparty (DENK) also exhibited troll-like behaviour, including sock puppetry \non both Twitter as well as Facebook (Kouwenhoven and Logtenberg, 2017).\nWhile Dutch news consumers have been found to use a variety of news \nsources, the Netherlands also has a steady \u2018pulp news\u2019 diet (Burger et al., \n2019; van der Poel, 2019). From 2013-2017 Dutch Facebook users consumed \nmore low-quality, commercially driven clickbait than mainstream news, \nas was found through engagement scores. As may be expected, there is also \nrelatively more clickbait on Facebook than quality news.\nThe consumption and forwarding of clickbait, extreme clickbait as well \nas other problematic information extends also to politicians and public \nfigures. One Dutch researcher, Peter Burger, has a collection of instances \nwhen Dutch politicians have retweeted anti-Semitic or otherwise disturbing \ncontent. In one example, a video purporting to show \u2018Muslims vandalizing \nChristmas market in Lithuania\u2019 was actually a recording of an event that \ntook place in the city of Baltimore in the US (Burger, 2016).\nRecognizing and countering disinformation in the Dutch online space\nVarious initiatives aim to detect and counter disinformation in the Neth -\nerlands and on an EU-level. The EU taskforce ( East Stratcom Task Force)  \nagainst disinformation was heavily criticized in the Netherlands after its \nproject EUvsDisInfo mistakenly categorized articles by The Post Online , \nGeenStijl  and De Gelderlander  as disinformation (van Keulen et al., 2018; \nHeck, 2018). (Figure\u00a01.1 shows a cartoon about the fake news taskforce, \n3 B y @mentioning them at least 100 times in a one-month period.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  37\nstating internet trolls are best countered with internet hobbits.) In a sense, \nthe dispute stemmed from misreadings of single stories, perhaps without \nan appreciation of how settled some of the sources are in the Dutch media \nlandscape, despite their tendentious style (in the case of The Post Online  \nand GeenStijl ). For its part, De Gelderlander  had taken over nearly verbatim \na Russian storyline concerning the perpetrator behind the downing of the \nMH17 but did attribute it to its original source in a barebones reporting style. \nThe flagged cases were removed from the EUvsDisInfo site after complaints \nby the Dutch media organization Persgroep (EUvsDisinfo, 2018).\nFact-checking as a journalistic practice has taken hold in the Nether -\nlands. Many newspapers have implemented (or revived) a fact-checking \nsection, often dedicated to checking statements made by political figures \nin interviews in newspapers or TV shows. There are also websites such as \nHoaxmelding.nl and Nieuwscheckers.nl that compile lists of instances of \nfalse news on Facebook and elsewhere. For their study of disinformation, \nRathenau researchers analyzed these lists, comprising respectively 140 on \nHoaxmelding (collected between 1\u00a0February\u00a02014 and 18\u00a0December\u00a02017) and \n166 on Nieuwscheckers (between 3\u00a0February\u00a02017 and 5\u00a0January\u00a02018) (van \nKeulen et al., 2018). They found that the items on the list of Hoaxmelding \ninvolved examples of unfounded warnings (65), polarizing disinformation \n(32) and fake crime news (31). Additionally, there were several examples \nof clickbait, benign as well as malicious. The content steers users to Figure\u00a01.1   C artoon that ridicules the fake news taskforce, stating: \u2018internet trolls \nare best countered by internet hobbits\u2019\nSource: Reid et al. (2018)\n38 R icha Rd R oge R S  and Sabine ni ede ReR \nadvertising, \u2018like-farming\u2019 and phishing sites (van Keulen et al., 2018: 38). \nSuch posts contain human interest stories that are \u2018painful on a personal \nlevel\u2019 (van Keulen et al., 2018: 45). The researchers found that only 25% of \nthe disinformation concerned political content and most clickbait serves a \ncommercial goal, rather than a political one. On the list of items collected by \nNieuwscheckers, the Leiden University-based initiative, less than half was \nfound to have political content. Within the full set, the researchers found \nsix examples of polarizing content. Otherwise, many of the posts concern \nfactually incorrect, public statements by politicians, the investigation of \nwhich is how fact-checking is conventionally practiced.\nFact-checking now extends well beyond unpacking politicians\u2019 statements, \nand Facebook has entered into partnerships with many bureaus around \nthe world, including in the Netherlands, to explore and catalogue dubious content. In 2017 Nieuwscheckers partnered with Facebook and NU.nl and \ncelebrated their first collaborative, \u2018successful detection and elimination \nof fake news\u2019 that year when they flagged a tabloid-style, human-interest \npost about an Australian new-born weighing 20 kilograms (see Figure\u00a01.2). \nIn February of 2019, however, Nieuwscheckers withdrew from the Facebook \nfact-checking initiative because of liability risks (Kist, 2019). Nu.nl continued \nto work with Facebook on fact-checking, on a paid basis, an issue raised Figure\u00a01.2   \u2018Det ected and eliminated\u2019 fake news, with a warning issued by NU.nl \nand Nieuwscheckers\nSource: noS ( 2017a)\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  39\nrepeatedly in the context of journalists\u2019 being asked to address an issue of \nFacebook\u2019s making on a voluntary basis.\nThe effectiveness of fact-checking as a strategy in the Netherlands is a \ndifferent question. As mentioned above, fact-checks and fake news often \nhave separate publics, and fact-checks may lead people to fake news, rather \nthan away from it. A recent study in the Netherlands found that even when \nmany people would agree with a fact-check, they are not interested in reading \nthe fact-checking article, prompting the scholars to advise journalists to \nmake the fact checks an engaging read (Hameleers and van der Meer, 2019). \nAnother strategy to counter disinformation concerns a strand of media \nliteracy that involves developing skills to recognize fake user accounts and \ndisinformation. One is on a source level, the other on a story level. The Field \nGuide to Fake News provides a method for the detection of trolling accounts \nby looking at their friends, or their profile information (Bounegru et al., 2018). \nThere are also courses and training modules for fake news detection and \nfact-checking, such as those given by Radio Netherlands (RNTC, 2019). The \nother format is the fake news quiz, such as those by de Volkskrant  (2016) and \nthe Guardian  (2016), as well as the New York Times \u2018deceptive Facebook post\u2019 \ntest (2018). These quizzes make it clear how challenging it is to recognize \nfake news. The Dutch serious game, titled Slecht Nieuws (\u2018Bad News\u2019), invites \nplayers to create fake news and by doing so gain insight into the strategies \nbehind it and become more astute in its recognition (NRC, 2018; DROG, \n2018). It is part of efforts that study false news as risk and ultimately seek \nto inoculate populations against it (Roozenbeek and van der Linden, 2018).\nVoting aid applications\nVoting aid applications (VAAs), often called stemwijzers  in Dutch, are \ngenerally websites that describe their purpose as helping undecided voters \nfind the political party that best matches their preferences and positions. \nAs such, in the context of the study of disinformation and so-called fake \nnews, they could be regarded as a competing persuasion instrument, a \npre-emptive measure against influence campaigning, or even a potential \nsite that may include it, either through parody, hoax or hack. The literature \non VAAs takes up the Dutch and Belgian cases, countries that together with \nGermany, Austria and Switzerland have upwards of half the voter population \naccessing them prior to elections. The work can be positioned broadly as \npertaining to \u2018the impact of internet-based applications on politics\u2019 and can \nbe roughly divided into user studies, impacts of VAAs on the voters as well \nas the methods behind them (Hirzalla and van Zoonen, 2015: 88). To date \n40 R icha Rd R oge R S  and Sabine ni ede ReR \nthese online voting aids have not been raised as recommended technology \nto combat disinformation and influence campaigning per se, though they do \nfurnish a rather personalised information experience that may be studied \nfor its \u2018influence\u2019 effects, as discussed briefly below.\nIn studies of their usage, researchers have asked whether VAAs \u2018mobilize \nthe mobilized\u2019 (Hirzalla and van Zoonen, 2015). And indeed, while VAAs \nhave a heterogenous user base across demographics, interests, attitudes and \nbehaviour (Vassil, 2011), there is an overrepresented subgroup of younger, \nmainly left-of-centre, urban and well-educated male users who are politically \nactive or knowledgeable. This imbalance could lead to the conclusion that \nthose who may benefit from political advice are not seeking it (Ruusuvirta, \n2010).\nA second set of literature concerns the impact of VAAs and assesses \nwhether they have influenced the voting behaviour of its users, though it \nis not clear whether the quality, reach and graphical interfaces of the aids affected the extent of the influence. From those surveyed anywhere from \n1% to 15% using DoeDeStemTest (in Belgium) as well as StemWijzer and \nKieskompas (in the Netherlands) reported having been influenced by the \naids (Walgrave et al., 2009; Hirzalla and van Zoonen, 2015). While research \nhas found that the politically knowledgeable and engaged users that are \ncommon to use VAAs perceive them as useful, they are also among the \nless likely users to be influenced by them (Alvarez et al., 2014; Dumont \nand Kies, 2012).\nA third set of literature concerns the methods used by the VAAs. Here \nthere is a distinction between the choice of the policy positions to include \nin the interactive system and the models underlying the advice. The very \nselection of the policy positions is a crucial factor in the voting advice \ngiven, where another set would lead to other advice (Walgrave et al, 2009). \nIn general, VAAs are found to select policy positions according to their \nsaliency (for the election period), and variability (in that different parties \nhold different positions) (Hirzalla and van Zoonen, 2015). The editorial \nprocess differs, where certain VAAs select their statements solely with \nexperts such as political scientists or journalists (e.g., the Austrian VAA \nwahlkabine.at), while others co-create the formulation of VAA positions, \nworkshopping them with party representatives in the case of the Dutch \nStemWijzer, or with an editorial board that consists of professional experts \nas well as first and second-time voters in the German \u2018Wahl-O-Mat\u2019 (Garzia \nand Marshall, 2017).\nAs the voters register their political views, and in certain cases add weight \nto them, the software calculates the extent to which the voters\u2019 preferences \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  41\nmatch the respective parties\u2019 and presents its results as a ranked list, bar \nchart, grid or radar chart. Several studies concentrate on the workings and \nvisual outputs of the different voting aids. Louwerse and Rosema (2014) \ndissect them by examining how many dimensions are taken into account \nwhen ranking the political parties. In their study, a one-dimensional model \nrefers to the ranking the political parties based on the level of agreement \nwith the voter and presents its findings as a ranked list or bar chart. A two-\ndimensional model places the political parties\u2019 statements and the voters\u2019 \nresponses on a continuum from left-wing to right-wing and proposes its \nmatch accordingly. The more elaborate multi-dimensional model, employed \nby the Swiss smartvote application, plots the statements and responses \nonto eight policy dimensions and presents its results in a spider plot that is \nmore complex to read (Louwerse and Rosema, 2014). In a comparative test \nof these models, researchers took a dataset from the Dutch Stemwijzer and \nfound that the different spatial models would lead to very different matches \n(Louwerse and Rosema, 2014).\nAs mentioned above, the voting aids are rather popular in a series of \nEuropean countries and could be considered not only as another information \ninput but also as one that competes with campaigning. Though the influence \n(similar to campaigning) may again be minimal, it could be considered as \nanother approach or countermeasure in the discussion of how to address \nthe disinformation problem.\nJunk news may be pervasive, but is it persuasive?\nIf one were to divide the current period of junk news studies into waves, it \ncould be argued that the first related to the definitional issues and the pro -\nduction side (as mainly discussed above), whilst the second is increasingly \nconcerned with the study of its consumption (Boczkowski, 2016). In other \nwords, junk news may be seen as \u2018pervasive, but is it persuasive?\u2019 (Shaw, \n1979). Why do people consume it, and do these readers have particular \ndemographics or profiles? Which people deem these stories credible or \nat least have pass-along value? Are they persuaded or even persuadable? \nIn the US and in a growing list of other countries social media platforms \nare increasingly a main source of news, and the manner in which they \ndeliver news is different from a newspaper or similar package or container \n(Gottfried and Shearer, 2016; Poynter, 2019). One receives single stories, \nrather than an entire newspaper, each shared by someone with whom the \nsocial media user has made a connection, most often directly. These can \n42 R icha Rd R oge R S  and Sabine ni ede ReR \nbe friends (Facebook), followers (Twitter), connections (LinkedIn), etc. \nStories arrive in the feeds algorithmically, meaning there is a filtering \nmechanism where certain of them are boosted, based on signals such as \nactivity and increasingly trustworthiness, or the amount of given and \nmeasured meaningful engagement between individuals. Put differently, \nthose who are close to the user (by some special measure) are the ones \nwhose stories more likely will be seen (Eslami et al., 2015). Such observations \nhave led to discussions of the re-application of the notion of the filter \nbubble, a term originally associated with a user receiving personalised \n(rather than universal) search engine results (Pariser, 2011; van Keulen et \nal., 2018; Puschmann, 2018). Personalisation, however, has evolved from \nbeing the result of the information interactions of one user searching to \nengagement with an entire social network. As such it shifts the bubble \nfrom enveloping the individual to the group; it has prompted \u2018bubble \nstudies\u2019 of not just social media news environments, but those of health, \nscience, fashion and other areas of collective information production, \nsharing and recommendation (Pedersen and Hendricks, 2014; Hendricks \nand Vestergaard, 2019). Indeed, junk news circulation and consumption \nare increasingly experienced as an issue for the environment (e.g., climate \nchange and its sceptics), health (e.g., the anti-vaccination discourse) and \na variety of other areas (Kitta, 2018).\nSuch findings have led researchers to define on the one hand the groups \nmost likely to consume and share the news together with the dynamics \nof their bubbles, and on the other the meaning, or sincerity, attached to \nthe sharing. In terms of the consumption of junk news, it could be said \nat the outset that there have been two widely cited findings about their \nsignificance from the journalistic arena. One found the most shared stories \nduring the US presidential elections were \u2018fake news\u2019 (see Figure\u00a01.3), and the \nother that Russian disinformation campaigns had a far greater spread than \npreviously imagined as well as reported in testimony by Facebook before the \nUS Congress (Silverman, 2016; Timberg, 2017). These findings have since been \nput into a broader context and compared to \u2018normal\u2019 political campaigning \nand the development of messaging strategies, filtered through news. First, \nin the event, only a small fraction of the population consumed such \u2018news\u2019 \n(Allcott and Gentzkow, 2017). Given the limited exposure, the impact, if at \nall, would have paled in comparison to political TV commercials (Persily, \n2017). There is the larger question, however, of whether the messaging would \nhave anything but \u2018minimal effects\u2019 (Lazarsfeld et al., 1948). As has been \nrepeatedly found, the net effect of campaigning, albeit by political elites, \nthat persuades the prospective voter is exceedingly low or even zero (Kalla \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  43\nand Broockman, 2017). The aim then is less to persuade than to \u2018rous[e] the \nenthusiasm of existing supporters\u2019 (Panagopoulos, 2016).\nThough they may have begun as symmetrical studies of the right and \nthe left, of the most circulated findings to date about the spread of junk \nnews \u2013 both with respect to the contents as well as its consumers \u2013 ultimately \nall have overwhelmingly concentrated on the right, be it conservatives \nand the alt right in the US or other right-leaning, populist radical right or \nnew right publics in Europe (Bounegru et al., 2018; Benkler et al., 2018). \nIt is of interest to note for starters that both during the US presidential \ncampaigning and thereafter the information spaces or spheres of the right \ncontained far more fake, junk, disinformation or otherwise dubious stories \nand sources than the left (Faris et al., 2017). Thus, conclusions drawn about \nright-leaning publics sharing information should take into account that they \nare disproportionately exposed to such information; all else being equal, the \nright would share more of it (Marwick, 2018). In the empirical studies it was \nfound that the right (most notably Trump supporters) consumed the most \nso-called fake news. However, there seems to be an older, hard core of its \nconsumers in the US during the run-up to the US presidential elections in Figure\u00a01.3   T he birth of the fake news crisis, or \u2018fake news\u2019 outperforms \u2018mainstream \nnews\u2019 on Facebook, in the run-up to the U.S. elections in 2016\nSource: Silverman (2016)\n44 R icha Rd R oge R S  and Sabine ni ede ReR \n2016 \u2013 \u2018the 10% of Americans with the most conservative information diets\u2019 \n(Guess et al., 2018: 11). These are heavy media users, and \u2018available audiences\u2019, \nwho have made time to consume media (Nelson and Taneja, 2018). Unlike \nthe majority of the media-consuming public, they are far more likely to read \nniche rather than only establishment sources. There is, in other words, a \nnormalcy to the consumption by those audiences of fringe materials.\nThe strand of work that considers why users share \u2018fake news\u2019 should be \nprefaced by the distinction between \u2018earnest and ambivalent\u2019 internet users \n(Hedrick et al., 2018). Much of the scholarship about internet culture has not \nconsidered that considerable cultural production and sharing are undertaken \nnot to be part of participatory culture, connective action and other earnest \nforms of civic culture online but rather for unsympathetic amusement (aka \n\u2018lulz\u2019) (Phillips, 2015). \u2018Sharing\u2019, a term that has mutated in digital culture \nfrom acting in a gift economy to a dominant form of so-called platform \ncapitalism, could have been prompted these days as much by insincerity \nas by mindfulness (Barbrook, 1998; Belk, 2007; Srnicek, 2017). That is, the \nrationale for making and sharing could \u2018go either way [\u2026] complicating an \neasy assessment of authorial intent\u2019 (Phillips and Milner, 2018: 10-11). Such a tricky attribution of intent is especially troublesome in the spaces where vitriolic exchange as well as extreme speech and content are prevalent. It \nis difficult to disentangle whether one is sharing for amusement and to \ntrigger a reaction, or for substantive reasons.\nAs has been found in the US context, the problematic news stories most \nshared on social media resonate with particular grievances (about the bias of \nestablishment sources) and resentments (concerning economic opportunity) \nthat underlie certain societal divides (Marwick, 2018). Moreover, the stories \ndo not stand alone in a mirror world of conspiracy theory but rather are \ncontiguous with more mainstream conservative news, anchored by Fox \nNews; they are more extreme as well as transgressive in their wording and \npresentation. Hence the notion of \u2018hyperpartisan\u2019, but there is also reference \nmade to tendentious, anti-establishment sources. Here the Overton Window \nis appropriately referenced, meaning the bounds of current, acceptable public \ndiscourse, and the extent to which extreme speech in hyperpartisan and \ntendentious sources is moving established norms (Daniels, 2018).\nJunk news studies: Digital methods and data journalism\nAs we come to shortly, one research strategy for measuring the prevalence \nof problematic news story types and sources around national elections \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  45\nis to gauge their presence generally in scoping exercises, but also more \nspecifically in the most engaged-with content in social media concerning \nelections, political parties, candidates and social issues. A more subtle \nanalysis would examine the top stories for the penetration of problematic \nnews narratives, measuring mainstreaming. Moreover, through comparison \nof engagement with such news, one also could determine which platforms \nare most susceptible (or amenable) to hosting and circulating such content. \nFacebook in particular has been held up as a \u2018hyperpartisan media machine\u2019 \n(Herrman, 2016). Empirically, it has been found to host (proportionately) \nmore of it, whether narrowly or liberally defined, than other platforms \n(Guess et al., 2018).\nIn order to contextualize such measures, it is worthwhile to consider the \nways in which the scale, reach and impact of such news have been studied \nto date with media analysis, or more specifically digital methods and data \njournalism. The methods generally could be considered mixed quantitative/\nqualitative approaches. They often begin in the journalistic arena, with \nthe qualitative determination of the dubiousness of a set of sources and/or \nstories and proceed with digital methods that design queries and collect \ndata from platform APIs, media monitoring company dashboards, and \nsocial media companies that have furnished lists of banned trolls or user \naccounts. Indeed, with respect to the dubious source lists, Buzzfeed News\u2019 \noriginal list of about 20 sources determined to be \u2018fake news\u2019 inform a \nseries of empirical studies (Silverman, 2016; Allcott and Gentzkow, 2017; \nBounegru et al., 2018; Marwick, 2018; Grinberg et al., 2019). For studies of \nthe Italian news space, the lists relied upon are from BUTAC, Bufale and \nBufalopedia (Fletcher et al., 2018; Butac, 2018). Hoaxwijzer\u2019s list of 92 Dutch-\nlanguage \u2018false news\u2019 sites also informs certain of the empirical studies to \ndate in the Netherlands (van Keulen et al., 2018; Wieringa, 2017).4 But other \nwork, such as the NRC Handelblad \u2019s analysis of the extent of the problem of \n\u2018fake news\u2019 in the Netherlands in the run-up to the 2017 national elections, \nlooks at the sources afresh, making on-the-spot determinations of fakeness \n(Kist and Zantingh, 2017). These may conflict with previous listings. For \nexample, Hoaxwijzer lists De Dagelijkse Standaard as a \u2018false news\u2019 site \nwhereas the NRC Handelsblad  did not determine it to be \u2018fake news\u2019, but \nit fell among those they called \u2018misleading\u2019 because it reported that \u20181,000 \ncrazy Muslims\u2019 had \u2018torched\u2019 a church in Dortmund on New Year\u2019s Eve when \ninstead a firework had landed on its roof causing light damage. The NRC \n4 A s other studies also found, the list is dated; as of April\u00a02019, 40 of the 92 sites are offline. \nIt remains useful as a list for older media corpora.\n46 R icha Rd R oge R S  and Sabine ni ede ReR \nHandelsblad  determined that it did not meet its definition of fake news as \na \u2018fully fabricated story packaged as news\u2019.\nIndeed, the question of detecting fabricated news, on a source or story \nlevel, is often placed at the feet of journalists, media organizations and \nfact-checking bureaus, where credibility and transparency may be rated \n(NewsGuard, 2019). Masked sources are penalised, for example. As mentioned \nabove, for online stories, the determination of dubious content may benefit, \ntoo, from a genre analysis (Lu\u0308ders et al., 2010). Disinformation, conspiracy, \nclickbait and (automated) amplification have styles (Rony et al., 2017). \nDisinformation tends to be a hard counterfactual presentation, conspiracy \nhas multiple characters and plot entanglements, clickbait is a cliff-hanger \nthat is often painful on a personal level and (automated) amplification \nposts at particular intervals and in coordination, as malicious social bot \ndetection projects have found (Ratkiewicz et al., 2011; Bessi and Ferrara, \n2016; RoBhat labs, 2017). Other technical signatures of dubious news sites \nare of interest. For instance, empirical work on the types of cookies and \nthird-party elements in mainstream and nominally fake news sites found \ndistinctive types in each, with the mainstream sites using customised \ntrackers and the other off-the-shelf (Bounegru et al., 2018).\nWith the lists of fake news sources either in place or determinations still \nto be made, the next step is to build a media corpus. Following Buzzfeed \nNews \u2019 method, many undertakings query media monitoring services (such \nas Buzzsumo and Facebook\u2019s Crowdtangle) for political and issue-related \nkeywords, in order to build source sets of most engaged-with media and \npull in engagement scores per story. Certain of the techniques also include \nfurther interpretative coding of stories, including grievance narratives \n(Marwick, 2018).\nWhilst much attention has been directed towards Facebook, and the \nstudy of the election-related stories most engaged with on that platform, \nTwitter is often used as the preferred data source, given dedicated data \nsets (made available by Twitter or academic researchers) of accounts run \nby the Internet Research Agency (Farkas and Bastos, 2018). There is a series \nof studies that rely on Twitter\u2019s curated sets as well as on the data robustly \ncollected and shared among data researchers, such as by Clemson University \nand FiveThirtyEight, mentioned above. In a form of crowd science, the \npublication on GitHub of the Clemson data set led to numerous studies; in \nthe US widespread disinformation campaigning was found, as is known, \nbut also more niche-targeting of politicians in such states as Maine (Roeder, \n2018). As in the Netherlands, discussed above, the data were put to use in \nother countries that according to journalistic accounts had been previously \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  47\nunderstudied. For example, in Italy IRA trolls posted numerous pro-populist \nparty tweets in Italian, joining the \u2018cacophony\u2019 or media ecology around the \npopulist right, as discussed in the Oxford Internet Institute work (Fubini, \n2018; Fletcher et al., 2018). Twitter is also preferred given the general ease of \nuse of data collection through its streaming and search APIs, intermediate \nservices such as Hexagon Crimson for samples as well as the availability of \nhistorical data sets, albeit at a price.\nOther approaches (considering consumption and persuasion rather than \ndefinition and production) should be touched on that rely on surveys, \nuser data collection and experiments. Numerous experiments have been \nperformed on misinformation (Jankowski, 2018). For example, a repre -\nsentative sample of the population consents to having their online media \nconsumption passively monitored, and subsequently surveyed thereafter \n(Guess et al., 2018). Or, there are experiments that show fabricated news \nto consumers, and subsequently provide fact-checks to them in order to \ndetermine whether the fact-checks should be \u2018attitudinally congruent\u2019 for \nthem to be persuasive (Hameleers and van der Meer, 2019). In another experi -\nment in the Netherlands, commissioned by the newspaper, de Volkskrant , \nrespondents were presented with fabricated news around one of four topics: \nvaccinations and autism, MH17, rape incidents in connection to migration, \nor Sylvana Simons (a politician and media personality) and discrimination. \nThe study tests whether they became less certain about the facts after being \nmisinformed (I&O Research, 2017; Kranenberg, 2017).\nWith respect to platforms other than Facebook and Twitter, YouTube and \nespecially Instagram appear to be relatively understudied but significant, \nand Reddit and 4chan are being recognized as breeding grounds for some of the more outlandish and consequential content such as Pizzagate (New \nKnowledge, 2018; Tuters et al., 2018). There are platform-specific approaches \nfor building and analysing datasets for Instagram (through queries for \nhashtags and place names), as well as YouTube, Reddit and 4chan (Rogers, \n2018b; Rieder et al., 2018). Google web search also has invited scrutiny, given \nthe extreme content returned for queries such as the Holocaust.\nBuzzfeed News \u2019 work on detecting and analysing \u2018fake news\u2019 on Facebook \nhas been particularly influential in data journalism research and subsequent \nstudies that build upon it, and thus is worthy of mention in some detail \n(Silverman, 2016). First, the researchers built a keyword list concerning elec -\ntions (and especially controversial election topics), and subsequently queried \nthose keywords in media monitoring software (Buzzsumo) that returns \nstories ranked by engagement scores. With the aid of the results, they built a fake news and hyperpartisan website list, which they merged with lists of \n48 R icha Rd R oge R S  and Sabine ni ede ReR \nthe same that they curated previously through separate reporting, including \non the infamous collection of about 100 websites created by the Macedonian \nclickbait makers, members of the same family of sites (with the same Google \nAnalytics ID) of WTOE 5 News that created the story about the Pope endorsing \nTrump, and a collection of hyperpartisan sites (Silverman and Singer-Vine, \n2016; Silverman et al., 2016). They also curated a list of some 20\u00a0mainstream \nnews sites.5 (All the accompanying data Buzzfeed also made available through \nonline Google spreadsheets, in keeping with emerging standards in data \njournalism.) The engagement scores of the top mainstream news and top \nfake news stories are subsequently compared. In the first study of this kind and perhaps the beginning of what could be called the \u2018fake news crisis\u2019 for Facebook, it was found that the fake news stories outperformed by engage -\nment scores those from the mainstream news in the three-month period \nbefore the US presidential elections, thereby leading to conclusions about \nthe comparable \u2018power of fake election news on Facebook\u2019 (see Figure\u00a01.3) \n(Silverman, 2016). Follow-up reporting has considered the extent to which \nsuch news continues to resonate more on Facebook than mainstream news \nstories, despite incipient efforts by the company to curtail its impact. One of \nthe major studies commissioned by the US Congress found that such news \nand influence campaigning activity on Facebook and especially Instagram substantially increased after the US elections (Howard et al., 2018).\nIn April of 2019, some two and one-half years after Buzzfeed News  story, \nwe found that only 4 of the 13 top-performing \u2018fake news\u2019 and hyperpartisan \nwebsites are still online: World News Daily Report, Burrard Street Journal, \nTwitchy and Breitbart. The others appeared to have been fly-by-night opera -\ntions, which is another means of considering a source\u2019s dubiousness. That is, \nthe other 9 sites, including two Macedonian-made ones (Denver Guardian \nand World Politicus) and the highest-performing site (Ending the Fed) that \nspread the \u2018Pope endorses Trump\u2019 story are gone.\nFacebook\u2019s adjustments\nAfter the US elections in 2016, Facebook CEO Mark Zuckerberg initially \nargued that \u2018the idea that fake news on Facebook influenced the election in \n5 B uzzfeed\u2019s list contains the following mainstream sources: New York Times, Washington \nPost, NBC News, USA Today, Politico, CNN, Wall Street Journal, CBS News, ABC News, New York \nDaily News, New York Post, BuzzFeed, Los Angeles Times, NPR, The Guardian, Vox, Business \nInsider, Huffington Post and Fox News (Silverman, 2016).\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  49\nany way, I think is a pretty crazy idea,\u2019 and put forward that such material \namounted to a small fraction of its platform\u2019s content (Isaac, 2016). Two years \nlater Facebook\u2019s work to quell fake news, together with its more stringent \npolicies on (research) data access should be considered here. Addressing \nthe fake news crisis, there has been an increase in those hired to perform \n\u2018content moderation\u2019, referred to as the janitors of social media, or even those \ndoing the platform\u2019s dirty work (Roberts, 2017). Facebook also installed a \npolitical ad transparency tool; it lists on the ad itself who has sponsored \nit, and there also is a political ad archive and an API (Hern and Waterson, \n2018). No longer is the maker and targeted individual the only ones able to view the hitherto \u2018dark post\u2019.\nWith respect to algorithmic changes, in 2018 Facebook began a three-\npronged strategy that would favour \u2018meaningful connections\u2019 (family and \nfriends), \u2018trusted sources\u2019 (user-surveyed media) and \u2018local news\u2019 in the news \nfeed over more far-flung \u2018businesses, brands, and media\u2019 (Abbruzzese, 2018; \nFlynn, 2018; Gartenberg, 2018). It should be remarked that these are global \ninitiatives, coming on the heels of well-reported Facebook-associated riots \nin Myanmar and Sri Lanka but also the compilation of compendiums on \nthe effects of \u2018fake news\u2019 on Facebook all over the world, as the OII\u2019s global \nstudy have shown, but also the numerous governmental and think tank \n(umbrella) initiatives such as disinfoportal.org.\nWhether Facebook\u2019s measures are working in some sense is unclear. The \npolitical ad library tool may show a source, but who is behind it may remain \nunclear as in the case of a pro-Brexit campaign group, Britain\u2019s Future (see \nFigure\u00a01.4), that spent hundreds of thousands of pounds on ads in the run-up \nto significant UK parliamentary votes (Waterson and Hern, 2019). Efforts \nby journalists to unmask the source behind Britain\u2019s Future as well as other \n\u2018dark money\u2019 campaigners had for months been in vain (Monbiot, 2019). \nSignificant political ads are also not in the archive, as ProPublica found, \nbefore its tool crowdsourcing Facebook ads and targeted individuals was \npurposively rendered inoperable by the company in what it called a \u2018routine \nupdate\u2019 that would prevent illegitimate \u2018scraping\u2019 (Merrill and Tobin, 2019). \nSimilar tools by Mozilla and Who Targets Me also broke, thus making the verification work a difficult prospect.\nThe news feed tweak to boost \u2018meaningful connections\u2019 was initially \ncritiqued for its capacity to exaggerate the importance of \u2018fake news\u2019, as \nwas observed in Slovakia and elsewhere when dubious sources saw their \nengagement scores rise (Frenkel et al., 2018). The prominence of \u2018meaningful \nconnections\u2019 and \u2018local news\u2019 in the news feed, according to Buzzfeed, stirred \nas well as amplified the Gilets Jaunes protests in France, for their coverage \n50 R icha Rd R oge R S  and Sabine ni ede ReR \non the local news made the anger groups (groupes col\u00e8re) and their posts \nmore prominent in the news feeds, as evidenced by engagement scores from \nCrowdtangle (Broderick and Darmanin, 2018).\nGiven the fake news crisis stemmed from the US elections, Facebook \nalso created specific initiatives for future elections that would put political \nparties and their positions on issues in a single, curated Facebook portal. \nOne of the early projects was for Sweden\u2019s national elections in 2018, which, \nit was found in a separate study (with Twitter data), suffered from \u2018junk news\u2019 \nquantities second in magnitude only to that surrounding the US elections, \nand much larger in fact than such materials around the German, French \nand Dutch elections in 2017 (Hedman et al., 2018; Kist and Zantingh, 2017). \nThe Facebook elections project, rolled out in meetings with social media \nresearchers in 2018, also coincided with their new academic \u2018partnership\u2019 \nproject, Social Science One. It seeks to make available to researchers data sets \nsuch as all the URLs that have been posted to Facebook over the course of a \nyear (King and Persily, 2018). At the same time, however, Facebook revoked \napproval for research software (such as Netvizz and Netlytic) that made use \nof its Pages API, sparking academic protest about \u2018locked platforms\u2019 (Bruns \net al., 2018; Rieder, 2018). Seen as reactions to the Cambridge Analytica \nscandal, Facebook\u2019s measures could be described as curating the datasets \nresearchers can use. The new datasets (that would be available in the Social \nScience One initiative) notably do not include Facebook pages themselves \nand their engagement scores \u2013 data that led to the very knowledge about \nthe fake news crisis and the scope of the Russian influence campaign in \nthe first instance (Albright, 2017).Figure\u00a01.4   F acebook political ad library tool, results for Britain\u2019s Future, \n13\u00a0March\u00a02019\n\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  51\nConclusions: Fakery and campaigning\nThe \u2018fake news\u2019 phenomenon could be viewed as a revival of previous ones \nthat typically have occurred when a new media technology is introduced that \ndestabilises production, distribution and consumption of news and informa -\ntion, as was the case with eighteenth and nineteenth century broadsheets \nand tabloids (respectively) but also the radio and newswire of the twentieth \ncentury. The early web and the blogosphere also challenged existing news \npublication practices and were considered unedited spaces populated by \nself-styled authors, providing speedy news \u2018too fresh to be true\u2019. Now social \nmedia platforms disrupt the trustworthiness of established news and fact \nand reintroduce the idea of the web as \u2018truthless medium\u2019 (Marres, 2018).\nThe post-truth age, or condition, as it were, may be viewed in light of a \nconflict between what counts as \u2018fake\u2019 (on a source or a story level), but it has \nbeen described rather as a contest between facticity regimes, or even sets \nof sectarian expertise. Locating a network of so-called \u2018fake news\u2019 websites, \nfor example, could be viewed as the discovery of an influence campaign, \nbut it just as well can be seen as an \u2018alternative facts\u2019 media ecology. When \nit is a hyperpartisan, right-wing news ecology, as in the US in the run-up \nto the presidential elections of 2016, it could be described as a part of the \ncontemporary post-truth situation, or, as been often related, a culture war.\nHaving the \u2018trappings of news\u2019 in terms of look and feel, \u2018fake news\u2019 has \nbeen defined as consisting of distinctive types with varying intentionality. \nFor instance, disinformation and mal-information (the neologism) are meant \nto harm, whereas misinformation may be just as false but its circulation \nunintentional. As a case in point, satirical stories and parody may become \nmisinformation, such as the story about the Pope endorsing Trump, which \noutperformed (by engagement score) any other \u2018news\u2019 on Facebook during \nthe US presidential election campaigning in 2016.\nIn both the public as well as scholarly discourses, there has been a swing \nfrom the hype of the \u2018fake news\u2019 problem (perhaps well exemplified by the \nDutch tabloid headline \u2018landslide of fake news\u2019) to its gradual debunking, \ne.g., \u2018researchers say fears about \u201cfake news\u201d are exaggerated\u2019 (Ingram, 2019). \nSuch a view has resulted from a series of studies not just on engagement but \nalso on its consumption, including the rationale behind its sharing. Small, \nolder populations appear particularly active, as do \u2018heavy news consumers\u2019 \nand \u2018available audiences\u2019, or those who have at their disposal time for fringe \nnews consumption and spreading it among online friends. The vast majority \nof news consumption remains of the mainstream sources, however. The \nevidence that consumers have been influenced or persuaded is minimal.\n52 R icha Rd R oge R S  and Sabine ni ede ReR \nNevertheless, there appears to be agreement that social media platforms \nremain worthy of study not only as the new \u2018truthless medium\u2019 but for their \ncapacity to accelerate (or \u2018supercharge\u2019) \u2018fake news\u2019 distribution in a hybrid \nmedia system comprised of new and established media and media formats. \nDespite increased content moderation, automated detection work, and a \nreorientation of its news feed principles, does Facebook remain a \u2018fake news\u2019 \nmachine, comparable to the one during the US presidential campaigning? \nIndeed, Facebook, at first hesitant to admit an issue, has taken a series of \nmeasures since then that strive to produce more trustworthiness, such as \nboosting posts by friends and family, crowdsourcing trusted sources as well \nas favouring local news, though the effectiveness of these reengineered \nprinciples has been questioned. Indeed, continuing empirical research on \nthe most engaged-with, political news on Facebook could shed light on the \nquality of the platform\u2019s content delivery, however much data access may be \nrestricted to researchers. It remains to be seen how \u2018oversight\u2019 research will \nbe affected now that Facebook has closed research APIs and instead plans \nto curate data sets for researchers, rather than allowing them to create their \nown. Other oversight projects have been thwarted; in early 2019 Facebook\u2019s \n\u2018routine update\u2019 blocked the software by ProPublica, Mozilla and Who \nTargets Me that was collecting political ads and their targets, as mentioned.\nThe question of \u2018fake news\u2019 as a campaign strategy \u2013 be it by Russian \noperatives, Russified domestic actors, hyperpartisan media-makers, and \nothers \u2013 also has been meticulously studied, with detailed \u2018playbooks\u2019 \nlaid bare as tactics to create both a media mirage (where fact and fiction \nare difficult to disentangle) as well as competing truth regimes, offering \ncounter-expertise as well as uncertainty. Governments around the world \nhave commissioned studies, revealing the breadth and scope of the problem, \nexplaining the playbook and putting forward policy recommendations \nsuch as increased media literacy and the regulation of political advertising \non platforms, including \u2018dark\u2019 posts. Platforms are asked to create public \narchives, which also would benefit research as well as (data) journalism. \nFact-checking also has gone global, though it often remains a small-scale \nenterprise practiced by bespoke bureaus, occasionally working in tandem \nwith Facebook, checking posts that have been flagged by users, and weighing \nin on the question of fakery.\nFinally, there are scholars in the US and recently in Europe putting \nforward the argument that studying Russian disinformation shifts the \nattention away from the home-grown hyperpartisan news ecologies that \nhave been emerging over the past few years, particularly on the right \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  53\n(Benkler et al., 2017; Benkler et al., 2018; Rone, 2019). The point also fits \nwith the \u2018dark globalization\u2019 argument concerning how existing domestic \ndivisions, displayed in this media, may be exacerbated by foreign operatives \nbut are not created by them. To date the effectiveness of Russian influence \ncampaigning in Europe, in either sowing or exacerbating division, has yet \nto be compellingly demonstrated; the false and junk domestic news sources \n(e.g., the pro-Russian sources re-narrating the cause of the downing of \nMH17) also appear to have scant reach (Fletcher et al., 2018). In a climate of \nheightened sensitivity towards dubious sources and stories, it remains to \nbe seen whether they have staying power.\n* * *\nAppendix: Governmental efforts and discussions of \ncountermeasures\nA first step for many national governments and other regional political \nentities that wish to counter disinformation is to install committees as well \nas task forces; it occurs across the globe, from the much publicised hearings \nby the US Congress and UK Parliament on the Russian involvement in the \nUS elections and the Cambridge Analytica affair, to the task forces and \nother entities formed in many of the nearly 50 countries where influence \ncampaigning has taken place (Bradshaw and Howard, 2018). Following from \nthese convenings, there have been national calls to regulate the \u2018digital \ngiants\u2019, and the European Union, through its creation of a High-Level Expert \nGroup (EU HLEG) on fake news and online disinformation, has issued \nits recommendations for countering disinformation, including calls for \ntransparency, media and information literacy, and tools for empowering \njournalism. In the European countries with recent or imminent national \nelections there has been even greater urgency, with Germany and France \nenacting legislation (online hate speech and \u2018fake news laws\u2019, respectively), \nand Sweden and Denmark engaging in awareness-raising as well as media \nliteracy campaigns. Denmark installed a \u2018digital ambassador\u2019 (Gramer, \n2017).\nBelow is a list of certain measures to counteract disinformation and fake \nnews, gleaned from governmental documents and related materials. They \ninclude social media company regulation, codes of ethics, fact-checking \nand media literacy campaigning.\n54 R icha Rd R oge R S  and Sabine ni ede ReR \nSocial media company regulation\nMany government committees agree that the large tech companies that have \ncome to dominate the online realm, such as Google, Twitter, and Facebook, \nshould be regulated, but caution over-regulation in forms that would curtail \nexpression and press freedoms. The starting point for the regulation of these \ncompanies to counter disinformation is to address political advertising \non social media platforms. It can include the verification of those paying \nfor political advertisements and disclosing them publicly. Additionally, \nall social media companies could be required to create public archives of \nadvertisements so that among other ad types \u2018dark posts\u2019 may be studied \n(Bradshaw, 2018). In fact, as said, Facebook has such an archive (and an \nAPI), but it also prevented watchdogs including Mozilla from verifying \nits collection techniques, equating their methods with illegitimate data \n\u2018scraping\u2019 (Merrill and Tobin, 2019).\nRelatedly, the EU HLEG proposes the development of a \u2018European-wide \ncode of practices\u2019 that describes the roles and responsibilities of relevant \nstakeholders such as tech companies, and media organizations but also \nresearch organizations and fact-checking initiatives, based on key principles \n(2018). In short, they address the adaptation of political advertising policies \n(including sponsored advertisements and other forms of content), and \nthe provision of access to data for research and fact-checking. They also \npropose the installation of advanced settings for users to customise their \nuser experience, collaboration with news outlets to facilitate users\u2019 access \nto trustworthy news, the facilitation of fact-checking and content flagging, \nand allowing users to \u2018exercise their right to reply\u2019 (EU HLEG, 2018: 32-33).\nThe UK Parliamentary report on fake news and disinformation speaks \nin an unusually piqued tone of the importance of regulating social media \nplatforms and related tech companies, singling out Facebook as providing \nthe \u2018impression of working towards transparency\u2019, but often \u2018obfuscating\u2019 \nhow well it is capturing and archiving political ads (House of Commons, \n2019: 85). Ultimately, they propose the establishment of an \u2018educational \nlevy\u2019 or charge on social media companies to fund digital literacy as a \nfourth pillar of the education system after reading, writing and maths \n(House of Commons, 2019: 87). There is also a recommendation that social \nmedia companies should develop means to distinguish between those \nsources regularly furnishing disinformation and those who do not, in a new \nsystem of \u2018content regulation\u2019 (House of Commons, 2019: 87). While carefully \nworded, that measures can count on the criticism that similar proposals \nhave faced concerning the restriction of the freedom of expression, while \nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  55\nnot being effective measures against hateful or incendiary content (Access \nNow et al., 2018).\nNevertheless, legislation has been passed. Germany has established a \nlaw, NetzDG, that extends its hate speech legislation compelling social \nmedia companies (with more than two million registered users in Germany) \nto remove such speech rapidly or face hefty fines (Claussen, 2018). More \ncontroversially, France has new legislation which applies to \u2018false informa -\ntion\u2019; the law requires that three months prior to an election \u2018false news\u2019 \nbe removed.\nDetecting and removing false content\nThe Reporters\u2019 Lab at Duke University keeps track of fact-checking initiatives \nworldwide and has identified some 160 active initiatives (Duke Reporters Lab, \n2019). In European countries, some fact-checking initiatives are attached to \nnews organizations, but most are operating as not-for-profits (Wardle and \nDerakhshan, 2017; Graves and Cherubini, 2016). Many work in tandem with \nFacebook; as of January\u00a02019, some 50 fact-checking groups, who are party to \nthe International Fact Checking Network Code of Principles, independently \nassess fake news flagged by users (Volpicelli, 2019). The expertise developed \nincludes a variety of flagging and adjudication systems such as NewsGuard\u2019s \n\u2018nutrition label\u2019 that evaluates some 2,000 online news sources, or, as it \nrelates, the sites that garner about 95% of engagement in the news sector \n(2019).AutomationBrief mention should perhaps be made of automation as offering methods \nfor flagging dubious or false content, however much it is rarely recom -\nmended in governmental reports. With respect to fact-checking, if there are \nshared databases of \u2018already fact-checked\u2019 stories as well as sources, then \nsoftware could cross-check suspicious ones against those already debunked \nor evaluated, as the UK parliamentary report mentions. The discussion \nconcerning the need for human reviewers for content interpretation and \ncuration remains pertinent.Counter-narratives\nIn Germany the government chooses to actively participate in spaces where \ndisinformation is spread. \u2018On these platforms, the German Government \n56 R icha Rd R oge R S  and Sabine ni ede ReR \nprovides both reliable information that can be fact-checked and a narrative \nbased on this information\u2019 (German Federal Foreign Office, 2018). In that \nvein, rumoursaboutgermany.info is a website for collecting and counter -\ning disinformation about Germany spread by human traffickers. While \nGermany chooses to work with counter-narratives, others have criticised \nthis approach. A Canadian intelligence report argues that developing \ncounter-narratives is a \u2018one event at a time approach\u2019 that \u2018fails to address \nthe source and methodology of information campaigns\u2019 (Canadian Security \nIntelligence Service, 2018: 66).\nMedia literacy and digital \u2018hygiene\u2019\nThe EU high level expert group on fake news and online disinformation \nmakes a case for increased media and information literacy to counter \ndisinformation, which should be \u2018implemented on a massive scale in school \nand teacher training curricula\u2019 (EU HLG, 2018: 26). This media literacy \nalso should involve the development of tools and training modules for \njournalists. As a particularly relevant method, the group proposes \u2018more \npowerful tools to be able to visually map online networks and connections \nto understand how disinformation is being created, spread and amplified\u2019 \n(EU HLG, 2018: 28).\nSome countries speak of \u2018digital hygiene\u2019 when referring to media literacy \npractices, for instance in France when making a case for the develop -\nment of skills to assess the validity of the arguments and the reliability \nof the source. \u2018This is a public hygiene measure \u2013 just as people in the \n19th century learned to wash their hands\u2019 (Jeang\u00e8ne Vilmer et al., 2018: \n179). In Sweden the word \u2018cyberhygien\u2019 is employed. The Swedish Civil \nContingencies Agency has published a handbook for communicators in \npublic sector organizations for the countering of disinformation, which \nincludes strategies that range from source checking and recognizing a \nbot to choosing an appropriate response to disinformation. The Swedish \nMedia Council developed a media literacy programme for young people, \nteaching them critical thinking and disinformation detection; it includes a \nset of educational materials on \u2018source criticism\u2019 (\u2018K a\u0308l lkritik\u2019) (Government \nOffices of Sweden, 2017; Swedish Media Council, 2019). Several recent \nreports stress the importance of better equipping journalists with tools and \nskills to recognize and avoid disinformation, mentioning the importance \nof fact-checking, critical source assessment and ethics (Jeang\u00e8ne Vilmer \net al., 2018; Wardle and Derakhshan, 2017).\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  57\nInvesting in civil society and building public trust\nA more general way forward that is presented in the literature is to invest \nin civil society, as it \u2018must remain the first shield against information ma -\nnipulation in liberal, democratic societies\u2019 (Jeang\u00e8ne Vilmer et al., 2018: 169). \nSuch initiatives are specifically relevant around events such as elections, in \nwhich civil society can be supported through non-legislative, pre-emptive \nmeasures and multi-stakeholder collaboration of government with the \nindustry, non-governmental sector, and regional actors (Haciyakupoglu \net al., 2018). In Sweden, the aforementioned Swedish Media Council is an \nexample in which politicians and media professionals collaborate and meet \nregularly to discuss and counter disinformation and related challenges. Such \nregular, multi-stakeholder consultation both within and across European \ncountries is among the recommendations often given (Brattberg and Mauer, \n2018).\nGuaranteeing participation in public debate by all\nLastly is the admonition issued in the 2017 joint UN declaration on \u2018fake \nnews\u2019 that emphasized the need for states to enable the participation of all \nin public debate. They should ensure that any efforts to quell or thwart the \npractices of fake news-making and spread as well as that of disinformation \nbe handled within the context of the freedom of expression and the freedom \non the press (McGonagle, 2017).\nReferences\nAbbruzzese, Jason (2018) \u2018Facebook became your news diet. Now, it\u2019s going to serve \nyou junk\u2019, Mashable , 17\u00a0January.\nAccess Now, Civil Liberties Union For Europe, and European Digital Rights (2018) \nInforming the \u201cdisinformation\u201d debate , Report, Published online on October\u00a018. \nhttps://edri.org/files/online_disinformation.pdf\nAlbright, Jonathan (2017) \u2018Itemized Posts and Historical Engagement \u2013 6 Now-Closed \nFB Pages\u2019, Data set, Tableau Public , 5\u00a0October, https://public.tableau.com/profile/\nd1gi#!/vizhome/FB4/TotalReachbyPage\nAllcott, Hunt and Matthew Gentzkow (2017) \u2018Social Media and Fake News in \nthe 2016 Election\u2019, Journal of Economic Perspectives , 31(2): 211-236. https://doi.\norg/10.1257/jep.31.2.211\n58 R icha Rd R oge R S  and Sabine ni ede ReR \nAlvarez, R. Michael, Ines Levin, Alexander H. Trechsel and Kristjan Vassil (2014) \n\u2018Voting Advice Applications: How Useful and for Whom?\u2019, J ournal of Information \nTechnology & Politics , 11(1): 82-101, DOI: 10.1080/19331681.2013.873361\nAngwin, Julia, Madeleine Varner and Ariana Tobin (2017) \u2018Facebook Enabled \nAdvertisers to Reach \u201cJew Haters\u201d\u2019, ProPublica , 14\u00a0September. https://www.\npropublica.org/article/facebook-enabled-advertisers-to-reach-jew-haters\nBarbrook, Richard (1998) \u2018The Hi-Tech Gift Economy\u2019, First Monday , 3(12). https://\nojphi.org/ojs/index.php/fm/article/view/631\nBeiler, Markus and Johanna Kiesler (2018) \u2018\u201cL u\u0308g enpresse! Lying press!\u201d Is the Press \nLying?\u2019, in Otto, Kim and Andreas K\u00f6hler (eds.) Trust in Media and Journalism , \nWiesbaden: Springer, 155-179.\nBelk, Russell (2007) \u2018Why Not Share Rather Than Own?\u2019, The ANNALS of the American \nAcademy of Political and Social Science , 611: 126-140.\nBell, Emily and Taylor Owen (2017) \u2018The Platform Press\u2019, Report, Columbia University: \nTow Center for Journalism.\nBellingcat Investigation Team (2016) \u2018Behind the Dutch Terror Threat Video: The \nSt. Petersburg \u201cTroll Factory\u201d Connection\u2019, Bellingcat , 3\u00a0April.\nBenkler, Yochai, Robert Faris, Hal Roberts, and Ethan Zuckerman (2017) \u2018Study: \nBreitbart-Led Right-Wing Media Ecosystem Altered Broader Media Agenda\u2019, \nColumbia Journalism Review , 3\u00a0March.\n\u2014, Robert Faris and Hal Roberts (2018) Network Propaganda: Manipulation, Disinfor -\nmation, and Radicalization in American Politics , Oxford: Oxford University Press.\nBessi, Alessandro and Emilio Ferrara (2016) \u2018Social bots distort the 2016 US presi -\ndential election online discussion\u2019,  First Monday , 21(11). https://firstmonday.org/\narticle/view/7090/5653\nBoczkowski, Pablo (2016) \u2018Fake news and the future of journalism\u2019, NiemanLab , \nDecember. https://www.niemanlab.org/2016/12/fake-news-and-the-future-of-\njournalism/\nBoghardt, Thomas (2009) \u2018Soviet Bloc Intelligence and Its AIDS Disinformation \nCampaign\u2019, Studies in Intelligence , 53(4): 1-24.\nBounegru, Liliana, Jonathan Gray, Tommaso Venturini, Michele Mauri (2018) A Field \nGuide to \u201cFake News\u201d and Other Information Disorders: A Collection of Recipes \nfor Those Who Love to Cook with Digital Methods , Amsterdam: Public Data Lab.\nBradshaw, Samantha (2018) \u2018Responding to Fake News through regulation and \nautomation\u2019, in  Fake News, Authentic Views, Report, London: Carter- Ruck. \nhttps://www.carter-ruck.com/images/uploads/documents/RESPONDING_\nTO_FAKE_NEWS.pdf\n\u2014 and Phillip N. Howard (2018) \u2018Challenging Truth and Trust: A Global Inventory \nof Organized Social Media Manipulation\u2019, Computational Propaganda Data \nMemo, Oxford: Oxford Internet Institute.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  59\nBrattberg, Erik and Tim Mauer (2018) \u2018Russian Election Interference: Europe\u2019s \nCounter to Fake News and Cyber Attacks\u2019, White Paper, Washington, DC: \nCarnegie Endowment for International Peace, May.\nBrennen, Bonnie (2017) \u2018Making Sense of Lies, Deceptive Propaganda, and Fake \nNews\u2019, Journal of Media Ethics , 32(3): 179-181.\nBroderick, Ryan and Jules Darmanin (2018) \u2018The \u201cYellow Vest\u201d Riots In France \nAre What Happens When Facebook Gets Involved With Local News\u2019, Buzzfeed \nNews , 6\u00a0December.\nBruns, Axel, Anja Bechmann, Jean Burgess et al. (2018) \u2018Facebook shuts the gate \nafter the horse has bolted, and hurts real research in the process\u2019, Internet Policy \nReview , 25\u00a0April.\nBump, Philip (2017) \u2018The investigation goes digital: Did someone point Russia to \nspecific online targets?\u2019 Washington Post , 12\u00a0July.\nBurger, Peter (2016) \u2018Moslims vernielen kerstmarkt in Litouwen? Nee: rellen in de VS\u2019, \nDe Gestolen Grootmoeder blog, 14\u00a0December. http://www.gestolengrootmoeder.\nnl/wordpress/moslims-vernielen-kerstmarkt-in-litouwen-nee-rellen-in-de-vs/\n\u2014, Soeradj Kanhai, Alexander Pleijter, and Suzan Verberne (2019) \u2018The Reach \nof Commercially Motivated Junk News on Facebook\u2019. ArXiv:1901.07290 [Cs] , \n22\u00a0January. http://arxiv.org/abs/1901.07290.\nButac, Maicolengel (2018) \u2018The Reuters Institute for the Study of Journalism vs fake \nnews\u2019, BUTAC blog, 8\u00a0February.\nCadwalladr, Carole and Emma Graham-Harrison (2018) \u2018Revealed: 50 million \nFacebook profiles harvested for Cambridge Analytica in major data breach\u2019, \nThe Guardian , 17\u00a0March.\nCanadian Security Intelligence Service (2018) Who said what? The Security Chal -\nlenges of Modern Disinformation , World Watch: Expert Notes series publication \n(No.\u00a02016-12-05), Canada: Canadian Security Intelligence Service.\nCary, Stephen G. (1955) Speak Truth to Power: A Quaker Search for an Alternative to \nViolence , Philadelphia: American Friends Service Committee.\nChadwick, Andrew (2013) The Hybrid Media System: Politics and Power . Oxford: \nOxford University Press.\nChen, Adrian (2015) \u2018The Agency\u2019, The New York Times , 2\u00a0June.\nClaussen, Victor (2018) \u2018Fighting hate speech and fake news. The Network Enforce -\nment Act (NetzDG) in Germany in the context of European legislation\u2019, Media Laws  3, published online on October\u00a014.\nColbert Report (2005) \u2018The W\u00d8RD \u201cTruthiness\u201d, Comedy Central , 17\u00a0October.\nCollins, Keith Sheera Frenkel (2018) \u2018Can you spot the deceptive Facebook post?\u2019 \nNew York Times , 4\u00a0September.\nDahlgren, Kristen and Daniel Arkin (2017) \u201811-Year-Old Texas Boy Invents Device \nto Prevent Hot Car Deaths\u2019, NBC News , 29\u00a0June.\n60 R icha Rd R oge R S  and Sabine ni ede ReR \nDaniels, Jessie (2018) \u2018The algorithmic rise of the alt-right\u2019, Contexts , 17(1): 60-65.\nDarnton, Robert (2010) Poetry and the Police: Communication Networks in Eighteenth-\nCentury Paris . Cambridge, MA: Harvard University Press.\n\u2014 (2017) \u2018The True History of Fake News\u2019, New York Review of Books , 13\u00a0February.\nDay, Amber and Ethan Thompson (2012) \u2018Live from New York, it\u2019s the fake news! \nSaturday night live and the (non)politics of parody,\u2019 Popular Communication  \n10(1-2): 170-182.\nDeAmicis, Carmel (2014) \u2018Facebook shifts its algorithm to fight clickbait. Will it \nkill off Upworthy and Buzzfeed?\u2019, GIGAOM , Austin: Giga Omni Media.\nDrog (2018) \u2018Slecht Nieuws: Serious game over propaganda\u2019, Website, https://www.\nslechtnieuws.nl/.\nDuke Reporters Lab (2019) \u2018Fact Checking News\u2019, Website. https://reporterslab.\norg/fact-checking/\nDumont, Patrick and Rapha\u00ebl Kies (2012) \u2018Smartvote.lu: Usage and impact of the \nfirst VAA in Luxembourg\u2019, International Journal of Electronic Governance  5(3/4): \n388-410.\nEllick, Adam B. and Adam Westbrook (2018) \u2018Operation Infektion\u2019, New York Times , \n12\u00a0November.\nEU HLEG (2018) A multi-dimensional approach to disinformation , Report of the \nindependent High level Group on fake news and online disinformation, Lux -\nembourg: Publications Office of the European Union.\nFandos, Nicholas (2017) \u2018White House Pushes \u2018Alternative Facts.\u2019 Here Are the Real \nOnes\u2019, New York Times , 22\u00a0January.\nFaris, Robert M., Hal Roberts, Bruce Etling, Nikki Bourassa, Ethan Zuckerman, \nand Yochai Benkler (2017) \u2018Partisanship, Propaganda, and Disinformation: \nOnline Media and the 2016 U.S. Presidential Election\u2019, Berkman Klein Center \nfor Internet & Society Research Paper.\nFarkas, Johan and Marco Bastos (2018) \u2018IRA Propaganda on Twitter: Stoking \nAntagonism and Tweeting Local News\u2019, SMSociety \u201818, Copenhagen.\nFireEye (2018) \u2018Suspected Iranian Influence Operation\u2019, Report, Milpitas, CA: \nFireEye.\nFitts, Alexis Sobel (2017) \u2018Welcome to the Wikipedia of the Alt-right\u2019, Wired , 21\u00a0June.\nFletcher, Richard, Alessio Cornia, Lucas Graves, and Rasmus Kleis Nielsen (2018) \n\u2018Measuring the reach of \u201cfake news\u201d and online disinformation in Europe\u2019, \nReuters Institute for the Study of Journalism, Oxford University, February.\nFlynn, Kerry (2018) \u2018Facebook will elevate \u201ctrusted\u201d news outlets after surveying \nU.S. users\u2019, Mashable , 19\u00a0January.\nFrenkel, Sheera, Kate Conger and Kevin Roose (2019) \u2018Russia\u2019s Playbook for Social \nMedia Disinformation Has Gone Global\u2019, New York Times , 31\u00a0January.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  61\n\u2014, Nicholas Casey and Paul Mozur (2018) \u2018In Some Countries, Facebook\u2019s Fiddling \nHas Magnified Fake News\u2019, New York Times , 14\u00a0January.\nFubini, Federico (2018) \u2018Tweet populisti dalla Russia sulla politica italiana. Come \nnegli Usa\u2019, Corriere della Sera , 1\u00a0August.\nGartenberg, Chaim (2018) \u2018Facebook is going to start surveying users to determine \ntrustworthy news sources\u2019, The Verge , 19\u00a0January.\nGarzia, Diego and Marschall, Stefan (2012) \u2018Voting Advice Applications Under \nReview: The State of Research\u2019,  International Journal of Electronic Governance,  \n5: 203-22.\nGerman Federal Foreign Office (2018) \u2018Fake news, bots and provocative state -\nments \u2013 disinformation on the internet\u2019, Auswaertiges Amt website, published \nonline on August\u00a07.\nGessen, Masha (2018) \u2018Why the Russian Influence Campaign Remains So Hard to \nUnderstand\u2019, The New Yorker , 18\u00a0December.\nGitelman, Lisa (2006) Always Already New: Media, History, and the Data of Culture . \nCambridge, MA: MIT Press.\nGottfried, Jeffrey and Elisa Shearer (2016) \u2018News Use Across Social Media Platforms \n2016\u2019, Washington, DC: Pew Research Center.\nGovernment Offices of Sweden (2017) A practical approach on how to cope with \ndisinformation , Government Offices of Sweden website, published online on \nOctober\u00a06.\nGramer, Robbie (2017) \u2018Denmark Creates the World\u2019s First Ever Digital Ambassador\u2019, \nForeign Policy, published online on January\u00a027.\nGraves, Lucas (2016) Deciding What\u2019s True: The Rise of Political Fact-Checking in \nAmerican Journalism . New York: Columbia University Press.\nGraves, Lucas and Federica Cherubini (2016) The Rise of Fact-checking Sites in Europe . \nOxford: University of Oxford, Reuters Institute for the Study of Journalism.\nGrinberg, Nir, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson and David \nLazer (2019) \u2018Fake news on Twitter during the 2016 U.S. presidential election\u2019, \nScience  363(6425): 374-378.\nGroll, Elias (2018) \u2018Battling the Bots\u2019, Foreign Policy , 12\u00a0November.\nGuess, Andrew, Brendan Nyhan and Jason Reifler (2018) \u2018Selective Exposure to \nMisinformation: Evidence from the consumption of fake news during the 2016 \nU.S. presidential campaign\u2019, Report, Hannover, NH: Dartmouth College, https://\nwww.dartmouth.edu/~nyhan/fake-news-2016.pdf.\nHaciyakupoglu, Gulizar, Jennifer Yang Hui, V. S. Suguna, Dymples Leong, and \nMuhammad Faizal Bin Abdul Rahman (2018) Countering Fake News: A Survey Of Recent Global Initiatives , Singapore: Nanyang Technological University.\nHall, Jim (2001) Online journalism: a critical primer . London: Pluto Press.\n62 R icha Rd R oge R S  and Sabine ni ede ReR \nHameleers, Michael and Toni van der Meer (2019) \u2018Fact-checks helpen tegen \ndesinformatie! Maar dan moeten ze wel gezien worden\u2019, De Nieuwe Reporter , \n29\u00a0January.\nHarvey, Del and Yoel Roth (2018) \u2018An update on our elections integrity work\u2019, \nTwitter blog, 1\u00a0October.\nHaynes, Gavin (2016) \u2018Can you spot the \u2018real\u2019 fake news story?\u2019 The Guardian , \n28\u00a0December.\nHeck, Wilmer (2018) \u2018Nederlandse media dagen EU voor rechter na beschuldigingen \ndesinformatie\u2019, NRC Handelsblad , 20\u00a0February.\nHedman, Freja, Fabian Sivnert, Lisa-Maria Neudert, Bence Kollanyi, Philip N. How -\nard and Vidya Narayanan (2018) \u2018News and Political Information Consumption in \nSweden: Mapping the 2018 Swedish General Election on Twitter\u2019, Computational \nPropaganda Data Memo, Oxford: Oxford Internet Institute, 6\u00a0September.\nHedrick, Ashley, Dave Karpf and Daniel Kreiss (2018) \u2018The Earnest Internet vs. the \nAmbivalent Internet\u2019, International Journal of Communication , 12:1057-1064.\nHendricks, Vincent F. and Mads Vestergaard (2019) Reality Lost: Markets of Attention, \nMisinformation and Manipulation , Cham: Springer.\nHern, Alex (2017) \u2018Google acts against fake news on search engine\u2019, The Guardian , \n25\u00a0April.\n\u2014 and Jim Waterson (2018) \u2018Facebook cracks down on \u2018dark ads\u2019 by British political \ngroups\u2019, The Guardian , 16\u00a0October.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August. https://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHirzalla, Fadi and Liesbet van Zoonen (2015) \u2018Online voting applications. Foci, \nfindings and future of an emerging research field\u2019 in Coleman, S. & Freelon, \nD. (eds), Handbook of Digital Politics , Northampton, MA: Edward Elgar: 87-103.\nHolzman, Michael (2008) James Jesus Angleton, the CIA and the Craft of Counterintel -\nligence , Amherst: University of Massachusetts Press.\nHouse of Commons (2019) \u2018Disinformation and \u201cFake News\u201d: Final Report Eighth \nReport of Session 2017-19\u2019, Digital, Culture, Media and Sport Committee, London: \nUK Parliament.\nHoward, Philip N., Gillian Bolsover, Bence Kollanyi, Samantha Bradshaw, and \nLisa-Maria Neudert (2017) \u2018Junk news and bots during the U.S. election: What \nwere Michigan voters sharing over Twitter?\u2019 Computational Propaganda Data Memo, Oxford: Oxford Internet Institute.\n\u2014, Bharath Ganesh, Dimitra Liotsiou, John Kelly and Camille Franc\u0327ois (2018) \u2018The \nIRA, Social Media and Political Polarization in the United States, 2012-2018\u2019, Report, \nComputational Propaganda Research Project, Oxford: Oxford Internet Institute.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  63\nIsaac, Mike (2016) \u2018Facebook, in Cross Hairs After Election, Is Said to Question Its \nInfluence\u2019, New York Times , 12\u00a0November.\nJack, Caroline (2017) Lexicon of Lies: Terms for Problematic Information  New York: \nData & Society Research Institute.\nJankowski, Nicholas W. (2018) \u2018Researching Fake News: A Selective Examination \nof Empirical Studies\u2019, Javnost \u2013 The Public , 25(1-2): 248-255.\nJeang\u00e8ne Vilmer, Jean-Baptiste, Alexandre Escorcia, Marine Guillaume, Janaina \nHerrera (2018) Information Manipulation: A Challenge for Our Democracies , report \nby the Policy Planning Staff (CAPS) of the Ministry for Europe and Foreign \nAffairs and the Institute for Strategic Research (IRSEM) of the Ministry for the \nArmed Forces, Paris, August.\nJonker, Jorn (2017) \u2018Nepnieuws gevaar voor Nederland\u2019, De Telegraaf , 14\u00a0November.\nKanne, Peter and Milan Driessen (2017) Desinformatie leidt tot verwarring bij \nnieuwsconsument , Amsterdam: I&O Research.\nKasteleijn, Nando (2017) \u2018Nepnieuws groot gevaar voor Nederland? Dat lijkt dus \nwel mee te vallen\u2019, NOS , 28\u00a0August.\nvan Keulen, Ira, Iris Korthagen, Paul Diederen en Pieter van Boheemen (2018) \n\u2018Digitalisering van het nieuws: Online nieuwsgedrag, desinformatie en per -\nsonalisatie in Nederland\u2019, Den Haag: Rathenau Instituut.\nKing, Gary and Nathaniel Persily (2018) \u2018A New Model for Industry-Academic \nPartnerships\u2019, Working Paper, 9\u00a0April. http://j.mp/2q1IQpH\nKist, Reinier (2019) \u2018Factchecken Facebook loopt stuk op aansprakelijkheid\u2019, NRC \nHandelsblad , 26\u00a0February.\n\u2014 and Rik Wassens (2017) \u2018Ook Nederlandse media werden misleid door Russische \ntrollen\u2019, NRC Handelsblad , 8\u00a0December.\n\u2014 and Rik Wassens (2018a) \u2018Russische trollen actief in Nederland\u2019, NRC Handelsblad,  \n15\u00a0July.\n\u2014 and Rik Wassens (2018b) \u2018Russisch trollenleger ook actief in Nederland\u2019, NRC \nHandelsblad , 15\u00a0July.\n\u2014 and Peter Zantingh (2017) \u2018Geen grote rol nepnieuws in aanloop naar verkiez -\ningen\u2019, NRC Handelsblad , 6\u00a0March.\nKitta, Andrea (2018) \u2018Alternative Websites and Fake News: Taking a Stab at Defini -\ntion, Genre and Belief\u2019, The Journal of American Folklore 131(522): 405-412.\nKouwenhoven, Andreas and Hugo Logtenberg (2017) \u2018Hoe Denk met \u2018trollen\u2019 poli -\ntieke tegenstanders monddood probeert te maken\u2019, NRC Handelsblad , 10\u00a0February.\nKranenberg, Annieke (2017) Wie weet nog wat er waar is?, de Volkskrant , \n23\u00a0December.\nLaquintano, Timothy and Annette Vee (2017) \u2018How Automated Writing Systems \nAffect the Circulation of Political Information Online\u2019, Literacy in Composition \nStudies , 5(2): 43-62.\n64 R icha Rd R oge R S  and Sabine ni ede ReR \nLatour, Bruno (2008) What is the style of matters of concern? Assen: Van Gorcum.\nLazarsfeld, Paul F., Bernard R. Berelson and Hazel Gaudet (1948) The People\u2019s Choice: \nHow the Voter Makes Up His Mind in a Presidential Campaign , New York, NY: \nColumbia University Press.\nLazer, David M.J., Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly \nM. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan, Gordon \nPennycook, David Rothschild, Michael Schudson, Steven A. Sloman, Cass R. \nSunstein, Emily A. Thorson, Duncan J. Watts and Jonathan L. Zittrain (2018) \n\u2018The science of fake news\u2019, Science , 359(6380):1094-1096.\nLippmann, Walter (1922) Public Opinion , New York, NY: Harcourt, Brace and Co.\nLouwerse, Tom and Martin Rosema (2014) \u2018The design effects of voting applications: \nComparing methods of calculating matches\u2019, Acta Politica  49(3):286-312.\nLu\u0308ders, Marika, Lin Pr\u00f8itz and Terje Rasmussen (2010) \u2018Emerging personal media \ngenres\u2019, New Media & Society , 12(6): 947-963.\nMargolis, Joseph (1995) \u2018Beyond postmodernism: Logic as rhetoric\u2019, Argumentation , \n9(1): 21-31.\nMarres, Noortje (2018) \u2018Why We Can\u2019t Have Our Facts Back\u2019, Engaging Science, \nTechnology, and Society,  4: 423-443.\nMarvin, Carolyn (1988) When Old Technologies were New . New York, NY: Oxford \nUniversity Press.\nMarwick, Alice E. (2018) \u2018Why Do People Share Fake News? A Sociotechnical Model \nof Media Effects\u2019, Georgetown Law Technology Review , 2(2): 474-512.\nMcGonagle, Tarlach (2017) \u2018\u201cFake news\u201d: False fears or real concerns?\u2019, Netherlands \nQuarterly of Human Rights , 35(4): 203-209.\nMcKernon, Edward (1925) \u2018Fake News and the Public\u2019, The Harper\u2019s Monthly, October, \npp.\u00a0528-536.\n\u2014 (1928) \u2018News Fakers\u2019, The Outlook,  149(4): 130-141.\nMcNeil, Maureen (2013) \u2018Between a Rock and a Hard Place: The Deficit Model, the \nDiffusion Model and Publics in STS\u2019, Science as Culture , 22(4): 589-608.\nMcQueen, Sharon (2018) \u2018From Yellow Journalism to Tabloids to Clickbait: The \nOrigins of Fake News in the United States\u2019, in Agosto, Denise E. (ed.) Information \nLiteracies and Libraries in the Age of Fake New s, Santa Barbara, CA: Libraries \nUnlimited, pp.\u00a012-35.\nMerrill, Jeremy B. and Ariana Tobin (2019) \u2018Facebook Moves to Block Ad Transpar -\nency Tools \u2013 Including Ours\u2019, ProPublica , 29\u00a0January.\nMilneil, Christian (2018) \u2018Data: Read the tweets from alleged Russian troll accounts \ntargeting Maine politicians\u2019, Portland Press Herald , 2\u00a0August.\nMina, An Xiao (2019). Memes to Movements: How the World\u2019s Most Viral Media Is \nChanging Social Protest and Power, Boston, MA: Beacon Press.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  65\nMis\u00e9rus, Mark and Robert van der Noordaa (2018a) \u2018Het trollenleger van popartiest \nDotan\u2019, de Volkskrant , 14\u00a0April.\n\u2014 and Robert van der Noordaa (2018b) \u2018Dotan erkent aanmaken nepfans: \u201cIk was \nheel na\u00efef, veel te ambitieus en onzeker\u201d\u2019, de Volkskrant , 16\u00a0April.\nMonbiot, George (2019) \u2018Dark money is pushing for a no-deal Brexit. Who is behind \nit?\u2019, The Guardian , 13\u00a0February.\nMorozov, Evgeny (2017) \u2018Moral panic over fake news hides the real enemy \u2013 the \ndigital giants\u2019, The Guardian , 8\u00a0January.\nNeudert, Lisa-Maria N. (2017) \u2018Computational Propaganda in Germany: A Cautionary \nTale\u2019, Computational Propaganda Working Paper, 2017.7, COMPROP Data Memo, \nOxford: Oxford Internet Institute.\nNew Knowledge (2018) \u2018The Tactics & Tropes of the Internet Research Agency\u2019, \nWhite Paper, Austin, TX: New Knowledge.\nNewman, Michelle C. (2010) \u2018The Daily Show and Meta-Coverage: How Mock News \nCovers the Political Communications System\u2019, The Elon Journal of Undergraduate \nResearch in Communications , 1(2).\nNewsGuard (2019), \u2018Restoring Trust and Accountability\u2019, webpage, https://www.\nnewsguardtech.com.\nNijmeijer, Bert (2018) \u2018Zelf nepnieuws maken om daarna de echte trollen te kunnen \nherkennen\u2019, NRC Handelsblad,  22\u00a0July.\nvan der Noordaa, Robert and Coen van de Ven (2018a) \u2018Hoe Russische trollen inspelen \nop westerse angsten\u2019, De Groene Amsterdammer , 28\u00a0Augustus.\n\u2014 and Coen van de Ven (2018b) \u20183 Miljoen \u201ctrollentweets\u201d onderzocht: hoe Rusland \nvia sociale media ook in Belgi\u00eb verdeeldheid zaait\u2019, Knack , 27\u00a0November.\nNOS (2017a) \u2018Baby van 20 kilo heeft de primeur: eerste nepnieuws in Nederland\u2019, \nNOS, 8\u00a0June.\n\u2014 (2017b) \u2018Ollongren: Russische desinformatie bij Oekra\u00efne-referendum\u2019, NOS , \n15\u00a0November.\n\u2014 (2018) \u2018Twitters grote schoonmaak: Wilders en Denk-politici verliezen volgers\u2019, \nNOS, 13\u00a0July.\nNuzzi, Olivia (2017) \u2018Kellyanne Conway Is a Star\u2019, New York Magazine, March.\nNyhan, Brendan, Ethan Porter, Jason Reifler and Thomas J. Wood (2019) \u2018Taking \nFact-Checks Literally But Not Seriously? The Effects of Journalistic Fact-Checking \non Factual Beliefs and Candidate Favorability\u2019, Political Behavior , published \nonline 21\u00a0January.\nO\u2019Brien, Chris (2019) \u2018Sheryl Sandberg says Facebook is now blocking 1 million fake \naccounts every day\u2019, Venture Beat , 21\u00a0January.\nO\u2019Donovan, Caroline (2014) \u2018What is clickbait?\u2019, Niemanlab , 25\u00a0August.\nOpper, F. (1894) \u2018The fin de si\u00e8cle newspaper proprietor\u2019, Puck,  35(887).\n66 R icha Rd R oge R S  and Sabine ni ede ReR \nPanagopoulos, Costas (2016) \u2018All about that base: Changing campaign strategies \nin US presidential elections\u2019 Party Politics , 22(2): 179-90.\nPariser, Eli (2011) The Filter Bubble: What the Internet Is Hiding From You. New \nYork, NY: Penguin.\nParlapiano, Alicia and Jasmine C. Lee (2018) \u2018The Propaganda Tools Used by Russians \nto Influence the 2016 Election\u2019, New York Times , 16\u00a0February.\nPeck, Reece (2019) Fox Populism: Branding Conservatism as Working Class , Cam -\nbridge: Cambridge University Press.\nPedersen, David B. and Vincent F. Hendricks (2014) \u2018Science Bubbles\u2019, Philosophy \nand Technology , 27(4): 503-518.\nPersily, Nathaniel (2017) \u2018The 2016 U.S. Election: Can Democracy Survive the \nInternet?\u2019.  Journal of Democracy , 28(2): 63-76\nPhillips, Whitney (2015) This Is Why We Can\u2019t Have Nice Things: Mapping the Relation -\nship Between Online Trolling and Mainstream Culture . C ambridge, MA: MIT Press.\n\u2014 (2018) \u2018The Oxygen of Amplification: Better Practices for Reporting on Extrem -\nists, Antagonists and Manipulators Online\u2019, Report, New York: Data & Society \nResearch Institute.\n\u2014 and Ryan Milner (2018) The Ambivalent Internet: Mischief, Oddity, and Antagonism \nOnline , Cambridge: Polity Press.\nPleijter, Alexander (2017) \u2018De nepnieuwslawine zonder nepnieuws\u2019, Villamedia, \n17\u00a0November.\nPohjonen, Matti and Sahana Udupa (2017) \u2018Extreme Speech Online: An Anthropo -\nlogical Critique of Hate Speech Debates\u2019, International Journal of Communication,  \n11: 1173-1191.\nPosetti, Julie and Alice Matthews (2018) A short guide to the history of \u2018fake news\u2019 \nand disinformation. A learning module for journalists and journalism educator , \nWashington, DC: International Center for Journalists.\nPoynter (2019) A guide to anti-misinformation actions around the world , St. Peters -\nburg, FL: The Poynter Institute.\nPuschmann, Cornelius (2018) \u2018Beyond the Bubble: Assessing the Diversity of Political \nSearch Results\u2019 Digital Journalism , published online 28\u00a0November. https://doi.\norg/10.1080/21670811.2018.1539626\nRatkiewicz, Jacob, Michael D. Conover, Mark Meiss, Bruno Goncalves, Alessandro \nFlammini, Filippo Menczer Menczer (2011) \u2018Detecting and Tracking Political \nAbuse in Social Media\u2019, Proceedings of the Fifth International AAAI Conference \non Weblogs and Social Media , Barcelona, Spain, July.\nReid, John, Bastiaan Geleijnse and Jean-Marc van Tol (2018) \u2018Fokke en Sukke hebben \nzitting in de taskforce nepnieuws\u2019, Cartoon, 17\u00a0January.\nRenner, Nausicaa (2017) \u2018Memes trump articles on Breitbart\u2019s Facebook page\u2019, \nColumbia Journalism Review , 30\u00a0January.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  67\nRieder, Bernhard (2018) \u201cFacebook\u2019s app review and how independent research \njust got a lot harder\u201d. Politics of Systems blog, 11\u00a0August.\n\u2014, Ariadna Matamoros-Fern\u00e1ndez and \u00d2scar Coromina (2018) \u2018From ranking \nalgorithms to \u2018ranking cultures\u2019: Investigating the modulation of visibility in \nYouTube search results.\u2019 Convergence: The International Journal of Research into \nNew Media Technologies , 24(1): 50-68.\nRNTC (2019). \u2018Challenging fake news\u2019, webpage, Hilversum: RNTC. Https://rntc.\ncom/blog/challenging-fake-news.\nRoberts, Sarah T. (2016) \u2018Commercial Content Moderation: Digital Laborers\u2019 Dirty \nWork\u2019, in Safiya Umoja Noble and Brendesha M. Tynes (eds.) The Intersectional \nInternet , New York, NY: Peter Lang, pp.\u00a0147-160.\nRoBhat Labs (2017) \u2018Identifying Propaganda Bots on Twitter\u2019, Medium , 31\u00a0October.\nRoeder, Oliver (2018) \u2018We Gave You 3 Million Russian Troll Tweets. Here\u2019s What \nYou\u2019ve Found So Far\u2019, FiveThirtyEight , 8\u00a0August.\nRogers, Richard (2018a) \u2018Otherwise Engaged: Social Media from Vanity Metrics to \nCritical Analytics\u2019, International Journal of Communication , 12: 450-472.\n\u2014 (2018b) \u2018Digital Methods for Cross-Platform Analysis\u2019, in Jean Burgess, Alice \nMarwick and Thomas Poell (eds.), SAGE Handbook of Social Media . London: \nSage, pp.\u00a091-110.\n\u2014 (2005) \u2018Poignancy in the US political blogosphere\u2019, Aslib Proceedings: New \nInformation Perspectives , 57(4): 356-368.\nRone, Julia (2019) \u2018Why talking about \u201cdisinformation\u201d misses the point when \nconsidering radical right \u201calternative\u201d media\u2019, LSE Media Policy project blog, \n9\u00a0January.\nRony, Md Main Uddin, Naeemul Hassan and Mohammad Yousuf (2017) \u201cBaitBuster: \nDestined to Save You Some Clicks\u201d. Proceedings of Computation+Journalism \nSymposium , Northwestern University, October.\nRoozenbeek, Jon and Sander van der Linden (2018) \u2018The fake news game: actively \ninoculating against the risk of misinformation\u2019, Journal of Risk Research , DOI: \n10.1080/13669877.2018.1443491.\nRuusuvirta, Outi (2010) \u2018Much Ado About Nothing? Online Voting Advice Ap -\nplications in Finland\u2019, in Cedroni, Lorella and Diego Garzia (eds.), Voting Advice \nApplications in Europe. The State of the Art , Napoli: ScriptaWeb, pp.\u00a047-77.\nSa\u0308ngerlaub, Alexander, Miriam Meier and Wolf-Dieter Ru\u0308hl (2017) \u2018Fakten statt \nFakes: Das Pha\u0308nomen \u201cFake News\u201d\u2019, Berlin: Stiftung Neue Verantwortung.\nShane, Scott (2018) \u2018How Unwitting Americans Encountered Russian Operatives \nOnline\u2019, New York Times , 18\u00a0February.\nShao, Chengcheng, Giovanni Luca Ciampaglia, Onur Varol, Kai-Cheng Yang, Ales -\nsandro Flammini and Filippo Menczer (2018) \u2018The spread of low-credibility \ncontent by social bots\u2019, Nature Communications , (9)4787, 20\u00a0November.\n68 R icha Rd R oge R S  and Sabine ni ede ReR \nShaw, Eugene (1979) \u2018Agenda-Setting and Mass Communication Theory\u2019, Interna-\ntional Communication Gazette , 25(2): 96-105.\nSilverman, Craig, J. Lester Feder, Saska Cvetkovska, and Aubrey Belford (2018) \n\u2018Macedonia\u2019s Pro-Trump Fake News Industry Had American Links, And Is Under \nInvestigation For Possible Russia Ties\u2019, Buzzfeed News , 18\u00a0July.\n\u2014 (2016) \u2018This Analysis Shows How Viral Fake Election News Stories Outperformed \nReal News On Facebook\u2019, Buzzfeed News , 16\u00a0November.\n\u2014 and Lawrence Alexander (2016) \u2018How Teens In The Balkans Are Duping Trump \nSupporters With Fake News\u2019, Buzzfeed New s, 3\u00a0November.\n\u2014 and Jeremy Singer-Vine (2016) \u2018The True Story Behind The Biggest Fake News \nHit Of The Election\u2019, Buzzfeed News , 16\u00a0December.\n\u2014, Lauren Strapagiel, Hamza Shaban, Ellie Hall, and Jeremy Singer-Vine (2016) \n\u2018Hyperpartisan Facebook Pages Are Publishing False And Misleading Informa -\ntion At An Alarming Rate\u2019, Buzzfeed News , 20\u00a0October.\nSismondo, Sergio (2017) \u2018Post-truth?\u2019, Social Studies of Science , 47(1): 3-6.\nSnyder, Timothy (2018) The Road to Unfreedom: Russia, Europe, America , New York, \nNY: Tim Duggan Books.\nSolon, Olivia and Sam Levin (2016) \u2018How Google\u2019s search algorithm spreads false \ninformation with a rightwing bias\u2019, The Guardian , 16\u00a0December.\nSrnicek, Nick (2017) Platform Capitalism . Cambridge: Polity Press.\nStill, Keith (2017) \u2018Inauguration Crowd Size\u2019, Crowd Safety and Risk Analysis blog, \nManchester: Manchester Metropolitan University. http://www.gkstill.com/CV/\nProjects/Counting.html.\nSwedish Civil Contingencies Agency (2018) Countering information influence \nactivities: A handbook for communicators , Karlstad: Swedish Civil Contingencies \nAgency (MSB).\nSwedish Media Council (2019) K\u00e4llkritik \u2013 en utmaning, webpage, https://statensme -\ndierad.se/larommedier/kallkritikvemvadvarfor/kallkritikenutmaning.422.\nhtml, 5\u00a0March.\nTandoc Jr., Edson C., Zheng Wei Lim and Richard Ling (2018) \u2018Defining \u201cFake News\u201d: \nA typology of scholarly definitions\u2019, Digital Journalism , 2: 137-153.\nTimberg, Craig (2017) \u201cRussian propaganda may have been shared hundreds of \nmillions of times, new research says\u201d. Washington Post , 5\u00a0October.\nTripodi, Francesca (2018) \u2018Alternative Facts, Alternative Truths\u2019, Data & Society: \nPoints blog , 23\u00a0February.\nTucker, Joshua A., Andrew Guess, Pablo Barber\u00e1, Cristian Vaccari, Alexandra \nSiegel, Sergey Sanovich, Denis Stukal, and Brendan Nyhan (2018) \u2018Social Media, \nPolitical Polarization, and Political Disinformation: A Review of the Scientific \nLiterature\u2019, Report, Menlo Park, CA: William and Flora Hewlett Foundation.\nThe Po li Ti cS  of So cial Me dia Ma niPu laTi on  69\nTurner, Stephen (2001) \u2018What is the problem with experts?\u2019, Social Studies of Science , \n31(1): 123-149.\nTuters, Marc, Emilija Jokubauskait\u0117, and Daniel Bach (2018) \u2018Post-Truth Protest: \nHow 4chan Cooked Up the Pizzagate Bullshit\u2019, M/C Journal  21(3). http://journal.\nmedia-culture.org.au/index.php/mcjournal/article/view/1422.\nVaidhyanathan, Siva (2018) \u2018Why Facebook Will Never Be Free of Fakes\u2019, New York \nTimes , 5\u00a0September.\n\u2014 (2017) \u2018Facebook Wins, Democracy Loses\u2019, New York Times , 8\u00a0September.\nVassil, Kristjan (2011) Voting smarter? The impact of voting advice applications on \npolitical behavior , PhD dissertation, European University Institute, Tartu, Estonia.\nVolpicelli, Gina (2019) \u2018This is how Facebook\u2019s news feed fact-checking will work \nin the UK,\u2019 Wired , 11\u00a0January.\nVosoughi, Soroush, Deb Roy and Sinan Aral (2018) \u2018The spread of true and false \nnews online\u2019, Science , 359(6380): 1146-1151.\nWalgrave, Stefaan, Michiel Nuytemans and Koen Pepermans (2009) \u2018Voting Aid \nApplications and the Effect of Statement Selection\u2019, West European Politics,  \n32(6): 1161-1180.\nWardle, Claire (2018) Information Disorder: The Essential Glossary , Shorenstein \nCenter, Cambridge, MA: Harvard Kennedy School.\n\u2014 and Hossein Derakhshan (2017) Information Disorder: Toward an interdiscipli -\nnary framework for research and policy making , Strasbourg: Council of Europe, \nSeptember\u00a027.\nWendling, Mike (2018a) \u2018The (almost) complete history of \u2018fake news\u2019\u2019, BBC News , \n22\u00a0January.\nWieringa, Maranke, Tim de Winkel and Callum Lewis (2017) \u2018Wie is de waakhond \nop sociale media?\u2019, report, Utrecht: Utrecht Data School.\nWoolley, Samuel and Philip N. Howard (2016) \u2018Social media, revolution, and the \nrise of the political Bot\u2019, in Piers Robinson, Philip Seib, Romy Fr\u00f6hlich (eds.), \nHandbook of Media, Conflict and Security . New York, NY: Routledge, 282-292.\nWynne, Brian (1991) \u2018Knowledge in context\u2019, Science, Technology & Human Values , \n16(1): 111-121.\nvan Zijl, Frank and Huib Modderkolk (2017) \u2018Generaal: Nederland kan digitale \ndreiging niet aan\u2019, de Volkskrant , 29\u00a0August.\n70 R icha Rd R oge R S  and Sabine ni ede ReR \nAbout the authors\nRichard Rogers  is Professor of New Media & Digital Culture at the Univer -\nsity of Amsterdam and Director of the Digital Methods Initiative, the group \nresponsible for social media research tools. Among other works, Rogers is \nauthor of Information Politics on the Web  (MIT Press, 2004), Digital Methods  \n(MIT Press, 2013), and Doing Digital Methods (Sage, 2019).\nSabine Niederer  is Professor of Visual Methodologies at the Amsterdam \nUniversity of Applied Sciences. Her research focuses on the cartography \nof issues and online debates through visual and digital methods, with a \nparticular interest in climate-related issues. In 2014, Niederer founded the \nCitizen Data Lab as an applied research lab specializing in participatory \nmapping of local issues.\n2 P olitical news on Facebook during the \n2019 Dutch elections\nStijn Peeters and Richard Rogers1\nAbstract\nThis chapter discusses Facebook-based engagement with news sources \nduring the campaigns for two Dutch election campaigns in 2019. Building \non earlier journalistic and academic work, a broad typology of \u2018junk\u2019 versus \nmainstream news is developed, as well as a number of more specific alter -\nnative categories. Engagement with news articles within these categories \non Facebook is then analysed with BuzzSumo (a media monitoring service \nbuilt atop CrowdTangle). While mainstream news receives significantly \nmore engagement than other types of news during both campaigns, \njunk news also receives consistent and significant engagement, though \nno substantial engagement with outright disinformation is found. We \nconclude with a cursory comparison of the findings with those for other \nsocial media platforms, positioning Facebook as the platform where \nengagement with junk news is most significant.\nKeywords:  Facebook, news engagement, junk news, cross-platform analysis\nIntroduction: Facebook\nSince 2016 online disinformation and so-called fake or junk news have been \nvirtually synonymous with social media platforms, serving as their most \nsignificant conduits. The 2016 U.S. presidential elections and the British \nBrexit referendum of the same year opened a period of increased scrutiny \nof these platforms in how false or misleading information are published \nand amplified. Facebook, the single largest social media platform of the \n1 T he research reported here was undertaken in collaboration with Tim Groot.\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch02\n72 STiJn P eeTeR S  and Richa Rd R oge R S \npast decade, has been an obvious focal point. It has been the subject of a \nsubstantial and growing amount of studies that investigate its \u2018challenge \n[to] journalism\u2019 (Johnson and Kelling, 2018: 817), the persuasiveness of fake \nnews shared on it (Allcott and Gentzkow, 2017) and the prevalence of it in \nthe average user\u2019s Facebook practice (Guess et al., 2018).\nOne of the first well-publicized reports on this topic, and the one that \ninformed some of the subsequent research, was BuzzFeed News \u2019 2016 story on \nthe prevalence of \u2018fake news\u2019 in the three months leading up to the presidential \nelections that saw Donald Trump elected the 45th president of the United \nStates. The report, entitled \u2018This Analysis Shows How Viral Fake Election News \nStories Outperformed Real News On Facebook\u2019 (Silverman 2016), outlines \nuser engagement with \u2018fake news\u2019, finding that in the last few weeks before the election it was engaged with more often than mainstream news.\nFollowing this piece and other coverage on the prevalence of \u2018fake news\u2019 on \nits platform, Facebook repeatedly announced initiatives that were ostensibly \nintended to prevent it from happening again by employing third-party \nfact-checking organizations (Mosseri 2017a), giving \u2018more informative\u2019 \ncontent higher priority (Mosseri 2017b), providing more information about \nthe authors of news content (Hughes et al., 2018) and increasing content \nmoderation. Despite these changes, a few years after the 2016 US elections \nthe platform has still repeatedly been found in studies to be spreading \nproblematic content. It has been criticized because of its role in spreading \nfalse and hateful content about minorities in Myanmar (Fink, 2018), live \nstreaming the 2019 Christchurch mass shooting (Shead, 2019) and in inciting \nreligious hatred in Bangladesh through viral content that is misleading \n(Haque et al., 2018: 1). In an analysis of social media use around the Mexican \npresidential elections in 2018, however, only \u2018limited evidence of junk content \non [Facebook]\u2019 was found (Glowacki et al., 2018: 4). Similarly, a 2017 analysis \nof social media usage by Dutch political parties found scant \u2018dubious\u2019 content \nshared by Dutch political Facebook pages (Wieringa et al.,\u00a02017: 60), though \ntheir focus was Facebook pages associated with political parties rather than \na larger Dutch Facebook sphere.\nFacebook therefore remains an interesting object of study. It is both \nthe platform most commonly associated with dubious content as well as \none that, taken at face value, has been relatively proactive in deploying \ninitiatives against its spread. Additionally, existing literature is inconclusive \nwith regards to the extent to which these measures have been effective, \nand there seem to be significant regional differences in the penetration of \u2018fake news\u2019 in the discourse on the platform, and its effects. There is some \nexisting research focused on the overall Dutch media sphere, most notably \nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  73\na study on fake news during the 2017 Dutch parliamentary elections by the \nNRC Handelsblad , the national newspaper. The NRC Handelsblad  found \nlittle evidence of the phenomenon; however, as both Dutch politics and \nFacebook\u2019s platform have undergone changes since then, the two Dutch \nelections of 2019 \u2013 the provincial elections ( provinciale statenverkiezingen ) \nand the EU Parliamentary elections \u2013 present a useful case study through \nwhich one may investigate the extent to which disinformation and \u2018fake \nnews\u2019 in a broader sense play a role in this particular geographical context \non the platform, three years after the 2016 U.S. elections, and two years \nafter the previous major national Dutch elections.\nWhile ostensibly regional in character, the Dutch provincial elections \nnevertheless have a \u2018strong national component2\u2018 (Hietbrink and van Voorst, \n2011: 6) as they determine the composition of the Dutch senate, which is \nindirectly elected by the \u2018provincial states\u2019 ( provinciale staten ). As such they \ncan serve as a national case study similar to that of the two other major case \nstudies by BuzzFeed News  and the NRC Handelsblad  that serve as a kind of \nbaseline for this one. In addition to provincial elections, only two months \nlater, in May\u00a02019, the Netherlands took part in the EU parliamentary elec -\ntions. Given the close proximity of these two elections, and their different \ncharacter, they together provide an opportunity to explore disinformation \nand \u2018fake news\u2019 in the media concerning Dutch politics.\nIn the following, we first discuss how their methods may be appropriated \nfor this case study, through an adapted query list and a more well-defined \ntypology of \u2018mainstream\u2019 versus \u2018junk news\u2019 sources, a term preferred over \nfake news, as we discuss in more detail below. We then analyze the results \nin terms of overall trends and a characterization of the sites found in the \njunk news category. By way of wider contextualization, these findings are \nfurther compared with results found in other case studies contained within \nthis volume. Finally, we offer a characterization of the platform-specific \nand cross-platform trends, and a qualification of the role junk news plays \nin Dutch political news coverage.\nThe BuzzFeed method: results so far\nThe two aforementioned journalistic analyses that have investigated discourse on Facebook in the context of national elections serve as a \n2 T ransl. from Dutch: \u2018de statenverkiezingen hadden een sterke nationale component\u2019 \n(Hietbrink and van Voorst, 2011: 6).\n74 STiJn P eeTeR S  and Richa Rd R oge R S \nmethodological starting point here. These are BuzzFeed News \u2019 landmark \nreport into \u2018fake news\u2019 in the lead-up to the US presidential elections of \n2016, and the NRC Handelsblad \u2019s study of news shared on Facebook around \nthe Dutch parliamentary elections of 2017, which was inspired by BuzzFeed \nNews \u2019 report and to a large extent employed the same method.\nBoth of these studies used BuzzSumo, a commercial content aggregation \nand analysis platform, to track the most engaged-with articles shared on \nFacebook in the chosen time period. BuzzSumo defines \u2018engagement\u2019 as a \n\u2018sum of likes, comments, and shares attributed to an article\u2019 (Lee, 2019). If the \narticle is shared in multiple places (e.g., in multiple groups), the engagement \nscore represents the sum of all engagement that BuzzSumo has gathered \nfrom the platform. After capturing this data through BuzzSumo, both \nBuzzFeed News  and the NRC Handelsblad  categorized the results as of one of \ntwo categories, \u2018mainstream\u2019 and \u2018fake news\u2019. This simple typology has the \nadvantage of providing clear results, though is potentially limited through \nits lack of nuance in terms of distinguishing between disinformation, con -\nspiracy, clickbait, and hyperpartisan (as discussed in the introduction to \nthis volume), or related terms as problematic information, misinformation \nand mal-information.\nWe adopt this basic method for our case study, but some refining is offered \nas the original description could be said to lack specificity in some areas. \nParticularly, with regards to what BuzzFeed News  considers \u2018fake\u2019, the report \nis somewhat ambiguous, but it does provide the source list in the form of \nopen data. On the one hand, BuzzFeed News  consistently refers to content \nas either \u2018mainstream\u2019 or \u2018fake\u2019/\u2018false\u2019, implying that all of the content in \nthat category constitutes articles containing untrue information. On the \nother hand, their definition of \u2018fake\u2019 is somewhat expansive in the sense that \nhyperpartisan sites such as Breitbart News  are included in their \u2018fake news\u2019 \ncategory. Either way, the most engaged with content they found primarily \nconsisted of such false stories as the Pope endorsing Donald Trump, Hillary \nClinton selling weapons to ISIS, and a fabricated \u2018leaked email\u2019.\nWhile the NRC Handelsblad\u2019 s study broadly uses the same approach, \nits method differs in how it categorizes the articles it found. Rather than \nfocusing on \u2018fake\u2019/\u2018false\u2019 news, the NRC Handelsblad  uses a broader category \nof \u2018news that is taken out of context, strongly politically coloured, or has a \nstrongly exaggerated headline\u20193 (Kist and Zantingh, 2017). Approximately \n10% of the content they found fit this description. This would include \n3 T ransl. from Dutch: \u2018nieuws [dat] uit zijn context werd gehaald, sterk politiek gekleurd werd \ngebracht of werd voorzien van een sterk aangezette kop\u2019 (Kist & Zantingh 2017).\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  75\nhyperpartisan outlets, even if they do not make false claims in their content. \nTheir report notes that very little of the content they found was actually \nfalse news, or consciously misleading, but that approximately 10% of the \ncontent they found fit the broader description. Crucially, even with this \nbroader definition their \u2018non-mainstream\u2019 category is far smaller than that of \nBuzzFeed News \u2019 findings, and thus the NRC Handelsblad  answers its question \nof whether fake news (\u2018nepnieuws\u2019) plays a role in Dutch elections with a \nresounding \u2018no\u2019. In spite of these different outcomes, in different contexts, \nboth studies follow the same basic methodology of extracting results from \na number of relevant queries from BuzzSumo, which we follow here.\nBuzzFeed News \u2019 method, as described in their report, is relatively straight -\nforward: a list of queries is prepared, engagement for articles matching \nthese articles is extracted from Facebook (via BuzzSumo), the results are \naggregated and divided into three-month periods, results are coded as \neither \u2018fake\u2019 or \u2018mainstream\u2019, and the relative prevalence of both categories is \nplotted over time (Silverman, 2016). More practically, this data was collected \nby BuzzFeed News  by querying BuzzSumo for a number of thematically \nappropriate queries. While no full query list is given, the examples include \nnames of election candidates ([\u201cHillary Clinton\u201d] and [\u201cDonald Trump\u201d]) and \nphrases reflecting topics of debate during the campaign, such as [Clinton \nAND emails]. They also included a number of \u2018known viral lies\u2019 such as \n[Soros AND voting machine]. It should be noted that the latter inclusion \nis somewhat asymmetrical for it means the search for more sensational \nand divisive subject matters is more precise and targeted than the search \nfor mainstream news topics, thereby seeking \u2018fake news\u2019. In any case, the \nquestion of asymmetry is addressed in the case study at hand.\nQuery design: descriptions, issues and party leaders\nDutch provincial elections\nWe follow BuzzFeed News  and the NRC Handelsblad  in their general method \nin terms of query design, querying BuzzSumo in order to find the most \nengaged-with content on Facebook. We compiled a list of queries to search \nBuzzSumo following BuzzFeed News \u2019 approach of mixing names of political \nleaders with issues that were particular to the given election campaign. \nThis method also was used by the 2017 NRC  study which queried \u2018words like \n\u201celections\u201d, \u201cparliament\u201d and \u201cpolls\u201d, and/or the name of a party, party leader, \nand/or widely discussed topics such as \u201chealth care\u201d, \u201cpensions\u201d, \u201cimmigrants\u201d \n76 STiJn P eeTeR S  and Richa Rd R oge R S \nand \u201cEU\u201d\u2019 (Kist and Zantingh, 2017).4 We used the NRC Handelsblad  list as \na starting point and adjusted it to fit the provincial elections rather than \nthe national elections they studied.\nA complication here is the dual local/national focus of the elections. While \ncandidate lists differ per province, in televised debates, national rather than \nlocal party leaders participate, and they can generally be said to dominate \nmedia coverage (though some local broadcasters organize their own debates \nas well). In terms of media coverage, local leaders are simultaneously more \nnumerous (as there are far more local leaders than national leaders) and \nmuch less significant (as news coverage and debates concentrate on national \nleaders). A national focus additionally was particularly apparent in the \n2019 elections as polls indicated the cabinet risked losing a senate majority \nfollowing the elections (Herdersche\u00ea and Meijer, 2019). For this reason, we \nlimited our party-based queries to the last names of the political leaders \nof the parties that currently constitute the Dutch parliament,5 as well as \nthe name of the Prime Minister, representing the national government.6\nAdditionally, we queried a number of political issues that were topics of \ndebate during the election campaign. We looked at the manifestos of the \nlarger Dutch parties and chose three themes that were both significant across \nall parties\u2019 manifestos and had been the topic of media coverage during the \nongoing campaign: [Klimaat] ( climate ), [Migratie] ( migration ), and [EU]. \nFinally, we queried two further general keywords, [verkiezingen] ( elections ) \nand [PS2019], a widely used hashtag and shorthand for the elections at hand.\nThe queries were undertaken to capture the election campaign period \nfrom 18\u00a0February\u00a02019 (the start of the first full week of campaigning, marked \nby the launch of various voting aids and launch events hosted by a number \nof parties) to 5\u00a0March\u00a02019 (five days after the elections), or five full weeks \nafter the start of the campaign for the provincial elections\nEU parliamentary elections\nUsing the same general strategy, another set of queries was made to find \ndiscussion pertaining to the EU parliamentary elections on 23\u00a0May\u00a02019. \nAs parties ran with national lists of candidates in this case, we queried the \n4 T ransl. from the Dutch by the authors: \u2018termen als \u201cverkiezingen\u201d, \u201cTweede Kamer\u201d en \n\u201cpeiling\u201d, en/of de naam van een partij, lijsttrekker en/of veelbesproken onderwerpen als \u201czorg\u201d, \n\u201cAOW\u201d, \u201casielzoekers\u201d en \u201cEU\u201d\u2019 (Kist and Zantingh, 2017).\n5 [ Asscher], [Baudet], [Buma], [Dijkhoff], [Jetten], [Klaver], [Krol], [Kuzu], [Marijnissen], \n[Segers], [Staaij], [Thieme], and [Wilders].\n6 [R\nutte].\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  77\nlead candidates for each party in addition to the current political leaders of \nall parties in the Dutch parliament.7 Querying these again was necessary \nas national leaders played an active role in the election campaign, such as \nwhen Mark Rutte, the VVD Prime Minister, and Thierry Baudet, the leader \nof the FvD, engaged in a televised debate on the eve of the elections.\nWe further queried general election-related phrases, as well as three \nthemes that occurred across multiple parties\u2019 manifestos: climate [klimaat], \nmigration [migratie] and [privacy]. As the elections coincided with a govern -\nment campaign seeking to make voters aware of the dangers of disinforma -\ntion (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties, 2019), we \nalso queried [\u201cfake news\u201d OR fakenews OR nepnieuws OR desinformatie \nOR junknieuws]. Finally, for this election we also queried the names of all \nparties for which one could cast a vote.8\nWe queried these keywords using BuzzSumo, limiting ourselves to articles \nin Dutch, excluding Belgian sources. As with the Dutch provincial elections, \nfor the EU campaign we queried a similar 5-week period between 19\u00a0April \nand 23\u00a0May (election day). Finally, we removed irrelevant results such as \nthose covering various Belgian election campaigns and those resulting \nfrom ambiguous keywords such as [Klaver], the name of a party leader but \nalso the word for clover.\nOutlet coding: fake and/or junk news?\nAn important question here is how one identifies a source as either mainstream or its counterpart, whether fake news, junk news or an -\nother term (such as problematic information). While mainstream appears \nrather straightforward to identify (though that also may shift in time), \nits counterpart is a fuzzier concept. BuzzFeed News described their \u2018fake \nnews\u2019 as emanating \u2018from news websites that only publish hoaxes or from \nhyperpartisan websites that present themselves as publishing real news\u2019 \n(Silverman, 2016). Here both types of sites purport to be \u2018news\u2019, but not in \nthe manner or with the substance that the mainstream publishes, given \ntheir hoaxes or hyperpartisanship, or strong political colour.\n7 [ \u201cDe Graaff\u201d], [\u201cDe Lange\u201d], [\u201cin \u2018t Veld\u201d], [\u201cvan Dalen\u201d], [\u201cvan der Spek\u201d], [\u201cvan der Staaij\u201d], \n[\u201cvan Lanschot\u201d], [Asscher], [Azmani], [Baudet], [Berendsen], [Buma], [Dijkhoff], [Eickhout], \n[Eppink], [Hazekamp], [Hoekstra], [Jetten], [Klaver], [Krol], [Kuzu], [Manders], [Marijnissen], \n[Rutte], [Segers], [Thieme], [Timmermans], [Ton c\u0327a\n], [Wierda], [Wilders].\n8 [ 50Plus], [CDA], [Christenunie OR SGP], [D66], [Denk], [FvD OR \u201cForum voor Democratie\u201d], \n[GroenLinks], [\u201cJezus Leeft\u201d], [PvdA], [PvdD OR \u201cPartij voor de Dieren\u201d], [PVV], [SP], [VVD].\n78 STiJn P eeTeR S  and Richa Rd R oge R S \nAnother notion is \u2018junk news\u2019, and it may be preferred because it avoids \nthe other, historically fraught \u2018fake news\u2019 definition of the \u2018lying media\u2019, but \nis more ontologically flexible, at least as scholars have described it. While \nthis term has been used as a synonym for \u2018fake news\u2019 (Venturini, 2019: 10), \nMarchal et al. (2018) employ it to capture a broader category of content \nthat consists of \u2018various forms of propaganda and ideologically extreme, \nhyperpartisan or conspiratorial news and information\u2019 (2). This then would \ninclude BuzzFeed News \u2019 notion, but also part of the NRC Handelsblad\u2019 s \nbroader category of tendentious sites that may more often comment upon rather than deliver news, as we come to.\nFor their \u2018Junk News Aggregator\u2019, a Facebook junk news scraping project, \nresearchers at the Oxford Internet Institute identified a set of measures to \ndefine what qualifies as junk news, consisting of 1) a lack of journalistic \nstandards; 2) tendentious style; 3) low credibility; 4) clear bias; 5) a mimicry \nof traditional news reporting aesthetics; or 6) aggregating content matching \nthe first five criteria (Liotsou et al., 2019: 3). A source was then considered junk news if it satisfied at least three of the first five criteria, or the sixth. \nHerein lies the flexibility, but also the breadth of the definition that may \nbe suitable for the current analytical purposes in the Dutch case.\nIn its report, the NRC Handelsblad  concluded that propaganda or disinfor -\nmation did not play a significant role in Dutch media. It also distinguished \nbetween mainstream and hyperpartisan sources, where the latter is news \nthat is purposively taken out of context, exaggerated to promote a cause \n(i.e., tendentious) or strongly politically coloured. A number of Dutch outlets \ncan be qualified as both \u2018tendentious\u2019 and strongly politically coloured, \nwhile also being embedded in the Dutch media landscape (and in that \nsense mainstream or mainstreaming). Originally a so-called \u2018shock blog\u2019, \nGeenstijl  describes itself as tendentious, and gave birth to PowNed, a public \nTV broadcaster with a similar signature style. Given its durability and \nlink with the public broadcasting company, GeenStijl  could be considered \nboth tendentious and mainstream, or the hybrid category, tendentious-\nmainstream. Another case that is prominent in the BuzzSumo results we \nfound is The Post Online  (TPO). It is a right-wing media outlet and could fit the \nNRC Handelsblad\u2019 s definition as well as a broader definition of hyperpartisan \nsites as \u2018openly ideological web operations\u2019 (Hermann, 2016). Putting it in the \nsame category as more fringe sites such as Ninefornews (a site promoting \nconspiracies and UFOlogy) or De Dagelijkse Standaard  (a far-right outlet \nthat regularly publishes anti-immigrant articles) would not do justice to \nthe less extreme tone. Thus, we could dub it tendentious-hyperpartisan. \nIn the analyses to follow here we show the results with tendentious as a \nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  79\nseparate category made up of these two sources. In other studies to follow \n(on Twitter), the results are compared when the tendentious-hyperpartisan \nsource is categorized as either tendentious or hyperpartisan (see Niederer \nand Groen, this volume).\nIn the following we employ the fine-grained categorization and con -\ntinuum, distinguishing between \u2018mainstream\u2019, \u2018tendentious\u2019, \u2018hyperpartisan\u2019, \n\u2018conspiracy\u2019 and \u2018clickbait\u2019, occasionally linking the categories, as mentioned. \nThese categories reflect the various sub-types of mainstream, tendentious \nand otherwise lower-quality content discussed in the introductory chapter. \nThis also allows more nuanced categorizations of sites such as GeenStijl  \nand The Post Online. In the following analysis we offer this five-category \ncoding as an addition to the binary OII-based categorization, as a way to \nillustrate the make-up of non-mainstream content found in the data. This \ncategorization resulted from a collaborative coding effort across all case \nstudies found in this volume and provides a more detailed alternative to \nthe binary \u2018fake/junk\u2019 versus \u2018mainstream\u2019 opposition found in, for example, \nthe BuzzFeed News  and NRC Handelsblad  studies.\nIn all we therefore elect not to reduce the sources to fake but rather use \na more inclusive category of \u2018junk news\u2019, but then also pay special attention \nto the tendentious outlets. After identifying the sites using this typology, we \nfurther removed all other sites from the results that were either marginal \nor local. Marginal here refers to sites that received very low engagement \nscores in the BuzzSumo results and were not otherwise notable in terms of \ncontent or overall engagement. We also excluded local news sites, as our main \nconcern for this analysis are outlets with a national or otherwise substantial \nreach; regional outlets conversely typically have a limited audience, and \nour list of \u2018junk\u2019 sites contained more nationally oriented outlets rather \nthan regional ones. This left a \u2018mainstream\u2019 category containing national \noutlets, mostly firmly embedded in the Dutch media landscape, such as \nvarious national newspapers, TV broadcasters and a number of online news \nsites and magazines.\nData analysis: overall and per-query trends\nDutch provincial elections\nWe used the annotated source list (or expert list) to code the results for \nthe BuzzSumo queries, as discussed in more detail below. This allows for a \nper-query observation of the ratio between mainstream and junk sources. \n80 STiJn P eeTeR S  and Richa Rd R oge R S \nNext to these separate analyses we also calculated an average ratio, weighted \nby the relative engagement per category, on both an overall and a per-week \nbasis. While our categorization method is slightly different from BuzzFeed \nNews \u2019, this per-week analysis nevertheless allows for a trend comparison with \nthe results of their over-time analysis of the US 2016 presidential election \ncampaign.\nNotably, the trendline found in our over-time analysis (Figure\u00a02.1) does \nnot match the one in BuzzFeed\u2019s study (see Figure\u00a02.2). While BuzzFeed \nNews\u2019  data saw a clear increase of engagement of fake news in the weeks \nleading up to the elections, in our data junk news stayed relatively constant \nin terms of engagement and even decreased slightly during the last few \nweeks. There are, however, some differences between the two campaigns \nthat complicate a direct comparison. The US election campaign is typically \nfar longer than Dutch election campaigns, especially in this case as the 2019 \nelection was concerned with the provincial states and senate rather than the \nlower house of parliament (typically the most important Dutch election). \nWhile the US campaign was analyzed over a period of 9\u00a0months, the Dutch \ncampaign and hence our data spans five weeks only. Additionally, BuzzFeed \nNews \u2019 data resolution is quite low (one datapoint per three months) while \nours is more fine-grained (one per week).\nNevertheless, even considering these differences it is striking that the \ngraphs indicate rather different dynamics. While the BuzzFeed data points Figure\u00a02.1   Engagemen t of mainstream (blue) and junk-like news (pink) articles \nfound through provincial elections-related BuzzSumo queries, per \nweek, between 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engagement scores have been normalized.\nline graph; visualization by fe derica ba rdelli\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  81\nto a clear ramping up of fake news content as the election date draws near, \nour data is more in line with the NRC Handelblad\u2019 s earlier study and suggests \na more constant but persistent undercurrent of junk news that is a part \nof politically oriented media output. The above data is an aggregate of all \nqueries performed on BuzzSumo, however. While in aggregate there is no \nclear trend, this could be the result of summing up the values, and more \napparent trends exist in the results for individual queries.\nAs can be seen in the overview in Figure\u00a02.3, even on a per-query basis \nthere are few clear trends with regards to the prevalence of junk news \nengagement. There is an interesting uptick in the prevalence of mainstream  \nengagement for a few queries. Most notably, the data for [Segers], the leader \nof ChristenUnie (a centrist Christian party), shows a sharp increase in the \nlast week of the election campaign. This can almost entirely be attributed, \nhowever, to news coverage after  the elections about the implications of the \nelection results for the cabinet, of which Segers\u2019 party is the smallest member. \n(Note the similar uptick for [Jetten], whose D66 party is the second-smallest \ncabinet member.) Another notable bump in mainstream engagement occurs Figure\u00a02.2   T otal Facebook engagement of fake versus mainstream news. Results \nfrom election-related queries on BuzzSumo, for the 20 most-engaged \nwith articles between February and November 2016, per three-month period\nSource: Silverman (2016)\n82 STiJn P eeTeR S  and Richa Rd R oge R S \nfor a number of queries ([PS2019], [Buma], [Kuzu] and [Dijkhoff]) around the \nmiddle of the election campaign. A closer look at the articles responsible \nfor this engagement reveals that this may be an indication of the campaign \ncoming into full swing and hence the increasing media coverage of it. The \noft-quoted and feared BuzzFeed News  pattern of fake news outperforming \nmainstream news is thus not repeated on either an aggregate or query level \nin this case study.Figure\u00a02.3   P er-query engagement of mainstream (blue) and junk (pink) articles \nfound through provincial elections-related BuzzSumo queries, per \nweek, between 18\u00a0February and 25\u00a0March\u00a02019. Engagement scores have been normalized.\nline graphs; visualization by fe derica ba rdelli\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  83\nWhat remains of interest is the relative performance of mainstream and \njunk news on a per-week and per-query level, particularly on a number of \noccasions where junk news briefly outperforms mainstream news in terms \nof Facebook engagement. For queries of politicians, it occurs most notably \nfor [Baudet], [Kuzu] and [Wilders] during the first week of the election \ncampaign, where the dominance of junk news is most pronounced. These \npoliticians all lead relatively fringe parties: Baudet leads the far-right Forum \nvoor Democratie (FvD), Kuzu the left-wing and immigrant-oriented DENK, \nand Wilders is the leader of the far-right Partij voor de Vrijheid (PVV). A \ncloser look at the junk news articles that are responsible for these surges \nshows that in all three cases, these are not articles primarily concerned \nwith the elections themselves but rather coverage of other political issues \n(mostly around climate laws that were being discussed at the time) by \nhyperpartisan outlets like De Dagelijkse Standaard . The relative prevalence \nof this coverage is perhaps an indication that media had not yet started \ncovering the election campaign in earnest, rather than a dominance of \njunk news in election discourse. Overall, while in some individual cases \njunk news outperforms mainstream news, these episodes are outliers and \nrepresent less of an overall trend than one for particular parties. There is \none general exception to this rule, however, and it concerns the query for \n[migratie], or migration, where junk outperforms mainstream for most of \nthe period. Also, [klimaat] or climate, has a week where junk news had \nmore engagement that the mainstream. These are rather polarizing issues, \ndrawing attention from hyperpartisan outlets.\nEU Parliamentary elections\nA trend analysis of the EU parliamentary results (see Figure\u00a02.4) shows a \npattern not too dissimilar to the one found in the provincial elections data, \nsimilarly seeing junk news match the performance of mainstream news \nparticularly in the beginning of the query period. Recall that during the \nprovincial elections campaign junk news performed as well as mainstream \nnews on two occasions. Though this trend is still notably different from the \none found by BuzzFeed News , where junk news overtook mainstream news \ntowards the end of the campaign, it is nevertheless a significant finding that \nsuggests an increasingly robust position for junk news in the Dutch context.\nA closer look at this second week of the EU campaign data shows that \nthe junk news engagement can for a large part be attributed to an article \nin De Dagelijkse Standaard , which discusses a video posted by the political \nparty Denk on their Facebook page, accusing the party of demonizing \n84 STiJn P eeTeR S  and Richa Rd R oge R S \nGeert Wilders (of the PVV party).9 This article\u2019s engagement is responsible \nfor about 36% of that week\u2019s \u2018junk\u2019 engagement, providing a major boost.\nMore generally the relatively high engagement attained by junk sources \ncan in many cases be attributed to a small number of high-performing \narticles. This matches the findings from the analysis of the provincial elec -\ntions, where peaks in junk news engagement could similarly be attributed \nto a smaller number of well-scoring articles. While junk sources perform \nrelatively well, especially in the earlier weeks of the data set, this success is \nthus attributable to a relatively small number of sources and articles rather \nthan a broadly successful and diversified ecosystem or even a coordinated \ncampaign.\nThough the findings do not approximate those in the BuzzFeed News  story, \nin the case of the EU election campaign it is noteworthy that indeed junk \nnews does on one occasion match the performance of mainstream news, \nthough not during the tail end of the campaign period as was the case in \nthe BuzzFeed News  data. Overall, junk news is roughly as successful during \nthe EU campaign as it was during the provincial election campaign, and \nhas a significant presence, though over the whole campaign mainstream \nnews still easily outperforms it.\n9 \u2018 Video! Kuzu (DENK) wil dat Wilders gestopt wordt, voordat hij een tweede Srebrenica-\nbloedbad kan aanrichten\u2019: https://www.dagelijksestandaard.nl/2019/05/video-kuzu-denk-wil-\ndat-wilders-gestopt-wordt-voordat-hij-een-tweede-srebrenica-bloedbad-kan-aanrichten/Figure\u00a02.4\n  Engagemen\nt of mainstream and junk-like articles found through EU \nelections-related queries on BuzzSumo, between 19\u00a0April\u00a02019 and \n23\u00a0May\u00a02019. Engagement scores have been normalized.\nline graph; visualization by fe derica ba rdelli\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  85\nFigure\u00a02.5   P er-query engagement of mainstream (blue) and junk (pink) articles \nfound through EU parliamentary election-related BuzzSumo queries, \nper week, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalized.\nmainstrea m news\njunk news\n(EU)0600120023/05/19\n17/05\n10/0503/0526/04de Graaff23/05/19\n17/05\n10/0503/0526/0406001200 de La nge\n23/05/19\n17/05\n10/0503/0526/0406001200 De G roenen23/05/19\n17/05\n10/0503/0526/0406001200 fake news O R \nfakenews\n23/05/19\n17/05\n10/0503/0526/0406001200 Foru m voor\nDemocratie O R FvD \n23/05/19\n17/05\n10/0503/0526/0406001200 Jezus L eeft23/05/19\n17/05\n10/0503/0526/0406001200 van Da len\n23/05/19\n17/05\n10/0503/0526/0406001200 van La nschot23/05/19\n17/05\n10/0503/0526/0406001200 van der Sta aij\n23/05/19\n17/05\n10/0503/0526/0406001200 50plus23/05/19\n17/0510/0503/0526/0406001200 Azmani23/05/19\n17/0510/0503/0526/0406001200 Baudet23/05/19\n17/0510/0503/0526/0406001200 Berendsen23/05/19\n17/0510/0503/0526/0406001200 Buma\n23/05/19\n17/0510/0503/0526/0406001200 CDA23/05/19\n17/0510/0503/0526/0406001200 D66\n23/05/19\n17/0510/0503/0526/0406001200 Dijkhoff23/05/19\n17/0510/0503/0526/0406001200 EU OR Eur opa\nOR23/05/19\n17/0510/0503/0526/0406001200 EUverkie-\nzingen2019\n23/05/19\n17/0510/0503/0526/0406001200 Eickhout23/05/19\n17/0510/0503/0526/0406001200 Eppink23/05/19\n17/0510/0503/0526/0406001200 Hazek amp23/05/19\n17/0510/0503/0526/0406001200 Hoekstra23/05/19\n17/0510/0503/0526/0406001200 Jetten\n23/05/19\n17/0510/0503/0526/0406001200 Klaver23/05/19\n17/0510/0503/0526/040500100015003000\nKuzu\n23/05/19\n17/05\n10/0503/0526/0406001200 Segers\n23/05/19\n17/0510/0503/0526/0406001200 Manders23/05/19\n17/0510/0503/0526/0406001200 Marij nissen\n23/05/19\n17/0510/0503/0526/0406001200 PVV\n23/05/19\n17/0510/0503/0526/0406001200 PvdA23/05/19\n17/0510/0503/0526/0406001200 Thieme23/05/19\n17/0510/0503/0526/0406001200 Timmermans23/05/19\n17/0510/0503/0526/0406001200 Ton\u00e7a23/05/19\n17/05\n10/0503/0526/0406001200 Wilders23/05/19\n17/05\n10/0503/0526/0406001200 Denk\n23/05/19\n17/05\n10/0503/0526/040500100015002500\nGroenL inks\n23/05/19\n17/05\n10/0503/0526/0406001200 klimaat23/05/19\n17/05\n10/0503/0526/0406001200 privacy\n23/05/19\n17/05\n10/0503/0526/0406001200 Rutte23/05/19\n17/05\n10/0503/0526/0406001200 VandeR egio\nOR P iraten-\npartij23/05/19\n17/05\n10/05\n03/0526/0406001200 verkiezinge n\n23/05/19\n17/05\n10/0503/0526/0406001200 Volt23/05/19\n17/05\n10/0503/0526/0406001200 in 't Veld\n23/05/19\n17/05\n10/0503/0526/0406001200 Asscher\n23/05/19\n17/0510/0503/0526/0406001200 Christenu nie\nOR SGP23/05/19\n17/0510/0503/0526/0406001200 Krol23/05/19\n17/0510/0503/0526/0406001200 SP\n23/05/19\n17/0510/0503/0526/0406001200 Wierda23/05/19\n17/05\n10/0503/0526/0406001200 PvdD OR\nPartij v oor \nde Dieren23/05/19\n17/0510/0503/0526/0406001200 VVD\nline graphs; visualization by fe derica ba rdelli\n86 STiJn P eeTeR S  and Richa Rd R oge R S \nCharacterizing sources\nIt is useful here to briefly discuss the sites that make up both categories of \ncontent. Our category of mainstream outlets (see Table\u00a02.1) consists of well-\nknown outlets with a national reach, which in practice translates to a number \nof national newspapers, public broadcasting organizations, national TV \nprogrammes and large online magazines. The junk category is comparatively \nmore diverse; the typology we use covers conspiracy sites, hyperpartisan \nonline sources (including independent self-styled journalists), and clickbait \naggregators. Some of these are relatively large: De Dagelijkse Standaard , a far-\nright weblog, appears in the top three of most engaged-with articles for 15 of \nour 19 queries. Some other junk sites appear to be more focused on a particular \ntopic; this is especially apparent in the results for the provincial elections \n[Migratie] ( migration ) query, in which fenixx.org \u2013 a far-right extreme site \nadvancing the \u2018race replacement\u2019 theory \u2013 appears often, while it is far less \nprominent for the other queries, save for the [EU], in which it also appears \noccasionally. This site was also noted by the earlier 2017 NRC Handelsblad  \nstudy as being especially prevalent in their \u2018hyperpartisan\u2019 category.\nThis \u2018hyperpartisan\u2019 category can then be seen to be comprised of roughly \nthe same set of sites in both data sets (see Table\u00a02.1 and 2.2). This could be \nconsidered to suggest a hyperpartisan news ecosystem of sites that enjoy a \nsignificant and stable readership. On the other hand, this ecosystem is notably \ntop-heavy; for both data sets De Dagelijkse Standaard  (DDS) is by far the most \nengaged-with site, almost four times as popular as the next site in the list. \nFollowing DDS  is a number of far smaller but simultaneously more outspokenly \nfar-right blogs such as Stop de Bankiers, Fenixx  and JD Report . Fenixx  here is \nfurther notable as a site that was also mentioned as a relatively prominent \njunk site in the 2017 NRC study. While we can thus identify a stable sphere \nof hyperpartisan news sites that drive significant engagement, the success \nof this sphere is still mostly reliant on De Dagelijkse Standaard , and with the \nexception of that site is quite marginal compared to the mainstream sphere.\nAs discussed above, an alternative to the binary mainstream/junk op -\nposition one may consider the data for both election campaigns in terms of a \nmore detailed five-category perspective (see Figures 2.5 and 2.6). For both the \nprovincial and EU elections it is apparent that the largest non-mainstream \ncategory by far consists of hyperpartisan sources. The only other category \nthat has a noteworthy impact are tendentious sources GeenStijl  and The \nPost Online  (which are both not included in the other, binary, categorization \nin Figures 2.1 and 2.4). Conspiracy and clickbait sources are present in the data but do not play a significant role compared to the other categories.\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  87\nTable\u00a02.1   T op 10 sites per category (provincial elections), for all queries combined, \nsorted by overall engagement scores as reported by BuzzSumo\nMainstream Junk news\nSite Engagement Site Engagement\ntelegraaf.nl 102117 dagelijksestandaard.nl 98414\nnu.nl 46962 stopdebankiers.com 26429\nrtlnieuws.nl 46849 fenixx.org 13024\nwnl.tv 39975 jdreport.com 8564\nnos.nl 37319 ninefornews.nl 5975\nnrc.nl 16010 tpook.nl 4431\nmetronieuws.nl 14746 ejbron.wordpress.com 4126\npauw.bnnvara.nl 10130 opiniez.com 2777\nevajinek.kro-ncrv.nl 7412 dlmplus.nl 2110\nTable\u00a02.2   T op 10 sites per category (EU parliamentary elections), for all queries \ncombined, sorted by overall engagement scores as reported by BuzzSumo\nMainstream Junk news\nSite Engagement Site Engagement\ntelegraaf.nl 232327 dagelijksestandaard.nl 225006\nnu.nl 192962 stopdebankiers.com 46892\nnos.nl 141440 fenixx.org 25852\nrtlnieuws.nl 99820 tpook.nl 17453\nwnl.tv 91211 jdreport.com 9199\nelsevierweekblad.nl 31150 opiniez.com 8302\nmetronieuws.nl 28038 ejbron.wordpress.com 6427\nnrc.nl 27195 reactnieuws.net 5565\njoop.bnnvara.nl 22509 ninefornews.nl 2047\nTable\u00a02.3   T op 10 \u2018hyperpartisan\u2019 sites for both data sets (provincial and EU \nelections), sorted by overall engagement scores as reported by BuzzSumo\nDutch provincial elections EU Parliamentary elections\nSite Engagement Site Engagement\ndagelijksestandaard.nl 168668 dagelijksestandaard.nl 225006\nstopdebankiers.com 35414 stopdebankiers.com 46892\nfenixx.org 20757 fenixx.org 25852\njdreport.com 15679 jdreport.com 9199\nejbron.wordpress.com 5285 opiniez.com 8302\ndailypaper.org 4887 ejbron.wordpress.com 6427\nopiniez.com 4554 reactnieuws.net 5565\ndestaatvanhet-klimaat.nl 3912 xandernieuws.net 2009\npallieterke.net 3228 eunmask.wordpress.com 1296\neunmask.wordpress.com 2487 novini.nl 862\n88 STiJn P eeTeR S  and Richa Rd R oge R S \nFigure\u00a02.6   Engagemen t of mainstream, hyperpartisan, conspiracy and clickbait \narticles found for provincial elections-related queries on BuzzSumo, \nbetween 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engagement scores have been normalized. GeenStijl is considered \u2018mainstream\u2019 here, while The Post Online is classified as \u2018hyperpartisan\u2019 .\nline graph; visualization by fe derica ba rdelli\nFigure\u00a02.7   Engagemen t of mainstream, tendentious, hyperpartisan, conspiracy \nand clickbait articles found for provincial elections-related queries on BuzzSumo, between 18\u00a0February\u00a02019 and 25\u00a0March\u00a02019. Engagement scores have been normalized. GeenStijl and The Post Online are considered \u2018tendentious\u2019 here.\nline graph; visualization by fe derica ba rdelli\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  89\nFigure\u00a02.8   Engagemen t of mainstream, tendentious, hyperpartisan, conspiracy \nand clickbait articles found for EU parliamentary elections-related \nqueries on BuzzSumo, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalized. GeenStijl is considered \u2018mainstream\u2019 here while The Post Online is classified as \u2018hyperpartisan\u2019 .\nline graph; visualization by fe derica ba rdelli\nFigure\u00a02.9   Engagemen t of mainstream, tendentious, hyperpartisan, conspiracy \nand clickbait articles found for EU parliamentary elections-related queries on BuzzSumo, between 19\u00a0April\u00a02019 and 23\u00a0May\u00a02019. Engagement scores have been normalized. GeenStijl and The Post Online are considered \u2018tendentious\u2019 here.\nline graph; visualization by fe derica ba rdelli\n90 STiJn P eeTeR S  and Richa Rd R oge R S \nAn examination of the most engaged-with sites in the hyperpartisan \ncategory (see Table\u00a02.3) further confirms that this category is the most \ninfluential one in the broader \u2018junk\u2019 (or \u2018junk-like\u2019) sphere, with the top ten \nsites mostly matching those found in the top 10 of \u2018junk\u2019 sites identified in \ntables\u00a01 and 2. The top five is similar on all lists, and again De Dagelijkse \nStandaard  is the most important site. Notably, as the campaign draws on, \nmainstream engagement can be seen to increase while junk news perfor -\nmance is relatively stable, meaning interest in mainstream news coverage \nincreases towards the end of a political campaign, while junk news remains \nstable. Perhaps they serve different publics, though such a construal would \nrequire further work.\nGenerally, the junk news sites, of which hyperpartisan sites are the largest \nconstituent, can be characterized as on the right, anti-immigrant, anti-EU \nand in some cases anti-Semitic or advancing conspiracy theories (the latter \nespecially applying to ninefornews.nl and jdreport.com). This ideological \nslant in our findings is consistent with other studies on junk news, including \nthe 2016 BuzzFeed News  analysis but also others that found that left-wing \ncontent was less prominent in that category (Silverman, 2016; Neudert et \nal., 2017: 1; Alcott and Gentzkow, 2017: 223). In this case study, next to the \nprevalence of hyperpartisan sites such as DDS  the relatively large engagement \nof especially conspiracy sites is notable; ninefornews.nl, which is the 5th-\nmost engaged with site in our data, regularly promotes conspiracy theories \nranging from UFO sightings to such far-fetched concoctions as Pizzagate and \nQAnon. The authors seem to be convinced that this is accurate accounting \nof events. Overall, the data show that junk news, consisting primarily of \nhyperpartisan and conspiracy theory sites, are a minor but constant and \nsignificant factor.\nA cross-platform appraisal\nThis case study focuses on Facebook, but a similar analysis may be performed \nfor other platforms. While Facebook has the dubious honour of being the \nplatform with perhaps the strongest association with fake news, other \nplatforms have their own affordances that could make them attractive for \nthose seeking to spread forms of junk content. Just as this case study builds on \nthe analyses of BuzzFeed News \u2019 and the NRC Handelsblad \u2019s, with a number of \nmethodological tweaks, one could similarly move to other platforms as well, \nstudying over-time engagement of junk and mainstream content respectively. \nMultiple case studies in this volume employ a method of this type.\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  91\nThe multiple platform analyses present an opportunity not only to \ninvestigate the prevalence of junk news on individual platforms, but also \nto perform a cross-platform analysis in order to investigate whether there \nare platforms that are particularly susceptible to junk content, or whether \nsome platforms have perhaps succeeded in combating the spread of it, given \nthat the phenomenon has been addressed for some time now, and the case \nstudies in question take place in early to mid-2019. While we present such \na comparison in this section, it should be noted that a direct comparison \nbetween platforms is complicated for a number of reasons.\nOne issue with a comparison between various platforms is that \u2018engage -\nment\u2019 means different things depending on the features a platform offers for interacting with content. On Facebook, engagement means the sum of \ncomments, likes (or reactions) and shares a post received. But Reddit, for \nexample, has no direct counterpart to some of those, as \u2018shares\u2019 are not a \nrelevant concept on that platform. It simultaneously offers metrics Facebook \ndoes not use (including upvotes and downvotes). Moreover, on Facebook \na dislike or angry reaction, for example, often would be counted as a plus engagement, whereas a downvote on Reddit reduces a post\u2019s score.\nMore specifically, the case studies in this collection use different time \nperiods and, in some cases, investigate, apart from election issues and \nleaders, certain polarized topics (such as MH17 and Zwarte Piet) so as to \nseek disinformation or junk, as we discussed above in terms of asymmetrical \nquerying. Such query design may be justified, given that previous studies of disinformation in the Dutch media context were borne of data curated by Twitter that consisted of Russian IRA trolls, and found activity around \nthe downing of the MH17 airliner in 2014 as well as the terrorist attacks \nin the Brussels airport and metro in 2016. When examining on Twitter \nthe MH17 hashtag and keyword usage over the past number of years, one \nmay find increased activity around elections (such as during the national \nelections of 2017), thus further justifying a renewed attention towards at \nleast MH17 during the 2019 elections. Such asymmetrical querying of course \ncomplicates comparisons, as the ratio between mainstream and junk news \nengagement may be less balanced, given conspiracy and other sources\u2019 \ncontinual attention to such themes. Differences in time periods also pose issues, as there may be particularly \u2018junk-sensitive\u2019 episodes from the past \nthat are missing from the current analyses, and for analytical purposes \nhave been removed from the comparison.\nNevertheless, provided one is aware of the limitations in such a com -\nparison, the results of such an analysis for other platforms compared to the \nFacebook case study can provide an impression of the relative penetration of \n92 STiJn P eeTeR S  and Richa Rd R oge R S \njunk across different social media platforms. While in the rest of this volume \nthere are separate case studies that investigate the individual platforms with \nmethods similar to this one, the graphs above present a rough impression \nof the results across platforms, using data from this chapter and the other case studies.\nWhat is striking in the cross-platform comparison of results in Figures 2.10 \nand 2.11 is that the two \u2018mainstream\u2019 social platforms, Facebook and Twitter, \nshow a higher prevalence of junk content than 4chan and Reddit, the deep \nvernacular web platforms. This is interesting because the latter two \u2013 the \n\u2018seedy underbelly\u2019 of the internet (Bergstrom, 2011) \u2013 are often characterized \nas hotbeds of polarizing and alt-right political discussion, thus providing an Figure\u00a02.10   Rela tive engagement of content categories across 4chan /pol/, Reddit, \nTwitter and Facebook. GeenStijl is considered \u2018mainstream\u2019 here while \nThe Post Online is classified as \u2018hyperpartisan\u2019 . 4chan and reddit data from 1 Dec 2015 until 1\u00a0June; Twitter and Facebook data from 18 Feb 2019-25 Mar 2019 and 19 Apr 2019-23\u00a0May\u00a02019\nFigure\u00a02.11   Rela tive engagement of content categories across 4chan /pol/, Reddit, \nTwitter and Facebook. 4chan and reddit data from 1 Dec 2015 until 1\u00a0June; Twitter and Facebook data from 18 Feb 2019-25 Mar 2019 and 19 Apr 2019-23\u00a0May\u00a02019\n\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  93\nenvironment where one could expect particularly hyperpartisan content \nto thrive.\nOne plausible explanation of this is that especially on 4chan\u2019s /pol/, the \n\u2018politically incorrect\u2019 sub-forum that was investigated in this case, those \nposting may position themselves in opposition to mainstream sources. \nThis positioning often goes hand in hand with linking to the sources in \nquestion, thus increasing the share of mainstream content in the overall \npicture for the platform. As such it underlines the notion that engagement \ndoes not necessarily indicate that one agrees with the engaged-with content, \nand in fact high engagement may be taken to indicate controversiality, as \nsomething polarizing that is hotly debated can be expected to be clicked \non and scrutinized by many of those posting about it.\nAs discussed, a detailed cross-platform comparison is complicated by \nthe different methods used in each case study. While outside the scope of \nthis research, further commensuration of these methods and results for a \nmore thorough cross-platform analysis presents an opportunity for further \nresearch.\nConclusions: Absence of disinformation and junk news prevalence\nThis particular case study, focused on Facebook, is informed by similar \ninvestigative (data) journalism originating with BuzzFeed News  and the \nNRC Handelsblad. Our results are not strictly in keeping with theirs. It is of \nparticular interest that the prevalence of intentionally false news BuzzFeed \nNews  found was not apparent in our data, indicating that this is far less of a \nproblem in the Dutch sphere than in the US. The data do seem to confirm \nthe reputation of Facebook as an especially fertile ground for junk news in \ncomparison to other platforms and indicates that despite its initiatives to \ncombat such content, it is still endemic on the platform. In fact, whereas the \nNRC found that \u2018at most 10%\u201910 (Kist and Zantingh, 2017) of the engagement \nthey analyzed concerned hyperpartisan and tendentious content, in our \nanalysis a little over a year later we find this share has risen to 25%.\nWhile this difference between our findings and the NRC Handelsblad \u2019s \ncould partially be explained by the differences in the criteria used to catego -\nries the content, it seems justified to conclude that even if junk news is in the \nminority, it is certainly not marginal, and seems to be a growing product in \nthe Dutch media landscape, on some occasions matching the performance \n10 T ransl. from Dutch by authors of \u2018hoogstens 10\u00a0procent\u2019 (Kist & Zantingh, 2017).\n94 STiJn P eeTeR S  and Richa Rd R oge R S \nof mainstream news in terms of Facebook engagement. Though this case \nstudy is limited to the 2019 provincial and EU elections, its findings suggest \nthat a broader analysis of junk coverage of Dutch politics on Facebook is \nwarranted. Such an analysis could also investigate what \u2018engagement\u2019 means \nin practice; as indicated by the cursory cross-platform analysis, engagement \nmay not translate to agreement, and if junk news is such a factor on Facebook \nit is important to understand the motivations behind engaging with it if \nwe are to understand the significance of it in the wider political debate.\nA silver lining (so to speak) is that there was virtually no outright (foreign) \ndisinformation in the data we found, and indeed across all platforms we \ninvestigated. While especially on Facebook there is a solid undercurrent of \njunk sites including hyperpartisan content, and a number of well-shared \nconspiracy sites which promote highly dubious content, there is no imminent \nreason to expect so-called fake news affecting Dutch election coverage in \nthe same way it appeared to for the 2016 US elections. Overall, our Facebook \ncase study indicates that there is no immediate cause for concern about \ndisinformation about Dutch elections, but that junk news is a growing \nfactor that warrants closer scrutiny.\nReferences\nAllcott, Hunt and Matthew Gentzkow (2017) \u2018Social Media and Fake News in \nthe 2016 Election\u2019, Journal of Economic Perspectives , 31(2): 211-236. https://doi.\norg/10.1257/jep.31.2.211\nBergstrom, Kelly. 2011. \u2018\u2018Don\u2019t Feed the Troll\u2019: Shutting down Debate about Com -\nmunity Expectations on Reddit.Com\u2019, First Monday , 16(8). https://doi.org/10.5210/\nfm.v16i8.3498\nFink, Christina (2018) \u2018Dangerous Speech, Anti-Muslim Violence, and Facebook in \nMyanmar\u2019, Journal of International Affairs  71(1.5): 43-52.\nGlowacki, Monika, Vidya Narayanan, Sam Maynard, Gustavo Hirsch, Bence Kollanyi, \nLisa-Maria Neudert, Phil Howard, Thomas Lederer, and Vlad Barash (2018) \u2018News \nand Political Information Consumption in Mexico: Mapping the 2018 Mexical \nPresidential Election on Twitter and Facebook,\u2019 2018.2, COMPROP Data Memo. \nOxford: Oxford Internet Institute.\nGuess, Andrew, Brendan Nyhan and Jason Reifler (2018) \u2018Selective Exposure to \nMisinformation: Evidence from the consumption of fake news during the 2016 \nU.S. presidential campaign\u2019, Report, Hannover, NH: Dartmouth College, https://\nwww.dartmouth.edu/~nyhan/fake-news-2016.pdf.\nPoli Ti cal ne W S  on fa cebook du Ri ng Th e 2019 duTc h elec Ti onS  95\nHaque, Md Mahfuzul, Mohammad Yousuf, Zahedur Arman, Md Main Uddin Rony, \nAhmed Shatil Alam, Kazi Mehedi Hasan, Md Khadimul Islam, and Naeemul \nHassan (2018) \u2018Fact-Checking Initiatives in Bangladesh, India, and Nepal: A \nStudy of User Engagement and Challenges\u2019, ArXiv:1811.01806 [Cs] , November. \nhttp://arxiv.org/abs/1811.01806.\nHerdersche\u00ea, Gijs and Remco Meijer (2019) \u2018Kabinet krijgt bitter voorproefje van \nregeren zonder meerderheid in Eerste Kamer\u2019, de Volkskrant , January\u00a031. https://\nwww.volkskrant.nl/gs-b378d420.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August. https://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHietbrink, Niek and Evert van Voorst (2011). Regionale media: oog en oor voor de \nprovinciale democratie?  Zwolle: Hogeschool Windesheim.\nHughes, Taylor, Jeff Smith and Alex Leavitt (2018) \u2018Helping People Better Assess the \nStories They See in News Feed with the Context Button | Facebook Newsroom\u2019, \nFacebook Newsroom  (blog). April. https://newsroom.fb.com/news/2018/04/\nnews-feed-fyi-more-context/\nJohnson, Brett G. and Kimberly Kelling (2018) \u2018Placing Facebook\u2019, Journalism Practice \n12(7): 817-33. https://doi.org/10.1080/17512786.2017.1349546\nKist, Reinier and Peter Zantingh (2017) \u2018Geen grote rol nepnieuws in aanloop naar \nverkiezingen\u2019, NRC Handelsblad , 6\u00a0March.\nLee, Alexis (2019) \u2018What Is a \u2018Facebook Engagement?\u2019, BuzzSumo Knowledge \nBase . https://help.buzzsumo.com/faqs-and-troubleshooting/product-faqs/\nwhat-is-a-facebook-engagement.\nLiotsiou, Dimitra, Bence Kollanyi, and Philip N. Howard (2019) \u2018The Junk News \nAggregator: Examining Junk News Posted on Facebook, Starting with the 2018 US \nMidterm Elections\u2019, ArXiv:1901.07920 [Cs] , January. http:/ /arxiv.org/abs/1901.07920.\nMarchal, Nahema, Lisa-Maria Neudert, Bence Kollanyi and Philip N. Howard \n(2018) \u2018Polarization, Partisanship and Junk News Consumption on Social Media \nDuring the 2018 US Midterm Elections\u2019 2018.5, COMPROP Data Memo, Oxford: \nOxford Internet Institute.\nMinisterie van Binnenlandse Zaken en Koninkrijksrelaties (2019) \u2018Campagne \nnepnieuws vandaag van start \u2013 Nieuwsbericht\u2019, Rijksoverheid.nl . March\u00a011. \nhttps://www.rijksoverheid.nl/actueel/nieuws/2019/03/11/campagne-nepnieuws-\nvandaag-van-start.\nMosseri, Adam (2017a) \u2018Working to Stop Misinformation and False News | Facebook \nNewsroom\u2019, Facebook Newsroom,  blog post, April. https://newsroom.fb.com/\nnews/2017/04/working-to-stop-misinformation-and-false-news/.\n96 STiJn P eeTeR S  and Richa Rd R oge R S \n\u2014. 2017b. \u201cShowing More Informative Links in News Feed | Facebook Newsroom.\u201d \nFacebook Newsroom , blog post, June\u00a030. https://newsroom.fb.com/news/2017/06/\nnews-feed-fyi-showing-more-informative-links-in-news-feed/\nShead, Sam (2019) \u2018Facebook Reacts to Live-Streamed Footage of the Deadly New \nZealand Mass Shooting That Was Posted on Its Platform\u2019, Business Insider Aus -\ntralia , March\u00a015. https://www.thisisinsider.com/facebook-responds-to-alleged-\nlive-stream-of-christchurch-shooting-2019-3.\nSilverman, Craig, J. Lester Feder, Saska Cvetkovska and Aubrey Belford (2018) \n\u2018Macedonia\u2019s Pro-Trump Fake News Industry Had American Links, And Is Under \nInvestigation For Possible Russia Ties\u2019, Buzzfeed News , 18\u00a0July.\nVenturini, Tommaso (2019) \u2018From Fake to Junk News, the Data Politics of Online \nVirality\u2019, in Didier Bigo, Engin Isin, and Evelyn Ruppert (eds), Data Politics: \nWorlds, Subjects, Rights . London: Routledge. https://hal.archives-ouvertes.fr/\nhal-02003893.\nWieringa, Maranke, Tim de Winkel and Callum Lewis (2017) \u2018Wie is de waakhond \nop sociale media?\u2019, report, Utrecht: Utrecht Data School.\nAbout the authors\nStijn Peeters  is a postdoctoral researcher at the University of Amsterdam, \nworking on the ODYCCEUS Horizon 2020 project. In 2018 he completed his \nPh.D. research on the platform histories of Twitter and IRC at King\u2019s College \nLondon. His research focuses on platform history and the development of \ndigital research protocols and tools.\nRichard Rogers  is Professor of New Media & Digital Culture at the Univer -\nsity of Amsterdam and Director of the Digital Methods Initiative, the group \nresponsible for social media research tools. Among other works, Rogers is \nauthor of Information Politics on the Web  (MIT Press, 2004), Digital Methods  \n(MIT Press, 2013), and Doing Digital Methods (Sage, 2019).\n3 P olitical news in search engines\nExploring Google\u2019s susceptibility to hyperpartisan sources \nduring the Dutch elections\nGuill\u00e9n Torres and Richard Rogers1\nAbstract\nThe research enquires into the susceptibility of Google\u2019s search engine \nto provide users with questionable information when querying political \nparties and their issues during the run-up to the Dutch provincial and \nEuropean parliamentary elections. Which rankings has the search engine \nassigned to problematic sources when querying political parties and \ntheir issues? Are there particular political issues and party spaces where \nthese sources are prevalent or entirely absent? Do the ranks and amounts \nincrease as the elections draw near? In all, it was found that hyperpartisan \nsources are rather pervasive in the search-demarcated political space, \nbut far more so for certain actors and their issues on the far right of the \npolitical spectrum.\nKeywords:  Google Web Search, search engines, elections, social issues, \ndigital methods\nIntroduction: Search engines as junk source space\nAs key entry points to the web, search engines serve as a site for the con -\nsumption of information, including political information, and as such are a \nrelevant space for the study of both the presence of disinformation and junk \nnews as well as approaches to combat it (Bowden, 2016). Although they are \ndescribed in the industry as \u2018organic\u2019, the output of search engines could be \n1 T he research reported here was undertaken in collaboration with Anja Duricic, Lisa Fluttert, \nJames Ingleby and Ziwen Tang.\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch03\n98 gu ill\u00e9n To R ReS  and Richa Rd R oge R S \ntermed manufactured hierarchy (Hindman, 2008; Halavais, 2017). Sources \nare ranked per query, and as such certain ones are offered as more relevant \nthan others, as if naturally. Such ranking practices are often considered \ninscrutable, since search engines generally do not provide a means to save \nand study query results, e.g., through offering an API that enables it or terms \nof service that allow it. In fact, the ranking algorithms are trade secrets \njealously guarded by corporations.\nSince 2009 Google and subsequently other search engines have personal -\nized results, be it for the individual or the place where the search has taken \nplace (Pariser, 2011; Puschmann, 2018). Increasingly engines are thus both \nproviding ranked political information but also tailoring it to user prefer -\nences and/or location (Martens et al., 2018).\nWhen it comes to events, such as elections, search engines become provid -\ners not only of topical but also of timely information. These are particularly \npoignant moments to study the presence of disinformation and junk news. As \ncases in point, there have been occasions when sources that were otherwise \ninsignificantly ranked rose to the top of engine returns during the \u2018breaking \nnews\u2019 period of an event, such as in the immediate aftermath of the Las Vegas \nshootings in 2017, when a 4chan post misidentifying the shooter rose to the \ntop of the results (Robertson, 2017). Google results also prominently linked to \nrumours about the identity of a Texas shooter in 2018 as \u2018a Muslim convert, \nmember of Antifa or Democrat supporter\u2019 (Lomas, 2018). One could point to \nartificial manipulation, such as search engine optimization, as triggering \nthe unexpected rankings and sudden presence of dubious information. \nWith respect to the 4chan post, the gaming of the engine (if that were the \ncause) also may have been maliciously playful, introducing misinformation \nas an act of trolling. In the case of the rumours about the Texas shooter, the \nmanipulation appears to have been hyperpartisan. Both spates of false news \nwere not \u2018corrected\u2019 in the editorial sense of an erratum notice; rather, the dynamically published results are continually algorithmically tweaked so \u2018good information\u2019 is said to ultimately prevail (Waters, 2017).\nIn the study of engine returns and hierarchies (through manual capture \ntechniques) it is often pointed out that top placement matters, since engine \nusers over the years have been browsing fewer and fewer result pages (Jansen \nand Spink, 2003; Dan and Davison, 2016). Thus, in the above examples, the \nsignificance of the location of misinformation, rumour and extreme results \nrelies on findings about how users gravitate to the top results, making them the most consumed and thereby particularly worthy of study. An additional \nresearch strategy for inquiries into junk news presence concerns anticipatory \nsearch, also known as autosuggestion, which drives the user to particular search \nPoli Ti cal ne W S  in Se aRc h engine S  99\nterms. It also has been studied for the offensive associations made by engines, \nsuch as the completion of \u2018are Jews\u2019 with \u2018evil\u2019 (Cadwalladr, 2016). Misogynistic \nautosuggestions also were documented in earlier cases which led to a UN \ncampaign in 2013 discussed in a longer study of \u2018how search engines reinforce \nracism\u2019 (Noble, 2018). Other extremist content has been similarly documented \ntowards the top of Google results for the query \u2018holocaust\u2019 (Hern, 2017).\nThe discovery by The Guardian  journalist of the offensive associations \nwith the word \u2018Jews\u2019 and the resulting sites that surfaced (such as the neo-\nNazi website, The Daily Stormer) have led to discussions of not just how \nGoogle\u2019s algorithms could be tweaked, but also the reach of the sources \nproducing and driving such information in the first place. Their presence \n(and top placement) could be interpreted as a proxy for the significance \nand audience of such material online, or as others have argued as evidence \nof a culture war, driven by the online boosting tactics of \u2018culture hackers\u2019 \n(Albright, 2016; Confessore and Wakabayashi, 2017). Whilst they may seek to \ncorrect the autosuggestions (and perhaps remove religious ones all together), \ncompanies such as Google are hesitant to delist such extreme websites, given \nfree speech concerns, which also may arise if they are nudged downwards.\nThe present chapter studies the susceptibility of Google\u2019s search engine to \nprovide users with questionable information sources in the results for queries \nrelated to Dutch political parties during the Dutch provincial and European \nparliamentary elections of 2019. Our goal is to identify the presence of dubious \nsources in the results for political queries. Thus, the research questions read \nas follows. Which rankings has the search engine assigned to false and junk \nsources when querying political parties and their issues? Are there particular \npolitical issues and party spaces where junk news is prevalent or entirely \nabsent? Do the ranks and amounts increase as the elections draw near?\nWe have divided the chapter into six sections: a brief reflection about \nthe methodological challenges of studying search engines, the methodology \nfor building our dataset, three sets of findings, and a discussion of the \nlimitations and further steps. In all it was found that junk news, specifically \nof the hyperpartisan variety, is rather pervasive in the search-demarcated \npolitical space, but far more so for certain actors and their issues on the far \nright of the political spectrum.\nStudying personalization, junk news, or both?\nThe extent to which autosuggestions are personalized is understudied, \nbut the personalization of results more generally has been the subject of \n100  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nnumerous inquiries and methodological innovations that work around \nGoogle\u2019s inscrutability through selectively scraping results or soliciting data \ndonations. The findings from scraping batch-queried results have shown \nrelatively low amounts of results affected by personalization in the Google \nsearch engine (Feuz et al., 2011), and the same held for Google News (Haim et \nal., 2018), suggesting that original concerns regarding the \u2018filter bubble\u2019 may \nnot be as well founded any longer. Where the second method is concerned, \nAlgorithm Watch, the German NGO, created a browser extension for users \nto install that regularly would make political queries, such as for [\u201cAngela \nMerkel\u201d] (Puschmann, 2017). The results would be donated by the users \nto Algorithm Watch so as to enable a larger number of those under study \nthan is normally the case. Here again the findings have shown low levels \nof personalization, but the study of the presence of certain junk sites (be \nthey disinformation or another genre) could be pursued further. Another \ntechnique, discussed below, is to selectively scrape results in a manner that \nseeks to minimize personalization effects, thereby concentrating on the \noverall presence of junk sites rather than on whether particular users, in a \nfilter bubble, are seeing more of them.\nTo begin to understand the amount and placement of junk news in search \nengine space, be it around events or even after an algorithmic tweak, a query \nroutine is designed, and a window of activity is chosen. (Longer-term studies \nalso may be undertaken, as in the Issuedramaturg project that followed \n9/11 query results for years, but Google often changes its output formats, \nbreaking automated tools (Rogers, 2013).) In order to reduce personalization, \na research browser may be deployed, which is a clean instance of a browser \nwith the user not logged in. City-level geographical personalization may be \navoided through the use of advanced settings, choosing a particular region, \nsuch as the Netherlands. For projects as ours, geographical personalization \nis not viewed as a disadvantage in the sense of creating the conditions for a filter bubble to materialize.\nA brief mention should be made of the search engine under study. Among \nthem Google is the most popular, with the largest market share of users \nin most countries, certainly in the Netherlands. As mentioned above, \nrecently, the company has become entangled in the fake news debate \nthrough the appearance not of Russian disinformation sources (though \nthat to our knowledge has not been studied in great detail), but owing \nfirst to the appearance of misogynistic and extremist content that the \ncompany previously defended as \u2018reflective\u2019 of societal concern rather than \nthe product of algorithmic error or \u2018culture hacking\u2019. If one were to expand \nthe number of search engines under study (to include Bing and Yahoo!, \nPoli Ti cal ne W S  in Se aRc h engine S  101\nfor example), one could triangulate results, and inquire further into the \nnormalcy and regularity of misogynistic and extremist content present in \nthe top results, though one could not control for algorithmic concentration \nor the extent to which the big engines\u2019 algorithms are anyways similar. \nThe extent to which the results reflect societal concern would remain an \nopen question.\nStudying Google results\nThe presence of junk news within Google\u2019s search engine results is a multi-\ncausal phenomenon that may be credited to a number of factors. Among \nothers, Google\u2019s algorithm reacts and learns from users\u2019 own consumption \nof junk sources. It is trained using varied datasets, and content producers\u2019 attempt to game the search engine via search engine optimization tactics \n(Finkel et al., 2017). Given the inscrutability of Google\u2019s tools, it is difficult to \ndetermine what could be causing the presence of junk sources in the Dutch \nweb sphere or others. Here, rather than attempting an explanation for the \npresence of junk news, we conduct a test of the engine\u2019s susceptibility to \nconnect politically relevant queries with junk sources.\nAs noted, the investigation relies on scraping as a method (Marres \nand Weltevrede, 2013), and takes as its point of departure the question of \njunk news in search returns rather than the effect of personalization in \nthe creation of a filter bubble. The research seeks so-called junk news in \nsearch engine results, which has been defined as \u2018extremist, sensationalist, \nconspiratorial and masked commentary\u2019 (Howard et al., 2017: 1). In keeping \nwith Buzzfeed News \u2019 definition of fake news (Silverman, 2016), we also seek \n(foreign) disinformation, hyperpartisan sources as well as clickbait, which \nitself may be extreme. In order to do so we rely on a list of sources expertly \ncurated by other researchers in the project (see the Appendix 6.2 in Hagen \nand Jokubauskaite, this volume).\nGenerally, the research employs the \u2018source distance\u2019 approach, inquiring \ninto how far from the top of the returns are the offending results (Rogers, \n2013). More specifically, we investigate how false and junk webpages are \npositioned in the first twenty Google.nl results of various queries of political \nparties and their most significant issues during the 2019 provincial elections \ncampaign as well as those of the European parliamentary elections. Thus, \nthis case examines the susceptibility of search engine results to junk news, \nas defined above, rather than exploring the issue of falseness and junk in \nthemselves or the effectiveness of countermeasures.\n102  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nEngine returns as political spaces\nIn order to demarcate a political space in search engine results, we designed \na query protocol based on combining the names of political parties with \nspecific issues associated with their respective political agendas. In that \nsense, the underlying assumption is that junk news may have a more \nsignificant impact when discussed in a specific political context, such as \nelection campaigns, when voters gather information to guide their choice. \nTo be able to collect the results of a large number of queries, we used the \nSearch Engine Scraper by the Digital Methods Initiative, a tool that allows \none to scrape search engine results for a given query and commit them to a database for further scrutiny through visualization.\nThe first step of the methodology consisted in constructing a list of Dutch \nparliamentary parties and locating their websites as well as Facebook pages \n(see Table\u00a03.1). Another list was created pertaining to the parties participating \nin the European parliamentary elections. In the next step we identified the \nrelevant keywords to build the queries; in the case of the Dutch provincial \nelections, these were sourced from both the party webpages and the party \nFacebook pages. For the parties competing in the European parliamentary \nelections, only the parties\u2019 own websites were consulted. The party webpages \nprovided the parties\u2019 issue keywords. The Facebook pages furnished a more \nvernacular set of issue terms, as they contain issue keywords from users \nor citizens in the comment space. The aim of sourcing these two sets of \nkeywords is to enable us to capture and compare the results for both official \nas well as more popular issue language.\nThe lists of party keywords were built by collecting the platform stand-\npoints ( standpunten ) on the party websites. There is one list for the provincial \nelections and another for the European parliamentary elections. Most \npolitical parties mention between five and ten keywords on their platforms, \nand all were collected. A few parties (e.g., the Staatkundig Gereformeerde \nPartij , SGP) offer longer lists which were shortened on the basis of their key \nissues. In all, the political party issue space consisted of 158 keywords across \nthe thirteen parties for the provincial elections, and four keywords across \nfourteen parties for the European parliamentary elections. The vernacular \nlist was made through a close reading of the comments made under the \nposts of the Facebook pages of each political party. To build this list, the \nmost commented posts around the days of the elections were close-read, \nand the most representative keywords related to the views expressed by the \ncommenters were chosen. Identifying the most relevant issues in the com -\nment space on Facebook proved to be problematic, given that the comments \nPoli Ti cal ne W S  in Se aRc h engine S  103\nwere often polarizing and emotive, especially those relating to the elections \nthemselves. This citizen-enriched political issue space consisted of five \nkeywords for each of the thirteen parties, making a total of 65.\nTable\u00a03.1   List of D utch political parties under study\nDutch Provincial Elections European Parliamentary Elections\nName of the Party Abbreviation Name of the Party Abbreviation\nVolkspartij voor Vrijheid en \ndem\nocratieVV d V olkspartij voor Vrijheid en \ndem\nocratieVV d\nP\nartij voor de Vrijheid PVV Partij voor de Vrijheid PVV\nch\nristen- de\nmocratisch \na\nppe\u0300lc\nda ch\nristen- de\nmocratisch \nap\npe\u0300l \u2013 \neu\nropese Volkspartijc\nda-eV\ndem\nocraten 66 d\n66 dem\nocraten 66 d\n66\ngro\nenlin\nks gl gro\nenlin\nks gl\nS\nocialistische Partij SP ch\nristen uni\ne \u2013 Staatkundig \nge\nreformeerde Partijc\nu\n \u2013 SgP\nP\nartij van de \nar\nbeid Pvd a P\nartij voor de \ndi\neren Pvd d\nch\nristen un\nie cu 5\n0Plus 50plus\nPartij voor de \ndi\neren Pvd d J\nezus \nl\neeft\n50Plus 50plus de\nnk d\nenk\nS\ntaatkundig \nge\nreformeerde \nPartijS\ngP foru\nm voor \nde\nmocratie fvd\nde\nnk d\nenk V\nan de Regio & Piratenpartij VR \u2013 PP\nforu\nm voor \nde\nmocratie fvd V\nolt \nne\nderland V\nn\nde\n \ngr\noenen gn\nThe three lists of keywords were inputted in the Search Engine Scraper along \nwith the name of each party. The results from the parties\u2019 own websites were \nexcluded. For example, for the political party D66  and the keyword onderwijs \n( e ducation), the following query was made: [onderwijs d66 -d66.nl]. Using \nthe advanced search features of Google, maximum results were set to 1,000, \nand each day of our periods of interest (13-22\u00a0March and 22-24\u00a0May\u00a02019) was \nqueried separately. The date ranges included the run up to the provincial elec -\ntions on 20\u00a0March and a short election aftermath period, and the days before \nand after the European Parliamentary elections on May\u00a023. The searches were \nconducted in a clean browser, in the Dutch Google.nl domain, in the Dutch \nlanguage, and in the Netherlands region (through the advanced settings). The \nkeyword and party were queried together so that the scraper tool delivered \nresults that are related to election politics, rather than a general overview by \nquerying each keyword in isolation. The keywords derived from Facebook \nwere queried in the same format, using the same settings and date range.\n104  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nThe outputs of the Scraper tool are the top twenty ranked Google.nl \nresults per query. The URLs in our lists were then truncated to their host \nnames so that they could be cross-checked with the list of known false and \njunk websites curated by other researchers in the project. Here a formula \nwas used that effectively linked the search engine results spreadsheet to \nthat of the expertly curated list of junk sites. The question for each source \nconcerned its ranking per query and its presence or absence in the expert \nlist. All query results (per party and per official or vernacular language type) \nwere marked as junk sites or not and listed in the order they were returned.\nTable\u00a03.2   List of c ategories and political keywords used in the study\nParty platforms\nfo\nreign affairs Europese Unie, Europa, EU, Nederland en Europa, buitenland, internationale \nzaken\nPolarizing topics Islamisering, Islam \nhealt\nh zorg, menselijke zorg \ne\nnvironment klimaat, natuur, milieu, dierenrechten, natuur en milieu \nfi\nnances belasting, economie, inkomen, pensioen, werk en inkomen, schone economie, eerlijk delen, werklozen, economisch beleid, overheid en bestuur \nSafety and security veiligheid, privacy, defensie, criminaliteit, rechtsstaat, terrorisme \nSociety waarden, gezin, respect, familie, samenleving, burgers, democratie, ouderen, onderwijs, goed onderwijs voor iedereen, vrijheid, verantwoorde\u00adlijkheid, drugs \nfu\nture innovatie, duurzaamheid, schone energie, energie \nMigration immigranten, migratie \nFacebook\nfo\nreign affairs Europa, EU, referendum \nPolarizing topics Islam, Moslim, racisme, discriminatie2 \ne\nnvironment milieu, klimaat, kernenergie, energie \nfi\nnances belasting, bezuinigingen, pensioen, onderwijs \nSociety samenleving, democratie, toekomst crisis, vrouwen, vrijheid, Nederland, armoede \nf\naith Islam, Moslim, Christendom, Christenen, geloof \nMigration migratie, immigranten, gelukszoekers, migranten \n2 I slam is placed in both faith as well as polarizing topics categories, given how it is discussed \nas shorthand for a social issue.\nPoli Ti cal ne W S  in Se aRc h engine S  105\nWe zoomed in on those queries in which junk news showed up consistently, \nthat is, for a minimum of four days within our period of interest for the \nprovincial elections, and two days for the European parliamentary elections. \nThe keywords that produced junk news websites in their search results in \nthe first case were then grouped thematically in the following categories: \n\u2018foreign affairs\u2019, \u2018polarizing topics\u2019, \u2018health\u2019, \u2018environment\u2019, \u2018economy\u2019, \u2018safety \nand security\u2019, \u2018society\u2019, \u2018future\u2019, \u2018migration\u2019 and \u2018faith\u2019, the most salient of \nwhich are described in some detail below (see Table\u00a03.2). For the case of \nthe European parliamentary elections, the four keywords common to all \nparties were queried: Europese Unie [\u201cEuropean Union\u201d], klimaat  [\u201cclimate\u201d], \nmigratie  [\u201cmigration\u201d] and economie [\u201ceconomy\u201d].\nPolitical parties and issue keywords\nBefore analyzing the presence and positioning of junk news in Google \nweb search, we would like to discuss briefly the keywords obtained for the \nprovincial election campaign from the official websites and Facebook pages \nof the political parties. Comparing the composition of the categories that \nemerged from each of the two political spaces allows for showing differences \nbetween the matters of concern as expressed by political parties and citizens \nor social media users. Whereas political parties included keywords that \ncould be grouped under the categories, \u2018future\u2019, \u2018security\u2019, and \u2018health\u2019, that \nwas not the case for the Facebook users. In contrast, \u2018faith\u2019 was present in \nthe Facebook comment space, whereas it was largely absent from the party \nplatforms (except for the SGP, with its long list).3 There are also matters of \nconcern common to citizens and political parties alike, such as \u2018foreign \naffairs\u2019, \u2018economy\u2019, \u2018society\u2019, and \u2018environment\u2019.\nWithin the shared concerns there are still differences between the \nway each political space is constructed by political parties or citizens. For \nexample, within the \u2018foreign affairs\u2019, \u2018economy\u2019 and \u2018society\u2019 categories, \nparties tend to refer to a wider variety of issues in comparison to the concerns \nexpressed by citizens, which are mostly focused on the European Union and \nthe referendum. In the economy cluster, political parties address ten issues, \nwhereas citizens are concerned with far fewer. The same holds roughly for \nthe society cluster. Interestingly, this trend reverses in the environment \ncluster, where users tend to express concerns about nuclear energy, while \n3 I slam was present in the party platforms (largely the PVV and SGP) but discussed in terms \nof a social issue.\n106  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nthe topic is not present in parties\u2019 platforms (again, with the exception of \nSGP). Lastly, even though the usage of some keywords is more or less the \nsame in party platforms and the Facebook comment spaces, for others it \ndiffered, as is the case for onderwijs (education). By the political parties \nit is framed as a societal issue, whereas in the discourse on Facebook it is \ndiscussed in terms of citizens\u2019 ability to afford it.\nVisualizations are made to facilitate the analysis; they show at a glance \nthe presence and ranked position of junk news for each query over time. \nThe columns represent the days in the timeframes studied (13-22\u00a0March or \n22-24\u00a0May\u00a02019). Red cells indicate the source as marked as junk news. One \nalso may read the placement and distribution of it over time.\nPolitical party standpoint space\nThe study of the political party standpoint space found overall that all false \nand junk webpages that appeared can be subcategorized as hyperpartisan. The \none exception fell within the environment cluster in the form of a conspiracy \nwebsite in the top twenty. Three specific websites make up for the biggest \namount of junk: De Dagelijkse Standaard, Stop de Bankiers, and Opiniez.  \nA second general observation is that queries related to right-wing parties \nreturned hyperpartisan sources in a greater proportion than queries related to \nparties with other political orientations. In particular, the queries related to the \nFvD were the most populated by hyperpartisan sources. Thirdly, queries related \nto parties located at the centre of the political spectrum seem to produce \nresults with less questionable sources. In those instances where hyperpartisan \nwebsites appear among the top twenty results for centre-oriented parties, the \nsites mainly do not make it to the top positions (though there were exceptions).\nIn the political party standpoint space, most junk appears to be associated \nwith queries related to keywords within \u2018foreign affairs\u2019 and \u2018polarizing \ntopics\u2019. The keywords within the foreign affairs cluster mainly relate to \nthe European Union and the Dutch relationship with it. Issues related \nto political parties from the centre of the political spectrum seem to be \nleast connected to junk, as may be noted for 50Plus, Partij voor de Dieren \nor D66 (see Figure\u00a03.1). Contrariwise, parties that position themselves \nstrongly against the European Union are linked to a high concentration of \njunk results. For example, when looking at FvD and PVV, we can see that \nhyperpartisan sites account for 37% and 47% respectively of all the returns \ndiscussing the European Union. Moreover, the hyperpartisan sources are \namong the top five results throughout almost the entire time period.\nPoli Ti cal ne W S  in Se aRc h engine S  107\nRegarding the keywords within the \u2018polarizing topics\u2019 cluster (Figure\u00a03.2), \ntwo related issues in the political party-demarcated space lead to search \nengine results with a large amount of hyperpartisan sources: Islam and \nIslamisering (Islamization). These keywords are only discussed by two \nright-wing parties, PVV and SGP, the latter from the religious right. In \nparticular, when PVV is queried together with the keyword Islamisering \n(Islamization), hyperpartisan websites appear at the top of the results \nthroughout the entire time span, occupying even the highest positions. \nThis changes only for three days (16, 19 and 20\u00a0March), when, however, the \namount of junk increases overall.\nThe queries for environmental keywords (Figure\u00a03.3) also lead to sig -\nnificant quantities of junk. First, it is of note that the amount decreased as Figure\u00a03.1   P resence of junk news in Google.nl search engine results for political \nqueries related to foreign affairs, 13-22\u00a0March\u00a02019\nFigure\u00a03.2   P resence of junk news in Google.nl search engine results for political \nqueries related to polarizing topics, 13-22\u00a0March\u00a02019\nPVV - islamisering SGP - Islam Polarizing topics\n13 03 19 22 03 19RANKED\nRESULTSJUNK WEB PAGE 1 DAY\n108  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nthe elections neared, though junk websites still maintained a prominent \nposition among the first 10 results. Once again, queries mentioning right-wing \nparties such as FvD are more prone to produce junk sources within their \nresults. The site, ninefornews.nl, was identified here as the only conspiracy \nwebsite in the entire data set. It emerged in the 8th position when [milieu \nFvD -www.fvd.nl] was queried, meaning that it appears on the first page \nof Google results (with default settings at 10). The centre party, D66, also \nregistered significant amounts of junk for the query climate (klimaat), as \ndid the centre-left labour party (PvdA).\nThe cluster related to economic issues, the second largest in our set of \nresults, contains nine keywords such as belasting (ta xes), eerlijk  delen (fair \nsharing) and werklozen (unemployed) (see Figure\u00a03.4). Queries including \nFvD are once again among the most prone to produce hyperpartisan results, \nparticularly with the keywords economie (economy), pensioen (pension) and \nbelasting (taxes). When examining the remaining parties (with the possible \nexception of the PVV), the number of junk results is relatively low overall, \nand they rarely occupy the first position of the search engine results.\nThe \u2018society\u2019 cluster is the largest; twenty issues were identified in this \ncluster, ranging from concerns about   warden (values) to drugs (see Figure\u00a03.5). \nSocial issues produced a varied distribution of hyperpartisan sources over -\ntime, with hyperpartisan websites appearing less prominently. Only three \nqueries, two including the FvD and one the VVD, stand out in this cluster \nas junk-ridden: drugs, democracy and responsibility ( verantwoordelijkheid ).\nLastly, the thematic cluster, \u2018future developments\u2019 (Figure\u00a03.6), with such \nissues as duurzaamheid (sustainability), innovatie (innovation), and schone \nenergie (clean energy), are addressed by parties located at the extremes of \nthe political spectrum and the query results are populated by hyperpartisan \nsources. This is most evident in the case of FvD, where questionable sources \nappear nearly every day, and in four instances are returned in the top two \npositions, albeit not in close vicinity of election day, which remains largely \nunaffected by junk sources in relation to these terms.\nVernacular political issue space\nBased on the keywords gleaned from the Facebook pages of the Dutch politi -\ncal parties, one new category was created (\u2018faith\u2019) on top of the other six from \nthe previous exercise. Generally, the results were similar. Queries mentioning \nright-wing parties such as PVV and FvD returned more hyperpartisan \nPoli Ti cal ne W S  in Se aRc h engine S  109Figure\u00a03.3   P resence of junk news in Google.nl search engine results for political queries related to the environment, 13-22\u00a0March\u00a02019\n\n110  gu ill\u00e9n To R ReS  and Richa Rd R oge R S Figure\u00a03.4   P resence of junk news in Google.nl search engine results for political queries related to the economy, 13-22\u00a0March\u00a02019\n\nPoli Ti cal ne W S  in Se aRc h engine S  111Figure\u00a03.5   P resence of junk news in Google.nl search engine results for political queries related to societal issues, 13-22\u00a0March\u00a02019\n\n112  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nsources in the top 20 Google results, and the positions of these junk sources \ntend to be higher than in queries related to other parties.\nIn the vernacular political issue space, the foreign affairs cluster received \nthe most junk news returns; nearly 25% of the top 20 results are considered \nhyperpartisan websites. Migration and polarizing topics have the second \nand third highest percentage of junk websites, with 19% and 17% of junk, \nrespectively. Results associated with keywords such as immigranten  (im-\nmigrants) and Islam  were significantly populated with hyperpartisan \nsources. Issues related to environment, society, and finance obtained fewer \njunk returns (less than 10%). The faith cluster had the fewest hyperpartisan \nreturns.4\nThe environment cluster (which for many terms could have been merged \nwith the future innovations one) is the largest one in the vernacular is -\nsue space. In it the keyword  k limaat  ( climate) was discussed by Facebook \nusers on the pages of five different parties, and  m ilieu (environment) on \nthree. For Groenlinks, D66, PvdA and VVD, the keyword klimaat features \nhyperpartisan sources in the top results (see Figure\u00a03.7). From the election \nday onwards, fewer junk websites showed up in the top 20 results. The \nsame pattern was observed in the \u2018foreign affairs\u2019 cluster (see Figure\u00a03.8). \nHyperpartisan websites occupied the first position for five days during our \n10-day research period for queries related to FvD and PVV. Queries for FvD \nand EU were the most likely to return junk webpages.\nRegarding the keywords grouped under the \u2018polarizing topics\u2019 cluster,  \nIslam  was brought up by Facebook users in the pages of four political parties: \n4 H ere again, Islam is excluded, because it is considered a social issue, given the manner in \nwhich it is discussed in the vernacular issue space.Figure\u00a03.6\n  P\nresence of junk news in Google.nl search engine results for political \nqueries related to future innovation, 13-22\u00a0March\u00a02019\n\nPoli Ti cal ne W S  in Se aRc h engine S  113Figure\u00a03.7   P resence of junk news in Google.nl search engine results for political queries related to the environment, using language \nfrom the Facebook comment space of the political parties, 13-22\u00a0March\u00a02019\n\n114  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nPVV, SGP, FvD and DENK.5 Among them, results associated with FvD received \nthe most junk webpage returns in the top 20 results, and hyperpartisan \nresults maintained the first position for seven days (Figure\u00a03.9). On election \nday, however, all the parties returned few to no such results in the cluster of \n\u2018polarizing topics\u2019, with the exception of the FvD. The number of junk sources \nand the rankings dropped dramatically on that day. Concerning DENK, \nalthough queries including it did not return many junk websites overall, \n5 F or the political party, DENK, Islam, while discussed as a social issue, also could be catego -\nrized as \u2018faith\u2019.Figure\u00a03.8\n  P\nresence of junk news in Google.nl search engine results for political \nqueries related to foreign affairs, using language from the Facebook \ncomment space of the political parties, 13-22\u00a0March\u00a02019\nFigure\u00a03.9   P resence of junk news in Google.nl search engine results for political \nqueries related to polarizing topics, using language from the Facebook comment space  of the political parties, 13-22\u00a0March\u00a02019\n\nPoli Ti cal ne W S  in Se aRc h engine S  115\nthey were found in relation to the issues Moslim (Muslim), discriminatie \n(discrimination) and racisme (racism).\nThe migration cluster (Figure\u00a03.10) was more prominent in the discussion \nspace on Facebook pages than in the platforms of the political parties. \nKeywords as migranten (migrants), migratie (migration), immigranten \n(immigrants) and gelukszoekers (fortune seekers) were often mentioned in \nthe comments on the Facebook homepages of political parties. ( Gelukszoekers  \ncould be said to be a pejorative term for economic migrants.) Results for \nthree parties in particular (FvD, PVV and VVD) had junk webpages in the \ntop 10 Google search results, and they were spread evenly over the ten-day \nresearch period. It is also noteworthy to see that there appears to be a \ndecreasing tendency of junk news from the election day onwards in this \ncluster, both in terms of the amount as well as the rankings.\nEuropean Parliamentary Elections\nThe results for the political party standpoint space during the European \nParliamentary elections also show a consistent presence of junk news. \nThree major findings are worth mentioning. Firstly, as figures 11 and 12 \nmake evident, the presence of junk sources in the Google search engine \nresults was lower during the European parliamentary elections than during \nthe provincial elections. In many cases, our queries combining issues with \nparties did not produce links to hyperpartisan material or only did so for \none day. Only  25% of our queries returned junk for more than one day \nduring the three-day period under research. Of the four keywords queried, \nthe one that produced the least amount of junk in combination with party Figure\u00a03.10   P resence of junk news in Google.nl search engine results for political \nqueries related to migration, using language from the Facebook \ncomment space of the political parties, 13-22\u00a0March\u00a02019\n\n116  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nnames was economie (economy). In contrast, migratie was the most prone \nto returning junk, with queries related to five parties consistently returning \njunk websites between May\u00a022 and 24 (see Figure\u00a03.11).\nQueries in combination with the political party DENK were particularly \njunk ridden. On the day of the election and the day after, almost half of the \nresults provided by the Google search engine is problematic. It is particularly \nrelevant that during the 24th of May, hyperpartisan websites occupied the \ntop seven positions.\nA second relevant finding is that the presence of hyperpartisan resources \nis more prevalent on the day after the election than the day before, in contrast \nto what happened during the provincial elections. Although this is the \ncase for all parties and keywords where junk sources were identified, it \nwas especially prominent for the issues of migration, economy and climate \n(keywords migratie , economie  and klimaat ). In most cases, junk sources \nalso occupy the first positions in the results during the 24th of May. We \ncannot answer the question of whether this phenomenon can be credited \nto the Google search algorithms reacting to an increase in searches related \nto the elections, to a surge in the activity of hyperpartisan websites after \nthey took place, or to some combination. A close reading of the results \nin the highest positions, however, shows that the hyperpartisan sources \nbehave as one would expect from any information provider during election \nseason, if only keeping their radical tone; before the election they provide \npredictions about the results, on the day of the election they invite citizens \nto vote, and on the day after they discuss the results. An article by the De \nDagelijkse Standaard  that consistently occupied the top result for various \nkeywords and parties is a reflection about how the FvD and leader Thierry \nBaudet need to tone down their radical discourse in order to become a more \npowerful political force.\nLastly, whereas during the Dutch provincial elections the queries related \nto right-wing parties were more strongly connected by the search engine \nwith junk sources, during the European elections this is not the case. For \nexample, although queries performed in May involving FvD also produced \nresults pointing to hyperpartisan websites \u2013 similarly to the results obtained \nin March \u2013 it was those related to DENK which, in aggregate terms, produced \nmore junk (i.e., 25 for FvD and 27 for DENK). However, the case of DENK \nis difficult to assess given that, apart from the name of a party, it is also a \ncommon Dutch word (\u2018think\u2019, in English). Although this does not change \nthe fact that people looking for information about this party would likely be \nexposed to junk sources, the content may not specifically relate to DENK. In \nfact, the highest-ranking result for the query [migratie DENK -bewegingdenk.\nPoli Ti cal ne W S  in Se aRc h engine S  117\nFigure\u00a03.11   P resence of junk news in Google.nl search engine results for political \nqueries related to migration and European Union issues, 22-24\u00a0May\u00a02019\nFigure\u00a03.12   P resence of junk news in Google.nl search engine results for political \nqueries related to climate and economic issues, 22-24\u00a0May\u00a02019\n\n118  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nnl] is an article in the hyperpartisan website De Dagelijkse Standaard  that \nmakes no specific mention to this party, but instead generally reflects on \nthe results of the elections and specifically on the demise of the PVV.\nConclusions: Junk news in search engine results\nThe goal of this research is to locate the presence and ranking of junk \nwebsites within the first twenty Google.nl results of queries concerning \nDutch political parties and their most significant issues during the 2019 \nprovincial and European parliamentary elections. The keyword queries \nwere built by combining political party names with keywords retrieved from \npolitical party platforms and party Facebook page comment spaces (in the \ncase of the provincial elections). We clustered the keywords into categories to \nenable a comparative analysis. At the outset the research questions were as \nfollows: Which rankings has the search engine assigned to junk sources when \nquerying political parties and their issues? Are there particular political \nissues and party spaces where junk news is prevalent or largely absent? Do \nthe ranks and amounts increase as the elections draw near?\nOur results indicate that the junk websites present in the results of our \nGoogle.nl political queries are almost exclusively hyperpartisan, rather than \nsources spreading disinformation, conspiracy theories, or clickbait. Three \nwebsites, namely De Dagelijkse Standaard , Stop de Bankiers and Opiniez, \naccount for the largest portion of the junk sources identified. We did not find \nfake advocacy groups or foreign disinformation operatives. Furthermore, we \nfound that queries involving right-wing parties were more prone to result in \nexposure to hyperpartisan sources than those associated with centre-left or \nleft-wing parties. For most keywords, hyperpartisan websites appeared in \nthe top positions, and certainly always within the first page of results. Our \nfindings suggest that on Google.nl there is a considerably high probability \nthat junk news is outputted on the first page of results when the queries \nconcern right-wing parties and their issues.\nAnother finding is that hyperpartisan results spread unevenly during \nour research period. For the case of the Dutch provincial elections, they are \nmore present before the day of the election and drop their presence and \nranking, in some cases dramatically, on election day and in the immediate \naftermath, for instance in the case of migration issues in the vernacular \nissue space. In contrast, during the European parliamentary elections this \nphenomenon reversed, and junk sources were more prominent the day \nafter the elections.\nPoli Ti cal ne W S  in Se aRc h engine S  119\nConcerning the comparison between the two spaces, the vernacular space \nhad the highest percentage of junk news returns, especially in the categories \nof foreign affairs and migration. In the political party standpoint space, the \ndifferences among themes is smaller. In other words, the queries designed \nwith the political language of Dutch Facebook users were more likely to \nresult in hyperpartisan results than the queries built with the standpoint \nlanguage of political parties. Although more research is needed in this \nregard, such a finding suggests that the discourse of normal citizens, or \nthose commenting on party Facebook pages, is more politically contentious \nthan that of political parties.\nThe results are indicative of the amount of hyperpartisan material in \npolitical space in Google.nl rather than conclusive, for they derive from a \nparticular query strategy and not from multiple strategies and are only a \nsnapshot from a particular event-related timeframe. The data set we built \ncould also be read more closely, and additional junk sources could be found, \nmeaning that we could have undercounted (rather than overcounted).\nGiven that our intention is to determine the susceptibility of the Google \nsearch engine to junk news, the question remains whether the location of the \nresults of politically charged queries can be credited to an optimization effort \non the side of hyperpartisan content generators, an overall susceptibility \nof Google\u2019s search algorithm to provide questionable content to its users, \nconsumers\u2019 preference for low quality information, or some combination \nof the three.\nWhile discussing the two latter hypotheses would require more space, a \nfew words can be said about the first. A possible way to detect search engine \noptimization strategies consists of using one of the many online services \nproviding SEO analysis. Given the proprietary nature of their methodologies, \nhowever, the results should be interpreted with caution. We submitted \nthe three most recurrent junk websites we found during our research to \nthe service SEO Tester Online, a tool that measures a website\u2019s readiness to \nachieve top positions within search results. This tool provides analysis in \nfour different categories: basic (related to the overall online presence of \nthe website), content (measuring the richness of the keywords that trig -\nger the website to pop up in search results), web performance (indicating \nhow fast the website can be rendered in mobile and desktop devices), and \nsocial (providing information about the website\u2019s engagement with users \nthrough social networks). De Dagelijkse Standaard obtained a score of \n56/100, faring the lowest in their web performance, and the highest in its \nsocial engagement. Opiniez  obtained a score of 62/100, faring the best in web \nperformance and the lowest in content, although it obtained an excellent \n120  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nscore in the number of unique keywords. Stop de bankiers obtained the \nhighest score, with 74/100, including a 100/100 in the assessment of keywords \nwhich may lead to the site through search engines. It also fared the best in \nsocial engagement and the lowest in web performance.\nThe reports produced by SEO Tester Online , which for all websites included \na considerable amount of suggestions about how to improve the websites\u2019 \ncode, suggest that, at least currently, content producers are not actively \nseeking to artificially alter the performance of their sites. Consequently, \nthe presence of these junk sources in our analysis is more likely related \nto an inherent susceptibility of Google\u2019s search engine and/or an organic \nresult of users\u2019 preferences.\nFurther research is necessary to paint a clearer picture regarding the \nincreased consumption of junk news. One could repeat the work for longer \nperiods of time in order to ascertain the extent to which the presence of \nthese or other dubious source types is becoming more widespread or even \ndisappearing in the top results for political queries, as is currently the case \nwith clickbait. Furthermore, specific sources could be monitored over time \nto track the performance of their content (and the changes to their code), \nin order to detect attempts to artificially increase relevance and thus the \nranking assigned by search engine algorithms.\nReferences\nAlbright, Jonathan (2016). \u201cThe #Election2016 Micro-Propaganda Machine\u201d, Medium , \n18\u00a0November.\nBowden, Ian (2016). \u201cHow Google is tackling fake news, and why it should not do \nit alone,\u201d Search Engine Land , 30\u00a0November, https://searchengineland.com/\ngoogle-tackling-fake-news-not-alone-264058.\nCadwalladr, Carole (2016). \u201cGoogle, democracy and the truth about internet search\u201d, \nThe Guardian , 4\u00a0December.\nConfessore, Nicholas and Daisuke Wakabayashi (2017). \u201cHow Russia Harvested \nAmerican Rage to Reshape U.S. Politics\u201d, New York Times , 9\u00a0October.\nDan, Ovidiu and Brian D. Davison (2016). \u201cMeasuring and Predicting Search Engine \nUsers\u2019 Satisfaction\u201d, ACM Computing Surveys , 49(1), art.\u00a018.\nFeuz, Martin, Matthew Fuller and Felix Stalder (2011). \u201cPersonal Web Searching in \nthe Age of Semantic Capitalism: Diagnosing the Mechanisms of Personalisation\u201d, \nFirst Monday, Volume\u00a016, Number 2 \u2013 7\u00a0February\u00a02011. https://doi.org/10.5210/\nfm.v16i2.3344.\nPoli Ti cal ne W S  in Se aRc h engine S  121\nHern, Alex (2017). \u201cGoogle acts against fake news on search engine,\u201d The Guardian , \n25\u00a0April.\nHaim, Mario, Andreas Graefe and Hans-Bernd Brosius (2018). \u201cBurst of the Filter \nBubble? Effects of personalization on the diversity of Google News\u201d, Digital \nJournalism , 6 (3): 1-14.\nHoward, Philip N., Gillian Bolsover, Bence Kollanyi, Samantha Bradshaw and \nLisa-Maria Neudert (2017). \u201cJunk news and bots during the U.S. election: What \nwere Michigan voters sharing over Twitter?\u201d, Computational Propaganda Data \nMemo, Oxford: Oxford Internet Institute.\nJansen, Bernard J. and Amanda Spink (2003). \u201cAn Analysis of Web Documents \nRetrieved and Viewed\u201d, 4th International Conference on Internet Computing, \nLas Vegas, Nevada, 23-26\u00a0June, 65-69.\nLomas, Natasha (2018). \u201cGoogle is surfacing Texas shooter misinformation in search \nresults \u2014 thanks also to Twitter\u201d, TechCrunch , 11\u00a0June.\nMartens, Bertin, Luis Aguiar, Estrella Gomez-Herrera and Frank Mueller-Langer \n(2018). \u201cThe Digital Transformation of News Media and the Rise of Disinformation \nand Fake News,\u201d SSRN Electronic Journal , doi:10.2139/ssrn.3164170.\nMarres, Noortje and Esther Weltevrede (2013). \u201cScraping the Social?\u201d Journal of \nCultural Economy , 6(3): 313-35, doi:10.1080/17530350.2013.772070.\nNoble, Safiya Umoja (2018). Algorithms of Oppression: How Search Engines Reinforce \nRacism . New York: New York University Press.\nPariser, Eli (2011). The Filter Bubble . New York: Penguin.\nPuschmann, Cornelius (2017). \u201cHow significant is algorithmic personalization in \nsearches for political parties and candidates?\u201d, Algorithmed Public Spheres blog, \nhttps://aps.hans-bredow-institut.de/personalization-google/\nRobertson, Adi (2017). \u201cAfter its 4chan slip-up, is it time for Google to drop Top \nStories?\u201d, The Verge , 3\u00a0October.\nRogers, Richard (2013). Digital Methods . Cambridge, MA: MIT Press.\nRogers, Richard and Sabine Niederer (eds.) (2019). The Politics of Social Media \nManipulation . The Hague: Ministry of Internal Affairs.\nSilverman, Craig (2016) \u201cThis Analysis Shows How Viral Fake Election News Stories \nOutperformed Real News On Facebook\u201d, Buzzfeed News , 16\u00a0November.\nWaters, Richard (2017). \u201cFacebook and Google help showcase Las Vegas fake news\u201d, \nFinancial Times , 3\u00a0October.\n122  gu ill\u00e9n To R ReS  and Richa Rd R oge R S \nAbout the auhors\nGuill\u00e9n Torres  is a Ph.D. researcher at the University of Amsterdam, \nwithin the DATACTIVE research group, and an information activist at \nControlaTuGobierno, a Civil Society Organization based in Mexico. His \nwork focuses on how data and information mediate the interaction between \ncitizens and the state.\nRichard Rogers  is Professor of New Media & Digital Culture at the Univer -\nsity of Amsterdam and Director of the Digital Methods Initiative, the group \nresponsible for social media research tools. Among other works, Rogers is \nauthor of Information Politics on the Web  (MIT Press, 2004), Digital Methods  \n(MIT Press, 2013), and Doing Digital Methods (Sage, 2019).\n4 T he circulation of political news on \nTwitter during the Dutch elections\nSabine Niederer and Maarten Groen1\nAbstract\nThis chapter enquires into the resonance of junk news on Twitter during \nthe campaign periods prior to the 2019 Dutch Provincial elections and \nEuropean Parliamentary elections. Querying Twitter for political topics \nrelated to the two elections, and various divisive social issues such as \nZwarte Piet and MH17, we analyse the spread and prominence of prob -\nlematic sources. We also examined the claim that Twitter is susceptible \nto abuse by bot and troll-like users, and found that troll-like users were \nactive across all political and issue spaces during the Dutch Provincial \nelections of 2019. Divisive issues remain steadily (even if marginally) \nactive in junk and tendentious news throughout the tested time frames, \nsuggesting these issues are year-round rather than event-based or seasonal, \nas they are in mainstream media.\nKeywords:  Twitter, social media analysis, junk news, social issues, trolling, \ndigital methods\nIntroduction\nIn 2018 the Dutch daily newspaper de Volkskrant  published an article en -\ntitled \u2018The troll army of pop artist Dotan\u2019, which revealed how the Dutch \nsinger-songwriter had made use of fictitious accounts pretending to be \nfans (Mis\u00e9rus and van der Noordaa, 2018a). The fake fans were highly active \n1 T he research reported here was undertaken in collaboration with Layal Boulos, Peter Fussy, \nOana Patrici, Maria Stenzel Timmermans, Emile den Tex, Carlo De Gaetano, and Federica \nBardelli.\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch04\n124  S abine ni ede Re R a nd Maa R Ten  gRo en \nacross social media platforms (including Facebook, Twitter, and Instagram) \nwhere they circulated heart-warming stories about the artist, requested \nhis songs on Dutch and German radio stations, and actively tried to edit \nthe Wikipedia pages about the artist and his mother (who is also a Dutch \nsinger). At the root of these activities were 140 accounts that the newspaper \nretrieved, at least one of which connected directly to the artist\u2019s own Gmail \naccount, and others to accomplices. Dotan\u2019s case is perhaps the most-known \nexample of artificially boosted accounts and content in the Netherlands, \nbut certainly not the only known case of such behaviour. The politicians \nGeert Wilders and members of the political party Denk were found to have \nsuspiciously inflated follower counts, which surfaced when Twitter started \ndeleting unvalidated users (NOS, 2018).\nThe present study builds on previous digital research in which the social \nmedia platform Twitter, used by over 326 million monthly active users \naccounting for 500 million tweets per day, is repurposed for social research \n(Omnicore, 2019). As with Dotan and the Dutch politicians mentioned above, \nit similarly looks into social media use and the question of manipulation, \nin particular in political spaces around elections. It studies troll-like and \nartificial boosting as well as the circulation of junk and tendentious news \nsources during two election campaign periods in 2019. Initially intending to \ndetect the possible presence of Russian disinformation in the Dutch Twitter \nspace, the study enquires into coordinated campaigning around divisive \nissues and ascertains the extent of homegrown junk news in Dutch political \nTwitter, including hyperpartisan, conspiracy and clickbait sources. So-called \n(and self-identified) tendentious sources such as Geenstijl.nl and TPO.nl are \nlabelled as such, and one could argue that they are mainstreaming, given \nhow they are shared, as we discuss below. These two sources are part of the \n\u2018anti-establishment established source\u2019 set, and as such are closely related \nto an emerging alternative media landscape (see Tuters, this volume).\nIn employing digital research methods and techniques, the analysis makes \nuse of the platform\u2019s own features and cultures of use, which offer built-in \nstructuring of the content being shared (Rogers, 2019). These are repurposed \nfor social or political research. Hashtags can be repurposed as content \ncategories or issue activity indicators, retweeting suggests \u2018pass-along value\u2019, \nand the @reply and @mention functionalities network users and their \ncontent to fellow users and content (Niederer, 2018). Through an analysis of \n@replies, Twitter can be studied \u2018as a conversation-maker, where one may explore the extent to which there is dialogue, or broadcasting\u2019 (Honeycutt \nand Herring, 2009; boyd et al., 2010). The @mentions may contribute to the \ninquiry of dominant voice \u2013 certain understandings of issues can be shaped \nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  125\nby the actors most mentioned in a tweet corpus, and also by the actors that \nare the most vocal. Twitter can be studied as a social network of professional \ninformation-sharers (Java, 2007). It also can be considered a \u2018rebroadcaster\u2019 \nof (political) news, in which the platform\u2019s built-in algorithms reinforce the \nissues and framings discussed there as so-called trending topics (Kwak et \nal., 2010). Furthermore, Twitter is often moving information faster than the \nnews, and Twitter content in some cases becomes news (Niederer, 2018). As \nnews and mass media sources strive to make their content \u2018platform-ready\u2019 \n(Helmond, 2015), political news, other mass media content and new platforms \nbecome further entangled, forming a hybrid media system (Chadwick, 2013). \nHere, professional journalists include tweets in their stories, and when their \nwork has been published, they may post a link to that article on Twitter and \nother social media, using the platforms both as a source of information and \nas a channel for the distribution of their own work.\nCritiques of digital social research take issue with its dependency on \nthe already problematic hegemony of proprietary social media platforms. \nOn a methodological level, scholars warn of the sheer impossibility of \ndistinguishing between the working logic of web platforms and exemplary \n\u2018platform artefacts\u2019 (Marres, 2015; Marres and Weltevrede, 2013; Rogers, 2013; \nNiederer, 2019). How do we know whether the most-retweeted Twitter post \nis the most relevant, or the most Twitter-friendly (Marres, 2015)? One way \nto approach this issue is to take into account the socio-technical specifics \nof each platform, and to regard Twitter and other social media platforms \nas distinct windows on an issue. Rather than questioning the relevance of \nthe platform for the elections, we then ask: how does Twitter present the \nelections? And how does this compare to how other social media platforms \ncover the topic? Such lines of questioning open up avenues for qualitative \nand empirical digital research across political events and social issues as \nthey resonate online and offer insights into the cultures of use of the various \nplatforms. In this present study, Twitter can be seen to produce political \nsubspaces around divisive issues, in which a relatively small number of \nhighly active, troll-like users sow division and where junk news at times \noutperforms mainstream news.\nTroll-like user activity during the 2017 Dutch general elections\nThe present study follows from an earlier one, which itself concerned Dutch \nelections. In the lead up to the 2017 Dutch general elections for the national \nparliament, journalists revealed the use of sock puppets (i.e., false online \n126  S abine ni ede Re R a nd Maa R Ten  gRo en \nidentities assumed to deceive and influence opinion) by the political party \nDenk, in order to amplify their online messages and attack their political \nopponents on Twitter and Facebook (Kouwenhoven and Logtenberg, 2017). \nIn an empirical study as part of the Field Guide to Fake News (Bounegru et \nal., 2018), we studied troll-like behaviour in Twitter, developing a research \nprotocol for identifying and analyzing political trolling, which in this case \nreferred to repeated attacks of politicians on Twitter. It focused on the \nsources of troll-like activity (i.e., which user accounts target politicians?), \ntheir targets (who do these troll-like users address?), and the characteristics \nof these practices (what do troll-like users do?) (Borra et al., 2018).\nThe detection of user accounts engaging in political trolling behaviour \nstarts by compiling a list of potential targets. The aforementioned study \nlooked into the user accounts of 28 political party leaders participating \nin the 2017 elections. The users that @-mention them were queried. For \nthe most-active users per @mention, their posts in which they @-mention \nthe political leaders were qualitatively studied. In a next step, only those \nwho @-mention one or more political leaders at least 100 times during \na one-month period (8\u00a0February-8\u00a0March\u00a02017) were retained, and their \ntweets coded for being favourable or unfavourable of the politician. The \nstudy found an asymmetry in the troll-like behaviour across the political \nspectrum, as more left-wing politicians were being targeted by negative Figure\u00a04.1   P olitical party leaders as trolling targets on Twitter during the 2017 \nDutch general elections. Each dot represents one mention (by a user \nmentioning political leaders at least 100 times). Red represents an attack, and green represents a favourable mention.\nSource: bo rra et al., 2017\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  127\nmentions while most right-wing politicians were receiving support (see \nFigure\u00a04.1). There are exceptions, such as Emile Roemer (SP) and Marianne \nThieme (PvdD), who in this time frame received only support by troll-like \nusers, and Prime Minister Mark Rutte (VVD) who received unfavourable \nmentions, in particular on his personal account though less so on his official \n@MinPres account.\nTo classify the sources of political trolling, we used the same list of 24 \nhighly active and troll-like users (mentioning political leaders at least 100 \ntimes in the one-month time frame), and collected their profile informa -\ntion (description, profile picture and banner) from the Twitter interface. \nIf the profiles had a profile picture, Google reverse image search was used \nto check these images for authenticity. Then, using the Twitter API, the \ncreation date for each of these accounts was retrieved, in order to assess \nwhether accounts in our dataset had been created on the same date. This \nanalysis provided a more nuanced view of the user accounts responsible for \nthe trolling behaviour. Of the 24 accounts still active at the time of study, \nthree users appeared to be sock puppets created for trolling activities. They \nhad very similar profiles and had been created within a short timeframe. \nAnother six accounts in the data set promoted the same anti-Islam agenda, \nbut were not determined to be fake accounts.\nTo characterize the substance of the trolling practices, the study looked \nat the issues and the media sources that resonate in the set of tweets. To \nidentify the issues, the hashtags used by the highly active and trolling \nusers in their tweets (that @mention a political leader) were collected and \nanalyzed. Most tweets that include hashtags were found to mention the \nright-wing populist candidate Geert Wilders, and most hashtags referred \nto the issues in PVV\u2019s political messages from 2017 (\u2018Nexit\u2019, \u2018StopIslam\u2019 and \n\u2018BanIslam\u2019), as well as those pertaining to expressions of Dutch patriotism \n(Borra et al., 2017: 188). To assess which media sources were circulated by \nthe troll-like users, the most-circulated URLs in the tweets were collected \nand categorized. For the 2017 general elections, the most-tweeted media \nsources by the 24 trolling users were the Dutch extreme blog fenixx.org \nfollowed by the anti-Islam site Jihad Watch  and the right-wing think tank \nthe Gatestone Institute (Borra et al., 2018: 192).\nResearch questions and data collection\nFor the study presented in the next section, the main research question is \nto what extent junk news sources and troll-like user accounts are present \n128  S abine ni ede Re R a nd Maa R Ten  gRo en \non Twitter around both the provincial and the European parliamentary \nelections in the Netherlands in 2019. To answer these questions, we examine \nTwitter activity concerning the elections, the party leadership as well as \npolitical candidates, and zoom in on potentially divisive issues, including \nZwarte Piet and MH17.\nIn addressing these research questions, queries are formulated to de -\nmarcate the political and issue spaces in Twitter (see Table\u00a04.1). The data \nare collected using the commercial social media monitoring tool, Coosto, \nand the Twitter Capturing and Analysis Toolkit developed by the Digital \nMethods Initiative (DMI-TCAT). Coosto was used to retrieve data from \nboth the provincial and European election periods, in order to conduct \na comparative analysis of the engagement with mainstream and junk \nnews across political and issue spaces, and the presence of troll-like users \nin these spaces, as discussed in detail in the next sections. DMI-TCAT, a \ntool that \u2018provides robust and reproducible data capture and analysis and Table\u00a04.1   Q uery overview showing the election campaign period (Provincial, EU \nor both), the political or issue space and the query made resulting in \nTwitter data sets\nElections Topic Query\nPS gen\neral Ps2019, Ps19, verkiezingen\neu gen\neral e\nu\nverkiezingen2019, euverkiezingen, ep2019, eu2019, \neuelections2019, verkiezingen, verkiezingen2019, \neu,\n \neu\nropa, \neu\nropese \nun\nie, europeseverkiezingen\nPS Party leaders Mark Rutte, MinPres, markrutte, \nge\nert Wilders, geertwilder -\nspvv, Thierry \nba\nudet, thierrybaudet, Jesse \nkl\naver, jesseklaver, \nRob Jetten, RobJetten, \nli\nlian Marijnissen, Marijnissen l,\n Mari -\nanne Thieme, mariannethieme, \nge\nrt-Jan Segers, gertjansegers, \nlo\ndewijk \nas\nscher, \nlo\ndewijk a,\n Tunahan \nku\nzu, tunahankuzu, \nhe\nnk \nkr\nol, \nhe\nnkkr\nol, \nkl\naas-Jan \ndi\njkhoff, dijkhoff, Sybrand \nbu\nma, \nsybrandbuma, ke\nes van der Staaij, keesvdstaaij\neu P\narty leaders SophieintVeld, \nes\nther_de_ lan\nge, mjrldegraaff, malikazmani, \narnouthoekstra, Timmermans e\nu,\n petervdalen, \nba\nsei\nckhout, \nanjahazekamp, ToineManders, florens0148, atonca, paulbeasd, \ndjeppink, sentwierda, R la\nnschot, MinPres, markrutte, geertwil -\nderspvv, thierrybaudet, jesseklaver, RobJetten, Marijnissen l,\n \nmariannethieme, gertjansegers, \nlo\ndewijk a,\n tunahankuzu, \nhe\nnkkr\nol, dijkhoff, sybrandbuma, keesvdstaaij\nPS and \neu Mh17 m\nh17\nPS and \neu Z\nwarte Piet Zwartepiet, zwarte piet\nPS and \neu\n c\nlimate klimaat\nPS and \neu fa\nke news fa\nke news, fakenews, nepnieuws, desinformatie, junknieuws\nPS ut\nrecht utrecht, 24oktoberplein, gokmen tanis, gokman tanis\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  129\ninterlinks with existing analytical software\u2019 (Borra and Rieder, 2014: 262), \nwas used to analyze the engagement with junk and tendentious news sources \nand the users responsible for this engagement. While some collections \n(or \u2018bins,\u2019 in the terminology of the TCAT-tool) were created only for this \nstudy, others had been running for months prior, such as MH17, or in the \ncase of Zwarte Piet even years (with a bin that was created in December \nof 2017). The set for the Utrecht tram shooting was created on the day that \nevent took place, 18\u00a0March\u00a02019. For this study, the sets were limited to the \nprovincial elections campaign period (18\u00a0February-25\u00a0March\u00a02019) and the \nEuropean Parliamentary election campaign period (26\u00a0April-24\u00a0May). The \none exception was the Utrecht tram shooting set, which was only included \nin the Provincial Elections campaign period, as it took place during that \ntime frame.\nJunk news sources and troll-like users during the provincial \nelections on Twitter\nDuring both the provincial and the European election campaigns we tracked \nthe resonance of mainstream, junk and tendentious sources in Twitter. We \ndid so around the potentially divisive issues of Zwarte Piet and MH17 and \nchose to include climate and fake news (as an issue). Furthermore, we tracked \nthe resonance of news sources for the political spaces of the (Provincial \nand EU) elections, as well as the party leadership and political candidates. \nFor each of the elections, we demarcated a five-week campaign period. Per Figure\u00a04.2   Engagemen t of mainstream (blue) and junk news (pink) articles \nduring the Dutch Provincial election campaign (left) and the European \nElection campaign period (right)\nline graphs; visualizations by fe derica ba rdelli\n130  S abine ni ede Re R a nd Maa R Ten  gRo en \npolitical and issue space, and for each of the five weeks of the campaign, \nthe most-shared links (up to a maximum of 500) were collected and coded \n(for mainstream or junk news of various types, using the aforementioned \nexpert list). The engagement scores for the mainstream and junk news source \nengagement per week were visualized as line graphs, as in the well-known \nBuzzfeed News  study (Silverman, 2016).\nFor both election campaign periods, overall the mainstream news \noutperforms junk news (see Figure\u00a04.2). When zooming in on the political \nspaces of the elections and the party leadership and political candidates, \nthe mainstream news sources garner far more engagement than junk news. \nA look at the top 500 most engaged-with links shows the rise and fall of \nmainstream hosts circulated in the issue space, and the relatively small but \nsteady resonance of junk news hosts, which during the provincial election \ncampaign rises slightly in its last week.Figure\u00a04.3   Engagemen t with mainstream news (blue) and junk news (pink) for \nthe issue of Zwarte Piet (top left) and MH17 (top right) and during the \nProvincial elections, and the EU elections (bottom left and right)\nline graphs; visualization by fe derica ba rdelli\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  131\nDivisive issues: Zwarte Piet and MH17\nBoth for Zwarte Piet and MH17, there are instances in which junk news \noutperforms mainstream news. In the climate and fake news datasets \nmainstream news outperforms junk news in all weeks. The line graphs \nin Figure\u00a04.3 include a zoomed-in view that renders visible the moments \nin which junk news is more engaged with than the mainstream news. \nFor the controversial topic of Zwarte Piet, during the Provincial election \nperiod mainstream news receives more engagement. Junk news outperforms \nmainstream news in weeks three and four of the European parliamentary \nelections campaign. The article mostly responsible for this peak in week \nthree is a short commentary on tendentious-hyperpartisan website The Post \nOnline , about the proposal by Dutch politician Sylvana Simons (addressed \nto the Amsterdam Municipality) to ban the \u2018racist caricature of Zwarte \nPiet\u2019 in the city of Amsterdam. When one removes The Post Online  from \nthe graph, the results remain the same apart from the one week in May \nduring the European parliamentary election period where now mainstream \nnews outperforms junk (see Appendix 4.1). In week four, an article on \nCultuurondervuur.nu (\u2018culture under fire\u2019) entitled \u2018Jerry Afriyie receives \nfunding for anti-Zwarte Piet educational materials\u2019 is responsible for the \nincreased activity. In it, activist Jerry Afriyie is described as a \u2018Zwarte Piet \nhater\u2019 (cultuurondervuur.nu, 2019).\nFor the issue of MH17, during the Provincial elections campaign there \nare times in which junk news outperforms mainstream news in terms of \nengagement. For the European parliamentary elections, the mainstream \nattracts more engagement, but during certain periods junk news is on a \nsimilar level as the mainstream. The peaks that occur during the Pro -\nvincial elections are mainly caused by engagement with a piece from \ncitizen-journalist Max van der Werff, on his website kremlintroll.nl, in \nwhich he demands rectification of an article in De Groene Amsterdammer  \n(from August\u00a02018) about Russian internet trolls (van der Werff, 2019). Two \nother articles that attract engagement are from the hyperpartisan website \njdreport.nl, questioning the integrity of the MH17 investigation, and in \none Frans Timmermans (who would win a seat for the PvdA in the EU \nparliamentary elections) is named as part of an \u2018MH17-doofpot\u2019, or cover-up \n(jdreport.nl, 2019). In week four of the Provincial elections campaign \nperiod, the Kremlintroll piece requesting rectification is particularly \nactively shared. Simultaneously, the interlinked article with the actual \ncritiques of the article from De Groene Amsterdammer  is receiving more \nengagement.\n132  S abine ni ede Re R a nd Maa R Ten  gRo en \nDuring the EU election campaign, mainstream news receives more \nengagement. It is important to note, however, that aside from a peak in \nmainstream news in week three of the campaign, its engagement level is \nequal to that of junk news sources. Where in the mainstream certain events \ncause peaks in media coverage, it appears that for junk news these divisive \nissues are continuous and year-round. Zwarte Piet may not be a subject \nmatter in the mainstream news in Springtime, but it remains a matter of \nconcern and a source of engagement in junk news media.\nTroll-like users during the Dutch provincial and European \nelections on Twitter\nFor the Dutch provincial elections campaign period, the next step in the \nstudy is to look closely at the user activity related to the Dutch provincial \nelections and the political party leadership, as well as coverage of the \npotentially divisive issues of Zwarte Piet, MH17 and the Utrecht tram \nshooting. As a first step, the URLs (hosts) were extracted from the sets of \ntweets and checked against a collaboratively compiled expert list of junk \nand tendentious news sources. Similarly, the users active in each of the sets \nof tweets were checked against a list of flagged users. Here, we made use \nof existing lists from the previous project in The Field Guide to Fake News  \n(Borra et al., 2017) and expanded these lists. To do so, we extracted top \nusers from the data sets of Zwarte Piet, MH17, Utrecht tram shooting, the \nDutch provincial elections and the political party leadership and followed \na protocol adapted from the aforementioned study, and combined them \nwith research on credibility metrics (Borra et al., 2017; Groot et al., 2019).2 \nWith the Compare List tool (Borra, 2013), the study assessed whether any \nof the flagged users were active in one or more of the political issue spaces. \nZwarte Piet had an initial list of 26 potentially troll- or bot-like accounts, \n2 F or this particular study, to identify potentially troll-like users in the data sets, the top 15 \nmost-active users in the set were selected, as well as the top 15 users who were highly active yet \nat the same time very low on visibility (i.e., rarely or not at all @mentioned). Then, the profiles \nof these user accounts were checked for the following flags: mostly retweeting, or retweeting \nin several languages (as possible indicators of automation) which is of interest given the wide \ndistribution of easily acquirable retweet bots (McGarry, 2013); profile oddities such as inauthentic \nuser\u2019s profile images, which were checked with Google Image search to assess their authenticity; \na recently created account; a high following count (of over 1,000); a username with over 3 numbers \nin it; high tweet frequency as tweeting over 200 times mentioning the issue; posting 20 tweets \nor more times per day; and, whether the user seems to mostly retweet more often rather than tweet his/her own content.\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  133\nfive of which had already been taken offline at the time of inquiry. Of \nthe 21 remaining each was flagged as potentially troll-like; one of which \ndescribed itself as a retweet bot (in the user profile). For MH17, of an initial \nlist of 26 potentially troll- or bot-like user accounts, two were inactive at the \ntime of inquiry. Of the remaining user accounts, 13 accounts were flagged, \nand 10 were not. For the Utrecht tram shooting, from an initial list of 23 \npotential troll- or bot-like accounts, 10 were flagged after examination. For \nthe provincial elections dataset, the list of potentially troll- or bot-like users \nentailed 24 accounts, 17 of which were flagged according to our criteria and \none of them described itself as a bot.\nSubsequently, these flagged users were checked for activity in more than \none issue. This would make sense for those data sets that are of related \ntopics, such as the provincial elections and the political leadership. When \nusers are active across distinct controversial issues such as Zwarte Piet, \nMH17, and the shooting in Utrecht, which have in common their potential \ndivisiveness, such multi-issue users and the content they circulate would \nbe further scrutinized. In fact, 14 flagged accounts are common to all of \nthe five political issue spaces, and as many as 29 flagged user accounts are \ncommon to four of the data sets, pointing to efforts to fuel division during \nt\nhe election period.\nFigure\u00a04.4 provides an overview of the tweet- and user counts per issue, as \nwell as the most-resonating hashtags, and most-retweeted tweets, during the \ntime around the elections (18\u00a0February-25\u00a0March\u00a02019). The analysis shows \nthat there is no disinformation resonating in the top 10 hosts per political and \nissue space. The top hosts are mostly (Dutch and international) mainstream \nnews media. The hyperpartisan site Opiniez.nl is among the top 10 hosts \nfor Zwarte Piet in the provincial elections space, and the tendentious site \ngeenstijl.nl is shared for MH17 and PS2019. Junk sources are present across \npolitical and issue spaces around MH17, Zwarte Piet, Utrecht, PS2019, and the \nDutch party leadership. There are junk news hosts that are common across \nall five issues: Ninefornews.nl, fenixx.org, tref.eu, ejbron.wordpress.com, \ndrimble.nl (a particular story), and dagelijksestandaard.nl. Hyperpartisan \nand conspiracy sources are mostly circulated by flagged users. However, \nsome hyperpartisan and tendentious sources are being mainstreamed, and \ncirculated by regular (as in: unflagged) users. These include tendentious-\nhyperpartisan host The Post Online and hyperpartisan sources, De Dagelijkse \nStandaard  and Fenixx .\nLooking at the time frame around the provincial elections, flagged users \nare among the top, most active users across issues. In particular for Zwarte \nPiet and MH17, six of the top ten users are flagged accounts. Analyzing the \n134  S abine ni ede Re R a nd Maa R Ten  gRo en \ntop @-mentioned users in tweets about Zwarte Piet and MH17, we found that \ntwo flagged user accounts are among the top 10 @mentioned. When analyz -\ning the most-used hashtags across the issues, what stands out is that the top \nhashtags used in the MH17 issue space all seem to be Pro-Russian. Across \nthe issue spaces of Zwarte Piet, MH17 and PS2019, we see the resonance \nof right-wing political party hashtags, such as PVV and FvD. Zwarte Piet \ncontains hashtags both for pro-Zwarte Piet (e.g., \u2018blokkeerfriezen\u2019, referring to \nthe Frisian counter-protest in Dokkum against anti-Zwarte Piet protesters of \n\u2018Kick out Zwarte Piet\u2019, which can be found in the data set with hashtag #kozp, \nin which they blocked the highway to prevent anti-Zwarte Piet protesters \nfrom entering their town) and anti-Zwarte Piet, e.g., \u2018SamenTegenRacisme\u2019, \nwhich translates as \u2018united against racism\u2019.\nFor the EU election campaigns, we similarly investigated the activity \nof flagged users in the political and issue space. For the political spaces, \nthe top 1000 most active users were collected for the general EU election \nhashtags and the political leaders relevant to the EU election campaigns. \nFor the issue spaces, the top 1000 most active users were collected on the \ntopics of climate change, Zwarte Piet, MH17 and fake news. These lists of \ntop users were matched with the flagged users list from the first part of \nthe empirical study. Because some topics were more active than others, the Figure\u00a04.4   T weet and user counts, top hashtags, and most-retweeted tweets \nduring the Dutch provincial election period of 2019\nda shboard; visualization by ca rlo de  ga etano\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  135\nactivity of the top 1000 users varies per dataset. For the more generic EU \nset, the top 1000 users each posted more than 44 tweets in the EU election \nperiod. In comparison, in the Zwarte Piet dataset the top 1000 users each \nposted two or more tweets.\nOf the flagged users list, eight users were active in all six issue spaces \nduring the EU campaign period. Three users were active in five of the \nspaces and another three users in four of the spaces. Four of the eight \nusers active in all spaces were also active in all the provincial election \nperiod datasets. From the users active in all datasets, the top user posted \n2,781 tweets. 2,578 of those tweets were in the general EU and party \nleader dataset. This user is not only retweeting other content, but also \nposts his own content. The content in the EU Elections period can be \ncharacterized as anti-EU, anti-immigration, pro-PVV/FvD and critical \nof all other parties.\nThe circulation of junk and tendentious news during the \nprovincial elections\nTo gain a better view of these troll-like, junk and tendentious news activities, \na next step zooms in on the circulation of these news sources during the \ncampaign period in each of the political issue spaces. Visualized as network \ngraphs, the analysis considers whether such news sources are circulated by \nflagged or regular (non-flagged) users.3 Each host-user bi-partite network \ngraph includes a short overview of the user and host types per data set, \nclearly illustrating that the number of flagged users and the circulation \nof junk or tendentious news sources are outnumbered by unflagged users \nand the circulation of mainstream news. Thus, these visualizations should \nbe read as a zoom-in on a particular, small set of hosts that are of interest \nto the study of the presence and circulation of junk news and tendentious news and the users that circulate them.\nIn each issue space, hyperpartisan sources are circulated the most. And \nwhile the issue space of Zwarte Piet is dominated by the circulation of \nhyperpartisan sources being shared by flagged but also by regular users, \nthe main junk news sources for MH17 are more diverse in composition. \nHere, we see a mix of tendentious, hyperpartisan, as well as conspiracy \nhosts. For the Utrecht shooting, tendentious and hyperpartisan hosts are \ncirculated the most, by flagged and regular users, making them appear as \n3 R egular in this case in fact strictly speaking means not flagged .\n136  S abine ni ede Re R a nd Maa R Ten  gRo en \nmainstream. The junk news and tendentious sources in both of the political \nspaces, PS2019 and the party leaders, revolve around mostly hyperpartisan \nand tendentious sources.\nThe host-user network of the Zwarte Piet issue space (Figure\u00a04.5) is dense \nand, as said, is dominated by the circulation of hyperpartisan sources such Figure\u00a04.5   G ephi visualization of Zwarte Piet host-user network during the \nprovincial elections campaign period, depicting only junk and \ntendentious hosts and the user accounts that circulate these sources\nVisualization by ca rlo de ga etano\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  137\nas dagelijksestandaard.nl, fenixx.org, cultuurondervuur.nu and opiniez.\nnl, and, at a slightly lower level, the tendentious source geenstijl.nl. These \ncentral nodes are the sources of choice for the majority of the flagged users, \nbut also have been shared by regular users, who demonstrate a preference \nfor the hyperpartisan source, dagelijksestandaard.nl. One clickbait host \n(tpook.nl), which can be found in the outskirts of the graph, stands out as \nbeing circulated by both flagged and regular users.\nThe network visualization of the MH17 junk news source circulation \n(Figure\u00a04.6) shows a different source composition to that of Zwarte Piet, Figure\u00a04.6   G ephi visualization of MH17 host-user network during the provincial \nelections campaign period, depicting only junk and tendentious hosts \nand the user accounts that circulate these sources\nVisualization by ca rlo de ga etano\n138  S abine ni ede Re R a nd Maa R Ten  gRo en \nwhich had hyperpartisan sources at its core. For MH17, we see a more di -\nverse set of sources central to the network: tendentious source geenstijl.nl, \nhyperpartisan/conspiracy source novini.nl, and a set of two other conspiracy \nhosts (ninefornews.nl and niguru.co), which have been widely circulated \nby flagged users.\nThe flagged users in this issue space mostly circulate tendentious hosts, \nsuch as geenstijl.nl, and hyperpartisan and conspiracy sites, hersteldere -\npubliek.wordpress.com and novini.nl. The source most circulated by regular \nusers is the tendentious geenstijl.nl.Figure\u00a04.7   G ephi visualization of Utrecht shooting host-user network during \nthe provincial elections campaign period, depicting only junk and \ntendentious hosts and the user accounts that circulate these sources\nVisualization by ca rlo de ga etano\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  139\nFigure\u00a04.8   G ephi visualization of PS2019 host-user network during the provincial \nelections campaign period, depicting only junk and tendentious hosts \nand the users that circulate these sources\nVisualization by ca rlo de ga etano\n140  S abine ni ede Re R a nd Maa R Ten  gRo en \nIn the issue space for the Utrecht shooting (Figure\u00a04.7), tendentious and \nhyperpartisan sources (geenstijl.nl, tpo.nl and dagelijksestandaard.nl) \npopulate the centre of the network. Several smaller clusters of junk news \nsources that have been circulated by regular users are evenly distributed \non the periphery of the graph (e.g., drimble.nl (story-level), evendelen.net, \ndagelijksekrant.nl or hardwaarheid.nl). Only a minority of flagged users \ncirculate clickbait (tpook.nl, nietbarkie.nl) and conspiracy pages (martin -\nvrijland.nl, ninefornews.nl, brekendnieuws.nl, ellaster.nl,  w anttoknow.nl). Figure\u00a04.9   G ephi visualization of Party Leadership host-user network during \nthe provincial elections campaign period, depicting only junk and \ntendentious hosts and the users that circulate these sources\nVisualization by ca rlo de ga etano\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  141\nIt is important to note that overall the hyperpartisan and tendentious \nsources in this network have been circulated by both flagged and regular \nusers, making them appear to be mainstream(ing).\nThe PS2019 (Provincial State elections) host-user network appears to \nbe organized around two major hosts, hyperpartisan source opiniez.\ncom and tendentious source geenstijl.nl (Figure\u00a04.8). The (marginal) \npresence of clickbait host aboutmedia.nl is caused by the activity of only \none regular user. Conspiracy hosts ninefornews.nl and dlmplus.nl have \nbeen only marginally circulated by users who also shared other junk \nnews hosts. Two recently created user accounts in the network (created \nin December\u00a02018) demonstrate an uncommonly high number of tweets \nand likes. One of them has around 39,300 posts, and 31,900 likes within \nfour months of existence, a level of activity that suggests automation and \nartificial inflation.4\nFor the Party leadership network, the tendentious-hyperpartisan source \ntpo.nl and hyperpartisan source dagelijksestandaard.nl are the largest \nnodes in the network and are circulated by both flagged and regular users \n(Figure\u00a04.9). Smaller nodes of hyperpartisan sources, such as fenixx.org, \nopiniez.com and verenoflood.nu, are positioned slightly more towards the \nperiphery of the network. A dense cluster of flagged users is situated in the \nheart of the network and has circulated mostly tendentious and hyperpar -\ntisan hosts as well as conspiracy hosts, such as ninefornews.nl or ellaster.nl. \nRegular users populate the rest of the network and have circulated mostly \ntendentious and hyperpartisan hosts (e.g., tpo.nl, dagelijksestandaard.nl \nand opiniez.com) and to a lesser extent, have circulated conspiracy hosts \n(e.g., donquijotte.wordpress.com or stoppasfamiliedrama.blogspot.com) \nwhich are visible in the margins of the graph.\nConclusions: Troll-like activity in divisive issue spaces\nAs emphasized in studies of the campaigning by the Russian Internet \nResearch Agency as well as so-called home-grown actors, Twitter allows \nfor easy automation, which makes the platform susceptible to abuse by bot and troll-like users (boyd et al., 2018; DiResta et al., 2018; Howard et \nal., 2018). We have identified such suspicious activity during the Dutch \nProvincial elections of 2019, when looking at political issue spaces as well \n4 T heir high number of likes is also inconsistent with the pattern of activity, which is mostly \nretweets and replies with GIFs or funny images.\n142  S abine ni ede Re R a nd Maa R Ten  gRo en \nas divisive issues. In fact, troll-like users are central across political and \nissue spaces around MH17, Zwarte Piet, Utrecht, PS2019, and the Dutch \nparty leadership. In particular, 14 flagged users were found to be active \nacross all political and issue spaces, and the 29 that appear in four out \nof five, deserve further scrutiny. Four suspect users active during the \nprovincial election period were also (or still) active in all issue spaces \nduring the EU election period. Some of these users had already been \nflagged in previous research from 2017, which means they have been \noperating and engaging in new and existing issues for over two years. \nOverall, our study found that such flagged users tend to spread mostly \nhyperpartisan and tendentious sources, followed by conspiracy websites. \nWe also found no indication of a coordinated campaign, whereby (as found \nelsewhere) the troll-like users would include sock puppets, automated \naccounts, and semi-automated user accounts that post both retweets \nand original content.\nDivisive issue spaces are active year-round. From 18\u00a0February \u2013 the begin -\nning of the official campaign \u2013 to 25\u00a0March\u00a02019, the issue spaces of Zwarte \nPiet and MH17 were still active, even though Sinterklaas, the holiday related \nto Zwarte Piet, takes place in December and the downing of the Malaysian \nairliner was not in the news, either through new developments or official \nmemorial events. A significant number of the most active users in each issue \nduring this period display troll-like behaviour through their high activity \n(30% in the case of Utrecht and 60% in MH17 and Zwarte Piet). Despite the \nactivity, most of these users\u2019 influence is still limited, however. Only two \nof them appear among the top ten most @-mentioned for each issue space.\nAt the same time, we identified at least three highly active new ac -\ncounts that were created close to the elections with a clear purpose of \ndisseminating divisive content, indicating how the platform may be \nemployed around election time. When these troll or bot-like users are \nnot aggressively attacking the opposition, they function as amplification \nmachines for web news operations, ranging from tendentious sources \nsuch as Geenstijl  and The Post Online to hyperpartisan sources such as \nDe Dagelijkse Standaard , Opiniez  and Fenixx . Repeatedly, we have seen \nhow these tendentious and hyperpartisan sources are widely circulated \nby regular users who crowd out the flagged users (in a network cluster -\ning sense). The uptake of tendentious and hyperpartisan sources by \nsuch regular users leads to a \u2018mainstreaming\u2019 of these hosts, in times \nof elections.\nIn all, flagged users tend to spread mostly tendentious and hyperpartisan \nhosts, followed by conspiracy hosts, which appear in all datasets but seem to \nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  143\nbe more pervasive in tragedy spaces as MH17 and the Utrecht tram shooting. \nDuring the EU election period, on several occasions, junk news sources \noutperformed mainstream sources around the controversial topics, Zwarte \nPiet and MH17. On both issues, junk news outperformed mainstream news \nin two of the five weeks. During these weeks, there is not a large increase \nvisible in the engagement of junk news sources compared to other weeks. \nInstead, the overperformance is mostly caused by a drop in the mainstream \nmedia attention for the topics on hand, while coverage persists on the junk \nnews sources, fuelling the debate.\nAccording to these results, the Dutch political Twittersphere does not \nappear to have a junk news problem, though it is populated by some troll-\nlike users, whose existence serves to amplify certain voices. While we did \nnot find a professional or large-scale trolling campaign, the activity across \nissues in spreading divisive content was caused by various types of user \naccounts, both bot-like (as in: automated) and troll-like (as in: repeatedly \nengaging with divisive issues and targeting politicians). Divisive issues \nremain steadily (even if marginally) active in junk news and tendentious \nnews throughout the tested time frames, suggesting these issues are year-\nround rather than event-based or seasonal (as may be expected with Zwarte \nPiet).\nAppendix 4.1  A lternate figures\nAlternate Figure\u00a04.2   T hese line graphs visualize the engagement with mainstream \nnews (blue) and junk news sources (pink) during the Dutch \nprovincial election campaign (PS) and the European Election campaign period (EU), similar to Figure\u00a04.2, but excluding the tendentious-hyperpartisan sources.\nVisualization by fe derica ba rdelli\n144  S abine ni ede Re R a nd Maa R Ten  gRo en \nAlternate Figure\u00a04.3   T hese line graphs visualize the engagement with \nmainstream news (blue) and junk news sources (pink) for \nthe issues of MH17 and Zwarte Piet during the provincial elections (PS), and the EU elections (EU), similar to Figure\u00a04.3, but excluding the tendentious-hyperpartisan sources.\nVisualizations by fe derica ba rdelli\nReferences\nBorra, Erik (2013) \u2018DMI Tools\u2019, wiki. https://wiki.digitalmethods.net/Dmi/\nToolDatabase.\n\u2014 and Bernhard Rieder (2014) \u2018Programmed method: developing a toolset for \ncapturing and analyzing tweets\u2019, Aslib Journal of Information Management , \n66(3): 262-278.\n\u2014, Sabine Niederer, Johannes Preu\u00df and Esther Weltevrede (2018) \u2018Mapping troll-\nlike practices on Twitter\u2019, in Liliana Bounegru, Jonathan Gray, Tomasso Venturini \n& Michele Mauri (Eds.), A Field Guide to \u2018Fake News\u2019 and Other Information \nDisorders: A collection of recipes for those who love to cook with digital methods , \nAmsterdam: Public Data Lab, pp.\u00a0161-196.\nBounegru, Liliana, Jonathan Gray, Tommaso Venturini and Michele Mauri (eds.) (2018) \nA Field Guide to \u201cFake News\u201d and Other Information Disorders: A Collection of Recipes \nfor Those Who Love to Cook with Digital Methods , Amsterdam: Public Data Lab.\nThe ci Rc ula Ti on of Po liTi cal ne W S  on T WiT TeR  du Ri ng Th e duTc h elec Ti onS  145\nBoyd, Danah, Scott Golder and Gilad Lotan (2010) \u2018Tweet, tweet, retweet: Con -\nversational aspects of retweeting on Twitter\u2019, in 43rd Hawaii International \nConference on System Sciences,  Honolulu, HI: IEEE, January, pp.\u00a01-10, DOI: 10.1109/\nHICSS.2010.412.\nChadwick, Andrew (2013) The Hybrid Media System: Politics and Power . Oxford: \nOxford University Press.\nCultuurondervuur (2019) \u2018Jerry Afriyie ontvangt subsidie voor lespakket tegen \nzwarte piet\u2019, Cultuurondervuur.nu , 13\u00a0May. https://cultuurondervuur.nu/\njerry-afriyie-ontvangt-subsidie-voor-lespakket-tegen-zwarte-piet/\nDiResta, Renee, Kris Shaffer, Becky Ruppel, et al. (2018) \u2018The Tactics & Tropes of the \nInternet Research Agency\u2019, Report, New Knowledge . https://disinformationreport.\nblob.core.windows.net/disinformation-report/NewKnowledge-Disinformation-\nReport-Whitepaper.pdf.\nGroot, Tim, Sophie Minihold, Jessica Robinson, Manuel Schneider, Joanna Sleigh \nand Dydimus Zengenene (2019) \u2018Russia, Twitter & Authenticity: Establishing \nCredibility Metrics\u2019, Digital Methods Initiative , Winter School 2019. https://wiki.\ndigitalmethods.net/Dmi/WinterSchool2019CredibilityMetrics\nHelmond, Anne (2015) \u2018The Platformization of the Web: Making Web Data Platform \nReady\u2019, Social Media + Society 1(2):1-11. https://doi.org/10.1177/2056305115603080.\nHoneycutt, Courtenay and Susan C. Herring (2009) \u2018Beyond microblogging. Con -\nversation and collaboration\u2019, 42nd Hawaii International Conference on System \nSciences . Los Alamitos, CA: IEEE Press.\nHoward, Philip N., Bharath Ganesh, Dimitra Liotsiou, John Kelly and Camille \nFranc\u0327ois (2018) \u2018The IRA, Social Media and Political Polarization in the United \nStates, 2012-2018\u2019, Report, Computational Propaganda Research Project, Oxford: \nOxford Internet Institute.\nJava, Akshay, Xiaodan Song, Tim Finin and Belle Tseng (2007) \u2018Why we twitter: \nunderstanding microblogging usage and communities\u2019. In Proceedings of the \n9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network \nanalysis , New York, NY: ACM, pp.\u00a056-65.\nJDReport (2019) \u2018Zal Frans Timmermans met zijn walgelijke rol bij de MH17 ramp \neindigen in een Roemeense cel?\u2019, jdreport.nl , 24\u00a0February. https://jdreport.com/\nzal-frans-timmermans-met-zijn-walgelijke-rol-bij-de-mh17-ramp-eindigen-in-\neen-roemeense-cel/\nKouwenhoven, Andreas and Hugo Logtenberg (2017) \u2018Hoe Denk met \u2018trollen\u2019 \npolitieke tegenstanders monddood probeert te maken\u2019, NRC Handelsblad , \n10\u00a0February.\nKwak, Haewoon, Changhyun Lee, Hosung Park and Sue Moon (2010) \u2018What is Twit -\nter? A social network or a news media?\u2019, in Proceedings of the 19th International \nConference on World Wide Web , New York: ACM, April, pp.\u00a0591-600.\n146  S abine ni ede Re R a nd Maa R Ten  gRo en \nMarres, Noortje (2018) \u2018Why We Can\u2019t Have Our Facts Back\u2019, Engaging Science, \nTechnology, and Society,  4: 423-443.\nMarres, Noortje and Esther Weltevrede (2013) \u2018Scraping the Social?\u2019 Journal of \nCultural Economy , 6(3): 313-35, DOI:10.1080/17530350.2013.772070.\nMis\u00e9rus, Mark and Robert van der Noordaa (2018a) \u2018Het trollenleger van popartiest \nDotan\u2019, de Volkskrant , 14\u00a0April.\nNiederer, Sabine (2018) \u2018The Study of Networked Content: Five Considerations for \nDigital Research in the Humanities,\u2019 in Giovanni Schiuma and Daniela Carlucci \n(eds.), Big Data in the Arts and Humanities: Theory and Practice, Boca Raton, \nFL: CRC Press, pp.\u00a089-100.\n\u2014 (2019) Networked Content Analysis: The case of climate change , Amsterdam: \nInstitute of Network Cultures.\nNOS (2018) \u2018Twitters grote schoonmaak: Wilders en Denk-politici verliezen \nvolgers\u2019, NOS , 13\u00a0July. https://nos.nl/nieuwsuur/artikel/2241321-twitters-grote-\nschoonmaak-wilders-en-denk-politici-verliezen-volgers.html\nOmnicore (2019) \u2018Twitter by the numbers\u2019, Omnicore  Agency . https://www.omni -\ncoreagency.com/twitter-statistics/\nRogers, Richard (2019) Doing Digital Methods, London: Sage.\n\u2014 (2013) Digital Methods , Cambridge, MA: MIT Press.\nSilverman, Craig (2016) \u2018This Analysis Shows How Viral Fake Election News Stories \nOutperformed Real News On Facebook\u2019, Buzzfeed News , 16\u00a0November.\nvan der Werff, Max (2019) \u2018De Groene trolt Rusland \u2013 Deel II\u2019, Kremlintroll , 17\u00a0March. \nhttp://kremlintroll.nl/?p=2854\nAbout the authors\nSabine Niederer  is Professor of Visual Methodologies at the Amsterdam \nUniversity of Applied Sciences. Her research focuses on the cartography \nof issues and online debates through visual and digital methods, with a \nparticular interest in climate-related issues. In 2014, Niederer founded the \nCitizen Data Lab as an applied research lab specializing in participatory \nmapping of local issues.\nMaarten Groen  is a researcher and programmer at the Visual Method -\nologies Collective at the Amsterdam University of Applied Sciences. He is \ninterested in developing and researching tools that empower citizens. In the \npast, he has worked on projects involving open data, social media analysis, \nintelligent sensory systems, and public screens.\n5 D utch political Instagram\nJunk news, follower ecologies and artificial amplification\nGabriele Colombo and Carlo De Gaetano1\nAbstract\nThe research examines junk news, followers of problematic sources \nas well as artificial amplification on Instagram during the 2019 Dutch \nprovincial and European parliamentary elections. First, this study looks \nat the circulation of junk content in high-engagement political spaces on \nInstagram. Second, it takes up the question of the mainstreaming of Dutch \njunk news providers by looking at the intersection between the followers \nof Dutch political entities and those of junk news sources. Third, it looks at \nthe presence of artificial engagement tactics (specifically fake followers) \nemployed by Dutch political entities and news sources on Instagram. \nIn all it was found that Dutch political Instagram is a relatively healthy \nspace, but not for all issues or political entities.\nKeywords:  Instagram, artificial engagement, junk sources, fake followers, \ndigital methods\nIntroduction: Fake followers, computational propaganda and \ntheir detection on Instagram\nThough Facebook has been labelled the \u2018hyperpartisan media machine\u2019 \n(Herrman, 2016) and Twitter studied as a matter of routine, owing to the \navailability of datasets, Instagram, when scrutinized, has been found \nto perform well as an outlet for junk or hyperpartisan news circulation, \nartificially amplified engagement and other types of problematic content \nand users.\n1 T he research was undertaken together with Rama Adityadarma, Joris van Breugel and Vic Krens.\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch05\n148  ga bRi ele co loMb o and caRlo de ga eTa no \nThe relationship between Instagram and different types of \u2018problematic \ninformation\u2019 (Jack, 2017) has been studied in connection with the Russian \neffort to influence the 2016 American elections. A study by New Knowledge \n(2018) found that Russian propaganda tactics played well on Instagram. The \nreport analyses data from a variety of platforms, in order to detect efforts by \nthe Internet Research Agency (IRA) to spread disinformation and divisive \ncontent. The study found that Instagram, with \u2018187 million engagements\u2019 of \n\u2018116,000 Instagram posts across 133 accounts\u2019 (New Knowledge, 2018: 7), to be \nat the forefront of an IRA operation, with better performing fake accounts \nand overall higher engagement than on Facebook.\nThe significance of Instagram, which \u2018outperformed Facebook\u2019 (New \nKnowledge, 2018: 8) as a battleground in the Russian disinformation enter -\nprise, is linked, according to the report, to two possible causes. First, since \nit is a platform designed around sharing visual materials, Instagram may \nbe well suited for the so-called \u2018image-centric memetic (meme) warfare\u2019 \n(2018: 8), that is, the weaponized use of image macros to stir conflict and \nfoster division online. Second, the report states that the considerably high engagement of content from the IRA\u2019s accounts on Instagram may also be \nthe result of click-farm activity, and some of the accounts in the dataset \nappeared indeed to be linked to \u2018a live engagement farm\u2019 (2018: 8).\nWith respect to the Dutch case, Russian influence has been studied \nmainly on Twitter, with the detection of trolling activities, especially in \nthe aftermath of tragic and divisive events both in the Netherlands and \nin Belgium. For example, two journalistic studies found peaks in Russian \ntrolling activity following the downing of MH17 in 2014 (Kist and Wassens, \n2018; van der Noordaa and van de Ven, 2018a), while another study uncovered \na (rather unsuccessful) organized Russian effort in spreading anti-Islam \ncontent on Twitter after the 2016 Brussels airport attacks (van der Noordaa \nand van de Ven, 2018b). Despite the lack of empirical research regarding \nRussian influence on Instagram, one study from the NRC Handelsblad  (Kist \nand Wassens, 2018) suggests that a larger organized trolling activity may be \nfound on other platforms beyond Twitter, including Instagram.\nThe use of computational means to amplify misinformation and hy -\nperpartisan content on Instagram has not been linked exclusively to the \nRussian propaganda operation in the West, but it has also been described \nas a domestic tactic, adopted by national campaigners as well. A compara -\ntive, global study of social media manipulation in 48 countries (Bradshaw \nand Howard, 2018) describes different computational tactics for political \ninfluence online, including the use of fake accounts to attack other users, \nautomated accounts generating artificial engagement, and human-curated \nduTc h Po liTi cal inS Ta g RaM 149\naccounts that employ automation to be more efficient. With respect to the \nNetherlands, the study found such automated activity to be mainly linked to \nthe boosting of Geert Wilders\u2019 hashtags on Twitter. While the study describes \nTwitter as the platform where automation thrives the most, signs of \u2018cyber \ntroop activity\u2019 (Bradshaw and Howard, 2018: 13) are also to be found in \nother platforms, including Instagram, among 25% of the countries studied.\nThat fake following and artificial engagement flourish on Instagram may \nalso be noted from reported cases in the news. As a case in point, in June\u00a02017, \nthe Russian journalist, Vasily Sonkin, posted an image of a vending machine, \nplaced inside a shopping centre in Moscow, that lets users buy Instagram \nfollowers and likes. The news that for the (cheap) price of 50 Russian roubles \n(about EUR\u00a00.70) one could buy 100 fake Instagram likes was reported by \nnumerous tech or news media outlets (Matsakis, 2017; Feldman, 2017; Tan, 2017).\nThere have also been efforts by Instagram itself to counter artificially \namplified activities on the platform. In December\u00a02014, Instagram an -\nnounced a crackdown on fake (or improperly obtained) profiles, in the \nso-called \u2018Instagram rapture\u2019 (Lorenz, 2014) that resulted in the deletion of \nhundreds of thousands of accounts. And later, in December\u00a02018, a \u2018Christmas \ncrackdown\u2019 (Lorenz, 2018) resulted in the shutdown of 500 meme accounts, \nsome of which with millions of followers, suspected of using stolen or traded \nprofiles. On the same note, in April\u00a02019, Facebook filed a lawsuit against \none company based in New Zealand, accusing it of providing \u2018fake likes, \nviews and followers to Instagram users\u2019 (Romero, 2019). The lawsuit is \npresented as part of a larger effort by the platform to prevent \u2018inauthentic \nbehaviour\u2019 on Instagram. While actions have been taken to cope with \nartificial engagement as well as fake or improperly obtained accounts, the \nplatform has been apparently less active in limiting the spread of extremely \ncoloured or hyperpartisan content, but rather has become the \u2018Alt-Right\u2019s \nnew favourite haven\u2019 (Sommer, 2018), offering refuge to extreme right-wing \npersonalities, after their accounts are deleted from Twitter.\nThe presence of a large automated engagement infrastructure on Ins -\ntagram is also indicated by the deluge of fakeness-detection tools offered \nby commercial services online. The detection of inauthentic automated \nactivity on Instagram may work by fingerprinting one account\u2019s follower \nbase by nationality, and associate specific geographical locations, such as \nBrazil, Turkey or China, to suspected bot activity (Maheshwari, 2018). For \nexample, among the available tools, HypeAuditor , a \u2018100% AI-powered\u2019 \nservice to expose \u2018fake followers and engagement\u2019 on Instagram, flags \ncertain countries, such as Brazil, as geographical locations that may signal \nthe presence of fake followers (Komok, 2018).\n150  ga bRi ele co loMb o and caRlo de ga eTa no \nDespite being understudied, specifically in the Dutch context, Instagram \nappears to be a platform prone to the presence of various instantiations of \njunk and fakeness. There is the presence of content that can be described as \nfalse as well as merely hyperpartisan and divisive, but deliberately pushed \nonline in order to stir conflict in a political space, both from outside the \ncountry and from within. It is also a platform prone to various computational \ntactics (such as bot work, fake likes and fake following) employed as a means \nto artificially amplify that same content.\nJunk content and artificial amplification in the Dutch political \nspace on Instagram\nAs mentioned, a few studies have described Instagram as fertile ground for \nthe distribution of inflammatory content in the form of memes, but also as a \nwell-performing infrastructure for the artificial amplification of engagement. In \nthis empirical research project, we devised three complementary approaches for \nthe assessment of Dutch political Instagram in order to test these premises. They \nstudy the amount of junk content shared on the platform, the dubiousness of \nthe most relevant information sources within the space, and the inauthenticity \nof followers that may generate artificial engagement (see Figure\u00a05.1).\nIn the first part of this study, we search for levels of junk content shared on \nthe platform, by asking to what extent the most liked content in a demarcated \nDutch political space on Instagram can be defined as junk (i.e., disinforma -\ntion, conspiracy, clickbait or hyperpartisan). Second, as the estimation of junk \nalso can be made through \u2018online source criticism\u2019 (Rogers and Niederer, this \nvolume), we expand the work by detecting it on Instagram at a source level. \nHere, we study the mainstreaming of junk sources by exploring the affinity of \nthe follower bases of Dutch political entities with those of junk news providers \n(flagged as such by experts). We ask, to what extent do Dutch political entities \nshare an audience with junk news sources on Instagram? Thirdly, in order \nto study the tactics of artificial engagement that political parties and news \nsources may employ on Instagram to boost their content, we search for signs \nof inauthentic activity in the follower bases in the Dutch political space and \ninquire into the extent of any efforts at artificially boosting (by means of fake \nfollowers) present around divisive topics on the Dutch Instagram.\nIn this research we employ a \u2018digital methods\u2019 approach (Rogers, 2013), \nrepurposing Instagram-specific features to gather data from the platform. In \nparticular, we compile a list of hashtags and profiles in order to demarcate \nthe Dutch political space on Instagram. Within this space, we collect and \nduTc h Po liTi cal inS Ta g RaM 151Figure\u00a05.1   D iagram of the research protocol, showing the type of hashtags and accounts used for querying Instagram, and the tools used to \ncollect, visualize and analyze the data\n\n152  ga bRi ele co loMb o and caRlo de ga eTa no \nanalyze most liked posts (i.e., posts that receive a certain number of likes) \nto study junk in the shared content. Furthermore, we collect followers of \nthe accounts of Dutch political entities, mainstream news sources, and junk \nnews sources, in order to study the intersection between their audiences, \nand more generally to assess the degree of junk in the Dutch political space \nat the level of the sources. Finally, we rely on profile features (such as the \n150 characters bio in one\u2019s profile, or post captions), to evaluate the number \nof fake followers of the Dutch political space.\nDetecting junk in the most liked content\nThe aim of the following analysis is to identify engaging content in the \nDutch Instagram political space and observe the extent to which it contains \njunk \u2013 in the sense of how much engagement is generated by content that \nis either disinformation, conspiracy, clickbait or hyperpartisan.\nTo outline the Dutch political space in Instagram, we compiled a list of \nhashtags (see Table\u00a05.1) that are used on the social network to identify the \nleaders of Dutch political parties (e.g., #markrutte), the 2019 Dutch provincial \nelections (#PS2019) as well as politically charged issues such as climate change \n(#klimaatverandering). We used the Instagram Scraper tool,2 offered by the \nDigital Methods Initiative, to collect the 1,000 most recent posts per hashtag \n(data collected between the 25th and 28th of March\u00a02019), together with their \nmetadata (date of the post, media URL, caption, number of comments and \nnumber of likes). For each hashtag we selected only the 20 most liked posts, \nmanually filtering out posts that are not relevant to the search criteria, or \nidentical posts that prevent more diverse results from reaching the top 20.3\nIn this curated list of most liked posts, we conducted a close reading \nby looking at post captions and embedded media (images and videos) to \nunderstand how political party leaders and politically charged topics are \ndiscussed within the limits of the Instagram Dutch political space, and \nspecifically to flag the presence of junk content.\nAs a result of this evaluation (see Figure\u00a05.2), we found that out of the \n400 most liked posts within our dataset there are (only) 45 posts that can \n2 T he tool is available at this link: https://wiki.digitalmethods.net/Dmi/ToolInstagramScraper\n3 F or example, we filter out posts about the Slovak professional footballer Marek Ham\u0161\u00edk, \nwho plays with the number 17 and is referred to in Instagram with the same hashtag of the \nMalaysia Airlines Flight 17 (#MH17). We also do not include in the dataset the identical posts \nof condolence messages for the Utrecht attack posted by Dutch national football team players \nwith the hashtag #Utrecht.\nduTc h Po liTi cal inS Ta g RaM 153\nbe flagged as junk, 4 satirical posts, and 351 posts that do not appear to be \njunk. Looking at the engagement generated by these posts, junk content \nwas liked 79,466 times, satirical content 37,532 times, and non-junk content \n838,794 times.\nIn Figure\u00a05.3, the 400 most liked posts are divided in hashtag-dedicated \ncolumns, in which they are also ranked from the most liked post in the \nfirst row to the least liked one in the last. Junk content is flagged using \nthree different colours: light blue for hyperpartisan content, magenta \nfor conspiracy, and blue for click-bait. Satirical posts are color-coded in \ndark blue. Finally, columns are ordered from left to right according to \nthe amount of junk content, calculated on the total number of likes for \neach hashtag.\nThe analysis shows that the #zwartepiet, #geertwilders and #tuna-\nhankuzu hashtags represent the most divisive political spaces, with \nrespectively 56.1%, 42.8% and 42.7% of their total amount of likes directed \nto junk content. Moreover, we find that the majority of the posts flagged as \nsuch can be considered hyperpartisan, mostly supporting and/or oppos -\ning particular ideology or figures, while only one post can be considered \nas clickbait, and one conspiracy. Generally, we did not find any trace of \ndisinformation linked to the content that receives the most likes. The \nfindings suggest that certain issues or political leaders, such as the Zwarte \nPiet debate and the leader of Denk political party, Tunahan Kuzu, draw \nmore divisive content than others. Of the 20 most liked posts, however, we \nfound no strong presence of junk.\nIn general, we found a relative scarcity of junk content in this high-\nengagement political space. In the top results for the Dutch provincial \nelections, #PS2019, we found only positive content, either celebrating \npreliminary poll results or encouraging people to exercise their right to vote. \nThe hashtags, #24oktoberplein and #utrecht, returned mainly condolence \nposts and the news that the attacker was spotted and arrested. Almost \nall of the content we considered as junk is hyperpartisan. We found no \npresence of disinformation in the most liked results within the demarcated \npolitical space.\nIn order to ascertain the presence of junk content on Instagram sur -\nrounding the 2019\u00a0European Parliamentary elections in the Netherlands, \nwe conducted a second hashtag analysis concerning content posted in the \nmonths before the election day (23\u00a0May). With the goal of demarcating the \nDutch political space around the 2019\u00a0European elections, we compiled a \nnew list of hashtags (see Table\u00a05.2) used to identify Dutch political parties \n(e.g. #fvd) and their leaders (e.g. #thierrybaudet), the European elections \n154  ga bRi ele co loMb o and caRlo de ga eTa no \nTable\u00a05.1   Lists of hash tags pertaining to political leaders and politically charged \ndiscussions used to demarcate the Dutch political space on Instagram \naround the 2019 provincial elections\nHashtags related to\ndu\ntch political party leadersHashtags related to\npolitically charged discussions \n#markrutte, #rutte, #geertwilders, #wilders, #thierrybaudet, #baudet, #jetten, #tunahankuzu, #jesseklaver, #lodewijkasscher, #alexanderpechtold, #gertjansegers, #sybrand -\nbuma, #mariannethieme#PS2019, #klimaatverandering, #immigranten, #utrecht, #zwartepiet, #M\nh1\n7, #24oktoberplein\nFigure\u00a05.2   P roportions of most liked content shared around the 2019 Dutch \nprovincial elections, categorized as junk, satire, and not junk\nda ta source: in stagram Scraper; data collection: 25-28\u00a0March\u00a02019; pie charts\n(#EUverkiezingen2019, #EUverkiezingen), and various politically charged \nissues such as immigration (#immigratie, #migratie, #immigranten) and \nclimate change (#klimaat, #klimaatverandering).\nWith the Instagram Scraper tool, we collected the 1,000 most recent \nposts per hashtag (data collected on the 22nd of May) and their metadata. \nFor each hashtag we only retained posts shared after the 28th of March, \nin order to focus on the detection of junk in the period prior to the Euro -\npean elections, but after that of the Dutch provincial elections. For each \nhashtag we selected the 20 most-liked posts, excluding those included in \nduTc h Po liTi cal inS Ta g RaM 155Figure\u00a05.3   20 most-lik ed posts per hashtag shared around the 2019 Dutch provincial elections, sorted from right  \n(most junk) to left (least junk)\nda ta source: in stagram Scraper; data collection: 25-28\u00a0March; image wall\n156  ga bRi ele co loMb o and caRlo de ga eTa no \nthe dataset but not relevant to the search criteria.4 Subsequently, in order \nto ascertain the amount of junk in the dataset, we looked at embedded \nmedia and textual captions and flagged each post as junk or not (making \nthe additional distinctions between disinformation, conspiracy, clickbait \nand hyperpartisan content).\nThe analysis (see Figure\u00a05.5) confirmed the relative lack of junk content \nin the Dutch political space, also around the 2019\u00a0European parliamentary \nelections: out of 452 most liked posts, we found only 41 that can be considered \njunk (specifically hyperpartisan), counting for less than 10% of the total \namount of posts. Moreover, hyperpartisan posts score low even in terms of \nengagement, generating only 4.66% of likes out of the total amount.\nIn Figure\u00a05.6, most liked posts are organized in hashtag-dedicated col -\numns. Columns are grouped by type of hashtag and sorted from right to left \naccording to the number of likes generated by hyperpartisan content. The \n4 T he query for some of the less popular hashtags returned less than 20 posts in the specified \ndate range.Figure\u00a05.4\n Examples of the p\nosts flagged as hyperpartisan or satire\nda ta source: in stagram Scraper; data collection: 25-28\u00a0March; image wall\nduTc h Po liTi cal inS Ta g RaM 157\nanalysis shows that the hashtags related to political parties attracting more \ndivisive content are #pvda and #christenunie, with respectively 27.6% and \n25.1% of likes directed to hyperpartisan content. Compared to the dataset \naround the provincial elections, Geert Wilders (#geertwilders, #wilders) \nremains the political leader receiving the highest percentage of likes directed \nto hyperpartisan content (28.4%), followed by Jesse Klaver (#jesseklever) \nwith 13.4%, who instead scored low in terms of junk content in the previous \nanalysis. We did not find traces of hyperpartisan content in the most-liked Table\u00a05.2   Lists of hash tags pertaining to political leaders and politically charged \ndiscussions used to demarcate the Dutch political space on Instagram \nduring the months before the 2019\u00a0European elections\nHashtags related to\ndu\ntch political party \nleadersHashtags related to\ndu\ntch political partiesHashtags related to\npolitically charged discussions\n#markrutte, #rutte, #geertwilders, #wilders, #thierrybaudet, #baudet, #jesseklaver, #jetten, #mariannethieme, #tunahankuzu#cdavandaag, #pvv, #social -\nistischepartij, #pvda, #chris -\ntenunie, #partijvoordedieren, #50pluspartij, #groenlinks, #fvd, #stempiraat, #voltneder -\nland, #d66, #degroenen#duurzaamheid, #klimaat, #klimaatverandering, #immigratie, #migratie, #immigranten, #mh17, #zwartepiet\nFigure\u00a05.5   P roportions of most-liked content shared around the 2019\u00a0European \nelections, categorized as junk and not junk\nda ta source: in stagram Scraper; data collection: 22\u00a0May\u00a02019; pie charts\n158  ga bRi ele co loMb o and caRlo de ga eTa no Figure\u00a05.6   20 most lik ed posts per hashtag shared around the 2019\u00a0European elections, sorted from right \n(most junk) to left (least junk) and grouped by type (elections, issues, political leaders, and parties). \nPosts flagged as hyperpartisan are coloured in red\nda ta source: in stagram Scraper; data collection: 22\u00a0May\u00a02019; image wall\nduTc h Po liTi cal inS Ta g RaM 159\nposts around other political leaders. As was the case with the hashtags \nused to refer to the Dutch provincial elections, #EUverkiezingen2019 and \n#EUverkiezingen are related mainly to invitations to exercise the right to \nvote. Among the issues under study, #zwartepiet remains the most divisive \none, with 22.9% of likes directed to hyperpartisan content.\nIn general, we did not find evident signs of dubiousness in the most-liked \ncontent around the 2019\u00a0European elections, except for a few hyperpartisan \nposts. The finding is aligned with that of the hashtag analysis conducted \naround the 2019 Dutch provincial elections.\nFollower ecologies and the relevance of junk sources\nIn order to detect the relevance of junk news sources within the Dutch \npolitical space on Instagram, and to assess whether and how much junk news \nsources are becoming mainstream, we studied the overlap between followers \nof Dutch political entities, mainstream news sites and Dutch-language junk \nnews sites.5 Specifically, we asked, to what extent are followers of junk news \nproviders shared with those of Dutch political entities?\nFirst, we demarcated the Dutch political space on Instagram, by compiling \nthree lists of profiles: a list of Dutch political parties and their leaders, a list \nof Dutch mainstream media outlets, and the profiles of Dutch information \nsources flagged as junk in the expert list (see Appendix 6.2 in Hagen and \nJokubauskaite, this volume). We then used the API Instagram Follower \nCollector by Phantombuster6 to collect the follower list of each Instagram \naccount, and then, by creating a co-follower network, we looked at the \namounts of shared followers between the political entities and the dubious \nDutch information sources from the expert list.\nIn mapping the follower network of the Dutch political space, we found \nthree distinct follower ecologies (see Figure\u00a05.7). First, an ecosystem of \nfollowers of mostly established mainstream news organizations, such as \nthe Dutch public broadcasting station, NOS. The follower bases of these \nnews organizations are the largest in the network, which suggests that the \nDutch mainstream news providers are still more relevant that those flagged \n5 W e use the list of sites flagged by the Hoax-Wijzer  (www.hoax-wijzer.be), which was edited \nand enhanced by University of Amsterdam researchers, and is dubbed the \u2018expert list\u2019 (see \nAppendix 6.2 in Hagen and Jokubauskaite, this volume).\n6 P hantombuster is an API store that \u2018provides ready-made cloud APIs to collect data from \nvarious social networks and improve marketing strategies\u2019 (phantombuster.com).\n160  ga bRi ele co loMb o and caRlo de ga eTa no \nas junk, at least in terms of follower count. Few sites from the expert list \nare close to (or part of) the cluster of mainstream news organizations, due \nto a relatively high number of shared followers. Shared followers among \nmainstream news organizations and junk news sites may indeed suggest a \nspecial affinity among them, or rather be the signal of the mainstreaming \nof junk news providers.\nA second ecosystem is made up of political parties and their youth organi -\nzations. The distribution of parties is laid out from left-wing to right-wing parties, whilst still being tightly clustered together. This may suggest that \nmost followers either follow multiple parties on the same side of the political \nspectrum or follow all political parties regardless of political leaning. What \ncan also be observed is the relative distance of the cluster of political parties \nto that of news organizations, suggesting that followers of political entities \nare mostly not shared with those of news organizations.\nA third cluster is made up of right-wing political entities, which are \nfar from other political entities, closer to few hyperpartisan or clickbait \nsites and to few, less established, mainstream news providers. Within this \ncluster, the account of PVV leader Geert Wilders is surrounded by GeenStijl , \na tendentious \u2018shock blog\u2019 and PowNed, the public broadcasting station that \nis an offshoot of GeenStijl . The official profile of FvD (Forum for Democracy) \nand the youth organization of the same party are even more distant and \nisolated from other parties: they are surrounded by individual political \ncommentators and share a high number of followers with the hyperpartisan \nnews site, De Dagelijkse Standaard . This topology may suggest that although \nthese parties and personalities share some followers with those from other \nsides of the political spectrum, they are mostly on their own and produce content consumed by a unique audience.\nFake followers and artificial engagement\nIn order to profile the follower base of the previously demarcated Dutch \npolitical space, we feed each account7 (of political entities, but also of \nmainstream media, and of those from the expert list) in the HypeAuditor \ntool to check the authenticity of the accounts and look for signs of artificial \nboosting and fake followers. With HypeAuditor one can profile an Instagram \naccount to determine the authenticity of its follower base. To assess the \n7 H ypeAuditor  analyzes only accounts with more than 1,000 followers. For this reason, we \nlimited the detection of fakeness to accounts with more than 1,000 followers.\nduTc h Po liTi cal inS Ta g RaM 161\nextent to which Dutch political accounts are employing artificial engagement \ntactics, we use reports from HypeAuditor, regarding the percentage of real \nfollowers, and their geographical origin.8 The percentage of fake followers \n8 A ccording to HypeAuditor, the geographical origin of one follower base is detected by \nanalysing profiles biographies and place names in post captions (twitter.com/hypeauditor/\nstatus/1077143110432538624).Figure\u00a05.7   F ollower ecologies in the Dutch political space, visualized as a co-follower \nnetwork and manually annotated. In the network, accounts with higher \namounts of shared followers (pink) are placed closer to each other.\nad_nl\nde_volkskrant\nminpres\nnos\ntelegraaf.nl\ntweede_kamer\nomroeppowned\nmarkopinsta\nprankster.nl\ngeertwilders\ngroenlinks\ncdavandaag\nd66_insta\nnrcnl\npartijvandearbeid\nvvd\nfvdnl\ndenknl\nchristenunie\njongerenfvd\nnieuwetijdskindmagazine\ndwars\npartijvddieren\ntrouw.deverdieping\ntrendnova\nvrouwendingenonline\neerstekamer\ngeenstijl\nsgpnieuws\nsocialistischepartij\ndestillewaarheid\npink.politiek\njspvda\ncujongeren\nde_speld\njovdonline\nsgpjongeren\njboppositie\nhealthwatch_nl\njongedemocraten\nroodjongindesp\nthepostonline\nleeshetnu\nstevebrownamsterdamnoir\ndedagelijksestandaard\nninefornews\njdreport\nlikemag\ntrendnieuwstv\nMainstream media\nPolitical entities\nJunk sources\nFollowersSize represents\nthe numberof followers\nMAINSTREAM MEDIA\nPOLITICAL PARTIES\nALTERNATIVE MEDIA ECOSYSTEM\nda ta source: Phantombuster; data collection: 25-28\u00a0March; network graph\n162  ga bRi ele co loMb o and caRlo de ga eTa no Figure\u00a05.8   Degr ee of account fakeness according to report by the HypeAuditor tool. Accounts on the further right have more suspected \u2018fake \nfollowers\u2019 than accounts on the left side of the graphs.\nda ta source: hy peau ditor; data collection: 25-28\u00a0March\u00a02019; bee swarm plot\nduTc h Po liTi cal inS Ta g RaM 163\nreturned by the tool is then used to rank each account from less fake to \nmore fake (see Figure\u00a05.8). Furthermore, we zoomed in on those accounts \nwith a higher percentage of fake followers, to observe their geographical \nprovenance (paying particular attention to suspicious countries), as well \nas the segmentation of the follower base provided by HypeAuditor, which \nbreaks down followers in \u2018real people\u2019, \u2018influencers\u2019, \u2018mass followers\u2019 and \n\u2018suspicious accounts\u2019 (see Figure\u00a05.9).\nGenerally, we found that the majority of profiles do not have a suspicious \nfollower base, with most accounts scoring higher than 70% in the real \nfollower metrics provided by the tool. There are some accounts, however, \nthat are suspect of having a fake follower base. For instance, the media \nentity PowNed has 32.6% of suspicious followers. The clickbait site Prankster \nalso scores relatively high in terms of fake following. Within the group of \npolitical entities, the personal account of Mark Rutte and the account of \nGeert Wilders have the highest number of suspicious followers. Strikingly, \nthe \u2018work\u2019 account of the prime minister, Mark Rutte, has a lower percentage Figure\u00a05.9   V isualization of the follower base of Mark Rutte\u2019s personal and work \naccounts and Geert Wilders\u2019 account, based on results from the \nHypeAuditor tool. Each follower base is segmented based on \u2018audience type\u2019 and geographical provenance. Popular suspicious countries, that may suggest an inauthentic follower base, are coloured in red.\nda ta source: hy peau ditor; data collection: 25-28\u00a0March\u00a02019; pie charts\n164  ga bRi ele co loMb o and caRlo de ga eTa no \nof fake followers than that of his personal account. On the other hand, the \naccount for the political party, Christenunie, has hardly any suspicious \nfollowers, just as the SGP (Reformed Political Party) and that of the minister \nGert-Jan Segers.\nWhen we look closer to the nationality of the follower bases, we found \nno suspicious results, with most of the accounts followed by users based \nin The Netherlands. For both of Mark Rutte\u2019s accounts, the followers are \nmostly based in the Netherlands. On the contrary, Geert Wilders account \nhas 36% of his followers from Brazil. This raises some questions regarding \nthe legitimacy of Geert Wilders\u2019 follower base, for Brazil is often mentioned \nas one location that can signal the presence of fake followers (Maheshwari, \n2018).\nIn all the follower analysis does not show an organized effort of artificial \nboosting within the Dutch political Instagram sphere, and it indicates, with \nthe exception of Geert Wilders, a rather authentic follower base.\nConclusions: Findings and limitations\nThe goal of the present research is to detect the scope of junk news and the \ndegree of artificial amplification in the Dutch political Instagram sphere. \nMore generally, it can be considered an attempt at applying to the Dutch \ncontext the argument in the New Knowledge report (2018) that Instagram \nperforms well in terms of junk content circulation and artificial amplifica -\ntion strategies. It also takes up the invitation from the NRC Handelsblad  study \nto inquire into other platforms than Facebook and Twitter for disinformation \ncampaigning and computational propaganda.\nThe presence of dubious content (or lack of thereof) has been studied on \nthree levels: at the story level (by looking at the circulation of junk content \nin high-engagement political spaces on Instagram); at the source level (by \nlooking at the intersection between the follower bases of Dutch political \nentities and that of news sources flagged as junk); and through the detection \nof artificial engagement tactics, specifically fake followers, among the \nprofiles of Dutch political entities as well as Dutch information sources.\nIn general, we found a rather healthy political space. Most liked content in \nthe Dutch political space proved to be junk to a very small degree, although \nwe found a small amount of hyperpartisan and polarizing content centred \naround more divisive figures and issues in the 2019 Dutch provincial and \nEuropean elections. With respect to the alignment of the audience of Dutch \npolitical parties with that of (mainstream or junk) news providers, we found \nduTc h Po liTi cal inS Ta g RaM 165\nmainstream news organizations to be still more relevant in this political \nspace, somehow confirming the argument that in the Netherlands \u2018the vast \nmajority of news consumption remains of the mainstream sources\u2019 (Rogers \nand Niederer 2019, this volume). Furthermore, the analysis of the follower \nbase of Dutch political entities (and that of news sites, both mainstream \nand junk) revealed an apparent authentic audience with almost no signs \nof artificial engagement.\nWithin a relatively healthy political spectrum, it is at the extremes \nthat junk sources and artificial amplification surface. With the cur -\nrent research we have pointed out a special affinity between right-wing \npolitical entities and some information sources that may be defined as \njunk (or at least hyperpartisan). Furthermore, the few indications of \nartificial engagement we have found are located at the far end of the \npolitical spectrum, with Geert Wilders\u2019 account being the most suspected \nof inauthentic activity.\nIn the co-follower analysis, we found that extreme political entities to \nhave a unique follower base, not shared with other parties or mainstream \nnews sites. Right-wing political entities are also relatively closer (in terms \nof shared followers) to suspicious sources (a few of them flagged by the \nexpert list). Above all, Geert Wilders\u2019 account is the closest (according to \nshared followers) to hyperpartisan news sources. Relatedly, Geert Wilders\u2019 \naccount is the only one of those under study that may reveal signs of artificial \nengagement, as suggested by a geographically dubious follower base. This finding resonates with the 2015 scandal about a suspicious increase of the \nfollower count of Geert Wilders\u2019 Twitter profile. In addition, the already \nmentioned comparative study of social media manipulation strategies by \nthe Oxford Internet Institute (Bradshaw and Howard, 2018) also refers to \nGeert Wilders as making use of various artificial boosting strategies in \nThe Netherlands, reporting on an analysis by a social media analytics firm \nthat in February\u00a02016 found 26 fake accounts amplifying the #geertwilders \nhashtag on Twitter.\nThe determination of the relative absence of junk content, dubious \nsources and fake followers in the scope of the current research has a series \nof methodological limitations. First, in the search for junk news in the shared \ncontents, we collected data based on a limited list of hashtags related to \nDutch politicians and controversial topics. One could repeat the analysis to \ninclude other politically charged issues. Furthermore, we have considered only the top 20 most-liked posts per hashtag, whereas we could have also \ncounted the number of comments per posts to analyze most engaged-with \ncontent. Moreover, we could have included in the analysis a larger set of \n166  ga bRi ele co loMb o and caRlo de ga eTa no \nposts that do not necessarily make it to the top (because they receive fewer \nlikes, or have fewer comments), in order to evaluate the presence of junk \nnews in less engaged-with spaces. In addition, given that for data collection \nwe made use of the DMI Instagram Scraper , which \u2018scrapes Instagram to \nretrieve posts\u2019 (Digital Methods Initiative, 2019), this research is dependent \non the limits of such scraping, including Instagram\u2019s rate limits which are \nnot documented and unknown security challenges (Instaloader, 2019). It is \nalso not a platform that invites research through scraping. As others have \npointed out, social media platforms are designed to increase a platform\u2019s \ncommercial value, rather than to meet researchers\u2019 needs (Borra and Rieder, \n2014). To overcome the limitations, one could use additional tools for data \ncollection and compile a richer data set.\nSecondly, we established the fakeness in the Dutch political follower base \nusing the metrics provided by a single tool (HypeAuditor). We could have \ncompared the results with those by other similar services (and audited the \nauditors, so to speak). Moreover, we searched for signs of inflated engagement \nin the Dutch political space only by looking at followers\u2019 demographics, while \nwe could have paid attention to other signals such as patterns of repetition \nin posts comments. For example, to account for other tactics of artificial \nengagement on Instagram, one could perform a co-hashtag analysis9 in a \ndemarcated issue space, and detect signs of (semi-automatic) boosting, such \nas the use of long list of popular unrelated hashtags, deliberately added in \nthe post captions to increase content visibility.10 Moreover, one could trace \nback the users involved in this activity and profile them in order to evaluate \ntheir authenticity.\n9 I n addition to the most recent lists of posts, the Instagram Scraper  tool returns a network of \nhashtag co-occurrences, that is, a file that contains the hashtags used at least once together with \nthe hashtag under study. For each pair of hashtags, the tool returns a numeric value representing \nthe total number of posts in which the two hashtags appear together in the data set. A similar \napproach is largely used for empirical research on Twitter: with co-hashtag analysis one can gain \na sense of the relationship between subtopics in a conversation (Borra and Rieder, 2014); or find \nadditional and/or more \u2018significant hashtags\u2019 (Rogers, 2017) to be queried to expand a corpus of \ndata; or spot hashtags practices aimed at enhancing the visibility of particular content (Wang et \nal.\u00a02016), or overturning its original meaning through hashtag hijacking practices (Berg, 2017).\n10 Un like Twitter, which has a character limit of 280 characters, Instagram\u2019s character limit is \n2,200 characters, and users can include up to 30 hashtags in the caption and comment sections \nof the post. This results in certain users adding blocks of more or less related hashtags to the \nposts to enhance their visibility. Even if Instagram is applying countermeasures to block the \nuse of certain hashtags (Drewe, 2016), there are several websites that provide lists of safe and \npopular hashtags that users can copy paste directly in their posts (for example, tagblender.net).\nduTc h Po liTi cal inS Ta g RaM 167\nReferences\nBerg, Kati Tusinski (2017). \u2018Social Media, Hashtag Hijacking, and the Evolution of \nan Activist Group Strategy.\u2019 in Social media and crisis communication , edited \nby Lucinda Austin and Yan Jin. Routledge, pp.\u00a0141-156\nBradshaw, Samantha and Phillip N. Howard (2018) \u2018Challenging Truth and Trust: \nA Global Inventory of Organized Social Media Manipulation\u2019, Computational \nPropaganda Data Memo, Oxford: Oxford Internet Institute.\nBorra, Erik and Bernard Rieder (2014). \u2018Programmed method: developing a toolset \nfor capturing and analyzing tweets\u2019. Aslib Journal of Information Management , \n66(3), 262-278.\nDigital Methods Initiative (2015) Instagram scraper. Available at: https://wiki.\ndigitalmethods.net/Dmi/ToolInstagramScraper. [Accessed 22\u00a0April\u00a02019].\nDrewe, Nick (2016) \u2018The Hilarious List Of Hashtags Instagram Won\u2019t Let You Search\u2019, \nThe Data Pack , 10\u00a0May. http://thedatapack.com/banned-instagram-hashtags-\nupdate/\nFeldman, Brian (2017) \u2018In Russia, You Can Buy Instagram Likes From a Vending \nMachine\u2019, N ew York Magazine, 8\u00a0June.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August.\nInstaloader (2019) Instaloader software, version 4.2.5, GitHub project, https://\ninstaloader.github.io/.\nJack, Caroline (2017) Lexicon of Lies: Terms for Problematic Information   N\new York: \nData & Society Research Institute.\nKist, Reinier and Rik Wassens (2018) \u2018Russisch trollenleger ook actief in Nederland\u2019, \nNRC Handelsblad , 15\u00a0July.\nKomok, Anna (2018) \u2018How to Check Instagram Account for Fake Followers\u2019, \nHypeAuditor , 6\u00a0July. https://hypeauditor.com/blog/how-to-check-instagram-\naccount-for-fake-followers/\nLorenz, Taylor (2014) \u2018Instagram Rapture Claims Millions Of Celebrity Instagram \nFollowers\u2019, Business Insider , 18\u00a0December.\nLorenz, Taylor (2018) \u2018Instagram\u2019s Christmas Crackdown. No meme account is \nsafe \u2013 not even @God\u2019, The Atlantic , 27\u00a0December.\nMaheshwari, Sapna (2018) \u2018Uncovering Instagram Bots With a New Kind of Detective \nWork\u2019, The New York Times , 12\u00a0March.\nMatsakis, Louise (2017) \u2018This Russian Vending Machine Will Sell You Fake Instagram \nLikes\u2019, Motherboard Vice , 7\u00a0June.\nNew Knowledge (2018) \u2018The Tactics & Tropes of the Internet Research Agency\u2019, \nWhite Paper, Austin, TX: New Knowledge.\n168  ga bRi ele co loMb o and caRlo de ga eTa no \nRomero, Jessica (2019) \u2018Preventing Inauthentic Behavior on Instagram\u2019, Facebook \nNewsroom , 25\u00a0April. https://newsroom.fb.com/news/2019/04/preventing-\ninauthentic-behavior-on-instagram/\nRogers, Richard (2013) Digital Methods . Cambridge, MA: MIT Press\nRogers, Richard (2017) \u2018Foundations of digital methods: Query design\u2019 in The Datafied \nSociety. Studying Culture through Data, edited by Mirko Tobias Sch a\u0308f er and \nKarin Van Es. Amsterdam University Press, pp.\u00a075-94\nRogers, Richard and Sabine Niederer (2019) The Politics of Social Media Manipulation , \nThe Hague: Ministry of Internal Affairs.\nSommer, Will (2018) \u2018Instagram Is the Alt-Right\u2019s New Favorite Haven\u2019, The Daily \nBeas t, 30\u00a0October.\nTan, Yvette (2017) \u2018There\u2019s a vending machine selling fake Instagram likes, because \nthis is what we\u2019ve become\u2019, Mashable , 7\u00a0June.\nvan der Noordaa, Robert and Coen van de Ven (2018a) \u2018Hoe Russische trollen inspelen \nop westerse angsten\u2019, De Groene Amsterdammer , 28\u00a0August.\nvan der Noordaa, Robert and Coen van de Ven (2018b) \u20183\u00a0miljoen \u201ctrollentweets\u201d \nonderzocht: hoe Rusland via sociale media ook in Belgi \u00eb  verdeeldheid zaait\u2019, \nKnack , 27\u00a0November.\nWang, Rong, Wenlin Liu, and Shuyang Gao (2016) \u2018Hashtags and information virality \nin networked social movement: Examining hashtag co-occurrence patterns.\u2019 \nOnline Information Review  40(7): 850-866.\nAbout the authors\nGabriele Colombo  is a design researcher. In 2018 he completed his Ph.D. \nresearch at Politecnico di Milano. His research and teaching activities \nrevolve around the design of visual tools in support of digital social research, \nfocusing on the design of novel strategies for the analysis of collections of \nimages and videos.\nCarlo De Gaetano is a designer and researcher with the Visual Method-\nologies Collective, Amsterdam University of Applied Sciences. He focuses \non data visualization for social and cultural research. Carlo is interested \nin speculative methods with machine learning, images as data and the \nmapping of social issues.\n6 D utch junk news on Reddit and \n4chan/pol\nSal Hagen and Emilija Jokubauskait\u01171\nAbstract\nThis chapter investigates the presence of junk news on Reddit and 4chan\u2019s \n/pol/ subforum, spaces often described as \u201calternative\u201d owing to their lower \nuser numbers and subcultural ethos compared to the likes of Facebook. \nWe first delineate Dutch spheres within the two spaces over multiple \nyears, finding a rising number of posts within Reddit\u2019s Dutch sphere and \na stagnant yet non-negligible number of Dutch posters on 4chan/pol/. We \nthen categorise and analyse what URLs are shared to gauge the presence \nof junk news domains. We find that Reddit seems fairly resilient against \nthe presence of disinformation or other forms of junk news, save for the \nappearance of some hyperpartisan sources and incidental malicious users. \n4chan/pol/ shows a somewhat more problematic situation, returning a \nlarger presence of (foreign) junk news sources.\nKeywords:  Reddit, 4chan/pol/, junk news, alternative media, digital \nmethods\nIntroduction: The understudied, deep vernacular Web\nRecent debates on online fake news and disinformation have largely been \ndiscussed with respect to the social media behemoths in the context of a \n\u2018platformized\u2019 internet ecosystem (Helmond, 2015), with Facebook, Twitter, \nInstagram and YouTube in the spotlight. It is not without reason; given their \ngigantic user bases, open publishing and micro-targeting, they are vulnerable \n1 T he research team includes Lucie Chateau, Gabriele Colombo, Ognjan Denkovski, Carmen \nFerri and Holly Foxton.\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch06\n170  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nto disinformation campaigns and dubious information, not so unlike the \nWeb itself. Regardless, they do not exist in a vacuum. On the fringes of the \nWeb, yet difficult to characterize as marginal, are pseudonymous or anony -\nmous platforms like Reddit and 4chan. Instead of public-facing \u2018e-celebs\u2019 or \notherwise identifiable accounts, these spaces are characterized by \u2018masked\u2019 \nusers with distinctive subcultural styles, vernaculars and iconographies. \nThe pseudonymous and anonymous users on Reddit and 4chan do not only \ncongregate around shared interests or common goals, but also \u2013 and in some \ncases predominantly \u2013 around a deep understanding of shared subcultural \nknowledge and norms. The unconventional and sometimes downright eso -\nteric cultural productions some of these groups create feed into community \nmembers\u2019 self-imagination as \u2018underground\u2019, \u2018countercultural\u2019, or \u2018internet \nnative\u2019. 4chan and (parts of) Reddit can be associated with the term \u2018deep \nvernacular Web\u2019 (Tuters and De Zeeuw, 2019), referring to online discussion \nforums that lack stable user identities and whose masked participants \nfrequently transgress the boundaries of \u2018mainstream\u2019 conventions, often \nthrough an entangled mix of sincere ideology and ironic play.\nWhile Facebook, Twitter, Instagram and YouTube have already been studied \nin relation to issues of \u2018fake news\u2019, the abovementioned \u2018virality-oriented \nsubcultures\u2019 of the deep vernacular Web are also said to play a \u2018crucial role in \nthe system\u2019 of the circulation of various types of \u2018junk news\u2019 (Venturini, 2019). \n4chan and certain parts of Reddit have indeed been characterized as hotbeds for \ndisinformation (Shiebel, 2017; Collins and Russell, 2018; Lagorio-Shafkin, 2018), \ntrolling campaigns (Phillips, 2015), and conspiracy theories (Marwick and Lewis, \n2017; Tuters et al., 2018). Despite their relatively marginal number compared to \nmore mainstream platforms, users of 4chan and areas of Reddit are considered \nparticularly skilled in \u2018setting the agenda\u2019 of broader news media (Phillips, 2018). \nIn a 2017 report, Marwick and Lewis highlight how an underground current of Internet subcultures associated with 4chan and Reddit \u2018take advantage of \nthe current media ecosystem to manipulate news frames, set agendas, and \npropagate ideas\u2019 (Phillips, 2018: 1). Later, Phillips builds on this research by \nexploring how and why the false narratives of these online antagonists were \namplified by major U.S. news outlets (2018). As she identifies, journalists were \nkeen on reporting the narratives with false information or dark undertones \npartly because of a fascination with their bizarre cultural phenomena or simply \ndue to a lack of time required to decipher their problematic code language. \nThe reporting, she argues, \u2018amplifies\u2019 their overall presence. By 2019, there \nare now well-known by-products of this cycle of the normalization of false \ncontent emerging from fringe online spaces. To provide but one example, the \n\u2018Pizzagate\u2019 conspiracy theory, originating on 4chan, presumed the Clintons \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  171\nwere maintaining a child sex trafficking ring, which led to media coverage and \nan actual shooting in a US pizza parlour (Tokmetzis, 2018; Tuters et al., 2018). A \nrelated conspiracy theory, \u2018QAnon\u2019, gradually spread from 4chan to Reddit and \nmainstream news sources (Hagen et al., 2019), even sprouting international \nsupport groups including \u2018QAnon Nederland\u2019 (QAnon Netherlands).\nThe influence of fringe internet subcultures on the news ecosystem has \nmostly been scrutinized in relation to English-language spheres and U.S. \npolitics. As such, it remains unclear to what extent the propagation of prob -\nlematic content from the \u2018deep vernacular Web\u2019 affects other news ecosystems \nsuch as the Dutch. Such activity already has caught the attention of Dutch \nmedia outlets. For example, the QAnon conspiracy was covered by major \noutlets like RTL Nieuws (2018) and Algemeen Dagblad  (Van Huet, 2018), while \nDe Correspondent  untangled the related Pizzagate conspiracy in some depth \n(Tokmetzis, 2018). De Volkskrant  discussed Dutch users active in the far-right \n\u2018politically incorrect\u2019 subforum of 4chan, /pol/, by observing an increasing \nprevalence of anti-Semitic conspiracies (Kranenberg and Bahara, 2018). In a \nbroader sense, conspiratorial rhetoric native to the deep vernacular Web seems \nto be normalizing in the Dutch political and media discourse at large. For \ninstance, the concept of \u2018cultural Marxism\u2019 has increasingly appeared in Dutch \nnews media (Van den Bos, 2018). It concerns a theory assuming a Marxist and/\nor Jewish network pulling the strings of European institutions \u2013 a narrative \nparticularly popular on 4chan/pol/. Dutch politicians have subsequently \nflirted with such sweeping theories. For instance, the party Forum voor \nDemocratie tweeted that Mark Rutte was a puppet of the Jewish philanthropist \nGeorge Soros ,2 while the party\u2019s leader Thierry Baudet supported the most \nconspiratorial aspects of the \u2018cultuurmarxisme\u2019 debate, tweeting that the \nEuropean Union is \u2018a cultural Marxist project aiming to destroy European \ncivilization\u2019.3 NOS, the public broadcaster, subsequently published an article \nframing George Soros as an \u2018influential meddler with tentacles deep in world \npolitics\u2019,4 which was later withdrawn after heavy criticism pointing out the \n2 T he original Dutch tweet by Forum voor Democratie notes: \u2018@MinPres [i.e. Mark Rutte] \ndraait er niet eens meer omheen: De belangen van NDO\u2019s (lees: Soros) gaan boven het beleid \nvan de democratisch gekozen regering van #Hongarije. Hoogste tijd dat deze loopjongen van \nhet grootkapitaal nu van het toneel verdwijnt. Reken af met #Rutte op 20\u00a0maart! Stem #FVD\u2019 \n(@fvdemocratie, 14 Sep.\u00a02018).\n3 T he original Dutch tweet by Baudet noted: \u2018Omdat de Europese Unie een cultuurmarxistisch \nproject is dat tot doel heeft de vernietiging van de Europese beschaving\u2019 (@thierrybaudet, 19 \nAug. 2017).\n4 I n their original article, NOS  used the title \u2018George Soros: invloedrijke bemoeial met tentakels \nver in de wereldpolitiek\u2019 and noted: \u2018De jood Soros steunt organisaties die regeringen openlijk \nbekritiseren [\u2026]. Dat moet stoppen, zeggen tegenstanders\u2019 (Peek 2018).\n172  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nframing\u2019s commonalities with anti-Semitic rhetoric (Peek, 2018). While direct \nties between such mainstream attention and fringe internet platform rhetoric \nare not to be drawn, each incident in its own right could be situated in the \naforementioned dynamics of amplification in a Dutch context.\nThe falsehoods cooked up on the deep vernacular Web are hard to \ngrasp through the concepts of \u2018disinformation\u2019 or \u2018fake news\u2019, since their \n\u2018fakeness\u2019 is broader than deliberately coordinated campaigns or clearly \nfalse information. Rather, they speak to what Muirhead and Rosenblum \n(2019) call a \u2018new conspiracism\u2019, whereby sweeping accusations are made \nindependent of evidence or coherent explanations, and complex phenomena \nare \u2018explained\u2019 through \u2018conspiracy without theory\u2019. Such conspiracism is said \nto be dangerous since it delegitimizes the knowledge-making institutions \nat the foundations of democratic societies (Muirhead and Rosenblum, 2019). \nImportantly, this conspiracism can be fuelled by or work alongside a mix of \nforeign interferers, sincere believers and hyperpartisan actors.\nTo understand these broad range of actors and interests that stimulate the \nemergence of problematic information, the concept of \u2018junk news\u2019 (or \u2018pulp -\nnieuws\u2019) is more apt. Junk news shifts the focus from clear and coordinated \nfalsehoods towards a broader notion of news crafted to be engaged with and \nto circulate, which, in turn, stimulates polarizing or \u2018simple\u2019 information \nthat \u2018saturates public debate\u2019 (Venturini, 2019). Junk news thereby forms \nan umbrella term for conspiracies, hyperpartisan slander, \u2018ironic\u2019 false -\nhoods, low-effort clickbait articles, as well as deliberate disinformation. \nThe circulation of these types of junk news has a plethora of reasons, but as \nnoted \u2018tightly-knit communities\u2019 (Zannettou, 2017) and \u2018virality-oriented\u2019 \nsubcultures creating and engaging with this highly \u2018shareable\u2019 content are \nsaid to be a crucial factor in their effectiveness (Venturini, 2019).\nMuch has been said about the grassroots production of false narratives \nwithin  spaces like Reddit and 4chan (Marwick and Lewis, 2017; Phillips, 2018; \nTuters et al., 2018; Benkler et al., 2018). However, a more elementary question \nis usually left untouched: what kinds of news sources do these actors rely on \nthemselves? Zannettou et al. (2017) found that \u2018\u201cfringe\u201d communities often \nsucceed in spreading alternative news to mainstream social networks and \nthe greater Web\u2019 (1), employing a statistical model (Hawkes process) that \nindicated that fairly marginal spaces like Reddit\u2019s pro-Trump subforum r/\nThe_Donald and 4chan\u2019s /pol/ board are often first to post a URL to alter -\nnative news, only later catching attention on Twitter. They furthermore \ntraced which alternative sources were shared on Reddit, 4chan, and Twitter, \nshowing that alternative news was shared more often on 4chan/pol/ and \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  173\nselect subreddits than on Twitter, noting the popular use of breitbart.com, \nrt.com, infowars.com, and sputniknews.com across the three platforms.\nWhat about junk news in a Dutch context? Is there a Dutch alternative \u2018junk \nnews\u2019 network within the deep vernacular web, or do these platforms mostly \nrely on mainstream sources? If found, how vast is the presence of Dutch junk \nnews in these spaces? In identifying linked-to websites, can signs of coordinated \ndisinformation campaigns be discerned? Or are the types of junk news shared \nmostly hyperpartisan, clickbait, or some other \u2018junk\u2019 category? These questions \nare of interest when applied to fringe and \u2018extreme\u2019 spaces like 4chan/pol/ but \ncan also aid in positioning more widely used yet still largely \u2018alternative\u2019 spaces, \nlike the largest Dutch subreddit, r/thenetherlands. The research reported here \nthereby begins with the question, where does Dutch junk news appear (if at \nall) on Reddit and 4chan/pol/? Subsequently, it asks, what kinds of junk news \nresonate? It concludes with a brief section on YouTube as a possible alternative \nnews network by following the links to Google\u2019s video platform.\nDemarcating the Dutch spaces and Dutch junk news in the deep \nvernacular Web\nCase studies: Reddit and 4chan\nFor Dutch cases of virality-oriented subcultures, we focus on Reddit and 4chan/\npol/. Although less known than the likes of Twitter, Facebook, Instagram and \nYouTube, Reddit is one of the largest discussion sites globally, with Alexa metrics \ncurrently showing 234 million unique visitors per month. The platform is divided \ninto different subreddits dedicated to the discussion of specific topics, such as \nr/tennis or r/politics. Posts on these subreddits can be \u2018upvoted\u2019 or \u2018downvoted\u2019 \nby users. The higher the post\u2019s score (upvotes minus downvotes), the higher it is \nplaced in a ranked list of content and the more visibility it gains. In the comment \nsection underneath every post, \u2018redditors\u2019 discuss, debate, or simply joke around. \nReddit\u2019s Dutch user base seems to be growing (as is shown below), with the \nlargest Dutch subreddit r/thenetherlands amounting to 236,000 \u2018subscribers\u2019 at \nthe time of writing. Its growing popularity makes it an increasingly important \nobject of study in a Dutch context. This is heightened by the fact that Reddit \nhas been identified as a target of multiple Russian disinformation campaigns, \nwith \u2018at least a hundred\u2019 IRA accounts influencing the 2016 U.S. elections and \ncampaigns continuing into late 2018 (Collins and Russel, 2018; Lagorio-Shafkin, \n2018). Exploring whether such campaigns have also transpired within Dutch \nspheres of Reddit is thus part of the objective of this research.\n174  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nThe second case study is 4chan, an infamous imageboard where users post \nanonymously within one of its subforums (called boards) dedicated to different \ntopics like videogames or fitness. 4chan is ephemeral, meaning posts are deleted \nfrom the site after a few days or even hours. It is a visual environment conducive \nto the production of viral content and generation of junk news (Venturini, 2019). \nThe space\u2019s creativity extends beyond the generation of alternative theories, as \n4chan is also infamous as the \u2018birthplace of internet memes\u2019, as well as a hotbed \nfor nebulous political movements. The latter include \u2018Anonymous\u2019, the loose \n\u2018masked\u2019 collective of geeks and hackers infamous for trolling and DDoSing the \nlikes of the Church of Scientology and MasterCard (Coleman, 2014), as well as \nmore recently the \u2018alt-right\u2019, once characterized as an \u2018amalgam of conspiracy \ntheorists, techno-libertarians, white nationalists, Men\u2019s Rights advocates, \ntrolls, anti-feminists, anti-immigration activists, and bored young people\u2019 \n(Marwick and Lewis, 2017: 3) but now arguably pertaining to the extreme side \nof those far-right actors. For this research, we chose to focus squarely on 4chan\u2019s \npolitics board, /pol/. This is the most relevant board in relation to the research \nquestions, for it is currently among the most active boards on the website5 and \nis a fertile ground for conspiracy theories (Tuters et al., 2018) and alternative \nnews sources (Zannettou, 2017). 4chan/pol/ is a far-right space, identified as a \nrecruitment zone for neo-Nazis (Wendling, 2018) and connected to various acts \nof extreme violence (Hankes and Amend, 2018). This partisanship naturally \naffects the types of news shared on this platform. For balance, other partisan \nareas of the deep vernacular Web were also considered (e.g., 8chan/leftypol/) \nbut were ultimately found too insignificant in terms of Dutch activity.\nTools and timeframe\nIn contrast to mainstream platforms like Facebook and Twitter, data from \nReddit and 4chan are rather accessible. For most of the data collection, we \nused 4CAT (Peeters and Hagen, 2018), a tool developed by the Digital Methods \nInitiative that captures data from a variety of sources, including 4chan/pol/ since \nNovember\u00a02013. For Reddit, 4CAT makes use of the Pushshift API, which allows \naccess to an archive of nearly all Reddit posts and comments (Baumgartner, 2018).\nWe chose a timeframe from 1\u00a0December\u00a02015 up to 1\u00a0June\u00a02019, span -\nning 4 1/2 years in total. Whereas most other studies in this volume present \n5 A t the time of writing, the website 4stats.io, which tracks activity on each 4chan board, lists \n/pol/ and /v/ (video games) as the most active boards, with almost 50 posts per minute and 120 \nthousand posts per day (taking the last 4 weeks as a benchmark). These numbers are supported \nby metrics from our own tools (Peeters and Hagen, 2018).\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  175\nFigure\u00a06.1   T he frontpage of Reddit (retrieved 11\u00a0June\u00a02019)\nFigure\u00a06.2   T he index page of 4chan/pol/ (retrieved 11\u00a0June\u00a02019)\n\n176  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \ntimeframes based on specific events, this long-term timeframe is more \nsuitable here for multiple reasons. Firstly, as we will show, the activity in \nrelation to junk news posting on these platforms was shown to be fairly \nmarginal in comparison to more mainstream social media websites. A larger \ntimeframe thereby aids to arrive at patterns in this relatively small stream of \ndata. Secondly, to the best of our knowledge, it is the first time the presence of \nquestionable Dutch  news is researched on these platforms, so it makes sense \nto start with a high-level perspective on the object of study instead of limiting \nit to a particular case. Moreover, this timeframe includes a variety of major \npolitical events in the Netherlands, including the general elections in 2017 and \nmore recently the provincial and European parliamentary elections in 2019.\nAnalyses: Haystack to needle and needle to haystack\nAs the research focuses on the presence of junk news linked to  on Reddit \nand 4chan/pol/, it takes URLs as the primary research objects. To provide \nan overview of the types of news linked to, we decided to focus on domain \nnames (sources) instead of links to individual articles (stories). To identify and \ncategorize domains, we used two related approaches, referred to metaphorically \nas \u2018haystack to needle\u2019 and \u2018needle to haystack\u2019. The haystack to needle approach \ndenotes a macro to micro inquiry where all  domains posted were categorized \nin order to subsequently identify the presence of Dutch junk news within this \nlarger pool of data. The needle to haystack does the reverse and starts from \nan expert list of Dutch junk news domains6 and subsequently enquires into \nwhen and where these sources appear, and, for Reddit, what kinds of users \npost them. The next two subsections describe these approaches in more depth.\nHaystack to Needle\nThe haystack to needle  approach moves from a high-level overview to the \ncategorization of particular linked-to domains, specifically by parsing (1) \nnews from non-news, (2) Dutch news from non-Dutch news, and (3) types \nof junk news (mainstream/junk and types of junk). To do so, a Dutch sphere \nfirst had to be defined for Reddit and 4chan/pol/ from which an initial list \nof domains could be extracted. For Reddit, the full dataset of opening posts \n6 T he expert list is comprised of an original list by De Hoax-Wijzer , edited to remove inactive \nsources, with additional sites added through qualitative analysis by University of Amsterdam \nresearchers.\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  177\nwas filtered for a list of Dutch subreddits (thus excluding comments; the most \n\u2018authoritative\u2019 and visible URLs are usually in opening posts). The relevant \nsubreddits were compiled from a set of \u2018related communities\u2019 posted by \nadministrators of r/thenetherlands7 and supplemented through querying \nDutch issues on Reddit. This resulted in a final collection of 182 subreddits \n(see Appendix 6.1). Not all of these subreddits were equally of interest, but \nwe nonetheless kept the full list considering our bird\u2019s-eye approach. On \n4chan/pol/, all posts show a flag icon indicating the location of the IP address \nof the poster. To identify a Dutch sphere on /pol/, all posts with a country \nflag of the Netherlands were extracted. It is important to note that this only \nresults in a partial sample of Dutch posters, since users can also choose to \ndisplay a custom flag (like \u2018Hippie\u2019) instead of one based on geolocation, or \nthey can spoof their IP addresses. In all, the dataset collected consists of over \n2 million posts with Dutch country flags, forming a large enough sample to \ngauge the presence of Dutch junk news using the haystack to needle approach.\nHaving demarcated Dutch spheres on Reddit and 4chan/pol/, domains \nfrom URLs posted were extracted from all posts. For Reddit, this resulted \nin 3,489 unique domains. To make categorization manageable, only the \ndomains that were posted five times or more were retained. This resulted \nin a list of 372 domains. Similarly, domain names from the Dutch 4chan/\npol/ posts were extracted using 4CAT, yielding 8,048 domains.8 To arrive at \na comparative sample, we kept the domains that were posted twenty times \nor more, resulting in 352 unique domains.\nThe two lists were then categorized according to (1) whether the domains \nwere news websites, (2) whether the news websites were in the Dutch lan -\nguage or concerned Dutch affairs, and (3) the category of news websites \nthey would fall in. \u2018News websites\u2019 here refer to a fairly broad selection of \nwebsites focusing on the production of news and opinionated columns \nwhich contain a section dedicated to timely updates. They include blogs on \ncurrent affairs, special interest news, and websites of TV news programmes. \nThereafter, the news sources were categorized as follows:\n\u0336 M ainstream: Reporting by \u2018established\u2019 general news outlets with a \npredominantly neutral tone of voice.\n\u0336 O ther mainstream: All other mainstream news websites concerning \nspecial interests, such as business or sports news.\n7 S ee: https://www.reddit.com/r/theNetherlands/wiki/related. Accessed 25\u00a0March\u00a02019\n8 T his is a higher number than for Reddit because for 4chan, not only the first posts in a \nthread were kept, but also the replies, matching 4chan\u2019s infrastructure of more \u2018horizontal\u2019 \nconversational threads.\n178  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \n\u0336 D isinformation: Sources deliberately publishing false information, often \nwith harmful intention, and part of a network or campaign.\n\u0336 H yperpartisan: Extremely coloured and \u2018openly ideological\u2019 reporting and \neditorializing from a far end of the political spectrum (Herrman 2016).\n\u0336 C\nlickbait: Sources consisting mainly of articles with sensational head-\nlines and gossip, often in the form of cliff-hangers and listicles, with a \nfinancial incentive to gain advertising revenue.\n\u0336 C onspiracy: Sources mainly dedicated to propagating a range of ex -\nplanations to events behind which are secret plots and multiple actor entanglements.\nThree researchers categorized the domains, discussed the debatable cases \nwith other researchers in this volume for higher intercoder reliability, and used external sources like mediabiasfactcheck.com. Mostly, these discus -\nsions were held for websites that could be categorized with multiple labels \nor that fall between hyperpartisan and mainstream such as tendentious \nones (Peeters and Rogers, this volume). A caveat to this method is that \ncategorizing websites on a source instead of story level results in stories being \nlabelled, for example, as \u2018hyperpartisan\u2019, even though the categorization \nwould differ on a story-by-story basis. Websites like The Post Online , for \ninstance, contain stories from press agencies as well as tendentious and \nhyperpartisan ones. Despite this, the rigorous domain categorization did \nallow preliminary overviews, which is why it was fitting for the \u2018bird\u2019s-eye\u2019 \nperspective of this research. In the haystack to needle approach, we kept \nand categorized the non-Dutch news sources, since they made up a sizable \npercentage of posts, especially on 4chan. Considering these are largely \nDutch users, it is worth understanding what foreign sites they circulate. To \nshow the different categorizations (news or non-news, Dutch or non-Dutch, \ntypes of news), they were visualized in treemap diagrams using the software \nRAWGraphs (Mauri et al., 2017).\nNeedle to Haystack\nNext, the needle to haystack approach was used to analyze the prevalence of \nDutch junk news in the entirety of Reddit and 4chan/pol/, now by starting \nwith a list of URLs that were already identified as questionable. This list was \nconstructed by combining an edited list by De Hoax-Wijzer  (\u2018Valse Nieuws -\nsites\u2019, n.d.) with websites found through engagement analysis by researchers \nin this volume (see Appendix 6.2). The list refers to Dutch domains known \nto present news of questionable validity, with an overwhelming partisan \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  179\ntone but also occasionally showing traits of conspiracism. The list was \ncoded by the researchers who compiled it and contains the categories \nhyperpartisan, clickbait, conspiracy, and disinformation.9 We fetched all \nthe posts containing these domains with 4CAT, resulting in 1714 posts on \nReddit and 443 on 4chan/pol/.\nWe then \u2018scoped\u2019 how often junk news appears over time, plotting it as \nhistograms. To compare these junk posts to all  of Reddit, Google BigQuery \nwas used. The total number of posts within subreddits where at least one \nDutch junk domain appears was fetched to calculate the relative pres -\nence of junk news. Additionally, the \u2018size\u2019 of the Dutch Reddit sphere and \nthe entirety of Reddit was retrieved through fetching the total number of \nposts on Dutch subreddits and on Reddit overall. The data was mapped \nas circle-pack diagrams with RAWGraphs. For 4chan/pol/, we used 4CAT \nto fetch all posts (both opening posts and replies) mentioning one of the \ndomain names from the expert list in the full  timeframe. In order to identify \ntemporal trends, the amount of posts with Dutch junk domains was plotted \nper month as histograms.\nCharacterizing junk news propagation on Reddit\nFinally, to characterize the kinds of actors propagating Dutch junk news \nand the effectiveness of their activities, various metrics were calculated for \n(further anonymized) junk news posters on Reddit. A similar analysis was \nimpossible for 4chan/pol/ owing to the imageboard\u2019s anonymity and lack \nof \u2018repurposable\u2019 objects to shine light on the posters. Taking the needle to \nhaystack  approach, 4CAT and the Pushshift API were used to retrieve all \nposts by Reddit accounts who posted a source from the expert list at least twice . The retrieved users were considered \u2018junk news propagators\u2019 for the \npurposes of this research. The following metrics were calculated for the \ntotal corpus as well as for individual users:\n\u0336 S\nubreddits most posted often in.\n\u0336 A\nverage score of all posts as indicated by the Pushshift API.10\n\u0336 A verage score of posts referring to Dutch junk news domain as indicated \nby the Pushshift API.\n9 I t also has the category tendentious-hyperpartisan, which seeks to capture sources like \nThe Post Online that have stories from press agencies as well as hyperpartisan columns and \nother contributions that could be described as \u2018edgy\u2019, anti-establishment and against political \ncorrectness (Tuters, this volume).\n10 T hese scores might slightly differ from their latest number; Pushshift stores it only once, \ni.e., upon encountering the post.\n180  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \n\u0336 M ost linked-to domains.\n\u0336 T\notal posts with domains to Dutch junk domains.\n\u0336 P\nercentage of posts linking to Dutch junk domains.\n\u0336 T\notal posts by user.\nThe Reddit users\u2019 pseudonyms were (further) anonymized, since not the \nidentity but rather the characteristics of the users is of importance here. \nThe first four metrics in the list above were plotted for the whole corpus in \nhistograms and circle diagrams, while all metrics were also visualized in \na matrix for the ten most active Dutch junk news posters, i.e., those who \nlinked to the domains from the expert list most often.\nFollowing and categorizing YouTube links\nYouTube emerged as one of the most popular websites linked to on \u2018Dutch \nReddit\u2019 and \u2018Dutch 4chan/pol/\u2019. Since the video platform is often described \nas offering alternative news consumption, we also followed the links to \nYouTube videos in all posts in Dutch subreddits and 4chan/pol/ posts \nwith a country flag of the Netherlands. Having collected these links, we \nused 4CAT\u2019s \u2018YouTube metadata\u2019 module (in turn using YouTube\u2019s API) \nto retrieve metadata on the videos linked to, such as video title, views, \nand topics. We then plotted the thumbnails of the 100811 videos that were \nlinked to most often on image walls with a custom Python script. To \nvisualize what types of videos these concerned, we plotted YouTube\u2019s \n\u2018video categories\u2019 (selected by the uploaders) on top of the image wall. We \nfinally ranked the most-linked to YouTube channels, derived from the full \nlist of videos linked to on 4chan and Reddit, to gain a grasp of the type \nof video content posted.\nScoping Dutch junk news\nThis section explores the scope of Dutch junk news on both platforms \nunder study. We do so by showing the volume of posts linking to one of \nthe URLs in the expert list (i.e., the needle to haystack approach). These \nare then compared to the overall volume of (Dutch) posts on Reddit and \n4chan/pol/.\n11 W e settled on the peculiar number of 1008 since it would make the image wall adhere to \nthe common 18:9 screen aspect ratio.\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  181\nScoping junk news on Reddit\nFirst, as a way to ground the corpus, Figure\u00a06.3 shows the total amount of \nposts made on one of the Dutch subreddits (Appendix 6.1). Just like activity \non Reddit in general, Dutch activity is increasing: in December\u00a02015 there \nwere just over 2,000 posts and comments per month, whereas in January\u00a02019 \nthis number had grown to 14,000 and seems to be rising.\nDoes this increase in activity also mean an increase in Dutch junk news \nlinked to on Dutch subreddits? As is evident in Figure\u00a06.4, the amount \nof posts linking to one of the domains from the expert list started at a \nmaximum of just eighteen instances in 2016. Two subsequent spikes can \nbe observed. The first one, in April to July\u00a02017, speak to the \u2018spammy\u2019 \nnature of some areas of Reddit, since one user frequently posted a Dutch \njunk news domain (ninefornews.nl) to an English subreddit. The second \nspike is more varied, however, showing a range of websites like boinnk.nl, \nworldunity.me, and ninefornews.nl. Upon closer inspection, these were \nagain posted by a single account, mrthirdeye, the closest one will find \nto a \u2018fake news troll\u2019, though its posts received little to no engagement \n(discussed in more detail in section\u00a04). The subsequent dip in November Figure\u00a06.3   T otal amount of posts and comments on one of the Dutch subreddits \n(see Appendix 6.1)\nda ta source: 4 c aT a nd Pushshift; timeframe: 1- de c-2015 to 1-Jun-2019; line graph\n182  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \ncan be attributed to a content policy change in 2017, possibly leading to \nthe banning of this malicious account (Alexander 2017). In subsequent \nmonths, junk news sharing increased somewhat compared to 2016 but \nremained fairly consistent with around fifty instances per month. An \nincrease of posts linking to (at the time) a tendentious-hyperpartisan \nwebsite, The Post Online, can be seen in 2019, although no significant spikes \nduring the 2019 Dutch provincial elections and 2019\u00a0European elections \ncan be discerned. In perspective, these numbers do not seem extremely \ntroubling, especially since most posts link to hyperpartisan sources instead \nof outright disinformation (see section\u00a03), and furthermore do not receive \na lot of engagement (see section\u00a04).\nTo further put the scope of Dutch junk news on Reddit in perspective, Fig -\nures 6.5 to 6.8 contain circle pack diagrams that show its amount compared \nto the entirety of Reddit, as measured in terms of posting activity (excluding \ncomments). Figure\u00a06.5 shows the size of all subreddits where a link to a Dutch \njunk news source was shared at least once. The Dutch subreddits are tiny \nin comparison to non-Dutch subreddits (Figure\u00a06.5), given the dominance \nof English-language subreddits on the site. There are a few occasions when \nDutch junk news was shared on very large subreddits, such as r/viral, r/news, \nand r/worldnews, as well as the infamous pro-Trump subreddit, The_Donald. \nNotably, however, in the Dutch subreddits, the proportion of junk news is Figure\u00a06.4   F requency of posts linking to Dutch junk news domains on Reddit\nda ta source: go ogle bi gQuery; timeframe: 1- de c-2015 to 1-Jun-2019; stream graph\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  183Figure\u00a06.5   D utch versus non-Dutch subreddits in which Dutch junk news appears. Size of circle represents the overall number \nof posts in that subreddit within the timeframe, and colour represents the relative amount of posts with junk news.\nda ta source: go ogle bi gQuery. Timeframe: 1- de c-2015 to 31-Jan-2019; circle pack diagram\n184  S al ha gen and eMi liJa J okubau Sk aiT\u0117  Figure\u00a06.6   D utch subreddits where Dutch junk news appear compared to the size of all Dutch subreddits. \nSize of circle represents the overall number of posts in that subreddit, and colour represents the \nrelative amount of posts with junk news.\nda ta source: go ogle bi gQuery. Timeframe: 1- de c-2015 to 31-Jan-2019; circle pack diagram\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  185\nFigures 6.7 and 6.8   A ll Dutch and non-Dutch subreddits where Dutch junk news \nappear compared to the size of all of Reddit. Size of circle \nrepresents the overall number of posts in that subreddit, and colour represents the relative amount of posts with junk news.\nda ta source: go ogle bi gQuery. Timeframe: 1- de c-2015 to 31-Jan-2019; circle pack diagram\n186  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nvery low as well. As will be touched on, only occasionally does a subreddit \nhave over 5% of its posts linking to Dutch junk news. For the majority of \nsubreddits, this figure is less than 1%.\nWhen zooming in on Dutch subreddits (Figure\u00a06.6), a clearer variation in \nthe volume of junk news is observable. For the subreddits where these sources \nappear, they are still in small amounts, with the highest percentages appear -\ning in r/Forum_Democratie (5,37% of all posts), r/meerderheidnederland \n(5,67%), r/de_thierry (4,93%), r/Duindorp (13%), r/The_Wilders (1,97%), and \nr/FreeDutch (3,04%). Most of these subreddits are related to right-wing \npolitical parties, ideologies or politicians, such as Geert Wilders or Thierry \nBaudet. These subreddits appear mostly because of the frequent posting of \nlinks to hyperpartisan websites such as De Dagelijkse Standaard .\nWhen compared to the overall Dutch sphere on Reddit (Figure\u00a06.6), quite \na large area of the Dutch subreddits has at least some presence of junk news \nfrom the expert list. Still, the largest and most mainstream Dutch subreddits \n(r/thenetherlands, r/cirkeltrek, r/Amsterdam) contain a negligible amount. \nDutch junk news can most notably be seen within already polarized or \npartisan spaces, such as the right-wing subreddits listed above. Larger and \nless partisan subreddits like r/thenetherlands seem fairly immune, likely \nbecause of a different user base and content moderation.\nLastly, Figures 6.7 and 6.8 provide a zoomed-out visualization of the \nrelative amount of Dutch junk news in the entirety of posts on Reddit. While \nsome Dutch junk news appears in a number of both Dutch and non-Dutch \nsubreddits, it pales in comparison to the total number of posts in other \nsubreddits in the research timeframe. Moreover, even though some Dutch \njunk news appears on a number of large international subreddits (in turn, \nmaking the sphere appear large), the relative  number of appearances of \nDutch junk news in those subreddits is close to zero. Concluding, then, in \nterms of frequency, links to questionable Dutch-language news sources on \nReddit is a small issue outside of a few partisan subreddits.\nScoping junk news on 4chan/pol/\n4chan\u2019s infrastructure allows less of a comparative approach than that \nof Reddit, but some metrics can shine light on the relative appearance of \nDutch junk news on /pol/. First, to scope the Dutch sphere, the amount \nof posts with the country flag of the Netherlands is fairly stagnant since \nlate 2015 (Figure\u00a06.9). Each month, around 40,000 \u2018Dutch flagged\u2019 posts are \nmade. The amount increased in March\u00a02017, owing to the Dutch general \nelections. While these numbers are lower in comparison to Dutch users on \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  187\nmainstream platforms like Facebook, they are at times comparable to Reddit, \nand a non-negligible number \u2013 a fairly significant insight considering the \nextreme political ideas present on /pol/. It is impossible to tell how many \nindividual people these numbers of posts denote, however.\nDespite the frequent Dutch posts on /pol/, the amount of posts linking \nto Dutch junk news is quite low (Figure\u00a06.10). Links to Dutch junk news \ndomains appear only around ten times per month. One significant spike \noccurs in March\u00a02017, caused by links mostly to The Post Online and  De \nDagelijkse Standaard , again concerning the general election on March\u00a015. \nInterestingly, a similar spike associated with the elections is absent from \nReddit. Afterwards, however, the amount of posts linking to Dutch junk news \ndrops, remaining low for both the 2019 Dutch provincial elections and the \n2019\u00a0European elections. Considering the total amount of posts by Dutch /pol/ \nusers (averaging around 40,000 posts per month), the amount of references to \njunk news URLs should be considered negligible. This should not be equated \nwith a lack of problematic news content, however, as is discussed below.\nCategories of Dutch junk news\nHow sizable of a role do online news media play within 4chan/pol/ and Red -\ndit? What types of domains are linked to when categorizing news domains Figure\u00a06.9   Line gr aph of posts with Dutch country flags on 4chan/pol/\nda ta source: 4 c aT ; timeframe: 1- de c-2015 to 01-Jun-2019; line graph\n188  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nposted in these forums? What types of junk news can we discern? This \nsection uses the haystack to needle approach to walk through a number of \ntree maps, each showing a different categorization of the most-linked to \ndomains. First, the proportion of news websites is compared to non-news \ndomains. Afterwards, the news websites are sorted by Dutch or non-Dutch. \nFinally, the categories of these news sources are outlined and discussed \n(mainstream, hyperpartisan, disinformation, etc.).\nFirstly, Figures 6.11 and 6.12 show which domains from the most-posted \ndomain sample are categorized as \u2018news\u2019. For Reddit (Figure\u00a06.11), 21,6% of \nall posts on Dutch subreddits refer to \u2018news\u2019 websites. Notably, tweedekam -\ner.nl appears 15,694 times, caused by the bot u/kamerstukken-bot posting \nparliamentary texts to the subreddit r/kamerstukken. Removing this bot \nincreases the news proportion to 50% \u2013 quite a considerable number. \nOther non-news websites include reddit.com itself, often used to host \nimages and text, and youtube.com and youtu.be, appearing 951 times \ncumulatively.\n4chan/pol/ paints quite a different news/non-news picture. At 16.6% the \nproportion of links to news websites is lower than Reddit\u2019s 50%. After twitter.\ncom and en.wikipedia.org, a staggering 50% of URLs point to YouTube. \nConsidering this major presence of Google\u2019s video service, it is further \nscrutinized as an alternative news sphere in section five.Figure\u00a06.10   F requency of posts linking to Dutch junk news domains on 4chan/pol/\nda ta source: 4 c aT ; timeframe: 1- de c-2015 to 01-Jun-2019; streamgraph\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  189Figure\u00a06.11   Links t o news (red) and non-news (blue) sources in posts in Dutch subreddits\nda ta source: 4 c aT a nd Pushshift; timeframe: from 1- de c-2015 to 01-Jun-2019; treemap diagram\n190  S al ha gen and eMi liJa J okubau Sk aiT\u0117  Figure\u00a06.12   Links t o news (red) and non-news (blue) sources in Dutch posts on 4chan/pol/\nda ta source: 4 c aT ; timeframe: 1- de c-2015 to 1-Jun-2019; treemap diagram\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  191Figure\u00a06.13   Links t o Dutch (orange) and non-Dutch (blue) news on Dutch subreddits\nda ta source: 4 c aT a nd Pushshift; timeframe: 1- de c-2015 to 01-Jun-2019; treemap diagram\n192  S al ha gen and eMi liJa J okubau Sk aiT\u0117  Figure\u00a06.14   Links t o Dutch (orange) and non-Dutch (blue) news on Dutch subreddits\nda ta source: 4 c aT ; timeframe: from 1- de c-2015 to 01-Jun-2019; treemap diagram\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  193Figure\u00a06.15   C ategories of news domains in posts on Dutch subreddits\nda ta source: 4 c aT a nd Pushshift; timeframe: 1- de c-2015 to 01-Jun-2019; treemap diagram\n194  S al ha gen and eMi liJa J okubau Sk aiT\u0117  Figure\u00a06.16   C ategorized types of news from news sources posted 4chan/pol/\nda ta source: 4 c aT ; timeframe: 1- de c-2015 to 1-Jun-2019; treemap diagram\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  195\nFigures 6.13 and 6.14 show the news domains on Reddit and 4chan/pol/, \nrespectively, according to their origin (Dutch or non-Dutch). On Reddit, the \ndomains shared on Dutch subreddits are almost exclusively of Dutch origin. \nThis is likely due to content moderation in these spaces, requiring posts to \nbe specifically about the Netherlands (e.g. on r/thenetherlands). The news sources on 4chan/pol/ (Figure\u00a06.4), on the other hand, are predominantly from Anglophone sources, such as The Daily Mail , The Guardian , BBC , and \nReuters . This is fairly unsurprising considering 4chan/pol/\u2019s designation as an \nEnglish language space, unlike the Dutch subreddits. Still, it is worth noting \nthat Dutch users on 4chan/pol/ are mostly concerned with English sources \nand are thus more internationally oriented in terms of news propagation \nthan users on Dutch subreddits. This also implies foreign news sources \nmight significantly influence their news consumption. As shown below, \nEnglish junk news is indeed posted by these Dutch \u2018anons\u2019.\nNext, we explore the types of news sources, and if \u2018junky\u2019, how they can \nbe categorized. Figures 15 and 16 show the categorization of the shared news \ndomains as mainstream, other (mainstream), conspiracy, disinformation, \nhyperpartisan, and clickbait, as defined in section\u00a01.3.1. As is evident in the \nvisualizations, mainstream or special interest (other mainstream) sources \nmake up the largest share of URLs posted on both platforms: 99,6% for \nReddit and 81% for 4chan/pol/. Despite the frequent characterization of \npseudonymous spheres like Reddit as \u2018alternative\u2019, these results are thus \nsomewhat counterintuitive since mainstream sources make up the domi -\nnant proportion links shared. On both sites, NOS.nl is the most linked-to \nnews source, meaning the established source is highly relevant. For Reddit \nespecially, the lack of problematic content in Dutch spaces is remarkable, \nas in these most-posted domains almost no websites from the expert list \ncan be found, save for a few instances of dagelijksestandaard.nl and tpo.\nnl. Indeed, the platform and Dutch users show they seem to be inoculated against \u2018pulpnieuws\u2019.\nDutch-flagged posts on 4chan/pol/ show a more problematic, hyperpar -\ntisan nature. Here, 21% of top news domains are \u2018junk\u2019, with hyperpartisan \nsources making up most of these. Some of these are foreign state-influenced \nand/or hyperpartisan, such as rt.com and breitbart.com, and others are \noutright extremist, like the neo-Nazi website, The Daily Stormer. As alluded \nto above, Dutch  junk news seems to play less of a role here. A few sporadic \ninstances of far-right disinformation appeared in the Dutch posts (shown \nin orange), all originating outside of the Netherlands. These include links to \nsputniknews.com, the large Russian news website that has been known to \npropagate disinformation (MacFarquhar, 2016; EUvsDisinfo, 2017), as well \n196  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nas two far-right websites that post a large amount of Islamophobic stories, \nSpeisa.com and the Gatestone Institute. In posts linking to Russian sources, \nlike rt.com and sputniknews.com, the top URLs are usually referring to \nrefugee slander, particularly in Sweden (see Appendix 6.4). It is impossible \nto tell who posted these links considering 4chan\u2019s built-in anonymity, but \nit could potentially point to foreign interference.\nCharacteristics of Dutch junk news propagation on Reddit\nWhat are the characteristics of online actors who share Dutch junk news? \nAnd are their actions effective? While these questions are nearly impossible \nto answer for 4chan, considering its anonymity, Reddit does afford \u2018natively \ndigital\u2019 (Rogers, 2013) objects to explore the characteristics and effectiveness \nof junk news propagators. This section will therefore discuss a range of \nmetrics and lists concerning Dutch junk news on Reddit.\n298 Reddit accounts were found within the timeframe that linked to \ndomains from the expert list of Dutch junk news domains. Out of those, 193 \naccounts only posted a Dutch junk news URL once. Only sixteen accounts \ndid so ten times or more, meaning there is a long tail of occasional junk news \nposters. When these junk news sources are linked to, they furthermore receive \na lower score on average than other posts these propagators make (Figure\u00a06.17). \nTo reiterate, Reddit scores are created by users\u2019 \u2018upvoting\u2019 or \u2018downvoting\u2019 a \npost, with a high score meaning a post will move to a higher position on a \nsubreddit, thus receiving more visibility. As can be seen in Figure\u00a06.17, posts \nto non-junk news by these propagators outperform posts linking to one of the \nsites in the expert lists, with the propagators\u2019 mean score being 9.8 and the \nmean for their posts linking to a Dutch junk source being 5.6. This is mostly caused by automated, \u2018spammy\u2019 posts. The median for each of these is 1 and \noverall, 1.24 of the 1.72 of junk news posts have a score of 1 or less (72%), meaning \nthe Dutch junk news posts receive little visibility and approval on average.\nThese low average scores do not mean that junk news stories are totally \nvoid of success, however. 33 of the 1,761 posts received a score of 50 or more. \nReddit\u2019s infrastructure stimulates a snowball effect of \u2018rich get richer\u2019 posts, \nand some of these even scored higher than 1,000. Zooming in on a URL \ninstead of a domain level, it shows that most of these stories are hyperpar -\ntisan of tone. Table\u00a06.1 shows the top three highest-scoring posts on Reddit \nlinking to a domain from the expert list. All three best-performing spots are \n\u2018junky\u2019 and Islamophobic in tone. The first concerns a story by De Dagelijkse \nStandaard  on rape and refugees. The second and third are both linking to \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  197\nFigure\u00a06.17   M ean Reddit posts scores by Dutch junk news propagators (users who \nposted a link to a Dutch junk news domain at least twice) as reported \nby Pushshift API\nda ta source: 4 c aT a nd Pushshift; timeframe: 1- de c-2015 to 01-Jun-2019; bar graph\nTable\u00a06.1   T he top 3 best performing posts linking to a Dutch junk domain on Reddit\nsubject URL subreddit timestamp score\na\nmsterdam Square driver \n(terrorist) before declared \na confused and sick \ndu\ntch \nnational is now revealed to be \nkhalid\n \nk. f\nrom \nca\nsablanca. The media \ncover up doesn\u2019t stop!dagelijksestandaard.nl/2017/08/onthulling-werkelijke-naam-van-de-amserdamse-stationsrammer-blijkt-dus-khalid-karmaoui/The_\ndo\nnald 22/08/2017 13:311811\nJapan \nonl Y \nad\nmits 27 \nMuslim \u2018Refugees\u2019, Two \na\nlready \na\nrrested \nfo\nr \ngan\ng \nRape.fenixx.org/2017/05/14/japan-only-admits-27-muslim-refugees-two-already-arrested-for-gang-rape/The_\ndo\nnald 15/05/2017 06:021211\nJapan \nonl Y \nad\nmits 27 \nMuslim \u2018Refugees\u2019, Two \na\nlready \na\nrrested \nfo\nr \ngan\ng \nRape.fenixx.org/2017/05/14/japan-only-admits-27-muslim-refugees-two-already-arrested-for-gang-rape/cr inge a narchy 10/08/2017 5:13936\nda ta source: 4 c aT a nd Pushshift. Timeframe: 01- de c-2015 to 01-Jun-2019\n198  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nthe same story by Fenixx  that framed a man who drove a car into a group of \npeople at Amsterdam Central Station as a Moroccan terrorist, even though \nhe was officially declared as unwell and confused. Interestingly, these \nstories are posted in English-language subreddits, notably the pro-Trump \nr/The_Donald and the now-banned r/CringeAnarchy, showing how junk \nnews from the Netherlands spreads to  foreign spaces.\nIn summary, the overall performance of Dutch junk news throughout \nReddit is fairly weak. Moreover, the high-scoring stories are usually hy -\nperpartisan instead of clear-cut disinformation. Dutch junk news thereby \ncan garner considerable engagement on Reddit, but it does not do so on a Figure\u00a06.18   Subr eddits where Dutch junk news domains are most often posted\nda ta source: 4 c aT a nd Pushshift; timeframe: from 1- de c-2015 to 31-Jun-2019; circle pack diagram\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  199\nregular basis. In this sense, Reddit is more \u2018resistant\u2019 to junk news than (for \nexample) Facebook is said to be (Burger et al., 2019).\nIn which subreddits are Dutch junk news domains posted? Figure\u00a06.18 \nshows that r/viral links to most Dutch junk news with 543 instances, but \nmuch of the prevalence is caused by a single \u2018spam\u2019 account, receiving no \nengagement whatsoever. More interestingly, r/Forum_Democratie, the \nunofficial subreddit for the currently the largest party in the Dutch Senate, \ncomes in second with 312 posts to junk news sites. Other right-wing partisan \nand hyperpartisan subreddits appear further down the long tail, such as \nr/The_Wilders, r/FreeDutch, r/meerderheidnederland, r/The_Donald, and \nr/de_thierry. This is mainly caused by posts on these subreddits linking to \nThe Post Online  and De Dagelijkse Standaard .Figure\u00a06.19   M ost linked to Junk news domains on all of Reddit\nda ta source: 4 c aT a nd Pushshift; timeframe: from 1- de c-2015 to 1-Jun-2019; circle pack diagram\n200  S al ha gen and eMi liJa J okubau Sk aiT\u0117  Table\u00a06.2   M etrics of users who shared the Dutch junk news on Reddit\nauthor Avg. score \nwith\nDutch junk sourceAvg. score% Dutch junk postsDutch \njunk postsTop domains Top Dutchjunk domainsTop subreddits Total posts\nuser1 1 1 13.5 591 youtube.com: 416welingelichtekringen.nl: 153rt.com: 125boinnk.nl: 82earth-matters.nl: 77stopdebankiers.com: 61viral: 4390 4390\nuser2 1 1 100 294 ninefornews.nl: 294 ninefornews.nl: 294 news: 294 294\nuser3 1 1.1 0.1 70 112.international: 9891unian.info: 6238liveuamap.com: 6210dagelijksestandaard.nl: 23 fenixx.org: 9politiek.tpo.nl: 4russiawarinukraine: 6470meerderheidnederland: 788oekraineukraine: 70766860\nuser4 11. 2 28 3.9 60 i.redd.it: 431twitter.com: 352imgur.com: 106dagelijksestandaard.nl: 22tpo.nl: 19politiek.tpo.nl: 12\nfo\nrum_ de\nmocratie: 1337\nfr\needu\ntch: 83\nThe_ do\nnald: 211525\nuser5 16 18.2 12.7 62 twitter.com: 126youtu.be: 60tpo.nl: 50tpo.nl: 50opiniez.com: 10tpook.nl: 1\nfo\nrum_ de\nmocratie: 489 489\nuser6 11. 5 74.7 16.8 48 geenstijl.nl: 52twitter.com: 42tpo.nl: 28tpo.nl: 28politiek.tpo.nl: 12tpook.nl: 2\nfo\nrum_ de\nmocratie: 263\nThe_ do\nnald: 11\nf\nreedu\ntch: 9286\nuser7 8.4 9 3 29 youtube.com: 118twitter.com: 91i.redd.it: 64dagelijksestandaard.nl: 13tpo.nl: 11opiniez.com: 3\nfo\nrum_ de\nmocratie: 954\ntest_forum: 3J\nfVd: 29\n61\nuser8 25.6 23.7 7.7 19 youtube.com: 32imgur.com: 14twitter.com: 14verenoflood.nu: 6politiek.tpo.nl: 5opiniez.com: 4The_Wilders: 113The_\ne\nurope: 60\nThe_ do\nnald: 46246\nuser9 1.5 1.5 0.1 19 youtube.com: 5859gellerreport.com: 1698bitchute.com: 1677fenixx.org: 19 news: 5813worldnews: 5537worldpolitics: 423222477\nda ta source: 4 c aT a nd Pushshift. Timeframe: 01- de c-2015 to 01-Jun-2019\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  201\nAccording to Figure\u00a06.19, the junk domains that are linked to often are \nmostly the well-known right-wing tendentious and hyperpartisan blogs, \nwith The Post Online and De Dagelijkse Standaard  ranking on top. The \n\u2018alternative\u2019 news website NineForNews, which has been host to conspiracies \nand hyperpartisanship (Roermund, 2017), is also amongst the most shared \ndomains, but this is mostly due to an automated bot posting links to the \nwebsite (u/ninefornews). As such, most of the shared junk news domains \ncan be categorized as hyperpartisan, often with an \u2018alternative\u2019, right-wing \nstance. Signs of disinformation or coordinated Russian influence are fairly \nmarginal, with Novini appearing 22 times, a website known for pro-Putin \nsentiment (Heck, 2017). As such, from this needle to haystack method , partisan \nand hyperpartisan content is easy to find, but disinformation appears to \nbe less of an issue.\nFinally, we highlight the Reddit accounts most active in propagating junk \nnews to profile actor types. Table\u00a06.2 shows various metrics on the ten ac -\ncounts ranked by the amount of posts linking to one of the domains in the \nexpert list. As indicated by total posts and average score, some of the accounts \npost frequently but receive no engagement. Most of these are \u2018spam\u2019 accounts \nor automated bots. Interestingly, user 1, the aforementioned u/mrthirdeye68 , \nhas posted many URLs to Russian and pro-Russian websites as RT.com and \nnovini.nl, as well as mainstream sources and hyperpartisan websites like \nRed Ice TV. It is possible that user 1 is a Russian \u2018troll\u2019. It received no upvotes, \nhowever, and only posted links to the obscure subreddit r/viral, meaning it did \nnot garner any engagement. As such, it is likely this user is an automated bot, \nor some hybrid. Other bots seem more effective, however. User 2, for instance, \nis the abovementioned ninefornews.nl bot, posting a hundred percent of \nposts to this website in the global news subreddit r/news. Of interest here \nis that user 2 does receive engagement, with a fairly high average post score \nof 570 and a junk news post score of 50. As such, Reddit is at least somewhat susceptible to manipulation, depending on the \u2018strategy\u2019 of its users.\nIn terms of issues, it can be discerned that the most active accounts \nare either concerned with Dutch right-wing parties or topics surrounding \nUkraine. Despite their frequent linking to junk news websites, the most \nactive accounts still link most often to platforms like YouTube and Twitter.12 \nA cohort of four right-wing partisans can be observed, who are most active on \nr/Forum_Democratie and frequently link to websites like GeenStijl  and The \nPost Online . Most of the accounts actually use the Dutch language, and, upon \n12 F urther research might scrutinise what YouTube videos or Tweets are linked to, for instance \nto identify further \u2018newsy\u2019 sources or influencers.\n202  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \ncloser inspection, are also likely Dutch natives. As such we may conclude that \nthere is not a significant attempt of foreign accounts meddling with Dutch \naffairs, with the possible exception of the now-banned u/mrthirdeye68.\nYouTube as an alternative news network\nThus far, this text has handled \u2018news\u2019 in the conventional sense of designated \noutlets publishing on current affairs. As discussed in the introduction, \nhowever, the consumption of both amateur and professional reporting \nincreasingly occurs on social media. These modern, alternative ways of \nnews consumption cannot be identified when the \u2018needle\u2019 is formulated as \ntraditional news outlets. As we have identified in section\u00a03, URLs linking \nto YouTube are frequent, especially on 4chan. As discussed elsewhere in \nthis volume, the video hosting site is host to various spheres of alternative \nnews commentary and opinions, leading Zeynep Tufekci to describe it as \n\u2018the Great Radicalizer\u2019 (2018). Can we indeed outline an \u2018alternative news \nnetwork\u2019 working in tandem with 4chan/pol/ and Reddit? This section briefly \ntouches on this question by visualizing and categorizing the most-posted \nvideos on 4chan/pol/ and Reddit, as well as the most popular channels.\nFigures 6.20 and 6.22 display the thumbnails of the 1008 most-posted \nYouTube videos within our Dutch Reddit and 4chan/pol/ corpora. Figures \n6.21 and 6.23 show the \u2018video categories\u2019 for each of these videos. For the \ntop videos on Dutch subreddits, 161 are concerned with \u2018People and Blogs\u2019, \n129 with \u2018Entertainment\u2019, and 118 with \u2018News & Politics\u2019. From this, the \ntype of content shared is fairly diverse. 4chan/pol/ is more concentrated \non news and politics, with 196 videos categorized as such, with \u2018People & \nBlogs\u2019 following at 95 and \u2018Entertainment\u2019 at 64.\nThe number of missing videos for 4chan (the black labels) is notable, com -\nprising almost half of the total, indicating 4chan\u2019s extremism as well as YouTube \ncontent moderation. The number of deleted videos is visibly less on Reddit.\nIf one takes the videos labelled as \u2018News & Politics\u2019 as an indicator of a \n\u2018news source\u2019, as we categorized in the sections above, it becomes possible to quantify the role of YouTube as a news source on the two platforms. The \n\u2018News & Politics\u2019 category comprises 11.7% of the still-online videos for Reddit \nin the sample above, and 19.4% for that of 4chan/pol/. Considering the total \namount of links to still-online YouTube videos in this timeframe \u2013 7,667 for \nReddit and 26,635 for 4chan/pol/ \u2013 one can estimate that around 896 \u2018News \n& Politics\u2019 videos were posted on Dutch subreddits and 3,748 on 4chan/pol/ \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  203\nby users with a Dutch flag.13 Comparing these numbers to those presented in \nsection\u00a03, for YouTube news videos would constitute the largest and second \nlargest source of news content. On Reddit, they would form the second-largest \nnews source, only behind NOS.nl with 1,615 mentions. For 4chan, YouTube is \nby far the largest player in relation to news circulation, since the next most \npopular source, NOS.nl (861 mentions), comprises only one-third of the \namount YouTube news videos. As such, the role of YouTube as a new player \nin the circulation and consumption of news should not be understated.\nIs this dominant presence of YouTube of great significance in the study of junk \nnews? Table\u00a06.3 shows the 25 most-occurring channels from all of the YouTube \nlinks in our two Dutch corpora. Here, the platforms differ significantly. On \nReddit, some partisan channels can be discerned, like the one for Forum voor \nDemocratie and PVV pers, but the list mostly consists of \u2018established\u2019 sources \nlike NOS, GeenStijl , and VPRO Zondag met Lubach. On 4chan/pol/, however, \nthey are far more extreme and potentially harmful. The most-posted channel \nis SouthFront, dedicated to videos on the Syrian civil war. Below that is Stefan \nMolyneux, a popular Canadian YouTuber who promotes \u2018scientific racism\u2019 \nand white supremacist views. Further down the list are (hyper)partisan news \nchannels like Fox News  as well as the Russian RT and Ruptly. Other far-right \nYouTubers and channels also appear, like Paul Joseph Watson and Rebel Media, \nas well as some left-leaning channels like The Young Turks and VICE. Together, \nthe channels referred to by Dutch posters are thus of a hyperpartisan, sometimes \nwith a far-right makeup. As such, YouTube videos on Dutch subreddits seem to \nalign with consumption of \u2018established\u2019 and \u2018traditional\u2019 news media outlets, \nwhile those on 4chan/pol/ show a highly hyperpartisan and polarized landscape.\nConclusions\nDespite the frequent characterization of Reddit and 4chan as \u2018alternative\u2019 \nzones on the Web, the results presented in this text generally do not reveal a \nlarge share of alternative news networks spreading disinformation within  the \nplatforms, at least in a Dutch context. Despite a few instances of pro-Russian \nwebsites like Novini and one suspicious Reddit account, coordinated campaigns \nof malicious users posting links to disinformation seem largely absent. Dubious \ncontent can certainly be discerned but compared to overall activity (as shown \nin section two) it should be considered fairly marginal within the spaces we \n13 I n reality, these numbers will be somewhat lower because not every YouTube URL points \nto videos (they can also refer to channels), although the vast majority in our corpus does.\n204  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nFigure\u00a06.20   T he top 1008 most posted Y ouTube videos in Dutch subreddits. Black \nlabels denote deleted videos/channels. Ranked left to right, top to \nbottom\nda ta source: 4 c aT , Pushshift, and YouTube aPi; i mage wall\nFigure\u00a06.21   T he top 1008 most posted Y ouTube videos in Dutch subreddits, with \nvideo categories as an overlay. Black labels denote deleted videos/\nchannels. Ranked left to right, top to bottom\nda ta source: 4 c aT , Pushshift, and YouTube aPi; i mage wall\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  205\nFigure\u00a06.22   T he top 1008 most posted Y ouTube videos in 4chan/pol/in posts with \na Dutch country flag. Black labels denote deleted videos/channels. \nRanked left to right, top to bottom\nda ta source: 4 c aT a nd YouTube aPi; i mage wall\nFigure\u00a06.23   T he top 1008 most posted Y ouTube videos in 4chan/pol/in posts with \na  Dutch country flag, with video categories as an overlay. Ranked left \nto right, top to bottom. Black labels denote deleted videos/channels\nda ta source: 4 c aT a nd YouTube aPi; i mage wall\n206  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nTable\u00a06.3   T he most occurring Y ouTube channels from all Y ouTube links posted in \nthe Dutch Reddit and 4chan/pol/ samples. Data source: 4CAT, Pushshift, \nand Y ouTube API. Timeframe: 01-Dec-2015 to 01-Jun-2019\n4chan/pol/ \u2013 top 25 most-occurring \nchannelsReddit \u2013 top 25 most-occurring  \nchannels\nchannel count channel count channel count channel count\nSouth Front 191 FOX 10 \nPhoenix49 AFC Ajax 476 AT5 38\nStefan Molyneux177\nsanderson161 1 46 VitesseTV 269 FvD Meems 37\nFox News 156 PewDiePie 41 Forum Democratie143 De Speld 36\nRT 155 Paul Joseph Watson39 Omroep PowNed107 Football\n\u00ad\nO\nranje32\nThe White House136 Acts17Apolo \u00ad\ngetics38 Politie #PRO24795 LISSAUER 31\nRuptly 125 Rebel Media 37 BRAXATORES 82 vpro.nl 30\nRight Side Broadcasting Network112 VICE 37 VPRO Zondag met Lubach69 De Telegraaf 30\nOmroep PowNed108 Fullwhiskey 36 GeenStijl 67 NOS op 3 30\nU.S. Department of State76 VICE News 34 Cafe Weltschmerz51 Hoop Stront 29\nCNN 68 ABC News 34 NOS 51 PVVpers 28\nForum Democratie67 DeroVolk 33 WNL 48 RTL Z 27\nFox Business 65 corbettreport 31 Xbox 47 Politie Den Haag24\nThe Young Turks56 TopNotch 43\nscrutinized. Reddit seems especially resilient against the circulation of junk \nnews. In turn, the characterization as actors within 4chan and parts of Reddit as \ninfluential \u2018agenda setters\u2019 should therefore likely be taken with a grain of salt.\nWhat can be observed, however, are the types of junk news that can be \ncharacterized as hyperpartisan, especially on 4chan/pol/. This appeared \nmostly through links to popular tendentious and hyperpartisan blogs like \nThe Post Online and De Dagelijkse Standaard , but also the more clearly \u2018fake\u2019 \n(in the sense of conspiratorial) NineForNews. This right-wing bias is expected \nfor 4chan/pol/ due to its infamy as a far-right hub; for Reddit it is more \nnotable because we took a politically diverse range of URLs and subreddits \nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  207\nas a starting point. While labelling these websites as \u2018fake\u2019 is problematic, \nthey do indicate a non-negligible presence of polarizing content. Indeed, \nsection four showed that the most engaged-with articles from these websites \noften concern topics like migration and Islam, instead of other geopolitical \nevents like Russian interference.\nNonetheless, mainstream sources such as NOS.nl remain popular linked-to \ndomains on both Reddit and 4chan/pol/. This is somewhat counterintuitive \nsince it has been argued the \u2018fringe\u2019 characterization of these pseudonymous \nand anonymous spaces implies their users find knowledge in different \nepistemological drawers. Despite these assumptions, the prevalence of \nmainstream sources shows they have at least some authority within these \nonline spaces. It is important to note, however, that we have not considered \nhow  these mainstream websites are discussed. Likely, domains like NOS.\nnl are considered on Reddit as a trustworthy source, while on 4chan/pol/ \nit might be referenced purely to ridicule it or to portray it as \u2018fake news\u2019 \nitself \u2013 as is discussed elsewhere in this volume.\nOne should furthermore not be blinded by exclusively considering \nwebsites devoted to reporting on current affairs as the sole source of news, \nas YouTube emerged as a particularly big \u2018new\u2019 player in relation to news \nconsumption and circulation, especially on 4chan/pol/. On Reddit, \u2018News & \nPolitics\u2019 videos on YouTube are estimated to form the second-largest source, \nwhile on 4chan/pol/, they are estimated to strongly outperform any other \nnews source. From a brief exploration of the YouTube channels posted on \nboth platforms, it seems Dutch Reddit is largely linking to fairly established \nsources, like PowNed, Zondag met Lubach, and NOS, while on 4chan/pol/, \nalternative, hyperpartisan, and problematic information channels emerged, \nlike Mike Cernovich and RT. As such, non-Dutch YouTube content might \nhave a \u2018radicalizing\u2019 role on Dutch users within certain Internet forums.\nSince this report concerns the news sources linked to  by actors on Reddit and \n4chan, it does not shed light on the grassroots production of  alternative news or \nconspiracies within these spaces. As Tuters et al. (2018) show in relation to the \nPizzagate conspiracy, the wildest theories can be cooked-up in these spaces \nthrough a short burst of a \u2018butterfly effect\u2019 of \u2018bullshit\u2019, unobservable when \nmerely considering the prominence of URLs. A more holistic approach, also \ntaking into account text and images, could thus aid in further contextualizing \nthe current \u2018fake news\u2019 debate. Instead of identifying isolated issues of \u2018fake \nnews\u2019, such broader approaches could tackle the interwoven problematics \nsurrounding the circulation of \u2018junk news\u2019 (Venturini, 2019) and \u2018network \npropaganda\u2019 (Benkler et al., 2018), from the conspiracist mindset of \u2018virality-oriented subcultures\u2019 to the prevalence of polarizing hyperpartisan content.\n208  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nReferences\nAlexander, Julia (2017) \u2018Reddit\u2019s New Policy Won\u2019t Affect Some of Its Most Notori -\nous, Hate-Filled Subreddits\u2019, Polygon (blog). 2\u00a0November. https://www.polygon.\ncom/2017/11/2/16591508/reddit-content-policy-update-subreddit-ban-the-donald-kia.\nBaumgartner, Jason (2018) \u2018Pushshift API (version 1.0)\u2019, API Documentation, \nPushshift . https://pushshift.io/api-parameters/.\nBenkler, Yochai, Robert Faris and Hal Roberts (2018) Network Propaganda: Manipula -\ntion, Disinformation, and Radicalization in American Politics , Oxford: Oxford \nUniversity Press.\nBos, Menno van den (2018) \u2018Nee, J\u00edj Bent Een Cultuurrelativist! Hoe Academische \nBegrippen Strijdwapens Werden\u2019, Vrij Nederland , 12\u00a0December. https://www.\nvn.nl/identiteitspolitiek-cultuurmarxisme-intersectionaliteit/.\nBurger, Peter (2016) \u2018Moslims vernielen kerstmarkt in Litouwen? Nee: rellen in de VS\u2019, De \nGestolen Grootmoeder blog  (blog), 14\u00a0December. http://www.gestolengrootmoed -\ner.nl/wordpress/moslims-vernielen-kerstmarkt-in-litouwen-nee-rellen-in-de-vs/.\nCollins, Ben and John Russell (2018) \u2018Russians Used Reddit and Tumblr to Troll \nthe 2016 Election\u2019, The Daily Beast , 2\u00a0March. https://www.thedailybeast.com/\nrussians-used-reddit-and-tumblr-to-troll-the-2016-election.\nDe Hoax-Wijzer (n.d.) \u2018Valse Nieuwssites\u2019. https://sites.google.com/site/dehoaxwijzer/\nvalse-nieuwssites.\nDupuy, Lisa (2018) \u2018GeenStijl Staat Niet Meer Op EU-Lijst Nepnieuws\u2019, NRC Han -\ndelsblad , 29\u00a0January. https://www.nrc.nl/nieuws/2018/01/29/geenstijl-staat-niet-\nmeer-op-eu-lijst-nepnieuws-a1590216.\nEU vs Disinfo. 2017. \u2018Sputnik\u2019s Short-Lived Presence in the Slovak Press Agency\u2019, EU \nvs Disinfo  (blog), 1\u00a0April. https://euvsdisinfo.eu/sputniks-short-lived-presence-\nin-the-slovak-press-agency/.\nHagen, Sal, Dani\u00ebl de Zeeuw, Stijn Peeters, Emilija Jokubauskait\u0117 and \u00c1ngeles \nBriones (2019). \u2018Understanding Normiefication: A Cross-Platform Analysis of \nthe QAnon Conspiracy Theory\u2019, Digital Methods Initiative , 21\u00a0February.https://\nwiki.digitalmethods.net/Dmi/WinterSchool2019Normiefication.\nHankes, Keegan and Alex Amend (2018) \u2018The Alt-Right Is Killing People\u2019, South -\nern Poverty Law Center , 5\u00a0February. https://www.splcenter.org/20180205/\nalt-right-killing-people.\nHeck, Wilmer (2017) \u2018Rusland Be\u00efnvloedt Ons Vooral Online\u2019, NRC Handelsblad , \n8\u00a0January.\nHelmond, Anne (2015) \u2018The Platformization of the Web: Making Web Data Platform \nReady\u2019, Social Media + Society 1(2):1-11. https://doi.org/10.1177/2056305115603080.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August. https://\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  209\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August. https://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHuet, Bob van (2018) \u2018QAnon Rukt Op in Amerika: Complotgekkies of Wakkere \nPatriotten?\u2019 Algemeen Dagblad , 3\u00a0August. https://www.ad.nl/buitenland/\nqanon-rukt-op-in-amerika-complotgekkies-of-wakkere-patriotten~aa24a2ab/.\nKranenberg, Annieke and Hassan Bahara (2018) \u2018Hoe alt-right online Jodenhaat \nverspreidt\u2019, de Volkskrant , 9\u00a0November. https://www.volkskrant.nl/gs-b1714693.\nLagorio-Chafkin, Christine (2018) \u2018Reddit Confirms New Russian Meddling Efforts\u2019, \nInc., 4\u00a0October.https://www.inc.com/christine-lagorio/reddit-finds-new-russian-\ninterference-campaign.html.\nMacFarquhar, Neil (2018) \u2018A Powerful Russian Weapon: The Spread of False Stories\u2019, \nThe New York Times , 20\u00a0January. https:/ /www.nytimes.com/2016/08/29/world/\neurope/russia-sweden-disinformation.html.\nMarwick, Alice and Rebecca Lewis (2017) \u2018Media Manipulation and Disinformation \nOnline\u2019, Data & Society , New York.\nMauri, Michele, Tommaso Elli, Giorgio Caviglia, Giorgio Uboldi and Matteo Azzi \n(2017) \u2018RAWGraphs: A Visualisation Platform to Create Open Outputs\u2019, in Proceed -\nings of the 12th Biannual Conference on Italian SIGCHI Chapter , 28:1-28:5. CHItaly \n\u201917, New York, NY: ACM.https://doi.org/10.1145/3125571.3125585.\nMuirhead, Russell and Nancy L. Rosenblum (2019) A Lot of People Are Saying: The \nNew Conspiracism and the Assault on Democracy , Princeton, NJ: Princeton \nUniversity Press.\nOudenampsen, Merijn (2013) \u2018Met de Tjoeki Tjoeki Naar Takki Takki\u2019. De Groene \nAmsterdammer , 3\u00a0July. https://www.groene.nl/artikel/met-de-tjoeki-tjoeki-\nnaar-takki-takki.\nPeek, Simone (2018) \u2018NOS-Hoofdredacteur Over Bericht Soros: \u201cZo Had Het Niet \nGemoeten\u201d\u2019, NRC Handelsblad , 24\u00a0October.\nPhillips, Whitney (2018) \u2018The Oxygen of Amplification: Better Practices for Reporting \non Extremists, Antagonists and Manipulators Online\u2019, Data & Society , New York.\nRoermund, Jannes van (2017) \u2018Wie Zijn de Mensen Achter Het Nepnieuws in \nNederland?\u2019 Nieuwe Revu , 26\u00a0April.\nRoig-Franzia, Manuel (2019) \u2018Inside the Spectacular Fall of the Granddaddy of Right-\nWing Conspiracy Sites\u2019, The Washington  Post , 2\u00a0April. https://www.washingtonpost.\ncom/lifestyle/style/inside-the-spectacular-fall-of-the-granddaddy-of-right-wing-\nconspiracy-sites/2019/04/02/6ac53122-3ba6-11e9-a06c-3ec8ed509d15_story.html.\nRogers, Richard (2013) Digital Methods , Cambridge, MA: MIT Press\n210  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nRTL Nieuws (2018) \u2018Alles Over Complottheorie QAnon \u2013 #TrumpUpdate 77\u2019, RTL \nNieuws , 15\u00a0September. https://www.rtlnieuws.nl/nieuws/laatste-videos-nieuws/\nvideo/4417801/alles-over-complottheorie-qanon-trumpupdate-77.\nShieber, Jason (2017) \u2018How Reports from 4chan on the Las Vegas Shooting \nShowed Up on Google Top Stories\u2019, TechCrunch (blog), 2\u00a0October. http://\nsocial.techcrunch.com/2017/10/02/how-reports-from-4chan-on-the-las \n-vegas-shooting-showed-up-on-google-top-stories.\nSouthern Poverty Law Center (n.d.), \u2018WorldNetDaily\u2019, Southern Poverty Law \nCenter  (blog). https://www.splcenter.org/fighting-hate/extremist-files/group/\nworldnetdaily.\nThomas, David R. (n.d.) \u2018A General Inductive Approach for Analyzing Qualitative \nEvaluation Data\u2019, American Journal of Evaluation 27 (2): 238-46. https://doi.\norg/10.1177/1098214005283748.\nTufekci, Zeynep (2018) \u2018YouTube, the Great Radicalizer\u2019, The New York Times , \n10\u00a0March. https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-\npolitics-radical.html.\nTuters, Marc, and Dani\u00ebl De Zeeuw (2019) \u2018Teh Internet Is Serious Business: On the \nDeep Vernacular Web Imaginary\u2019, ANSOC Working Paper .\nTuters, Marc, Emilija Jokubauskait\u0117 and Daniel Bach (2018) \u2018Post-Truth Protest: \nHow 4chan Cooked Up the Pizzagate Bullshit\u2019, M/C Journal  21(3). http://journal.\nmedia-culture.org.au/index.php/mcjournal/article/view/1422.\nVenturini, Tommaso (2019) \u2018From Fake to Junk News, the Data Politics of Online \nVirality\u2019, in Didier Bigo, Engin Isin, and Evelyn Ruppert (eds), Data Politics: \nWorlds, Subjects, Rights . London: Routledge. https://hal.archives-ouvertes.fr/\nhal-02003893.\nWendling, Mike (2018). Alt-Right: From 4chan to the White House . London: Pluto Press.\nZannettou, Savvas, Tristan Caulfield, Emiliano De Cristofaro, Nicolas Kourtelris, \nIlias Leontiadis, Michael Sirivianos, Gianluca Stringhini and Jeremy Blackburn \n(2017) \u2018The Web Centipede: Understanding How Web Communities Influence \nEach Other through the Lens of Mainstream and Alternative News Sources\u2019, \n17th ACM Internet Measurement Conference , 405-17.\nAbout the authors\nSal Hagen  is a Ph.D. candidate at the University of Amsterdam and co-\nfounder of OILab. His research focuses on anonymous and pseudonymous \nonline subcultures and their political engagements. Methodologically, his \nwork combines media theory with data-driven methods.\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  211\nEmilija Jokubauskait\u0117 is a Ph.D. candidate and lecturer in Media Studies at \nthe University of Amsterdam as well as co-founder of the Open Intelligence \nLab. Her main research interests consist of fringe online spaces and platforms \nas well as the scrutiny of research tools and techniques.\nAppendices\nAppendix 6.1  C ompiled list of Dutch Subreddits\nTable\u00a06.4   C ompiled list of Dutch subreddits\nadod e n haa g,aja xa msterdam, a lkmaar, a luhoedjes, a mersfoort, a msterdam, a msterdam e\nnts,ap piememes, ar nhem, ar uba, as sen,avd, aZal kmaar, ba ssie_en_ ad riaan, be ermoney nl\n,benelu x, b ier,b innenhof, b itcoin nl,bo eken, bo naire, b uurman en b uurman, ca riceVan ho ute\nn,ce lebs nl,ci rkeltrek, cr eatieve ko ppen, cu racao,de_thierry,de_thierry, deco rrespondent,\ndegr aafschap, d elain, d elft, d epressie, d eSpeld ofni etd eSpeld, d eStaat, d eStagiair, d eTand\nenborstel, di rkJan, dor drecht, douc hege dachten, dou tzen kr oes, dr enthe, du indorp, du mo\nulin, du nglish,dutch, du tch,du tchbo ardgames, du tchco medy, du tchde sign, du tchen ts,du\ntchfiRe,du tch hi pho p,du tch ho use, du tch ke to,du tchMusic, du tchPoetry, du tchProblems,\ndu tchSkincare, du tchTech, ei ndhoven, elf stedentocht, en schede, epi ca,er edivisie, et htrader\nnl,f cg r oningen, f cT wente, f cut recht, fe yenoord, for mule1, for um_ de mocratie, fr eedu tch\n,fri sia, fr ysk, ge kkeJongens, ge ldzaken, ge schiedenis, ge zellig, gl itterplaatjes,groenlinks, gr\noningen, ha arlem, ha nzeMemes, hei lzameMeems, hu lpdiensten,ik_ihe,Juridisch ad vies, ka\nmerstukken, ka tholieke ne derlanden, ki bbeling, k nVb,ko ffie,ku t_do en_op _Tinder, ku tleve\nn,ku treclames, le arndu tch,lecu tin sideMan, le iden, ler aren, li mburgMan, lo wlands,Maast\nricht,Mama ap pelsap,Marktplaats,MaxV,Medejongeren,meerderheidnederland,Metal_ nl\n,Motorfietsen, n acb r eda, n ec,ne dercringe, ne derporn, nep Parlement,netherlands, ne th\nerlandsPics, nie tde Speld, ni jmegen, n lv sf i,nu enen, nu Jijinac tie,oekraineukraine,ossem\n,otonde,Papgrappen,ParadoxPlaats,P e cZ wolle,Podcast ne d,Pokemon gonl, Poldersocia\nlisme,Politiek,Politiekmemes,PSV,Rijmen di chten,RMT k, RodaJ c, RomeeStrijd,Rotterdam\n,Saba,S c c a mbuur,S c he erenveen,Scouts nl, Sport nl, Spyker,StefanieJoosten,Strips,Stro\nopwafels,Study in The ne therlands,SXM,SylvieMeis,Tenenkrommend,The_ kl aver,The_Wi\nlders,The ha gue,the ne therlands,the ne therlands fr ee,the ne therlands na ture,Tiesto,tokk\niefeesboek,tokkiefeesboek,Tokkie fe esboek,Top2000,T u de lft,Tuurlijk isda teendi ng,Twe\nnte, ut recht,Vegan nl, Veluwe,Vitesse ar nhem,Voetbalnieuws,Vraag derne derlanden,Vra\naghe t a anTonyQuark,Wetenschap,W i dM ,WithinTemptation,Xbox ne derland,Zitkamer,Z\nonder con text,Zwolle\n212  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nAppendix 6.2  E xpert List of Dutch Junk News Domains\nTable\u00a06.5   Junk ne ws categorization. Edited and enhanced list originating from \nHoax-Wijzer. 23 March, 2019\nname domain_name category\nop\niniez opiniez.com hyperpartisan\nStop de \nba\nnkiers stopdebankiers.com hyperpartisan\nt Pallieterke pallieterke.net hyperpartisan\ne.\nJ. \nbr\non ejbron.wordpress.com hyperpartisan\nda\ngelijkse Standaard dagelijksestandaard.nl hyperpartisan\nc\nlimategate climategate.nl hyperpartisan\nde S\ntaat van het klimaat destaatvanhet-klimaat.nl hyperpartisan\nJdre\nport.com jdreport.com hyperpartisan\ntpook.nl tpook.nl clickbait\nni\nne for news ninefornews.nl conspiracy\nd\naily Paper dailypaper.org hyperpartisan\nParra parra.nu clickbait\nViraaltjes viraaltjes.nl clickbait\nabout media aboutmedia.nl clickbait\nMartin Vrijland martinvrijland.nl conspiracy\nThe \nl\noyalist loyalist.nl conspiracy\ndesportgek desportgek.nl clickbait\ne\nven \nde\nlen evendelen.net clickbait\nnietbarkie.nl nietbarkie.nl clickbait\nhardewaarheid.nl hardewaarheid.nl clickbait\nThe Post \non\nline tpo.nl tendentious-\nhyperpartisan\nSaltmines.nl saltmines.nl hyperpartisan\neunmask.wordpress.com eunmask.wordpress.com hyperpartisan\nnovini.nl novini.nl hyperpartisan\nniburu.nl niburu.nl conspiracy\nReact nieuws reactnieuws.net hyperpartisan\ndMlp\nlus dlmplus.nl conspiracy\nmartinvrijland.nl martinvrijland.nl conspiracy\nworld unity worldunity.me conspiracy\ncultuur onder vuur cultuurondervuur.nu hyperpartisan\nvolks nieuws uit \na\nmsterdam noir volksnieuwsuitamsterdamnoir.com conspiracy\nstop pas familie drama stoppasfamiliedrama.blogspot.com conspiracy\nob\ned \nbr\ninkman obedbrinkman.noblogs.org hyperpartisan\nveren of lood verenoflood.nu hyperpartisan\nde f\nouten van Rutte defoutenvanvvdrutte.nl hyperpartisan\nf\ninding voices finding-voices.blogspot.com conspiracy\nik was in haren ikwasinharen.nl hyperpartisan\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  213\nname domain_name category\nPiet \nkei p\nietkei.nl conspiracy\nbewiseman bewiseman.nl hyperpartisan\na\nlternatieve Media \nne\nderland alternatievemedianederland.com hyperpartisan\nap\nokalypsnu apokalypsnu.nl conspiracy\ndo\nn Quijotte donquijotte.wordpress.com conspiracy\nd\nrimble drimble.nl hyperpartisan\nf\nenixx fenixx.org hyperpartisan\nhe\nctor Reban hectorreban.wordpress.com hyperpartisan\nher\nstelde Republiek herstelderepubliek.wordpress.com hyperpartisan\nkr\nemlin Troll kremlintroll.nl hyperpartisan\nMagilando magilando.wordpress.com conspiracy\nni\nburu niburu.co conspiracy\nab\nsolute \ndual\nity nl.absoluteduality.com conspiracy\nStan van \nho\nucke stanvanhoucke.blogspot.com hyperpartisan\nStelling stelling.nl conspiracy\nTref tref.eu hyperpartisan\nWant to know wanttoknow.nl conspiracy\nXandernieuws xandernieuws.punt.nl hyperpartisan\naPo\nst apost.com clickbait\nbe\nst \nge\nzond bestgezond.nl clickbait\nbew\nust \nni\neuws bewustnieuws.nl conspiracy\nbl\nik \nop \nno\nSjournaal blikopnosjournaal.blogspot.nl hyperpartisan\nbo\nvendien bovendien.com conspiracy\nb\nrekend \nn\nieuws brekendnieuws.nl conspiracy\nda\ngelijks.nu dagelijks.nu clickbait\nda\ngelijkse \nkr\nant dagelijksekrant.nl clickbait\nde\n Stille Waarheid destillewaarheid.nl hyperpartisan\nea\nrth Matters earth-matters.nl conspiracy\nel\nla\u2019ster ellaster.nl conspiracy\nhealt\nh \nby\ntes healthbytes.me conspiracy\nhealt\nhwatch \ngezondheidswaakhondhealthwatch.nu conspiracy\nle\neshetnu leeshetnu.nl clickbait\nle\nkkerwonen lekkerwonen.org clickbait\nli\nkeMag likemag.com clickbait\nli\njstverse lijstverse.nl clickbait\nl\nive kijken livekijken.nl clickbait\nni\neuwsdump nieuws-dump.nl clickbait\nno\nt100 not100.nl clickbait\nong\nelooflijke Verhalen smullen-maar.nl clickbait\nPrankster prankster.nl clickbait\nRevolutionair \non\nline revolutionaironline.com hyperpartisan\nSnuggerd snuggerd.nl clickbait\nTime 2 Wake \nup t\nime2wakeup.me hyperpartisan\n214  S al ha gen and eMi liJa J okubau Sk aiT\u0117  \nname domain_name category\nTips & Weetjes tipsenweetjes.nl clickbait\nTis Wat tis-wat.nl clickbait\nTrend buz\nz trendbuzz.nl clickbait\nTrendnieuws trendnieuws.nl clickbait\nTrendnova trendnova.nl clickbait\nun\nited- li\nghtworkers united-lightworkers.be conspiracy\nVaccinatieraad vaccinatieraad.nl conspiracy\nViraalpunt viraalpunt.nl clickbait\nViral Mundo viralmundo.nl clickbait\nViraaltje Viraaltje.nl clickbait\nVrouwen \ndi\nngen vrouwendingen.com clickbait\nVrijspreker vrijspreker.nl hyperpartisan\nThe Post \non\nline \u2013 Politiek politiek.tpo.nl tendentious-\nhyperpartisan\ner\nkenbrand erkenbrand.eu hyperpartisan\nda\ns \nka\npital daskapital.nl hyperpartisan\nglop g\nlop.nl hyperpartisan\nAppendix 6.3  M etrics on domains shared on Reddit and 4chan/pol/\nTable\u00a06.6   M etrics for the proportions of news, Dutch news, Dutch junk news, \nand categories in posts on Dutch language subreddits, 01-Dec-2015 to \n01-Jun-2019\nReddit\n01-12-2015 to 01-06-2019 OPs Category Count Percentage\nPositive ne gative Percentage Mainstream 5255 89.9%\nnew\ns 5959 27594 21.64% Other 580 9.7%\ndu\ntch news 5557 402 93.3% Hyperpartisan 24 0.4%\ndu\ntch junk news 24 5935 0.4% Disinformation 0 0%\nClickbait 0 0%\nConspiracy 0 0%\nduTc h Ju nk ne W S  on Reddi T  and 4chan/ Po l  215\nTable\u00a06.7   M etrics for the proportions of news, Dutch news, Dutch junk news, \nand categories in posts on 4chan/pol/ with a country flag from the \nNetherlands, 01-Dec-2015 to 01-Jun-2019\nReddit\n01-12-2015 to 01-06-2019 OPs Category Count Percentage\nPositive ne gative Percentage Mainstream 10399 71.5%\nnew\ns 14541 87301 16.6% Other 1414 9.5%\ndu\ntch news 3403 11138 23.41% Hyperpartisan 2091 14.4%\ndu\ntch junk news 2809 11732 19.3% Disinformation 241 1.7%\nClickbait 45 0.3%\nConspiracy 351 2.4%\nAppendix 6.4  M ost-posted URLs from posts containing links to RT.com \nand Sputnik on 4chan/pol/\nTable\u00a06.8   M ost occurring URLs from posts containing links to RT.com and Sputnik \nby posts with a Dutch country flag on 4chan/pol/. Derived with 4CAT\nTitle URL Amount of \nappearances\nStabbing death of 15yo schoolboy by \n\u2018ar\nab migrant\u2019 classmate in Sweden \nsparks outragehttps://www.rt.com/news/329243-sweden-migrant-stabbed-teenager/ 9\nSweden: Rape \nca\npital of the West https://www.gatestoneinstitute.org/5195/sweden-rape 9\nSweden charges 5 teenage refugees with beating, gang-raping boy for over an hourhttps://www.rt.com/news/369415-sweden-refugees-rape-afgan-boy/ 9\nbe\nlgian prosecutor\u2019s office denies \nterrorist track in murder of guard at nuclear centrehttps://www.rt.com/news/337276-belgium-nuclear-guard-killed/ 8\nSex Slave \nfo\nund \nch\nained in \nba\nse-\nment of \nim\nmigrant \nca\nfe in Swedenhttp://speisa.com/modules/articles/index.php/item.3584/sex-slave-found-chained-in-basement-of-immigrant-cafe-in-sweden.html (now offline)8\n\n7 F ake news and the Dutch YouTube \npolitical debate space\nMarc Tuters1\nAbstract\nFake news is a contested concept. In the wake of the Trump insurgency, \nit has been reclaimed by \u201chyperpartisan\u201d news providers as a term of \nderision intended to expose perceived censorship and manipulation in \nthe \u201cmainstream media\u201d. As patterns of televisual news consumption have \nshifted over the past several years, YouTube has emerged as a primary \nsource for \u201calternative\u201d views on politics. Current debates have highlighted \nthe apparent role of YouTube\u2019s recommendation algorithms in nudging \nviewers towards more extreme perspectives. Against this background, \nthis chapter looks at how YouTube\u2019s algorithms frame a Dutch \u201cpolitical \ndebate space\u201d. Beginning from Dutch political parties\u2019 YouTube channels, \nwe find the existence of an \u201calternative media ecology\u201d with a distinctly \npartisan political bias, the latter which is resonant with the populist-right \ncritique of the mainstream media as the purveyors of \u201cfake news\u201d.\nKeywords:  YouTube, hyperpartisan media, right-wing populism, comment \nculture, Forum voor Democratie\nIntroduction: YouTube as radicalizing platform\nOn 1\u00a0February\u00a02019, de Volkskrant  and De Correspondent published a \nmuch-anticipated report on YouTube as a radicalization platform: \u2018Leidt \nhet algoritme van YouTube je naar extreme content?\u2019 (Translated: Does \nthe YouTube algorithm lead you to extreme content?) (Bahare et al.,\u00a02019). \n1 T he research was undertaken with Camille Godineau, Daniel Jurg, Lieve Keizer, Dana Lamb, \nAikaterini Mniestri and Ashley Snoei. (Special thanks to Daniel Jurg.)\nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch07\n218  M aRc  Tu T eR S \nDrawing on data analysis produced by some of the same authors of this cur -\nrent report, it sought to investigate the extent to which YouTube functioned \nas an engine for online \u2018radicalization\u2019 (Tufekci, 2018; Holt, 2017). As these \nand other reports claimed, YouTube appears to be playing a significant \nrole in the development of a new antagonistic culture of debate, in which \nan \u2018alternative influence network\u2019 is said to have the capacity to shape \npublic opinion, especially amongst a demographic of young and politically \nrightward leaning men (Lewis, 2018). Amongst the figures who have risen \nto prominence through this YouTube debate culture, is for example the \nnow internationally well-known, Canadian academic psychologist Jordan \nPeterson. Peterson is often viewed as a conservative political figure, even as \na member of the so-called \u2018alt-right\u2019 (Lynskey, 2018). This latter term, which \nstands for \u2018alternative right\u2019, gained popularity in the aftermath of the 2016 \nUS election as a means of describing a seemingly new breed of conservative \nonline activism that brought together a diverse array of actors united against \nthe perceived hegemony of \u2018politically correct\u2019 liberal values, often through \na jokey and transgressive style (Hawley, 2017; Heikkil a\u0308, 2 017; Nagle, 2017). \nWhilst Peterson has refuted an association with the alt-right, in consulting \nhow the YouTube algorithm itself categorizes Peterson it would appear that \nthe platform nevertheless still views him in this light. How exactly this \ncategorization works is inscrutable to all but the owners of the platform. \nAnd while it should not be taken as definitive proof of what a given channel \nis about, we can nevertheless assume that YouTube\u2019s categorization does \nreflect some essential aspect of its bottom line, which is to keep the most \npeople watching for the longest time possible.\nThe present research report uses the same platform-centric categorization \nmethod as introduced above, applying it to studying the space of Dutch \nparliamentary political debate on YouTube. While initially motivated by \nthe question of how this space engages with the issue of \u2018fake news\u2019, the \nreport however moves away from defining fake news as disinformation \n(which is to say the deliberate manipulation of facts) towards conceiving of \nit in terms of a form of \u2018hyperpartisan\u2019 information as produced by \u2018openly \nideological web operations\u2019 (Herrman, 2016). This latter conception of fake \nnews is furthermore also resonant with the redefinition of the term as it \nhas begun to be appropriated by politicians around the world in order to \ndescribe news organizations whose coverage they find \u2018disagreeable\u2019 (Wardle \nand Derakshan, 2017: 16) \u2013 notably by Donald Trump who often refers to \n\u2018establishment\u2019 media outlets such as CNN and the New York Times as fake \nnews (Weisman, 2018). In the European context, where laws such as the \nGerman Netz DG have been passed at the national level rendering platforms \nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  219\nresponsible for policing this problem, such critics have framed the attempt \nat regulating fake news as a \u2018blueprint\u2019 for state censorship (Wardle and \nDerakshan, 2017: 71). In spite of these controversies, the bewildering issue \nof fake news, entangled as it is together with broader changes in political \nand media spheres at a variety of levels, remains relatively understudied \noutside of the American context \u2013 the latter which is in many ways quite \nunique for a variety of factors (Benkler et al., 2018: 381-387).\nWhilst the precise mechanisms of YouTube\u2019s algorithms are unknown, \nwhat is clear is that they are designed to optimize \u2018engagement,\u2019 defined \nin terms of \u2018views\u2019 as well as the number of \u2018comments\u2019, \u2018likes\u2019, and so forth \n(Covington et al., 2016). In recent years, YouTube\u2019s algorithm has been \ncritiqued as creating a so-called \u2018rabbit-hole effect\u2019 (Holt, 2017), whereby \nthe platform\u2019s algorithms, as mentioned above, have been accused of recom -\nmending ever more extreme content, in an effort to keep viewers engaged. \nIt has thus been argued that this particular environment has helped to \ndraw audiences from the mainstream towards the fringe. Along these lines, \nit has indeed been argued that, on YouTube, \u2018far-right ideologies such as \nethnonationalism and anti-globalism seem to be spreading into subcultural \nspaces in which they were previously absent\u2019 (Marwick and Lewis, 2017: 45). \nAcademic researchers exploring this phenomenon have, for instance, found \nthat YouTube\u2019s \u2018recommendation algorithm\u2019 has a history of suggesting \nvideos promoting bizarre conspiracy theories to channels with little or \nno political content (Kaiser and Rauchfleisch, 2018). Beyond this current \n\u2018radicalization\u2019 thesis, for some years new media scholars have observed that \nYouTube appears to multiply extreme perspectives rather than facilitating \nan exchange or dialogue between them \u2013 as for instance observed in an \nearlier audience reception study of a polemical documentary produced by \nthe Dutch parliamentarian Geert Wilders and published to YouTube (van Zoonen et al., 2011).\nWe may perhaps want to consider the growth of a new combative and \nconspiratorial culture of debate on YouTube, as documented by these more \nrecent YouTube studies, in the context of broader global political shifts that \nhave been picking up pace in the latter part of the 2010s, the latter which \nmay be referred to under the umbrella term of \u2018national populism\u2019 (Eatwell and Goodwin, 2018). Referred to as \u2018thin ideology\u2019 (Mudde and Kaltwasser, \n2017), populism is characterized by a suspicion of the \u2018elite\u2019 as well as a purist \nnotion of the \u2018general will\u2019 of the true people, the latter which is not necessarily \nequivalent to the democratic electorate (Muller, 2016). Recent new media \nscholarship has convincingly demonstrated how such populist anti-elite \nsentiment translated readily into an embrace of alternative news media, \n220  M aRc  Tu T eR S \nparticularly in the US context in which the rise of an \u2018alternative partisan \nnews system\u2019 is said to have played a crucial role in the last presidential \nelection (Benkler et al., 2018). While there exists right and left variants of \nthe concept, right-wing populists tend to have an advantage in speaking to \nnationalist issues (Goodwin and Eatwell, 2018). In the analysis of political \nscientists Matthew Goodwin and Roger Eatwell, national populism can \nbe characterized by four factors, that they call the \u2018four D\u2019s\u2019. These are a \ndistrust  in the liberal \u2018establishment\u2019, the destruction  of long-held communal \nidentity owing to forces of globalization, the relative deprivation  as \u2018neoliberal\u2019 \neconomics leads to a rise in inequality and finally the political de-alignment  \nfrom traditional political parties. Whatever the political valence of national \npopulism going forward, Goodwin and Eatwell conclude that these four \nfactors are destined to have \u2018a powerful effect on the politics of many Western \ncountries for many years to come\u2019 (Goodwin and Eatwell, 2018).\nFakeness and hyperpartisanship\nThus far the problem of fake news has primarily been studied in the context of \nAnglo-American national populism, specifically the political communication \nsurrounding the Brexit referendum and the insurgent Trump campaign and \nsubsequent presidency. Furthermore, most current studies of fake news have \ntended to focus on the US context, where institutional trust levels in media \nand in the government are said to be at an all-time low (Edelman, 2018) and \npolitical polarization stands at an all-time high (boyd, 2017). In that context, \nit has been noted that the standard designation of \u2018fakeness\u2019, as a diagnosis to \nbe remedied by \u2018fact-checking\u2019, fails to acknowledge a much more profound \nepistemological problem. As has long been argued in the literature on the \nsociology of scientific knowledge, \u2018facts\u2019 are better understood as products \nof negotiated settlements amongst domain experts (Latour and Woolgar, \n1976). The atmosphere of general suspicion towards expertise that underpins \nthe rise of national populism thus poses a fundamental epistemological \nproblem. This same general atmosphere of suspicion furthermore works to \nundermine trust in professional media institutions as the arbiters of facts. It is argued that this particular context plays into an innate psychological tendency to seek out bias-confirming information.\n2\n2 I ndeed, from the social psychology perspective, \u2018fake news\u2019 would arguably represent a more \n\u2018natural\u2019 human preference than \u2018facts\u2019, insofar as the former more readily provides support that \nconforms to the \u2018moral foundations theory\u2019 of human values (see Haidt, 2012).\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  221\nA leading scholar in the field recently posed the dilemma thusly: in the US, \nsomewhere between \u201825 and 30\u00a0percent of Americans willingly and intentionally \npay attention to media outlets that consistently tell that audience what it \nwants to hear, and what that audience wants to hear is often untrue \u2019 (Benkler \net al., 2018: 367, emphasis added). In the aforementioned context, such scholars \nfurthermore suggest that technocratic solutions designed to regulate and censor \nthis fake news would be \u2018neither feasible nor normatively attractive as they \nwould certainly generate heated protest from a large spectrum of the populace\u2019 \n(367). Even in less politically polarized contexts the problem of regulation is \nextremely challenging. It is not isolated cases of fake news that are at issue \nbut the larger problem of what these scholars refer to as \u2018network propaganda\u2019, \nwhich constructs \u2018materially misleading\u2019 narratives from a tissue of facts (102). \nBecause it is extremely difficult to establish \u2018ground truth\u2019, reliable technological \nsolutions to the problem of fake news are thus unlikely at present (377).\nIn light of the former diagnosis, the empirical study below reframes the \nissue of \u2018fake news\u2019 in the Dutch-language YouTube space by profiling the \nemergence of a network of channels engaged in political debate and commen -\ntary. It conceptualizes elements of this network as hyperpartisan, in the sense \nthat they are \u2018openly ideological web operations\u2019 (Hermann, 2016). Whilst \nmarginal in comparison to mainstream Dutch news organizations these \nchannels nevertheless appear highly engaging, at least from the perspective \nof the YouTube algorithm. As alternative news organizations almost all of \nthese channels are unique to YouTube, making them \u2018natively digital objects\u2019 \n(Rogers, 2013: 1). The empirical research that follows is thus concerned with \nunderstanding how these channels work, what their issues are, how they \u2018do\u2019 \nDutch national politics, and how they differ from the mainstream.\nYouTube\u2019s \u2018related channels\u2019 and Dutch political space\nFollowing the \u2018digital methods\u2019 approach (Rogers, 2013), \u2018the discussion that \nproceeds here can be considered as an endeavour to \u2018repurpose\u2019 YouTube \nas a research device by thinking along those lines that the platform makes \navailable to the public. In particular the approach uses YouTube\u2019s \u2018related \nchannel\u2019 algorithm as the basis for an analytical method that takes a set of Dutch \nalternative news channels as its primary site of study. As a forewarning, it is \nimportant to recognize the contrived or \u2018artificial conditions\u2019 with which the \nmedium frames the object (Rieder et al., 2016: 3). These conditions effectively \nmake it impossible for the digital methods researcher to identify where the \nmedium ends and where in turn the social begins. Though we do have a sense \n222  M aRc  Tu T eR S \nof how some of YouTube\u2019s algorithms work from both the official corporate \nstatement (Press, 2019), as well as from attempts by scholars to \u2018reverse engineer\u2019 \nor \u2018teardown\u2019 the platform (Bessi et al., 2016), the precise functioning is unknown \nand in any case likely to change, thus frustrating the exact reproducibility \nof any of our findings. At any time, YouTube may furthermore suddenly and \nunaccountably change its algorithms, which are in any case invisible to all but \ncertain engineers at YouTube. Needless to say, the capriciousness of platforms  \nrenders the effective control of variables practically impossible. Whilst the \nlatter is axiomatic to digital methods it should also be recognized as an inherent \nlimitation of the methods as well. For these reasons the present report is thus \nbest approached as \u2018snapshots\u2019 of a milieu that is constantly in flux.\nThe empirical research focuses primarily on repurposing YouTube\u2019s \n\u2018related channels\u2019 for the purpose of analysis of the Dutch political space. \nIn order to delineate what we are here calling the Dutch \u2018political debate \nspace\u2019 in YouTube, we started from the channels corresponding to the Dutch \npolitical parties. Since all 13 Dutch national political parties currently in \n3 No te that the Dutch labour party visualized on the far right of the graph did not return any \nrelated channels.Figure\u00a07.1\n  Rela\nted channels on Y ouTube. Table where the top row displays the \nname of each Dutch political party and the columns below each \nof these are the media organizations associated with each party\u2019s Y ouTube channel. 29\u00a0March\u00a02019\nSource: YouTube3\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  223\nthe parliament have a YouTube presence, we used these channels as a \u2018seed \nlist\u2019, or set of starting points, for the subsequent research. Starting then \nfrom this seed list the first technique compares all of the channels that \nYouTube classified as related to those of the Dutch political parties. This \nparticular approach to categorization in all likelihood involved no human \noversight; rather, it should be understood as an artefact of how the algorithm \n\u2018values\u2019 the object, in relation to the aforementioned \u2018engagement\u2019 metrics. \nFollowing the digital methods approach, the analytical gambit here is that \nthe channels that YouTube suggests may be treated as a measure of how \nthe platform views those parties.4\nThe most unusual finding is that the algorithm relates one particular \nchannel to almost all parties across the political spectrum: Forum voor \nDemocratie (FvD). As a new \u2018Eurosceptic\u2019 party with a younger demographic \nthan the established nationalist populist Partij Voor de Vrijheid (PVV), FvD \nand its agenda seem to dominate discussion in political debate in a network \nof \u2018alternative\u2019 channels discussed below, several of which YouTube relates \nto the parties, most notably \u2018TheLvkrijger\u2019. Before going on to discuss these \nalternative news channels in detail, the next most striking finding here is how \nthe algorithm seems to organize the political spectrum in relation to different \n\u2018establishment\u2019 news organizations. One cluster of parties is associated with \nCNN, ABC, NOS5 and another around De Telegraaf , media organizations that \nmay be considered as relative liberal and conservative/populist, respectively. \nWhile it is not necessarily easy to arrange the Dutch political parties on a \nleft-right axis \u2013 as many smaller parties are more issue-based \u2013 it is worthy to \nnote how the algorithm groups the Groen Links and Denk parties with centre-\nright and right-of-centre parties. In addition to De Telegraaf , the algorithm \nalso relates all of the parties in this latter cluster to alternative Dutch news \norganization: Omroep PowNed, a public radio and TV broadcast renowned for its satirical news show, PowNews, which often ridicules politicians with provocative questions. In what follows we will categorize Omroep PowNed, \nalong with GeenStijl,  a blog popular for its similarly abrasive style, as members \nof the established anti-establishment  alternative news organizations.\nThat the algorithm also relates the parties to a smattering of large Dutch \ncommercial and public media channels (WNL, RTL Nieuws, NPO Radio 1, \n4 O ne should note here that social media use machine learning for predictive consumption in \nwhich \u2018success\u2019 is a measure of how correctly the algorithm predicts what a user will engage with. \nA well-known critique here is the notion of the \u2018filter bubble\u2019 (Pariser, 2011), which argues that \nalgorithmic categorization can have the effect of narrowing the range of alternate viewpoints that one is exposed to.5\n N\note that we removed most US channels from Dutch media network visualization below.\n224  M aRc  Tu T eR S \nVeronica Inside), is unsurprising as these would be an expected part of an \naverage Dutch media diet. What is likely surprising to those unfamiliar with the \nDutch political space in YouTube is the network of alternative or \u2018alt\u2019 channels \nthat YouTube relates to the parties, notably the aforementioned \u2018TheLvkrijger\u2019, \nbut also \u2018Arnews\u2019, \u2018Leukste YouTube fragmenten\u2019, \u2018Lissauer\u2019 and \u2018Rafiek de \nBruin.\u2019 With the possible exception of \u2018Arnews\u2019, all of these channels could be \ncategorized as \u2018openly ideological web operations\u2019. As we will see, these Dutch \npolitical debate channels are \u2018natively digital objects [\u2026] \u201cborn\u201d in the new \nmedium\u2019 (Rogers, 2013: 19), as opposed, for example to Omroep PowNed. While \nsome of these channels, like TheLvkrijger, are transparently partisan, national \npopulist sentiments seem common in this space, as for example captured in a \npost by TheLvkrijger encouraging viewers to vote in the upcoming elections, \nwhich featured the slogan \u2018He who is silent agrees! This is your country! Claim it\u2019.\nThe Dutch YouTube media sphere\nIn an effort to create a panoramic graph of the larger Dutch YouTube media \nsphere that would also remain connected to the Dutch political sphere on \nthe platform we used YouTube\u2019s related channels algorithm to \u2018snowball\u2019 out \nfrom the seed list of the 13 parties to 3 degrees of relations. We subsequently \nvisualized the related channel network with network analysis software, Figure\u00a07.2   T heLvkrijger post: Translated into English: \u2018He who is silent agrees! \nDon\u2019t shut up anymore! This is your country! Claim it!\u2019\n\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  225\nFigure\u00a07.3   Rela ted channels on Y ouTube. Panoramic graph of larger Dutch \nY ouTube media sphere. This graph was produced two months apart on \n29\u00a0March\u00a02019 and again on 22\u00a0May\u00a02019 with identical outcomes.\nVisualization by fe derica ba rdelli using ge phi ( ba sian et al., 2009)\n226  M aRc  Tu T eR S \nwhere nodes represent channels and edges represent relations according \nto YouTube\u2019s algorithm. The size of the text represents a measure of their \nrelative importance within the network. Finally, relative similarity between \nchannels determines their colouration, clusters which we have then labelled \nas government , military , commercial , vlog , public , sport  and, finally, our \nspecific alternative media ecology. The largest nodes in the graph are all \n\u2018establishment\u2019 media organizations with NOS Jeugdjournaal, RTL Nieuws \nand De Telegraaf  at the centre. Slightly outside of the centre another large \nnode is the established, anti-establishment channel Omroep PowNed, known \nonce again for its \u2018edgy\u2019 confrontational style of reportage. If one continues \nalong this same line one encounters the cluster labelled alternative media \necology at the centre of which the most connected node is FvD but which \nalso includes a few government channels (for example Eerste Kamer) as well \nas a number of the aforementioned \u2018alt\u2019 political debate channels which we \nencountered earlier (for example \u2018Leukste YouTube Fragmenten\u2019). In the \nnext steps of the analysis we will delve more deeply into these \u2018alt\u2019 debate channels by performing some qualitative analyses of their content.\nIn both the panoramic map as well as in the prior analysis (based on only \na single degree of relations to the seed list), we find the presence of a number \nof \u2018natively digital\u2019 political debate channels, such as \u2018Leukste YouTube \nFragmenten\u2019 and TheLvkrijger. In considering these channels as a type of \nmini-genre, we can thus compare their style and how they \u2018do\u2019 Dutch politics. \nAt the outset it should be noted that, by certain measures, some of these \nchannels appear quite marginal. \u2018TheLvkrijger\u2019, for example, which YouTube \nrelated to half the parties, only has 6.5 thousand subscribers. CNN, which \nYouTube also related to half the parties, has 6.5 million subscribers. The Dutch \npolitical space on YouTube is not that large, however, and in any case, despite \ndiffering by orders of magnitude, YouTube related channels algorithm places \nCNN and \u2018TheLvkrijger\u2019 on the same footing. One degree of relations gives us \na collection of \u2018alt\u2019 political debate channels including \u2018TheLvkrijger\u2019, \u2018Leukste \nYouTube Fragmenten\u2019, \u2018Rafiek de Bruin\u2019, \u2018LISSAUER.COM\u2019, \u2018Res Cogitans\u2019, \n\u2019Omroep PowNed\u2019, \u2018Arnews\u2019, to which we can add a few more by exploring \ntheir relations including \u2018GeenStijl\u2019, \u2018AllePolitiek\u2019 and \u2018Deweycheatumnhowe\u2019. \nIn analyzing their style, we can observe that \u2018TheLvkrijger\u2019, \u2018Leukste YouTube \nFragmenten\u2019, \u2018Rafiek de Bruin\u2019, \u2018AllePolitiek\u2019 and \u2018Deweycheatumnhowe\u2019 are \nall of a sort, in that all post debate clips or interviews. Furthermore, sites \nas \u2018Arnews\u2019 and \u2018LISSAUER\u2019 use \u2018meme\u2019 graphics \u2013 a style also employed, \nand in fact pioneered to an extent, by PowNed and GeenStijl . Somewhat \nlike Omroep PowNed in style, GeenStijl  is famed for its provocative anti-PC \ntone. Settled in the Dutch media landscape (and with PowNed receiving \nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  227\nstructural funds from the government), they can thus fairly be labelled as \n\u2018established anti-establishment\u2019. Using clickbait tactics to attract attention, \nwith the notable exception of AllePolitiek, the aim of these channels seems \nto be to amplify dissensus in the Dutch political space. Whilst this of course \nstands in marked contrast to the country\u2019s long history of consensus politics, \nwhere one normatively stands on this depends on one\u2019s democratic political \ntheory. Furthermore, whilst several channels are transparently partisan, \nwhat is remarkable is that the majority of the most viewed videos in most \nof the channels focuses on figures from the FvD and PVV.\nTo provide a synoptic view of the natively digital debate channels\u2019 issues one \ncan look at the most commonly used words in the titles of all of the channels \nin the form of \u2018word clouds\u2019 with words colour-coded and sized by frequency. \nThose appearing in black are issues such as referendum, climate agreement, \ndividend tax and Brexit, whist those in colour are the names of parties and \ntheir spokespeople. At first glance, what one notices is that \u2018Arnews\u2019 and \n\u2018AllePolitiek\u2019 appear primarily issue driven, whilst the other channels seem \nmore engaged with Dutch political personalities. One can also observe the \nrelative similarity between \u2018ResCogitans\u2019 and \u2018Leukste YouTube Fragmenten\u2019, \nas channels that both appear partisan towards FvD \u2013 on closer inspection this \nis indeed the case (and in fact they even appear to be run by the same person). \nSimilarly, \u2018TheLvkrijger\u2019 appears to be partisan towards the PVV, which is also \nthe case on closer inspection. As with the thumbnails, discussed above, the names of the figures from both these parties commonly appear in all these channels video titles. Further scrutiny reveals all of these channels to be at \nleast somewhat sensationalistic, with \u2018Arnews\u2019, often using terms like heated \ndebate (\u2018verhit debat\u2019) in order to describe content. The more partisan of the \nchannels follow an antagonistic logic when commenting on parliamentary \ndebates, identifying the winner or loser of a given debate, at times resembling \na debate genre familiar on YouTube, for example in videos featuring Jordan Peterson, often labelled in the style: Jordan Peterson DESTROYS so and so .\nAlongside the related channels findings, the fact that official Dutch \nparliament channels, along with Forum voor Democratie (but not  the other \nDutch political parties), are clustered alongside these \u2018alt\u2019 debate channels \nseems peculiar. Given the aforementioned capriciousness of platforms, \nmight these findings be attributable to an excited algorithm in the aftermath \nof FvD\u2019s surprising success in the senate elections? If so, then one would \nexpect these findings to differ when reproduced at another point in time, either revealing an underlying stable state of network composition or else \nanother excited state. With this question in mind we reproduced these first \ntwo methods, that were initially explored prior to the provincial (senate) \n228  M aRc  Tu T eR S Figure\u00a07.4   T humbnail diagram of the \u2018fringe channels\u2019\u2019 top ten most popular videos\nVisualization by fe derica ba rdelli\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  229\nelection, at the time of the EU parliamentary elections. Remarkably, we found \nno substantial difference in either the channels that YouTube considered \nas related to the parties (see Appendix 7.1). Moreover, the panoramic graph \nremained identical ,6 suggesting that it may thus reflect an underlying stable \nstate of how the algorithm currently categorizes the larger Dutch YouTube \nmedia sphere (see Figure\u00a07.3). Because the EU elections did involve several \nother parties, we did however identify the presence of two new clusters in \nthe panoramic graph: one of which, associated with the new pan-European \nVolt party, floats on its own completely disconnected from the overall \nnetwork; and another, associated with Dutch Pirate Party, which is con-\nnected to the larger network via a channel \u2018talking-head chat show\u2019 called \n\u2018Cafe Weltschmertz\u2019. In close proximity to the alternative media ecosystem \ndiscussed above, Cafe Weltschmertz seems to frame its political debates in a \ntendentious style  similar to some of the channels profiled above \u2013 referring \nto its approach, for example, as \u2018politically incorrect\u2019. In this same cluster \nwe also however find leftist investigative journalism channels including \n\u2018Follow the Money\u2019 and De Correspondent  as well as the expected channels \nfocused on the issue of privacy, \u2018Bits of Freedom\u2019, \u2018Privacy First\u2019 and finally a \ndebate channel called \u2018Potkaars Podcast\u2019 featuring a video on its front page, \nentitled \u2018Potkaars praat met iedereen\u2019 (Potkaars speaks with everybody). \nIn light of our subsequent discussion of fake news as a topic of debate, the \nvideo\u2019s description is worth quoting at length: \u2018If you want real news, you \nhave to cut through the smoke -smoke & mirrors- to get to information and \ndemand a controllable government. Dismissing information as \u2018fake news\u2019 \nis easy. But what do you replace it with?\u2019\n6 Y ouTube disabled the related video feature shortly after we completed this analysis (YouTube, \n2019).Figure\u00a07.5\n  S\ncreenshot from the \u2018About\u2019 page on Cafe Weltschmertz\u2019s Y ouTube \nchannel which includes a sarcastic \u2018trigger warning\u2019 for viewers who \nmight be angered by its frank approach to political debate, as well as crypto-normative espousal of \u2018democratic hygiene processes\u2019\n7\n\n230  M aRc  Tu T eR S \nOn fake news as issue\nThe final analysis concerns how channels in the Dutch political space \u2018do\u2019 the \none issue in particular: fake news. We begin with a video from \u2018TheLvkrijger\u2019 \nof PVV representative Martin Bosma confronting the government minister \nof Internal Affairs, Kajsa Ollongren in a Tweede Kamer debate on the fake \nnews that became central to her portfolio. In the video Bosma accuses \nOllongren of \u2018playing a strange game\u2019 with \u2018what is truthful and what is \nnot\u2019.  Bosma points to a fundamental lack of consensus of what\u2019s at issue in \nthe fake news controversy more generally as well as alleging that Ollongren \nhas seemingly tended to change her own definition of what constitutes fake \nnews in order to suit her political purposes. When examining the comment \nsection below this video we see commenters echoing Bosma\u2019s sentiments \nand questioning Ollongren\u2019s integrity, expressing the need for a concrete \ndefinition of fake news (45 likes). Commenters furthermore speak of Dutch \npublic broadcasting as fake news that does \u2018nothing but mislead citizens\u2019 \n(78 likes).8 This latter use of the concept of fake news echoes Trump\u2019s use \nof the term as means of attacking the establishment media.\nAnother video of interest, also published by \u2018TheLvkrijger\u2019, features a \nPVV-organized populist-type debate with pundits on the topic of fake news \n(\u2018nepnieuws\u2019) and the European Union. Similar to the aforementioned \nTrumpian framing of fake news, the debate discusses the supposedly left-\nwing bias in the establishment media, as represented in one participant\u2019s statement that \u2018media serve the ideology of the establishment\u2019. Again, we see positive reception in the comment section where a commenter writes \nabout the Dutch public broadcaster \u2018NOS = FAKE NEWS\u2019, and advocates \nviewers to seek their news from alternative sources on YT.9\nIn another video on the topic, this time published by GeenStijl , a reporter \nasks politicians leaving the Tweede Kamer about the issue of \u2018fake news\u2019. \nThis time the reporter\u2019s questioning revolves around proposed European \n7 W ithout offering any analysis of this particular unique term, for reasons of brevity and \nfocus, it is nevertheless worth noting here that one of the signature accomplishments of some \nof the American alternative partisan news system, especially those on the far-right, has been \nto introduce new terminology in the hopes of normalizing certain formerly radical conceptual \nframes (Hatewatch Staff, 2015; Benkler et al., 2018: 128-132). In political punditry this technique \nis sometimes called \u2018opening the Overton window\u2019 (Marwick and Lewis, 2017: 11)\n8 T he number of likes on a comment can be treated here as a measure of agreement with \nthese sentiments expressed therein.9\n T\nhis theme of framing of \u2018NOS is fake news\u2019 and \u2018NOS is left-wing propaganda\u2019 came up in \nmultiple comments of multiple videos.\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  231\nFigure\u00a07.6   W eighted word lists of the titles of all the videos from the political \ncommentary channels\nVisualization by fe derica ba rdelli\n232  M aRc  Tu T eR S \nlegislation, rather than Ollongren\u2019s engagement with the issue. As per the \nchannel\u2019s provocative style, the video does not hide its partisan stance on the \nissue, titling the video: \u2018Brussels is censoring free speech\u2019. Again, representa -\ntive Bosma appears, this time with an attack on liberal political correctness \nemanating from the liberal technocrats in Brussels, stating \u2018everything \nthat is not politically correct will be tackled\u2019.10 By contrast other politicians \ninterviewed by the journalist see the necessity of government action in \nresponse to the \u2018crisis\u2019 of fake news. In the comments section multiple com -\nmenters reiterate the theme of the Dutch Government itself being \u2018fake news\u2019.\nA video published on \u2018Leukste YouTube Fragmenten\u2019 features a Tweede \nKamer debate fragment, once again on the concept of freedom of speech, this \ntime by FvD leader Thierry Baudet. In this clip Baudet makes a sophisticated \nconceptual point on the alethiological (the study of truth). Using logic, Baudet \ntries to refute Ollongren\u2019s concept of fake news as fallacious. He argues that \nif for an atheist god is not true, then that would not make preaching a form \nof disinformation. Based on this argument he then claims that Ollongren \nwould \u2018accuse the teachings of Catholicism of being untrue\u2019 and thus \u2018a form \nof disinformation\u2019. After his sophistry, Baudet then goes on to make the point \nthat state actors should not  be allowed to decide what is true and what is \nnot true. \u2018You cannot trust the state\u2019, he says, what \u2018we need\u2019, he argues is \n\u2018free press\u2019. In the comments section commenters state that all politicians, \nbesides Baudet, define fake news subjectively in particular falling back on the \nRussian \u2018evil actor\u2019 narrative, which a commenter characterized as \u2018Orwellian\u2019.\nAlthough our analysis in the report did not include any left-of-centre \nDutch political commentators, this is not to say that they do not exist on \nYouTube. Rather, the methods we used did not bring them to the fore. Indeed, \nalongside the \u2018alt\u2019 channels profiled above we can in fact find a video of Arjen \nLubach\u2019s Zondag met Lubach, the VPRO broadcast in which the commentator, \n10 P olitical correctness is a very popular straw man amongst \u2018dark intellectual web\u2019 figures \nlike Jordan Peterson on the right (Weiss 2018), but also left-wing figures such as Slavoj \u017di\u017eek.Figure\u00a07.7\n  S\ncreenshot of a comment under the video of \u2018Leukste YT Fragmenten\u2019 , \nreferring to a \u2018hopeless debate\u2019 and the lack of consensus on the \ndefinition of \u2018nepnieuws\u2019\n\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  233\nas with the one on the Green Style video, critiques the Russian \u2018evil actor\u2019 \nnarrative. In Lubach\u2019s opinion the real threat is in fact an alt-right conspiracy \ntheory, in the style of Pizzagate, which Russian actors merely amplify.\nConclusions: Left-leaning bias?\nAcademics are often accused by conservatives of having a left-leaning \nbias; indeed, apparently evidence reflects these allegations (Abrams, 2016). \nThis narrative of \u2018liberal bias\u2019 has been one of the central themes of the \nAmerican new right, extending from contemporary \u2018neo-reactionaries\u2019 \n(Malice 2019), to 1990\u2019s \u2018culture warriors\u2019 (Nagle 2017), and back to the 1960\u2019s \n\u2018messengers of the right\u2019, who pioneered new media formats in order to \ndisseminate their message (Hemmer 2016). And whilst accusations of such \nperceived liberal bias may be offered against this report, the fact remains \nthat we came by the data underlying our findings by merely following \nthe platform and the way that it categorized the Dutch political parties. \nIn doing so we identified a series of \u2018alternative\u2019 debate channels many of \nwhich appeared hyperpartisan \u2013 following Hermann\u2019s initial definition of \nthe concept as \u2018openly ideological web operations\u2019. If we were to locate the \npolitical bias of these \u2018alternative\u2019 political debate channels in relation to \n\u2018establishment\u2019 media organizations in the Netherlands, then many would \nseem to be roughly aligned with the conservative and populist tone of De \nTelegraaf . Closer still to the antagonistic debate style that we observed in \nmany of these channels is the transgressive style of reportage pioneered \nby the \u2018established anti-establishment\u2019 of GeenStijl  and Omroep PowNed.\nThe Netherlands is also well known for having innovated new media formats, \nnotably reality TV. Additionally, one might also say that the Netherlands has \nbeen innovative in developing new positions and issues on the right \u2013 notably \nthe issue of homo-nationalism (Aydemir 2011). What we may however also \nbe seeing in this research is the possible emergence of US-style right-wing \npunditry in the Dutch sphere. While it still seems marginal in the current \n\u2018alternative\u2019 debate space on YouTube space, exemplary here is the channel \nof \u2018Paul Nielsen\u2019 (24,531 subscriptions), an English language Dutch \u2018alt-lite\u2019 \nchannel which features such titles as: \u2018NOS is the Dutch CNN | Biased News in \nHolland\u2019 and \u2018How Marxists took over the Netherlands\u2019. The site claims to be \nendorsed by Prof. Dr. Paul Cliteur, expert witness at Geert Wilders\u2019 hate speech \ntrial and Ph.D. supervisor to Thierry Baudet. This channel may be a bridging \nnode to the figures in what has been called YouTube\u2019s \u2018dark intellectual web\u2019 \n(Weiss, 2018) or its \u2018alternative influence network\u2019 (Lewis, 2018), such as for \n234  M aRc  Tu T eR S \nexample Stephan Molyneux who features a video with the title: \u2018The Truth \nAbout Immigration and Crime in the NL\u2019. At the same time, in scrutinizing \na network one should be careful of the guilt by association fallacy. The point \nis rather to acknowledge the proximity to an active and controversial area of debate within the platform.\nWhile the possible intervention of \u2018Russian trolls\u2019 as a factor in 2016 US \nelections has been convincingly made (Jamieson, 2018), the Dutch case is \ndifferent. In addition to the absence of an Anglo-American \u2018first-past-the-post\u2019 \nelectoral system there is a very different media ecosystem in the Netherlands, \nwhich for example still has a much higher trust in the general \u2018establishment\u2019 \nthan in the US (Edelman, 2018). Furthermore, as opposed to the \u2018neutrality\u2019 \naxiom that has characterized 20th-century US news media, Dutch news media \nhave always been partisan. This having been said what we see in YouTube \nsuggests the emergence of a hyperpartisan Dutch new media political space. \nCurrently it is mostly dominated by one party, but other parties may take this \nas a challenge. Insofar as YouTube represents a media source in the Nether -\nlands, especially for youth, the Dutch YouTube \u2018alt\u2019 political debate space may \nrepresent a re-politicization of youth, which runs counter to neoliberalism\u2019s \nhistorical project of pre-emptive depoliticization (Foucault, 2008). If political \npluralism advocates peaceful coexistence of different interests the combative \nand anti-politically correct tone of much of political debate on YouTube may \nmilitate against this. Can the long tradition of consensus in Dutch culture be \nbrought to bear on this new debate culture or is the Netherlands on the path to \nAmericanized Trump-style polarization? In terms of final takeaways, we can \nsay that an inquiry into fake news, which defines the latter as the deliberate \nmanipulations of facts, must also consider the inherently problematic aspects \nof this very conception as well. For this reason, regulating disinformation can \nbe portrayed as Orwellian \u2018thought control\u2019, which in turn resonates with \npopulists\u2019 anti-establishment, conspiratorial frameworks.\nReferences\nAydemir, Murat (2011) Dutch Homonationalism and Intersectionality , ARC-GS Lec -\nture, https://arcgs.uva.nl/videos/video-artikelen/dutch-homonationalismand-\nintersectionality.html?1556011447190\nBahara, Hassan, Annieke Kranenberg and Dimitri Tokmetzis (2019) \u2018Leidt het \nAlgoritme van Youtube je Naar Extreme Content?\u2019, de Volkskrant , 11\u00a0February, \nhttps://www.volkskrant.nl/nieuws-achtergrond/leidt-het-algoritme-vanyoutube-\nje-naar-extreme-content~bea101e3/\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  235\nBenkler, Yochai, Robert Faris and Hal Roberts (2018) Network Propaganda: Manipula -\ntion, Disinformation, and Radicalization in American Politics . Oxford: Oxford \nUniversity Press.\nBessi, Alessandro et al. (2016) \u2018Users Polarization on Facebook and Youtube\u2019, PLoS \nONE , (11)8, pp.\u00a01-13. Open WorldCat, doi:10.1371/journal.pone.0159641.\nboyd, danah (2017) \u2018Did Media Literacy Backfire?\u2019, Data & Society Points , 5\u00a0January, \nhttps://points.datasociety.net/did-media-literacy-backf\u0133ire-7418c084d88d\nEatwell, Roger, and Matthew Goodwin (2018) National Populism: The Revolt Against \nLiberal Democracy . London: Penguin Books.\nEdelman (2018) 2018 Edelman Trust Barometer . https://www.edelman.com/sites/g/\nf\u0133iles/aatuss191/f\u0133iles/2018-10/Edelman_Trust_Barometer_Employee_Experi -\nence_2018_0.pdf\nFoucault, Michel (2008) The Birth of Biopolitics: Lectures at the College De France, \n1978-1979 , Edited by Michel Senellart, Translated by Graham Burchell. New \nYork: Palgrave Macmillan.\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine.\u2019 The New York Times Magazine , 24\u00a0Au -\ngust, https://www.nytimes.com/2016/08/28/magazine/inside-facebookstotally-\ninsane-unintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHolt, Jared (2017) \u2018White Supremacy Figured Out How to Become YouTube Fa -\nmous\u2019, Right Wing Watch , October. http://www.rightwingwatch.org/report/\nwhite-supremacy-f\u0133igured-out-how-to-become-youtube-famous/.\nJamieson, Kathleen Hall (2018) Cyberwar: How Russian Hackers and Trolls Helped \nElect a President . Oxford: Oxford University Press.\nKaiser, Jonas and Adrian Rauchfleisch (2018) \u2018Unite the Right? How YouTube\u2019s \nRecommendation Algorithm Connects the U.S. Far-Right.\u2019 Data & Society \nMedia Manipulation , 11\u00a0April. doi:10.1093/acprof:oso/9780199641260.001.0001/\nacprof-9780199641260.\nLewis, Rebecca (2018) \u2018Alternative Influence: Broadcasting the Reactionary Right on \nYouTube,\u2019 Data & Society . https://datasociety.net/wp-content/uploads/2018/09/\nDS_Alternative_Influence.pdf.\nLynskey, Dorian (2018) \u2018How Dangerous Is Jordan B Peterson, the Rightwing \nProfessor Who \u2018Hit a Hornets\u2019 Nest\u2019?\u2019 The Guardian , 7\u00a0February. https://www. \ntheguardian.com/science/2018/feb/07/how-dangerous-is-jordan-b-petersonthe-\nrightwing-professor-who-hit-a-hornets-nest.\nMudde, Cas and Crist.bal Rovira Kaltwasser (2017) Populism: A Very Short Introduc -\ntion . Oxford: Oxford University Press.\nMuller, Jan-Werner (2016) What Is Populism? Philadelphia: University of Pennsyl -\nvania Press.\n236  M aRc  Tu T eR S \nPariser, Eli (2011) The Filter Bubble: What the Internet Is Hiding From You. New \nYork: Penguin.\n\u2018Press \u2013 YouTube\u2019. YouTube, 2018, https://www.youtube.com/intl/en-GB/yt/about/\npress/.\nRieder, Bernhard et al. (2016) \u2018Data Critique and Analytical Opportunities for Very \nLarge Facebook Pages. Lessons Learned from Exploring \u201cWe Are All Khaled \nSaid\u201d\u2019. Big Data & Society 2(2), pp.\u00a01-22.\nRogers, Richard (2013) Digital Methods. Cambridge, MA: MIT Press.\nTufekci, Zeynep (2018) \u2018YouTube, the Great Radicalizer\u2019, New York Times, 10\u00a0March. \nhttps://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.\nhtml.\nWardle, Claire and Hossein Derakhshan (2017) \u2018Information Disorder: Toward \nan interdisciplinary framework for research and policy making\u2019, Council of \nEurope. 27\u00a0September.\nWeisman, Jonathan (2018) (((Semitism))): Being Jewish in America in the Age of \nTrump . New York: St. Martin\u2019s Press.\nWeiss, Ben (2018) \u2018Meet the Renegades of the Intellectual Dark Web\u2019, New York Times , \n8\u00a0May. https://www.nytimes.com/2018/05/08/opinion/intellectualdark-web.html.\nAbout the author\nMarc Tuters  is Assistant Professor in New Media & Digital Culture at the \nUniversity of Amsterdam. He has graduate degrees from Concordia (Canada) \nand the University of Southern California (USA), and has worked as an artist \nand researcher in organizations including the Annenberg Centre, the Banff \nCentre, National University of Singapore, and Waseda University.\nfa ke ne W S  and Th e duTc h YouTube Po liTi cal deba Te SPa ce  237\nAppendix 7.1\nFigure\u00a07.8   Rela ted channels on Y ouTube, 22\u00a0May\u00a02019\nTable where the top row displays the name of each Dutch political party \nwho ran candidates in the EU election. As with Figure\u00a07.1, the columns \nbelow each of these are the media organizations associated with each \nparty\u2019s YouTube channel. The related channels for the parties are identical \nto Figure\u00a07.1 apart from a few minor differences and the fact that D66 now \nno longer returns any related channels, as with PvdA. Note also that of the \ntwo EU parties that return channels are categorized quite differently than \nthe other national Dutch political parties. Source: YouTube.\n\n8 Conclusions\nMainstream under fire\nRichard Rogers and Sabine Niederer\nAbstract\nTo what extent do (foreign) disinformation and so-called fake news \nresonate in political spaces online within social media around the 2019 \nprovincial elections and the European parliamentary elections in the \nNetherlands? We found no foreign disinformation, fake advocacy groups \nor imposter news organizations, but we did take notice of a polarised \nmedia landscape, where problematic information, including extreme \ncontent, is engaged with (liked, shared, retweeted, etc.) or returned in \nsearch engines when querying political parties, political leaders as well as \nsocial issues. The study ultimately recommends media training as well as \ndisengagement with extreme content, together with a call for continued \naccess to social media platform data for media monitoring purposes.\nKeywords:  fake news, disinformation, polarisation, extreme content, \nmedia monitoring\nSeparating disinformation and fake news and developing other \nnotions further\nDisinformation and fake news are contemporary phenomena with rich \nhistories. Disinformation, or the wilful introduction of false information \nfor the purposes of causing harm, recalls infamous foreign interference \noperations in national media systems, such as the Russian campaign \n\u2018Operation Infektion\u2019 that in the early 1980s effectively publicly linked the \nHIV virus with a supposed, secret US bioweapons lab. Outcries over fake \nnews, or dubious stories that have the trappings of news, have occurred \nrepeatedly with the introduction of new media technologies that disrupt \nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch08\n240  R icha Rd R oge R S  and Sabine ni ede ReR \nthe publication, distribution and consumption of news \u2013 from the so-called \nrumour-mongering broadsheets centuries ago to the blogosphere more \nrecently. Social media are only the most recent \u2018truthless\u2019 media. Designating \na news organization as fake, or calling it der L\u00fcgenpresse , however, has a \ndarker history, associated with authoritarian regimes or populist bombast \ndiminishing the reputation of \u2018elite media\u2019 and the value of inconvenient \ntruths more generally.\nThese days social media platforms have been implicated in both the \npractice of disinformation as well as the rise of these two varieties of fake \nnews. As discussed in the theoretical and empirical scholarship to date, \nsocial media have enabled the penetration of foreign disinformation opera -\ntions, the widespread publication and spread of dubious content as well as \nextreme commentators with considerable followings attacking mainstream \nmedia as fake.\nWorldwide, disinformation and fake news are increasingly under study \ntogether, but the argument could be made to separate them. Indeed, in the \nNetherlands evidence of foreign disinformation campaigning is scant; cases \nof domestic actors employing the \u2018Russian playbook\u2019 of disinformation tactics \nare also seldom documented. Unlike in the case of the US, to which much of \nthe scholarship is dedicated, in the Netherlands one has not witnessed the \nrise of imposter news organizations or the formation of advocacy groups \npurporting to represent social groups or causes. Indeed, when employing \nnarrow definitions of disinformation and fake news, there is hardly any to \nbe found in the Netherlands.\nBut definitions of fake and its next-of-kin \u2018junk\u2019 news often extend \nto clickbait, conspiracy, hyperpartisan and tendentious sources as well \nas artificially amplified social media content and accounts. As a case in \npoint, when Buzzfeed News  famously reported in 2016 that \u2018fake news\u2019 was \noutperforming mainstream news on Facebook, included in its definition \nwere clickbait and hyperpartisan sources, such as Breitbart News . Expand-\ning the definition in such a manner would have consequences in that the \nNetherlands has all of them in relative abundance.\nInitial studies have found that the Dutch are great consumers of clickbait \nand \u2018pulp\u2019 content; there is a well engaged-with set of tendentious and highly \npartisan news-like organizations especially on the right of the political \nspectrum, and the artificial amplification of social media accounts, including \nthose of certain politicians and musicians, has been well documented. \nTheir sway varies. Clickbait is said to be consumed more often than main -\nstream news, though there is also more of it. Conspiracy is perhaps the \nleast clicked on, at least according to our findings per platform, discussed \ncon clu Sion S 241\nbelow. In political spaces online, news furnished by commercial and public \nbroadcasting are still referenced, liked or shared in greater quantities than \ntendentious and hyperpartisan sources, though the latter has been present \nin the most engaged-with lists of sources around election issues. Artificial \namplification both burnishes one\u2019s image but also has led to mini-scandals \nwhen fake followers are revealed through new online detection tools and \nnews reporting.\nWhether any of them is particularly persuasive is a question increasingly \nposed. The first wave of scholarship on the production and spread of disinfor -\nmation has yielded to the next wave on its effects. Given people\u2019s hardened \nattitudes the question concerns whether the influence of disinformation \nand fake news is ever more than \u2018minimal\u2019.\nIn that regard, the rise of extreme content (including extreme clickbait), \ncirculated on social media platforms, is one source of continuing con -\nsternation and measurement, leading to calls for platform regulation and \nprompting social media companies to hire more content reviewers and work \non automated detection. Another source of concern is the mainstreaming \nof doubt and trust in public institutions and media, concomitant with the \nrise of both \u2018alternative facts\u2019 and \u2018alternative fact infrastructures\u2019. The \npost-truth condition, as it is termed, is discussed as both first-order \u2018fact \nfights\u2019 as well as second-order competitions between \u2018sectarian knowledge\u2019 \nregimes and competing media ecologies. Is the authority of mainstream \nnews and knowledge institutions declining for increasing segments of \nsociety that consume the alternatives? One finding often related is that \nolder consumers are \u2018available audiences\u2019 for fringe media and are relatively \n\u2018heavy users\u2019.\nThe consuming and sharing of so-called fake news have been the subject \nof media literacy initiatives, including quizzes, serious games and public \nservice campaigns. Through heightened awareness, especially around \nthe time of elections, the impact on consumers of any disinformation and \ndubious content may be mitigated and the institutions made resilient, it has \nbeen argued. Voluntary and professional fact-checking are also discussed in \nthis regard, as are (automated) content flagging, together with the need for \nhuman review. The question regularly posed is whether the sheer amount \nof platform junk will overwhelm the capacity to review it, together with \nthe related issue of who will review the reviewers.\nFinally, there is widespread scholarly concern about the restrictions to \npublic access of social media data, otherwise known as the issue of \u2018locked \nplatforms\u2019. Future research should address the extent to which disinforma -\ntion and \u2018fake news\u2019 (in all its more exacting definitions) continue to thrive \n242  R icha Rd R oge R S  and Sabine ni ede ReR \nonline, and whether there are monitoring capacities in place so that its \noverall consumption and persuasive capacity may be measured, and the \nwider societal implications may be studied and acted upon.\nEmpirical findings concerning junk news around the Dutch \nelections of 2019\nThe present study consists of a series of empirical case studies concerning \nthe engagement with junk news, including hyperpartisan and tendentious \nsources, in Dutch political spaces in social media in the run up to two elec -\ntions in 2019. These spaces were demarcated using queries of politicians\u2019 and \npolitical party names as well as social issues, some related to the elections \n(such as climate and EU) and others more controversial (such as Zwarte Piet). \nHere the findings are summarized, and subsequently put into perspective \nin a discussion of their implications, also for policy.\nThe overall research question driving the study is as follows. To what extent \ndo disinformation and so-called fake or junk news resonate in political spaces \nonline within social media (and search engine returns) around the 2019 provin -\ncial elections and the European parliamentary elections in the Netherlands?\nHere the findings are provided in brief:\n1) W e found neither foreign disinformation (campaigning) nor fake ad -\nvocacy groups operating around the Dutch provincial and European \nparliamentary elections of 2019.\n2) M ainstream news is consumed and engaged-with more than junk \nnews, but not for all platforms in all periods under study (8\u00a0Febru -\nary-25\u00a0March\u00a02019, 26\u00a0April-24\u00a0May\u00a02019 or longer durations). The issue \nspaces around Zwarte Piet and MH17 have proportionately higher \nquantities of junk news than election issues and are also \u2018year-round\u2019 \nissues, so to speak, rather than seasonal or event-based.\n3) W ith respect to social media manipulation, troll-like users are active \nacross Dutch political issues spaces (on Twitter). We also suspect there \nis (rather light) artificial amplification taking place (fake followers on Instagram).\n4) T here is the emergence of a hyperpartisan/tendentious alternative media \necology, competing with the mainstream news and also mainstreaming, \nin the sense that these sources include newswire content and are spread \nby regular (non-flagged) social media users as well as flagged, troll-like \nusers.\ncon clu Sion S 243\n5) P roportionately, Facebook has the greatest amount of junk news com -\npared to other platforms, followed by Twitter. YouTube is a significant \nextreme news space generally, and a cultural commentary and debate space for \u2018fake news\u2019 as issue.\n6) D utch 4chan and Reddit circulate far more Dutch mainstream than \njunk news, with 4chan users likely commenting upon rather than \ntaking over its narratives. 4chan is an incubator of far-right activ -\nity in the Netherlands as seen through the types of YouTube videos \nreferenced.\nFacebook: Fertile ground for junk news\nThe method behind the research presented here derives from data journal -\nism, particularly that of Buzzfeed News, and later the NRC Handelsblad , which \nboth ascertained the most engaged-with stories on Facebook in the run-up \nto national elections. Whereas Buzzfeed News  found that \u2018fake news\u2019 on \nFacebook outperformed mainstream news in the months preceding the US \nfederal elections of 2016, leading in part to the overall \u2018fake news crisis\u2019, the \nNRC Handelsblad , deploying a far stricter definition, found scant presence \nof such material prior to the 2017 Dutch national elections. Our study found \nthat Facebook is a fertile ground not for disinformation and fake news in \nthe Netherlands but rather for junk news, a roomier definition than fake \nnews as discussed above. Whilst it is not outperforming mainstream news, \nit is far from marginal, and in a few periods under study its presence in \nthe top stories on Facebook (judged from engagement measures) equals or \noutperforms the mainstream. Engagement, measured by such interaction \nas shares and likes, requires further study, however, for it should not be \nequated in each case with support or agreement.\nWhile Facebook contains a significant stream of junk news, including \nhyperpartisan and conspiracy sources, foreign disinformation and fake \nnews \u2013 such as organizations pretending to be news sources or advocacy \ngroups \u2013 were found to be absent, at least for the most engaged-with stories \nrelated to the elections gathered through keyword queries of political lead -\ners, parties and social issues (or in longer longitudinal studies of certain \nissue spaces on Twitter as well as in Dutch spaces on Reddit and 4chan). \nDisinformation and fake news may have not been encountered, but junk \nnews is a factor in Dutch political spaces on social media and its impact \nshould be critically studied.\n244  R icha Rd R oge R S  and Sabine ni ede ReR \nGoogle Web Search: vernacular search queries result in junk news\nThe Google Web Search study involved locating junk news within the top \ntwenty results in Google.nl for queries of Dutch political parties and signifi -\ncant social issues prior to the Dutch provincial and European parliamentary \nelections of 2019. The queries were formulated by combining the names of \nthe political parties with social issue keywords. The keywords derive both \nfrom the \u2018official\u2019 issue language collected from the party platforms as well \nas vernacular terms distilled from the comments on political party Facebook \npages. Of the junk news found nearly all originate from hyperpartisan \nand tendentious sources rather than disinformation, conspiracy theory or \nclickbait. For particular groups of issue queries, up to 25% of the results were \nhyperpartisan. As on the other platforms under study, in the \u2018top content\u2019 \nno foreign disinformation, fake news organizations or fake advocacy groups \nwere present during the election periods.\nThe social issue keyword queries in combination with right-of-centre \npolitical parties resulted in junk news sources in greater quantities than \nthat of left-of-centre party names. It was also found that the presence of junk \nnews is not stable over time. Prior to the provincial elections the quantities \nrose, only to decline the day of the election and in its immediate aftermath, \nas witnessed by the issue of migration. The inverse was witnessed during \nthe European parliamentary elections. When comparing the two types of \nsearch queries, the official and the vernacular, the latter results in a higher \npercentage of junk news in the results.\nTwitter: junk news and troll activity around polarizing subject \nmatters\nThe Twitter study examined the presence of junk news as well as troll-like \nactivity during the campaign periods around the Dutch provincial and \nEuropean parliamentary elections of 2019. There was troll-like activity \nencountered around the provincial elections around political terms such \nas the tag for the elections themselves (\u2018PS2019\u2019), certain party leaders as \nwell as potentially polarizing issues such as MH17, Zwarte Piet and the \nUtrecht tram shooting of March\u00a02019. Troll-like activity refers to a series of \nbehavioural indicators, including targeting politicians with unusually high \nbursts of tweets in short periods of time or through a set of accounts created \nat about the same time. The analysis found fourteen troll-like Twitter users \nwere active around all issues studied and twenty-nine around most of them. \ncon clu Sion S 245\nFour of these profiles remained active (or became active again) around the \nEuropean parliamentary elections. They all spread mainly hyperpartisan \nand tendentious sources, followed in quantity by conspiracy websites.\nIn answering the question of the extent to which junk news is present in \nthe Dutch political Twittersphere, we ascertained the most shared sources, \nfinding a steady resonance of junk news, paling in comparison however to \nmainstream sources. One finding of note is that during the Provincial elec -\ntions both Zwarte Piet and MH17 witnessed proportionately high amounts \nof activity, in spite of the fact that the Santa Klaus holiday (where Zwarte \nPiets make their appearance) does not take place until December and there \nwas no particular MH17 news, for example concerning the investigations \ninto the cause of the crash of the airliner. Troll-like users shared mostly \nhyperpartisan and tendentious sources, followed by conspiracy websites \nputting forward theories concerning MH17 and the Utrecht tram shooting. \nThe pro-Russian site, novini.nl, which on a story level oscillates between \nhyperpartisan and conspiracy, also was circulated by troll-like users for \nall social issues under study, but only rarely in relation to political leaders. \nDuring the European Parliamentary elections junk news occasionally \nresonated more than mainstream news around such polarizing issues as \nZwarte Piet and MH17. It outperformed mainstream news largely owing to \nthe lack of news coverage of these issues during the periods under study, \nwhen junk news remains steady.\nBased on the findings, it appears that the Dutch Twittersphere does not \nhave a disinformation problem; no professional or large-scale disinformation \nor fake advocacy campaigns were encountered. Troll-like users, whether \nin the form of bots, semi-automated users auto-retweeting and posting \noriginal content or unusually active users targeting politicians, do lend \nsome symbolic power to divisive points of view around several social is -\nsues. Polarizing issue activity, fuelled by reference to hyperpartisan news, \nremains rather stable (albeit marginal) throughout both periods of study, \nsuggesting that these issues do not resonate at expected times of the year only, but rather throughout.\nInstagram: a separate extreme media ecology and signs of \nartificial amplification\nThe Instagram study inquired into the presence (and absence) of disinforma -\ntion and junk news in three ways: on a post-level, a source-level and that \nof followers. On a post-level, we examine the circulation of junk news in \n246  R icha Rd R oge R S  and Sabine ni ede ReR \npolitical spaces, on a source-level we compare the audiences of junk news \nand political leaders and parties, and finally we study the follower bases of \nthe political entities, searching for signs of inauthentic behaviour. In all we \nfound a relatively healthy Dutch political arena on Instagram with only small \namounts of junk news and fake followers. The vast majority of liked content \nin Dutch political Instagram, demarcated through political keyword queries, \nis not junk news, though around certain political leaders (at the far end of \nthe political spectrum) and divisive issues small amounts of hyperpartisan \nnews appear. Mainstream news was more prominent than junk news in the \nposts related to political parties and leaders in both periods under study. \nThe most active users of the platform in the Dutch political Instagram arena \nare seemingly authentic with little sign artificial manipulation.\nWithin this relatively healthy political space online the only suspicious \nactivity encountered was on the far right of the political spectrum, where \nthe circulation of junk news takes place and where those who follow the \nparties and leaders also follow the junk news sources. Here there are also \nindications of artificial manipulation. Certain party leaders (as well as \nthe personal account of the Prime Minister) show signs of a significant \nfake follower base. The artificial activity found is in line with the 2015 fake \nfollower incident when Twitter announced the deletion of fake followers \nthat affected certain Dutch politicians (and celebrities) disproportionately.\nReddit and 4chan: YouTube videos as news source contribute to \npolarization\nDespite their characterizations as alternative spaces on the web, the \u2018Dutch\u2019 \nReddit and 4chan, following from our findings, do not appear to spread \nalternative news sources, but rather refer more often (even overwhelmingly) \nto mainstream news sources. Apart from witnessing examples of circulating \nthe pro-Russian site, novini.nl, and the activity of one particularly suspect \nReddit account, there does not appear to be any coordinated disinformation \nor fake news campaigning. There is certainly junk news to be found but \ncompared to the overall spreading of sources the proportion is marginal. \nParticularly Reddit seems to be \u2018resistant\u2019 to disinformation.\nThe research found the presence of junk news, especially of the hy -\nperpartisan variety, particularly in 4chan/pol/. These are largely links \nt\no tendentious and hyperpartisan sources such as The Post Online and \nDe Dagelijkse Standaard , but also to the conspiracy site, NineForNews. A \nright-wing orientation was to be expected in 4chan/pol/, given its reputation \ncon clu Sion S 247\nas a hub of the extreme right, but it was perhaps less likely for Reddit, as \nthe \u2018Dutch\u2019 Reddit that we took as a starting point contains a number of \npolitically diverse subreddits. The articles that have gained the greatest \nsalience concern migration and Islam rather than such geopolitical content \nas the Russian involvement in MH17. Whilst it may be problematic to label \nthese sources as \u2018fake\u2019, they could be characterized as polarizing.\nNevertheless, the vast majority of the links to news sources are directed \nat mainstream outlets such as NOS.nl, both on 4chan/pol as well as Reddit. \nThese findings are counterintuitive in that the platforms are often described \nas alternative, as was said, and the anonymous and pseudonymous users \npoint to marginal or alternative knowledge sources such as alternatives to \nWikipedia. Our findings dispute such a characterization, for mainstream \nsources enjoy some authority on these platforms, but we did not as of yet \nresearch how they are discussed, e.g., as the starting point for a discussion \nor ridicule. On Reddit it could be that the mainstream NOS.nl is considered \na reliable source and on 4chan/pol/ \u2018fake news\u2019.\nFinally, it is important not to regard mainstream and junk news as the \nonly sources of news on the web. In both the Reddit and 4chan research \nbut also in the YouTube study, we found that YouTube has emerged as a \nmajor news source. That can be said particularly for 4chan/pol/ but also for \nReddit, where \u2018News & Politics\u2019 videos are a significant source. On 4chan/\npol/ they may be the most significant, quantitatively leaving other sources \nwell behind. From a small explorative study of the YouTube channels posted \non Reddit we found established sources referenced such as PowNed, Zondag \nmet Lubach and NOS, while on 4chan/pol/ alternative, foreign and political \n(hyperpartisan) sources are pointed to, such as Mike Cernovich and Russia \nToday. Should such linking and engagement continue, such polarizing \ncontent could have a polarizing effect in the Dutch political space.\nFrom findings to implications: Mainstream under fire\nThere is a small, but growing literature concerning how fake news could \nbe considered a moral panic (Morozov, 2017; Hirst, 2017). The term refers to \nrecurring episodes in history when \u2018right-thinking people\u2019 (defined seminally \nby Stanley Cohen as \u2018editors, bishops and politicians\u2019) spot a condition that is \nsupposedly prompting a decline in societal standards and values (1972). When \nfake news is viewed through that lens, the concern is about how traditional \njournalism as a pillar or \u20184th estate\u2019 of democracy is being hollowed out by \nsocial media and replaced by low-quality clickbait as well as openly ideological \n248  R icha Rd R oge R S  and Sabine ni ede ReR \ncommentary, both formatted in manners that drive their consumption \nnot so unlike sugary junk food. The overall health of media as social fabric \nis said to be at stake, for citizens using social media as source for political \ninformation are disadvantaged in their capacity to form judgements about \nsocial issues and politics more broadly (Carlson, 2018). There is a second set of \nliterature describing how the media coverage of so-called fake or junk news, \nand especially its relationship to the growth of an alternative, right-wing \nmedia ecology, gives it \u2018oxygen\u2019 (Phillips, 2018). More poignantly, it has been \nargued that journalistic coverage should turn its attention to the victims, \nrather than to the fascinating subcultural milieu online where the far right \ncultivates itself. There are also cases of politicians\u2019 forwarding extremist and \ndivisive content, which also gives it oxygen in the sense that it contributes \nto its spread and perhaps to its normalcy. Along all these lines, the recom -\nmendations concern identifying and acting upon threats to the mainstream, \nbe they from social media platforms or from within the professions and \npractices of journalism, online content creation and political leadership.\nAs we have found there are particular platforms and subject matters where \nthe threats to the mainstream appear more acute. Whilst not a space where \nDutch junk news sources are spread on a massive scale, the Dutch 4chan is \nan incubator of extremist sentiment, especially with respect to anti-Semitism \nand anti-immigration. Other platforms are problematic for different reasons. \nDutch political spaces in Facebook and Twitter, demarcated through politi-\ncian, party and issue queries, have the largest quantities of junk news that is \nengaged with, though they are still smaller than mainstream news consump -\ntion overall in those same spaces. Among the junk news, hyperpartisan \nsources (rather than disinformation or conspiracy) are amongst the more \npopular, and for divisive subject matters such as climate change, MH17 and \nZwarte Piet their stories occasionally outperform those in the mainstream \npress. On Twitter during the European parliamentary election campaign \nperiod, for example, a pro-Nexit story in the hyperpartisan newspaper, De \nDagelijkse Standaard , about the Netherlands leaving the EU outperformed \na counterpart article in the mainstream NRC Handelsblad . A more general \npolarized media ecology is also in evidence. On YouTube an alternative media \nsphere has formed, where extreme YouTubers, or micro-celebrities, hold \nsway. Instagram also has a new-right, alternative media space, analytically \ndetected through shared followers of politicians at the far end of the political \nspectrum and hyperpartisan media organizations. These are largely \u2018alt lite\u2019, \nmeaning anti-establishment and anti-political correctness, with content \nthat also could be considered anti-Islam. There are no discernible left-wing equivalents. Rather, these spaces compete with more mainstream ones.\ncon clu Sion S 249\nIn contrast to the situation in other countries during the European Par -\nliamentary elections, in our study we did not find foreign disinformation \nbut rather so-called junk news, especially around particular issues, such \nas Zwarte Piet, MH17, climate and the European Union (Peel, 2019). We \nalso found it around the topic of \u2018fake news\u2019, studied in this instance as a \nsocial issue. Although decent quantities of junk news were in evidence, \nmainstream news largely outperformed it. The largest quantities of junk \nnews circulated not so much around political parties and leaders (with \nsome exceptions), but around specific polarizing issues. Junk news activity \naround these issues sometimes appeared during the election periods, but \nfor other issues there was year-round activity, even for such seasonal issues \nas Zwarte Piet. Thus, the question is not only whether there is junk news \naround election time, but also more generally when it manifests itself, and \nwith which intensity and duration.\nThe following policy implications of our work are directed specifically \nat the phenomenon of junk news, rather than at foreign disinformation \nand fake news from organizations feigning to be news organizations or \nfake advocacy groups, of which we found none, at least in the top or most \nengaged-with content related to Dutch politics across the web and social \nmedia platforms. Our recommendations concern the recognition and \nmonitoring of the polarization of the media landscape, the devitalization \nor disengagement with extreme content, a national conversation about issues \nthat appear frequently in junk news (such as Zwarte Piet) rather than one \nabout disinformation or fake news generally, training for professionals that \nproduce online content, and enabling access to the (increasingly inaccessible) \ndata on social media platforms for research and media monitoring.\nPolicy themes in brief\n1) T he monitoring of the polarization of the media landscape, and the \nmainstreaming of polarizing media with extreme content on social \nmedia platforms.\nSocial media platforms rely on software, their users as well as content \nreviewers to detect extreme content. More and more of it is subsequently \nremoved. But historically the attention paid by social media companies \nto extreme content has been uneven, and definitions unstable. It thereby \nremains desirable to institute independent monitoring. Such work could \nbe taken up by academic researchers, non-governmental organizations, \n250  R icha Rd R oge R S  and Sabine ni ede ReR \ngovernmental agencies specialized in extremism and polarization as well \nas media watchdogs.\n2) M edia training for professional content makers \u2013 from journalists to \ndigital media producers \u2013 concerning online source criticism as well \nas amplification or \u2018oxygen-giving\u2019 of extreme speech actors in society.\nThe Netherlands has existing media literacy training programs, designed for \nexample for senior citizens as well as primary and secondary school students. \nThis recommendation is made specifically for professional content-makers \nsuch as journalists and editors. It could be made a part of existing or new media literacy programs dedicated to online source criticism and dealing \nwith polarizing content (see also point three below). Such a training program \nis also of use to lecturers in higher education, policymakers and civil society.\n3) N o oxygen-giving to extreme actors and their (online) content by media \norganizations.\nIn our study we found that tendentious news stories circulate well during \nthe election campaign periods and beyond. The articles are shared and liked \nby troll-like users but also by regular news consumers, which we found for \nexample on Twitter during the Provincial elections. In the same spaces we \nalso found users sharing and liking discriminatory, anti-Semitic, misogynist \nand xenophobic content, albeit it to a lesser degree.\nIt is important not to equate tendentious and extreme media, even when \nthey appear to share standpoints without using the same words. Similarly, \nthat tendentious media is on the rise and mainstreaming does not mean \nthat similar weight should be given to extreme media. The recommenda -\ntion is that no oxygen should be given to extreme media sources and their content, meaning no sharing, liking, reacting, commenting, retweeting or \nYouTube-debating. Any form of engagement with such content increases \nthe attention and the metrics and contributes to its spread, ranking and \nnormalization. Such a recommendation goes for public broadcasting and \ncommercial media organizations, but also for the tendentious media. Instead \nof journalists\u2019 writing about far-right subcultures, attention could be spent \non their victims (Philips, 2018).\n4) R ecognition of polarizing issues such as Zwarte Piet and the facilitation \nof national and regional conversations.\ncon clu Sion S 251\nThe research found that attention to polarizing issues such as Zwarte Piet is \nyear-round rather than seasonal. Such recognition of increasing polarization \nin society should lead to discussions about how common ground may be \nfound. The Netherlands has a tradition of collective discussion concerning \nmajor societal issues through such mechanisms as the Brede Maatschap -\npelijke Debat (society-wide debate) and interactive policy making. There are \nother contemporary forms of citizen participation and discussion that could \nbe instrumental in dealing with polarizing issues and cultural contestation. \nInstitutions experienced in organizing societal discussion and debate should \nbe called upon and supported to do so, and bottom-up initiatives should \nbe facilitated.\n5)\n A\ndvocacy for social media data access for researchers, journalists and \nwatchdogs, and creation of research archives of deleted content.\nThe current issue of \u2018locked platforms\u2019 concerns the extent to which social \nmedia companies are making their data inaccessible to researchers, journal-\nists and non-governmental organizations. As an answer to governmental \nconcern about \u2018dark political posts\u2019 (political ads directed only at a segment \nof users in their newsfeeds) and other political ads without clear provenance, \nFacebook has launched a political ad archive tool and API. But at the same \ntime Facebook has removed in part or in whole access to services such as \nthe Pages API and Graph Search, which had been in widespread use by \nresearchers. Social media companies should take up the task of making \navailable the data that researchers, journalists and non-governmental \norganizations would like to use for the purposes of research, monitoring \nand archiving. Governmental agencies, in consultation with the users and \nuse types mentioned above, have a facilitative as well as a regulatory role \nto play here.\nReferences\nCarlson, Matt (2018) \u2018Fake news as an informational moral panic: the symbolic \ndeviancy of social media during the 2016 US presidential election\u2019, Information, \nCommunication & Society , DOI: 10.1080/1369118X.2018.1505934, published online \non August\u00a01.\nCohen, Stanley (1972) Folk Devils and Moral Panics . London: Routledge.\nHirst, Martin (2017) \u2018Towards a political economy of fake news\u2019, The Political Economy \nof Communication  5(2), 82-94.\n252  R icha Rd R oge R S  and Sabine ni ede ReR \nMorozov, Evgeny (2017) \u2018Moral panic over fake news hides the real enemy \u2013 the \ndigital giants\u2019, The Guardian , 8\u00a0January.\nPeel, Michael (2019) \u2018EU election suffered Russian disinformation, Brussels finds\u2019, \nFinancial Times , 14\u00a0June.\nPhillips, Whitney (2018) \u2018The Oxygen of Amplification: Better Practices for Reporting \non Extremists, Antagonists and Manipulators Online\u2019, Report, New York: Data \n& Society Research Institute.\nAbout the authors\nRichard Rogers  is Professor of New Media & Digital Culture at the Univer -\nsity of Amsterdam and Director of the Digital Methods Initiative, the group \nresponsible for social media research tools. Among other works, Rogers is \nauthor of Information Politics on the Web  (MIT Press, 2004), Digital Methods  \n(MIT Press, 2013), and Doing Digital Methods (Sage, 2019).\nSabine Niederer  is Professor of Visual Methodologies at the Amsterdam \nUniversity of Applied Sciences. Her research focuses on the cartography \nof issues and online debates through visual and digital methods, with a \nparticular interest in climate-related issues. In 2014, Niederer founded the \nCitizen Data Lab as an applied research lab specializing in participatory \nmapping of local issues.\n9 Epilogue\nAfter the tweet storm\nRichard Rogers and Sal Hagen\nAbstract\nThe publication of the study elicited reactions, especially on Twitter, where \nquestions arose about the use of the notion of junk news, rather than \u2018pulp \nnews\u2019, among other points. The analogy to junk food is emphasised. There \nwas also the question of symmetry, and the treatment of both ends of the \npolitical spectrum. Why is the new populist right identified as the pur -\nveyors of extreme content? We found a polarised Dutch media landscape \nwhere hyperpartisan (and to a lesser extent conspiracy) content from new \npopulist right (rather than the left or other orientations) circulates well \non social media. Unlike in the US during the initial Trump insurgency, \nmainstream news in the Netherlands still outperforms what was hitherto \nknown as \u2018fake news\u2019, across all platforms.\nKeywords:  Twitter, new populist right, junk news, mainstream news, \nDutch media landscape\nIn line with the theme of our study, \u2018The Politics of Social Media Manipula -\ntion\u2019, commissioned by the Ministry of Internal Affairs and published in \nOctober\u00a02019, most of the attention it has garnered since has been on social \nmedia rather than in the press. One reason is our report into so-called fake \nnews and disinformation, was published on a Friday afternoon prior to the \nOctober holiday break. It also contains no scintillating findings concern -\ning (Russian or foreign) disinformation campaigning in the Netherlands; \nduring the run up to the two elections in 2019 no disinformation, front \ngroups or fake news sources were found whose stories were circulating on \nFacebook, Instagram, Twitter, Google Web Search, YouTube, Reddit or 4chan, \nthe multiple platforms under study. Since there was no disinformation in \nRogers, Richard, and Sabine Niederer (eds), The Politics of Social Media Manipulation . Amsterdam, \nAmsterdam University Press 2020\ndoi: 10.5117/9789463724838 _ch09\n254  R icha Rd  Roge R S an d Sal h agen \ncirculation, at least not any that Facebook and other social media users \nengaged with in any significant degree, could the \u2018Echt?!\u2019 fake news public \nawareness campaign the Ministry ran be considered tilting at windmills? Is \nthe study and monitoring of fake news and disinformation in the Netherlands \na worthwhile endeavour, given that to date hardly any has been found?\nThese are some of the questions that have arisen in the one space where \nthere has been considerable commentary on the study, Twitter. The reason \nis that the report found the rise of a growing alternative, new right media \nsphere in the Netherlands, without an equivalent on the left, which also \nmanifests itself on Twitter. This media sphere contains stories (and sources) \nthat are hyperpartisan, conspiracy-related and/or clickbait, which the \nstudy collectively defines as \u2018junk news\u2019, employing a term used by Oxford \nUniversity researchers characterizing similar sources elsewhere. Junk \nnews shares commonalities with junk food, in that it contains attractively \npackaged stories, of a low journalistic standard, that we know we probably \nshould not consume, such as sensationalist clickbait, headlines and teaser \ntexts designed to be clicked rather than actually read.\nEspecially on Facebook a great deal of such material circulated prior to the \nelections, and was liked or shared, tallying high engagement scores. Through \nthe circulation of their stories on Facebook, particularly hyperpartisan \nsites, defined as \u2018openly ideological web operations\u2019, are on the rise in the \nNetherlands, certainly compared to the results of a smaller study published \nin the NRC Handelsblad  on political stories that circulated on Facebook \nprior to the 2017 national elections, when there were relatively few. For \nexample, the hyperpartisan site, De Dagelijkse Standaard , received more \nattention during both 2019 election periods than the mainstream media \nsites, RTL Nieuws and NU.nl. Openly extreme sites such as Fenixx  nearly had \nthe same engagement on Facebook for political news stories as the quality \nnewspaper, the NRC Handelsblad . Hyperpartisan, left-wing sites with similar \nengagement scores were hardly in evidence. It should be pointed out that \nmainstream news, in total, still outperforms alternative, new-right (or, using \nthe terminology of political scientist, Cas Mudde, \u2018populist radical right\u2019) \nsources for election-related subjects (Bahara, 2019), but not for every issue and not for every election period under study. For example, we found that \nwhilst political issues, parties and leaders may wax and wane, there are \nparticular issues in this alternative media sphere that are hot year-round, \nsuch as Zwarte Piet, climate change and the European Union itself. Both the \nhigh engagement scores for hyperpartisan content as well as the unceasing \nattention to divisive issues by the alternative media sphere could be viewed \nas indications of societal unrest.\nePi logue  255\nSocial media such as Twitter and the online comment space more broadly \ndefined are sometimes described as increasingly toxic, and commentators as \nmore and more uninhibited; indeed, hundreds of the online reactions to our \nstudy could be characterized as such. We also found, in the reactions, that \nthere are (albeit very few) users who behave troll-like, active across divisive \nissues and ever-targeting politicians, and are actually battling misinformation.\nIn the recommendations of the report, which we entitled \u2018the mainstream \nunder fire\u2019, we called for the (academic, non-governmental) monitoring of the \ngrowing polarization in the country that we identified in the rise of new-right \nalternative media. We also believe that continued study of the mainstreaming \nof hyperpartisan and extreme content remains important here, even if it \nis not the product of organized influence campaigning by foreign actors. \nFor example, certain Dutch hyperpartisan sources are actively seeking to \nmainstream by adding newswire stories to supplement the pages of their \notherwise fervent commentary. Through the circulation on Facebook and \nother social media as well as its large-scale engagement through likes and \nshares, certain extreme content also is gaining more exposure. We recommend \nthat these stories, whether brought together with actual news or otherwise shared even if in gest, should not be given so much oxygen. Right-of-centre, \nself-described tendentious media sources but also other mainstream and \ntransgressive media should consider refraining from rebroadcasting extreme \ncontent. Finally, we note that Facebook (and Instagram) have ceased allowing \nresearcher access to its (API page) data, making such studies as ours increas -\ningly arduous to undertake. Considering the important cultural and societal \nstakes, we need to be able to study Facebook and other social media platform \ndata to understand the nature and scale of the problem now and in future.\nReferences\nBahara, Hassan (2019) \u2018Politicoloog Cas Mudde waarschuwt voor de normalisering \nvan radicaal rechts\u2019, de Volkskrant , 15\u00a0November. https://www.volkskrant.nl/\nnieuws-achtergrond/politicoloog-cas-mudde-waarschuwt-voor-het-normal -\niseren-van-radicaal-rechts~b33b602e/\nAbout the authors\nRichard Rogers  is Professor of New Media & Digital Culture at the Univer -\nsity of Amsterdam and Director of the Digital Methods Initiative, the group \n256  R icha Rd  Roge R S an d Sal h agen \nresponsible for social media research tools. Among other works, Rogers is \nauthor of Information Politics on the Web  (MIT Press, 2004), Digital Methods  \n(MIT Press, 2013), and Doing Digital Methods (Sage, 2019).\nSal Hagen  is a Ph.D. candidate at the University of Amsterdam and co-\nfounder of OILab. His research focuses on anonymous and pseudonymous \nonline subcultures and their political engagements. Methodologically, his \nwork combines media theory with data-driven methods.\n References\nAbbruzzese, Jason (2018) \u2018Facebook Became Your News Diet. Now, It\u2019s Going to \nServe You Junk\u2019, Mashable , 17\u00a0January, https://mashable.com/2018/01/17/facebook-\nnews-readers/ (accessed 1\u00a0April\u00a02020).\nAbrams, Sam (2016) \u2018Professors Moved Left Since 1990s, Rest of Country Did Not\u2019, \nHeterodox Academy , January\u00a09, https://heterodoxacademy.org/professors-moved-\nleft-but-country-did-not/ (accessed 1\u00a0April\u00a02020).\nAccess Now, Civil Liberties Union For Europe, and European Digital Rights (2018) \nInforming the \u2018Disinformation\u2019 Debate , Report, Published online on October\u00a018, \nhttps://edri.org/files/online_disinformation.pdf (accessed 1\u00a0April\u00a02020).\nAlbright, Jonathan (2017) \u2018Itemized Posts and Historical Engagement \u2013 6 Now-Closed \nFB Pages\u2019, Data set, Tableau Public , 5\u00a0October, https://public.tableau.com/profile/\nd1gi#!/vizhome/FB4/TotalReachbyPage (accessed 1\u00a0April\u00a02020).\n\u2014 (2016) \u2018The #Election2016 Micro-Propaganda Machine\u2019, Medium , 18\u00a0November, \nhttps://medium.com/@d1gi/the-election2016-micro-propaganda-machine-\n383449cc1fba (accessed 1\u00a0April\u00a02020).\nAlexander, Julia (2017) \u2018Reddit\u2019s New Policy Won\u2019t Affect Some of Its Most Notori -\nous, Hate-Filled Subreddits\u2019, Polygon blog , 2\u00a0November, https://www.polygon.\ncom/2017/11/2/16591508/reddit-content-policy-update-subreddit-ban-the-donald-\nkia (accessed 1\u00a0April\u00a02020)\nAllcott, Hunt and Matthew Gentzkow (2017) \u2018Social Media and Fake News in \nthe 2016 Election\u2019, Journal of Economic Perspectives , 31(2): 211-236, https://doi.\norg/10.1257/jep.31.2.211.\nAlvarez, R. Michael, Ines Levin, Alexander H. Trechsel and Kristjan Vassil (2014) \n\u2018Voting Advice Applications: How Useful and for Whom?\u2019, Journal of Information \nTechnology & Politics , 11(1): 82-101, DOI: 10.1080/19331681.2013.873361.\nAngwin, Julia, Madeleine Varner and Ariana Tobin (2017) \u2018Facebook Enabled \nAdvertisers to Reach \u201cJew Haters\u201d\u2019, ProPublica , 14\u00a0September, https://www.\npropublica.org/article/facebook-enabled-advertisers-to-reach-jew-haters (ac -\ncessed 1\u00a0April\u00a02020).\nAydemir, Murat (2011) \u2018Dutch Homonationalism and Intersectionality\u2019, ARC-\nGS Lecture, University of Amsterdam, 15\u00a0April, https://arcgs.uva.nl/videos/\nvideo-artikelen/dutch-homonationalism-and-intersectionality.html (accessed \n1\u00a0April\u00a02020).\nBahara, Hassan (2019) \u2018Politicoloog Cas Mudde waarschuwt voor de normalisering \nvan radicaal rechts\u2019, de Volkskrant , 15 November. https://www.volkskrant.nl/\nnieuws-achtergrond/politicoloog-cas-mudde-waarschuwt-voor-het-normal -\niseren-van-radicaal-rechts~b33b602e/\n258  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nBahara, Hassan, Annieke Kranenberg and Dimitri Tokmetzis (2019) \u2018Leidt het \nalgoritme van YouTube je naar extreme content?\u2019, de Volkskrant , February\u00a011, \nhttps://www.volkskrant.nl/nieuws-achtergrond/leidt-  het-algoritme-van-\nyoutube-je-naar-extreme-content~bea101e3/ (accessed 1\u00a0April\u00a02020).\nBarbrook, Richard (1998) \u2018The Hi-Tech Gift Economy\u2019, First Monday , 3(12), https://\ndoi.org/10.5210/fm.v3i12.631.\nBastian M., Heymann S., Jacomy M. (2009) \u2018Gephi: An Open Source Software for \nExploring and Manipulating Networks\u2019, International AAAI Conference on \nWeblogs and Social Media, https://www.aaai.org/ocs/index.php/ICWSM/09/\npaper/view/154 (accessed 1\u00a0April\u00a02020).\nBaumgartner, Jason (2018) \u2018Pushshift API (Version 1.0)\u2019, API Documentation, \nPushshift, https://pushshift.io/api-parameters/ (accessed 1\u00a0April\u00a02020).\nBeiler, Markus and Johanna Kiesler (2018) \u2018\u201cL u\u0308g enpresse! Lying Press!\u201d Is the Press \nLying?\u2019, in Otto, Kim and Andreas K\u00f6hler (eds.) Trust in Media and Journalism , \nWiesbaden: Springer, 155-179.\nBelk, Russell (2007) \u2018Why Not Share Rather Than Own?\u2019, The ANNALS of the \nAmerican Academy of Political and Social Science , 611: 126-140, https://doi.\norg/10.1177/0002716206298483\nBell, Emily and Taylor Owen (2017) \u2018The Platform Press\u2019, Report, Columbia University: \nTow Center for Journalism, https://www.cjr.org/tow_center_reports/platform-\npress-how-silicon-valley-reengineered-journalism.php (accessed 1\u00a0April\u00a02020).\nBellingcat Investigation Team (2016) \u2018Behind the Dutch Terror Threat Video: The \nSt. Petersburg \u201cTroll Factory\u201d Connection\u2019, Bellingcat , 3\u00a0April, https://www.bell -\ningcat.com/news/uk-and-europe/2016/04/03/azov-video/ (accessed 1\u00a0April\u00a02020).\nBenkler, Yochai, Robert Faris, Hal Roberts, and Ethan Zuckerman (2017) \u2018Study: \nBreitbart-Led Right-Wing Media Ecosystem Altered Broader Media Agenda\u2019, \nColumbia Journalism Review , 3\u00a0March, https://www.cjr.org/analysis/breitbart-\nmedia-trump-harvard-study.php (accessed 1\u00a0April\u00a02020).\nBenkler, Yochai, Robert Faris and Hal Roberts (2018) Network Propaganda: Manipula -\ntion, Disinformation, and Radicalization in American Politics , Oxford: Oxford \nUniversity Press.\nBerg, Kati Tusinski (2017) \u2018Social Media, Hashtag Hijacking, and the Evolution of \nan Activist Group Strategy,\u2019 in Lucinda Austin and Yan Jin (eds.), Social media \nand crisis communication , London: Routledge, pp.\u00a0141-156.\nBergstrom, Kelly (2011) \u2018\u201cDon\u2019t Feed the Troll\u201d: Shutting Down Debate about Com-\nmunity Expectations on Reddit.Com\u2019, First Monday , 16(8), https://doi.org/10.5210/\nfm.v16i8.3498.\nBessi, Alessandro and Emilio Ferrara (2016) \u2018Social Bots Distort the 2016 US Presi -\ndential Election Online Discussion\u2019, First Monday , 21(11), https://firstmonday.\norg/article/view/7090/5653 (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 259\n\u2014, Fabiana Zollo, Michela Del Vicario, Michelangelo Puliga, Antonio Scala, Guido \nCaldarelli, Brian Uzzi, Walter Quattrociocchi (2016) \u2018Users Polarization on \nFacebook and Youtube\u2019, PLoS ONE , 11(8): 1-13. Accessed April\u00a01, 2020, https://doi.\norg/10.1371/journal.pone.0159641.\nBoczkowski, Pablo (2016) \u2018Fake News and the Future of Journalism\u2019, NiemanLab , \nDecember, https://www.niemanlab.org/2016/12/fake-news-and-the-future-of-\njournalism/ (accessed 1\u00a0April\u00a02020).\nBoghardt, Thomas (2009) \u2018Soviet Bloc Intelligence and Its AIDS Disinformation \nCampaign\u2019, Studies in Intelligence , 53(4): 1-24.\nBorra, Erik (2013) \u2018DMI Tools\u2019, wiki, https://wiki.digitalmethods.net/Dmi/ToolDa -\ntabase (accessed 1\u00a0April\u00a02020).\n\u2014 and Bernhard Rieder (2014) \u2018Programmed Method: Developing a Toolset for \nCapturing and Analyzing Tweets\u2019, Aslib Journal of Information Management , \n66(3): 262-278, https://doi.org/10.1108/AJIM-09-2013-0094.\n\u2014, Sabine Niederer, Johannes Preu\u00df and Esther Weltevrede (2017) \u2018Mapping Troll-\nlike Practices on Twitter\u2019, in Liliana Bounegru, Jonathan Gray, Tomasso Venturini \nand Michele Mauri (eds.), A Field Guide to \u2018Fake News\u2019 and Other Information \nDisorders , Amsterdam: Public Data Lab, pp.\u00a0161-196.\nBos, Menno van den (2018) \u2018Nee, jij bent een cultuurrelativist! Hoe academische \nbegrippen strijdwapens werden\u2019, Vrij Nederland , 12\u00a0December, https://www.vn.nl/\nidentiteitspolitiek-cultuurmarxisme-intersectionaliteit/ (accessed 1\u00a0April\u00a02020).\nBounegru, Liliana, Jonathan Gray, Tommaso Venturini and Michele Mauri (eds.) \n(2018) A Field Guide to \u2018Fake News\u2019 and Other Information Disorders . Amsterdam: \nPublic Data Lab.\nBowden, Ian (2016) \u2018How Google is Tackling Fake News, and Why It Should Not \nDo It Alone,\u2019 Search Engine Land , 30\u00a0November, https://searchengineland.com/\ngoogle-tackling-fake-news-not-alone-264058 (accessed 1\u00a0April\u00a02020).\nboyd, danah (2017) \u2018Did Media Literacy Backfire?\u2019, Points blog , Data & Society, 5\u00a0Janu -\nary, https://points.datasociety.net/did-media-literacy-backfire-7418c084d88d \n(accessed 1\u00a0April\u00a02020).\n\u2014, Scott Golder and Gilad Lotan (2010) \u2018Tweet, Tweet, Retweet: Conversational Aspects \nof Retweeting on Twitter\u2019, Proceedings of 43rd Hawaii International Conference on \nSystem Sciences,  Honolulu, HI: IEEE, January, pp.\u00a01-10, DOI: 10.1109/HICSS.2010.412.\nBoyd, Ryan, Alexander Spangher, Adam Fourney, Besmira Nushi, Gireeja Ranade, \nJames Pennebaker and Eric Horvitz (2018) \u2018Characterizing the Internet Research \nAgency\u2019s Social Media Operations During the 2016 U.S. Presidential Election \nUsing Linguistic Analyses\u2019, DataCite, DOI:10.31234/osf.io/ajh2q.\nBradshaw, Samantha (2018) \u2018Responding to Fake News Through Regulation and \nAutomation\u2019, Report, London: Carter-Ruck, https://www.carter-ruck.com/images/\nuploads/documents/RESPONDING_TO_FAKE_NEWS.pdf (accessed 1\u00a0April\u00a02020).\n260  T he Poli Ti cS  of  Social Media Mani Pu laTi on\n\u2014 and Phillip N. Howard (2018) \u2018Challenging Truth and Trust: A Global Inventory \nof Organized Social Media Manipulation\u2019, Computational Propaganda Data \nMemo, Oxford: Oxford Internet Institute, https://comprop.oii.ox.ac.uk/research/\ncybertroops2018/(accessed 1\u00a0April\u00a02020).\nBrattberg, Erik and Tim Mauer (2018) \u2018Russian Election Interference: Europe\u2019s \nCounter to Fake News and Cyber Attacks\u2019, White Paper, Washington, DC: Car -\nnegie Endowment for International Peace, May, https://carnegieendowment.\norg/2018/05/23/russian-election-interference-europe-s-counter-to-fake-news-\nand-cyber-attacks-pub-76435 (accessed 1\u00a0April\u00a02020).\nBrennen, Bonnie (2017) \u2018Making Sense of Lies, Deceptive Propaganda, and Fake News\u2019, \nJournal of Media Ethics , 32(3): 179-181, https://doi.org/10.1080/23736992.2017.1331023.\nBroderick, Ryan and Jules Darmanin (2018) \u2018The \u201cYellow Vest\u201d Riots in France \nAre What Happens When Facebook Gets Involved With Local News\u2019, Buzzfeed \nNews , 6\u00a0December, https://www.buzzfeednews.com/article/ryanhatesthis/\nfrance-paris-yellow-jackets-facebook (accessed 1\u00a0April\u00a02020).\nBruns, Axel, Anja Bechmann, Jean Burgess et al. (2018) \u2018Facebook Shuts the Gate after \nthe Horse Has Bolted, and Hurts Real Research in the Process\u2019, Internet Policy \nReview , 25\u00a0April, https://policyreview.info/articles/news/facebook-shuts-gate-after-\nhorse-has-bolted-and-hurts-real-research-process/786 (accessed 1\u00a0April\u00a02020).\nBump, Philip (2017) \u2018The Investigation Goes Digital: Did Someone Point Russia to \nSpecific Online Targets?\u2019 Washington Post , 12\u00a0July, https://www.washingtonpost.\ncom/news/politics/wp/2017/07/12/the-investigation-goes-digital-did-someone-\npoint-russia-to-specific-online-targets/ (accessed 1\u00a0April\u00a02020).\nBurger, Peter (2016) \u2018Moslims vernielen kerstmarkt in Litouwen? Nee: rellen in de VS\u2019, \nDe Gestolen Grootmoeder blog, 14\u00a0December, http://www.gestolengrootmoeder.\nnl/wordpress/moslims-vernielen-kerstmarkt-in-litouwen-nee-rellen-in-de-vs/ \n(accessed 1\u00a0April\u00a02020).\n\u2014, Soeradj Kanhai, Alexander Pleijter, and Suzan Verberne (2019) \u2018The Reach \nof Commercially Motivated Junk News on Facebook\u2019. ArXiv:1901.07290 [Cs] , \n22\u00a0January. http://arxiv.org/abs/1901.07290.\nButac, Maicolengel (2018) \u2018The Reuters Institute for the Study of Journalism vs. Fake \nNews\u2019, BUTAC blog, 8\u00a0February, https://www.butac.it/the-reuters-institute-for-\nthe-study-of-journalism-vs-the-fake-news/ (accessed 1\u00a0April\u00a02020).\nCadwalladr, Carole and Emma Graham-Harrison (2018) \u2018Revealed: 50 Million \nFacebook Profiles Harvested for Cambridge Analytica in Major Data Breach\u2019, \nThe Guardian , 17\u00a0March, https://www.theguardian.com/news/2018/mar/17/\ncambridge-analytica-facebook-influence-us-election (accessed 1\u00a0April\u00a02020).\n\u2014 (2016) \u2018Google, Democracy and the Truth about Internet Search\u2019, The Guardian , \n4\u00a0December, https://www.theguardian.com/technology/2016/dec/04/google-\ndemocracy-truth-internet-search-facebook (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 261\nCanadian Security Intelligence Service (2018) \u2018Who Said What? The Security Chal -\nlenges of Modern Disinformation\u2019, World Watch: Expert Notes series publication \n(No.\u00a02016-12-05), Canada: Canadian Security Intelligence Service.\nCarlson, Matt (2018) \u2018Fake News as an Informational Moral Panic: The Sym -\nbolic Deviancy of Social Media During the 2016 US Presidential Election\u2019, \nInformation, Communication & Society , published online on August\u00a01, DOI: \n10.1080/1369118X.2018.1505934.\nCary, Stephen G. (1955) Speak Truth to Power: A Quaker Search for an Alternative to \nViolence . Philadelphia: American Friends Service Committee.\nChadwick, Andrew (2013) The Hybrid Media System: Politics and Power . Oxford: \nOxford University Press.\nChen, Adrian (2015) \u2018The Agency\u2019, The New York Times , 2\u00a0June, https://www.nytimes.\ncom/2015/06/07/magazine/the-agency.html (accessed 1\u00a0April\u00a02020).\nClaussen, Victor (2018) \u2018Fighting Hate Speech and Fake News. The Network Enforce -\nment Act (NetzDG) in Germany in the Context of European Legislation\u2019, Media \nLaws  3, published online October\u00a014, http://www.medialaws.eu/wp-content/\nuploads/2019/05/6.-Claussen.pdf (accessed 1\u00a0April\u00a02020).\nCohen, Stanley (1972) Folk Devils and Moral Panics . London: Routledge.\nColbert Report (2005) \u2018The W\u00d8RD \u201cTruthiness\u201d\u2019, Comedy Central , 17\u00a0October.\nCollins, Ben and John Russell (2018) \u2018Russians Used Reddit and Tumblr to Troll the \n2016 Election\u2019, The Daily Beast , 2\u00a0March, https://www.thedailybeast.com/russians-\nused-reddit-and-tumblr-to-troll-the-2016-election (accessed 1\u00a0April\u00a02020).\nCollins, Keith and Sheera Frenkel (2018) \u2018Can You Spot the Deceptive Facebook Post?\u2019 \nNew York Times , 4\u00a0September, https://www.nytimes.com/interactive/2018/09/04/\ntechnology/facebook-influence-campaigns-quiz.html (accessed 1\u00a0April\u00a02020).\nConfessore, Nicholas and Daisuke Wakabayashi (2017) \u2018How Russia Harvested \nAmerican Rage to Reshape U.S. Politics\u2019, New York Times , 9\u00a0October, https://\nwww.nytimes.com/2017/10/09/technology/russia-election-facebook-ads-rage.\nhtml (accessed 1\u00a0April\u00a02020).\nCovington, Paul, Jay Adams, and Emre Sargin (2016) \u2018Deep Neural Networks for You -\nTube Recommendations\u2019, Proceedings of the 10th ACM Conference on Recommender \nSystems , New York, NY: ACM, pp.\u00a0191-198, https://doi.org/10.1145/2959100.2959190.\nDahlgren, Kristen and Daniel Arkin (2017) \u201811-Year-Old Texas Boy Invents Device \nto Prevent Hot Car Deaths\u2019, NBC News , 29\u00a0June, https://www.nbcnews.com/\nstoryline/hot-cars-and-kids/11-year-old-texas-boy-invents-device-prevent-hot-\ncar-n777876 (accessed 1\u00a0April\u00a02020).\nDan, Ovidiu and Brian D. Davison (2016) \u2018Measuring and Predicting Search Engine \nUsers\u2019 Satisfaction\u2019, ACM Computing Surveys , 49(1), art.\u00a018.\nDaniels, Jessie (2018) \u2018The Algorithmic Rise of the Alt-right\u2019, Contexts , 17(1): 60-65, \nhttps://doi.org/10.1177/1536504218766547.\n262  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nDarnton, Robert (2010) Poetry and the Police: Communication Networks in Eighteenth-\nCentury Paris . Cambridge, MA: Harvard University Press.\n\u2014 (2017) \u2018The True History of Fake News\u2019, New York Review of Books , 13\u00a0February, \nhttps://www.nybooks.com/daily/2017/02/13/the-true-history-of-fake-news/ \n(accessed 1\u00a0April\u00a02020).\nDay, Amber and Ethan Thompson (2012) \u2018Live from New York, It\u2019s the Fake News! \nSaturday Night Live and the (Non)politics of Parody,\u2019 Popular Communication  \n10(1-2): 170-182, https://doi.org/10.1080/15405702.2012.638582.\nDeAmicis, Carmel (2014) \u2018Facebook Shifts its Algorithm to Fight Clickbait. Will it \nKill off Upworthy and Buzzfeed?\u2019, GIGAOM , Austin: Giga Omni Media, https://\ngigaom.com/2014/08/25/facebook-shifts-its-algorithm-to-fight-clickbait-will-\nit-kill-off-upworthy-and-buzzfeed/ (accessed 1\u00a0April\u00a02020).\nDe Hoax-Wijzer (n.d.) \u2018Valse Nieuwssites\u2019, https://sites.google.com/site/dehoaxwi -\njzer/valse-nieuwssites (accessed 1\u00a0April\u00a02020).\nDigital Methods Initiative (2015) \u2018Instagram scraper\u2019, https://wiki.digitalmethods.\nnet/Dmi/ToolInstagramScraper (accessed 1\u00a0April\u00a02020).\nDiResta, Renee, Kris Shaffer, Becky Ruppel, et al. (2018) \u2018The Tactics & Tropes of \nthe Internet Research Agency\u2019, Report, New Knowledge, https://disinforma -\ntionreport.blob.core.windows.net/disinformation-report/NewKnowledge-\nDisinformation-Report-Whitepaper.pdf (accessed 1\u00a0April\u00a02020).\nDrewe, Nick (2016) \u2018The Hilarious List of Hashtags Instagram Won\u2019t Let You Search\u2019, \nThe Data Pack , 10\u00a0May, http://thedatapack.com/banned-instagram-hashtags-\nupdate/ (accessed 1\u00a0April\u00a02020).\nDrog (2018) \u2018Slecht Nieuws: Serious game over propaganda\u2019, Website, https://www.\nslechtnieuws.nl/ (accessed 1\u00a0April\u00a02020).\nDuke Reporters Lab (2019) \u2018Fact Checking News\u2019, website, https://reporterslab.org/\nfact-checking/ (accessed 1\u00a0April\u00a02020).\nDumont, P. and Kies, R. (2012) \u2018Smartvote.lu: Usage and impact of the First VAA \nin Luxembourg\u2019, International Journal of Electronic Governance  5(3/4): 388-410, \nhttp://hdl.handle.net/10993/21881 (accessed 1\u00a0April\u00a02020).\nDupuy, Lisa (2018) \u2018GeenStijl staat niet meer op EU-lijst nepnieuws\u2019, NRC Handels -\nblad , 29\u00a0January, https://www.nrc.nl/nieuws/2018/01/29/geenstijl-staat-niet-\nmeer-op-eu-lijst-nepnieuws-a1590216 (accessed 1\u00a0April\u00a02020).\nEdelman (2018) \u20182018 Edelman Trust Barometer\u2019, Report, https://www.edelman.com/\nsites/g/files/aatuss191/files/2018-10/Edelman_Trust_Barometer_Employee_Ex -\nperience_2018_0.pdf (accessed 1\u00a0April\u00a02020).\nEllick, Adam B. and Adam Westbrook (2018) \u2018Operation Infektion\u2019, New York Times , \n12\u00a0November, https://www.nytimes.com/2018/11/12/opinion/russia-meddling-\ndisinformation-fake-news-elections.html (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 263\nEU HLEG (2018) A Multi-dimensional Approach to Disinformation , Report of the \nIndependent High-level Group on Fake News and Online Disinformation, \nLuxembourg: Publications Office of the European Union, http://ec.europa.eu/\nnewsroom/dae/document.cfm?doc_id=50271(accessed 1\u00a0April\u00a02020).\nEU vs Disinfo (2017) \u2018Sputnik\u2019s Short-Lived Presence in the Slovak Press Agency\u2019, \nEU vs Disinfo  blog, 1\u00a0April, https://euvsdisinfo.eu/sputniks-short-lived-presence-\nin-the-slovak-press-agency/ (accessed 1\u00a0April\u00a02020).\nFandos, Nicholas (2017) \u2018White House Pushes \u201cAlternative Facts.\u201d Here Are the \nReal Ones\u2019, New York Times , 22\u00a0January, https://www.nytimes.com/2017/01/22/\nus/politics/president-trump-inauguration-crowd-white-house.html (accessed \n1\u00a0April\u00a02020).\nFaris, Robert M., Hal Roberts, Bruce Etling, Nikki Bourassa, Ethan Zuckerman, and \nYochai Benkler (2017) \u2018Partisanship, Propaganda, and Disinformation: Online \nMedia and the 2016 U.S. Presidential Election\u2019, Berkman Klein Center for Internet \n& Society Research Paper, https:/ /cyber.harvard.edu/publications/2017/08/\nmediacloud (accessed 1\u00a0April\u00a02020).\nFarkas, Johan and Marco Bastos (2018) \u2018IRA Propaganda on Twitter: Stoking \nAntagonism and Tweeting Local News\u2019, SMSociety \u201818, Copenhagen, DOI: \n10.1145/3217804.3217929.\nFeldman, Brian (2017) \u2018In Russia, You Can Buy Instagram Likes From a Vending \nMachine\u2019, N ew York Magazine , 8\u00a0June, https://nymag.com/intelligencer/2017/06/\nyou-can-buy-instagram-likes-from-a-russian-vending-machine.html (accessed \n1\u00a0April\u00a02020).\nFeuz, Martin, Matthew Fuller, and Felix Stalder (2011) \u2018Personal Web Searching in \nthe Age of Semantic Capitalism: Diagnosing the Mechanisms of Personalisation\u2019, \nFirst Monday 16(2), 7\u00a0February, https://doi.org/10.5210/fm.v16i2.3344.\nFink, Christina (2018) \u2018Dangerous Speech, Anti-Muslim Violence, and Facebook in \nMyanmar\u2019, Journal of International Affairs  71(1.5): 43-52, https://jia.sipa.columbia.\nedu/dangerous-speech-anti-muslim-violence-and-facebook-myanmar (accessed \n1\u00a0April\u00a02020).\nFinkel, Jacob, Steven Jiang, Luo Mufan, Rebecca Mears, Dana\u00eb Metaxa-Kakavouli, \nCamille Peeples, Brendan Sasso, Arjun Shenoy, Vincent Sheu, and Nicol\u00e1s Torres-\nEcheverry (2017) \u2018Fake News and Misinformation: The Roles of the Nation\u2019s Digital \nNewsstands, Facebook, Google, Twitter and Reddit\u2019, Stanford, CA: Stanford \nLaw School, https://www-cdn.law.stanford.edu/wp-content/uploads/2017/10/\nFake-News-Misinformation-FINAL-PDF.pdf (accessed 1\u00a0April\u00a02020).\nFireEye (2018) \u2018Suspected Iranian Influence Operation\u2019, Report, Milpitas, CA: \nFireEye, https://www.fireeye.com/blog/threat-research/2018/08/suspected-\niranian-influence-operation.html (accessed 1\u00a0April\u00a02020).\n264  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nFitts, Alexis Sobel (2017) \u2018Welcome to the Wikipedia of the Alt-right\u2019, Wired , 21\u00a0June, \nhttps://www.wired.com/story/welcome-to-the-wikipedia-of-the-alt-right/ \n(accessed 1\u00a0April\u00a02020).\nFletcher, Richard, Alessio Cornia, Lucas Graves, and Rasmus Kleis Nielsen (2018) \n\u2018Measuring the Reach of \u201cFake News\u201d and Online Disinformation in Europe\u2019, \nReuters Institute for the Study of Journalism, Oxford University, February, https://\nreutersinstitute.politics.ox.ac.uk/sites/default/files/2018-02/Measuring%20\nthe%20reach%20of%20fake%20news%20and%20online%20distribution%20\nin%20Europe%20CORRECT%20FLAG.pdf (accessed 1\u00a0April\u00a02020).\nFlynn, Kerry (2018) \u2018Facebook Will Elevate \u201cTrusted\u201d News Outlets after Surveying \nU.S. Users\u2019, Mashable , 19\u00a0January, https://mashable.com/2018/01/19/facebook-\nnews-feed-trusted-sources-fake-news/?europe=true (accessed 1\u00a0April\u00a02020).\nFoucault, Michel (2008) The Birth of Biopolitics: Lectures at the Coll\u00e8ge De France, \n1978-1979 , New York, NY: Palgrave Macmillan.\nFrenkel, Sheera, Kate Conger and Kevin Roose (2019) \u2018Russia\u2019s Playbook for Social \nMedia Disinformation Has Gone Global\u2019, New York Times , 31\u00a0January, https://\nwww.nytimes.com/2019/01/31/technology/twitter-disinformation-united-states-\nrussia.html (accessed 1\u00a0April\u00a02020).\nFrenkel, Sheera, Nicholas Casey and Paul Mozur (2018) \u2018In Some Countries, Face -\nbook\u2019s Fiddling Has Magnified Fake News\u2019, New York Times , 14\u00a0January, https://\nwww.nytimes.com/2018/01/14/technology/facebook-news-feed-changes.html \n(accessed 1\u00a0April\u00a02020).\nFubini, Federico (2018) \u2018Tweet populisti dalla Russia sulla politica italiana. Come \nnegli Usa\u2019, Corriere della Sera , 1\u00a0August, https://www.corriere.it/politica/18_ago -\nsto_01/tweet-populisti-russia-voto-italiano-come-usa-f33df26c-95cc-11e8-819d-\n89f988769835.shtml (accessed 1\u00a0April\u00a02020).\nGartenberg, Chaim (2018) \u2018Facebook is Going to Start Surveying Users to Deter -\nmine Trustworthy News Sources\u2019, The Verge , 19\u00a0January, https://www.theverge.\ncom/2018/1/19/16911284/facebook-news-sources-trustworthiness-survey-users-\nnews-feed (accessed 1\u00a0April\u00a02020).\nGarzia, Diego and Marschall, Stefan (2012) \u2018Voting Advice Applications Under \nReview: The State of Research\u2019,  International Journal of Electronic Governance,  \n5: 203-22, DOI: 10.1504/IJEG.2012.051309.\nGerman Federal Foreign Office (2018) \u2018Fake News, Bots and Provocative Statements \n\u2013 Disinformation on the Internet\u2019, Berlin: Federal Foreign Office, 7 August, \nhttps:/ /www.auswaertiges-amt.de/en/aussenpolitik/themen/disinformation-\non-the-internet/2125634 (accessed 1\u00a0April\u00a02020).\nGessen, Masha (2018) \u2018Why the Russian Influence Campaign Remains So Hard to \nUnderstand\u2019, The New Yorker , 18\u00a0December, https://www.newyorker.com/news/\nRefe Ren ce S 265\nour-columnists/why-the-russian-influence-campaign-remains-so-hard-to-\nunderstand (accessed 1\u00a0April\u00a02020).\nGitelman, Lisa (2006) Always Already New: Media, History, and the Data of Culture . \nCambridge, MA: MIT Press.\nGlowacki, Monika, Vidya Narayanan, Sam Maynard, Gustavo Hirsch, Bence Kollanyi, \nLisa-Maria Neudert, Phil Howard, Thomas Lederer, and Vlad Barash (2018) \u2018News \nand Political Information Consumption in Mexico: Mapping the 2018 Mexical \nPresidential Election on Twitter and Facebook\u2019, Computational Propaganda \nData Memo, Oxford: Oxford Internet Institute, https://comprop.oii.ox.ac.uk/\nwp-content/uploads/sites/93/2018/06/Mexico2018.pdf (accessed 1\u00a0April\u00a02020).\nGoodwin, Matthew and Roger Eatwell (2018) National Populism: The Revolt Against \nLiberal Democracy , London: Penguin Books.\nGottfried, Jeffrey and Elisa Shearer (2016) \u2018News Use Across Social Media Plat -\nforms 2016\u2019, Washington, DC: Pew Research Center, https://www.journalism.\norg/2016/05/26/news-use-across-social-media-platforms-2016/ (accessed \n1\u00a0April\u00a02020).\nGovernment Offices of Sweden (2017) \u2018A Practical Approach on How to Cope with \nDisinformation\u2019, webpage, Government Offices of Sweden, 6\u00a0October, https://\nwww.government.se/articles/2017/10/a-practical-approach-on-how-to-cope-\nwith-disinformation/ (accessed 1\u00a0April\u00a02020).\nGramer, Robbie (2017) \u2018Denmark Creates the World\u2019s First Ever Digital Ambassador\u2019, \nForeign Policy , 27\u00a0January, https://foreignpolicy.com/2017/01/27/denmark-creates-\nthe-worlds-first-ever-digital-ambassador-technology-europe-diplomacy/ \n(accessed 1\u00a0April\u00a02020).\nGraves, Lucas (2016) Deciding What\u2019s True: The Rise of Political Fact-Checking in \nAmerican Journalism . New York: Columbia University Press.\n\u2014 and Federica Cherubini (2016) \u2018The Rise of Fact-checking Sites in Europe\u2019, \nReuters Institute for the Study of Journalism, Oxford: University of Oxford, \nhttps://reutersinstitute.politics.ox.ac.uk/sites/default/files/research/files/\nThe%2520Rise%2520of%2520Fact-Checking%2520Sites%2520in%2520Euro\npe.pdf (accessed 1\u00a0April\u00a02020).\nGrinberg, Nir, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson and David \nLazer (2019) \u2018Fake News on Twitter During the 2016 U.S. Presidential Election\u2019, \nScience  363(6425): 374-378, DOI: 10.1126/science.aau2706.\nGroll, Elias (2018) \u2018Battling the Bots\u2019, Foreign Policy , 12\u00a0November, https://foreign -\npolicy.com/2018/11/12/battling-the-bots-ai-russia-disinformation-fake-news/ \n(accessed 1\u00a0April\u00a02020).\nGroot, Tim, Sophie Minihold, Jessica Robinson, Manuel Schneider, Joanna Sleigh \nand Dydimus Zengenene (2019) \u2018Russia, Twitter & Authenticity: Establishing \nCredibility Metrics\u2019, Winter School 2019, Digital Methods Initiative, https://\n266  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nwiki.digitalmethods.net/Dmi/WinterSchool2019CredibilityMetrics (accessed \n1\u00a0April\u00a02020).\nGuess, Andrew, Brendan Nyhan and Jason Reifler (2018) \u2018Selective Exposure to \nMisinformation: Evidence from the consumption of fake news during the 2016 \nU.S. presidential campaign\u2019, Report, Hannover, NH: Dartmouth College, https://\nwww.dartmouth.edu/~nyhan/fake-news-2016.pdf (accessed 1\u00a0April\u00a02020).\nHaciyakupoglu, Gulizar, Jennifer Yang Hui, V. S. Suguna, Dymples Leong, and \nMuhammad Faizal Bin Abdul Rahman (2018) \u2018Countering Fake News: A Survey Of \nRecent Global Initiatives\u2019, report, Singapore: Nanyang Technological University, \nhttps://www.rsis.edu.sg/rsis-publication/cens/countering-fake-news-a-survey-\nof-recent-global-initiatives/ (accessed 1\u00a0April\u00a02020).\nHagen, Sal, Dani\u00ebl de Zeeuw, Stijn Peeters, Emilija Jokubauskait\u0117, and \u00c1ngeles \nBriones (2019) \u2018Understanding Normiefication: A Cross-Platform Analysis of \nthe QAnon Conspiracy Theory\u2019, Winter School 2019, Digital Methods Initia -\ntive, https://wiki.digitalmethods.net/Dmi/WinterSchool2019Normiefication \n(accessed 1\u00a0April\u00a02020).\nHaidt, Jonathan (2012) The Righteous Mind: Why Good People Are Divided by Politics \nand Religion . New York: Pantheon Books.\nHaim, Mario, Andreas Graefe and Hans-Bernd Brosius (2018) \u2018Burst of the Filter \nBubble? Effects of Personalization on the Diversity of Google News\u2019, Digital \nJournalism , 6(3):1-14, https://doi.org/10.1080/21670811.2017.1338145.\nHalavais, Alexander M. Campbell (2017) Search Engine Society . Cambridge, UK: \nPolity Press.\nHall, Jim (2001) Online Journalism: A Critical Primer . London: Pluto Press.\nHameleers, Michael and Toni van der Meer (2019) \u2018Fact-checks helpen tegen \ndesinformatie! Maar dan moeten ze wel gezien worden\u2019, De Nieuwe Reporter , \n29\u00a0January, https://www.denieuwereporter.nl/2019/01/fact-checks-helpen-tegen-\ndesinformatie-maar-dan-moeten-ze-wel-gezien-worden/ (accessed 1\u00a0April\u00a02020).\nHankes, Keegan, and Alex Amend (2018) \u2018The Alt-Right Is Killing People\u2019, Southern \nPoverty Law Center, 5\u00a0February, https://www.splcenter.org/20180205/alt-right-\nkilling-people (accessed 1\u00a0April\u00a02020).\nHaque, Md Mahfuzul, Mohammad Yousuf, Zahedur Arman, Md Main Uddin Rony, \nAhmed Shatil Alam, Kazi Mehedi Hasan, Md Khadimul Islam, and Naeemul \nHassan (2018) \u2018Fact-Checking Initiatives in Bangladesh, India, and Nepal: A \nStudy of User Engagement and Challenges\u2019, ArXiv:1811.01806 [Cs] , November, \nhttp://arxiv.org/abs/1811.01806.\nHarsin, Jayson (2018) \u2018A Critical Guide to Fake News: From Comedy to Tragedy\u2019, \nPouvoirs , 2018/1:164, 99-119, DOI: 10.3917/pouv.164.0099.\nRefe Ren ce S 267\nHarvey, Del and Yoel Roth (2018) \u2018An Update on Our Elections Integrity Work\u2019, \nTwitter blog, 1\u00a0October, https://blog.twitter.com/en_us/topics/company/2018/\nan-update-on-our-elections-integrity-work.html (accessed 1\u00a0April\u00a02020).\nHatewatch Staff (2015) \u2018Getting Cucky: A Brief Primer On The Radical Right\u2019s Newest \n\u201ccuckservative\u201d Meme\u2019, Southern Poverty Law Center, 7\u00a0August, https://www.\nsplcenter.org/hatewatch/2015/08/07/getting-cucky-brief-primer-radical-rights-\nnewest-cuckservative-meme (accessed 1\u00a0April\u00a02020).\nHawley, George (2017) Making Sense of the Alt-Right . New York: Columbia University \nPress.\nHaynes, Gavin (2016) \u2018Can You Spot The \u2018Real\u2019 Fake News Story?\u2019 The Guardian , \n28\u00a0December, https://www.theguardian.com/theguardian/2016/dec/28/can-\nyou-spot-the-real-fake-news-story-quiz (accessed 1\u00a0April\u00a02020).\nHeck, Wilmer (2018) \u2018Nederlandse media dagen EU voor rechter na beschuldig -\ningen desinformatie\u2019, NRC Handelsblad , 20\u00a0February, https://www.nrc.nl/\nnieuws/2018/02/20/nederlandse-media-dagen-eu-voor-rechter-na-beschul -\ndigingen-desinformatie-a1592915 (accessed 1\u00a0April\u00a02020).\n\u2014 (2017) \u2018Rusland Be\u00efnvloedt Ons Vooral Online\u2019, NRC Handelsblad, 8\u00a0January, \nhttps://www.nrc.nl/nieuws/2017/01/08/rusland-is-online-op-vriendenjacht-\n6122994-a154030 (accessed 1\u00a0April\u00a02020).\nHedman, Freja, Fabian Sivnert, Lisa-Maria Neudert, Bence Kollanyi, Philip N. How -\nard and Vidya Narayanan (2018) \u2018News and Political Information Consumption in \nSweden: Mapping the 2018 Swedish General Election on Twitter\u2019, Computational \nPropaganda Data Memo, Oxford: Oxford Internet Institute, 6\u00a0September, https://\ncomprop.oii.ox.ac.uk/research/sweden-election/ (accessed 1\u00a0April\u00a02020).\nHedrick, Ashley, Dave Karpf and Daniel Kreiss (2018) \u2018The Earnest Internet vs. the \nAmbivalent Internet\u2019, International Journal of Communication , 12:1057-1064, \nhttps://ijoc.org/index.php/ijoc/article/viewFile/8736/2284 (accessed 1\u00a0April\u00a02020).\nHeikkil a\u0308, N iko (2017) \u2018Online Antagonism of the Alt-Right in the 2016 Election\u2019, \nEuropean Journal of American Studies 12(2): 1-23, DOI:10.4000/ejas.12140.\nHelmond, Anne (2015) \u2018The Platformization of the Web: Making Web Data Platform \nReady\u2019, Social Media + Society 1(2):1-11, https://doi.org/10.1177/2056305115603080.\nHemmer, Nicole (2016) Messengers of the Right: Conservative Media and the \nTransformation of American Politics . Philadelphia: University of Pennsylvania \nPress.\nHendricks, Vincent F. and Mads Vestergaard (2019) Reality Lost: Markets of Attention, \nMisinformation and Manipulation. Cham: Springer.\nHerdersche\u00ea, Gijs, and Remco Meijer (2019) \u2018Kabinet krijgt bitter voorproefje van \nregeren zonder meerderheid in Eerste Kamer\u2019, de Volkskrant , 31\u00a0January, https://\nwww.volkskrant.nl/gs-b378d420 (accessed 1\u00a0April\u00a02020).\n268  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nHern, Alex (2017) \u2018Google Acts Against Fake News on Search Engine\u2019, The Guardian , \n25\u00a0April, https://www.theguardian.com/technology/2017/apr/25/google-launches-\nmajor-offensive-against-fake-news (accessed 1\u00a0April\u00a02020).\n\u2014 and Jim Waterson (2018) \u2018Facebook Cracks Down on \u201cDark Ads\u201d by British \npolitical Groups\u2019, The Guardian , 16\u00a0October, https://www.theguardian.com/\ntechnology/2018/oct/16/facebook-dark-ads-british-political-groups (accessed \n1\u00a0April\u00a02020).\nHerrman, John (2016) \u2018Inside Facebook\u2019s (Totally Insane, Unintentionally Gigantic, \nHyperpartisan) Political-Media Machine\u2019, The New York Times , 28\u00a0August, https://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html (accessed \n1\u00a0April\u00a02020).\nHindman, Matthew Scott (2008) The Myth of Digital Democracy . Princeton: \nPrinceton University Press.\nHirst, Martin (2017) \u2018Towards a Political Economy of Fake News\u2019, The Political \nEconomy of Communication  5(2), 82-94, http://www.polecom.org/index.php/\npolecom/article/view/86/288 (accessed 1\u00a0April\u00a02020).\nHirzalla, Fadi and Liesbet van Zoonen (2015) \u2018Online Voting Applications. Foci, \nFindings and Future of an Emerging Research Field\u2019 in Stephen Coleman and \nDean Freelon (eds), Handbook of Digital Politics , Northampton, MA: Edward \nElgar, pp.\u00a087-103, https://doi.org/10.4337/9781782548768.00014.\nHolt, Jared (2017) \u2018White Supremacy Figured Out How to Become YouTube Fa -\nmous | Right Wing Watch\u2019, October, http://www.rightwingwatch.org/report/\nwhite-supremacy-figured-out-how-to-become-youtube-famous/ (accessed \n1\u00a0April\u00a02020).\nHolzman, Michael (2008) James Jesus Angleton, the CIA and the Craft of Counterintel -\nligence . Amherst: University of Massachusetts Press.\nHoneycutt, Courtenay and Susan C. Herring (2009) \u2018Beyond Microblogging. Con -\nversation and Collaboration\u2019, 42nd Hawaii International Conference on System \nSciences , Los Alamitos, CA: IEEE Press, http://citeseerx.ist.psu.edu/viewdoc/\ndownload?doi=10.1.1.692.9575&rep=rep1&type=pdf (accessed 1\u00a0April\u00a02020).\nHouse of Commons (2019) \u2018Disinformation and \u201cFake News\u201d: Final Report Eighth \nReport of Session 2017-19\u2019, Digital, Culture, Media and Sport Committee, London: \nUK Parliament, https:/ /publications.parliament.uk/pa/cm201719/cmselect/\ncmcumeds/1791/1791.pdf (accessed 1\u00a0April\u00a02020).\nHoward, Philip N., Gillian Bolsover, Bence Kollanyi, Samantha Bradshaw, and \nLisa-Maria Neudert (2017) \u2018Junk News and Bots During the U.S. Election: What \nWere Michigan Voters Sharing Over Twitter?\u2019, Computational Propaganda \nData Memo, Oxford: Oxford Internet Institute, https://comprop.oii.ox.ac.uk/\nresearch/working-papers/junk-news-and-bots-during-the-u-s-election-what-\nwere-michigan-voters-sharing-over-twitter/ (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 269\n\u2014, Bharath Ganesh, Dimitra Liotsiou, John Kelly and Camille Franc\u0327ois (2018) \u2018The \nIRA, Social Media and Political Polarization in the United States, 2012-2018\u2019, \nReport, Computational Propaganda Research Project, Oxford: Oxford Internet \nInstitute, https://comprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2018/12/\nThe-IRA-Social-Media-and-Political-Polarization.pdf (accessed 1\u00a0April\u00a02020).\nHughes, Taylor, Jeff Smith, and Alex Leavitt (2018) \u2018Helping People Better Assess the \nStories They See in News Feed with the Context Button | Facebook Newsroom\u2019, \nFacebook Newsroom , April, https://newsroom.fb.com/news/2018/04/news-feed-\nfyi-more-context/(accessed 1\u00a0April\u00a02020).\nIngram, Matthew (2019) \u2018Researchers Say Fears About \u201cFake News\u201d Are Exaggerated\u2019, \nColumbia Journalism Review , 7\u00a0February, https://www.cjr.org/the_media_today/\nresearchers-fake-news-exaggerated.php (accessed 1\u00a0April\u00a02020).\nInstaloader (2019) Instaloader software, version 4.2.5, GitHub project, https://\ninstaloader.github.io/ (accessed 1\u00a0April\u00a02020).\nIsaac, Mike (2016) \u2018Facebook, in Cross Hairs After Election, Is Said to Question Its \nInfluence\u2019, New York Times , 12\u00a0November, https://www.nytimes.com/2016/11/14/\ntechnology/facebook-is-said-to-question-its-influence-in-election.html (accessed \n1\u00a0April\u00a02020).\nJack, Caroline (2017) \u2018Lexicon of Lies: Terms for Problematic Information\u2019, New \nYork: Data & Society Research Institute.\nJamieson, Kathleen Hall. 2018. Cyberwar: How Russian Hackers and Trolls Helped \nElect a President . Oxford: Oxford University Press.\nJankowski, Nicholas W. (2018) \u2018Researching Fake News: A Selective Examination \nof Empirical Studies\u2019, Javnost \u2013 The Public , 25(1-2): 248-255, https://doi.org/10.1\n080/13183222.2018.1418964.\nJansen, Bernard J. and Amanda Spink (2003) \u2018An Analysis of Web Documents \nRetrieved and Viewed\u2019, 4th International Conference on Internet Computing, \nLas Vegas, Nevada, 23-26\u00a0June, pp.\u00a065-69, https://faculty.ist.psu.edu/jjansen/\nacademic/pubs/pages_viewed.pdf (accessed 1\u00a0April\u00a02020).\nJava, Akshay, Xiaodan Song, Tim Finin and Belle Tseng (2007) \u2018Why We Twitter: \nUnderstanding Microblogging Usage and Communities\u2019, Proceedings of the 9th \nWebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network \nAnalysis , New York: ACM, pp.\u00a056-65, DOI: 10.1145/1348549.1348556.\nJeang\u00e8ne Vilmer, Jean-Baptiste, Alexandre Escorcia, Marine Guillaume, Janaina \nHerrera (2018) \u2018Information Manipulation: A Challenge for Our Democracies\u2019, \nreport by the Policy Planning Staff (CAPS) of the Ministry for Europe and \nForeign Affairs and the Institute for Strategic Research (IRSEM) of the Ministry \nfor the Armed Forces, Paris, August, https://www.diplomatie.gouv.fr/IMG/pdf/\ninformation_manipulation_rvb_cle838736.pdf (accessed 1\u00a0April\u00a02020).\n270  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nJohnson, Brett G., and Kimberly Kelling (2018) \u2018Placing Facebook\u2019, Journalism \nPractice  12(7): 817-33, https://doi.org/10.1080/17512786.2017.1349546.\nJonker, Jorn (2017) \u2018Nepnieuws gevaar voor Nederland\u2019, De Telegraaf , 14\u00a0November, \nhttps://www.telegraaf.nl/nieuws/1196666/nepnieuws-gevaar-voor-nederland \n(accessed 1\u00a0April\u00a02020).\nKaiser, Jonas, and Adrian Rauchfleisch (2018) \u2018Unite the Right? How YouTube\u2019s Rec -\nommendation Algorithm Connects the U.S. Far-Right\u2019, Medium , New York: Data & \nSociety Research Institute, April\u00a011, https://medium.com/@MediaManipulation/\nunite-the-right-how-youtubes-recommendation-algorithm-connects-the-u-s-\nfar-right-9f1387ccfabd (accessed 1\u00a0April\u00a02020).\nKanne, Peter and Milan Driessen (2017) \u2018Desinformatie leidt tot verwarring bij \nnieuwsconsument\u2019, Amsterdam: I&O Research, https://www.ioresearch.nl/\nactueel/desinformatie-leidt-tot-verwarring-bij-nieuwsconsument/ (accessed \n1\u00a0April\u00a02020).\nKasteleijn, Nando (2017) \u2018Nepnieuws groot gevaar voor Nederland? Dat lijkt dus wel \nmee te vallen\u2019, NOS , 28\u00a0August, https://nos.nl/artikel/2190381-nepnieuws-groot-\ngevaar-voor-nederland-dat-lijkt-dus-wel-mee-te-vallen.html (accessed 1\u00a0April\u00a02020).\nvan Keulen, Ira, Iris Korthagen, Paul Diederen en Pieter van Boheemen (2018) \n\u2018Digitalisering van het nieuws: Online nieuwsgedrag, desinformatie en person -\nalisatie in Nederland\u2019, Den Haag: Rathenau Instituut, https://www.rathenau.\nnl/sites/default/files/2018-05/Digitalisering%20van%20het%20nieuws.pdf \n(accessed 1\u00a0April\u00a02020).\nKing, Gary and Nathaniel Persily (2018) \u2018A New Model for Industry-Academic \nPartnerships\u2019, Working Paper, 9\u00a0April, http://j.mp/2q1IQpH (accessed 1\u00a0April\u00a02020).\nKist, Reinier (2019) \u2018Factchecken Facebook loopt stuk op aansprakelijkheid\u2019, NRC \nHandelsblad , 26\u00a0February, https://www.nrc.nl/nieuws/2019/02/26/factchecken-\nfacebook-loopt-stuk-op-aansprakelijkheid-a3655348 (accessed 1\u00a0April\u00a02020).\n\u2014 and Rik Wassens (2017) \u2018Ook Nederlandse media werden misleid door Russische \ntrollen\u2019, NRC Handelsblad , 8\u00a0December, https://www.nrc.nl/nieuws/2017/12/08/\nmedia-nederland-citeerden-trollen-als-bron-a1584306 (accessed 1\u00a0April\u00a02020).\n\u2014 and Rik Wassens (2018a) \u2018Russische trollen actief in Nederland\u2019, NRC Handelsblad,  \n15\u00a0July, https://www.nrc.nl/nieuws/2018/07/15/russische-trollen-actief-in-\nnederland-a1610158 (accessed 1\u00a0April\u00a02020).\n\u2014 and Rik Wassens (2018b) \u2018Russisch trollenleger ook actief in Nederland\u2019, NRC \nHandelsblad , 15\u00a0July, https://www.nrc.nl/nieuws/2018/07/15/de-russische-trollen-\nzijn-anti-islam-en-voor-wilders-a1610155 (accessed 1\u00a0April\u00a02020).\n\u2014 and Peter Zantingh (2017) \u2018Geen grote rol nepnieuws in aanloop naar verk -\niezingen\u2019, NRC Handelsblad , 6\u00a0March, https://www.nrc.nl/nieuws/2017/03/06/\nfake-news-nee-zo-erg-is-het-hier-niet-7144615-a1549050 (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 271\nKitta, Andrea (2018) \u2018Alternative Websites and Fake News: Taking a Stab at Defini -\ntion, Genre and Belief\u2019, The Journal of American Folklore 131(522): 405-412, DOI: \n10.5406/jamerfolk.131.522.0405.\nKomok, Anna (2018) \u2018How to Check Instagram Account for Fake Followers\u2019, \nHypeAuditor , 6\u00a0July, https://hypeauditor.com/blog/how-to-check-instagram-\naccount-for-fake-followers/(accessed 1\u00a0April\u00a02020).\nKouwenhoven, Andreas and Hugo Logtenberg (2017) \u2018Hoe Denk met \u2018trollen\u2019 politieke \ntegenstanders monddood probeert te maken\u2019, NRC Handelsblad , 10\u00a0February, \nhttps://www.nrc.nl/nieuws/2017/02/10/de-trollen-van-denk-6641045-a1545547 \n(accessed 1\u00a0April\u00a02020).\nKranenberg, Annieke (2017) \u2018Wie weet nog wat er waar is?\u2019, de Volkskrant , 23\u00a0De -\ncember, https://www.volkskrant.nl/cultuur-media/wie-weet-nog-wat-er-waar-\nis~befc3c42/(accessed 1\u00a0April\u00a02020).\n\u2014 and Hassan Bahara (2018) \u2018Hoe alt-right online Jodenhaat verspreidt\u2019, de Volksk -\nrant , 9\u00a0November, https://www.volkskrant.nl/gs-b1714693 (accessed 1\u00a0April\u00a02020).\nKwak, Haewoon, Changhyun Lee, Hosung Park and Sue Moon (2010) \u2018What is \nTwitter? A Social Network or a News Media?\u2019, Proceedings of the 19th International \nConference on World Wide Web , New York: ACM, April, pp.\u00a0591-600, https://doi.\norg/10.1145/1772690.1772751.\nLagorio-Chafkin, Christine (2018) \u2018Reddit Confirms New Russian Meddling Efforts\u2019, \nInc., 4\u00a0October, https://www.inc.com/christine-lagorio/reddit-finds-new-russian-\ninterference-campaign.html (accessed 1\u00a0April\u00a02020).\nLaquintano, Timothy and Annette Vee (2017) \u2018How Automated Writing Systems \nAffect the Circulation of Political Information Online\u2019, Literacy in Composition \nStudies  5(2): 43-62, http://dx.doi.org/10.21623/1.5.2.4.\nLatour, Bruno (2008) What is the Style of Matters of Concern? Assen: Van Gorcum.\n\u2014 and Steve Woolgar (1979) Laboratory Life: The Social Construction of Scientific \nFacts.  Princeton, NJ: Princeton University Press.\nLazarsfeld, Paul F., Bernard R. Berelson and Hazel Gaudet (1948) The People\u2019s \nChoice: How the Voter Makes Up His Mind in a Presidential Campaign . New York: \nColumbia University Press.\nLazer, David M.J., Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly \nM. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan, Gordon \nPennycook, David Rothschild, Michael Schudson, Steven A. Sloman, Cass R. \nSunstein, Emily A. Thorson, Duncan J. Watts and Jonathan L. Zittrain (2018) \u2018The \nScience of Fake News\u2019, Science , 359(6380):1094-1096, DOI: 10.1126/science.aao2998.\nLee, Alexis (2019) \u2018What is a \u2018Facebook Engagement\u2019?\u2019, BuzzSumo Knowledge \nBase, https://help.buzzsumo.com/faqs-and-troubleshooting/product-faqs/\nwhat-is-a-facebook-engagement (accessed 1\u00a0April\u00a02020).\n272  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nLewis, Rebecca (2018) \u2018Alternative Influence: Broadcasting the Reactionary Right on \nYouTube\u2019, New York: Data & Society Research Institute, https://datasociety.net/wp-\ncontent/uploads/2018/09/DS_Alternative_Influence.pdf (accessed 1\u00a0April\u00a02020).\nLiotsiou, Dimitra, Bence Kollanyi, and Philip N. Howard (2019) \u2018The Junk News \nAggregator: Examining Junk News Posted on Facebook, Starting with the 2018 US \nMidterm Elections\u2019, ArXiv:1901.07920 [Cs] , January, http:/ /arxiv.org/abs/1901.07920.\nLippmann, Walter (1922) Public Opinion . New York: Harcourt, Brace and Co.\nLomas, Natasha (2018) \u2018Google is Surfacing Texas Shooter Misinformation in Search \nResults \u2013 Thanks also to Twitter\u2019, TechCrunch , 11\u00a0June, https://techcrunch.\ncom/2017/11/06/google-is-surfacing-texas-shooter-misinformation-in-search-\nresults-thanks-also-to-twitter/(accessed 1\u00a0April\u00a02020).\nLorenz, Taylor (2014) \u2018Instagram Rapture Claims Millions Of Celebrity Instagram \nFollowers\u2019, Business Insider , 18\u00a0December, https://www.businessinsider.com/\ninstagram-rapture-claims-millions-of-celebrity-instagram-followers-2014-12/ \n(accessed 1\u00a0April\u00a02020).\n\u2014 (2018) \u2018Instagram\u2019s Christmas Crackdown. No Meme Account is Safe \u2013 Not Even \n@God\u2019, The Atlantic , 27\u00a0December, https://www.theatlantic.com/technology/\narchive/2018/12/instagrams-christmas-crackdown-meme-accounts/579055/ \n(accessed 1\u00a0April\u00a02020).\nLouwerse, Tom and Martin Rosema (2014) \u2018The Design Effects of Voting Applications: \nComparing Methods of Calculating Matches\u2019, Acta Politica  49(3):286-312, DOI: \nhttps://doi.org/10.1057/ap.2013.30.\nLu\u0308ders, Marika, Lin Pr\u00f8itz and Terje Rasmussen (2010) \u2018Emerging Per -\nsonal Media Genres\u2019, New Media & Society ,  12(6): 947-963, https://doi.\norg/10.1177/1461444809352203.\nLynskey, Dorian (2018) \u2018How Dangerous is Jordan B Peterson, the Rightwing \nProfessor Who \u201cHit a Hornets\u2019 Nest\u201d?\u2019 The Guardian , February\u00a07, https://www.\ntheguardian.com/science/2018/feb/07/how-dangerous-is-jordan-b-peterson-\nthe-rightwing-professor-who-hit-a-hornets-nest (accessed 1\u00a0April\u00a02020).\nMacFarquhar, Neil (2018) \u2018A Powerful Russian Weapon: The Spread of False Stories\u2019, \nThe New York Times , 20\u00a0January, https://www.nytimes.com/2016/08/29/world/\neurope/russia-sweden-disinformation.html (accessed 1\u00a0April\u00a02020).\nMaheshwari, Sapna (2018) \u2018Uncovering Instagram Bots With a New Kind of Detective \nWork\u2019, The New York Times , 12\u00a0March, https://www.nytimes.com/2018/03/12/\nbusiness/media/instagram-bots.html (accessed 1\u00a0April\u00a02020).\nMalice, Michael (2019) The New Right: A Journey to the Fringe of American Politics . \nNew York: All Points Books.\nMarchal, Nahema, Lisa-Maria Neudert, Bence Kollanyi, and Philip N. Howard (2018) \n\u2018Polarization, Partisanship and Junk News Consumption on Social Media During \nRefe Ren ce S 273\nthe 2018 US Midterm Elections\u2019, Computational Propaganda Data Memo, Oxford: \nOxford Internet Institute, https://comprop.oii.ox.ac.uk/research/midterms2018/ \n(accessed 1\u00a0April\u00a02020).\nMargolis, Joseph (1995) \u2018Beyond Postmodernism: Logic as Rhetoric\u2019, Argumentation , \n9(1): 21-31, https://doi.org/10.1007/BF00733098.\nMarres, Noortje (2018) \u2018Why We Can\u2019t Have Our Facts Back\u2019, Engaging Science, \nTechnology, and Society  4: 423-443, https://doi.org/10.17351/ests2018.188.\n\u2014 and Esther Weltevrede (2013), \u2018Scraping the Social?\u2019 Journal of Cultural Economy  \n6(3): 313-35, DOI:10.1080/17530350.2013.772070.\nMartens, Bertin, Luis Aguiar, Estrella Gomez-Herrera and Frank Mueller-Langer \n(2018) \u2018The Digital Transformation of News Media and the Rise of Disinformation \nand Fake News\u2019, SSRN Electronic Journal , DOI:10.2139/ssrn.3164170.\nMarvin, Carolyn (1988) When Old Technologies Were New . New York, NY: Oxford \nUniversity Press.\nMarwick, Alice E. (2018) \u2018Why Do People Share Fake News? A Sociotechnical Model \nof Media Effects\u2019, Georgetown Law Technology Review 2(2): 474-512.\n\u2014, and Rebecca Lewis (2017) \u2018Media Manipulation and Disinformation Online\u2019, \nNew York: Data & Society Research Institute, https://datasociety.net/wp-content/\nuploads/2017/05/DataAndSociety_MediaManipulationAndDisinformationOn -\nline-1.pdf (accessed 1\u00a0April\u00a02020).\nMatsakis, Louise (2017) \u2018This Russian Vending Machine Will Sell You Fake \nInstagram Likes\u2019, Motherboard Vice , 7\u00a0June, https://www.vice.com/en_us/\narticle/xw8yv3/russian-vending-machine-fake-instagram-likes (accessed \n1\u00a0April\u00a02020).\nMauri, Michele, Tommaso Elli, Giorgio Caviglia, Giorgio Uboldi, and Matteo Azzi \n(2017) \u2018RAWGraphs: A Visualisation Platform to Create Open Outputs\u2019, Proceed -\nings of the 12th Biannual Conference on Italian SIGCHI Chapter , CHItaly \u201917, New \nYork: ACM, https://doi.org/10.1145/3125571.3125585.\nMcGarry, Caitlin (2013) \u2018Twitter Bots, Fake Retweets Rake in Big Bucks\u2019, PCWorld , \n10\u00a0April, https://www.pcworld.com/article/2033766/twitter-bots-fake-retweets-\nrake-in-big-bucks.html (accessed 1\u00a0April\u00a02020).\nMcGonagle, Tarlach (2017) \u2018\u201cFake News\u201d: False Fears or Real Concerns?\u2019, \nNetherlands Quarterly of Human Rights  35(4): 203-209, https://doi.\norg/10.1177/0924051917738685.\nMcKernon, Edward (1925) \u2018Fake News and the Public\u2019, The Harper\u2019s Monthly, October, \npp.\u00a0528-536.\n\u2014 (1928) \u2018News Fakers\u2019, The Outlook  149(4): 130-141.\nMcNeil, Maureen (2013) \u2018Between a Rock and a Hard Place: The Deficit Model, the \nDiffusion Model and Publics in STS\u2019, Science as Culture 22(4): 589-608, https://\ndoi.org/10.1080/14636778.2013.764068.\n274  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nMcQueen, Sharon (2018) \u2018From Yellow Journalism to Tabloids to Clickbait: The \nOrigins of Fake News in the United States\u2019, in Denise E. Agosto (ed.) Information \nLiteracies and Libraries in the Age of Fake New s. Santa Barbara, CA: Libraries \nUnlimited, pp.\u00a012-35.\nMerrill, Jeremy B. and Ariana Tobin (2019) \u2018Facebook Moves to Block Ad Transpar -\nency Tools \u2013 Including Ours\u2019, ProPublica , 29\u00a0January, https://www.propublica.\norg/article/facebook-blocks-ad-transparency-tools (accessed 1\u00a0April\u00a02020).\nMilneil, Christian (2018) \u2018Data: Read the Tweets from Alleged Russian Troll Accounts \nTargeting Maine Politicians\u2019, Portland Press Herald , 2\u00a0August, https://www.\npressherald.com/2018/08/02/data-read-the-tweets-from-alleged-russian-troll-\naccounts-targeting-maines-congressional-delegation/ (accessed 1\u00a0April\u00a02020).\nMina, An Xiao (2019). Memes to Movements: How the World\u2019s Most Viral Media Is \nChanging Social Protest and Power . Boston, MA: Beacon Press.\nMinisterie van Binnenlandse Zaken en Koninkrijksrelaties (2019) \u2018Campagne \nnepnieuws vandaag van start \u2013 Nieuwsbericht\u2019, Rijksoverheid.nl . March\u00a011, \nhttps://www.rijksoverheid.nl/actueel/nieuws/2019/03/11/campagne-nepnieuws-\nvandaag-van-start (accessed 1\u00a0April\u00a02020).\nMis\u00e9rus, Mark and Robert van der Noordaa (2018a) \u2018Het trollenleger van popartiest \nDotan\u2019, de Volkskrant , 14\u00a0April, https://www.volkskrant.nl/kijkverder/2018/\ndotan/#/ (accessed 1\u00a0April\u00a02020).\nMis\u00e9rus, Mark and Robert van der Noordaa (2018b) \u2018Dotan erkent aanmaken nepfans: \n\u201cIk was heel na\u00efef, veel te ambitieus en onzeker\u201d\u2019, de Volkskrant , 16\u00a0April, https://\nwww.volkskrant.nl/nieuws-achtergrond/dotan-erkent-aanmaken-nepfans-ik-\nwas-heel-naief-veel-te-ambitieus-en-onzeker~b80fb404/ (accessed 1\u00a0April\u00a02020).\nMonbiot, George (2019) \u2018Dark Money Is Pushing for a No-deal Brexit. Who Is \nBehind It?\u2019, The Guardian , 13\u00a0February, https://www.theguardian.com/com -\nmentisfree/2019/feb/13/dark-money-hard-brexit-targeted-ads-facebook (accessed \n1\u00a0April\u00a02020).\nMorozov, Evgeny (2017) \u2018Moral Panic Over Fake News Hides the Real Enemy \u2013 the \nDigital Giants\u2019, The Guardian , 8\u00a0January, https://www.theguardian.com/com -\nmentisfree/2017/jan/08/blaming-fake-news-not-the-answer-democracy-crisis \n(accessed 1\u00a0April\u00a02020).\nMosseri, Adam (2017a) \u2018Working to Stop Misinformation and False News | Facebook \nNewsroom\u2019, Facebook Newsroom,  blog post, April, https://newsroom.fb.com/\nnews/2017/04/working-to-stop-misinformation-and-false-news/ (accessed \n1\u00a0April\u00a02020).\n\u2014 2017b. \u2018Showing More Informative Links in News Feed | Facebook Newsroom,\u2019 \nFacebook Newsroom , blog post, June\u00a030, https://newsroom.fb.com/news/2017/06/\nnews-feed-fyi-showing-more-informative-links-in-news-feed/ (accessed \n1\u00a0April\u00a02020).\nRefe Ren ce S 275\nMudde, Cas, and Crist\u00f3bal Rovira Kaltwasser (2017) Populism: A Very Short Introduc -\ntion.  Oxford: Oxford University Press.\nMuirhead, Russell, and Nancy L. Rosenblum (2019) A Lot of People Are Saying: The \nNew Conspiracism and the Assault on Democracy . Princeton, NJ: Princeton \nUniversity Press.\nMuller, Jan-Werner (2016) What Is Populism? Philadelphia, PA: University of \nPennsylvania Press.\nNagle, Angela (2017) Kill All Normies: Online Culture Wars From 4Chan and Tumblr \nto Trump and the Alt-Right. London: Zero Books.\nNeudert, Lisa-Maria N. (2017) \u2018Computational Propaganda in Germany: A Cau -\ntionary Tale\u2019, Computational Propaganda Working Paper, Oxford: Oxford \nInternet Institute, https://blogs.oii.ox.ac.uk/politicalbots/wp-content/uploads/\nsites/89/2017/06/Comprop-Germany.pdf (accessed 1\u00a0April\u00a02020).\nNeudert, Lisa-Maria, Bence Kollanyi, and Philip N. Howard (2017) \u2018Junk News and \nBots during the German Parliamentary Election: What Are German Voters \nSharing over Twitter?\u2019, Computational Propaganda Data Memo, Oxford: Oxford \nInternet Institute, https://comprop.oii.ox.ac.uk/research/junk-news-and-bots-\nduring-the-german-parliamentary-election-what-are-german-voters-sharing-\nover-twitter/ (accessed 1\u00a0April\u00a02020).\nNew Knowledge (2018) \u2018The Tactics & Tropes of the Internet Research Agency\u2019, \nWhite Paper, Austin, TX: New Knowledge, https://disinformationreport.blob.\ncore.windows.net/disinformation-report/NewKnowledge-Disinformation-\nReport-Whitepaper.pdf (accessed 1\u00a0April\u00a02020).\nNewman, Michelle C. (2010) \u2018The Daily Show and Meta-Coverage: How Mock News \nCovers the Political Communications System\u2019, The Elon Journal of Undergraduate \nResearch in Communications , 1(2), http://www.elon.edu/docs/e-Web/academics/\ncommunications/research/vol1no2/EJFall10_Full.pdf (accessed 1\u00a0April\u00a02020).\nNewsGuard (2019), \u2018Restoring Trust and Accountability\u2019, NewsGuard  webpage, \nhttps://www.newsguardtech.com, (accessed 1\u00a0April\u00a02020).\nNiederer, Sabine (2018) \u2018The Study of Networked Content: Five Considerations for \nDigital Research in the Humanities\u2019, in Giovanni Schiuma and Daniela Carlucci \n(eds.), Big Data in the Arts and Humanities: Theory and Practice, Boca Raton, \nFL: CRC Press, pp.\u00a089-100.\n\u2014 (2019) Networked Content Analysis: The Case of Climate Change , Amsterdam: \nInstitute of Network Cultures.\nNijmeijer, Bert (2018) \u2018Zelf nepnieuws maken om daarna de echte trollen te kunnen \nherkennen\u2019, NRC Handelsblad,  22\u00a0July, https://www.nrc.nl/nieuws/2018/07/22/zelf-\nnepnieuws-maken-om-daarna-de-echte-trollen-te-kunnen-herkennen-a1610863 \n(accessed 1\u00a0April\u00a02020).\n276  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nNoble, Safiya Umoja (2018) Algorithms of Oppression: How Search Engines Reinforce \nRacism . New York, NY: New York University Press.\nvan der Noordaa, Robert and Coen van de Ven (2019) \u2018Het MH17 Complot\u2019, De Groene \nAmsterdammer , 29\u00a0May, https://www.groene.nl/artikel/het-mh17-complot \n(accessed 1\u00a0April\u00a02020).\nvan der Noordaa, Robert and Coen van de Ven (2018a) \u2018Hoe Russische trollen \ninspelen op westerse angsten\u2019, De Groene Amsterdammer , 28\u00a0Augustus, https://\nwww.groene.nl/artikel/hoe-russische-trollen-inspelen-op-westerse-angsten \n(accessed 1\u00a0April\u00a02020).\nvan der Noordaa, Robert and Coen van de Ven (2018b) \u20183 Miljoen \u201ctrollentweets\u201d \nonderzocht: hoe Rusland via sociale media ook in Belgi\u00eb verdeeldheid zaait\u2019, \nKnack , 27\u00a0November, https://www.knack.be/nieuws/belgie/3-miljoen-trollent -\nweets-onderzocht-hoe-rusland-via-sociale-media-ook-in-belgie-verdeeldheid-\nzaait/article-longread-1398723.html (accessed 1\u00a0April\u00a02020).\nNOS (2017a) \u2018Baby van 20 kilo heeft de primeur: eerste nepnieuws in Nederland\u2019, \nNOS, 8\u00a0June, https://nos.nl/artikel/2177218-baby-van-20-kilo-heeft-de-primeur-\neerste-nepnieuws-in-nederland.html (accessed 1\u00a0April\u00a02020).\nNOS (2017b) \u2018Ollongren: Russische desinformatie bij Oekra\u00efne-referendum\u2019, NOS , \n15\u00a0November, https://nos.nl/artikel/2202937-ollongren-russische-desinformatie-\nbij-oekraine-referendum.html (accessed 1\u00a0April\u00a02020)..\nNOS (2018) \u2018Twitters grote schoonmaak: Wilders en Denk-politici verliezen volgers\u2019, \nNOS, 13\u00a0July, https://nos.nl/nieuwsuur/artikel/2241321-twitters-grote-schoon -\nmaak-wilders-en-denk-politici-verliezen-volgers.html (accessed 1\u00a0April\u00a02020).\nNuzzi, Olivia (2017) \u2018Kellyanne Conway Is a Star\u2019, New York Magazine, March, \nhttps://nymag.com/intelligencer/2017/03/kellyanne-conway-trumps-first-lady.\nhtml (accessed 1\u00a0April\u00a02020).\nNyhan, Brendan, Ethan Porter, Jason Reifler and Thomas J. Wood (2019) \u2018Taking \nFact-Checks Literally But Not Seriously? The Effects of Journalistic Fact-Checking \non Factual Beliefs and Candidate Favorability\u2019, Political Behavior , published \nonline 21\u00a0January, https://doi.org/10.1007/s11109-019-09528-x.\nO\u2019Brien, Chris (2019) \u2018Sheryl Sandberg says Facebook Is Now Blocking 1 Million \nFake Accounts Every Day\u2019, Venture Beat, 21\u00a0January, https:/ /venturebeat.\ncom/2019/01/21/sheryl-sandberg-says-facebook-is-now-blocking-1-million-fake-\naccounts-every-day/ (accessed 1\u00a0April\u00a02020).\nO\u2019Donovan, Caroline (2014) \u2018What Is Clickbait?\u2019, Niemanlab , 25\u00a0August, https://\nwww.niemanlab.org/2014/08/what-is-clickbait/ (accessed 1\u00a0April\u00a02020).\nOmnicore. (2019) \u2018Twitter by the Numbers\u2019, Omnicore  Agency , https://www.omni -\ncoreagency.com/twitter-statistics/ (accessed 1\u00a0April\u00a02020).\nRefe Ren ce S 277\nOpper, F. (1894) \u2018The Fin de Si\u00e8cle Newspaper Proprietor\u2019, Puck,  35(887).\nOudenampsen, Merijn (2013) \u2018Met de Tjoeki Tjoeki Naar Takki Takki\u2019. De Groene \nAmsterdammer , 3\u00a0July, https://www.groene.nl/artikel/met-de-tjoeki-tjoeki-\nnaar-takki-takki (accessed 1\u00a0April\u00a02020).\nPanagopoulos, Costas (2016) \u2018All about that Base: Changing Campaign Strate -\ngies in US Presidential Elections\u2019, Party Politics , 22(2): 179-90, https://doi.\norg/10.1177/1354068815605676.\nPariser, Eli (2011) The Filter Bubble: What the Internet Is Hiding From You. New \nYork: Penguin.\nParlapiano, Alicia and Jasmine C. Lee (2018) \u2018The Propaganda Tools Used by Russians \nto Influence the 2016 Election\u2019, New York Times , 16\u00a0February, https://www.\nnytimes.com/interactive/2018/02/16/us/politics/russia-propaganda-election-2016.\nhtml (accessed 1\u00a0April\u00a02020).\nPeck, Reece (2019) Fox Populism: Branding Conservatism as Working Class . Cam -\nbridge: Cambridge University Press.\nPedersen, David B. and Vincent F. Hendricks (2014) \u2018Science Bubbles\u2019, Philosophy \nand Technology , 27(4): 503-518, https://doi.org/10.1007/s13347-013-0142-7.\nPeek, Simone (2018) \u2018NOS-hoofdredacteur over bericht Soros: \u201cZo had het niet \ngemoeten\u201d\u2019, NRC Handelsblad , 24\u00a0October, https://www.nrc.nl/nieuws/2018/10/24/\nnos-hoofdredacteur-over-bericht-soros-zo-had-het-niet-gemoeten-a2752535 \n(accessed 1\u00a0April\u00a02020).\nPeel, Michael (2019) \u2018EU Election Suffered Russian Disinformation, Brussels Finds\u2019, \nFinancial Times , 14\u00a0June, https://www.ft.com/content/bc4b65b0-8dfa-11e9-a1c1-\n51bf8f989972 (accessed 1\u00a0April\u00a02020).\nPersily, Nathaniel (2017) \u2018The 2016 U.S. Election: Can Democracy Survive the Inter -\nnet?\u2019.  Journal of Democracy 28(2): 63-76, https://www.journalofdemocracy.org/\nwp-content/uploads/2017/04/07_28.2_Persily-web.pdf (accessed 1\u00a0April\u00a02020).\nPhillips, Whitney (2015) This Is Why We Can\u2019t Have Nice Things: Mapping the Relation -\nship Between Online Trolling and Mainstream Culture . C ambridge, MA: MIT Press.\nPhillips, Whitney (2018) \u2018The Oxygen of Amplification: Better Practices for Reporting \non Extremists, Antagonists and Manipulators Online\u2019, New York: Data & Society \nResearch Institute, https://datasociety.net/library/oxygen-of-amplification/ \n(accessed 1\u00a0April\u00a02020).\nPhillips, Whitney and Ryan Milner (2018) The Ambivalent Internet: Mischief, Oddity, \nand Antagonism Online . Cambridge: Polity Press.\nPleijter, Alexander (2017) \u2018De nepnieuwslawine zonder nepnieuws\u2019, Villamedia, \n17\u00a0November, https://www.villamedia.nl/artikel/pas-op-die-nepnieuwslawine-\nis-niet-meer-dan-een-sneeuwvlok (accessed 1\u00a0April\u00a02020).\n278  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nPohjonen, Matti and Sahana Udupa (2017) \u2018Extreme Speech Online: An Anthropological \nCritique of Hate Speech Debates\u2019, International Journal of Communication,  11: 1173-1191.\nPosetti, Julie and Alice Matthews (2018) \u2018A Short Guide to the History of \u2018Fake News\u2019 \nand Disinformation\u2019, Washington, DC: International Center for Journalists, \nhttps://www.icfj.org/sites/default/files/2018-07/A%20Short%20Guide%20to%20\nHistory%20of%20Fake%20News%20and%20Disinformation_ICFJ%20Final.\npdf (accessed 1\u00a0April\u00a02020).\nPoynter (2019) \u2018A Guide to Anti-misinformation Actions around the World\u2019, St. \nPetersburg, FL: The Poynter Institute, https://www.poynter.org/ifcn/anti-\nmisinformation-actions/ (accessed 1\u00a0April\u00a02020).\nPuschmann, Cornelius (2018) \u2018Beyond the Bubble: Assessing the Diversity of Political \nSearch Results\u2019, Digital Journalism , 7(6): 824-843, https://doi.org/10.1080/21670\n811.2018.1539626.\nPuschmann, Cornelius (2017) \u2018How Significant Is Algorithmic Personalization in \nSearches for Political Parties and Candidates?\u2019, Digital Society Blog , Alexander \nvon Humboldt Institute for Internet and Society (HIIG), https://www.hiig.de/\nen/personalized-search-results-elections/ (accessed 1\u00a0April\u00a02020).\nRatkiewicz, Jacob, Michael D. Conover, Mark Meiss, Bruno Goncalves, Alessandro \nFlammini and Filippo Menczer (2011) \u2018Detecting and Tracking Political Abuse in \nSocial Media\u2019, Proceedings of the Fifth International AAAI Conference on Weblogs \nand Social Media, Barcelona, Spain, July, https://www.aaai.org/ocs/index.php/\nICWSM/ICWSM11/paper/view/2850/3274 (accessed 1\u00a0April\u00a02020).\nReid, John, Bastiaan Geleijnse and Jean-Marc van Tol (2018) \u2018Fokke en Sukke hebben \nzitting in de taskforce nepnieuws\u2019, Cartoon, 17\u00a0January, http://www.foksuk.nl/nl/?cm=79&ctime=1516143600&cid=7814 (accessed 1\u00a0April\u00a02020).\nRenner, Nausicaa (2017) \u2018Memes Trump Articles on Breitbart\u2019s Facebook Page\u2019, \nColumbia Journalism Review , 30\u00a0January, https://www.cjr.org/tow_center/\nmemes-trump-articles-on-breitbarts-facebook-page.php (accessed 1\u00a0April\u00a02020).\nRieder, Bernhard (2018) \u2018Facebook\u2019s App Review and How Independent Research Just \nGot a Lot Harder\u2019, Politics of Systems blog, 11\u00a0August, http://thepoliticsofsystems.\nnet/2018/08/facebooks-app-review-and-how-independent-research-just-got-a-\nlot-harder/ (accessed 1\u00a0April\u00a02020).\n\u2014 (2012) \u2018The Refraction Chamber: Twitter as Sphere and Network\u2019, First Monday , \n17(11), https://firstmonday.org/ojs/index.php/fm/article/view/4199/3359 (accessed \n1\u00a0April\u00a02020).\n\u2014, Ariadna Matamoros-Fern\u00e1ndez and \u00d2scar Coromina (2018) \u2018From Ranking \nAlgorithms to \u2018Ranking Cultures\u2019: Investigating the Modulation of Visibility in \nYouTube Search Results\u2019, Convergence: The International Journal of Research into \nNew Media Technologies , 24(1): 50-68, https://doi.org/10.1177/1354856517736982.\nRefe Ren ce S 279\n\u2014, Rasha Abdulla, Thomas Poell, Robbert Woltering, Liesbeth Zack (2016) \u2018Data \nCritique and Analytical Opportunities for Very Large Facebook Pages. Lessons \nLearned from Exploring \u201cWe Are All Khaled Said\u201d\u2019, Big Data & Society, 2.2: 1-22, \nhttps://doi.org/10.1177/2053951715614980.\nRieder, Bernhard (2015). YouTube Data Tools (Version 1.11), software, https://tools.\ndigitalmethods.net/netvizz/youtube/ (accessed 1\u00a0April\u00a02020).\nRNTC (2019). \u2018Challenging fake news\u2019, webpage, Hilversum: RNTC, https://rntc.\ncom/blog/challenging-fake-news (accessed 1\u00a0April\u00a02020).\nRoberts, Sarah T. (2016) \u2018Commercial Content Moderation: Digital Laborers\u2019 Dirty \nWork\u2019, in Safiya Umoja Noble and Brendesha M. Tynes (eds.) The Intersectional \nInternet . New York, NY: Peter Lang, pp.\u00a0147-160.\nRobertson, Adi (2017) \u2018After Its 4chan Slip-up, Is It Time for Google to Drop Top \nStories?\u2019, The Verge , 3\u00a0October, https://www.theverge.com/2017/10/3/16413082/\ngoogle-4chan-las-vegas-shooting-top-stories-algorithm-mistake (accessed \n1\u00a0April\u00a02020).\nRoBhat Labs (2017) \u2018Identifying Propaganda Bots on Twitter\u2019, Medium , 31\u00a0October, \nhttps://medium.com/@robhat/identifying-propaganda-bots-on-twitter-\n5240e7cb81a9 (accessed 1\u00a0April\u00a02020).\nRoeder, Oliver (2018) \u2018We Gave You 3 Million Russian Troll Tweets. Here\u2019s What \nYou\u2019ve Found So Far\u2019, FiveThirtyEight , 8\u00a0August, https://fivethirtyeight.\ncom/features/what-you-found-in-3-million-russian-troll-tweets/ (accessed \n1\u00a0April\u00a02020).\nRoermund, Jannes van (2017) \u2018Wie zijn de mensen achter het nepnieuws in Neder -\nland?\u2019 Nieuwe Revu , 26\u00a0April, https://revu.nl/artikel/2933/wie-zijn-de-mensen-\nachter-het-nepartikel-in-nederland (accessed 1\u00a0April\u00a02020).\nRoig-Franzia, Manuel (2019) \u2018Inside the Spectacular Fall of the Granddaddy of Right-\nWing Conspiracy Sites\u2019, The Washington Post , 2\u00a0April, https://www.washington -\npost.com/lifestyle/style/inside-the-spectacular-fall-of-the-granddaddy-of-right-\nwing-conspiracy-sites/2019/04/02/6ac53122-3ba6-11e9-a06c-3ec8ed509d15_story.\nhtml (accessed 1\u00a0April\u00a02020).\nRogers, Richard (2019) Doing Digital Methods. Los Angeles: Sage.\n\u2014 (2018a) \u2018Otherwise Engaged: Social Media from Vanity Metrics to Critical \nAnalytics\u2019, International Journal of Communication , 12: 450-472.\n\u2014 (2018b) \u2018Digital Methods for Cross-Platform Analysis\u2019, in Jean Burgess, Alice \nMarwick and Thomas Poell (eds.), SAGE Handbook of Social Media . London: \nSage, pp.\u00a091-110.\n\u2014 (2017) \u2018Foundations of Digital Methods: Query Design\u2019 in Mirko Tobias Sch a\u0308f er \nand Karin Van Es (eds.) The Datafied Society. Studying Culture through Data, \nAmsterdam: Amsterdam University Press, pp.\u00a075-94.\n\u2014 (2013) Digital Methods , Cambridge, MA: MIT Press.\n280  T he Poli Ti cS  of  Social Media Mani Pu laTi on\n\u2014 (2013). Debanalizing Twitter: The Transformation of an Object of Study, in \nProceedings of the 5th Annual ACM Web Science Conference , New York, NY: ACM, \npp.\u00a0356-365, https://doi.org/10.1145/2464464.2464511.\n\u2014 (2005) \u2018Poignancy in the US Political Blogosphere\u2019, Aslib Proceedings: New Infor -\nmation Perspectives , 57(4): 356-368, https://doi.org/10.1108/00012530510612086.\nRomero, Jessica (2019) \u2018Preventing Inauthentic Behavior on Instagram\u2019, Facebook \nNewsroom , 25\u00a0April, https://newsroom.fb.com/news/2019/04/preventing-\ninauthentic-behavior-on-instagram/ (accessed 1\u00a0April\u00a02020).\nRone, Julia (2019) \u2018Why Talking about \u201cDisinformation\u201d Misses the Point when \nConsidering Radical Right \u201cAlternative\u201d Media\u2019, Inforrm\u2019s Blog , The International \nForum for Responsible Media Blog, 9\u00a0January, https://inforrm.org/2019/01/09/\nwhy-talking-about-disinformation-misses-the-point-when-considering-radical-\nright-alternative-media-julia-rone/ (accessed 1\u00a0April\u00a02020).\nRony, Md Main Uddin, Naeemul Hassan and Mohammad Yousuf (2017) \u2018BaitBuster: \nDestined to Save You Some Clicks\u2019, Proceedings of Computation+Journalism \nSymposium , Northwestern University, October, https://northwestern.app.box.\ncom/s/rim87qta59zgtykx7a149dzmldalm72p (accessed 1\u00a0April\u00a02020).\nRoozenbeek, Jon and Sander van der Linden (2018) \u2018The Fake News Game: Actively \nInoculating Against the Risk of Misinformation\u2019, Journal of Risk Research 22(5): \n570-580, DOI: 10.1080/13669877.2018.1443491.\nRTL Nieuws (2018) \u2018Alles over complottheorie QAnon \u2013 #TrumpUpdate 77\u2019, RTL \nNieuws, 15\u00a0September, https://www.rtlnieuws.nl/nieuws/laatste-videos-nieuws/\nvideo/4417801/alles-over-complottheorie-qanon-trumpupdate-77 (accessed \n1\u00a0April\u00a02020).\nRuusuvirta, Outi (2010) \u2018Much Ado About Nothing? Online Voting Advice Ap -\nplications in Finland\u2019, in Cedroni, Lorella and Diego Garzia (eds.), Voting Advice \nApplications in Europe: The State of the Art , Napoli: ScriptaWeb, pp.\u00a047-77.\nSa\u0308ngerlaub, Alexander, Miriam Meier and Wolf-Dieter Ru\u0308hl (2017) \u2018Fakten statt Fakes: \nDas Pha\u0308nomen \u201cFake News\u201d\u2019, Berlin: Stiftung Neue Verantwortung, https://www.\nstiftung-nv.de/sites/default/files/snv_fakten_statt_fakes.pdf (accessed 1\u00a0April\u00a02020).\nShane, Scott (2018) \u2018How Unwitting Americans Encountered Russian Operatives \nOnline\u2019, New York Times , 18\u00a0February, https://www.nytimes.com/2018/02/18/\nus/politics/russian-operatives-facebook-twitter.html (accessed 1\u00a0April\u00a02020).\nShao, Chengcheng, Giovanni Luca Ciampaglia, Onur Varol, Kai-Cheng Yang, Ales -\nsandro Flammini and Filippo Menczer (2018) \u2018The Spread of Low-Credibility \nContent by Social Bots\u2019, Nature Communications  9(4787), https://doi.org/10.1038/\ns41467-018-06930-7.\nShaw, Eugene (1979) \u2018Agenda-Setting and Mass Communication Theory\u2019, International \nCommunication Gazette  25(2): 96-105, https://doi.org/10.1177/001654927902500203.\nRefe Ren ce S 281\nShead, Sam (2019) \u2018Facebook Reacts to Live-Streamed Footage of the Deadly New \nZealand Mass Shooting that was Posted on its Platform\u2019, Business Insider Aus -\ntralia , 15\u00a0March, https://www.thisisinsider.com/facebook-responds-to-alleged-\nlive-stream-of-christchurch-shooting-2019-3 (accessed 1\u00a0April\u00a02020).\nShieber, Jason (2017) \u2018How Reports from 4chan on the Las Vegas Shooting Showed \nUp on Google Top Stories\u2019, TechCrunch  blog, 2\u00a0October, http://social.techcrunch.\ncom/2017/10/02/how-reports-from-4chan-on-the-las-vegas-shooting-showed-\nup-on-google-top-stories/ (accessed 1\u00a0April\u00a02020).\nSilverman, Craig, J. Lester Feder, Saska Cvetkovska and Aubrey Belford (2018) \n\u2018Macedonia\u2019s Pro-Trump Fake News Industry Had American Links, and Is Under \nInvestigation for Possible Russia Ties\u2019, Buzzfeed News , 18\u00a0July, https://www.\nbuzzfeednews.com/article/craigsilverman/american-conservatives-fake-news-\nmacedonia-paris-wade-libert (accessed 1\u00a0April\u00a02020).\nSilverman, Craig (2016) \u2018This Analysis Shows How Viral Fake Election News Stories \nOutperformed Real News On Facebook\u2019, Buzzfeed News , 16\u00a0November, https://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook (accessed 1\u00a0April\u00a02020).\nSilverman, Craig and Lawrence Alexander (2016) \u2018How Teens in the Balkans are \nDuping Trump Supporters with Fake News\u2019, Buzzfeed New s, 3\u00a0November, https://\nwww.buzzfeednews.com/article/craigsilverman/how-macedonia-became-a-\nglobal-hub-for-pro-trump-misinfo (accessed 1\u00a0April\u00a02020).\nSilverman, Craig and Jeremy Singer-Vine (2016) \u2018The True Story Behind the Biggest \nFake News Hit of The Election\u2019, Buzzfeed News , 16\u00a0December, https://www.\nbuzzfeednews.com/article/craigsilverman/the-strangest-fake-news-empire \n(accessed 1\u00a0April\u00a02020).\nSilverman, Craig, Lauren Strapagiel, Hamza Shaban, Ellie Hall and Jeremy Singer-\nVine (2016) \u2018Hyperpartisan Facebook Pages are Publishing False and Misleading \nInformation at an Alarming Rate\u2019, Buzzfeed News , 20\u00a0October, https://www.\nbuzzfeednews.com/article/craigsilverman/partisan-fb-pages-analysis (accessed \n1\u00a0April\u00a02020).\nSismondo, Sergio (2017) \u2018Post-truth?\u2019, Social Studies of Science , 47(1): 3-6, https://\ndoi.org/10.1177/0306312717692076.\nSnyder, Timothy (2018) The Road to Unfreedom: Russia, Europe, America . New York: \nTim Duggan Books.\nSolon, Olivia and Sam Levin (2016) \u2018How Google\u2019s Search Algorithm Spreads False \nInformation with a Rightwing Bias\u2019, The Guardian , 16\u00a0December, https://www.\ntheguardian.com/technology/2016/dec/16/google-autocomplete-rightwing-bias-\nalgorithm-political-propaganda (accessed 1\u00a0April\u00a02020).\nSommer, Will (2018) \u2018Instagram Is the Alt-Right\u2019s New Favorite Haven\u2019, The Daily \nBeas t, 30\u00a0October.\n282  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nSouthern Poverty Law Center (n.d.), WorldNetDaily blog, Southern Poverty Law \nCenter, https://www.splcenter.org/fighting-hate/extremist-files/group/world -\nnetdaily (accessed 1\u00a0April\u00a02020).\nSrnicek, Nick (2017) Platform Capitalism . Cambridge: Polity Press.\nStatista (2019) \u2018Most Famous Social Network Sites Worldwide as of January\u00a02019, \nRanked by Number of Active Users (in Millions)\u2019, Statista webpage, https://www.\nstatista.com/statistics/272014/global-social-networks-ranked-by-number-of-\nusers/ (accessed 1\u00a0April\u00a02020).\nStill, Keith (2017) \u2018Inauguration Crowd Size\u2019, Crowd Safety and Risk Analysis blog, \nManchester: Manchester Metropolitan University, http://www.gkstill.com/CV/\nProjects/Counting.html (accessed 1\u00a0April\u00a02020).\nSwedish Civil Contingencies Agency (2018) Countering Information Influence Activi -\nties: A Handbook for Communicators . Karlstad: Swedish Civil Contingencies Agency \n(MSB), https://www.msb.se/RibData/Filer/pdf/28698.pdf (accessed 1\u00a0April\u00a02020).\nSwedish Media Council (2019) K\u00e4llkritik \u2013 en utmaning, Stockholm: State Media \nCouncil, 5\u00a0March, https://statensmedierad.se/larommedier/kallkritikvemvad -\nvarfor/kallkritikenutmaning.422.html (accessed 1\u00a0April\u00a02020).\nTan, Yvette (2017) \u2018There\u2019s a Vending Machine Selling Fake Instagram Likes, Because \nThis is What We\u2019ve Become\u2019, Mashable , 7\u00a0June, https://mashable.com/2017/06/07/\ninstagram-likes-vending-machine/ (accessed 1\u00a0April\u00a02020).\nTandoc Jr., Edson C., Zheng Wei Lim and Richard Ling (2018) \u2018Defining \u201cFake News\u201d: \nA Typology of Scholarly Definitions\u2019, Digital Journalism  2: 137-153, https://doi.or\ng/10.1080/21670811.2017.1360143.\nThomas, David R. (2006) \u2018A General Inductive Approach for Analyzing Qualitative \nEvaluation Data\u2019, American Journal of Evaluation 27(2): 238-246, https://doi.\norg/10.1177/1098214005283748.\nTimberg, Craig (2017) \u2018Russian Propaganda May Have Been Shared Hundreds of \nMillions of Times, New Research Says\u2019, Washington Post, 5\u00a0October, https://www.\nwashingtonpost.com/news/the-switch/wp/2017/10/05/russian-propaganda-\nmay-have-been-shared-hundreds-of-millions-of-times-new-research-says/ \n(accessed 1\u00a0April\u00a02020).\nTripodi, Francesca (2018) \u2018Alternative Facts, Alternative Truths\u2019, Points blog , Data & \nSociety, 23\u00a0February, https://points.datasociety.net/alternative-facts-alternative-\ntruths-ab9d446b06c (accessed 1\u00a0April\u00a02020).\nTucker, Joshua A., Andrew Guess, Pablo Barber\u00e1, Cristian Vaccari, Alex -\nandra Siegel, Sergey Sanovich, Denis Stukal, and Brendan Nyhan (2018) \n\u2018\nSocial Media, Political Polarization, and Political Disinformation: A \nReview of the Scientific Literature\u2019, Report, Menlo Park, CA: William and \nFlora Hewlett Foundation, https://hewlett.org/wp-content/uploads/2018/03/\nRefe Ren ce S 283\nSocial-Media-Political-Polarization-and-Political-Disinformation-Literature-\nReview.pdf (accessed 1\u00a0April\u00a02020).\nTufekci, Zeynep (2018) \u2018YouTube, the Great Radicalizer\u2019, The New York Times , \n10\u00a0March. https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-\npolitics-radical.html (accessed 1\u00a0April\u00a02020).\nTurner, Stephen (2001) \u2018What is the Problem with Experts?\u2019, Social Studies of Science  \n31(1): 123-149, https://doi.org/10.1177/030631201031001007.\nTuters, Marc, and Dani\u00ebl De Zeeuw (2020) \u2018Teh Internet Is Serious Business: On the \nDeep Vernacular Web Imaginary\u2019, Cultural Politics , forthcoming.\nTuters, Marc, Emilija Jokubauskait\u0117 and Daniel Bach (2018) \u2018Post-Truth Protest: \nHow 4chan Cooked Up the Pizzagate Bullshit\u2019, M/C: A Journal of Media and \nCulture 21(3), http://journal.media-culture.org.au/index.php/mcjournal/article/\nview/1422 (accessed 1\u00a0April\u00a02020).\nVaidhyanathan, Siva (2018) \u2018Why Facebook Will Never Be Free of Fakes\u2019, New York \nTimes , 5\u00a0September, https://www.nytimes.com/2018/09/05/opinion/facebook-\nsandberg-congress.html (accessed 1\u00a0April\u00a02020).\nVaidhyanathan, Siva (2017) \u2018Facebook Wins, Democracy Loses\u2019, New York Times , \n8\u00a0September, https://www.nytimes.com/2017/09/08/opinion/facebook-wins-\ndemocracy-loses.html (accessed 1\u00a0April\u00a02020).\nVassil, Kristjan (2011) Voting smarter? The Impact of Voting Advice Applications \non Political Behavior , PhD dissertation, European University Institute, Tartu, \nEstonia.\nVenturini, Tommaso (2019) \u2018From Fake to Junk News: the Data Politics of Online \nVirality\u2019, in Didier Bigo, Engin Isin, and Evelyn Ruppert (eds), Data Politics: \nWorlds, Subjects, Rights . London: Routledge, pp.\u00a0123-144.\nVolkova, Svitlana, Kyle Shaffer, Jin Yea Jang and Nathan Hodas (2017) \u2018Separating \nFacts from Fiction: Linguistic Models to Classify Suspicious and Trusted News \nPosts on Twitter\u2019, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics , 2: 647-653, DOI: 10.18653/v1/P17-2102.\nVolpicelli, Gian (2019) \u2018This is How Facebook\u2019s News Feed Fact-Checking Will Work \nin the UK\u2019, Wired , 11\u00a0January, https:/ /www.wired.co.uk/article/full-fact-facebook-\nfact-checking (accessed 1\u00a0April\u00a02020).\nVosoughi, Soroush, Deb Roy and Sinan Aral (2018) \u2018The Spread of True and False \nNews Online\u2019, Science , 359(6380): 1146-1151, DOI: 10.1126/science.aap9559.\nWalgrave, Stefaan, Michiel Nuytemans and Koen Pepermans (2009) \u2018Voting Aid \nApplications and the Effect of Statement Selection\u2019, West European Politics  32(6): \n1161-1180, https://doi.org/10.1080/01402380903230637.\n284  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nWang, Rong, Wenlin Liu, and Shuyang Gao (2016). \u2018Hashtags and Informa -\ntion Virality in Networked Social Movement: Examining Hashtag Co-\noccurrence Patterns\u2019, Online Information Review  40(7): 850-866, DOI: 10.1108/\nOIR-12-2015-0378.\nWardle, Claire (2018) \u2018Information Disorder: The Essential Glossary\u2019, Shorenstein \nCenter, Cambridge, MA: Harvard Kennedy School, https://firstdraftnews.org/\nwp-content/uploads/2018/07/infoDisorder_glossary.pdf (accessed 1\u00a0April\u00a02020).\nWardle, Claire and Hossein Derakhshan (2017) \u2018Information Disorder: Toward \nan Interdisciplinary Framework for Research and Policy Making\u2019, Strasbourg: \nCouncil of Europe, 27\u00a0September, https://rm.coe.int/information-disorder-toward-\nan-interdisciplinary-framework-for-researc/168076277c (accessed 1\u00a0April\u00a02020).\nWaters, Richard (2017) \u2018Facebook and Google Help Showcase Las Vegas Fake News\u2019, \nFinancial Times , 3\u00a0October, https://www.ft.com/content/030184c2-a7f1-11e7-\nab55-27219df83c97 (accessed 1\u00a0April\u00a02020).\nWeisman, Jonathan (2018) (((Semitism))): Being Jewish in America in the Age of \nTrump . New York: St. Martin\u2019s Press.\nWeiss, Ben (2018) \u2018Meet the Renegades of the Intellectual Dark Web\u2019, New York Times , \n8\u00a0May. https://www.nytimes.com/2018/05/08/opinion/intellectual-dark-web.\nhtml (accessed 1\u00a0April\u00a02020).\nWendling, Mike (2018a) \u2018The (Almost) Complete History of \u201cFake News\u201d\u2019, BBC \nNews , 22\u00a0January.\n\u2014 (2018b). Alt-Right: From 4chan to the White House . London: Pluto Press.\nWieringa, Maranke, Tim de Winkel and Callum Lewis (2017) \u2018Wie is de waakhond \nop sociale media?\u2019, report, Utrecht: Utrecht Data School.\nWoolley, Samuel and Philip N. Howard (2016) \u2018Social Media, Revolution, and the \nRise of the Political Bot\u2019, in Piers Robinson, Philip Seib and Romy Fr\u00f6hlich (eds.), \nHandbook of Media, Conflict and Security . New York, NY: Routledge, pp.\u00a0282-292.\nWynne, Brian (1991) \u2018Knowledge in Context\u2019, Science, Technology & Human Values  \n16(1): 111-121.\nYouTube (2019) \u2018Related Channels Discontinued May\u00a02019\u2019, https://support.google.\ncom/youtube/answer/7216516 (accessed 1\u00a0April\u00a02020).\n\u2014 (2018) \u2018Press \u2013 YouTube\u2019, https://www.youtube.com/intl/en-GB/yt/about/press/ \n(accessed 1\u00a0April\u00a02020).\nZannettou, Savvas, Tristan Caulfield, Emiliano De Cristofaro, Nicolas Kourtelris, \nIlias Leontiadis, Michael Sirivianos, Gianluca Stringhini, and Jeremy Blackburn \n(2017) \u2018The Web Centipede: Understanding How Web Communities Influence \nEach Other through the Lens of Mainstream and Alternative News Sources\u2019, \n17th ACM Internet Measurement Conference , 405-17, arXiv:1705.06947.\nRefe Ren ce S 285\nvan Zijl, Frank and Huib Modderkolk (2017) \u2018Generaal: Nederland kan digitale \ndreiging niet aan\u2019, de Volkskrant , 29\u00a0August, https://www.volkskrant.nl/nieuws-\nachtergrond/generaal-nederland-kan-digitale-dreiging-niet-aan~b043212e/ \n(accessed 1 April 2020).\nvan Zoonen, Liesbet, Farida Vis and Sabina Mihelj (2011) \u2018YouTube Interactions \nbetween Agonism, Antagonism and Dialogue: Video Responses to the Anti-Islam \nFilm Fitna\u2019, New Media & Society 13(8): 1283-300, DOI:10.1177/1461444811405020.\n\n Index\nReferences to illustration are in bold .\n4CAT tool\u2003174, 179, 215\n4chan/pol imageboard\u200398\ncharacteristics\u2003170ephemerality of content\u2003174front page\u2003175Pizzagate conspiracy theory\u2003170-171politics board\u2003174QAnon conspiracy theory\u2003171research study\nclickbait sources\u2003178conspiracy sources\u2003178disinformation\u2003178domains extraction 177Dutch junk news\u2003186-187, 187 , 190 , 195, \n213-214 (table), 215\nDutch sphere\u2003177haystack to needle approach\u2003176, 177-178hyperpartisan sources\u2003178mainstream news\u2003177, 243, 246methodology\u2003176-177needle to haystack approach\u2003178-179news types\u2003194Russian URLs, most frequent\u2003215 \n(table)\nYouTube links\u2003180\nAfriyie, Jerry\u2003131Algorithm Watch\u2003100\u2018alt-right\u2019\nconspiracy\u2003233definition\u2003174, 218political discussion\u200392-93\n\u2018alternative facts\u2019\u200329-30, 51\ninfrastructures\u2003241see also  \u2018truthiness\u2019\nanti-Islam\nJihad Watch  site\u2003127\nRussian trolling\u200325, 33, 148Twitter\u2003127Wilders\u2019 video\u200335\nAPI (Application Programming Interface)\nFacebook\u200349, 50, 54Instagram Follower Collector\u2003159Pushshift\u2003174, 179Twitter\u2003127\nastroturfing\u200320, 34fn2\ndefinition\u200325examples\u200326fake follower base\u200335see also  fake news\nBaudet, Thierry\u200377, 83, 171Bosma, Martin\u2003230Breitbart News , hyperpartisan site\u200374, 195, 240\nBrexit referendum (UK)\u200325, 49, 71, 220Britain\u2019s Future group, transparency\u200349, 50Brussels, suicide bombings (2016)\u200320, 33, 91, \n148\nBuzzfeed News \u200346\nfake news\ndefinition\u200374, 77, 101on Facebook, analysis\u200347-48, 243in USA presidential elections \n(2016)\u200372, 74\nmethodology\u200374, 75NRC Handelsblad , comparison\u200373-75\nBuzzSumo, media query tool\u200346, 47, 74\nand Dutch EU parliamentary elections \n(2019)\u200376-77\nCafe Weltschmertz, YouTube channel, \nscreenshot\u2003229, 229\nCambridge Analytica case\u200320fn1, 28, 50, 53campaign strategy, fake news as\u200352clickbait\n4chan/pol imageboard\u2003178conspiracy engagement, Dutch provincial \nelections (2019)\u200388\ndefinition\u200324Dutch consumption of\u2003240-241examples\u200324, 27, 36features\u200346Netherlands\u200336Prankster site\u2003163\nClinton, Hillary\u200374, 75Compare List tool\u2003132computational propaganda\ndefinition\u200324examples\u200324-25study\u200334-35\nCoosto, social media management suite\u2003128counter-narratives, to disinformation\u200355CrowdTangle, media monitoring software\u200346, \n50, 71\nculture\nhackers\u200399hacking\u2003100\n\u2018dark globalization\u2019\u200326\u2018dark posts\u2019\u200325De Dagelijkse Standaard\u200378, 83, 86, 90, 106, \n118, 119, 160, 201, 246\nDe Groene Amsterdammer \u2003131\nDe Hoax-Wijzer , junk news categorization\u200378, \n212-214\nDe Volkskrant \u2003123\n288  T he Poli Ti cS  of  Social Media Mani Pu laTi on\ndigital literacy, and disinformation\u200356\nDigital Methods Initiative, Search Engine \nScraper\u2003102, 152see also  DMI-TCAT\ndisinformation\n4chan/pol imageboard\u2003178countermeasures\nautomated\u200355civil society investment\u200357counter-narratives\u200355-56digital hygiene\u200356digital literacy\u200356EU task force\u200336, 37 , 53, 54\ngovernmental\u200353participation in public debate\u200357social media company \nregulation\u200354-55\nand digital literacy\u200356features\u200346HIV virus, attribution to USA\u2003239misinformation, comparison\u200323, 51Netherlands\u200332, 36-9Russian\u200320see also  political disinformation; \u2018wilder-\nness of mirrors\u2019\nDMI-TCAT (Digital Methods Initiative, Twitter \nCapturing and Analysis Toolkit)\u2003128-129\nDotan, singer-songwriter, fake fans\u2003123-124dubiousness, determination of\u200321Dutch EU parliamentary elections (2019)\nBuzzSumo media query tool\u200376-77clickbait/conspiracy engagement\u2003 89\nfake news\u200377, 242-243hyperpartisan sites\u200387 (table)mainstream/hyperpartisan \nengagement\u2003 89\nmainstream/junk-like articles\u200383, 84, \n84-85 , 129\nparty names\u200377political parties, list\u2003103research design\u200376-77themes\u200377, 83trend analysis\u200384\nDutch junk news\n4chan/pol imageboard\u2003186-187, 187 , 190 , \n195, 213-214 (table), 215\n4chan/pol research study\u2003186-188, 187-188categories\u2003187-188, 189-194 , 195-196\ndomains\u2003212-214 (list)Reddit, research study\u2003181-182, 182-185 , \n188, 189 , 196, 197-199 , 198-199, 200 \n(table), 201, 213 -214 (table)\nresearch query\u2003173\nDutch media landscape\u200378Dutch media sphere\nright-wing punditry\u2003233-234YouTube\u2003 see YouTube, Dutch media sphere\nDutch parliamentary elections (2017)\nfake news\u200373hyperpartisan sites\u200387 (table)mainstream/junk-like articles\u200387 (table)Twitter trolling of political leaders\u2003125-\n127, 126\nDutch political Instagram\nAPI Instagram Follower Collector\u2003159fake followers\u2003160-161, 162 , 163, 246\nfollower ecologies\u2003159-160, 161hashtags about leaders/parties/political \ndiscussions\u2003157 (list)\nhyperpartisan/satirical posts\u2003156Instagram Scraper  tool\u2003152, 154\njunk content\u2003152-153, 154 , 164, 246\njunk information sources\u2003159mainstream media outlets\u2003159, 165mainstream news\u2003164, 246most liked posts per hashtag\u2003156, 157, \n158, 159\nmost liked posts, junk/not-junk\u2003157political hashtags\u2003152, 154 (table)political parties and leaders\u2003159posts per hashtag\u2003152, 154, 155\nmetadata\u2003152\nresearch findings\u2003164-166, 245-246research protocol\u2003150, 151 , 152\nDutch political parties\nissue keywords\u2003105-106left-right spectrum\u2003223-224standpoint space\u2003106table\u2003103\nDutch provincial elections (2019)\nBuzzfeed News  study\u200380\nclickbait/conspiracy engagement\u2003 88\ndata analysis\u200379-83, 80 , 81, 82\nfake news\u200373hyperpartisan sites\u200387 (table)mainstream/hyperpartisan \nengagement\u2003 88\nmainstream/junk-like articles\u2003 80-82 , 83, \n87 (table), 129\nMH17 aircraft downing, junk sources\u2003137-\n138, 137\npolitical leaders, junk sources\u2003140 , 141\npolitical parties, list\u2003103PS2019, junk sources\u2003139 , 141\nresearch design\u200375-76themes\u200376top tweets, topics\u2003134trollers\u2003132-135Zwarte Piet, junk sources\u2003136\nDutch Twitter\u2003124, 242\nDutch provincial elections (2019), top \ntweets\u2003134\njunk news\u2003143, 254research questions, overview\u2003128 (table)trolling of political leaders, Dutch \nparliamentary elections (2017)\u2003125-126, 126, 244-245\nelections project, Facebook\u200350engagement concept, problems with\u200391, 94\nin de X 289\nFacebook\nAPI\u200349, 50, 54\nelections project\u200350fact-checking\u200338-39, 72fake accounts\u200328fake news\u200347, 52, 72, 90, 93\nBuzzfeed News  analysis\u200347-48, 74, 243\nhyperpartisan groups\u200329junk news\u2003243keywords, Google.nl search engine\u2003103, \n104 (table)\nNew York Times description\u200328-29political ad transparency tool\u200349, 50riots inspired by\u200349Social Science One, partnership\u200350studies on\u200371-72\nfact-checking\u200330, 52\nFacebook\u200338, 72and fake news\u2003220, 241initiatives\u200355Netherlands\u200339research\u200337-38websites\u200337see also  \u2018alternative facts\u2019\nfake\nfans, of Dotan, singer-songwriter\u2003123-124followers, Netherlands\u200334\nfake accounts\nFacebook\u200328Instagram\u2003149tactics\u200335see also  hybrid accounts\nfake news\u200319\nantecedents\u200321-22, 51as campaign strategy\u200352consumers of\u200343-44countermeasures\u2003241definitions\u200322, 46, 218\nBuzzfeed News \u200374, 77, 101\ndetected and eliminated\u200338detection\u200339, 46Dutch EU parliamentary elections \n(2019)\u200377, 242-243\nDutch parliamentary elections (2017)\u200373, \n74, 87\nDutch political space\u2003230, 231-232 , \n232-233\nDutch provincial elections (2019)\u200373examples\u200338 , 218\nFacebook\u200347, 52, 72, 90and fact-checking\u2003220, 241vs free press\u200322-23on HIV\u200328junk news, comparison\u200378mainstream news\ndistinction\u200377USA elections (2016)\u200342, 43 , 48, 72\nas moral panic\u2003247-248and network propaganda\u2003207, 221popularity of\u2003221quizzes\u200339sharing of\u200344and social media platforms\u200324, 71and social unrest\u200323studies\u2003220in USA presidential elections (2016)\u200372websites\u200348see also  astroturfing; fact-checking; junk \nnews; yellow journalism\nfake rallies (2016)\u200326 (table)Field Guide to Fake News\u200339filter bubble\u200342France, Gilet Jaunes\u200349-50FvD (Forum for Democracy)\u2003160, 223\nGatestone Institute \u2003127\nGeenStijl  blog\u200378, 79, 88, 89, 92, 160\nsee also  geenstijl.nl\ngeenstijl.nl\u2003124, 133, 137, 138, 141, 200\nGilet Jaunes, France\u200349-50Goodwin, Matthew & Eatwell, Roger\u2003220Google News\u2003100Google search engine\nalgorithm\u2003101junk news\u2003101learning capacity\u2003101see also  Google.nl search engine\nGoogle.nl search engine\noptimization strategies\u2003119research study\nDutch EU parliamentary elections \n(2019)\u2003103\nDutch parliamentary parties \n(2019)\u2003102, 103\nDutch provincial elections (2019)\u2003103Facebook keywords\u2003103, 104 (table)hyperpartisan material\u2003119junk news\u2003105, 107 , 118-120, 244\nclimate\u2003 117\neconomy\u2003 110, 117\nenvironment\u2003 109, 112, 113\nEU parliamentary elections\u2003115-\n116, 117 , 118\nEuropean Union\u2003 117\nforeign affairs\u2003114, 114future innovation\u2003112main websites\u2003118migration\u2003115 , 117\npolarizing topics\u2003114society\u2003111susceptibility to\u2003101, 119\npolitical party keywords\u2003102, 103, 105-106political party platforms\u2003104 (list)political party standpoint space\u2003106-108research methodology\u2003102research questions\u2003101-102, 118research results\u2003118-119Search Engine Scraper, use\u2003103vernacular political issue space\u2003108, \n109-112 , 112, 113-114 , 114-115, 119\n290  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nHIV, fake news\u200328\nhomo-nationalism\u2003233hybrid accounts\u200335HypeAuditor tool\u2003149, 160-161, 163, 166hyperpartisan\ndefinition\u2003233groups, Facebook\u200329news, mainstream news, distinction\u200378\nhyperpartisan sites\nDutch parliamentary elections (2017)\u200387 \n(table)\nDutch EU parliamentary elections \n(2019)\u200387 (table)\ninfluence campaigning\u200319, 39-40, 48, 255\npervasiveness\u200353Russian\u200353\nUSA\u200320, 26-72, 28\nstrategies\u200320, 27-28\n\u2018information cacophony\u2019\u200327Instagram\u200347\nfake accounts\u2003149junk news\u2003147-148, 150meme warfare\u2003148, 150Russian disinformation on\u2003148see also  Dutch political Instagram\nInstagram Scraper  tool\u2003152, 166\nInternet Research Agency\u200346, 141Islam\u2003see  anti-Islam\nIssuedramaturg project\u2003100\nJihad Watch  site, anti-Islam\u2003127\njunk news\ncriteria\u200378\nDe Hoax-Wijzer , categorization\u2003178, \n212-214\ndefinition\u200323, 101Dutch EU parliamentary elections (2019), \nmain sources\u200386, 87 (table)\nDutch provincial elections (2019)\u200387 \n(table)\nDutch Twitter\u2003143, 254examples\u200335Facebook\u2003243fake news, comparison\u200378features\u200378, 90, 172Google search engine\u2003101Instagram\u2003147-148, 150multiple platform analyses\u200391, 92persuasiveness\u200341-44Reddit research study\u2003179-80, 197studies\u200344-48as umbrella term\u2003172see also  Dutch junk news; fake news\njunk websites\u2003100, 106\nSEO analysis\u2003119\nKlaver, Jesse\u2003157Kuzu, Tunahan\u200383Las Vegas shootings (2017)\u200398liberal bias, new right narrative\u2003233\nmagic bullet theories\u200320-21\nmainstream news\n4chan/pol imageboard\u2003177, 243, 246Dutch EU parliamentary elections \n(2017)\u200386, 87 (table)\nDutch political Instagram\u2003164, 246Dutch provincial elections (2019)\u200387 (table)fake news\ndistinction\u200377USA elections (2016)\u200342, 43 , 48, 72\nhyperpartisan news, distinction\u200378junk news\nengagements\nDutch elections\u2003143MH17 aircraft\u2003 144\nZwarte Piet\u2003144\nReddit\u2003177, 243, 246threats to\u2003248\nmedia landscape\nmonitoring, policy themes\u2003249-250polarization\u2003249\n\u2018media mirage\u2019\u200327, 30-31, 52meme warfare, Instagram\u2003148, 150memes\u200326, 27MH17 aircraft, downing of\u200320, 32, 37, 53, 91, \n129, 132, 245Dutch provincial elections (2019), junk \nsources\u2003137-138, 137\njunk news, prevalence\u2003131, 249mainstream news/junk news engagement, \nin Dutch provincial and EU elections (2019)\u2003 130, 144 , 242\ntroll-/bot-like accounts\u2003133tweet traffic, Dutch provincial elections \n(2019)\u2003 134\nmisinformation\ndisinformation, comparison\u200323, 51example\u200351studies\u200347\nmoral panic\ndefinition\u2003247fake news as\u2003247-248\nmultiple platform analysis\ncomparison problems\u200391, 93junk news\u200391, 92relative engagement of content catego -\nries\u200392-93, 92\nNetherlands\nclickbait\u200336fact-checking\u200339fake followers\u200334news scene\u200331-32political disinformation\u200332Russian trolling\u200332-33see also  entries beginning with \u2018Dutch\u2019\nin de X 291\nnetwork propaganda, and fake news\u2003207, 221\nNew Knowledge\u200327\nstudy of Russian propaganda on \nInstagram\u2003148\nninefornews.nl, conspiracy/UFOlogy site\u200378, \n108, 133, 141, 181, 200, 201, 212, 246\nNRC Handelsblad\nBuzzfeed News , comparison\u200373-75\nfake news, Dutch parliamentary elections \n(2017)\u200373, 74, 87, 243, 254\nresearch method\u200374-75\nOllongren, Kajsa\u2003230Omroep PowNed\u2003206, 223, 224, 226, 233Opiniez \u2003106, 118, 119\nOpiniez.nl\u2003133, 137Overton Window\u200344, 230fn7Oxford Internet Institute (OII)\u200323, 47, 79\nJunk News Aggregator\u200378\nparty leaders, Dutch provincial elections (2019), \ntwitter traffic\u2003134\nPegida movement\u200322-23personalization\ngeographic\u2003100reduction of\u2003100search engines\u200398, 99-100and selective scraping\u2003100\nPeterson, Jordan\u2003218Pizzagate conspiracy theory, 4chan/pol \nimageboard\u2003170-171\npolicy themes 249-251\ndenial of publicity to extreme media\u2003250, \n255\nmedia training for content makers\u2003250monitoring of media landscape\u2003249-250promotion of advocacy for social media \naccess for professionals\u2003251\nrecognition of polarizing issues\u2003250-251, \n255\npolitical ad transparency tool, Facebook\u200349, 50political disinformation, Netherlands\u200332political leaders, Dutch provincial elections \n(2019), junk sources\u2003140 , 141\npopulism, national\ncharacteristics\u2003220YouTube\u2003219\npost-truth condition\u200329-31, 51, 241PowNed, TV broadcaster\u200378, 160\nfake followers\u2003163see also  Omroep PowNed\nPrankster clickbait site, fake followers\u2003163PS2019\u200382, 128 , 133\nDutch provincial elections (2019)junk sources\u2003139 , 141\ntweet traffic\u2003134\npublicity tactics\u200320\nsee also  magic bullet theories\nPushshift\u2003 see API, PushshiftQAnon conspiracy theory\u200390\n4chan/pol imageboard\u2003171\nRathenau Institute, on Dutch news \nscene\u200331-32\nreality TV\u2003233Reddit\u200391\ncharacteristics\u2003170front page\u2003175research study\nclickbait sources\u2003178conspiracy sources\u2003178disinformation\u2003178domains extraction\u2003177Dutch sphere\u2003177haystack to needle approach\u2003176-178hyperpartisan sources\u2003178junk news\u2003179-180, 181-182, 182-185 , 197, \n213-214 (table)\nmainstream news\u2003177, 243, 246methodology\u2003176-177needle to haystack approach\u2003178-179subreddits\u2003173, 177, 181 , 192-193 , 211 \n(list), 214, 247\nYouTube links\u2003180\nRietdijk, Wilfred\u200332riots, inspired by Facebook content\u200349Roemer, Emile\u2003127Russian propaganda, on Instagram, New \nKnowledge study\u2003148\nRussian trolling\nanti-Islam\u200325, 33, 148Netherlands\u200332-33USA presidential elections (2016)\u2003234\nRutte, Mark\u200377, 127, 128, 171\nfollower base\u2003163-164, 163\nsatirical news\nOmroep PowNed\u2003223sources\u200322\nSaturday Night Live!\u200322scraping\u200378, 101\nselective, and personalization\u2003100see also  Search Engine Scraper\nSearch Engine Scraper\npurpose\u2003102use in Google.nl research\u2003103\nsearch engines\noffensive associations\u200399personalization of results\u200398, 99-100ranking practices\u200398see also  Google search engine\nSEO Tester Online\u2003119, 120Simons, Sylvana\u2003131Snyder, Timothy\u200326social media manipulation, global \nstudy\u2003148-149muted reaction to\u2003253-254\n292  T he Poli Ti cS  of  Social Media Mani Pu laTi on\nsocial media platforms\u200321\nand fake news\u200324, 71\nweaponization of\u200323\nSocial Science One, Facebook, partnership\u200350social unrest, and fake news\u200323sock puppets\u200335-36, 125-126, 127Sonkin, Vasily\u2003149Soros, George\u2003171speech\nextreme\u200323-24, 44, 250hate\u200323, 53, 55, 233\nSputnik  website\u2003195, 196, 215\nStop de Bankiers\u2003106, 118, 119suicide bombings, Brussels (2016)\u200320, 33, 91, \n148\nTexas shooting (2018)\u200398The Daily Show\u200322The Daily Stormer\u200399, 195The Post Online (TPO)\u200378, 79, 88, 89, 92, 130, \n178, 182, 201, 246\nTheLvkrijger news channel\u2003223, 226\nexhortation to vote\u2003224\nThieme, Marianne\u2003127Timmermans, Frans\u2003131transfer models\u200320\nsee also  magic bullet theories\ntroll networks\u200320troll-/bot-like accounts\nMH17 aircraft downing\u2003133Utrecht tram shooting (2019)\u2003133Zwarte Piet\u2003132-133\ntrolling\nin divisive issue spaces\u2003141-143Dutch EU parliamentary elections \n(2019)\u2003134-135\nDutch provincial elections (2019)\u2003132-133, \n134, 135, 141-142\nof political leaders, Dutch parliamentary \nelections (2017)\u2003125-127, 126 , 244-245\nresearch study\u2003127sources\u2003127see also  Russian trolling\nTrump, Donald\u200322, 26, 33, 48, 51, 72, 74, 182, \n218\n\u2018truthiness\u2019 notion\u200329, 30\nsee also  \u2018alternative facts\u2019\nTwitter\u200391\nanti-Islam\u2003127API\u2003127Russian trolling on\u2003148study approaches\u2003124-125usage\u2003124see also  Dutch Twitter\nUSA\nHIV virus, attribution to\u2003239Russian influence campaigning\u200320, 26-27, \n28USA presidential elections (2016)\nfake news\u200372, 74mainstream news\u200342, 43 , 48, 72\nRussian influence campaigning\u200320, 26-27, \n28\nRussian trolling\u2003234\nUtrecht tram shooting (2019)\u2003129, 132\ntroll-/bot-like accounts\u2003133tweet traffic, Dutch provincial elections \n(2019)\u2003 134, 140\nvideos, most popular on fringe channels\u2003228Voting Aid Applications (AAAs)\u200339-41\nimpact\u200340methods\u200340-41models\u200341\nweaponization, of social media platforms\u200323Wikipedia, alternatives to\u200331\u2018wilderness of mirrors\u2019 concept\u200327\nsee also  disinformation\nWilders, Geert\u200333-34, 83, 84, 124, 127, 157, 160, \n219anti-Islam video\u200335artificial boosting strategies\u2003165follower base\u2003163 , 164, 165\nyellow journalism\u200322YouTube\nand 4chan imageboard, research study\u2003180algorithms\u2003218, 219, 221-222, 223as alternative news network\u2003202-203channels, most occurring\u2003206, 247Dutch media sphere\u2003224, 225  (graph), \n226-227, 228-229 , 229\nrelated channels\u2003237\nDutch political parties, and associated \nmedia\u2003222\nmost posted videos\nDutch 4chan/pol\u2003205Dutch subreddits\u2003204\nnational populism\u2003219-220as radicalizing platform\u2003217-220and Reddit research study\u2003180research study, Dutch political \nspace\u2003221-234\nZuckerberg, Mark\u200348-49Zwarte Piet\u2003129\nDutch provincial elections (2019)\njunk sources\u2003136tweet traffic\u2003134 , 245\njunk news engagement\u2003131, 132, 249junk sources\u2003136mainstream news/junk news engagement, \nin Dutch provincial and EU elections (2019)\u2003 130, 144 , 242\nrace issues\u2003131troll-/bot-like accounts\u2003132-133", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "6 Dutch junk news on Reddit and 4chan/pol", "author": ["S Hagen", "E Jokubauskait\u0117"], "pub_year": "2020", "venue": "The politics of social media \u2026", "abstract": "This chapter investigates the presence of junk news on Reddit and 4chan\u2019s/pol/subforum,  spaces often described as \u201calternative\u201d owing to their lower user numbers and subcultural"}, "filled": false, "gsrank": 403, "pub_url": "https://library.oapen.org/bitstream/handle/20.500.12657/42884/9789048551675.pdf?sequ#page=170", "author_id": ["yUfs_90AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:VbFV-iZ8BZ4J:scholar.google.com/&output=cite&scirp=402&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=VbFV-iZ8BZ4J&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 7, "citedby_url": "/scholar?cites=11386643739726688597&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:VbFV-iZ8BZ4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://library.oapen.org/bitstream/handle/20.500.12657/42884/9789048551675.pdf?sequ#page=170"}}, {"title": "Steve martin at SemEval-2019 task 4: ensemble learning model for detecting hyperpartisan news", "year": "2019", "pdf_data": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019) , pages 990\u2013994\nMinneapolis, Minnesota, USA, June 6\u20137, 2019. \u00a92019 Association for Computational Linguistics990Steve Martin at SemEval-2019 Task 4: Ensemble Learning Model for\nDetecting Hyperpartisan News\nYoungjun Joo\nDepartment of Computer Engineering\nYonsei University, Seoul, Korea\nyj.joo@yonsei.ac.krInchon Hwang\nDepartment of Computer Engineering\nYonsei University, Seoul, Korea\nich0103@yonsei.ac.kr\nAbstract\nThis paper describes our submission to task\n4 in SemEval 2019, i.e., hyperpartisan news\ndetection . Our model aims at detecting hy-\nperpartisan news by incorporating the style-\nbased features and the content-based features.\nWe extract a broad number of feature sets and\nuse as our learning algorithms the GBDT and\nthe n-gram CNN model. Finally, we apply\nthe weighted average for effective learning be-\ntween the two models. Our model achieves an\naccuracy of 0.745 on the test set in subtask A.\n1 Introduction\nThe proliferation of misleading information in the\nmedia has made it challenging to identify trust-\nworthy news sources, thus increasing the need\nfor fake news detection tools able to provide in-\nsight into the reliability of news contents. Since\nthe spread of fake news is causing irreversible re-\nsults, near-real-time fake news detection is cru-\ncial. However, knowledge-based and context-\nbased approaches to fake news detection can only\nbe applied after publication; they may not be fast\nenough (Potthast et al., 2017).\nAs a practical alternative, style-based ap-\nproaches try to detect fake news by capturing the\nmanipulators in the writing style of news con-\ntent. This approach captures style signals that can\nindicate a decreased objectivity of news content\nand thus the potential to mislead consumers, such\nas hyperpartisan style. Hyperpartisan style repre-\nsents extreme behavior in favor of a particular po-\nlitical party, which often correlates with a strong\nmotivation to create fake news. Linguistic-based\nfeatures can be applied to detect hyperpartisan ar-\nticles (Potthast et al., 2017). Deep network mod-\nels, such as convolution neural networks (CNN),\napplied to classify fake news detection (Wang,\n2017). In this paper, we employ the stylometry-based approach and N-gram CNN model for de-\ntecting hyperpartisan news.\n2 System Overview\nFor this task, we extract a broad number of fea-\ntures from the training data and then apply the\nclassi\ufb01er model to make predictions. Our system\nemploys a gradient boosting decision tree (GBDT)\nmodel and N-gram CNN model. In subsequent\nsections, we describe data preprocessing, feature\nengineering and learning algorithms.\n2.1 Data Preprocessing\nBefore applying the models, we need to do some\ntransforming tasks of the article texts (i.e., xml\nparsing, text tokenizing, stemming, lemmatization,\nand removing stopwords ) and extracting tasks of\nthe internal and external links for each article.\nApart from these tasks, we construct the bias do-\nmain dictionary from the mediabiasfactcheck site\n1to check the bias on the external linked domain in\nthe article. For this ends, we crawled the top-level\ndomain information from the sites corresponding\nto the \ufb01ve categories associated with hyperparti-\nsan (e.g., Left, Center, Least Biased, Right-center\nBias, and Right Bias ) respectively.\n2.2 Feature Engineering\nSince hyperpartisan news is intentionally created\nfor political gain rather than to report objective\nclaims, they often contain opinionated and in\ufb02am-\nmatory language. Thus, it is reasonable to ex-\nploit linguistic features that capture different writ-\ning styles to detect hyperpartisan news. Linguis-\ntic features are extracted from the text content\nin terms of document organizations at a different\nlevel, such as characters, words, and sentences.\nTypical common linguisitic features are: lexical\n1http://mediabiasfactcheck.com/\n991Type of Features Feature Count\nCount features 10\nExternal link bias 3\nSentiment features 8\nReadability features 14\nTerm features 44\nGrammar transformation 45\nPsycholinguistic features 54\nPOS tags 36\nWord2vec features 301\nTF-IDF 10,000\nTable 1: Statistics of features.\nfeatures , including character-level and word-level\nfeatures; syntactic features , including sentence-\nlevel features (i.e., n-gram, POS tagging, etc. ).\nWe start by extracting several sets of linguistic\nfeatures. These feature sets are designed to capture\nhyperpartisan article from the training datasets.\nOverall we selected 515 binary features and TF-\nIDF features. Table 1 provides extracted features\non the training dataset.\nBasic count features : Previous works on fake\nnews detection (Rubin et al., 2016) as well as on\nopinion spam (Ott et al., 2011) suggest that the use\nof punctuation is useful to differentiate deceptive\nfrom truthful texts. We construct a basic count fea-\nture set including various punctuation characters\nand other features.\nExternal link bias : We extract bias counts\nbased on the bias domain dictionary for each exter-\nnal linked domain in the article (i.e., hyperpartisan\nlinks count, non-hyperpartisan links count, and\nunknown links count ). To determine biases of\nthe external links, we exploit a biased domain\ndictionary crawling from the mediabasisfactcheck\nsite, which consists of \ufb01ve categories for top-level\ndomains(i.e., left, right, left-center, center, right-\ncenter ). The external link bias is counted as the\nhyperpartisan when the externally linked site is be-\nlonging to leftandright among these categories.\nSentiment features : Our system used the\nV ADER sentiment analysis tools2to generate sen-\ntiment features on the title and body of articles.\nThe V ADER not only tells about the Positivity and\nNegativity score but also tells us about how posi-\ntive or negative a sentiment is as shown in Figure\n1.\n2https://github.com/cjhutto/vaderSentiment\nFigure 1: An example of sentiment analysis.\nVocabulary richness and readability fea-\ntures : We also extract features indicating arti-\ncle understandability. These features include sev-\neral vocabulary richness and readability scores, in-\ncluding the Brunet\u2019s Measure W, Hapax DisLege-\nmena, Hapax Legomenon, Honores R Measure,\nSichels Measure, Yules Characteristic K, Dale\nChall Readability Formula, Flesch Reading Ease,\nGunning Fog Index, Shannon Entropy, Simpson\u2019s\nIndex etc3. Among this index, Simpson\u2019s index\nstems from the concept of biodiversity. We apply\nthis index to measure the diversity of a text.\nSimpson\u2019s Index (D) =P(n=N )2\nN= total number of words in a text\nn= total number of unique tokens\nTerm features : Hyperpartisan news uses their\nlanguage strategically despite the attempt to con-\ntrol what they are saying. This language occurs\nwith certain verbal aspects and patterns of pro-\nnoun, conjunction, and negative emotional word\nusage. Based on this assumption, we extract term\ncount features which count synonyms of several\nterms (e.g., to obtain the ORDER term Feature,\nwe calculated the frequency of words such as com-\nmand, demand, instruction, prescription, order in\neach article).\nGrammar transformation : Analysis of the\ncontent-based approach is often not enough in pre-\ndicting hyperpartisan news. Thus, we adopt lan-\nguage structure (syntax) to predict this task. We\nuse spaCy tool4to transform news articles into a\nset of parse tree describing syntax structure.\nPsycholinguistic features : For psycholinguis-\ntic features, we use the 2015 Linguistic Inquiry\nand Word Count (LIWC5) lexicon to extract the\nproportions of words that belong to the psycholin-\nguistic categories. LIWC has two types of cat-\negories; the \ufb01rst kind captures the writing style\n3https://en.wikipedia.org/wiki/Readability\n4https://spacy.io\n5http://liwc.wpengine.com/\n992of the author by considering features like the\nPOS frequency or the length of the used words.\nThe second category captures content informa-\ntion by counting the frequency of words related\nto some thematic categories such as affective pro-\ncesses(e.g., positive emotion, negative emotion,\nanxiety, anger, sadness ), social processes (e.g.,\nfamily, friends, female references, male refer-\nences ), etc. Regarding the use of this tool, we fo-\ncus on the content information, and consequently,\nwe decide to ignore the style categories.\nPart-of-Speech (POS) tags : Syntactic features\nconsist of function words and part-of-speech tags.\nSyntactic pattern varies signi\ufb01cantly from one au-\nthor to another. These features were extracted us-\ning more accurate and robust text analysis tools\n(i.e., part-of-speech taggers, and lemmatizers). In\nour system, we expand the possibilities of word-\nlevel analysis by extracting the utilities of features\nlike POS frequency. For the extraction of syntactic\nfeatures, we used NLTK POS tagger1.\nWord2Vec features : Recently, word repre-\nsentation model (e.g., word2vec, GloVe ) based on\nneural networks which represents a word into a\nform of a real-valued vector have increased pop-\nularity (Mikolov et al., 2013). These approaches\nproved to be advantageous in many NLP tasks,\nsuch as Machine Translation, Question Answer-\ning, Document Classi\ufb01cation, to name a few. We\nadopted a pre-trained 300-dimensional word vec-\ntor6to create a vector representation of the article,\nwith an average word2vec. Besides, we use the\nword2vec feature to extract the cosine similarity\nvalue between the news title and the text.\nTF-IDF features : Finally, We extract uni-\ngrams, bigrams, and trigrams derived from the\nbag of words representation of each news article.\nTo account for occasional differences in content\nlength between train dataset and test dataset, these\nfeatures are encoded as tf-idf values. We limit the\nnumber of features that the vectorizer will learn to\n10,000 features.\n2.3 Learning Algorithms\nBased on the above multiple features, we explore\nseveral learning algorithms to build classi\ufb01cation\nmodels. We adopt the average weighted value for\neffective learning between GBDT for the style-\nbased and content-based features and the N-gram\n1https://www.nltk.org/\n6https://code.google.com/archieve/p/word2vec/Layer # of layers hyperparameters\nEmbedding 1 l 5000\nd 300\nConvoulution 3 m [500,500,500]\nw [3,4,5]\nw max\nDense Layer 2 t 128\no 2\nl: max sequence length d: embedding dimension\nm: \ufb01lter w: kernel size\nw: max-pooling t: dense unit size\no: softmax\nTable 2: N-gram CNN model hyperparameters.\nCNN model. (see Figure 2).\nFor deep learning model, we adopt N-gram\nCNN model proposed in (Shrestha et al., 2017).\nAs shown in Figure 2 (right), the model receives a\nsequence of character n-gram as input. These N-\ngram are then processed by four layers: (1) an em-\nbedding layer, (2) a convolution layer, (3) a max-\npooling layer, and (4) a softmax layer. We brie\ufb02y\nsketch the processing procedure.\nThe network takes a sequence of character bi-\ngrams x=< x 1; :::; x l>as input, and outputs\na multinomial over class labels as a prediction.\nThe model \ufb01rst look up the embedding matrix\nto generate the embeddings sequence for x(i.e.,\nthe matrix C), and then pushes the embedding\nsequence through convolutional \ufb01lters of three\nbigram-window sizes w= 3;4;5, each yielding\nmfeature maps. We then apply the max-pooling\nto the feature maps of each \ufb01lter, and concate-\nnate the result vectors to obtain a single vector y,\nwhich then generate a prediction through the soft-\nmax layer.\nBased on this model, we modi\ufb01ed the network\nby adding a dense layer which helps detect hy-\nperpartisan news features. After the experiment,\nthe result shows that the character bigram CNN\nmodel outperforms the unigram CNN model. Ta-\nble 2 summarizes the sizes of various parameters\nincluded in the N-gram CNN model. The of\ufb01cial\nevaluation measure for subtasks A is accuracy .\nTable 3\n3 Experiments and Results\n3.1 Datasets\nThe statistics of the datasets provided by SemEval\n2019 task 4 (Kiesel et al., 2019) are shown Table\n993\nFigure 2: Hyperpartisan news detection model.\nSubtask A Hp(%) NHp(%)\ntrain (645) 238(36.9) 407(63.1)\nSubtask B Hp(%) NHp(%)\ntrain (600k) 300k(50%) 300k(50%)\nvalid (150k) 75k(50%) 75k(50%)\nTable 3: Statistics of data sets in SemEval 2019 Task 4\nHp: hyperpartisan news; NHp: non-hyperpartisan news.\n3.\n3.2 Experiments on the Train Dataset\nWe conduct several experiments on each feature\nset to explore predictive separately. In these ex-\nperiments, we use the GDBC (i.e., XGBoost) for\nthe above feature set. For comparison with the N-\ngram model, we used the Char-level CNN model\n(Kim et al., 2016). The objective function was\nminimized through stochastic gradient descent\nover shuf\ufb02ed mini-batches with Adam(Kingma\nand Ba, 2014).\nThe performance is evaluated using 5-fold cross\nvalidation with accuracy and F-score. Table 4 lists\nthe experimental results for each feature set on the\ntraining dataset. The prediction model through the\nincorporation of the entire feature showed higher\naccuracy than the prediction model for the individ-\nual feature.\n3.3 Experiments on the Test Dataset\nOur submission results to the subtask A on TIRA\n(Potthast et al., 2019)\u2013the web service platform\nto facilitate software submissions into virtual\nmachine\u2013 achieve an accuracy of 0.745 (precision:Features (# of features) Acc F1\nCount features (10) 0.6977 0.60\nExternal link bias (3) 0.6512 0.60\nSentiment features (8) 0.6124 0.61\nReadability features (14) 0.7442 0.74\nTerm features (44) 0.6512 0.65\nGrammar transformation (45) 0.7829 0.78\nPsycholinguistic features (54) 0.7984 0.79\nPOS tags (36) 0.7132 0.72\nWord2vec features (301) 0.7752 0.77\nTF-IDF (10,000) 0.7364 0.73\nChar CNN (unigram) 0.7442 0.73\nN-gram CNN (bigram) 0.7752 0.78\nAll Features (train dataset) 0.8450 0.84\nAll Features (test dataset) 0.7450 0.70\nTable 4: Experimental results on the subtask A dataset.\n0.853, recall: 0.592, F1: 0.6999). We ranked the\n14th for subtask A in terms of accuracy. The pre-\ndiction results of the test data are lower than the\nresults of the training set, especially gains huge\ngap between precision and recall score.\n4 Conclusion\nUsing a combination of the style-based ap-\nproaches, the content-based approaches, and the\nN-gram CNN model, we construct the model for\ndetecting hyperpartisan news. For this ends, we\nextract a broad number of linguistic features and\nemploy GBDT model to make predictions. Fi-\nnally, we adopted the weighted average value for\neffective learning between the two models.\n994References\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. Semeval-\n2019 task 4: Hyperpartisan news detection. In In\nProceedings of The 13th International Workshop on\nSemantic Evaluation (SemEval 2019) . Association\nfor Computational Linguistics.\nYoon Kim, Yacine Jernite, David Sontag, and Alexan-\nder M Rush. 2016. Character-aware neural language\nmodels. In Thirtieth AAAI Conference on Arti\ufb01cial\nIntelligence .\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980 .\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\nrado, and Jeff Dean. 2013. Distributed representa-\ntions of words and phrases and their compositional-\nity. In Advances in neural information processing\nsystems , pages 3111\u20133119.\nMyle Ott, Yejin Choi, Claire Cardie, and Jeffrey T\nHancock. 2011. Finding deceptive opinion spam\nby any stretch of the imagination. In Proceed-\nings of the 49th Annual Meeting of the Association\nfor Computational Linguistics: Human Language\nTechnologies-Volume 1 , pages 309\u2013319. Association\nfor Computational Linguistics.\nMartin Potthast, Tim Gollub, Matti Wiegmann, and\nBenno Stein. 2019. TIRA Integrated Research Ar-\nchitecture. In Nicola Ferro and Carol Peters, edi-\ntors, Information Retrieval Evaluation in a Chang-\ning World - Lessons Learned from 20 Years of CLEF .\nSpringer.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2017. A sty-\nlometric inquiry into hyperpartisan and fake news.\narXiv preprint arXiv:1702.05638 .\nVictoria Rubin, Niall Conroy, Yimin Chen, and Sarah\nCornwell. 2016. Fake news or truth? using satirical\ncues to detect potentially misleading news. In Pro-\nceedings of the Second Workshop on Computational\nApproaches to Deception Detection , pages 7\u201317.\nPrasha Shrestha, Sebastian Sierra, Fabio Gonzalez,\nManuel Montes, Paolo Rosso, and Thamar Solorio.\n2017. Convolutional neural networks for authorship\nattribution of short texts. In Proceedings of the 15th\nConference of the European Chapter of the Associa-\ntion for Computational Linguistics: Volume 2, Short\nPapers , volume 2, pages 669\u2013674.\nWilliam Yang Wang. 2017. \u201d liar, liar pants on \ufb01re\u201d:\nA new benchmark dataset for fake news detection.\narXiv preprint arXiv:1705.00648 .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Steve martin at SemEval-2019 task 4: ensemble learning model for detecting hyperpartisan news", "author": ["Y Joo", "I Hwang"], "pub_year": "2019", "venue": "Proceedings of the 13th International Workshop \u2026", "abstract": "This paper describes our submission to task 4 in SemEval 2019, ie, hyperpartisan news  detection. Our model aims at detecting hyperpartisan news by incorporating the style-based"}, "filled": false, "gsrank": 405, "pub_url": "https://aclanthology.org/S19-2171/", "author_id": ["", ""], "url_scholarbib": "/scholar?hl=en&q=info:AybelftZlOUJ:scholar.google.com/&output=cite&scirp=404&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=AybelftZlOUJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 6, "citedby_url": "/scholar?cites=16542946268324701699&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:AybelftZlOUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/S19-2171.pdf"}}]