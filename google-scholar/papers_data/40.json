[{"title": "Correcting misinformation on social media with a large language model", "year": "2024", "pdf_data": "Correcting misinformation on social media with a\nlarge language model\nXinyi Zhou, Ashish Sharma, Amy X. Zhang, and Tim Althoff\nPaul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA\nAbstract\nReal-world misinformation, often multimodal, can be partially correct and factual but misleading by\ncherry-picking, conflating correlation with causation, and using other tactics. Such misinformation is\nseverely understudied, challenging to address, and harms many social domains, including democracy,\neconomics, justice, human rights, and public health, particularly on social media, where it can spread\nrapidly. High-quality and timely correction of misinformation that identifies and explains its inaccuracies\nand accuracies has been shown to effectively reduce false beliefs. Despite the wide acceptance of manual\ncorrection, it is difficult to be timely and scalable, a concern as technologies like large language models\n(LLMs) make misinformation easier to produce. LLMs also have versatile capabilities that could accelerate\nmisinformation correction\u2014however, they struggle due to a lack of recent information, a tendency to\nproduce false content, and limitations in addressing multimodal information. We propose MUSE, an LLM\naugmented with access to and credibility evaluation of up-to-date information. By retrieving evidence as\nrefutation or supporting context, MUSE identifies and explains (in)accuracies in a piece of content\u2014not\npresupposed to be misinformation\u2014with references. It conducts multimodal retrieval and interprets visual\ncontent to verify and correct multimodal content. Given the absence of a systematic and comprehensive\nevaluation approach, we propose and define 13 dimensions of misinformation correction quality, ranging\nfrom the accuracy of identifications and factuality of explanations to the relevance and credibility of\nreferences. Then, fact-checking experts correspondingly evaluate responses to social media content that\nare not presupposed to be (non-)misinformation but broadly include incorrect, partially correct, and correct\nposts that may or may not be misleading. The results demonstrate MUSE\u2019s ability to write high-quality\nresponses to potential misinformation\u2014across modalities, tactics, domains, political leanings, and for\ninformation that has not previously been fact-checked online\u2014within minutes of its appearance on social\nmedia. Overall, MUSE outperforms GPT-4 by 37% and even high-quality responses from laypeople by\n29%. Our work provides a general methodological and evaluative framework to correct misinformation at\nscale. It reveals LLMs\u2019 potential to help combat real-world misinformation effectively and efficiently.\nIntroduction\nMisinformation has far-reaching and detrimental effects on individuals and society1\u20135. It erodes public trust\nin government, decreases civil engagement in elections, and has been viewed as a threat to democracy3, 6, 7.\nEvidence has demonstrated that election misinformation helped fuel the January 6th attack on the U.S.\nCapitol, where five people died and more than 100 police officers were injured8. Misinformation also\ndrastically increases during outbreaks and disasters, as seen with the \u201cinfodemic\u201d during the COVID-19\npandemic, which significantly increased vaccine hesitancy9, 10. The result is tragic, where COVID-19\nvaccines could have prevented at least 232,000 COVID-19-associated deaths between May 2021 and\nSeptember 2022 in the U.S. alone11. Concerns over misinformation on social media have been particularly\n1arXiv:2403.11169v4  [cs.CL]  3 Sep 2024\nsignificant12\u201314, as the social media context interferes with truth discernment, where users post content\nwithout professional moderation and often consume news in a hasty and distracted way15, 16.\nFortunately, high-quality and timely correction of misinformation, which identifies what part(s) of\nits content is or is not accurate and explains why that part of the content is (in)accurate with references,\nhas been shown to effectively reduce the spread of misinformation and false beliefs4, 17\u201319. While domain\nexperts (e.g., on FactCheck.org) and groups of laypeople (e.g., on X Community Notes, formerly Twitter\nBirdwatch) have played pivotal roles in correcting misinformation17, 19, 20, keeping pace with massive\nsocial media posts is impossible. As Brandolini\u2019s law indicates21, correcting misinformation is laborious\u2014\noften requiring domain knowledge, information and media literacy, and explanatory skills\u2014whereas\ncreating and spreading misinformation is easy. As a consequence, 88% of suspicious content on X did not\nreceive any response, and 93% did not receive a high-quality response within the first hour (according\nto X/Twitter Community Notes as of February 2023; Supp. Fig. S1). Even high-quality responses suffer\nfrom limited effectiveness when they are created after rather than before initial bursts of attention to\nmisinformation content4, 14. The absence of sufficient coverage also markedly diminishes the impact\nof correction and, as the implied truth effect suggests, may even increase the perceived accuracy of\nmisinformation that escapes correction22.\nWhile generative AI models like LLMs raise concerns that they facilitate creating misinformation, they\nalso potentially make scaling up and accelerating misinformation\u2019s correction possible. Recent LLMs have\nexhibited proficiency in generating fluent and coherent text, laying a foundation for producing explanations\nthat the public can understand. Indeed, LLMs have revolutionized the field of AI and presented remarkable\ncapabilities across domains and tasks23\u201325. However, accurate and trustworthy misinformation correction\nis inseparable from accessing up-to-date and reliable information, providing accurate references to back\nup claims, and addressing textual and visual information, all areas where existing LLMs fall short26.\nSpecifically, GPT-427(as of March 2023), Llama-3 (as of July 2024)28, MisinfoCorrect29, MADR30,\nJustiLM31, and many other LLMs lack access to constantly growing and changing knowledge. These\nmodels are thereby ill-equipped to combat misinformation on emerging topics. They either do not provide\nor \u201challucinate\u201d references, which can be fabricated or irrelevant26, 32. A growing body of literature has\nfocused on retrieval-augmented LLMs, which can retrieve up-to-date information from Wikipedia or the\nentire Internet33\u201339. However, their retrieval does not explicitly consider the factuality and bias of retrieved\nsources, posing risks of generating falsehood and backfiring (i.e., reinforcing rather than reducing false\nbeliefs)40\u201342. Every above LLM also struggles with counteracting multimodal misinformation due to their\nnonacceptance of visual inputs.\nReal-world misinformation commonly encompasses content that is partially correct and even factual\nbut misleading through various tactics and across domains2, 3. Such misinformation can be more difficult\nto recognize, prevalent, and harmful2, 3. Existing LLM and other AI models to tackle misinformation\nfocus narrowly on it that is factually incorrect (e.g., MADR30, FOLK38, and ProgramFC43), within a\nsingle domain (e.g., politics30or COVID-1929, 39), or employing one specific tactic (e.g., repurposing\nauthentic images with fabricated stories44). A general AI framework to practically identify and correct\nmisinformation is demanded but absent. Evaluating the quality of a correction presented in natural\nlanguage is another core challenge. Related studies heavily rely on automatic evaluation, which calculates\nthe similarity between model-generated and \u201cground-truth\u201d text using metrics such as ROUGE31, 44.\nHowever, what qualifies a correction as the ground truth is unclear29, and existing metrics struggle to\ncapture content factuality, especially when compared to fact-checking experts26. The need for an accurate\nand comprehensive understanding of a model\u2019s performance in identifying and explaining (in)accuracies,\ngenerated text, and references is recognized, but a solution is still lacking.\nIn this article, we propose MUSE, a scalable approach for multimodal mi sinformation corr ection.\n2/50\nMUSEmakes use of an LLM and augments it with the ability to handle images, access timely and credible\nknowledge on the web, retrieve evidence that refutes or contextualizes the given content that may or\nmay not be misinformation, and generate clear explanations with accurate and trustworthy references.\nMUSE is a nonparametric approach and therefore easily and cheaply updated, especially compared to\nparametric language models. Fact-checking experts comprehensively evaluate MUSE-generated responses\nto real social media posts that potentially are misinformation, and compare them to baselines including\nGPT-4 and high-quality responses based on the collective efforts of laypeople. Our assessment measures\nthe overall quality of a response, specifically defined as the explicitness, accuracy, comprehensiveness,\nand informativeness when it identifies and explains (in)accuracies; the relevance, factuality, fluency,\ncoherence, and toxicity of generated text; and the reachability, relevance, and credibility of references. We\nfind that MUSE outperforms GPT-4 by 37% and even high-quality responses from laypeople by 29% in\naccurately and promptly responding to potential misinformation. Results demonstrate MUSE\u2019s advance no\nmatter whether the potential misinformation content is textual with or without images; fabricates a story,\nmisinterprets or misrepresents facts, lacks context, implies false or oversimplified causation, uses loaded\nlanguage, presents false or biased data, has improper analogy or equivalence, and adopts other tactics;\nacross a broad range of domains, including politics and international affairs, economy and business, crime\nand law, social issues and human rights, and health and medicine; leans liberal or conservative; or whether\nthe content has previously fact-checked online or not.\nApproach\nMUSE is designed to automatically respond to content that potentially is misinformation. In other\nwords, the content might be (partially) inaccurate or factually accurate but misleading, all of which are\nmisinformation, or fully accurate as non-misinformation. The content can contain text with or without\nvisuals. The response should identify what part(s) of the content is or is not accurate, explain why that part\nof the content is or is not accurate, and provide links as references. Overall, MUSEfeatures three modules\nto reliably and efficiently address generalized misinformation: (1) a highly parallelizable relevance- and\ncredibility-aware evidence retriever, (2) an LLM-based evidence-assisted response generator, and (3) an\nimage describer that enables text-only LLMs to jointly interpret multimodal signals from the input.\nFig. 1 illustrates MUSE\u2019s pipeline. We start by introducing the details of MUSE with a piece of\ntext-only potential misinformation as the input. First, MUSE generates queries based on an LLM from\nthe potential misinformation (Fig. 1b; Methods). Each query acts as the input of a web search engine to\naccess timely updated web content and obtain a list of web links directly relevant to the query (Fig. 1b;\nMethods). After scraping the content from these web links, MUSE calculates their direct relevance to the\npotential misinformation and removes irrelevant web pages (Fig. 1b; Methods). Then, MUSE determines\nthe credibility of web pages by looking up their publishers\u2019 factuality and bias ratings and selects pages\nwith high factuality and minimal bias (Fig. 1c; Methods). Next, MUSE leverages an LLM to extract\ntext from each of the web pages as evidence. Such evidence can refute the potential misinformation,\ntypically happening when it is misinformation with false claims, or provide additional context, which can\ndemonstrate that the potential misinformation is accurate or part(s) of its claims are accurate (Fig. 1d;\nMethods). Finally, MUSEgenerates a response to the potential misinformation by providing an LLM with\nthe extracted pieces of evidence and their source web links (Fig. 1d; Methods).\nNote that content, especially content posted on social media, often contains extraneous information\nthat does not need verification and is irrelevant to correction, including unverifiable opinions or emojis,\nsuch as the textual content of the false post in Fig. 1. Therefore, generating queries instead of simply using\nthe post content improves web searches as a way of denoising the post content; see example queries in\n3/50\nFig. 1b. Meanwhile, generating multiple queries helps decompose a post, which may have multiple claims\nthat each needs verification or correction, whereas generating one query may overlook some of the claims\nand hence lead to not comprehensive identifications and explanations of (in)accuracies (Supp. Fig. S2).\nAnother concern may arise from filtering retrieved web pages based on how relevant the page content is\nto the potential misinformation: theoretically, including all retrieved web pages increases the amount of\nextracted evidence, which may not hurt and perhaps even benefit correction. However, the increase in\nselected web pages drastically elevates the expense of MUSE (Methods). We also observe that retrieved\nweb pages with relatively low relevance can increase the prevalence of hallucinations when generating\nresponses (Supp. Fig. S3). Moreover, as illustrated in Fig. 1c, MUSE filters and ranks the selected web\npages by their publishers\u2019 factuality and bias. It starts extracting evidence from pages with the highest\nfactuality and least bias and then continues down the ranking, stopping when it has obtained sufficient\nrefutations (i.e., at least two web pages were found to refute the misinformation) or gone through all the\ncredible pages.\nWhen the input is a piece of multimodal (textual and visual) content, MUSE first generates textual\ndescription of each image (Fig. 1a) so that the content can be handled by any LLM on downstream tasks,\nincluding query generation (Fig. 1b), evidence extraction (Fig. 1d), and response generation (Fig. 1d).\nSpecifically, MUSEaugments image captioning models developed to describe an image in natural language\nwith recognizing celebrities and optical characters based on an LLM (Fig. 1a; Methods). Compared to\nexisting image captioning models that capture global features of images, MUSEproduces more informative\ndescriptions with features crucial for making accurate verification and corrections45(Methods). For\nexample, even a state-of-the-art image captioning model46may describe the visual misinformation in\nFig. 1 as simply \u201clist of banned books in Florida.\u201d The description overlooks the listed titles of books that\nare essential for the visual content\u2019s verification and correction (see more examples in Supp. Fig. S4). In\naddition, MUSE conducts multimodal search on the web and computes multimodal relevance to filter out\nirrelevant web pages (Fig. 1b; Methods).\nEvaluation\nMUSE\u2019s evaluation was based on X Community Notes data. Community Notes empowers people on\nX, often laypeople, to collaboratively fact-check tweets, which has been shown to reduce the spread of\nmisinformation17. Every laypeople\u2019s free-response fact-check is associated with a helpfulness score by\naggregating the assessments of people with diverse backgrounds, e.g., different political ideologies. A\nresponse with a sufficiently high helpfulness score is then displayed on the corresponding tweet and\npublicly visible17(Supp. Fig. S6). We included the tweets from Community Notes with at least two\nresponses ( n=247, posted from February 2021 to February 2023); one has a high helpfulness score and\nthe other has an average helpfulness score (as of February 2023; Methods). Though we do not presuppose\nthe accuracy of the tweets in MUSE\u2019s design and evaluation, we found that more than half of the tweets\nare not fully (in)accurate or misleading but frequently presented in a way that combines accurate claims\nand inaccurate or misleading claims (Methods). We further generated responses to these tweets based\nonMUSE and GPT-4 (as of June 2023) (Discussion; Methods). Experts in fact-checking and journalism\nevaluated the quality of responses by various approaches to the same tweet (Methods); they were blinded\nto which approach had generated each response. The evaluation contains 13 specific criteria, covering\nhow well a response identifies and explains (in)accuracies, the quality of generated text, and the quality of\nreferences (Methods). It also contains the overall quality of a response by taking all 13 evaluation criteria\ninto account (Methods).\nOur primary finding is that the overall quality of MUSE-generated responses is higher than responses\n4/50\nby GPT-4 and even high-helpfulness responses by laypeople (Fig. 2a). The overall quality of MUSE-\ngenerated responses has an average score of 8.1 out of 10, 29% higher than laypeople\u2019s high-helpfulness\nresponses (mean: 6.3; p=3\u00d710\u221248, by Mann-Whitney U test unless otherwise specified; N=464), 37%\nhigher than GPT-4-generated responses (mean: 5.9; p=4\u00d710\u221242;N=464), and 56% significantly higher\nthan laypeople\u2019s average-helpfulness responses (mean: 5.2; p=5\u00d710\u221281;N=462). Despite statistical\ninsignificance between the overall quality of laypeople\u2019s high-helpfulness responses and GPT-4-generated\nresponses ( p=0.4;N=464), the overall quality of GPT-4-generated responses has the highest variability,\nand GPT-4 generates more responses with extremely low quality. The standard deviation of the overall\nquality of GPT-4-generated responses is 2.7, vs only 2.0 for MUSE and laypeople. 10% of GPT-4\u2019s\ngenerated responses have a quality score of 0 (lowest) or 1 out of 10, whereas this proportion is 5% for\nlaypeople\u2019s average-helpfulness responses, 3% for laypeople\u2019s high-helpfulness responses, and 2% for\nMUSE-generated responses. Note that laypeople\u2019s responses were created on average 14 hours after the\ntweet was posted on social media. Here, MUSE only retrieved web pages published before the tweet was\nposted (Methods).\nExamining specific components of response quality, results show that MUSE outperforms GPT-4\nand laypeople who produce even high-helpfulness responses in identifying and explaining (in)accuracies\n(Fig. 2b-f). Experts assessed that MUSE-generated responses more explicitly identify and explain where\nand why a tweet is (in)accurate than GPT-4\u2019s and laypeople\u2019s high-helpfulness responses (Fig. 2b). 89%\nofMUSE\u2019s generated responses explicitly identify and explain (in)accuracies, 16% more than GPT-\n4-generated responses, 29% more than laypeople\u2019s high-helpfulness responses, and 43% more than\nlaypeople\u2019s average-helpfulness responses (Fig. 2b). As for identifying where a tweet is (in)accurate,\nwe found that MUSE more comprehensively identifies a tweet\u2019s (in)accuracies with fewer mistakes\u2014\nhere, mistakes indicate falsely claiming where a tweet should be inaccurate as accurate or where a\ntweet should be accurate as inaccurate\u2014than GPT-4 and laypeople who produce even high-helpfulness\nresponses (Fig. 2c-d). 91% of MUSE\u2019s generated responses have at least one correct identification without\nanymistake, 11% more than laypeople\u2019s high-helpfulness responses, 19% more than GPT-4-generated\nresponses, and 26% more than laypeople\u2019s average-helpfulness responses (Fig. 2c). MUSE has 61% of\ngenerated responses accurately identifying allthe (in)accuracies in a tweet, vs GPT-4 has 38%, laypeople\nwho produce high-helpfulness responses have 26%, and laypeople who produce average-helpfulness\nresponses have 17% only (Fig. 2d). Furthermore, MUSE explains (in)accuracies more precisely and\ninformatively than GPT-4 and laypeople who produce even high-helpfulness responses (Fig. 2e-f). 70% of\nresponses by MUSE have fully accurate explanations, vs 55% for laypeople\u2019s high-helpfulness responses,\n47% by GPT-4, and 37% for laypeople\u2019s average-helpfulness responses only (Fig. 2e). Meanwhile, the\naverage informativeness score of MUSE-generated responses is 7.9, 32% higher than laypeople\u2019s high-\nhelpfulness responses, 36% higher than GPT-4-generated responses, and 65% higher than laypeople\u2019s\naverage-helpfulness responses (Fig. 2f).\nResults also demonstrate that MUSE outperforms GPT-4 and laypeople who produce even high-\nhelpfulness responses in the quality of generated text (Fig. 2g-k). MUSE, when it augments GPT-4 with the\ncapabilities of accessing timely updated knowledge and addressing visuals (Methods), exhibits enhanced\nrelevance ( p=10\u221215;N=460) and factuality ( p=2\u00d710\u221220;N=459) of text compared to GPT-4\nwithout sacrificing fluency ( p=0.6;N=464), coherence ( p=0.1;N=459), and toxicity ( p=0.8;\nN=464). Meanwhile, MUSE-generated text is more relevant to the responded tweet ( p=2\u00d710\u221230;\nN=464), factual ( p=4\u00d710\u22126;N=463), fluent ( p=2\u00d710\u221210;N=464), and coherent ( p=10\u22125;\nN=451) than the text of high-helpfulness responses by laypeople and additionally less toxic than the\ntext of average-helpfulness responses by laypeople ( p=4\u00d710\u221212;N=462).MUSE-generated text has\nan average relevance score of 8.7, 18% higher than GPT-4-generated text, 21% higher than the text of\n5/50\nhigh-helpfulness responses by laypeople, and 43% higher than the text of average-helpfulness responses\nby laypeople (Fig. 2g). 74% of MUSE-generated text is completely factual, vs 59% for the text of even\nhigh-helpfulness responses by laypeople and 45% for GPT-4-generated text (Fig. 2h). Almost all of\nMUSE-generated text does not have any mistake in the use of English (Fig. 2i) and is not biased, impolite,\nand provoking (Fig. 2k), and 91% is highly coherent and logical (vs 76% and 61% for laypeople, Fig. 2j).\nAdditionally, results reveal that MUSE outperforms GPT-4 and laypeople who produce even high-\nhelpfulness responses in the quality of references (Fig. 2l-n). First, GPT-4 hallucinates references frequently.\n49% of its links result in \u201cpage-not-found\u201d errors (Fig. 2l), and only 76% of reachable links are relevant to\nthe generated text (Fig. 2m). MUSEsignificantly reduces such hallucinations with nearly 100% links being\nreachable (Fig. 2l) and 96% reachable links being relevant to the generated text (Fig. 2m). Meanwhile,\nMUSE\u2019s references are more credible than the references offered in even high-helpfulness responses by\nlaypeople ( p=4\u00d710\u221211;N=744; Fig. 2n).\nWe further analyzed the robustness of MUSEin addressing diverse forms of real-world misinformation,\nwhich may vary in modality, difficulty to correct, political leaning, domain, and adopted tactics. We\nfirst observed that the quality of MUSE-generated responses to textual and multimodal (textual and\nvisual) content is consistently higher than responses by GPT-4 and even high-helpfulness responses by\nlaypeople, with a margin of 21% or higher (Fig. 3a). GPT-4 can be comparable to laypeople who write\nhigh-helpfulness responses when responding to text-only tweets. However, its performance significantly\ndeclines when responding to multimodal tweets, often resulting in a quality lower than laypeople who\nproduce average-helpfulness responses.\nSecond, we removed tweets where MUSE\u2019s response references at least one related fact-checking\narticle, accounting for 16% of all tweets. Notably, in only 6% of all tweets, MUSE\u2019s response exclusively\nreferences related fact-checking article(s). The quality of MUSE-generated responses to these tweets can\nbe more associated with MUSE\u2019s ability to summarize retrieved professional fact-checking articles, rather\nthan fact-checking such content from scratch. We found that the quality of MUSE-generated responses\nto content that has notbeen fact-checked online is at least 28% higher than responses by GPT-4 and\neven high-helpfulness responses by laypeople (Fig. 3b). The average quality score of MUSE-generated\nresponses for these potentially more challenging tweets is 8.0, close to its 8.1 average score for all tweets.\nThird, LLMs have exhibited political bias47, which may diminish their ability to debunk misinformation\nthat aligns with their political stance. We annotated the political leaning of tweets and found that GPT-\n4, which has an observed liberal bias47, indeed performs 5% worse in correcting misinformation that\naligns with liberal ideology compared to conservative ideology (Fig. 3c). Nevertheless, the quality of\nMUSE-generated responses to both liberal and conservative content has the same average score of 8.3.\nThis score is consistently higher than GPT-4-generated responses and even high-helpfulness responses\nfrom laypeople by at least 26%.\nFinally, we annotated the domain of tweets and tactics used to make them or part of them false or\nmisleading. Results in Fig. 3d-e indicate that the quality of MUSE-generated responses to potential\nmisinformation across different domains and tactics maintains an average score around 8, consistently\nhigher than responses by GPT-4 and even high-helpfulness responses from laypeople, with a margin of at\nleast 19%. Here, domains broadly include politics and international affairs, economy and business, crime\nand law, social issues and human rights, and health and medicine. Tactics primarily include fabricating,\ne.g., a story with or without an authentic image, or using a digitally fabricated or altered screenshot or\nphoto; misinterpreting or misrepresenting someone\u2019s claim, a symbol, a policy, and others; lacking context;\nimplying false or oversimplified causation, such as conflating correlation with causation; using loaded\nlanguage; presenting false, partial, or biased data, such as cherry-picking; and having improper analogy or\nequivalence (see examples in Supp. Fig. S7).\n6/50\nDiscussion\nWhile concerns have arisen about LLMs in facilitating the creation of misinformation48, 49, our work\ndemonstrates LLMs\u2019 potential to improve the online information ecosystem by correcting misinforma-\ntion2, 3. Correcting misinformation requires identifying what part(s) of the content is (in)accurate and\nexplaining why that part of the content (in)accurate with trustworthy references. Such identifications with\nclear explanations have been shown to reduce misinformation\u2019s spread and people\u2019s false beliefs, but its\neffectiveness is affected by quality, timeliness, and scalability4, 22. However, research on scaling up and\naccelerating misinformation correction is still at the early stage. Existing AI models are ill-equipped to\nidentify and correct misinformation on social media. Such misinformation often spreads rapidly and is\nnot restricted to narrow domains. It can combine (in)accurate, factually accurate but misleading, and\nunverifiable claims. It can employ various tactics, deliberately or accidentally, to create falsehood or\nmisleadingness. Addressing it requires comprehending content that can be multimodal and the context\nbeyond it that often involves emerging events. Existing methods to evaluate the quality of corrections\npresented in natural language also struggle to be accurate and comprehensive. Such evaluation relies\non professional knowledge and skills. It should thoroughly assess the identification and explanation of\n(in)accuracies, as well as the use of references from diverse perspectives.\nWe propose MUSE, which augments existing powerful LLMs (here, it is GPT-4) with the capabilities\nof addressing images, accessing up-to-date knowledge, and finding accurate references, and 13 dimensions\nof misinformation correction quality. Evaluation by fact-checking experts demonstrates the high quality\nofMUSE\u2019s automatically generated responses to social media posts that potentially are misinformation.\nResults further validate that GPT-4 struggles to effectively respond to visual content but MUSE excels\n(Fig. 3a). MUSE also exhibits significantly fewer \u201challucinations\u201d by having fewer errors in identifying\nand explaining (in)accuracies (Fig. 2c,e), generating text that is more factual and relevant to the responded\ncontent (Fig. 2g-h), and providing more references that are real and relevant to the generated text (Fig. 2l-\nm) than GPT-4. Note that addressing LLM \u2019hallucination\u2019 has been a long-standing challenge stressed in\nmany works26, 50.\nWe provide MUSE as a solution to assist social media users and platforms in reliably, scalably,\npromptly, and transparently responding to suspicious content. MUSE is end-to-end and thereby simple\nto use. It is nonparametric and thereby easily and cheaply updated51. Meanwhile, our results reveal that\nMUSE-generated responses have high quality in identifying and explaining inaccuracies, generated text,\nand provided references, significantly surpassing GPT-4 and laypeople who produce even high-helpfulness\nresponses in correcting misinformation across modalities, domains, political leanings, and tactics and that\nhas not even been fact-checked online (Fig. 2-3). Besides the highest accuracy and factuality (Fig. 2c,e,g-\nh,l-m), MUSE\u2019s generated responses show the highest readability by being the most explicit, fluent,\nand coherent (Fig. 2b,i-j). MUSE can reduce the risk of a correction backfiring (i.e., reinforcing rather\nthan reducing people\u2019s false beliefs) by generating responses with the least toxic text and most credible\nreferences29, 41, 42(Fig. 2k,n). It can also reduce the implied truth effect (i.e., increasing people\u2019s perceived\naccuracy of overlooked inaccuracies)22by comprehensively identifying all the inaccuracies in a social\nmedia post (Fig. 2d) and being more capable of correcting misinformation at scale. These high-quality\nresponses by MUSE can generally be obtained within minutes of suspicious content appearing on social\nmedia (Methods). By transparently providing references that refer to the retrieved web pages where\nevidence was collected, users can become more informed and also verify responses themselves (Fig 2,3f).\nMUSE can also inform users of the current lack of evidence, provide an accuracy nudge, and when\napplicable, express uncertainty (Supp. Fig. S8).\nMUSE\u2019s responses cost about 0.5 USD per social media post at the time of our evaluation, though this\n7/50\ncost has now been reduced to 0.2 USD, as GPT-4\u2019s price has lowered (as of February 2024; Methods).\nOur focus in designing MUSE was in maximizing the quality of corrections. Considering the task\u2019s\ncomplexity and our significant improvement in quality, the cost is relatively inexpensive compared to\nalternatives. For example, a crowd of laypeople can already cost about 0.9 USD19to identify whether a\nnew article\u2019s headline and lede contains misinformation without writing down the explanation. Notably,\nwe also changed MUSE\u2019s foundation LLM from GPT-4 to open-sourced Llama-3 (70B) and observed two\nMUSEs are comparable without modifying anyother implementation details (Supp. Fig. S9; Methods),\nsuggesting MUSE\u2019s generalizability. Note that the knowledge cutoff for Llama-3 is December 2023,\nwhereas that of GPT-4 is September 2021. Llama-3\u2019s training data might have included some or even all\ntweets used in evaluation and related events, knowledge, and corrections (e.g., their Community Notes\ndata). As a comparison, GPT-4\u2019s training data might only include up to 10% (Methods, where we show\nthatMUSE\u2019s performance remains consistent after removing these tweets). Hence, it is unfair to compare\nbetween Llama-3-based and GPT-4-based MUSE, and we did not include Llama-3 and its based MUSE in\nexpert evaluation. Nevertheless, our qualitative analysis illustrated in Supp. Fig. S9 reveals the potential to\nsignificantly reduce MUSE\u2019s cost, as GPT-4 was MUSE\u2019s most costly component. Furthermore, as one\nof the most capable open-sourced LLMs, Llama-3 still cannot accept visual inputs (as of August 2024),\nemphasizing the importance of M USE\u2019s image describer module.\nThis work also faces the following limitations. First, although MUSE is capable of responding to\nmultimodal misinformation with text and images, it cannot accept video inputs. Second, we only focus on\nEnglish, one of the most spoken languages in the world. Third, we evaluated MUSEusing real social media\ncontent on a single platform, X, as its Community Notes system has been shown to reduce the spread of\nmisinformation17and transparent. X is also a popular social media platform, and one where more than\nhalf of users consume news regularly52and where misinformation has been shown to diffuse faster than\nthe truth13. Fourth, experts assessed and compared MUSE against one foundation LLM, GPT-4, which\ncan also be seen as an ablation study, since MUSE augments GPT-4 (see Methods and Supp. Fig. S24\nfor additional results of our ablation study). GPT-4 was chosen as a comparison as it is one of the best\nperforming LLMs across a wide range of tasks available today53, 54.\nConclusion\nWe proposed MUSE, a nonparametric LLM to identify and explain (in)accuracies in social media content.\nMUSE can integrate textual and visual information, access timely knowledge, and generate responses that\nuse natural languages and have accurate and trustworthy references. Experts assessed that MUSE signifi-\ncantly outperforms GPT-4 and even laypeople who write high-helpfulness responses on X Community\nNotes in identifying and explaining (in)accuracies, generating high-quality text, providing high-quality\nreferences, and producing high-quality responses overall. MUSE excels when the responded content is\ntextual or multimodal, related to a broad range of domains, false or misleading by applying various tactics,\nand even when the content has not been fact-checked online. MUSE also performs consistently well\nwhen responding to liberal and conservative content. This work demonstrates the potential of LLMs to\nrespond to online misinformation in a scalable, prompt, reliable, and transparent manner\u2014addressing key\nbottlenecks where existing studies struggle. This work also contributes to a comprehensive framework,\nincorporating with 13 associated standards (Methods, where we analyzed their importance), for evaluating\nmisinformation correction models. Additionally, we publicly release rich annotations on social media\nposts covering aspects such as political leanings, domains, and tactics that make them false or misleading,\nalong with expert-annotated responses to enable research.\n8/50\nReferences\n1.Lazer, D. M. et al. The science of fake news. Science 359, 1094\u20131096 (2018).\n2.Traberg, C. S. Misinformation: broaden definition to curb its societal influence. Nature 606, 653\u2013653\n(2022).\n3.Watts, D. J., Rothschild, D. M. & Mobius, M. Measuring the news and its impact on democracy. Proc.\nNatl. Acad. Sci. 118, e1912443118 (2021).\n4.Van Der Linden, S. Misinformation: susceptibility, spread, and interventions to immunize the public.\nNat. Medicine 28, 460\u2013467 (2022).\n5.West, J. D. & Bergstrom, C. T. Misinformation in and about science. Proc. Natl. Acad. Sci. 118,\ne1912444117 (2021).\n6.Moore, R. C., Dahlke, R. & Hancock, J. T. Exposure to untrustworthy websites in the 2020 US\nelection. Nat. Hum. Behav. 1\u201310 (2023).\n7.Forum, W. E. Global risks report 2024 (World Economic Forum, 2024).\n8.Thompson, B. G. et al. Final Report of the Select Committee to Investigate the January 6th Attack on\nthe United States Capitol (U.S. Government Publishing Office, 2022).\n9.Zarocostas, J. How to fight an infodemic. The Lancet 395, 676 (2020).\n10.Pertwee, E., Simas, C. & Larson, H. J. An epidemic of uncertainty: rumors, conspiracy theories and\nvaccine hesitancy. Nat. Medicine 28, 456\u2013459 (2022).\n11.Jia, K. M. et al. Estimated preventable COVID-19-associated deaths due to non-vaccination in the\nUnited States. Eur. J. Epidemiol. 1\u20134 (2023).\n12.Ledford, H. Deepfakes, trolls and cybertroopers: how social media could sway elections in 2024.\nNature (2024).\n13.V osoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science 359, 1146\u20131151\n(2018).\n14.Bak-Coleman, J. B. et al. Combining interventions to reduce the spread of viral misinformation. Nat.\nHum. Behav. 6, 1372\u20131380 (2022).\n15.Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G. & Rand, D. The social media context interferes\nwith truth discernment. Sci. Adv. 9, eabo6169 (2023).\n16.Ceylan, G., Anderson, I. A. & Wood, W. Sharing of misinformation is habitual, not just lazy or biased.\nProc. Natl. Acad. Sci. 120, e2216614120 (2023).\n17.Wojcik, S. et al. Birdwatch: Crowd wisdom and bridging algorithms can inform understanding and\nreduce the spread of misinformation. arXiv preprint arXiv:2210.15723 (2022).\n18.Porter, E., Velez, Y . & Wood, T. J. Factual corrections eliminate false beliefs about COVID-19\nvaccines. Public Opin. Q. 86, 762\u2013773 (2022).\n19.Allen, J., Arechar, A. A., Pennycook, G. & Rand, D. G. Scaling up fact-checking using the wisdom\nof crowds. Sci. Adv. 7, eabf4393 (2021).\n20.Martel, C., Allen, J., Pennycook, G. & Rand, D. G. Crowds can effectively identify misinformation at\nscale. Perspectives on Psychol. Sci. 17456916231190388 (2022).\n21.Williamson, P. Take the time and effort to correct misinformation. Nature 540, 171\u2013171 (2016).\n9/50\n22.Pennycook, G., Bear, A., Collins, E. T. & Rand, D. G. The implied truth effect: Attaching warnings to\na subset of fake news headlines increases perceived accuracy of headlines without warnings. Manag.\nSci.66, 4944\u20134957 (2020).\n23.Bommasani, R. et al. On the opportunities and risks of foundation models. arXiv preprint\narXiv:2108.07258 (2021).\n24.Editorials. AI will transform science \u2013 now researchers must tame it. Nature 621(2023).\n25.Sharma, A., Lin, I. W., Miner, A. S., Atkins, D. C. & Althoff, T. Human\u2013AI collaboration enables\nmore empathic conversations in text-based peer-to-peer mental health support. Nat. Mach. Intell. 5,\n46\u201357 (2023).\n26.Augenstein, I. et al. Factuality challenges in the era of large language models. arXiv preprint\narXiv:2310.05189 (2023).\n27.OpenAI. GPT-4 technical report. ArXiv abs/2303.08774 (2023).\n28.Dubey, A. et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024).\n29.He, B., Ahamad, M. & Kumar, S. Reinforcement learning-based counter-misinformation response\ngeneration: a case study of COVID-19 vaccine misinformation. In Proceedings of the ACM Web\nConference 2023 , 2698\u20132709 (2023).\n30.Kim, K. et al. Can llms produce faithful explanations for fact-checking? towards faithful explainable\nfact-checking via multi-agent debate. arXiv preprint arXiv:2402.07401 (2024).\n31.Zeng, F. & Gao, W. JustiLM: Few-shot justification generation for explainable fact-checking of\nreal-world claims. Transactions Assoc. for Comput. Linguist. 12, 334\u2013354 (2024).\n32.Peskoff, D. & Stewart, B. M. Credible without credit: Domain experts assess generative language\nmodels. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\n(Volume 2: Short Papers) , 427\u2013438 (2023).\n33.Shuster, K., Poff, S., Chen, M., Kiela, D. & Weston, J. Retrieval augmentation reduces hallucination in\nconversation. In Findings of the Association for Computational Linguistics: EMNLP 2021 , 3784\u20133803\n(2021).\n34.Peng, B. et al. Check your facts and try again: Improving large language models with external\nknowledge and automated feedback. arXiv preprint arXiv:2302.12813 (2023).\n35.Mallen, A. et al. When not to trust language models: Investigating effectiveness of parametric\nand non-parametric memories. In Proceedings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , 9802\u20139822 (2023).\n36.Vu, T. et al. FreshLLMs: Refreshing large language models with search engine augmentation. arXiv\npreprint arXiv:2310.03214 (2023).\n37.Gao, L. et al. RARR: Researching and revising what language models say, using language models. In\nProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers) , 16477\u201316508 (2023).\n38.Wang, H. & Shu, K. Explainable claim verification via knowledge-grounded reasoning with large\nlanguage models. In Findings of the Association for Computational Linguistics: EMNLP 2023 ,\n6288\u20136304 (Association for Computational Linguistics, 2023).\n10/50\n39.Yue, Z. et al. Evidence-driven retrieval augmented response generation for online misinformation.\nInProceedings of the 2024 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies (Volume 1: Long Papers) , 5628\u20135643\n(2024).\n40.Menick, J. et al. Teaching language models to support answers with verified quotes. arXiv preprint\narXiv:2203.11147 (2022).\n41.Ecker, U. K. et al. The psychological drivers of misinformation belief and its resistance to correction.\nNat. Rev. Psychol. 1, 13\u201329 (2022).\n42.Swire-Thompson, B., DeGutis, J. & Lazer, D. Searching for the backfire effect: Measurement and\ndesign considerations. J. Appl. Res. Mem. Cogn. 9, 286\u2013299 (2020).\n43.Pan, L. et al. Fact-checking complex claims with program-guided reasoning. In Proceedings of the\n61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\n6981\u20137004 (2023).\n44.Qi, P., Yan, Z., Hsu, W. & Lee, M. L. SNIFFER: Multimodal large language model for explainable\nout-of-context misinformation detection. In Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition , 13052\u201313062 (2024).\n45.Stefanini, M. et al. From show to tell: A survey on deep learning-based image captioning. IEEE\nTransactions on Pattern Analysis Mach. Intell. 45, 539\u2013559 (2022).\n46.Li, J., Li, D., Savarese, S. & Hoi, S. BLIP-2: Bootstrapping language-image pre-training with frozen\nimage encoders and large language models. arXiv preprint arXiv:2301.12597 (2023).\n47.Feng, S., Park, C. Y ., Liu, Y . & Tsvetkov, Y . From pretraining data to language models to downstream\ntasks: Tracking the trails of political biases leading to unfair NLP models. In Proceedings of the\n61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\n11737\u201311762 (2023).\n48.Menczer, F., Crandall, D., Ahn, Y .-Y . & Kapadia, A. Addressing the harms of AI-generated inauthentic\ncontent. Nat. Mach. Intell. 5, 679\u2013680 (2023).\n49.Pan, Y . et al. On the risk of misinformation pollution with large language models. In Findings of the\nAssociation for Computational Linguistics: EMNLP 2023 , 1389\u20131403 (Association for Computational\nLinguistics, 2023).\n50.Hu, X. et al. Do large language models know about facts? arXiv preprint arXiv:2310.05177 (2023).\n51.Asai, A., Min, S., Zhong, Z. & Chen, D. Retrieval-based language models and applications. In\nProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6:\nTutorial Abstracts) , 41\u201346 (2023).\n52.Walker, M. & Matsa, K. E. News consumption across social media in 2021. Pew Res. Cent. (2021).\n53.Katz, D. M., Bommarito, M. J., Gao, S. & Arredondo, P. GPT-4 passes the bar exam. Philos.\nTransactions Royal Soc. A 382, 20230254 (2024).\n54.Bubeck, S. et al. Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv\npreprint arXiv:2303.12712 (2023).\n11/50\nFigure 1. Overview of M USE, an LLM augmented by addressing images and accessing timely knowledge from\ncredible publishers to enable identifying and explaining (in)accuracies in a piece of multimodal content with\naccurate and trustworthy references. Given a piece of content that may or may not be misinformation,\nMUSE searches for related and credible web pages, from which extracts evidence as refutations or contexts, with\nwhich generates a response identifying and explaining the (in)accuracies within it. a: Image processing.\nMUSE augments image captioning models with celebrity and optical character recognition (OCR) to generate\ninformative descriptions of images. b: Retrieval of related web pages. M USE retrieves web pages using\nLLM-generated queries and a web search engine and filters them based on their multimodal relevance to the given\ncontent. c-d: Credibility evaluation of the publishers of web pages ( c) and evidence-assisted response generation ( d).\nMUSE filters and ranks publishers based on their professionally rated factuality and bias. It starts from the web\npages with the highest factuality and least bias and leverages an LLM to extract evidence refuting or contextualizing\nthe given content. It continues down the ranking, stopping when it has obtained sufficient refutations (i.e., at least\ntwo pages were found to refute the misinformation) or gone through all the credible pages. Finally, it generates a\nresponse by providing an LLM with the extracted evidence. Besides identifying and correcting a false post shown\nhere, MUSE can also identify and respond to accurate, partially accurate, and factually accurate but misleading (see\nexamples in Supplementary Fig. S5).\n12/50\nFigure 2. Results of expert evaluation ( p<2\u00d710\u22125for each approach pair respectively in a-nby Mann-Whitney\nU test; experiments=84). a: The overall quality of M USE-generated responses (mean \u00b1SD: 8 .1\u00b12.0;n=232) is\n29% higher than laypeople\u2019s high-helpfulness responses (6 .3\u00b12.0; 232), 37% higher than GPT-4-generated\nresponses (5 .9\u00b12.7; 232), and 56% higher than laypeople\u2019s average-helpfulness responses (5 .2\u00b12.1; 230).\nb-f: The quality of identifying and explaining inaccuracies. MUSE-generated responses more explicitly identify and\nexplain inaccuracies ( b), more comprehensively identify inaccuracies with fewer mistakes that falsely state an\naccurate claim as inaccurate or an inaccurate claim as accurate ( c-d), and more accurately and informatively explain\ninaccuracies ( e-f) than GPT-4-generated and laypeople\u2019s high- and average-helpfulness responses. g-k: The quality\nof generated text. MUSE\u2019s generated text is more relevant to the responded misinformation and factual than GPT-4\u2019s\ngenerated text and the text of high- and average-helpfulness responses by laypeople ( g-h).MUSE-generated text is\nmore fluent and coherent than the text of high-helpfulness responses by laypeople and additionally less toxic than\nthe text of average-helpfulness responses by laypeople ( i-k).l-n: The quality of links as references. M USE rarely\nwhile GPT-4 frequently hallucinates references; MUSE provides significantly more reachable links that are relevant\nto the generated text ( l-m). M USE\u2019s references are more credible than the references offered in high- and\naverage-helpfulness responses by laypeople ( n). Note that laypeople\u2019s responses were created on average 14 hours\nafter the social media post. Here, M USE only retrieved web pages published before the post (Methods).\n13/50\nacdbe\nFigure 3. Quality of responses to social media posts across modalities, fact-checking statuses, political divides,\ndomains, and tactics used to make them or part of them false or misleading. a: M USE consistently outperforms\nGPT-4 and laypeople who produce even high-helpfulness responses by at least 21% when responding to textual\ncontent (n=155) and multimodal content (n=77). b: M USE outperforms GPT-4 and laypeople who produce even\nhigh-helpfulness responses by at least 28% even when responding to content that has not been fact-checked online\n(n=195). c:MUSE consistently outperforms GPT-4 and laypeople who produce even high-helpfulness responses by\nat least 26% when responding to liberal content (n=110) and conservative content (n=50). d: M USE consistently\noutperforms GPT-4 and laypeople who produce even high-helpfulness responses by at least 25% when responding\nto content about politics and international affairs (n=80), economy and business (n=38), crime and law (n=38),\nsocial issues and human rights (n=30), and health and medicine (n=24). e: M USE consistently outperforms GPT-4\nand laypeople who produce even high-helpfulness responses by at least 19% when responding to misinformation\nthat includes misinterpretations or misrepresentations (n=51), false or oversimplified causation (n=35), lack of\ncontext (n=33), fabrications (n=31), loaded language (n=30), false or biased data (n=29), and improper analogies or\nequivalences (n=19). Note that laypeople\u2019s responses were created on average 14 hours after the social media post.\nHere, M USE only retrieved web pages published before the post (Methods).\n14/50\nMethods\nImplementation Details of M USE\nInformative image captioning. We employed pretrained BLIP-246for image captioning with \u201c A photo\nof\u201d as the prompt, Amazon Rekognition API (aws.amazon.com/rekognition) for celebrity recognition, and\nAmazon Textract API (aws.amazon.com/textract) for OCR. GPT-4 ( gpt-4-0613 ) was leveraged with\nin-context learning to integrate image captioning, celebrity recognition, and OCR results into informative\nimage descriptions. As examples, we selected eight images with quotes, photos, screenshots of posts,\narticles, and charts from social media, and manually generated their informative descriptions (see the\nexample images in Supplementary Fig. S10 and the prompt in Supplementary Fig. S11). These example\nimages do not appear in the dataset we used.\nQuery generation. We applied GPT-4 ( gpt-4-0613 ) to generate queries. The prompt was \u201c Given a\ntweet, you are required to generate Ndifferent queries from the tweet for the Google search engine to\nget the most relevant web content to fact-check the tweet. If the given tweet is not informative enough\nto generate a query, you should answer \"none\". \u201d;N=3for text-only tweets, and N=5for tweets with\nimages. The tweet information concatenated its textual content, informative descriptions of images (for\ntweets with images), time, and the poster\u2019s name.\nWeb search. Google Programmable Search Engine (programmablesearchengine.google.com) was utilized\nfor text-only misinformation. We limited its search scope to the target publishers. The maximum number\nof retrieved web links with the same priority was set as 10. For misinformation with images, we used\nGoogle Reverse Image API provided by SerpApi (serpapi.com/google-reverse-image). Since Google\nReverse Image API does not have access to customizing sites to search, we started with collecting the\nfirst page of retrieval results by the reverse image search engine (i.e., the first ten retrieved web links) and\nselected the web pages from the target publishers. We set the maximum number of pages as five (i.e., the\nmaximum number of retrieved web links as 50) and the maximum number of retrieved web links with the\nsame priority as 10.\nRelevance of web pages to misinformation content. First, we obtained the web content from each\nretrieved web link based on news-please, a generic and open-source web content extractor that works for a\nlarge variety of websites55. To compute the relevance between a piece of text-only misinformation and a re-\ntrieved web page, we first applied a pretrained Sentence-Transformer ( msmarco-distilbert-base-\ntas-b )56to embed the misinformation (URLs and emojis were removed) and the web page\u2019s main text.\nThen, we measured their relevance by the dot product of two embeddings, following the guidance from\nReimers and Gurevych56. The web page was relevant to the misinformation only if their dot product\nwas equal to or above a threshold value. To determine this threshold value, we randomly selected ten\npieces of text-only misinformation excluded in MUSE\u2019s evaluation, collected the top ten web pages for\neach piece of misinformation after searching the web, and manually checked their actual relevance and\ncomputed relevance scores to the misinformation. We set this threshold value as 90 such that the removed\nweb pages were indeed irrelevant. For misinformation with images, we further adopted a pretrained\nVision-Transformer ( facebook/dino-vitb8 )57to embed each image of the misinformation and the\nweb page\u2019s main image and measured their relevance by the cosine similarity of two embeddings. The\nweb page was relevant to the misinformation only if the textual relevance was equal to or above 95 or the\nvisual relevance was equal to or above 0.7. We determined the threshold values in the same way as for\ntext-only misinformation, which ensured the selected web pages were indeed relevant.\nCredibility evaluation of publishers. We used the professional human ratings from Media Bias/Fact\n15/50\nCheck (MBFC, mediabiasfactcheck.com) to determine the factuality and bias of web pages. MBFC is\na widely accepted independent and transparent website offering a large-scale evaluation of more than\n5,000 publishers58\u201360. It provides six factuality categories: \u201cvery high,\u201d \u201chigh,\u201d \u201cmostly factual,\u201d \u201cmixed,\u201d,\n\u201clow,\u201d and \u201cvery low\u201d and 11 bias categories: \u201cleast biased,\u201d \u201cleft-center,\u201d \u201cright-center,\u201d \u201cleft,\u201d \u201cright,\u201d\n\u201cextremely left,\u201d \u201cextremely right,\u201d \u201cpro-science,\u201d \u201cquestionable,\u201d \u201csatire,\u201d and \u201cconspiracy-pseudoscience\u201d\n(see their definitions and statistics in Supplementary Table S1). MUSE only considered as references the\nweb pages whose factuality was annotated as one of \u201cvery high,\u201d \u201chigh,\u201d and \u201cmostly factual\u201d, and bias\nwas annotated as one of \u201cleast biased,\u201d \u201cleft-center,\u201d \u201cright-center,\u201d and \u201cpro-science,\u201d where \u201cpro-science\u201d\npublishers are defined as consisting of least biased legitimate science publishers (Supplementary Table S1).\nIn this way, MUSEexplicitly excluded moderately to strongly biased publishers (e.g., Daily Beast and Fox\nNews). It also explicitly excludes the publishers whose factuality is mixed (e.g., Wikipedia and Twitter) or\nlow, including those rejecting established scientific consensus on issues such as climate change or vaccines\nand identified as overt propaganda by reputable third-party evaluators (e.g., Infowars and Natural News;\nSupplementary Table S1). MUSE further divided the publishers considered as potential references into\nthree priorities. High-priority publishers (e.g., CDC, Science, Pew Research, and Reuters; n=118) have\n\u201cvery high\u201d factuality and are either \u201cleast biased\u201d or \u201cpro-science.\u201d Of the remaining, publishers whose\nfactuality is at least \u201chigh\u201d were labeled medium priority (e.g., Britannica, Statista, Psychology Today,\nThe Economist, The Dispatch, NPR, Propublica, and Know Your Meme; n=2,123), and publishers who do\nnot have high- or medium priority were low priority (e.g., Forbes and USA Today; n=204).\nEvidence extraction. We leveraged GPT-4 ( gpt-4-0613 ) for evidence extraction. The prompt is\n\u201cGiven an article: 1. Quote its paragraphs, at most two, that explicitly and completely refute the given\ntweet. 2. Quote its paragraphs, at most two, that implicitly refute the given tweet. Such paragraphs often\nprovide the tweet\u2019s context that can imply the tweet is cherry-picking by showing the full picture. If the\narticle does not have such content or is irrelevant to the tweet, you should answer \u2018none. \u2019 \u201d The article\ninformation included the article\u2019s content and published date. The article\u2019s content has the maximum\nnumber of characters, which we set as 20,000 considering gpt-4-0613 \u2019s context window is 8,192\ntokens. The tweet information concatenated its textual content, informative image captions (for tweets\nwith images), time, the poster\u2019s name, the poster\u2019s screen name, and the poster\u2019s description.\nResponse generation. We utilized GPT-4 ( gpt-4-0613 ) for response generation. The prompt is \u201c You\nare required to respond to a tweet, given some facts as references. Your response should satisfy all the\nfollowing requirements: - Your response should explain where and why the tweet is or is not misinformed\nor potentially misleading. - You should prioritize the facts very close to the date the user tweeted, very\nrecently, and listed at the beginning of the facts. - You should show the URLs that support your explanation.\nYou should not number the URLs. - Your response should be informative and short. - Your response should\nstart with \u2018This tweet is. \u2019 \u201d The tweet information concatenated its textual content, informative image\ncaptions (for tweets with images), time, the poster\u2019s name, the poster\u2019s screen name, and the poster\u2019s\ndescription. The facts listed every piece of extracted evidence with its source link and published date. The\npieces of evidence were sorted by their publishers\u2019 priorities (from highest to lowest). Pieces of evidence\nwith the same priority were further sorted by their relevance to the tweet in descending order, which has\nbeen shown to increase GPT-4\u2019s accuracy36.\nEvaluation\nHelpfulness classification. The helpfulness of laypeople\u2019s responses in Community Notes is positively\nassociated with their helpfulness scores, normally distributed from -0.3 to 0.6 with an average score of 0.17\n(standard deviation: 0.17; Supplementary Fig. S12; as of February 2023). We viewed laypeople\u2019s responses\n16/50\nwhose helpfulness scores are equal to or above 0.35 as having high helpfulness, as the average helpfulness\nscore of these responses is 0.44, which is above 0.4\u2014X\u2019s suggested threshold value to differentiate helpful\nresponses, often displayed on the corresponding tweets on X and visible to the public (Supplementary\nFig. S6), from the others17(Supplementary Fig. S12). We considered laypeople\u2019s responses whose\nhelpfulness scores are in [0.05, 0.25) to be average helpfulness, as the average helpfulness score of these\nresponses is 0.17, same as the average helpfulness score of all laypeople\u2019s responses in Community Notes\n(Supplementary Fig. S12).\nAccuracy of social media posts. We obtained the accuracy label of the tweets included in our evaluation\nbased on their responses generated by MUSEand baselines along with the annotations of experts (specified\nlater). Specifically, we selected the responses that identify a tweet\u2019s (in)accuracies without mistakes. If\na tweet has more than one such response, we further selected the response that has the highest overall\nquality score. Then, we determined a tweet\u2019s accuracy by manually reviewing the corresponding response.\nWe observed that 48% of the tweets are a combination of accurate claims and inaccurate or misleading\nclaims, 46% are inaccurate or misleading, 3% are fully accurate and not misleading, and the remaining\n3% cannot be determined are not unverifiable. Note that we neither presuppose the fine-grained accuracy\nlabels of the tweets nor whether the tweets are misinformation in both M USE\u2019s design and evaluation.\nResponse approaches. We included laypeople, MUSE, and MUSE\u2019s variants as the approaches evaluated\nin our study. For each tweet, laypeople have two responses: one has high helpfulness, and the other\nhas average helpfulness. We further generated responses by MUSE. Note that laypeople\u2019s responses\nwere created in the past, where MUSE could potentially have an advantage by retrieving more recently\npublished web pages. Therefore to have a fair comparison, we constrained MUSE to only retrieve older\nweb pages. Responses from Community Notes range from seven minutes to three years (median: 14\nhours) after the tweet was originally posted on social media. We generated one response by MUSEto each\ntweet by only retrieving web pages published thirty minutes before the creation time of the corresponding\nlaypeople\u2019s high-helpfulness response (Supplementary Fig. S13). We also had MUSEgenerate an additional\nresponse to each tweet by only retrieving web pages published thirty minutes before the creation time\nof the corresponding laypeople\u2019s average-helpfulness response (Supplementary Fig. S13). To evaluate\nMUSE\u2019s capability for immediately responding to potential misinformation, we finally generated one\nresponse where MUSEonly retrieved web pages published before the post time of the corresponding tweet.\nMoreover, we generated one response to each tweet by GPT-4 ( gpt-4-0613 ), which can be seen as a\nvariant of MUSEthat is not augmented by credibility-aware retrieval and vision-enabled, i.e., only has the\nstep of response generation in Fig. 1d. For tweets with images, we included two more variants of MUSE:\none is augmented by credibility-aware retrieval but not vision-enabled (denoted as MUSE\\vision), and\nthe other is vice versa (denoted as MUSE\\retrieval). For MUSE\\vision, it generated one response to each\ntweet by only retrieving web pages published thirty minutes before the creation time of the corresponding\nlaypeople\u2019s high-helpfulness response.\nExpert recruitment. We worked with Hacks/Hackers (hackshackers.com), an international grassroots\njournalism organization, to recruit fact-checking and journalism experts. Hacks/Hackers helped send our\nrecruitment materials to the people in its email list. Recruitment started in May 2023 and continued until\nAugust 2023. Among the 15 respondents, we selected the 12 respondents who had the highest experience\nin fact-checking or journalism and whose proficiency in English is at least fluent. Specifically, five (41.7%)\nof the selected respondents had 1\u20133 years, three (25%) had 4\u20136 years, one (8.3%) had 7\u20139 years, and three\n(25%) had 9+ years of experience in fact-checking or journalism. Nine (75%) of the selected respondents\nare native speakers, and three (25%) are fluent in English. The study was approved by the University of\nWashington\u2019s Institutional Review Board (determined to be exempt; IRB ID STUDY00017831). We have\n17/50\nalso obtained informed consent from all respondents.\nStudy workflow. We divided our study into two phases:\n\u2022Phase I: Onboarding. First, we scheduled and hosted an onboarding remote meeting with every\nparticipant. We explained our data annotation protocol (Supplementary Fig. S14-S20) and demon-\nstrated the use of our web interface for data annotation (Supplementary Fig. S21). Every participant\nwas asked to complete three annotation tasks (i.e., annotate the order-randomized responses made\nby various approaches to three tweets) after the meeting. Phase-I annotation was designed for the\nparticipants to enhance their understanding of the protocol and to familiarize themselves with the\ninterface where they were required to provide explanations. Finally, we manually reviewed the\nexplanations and sent each participant feedback to resolve any potential confusion and misunder-\nstanding. Two participants who are native speakers in English dropped out of the study during Phase\nI. One of the participants had 1\u20133 years, and the other had 9+ years of experience in fact-checking\nor journalism. We removed their data from the final analyses and moved their annotation tasks to\nPhase II. There were 15 tasks completed in this training session; the same task can be assigned to\nmore than one participant. In our final analyses, we excluded any data from this training session.\n\u2022Phase II: Annotation. We randomly divided the remaining ten participants into five groups, with\ntwo participants in each group. Every participant was randomly assigned 26 or 27 tasks for Phase II\nannotation. Seven, around 30% of these tasks, were the same as those assigned to another participant\nwithin the same group, which allowed us to evaluate inter-annotator agreement. The remaining 19\nor 20 tasks were different from those assigned to the other participants. No participants dropped out\nof the study during Phase II. Finally, all the 232 tasks at this phase were completed and included in\nour final analyses. In our final analyses, the weight of each annotation for the tasks assigned to two\nparticipants was 0.5 and that for the tasks assigned to one participant was 1 to avoid bias towards\nthe tasks assigned to two participants.\nWe compensated each participant who completed the study with a 450 USD Amazon gift card.\nEvaluation criteria. Recruited experts evaluated each response from the following perspectives:\n\u2022Quality of identifying and explaining (in)accuracies. Such quality was measured by the response\u2019s\n1)explicitness , i.e., whether the response explicitly, implicitly, or unclearly identifies and explains\n(in)accuracies; 2) existence of (in)correct identifications , i.e., whether the correction precisely\nidentifies any (in)accuracies, with or without falsely identifying any inaccurate claims as accurate or\nan accurate claim as inaccurate; 3) comprehensiveness of correct identifications , which is five-scaled,\nranging from no comprehensiveness (the response does not precisely identify any (in)accuracies in\nthe tweet) to extremely high comprehensiveness (the response precisely identifies every (in)accuracy\nin the tweet); 4) accuracy of explanations , which is five-scaled, ranging from completely inaccurate\nto fully accurate; and 5) informativeness of accurate explanations , ranging from score 0 (the\nresponse does not provide any context in explaining the (in)accuracies) to 10 (the response provides\ncompletely sufficient context that helps a person understand why the content is inaccurate).\n\u2022Quality of generated text. Such quality was measured by the generated text\u2019s 1) relevance to the\ntweet , ranging from score 0 (the generated text is completely irrelevant to the responded tweet) to\n10 (the generated text catches at least the most critical point in the responded tweet); 2) factuality ,\nwhich is five-scaled, ranging from completely false, inaccurate, or unverifiable to completely factual\nand accurate; 3) fluency , i.e., whether the generated text had mistakes in the use of English, such\n18/50\nas capitalization errors, misspelled words, and sentence fragments61, 62\u2014the fluency had three\nlevels: high (the generated text does not have any mistakes), medium (the generated text has minor\nmistakes barely causing confusion and reducing the text\u2019s readability), and low (the generated\ntext has mistakes leading to confusion and reducing the text\u2019s readability); 4) coherence (logical\nconsistency and correct and valid reasoning)61, i.e., whether the generated text is barely, partially, or\nfully coherent and logical; and 5) toxicity , i.e., whether the generated text is impolite, provoking, or\nbiased.\n\u2022Quality of references. Such quality was measured by the reference\u2019s 1) reachability , i.e., whether\nthe web page is found; 2) relevance to the generated text , i.e., whether the web page is relevant to or\nsupports the generated text; and 3) credibility , ranging from low (the page content and its publisher\nare both questionable), medium, high, to very high (the page content is backed up by facts with\nminimal bias, and its publisher always publishes high-quality information with minimal bias).\n\u2022Overall quality of corrections. Such quality was measured by taking all 13 aforementioned\nevaluation criteria into account, ranging from 0 (very low quality) to 10 (very high quality).\nInter-annotator agreement. We adopted the weighted Cohen\u2019s kappa coefficient ( \u03ba) to compute the\nagreement between two experts in every group, except for the toxicity of generated text, the fluency\nof generated text, and the relevance of references to the generated text because of their highly skewed\ndistributions. Such distributions significantly underestimate the inter-annotator agreement and may cause\nthe coefficient calculation to be not applicable63; for example, when two experts in a group annotated all\npieces of generated text as not toxic. Instead, we reported the average observed agreement for the toxicity\nof generated text, the fluency of generated text, and the relevance of references to the generated text,\nwhich is 0.96 (vs \u03bais not applicable), 0.86 (vs \u03ba=0.02), and 0.81 (vs \u03ba=0.02), respectively. According\nto\u03ba\u2019s interpretation64, experts achieved substantial agreement on the reachability of references (mean:\n0.79). They achieved moderate agreement on the overall quality of responses (0.51), the informativeness\nof accurate explanations (0.50), the comprehensiveness of correct identifications (0.46), and the relevance\nof generated text to the responded responses (0.41). They achieved fair agreement on the accuracy of\nexplanations (0.40), the factuality of generated text (0.39), the existence of (in)correct identifications (0.39),\nthe explicitness of identifying and explaining (in)accuracies (0.34), the credibility of references (0.31), and\nthe coherence of generated text (0.28), consistent with prior observations that even fact-checking experts\ncan disagree on misinformation19,65.\nImpact of time. We assessed the impact of time on MUSE\u2019s performance from two perspectives. First, we\ncompared three responses by MUSE to each tweet, which simulated responding the tweet under different\nstarting times. Results in Supplementary Fig. S22 show that MUSE performs similarly (mean \u00b1SD of the\noverall quality of responses: 8.1 \u00b12.0) when it starts responding the tweet right after appearing on social\nmedia, when it follows the starting times of laypeople who produce high-helpfulness responses (median:\n13 hours after the tweet was posted; Supplementary Fig. S13), and when it follows the starting times\nof laypeople who produce average-helpfulness responses (median: 16 hours after the tweet was posted;\nSupplementary Fig. S13). Second, we separated tweets posted after September 2021 (n=207) from all\ntweets (n=232), considering that GPT-4 ( gpt-4-0613 )\u2019s training data is up to September 2021. In other\nwords, tweets posted before and in September 2021, along with its Community Notes data, might have\nbeen included in the training data of the GPT-4 that MUSE augments. If this information was available\nduring GPT-4 training, it may lead to artificially inflated performance that is unlikely to generalize to\nfuture tweets, where such information is not available. Results in Supplementary Fig. S23 show that\n19/50\nMUSE performs stably (mean \u00b1SD of the overall quality of corrections: 8.1 \u00b12.0) when responding to all\ntweets and when responding to tweets posted after September 2021, consistently outperforming GPT-4\nand even high-helpfulness responses made by laypeople.\nImpact of retrieval and vision. We have demonstrated that MUSEoutperforms GPT-4, which can be seen\nas a variant of MUSE that is not augmented by credibility-aware retrieval and vision-enabled (Approach).\nResults in Supplementary Fig. S24 further demonstrate that both the retrieval and vision components are\nvaluable. Overall, MUSE outperforms its variant that is not augmented by the retrieval by 25% and its\nvariant that is not vision-enabled by 33% in the quality of generated responses.\nImportance of evaluation criteria. We calculated the Spearman correlation coefficient between experts\u2019\nannotation results on overall response quality and each criterion that specifies overall response quality.\nResults demonstrate that each of the 13 criteria we proposed and defined is significantly associated with\noverall response quality ( p<10\u22125;n=1124 ; Supp. Fig. S25). We further separated responses into two\ngroups based on their overall quality annotated by experts. One group has relatively low quality (i.e.,\nquality is in [0,0.6]), and the other has relatively high quality (i.e., quality is in (0.6,1]). The threshold of\n0.6 is close to the median quality rating, leading to two similarly sized groups. Calculating the correlation\ncoefficient for each group reveals the following insights (Supp. Fig. S25). First, to enhance the overall\nquality from low to medium, a response should accurately identify and explain inaccuracies, ensure the\ngenerated text is factual and not toxic, and use references relevant to the text. Second, to further improve\nthe response\u2019s overall quality from medium to high, it is not sufficient to identify just an inaccuracy; instead,\nevery inaccuracy in the misinformation needs to be identified accurately. Additionally, the correction\nshould be explicit, fluent, and coherent, which enhances readability. The explanation should be informative\nand supported by credible references, thereby improving the response\u2019s transparency and trustworthiness.\nThe generated text should be relevant to the misinformation, such as by capturing its multimodal content.\nFinally, it is always crucial to generate factual text that accurately explains inaccuracies.\nRuntime and cost. The average runtime of MUSE in responding to a social media post was two minutes.\nNote that the experiments were conducted on 16G memory M1 CPU, running five parallel processes. The\nruntime could be further optimized with GPUs and more memory. Our focus in designing MUSE was\nin maximizing the quality of corrections. The total cost of MUSE in responding to a social media post\nwas roughly 0.5 USD, almost all from the GPT-4 ( gpt-4-0613 ) that MUSE augmented. In particular,\nevidence extraction cost the most, and increases with the number of retrieved web pages used to extract\nevidence and their content length, which is often substantial. We reduced the cost by removing the\nretrieved web pages with relatively low relevance to misinformation, which also helped reduce GPT-4\u2019s\nhallucinations assessed through qualitative evaluation (Approach; Supplementary Fig. S3). The cost could\nbe further reduced significantly with an open-sourced LLM, such as Llama-3 (Discussion; Supp. Fig. S9).\nData availability\nData used in this study are available at https://github.com/Social-Futures-Lab/MUSE. We comply with\nX/Twitter Terms of Service by only releasing the IDs of tweets. The experts\u2019 names are anonymized.\nCode availability\nCode used for analyzing the study data is available at https://github.com/Social-Futures-Lab/MUSE.\nSource code of M USE will be made available with publication.\n20/50\nReferences\n55.Hamborg, F., Meuschke, N., Breitinger, C. & Gipp, B. news-please: A generic news crawler and\nextractor. In Proceedings of the 15th International Symposium of Information Science , 218\u2013223, DOI:\n10.5281/zenodo.4120316 (2017).\n56.Reimers, N. & Gurevych, I. Sentence-BERT: Sentence embeddings using Siamese BERT-networks.\nInProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the\n9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982\u20133992\n(2019).\n57.Caron, M. et al. Emerging properties in self-supervised vision transformers. In Proceedings of the\nIEEE/CVF International Conference on Computer Vision , 9650\u20139660 (2021).\n58.Weld, G., Glenski, M. & Althoff, T. Political bias and factualness in news sharing across more than\n100,000 online communities. In Proceedings of the International AAAI Conference on Web and Social\nMedia , vol. 15, 796\u2013807 (2021).\n59.Zhou, X., Mulay, A., Ferrara, E. & Zafarani, R. ReCOVery: A multimodal repository for COVID-19\nnews credibility research. In Proceedings of the 29th ACM International Conference on Information\n& Knowledge Management , 3205\u20133212 (2020).\n60.Bozarth, L., Saraf, A. & Budak, C. Higher ground? How groundtruth labeling impacts our under-\nstanding of fake news about the 2016 US presidential nominees. In Proceedings of the International\nAAAI Conference on Web and Social Media , vol. 14, 48\u201359 (2020).\n61.Yuan, W., Neubig, G. & Liu, P. BARTScore: Evaluating generated text as text generation. Adv. Neural\nInf. Process. Syst. 34, 27263\u201327277 (2021).\n62.Fabbri, A. R. et al. SummEval: Re-evaluating summarization evaluation. Transactions Assoc. for\nComput. Linguist. 9, 391\u2013409 (2021).\n63.Xu, S. & Lorber, M. F. Interrater agreement statistics with skewed data: Evaluation of alternatives to\ncohen\u2019s kappa. J. Consult. Clin. Psychol. 82, 1219 (2014).\n64.McHugh, M. L. Interrater reliability: the kappa statistic. Biochem. Medica 22, 276\u2013282 (2012).\n65.Bhuiyan, M. M., Zhang, A. X., Sehat, C. M. & Mitra, T. Investigating differences in crowdsourced\nnews credibility assessment: Raters, tasks, and expert criteria. Proc. ACM on Human-Computer\nInteract. 4, 1\u201326 (2020).\nAcknowledgements\nWe would like to thank Hacks/Hackers for advertising the study and helping with the recruitment. We also\nthank members of the UW Social Futures Lab and Behavioral Data Science Group for their suggestions and\nfeedback. This work was supported in part by the National Science Foundation\u2019s Convergence Accelerator\nprogram under Award No. 49100421C0037. T.A. and A.S. were supported in part by the Office of Naval\nResearch (#N00014-21-1-2154), NSF IIS-1901386, and NSF CAREER IIS-2142794.\nAuthor contributions\nX.Z., A.X.Z., and T.A. designed the study. X.Z. led, and A.S. assisted in developing the model. A.S. built\nthe web interface for evaluation. X.Z. prepared and analyzed the data. X.Z. drafted and all authors revised\nthe manuscript. A.X.Z. and T.A. supervised the study.\n21/50\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary information is available for this paper.\nCorrespondence and requests for materials should be addressed to Tim Althoff (althoff@cs.washington.edu)\nand Amy X. Zhang (axz@cs.uw.edu).\n22/50\nSupplementary materials\nList of supplementary materials\nTable S1\nFigures S1 to S25\n23/50\nTable S1. Definitions and statistics of factuality and bias categories offered by Media Bias/Fact Check\n(mediabiasfactcheck.com).\nCategory Definition # of sources\nFactuality:\n- Very high: The source is consistently factual, relies on credible information, promptly\ncorrects errors, and has never failed any fact checks in news reporting or\nopinion pieces.118\n- High: The source is mostly factual and uses mostly credible, low-biased, or high-\nfactual sources. It corrects errors quickly and has failed only one news fact\ncheck and up to two op-ed fact checks.2,313\n- Mostly factual: The source is generally accurate but may have a few uncorrected fact-check\nfailures. It can fail up to three op-ed fact checks, especially if it is a low-\nvolume site. While it may use biased sources occasionally, it mostly links to\nfactual content. It is usually pro-science but may sometimes use misleading\nwording or offer alternative viewpoints. It is reasonably transparent and\ntrustworthy most of the time, but caution is advised.326\n- Mixed: The source may rely on improper sourcing or link to other biased or mixed-\nfactual sources. It often has multiple failed fact checks and does not correct\nfalse information or lacks transparency, including the absence of a disclosed\nmission statement or ownership details. Sources rejecting established scien-\ntific consensus on issues such as climate change or vaccines will receive this\nrating or lower. Sources identified as overt propaganda or designated as hate\ngroups by reputable third-party evaluators will receive this rating or lower\ndue to their inherent bias and potential spread of misleading information.1,437\n- Low: The source is often unreliable and should be fact-checked for fake news,\nconspiracy theories, and propaganda.677\n- Very low: The source is almost always unreliable and should always be fact-checked\nfor intentional misinformation.252\nTotal: 5,123\nBias:\n- Least biased: The source has minimal bias and uses very few loaded words (i.e., wording\nthat attempts to influence an audience by using an appeal to emotion or\nstereotypes). It is factual and usually sourced.1,054\n- Left-center: The source has a slight to moderate liberal bias. It often publishes factual\ninformation that utilizes loaded words to favor liberal causes. It is generally\ntrustworthy for information but may require further investigation.850\n- Right-center: Similar to the definition of left-center bias but replacing liberal with conser-\nvative.492\n- (Extremely) left: The source is moderately to strongly biased toward liberal causes through\nstory selection or political affiliation. It may utilize strong loaded words,\npublish misleading reports, and omit reporting of information that may\ndamage liberal causes. It may be untrustworthy.402\n- (Extremely) right: Similar to the definition of (extremely) left bias but replacing liberal with\nconservative.314\n24/50\n- Pro-science: The source consists of legitimate science or is evidence-based through the\nuse of credible scientific sourcing. Legitimate science follows the scientific\nmethod, is unbiased, and does not use emotional words. The source also\nrespects the consensus of experts in the given scientific field and strives\nto publish peer-reviewed science. It may have a slight political bias but\nadheres to scientific principles.189\n- Conspiracy-\npseudoscience:The source may publish unverifiable information not always supported by\nevidence. It may be untrustworthy for credible or verifiable information, so\nfact-checking and further investigation are recommended on a per-article\nbasis when obtaining information from it.433\n- Questionable: The source exhibits one or more of the following: extreme bias, consistent\npromotion of propaganda or conspiracies, poor or no sourcing of credible\ninformation, a complete lack of transparency, or fake news (i.e., the delib-\nerate attempt to publish hoaxes or disinformation for profit or influence).\nIt may be very untrustworthy and should be fact-checked on a per-article\nbasis.1,390\n- Satire: The source exclusively uses humor, irony, exaggeration, or ridicule to\nexpose and criticize people\u2019s stupidity or vices, particularly in the context\nof contemporary politics and other topical issues. It does not attempt to\ndeceive.148\nTotal: 5,272\n25/50\n100101102\nHours020406080100Tweets received their first response (%)\nAny response\nHigh-quality responseFigure S1. Distribution of potential misinformation in X Community Notes (as of February 2023) that received its\nfirst response (gray) or first high-quality response (orange) within a certain amount of time.\n26/50\nFigure S2. Examples that show that generating multiple queries helps decompose a post, which may have multiple\nclaims that each needs to be verified, whereas generating one query may overlook some of them and hence lead to\nnot comprehensive identifications of (in)accuracies. Bold text: the verification-needed claims that are overlooked\nwhen generating one query but captured when generating more than one query.\n27/50\nFigure S3. Examples that show how retrieved web pages with relatively low relevance to potential misinformation\ncan promote LLM (in this case, GPT-4) hallucinations when generating responses.\n28/50\nFigure S4. Examples of informative image captions, which augment image captions with names of visually\nrepresented celebrities and embedded text (see Methods for implementation details).\n29/50\nFigure S5. Examples of M USE-generated responses to accurate, partially accurate, and factually correct but\nmisleading content on social media.\n30/50\nFigure S6. An example of a high-helpfulness response from Community Notes displayed on the corresponding\ntweet and visible to the public.\n31/50\n#BREAKING \ufe0f ACCORDING T O ISRAELI SOURCES, \nTHE ISRAELI ARMY  WILL  CONTINUE T O STRIKE \nSTRA TEGIC T ARGETS IN IRAN.\nCan Someone Please Explain Me \nWhat In \u203cHELL\u203c W ere Doing Obama \nAnd Fauci In Late 2015 In W uhan \nLaboratory \u2049\ufe0f   \nI hope you don't mind this \nadorably majestic blue owl \nin your newsfeed.\n#1a\n365,348 children went missing in 2020. Y ou haven't \nheard a word from the media about it. There enlies \nthe problem.#1\nAll 16 of Florida\u2019 s Republican members of the House voted \nAGAINST  federal disaster relief for Florida yesterday .\nFentanyl is devastating \nour communities, and \nlaw enforcement \nagents are on the front \nlines of the fight to stop \nit. T o help them protect \nus from this dangerous \ndrug, I introduced my \nbipartisan PREVENT  \nAct last week to ensure \nthey're properly \nequipped against \nsecondary exposure.#3#2\nPer Andy Howlett \u201cHow can anyone see this chart and \nseriously still be brainwashed into believing that we \nare at the end of days? It's very basic stuf f\u201d.#2\n#2cdb\nSo many people still wearing masks. I just want to ask you. If a pair of \nunderwear , really thick ones, high quality cotton, can\u2019t protect you from a \nfart, then how will a mask protect you from covid??\nEvery single year more than 600,000 people in the US die from cancer . The \ncountry has never once shut down. Not a single school has closed. Every year , \nover 600,000 people, of all ages and all races will continue to die from cancer .egf\nA  reminder that Biden ran on canceling * all *  \nyour federal student debt if you went to an \nHBCU or public college and make under \n$ 125k. That was the campaign trail.#1\nThis should be troubling to more people.\n#2\nOver 7 0 %  of Americans who died with \nCOVID, died on Medicare, and some \npeople want #MedicareForAll ?#1\n#1#2\nBREAKING :  police in Georgia have \ncharged a man for allegedly ** shooting \na 15 - year - old kid **  who was out \ncampaigning for @ ReverendW arnock.\n#2\nFigure S7. Examples of social media content that uses various tactics to make it or part of it false or misleading.\nThese tactics include a:Fabricating a news event (#1), a story with an authentic image (#2, also related to\nconspiracy theory), and an image with AI (#3). b:Lacking context regarding the motivation behind behavior. Here,\nit is the consideration that the bill contained no funding for Florida, without which could mislead readers. c:\nMisinterpreting or misrepresenting a plan, where Biden did not promise to cancel all the debt (#1), or symbol, which\nis not Nazi SS runes but a shorthand for the 46th Separate Airmobile Brigade (#2). d:Using loaded language .e:\nImproperly analogizing or equating masks blocking respiratory droplets and underwear blocking gas molecules (#1),\nand COVID-19 and cancer (#2). f:Presenting false, partial, or biased data . 365348 includes multiple reports for the\nsame child and runaways who may not be considered missing because of their guardians know their whereabouts\n(#1). The data ends in 1885 and is from a specific high elevation site in Greenland, not global temperatures (#2). g:\nImplying false or oversimplified causation . Many COVID-19 deaths occurred among Medicare beneficiaries\nbecause Medicare primarily serves the groups who are at greater risk of adverse outcomes from COVID-19 (#1).\nThe boy was shot when\u2014but not because\u2014he was campaigning for Raphael Warnock (#2). Note that one content\nmay apply more than one tactic intentionally or accidentally.\n32/50\nFigure S8. Examples of M USE-generated responses to social media posts that lack evidence to verify.\n33/50\nFigure S9. Comparison between responses generated by GPT-4, Llama-3, and their based M USE. We observed\nthat GPT4-based MUSEand Llama3-based MUSEfrequently generate similar responses to social media content (see\nthe top example). GPT4-based M USE occasionally generates more comprehensive corrections than Llama3-based\nMUSE (see the middle example). Note that the knowledge cutoff for Llama3 is December 2023, whereas that of\nGPT-4 is September 2021. In other words, Llama-3\u2019s training data include more recent events and knowledge than\nGPT-4\u2019s (see the bottom example, where the post was posted in February 2023, and Llama-3 more accurately\nidentifies its falsehood than GPT-4).\n34/50\n(a)\n (b)\n (c)\n (d)\n(e)\n (f)\n(g)\n (h)\nFigure S10. Images as examples used for informative image captioning with in-context learning.\n35/50\n1Describe an image in an informative way. Your description should be only based on the given {short\ncaption}, {name of each person}, and {raw text}. If the image is from social media, you should\nstart with \"A screenshot of\". If the image is a quote from someone, you should start with \"A\nquote from\" followed by this person's name if there is any, then by the quoted text. If the image\nis an article, you should start with \"An article\". If the image is a photo, you should start with\n\"A photo of\". If the image is a map, you should start with \"A map of\". {raw text} may contain\nnonsense data that are unnecessarily included in the image description; however, {name of each\nperson} is not, and if the concept in {raw text} has a conflict with that in {short caption}\n(e.g., \"Robbie Lemos\" versus \"robbie leems\" shown later), {raw text} is often the right one.,\u2192\n,\u2192\n,\u2192\n,\u2192\n,\u2192\n,\u2192\n,\u2192\n,\u2192\n2short caption: {a woman with glasses and a quote that says, in real life, i assure you there is no\nsuch thing as algebra} ,\u2192\n3name of each person: {Fran Lebowitz}\n4raw text: {\"In real life, I assure you, there is no such thing as algebra.\"}\n5image description: {A quote from Fran Lebowitz, \"In real life, I assure you, there is no such thing\nas algebra.\"} ,\u2192\n6short caption: {two men in suits}\n7name of each person: {Jim Caviezel, Michael Emerson}\n8raw text: {}\n9image description: {A photo of Jim Caviezel and Michael Emerson in suits}\n10short caption: {robbie leems on twitter}\n11name of each person: {}\n12raw text: {Robbie Lemos @RobbieLemos 1d I'd like to congratulate my dear friend Deep Mind on a\nwonderful 1st day at work today at Google. Just in time for #EarthDay2023, cheers brother! 1 2\n3,790},\u2192\n,\u2192\n13image description: {A screenshot of a post of Robbie Lemos, \"I'd like to congratulate my dear friend\nDeep Mind on a wonderful 1st day at work today at Google. Just in time for #EarthDay2023, cheers\nbrother!\" The post was posted on Twitter.},\u2192\n,\u2192\n14short caption: {a moose}\n15name of each person: {}\n16raw text: {Yahoo Finance @YahooFinance Typically, the stock market bottoms four to five months before\na recession ends, but RBC's research details that it has bottomed as early as nine months before\nthe end of a recession. finance.yahoo.com Could the stock market power through a recession? 'This\nwould be rare.' 09:57 22/4/2023 3.4,011 Views 1 Retweet 1 Quote 5 Likes 1 Bookmark},\u2192\n,\u2192\n,\u2192\n17image description: {A screenshot of a post from Yahoo Finance, \"Typically, the stock market bottoms\nfour to five months before a recession ends, but RBC's research details that it has bottomed as\nearly as nine months before the end of a recession.\" The post shared an article from\nfinance.yahoo.com claiming, \"Could the stock market power through a recession? 'This would be\nrare.'\" with a picture of a moose. The post was posted at 09:57 22/4/2023.},\u2192\n,\u2192\n,\u2192\n,\u2192\n18short caption: {a person pouring tea into a cup}\n19name of each person: {}\n20raw text: {New research reveals how coffee and tea can affect risk of early death for adults with\ndiabetes By Sandee LaMotte, CNN Updated 7:01 PM EDT, Wed April 19, 2023 f The health benefits of\ntea 01:10 - Source: CNN},\u2192\n,\u2192\n21image description: {An article claiming, \"New research reveals how coffee and tea can affect risk of\nearly death for adults with diabetes.\" It attached a picture of a person pouring tea into a cup.\nIt was written by Sandee LaMotte, published by CNN, and updated at 7:01 PM EDT, Wed April 19,\n2023.},\u2192\n,\u2192\n,\u2192\n22short caption: {two people standing next to each other with the words love is blind}\n23name of each person: {Nick Lachey}\n24raw text: {\\\"Love Is Blind\\\" co-host faceplants with a regressive line of questioning Hayley Miller\nMSNBC DAILY MSNBC} ,\u2192\n25image description: {An article claiming, \"'Love Is Blind' co-host faceplants with a regressive line\nof questioning.\" It attached a picture of Nick Lachey and another person standing next to each\nother. It was written by Hayley Miller and published by MSNBC.},\u2192\n,\u2192\n26short caption: {a bar graph that shows how engaged are the most followed journalists on twitter}\n27name of each person: {Rahul Kanwal}\n28raw text: {How engaged are the most-followed journalists on Twitter? Percentage of tweets from each\njournalist that are at-replies BDUTT 64% ,\u2192\n29image description: {A bar graph showing how engaged the most followed journalists, including Rahul\nKanwal, are on Twitter through the percentage of tweets from each journalist that are at-replies.\nThe chart was made by mattmaldre.com.},\u2192\n,\u2192\n30short caption: {a graph showing the global defense budget by region}\n31name of each person: {}\n32raw text: {Global Defense Budgets by Region ($ Billions) $1,000 800 600 400 200 0 2020 2021 2022 2023\n2024 2025 Asia-Pacific Latin America North America Sub-Saharan Africa Europe Middle East & North\nAfrica Russia & Commonwealth of Independent States Source: Aviation Week},\u2192\n,\u2192\n33image description: {A graph showing the global defense budget by region. It is from Aviation Week.}\n34short caption: {[IMAGE_CAPTION]}\n35name of each person: {[CELEBRITIES]}\n36raw text: {[OCR]}\n37image description:\nFigure S11. LLM prompt for informative image captioning.\n36/50\n0.2\n 0.0 0.2 0.4 0.6\nHelpfulness scores102103Number of responses0.17\u00b10.17\n0.17\u00b10.060.44\u00b10.07All Average helpfulness High helpfulnessFigure S12. Distribution of helpfulness scores of laypeople\u2019s responses in X Community Notes. All: All\nlaypeople\u2019s responses in Community Notes. Average helpfulness: Laypeople\u2019s responses in Community Notes\nidentified with average helpfulness and used in our study. High helpfulness: Laypeople\u2019s responses in Community\nNotes identified with high helpfulness and used in our study. For x\u00b1y,x: mean, y: standard deviation. Community\nNotes data are regularly updated; ours are up until February 12, 2023.\n37/50\nAverage helpfulness High helpfulness\nLaypeople's responses101\n100101102103104Creation time (hours after the tweet was posted)\nFigure S13. Distribution of creation times of laypeople\u2019s responses in X Community Notes used in our study.\nMedian of the creation time of laypeople\u2019s average-helpfulness responses: 16 hours after the tweet was posted.\nMedian of the creation time of laypeople\u2019s high-helpfulness responses: 13 hours after the tweet was posted.\n38/50\nMisinformation\nResponse Study\nPlease evaluate and compare responses to misinformed or potentially\nmisleading tweets from various aspects, such as factuality.\nContent Warning\nThe study may contain tweets with but not limited to abusive language, which\nmay be disturbing you. If you have concerns or questions, please get in touch\nwith us at xzhou@cs.uw.edu later!\nPrerequisite\nTo participate in this study, you should have a decent understanding of fact-\nchecking and media bias.\nNotes before Starting\n1. You are allowed and encouraged to search online and use tools for\nannotation, but please be sure that you are collecting evidence from\ncredible sources, do not overtrust the tools, and have your own\njudgments. Meanwhile, please be aware that any GPT models, such as\nChatGPT, GPT-4, and Bing Chat are NOT allowed when annotating.\n2. Each response has a corresponding UTC time stamp when it was created.\nPlease note that some claims in the response can be false at this point but\nfactual back when the response was made, or vice versa. For example,\n\u201cElon Musk does not own Twitter\u201d is true in 2021 but false in 2023. For\nthese claims, you should consider their factuality consistent with when\nthe response was made. In other words, your fact-checking should be\nbased on the knowledge publically available before the response was\ncreated.\n3. When you are not con\u0000dent about a speci\u0000c annotation, you can brie\u0000y\nexplain it in the \u201cOther Comments / Explanation\u201d box. We understand it\nhappens, but please make your best judgment with or without references.\n4. Please be objective and politically neutral when annotating.\nFigure S14. Annotation instructions (page 1/7, continued on the next page).\n39/50\n5. Please use your computer (laptop or desktop, rather than mobile device)\nfor the annotation.\n6. Any questions? Do not hesitate to contact us at xzhou@cs.uw.edu!\nWhat Will You Do?\nYou will be shown 26 or 27 tweets that can be misinformed or potentially\nmisleading. For each tweet, you will be shown several responses \u2014 the number\ncan vary from three to seven, with four as an average \u2014 that are supposed to\nbe corrections in response to the tweet. In other words, each response aims to\nexplain where and why the tweet is misinformed or potentially misleading.\nEach response consists of text as explanations and/or links as references.\nYou will be asked to evaluate various aspects of the responses that re\u0000ect how\nhigh-quality the explanation is. Speci\u0000cally, you will need to answer the\nfollowing questions for each response:\nQ1) What's the clarity of the response in identifying and explaining where and\nwhy the tweet is misinformed or potentially misleading? Your answer should be\none of the following options:\nA. The response explicitly identi\u0000es and explains where and why the tweet\nis misinformed or potentially misleading (regardless of whether the\nidenti\u0000cation and explanation are correct). A typical example of such\nexpressions can be, \"Though it is true that X, the tweet is misinformed by\nclaiming that Y because Z\", where X and Y are from the tweet and Z is the\nexplanation.\nB. Given the response, it is hard to tell where and why the tweet is\nmisinformed or potentially misleading.\nC. Somewhere between A and B. For example, the response may only\nimplicitly identify and explain where and why the tweet is misinformed or\npotentially misleading.\nQ2) Does the response correctly identify where the tweet is misinformed or\npotentially misleading? Your answer should be one of the following options:\nA. Yes. The response correctly identi\u0000es at least one place in the tweet that\nis misinformed or potentially misleading. The response may overlook the\nothers, and the correctly identi\u0000ed place may not be the critical point of\nthe tweet. However, the response does not misidentify, i.e., explicitly claim\nwhere the tweet should be misinformed or potentially misleading as\naccurate or factual or vice versa.\nFigure S15. Annotation instructions (page 2/7, continued on the next page).\n40/50\nB. No. The response doesn't correctly identify any place in the tweet that is\nmisinformed or potentially misleading.\nC. Somewhere between A and B.\nIf your answer to Q2 was either A or C, please answer Q2.1 and Q2.2 below.\nQ2.1) What's the comprehensiveness of the response in correctly identifying\nwhere the tweet is misinformed or potentially misleading? Your answer should be\none of the following options:\nA. The response is of extremely high comprehensiveness, meaning it\ncorrectly identi\u0000es every place in the tweet that is misinformed or\npotentially misleading.\nB. The response is of high comprehensiveness, meaning it correctly\nidenti\u0000es most places in the tweet that is misinformed or potentially\nmisleading.\nC. The response is of medium comprehensiveness, meaning it correctly\nidenti\u0000es half places in the tweet that is misinformed or potentially\nmisleading.\nD. The response is of low comprehensiveness, meaning it correctly identi\u0000es\nfew places in the tweet that is misinformed or potentially misleading.\nE. The response is of no comprehensiveness, meaning it correctly identi\u0000es\nno places in the tweet that is misinformed or potentially misleading.\nQ2.2) For the places in the tweet which the response correctly identi\u0000ed as\nmisinformed or potentially misleading, does the response also correctly explain\nwhy they are misinformed or potentially misleading by showing the facts refuting\nor providing the context around them (regardless of the language style)? Your\nanswer should be one of the following options.\nA. The response is fully correct in explaining why they are misinformed or\npotentially misleading.\nB. The response is mostly correct in explaining why they are misinformed or\npotentially misleading while having minor mistakes.\nC. The response is about half correct and half incorrect in explaining why\nthey are misinformed or potentially misleading.\nD. The response is mostly incorrect in explaining why they are misinformed\nor potentially misleading with signi\u0000cant mistakes.\nE. The response is completely incorrect in explaining why they are\nmisinformed or potentially misleading.\nIf your answer to Q2.2 is among A-D, please answer Q2.2.1.Figure S16. Annotation instructions (page 3/7, continued on the next page).\n41/50\nQ2.2.1) How informative is the response on correctly explaining why the tweet is\nmisinformed or potentially misleading? Your answer should be a score between\n0 and 10, where '0' means the response does not provide context for the correct\nexplanation. '10' means the response offers completely suf\u0000cient context that\nhelps any person understand why the tweet is misinformed or potentially\nmisleading. Note that if two or more responses to the same tweet are similarly\ninformative, they can be scored the same, but we encourage you to try to\nseparate out responses into different scores.\nNote that your answer to the following questions (Q3-Q7) should only be based on\nthe text of the responses.\nQ3) How relevant is the response text to the tweet? Your answer should be a\nscore between 0 and 10 measuring the response's ability to catch the key\nrather than the subsidiary point and opinion expressed in the tweet. '0'\nindicates complete irrelevance, and '10' means the response catches (at least)\nthe most critical point in the tweet. Note that if the tweet consists of both\ntextual and visual information, catching the key point may require to well\nunderstand both text and images in the tweet.\nQ4) What's the overall factuality of the response text? Your answer should be\none of the following options:\nA. The response is completely factual and accurate. It does not cherry-pick\nthe facts and has no claims in it that are unveri\u0000able (e.g., opinions) or\nneed clari\u0000cation or context (regardless of the language style).\nB. The response is mostly factual and accurate, with a handful of claims in it\nthat are unveri\u0000able or need clari\u0000cation or context. Overall, however,\nthe response is barely misleading.\nC. The response is formed by about half factual and accurate claims but half\nfalse, inaccurate, or unveri\u0000able claims. It becomes misleading by leaving\nout important details or takes things out of context.\nD. The response is mostly false, inaccurate, or unveri\u0000able. It contains an\nelement of truth. However, it is de\u0000nitely misleading by ignoring critical\nfacts that would give a different impression.\nE. The response is completely false, inaccurate, or unveri\u0000able.\nF. Not applicable; the response does not have text.\nQ5) Does the response text have mistakes in the use of English? Such mistakes\ninclude but are not limited to capitalization errors, misspelled words, sentence\nfragments, and missing or redundant blank spaces. Note that if a piece of text\ndoes not follow the rules of American English but non-American English orFigure S17. Annotation instructions (page 4/7, continued on the next page).\n42/50\nvice versa, it does NOT count as a mistake. Your answer should be one of the\nfollowing options.\nA. Yes, the response has mistakes in the use of English leading to confusion\nand reducing the readability of the response.\nB. Yes, but the mistakes are minor. In other words, the mistakes barely cause\nconfusion and reduce the readability of the response.\nC. No. The response does not have mistakes in the use of English.\nD. Not applicable; the response does not have text.\nQ6) What is the overall coherence (logical consistency) and logicalness (correct\nand valid reasoning) of the response text? Your answer should be one of the\nfollowing options:\nA. The response builds from sentence to sentence to a coherent and logical\nbody of information about a topic.\nB. The response is partially coherent and logical. It is hard to understand\nthe meaning of a handful of sentences in it, like the causality they present,\nor why they are there. Nevertheless, with some effort, you are able to\nunderstand and \u0000gure it out.\nC. The response is barely coherent and logical. You are not able to\nunderstand the meaning of some sentences or why they are there.\nD. Not applicable; the response is too short to be evaluated or does not have\ntext.\nQ7) Is the response text impolite, provoking, or biased toward who posted the\ntweet, a third individual, or a certain group (e.g., Democrats or Republicans)? Your\nanswer should be one of the following options:\nA. Yes, the response is impolite, provoking, or biased toward individuals or\ngroups.\nB. No, the response is NOT impolite, provoking, or biased toward individuals\nor groups.\nC. Not applicable; the response does not have text.\nNow, let's focus on the links included within responses...\nQ8) Can this link be accessed? To answer this question, you will need to click\neach link to verify whether it points to a valid web page, which can be with or\nwithout a paywall, or an invalid web page (e.g., \"Page not found\"). Your answer\nshould be one of the following options:\nA. Yes, the link can be accessed.\nB. No, the link can NOT be accessed.Figure S18. Annotation instructions (page 5/7, continued on the next page).\n43/50\nIf your answer to Q8 is A, please answer Q8.1-Q8.2.\nQ8.1) What's the credibility of this link? Your answer should be one of the\nfollowing options:\nA. Very high credibility. The link's content appears to be backed up by facts\nwith minimal bias, e.g., in politics and language. The source always\npublishes high-quality information with minimal bias.\nB. High credibility. The link's content appears to be backed up by facts,\nthough it can be slightly biased, e.g., in politics and language. The source\nleans towards a certain group (e.g., a political party), but overall it\npublishes information backed up by facts.\nC. Medium credibility. The link's content appears to be backed up by facts,\nthough it can be biased, e.g., in politics and language. However, the source\nhas a mix of high- and low-quality information, or the source has a clear\nbias toward a certain group (e.g., a political party), often publishing\ninformation favoring it and information negative to the other group.\nD. Low credibility (informed in the response). The link's content and its\nsource are both questionable. However, the response informs readers of\nits low credibility; typical examples of such expressions can be \"[LINK] in\nthe tweet is false\u2026\u201d and \u201cThe image attached in the tweet originates from\na satire website ([LINK])...\"\nE. Low credibility (not informed in the response). The link's content and its\nsource are both questionable. Meanwhile, the response doesn't inform\nreaders of its low credibility.\nF. Can't determine; the link's content is behind a paywall or uses non-\nEnglish language, or the link cannot be accessed.\nQ8.2) Is this link relevant to the response text (note: not the tweet)? Note that if\nthe link is provided after some sentences of the response text rather than at\nthe end of the response, evaluating the relevance should be conducted\nbetween the content that the link points to and these sentences rather than\nthe whole response text. Your answer should be one of the following options:\nA. Yes, the link's content is relevant to or supports the response text.\nB. No, the link's content is barely relevant to the response text.\nC. Can't determine; the link's content is behind a paywall or uses non-English\nlanguage, or the link cannot be accessed, or the response does not have\ntext.\nFinally, you will need to answer one last question (Q9) based on the text and links\nin the responses as well as your answers to the previous questions.Figure S19. Annotation instructions (page 6/7, continued on the next page).\n44/50\nQ9) How high-quality is the response in general? Your answer should be a score\nbetween 0 and 10, where '0' refers to extremely low quality, and '10' refers to\nextremely high quality. If two or more responses to the same tweet are of\nsimilar quality, they can be scored the same, but we encourage you to try to\nseparate out responses into different scores.\nContinueFigure S20. Annotation instructions (page 7/7).\n45/50\nFigure S21. Annotation task page.\n46/50\n6 7 8 9 10Quality of responses\nMUSEMUSE (high)MUSE (avg)Figure S22. Impact of starting times of responding to tweets on MUSE\u2019s performance. The simulated starting time\nfor M USE (avg): Thirty minutes before the corresponding laypeople\u2019s average-helpfulness responses was created\n(median: 16 hours after the corresponding tweet was posted; Supplementary Fig. S13). The simulated starting time\nfor M USE (high): Thirty minutes before the corresponding laypeople\u2019s high-helpfulness responses was created\n(median: 13 hours after the corresponding tweet was posted; Supplementary Fig. S13). The simulated starting time\nfor M USE: The post time of the corresponding tweet (i.e., 0 hours after the corresponding tweet was posted).\n47/50\n2 4 6 8 10Quality of responses\nAfter Sept 2021All\nLaypeople (avg) Laypeople (high) GPT-4 MUSEFigure S23. Impact of post times of tweets on the performance of M USE and baselines.\n48/50\n0 2 4 6 810Quality of responses\nMUSEMUSE\\visionMUSE\\retrieval(a)Overall quality of responses.\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n81%61%73%\n876\n113221Explicitness of identifications and explanations\nHigh Medium Low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n86%62%71%\n1112\n92617Accurate identifications\nExist w/o errors Exist w/ errors Do not exist\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n47%30%32%\n272125\n111615\n68\n102819Comprehensiveness of accurate identifications\nVery high High Medium Low Very low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n64%42%46%\n181619\n71113\n102918Accuracy of explanations\nFully Mostly Half Mostly not Fully not\n0 2 4 6 8 10Informativeness of accurate explanations\nMUSEMUSE\\visionMUSE\\retrieval\n(b)Quality of responses in identifying and explaining (in)accuracies.\n0 2 4 6 8 10Relevance of text\nMUSEMUSE\\visionMUSE\\retrieval\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n64%46%45%\n192219\n141819\n910Factuality of text\nVery high High Medium Low Very low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n97%97%97%Fluency of text\nHigh Medium Low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n88%82%84%\n111511Coherence of text\nHigh Medium Low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n97%99%97%Toxicity of text\nDoes not exist Exists\n(c)Quality of responses in generated text.\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n99%100%49% 51Reachability of references\nYes No\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n96%95%81% 19Relevance of reachable references\nHigh Low\n0% 25 50 75 100\nMUSEMUSE\\visionMUSE\\retrieval\n29%27%34%\n585637\n131519Credibility of reachable references\nVery high High Medium Low\n(d)Quality of responses in references.\nFigure S24. Impact of retrieval and vision on MUSE\u2019s performance. Here, MUSE andMUSE\\vision responded to\ntweets by only retrieving web pages published thirty minutes before the creation time of the corresponding\nlaypeople\u2019s high-helpfulness response.\n49/50\n0.0 0.3 0.6 0.9\nSpearman's \nRelevance of referencesCredibility of referencesReachability of referencesToxicity of textCoherence of textFluency of textFactuality of textRelevance of textInformativeness of accurate explanationsAccuracy of explanationsComprehensiveness of accurate identificationsAccurate identificationsExplicitness of identifications & explanations(a)Correlation for all responses.\n(b)Correlation for responses whose overall quality is relatively low vs high.\nFigure S25. Spearman correlation coefficient between overall response quality and each criterion that specifies\noverall response quality.\n50/50", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Correcting misinformation on social media with a large language model", "author": ["X Zhou", "A Sharma", "AX Zhang", "T Althoff"], "pub_year": "2024", "venue": "arXiv preprint arXiv:2403.11169", "abstract": "Real-world misinformation, often multimodal, can be partially or fully factual but misleading  using diverse tactics like conflating correlation with causation. Such misinformation is"}, "filled": false, "gsrank": 49, "pub_url": "https://arxiv.org/abs/2403.11169", "author_id": ["9U_Ge4MAAAAJ", "AHUNnG0AAAAJ", "thZJZaYAAAAJ", "yc4nBNgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:3haRJ_HBuRAJ:scholar.google.com/&output=cite&scirp=48&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=3haRJ_HBuRAJ&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 22, "citedby_url": "/scholar?cites=1205207616793417438&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:3haRJ_HBuRAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2403.11169"}}, {"title": "Fighting the COVID-19 infodemic: Modeling the perspective of journalists, fact-checkers, social media platforms, policy makers, and the society", "year": "2020", "pdf_data": "Fighting the COVID-19 Infodemic:\nModeling the Perspective of Journalists, Fact-Checkers,\nSocial Media Platforms, Policy Makers, and the Society\nFiroj Alam,1Shaden Shaar,1Fahim Dalvi,1Hassan Sajjad,1Alex Nikolov,2\nHamdy Mubarak,1Giovanni Da San Martino,3Ahmed Abdelali,1Nadir Durrani,1\nKareem Darwish,1Abdulaziz Al-Homaid,1Wajdi Zaghouani,4Tommaso Caselli,5\nGijs Danoe,5Friso Stolk,5Britt Bruntink5and Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Qatar,2So\ufb01a University, So\ufb01a, Bulgaria\n3University of Padova, Italy,4Hamad Bin Khalifa University, Qatar\n5University of Groningen, The Netherlands\n{\ufb01alam, faimaduddin, hsajjad, hmubarak, aabdelali, ndurrani}@hbku.edu.qa,\n{abalhomaid, kdarwish, pnakov}@hbku.edu.qa,\nalexnickolow@gmail.com, dasan@math.unipd.it, wzaghouani@hbku.edu.qa\nt.caselli@rug.nl, {g.danoe, b.m.bruntink, f.r.p.stolk}@student.rug.nl\nAbstract\nWith the emergence of the COVID-19 pan-\ndemic, the political and the medical aspects\nof disinformation merged as the problem got\nelevated to a whole new level to become the\n\ufb01rst global infodemic . Fighting this infodemic\nhas been declared one of the most impor-\ntant focus areas of the World Health Orga-\nnization, with dangers ranging from promot-\ning fake cures, rumors, and conspiracy theo-\nries to spreading xenophobia and panic. Ad-\ndressing the issue requires solving a number\nof challenging problems such as identifying\nmessages containing claims, determining their\ncheck-worthiness and factuality, and their po-\ntential to do harm as well as the nature of that\nharm, to mention just a few. To address this\ngap, we release a large dataset of 16K man-\nually annotated tweets for \ufb01ne-grained disin-\nformation analysis that ( i) focuses on COVID-\n19, ( ii) combines the perspectives and the in-\nterests of journalists, fact-checkers, social me-\ndia platforms, policy makers, and society, and\n(iii) covers Arabic, Bulgarian, Dutch, and En-\nglish. Finally, we show strong evaluation re-\nsults using pretrained Transformers, thus con-\n\ufb01rming the practical utility of the dataset in\nmonolingual vs.multilingual, and single task\nvs.multitask settings.\n1 Introduction\nThe rise of social media has made them one of\nthe main channels for information dissemination\nand consumption. As a result, nowadays, many\npeople rely on social media as their primary source\nof news (Perrin, 2015), attracted by the broader\nchoice of information sources and by the ease for\nanybody to become a news producer.Unfortunately, the democratic nature of social\nmedia has raised questions about the quality and the\nfactuality of the information that is shared on these\nplatforms. Eventually, social media have become\none of the main channels to spread disinformation.\nFigure 1 demonstrates how online users discuss\ntopics related to COVID-19 in social media. We\ncan see that the problem goes beyond factuality:\nthere are tweets spreading rumors (Figure 1a), in-\nstilling panic (Figure 1b), making jokes (Figure 1c),\npromoting fake cures (Figure 1d), spreading xeno-\nphobia, racism, and prejudices (Figure 1e), or pro-\nmoting conspiracy theories (Figure 1h).\nOther examples in Figure 1 contain information\nthat could be potentially useful and might deserve\nthe attention of government entities. For example,\nthe tweet in Figure 1f blames the authorities for\ntheir inaction regarding COVID-19 testing. The\ntweet in Figure 1g is useful both for policy makers\nand for the general public as it discusses action\ntaken and suggest actions that probably should be\ntaken elsewhere to \ufb01ght the pandemic.\nFor the tweets in Figure 1, it is necessary to un-\nderstand whether the information is correct, harm-\nful, calling for action to be taken by relevant author-\nities, etc. Rapidly sorting these questions is crucial\nto help organizations channel their efforts, and to\ncounter the spread of disinformation, which may\ncause panic, mistrust, and other problems.\nAddressing these issues requires signi\ufb01cant ef-\nfort in terms of ( i) de\ufb01ning comprehensive annota-\ntion guidelines, ( ii) collecting tweets about COVID-\n19 and sampling from them, ( iii) annotating the\ntweets, and ( iv) training and evaluating models.\nGiven the interconnected nature of these issues, it\nis more ef\ufb01cient to address them simultaneously.arXiv:2005.00033v5  [cs.CL]  22 Sep 2021\nFigure 1: Examples of tweets that would be of potential interest to journalists, fact-checkers, social media plat-\nforms, policy makers, government entities, and the society as a whole.\nWith this consideration in mind, we adopt a mul-\ntifaceted approach, which is motivated by engag-\ning with different stakeholders such as journalists\nand policy makers. We focused on three key as-\npects, which are formulated into seven questions:\n(i) Check worthiness and veracity of the tweet (Q1-\n4 and Q5). ( ii) Harmfulness to society (Q6); and\n(iii) Call for action addressing a government / pol-\nicy makers (Q7). Q1\u2013Q5 were motivated by con-\nversations with journalists and professional fact-\ncheckers, while Q6-Q7 were formulated in conver-\nsations with a Ministry of Public Health.\nOur contributions can be summarized as follows:\n\u2022We develop a large manually annotated\ndataset of 16K tweets related to the COVID-\n19 infodemic in four languages (Arabic, Bul-\ngarian, Dutch, and English), using a schema\nthat combines the perspective of journalists,\nfact-checkers, social media platforms, policy-\nmakers, and the society.\n\u2022We demonstrate sizable performance gains\nover popular deep contextualized text repre-\nsentations (such as BERT), when using mul-\ntitask learning, cross-language learning, and\nwhen modeling the social context of the tweet,\nas well as the propagandistic nature of the\nlanguage used.\n\u2022We make our data and code freely available.1\n1https://github.com/firojalam/\nCOVID-19-disinformation2 Related Work\nFact-Checking Research on fact-checking\nclaims is largely based on datasets mined from\nmajor fact-checking organizations. Some of the\nlarger datasets include the Liar, Liar dataset of\n12.8K claims from PolitiFact (Wang, 2017), the\nClaimsKG dataset and system (Tchechmedjiev\net al., 2019) of 28K claims from eight fact-\nchecking organizations, the MultiFC dataset of\n38K claims from 26 fact-checking organizations\n(Augenstein et al., 2019), and the 10K claims Truth\nof Various Shades dataset (Rashkin et al., 2017).\nThere have been also datasets for other languages,\ncreated in a similar fashion, e.g., for Arabic (Baly\net al., 2018; Alhindi et al., 2021).\nA number of datasets were created as part of\nshared tasks. In most cases, they performed their\nown annotation, either (a) manually, e.g., the Se-\nmEval tasks on determining the veracity of ru-\nmors (Derczynski et al., 2017; Gorrell et al., 2019),\npropaganda detection in news articles and memes\n(Da San Martino et al., 2020a; Dimitrov et al.,\n2021a,b), fact-checking in community question an-\nswering forums (Mihaylova et al., 2019), the CLEF\nCheckThat! lab on identi\ufb01cation and veri\ufb01cation\nof claims (Nakov et al., 2018; Elsayed et al., 2019;\nBarr\u00f3n-Cede\u00f1o et al., 2020; Shaar et al., 2020;\nNakov et al., 2021c; Shaar et al., 2021b,c), or (b) us-\ning crowdsourcing, e.g., the FEVER task on fact ex-\ntraction and veri\ufb01cation, focusing on claims about\nWikipedia content (Thorne et al., 2018, 2019).\nUnlike our work, the above datasets did not focus\non tweets (they used claims from news, speeches,\npolitical debates, community question answering\nfora, or were just made up by human annotators;\nRumourEval is a notable exception), targeted fac-\ntuality only (we cover a number of other issues),\nwere limited to a single language (typically English;\nexcept for CLEF), and did not focus on COVID-19.\nCheck-Worthiness Estimation Another rele-\nvant research line is on detecting check-worthy\nclaims in political debates using manual annota-\ntions (Hassan et al., 2015) or by observing the se-\nlection of fact-checkers (Gencheva et al., 2017;\nPatwari et al., 2017; Jaradat et al., 2018; Vasileva\net al., 2019).\nCOVID-19 Research There are a number of\nCOVID-19 Twitter datasets: some unlabeled (Chen\net al., 2020; Banda et al., 2021; Haouari et al.,\n2021), some automatically labeled with location\ninformation (Abdul-Mageed et al., 2021; Qazi\net al., 2020), some labeled using distant supervi-\nsion (Cinelli et al., 2020; Zhou et al., 2020), and\nsome manually annotated (Song et al., 2020; Vid-\ngen et al., 2020; Shahi and Nandini, 2020; Pulido\net al., 2020; Dharawat et al., 2020).\nThere is also work on credibility (Cinelli et al.,\n2020; Pulido et al., 2020; Zhou et al., 2020), racial\nprejudices and fear (Medford et al., 2020; Vidgen\net al., 2020), as well as situational information,\ne.g., caution and advice (Li et al., 2020), as well as\non detecting mentions and stance with respect to\nknown misconceptions (Hossain et al., 2020).\nThe closest work to ours is that of Song et al.\n(2020), who collected false and misleading claims\nabout COVID-19 from IFCN Poynter, and anno-\ntated them as (1) Public authority, (2) Commu-\nnity spread and impact, (3) Medical advice, self-\ntreatments, and virus effects, (4) Prominent actors,\n(5) Conspiracies, (6) Virus transmission, (7) Virus\norigins and properties, (8) Public reaction, and\n(9) Vaccines, medical treatments, and tests. These\ncategories partially overlap with ours, but account\nfor less perspectives. Moreover, we cover both true\nand false claims, we focus on tweets (while they\nhave general claims), and we cover four languages.\nLast but not least, we have described the general\nannotation schema in previous work (Alam et al.,\n2021a). Unlike that work, here we focus on the\ndataset , which is much larger and covers four lan-\nguages, and we present a rich set of experiments.3 Dataset\n3.1 Data Collection\nWe collected tweets by specifying a target language\n(English, Arabic, Bulgarian, or Dutch), a set of\nCOVID-19 related keywords, as shown in Figure 2,\nand different time frames: from January 2020 till\nMarch 2021. We collected original tweets (no\nretweets or replies), we removed duplicates using\na similarity-based approach (Alam et al., 2021b),\nand we \ufb01ltered out tweets with less than \ufb01ve words.\nFinally, we selected the most frequently liked and\nretweeted tweets for annotation.\nFigure 2: The keywords used to collect the tweets.\n3.2 Annotation Task\nThe annotation task consists of determining\nwhether a tweet contains a factual claim, as well as\nits veracity, its potential to cause harm (to the soci-\nety, to a person, to an organization, or to a product),\nwhether it needs veri\ufb01cation, and how interesting\nit is for policy makers. These are then formulated\ninto seven questions presented in Table 1.\nThe full annotation instructions we gave to the\nannotators, together with examples, can be found\nin Appendix D. To facilitate the annotation task,\nwe used the annotation platform described in Alam\net al. (2021a). There were 10, 14, 5, and 4 anno-\ntators for English, Arabic, Bulgarian, and Dutch,\nrespectively. We used three annotators per tweet,\nnative speakers or \ufb02uent in the respective language,\nmale and female, with quali\ufb01cations ranging from\nundergrads to PhDs in various disciplines. We re-\nsolved the cases of disagreement in a consolidation\ndiscussion including external consolidators.\nTable 3 shows two tweets, annotated for all ques-\ntions. The \ufb01rst tweet contains a harmful factual\nclaim with a causal argument of interest to the pub-\nlic and requiring urgent fact-checking. Moreover,\nit appears to spread rumors. It also attacks govern-\nment of\ufb01cials, and thus might need the attention of\ngovernment entities. The second tweet contains a\nnon-harmful factual claim of interest to the general\npublic, which is probably true, but should be fact-\nchecked urgently. It might be of interest to policy\nmakers as it discusses protection from COVID-19.\n3.3 Labels\nThe annotation was designed in a way that the \ufb01ne-\ngrained multiclass labels can be easily transformed\ninto binary labels by mapping all Yes* intoYes, and\nallNo* intoNo, and dropping the not sure tweets.\nAlthough some of the questions are correlated\n(for Q1-Q5, this is on purpose), the annotation\ninstructions are designed, so that the dataset can be\nused independently for different tasks. Questions\nQ2-Q4 (see Table 1) can be seen as categorical or\nnumerical (i.e., on a Likert scale), and thus can\nbe addressed in a classi\ufb01cation or in an ordinal\nregression setup. Below, we will use classi\ufb01cation.\n3.4 Statistics\nWe annotated a total of 4,542, 4,966, 3,697, and\n2,665 tweets for English, Arabic, Bulgarian, and\nDutch, respectively. Table 1 shows the distribution\nof the class labels for all languages.\nThe distribution for Q1 is quite balanced: 64%\nYesvs. 36% No. Only tweets that contain factual\nclaims were annotated for Q2\u2013Q5.\nFor question Q2, 81% of the tweets were judged\nto contain no false information, for 6% the judges\nwere unsure, and 13% were suspected to possibly\ncontains false information. Note that this is not\nfact-checking, but just a subjective judgment about\nwhether the claim seems credible.Exp. Class labels En Ar Bg Nl\nQ1: Does the tweet contain\na veri\ufb01able factual claim?4,542 4,966 3,697 2,665\nBinNo 1,651 1,527 1,130 1,412\nYes 2,891 3,439 2,567 1,253\nQ2: To what extent does the tweet\nappear to contain false information?2,891 3,439 2,567 1,253\nMultiNo, de\ufb01nitely contains no false info 222 137 102 190\nNo, probably contains no false info 2,272 2,465 2,166 718\nnot sure 213 22 219 113\nYes, probably contains false info 142 764 5 162\nYes, de\ufb01nitely contains false info 42 51 75 70\nBinNo 2,494 2,602 2,268 908\nYes 184 815 80 232\nQ3: Will the tweet\u2019s claim have\nan impact on or be of interest to\nthe general public?2,891 3,439 2,567 1,253\nMultiNo, de\ufb01nitely not of interest 11 9 2 108\nNo, probably not of interest 94 120 68 181\nnot sure 8 14 0 21\nYes, probably of interest 2,481 2,047 2,000 645\nYes, de\ufb01nitely of interest 297 1249 497 298\nBinNo 105 129 70 289\nYes 2,778 3,296 2,497 943\nQ4: To what extent does the tweet\nappear to be harmful to the society,\na person(s), a company(s)\nor a product(s)?2,891 3,439 2,567 1,253\nMultiNo, de\ufb01nitely not harmful 1,107 1,591 437 520\nNo, probably not harmful 1,126 1,088 1,876 449\nnot sure 21 22 17 23\nYes, probably harmful 505 433 196 204\nYes, de\ufb01nitely harmful 132 305 41 57\nBinNo 2,233 2,233 2,313 969\nYes 637 637 237 261\nQ5: Do you think that a professional\nfact-checker should verify\nthe claim in the tweet?2,891 3,439 2,567 1,247\nMultiNo, no need to check 472 163 721 410\nNo, too trivial to check 1,799 1,948 1,326 330\nYes, not urgent 513 1086 422 309\nYes, very urgent 107 242 98 198\nBinNo 2,271 2,111 2,047 740\nYes 620 1,328 520 507\nTable 1: Statistics about Q1\u2013Q5. In rows with a ques-\ntion, the number refers to the total number of tweets for\nthe respective language. Bin: binary, Multi: multiclass.\nFor Q3, which asks whether the tweet is of poten-\ntial interest to the general public, the distribution\nis quite skewed towards Yes: 94% of the examples.\nThis can be attributed to the fact that we selected\nthe tweets based on frequency of retweets and likes,\nand these would be the interesting tweets.\nFor Q4, which asks whether the tweet is harmful\nto the society, we can see that the labels vary widely\nfrom not harmful to harmful; yet, most are not\nharmful.\nExp. Class labels En Ar Bg Nl\nQ6: Is the tweet harmful to the\nsociety and why?4,542 4,966 3,697 2,665\nMultiNo, joke or sarcasm 95 155 200 162\nNo, not harmful 4,040 3,872 3,017 2,254\nnot sure 2 12 4 9\nYes, bad cure 4 6 7 10\nYes, other 33 23 4 7\nYes, panic 90 347 305 35\nYes, rumor conspiracy 246 425 151 159\nYes, xenophobic racist\nprejudices or hate speech32 126 9 29\nBinNo 4,135 4,027 3,217 2,416\nYes 405 927 476 240\nQ7: Do you think that this tweet\nshould get the attention of\na government entity?4,542 4,966 3,697 2,665\nMultiNo, not interesting 3,892 1,598 3,186 2,092\nnot sure 6 12 0 4\nYes, asks question 7 129 1 116\nYes, blame authorities 181 93 51 177\nYes, calls for action 63 61 8 43\nYes, classi\ufb01ed as in question 6 249 725 333 136\nYes, contains advice 18 102 10 50\nYes, discusses action taken 35 695 25 32\nYes, discusses cure 60 1,536 79 8\nYes, other 31 15 4 7\nBinNo 3,892 1,598 3,186 2092\nYes 644 3,356 511 569\nTable 2: Statistics about Q6\u2013Q7.\nFor Q5, which asks whether a professional fact-\nchecker should verify the claim, the majority of the\ncases were either Yes, not urgent (23%) or No, no\nneed to check (17%). It appears that a professional\nfact-checker should verify the claim urgently in a\nrelatively small number of cases (6%).\nFor questions Q2-4, the not sure cases are very\nrare. However, they are substantially more preva-\nlent for Q2 (6%), which is hard to annotate, as in\nmany cases, it requires access to external informa-\ntion. When annotating Q2 (as well as Q3\u2013Q7, but\nnot Q1), the annotators were presented the tweet\nas it appears in Twitter, which allows them to see\nsome context, e.g., the user identi\ufb01er, a snapshot of\nlinked webpage, a video, an image, etc.\nFor Q6, most of the tweets were considered not\nharmful for the society or a joke. However, 1%\nof the tweets were found to be xenophobic, racist,\nprejudices or hate speech , 6% to be rumor conspir-\nacy, and 5% to be spreading panic .\nFor Q7, the vast majority of the tweets were\nnot interesting for policy makers and government\nentities. However, 3% blamed the authorities.Tweet 1: This is unbelievable. It reportedly took\nMacron\u2019s threat to close the UK border for Boris\nJohnson to \ufb01nally shutdown bars and restaurants.\nThe Elysee refers to UK policy as \u2018benign neglect\u2019.\nThis failure of leadership is costing lives.\nQ1: Yes\nQ2: No, probably contains no false info\nQ3: Yes, probably of interest\nQ4: Yes, de\ufb01nitely harmful\nQ5: Yes, very urgent\nQ6: Yes, rumor, or conspiracy\nQ7: Yes, blames authorities\nTweet 2: An antiviral spray against novel #coron-\navirus has developed in Shanghai Public Health Clin-\nical Center, which can be put into throat as shield\nfrom virus. The spray can greatly help protect front-\nline medical staff, yet mass-production for public use\nis not available for now. https://t.co/bmRzCssCY5\nQ1: Yes\nQ2: not sure\nQ3: Yes, de\ufb01nitely of interest\nQ4: No, de\ufb01nitely not harmful\nQ5: Yes, very urgent\nQ6: No, not harmful\nQ7: Yes, discusses cure\nTable 3: Examples of annotated English tweets.\n3.5 Inter-Annotation Agreement\nWe assessed the quality of the annotations by com-\nputing inter-annotator agreement. As mentioned\nearlier, three annotators independently annotated\neach tweet, following the provided annotation in-\nstructions, and the cases of disagreement were\nresolved in a consolidation discussion including\nexternal consolidators. We computed the Fleiss\nKappa (\u0014) between each annotator and the consoli-\ndated label, using (a) the original multiclass labels,\nand (b) binary labels. The results for the English\ndataset are shown in Table 4, where we can see\nthat overall, there is moderate to substantial agree-\nment.2The Kappa value is higher for objective\nquestions such as Q1, and it is lower for subjective\nand partially subjective questions;3the number of\nlabels is also a factor. The agreement for the other\nlanguages is also moderate to substantial for all\nquestions and also both for binary and for multi-\nclass labels; see Appendix E for more detail.\n2Recall that values of Kappa of 0.21\u20130.40, 0.41\u20130.60, 0.61\u2013\n0.80, and 0.81\u20131.0 correspond to fair, moderate, substantial\nand perfect agreement, respectively (Landis and Koch, 1977).\n3Our agreement is much higher than for related tasks (Roi-\ntero et al., 2020): Krippendorff\u2019s \u000bin [0.066; 0.131].\nAgree. Pair Q1 Q2 Q3 Q4 Q5 Q6 Q7\nMulticlass\nA1 - C 0.81 0.73 0.59 0.74 0.79 0.67 0.73\nA2 - C 0.67 0.53 0.44 0.45 0.39 0.65 0.47\nA3 - C 0.78 0.58 0.63 0.61 0.70 0.17 0.42\nAvg 0.75 0.61 0.55 0.60 0.63 0.50 0.54\nBinary\nA1 - C 0.81 0.73 0.77 0.85 0.84 0.77 0.92\nA2 - C 0.67 0.58 0.53 0.43 0.52 0.33 0.57\nA3 - C 0.78 0.70 0.63 0.70 0.74 0.11 0.57\nAvg 0.75 0.67 0.64 0.66 0.70 0.40 0.69\nTable 4: Inter-annotator agreement using Fleiss Kappa\n(\u0014) for the English dataset. Arefers to annotator, and C\nrefers to consolidation.\n4 Experimental Setup\nWe experimented with binary and multiclass set-\ntings for all languages, using deep contextual-\nized text representations based on large-scale pre-\ntrained transformer models such as BERT, mBERT,\nRoBERTa, XLM-R, etc. We further performed mul-\ntitask and cross-language learning, and we modeled\nthe social context of the tweet, as well as the pro-\npagandistic nature of the language used.\n4.1 Data Preprocessing\nThe preprocessing includes removal of hash-\nsymbols and non-alphanumeric symbols, case fold-\ning, URL replacement with a URL tag, and user-\nname replacement with a user tag. We generated\na strati\ufb01ed split (Sechidis et al., 2011) of the data\ninto 70%/10%/20% for training/development/test-\ning. We used the development set to tune the model\nhyper-parameters.\nModels Large-scale pretrained Transformer mod-\nels have achieved state-of-the-art performance for\nseveral NLP tasks. We experimented with several\nsuch models to evaluate their ef\ufb01cacy under various\ntraining scenarios such as, binary vs. multiclass\nclassi\ufb01cation, multilingual setup, etc.\nWe used BERT (Devlin et al., 2019) and\nRoBERTa for English, AraBERT (Antoun et al.,\n2020) for Arabic, and BERTje (de Vries et al.,\n2019) for Dutch. We further used multilingual\ntransformers such as (Liu et al., 2019), multilin-\ngual BERT (mBERT) and XLM-r (Conneau et al.,\n2020). Finally, we used static embeddings from\nFastText (Joulin et al., 2017).For Transformer models, we used the Trans-\nformer toolkit (Wolf et al., 2020). We \ufb01ne-tuned\neach model using the default settings for ten epochs\nas described in (Devlin et al., 2019). Due to insta-\nbility, we performed ten reruns for each experiment\nusing different random seeds, and we picked the\nmodel that performed best on the development set.\nFor FastText, we used embeddings pretrained on\nCommon Crawl, which were released by FastText\nfor different languages.\n4.2 Multitask Learning\nWhile question Q1, Q2, :::, Q7 can be deemed as\nindependent tasks, some questions are interrelated\nand information in one can help improve the pre-\ndictive performance for another task. For example,\nQ5 asks whether the claim in a tweet should be\nchecked by a professional fact-checker. A tweet\nis more likely to be worth fact-checking if its fac-\ntuality is under question (Q2), if it is interesting\nfor the general public (Q3), and, more importantly,\nif it is harmful (Q4). This interdependence be-\ntween the tasks (which was by design) motivated\nmultitask learning with the goal of improving the\nperformance of the classi\ufb01er on Q5 using Q2, Q3,\nand Q4 as auxiliary tasks. We applied multitask\nlearning by aggregating task-speci\ufb01c dense layers\nof transformers. More speci\ufb01cally, for the four\nquestions, we computed the cross-entropy loss for\neach task independently and we then combined\nthem linearly: L=\u00151L1+\u00152L2+\u00153L3+\u00154L4\nwhere the lambdas sum up to 1.\n4.3 Twitter/Propagandistic/Botometer\nFeatures\nPrevious work has demonstrated the utility of mod-\neling the social context for related tasks such as\npredicting factuality (Canini et al., 2011; Baly et al.,\n2020), and thus we extracted context features from\nthe Twitter object. We further modeled the degree\nof propagandistic content in the tweet, and we also\nused bot-related features.\nThe features from the Twitter object include gen-\neral information about the tweet\u2019s content, as well\nas about its author, i.e., whether the account is veri-\n\ufb01ed, whether it uses the default pro\ufb01le picture, the\nnumber of years since the account\u2019s creation, the\nnumber of followers, statuses, and friends, whether\nthe tweet contains quotes, media or a URL, and the\nfactuality of the website it points to.4\n4From http://mediabiasfactcheck.com\nEnglish Arabic Bulgarian Dutch\nQ. Cls. Maj. FT BT RT Maj. FT ArBT XLM-r Maj. FT mBT XLM-r Maj. FT BTje XLM-r\nBinary (Coarse-grained)\nQ1 2 48.7 77.7 76.5 78.6 56.8 63.1 83.8 84.2 58.3 75.5 84.0 87.6 36.5 61.9 75.4 80.0\nQ2 2 91.6 89.0 92.1 92.7 68.3 81.7 84.0 83.1 95.0 85.2 94.7 95.0 64.9 87.9 75.1 83.1\nQ3 2 96.3 69.3 96.4 96.9 96.3 82.0 96.0 96.3 96.5 79.3 96.0 96.5 62.3 69.9 76.9 78.3\nQ4 2 66.7 96.3 85.6 89.0 67.2 96.2 90.3 89.0 86.8 96.5 87.7 88.4 63.9 72.7 77.1 83.9\nQ5 2 67.7 83.8 80.6 84.4 46.8 74.0 65.9 66.7 70.5 81.5 80.5 82.9 44.4 75.3 66.8 70.9\nQ6 2 86.7 92.1 88.9 90.5 72.5 79.3 88.9 89.8 83.2 95.0 84.5 85.1 84.7 74.9 86.9 88.1\nQ7 2 78.3 80.6 85.5 86.1 57.7 81.6 77.4 77.4 80.1 87.2 81.6 81.7 65.6 74.1 78.3 79.6\nAvg. 76.6 84.1 86.5 88.3 66.5 79.7 83.8 83.7 81.5 85.8 87.0 88.2 60.3 73.8 76.6 80.5\nMulticlass (Fine-grained)\nQ2 5 67.9 44.7 69.2 70.6 62.9 53.3 75.6 76.2 77.3 78.8 77.8 79.3 36.5 39.7 45.7 51.1\nQ3 5 78.9 57.4 82.5 82.8 44.4 75.6 53.7 59.5 64.2 78.2 68.1 68.8 32.0 77.7 50.9 53.9\nQ4 5 19.9 69.2 56.0 58.0 28.1 54.2 46.9 50.6 58.8 69.0 65.6 67.1 21.0 42.9 46.3 53.1\nQ5 5 46.8 84.9 62.0 70.0 41.2 52.6 52.6 52.4 36.0 81.5 58.0 61.6 18.4 69.6 40.7 46.4\nQ6 8 84.0 71.7 86.5 87.7 68.7 71.5 82.2 84.8 76.6 79.6 77.2 78.8 74.4 46.0 76.7 76.3\nQ7 10 78.1 82.4 83.4 85.3 13.8 40.8 57.5 61.6 80.1 66.8 81.7 81.8 65.4 45.3 72.2 74.1\nAvg. 62.6 68.4 73.3 75.8 43.2 58.0 61.4 64.2 65.5 75.6 71.4 72.9 41.3 53.5 55.4 59.1\nTable 5: Monolingual experiments. We report weighted F 1for binary (top) and multiclass (bottom) experiments\nfor English, Arabic, Bulgarian, and Dutch using various Transformers and FastText ( FT). The results that improve\nover the majority class baseline ( Maj.) are in bold , and the best system is underlined . Legend: Q. \u2013 question,\nCls \u2013 number of classes. BT: BERT, ArBT : Monolingual BERT in Arabic (AraBERT), RT: RoBERTa. mBT:\nmultilingual BERT, BTje : Monolingual BERT in Dutch (BERTje), XLM-r : XLM-RoBERTa.\nThe propagandistic features include two scores\nmodeling the degree to which the message is pro-\npagandistic: one from the Proppy (Barr\u00f3n-Cede\u00f1o\net al., 2019; Barr\u00f3n-Cede\u00f1o et al., 2019) and one\nfrom the Prta (Da San Martino et al., 2020b) sys-\ntems, as implemented in Tanbih (Zhang et al.,\n2019).\nWe extracted bot-related features using the\nBotometer (Davis et al., 2016). This includes a\nscore about whether the tweet author is likely to\nbe a bot, as well as content-, network- and friend-\nrelated scores. These features are summarized in\nAppendix (Table 9).\n4.4 Baseline\nFor all tasks, we use a majority class baseline. Note\nthat for questions with highly imbalanced class\ndistribution, this baseline could be very high, which\ncan make it hard for models to improve upon (see\nTable 5). For example, in the Arabic dataset for\nQ3 in the binary setting, the tweets from the Yes\ncategory comprise 96% of the total.\n4.5 Evaluation Measures\nWe report weighted F 1score, which takes into ac-\ncount class imbalance. In Appendix C, we further\nreport some other evaluation measures such as ac-\ncuracy and macro-average F 1score.5 Evaluation Results\n5.1 Binary Classi\ufb01cation\nThe evaluation results for binary classi\ufb01cation are\nshown in the \ufb01rst half of Table 5.\nEnglish Most models outperformed the baseline.\nRoBERTa outperformed the other models in \ufb01ve\nof the seven tasks, and FastText was best on the\nremaining two.\nArabic In all the cases except for Q3 (which has\na very skewed distribution as we mentioned above),\nall models performed better than the baseline. The\nstrongest models were FastText and XLM-r, each\nwinning 3 of the seven tasks. AraBERT was best\non one of the tasks.\nBulgarian For Bulgarian, most models outper-\nformed the baselines. We also have a highly im-\nbalanced distribution for Q2 (96.6% \u2018No\u2019) and for\nQ3 (97.3% \u2018Yes\u2019), which made for a very hard to\nbeat baseline. XLM-r was best for four out of seven\ntasks, and FastText was best on the remaining three.\nDutch For Dutch, all models managed to outper-\nform the majority class baseline, except for Fast-\nText on Q6 (due to class imbalance). XLM-r per-\nformed best in \ufb01ve out of the seven tasks, and Fast-\nText was best on the other two.\n5.2 Multiclass Classi\ufb01cation\nThe bottom part of Table 5 shows the multiclass re-\nsults. The Clscolumn shows the number of classes\nper task. We can see that this number ranges in\n[5,10], and thus the multiclass setup is a much\nharder compared to binary classi\ufb01cation. This ex-\nplains the much lower results compared to the bi-\nnary case (including for the baseline).\nEnglish Most models outperformed the baseline.\nThe most successful model was RoBERTa, which\nwas best for four out of the six tasks; FastText was\nbest on the remaining two tasks.\nArabic Almost all models outperformed the ma-\njority class baseline for all tasks (except for Fast-\nText on Q2). FastText was best for three of the six\ntasks, XLM-r was best on two, and AraBERT was\nbest on the remaining one.\nBulgarian All models outperformed the base-\nlines for all tasks. FastText was best for four tasks,\nand XLM-r was best for the remaining two.\nDutch Most models outperformed the majority\nclass baseline. XLM-r was best for three of the six\ntasks, FastText was best on two, and BERTje won\nthe remaining one.\n5.3 Discussion\nOverall, the experimental results above have shown\nthat there is no single model that performs uni-\nversally best across all languages, all tasks, and\nall class sizes. We should note, however, the\nstrong performance of RoBERTa for English, and\nof XLM-r for the remaining languages.\nInterestingly, language-speci\ufb01c models, such as\nAraBERT for Arabic and BERTje for Dutch, were\nnot as strong as multilingual ones such as XLM-r.\nThis could be partially explained by the fact that\nfor them we used a base-sized models, while for\nXLM-r we used a large model.\nFinally, we should note the strong performance\nof context-free models such as FastText. We\nbelieve that it is suitable for the noisy text of\ntweets due to its ability to model not only words\nbut also character n-grams. In future work, we\nplan to try transformers speci\ufb01cally trained on\ntweets and/or on COVID-19 related data such\nas BERTweet (Nguyen et al., 2020) and COVID-\nTwitter-BERT (M\u00fcller et al., 2020).6 Advanced Experiments\nNext, we performed some additional, more ad-\nvanced experiments, including multilingual train-\ning, modeling the Twitter context, the use of propa-\ngandistic language, and whether the user is likely to\nbe a bot, as well as multitask learning. We describe\neach of these experiments in more detail below.\n6.1 Multilingual Training\nWe experimented with a multilingual setup, where\nwe combined the data from all languages. We \ufb01ne-\ntuned a multilingual model (mBERT),5separately\nfor each question. The results are shown in Table 6,\nwhere the Mulcolumns shows the multilingual \ufb01ne-\ntuning results, which are to be compared to the\nmonolingual \ufb01ne-tuning results in the previous re-\nspective columns. We can see that the differences\nare small and that the results are mixed. Multlin-\ngual \ufb01ne-tuning helps a bit in about half of the\ncases, but it also hurts a bit in the other half of the\ncases. This is true both in the binary and in the\nmulticlass setting.\nEnglish Arabic Bulgarian Dutch\nQ. Cls. EN Mul AR Mul BG Mul NL Mul\nBinary (Coarse-grained)\nQ1 2 76.5 77.5 82.6 81.5 84.0 81.8 76.6 76.6\nQ2 2 92.1 92.6 81.4 78.8 94.7 94.4 73.4 71.3\nQ3 2 96.4 96.4 96.1 96.5 96.0 96.5 78.6 77.2\nQ4 2 85.6 83.9 87.7 87.2 87.7 87.2 75.7 74.7\nQ5 2 80.6 78.6 63.1 66.5 80.5 83.2 64.3 68.7\nQ6 2 88.9 85.6 84.6 85.6 84.5 85.6 87.5 85.6\nQ7 2 85.5 79.9 73.4 79.9 81.6 79.9 77.7 79.9\nAvg. 86.5 84.9 81 82.4 87.5 87.8 76.2 76.2\nMulticlass (Fine-grained)\nQ2 5 69.2 70.2 70.8 72.0 77.8 77.8 46.1 47.6\nQ3 5 82.5 82.9 55.8 55.9 68.1 68.3 49.7 47.1\nQ4 5 56.0 56.3 48.2 43.8 65.6 68.9 47.9 48.5\nQ5 5 62.0 61.2 56.0 54.6 58.0 56.3 40.8 42.4\nQ6 8 86.5 84.8 79.0 78.9 77.2 77.8 78.1 75.6\nQ7 10 83.4 83.4 54.7 53.5 81.7 80.2 69.2 68.3\nAvg. 73.3 73.1 60.7 59.8 71.4 71.5 55.3 54.9\nTable 6: Multilingual experiments using mBERT.\nShown are results for monolingual vs. multilingual\nmodels (weighted F 1).Mul is trained on the combined\nEnglish, Arabic, Bulgarian, and Dutch data.\n5We also tried XLM-r, but it performed worse.\n6.2 Twitter/Propagandistic/Botometer\nWe conducted experiments with Twitter, propa-\nganda, and botness features alongside the poste-\nriors from the BERT classi\ufb01er, which we combined\nusing XGBoost (Chen and Guestrin, 2016). The\nresults are shown in Table 7. We can see that many\nof the combinations yielded improvements, with\nbotness being the most useful, followed by propa-\nganda, and \ufb01nally by the Twitter object features.\nBinary (Coarse-grained)\nQ. Cls BERT B+TF B+Prop B+Bot B+All\nQ1 2 76.5 76.9 77.1 77.8 76.8\nQ2 2 92.1 91.8 92.3 92.3 92.4\nQ3 2 96.4 96.3 96.4 96.4 96.3\nQ4 2 85.6 86.5 86.5 86.7 86.4\nQ5 2 80.6 82.0 81.5 81.9 81.4\nQ6 2 88.9 88.9 89.6 89.4 87.6\nQ7 2 85.5 84.1 85.6 86.2 83.9\nMulticlass (Fine-grained)\nQ2 5 69.2 69.4 70.0 70.3 69.1\nQ3 5 82.5 81.2 82.2 82.2 81.6\nQ4 5 56.0 52.7 55.9 56.8 53.4\nQ5 4 62.0 60.9 63.2 62.8 58.2\nQ6 8 86.5 84.3 86.4 86.6 84.1\nQ7 10 83.4 79.6 83.7 83.9 80.8\nTable 7: Experiments with social features and BERT\n(weighted F 1). Improvements over BERT ( B) are\nshown in bold , while the highest scores for each ques-\ntion are underlined .TF: Tweet features, Prop : propa-\nganda features, Bot: Botometer features.\n6.3 Multitask Learning\nFor the multitask learning experiments, we used\nBERT and RoBERTa on the English dataset, in\na multiclass setting, \ufb01ne-tuned with a multiclass\nobjective on Q2\u2013Q5. The results are shown in\nTable 8. We achieved sizable improvements for Q2,\nQ4, and Q5 over the single-task setup. However,\nperformance degraded for Q3, probably due to the\nskewed label distribution for this question.\nEnglish, multiclass\nBERT(S) BERT(M) RoBERTa(S) RoBERTa(M)\nQ2 69.2 72.9 70.62 73.85\nQ3 82.5 71.6 82.84 67.34\nQ4 56.0 67.9 58.04 66.95\nQ5 62.0 76.8 70.02 75.75\nTable 8: Multitask learning experiments (weighted\nF1).S: Single task, M: Multitask.7 Conclusion and Future Work\nWe presented a large manually annotated dataset\nof COVID-19 tweets, aiming to help in the \ufb01ght\nagainst the COVID-19 infodemic. The dataset com-\nbines the perspectives and the interests of journal-\nists, fact-checkers, social media platforms, policy-\nmakers, and society as a whole. It includes tweets\nin Arabic, Bulgarian, Dutch, and English, and we\nare making it freely available to the research com-\nmunity. We further reported a number of evaluation\nresults for all languages using various transformer\narchitectures. Moreover, we performed advanced\nexperiments, including multilingual training, mod-\neling the Twitter context, the use of propagandistic\nlanguage, and whether the user is likely to be a bot,\nas well as multitask learning.\nIn future work, we plan to explore multimodal-\nity and explainability (Yu et al., 2021). We further\nwant to model the task as a multitask ordinal regres-\nsion (Baly et al., 2019), as Q2\u2013Q5 are de\ufb01ned on\nan ordinal scale. Moreover, we would like to put\nthe data and the system in some practical use; in\nfact, we have already used them to analyze disinfor-\nmation about COVID-19 in Bulgaria (Nakov et al.,\n2021a) and Qatar (Nakov et al., 2021b). Finally,\nthe data will be used in a shared task at the CLEF-\n2022 CheckThat! lab; part of it was used for the\nNLP4IF-2021 shared task (Shaar et al., 2021a).\nAcknowledgments\nWe thank Akter Fatema, Al-Awthan Ahmed, Al-\nDobashi Hussein, El Messelmani Jana, Fayoumi\nSereen, Mohamed Esraa, Ragab Saleh, and Shurafa\nChereen for helping with the Arabic annotations.\nWe also want to thank the Atlantic Club in Bul-\ngaria and DataBee for their support for the Bulgar-\nian annotations.\nThis research is part of the Tanbih mega-project,\ndeveloped at the Qatar Computing Research In-\nstitute, HBKU, which aims to limit the impact of\n\u201cfake news,\u201d propaganda, and media bias by making\nusers aware of what they are reading.\nThis material is also based upon work supported\nby the US National Science Foundation under\nGrants No. 1704113 and No. 1828199.\nThis publication was also partially made possi-\nble by the innovation grant No. 21 \u2013 Misinforma-\ntion and Social Networks Analysis in Qatar from\nHamad Bin Khalifa University\u2019s (HBKU) Innova-\ntion Center. The \ufb01ndings achieved herein are solely\nthe responsibility of the authors.\nEthics Statement\nDataset Collection\nWe collected the dataset using the Twitter API6\nwith keywords that only use terms related to\nCOVID-19, without other biases. We followed\nthe terms of use outlined by Twitter.7Speci\ufb01cally,\nwe only downloaded public tweets, and we only\ndistribute dehydrated Twitter IDs.\nBiases\nWe note that some of the annotations are subjective,\nand we have clearly indicated in the text which\nthese are. Thus, it is inevitable that there would\nbe biases in our dataset. Yet, we have a very clear\nannotation schema and instructions, which should\nreduce biases.\nMisuse Potential\nMost datasets compiled from social media present\nsome risk of misuse. We, therefore, ask researchers\nto be aware that our dataset can be maliciously\nused to unfairly moderate text (e.g., a tweet) that\nmay not be malicious based on biases that may or\nmay not be related to demographics and other in-\nformation within the text. Intervention with human\nmoderation would be required in order to ensure\nthis does not occur.\nIntended Use\nOur dataset can enable automatic systems for analy-\nsis of social media content, which could be of inter-\nest to practitioners, professional fact-checker, jour-\nnalists, social media platforms, and policymakers.\nSuch systems can be used to alleviate the burden\nfor social media moderators, but human supervi-\nsion would be required for more intricate cases and\nin order to ensure that the system does not cause\nharm.\nOur models can help \ufb01ght the infodemic, and\nthey could support analysis and decision making\nfor the public good. However, the models can also\nbe misused by malicious actors. Therefore, we ask\nthe potential users to be aware of potential misuse.\nWith the possible rami\ufb01cations of a highly subjec-\ntive dataset, we distribute it for research purposes\nonly, without a license for commercial use. Any bi-\nases found in the dataset are unintentional, and we\ndo not intend to do harm to any group or individual.\n6http://developer.twitter.com/en/docs\n7http://developer.twitter.com/en/\ndeveloper-terms/agreement-and-policyReferences\nMuhammad Abdul-Mageed, AbdelRahim Elmadany,\nEl Moatez Billah Nagoudi, Dinesh Pabbi, Kunal\nVerma, and Rannie Lin. 2021. Mega-COV: A\nbillion-scale dataset of 100+ languages for COVID-\n19. In Proceedings of the 16th Conference of the\nEuropean Chapter of the Association for Computa-\ntional Linguistics , EACL \u201921, pages 3402\u20133420, On-\nline. Association for Computational Linguistics.\nFiroj Alam, Fahim Dalvi, Shaden Shaar, Nadir Dur-\nrani, Hamdy Mubarak, Alex Nikolov, Giovanni Da\nSan Martino, Ahmed Abdelali, Hassan Sajjad, Ka-\nreem Darwish, and Preslav Nakov. 2021a. Fighting\nthe COVID-19 infodemic in social media: A holistic\nperspective and a call to arms. In Proceedings of the\nInternational AAAI Conference on Web and Social\nMedia , ICWSM \u201921, pages 913\u2013922.\nFiroj Alam, Hassan Sajjad, Muhammad Imran, and\nFerda O\ufb02i. 2021b. CrisisBench: Benchmarking\ncrisis-related social media datasets for humanitarian\ninformation processing. In Proceedings of the Inter-\nnational AAAI Conference on Web and Social Media ,\nICWSM \u201921, pages 923\u2013932.\nGerald Albaum. 1997. The likert scale revisited. Mar-\nket Research Society. Journal. , 39(2):1\u201321.\nTariq Alhindi, Amal Alabdulkarim, Ali Alshehri,\nMuhammad Abdul-Mageed, and Preslav Nakov.\n2021. AraStance: A multi-country and multi-\ndomain dataset of Arabic stance detection for fact\nchecking. In Proceedings of the Fourth Workshop\non NLP for Internet Freedom: Censorship, Disinfor-\nmation, and Propaganda , NLP4IF \u201921, pages 57\u201365,\nOnline. Association for Computational Linguistics.\nGordon W Allport and Leo Postman. 1947. The psy-\nchology of rumor. Henry Holt.\nWissam Antoun, Fady Baly, and Hazem Hajj. 2020.\nAraBERT: Transformer-based model for Arabic lan-\nguage understanding. In Proceedings of the 4th\nWorkshop on Open-Source Arabic Corpora and Pro-\ncessing Tools, with a Shared Task on Offensive Lan-\nguage Detection , OSACT \u201920, pages 9\u201315, Mar-\nseille, France. European Language Resource Asso-\nciation.\nIsabelle Augenstein, Christina Lioma, Dongsheng\nWang, Lucas Chaves Lima, Casper Hansen, Chris-\ntian Hansen, and Jakob Grue Simonsen. 2019.\nMultiFC: A real-world multi-domain dataset for\nevidence-based fact checking of claims. In Pro-\nceedings of the Conference on Empirical Methods in\nNatural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing , EMNLP-IJCNLP \u201919, pages 4685\u20134697,\nHong Kong, China. Association for Computational\nLinguistics.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020. What was written vs. who\nread it: News media pro\ufb01ling using text analysis and\nsocial media context. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics , ACL \u201920, pages 3364\u20133374, Online. As-\nsociation for Computational Linguistics.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames Glass, and Preslav Nakov. 2019. Multi-task\nordinal regression for jointly predicting the trustwor-\nthiness and the leading political ideology of news\nmedia. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 2109\u20132116, Min-\nneapolis, Minnesota, USA. Association for Compu-\ntational Linguistics.\nRamy Baly, Mitra Mohtarami, James Glass, Llu\u00eds\nM\u00e0rquez, Alessandro Moschitti, and Preslav Nakov.\n2018. Integrating stance detection and fact checking\nin a uni\ufb01ed corpus. In Proceedings of the Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201918, pages 21\u2013\n27, New Orleans, Louisiana, USA. Association for\nComputational Linguistics.\nJuan M. Banda, Ramya Tekumalla, Guanyu Wang,\nJingyuan Yu, Tuo Liu, Yuning Ding, Ekaterina\nArtemova, Elena Tutubalina, and Gerardo Chow-\nell. 2021. A large-scale COVID-19 Twitter chatter\ndataset for open scienti\ufb01c research \u2013 an international\ncollaboration. Epidemiologia , 2(3):315\u2013324.\nAlberto Barr\u00f3n-Cede\u00f1o, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the Thirty-Third AAAI Conference on\nArti\ufb01cial Intelligence , AAAI \u201919, pages 9847\u20139848,\nHonolulu, Hawaii, USA. AAAI.\nAlberto Barr\u00f3n-Cede\u00f1o, Tamer Elsayed, Preslav\nNakov, Giovanni Da San Martino, Maram Hasanain,\nReem Suwaileh, and Fatima Haouari. 2020. Check-\nthat! at CLEF 2020: Enabling the automatic identi\ufb01-\ncation and veri\ufb01cation of claims in social media. In\nProceedings of the 42nd European Conference on In-\nformation Retrieval , ECIR \u201919, pages 499\u2013507, Lis-\nbon, Portugal. Springer.\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni Da\nSan Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing and Management ,\n56(5):1849\u20131864.\nDavid A Broniatowski, Amelia M Jamison, SiHua Qi,\nLulwah AlKulaib, Tao Chen, Adrian Benton, San-\ndra C Quinn, and Mark Dredze. 2018. Weaponized\nhealth communication: Twitter bots and Russian\ntrolls amplify the vaccine debate. American journal\nof public health , 108(10):1378\u20131384.\nKevin R Canini, Bongwon Suh, and Peter L Pirolli.\n2011. Finding credible information sources in so-\ncial networks based on content and social structure.InProceedings of the 2011 IEEE Third International\nConference on Privacy, Security, Risk and Trust and\n2011 IEEE Third International Conference on So-\ncial Computing , SocialCom/PASSAT \u201911, pages 1\u2013\n8, Boston, Massachusetts, USA.\nEmily Chen, Kristina Lerman, and Emilio Ferrara.\n2020. Tracking social media discourse about the\nCOVID-19 pandemic: Development of a public\ncoronavirus Twitter data set. JMIR Public Health\nSurveill , 6(2):e19273.\nTianqi Chen and Carlos Guestrin. 2016. XGBoost: A\nscalable tree boosting system. In Proceedings of the\n22nd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining , KDD \u201916,\npages 785\u2013794, San Francisco, California, USA. As-\nsociation for Computing Machinery.\nMatteo Cinelli, Walter Quattrociocchi, Alessandro\nGaleazzi, Carlo Michele Valensise, Emanuele Brug-\nnoli, Ana Lucia Schmidt, Paola Zola, Fabiana Zollo,\nand Antonio Scala. 2020. The COVID-19 social me-\ndia infodemic. Scienti\ufb01c Reports , 10(1):1\u201310.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In\nProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics , ACL \u201920,\npages 8440\u20138451, Online. Association for Compu-\ntational Linguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 task 11: Detection of\npropaganda techniques in news articles. In Proceed-\nings of the Fourteenth Workshop on Semantic Evalu-\nation , SemEval \u201920, pages 1377\u20131414. International\nCommittee for Computational Linguistics.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr\u00f3n-Cede\u00f1o, and Preslav\nNakov. 2020b. Prta: A system to support the anal-\nysis of propaganda techniques in the news. In Pro-\nceedings of the 58th Annual Meeting of the Associa-\ntion for Computational Linguistics: System Demon-\nstrations , pages 287\u2013293, Online. Association for\nComputational Linguistics.\nClayton Allen Davis, Onur Varol, Emilio Ferrara,\nAlessandro Flammini, and Filippo Menczer. 2016.\nBotOrNot: A system to evaluate social bots. In Pro-\nceedings of the 25th International Conference Com-\npanion on World Wide Web , WWW \u201916, pages 273\u2013\n274, Montr\u00e9al, Qu\u00e9bec, Canada. International World\nWide Web Conferences.\nWietse de Vries, Andreas van Cranenburgh, Arianna\nBisazza, Tommaso Caselli, Gertjan van Noord, and\nMalvina Nissim. 2019. BERTje: A Dutch BERT\nmodel. ArXiv:1912.09582 .\nLeon Derczynski, Kalina Bontcheva, Maria Liakata,\nRob Procter, Geraldine Wong Sak Hoi, and Arkaitz\nZubiaga. 2017. SemEval-2017 Task 8: RumourEval:\nDetermining rumour veracity and support for ru-\nmours. In Proceedings of the 11th International\nWorkshop on Semantic Evaluation , SemEval \u201917,\npages 60\u201367, Vancouver, Canada. Association for\nComputational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, Minnesota, USA. Association for Compu-\ntational Linguistics.\nArkin Dharawat, Ismini Lourentzou, Alex Morales,\nand ChengXiang Zhai. 2020. Drink bleach or\ndo what now? Covid-HeRA: A dataset for risk-\ninformed health decision making in the presence of\nCOVID19 misinformation. arXiv:2010.08743 .\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021a. De-\ntecting propaganda techniques in memes. In Pro-\nceedings of the 59th Annual Meeting of the Associa-\ntion for Computational Linguistics and the 11th In-\nternational Joint Conference on Natural Language\nProcessing , ACL-IJCNLP \u201921, pages 6603\u20136617,\nOnline. Association for Computational Linguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021b.\nSemEval-2021 task 6: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the\n15th International Workshop on Semantic Evalua-\ntion, SemEval \u201921, pages 70\u201398, Online. Associa-\ntion for Computational Linguistics.\nTamer Elsayed, Preslav Nakov, Alberto Barr\u00f3n-\nCede\u00f1o, Maram Hasanain, Reem Suwaileh, Gio-\nvanni Da San Martino, and Pepa Atanasova. 2019.\nCheckThat! at CLEF 2019: Automatic identi\ufb01cation\nand veri\ufb01cation of claims. In Advances in Informa-\ntion Retrieval , ECIR \u201919, pages 309\u2013315, Cologne,\nGermany. Springer International Publishing.\nPepa Gencheva, Preslav Nakov, Llu\u00eds M\u00e0rquez, Al-\nberto Barr\u00f3n-Cede\u00f1o, and Ivan Koychev. 2017.\nA context-aware approach for detecting worth-\nchecking claims in political debates. In Proceedings\nof the International Conference Recent Advances in\nNatural Language Processing , RANLP \u201917, pages\n267\u2013276, Varna, Bulgaria. INCOMA Ltd.\nGenevieve Gorrell, Ahmet Aker, Kalina Bontcheva,\nLeon Derczynski, Elena Kochkina, Maria Liakata,\nand Arkaitz Zubiaga. 2019. SemEval-2019 task 7:RumourEval, determining rumour veracity and sup-\nport for rumours. In Proceedings of the 13th In-\nternational Workshop on Semantic Evaluation , Se-\nmEval \u201919, pages 845\u2013854, Minneapolis, Minnesota,\nUSA. Association for Computational Linguistics.\nFatima Haouari, Maram Hasanain, Reem Suwaileh,\nand Tamer Elsayed. 2021. ArCOV-19: The \ufb01rst\nArabic COVID-19 Twitter dataset with propagation\nnetworks. In Proceedings of the Sixth Arabic Nat-\nural Language Processing Workshop , ANLP \u201921,\npages 82\u201391, Kyiv, Ukraine (Virtual). Association\nfor Computational Linguistics.\nNaeemul Hassan, Chengkai Li, and Mark Tremayne.\n2015. Detecting check-worthy factual claims in\npresidential debates. In Proceedings of the 24th\nACM International on Conference on Information\nand Knowledge Management , CIKM \u201915, pages\n1835\u20131838, Melbourne, Australia. Association for\nComputing Machinery.\nTamanna Hossain, Robert L. Logan IV , Arjuna Ugarte,\nYoshitomo Matsubara, Sean Young, and Sameer\nSingh. 2020. COVIDLies: Detecting COVID-19\nmisinformation on social media. In Proceedings of\nthe 1st Workshop on NLP for COVID-19 (Part 2)\nat EMNLP 2020 , Online. Association for Computa-\ntional Linguistics.\nIsraa Jaradat, Pepa Gencheva, Alberto Barr\u00f3n-Cede\u00f1o,\nLlu\u00eds M\u00e0rquez, and Preslav Nakov. 2018. Claim-\nRank: Detecting check-worthy claims in Arabic\nand English. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Asso-\nciation for Computational Linguistics: Demonstra-\ntions , NAACL-HLT \u201918, pages 26\u201330, New Orleans,\nLouisiana, USA. Association for Computational Lin-\nguistics.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for ef\ufb01cient text\nclassi\ufb01cation. In Proceedings of the 15th Confer-\nence of the European Chapter of the Association for\nComputational Linguistics , EACL \u201917, pages 427\u2013\n431, Valencia, Spain. Association for Computational\nLinguistics.\nLev Konstantinovskiy, Oliver Price, Mevan Babakar,\nand Arkaitz Zubiaga. 2021. Toward automated\nfactchecking: Developing an annotation schema and\nbenchmark for consistent automated claim detection.\nDigital Threats: Research and Practice , 2(2).\nJ Richard Landis and Gary G Koch. 1977. The mea-\nsurement of observer agreement for categorical data.\nbiometrics , pages 159\u2013174.\nLifang Li, Qingpeng Zhang, Xiao Wang, Jun Zhang,\nTao Wang, Tian-Lu Gao, Wei Duan, Kelvin Kam-\nfai Tsoi, and Fei-Yue Wang. 2020. Characterizing\nthe propagation of situational information in social\nmedia during COVID-19 epidemic: A case study on\nWeibo. IEEE Transactions on Computational Social\nSystems , 7(2):556\u2013562.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A robustly optimized BERT pretraining\napproach. ArXiv:1907.11692 .\nRichard J Medford, Sameh N Saleh, Andrew Sumar-\nsono, Trish M Perl, and Christoph U Lehmann. 2020.\nAn \u201cInfodemic\u201d: Leveraging High-V olume Twitter\nData to Understand Early Public Sentiment for the\nCoronavirus Disease 2019 Outbreak. Open Forum\nInfectious Diseases , 7(7). Ofaa258.\nTsvetomila Mihaylova, Georgi Karadzhov, Pepa\nAtanasova, Ramy Baly, Mitra Mohtarami, and\nPreslav Nakov. 2019. SemEval-2019 task 8: Fact\nchecking in community question answering forums.\nInProceedings of the 13th International Workshop\non Semantic Evaluation , SemEval \u201919, pages 860\u2013\n869, Minneapolis, Minnesota, USA. Association for\nComputational Linguistics.\nMartin M\u00fcller, Marcel Salath\u00e9, and Per Egil Kummer-\nvold. 2020. COVID-Twitter-BERT: A natural lan-\nguage processing model to analyse COVID-19 con-\ntent on Twitter. arXiv:2005.07503 .\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021a. COVID-\n19 in Bulgarian social media: Factuality, harmful-\nness, propaganda, and framing. In Proceedings of\nthe International Conference on Recent Advances in\nNatural Language Processing , RANLP \u201921, pages\n1001\u20131013, Online. INCOMA Ltd.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021b. A second\npandemic? Analysis of fake news about COVID-\n19 vaccines in Qatar. In Proceedings of the Inter-\nnational Conference on Recent Advances in Natu-\nral Language Processing , RANLP \u201921, pages 1014\u2013\n1025, Online. INCOMA Ltd.\nPreslav Nakov, Alberto Barr\u00f3n-Cede\u00f1o, Tamer El-\nsayed, Reem Suwaileh, Llu\u00eds M\u00e0rquez, Wajdi Za-\nghouani, Pepa Atanasova, Spas Kyuchukov, and\nGiovanni Da San Martino. 2018. Overview of the\nCLEF-2018 CheckThat! lab on automatic identi\ufb01ca-\ntion and veri\ufb01cation of political claims. In CLEF ,\nLecture Notes in Computer Science, pages 372\u2013387,\nAvignon, France. Springer.\nPreslav Nakov, Giovanni Da San Martino, Tamer\nElsayed, Alberto Barr\u00f3n-Cede\u00f1o, Rub\u00e9n M\u00edguez,\nShaden Shaar, Firoj Alam, Fatima Haouari, Maram\nHasanain, Watheq Mansour, Bayan Hamdan,\nZien Sheikh Ali, Nikolay Babulkov, Alex Nikolov,\nGautam Kishore Shahi, Julia Maria Stru\u00df, Thomas\nMandl, Mucahid Kutlu, and Yavuz Selim Kartal.\n2021c. Overview of the CLEF-2021 CheckThat!\nlab on detecting check-worthy claims, previously\nfact-checked claims, and fake news. In Experimen-\ntal IR Meets Multilinguality, Multimodality, and\nInteraction. Proceedings of the Twelfth Interna-\ntional Conference of the CLEF Association , LNCS\n(12880). Springer.Dat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen.\n2020. BERTweet: A pre-trained language model\nfor English tweets. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing: System Demonstrations , EMNLP \u201920,\npages 9\u201314, Online. Association for Computational\nLinguistics.\nAyush Patwari, Dan Goldwasser, and Saurabh Bagchi.\n2017. TATHYA: A multi-classi\ufb01er system for\ndetecting check-worthy statements in political de-\nbates. In Proceedings of the 2017 ACM on Confer-\nence on Information and Knowledge Management ,\nCIKM \u201917, page 2259\u20132262, Singapore. Associa-\ntion for Computing Machinery.\nAndrew Perrin. 2015. Social media usage. Pew re-\nsearch center , pages 52\u201368.\nCristina M Pulido, Beatriz Villarejo-Carballido, Gisela\nRedondo-Sama, and Aitor G\u00f3mez. 2020. COVID-\n19 infodemic: More retweets for science-based in-\nformation on coronavirus than for false information.\nInternational Sociology , 35(4):377\u2013392.\nUmair Qazi, Muhammad Imran, and Ferda O\ufb02i. 2020.\nGeoCoV19: A dataset of hundreds of millions of\nmultilingual COVID-19 tweets with location infor-\nmation. SIGSPATIAL Special , 12(1):6\u201315.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and po-\nlitical fact-checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Lan-\nguage Processing , EMNLP \u201917, pages 2931\u20132937,\nCopenhagen, Denmark. Association for Computa-\ntional Linguistics.\nKevin Roitero, Michael Soprano, Shaoyang Fan, Dami-\nano Spina, Stefano Mizzaro, and Gianluca Demar-\ntini. 2020. Can the crowd identify misinformation\nobjectively? The effects of judgment scale and as-\nsessor\u2019s background. In Proceedings of the 43rd\nInternational ACM SIGIR Conference on Research\nand Development in Information Retrieval , SIGIR\n\u201920, pages 439\u2013448, Virtual Event, China. Associa-\ntion for Computing Machinery.\nKonstantinos Sechidis, Grigorios Tsoumakas, and Ioan-\nnis Vlahavas. 2011. On the strati\ufb01cation of multi-\nlabel data. In Machine Learning and Knowledge\nDiscovery in Databases , ECML-PKDD \u201911, pages\n145\u2013158, Berlin, Heidelberg. Springer Berlin Hei-\ndelberg.\nShaden Shaar, Firoj Alam, Giovanni Da San Martino,\nAlex Nikolov, Wajdi Zaghouani, Preslav Nakov, and\nAnna Feldman. 2021a. Findings of the NLP4IF-\n2021 shared tasks on \ufb01ghting the COVID-19 info-\ndemic and censorship detection. In Proceedings\nof the Fourth Workshop on NLP for Internet Free-\ndom: Censorship, Disinformation, and Propaganda ,\nNLP4IF \u201921\u2019, pages 82\u201392, Online. Association for\nComputational Linguistics.\nShaden Shaar, Fatima Haouari, Watheq Mansour,\nMaram Hasanain, Nikolay Babulkov, Firoj Alam,\nGiovanni Da San Martino, Tamer Elsayed, and\nPreslav Nakov. 2021b. Overview of the CLEF-\n2021 CheckThat! lab task 2 on detecting previously\nfact-checked claims in tweets and political debates.\nInWorking Notes of CLEF 2021\u2014Conference and\nLabs of the Evaluation Forum , CLEF \u201921, Bucharest,\nRomania (online). CEUR-WS.\nShaden Shaar, Maram Hasanain, Bayan Hamdan,\nZien Sheikh Ali, Fatima Haouari, Alex Nikolov,\nMucahid Kutlu, Yavuz Selim Kartal, Firoj Alam,\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nRub\u00e9n M\u00edguez, Javier Beltr\u00e1n, Tamer Elsayed, and\nPreslav Nakov. 2021c. Overview of the CLEF-2021\nCheckThat! lab task 1 on check-worthiness estima-\ntion in tweets and political debates. In Working\nNotes of CLEF 2021\u2014Conference and Labs of the\nEvaluation Forum , CLEF \u20192021, Bucharest, Roma-\nnia (online). CEUR-WS.org.\nShaden Shaar, Alex Nikolov, Nikolay Babulkov, Firoj\nAlam, Alberto Barr\u00f3n-Cede\u00f1o, Tamer Elsayed,\nMaram Hasanain, Reem Suwaileh, Fatima Haouari,\nGiovanni Da San Martino, and Preslav Nakov. 2020.\nOverview of CheckThat! 2020 English: Automatic\nidenti\ufb01cation and veri\ufb01cation of claims in social me-\ndia. In Working Notes of CLEF 2020\u2014Conference\nand Labs of the Evaluation Forum , CEUR Workshop\nProceedings. CEUR-WS.org.\nGautam Kishore Shahi and Durgesh Nandini. 2020.\nFakeCovid \u2013 a multilingual cross-domain fact check\nnews dataset for COVID-19. In Workshop Proceed-\nings of the 14th International AAAI Conference on\nWeb and Social Media , Online.\nXingyi Song, Johann Petrak, Ye Jiang, Iknoor Singh,\nDiana Maynard, and Kalina Bontcheva. 2020. Clas-\nsi\ufb01cation aware neural topic model and its appli-\ncation on a new COVID-19 disinformation corpus.\nArXiv:2006.03354 .\nAndon Tchechmedjiev, Pavlos Fafalios, Katarina\nBoland, Malo Gasquet, Matth\u00e4us Zloch, Benjamin\nZapilko, Stefan Dietze, and Konstantin Todorov.\n2019. ClaimsKG: A knowledge graph of fact-\nchecked claims. In Proceedings of the 18th Interna-\ntional Semantic Web Conference , ISWC \u201919, pages\n309\u2013324, Auckland, New Zealand.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFEVER: a large-scale dataset for fact extraction\nand VERi\ufb01cation. In Proceedings of the 2018\nConference of the North American Chapter of\nthe Association for Computational Linguistics:\nHuman Language Technologies , NAACL-HLT \u201918,\npages 809\u2013819, New Orleans, Louisiana, USA.\nAssociation for Computational Linguistics.\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\nChristos Christodoulopoulos, and Arpit Mittal. 2019.\nThe FEVER2.0 shared task. In Proceedings of theSecond Workshop on Fact Extraction and VERi\ufb01ca-\ntion, FEVER \u201919, pages 1\u20136, Hong Kong, China. As-\nsociation for Computational Linguistics.\nSlavena Vasileva, Pepa Atanasova, Llu\u00eds M\u00e0rquez, Al-\nberto Barr\u00f3n-Cede\u00f1o, and Preslav Nakov. 2019. It\ntakes nine to smell a rat: Neural multi-task learn-\ning for check-worthiness prediction. In Proceedings\nof the International Conference on Recent Advances\nin Natural Language Processing , RANLP\u201919, pages\n1229\u20131239, Varna, Bulgaria. INCOMA Ltd.\nBertie Vidgen, Scott Hale, Ella Guest, Helen Mar-\ngetts, David Broniatowski, Zeerak Waseem, Austin\nBotelho, Matthew Hall, and Rebekah Tromble. 2020.\nDetecting East Asian prejudice on social media.\nInProceedings of the Fourth Workshop on Online\nAbuse and Harms , ALW \u201920, pages 162\u2013172, On-\nline. Association for Computational Linguistics.\nWilliam Yang Wang. 2017. \u201cLiar, liar pants on \ufb01re\u201d:\nA new benchmark dataset for fake news detection.\nInProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics , ACL \u201917,\npages 422\u2013426, Vancouver, Canada. Association for\nComputational Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations , EMNLP \u201920, pages 38\u201345,\nOnline. Association for Computational Linguistics.\nSeunghak Yu, Giovanni Da San Martino, Mitra Mo-\nhtarami, James Glass, and Preslav Nakov. 2021. In-\nterpretable propaganda detection in news articles.\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing ,\nRANLP \u201921, pages 1601\u20131609, Online.\nYifan Zhang, Giovanni Da San Martino, Alberto\nBarr\u00f3n-Cede\u00f1o, Salvatore Romeo, Jisun An, Hae-\nwoon Kwak, Todor Staykovski, Israa Jaradat, Georgi\nKaradzhov, Ramy Baly, Kareem Darwish, James\nGlass, and Preslav Nakov. 2019. Tanbih: Get to\nknow what you are reading. In Proceedings of the\nConference on Empirical Methods in Natural Lan-\nguage Processing and the 9th International Joint\nConference on Natural Language Processing: Sys-\ntem Demonstrations , EMNLP-IJCNLP \u201919, pages\n223\u2013228, Hong Kong, China.\nXinyi Zhou, Apurva Mulay, Emilio Ferrara, and Reza\nZafarani. 2020. ReCOVery: A multimodal reposi-\ntory for COVID-19 news credibility research. In\nProceedings of the 29th ACM International Con-\nference on Information & Knowledge Management ,\nCIKM \u201920, pages 3205\u20133212. Association for Com-\nputing Machinery.\nAppendix\nA Experimental Setup\nA.1 Transformer Parameters\nBelow, we list the values of the hyper-parameters\nthat we used for \ufb01ne-tuning the Transformer mod-\nels we used. We further release all our scripts,\ntogether with the data.\n\u2022 Batch size: 32;\n\u2022 Learning rate (Adam): 2e-5;\n\u2022 Number of epochs: 10;\n\u2022 Max seq length: 128.\nModels and Number of Parameters:\n\u2022BERT (bert-base-uncased): L=12, H=768,\nA=12, total parameters: 110M; where Lis the\nnumber of layers (i.e., Transformer blocks),\nHis the hidden size, and Ais the number of\nself-attention heads;\n\u2022RoBERTa (roberta-base): similar to BERT-\nbase, but with a higher number of parameters\n(125M);\n\u2022AraBERT (bert-base-arabert): same number\nas BERT (110M);\n\u2022BERTje (bert-base-dutch-cased): same num-\nber as BERT (110M);\n\u2022RoBERTa for Bulgarian (roberta-base-\nbulgarian): L=12, H=768, A=12, parame-\nters=125M;\n\u2022BERT Multilingual (bert-base-multilingual-\nuncased) (mBERT): similar to BERT-base\nwith a higher number of parameters (172M);\n\u2022XLM-RoBERTa (xlm-roberta-base): L=12,\nH=768, A=12; the total number of parameters\nis 270M.A.2 FastText Parameters\nWe release all the FastText parameters with our\nreleased packages. We have not listed them here\ndue to the length of the resulting list.\nA.3 XGBoost Parameters\nWe used XGBoost to run experiments with Twitter,\nPropaganda, Botometer, and BERT model predic-\ntions. We release the scripts with our code repos-\nitory, which contains detailed the parameter set-\ntings.\nA.4 Computing Infrastructure and Runtime\nWe used a server with NVIDIA Tesla V100-SXM2-\n32 GB GPU, 56 cores, and 256GB CPU memory.\nTo perform an experiment for a question, on aver-\nage the computing time took 40 minutes using the\nBERT base model. This means about four hours\nfor all seven questions using one Transformer ar-\nchitecture.\nB Twitter/Propagandistic/Botometer\nFeatures Types\nIn the additional experiments in Section 6, we ex-\ntracted features from the Twitter object, botness\nscores from the Botometer API, and propaganda\nscores from the Tanbih API. We have already de-\nscribed the experiments with these features in Sec-\ntion 6, but we did not have enough space in the\nmain text of the paper to describe the features them-\nselves. Table 9 aims to address this. It lists the fea-\ntures, offers a brief description for each one, and\nspeci\ufb01es its type, which can be one of the follow-\ning:\n\u2022Boolean features take a value of either 0 or 1;\nwe use them directly.\n\u2022Categorical features take a \ufb01xed number of\npossible values, and we encode them using\none-hot representation.\n\u2022Numerical features are continuous and may\ntake an in\ufb01nite number of values; we trans-\nform the value xof such a feature according\nto the formula x0=ln(x+ 1) .Tweet-Speci\ufb01c Description\nURL BIs there aa URL\nis included in the tweet?\nReply B Is the tweet a reply?\nQuotes B Is this a quoted tweet?\nURL B Does the tweet contain a URL?\nMedia B Does the tweet contain media?\nSource CTools/devices used to post the tweet,\nas an HTML-formatted string.\nDomain C Domain of the included URL.\nNum media N Number of media mentioned in the tweet.\nMedia type C Type of included media, e.g., image.\nFact CA label (unknown, high, mixed, or low)\nfor factuality of the linked information,\ne.g., if it is a news medium.\nUser-Speci\ufb01c Description\nStatuses N Number of tweets (incl. retweets) posted.\nFollowers N The number of followers.\nFriends N The number of following.\nFavorites The number of liked tweets.\nListed N The number of subscriptions to public lists.\nDefault pro\ufb01le BHas the user altered the theme\nor the background of the pro\ufb01le?.\nPro\ufb01le img BHas the user uploaded\na pro\ufb01le image?\nVeri\ufb01ed B Is it a veri\ufb01ed account?\nProtected BHas the user chosen\nto protect their tweets?\nGEO-enabled B Is geotagging enabled?\nBotometer Description\nContent NScore of the length of tweets\nand frequency of part-of-speech tags.\nNetwork NScore about retweets, mentions,\nand hashtags that a user tweeted in the past.\nTemporal N Score about time patterns of tweets.\nSentiment N Score about the sentiment of the user.\nFriend NScore about users that liked or\nretweeted tweets by the user.\nLanguage C Language used.\nUser NScore about the number of followers\u2019 user\nname, and consistency of shared language\nbetween the tweets.\nPropaganda Description\nPrta N Sentence-level Prta propaganda score\nProppy N Article-level Proppy propaganda score\nTable 9: Features modeling social context, botness, and\npropaganda. The middle column shows the type of fea-\nture: B is Boolean, C is categorical, and N is numerical.\nC Detailed Result by Language\nThe main text of the paper had only weighted F1\nscores; here we report also accuracy (Acc) and\nmacro-F1 (M-F1) for English, Arabic, Bulgarian\nand Dutch are shown in Tables 10, 11, 12 and 13,\nrespectively.\nBinary Multiclass\nQ Acc M-F1 W-F1 Acc M-F1 W-F1\nMajority\nQ1 63.0 38.7 48.7\nQ2 94.3 48.5 91.6 77.7 17.5 67.9\nQ3 97.6 49.4 96.3 85.5 18.4 78.9\nQ4 76.8 43.4 66.7 36.9 10.8 19.9\nQ5 77.5 43.7 67.7 61.5 19.0 46.8\nQ6 91.0 47.6 86.7 89.1 11.8 84.0\nQ7 85.1 46.0 78.3 85.0 9.2 78.1\nFastText\nQ1 79.3 65.9 77.7\nQ2 90.8 61.3 89.0 46.3 28.9 44.7\nQ3 69.5 66.9 69.3 65.0 33.5 57.4\nQ4 97.0 54.5 96.3 78.0 20.7 69.2\nQ5 85.4 65.2 83.8 89.4 14.3 84.9\nQ6 93.0 58.8 92.1 72.9 68.7 71.7\nQ7 81.9 71.3 80.6 86.8 23.6 82.4\nBERT\nQ1 76.8 74.5 76.5\nQ2 92.8 60.1 92.1 73.0 25.5 69.2\nQ3 97.2 54.8 96.4 85.2 27.0 82.5\nQ4 85.9 79.3 85.6 56.4 40.3 56.0\nQ5 81.5 71.0 80.6 64.8 37.2 62.0\nQ6 90.2 62.3 88.9 88.3 22.2 86.5\nQ7 87.0 68.5 85.5 85.2 27.7 83.4\nRoBERTa\nQ1 78.8 76.8 78.6\nQ2 93.2 63.6 92.7 71.1 37.9 70.6\nQ3 97.6 60.5 96.9 83.3 33.2 82.8\nQ4 89.1 84.5 89.0 58.7 43.9 58.0\nQ5 84.7 77.4 84.4 71.4 51.3 70.0\nQ6 91.4 68.6 90.5 88.7 26.2 87.7\nQ7 86.7 71.3 86.1 86.1 33.7 85.3\nTable 10: Classi\ufb01cation results on the test set for En-\nglish using various models including a majority class\nbaseline for different questions. Acc. is Accuracy, M-\nF1 is macro F1, and W-F1 is weighted average F1.Binary Multiclass\nQ Acc M-F1 W-F1 Acc M-F1 W-F1\nMajority\nQ1 69.4 41.0 56.8\nQ2 78.0 43.8 68.3 74.0 17.0 62.9\nQ3 97.5 49.4 96.3 59.5 14.9 44.4\nQ4 77.1 43.5 67.2 45.2 12.4 28.1\nQ5 61.5 38.1 46.8 56.9 18.1 41.2\nQ6 81.0 44.7 72.5 78.2 11.0 68.7\nQ7 70.1 41.2 57.7 29.9 4.6 13.8\nFastText\nQ1 64.4 60.0 63.1\nQ2 84.5 66.6 81.7 57.0 30.4 53.3\nQ3 82.6 78.2 82.0 81.1 22.7 75.6\nQ4 97.2 49.3 96.2 56.6 21.0 54.2\nQ5 75.9 67.2 74.0 54.7 27.7 52.6\nQ6 81.5 67.2 79.3 75.3 26.6 71.5\nQ7 83.7 71.5 81.6 43.7 28.0 40.8\nAraBERT\nQ1 84.1 80.7 83.8\nQ2 84.7 75.7 84.0 78.1 30.6 75.6\nQ3 96.5 53.0 96.0 54.4 22.9 53.7\nQ4 90.4 86.3 90.3 47.6 34.0 46.9\nQ5 66.3 63.7 65.9 53.3 34.7 52.6\nQ6 89.2 81.4 88.9 82.8 32.3 82.2\nQ7 77.8 72.6 77.4 57.8 37.3 57.5\nXLM-RoBERTa\nQ1 84.6 81.0 84.2\nQ2 84.0 74.4 83.1 78.7 31.4 76.2\nQ3 97.5 49.4 96.3 60.6 23.7 59.5\nQ4 89.1 84.3 89.0 52.1 36.5 50.6\nQ5 67.1 64.5 66.7 55.3 31.7 52.4\nQ6 89.8 83.3 89.8 85.1 36.4 84.8\nQ7 77.8 72.6 77.4 61.7 40.8 61.6\nTable 11: Classi\ufb01cation results on the test set for Ara-\nbicusing various models including a majority class\nbaseline for different questions. Acc. is Accuracy, M-\nF1 is macro F1, and W-F1 is weighted average F1.\nBinary Multiclass\nQ Acc M-F1 W-F1 Acc M-F1 W-F1\nMajority\nQ1 70.5 41.4 58.3\nQ2 96.6 49.1 95.0 84.4 18.3 77.3\nQ3 97.7 49.4 96.5 75.0 21.4 64.2\nQ4 91.1 47.7 86.8 70.9 16.6 58.8\nQ5 79.6 44.3 70.5 52.4 17.2 36.0\nQ6 88.6 47.0 83.2 84.0 11.4 76.6\nQ7 86.4 46.4 80.1 86.4 10.3 80.1\nFastText\nQ1 78.8 58.1 75.5\nQ2 88.7 55.9 85.2 84.0 16.6 78.8\nQ3 80.6 74.0 79.3 78.5 73.5 78.2\nQ4 97.7 49.4 96.5 76.1 26.5 69.0\nQ5 86.4 51.7 81.5 86.4 13.6 81.5\nQ6 96.6 49.1 95.0 85.2 27.7 79.6\nQ7 91.1 49.7 87.2 73.6 24.2 66.8\nmBERT\nQ1 84.5 80.3 84.0\nQ2 96.0 49.0 94.7 80.9 27.5 77.8\nQ3 96.5 49.1 96.0 71.1 27.8 68.1\nQ4 87.8 62.0 87.7 68.2 26.8 65.6\nQ5 81.7 68.2 80.5 59.5 41.9 58.0\nQ6 86.1 58.1 84.5 80.3 16.2 77.2\nQ7 82.9 58.1 81.6 84.4 17.8 81.7\nXLM-RoBERTa\nQ1 88.0 84.7 87.6\nQ2 96.6 49.1 95.0 83.6 28.6 79.3\nQ3 97.7 49.4 96.5 71.3 28.6 68.8\nQ4 88.8 63.2 88.4 67.4 32.2 67.1\nQ5 83.6 72.7 82.9 63.0 44.7 61.6\nQ6 86.0 61.1 85.1 79.2 23.2 78.8\nQ7 82.1 60.5 81.7 84.4 18.5 81.8\nTable 12: Classi\ufb01cation results on the test set for Bul-\ngarian using various models including a majority class\nbaseline for different questions. Acc. is Accuracy, M-\nF1 is macro F1, and W-F1 is weighted average F1.Binary Multiclass\nQ Acc M-F1 W-F1 Acc M-F1 W-F1\nMajority\nQ1 52.8 34.6 36.5\nQ2 75.4 43.0 64.9 52.8 13.8 36.5\nQ3 73.5 42.4 62.3 48.8 13.1 32.0\nQ4 74.7 42.8 63.9 38.1 11.0 21.0\nQ5 59.5 37.3 44.4 35.3 10.4 18.4\nQ6 89.6 47.3 84.7 82.4 11.3 74.4\nQ7 76.0 43.2 65.6 75.8 8.6 65.4\nFastText\nQ1 63.1 59.7 61.9\nQ2 89.8 62.6 87.9 40.1 29.7 39.7\nQ3 69.9 69.8 69.9 81.8 26.6 77.7\nQ4 75.9 61.9 72.7 47.2 27.1 42.9\nQ5 76.2 65.1 75.3 74.5 15.6 69.6\nQ6 77.6 63.1 74.9 52.0 28.2 46.0\nQ7 77.6 62.2 74.1 47.2 29.4 45.3\nBERTje\nQ1 75.5 75.3 75.4\nQ2 76.3 64.9 75.1 51.6 27.8 45.7\nQ3 78.7 68.5 76.9 53.2 36.7 50.9\nQ4 78.8 67.8 77.1 48.0 29.7 46.3\nQ5 67.1 65.3 66.8 40.9 30.3 40.7\nQ6 88.9 59.7 86.9 80.5 16.7 76.7\nQ7 78.8 69.5 78.3 75.5 19.1 72.2\nXLM-RoBERTa\nQ1 80.0 80.0 80.0\nQ2 84.2 75.9 83.1 56.7 31.2 51.1\nQ3 79.1 71.1 78.3 56.3 38.4 53.9\nQ4 84.1 78.4 83.9 54.4 36.1 53.1\nQ5 71.0 69.7 70.9 46.8 35.0 46.4\nQ6 89.1 65.5 88.1 80.7 15.7 76.3\nQ7 79.4 72.3 79.6 77.0 21.3 74.1\nTable 13: Classi\ufb01cation results on the test set for\nDutch using various models including a majority class\nbaseline for different questions. Acc. is Accuracy, M-\nF1 is macro F1, and W-F1 is weighted average F1.\nD Detailed Annotation Instructions\nGeneral Instructions:\n1.For each tweet, the annotator needs to read the\ntext, including the hashtags, and also to look at\nthe tweet itself when necessary by going to the\nlink (i.e., for Q2-7 it might be required to open\nthe tweet link). The reason for not going to the\ntweet link for Q1 is that we wanted to reduce\nthe complexity of the annotation task and to\nfocus on the content of the tweet only. As for\nQ2, it might be important to check whether the\ntweet was posted by an authoritative source,\nand thus it might be useful for the annotator\nto open the tweet to get more context. After\nall, this is how real users perceive the tweet.\nSince the annotators would open the tweet\u2019s\nlink for Q2, they can use that information for\nthe rest of the questions as well (even though\nthis is not required).\n2.The annotators should assume the time when\nthe tweet was posted as a reference when mak-\ning judgments, e.g., \u201cTrump thinks, that for\nthe vast majority of Americans, the risk is very,\nvery low. \u201d would be true when he made the\nstatement but false by the time annotations\nwere carried out for this tweet.\n3.The annotators may look at the images, the\nvideos and the Web pages that the tweet links\nto, as well as at the tweets in the same thread\nwhen making a judgment, if needed.\n4.The annotators are not asked to complete ques-\ntions Q2-Q5 if the answer to question Q1 is\nNO.\nD.1 Veri\ufb01able Factual Claim\nQuestion 1: Does thetweet contain averi\ufb01able\nfactual claim?\nAveri\ufb01able factual claim is a sentence claiming\nthat something is true, and this can be veri\ufb01ed us-\ning factual veri\ufb01able information such as statistics,\nspeci\ufb01c examples, or personal testimony. Factual\nclaims include the following:8\n\u2022 Stating a de\ufb01nition;\n\u2022Mentioning quantity in the present or the past;\n\u2022Making a veri\ufb01able prediction about the fu-\nture;\n8Inspired by (Konstantinovskiy et al., 2021).\u2022 Statistics or speci\ufb01c examples;\n\u2022Personal experience or statement (e.g., \u201cI\nspent much of the last decade working to de-\nvelop an #Ebola treatment. \u201d )\n\u2022Reference to laws, procedures, and rules of\noperation;\n\u2022References (e.g., URL) to images or videos\n(e.g., \u201cThis is a video showing a hospital in\nSpain. \u201d );\n\u2022Statements that can be technically classi\ufb01ed\nas questions, but in fact contain a veri\ufb01able\nclaim based on the criteria above (e.g., \u201cHold\non - #China Communist Party now denying\n#CoronavirusOutbreak originated in China?\nThis after Beijing\u2019s catastrophic mishandling\nof the virus has caused a global health cri-\nsis?\u201d )\n\u2022Statements about correlation or causation.\nSuch a correlation or causation needs to\nbe explicit, i.e., sentences like \u201cThis is\nwhy the beaches haven\u2019t closed in Florida.\nhttps://t.co/8x2tcQeg21\u201d is not a claim be-\ncause it does not explicitly say why, and thus\nit is not veri\ufb01able.\nTweets containing personal opinions and prefer-\nences are not factual claims. Note that if a tweet is\ncomposed of multiple sentences or clauses, at least\none full sentence or clause needs to be a claim in\norder for the tweet to contain a factual claim. If\na claim exists in a sub-sentence or a sub-clause,\nthen the tweet is not considered to contain a fac-\ntual claim. For example, \u201cMy new favorite thing\nis Italian mayors and regional presidents LOSING\nIT at people violating quarantine\u201d is not a claim\n\u2013 it is in fact an opinion. However, if we consider\n\u201cItalian mayors and regional presidents LOSING IT\nat people violating quarantine\u201d it would be a claim.\nIn addition, when answering this question, annota-\ntors should not open the tweet URL. Since this is\na binary decision task, the answer of this question\nconsists of two labels as de\ufb01ned below.\nLabels:\n\u2022YES: if it contains a veri\ufb01able factual claim;\n\u2022NO: if it does not contain a veri\ufb01able factual\nclaim;\n\u2022Don\u2019t know or can\u2019t judge: the\ncontent of the tweet does not provide enough\ninformation to make a judgment. It is rec-\nommended to categorize the tweet using this\nlabel when the content of the tweet is not un-\nderstandable at all. For example, it uses a\nlanguage (i.e., non-English) or references dif-\n\ufb01cult to understand;\nExamples:\n1.Please don\u2019t take hydroxychloroquine\n(Plaquenil) plus Azithromycin for #COVID19\nUNLESS your doctor prescribes it. Both\ndrugs affect the QT interval of your heart and\ncan lead to arrhythmias and sudden death,\nespecially if you are taking other meds or\nhave a heart condition.\nLabel: YES\nExplanation: There is a claim in the text.\n2.Saw this on Facebook today and it\u2019s a must\nread for all those idiots clearing the shelves\n#coronavirus #toiletpapercrisis #auspol\nLabel: NO\nExplanation: There is no claim in the text.\nD.2 False Information\nQuestion 2: Towhat extent does thetweet appear\ntocontain false information?\nThe stated claim may contain false information.\nThis question labels the tweets with the categories\nmentioned below. False Information appears on\nsocial media platforms, blogs, and news-articles to\ndeliberately misinform or deceive readers.\nLabels: The labels for this question are de\ufb01ned on\na \ufb01ve point Likert scale (Albaum, 1997). A higher\nvalue means that it is more likely to be false:\n1.NO, definitely contains no\nfalse information\n2.NO, probably contains no false\ninformation\n3.Not sure\n4.YES, probably contains false\ninformation\n5.YES, definitely contains false\ninformationTo answer this question, it is recommended to\nopen the link of the tweet and to look for additional\ninformation to determine the veracity of the claims\nit makes. For example, if the tweet contains a link\nto an article from a reputable information source\n(e.g., Reuters, Associated Press, France Press, Al-\njazeera English, BBC), then the answer could be\n\u201c. . . contains no false info\u201d. Note that answering\nthis question is not required if the answer to Ques-\ntion 1 is NO.\nExamples:\n1.\u201cDominican Republic found the cure for\nCovid-19 https://t.co/1CfA162Lq3\u201d\nLabel: 5. YES, definitely\ncontains false information\nExplanation: This is not correct information\nat the time of this tweet is posted.\n2.This is Dr. Usama Riaz. He spent past weeks\nscreening and treating patients with Corona\nVirus in Pakistan. He knew there was no PPE.\nHe persisted anyways. Today he lost his own\nbattle with coronavirus but he gave life and\nhope to so many more. KNOW HIS NAME\nhttps://t.co/\ufb02SwhLCPmx\nLabel: 2. NO, probably contains\nno false info\nExplanation: The content of the tweet states\ncorrect information.\nD.3 Interest to the General Public\nQuestion 3: Will thetweet\u2019s claim have animpact\nonorbeofinterest tothegeneral public?\nMost often, people do not make interesting\nclaims, which can be veri\ufb01ed by our general knowl-\nedge. For example, though \u201cThe sky is blue\u201d is a\nclaim, it is not interesting to the general public. In\ngeneral, topics such as healthcare, political news,\nand current events are of higher interest to the gen-\neral public. Using the \ufb01ve point Likert scale the\nlabels are de\ufb01ned below.\nLabels: The labels are on a 5-point Likert scale:\n1.NO, definitely not of interest\n2.NO, probably not of interest\n3.Not sure\n4.YES, probably of interest\n5.YES, definitely of interest\nExamples:\n1.Germany is conducting 160k Covid-19 tests\na week. It has a total 35k ventilators, 10k\nordered to be made by the govt. It has\nconverted a new 1k bed hospital in Berlin.\nIt\u2019s death rate is tiny bcos it\u2019s mass testing\nallows quarantine and bcos it has fewer non\nreported cases.\nLabel: 4. YES: probably of\ninterest\nExplanation: This information is relevant\nand of high interest for the general population\nas it reports how a country deals with\nCOVID-19.\n2.Fake news peddler Dhruv Rathee had said:\n\u201cCorona virus won\u2019t spread outside China, we\nneed not worry\u201d Has this guy ever spoke\nsomething sensible? https://t.co/siBAwIR8Pn\nLabel: 2. NO, probably not of\ninterest\nExplanation: The information is not interest-\ning for the general public as it is an opinion\nand discusses the statement by someone else.\nD.4 Harmfulness\nQuestion 4: Towhat extent does thetweet appear\ntobeharmful tosociety, person(s), company(s) or\nproduct(s)? The purpose of this question is to de-\ntermine whether the content of the tweet aims to\nand can negatively affect society as a whole, spe-\nci\ufb01c person(s), company(s), product(s), or spread\nrumors about them. The content intends to harm\norweaponize the information9(Broniatowski et al.,\n2018). A rumor involves a form of a statement\nwhose veracity is not quickly veri\ufb01able or ever con-\n\ufb01rmed.10\nLabels: To categorize the tweets in terms of\ntheir harmfulness, we de\ufb01ned the following labels,\nagain using a Likert scale, where a higher value\nindicates a higher degree of harm:\n1.NO, definitely not harmful\n2.NO, probably not harmful\n3.Not sure\n4.YES, probably harmful\n5.YES, definitely harmful\n9The use of information as a weapon to spread misinfor-\nmation and mislead people.\n10https://en.wikipedia.org/wiki/RumorExamples:\n1.How convenient but not the least bit sur-\nprising from Democrats! As usual they put\npolitics over American citizens. @Speaker-\nPelosi withheld #coronavirus bill so DCCC\ncould run ads AGAINST GOP candidates!\n#tcot\nLabel: 5. YES, definitely\nharmful\nExplanation: This tweet is weaponized to\ntarget Nancy Pelosi and the Democrats in\ngeneral.\n2.As we saw over the wkend, disinfo is being\nspread online about a supposed national\nlockdown and grounding \ufb02ights. Be skeptical\nof rumors. Make sure you\u2019re getting info\nfrom legitimate sources. The @WhiteHouse\nis holding daily brie\ufb01ngs and @cdcgov is\nproviding the latest.\nLabel: 1. NO, definitely not\nharmful\nExplanation: This tweet is informative and\ngives advice. It does not attack anyone and is\nnot harmful.\nD.5 Need for Veri\ufb01cation\nQuestion 5: Doyou think that aprofessional\nfact-checker should verify theclaim inthetweet?\nIt is important that a veri\ufb01able factual check-\nworthy claim be veri\ufb01ed by a professional fact-\nchecker, as the claim may cause harm to soci-\nety, speci\ufb01c person(s), company(s), product(s), or\nsome government entities. However, not all fac-\ntual claims are important or worth fact-checking\nby a professional fact-checker, as this very time-\nconsuming. Therefore, the purpose is to categorize\nthe tweet using the labels de\ufb01ned below. While do-\ning so, the annotator can rely on the answers to the\nprevious questions. For this question, we de\ufb01ned\nthe following labels to categorize the tweets. This\nquestion is to be answered, taking the responses to\nthe previous questions into account.\nLabels:\n1.NO, no need to check : the tweet\ndoes not need to be fact-checked, e.g., be-\ncause it is not interesting, a joke, or does not\ncontain any claim.\n2.NO, too trivial to check : the\ntweet is worth fact-checking, however, this\ndoes not require a professional fact-checker,\ni.e., a non-expert might be able to fact-check\nthe claim. For example, one can verify the\ninformation using reliable sources such as the\nof\ufb01cial website of the WHO, etc. An example\nof a claim is as follows: \u201cThe GDP of the\nUSA grew by 50% last year. \u201d\n3.YES, not urgent : the tweet should be\nfact-checked by a professional fact-checker,\nhowever, this is not urgent or critical;\n4.YES, very urgent : the tweet can cause\nimmediate harm to a large number of people;\ntherefore, it should be veri\ufb01ed as soon as pos-\nsible by a professional fact-checker;\n5.Not sure : the content of the tweet does not\nhave enough information to make a judgment.\nIt is recommended to categorize the tweet us-\ning this label when the content of the tweet is\nnot understandable at all. For example, it uses\na language (i.e., non-English) or references\nthat it is dif\ufb01cult to understand.\nExamples:\n1.Things the GOP has done during the Covid-19\noutbreak: - Illegally traded stocks - Called it\na hoax - Blamed it on China - Tried to bailout\nbig business without conditions What they\nhaven\u2019t done: - Help workers - Help small\nbusinesses - Produced enough tests or ventila-\ntors\nLabel: 2. YES, very urgent\nExplanation: The tweet blames the author-\nities, and thus, it is important to verify it\nquickly by a professional fact-checker. In ad-\ndition, the attention of government entities\nmight be required in order to take necessary\nactions.\n2.ALERT\n The corona virus can be\nspread through internationally printed albums.\nIf you have any albums at home, put on some\ngloves, put all the albums in a box and put it\noutside the front door tonight. I\u2019m collecting\nall the boxes tonight for safety. Think of your\nhealth.\nLabel: 5. NO, no need to check\nExplanation: This is clearly a joke, and thus\nis does not require to be checked by a profes-\nsional fact-checker.D.6 Harmful to Society\nQuestion 6: Isthetweet harmful tosociety and\nwhy?\nThis question asks whether the content of the\ntweet is intended to harm or is weaponized to mis-\nlead the society. To identify that, we de\ufb01ned the\nfollowing labels for the categorization.\nLabels:\nA.NO, not harmful: the content of the\ntweet would not harm the society (e.g., \u201cI\nlike corona beer\u201d ).\nB.NO, joke or sarcasm: the tweet con-\ntains a joke (e.g., \u201cIf Corona enters Spain, it\u2019ll\nenter from the side of Barcelona defense\u201d ) or\nsarcasm (e.g., \u201c\u2018The corona virus is a real\nthing. \u2019 \u2013 Wow, I had no idea!\u201d ).\nC.Not sure: if the content of the tweet is not\nunderstandable enough to judge.\nD.YES, panic: the tweet spreads panic. The\ncontent of the tweet can cause sudden fear\nand anxiety for a large part of the society\n(e.g., \u201cthere are 50,000 cases ov COVID-19\nin Qatar\u201d ).\nE.YES, xenophobic, racist,\nprejudices, or hate-speech:\nthe tweet spreads xenophobia, racism, or\nprejudices. According to the dictionary11\nXenophobic refers to fear or hatred of\nforeigners, people from different cultures, or\nstrangers. Racism is the belief that groups\nof humans possess different behavioral traits\ncorresponding to physical appearance and\ncan be divided based on the superiority of\none race over another.12It may also refer\nto prejudice, discrimination, or antagonism\ndirected against other people because they are\nof a different race or ethnicity. Prejudice is an\nunjusti\ufb01ed or incorrect attitude (i.e., typically\nnegative) towards an individual based solely\non the individual\u2019s membership in a social\ngroup.13Here is an example: \u201cdo not buy\ncucumbers from Iran\u201d .\nF.YES, bad cure: the tweet promotes\nquestionable cure, medicine, vaccine, or pre-\nvention procedures (e.g., \u201c. . . drinking bleach\ncan help cure coronavirus\u201d ).\n11https://www.dictionary.com/\n12https://en.wikipedia.org/wiki/Racism\n13http://www.simplypsychology.org/\nprejudice.html\nG.YES, rumor, or conspiracy: the\ntweet spreads rumors. Rumor is de\ufb01ned as\na \u201cspeci\ufb01c (or topical) proposition for belief\npassed along from person to person usually by\nword of mouth without secure standards of ev-\nidence being present\u201d (Allport and Postman,\n1947). For example, \u201cBREAKING: Trump\ncould still own stock in a company that, ac-\ncording to the CDC, will play a major role in\nproviding coronavirus test kits to the federal\ngovernment, which means that Trump could\npro\ufb01t from coronavirus testing. #COVID-19\n#coronavirus https://t.co/Kwl3ylMZRk\u201d\nH.YES, other: if the content of the tweet\ndoes not belong to any of the above categories,\nthen this category can be chosen to label the\ntweet.\nD.7 Requires Attention\nQuestion 7: Doyouthink thatthistweet should\ngettheattention ofpolicy makers ofgovernment\nentities?\nMost often people tweet by blaming authorities,\nproviding advice, and/or call for action. Policy\nmakers might want to respond or to react to this.\nThe purpose of this question is to categorize such\ninformation. It is important to note that not all infor-\nmation requires attention from a government entity.\nTherefore, even if the tweet\u2019s content belongs to\nany of the positive categories, it is important to\nunderstand whether it requires attention. For the\nannotation, it is mandatory to \ufb01rst decide whether\nattention is necessary (i.e., YES/NO ). If the answer\nisYES, it is obligatory to select a category from\ntheYES sub-categories below.\nLabels:\nA.NO, not interesting: the content of\nthe tweet is not important or interesting for\nany government entity to pay attention to.\nB.Not sure: if the content of the tweet is not\nunderstandable enough to judge;\nC.YES, categorized as in\nquestion 6: some government en-\ntity needs to pay attention to this tweet as it is\nharmful for society and it was labeled as any\nof the YES sub-categories in question 6;\nD.YES, other: if the tweet cannot be la-\nbeled as any of the above categories, then this\nlabel should be selected;E.YES, blames authorities: the\ntweet blames authorities, e.g., \u201cDear @VP\nPence: Is the below true? Do you have a\nplan? Also, when are local jurisdictions\ngoing to get the #Coronavirus test kits you\npromised?\u201d ;\nF.YES, contains advice: the tweet\ncontains advice about social, political, na-\ntional, or international issues that requires\nattention from some government entity\n(e.g., The elderly & people with pre-existing\nhealth conditions are more susceptible to\n#COVID19. To stay safe, they should:\nXKeep distance from people who are sick\nXFrequently wash hands with soap & water\nXProtect their mental health );\nG.YES, calls for action: the tweet\nstates that some government entity should\ntake action for a particular issue (e.g., I think\nthe Government should close all the Barber\nShops and Salons, let people buy shaving\nmachines and other beauty gardgets keep in\ntheir houses. Salons and Barbershops might\nprove to be another Virus spreading chan-\nnels @citizentvkenya @SenMutula @CSMu-\ntahi_Kagwe );\nH.YES, discusses action taken:\nthe tweet discusses actions taken by gov-\nernments, companies, individuals for any\nparticular issue, for example, closure of bars,\nconferences, churches due to the corona virus\n(e.g., Due to the current circumstances with\nthe Corona virus, The 4th Mediterranean\nHeat Treatment and Surface Engineering\nConference in Istanbul postponed to 26-28\nMay\u0131s 2021. ).\nI.YES, discusses cure: attention is\nneeded by some government entity as the\ntweet discusses a possible cure, vaccine, or\ntreatment for a disease;\nJ.YES, asks question: the tweet asks\na question about a particular issue and it\nrequires attention from government entities\n(e.g., Special thanks to all doctors and nurses,\nnew found respect for you\u2019ll. Is the virus go-\ning to totally disappear in the summer? I live\nin USA and praying that when the tempera-\nture warms up the virus will go away...is my\nthinking accurate? )\nE Annotation Agreement\nIn Tables 14, 15, 16 and 17, we report the inter-\nannotator agreement for English,14Arabic, Bul-\ngarian and Dutch, respectively. Overall, we can\nsee that there is moderate to substantial agreement\nfor all questions both for the binary and for the\nmulti-label setting.\nAgree. Pair Q1 Q2 Q3 Q4 Q5 Q6 Q7\nMulticlass\nA1 - C 0.81 0.73 0.59 0.74 0.79 0.67 0.73\nA2 - C 0.67 0.53 0.44 0.45 0.39 0.65 0.47\nA3 - C 0.78 0.58 0.63 0.61 0.70 0.17 0.42\nAvg 0.75 0.61 0.55 0.60 0.63 0.50 0.54\nBinary\nA1 - C 0.81 0.73 0.77 0.85 0.84 0.77 0.92\nA2 - C 0.67 0.58 0.53 0.43 0.52 0.33 0.57\nA3 - C 0.78 0.70 0.63 0.70 0.74 0.11 0.57\nAvg 0.75 0.67 0.64 0.66 0.70 0.40 0.69\nTable 14: Inter-annotator agreement using Fleiss\nKappa (\u0014) for the English dataset. Arefers to anno-\ntator, and Crefers to consolidation.\nAgree. Pair Q1 Q2 Q3 Q4 Q5 Q6 Q7\nMulticlass\nA1 - C 0.58 0.5 0.52 0.53 0.4 0.61 0.47\nA2 - C 0.59 0.52 0.52 0.55 0.44 0.62 0.4\nA3 - C 0.57 0.44 0.48 0.37 0.36 0.4 0.3\nAvg 0.58 0.49 0.51 0.48 0.4 0.54 0.39\nBinary\nA1 - C 0.58 0.52 0.53 0.58 0.47 0.65 0.45\nA2 - C 0.59 0.57 0.57 0.59 0.47 0.67 0.36\nA3 - C 0.57 0.48 0.53 0.47 0.39 0.46 0.29\nAvg 0.58 0.52 0.54 0.55 0.44 0.59 0.37\nTable 15: Inter-annotator agreement using Fleiss\nKappa (\u0014) for the Arabic dataset. Arefers to annota-\ntor, and Crefers to consolidation.\n14We have already presented the table for English in the\nmain text of the paper, but we repeat it here to facilitate cross-\nlanguage comparisons.Agree. Pair Q1 Q2 Q3 Q4 Q5 Q6 Q7\nMulticlass\nA1 - C 0.77 0.44 0.64 0.53 0.49 0.53 0.51\nA2 - C 0.51 0.40 0.59 0.49 0.44 0.56 0.53\nA3 - C 0.47 0.38 0.57 0.49 0.38 0.53 0.40\nAvg 0.58 0.41 0.60 0.50 0.44 0.54 0.48\nBinary\nA1 - C 0.77 0.41 0.71 0.56 0.61 0.47 0.50\nA2 - C 0.51 0.39 0.64 0.52 0.57 0.51 0.53\nA3 - C 0.47 0.34 0.62 0.52 0.54 0.47 0.38\nAvg 0.58 0.38 0.66 0.53 0.57 0.48 0.47\nTable 16: Inter-annotator agreement using Fleiss\nKappa (\u0014) for the Bulgarian dataset. Arefers to an-\nnotator, and Crefers to consolidation.\nAgree. Pair Q1 Q2 Q3 Q4 Q5 Q6 Q7\nMulticlass\nA1 - C 0.63 0.54 0.58 0.58 0.54 0.66 0.63\nA2 - C 0.83 0.69 0.68 0.70 0.65 0.59 0.62\nA3 - C 0.76 0.64 0.59 0.59 0.62 0.51 0.59\nAvg 0.74 0.62 0.62 0.62 0.60 0.59 0.61\nBinary\nA1 - C 0.63 0.62 0.63 0.60 0.60 0.68 0.69\nA2 - C 0.83 0.73 0.76 0.77 0.75 0.63 0.69\nA3 - C 0.76 0.68 0.68 0.66 0.69 0.53 0.65\nAvg 0.74 0.67 0.69 0.68 0.68 0.61 0.68\nTable 17: Inter-annotator agreement using Fleiss\nKappa (\u0014) for the Dutch dataset. Arefers to annotator,\nandCrefers to consolidation.\nF Class Label Distribution\nFigures 3, 4, 5 and 6 report detailed statistics about\nthe label distribution for the manual annotations for\neach question in English, Arabic, Bulgarian, and\nDutch, respectively.\n(a) Questions (Q1-5).\n(b) Questions (Q6-7).\nFigure 3: Distribution of class labels for English tweets\n(a) Questions (Q1-5).\n(b) Questions (Q6-7).\nFigure 4: Distribution of class labels for Arabic tweets\n(a) Questions (Q1-5).\n(b) Questions (Q6-7).\nFigure 5: Distribution of class labels for Bulgarian tweets\n(a) Questions (Q1-5).\n(b) Questions (Q6-7).\nFigure 6: Distribution of class labels for Dutch tweets\nG Correlation Between Questions\nFinally, we study the correlation between the labels\nfor different questions across for each of the four\nlanguages.\nG.1 English Tweets\nFigure 7 shows contingency and correlation tables\nin a form of a heatmap for different question pairs\nobtained from the English tweet dataset. For ques-\ntions Q2-3, it appears that there is a high associ-\nation between \u201c. . . no false info\u201d and the general\npublic interest as shown in Figure 7a. For questions\nQ2 and Q4 (Figure 7b), strong association can be\nobserved between \u201c. . . no false info\u201d and \u201c. . . not\nharmful\u201d (86%) compared to \u201charmful\u201d (13%) for\neither an individual, a products or government en-\ntities. By analyzing questions Q2 and Q5 (Figure\n7c), we conclude that \u201c. . . no false info\u201d is associ-\nated with either \u201cno need to check\u201d or \u201ctoo trivial\nto check\u201d, highlighting the fact that a professional\nfact-checker does not need to spend time on them.\nFrom questions Q3 and Q4 (Figure 7d), it appears\nthat when the content of the tweets is \u201cnot harm-\nful\u201d the general public interest is higher (74%) than\nwhen it is \u201charmful\u201d (22%). From question Q3 and\nQ5 (Figure 7e), we see an interesting phenomenon,\nnamely that tweets of high general public interest\nhave a greater association with a professional fact-\nchecker having to verify them (22%) compared to\neither \u201ctoo trivial to check\u201d or \u201cno need to check\u201d\n(78%). Questions Q4 and Q5 (Figure 7f) show\nthat \u201charmful\u201d tweets require an attention (69%)\nfrom a professional fact-checkers than \u201cnot harm-\nful\u201d tweets (30%). Our \ufb01ndings for Q6 and Q7\n(Figure 7g) suggest that the majority of the tweets\nare not harmful to society, which also requires less\nattention from government entities. The third most\ncommon tweet label for Q7 blames the authori-\nties, even though they are mostly not harmful for\nsociety.\nWe computed the correlation using the Likert\nscale values (i.e., 1-5) that we de\ufb01ned for these\nquestions. We observed that overall Q2 and Q3\nare negatively correlated, which suggests that if\nthe claim contains no false information, it is of\nhigh interest to the general public. This can be\nalso observed in Figure 7a. Questions Q2 and Q4\nexhibit positive correlation, which might be due to\ntheir high association with \u201c. . . no false info\u201d and\n\u201c. . . not harmful\u201d.G.2 Arabic Tweets\nFigure 8 shows similar heatmaps for the Arabic\ntweets. For Q2 and Q3 (Figure 8a), we can ob-\nserve that the association between \u201c. . . contains no\nfalse info\u201d and general public interest is higher\n(76%) than \u201c. . . contains false info\u201d (23%). From\nquestions Q2 and Q4 (Figure 8b), we can conclude\nthat \u201c. . . contains no false info\u201d is associated with\n\u201c. . . not harmful\u201d and \u201c. . . contains false info\u201d is\nassociated with \u201c. . . harmful\u201d. From the relation be-\ntween Q2 and Q5 (Figure 8c), we can observe that\nin the majority of the cases \u201c. . . contains no false\ninfo\u201d is associated with either \u201cno need to check\u201d\nor \u201ctoo trivial to check\u201d, which means that a pro-\nfessional fact-checker does not need to verify them.\nThe analysis between questions Q3 and Q4 sug-\ngests that the general public interest is higher when\nthe content of the tweets is not harmful (79%) than\nwhen it is harmful (21%) (Figure 8d). From ques-\ntions Q3 and Q5, we can observe that the general\npublic interest is higher when the claim(s) in the\ntweets are either \u201cno need to check\u201d or \u201ctoo trivial\nto check\u201d (Figure 8e). The analysis between ques-\ntion Q4 and Q5 shows that \u201cnot harmful\u201d tweets are\neither \u201cno need to check\u201d or \u201ctoo trivial to check\u201d\nby a professional fact-checker (Figure 8f). From\nquestions Q6 and Q7, we notice that in the majority\nof the cases the tweets are not harmful for society\nand hence they are not interesting for government\nentities (Figure 8g).\nG.3 Bulgarian and Dutch Tweets\nFigures 9 and 10 show the same kinds of heatmaps\nfor the Bulgarian and the Dutch datasets, respec-\ntively. The observations are very similar.\n(a) Heatmap for Q2 and Q3.\n (b) Heatmap for Q2 and Q4.\n(c) Heatmap for Q2 and Q5.\n (d) Heatmap for Q3 and Q4.\n(e) Heatmap for Q3 and Q5.\n (f) Heatmap for Q4 and Q5.\n(g) Heatmap for Q6 and Q7. YES, X/R/P/HS \u2013 YES, xenophobic, racist,\nprejudices or hate speech\nFigure 7: Contingency and correlation heatmaps for the English tweets for different question pairs.\n(a) Heatmap for Q2 and Q3.\n (b) Heatmap for Q2 and Q4.\n(c) Heatmap for Q2 and Q5.\n (d) Heatmap for Q3 and Q4.\n(e) Heatmap for Q3 and Q5.\n (f) Heatmap for Q4 and Q5.\n(g) Heatmap for Q6 and Q7. YES, X/R/P/HS \u2013 YES, xenophobic, racist,\nprejudices or hate speech\nFigure 8: Contingency and correlation heatmaps for the Arabic tweets for different question pairs.\n(a) Heatmap for Q2 and Q3.\n (b) Heatmap for Q2 and Q4.\n(c) Heatmap for Q2 and Q5.\n (d) Heatmap for Q3 and Q4.\n(e) Heatmap for Q3 and Q5.\n (f) Heatmap for Q4 and Q5.\n(g) Heatmap for Q6 and Q7. YES, X/R/P/HS \u2013 YES, xenophobic, racist,\nprejudices or hate speech\nFigure 9: Contingency and correlation heatmaps for the Bulgarian tweets for different question pairs.\n(a) Heatmap for Q2 and Q3.\n (b) Heatmap for Q2 and Q4.\n(c) Heatmap for Q2 and Q5.\n (d) Heatmap for Q3 and Q4.\n(e) Heatmap for Q3 and Q5.\n (f) Heatmap for Q4 and Q5.\n(g) Heatmap for Q6 and Q7. YES, X/R/P/HS \u2013 YES, xenophobic, racist,\nprejudices or hate speech\nFigure 10: Contingency and correlation heatmaps for the Dutch tweets for different question pairs.\nH Geographical Distribution: English\nand Arabic\nFigure 11 shows the geographical distribution of\nthe annotated tweets for English and Arabic. We\nconsider the country of the tweet author or the\noriginal author in case of a retweet. We can see that\nmost English tweets come from USA, UK, Canada,\nand India, while most Arabic tweets come from the\nGulf region (KSA, UAE, Qatar, and Kuwait). Yet,\nfor both languages, we have tweets from multiple\ncountries, which means that there is good diversity\nof interests, topics, style, etc.\nWe did not perform this analysis for Bulgarian\nand Dutch, as these are less international languages,\nand their speakers are mostly concentrated in Bul-\ngaria and the Netherlands, respectively.\n(a) English dataset\n(b) Arabic dataset\nFigure 11: Distribution by country for English and Ara-\nbic tweets.\nI Veri\ufb01ed and Unveri\ufb01ed Accounts:\nEnglish and Arabic\nWe study the correlation between tweet labels and\nwhether or not the original author of a tweet has\na veri\ufb01ed account. Veri\ufb01ed accounts include such\nby government entities, public \ufb01gures, celebrities,\netc., which have a large number of followers, and\nthus their tweets typically have higher impact.\nFigure 12 shows that veri\ufb01ed accounts tend to\npost more tweets that contain factual claims than\nunveri\ufb01ed accounts (Q1), and their tweets are less\nlikely to contain false information (Q2), are more\nlikely to be of interest to the general public (Q3),\nand are less likely to be harmful (Q4 and Q6).\nBased on this study, we have added correspond-\ning features for our models.\nFigure 12: Veri\ufb01ed vs. non-veri\ufb01ed account distribution for English and Arabic across the different questions. NA\nrefers to tweets that have not been labeled for those questions, they are identical to the tweets categorized with the\nlabel NO in Q1.\nJ Multimedia in Tweets: English and\nArabic\nIn this subsection, we study the correlation between\nwhether a tweet contains multimedia (image or\nvideo) and the annotation labels. Generally, people\ntrust videos more than images or plain texts, which\nsuggests that tweets with video could have a higher\nimpact. Figure 13 shows the distribution of media\ntypes for English and Arabic.\nWe can see that if a tweet contains multimedia\ncontent, it is likely to contain a factual claim (Q1),\nto have a higher impact to the general public (Q3),\nbut it is less likely to contain false information\n(Q2) or to be harmful to the society (Q4). These\nobservations in part motivated us to model the use\nof multimedia as part of our features.\nFigure 13: Distribution of media types in English and Arabic tweets.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fighting the COVID-19 infodemic: Modeling the perspective of journalists, fact-checkers, social media platforms, policy makers, and the society", "author": ["F Alam", "S Shaar", "F Dalvi", "H Sajjad", "A Nikolov"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "With the emergence of the COVID-19 pandemic, the political and the medical aspects of  disinformation merged as the problem got elevated to a whole new level to become the first"}, "filled": false, "gsrank": 53, "pub_url": "https://arxiv.org/abs/2005.00033", "author_id": ["j-RtwDQAAAAJ", "yMArLRcAAAAJ", "uQGCv10AAAAJ", "t3BH6NkAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:OxpvstlAmegJ:scholar.google.com/&output=cite&scirp=52&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D50%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=OxpvstlAmegJ&ei=DbWsaIjTFLTWieoP1pCJ2AY&json=", "num_citations": 203, "citedby_url": "/scholar?cites=16760498791981718075&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:OxpvstlAmegJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2005.00033"}}, {"title": "Predicting the topical stance and political leaning of media using tweets", "year": "2020", "pdf_data": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 527\u2013537\nJuly 5 - 10, 2020. c\r2020 Association for Computational Linguistics527Predicting the Topical Stance and Political Leaning of Media using Tweets\nPeter Stefanov1, Kareem Darwish2, Atanas Atanasov3, Preslav Nakov2\n1SiteGround Hosting EOOD, Bulgaria\n2Qatar Computing Research Institute, HBKU, Doha, Qatar\n3So\ufb01a University \u201cSt. Kliment Ohridski\u201d, So\ufb01a, Bulgaria\nfstefanov.peter.ps,atanas.atanasov.sf g@gmail.com ,\nfkdarwish,pnakov g@hbku.edu.qa\nAbstract\nDiscovering the stances of media outlets and\nin\ufb02uential people on current, debatable topics\nis important for social statisticians and policy\nmakers. Many supervised solutions exist for\ndetermining viewpoints, but manually annotat-\ning training data is costly. In this paper, we\npropose a cascaded method that uses unsuper-\nvised learning to ascertain the stance of Twit-\nter users with respect to a polarizing topic by\nleveraging their retweet behavior; then, it uses\nsupervised learning based on user labels to\ncharacterize both the general political leaning\nof online media and of popular Twitter users,\nas well as their stance with respect to the tar-\nget polarizing topic. We evaluate the model by\ncomparing its predictions to gold labels from\nthe Media Bias/Fact Check website, achieving\n82.6% accuracy.\n1 Introduction\nOnline media and popular Twitter users, which we\nwill collectively refer to as in\ufb02uencers , often ex-\npress overt political leanings, which can be gleaned\nfrom their positions on a variety of political and\ncultural issues. Determining their leaning can be\ndone through the analysis of their writing, which in-\ncludes the identi\ufb01cation of terms that are indicative\nof stance (Groseclose and Milyo, 2005; Gentzkow\nand Shapiro, 2011). Performing such analysis auto-\nmatically can be done using supervised classi\ufb01ca-\ntion, which in turn would require manually labeled\ndata (Groseclose and Milyo, 2005; Gentzkow and\nShapiro, 2011; Mohammad et al., 2016). Alter-\nnatively, leanings can be inferred based on which\npeople share the content (blogs, tweets, posts, etc.)\non social media, as social media users are more\nlikely to share content that originates from sources\nthat generally agree with their positions (An et al.,\n2012; Morgan et al., 2013; Ribeiro et al., 2018;\nWong et al., 2013).Here, we make use of this observation to character-\nize in\ufb02uencers, based on the stances of the Twitter\nusers that share their content. Ascertaining the\nstances of users, also known as stance detection,\ninvolves identifying the position of a user with re-\nspect to a topic, an entity, or a claim (Mohammad\net al., 2016). For example, on the topic of abortion\nin USA, the stances of left- vs. right-leaning users\nwould typically be \u201cpro-choice\u201d vs. \u201cpro-life\u201d, re-\nspectively.\nIn this paper, we propose to apply unsupervised\nstance detection to automatically tag a large num-\nber of Twitter users with their positions on speci\ufb01c\ntopics (Darwish et al., 2020). The tagging identi-\n\ufb01es clusters of vocal users based on the accounts\nthat they retweet. Although the method we use\nmay yield more than two clusters, we retain the\ntwo largest ones, which typically include the over-\nwhelming majority of users, and we ignore the rest.\nThen, we train a classi\ufb01er that predicts which clus-\nter a user belongs to, in order to expand our clus-\nters. Once we have increased the number of users\nin our sets, we determine which sources are most\nstrongly associated with each group based on shar-\ning by each group. We apply this methodology to\ndetermine the positions of in\ufb02uencers and of media\non eight polarizing topics along with their overall\nleaning: left, center or right. In doing so, we can\nalso observe the sharing behavior of right- and left-\nleaning users, and we can correlate their behavior\nwith the credibility of the sources. Further, given\nthe user stances for these eight topics, we train a\nsupervised classi\ufb01er to predict the overall bias of\nsources using a variety of features, including the\nso-called valence (Conover et al., 2011a), graph\nembeddings, and contextual embeddings. Using\na combination of these features, our classi\ufb01er is\nable to predict the bias of sources with 82.6% accu-\nracy, with valence being the most effective feature.\nFigure 1 outlines our overall methodology.\n528\nFigure 1: General outline of our methodology.\nOur contributions are as follows:\n\u000fWe use unsupervised stance detection to au-\ntomatically determine the stance of Twitter\nusers with respect to several polarizing topics.\n\u000fWe then use distant supervision based on these\ndiscovered user stances to accurately charac-\nterize the political leaning of media outlets\nand of popular Twitter accounts. For classi-\n\ufb01cation, we use a combination of source va-\nlence, graph embeddings, and contextualized\ntext embeddings.\n\u000fWe evaluate our approach by comparing its\nbias predictions for a number of news out-\nlets against gold labels from Media Bias/Fact\nCheck. We further evaluate its predictions\nfor popular Twitter users against manual judg-\nments. The experimental results show sizable\nimprovements over using graph embeddings\nor contextualized text embeddings.\nThe remainder of this paper is organized as fol-\nlows: Section 2 discusses related work. Section 3\ndescribes the process of data collection. Section 4\npresents our method for user stance detection. Sec-\ntion 5 describes how we characterize the in\ufb02u-\nencers. Section 6 discusses our experiments in\nmedia bias prediction. Finally, Section 7 concludes\nand points to possible directions for future work.\n2 Related Work\nRecent work that attempted to characterize the\nstance and the ideological leaning of media and\nTwitter users relied on the observation that users\ntend to retweet content that is consistent with their\nworld view. This stems from selective exposure ,\nwhich is a cognitive bias that leads people to avoid\nthe cognitive overload from exposure to opposing\nviews as well as the cognitive dissonance in which\npeople are forced to reconcile between their views\nand opposing views (Morgan et al., 2013).Concerning media, Ribeiro et al. (2018) used the\nFacebook advertising services to infer the ideologi-\ncal leaning of online media based on the political\nleaning of Facebook users who consumed them. An\net al. (2012) relied on follow relationships to online\nmedia on Twitter to ascertain ideological leaning\nof media and users based on the similarity between\nthem. Wong et al. (2013) studied retweet behavior\nto infer the ideological leanings of online media\nsources and popular Twitter accounts. Barber \u00b4a and\nSood (2015) proposed a statistical model based\non the follower relationships to media sources and\nTwitter personalities in order to estimate their ideo-\nlogical leaning.\nAs for individual users, much recent work fo-\ncused on stance detection to determine a person\u2019s\nposition on a topic including the deduction of politi-\ncal preferences (Barber \u00b4a, 2015; Barber and Rivero,\n2015; Borge-Holthoefer et al., 2015; Cohen and\nRuths, 2013; Colleoni et al., 2014; Conover et al.,\n2011b; Fowler et al., 2011; Hasan and Ng, 2014;\nHimelboim et al., 2013; Magdy et al., 2016a,b;\nMakazhanov et al., 2014; Trabelsi and Za \u00a8\u0131ane,\n2018; Weber et al., 2013). User stance classi\ufb01-\ncation is aided by the tendency of users to form\nso-called \u201cecho chambers\u201d, where they engage\nwith like-minded users (Himelboim et al., 2013;\nMagdy et al., 2016a), and the tendency of users\u2019\nbeliefs to be persistent over time (Borge-Holthoefer\net al., 2015; Magdy et al., 2016a; Pennacchiotti and\nPopescu, 2011b).\nStudies have examined the effectiveness of differ-\nent features for stance detection, including textual\nfeatures such as word n-grams and hashtags, net-\nwork interactions such as retweeted accounts and\nmentions, and pro\ufb01le information such as user loca-\ntion (Borge-Holthoefer et al., 2015; Hasan and Ng,\n2013; Magdy et al., 2016a,b; Weber et al., 2013).\nNetwork interaction features were shown to yield\nbetter results compared to using textual features\n(Magdy et al., 2016a; Wong et al., 2013). Srid-\nhar et al. (2015) leveraged both user interactions\nand textual information when modeling stance and\ndisagreement, using a probabilistic programming\nsystem that allows models to be speci\ufb01ed using a\ndeclarative language.\nTrabelsi and Za \u00a8\u0131ane (2018) described an unsu-\npervised stance detection method that determines\nthe viewpoints of comments and of their authors.\nIt analyzes online forum discussion threads, and\ntherefore assumes a certain structure of the posts.\n529It also assumes that users tend to reply to each\nothers\u2019 comments when they are in disagreement,\nwhereas we assume the opposite in this paper. Their\nmodel leverages the posts\u2019 contents, whereas we\nonly use the retweet behavior of users.\nMany methods involving supervised learning\nwere proposed for stance detection. Such meth-\nods require the availability of an initial set of la-\nbeled users, and they use some of the aforemen-\ntioned features for classi\ufb01cation (Darwish et al.,\n2018; Magdy et al., 2016b; Pennacchiotti and\nPopescu, 2011a). Such classi\ufb01cation can label\nusers with precision typically ranging between\n70% and 90% (Rao et al., 2010; Pennacchiotti and\nPopescu, 2011a). Label propagation is a semi-\nsupervised method that starts with a seed list of\nlabeled users and propagates the labels to other\nusers who are similar based on the accounts they\nfollow or retweet (Barber \u00b4a and Sood, 2015; Borge-\nHolthoefer et al., 2015; Weber et al., 2013). While\nlabel propagation may label users with high preci-\nsion (often above 95%), it is biased towards users\nwith more extreme views; moreover, careful choice\nof thresholds is often required, and post-checks are\nneeded to ensure quality.\nAbu-Jbara et al. (2013) and more recently Dar-\nwish et al. (2020) used unsupervised stance de-\ntection, where users are mapped into a lower di-\nmensional space based on user-user similarity, and\nthen clustered to \ufb01nd core sets of users represent-\ning different stances. This was shown to be highly\neffective with nearly perfect clustering accuracy\nfor polarizing topics, and it requires no manual\nlabeling of users. Here, we use the same idea,\nbut we combine it with supervised classi\ufb01cation\nbased on retweets in order to increase the number\nof labeled users (Darwish, 2018). Other methods\nfor user stance detection include collective clas-\nsi\ufb01cation (Duan et al., 2012), where users in a\nnetwork are jointly labeled and classi\ufb01cation in a\nlow-dimensional user-space (Darwish et al., 2017).\nAs for predicting political leaning or sentiment,\nthis problem was studied previously as a super-\nvised learning problem, where a classi\ufb01er learns\nfrom a set of manually labeled tweets (Pla and Hur-\ntado, 2014; Bakliwal et al., 2013; Bermingham and\nSmeaton, 2011). Similarly, V olkova et al. (2014)\npredicted Twitter users\u2019 political af\ufb01liation (being\nRepublican or Democratic), using their network\nconnections and textual information, relying on\nuser-level annotations.3 Data Collection\nWe obtained data on eight topics that are consid-\nered polarizing in the USA (Darwish et al., 2020),\nshown in Table 1.\nThey include a mix of long-standing issues such\nas racism and gun control, temporal issues such as\nthe nomination of Judge Brett Kavanaugh to the US\nSupreme Court and Representative Ilhan Omar\u2019s\npolarizing remarks, as well as non-political issues\nsuch as the potential dangers of vaccines. Further,\nthough long-standing issues typically show right\u2013\nleft polarization, stances towards Omar\u2019s remarks\nare not as clear, with divisions on the left as well.\nSince we are interested in US users, we \ufb01ltered\nsome tweets to retain such by users who have stated\nthat their location was USA. We used a gazetteer\nthat included words that indicate USA as a country\n(e.g., America, US), as well as state names and\ntheir abbreviations (e.g., Maryland, MD).\nOther data that we used in our experiments is a\ncollection of articles that were cited by users from\nthe tweets collection and that originate from media,\nwhose bias is known, i.e., is discussed on the Media\nBias/Fact Check website.\n4 User Stance Detection\nIn order to analyze the stance of in\ufb02uencers on\na given topic, we \ufb01rst \ufb01nd the stances of Twitter\nusers, and then we project them to the in\ufb02uencers\nthat the users cite. A central (initial) assumption\nhere is that if a user includes a link to some arti-\ncle in their tweet, they are more likely to agree or\nendorse the article\u2019s message. Similarly, when a\nuser retweets a tweet verbatim without adding any\ncomments, they are more likely to agree with that\ntweet. We label a large number of users with their\nstance for each topic using a two-step approach,\nnamely projection and clustering andsupervised\nclassi\ufb01cation .\nFor the projection and clustering step, we iden-\ntify clusters of core vocal users using the unsuper-\nvised method described in (Darwish et al., 2020).\nIn this step, users are mapped to a lower dimen-\nsional space based on their similarity, and then they\nare clustered. After performing this unsupervised\nlearning step, we train a supervised classi\ufb01er using\nthe two largest identi\ufb01ed clusters in order to tag\nmany more users. For that, we use FastText, a deep\nneural network text classi\ufb01er, that has been shown\nto be effective for various text classi\ufb01cation tasks\n(Joulin et al., 2017).\n530Topic Keywords Date Range No. of Tweets\nClimate change #greendeal, #environment, #climate, #climatechange, #carbonfootprint, #climatehoax, #cli-\nmategate, #globalwarming, #agw, #renewablesFeb 25\u2013Mar 4, 2019 1,284,902\nGun control/rights #gun, #guns, #weapon, #2a, #gunviolence, #secondamendment, #shooting, #massshooting,\n#gunrights, #GunReformNow, #GunControl, #NRAFeb 25\u2013Mar 3, 2019 1,782,384\nIlhan Omar remarks on\nIsrael lobbyIlhanOmarIsATrojanHorse, #IStandWithIlhan, #ilhan, #Antisemitism, #IlhanOmar, #IlhanMN,\n#RemoveIlhanOmar, #ByeIlhan, #RashidaTlaib, #AIPAC, #EverydayIslamophobia, #Islamo-\nphobia, #ilhanMar 1\u20139, 2019 2,556,871\nIllegal immigration #border, #immigration, #immigrant, #borderwall, #migrant, #migrants, #illegal, #aliens Feb 25\u2013Mar 4, 2019 2,341,316\nMidterm midterm, election, elections Oct 25\u201327, 2018 520,614\nRacism & police brutal-\nity#blacklivesmatter, #bluelivesmatter, #KKK, #racism, #racist, #policebrutality, #excessiveforce,\n#StandYourGround, #ThinBlueLineFeb 25\u2013Mar 3, 2019 2,564,784\nKavanaugh Nomination Kavanaugh, Ford, Supreme, judiciary, Blasey, Grassley, Hatch, Graham, Cornyn, Lee, Cruz,\nSasse, Flake, Crapo, Tillis, Kennedy, Feinstein, Leahy, Durbin, Whitehouse, Klobuchar, Coons,\nBlumenthal, Hirono, Booker, HarrisSept. 28-30, 2018 &\nOct. 6-9, 20182,322,141\nVaccination bene\ufb01ts &\ndangers#antivax, #vaxxing, #BigPharma, #antivaxxers, #measlesoutbreak, #Antivacine, #Vac-\ncinesWork, #vaccine, #vaccines, #Antivaccine, #vaccinestudy, #antivaxx, #provaxx, #Vaccines-\nSaveLives, #ProVaccine, #VaxxWoke, #mykidmychoiceMar 1\u20139, 2019 301,209\nTable 1: Polarizing topics used in study.\nOnce we have expanded our sets of labeled users,\nwe identify in\ufb02uencers that are most closely asso-\nciated with each group using a modi\ufb01ed version of\nthe so-called valence score , which varies in value\nbetween\u00001 and 1. If an in\ufb02uencer is being cited\nevenly between the groups, then it would be as-\nsigned a valence score close to zero. Conversely,\nif one group disproportionately cites an in\ufb02uencer\ncompared to another group, then it would be as-\nsigned a score closer to \u00001 or 1. We perform these\nsteps for each of the given topics, and \ufb01nally we\nsummarize the stances across all topics. Below, we\nexplain each of these steps in more detail.\n4.1 Projection and Clustering\nGiven the tweets for each topic, we compute the\nsimilarity between the top 1,000 most active users.\nTo compute similarity, we construct a vector for\neach user containing the number of all the accounts\nthat a user has retweeted, and then we compute\nthe pairwise cosine similarity between them. For\nexample, if user A has only retweeted user B 3\ntimes, user C 5 times and user E 8 times, then\nuser A\u2019s vector would be (0, 3, 5, 0, 8, 0, 0, ... 0).\nSolely using the retweeted accounts as features has\nbeen shown to be effective for stance classi\ufb01cation\n(Darwish et al., 2020; Magdy et al., 2016a). Fi-\nnally, we perform dimensionality reduction and we\nproject the users using Uniform Manifold Approxi-\nmation and Projection (UMAP). When performing\ndimensionality reduction, UMAP places users on\na two-dimensional plane such that similar users\nare placed closer together and dissimilar users are\npushed further apart. Figure 2 shows the top users\nfor the \u201cmidterm\u201d topic projected with UMAP onto\nthe 2D plane. After the projection, we use Mean\nShift to cluster the users as shown in Figure 2. This\nis the best setup described in (Darwish et al., 2020).\n1.00\n 0.75\n 0.50\n 0.25\n 0.00 0.25 0.50 0.75 1.001.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00\nCluster\nCluster 0\nCluster 1\nNot clusteredFigure 2: Top active users on the midterm topic clus-\ntered using UMAP + Mean Shift.\nClustering high-dimensional data often yields sub-\noptimal results, but can be improved by projecting\nto a low-dimensional space (Darwish et al., 2020).\n4.2 Supervised Classi\ufb01cation\nSince unsupervised stance detection is only able to\nclassify the most vocal users, which only constitute\na minority of the users, we wanted to assign stance\nlabels to as many additional users as we can. Given\nthe clusters of users that we obtain for each topic,\nwe retain the two largest clusters for each topic,\nand we assign cluster labels to the users contained\ntherein. Next, we use all the automatically labeled\nusers for each topic to train a supervised classi-\n\ufb01er using the accounts that each user retweeted\nas features (same as the features we used to com-\npute user similarity earlier). For classi\ufb01cation, we\ntrain a FastText model using the default parameters,\nand then we classify all other users with \ufb01ve or\nmore retweeted accounts, only accepting the classi-\n\ufb01cation if FastText was more than 80% con\ufb01dent\n(70\u201390% yielded nearly identical results).\n531Topic No. of Users Clustered Classi\ufb01ed\nUsers Users\nclimate change 724,470 860 5,851\ngun control 973,206 813 11,281\nIlhan Omar 563,706 723 25,484\nimmigration 940,840 901 22,456\nmidterm elections 312,954 860 12,765\npolice brutality & racism 1,175,081 891 18,978\nKavanaugh 809,835 891 10,100\nvaccine 194,245 545 556\nTable 2: Users per topic: total number of users, umber\nof clustered users, and number of automatically labeled\nusers.\nIn order to obtain a rough estimate of the ac-\ncuracy of the model, we trained FastText using\na random 80% subset of the clustered users for\neach topic and we tested on the remaining 20%.\nThe accuracy was consistently above 95% for all\ntopics. This does not mean that this model can\npredict the stance for all users that accurately \u2014\nthe clustered users were selected to be the most\nactive ones. Rather, it shows that the classi\ufb01er can\nsuccessfully capture what the previous, unsuper-\nvised step has already learned. Table 2 lists the\ntotal number of users who authored the tweets for\neach topic, the number of users who were automat-\nically clustered using the aforementioned unsuper-\nvised clustering technique, and the number of users\nwho were automatically labeled afterwards using\nsupervised classi\ufb01cation. Given that we applied\nunsupervised stance detection to the most active\n1,000 users, the majority of the users appeared in\nthe largest two clusters (shown in Table 2).\n4.3 Calculating Valence Scores\nGiven all the labeled users for each topic, we com-\nputed a valence score for each in\ufb02uencer. As\nmentioned earlier, the valence score ranges be-\ntween [\u00001;1], where a value close to 1 implies\nit is strongly associated with one group of users,\n\u00001 shows it is strongly associated with the other\ngroup of users, and 0 means that it is being shared\nor cited by both groups. The original valence score\ndescribed by Conover et al. (2011a) is calculated\nas follows:\nV(u) =2t f(u;C0)\ntotal(C0)\nt f(u;C0)\ntotal(C0)+t f(u;C1)\ntotal(C1)\u00001 (1)\nwhere t f(u;C0)is the number of times (term fre-\nquency) item uis cited by group C0, and total(C0)\nis the sum of the term frequencies of all items cited\nbyC0.t f(u;C1)andtotal(C1)are de\ufb01ned in a sim-\nilar fashion.We use the above equation to compute valence\nscores for the retweeted accounts, but we using\na modi\ufb01ed version for calculating the score for\nin\ufb02uencers ( I):\nV(I) =2t f(I;C0)\ntotal(C0)\nt f(I;C0)\ntotal(C0)+t f(I;C1)\ntotal(C1)\u00001 (2)\nwhere\nt f(I;Ci) =\u00e5a2ITCi[ln(Cnt(a;Ci))+1]\ntotal(Ci) =\u00e5It f(I;Ci)\nIn the latter equation, Cnt(a;Ci)is the number\nof times article awas cited by users from cluster Ci.\nIn essence, we are replacing term frequencies with\nthe natural log of the term frequencies. We opted to\nmodify the equation in order to tackle the following\nissue: if users from one of the clusters, say C1, cite\nonly one single article from some media source a\nlarge number of times (e.g., 2,000 times), while\nusers from the other cluster ( C0) cite 10 other arti-\ncles from the same media 50 times each, then using\nequation 1 would result in a valence score of \u00000.6.\nWe would then regard the given media as having\nan opposing stance to the stance of users in C0. Al-\nternatively, using the natural log would lead to a\nvalence score close to 0.88. Thus, dampening term\nfrequencies using the natural log has the desired\neffect of balancing between the number of articles\nbeing cited by each group and the total number of\ncitations. We bin the valence scores between \u00001\nand 1 into \ufb01ve equal size bands as follows:\nCat(V) =8\n>>>>>><\n>>>>>>:\u0000\u0000 ;ifs2[\u00001;\u00000:6)\n\u0000; ifs2[\u00000:6;\u00000:2)\n0; ifs2[\u00000:2;0:2)\n+; ifs2[0:2;0:6)\n++ ;ifs2[0:6;1](3)\n5 Characterizing the In\ufb02uencers\nWe use valence to characterize the leaning of all\ncited in\ufb02uencers for each of the topics. Table 3\nshows the valence categories for the top-cited me-\ndia sources across all topics. It also shows each\nmedia\u2019s factuality of reporting, i.e., trustworthiness,\nand bias (ranging from far-left to far-right) as de-\ntermined by mediaBiasFactCheck.com . Since the\nchoice of which cluster should be C0and which\nwould be C1is arbitrary, we can multiply by \u00001\nthe valence scores for any topic and the meaning\nof the results would stay the same.\n532\nEXTREME-LEFT\nLEFT\nLEFT-CENTER\nCENTER\nRIGHT-CENTER\nRIGHT\nEXTREME-RIGHT\nBias-- - 0 + ++Valence Category0 3 24 18 31 110 58\n0 2 8 3 8 9 3\n0 4 25 13 20 4 0\n0 14 45 21 14 2 0\n3 101 148 70 36 6 3\n020406080100120140Figure 3: Valence category vs. bias: number of media.\nWe resorted to doing so for some topics in order\nto align the extreme valence bands across all topics.\nGiven tweet samples from users in a given cluster\nfor a given topic, labeling that cluster manually was\nstraightforward with almost no ambiguity. Table 4\nshows the most frequently cited media source for\neach topic and for each valence band.\nOf the 5,406 unique media sources that have\nbeen cited in tweets across all topics, 806 have\nknown political bias from mediaBiasFactCheck.\ncom. Figure 3 shows the confusion matrix between\nour valence categories and the goold labels from\nmediaBiasFactCheck.com .\nWe notice that many of the media that have a\nnegative valence score (categories \u0000and\u0000\u0000) are\nclassi\ufb01ed on the right side of the political spec-\ntrum by mediaBiasFactCheck.com , while most\nmedia with positive scores (categories +and++)\nare classi\ufb01ed as slightly left-leaning. Although\nthere are almost no extreme-left cases, there is a\ncorrelation between bias and our valence score.\nmediaBiasFactCheck.com seems to rarely catego-\nrize media sources as \u201cextreme-left\u201d. This could\nbe a re\ufb02ection of reality or it might imply that\nmediaBiasFactCheck.com has an inherent bias.\nWe also computed the valence scores for the\ntop-200 retweeted accounts, and we assigned each\naccount a valence category based on the score. In-\ndependently, we asked a person who is well-versed\nwith US politics to label all the accounts as left, cen-\nter, or right. When labeling accounts, right-leaning\ninclude those expressing support for Trump, the\nRepublican party, and gun rights, opposition to\nabortion, and disdain for Democrats.\n1.00\n 0.75\n 0.50\n 0.25\n 0.00 0.25 0.50 0.75 1.00Figure 4: The top-200 retweeted accounts, projected on\na number line according to their average valence.\nAs for left-leaning accounts, they include those\nattacking Trump and the Republicans, and ex-\npressing support for the Democratic party and\nfor Liberal social positions. If the retweeted ac-\ncount happens to be a media source, we used\nmediaBiasFactCheck.com . Table 5 compares the\nper-topic valence for each retweeted account along\nwith the average category and the true label.\nIt is noteworthy that all top-200 retweeted ac-\ncounts have extreme valence categories on average\nacross all topics. Their average valence scores, with\none exception, appear between \u00000.6 and\u00001.00 for\nright, and between 0.6 and 1 for left (see Figure 4).\nOf those manually and independently tagged ac-\ncounts, all that were tagged as left-leaning have\na strong positive valence score and all that were\ntagged as right-leaning have a strong negative va-\nlence score. Only two accounts were manually la-\nbeled as center , namely Reuters and CSPAN, which\nis a US channel that broadcasts Federal Govern-\nment proceedings, and they had valence scores of\n0.55 and 0.28, respectively. Though their absolute\nvalues are lower than those of all other sources,\nthey are mapped to the +valence category.\nTable 3 summarizes the valence scores for the\nmedia across all topics. Table 4 lists the most cited\nmedia sources for each topic and for each of the\n\ufb01ve valence bands. The order of the bands from\ntop to bottom is: ++,+,0,\u0000and\u0000\u0000. The table\nalso includes the credibility and the political lean-\ning tags from mediaBiasFactCheck.com . The key\nobservations from the table as follows:\n1.Most right-leaning media appear overwhelm-\ningly in the\u0000and\u0000\u0000valence categories. Con-\nversely, left-leaning media appear in all valence\ncategories, except for the \u0000\u0000 category. This\nimplies that left-leaning users cite right-leaning\nmedia sparingly. We looked at some instances\nwhere right-leaning users cited left-leaning me-\ndia, and we found that in many cases the cited\narticles reinforced a right-leaning viewpoint. For\nexample, right-leaning users shared a video from\nthehill.com , a left-center site, 2,398 times for the\npolice racism topic. The video defended Trump\nagainst charges of racism by Lynne Patton, a long-\ntime African-American associate of Trump.\n533Medium\nfactuality\nbias\nAverage\nclimate change\ngun control\nilhan\nimmigration\nmidterm\npolice & racism\nKavanaugh\nvaccine\nthehill.com H L-C +++ 0 ++ + + + + ++ ++\ntheguardian.com H L-C ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nwashingtonpost.com H L-C ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nbreitbart.com VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nfoxnews.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnytimes.com H L-C ++++++ + ++ + + + ++ ++ ++\ncnn.com M L +++ + ++ + ++ + + ++ +\napple.news +++ 0 0 + 0 0 + + ++\ndailycaller.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nrawstory.com M L ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nhuf\ufb01ngtonpost.com H L ++++++ ++ ++ ++ ++ + ++ ++ ++\ntruepundit.com L \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnbcnews.com H L-C +++\u0000\u0000 ++ + ++ + + ++ ++\nwesternjournal.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nreuters.com VH C +++ + ++ ++ + + + + ++\nwashingtonexaminer.com H R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\nthegatewaypundit.com VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\npolitico.com H L-C +++ + + + + ++ + + ++\nnpr.org VH L-C +++ 0 ++ ++ ++ 0 ++ ++ ++\ntownhall.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nmsn.com H L-C +++ + + + 0 ++ 0 ++ 0\nnypost.com M R-C\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000 +\u0000\u0000\u0000\nvox.com H L ++++++ ++ ++ ++ ++ ++ + ++ ++\nthedailybeast.com H L ++++++ ++ ++ + ++ ++ + ++ ++\nbbc.com H L-C +++ + + ++ ++ 0 + + ++\nindependent.co.uk H L-C ++++++ ++ + ++ ++ ++ + ++ ++\nilovemyfreedom.org VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nthinkprogress.org M L ++++++ ++ ++ ++ ++ ++ ++ ++ ++\ndailywire.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 ++\npscp.tv \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000 0\u0000\ndailymail.co.uk VL R\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nmsnbc.com M L ++++++ ++ ++ ++ ++ + ++ ++\ndailykos.com M L ++++++ ++ ++ ++ ++ + ++ ++\nbloomberg.com H L-C +++ + ++ 0 ++ + 0 + ++\nusatoday.com H L-C +++ + + 0 + ++ + 0 +\nTable 3: Media valence categories for each topic with included average column. Plus ( +) and minus (\u0000) signify\nleft or right leaning, respectively. Factuality: Very High (VH), High (H), Mixed (M), Low (L), Very Low (VL).\nBias: Left (L), Left-Center (L-C), Center (C), Right-Center (R-C), Right (R), Far Right (Far R). Blank cells mean\nthat we did not have information.\n2.Most right-leaning sources in the \u0000\u0000cate-\ngory have mixed, low, or very low factuality. Con-\nversely, most left-leaning sites appearing in the \u0000\nvalence category have high or very high factuality.\nSimilarly for the vaccine topic, where high credi-\nbility sources, such as fda.gov andnih.gov , are\nfrequently cited by anti-vaccine users, mostly to\nsupport their beliefs.\n3.The placements of sources in different cate-\ngories are relatively stable across topics. For exam-\nple,washingtonPost.com andtheguardian.com\nexclusively appear in the ++ category, while\nbreitbart.com andfoxnews.com consistently ap-\npear in the\u0000\u0000category.\n6 Predicting Media Bias\nGiven the stances of users on the aforementioned\neight topics, we leverage this information to predict\nmedia bias. Speci\ufb01cally, we describe in this section\nhow we make use of the valence scores, as well\nas other features, namely graph and contextualized\ntext embeddings, to train supervised classi\ufb01ers for\nthis purpose.Valence Scores. We use valence scores in two\nways. First, we average the corresponding va-\nlence across the different polarizing topics to ob-\ntain an average valence score for a given target\nnews medium. This is an unsupervised method\nfor computing polarity. Second, we train a Logis-\ntic Regression classi\ufb01er that uses the calculated\nvalence scores as features and annotations from\nmediaBiasFactCheck.com as gold target labels in\norder to predict the general political leaning of a tar-\nget news medium. We merged \u201cleft\u201d and \u201cextreme\nleft\u201d, and similarly we merged \u201cright\u201d and \u201cextreme\nright\u201d. We discarded media labeled as being \u201cleft-\ncenter\u201d and \u201cright-center\u201d. Each news medium was\nrepresented by an 8-dimensional vector containing\nthe valence scores for the above topics. In the ex-\nperiments, we used the lbfgs solver and C=0:1.\nWe used two measures to evaluate its performance,\nnamely accuracy and mean absolute error (MAE).\nThe latter is calculated by considering the different\nclasses as ordered and equally distant from each\nother, i.e., if the model predicts right and the true\nlabel is left, this amounts to an error equal to 2.\n534climate change gun control Ilhan Omar immigration\ntheguardian.com H L-C thehill.com H L-C washingtonpost.com H L-C theguardian.com H L-C\nwashingtonpost.com H L-C cnn.com M L theguardian.com H L-C washingtonpost.com H L-C\nindependent.co.uk H L-C nytimes.com H L-C mondoweiss.net H L cnn.com M L\nwef.ch npr.org VH L-C thinkprogress.org M L huf\ufb01ngtonpost.com H L\nvox.com H L washingtonpost.com H L-C haaretz.com H L-C npr.org VH L-C\nnytimes.com H L-C politico.com H L-C nytimes.com H L-C thehill.com H L-C\nbbc.com H L-C usatoday.com H L-C thehill.com H L-C nytimes.com H L-C\ncnn.com M L msn.com H L-C politico.com H L-C reuters.com VH C\nreuters.com VH C bbc.com H L-C cnn.com M L politico.com H L-C\nbloomberg.com H L-C cnbc.com H L-C apple.news usatoday.com H L-C\nthehill.com H L-C apple.news mediaite.com H L apple.news\napple.news sun-sentinel.com H R-C usatoday.com H L-C msn.com H L-C\nnpr.org VH L-C nypost.com M R-C yahoo.com M L-C pscp.tv\nseattletimes.com H L-C dailymail.co.uk VL R timeso\ufb01srael.com H L-C whitehouse.gov M R\nnewsweek.com M L mailchi.mp theatlantic.com H L-C texastribune.org H C\nchange.org H L washingtontimes.com H R-C nypost.com M R-C dailymail.co.uk VL R\nlatimes.com H L-C breaking911.com VL jpost.com H C nypost.com M R-C\ndailymail.co.uk VL R chicagotribune.com H R-C dailymail.co.uk VL R zerohedge.com M\nclimatechangedispatch.com rt.com M R-C algemeiner.com H R-C ir.shareaholic.com\ncnbc.com H L-C forbes.com M R-C startribune.com H L-C breaking911.com VL\nforbes.com M R-C breitbart.com VL Far R foxnews.com M R breitbart.com VL Far R\nbreitbart.com VL Far R foxnews.com M R breitbart.com VL Far R illegalaliencrimereport.com\ndailycaller.com M R ammoland.com H R townhall.com M R washingtonexaminer.com H R\ntambonthongchai.com dailycaller.com M R change.org H L foxnews.com M R\nwattsupwiththat.com L bearingarms.com M R hannity.com westernjournal.com M R\nmidterm police & racism Kavanaugh vaccine\nwashingtonpost.com H L-C washingtonpost.com H L-C thehill.com H L-C thehill.com H L-C\ntheguardian.com H L-C rawstory.com M L washingtonpost.com H L-C theguardian.com H L-C\nrawstory.com M L huf\ufb01ngtonpost.com H L cnn.com M L washingtonpost.com H L-C\ntacticalinvestor.com theguardian.com H L-C nytimes.com H L-C vaxopedia.org\nvox.com H L nytimes.com H L-C huf\ufb01ngtonpost.com H L nytimes.com H L-C\nthehill.com H L-C thehill.com H L-C politico.com H L-C cnn.com M L\nreuters.com VH C apple.news apple.news statnews.com H C\nnytimes.com H L-C cnn.com M L yahoo.com M L-C latimes.com H L-C\ncnn.com M L nbcnews.com H L-C apnews.com VH C cbc.ca H L-C\ndailykos.com M L thedailybeast.com H L latimes.com H L-C usatoday.com H L-C\napple.news msn.com H L-C usatoday.com H L-C cdc.gov VH\nsagagist.com.ng pscp.tv mediaite.com H L medium.com M L-C\nbbc.com H L-C bloomberg.com H L-C theweek.com H L-C newsroom.fb.com\nalzwaaj.com politics.theonion.com lawandcrime.com help.senate.gov\nwashingtonexaminer.com H R rollcall.com VH C cnbc.com H L-C msn.com H L-C\ndailymail.co.uk VL R mediaite.com H L pscp.tv change.org H L\npbs.org H L-C dailymail.co.uk VL R nypost.com M R-C fda.gov\nzerohedge.com M news.sky.com H L-C ir.shareaholic.com variety.com\najc.com H L-C newsone.com H L-C rollcall.com VH C\nveritablenouvelordre.forumcanada.org aol.com H L-C c-span.org VH C\nbreitbart.com VL Far R breitbart.com VL Far R foxnews.com M R ncbi.nlm.nih.gov VH\nfoxnews.com M R defensemaven.io truepundit.com L vaccineimpact.com\ndailycaller.com M R foxnews.com M R dailycaller.com M R naturalnews.com M\nilovemyfreedom.org VL Far R thegatewaypundit.com VL Far R breitbart.com VL Far R vaccines.me\nwesternjournal.com M R nypost.com M R-C thegatewaypundit.com VL Far R thevaccinereaction.org\nTable 4: Top 5 websites per valence category for each topic.\nAccount\nTruth\nAverage\nclimate change\ngun control\nilhan\nimmigration\nmidterm\npolice & racism\nKavanaugh\nvaccine\nrealdonaldtrump R\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ncharliekirk11 R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkylegrif\ufb01n1 L ++++++ ++ ++ ++ ++ ++ ++ ++\ndbongino R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkamalaharris L ++++++ ++ ++ ++ ++ ++ ++\nmitchellvii R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nrealsaavedra R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkrassenstein L ++++++ ++ ++ ++ ++ ++ ++ ++\nrealjack R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnbcnews L ++++++ ++ ++ + ++ ++ ++ ++ ++\neducation4libs R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnra R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ndonaldjtrumpjr R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nshannonrwatts L ++++++ ++ ++ ++ ++ ++\nthehill L ++++++ ++ ++ + ++ + + ++ ++\nrealjameswoods R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ngopchairwoman R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\njackposobiec R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nfunder L ++++++ ++ ++ ++ ++ ++ ++ ++\ncnn L ++++++ ++ ++ ++ ++ 0 ++ ++ ++\najplus L ++++++ ++ ++ ++ ++ ++ ++ 0 ++\nrashidatlaib L ++++++ ++ ++ ++ ++ +\nstevescalise R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\njordan sather ?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\naoc L ++++++ ++ ++ ++ ++\nTable 5: User valence categories for each topic, preceded by an average column, and a ground truth label. When a\ncell is blank, there is insuf\ufb01cient data for that particular topic.\n535No Valence With Valence\nAcc MAE Acc MAE\nBaseline 1 (majority class) 43.3 .856 43.3 .856\nBaseline 2 (average valence) \u2013 \u2013 68.0 .330\nValence scores \u2013 \u2013 75.2 .278\nBERT (article title) 60.6 .539 78.3 .264\nBERT (article content) 61.1 .526 79.2 .255\nBERT (title+content) 62.2 .510 80.8 .228\nBERT(Tweet) 64.0 .485 73.6 .302\nGraphEmbM 63.5 .468 69.1 .380\nGraphEmbH 66.9 .425 71.8 .347\nGraphEmbM+H 68.0 .400 79.0 .251\nGraphEmbM+H+BERT (tweet) 72.5 .358 80.5 .230\nGraphEmbM+H+BERT (tweet, content) 76.1 .311 81.2 .221\nGraphM+H+BERT (tweet, title, content) 78.1 .284 82.6 .206\nTable 6: Predicting media bias.\nThe results are shown in Table 6, where we can\nsee that using the average valence score yields\n68.0% accuracy (0.330 MAE) compared to 75.2%\naccuracy (0.278 MAE) when using the eight indi-\nvidual valence scores as features.\nGraph embeddings. We further use graph em-\nbeddings, generated by building a User-to-Hashtag\ngraph (U2H) and a User-to-Mention (U2M) graph\nand then running node2vec on both (Atanasov et al.,\n2019), producing two types of graph embeddings.\nWhen using graph embeddings, we got worse re-\nsults compared to our previous setup with valence\nscores (see Table 6). However, when we combine\nthem with the valence scores, we observe a sizable\nboost in performance, up to 11% absolute.\nTweets. We also experimented with BERT-base.\nWe used the text of the tweets that cite the me-\ndia we are classifying. For classi\ufb01cation, we fed\nBERT representations of tweets to a dense layer\nwith softmax output to \ufb01ne-tune it with the textual\ncontents of the tweets. We trained at the tweet level,\nand we averaged the scores (from softmax) for all\ntweets from the same news medium to obtain an\noverall label for that news medium. The accuracy\nis much lower than for the valence scores: 64.0%\naccuracy vs. 75.2% for supervised and 68.0% for\nunsupervised.\nArticle titles and text. Using the BERT setup\nforTweets , we used the titles and the full text of\nup to 100 articles from each of the target media.\nWhen using the full text of articles, we balanced the\nnumber of articles per news medium. We trained\ntwo separate BERT models, one on the titles and\nanother one on the full text (content). Both models\ndid worse than using valence alone, but the combi-\nnation improved over valence only.System Combination. We combined different\nsetups including using all the aforementioned mod-\nels in combination. Using graph embeddings\n(GraphH + GraphM) with BERT embeddings\n(Tweet+Title+Content) and valence yielded the\nbest results with accuracy of 82.6% and MAE of\n.206. If we remove valence from the combination,\nthe accuracy drops by 4.5% while MAE jumps by\n.078, absolute. This suggests that valence is a very\neffective feature that captures important informa-\ntion, complementary to what can be modeled using\ngraph and contextualized text embeddings.\n7 Conclusion and Future Work\nWe have presented a method for predicting the gen-\neral political leaning of media sources and popular\nTwitter users, as well as their stances on speci\ufb01c\npolarizing topics. Our method uses retweeted ac-\ncounts, and a combination of dimensionality reduc-\ntion and clustering algorithms, namely UMAP and\nMean Shift, in order to produce sets of users that\nhave opposing opinions on speci\ufb01c topics. Next,\nwe expand the discovered sets using supervised\nlearning that is trained on the automatically discov-\nered user clusters. We are able to automatically\ntag large sets of users according to their stance of\npreset topics. Users\u2019 stances are then projected to\nthe in\ufb02uencers that are being cited in the tweets for\neach of the topics using the so-called valence score .\nThe projection allows us to tag a large number of\nin\ufb02uencers with their stances on speci\ufb01c issues and\nwith their political leaning in general (i.e., leftvs.\nright ) with high accuracy and with minimal human\neffort. The main advantage of our method is that it\ndoes not require manual labeling of entity stances,\nwhich requires both topical expertise and time. We\nalso investigated the quality of the valence features,\nand we found that valence scores help to predict\nmedia bias with high accuracy.\nIn future work, we plan to increase the number\nof topics that we use to characterize media. Ideally,\nwe would like to automatically identify such polar-\nizing topics. Doing so would enable us to easily\nretarget this work to new countries and languages.\nAcknowledgments\nThis research is part of the Tanbih project1, which\naims to limit the effect of \u201cfake news,\u201d propaganda\nand media bias by making users aware of what they\nare reading.\n1http://tanbih.qcri.org/\n536References\nAmjad Abu-Jbara, Ben King, Mona Diab, and\nDragomir Radev. 2013. Identifying opinion sub-\ngroups in Arabic online discussions. In Proceed-\nings of the 51st Annual Meeting of the Association\nfor Computational Linguistics , ACL \u201913, pages 829\u2013\n835, So\ufb01a, Bulgaria.\nJisun An, Meeyoung Cha, Krishna Gummadi, Jon\nCrowcroft, and Daniele Quercia. 2012. Visualizing\nmedia bias through Twitter. In Proceedings of the\nInternational AAAI Conference on Web and Social\nMedia , Dublin, Ireland, pages 2\u20135.\nAtanas Atanasov, Gianmarco De Francisci Morales,\nand Preslav Nakov. 2019. Predicting the role of po-\nlitical trolls in social media. In Proceedings of the\n2019 SIGNLL Conference on Computational Natu-\nral Language Learning , CoNLL \u201919, pages 1023\u2013\n1034, Hong Kong, China.\nAkshat Bakliwal, Jennifer Foster, Jennifer van der Puil,\nRon O\u2019Brien, Lamia Tounsi, and Mark Hughes.\n2013. Sentiment analysis of political tweets: To-\nwards an accurate classi\ufb01er. In Proceedings of the\nWorkshop on Language Analysis in Social Media ,\npages 49\u201358, Atlanta, GA, USA.\nPablo Barber \u00b4a. 2015. Birds of the same feather tweet\ntogether: Bayesian ideal point estimation using Twit-\nter data. Political Analysis , 23(1):76\u201391.\nPablo Barber \u00b4a and Gaurav Sood. 2015. Follow your\nideology: Measuring media ideology on social net-\nworks. In Proceedings of the Annual Meeting of\nthe European Political Science Association , Vienna,\nAustria.\nPablo Barber and Gonzalo Rivero. 2015. Understand-\ning the political representativeness of Twitter users.\nSocial Science Computer Review , 33(6):712\u2013729.\nAdam Bermingham and Alan Smeaton. 2011. On us-\ning Twitter to monitor political sentiment and pre-\ndict election results. In Proceedings of the Workshop\non Sentiment Analysis where AI meets Psychology ,\nSAAIP \u201911, pages 2\u201310, Chiang Mai, Thailand.\nJavier Borge-Holthoefer, Walid Magdy, Kareem Dar-\nwish, and Ingmar Weber. 2015. Content and net-\nwork dynamics behind Egyptian political polariza-\ntion on Twitter. In Proceedings of the 18th ACM\nConference on Computer Supported Cooperative\nWork & Social Computing , CSCW \u201915, pages 700\u2013\n711, Vancouver, BC, Canada.\nRaviv Cohen and Derek Ruths. 2013. Classifying po-\nlitical orientation on Twitter: It\u2019s not easy! In Pro-\nceedings of the 7th International AAAI Conference\non Weblogs and Social Media , ICWSM \u201913, pages\n91\u201399, Cambridge, MA, USA.Elanor Colleoni, Alessandro Rozza, and Adam Arvids-\nson. 2014. Echo chamber or public sphere? Predict-\ning political orientation and measuring political ho-\nmophily in Twitter using big data. Journal of Com-\nmunication , 64(2):317\u2013332.\nMichael Conover, Jacob Ratkiewicz, Matthew R Fran-\ncisco, Bruno Gonc \u00b8alves, Filippo Menczer, and\nAlessandro Flammini. 2011a. Political polarization\non Twitter. In Proceedings of the Fifth Interna-\ntional AAAI Conference on Weblogs and Social Me-\ndia, ICWSM \u201911, pages 89\u201396, Barcelona, Spain.\nMichael D Conover, Bruno Gonc \u00b8alves, Jacob\nRatkiewicz, Alessandro Flammini, and Filippo\nMenczer. 2011b. Predicting the political alignment\nof Twitter users. In Proceedings of the 2011 IEEE\nThird International Conference on Privacy, Security,\nRisk and Trust (PASSAT) and 2011 IEEE Third\nInernational Conference on Social Computing\n(SocialCom) , pages 192\u2013199, Boston, MA, USA.\nKareem Darwish. 2018. To Kavanaugh or not to Ka-\nvanaugh: That is the polarizing question. arXiv\npreprint arXiv:1810.06687 .\nKareem Darwish, Michael Aupetit, Peter Stefanov, and\nPreslav Nakov. 2020. Unsupervised user stance de-\ntection on Twitter. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nICWSM \u201920, Atlanta, GA, USA.\nKareem Darwish, Walid Magdy, Afshin Rahimi, Tim-\nothy Baldwin, and Norah Abokhodair. 2018. Pre-\ndicting online islamophobic behavior after #ParisAt-\ntacks. The Journal of Web Science , 4(3):34\u201352.\nKareem Darwish, Walid Magdy, and Tahar Zanouda.\n2017. Improved stance prediction in a user sim-\nilarity feature space. In Proceedings of the 2017\nIEEE/ACM International Conference on Advances\nin Social Networks Analysis and Mining 2017 ,\nASONAM \u201917, pages 145\u2013148, Sydney, Australia.\nYajuan Duan, Furu Wei, Ming Zhou, and Heung-Yeung\nShum. 2012. Graph-based collective classi\ufb01cation\nfor tweets. In Proceedings of the 21st ACM Inter-\nnational Conference on Information and Knowledge\nManagement , CIKM \u201912, pages 2323\u20132326, Maui,\nHI, USA.\nJames H Fowler, Michael T Heaney, David W Nick-\nerson, John F Padgett, and Betsy Sinclair. 2011.\nCausality in political networks. American Politics\nResearch , 39(2):437\u2013480.\nMatthew Gentzkow and Jesse M Shapiro. 2011. Ide-\nological segregation online and of\ufb02ine. The Quar-\nterly Journal of Economics , 126(4):1799\u20131839.\nTim Groseclose and Jeffrey Milyo. 2005. A measure\nof media bias. The Quarterly Journal of Economics ,\n120(4):1191\u20131237.\n537Kazi Saidul Hasan and Vincent Ng. 2013. Stance clas-\nsi\ufb01cation of ideological debates: Data, models, fea-\ntures, and constraints. In Proceedings of the Sixth In-\nternational Joint Conference on Natural Language\nProcessing , IJCNLP \u201913, pages 1348\u20131356, Nagoya,\nJapan.\nKazi Saidul Hasan and Vincent Ng. 2014. Why are\nyou taking this stance? Identifying and classifying\nreasons in ideological debates. In Proceedings of the\n2014 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201914, pages 751\u2013762,\nDoha, Qatar.\nItai Himelboim, Stephen McCreery, and Marc Smith.\n2013. Birds of a feather tweet together: Integrat-\ning network and content analyses to examine cross-\nideology exposure on Twitter. Journal of Computer-\nMediated Communication , 18(2):40\u201360.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for ef\ufb01cient text\nclassi\ufb01cation. In Proceedings of the 15th Confer-\nence of the European Chapter of the Association for\nComputational Linguistics , EACL \u201917, pages 427\u2013\n431, Valencia, Spain.\nWalid Magdy, Kareem Darwish, Norah Abokhodair,\nAfshin Rahimi, and Timothy Baldwin. 2016a. #isi-\nsisnotislam or #deportallmuslims?: Predicting un-\nspoken views. In Proceedings of the 8th ACM Con-\nference on Web Science , WebSci \u201916, pages 95\u2013106,\nHannover, Germany.\nWalid Magdy, Kareem Darwish, and Ingmar Weber.\n2016b. #FailedRevolutions: Using Twitter to study\nthe antecedents of ISIS support. First Monday ,\n21(2).\nAibek Makazhanov, Davood Ra\ufb01ei, and Muhammad\nWaqar. 2014. Predicting political preference of Twit-\nter users. Social Network Analysis and Mining ,\n4(1):1\u201315.\nSaif Mohammad, Svetlana Kiritchenko, Parinaz Sob-\nhani, Xiaodan Zhu, and Colin Cherry. 2016.\nSemEval-2016 task 6: Detecting stance in tweets.\nInProceedings of the 10th International Workshop\non Semantic Evaluation , SemEval \u201916, pages 31\u201341,\nSan Diego, CA, USA.\nJonathan Scott Morgan, Cliff Lampe, and Muham-\nmad Zubair Sha\ufb01q. 2013. Is news sharing on Twit-\nter ideologically biased? In Proceedings of the\n2013 Conference on Computer Supported Coopera-\ntive Work , CSCW 13, pages 887\u2013896, San Antonio,\nTX, USA.\nMarco Pennacchiotti and Ana-Maria Popescu. 2011a.\nDemocrats, Republicans and Starbucks af\ufb01cionados:\nuser classi\ufb01cation in Twitter. In Proceedings of\nthe 17th ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining , KDD 11,\npages 430\u2013438, San Diego, CA, USA.Marco Pennacchiotti and Ana-Maria Popescu. 2011b.\nA machine learning approach to Twitter user classi-\n\ufb01cation. In Proceedings of the Fifth International\nAAAI Conference on Weblogs and Social Media ,\nICWSM \u201911, pages 281\u2013288, Barcelona, Spain.\nFerran Pla and Llu \u00b4\u0131s-F. Hurtado. 2014. Political ten-\ndency identi\ufb01cation in Twitter using sentiment anal-\nysis techniques. In Proceedings of the 25th Inter-\nnational Conference on Computational Linguistics ,\nCOLING \u201914, pages 183\u2013192, Dublin, Ireland.\nDelip Rao, David Yarowsky, Abhishek Shreevats, and\nManaswi Gupta. 2010. Classifying latent user at-\ntributes in Twitter. In Proceedings of the 2nd In-\nternational Workshop on Search and Mining User-\nGenerated Contents , SMUC \u201910, pages 37\u201344,\nToronto, ON, Canada.\nFilipe N Ribeiro, Lucas Henrique, Fabricio Ben-\nevenuto, Abhijnan Chakraborty, Juhi Kulshrestha,\nMahmoudreza Babaei, and Krishna P Gummadi.\n2018. Media bias monitor: Quantifying biases of\nsocial media news outlets at large-scale. In Proceed-\nings of the Twelfth International AAAI Conference\non Web and Social Media , ICWSM \u201918, pages 290\u2013\n299, Stanford, CA, USA.\nDhanya Sridhar, James Foulds, Bert Huang, Lise\nGetoor, and Marilyn Walker. 2015. Joint models of\ndisagreement and stance in online debate. In Pro-\nceedings of the 53rd Annual Meeting of the Associa-\ntion for Computational Linguistics and the 7th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing , AXLL-IJCNLP \u201915, pages 116\u2013125, Bei-\njing, China.\nAmine Trabelsi and Osmar R Za \u00a8\u0131ane. 2018. Unsuper-\nvised model for topic viewpoint discovery in online\ndebates leveraging author interactions. In Proceed-\nings of the Twelfth International AAAI Conference\non Web and Social Media , ICWSM \u201918, pages 425\u2013\n433, Stanford, CA, USA.\nSvitlana V olkova, Glen Coppersmith, and Benjamin\nVan Durme. 2014. Inferring user political prefer-\nences from streaming communications. In Proceed-\nings of the 52nd Annual Meeting of the Association\nfor Computational Linguistics , ACL \u201914, pages 186\u2013\n196, Baltimore, MD, USA.\nIngmar Weber, Venkata R. Kiran Garimella, and\nAlaa Batayneh. 2013. Secular vs. Islamist polar-\nization in Egypt on Twitter. In Proceedings of\nthe 2013 IEEE/ACM International Conference on\nAdvances in Social Networks Analysis and Min-\ning, ASONAM \u201913, pages 290\u2013297, Niagara, ON,\nCanada.\nFelix Ming Fai Wong, Chee Wei Tan, Soumya Sen, and\nMung Chiang. 2013. Quantifying political leaning\nfrom tweets and retweets. In Proceedings of the Sev-\nenth International AAAI Conference on Weblogs and\nSocial Media , ICWSM \u201913, pages 640\u2013649, Boston,\nMA, USA.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Predicting the topical stance and political leaning of media using tweets", "author": ["P Stefanov", "K Darwish", "A Atanasov"], "pub_year": "2020", "venue": "Proceedings of the 58th \u2026", "abstract": "Discovering the stances of media outlets and influential people on current, debatable topics  is important for social statisticians and policy makers. Many supervised solutions exist for"}, "filled": false, "gsrank": 54, "pub_url": "https://aclanthology.org/2020.acl-main.50/", "author_id": ["9x-z3YUAAAAJ", "y7tlR6UAAAAJ", "bmKeP4UAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:tn1ZRRXkSD4J:scholar.google.com/&output=cite&scirp=53&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D50%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=tn1ZRRXkSD4J&ei=DbWsaIjTFLTWieoP1pCJ2AY&json=", "num_citations": 127, "citedby_url": "/scholar?cites=4488087808683638198&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:tn1ZRRXkSD4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2020.acl-main.50.pdf"}}, {"title": "Influence of fake news in Twitter during the 2016 US presidential election", "year": "2019", "pdf_data": "ARTICLE\nIn\ufb02uence of fake news in Twitter during the 2016\nUS presidential election\nAlexandre Bovet1,2,3& Hern\u00e1n A. Makse1\nThe dynamics and in \ufb02uence of fake news on Twitter during the 2016 US presidential election\nremains to be clari \ufb01ed. Here, we use a dataset of 171 million tweets in the \ufb01ve months\npreceding the election day to identify 30 million tweets, from 2.2 million users, which containa link to news outlets. Based on a classi \ufb01cation of news outlets curated by www.opensources.\nco,w e \ufb01nd that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information \ufb02ow to \ufb01nd the most in \ufb02uential spreaders of fake\nand traditional news and use causal modeling to uncover how fake news in \ufb02uenced the\npresidential election. We \ufb01nd that, while top in \ufb02uencers spreading traditional center and left\nleaning news largely in \ufb02uence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters in \ufb02uences the dynamics of the top fake news\nspreaders.https://doi.org/10.1038/s41467-018-07761-2 OPEN\n1Levich Institute and Physics Department, City College of New York, New York, NY 10031, USA.2ICTEAM, Universit\u00e9 Catholique de Louvain, Avenue George\nLema\u00eetre 4, 1348 Louvain-la-Neuve, Belgium.3naXys and Department of Mathematics, Universit\u00e9 de Namur, Rempart de la Vierge 8, 5000 Namur, Belgium.\nCorrespondence and requests for materials should be addressed to H.A.M. (email: hmakse@ccny.cuny.edu )\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 11234567890():,;\nRecent social and political events, such as the 2016 US\npresidential election1, have been marked by a growing\nnumber of so-called \u201cfake news \u201d, i.e. fabricated information\nthat disseminate deceptive content, or grossly distort actual newsreports, shared on social media platforms. While misinformation\nand propaganda have existed since ancient times\n2, their impor-\ntance and in \ufb02uence in the age of social media is still not clear.\nIndeed, massive digital misinformation has been designated as a\nmajor technological and geopolitical risk by the 2013 report of the\nWorld Economic Forum3. A substantial number of studies have\nrecently investigated the phenomena of misinformation in online\nsocial networks such as Facebook4\u201310, Twitter10\u201313, YouTube14,\nor Wikipedia15. These investigations, as well as theoretical\nmodeling16,17, suggest that con \ufb01rmation bias18and social in \ufb02u-\nence results in the emergence, in online social networks, of user\ncommunities that share similar beliefs about speci \ufb01c topics, i.e.\necho chambers, where unsubstantiated claims or true informa-\ntion, aligned with these beliefs, are as likely to propagate\nvirally6,19. A comprehensive investigation of the spread of true\nand false news in Twitter also showed that false news is char-\nacterized by a faster and broader diffusion than true news mainly\ndue to the attraction of the novelty of false news12. A polarization\nin communities is also observed in the consumption of news in\ngeneral20,21and corresponds with political alignment22. Recent\nworks also revealed the role of bots, i.e. automated accounts, in\nthe spread of misinformation12,23\u201325. In particular, Shao et al.\nfound that, during the 2016 US presidential election on Twitter,\nbots were responsible for the early promotion of misinformation,\nthat they targeted in \ufb02uential users through replies and men-\ntions26and that the sharing of fact-checking articles nearly dis-\nappears in the core of the network, while social bots proliferate13.\nThese results have raised the question of whether such mis-\ninformation campaigns could alter public opinion and endanger\nthe integrity of the presidential election24. Here, we use a\ndataset of 171 million tweets sent by 11 million users covering\nalmost the whole activity of users regarding the two main US\npresidential candidates, Hillary Clinton and Donald Trump,collected during the \ufb01ve months preceding election day and used\nto extract and analyze Twitter opinion trend in our previous\nwork\n27. We compare the spread of news coming from websites\nthat have been described as displaying fake news with the spread\nof news coming from traditional, fact-based, news outlets with\ndifferent political orientations. We relied upon the opinion of\ncommunications scholars (see Methods for details) who have\nclassi \ufb01ed websites as containing fake news or extremely biased\nnews. We investigate the diffusion in Twitter of each type of\nmedia to understand what is their relative importance, who are\nthe top news spreaders, and how they drive the dynamics of\nTwitter opinion. We \ufb01nd that, among the 30.7 million tweets\ncontaining an URL directing to a news outlet website, 10% point\ntoward websites containing fake news or conspiracy theory and\n15% point toward websites with extremely biased news. When\nconsidering only tweets originating from non-of \ufb01cial Twitter\nclients, we see a tweeting rate for users tweeting links to websites\ncontaining news classi \ufb01ed as fake more than four times larger\nthan for traditional media, suggesting a larger role of bots in the\ndiffusion of fake news. We separate traditional news outlets from\nthe least biased to the most biased and reconstruct the informa-\ntion \ufb02ow networks by following retweets tree for each type of\nmedia. User diffusing fake news form more connected networks\nwith less heterogeneous connectivity than users in traditional\ncenter and left leaning news diffusion networks. While top news\nspreaders of traditional news outlets are journalists and public\n\ufb01gures with veri \ufb01ed Twitter accounts, we \ufb01nd that a large number\nof top fake and extremely biased news spreaders are unknown\nusers or users with deleted Twitter accounts. The presence of twoclusters of media sources and their relation with the supporters of\neach candidate is revealed by the analysis of the correlation of\ntheir activity. Finally, we explore the dynamics between the top\nnews spreaders and the supporters \u2019activity with a multivariate\ncausal network reconstruction28.W e \ufb01nd two different\nmechanisms for the dynamics of fake news and traditional news.\nThe top spreaders of center and left leaning news outlets, who are\nmainly journalists, are the main drivers of Twitter \u2019s activity and\nin particular of Clinton supporters \u2019activity, who represent the\nmajority in Twitter27. For fake news, we \ufb01nd that it is the activity\nof Trump supporters that governs their dynamics and top\nspreaders of fake news are merely following it.\nResults\nNews spreading in Twitter . To characterize the spreading of\nnews in Twitter we analyze all the tweets in our dataset that\ncontained at least one URL (Uniform Resource Locator, i.e. web\naddress) linking to a website outside of Twitter. We \ufb01rst separate\nURL in two main categories based on the websites they link to:\nwebsites containing misinformation and traditional, fact-based,\nnews outlets. We use the term traditional in the sense that news\noutlets in this category follow the traditional rules of fact-based\njournalism and therefore also include recently created news\noutlets (e.g. vox.com ).\nClassifying news outlets as spreading misinformation or real\ninformation is a matter of individual judgment and opinion, and\nsubject to imprecision and controversy. We include a \ufb01ner\nclassi \ufb01cation of news outlets spreading misinformation in two\nsub-categories: fake news and extremely biased news. Fake news\nwebsites are websites that have been \ufb02agged as consistently\nspreading fabricated news or conspiracy theories by several fact-\nchecking groups. Extremely biased websites include more\ncontroversial websites that not necessarily publish fabricated\ninformation but distort facts and may rely on propaganda,\ndecontextualized information, or opinions distorted as facts. We\nbase our classi \ufb01cation of misinformation websites on a curated\nlist of websites which, in the judgment of a media and\ncommunication research team headed by a researcher of\nMerrimack College, USA, are either fake, false, conspiratorial,\nor misleading (see Methods). They classify websites by analyzing\nseveral aspects, such as if they try to imitate existing reliable\nwebsites, if they were \ufb02agged by fact-checking groups (e.g. snopes.\ncom,hoax-slayer.com , and factcheck.org ), or by analyzing the\nsources cited in articles (the full explanation of their methods is\navailable at www.opensources.co ). We discard insigni \ufb01cant\noutlets accumulating less than 1% of the total number of tweets\nin their category. We classify the remaining websites in the\nextremely biased category according to their political orientation\nby manually checking the bias report of each websites on www.\nallsides.com and mediabiasfactcheck.com . Details about our\nclassi \ufb01cation of websites spreading misinformation is available\nin the Methods section.\nWe also use a \ufb01ner classi \ufb01cation for traditional news websites\nbased on their political orientation. We identify the most\nimportant traditional news outlets by manually inspecting the\nlist of top 250 URL \u2019s hostnames, representing 79% of all URLs,\nshared on Twitter. We classify news outlets as right, right leaning,\ncenter, left leaning, or left based on their reported bias on www.\nallsides.com andmediabiasfactcheck.com . The news outlets in the\nright leaning, center, and left leaning categories are more likely to\nfollow the traditional rules of fact-based journalism. As we move\ntoward more biased categories, websites are more likely to have\nmixed factual reporting. As for misinformation websites, we\ndiscard insigni \ufb01cant outlets by keeping only websites that\naccumulate more than 1% of the total number of tweets of theirARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n2 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\nrespective category. Although we do not know how many news\nwebsites are contained in the list of less popular URLs, a\nthreshold as small as 1% allows us to capture a relatively broad\nsample of the media in term of popularity. Assuming that thedecay in popularity of the websites in each media category is\nsimilar, our measure of the proportion of tweets and users in each\ncategory should not be signi \ufb01cantly changed if we extended our\nmeasure to the entire dataset of tweets with URLs. While the\ndetail of our classi \ufb01cation is subject to some subjectivity, we \ufb01nd\nthat our analysis reveals patterns encompassing several mediacategories that form a group with similar characteristics. Our\nresults are therefore robust to changes of classi \ufb01cation within\nthese larger group of media.\nWe report the hostnames in each categories along with the\nnumber of tweets with a URL pointing toward them in\nSupplementary Table 1. Using this \ufb01nal separation in seven\nclasses, we identify in our dataset (we give the top hostname as an\nexample in parenthesis): 16 hostnames corresponding to fake\nnews websites (e.g. thegatewaypundit.com ), 17 hostnames for\nextremely biased (right) news websites (e.g. breitbart.com ), 7\nhostnames for extremely biased (left) news websites (e.g.\ndailynewsbin.com ), 18 hostnames for left news websites (e.g.\nhuf\ufb01ngtonpost.com ), 19 hostnames for left leaning news websites\n(e.g. nytimes.com ), 13 hostnames for center news websites (e.g.\ncnn.com ), 7 hostnames for right leaning websites (e.g. wsj.com ),\nand 20 hostnames for right websites (e.g. foxnews.com ).\nWe identi \ufb01ed 30.7 million tweets with an URL directing to a\nnews outlet website, sent by 2.3 million users. An important point\nwhen comparing the absolute number of tweets and users\ncontributing to the spread of different types of news is the bias\nintroduced by the keywords selected during the data collection.\nIndeed, if we had used keywords targeting speci \ufb01c news outlets or\nhashtags concerning speci \ufb01c news event, it would be impossible\nto perfectly control the bias toward fake and reliable news or\nthe representation of the political orientation of the tweet sample.\nHere, we used neutral keywords in term of media representation,\nthe names of the two main candidates to the presidential election\n(see Methods), in order to collect a sample representative of the\nreal coverage of the election on Twitter by all media sources.\nWe see a large number of tweets linking to fake news websites\nand extremely biased news websites (Fig. 1a and Table 1).\nHowever, the majority of tweets linking to news outlets points\ntoward left leaning news websites closely followed by center news\nwebsites. Tweets directing to left and left leaning news websites\nrepresent together 38% of the total and tweets directing towards\ncenter news outlets represents 21%. Tweets directing to fake and\nextremely biased news websites represents a share of 25%. Whenconsidering the number of distinct users having sent the tweets\ninstead of the number of tweets (Fig. 1b and Table 1), the share of\nleft and left leaning websites increases to 43% and the share of\ncenter news to 29%, while the share going to fake news and\nextremely biased news is equal to 12% (the share of users differ\nslightly from Table 1when grouping categories as users may\nbelong to several categories). The number of tweets linking to\nwebsites producing fake and extremely biased news is comparable\nwith the number for center, left and left leaning media outlets.\nHowever, users posting links to fake news or extreme bias (right)\nwebsites are, in average, more active than users posting links to\nother news websites (Table 1). In particular, they post arounda\nb6Number of tweets ( Nt)Number of users ( Nu)\u00d7106\n\u00d71064\n2\n0\n1.0\n0.5\n0.0\nFake news &extreme biasRightCenterLeft\nleaningLeftRight\nleaning\nFig. 1 Importance of different types of news outlets in Twitter. Number of\ndistinct tweets ( a) and number of distinct users having sent tweets ( b) with\na URL pointing to a website belonging to one of following categories: fake or\nextremely biased, right, right leaning, center, left and left leaning news\noutlets. While the tweet volume of fake and extremely biased news iscomparable to the tweet volumes of center and left volume ( a), users\nposting fake and extremely biased news are around twice more active in\naverage (see Table 1). Consequently, the share of users posting fake and\nextremely biased news ( b) is smaller (12%) than the share of tweets\ndirecting toward fake and extremely biased news websites (25%)\nTable 1 Tweet and user volume corresponding to each media category in Twitter\nNt pt Nu pu Nt/Nu pt,n/o pu,n/o Nt,n/o/Nu,n/o\nFake news 2,991,073 0.10 204,899 0.05 14.60 0.19 0.03 80.35\nExtreme bias (right) 3,969,639 0.13 294,175 0.07 13.49 0.09 0.03 36.52Right news 4,032,284 0.13 416,510 0.10 9.68 0.11 0.04 24.80Right leaning news 1,006,746 0.03 272,347 0.06 3.70 0.18 0.06 11.39Center news 6,322,257 0.21 1,032,722 0.24 6.12 0.20 0.05 26.68Left leaning news 7,491,344 0.24 1,272,672 0.30 5.89 0.14 0.04 18.64Left news 4,353,999 0.14 674,744 0.16 6.45 0.14 0.05 16.64Extreme bias (left) 609,503 0.02 99,743 0.02 6.11 0.06 0.03 11.46\nNumber, Nt, and proportion, pt, of tweets with a URL pointing to a website belonging to one of the media categories. Number, Nu, and proportion, pu, of users having sent the corresponding tweets, and\naverage number of tweets per user, Nt/Nu, for each category. Proportion of tweets sent by non-of \ufb01cial clients, pt,n/o, proportion of users having sent at least one tweet from an non-of \ufb01cial client, pu,n/o,\nand average number of tweets per user sent from non-of \ufb01cial clients, Nt,n/o/ Nu,n/oNATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 3\nFake news Extreme bias\n(right)\n2 @RealAlexJones\n3 @zerohedge\n6 @mitchellvii5 @realDonaldTrump4 @DRUDGE_REPORT1 @PrisonPlanet\n10 deleted9 @RickRWells8 @TruthFeedNews\n1 @realDonaldTrump5 @DRUDGE_REPORT\n6 @seanhannity\n7 @WayneDupreeShow\n9 @mitchellvii\n10 @LouDobbs\nCenter news8 @LindaSuhler\n4 @wikileaks\n1 @CNN\n9\n8\n57\n10\n6\n32142 @thehill\n6 @NateSilver538\n7 @AP\n8 @business\n10 @AP_Politics9 @USATODAY5 @Reuters4 @CNNPolitics3 @politico\n2 @realDonaldTrump\n3 @dcexaminer\n4 @DRUDGE_REPORT\n5 @nypost\n6 @FoxNewsInsider\n7 @DailyMail1 @FoxNews\n9 @RealJamesWoods\n10 @foxandfriends\n63 Left news\n9\n845\n1\n1027\n6 @PolitiFact\n7 @CBSNews\n8 @voxdotcom\n9 @ABCPolitics\n10 @ezraklein1 @HuffPost\n2 @TIME\n3 @thedailybeast\n4 @RawStory\n5 @HuffPostPol\n6 @NewY orker\n7 @MotherJones 10 @thinkprogress9 @Salon8 @TPM2 @washingtonpost\n3 @ABC\n4 @NBCNews\n5 @Slate\nNode's size: CloutColor's darkness: out-degree1 @nytimesLeft leaning\nnews8 @AllenWest3 @BreitbartNews2 @DailyCaller7 deleted8\n10\n712\n3\n4 1 57\n286910\n3\n2 Right news\n1061\n7\n35\n9\n9735\n68\n10\n4\n12844\n65\n9ab\nc\nd\ne\nf\nFig. 2 Retweet networks formed by the top 100 news spreaders of different media categories. Retweet networks for fake news ( a), extreme bias (right)\nnews ( b), right news ( c), center news ( d), left leaning news ( e), and left news ( f) showing only the top 100 news spreaders ranked according to their\ncollective in \ufb02uence. The direction of the links represents the \ufb02ow of information between users. The size of the nodes is proportional to their Collective\nIn\ufb02uence score, CI out, and the shade of the nodes \u2019color represents their out-degree, i.e. the number of different users that have retweeted at least one of\nher/his tweets with a URL directing to a news outlet, from dark (high out-degree) to light (low out-degree). The network of fake ( a) and extreme bias\n(right) ( b) are characterized by a connectivity that is larger in average and less heterogeneous than for networks of center and left leaning news (Table 2)ARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n4 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\ntwice the number of tweets compared to users posting links\ntowards center or left leaning news outlets.\nThe proportion of tweets sent by, and users using, non-of \ufb01cial\nTwitter clients (Table 1) allows to evaluate the importance of\nautomated posting in each category. Details about our classi \ufb01ca-\ntion of of \ufb01cial Twitter clients are available in the Methods. We see\nthat the two top categories are fake news and center news with\naround 20% of tweets being sent from non-of \ufb01cial accounts.\nWhen considering the proportion of users sending tweets from\nnon-of \ufb01cial clients, the number is very similar for all categories,\naround 4%, showing that the automation of posting plays an\nimportant role across all media categories. Indeed, non-of \ufb01cial\nclients includes a broad range of clients, from \u201csocial bots \u201dto\napplications used to facilitate the management of professional\nTwitter accounts. A large discrepancy between sources arises\nwhen we consider the average number of tweets per users sent\nfrom non-of \ufb01cial clients (Table 1). Users using non-of \ufb01cial clients\nto send tweets with links directing to websites displaying fakenews tweeted an average of 80 times during the collection period,\nwhich is more than twice the value for other types of news outlets.\nThis high activity from non-of \ufb01cial clients suggests an abnormal\npresence of bots. The role of bots in the diffusion of fake news has\nalready been documented\n13,26as well as their presence in the\nTwitter discussions during 2016 US election24.\nWe note that Breitbart News is the most dominant media\noutlet in term of number of tweets among the right end of the\noutlet categories with 1.8 million tweets (see Supplementary\nTable 1). We examine the relation between Breitbart and the rest\nof the media outlets in Supplementary Note 1, Supplementary\nTables 2 \u20136 as well as Supplementary Fig. 1. Our analysis shows\nthat removing Breitbart from the extreme bias category does not\nchange our results signi \ufb01cantly.\nNetworks of information \ufb02ow. To investigate the \ufb02ow of\ninformation we build the retweet networks for each category of\nnews websites, i.e. when a user uretweets (a retweet allows a user\nto rebroadcast the tweet of an other user to his followers) the\ntweet of a user vthat contains a URL linking to a website\nbelonging to one of the news media category, we add a link, or\nedge, going from node vto node uin the network. The direction\nof the links represents the direction of the information \ufb02ow\nbetween Twitter users. We do not consider multiple links with the\nsame direction between the same two users and neither consider\nself-links, i.e. when a user retweet her/his own tweet. The out-\ndegree of a node is its number of outgoing links and is equal to\nthe number of different users that have retweeted at least one of\nher/his tweets. Its in-degree is its number of in-going links and\nrepresents the number of different users she/he retweeted.Figure 2shows the networks formed by the top 100 news\nspreaders of the six most important retweet networks. The\nretweet networks for right leaning and extreme bias (left) news is\nshown in Supplementary Fig. 2. We explain in the section Top\nnews spreaders and in the Methods how the news spreaders are\nidenti \ufb01ed. A clear difference is apparent between the networks\nrepresenting the \ufb02ow of fake and extremely biased (right) news\nand the networks for left leaning and center news (Table 2and\nSupplementary Fig. 3). The left leaning and center news outlets\ncorrespond to larger networks in term of number of nodes and\nedges, revealing their larger reach and in \ufb02uence in Twitter.\nHowever, the retweet networks corresponding to fake and\nextremely biased (right) news outlets are the most dense with\nan average degree \u2329k\u232a\u22436.5. The retweet network for right news\nhas characteristics in between those two groups with a slightly\nlarger size than the networks for fake and extremely biased (right)\nnews and a larger average degree than center news. These results\nshow that users spreading fake and extremely biased news,although in smaller numbers, are not only more active in average\n(Table 1), but also connected (through retweets) to more users in\naverage than users in the traditional news networks. Table 2also\nshows that the center and left leaning networks have the most\nheterogeneous out-degree distribution and the fake news retweet\nnetworks has the less heterogeneous out-degree distribution. We\nmeasure the heterogeneity of the distribution with a boot-\nstrapping procedure (see Table 2) to ensure the independence of\nthe measure on the networks \u2019sizes. Our analysis indicates that the\nlarger networks (center, left leaning) differ from the smaller ones\nnot just by their size but also by their structure. The heterogeneity\nof the degree distribution plays an important role in spreading\nprocesses on networks, indicating a strong hierarchical diffusion\ncascade from hubs to intermediate degree, and \ufb01nally to small\ndegree classes\n29,30. The characteristics of the weighted retweet\nnetworks, taking into account multiple interactions between\nusers, reveal the same patterns than the unweighted networks\n(Supplementary Table 7). Table 2and Supplementary Fig. 3a\nreveals the existence of users with very large out-degree ( kout>\n5\u00d71 05), in the center and left leaning networks, i.e. very\nimportant broadcasters of information, which are not present\nin other networks. This suggests that different mechanisms of\ninformation diffusion could be at play in the center and left\nleaning news networks, where high degree nodes may play a more\nimportant role, than in the fake and extremely biased news\nnetworks.\nWe note that a difference between the largest networks, i.e\ncenter and left leaning news, and the fake and extremely biased\nnetworks is that the former have typically access to more\nbroadcasting technologies, which may be disruptive to under-\nstanding diffusion patterns based on network data31. TheTable 2 Retweet networks characteristics for each news source categories\nNnodes Nedges \u2329k\u232a \u03c3(kout)/\u2329k\u232a \u03c3(kin)/\u2329k\u232a max ( kout) max ( kin)\nFake news 175,605 1,143,083 6.51 32 \u00b1 4 2.49 \u00b1 0.06 42,468 1232\nExtreme bias (right) 249,659 1,637,927 6.56 36 \u00b1 6 2.73 \u00b1 0.03 51,845 588Right 345,644 1,797,023 5.20 44 \u00b1 11 2.70 \u00b1 0.04 86,454 490Right leaning 216,026 495,307 2.29 45 \u00b1 11 1.72 \u00b1 0.02 32,653 129Center 864,733 2,501,037 2.89 75 \u00b1 39 2.69 \u00b1 0.06 229,751 512Left leaning 1,043,436 3,570,653 3.42 59 \u00b1 19 3.38 \u00b1 0.10 145,047 843Left 536,903 1,801,658 3.36 47 \u00b1 12 3.50 \u00b1 0.08 58,901 733Extreme bias (left) 78,911 277,483 3.52 33 \u00b1 6 2.49 \u00b1 0.08 23,168 648\nWe show the number of nodes and edges (links) of the networks, the average degree, \u2329k\u232a=\u2329kin\u232a=\u2329kout\u232a(the in-/out-degree of a node is the number of in-going/out-going links attached to it). In a\ndirected network, the average in-degree and out-degree are always equal. The out-degree of a node, i.e. a user, is equal to the number of different user s that have retweeted at least one of her/his tweets.\nIts in-degree represents the number of different users she/he retweeted. The ratio of the standard deviation and the average of the in- and out-degree distribution, \u03c3(kin)/\u2329k\u232aand \u03c3(kout)/\u2329k\u232a, measures\nthe heterogeneity of the connectivity of each networks. As the standard deviation of heavy-tailed degree distributions can depend on the network siz e, we computed the values of \u03c3(kin)/\u2329k\u232aand \u03c3(kout)/\n\u2329k\u232aby taking the average, and standard error, of 1000 independent samples, of 78,911 values each, drawn from the in- and out-degree distributions of each networkNATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 5\nstructural differences we observe may be explained by the fact\nthat there is something different about the way that the people in\nthese networks organize and share information but it may also be\nthe case that there are subgroups of users in the center and left\nleaning news networks that form diffusion networks with a\nsimilar structure as the smaller fake and extremely biased news\nnetworks and then also have a large number of other individualsadded to these subgroups due to the presence of important\nbroadcast networks that feed their ideology or information needs.\nWhile inspecting speci \ufb01c accounts is not the goal of this study,\nlooking at the two accounts with the maximum koutand kin\nreveals an interesting contrast between users of both networks.\nThe user with the largest out-degree of the center news network is\nthe veri \ufb01ed account of the Cable News Network, CNN, (@CNN),Table 3 Top 25 CI news spreaders of the retweet networks corresponding to each media category\nRank Fake news (7 veri \ufb01ed, 2\ndeleted, 16 unveri \ufb01ed)Extreme bias (right) news (15\nveri\ufb01ed, 1 deleted, 9 unveri \ufb01ed)Right news (23 veri \ufb01ed, 0\ndeleted, 2 unveri \ufb01ed)Right leaning news (20 veri \ufb01ed,\n1 deleted 4 unveri \ufb01ed)\n1 @PrisonPlanet \u2713 @realDonaldTrump \u2713 @FoxNews \u2713 @WSJ\u2713\n2 @RealAlexJones \u2713 @DailyCaller \u2713 @realDonaldTrump \u2713 @WashTimes \u2713\n3 @zerohedge @BreitbartNews \u2713 @dcexaminer \u2713 @RT_com \u2713\n4 @DRUDGE_REPORT @wikileaks \u2713 @DRUDGE_REPORT @realDonaldTrump \u2713\n5 @realDonaldTrump \u2713 @DRUDGE_REPORT @nypost \u2713 @RT_America \u2713\n6 @mitchellvii \u2713 @seanhannity \u2713 @FoxNewsInsider \u2713 @WSJPolitics \u2713\n7 deleted @WayneDupreeShow \u2713 @DailyMail \u2713 @DRUDGE_REPORT\n8 @TruthFeedNews @LindaSuhler @AllenWest \u2713 @KellyannePolls \u2713\n9 @RickRWells @mitchellvii \u2713 @RealJamesWoods \u2713 @TeamTrump \u2713\n10 deleted @LouDobbs \u2713 @foxandfriends \u2713 @LouDobbs \u2713\n11 @gatewaypundit \u2713 @PrisonPlanet \u2713 @foxnation \u2713 @rebeccaballhaus \u2713\n12 @infowars @DonaldJTrumpJr \u2713 @LouDobbs \u2713 @WSJopinion \u2713\n13 @Lagartija_Nix @ger \ufb01ngerpoken @KellyannePolls \u2713 @reidepstein \u2713\n14 @DonaldJTrumpJr \u2713 @FreeBeacon \u2713 @JudicialWatch \u2713 deleted\n15 @ThePatriot143 @ger \ufb01ngerpoken2 @PrisonPlanet \u2713 @JasonMillerinDC \u2713\n16 @V_of_Europe @TeamTrump \u2713 @wikileaks \u2713 @DanScavino \u2713\n17 @KitDaniels1776 @Italians4Trump @TeamTrump \u2713 @PaulManafort \u2713\n18 @Italians4Trump @benshapiro \u2713 @IngrahamAngle \u2713 @SopanDeb \u2713\n19 @_Makada_ @KellyannePolls \u2713 @marklevinshow \u2713 @asamjulian\n20 @BigStick2013 @DanScavino \u2713 @LifeZette \u2713 @JudicialWatch \u2713\n21 @conserv_tribune \u2713 deleted @theblaze \u2713 @_Makada_\n22 @Miami4Trump @JohnFromCranber @FoxBusiness \u2713 @mtracey \u2713\n23 @MONAKatOILS @true_pundit @foxnewspolitics \u2713 @Italians4Trump\n24 @JayS2629 @ThePatriot143 @BIZPACReview @Telegraph \u2713\n25 @ARnews1936 @RealJack @DonaldJTrumpJr \u2713 @RealClearNews \u2713\nRank Center news (24 veri \ufb01ed, 0\ndeleted, 1 unveri \ufb01ed)Left leaning news (25 veri \ufb01ed, 0\ndeleted 0 unveri \ufb01ed)Left news (25 veri \ufb01ed, 0\ndeleted, 0 unveri \ufb01ed)Extreme bias (left) news (7 veri \ufb01ed,\n1 deleted, 17 unveri \ufb01ed)\n1 @CNN \u2713 @nytimes \u2713 @HuffPost \u2713 @Bipartisanism \u2713\n2 @thehill \u2713 @washingtonpost \u2713 @TIME \u2713 @PalmerReport \u2713\n3 @politico \u2713 @ABC\u2713 @thedailybeast \u2713 @peterdaou \u2713\n4 @CNNPolitics \u2713 @NBCNews \u2713 @RawStory \u2713 @crooksandliars \u2713\n5 @Reuters \u2713 @Slate \u2713 @HuffPostPol \u2713 @BoldBlueWave\n6 @NateSilver538 \u2713 @PolitiFact \u2713 @NewYorker \u2713 @Shareblue \u2713\n7 @AP \u2713 @CBSNews \u2713 @MotherJones \u2713 @Karoli\n8 @business \u2713 @voxdotcom \u2713 @TPM \u2713 @RealMuckmaker\n9 @USATODAY \u2713 @ABCPolitics \u2713 @Salon \u2713 @GinsburgJobs\n10 @AP_Politics \u2713 @ezraklein \u2713 @thinkprogress \u2713 @AdamsFlaFan\n11 @FiveThirtyEight \u2713 @nytpolitics \u2713 @mmfa \u2713 @mcspocky\n12 @bpolitics \u2713 @guardian \u2713 @joshtpm \u2713 @Shakestweetz \u2713\n13 @jaketapper \u2713 @NYDailyNews \u2713 @MSNBC \u2713 deleted\n14 @DRUDGE_REPORT @latimes \u2713 @NYMag \u2713 @JSavoly\n15 @cnnbrk \u2713 @BuzzFeedNews \u2713 @samstein \u2713 @OccupyDemocrats\n16 @businessinsider \u2713 @Mediaite \u2713 @JuddLegum \u2713 @ZaibatsuNews\n17 @AC360 \u2713 @HillaryClinton \u2713 @mashable \u2713 @wvjoe911\n18 @cnni \u2713 @nytopinion \u2713 @theintercept \u2713 @DebraMessing \u2713\n19 @brianstelter \u2713 @CillizzaCNN \u2713 @DavidCornDC \u2713 @SayNoToGOP\n20 @KellyannePolls \u2713 @MSNBC \u2713 @dailykos \u2713 @coton_luver\n21 @wikileaks \u2713 @KFILE \u2713 @JoyAnnReid \u2713 @EJLandwehr\n22 @SopanDeb \u2713 @TheAtlantic \u2713 @nxthompson \u2713 @mch7576\n23 @KFILE \u2713 @SopanDeb \u2713 @thenation \u2713 @RVAwonk\n24 @BBCWorld \u2713 @Fahrenthold \u2713 @justinjm1 \u2713 @_Carja\n25 @NewDay \u2713 @BuzzFeed \u2713 @ariannahuff \u2713 @Brasilmagic\nVeri\ufb01ed users have a checkmark ( \u2713) next to their user name. Verifying its accounts is a feature offered by Twitter that \u201clets people know that an account of public interest is authentic \u201d(help.twitter.com/\nen/managing-your-account/about-twitter-veri \ufb01ed-accounts ). Unveri \ufb01ed accounts do not have a checkmark and accounts marked as deleted have been deleted either by Twitter or by the users\nthemselvesARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n6 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\nwhich regularly posts links towards its own website using mainly\nthe non-of \ufb01cial professional client Sprinklr ( www.sprinklr.com ).\nThe user with the largest in-degree of the fake news network is\nthe user @Patriotic_Folks, which, at the moment of this writing,seems to belong to a deceiving user, whose pro \ufb01le description\ncontains the hashtag #MAGA and refer to a website belonging to\nour fake news website list ( thetruthdivision.com ). The name of\nthe account is \u201cAnnabelle Trump \u201dand its pro \ufb01le picture is a\nyoung woman wearing cow-boy clothes (a reverse image search\non the web reveals that this pro \ufb01le image is not authentic as it\ncomes in fact from the catalog of a website selling western\nclothes). Most of its tweet are sent from the of \ufb01cial Twitter Web\nClient, suggesting that a real person is managing the account, and\ncontains URLs directing to the same fake news website. However,\nhaving a high in-degree does not indicate that this user has an\nimportant in \ufb02uence. Indeed, its out-degree is approximately 3.5\ntimes smaller than its in-degree and, as we explain in the next\nsection, in \ufb02uence is poorly measured by local network properties\nsuch as in- or out-degree.\nTop news spreaders . In order to uncover the most in \ufb02uential\nusers of each retweet network, we use the Collective In \ufb02uence\n(CI) algorithm\n32which is based on the solution of the optimal\nnetwork percolation. For a Twitter user to be highly ranked by the\nCI algorithm, she/he does not necessarily need to be directly\nretweeted by many users, but she/he needs to be surrounded by\nhighly retweeted users (see Methods for more details).\nWe\ufb01nd that top news spreaders of left leaning and center news\nare almost uniquely veri \ufb01ed accounts belonging to news outlets or\njournalists (Table 3). A very different situation for news spreaders\nof the fake news and extremely biased news websites is revealed,\nwhere, among veri \ufb01ed accounts of news websites and journalists,\nwe also \ufb01nd a large number of unknown, unveri \ufb01ed, users that are\nnot public \ufb01gures but are important news spreaders in Twitter\n(Fig. 3and Table 3). We also \ufb01nd deleted accounts, which could\nhave been deleted either by Twitter for infringing their rules and\npolicies or by the users themselves, mostly in the fake and\nextremely biased news spreaders. We \ufb01nd that, based on the\ntimestamp of their last tweet in our dataset, 24 out of the 28\naccounts had tweeted after election day (8 November 2016),\nindicating that they were deleted after the election. Deleted\naccounts were extremely active, with a median number of tweets\nof 2224 (minimum: 156, 1st quartile: 1400, 3rd quartile: 6711, andmaximum: 15,930). In comparison, the median number of tweets\nper users for our entire dataset is 2. We also \ufb01nd that 21 deleted\naccounts used an unof \ufb01cial Twitter client (the most used one by\ndeleted accounts is dlvr.it ). The list of the right, right leaning, and\nleft news top spreaders form a mix of veri \ufb01ed and unveri \ufb01ed\naccounts. Figure 2shows the retweet networks formed by the top\n100 spreaders of each category and Fig. 4shows the combined\nretweet network formed by top 30 news spreaders of all media\ncategories and reveals the separation of the top news spreaders in\ntwo main clusters as well as the relative importance of the top\nspreaders. The sets of top 100 fake news, extremely biased (right),\nright, and right leaning news spreaders have an important\noverlap, >30 (Fig. 4and Supplementary Table 8). Fake and\nextremely biased news is mostly spread by unveri \ufb01ed accounts\nwhich could be due to the fact that some accounts are trying to\nhide their real identity but also to the fact that audiences of the\nfake and extremely biased news are more likely to listen to \u201cnon-\npublic \u201d\ufb01gures due to their distrust of the establishment.\nWe distinguish three types of unveri \ufb01ed accounts: (1)\nunveri \ufb01ed accounts that are not necessarily misleading or\ndeceiving, for example, @zerohedge, @DRUDGE_REPORT or\n@TruthFeedNews make their af \ufb01liation to their respective news\nwebsites clear, although their identities or the ones of their\nwebsites administrators is not always clear; (2) unveri \ufb01ed\naccounts that make their motif clear in their choice of screen-\nname, e.g. @Italians4Trump or @Miami4Trump, although the\nreal identity of the persons behind such accounts is also usually\nundisclosed; (3) \ufb01nally, unveri \ufb01ed accounts that seem to be real\npersons with pro \ufb01le pictures and user names, e.g @Lagartija_Nix,\n@ThePatriot143, @BigStick2013, @LindaSuhler, @ger \ufb01ngerpo-\nken, or @AdamsFlaFan, but are not public \ufb01gures. Whether such\nusers are authentic, social bots or fake users operated by someone\nelse is not clear. However, our results show that such users are not\npresent in the top news spreaders of the center and left leaning\nnews, while they have a high prevalence in the fake and extremely\nbiased categories.\nAnother observation is the presence of members of the\ncampaign staffs of each candidate in the top news spreaders\n(see Supplementary Note 2 and Supplementary Table 9). We see\nmore users linked to the campaign staff of Donald Trump (13),\nand with higher ranks in term of in \ufb02uence, than to the campaign\nstaff of Hillary Clinton (3), revealing the more important direct\nrole of the Trump team in the diffusion of news in Twitter.\nNews spreading dynamics . To investigate the news spreading\ndynamics of the different media categories on Twitter, we analyze\nthe correlations between the time series of tweeting rate measured\nfor each category. The Twitter activity time series are constructed\nby counting the number of tweets with a URL directing toward a\nwebsite belonging to each of the media category at a 15 min\nresolution. In addition to the activity related to each media group,\nwe also consider the time series of the activity of the supporters of\neach presidential candidates. We classify supporters based on the\ncontent of their tweets using a supervised machine learning\nalgorithm trained on a dataset obtained from the network of\nhashtag co-occurrences. The full detail of our method and the\nvalidation of its opinion trend with the national polling average of\nthe New York Times is described in ref.27. We use our full dataset\nof tweets concerning the two candidates, namely 171 million\ntweets sent by 11 million distinct users during more than \ufb01ve\nmonths. After removing automated tweets (see Methods), we\nhave a total of 157 million tweets. This represents an average of\n1.1 million tweets per day (standard deviation of 0.6 million) sent\nby an average of about 375,000 distinct users per day (standard\ndeviation of 190,000). A majority of users, 64%, is in favor of100\nVerified\nUnverified\nDeleted80Number of accounts60\n40\n20\n0\nFake\nnewsRightCenterLeft\nleaningLeftRight\nleaning\nExtreme bias(right)\nExtreme bias(left)\nFig. 3 Types of top news spreaders accounts per media category.\nProportion of veri \ufb01ed (green), unveri \ufb01ed (orange), and deleted (black)\naccounts among the top 100 news spreaders in each media categoryNATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 7\nHillary Clinton while 28% is in favor of Donald Trump (8% are\nunclassi \ufb01ed as they have the same number of tweets in each\ncamp). However, we \ufb01nd that Trump supporters are, in average,\n1.5 times more active than Clinton supporters27. The supporters\ntherefore represent the general Twitter population commenting\non the candidate of the election.\nWe removed the trend and circadian cycles present in the time\nseries with the widely used STL (seasonal-trend decomposition\nprocedure based on Loess) method33, which is a robust iterative\n\ufb01ltering method allowing to separate a time series in seasonal (in\nthis case, daily), trend, and remainder components (see Methods).\nThe separation of the media sources in two correlated clusters\nis revealed when using a threshold of r0=0.49, corresponding to\nthe place of the largest gap between the sorted correlation values\n(Fig. 5). The value of each cross-correlation coef \ufb01cient is reported\nin Supplementary Table 10. The \ufb01rst activity cluster (indicated by\na red square in Fig. 5a) comprises the fake, extreme bias (right),\nand right news. The second activity cluster (indicated by a blue\nsquare) is made of the center, left, and left leaning news sources.\nThe activities of right leaning and extremely biased (left) news are\nonly poorly correlated with the other news categories or\nsupporters (see Supplementary Table 10). We observe the\nfollowing patterns between the media groups and the supporters\ndynamics: the activity of Clinton supporters has a higher\ncorrelation with the second cluster than with the \ufb01rst one while\nthe activity of Trump supporters is equally correlated with the\ntwo clusters. This indicate that Trump supporters are likely to\nreact to any type of news while Clinton supporters mostly react to\ncenter and news on the left and tend to ignore news coming from\nthe right side.\nThese results indicate that the media included in the two\nclusters respond to two different news dynamics and show thatthe polarization of news observed at the structural level in\nprevious works20\u201322also corresponds to a separation in\ndynamics. This separation could be showing that Americanswith different political loyalties prefer different news sources but\ncould also be due to the fact that supporters prefer the news that\ntheir candidate prefers\n34.\nIn order to investigate the causal relations between news media\nsources and Twitter dynamics, we use a multivariate causal\nnetwork reconstruction of the links between the activity of top\nnews spreaders and supporters of the presidential candidates\nbased on a causal discovery algorithm28,35,36. The causal network\nreconstruction tests the independence of each pair of time series,\nfor several time lags, conditioned on potential causal parents with\na non-parametric conditional independence test37,38(see Meth-\nods). We use the causal algorithm as a variable selection and\nperform a regression of a linear model using only the true causal\nlink discovered. We consider linear causal effects for their reliable\nestimation and interpretability. This permits us to compare the\ncausal effect as \ufb01rst order approximations, estimate the\nuncertainties of the model, and reconstruct a causal directed\nweighted networks28. In this framework, the causal effect between\na time series XiandXjat a time delay \u03c4,ICE\ni!j\u00f0\u03c4\u00de, is equal to the\nexpected value of Xj\nt(in unit of standard deviation) if Xi\nt/C0\u03c4is\nperturbed by one standard deviation28.\nAn assumption of causal discovery is causal suf \ufb01ciency, i.e. the\nfact that every common cause of any two or more variables is in\nthe system35. Here, causal suf \ufb01ciency is not satis \ufb01ed since\nTwitter \u2019s activity is only the observed part of a larger social\nsystem and the term \u201ccausal \u201dmust be understood to be meant\nrelative to the system under study. As for the cross-correlation\nanalysis, we use the residuals of the STL \ufb01ltering of the 15 tweet\nvolume time series (Fig. 6a, b).\n1\n531\n232\n115\n21544514\n253\n3\n4\n3\n53\n42\n32\n2\n5 @realDonaldTrump1,2,44 @DRUDGE_REPORT4,53 @zerohedge2 @RealAlexJones1 @PrisonPlanet\n2 @realDonaldTrump1,4,5\n4 @DRUDGE_REPORT4,5\n5 @nypost3 @dcexaminer1 @FoxNews\n2 @WashTimes\n4 @realDonaldTrump1,2,53 @RT_com\n5 @RT_America1 @WSJ\n4 @CNNPolitics\n5 @Reuters3 @politico2 @thehill1 @CNN\n5 @Slate4 @NBCNews3 @ABC2 @washingtonpost1 @nytimes\n5 @HuffPostPol4 @RawStory3 @thedailybeast2 @TIME1 @HuffPost\n5 @BoldBlueWave4 @crooksandliars3 @peterdaou2 @PalmerReport1 @Bipartisanism 1 @realDonaldTrump2,4,5\n2 @DailyCaller\n5 @DRUDGE_REPORT4,44 @wikileaks3 @BreitbartNews34\n11\nFake news Extreme bias (right) Right Right leaning Center Left leaning Left Extreme bias (left)\nFig. 4 Retweet network formed by the top 30 in \ufb02uencers of each media category. The direction of the links represents the \ufb02ow of information between\nusers. The size of the nodes is proportional to their out-degree in the complete combined network, i.e. the number of different users that have retweet ed at\nleast one of her/his tweets with a URL directing to a news outlet, and the color of the nodes indicates to which news category they belong. Nodes that\nbelong to several news categories are represented by pie charts where the size of each slice is proportional to their CI outranking, taking into accounts only\ntheir rank among the top 30ARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n8 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\nWe consider only the activity of the top 100 news spreaders\nsince, by de \ufb01nition of CI, they are the most important sources of\ninformation. Therefore, within the limitation of considering\nTwitter as a closed system, they are the most likely set of users to\ntrigger the activity of the rest of the population. We test this\nhypothesis with Granger causal modeling.\nOur causal analysis takes into account self-links, i.e. the auto-\ncorrelation of each time series, and reveals that they are the\nstrongest causal effect for all time series. Since we are interested in\nthe cross-links, we leave the self-links aside for the rest of thediscussion. The center and left leaning news spreaders have the\nstrongest causation on the supporters activity, with a stronger\neffect on the Clinton supporters than on the Trump supporters\n(Table 4and Fig. 6c). Since the Clinton supporters dominate\nTwitter activity, they also are the main drivers of the global\nactivity. The other top news spreaders have only a small or\nnegligible effect on the supporters activity. In particular, extreme\nbias (left), left, right leaning, and right news spreaders are more\nin\ufb02uenced by the activity of Clinton and Trump supporters than\nthe opposite. We also observe that Trump supporters have a\nsigni\ufb01cant causal effect on the fake news spreaders \u2019activity and\nClinton supporters have a signi \ufb01cant effect on extreme bias (left)\nspreaders \u2019activity (Fig. 6c). This suggests that they are in fact\nfollowing Twitter activity rather than driving it. Regarding the\ncausal relations in-between news spreaders, center news spreaders\nare the most central driver as they are among the top three drivers\nof all news spreaders except for fake news (Table 4). Strong\nmutual causal effects are revealed between center and left leaning\nspreaders. Right leaning top spreaders are driving the activity of\nthe right, extremely biased (right) and fake news spreaders. The\ntwo supporter groups have also strong mutual causal effects.\nThese results reveal two very different dynamics of news\ndiffusion for traditional, center and left leaning, news and\nmisinformation. Center and left leaning news spreaders are the\nmost in \ufb02uential and are driving the supporters activity. On the\nother hand, the dynamics of fake news spreaders seems to be\ngoverned by the ensemble of Trump supporters.\nThe interpretation of the discovered causal effects must be\nunderstood within the limitation that we do not measure the\ndiffusion of news outside of Twitter. Indeed, the reason why\ncenter and left leaning news spreaders have a causal effect on the\nClinton supporters could be explained by the fact that they are\nthe\ufb01rst to be \u201cactivated \u201dby some news appearing, for example on\ntelevision, while the supporters take more time to be \u201cactivated \u201d\nby the same news. However, we have other indications that the\nnews spreaders are directly causing at least part of the supporters \u2019\nactivity, namely that the top news spreaders are precisely the mostimportant source of news retweets. Moreover, if the external\ndriver is an other media outside of Twitter and that the center/left\nleaning news spreaders, who are almost all journalists, are the \ufb01rst\nto be activated, it is very likely that the media channel outside of\nTwitter is related to the journalists. In this case, even if the\ncausation is indirect, we still identify the correct driver through\nthe af \ufb01liation of the journalists. More importantly, while we\nobserve a strong causal effect between center/left leaning news\nspreaders and the supporters, we do not observe a signi \ufb01cant\ncausal effect between other news spreaders and the supporters.\nThis indicates that, even if the causal driver could be outside of\nTwitter, the diffusion mechanisms of traditional and fake news\nare very likely different.\nWe investigate the in \ufb02uence of the presence of staff members\nof the candidates\n\u2019teams in Supplementary Note 2, Supplementary\nFig. 4 and Supplementary Table 11. We observe no signi \ufb01cant\nchanges in the causal relations after having removed all users\nlinked to the campaigns. We also repeated our analysis after\nhaving removed news aggregators from our dataset (see\nSupplementary Note 3, Supplementary Fig. 5, Supplementary\nTables 12 and 13) and found that news aggregators are not\nresponsible for the observed differences in dynamics.\nDiscussion\nUsing a dataset of tweets collected during the 5 months preceding\nthe 2016 presidential elections, we investigated the spread of\ncontent classi \ufb01ed as fake news and compared its importance and\nin\ufb02uence with traditional, fact-based, media. We \ufb01nd that fake\nPro-Clintona\nbLeft leaning\nCenter\nExtreme bias\n(right)Right\nFake news\nNews websites\nRightFake news\nPro-Trump\nLeft leaningPro-Clinton\nLeftCenterExtreme bias (right)\nSupportersFake news Pro-ClintonLeft\nLeft leaningCenter\nPro-TrumpRight\nExtreme bias(right)Pro-TrumpLeft1.0\n0.90.8\n0.7\n0.60.50.4\nFig. 5 Activity correlation between news outlets and supporters. aPearson\ncross-correlation coef \ufb01cients between activity time series related to the\ndifferent types of news outlets, Trump supporters and Clinton supporters.\nbGraph showing the correlation relations between the types of news\nwebsites and the supporters. The edges of the graph represent correlations\nlarger than r0=0.49. Fake news, extreme bias (right), and right websites\nform a \ufb01rst cluster, indicated by a red square in aand shown in orange in b,\nwhile center, left leaning, and left news websites form a second cluster,\nindicated by a blue square in aand shown in blue in b. The activity of Trump\nsupporters is equally correlated with all news sources and the activity of\nClinton supporters, which represents the largest activity, is mainly\ncorrelated with the second media cluster and only poorly with the \ufb01rst oneNATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 9\nnews represents 10% and extremely biased news 15% of the\ntweets linking to a news outlet media. However, taking into\naccount the difference in user activity decreases the share of fake\nand extremely biased news to 12%. Although we \ufb01nd approxi-\nmately the same ratio of users using automated Twitter clients in\neach media category, we \ufb01nd that automated accounts diffusing\nfake news are much more active than the automated accounts\ndiffusing other types of news. This results con \ufb01rms the role of\nbots in the diffusion of fake news, which has been shown using a\ndifferent method of bot detection26, and shows that automated\naccounts also play a role, although smaller, in the diffusion of\ntraditional news.\nWe analyzed the structure of the information diffusion net-\nwork of each category of news and found that fake and extremely\nbiased (right) news diffusion networks are more densely con-\nnected, i.e. users retweet more people and are more retweeted in\naverage, and have less heterogeneous connectivity distributions\nthan traditional, center, and left leaning, news diffusion networks.\nThe heterogeneity of the degree distribution is known to play an\nimportant role in spreading processes on networks29,30. Spread-\ning in networks with heterogeneous connectivity usually follows a\nhierarchical dynamics in which the information propagates from\nhigher-degree to lower-degree classes30.\nWe discovered the top news spreaders of each type of news by\ncomputing their Collective In \ufb02uence32and found very differentpro\ufb01les of fake and extremely biased news top spreaders com-\npared to traditional news spreaders. While traditional news\nspreaders are mostly journalists with veri \ufb01ed Twitter accounts,\nfake and extremely biased news top spreaders include unveri \ufb01ed\naccounts with seemingly deceiving pro \ufb01les and deleted accounts.\nAnalyzing the Twitter activity dynamics of the news diffusion\ncorresponding to each media category, we reveal the existence of\ntwo main clusters of media in term of activity correlation which is\nconsistent with the \ufb01ndings of previous works4\u20139that revealed\nthe separation in polarized communities of online social media\nnews consumers. We also show that right news media outlets are\nclustered together with fake news. Finally, a causality analysis\nbetween the top news spreaders activity and the activity of pre-\nsidential candidate supporters revealed that the top news sprea-\nders of center and left leaning news outlets are the ones driving\nTwitter activity while top news spreaders of fake news are in fact\nfollowing Twitter activity, particularly Trump supporters activity.\nOur analysis focuses on news concerning the candidate of the\npresidential election published from the most popular news\noutlets and therefore its results cannot be directly generalized to\nthe entire Twitter population. Nevertheless, our investigation\nprovides new insights into the dynamics of news diffusion in\nTwitter. Namely, our results suggests that fake and extremely\nbiased news are governed by a different diffusion mechanisms\nthan traditional center and left leaning news. Center and left40ac\nbTop news spreaders\nFake news\nRight\nLeft\nExtreme bias\n(left)Left leaningRight leaning\nCenterSupporters\nWho influences whom?Pro-Trump\nPro-ClintonExtreme bias\n(right)\nClinton supporters (STL residuals)Top 100 left leaning influencers (STL residuals)\nTrump supporters (STL residuals)Top 100 fake news influencers (STL residuals)\u00d7103\n\u00d710310\n5\n030Num tweets/15 min\nNum tweets/15 min\n4\n2\n0\nNum tweets/15 minNum tweets/15 min20\n10\n0\n08\u201308\n09 h08\u201308\n13 h08\u201308\n17 h08\u201308\n21 h09\u201308\n01 h09\u201308\n05 h09\u201308\n09 h\n06\u201307\n18 h06\u201307\n22 h07\u201307\n02 h07\u201307\n06 h07\u201307\n10 h07\u201307\n14 h\u201310\n\u20131001020\nFig. 6 Granger causal network reconstruction between top news spreaders and supporters activity. aActivity time series corresponding to the top 100 left\nleaning news spreaders (dashed) and the Clinton supporters (continuous, right vertical axis). bActivity time series of the top 100 fake news spreaders\n(dashed) and the Trump supporters (continuous, right vertical axis). We show the residuals of the STL \ufb01ltering after the removal of the seasonal (daily)\nand trend components. A causal effect seems apparent from the top 100 left leaning news spreaders to the Clinton supporters ( a). Peaks in the left leaning\nnews spreaders activity (yellow, dashed) tend to precede peaks in the activity of Clinton supporters (blue). A causal effect relation from the Trump\nsupporters to the top 100 fake news news spreaders ( b) seems also apparent. cGraph showing the maximal causal effects between the activity of the top\n100 news spreaders of each media category (left) and the activity of the presidential candidate supporters (right) computed over the entire 5 months.\nArrows indicate the direction of a the maximal causal effect (>0.05) between two activity time series. The width of each arrow is proportional to the\nstrength of the causation and the size of each node is proportional to the auto-correlation of each time series. The center and left leaning top news\nspreaders are the news spreaders that show the strongest causal effect on the supporters activity. The values of the causal effects between each activ ity\ntime series are shown in Table 4ARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n10 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\nleaning news diffusion is driven by a small number of in \ufb02uential\nusers, mainly journalists, and follow a diffusion cascade in a\nnetwork with heterogeneous degree distribution which is typical\nof diffusion in social networks30, while the diffusion of fake and\nextremely biased news seems to not be controlled by a small set of\nin\ufb02uencers but rather to take place in more connected clusters\nand to be the result of a collective behavior.\nMethods\nTwitter data collection and processing . We collected tweets continuously using\nthe Twitter Search API from 1 June 2016 to 8 November 2016. We gather a total of\n171 million tweets in the English language, mentioning the two top candidates\nfrom the Republican Party (Donald J. Trump) and Democratic Party (HillaryClinton) by using two different queries with the following keywords: hillary OR\nclinton OR hillaryclinton and trump OR realdonaldtrump OR donaldtrump.\nWe extracted the URLs from tweets by using the expanded_url \ufb01eld attached to\neach tweet containing at least one URL. A large number of URL were redirecting\nlinks using URL shortening services (e.g. bit.ly ,dlvr.it ,o rift.tt). News websites\nsometimes also uses shortened versions of their hostnames (e.g. cnn.it ,nyti.ms ,hill.\ncm,o rpoliti.co ). We programmatically resolved shortened URLs, using the Python\nRequests library, in order to \ufb01nd their \ufb01nal destination URL and extracted the\nhostname of each \ufb01nal URL in our dataset.\nTo identify tweets that may originate from bots, we extract the name of the\nTwitter client used to post each tweet from their source \ufb01eld and kept only tweets\noriginating from an of \ufb01cial twitter client. Third-party clients represents a variety of\napplications, form applications mainly used by professional for automating some\ntasks (e.g. sprinklr.com ordlvrit.com ) to manually programmed bots, and are used\nto post \u22648% of the total number of tweets. When a programmatic access to Twitter\nis gained through its API to send tweets, the value of the source \ufb01eld of automated\ntweets corresponds to the name, which must be unique, given to the \u201cApp\u201dduring\nthe creation of access tokens. Supplementary Table 14 shows the clients we\nconsider as of \ufb01cial and the corresponding number of tweets with URLs originating\nfrom each client. The number of tweets with a URL originating from of \ufb01cial clients\nrepresents 82% of the total number of tweets with a URL. This simple method\nallows to identify tweets that have not been automated and scales very easily tolarge datasets contrary to more sophisticated methods\n39. Indeed, Botometer is not\nwell suited for historical data as it requires several tweets per users (up to 200) and\nresults of a Twitter search of tweets (up to 100) mentioning each users, which we\ncannot do retroactively. We compared our method with the results of Botometer\n(see Methods section of ref.27) and found that our method has a good accuracy but\nsuffer from a relatively high number of false positive compared to Botometer.\nAdvanced bots might not be detected by our method, but this is also a problem for\nmore advanced methods that relies on a training set of known bots39. We removeall tweets sent from non-of \ufb01cial clients when computing the activity of supporters\nbut we keep them when building the retweet networks, as we want to includeautomated accounts that play a role in the diffusion of news.\nNews outlets classi \ufb01cation . Among the 55 million tweets with URLs linking\noutside of Twitter, we identi \ufb01ed tweets directing to websites containing fake news\nby matching the URLs \u2019hostname with a curated list of websites, which, in the\njudgment of a media and communication research team headed by Melissa Zim-\ndars of Merrimack College, USA, are either fake, false, conspiratorial, or mis-leading. The list, freely available at www.opensources.co , classi \ufb01es websites in\nseveral categories, such as \u201cFake News \u201d,\u201cSatire \u201d,o r\u201cJunk Science \u201d. For our study,\nwe construct two non-overlapping set of websites: fake news websites and extre-\nmely biased websites. The set of fake news website is constructed by joining the\nhostnames listed under the categories \u201cFake News \u201dand\u201cConspiracy Theory \u201dby\nwww.opensources.co . The following de \ufb01nitions of these two categories are given at\nwww.opensources.co\n\u25cf\u201cFake News \u201d: sources that entirely fabricate information, disseminate\ndeceptive content, or grossly distort actual news reports,\n\u25cf\u201cConspiracy Theory \u201d: sources that are well-known promoters of kooky\nconspiracy theories.\nThe set of extremely biased websites contains hostnames appearing in the\ncategory \u201cExtreme Bias \u201d(de\ufb01ned as sources that come from a particular point of\nview and may rely on propaganda, decontextualized information, and opinions\ndistorted as facts by www.opensources.co ) but not in any of the categories used to\nconstruct the set of fake news. Hostnames in each categories along with the number\nof tweets with a URL pointing toward them are reported in Supplementary Table 1.\nWe discard insigni \ufb01cant outlets accumulating less than 1% of the total number of\ntweets in their category.\nWebsites classi \ufb01ed in the extremely biased (right) category, respectively\nextremely biased (left) category, have a ranking between right bias and extreme\nright bias, respectively left and extreme left, on mediabiasfactcheck.com . The bias\nranking on www.allsides.com of these same websites is right, respectively left\n(corresponding to the most biased categories of www.allsides.com ). The website\nmediabiasfactcheck.com also reports a level of factual reporting for each websites\nand we \ufb01nd that all the websites classi \ufb01ed in the extremely bias category have a\nlevel of factual reporting which is mixed or worse. We also \ufb01nd that all the websites\nremaining in the fake news category have a bias between right and extreme right on\nmediabiasfactcheck.com . The website www.allsides.com rates media bias using a\ncombination of several methods such as blind surveys, community feedback, and\nindependent research (see www.allsides.com/media-bias/media-bias-rating-\nmethods for a detailed explanation of the media bias rating methodology used by\nAllSides), and mediabiasfactcheck.com scores media bias by evaluating wording,\nsourcing, and story choices as well as political endorsement (seeTable 4 Causal effects between the top spreaders and the candidates supporters\n\u2199 Pro-Clinton Pro-Trump Fake news Extreme bias (right) Right\nPro-Clinton 0.65 \u00b1 0.01 0.14 \u00b1 0.01 0.029 \u00b1 0.007 0.021 \u00b1 0.006 0.002 \u00b1 0.006\nPro-Trump 0.11 \u00b1 0.02 0.46 \u00b1 0.01 0.009 \u00b1 0.006 0.003 \u00b1 0.001 0.0014 \u00b1 0.0009\nFake news 0.015 \u00b1 0.003 0.10 \u00b1 0.01 0.14 \u00b1 0.01 0.05 \u00b1 0.01 0.03 \u00b1 0.01\nExtreme bias(right)0.02 \u00b1 0.01 0.009 \u00b1 0.002 0.03 \u00b1 0.01 0.21 \u00b1 0.01 0.04 \u00b1 0.01\nRight 0.009 \u00b1 0.002 0.025 \u00b1 0.008 0.03 \u00b1 0.01 0.02 \u00b1 0.01 0.18 \u00b1 0.01\nRight leaning 0.018 \u00b1 0.008 0.038 \u00b1 0.008 0.02 \u00b1 0.01 0.01 \u00b1 0.01 0.07 \u00b1 0.01\nCenter 0.04 \u00b1 0.01 0.023 \u00b1 0.010 0.021 \u00b1 0.007 0.0020 \u00b1 0.0007 0.009 \u00b1 0.008\nLeft leaning 0.04 \u00b1 0.01 0.015 \u00b1 0.006 0.003 \u00b1 0.001 0.0010 \u00b1 0.0005 0.009 \u00b1 0.007\nLeft 0.03 \u00b1 0.01 0.03 \u00b1 0.01 0.010 \u00b1 0.008 0.002 \u00b1 0.001 0.01 \u00b1 0.01Extreme bias (left) 0.08 \u00b1 0.01 0.03 \u00b1 0.02 0.031 \u00b1 0.009 0.03 \u00b1 0.01 0.0025 \u00b1 0.0008\n\u2199 Right leaning Center Left leaning Left Extreme bias (left)\nPro-Clinton 0.003 \u00b1 0.001 0.065 \u00b1 0.008 0.062 \u00b1 0.008 0.017 \u00b1 0.009 0.006 \u00b1 0.006\nPro-Trump 0.0020 \u00b1 0.0009 0.038 \u00b1 0.006 0.033 \u00b1 0.008 0.020 \u00b1 0.007 0.015 \u00b1 0.006\nFake news 0.06 \u00b1 0.01 0.037 \u00b1 0.009 0.016 \u00b1 0.002 0.014 \u00b1 0.008 0.022 \u00b1 0.009\nExtreme bias (right) 0.06 \u00b1 0.01 0.039 \u00b1 0.009 0.018 \u00b1 0.002 0.026 \u00b1 0.009 0.027 \u00b1 0.009\nRight 0.09 \u00b1 0.01 0.044 \u00b1 0.009 0.016 \u00b1 0.002 0.0026 \u00b1 0.0009 0.033 \u00b1 0.008\nRight leaning 0.22 \u00b1 0.01 0.042 \u00b1 0.009 0.033 \u00b1 0.009 0.0014 \u00b1 0.0008 0.0027 \u00b1 0.0008\nCenter 0.012 \u00b1 0.010 0.266 \u00b1 0.009 0.18 \u00b1 0.01 0.019 \u00b1 0.010 0.013 \u00b1 0.008\nLeft leaning 0.005 \u00b1 0.003 0.18 \u00b1 0.01 0.299 \u00b1 0.009 0.012 \u00b1 0.008 0.003 \u00b1 0.002\nLeft 0.015 \u00b1 0.008 0.08 \u00b1 0.01 0.10 \u00b1 0.01 0.164 \u00b1 0.010 0.07 \u00b1 0.01\nExtreme bias (left) 0.005 \u00b1 0.009 0.034 \u00b1 0.009 0.045 \u00b1 0.009 0.03 \u00b1 0.01 0.27 \u00b1 0.01\nWe show the value of the maximal causal effect ICE;max\ni!j\u00bcmax0<\u03c4/C20\u03c4maxICE\ni!j\u00f0\u03c4\u00de/C12/C12/C12/C12/C12/C12between each pair ( i,j) of activity time series, where \u03c4max=18 \u00d7 15 min =4.5 h is the maximal time lag considered, with\nstandard errors (s.d., see Methods). The arrows indicate the direction of the causal effect. For each activity time series, we indicate in bold the thr ee most important drivers of activity (excluding\nthemselves)NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 11\nmediabiasfactcheck.com/methodology for an explanation of Media Bias Fact Check\nmethodology).\nA potential issue with the methodology of OpenSources is the blurring of the\nassessment of \u201cbias,\u201dwhich has to do with news content, with the assessment of\n\u201cestablishment \u201d, which has to do with news form. Speci \ufb01cally, their steps 4 \u20136\nindicate they count thinks like use of the Associated Press style guide and the\nproduction quality of the website. These criteria thus con \ufb02ate adherence to\nestablishment norms \u2014which are likely to be correlated with things like budgets for\nprofessional design, fact-checking, editorial oversight etc. \u2014with lack of bias. That\nis, if two media sites present the same news, but one does it in a less established\nformat, it may be considered \u201cextremely biased. \u201dFor this reason, we manually\nreassessed the bias of each website in the extreme bias categories on\nmediabiasfactcheck.com andallsides.com to validate their bias, as these two\nwebsites do not list the rejection of the establishment as a criteria for their biasassessment. However, even if we do not use the criteria of adherence or rejection of\nthe establishment in our classi \ufb01cation, websites in the extreme bias (right) and\nextreme bias (left) categories are more likely to not adhere with the establishment\nas this variable seems to be highly correlated with political bias.\nIn order to validate our classi \ufb01cation, we compare it to the domain-level\nideological alignment scores of news outlets obtained by Bakshy et al.\n22which is\nbased on the average self declared ideological alignment of Facebook users sharing\nURLs directing to news outlets. We \ufb01nd a R2=0.9 for the linear regression\nbetween the ideological alignment found by Bakshy et al. and our classi \ufb01cation\nwhere we mapped our categories between \u22123 and 3 (see Supplementary\nFig. 6). Supplementary Data \ufb01le SuppData_top_urls_per_category.csv contains the\ntop 10 URLs of each media category along with notes about their classi \ufb01cation on\nfact-checking websites (when available), links to the fact-checking websites, andadditional information. We observe that the classi \ufb01cation of the most popular\nURLs is well aligned with the label assigned to their domains.\nWe investigate the in \ufb02uence and importance of news at the domain level and\nnot at the article level. Since a website classi \ufb01ed as fake may contain factual articles\nand vice versa, domain-level classi \ufb01cation implies a level of imprecision. However,\nit allows us to reveal the integrated effect of news outlets over more than 5 months\nand to measure the relative importance of each type of news by classifying all URLs\ndirecting to important news outlets. Moreover, classifying domains instead of URL(or article) allows to consider the extended effect of each type of news. Indeed,\nwhen a Twitter user follows a URL to a news article containing factual information\non a website publishing mostly fake news, she/he will be exposed to the otherarticles containing fake news on the websites. Therefore, this particular fact-based\nnews ultimately increases the potential in \ufb02uence of fake news.\nCollective in \ufb02uence algorithm in directed networks . We use the CI algorithm\n32\napplied to directed networks to \ufb01nd the most in \ufb02uential nodes of the information\nretweet networks. The CI algorithm is based on the solution of the optimal per-colation of random networks which consists of identifying the minimal set of\nnodes, the super-spreaders, whose removal would dismember the network in many\ndisconnected and non-extensive components. The fragmentation of the network is\nmeasured by the size of the largest connected component, called the giant com-\nponent of the network. The CI algorithm considers in \ufb02uence as an emergent\ncollective property, not as a local property such as the node \u2019s degree, and has been\nshown to be able to identify super-spreaders of information in social networks\n40,41.\nHere, we consider a directed version of the algorithm where we target the super-sources of information.\nThe procedure is as follows\n40:w e\ufb01rst compute the value of CI\u2018;out\u00f0i\u00defor all\nnodes i=1,\u2026,Nas\nCI\u2018;out\u00f0i\u00de\u00bc kout\u00f0i\u00de/C01 \u00f0\u00deX\nj2\u2202Bout\u00f0i;\u2018\u00de\nkout\u00f0j\u00de>0kout\u00f0j\u00de/C01 \u00f0\u00de ;\n\u00f01\u00de\nwhere \u2018is the radius of the ball around each node we consider, here we use \u2018\u00bc2,\nkout(i) is the out-degree of node i, and \u2202Bout\u00f0i;\u2018\u00deis the set of nodes situated at a\ndistance \u2018from node icomputed by following outgoing paths from i. The node\nwith the largest CI\u2018;outvalue is then removed from the network and the value of\nCI\u2018;outof nodes whose value is changed by this removal is recomputed. This\nprocedure is repeated until the size of the weakly connected largest componentbecomes negligible. The order of removal of the nodes corresponds to the \ufb01nal\nranking of the network top news spreaders shown in Table 3.\nA comparison of the ranking obtained by the CI algorithm with rankings\nobtained by considering out-degree (high degree centrality) and Katz centrality\n42\n(Supplementary Fig. 7) shows that high degree (HD) and Katz rankings of the top100 CI spreaders fall mostly within the top 100 ranks of these two other measures\nwith only a small number of top CI spreaders having a poor HD or Katz ranking.\nNote that the CI algorithm is especially good at identifying in \ufb02uential nodes that\nare locally weakly connected but are in \ufb02uent on a larger scale\n32.\nTime series processing .W e \ufb01nd that a 15 min resolution offers a suf \ufb01ciently\ndetailed sampling of Twitter activity. Indeed, a representative time scale of Twitter\nactivity is given by the characteristic retweet delay time, i.e. the typical time\nbetween an original tweet and its retweet. We \ufb01nd that the median time of theretweet delay distribution in our dataset is 1 h 57 min and the distribution has a\nlog-normal shape ( \ufb01rst quartile at 20 min and third quartile at 9 h 11 min). We\ntested the consistency of our results using a resolution of 5 min and 1 h and did not\nsee signi \ufb01cant changes.\nIn order to perform the cross-correlation and causality analysis of the activity\ntime series, we processed the time series to remove the trend and circadian activity\ncycles and to deal with missing data points. For each missing data points, we\nremove the entire day corresponding to the missing observation in order to keepthe period of the circadian activity consistent over the entire time series. This is\nnecessary to apply \ufb01ltering technique to remove the periodic component of the\ntime series. When removing an entire day, we consider that the day starts and ends\nat 4 a.m., corresponding to the time of the day with lowest Twitter activity. We\nremoved a total of 24 days, representing 15% of our observation period. We thenapplied an STL (seasonal-trend decomposition procedure based on Loess)\n33\nprocedure to extract the trend, seasonal and remainder components of each activitytime series. We only consider the remainder components for the cross-correlationand causality analysis. We set the seasonal period of the STL \ufb01lter equal to the\nnumber of observations per day, n\np=96, and the seasonal smoothing period to\nns=95, such that the seasonal component is smooth and the remainder component\nretains the higher frequency signal containing the activity of interest. Varying the\nvalue of the smoothing period to ns=47 does not change signi \ufb01cantly the results.\nCausal analysis . The STL procedure removes the trend and circadian pattern in\nthe time series, resulting in stationary time series (the stationarity of each time\nseries is con \ufb01rmed by an augmented Dickey \u2013Fuller test43). Before performing the\ncausal analysis, we also standardized each time series in order to remove any\nin\ufb02uence of the difference in absolute values of time series. The causal analysis is\nperformed using the entire time period (more than 5 months) and therefore reveals\ncausal effects that are observed \u201cin average \u201dover the entire time period.\nIn order to infer the causal relations between the activity of the top news\nspreaders and the supporters, we use a multivariate causal discovery algorithm\nbased on the PC algorithm35and further adapted for multivariate time series by\nRunge et al.28,36,44. Considering an ensemble of stochastic processes Xthe\nalgorithm proceeds as follows. First, for every time series Y\u2208Xthe sets of\npreliminary parents is constructed by testing their independence at a range of timelags:P\nYt\u00bcXt/C0\u03c4j0<\u03c4/C20\u03c4max;Yt?=Xt/C0\u03c4 fg . As this set also contains indirect links,\nthey are then removed by testing if the dependence between Ytand each X\u03c42PYtvanishes when it is conditioned on an incrementally increased set of conditions\nPn;i\nYt/C18PYt, where nis the cardinality of Pn;i\nYtandiis the index iterating over the\nnumber of combinations of picking nconditions from PYt. The combinations of\nparents having the strongest dependence in the previous step are selected \ufb01rst28,44.\nThe main free parameters are the maximum time lag \u03c4maxand the signi \ufb01cance\nlevel of the independence test used during the \ufb01rst step to build the set of\npreliminary parents which we set to \u03b1PC=0.1. We set the value of the maximum\ntime lag to \u03c4max=18 time steps (i.e. 270 min) as it is the lag after which the lagged\ncross-correlations between each time series falls below 0.1 in absolute value (seeSupplementary Figs. 8 \u201311). We set the maximum number of tested combinations\nof the conditioning set to 3 and we do not limit the size of the conditioning set.\nWe test the conditional independence of time series with the non-parametric\nRCoT test\n38. This test uses random Fourier features to approximate the kernel-\nbased conditional independence test KCIT37and is at least as accurate as KCIT\nwhile having a run time that scales linearly with sample size38. This point is crucial\nfor our case given the size of our dataset (13,152 time points \u00d7 10 time series \u00d7 18\ntime lags). We set the number of Fourier features to nf=400.\nWe select the signi \ufb01cant \ufb01nal causal links by applying a Benjamini \u2013Hochberg\nFalse Discovery Rate (FDR) correction45to the p-values of the conditional\nindependence tests with a threshold level of 0.05. FDR corrections allow to controlthe expected proportion of false positive. The \ufb01nal causal links, i.e. parents of each\ntime series, are reported in Supplementary Table 15.\nFollowing the procedure of refs.\n28,46, We then regress a linear model:\nXt\u00bcX\u03c4max\n\u03c4\u00bc1\u03a6\u00f0\u03c4\u00deXt/C0\u03c4\u00fe\u03b5t; \u00f02\u00de\nwhere all time series are standardized and only coef \ufb01cients corresponding to true\ncausal links are estimated while all the other ones are kept equal to zero, i.e.\n\u03a6ij(\u03c4)\u22600 only for Xi\nt/C0\u03c4!Xj\nt. The causal effect between a time series XiandXjat a\ntime delay \u03c4can be computed from the regressed coef \ufb01cients as\nICE\ni!j\u00f0\u03c4\u00de\u00bc\u03a8ij\u00f0\u03c4\u00de; \u00f03\u00de\nwhere\u03a8(\u03c4) is computed from the relation \u03a8\u00f0\u03c4\u00de\u00bcP\u03c4\ns\u00bc1\u03a6\u00f0s\u00de\u03a8\u00f0\u03c4/C0s\u00de, with\n\u03a6(0)=I. Here,\u03a8ij(\u03c4) gives the sum over the products of path coef \ufb01cients along all\ncausal paths up to a time lag \u03c4. The causal effect ICE\ni!j\u00f0\u03c4\u00derepresents the expected\nvalue of Xj\nt(in unit of standard deviation) if Xi\nt/C0\u03c4is perturbed by one standard\ndeviation28.\nTo reconstruct the causal network, we are interested in the aggregated effects\nand therefore use the lag with maximum effect:\nICE;max\ni!j\u00bcmax\n0<\u03c4/C20\u03c4maxICE\ni!j\u00f0\u03c4\u00de/C12/C12/C12/C12/C12/C12: \u00f04\u00deARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n12 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications\nWe estimate the standard errors of each causal effects with a residual-based\nbootstrap procedure (similarly to ref.28). We employ 200 bootstrap surrogates time\nseries generated by running model (2) with a joint random sample \u03b5/C3\nt(with\nreplacement) of the original multivariate residual time series \u03b5tand compute the\nstandard deviation of the ICE;max\ni!jvalues.\nCode availability . The analysis and plotting scripts allowing to reproduce the results\nof this paper are available at https://github.com/alexbovet/information_diffusion .T h e\nPython module used for the network analysis (graph-tool) is available at https://\ngraph-tool.skewed.de . The causal discovery algorithm software (TIGRAMITE) is\navailable at https://jakobrunge.github.io/tigramite . The code for the conditional\nindependence test (RCIT and RCoT software) is available at https://github.com/\nericstrobl/RCIT . The code for the LOESS processing is available at https://github.com/\njcrotinger/pyloess .\nData availability\nThe raw Twitter data cannot be directly shared as it would infringe the Twitter\nDeveloper Terms. However, we are sharing the tweet IDs of the data we collected\nwhich allows anyone to download the tweets used for this study directly from\nTwitter using Twitter's API. The datasets analyzed in this study are available underthe limits of Twitter \u2019s Developer Terms at http://kcore-analytics.com . The classi-\n\ufb01cation of news as \u201cfake\u201dnews or \u201cextremely biased \u201dnews is a matter of opinion,\nrather than a statement of fact. This opinion originated in publically availabledatasets from fact-checking organizations (i.e. www.opensources.co ). The conclu-\nsions contained in this article should not be interpreted as representing those of the\nauthors.\nReceived: 17 March 2018 Accepted: 19 November 2018\nReferences\n1. Allcott, H. & Gentzkow, M. S ocial Media and Fake News in the 2016\nElection (National Bureau of Economic Research, Cambridge, MA, 2017).\n2. Soll, J. The long and brutal history of fake news. Politico ,https://www.politico.\ncom/magazine/story/2016/12/fake-news-history-long-violent-214535 (2016).\n3. Howell, L. et al. Digital wild \ufb01res in a hyperconnected world. WEF Rep. 3,\n15\u201394 (2013).\n4. Bessi, A. et al. Science vs conspiracy: collective narratives in the age of\nmisinformation. PLoS ONE 10, e0118093 (2015).\n5. Bessi, A. et al .Viral misinformation. In Proc. of the 24th International\nConference on World Wide Web 355\u2013356. (ACM Press, New York, New York,\nUSA, 2015).\n6. Mocanu, D., Rossi, L., Zhang, Q., Karsai, M. & Quattrociocchi, W. Collective\nattention in the age of (mis)information. Comput. Hum. Behav. 51, 1198 \u20131204\n(2015).\n7. Bessi, A. et al. Trend of narratives in the age of misinformation. PLoS ONE 10,\ne0134641 (2015).\n8. Bessi, A. et al. Homophily and polarization in the age of misinformation. Eur.\nPhys. J. Spec. Top. 225, 2047 \u20132059 (2016).\n9. Del Vicario, M. et al. The spreading of misinformation online. Proc. Natl\nAcad. Sci. USA 113, 554\u2013559 (2016).\n10. Del Vicario, M., Gaito, S., Quattrociocchi, W., Zignani, M. & Zollo, F. Public\ndiscourse and news consumption on online social media: a quantitative, cross-\nplatform analysis of the Italian Referendum. Preprint at http://arxiv.org/abs/\n1702.06016 (2017)\n11. Shao, C., Ciampaglia, G. L, Flammini, A. & Menczer, F. Hoaxy: a platform for\ntracking online misinformation. In Proc. of the 25th International Conference\nCompanion on World Wide Web 745\u2013750. (ACM Press, New York, New York,\nUSA, 2016).\n12. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online.\nScience 359, 1146 \u20131151 (2018).\n13. Shao, C. et al. Anatomy of an online misinformation network. PLoS ONE 13,\n1\u201323 (2018).\n14. Bessi, A. et al. Users polarization on Facebook and Youtube. PloS ONE 11,\n1\u201324 (2016).\n15. Kumar, S., West, R. & Leskovec, J. Disinformation on the web. In Proc. of the\n25th International Conference on World Wide Web 591\u2013602. (ACM Press,\nNew York, NY, USA, 2016).\n16. Del Vicario, M., Scala, A., Caldarelli, G., Stanley, H. E. & Quattrociocchi, W.\nModeling con \ufb01rmation bias and polarization. Sci. Rep. 7, 40391 (2017).\n17. Askitas, N. Explaining opinion polarisation with opinion copulas. PLoS ONE\n12, e0183277 (2017).\n18. Klayman, J. & Ha, Y.-W. Con \ufb01rmation, discon \ufb01rmation, and information in\nhypothesis testing. Psychol. Rev. 94, 211\u2013228 (1987).19. Qiu, X. et al. Limited individual attention and online virality of low-quality\ninformation. Nat. Hum. Behav. 1, 0132 (2017).\n20. Schmidt, A. L. et al. Anatomy of news consumption on Facebook. Proc. Natl\nAcad. Sci. USA 114, 3035 \u20133039 (2017).\n21. Del Vicario, M., Zollo, F., Caldarelli, G., Scala, A. & Quattrociocchi, W.\nMapping social dynamics on Facebook: the Brexit debate. Soc. Netw. 50,6\u201316\n(2017).\n22. Bakshy, E., Messing, S. & Adamic, L. A. Exposure to ideologically diverse news\nand opinion on Facebook. Science 348, 1130 \u20131132 (2015).\n23. Lee, K., Eoff, B. D. & Caverlee, J. Seven months with the devils: a long-term\nstudy of content polluters on Twitter. In Proc. of the 5th International AAAI\nConference on Weblogs and Social Media 185\u2013192. (AAAI, 2006).\n24. Bessi, A. & Ferrara, E. Social bots distort the 2016 U.S. Presidential election\nonline discussion. First Monday 21,https://doi.org/10.5210/fm.v21i11.7090\n(2016).\n25. Ferrara, E., Varol, O., Davis, C., Menczer, F. & Flammini, A. The rise of social\nbots. Commun. ACM 59,9 6\u2013104 (2016).\n26. Shao, C. et al. The spread of low-credibility content by social bots. Nat.\nCommun. 9, 4787 (2018).\n27. Bovet, A., Morone, F. & Makse, H. A. Validation of Twitter opinion trends\nwith national polling aggregates: Hillary Clinton vs Donald Trump. Sci. Rep. 8,\n8673 (2018).\n28. Runge, J. et al. Identifying causal gateways and mediators in complex spatio-\ntemporal systems. Nat. Commun. 6, 8502 (2015).\n29. Barth\u00e9lemy, M., Barrat, A., Pastor-Satorras, R. & Vespignani, A. Velocity and\nhierarchical spread of epidemic outbreaks in scale-free networks. Phys. Rev.\nLett. 92, 178701 (2004).\n30. Vespignani, A. Modelling dynamical processes in complex socio-technical\nsystems. Nat. Phys. 8,3 2\u201339 (2011).\n31. Goel, S., Watts, D. J. & Goldstein, D. G. The structure of online diffusion\nnetworks. In Proc. of the 13th ACM Conference on Electronic Commerce Vol. 1,\n623\u2013638. (SIGecom, 2012).\n32. Morone, F. & Makse, H. A. In \ufb02uence maximization in complex networks\nthrough optimal percolation. Nature 524,6 5\u201368 (2015).\n33. Cleveland, R. B., Cleveland, W. S., McRae, J. E. & Terpenning, I. STL: a\nseasonal-trend decomposition procedure based on loess. J. Off. Stat. 6,3\u201373\n(1990).\n34. Margolin, D. B., Hannak, A. & Weber, I. Political fact-checking on Twitter:\nwhen do corrections have an efect? Political Commun. 35, 196\u2013219\n(2018).\n35. Spirtes, P., Glymour, C. & Scheines, R. Causation, Prediction, and Search (MIT\nPress, Cambridge, MA, 2000).\n36. Runge, J., Heitzig, J., Petoukhov, V. & Kurths, J. Escaping the curse of\ndimensionality in estimating multivariate transfer entropy. Phys. Rev. Lett.\n108, 258701 (2012).\n37. Zhang, K., Peters, J., Janzing, D. & Schoelkopf, B. Kernel-based conditional\nindependence test and application in causal discovery. Preprint at http://arxiv.\norg/abs/1202.3775 (2011).\n38. Strobl, E. V., Zhang, K. & Visweswaran, S. Approximate kernel-based\nconditional independence tests for fast non-parametric causal discovery.Preprint at http://arxiv.org/abs/1702.03877 (2017).\n39. Varol, O., Ferrara, E., Davis, C. A., Menczer, F. & Flammini, A. Online\nhuman-bot interactions: detection, estimation, and characterization. In Proc.\nof the 11th International AAAI Conference on Weblogs and Social Media280\u2013289. (AAAI Publications, 2017).\n40. Morone, F., Min, B., Bo, L., Mari, R. & Makse, H. A. Collective In \ufb02uence\nAlgorithm to \ufb01nd in \ufb02uencers via optimal percolation in massively large social\nmedia. Sci. Rep. 6, 30062 (2016).\n41. Teng, X., Pei, S., Morone, F. & Makse, H. A. Collective in \ufb02uence of multiple\nspreaders evaluated by tracing real information \ufb02ow in large-scale social\nnetworks. Sci. Rep. 6, 36043 (2016).\n42. Katz, L. A new status index derived from sociometric analysis. Psychometrika\n18,3 9\u201343 (1953).\n43. MacKinnon, J. G. Approximate asymptotic distribution functions for unit-\nroot and cointegration tests. J. Bus. Econ. Stat. 12, 167\u2013176 (1994).\n44. Runge, J., Sejdinovic, D. & Flaxman, S. Detecting causal associations in large\nnonlinear time series datasets. Preprint at http://arxiv.org/abs/1702.07007\n(2017).\n45. Benjamini, Y. & Hochberg, Y. Controlling the false discovery rate: a practical\nand powerful approach to multiple testing. J. R. Stat. Soc. Ser. B 57, 289\u2013300\n(1995).\n46. Eichler, M. & Didelez, V. On Granger causality and the effect of interventions\nin time series. Lifetime Data Anal. 16,3\u201332 (2010).\nAcknowledgements\nA.B. thanks the Swiss National Science Foundation (SNSF project P2ELP2_165158)\nand the Flagship European Research Area Network (FLAG-ERA) Joint TransnationalNATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2 ARTICLE\nNATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications 13\nCall\u201cFuturICT 2.0 \u201dfor the \ufb01nancial support provided and R. Lambiotte for helpful\ncomments.\nAuthor contributions\nH.A.M. and A.B. conceived the project and wrote the manuscript. A.B. performed theanalysis and prepared \ufb01gures.\nAdditional information\nSupplementary Information accompanies this paper at https://doi.org/10.1038/s41467-\n018-07761-2 .\nCompeting interests: H.A.M. has shares in KCore Analytics, LLC. The remaining author\ndeclares no competing interests.\nReprints and permission information is available online at http://npg.nature.com/\nreprintsandpermissions/Publisher \u2019s note: Springer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional af \ufb01liations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the CreativeCommons license, and indicate if changes were made. The images or other third partymaterial in this article are included in the article \u2019s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in thearticle \u2019s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder. To view a copy of this license, visit http://creativecommons.org/\nlicenses/by/4.0/ .\n\u00a9 The Author(s) 2019ARTICLE NATURE COMMUNICATIONS | https://doi.org/10.1038/s41467-018-07761-2\n14 NATURE COMMUNICATIONS |            (2019) 10:7 | https://doi.org/10.1038/s41467-018-07761-2 | www.nature.com/naturecommunications", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Influence of fake news in Twitter during the 2016 US presidential election", "author": ["A Bovet", "HA Makse"], "pub_year": "2019", "venue": "Nature communications", "abstract": "The dynamics and influence of fake news on Twitter during the 2016 US presidential election  remains to be clarified. Here, we use a dataset of 171 million tweets in the five months"}, "filled": false, "gsrank": 58, "pub_url": "https://www.nature.com/articles/s41467-018-07761-2", "author_id": ["rbHfk1EAAAAJ", "Xa30RAUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:gk3Wn2sAgiUJ:scholar.google.com/&output=cite&scirp=57&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D50%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=gk3Wn2sAgiUJ&ei=DbWsaIjTFLTWieoP1pCJ2AY&json=", "num_citations": 1301, "citedby_url": "/scholar?cites=2702723188618841474&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:gk3Wn2sAgiUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41467-018-07761-2.pdf"}}, {"title": "Comparative Sentiment Analysis of Media Bias", "year": "NA", "pdf_data": "Masaryk  University \nFaculty of Arts \nDepartment  of English \nand American  Studies \nEnglish  Language and Literature \nJana Rojkov\u00e4 \nComparative  Sentiment  Analysis  of \nMedia  Bias \nBachelor's  Diploma  Thesis \nSupervisor:  Mgr.  Irina  Matusevich \n2018 \n\nI declare that I have worked on this thesis independently, \nusing only the primary and secondary sources listed in the bibliography. \nAuthor's  signature \n\nAcknowledgement \nFirstly,  I would  like to express my sincere gratitude to my supervisor  Mgr.  Irina \nMatusevich  for her guidance and patience.  My thanks also  goes  to my  family  and friends \nfor their continuous support and encouragement. \n\nTable  of Contents \nAcknowledgement  3 \nTable  of Contents 4 \nList of Tables 7 \nList of Figures 9 \n1. Introduction 1 \n1.1 Key  Terms 2 \n1.1.1 Media  bias 2 \n1.1.2 Wedge  issue  3 \n2. Literature Review 5 \n3. Methodology 12 \n3.1 Data  Collection  13 \n3.2 Wedge  Issue  Selection 16 \n3.3 Retrieval of  Articles  IV \n3.4 Sentiment  Analysis  21 \n3.5 Syntax  Analysis  25 \n3.6 Data Processing 26 \n4. Results and Discussion 29 \n4.1 Article  Statistics 29 \n\n4.1.1 Mainstream media 29 \n4.1.2 Alternative left-leaning media 30 \n4.1.3 Alternative right-leaning media 31 \n4.1.4 Total number of retrieved articles 32 \n4.2 Sentiment  Analysis  33 \n4.3 Syntax  Analysis  37 \n4.4 Discussion 42 \n4.4.1 Negative  average  article  sentiments  42 \n4.4.2 Comparison of identified article  sentiments  43 \n4.4.3 Shared word frequency 44 \n5. Limitations and Further Research 45 \n5.1 Selected News Outlets and Wedge  Issues  45 \n5.2 Data Quality and Sample Size 45 \n5.3 Quotations 46 \n5.4 Artificial  Intelligence 46 \n5.5 Suggestions for Further Research 47 \n6. Conclusion 48 \nReferences 49 \nSummary 52 \nResum\u00e9  53 \n\nAppendix  A 54 \nImplementation 54 \nRuntime configuration and instructions 57 \nEvent Registry API Key 58 \nGoogle  Natural Language API Key 58 \nConfiguration  file 59 \nExecution  60 \nAppendix  B 61 \nRaw data  and statistical  outputs  61 \nAppendix  C 63 \n\nList of Tables \nTable  1. Mainstream media news outlets  page  ranking and number of monthly \nunique  visitors  14 \nTable  2. Alternative left-leaning media news outlets  page  ranking and number of \nmonthly  unique visitors 15 \nTable  3. Alternative  right-leaning media news outlets  page  ranking and number of \nmonthly  unique visitors 15 \nTable  4. Mapping  of news outlets to  URLs  used in Event Registry API article \nsearch 20 \nTable  5. Mapping  of wedge issues to  DMOZ  taxonomy categories for Event \nRegistry  API article search 21 \nTable  6. Distribution  and sums of retrieved articles for mainstream media news \noutlet category 30 \nTable  7. Distribution  and sums of retrieved articles for left-leaning alternative \nmedia  news outlet category 31 \nTable  8. Distribution  and sums of retrieved articles for right-leaning alternative \nmedia  news outlet category 31 \nTable  9. Average article sentiment score per wedge issue for news outlet groups \nwith differences between news outlet groups 35 \nTable  10. Average article sentiment score adjusted by sentiment magnitude per \nwedge issue for news outlet groups  with  differences between news outlet groups 36 \nTable  11. Sums and statistics of unique words by wedge issue and news outlet \ngroups  with  sentiment 38 \n\nTable  12. Sums and statistics of unique words by news outlet group and wedge \nissues  with  sentiment 38 \nTable  CI. Detailed  average article sentiment data  with  additional  information  for \nmainstream  media news outlets 65 \nTable  C2.  Detailed  average article sentiment data  with  additional  information  for \nalternative  left-leaning media news outlets 67 \nTable  C3.  Detailed  average article sentiment data  with  additional  information  for \nalternative  right-leaning  media news outlets 69 \n\nList of Figures \nFigure  1. NLAPI  sentiment analysis output  visualization. 23 \nFigure  2. NLAPI  syntax analysis output  visualization. 26 \nFigure  3. Total  number of  retrieved  articles  per wedge issue 32 \nFigure  4. Average article sentiment score  per wedge issue  for each news outlet \nFigure  5. Average article sentiment score adjusted  with  sentiment magnitude  per \nFigure  6. Number  of shared words  in the top 75  most used words between \nmainstream  and alternative media  for wedge issues and positive/negative sentiments  40 \nFigure  7. Number  of shared words  in the top 75  most used words between \nmainstream  and alternative media  for wedge issues and positive/negative sentiments  41 \nFigure  Al. Screenshot  of entire package structure  of Sentiment  Analyzer \napplication  57 category 33 \nwedge issue  for news outlet groups. 36 \n\n1. Introduction \nThe media plays a  pivotal  role in not  only  keeping the general populace informed on \ncurrent  matters  but also in shaping the public discourse on important ongoing  debates. \nBecause of this capacity to directly influence informedness and by extension, the generally \nheld opinions by the public as  well  as the decision-making process of voters, the necessity \nfor unbiased information is apparent in democratic societies.  While  most Americans  agree \non the importance of media for democracy, increasingly few trust the media in actually \nfulfilling  that  role (Ritter & Jones, 2018).  With  the perception of biased coverage in the \nUnited  States  consistently on the rise (Jones & Ritter, 2018) and charges of bias by both \nRepublicans  as well  as Democrats leveled at the media ever since its conception, research \non the topic has  long  been a matter of  great  interest in a wide range of  fields. \nDespite  the considerable body of research on everything  from  the various sources of \nmedia  bias to its effects on the public at large, the scholarly community has been  still \nlargely  unable to  definitively  measure the presence of systematic media bias as  well  as fully \nestimate its direction. The main reason for  that  being the  difficulty  to conceptualize a \nmethodology  void  of human subjectivity and without a need for defining what exactly \nconstitutes a balanced coverage. The lack of  conclusive  and well-founded results up to this \ntime thus  merits further research into this area of study through an approach  that avoids the \npitfalls  of previously used methods.  This  thesis expands on the body of knowledge  from \nprevious  studies by attempting to measure the bias of the mainstream media news outlets in \nthe United  States  as it manifests in their language use in relation to the language use of the \nalternative left-leaning and right-leaning news outlets. Despite the fact  that  this study \nattempts  to measure bias along  ideological  lines it is not the purpose of this study to make \n1 \n\ndefinitive  claims of conservative or  liberal  bias as was an aim of numerous preceding \nstudies, but rather to gauge  patterns  of similarities and differences in the framing of \nparticular  wedge issues by various news outlets. \nThe main body of the thesis is composed of  six themed chapters. In the remainder of \nthis chapter, a  brief  introduction  of key terminology  utilized  throughout the thesis is offered \nalong  with  the assumptions the thesis is based on. The second chapter contains an overview \nof the results of a selected few previous  empirical  studies on media bias  including  the \nstrengths  and deficiencies in their methodology and positions the study into the context of \nrelevant literature. The particular methods used to obtain the data of the study and their \njustification  are clarified  in Chapter 3. Chapter 4 gives an account of the results of the study \nwith a corresponding discussion on the findings. The subsequent chapter \u2014 Chapter 5 \noutlines the limitations of the study. Chapter 6  presents  a conclusion  as well  as suggestions \nfor further research. \n1.1 Key Terms \nThis section defines the key terminology and outlines the fundamental assumptions \nupon  which  the rest of the thesis builds. \n1.1.1 Media  bias. \nThere are various  academically  recognized types of media bias categorized by either \nthe many different sources  from  which  a media bias is hypothesized to originate or by the \nform  in which  a bias manifests. It is, therefore,  crucial  to establish an operational  definition \n2 \n\nof the term throughout this thesis to prevent confusion on what exactly is the object of \nstudy. As the types of media bias according to the sources of their  origination  are currently \nnearly  impossible to be measured  empirically  and thus, stay at the  level  of research \nemploying  theoretical models, the focus  will be on its manifestation. Waldman and Devitt \n(1998), for instance, define media bias as \"any systematic slant favoring one candidate or \nideology  over another\" (p. 302). For the purposes of this study, the aforementioned \ndefinition  will  be narrowed down to  denote  the conceptualization of bias as a  form  of \nsystematic  ideological  position-taking  by framing of covered issues through particular word \nchoice.  Nevertheless, in their article, Waldman and Devitt (1998) did not specify the \nreference point for systematicity of media bias. For  that reason, the benchmark for what \nconstitutes a systematic bias in this study has been established to be accounted for by the \nscope and magnitude of the sample size. \n1.1.2 Wedge  issue. \nDespite  the term 'wedge issue' emerging in the  political  discourse of the general \npublic  on a day-to-day basis and the existence of a commonly accepted understanding of its \nmeaning by most members of the society, not a lot of academic literature  attempts  to \nconceptualize  the precise use of the term. A few scholars, however, did embark on the \nendeavor to delineate its scope. Notably, Wiant (2002) in his work on wedge issues in \npolitical  discourse  asserts,  that a wedge issue constitutes \"an issue whose  only  purpose is to \ncreate  political  division\"  (p. 277). He further  argues  that  these  issues  cause  a division \namong the electorate through the use of \"code words,  labeling,  and others  [sic]  strategies  in \norder to gain  political  advantage\" (p. 277).  Similarly,  Wardt,  Vries,  and  Hobolt  (2014) \n3 \n\ncorroborate this  definition  with  an emphasis on the importance of wedge issues as a major \nfactor  influencing  the decision making of voters (p. 987). Throughout this thesis, the term \n'wedge issue'  will  thus  denote any  politically  divisive  issue as outlined in the paper by \nWiant  (2002). \n4 \n\n2. Literature  Review \nThis literature review examines the previous research in the area of media bias and \nconcludes on how it pertains to the methodological proceedings of this thesis. It offers a \ncross-section  view  of key studies and analyses conducted on the topic  that utilized  different \nmethods, each  with  different  advantages  and disadvantages. The suppositions and \nconclusions  of each study are  critically  evaluated. To specify more clearly, the goal of this \nliterature review is to identify the  gaps  in the  empirical  research on the topic and justify the \nmethodology  of this thesis  which  builds upon the body of  existing  research. \nTo date,  numerous studies have attempted to investigate the existence of media bias \nthrough  empirical  measures. To begin  with,  in his 2003 study,  Niven  analyzed media bias \nthrough comparing the favorability of newspaper coverage of  U.S.  Congress members who \nunderwent a change in their party  affiliation.  The baseline for the comparison was the act of \npolitical  party switching itself,  which  Niven  (2003) considered a  valid  form  of measure  by \nvirtue  of it being an \"equivalent  political  behavior\" (p. 316).  Building  on this assumption, \nan equal  treatment  of party switchers was expected should the media be unbiased or, by the \nsame  token, a difference in sympathies if media bias has been observed.  Niven  (2003) \nanalyzed  the coverage of four then-recently members of  U.S.  Congress who changed their \nparty  affiliation  with  a total of 470 different news articles included in the examination. The \narticles  were evaluated by two coders, who estimated a positive or a negative  tone  of the \ncoverage of each of the congress members. The results of the study provide no statistically \nsignificant  evidence of media bias in favor of any of the congress members, parties or \nideologies  (pp. 321-322).  With  that  in mind,  the study has several shortcomings  which \nsomewhat weaken the significance of its findings,  with  the first one being its sample size. \n5 \n\nThe study focused on coverage of  only  four Congress members and analyzed  only  470 \narticles,  which  is a rather  small  sample  that  cannot account for the influence of external \nfactors, such as personal and  political  scandals of the selected congressmen, their public \nreputation and the popularity of issues they supported or stood up against,  which  might \nhave played a role in the  overall  coverage. The second  limitation  is the  difficulty  of \ndetermining  a fair baseline for a comparison. Despite its claims of switching  political \nparties as being a comparable measure, it is not necessarily the case. There might have been \nvarious  different reasons and motivations for the members of Congress to switch parties \nand these  motivations might not have been comparable and, as such, might have \nsignificantly  influenced the news coverage. To illustrate, a party switch because of a \nprincipled  political  position might  generate  a vastly different coverage on both sides of the \npolitical  spectrum compared to a party switch motivated by  financial  or special interest \nreasons. The study does  little  to address  that  limitation.  The third issue is the potential \nsubjectivity  of the two coders who evaluated the selected articles (be it conscious or \nunconscious).  Despite the  attempts  to address the partiality of the coders by calculating the \nvalue  of Scott's Pi of 0.85 between the results of the two coders, the  limitation  was not \nresolved,  especially because no additional information on the coders was provided,  which \ncould,  for instance, reveal the reason for the  high-reliability  check result to be the  similarity \nof their subjective bias. \nA study by Groseclose and  Milyo  (2005) arrived at quite a different  conclusion  than \nthe one performed by  Niven  (2003).  This  study claimed to have found a heavy  liberal  bias \npresent in the coverage by  U.S.  media (p. 2). Their main method consisted of comparing \nthe number of citations or references to various think tanks (both  liberal  and conservative) \nby members of the  U.S.  Congress. The Congress was,  thus  used as a relative baseline to \n6 \n\nwhich  the reference  patterns  of the media were compared. Despite avoiding the limitations \nof a small  sample size as used in the aforementioned 2003 study by  Niven  by examining a \nsufficiently  large data set, some of the  criticisms  of the previous study applies  here  as well. \nFirst and foremost, the study calculates  ADA  scores for various news outlets and compares \nthem  with  the ADA  scores for various members of Congress who cited one of the observed \nthink  tanks. As the ADA (Americans for Democratic  Action)  is itself  a left-leaning \nprogressive organization, it is safe to assume  that  any score they assigned to the members \nof Congress was informed by their progressive agenda. Furthermore, the  usage  of the \ncitations and references of think tanks as a baseline for comparing media bias is the main \nproblematic  aspect of their methodology. To illustrate, the researchers do not at any point in \ntheir work address the extent to  which  the news coverage constitutes of  citing  think tanks \nand thus, do not account for the actual salience of such reporting behavior. If a selection of \narticles  that  utilizes citations frequently is juxtaposed to those who do so rarely, the \nidentified  bias  will  likely  be on the side of the journalists and news outlets  that  employ \ncitations on a more regular basis for no particular reason. If such disparity exists, \noverlooking  this specific piece of the puzzle  will invariably  lead to skewed findings. \nMore  recently, a 2016 study by Budak,  Goel,  and Rao attempted to quantify media \nbias through a combination of machine learning and crowdsourcing of content analysis. \nThe study used a machine learning algorithm to  filter  out political  articles  from  more than \n800 000 news stories published in 2013 taken  from  fifteen  U.S.  publishers. It then had 749 \nparticipants to evaluate almost 11 000 randomly selected articles and  classify  them \naccording  to expressed slant as either positive or negative. No strong evidence of media \nbias in the coverage other than the natural expected  ideological  differences between \nparticular  news outlets  with  a proclaimed partisan leaning was found. They did, however, \n7 \n\nobserve an interesting pattern in the manifestation of the  ideological  differences between \nthe various news outlets \u2014 namely,  that  it tends  to manifest \"not by advocating for a \npreferred party but rather by  criticizing  one side more frequently\" (Budak,  Goel  & Rao, \n2016,  p. 16).  This  study, in contrast to the two previously mentioned studies and thanks to \nthe use of machine learning, amassed vast amounts of data for its analysis.  Using \ncrowdsourced  volunteers, however, is considered a serious weakness in the article slant \nevaluation,  which  is something the authors themselves acknowledge in the paper \u2014  \"This \napproach facilitates far greater scale and diversity of workers, but also raises concerns \nregarding data quality. For instance, the  small  partisan differences we observe across \noutlets ...  could  simply  reflect  limited  political  awareness of workers\" (Budak et al., 2016, \np. 8). On the other hand, the study took several  steps  to mitigate the possible negative \nimpact  on data quality. For instance, they restricted volunteer participation to the  United \nStates, filtered volunteers by their score on the used  crowdsourcing  platform, required them \nto pass  a test of political  knowledge as  well  as other additional measures outlined in their \nmethodology  (p. 254). Despite this approach  significantly  increasing the  validity  of \nacquired  data and the  overall  study results, it does not completely dismiss  these  worries. \nNot to mention the fact  that  the study does not define what exactly constitutes a neutral \narticle,  or an article  with  left- or right-leaning slant for  that matter  which  is a major issue, as \nwithout  unified  and clearly defined standards, the significance of the study remains \nquestionable. \nOne of the more complex and comprehensive studies of media bias was conducted \nin 2015 by  Niculae  et al. In order to identify the character of media bias as  well  as the \nextent to  which  it is exhibited  systematically,  the paper  uses  \"a framework based on quoting \npatterns\" for its estimation (Niculae et  al, 2015). The proposed framework was executed on \n8 \n\na collection  of more than 220 000 articles  from  275 news outlets  that  contain quotes of \nBarack  Obama over the six years of his presidency.  Unlike  other studies mentioned \npreviously,  this one does not rely on human evaluation and instead entirely utilizes natural \nlanguage processing and machine learning algorithms. The study builds two analyses, one \nsmall-scale  and focused, the other large-scale and quantitative. The focused study served as \na controlled proof-of-concept, data  verification  and unsupervised training exercise for the \nneural  network,  while  the large-scale analysis was then  utilized  to analyze the entire \ndataset.  It further used multiple advanced techniques to process and the analyze data, such \nas an outlet-to-quote graph construction and an analysis, a low-rank approximation, a \nsentiment and a  lexical  analysis as  well  as a lot more. They identified a bias in conservative \nnews outlets  that  manifested in their quotation  patterns  of Obama's speeches to portray him \nin a negative light. Not  only  was the bias detected, the trained neural network was able to \nactually  predict quotation  patterns  of different news sources without making any prior \nassumptions,  which  further  solidified  the study's conclusion. At the same time, one major \nlimitation  still persists. The study proclaims to have measured a systematic  ideological  bias \nin the mainstream conservative outlets as it, presumably, compares to an objective baseline \nof neutral coverage. The concept of neutral coverage is ambiguous and unmeasurable as \none can never account for those instances where a neutral coverage equals a negative \ncoverage. In other words, it does not  find a solution for  filtering  the instances where reality \nand facts necessitate a negative sentiment. Furthermore, the decision to handle Obama's \nspeeches as a news item on  which  a differing  coverage is equivalent to systematic negative \nbias by a media outlet  with  self-proclaimed  ideological  leaning is questionable as it is \nfarfetched to proclaim the speeches by one particular person to be representative of an \nentire party or an ideology. \n9 \n\nComparatively,  a recent study  from  Stanford conducted by Sholar and Glaser (2016) \nutilizes  machine learning in a fashion  similar  to that of Budak  et al. (2016). Instead of using \na crowdsourced approach to data analysis, however, they used a so-called  Multinomial \nNaive  Bayes and Support  Vector  Machine models to train machine learning classifiers to \nmap article titles and keywords to news sources. It improves on the study by  Niculae  et al. \n(2015) through the  utilization  of Event Registry  API to fully  automate acquired articles and, \nas such, draws  from  a pool  of more than 1 126 news outlets. The study found a significant \ncorrelation  between the most \"indicative keywords\" (p. 2) of  individual  news outlets as \nidentified  by their methods and the generally accepted  political  inclination  of that  outlet, \nbut did not  attempt  to measure  patterns  of coverage across various  politically  aligned \noutlets in order to make claims of systematic bias by the media. They, however, did initiate \nan early conceptualization of the general direction of analysis required to measure media \nbias void  of \"subjective metrics\" in the future. \nTaken  together, all  these  different studies, approaches, methodologies and results \nprovide  evidence  that  objective identification and quantification of bias is a rather \nchallenging  endeavor. A more exhaustive  list of the most common limitations of  empirical \nstudies on research bias is outlined in  Groeling  (2013). He identifies  three  major problems \nwith measuring media bias: the  difficulty  to define an objective baseline against  which  bias \nshould  be compared; the issue of what he terms an \"unobserved  population\"  which  denotes \nthe portion of published articles excluded  from  the analysis  which  translates to skewed \nfindings  in some direction and the problem of personal subjectivity in some  steps  of the \nanalysis  (Groeling,  2013, pp. 137-139). Be as it may, as some of the most recent examples \nof studies included in this literature review prove  that these  issues can be addressed or at \nleast avoided and  that better  methods of measuring bias are being constantly hypothesized \n10 \n\nand developed. The recent advancements in the  field  of natural language processing, \nmachine learning, and  artificial  intelligence are helping  researchers  to overcome  these \nchallenges by increasing their data collection capabilities and removing human bias and \npartiality  from the evaluation of data. This thesis  attempts  to do exactly  that  by building \nupon this body of previous research by expanding on some of the outlined methodologies to \npursue its ambitions while avoiding some of the shortcomings of previous studies in order \nto further the current knowledge on the topic of media bias. \n11 \n\n3. Methodology \nThe aim of this thesis was to  gauge  media bias as it manifests in the  level  of \nsimilarity  of language use between the mainstream media and both the alternative left-\nleaning  and the alternative right-leaning media in the  United  States  by performing a \ncomparative sentiment analysis of collected articles on selected  politically  divisive  issues. \nAs the online media  allow  for a  greater  technical feasibility of retrieval of news items as \nwell as for an easier aggregation of a much larger sample of articles, the data was \naccumulated from  digital  media exclusively in order to  amass  a representative sample. \nWhere the methodology of this study differs from a large portion of some of the previous \nresearch attempting to  measure  media bias is in its endeavor to  measure  bias without a need \nfor establishing some form of a subjective baseline for objectivity or neutrality  that  could \ndiminish  the significance of the findings as theorized by  Groeling  (2013) (see Chapter 2). \nTo solidify  the objectivity further, the research design included the  utilization  of natural \nlanguage processing to perform a complex sentiment analysis  that  derived sentiment from \nboth the  individual  words as  well  as the context they occur in avoiding, thus, the \ninterference of human subjectivity. The actual analysis was then performed in several \nsequential  steps.  The first requirement was the download of articles based on the criteria \ndescribed in later sections of this chapter. Once the articles were downloaded and stored, a \nsentiment and a syntax analysis of the articles was performed. The  final  step  was the \nevaluation  of the acquired data itself. The motivation behind each  part  of the overall \nanalysis and different tools and techniques employed in the analysis are described more \nthoroughly in the  following  sections of this chapter. \n12 \n\n3.1 Data Collection \nThe analysis was performed on a statistically significant selection of online \npublished  articles selected  from  a representative sample of  three  media types recognized for \ncomparative purposes throughout the study \u2014 the mainstream media, the alternative left-\nleaning  media and the alternative right-leaning media.  Five  media outlets were selected for \neach of the  three  categories, totaling fifteen different news outlets altogether. The \nmainstream media in the  United  States  were represented by Fox News,  CNN,  The New \nYork  Times,  The Washington Post and The  Wall  Street Journal. \nDue to the fact  that  news outlets exist on a continuum as opposed to a clear and \ndefined  alternative-mainstream media dichotomy, it is impossible to define a set of \ngenerally  accepted criteria a media outlet  would  have to meet in order to  fall under the \nclassification  of alternative  with  an absolute certainty. (Rauch, 2016, p. 757) Thus, for the \npurposes of this research, the alternative media were selected based on being a generally \nsmaller-scale  news outlets  that  do not  claim  to provide a neutral perspective on covered \nnews events and whose goal is to supply for the market demand for a news coverage  from  a \nparticular  political  perspective leaning closer to the  political  extremes. \nIn order to ensure both alternative left- and right-leaning outlets are equally far  from \nthe positions of balanced coverage, the study takes into account a classification of media \noutlets constructed by a media bias and fact-checking website mediabiasfactcheck.com \nwhich  uses  multiple variables in their methodology to determine the  overall  political \nleanings of a particular news outlet. The  Daily  Beast,  Vox,  Slate, Raw Story and Mother \nJones constitute selected alternative left-leaning media  while  The  Blaze,  The  Daily  Caller, \nBreitbart  News,  Reason.com  and World  Net  Daily  were selected to represent the alternative \n13 \n\nright-leaning media.  Additionally,  a page  ranking and an estimated number of unique \nmonthly visitors was retrieved from a website tracking, monitoring and analysis service \nalexa.com  in order to determine the line between the mainstream and the alternative media \nby virtue of the  sheer  number of their audience. It is important to  note  that data  on both \nmediabiasfactcheck.com  and on alexa.com  are continually updated based on new  data  and \nare, as such, subject to change. Information from both services for each  individual  news \noutlet selected for this thesis is summed in Table 1, Table 2 and Table 3 below and was \ncollected  on 1st of  March,  2018. \nThe data  show a visitor disparity between the mainstream and the alternative media \nand for the alternative media indicate their position on the  political  spectrum according to \nmediabiasfactcheck.com . The  tables  below have  five  columns (with the exception of Table \n1) containing: a news outlet, website  URL,  ranking, bias and the number of visitors. The \ncontent of the first two columns is self-evident from their headings. The column ranking \ncontains  page  ranking for each news outlet among other U.S. websites according to \nalexa.com  and the column bias  represents  the estimated media bias according to \nmediabiasfactcheck.com . The  final  column, visitors, contains the estimated number of \nunique monthly visitors according to  Alexa.com . \nNews  outlet Website Ranking Visitors \nFox News https://foxnews.com 63 24 812 028 \nCNN https://cnn.com 25 41 788 639 \nNew  York  Times https://www.nytimes.com 31 43 345 290 \nWashington Post https://www.washingtonpost.com 53 34 662 165 \nWall  Street  Journal https://www.wsj.com 155 13 325 171 \nTable  1. Mainstream  media  news  outlets  page  ranking  and number  of monthly  unique  visitors. \n14 \n\nNews  outlet Website Ranking Bias Visitors \nSlate https://slate.com 366 Left 6 768 171 \nThe Daily  Beast https://www.thedailybeast.com 291 Left 8 939 954 \nVOX https://www.vox.com 331 Left 8 110 497 \nRaw Story https://www.rawstory.com 1 092 Left 2 132 491 \nMother  Jones https://www.motherjones.com 1 482 Left 2 799 544 \nTable  2. Alternative  left-leaning  media  news  outlets  page  ranking  and number  of monthly  unique  visitors. \nNews  outlet Website Ranking Bias Visitors \nBreitbart  News http ://www.breitbart.com 71 Right 4 229 274 \nThe Daily  Caller http ://dailycaller.com 207 Right 2 252 949 \nThe Blaze https://www.theblaze.com 1 359 Right 1 690 014 \nReason.com https://reason.com 3 459 Right 837 912 \nWorldNetDaily http://www.wnd.com 1 099 Right 2 752 650 \nTable  3. Alternative  right-leaning  media  news  outlets  page  ranking  and number  of monthly  unique  visitors. \nTo improve the accuracy of the analysis and prevent selection of  wholly  unrelated \narticles as  well  as ensure  contemporary relevance of the articles,  date,  count and content \nfilter  criteria were applied to all articles.  Only  the articles  that  were published in the time \nperiod  between 1st of January, 2014 and 1st of January 2018 and are listed  chronologically \nfrom newest  to oldest, in order to  ensure  that the latest  articles were consistently preferred \nand invariably selected for the  purposes  of the research. \nThe general topic of an article was  another  crucial criterion when determining the \neligibility  of any particular article for the study. Each selected article covered one of the \n15 \n\npredetermined topics of interest \u2014 a particular wedge issue in contemporary  U.S.  politics \n\u2014 the selection of  which  is covered in the  subsequent  section of this chapter. \nA few limitations on the number of retrieved articles were imposed.  Firstly,  a \nmaximum  of 200 articles per each news outlet and a wedge issue combination was \nrequired,  while  simultaneously the total  minimum  of articles for every wedge issue and a \nnews outlet category was 800.  This  criterion helped  limit  an overrepresentation of any \nparticular  news outlet in the study by virtue of  having  written an unusually  high  number of \narticles  on any  specific  wedge issue,  while  at the  same  time it guaranteed  that  the maximum \ndifference  between any two types of news outlets on any  given  wedge issue was 200 \narticles  (from a theoretical maximum of 2 000 articles retrieved)  which  amounts to \nstatistically  acceptable 10% difference. These limitations guaranteed a balanced sample \nfrom each news outlet and for each category. Based on the aforementioned criteria the \nexpected number of retrieved unique articles was between 12 000 and 15 000. \n3.2 Wedge  Issue  Selection \nThe wedge issues used in this thesis were selected as a representative sample of \nimportant and increasingly  divisive  topics in contemporary  U.S.  politics  based on a 2017 \nGallup  analysis of  attitudes  of Americans  (Newport and Dugan, 2017). The  following  five \nissues  listed  in the aforementioned  Gallup  poll were selected  from  the list of issues where \nthe partisan  division  grew over the  past  decade:  immigration,  gun laws (gun  control),  global \nwarming  (climate change), healthcare and abortion. Number of selected issues was  limited \nto five  in order to keep the  overall  data sample in manageable size (based on the \nmethodology  and data requirements  listed  in previous section, each selected issue amounts \n16 \n\nto a collection  of 3 000 articles under ideal circumstances) and the above mentioned issues \nwere selected arbitrarily. A  greater  division  on a particular wedge issue directly  translates \ninto a less nuanced view on the topic by both sides of the opinion and  thus,  presumably, a \nless nuanced coverage on the topic as the alternative media  cater  to their  target  audience by \nreflecting  the views of their readership. This should allow for a clearer  assessment  of levels \nof dissimilarity in language use by virtue of the position-taking reflecting in the word \nchoice.  As a consequence, the results should not only be less fuzzy but also  greater  in \nsalience. Furthermore, covering multiple  areas  of division  helped in both ensuring the \nsystematicity of examined bias and accounting for the  cases  of single-issue bias by a \nparticular news outlet. Any such deviation would have been  visible  in the data. \n3.3 Retrieval  of Articles \nIn order to obtain raw  data  for the  subsequent  analysis, articles were retrieved from \nselected news outlets. Several options were available to accomplish this objective, with \nvarying  degrees  of implementation and execution complexity. Each of the considered \noptions had its  advantages  and disadvantages and for each option, multiple tools were \navailable  for its execution. The options could be classified into  three  main  methods  of \nexecution \u2014 manual retrieval of articles, a  utilization  of a website crawler, and a  utilization \nof a news aggregation service. \nWhile  the manual retrieval of articles would be the  easiest  out of the  three  methods \nto implement in  terms  of technical requirements, it was deemed unfit for any further \nconsideration due to being too prohibitive timewise and  thus,  ineffective. \n17 \n\nThe second method, a website crawler is a piece of software  that  can be  utilized  to \nautomatically  scan websites for  links  and subsequently, download their content. One of the \nbest and the most popular available open-source website crawlers designed  specifically  to \nidentify  and download articles and their metadata  from  news outlets is newsplease \n(https://github.com/fhamborg/news-please ). Although  generally a  great  and a powerful  tool, \nthere  were  three  concerns raised  that made its use less than ideal for its intended purpose. \nThe crawler retrieved data  from  websites at the time of  execution,  which  meant articles  that \nwere unpublished, deleted or  modified  between the  date  of their  publishing  and the  date  the \nwebsite crawler was used to retrieve data for the thesis, were  simply  lost. The second and a \nmore significant concern was the fact  that  website  crawling  is a  fairly  slow  and lengthy \nprocess. A  small  proof-of-concept  crawl  was performed on the website foxnews.com  which \nhelped  demonstrate  that  even after 16 hours since the  initiation,  the crawling  process was \nstill running.  This  meant data retrieval  from  all news outlets  would  take anywhere between \none and two weeks, provided no errors  would  occur during the process. The third setback \nwas not on the part of the website crawler itself, but rather on the part of the crawled \nwebsites. A significant number of the websites considered  crawling  to be an unwanted \nbehavior  that  could  potentially be  classified  as violating  their terms of service, and thus, \nmany of them contained countermeasures  which  prevented large-scale automated  crawling \nof their content  which  further  solidified  this method as unsuitable for the study. \nThe third option was to make use of a news aggregation service. A  great  advantage \nof such approach in comparison to a website crawler was in the fact  that  the crawling  itself \nwas already performed by the aggregation service and data retrieval was a matter of a \nsimple  search in an already existing  database.  This  specific approach was proven to be \n18 \n\norders of magnitude faster than  that  of a conventional website crawler in addition to \nallowing  for the use of advanced data  filtering. \nA news aggregation web service  utilized  for this purpose throughout the study and \nchosen  by virtue of being one of the  best  available services was Event Registry. A  similar \napproach  which  utilized  Event Registry was used in the study Sholar and Glaser (2016) \nreferenced and evaluated in the literature review chapter of this thesis. Developed by a \ngroup of data scientists in partnership  with  Laboratory for  Artificial  Intelligence at Institut \nJozef  Stefan,  Slovenia  and  Machine  Learning  Lab at Federal  University  of Sao  Carlos, \nBrazil,  it collects data  from  more than 30 000 news publishers  worldwide.  Event Registry \nutilizes  machine learning and natural language processing to analyze, process and \ncategorize collected data and provides high-performance search over a huge  database  of \narticles.  The search allows to narrow down the scope of retrieved data by various criteria, \nsuch as news outlet, keywords and  DMOZ  taxonomy categories  (DMOZ, \ndomain.mozilla.org , is a  multilingual  directory of websites organized into more than a \nmillion  categories). For overcoming all the previous complications  with  manual retrieval \nand website  crawling  and for numerous additional functional advantages, Event Registry \nwas determined an  ideal  choice for the requirements of this thesis. \nIn order to search Event Registry for  specific  news outlets and wedge issues, it was \nnecessary to map the selected news outlets to a  URL  address.  This  mapping is  listed  in \nTable  4 below: \n19 \n\nNews outlet -> Event  Registry  URL \nFox News -> https://foxnews.com \nCNN \u2014> https://edition.cnn.com \nNew  York  Times -> https://nytimes.com \nWashington  Post -> https://washingtonpost.com \nWall  Street  Journal -> https://wsj.com \nSlate -> https://slate.com \nThe Daily  Beast -> https://thedailybeast.com \nVOX -* https://vox.com \nRaw Story -> https://rawstory.com \nMother  Jones -* https://motherjones.com \nBreitbart  News -> https://breitbart.com \nThe Daily  Caller -* https://dailycaller.com \nThe Blaze -> https://theblaze.com \nReason.com -> https://reason.com \nWorldNetDaily -> https://wnd.com \nTable  4. Mapping  of news outlets  to URLs  used in Event Registry  API article search. \nSimilarly  to the  mapping of news outlets in Table  4 above,  the wedge issues had  to \nbe mapped  to DMOZ  categories in order to be used in Event Registry search.  This  mapping \nis listed in Table 5 below: \n20 \n\nWedge  Issue -> DMOZ  Taxonomy  Category \nAbortion -> dmoz/Society/Issues/Abortion \nGun Control -> dmoz/Society/Issues/Gun_Control \nHealthcare -> dmoz/Society/Issues/Health \nImmigration -\u00bb dmoz/Society/Issues/Immigration \nClimate  Change \u2014> dmoz/Science/Environment/Climate_Change \nTable  5. Mapping  of wedge  issues  to DMOZ  taxonomy  categories  for Event Registry  API  article search. \nEvent Registry returned the  following  information for each article it returned: the \nURL  address  of where the article can be accessed, the  date  and time of publication, the title, \nand body of the article, publisher information along  with  additional  metadata  that  were \nirrelevant for this analysis. \n3.4 Sentiment  Analysis \nIn more general  terms,  sentiment  analysis is a  process  that  combines  text  analysis, \ncomputational linguistics, natural  language  processing and machine learning to extract \nsentiment  information and affective  states  expressed by the  author  of a certain  text.  The \npurpose  of the  sentiment  analysis in this  thesis  was to identify emotions and  sentiments \nexpressed in retrieved articles and then perform the  same  analysis  individually  for each \nsentence  in each article. \n21 \n\nTwo methods were considered for sentiment analysis portion of the thesis: a rather \nsimple  pattern-matching approach, and much more advanced  utilization  of natural language \nprocessing  and machine learning. \nA pattern-matching approach, where words  from  an article  could  be mapped onto a \npredefined  database  consisting of words and their general sentiments, is somewhat \nrudimentary. An example of such a  database  that  was considered for the study was \nSentiWordNet  3, a  database  of more than 300 000  English  words  with  assigned sentiment \nvalues based on the WordNet  lexical  database.  Two major drawbacks to  utilizing \nSentiWordNet  database  for this purpose were discovered.  Firstly,  the number of words  with \nassignable sentiment values was  limited  to the size of the  database,  which  in case of \nSentiWordNet  3 is a mere 300 000 words and thus,  limits  the number of words  that can be \nevaluated to a very  small  subset of  all words available in the  English  language. The second \nmatter of contention  lied  in the sentiment values of words themselves. As this approach \nconsidered  neither the context of the entire article nor the context of the sentence a \nparticular  word occured in, the sentiment of a word was the same regardless of its context \nand its use by any particular news outlet. Such approach to sentiment analysis  would  by \nextension,  hinder the study  significantly  limited  in both scope and quality and thus, \nsolidified  SentiWordNet  3 as an inadequate means of  conducting  the research. \nA superior choice for conducting sentiment analysis was the  utilization  of natural \nlanguage processing software and machine learning algorithms,  which  was an approach \nsimilar  to the ones explored in the studies by  Niculae  et al. (2015) as  well  as Sholar and \nGlaser  (2016). However, because development of custom natural language processing \nsoftware or creation of custom machine learning neural network is a task  that  is too \ncomplex  for the scope of this thesis, especially when taking into consideration the fact  that \n22 \n\nfully developed  and trained  software  is already  widely  available,  a few  already  existing \noptions  were  considered. \nEvent  Registry,  an aforementioned  service  already  utilized for  article  retrieval \nprovides  a service  for sentiment  analysis  evaluation.  However  to limit  dependency  of the \nresults  of this analysis  on one  single  service  and its  inherent  limitations  such  as bias  of the \nmachine  learning  algorithm  acquired  from its  learning  data,  a use of a  different  tool was \npreferable.  A fairly new and widely  available  service  from Google called  Natural  Language \nAPI (NLAPI)  was  considered  instead.  This  service  was able  to provide  a fast  and  well-\nfunctioning  API for  sentiment  and syntax  analysis  of any  article.  For the  reasons  detailed \nbelow,  Google's  NLAPI  was selected  for the  sentiment  analysis  portion  of the  research. \nFor the  purposes  of demonstrating  how  exactly  this  NLAPI  feature  works,  Figure  1 \nbelow  contains  a visualization of a  sentiment  analysis  on an  arbitrarily  selected  sentence. \nNLAPI  determined  the sentiment  of the  sentence  to be -0.5 on a  scale  of -1 to 1, which \nseems  a fair  value,  given  that  the sentiment  of the  sentence  is objectively  negative. \nDocument & Sentence Level Sentiment \nEntire Document \nDoublethink means the power of holding two contradictory beliefs in one's mind simultaneously, and accepting both of them. \nScars  Range -0.25 \u2014 0.25 \nEntity Level Sentiment \n1.one I \nSentiment: Score 0 Magnitude 0 2 Doublethink B \nSentiment: Sccre-0.1 MagnitudeO! 3, power \nSentiment: Score-0.7 Magnitude 4. beliefs Hi \nSentiment: Score -0.9 Magnitude 0.S \n5. mind \nSentiment: Score 0 MagnitudeO 6. both B \nSentiment: Score-0.1 MagnitudeO! \nFigure  1. NLAPI  sentiment  analysis  output  visualization. \n23 \n\nA sentiment analysis for any given text through  NLAPI  retrieves two important \npieces of information about the text: a sentiment score and a sentiment magnitude. The \nscore indicates the  overall  sentiment of the analyzed text and has a range in an interval  from \n-1 for extremely negative sentiment to +1 for a sentiment  that  is extremely positive. \nDifferent  types of emotions are not distinguished, however, therefore emotions such as \n\"sad\" or \"disappointed\" are both  simply  identified as having negative sentiment value \n(between -1 and 0) and emotions such as \"happy\" or \"excited\" have positive value \n(between 0 and 1). Neutral texts or  mixed  texts  with  both negative and positive values \ncanceling  each other out tend to have a value of around zero. The second important piece of \ninformation,  the magnitude, indicates how much emotional content is present in an article. \nMagnitude  can have values ranging  from  0 for no emotional content in text, to potentially \ninfinity  \u2014 an extremely emotional text of  infinite  length  would  in theory reach magnitude \nof infinity,  however, in reality, such a computation  would  never happen.  Practically \nspeaking,  magnitude  tends  to gain values of few decimal points for short and non-emotional \narticles,  all the way up to about a dozen for articles  long  few hundreds words  with  strong \nemotional  content. Because magnitude is a metric  that works as a function of a length of an \narticle,  it was not the primary input for data evaluation, however, it was considered later in \norder to examine whether the  inclusion  of magnitude into the evaluation had any noticeable \neffect on the results of the analysis. By the same token, a sentiment score was returned for \nevery  individual  sentence in an article. \n24 \n\n3.5 Syntax  Analysis \nAfter  a successful sentiment analysis of all articles and their sentences, additional syntax \nanalysis  was performed on  sentences  with  a strongly negative sentiment (sentiment score \nbetween -1 and -0.75) and  with  a strongly positive sentiment (sentiment score between 0.75 \nand 1). The goal of this analysis was to identify words (nouns, adjectives and verbs) used in \nsentences  with  strong sentiment in different news outlets for different wedge issues and \nlook for similarities or differences between those words in the media. A somewhat  similar \napproach was employed by Sholar and Glaser (2016), who used keyword extraction on \ntheir evaluated data. The difference in the approach taken in this study and the one in \nSholar  and Glaser (2016) is  that instead of representative keywords of the analyzed outlets, \nthe most frequent words were extracted and not  only  evaluated, but also compared between \nthe investigated news outlet types. The syntax analysis was performed through Google's \nNatural  Language  API  (NLAPI). \nThe visualization  in Figure 2 below shows result of syntax analysis performed on \nthe same example sentence  from  the previous section of this chapter.  NLAPI  identified \ndependencies between words, their classification into  parts  of speech, derived their lemma \nand other relevant morphological information. For the purposes of this analysis, the \nfollowing  data about each word in every selected sentence was taken into consideration: \nword's lemma and word's part of speech  (POS)  tag. The analyzed words were stored into a \nlist of words and saved  with  each sentence  that  was analyzed for further processing. \n25 \n\nQ Dependency  Q Parse Label  Q Part  of Speech  Q Lemma  Q Morphology \nnsubj root  det  dobj prep pcomp  rum  amod dobj prep poss  ps  pobj advmod  p cc  conj dobj prep pobj  p \nDoublethink means  the  power  of  holding  two  contradictory beliefs  in one 's  mind simultaneously  , and  accepting both  of  them \nmean hold belief accept \nNOUN VERB  DET  NOUN  ADP  VERB NIJM  AD J  NOUN  ADP NUM PRT  NOUN  ADV  PUNCT CONJ VERB  DET ADP  PRON  PL  NOT \nmnber=\u00a3IN\u00abJL4F imofcKDICATlYE mmber=\u00a3irJGULAF numlnr=  PLURAL  mmbet=ilNflJLAF  cmFiUfflJGffTWE \nFigure  2. NLAPI  syntax analysis output  visualization. \n3.6 Data  Processing \nOnce  all the relevant data were collected, they were evaluated. In order to do so, \nraw data needed to be processed into statistical data, such as information about the number \nof retrieved articles, for each news outlet and wedge issue, aggregated data about article \nsentiments, and evaluation of  word  lists  from  syntax analysis. \nThe statistics about the number of retrieved articles  with  tools described in section \n3.3 of this chapter are organized in a table where columns represent a particular wedge \nissue and rows represent a particular news outlet. The information available in the resulting \ntable includes the total number of articles for each news outlet and wedge issue \ncombination,  a sum of articles for each news outlet category and wedge issue combination, \na sum of articles for each news outlet category  overall,  a sum of articles for each wedge \nissue  overall  and a sum of  all retrieved articles. \nData  from  sentiment analysis described in section 3.4 of this chapter were \naggregated into a table  similar  to the one described in the previous paragraph.  This  table is \nextended  with  additional  columns for data such as the sentiment score sum for  all articles in \n26 \n\nthe news outlet and wedge issue  combination,  average sentiment score (score sum  divided \nby number of  articles),  the sentiment magnitude sum for all articles in the news outlet and \nwedge issue combination, average sentiment magnitude (magnitude sum  divided  by \nnumber of articles), sentiment score adjusted by sentiment magnitude (score times \nmagnitude) and average sentiment score adjusted by average sentiment magnitude (score \ntimes magnitude  divider  by number of  articles). \nFinally,  data  from  word  lists created during syntax analysis described in the section \ndetailing  the syntax analysis were processed. The goal was to  identify  similarities  between \nwords  used by mainstream compared to left- and right-leaning alternative media.  This \nanalysis  has focused  only  on nouns, verbs, and adjectives as  these  are the  parts  of speech \nthat generally carry most of the meaning and sentiment of a  sentence.  Therefore all words \nexcept nouns, adjectives, and verbs were  filtered  out from  the lists.  Additionally,  modal \nverbs,  such as can, be, do, might, have and  would,  were also  filtered  out, since they are \nfairly  common in  English  language and do not  hold  any significant sentiment or meaning, \nand would  therefore not add any value in the comparison between words used by \nmainstream and left- and  right-leaning  alternative media. \nThe remaining words were sorted into 150 lists based on them  belonging  to a unique \ncombination  of originating  news outlet (15 news outlets) and wedge issue (5 wedge issues) \ninto which  article containing the  word  belongs, and sentiment of the  sentence  to which  the \nword  belongs (positive or negative sentiment).  Each  word  had  only  one entry in each  list, \nbut a counter of the total number of occurrences was kept. Words in lists were sorted by the \nnumber of occurrences and the total number of entries in each  list was  limited  to a number \nof most used words. The  specific  number was determined based on the retrieved data in \neach  list to ensure  comparability of the resulting data. These lists were then used to  find \n27 \n\nmost used words  that mainstream media and left-leaning alternative media, and mainstream \nmedia  and right-leaning alternative media, have in common in the way they express a \npositive  and negative sentiment. \n28 \n\n4. Results  and Discussion \nThis chapter is the culmination of efforts  from  previous chapters. The application \ndeveloped  for this thesis as described in  Appendix  A was used to retrieve articles and \nadditional  data based on the methodology described in Chapter 3. The collected data was \nthen processed, analyzed and evaluated, leading to the  final  results and conclusions \narticulated  in this chapter. To keep the text of this thesis comprehensible,  only  the most \nimportant part of the  overall  available data is  included  in this text as figures and tables. The \ncomplete  datasets  can be found as  digital  attachments to this thesis and are  listed  and \ndescribed  in Appendix  B. The collected data and results are  divided  into sections in the \nsame fashion as they are described in the chapter  detailing  methodology. \n4.1 Article  Statistics \nThe final  number of all processed articles returned by Event Registry during \nexecution  was 14 346.  All of the articles combined consisted of 7 271 643 words. The \nfollowing  sections break down the distribution of collected articles between wedge issues \nand news outlets. Tables below provide deeper insight into acquired data and were used to \nidentify  possible discrepancies  that might have affected  comparability  between  individual \ndata groups or  overall  statistical accuracy of consequent analyses. \n4.1.1 Mainstream  media. \nThe search for articles  from  mainstream media news outlets returned a complete set \nof 5000 articles  which  corresponds to the expected quantity outlined in chapter 3. Table 6 \nprovides  an extensive itemization of the distribution for the purpose of easier  visualization \nof the dataset  available for the mainstream media. \n29 \n\nNews  outlet Abortion Gun  Control Healthcare Immigration Climate  Change Total \nfoxnews.com 200 200 200 200 200 1000 \nedition.cnn.com 200 200 200 200 200 1000 \nnytimes.com 200 200 200 200 200 1000 \nwashingtonpost.com 200 200 200 200 200 1000 \nwsj.com 200 200 200 200 200 1000 \nTotal: 1000 1000 1000 1000 1000 5000 \nTable  6. Distribution  and sums  of retrieved  articles  for mainstream  media  news  outlet  category. \n4.1.2 Alternative  left-leaning  media. \nThe news outlet  VOX  was the most significant outlier in the article retrieval and \nreturned only 511 articles compared to the ideal  target  of 1000 articles, lowering the total \nnumber of collected articles to only 4441  which  was less than was  initially  aimed for. \nAlthough  this result is suboptimal, the created discrepancy was addressed through simple \ndata normalization  so that the data  could  be compared on an average per-article basis. Table \n7 offers a breakdown of the retrieved articles for each wedge issue and a news outlet to help \nvisualize  this disparity. \n30 \n\nNews outlet Abortion Gun  Control Healthcare Immigration Climate  Change Total \nslate.com 200 200 200 200 200 1000 \nthedailybeast.com 178 200 200 200 552 930 \nvox.com 61 64 147 158 81 511 \nrawstory.com 200 200 200 200 200 1000 \nmotherjones.com 200 200 200 200 200 1000 \nTotal: 839 864 947 958 833 4441 \nTable  7. Distribution  and sums of retrieved articles for left-leaning alternative media news outlet category. \n4.1.3  Alternative  right-leaning  media. \nThe retrieval  of articles from  the  alternative right-leaning media news outlets \nperformed according  to expectations,  with  only  a minor deviation  for the  news outlet \nReason.com . Regardless,  the difference between  the number  of acquired articles  and the \nideal  expected number  of articles  is under  ten percent (95  out of  1000),  which  lies  within \nthe tolerance levels defined  in the  methodology.  The  extent  of this deviation  can be \nobserved in Table 8 below. \nnews outlet Abortion Gun  Control Healthcare Immigration Climate  Change Total \nbreitbart.com 200 200 200 200 200 1000 \ndailycaller.com 200 200 200 200 200 1000 \ntheblaze.com 200 200 200 200 200 000 \nreason.com 128 200 200 200 177 905 \nwnd.com 200 200 200 200 200 1000 \nTotal: 928 1000 1000 1000 977 4905 \nTable  8. Distribution  and sums of retrieved articles for right-leaning alternative media news outlet category. \n31 \n\n4.1.4 Total  number  of retrieved  articles. \nThe overall  number of retrieved articles for each wedge issue is  visualized  in Figure \n3 below. The retrieval of articles  overall  performed as expected and no issues  that  could \ninfluence  the sentiment and syntax analysis in a statistically significant way were \ndiscovered.  Figure 3  demonstrates  the total magnitude of the data set as  well  as the data set \nfor each wedge issue for an easier understanding of the  final  sample  size. \nTotal number  of retrieved articles  per issue \nI Abortion  | Gun  Control Healthcare  |  Immigration  |  Climate Change \n3000 \n2000 \n1000 \nFigure  3. Total  number of  retrieved  articles per wedge issue \n32 \n\n4.2 Sentiment  Analysis \nThe results of sentiment analysis were evaluated by the average sentiment scores of \nall articles  from  all news outlets grouped by each news outlet category and  are displayed  in \nFigure  4 below. \nAverage article sentiment comparison (Sentiment score) \nI Mainstream Media  | Left-leaning alternative media  |  Right-leaning alternative media \n-0.152 \n-0.16 \n-0-2 \nAbortion Gun Control Healthcare Immigration Climate Change \nFigure  4. Average article sentiment score per wedge issue for news outlet category. \nThree  significant  observable trends were drawn  from  the available data.  The  first \nobservation  derived  from  Figure  4 was  that the average article sentiments were  in close \nvicinity  of zero,  despite the possible attainable range of expressed sentiment ranging  from  -\n1 to 1  and thus,  allowing  for a  greater extent  of sentiment.  Equally  important,  the second \nobservable  trend revealed  all average article sentiments  for all  news outlets groups  and \nwedge issues to be  largely  negative.  Lastly,  the mainstream media had the smallest average \nsentiment value in  comparison  to the alternative  right-leaning  media who managed to reach \n33 \n\nthe largest sentiment value as  well  as the alternative left-leaning media  with  their average \nsentiment value  positioned  in between the two aforementioned categories. \nThese  three  trends in the data suggest  that  regardless of the topic,  there  was a \nconsistent difference of expressed sentiment between the mainstream, the alternative left-\nleaning  and the alternative right-leaning media,  with  the mainstream and the alternative \nleft-leaning  media being much closer to each other in terms of sentiment (29.52% \ndifference)  than the mainstream and the alternative right-leaning media (42.78% \ndifference).  On a side-note, results of the sentiment analysis also revealed  that  articles \nabout abortion had a lot more negative sentiment than articles about any other examined \nwedge issue. The aforesaid result  thus  uncovered a fact  that  articles about abortion used \nmore emotionally loaded language  overall  compared to the other examined wedge issues. \nDetailed  information about article sentiments and their comparisons between news outlet \ngroups are  listed  in Table 9 below. The table contains 10 columns for the  following  data: a \nwedge issue, the average article sentiment for the mainstream media  (Main),  the average \narticle  sentiment for the alternative left-leaning media (left), the average article sentiment \nfor the alternative right-leaning media (right), a difference in sentiment value between the \nmainstream and the alternative left-leaning media (M A  L), that  difference expressed as \npercentage  (M A L (%))  with  the same values for comparison between the mainstream and \nthe alternative right-leaning media  (M A R, M  A R (%)) as  well  as for comparison between \nthe alternative left-leaning media and the alternative right-leaning media (L A R, L A R \n(%)) respectively. \n34 \n\nWedge  issue Main Left Right M A L M A L \n(%) MAR MAR \n(%) LAR LAR \n(%) \nAbortion -0.092 -0.152 -0.16 -0.06 39.47% -0.068 42.50% 0.008 5.00% \nGun  Control -0.084 -0.094 -0.112 -0.01 10.64% -0.028 25.00% 0.018 16.07% \nHealthcare -0.078 -0.088 -0.102 -0.01 11.36% -0.024 23.53% 0.014 13.73% \nImmigration -0.08 -0.09 -0.122 -0.01 11.11% -0.042 34.43% 0.032 26.23% \nClimate  Change -0.006 -0.024 -0.052 -0.018 75.00% -0.046 88.46% 0.028 53.85% \nAverage -0.068 -0.0896 -0.1096 -0.0216 29.52% -0.0416 42.78% 0.02 2.98% \nTable  9. Average  article  sentiment score per wedge issue for news outlet groups  with  differences between \nnews outlet groups. \nAfter  adjusting  the  sentiment score  with  the  sentiment magnitude,  the  results \nyielded  to be quite  similar,  with  only  small  deviations and  an increased average  percentage \ndifferences  from  29.52%  to 37.81% and  from  42.78% up to  55.01%  (data available in Table \n9 and Table 10 respectively). Figure  5 shows changed sentiment values after adjusting  for \nmagnitude,  as opposed  to values without magnitude available in Figure 4.  Similarly,  Table \n10 shows  how  individual  values  and  comparisons have changed after article sentiment \nadjustment for magnitude. \n35 \n\nAverage article sentiment comparison (Sentiment score  x magnitude) \nB Mainstream Media  | Left-leaning alternative media  |  Right-leaning alternative media \n0.5 \n0.016 \nFigure  5. Average  article  sentiment score adjusted  with  sentiment magnitude per wedge issue for \nnews outlet groups. \nWedge  issue Main Left Right MAL MAL \n(%) MAR MAR \n(%) L AR LAR \n(%) \nAbortion -0.73 -1.308 -1.562 -0.578 44.19% -0.832 53.27% -0.254 16.26% \nGun Control -0.598 -0.588 -0.804 0.01 -1.70% -0.206 25.62% -0.216 26.87% \nHealthcare -0.494 -0.67 -0.846 -0.176 26.27% -0.352 41.61% -0.176 20.80% \nImmigration -0.532 -0.592 -1.072 -0.06 10.14% -0.54 50.37% -0.48 44.78% \nClimate  Change 0.016 -0.158 -0.384 -0.174 110.13% -0.4 104.17% -0.226 58.85% \nAverage -0.24 -0.6632 -0.9336 -0.1956 37.81% -0.466 55.01% -0.2704 33.51% \nTable  10. Average  article  sentiment score adjusted by sentiment magnitude per wedge issue for news outlet \ngroups  with  differences between news outlet groups. \n36 \n\n4.3 Syntax  Analysis \nThe syntax analysis was executed on a total of 346 733  sentences  and resulted in a \ndataset  of 420 185 words, 89 148 of  which  came  from  sentences  with  a strong positive \nsentiment, and 331 037 of  which  came  from  sentences  with  a strong negative sentiment. \nConsidering  the results of the sentiment analysis, the overrepresentation of  sentences  with  a \nstrong negative sentiment was expected. The resulting words were sorted into 150 lists of \n75 words each, using the methodology described in Chapter 3. The  limit  of 75 words was \nchosen  as the number at  which  some of the lists began to show a count of repeated  word \nusage  under 5 occurrences, at  which  point  could  these  words be considered an irregularity \nrather than a representative sample of the  overall  language expressions used for  individual \nnews outlets and wedge issues. Table 11 and Table 12 below contain an  overall  number of \nunique words  from  all types of news outlets for each wedge issue, plus an additional \nstatistical  data such as the average values, the standard deviation, and the variance. Table \n11 contains both the positive and the negative sentiment values and statistical information \nfor news outlet groups,  while  Table 12 contains  similar  information for the wedge issues (+ \nindicates  the data for a  positive  sentiment, - indicates the data for a negative sentiment). \n37 \n\nNumber  of unique  words  from all  lists \nWedge  issue Mainstream  + Mainstream  - Left+ Left- Right  + Right  -\nAbortion 236 179 292 173 272 193 \nGun  control 271 224 303 224 281 209 \nHealthcare 245 217 250 213 262 244 \nImmigration 262 215 284 206 272 203 \nClimate  change 260 219 261 234 271 225 \nAVERAGE 255 211 278 270 272 214 \nSTANDARD  DEVIATION 14.06 18.09 21.97 23.27 6.73 20 \nVARIANCE 197.7 327.2 482.5 541.5 45.3 401.2 \nTable  11. Sums and statistics of unique words by wedge issue and news outlet groups  with  sentiment. \nPositive  sent. Number  of unique  words  from all  lists \nWedge  issue Mainstream Left-leaning Right-leaning AVERAGE STD.  DEV. VARIANCE \nAbortion  + 236 292 272 266.67 28.38 805.34 \nAbortion  - 179 173 193 208 28.38 3081 \nGun  control  + 271 303 281 285 16.37 268 \nGun  control  - 224 224 209 243 16.37 1083 \nHealthcare  + 245 250 262 252.34 8.74 76.34 \nHealthcare  - 217 213 244 230.67 8.74 740.34 \nImmigration  + 262 284 272 272.67 11.02 121.34 \nImmigration  - 215 206 203 231 11.02 1281 \nClimate  change + 260 261 271 264 6.08 37 \nClimate  change - 219 234 225 241.34 6.08 716.34 \nTable  12. Sums and statistics of unique words by news outlet group and wedge issues  with  sentiment. \n38 \n\nThese results show significant disparities in standard deviations and the variances \nfor both the news outlet categories (Table 12) as  well  as the wedge issues. The  high \nvariations  in the numbers show  that there  were large differences between the collected data \nand as such, a data  normalization  was  justified.  The lowest number of available words was \n173, which  became the new baseline for a unique words comparison.  Any  words below the \ntop 173 were excluded  from  consideration. Once the data underwent an adjustment, the \nremaining  unique most frequently used words were organized into 27 lists for  individual \nword  sentiment, news outlet group and wedge issue combinations. These were then \ncompared  to find  the number of shared words between the mainstream and the alternative \nleft-leaning  as well  as the mainstream and the alternative right-leaning media respectively. \nThe results of  these  comparisons can be seen in Figure 6 and  Figure  7 below. \n39 \n\nNumber  of shared most used words (mainstream vs alternative \nleft/right leaning media, by sentiment) \nLeft-leaning alternative media Right-leaning alternative media \nAbortion (Positive) \nAbortion (Negative) \nGun Control \n(Positive) \nGun Control \n(Negative) \nHealthcare \n(Positive) \nHealthcare \n(Negative) \nImmigration \n(Positive) \nImmigration \n(Negative) \nClimate Change \n(Positive) \nClimate Change \n(Negative) 88 \n91 \n84 \n82 \n89 \n84 \n83 \n100 105 \n125 \nFigure  6. Number of shared words in the top 75 most used words between mainstream and alternative media \nfor wedge issues and positive/negative sentiments. \n40 \n\nTotal number  of shared most used words (mainstream  vs alternative \nleft/right leaning media) \nI Left-leaning alternative media  | Right-leaning alternative media \n200 \n150 \n100 \n50 \n0 \nAbortion Gun Control Healthcare Immigration Climate Change \nFigure  7. Number of shared words in the top 75 most used words between mainstream and \nalternative media for wedge issues and positive/negative sentiments. \nThe data collected during a syntax analysis and its further processing showed  that \nfour of the  five selected wedge issues, namely abortion, gun  control,  healthcare and climate \nchange, performed according to what  would  be expected based on the results of the \nsentiment analysis \u2014 suggesting  that in these  four wedge issues, the mainstream media and \nthe alternative left-leaning media use  similar  language expressions in sentimentally loaded \nsentences.  The results for  immigration,  however, did not  follow  this pattern. The  cause  of \nthe aforementioned pattern deviation for immigration, along  with  all the additional \nobservations and results of the analysis are discussed in the  following  section of this \nchapter. \n41 \n\n4.4 Discussion \nThe results of this analysis suggest  that  there  are observable  patterns  and trends in \nboth the article sentiments as  well  as in the usage frequency of words when  juxtaposing  the \nmainstream to the alternative left-leaning and the alternative right-leaning media in the \nUnited  States. The  following  section describes each of the observed phenomena, \ncontemplates the  likely  causes, examines the  identified  exceptions and details the possible \nimplications  stemming  from  the acquired data. \n4.4.1 Negative  average  article  sentiments. \nThe first noticeable trend about the sentiments of the retrieved articles is the fact \nthat nearly all of the average sentiment scores for all of the news outlets and wedge issues \nhave a negative value (see Table  CI, Table C2 and Table C3 in  Appendix  C), with  the only \nexceptions among the 75 combinations being The New  York  Times,  The Washington \nPost,The  Wall  Street  Journal  and  VOX  for the wedge issue of  climate  change,  implying  that \nthe overall  news coverage of most of the wedge issues analyzed in this thesis was \npredominantly  negative.  This  finding  supports some of the previous research done in the \narea of  political  science and communication  that deals  with  the negative nature of news \ncoverage.  According  to Trussler and Soraka (2014), who demonstrate  that  consumer \ninterest in news is directly related to the negativity of their content, the prevalence of \nnegative coverage is a direct consequence of news outlets catering to the demand of their \naudience in order to maximize profit, (pp. 373-374) In other words, a more negative \ncoverage of events directly translates to a greater consumer interest,  which  leads to either \nhigher  sales or higher ad revenue. The reasoning behind this phenomenon is based on \n42 \n\nresearch into  a so-called negativity bias,  a sound  biological  and  psychological  theory  that \nshows human brain  is biologically  programmed  to give greater significance  to negative \nemotions compared  to neutral  or positive emotions  (Rozin  & Royzman,  2001; Ito, Larsen, \nSmith  & Cacioppo,  1998). As such, findings in this analysis seem  to align  with  some of the \nexisting  research in  the field. \n4.4.2  Comparison  of identified  article  sentiments. \nThe second trend in  the data analysis can  be seen in  the comparison of the sentiment values \nof individual  types  of news outlets across  all wedge issues  \u2014 specifically,  the relative \nconsistency  of the  differences between them. Figure  6 and  Figure  7 show  that  the \nmainstream media exhibit  the lowest sentiment value across  all wedge issues,  that  the \nalternative right-leaning media exhibit  the highest sentiment value  and the  alternative left-\nleaning  media  lie somewhere  in between.  This  observation  has two  implications:  the \nalternative right-leaning media word choice displays  a significantly  stronger sentiment than \nthe other  two  types,  and  that the average sentiment  for every examined wedge issue  is \ncloser  between  the mainstream and  the alternative left-leaning media than  it is  between  the \nmainstream and  the alternative right-leaning media. As such,  there  are similarities  between \nthe framing  of news  by the  mainstream and  the alternative left-leaning media. Whether this \nfinding  constitutes  an indication of unbalanced news coverage  by the  mainstream media  or \na greater balance  of news coverage  by the  alternative left-leaning media  is impossible  to \nconclude  as there  is no  measurable baseline  to assess  balanced coverage. What  can be \ninferred  with  certainty, however,  is the  reality  that  framing  of particular selected wedge \n43 \n\nissues is less  dissimilar  between the mainstream media outlets and the alternative left-\nleaning  media outlets as opposed to the outlets leaning to the right of the  political  spectrum. \n4.4.3 Shared word  frequency. \nThe third area of interest is based on the most frequently used words  from  each \nnews outlet and subsequently each news outlet type. The goal of this part of the analysis \nwas to identify shared words used by the mainstream and the alternative left-leaning, and \nthe mainstream and the alternative right-leaning media respectively, in emotionally loaded \nsentences  \u2014 either  with  positive or negative sentiment \u2014 and  find patterns  in the data  that \nwould  indicate correlations between  individual  types of news outlets. \nThe results show  relatively  small  differences of around  five to ten percent, but given \nthat many of the most frequent words are used in both negative and positive sentiments \nacross all types of news outlets (for example, the word  \"life\"  belongs to the top 15 most \nfrequently used words in both sentiments and types of news outlets for the topic of \nabortion),  these  small  differences in shared words seem a lot more significant. Therefore, \neven though it is  difficult  to draw hard conclusions  from  the analysis of the shared most \nfrequently used words, it corroborates the sentiment analysis findings and affirms  that  the \nalternative left-leaning media use sentiment and language in a fashion  similar  to the \nmainstream media, at least relative to the alternative right-leaning media. \n44 \n\n5. Limitations and Further  Research \nDespite  the efforts to ensure the  scientific  merit of the  findings,  as in any research, a \nnumber of  limitations  were  identified  and need addressing. \n5.1 Selected  News  Outlets  and Wedge  Issues \nA likelihood  that a difference in the selection process of particular news outlets and \nparticular  wedge issues for the purposes of the study might  yield  divergent results is \nobservable.  This  limitation  stems  from  the need to  amass  a manageable sample size  with \nrespect to computing power and time  complexity.  It is impossible to estimate  with  certainty \nthe magnitude of the impact of this  limitation,  but the truth of the matter is  that a different \nmethodology  in the selection of the input data  could  produce different findings and, by \nextension,  different conclusions. A future research  could  address this  limitation  by using \nmore performant software technologies, optimization of the implemented algorithm and \nmore powerful hardware. \n5.2 Data Quality and  Sample  Size \nAnother  important research  limitation  is the sample size itself.  Although  this study \nworked  with  a reasonably large sample size of almost 14 346 articles, this number is far \nfrom covering all or even most of the articles published  online.  Granted  that to expand the \ncollection  of retrieved articles  could  lead to more accurate results, it does not automatically \nundermine the  validity  of the findings and  could  be remedied in the future research by \n45 \n\nsimply  analyzing  a greater  number  of articles  by expanding  the conditions specified  for \ntheir retrieval. \n5.3 Quotations \nA small proportion  of the  sentiment expressed  in the  analyzed articles  could \noriginate from  a decision  of a  journalist  to include  a direct quotation  of a  sentiment \nexpressed by another person and thus,  does  not necessarily  represent  an instance of a direct \nlanguage  use by the  media outlet itself.  At the  same  time,  the utilization  of a  piece  of \nlanguage crafted  by another person who may have been employed  as a  source  of authority \non a discussed  matter  is undoubtedly  a part of the  framing process  utilized  by the  media. \nGiven  the commonplace  of this practice  in all of the  media types and  the magnitude  of the \ndata sample size, this limitation  has a  rather  low statistical significance  on the  sentiment \nscore  as well  as the  magnitude  of the  entire article  and,  therefore,  does  not diminish  the \nimportance  of the findings  to any substantial degree. Then again, for  the purposes of future \nresearch  in the  area, this limitation  can be  addressed  by constructing some form  of a \nfiltering  mechanism  to avoid  the unpredictable  nature  of the  direct quotation occurrence, \nshould  the researcher decide  to disregard  the impact  of quoting  on the  framing efforts  by \nthe media. \n5.4 Artificial  Intelligence \nThe sentiment analysis portion of the study was done through  a utilization  of natural \nlanguage processing software based on neural networks. Regardless  of the fact  that  Google \nis at the  forefront  of machine learning research  and  development,  no artificial  intelligence \n46 \n\nsoftware is guaranteed to work completely objectively and without any faults. A few \nrandom checks of articles and their sentiment scores and magnitudes were performed on 50 \narticles before attempting to  utilize  this software for the purposes of the thesis  with  no \nunusual values emerging. There is, however, no absolute  guarantee  that  some of the data \ncould  have been affected by an inherent bias or computational errors  which  is an \nunavoidable  limitation. \n5.5 Suggestions  for Further  Research \nA natural progression of this thesis  would  be to provide a more exhaustive analysis \nof the particular shared words between both the different groupings of news outlets as  well \nas between selected  individual  news outlets. Such findings  could  provide a  greater \nunderstanding of how exactly polarization on a particular topic manifests in word choice. \nMore  broadly, additional research is also needed to  measure  how the  similarity  and \ndissimilarity  of language use  measures  over longer periods of time and how it fairs in \ncomparison  to different time periods. It  could  help shed light on how media bias through \nframing  evolves over time and what variables in the circumstances of  political  climate \ninfluence  the outcomes. \n47 \n\n6. Conclusion \nIn this thesis, the aim was to  attempt  to measure media bias of the mainstream \nmedia  as it is revealed in the  patterns  of language use by comparing the  overall  sentiment  of \nthe mainstream media articles on particular wedge issues to the sentiment of articles \npublished  in the alternative left- and right-leaning media. The results of this investigation \nshow  that there  is a greater  similarity  between the language use of the mainstream media \nand the alternative left-leaning media than between the mainstream media and the \nalternative right-leaning media. \nWhether this  finding  stems  from  the mainstream media providing a more left of \ncenter coverage or the alternative left-leaning media  providing  a more centrist one or  that \nthe right-leaning media are so much further to the  political  extremes is unclear. On the \nother hand, the examination of shared words  suggests  that  there  is a greater overlap \nbetween the word choice in the mainstream and left-leaning media.  This  finding  seems  to \ncorroborate the perception by the general public  that  some  form  of media bias is \nobservable. \nThe practical implications of the results are  that  should the reader  wish  to avoid \nbeing  influenced by the framing through word choice, they are  likely  to acquire a more \ndiverse perspective by not  exclusively  relying  on the perspectives provided in the \nmainstream media. In addition, the study  fills the gap in research by providing a proof of \nconcept of measuring media bias by using a previously unexplored methodology  which \ncould  serve as a good foundation for conducting future research in this area of study. \n48 \n\nReferences \nBudak,  C, Goel,  S., & Rao, J.  M. (2016).  Fair  and Balanced? Quantifying  Media  Bias \nthrough  Crowdsourced Content  Analysis.  Public Opinion  Quarterly,  S0(S1),  250 \n271. doi:10.1093/poq/nfw007 \nGroeling,  T. (2013).  Media  Bias by  the Numbers: Challenges and Opportunities in  the \nEmpirical  Study  of Partisan News.  Annual  Review  of Political  Science,  16(1),  129 \n151. doi: 10.1146/annurev-polisci-040811-115123 \nGroseclose,  T., &  Milyo,  J. (2005). A Measure of  Media  Bias.  The Quarterly Journal of \nEconomics,  120(A),  1191-1237.  doi: 10.1162/003355305775097542 \nIto, T.  A., et al. (1998). Negative Information Weighs More  Heavily  on the Brain:  The \nNegativity  Bias in Evaluative Categorizations. Journal of Personality and Social \nPsychology,  vol. 75, no.  4, pp. 887-900.,  doi: 10.1037//0022-3514.75.4.887. \nJones,  J., & Ritter,  Z. (2018).  Americans  See More  News  Bias;  Most  Can't  Name  Neutral \nSource,  [online]  Gallup.  Available  at: \nhttp://news.gallup.com/poll/225755/americans-news-bias-name-neutral-source.aspx \n[Accessed  25 Apr.  2018]. \nNewport,  F., & Dugan,  A. (2017). Partisan  Differences  Growing on  a Number  of Issues. \n[online]  Gallup.  Available  at: http://news.gallup.com/opinion/polling \n49 \n\nmatters/215210/partisan-differences-growing-number-issues.aspx  [Accessed 25 \nApr. 2018]. \nNiculae,  V., Suen, C, Zhang, J.,  Danescu-Niculescu-Mizil,  C, Leskovec, J. (2015). \nQUOTUS:  The Structure  of Political  Media Coverage as  Revealed  by Quoting \nPatterns.  Florence. Retrieved from \nhttps://www.cs.cornell.edu/~cristian/Structure_of_Political_Media_Coverage_files \nquoting_patterns  .pdf \nNiven,  D. (2003). Objective Evidence on  Media  Bias:  Newspaper Coverage of \nCongressional Party Switchers. Journalism  & Mass  Communication Quarterly, \n80(2),  311-326.  doi:  10.1177/107769900308000206 \nRauch,  J. (2016). Are  There  Still  Alternatives? Relationships Between Alternative  Media \nand Mainstream  Media  in a Converged Environment.  Sociology  Compass,  vol. 10, \nno. 9, pp. 756-767.,  doi:  10.1 lll/soc4.12403. \nRitter,  Z., & Jones,  J. (2018). Media  Seen  as Key to  Democracy  But Not  Supporting  It Well. \n[online]  Gallup.  Available  at: http://news.gallup.com/poll/225470/media-seen-key-\ndemocracy-not-supporting.aspx  [Accessed 25 Apr. 2018]. \nRozin,  P., & Royzman, E. B. (2001). Negativity  Bias,  Negativity Dominance, and \nContagion. Personality and Social  Psychology  Review,  vol. 5, no. 4, pp. 296-320., \ndoi:10.1207/sl5327957pspr0504_2. \n50 \n\nSholar,  J., & Glaser,  N. (2016). Predicting Media  Bias  in Online  News  CS 229:  Machine \nLearning  - Final  Project.  [PDF  file]  Available  at: \nhttp://cs229.stanford.edu/proj2016spr/report/059.pdf  [Accessed 25  Apr.  2018]. \nTrussler,  M., & Soroka,  S. (2014). Consumer Demand  for Cynical  and Negative News \nFrames. The  International  Journal  of Press/Politics,  vol.  19, no. 3,  pp. 373-374., \ndoi:10.1177/1940161214524832. \nWaldman,  P., & Devitt, J. (1998). Newspaper  Photographs  and the  1996 Presidential \nElection:  The  Question  of Bias.  Journalism  &amp;  Mass  Communication \nQuarterly,  vol. 75, no. 2, pp.  302-311.,  doi: 10.1177/107769909807500206. \nWardt,  M., et al. (2014).  Exploiting  the Cracks:  Wedge  Issues  in Multiparty  Competition. \nThe Journal  of Politics,  vol. 76, no. 4, pp.  986-999., \ndoi:10.1017/s0022381614000565. \nWiant,  F. M. (2002).  Exploiting  Factional Discourse: Wedge  Issues in  Contemporary \nAmerican  Political  Campaigns.  Southern  Communication  Journal,  vol. 67, no. 3, \npp. 276-289.,  doi: 10.1080/10417940209373236. \n51 \n\nSummary \nThe charges  of bias have been directed at the media virtually since its conception. \nNo research to this day, however, has been able to definitively  measure  its extent  and \ndirection.  The objective of the study was to  gauge  the extent  of mainstream media bias in \nthe U.S.  as it manifests in the use of language on particular  politically  divisive  issues, by \ncomparing the sentiment of collected articles from the mainstream media outlets to the \nsentiment of articles from both left- and right-leaning media. The study employs natural \nlanguage processing and machine learning algorithms to  measure  the sentiment of all \ncollected  articles,  sentences  as well  as individual  words. The  advantage  of this approach is \nthe ability to  measure  media bias without the need to establish a subjective baseline for \nobjectivity.  Three significant findings were discovered: the  average  sentiment of  all articles \nwas negative; the  average  sentiment of articles collected from the mainstream media was \ncloser to the sentiment of articles from alternative left-leaning media;  there  was a  greater \noverlap of word choice between the mainstream and left-leaning outlets.  According  to these \ndata, it can be inferred  that  the perception of media bias by the public at large may not be \njust a  matter  of perception, and as such, the  readers  should  take  this information into \nconsideration and  adjust  their consumer behavior accordingly. \n52 \n\nResum\u00e9 \nU\u017e prakticky  od sv\u00e9ho vzniku \u010delila m\u00e9dia obvin\u011bn\u00ed ze  zaujatosti.  K dne\u0161n\u00edmu dni \nse v\u0161ak je\u0161t\u011b \u017e\u00e1dn\u00e9mu v\u00fdzkumu nepoda\u0159ilo  rozsah  a sm\u011br t\u00e9to  zaujatosti  jednozna\u010dn\u011b \nidentifikovat.  C\u00edlem t\u00e9to  studie  bylo zm\u011b\u0159it v jak\u00e9m  rozsahu  se projevuje  zaujatosti  m\u00e9di\u00ed v \nUSA  v u\u017e\u00edv\u00e1n\u00ed jazykov\u00fdch prost\u0159edk\u016f p\u0159i vybran\u00fdch politicky rozd\u011bluj\u00edc\u00edch ot\u00e1zk\u00e1ch, a to \nporovn\u00e1n\u00edm  sentimentu  ve vybran\u00fdch \u010dl\u00e1nc\u00edch z mainstreamov\u00fdch m\u00e9di\u00ed se  sentimentem \n\u010dl\u00e1nku z levicov\u00fdch a pravicov\u00fdch m\u00e9di\u00ed.  Studie  vyu\u017e\u00edv\u00e1  algoritmy  na zpracov\u00e1n\u00ed \np\u0159irozen\u00e9ho  jazyka  a strojov\u00e9 u\u010den\u00ed na m\u011b\u0159en\u00ed  sentimentu  v\u0161ech shrom\u00e1\u017ed\u011bn\u00fdch \u010dl\u00e1nk\u016f, v\u011bt \na tak\u00e9 jednotliv\u00fdch slov. V\u00fdhodou  tohoto  p\u0159\u00edstupu je  schopnost  m\u011b\u0159it  zaujatost  m\u00e9di\u00ed bez \npot\u0159eby  stanovit  subjektivn\u00ed b\u00e1zi pro  objektivitu.  Z v\u00fdsledk\u016f vyplynula t\u0159i v\u00fdznamn\u00e1 \nzji\u0161t\u011bn\u00ed: pr\u016fm\u011brn\u00fd  sentiment  v\u0161ech \u010dl\u00e1nk\u016f byl negativn\u00ed; pr\u016fm\u011brn\u00fd  sentiment  \u010dl\u00e1nk\u016f \nz\u00edskan\u00fdch z mainstreamov\u00fdch medi\u00ed byl bli\u017e\u0161\u00ed  k sentimentu  z \u010dl\u00e1nk\u016f z alternativn\u00edch \nlevicov\u00fdch m\u00e9di\u00ed; do\u0161lo  k v\u011bt\u0161\u00edmu shod\u011b v\u00fdb\u011bru slov mezi mainstreamov\u00fdmi a levicov\u00fdmi \nm\u00e9dii. Z t\u011bchto \u00fadaj\u016f lze vyvodit, \u017ee jak vn\u00edm\u00e1 \u0161irok\u00e1 ve\u0159ejnost medi\u00e1ln\u00ed  zaujatost  nemus\u00ed \nb\u00fdt pouze  ot\u00e1zkou  pocitu,  naopak  je mo\u017en\u00e9  takovou  zaujatost  identifikovat  a kvantifikovat \nanal\u00fdzou medi\u00e1ln\u00edho  obsahu.  Tato  zji\u0161t\u011bn\u00ed by \u010dten\u00e1\u0159i m\u011bli br\u00e1t na v\u011bdom\u00ed a adekv\u00e1tn\u011b jim \np\u0159izp\u016fsobit sv\u00e9 spot\u0159ebitelsk\u00e9 chov\u00e1n\u00ed. \n53 \n\nAppendix  A \nImplementation \nThe methodology described in Chapter 3 was implemented as a command-line \napplication  in Java programming language.  Application  provides a  CLI that  supports  basic \nuser input,  which  is transformed into code execution of  individual  predefined functions. \nThe code is structured into a main class  that  handles  user  input and a top-level application \nlogic,  while  the rest  of the functionality is split into 6 packages, each of  which  handles \ndifferent application  features: \nsk.rojkova.bachelorsthesis.configuration \nThis package provides core application  setup,  such as reading configuration \nfiles and setting up required  API  keys, news outlets and wedge issues. \nsk.rojkova.bachelorsthesis.eventregistry \nThis package provides connection to Event Registry  API,  manages  HTTP \nrequests  and provides mappings of  response  data  to internal Java classes. \nsk.rojkova.bachelorsthesis.filesystem \nThis package provides a wrapper API around Java 8  Files  API to  simplify \ninteractions  with  filesystem of the runtime environment  that  allows to  create \nnew files,  delete  existing  files,  read  from  files  and write into  files. \nsk.rojkova.bachelorsthesis.naturallanguage \nThis package provides connection to  NLAPI,  manages  HTTP  requests  and \nprovides mappings of  response  data  to internal Java classes. \nsk.rojkova.bachelorsthesis.util \n54 \n\nThis package contains single convenience  utility  class \nExtendedObjectMapper,  which  is an extension of standard Jackson \nObjectMapper  class  with  extended configuration. \nrojkova.bachelorsthesis.wordmap \nPackage provides a wrapper  API  around Java's Map object  that  holds lists of \nwords on  which  sentiment and syntax analysis has been performed. \n55 \n\n\u2022 M STL \n\u2022 lj main \n\u2022 kjava \n\u2022 El skrojkova.bacheLorsthesis \n\u2022 El cLoudnaturaLLanguage \n\u2022 El data \nArticle Sentiment \nO SentenceSentiment \n0Word \nO QoudNaturaLLanguageAPI \nt El configuration \n0 Category \n0 Configuration \nO Source \n0 SourceType \n\u2022 El eventregistry \n\u2022 El data \nO Article \nO Articles \nO ArticleSource \n0 ArticlesResponse \nO EventRegistryAPI \nt EifiLesystem \nFiLeManager \n\u2022 Elutil \nO ExtendedObjectMapper \n\u2022 Eiwordmap \nO WordMap \nO WordMapltem \nO Word Sentiment \n0 SentimentAnaLyzer \n1| resources \nFigure  AI. Screenshot  of entire package structure of Sentiment  Analyzer  application. \n56 \n\nFigure Al  above  shows the application  structure.  The complete class diagram with \nall classes, fields,  methods  and dependencies  is available as an  attachment  to this  thesis  as \nlisted  in Appendix C. \nRuntime  configuration  and instructions \nIn order to run the application from the compiled Java archive  file  listed in \nAppendix  C, the  following  requirements  must  be satisfied: \nCLI (shell on  Linux,  cmd or PowerShell on Windows) \nJava 8 (recommended: openjdk-8-jre). \nEvent Registry  API Key \nGoogle  Natural Language API Key \nConfiguration  file \nRecommended operating system is Ubuntu 17.10 or Ubuntu 18.04 LTE and \ninstructions in this section  assume  user  will  be using a Ubuntu or  other  Debian-based \noperating system. \nFirst,  create  a directory  somewhere  in your filesystem, for example in your  home \ndirectory. Locate the  executable  JAR  file called sentiment-analyzer .jar which has  been \ndistributed as an  attachment  of this  thesis  and move this  file to the newly  created  directory. \nAny additional files  that  this tutorial  will  ask you to  create  should be placed in the  same \ndirectory, which  will from  here  on be referenced to as the root folder. \n57 \n\nEvent  Registry  API Key \nTo execute calls to Event Registry API, an Event Registry API key must be \nobtained. To acquire the API key, an Event Registry account is required. Account can be \ncreated at the Event Registry website ( http://eventregistry.org/login ). API  key can be then \nfound  on the profile  page  (http://eventregistry.org/me ). After  acquiring an  API key,  create  a \nnew file in the root directory called Event-Registry-API-Key.json  with  the following \ncontent: \n{ \"apiKey\":  \"YOUR_API_KEY\" } \nReplace  the YOUR_API_KEY  placeholder  with  the API key you can see on your \nprofile  page  in the Event Registry (see screenshot above). \nGoogle  Natural  Language  API Key \nTo execute calls to  NLAPI, API  credentials from a Google  Cloud  Platform project \nis required. An extensive tutorial on how to  create  a new GCP project, enable Google \nNatural  Language API and download API credentials  JSON  file can be found on the \nNLAPI  official  documentation page: \nhttps://cloud.google.com/natural-language/docs/quickstart-client-libraries . \nFollow  documentation instructions and then copy the downloaded the API \ncredentials  file (Cloud-Natural-Language-API-....json) into the root folder and delete the \nunnecessary  file suffix  (eg. a68467ge6s5d). \n58 \n\nConfiguration  file \nCreate a new  file called  Sentiment-Analyzer-Configuration.json  in the root folder \nwith the following  content: \n{ \n\"rootFolder\"  : \n\"sources\":  [ \"ROOT FOLDER\", \n{ \"url\": \n1 \"SOURCE URL\", \"type' i. \"TYPE\" } \nJ i \n\"categories\": [ \n{ \"dmoz\" \n] : \"DMOZ\",  \"keyword\": null } \n} { \"dmoz\" \n] \nReplace the  ROOT_FOLDER  placeholder with the absolute path to the root folder, \nSOURCE_URL  placeholder with an URL found in Event Registry  database,  TYPE \nplaceholder for of the  following  options: \nMAINSTREAM,  which  represents  the mainstream media. \nLEFT,  which  represents  the left-leaning alternative media. \nRIGHT,  which  represents  the right-leaning alternative media. \nFinally  replace  CATEGORY  placeholder for a  DMOZ  category found in Event \nRegistry  database.  Additional  sources and categories can be added using the standard  JSON \narray notation. A default configuration  file is available as an  attachment  to this thesis \n(Sentiment-Analyzer-Default-Configuration.json). \n59 \n\nExecution \nAfter  completing  steps  in previous sections, application is ready to run. To run the \napplication,  execute the  following  command in a  CLI  from the root folder: \nJava -jar sentiment-analyzer.jar  -\nDGOOGLE_APPLICATION_CREDENTIALS=Cloud-Natural-Language-API.json  -\nDEVENT_REGISTRY_API_KEY=Event-Registry-API-key.json  -\nDSENTIMENT_ANALYZER_CONFIGUPATION=Sentiment-Analyzer-Configuration.json \nTo execute all  steps  of analysis described in Chapter 3 run all application options in \norder from 1 to 5. Successful execution produces  JSON  files  for all downloaded articles \navailable  in /data/articles folder.  Each  article has two  files,  one that  contains article and its \nmeta data as returned from Event Registry  API,  another contains sentiment analysis for the \narticle  and all of its  sentences.  Additionally,  following  CSV  files  are created in the \n/data/results  folder: \narticle-sentiments  .csv - Result of sentiment analysis of articles ready to be imported \ninto a table editor. \narticle-statistics.csv - Summary of the number of articles downloaded for each news \noutlet and wedge issue combination. \nword-count.csv - Summary of the number of words from syntax analysis of \nsentences. \nword-list.csv  - Lists  of most frequently used words from syntax analysis of \nsentences. \nword-pairs.csv  - Lists  of shared most frequently used words between mainstream \nmedia  and alternative left- and right-leaning media. \n60 \n\nAppendix  B \nRaw data  and statistical  outputs \nAttachments created during implementation and evaluation of this thesis. \nsentiment-analyzer.zip -  Archive  containing the source code for the sentiment-\nanalyzer application created during the implementation. \nsentiment-analyzer .jar -  Compiled  executable Java archive version of the sentiment-\nanalyzer. \nSentiment-Analyzer-Default-Configuration.json  - Default configuration  file  for \nsentiment-analyzer. \nsentiment-analyzer-class-diagram.png - UML class diagram of the sentiment-\nanalyzer application. \nArticles.zip  - Archive  containing all collected articles from sentiment analysis, \narticle-sentiments  .csv - Raw  data  generated  during sentiment analysis from \nsentiment-analyzer. \narticle-statistics.csv - Raw  data  for all articles downloaded by sentiment-analyzer, \nword-count.csv - Raw  data  for the number of unique words  generated  by sentiment-\nanalyzer during syntax analysis. \nword-list.csv  - Raw  data  for lists of unique words  generated  by sentiment-analyzer \nduring  syntax analysis. \nword-pairs.csv - Raw  data  for unique words comparisons  generated  by sentiment-\nanalyzer during syntax analysis. \n61 \n\nArticle  Statistics.xls - Processed data and table summary of  collected  articles. \nMost  Used  Word  List.xls  - Processed data, table summary and statistical data for \nanalyzed  and identified most used words. \nSentiment  Analysis.xls  - Processed data, table summary and comparison of article \nsentiment analysis results. \nSyntax  Analysis.xls  - Processed data and table summary of syntax analysis results. \n62 \n\nAppendix  C \nSentiment  Analysis  Results \nTable  CI, Table C2  and Table C3  listed  below break  down  all the collected  article \nsentiment data into groups  by wedge issues  and  news outlets.  The  tables show  8 columns \nwhich  represent  the following  data:  the wedge issues,  the number  of retrieved articles  (# of \narticles),  the sentiment score  for all  articles (Score),  the average article sentiment score \n(Score  (adj)),  the sentiment magnitude  of all  articles (Magnitude),  the average article \nsentiment magnitude (Magnitude (adj)),  the total sentiment score adjusted  by sentiment \nmagnitude  (Scr. x  Mag.)  and the  average article sentiment score adjusted  by sentiment \nmagnitude.  The  rows  are organized into groups  of six  rows, where  the first row in the \ncluster  of the six  defines  the wedge issue  and  contains  the sums  of values  from  all news \noutlets  for a  given  wedge issue,  with  the five subsequent rows representing each  individual \nnews outlet. \n63 \n\nSentiment  analysis  results  - Mainstream  media \nWedge  issue #of \narticles Score Score \n(adj) Magnitud \ne Mag. \n(adj) Scr. x  Mag. S.xM. \n(adj) \nAbortion 1,000.00 -91.1 -0.092 9,172.70 9.176 -728.74 -0.73 \nfoxnews.com 200 -23.7 -0.12 1,565.60 7.83 -182.31 -0.91 \nedition.cnn.com 200 -19.2 -0.1 2,019.20 10.1 -183.32 -0.92 \nnytimes.com 200 -11.6 -0.06 2,263.20 11.32 -121.1 -0.61 \nwashingtonpost.com 200 -20.7 -0.1 2,547.70 12.74 -231.35 -1.16 \nwsj.com 200 -15.9 -0.08 111 3.89 -10.66 -0.05 \nGun  Control 1,000.00 -81.7 -0.084 7,573.10 7.574 -597.33 -0.598 \nfoxnews.com 200 -25 -0.13 1,114.00 5.57 -168.34 -0.84 \nedition.cnn.com 200 -17.8 -0.09 1,777.50 8.89 -149.94 -0.75 \nnytimes.com 200 -11.1 -0.06 1,772.30 8.86 -104.49 -0.52 \nwashingtonpost.com 200 -13.4 -0.07 2,291.30 11.46 -137.43 -0.69 \nwsj.com 200 -14.4 -0.07 618 3.09 -37.13 -0.19 \nHealthcare 1,000.00 -78.8 -0.078 8,238.40 8.24 -494.29 -0.494 \nfoxnews.com 200 -24.5 -0.12 1,277.40 6.39 -144.45 -0.72 \nedition.cnn.com 200 -13.7 -0.07 2,025.40 10.13 -143.01 -0.72 \nnytimes.com 200 -7.7 -0.04 2,213.40 11.07 -78.44 -0.39 \nwashingtonpost.com 200 -10 -0.05 2,231.80 11.16 -82.17 -0.41 \nwsj.com 200 -22.9 -0.11 490.4 2.45 -46.22 -0.23 \nImmigration 1,000.00 -80.5 -0.08 7,278.40 7.278 -531.14 -0.532 \nfoxnews.com 200 -23.1 -0.12 1,364.00 6.82 -147.27 -0.74 \nedition.cnn.com 200 -18.6 -0.09 1,614.40 8.07 -157.58 -0.79 \nnytimes.com 200 -8.4 -0.04 1,839.00 9.2 -66.87 -0.33 \nwashingtonpost.com 200 -13 -0.06 2,270.70 11.35 -139.43 -0.7 \nwsj.com 200 -17.4 -0.09 190.3 0.95 -19.99 -0.1 \nClimate  Change 1,000.00 -3 -0.006 6,753.00 6.754 14.57 0.016 \nfoxnews.com 200 -3.8 -0.02 903.9 4.52 -6.3 -0.03 \n64 \n\nedition.cnn.com 200 -5.1 -0.03 1,430.30 7.15 -24.74 -0.12 \nnytimes.com 200 2.2 0.01 1,718.00 8.59 19.23 0.1 \nwashingtonpost.com 200 0.9 0 2,199.50 11 16.56 0.08 \nwsj.com 200 2.8 0.01 501.3 2.51 9.82 0.05 \nTOTAL  SUM 5,000.00 -335.1 -0.567 39,015.60 195.11 -2,336.93 -11.69 \nTable  CI.  Detailed  average  article  sentiment data  with  additional  information  for mainstream  media  news \noutlets. \n65 \n\nSentiment  analysis  results  - Left-leaning  alternative  media \nWedge  issue # of articles Score Score \n(adj) Magnitude Mag. \n(adj) Scr. x Mag. S.xM. \n(adj) \nAbortion 839 -128.3 -0.152 6,004.90 8.562 -954.5 -1.308 \nslate.com 200 -30.7 -0.15 607.3 3.04 -95.48 -0.48 \nthedailybeast.com 178 -21.1 -0.12 1,230.20 6.91 -142.99 -0.8 \nvox.com 61 -9.1 -0.15 1,056.00 17.31 -147.06 -2.41 \nrawstory.com 200 -35.7 -0.18 1,168.60 5.84 -213.31 -1.07 \nmotherjones.com 200 -31.7 -0.16 1,942.80 9.71 -355.66 -1.78 \nGun  Control 864 -84.5 -0.094 5,582.30 7.322 -481.1 -0.588 \nslate.com 200 -19.7 -0.1 495.6 2.48 -47.48 -0.24 \nthedailybeast.com 200 -22.5 -0.11 1,641.00 8.21 -127.58 -0.64 \nvox.com 64 -4.6 -0.07 818.6 12.79 -50.23 -0.78 \nrawstory.com 200 -24 -0.12 994.5 4.97 -125.84 -0.63 \nmotherjones.com 200 -13.7 -0.07 1,632.60 8.16 -129.97 -0.65 \nHealthcare 947 -87.2 -0.088 8,026.10 8.858 -633.92 -0.67 \nslate.com 200 -19.3 -0.1 482.5 2.41 -52.43 -0.26 \nthedailybeast.com 200 -22.6 -0.11 2,023.60 10.12 -177.83 -0.89 \nvox.com 147 -6.6 -0.04 2,309.80 15.71 -99.56 -0.68 \nrawstory.com 200 -26.5 -0.13 1,314.50 6.57 -163.36 -0.82 \nmotherjones.com 200 -12.2 -0.06 1,895.70 9.48 -140.74 -0.7 \nImmigration 958 -85.6 -0.09 7,184.00 7.856 -548.38 -0.592 \nslate.com 200 -21.8 -0.11 489.1 2.45 -46.67 -0.23 \nthedailybeast.com 200 -17.5 -0.09 1,472.20 7.36 -83.15 -0.42 \nvox.com 158 -9 -0.06 2,526.90 15.99 -160.72 -1.02 \nrawstory.com 200 -24 -0.12 1,066.80 5.33 -129.1 -0.65 \nmotherjones.com 200 -13.3 -0.07 1,629.00 8.15 -128.74 -0.64 \nClimate  Change 833 -23.4 -0.024 5,923.50 8.462 -141.59 -0.158 \nslate.com 200 -11.8 -0.06 456.4 2.28 -25 -0.13 \n66 \n\nthedailybeast.com 152 -2.1 -0.01 880.1 5.79 -14.98 -0.1 \nvox.com 81 -0.1 0 1,538.10 18.99 -6.56 -0.08 \nrawstory.com 200 -7.6 -0.04 1,255.30 6.28 -51.57 -0.26 \nmotherjones.com 200 -1.8 -0.01 1,793.60 8.97 -43.48 -0.22 \nTOTAL  SUM 4,441.00 -409 -0.7467 32,720.80 205.3 -2,759.49 -16.58 \nTable  C2. Detailed  average  article  sentiment  data  with additional information for alternative left-leaning \nmedia  news  outlets. \n67 \n\nSentiment  analysis  results  - Right-leaning  alternative  media \nWedge  issue # of articles Score Score \n(adj) Magnitude Mag. \n(adj) Scr. x Mag. S.xM. \n(adj) \nAbortion 928 -149.6 -0.16 8,987.20 9.744 -1,435.60 -1.562 \nbreitbart.com 200 -28.9 -0.14 1,963.00 9.82 -301.46 -1.51 \ndailycaller.com 200 -40 -0.2 1,425.10 7.13 -304.5 -1.52 \ntheblaze.com 200 -29.8 -0.15 1,536.50 7.68 -250.53 -1.25 \nreason.com 128 -19.1 -0.15 1,343.10 10.49 -224.02 -1.75 \nwnd.com 200 -31.8 -0.16 2,719.50 13.6 -355.09 -1.78 \nGun  Control 1,000.00 -111.1 -0.112 7,689.20 7.688 -800.65 -0.804 \nbreitbart.com 200 -21.5 -0.11 1,074.20 5.37 -117.25 -0.59 \ndailycaller.com 200 -12.5 -0.06 1,769.90 8.85 -37.05 -0.19 \ntheblaze.com 200 -23.9 -0.12 1,250.10 6.25 -165.68 -0.83 \nreason.com 200 -30.1 -0.15 2,070.30 10.35 -341.55 -1.71 \nwnd.com 200 -23.1 -0.12 1,524.70 7.62 -139.12 -0.7 \nHealthcare 1,000.00 -101.5 -0.102 7,989.70 7.988 -847.8 -0.846 \nbreitbart.com 200 -21.7 -0.11 1,454.60 7.27 -168.49 -0.84 \ndailycaller.com 200 -20.3 -0.1 1,511.80 7.56 -166.99 -0.83 \ntheblaze.com 200 -19.7 -0.1 1,376.40 6.88 -132.01 -0.66 \nreason.com 200 -22.4 -0.11 2,384.90 11.92 -301.79 -1.51 \nwnd.com 200 -17.4 -0.09 1,262.00 6.31 -78.52 -0.39 \nImmigration 1,000.00 -120.6 -0.122 8,582.60 8.584 -1,070.23 -1.072 \nbreitbart.com 200 -22.4 -0.11 1,861.10 9.31 -191.6 -0.96 \ndailycaller.com 200 -21.1 -0.11 1,143.10 5.72 -125.65 -0.63 \ntheblaze.com 200 -28 -0.14 1,349.60 6.75 -199.98 -1 \nreason.com 200 -19.1 -0.1 2,119.90 10.6 -217.43 -1.09 \nwnd.com 200 -30 -0.15 2,108.90 10.54 -335.57 -1.68 \nClimate  Change 977 -49 -0.052 7,267.80 7.49 -376.57 -0.384 \nbreitbart.com 200 -10 -0.05 1,553.10 7.77 -90.98 -0.45 \n68 \n\ndailycaller.com 200 -9.1 -0.05 1,182.00 5.91 -57.91 -0.29 \ntheblaze.com 200 -9.8 -0.05 1,196.60 5.98 -70.83 -0.35 \nreason.com 177 -6.9 -0.04 1,702.90 9.62 -74.99 -0.42 \nwnd.com 200 -13.2 -0.07 1,633.20 8.17 -81.86 -0.41 \nTOTAL  SUM 4,905.00 -531.8 -0.913 40,516.50 207.47 -4,530.85 -2334 \nTable  C3.  Detailed  average  article  sentiment data  with  additional information  for alternative  right-leaning \nmedia  news outlets. \n69 \n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Comparative Sentiment Analysis of Media Bias", "author": ["J Rojkov\u00e4"], "venue": "NA", "pub_year": "NA", "abstract": "The media plays a pivotal role in not only keeping the general populace informed on current  matters but also in shaping the public discourse on important ongoing debates. Because of"}, "filled": false, "gsrank": 61, "pub_url": "https://is.muni.cz/th/rwta3/rojkova-bachelors-thesis.pdf_Archive.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:ub3wCZYzKi4J:scholar.google.com/&output=cite&scirp=60&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ub3wCZYzKi4J&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:ub3wCZYzKi4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://is.muni.cz/th/rwta3/rojkova-bachelors-thesis.pdf_Archive.pdf"}}, {"title": "Predicting the topical stance of media and popular twitter users", "year": "2019", "pdf_data": "Predicting the Topical Stance and Political Leaning of Media using Tweets\nPeter Stefanov1, Kareem Darwish2, Atanas Atanasov3, Preslav Nakov2\n1SiteGround Hosting EOOD, Bulgaria\n2Qatar Computing Research Institute, HBKU, Doha, Qatar\n3So\ufb01a University \u201cSt. Kliment Ohridski\u201d, So\ufb01a, Bulgaria\nfstefanov.peter.ps,atanas.atanasov.sf g@gmail.com ,\nfkdarwish,pnakov g@hbku.edu.qa\nAbstract\nDiscovering the stances of media outlets and\nin\ufb02uential people on current, debatable topics\nis important for social statisticians and policy\nmakers. Many supervised solutions exist for\ndetermining viewpoints, but manually annotat-\ning training data is costly. In this paper, we\npropose a cascaded method that uses unsuper-\nvised learning to ascertain the stance of Twit-\nter users with respect to a polarizing topic by\nleveraging their retweet behavior; then, it uses\nsupervised learning based on user labels to\ncharacterize both the general political leaning\nof online media and of popular Twitter users,\nas well as their stance with respect to the tar-\nget polarizing topic. We evaluate the model by\ncomparing its predictions to gold labels from\nthe Media Bias/Fact Check website, achieving\n82.6% accuracy.\n1 Introduction\nOnline media and popular Twitter users, which we\nwill collectively refer to as in\ufb02uencers , often ex-\npress overt political leanings, which can be gleaned\nfrom their positions on a variety of political and\ncultural issues. Determining their leaning can be\ndone through the analysis of their writing, which in-\ncludes the identi\ufb01cation of terms that are indicative\nof stance (Groseclose and Milyo, 2005; Gentzkow\nand Shapiro, 2011). Performing such analysis auto-\nmatically can be done using supervised classi\ufb01ca-\ntion, which in turn would require manually labeled\ndata (Groseclose and Milyo, 2005; Gentzkow and\nShapiro, 2011; Mohammad et al., 2016). Alter-\nnatively, leanings can be inferred based on which\npeople share the content (blogs, tweets, posts, etc.)\non social media, as social media users are more\nlikely to share content that originates from sources\nthat generally agree with their positions (An et al.,\n2012; Morgan et al., 2013; Ribeiro et al., 2018;\nWong et al., 2013).Here, we make use of this observation to character-\nize in\ufb02uencers, based on the stances of the Twitter\nusers that share their content. Ascertaining the\nstances of users, also known as stance detection,\ninvolves identifying the position of a user with re-\nspect to a topic, an entity, or a claim (Mohammad\net al., 2016). For example, on the topic of abortion\nin USA, the stances of left- vs. right-leaning users\nwould typically be \u201cpro-choice\u201d vs. \u201cpro-life\u201d, re-\nspectively.\nIn this paper, we propose to apply unsupervised\nstance detection to automatically tag a large num-\nber of Twitter users with their positions on speci\ufb01c\ntopics (Darwish et al., 2020). The tagging identi-\n\ufb01es clusters of vocal users based on the accounts\nthat they retweet. Although the method we use\nmay yield more than two clusters, we retain the\ntwo largest ones, which typically include the over-\nwhelming majority of users, and we ignore the rest.\nThen, we train a classi\ufb01er that predicts which clus-\nter a user belongs to, in order to expand our clus-\nters. Once we have increased the number of users\nin our sets, we determine which sources are most\nstrongly associated with each group based on shar-\ning by each group. We apply this methodology to\ndetermine the positions of in\ufb02uencers and of media\non eight polarizing topics along with their overall\nleaning: left, center or right. In doing so, we can\nalso observe the sharing behavior of right- and left-\nleaning users, and we can correlate their behavior\nwith the credibility of the sources. Further, given\nthe user stances for these eight topics, we train a\nsupervised classi\ufb01er to predict the overall bias of\nsources using a variety of features, including the\nso-called valence (Conover et al., 2011a), graph\nembeddings, and contextual embeddings. Using\na combination of these features, our classi\ufb01er is\nable to predict the bias of sources with 82.6% accu-\nracy, with valence being the most effective feature.\nFigure 1 outlines our overall methodology.arXiv:1907.01260v2  [cs.SI]  21 May 2020\nFigure 1: General outline of our methodology.\nOur contributions are as follows:\n\u000fWe use unsupervised stance detection to au-\ntomatically determine the stance of Twitter\nusers with respect to several polarizing topics.\n\u000fWe then use distant supervision based on these\ndiscovered user stances to accurately charac-\nterize the political leaning of media outlets\nand of popular Twitter accounts. For classi-\n\ufb01cation, we use a combination of source va-\nlence, graph embeddings, and contextualized\ntext embeddings.\n\u000fWe evaluate our approach by comparing its\nbias predictions for a number of news out-\nlets against gold labels from Media Bias/Fact\nCheck. We further evaluate its predictions\nfor popular Twitter users against manual judg-\nments. The experimental results show sizable\nimprovements over using graph embeddings\nor contextualized text embeddings.\nThe remainder of this paper is organized as fol-\nlows: Section 2 discusses related work. Section 3\ndescribes the process of data collection. Section 4\npresents our method for user stance detection. Sec-\ntion 5 describes how we characterize the in\ufb02u-\nencers. Section 6 discusses our experiments in\nmedia bias prediction. Finally, Section 7 concludes\nand points to possible directions for future work.\n2 Related Work\nRecent work that attempted to characterize the\nstance and the ideological leaning of media and\nTwitter users relied on the observation that users\ntend to retweet content that is consistent with their\nworld view. This stems from selective exposure ,\nwhich is a cognitive bias that leads people to avoid\nthe cognitive overload from exposure to opposing\nviews as well as the cognitive dissonance in which\npeople are forced to reconcile between their views\nand opposing views (Morgan et al., 2013).Concerning media, Ribeiro et al. (2018) used the\nFacebook advertising services to infer the ideologi-\ncal leaning of online media based on the political\nleaning of Facebook users who consumed them. An\net al. (2012) relied on follow relationships to online\nmedia on Twitter to ascertain ideological leaning\nof media and users based on the similarity between\nthem. Wong et al. (2013) studied retweet behavior\nto infer the ideological leanings of online media\nsources and popular Twitter accounts. Barber \u00b4a and\nSood (2015) proposed a statistical model based\non the follower relationships to media sources and\nTwitter personalities in order to estimate their ideo-\nlogical leaning.\nAs for individual users, much recent work fo-\ncused on stance detection to determine a person\u2019s\nposition on a topic including the deduction of politi-\ncal preferences (Barber \u00b4a, 2015; Barber and Rivero,\n2015; Borge-Holthoefer et al., 2015; Cohen and\nRuths, 2013; Colleoni et al., 2014; Conover et al.,\n2011b; Fowler et al., 2011; Hasan and Ng, 2014;\nHimelboim et al., 2013; Magdy et al., 2016a,b;\nMakazhanov et al., 2014; Trabelsi and Za \u00a8\u0131ane,\n2018; Weber et al., 2013). User stance classi\ufb01-\ncation is aided by the tendency of users to form\nso-called \u201cecho chambers\u201d, where they engage\nwith like-minded users (Himelboim et al., 2013;\nMagdy et al., 2016a), and the tendency of users\u2019\nbeliefs to be persistent over time (Borge-Holthoefer\net al., 2015; Magdy et al., 2016a; Pennacchiotti and\nPopescu, 2011b).\nStudies have examined the effectiveness of differ-\nent features for stance detection, including textual\nfeatures such as word n-grams and hashtags, net-\nwork interactions such as retweeted accounts and\nmentions, and pro\ufb01le information such as user loca-\ntion (Borge-Holthoefer et al., 2015; Hasan and Ng,\n2013; Magdy et al., 2016a,b; Weber et al., 2013).\nNetwork interaction features were shown to yield\nbetter results compared to using textual features\n(Magdy et al., 2016a; Wong et al., 2013). Srid-\nhar et al. (2015) leveraged both user interactions\nand textual information when modeling stance and\ndisagreement, using a probabilistic programming\nsystem that allows models to be speci\ufb01ed using a\ndeclarative language.\nTrabelsi and Za \u00a8\u0131ane (2018) described an unsu-\npervised stance detection method that determines\nthe viewpoints of comments and of their authors.\nIt analyzes online forum discussion threads, and\ntherefore assumes a certain structure of the posts.\nIt also assumes that users tend to reply to each\nothers\u2019 comments when they are in disagreement,\nwhereas we assume the opposite in this paper. Their\nmodel leverages the posts\u2019 contents, whereas we\nonly use the retweet behavior of users.\nMany methods involving supervised learning\nwere proposed for stance detection. Such meth-\nods require the availability of an initial set of la-\nbeled users, and they use some of the aforemen-\ntioned features for classi\ufb01cation (Darwish et al.,\n2018; Magdy et al., 2016b; Pennacchiotti and\nPopescu, 2011a). Such classi\ufb01cation can label\nusers with precision typically ranging between\n70% and 90% (Rao et al., 2010; Pennacchiotti and\nPopescu, 2011a). Label propagation is a semi-\nsupervised method that starts with a seed list of\nlabeled users and propagates the labels to other\nusers who are similar based on the accounts they\nfollow or retweet (Barber \u00b4a and Sood, 2015; Borge-\nHolthoefer et al., 2015; Weber et al., 2013). While\nlabel propagation may label users with high preci-\nsion (often above 95%), it is biased towards users\nwith more extreme views; moreover, careful choice\nof thresholds is often required, and post-checks are\nneeded to ensure quality.\nAbu-Jbara et al. (2013) and more recently Dar-\nwish et al. (2020) used unsupervised stance de-\ntection, where users are mapped into a lower di-\nmensional space based on user-user similarity, and\nthen clustered to \ufb01nd core sets of users represent-\ning different stances. This was shown to be highly\neffective with nearly perfect clustering accuracy\nfor polarizing topics, and it requires no manual\nlabeling of users. Here, we use the same idea,\nbut we combine it with supervised classi\ufb01cation\nbased on retweets in order to increase the number\nof labeled users (Darwish, 2018). Other methods\nfor user stance detection include collective clas-\nsi\ufb01cation (Duan et al., 2012), where users in a\nnetwork are jointly labeled and classi\ufb01cation in a\nlow-dimensional user-space (Darwish et al., 2017).\nAs for predicting political leaning or sentiment,\nthis problem was studied previously as a super-\nvised learning problem, where a classi\ufb01er learns\nfrom a set of manually labeled tweets (Pla and Hur-\ntado, 2014; Bakliwal et al., 2013; Bermingham and\nSmeaton, 2011). Similarly, V olkova et al. (2014)\npredicted Twitter users\u2019 political af\ufb01liation (being\nRepublican or Democratic), using their network\nconnections and textual information, relying on\nuser-level annotations.3 Data Collection\nWe obtained data on eight topics that are consid-\nered polarizing in the USA (Darwish et al., 2020),\nshown in Table 1.\nThey include a mix of long-standing issues such\nas racism and gun control, temporal issues such as\nthe nomination of Judge Brett Kavanaugh to the US\nSupreme Court and Representative Ilhan Omar\u2019s\npolarizing remarks, as well as non-political issues\nsuch as the potential dangers of vaccines. Further,\nthough long-standing issues typically show right\u2013\nleft polarization, stances towards Omar\u2019s remarks\nare not as clear, with divisions on the left as well.\nSince we are interested in US users, we \ufb01ltered\nsome tweets to retain such by users who have stated\nthat their location was USA. We used a gazetteer\nthat included words that indicate USA as a country\n(e.g., America, US), as well as state names and\ntheir abbreviations (e.g., Maryland, MD).\nOther data that we used in our experiments is a\ncollection of articles that were cited by users from\nthe tweets collection and that originate from media,\nwhose bias is known, i.e., is discussed on the Media\nBias/Fact Check website.\n4 User Stance Detection\nIn order to analyze the stance of in\ufb02uencers on\na given topic, we \ufb01rst \ufb01nd the stances of Twitter\nusers, and then we project them to the in\ufb02uencers\nthat the users cite. A central (initial) assumption\nhere is that if a user includes a link to some arti-\ncle in their tweet, they are more likely to agree or\nendorse the article\u2019s message. Similarly, when a\nuser retweets a tweet verbatim without adding any\ncomments, they are more likely to agree with that\ntweet. We label a large number of users with their\nstance for each topic using a two-step approach,\nnamely projection and clustering andsupervised\nclassi\ufb01cation .\nFor the projection and clustering step, we iden-\ntify clusters of core vocal users using the unsuper-\nvised method described in (Darwish et al., 2020).\nIn this step, users are mapped to a lower dimen-\nsional space based on their similarity, and then they\nare clustered. After performing this unsupervised\nlearning step, we train a supervised classi\ufb01er using\nthe two largest identi\ufb01ed clusters in order to tag\nmany more users. For that, we use FastText, a deep\nneural network text classi\ufb01er, that has been shown\nto be effective for various text classi\ufb01cation tasks\n(Joulin et al., 2017).\nTopic Keywords Date Range No. of Tweets\nClimate change #greendeal, #environment, #climate, #climatechange, #carbonfootprint, #climatehoax, #cli-\nmategate, #globalwarming, #agw, #renewablesFeb 25\u2013Mar 4, 2019 1,284,902\nGun control/rights #gun, #guns, #weapon, #2a, #gunviolence, #secondamendment, #shooting, #massshooting,\n#gunrights, #GunReformNow, #GunControl, #NRAFeb 25\u2013Mar 3, 2019 1,782,384\nIlhan Omar remarks on\nIsrael lobbyIlhanOmarIsATrojanHorse, #IStandWithIlhan, #ilhan, #Antisemitism, #IlhanOmar, #IlhanMN,\n#RemoveIlhanOmar, #ByeIlhan, #RashidaTlaib, #AIPAC, #EverydayIslamophobia, #Islamo-\nphobia, #ilhanMar 1\u20139, 2019 2,556,871\nIllegal immigration #border, #immigration, #immigrant, #borderwall, #migrant, #migrants, #illegal, #aliens Feb 25\u2013Mar 4, 2019 2,341,316\nMidterm midterm, election, elections Oct 25\u201327, 2018 520,614\nRacism & police brutal-\nity#blacklivesmatter, #bluelivesmatter, #KKK, #racism, #racist, #policebrutality, #excessiveforce,\n#StandYourGround, #ThinBlueLineFeb 25\u2013Mar 3, 2019 2,564,784\nKavanaugh Nomination Kavanaugh, Ford, Supreme, judiciary, Blasey, Grassley, Hatch, Graham, Cornyn, Lee, Cruz,\nSasse, Flake, Crapo, Tillis, Kennedy, Feinstein, Leahy, Durbin, Whitehouse, Klobuchar, Coons,\nBlumenthal, Hirono, Booker, HarrisSept. 28-30, 2018 &\nOct. 6-9, 20182,322,141\nVaccination bene\ufb01ts &\ndangers#antivax, #vaxxing, #BigPharma, #antivaxxers, #measlesoutbreak, #Antivacine, #Vac-\ncinesWork, #vaccine, #vaccines, #Antivaccine, #vaccinestudy, #antivaxx, #provaxx, #Vaccines-\nSaveLives, #ProVaccine, #VaxxWoke, #mykidmychoiceMar 1\u20139, 2019 301,209\nTable 1: Polarizing topics used in study.\nOnce we have expanded our sets of labeled users,\nwe identify in\ufb02uencers that are most closely asso-\nciated with each group using a modi\ufb01ed version of\nthe so-called valence score , which varies in value\nbetween\u00001 and 1. If an in\ufb02uencer is being cited\nevenly between the groups, then it would be as-\nsigned a valence score close to zero. Conversely,\nif one group disproportionately cites an in\ufb02uencer\ncompared to another group, then it would be as-\nsigned a score closer to \u00001 or 1. We perform these\nsteps for each of the given topics, and \ufb01nally we\nsummarize the stances across all topics. Below, we\nexplain each of these steps in more detail.\n4.1 Projection and Clustering\nGiven the tweets for each topic, we compute the\nsimilarity between the top 1,000 most active users.\nTo compute similarity, we construct a vector for\neach user containing the number of all the accounts\nthat a user has retweeted, and then we compute\nthe pairwise cosine similarity between them. For\nexample, if user A has only retweeted user B 3\ntimes, user C 5 times and user E 8 times, then\nuser A\u2019s vector would be (0, 3, 5, 0, 8, 0, 0, ... 0).\nSolely using the retweeted accounts as features has\nbeen shown to be effective for stance classi\ufb01cation\n(Darwish et al., 2020; Magdy et al., 2016a). Fi-\nnally, we perform dimensionality reduction and we\nproject the users using Uniform Manifold Approxi-\nmation and Projection (UMAP). When performing\ndimensionality reduction, UMAP places users on\na two-dimensional plane such that similar users\nare placed closer together and dissimilar users are\npushed further apart. Figure 2 shows the top users\nfor the \u201cmidterm\u201d topic projected with UMAP onto\nthe 2D plane. After the projection, we use Mean\nShift to cluster the users as shown in Figure 2. This\nis the best setup described in (Darwish et al., 2020).\n1.00\n 0.75\n 0.50\n 0.25\n 0.00 0.25 0.50 0.75 1.001.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00\nCluster\nCluster 0\nCluster 1\nNot clusteredFigure 2: Top active users on the midterm topic clus-\ntered using UMAP + Mean Shift.\nClustering high-dimensional data often yields sub-\noptimal results, but can be improved by projecting\nto a low-dimensional space (Darwish et al., 2020).\n4.2 Supervised Classi\ufb01cation\nSince unsupervised stance detection is only able to\nclassify the most vocal users, which only constitute\na minority of the users, we wanted to assign stance\nlabels to as many additional users as we can. Given\nthe clusters of users that we obtain for each topic,\nwe retain the two largest clusters for each topic,\nand we assign cluster labels to the users contained\ntherein. Next, we use all the automatically labeled\nusers for each topic to train a supervised classi-\n\ufb01er using the accounts that each user retweeted\nas features (same as the features we used to com-\npute user similarity earlier). For classi\ufb01cation, we\ntrain a FastText model using the default parameters,\nand then we classify all other users with \ufb01ve or\nmore retweeted accounts, only accepting the classi-\n\ufb01cation if FastText was more than 80% con\ufb01dent\n(70\u201390% yielded nearly identical results).\nTopic No. of Users Clustered Classi\ufb01ed\nUsers Users\nclimate change 724,470 860 5,851\ngun control 973,206 813 11,281\nIlhan Omar 563,706 723 25,484\nimmigration 940,840 901 22,456\nmidterm elections 312,954 860 12,765\npolice brutality & racism 1,175,081 891 18,978\nKavanaugh 809,835 891 10,100\nvaccine 194,245 545 556\nTable 2: Users per topic: total number of users, umber\nof clustered users, and number of automatically labeled\nusers.\nIn order to obtain a rough estimate of the ac-\ncuracy of the model, we trained FastText using\na random 80% subset of the clustered users for\neach topic and we tested on the remaining 20%.\nThe accuracy was consistently above 95% for all\ntopics. This does not mean that this model can\npredict the stance for all users that accurately \u2014\nthe clustered users were selected to be the most\nactive ones. Rather, it shows that the classi\ufb01er can\nsuccessfully capture what the previous, unsuper-\nvised step has already learned. Table 2 lists the\ntotal number of users who authored the tweets for\neach topic, the number of users who were automat-\nically clustered using the aforementioned unsuper-\nvised clustering technique, and the number of users\nwho were automatically labeled afterwards using\nsupervised classi\ufb01cation. Given that we applied\nunsupervised stance detection to the most active\n1,000 users, the majority of the users appeared in\nthe largest two clusters (shown in Table 2).\n4.3 Calculating Valence Scores\nGiven all the labeled users for each topic, we com-\nputed a valence score for each in\ufb02uencer. As\nmentioned earlier, the valence score ranges be-\ntween [\u00001;1], where a value close to 1 implies\nit is strongly associated with one group of users,\n\u00001 shows it is strongly associated with the other\ngroup of users, and 0 means that it is being shared\nor cited by both groups. The original valence score\ndescribed by Conover et al. (2011a) is calculated\nas follows:\nV(u) =2t f(u;C0)\ntotal(C0)\nt f(u;C0)\ntotal(C0)+t f(u;C1)\ntotal(C1)\u00001 (1)\nwhere t f(u;C0)is the number of times (term fre-\nquency) item uis cited by group C0, and total(C0)\nis the sum of the term frequencies of all items cited\nbyC0.t f(u;C1)andtotal(C1)are de\ufb01ned in a sim-\nilar fashion.We use the above equation to compute valence\nscores for the retweeted accounts, but we using\na modi\ufb01ed version for calculating the score for\nin\ufb02uencers ( I):\nV(I) =2t f(I;C0)\ntotal(C0)\nt f(I;C0)\ntotal(C0)+t f(I;C1)\ntotal(C1)\u00001 (2)\nwhere\nt f(I;Ci) =\u00e5a2ITCi[ln(Cnt(a;Ci))+1]\ntotal(Ci) =\u00e5It f(I;Ci)\nIn the latter equation, Cnt(a;Ci)is the number\nof times article awas cited by users from cluster Ci.\nIn essence, we are replacing term frequencies with\nthe natural log of the term frequencies. We opted to\nmodify the equation in order to tackle the following\nissue: if users from one of the clusters, say C1, cite\nonly one single article from some media source a\nlarge number of times (e.g., 2,000 times), while\nusers from the other cluster ( C0) cite 10 other arti-\ncles from the same media 50 times each, then using\nequation 1 would result in a valence score of \u00000.6.\nWe would then regard the given media as having\nan opposing stance to the stance of users in C0. Al-\nternatively, using the natural log would lead to a\nvalence score close to 0.88. Thus, dampening term\nfrequencies using the natural log has the desired\neffect of balancing between the number of articles\nbeing cited by each group and the total number of\ncitations. We bin the valence scores between \u00001\nand 1 into \ufb01ve equal size bands as follows:\nCat(V) =8\n>>>>>><\n>>>>>>:\u0000\u0000 ;ifs2[\u00001;\u00000:6)\n\u0000; ifs2[\u00000:6;\u00000:2)\n0; ifs2[\u00000:2;0:2)\n+; ifs2[0:2;0:6)\n++ ;ifs2[0:6;1](3)\n5 Characterizing the In\ufb02uencers\nWe use valence to characterize the leaning of all\ncited in\ufb02uencers for each of the topics. Table 3\nshows the valence categories for the top-cited me-\ndia sources across all topics. It also shows each\nmedia\u2019s factuality of reporting, i.e., trustworthiness,\nand bias (ranging from far-left to far-right) as de-\ntermined by mediaBiasFactCheck.com . Since the\nchoice of which cluster should be C0and which\nwould be C1is arbitrary, we can multiply by \u00001\nthe valence scores for any topic and the meaning\nof the results would stay the same.\nEXTREME-LEFT\nLEFT\nLEFT-CENTER\nCENTER\nRIGHT-CENTER\nRIGHT\nEXTREME-RIGHT\nBias-- - 0 + ++Valence Category0 3 24 18 31 110 58\n0 2 8 3 8 9 3\n0 4 25 13 20 4 0\n0 14 45 21 14 2 0\n3 101 148 70 36 6 3\n020406080100120140Figure 3: Valence category vs. bias: number of media.\nWe resorted to doing so for some topics in order\nto align the extreme valence bands across all topics.\nGiven tweet samples from users in a given cluster\nfor a given topic, labeling that cluster manually was\nstraightforward with almost no ambiguity. Table 4\nshows the most frequently cited media source for\neach topic and for each valence band.\nOf the 5,406 unique media sources that have\nbeen cited in tweets across all topics, 806 have\nknown political bias from mediaBiasFactCheck.\ncom. Figure 3 shows the confusion matrix between\nour valence categories and the goold labels from\nmediaBiasFactCheck.com .\nWe notice that many of the media that have a\nnegative valence score (categories \u0000and\u0000\u0000) are\nclassi\ufb01ed on the right side of the political spec-\ntrum by mediaBiasFactCheck.com , while most\nmedia with positive scores (categories +and++)\nare classi\ufb01ed as slightly left-leaning. Although\nthere are almost no extreme-left cases, there is a\ncorrelation between bias and our valence score.\nmediaBiasFactCheck.com seems to rarely catego-\nrize media sources as \u201cextreme-left\u201d. This could\nbe a re\ufb02ection of reality or it might imply that\nmediaBiasFactCheck.com has an inherent bias.\nWe also computed the valence scores for the\ntop-200 retweeted accounts, and we assigned each\naccount a valence category based on the score. In-\ndependently, we asked a person who is well-versed\nwith US politics to label all the accounts as left, cen-\nter, or right. When labeling accounts, right-leaning\ninclude those expressing support for Trump, the\nRepublican party, and gun rights, opposition to\nabortion, and disdain for Democrats.\n1.00\n 0.75\n 0.50\n 0.25\n 0.00 0.25 0.50 0.75 1.00Figure 4: The top-200 retweeted accounts, projected on\na number line according to their average valence.\nAs for left-leaning accounts, they include those\nattacking Trump and the Republicans, and ex-\npressing support for the Democratic party and\nfor Liberal social positions. If the retweeted ac-\ncount happens to be a media source, we used\nmediaBiasFactCheck.com . Table 5 compares the\nper-topic valence for each retweeted account along\nwith the average category and the true label.\nIt is noteworthy that all top-200 retweeted ac-\ncounts have extreme valence categories on average\nacross all topics. Their average valence scores, with\none exception, appear between \u00000.6 and\u00001.00 for\nright, and between 0.6 and 1 for left (see Figure 4).\nOf those manually and independently tagged ac-\ncounts, all that were tagged as left-leaning have\na strong positive valence score and all that were\ntagged as right-leaning have a strong negative va-\nlence score. Only two accounts were manually la-\nbeled as center , namely Reuters and CSPAN, which\nis a US channel that broadcasts Federal Govern-\nment proceedings, and they had valence scores of\n0.55 and 0.28, respectively. Though their absolute\nvalues are lower than those of all other sources,\nthey are mapped to the +valence category.\nTable 3 summarizes the valence scores for the\nmedia across all topics. Table 4 lists the most cited\nmedia sources for each topic and for each of the\n\ufb01ve valence bands. The order of the bands from\ntop to bottom is: ++,+,0,\u0000and\u0000\u0000. The table\nalso includes the credibility and the political lean-\ning tags from mediaBiasFactCheck.com . The key\nobservations from the table as follows:\n1.Most right-leaning media appear overwhelm-\ningly in the\u0000and\u0000\u0000valence categories. Con-\nversely, left-leaning media appear in all valence\ncategories, except for the \u0000\u0000 category. This\nimplies that left-leaning users cite right-leaning\nmedia sparingly. We looked at some instances\nwhere right-leaning users cited left-leaning me-\ndia, and we found that in many cases the cited\narticles reinforced a right-leaning viewpoint. For\nexample, right-leaning users shared a video from\nthehill.com , a left-center site, 2,398 times for the\npolice racism topic. The video defended Trump\nagainst charges of racism by Lynne Patton, a long-\ntime African-American associate of Trump.\nMedium\nfactuality\nbias\nAverage\nclimate change\ngun control\nilhan\nimmigration\nmidterm\npolice & racism\nKavanaugh\nvaccine\nthehill.com H L-C +++ 0 ++ + + + + ++ ++\ntheguardian.com H L-C ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nwashingtonpost.com H L-C ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nbreitbart.com VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nfoxnews.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnytimes.com H L-C ++++++ + ++ + + + ++ ++ ++\ncnn.com M L +++ + ++ + ++ + + ++ +\napple.news +++ 0 0 + 0 0 + + ++\ndailycaller.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nrawstory.com M L ++++++ ++ ++ ++ ++ ++ ++ ++ ++\nhuf\ufb01ngtonpost.com H L ++++++ ++ ++ ++ ++ + ++ ++ ++\ntruepundit.com L \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnbcnews.com H L-C +++\u0000\u0000 ++ + ++ + + ++ ++\nwesternjournal.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nreuters.com VH C +++ + ++ ++ + + + + ++\nwashingtonexaminer.com H R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\nthegatewaypundit.com VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\npolitico.com H L-C +++ + + + + ++ + + ++\nnpr.org VH L-C +++ 0 ++ ++ ++ 0 ++ ++ ++\ntownhall.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nmsn.com H L-C +++ + + + 0 ++ 0 ++ 0\nnypost.com M R-C\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000 +\u0000\u0000\u0000\nvox.com H L ++++++ ++ ++ ++ ++ ++ + ++ ++\nthedailybeast.com H L ++++++ ++ ++ + ++ ++ + ++ ++\nbbc.com H L-C +++ + + ++ ++ 0 + + ++\nindependent.co.uk H L-C ++++++ ++ + ++ ++ ++ + ++ ++\nilovemyfreedom.org VL Far R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nthinkprogress.org M L ++++++ ++ ++ ++ ++ ++ ++ ++ ++\ndailywire.com M R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 ++\npscp.tv \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000 0\u0000\ndailymail.co.uk VL R\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nmsnbc.com M L ++++++ ++ ++ ++ ++ + ++ ++\ndailykos.com M L ++++++ ++ ++ ++ ++ + ++ ++\nbloomberg.com H L-C +++ + ++ 0 ++ + 0 + ++\nusatoday.com H L-C +++ + + 0 + ++ + 0 +\nTable 3: Media valence categories for each topic with included average column. Plus ( +) and minus (\u0000) signify\nleft or right leaning, respectively. Factuality: Very High (VH), High (H), Mixed (M), Low (L), Very Low (VL).\nBias: Left (L), Left-Center (L-C), Center (C), Right-Center (R-C), Right (R), Far Right (Far R). Blank cells mean\nthat we did not have information.\n2.Most right-leaning sources in the \u0000\u0000cate-\ngory have mixed, low, or very low factuality. Con-\nversely, most left-leaning sites appearing in the \u0000\nvalence category have high or very high factuality.\nSimilarly for the vaccine topic, where high credi-\nbility sources, such as fda.gov andnih.gov , are\nfrequently cited by anti-vaccine users, mostly to\nsupport their beliefs.\n3.The placements of sources in different cate-\ngories are relatively stable across topics. For exam-\nple,washingtonPost.com andtheguardian.com\nexclusively appear in the ++ category, while\nbreitbart.com andfoxnews.com consistently ap-\npear in the\u0000\u0000category.\n6 Predicting Media Bias\nGiven the stances of users on the aforementioned\neight topics, we leverage this information to predict\nmedia bias. Speci\ufb01cally, we describe in this section\nhow we make use of the valence scores, as well\nas other features, namely graph and contextualized\ntext embeddings, to train supervised classi\ufb01ers for\nthis purpose.Valence Scores. We use valence scores in two\nways. First, we average the corresponding va-\nlence across the different polarizing topics to ob-\ntain an average valence score for a given target\nnews medium. This is an unsupervised method\nfor computing polarity. Second, we train a Logis-\ntic Regression classi\ufb01er that uses the calculated\nvalence scores as features and annotations from\nmediaBiasFactCheck.com as gold target labels in\norder to predict the general political leaning of a tar-\nget news medium. We merged \u201cleft\u201d and \u201cextreme\nleft\u201d, and similarly we merged \u201cright\u201d and \u201cextreme\nright\u201d. We discarded media labeled as being \u201cleft-\ncenter\u201d and \u201cright-center\u201d. Each news medium was\nrepresented by an 8-dimensional vector containing\nthe valence scores for the above topics. In the ex-\nperiments, we used the lbfgs solver and C=0:1.\nWe used two measures to evaluate its performance,\nnamely accuracy and mean absolute error (MAE).\nThe latter is calculated by considering the different\nclasses as ordered and equally distant from each\nother, i.e., if the model predicts right and the true\nlabel is left, this amounts to an error equal to 2.\nclimate change gun control Ilhan Omar immigration\ntheguardian.com H L-C thehill.com H L-C washingtonpost.com H L-C theguardian.com H L-C\nwashingtonpost.com H L-C cnn.com M L theguardian.com H L-C washingtonpost.com H L-C\nindependent.co.uk H L-C nytimes.com H L-C mondoweiss.net H L cnn.com M L\nwef.ch npr.org VH L-C thinkprogress.org M L huf\ufb01ngtonpost.com H L\nvox.com H L washingtonpost.com H L-C haaretz.com H L-C npr.org VH L-C\nnytimes.com H L-C politico.com H L-C nytimes.com H L-C thehill.com H L-C\nbbc.com H L-C usatoday.com H L-C thehill.com H L-C nytimes.com H L-C\ncnn.com M L msn.com H L-C politico.com H L-C reuters.com VH C\nreuters.com VH C bbc.com H L-C cnn.com M L politico.com H L-C\nbloomberg.com H L-C cnbc.com H L-C apple.news usatoday.com H L-C\nthehill.com H L-C apple.news mediaite.com H L apple.news\napple.news sun-sentinel.com H R-C usatoday.com H L-C msn.com H L-C\nnpr.org VH L-C nypost.com M R-C yahoo.com M L-C pscp.tv\nseattletimes.com H L-C dailymail.co.uk VL R timeso\ufb01srael.com H L-C whitehouse.gov M R\nnewsweek.com M L mailchi.mp theatlantic.com H L-C texastribune.org H C\nchange.org H L washingtontimes.com H R-C nypost.com M R-C dailymail.co.uk VL R\nlatimes.com H L-C breaking911.com VL jpost.com H C nypost.com M R-C\ndailymail.co.uk VL R chicagotribune.com H R-C dailymail.co.uk VL R zerohedge.com M\nclimatechangedispatch.com rt.com M R-C algemeiner.com H R-C ir.shareaholic.com\ncnbc.com H L-C forbes.com M R-C startribune.com H L-C breaking911.com VL\nforbes.com M R-C breitbart.com VL Far R foxnews.com M R breitbart.com VL Far R\nbreitbart.com VL Far R foxnews.com M R breitbart.com VL Far R illegalaliencrimereport.com\ndailycaller.com M R ammoland.com H R townhall.com M R washingtonexaminer.com H R\ntambonthongchai.com dailycaller.com M R change.org H L foxnews.com M R\nwattsupwiththat.com L bearingarms.com M R hannity.com westernjournal.com M R\nmidterm police & racism Kavanaugh vaccine\nwashingtonpost.com H L-C washingtonpost.com H L-C thehill.com H L-C thehill.com H L-C\ntheguardian.com H L-C rawstory.com M L washingtonpost.com H L-C theguardian.com H L-C\nrawstory.com M L huf\ufb01ngtonpost.com H L cnn.com M L washingtonpost.com H L-C\ntacticalinvestor.com theguardian.com H L-C nytimes.com H L-C vaxopedia.org\nvox.com H L nytimes.com H L-C huf\ufb01ngtonpost.com H L nytimes.com H L-C\nthehill.com H L-C thehill.com H L-C politico.com H L-C cnn.com M L\nreuters.com VH C apple.news apple.news statnews.com H C\nnytimes.com H L-C cnn.com M L yahoo.com M L-C latimes.com H L-C\ncnn.com M L nbcnews.com H L-C apnews.com VH C cbc.ca H L-C\ndailykos.com M L thedailybeast.com H L latimes.com H L-C usatoday.com H L-C\napple.news msn.com H L-C usatoday.com H L-C cdc.gov VH\nsagagist.com.ng pscp.tv mediaite.com H L medium.com M L-C\nbbc.com H L-C bloomberg.com H L-C theweek.com H L-C newsroom.fb.com\nalzwaaj.com politics.theonion.com lawandcrime.com help.senate.gov\nwashingtonexaminer.com H R rollcall.com VH C cnbc.com H L-C msn.com H L-C\ndailymail.co.uk VL R mediaite.com H L pscp.tv change.org H L\npbs.org H L-C dailymail.co.uk VL R nypost.com M R-C fda.gov\nzerohedge.com M news.sky.com H L-C ir.shareaholic.com variety.com\najc.com H L-C newsone.com H L-C rollcall.com VH C\nveritablenouvelordre.forumcanada.org aol.com H L-C c-span.org VH C\nbreitbart.com VL Far R breitbart.com VL Far R foxnews.com M R ncbi.nlm.nih.gov VH\nfoxnews.com M R defensemaven.io truepundit.com L vaccineimpact.com\ndailycaller.com M R foxnews.com M R dailycaller.com M R naturalnews.com M\nilovemyfreedom.org VL Far R thegatewaypundit.com VL Far R breitbart.com VL Far R vaccines.me\nwesternjournal.com M R nypost.com M R-C thegatewaypundit.com VL Far R thevaccinereaction.org\nTable 4: Top 5 websites per valence category for each topic.\nAccount\nTruth\nAverage\nclimate change\ngun control\nilhan\nimmigration\nmidterm\npolice & racism\nKavanaugh\nvaccine\nrealdonaldtrump R\u0000\u0000\u0000\u0000\u0000\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ncharliekirk11 R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkylegrif\ufb01n1 L ++++++ ++ ++ ++ ++ ++ ++ ++\ndbongino R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkamalaharris L ++++++ ++ ++ ++ ++ ++ ++\nmitchellvii R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nrealsaavedra R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nkrassenstein L ++++++ ++ ++ ++ ++ ++ ++ ++\nrealjack R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnbcnews L ++++++ ++ ++ + ++ ++ ++ ++ ++\neducation4libs R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nnra R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ndonaldjtrumpjr R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nshannonrwatts L ++++++ ++ ++ ++ ++ ++\nthehill L ++++++ ++ ++ + ++ + + ++ ++\nrealjameswoods R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\ngopchairwoman R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\njackposobiec R\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\nfunder L ++++++ ++ ++ ++ ++ ++ ++ ++\ncnn L ++++++ ++ ++ ++ ++ 0 ++ ++ ++\najplus L ++++++ ++ ++ ++ ++ ++ ++ 0 ++\nrashidatlaib L ++++++ ++ ++ ++ ++ +\nstevescalise R\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\njordan sather ?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\naoc L ++++++ ++ ++ ++ ++\nTable 5: User valence categories for each topic, preceded by an average column, and a ground truth label. When a\ncell is blank, there is insuf\ufb01cient data for that particular topic.\nNo Valence With Valence\nAcc MAE Acc MAE\nBaseline 1 (majority class) 43.3 .856 43.3 .856\nBaseline 2 (average valence) \u2013 \u2013 68.0 .330\nValence scores \u2013 \u2013 75.2 .278\nBERT (article title) 60.6 .539 78.3 .264\nBERT (article content) 61.1 .526 79.2 .255\nBERT (title+content) 62.2 .510 80.8 .228\nBERT(Tweet) 64.0 .485 73.6 .302\nGraphEmbM 63.5 .468 69.1 .380\nGraphEmbH 66.9 .425 71.8 .347\nGraphEmbM+H 68.0 .400 79.0 .251\nGraphEmbM+H+BERT (tweet) 72.5 .358 80.5 .230\nGraphEmbM+H+BERT (tweet, content) 76.1 .311 81.2 .221\nGraphM+H+BERT (tweet, title, content) 78.1 .284 82.6 .206\nTable 6: Predicting media bias.\nThe results are shown in Table 6, where we can\nsee that using the average valence score yields\n68.0% accuracy (0.330 MAE) compared to 75.2%\naccuracy (0.278 MAE) when using the eight indi-\nvidual valence scores as features.\nGraph embeddings. We further use graph em-\nbeddings, generated by building a User-to-Hashtag\ngraph (U2H) and a User-to-Mention (U2M) graph\nand then running node2vec on both (Atanasov et al.,\n2019), producing two types of graph embeddings.\nWhen using graph embeddings, we got worse re-\nsults compared to our previous setup with valence\nscores (see Table 6). However, when we combine\nthem with the valence scores, we observe a sizable\nboost in performance, up to 11% absolute.\nTweets. We also experimented with BERT-base.\nWe used the text of the tweets that cite the me-\ndia we are classifying. For classi\ufb01cation, we fed\nBERT representations of tweets to a dense layer\nwith softmax output to \ufb01ne-tune it with the textual\ncontents of the tweets. We trained at the tweet level,\nand we averaged the scores (from softmax) for all\ntweets from the same news medium to obtain an\noverall label for that news medium. The accuracy\nis much lower than for the valence scores: 64.0%\naccuracy vs. 75.2% for supervised and 68.0% for\nunsupervised.\nArticle titles and text. Using the BERT setup\nforTweets , we used the titles and the full text of\nup to 100 articles from each of the target media.\nWhen using the full text of articles, we balanced the\nnumber of articles per news medium. We trained\ntwo separate BERT models, one on the titles and\nanother one on the full text (content). Both models\ndid worse than using valence alone, but the combi-\nnation improved over valence only.System Combination. We combined different\nsetups including using all the aforementioned mod-\nels in combination. Using graph embeddings\n(GraphH + GraphM) with BERT embeddings\n(Tweet+Title+Content) and valence yielded the\nbest results with accuracy of 82.6% and MAE of\n.206. If we remove valence from the combination,\nthe accuracy drops by 4.5% while MAE jumps by\n.078, absolute. This suggests that valence is a very\neffective feature that captures important informa-\ntion, complementary to what can be modeled using\ngraph and contextualized text embeddings.\n7 Conclusion and Future Work\nWe have presented a method for predicting the gen-\neral political leaning of media sources and popular\nTwitter users, as well as their stances on speci\ufb01c\npolarizing topics. Our method uses retweeted ac-\ncounts, and a combination of dimensionality reduc-\ntion and clustering algorithms, namely UMAP and\nMean Shift, in order to produce sets of users that\nhave opposing opinions on speci\ufb01c topics. Next,\nwe expand the discovered sets using supervised\nlearning that is trained on the automatically discov-\nered user clusters. We are able to automatically\ntag large sets of users according to their stance of\npreset topics. Users\u2019 stances are then projected to\nthe in\ufb02uencers that are being cited in the tweets for\neach of the topics using the so-called valence score .\nThe projection allows us to tag a large number of\nin\ufb02uencers with their stances on speci\ufb01c issues and\nwith their political leaning in general (i.e., leftvs.\nright ) with high accuracy and with minimal human\neffort. The main advantage of our method is that it\ndoes not require manual labeling of entity stances,\nwhich requires both topical expertise and time. We\nalso investigated the quality of the valence features,\nand we found that valence scores help to predict\nmedia bias with high accuracy.\nIn future work, we plan to increase the number\nof topics that we use to characterize media. Ideally,\nwe would like to automatically identify such polar-\nizing topics. Doing so would enable us to easily\nretarget this work to new countries and languages.\nAcknowledgments\nThis research is part of the Tanbih project1, which\naims to limit the effect of \u201cfake news,\u201d propaganda\nand media bias by making users aware of what they\nare reading.\n1http://tanbih.qcri.org/\nReferences\nAmjad Abu-Jbara, Ben King, Mona Diab, and\nDragomir Radev. 2013. Identifying opinion sub-\ngroups in Arabic online discussions. In Proceed-\nings of the 51st Annual Meeting of the Association\nfor Computational Linguistics , ACL \u201913, pages 829\u2013\n835, So\ufb01a, Bulgaria.\nJisun An, Meeyoung Cha, Krishna Gummadi, Jon\nCrowcroft, and Daniele Quercia. 2012. Visualizing\nmedia bias through Twitter. In Proceedings of the\nInternational AAAI Conference on Web and Social\nMedia , Dublin, Ireland, pages 2\u20135.\nAtanas Atanasov, Gianmarco De Francisci Morales,\nand Preslav Nakov. 2019. Predicting the role of po-\nlitical trolls in social media. In Proceedings of the\n2019 SIGNLL Conference on Computational Natu-\nral Language Learning , CoNLL \u201919, pages 1023\u2013\n1034, Hong Kong, China.\nAkshat Bakliwal, Jennifer Foster, Jennifer van der Puil,\nRon O\u2019Brien, Lamia Tounsi, and Mark Hughes.\n2013. Sentiment analysis of political tweets: To-\nwards an accurate classi\ufb01er. In Proceedings of the\nWorkshop on Language Analysis in Social Media ,\npages 49\u201358, Atlanta, GA, USA.\nPablo Barber \u00b4a. 2015. Birds of the same feather tweet\ntogether: Bayesian ideal point estimation using Twit-\nter data. Political Analysis , 23(1):76\u201391.\nPablo Barber \u00b4a and Gaurav Sood. 2015. Follow your\nideology: Measuring media ideology on social net-\nworks. In Proceedings of the Annual Meeting of\nthe European Political Science Association , Vienna,\nAustria.\nPablo Barber and Gonzalo Rivero. 2015. Understand-\ning the political representativeness of Twitter users.\nSocial Science Computer Review , 33(6):712\u2013729.\nAdam Bermingham and Alan Smeaton. 2011. On us-\ning Twitter to monitor political sentiment and pre-\ndict election results. In Proceedings of the Workshop\non Sentiment Analysis where AI meets Psychology ,\nSAAIP \u201911, pages 2\u201310, Chiang Mai, Thailand.\nJavier Borge-Holthoefer, Walid Magdy, Kareem Dar-\nwish, and Ingmar Weber. 2015. Content and net-\nwork dynamics behind Egyptian political polariza-\ntion on Twitter. In Proceedings of the 18th ACM\nConference on Computer Supported Cooperative\nWork & Social Computing , CSCW \u201915, pages 700\u2013\n711, Vancouver, BC, Canada.\nRaviv Cohen and Derek Ruths. 2013. Classifying po-\nlitical orientation on Twitter: It\u2019s not easy! In Pro-\nceedings of the 7th International AAAI Conference\non Weblogs and Social Media , ICWSM \u201913, pages\n91\u201399, Cambridge, MA, USA.Elanor Colleoni, Alessandro Rozza, and Adam Arvids-\nson. 2014. Echo chamber or public sphere? Predict-\ning political orientation and measuring political ho-\nmophily in Twitter using big data. Journal of Com-\nmunication , 64(2):317\u2013332.\nMichael Conover, Jacob Ratkiewicz, Matthew R Fran-\ncisco, Bruno Gonc \u00b8alves, Filippo Menczer, and\nAlessandro Flammini. 2011a. Political polarization\non Twitter. In Proceedings of the Fifth Interna-\ntional AAAI Conference on Weblogs and Social Me-\ndia, ICWSM \u201911, pages 89\u201396, Barcelona, Spain.\nMichael D Conover, Bruno Gonc \u00b8alves, Jacob\nRatkiewicz, Alessandro Flammini, and Filippo\nMenczer. 2011b. Predicting the political alignment\nof Twitter users. In Proceedings of the 2011 IEEE\nThird International Conference on Privacy, Security,\nRisk and Trust (PASSAT) and 2011 IEEE Third\nInernational Conference on Social Computing\n(SocialCom) , pages 192\u2013199, Boston, MA, USA.\nKareem Darwish. 2018. To Kavanaugh or not to Ka-\nvanaugh: That is the polarizing question. arXiv\npreprint arXiv:1810.06687 .\nKareem Darwish, Michael Aupetit, Peter Stefanov, and\nPreslav Nakov. 2020. Unsupervised user stance de-\ntection on Twitter. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nICWSM \u201920, Atlanta, GA, USA.\nKareem Darwish, Walid Magdy, Afshin Rahimi, Tim-\nothy Baldwin, and Norah Abokhodair. 2018. Pre-\ndicting online islamophobic behavior after #ParisAt-\ntacks. The Journal of Web Science , 4(3):34\u201352.\nKareem Darwish, Walid Magdy, and Tahar Zanouda.\n2017. Improved stance prediction in a user sim-\nilarity feature space. In Proceedings of the 2017\nIEEE/ACM International Conference on Advances\nin Social Networks Analysis and Mining 2017 ,\nASONAM \u201917, pages 145\u2013148, Sydney, Australia.\nYajuan Duan, Furu Wei, Ming Zhou, and Heung-Yeung\nShum. 2012. Graph-based collective classi\ufb01cation\nfor tweets. In Proceedings of the 21st ACM Inter-\nnational Conference on Information and Knowledge\nManagement , CIKM \u201912, pages 2323\u20132326, Maui,\nHI, USA.\nJames H Fowler, Michael T Heaney, David W Nick-\nerson, John F Padgett, and Betsy Sinclair. 2011.\nCausality in political networks. American Politics\nResearch , 39(2):437\u2013480.\nMatthew Gentzkow and Jesse M Shapiro. 2011. Ide-\nological segregation online and of\ufb02ine. The Quar-\nterly Journal of Economics , 126(4):1799\u20131839.\nTim Groseclose and Jeffrey Milyo. 2005. A measure\nof media bias. The Quarterly Journal of Economics ,\n120(4):1191\u20131237.\nKazi Saidul Hasan and Vincent Ng. 2013. Stance clas-\nsi\ufb01cation of ideological debates: Data, models, fea-\ntures, and constraints. In Proceedings of the Sixth In-\nternational Joint Conference on Natural Language\nProcessing , IJCNLP \u201913, pages 1348\u20131356, Nagoya,\nJapan.\nKazi Saidul Hasan and Vincent Ng. 2014. Why are\nyou taking this stance? Identifying and classifying\nreasons in ideological debates. In Proceedings of the\n2014 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201914, pages 751\u2013762,\nDoha, Qatar.\nItai Himelboim, Stephen McCreery, and Marc Smith.\n2013. Birds of a feather tweet together: Integrat-\ning network and content analyses to examine cross-\nideology exposure on Twitter. Journal of Computer-\nMediated Communication , 18(2):40\u201360.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for ef\ufb01cient text\nclassi\ufb01cation. In Proceedings of the 15th Confer-\nence of the European Chapter of the Association for\nComputational Linguistics , EACL \u201917, pages 427\u2013\n431, Valencia, Spain.\nWalid Magdy, Kareem Darwish, Norah Abokhodair,\nAfshin Rahimi, and Timothy Baldwin. 2016a. #isi-\nsisnotislam or #deportallmuslims?: Predicting un-\nspoken views. In Proceedings of the 8th ACM Con-\nference on Web Science , WebSci \u201916, pages 95\u2013106,\nHannover, Germany.\nWalid Magdy, Kareem Darwish, and Ingmar Weber.\n2016b. #FailedRevolutions: Using Twitter to study\nthe antecedents of ISIS support. First Monday ,\n21(2).\nAibek Makazhanov, Davood Ra\ufb01ei, and Muhammad\nWaqar. 2014. Predicting political preference of Twit-\nter users. Social Network Analysis and Mining ,\n4(1):1\u201315.\nSaif Mohammad, Svetlana Kiritchenko, Parinaz Sob-\nhani, Xiaodan Zhu, and Colin Cherry. 2016.\nSemEval-2016 task 6: Detecting stance in tweets.\nInProceedings of the 10th International Workshop\non Semantic Evaluation , SemEval \u201916, pages 31\u201341,\nSan Diego, CA, USA.\nJonathan Scott Morgan, Cliff Lampe, and Muham-\nmad Zubair Sha\ufb01q. 2013. Is news sharing on Twit-\nter ideologically biased? In Proceedings of the\n2013 Conference on Computer Supported Coopera-\ntive Work , CSCW 13, pages 887\u2013896, San Antonio,\nTX, USA.\nMarco Pennacchiotti and Ana-Maria Popescu. 2011a.\nDemocrats, Republicans and Starbucks af\ufb01cionados:\nuser classi\ufb01cation in Twitter. In Proceedings of\nthe 17th ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining , KDD 11,\npages 430\u2013438, San Diego, CA, USA.Marco Pennacchiotti and Ana-Maria Popescu. 2011b.\nA machine learning approach to Twitter user classi-\n\ufb01cation. In Proceedings of the Fifth International\nAAAI Conference on Weblogs and Social Media ,\nICWSM \u201911, pages 281\u2013288, Barcelona, Spain.\nFerran Pla and Llu \u00b4\u0131s-F. Hurtado. 2014. Political ten-\ndency identi\ufb01cation in Twitter using sentiment anal-\nysis techniques. In Proceedings of the 25th Inter-\nnational Conference on Computational Linguistics ,\nCOLING \u201914, pages 183\u2013192, Dublin, Ireland.\nDelip Rao, David Yarowsky, Abhishek Shreevats, and\nManaswi Gupta. 2010. Classifying latent user at-\ntributes in Twitter. In Proceedings of the 2nd In-\nternational Workshop on Search and Mining User-\nGenerated Contents , SMUC \u201910, pages 37\u201344,\nToronto, ON, Canada.\nFilipe N Ribeiro, Lucas Henrique, Fabricio Ben-\nevenuto, Abhijnan Chakraborty, Juhi Kulshrestha,\nMahmoudreza Babaei, and Krishna P Gummadi.\n2018. Media bias monitor: Quantifying biases of\nsocial media news outlets at large-scale. In Proceed-\nings of the Twelfth International AAAI Conference\non Web and Social Media , ICWSM \u201918, pages 290\u2013\n299, Stanford, CA, USA.\nDhanya Sridhar, James Foulds, Bert Huang, Lise\nGetoor, and Marilyn Walker. 2015. Joint models of\ndisagreement and stance in online debate. In Pro-\nceedings of the 53rd Annual Meeting of the Associa-\ntion for Computational Linguistics and the 7th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing , AXLL-IJCNLP \u201915, pages 116\u2013125, Bei-\njing, China.\nAmine Trabelsi and Osmar R Za \u00a8\u0131ane. 2018. Unsuper-\nvised model for topic viewpoint discovery in online\ndebates leveraging author interactions. In Proceed-\nings of the Twelfth International AAAI Conference\non Web and Social Media , ICWSM \u201918, pages 425\u2013\n433, Stanford, CA, USA.\nSvitlana V olkova, Glen Coppersmith, and Benjamin\nVan Durme. 2014. Inferring user political prefer-\nences from streaming communications. In Proceed-\nings of the 52nd Annual Meeting of the Association\nfor Computational Linguistics , ACL \u201914, pages 186\u2013\n196, Baltimore, MD, USA.\nIngmar Weber, Venkata R. Kiran Garimella, and\nAlaa Batayneh. 2013. Secular vs. Islamist polar-\nization in Egypt on Twitter. In Proceedings of\nthe 2013 IEEE/ACM International Conference on\nAdvances in Social Networks Analysis and Min-\ning, ASONAM \u201913, pages 290\u2013297, Niagara, ON,\nCanada.\nFelix Ming Fai Wong, Chee Wei Tan, Soumya Sen, and\nMung Chiang. 2013. Quantifying political leaning\nfrom tweets and retweets. In Proceedings of the Sev-\nenth International AAAI Conference on Weblogs and\nSocial Media , ICWSM \u201913, pages 640\u2013649, Boston,\nMA, USA.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Predicting the topical stance of media and popular twitter users", "author": ["P Stefanov", "K Darwish", "A Atanasov", "P Nakov"], "pub_year": "2019", "venue": "arXiv preprint arXiv \u2026", "abstract": "Discovering the stances of media outlets and influential people on current, debatable topics  is important for social statisticians and policy makers. Many supervised solutions exist for"}, "filled": false, "gsrank": 62, "pub_url": "https://arxiv.org/abs/1907.01260", "author_id": ["", "y7tlR6UAAAAJ", "", "DfXsKZ4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:U8fz0hA9nKwJ:scholar.google.com/&output=cite&scirp=61&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=U8fz0hA9nKwJ&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 10, "citedby_url": "/scholar?cites=12437883413358430035&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:U8fz0hA9nKwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1907.01260"}}, {"title": "DONALD: the 2M-document Dataset Of News Articles for studying the Language of Dubious information", "year": "2024", "pdf_data": "DONALD 1\nDONALD: the 2M-document Dataset Of News Articles for studying the Language of\nDubious information\nAlessandro Miani1, Fabio Carrella1, and Stephan Lewandowsky1,2\n1University of Bristol\n2University of Potsdam\nAuthor Note\nAM ( https://orcid.org/0000-0001-6610-3510) is supported by the Swiss National Science Foundation\n(SNSF, project number 214293, \u201cIn/coherent worldviews\u201d).\nFC (https://orcid.org/0000-0003-4918-3875) is supported by the Volkswagen Foundation (grant\n\u201cReclaiming individual autonomy and democratic discourse online: How to rebalance human and\nalgorithmic decision making\u201d).\nSL (https://orcid.org/0000-0003-1655-2013) acknowledges financial support from the European\nResearch Council (ERC Advanced Grant 101020961 PRODEMINFO), the Humboldt Foundation through a\nresearch award, the Volkswagen Foundation (grant \u201cReclaiming individual autonomy and democratic\ndiscourse online\u201d), the European Commission (Horizon 2020 grant 101094752 SoMe4Dem) and from UK\nResearch and Innovation (through EU Horizon replacement funding grant number 10049415).\nAddress correspondence to the authors at the School of Psychological Science, University of Bristol, 12a\nPriory Road, Bristol BS8 1TU, United Kingdom; email: alessandro.miani@bristol.ac.uk .\nA manuscript for DONALD is currently being prepared. Here, we describe the methods and\nthe repository folder with files so that researchers can start benefiting from DONALD.\nDONALD 2\nDONALD: the 2M-document Dataset Of News Articles for studying the Language of\nDubious information\n1 Introduction\nWe present DONALD (Dataset Of News Articles for studying the Language of Dubious information), a topic-\nmatched corpus comprising 2,173,172 news articles, gathered from 1,709 domains, focused on 172 politically\npolarizing topics. DONALD serves as a comprehensive resource for shedding light on the language of\nmisinformation circulating online, facilitating comparisons between documents from domains with varying\nideological biases and information quality.\nLike its predecessor LOCO (Miani, Hills, & Bangerter, 2021), DONALD is hierarchically structured. Doc-\numents are clustered within 1,709 domains, divided by their ideological stance (see Table 1). At the\nhighest level, four broad categories, or sub-corpora, define the domains\u2019 ideological biases (obtained from\nhttps://mediabiasfactcheck.com ), including liberal (884,190 documents from 619 domains), conservative\n(649,883 documents from 534 domains), and conspiratorial (220,231 documents from 218 domains) docu-\nments, as well as a group of documents from domains delivering high-quality and least-biased information\n(418,918 documents from 338 domains). Within these sub-corpora, domains are further divided by ideolog-\nical strength, ranging from 0 (least-biased) to 5 (extreme liberal/conservative bias and high conspiracism).\nDomains are also classified on a fine-grained measure of information quality derived from aggregating differ-\nent expert ratings (Lin et al., 2023).\nTable 1\nOverview of DONALD documents\u2019 ideological bias and strength, count, and quality of information\nIdeological Bias Label & Strength N Documents N Domains Quality\nLeft\nliberalL05 extreme 54,404 46 .444\nL03 left 257,742 884,190 187 619 .606 .711\nL01 center-left 572,044 386 .794\nLeast-bias LB00 least-biased 418,918 418,918 338 338 .877 .877\nRight\nconservativeR01 center-right 264,068 192 .741\nR03 right 249,624 649,833 204 534 .503 .520\nR05 extreme 136,141 138 .237\nCT01 low 26,595 29 .283\nCT02 mild 24,662 28 .210\nConspiratorial CT03 moderate 50,552 220,231 43 218 .201 .193\nCT04 strong 56,618 46 .186\nCT05 extreme 61,804 72 .150\nN= 4 N= 12 N= 2,173,172 N= 1,709\nNote. Domains\u2019 bias and strength were obtained by MBFC (mediabiasfactcheck). Ideological\nstrength is indicated in the label, ranging from 0 (least ideological strength) to 5 (the highest\nideological strength), see Section 2.1. Quality refers to domains\u2019 information quality as obtained\nby Lin et al. (2023), see Section 3.6. See Table 2 for the top-40 most frequent domains.\nDONALD 3\nDONALD revolves around 172 politically polarizing topics (e.g., abortion, Black Lives Matter). As such,\neach document is cross-nested within both ideologies and topics, enabling within- and between-ideology\nand topic comparisons. This multilevel structure allows researchers to consider the natural hierarchical\ngrouping of documents and it is useful for extracting specific linguistic markers between ideologically biased\nsub-corpora within specific topics. Researchers can, for instance, investigate whether the language used by\nconservative news on abortion differs from that of liberal news, or to what extent the language of extremely\nbiased political news converges with that of conspiracy theories.\nIn advancing the study of misinformation language, DONALD complements LOCO, notably in size and\nscope. While LOCO focuses on topics generating conspiracy theories, (e.g., the death of Princess Diana and\nMoon Landing), DONALD expands the scope to dubious information across ideologies relying on politically\npolarizing topics (e.g., abortion and Black Lives Matter). This expansion enriches the conspiracy sub-corpus\nwith out-of-domain topics. LOCO\u2019s emphasis on conspiracy theories did not require detailed classification of\nmainstream documents by ideological bias and strength, because its aim was to to match conspiracy theories\nwith non-conspiracy documents. In contrast, DONALD focuses on dubious information across ideologies,\nproviding a fine-grained classification of ideological bias, strength, and quality of information. The larger\nsize of DONALD (over 2 million documents compared to LOCO\u2019s 100,000) allows for creating subsets while\nmaintaining a substantial sample of documents.\nBeyond texts and metadata about the domains and the seeds used to retrieve documents (see Sections 2.1\nand 2.2), DONALD includes a rich set of features for each document. These features include titles, pub-\nlication dates (see Section 3.1), and various semantic indices such as keywords (extracted via TF-IDF, see\nSection 3.3), topics (extracted via latent Dirichlet allocation, see Section 3.4), and lexical features (extracted\nvia dictionaries such as LIWC and Empath, see Section 3.2). With these metrics, at both the domain and\ndocument levels, researchers can perform a wide range of analyses or subset the corpus prior to data analysis.\nUsing DONALD\u2019s raw texts, researchers can apply various Natural Language Processing techniques previ-\nously used in misinformation research to investigate biased language such as analyzing term co-occurrence\n(Fleckenstein, 2024), parsing texts to identify narrative elements via syntactic rules (Samory & Mitra, 2018),\nor analyzing word-formation patterns extracting nominal compounds (Miani, van der Plas, & Bangerter,\n2024). Document date information permits to test time-related hypotheses, such as the evolution of topics\nand lexical features over time (Lasser et al., 2023, 2022; Mayor & Miani, 2023). Researchers can also replicate\nsocial media studies by testing ideological differences in language use (Fong, Roozenbeek, Goldwert, Rathje,\n& van der Linden, 2021; Klein, Clutton, & Dunn, 2019; Lasser et al., 2023, 2022). Topics, seeds, keywords,\nand lexical features can serve as in/dependent variables or help further subset DONALD for analyses, such\nDONALD 4\nas focusing on health-related content between ideologies (Reiter-Haas, 2023) or building networks from their\nco-occurrence (Miani, Hills, & Bangerter, 2022). Using the URLs associated with each document, researchers\ncan extract HTML data to analyze web markup features as in previous fake news research (Castelo et al.,\n2019), or use the links-in-text variable to understand the extent to which documents deliver misinformation\n(Lasser et al., 2022). Efforts could also be made to develop annotation schemes and tools capable of auto-\nmatically identifying misinformation and ideological language (e.g., Diab, Nefriana, & Lin, 2024; Fort et al.,\n2023; Mompelat et al., 2022).\nIn the following sections, we describe how DONALD was built (see Section 2) and how we extracted the\nrich set of additional data (see Section 3). Finally, we describe the datasets stored in the repository (see\nSection 4). DONALD\u2019s data and metadata are stored at https://osf.io/6xpa2 .\n2 Building DONALD\nDONALD was built via web-search queries, by searching politically polarizing topics within domains pre-\nviously categorized by their ideological bias. This process involved pairing two sets of ready-made lists: a\nlist of domains ( Di) with a list of topic seeds ( Sj) to generate a list of queries ( Qij=Wi\u00d7Sj). Figure 1\nillustrates the workflow used in building DONALD: the lists of domains (see Section 2.1) and seeds (see\nSection 2.2) are combined to create search queries. These queries allowed us to extract the URLs associated\nwith documents (see Section 2.3), from which we obtained the human-readable text (see Section 2.4).\n2.1 List of domains\nThe list of domains was compiled in November 2020 by examining all news domains annotated in medi-\nabiasfactcheck (MBFC).1MBFC provides manual annotations and bias analyses for over 2,000 domains,\nevaluating each domain\u2019s bias based on criteria such as biased wording in headlines, factual sourcing, story\nchoices, and political affiliation. Since DONALD focuses on news articles, we selected domains that deliver\nnews, specifically those labeled by MBFC as:\n\u2022Least-biased , that exhibit minimal bias, use few loaded words, and provide factual reporting;\n\u2022Politically biased , that exhibit moderate to strong bias toward liberal/conservative causes and may use\nloaded words and publish misleading reports;\n\u2022Conspiracy , that may publish unverifiable information related to known conspiracy theories.\nMBFC also indicates the ideological strength within an ideology for each domain. It ranges from 0 (for\nleast-biased domains) to 5 (for political and conspiratorial ideologies). Note that conspiratorial ideology\n1https://mediabiasfactcheck.com\nDONALD 5\nDomains\nbbc\nfoxnews\ninfowars\n...Seeds\nAbortion\nclimate change\ncovid-19\n...\nSearch query (domain i\u00d7seed j)\nsite:bbc.com climate change\nWeb Search page\n1.bbc.com\u00b78 Feb 2024\u00b7\nhttps://www.bbc.com/url_01.html\nClimate change: \u2018Uncharted territory\u2019 fears after record hot ...\n2.bbc.com\u00b726 Aug 2024\u00b7\nhttps://www.bbc.com/url_02.html\nClimate change: The \u2019insane\u2019 plan to save the Arctic\u2019s sea-ice ...\n3.bbc.com\u00b75 Apr 2023\u00b7\nhttps://www.bbc.com/url_03.html\nNine breakthroughs for climate and nature in 2023 you ...\nURLs Extraction\n1.https://www.bbc.com/url_01.html\n2.https://www.bbc.com/url_02.html\n3.https://www.bbc.com/url_03.html\nText Extraction\nDoc1:Climate change could move \u201cinto\nuncharted territory\u201d if temperatures don\u2019t fall\nby the end of the year, a leading scientist has\ntold the BBC...\nDoc2:The ultimate goal of the Arctic exper-\niment is to thicken enough sea-ice to slow or\neven reverse the melting already seen, says\nDr Shaun Fitzgerald...\nDoc3:In a tumultuous year, the positive\nmilestones for the climate and nature might\nwell have gone under your radar. Future\nPlanet rounds up nine...Add to DONALD\n&\ngo to next query\nFigure 1|DONALD\u2019s construction workflow\nis assessed on 5 points while political ideology on 3 points. In order to match the extreme political bias\nwith extreme conspiratorial bias, we rescaled both scales from 1 to 5 (but note the fewer points in political\nideological strength).\nIn the initial stage, we compiled a list of 2,323 domains potentially suitable for scraping (i.e., extracting\ncontent from web pages). Once we crossed the list of domains with that of seeds (see Section 2.2), we\nscraped web pages from domains containing seeds and build the corpus. Because some domains did not\nallow to retrieve documents, the final number of domains included in DONALD is 1,709.\nIn Table 2, we show the top 40 most frequent domains, along with their document count, domain quality\n(assessed by Lin et al., 2023, see Section 3.6) as well as their group label. The full table for the whole\nDONALD 6\nlist of domains comprised in DONALD ( N= 1,709) can be found in our repository (see Section 4.4 for a\ndescription).\nTable 2\nTop 40 most frequent domains\nDomain N Quality Group\n1forbes.com 4,524 .830 R01\n2nypost.com 4,422 .639 R01\n3theguardian.com 4,339 .750 L01\n4express.co.uk 4,300 .370 R03\n5indianexpress.com 4,276 .760 L01\n6news.yahoo.com 4,162 .817 L01\n7financialexpress.com 4,089 .694 R01\n8huffpost.com 4,030 .568 L03\n9hindustantimes.com 4,010 .725 L01\n10latimes.com 4,006 .854 L01\n11mirror.co.uk 3,904 .695 L01\n12firstpost.com 3,867 .457 R01\n13patch.com 3,865 .933 LB00\n14gulfnews.com 3,846 .505 R01\n15ibtimes.com 3,833 .713 L01\n16pjmedia.com 3,760 .225 R05\n17globalnews.ca 3,757 .860 L01\n18ndtv.com 3,740 .716 L01\n19foxnews.com 3,715 .534 R03\n20deccanchronicle.com 3,639 .754 R01\n21nj.com 3,633 .885 L01\n22euronews.com 3,628 .823 LB00\n23inquisitr.com 3,586 .692 L01\n24deseret.com 3,567 .762 R01\n25mb.com.ph 3,561 .725 L01\n26nbcnewyork.com 3,545 .831 L01\n27economist.com 3,527 .926 LB00\n28inews.co.uk 3,526 .843 L01\n29insider.com 3,520 .847 L01\n30dailymail.co.uk 3,493 .384 R03\n31euractiv.com 3,488 .775 L01\n32dawn.com 3,480 .834 L01\n33detroitnews.com 3,476 .880 R01\n34people.com 3,453 .554 L03\n35news24.com 3,427 .871 LB00\n36nola.com 3,420 .887 L01\n37democraticunderground.com 3,417 .424 L05\n38newsnationnow.com 3,415 .947 LB00\n39scroll.in 3,409 .754 L01\n40techcrunch.com 3,405 .886 L01\n2.2 List of Seeds\nSeeds are keywords needed to retrieve web pages from domains through search engine queries (see e.g.,\nBaroni, Bernardini, Ferraresi, & Zanchetta, 2009; Miani et al., 2021). By mimicking user online behavior, a\nseed (e.g., climate change ) prompts the search engine to return web pages related to a specific topic (e.g.,\nDONALD 7\nclimate change; see Figure 1 and Section 2.3). We did so by further specify in the query, for each seed, the\ndomain from which the search engine should extract web pages (see Section 2.3).\nThe list of seeds was designed to cover topics considered polarizing in the US, often expressed with a strong\npartisan view (Darwish, Stefanov, Aupetit, & Nakov, 2020; Stefanov, Darwish, Atanasov, & Nakov, 2020).\nWe compiled a list of controversial political topics by surveying and merging external lists.2Additionally, to\nexpandthescopetounforeseentopics, weincludedinthelistofseedsthetopG20countriesandtheirleaders.3\nSome seeds were entered with synonyms to accommodate variations, such as vaccines andvaccination , or\ndifferent perspectives on the same topic, like water supply regulation ,water supply policy , etc. In total, we\ninitially compiled a set of 182 seeds, which ensures broad topic coverage. After constructing the corpus, we\nresolved synonyms for seeds that greatly overlapped semantically, e.g., vaccination being synonymous with\nvaccines andvaccination mandates . This process ensured consistency in topic coverage and search results.\nOnce the corpus was built, we resolved the synonyms (see Section A in Appendix). Once the seeds were\naggregated, we finally obtained a list of 172 seeds.\n2.3 URLs Extraction\nTo collect web pages relevant to each seed from the list of domains, we generated search queries by com-\nbining each seed with each domain. This resulted in 422,786 queries (182 seeds \u00d72,323 domains). For\nexample, combining the domain bbc.com with the seed climate change yielded the query \u201csite:bbc.com\nclimate change\u201d (see Figure 1). Between April 2022 and July 2023, we retrieved URLs using four search\nengines: Bing,Yahoo,Ecosia, andAOL.4Although we attempted to use additional search engines, none\npermitted scraping.5We then proceeded to extract URLs. For each query, we extracted the URLs pointing\nto web pages within the target domains by parsing the HTML page and extracting URL nodes using the\nR packages curl,xml2, andrvest(Ooms, 2023; Wickham, 2022; Wickham, Hester, & Ooms, 2023). Af-\nter obtaining the list of URLs, we cleaned it by removing URLs pointing to non-HTML files (i.e., URLs\nending in pdf, doc, docx, xlsx, xls, jpg, and jpeg). We removed duplicates URLs and recorded the each\nseed that hit the web page. If a web page was retrieved by more than one seed (e.g., \u201dvladimir_putin\u201d\nand\u201dukraine_and_russia\u201d ) we combined them (sorted alphabetically and separated by comma + space:\n2https://thebestschools.org/magazine/controversial-topics-research-starter ,\nhttps://academicinfluence.com/inflection/influence/most-controversial-topics-today ,\nhttps://libguides.umflint.edu/topics/current , accessed in March 2022\n3https://en.wikipedia.org/wiki/G20 , accessed in March 2022\n4https://www.bing.com ;https://search.yahoo.com ;https://www.ecosia.org ; andhttps://search.aol.com .\n5The list of search engines was obtained from https://www.semrush.com/blog/search-engine-list/ and\nhttps://blog.hubspot.com/marketing/top-search-engines . We also tried the following search engines: Google,\nDuckDuckGo ,Baidu,Yandex,Brave Search ,Neeva,You,Startpage ,Swisscows ,Ask.com,Naver, andInternet Archive .\nDONALD 8\n\u201dukraine_and_russia, vladimir_putin\u201d ). This refinement left us with 4,546,163 URLs eligible for text\nextraction.\n2.4 Text extraction\nText extraction was conducted between June and July 2023. We relied on the Python package goose6\nfor its superior performance in extracting useful text compared to other methods such as beautifulsoup ,\nboilerpipe ,HTML2text , andjustext(Miani et al., 2021). To limit storage space and computing resources\nduring DONALD\u2019s construction, text cleaning was performed concurrently with text collection. We excluded\nweb pages not in English, duplicated texts, and filtered out pages with word counts below 100 or above 10,000\nwords(countedbytokeninizingtextvianon-wordcharactersplit; inR: \u201c//W+\u201d.) Inadditiontothemaintext,\ngooseallows extraction of other information from parsed HTML files, including the document\u2019s publication\nand modification dates, title, description, and URLs within the text after boilerplate stripping.\n3 Extracting Additional Data\nDONALD is enriched with a comprehensive set of additional data at both document and domain levels. At\nthe document level, we provide titles, URLs of the retrieved web pages, and their creation, upload, and edit\ndates. Besides the seeds (see Section 2.2), DONALD includes diverse semantic indices for each document,\nsuch as lexical features (extracted via dictionary methods, see Section 3.2), keywords (extracted via TF-IDF,\nsee Section 3.3), and topics (extracted via Latent Dirichlet Allocation, see Section 3.4). Documents are also\nbinarily labeled to indicate whether they are representative of the category from which they are drawn (see\nSection 3.5). Details on text pre-processing are discussed in the Appendix (see Section B). At the domain\nlevel, in addition to the ideological bias and strength obtained by MBFC (see Section 2.1), we provide a\nfine-grained measure of domain quality (obtained by Lin et al. 2023, see Section 3.6).\n3.1 Dates\nViagoose(see Section 2.4), we were able to extract the date of upload and/or authoring for approximately\n68.56% of documents ( N= 1,489,932), ranging from \u201c1689-01-01\u201d to\u201c2023-07-14\u201d . While dates before\nthe internet era (e.g., in 1689) unambiguously refer to the authoring date, this distinction is less clear for\nmore recent documents, which could represent either authoring or upload dates. Despite this ambiguity,\nwe retained dates from the pre-internet era and advise researchers to exercise caution when analyzing time-\nrelated hypotheses. We also provide the date when the web page was edited ( N= 798,195, about 36.73%).\n6https://github.com/goose3/goose3\nDONALD 9\nInFigure2,wedisplaythedocumentcount( y-axis)aggregatedbyyear( x-axis). From1980onward,eachyear\nhasatleast50documents, increasingto100documentsperyearby1990, andsurpassing1,000documentsper\nyearbythe2000s. Thespikein1970islikelyduetoJanuary 1st, 1970beingtheUnixepoch, whichmayreflect\ndocuments with default dates left by web developers. Some dates ( N= 120,933) were extracted converting\nthe URL character string into the date format (using the regular expression \u201c[0-9]4/[0-9]2/[0-9]2\u201d , we\nhave visually inspected a portion of these documents and established its feasibility).\n101001,00010,000100,000\n1960 1980 2000 2020\nyeardocument count\nFigure 2|Distribution of documents by date aggregated by year (from 1950 to 2023)\n3.2 Lexical Features\nEach document in DONALD is associated with a lexical fingerprint, a detailed multidimensional (315 fea-\ntures) quantification of language use within the document. Lexical fingerprinting involves the use of dictio-\nnaries, which are pre-compiled lists of words or features categorized by topic (e.g., tourism), psychological\ndimension (e.g., positive emotions), or typographical/grammatical category (e.g., punctuation, past-tense\nverbs). For example, the category anxietymight include words such as anxiousandavoid. If a text contains\nthese words, the category score increases proportionally. Typically, tools based on dictionaries provide nor-\nmalized scores, which are counts of words in a category divided by the total word count of a document (for a\ncomprehensive discussion, see Hills & Miani, in press). In DONALD, we used two widely-used word-counting\ntools: LIWC (Tausczik & Pennebaker, 2010) and Empath (Fast, Chen, & Bernstein, 2016). Additionally, we\nemployed specialized dictionaries such as the polarization dictionary (Simchon, Brady, & Van Bavel, 2022),\nDONALD 10\nand the honesty dictionaries (Lasser et al., 2023). LIWC\u2019s lexical features were extracted using the stan-\ndalone application (version 2022, Boyd, Ashokkumar, Seraj, & Pennebaker, 2022). Lexical features based\non the other dictionaries were extracted using the function dictionary from the quanteda R package after\nlemmatizing both texts and dictionaries (Benoit et al., 2018, see also Section B in Appendix).\nIn Figure 3, we show an example of lexical feature, specifically the one related to deception, extracted via the\ndictionary Empath (example of words: traitor,liar,dishonesty ). Note this is an excerpt from the file in our\nrepository (see Section 4.3). In panel A, the normalized count of words related to deception (theoretically\nranging from 0 = no words to 1 = all words in a text are related to deception) are plotted against political\nideological strength (from extreme liberals to extreme conservative, including least-biased) and conspiratorial\nstrength (ranging from 1 to 5), with quadratic and linear fitted regression lines, respectively. Although not\nvisible (because small due to the large sample in each group), each dot is associated with the error bars\nindicating the standard error of the mean. In panel B, values of the lexical feature is plotted against domain\nquality, with the fitted regression line and the standardized \u03b2coefficient yielded by the regression (calculated\nregressing domain quality on lexical feature, using only domains for which we have at least 10 documents).\n0.001500.001750.002000.002250.002500.00275\nL05 L03 L01 LB00 R01 R03 R05\nPoliticalCT01 CT02 CT03 CT04 CT05\nConspiracyA)\n\u03b2 = -0.475 0.0020.0040.006\nmin (0) max (1)\ndomain qualityB)Empath_deception\nFigure 3|Lexical feature \u201cdeception\u201d from the Empath dictionary (A) by political and conspiratorial\nstrength and (B) by domain quality. Error bars indicate the standard error of the mean.\n3.3 Keywords\nKeywords, distinct from seeds, represent the 10 most representative words for a document (for a similar\napproach, see Carrella, Miani, & Lewandowsky, 2023). Keywords were extracted from each document using\nthe TF-IDF (term frequency-inverse document frequency) technique, which assesses the relevance of a term\nto a document within a corpus by considering both the frequency of the term in the document and its rarity\nDONALD 11\nacross the corpus. This method permits identification of terms that are characteristic of each document. We\ncomputed TF-IDF scores using the dfm_tfidf function from the quanteda R package (Benoit et al., 2018).\nKeywords were defined as the top 10,000 stemmed words with the highest TF-IDF score per document.\nKeywords were stemmed, i.e., reduced to their root, to reduce the keyword vocabulary hence facilitating\ngrouping of documents (e.g., immigration ,immigrant , andimmigrants are reduced to immigr).\nNote that keywords are different from seeds in that they are derived post hoc from the corpus (while seeds\nwere used to retrieved documents via search engine queries). While some semantic overlap between seeds\nand keywords is expected, it is not guaranteed. Seeds serve as search terms used to retrieve web pages,\nwhereas keywords are extracted from the document content itself. To measure the semantic overlap between\nseeds and keywords, we employed Global Vectors word embedding (GloVe, Pennington, Socher, & Manning,\n2014). GloVe was trained on the stemmed version of DONALD, including both seeds and top keywords,\nto ensure all terms are in the GloVe matrix. Semantic similarity between seeds and keywords was assessed\nusing cosine similarity (via the function cosinefrom the R package lsa;Wild, 2022).\nTable 3 presents the top-40 most frequent seeds and keywords in DONALD with their count. For example,\nthe seed women_rights occurs in 32,445 documents (see column A), the keyword womenappears in 46,924\ndocuments (column B), but it occurs in first position (hence as the most important word in the document)\nin 6,400 documents (column C). Note that water supply rights is the most frequent seed in the corpus. This\nmight be an artifact due to the fact that we resolved (i.e., aggregated) five synonym seeds related to water\n(see Section A in Appendix).\n3.4 Topics\nTopics were extracted using Latent Dirichlet Allocation (LDA), an unsupervised probabilistic machine learn-\ning model introduced by Blei, Ng, and Jordan (2003). LDA identifies co-occurring word patterns in a corpus\nand extracts the underlying topic distribution for each document. Determining the number of topics ( k) in\nLDA is crucial. A larger kyields finer-grained topics, whereas a smaller kresults in more general topics\n(Colin & Murdock, 2020). Although researchers typically set kmanually, unsupervised algorithms, such as\ntheldatuning package in R (Nikita, 2020), aim to estimate the optimal kautomatically (see e.g., Lasser et\nal., 2023; Mayor & Miani, 2023; Miani et al., 2022). However, due to the size of DONALD, employing such\nalgorithms would be resource- and time-intensive. To address this challenge, we (1) provided different topic\nresolutions to accommodate varying research needs (for a similar approach see Carrella et al., 2023; Miani\nDONALD 12\nTable 3\nTop 40 most frequent seeds and keywords\n(A) Seeds (B) KWs (all) (C) KWs (1stterm)\nTerm Freq Term Freq Term Freq\n1water_supply_rights 73,675 trump 95,415 vaccin 26,855\n2voting 60,210 vaccin 68,464 abort 15,575\n3health_care 58,170 biden 68,200 trump 12,926\n4immigration 54,343 russia 60,323 ukrain 11,689\n5climate_change 40,150 ukrain 58,001 climat 10,450\n6vaccination 37,607 russian 57,975 immigr 9,903\n7women_rights 32,445 china 57,459 gun 9,875\n8freedom_of_speech 27,905 student 56,117 biden 9,668\n9privacy_rights 25,433 vote 55,392 china 9,313\n10civil_rights 23,951 polic 55,039 water 9,173\n11social_security 23,783 school 53,223 marijuana 7,268\n12china 23,378 climat 47,629 polic 7,083\n13united_states 23,282 women 46,924 women 6,400\n14government_regulations 23,050 court 46,793 saudi 6,372\n15executive_order 22,651 immigr 46,645 israel 6,206\n16infrastructure 22,604 elect 46,552 russian 6,108\n17gun_control 22,380 covid 45,308 student 5,846\n18covid_restrictions 22,323 water 40,510 palestinian 5,708\n19ukraine_and_russia 22,195 health 39,698 nuclear 5,659\n20russia 21,818 republican 39,652 vote 5,634\n21me_too_movement 21,623 bill 39,535 tax 5,420\n22sex_education 21,492 black 38,873 putin 5,279\n23environmental_health 21,363 democrat 36,280 school 5,250\n24political_activism 21,258 abort 34,623 russia 5,158\n25border_security 21,217 citi 34,332 ai 5,107\n26black_lives_matter 21,087 energi 33,784 wage 4,978\n27abortion 21,005 drug 33,008 iran 4,920\n28joe_biden 20,917 israel 32,971 black 4,812\n29religious_freedom 20,908 counti 32,959 india 4,673\n30green_new_deal 20,863 senat 32,502 oil 4,668\n31police_reform 20,818 worker 32,307 korea 4,546\n32animal_rights 20,563 chines 31,937 eu 4,526\n33alt-right 20,552 voter 31,756 marriag 4,476\n34citizen_scientists 20,544 compani 31,569 border 4,306\n35misinformation 20,361 putin 29,945 drug 4,254\n36european_union 20,334 food 29,878 turkey 3,885\n37nuclear_energy 20,318 percent 29,320 insur 3,825\n38france 20,291 border 29,259 macron 3,784\n39mexico 20,264 protest 29,208 film 3,739\n40canada 20,254 tax 29,201 daca 3,587\nTop-40 most frequent seeds (column A; see Section 2.2) and stemmed keywords (KWs, see\nSection 3.3) with their count. Column B shows the count of KWs that appear within the whole\nset of 10 KWs for each document (e.g., third of fourth position); Column C shows the count of\nKws that appear only within first position, hence the most important word for a document.\net al., 2021); and (2) fitted LDA models using keywords extracted via TF-IDF (see Section 3.3) instead of\nthe raw text, reducing each document\u2019s content to its top-10 most important terms.\nUsing the topicmodels package in R (Gr\u00fcn & Hornik, 2011), we fitted three LDA models with kset at\n100, 200, and 300 topics, resulting in a total of 600 topics. Each topic was labeled with its top 5 words,\nwhich succinctly summarize its content (Nguyen et al., 2020). Additionally, we assigned a unique short topic\nidentifier, comprising the kvalue (100, 200, or 300) followed by an arbitrary topic number. For example,\nthe label \u201ck300_218\u201d denotes the 218thtopic with resolution k= 300.\nDONALD 13\nPrevious works have shown an association between LDA topics with real-world events such as disease out-\nbreaks (e.g., Ebola, Zika, as well as COVID-19 and its specific Omicron variant), deaths of significant figures\n(e.g., Michael Jackson, Osama bin Laden), and wars (Carrella et al., 2023; Lansdall-Welfare et al., 2017;\nMayor & Miani, 2023; Miani et al., 2021), by averaging the topic\u2019s gamma values (the probability a topic is\npart of a document) for each month, obtaining a fine-grained time series of gamma values that reflect the\nimportance of a topic in a certain period of time. In Figure 4, we employ the same methodology and show\nthat fitting LDA\u2019s topics over keywords produces a reliable and sensitive identification of topics, as indicated\nby the timeline of social concerns across documents. Vertical dotted red lines indicate the approximate start\nof the events described by the topic labels.7\nFor each document, we extracted the name of the topic with the highest gamma value within each set of\ntopick, identifying the topic that accounts for most of the document\u2019s semantic content. This approach\nis thought to help in topic matching during analyses, such as nesting documents within topics. Although\nthis method is not perfect due to varying gamma value distributions across documents (see e.g., Miani\net al., 2022), it offers advantages for multilevel analyses compared to other semantic aggregation methods\nlike seeds (see Section 2.2) or keywords (see Section 3.3). Keywords and seeds can include multiple items\n(e.g.,\u201cukraine_and_russia, vladimir_putin\u201d ), leading to a high number of unique combinations that\ncomplicate clustering and reduce statistical power during analyses. For instance, there are 128,427 unique\nseedcombinationsand2,120,554uniquekeywordcombinations. Evenwhenconsideringonlythefirstposition\nkeywords (see Section 3.3 and Table 3), the number remains high, with 9,865 unique keywords in the\nfirst position. Following multilevel analyses in LOCO (Miani et al., 2021), we provide three variables,\ncorresponding to 100, 200, and 300 topics, to cluster documents within a chosen set of topic k.\n3.5 Representative Documents\nIn LOCO (Miani et al., 2021), the concept of representative documents aimed to identify those exhibiting\nprototypicalconspiratoriallanguage. Thissetofdocumentswascompiledbyextractingdocumentsthatmost\nclosely resembled the conspiracy sub-corpus. This was measured by computing the cosine similarity between\nthe vector containing the count of each word in a document ( vdoc1 ={W1= 10,W2= 1,W3= 0,...};\nvdoc2 ={W1= 7,W2= 2,W3= 4,...}) and the vector containing the averaged count of each word in\nthe entire conspiracy sub-corpus ( vs={W1= 9.7,W2= 2.1,W3= 0.6,...}). High similarity indicated\n7https://en.wikipedia.org/wiki/COVID-19_vaccination_mandates_in_the_United_States (\u201c2021-08-01\u201d for topic\nk300_167), https://en.wikipedia.org/wiki/COVID-19_lockdowns (\u201c2020-03-01\u201d for topic k300_179),\nhttps://en.wikipedia.org/wiki/Pfizer\u00e2\u0102\u015eBioNTech_COVID-19_vaccine (\u201c2020-11-01\u201d for topic k300_232),\nhttps://en.wikipedia.org/wiki/SARS-CoV-2_Omicron_variant (\u201c2021-11-24\u201d for topic k300_267),\nhttps://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States (\u201c2020-03-01\u201d for topic k300_286); pages\naccessed on 2024-06-02 .\nDONALD 14\n0.0150.0200.025\n19992000200120022003200420052006200720082009201020112012201320142015201620172018201920202021202220232024\ndate\u03b3Sum of COVID\u221219 topics\n0.0030.0040.0050.0060.007\n2019 2020 2021 2022 2023\ndate\u03b3vaccin_mandat_mask_covid_wear k300_167\n0.0040.0060.0080.010\n2019 2020 2021 2022 2023\ndate\u03b3lockdown_coronavirus_covid_pandem_virus k300_179\n0.0030.0040.0050.006\n2019 2020 2021 2022 2023\ndate\u03b3vaccin_covid_dose_pfizer_shot k300_232\n0.0040.0060.0080.010\n2019 2020 2021 2022 2023\ndate\u03b3vaccin_covid_variant_omicron_infect k300_267\n0.0030.0040.0050.006\n2019 2020 2021 2022 2023\ndate\u03b3test_covid_travel_quarantin_vaccin k300_286\nFigure 4|Time-series of topics over time. Topics were extracted from keywords (see Section 3.3) via\nLatent Dirichlet Allocation (LDA, see Section 3.4). Here, topics related to COVID-19, selected by searching\nfor the term \u201ccovid\u201d within the top-5 most important words (those with highest beta weights) within the k=\n300 topics. Vertical dotted red lines indicate the approximate start of the events (in the USA) described by\nthe topic labels. In the top panel, we sum the gamma weights (i.e., the importance of a topic for a\ndocument) and extended the time span to the year 2000, showing that COVID-19 was not important prior\nto 2020.\nDONALD 15\nthat the distribution of word counts within a document was proportional to that of the whole sub-corpus.\nDocuments with a high count of frequently recurring words in the conspiracy sub-corpus showed greater\nsimilarity with the conspiracy sub-corpus. Representative documents in LOCO were found to be more\nrhetorically appealing, emotionally charged, and focused on deception and social identification. Moreover,\nthese documents tended to be more frequently shared on Facebook.\nFollowing LOCO, we replicated this procedure to DONALD and extracted a set of prototypical documents\nfor each of the four ideological biases, namely least-biased, politically biased towards the left and right, and\nconspiratorial sub-corpora. To achieve this, we pre-processed each sub-corpus to obtain the Document-Term\nMatrix (DTM, see Section B in the Appendix), a matrix of documents \u00d7terms (i.e., words) containing\nthe word count of each word in each document. To compute the document-to-sub-corpus similarity, we\nneeded two vectors of word counts: one for the sub-corpus and one for the document being tested. Both\nvectors had lengths equal to the sub-corpus vocabulary. The document vector contained the word count for\neach term, while the sub-corpus vector was built by computing the average occurrences of each term across\ndocuments. We then evaluated the cosine similarity between each document\u2019s vector and the sub-corpus\nvector. High similarity scores indicated that the distribution of words in a document is similar to that\nof the sub-corpus. We dichotomized the similarity scores into a logical vector, classifying a document as\nrepresentative if its cosine similarity was one standard deviation above the mean of similarity scores of the\nsub-corpus. To evaluate cosine similarity, we used the cosinefunction from the R package lsa(Wild, 2022).\nAlthough this method differs slightly from the one used in LOCO (where similarity was computed using the\nquanteda functiontextstat_simil ), the results are highly correlated ( r=.99on a random sample of 50,000\ndocuments) and significantly faster (3.77 minutes vs. 1.04 hours).\n3.6 Domain quality\nFornearlyalldomains(99.65%, N=1,703)inDONALD,weprovideameasureofinformationqualitysourced\nfrom Lin et al. (2023). This measure combines six sets of expert ratings on news reliability, encompassing\nfactors such as bias, factuality, credibility, and transparency. The resulting score ranges from 0 to 1, with\nhigher scores indicating higher quality. We observed an overall strong negative correlation between domain\nquality and ideological strength, with a correlation coefficient of r1701= -.82,p< .001 (with r214= -.43 for\nconspiracy, r616= -.78 for liberal, and r530= -.84 for conservative domains; all ps < .001). This indicates\nthat as the ideological strength of domains increases (ranging from 0 for least biased to 5 for strong liberal,\nconservative, or conspiratorial), the quality of information they deliver tends to decrease.\nDONALD 16\n3.7 URLs in text\nTo extract text from web pages, we relied on goose(see Section 2.4), which also facilitated the extraction of\nmeta-data from each web page. Besides documents\u2019 titles and date of upload/edit (see Section 3.1), we used\ngooseto extract the URLs embedded within the scraped text. These URLs were aggregated into a character\nvector, with each URL separated by the character sequence \u201c - \u201d.8Additionally, we recorded the number\nof links mentioned in each text.\n4 Repository content\nDONALD and its meta-data are available at https://osf.io/6xpa2 . In Figure 5, we map the repository\ndirectory. In the following, we describe the data stored in each repository\u2019s folder.\nOSF(https://osf.io/6xpa2)\nDONALD (see Section 4.1)\nDONALD.rdata\nDONALD.dtm.rdata\nAdditional data (see Section 4.2)\nLDA\nf.beta.{100|200|300}.rdata\nf.gamma.{100|200|300}.rdata\nLexical Features\nLFs.rdata\nFigures (see Section 4.3)\nLDA\ng{100|200|300}.pdf\nLexical Features\nLFs by type.pdf\nLFs by years.pdf\nTables (see Section 4.4)\nN_KWs_1st.csv\nN_KWs_all.csv\nN_seeds.csv\nFigure 5|Repository directory map\n4.1 DONALD\nThe folder named \u201cDONALD\u201d contains the corpus dataset with most of its meta-data, split into two R\ndata frames. The file DONALD.rdata (size = 3.6 Gb, 775 Mb compressed) contains individual-document level\ninformation for DONALD. It consists of 2,173,172 rows (one per document) \u00d718 columns, as described\nin Table 4. The file DONALD.dtm.rdata (size = 11.6 Gb, 3 Gb compressed) contains the un-pre-processed\n8e.g.,\u201chttps://www.domain.com/url1.html - https://www.domain.com/url2.html\u201d\nDONALD 17\nDTM of DONALD\u2019s documents. It is a highly sparse DTM (sparsity > 99.9%), consisting of 2,173,172\ndocuments, 4,533,948,110 tokens, and 6,129,573 features. DONALD\u2019s raw texts are stored in the R data\nframe\u201cDONALD.txt.rdata\u201d (size = 12.5 Gb, 4.87 Gb compressed) consisting of 2,173,172 rows (one per\ndocument)\u00d72 columns, namely document ID and text. The file is available under controlled access at\nhttps://doi.org/10.7910/DVN/VDQL8A .\nTable 4\nVariables name and description in the file \u201cDONALD.rdata\u201d\nVariable Description\ndoc_id Unique document identifier (e.g., \u201cL03_w564_d2ec\u201d ,\u201cCT05_w40f_d508\u201d ), which stores three types\nof information: (a) domain group (e.g., CT01); (b) a hexadecimal domain identifier preceded by the\nletter\u201cw\u201d(e.g.,w5d6); (c) a hexadecimal document-within-domain identifier preceded by the letter\n\u201cd\u201d(e.g.,d56b).\ndomain Domain name from which the documents are gathered (e.g., forbes.com ,revolutionradio.org ; see\nSection 2.1).\ndomain_group Code for domains\u2019 ideology and strength (e.g., \u201cCT01\u201d,\u201cLB00\u201d,\u201cR05\u201d, see labels in Table 1).\ndomain_quality Domains\u2019 quality obtainedbyLinet al.(2023), theoreticallyranging from0 to1 (low tohigh quality,\nas described in Section 3.6; missing N= 2,436).\nurl The URL of the web page from which the document was gathered.\ntitle The title of the document (missing N= 937).\ntxt_WC Documents\u2019 word count.\ndate_published Date of writing/upload of the document (see Section 3.1; missing N= 683,240).\ndate_modified The date the online document was edited (missing N= 1,374,977).\nkw_seeds Seed(s) used to retrieve the document (see Section 2.2; missing N= 293).\nkw_tfidf Documents\u2019 keywords extracted via TF-IDF (see Section 3.3).\nkw_match Semantic relatedness between seeds and keywords (see Section 3.3; missing N= 293).\nk_{100|200|300} Top-highest LDA topic (see Section 3.4).\nlinks_n Count of links (URLs) included in the document (see Section 3.7; missing N= 275,406)\nlinks List of links extracted from the document; each link is separated with \u201c - \u201d(missing N= 275,406).\nrepresentative Logical vector ( TRUE|FALSE ) indicating whether or not the document is representative for its respec-\ntive ideology (either least-biased, liberal, conservative, or conspiratorial; see Section 3.5).\n4.2 Additional data\nThe folder named \u201cAdditional data\u201d contains the R data frames for LDA topics (see Section 3.4) and lexical\nfeatures (see Section 3.2).\nThree files named \u201cf.beta.{100|200|300}.Rdata\u201d are matrices with dimensions of 10,000 rows (terms) \u00d7\n100|200|300 columns (topics), containing the beta weights, which represent the probability of a term being\npartofatopic(i.e.,theimportanceofawordwithinatopic). Threefilesnamed \u201cf.gamma.{100|200|300}.Rdata\u201d\nare matrices with dimensions of 2,173,172 rows (documents) \u00d7100|200|300 columns (topics), containing the\ngamma weights, which indicate the probability of a topic representing a document (i.e., the importance of a\ntopic within a document).\nThe file\u201cLFs.Rdata\u201d is an R data frame with dimensions of 2,173,172 rows (documents) \u00d7315 columns\n(lexical features), containing the complete set of lexical features extracted from DONALD (see Section 3.2).\nDONALD 18\nThe columns are named according to the dictionaries used: LIWC (118 columns), Empath (194 columns),\nLasser (2 columns), and Simchon (1 column).\n4.3 Figures\nThe folder named \u201cFigures\u201d includes PDF files containing descriptive figures of topics and lexical features.\nWithin the \u201cLDA\u201d folder, we included illustrations of the time-series data of topics (see Section 3.4) over\ntime\u2014replicating Figure 4) for each of our 600 topics. Each PDF file corresponds to a set of topics (600 in\ntotal) extracted with different values of k(100, 200, and 300). Each page of the PDF displays the time-series\nof gamma values for a specific topic, averaged by month over the period from 2000 to 2023.\nThe \u201cLexical Features\u201d folder includes visualizations of lexical features (see Section 3.2). In the file named\n\u201cLFs by type.pdf\u201d , each page shows two panels similar to Figure 3, for each lexical feature. In the file\nnamed\u201cLFs by years.pdf\u201d , each page displays the average lexical feature values plotted over time from\n2000 to 2023, aggregated by month.\n4.4 Tables\nInfoldernamed\u201cTables\u201d,weincludedcomma-separated-value(csv)filesinwhichwereportedtheoccurrences\nin DONALD of seeds, keywords, and domains. The file named \u201cdomains.csv\u201d contains the full list of 1,709\ndomains, similar to the one used in Table 2. Additionally, the folder includes an extended versions of Table 3,\nincluding the full list of occurrences of seeds ( \u201cN_seeds.csv\u201d ) and keywords extracted via TF-IDF in both\nthe first position (i.e., the most important word; \u201cN_KWs_1st.csv\u201d ) and overall occurrence at any position\nwithin the 10 keywords per document ( \u201cN_KWs_all.csv\u201d ).\nDONALD 19\nAppendix A\nSeeds synonym\nOnce the corpus was built, we resolved the synonyms for the seeds listed in Table A1.\nTable A1\nSeeds synonym\nFinal seed Synonym seeds\nvaccination [vaccines, vaccination mandates]\nhealth care [universal healthcare, health care access, health insurance]\nvoting [early voting, voter fraud, voting laws]\nwater supply rights [water filtration, water resource development act s2848, water rights, water supply\npolicy, water supply regulation]\nimmigration [illegal immigrants, immigration reform]\ncensorship and freedom of speech [freedom of speech, censorship]\nDONALD 20\nAppendix B\nPre-processing\nIn Table B1, we list the pre-processing workflow for each step of DONALD\u2019s construction. To remove non-\nASCII characters (e.g., emojis) and lower-casing the text, we used the R base functions iconvandtolower.\nFor other text pre-processing steps, we mainly relied on the R package quanteda (Benoit et al., 2018, unless\ndifferently specified). Specifically, tokenization was applied using the function tokens. Tokens were split\nwithtokens_split Tokens replacement via mapping data sets was applied using the the tokens_replace\nfunction. To expand contractions (e.g., from I\u2019mtoI am), we used the contractions mapping data set\n(N= 70 mappings from the qdapDictionaries package; Rinker, 2013). Lemmas were mapped from the\ndatasethash_lemmas (N= 41,531) in the package lexicon(Rinker, 2018). Stemming was applied with the\ntokens_wordstem function (using Martin Porter\u2019s stemming algorithm). The Document-Term Matrix was\nbuilt with the function dfmand pruned (i.e., keeping the top 10,000 features) with the function dfm_select .\nTable B1\nPre-processing workflow for each step of DONALD\u2019s construction\nLFs\nsee 3.2TF-IDF\nsee 3.3GloVe (seeds)\nsee 3.3GloVe (docs)\nsee 3.3LDA\nsee 3.4Representative\nsee 3.5\nInput text documents documents seeds \u2192+ seeds TF-IDF documents\nRemoving non-ASCII 1 1 1\nLower-casing 2 2 2\nTokenization 3 3 1 1\nSplit tokens 2\nExpanding contractions 3\nRemoving stop words 4(a) 1(b) 4(c)\nLemmatizing 4 \u2192 3\nStemming 5 4 3 5\nBuild DTM 6 2 6\nSelecting top 10k terms 7 2 3 7\nNote. LFs: Lexical Features; TF-IDF : Term Frequency-Inverse Document Frequency; GloVe: Global Vector; LDA:\nLatent Dirichlet Allocation; DTM: Document-Term Matrix. \u2192indicates the output of LFs (lemmatized DONALD\u2019s\ndocuments) is the input for training the GloVe.\nDepending on the task, we used three sets of stop words: (a) stop words from quanteda in addition\nto single letters ( N= 199); (b) stop words from quanteda ( N= 175); and (c) an ad hoc set, replicating the\nanalyses in LOCO (see Section SM5 in supplemental materials, Miani et al., 2021), in which, motivated by\nthe literature, pronouns and negations were removed from the stop words list ( N= 137). Stop words are\nlisted in Table B2.\nDONALD 21\nTable B2\nStop words sets\nSet Stop words\n(a)a,about,above,after,again,against,all,am,an,and,any,are,aren\u2019t,as,at,b,be,because,been,before,being,\nbelow,between,both,but,by,c,can\u2019t,cannot,could,couldn\u2019t,d,did,didn\u2019t,do,does,doesn\u2019t,doing,don\u2019t,down,\nduring,e,each,f,few,for,from,further,g,h,had,hadn\u2019t,has,hasn\u2019t,have,haven\u2019t,having,he,he\u2019d,he\u2019ll,he\u2019s,\nher,here,here\u2019s,hers,herself,him,himself,his,how,how\u2019s,i,i\u2019d,i\u2019ll,i\u2019m,i\u2019ve,if,in,into,is,isn\u2019t,it,it\u2019s,its,\nitself,j,k,l,let\u2019s,m,me,more,most,mustn\u2019t,my,myself,n,no,nor,not,o,of,off,on,once,only,or,other,\nought,our,ours,ourselves ,out,over,own,p,q,r,s,same,shan\u2019t,she,she\u2019d,she\u2019ll,she\u2019s,should,shouldn\u2019t ,so,\nsome,such,t,than,that,that\u2019s,the,their,theirs,them,themselves ,then,there,there\u2019s,these,they,they\u2019d,they\u2019ll,\nthey\u2019re,they\u2019ve,this,those,through,to,too,u,under,until,up,v,very,w,was,wasn\u2019t,we,we\u2019d,we\u2019ll,we\u2019re,\nwe\u2019ve,were,weren\u2019t,what,what\u2019s,when,when\u2019s,where,where\u2019s,which,while,who,who\u2019s,whom,why,why\u2019s,will,\nwith,won\u2019t,would,wouldn\u2019t,x,y,you,you\u2019d,you\u2019ll,you\u2019re,you\u2019ve,your,yours,yourself,yourselves ,z\n(b)a,about,above,after,again,against,all,am,an,and,any,are,aren\u2019t,as,at,be,because,been,before,being,\nbelow,between,both,but,by,can\u2019t,cannot,could,couldn\u2019t,did,didn\u2019t,do,does,doesn\u2019t,doing,don\u2019t,down,during,\neach,few,for,from,further,had,hadn\u2019t,has,hasn\u2019t,have,haven\u2019t,having,he,he\u2019d,he\u2019ll,he\u2019s,her,here,here\u2019s,\nhers,herself,him,himself,his,how,how\u2019s,i,i\u2019d,i\u2019ll,i\u2019m,i\u2019ve,if,in,into,is,isn\u2019t,it,it\u2019s,its,itself,let\u2019s,me,\nmore,most,mustn\u2019t,my,myself,no,nor,not,of,off,on,once,only,or,other,ought,our,ours,ourselves ,out,\nover,own,same,shan\u2019t,she,she\u2019d,she\u2019ll,she\u2019s,should,shouldn\u2019t ,so,some,such,than,that,that\u2019s,the,their,\ntheirs,them,themselves ,then,there,there\u2019s,these,they,they\u2019d,they\u2019ll,they\u2019re,they\u2019ve,this,those,through,to,\ntoo,under,until,up,very,was,wasn\u2019t,we,we\u2019d,we\u2019ll,we\u2019re,we\u2019ve,were,weren\u2019t,what,what\u2019s,when,when\u2019s,\nwhere,where\u2019s,which,while,who,who\u2019s,whom,why,why\u2019s,will,with,won\u2019t,would,wouldn\u2019t,you,you\u2019d,you\u2019ll,\nyou\u2019re,you\u2019ve,your,yours,yourself,yourselves\n(c)a,about,above,after,again,all,am,an,and,any,are,as,at,b,be,because,been,before,being,below,between,\nboth,but,by,c,call,can,come,could,d,day,did,do,does,doing,down,during,e,each,f,few,find,first,for,\nfrom,further,g,get,go,h,had,has,have,having,here,if,in,into,is,it,its,itself,j,k,l,like,long,look,m,made,\nmake,many,may,more,most,n,now,number,o,of,off,on,once,one,only,or,other,ought,out,over,own,p,\npart,q,r,s,said,same,should,so,some,such,t,than,that,the,then,there,these,this,those,through,time,to,\ntoo,two,u,under,until,up,use,v,very,w,was,water,way,were,while,whom,will,with,word,would,x,y,z\nDONALD 22\n5 References\nBaroni, M., Bernardini, S., Ferraresi, A.,&Zanchetta, E. (2009, February). Thewackywideweb: acollection\nof very large linguistically processed web-crawled corpora. Language Resources and Evaluation ,43(3),\n209\u2013226. Retrieved from http://dx.doi.org/10.1007/s10579-009-9081-4 doi: 10.1007/s10579\n-009-9081-4\nBenoit, K., Watanabe, K., Wang, H., Nulty, P., Obeng, A., M\u00fcller, S., & Matsuo, A. (2018). quanteda: An\nr package for the quantitative analysis of textual data. Journal of Open Source Software ,3(30), 774.\nRetrieved from https://quanteda.io doi: 10.21105/joss.00774\nBlei, D. M., Ng, A. Y., & Jordan, M. I. (2003, March). Latent dirichlet allocation. The Journal of Machine\nLearning Research ,3(null), 993\u20131022.\nBoyd, R. L., Ashokkumar, A., Seraj, S., & Pennebaker, J. W. (2022). The development and psychometric\nproperties of liwc-22. Austin, TX: University of Texas at Austin , 1\u201347.\nCarrella, F., Miani, A., & Lewandowsky, S. (2023, May). IRMA: the 335-million-word Italian coRpus for\nstudying MisinformAtion. In A. Vlachos & I. Augenstein (Eds.), Proceedings of the 17th conference\nof the european chapter of the association for computational linguistics (pp. 2339\u20132349). Dubrovnik,\nCroatia: Association for Computational Linguistics. Retrieved from https://aclanthology.org/\n2023.eacl-main.171 doi: 10.18653/v1/2023.eacl-main.171\nCastelo, S., Almeida, T., Elghafari, A., Santos, A., Pham, K., Nakamura, E., & Freire, J. (2019). A topic-\nagnostic approach for identifying fake news pages. In Companion proceedings of the 2019 world wide\nweb conference. ACM. doi: 10.1145/3308560.3316739\nColin, A., & Murdock, J. (2020). LDA Topic Modeling: Contexts for the History \\& Philosophy of Science.\nIn G. Ramsey & A. de Block (Eds.), Dynamics Of Science: Computational Frontiers in History and\nPhilosophy of Science. S.l.: Pittsburgh University Press.\nDarwish, K., Stefanov, P., Aupetit, M., & Nakov, P. (2020, May). Unsupervised user stance detection on\ntwitter. Proceedings of the International AAAI Conference on Web and Social Media ,14, 141\u2013152.\nRetrieved from https://doi.org/10.1609/icwsm.v14i1.7286 doi: 10.1609/icwsm.v14i1.7286\nDiab, A., Nefriana, R., & Lin, Y.-R. (2024). Classifying conspiratorial narratives at scale: False alarms and\nerroneous connections.\nFast, E., Chen, B., & Bernstein, M. S. (2016, May). Empath. In Proceedings of the 2016 CHI conference\non human factors in computing systems. ACM. Retrieved from https://doi.org/10.1145/2858036\n.2858535 doi: 10.1145/2858036.2858535\nFleckenstein, K. (2024, March). Representations of gender in conspiracy theories: a corpus-assisted critical\nDONALD 23\ndiscourse analysis. Critical Discourse Studies , 1\u201317. Retrieved from http://dx.doi.org/10.1080/\n17405904.2024.2334263 doi: 10.1080/17405904.2024.2334263\nFong, A., Roozenbeek, J., Goldwert, D., Rathje, S., & van der Linden, S. (2021). The language of conspiracy:\nA psychological analysis of speech used by conspiracy theorists and their followers on Twitter. Group\nProcesses & Intergroup Relations ,24(4), 606\u2013623. doi: 10.1177/1368430220987596\nFort, M., Tian, Z., Indiana University, USA, Gabel, E., Indiana University, USA, Georgiades, N., ... In-\ndiana University, USA (2023). Bigfoot in Big Tech: Detecting Out of Domain Conspiracy Theories.\nInProceedings of the Conference Recent Advances in Natural Language Processing - Large Language\nModels for Natural Language Processings (pp. 353\u2013363). INCOMA Ltd., Shoumen, BULGARIA. doi:\n10.26615/978-954-452-092-2_040\nGr\u00fcn, B., & Hornik, K. (2011). Topicmodels : AnRPackage for Fitting Topic Models. Journal of\nStatistical Software ,40(13). doi: 10.18637/jss.v040.i13\nHills, T., & Miani, A. (in press). A short primer on historical natural language processing. In T. Hills &\nG. Pogrebna (Eds.), Cambridge handbook of behavioral data science. Cambridge University Press.\nKlein, C., Clutton, P., & Dunn, A. G. (2019, June). Pathways to conspiracy: The social and linguistic\nprecursors of involvement in Reddit\u2019s conspiracy theory forum. PLOS ONE ,14(11), e0225098. doi:\n10.1371/journal.pone.0225098\nLansdall-Welfare, T., Sudhahar, S., Thompson, J., Lewis, J., Cristianini, N., Gregor, A., ... Callison, R.\n(2017, January). Content analysis of 150 years of british periodicals. Proceedings of the National\nAcademy of Sciences ,114(4). Retrieved from http://dx.doi.org/10.1073/pnas.1606380114 doi:\n10.1073/pnas.1606380114\nLasser, J., Aroyehun, S. T., Carrella, F., Simchon, A., Garcia, D., & Lewandowsky, S. (2023). From\nalternative conceptions of honesty to alternative facts in communications by us politicians. Nature\nhuman behaviour ,7(12), 2140\u20132151. Retrieved from https://doi.org/10.1038/s41562-023-01691\n-wdoi: 10.1038/s41562-023-01691-w\nLasser, J., Aroyehun, S. T., Simchon, A., Carrella, F., Garcia, D., & Lewandowsky, S. (2022, 9 30).\nSocial media sharing of low-quality news sources by political elites. PNAS Nexus ,1(4), pgac186. doi:\n10.1093/pnasnexus/pgac186\nLin, H., Lasser, J., Lewandowsky, S., Cole, R., Gully, A., Rand, D. G., & Pennycook, G. (2023, September).\nHigh level of correspondence across different news domain quality rating sets. PNAS Nexus ,2(9).\nRetrieved from https://doi.org/10.1093/pnasnexus/pgad286 doi: 10.1093/pnasnexus/pgad286\nMayor, E., & Miani, A. (2023, August). A topic models analysis of the news coverage of the omicron\nvariant in the united kingdom press. BMC Public Health ,23(1). Retrieved from http://dx.doi.org/\nDONALD 24\n10.1186/s12889-023-16444-7 doi: 10.1186/s12889-023-16444-7\nMiani, A., Hills, T., & Bangerter, A. (2021, October). LOCO: The 88-million-word language of conspiracy\ncorpus.Behavior Research Methods ,54(4), 1794\u20131817. doi: 10.3758/s13428-021-01698-z\nMiani, A., Hills, T., & Bangerter, A. (2022). Interconnectedness and (in)coherence as a signature of\nconspiracy worldviews. Science Advances ,8(43). doi: 10.1126/sciadv.abq3668\nMiani, A., van der Plas, L., & Bangerter, A. (2024). Loose and tight: Creative formation but rigid use\nof nominal compounds in conspiracist texts. The Journal of Creative Behavior ,58(1), 114\u2013127. doi:\n10.1002/jocb.633\nMompelat, L., Tian, Z., Kessler, A., Luettgen, M., Rajanala, A., K\u00fcbler, S., & Seelig, M. (2022). How\n\u201cloco\u201d is the loco corpus? annotating the language of conspiracy theories. In Proceedings of the 16th\nlinguistic annotation workshop (law-xvi) within lrec2022.\nNguyen, D., Liakata, M., DeDeo, S., Eisenstein, J., Mimno, D., Tromble, R., & Winters, J. (2020, August).\nHow We Do Things With Words: Analyzing Text as Social and Cultural Data. Frontiers in Artificial\nIntelligence ,3, 62. doi: 10.3389/frai.2020.00062\nNikita, M. (2020). ldatuning: Tuning of the latent dirichlet allocation models parameters [Computer\nsoftware manual]. Retrieved from https://CRAN.R-project.org/package=ldatuning (R package\nversion 1.0.2)\nOoms, J. (2023). curl: A modern and flexible web client for r [Computer software manual]. Retrieved from\nhttps://CRAN.R-project.org/package=curl (R package version 5.1.0)\nPennington, J., Socher, R., & Manning, C. (2014, October). GloVe: Global vectors for word representation.\nInProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)\n(pp. 1532\u20131543). Doha, Qatar: Association for Computational Linguistics. Retrieved from https://\naclanthology.org/D14-1162 doi: 10.3115/v1/D14-1162\nReiter-Haas, M. (2023). Exploration of Framing Biases in Polarized Online Content Consumption. In\nCompanion Proceedings of the ACM Web Conference 2023 (pp. 560\u2013564). Austin TX USA: ACM. doi:\n10.1145/3543873.3587534\nRinker, T. W. (2013). qdapDictionaries: Dictionaries to accompany the qdap package [Computer soft-\nware manual]. Buffalo, New York. Retrieved from http://github.com/trinker/qdapDictionaries\n(1.0.7)\nRinker, T. W. (2018). lexicon: Lexicon data [Computer software manual]. Buffalo, New York. Retrieved\nfromhttp://github.com/trinker/lexicon (version 1.2.1)\nSamory, M., & Mitra, T. (2018). \u201cthe government spies using our webcams\u201d: The language of conspiracy\ntheories in online discussions. Proceedings of the ACM on Human-Computer Interaction ,2(CSCW),\nDONALD 25\n1\u201324. doi: 10.1145/3274421\nSimchon, A., Brady, W. J., & Van Bavel, J. J. (2022, March). Troll and divide: the language of online\npolarization. PNAS Nexus ,1(1). Retrieved from https://doi.org/10.1093/pnasnexus/pgac019\ndoi: 10.1093/pnasnexus/pgac019\nStefanov, P., Darwish, K., Atanasov, A., & Nakov, P. (2020). Predicting the topical stance and po-\nlitical leaning of media using tweets. In Proceedings of the 58th annual meeting of the associ-\nation for computational linguistics. Association for Computational Linguistics. Retrieved from\nhttps://doi.org/10.18653/v1/2020.acl-main.50 doi: 10.18653/v1/2020.acl-main.50\nTausczik, Y. R., & Pennebaker, J. W. (2010, March). The Psychological Meaning of Words: LIWC and\nComputerized Text Analysis Methods. Journal of Language and Social Psychology ,29(1), 24\u201354. doi:\n10.1177/0261927X09351676\nWickham, H. (2022). rvest: Easily harvest (scrape) web pages [Computer software manual]. Retrieved from\nhttps://CRAN.R-project.org/package=rvest (R package version 1.0.3)\nWickham, H., Hester, J., & Ooms, J. (2023). xml2: Parse xml [Computer software manual]. Retrieved from\nhttps://CRAN.R-project.org/package=xml2 (R package version 1.3.5)\nWild, F. (2022). lsa: Latent semantic analysis [Computer software manual]. Retrieved from https://\nCRAN.R-project.org/package=lsa (R package version 0.73.3)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "DONALD: the 2M-document Dataset Of News Articles for studying the Language of Dubious information", "author": ["A Miani", "F Carrella", "S Lewandowsky"], "pub_year": "2024", "venue": "NA", "abstract": "We present DONALD (Dataset Of News Articles for studying the Language of Dubious  information), a topicmatched corpus comprising 2,173,172 news articles, gathered from 1,709"}, "filled": false, "gsrank": 63, "pub_url": "https://files.osf.io/v1/resources/j3ma9_v1/providers/osfstorage/66a9f0e252e2e351e92ee6b2?action=download&direct&version=1", "author_id": ["zsMnlFgAAAAJ", "c99Fq90AAAAJ", "_A7rrswAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:uF8AxQVUvMAJ:scholar.google.com/&output=cite&scirp=62&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=uF8AxQVUvMAJ&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:uF8AxQVUvMAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.osf.io/v1/resources/j3ma9_v1/providers/osfstorage/66a9f0e252e2e351e92ee6b2?action=download&direct&version=1"}}, {"title": "News consumption in time of conflict: 2021 Palestinian-Israel War as an example", "year": "2022", "pdf_data": "News Consumption in Time of Con\ufb02ict: 2021 Palestinian-Israel War as an\nExample\nKareem Darwish\nQCRI, HBKU, Doha, Qatar\nkdarwish@hbku.edu.qa\nAbstract\nThis paper examines news consumption in response to a\nmajor polarizing event, and we use the May 2021 Israeli-\nPalestinian con\ufb02ict as an example. We conduct a detailed\nanalysis of the news consumption of more than eight thou-\nsand Twitter users who are either pro-Palestinian or pro-\nIsraeli and authored more than 29 million tweets between Jan-\nuary 1 and August 17, 2021. We identi\ufb01ed the stance of users\nusing unsupervised stance detection. We observe that users\nmay consume more topically-related content from foreign\nand less popular sources, because, unlike popular sources,\nthey may reaf\ufb01rm their views, offer more extreme, hyper-\npartisan, or sensational content, or provide more in depth cov-\nerage of the event. The sudden popularity of such sources\nmay not translate to longer-term or general popularity on\nother topics.\nIntroduction\nThe emergence of a major polarizing event attracts the atten-\ntion of social media users resulting in a \ufb02urry of interactions\nsuch as posts, likes, retweets, and shares. Such interactions\noften stem from the desire of users to express their stances\nand opinions on the polarizing event. One of the important\nforms of expression is content sharing from different media\nsources that support the views of users. Thus, users may turn\nto sympathetic media sources that provide greater coverage,\nin the form of news articles, opinion pieces, video clips, doc-\numentaries, or podcasts. Depending on the event of interest,\nthe media sources may be well-established, foreign, or less\npopular. In this paper, we examine the reaction of US Twitter\nusers to the con\ufb02agration of hostilities between Israelis and\nPalestinians in May 2021, and we focus primarily on users\u2019\nsharing activities from media sources that are either foreign\nor generally less popular among US users. This event has\ntwo distinctive characteristics, namely: 1) it is related to a\nforeign issue that may not receive continuous coverage in\npopular news sources, but is yet highly polarizing; and 2)\npopular US media sources are generally sympathetic to the\nIsraeli narrative, including left-leaning media such as CNN1\nCopyright \u00a9 2020, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.\n1https://mediabiasfactcheck.com/left/\ncnn-bias/Ezzina (2021), while many progressive voices are sympa-\nthetic to the Palestinian narrative2. These two characteristics\nmay cause users to express clear stances by sharing content\nfrom media sources that reaf\ufb01rm their views, including for-\neign or less popular. In the context of the May 2021 Israeli-\nPalestinian con\ufb02ict, we are interested in answering the fol-\nlowing questions:\n1. With the advent of a major polarizing events, are social\nmedia users likely to share content from foreign or less\npopular media sources?\n2. If users are likely to do so, what is the reason? Is it due to\ninterest in deeper coverage or mismatch in stance align-\nment with popular sources?\n3. Does the sudden popularity of the sources translate into\nfuture longer-term popularity?\nTo answer these questions, we collected 6.9 million tweets\npertaining to the May 2021 Israeli-Palestinian con\ufb02ict, and\nwe used stance detection to identify the stances of the most\nvocal 8,034 users as either pro-Palestinian or pro-Israeli. We\nthen proceeded to acquire the historical tweets of these users\nthat cover the period from January 1, 2021 to August 17,\n2021 to measure their relative consumption of different right\nand left-leaning sources of varying popularity before, dur-\ning, and after the con\ufb02ict.\nOur contributions in this work are as follows:\n\u2022 We analyze the news consumption of thousands of users\nover a span of several months in reference to a major\npolarizing event. This includes automatically identifying\nusers with opposing stances along with the frames that\nthey respond to in the news.\n\u2022 We show that users may resort to foreign or less popu-\nlar, but potentially more focused, media, and we attempt\nto explain the motivations of users based on their interac-\ntions with different media sources.\n\u2022 We show that the sudden popularity of some sources on\nspeci\ufb01c topics may not translate to longer-term or broader\npopularity on other topics, and we explore possible rea-\nsons for this.\n2https://aje.io/lep74arXiv:2109.12844v1  [cs.SI]  27 Sep 2021\nBackground\nNews Popularity Much of the work on news popular-\nity has focused on predicting future popularity of indi-\nvidual news items (Bandari, Asur, and Huberman, 2012;\nHensinger, Flaounas, and Cristianini, 2013; Keneshloo et\nal., 2016). Prior work has shown that the frequency of inter-\nactions among Twitter users with a news item is correlated\nwith the popularity of that item (Wu and Shen, 2015) and can\nbe used to predict the size of the items\u2019s readership (or view-\nership) (Castillo et al., 2014). Thus, social media popularity\nis indicative of real-world popularity. As for the popularity\nof news media sources, as opposed to individual items, prior\nworked has focused on a variety of aspects such as: the rela-\ntive popularity of established versus upcoming media orga-\nnizations, where older well-established organization have an\nadvantage over newer less-recognized ones (Nelson, 2020);\nthe emergence of online news media, where print media has\nbeen in decline for years (Chyi and Tenenboim, 2019); the\npolarizing effect of social media in increasing the popularity\nof more extreme sources (and views) (Warner and Neville-\nShepard, 2014); whether users consume news from ideologi-\ncally homogeneous or heterogeneous sources (Mullainathan\nand Shleifer, 2005; Nelson and Webster, 2017); and the cor-\nrelation between the ideological positions or stances of users\nand the news they share, where such correlation was used to\nestimate the political leaning of news sources (Stefanov et\nal., 2020). In this work, we focus the effect of polarizing\nevents on the relative popularity of news sources.\nStance Detection Stance detection can be performed us-\ning supervised classi\ufb01cation with a variety of features,\nsuch as text-level features (e.g., words or hashtags), user-\ninteraction features (e.g., user mentions and retweets), and\npro\ufb01le-level features (e.g., name and location) (Borge-\nHolthoefer et al., 2015; Magdy et al., 2016; Magdy, Dar-\nwish, and Weber, 2016). The use of retweets seems to\nyield competitive results (Magdy et al., 2016; Wong et al.,\n2013, 2016). Label propagation is also an effective semi-\nsupervised method that propagates labels in a network based\non follow or retweet relationships (Borge-Holthoefer et al.,\n2015; Weber, Garimella, and Batayneh, 2013) or the sharing\nof identical tweets (Darwish, 2018; Kutlu, Darwish, and El-\nsayed, 2018; Magdy et al., 2016). More recent work projects\nuser onto a two dimensional space and then uses clustering\nto perform unsupervised stance detection (Darwish et al.,\n2019), with the best setup involving the use of UMAP for\nprojection, mean shift for clustering, and the retweeted ac-\ncounts as user features. Though this method may have rela-\ntively low recall, it has nearly perfect precision. In this paper,\nwe use the published implementation of this method3to au-\ntomatically label users. Detecting the stance of Twitter users\nhas been shown to be effective in ascertaining the leaning of\nmedia sources overall and on speci\ufb01c topics, as users tend to\ncite sources that agree and/or reaf\ufb01rm their beliefs (Stefanov\net al., 2020).\n3https://github.com/p-stefanov/\nstance-detectionMay 2021 Israeli-Palestinian Con\ufb02ict In April 2021,\ntensions between Palestinians and Israelis increased due to\ntwo main factors. The \ufb01rst is related to the threatened ex-\npulsion of 75 Palestinian families from the Sheikh Jarrah\nneighborhood in Jerusalem. The issue was framed by the Is-\nraeli authorities as a property dispute between Palestinians\nand Israelis to be settled through court proceedings, while\nthe Palestinians dubbed it as ethnic cleansing of Jerusalem\nthat is carried out by an apartheid system. The second is re-\nlated to repeated clashes between Palestinian worshippers\nand Israeli forces in and around Al-Aqsa Mosque Com-\npound, which is one of the holiest sites for Muslims. The\nclashes started in April 2021 with Israeli efforts to partially\nblock entry into Al-Aqsa Mosque and to limit the number of\nworshippers and culminated with Israeli police repeatedly\nstorming Al-Aqsa compound on May 7, 8, and 10. Hamas,\nthe ruling authority in the Gaza Strip, delivered an ultima-\ntum to Israel to cease the expulsions in Sheikh Jarrah and to\nstop incursions into Al-Aqsa Compound by May 10. With\nthe Israeli government ignoring the ultimatum, Hamas along\nwith other Palestinian factions in Gaza launched hundreds of\nrockets into Israel, sparking a full blown war between Pales-\ntinians and Israelis that lasted until a cease\ufb01re agreement\nwas reached on May 21.\nDataset\nWe collected tweets on May 19, 2021 related to the Isreali-\nPalestinian con\ufb02ict using the Twitter search API using\nthe following keywords: Palestine, Palestinian(s), Gaza, Is-\nrael, Zionist, Quds (Arabic name for Jerusalem), Alquds,\nJerusalem, Netanyahu, Israeli(s), and Jarrah along with their\nequivalents in Arabic. In all we collected 6,944,076 tweets\nas follows:\nDate Count\nMay 17 537,571\nMay 18 3,822,528\nMay 19 2,576,534\nNext, we \ufb01ltered tweets to retain tweets that were au-\nthored in English by US users. To \ufb01lter by language, we used\nthe language labels provided by Twitter. As for location \ufb01l-\ntering, we examined the users\u2019 declared locations, where we\nconsidered a user from the US if his/her location matched a\nmanually curated list of 16,383 US locations (ex. \u201cPinellas,\nFlorida, USA\u201d and \u201cPrev:NJ/V A/PT/CA,now:Lville,ky\u201d) or\nmatched the pattern \u201ccity name, (state name jabbreviation)\u201d\n(ex. \u201cChicago, Ill.\u201d, \u201cChicago, IL\u201d, and \u201cLittle Rock,\nArkansas\u201d). After \ufb01ltration, we were left with 357,725\ntweets from 130,110 different users. Using unsupervised\nstance detection Darwish et al. (2019) over the most active\n20,000 users, we attempted to identify underlying groups\nwith varying stances. The method was able to identify the\nstances of 8,034 users, with 6,495 siding with the Palestinian\nside and 1,539 siding with the Israeli side. Figure 1 show the\nmost retweeted tweets for both groups respectively. Table 1\nshows the 10 most cited news sources for both groups along\nwith their ideological leaning and credibility as provided by\nmediabiasfactcheck.com . What is noteworthy in the\nlist of most cited sources is the prominence of: foreign news\nsources (ex. the Guardian ( theGuardian.com \u2013 UK),\nAlJazeera ( AlJazeera.com \u2013 Qatar), and Jerusalem Post\n(JPost.com \u2013 Israel)); and less popular news sources\nthat typically have limited reach (ex. Electronic Intifada\n(electronicIntifada.net \u2013 Alexa rank: 272,4014)\nand National Review ( NationalReview.com \u2013 9,6575))\ncompared to sites with much higher reach such as the Wash-\nington Post ( WashingtonPost.com ) and Fox News\n(FoxNews.com ) that have Alexa ranks of 2086and 2517\nrespectively. Another noteworthy observation is that the\nmedia sources in Table 1 for pro-Palestinian users are\noverwhelmingly left-leaning with mixed to high credibil-\nity, while those for pro-Israeli users are right-leaning with\nmostly mixed to low credibility.\nFigure 1: Sample tweets for pro-Palestinian and pro-Israeli\nclusters.\nTimeline Data Crawling: On July 1, 2021 and again on\nAugust 21, 2021, we crawled the timelines of the 8,034\nusers, who were automatically tagged as pro-Palestinian or\npro-Israeli, using the twarc Python library8, which is a Twit-\nter API wrapper. We collected on two separate days to crawl\nas many tweets as possible for the users. Twitter typically al-\nlows the crawling of the last 3,200 tweets for a user. Depend-\ning on how active each user is, 3,200 tweets can cover days,\nmonths, or years. Hence, the number of collected tweets per\n4https://www.alexa.com/siteinfo/\nelectronicintifada.net\n5https://www.alexa.com/siteinfo/\nnationalreview.com\n6https://www.alexa.com/siteinfo/\nwashingtonpost.com\n7https://www.alexa.com/siteinfo/foxnews.\ncom\n8https://github.com/DocNow/twarcday decreases as we go back in time. In all, we collected a\nlittle over 29 million tweets from January 1, 2021 to August\n17, 2021. We also split the tweets by group (pro-Palestinian\nor pro-Israeli) and by topic (Palestinian-Israeli con\ufb02ict re-\nlated or not), where we \ufb01ltered tweets using the follow-\ning keywords: Israel, Israeli, Palestine, Palestinian, Quds,\nAlquds, Jerusalem, Hamas, and Jarrah. The breakdown of\ntweets is as follows:\npro-Palestinian pro-Israeli\nTopically related 1,375,675 373,347\nNon-topically related 20,597,511 6,723,035\nFigure 2 shows the percentage of topically related tweets\nover time for both groups. It seems that the pro-Israeli\ngroup was generally more topically engaged than the pro-\nPalestinian from January to April, and the percentage of\ntopically related tweets is evenly matched from May on-\nward. We checked the most frequent hashtags for the pro-\nIsraeli group in the January to April time window, and\n10 out of the top 30 hashtags were related to: the Holo-\ncaust (Auschwitz, YomHaShoah, and HolocaustRemem-\nbranceDay, and Holocaust); anti-Semitism (Antisemitism,\nJusticeForSarahHalimi, and SarahHalimi \u2013 French Jewish\ndoctor who was killed in a seemingly anti-Semitic attack);\nand general Judaism-related terms (ShabbatShalom, Jew-\nish, and Passover). Such may indicate a large presence\nof Jewish users in the pro-Israeli group. Other hashtags\nalign with right-leaning or Republican talking points such\nas: Antifa, BidenBorderCrisis, WeveGotACountryToSave,\nGodBlessAmerica, GodBlessPresidentTrump, and Expel-\nMaxineWaters. For the most frequent hashtags for the\npro-Palestinian group, they were dominated by: progres-\nsive issues (MedicareForAll, ForceTheV ote, FreeAssange,\nTransDayOfVisibility, CancelStudentDebt, AbolishThePo-\nlice, and RaiseTheWage) and foreign issues (FarmersProtest\n(India), Haiti, YemenCantWait, Somalia, FreePalestine, and\nSaveSheikhJarrah).\nFigure 2: Percentage of topically related tweets for pro-\nPalestinian and pro-Israeli groups.\nGoing back to the central questions of the paper, the \ufb01rst\nPro-Palestinian Pro-Israeli\nSource Credibility Leaning Source Credibility Leaning\nWashingtonPost.com Mostly Factual Left-center FoxNews.com Mixed Right\ntheGuardian.com Mixed Left-center JPost.com Mostly Factual Right-center\nReuters.com Very High Center Breitbart.com Mixed Extreme right\nAlJazeera.com Mixed Left-center FreeBeacon.com Mixed Right/Extreme right\nJewishCurrents.org NYPost.com Mixed Right-center\nMiddleEastEye.net Mostly Factual Left-center DjhjMedia.com Low Extreme right\nDemocracyNow.org High Left OANN.com Low Extreme right\nElectronicIntifada.net Mostly Factual Left Hannity.com Low Extreme right\nMondoWeiss.net Mixed Extreme left DailyCaller.com Mixed Right\ntheOnion.com Satire NationalReview.com Mostly Factual Right\nTable 1: Most cited news sources for pro-Palestinian and pro-Israeli users along with credibility and ideological leaning (from\nmediabiasfactcheck.com . Foreign sources are italicized and bolded.\nquestion is: Do users resort to foreign or less popular\nsources with the advent of a major polarizing event? To\nanswer this question, we need to compare the relative cita-\ntions of foreign and less popular sources in the periods prior,\nduring, and post the event compared to popular sources.\nFor the pro-Palestinian group, we use the Washington Post\n(WashingtonPost.com \u2013 Alexa rank: 208) and CNN\n(cnn.com \u2013 1099) as our reference popular media sources.\nAs for the pro-Israeli groups, we use Fox News ( FoxNews.\ncom \u2013 251) and Breitbart News ( breitbart.com \u2013\n41510) as our reference. For foreign and less popular\nsources for the pro-Palestinian group, we use Aljazeera\n(AlJazeera.com \u2013 Alexa rank: 1,659), Middle East Eye\n(MiddleEastEye.net \u2013 40,196), and Jewish Currents\n(JewishCurrents.org \u2013 292,953). For the equivalent\nfor the pro-Israeli group, we use Jerusalem Post ( JPost.\ncom \u2013 Alexa rank: 4,487), Free Beacon ( FreeBeacon.\ncom \u2013 30,681), and Sean Hannity ( Hannity.com \u2013\n62,718). We chose these media sources to cover foreign\n(non-US) and US sources with varying levels of popularity.\nUsers may cite news items in their tweets by either retweet-\ning a source\u2019s tweets or by embedding a link to the site of\nthe news source. Many sources employ multiple Twitter ac-\ncounts (ex. AlJazeera operates @AJEnglish, @AJENews,\nand @AJPlus) and use different base URLs (ex. Fox News\nusesFoxNews.com andfxn.ws ). We count a retweet or\nan embedded URL as a citation of a source.\nFigure 3 shows the number of citations for the afore-\nmentioned sources for pro-Palestinian and pro-Israeli groups\nwith topically related and non-topically related tweets sepa-\nrated. The sub-\ufb01gures of the topically related citations show\nthat the less popular and foreign sources match or eclipse\nthe reference popular sources particularly during the period\nof the con\ufb02ict and the ensuing period. This was more pro-\nnounced for well established foreign sources, namely Al-\nJazeera and Jerusalem Post for the pro-Palestinian and pro-\nIsraeli groups respectively. Thus for our \ufb01rst question, the\ndata suggests that users may indeed resort to foreign or less\npopular sources for their information needs particularly in\nconjunction with major polarizing events.\n9https://www.alexa.com/siteinfo/cnn.com\n10https://www.alexa.com/siteinfo/breitbart.\ncomThis leads us to our second question, namely: Why do\nusers tune into less popular or foreign sources? Is it be-\ncause of depth of coverage or mismatch in stance align-\nment with popular sources? To answer this question, we\nexamine topically related tweets that refer to the Israeli-\nPalestinian con\ufb02ict during May 2021. We look at all tweets\nthat refer to one of the news sources of interest, whether in\nthe form a retweet, reply, mention, or share of an article.\nThis would allow us to examine how pro-Palestinian and\npro-Israeli users perceive the media sources. For all media\nsources, we manually labeled the 25 most retweeted tweets.\nPro-Palestinian Group The Washington Post tweets can\nbe roughly categorized into 4 categories, namely:\n\u2022 Reporting news (45.6%). Ex. RT @RashidaTlaib: No\nmore weapons to kill children and families @Joe-\nBiden. Enough. https://t.co/QQcs2WYEhl (arti-\ncle: Biden approves weapons sales to Israel).\n\u2022 Exposing Israeli atrocities (27.9%). Ex. RT @washing-\ntonpost: The Committee to Project Journalists expressed\nconcerns that Israel was \u201ddeliberately targeting media fa-\ncilities in order to disrupt coverage of the human suffering\nin Gaza\u201d https://t.co/vgSkZ3z0fu\n\u2022 Criticizing the Washington Post (21.0%). Ex. RT\n@m7mdkurd: The @WashingtonPost podcast featuring\nme is highly edited. It\u2019s amazing they used my quote say-\ning \u201cno one listens to Palestinians\u201d & then proceeded to\nremove \u201ccolonial\u201d \u201cfascist\u201d \u201capartheid\u201d from my vocabu-\nlary. They even took out the word \u201coccupation.\u201d\n\u2022 Praising coverage (5.5%). Ex. RT @4noura: This is\nhow it\u2019s done. And this is how well get it done.\n@washingtonpost with an honest headline. #GazaUn-\nderAttack #savesheikhjarah #Jerusalem #Haifa #Lydd\n#apartheidisrael #Palestinian #Freedom https://t.\nco/haLMk8sXct\nAs for CNN.com, tweets can be divided into 4 main cate-\ngories, namely:\n\u2022 Criticizing CNN (72.3%). Ex. RT @Dena: This @CNN\ninternal memo directs staff to say \u201cHamas-run Gaza Min-\nistry of Health\u201d when reporting casualty numbers. It\nwas sent by the Jerusalem bureau chief. This is a page\nstraight out of Israel\u2019s playbook. It serves to justify the at-\ntack on civilians & medical facilities https://t.co/\nnAWF4s7i1F\n\u2022 Referencing CNN staff (20.7%). Ex. RT\n@Stone SkyNews: The Israeli police pushing around\naccredited news correspondent @bencnn and his @cnni\ncrew. It\u2019s happened to us all this week. Today I walked\npast a policeman. I smiled and said hello. \u201cF*ck off\u201d he\nsaid.https://t.co/FuS1D9g3ey\n\u2022 Praising coverage (5.0%). Ex. RT @4noura: I rarely get\nasked what it feels like to be Palestinian. Thank you\n@BeckyCNN https://t.co/tHpWDaq9p8\n\u2022 Reporting news (2.0%). Ex. RT @ryanobles: FIRST ON\n@CNN: Sen. Jon @ossoff leads a group of 28 members\nof the Democratic Senate Caucus calling for a cease \ufb01re\nin Israeli- Palestinian con\ufb02ict. Full list of signatories: (W/\n@jessicadean & @DaniellaMicaela)\nAs can be seen, both CNN and Washington Post received\nmuch criticism (72.3% & 21.0% respectively) and very little\npraise (5.0% & 5.5% respectively) from the pro-Palestinian\ngroup. Unlike CNN, Washington Post articles were often\nused a source of news. Further, Washington Post articles\nwere far more likely to be critical of Israel compared to\nCNN, and such criticism may have contributed to signi\ufb01-\ncantly more topically-relevant citations of the Washington\nPost compared to CNN (Figure 6 (a)). One curious aspect\nabout CNN was that other journalists and activists reported\nattacks on CNN staff at the hands of Israeli soldiers. This\nhints to CNN having reporters on the ground. Yet, their cov-\nerage is criticized by a demographic that typical consumes\ntheir content.\nSimilarly we analyzed the 3 foreign and less popular\nsources, and we found 3 main themes in all of them, namely:\n\u2022 Exposing Israeli atrocities:\n\u2013Aljazeera (74.9% \u2013 mostly in the form of news). Ex.\nRT @AJPlus: Israeli police stormed Jerusalem\u2019s Al-\nAqsa Mosque hours after the Israel-Hamas cease\ufb01re,\n\ufb01ring rubber bullets and stun grenades at Palestinians.\nWitnesses say some Palestinians stayed after Friday\nprayers to celebrate the cease\ufb01re. Police claim there\nwere \u201driots.\u201d https://t.co/Mb8GWgT5OJ\n\u2013Middle East Eye (100%). Ex. RT @MiddelEastEye:\nI don\u2019t know what to do. A 10-year-old Palestinian\ngirl breaks down while talking to MEE after Israeli air\nstrikes destroyed her neighbour\u2019s house, killing 8 chil-\ndren and 2 women #Gaza #Palestine #Israel https:\n//t.co/PWXsS032F5\n\u2013Jewish Currents (13.4%). Ex. RT @ArielleLAngel: To-\nday in @jewishcurrents, a bit of our own teshuva for\nour magazine\u2019s abandonment of the Palestinian peo-\nple during the Nakba. Grateful to Dorothy Zellner, a\ndaughter of the Jewish Communist left, for her work\non bringing this little-known history to light https:\n//t.co/09WuEVYMkn\n\u2022 Criticizing US policy:\u2013AlJazeera (25.1%). Ex. RT @AJPlus: The U.S. blocked\nthe UN Security Council from issuing a statement\naimed at reducing tensions between Israel and Pales-\ntinians, diplomats say. Sources told @AFP that 14 out\nof 15 Sec. Council members were in favor of the state-\nment. The U.S. also blocked a similar text on Monday.\nhttps://t.co/xsvkwLTXbr\n\u2013Jewish Currents (39.9%). Ex. RT @theIMEU:\nBREAKING: @AOC plans to introduce a bill\nto block Biden\u2019s weapons sale to Israel. Read\nmore here: https://t.co/1jAVlsUVxF\nhttps://t.co/NaH7yVSTF1\n\u2022 Spreading awareness about Palestinian/Israeli con\ufb02ict:\n\u2013Jewish Currents (46.6%). Ex. RT @JewishCurrents:\nWe\u2019ve put together a selection of our articles from the\npast few years that provide essential background for\nthe crisis in Israel/Palestine. Here\u2019s a thread of some\nof them: https://t.co/pWRvniT4xl\nFigure 4 summarizes the categories for pro-Palestinian\ngroup. As seen from the references to foreign and less popu-\nlar sources, the sources report on the con\ufb02ict from different\nangles. For example, AlJazeera focused mostly on providing\nspeci\ufb01c news items (storming of Al-Aqsa compound, num-\nber of Palestinian casualties, etc.) that portray the Israeli side\nin a negative light. Middle East Eye tweets were more sen-\nsationally critical of Israel with, for example, an interview\nwith 10 year old girl featuring prominently in their coverage.\nJewish Currents tweets were more concerned with bringing\nawareness to the plight of the Palestinians and criticizing the\nUS position.\nIn contrasting all the sources for the pro-Palestinian\ngroups, the answer to the second questions of why users\nare resorting to foreign or less popular media seems to be\na mixture of diverging stances from popular sources such\nas CNN, a desire to learn more speci\ufb01c news about the\ncon\ufb02ict (ex. from AlJazeera), and the sharing of more sen-\nsational content (ex. from Middle East Eye). Figure 6 (a)\nshows the relative proportion of topically related citations\nfrom the \ufb01ve different sources between January to July 2021.\nThe Figure suggests that foreign and less popular sources\ndominated a greater proportion of user interest during the\ncon\ufb02ict period (May, 2021) and in the following months.\nThis reinforces the narrative that users are turning to less\npopular sources that satisfy their needs.\nPro-Israeli Group For the pro-Israeli group, we con-\nducted a similar analysis. For the \u201cpopular\u201d sources, namely\nFox News and Breitbart News. For Fox News, the categories\nare:\n\u2022 Attacking leftists and Democrats including Biden, Black\nLives Matter (BLM), and the \u201cSquad\u201d (group of pro-\ngressive lawmakers) (37.5%). Ex. RT @RichardGrenell:\nThis makes me sick. It\u2019s disgusting and every Amer-\nican should condemn this immediately. https://t.\nco/I8WavM578M \u2013 (citing a Fox News article about\nBLM solidarity with Palestinians).\n(a)\n (b)\n(c)\n (d)\nFigure 3: Number of citations per source for pro-Palestinian group for (a) topic-related and (b) non-topic-related tweets, and\nfor pro-Israeli group for (c) topic-related and (d) non-topic-related tweets.\n\u2022 Exposing antisemitism (30.3%). Ex. @DreyfusShawn:\nWhy is Fox the only major network covering the anti-\nsemitic attacks on Jews by Palestinians in the US?\n\u2022 Supporting Israel (19.7%). Ex. RT @Mike Pence: If\nthe World Knows Nothing else Let the World Know\nthis- America Stands With Israel https://t.co/\ni0waMKe2al\n\u2022 Blaming Hamas and Palestinian groups (12.4%). Ex.\nRT @TomCottonAR: There will be a \u2018signi\ufb01cant de-\nescalation\u2019 when Hamas stops its terror attacks against\nIsrael. https://t.co/pdftQttXFg\n\u2022 Attacking other media sources (5.2%). Ex. RT\n@BoSnerdley: CNN avoids Israel-Hamas con\ufb02ict\nduring primetime, spends over 90 minutes on Liz Cheney\nhttps://t.co/0lmHznAK98 #FoxNews\nAs for Breitbart News, the categories are:\u2022 Blaming Hamas and Palestinian groups (78.7%). Ex. RT\n@BreitbartNews: Gaza has spent $175 million on terror\nrockets in a week but has no money for vaccines or edu-\ncation. Let that sink in for a moment.\n\u2022 Attack leftists and Democrats including Biden, Black\nLives Matter, the \u201cSquad\u201d (16.4%). Ex. RT @Breitbart-\nNews: Andrew Yang did the right thing and backed Israel.\nNow Democrats are making him pay the price. https:\n//t.co/Y2C8n5q9Yo\n\u2022 Exposing anti-Semitism (11.5%). Ex. RT @Breitbart-\nNews: Pro-Palestinian demonstrators were \ufb01lmed Thurs-\nday as they attacked Jews in Manhattan. https://t.\nco/0JEvY8zdFK\n\u2022 Supporting Israel (2.7%). Ex. RT @BreitbartNews: Chris-\ntians from around the globe have donated nine portable\nbomb shelters to Israeli communities near the Gaza bor-\nFigure 4: Tweets categories for pro-Palestinian group\nder.https://t.co/Nda4F9eoiH\nFor the foreign/less popular sources, Sean Hannity and\nFree Beacon were very similar in their framing and very dif-\nferent from the Jersualem Post. For the Jerusalem Post, the\nmain categories are:\n\u2022 Expressing gratitude to US, including Biden and\nDemocrats (45.1%). Ex. RT @Jerusalem Post: House\nSpeaker #NancyPelosi condemned the \u201cescalating and in-\ndiscriminate rocket attacks by #Hamas against #Israel\u201d\nwho \u201chas the right to defend herself against this assault,\nwhich is designed to sow terror and undermine prospects\nfor peace.\u201d\n\u2022 Reporting news (26.4%). Ex. RT @allahpundit: Israel\nshowed US \u2018smoking gun\u2019 on Hamas in AP of\ufb01ce tower,\nof\ufb01cials say https://t.co/8sC8Ri3SG1\n\u2022 Exposing antisemitism (18.8%). Ex. RT\n@Jerusalem Post: Following a spate of anti-Israel\nprotests across Germany tied to the ongoing #Israel-\n#Gaza violence, political leaders here have vowed to\ncrack down on demonstrators who have used #antisemitic\nrhetoric and have attacked Jewish institutions.\n\u2022 Blaming Hamas and Palestinian groups (15.9%). Ex. RT\n@Jerusalem Post: #BREAKING: New Illustrated images\nshow exactly how #Hamas operate from within civilian\nneighborhoods in the #Gaza Strip. Read more: https:\n//bit.ly/3u4SyWe\n\u2022 Warning talks with Iran (8.3%). RT @Cliff Sims: John-\nRatcliffe in @Jerusalem Post: \u201cIf the Biden administra-\ntion continues on its current course, re-enters a nuclear\ndeal with Iran and lifts sanctions on the regime, this will\nbe tantamount to giving them another airplane full of\ncash.\u201d https://t.co/hNEFOJQjow\nFigure 5: Tweets categories for pro-Israeli group\nFor Sean Hannity and Free Beacon the main categories\nare:\n\u2022 Attacking leftists and Democrats including Biden, BLM,\nand the Squad:\n\u2013Sean Hannity (80.7%). Ex. RT @seanhannity: TRUMP\non ISRAEL: \u2018Under Biden the World is Getting\nMore Violent and More Unstable\u2019 https://t.co/\nltRpYebxgD\n\u2013Free Beacon (65.7%). Ex. RT @EliLake: Read @con-\ntinetti on the corbynization of the Democratic party.\nhttps://t.co/ishI4YnPPO\n\u2022 Blaming Hamas and Palestinian groups:\n\u2013Sean Hannity (11.0%). Ex. RT @seanhannity: Report:\nIran Funding Palestinian Terrorist Attacks On Israel\nhttps://t.co/RlV5HDI9f0\n\u2013Free Beacon (17.4%). Ex. RT @Kredo0: FLASH-\nBACK to March: Palestinians Funneled Hundreds\nof Millions to Terrorists, State Dept Report Reveals\nhttps://t.co/hiThij4hj9\n\u2022 Supporting Israel:\n\u2013Sean Hannity (11.0%). Ex. RT @seanhannity: CRUZ\nto VISIT ISRAEL: The Senator Will Travel to Israel\nin the \u2018Coming Days\u2019 to Assess Security Situation\nhttps://t.co/hRjmn7xAlX\n\u2013Free Beacon (8.7%). Ex. RT @SenTedCruz: \u201cSens.\nCruz and Hagerty Land in Israel to Assess Dam-\nage from Hamas War\u201d via @Kredo0 @FreeBeacon\nhttps://t.co/LKkfOgsSgI\n\u2022 Exposing anti-Semitism:\n(a)\n (b)\n(c)\n (d)\nFigure 6: Proportional citation per source for pro-Palestinian group for (a) topic-related and (b) non-topic-related tweets, and\nfor pro-Israeli group for (c) topic-related and (d) non-topic-related tweets.\n\u2013Sean Hannity (11.5%). Ex. RT @seanhannity: HATE\nIN LA: Pro-Hamas Activists Attack Jewish Ameri-\ncans at a Restaurant in Los Angeles https://t.co/\nFIKVh5GVh4\n\u2013Free Beacon (5.9%). Ex. RT @MatthewFoldi: new\nfrom @alexnester2020 and me @FreeBeacon @North-\nwesternU profs @NUQatar are quick to condemn Is-\nrael I reached out to 27 who signed an anti-Israel state-\nment asking if their avowed support for Asians ex-\ntends to Asian slaves in Qatar. No response https:\n//t.co/DYBk5X4tSs (1/8)\n\u2022 Attacking other media sources:\n\u2013Sean Hannity (11.1%). Ex. RT @seanhannity: Face-\nbook Shuts Down Prayers for Israel Page with Over 77\nMillion Followers https://t.co/peuuI3qH9x\n\u2013Free Beacon (11.5%). Ex. RT @BoSnerdley: AP HiresAnti-Israel Activist as News Associate https://t.\nco/dVAR2I7ON2\nFigure 5 summarizes the categories for the media sources\nfor the pro-Israeli group. As the data shows, the foreign\nsource (Jerusalem Post) was the most different from all the\nother sources in that it focused on expressing gratitude to\nthe US administration, including Biden and the Democrats,\nand reported on events on the ground. The less popular\nUS sources (Hannity and Free Beacon) are highly partisan\nwith the majority of the tweets associated with attacks on\nDemocrats, liberals, and progressives. Breitbart News was\nmostly concerned with assigning blame to Palestinians. Fox\nNews covered the different categories more evenly.\nIn contrasting all the sources for the pro-Israeli group, the\nanswer to the second questions of why users are resorting\nforeign or less popular media seems to be a mixture of more\nextreme partisanship or sensationalism and a desire to\nlearn more speci\ufb01c news about the con\ufb02ict. Both these as-\npects are shared with the pro-Palestinian group. However,\nunlike the case of the pro-Palestinian group, the stance of\nthe popular media sources was not divergent from the for-\neign and less popular ones, and the popular media sources\nwere not eclipsed by the foreign and less popular ones. Fig-\nure 6 (c) shows the relative proportion of topically related\ncitations from the \ufb01ve different sources between January to\nJuly 2021. The Figure suggests that Jerusalem Post was the\nmain source of topical information before the con\ufb02ict. With\nthe advent of the con\ufb02ict, it was crowded by popular sources.\nHowever, as the con\ufb02ict subsided, Jerusalem Post came back\nto reclaim a dominant position. This is the exact opposite of\nwhat it is observed for the pro-Palestinian group. We pos-\ntulate that when the narrative of the foreign or less popular\nsources contradicts that of the popular sources, such in the\ncase of pro-Palestinian group, such sources would dominate\nin the time of con\ufb02ict. However, when such sources are in\nline with the popular sources, the popular sources gain rela-\ntive market share in the time of con\ufb02ict.\nThe third question of interest is: Does the sudden boost\nin popularity of the sources translate into future pop-\nularity? Figures 6 (b) and (d) show proportional user in-\nteractions for the non-topically related tweets for the pro-\nPalestinian and pro-Israeli groups respectively. As the data\nsuggests, while foreign and less popular sources bene\ufb01ted\nfrom their topically-related coverage during and after the\ncon\ufb02ict, the bene\ufb01t did not translate into non-topically re-\nlated coverage. In fact, their relative share for non-topically\nrelated tweets decreased after the con\ufb02ict compared to be-\nfore the con\ufb02ict. This seems to be the case for all foreign and\nless popular sources for both groups. It is unclear whether\nthis is transient or more permanent, and more data from later\ntime epochs are required to reach a more de\ufb01nitive conclu-\nsion. Nonetheless, the answer to the third question seems to\nbe that the sudden boost in popularity may not translate into\nfuture popularity. We suspect two potential reasons for this.\nFirst, previous research suggests that well-established media\norganizations are resilient in the face of nascent media or-\nganization (Nelson, 2020). Second, the event may actually\nframe a media source, where it becomes strongly associated\nwith speci\ufb01c topics. Further work is required to con\ufb01rm our\nsuspicion.\nWe looked at the tweets of AlJazeera and Sean Hannity\nfor the pro-Palestinian and pro-Israeli groups respectively,\nas both maintained a sizeable, though decreased, propor-\ntion of user interest after the con\ufb02ict. From inspecting the\ntweets related to AlJazeera, we do not \ufb01nd clear pattern\nthat would de\ufb01nitively explain the post-con\ufb02ict trend. We\nfound among the top 50 retweeted tweets: 24 are related\nto the US (retweeted 565 times); 24 are related to foreign\nnews (retweeted 530); and the 2 remaining ones are re-\nlated to a global issue, namely climate change (retweeted\n91 times). We also notice that most of AlJazeera retweets\nwere from @AJPlus, which is a social media arm of Al-\njazeera \u2013 @AJPlus retweeted 3,483 times compared to 2,194\nretweets of @AJEnglish (Aljazeera English). As for the 50\nmost retweeted tweets associated with Sean Hannity: 30\ntweets are attacking Biden and the democrats (retweeted 862times), 13 tweets are praising Trump (retweeted 416 times),\nand the remaining are a mix of different news and political\nissues. Such a distribution highlights the politically sensa-\ntional nature of Sean Hannity.\nDiscussion and Conclusion\nIn this paper, we examined the interaction of users with for-\neign and less popular media sources in conjunction with a\nmajor polarizing event, speci\ufb01cally the May 2021 Israeli-\nPalestinian con\ufb02ict. We conducted our analysis on more\nthan 8 thousand users, whom we automatically labeled as\npro-Palestinian or pro-Israeli. We show that users may re-\nsort to consuming and/or referring to less popular or for-\neign sources during a polarizing event. We identi\ufb01ed mul-\ntiple reasons for this behavior. First is to \ufb01nd content that\nreaf\ufb01rms their worldview, specially when such view is not\nbeing expressed by popular media sources. This was clear\nfor the pro-Palestinian group, where they were sharing con-\ntent from AlJazeera and Middle East Eye that was mostly\ncritical of Israel, and they were critical of the coverage of\npopular left-leaning sources such as CNN and the Wash-\nington Post. Hence, news consumers may sideline popular\nsources that they typically consume in favor of other source\nfor speci\ufb01c topics. Second, users may be interested in more\nextreme, hyper-partisan, or sensational content, such as Sean\nHannity for the pro-Israeli group and Middle East Eye for\nthe pro-Palestinian group. Third, users may have a desire to\nlearn more about a topic, particularly when more popular\nsources do not provide suf\ufb01cient coverage or they provide\nmore opinionated content. We observed this in the case of\nJerusalem Post and AlJazeera, both of whom were reporting\non events on the ground, though they may have been framed\nin ways that reaf\ufb01rm speci\ufb01c viewpoints.\nLess popular and foreign sources may challenge the dom-\ninance of popular sources on speci\ufb01c topics if a substan-\ntial portion of the typical consumers of popular sources are\nunhappy with their narrative \u2013 as in the case of the pro-\nPalestinian group. If the stance of the foreign/less popular\nsources is aligned with the stance of the popular sources,\nthen popular sources may actually crowd out less popular\nsources that typically dominate a topic in normal times.\nGiven the increased popularity of foreign or less popular\nsource on a speci\ufb01c topic may not translate to popularity on\nother topics either during or after a major event. In fact, we\nobserved that relative percentage of citations of sources such\nas AlJazeera and Hannity for non-topical tweets actually de-\ncreased from May onward. Given the time horizon, we can-\nnot ascertain if this decrease is transient or sustained. How-\never, we can clearly observe no increase. Conversely, pop-\nular sources, such as CNN and Fox News, may experience\nsome drop in relative popularity among portions of their typ-\nical consumers during the time of the major event. However,\nthey seem to rebound after the event has passed. Further in-\nvestigation using other events and longer time horizons are\nneeded to con\ufb01rm this \ufb01nding. Another interesting note, par-\nticularly concerning CNN, is that pro-Palestinian users were\nin fact consuming CNN content in general (see Figure 6 (b)),\nbut they were choosing not share con\ufb02ict related content\nfrom the site (Figure 6 (a)).\nReferences\nBandari, R.; Asur, S.; and Huberman, B. 2012. The pulse of\nnews in social media: Forecasting popularity. In Proceed-\nings of the International AAAI Conference on Web and\nSocial Media , volume 6.\nBorge-Holthoefer, J.; Magdy, W.; Darwish, K.; and Weber,\nI. 2015. Content and network dynamics behind egyp-\ntian political polarization on twitter. In Proceedings of\nthe 18th ACM Conference on Computer Supported Coop-\nerative Work & Social Computing , 700\u2013711. ACM.\nCastillo, C.; El-Haddad, M.; Pfeffer, J.; and Stempeck, M.\n2014. Characterizing the life cycle of online news sto-\nries using social media reactions. In Proceedings of the\n17th ACM conference on Computer supported coopera-\ntive work & social computing , 211\u2013223.\nChyi, H. I., and Tenenboim, O. 2019. From analog dol-\nlars to digital dimes: A look into the performance of us\nnewspapers. Journalism Practice 13(8):988\u2013992.\nDarwish, K.; Stefanov, P.; Aupetit, M. J.; and Nakov, P.\n2019. Unsupervised user stance detection on twitter.\narXiv preprint arXiv:1904.02000 .\nDarwish, K. 2018. To kavanaugh or not to ka-\nvanaugh: That is the polarizing question. arXiv preprint\narXiv:1810.06687 .\nEzzina, R. 2021. Western\u2019s media representation of pales-\ntine. International Journal of Progressive Sciences and\nTechnologies 25(1):357\u2013365.\nHensinger, E.; Flaounas, I.; and Cristianini, N. 2013. Mod-\nelling and predicting news popularity. Pattern Analysis\nand Applications 16(4):623\u2013635.\nKeneshloo, Y .; Wang, S.; Han, E.-H.; and Ramakrishnan, N.\n2016. Predicting the popularity of news articles. In Pro-\nceedings of the 2016 SIAM International Conference on\nData Mining , 441\u2013449. SIAM.\nKutlu, M.; Darwish, K.; and Elsayed, T. 2018. De-\nvam vs. tamam: 2018 turkish elections. arXiv preprint\narXiv:1807.06655 .\nMagdy, W.; Darwish, K.; Abokhodair, N.; Rahimi, A.; and\nBaldwin, T. 2016. # isisisnotislam or# deportallmus-\nlims?: Predicting unspoken views. In Proceedings of the\n8th ACM Conference on Web Science , 95\u2013106. ACM.\nMagdy, W.; Darwish, K.; and Weber, I. 2016. # failedrevo-\nlutions: Using twitter to study the antecedents of isis sup-\nport. First Monday 21(2).\nMullainathan, S., and Shleifer, A. 2005. The market for\nnews. American economic review 95(4):1031\u20131053.\nNelson, J. L., and Webster, J. G. 2017. The myth\nof partisan selective exposure: A portrait of the on-\nline political news audience. Social Media+ Society\n3(3):2056305117729314.\nNelson, J. L. 2020. The enduring popularity of legacy jour-\nnalism: An analysis of online audience data. Media and\nCommunication 8(2):40\u201350.Stefanov, P.; Darwish, K.; Atanasov, A.; and Nakov, P. 2020.\nPredicting the topical stance and political leaning of me-\ndia using tweets. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics ,\n527\u2013537.\nWarner, B. R., and Neville-Shepard, R. 2014. Echoes of\na conspiracy: Birthers, truthers, and the cultivation of ex-\ntremism. Communication Quarterly 62(1):1\u201317.\nWeber, I.; Garimella, V . R. K.; and Batayneh, A. 2013. Sec-\nular vs. islamist polarization in egypt on twitter. In Pro-\nceedings of the 2013 IEEE/ACM International Confer-\nence on Advances in Social Networks Analysis and Min-\ning, 290\u2013297. ACM.\nWong, F. M. F.; Tan, C. W.; Sen, S.; and Chiang, M. 2013.\nQuantifying political leaning from tweets and retweets. In\nSeventh International AAAI Conference on Weblogs and\nSocial Media .\nWong, F. M. F.; Tan, C. W.; Sen, S.; and Chiang, M. 2016.\nQuantifying political leaning from tweets, retweets, and\nretweeters. IEEE transactions on knowledge and data en-\ngineering 28(8):2158\u20132172.\nWu, B., and Shen, H. 2015. Analyzing and predicting news\npopularity on twitter. International Journal of Informa-\ntion Management 35(6):702\u2013711.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "News consumption in time of conflict: 2021 Palestinian-Israel War as an example", "author": ["K Darwish"], "pub_year": "2022", "venue": "Proceedings of the 14th ACM Web Science \u2026", "abstract": "This paper examines news consumption in response to a major polarizing event, and we use  the May 2021 Israeli-Palestinian conflict as an example. We conduct a detailed analysis of"}, "filled": false, "gsrank": 64, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3501247.3531568", "author_id": ["y7tlR6UAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:NCFPm48M254J:scholar.google.com/&output=cite&scirp=63&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=NCFPm48M254J&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 9, "citedby_url": "/scholar?cites=11446756688817758516&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:NCFPm48M254J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2109.12844"}}, {"title": "Tuberculosis and foreign-born populations in the United States: A mixed methods pilot study of media reporting and political identification", "year": "2020", "pdf_data": "ZK[KF ZIN FZ\\OIS K\n\\ulo~muw{\u20act\u20ac kzn q{~otrz/l{~z |{|uwktt{z\u20ac tz\ntso]ztton [tkto\u20ac> Fytxon yots{n\u20ac |tw{t\n\u20actuny {qyontk ~o|{~ttzr kzn |{wtttmkw\ntnozttqtmktt{z\nFzrow U1Jo\ufffdkt OJ\n4.5*.[s~k\ufffdkz\ufffdst T1[o\ufffdsk\ufffdk\ufffdoo6.Tkty\ufffdzk [1Tku\ufffdyno~ OJ\n7.9.\nG~t\ufffd\ufffdk Sk\ufffd\ufffdykzz5.Sk\ufffd~ozmo I1Tkn{qq5.:.Kytw\ufffd S1I{sz9.;.Q{sz [1G~{\ufffdz\ufffd\ufffdotz9.;\n4Jt\ufffdt\ufffdt{z {qOzqom\ufffdt{\ufffd\ufffd Jt\ufffdok\ufffdo\ufffd .G~trsky \u2019_{yoz)\ufffd N{\ufffd|t\ufffdkw. G{\ufffd\ufffd{z. TF. ]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk.\n5Oz\ufffdo~zk\ufffd t{zkw [{mto\ufffd\ufffd q{~Ozqom\ufffdt{\ufffd\ufffd Jt\ufffdok\ufffdo\ufffd. G{\ufffd\ufffd{z. TF. ]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk. 6Ioz\ufffdo~ q{~\nV\ufffd\ufffdm{yo\ufffd Zo\ufffdok ~mskznK\ufffdkw\ufffdk\ufffdt{z. Tktzo Tontmkw Ioz\ufffdo~ Zo\ufffdok~ms Oz\ufffd\ufffdt\ufffd\ufffd\ufffdo. W{~\ufffdwkzn. Tktzo. ]zt\ufffdon\n[\ufffdk\ufffdo\ufffd {qFyo~tmk. 7I{y|\ufffd\ufffdk\ufffdt{zk wNokw\ufffds Ozq{~yk\ufffdtm\ufffd W~{r~ky. G{\ufffd\ufffd{z Istwn~oz )\ufffdN{\ufffd|t\ufffdkw. G{\ufffd\ufffd{z. TF\n]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk. 9Jo|k~\ufffdy oz\ufffd{qWontk\ufffd~tm\ufffd .Nk~\ufffdk~n Tontmkw [ms{{w. G{\ufffd\ufffd{z Istwn~oz )\ufffdN{\ufffd|t\ufffdkw.\nG{\ufffd\ufffd{z. TF. ]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk. :I{y|\ufffd\ufffdk\ufffdt{zk wK|tnoy t{w{r\ufffd Skl. G{\ufffd\ufffd{z Istwn~oz)\ufffd N{\ufffd|t\ufffdkw.\nG{\ufffd\ufffd{z. TF. ]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk. ;Jt\ufffdt\ufffdt{z {qOzqom\ufffdt{\ufffd\ufffd Jt\ufffdok\ufffdo \ufffd.]zt\ufffdo~\ufffdt\ufffd\ufffd {qTk\ufffd\ufffdkms \ufffd\ufffdo\ufffd\ufffd\ufffd.\n_{~mo\ufffd\ufffdo~. TF. ]zt\ufffdon [\ufffdk\ufffdo\ufffd {qFyo~tmk\n*kzrow1z 1no\ufffdktEryktw 1m{y\nFl\u20act~kmt\nGkmvr~{\ufffdzn\nTontk ~o|{~\ufffdtzr {zm{yy\ufffdztmklwo nt\ufffdok\ufffdo\ufffd sk\ufffdlooz noy{z\ufffd\ufffd~k\ufffdo n\ufffd{kqqom\ufffd \ufffdso|o~mo|\ufffdt{z\n{q\ufffdso|\ufffdlwtm1 I{yy\ufffdztmklwo nt\ufffdok\ufffdo ~o|{~\ufffdtzr ~owk\ufffdon \ufffd{q{~otrz/l{~z |o~\ufffd{z\ufffd sk\ufffdz{\ufffd\ufffdo\ufffd\nlooz o\ufffdkw\ufffdk\ufffdon1\nVluom\ufffdt\ufffdo\nK\ufffdkytzo s{\ufffd |{wt\ufffdtmkw wokztzr tz\ufffdsoyontk kqqom\ufffd\ufffd ~o|{~\ufffdtzr {z\ufffd\ufffdlo~m\ufffdw{\ufffdt\ufffd *\\G+ tzq{~otrz/\nl{~z |o~\ufffd{z\ufffd1\nTo\ufffds{n\ufffd\nNokw\ufffdsTk|. kntrt\ufffdkw \ufffd\ufffd~\ufffdotwwkzmo |wk\ufffdq{~y \ufffdsk\ufffdkrr~ork\ufffdo\ufffd zo\ufffd\ufffd \ufffd{\ufffd~mo\ufffd {zrw{lkw tzqom\ufffdt{\ufffd\ufffd\nnt\ufffdok\ufffdo\ufffd. \ufffdk\ufffd \ufffd\ufffdon1 Jk\ufffdk \ufffdk\ufffd }\ufffdo~ton q{~yontk ~o|{~\ufffd\ufffd q~{y \ufffdso]1[1 lo\ufffd\ufffdooz 5344\u02d8534=.\nm{z\ufffdktztzr \ufffdso\ufffdo~y \ufffd\\G\ufffd {~\ufffd\ufffd\ufffdlo~m\ufffdw{\ufffdt\ufffd\ufffd kzn\ufffdq{~otrz l{~z\ufffd. \ufffd~oq\ufffdroo *\ufffd+.\ufffd {~\ufffdty\n*ytr~kz\ufffd\ufffd+1\ufffd Zo|{~\ufffd\ufffd \ufffdo~o ~o\ufffdto\ufffdon \ufffd{o\ufffdmw\ufffdno n\ufffd|wtmk\ufffdo\ufffd kznz{z/s\ufffdykz mk\ufffdo\ufffd1 Kkms\nyontk \ufffd{\ufffd~mo \ufffdk\ufffd ~k\ufffdon \ufffd\ufffdtzr \ufffd\ufffd{tzno|oznoz\ufffd yontk ltk\ufffd tzntmk\ufffd{~\ufffd \ufffd{k\ufffd\ufffdo\ufffd\ufffd |{wt\ufffdtmkw\nwokztzr1 L{~\ufffd\ufffd/\ufffdt\ufffd z{z/\ufffd\ufffdlo~m\ufffdw{\ufffdt\ufffd ~o|{~\ufffd\ufffd \ufffdo~o ~kzn{yw\ufffd \ufffdky|won kzno\ufffdkw\ufffdk\ufffdon k\ufffdkm{z/\n\ufffd~{w1\\\ufffd{ tzno|oznoz\ufffd ~o\ufffdto\ufffdo~\ufffd |o~q{~yon \ufffdoz\ufffdtyoz\ufffd kzkw\ufffd\ufffdt\ufffd {zokms ~o|{~\ufffd1\nZo\ufffd\ufffdw\ufffd\ufffd\nVq<=4\\G/k\ufffd\ufffd{mtk\ufffdon ~o|{~\ufffd\ufffd tz\ufffdso][.7:~oqo~ozmon q{~otrz/l{~z tznt\ufffdtn\ufffdkw\ufffd. kzn\ufffdo~o\ntzmw\ufffdnon tz\ufffdst\ufffdkzkw\ufffd\ufffdt\ufffd1 :31=& *5<+ {q~o|{~\ufffd\ufffd \ufffdo~o |\ufffdlwt\ufffdson tz~trs\ufffd/wokztzr zo\ufffd\ufffd yontk\nPLOS ONE\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 4245k4444444444\nk4444444444\nk4444444444\nk4444444444\nk4444444444\nOPEN ACCESS\nIt\ufffdk\ufffdt{z> Jo\ufffdkt FU.[o\ufffdsk\ufffdk\ufffdo o[T.Tku\ufffdyno~\nT[.Sk\ufffd\ufffdykzz G.Tkn{qq SI.I{sz KS.o\ufffdkw1\n*5353+ \\\ufffdlo~m\ufffdw{\ufffdt \ufffdkznq{~otrz/l{ ~z|{|\ufffdwk\ufffdt{z \ufffd\ntz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\ufffd> Fyt\ufffdon yo\ufffds{n\ufffd |tw{\ufffd\ufffd\ufffd\ufffdn\ufffd\n{qyontk ~o|{~\ufffdtzr kzn|{wt\ufffdtmkw tnoz\ufffdtqtmk\ufffdt{z 1WS{[\nVUK49*7+> o3563=:;1 s\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42\nu{\ufffd~zkw1|{zo 13563=:;\nKnt\ufffd{~> Q{\ufffds\ufffdk Fy{/Fn uot.]zt\ufffdo~\ufffdt\ufffd\ufffd {qIk|o\nI{k\ufffd\ufffd. MNFUF\nZomot\ufffdon> Vm\ufffd{lo~ 53.534=\nFmmo|\ufffdon> Tk~ms 6.5353\nW\ufffdlwt\ufffdson> F|~tw 54.5353\nI{|\ufffd~trs\ufffd> \u00a95353 Jo\ufffdkt o\ufffdkw1\\st\ufffdt\ufffdkz{|oz\nkmmo\ufffd\ufffd k~\ufffdtmwo nt\ufffd\ufffd~tl\ufffd\ufffdon \ufffdzno~ \ufffdso\ufffdo~y\ufffd {q\ufffdso\nI~ok\ufffdt\ufffdo I{yy{z\ufffd F\ufffd\ufffd~tl\ufffd\ufffdt{z Stmoz\ufffdo. \ufffdstms\n|o~yt\ufffd\ufffd \ufffdz~o\ufffd\ufffd~tm\ufffdo n\ufffd\ufffdo.nt\ufffd\ufffd~tl\ufffd \ufffdt{z.kzn\n~o|~{n\ufffdm\ufffdt{z tzkz\ufffdyont\ufffdy. |~{\ufffdtnon \ufffdso{~trtzkw\nk\ufffd\ufffds{~ kzn\ufffd{\ufffd~mo k~om~ont\ufffdon1\nJk\ufffdk F\ufffdktwkltwt\ufffd \ufffd[\ufffdk\ufffdoyoz\ufffd> \\sonk\ufffdk\ufffdzno~w\ufffdtzr\n\ufffdso~o\ufffd\ufffdw\ufffd\ufffd |~o\ufffdoz\ufffdon tz\ufffdso\ufffd\ufffd\ufffdn\ufffd k~ok\ufffdktwklwo\nq~{y \ufffd\ufffd\ufffd1so kw\ufffdsyk|1{~r1\nL\ufffdzntzr> FUJ ~o|{~\ufffdon ~omot\ufffdtzr \ufffd\ufffd||{~\ufffd q~{y\nM~kz\ufffd U\ufffdylo~ \\65FO33;766 q~{y \ufffdsoUk\ufffdt{zkw\nOz\ufffd\ufffdt\ufffd\ufffd\ufffdo {qFwwo~r\ufffd kznOzqom\ufffdt{\ufffd \ufffdJt\ufffdok\ufffdo\ufffd. kznt\ufffd\ufffd\nm{z\ufffdoz\ufffd\ufffd k~o\ufffd{wow\ufffd \ufffdso~o\ufffd|{z\ufffdtltwt\ufffd \ufffd{q\ufffdsok\ufffd\ufffds{~\ufffd\nkznn{z{\ufffdzomo\ufffd\ufffdk~tw\ufffd ~o|~o\ufffdoz\ufffd \ufffdso{qqtmtkw \ufffdto\ufffd\ufffd\n{q\ufffdsoUON1 FUJ. GS.kznSIT ~o|{~\ufffdon ~omot\ufffdtzr\n\ufffd\ufffd||{~\ufffd q~{y \ufffdsoOz\ufffdo~zk\ufffdt{zk w[{mto\ufffd\ufffd q{~\nkzn:19& *6+{q~o|{~\ufffd\ufffd tzwoq\ufffd/wokztzr yontk. \ufffdstwo 6=14& *4<+ {q\ufffdsom{z\ufffd~{w r~{\ufffd| ~o|{~\ufffd\ufffd\n\ufffdo~o |\ufffdlwt\ufffdson tzwoq\ufffd/wokztzr yontk kzn431=& *9+tz~trs\ufffd/wokztzr yontk *|<1334+1 76&\n*53+ {qkww\ufffd\ufffd\ufffdn\ufffd ~o|{~\ufffd\ufffd \ufffdo~o |{\ufffd\ufffdon tz534:1 [oz\ufffdtyoz\ufffd kzkw\ufffd\ufffdt\ufffd ~o\ufffdokwon \ufffdsk\ufffd~trs\ufffd/wokztzr\n~o|{~\ufffd\ufffd {q\ufffdoz |{~\ufffd~k\ufffdon q{~otrz/l{~z |o~\ufffd{z\ufffd zork\ufffdt\ufffdow\ufffd1\nI{zmw\ufffd\ufffdt{z\nW~owtytzk~\ufffd nk\ufffdk q~{y \ufffdst\ufffd|tw{\ufffd \ufffd\ufffdrro\ufffd\ufffd \ufffdsk\ufffd|{wt\ufffdtmkw wokztzr yk\ufffd kqqom\ufffd ~o|{~\ufffdtzr {z\\Gtz\n][q{~otrz/l{~z |{|\ufffdwk\ufffdt{z \ufffd1Ztrs\ufffd/wokztzr zo\ufffd\ufffd {~rkzt\ufffdk\ufffdt{z\ufffd |~{n\ufffdmon \ufffdsoy{\ufffd\ufffd ~o|{~\ufffd\ufffd\n{z\\G.kzn\ufffdsoyku{~t\ufffd\ufffd {q\ufffdso\ufffdo ~o|{~\ufffd\ufffd |{~\ufffd~k\ufffdon q{~otrz/l{~z |o~\ufffd{z\ufffd zork\ufffdt\ufffdow\ufffd1 Ozknnt/\n\ufffdt{z. \ufffdsom{z\ufffd~{w r~{\ufffd| m{y|~t\ufffdon {qz{z/\\G. z{z/q{~otrz l{~z ~o|{~\ufffd\ufffd {zm{yy\ufffdztmklw ont\ufffd/\nok\ufffdo\ufffd qok\ufffd\ufffd~on kstrso~ |o~moz\ufffdkro {qwoq\ufffd/wokztzr zo\ufffd\ufffd {\ufffd\ufffdwo\ufffd\ufffd. \ufffd\ufffdrro\ufffd\ufffdtzr \ufffdsk\ufffd~o|{~\ufffdtzr\n{z\\Gtzq{~otrz/l{~z tznt\ufffdtn\ufffdkw\ufffd yk\ufffd lo{qr~ok\ufffdo~ tz\ufffdo~o\ufffd\ufffd \ufffd{~trs\ufffd/wokztzr {\ufffd\ufffdwo\ufffd\ufffd1 L\ufffd~\ufffdso~\ntz\ufffdo\ufffd\ufffdtrk\ufffdt{z l{\ufffds tz\ufffdso]1[1 kznrw{lkww\ufffd t\ufffdzoonon1\nOz\ufffd~{n\ufffdm\ufffdt{z\nTk\u20ac\u20ac yontk sk\u20ac\ufffdsokltwt\ufffd\u00de \ufffd{ty|km\ufffd |\ufffdlwtm |o~mo|\ufffdt{z\u20ac {qyontmtzo kzn nt\u20acok\u20aco |~{mo\u20ac\u20aco\u20ac d4f1\nMt\ufffdoz t\ufffd\u20ac\u00d0tno \u20acm{|o kzn \ufffdsotzm~ok\u20actzr k\ufffdktwkltwt\ufffd\u00de {qyontk \ufffds~{\ufffdrs \ufffdsontrt\ufffdkwt\u00fek\ufffdt{z {q\ufffdso\n|{|\ufffdwk~ |~o\u20ac\u20ac. {zwtzo zo\u00d0\u20ac ~o|{~\ufffd\u20ac sk\ufffdo lom{yo kzty|{~\ufffdkz\ufffd \u20ac{\ufffd~mo q{~|\ufffdlwtm sokw\ufffds mk~o\ntzq{~yk\ufffdt{z d5f1\\st\u20ac t\u20aco\u20ac|omtkww\u00de \u20actrztqtmkz\ufffd tz\ufffdso~o|{~\ufffdtzr {qm{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac.\n\u00d0so~o |{\u20act\ufffdt\ufffdo losk\ufffdt{~ mskzro\u02d8k\u20ac \u00d0oww k\u20acno\u20acoz\u20act\ufffdt\u00fek\ufffdt{z {~o\ufffdoz \u20ac\ufffdtryk\ufffdt\u00fek\ufffdt{z\u02d8tz \ufffdso\u20aco\ufffd\ufffdtzr\n{qkzo|tnoytm mkz{mm\ufffd~ d6.7f1\nI{zm\ufffd~~oz\ufffdw\u00de. yontk m{\ufffdo~kro {qtyytr~k\ufffdt{z tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac sk\u20aclom{yo tzm~ok\u20actzrw\u00de\n|~o\ufffdkwoz\ufffd tz\ufffdso\u20aco\ufffd\ufffdtzr {q|{wt\ufffdtmkw |{wk~t\u00fek\ufffdt{z k\u20ac\u00d0oww k\u20ac\ufffdso~t\u20aco{q\ufffdzo\u00d0 yontk\ufffd d9f1Zomoz\ufffd\n\u20ac\ufffd\ufffdnto\u20ac sk\ufffdo q{\ufffdzn \ufffdsk\ufffd \ufffdsoFyo~tmkz |\ufffdlwtm sk\u20aclom{yo tno{w{rtmkww\u00de m{z\u20act\u20ac\ufffdoz\ufffd kzn |k~\ufffdt\u20ackz\nd:f1\\st\u20ac qtzntzr t\u20ackw\u20ac{ ~oqwom\ufffdon tzyontk m{z\u20ac\ufffdy|\ufffdt{z |k\ufffd\ufffdo~z\u20ac lk\u20acon {z\u20acowq/tnoz\ufffdtqton |wkmo/\nyoz\ufffd kw{zr \ufffdsotno{w{rtmkw \u20ac|om\ufffd~\ufffdy d:f1\nW~t{~ \u20ac\ufffd\ufffdnto\u20ac sk\ufffdo o\u00f0kytzon \ufffdso~owk\ufffdt{z\u20acst|\u20ac lo\ufffd\u00d0ooz zo\u00d0\u20ac ~o|{~\ufffdtzr. |\ufffdlwtm |o~mo|\ufffdt{z.\nkzn m{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac d;\u02d843f1 N{\u00d0o\ufffdo~. z{zo \ufffd{{\ufffd~vz{\u00d0wonro sk\ufffdo tz\ufffdo\u20ac\ufffdtrk\ufffdon s{\u00d0\n|{wt\ufffdtmkw tno{w{r\u00de yk\u00de tzqw\ufffdozmo zo\u00d0\u20ac m{z\ufffdoz\ufffd k\u20act\ufffd|o~\ufffdktz\u20ac \ufffd{q{~otrz/l{~z tznt\ufffdtn\ufffdkw\u20ac1 \\so\nkty {q\ufffdst\u20ac|tw{\ufffd \u20ac\ufffd\ufffdn\u00de \u00d0k\u20ac\ufffd{o\u00f0kytzo \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz m{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac kzn\nq{~otrz/l{~z |o~\u20ac{z\u20ac k\u20ac|{~\ufffd~k\u00deon l\u00de\ufffdsoyk\u20ac\u20ac yontk1 \\\ufffdlo~m\ufffdw{\u20act\u20ac *\\G+ \u00d0k\u20acms{\u20acoz k\u20ackz\ntzno\u00f0 tzqom\ufffdt{\ufffd\u20ac |k\ufffds{roz k\u20act\ufffdt\u20ackzty|{~\ufffdkz\ufffd |\ufffdlwtm sokw\ufffds t\u20ac\u20ac\ufffdo \ufffdsk\ufffd t\u20ac{q\ufffdoz wtzvon \ufffd{q{~/\notrz/l{~z |o~\u20ac{z\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac d44f1 Fw\ufffds{\ufffdrs \ufffdsotzmtnozmo {q\\Gt\u20acqkwwtzr tz\ufffdso\n]zt\ufffdon [\ufffdk\ufffdo\u20ac. ;314& {qkww~o|{~\ufffdon \\Gmk\u20aco\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac tz534; {mm\ufffd~~on ky{zr\nz{z/]1[1/l{~z |o~\u20ac{z\u20ac d44.45f1 \\so yku{~t\ufffd\u00de {q\ufffdso\u20aco mk\u20aco\u20ac k~on\ufffdo\ufffd{~okm\ufffdt\ufffdk\ufffdt{z {qwk\ufffdoz\ufffd\n\\G?s{\u00d0o\ufffdo~ qkm\ufffd{~\u20ac \u20ac\ufffdms k\u20ackm\ufffdt\ufffdo {\ufffdo~\u20acok\u20ac \u20acm~ooztzr. ty|~{\ufffdon \u20ac\ufffd~\ufffdotwwkzmo. nomwtztzr y{~/\nltnt\ufffd\u00de. kzn mskzro\u20ac tznoy{r~k|stm\u20ac {q~omoz\ufffd oz\ufffd~kz\ufffd\u20ac yk\u00de lom{z\ufffd~tl\ufffd\ufffdtzr \ufffd{{\ufffdo~kww nom~ok\u20ac/\ntzrtzmtnozmo {q\\Gd46. 47f1 Jo\u20ac|t\ufffdo \ufffdst\u20ac. \\G~oyktz\u20ac kstrsw\u00de \u20ac\ufffdtryk\ufffdt\u00feon kzn {q\ufffdoz\nyt\u20ac\ufffdzno~\u20ac\ufffd{{n nt\u20acok\u20aco kzn \u00d0k\u20acms{\u20acoz q{~\ufffdst\u20ac|tw{\ufffd \u20ac\ufffd\ufffdn\u00de n\ufffdo\ufffd{\ufffdso\u20aco m~t\ufffdo~tk1\nTo\ufffds{n\ufffd\nJk\ufffdk \u20ac{\ufffd~mo\u20ac\nOz{~no~ \ufffd{o\ufffdkw\ufffdk\ufffdo yontk m{z\ufffdoz\ufffd ~owk\ufffdtzr q{~otrz/l{~z tznt\ufffdtn\ufffdkw\u20ac \ufffd{\\G.Nokw\ufffdsTk|\u02d8kz\ntz\ufffdo~zo\ufffd/lk\u20acon m{yy\ufffdztmklwo nt\u20acok\u20aco \u20ac\ufffd~\ufffdotwwkzmo \ufffd{{w \u00d0k\u20ac\ufffd\u20acon1 Nokw\ufffdsTk| \u00d0k\u20acq{\ufffdznon tz\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 5245Ozqom\ufffdt{\ufffd\ufffd Jt\ufffdok\ufffdo\ufffd *s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1t\ufffdtn1{~r2+1 \\so\nq\ufffdzno~\ufffd sknz{~{wotz\ufffd\ufffd\ufffdn\ufffd no\ufffdtrz. nk\ufffdkm{wwom\ufffdt{z\nkznkzkw\ufffd\ufffdt\ufffd. nomt\ufffdt{z \ufffd{|\ufffdlwt\ufffds {~|~o|k~k\ufffdt{z {q\n\ufffdsoykz\ufffd\ufffdm~t|\ufffd1\nI{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd >\\sok\ufffd\ufffds{~\ufffd sk\ufffdo nomwk~on\n\ufffdsk\ufffdz{m{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd o\ufffdt\ufffd\ufffd1\n533: kzn \ufffd\u20aco\u20ac {zwtzo. tzq{~ykw nk\ufffdk \u20ac{\ufffd~mo\u20ac \ufffd{|~{\ufffdtno m{z\ufffdtz\ufffd{\ufffd\u20ac nt\u20acok\u20aco {\ufffd\ufffdl~okv y{zt\ufffd{~/\ntzrd49. 4:f1 O\ufffdkrr~ork\ufffdo\u20ac nt\u20ac|k~k\ufffdo zo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac. {qqtmtkw ~o|{~\ufffd\u20ac. kzn o\u00f0|o~\ufffd/m\ufffd~k\ufffdon nt\u20acm\ufffd\u20ac/\n\u20act{z q{~\ufffdst\u20ac|\ufffd~|{\u20aco1 L{~\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de. \ufffdsoNokw\ufffdsTk| \u20acok~ms ozrtzo \u00d0k\u20ac}\ufffdo~ton q{~zo\u00d0\u20ac yontk\n~o|{~\ufffd\u20ac |o~\ufffdktztzr \ufffd{]1[1 {\ufffd\ufffdl~okv\u20ac \ufffdsk\ufffd m{z\ufffdktzon \ufffdso\ufffdo~y \ufffd\\G\ufffd {~\ufffd\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac\ufffd kzn \ufffdq{~/\notrz l{~z\ufffd. \ufffd~oq\ufffdroo*\u20ac+\ufffd {~\ufffdty*ytr~kz\ufffd\u20ac+\ufffd lo\ufffd\u00d0ooz Qkz\ufffdk~\u00de 5344 \ufffd{Q\ufffdzo 534=1 Vzw\u00de Kzrwt\u20acs\nwkzr\ufffdkro ~o|{~\ufffd\u20ac \u00d0o~o \u20acok~mson kzn tzmw\ufffdnon1 J\ufffd|wtmk\ufffdo ~om{~n\u20ac. z{z/s\ufffdykz mk\u20aco\u20ac. kzn\n~o|{~\ufffd\u20ac \u00d0t\ufffds{\ufffd\ufffd km\ufffdt\ufffdo ]ZS\u20ac \u00d0o~o o\u00f0mw\ufffdnon1 Vqz{\ufffdo. tq{zoo\ufffdoz\ufffd \u00d0k\u20ac~o|{~\ufffdon l\u00dey\ufffdw\ufffdt|wo\nyontk krozmto\u20ac. kww~owo\ufffdkz\ufffd ~o|{~\ufffd\u20ac \u00d0o~o ~o\ufffdktzon tz{~no~ \ufffd{m{y|k~o ~o|{~\ufffdtzr {z\\Gkzn\nq{~otrz/l{~z |o~\u20ac{z\u20ac lo\ufffd\u00d0ooz \ufffdk~t{\ufffd\u20ac yontk {\ufffd\ufffdwo\ufffd\u20ac1 Fzkw\u00de\u20ac\ufffd\u20ac ~o\ufffdto\u00d0on k\ufffd\ufffd{/|{|\ufffdwk\ufffdon qtown\u20ac\nkzn kyoznon q{~\u20ac\ufffd\u00dewo kmm{~ntzrw\u00de1\nJk\ufffdk o\u00f0\ufffd~km\ufffdt{z\nKkms ~o|{~\ufffd \u00d0k\u20acykz\ufffdkww\u00de ~o\ufffdto\u00d0on l\u00de\ufffd\u00d0{tzno|oznoz\ufffd tz\ufffdo\u20ac\ufffdtrk\ufffd{~\u20ac *FUJ kzn [T[+1 Jk\ufffdk\n{zyontk \u20ac{\ufffd~mo. nk\ufffdo {q|\ufffdlwtmk\ufffdt{z. kzn m{zqt~yon mk\u20aco m{\ufffdz\ufffd\u20ac *t1o1. nt\u20acok\u20aco tzmtnozmo k\u20ac\n~o|{~\ufffdon l\u00de~ort{zkw sokw\ufffds no|k~\ufffdyoz\ufffd\u20ac+ \u00d0o~o o\u00f0\ufffd~km\ufffdon \u00d0so~o k\ufffdktwklwo *Ltr 4+1Tontk\n\u20ac{\ufffd~mo\u20ac q{~okms ~o|{~\ufffd \u00d0o~o ~k\ufffdon l\u00de\ufffd\ufffdtwt\u00fetzr \ufffd\u00d0{ntqqo~oz\ufffd yontk ltk\u20ac tzntmk\ufffd{~\u20ac> MediaBias-\nFactCheck1com \u00d0k\u20ac\ufffdsotzt\ufffdtkw ~k\ufffdtzr \u20ac\u00de\u20ac\ufffdoy \ufffd\u20acon1 Oq|{wt\ufffdtmkw wokztzr \u00d0k\u20ac\ufffdzk\ufffdktwklwo. k\u20acom{zn\ntzntmk\ufffd{~. AllSides1com. \u00d0k\u20ack||wton d4;.4<f1 G{\ufffds yontk ltk\u20ac tzntmk\ufffd{~\u20ac oy|w{\u00de ~k\ufffdtzr \u20ac\u00de\u20ac\ufffdoy\u20ac\n\ufffdsk\ufffd k~oq\ufffd~\ufffdso~ no\u20acm~tlon ow\u20aco\u00d0so~o tzkzk\ufffd\ufffdoy|\ufffd \ufffd{mk\ufffdor{~t\u00feo |{\ufffdoz\ufffdtkw |{wt\ufffdtmkw wokztzr\nd4;.4<f1 Zk\ufffdtzr\u20ac q{~okms yontk \u20ac{\ufffd~mo |o~\ufffdktztzr \ufffd{kztznt\ufffdtn\ufffdkw zo\u00d0\u20ac ~o|{~\ufffd \u00d0o~o nowtzok\ufffdon\nkw{zr k\u20ac|om\ufffd~\ufffdy msk~km\ufffdo~t\u00fetzr |{wt\ufffdtmkw wokztzr. ~kzrtzr q~{y ~trs\ufffd. moz\ufffdo~. \ufffd{woq\ufffd1]\u20actzr\nMediaBiasFactCheck1com kznAllSides1com noqtzt\ufffdt{z\u20ac. ~trs\ufffd/wokztzr |{wt\ufffdtmkw ltk\u20ac \u00d0k\u20acmsk~km/\n\ufffdo~t\u00feon k\u20acknso~tzr \ufffd{\ufffdm{z\u20aco~\ufffdk\ufffdt\ufffdo\ufffd \ufffdkw\ufffdo\u20ac kzn |stw{\u20ac{|sto\u20ac \u00d0so~ok\u20ac woq\ufffd/wokztzr |{wt\ufffdtmkw ltk\u20ac\n\u00d0k\u20acnoqtzon k\u20ac\ufffdwtlo~kw\ufffd \ufffdkw\ufffdo\u20ac kzn |{wt\ufffdtmkw \ufffds{\ufffdrs\ufffd1 W~{/\u20acmtozmo \u00d0k\u20ac\ufffd\u20acon \ufffd{tzntmk\ufffdo qkm\ufffd\ufffdkw\n{~o\ufffdtnozmo/lk\u20acon ~o|{~\ufffd\u20ac. kzn moz\ufffdo~ tzntmk\ufffdon \ufffdsk\ufffd z{{l\ufffdt{\ufffd\u20ac ~trs\ufffd/ {~woq\ufffd/wokztzr \u20ac\ufffdk\ufffdo/\nyoz\ufffd\u20ac \u00d0o~o |~o\u20acoz\ufffd1 L{~|~o\u20acoz\ufffdk\ufffdt{z |\ufffd~|{\u20aco\u20ac. |~{/\u20acmtozmo kzn moz\ufffdo~ ~o|{~\ufffd\u20ac \u00d0o~o mk\ufffdor{/\n~t\u00feon \ufffd{ro\ufffdso~ tz\ufffdst\u20ackzkw\u00de\u20act\u20ac1 \\st\u20ac t\u20actzwtzo\u00d0t\ufffds \ufffdso\u20ac|om\ufffd~\ufffdy {q|{wt\ufffdtmkw tno{w{r\u00de k\u20ac\nrozo~kww\u00de mwk\u20ac\u20actqton tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac |{|\ufffdwk~ yontk d4=f1 L{~\ufffdso|\ufffd~|{\u20aco\u20ac {q\ufffdst\u20ackzkw\u00de\u20act\u20ac.\nwoq\ufffdkzn woq\ufffd/moz\ufffdo~ ltk\u20ac \u00d0k\u20acmsk~km\ufffdo~t\u00feon k\u20acwoq\ufffd/wokztzr. kzn ~trs\ufffd kzn ~trs\ufffd/moz\ufffdo~ ltk\u20ac \u00d0o~o\nmsk~km\ufffdo~t\u00feon k\u20ac~trs\ufffd/wokztzr1 Tontk {\ufffd\ufffdwo\ufffd\u20ac q{~\u00d0stms |{wt\ufffdtmkw ltk\u20ac m{\ufffdwn z{\ufffdlok\u20acmo~\ufffdktzon\nq~{y ot\ufffdso~ ltk\u20ac tzntmk\ufffd{~ \u00d0o~o ~o\ufffdktzon tz\ufffdsoqtzkw kzkw\u00de\u20act\u20ac kzn msk~km\ufffdo~t\u00feon k\u20ac\ufffd\ufffdzvz{\u00d0z1\ufffd\nOz\ufffdo~zo\ufffd/lk\u20acon. \ufffd{|tm/\u20ac|omtqtm zo\u00d0\u20ac krr~ork\ufffd{~\u20ac tzmw\ufffdnon tz\ufffdsoNokw\ufffdsTk| nk\ufffdk\u20aco\ufffd \u00d0o~o ~k\ufffdon\nk\u20acmoz\ufffdo~/wokztzr rt\ufffdoz \ufffdsk\ufffd \ufffdso|\ufffd~|{\u20aco {q\ufffdso\u20aco \u00d0ol\u20act\ufffdo\u20ac t\u20ac\ufffd{krr~ork\ufffdo m{z\ufffdoz\ufffd q~{y kww\n{zwtzo zo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac1\nF~kzn{y z\ufffdylo~ rozo~k\ufffd{~ \u00d0k\u20ac\ufffd\u20acon \ufffd{o\u00f0\ufffd~km\ufffd z{z/\\G. z{z/q{~otrz/l{~z k\u20ac\u20ac{mtk\ufffdon\nm{yy\ufffdztmklwo nt\u20acok\u20aco ~o|{~\ufffd\u20ac q~{y \ufffdsoNokw\ufffdsTk| \u20acok~ms ozrtzo \ufffd{km\ufffdk\u20ackm{z\ufffd~{w1 F\u20acowom\ufffd\nr~{\ufffd| {q{\ufffdso~ m{yy\ufffdztmklwo tzqom\ufffdt{z\u20ac k\u20acwt\u20ac\ufffdon low{\u00d0 \u00d0o~o \ufffdso|~tyk~\u00de \u20acky|wo \ufffd\u20acon k\u20ack\nm{z\ufffd~{w \ufffd{yk\ufffdms |o~mo|\ufffdt{z {qm{z\ufffdkrt{\ufffd\u20aczo\u20ac\u20ac kzn \u20aco\ufffdo~t\ufffd\u00de {q\\Gtz{~no~ \ufffd{ytztyt\u00feo m{z/\nq{\ufffdzntzr1 V\ufffdso~ m{yy\ufffdztmklwo tzqom\ufffdt{z\u20ac \u00d0o~o noqtzon k\u20ac\ufffdsoq{ww{\u00d0tzr> I~\u00de|\ufffd{m{mm\ufffd\u20ac. m~\u00de|/\n\ufffd{\u20ac|{~tnt\ufffdy. m\u00de\ufffd{yorkw{\ufffdt~\ufffd\u20ac. so~|o\u20ac \u20acty|wo\u00f0. |zo\ufffdy{ztk. |zo\ufffdy{m{mmkw |zo\ufffdy{ztk.\n\u20ackwy{zowwk. kzn \ufffd{\u00f0{|wk\u20acy{\u20act\u20ac1\n[oz\ufffdtyoz\ufffd kzkw\u00de\u20act\u20ac\n\\\u00d0{ ~o\ufffdto\u00d0o~\u20ac *FUJ kzn [T[+ \u20ac\u00de\u20ac\ufffdoyk\ufffdtmkww\u00de ~k\ufffdon {zwtzo zo\u00d0\u20ac ~o|{~\ufffd\u20ac ~o\ufffdktzon tz\ufffdsoqtzkw\n\u20ac\ufffd\ufffdn\u00de \u20acky|wo \ufffd{}\ufffdkwt\ufffdk\ufffdt\ufffdow\u00de k\u20ac\u20aco\u20ac\u20ac \u20acoz\ufffdtyoz\ufffd *o1r1. wkzr\ufffdkro kzn \ufffd{zo. kw\u20ac{ ~oqo~~on \ufffd{k\u20ac\n\ufffdkqqom\ufffd\ufffd+ tz\ufffdsosoknwtzo\u20ac kzn \ufffdo\u00f0\ufffd{qokms ~o|{~\ufffd1 Fqqom\ufffd ~k\ufffdtzr\u20ac \u00d0o~o mk\ufffdor{~t\u00feon k\u20ac|{\u20act\ufffdt\ufffdo.\nzork\ufffdt\ufffdo. {~zo\ufffd\ufffd~kw1 Ik\ufffdor{~to\u20ac \u00d0o~o noqtzonapriori k\u20acq{ww{\u00d0\u20ac> F~o|{~\ufffd \u00d0k\u20ac~k\ufffdon k\u20ac|{\u20ac\u20aco\u20ac\u20ac/\ntzrkzork\ufffdt\ufffdo kqqom\ufffd tqyt\u20acwokntzr {~tzqwk\ufffdon nt\u20acok\u20aco l\ufffd~noz\u20ac \u00d0o~o |~o\u20acoz\ufffdon. tqzork\ufffdt\ufffdo\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 6245\nLtr41Zo|{~\ufffd m{wwom\ufffdt {zkzn nk\ufffdk oz\ufffd~\u00de1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13563=:;1r33 4\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 7245\n~oyk~v\u20ac \u00d0o~o ykno ~ork~ntzr q{~otrz/l{~z |{|\ufffdwk\ufffdt{z\u20ac. {~tqkmkwwq{~y{~o \u20ac\ufffd~tzroz\ufffd |{wtmto\u20ac\n{ztyytr~k\ufffdt{z. k\u20ac\u00dew\ufffdy \u20acoovo~\u20ac. {~|~{\ufffdt\u20act{z {q|\ufffdlwtm \u20aco~\ufffdtmo\u20ac \ufffd{q{~otrz/l{~z |{|\ufffdwk\ufffdt{z\u20ac\n\u00d0k\u20acykno1 F~o|{~\ufffd \u00d0k\u20acm{z\u20actno~on \ufffd{sk\ufffdo k|{\u20act\ufffdt\ufffdo kqqom\ufffd tq\ufffdso~o \u00d0k\u20acyoz\ufffdt{z {q{~k~om{y/\nyoznk\ufffdt{z q{~|\ufffdlwtm sokw\ufffds ty|~{\ufffdoyoz\ufffd\u20ac1 Zo|{~\ufffd\u20ac \u00d0o~o no\ufffdo~ytzon \ufffd{lozo\ufffd\ufffd~kw tq\ufffdso\u00de |~{/\n\ufffdtnon tzq{~yk\ufffdt{z {z\ufffdsotzmtnozmo {~|~o\ufffdkwozmo {q\ufffdsont\u20acok\u20aco. \u00d0t\ufffds z{q\ufffd~\ufffdso~\n~om{yyoznk\ufffdt{z\u20ac {~mkww\u20ac q{~km\ufffdt{z1 Oz\ufffdo~/~k\ufffdo~ ~owtkltwt\ufffd\u00de tz\u20acoz\ufffdtyoz\ufffd kqqom\ufffd mwk\u20ac\u20actqtmk\ufffdt{z\n\u00d0k\u20acno\ufffdo~ytzon \ufffd\u20actzr I{soz)\u20ac \u03ba.q{ww{\u00d0tzr tzt\ufffdtkw mkwtl~k\ufffdt{z tz\u00d0stms okms ~o\ufffdto\u00d0o~ tzno|oz/\nnoz\ufffdw\u00de ~k\ufffdon k\u20acky|wo {q53~o|{~\ufffd\u20ac *43okms {q\ufffdso\u20ac\ufffd\ufffdn\u00de kzn m{z\ufffd~{w nk\ufffdk\u20aco\ufffd\u20ac+1 Oz\ufffdsoqtzkw kzkw/\n\u00de\u20act\u20ac. mk\u20aco\u20ac \u00d0so~o knt\u20ackr~ooyoz\ufffd lo\ufffd\u00d0ooz ~o\ufffdto\u00d0o~\u20ac ~ork~ntzr \u20acoz\ufffdtyoz\ufffd mwk\u20ac\u20actqtmk\ufffdt{z {qk\n|k~\ufffdtm\ufffdwk~ ~o|{~\ufffd {mm\ufffd~~on. nt\u20acm\ufffd\u20ac\u20act{z kzn ~om{zmtwtk\ufffdt{z \ufffd{{v |wkmo lo\ufffd\u00d0ooz ~o\ufffdto\u00d0o~\u20ac \ufffd{tnoz/\n\ufffdtq\u00dek\ufffdztqton ~k\ufffdtzr1 Ozmtnozmo kzn |~o\ufffdkwozmo nk\ufffdk |~o\u20acoz\ufffdon tzokms zo\u00d0\u20ac ~o|{~\ufffd \u00d0o~o tzno/\n|oznoz\ufffdw\u00de \ufffdo~tqton krktz\u20ac\ufffd {qqtmtkw nk\ufffdk \u20ac{\ufffd~mo\u20ac tzmw\ufffdntzr \ufffdso]1[1 Ioz\ufffdo~\u20ac q{~Jt\u20acok\u20aco I{z\ufffd~{w\nkzn ~ort{zkw |\ufffdlwtm sokw\ufffds no|k~\ufffdyoz\ufffd\u20ac \u00d0soz k||wtmklwo1 \\so \u20ac\ufffd\ufffdn\u00de kzkw\u00de\u00feon |\ufffdlwtmw\u00de k\ufffdktwklwo\nnk\ufffdk kzn z{tznt\ufffdtn\ufffdkw s\ufffdykz \u20ac\ufffdluom\ufffd\u20ac \u00d0o~o tz\ufffd{w\ufffdon1\nJk\ufffdk kzkw\u00de\u20act\u20ac\nY\ufffdkz\ufffdt\ufffdk\ufffdt\ufffdo kzkw\u00de\u20act\u20ac \ufffd\u20actzr no\u20acm~t|\ufffdt\ufffdo \u20ac\ufffdk\ufffdt\u20ac\ufffdtm\u20ac \u00d0k\u20acm{zn\ufffdm\ufffdon \ufffd\ufffdtwt\u00fetzr Ttm~{\u20ac{q\ufffd K\u00f0mow3kzn\n[\ufffdk\ufffdk *\ufffdo~\u20act{z 4614? [\ufffdk\ufffdkI{~| SW+1 F\u03c75/\u20ac}\ufffdk~on \ufffdo\u20ac\ufffd{qtzno|oznozmo \u00d0k\u20ac|o~q{~yon \ufffd{k\u20ac\u20aco\u20ac\u20ac\nntqqo~ozmo\u20ac tz|{wt\ufffdtmkw wokztzr ky{zr \ufffdsoyontk \u20ac{\ufffd~mo\u20ac \ufffdsk\ufffd ~o|{~\ufffdon {z\u20ac\ufffd\ufffdn\u00de mk\u20aco\u20ac \ufffdo~\u20ac\ufffd\u20ac\nm{z\ufffd~{w\u20ac1 Fzkw|sk wo\ufffdow {qwo\u20ac\u20ac\ufffdskz {~o}\ufffdkw \ufffd{139\u00d0k\u20acm{z\u20actno~on \u20ac\ufffdk\ufffdt\u20ac\ufffdtmkww\u00de \u20actrztqtmkz\ufffd1\nZo\ufffd\ufffdw\ufffd\ufffd\nL~{y Qkz\ufffdk~\u00de 4.5344. \ufffd{Qkz\ufffdk~\u00de 4.534=. \ufffdso~o \u00d0o~o 91:66 ytwwt{z kwo~\ufffd\u20ac m{wwom\ufffdon l\u00de\ufffdso\nNokw\ufffdsTk| \u20ac\u00de\u20ac\ufffdoy1 <=4~o|{~\ufffd\u20ac tz\ufffd{w\ufffdtzr \ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac kzn \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac \u00d0o~o o\u00f0\ufffd~km\ufffdon\nq~{y \ufffdsoNokw\ufffdsTk| nk\ufffdklk\u20aco n\ufffd~tzr \ufffdst\u20ac\ufffdtyo |o~t{n1 L{~\ufffd\u00de/\u20act\u00f0 {q\ufffdso\u20aco ~o|{~\ufffd\u20ac tz\ufffd{w\ufffdon q{~/\notrz/l{~z tznt\ufffdtn\ufffdkw\u20ac1 L{~\ufffd\u00de/\u20act\u00f0 ~o|{~\ufffd\u20ac {l\ufffdktzon q~{y Nokw\ufffdsTk| \u00d0o~o kw\u20ac{ o\u00f0\ufffd~km\ufffdon \u20acty\ufffdw/\n\ufffdkzo{\ufffd\u20acw\u00de \ufffd{km\ufffdk\u20ackm{z\ufffd~{w r~{\ufffd|1 U{~o|{~\ufffd\u20ac tz\ufffd{w\ufffdtzr \\Gkzn q{~otrz/l{~z tznt\ufffdtn\ufffdkw\u20ac\n\u00d0o~o |\ufffdlwt\u20acson q~{y 5344 \ufffd{53461 L~{y 5347 \ufffd{534=. kzk\ufffdo~kro {qqt\ufffdo~o|{~\ufffd\u20ac tz\ufffd{w\ufffdtzr\n\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac kzn q{~otrz/l{~z tznt\ufffdtn\ufffdkw\u20ac \u00d0o~o |\ufffdlwt\u20acson |o~\u00deok~1 76& *53+ {qkwwyontk\n~o|{~\ufffd\u20ac o\ufffdkw\ufffdk\ufffdon {\ufffdo~ \ufffdsom{\ufffd~\u20aco {q\ufffdst\u20ac|tw{\ufffd \u20ac\ufffd\ufffdn\u00de \u00d0o~o |\ufffdlwt\u20acson tz534: *Ltr 5+1\\s~oo\n~o|{~\ufffd\u20ac \u00d0o~o o\u00f0\ufffd~km\ufffdon q~{y z{z/]1[1 {~]1[1 \u20ac\ufffdl\u20actntk~\u00de {\ufffd\ufffdwo\ufffd\u20ac1 \\so\u20aco \u00d0o~o ~o\ufffdktzon kzn\ntzmw\ufffdnon tz\ufffdsoqtzkw m{s{~\ufffd k\u20ac\ufffdso\u00de |o~\ufffdktzon \ufffd{]1[1 \\G{\ufffd\ufffdl~okv\u20ac. kzn z{knnt\ufffdt{zkw ~o|{~\ufffd\u20ac\no\u00f0\ufffd~km\ufffdon q~{y \ufffdsotzt\ufffdtkw \u20acok~ms \ufffdsk\ufffd |o~\ufffdktzon \ufffd{\\Gkzn q{~otrz/l{~z |o~\u20ac{z\u20ac low{zron \ufffd{\nz{z/]1[1 yontk \u20ac{\ufffd~mo\u20ac1\nTontk \u20ac{\ufffd~mo\u20ac m{~~o\u20ac|{zntzr \ufffd{okms {q\ufffdsozo\u00d0\u20ac ~o|{~\ufffd\u20ac \u00d0o~o tznt\ufffdtn\ufffdkww\u00de mk\ufffdor{~t\u00feon l\u00de\n|{wt\ufffdtmkw wokztzr \ufffd\u20actzrMediaBiasFactCheck1com kznAllSides1com1 U{nt\u20ackr~ooyoz\ufffd\u20ac {mm\ufffd~~on\nlo\ufffd\u00d0ooz yontk ltk\u20ac tzntmk\ufffd{~\u20ac1 \\klwo 4\u20acs{\u00d0\u20ac \ufffdso~o|{~\ufffd m{\ufffdz\ufffd mk\ufffdor{~t\u00feon l\u00de|{wt\ufffdtmkw wokztzr\nq{~\\Gkzn q{~otrz/l{~z ~o|{~\ufffd\u20ac k\u20ac\u00d0oww k\u20acq{~\ufffdsom{z\ufffd~{w r~{\ufffd|1 I{y|k~on \ufffd{\ufffdsot~ m{z\ufffd~{w\nm{\ufffdz\ufffdo~|k~\ufffd\u20ac. yontk \u20ac{\ufffd~mo\u20ac ~o|{~\ufffdtzr {z\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac ky{zr q{~otrz/l{~z |{|\ufffdwk\ufffdt{z\u20ac tz\ufffdso\n]zt\ufffdon [\ufffdk\ufffdo\u20ac \u00d0o~o q{\ufffdzn \ufffd{loy{~o wtvow\u00de \ufffd{lo~trs\ufffd/wokztzr *:31=& \ufffd\u20ac1431=&+. kzn wo\u20ac\u20acwtvow\u00de\n\ufffd{lomoz\ufffdo~2|~{/\u20acmtozmo *:19& \ufffd\u20ac16=14&+ {~woq\ufffd/wokztzr *4915& \ufffd\u20ac1671<&+1 F\u00f05\ufffdo\u20ac\ufffd{qtzno/\n|oznozmo noy{z\u20ac\ufffd~k\ufffdon \ufffdsk\ufffd ~o|{~\ufffdtzr {z\\Gkzn q{~otrz/l{~z |{|\ufffdwk\ufffdt{z\u20ac tz\ufffdso][\u00d0k\u20ac\nk\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds yontk |{wt\ufffdtmkw wokztzr *|D1334+1 Ltr6noy{z\u20ac\ufffd~k\ufffdo\u20ac |{wt\ufffdtmkw wokztzr q{~\\G\nkzn q{~otrz/l{~z ~o|{~\ufffd\u20ac l\u00de\u00deok~1\n[oz\ufffdtyoz\ufffd kzkw\u00de\u20act\u20ac \u00d0k\u20acm{zn\ufffdm\ufffdon {zokms tznt\ufffdtn\ufffdkw zo\u00d0\u20ac ~o|{~\ufffd \ufffd{o\ufffdkw\ufffdk\ufffdo \u00d0so\ufffdso~ \ufffdso\nm{z\ufffdoz\ufffd {q~o|{~\ufffdtzr ~oqwom\ufffdon k|{\u20act\ufffdt\ufffdo. zork\ufffdt\ufffdo. {~zo\ufffd\ufffd~kw \ufffd{zo \ufffd{\u00d0k~n\u20ac q{~otrz/l{~z |{|\ufffd/\nwk\ufffdt{z\u20ac \u20ac|omtqtmkww\u00de1 \\klwo 5noy{z\u20ac\ufffd~k\ufffdo\u20ac \ufffdsont\u20ac\ufffd~tl\ufffd\ufffdt{z {q|{\u20act\ufffdt\ufffdo. zork\ufffdt\ufffdo. kzn zo\ufffd\ufffd~kw \u20acoz/\n\ufffdtyoz\ufffd |o~~o|{~\ufffd ~o\ufffdto\u00d0on1 \\klwo 6q\ufffd~\ufffdso~ nowtzok\ufffdo\u20ac \u20acoz\ufffdtyoz\ufffd nt\u20ac\ufffd~tl\ufffd\ufffdt{z \u00d0t\ufffds \ufffdsosoknwtzo\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 9245\nq{~okms k~\ufffdtmwo k\u20ac\u20aco\u20ac\u20acon kzn tz\ufffdo~/~k\ufffdo~ ~owtkltwt\ufffd\u00de1 Oz\ufffdo~/~k\ufffdo~ kr~ooyoz\ufffd tz\u20acoz\ufffdtyoz\ufffd mwk\u20ac\u20actqt/\nmk\ufffdt{z lk\u20acon {zmkwtl~k\ufffdt{z *I{soz)\u20ac vB31<;+ \u00d0k\u20acstrs1 \\st\u20ac kzkw\u00de\u20act\u20ac noy{z\u20ac\ufffd~k\ufffdon \ufffdsk\ufffd \ufffdso\nyku{~t\ufffd\u00de {q~trs\ufffd/wokztzr ~o|{~\ufffd\u20ac \u00d0o~o k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds kzork\ufffdt\ufffdo kqqom\ufffd. \u00d0stwo z{~trs\ufffd/wokztzr\n~o|{~\ufffd\u20ac \u00d0o~o k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds k|{\u20act\ufffdt\ufffdo kqqom\ufffd1 Zo|{~\ufffd\u20ac \ufffdsk\ufffd ~oqwom\ufffdon kzork\ufffdt\ufffdo kqqom\ufffd {q\ufffdoz nt\u20ac/\nm\ufffd\u20ac\u20acon wk\ufffdoz\ufffd kzn km\ufffdt\ufffdo \\Gtz\ufffdo~mskzroklw\u00de1 L{~o\u00f0ky|wo. {zo~o|{~\ufffd mwk\u20ac\u20actqton k\u20aczork\ufffdt\ufffdo kzn\n{~trtzk\ufffdtzr q~{y k~trs\ufffd/wokztzr zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd z{\ufffdon \ufffdsk\ufffd \ufffd444dkf\u20actrztqtmkz\ufffd |o~moz\ufffdkro {q~o\u20aco\ufffd/\n\ufffdwon~oq\ufffdroo\u20ac zo\ufffdo~ m{y|wo\ufffdo \ufffdsot~ sokw\ufffds \u20acm~ooztzr\u20ac. \u20ac{\ufffdso\u00de yk\u00de lo\u00d0kzno~tzr k~{\ufffdzn\n\ufffdz\ufffd~ok\ufffdon. q{~kz\u00de{qkz\ufffdylo~ {qnt\u20acok\u20aco\u20ac tzmw\ufffdntzr \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac4 44\ufffd\u00d0stwo ~oqo~ozmtzr wk\ufffdoz\ufffd\n\\Gmk\u20aco\u20ac d53f1 Uork\ufffdt\ufffdo ~o|{~\ufffd\u20ac kw\u20ac{ nt\u20acm\ufffd\u20ac\u20acon \\Gkzn q{~otrz/l{~z |o~\u20ac{z\u20ac tz\ufffdsom{z\ufffdo\u00f0\ufffd {q\n|{wtm\u00de kzn |{wt\ufffdtm\u20ac1 Vzo \u20ac\ufffdms ~o|{~\ufffd z{\ufffdon. \ufffdd\ufffdfso r{\ufffdo~zyoz\ufffd)\u20ac tzm~ok\u20acon tzqw{\u00d0 {q\ufffd\ufffdlo~m\ufffdw{/\n\u20act\u20ac/mk~~\u00detzr ytr~kz\ufffd\u20ac k||ok~\u20ac \ufffd{sk\ufffdo ~o\ufffdo~\u20acon k56/\u00deok~ nomwtzo {qm{z\ufffdkrt{\ufffd\u20ac \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac\nmk\u20aco\u20ac tz\u20actno \ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac1 \\so u\ufffdy| tzq{~otrz/l{~z mk\u20aco\u20ac q~{y 55|o~moz\ufffd tz4=<: \ufffd{::\n|o~moz\ufffd tz5349 t\u20acmk\ufffd\u20acon l\u00de\ufffdsoqono~kw r{\ufffdo~zyoz\ufffd)\u20ac |{wtm\u00de {qkmmo|\ufffdtzr y{~o \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac/\ntzqom\ufffdon ytr~kz\ufffd\u20ac q~{y m{\ufffdz\ufffd~to\u20ac \u00d0t\ufffds wk~ro/\u20acmkwo m{z\ufffdkrt{z\u20ac {q\ufffdsonoknw\u00de kzn noltwt\ufffdk\ufffdtzr nt\u20ac/\nok\u20aco d54f1\ufffd\nFmm\ufffd~km\u00de {q~o|{~\ufffdtzr m{z\ufffdoz\ufffd \u00d0k\u20ac\ufffdo~tqton l\u00dem{y|k~tzr mk\u20aco m{\ufffdz\ufffd\u20ac \u00d0t\ufffds \u20ac\ufffd~\ufffdotwwkzmo nk\ufffdk\nk\ufffdktwklwo \ufffds~{\ufffdrs \ufffdso]1[Ioz\ufffdo~\u20ac q{~Jt\u20acok\u20aco I{z\ufffd~{w d55f1 Ozknnt\ufffdt{z. ~ort{zkw |\ufffdlwtm sokw\ufffds\nLtr51\\\ufffdlo~m\ufffdw{\u20act \u20ackzn q{~otrz/ l{~z |o~\u20ac{z\u20ac ~o|{~\ufffd m{\ufffdz\ufffd l\u00de}\ufffdk~\ufffdo~1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13563=:;1r33 5\n\\klwo 41Zo|{~\ufffd m{\ufffdz\ufffd mk\ufffdor{~t\u00feon l\u00de|{wt\ufffdtmkw wokztzr1\n\\G\u2019L{~otrz/G{ ~zZo|{~\ufffd\ufffd. U*&+ I{z\ufffd~{w\ufffd. U*&+\nLeft-leaning 6*:19+ 4<*6=14+\nRight-leaning 5<*:31=+ 9*431=+\nCenter/Pro-Science ;*4915+ 4:*671<+\nUnknown <*4;17+ ;*4915+\nTotal 7:*433+ 7:*433+\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13563=:;1\ufffd33 4\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 :245\nno|k~\ufffdyoz\ufffd nk\ufffdk \u00d0k\u20ac\ufffd\u20acon. k\u20ac\ufffdst\u20actzq{~yk\ufffdt{z t\u20ack\ufffdktwklwo {zkm{\ufffdz\ufffd\u00de {~sokw\ufffds nt\u20ac\ufffd~tm\ufffd wo\ufffdow\ntz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac kzn krr~ork\ufffdon l\u00deNokw\ufffdsTk| d56f1 Oz9~o|{~\ufffd\u20ac. tznt\ufffdtn\ufffdkw wo\ufffdow {\ufffd\ufffdl~okv\nnk\ufffdk m{\ufffdwn z{\ufffdlo\ufffdkwtnk\ufffdon. s{\u00d0o\ufffdo~ kzz\ufffdkw |~o\ufffdkwozmo o\u20ac\ufffdtyk\ufffdo\u20ac q{~k\u20ac\ufffdk\ufffdo {~~ort{z \ufffdsk\ufffd\n\u00d0o~o kw\u20ac{ |~o\u20acoz\ufffdon tz\ufffdso\u20aco ~o|{~\ufffd\u20ac \u00d0o~o \ufffdo~tqton1 Ik\u20aco m{\ufffdz\ufffd\u20ac \u00d0o~o kmm\ufffd~k\ufffdo q{~kww~o|{~\ufffd\u20ac\nm\ufffd~k\ufffdon tz\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de1\nJt\ufffdm\ufffd\ufffd\ufffdt{z\nI{yy\ufffdztmklwo nt\u20acok\u20aco ~o|{~\ufffdtzr sk\u20ack\ufffdzt}\ufffdo kzn l\ufffd~ro{ztzr ~owk\ufffdt{z\u20acst| \u00d0t\ufffds {zwtzo zo\u00d0\u20ac\n{\ufffd\ufffdwo\ufffd\u20ac1 \\st\u20ac \u20ac\ufffd\ufffdn\u00de o\u00f0kytzon \ufffdso|{\ufffdoz\ufffdtkw q{~ltk\u20ac lk\u20acon {z|{wt\ufffdtmkw tno{w{r\u00de tz\ufffdso~o|{~\ufffdtzr\n{q\ufffdsotzmtnozmo kzn |~o\ufffdkwozmo {q\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac ky{zr q{~otrz/l{~z |o~\u20ac{z\u20ac tz\ufffdso]zt\ufffdon\nLtr61\\G~o|{~\ufffd m{\ufffdz\ufffd mk\ufffdor{~t\u00feon l\u00de|{wt\ufffdtmkw wokztzr l\u00de\u00deok~1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13563=:;1r33 6\n\\klwo 51[oz\ufffdtyoz\ufffd mk\ufffdor{~t\u00fek \ufffdt{z l\u00dekqqom\ufffd kzn |{wt\ufffdtmkw wokztzr1\n[ W{\u20act\ufffdt\ufffd oFqqom\ufffd Uork\ufffdt\ufffd oFqqom\ufffd Uo\ufffd\ufffd~kw Fqqom\ufffd \\{\ufffdkw\nSoq\ufffd/wokztzr2S tlo~kw 4 4 4 6\nZtrs\ufffd/wokz tzr2I{z\u20aco~\ufffdk \ufffdt\ufffdo 3 55 : 5<\nIoz\ufffdo~2W~{ /[mtozmo 4 3 : ;\n]zvz{\u00d0z 3 3 < <\n\\{\ufffdkw 5 56 54 7:\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13563=:;1\ufffd335\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 ;245\n\\klwo 61[oz\ufffdtyoz\ufffd mk\ufffdor{~t \u00fek\ufffdt{z l\u00dek~\ufffdtmwo kzn ~k\ufffdo~1\nNoknwtzo Zk\ufffdo~ $4 Zk\ufffdo~ $5\n5mk\u20aco\u20ac {qkm\ufffdt\ufffdo \ufffd\ufffdlo~m\ufffd w{\u20act\u20ac q{\ufffdzn tzIoz\ufffd~kw Fyo~tmkz tyytr~kz\ufffd \u20acl~{\ufffdrs\ufffd \ufffd{KwWk\u20ac{ q{~\nmk\u20aco |~{mo\u20ac\u20actzrUork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nN{\ufffd\u20ac\ufffd{z oqq{~\ufffd\u20ac vo\u00de\ufffd{ozntzr \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac tz][ W{\u20act\ufffdt\ufffdo W{\u20act\ufffdt\ufffdo\n][\u0152I{w {~kn{> \\\ufffdlo~m\ufffd w{\u20act\u20ac mk\u20aco k\ufffdF\ufffd~{~k OIK qkmtwt\ufffd\u00de Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n55Wo~moz\ufffd {qZo\u20aco\ufffd\ufffdwon Zoq\ufffdroo\u20ac tzTtzzo\u20ac {\ufffdk\\o\u20ac\ufffd W{\u20act\ufffdt\ufffdo q{~\\\ufffdlo~m\ufffdw{\u20act \u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nF~t\u00fe{zk> T{\u20ac\ufffd {q[\ufffdk\ufffdo)\u20ac 555Fm\ufffdt\ufffdo \\GIk\u20aco\u20ac Fy{zr Zoq\ufffdroo\u20ac )Ik\ufffd\u20acon l\u00deSk\ufffdoz\ufffd \\\ufffdlo~m\ufffd w{\u20act\u20ac\nOzqom\ufffdt{z\u20ac )Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n_{~vo~\u20ac k\ufffd5Ttzzo\u20ac{ \ufffdkN{\u20ac|t\ufffdkw\u20ac Jtkrz{\u20aco n\u00d0t\ufffds Fm\ufffdt\ufffdo \\G Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n][\\\ufffdlo~m\ufffd w{\u20act\u20ac Ik\u20aco\u20ac Zt\u20aco k\u20acL{~otrz/G{~ zWk\ufffdtoz\ufffd\u20ac \\~t|wo 4=<: Ik\u20acow{kn Wo~moz\ufffdkro Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nZoq\ufffdroo\u20ac n{\ufffdlwo \\Gmk\u20aco\u20ac tz\\o\u00f0k\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n^o~y{z\ufffd Nokw\ufffds Jo|k~\ufffdyoz \ufffdm{zmokwtzr z\ufffdylo~ {q~oq\ufffdroo\u20ac \u00d0t\ufffds m{z\ufffdkrt{\ufffd\u20ac \\G Uo\ufffd\ufffd~kw\ufffdUork\ufffdt\ufffdo\n[o\ufffdoz ~oq\ufffdroo\u20ac tzOnks{ )sk\ufffdo looz ntkrz{\u20acon \u00d0t\ufffds km\ufffdt\ufffdo \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac) Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n\\s~oo Zoq\ufffdroo\u20ac Jtkrz{\u20aco n_t\ufffds Fm\ufffdt\ufffdo \\Gtz^o~y{z\ufffd V\ufffdo~ Wk\u20ac\ufffd [o\ufffdoz T{z\ufffds\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n^o~y{z\ufffd Fnyt\ufffd\u20ac [o\ufffdoz\ufffdooz Zoq\ufffdroo\u20ac Jtkrz{\u20acon _t\ufffds Fm\ufffdt\ufffdo \\G Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n[t\u00f0Zoq\ufffdroo \u20actz_t\u20acm{z\u20actz Jtkrz{\u20acon \u00d0t\ufffds T\ufffdw\ufffdt/J~\ufffdr Zo\u20act\u20ac\ufffdkz\ufffd \\G[tzmo 5347 Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n\\s~oo L{~otrz/G{~z Ik\u20aco\u20ac {qT\ufffdw\ufffdt/J~\ufffd rZo\u20act\u20ac\ufffdkz\ufffd \\GtzUk\u20acs\ufffdtwwo. \\ozzo \u20ac\u20acoo Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nKwo\ufffdoz Zoq\ufffdroo\u20ac Jtkrz{\u20aco n_t\ufffds Fm\ufffdt\ufffdo \\\ufffdlo~m\ufffd w{\u20act\u20ac F~{\ufffdzn Fv~{z. Vst{ Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nLt\ufffdo L{~otrz/ G{~z Ik\u20aco\u20ac {qT\ufffdw\ufffdt/J~\ufffdr Zo\u20act\u20ac\ufffdkz\ufffd \\GJtkrz{\u20acon tzWstwknow|stk Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n\\\u00d0oz\ufffd\u00de/ Vzo Zoq\ufffdroo\u20ac Jtkrz{\u20aco n\u00d0t\ufffds Fm\ufffdt\ufffdo \\GtzUol~k\u20acvk Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n\\\ufffdlo~m\ufffd w{\u20act\u20ac [\ufffd~qkmo\u20ac k\ufffd\\o\u00f0k\u20ac Ntrs [ms{{w Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n5=:Zoq\ufffdroo\u20ac Jtkrz{\u20aco n\u00d0t\ufffds Fm\ufffdt\ufffdo \\GtzTtzzo\u20ac {\ufffdk.\\oz \\tyo\u20ac Fz\u00de V\ufffdso~ [\ufffdk\ufffdo? Tku{~t\ufffd\u00de\nF~o[{ykwt\u20acUork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nTU Zoq\ufffdroo \\GOzqom\ufffdt{z\u20ac F~o\\oz \\tyo\u20ac Ntrso~ \\skz V\ufffdso~ [\ufffdk\ufffdo\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nOzrsky I{\ufffdz\ufffd\u00de. Ttmstrkz> Vzo Zoq\ufffdroo Jtkrz{\u20aco n_t\ufffds T\ufffdw\ufffdt/J~\ufffdr Zo\u20act\u20ac\ufffdkz\ufffd \\G?55\nWo~moz\ufffd Nk\ufffdo Sk\ufffdoz\ufffd \\GUork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nOwwtz{t\u20ac I{zqt~y\u20ac Ktrs\ufffd Zoq\ufffdroo\u20ac Jtkrz{\u20acon \u00d0t\ufffds Fm\ufffdt\ufffdo \\G]|{z F~~t\ufffdkw Uo\ufffd\ufffd~kw\ufffdUork\ufffdt\ufffdo\nFz{\ufffdso~ Ik\u20aco {qFm\ufffdt\ufffdo \\GJtkrz{\u20acon tzNozzo|tz I{\ufffdz\ufffd\u00de. Ttzzo\u20ac{\ufffdk [ms{{w\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nT{~o \ufffdskz =333 Wo{|wo tz\ufffdso][M{\ufffd \\\ufffdlo~m\ufffdw{\u20act \u20acSk\u20ac\ufffd bok~1 _s{ _o~o \\so\u00deD Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nWkztm k\u20ac\\Gt\u20ac{z\ufffdso~t\u20acotzUo\u00d0 b{~v q{~\ufffdsoqt~\u20ac\ufffd \ufffdtyo \u20actzmo \ufffdso4==3\u20ac Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nLk~r{ It\ufffd\u00de I{yyt\u20ac\u20act{zo~ kmm\ufffd\u20acon S\ufffd\ufffdso~kz [{mtkw [o~\ufffdtmo\u20ac {qstntzr \ufffd\ufffdlo~m\ufffd w{\u20act\u20ac ~t\u20acv? ykvo\u20ac\ny{\ufffdt{z \ufffd{\u20ac\ufffd{| ~oq\ufffdroo tzqw{\u00d0 tz\ufffd{ Lk~r{Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n\ufffdI~t\u20act\u20ac\ufffd {q[o~t{\ufffd\u20acw\u00de OwwTtr~kz\ufffd\u20ac [wky\u20ac G{~no~ Wk\ufffd~{w/\\G. Wzo\ufffdy{ztk .Ozqw\ufffdoz\u00fek Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nM{\ufffdo~zy oz\ufffdZowok\u20actzr [tmv Owworkw\u20ac tzFyo~tmkz I{yy\ufffdzt\ufffd to\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\nWozz\u20ac\u00dew\ufffdk ztkI{zr~o\u20ac\u20acy kzQ{sz Q{\u00demo \ufffdkvo\u20ac lkmv mwkty\u20ac {q\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac/ tzqom\ufffdon ytr~kz\ufffd\u20ac\nm~{\u20ac\u20actzr l{~no~Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nG{~no~ Wk\ufffd~{w Vqqtmtkw> Ioz\ufffd~kw Fyo~tmkz\u20ac Kz\ufffdo~tzr ][_t\ufffds I{z\ufffdkrt{\ufffd\u20ac Nokw\ufffds I{znt\ufffdt{z\u20ac Uork\ufffdt\ufffdo Uork\ufffdt\ufffdo\n_stwo Zo|\ufffdlwtmk z\u20ac\ufffdt\u20act\ufffdon b\ufffdyk. kl{r\ufffd\u20ac \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac \u20acmk~o {z\ufffdsol{~no~ Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nWZV2KJZF \\\ufffdlo~m\ufffd w{\u20act\u20ac. TJZ\u0152] [F>*TU+ qk\ufffdkw. Ny{zr. \u20acozt{~ moz\ufffdo~ Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nWZV2FN 2KJZF \\\ufffdlo~m\ufffd w{\u20act\u20ac\u0152][F >mstwn~oz. q{~otrz/l{~z |k~oz\ufffd\u20ac Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n\\\ufffdlo~m\ufffd w{\u20act\u20ac [oo\u20ac Gtrro\u20ac\ufffd Ozm~ok\u20aco OzUbI [tzmo 4==5 Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nSk\ufffdoz\ufffd \\G\ufffdo\u20ac\ufffdtzr. \ufffd~ok\ufffdyoz\ufffd m{\u20ac\ufffd/oqqom\ufffd t\ufffdoq{~z{z/][ l{~z ~o\u20actnoz\ufffd\u20ac tzy{\u20ac\ufffd mk\u20aco\u20ac Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n\\~ozn\u20ac tz\\\ufffdlo~m\ufffdw{\u20act \u20ac/]zt\ufffdon [\ufffdk\ufffdo\u20ac. 5346 Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nUbI \\\ufffdlo~m\ufffdw{\u20act \u20acIk\u20aco\u20ac Fy{z rOyytr~ kz\ufffd\u20ac I{z\ufffdtz\ufffdo \ufffd{Zt\u20aco Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nOy|woyo z\ufffdk\ufffdt{z {qUo\u00d0 \\G[m~ooztzr Zo}\ufffdt~oyo z\ufffd\u20acq{~]1[1/G{\ufffdzn Oyytr~kz\ufffd\u20ac kzn\nZoq\ufffdroo\u20ac/5 33;/5347W{\u20act\ufffdt\ufffdo W{\u20act\ufffdt\ufffdo\nVwno~ Ny{zr Zo\u20actnoz\ufffd\u20ac Fqqom\ufffdon l\u00de\\\ufffdlo~m\ufffdw{\u20act \u20acV\ufffd\ufffdl~okv Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n[t\u00f0sk\ufffdo nton q~{y y\ufffdw\ufffdt/n~ \ufffdr/~o\u20act\u20ac\ufffdkz\ufffd \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac tzZky\u20aco\u00de I{\ufffdz\ufffd\u00de. {qqtmtkw\u20ac \u20ack\u00de Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n_s{wo/Moz {yo [o}\ufffdoz mtzr Onoz\ufffdtqto \u20acT\ufffdw\ufffdtn~\ufffdr/ Zo\u20act\u20ac\ufffdkz\ufffd \\\ufffdlo~m\ufffd w{\u20act\u20ac Fy{zr Zoq\ufffdroo \u20ac Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n5mk\u20aco\u20ac {qy\ufffdw\ufffdt/n ~\ufffdr~o\u20act\u20ac\ufffdkz\ufffd \\Gm{zqt~yon tzU{~\ufffdsok\u20ac\ufffd Mk1 Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n*Continued +\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 <245\n[\ufffdk\ufffdo\u20ac. kzn |{\ufffdoz\ufffdtkw q{~ltk\u20ac kw{zr tno{w{rtmkw \u20ac|om\ufffd~\ufffdy\u20ac ~oqwom\ufffdon tz{zwtzo zo\u00d0\u20ac ~o|{~\ufffd\u20ac\nm\ufffd~k\ufffdon \ufffds~{\ufffdrs \ufffdsoNokw\ufffdsTk| ntrt\ufffdkw nt\u20acok\u20aco no\ufffdom\ufffdt{z kzn yontk y{zt\ufffd{~tzr \u20ac\u00de\u20ac\ufffdoy1 \\st\u20ac\n\u20ac\ufffd\ufffdn\u00de \u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd ~trs\ufffd/wokztzr yontk \u20ac{\ufffd~mo\u20ac \ufffdoznon \ufffd{~o|{~\ufffd y{~o q~o}\ufffdoz\ufffdw\u00de {z\ufffd\ufffdlo~m\ufffd/\nw{\u20act\u20ac mk\u20aco\u20ac tzq{~otrz/l{~z |o~\u20ac{z\u20ac k\u20acm{y|k~on \ufffd{woq\ufffd/wokztzr yontk {\ufffd\ufffdwo\ufffd\u20ac. kzn \ufffdsk\ufffd \ufffds{\u20aco\n~o|{~\ufffd\u20ac \ufffdoznon \ufffd{~oqwom\ufffd zork\ufffdt\ufffdo \u20acoz\ufffdtyoz\ufffd k\u20ac\u00d0oww1\n\\st\u20ac t\u20ackw\u20ac{ z{\ufffdklwo k\u20ac\ufffdsotzmtnozmo {q\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac {\ufffdo~kww sk\u20aclooz\nnomwtztzr {\ufffdo~ \ufffdso|k\u20ac\ufffd \u20aco\ufffdo~kw \u00deok~\u20ac d44f1 I{z\ufffdo~\u20acow\u00de. tzk\u20acky|wo {qm{yy\ufffdztmklwo nt\u20acok\u20aco\n~o|{~\ufffdtzr q~{y Nokw\ufffdsTk| {\ufffdo~kww. \ufffdsoq~o}\ufffdozm\u00de {q~o|{~\ufffdtzr \u00d0k\u20acy{~o sok\ufffdtw\u00de ~o|~o\u20acoz\ufffdon tz\nwoq\ufffd/wokztzr yontk {\ufffd\ufffdwo\ufffd\u20ac1 _stwo \ufffdso\u20aco qtzntzr\u20ac \u20acs{\ufffdwn lotz\ufffdo~|~o\ufffdon \u00d0t\ufffds mk\ufffd\ufffdt{z. \ufffdst\u20acyk\u00de\n\u20ac\ufffdrro\u20ac\ufffd \ufffdsk\ufffd ~o|{~\ufffdtzr {z\\Gtzq{~otrz/l{~z |o~\u20ac{z\u20ac yk\u00de lo\ufffdzo}\ufffdkww\u00de nt\u20ac\ufffd~tl\ufffd\ufffdon kw{zr \ufffdso\n|{wt\ufffdtmkw \u20ac|om\ufffd~\ufffdy k\ufffdlk\u20acowtzo1 Ztrs\ufffd/wokztzr yontk {\ufffd\ufffdwo\ufffd\u20ac yk\u00de ~o|{~\ufffd {z\\Gtzq{~otrz/l{~z\n|o~\u20ac{z\u20ac y{~o q~o}\ufffdoz\ufffdw\u00de \ufffdskz woq\ufffd/wokztzr yontk. kzn woq\ufffd/wokztzr yontk {\ufffd\ufffdwo\ufffd\u20ac yk\u00de ~o|{~\ufffd {z\n{\ufffdso~ m{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac y{~o q~o}\ufffdoz\ufffdw\u00de. |o~sk|\u20ac strswtrs\ufffdtzr kntqqo~ozmo tz~o|{~\ufffdtzr\n|~t{~t\ufffdto\u20ac. tz\ufffdo~o\u20ac\ufffd. kzn |{wt\ufffdtmkw \u00d0tww1 W~t{~ \u20ac\ufffd\ufffdnto\u20ac tz\ufffdo\u20ac\ufffdtrk\ufffdtzr yontk kzn m{yy\ufffdztmklwo nt\u20ac/\nok\u20aco\u20ac sk\ufffdo \u20ac\ufffdrro\u20ac\ufffdon \ufffdsk\ufffd nt\u20acm{~nkzmo lo\ufffd\u00d0ooz q~o}\ufffdozm\u00de {q|~tz\ufffd kzn {zwtzo ~o|{~\ufffdtzr kzn\nkm\ufffd\ufffdkw ~t\u20acvk\u20acnoqtzon l\u00dey{~\ufffdkwt\ufffd\u00de ~k\ufffdo\u20ac yk\u00de o\u00f0t\u20ac\ufffd d57.59f1 T{~o{\ufffdo~. yontk ~o|{~\ufffd\u20ac \ufffdozn \ufffd{\nky|wtq\u00de o\ufffdoz\ufffd\u20ac \ufffdsk\ufffd k~o|o~mot\ufffdon \ufffd{lo~k~o {~n~kyk\ufffdtm. kzn \ufffdsotzqw\ufffdozmo {q\ufffdsoyk\u20ac\u20ac yontk\nsk\u20aclooz \u20ac\ufffd\ufffdnton tz\ufffdsom{z\ufffdo\u00f0\ufffd {q]1[1 |{wt\ufffdtmkw kroznk \u20aco\ufffd\ufffdtzr d4.5:f1\n\\so yokz z\ufffdylo~ {q~o|{~\ufffd\u20ac q~{y 5347 \ufffd{534= \u00d0k\u20ac9~o|{~\ufffd\u20ac |o~\u00deok~1 \\so ~owk\ufffdt\ufffdow\u00de qo\u00d0\nzo\u00d0\u20ac |tomo\u20ac yk\u00de ~oqwom\ufffd \ufffdsoq{m\ufffd\u20acon zk\ufffd\ufffd~o {q\ufffdst\u20ackzkw\u00de\u20act\u20ac rt\ufffdoz \ufffdsk\ufffd {zw\u00de ~o|{~\ufffd\u20ac m\ufffd~k\ufffdon q~{y\nNokw\ufffdsTk| {z\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac tzq{~otrz/l{~z tznt\ufffdtn\ufffdkw\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac \u00d0o~o tzmw\ufffdnon1\n\\so\u20aco ~o\u20ac\ufffdw\ufffd\u20ac yk\u00de kw\u20ac{ ~oqwom\ufffd \ufffdsotz\ufffdoznon q{m\ufffd\u20ac {qntrt\ufffdkw nt\u20acok\u20aco no\ufffdom\ufffdt{z \ufffd{{w\u20ac {zmw\ufffd\u20ac\ufffdo~\u20ac {~\n{\ufffd\ufffdl~okv o\ufffdoz\ufffd\u20ac \ufffdsk\ufffd k~o\ufffdz\ufffd\u20ac\ufffdkw {~y{~o z\ufffdyo~{\ufffd\u20ac \ufffdskz o\u00f0|om\ufffdon1 F\u20ac\u20ac\ufffdms. o\ufffdoz\ufffd\u20ac tz\ufffd{w\ufffdtzr\n\ufffdms~{ztm\ufffd tzqom\ufffdt{\ufffd\u20ac nt\u20acok\u20aco\u20ac \u20ac\ufffdms k\u20ac\ufffd\ufffdlo~m\ufffdw{\u20act\u20ac k~oz{\ufffdkw\u00d0k\u00de\u20ac mk|\ufffd\ufffd~on {zNokw\ufffdsTk| d49f1\nJo\u20ac|t\ufffdo \ufffdst\u20ac. t\ufffdt\u20acz{\ufffdklwo \ufffdsk\ufffd 76& *53+ {qkww~o|{~\ufffd\u20ac z{\ufffdon tz\ufffdst\u20ac|tw{\ufffd \u20ac\ufffd\ufffdn\u00de \u00d0o~o |{\u20ac\ufffdon tz\n534:1 \\so |{wt\ufffdtmkw oz\ufffdt~{zyoz\ufffd n\ufffd~tzr \ufffdso\u20ac\ufffdyyo~ {q534: tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac kzn ~so\ufffd{~tm\n\u20ac\ufffd~~{\ufffdzntzr tyytr~k\ufffdt{z yk\u00de sk\ufffdo m{z\ufffd~tl\ufffd\ufffdon \ufffd{\ufffdsom{zm\ufffd~~oz\ufffd tzm~ok\u20aco tz~o|{~\ufffdtzr1 I{z/\n\ufffdo~\u20acow\u00de. yontk |~t{~t\ufffdto\u20ac yk\u00de sk\ufffdo kw\u20ac{ kqqom\ufffdon |{wt\ufffdtmkw nt\u20acm{\ufffd~\u20aco1 Vzo \u20ac\ufffd\ufffdn\u00de l\u00deTmI{yl\u20ac\no\ufffdkw1z{\ufffdon \ufffdsk\ufffd k\u20ac\ufffd~{zr ~owk\ufffdt{z\u20acst| o\u00f0t\u20ac\ufffd\u20ac lo\ufffd\u00d0ooz \ufffdsot\u20ac\u20ac\ufffdo\u20ac \ufffdsoyontk oy|sk\u20act\u00feo\u20ac n\ufffd~tzr kz\nowom\ufffdt{z m\u00demwo kzn \ufffd{\ufffdo~ u\ufffdnryoz\ufffd d5;f1 Ozknnt\ufffdt{z. Tozut\ufffdk~ z{\ufffdon \ufffdsk\ufffd zork\ufffdt\ufffdo yontk |{~/\n\ufffd~k\u00dekw\u20ac {qtyytr~kz\ufffd\u20ac m{\ufffdwn m{z\ufffd~tl\ufffd\ufffdo \ufffd{s{\u20ac\ufffdtwt\ufffdto\u20ac k\ufffd\ufffdsowo\ufffdow {q|\ufffdlwtm nt\u20acm{\ufffd~\u20aco d5<f1 Mt\ufffdoz\n\ufffdso\u20acykww z\ufffdylo~ {q~o|{~\ufffd\u20ac m\ufffd~k\ufffdon q{~\ufffdst\u20ac|tw{\ufffd kzn \ufffdso{l\u20aco~\ufffdk\ufffdt{zkw zk\ufffd\ufffd~o {q\ufffdso\u20ac\ufffd\ufffdn\u00de. k\nm{~~owk\ufffdt{z lo\ufffd\u00d0ooz |{wt\ufffdtmkw o\ufffdoz\ufffd\u20ac \ufffdsk\ufffd yk\u00de sk\ufffdo tzqw\ufffdozmon tzm~ok\u20acon ~o|{~\ufffdtzr kzn \ufffdso\nz\ufffdylo~ {q~o|{~\ufffd\u20ac {mm\ufffd~~tzr tz534: m{\ufffdwn z{\ufffdlok\u20ac\u20aco\u20ac\u20acon1 N{\u00d0o\ufffdo~ t\ufffdyk\u00de lo\u00d0{~\ufffds m{z\u20actn/\no~tzr \ufffdsooqqom\ufffd\u20ac {qyontk \u20acoz\ufffdtyoz\ufffd tzq\ufffd\ufffd\ufffd~o \u20ac\ufffd\ufffdnto\u20ac1\\klwo 61*I{z\ufffdtz\ufffd on+\nNoknwtzo Zk\ufffdo~ $4 Zk\ufffdo~ $5\n_s\u00de t\u20ac\ufffd\ufffdlo~m \ufffdw{\u20act\u20ac {z\ufffdso~t\u20acotzUbI l\ufffd\ufffdz{\ufffdUo\u00d0 Qo~\u20aco\u00deD Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\n_GMV Oz\ufffdo\u20ac\ufffdtrk\ufffdo\u20ac> UbI \\GIk\u20aco [|tvo Zo\ufffdo~\u20aco\u20ac bok~\u20ac {qW~{r~o\u20ac\u20ac W{\u20act\ufffdt\ufffdo W{\u20act\ufffdt\ufffdo\nF~oK~kntmk\ufffdon Jt\u20acok\u20aco\u20ac Tkvtzr kI{yolkmv Gomk\ufffd\u20aco {qOyytr~kz\ufffd\u20ac 444 Uo\ufffd\ufffd~kw Uo\ufffd\ufffd~kw\nUbI \\GIk\u20aco [|tvo Zo\ufffdo~\u20aco\u20ac bok~\u20ac {qW~{r~o\u20ac\u20ac W{\u20act\ufffdt\ufffdo W{\u20act\ufffdt\ufffdo\n\ufffdZk\ufffdo~ \u20acoz\ufffdtyoz\ufffd ~om{zmtwon \ufffd{zork\ufffdt\ufffdo\nGw\ufffdo> Soq\ufffd/wokztzr2S tlo~kw\nV~kzro> Ztrs\ufffd/wokz tzr2I{z\u20aco~\ufffdk \ufffdt\ufffdo\nM~ooz> Ioz\ufffdo~2W~{/ [mtozmo\nboww{\u00d0> ]zvz{\u00d0z\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13563=:;1\ufffd33 6\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 =245\n\\st\u20ac t\u20ac\ufffdsoqt~\u20ac\ufffd \u20ac\ufffd\ufffdn\u00de \ufffd{{\ufffd~vz{\u00d0wonro \ufffdsk\ufffd sk\u20aco\u00f0kytzon \ufffdsok\u20ac\u20ac{mtk\ufffdt{z lo\ufffd\u00d0ooz m{yy\ufffd/\nztmklwo nt\u20acok\u20aco ~o|{~\ufffdtzr. yontk ltk\u20ac. kzn q{~otrz/l{~z |o~\u20ac{z\u20ac1 Ik\ufffd\u20ackw wtzv\u20ac. s{\u00d0o\ufffdo~. yk\u00de lo\nntqqtm\ufffdw\ufffd \ufffd{o\u20ac\ufffdklwt\u20acs1 [\ufffd\ufffdnto\u20ac tz\ufffdo\u20ac\ufffdtrk\ufffdtzr yontk ltk\u20ac kzn ~oq\ufffdroo |{|\ufffdwk\ufffdt{z\u20ac sk\ufffdo noy{z/\n\u20ac\ufffd~k\ufffdon \ufffdsk\ufffd zo\u00d0\u20ac ~o|{~\ufffdtzr n{o\u20ac. {z{mmk\u20act{z. \ufffdk~ro\ufffd yk\u20ac\u20ac m{z\u20ac\ufffdyo~ k||okw k\u20ac{||{\u20acon \ufffd{\n~oqwom\ufffdtzr \u20ac\ufffd~\ufffdm\ufffd\ufffd~kw {~~okw/\ufffdtyo mo~\ufffdktz\ufffdto\u20ac d5=f1 I{z\ufffdo~\u20acow\u00de. \ufffdso|{|\ufffdwk~ |~o\u20ac\u20ac sk\u20ackw\u20ac{ \u20acson\nwtrs\ufffd {z{zr{tzr s\ufffdykzt\ufffdk~tkz m~t\u20aco\u20ac1 \\so ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdsoyontk kzn tyytr~k\ufffdt{z\n~oyktz\u20ac m{y|wo\u00f0 k\ufffdlo\u20ac\ufffd kzn mskzrtzr zk\ufffdt{zkw |{wt\ufffdtm\u20ac kzn lowtoq \u20ac\u00de\u20ac\ufffdoy\u20ac kl{\ufffd\ufffd ytr~kz\ufffd\u20ac yk\u00de\nlol{\ufffds kztzqw\ufffdozmo {zk\u20ac\u00d0oww k\u20actzqw\ufffdozmon l\u00de\ufffdsoyk\u20ac\u20ac yontk1\n\\st\u20ac \u20ac\ufffd\ufffdn\u00de skn\u20aco\ufffdo~kw wtyt\ufffdk\ufffdt{z\u20ac1 Jo\u20ac|t\ufffdo \ufffdso~owk\ufffdt\ufffdo \u20ac\ufffd~ozr\ufffds\u20ac {q\ufffdso\u20ac\ufffd~\ufffdotwwkzmo \u20ac\u00de\u20ac\ufffdoy\n\ufffd\u20acon \ufffd{rozo~k\ufffdo ~o|{~\ufffd\u20ac tzmw\ufffdnon tz\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de. t\ufffd\u00d0k\u20acwtyt\ufffdon l\u00de\ufffdso\u20acykww \u20acky|wo \u20act\u00feo\ufffdsk\ufffd yo\ufffd\n\ufffdsotzmw\ufffd\u20act{z m~t\ufffdo~tk1 Mt\ufffdoz \ufffdsk\ufffd \ufffdst\u20act\u20ack|tw{\ufffd \u20ac\ufffd\ufffdn\u00de. kz\u00dem{zmw\ufffd\u20act{z\u20ac n~k\u00d0z so~o \u20acs{\ufffdwn lo\ntz\ufffdo~|~o\ufffdon u\ufffdntmt{\ufffd\u20acw\u00de1 Fnnt\ufffdt{zkw \u20ac\ufffd\ufffdnto\u20ac tz\ufffd{w\ufffdtzr kwk~ro~ \u20acky|wo \u20act\u00feo\u20acs{\ufffdwn lom{zn\ufffdm\ufffdon\ntz\ufffdsoq\ufffd\ufffd\ufffd~o1 Vzw\u00de zo\u00d0\u20ac ~o|{~\ufffd\u20ac \u00d0~t\ufffd\ufffdoz tzKzrwt\u20acs \u00d0o~o tzmw\ufffdnon q{~\ufffdso|\ufffd~|{\u20aco\u20ac {q\ufffdst\u20ac\n\u20ac\ufffd\ufffdn\u00de. wtyt\ufffdon l{\ufffds l\u00dero{r~k|stm \u20acm{|o {q\ufffdso\u20ac\ufffd\ufffdn\u00de k\u20ac\u00d0oww k\u20ackmm\ufffd~km\u00de kzn \ufffdkwtnt\ufffd\u00de {qyontk\nltk\u20ac tzntmk\ufffd{~\u20ac1 G{\ufffds yontk ltk\u20ac tzntmk\ufffd{~\u20ac k\ufffd\ufffdoy|\ufffd \ufffd{k||w\u00de ~tr{~{\ufffd\u20ac }\ufffdkwt\ufffd\u00de yo\ufffd~tm\u20ac \ufffd{o\u20ac\ufffdkl/\nwt\u20acskmm\ufffd~km\u00de. s{\u00d0o\ufffdo~ ltk\u20ac t\u20ac\ufffdw\ufffdtyk\ufffdow\u00de k\u20ac\ufffdluom\ufffdt\ufffdo |k~kyo\ufffdo~ kzn \ufffd{{w\u20ac \ufffdsk\ufffd k\ufffd\ufffdoy|\ufffd \ufffd{mwk\u20ac/\n\u20actq\u00deltk\u20ac \u20acs{\ufffdwn lotz\ufffdo~|~o\ufffdon mk\ufffd\ufffdt{\ufffd\u20acw\u00de1 O\ufffdt\u20ac|{\u20ac\u20actlwo \ufffdsk\ufffd \ufffdsooz\ufffdt~o\ufffd\u00de {qzo\u00d0\u20ac ~o|{~\ufffd\u20ac\nknn~o\u20ac\u20actzr \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac kzn q{~otrz/l{~z |o~\u20ac{z\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac sk\u20acz{\ufffdlooz mk|\ufffd\ufffd~on\nso~o. |k~\ufffdtm\ufffdwk~w\u00de rt\ufffdoz \ufffdsk\ufffd tz\ufffdo~zo\ufffd/lk\u20acon nt\u20acok\u20aco y{zt\ufffd{~tzr kzn o\ufffdkw\ufffdk\ufffdt{z \ufffd{{w\u20ac \u20ac\ufffdms k\u20ac\nNokw\ufffdsTk| q{m\ufffd\u20ac {z\ufffdz\ufffd\u20ac\ufffdkw o\ufffdoz\ufffd\u20ac {q\u20actrztqtmkzmo1 _stwo \ufffd\ufffdlo~m\ufffdw{\u20act\u20ac ~oyktz\u20ac ~owk\ufffdt\ufffdow\u00de ~k~o\ntz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac. \ufffds{\u20aco o\ufffdoz\ufffd\u20ac \ufffdsk\ufffd n{{mm\ufffd~ yk\u00de z{\ufffdsk\ufffdo |~{n\ufffdmon \u20actrzkw\u20ac \u20actrztqtmkz\ufffd\noz{\ufffdrs q{~~o|{~\ufffdtzr {zNokw\ufffdsTk|1 Ozknnt\ufffdt{z. Nokw\ufffdsTk| ~o|{~\ufffd\u20ac \ufffdzno~r{ kztzt\ufffdtkw |~{/\nmo\u20ac\u20ac {qno/n\ufffd|wtmk\ufffdt{z |~t{~ \ufffd{|{\u20ac\ufffdtzr. kzn k\u20ac\u20ac\ufffdms. \u20ac{yo ~o|{~\ufffd\u20ac {z\ufffdso\u20ackyo {\ufffd\ufffdl~okv q~{y\nntqqo~oz\ufffd zo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac yk\u00de sk\ufffdo looz ~oy{\ufffdon |~t{~ \ufffd{tzmw\ufffd\u20act{z q{~\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de1 _stwo \ufffdso\nm{z\ufffd~{w r~{\ufffd| \u00d0k\u20acms{\u20acoz tzkzk\ufffd\ufffdoy|\ufffd \ufffd{lkwkzmo \\G.kz{q\ufffdoz/\u20ac\ufffdtryk\ufffdt\u00feon nt\u20acok\u20aco. krktz\u20ac\ufffd\n{\ufffdso~ m{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac. k\ufffd~\ufffdo m{z\ufffd~{w t\u20acntqqtm\ufffdw\ufffd \ufffd{noqtzo. kzn yk\u00de z{\ufffdlo{|\ufffdtykw tz\n\ufffdst\u20ac\u20aco\ufffd\ufffdtzr1 Ltzkww\u00de. \u20ac{yo ~o|{~\ufffd\u20ac \u00d0o~o \ufffdzklwo \ufffd{lomk\ufffdor{~t\u00feon l\u00de|{wt\ufffdtmkw wokztzr. k\u20ac\ufffdso\u00de\nm{\ufffdwn z{\ufffdlotnoz\ufffdtqton tzot\ufffdso~ yontk ltk\u20ac tzntmk\ufffd{~1 _stwo \ufffdso~o|{~\ufffd\u20ac \u00d0o~o ~o\ufffdktzon q{~\ufffdso\n|\ufffd~|{\u20aco {qkzkw\u00de\u20act\u20ac. t\ufffdt\u20ac|{\u20ac\u20actlwo \ufffdsk\ufffd \ufffdzvz{\u00d0z ~o|{~\ufffd\u20acdosk\ufffdo k|{wt\ufffdtmkw wokztzr \ufffdsk\ufffd m{\ufffdwn\nsk\ufffdo kqqom\ufffdon \ufffdso~o\u20ac\ufffdw\ufffd\u20ac1 N{\u00d0o\ufffdo~. \ufffdso\ufffd{\ufffdkw z\ufffdylo~ {q\ufffdzvz{\u00d0z ~o|{~\ufffd\u20ac ~oyktzon \u20acykww. kzn\ntqm{z\u20aco~\ufffdk\ufffdt\ufffdo o\u20ac\ufffdtyk\ufffdo\u20ac \u00d0o~o k||wton kzn \ufffdso\u20aco ~o|{~\ufffd\u20ac \u00d0o~o knnon \ufffd{ot\ufffdso~ woq\ufffd/ {~~trs\ufffd/\nwokztzr mk\ufffdor{~to\u20ac. \ufffdso{\ufffdo~kww lkwkzmo {qyontk ltk\u20aco\u20ac \u00d0{\ufffdwn z{\ufffdsk\ufffdo mskzron oz{\ufffdrs \ufffd{\u20actr/\nztqtmkz\ufffdw\u00de kw\ufffdo~ {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac1\nI{zmw\ufffd\ufffdt{z\nKzm{\ufffd~krtzr |\ufffdlwtm nt\u20acm{\ufffd~\u20aco {zm{yy\ufffdztmklwo nt\u20acok\u20aco\u20ac t\u20acm~t\ufffdtmkw q{~\ufffdsont\u20ac\u20acoytzk\ufffdt{z {q\n\ufffdt\ufffdkw sokw\ufffds tzq{~yk\ufffdt{z1 K}\ufffdkww\u00de ty|{~\ufffdkz\ufffd s{\u00d0o\ufffdo~. t\u20ac\ufffdso|~{y{\ufffdt{z {qkmm\ufffd~k\ufffdo kzn \ufffdzlt/\nk\u20acon sokw\ufffds ~o|{~\ufffdtzr. |k~\ufffdtm\ufffdwk~w\u00de \u00d0soz tz\ufffd{w\ufffdtzr \ufffd\ufffdwzo~klwo |{|\ufffdwk\ufffdt{z\u20ac1 \\st\u20ac |tw{\ufffd \u20ac\ufffd\ufffdn\u00de\n\u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd |{wt\ufffdtmkw wokztzr yk\u00de kqqom\ufffd ~o|{~\ufffdtzr {zq{~otrz/l{~z |{|\ufffdwk\ufffdt{z\u20ac kzn \ufffd\ufffdlo~m\ufffdw{/\n\u20act\u20ac.s{\u00d0o\ufffdo~ knnt\ufffdt{zkw \u20ac\ufffd\ufffdnto\u20ac o\u00f0kytztzr kwk~ro~ \u20acky|wo \u20act\u00feokzn nt\ufffdo~\u20act\ufffd\u00de {qm{yy\ufffdztmklwo\nnt\u20acok\u20aco \u20ac\ufffdk\ufffdo\u20ac k~ozoonon1\nF\ufffd\ufffds{~ I{z\ufffd~tl\ufffd\ufffdt{z\ufffd\nI{zmo|\ufffd\ufffdkwt\u00fek\ufffdt{z> Fzrow U1Jo\u20ackt. Tkty\ufffdzk [1Tku\ufffdyno~. G~t\ufffd\ufffdk Sk\u20ac\u20acykzz. Sk\u00d0~ozmo I1\nTkn{qq. Q{sz [1G~{\u00d0z\u20ac\ufffdotz1\nJk\ufffdk m\ufffd~k\ufffdt{z> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo. Tkty\ufffdzk [1Tku\ufffdyno~. Kytw\u00de S1\nI{sz1\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 43245\nL{~ykw kzkw\u00de\u20act\u20ac> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo. Tkty\ufffdzk [1Tku\ufffdyno~. G~t\ufffd\ufffdk\nSk\u20ac\u20acykzz. Sk\u00d0~ozmo I1Tkn{qq1\nL\ufffdzntzr km}\ufffdt\u20act\ufffdt{z> Fzrow U1Jo\u20ackt1\nOz\ufffdo\u20ac\ufffdtrk\ufffdt{z> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo1\nTo\ufffds{n{w{r\u00de> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo. Tkty\ufffdzk [1Tku\ufffdyno~1\nZo\u20ac{\ufffd~mo\u20ac> Fzrow U1Jo\u20ackt1\n[\ufffd|o~\ufffdt\u20act{z> Fzrow U1Jo\u20ackt. G~t\ufffd\ufffdk Sk\u20ac\u20acykzz. Sk\u00d0~ozmo I1Tkn{qq. Q{sz [1G~{\u00d0z\u20ac\ufffdotz1\n^kwtnk\ufffdt{z> Fzrow U1Jo\u20ackt1\n_~t\ufffdtzr \u02d8{~trtzkw n~kq\ufffd> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo. Tkty\ufffdzk [1Tku\ufffdyno~.\nG~t\ufffd\ufffdk Sk\u20ac\u20acykzz. Sk\u00d0~ozmo I1Tkn{qq. Kytw\u00de S1I{sz1\n_~t\ufffdtzr \u02d8~o\ufffdto\u00d0 \u2019ont\ufffdtzr> Fzrow U1Jo\u20ackt. [s~k\ufffdkz\ufffdst T1[o\u20acsk\u20ack\u00deoo. Tkty\ufffdzk [1Tku\ufffdy/\nno~. G~t\ufffd\ufffdk Sk\u20ac\u20acykzz. Sk\u00d0~ozmo I1Tkn{qq. Kytw\u00de S1I{sz. Q{sz [1G~{\u00d0z\u20ac\ufffdotz1\nZoqo~ozmo\ufffd\n41 b{\ufffdzr o\ufffdkw1Tontmtzo tz\ufffdsoW{|\ufffdwk~ W~o\ufffd\ufffd> \\so Ozqw\ufffdozmo {q\ufffdsoTontk {zWo~mo|\ufffdt{z\ufffd {qJt\ufffdok\ufffdo1\nWS{[ Vzo1 5=Vm\ufffd{lo~ 533<1\n51 R{\ufffd\ufffdv{\ufffdk W.L{\ufffdwo~ J._t\ufffdoykz [._otzlo~r QZ1Tku{~ tzqom\ufffdt{z o\ufffdoz\ufffd\ufffd {\ufffdo~ 9\ufffdok~\ufffd> s{\ufffd t\ufffdyontk\nm{\ufffdo~kro tzqw\ufffdozmtzr {zwtzo tzq{~yk\ufffdt {zzoon\ufffd {qsokw\ufffds mk~o |~{qo\ufffd\ufffdt{z kw\ufffdkzn\ufffdso|\ufffdlwtmD QTon Oz\ufffdo~/\nzo\ufffdZo\ufffd1 5346 Q\ufffdw49?49*;+1\n61 I{wwtz\ufffd{z [.Rskz R.Noqqo~zkz Q1\\so Kqqom\ufffd\ufffd {qTontk Zo|{~\ufffd\ufffd {zJt\ufffdok\ufffdo [|~okn kznOy|{~\ufffdkz\ufffd W\ufffdl/\nwtmNokw\ufffds Tok\ufffd\ufffd~oyoz \ufffd\ufffd1WS{[ Vzo1 5349? 43*44+> o34747561 s\ufffd\ufffd|\ufffd>22n{t1{~ r243146;42 u{\ufffd~zkw1|{z o1\n3474756 WTOJ> 5:95<=3=\n71 Ntw\ufffd{z [.N\ufffdz\ufffd R1]Rzo\ufffd\ufffd|k|o~ \ufffd)~o|~o\ufffdo z\ufffdk\ufffdt{z\ufffd {q\ufffdso533=\u02d85343 {\ufffd\ufffdl~okv {q\ufffd\ufffdtzo qw\ufffd>{zosokw\ufffds\n\ufffdmk~o z{\ufffd{\ufffdo~/s\ufffd|on l\ufffd\ufffdsoyontkD QK|tnoyt{w I{yy\ufffdz t\ufffd\ufffdNokw\ufffds1 5344 Vm\ufffd? :9*43+>=74 \u02d8:1s\ufffd\ufffd|\ufffd>22\nn{t1{~r243144 6:2uoms153431 44=<;9 WTOJ> 54464636\n91 Fvnozt\ufffdwt .G.Jt{zzo. K1Q1. [\ufffd~{. Z1Joy{m~km \ufffdtz\ufffdsoFro {qUo\ufffd Tontk> FZo|{~\ufffd {z\ufffdsoTontk kzn\n\ufffdsoOyytr~k\ufffdt{z Jolk\ufffdo1 G~{{vtzr \ufffdOz\ufffd\ufffdt\ufffd\ufffd\ufffdt{z1 s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1l~{{vtzr\ufffd 1on\ufffd2~o\ufffdo k~ms2noy{ m~km\ufffd/tz/\ufffdso/\nkro/{q/zo\ufffd /yontk/k/~o |{~\ufffd/{z/\ufffdso /yontk/kzn/ \ufffdso/tyytr ~k\ufffdt{z/nol k\ufffdo21 Fmmo\ufffd\ufffdo n4514414<1\n:1 W{wt\ufffdtmkw W{wk~t\ufffdk\ufffdt{z tz\ufffdsoFyo~tmkz W\ufffdlwtm1 Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~1 Q\ufffdzo 45.53471 \ufffd\ufffd\ufffd1|o\ufffd ~o\ufffdok~ms1\n{~r1 Fmmo\ufffd\ufffdon 4514714<1\n;1 _kw\ufffds [.\\s{yk\ufffd JZ. Tk\ufffd{z G_. K\ufffdkz\ufffd TZ1 \\so ty|km\ufffd {q\ufffdsoyontk {z\ufffdsonomt\ufffdt{z {q|k~oz\ufffd\ufffd tz\n[{\ufffd\ufffds _kwo\ufffd \ufffd{kmmo|\ufffd yok\ufffdwo\ufffd/y \ufffdy|\ufffd/~\ufffdlowwk *TTZ+ tyy\ufffdzt\ufffd k\ufffdt{z1 K|tnoyt{w Ozqom\ufffd1 5349 Lol? 476\n*6+>993\u02d8:3 1s\ufffd\ufffd|\ufffd>22n{t1 {~r2431434;2[ 3=935:<<47 333;95 WTOJ> 59:33::;\n<1 G~olkz Z1Nokw\ufffds zo\ufffd\ufffdmk \ufffd\ufffd\ufffdq{~tzm~ok\ufffdtzr tzqw\ufffdoz\ufffdk \ufffdkmmtzk\ufffdt{z m{\ufffdo~kro >Fztzn\ufffdm\ufffdt\ufffdo ~ok\ufffd{ztzr\nrkyo k||~{kms1 WS{[ VUK1 5344?:1\n=1 [yt\ufffds RI.Ztykw ZU. [kznlo ~rN.[\ufffd{~o\ufffd QJ.Skrk\ufffd\ufffdo S.Tk\ufffdw\ufffdl\ufffd I.o\ufffdkw1]zno~\ufffd\ufffdkzn tzrzo\ufffd\ufffd\ufffd{~\ufffd st/\nzo\ufffd\ufffd {qkzoyo~rtzr |kznoyt m>Oz\ufffdo~zk\ufffdt{zkw zo\ufffd\ufffd|k|o~ m{\ufffdo~kro {q\ufffdsoN4U4 {\ufffd\ufffdl~okv 1Ozqw\ufffdoz\ufffdk kzn\nV\ufffdso~ Zo\ufffd|t~k\ufffd{~ \ufffd^t~\ufffd\ufffdo\ufffd1 5345? ;*9+><7;\u02d8< 961s\ufffd\ufffd|\ufffd>22n{t1{ ~r243144442t~ \ufffd1453;6 WTOJ> 565<346<\n431 [\ufffdz I.bkzr _.F~tz{ Q.Rskz R1Kqqom\ufffd {qyontk/t zn\ufffdmon \ufffd{mtkw nt\ufffd\ufffdkzmtzr {znt\ufffdok\ufffdo \ufffd~kz\ufffdyt\ufffd\ufffdt{z tzk\n\ufffd\ufffd{|k\ufffdms \ufffdo\ufffd\ufffdtzr1 Tk\ufffdsoyk\ufffd tmkwlt{\ufffdmtozmo\ufffd1 5344? 563><;\u02d8=91 s\ufffd\ufffd|\ufffd>22 n{t1{~r243143 4:2u1yl\ufffd1 53441341\n339WTOJ> 545=:3 =5\n441 IJI1 \\GOzmtnozmo tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\ufffd. 4=96\u02d8534:1 Sk\ufffd\ufffd \ufffd|nk\ufffdon> U{\ufffdoyl o~46534;1 F\ufffdktwklwo>\ns\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1mnm1r{\ufffd 2\ufffdl2\ufffd\ufffdk\ufffdt\ufffd\ufffdtm\ufffd 2\ufffdlmk\ufffdo\ufffd1s \ufffdy1Fmmo\ufffd\ufffdo n5Q\ufffdzo 534<1\n451 _{~wn Nokw\ufffds V~rkzt\ufffdk\ufffdt{ z1Mw{lkw \ufffd\ufffdlo~m\ufffdw {\ufffdt\ufffd ~o|{~\ufffd 5349 Mozo\ufffdk >_{~wn Nokw\ufffds V~rkzt\ufffdk\ufffdt{ z?\n53491 F\ufffdktwkl wo>s\ufffd\ufffd|>22\ufffd\ufffd\ufffd1\ufffd s{1tz\ufffd2\ufffdl2| \ufffdlwtmk\ufffdt{z\ufffd 2rw{lkwi~o| {~\ufffd2oz21 Fmmo\ufffd \ufffdon5=Tk\ufffd 534<1\n461 \\\ufffdkzro\ufffd1 kw1\\\ufffdlo~m\ufffdw {\ufffdt\ufffd Fy{zr L{~otrz/G {~zWo~\ufffd{z\ufffd Jtkrz{\ufffdon >43 bok~\ufffd Fq\ufffdo~ F~~t\ufffdkw tz\ufffdso\n]zt\ufffdon [\ufffdk\ufffdo\ufffd. 5343\u02d853491 Ty\ufffd~ T{~l T{~\ufffdkw _vw\ufffd Zo|1 534; Tk~ 57?::*44+> 5=9\u02d85= <1s\ufffd\ufffd|\ufffd>22n{t1\n{~r2431499<9 2yy\ufffd~1y y::44k6 WTOJ> 5<666=46\n471 Gkvo~ o\ufffd1kw1Fl~\ufffd|\ufffd Jomwtzo tz\\\ufffdlo~m\ufffdw {\ufffdt\ufffd ky{zr L{~otrz/G {~zWo~\ufffd{z\ufffd tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\ufffd1 WSV[\nVzo1 43Lol 534:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243146;42 u{\ufffd~zkw1|{z o1347;696 WTOJ> 5:<:63 37\n491 Nokw\ufffdsTk|1 Fl{\ufffd\ufffd1 F\ufffdktwklwo> s\ufffd\ufffd|>22\ufffd \ufffd\ufffd1sokw\ufffdsy k|1{~r2\ufffdt\ufffdo2 kl{\ufffd\ufffd1 Fmmo\ufffd\ufffdo nQ\ufffdzo 534<1\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 44245\n4:1 L~otqown II. Tkznw RJ.Zot\ufffd Gb.G~{\ufffdz\ufffd\ufffdot zQ[1Nokw\ufffdsTk|> rw{lkw tzqom\ufffdt{\ufffd\ufffd nt\ufffdok\ufffdo y{zt\ufffd{~t zr\n\ufffds~{\ufffdrs k\ufffd\ufffd{yk\ufffdon mwk\ufffd\ufffdtqtm k\ufffdt{z kzn\ufffdt\ufffd\ufffdkwt\ufffdk\ufffdt{z {qOz\ufffdo~zo\ufffd yontk ~o|{~\ufffd\ufffd1 QFyTon Ozq{~y F\ufffd\ufffd{m.\n49*533<+. ||1493\u02d849; s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 =;2ukytk1T5 977WTOJ> 4<3=:=3<\n4;1 Tontk Gtk\ufffd2Lkm\ufffd Isomv1 s\ufffd\ufffd|\ufffd>22y ontkltk\ufffdq km\ufffdmsomv1m{ y21Fmmo\ufffd\ufffdon 4514:14< 1\n4<1 Fww[tno\ufffd1 s\ufffd\ufffd|\ufffd>22\ufffd\ufffd \ufffd1kww\ufffdtno\ufffd1m {y2\ufffdzltk\ufffdo n/lkwkzmon/ zo\ufffd\ufffd1 Fmmo\ufffd\ufffdo n4514:14<1\n4=1 ]1[W{wt\ufffdtm\ufffd \u2019M{\ufffdo~zy oz\ufffd1G~{{vtzr\ufffd Oz\ufffd\ufffdt\ufffd\ufffd\ufffdt{z1 s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1l~{{vtzr\ufffd 1on\ufffd2\ufffd{|tm2\ufffd /\ufffd/|{wt\ufffdtm\ufffd /\nr{\ufffdo~zyo z\ufffd21534<1 Fmmo\ufffd\ufffdon 4514:14< 1\n531 Soks\ufffd TW1 [t\ufffdZoq\ufffdroo\ufffd tz_t\ufffdm{ z\ufffdtz Jtkrz{\ufffdon _t\ufffds T\ufffdw\ufffdt/J~\ufffdr Zo\ufffdt\ufffd\ufffdkz \ufffd\\G[tzmo 53471 G~ot\ufffdlk~\ufffd\nUo\ufffd\ufffd1 47Q\ufffdw534:1\n541 Soks\ufffd TW1 ]1[1 \\\ufffdlo~m\ufffdw{\ufffd t\ufffdIk\ufffdo\ufffd Zt\ufffdo k\ufffdL{~otrz/G {~zWk\ufffdtoz\ufffd\ufffd \\~t|wo 4=<: Ik\ufffdow{kn Wo~moz \ufffdkro1\nG~ot\ufffdlk~\ufffd Uo\ufffd\ufffd1 =Q\ufffdz534:1\n551 \\\ufffdlo~m\ufffdw {\ufffdt\ufffd tz\ufffdso]1[1 Nokw\ufffdsTk| 1s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1sokw\ufffdsyk |1{~r2\ufffdl21 Fmmo\ufffd\ufffdo n914:14=1\n561 \\\ufffdlo~m\ufffdw {\ufffdt\ufffd> Jk\ufffdk kzn[\ufffdk\ufffdt\ufffd\ufffdtm\ufffd 1][Ioz\ufffdo~\ufffd q{~Jt\ufffdok\ufffdo I{z\ufffd~{w kznW~o\ufffdoz \ufffdt{z1 Fmmo\ufffd\ufffdon s\ufffd\ufffd|\ufffd>22\n\ufffd\ufffd\ufffd1mnm 1r{\ufffd2\ufffdl2\ufffd\ufffdk\ufffd t\ufffd\ufffdtm\ufffd2noqk\ufffdw\ufffd1s\ufffd y1Fmmo\ufffd\ufffdo n=14514=1\n571 L~{\ufffd\ufffd R.L~kzv K.Tktlkms K*4==;+ Zowk\ufffdt\ufffdo ~t\ufffdvtz\ufffdsozo\ufffd\ufffd yontk> k}\ufffdkz\ufffdtqtmk \ufffdt{z{qyt\ufffd~o|~o \ufffdoz\ufffdk/\n\ufffdt{z1 FyQ{qW\ufffdl Nokw\ufffds <;><75\u02d8<791\n591 R~t\ufffd\ufffdtkz\ufffd ozIT*4=<6+ Uo\ufffd\ufffd|k| o~m{\ufffdo~kro {qnt\ufffdok\ufffdo\ufffd kznkm\ufffd\ufffdkw y{~\ufffdkwt\ufffd\ufffd \ufffd\ufffdk\ufffdt\ufffd\ufffdtm\ufffd1 K\ufffd~Q[{m\nW\ufffd\ufffdms 46>4=6\u02d8=71\n5:1 TmI{yl\ufffd TK. [sk\ufffd JS*4=;5+ \\so kroznk/\ufffd o\ufffd\ufffdtzr q\ufffdzm\ufffdt{z {qyk\ufffd\ufffd yontk1 W\ufffdlw V|tz Y[\ufffdyyo~ 6:>\n4;:\u02d84<;1\n5;1 M{wnozlo~ rKU.\\~k\ufffdr{ \ufffd\ufffdT_1 Tk\ufffd\ufffd Tontk tz]1[1 I{zr~o\ufffd\ufffd t{zkw Kwom\ufffdt{z\ufffd1 Sort\ufffdwk\ufffdt\ufffdo [\ufffd\ufffdnto \ufffdY\ufffdk~/\n\ufffdo~w\ufffd1 ^{w1 45.U{16*F\ufffdr1. 4=<;+. ||164;\u02d866=\n5<1 Tozut\ufffdk~ I1Oyytr~kz\ufffd I~tytzkwt\ufffdk \ufffdt{ztzSk\ufffd kzn\ufffdsoTontk> Kqqom\ufffd\ufffd {zSk\ufffdtz{ Oyytr ~kz\ufffd _{~vo~\ufffd) Onoz/\n\ufffdt\ufffdto\ufffd tzF~t\ufffd{z k1Fyo~tmkz Gosk\ufffdt{ ~kw[mtoz\ufffdt\ufffd\ufffd1 \ufffd{w1 :31z{19/:1Tk\ufffd 534:1 ||19=;\u02d8:4:1\n5=1 Go~~\ufffd. T1.Mk~mtk/Gw kzm{. O1.\u2019T{{~o. R1*5349+1 W~o\ufffd\ufffd I{\ufffdo~kro {q\ufffdsoZoq\ufffdroo kznTtr~kz\ufffd I~t\ufffdt\ufffd tz\n\ufffdsoK]>FI{z\ufffdoz\ufffd Fzkw\ufffd\ufffdt\ufffd {qLt\ufffdo K\ufffd~{|okz I{\ufffdz\ufffd~to\ufffd1 Zo\ufffd~to\ufffdon q~{y s\ufffd\ufffd|>22\ufffd\ufffd\ufffd 1\ufffdzsm~1{~r2\n9:ll6:=m =1|nq\nPLOS ONETontk ~o|{~\ufffdtzr {q\ufffd\ufffdlo~m\ufffdw{ \ufffdt\ufffdkznq{~otrz/l{ ~ztz\ufffdso][\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13563= :; F|~tw 54.5353 45245", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tuberculosis and foreign-born populations in the United States: A mixed methods pilot study of media reporting and political identification", "author": ["AN Desai", "SM Seshasayee", "MS Majumder"], "pub_year": "2020", "venue": "PloS one", "abstract": "Background Media reporting on communicable diseases has been demonstrated to affect the  perception of the public. Communicable disease reporting related to foreign-born persons"}, "filled": false, "gsrank": 65, "pub_url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230967", "author_id": ["", "iy7rktwAAAAJ", "l7WEDAcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:LLMBNZaeGkQJ:scholar.google.com/&output=cite&scirp=64&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=LLMBNZaeGkQJ&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 3, "citedby_url": "/scholar?cites=4907409111945163564&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:LLMBNZaeGkQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0230967&type=printable"}}, {"title": "Brenda Starr at SemEval-2019 Task 4: hyperpartisan news detection", "year": "2019", "pdf_data": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019) , pages 924\u2013928\nMinneapolis, Minnesota, USA, June 6\u20137, 2019. \u00a92019 Association for Computational Linguistics924Brenda Starr at SemEval-2019 Task 4: Hyperpartisan News Detection\nOlga Papadopoulou, Giorgos Kordopatis-Zilos, Markos Zampoglou,\nSymeon Papadopoulos, Yiannis Kompatsiaris\nCentre for Research and Technology Hellas, Information Technologies Institute,\nThessaloniki, Greece\n(olgapapa,georgekordopatis,markzampoglou,papadop,ikom)@iti.gr\nAbstract\nIn the effort to tackle the challenge of Hyper-\npartisan News Detection, i.e., the task of de-\nciding whether a news article is biased towards\none party, faction, cause, or person, we experi-\nmented with two systems: i) a standard super-\nvised learning approach using super\ufb01cial text\nand bag-of-words features from the article title\nand body, and ii) a deep learning system com-\nprising a four-layer convolutional neural net-\nwork and max-pooling layers after the embed-\nding layer, feeding the consolidated features to\na bi-directional recurrent neural network. We\nachieved an F-score of 0.712 with our best ap-\nproach, which corresponds to the mid-range of\nperformance levels in the leaderboard.\n1 Introduction\nThe emerging issue of online disinformation has\nlately attracted the public attention and is per-\nceived as a major risk for democracy and society.\nMedia content (text, images, videos) is often dis-\nseminated on the Internet with the purpose of ma-\nnipulating public opinion. Hyperpartisan news de-\ntection is a problem arising as a result of the inten-\ntion of publishers to in\ufb02uence readers in favour of\na given party, idea or person. The SemEval 2019\nTask 4 (Kiesel et al., 2019) seeks solutions to this\nchallenge, in particular text-based approaches that\ncan detect hyperpartisan news articles.\nWe experimented with two approaches: i) a\nstandard supervised learning approach using su-\nper\ufb01cial text and bag-of-words features, and ii)\na deep learning system. We deployed the devel-\noped systems on TIRA (Potthast et al., 2019) (a\nplatform that supports software submissions) and\nits evaluation was conducted on unseen news ar-\nticles. The results of our submissions, which are\npresented in Table 1, are promising, yet there is\nstill considerable room for improvement. Ourbest resulting approach was the deep learning sys-\ntem, which scored an F-score of 0.712. The im-\nplemented approaches are described below along\nwith additional experiments that were conducted\non the provided training and validation datasets.\n2 Data\nThe dataset provided by the organizers of the\ntask (Kiesel et al., 2019) consists of news arti-\ncles, half of which are labelled as hyperpartisan.\nIt is split into two sets, the training and the vali-\ndation set, where for each article the article title,\nbody and published date are provided. The train-\ning set consists of 500.000 news articles and it is\nused as training set for the presented experiments\nand the provided validation set (150.000 news ar-\nticles) is used for validating the approaches. A\nsmall dataset of 645 news articles, manually anno-\ntated, is also provided but not used in the following\nexperiments neither as training nor as validation\ndata. For the evaluation phase, two small datasets\nof 628 and 4000 articles are provided. The \ufb01rst,\ncalled by-article test dataset, is labeled through\ncrowdsourcing on an article basis while the latter,\nnamed by-publisher test dataset, is labeled by the\noverall bias of the publisher as provided by Buz-\nzFeed journalists and MediaBiasFactCheck.com.\nA pre-processing step is applied on both the\narticle title and body in order to clean the text\nand prepare it for the subsequent machine learn-\ning steps. The Natural Language Toolkit (NLTK)\n(Bird et al., 2009) was used to implement this step.\nFirst, the text is split into sentences and then each\nsentence is split in tokens. Lemmatization is ap-\nplied on each token in order to group together the\nin\ufb02ected forms of a word and subsequently re-\nmove the stop words based on a list of commonly\nagreed stop words provided by the NLTK.\n925By article test set By publisher test set\nPrecision Recall F-score Precision Recall F-score\nSuCla 0.556 0.643 0.596 0.535 0.809 0.644\nBOW 0.542 0.971 0.696 0.627 0.808 0.706\nDL 0.592 0.895 0.712 0.608 0.860 0.712\nTable 1: Evaluation results on the two unseen test sets provided by SemEval-2019 Task 4.\n3 Proposed Approach\nWe experimented with three approaches:\n\u000fSuCla: a simple classi\ufb01er based on super-\n\ufb01cial features extracted from the article text\n(e.g. number of words ,contains pronouns ,\nnumber of explanation marks ) and building\nsupervised machine learning models;\n\u000fBOW: a \u2018bag-of-words\u2019 text classi\ufb01er;\n\u000fDL: a deep learning system based on con-\nvolutional neural networks (CNN) (LeCun\net al., 2015) and recurrent neural networks\n(RNN) (Medsker and Jain, 1999).\nThese are further detailed in the next sections.\nIn the experiments reported here, the training\nset was used for building the models and the\nvalidation set for calculating the evaluation mea-\nsures: precision, recall and F-score1. The deci-\nsion threshold is set to 0.5 where probabilities \u0015\n0.5 indicate hyperpartisan articles and <0.5 non\nhyperpartisan. Regarding the submissions to the\ntask through the TIRA platform, training was con-\nducted of\ufb02ine by concatenating the training and\nvalidation sets as input and then, the trained mod-\nels were deployed to TIRA to classify the new, un-\nseen news articles.\n3.1 Super\ufb01cial Features Classi\ufb01er (SuCla)\nThis simple approach is an adaptation of the one\nintroduced in (Boididou et al., 2018), which was\nused to assess the credibility of Twitter posts. We\nextracted a set of super\ufb01cial features from the arti-\ncle title, which are a subset of the tweet-based fea-\ntures presented in (Boididou et al., 2018). These\nare listed in Table 2. In (Boididou et al., 2018),\nfurther information about the Twitter user who\nposted the tweet was used, but such information is\nnot available for the article publisher in this task.\nWe extracted the title-based features on the\ntraining and validation sets. The extracted 15-\ndimensional feature vectors were \ufb01rst normalized\n1https://en.wikipedia.org/wiki/Precision andrecall# Title-based features\n01 Text length\n02 Number of words\n03 Contains question mark (Boolean)\n04 Contains exclamation mark (Boolean)\n05 Contains 1st person pronoun (Boolean)\n06 Contains 2nd person pronoun (Boolean)\n07 Contains 3rd person pronoun (Boolean)\n08 Number of uppercase characters\n09 Number of positive sentiment words\n10 Number of negative sentiment words\n11 Number of slang words\n12 Has : symbol (Boolean)\n13 Number of question marks\n14 Number of exclamation marks\n15 Number of nouns\nTable 2: List of features extracted from the article title.\nin the [0,1] range and then fed to a Radial Ba-\nsis Function (RBF) kernel SVM. The model pa-\nrameters were calculated using a grid searching\nmethod. The software was deployed to TIRA\nand evaluated on the unseen articles of the test\nset. The normalization of test article features was\nconducted using the scaling parameters computed\nfrom the training set. Then, articles were classi\ufb01ed\nas hyperpartisan or not with a score in the [0,1]\nrange: the higher the score the more likely the ar-\nticle is hyperpartisan. The precision, recall and F-\nmeasure of this run are presented in Table 1 for the\ntwo test sets of unseen articles (by-pyblisher and\nby-article). The resulting F-scores of 0.596 and\n0.644 for the by-article and by-publisher test set\nrespectively indicate that this approach performs\nbetter than random but requires more distinctive\nfeatures to further improve the accuracy.\n3.2 Bag-of-words Classi\ufb01er (BOW)\nA text item, in our case the article title or body, can\nbe represented as a vector of word occurrences.\nThis is the well-known and widely used \u2018bag-of-\nwords\u2019 (BOW) model. For building the BOW, we\n926Precision Recall F-measure\nTitle Body Title Body Title Body\nMNB 0.54 0.54 0.66 0.79 0.59 0.65\nRF 0.56 0.54 0.74 0.68 0.64 0.60\nLR 0.58 0.56 0.79 0.81 0.67 0.66\nTable 3: Evaluation results for Bag of Words on article title and body. Three classi\ufb01ers are evaluated: Multinomial\nNaive Bayes (MNB), Random Forest (RF) and Logistic Regression (LR).\nstarted with the clean text resulting from the pre-\nprocessing step described in Section 2 and counted\nthe number of occurrences of each word from two\nvocabularies that were created based on the train-\ning set, and had a size of 64,663 and 364,359\nwords for the title and the body respectively. Three\nclassi\ufb01ers were evaluated: a) Multinomial Naive\nBayes (MNB), b) Random Forest (RF) and c) Lo-\ngistic Regression (LR). The obtained test results\nare presented in Table 3. According to it, LR out-\nperforms the other two, irrespective of whether the\narticle title or body is used as input. The result-\ning F-scores are 0.67 (title) and 0.66 (body). The\nBOW counts the number of times a word appear in\nthe text of an article (term frequency) regardless of\nits appearance in other articles. In addition, we ap-\nplied the Term Frequency-Inverse Document Fre-\nquency (TF-IDF), which adapts the term weight in\nrelation to the times that this term appears in all\narticles. However, the resulting F-score of 0.58\n(title) and 0.66 (body) for LR indicated that clas-\nsi\ufb01cation performance would suffer. Additionally,\nin the attempt to take advantage of both the title\nand body text, we implemented a fusion step based\non averaging the prediction scores of the individ-\nual models. As a result, a minor increase of the\nF-score to 0.69 was obtained at the expense of ad-\nditional complexity.\nThe LR classi\ufb01er was \ufb01nally trained on the full\nset of articles (both training and validation sets)\nand article title. The new BOW model was de-\nployed to TIRA to classify the unseen news ar-\nticles. This led to slightly better results as pre-\nsented in Table 1. Compared to the SuCla ap-\nproach, the BOW performance is signi\ufb01cantly bet-\nter, especially on the by-article dataset.\n3.3 Deep Learning System (DL)\nAn overview of the employed network architec-\nture, which was devised for the task, is presented\nin Figure 1.\nThe input to the network is the vectorized formof the articles\u2019 title and body. The input text is\npre-processed as described in Section 2. An addi-\ntional step is applied in order to form the text so\nthat the inputs to the network have the same shape\nfor each article. More speci\ufb01cally, for each article\nwe retain the \ufb01rst 64 sentences, and for each sen-\ntence the \ufb01rst 64 words. This results in a (64x64)-\ndimensional tensor that is provided as input to the\nnetwork. Zero padding is applied in order to \ufb01ll\nmissing words and/or sentences.\nThe input of the network is provided to an Em-\nbedding layer, to map each word of the input text\nto a word embedding . We used the pre-trained\nFastText word embeddings (Mikolov et al., 2018)\nof size 300. The weights of this layer are not up-\ndated during learning. In that way, we overcome\nthe limitation of a bounded vocabulary, imposed\nby the training set, and the network can process\nwords outside the training sets since they exist in\nthe vocabulary of FastText. The output of this\nlayer is a tensor of (64x64x300) for each article.\nThen, we apply multiple convolution \ufb01lters with\ndifferent kernel sizes on the output of the Em-\nbedding layer. In that way, the network can cap-\nture word sequence structure in different granu-\nlarity levels. The convolutional layers are used\nwith kernel sizes of (1x1), (1x3), (1x5), and (1x7)\nand in combination with a ReLU activation func-\ntion. The output of each convolutional layer is\na (64x64x128)-dimensional tensor. The outputs\nof the four convolutional layers are then concate-\nnated on the channel axis (the last tensor dimen-\nsion) to form a (64x64x512)-dimensional tensor\nper article. Finally max-pooling is performed over\nthe word axis, i.e., the maximum value per channel\nand sentence is extracted. To this end, the Embed-\nding and Convolutional layers of the network cap-\nture word-level information from the article text.\nAfter max-pooling on the outputs of the Convo-\nlutional layers, the (64x512)-dimensional tensors\nare given to a bidirectional Recurrent Neural Net-\nwork (bi-RNN) (Schuster and Paliwal, 1997) that\n927\nFigure 1: The deep learning architecture developed for classifying a news item as hyperpartisan or not.\ncalculates sentence vectors by taking into account\nthe neighbor sentences. More precisely, for every\narticle sentence i, the hidden vector hisummarizes\nthe neighbor sentences around sentence ibut still\nfocuses on that sentence. We employed the bidi-\nrectional Gated Recurrent Units (bi-GRU) (Cho\net al., 2014) as the recurrent unit of the bi-RNN,\nwhich is an improved version of the standard re-\ncurrent unit. The output of the bi-GRU layer is\nprovided to an attention mechanism (Yang et al.,\n2016) that weights each sentence vectors based\non their similarity to a sentence-level context vec-\ntor, and then averages the weighted vectors to sin-\ngle vector. The result of the Attention layer is a\n(1x256)-dimensional vector.\nAt the \ufb01nal stage, the network captures article-\nlevel information. The output of the Attention\nlayer is fed to a fully connected layer to get the\n\ufb01nal prediction of the network. In this layer, we\napply Sigmoid activation to map the output to the\n[0,1] range, which represents the probability of the\narticle being hyperpartisan. Finally, the network\nis trained with the binary cross-entropy loss func-\ntion, weight decay with a 5\u000310\u00004regularization\nfactor, Adam (Kingma and Ba, 2014) optimizer,\nand10\u00003learning rate. Training is done for 100\nepochs with a batch size of 32 articles, and the\nbest network is selected based on the performance\non the validation set.\nThis method performs better than the other two\napproaches, achieving an F-score of 0.712 (Table\n1) for both test sets.\n3.4 Ideal Fusion\nWe implemented an ideal fusion method in order\nto examine the complementarity between the threeproposed approaches. This is a theoretical scheme\n(oracle) which takes the outputs of the individ-\nual approaches and selects the correct classi\ufb01er:\nat least one model needs to classify correctly an\narticle. An F-score of 0.85 is achieved on the vali-\ndation set, far better than the individual classi\ufb01ers\naccuracy (SuCla: 0.51, BOW: 0.67, DL: 0.65) in-\ndicating that the models bring complementary in-\nformation, which make them good components of\na combined model.\n4 Conclusions\nThis paper summarized our participation in\nSemEval-2019 Task 4, where we aimed at the\nchallenge of Hyperpartisan News Detection. We\ntried to approach the problem from the perspec-\ntive of standard supervised learning techniques, as\nwell as more complex deep learning approaches.\nWhile none of the methods gave groundbreaking\nresults, our set of experiments and observations\nprovides a solid basis for future research on the\nproblem. In particular, we intend to conduct more\nextensive analysis on the annotated data and ex-\ntract patterns that will be more representative and\ndistinctive for the problem at hand. Moreover, we\nwill consider combining the three proposed ap-\nproaches with the aim of creating a stronger and\nmore accurate combined model. The signi\ufb01cant\nincrease in performance of the ideal fusion method\npoints out the bene\ufb01ts of such a strategy.\n5 Acknowledgments\nThis work is supported by the WeVerify project,\nwhich is funded by the European Commission un-\nder contract number 825297.\n928References\nSteven Bird, Ewan Klein, and Edward Loper. 2009.\nNatural language processing with Python: analyz-\ning text with the natural language toolkit . \u201d O\u2019Reilly\nMedia, Inc.\u201d.\nChristina Boididou, Symeon Papadopoulos, Markos\nZampoglou, Lazaros Apostolidis, Olga Pa-\npadopoulou, and Yiannis Kompatsiaris. 2018.\nDetection and visualization of misleading content\non twitter. International Journal of Multimedia\nInformation Retrieval , 7(1):71\u201386.\nKyunghyun Cho, Bart Van Merri \u00a8enboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using rnn encoder-decoder\nfor statistical machine translation. arXiv preprint\narXiv:1406.1078 .\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. SemEval-\n2019 Task 4: Hyperpartisan News Detection. In\nProceedings of The 13th International Workshop on\nSemantic Evaluation (SemEval 2019) . Association\nfor Computational Linguistics.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980 .\nYann LeCun, Yoshua Bengio, and Geoffrey Hinton.\n2015. Deep learning. nature , 521(7553):436.\nLarry Medsker and Lakhmi C Jain. 1999. Recurrent\nneural networks: design and applications . CRC\npress.\nTomas Mikolov, Edouard Grave, Piotr Bojanowski,\nChristian Puhrsch, and Armand Joulin. 2018. Ad-\nvances in pre-training distributed word representa-\ntions. In Proceedings of the International Confer-\nence on Language Resources and Evaluation (LREC\n2018) .\nMartin Potthast, Tim Gollub, Matti Wiegmann, and\nBenno Stein. 2019. TIRA Integrated Research Ar-\nchitecture. In Nicola Ferro and Carol Peters, edi-\ntors, Information Retrieval Evaluation in a Chang-\ning World - Lessons Learned from 20 Years of CLEF .\nSpringer.\nMike Schuster and Kuldip K Paliwal. 1997. Bidirec-\ntional recurrent neural networks. IEEE Transactions\non Signal Processing , 45(11):2673\u20132681.\nZichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,\nAlex Smola, and Eduard Hovy. 2016. Hierarchi-\ncal attention networks for document classi\ufb01cation.\nInProceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 1480\u20131489.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Brenda Starr at SemEval-2019 Task 4: hyperpartisan news detection", "author": ["O Papadopoulou", "G Kordopatis-Zilos"], "pub_year": "2019", "venue": "Proceedings of the \u2026", "abstract": "In the effort to tackle the challenge of Hyperpartisan News Detection, ie, the task of deciding  whether a news article is biased towards one party, faction, cause, or person, we"}, "filled": false, "gsrank": 67, "pub_url": "https://aclanthology.org/S19-2157/", "author_id": ["kd-2aqYAAAAJ", "Do-7qx4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:0RCkEumtpkMJ:scholar.google.com/&output=cite&scirp=66&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D60%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0RCkEumtpkMJ&ei=DrWsaPuyO5XUieoPmrax2A8&json=", "num_citations": 6, "citedby_url": "/scholar?cites=4874774863226867921&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:0RCkEumtpkMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/S19-2157.pdf"}}]